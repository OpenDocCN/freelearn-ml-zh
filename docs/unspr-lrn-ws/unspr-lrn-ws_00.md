# 第一章：The

# 无监督学习

# 研讨会

开始使用无监督学习算法，并简化你的未整理数据，以帮助进行未来的预测

Aaron Jones, Christopher Kruger, 和 Benjamin Johnston

# 无监督学习研讨会

版权 © 2020 Packt Publishing

版权所有。未经出版商事先书面许可，本课程的任何部分不得以任何形式或任何手段复制、存储于检索系统中或传播，但在关键文章或评论中嵌入简短的引用除外。

本课程在准备过程中已尽力确保所提供信息的准确性。然而，本课程所包含的信息是按“原样”销售的，不提供任何形式的明示或暗示的担保。无论是作者、Packt Publishing 还是其经销商和分销商，都不对因本课程直接或间接引起的或被声称引起的任何损害负责。

Packt Publishing 力求通过恰当使用大写字母提供课程中提及的所有公司和产品的商标信息。然而，Packt Publishing 无法保证这些信息的准确性。

**作者：** Aaron Jones, Christopher Kruger, 和 Benjamin Johnston

**审阅人：** Richard Brooker, John Wesley Doyle, Priyanjit Ghosh, Sani Kamal, Ashish Pratik Patil, Geetank Raipuria, 和 Ratan Singh

**执行编辑：** Rutuja Yerunkar

**采购编辑：** Manuraj Nair, Royluis Rodrigues, Anindya Sil, 和 Karan Wadekar

**生产编辑：** Salma Patel

**编辑委员会：** Megan Carlisle, Samuel Christa, Mahesh Dhyani, Heather Gopsill, Manasa Kumar, Alex Mazonowicz, Monesh Mirpuri, Bridget Neale, Dominic Pereira, Shiny Poojary, Abhishek Rane, Brendan Rodrigues, Erol Staveley, Ankita Thakur, Nitesh Thakur, 和 Jonathan Wray

初版：2020 年 7 月

生产参考：1280720

ISBN：978-1-80020-070-8

由 Packt Publishing Ltd. 出版

Livery Place, 35 Livery Street

英国伯明翰 B3 2PB

# 目录

## 前言    i

## 1. 聚类简介    1

### 简介    2

### 无监督学习与有监督学习   2

### 聚类    4

### 识别聚类   5

### 二维数据   6

### 练习 1.01：数据中的聚类识别   7

### k-means 聚类简介   11

### 无数学 k-means 步骤详解   11

### k-means 聚类深入讲解    13

### 替代距离度量 – 曼哈顿距离 14

### 更深的维度 15

### 练习 1.02：在 Python 中计算欧氏距离 16

### 练习 1.03：通过距离概念形成聚类 18

### 练习 1.04：从零开始的 k-means – 第一部分：数据生成 20

### 练习 1.05：从零开始的 k-means – 第二部分：实现 k-means 24

### 聚类性能 – 轮廓系数 29

### 练习 1.06：计算轮廓系数 31

### 活动 1.01：实现 k-means 聚类 33

### 总结 35

## 2. 层次聚类 37

### 简介 38

### 聚类复习 38

### k-means 复习 39

### 层次结构的组织 39

### 层次聚类简介 41

### 层次聚类步骤 43

### 层次聚类示例演练 43

### 练习 2.01：构建层次结构 47

### 连接 52

### 练习 2.02：应用连接标准 53

### 凝聚型与分裂型聚类 58

### 练习 2.03：使用 scikit-learn 实现凝聚层次聚类 60

### 活动 2.01：比较 k-means 和层次聚类 64

### k-means 与层次聚类 68

### 总结 69

## 3. 邻域方法与 DBSCAN 71

### 简介 72

### 聚类作为邻域 73

### DBSCAN 简介 75

### DBSCAN 详细解析 76

### DBSCAN 算法演练 77

### 练习 3.01：评估邻域半径大小的影响 80

### DBSCAN 属性 - 邻域半径 84

### 活动 3.01：从头实现 DBSCAN 86

### DBSCAN 属性 - 最小点数 88

### 练习 3.02：评估最小点数阈值的影响 89

### 活动 3.02：将 DBSCAN 与 k-means 和层次聚类进行比较 93

### DBSCAN 与 k-means 和层次聚类的对比 95

### 总结 96

## 4. 主成分分析与降维技术 99

### 介绍 100

### 什么是降维？ 100

### 降维技术的应用 102

### 维度灾难 104

### 降维技术概览 106

### 降维 108

### 主成分分析 109

### 均值 109

### 标准差 109

### 协方差 110

### 协方差矩阵 110

### 练习 4.01：使用 pandas 库计算均值、标准差和方差 111

### 特征值与特征向量 116

### 练习 4.02：计算特征值和特征向量 117

### PCA 的过程 121

### 练习 4.03：手动执行 PCA 123

### 练习 4.04：使用 scikit-learn 进行 PCA 128

### 活动 4.01：手动 PCA 与 scikit-learn 对比 133

### 恢复压缩后的数据集 136

### 练习 4.05：使用手动 PCA 可视化方差减少 136

### 练习 4.06：使用 scikit-learn 可视化方差减少 143

### 练习 4.07：在 Matplotlib 中绘制 3D 图 147

### 活动 4.02: 使用扩展的种子数据集进行 PCA 150

### 总结 153

## 5\. 自编码器 155

### 简介 156

### 人工神经网络基础 157

### 神经元 159

### Sigmoid 函数 160

### 修正线性单元 (ReLU) 161

### 练习 5.01: 建模人工神经网络的神经元 161

### 练习 5.02: 使用 ReLU 激活函数建模神经元 165

### 神经网络: 架构定义 169

### 练习 5.03: 定义一个 Keras 模型 171

### 神经网络: 训练 173

### 练习 5.04: 训练一个 Keras 神经网络模型 175

### 活动 5.01: MNIST 神经网络 185

### 自编码器 187

### 练习 5.05: 简单自编码器 188

### 活动 5.02: 简单 MNIST 自编码器 193

### 练习 5.06: 多层自编码器 194

### 卷积神经网络 199

### 练习 5.07: 卷积自编码器 200

### 活动 5.03: MNIST 卷积自编码器 205

### 总结 207

## 6\. t-分布随机邻居嵌入 209

### 简介 210

### MNIST 数据集 210

### 随机邻居嵌入 (SNE) 212

### t-分布 SNE 213

### 练习 6.01: t-SNE MNIST 214

### 活动 6.01: 葡萄酒 t-SNE 227

### 解释 t-SNE 图 229

### 困惑度 230

### 练习 6.02: t-SNE MNIST 和困惑度 230

### 活动 6.02: t-SNE 葡萄酒与困惑度 235

### 迭代   236

### 练习 6.03：t-SNE MNIST 和迭代   237

### 活动 6.03：t-SNE 葡萄酒和迭代   242

### 关于可视化的最终思考   243

### 总结   243

## 7. 主题建模   245

### 简介   246

### 主题模型   247

### 练习 7.01：设置环境   249

### 主题模型的高级概览   250

### 商业应用   254

### 练习 7.02：数据加载   256

### 清理文本数据   259

### 数据清理技术   260

### 练习 7.03：逐步清理数据   261

### 练习 7.04：完整数据清理   266

### 活动 7.01：加载和清理 Twitter 数据   268

### 潜在狄利克雷分配   270

### 变分推理   272

### 词袋模型   275

### 练习 7.05：使用计数向量化器创建词袋模型   276

### 困惑度   277

### 练习 7.06：选择主题数量   279

### 练习 7.07：运行 LDA   281

### 可视化   286

### 练习 7.08：可视化 LDA   287

### 练习 7.09：尝试四个主题   291

### 活动 7.02：LDA 和健康推文   296

### 练习 7.10：使用 TF-IDF 创建词袋模型   298

### 非负矩阵分解   299

### 弗罗贝纽斯范数   301

### 乘法更新算法   301

### 练习 7.11：非负矩阵分解   302

### 练习 7.12：可视化 NMF   306

### 活动 7.03：非负矩阵分解 309

### 总结 310

## 市场购物篮分析 313

### 介绍 314

### 市场购物篮分析 314

### 应用案例 317

### 重要的概率性指标 318

### 练习 8.01：创建样本事务数据 319

### 支持度 321

### 置信度 322

### 提升度和杠杆度 323

### 信念度 324

### 练习 8.02：计算指标 325

### 事务数据的特征 328

### 练习 8.03：加载数据 329

### 数据清理和格式化 333

### 练习 8.04：数据清理和格式化 334

### 数据编码 339

### 练习 8.05：数据编码 341

### 活动 8.01：加载和准备完整的在线零售数据 343

### Apriori 算法 344

### 计算修正 347

### 练习 8.06：执行 Apriori 算法 348

### 活动 8.02：在完整的在线零售数据集上运行 Apriori 算法 354

### 关联规则 356

### 练习 8.07：推导关联规则 358

### 活动 8.03：在完整的在线零售数据集上找出关联规则 365

### 总结 367

## 热点分析 369

### 介绍 370

### 空间统计 371

### 概率密度函数 372

### 在商业中使用热点分析 374

### 核密度估计 375

### 带宽值 376

### 练习 9.01：带宽值的影响 376

### 选择最优带宽 380

### 练习 9.02：使用网格搜索选择最优带宽 381

### 核函数 384

### 练习 9.03：核函数的影响 387

### 核密度估计推导 389

### 练习 9.04：模拟核密度估计推导 389

### 活动 9.01：一维密度估计 393

### 热点分析 394

### 练习 9.05：使用 Seaborn 加载数据和建模 396

### 练习 9.06：与底图一起工作 404

### 活动 9.02：分析伦敦犯罪 411

### 总结 414

## 附录 417
