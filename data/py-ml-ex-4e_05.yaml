- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Predicting Stock Prices with Regression Algorithms
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用回归算法预测股票价格
- en: In the previous chapter, we predicted ad clicks using logistic regression. In
    this chapter, we will solve a problem that interests everyone—predicting stock
    prices. Getting wealthy by means of smart investment—who isn’t interested?! Stock
    market movements and stock price predictions have been actively researched by
    a large number of financial, trading, and even technology corporations. A variety
    of methods have been developed to predict stock prices using machine learning
    techniques. Herein, we will focus on learning several popular regression algorithms,
    including linear regression, regression trees and regression forests, and support
    vector regression, utilizing them to tackle this billion (or trillion)-dollar
    problem.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们使用逻辑回归预测了广告点击。在本章中，我们将解决一个人人都感兴趣的问题——预测股票价格。通过智能投资致富——谁不感兴趣呢？股市波动和股价预测一直以来都是金融、交易甚至技术公司积极研究的课题。使用机器学习技术预测股票价格的各种方法已被开发出来。在此，我们将专注于学习几种流行的回归算法，包括线性回归、回归树和回归森林以及支持向量回归，利用它们来解决这个价值数十亿（甚至数万亿）美元的问题。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: What is regression?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是回归分析？
- en: Mining stock price data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挖掘股票价格数据
- en: Getting started with feature engineering
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始进行特征工程
- en: Estimating with linear regression
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线性回归进行估算
- en: Estimating with decision tree regression
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用决策树回归进行估算
- en: Implementing a regression forest
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现回归森林
- en: Evaluating regression performance
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估回归性能
- en: Predicting stock prices with the three regression algorithms
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用三种回归算法预测股票价格
- en: What is regression?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是回归分析？
- en: '**Regression** is one of the main types of supervised learning in machine learning.
    In regression, the training set contains observations (also called features) and
    their associated **continuous** target values. The process of regression has two
    phases:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归分析**是机器学习中监督学习的主要类型之一。在回归分析中，训练集包含观测值（也称为特征）及其相关的**连续**目标数值。回归的过程包括两个阶段：'
- en: The first phase is exploring the relationships between the observations and
    the targets. This is the training phase.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一阶段是探索观测值和目标之间的关系。这是训练阶段。
- en: The second phase is using the patterns from the first phase to generate the
    target for a future observation. This is the prediction phase.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二阶段是利用第一阶段的模式生成未来观测的目标。这是预测阶段。
- en: 'The overall process is depicted in the following diagram:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程如下图所示：
- en: '![A picture containing text, screenshot, font, diagram  Description automatically
    generated](img/B21047_05_01.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本、屏幕截图、字体、图表的图片  自动生成的描述](img/B21047_05_01.png)'
- en: 'Figure 5.1: Training and prediction phase in regression'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1：回归中的训练和预测阶段
- en: The major difference between regression and classification is that the output
    values in regression are continuous, while in classification they are discrete.
    This leads to different application areas for these two supervised learning methods.
    Classification is basically used to determine desired memberships or characteristics,
    as you’ve seen in previous chapters, such as email being spam or not, newsgroup
    topics, or ad click-through. Conversely, regression mainly involves estimating
    an outcome or forecasting a response.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析和分类的主要区别在于回归分析的输出值是连续的，而分类的输出值是离散的。这导致这两种监督学习方法在应用领域上有所不同。分类主要用于确定所需的成员资格或特征，正如您在前几章中看到的那样，例如电子邮件是否为垃圾邮件，新闻组主题或广告点击率。相反，回归分析主要涉及估算结果或预测响应。
- en: 'An example of estimating continuous targets with linear regression is depicted
    as follows, where we try to fit a line against a set of two-dimensional data points:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线性回归估算连续目标的示例如下，我们试图拟合一条直线以适应一组二维数据点：
- en: '![A picture containing screenshot, line, rectangle  Description automatically
    generated](img/B21047_05_02.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![包含屏幕截图、线条、矩形的图片  自动生成的描述](img/B21047_05_02.png)'
- en: 'Figure 5.2: Linear regression example'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2：线性回归示例
- en: 'Typical machine learning regression problems include the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的机器学习回归问题包括以下内容：
- en: Predicting house prices based on location, square footage, and the number of
    bedrooms and bathrooms
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据位置、面积以及卧室和浴室数量预测房价
- en: Estimating power consumption based on information about a system’s processes
    and memory
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据系统进程和内存信息估算功耗
- en: Forecasting demand in retail
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测零售需求
- en: Predicting stock prices
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测股票价格
- en: I’ve talked about regression in this section and will briefly introduce its
    use in the stock market and trading in the next one.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我在本节中讲解了回归分析，并将在下一节简要介绍它在股市和交易中的应用。
- en: Mining stock price data
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 挖掘股票价格数据
- en: In this chapter, we’ll work as a stock quantitative analyst/researcher, exploring
    how to predict stock prices with several typical machine learning regression algorithms.
    Let’s start with a brief overview of the stock market and stock prices.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将作为股票量化分析师/研究员，探讨如何使用几种典型的机器学习回归算法预测股票价格。我们从对股市和股票价格的简要概述开始。
- en: A brief overview of the stock market and stock prices
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 股市和股票价格的简要概述
- en: The stock of a corporation signifies ownership in the corporation. A single
    share of the stock represents a claim on the fractional assets and the earnings
    of the corporation in proportion to the total number of shares. Stocks can be
    traded between shareholders and other parties via stock exchanges and organizations.
    Major stock exchanges include the New York Stock Exchange, the NASDAQ, London
    Stock Exchange Group, and the Hong Kong Stock Exchange. The prices that a stock
    is traded at fluctuate essentially due to the law of supply and demand.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 公司股票代表对公司所有权的认定。每一股股票代表公司资产和收益的某个比例，具体比例依据总股数而定。股票可以在股东和其他各方之间通过股票交易所和组织进行交易。主要的股票交易所包括纽约证券交易所、纳斯达克、伦敦证券交易所集团和香港证券交易所。股票交易价格的波动基本上是由供求法则决定的。
- en: 'In general, investors want to buy low and sell high. This sounds simple enough,
    but it’s very challenging to implement, as it’s monumentally difficult to say
    whether a stock price will go up or down. There are two main streams of studies
    that attempt to understand factors and conditions that lead to price changes,
    or even forecast future stock prices, **fundamental analysis** and **technical
    analysis**:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，投资者希望以低价买入，高价卖出。这听起来很简单，但实施起来非常具有挑战性，因为很难准确预测股票价格是会上涨还是下跌。主要有两种研究方向试图理解导致价格变化的因素和条件，甚至预测未来的股票价格，**基本面分析**和**技术分析**：
- en: '**Fundamental analysis**: This stream focuses on underlying factors that influence
    a company’s value and business, including overall economy and industry conditions
    from macro perspectives, the company’s financial conditions, management, and competitors
    from micro perspectives.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基本面分析**：这一流派关注影响公司价值和经营的基础因素，包括从宏观角度来看整体经济和行业的情况，从微观角度来看公司的财务状况、管理层和竞争对手。'
- en: '**Technical analysis**: Conversely, this stream predicts future price movements
    through the statistical study of past trading activity, including price movement,
    volume, and market data. Predicting prices via machine learning techniques is
    an important topic in technical analysis nowadays.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**技术分析**：相反，这一领域通过对过去交易活动的统计研究来预测未来的价格走势，包括价格波动、交易量和市场数据。利用机器学习技术预测价格现在已经成为技术分析中的一个重要话题。'
- en: Many quantitative, or quant, trading firms use machine learning to empower automated
    and algorithmic trading.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 许多量化交易公司使用机器学习来增强自动化和算法交易。
- en: In theory, we can apply regression techniques to predict the prices of a particular
    stock. However, it’s difficult to ensure the stock we pick is suitable for learning
    purposes—its price should follow some learnable patterns, and it can’t have been
    affected by unprecedented instances or irregular events. Hence, herein we’ll focus
    on one of the most popular **stock indexes** to better illustrate and generalize
    our price regression approach.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，我们可以应用回归技术来预测某一特定股票的价格。然而，很难确保我们选取的股票适合用于学习——其价格应该遵循一些可学习的模式，且不能受到前所未有的事件或不规则情况的影响。因此，我们将在这里重点关注一个最流行的**股票指数**，以更好地说明和概括我们的价格回归方法。
- en: Let’s first cover what an index is. A stock index is a statistical measure of
    the value of a portion of the overall stock market. An index includes several
    stocks that are diverse enough to represent a section of the whole market. Also,
    the price of an index is typically computed as the weighted average of the prices
    of selected stocks.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们来了解什么是股票指数。股票指数是衡量整体股市一部分价值的统计指标。一个指数包含了几个股票，这些股票足够多样化，能够代表整个市场的一部分。此外，指数的价格通常是通过选定股票价格的加权平均计算得出的。
- en: The **NASDAQ Composite** is one of the longest-established and most commonly
    watched indexes in the world. It includes all the stocks listed on the NASDAQ
    exchange, covering a wide range of sectors. NASDAQ primarily lists stocks of technology
    companies, including established giants like Apple, Amazon, Microsoft, and Google
    (Alphabet), as well as emerging growth companies.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**纳斯达克综合指数**是全球历史最悠久、最常被关注的指数之一。它包括所有在纳斯达克交易所上市的股票，涵盖了广泛的行业。纳斯达克主要列出技术公司股票，包括苹果、亚马逊、微软和谷歌（字母表）等已建立的大公司，以及新兴的成长型公司。'
- en: 'You can view its daily prices and performance on Yahoo Finance at [https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC](https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC).
    For example:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在雅虎财经查看它的每日价格和表现，网址是[https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC](https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC)。例如：
- en: '![A screenshot of a graph  Description automatically generated](img/B21047_05_03.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![A screenshot of a graph  Description automatically generated](img/B21047_05_03.png)'
- en: 'Figure 5.3: Screenshot of daily prices and performance in Yahoo Finance'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3：雅虎财经每日价格和表现的截图
- en: 'On each trading day, the price of stock changes and is recorded in real time.
    Five values illustrating the movements in price over one unit of time (usually
    one day, but it can also be one week or one month) are key trading indicators.
    They are as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个交易日，股票价格会发生变化并实时记录。五个展示价格在一个单位时间（通常为一天，但也可以是一个星期或一个月）内波动的数值是关键交易指标，具体如下：
- en: '**Open**: The starting price for a given trading day'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开盘**：某个交易日的起始价格'
- en: '**Close**: The final price on that day'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收盘**：当天的最终价格'
- en: '**High**: The highest prices at which the stock traded on that day'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最高**：当天股票交易的最高价格'
- en: '**Low**: The lowest prices at which the stock traded on that day'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最低**：当天股票交易的最低价格'
- en: '**Volume**: The total number of shares traded before the market closed on that
    day'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交易量**：当天市场闭盘前的总交易股数'
- en: We will focus on NASDAQ and use its historical prices and performance to predict
    future prices. In the following sections, we will explore how to develop price
    prediction models, specifically regression models, and what can be used as indicators
    or predictive features.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重点关注纳斯达克，并利用其历史价格和表现来预测未来的价格。在接下来的部分中，我们将探讨如何开发价格预测模型，特别是回归模型，并研究哪些可以作为指标或预测特征。
- en: Getting started with feature engineering
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始进行特征工程
- en: When it comes to a machine learning algorithm, the first question to ask is
    usually what features are available or what the predictive variables are.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到机器学习算法时，通常第一个问题是可用的特征是什么，或者预测变量是什么。
- en: The driving factors that are used to predict future prices of NASDAQ, the **close**
    prices, include historical and current **open** prices as well as historical performance
    (**high**, **low**, and **volume**). Note that current or same-day performance
    (**high**, **low**, and **volume**) shouldn’t be included because we simply can’t
    foresee the highest and lowest prices at which the stock traded, or the total
    number of shares traded before the market closed on that day.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 用于预测纳斯达克未来价格的驱动因素，包括历史和当前的**开盘**价格以及历史表现（**最高**，**最低**，和**交易量**）。请注意，不应包括当前或当天的表现（**最高**，**最低**，和**交易量**），因为我们根本无法预见股票在当天交易中达到的最高和最低价格，或者在市场闭盘前的交易总量。
- en: Predicting the close price with only those preceding four indicators doesn’t
    seem promising and might lead to underfitting. So, we need to think of ways to
    generate more features in order to increase predictive power. In machine learning,
    **feature engineering** is the process of creating features in order to improve
    the performance of a machine learning algorithm. Feature engineering is essential
    in machine learning and is usually where we spend the most effort in solving a
    practical problem.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 仅用前面提到的四个指标来预测收盘价似乎不太可行，并可能导致欠拟合。因此，我们需要考虑如何生成更多的特征，以提高预测能力。在机器学习中，**特征工程**是通过创建特征来提高机器学习算法性能的过程。特征工程在机器学习中至关重要，通常是我们在解决实际问题时花费最多精力的地方。
- en: Feature engineering usually requires sufficient domain knowledge and can be
    very difficult and time-consuming. In reality, features used to solve a machine
    learning problem are not usually directly available and need to be specifically
    designed and constructed.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程通常需要足够的领域知识，并且可能非常困难且耗时。实际上，用于解决机器学习问题的特征通常不是直接可用的，而是需要专门设计和构建的。
- en: When making an investment decision, investors usually look at historical prices
    over a period of time, not just the price the day before. Therefore, in our stock
    price prediction case, we can compute the average close price over the past week
    (five trading days), over the past month, and over the past year as three new
    features. We can also customize the time window to the size we want, such as the
    past quarter or the past six months. On top of these three averaged price features,
    we can generate new features associated with the price trend by computing the
    ratios between each pair of average prices in the three different time frames,
    for instance, the ratio between the average price over the past week and the past
    year.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在做出投资决策时，投资者通常会查看一段时间内的历史价格，而不仅仅是前一天的价格。因此，在我们的股票价格预测案例中，我们可以计算过去一周（五个交易日）、过去一个月和过去一年的平均收盘价，作为三个新特征。我们也可以自定义时间窗口大小，例如过去一个季度或过去六个月。除了这三个平均价格特征，我们还可以通过计算三个不同时间框架内每对平均价格之间的比率，生成与价格趋势相关的新特征，例如过去一周和过去一年的平均价格比率。
- en: Besides prices, volume is another important factor that investors analyze. Similarly,
    we can generate new volume-based features by computing the average volumes in
    several different time frames and the ratios between each pair of averaged values.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 除了价格，成交量是投资者分析的另一个重要因素。类似地，我们可以通过计算不同时间框架内的平均成交量以及每对平均值之间的比率来生成新的基于成交量的特征。
- en: Besides historical averaged values in a time window, investors also greatly
    consider stock volatility. Volatility describes the degree of variation of prices
    for a given stock or index over time. In statistical terms, it’s basically the
    standard deviation of the close prices. We can easily generate new sets of features
    by computing the standard deviation of close prices in a particular time frame,
    as well as the standard deviation of volumes traded. Similarly, ratios between
    each pair of standard deviation values can be included in our engineered feature
    pool.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 除了时间窗口中的历史平均值，投资者还会非常关注股票的波动性。波动性描述的是在一定时间内某只股票或指数价格变化的程度。从统计学的角度来看，它基本上是收盘价的标准差。我们可以通过计算特定时间框架内的收盘价标准差以及成交量的标准差，轻松生成新的特征集。类似地，可以将每对标准差值之间的比率也包含在我们生成的特征池中。
- en: Last but not least, return is a significant financial metric that investors
    closely watch for. Return is the gain or loss percentage of a close price for
    a stock/index in a particular period. For example, daily return and annual return
    are financial terms we frequently hear.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，回报是投资者密切关注的一个重要金融指标。回报是某股票/指数在特定期间内收盘价的涨跌幅。例如，日回报和年回报是我们常听到的金融术语。
- en: 'They are calculated as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 它们的计算方式如下：
- en: '![](img/B21047_05_001.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_001.png)'
- en: '![](img/B21047_05_002.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_002.png)'
- en: Here, *price*[i] is the price on the *i*^(th) day and *price*[i][-1] is the
    price on the day before. Weekly and monthly returns can be computed similarly.
    Based on daily returns, we can produce a moving average over a particular number
    of days.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*price*[i] 是第 *i* 天的价格，*price*[i][-1] 是前一天的价格。周回报和月回报可以以类似方式计算。基于日回报，我们可以生成某一特定天数的移动平均值。
- en: 'For instance, given the daily returns of the past week, *return*[i:i-1], *return*[i-1:i-2],
    *return*[i-2:i-3], *return*[i-3:i-4], and *return*[i-4:i-5], we can calculate
    the moving average over that week as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，给定过去一周的每日回报，*return*[i:i-1]、*return*[i-1:i-2]、*return*[i-2:i-3]、*return*[i-3:i-4]
    和 *return*[i-4:i-5]，我们可以按如下方式计算该周的移动平均值：
- en: '![](img/B21047_05_003.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_003.png)'
- en: 'In summary, we can generate the following predictive variables by applying
    feature engineering techniques:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们可以通过应用特征工程技术生成以下预测变量：
- en: '![](img/B21047_05_04.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_04.png)'
- en: 'Figure 5.4: Generated features (1)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4：生成的特征 (1)
- en: '![](img/B21047_05_05.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_05.png)'
- en: 'Figure 5.5: Generated features (2)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5：生成的特征 (2)
- en: 'Eventually, we are able to generate, in total, 31 sets of features, along with
    the following six original features:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们能够总共生成31组特征，以及以下六个原始特征：
- en: 'OpenPrice[i]: This feature represents the open price'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenPrice[i]：该特征表示开盘价
- en: 'OpenPrice[i-1]: This feature represents the open price on the past day'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenPrice[i-1]：该特征表示前一日的开盘价
- en: 'ClosePrice[i-1]: This feature represents the close price on the past day'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ClosePrice[i-1]：该特征表示前一日的收盘价
- en: 'HighPrice[i-1]: This feature represents the highest price on the past day'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HighPrice[i-1]：该特征表示过去一天的最高价格
- en: 'LowPrice[i-1]: This feature represents the lowest price on the past day'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LowPrice[i-1]：该特征表示过去一天的最低价格
- en: 'Volume[i-1]: This feature represents the volume on the past day'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Volume[i-1]：该特征表示过去一天的成交量
- en: Acquiring data and generating features
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取数据并生成特征
- en: For easier reference, we will implement the code to generate features here rather
    than in later sections. We will start by obtaining the dataset we need for our
    project.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便参考，我们将在这里实现生成特征的代码，而不是在后续部分。我们将首先获取项目所需的数据集。
- en: 'Throughout the project, we will acquire stock index price and performance data
    from Yahoo Finance. For example, on the Historical Data [https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC](https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC),
    we can change the `Time Period` to `Dec 01, 2005 – Dec10, 2005`, select `Historical
    Prices` in `Show` and `Daily` in `Frequency` (or open this link directly: [https://finance.yahoo.com/quote/%5EIXIC/history?period1=1133395200&period2=1134172800&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true](https://finance.yahoo.com/quote/%5EIXIC/history?period1=1133395200&period2=1134172800&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true)),
    and then click on the **Apply** button. Click the **Download data** button to
    download the data and name the file `20051201_20051210.csv`.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个项目中，我们将从Yahoo Finance获取股票指数价格和表现数据。例如，在历史数据[https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC](https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC)页面上，我们可以将`Time
    Period`更改为`Dec 01, 2005 – Dec10, 2005`，在`Show`中选择`Historical Prices`，在`Frequency`中选择`Daily`（或者直接打开此链接：[https://finance.yahoo.com/quote/%5EIXIC/history?period1=1133395200&period2=1134172800&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true](https://finance.yahoo.com/quote/%5EIXIC/history?period1=1133395200&period2=1134172800&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true)），然后点击**Apply**按钮。点击**Download
    data**按钮下载数据并将文件命名为`20051201_20051210.csv`。
- en: 'We can load the data we just downloaded as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以如下加载刚才下载的数据：
- en: '[PRE0]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that the output is a pandas DataFrame object. The `Date` column is the
    index column, and the rest of the columns are the corresponding financial variables.
    In the following lines of code, you will see how powerful pandas is at simplifying
    data analysis and transformation on **relational** (or table-like) data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，输出的是一个pandas DataFrame对象。`Date`列是索引列，其余列是相应的财务变量。在接下来的代码行中，您将看到pandas如何在**关系型**（或表格型）数据上简化数据分析和转换的强大功能。
- en: 'First, we implement feature generation by starting with a sub-function that
    directly creates features from the original six features, as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们通过一个子函数实现特征生成，该子函数直接从原始的六个特征中创建特征，如下所示：
- en: '[PRE1]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, we develop a sub-function that generates six features related to average
    close prices:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们开发了一个生成六个与平均收盘价相关特征的子函数：
- en: '[PRE2]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Similarly, a sub-function that generates six features related to average volumes
    is as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，生成与平均成交量相关的六个特征的子函数如下：
- en: '[PRE3]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As for the standard deviation, we develop the following sub-function for the
    price-related features:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 至于标准差，我们为与价格相关的特征开发了以下子函数：
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Similarly, a sub-function that generates six volume-based standard deviation
    features is as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，生成六个基于成交量的标准差特征的子函数如下：
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Seven return-based features are generated using the following sub-function:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下子函数生成七个基于回报的特征：
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, we put together the main feature generation function that calls all
    the preceding sub-functions:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将所有前面的子函数汇总成主要的特征生成函数：
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that the window sizes here are `5`, `21`, and `252`, instead of `7`, `30`,
    and `365`, representing the weekly, monthly, and yearly windows respectively.
    This is because there are 252 (rounded) trading days in a year, 21 trading days
    in a month, and 5 in a week.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这里的窗口大小是`5`、`21`和`252`，而不是`7`、`30`和`365`，分别代表每周、每月和每年的窗口。这是因为一年有252个（四舍五入后的）交易日，一个月有21个交易日，一周有5个交易日。
- en: 'We can apply this feature engineering strategy on the NASDAQ Composite data
    queried from 1990 to the first half of 2023, as follows (or directly download
    it from this page: [https://finance.yahoo.com/quote/%5EIXIC/history?period1=631152000&period2=1688083200&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true](https://finance.yahoo.com/quote/%5EIXIC/history?period1=631152000&period2=1688083200&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true)):'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这种特征工程策略应用于从 1990 年到 2023 年上半年查询的 NASDAQ 综合指数数据，如下所示（或直接从此页面下载： [https://finance.yahoo.com/quote/%5EIXIC/history?period1=631152000&period2=1688083200&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true](https://finance.yahoo.com/quote/%5EIXIC/history?period1=631152000&period2=1688083200&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true)）：
- en: '[PRE8]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Take a look at what the data with the new features looks like:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下带有新特征的数据是什么样子的：
- en: '[PRE9]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding command line generates the following output:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令行生成了以下输出：
- en: '![A screenshot of a computer  Description automatically generated](img/B21047_05_06.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![计算机的截图  描述自动生成](img/B21047_05_06.png)'
- en: 'Figure 5.6: Printout of the first five rows of the DataFrame'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6：DataFrame 前五行的打印输出
- en: Since all the features and driving factors are ready, we will now focus on regression
    algorithms that estimate the continuous target variables based on these predictive
    features.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 既然所有特征和驱动因素已经准备就绪，我们现在将专注于回归算法，它们基于这些预测特征来估计连续的目标变量。
- en: Estimating with linear regression
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线性回归进行估计
- en: The first regression model that comes to mind is **linear regression**. Does
    this mean fitting data points using a linear function, as its name implies? Let’s
    explore it.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个想到的回归模型是 **线性回归**。这是否意味着用线性函数拟合数据点，正如其名字所暗示的那样？让我们来探索一下。
- en: How does linear regression work?
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性回归是如何工作的？
- en: 'In simple terms, linear regression tries to fit as many of the data points
    as possible, with a straight line in two-dimensional space or a plane in three-dimensional
    space. It explores the linear relationship between observations and targets, and
    the relationship is represented in a linear equation or weighted sum function.
    Given a data sample *x* with *n* features, *x*[1], *x*[2], …, *x*[n] (*x* represents
    a feature vector and *x = (x*[1]*, x*[2]*, …, x*[n]*)*), and weights (also called
    **coefficients**) of the linear regression model *w* (*w* represents a vector
    (*w*[1], *w*[2], …, *w*[n])), the target *y* is expressed as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，线性回归尝试用一条直线（在二维空间中）或一个平面（三维空间中）拟合尽可能多的数据点。它探索观察值与目标之间的线性关系，这种关系用线性方程或加权求和函数表示。给定一个数据样本
    *x*，其中包含 *n* 个特征，*x*[1]，*x*[2]，…，*x*[n]（*x* 表示特征向量，*x = (x*[1]*, x*[2]*, …, x*[n]*)*），以及线性回归模型的权重（也叫做
    **系数**）*w*（*w* 表示一个向量 (*w*[1]，*w*[2]，…，*w*[n]）），目标 *y* 表达如下：
- en: '![](img/B21047_05_004.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_004.png)'
- en: 'Also, sometimes the linear regression model comes with an intercept (also called
    bias), *w*[0], so the preceding linear relationship becomes as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，有时线性回归模型会带有截距项（也叫偏差），*w*[0]，所以之前的线性关系变为：
- en: '![](img/B21047_05_005.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_005.png)'
- en: 'Does it look familiar? The **logistic regression** algorithm you learned in
    *Chapter 4*, *Predicting Online Ad Click-Through with Logistic Regression*, is
    just an addition of logistic transformation on top of the linear regression, which
    maps the continuous weighted sum to the *0* (negative) or *1* (positive) class.
    Similarly, a linear regression model, or specifically its weight vector, *w*,
    is learned from the training data, with the goal of minimizing the estimation
    error defined as the **mean squared error** (**MSE**), which measures the average
    of squares of difference between the truth and prediction. Given *m* training
    samples, (*x*^((1)), *y*^((1))), (*x*^((2)), *y*^((2))), … (*x*^((i)), *y*^((i)))…,
    (*x*^((m)), *y*^((m))), the loss function *J(w)* regarding the weights to be optimized
    is expressed as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来熟悉吗？你在*第 4 章*《使用逻辑回归预测在线广告点击率》中学到的 **逻辑回归** 算法，实际上是在线性回归的基础上加上了逻辑变换，它将连续的加权和映射到
    *0*（负类）或 *1*（正类）。同样，线性回归模型，或特别是它的权重向量 *w*，是从训练数据中学习的，目标是最小化定义为 **均方误差** (**MSE**)
    的估计误差，它衡量真值和预测值之间差异的平方平均值。给定 *m* 个训练样本，(*x*^((1))，*y*^((1)))，(*x*^((2))，*y*^((2)))，…，(*x*^((i))，*y*^((i)))…，(*x*^((m))，*y*^((m)))，损失函数
    *J(w)* 关于待优化权重的表达式如下：
- en: '![](img/B21047_05_006.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_006.png)'
- en: Here, ![](img/B21047_05_007.png) is the prediction.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B21047_05_007.png) 是预测结果。
- en: 'Again, we can obtain the optimal *w* so that *J*(*w*) is minimized using gradient
    descent. The first-order derivative, the gradient ![](img/B21047_04_027.png),
    is derived as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以通过梯度下降法得到最优的 *w*，使得 *J*(*w*) 最小化。以下是导出的梯度，即一阶导数！[](img/B21047_04_027.png)：
- en: '![](img/B21047_05_009.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_009.png)'
- en: 'Combined with the gradient and learning rate ![](img/B21047_05_010.png), the
    weight vector *w* can be updated in each step as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 结合梯度和学习率！[](img/B21047_05_010.png)，权重向量 *w* 可以在每一步中按如下方式更新：
- en: '![](img/B21047_05_011.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_011.png)'
- en: 'After a substantial number of iterations, the learned *w* is then used to predict
    a new sample *x’*, as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在经过大量迭代后，学习到的 *w* 用于预测一个新样本 *x’*，如下所示：
- en: '![](img/B21047_05_012.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_012.png)'
- en: After learning about the mathematical theory behind linear regression, let’s
    implement it from scratch in the next section.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了线性回归背后的数学理论后，我们将在下一部分从头实现它。
- en: Implementing linear regression from scratch
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从头实现线性回归
- en: Now that you have a thorough understanding of gradient-descent-based linear
    regression, we’ll implement it from scratch.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经对基于梯度下降的线性回归有了透彻的了解，我们将从头实现它。
- en: 'We start by defining the function computing the prediction,![](img/B21047_05_013.png),
    with the current weights:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义计算预测的函数，![](img/B21047_05_013.png)，并使用当前的权重：
- en: '[PRE10]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, we continue with the function updating the weight, *w*, with one step
    in a gradient descent manner, as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们继续用梯度下降的方式更新权重 *w*，如下所示：
- en: '[PRE11]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, we add the function that calculates the loss *J(w)* as well:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们还添加计算损失 *J(w)* 的函数：
- en: '[PRE12]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, put all functions together with a model training function by performing
    the following tasks:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将所有函数与模型训练函数结合在一起，执行以下任务：
- en: Update the weight vector in each iteration
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每次迭代中更新权重向量
- en: Print out the current cost for every 500 (or it can be any number) iterations
    to ensure cost is decreasing and things are on the right track
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每 `500` 次（或者可以是任意数字）迭代时输出当前的成本，以确保成本在下降，且一切都在正确的轨道上：
- en: 'Let’s see how it’s done by executing the following commands:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过执行以下命令来看看是如何做到的：
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally, predict the results of new input values using the trained model as
    follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用训练好的模型预测新输入值的结果，如下所示：
- en: '[PRE14]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Implementing linear regression is very similar to logistic regression, as you
    just saw. Let’s examine it with a small example:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 实现线性回归与实现逻辑回归非常相似，正如你刚刚所看到的。让我们通过一个小示例来进一步检验：
- en: '[PRE15]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Train a linear regression model with `100` iterations, at a learning rate of
    `0.01`, based on intercept-included weights:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `100` 次迭代训练线性回归模型，学习率为 `0.01`，基于包含截距的权重：
- en: '[PRE16]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Check the model’s performance on new samples as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 检查模型在新样本上的表现，如下所示：
- en: '[PRE17]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Refer to the following screenshot for the result:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考以下截图查看结果：
- en: '![A picture containing screenshot, display, rectangle, square  Description
    automatically generated](img/B21047_05_07.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![A picture containing screenshot, display, rectangle, square  Description
    automatically generated](img/B21047_05_07.png)'
- en: 'Figure 5.7: Linear regression on a toy dataset'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7：在玩具数据集上进行线性回归
- en: The model we trained correctly predicts new samples (depicted by the stars).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们训练的模型正确地预测了新样本（由星号表示）。
- en: 'Let’s try it on another dataset, the diabetes dataset from scikit-learn:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在另一个数据集上试试，来自 scikit-learn 的糖尿病数据集：
- en: '[PRE18]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Train a linear regression model with `5000` iterations, at a learning rate
    of `1`, based on intercept-included weights (the loss is displayed every `500`
    iterations):'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `5000` 次迭代训练线性回归模型，学习率为 `1`，基于包含截距的权重（每 `500` 次迭代显示一次损失）：
- en: '[PRE19]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The estimate is pretty close to the ground truth.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 该估计与真实值非常接近。
- en: Next, let’s utilize scikit-learn to implement linear regression.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们利用 scikit-learn 来实现线性回归。
- en: Implementing linear regression with scikit-learn
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 实现线性回归
- en: So far, we have used gradient descent in weight optimization, but like with
    logistic regression, linear regression is also open to **Stochastic Gradient Descent**
    (**SGD**). To use it, we can simply replace the `update_weights_gd` function with
    the `update_weights_sgd` function we created in *Chapter 4*, *Predicting Online
    Ad Click-Through with Logistic Regression*.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经在权重优化中使用了梯度下降法，但与逻辑回归一样，线性回归也可以使用**随机梯度下降**（**SGD**）。为了使用它，我们只需用我们在*第4章*《使用逻辑回归预测在线广告点击率》中创建的
    `update_weights_sgd` 函数替换 `update_weights_gd` 函数。
- en: 'We can also directly use the SGD-based regression algorithm, `SGDRegressor`,
    from scikit-learn:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以直接使用 scikit-learn 中基于 SGD 的回归算法 `SGDRegressor`：
- en: '[PRE20]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here, `''squared_error''` for the `loss` parameter indicates that the cost
    function is MSE; `penalty` is the regularization term, and it can be `None`, `l1`,
    or `l2`, which is similar to `SGDClassifier` in *Chapter 4*, *Predicting Online
    Ad Click-Through with Logistic Regression*, in order to reduce overfitting; `max_iter`
    is the number of iterations; and the remaining two parameters mean the learning
    rate is `0.2` and unchanged during the course of training over, at most, `100`
    iterations. Train the model and output predictions on the testing set of the diabetes
    dataset, as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`'squared_error'`作为`loss`参数表示成本函数为均方误差（MSE）；`penalty`是正则化项，可以是`None`、`l1`或`l2`，类似于*第4章*中的`SGDClassifier`，*使用逻辑回归预测在线广告点击率*，用于减少过拟合；`max_iter`是迭代次数；其余两个参数表示学习率为`0.2`，并在最多`100`次训练迭代过程中保持不变。训练模型并输出糖尿病数据集测试集上的预测结果，过程如下：
- en: '[PRE21]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: You can also implement linear regression with TensorFlow. Let’s see this in
    the next section.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用TensorFlow实现线性回归。让我们在下一节中看看。
- en: Implementing linear regression with TensorFlow
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用TensorFlow实现线性回归
- en: 'First, we import TensorFlow and construct the model:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入TensorFlow并构建模型：
- en: '[PRE22]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: It uses a linear layer (or you can think of it as a linear function) to connect
    the input in the `X_train.shape[1]` dimension and the output in the `1` dimension.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 它使用一个线性层（或者你可以把它看作一个线性函数）将输入的`X_train.shape[1]`维度与输出的`1`维度连接。
- en: 'Next, we specify the loss function, the MSE, and a gradient descent optimizer,
    `Adam`, with a learning rate of `1`:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们指定损失函数为MSE，并使用学习率为`1`的梯度下降优化器`Adam`：
- en: '[PRE23]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, we train the model on the diabetes dataset for 100 iterations, as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将在糖尿病数据集上训练模型100次，过程如下：
- en: '[PRE24]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This also prints out the loss for every iteration. Finally, we make predictions
    using the trained model:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这还会打印出每次迭代的损失。最后，我们使用训练好的模型进行预测：
- en: '[PRE25]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The next regression algorithm you will learn about is decision tree regression.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将学习的回归算法是决策树回归。
- en: Estimating with decision tree regression
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用决策树回归进行估算
- en: '**Decision tree regression** is also called a **regression tree**. It is easy
    to understand a regression tree by comparing it with its sibling, the classification
    tree, which you are already familiar with. In this section, we will delve into
    employing decision tree algorithms for regression tasks.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**决策树回归**也称为**回归树**。通过将回归树与它的兄弟——分类树进行对比，理解回归树就变得容易了，而分类树你已经非常熟悉了。在本节中，我们将深入探讨使用决策树算法进行回归任务。'
- en: Transitioning from classification trees to regression trees
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从分类树到回归树的过渡
- en: In classification, a decision tree is constructed by recursive binary splitting
    and growing each node into left and right children. In each partition, it greedily
    searches for the most significant combination of features and its value as the
    optimal splitting point. The quality of separation is measured by the weighted
    purity of the labels of the two resulting children, specifically via Gini Impurity
    or Information Gain.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类中，决策树通过递归二叉分裂构建，每个节点分裂成左子树和右子树。在每个分区中，它贪婪地搜索最重要的特征组合及其值作为最优分割点。分割的质量通过两个子节点标签的加权纯度来衡量，具体是通过基尼不纯度或信息增益。
- en: 'In regression, the tree construction process is almost identical to the classification
    one, with only two differences because the target becomes continuous:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归中，树的构建过程几乎与分类树相同，只有两个不同之处，因为目标值变为连续值：
- en: The quality of the splitting point is now measured by the weighted MSE of two
    children; the MSE of a child is equivalent to the variance of all target values,
    and the smaller the weighted MSE, the better the split
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分割点的质量现在通过两个子节点的加权MSE来衡量；子节点的MSE等同于所有目标值的方差，加权MSE越小，分割效果越好。
- en: The **average** value of targets in a terminal node becomes the leaf value,
    instead of the majority of labels in the classification tree
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均**值作为终端节点的目标值，成为叶子值，而不是分类树中标签的多数值'
- en: 'To make sure you understand regression trees, let’s work on a small house price
    estimation example using the **house type** and **number of bedrooms**:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保你理解回归树，我们将通过一个小型房价估算示例，使用**房屋类型**和**卧室数量**：
- en: '![A picture containing text, screenshot, number, font  Description automatically
    generated](img/B21047_05_08.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![一张包含文本、截图、数字、字体的图片  描述自动生成](img/B21047_05_08.png)'
- en: 'Figure 5.8: Toy dataset of house prices'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8：房价玩具数据集
- en: 'We first define the MSE and weighted MSE computation functions that will be
    used in our calculation:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义用于计算的MSE和加权MSE函数：
- en: '[PRE26]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Then, we define the weighted MSE after a split in a node:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义了节点分割后的加权MSE：
- en: '[PRE27]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Test things out by executing the following commands:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行以下命令来测试：
- en: '[PRE28]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'To build the house price regression tree, we first exhaust all possible feature
    and value pairs, and we compute the corresponding MSE:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建房价回归树，我们首先列举所有可能的特征和值对，并计算相应的MSE：
- en: '[PRE29]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The lowest MSE is achieved with the `type, semi` pair, and the root node is
    then formed by this splitting point. The result of this partition is as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 最低的MSE是通过`type, semi`这一对得到的，因此根节点由这个分割点构成。此分割的结果如下：
- en: '![](img/B21047_05_09.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_09.png)'
- en: 'Figure 5.9: Splitting using (type=semi)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9：使用(type=semi)进行分割
- en: 'If we are satisfied with a one-level regression tree, we can stop here by assigning
    both branches as leaf nodes, with the value as the average of the targets of the
    samples included. Alternatively, we can go further down the road by constructing
    the second level from the right branch (the left branch can’t be split further):'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对一个单层回归树感到满意，我们可以通过将两个分支都指定为叶子节点来停止，并且该值为包含样本的目标值的平均值。或者，我们可以继续向下构建第二层，从右分支开始（左分支无法进一步分裂）：
- en: '[PRE30]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'With the second splitting point specified by the `bedroom, 3` pair (whether
    it has at least three bedrooms or not) with the lowest MSE, our tree becomes as
    shown in the following diagram:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 通过指定`bedroom, 3`这一对（是否至少有三间卧室）作为第二个分割点，它具有最低的MSE，我们的树如下图所示：
- en: '![](img/B21047_05_10.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21047_05_10.png)'
- en: 'Figure 5.10: Splitting using (bedroom>=3)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.10：使用(bedroom>=3)进行分割
- en: We can finish up the tree by assigning average values to both leaf nodes.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将平均值分配给两个叶子节点来完成树的构建。
- en: Implementing decision tree regression
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现决策树回归
- en: Now that you’re clear about the regression tree construction process, it’s time
    for coding.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，既然你已经清楚了回归树构建的过程，是时候开始编写代码了。
- en: 'The node splitting utility function we will define in this section is identical
    to what we used in *Chapter 3*, *Predicting Online Ad Click-Through with Tree-Based
    Algorithms*, which separates samples in a node into left and right branches, based
    on a feature and value pair:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本节中定义的节点分割工具函数与我们在*第3章*《基于树算法预测在线广告点击率》中使用的完全相同，它基于特征和值对，将节点中的样本分割为左分支和右分支：
- en: '[PRE31]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Next, we define the greedy search function, trying out all the possible splits
    and returning the one with the least weighted MSE:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义贪心搜索函数，尝试所有可能的分割，并返回具有最小加权均方误差（MSE）的分割：
- en: '[PRE32]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The preceding selection and splitting process occurs recursively in each of
    the subsequent children. When a stopping criterion is met, the process at a node
    stops, and the mean value of the sample, `targets`, will be assigned to this terminal
    node:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 前述的选择和分割过程会在每个后续的子节点中递归发生。当满足停止标准时，节点处的过程停止，样本的平均值`targets`将被分配给该终端节点：
- en: '[PRE33]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'And finally, here is the recursive function, `split`, that links it all together.
    It checks whether any stopping criteria are met and assigns the leaf node if so,
    proceeding with further separation otherwise:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这是一个递归函数`split`，它将所有内容连接在一起。它检查是否满足停止条件，如果满足，则分配叶子节点，否则继续分割：
- en: '[PRE34]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The entry point of the regression tree construction is as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 回归树构建的入口点如下：
- en: '[PRE35]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, let’s test it with a hand-calculated example:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过手动计算的示例来测试一下：
- en: '[PRE36]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'To verify that the trained tree is identical to what we constructed by hand,
    we write a function displaying the tree:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证训练得到的树与我们手动构建的树相同，我们编写了一个显示树的函数：
- en: '[PRE37]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now that you have a better understanding of the regression tree after implementing
    it from scratch, we can directly use the `DecisionTreeRegressor` package ([https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html))
    from scikit-learn. Let’s apply it to an example of predicting California house
    prices. The dataset contains a median house value as the target variable, median
    income, housing median age, total rooms, total bedrooms, population, households,
    latitude, and longitude as features. It was obtained from the StatLib repository
    ([https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html))
    and can be directly loaded using the `sklearn.datasets.fetch_california_housing`
    function, as follows:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过从零实现回归树，你已经对它有了更好的理解，我们可以直接使用scikit-learn中的`DecisionTreeRegressor`包（[https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)）。让我们将它应用于一个预测加利福尼亚房价的示例。数据集包含作为目标变量的房屋中位数价格、收入中位数、住房中位年龄、总房间数、总卧室数、人口、住户数、纬度和经度作为特征。它来自StatLib库（[https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html)），可以通过`sklearn.datasets.fetch_california_housing`函数直接加载，代码如下：
- en: '[PRE38]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We take the last 10 samples for testing and the rest to train a `DecisionTreeRegressor`
    decision tree, as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将最后10个样本用于测试，其他样本用于训练`DecisionTreeRegressor`决策树，代码如下：
- en: '[PRE39]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We then apply the trained decision tree to the test set:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将训练好的决策树应用到测试集上：
- en: '[PRE40]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Compare predictions with the ground truth, as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 与真实值比较预测结果，如下所示：
- en: '[PRE41]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: We see the predictions are quite accurate.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到预测结果非常准确。
- en: We have implemented a regression tree in this section. Is there an ensemble
    version of the regression tree? Let’s see next.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们实现了回归树。有没有回归树的集成版本呢？让我们接下来看看。
- en: Implementing a regression forest
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现回归森林
- en: In *Chapter 3*, *Predicting Online Ad Click-Through with Tree-Based Algorithms*,
    we explored **random forests** as an ensemble learning method, by combining multiple
    decision trees that are separately trained and randomly subsampling training features
    in each node of a tree. In classification, a random forest makes a final decision
    by a majority vote of all tree decisions. Applied to regression, a random forest
    regression model (also called a **regression forest**) assigns the average of
    regression results from all decision trees to the final decision.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第3章*，*基于树的算法预测在线广告点击率*中，我们探讨了**随机森林**作为一种集成学习方法，通过将多个决策树结合起来，分别训练并在每棵树的节点中随机子抽样训练特征。在分类中，随机森林通过对所有树的决策进行多数投票来做出最终决定。在回归中，随机森林回归模型（也叫做**回归森林**）将所有决策树的回归结果平均后作为最终决策。
- en: 'Here, we will use the regression forest package, `RandomForestRegressor`, from
    scikit-learn and deploy it in our California house price prediction example:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用scikit-learn中的回归森林包`RandomForestRegressor`，并将其应用到加利福尼亚房价预测的示例中：
- en: '[PRE42]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: You’ve learned about three regression algorithms. So, how should we evaluate
    regression performance? Let’s find out in the next section.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学习了三种回归算法。那么，我们应该如何评估回归性能呢？让我们在接下来的部分中找出答案。
- en: Evaluating regression performance
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估回归性能
- en: 'So far, we’ve covered three popular regression algorithms in depth and implemented
    them from scratch by using several prominent libraries. Instead of judging how
    well a model works on testing sets by printing out the prediction, we need to
    evaluate its performance with the following metrics, which give us better insights:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经深入讨论了三种流行的回归算法，并通过使用几个著名的库从零实现了它们。我们需要通过以下指标来评估模型在测试集上的表现，而不是仅仅通过输出预测值来判断模型的好坏，这些指标能为我们提供更深入的见解：
- en: The MSE, as I mentioned, measures the squared loss corresponding to the expected
    value. Sometimes, the square root is taken on top of the MSE in order to convert
    the value back into the original scale of the target variable being estimated.
    This yields the **Root Mean Squared Error** (**RMSE**). Also, the RMSE has the
    benefit of penalizing large errors more, since we first calculate the square of
    an error.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如我所提到的，MSE（均方误差）衡量的是对应于期望值的平方损失。有时，MSE会取平方根，以便将该值转换回目标变量的原始尺度。这就得到了**均方根误差**（**RMSE**）。此外，RMSE的一个优点是对大误差的惩罚更为严厉，因为我们首先计算的是误差的平方。
- en: Conversely, the **Mean Absolute Error** (**MAE**) measures the absolute loss.
    It uses the same scale as the target variable and gives us an idea of how close
    the predictions are to the actual values.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相反，**平均绝对误差**（**MAE**）衡量的是绝对损失。它使用与目标变量相同的尺度，并让我们了解预测值与实际值的接近程度。
- en: For both the MSE and MAE, the smaller the value, the better the regression model.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 对于MSE和MAE而言，值越小，回归模型越好。
- en: R² (pronounced **r squared**) indicates the goodness of the fit of a regression
    model. It is the fraction of the dependent variable variation that a regression
    model is able to explain. It ranges from `0` to `1`, representing from no fit
    to a perfect prediction. There is a variant of R² called **adjusted** R². It adjusts
    for the number of features in a model relative to the number of data points.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R²（读作**r平方**）表示回归模型拟合的好坏。它是回归模型能够解释的因变量变化的比例。其值范围从`0`到`1`，表示从无拟合到完美预测。R²有一个变种叫做**调整后的**R²，它会根据模型中的特征数与数据点数的比值进行调整。
- en: 'Let’s compute these three measurements on a linear regression model, using
    corresponding functions from scikit-learn:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个线性回归模型上计算这三个指标，使用scikit-learn中的相应函数：
- en: 'We will work on the diabetes dataset again and fine-tune the parameters of
    the linear regression model, using the grid search technique:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将再次使用糖尿病数据集，并通过网格搜索技术对线性回归模型的参数进行微调：
- en: '[PRE43]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We obtain the optimal set of parameters:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们获得了最优的参数集：
- en: '[PRE44]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We predict the testing set with the optimal model:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们用最优模型预测测试集：
- en: '[PRE45]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We evaluate the performance on testing sets based on the MSE, MAE, and R² metrics:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们基于MSE、MAE和R²指标评估测试集的性能：
- en: '[PRE46]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Now that you’ve learned about three (or four, you could say) commonly used and
    powerful regression algorithms and performance evaluation metrics, let’s utilize
    each of them to solve our stock price prediction problem.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了三种（或者四种，可以这么说）常用且强大的回归算法和性能评估指标，让我们利用它们来解决股票价格预测问题。
- en: Predicting stock prices with the three regression algorithms
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用三种回归算法预测股票价格
- en: 'Here are the steps to predict the stock price:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是预测股票价格的步骤：
- en: 'Earlier, we generated features based on data from 1990 to the first half of
    2023, and we will now continue to construct the training set with data from 1990
    to 2022 and the testing set with data from the first half of 2023:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之前，我们基于1990年到2023年上半年的数据生成了特征，现在我们将继续使用1990年到2022年的数据构建训练集，使用2023年上半年的数据构建测试集：
- en: '[PRE47]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'All fields in the `dataframe` data except `''close''` are feature columns,
    and `''close''` is the target column. We have `8,061` training samples and each
    sample is `37`-dimensional. We also have `124` testing samples:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '`dataframe`数据中的所有字段除了`''close''`都是特征列，`''close''`是目标列。我们有`8,061`个训练样本，每个样本是`37`维的。我们还拥有`124`个测试样本：'
- en: '[PRE48]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '**Best practice**'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '**最佳实践**'
- en: Time series data often exhibits temporal dependencies, where values at one time
    point are influenced by previous values. Ignoring these dependencies can lead
    to poor model performance. We need to use a train-test split to evaluate models,
    ensuring that the test set contains data from a later time period than the training
    set to simulate real-world forecasting scenarios.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据通常表现出时间依赖性，即某个时间点的值受前一个时间点值的影响。忽略这些依赖性可能导致模型性能差。我们需要使用训练集和测试集划分来评估模型，确保测试集的数据来自训练集之后的时间段，以模拟现实中的预测场景。
- en: 'We will first experiment with SGD-based linear regression. Before we train
    the model, you should realize that SGD-based algorithms are sensitive to data
    with features at very different scales; for example, in our case, the average
    value of the `open` feature is around 3,777, while that of the `moving_avg_365`
    feature is 0.00052 or so. Hence, we need to normalize features into the same or
    a comparable scale. We do so by removing the mean and rescaling to unit variance
    with `StandardScaler`:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先尝试基于SGD的线性回归。在训练模型之前，你应该意识到基于SGD的算法对特征尺度差异很大的数据非常敏感；例如，在我们的案例中，`open`特征的平均值大约是3,777，而`moving_avg_365`特征的平均值大约是0.00052。因此，我们需要将特征归一化为相同或可比的尺度。我们通过移除均值并使用`StandardScaler`将数据重新缩放到单位方差来实现这一点：
- en: '[PRE49]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We rescale both sets with `scaler`, taught by the training set:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`scaler`对两个数据集进行缩放，`scaler`由训练集教得：
- en: '[PRE50]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now, we can search for the SGD-based linear regression with the optimal set
    of parameters. We specify `l2` regularization and `5000` maximal iterations and
    we tune the regularization term multiplier, `alpha`, and initial learning rate,
    `eta0`:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以通过搜索具有最佳参数集的基于SGD的线性回归。我们指定`l2`正则化和`5000`次最大迭代，并调整正则化项乘数`alpha`和初始学习率`eta0`：
- en: '[PRE51]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'For cross-validation, we need to ensure that the training data in each split
    comes before the corresponding test data, preserving the temporal order of the
    time series. Here, we use the `TimeSeriesSplit` method from scikit-learn:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于交叉验证，我们需要确保每次拆分中的训练数据在相应的测试数据之前，从而保持时间序列的时间顺序。在这里，我们使用scikit-learn的`TimeSeriesSplit`方法：
- en: '[PRE52]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Here, we create a 3-fold time series-specific cross-validator and employ it
    in grid search.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个3折时间序列特定的交叉验证器，并在网格搜索中使用它。
- en: 'Select the best linear regression model and make predictions of the testing
    samples:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择最佳的线性回归模型并对测试样本进行预测：
- en: '[PRE53]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Measure the prediction performance via R²:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过R²测量预测性能：
- en: '[PRE54]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: We achieve an R² of `0.959` with a fine-tuned linear regression model.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过精调的线性回归模型实现了`0.959`的R²。
- en: '**Best practice**'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '**最佳实践**'
- en: With time series data, there is a risk of overfitting due to the potential complexity
    of temporal patterns. Models may capture noise instead of genuine patterns if
    not regularized properly. We need to apply regularization techniques like L1 or
    L2 regularization to prevent overfitting. Also, when you perform cross-validation
    for hyperparameter tuning, consider using time series-specific cross-validation
    methods to assess model performance while preserving temporal order.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 使用时间序列数据时，由于时间模式的复杂性，可能会存在过拟合的风险。如果没有正确地进行正则化，模型可能会捕捉到噪声而不是实际的模式。我们需要应用正则化技术，如L1或L2正则化，以防止过拟合。此外，在进行超参数调优的交叉验证时，考虑使用时间序列特定的交叉验证方法来评估模型性能，同时保持时间顺序。
- en: 'Similarly, let’s experiment with a decision tree. We tune the maximum depth
    of the tree, `max_depth`; the minimum number of samples required to further split
    a node, `min_samples_split`; and the minimum number of samples required to form
    a leaf node, `min_samples_leaf`, as follows:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似地，让我们尝试一个决策树。我们调整树的最大深度`max_depth`；进一步分割节点所需的最小样本数`min_samples_split`；以及形成叶节点所需的最小样本数`min_samples_leaf`，如下所示：
- en: '[PRE55]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Note this may take a while; hence, we use all available CPU cores for training.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这可能需要一些时间；因此，我们使用所有可用的CPU核心进行训练。
- en: 'Select the best regression forest model and make predictions of the testing
    samples:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择最佳的回归森林模型并对测试样本进行预测：
- en: '[PRE56]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Measure the prediction performance as follows:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如下所示测量预测性能：
- en: '[PRE57]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: An R² of `0.912` is obtained with a tweaked decision tree.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调整过的决策树，获得了`0.912`的R²。
- en: 'Finally, we experiment with a random forest. We specify 30 decision trees to
    ensemble and tune the same set of hyperparameters used in each tree, as follows:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们尝试了一个随机森林。我们指定30棵决策树进行集成，并调整每棵树使用的相同超参数集，如下所示：
- en: '[PRE58]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Note this may take a while; hence, we use all available CPU cores for training
    (indicated by `n_jobs=-1`).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这可能需要一些时间；因此，我们使用所有可用的CPU核心进行训练（通过`n_jobs=-1`表示）。
- en: 'Select the best regression forest model and make predictions of the testing
    samples:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择最佳的回归森林模型并对测试样本进行预测：
- en: '[PRE59]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Measure the prediction performance as follows:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如下所示测量预测性能：
- en: '[PRE60]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: An R² of `0.937` is obtained with a tweaked forest regressor.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调整过的森林回归器，获得了`0.937`的R²。
- en: 'We also plot the prediction generated by each of the three algorithms, along
    with the ground truth:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还绘制了三种算法生成的预测值，并与真实值进行对比：
- en: '![A graph with numbers and lines  Description automatically generated](img/B21047_05_11.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![A graph with numbers and lines  Description automatically generated](img/B21047_05_11.png)'
- en: 'Figure 5.11: Predictions using the three algorithms versus the ground truth'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.11：使用三种算法的预测值与真实值的对比
- en: 'The visualization is produced by the following code:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化是通过以下代码生成的：
- en: '[PRE61]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: We’ve built a stock predictor using three regression algorithms individually
    in this section. Overall, linear regression outperforms the other two algorithms.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们使用三种回归算法分别构建了一个股票预测器。总体来看，线性回归优于其他两种算法。
- en: Stock markets are known for their wild swings. Unlike more stable systems or
    a well-defined project in this chapter, stock prices are volatile and influenced
    by complex factors that are hard to quantify. Also, their behavior is not easily
    captured by even the most sophisticated models. Hence, it is notoriously difficult
    to accurately predict the stock market in the real world. This makes it a fascinating
    challenge to explore the capabilities of different machine learning models.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 股市以其剧烈波动而闻名。与本章中更为稳定的系统或明确的项目不同，股票价格是波动的，受到难以量化的复杂因素的影响。此外，甚至是最复杂的模型也难以捕捉其行为。因此，在现实世界中准确预测股市一直是一个众所周知的难题。这使得探索不同机器学习模型的能力成为一项引人入胜的挑战。
- en: Summary
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we worked on the project of predicting stock (specifically
    stock index) prices using machine learning regression techniques. Regression estimates
    a continuous target variable, as opposed to discrete output in classification
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们使用机器学习回归技术进行了股票（具体来说是股票指数）价格预测项目。回归估计一个连续的目标变量，而分类则估计离散的输出。
- en: We started with a short introduction to the stock market and the factors that
    influence trading prices. We followed this with an in-depth discussion of three
    popular regression algorithms, linear regression, regression trees, and regression
    forests. We covered their definitions, mechanics, and implementations from scratch
    with several popular frameworks, including scikit-learn and TensorFlow, along
    with applications on toy datasets. You also learned the metrics used to evaluate
    a regression model. Finally, we applied what was covered in this chapter to solve
    our stock price prediction problem.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从简要介绍股市及其影响交易价格的因素开始。接着，我们深入讨论了三种流行的回归算法：线性回归、回归树和回归森林。我们涵盖了它们的定义、原理及从零开始的实现，使用了包括scikit-learn和TensorFlow在内的几个流行框架，并应用于玩具数据集。你还学习了用于评估回归模型的指标。最后，我们将本章所学应用于解决股票价格预测问题。
- en: In the next chapter, we will continue working on the stock price prediction
    project, but with powerful **neural networks**. We will see whether they can beat
    what we have achieved with the three regression models in this chapter.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将继续进行股票价格预测项目，但这次我们将使用强大的**神经网络**。我们将看看它们是否能够超越本章中通过三种回归模型取得的成果。
- en: Exercises
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: As mentioned, can you add more signals to our stock prediction system, such
    as the performance of other major indexes? Does this improve prediction?
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，你能否向我们的股票预测系统添加更多信号，比如其他主要指数的表现？这样做是否能提升预测效果？
- en: Try to ensemble those three regression models, for example, by averaging the
    predictions, and see whether you can perform better.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试将这三种回归模型进行集成，例如通过对预测结果进行平均，看看你是否能取得更好的表现。
- en: Join our book’s Discord space
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们书籍的Discord空间
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/yuxi](https://packt.link/yuxi)'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/yuxi](https://packt.link/yuxi)'
- en: '![](img/QR_Code187846872178698968.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code187846872178698968.png)'
