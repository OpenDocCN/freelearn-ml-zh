- en: '*Chapter 1*: Machine Learning Landscape'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第一章*：机器学习的全景'
- en: Welcome to *Hands-On Gradient Boosting with XGBoost and Scikit-Learn*, a book
    that will teach you the foundations, tips, and tricks of XGBoost, the best machine
    learning algorithm for making predictions from tabular data.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到*XGBoost与Scikit-Learn实战*，本书将教授你XGBoost的基础知识、技巧和窍门，XGBoost是最佳的用于从表格数据中进行预测的机器学习算法。
- en: 'The focus of this book is **XGBoost**, also known as **Extreme Gradient Boosting**.
    The structure, function, and raw power of XGBoost will be fleshed out in increasing
    detail in each chapter. The chapters unfold to tell an incredible story: the story
    of XGBoost. By the end of this book, you will be an expert in leveraging XGBoost
    to make predictions from real data.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的重点是**XGBoost**，也称为**极端梯度提升**。XGBoost的结构、功能以及原始能力将在每一章中逐步详细展开。本书的章节展开讲述了一个令人难以置信的故事：XGBoost的故事。通过阅读完本书，你将成为利用XGBoost从真实数据中进行预测的专家。
- en: In the first chapter, XGBoost is presented in a sneak preview. It makes a guest
    appearance in the larger context of **machine learning** regression and classification
    to set the stage for what's to come.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中，XGBoost将以预览的形式出现。它将在**机器学习**回归和分类的更大背景下首次亮相，为接下来的内容铺垫基础。
- en: This chapter focuses on preparing data for machine learning, a process also
    known as **data wrangling**. In addition to building machine learning models,
    you will learn about using efficient **Python** code to load data, describe data,
    handle null values, transform data into numerical columns, split data into training
    and test sets, build machine learning models, and implement **cross-validation**,
    as well as comparing **linear regression** and **logistic regression** models
    with XGBoost.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点介绍为机器学习准备数据的过程，也叫做**数据处理**。除了构建机器学习模型，你还将学习如何使用高效的**Python**代码加载数据、描述数据、处理空值、将数据转换为数值列、将数据分割为训练集和测试集、构建机器学习模型、实施**交叉验证**，并且将**线性回归**和**逻辑回归**模型与XGBoost进行比较。
- en: The concepts and libraries presented in this chapter are used throughout the
    book.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中介绍的概念和库将在全书中使用。
- en: 'This chapter consists of the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含以下内容：
- en: Previewing XGBoost
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预览XGBoost
- en: Wrangling data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据处理
- en: Predicting regression
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测回归
- en: Predicting classification
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测分类
- en: Previewing XGBoost
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预览XGBoost
- en: Machine learning gained recognition with the first neural network in the 1940s,
    followed by the first machine learning checker champion in the 1950s. After some
    quiet decades, the field of machine learning took off when **Deep Blue** famously
    beat world chess champion Gary Kasparov in the 1990s. With a surge in computational
    power, the 1990s and early 2000s produced a plethora of academic papers revealing
    new machine learning algorithms such as **random forests** and **AdaBoost**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习在1940年代随着第一个神经网络的出现而获得认可，接着在1950年代迎来了第一个机器学习国际象棋冠军。经过几十年的沉寂，机器学习领域在1990年代迎来了飞跃，当时**深蓝**在著名的比赛中击败了世界象棋冠军加里·卡斯帕罗夫。随着计算能力的飞速增长，1990年代和2000年代初涌现出大量学术论文，揭示了诸如**随机森林**和**AdaBoost**等新的机器学习算法。
- en: The general idea behind boosting is to transform weak learners into strong learners
    by iteratively improving upon errors. The key idea behind **gradient boosting**
    is to use gradient descent to minimize the errors of the residuals. This evolutionary
    strand, from standard machine learning algorithms to gradient boosting, is the
    focus of the first four chapters of this book.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 提升的基本思路是通过反复改进错误，将弱学习器转变为强学习器。**梯度提升**的核心思想是利用梯度下降法最小化残差的错误。这一从标准机器学习算法到梯度提升的进化思路是本书前四章的核心内容。
- en: XGBoost is short for Extreme Gradient Boosting. The *Extreme* part refers to
    pushing the limits of computation to achieve gains in accuracy and speed. XGBoost's
    surging popularity is largely due to its unparalleled success in **Kaggle competitions**.
    In Kaggle competitions, competitors build machine learning models in attempts
    to make the best predictions and win lucrative cash prizes. In comparison to other
    models, XGBoost has been crushing the competition.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost是**极端梯度提升**（Extreme Gradient Boosting）的缩写。*极端*部分指的是通过极限计算来提高准确性和速度。XGBoost的快速流行主要得益于其在**Kaggle竞赛**中的无与伦比的成功。在Kaggle竞赛中，参赛者构建机器学习模型，力图做出最佳预测并赢取丰厚的现金奖励。与其他模型相比，XGBoost在竞赛中常常碾压对手。
- en: Understanding the details of XGBoost requires understanding the landscape of
    machine learning within the context of gradient boosting. In order to paint a
    full picture, we start at the beginning, with the basics of machine learning.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 理解XGBoost的细节需要了解梯度提升算法中机器学习的全貌。为了呈现完整的图景，我们从机器学习的基础开始讲起。
- en: What is machine learning?
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: Machine learning is the ability of computers to learn from data. In 2020, machine
    learning predicts human behavior, recommends products, identifies faces, outperforms
    poker professionals, discovers exoplanets, identifies diseases, operates self-driving
    cars, personalizes the internet, and communicates directly with humans. Machine
    learning is leading the artificial intelligence revolution and affecting the bottom
    line of nearly every major corporation.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是计算机从数据中学习的能力。2020年，机器学习能够预测人类行为、推荐产品、识别面孔、超越扑克高手、发现系外行星、识别疾病、操作自动驾驶汽车、个性化互联网体验，并直接与人类交流。机器学习正在引领人工智能革命，影响着几乎所有大公司底线。
- en: In practice, machine learning means implementing computer algorithms whose weights
    are adjusted when new data comes in. Machine learning algorithms learn from datasets
    to make predictions about species classification, the stock market, company profits,
    human decisions, subatomic particles, optimal traffic routes, and more.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，机器学习意味着实现计算机算法，当新数据进入时，算法的权重会随之调整。机器学习算法通过学习数据集来对物种分类、股市、公司利润、人类决策、亚原子粒子、最佳交通路线等进行预测。
- en: Machine learning is the best tool at our disposal for transforming big data
    into accurate, actionable predictions. Machine learning, however, does not occur
    in a vacuum. Machine learning requires rows and columns of data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是我们手中最好的工具，可以将大数据转化为准确、可操作的预测。然而，机器学习并非在真空中发生。机器学习需要大量的数据行和列。
- en: Data wrangling
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据清洗
- en: Data wrangling is a comprehensive term that encompasses the various stages of
    data preprocessing before machine learning can begin. Data loading, data cleaning,
    data analysis, and data manipulation are all included within the sphere of data
    wrangling.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清洗是一个全面的术语，涵盖了机器学习开始之前的数据预处理各个阶段。数据加载、数据清理、数据分析和数据操作都属于数据清洗的范畴。
- en: This first chapter presents data wrangling in detail. The examples are meant
    to cover standard data wrangling challenges that can be swiftly handled by **pandas**,
    Python's special library for handling data analytics. Although no experience with
    **pandas** is required, basic knowledge of **pandas** will be beneficial. All
    code is explained so that readers new to **pandas** may follow along.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本章详细介绍了数据清洗。示例旨在涵盖标准的数据清洗挑战，所有这些挑战都可以通过Python的数据分析专用库**pandas**快速处理。尽管不要求具有**pandas**的经验，但基本的**pandas**知识将对学习有帮助。所有代码都有详细解释，方便新手跟随学习。
- en: Dataset 1 – Bike rentals
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集1 – 自行车租赁
- en: The bike rentals dataset is our first dataset. The data source is the UCI Machine
    Learning Repository ([https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)),
    a world-famous data warehouse that is free to the public. Our bike rentals dataset
    has been adjusted from the original dataset ([https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset))
    by sprinkling in null values so that you can gain practice in correcting them.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 自行车租赁数据集是我们的第一个数据集。数据源来自世界著名的公共数据仓库UCI机器学习库（[https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)）。我们的自行车租赁数据集已从原始数据集（[https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset)）调整，添加了空值，以便你可以练习如何修正这些空值。
- en: Accessing the data
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 访问数据
- en: 'The first step in data wrangling is to access the data. This may be achieved
    with the following steps:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清洗的第一步是访问数据。可以通过以下步骤实现：
- en: Download the data. All files for this book have been stored on GitHub. You may
    download all files to your local computer by pressing the `Data` folder on your
    desktop.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载数据。所有本书的文件都存储在GitHub上。你可以通过点击桌面上的`Data`文件夹，将所有文件下载到本地计算机。
- en: 'Open a Jupyter Notebook. You will find the link to download Jupyter Notebooks
    in the preface. Click on `jupyter notebook` in the terminal. After the web browser
    opens, you should see a list of folders and files. Go to the same folder as the
    bike rentals dataset and select **New: Notebook: Python 3**. Here is a visual
    guide:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '打开 Jupyter Notebook。您可以在前言中找到下载 Jupyter Notebook 的链接。在终端中点击 `jupyter notebook`。网页浏览器打开后，您应该看到一列文件夹和文件。进入与自行车租赁数据集相同的文件夹，选择
    **New: Notebook: Python 3**。这里有一个视觉指南：'
- en: '![Figure 1.2 – Visual guide to accessing the Jupyter Notebook](img/B15551_01_02.jpg)'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.2 – 访问 Jupyter Notebook 的视觉指南](img/B15551_01_02.jpg)'
- en: Figure 1.2 – Visual guide to accessing the Jupyter Notebook
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.2 – 访问 Jupyter Notebook 的视觉指南
- en: Tip
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 小贴士
- en: If you are having difficulties opening a Jupyter Notebook, see Jupyter's official trouble-shooting
    guide: [https://jupyter-notebook.readthedocs.io/en/stable/troubleshooting.html](https://jupyter-notebook.readthedocs.io/en/stable/troubleshooting.html).
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您在打开 Jupyter Notebook 时遇到困难，请参阅 Jupyter 的官方故障排除指南：[https://jupyter-notebook.readthedocs.io/en/stable/troubleshooting.html](https://jupyter-notebook.readthedocs.io/en/stable/troubleshooting.html)。
- en: 'Enter the following code in the first cell of your Jupyter Notebook:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Jupyter Notebook 的第一个单元格中输入以下代码：
- en: '[PRE0]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Press *Shift* + *Enter* to run the cell. Now you may access the `pandas` library
    when you write `pd`.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 按下 *Shift* + *Enter* 运行单元格。现在，当你输入 `pd` 时，你可以访问 `pandas` 库了。
- en: 'Load the data using `pd.read_csv`. Loading data requires a `read` method. The
    `read` method stores the data as a DataFrame, a `pandas` object for viewing, analyzing,
    and manipulating data. When loading the data, place the filename in quotation
    marks, and then run the cell:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pd.read_csv` 加载数据。加载数据需要一个 `read` 方法。`read` 方法将数据存储为 DataFrame，这是一个用于查看、分析和操作数据的
    `pandas` 对象。加载数据时，将文件名放在引号内，然后运行单元格：
- en: '[PRE1]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If your data file is in a different location than your Jupyter Notebook, you
    must provide a file directory, such as `Downloads/bike_rental.csv`.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您的数据文件与 Jupyter Notebook 不在同一位置，您必须提供文件目录，例如 `Downloads/bike_rental.csv`。
- en: Now the data has been properly stored in a DataFrame called `df_bikes`.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在数据已正确存储在名为 `df_bikes` 的 DataFrame 中。
- en: Tip
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 小贴士
- en: '**Tab completion**: When coding in Jupyter Notebooks, after typing a few characters,
    press the *Tab* button. For CSV files, you should see the filename appear. Highlight
    the name with your cursor and press *Enter*. If the filename is the only available
    option, you may press *Enter*. Tab completion will make your coding experience
    faster and more reliable.'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**Tab 补全**：在 Jupyter Notebook 中编码时，输入几个字符后，按 *Tab* 键。对于 CSV 文件，您应该看到文件名出现。用光标高亮显示名称，然后按
    *Enter* 键。如果文件名是唯一的选项，您可以按 *Enter* 键。Tab 补全可以使您的编码体验更快速、更可靠。'
- en: 'Display the data using `.head()`. The final step is to view the data to ensure
    that it has loaded correctly. `.head()` is a DataFrame method that displays the
    first five rows of the DataFrame. You may place any positive integer in parentheses
    to view any number of rows. Enter the following code and press *Shift* + *Enter*:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '使用 `.head()` 显示数据。最后一步是查看数据以确保正确加载。`.head()` 是一个显示 DataFrame 前五行的方法。您可以在括号中放入任何正整数以查看任意数量的行。输入以下代码并按
    *Shift* + *Enter*：  '
- en: '[PRE2]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here is a screenshot of the first few lines along with the expected output:'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里是前几行的屏幕截图以及预期的输出：
- en: '![Figure 1.3 –The bike_rental.csv output](img/B15551_01_03.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.3 – `bike_rental.csv` 输出](img/B15551_01_03.jpg)'
- en: Figure 1.3 –The bike_rental.csv output
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3 – `bike_rental.csv` 输出
- en: Now that we have access to the data, let's take a look at three methods to understand
    the data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以访问数据，让我们看看三种理解数据的方法。
- en: Understanding the data
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解数据
- en: Now that the data has been loaded, it's time to make sense of the data. Understanding
    the data is essential to making informed decisions down the road. Here are three
    great methods for making sense of the data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已加载，是时候理解数据了。理解数据对于未来做出明智决策至关重要。以下是三种理解数据的好方法。
- en: .head()
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`.head()`'
- en: You have already seen `.head()`, a widely used method to interpret column names
    and numbers. As the preceding output reveals, `dteday` is a date, while `instant`
    is an ordered index.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经看到了 `.head()`，这是一个广泛使用的方法，用于解释列名和编号。如前面的输出所示，`dteday` 是日期，而 `instant` 是有序索引。
- en: .describe()
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: .describe()
- en: 'Numerical statistics may be viewed by using `.describe()` as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 `.describe()` 查看数值统计信息，如下所示：
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here is the expected output:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '![Figure 1.4 – The .describe() output](img/B15551_01_04.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.4 – `.describe()` 输出](img/B15551_01_04.jpg)'
- en: Figure 1.4 – The .describe() output
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4 – `.describe()` 输出
- en: You may need to scroll to the right to see all of the columns.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要向右滚动才能查看所有列。
- en: Comparing the mean and median (50%) gives an indication of skewness. As you
    can see, `mean` and `median` are close to one another, so the data is roughly
    symmetrical. The `max` and `min` values of each column, along with the quartiles
    and standard deviation (`std`), are also presented.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 比较均值和中位数（50%）可以指示数据的偏斜程度。正如你所看到的，`mean` 和 `median` 相近，所以数据大致对称。每列的 `max` 和 `min`
    值，以及四分位数和标准差（`std`）也被展示出来。
- en: .info()
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: .info()
- en: 'Another great method is `.info()`, which displays general information about
    the columns and rows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个很好的方法是 `.info()`，它显示有关列和行的一般信息：
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here is the expected output:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As you can see, `.info()` gives the number of rows, number of columns, column
    types, and non-null values. Since the number of non-null values differs between
    columns, null values must be present.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`.info()` 给出了行数、列数、列类型和非空值的数量。由于非空值的数量在列之间不同，空值一定存在。
- en: Correcting null values
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 修正空值
- en: If null values are not corrected, unexpected errors may arise down the road.
    In this subsection, we present a variety of methods that may be used to correct
    null values. Our examples are designed not only to handle null values but also
    to highlight the breadth and depth of `pandas`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果空值没有得到修正，未来可能会出现意外的错误。在本小节中，我们展示了多种修正空值的方法。我们的例子不仅用于处理空值，还展示了 `pandas` 的广度和深度。
- en: The following methods may be used to correct null values.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下方法可以用于修正空值。
- en: Finding the number of null values
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查找空值的数量
- en: 'The following code displays the total number of null values:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示空值的总数：
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here is the outcome:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that two `.sum()` methods are required. The first method sums the null
    values of each column, while the second method sums the column counts.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，需要两个 `.sum()` 方法。第一个方法对每一列的空值进行求和，第二个方法对列数进行求和。
- en: Displaying null values
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 显示空值
- en: 'You can display all rows containing null values with the following code:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下代码显示所有包含空值的行：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This code may be broken down as follows: `df_bikes[conditional]` is a subset
    of `df_bikes` that meets the condition in brackets. `.df_bikes.isna().any` gathers
    any and all null values while `(axis=1)` specifies values in the columns. In pandas,
    rows are `axis 0` and columns are `axis 1`.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码可以分解如下：`df_bikes[conditional]` 是满足括号内条件的 `df_bikes` 子集。`.df_bikes.isna().any`
    聚集所有的空值，而 `(axis=1)` 指定了列中的值。在 pandas 中，行是 `axis 0`，列是 `axis 1`。
- en: 'Here is the expected output:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '![Figure 1.5 – Bike Rentals dataset null values](img/B15551_01_05.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.5 – 自行车租赁数据集的空值](img/B15551_01_05.jpg)'
- en: Figure 1.5 – Bike Rentals dataset null values
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5 – 自行车租赁数据集的空值
- en: As you can see from the output, there are null values in the `windspeed`, `humidity`,
    and `temperature` columns along with the last row.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以看出，`windspeed`、`humidity` 和 `temperature` 列以及最后一行都存在空值。
- en: Tip
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: If this is your first time working with **pandas**, it may take time to get
    used to the notation. Check out Packt's *Hands-On Data Analysis with Pandas* for
    a great introduction: [https://subscription.packtpub.com/book/data/9781789615326](https://subscription.packtpub.com/book/data/9781789615326).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是你第一次使用 **pandas**，可能需要一些时间来习惯这种表示法。你可以查看 Packt 的 *Hands-On Data Analysis
    with Pandas*，这是一本很好的入门书籍：[https://subscription.packtpub.com/book/data/9781789615326](https://subscription.packtpub.com/book/data/9781789615326)。
- en: Correcting null values
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 修正空值
- en: Correcting null values depends on the column and dataset. Let's go over some
    strategies.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 修正空值的方法取决于列和数据集。我们来看看一些策略。
- en: Replacing with the median/mean
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 用中位数/均值替换
- en: One common strategy is to replace null values with the median or mean. The idea
    here is to replace null values with the average column value.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的策略是用中位数或均值替换空值。这里的想法是用列的平均值替换空值。
- en: 'For the `''windspeed''` column, the null values may be replaced with the `median`
    value as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `'windspeed'` 列，可以用 `median` 值替换空值，方法如下：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`df_bikes[''windspeed''].fillna` means that the null values of the `''windspeed''`
    column will be filled. `df_bikes[''windspeed''].median()` is the median of the
    `''windspeed''` column. Finally, `inplace=True` ensures that the changes are permanent.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`df_bikes[''windspeed''].fillna` 意味着 `''windspeed''` 列的空值将被填充。`df_bikes[''windspeed''].median()`
    是 `''windspeed''` 列的中位数。最后，`inplace=True` 确保更改是永久性的。'
- en: Tip
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: The median is often a better choice than the mean. The median guarantees that
    half the data is greater than the given value and half the data is lower. The
    mean, by contrast, is vulnerable to **outliers**.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 中位数通常比均值更合适。中位数保证数据中有一半的值大于该值，另一半小于该值。相比之下，均值容易受到**异常值**的影响。
- en: 'In the previous cell, `df_bikes[df_bikes.isna().any(axis=1)]` revealed rows
    `56` and `81` with null values for `windspeed`. These rows may be displayed using `.iloc`,
    short for **index location**:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的单元格中，`df_bikes[df_bikes.isna().any(axis=1)]`显示了`windspeed`列为空值的行 `56` 和
    `81`。可以使用`.iloc`显示这些行，`iloc`是**索引位置**的缩写：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here is the expected output:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '![Figure 1.6 – Rows 56 and 81](img/B15551_01_06.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.6 – 行 56 和 81](img/B15551_01_06.jpg)'
- en: Figure 1.6 – Rows 56 and 81
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 – 行 56 和 81
- en: As expected, the null values have been replaced with the windspeed median.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，空值已被替换为风速的中位数。
- en: Tip
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: 'It''s common for users to make mistakes with single or double brackets when
    using `.iloc` uses single brackets for one index as follows: `df_bikes.iloc[56]`.
    Now, `df_bikes` also accepts a list inside brackets to allow multiple indices.
    Multiple indices require double brackets as follows: `df_bikes.iloc[[56, 81]]`.
    Please see [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html)
    for further documentation.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 用户在使用`.iloc`时常常会因单括号或双括号的使用不当而出错。`.iloc`使用单括号来表示一个索引，如：`df_bikes.iloc[56]`。现在，`df_bikes`也支持在括号内使用列表来接受多个索引。多个索引需要使用双括号，如：`df_bikes.iloc[[56,
    81]]`。有关更多文档，请参考[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html)。
- en: Groupby with the median/mean
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用中位数/均值进行groupby
- en: It's possible to get more nuanced when correcting null values by using a **groupby**.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**groupby**可以在修正空值时获得更细致的结果。
- en: A groupby organizes rows by shared values. Since there are four shared seasons
    spread out among the rows, a groupby of seasons results in a total of four rows,
    one for each season. But each season comes from many different rows with different
    values. We need a way to combine, or aggregate, the values. Choices for the aggregate
    include `.sum()`, `.count()`, `.mean()`, and `.median()`. We use `.median()`.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: groupby通过共享的值来组织行。由于行中有四个共享的季节，按季节进行groupby会得到四行数据，每行对应一个季节。但是，每个季节的值来自许多不同的行。我们需要一种方法来合并或聚合这些值。常用的聚合方式包括`.sum()`、`.count()`、`.mean()`和`.median()`。我们使用`.median()`。
- en: 'Grouping `df_bikes` by season with the `.median()` aggregate is achieved as
    follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`.median()`聚合按季节分组`df_bikes`的代码如下：
- en: '[PRE11]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here is the expected output:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '![Figure 1.7 – The output of grouping df_bikes by season](img/B15551_01_07.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.7 – 按季节分组的df_bikes输出](img/B15551_01_07.jpg)'
- en: Figure 1.7 – The output of grouping df_bikes by season
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7 – 按季节分组的df_bikes输出
- en: As you can see, the column values are the medians.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，列中的值为中位数。
- en: To correct the null values in the `hum` column, short for **humidity**, we can
    take the median humidity by season.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要修正`hum`列中的空值，`hum`是**湿度**的缩写，我们可以按季节取湿度的中位数。
- en: The code for correcting null values in the `hum` column is `df_bikes['hum']
    = df_bikes['hum'].fillna()`.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 修正`hum`列空值的代码是`df_bikes['hum'] = df_bikes['hum'].fillna()`。
- en: 'The code that goes inside `fillna` is the desired values. The values obtained
    from `groupby` require the `transform` method as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`fillna`中的代码是所需的值。从`groupby`获取的值需要使用`transform`方法，如下所示：'
- en: '[PRE12]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here is the combined code in one long step:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这是合并后的代码，作为一步长操作：
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: You may verify the transformation by checking `df_bikes.iloc[[129, 213, 388]]`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过检查`df_bikes.iloc[[129, 213, 388]]`来验证转换结果。
- en: Obtaining the median/mean from specific rows
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 从特定行获取中位数/均值
- en: In some cases, it may be advantageous to replace null values with data from
    specific rows.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，用特定行的数据替代空值可能更有利。
- en: When correcting temperature, aside from consulting historical records, taking
    the mean temperature of the day before and the day after should give a good estimate.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在修正温度时，除了参考历史记录外，取前后两天的平均温度通常可以得到一个较好的估算值。
- en: 'To find null values of the `''temp''` column, enter the following code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要查找`'temp'`列中的空值，可以输入以下代码：
- en: '[PRE14]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here is the expected output:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '![Figure 1.8 – The output of the ''temp'' column](img/B15551_01_08.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.8 – ''temp'' 列的输出](img/B15551_01_08.jpg)'
- en: Figure 1.8 – The output of the 'temp' column
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8 – 'temp' 列的输出
- en: As you can see, index `701` contains null values.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，索引`701`包含空值。
- en: 'To find the mean temperature of the day before and the day after the `701`
    index, complete the following steps:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到 `701` 索引前一天和后一天的平均温度，完成以下步骤：
- en: 'Sum the temperatures in rows `700` and `702` and divide by `2`. Do this for
    the `''temp''` and `''atemp''` columns:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将第 `700` 和第 `702` 行的温度相加并除以 `2`。对 `'temp'` 和 `'atemp'` 列执行此操作：
- en: '[PRE15]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Replace the null values:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 替换空值：
- en: '[PRE16]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: You may verify on your own that the null values have been filled as expected.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以自行验证，空值已经按预期填充。
- en: Extrapolate dates
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 外推日期
- en: Our final strategy to correct null values involves dates. When real dates are
    provided, date values may be extrapolated.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们纠正空值的最终策略涉及日期。当提供了真实日期时，日期值可以进行外推。
- en: '`df_bikes[''dteday'']` is a date column; however, the type of column revealed
    by `df_bikes.info()` is an object, commonly represented as a string. Date objects
    such as years and months must be extrapolated from `datetime` types. `df_bikes[''dteday'']` may
    be converted to a `''datetime''` type using the `to_datetime` method, as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`df_bikes[''dteday'']` 是一列日期列；然而，`df_bikes.info()` 显示的列类型是对象，通常表示为字符串。日期对象，如年份和月份，必须从
    `datetime` 类型中外推。可以使用 `to_datetime` 方法将 `df_bikes[''dteday'']` 转换为 `''datetime''`
    类型，如下所示：'
- en: '[PRE17]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`infer_datetime_format=True` allows **pandas** to decide the kind of datetime
    object to store, a safe option in most cases.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`infer_datetime_format=True` 允许 **pandas** 决定存储哪种类型的日期时间对象，在大多数情况下这是一个安全的选项。'
- en: 'To extrapolate individual columns, first import the `datetime` library:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 要外推单个列，首先导入 `datetime` 库：
- en: '[PRE18]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can now extrapolate dates for the null values using some different approaches.
    A standard approach is convert the '`mnth`' column to the correct months extrapolated
    from the 'dteday' column. This has the advantage of correcting any additional
    errors that may have surfaced in conversions, assuming of course that the '`dteday`'
    column is correct.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用不同的方法来外推空值的日期。一个标准方法是将 '`mnth`' 列转换为从 'dteday' 列外推得到的正确月份。这有助于纠正转换过程中可能出现的其他错误，前提是当然
    'dteday' 列是正确的。
- en: 'The code is as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'It''s important to verify the changes. Since the null date values were in the
    last row, we can use `.tail()`, a DataFrame method similar to `.head()`, that
    shows the last five rows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 验证更改是非常重要的。由于空日期值位于最后一行，我们可以使用 `.tail()`，这是一个与 `.head()` 类似的 DataFrame 方法，用于显示最后五行：
- en: '[PRE20]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here is the expected output:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '![Figure 1.9 – The output of the extrapolated date values](img/B15551_01_09.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.9 – 外推日期值的输出](img/B15551_01_09.jpg)'
- en: Figure 1.9 – The output of the extrapolated date values
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9 – 外推日期值的输出
- en: As you can see, the month values are all correct, but the year value needs to
    be changed.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，月份值都是正确的，但年份值需要更改。
- en: The years of the last five rows in the '`dteday`' column are all `2012`, but
    the corresponding year provided by the '`yr`' column is `1.0`. Why?
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '''`dteday`'' 列中最后五行的年份都是 `2012`，但由 ''`yr`'' 列提供的对应年份是 `1.0`。为什么？'
- en: The data is normalized, meaning it's converted to values between `0` and `1`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 数据已被归一化，这意味着它已转换为介于 `0` 和 `1` 之间的值。
- en: Normalized data is often more efficient because machine learning weights do
    not have to adjust for different ranges.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化数据通常更高效，因为机器学习权重不需要调整不同范围的值。
- en: 'You can use the .loc method to fill in the correct value. The `.loc` method
    is used to locate entries by row and column as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `.loc` 方法填充正确的值。`.loc` 方法用于按行和列定位条目，方法如下：
- en: '[PRE21]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now that you have practiced correcting null values and have gained significant
    experience with **pandas**, it's time to address non-numerical columns.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经练习过修正空值并获得了相当的 **pandas** 使用经验，是时候处理非数值列了。
- en: Deleting non-numerical columns
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 删除非数值列
- en: For machine learning, all data columns should be numerical. According to `df.info()`,
    the only column that is not numerical is `df_bikes['dteday']`. Furthermore, it's
    redundant since all date information exists in other columns.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习，所有数据列都应该是数值型的。根据 `df.info()`，唯一不是数值型的列是 `df_bikes['dteday']`。此外，这列是冗余的，因为所有日期信息已经存在于其他列中。
- en: 'The column may be deleted as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 可以按如下方式删除该列：
- en: '[PRE22]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Now that we have all numerical columns and no null values, we are ready for
    machine learning.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了所有数值列且没有空值，我们可以进行机器学习了。
- en: Predicting regression
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测回归
- en: Machine learning algorithms aim to predict the values of one output column using
    data from one or more input columns. The predictions rely on mathematical equations
    determined by the general class of machine learning problems being addressed.
    Most supervised learning problems are classified as regression or classification.
    In this section, machine learning is introduced in the context of regression.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法旨在利用一个或多个输入列的数据来预测一个输出列的值。这些预测依赖于由所处理的机器学习问题的总体类别所决定的数学方程式。大多数监督学习问题被分类为回归或分类问题。在这一部分中，机器学习将在回归的背景下进行介绍。
- en: Predicting bike rentals
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测自行车租赁数量
- en: In the bike rentals dataset, `df_bikes['cnt']` is the number of bike rentals
    in a given day. Predicting this column would be of great use to a bike rental
    company. Our problem is to predict the correct number of bike rentals on a given
    day based on data such as whether this day is a holiday or working day, forecasted
    temperature, humidity, windspeed, and so on.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在自行车租赁数据集中，`df_bikes['cnt']`是某一天的自行车租赁数量。预测这一列对于自行车租赁公司来说非常有用。我们的问题是基于数据（如是否为假期或工作日、预报温度、湿度、风速等）来预测某一天的自行车租赁数量。
- en: According to the dataset, `df_bikes['cnt']` is the sum of `df_bikes['casual']`
    and `df_bikes['registered']`. If `df_bikes['registered']` and `df_bikes['casual']`
    were included as input columns, predictions would always be 100% accurate since
    these columns would always sum to the correct result. Although perfect predictions
    are ideal in theory, it makes no sense to include input columns that would be
    unknown in reality.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据集，`df_bikes['cnt']`是`df_bikes['casual']`和`df_bikes['registered']`的总和。如果将`df_bikes['registered']`和`df_bikes['casual']`作为输入列，则预测结果将始终100%准确，因为这些列的和始终是正确的结果。虽然完美的预测在理论上是理想的，但在现实中包括那些本应无法得知的输入列是没有意义的。
- en: 'All current columns may be used to predict `df_bikes[''cnt'']` except for `''casual''`
    and `''registered''`, as explained previously. Drop the `''casual''` and `''registered''`
    columns using the `.drop` method as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 所有当前的列都可以用来预测`df_bikes['cnt']`，除了之前提到的`'casual'`和`'registered'`列。可以通过`.drop`方法删除`'casual'`和`'registered'`列，如下所示：
- en: '[PRE23]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The dataset is now ready.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集现在已经准备好了。
- en: Saving data for future use
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存数据以供未来使用
- en: 'The bike rentals dataset will be used multiple times in this book. Instead
    of running this notebook each time to perform data wrangling, you can export the
    clean dataset to a CSV file for future use:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中将多次使用自行车租赁数据集。为了避免每次运行笔记本进行数据整理，可以将清理后的数据集导出为CSV文件，以便未来使用：
- en: '[PRE24]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The `index=False` parameter prevents an additional column from being created
    by the index.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`index=False`参数防止索引创建额外的列。'
- en: Declaring predictor and target columns
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 声明预测列和目标列
- en: Machine learning works by performing mathematical operations on each of the
    predictor columns (input columns) to determine the target column (output column).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习通过对每个预测列（输入列）执行数学运算来确定目标列（输出列）。
- en: 'It''s standard to group the predictor columns with a capital `X`, and the target
    column as a lowercase `y`. Since our target column is the last column, splitting
    the data into predictor and target columns may be done via slicing using index
    notation:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 通常将预测列用大写`X`表示，将目标列用小写`y`表示。由于我们的目标列是最后一列，可以通过使用索引表示法切片的方式将数据划分为预测列和目标列：
- en: '[PRE25]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The comma separates columns from rows. The first colon, `:`, means that all
    rows are included. After the comma, `:-1` means start at the first column and
    go all the way to the last column without including it. The second `-1` takes
    the last column only.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 逗号用于分隔列和行。第一个冒号`:`表示所有行都包含在内。逗号后的`:-1`表示从第一列开始，一直到最后一列，但不包括最后一列。第二个`-1`只包含最后一列。
- en: Understanding regression
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解回归
- en: Predicting the number of bike rentals, in reality, could result in any **non-negative
    integer**. When the target column includes a range of unlimited values, the machine
    learning problem is classified as **regression**.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 预测自行车租赁数量，在实际情况中可能会得到任何**非负整数**。当目标列包含无限范围的值时，机器学习问题被归类为**回归**问题。
- en: The most common regression algorithm is linear regression. Linear regression
    takes each predictor column as a **polynomial variable** and multiplies the values
    by **coefficients** (also called **weights**) to predict the target column. **Gradient
    descent** works under the hood to minimize the error. The predictions of linear
    regression could be any real number.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的回归算法是线性回归。线性回归将每个预测变量列视为 **多项式变量**，并将这些值乘以 **系数**（也称为 **权重**），以预测目标变量列。**梯度下降法**在幕后工作，以最小化误差。线性回归的预测结果可以是任何实数。
- en: Before running linear regression, we must split the data into a training set
    and a test set. The training set fits the data to the algorithm, using the target
    column to minimize the error. After a model is built, it's scored against the
    test data.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行线性回归之前，我们必须将数据分割为训练集和测试集。训练集将数据拟合到算法中，使用目标列来最小化误差。模型建立后，将其在测试数据上进行评分。
- en: The importance of holding out a test set to score the model cannot be overstated.
    In the world of big data, it's common to **overfit** the data to the training
    set because there are so many data points to train on. Overfitting is generally
    bad because the model adjusts itself too closely to outliers, unusual instances,
    and temporary trends. Strong machine learning models strike a nice balance between
    generalizing well to new data and accurately picking up on the nuances of the
    data at hand, a concept explored in detail in [*Chapter 2*](B15551_02_Final_NM_ePUB.xhtml#_idTextAnchor047)*,
    Decision Trees in Depth*.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 保留一个测试集来评估模型的重要性不容小觑。在大数据的世界中，由于有大量的数据点可用于训练，**过拟合**训练集是常见的现象。过拟合通常是不好的，因为模型会过于贴合离群点、不寻常的实例和临时趋势。强大的机器学习模型能够在对新数据进行良好泛化的同时，准确地捕捉到当前数据的细微差异，这一概念在
    [*第 2 章*](B15551_02_Final_NM_ePUB.xhtml#_idTextAnchor047)*《决策树深入解析》*中有详细探讨。
- en: Accessing scikit-learn
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问 scikit-learn
- en: All machine learning libraries will be handled through **scikit-learn**. Scikit-learn's
    range, ease of use, and computational power place it among the most widespread
    machine learning libraries in the world.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 所有机器学习库都将通过 **scikit-learn** 进行处理。Scikit-learn 的广泛功能、易用性和计算能力使其成为全球最广泛使用的机器学习库之一。
- en: 'Import `train_test_split` and `LinearRegression` from scikit-learn as follows:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 从 scikit-learn 导入 `train_test_split` 和 `LinearRegression`，如下所示：
- en: '[PRE26]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Next, split the data into the training set and test set:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将数据分割为训练集和测试集：
- en: '[PRE27]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note the `random_state=2` parameter. Whenever you see `random_state=2`, this
    means that you are choosing the seed of a pseudo-random number generator to ensure
    reproducible results.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 `random_state=2` 参数。每当看到 `random_state=2` 时，这意味着你选择了伪随机数生成器的种子，以确保结果可复现。
- en: Silencing warnings
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 静默警告
- en: Before building your first machine learning model, silence all warnings. Scikit-learn
    includes warnings to notify users of future changes. In general, it's not advisable
    to silence warnings, but since our code has been tested, it's recommended to save
    space in your Jupyter Notebook.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建你的第一个机器学习模型之前，先静默所有警告。Scikit-learn 包含警告，通知用户未来的更改。一般来说，不建议静默警告，但由于我们的代码已被测试过，建议在
    Jupyter Notebook 中节省空间。
- en: 'Warnings may be silenced as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 可以按如下方式静默警告：
- en: '[PRE28]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: It's time to build your first model.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候构建你的第一个模型了。
- en: Modeling linear regression
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建线性回归模型
- en: 'A linear regression model may be built with the following steps:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型可以通过以下步骤构建：
- en: 'Initialize a machine learning model:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化机器学习模型：
- en: '[PRE29]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Fit the model on the training set. This is where the machine learning model
    is built. Note that `X_train` is the predictor column and `y_train` is the target
    column.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上拟合模型。这是机器学习模型构建的地方。请注意，`X_train` 是预测变量列，`y_train` 是目标变量列。
- en: '[PRE30]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Make predictions for the test set. The predictions of `X_test`, the predictor
    columns in the test set, are stored as `y_pred` using the `.predict` method on
    `lin_reg`:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对测试集进行预测。`X_test`（测试集中的预测变量列）的预测结果使用 `.predict` 方法通过 `lin_reg` 存储为 `y_pred`：
- en: '[PRE31]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Compare the predictions with the test set. Scoring the model requires a basis
    of comparison. The standard for linear regression is the `mean_squared_error`,
    the sum of the squares of differences between predicted and actual values, and
    the square root, to keep the units the same. `mean_squared_error` may be imported,
    and the square root may be taken with **Numerical Python**, popularly known as
    **NumPy**, a blazingly fast library designed to work with **pandas**.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测结果与测试集进行比较。对模型进行评分需要一个比较基准。线性回归的标准是 `mean_squared_error`，即预测值与实际值之间差异的平方和，再取平方根，以保持单位一致。可以导入
    `mean_squared_error`，并使用 **Numerical Python**，即 **NumPy**，一个为与 **pandas** 一起工作而设计的高速库，来计算平方根。
- en: 'Import `mean_squared_error` and NumPy, and then compute the mean squared error
    and take the square root:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `mean_squared_error` 和 NumPy，然后计算均方误差并取平方根：
- en: '[PRE32]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Print your results:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印你的结果：
- en: '[PRE33]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The outcome is as follows:'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '[PRE34]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Here is a screenshot of all the code to build your first machine learning model:'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是构建你的第一个机器学习模型的所有代码的截图：
- en: '![Figure 1.10 – Code to build your machine learning model](img/B15551_01_10.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.10 – 构建你的机器学习模型的代码](img/B15551_01_10.jpg)'
- en: Figure 1.10 – Code to build your machine learning model
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.10 – 构建你的机器学习模型的代码
- en: It's hard to know whether an error of `898` rentals is good or bad without knowing
    the expected range of rentals per day.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在不知道每日预期租赁量的范围时，很难判断 `898` 次租赁错误是否好坏。
- en: 'The `.describe()` method may be used on the `df_bikes[''cnt'']` column to obtain
    the range and more:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`.describe()` 方法可以用于 `df_bikes[''cnt'']` 列，以获取范围等信息：'
- en: '[PRE35]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Here is the output:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '[PRE36]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: With a range of `22` to `8714`, a mean of `4504`, and a standard deviation of
    `1937`, an RMSE of `898` isn't bad, but it's not great either.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 预测的值范围从 `22` 到 `8714`，均值为 `4504`，标准差为 `1937`，RMSE 为 `898`，虽然不差，但也不能说很好。
- en: XGBoost
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: XGBoost
- en: Linear regression is one of many algorithms that may be used to solve regression
    problems. It's possible that other regression algorithms will produce better results.
    The general strategy is to experiment with different regressors to compare scores.
    Throughout this book, you will experiment with a wide range of regressors, including
    decision trees, random forests, gradient boosting, and the focus of this book,
    XGBoost.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是解决回归问题的众多算法之一。其他回归算法可能会产生更好的结果。一般的策略是尝试不同的回归器进行比较。你将在本书中尝试多种回归器，包括决策树、随机森林、梯度提升，以及本书的重点，XGBoost。
- en: A comprehensive introduction to XGBoost will be provided later in this book.
    For now, note that XGBoost includes a regressor, called `XGBRegressor`, that may
    be used on any regression dataset, including the bike rentals dataset that has
    just been scored. Let's now use the `XGBRegressor` to compare results on the bike
    rentals dataset with linear regression.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 本书后续将提供 XGBoost 的全面介绍。现在请注意，XGBoost 包括一个回归器，名为 `XGBRegressor`，可以用于任何回归数据集，包括刚才评分的自行车租赁数据集。现在我们将使用
    `XGBRegressor` 来将自行车租赁数据集的结果与线性回归进行比较。
- en: You should have already installed XGBoost in the preface. If you have not done
    so, install XGBoost now.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该已经在前面安装了 XGBoost。如果没有，请现在安装 XGBoost。
- en: XGBRegressor
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: XGBRegressor
- en: 'After XGBoost has been installed, the XGBoost regressor may be imported as
    follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 XGBoost 后，可以按如下方式导入 XGBoost 回归器：
- en: '[PRE37]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The general steps for building `XGBRegressor` are the same as with `LinearRegression`.
    The only difference is to initialize `XGBRegressor` instead of `LinearRegression`:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 构建 `XGBRegressor` 的一般步骤与构建 `LinearRegression` 的步骤相同，唯一的区别是初始化 `XGBRegressor`
    而不是 `LinearRegression`：
- en: 'Initialize a machine learning model:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个机器学习模型：
- en: '[PRE38]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Fit the model on the training set. If you get some warnings from XGBoost here,
    don''t worry:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上拟合模型。如果此时 XGBoost 给出一些警告，请不用担心：
- en: '[PRE39]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Make predictions for the test set:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对测试集进行预测：
- en: '[PRE40]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Compare the predictions with the test set:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测结果与测试集进行比较：
- en: '[PRE41]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Print your results:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印你的结果：
- en: '[PRE42]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The output is as follows:'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE43]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '`XGBRegressor` performs substantially better!'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '`XGBRegressor` 表现明显更好！'
- en: The reason why XGBoost often performs better than others will be explored in
    [*Chapter 5*](B15551_05_Final_NM_ePUB.xhtml#_idTextAnchor117)*, XGBoost Unveiled*.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 为什么通常比其他方法表现更好将在[*第五章*](B15551_05_Final_NM_ePUB.xhtml#_idTextAnchor117)中探讨，书名为
    *XGBoost 揭秘*。
- en: Cross-validation
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉验证
- en: One test score is not reliable because splitting the data into different training
    and test sets would give different results. In effect, splitting the data into
    a training set and a test set is arbitrary, and a different `random_state` will
    give a different RMSE.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 一个测试分数是不可靠的，因为将数据拆分为不同的训练集和测试集会得到不同的结果。实际上，将数据拆分为训练集和测试集是任意的，不同的`random_state`会得到不同的RMSE。
- en: One way to address the score discrepancies between different splits is **k-fold
    cross-validation**. The idea is to split the data multiple times into different
    training sets and test sets, and then to take the mean of the scores. The number
    of splits, called **folds**, is denoted by **k**. It's standard to use k = 3,
    4, 5, or 10 splits.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 解决不同分割之间评分差异的一种方法是**k折交叉验证**。其思路是将数据多次拆分为不同的训练集和测试集，然后取这些评分的均值。分割次数，称为**折叠**，由**k**表示。标准做法是使用k
    = 3、4、5或10个分割。
- en: 'Here is a visual description of cross-validation:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是交叉验证的可视化描述：
- en: '![Figure 1.11 – Cross-validation](img/B15551_01_11.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.11 – 交叉验证](img/B15551_01_11.jpg)'
- en: Figure 1.11 – Cross-validation
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.11 – 交叉验证
- en: (Redrawn from [https://commons.wikimedia.org/wiki/File:K-fold_cross_validation_EN.svg](https://commons.wikimedia.org/wiki/File:K-fold_cross_validation_EN.svg))
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: （重绘自[https://commons.wikimedia.org/wiki/File:K-fold_cross_validation_EN.svg](https://commons.wikimedia.org/wiki/File:K-fold_cross_validation_EN.svg)）
- en: Cross-validation works by fitting a machine learning model on the first training
    set and scoring it against the first test set. A different training set and test
    set are provided for the second split, resulting in a new machine learning model
    with its own score. A third split results in a new model and scores it against
    another test set.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证通过在第一个训练集上拟合机器学习模型，并在第一个测试集上进行评分来工作。为第二次分割提供不同的训练集和测试集，从而生成一个新的机器学习模型，并对其进行评分。第三次分割会生成一个新的模型，并在另一个测试集上进行评分。
- en: There is going to be overlap in the training sets, but not the test sets.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练集之间会有重叠，但测试集之间没有。
- en: Choosing the number of folds is flexible and depends on the data. Five folds
    is standard because 20% of the test set is held back each time. With 10 folds,
    only 10% of the data is held back; however, 90% of the data is available for training
    and the mean is less vulnerable to outliers. For a smaller datatset, three folds
    may work better.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 选择折叠数是灵活的，取决于数据。五折是标准做法，因为每次都会保留20%的测试集。使用10折时，只有10%的数据被保留；然而，90%的数据可用于训练，且均值对异常值的敏感性较小。对于较小的数据集，三折可能效果更好。
- en: At the end, there will be k different scores evaluating the model against k
    different test sets. Taking the mean score of the k folds gives a more reliable
    score than any single fold.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将会有k个不同的评分，评估模型在k个不同的测试集上的表现。取这k个折叠的平均得分比任何单一折叠的得分更可靠。
- en: '`cross_val_score` is a convenient way to implement cross-validation. `cross_val_score`
    takes a machine learning algorithm as input, along with the predictor and target
    columns, with optional additional parameters that include a scoring metric and
    the desired number of folds.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '`cross_val_score`是实现交叉验证的一种便捷方式。`cross_val_score`接受一个机器学习算法作为输入，以及预测列和目标列，可选的额外参数包括评分标准和所需的折叠次数。'
- en: Cross-validation with linear regression
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用线性回归进行交叉验证
- en: Let's use cross-validation with `LinearRegression`.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`LinearRegression`进行交叉验证。
- en: 'First, import `cross_val_score` from the `cross_val_score` library:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，从`cross_val_score`库中导入`cross_val_score`：
- en: '[PRE44]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now use cross-validation to build and score a machine learning model in the
    following steps:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用交叉验证按以下步骤构建和评分机器学习模型：
- en: 'Initialize a machine learning model:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个机器学习模型：
- en: '[PRE45]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Implement `cross_val_score` with the model, `X`, `y`, `scoring=''neg_mean_squared_error''`,
    and the number of folds, `cv=10`, as input:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cross_val_score`实现模型、`X`、`y`、`scoring='neg_mean_squared_error'`和折叠次数`cv=10`作为输入：
- en: '[PRE46]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Tip
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示
- en: Why `scoring='neg_mean_squared_error'`? Scikit-learn is designed to select the
    highest score when training models. This works well for accuracy, but not for
    errors when the lowest is best. By taking the negative of each mean squared error,
    the lowest ends up being the highest. This is compensated for later with `rmse
    = np.sqrt(-scores)`, so the final results are positive.
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为什么使用`scoring='neg_mean_squared_error'`？Scikit-learn的设计是选择最高的得分来训练模型。这对于准确度是有效的，但对于误差则不适用，因为最低的误差才是最佳的。通过取每个均方误差的负值，最低的结果最终变为最高值。后续通过`rmse
    = np.sqrt(-scores)`来补偿这一点，因此最终结果是正数。
- en: 'Find the RMSE by taking the square root of the negative scores:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过取负评分的平方根来找到RMSE：
- en: '[PRE47]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Display the results:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示结果：
- en: '[PRE48]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The output is as follows:'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE49]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Linear regression has a mean error of `972.06`. This is slightly better than
    the `980.38` obtained before. The point here is not whether the score is better
    or worse. The point is that it's a better estimation of how linear regression
    will perform on unseen data.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归的平均误差为`972.06`。 这比之前获得的`980.38`略好。 关键不在于分数是好还是坏，而在于这是对线性回归在未见数据上表现的更好估计。
- en: Using cross-validation is always recommended for a better estimate of the score.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 始终建议使用交叉验证以更好地估计分数。
- en: About the print function
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`print`函数
- en: When running your own machine learning code, the global `print` function is
    often not necessary, but it is helpful if you want to print out multiple lines
    and format the output as shown here.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行自己的机器学习代码时，全局`print`函数通常是不必要的，但如果要打印多行并格式化输出，则非常有用。
- en: Cross-validation with XGBoost
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用XGBoost进行交叉验证
- en: 'Now let''s use cross-validation with `XGBRegressor`. The steps are the same,
    except for initializing the model:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们用`XGBRegressor`进行交叉验证。 步骤相同，只是初始化模型不同：
- en: 'Initialize a machine learning model:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化机器学习模型：
- en: '[PRE50]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Implement `cross_val_score` with the model, `X`, `y`, scoring, and the number
    of folds, `cv`, as input:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型`X`、`y`、评分和折数`cv`实现`cross_val_score`：
- en: '[PRE51]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Find the RMSE by taking the square root of the negative scores:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过取负分数的平方根来查找RMSE：
- en: '[PRE52]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Print the results:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印结果：
- en: '[PRE53]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output is as follows:'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE54]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '`XGBRegressor` wins again, besting linear regression by about 10%.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '`XGBRegressor`再次胜出，比线性回归高约10%。'
- en: Predicting classification
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测分类
- en: You learned that XGBoost may have an edge in regression, but what about classification?
    XGBoost has a classification model, but will it perform as accurately as well
    tested classification models such as logistic regression? Let's find out.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 您已了解到XGBoost在回归中可能有优势，但分类呢？ XGBoost有分类模型，但它是否能像经过充分测试的分类模型（如逻辑回归）一样准确？ 让我们找出答案。
- en: What is classification?
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是分类？
- en: 'Unlike with regression, when predicting target columns with a limited number
    of outputs, a machine learning algorithm is categorized as a classification algorithm.
    The possible outputs may include the following:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 与回归不同，当预测具有有限输出数量的目标列时，机器学习算法被归类为分类算法。 可能的输出包括以下内容：
- en: Yes, No
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是，否
- en: Spam, Not Spam
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 垃圾邮件，非垃圾邮件
- en: 0, 1
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0, 1
- en: Red, Blue, Green, Yellow, Orange
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 红色，蓝色，绿色，黄色，橙色
- en: Dataset 2 – The census
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集 2 – 人口普查
- en: We will move a little more swiftly through the second dataset, the Census Income
    Data Set ([https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/Census+Income)),
    to predict personal income.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将更快地通过第二个数据集，人口普查收入数据集 ([https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/Census+Income))，来预测个人收入。
- en: Data wrangling
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据整理
- en: Before implementing machine learning, the dataset must be preprocessed. When
    testing new algorithms, it's essential to have all numerical columns with no null
    values.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施机器学习之前，必须对数据集进行预处理。 在测试新算法时，所有数值列都没有空值是至关重要的。
- en: Data loading
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据加载
- en: 'Since this dataset is hosted directly on the UCI Machine Learning website,
    it can be downloaded directly from the internet using `pd.read_csv`:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此数据集直接托管在UCI机器学习网站上，可以使用`pd.read_csv`直接从互联网下载：
- en: '[PRE55]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Here is the expected output:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是预期的输出：
- en: '![Figure 1.12 – The Census Income DataFrame](img/B15551_01_12.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.12 – 人口普查收入数据集](img/B15551_01_12.jpg)'
- en: Figure 1.12 – The Census Income DataFrame
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.12 – 人口普查收入数据集
- en: 'The output reveals that the column headings represent the entries of the first
    row. When this happens, the data may be reloaded with the `header=None` parameter:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，列标题代表第一行的条目。 当发生这种情况时，可以使用`header=None`参数重新加载数据：
- en: '[PRE56]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Here is the expected output without the header:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是没有标题的预期输出：
- en: '![Figure 1.13 – The header=None parameter output](img/B15551_01_13.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.13 – `header=None`参数输出](img/B15551_01_13.jpg)'
- en: Figure 1.13 – The header=None parameter output
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.13 – `header=None`参数输出
- en: As you can see, the column names are still missing. They are listed on the Census
    Income Data Set website ([https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/Census+Income))
    under *Attribute Information*.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，列名仍然缺失。 它们列在人口普查收入数据集网站的*属性信息*下 ([https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/Census+Income))。
- en: 'Column names may be changed as follows:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 列名可以更改如下：
- en: '[PRE57]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Here is the expected output with column names:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 这是包含列名的预期输出：
- en: '![Figure 1.14 – Expected column names](img/B15551_01_14.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.14 – 预期的列名](img/B15551_01_14.jpg)'
- en: Figure 1.14 – Expected column names
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.14 – 预期的列名
- en: As you can see, the column names have been restored.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，列名已经恢复。
- en: Null values
  id: totrans-316
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 空值
- en: 'A great way to check null values is to look at the DataFrame `.info()` method:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 检查空值的好方法是查看数据框的`.info()`方法：
- en: '[PRE58]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The output is as follows:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE59]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Since all columns have the same number of non-null rows, we can infer that there
    are no null values.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有列的非空行数相同，我们可以推断没有空值。
- en: Non-numerical columns
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 非数值列
- en: All columns of the `dtype` object must be transformed into numerical columns.
    A `get_dummies` method takes the non-numerical unique values of every column and
    converts them into their own column, with `1` indicating presence and `0` indicating
    absence. For instance, if the column values of a DataFrame called "Book Types"
    were "hardback," "paperback," or "ebook," `pd.get_dummies` would create three
    new columns called "hardback," "paperback," and "ebook" replacing the "Book Types"
    column.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 所有`dtype`为对象的列必须转换为数值列。`get_dummies`方法将每一列的非数值唯一值转换为各自的列，其中`1`表示存在，`0`表示不存在。例如，如果数据框"书籍类型"的列值为"精装书"、"平装书"或"电子书"，`pd.get_dummies`会创建三个新列，分别命名为"精装书"、"平装书"和"电子书"，并替换原有的"书籍类型"列。
- en: 'Here is a "Book Types" DataFrame:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 这是"书籍类型"数据框：
- en: '![Figure 1.15 – A "Book Types" DataFrame](img/B15551_01_15.jpg)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.15 – "书籍类型"数据框](img/B15551_01_15.jpg)'
- en: Figure 1.15 – A "Book Types" DataFrame
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.15 – "书籍类型"数据框
- en: 'Here is the same DataFrame after `pd.get_dummies`:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 这是应用了`pd.get_dummies`后的相同数据框：
- en: '![Figure 1.16 – The new DataFrame](img/B15551_01_16.jpg)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.16 – 新的数据框](img/B15551_01_16.jpg)'
- en: Figure 1.16 – The new DataFrame
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.16 – 新的数据框
- en: '`pd.get_dummies` will create many new columns, so it''s worth checking to see
    whether any columns may be eliminated. A quick review of the `df_census` data
    reveals an `''education''` column and an `education_num` column. The `education_num`
    column is a numerical conversion of `''education''`. Since the information is
    the same, the `''education''` column may be deleted:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.get_dummies`会创建许多新列，因此值得检查是否有某些列可以被删除。快速查看`df_census`数据可以发现`''education''`列和`education_num`列。`education_num`列是`''education''`列的数值转换，因为信息相同，`''education''`列可以删除：'
- en: '[PRE60]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Now use `pd.get_dummies` to transform the non-numerical columns into numerical
    columns:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用`pd.get_dummies`将非数值列转换为数值列：
- en: '[PRE61]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Here is the expected output:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '![Figure 1.17 – pd.get_dummies – non-numerical to numerical columns](img/B15551_01_17.jpg)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.17 – pd.get_dummies – 非数值列转换为数值列](img/B15551_01_17.jpg)'
- en: Figure 1.17 – pd.get_dummies – non-numerical to numerical columns
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.17 – pd.get_dummies – 非数值列转换为数值列
- en: As you can see, new columns are created using a `column_value` syntax referencing
    the original column. For example, `native-country` is an original column, and
    Taiwan is one of many values. The new `native-country_Taiwan` column has a value
    of `1` if the person is from Taiwan and `0` otherwise.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，新的列是通过`column_value`语法创建的，引用了原始列。例如，`native-country`是原始列，而台湾是其中一个值。新的`native-country_Taiwan`列的值为`1`（如果这个人来自台湾），否则为`0`。
- en: Tip
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Using `pd.get_dummies` may increase memory usage, as can be verified using the
    `.info()` method on the DataFrame in question and checking the last line. `1`
    are stored and values of `0` are not stored. For more information on sparse matrices,
    see [*Chapter 10*](B15551_10_Final_NM_ePUB.xhtml#_idTextAnchor230), *XGBoost Model
    Deployment*, or visit SciPy's official documentation at [https://docs.scipy.org/doc/scipy/reference/](https://docs.scipy.org/doc/scipy/reference/).
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pd.get_dummies`可能会增加内存使用量，可以通过在数据框上使用`.info()`方法并查看最后一行来验证。存储的是`1`，而`0`的值不会被存储。有关稀疏矩阵的更多信息，请参见[*第10章*](B15551_10_Final_NM_ePUB.xhtml#_idTextAnchor230)，*XGBoost模型部署*，或访问SciPy的官方文档：[https://docs.scipy.org/doc/scipy/reference/](https://docs.scipy.org/doc/scipy/reference/)。
- en: Target and predictor columns
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目标列和预测列
- en: Since all columns are numerical with no null values, it's time to split the
    data into target and predictor columns.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有列都是数值型且没有空值，接下来是将数据分为目标列和预测列。
- en: 'The target column is whether or not someone makes 50K. After `pd.get_dummies`,
    two columns, `df_census[''income_<=50K'']` and `df_census[''income_>50K'']`, are
    used to determine whether someone makes 50K. Since either column will work, we
    delete `df_census[''income_ <=50K'']`:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 目标列是判断某人是否赚取50K。经过`pd.get_dummies`处理后，生成了两个列，`df_census['income_<=50K']`和`df_census['income_>50K']`，用来判断某人是否赚取50K。由于任一列都能使用，我们删除了`df_census['income_<=50K']`：
- en: '[PRE62]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Now split the data into `X` (predictor columns) and `y` (target column). Note
    that `-1` is used for indexing since the last column is the target column:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将数据拆分为`X`（预测列）和`y`（目标列）。请注意，由于最后一列是目标列，因此使用`-1`进行索引：
- en: '[PRE63]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: It's time to build machine learning classifiers!
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候构建机器学习分类器了！
- en: Logistic regression
  id: totrans-347
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Logistic regression is the most fundamental classification algorithm. Mathematically,
    logistic regression works in a manner similar to linear regression. For each column,
    logistic regression finds an appropriate weight, or coefficient, that maximizes
    model accuracy. The primary difference is that instead of summing each term, as
    in linear regression, logistic regression uses the **sigmoid function**.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是最基本的分类算法。从数学上讲，逻辑回归的工作方式类似于线性回归。对于每一列，逻辑回归会找到一个适当的权重或系数，最大化模型的准确度。主要的区别在于，逻辑回归使用**sigmoid函数**，而不是像线性回归那样对每一项求和。
- en: 'Here is the sigmoid function and the corresponding graph:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 这是sigmoid函数及其对应的图：
- en: '![Figure 1.18 – Sigmoid function graph](img/B15551_01_18.jpg)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.18 – Sigmoid函数图](img/B15551_01_18.jpg)'
- en: Figure 1.18 – Sigmoid function graph
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.18 – Sigmoid函数图
- en: The sigmoid is commonly used for classification. All values greater than 0.5
    are matched to 1, and all values less than 0.5 are matched to 0.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid函数通常用于分类。所有大于0.5的值都会被匹配为1，所有小于0.5的值都会被匹配为0。
- en: Implementing logistic regression with scikit-learn is nearly the same as implementing
    linear regression. The main differences are that the predictor column should fit
    into categories, and the error should be in terms of accuracy. As a bonus, the
    error is in terms of accuracy by default, so explicit scoring parameters are not
    required.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 使用scikit-learn实现逻辑回归几乎与实现线性回归相同。主要的区别是，预测列应该适应类别，并且误差应该以准确率为度量。作为附加奖励，误差默认是以准确率为度量的，因此不需要显式的评分参数。
- en: 'You may import logistic regression as follows:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按如下方式导入逻辑回归：
- en: '[PRE64]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: The cross-validation function
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉验证函数
- en: Let's use cross-validation on logistic regression to predict whether someone
    makes over 50K.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在逻辑回归上使用交叉验证，预测某人是否赚取超过50K。
- en: 'Instead of copying and pasting, let''s build a cross-validation classification
    function that takes a machine learning algorithm as input and has the accuracy
    score as output using `cross_val_score`:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 不要重复复制粘贴，让我们构建一个交叉验证分类函数，该函数接受机器学习算法作为输入，并输出准确度得分，使用`cross_val_score`：
- en: '[PRE65]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Now call the function with logistic regression:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用逻辑回归调用函数：
- en: '[PRE66]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The output is as follows:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE67]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 80% accuracy isn't bad out of the box.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 80%的准确率已经不错了。
- en: Let's see whether XGBoost can do better.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看XGBoost是否能做得更好。
- en: Tip
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Any time you find yourself copying and pasting code, look for a better way!
    One aim of computer science is to avoid repetition. Writing your own data analysis
    and machine learning functions will make your life easier and your work more efficient
    in the long run.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 每当你发现自己在复制和粘贴代码时，应该寻找更好的方法！计算机科学的一个目标是避免重复。编写你自己的数据分析和机器学习函数，能让你的工作更加轻松和高效，长远来看也会带来好处。
- en: The XGBoost classifier
  id: totrans-368
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: XGBoost分类器
- en: 'XGBoost has a regressor and a classifier. To use the classifier, import the
    following algorithm:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost有回归器和分类器。要使用分类器，请导入以下算法：
- en: '[PRE68]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Now run the classifier in the `cross_val` function with one important addition.
    Since there are 94 columns, and XGBoost is an ensemble method, meaning that it
    combines many models for each run, each of which includes 10 splits, we are going
    to limit `n_estimators`, the number of models, to `5`. Normally, XGBoost is very
    fast. In fact, it has a reputation for being the fastest boosting ensemble method
    out there, a reputation that we will check in this book! For our initial purposes,
    however, `5` estimators, though not as robust as the default of `100`, is sufficient.
    Details on choosing `n_estimators` will be a focal point of [*Chapter 4*](B15551_04_Final_NM_ePUB.xhtml#_idTextAnchor093)*,
    From Gradient Boosting to XGBoost*:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在`cross_val`函数中运行分类器，并进行一个重要的添加。由于有94列，并且XGBoost是一个集成方法，这意味着它每次运行时会结合多个模型，每个模型包含10个分割，我们将把`n_estimators`（模型数量）限制为`5`。通常，XGBoost非常快速，事实上，它有着成为最快的提升集成方法的声誉，这个声誉我们将在本书中验证！然而，出于初步目的，`5`个估计器，虽然没有默认的`100`个那么强大，但已经足够。关于如何选择`n_estimators`的细节将在[*第四章*](B15551_04_Final_NM_ePUB.xhtml#_idTextAnchor093)*，从梯度提升到XGBoost*中深入探讨。
- en: '[PRE69]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The output is as follows:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE70]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: As you can see, XGBoost scores higher than logistic regression out of the box.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，XGBoost在默认设置下的表现优于逻辑回归。
- en: Summary
  id: totrans-376
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: Your journey through XGBoost has officially begun! You started this chapter
    by learning the fundamentals of data wrangling and **pandas**, essential skills
    for all machine learning practitioners, with a focus on correcting null values.
    Next, you learned how to build machine learning models in scikit-learn by comparing
    linear regression with XGBoost. Then, you prepared a dataset for classification
    and compared logistic regression with XGBoost. In both cases, XGBoost was the
    clear winner.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 你的XGBoost之旅正式开始了！你从学习数据处理的基础知识开始，并掌握了所有机器学习从业者必备的**pandas**技能，重点是处理空值。接着，你通过将线性回归与XGBoost进行比较，学习了如何在scikit-learn中构建机器学习模型。然后，你准备了一个分类数据集，并将逻辑回归与XGBoost进行了比较。在这两个案例中，XGBoost都是明显的赢家。
- en: Congratulations on building your first XGBoost models! Your initiation into
    data wrangling and machine learning using the **pandas**, NumPy, and scikit-learn
    libraries is complete.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你成功构建了第一个XGBoost模型！你已经完成了使用**pandas**、NumPy和scikit-learn库进行数据处理和机器学习的入门。
- en: In [*Chapter 2*](B15551_02_Final_NM_ePUB.xhtml#_idTextAnchor047)*, Decision
    Trees in Depth*, you will improve your machine learning skills by building decision
    trees, the base learners of XGBoost machine learning models, and fine-tuning hyperparameters
    to improve results.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第二章*](B15551_02_Final_NM_ePUB.xhtml#_idTextAnchor047)*，深入决策树*中，你将通过构建决策树（XGBoost机器学习模型的基础学习器）并微调超参数来提高你的机器学习技能，从而改善结果。
