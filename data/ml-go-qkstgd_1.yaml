- en: Introducing Machine Learning with Go
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Go介绍机器学习
- en: All around us, automation is changing our lives in subtle increments that live
    on the bleeding edge of mathematics and computer science. What do a Nest thermostat,
    Netflix's movie recommendations and Google's Images search algorithm all have
    in common? Created by some of the brightest minds in todays software industry,
    these technologies all rely on **machine learning** (**ML**) techniques.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们周围，自动化正在以细微的增量改变着我们的生活，这些增量处于数学和计算机科学的尖端。一个Nest恒温器、Netflix的电影推荐和Google的图片搜索算法有什么共同之处？这些技术都是由当今软件行业中最聪明的大脑之一创造的，它们都依赖于**机器学习**（**ML**）技术。
- en: In February 2019, Crunchbase listed over 4,700 companies that categorized themselves
    as **Artificial Intelligence** (**AI**) or ML^([1]). Most of these companies were
    very early stage and funded by angel investors or early round funding from venture
    capitalists. Yet articles in 2017 and 2018 by Crunchbase, and the UK Financial
    Times, center around a common recognition that ML is increasingly relied upon
    for sustained growth^([2]), and that its increasing maturity will lead to even
    more widespread applications^([3]), particularly if challenges around the opacity
    of decisions made by ML algorithms can be solved^([4]). The New York Times even
    has a column dedicated to ML^([5]), a tribute to its importance in everyday life.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在2019年2月，Crunchbase列出了超过4,700家将自己归类为**人工智能**（**AI**）或机器学习的公司^([1])。其中大部分公司处于非常早期阶段，由天使投资者或风险投资家的早期轮次融资。然而，Crunchbase在2017年和2018年的文章以及英国《金融时报》的文章都围绕着一个共同的认识，即机器学习越来越被依赖以实现持续增长^([2])，并且其日益成熟将导致更广泛的应用^([3])，尤其是如果能够解决机器学习算法决策不透明性的挑战^([4])。甚至《纽约时报》还设有专门关于机器学习的专栏^([5])，这是对其在日常生活中重要性的致敬。
- en: This book will teach a software engineer with intermediate knowledge of the
    Go programming language how to write and produce an ML application from concept
    to deployment, and beyond. We will first categorize problems suitable for ML techniques
    and the life cycle of ML applications. Then, we will explain how to set up a development
    environment specifically suited for data science with the Go language. Then, we
    will provide a practical guide to the main ML algorithms, their implementations,
    and their pitfalls. We will also provide some guidance on using ML models produced
    using other programming languages and integrating them in Go applications. Finally,
    we will consider different deployment models and the elusive intersection between
    DevOps and data science. We will conclude with some remarks on managing ML projects
    from our own experience.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将教会具有Go编程语言中级知识的软件工程师如何从概念到部署，以及更远地编写和制作一个机器学习应用程序。我们首先将分类适合机器学习技术的和机器学习应用程序的生命周期中的问题。然后，我们将解释如何使用Go语言设置一个专门适合数据科学开发的环境。接着，我们将提供主要机器学习算法、它们的实现及其陷阱的实用指南。我们还将提供一些关于使用其他编程语言产生的机器学习模型并在Go应用程序中集成的指导。最后，我们将考虑不同的部署模型以及DevOps和数据科学之间难以捉摸的交集。我们将结合我们自己的经验对管理机器学习项目进行一些评论。
- en: ML theory is a mathematically advanced subject, but you can develop ML applications
    without fully understanding it. This book will help you develop an intuition for
    which algorithms to use and how to formulate problems with only basic mathematical
    knowledge.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习理论是一个数学上高级的学科，但你可以在不完全理解它的情况下开发机器学习应用程序。本书将帮助你发展对使用哪些算法以及如何仅用基本数学知识来构建问题的直觉。
- en: 'In our first chapter, we will introduce some fundamental concepts of Go ML
    applications:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的第一章中，我们将介绍Go机器学习应用程序的一些基本概念：
- en: What is ML?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: Types of ML problems
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习问题类型
- en: Why write ML applications in Go?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么要在Go中编写机器学习应用程序？
- en: The ML development life cycle
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习开发生命周期
- en: What is ML?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: ML is a field at the intersection of statistics and computer science. The output
    of this field has been a collection of algorithms capable of operating autonomously
    by inferring the best decision or answer to a question from a dataset. Unlike
    traditional programming, where the programmer must decide the rules of the program
    and painstakingly encode these in the syntax of their chosen programming language,
    ML algorithms require only sufficient quantities of prepared data, computing power
    to learn from the data, and often some knowledge to tweak the algorithms parameters
    to improve the final result.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是统计学和计算机科学交叉的领域。这个领域的输出是一系列能够自主操作的算法，它们通过从数据集中推断出最佳决策或答案来解决问题。与传统的编程不同，程序员必须决定程序的规则，并费力地将这些规则编码在他们选择的编程语言的语法中，而机器学习算法只需要足够量的准备数据、从数据中学习的计算能力，以及通常需要一些知识来调整算法参数以改善最终结果。
- en: The resulting systems are very flexible and can be excellent at capitalizing
    on patterns that human beings would miss. Imagine writing a recommender system
    for a TV series from scratch. Perhaps you might begin by defining the inputs and
    the outputs of the problem, then finding a database of TV series that had such
    details as their date of release, genre, cast, and director. Finally, you might
    create a `score` func that rates a pair of series more highly if their release
    dates are close, they have the same genre, share actors, or have the same director.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 结果系统非常灵活，并且能够很好地利用人类可能忽略的模式。想象一下从头开始编写一个电视剧推荐系统。你可能首先定义问题的输入和输出，然后找到一个包含电视剧发布日期、类型、演员和导演等详细信息的数据库。最后，你可能创建一个`score`函数，如果两对电视剧的发布日期接近、属于同一类型、共享演员或拥有相同的导演，则给予更高的评分。
- en: A **recommender system** is a type of prediction algorithm that attempts to
    guess the rating a user would ascribe an input sample. A widely used application
    in online retail is to use a recommender system to suggest items to a user, based
    on their past purchases.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**推荐系统**是一种预测算法，试图猜测用户会对一个输入样本赋予的评分。在在线零售中，广泛使用的一种应用是使用推荐系统根据用户的过去购买行为向用户推荐商品。'
- en: Given one TV series, you could then rank all other TV series by decreasing similarity
    score and present the first few to the user. When creating the `score` func, you
    would make judgement calls on the relative importance of the various features,
    such as deciding that each pair of shared actors between two series is worth one
    point. This type of guesswork, also known as a **heuristic**, is what ML algorithms
    aim to do for you, saving time and improving the accuracy of the final result,
    especially if user preferences shift and you have to change the scoring func regularly
    to keep up.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一部电视剧，你可以根据相似度评分递减对所有其他电视剧进行排名，并将前几部推荐给用户。在创建`score`函数时，你会在各种特征的相对重要性上进行判断，例如决定两个系列之间每对共享演员值一分。这种猜测工作，也称为**启发式方法**，是机器学习算法旨在为你做的事情，节省时间并提高最终结果的准确性，尤其是如果用户偏好发生变化，你必须定期更改评分函数以保持同步。
- en: The distinction between the broader field of AI and ML is a murky one. While
    the hype surrounding ML may be relatively new^([6]), the history of the field
    began in 1959 when Arthur Samuel, a leading expert in AI, first used these words^([7]).
    In the 1950s, ML concepts such as the perceptron and genetic algorithms were invented
    by the likes of Alan Turing^([8]) as well as Samuel himself. In the following
    decades, practical and theoretical difficulties in achieving general AI, led to
    approaches such as rule-based methods such as expert systems, which did not learn
    from data, but rather from expert-devised rules which they had learned over many
    years, encoded in if-else statements.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能和机器学习这两个更广泛领域的区别是模糊的。虽然围绕机器学习的炒作可能相对较新^([6])，但这个领域的历史始于1959年，当时人工智能领域的领先专家Arthur
    Samuel首次使用了这些词^([7])。在20世纪50年代，像Alan Turing^([8])和Samuel本人这样的发明家发明了诸如感知器、遗传算法等机器学习概念。在接下来的几十年里，实现通用人工智能的实践和理论困难导致了诸如基于规则的方法（如专家系统）等方法的产生，这些方法不是从数据中学习，而是从专家制定的规则中学习，这些规则是他们多年来学到的，并以if-else语句的形式编码。
- en: The power of ML is in the ability of the algorithms to adapt to previously unseen
    cases, something that if-else statements cannot do. If you do not require this
    adaptability, perhaps because all cases are known beforehand, stick to basics
    and use traditional programming techniques instead!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的力量在于算法能够适应之前未见过的案例，这是if-else语句无法做到的。如果你不需要这种适应性，可能是因为所有案例事先都是已知的，那么坚持基本原理，使用传统的编程技术即可！
- en: In the 1990s, recognizing that achieving AI was unlikely with existing technology,
    there was an increasing appetite for a narrow approach to tackling very specific
    problems that could be solved using a combination of statistics and probability
    theory. This led to the development of ML as a separate field. Today, ML and AI
    are often used interchangeably, particularly in marketing literature^([9]).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪90年代，意识到在现有技术下实现人工智能的可能性不大，人们越来越倾向于采用一种狭隘的方法来解决可以用统计和概率论相结合解决的问题。这导致了机器学习作为一个独立领域的发展。今天，机器学习和人工智能经常被互换使用，尤其是在市场营销文献中^([9])。
- en: Types of ML algorithms
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习算法的类型
- en: 'There are two main categories of ML algorithms: supervised learning and unsupervised
    learning. The decision of which type of algorithm to use depends on the data you
    have available and the project objectives.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法主要有两大类：监督学习和无监督学习。选择哪种类型的算法取决于你拥有的数据和项目目标。
- en: Supervised learning problems
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习问题
- en: Supervised learning problems aim to infer the best mapping between an input
    and output dataset based on provided labeled pairs of input/output. The labeled
    dataset acts as feedback for the algorithm, allowing it to gauge the optimality
    of its solution. For example, given a list of mean yearly crude oil prices from
    2010-2018, you may wish to predict the mean yearly crude oil price of 2019\. The
    error that the algorithm makes on the 2010-2018 years will allow the engineer
    to estimate its error on the target prediction year of 2019.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习问题旨在根据提供的标记输入/输出对，推断输入和输出数据集之间最佳映射。标记数据集作为算法的反馈，允许算法评估其解决方案的优化程度。例如，给定2010-2018年每年的平均原油价格列表，你可能希望预测2019年的平均原油价格。算法在2010-2018年产生的误差将允许工程师估计其在目标预测年份2019年的误差。
- en: A **labeled pair** consists of an input vector consisting of independent variables
    and an output vector consisting of dependent variables. For example, a labeled
    dataset for facial recognition might contain input vectors with facial image data
    alongside output vectors encoding the photographed persons name. A **labeled set**
    (or dataset) is a collection of labeled pairs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**标记对**由一个包含独立变量的输入向量和一个包含依赖变量的输出向量组成。例如，用于面部识别的标记数据集可能包含带有面部图像数据的输入向量，以及编码照片中人物姓名的输出向量。**标记集**（或数据集）是标记对的集合。'
- en: Given a labeled collection of handwritten digits, you may wish to predict the
    label of a previously unseen handwritten digit. Similarly, given a dataset of
    emails that are labeled as being either spam or not spam, a company that wants
    to create a spam filter would want to predict whether a previously unseen message
    was spam. All these problems are supervised learning problems.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组标记的手写数字，你可能希望预测一个以前未见过的手写数字的标签。同样，给定一个标记为垃圾邮件或非垃圾邮件的电子邮件数据集，一个想要创建垃圾邮件过滤器的公司会希望预测一个以前未见过的消息是否为垃圾邮件。所有这些问题都是监督学习问题。
- en: 'Supervised ML problems can be further divided into prediction and classification:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习问题可以进一步分为预测和分类：
- en: Classification attempts to label an unknown input sample with a known output
    value. For example, you could train an algorithm to recognize breeds of cats.
    The algorithm would classify an unknown cat by labeling it with a known breed.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**试图用一个已知的输出值来标记一个未知的输入样本。例如，你可以训练一个算法来识别猫的品种。该算法会通过标记它已知的品种来对未知猫进行分类。'
- en: By contrast, prediction algorithms attempt to label an unknown input sample
    with either a known or unknown output value. This is also known as **estimation**
    or **regression**. A canonical prediction problem is time series forecasting,
    where the output value of the series is predicted for a time value that was not
    previously seen.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比之下，预测算法试图用一个已知或未知的输出值来标记一个未知的输入样本。这也被称为**估计**或**回归**。一个典型的预测问题是时间序列预测，其中预测序列的输出值是在之前未见过的某个时间值。
- en: 'A **classification algorithm** will try to associate an input sample with an
    item from a given list of output categories: for example, deciding whether a photo
    represents a cat, a dog, or neither is a classification problem. A **prediction
    algorithm** will map an input sample to a member of an output domain, which could
    be continuous: for example, attempting to guess a persons height from their weight
    and gender would be a prediction problem.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类算法**将尝试将输入样本与给定输出类别列表中的一个项目关联起来：例如，决定一张照片是否代表猫、狗或都不是，这是一个分类问题。**预测算法**将输入样本映射到输出域中的一个成员，该域可以是连续的：例如，尝试根据一个人的体重和性别猜测其身高，这是一个预测问题。'
- en: We will cover supervised algorithms in more detail in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml),
    *Supervised Learning*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第3章](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml)“监督学习”中更详细地介绍监督学习算法。
- en: Unsupervised learning problems
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习问题
- en: Unsupervised learning problems aim to learn from data that has not been labeled.
    For example, given a dataset of market research data, a clustering algorithm can
    divide consumers into segments, saving time for marketing professionals. Given
    a dataset of medical scans, unsupervised classification algorithms can divide
    the image between different kinds of tissues for further analysis. One unsupervised
    learning approach known as dimensionality reduction works in conjunction with
    other algorithms, as a pre-processing step, to reduce the volume of data that
    another algorithm will have to be trained on, cutting down training times. We
    will cover unsupervised learning algorithms in more detail in [Chapter 4](26788e93-3614-413f-bcde-5580516f9c5f.xhtml),
    *Unsupervised Learning*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习问题旨在从未标记的数据中学习。例如，给定一个市场研究数据集，聚类算法可以将消费者划分为不同的细分市场，为市场营销专业人士节省时间。给定一个医学扫描数据集，无监督分类算法可以将图像划分为不同类型的组织，以便进行进一步分析。一种称为降维的无监督学习方法与其他算法协同工作，作为预处理步骤，以减少另一个算法在训练时需要处理的数据量，从而缩短训练时间。我们将在[第4章](26788e93-3614-413f-bcde-5580516f9c5f.xhtml)“无监督学习”中更详细地介绍无监督学习算法。
- en: Most ML algorithms can be efficiently implemented in a wide range of programming
    languages. While Python has been a favorite of data scientists for its ease of
    use and plethora of open source libraries, Go presents significant advantages
    for a developer creating a commercial ML application.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习算法都可以在广泛的编程语言中高效实现。虽然 Python 以其易用性和丰富的开源库而受到数据科学家的青睐，但 Go 为创建商业机器学习应用的开发者提供了显著的优势。
- en: Why write ML applications in Go?
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要在 Go 中编写机器学习应用？
- en: There are libraries for other languages, especially Python, that are more complete
    than Go ML libraries and have benefited from years, if not decades, of research
    from the worlds brightest brains. Some Go programmers make the transition to Go
    in search of better performance, but because ML libraries are typically written
    in C and exposed to Python through their bindings, they do not suffer the same
    performance problems as interpreted Python programs. Deep learning frameworks
    such as TensorFlow and Caffe have very limited, if any, bindings to Go. Even with
    these issues in mind, Go is still an excellent, if not the best, language to develop
    an application containing ML components.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他语言，尤其是 Python，有更完整的库，这些库已经受益于数十年的世界顶尖大脑的研究。一些 Go 程序员为了寻求更好的性能而转向 Go，但由于机器学习库通常是用
    C 编写的，并通过它们的绑定暴露给 Python，因此它们不会像解释型 Python 程序那样遇到相同的性能问题。深度学习框架如 TensorFlow 和
    Caffe 对 Go 的绑定非常有限，甚至没有。即使考虑到这些问题，Go 仍然是一个优秀甚至可能是最好的语言，用于开发包含机器学习组件的应用程序。
- en: The advantages of Go
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Go 的优势
- en: For researchers attempting to improve state-of-the-art algorithms in an academic
    environment, Go may not be the best choice. However, for a start-up with a product
    concept and fast-dwindling cash reserves, completing the development of the product
    in a maintainable and reliable way within a short space of time is essential,
    and this is where the Go language shines.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于试图在学术环境中改进最先进算法的研究人员来说，Go 可能不是最佳选择。然而，对于拥有产品概念且现金储备快速减少的初创公司来说，在短时间内以可维护和可靠的方式完成产品的开发是至关重要的，这正是
    Go 语言大放异彩的地方。
- en: 'Go (or Golang) originates from Google, where its design began in 2007^([10]).
    Its stated objectives were to create an efficient, compiled programming language
    that feels lightweight and pleasant^([11]). Go benefits from a number of features
    that are designed to boost productivity and reliability of production applications:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Go（或 Golang）起源于 Google，其设计始于 2007 年^([10])。其声明的目标是创建一个高效、编译的编程语言，感觉轻便且令人愉悦^([11])。Go
    从众多旨在提高生产应用程序生产力和可靠性的特性中受益：
- en: Easy to learn and on-board new developers
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于学习和接纳新开发者
- en: Fast build time
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速构建时间
- en: Good performance at run-time
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行时良好的性能
- en: Great concurrency support
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 极佳的并发支持
- en: Excellent standard library
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优秀的标准库
- en: Type safety
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类型安全
- en: Easy-to-read, standardized code with `gofmt`
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `gofmt` 易于阅读、标准化的代码
- en: Forced error handling to minimize unforeseen exceptions
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强制错误处理以最小化意外异常
- en: Explicit, clear dependency management
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 明确、清晰的依赖管理
- en: Easy to adapt architecture as projects grow
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着项目增长，易于适应的架构
- en: All these reasons make Go an excellent language for building production systems,
    particularly web applications. The 2018 Stack Overflow developer survey reveals
    that while only 7% of professional developers use Go as their main language, it
    is 5^(th) on the most loved list and also commands very high salaries relative
    to other languages, recognizing the business value that Go programmers add^([12]).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些原因使 Go 成为构建生产系统的优秀语言，尤其是网络应用程序。2018 年 Stack Overflow 开发者调查揭示，尽管只有 7% 的专业开发者将
    Go 作为其主要语言，但它位列最受欢迎列表的第 5 位，并且与其他语言相比，Go 程序员的薪资非常高，这认可了 Go 程序员为企业带来的商业价值^([12])。
- en: Go's mature ecosystem
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Go 成熟的生态系统
- en: Some of the worlds most successful technology companies use Go as the main language
    of their production systems and actively contribute to its development, such as
    Cloudflare^([13]), Google, Uber^([14]), Dailymotion^([15]), and Medium^([16]).
    This means that there is now an extensive ecosystem of tools and libraries to
    help a development team create a reliable, maintainable application in Go. Even
    Docker, the worlds leading container technology, is written in Go.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一些世界上最成功的技术公司将 Go 作为其生产系统的主要编程语言，并积极为其开发做出贡献，例如 Cloudflare^([13])、Google、Uber^([14])、Dailymotion^([15])
    和 Medium^([16])。这意味着现在有一个广泛的工具和库生态系统，可以帮助开发团队在 Go 中创建可靠、可维护的应用程序。甚至全球领先的容器技术 Docker
    也是用 Go 编写的。
- en: At the time of writing, there are 1,774 repositories on GitHub written in the
    Go language that have over 500 stars, traditionally considered a good proxy measure
    of quality and support. In comparison, Python has 3,811 and Java 3,943\. Considering
    that Go is several decades younger and allows for faster production-ready development,
    the relatively large number of well-supported repositories written in the Go language
    constitutes a glowing endorsement from the open source community.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，GitHub 上有 1,774 个用 Go 语言编写的仓库拥有超过 500 个星标，这通常被认为是质量和支持的优良指标。相比之下，Python
    有 3,811 个，Java 有 3,943 个。考虑到 Go 相对较年轻，并且允许更快的生产就绪开发，用 Go 编写的得到良好支持的仓库数量相对较大，这构成了开源社区的高度认可。
- en: Go has a number of stable and well-supported open source ML libraries. The most
    popular Go ML library by number of GitHub stars and contributors is GoLearn^([17]).
    It is also the most recently updated. Other Go ML libraries include GoML and Gorgonia,
    a deep learning library whose API resembles TensorFlow.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Go 拥有众多稳定且得到良好支持的开放源代码机器学习库。按 GitHub 星标和贡献者数量，最受欢迎的 Go 机器学习库是 GoLearn^([17])。它也是最新更新的。其他
    Go 机器学习库包括 GoML 和 Gorgonia，这是一个深度学习库，其 API 类似于 TensorFlow。
- en: Transfer knowledge and models created in other languages
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转移在其他语言中创建的知识和模型
- en: Data scientists will often explore different methods to tackle an ML problem
    in a different language, such as Python, and produce a model that can solve the
    problem outside any application. The plumbing, such as getting data in and out
    of the model, serving this to a customer, persisting outputs or inputs, logging
    errors, or monitoring latencies, is not part of this deliverable and is outside
    the normal scope of work for a data scientist. As a result, taking the model from
    concept to a Go production application requires a polyglot approach such as a
    microservice.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家通常会探索不同的方法来解决机器学习问题，例如使用 Python，并创建一个可以在任何应用程序之外解决问题的模型。这些管道，如将数据输入和输出模型、向客户提供服务、持久化输出或输入、记录错误或监控延迟，并不属于这个交付成果，也不在数据科学家正常工作范围之内。因此，将模型从概念到
    Go 生产应用程序需要多语言方法，如微服务。
- en: Most of the code examples in this book use ML algorithms or bindings to libraries
    such as OpenCV that are also available in languages such as Python. This will
    enable you to take a data scientists prototype Python code and turn it into a
    production Go application in no time.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的大多数代码示例都使用了机器学习算法或绑定到库（如OpenCV），这些库也在Python等语言中可用。这将使您能够快速将数据科学家的原型Python代码转换为生产Go应用程序。
- en: However, there are Go bindings for deep learning frameworks such as TensorFlow
    and Caffe. Moreover, for more basic algorithms such as decision trees, the same
    algorithms have also been implemented in Go libraries and will produce the same
    results if they are configured in the same way. Together, these considerations
    imply that it is possible to fully integrate data science products into a Go application
    without sacrificing accuracy, speed, or forcing a data scientist to work with
    tools they are uncomfortable with.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于深度学习框架如TensorFlow和Caffe，存在Go绑定。此外，对于更基本的算法，如决策树，相同的算法也已经在Go库中实现，并且如果以相同的方式配置，将产生相同的结果。综合考虑，这意味着可以在不牺牲准确性、速度或强迫数据科学家使用他们不习惯的工具的情况下，将数据科学产品完全集成到Go应用程序中。
- en: ML development life cycle
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习开发生命周期
- en: The ML development life cycle is a process to create and take to production
    an application containing an ML model that solves a business problem. The ML model
    can then be served to customers through the application as part of a product or
    service offering.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习开发生命周期是一个创建并推向生产包含解决业务问题的机器学习模型的应用程序的过程。然后，该机器学习模型可以作为产品或服务提供的一部分通过应用程序提供给客户。
- en: 'The following diagram illustrates the ML development life cycle process:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了机器学习开发生命周期过程：
- en: '![](img/a23612fa-f381-4bd8-9cfa-cfb6a07d9ebe.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a23612fa-f381-4bd8-9cfa-cfb6a07d9ebe.png)'
- en: Defining problem and objectives
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义问题和目标
- en: Before any development begins, the problem to be solved must be defined together
    with objectives of what good will look like, to set expectations. The way the
    problem is formulated is very important, as this can mean the difference between
    intractability and a simple solution. It is also likely to involve a conversation
    about where the input data for any algorithm will come from.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何开发开始之前，必须定义要解决的问题以及理想结果的目标，以设定期望。问题的表述方式非常重要，因为这可能意味着无法解决的问题和简单解决方案之间的区别。这也可能涉及到关于任何算法的输入数据来源的讨论。
- en: ML algorithms usually require large amounts of data to perform at their best.
    Sourcing quality data is the most important consideration when planning a ML project.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法通常需要大量数据才能发挥最佳性能。在规划机器学习项目时，获取高质量数据是最重要的考虑因素。
- en: The typical formulation of an ML problem takes the form *given X dataset, predict
    Y*. The availability of data or lack of it thereof can affect the formulation
    of the problem, the solution, and its feasibility. For example, consider the problem
    *given a large labeled set of images of handwritten digits*^([18])*, predict the
    label of a previously unseen image*. Deep learning algorithms have demonstrated
    that it is possible to achieve relatively high accuracy on this particular problem
    with little work on the part of the engineer, as long as the training dataset
    is sufficiently large^([19]). If the training set is not large, the problem immediately
    becomes more difficult and requires a careful selection of the algorithm to use.
    It also affects the accuracy and thus, the set of attainable objectives.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习问题的典型表述形式是“给定X数据集，预测Y”。数据的可用性或缺乏可用性可能会影响问题的表述、解决方案及其可行性。例如，考虑以下问题：“给定一大组标注的手写数字图像”，预测一个之前未见过的图像的标签。深度学习算法已经证明，只要训练数据集足够大，工程师的工作量很小，就可以在这个特定问题上实现相对较高的准确性^([19])。如果训练集不大，问题立即变得更加困难，需要仔细选择要使用的算法。它还影响准确性，从而影响可达到的目标集。
- en: Experiments performed by Michael Nielsen on the MNIST handwritten digit dataset
    show that the difference between training an ML algorithm with 1 example of labeled
    input/output pairs per digit and 5 examples was an improvement of accuracy from
    around 40% to around 65% for most algorithms tested^([20]). Using 10 examples
    per digit usually raised the accuracy a further 5%.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Michael Nielsen在MNIST手写数字数据集上进行的实验表明，对于大多数测试的算法，使用每个数字1个标注的输入/输出对进行训练与使用5个示例相比，准确率从大约40%提高到大约65%^([20])。通常，每个数字使用10个示例可以将准确率进一步提高5%。
- en: If insufficient data is available to meet the project objectives, it is sometimes
    possible to boost performance by artificially expanding the dataset by making
    small changes to existing examples. In the previously mentioned experiments, Nielsen
    observed that adding slightly rotated or translated images to the dataset improved
    performance by as much as 15%.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可用的数据不足以满足项目目标，有时可以通过对现有示例进行微小修改来人工扩大数据集以提高性能。在之前提到的实验中，Nielsen观察到，向数据集中添加略微旋转或平移的图像可以将性能提高多达15%。
- en: Acquiring and exploring data
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取和探索数据
- en: We argued earlier that it is critical to understand the input dataset before
    specifying project objectives, particularly objectives related to accuracy. As
    a general rule, ML algorithms will produce the best results when there are large
    training datasets available. The more data is used to train them, the better they
    will perform.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已经论证，在指定项目目标之前理解输入数据集是至关重要的，尤其是与准确性相关的目标。一般来说，当有大量的训练数据集可用时，机器学习算法会产生最佳结果。用于训练它们的数据越多，它们的性能就越好。
- en: Acquiring data is, therefore, a key step in the ML development life cycle—one
    that can be very time-consuming and fraught with difficulty. In certain industries,
    privacy legislation may cause a lack of availability of personal data, making
    it difficult to create personalized products or requiring anonymization of source
    data before it can be used. Some datasets may be available but could require such
    extensive preparation or even manual labeling that it may put the project timeline
    or budget under stress.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，获取数据是机器学习开发生命周期中的一个关键步骤——这个步骤可能非常耗时且充满困难。在某些行业中，隐私法规可能导致个人数据不可用，这使得创建个性化产品变得困难，或者在使用之前需要对源数据进行匿名化。一些数据集可能可用，但可能需要如此广泛的准备甚至人工标记，这可能会给项目时间表或预算带来压力。
- en: 'Even if you do not have a proprietary dataset to apply to your problem, you
    may be able to find public datasets to use. Often, public datasets will have received
    attention from researchers, so you may find that the particular problem you are
    attempting to tackle has already been solved and the solution is open source.
    Some good sources of public datasets areas follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你没有专有数据集可以应用于你的问题，你也可能找到可用的公共数据集。通常，公共数据集已经引起了研究者的关注，因此你可能发现你试图解决的问题已经被解决，并且解决方案是开源的。以下是一些公共数据集的良好来源：
- en: '**Awesome datasets**: [https://github.com/awesomedata/awesome-public-datasets](https://github.com/awesomedata/awesome-public-datasets)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**出色的数据集**：[https://github.com/awesomedata/awesome-public-datasets](https://github.com/awesomedata/awesome-public-datasets)'
- en: '**Skymind open datasets**: [https://skymind.ai/wiki/open-datasets](https://skymind.ai/wiki/open-datasets)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Skymind 开放数据集**：[https://skymind.ai/wiki/open-datasets](https://skymind.ai/wiki/open-datasets)'
- en: '**OpenML**: [https://www.openml.org/](https://www.openml.org/)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenML**：[https://www.openml.org/](https://www.openml.org/)'
- en: '**Kaggle**: [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kaggle**：[https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)'
- en: '**UK Governments open data**: [https://data.gov.uk/](https://data.gov.uk/)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**英国政府开放数据**：[https://data.gov.uk/](https://data.gov.uk/)'
- en: '**US Governments open data**: [https://www.data.gov/](https://www.data.gov/)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**美国政府开放数据**：[https://www.data.gov/](https://www.data.gov/)'
- en: Once the dataset has been acquired, it should be explored to gain a basic understanding
    of how the different features (independent variables) may affect the desired output.
    For example, when attempting to predict correct height and weight from self-reported
    figures, researchers determined from initial exploration that older subjects were
    more likely to under-report obesity and therefore that age was thus a relevant
    feature when building their model. Attempting to build a model from all available
    data, even features that may not be relevant, can lead to longer training times
    in the best case, and can severely hamper accuracy in the worst case by introducing
    noise.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获取了数据集，就应该对其进行探索，以获得对不同的特征（自变量）如何影响所需输出的基本理解。例如，当试图从自我报告的数据中预测正确的高度和体重时，研究人员在初步探索中确定，年龄较大的受试者更有可能低估肥胖，因此年龄在构建他们的模型时是一个相关特征。试图从所有可用数据中构建模型，即使是不相关的特征，在最坏的情况下可能会导致训练时间更长，并且通过引入噪声严重损害准确性。
- en: It is worth spending a bit more time to process and transform a dataset as this
    will improve the accuracy of the end result and maybe even the training time.
    All the code examples in this book include data processing and transformation.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 花更多的时间来处理和转换数据集是值得的，因为这将提高最终结果的准确性，甚至可能缩短训练时间。本书中的所有代码示例都包括数据处理和转换。
- en: In [Chapter 2](532d8304-b31d-41ef-81c1-b13f4c692824.xhtml), *Setting Up the
    ML Environment*, we will see how to explore data using Go and an interactive browser-based
    tool called **Jupyter**.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](532d8304-b31d-41ef-81c1-b13f4c692824.xhtml)《设置机器学习环境》中，我们将看到如何使用Go语言和一个名为**Jupyter**的基于浏览器的交互式工具来探索数据。
- en: Selecting the algorithm
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择算法
- en: The selection of the algorithm is arguably the most important decision that
    an ML application engineer will need to make, and the one that will take the most
    research. Sometimes, it is even required to combine an ML algorithm with traditional
    computer science algorithms to make a problem more tractable—an example of this
    is a recommender system that we consider later.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的选取可以说是机器学习应用工程师需要做出的最重要的决定，也是需要投入最多研究的工作。有时，甚至需要将机器学习算法与传统计算机科学算法相结合，以便使问题更容易处理——这种例子就是我们后面将要讨论的推荐系统。
- en: A good first step to start homing in on the best algorithm to solve a given
    problem is to determine whether a supervised or unsupervised approach is required.
    We introduced both earlier in the chapter. As a rule of thumb, when you are in
    possession of a labeled dataset and wish to categorize or predict a previously
    unseen sample, this will use a supervised algorithm. When you wish to understand
    an unlabeled dataset better by clustering it into different groups, possibly to
    then classify new samples against, you will use an unsupervised learning algorithm.
    A deeper understanding of the advantages and pitfalls of each algorithm and a
    thorough exploration of your data will provide enough information to select an
    algorithm. To help you get started, we cover a range of supervised learning algorithms
    in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised Learning*, and
    unsupervised learning algorithms in [Chapter 4](26788e93-3614-413f-bcde-5580516f9c5f.xhtml), *Unsupervised
    Learning*.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 开始寻找解决特定问题的最佳算法的一个好方法是确定是否需要监督或无监督方法。我们在本章前面介绍了这两种方法。一般来说，当你拥有标记的数据集，并希望对之前未见过的样本进行分类或预测时，这将使用监督算法。当你希望通过将未标记的数据集聚类成不同的组来更好地理解它，可能为了随后对新样本进行分类，你将使用无监督学习算法。对每种算法的优点和缺点有更深入的了解，以及对你的数据进行彻底的探索，将提供足够的信息来选择算法。为了帮助你开始，我们在[第3章](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml)《监督学习》中涵盖了各种监督学习算法，在[第4章](26788e93-3614-413f-bcde-5580516f9c5f.xhtml)《无监督学习》中涵盖了无监督学习算法。
- en: Some problems can lend themselves to a deft application of both ML techniques
    and traditional computer science. One such problem is recommender systems, which
    are now widespread in online retailers such as Amazon and Netflix. This problem
    asks, *given a dataset of each users set of purchased items, predict a set of
    N items that the user is most likely to purchase next*. This is exemplified in
    Amazons *people who buy X also buy Y* system.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一些问题可以巧妙地应用机器学习技术和传统计算机科学。其中一个这样的问题是推荐系统，现在在像亚马逊和Netflix这样的在线零售商中非常普遍。这个问题要求，*给定每个用户购买物品的数据集，预测用户最有可能购买的下N个物品*。这在亚马逊的“购买X的人也购买Y”系统中得到了体现。
- en: The basic idea of the solution is that, if two users purchase very similar items,
    then any items not in the intersection of their purchased items are good candidates
    for their future purchases. First, transform the dataset so that it maps pairs
    of items to a score that expresses their co-occurrence. This can be computed by
    taking the number of times that the same customer has purchased both items, divided
    by the number of times a customer has purchased either one or the other, to give
    a number between 0 and 1\. This now provides a labeled dataset to train a supervised
    algorithm such as a binary classifier to predict the score for a previously unseen
    pair. Combining this with a sorting algorithm can produce, given a single item,
    a list of items in a sorted rank of purchasability.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案的基本思想是，如果两个用户购买非常相似的商品，那么任何不在他们购买商品交集中的商品都是他们未来购买的好候选。首先，将数据集转换成将商品对映射到表示它们共现的分数。这可以通过计算相同客户购买两个商品的次数除以客户购买任一商品的次数来计算，得到一个介于0和1之间的数字。现在这提供了一个标记的数据集来训练一个监督算法，如二元分类器，以预测先前未见对对的分数。结合排序算法，给定一个单一的商品，可以生成一个按可购买性排序的商品列表。
- en: Preparing data
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据
- en: Data preparation refers to the processes performed on the input dataset before
    training the algorithm. A rigorous preparation process can simultaneously enhance
    the quality of the data and reduce the amount of time it will take the algorithm
    to reach the desired accuracy. The two steps to preparing data are data pre-processing
    and data transformation. We will go into more detail on preparing data in [Chapters
    2](532d8304-b31d-41ef-81c1-b13f4c692824.xhtml), *Setting Up The Development Environment*, [Chapter
    3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised Learning*, and [Chapter
    4](26788e93-3614-413f-bcde-5580516f9c5f.xhtml), *Unsupervised Learning*.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备是指在训练算法之前对输入数据集所执行的过程。一个严谨的准备过程可以同时提高数据质量并减少算法达到所需精度所需的时间。数据准备的两个步骤是数据预处理和数据转换。我们将在[第2章](532d8304-b31d-41ef-81c1-b13f4c692824.xhtml)，*设置开发环境*，[第3章](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml)，*监督学习*，和[第4章](26788e93-3614-413f-bcde-5580516f9c5f.xhtml)，*无监督学习*中详细介绍数据准备。
- en: Data pre-processing aims to transform the input dataset into a format that is
    adequate for work with the selected algorithm. A typical example of a pre-processing
    task is to format a date column in a certain way, or to ingest CSV files into
    a database, discarding any rows that lead to parsing errors. There may also be
    missing data values in an input data file that need to either be filled in (say,
    with a mean), or the entire sample discarded. Sensitive information such as personal
    information may need to be removed.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理旨在将输入数据集转换为适合与所选算法一起工作的格式。预处理任务的典型示例是将日期列格式化为某种方式，或将CSV文件导入数据库，丢弃导致解析错误的任何行。输入数据文件中可能也存在需要填充（例如，使用平均值）或整个样本丢弃的缺失数据值。敏感信息，如个人信息，可能需要被移除。
- en: Data transformation is the process of sampling, reducing, enhancing, or aggregating
    the dataset to make it more suitable for the algorithm. If the input dataset is
    small, it may be necessary to enhance it by artificially creating more examples,
    such as rotating images in an image recognition dataset. If the input dataset
    has features that the exploration has deemed irrelevant, it would be wise to remove
    them. If the dataset is more granular than the problem requires, aggregating it
    to a coarser granularity may help speed up results, such as aggregating city-level
    data to counties if the problem only requires a prediction per county.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换是指对数据集进行采样、减少、增强或聚合的过程，使其更适合算法。如果输入数据集较小，可能需要通过人工创建更多示例来增强它，例如在图像识别数据集中旋转图像。如果输入数据集具有探索认为无关的特征，明智的做法是移除它们。如果数据集比问题所需的粒度更细，将其聚合到更粗的粒度可能有助于加快结果，例如，如果问题只需要对每个县进行预测，则将城市级数据聚合到县。
- en: Finally, if the input dataset is particularly large, as is the case with many
    image datasets intended for use by deep learning algorithms, it would be a good
    idea to start with a smaller sample that will produce fast results so that the
    viability of the algorithm can be verified before investing in more computing
    resources.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果输入数据集特别大，例如许多用于深度学习算法的图像数据集，那么从较小的样本开始，这将产生快速结果，以便在投资更多计算资源之前验证算法的可行性，这是一个好主意。
- en: The sampling process will also divide the input dataset into training and validation
    subsets. We will explain why this is necessary later, and what proportion of the
    data to use for both.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 样本过程还将把输入数据集分成训练和验证子集。我们将在后面解释为什么这是必要的，以及应该使用多少数据比例。
- en: Training
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练
- en: The most compute-intensive part of the ML development life cycle is the training
    process. Training an ML algorithm can take seconds in the simplest case or days
    when the input dataset is enormous and the algorithm requires many iterations
    to converge. The latter case is usually observed with deep learning techniques.
    For example, DeepMinds AlphaGo Zero algorithm took forty days to fully master
    the game of Go, even though it was proficient after only three^([22]). Many algorithms
    that operate on smaller datasets and problems other than image or sound recognition
    will not require such a large amount of time or computational resource.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习开发生命周期中最计算密集的部分是训练过程。在最简单的情况下，训练一个机器学习算法可能只需要几秒钟，而当输入数据集巨大且算法需要多次迭代才能收敛时，可能需要几天。后者通常与深度学习技术相关。例如，DeepMinds
    AlphaGo Zero 算法用了四十天时间才完全掌握围棋游戏，尽管它在仅仅三天后就已经很熟练了^([22])。在处理较小数据集和图像或声音识别以外的其他问题上的许多算法，可能不需要这么多的时间或计算资源。
- en: Cloud-based computational resources are getting cheaper and cheaper, so, if
    an algorithm, especially a deep learning algorithm, is taking too long to train
    on your PC, you can deploy and train it on a cloud instance for a few dollars.
    We will cover deployment models in [Chapter 6](a48ed496-8a06-4293-80fb-0413d05e7a3e.xhtml),
    *Deploying Machine Learning Applications*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 基于云的计算资源正变得越来越便宜，因此，如果一个算法，尤其是深度学习算法，在您的PC上训练时间过长，您可以在云实例上部署和训练它，只需花费几美元。我们将在[第6章](a48ed496-8a06-4293-80fb-0413d05e7a3e.xhtml)中介绍部署模型，*部署机器学习应用*。
- en: While the algorithm is training, particularly if the training phase will take
    a long time, it is useful to have some real-time measures of how well the training
    is going, so that it can be interrupted, re-configured, and restarted without
    waiting for the training to complete. These metrics are typically classified as
    **loss metrics**, where *loss* refers to the notional error that the algorithm
    makes either on the training or validation subsets.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当算法正在训练时，尤其是如果训练阶段将花费很长时间，那么有一些实时指标来衡量训练进展情况是有用的，这样就可以在不等待训练完成的情况下中断、重新配置和重新启动。这些指标通常被归类为**损失指标**，其中*损失*指的是算法在训练或验证子集上犯的假设性错误。
- en: 'Some of the most common loss metrics in prediction problems are as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测问题中最常见的损失度量指标如下：
- en: '**Mean square error** (**MSE**) measures the sum of the squared distance between
    the output variable and the predicted values.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均方误差**（**MSE**）衡量输出变量与预测值之间平方距离的总和。'
- en: '**Mean absolute error** (**MAE**) measures the sum of the absolute distance
    between the output variable and the predicted values.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均绝对误差**（**MAE**）衡量输出变量与预测值之间绝对距离的总和。'
- en: '**Huber loss** is a combination of the MSE and MAE that is more robust to outliers
    while remaining a good estimator of both the mean and median loss.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Huber损失**是MSE和MAE的组合，它对异常值更稳健，同时仍然是均值和中值损失的良好估计器。'
- en: 'Some of the most common loss metrics in classification problems are as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类问题中最常见的损失度量指标如下：
- en: '**Logarithmic loss** measures the accuracy of the classifier by placing a penalty
    on false classifications. It is closely related to cross-entropy loss.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对数损失**通过对错误分类进行惩罚来衡量分类器的准确性。它与交叉熵损失密切相关。'
- en: '**Focal loss** is a newer `loss` func aimed at preventing false negatives when
    the input dataset is sparse^([23]).'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**焦点损失**是一种新的`损失`函数，旨在防止当输入数据集稀疏时出现假阴性^([23])。'
- en: Validating/testing
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证/测试
- en: Software engineers are familiar with testing and debugging software source code,
    but how should ML models be tested? Pieces of algorithms and data input/output
    routines can be unit tested, but often it is unclear how to ensure that the ML
    model itself, which presents as a black box, is correct.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 软件工程师熟悉测试和调试软件源代码，但如何测试机器学习模型呢？算法片段和数据输入/输出例程可以进行单元测试，但通常不清楚如何确保作为黑盒的机器学习模型本身是正确的。
- en: The first step to ensuring correctness and sufficient accuracy of an ML model
    is validation. This means applying the model to predict or classify the validation
    data subset, and measuring the resulting accuracy against project objectives.
    Because the training data subset was already seen by the algorithm, it cannot
    be used to validate correctness, as the model could suffer from poor generalizability
    (also known as **overfitting**). To take a nonsensical example, imagine an ML
    model that consists of a hash map that memorizes each input sample and maps it
    to the corresponding training output sample. The model would have 100% accuracy
    on a training data subset, which was previously memorized, but very low accuracy
    on any data subset, and therefore it would not solve the problem it was intended
    for. Validation tests against this phenomenon.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 确保机器学习模型正确性和足够准确的第一步是验证。这意味着将模型应用于预测或分类验证数据子集，并将结果准确性与项目目标进行比较。因为训练数据子集已经被算法看到，所以不能用来验证正确性，因为模型可能会遭受泛化能力差（也称为**过拟合**）的问题。为了举一个荒谬的例子，想象一个由哈希表组成的机器学习模型，该表记住每个输入样本并将其映射到相应的训练输出样本。该模型在之前记忆的训练数据子集上会有100%的准确率，但在任何数据子集上都会有非常低的准确率，因此它将无法解决它打算解决的问题。验证测试针对这种现象。
- en: In addition, it is a good idea to validate model outputs against user acceptance
    criteria. For example, if building a recommender system for TV series, you may
    wish to ensure that the recommendations made to children are never rated PG-13
    or higher. Rather than trying to encode this into the model, which will have a
    non-zero failure rate, it is better to push this constraint into the application
    itself, because the cost of not enforcing it would be too high. Such constraints
    and business rules should be captured at the start of the project.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，将模型输出与用户接受标准进行验证也是一个好主意。例如，如果你正在为电视剧构建推荐系统，你可能希望确保向儿童推荐的节目永远不会被评为PG-13或更高。与其试图将此编码到模型中，这将有一个非零的失败率，不如将此约束推入应用程序本身，因为不执行此约束的成本会太高。此类约束和业务规则应在项目开始时捕获。
- en: Integrating and deploying
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成和部署
- en: The boundary between the ML model and the rest of the application must be defined.
    For example, will the algorithm expose a `Predict` method that provides a prediction
    for a given input sample? Will input data processing be required of the caller,
    or will the algorithm implementation perform it? Once this is defined, it is easier
    to follow best practice when it comes to testing or mocking the ML model to ensure
    correctness of the rest of the application. Separation of concerns is important
    for any application, but for ML applications where one component behaves like
    a black box, it is essential.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型与其他应用程序之间的边界必须定义。例如，算法是否会提供一个`Predict`方法来为给定的输入样本提供预测？是否需要调用者处理输入数据处理，还是算法实现会执行它？一旦这被定义，在测试或模拟机器学习模型以确保应用程序其余部分的正确性时，遵循最佳实践就会变得更容易。对于任何应用程序，关注点的分离都很重要，但对于那些一个组件表现得像黑盒的机器学习应用程序来说，这一点是至关重要的。
- en: There are a number of possible deployment methods for ML applications. For Go
    applications, containerization is particularly simple as the compiled binary will
    have no dependencies (except in some very special cases, such as where bindings
    to deep learning libraries such as TensorFlow are required). Different cloud vendors
    also admit serverless deployments and have different **continuous integration**/**continuous
    deployment** (**CI**/**CD**) offerings. Part of the advantage of using a language
    such as Go is that the application can be deployed very flexibly making use of
    available tooling for traditional systems applications, and without resorting
    to a messy polyglot approach.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习应用程序有几种可能的部署方法。对于Go应用程序来说，容器化特别简单，因为编译的二进制文件将没有依赖项（除非在某些非常特殊的情况下需要，例如需要绑定到深度学习库，如TensorFlow）。不同的云服务提供商也接受无服务器部署，并提供不同的**持续集成**/**持续部署**（**CI**/**CD**）服务。使用Go等语言的部分优势在于，应用程序可以非常灵活地部署，利用可用于传统系统应用程序的工具，而不必求助于混乱的多语言方法。
- en: In [Chapter 6](a48ed496-8a06-4293-80fb-0413d05e7a3e.xhtml), *Deploying Machine
    Learning Applications*, we will take a deep dive into topics such as deployment
    models, **Platform as a Service** (**PaaS**) versus **Infrastructure as a Service**
    (**IaaS**), and monitoring and alerting specific to ML applications, leveraging
    the tools built for the Go language.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](a48ed496-8a06-4293-80fb-0413d05e7a3e.xhtml)，“部署机器学习应用”中，我们将深入探讨诸如部署模型、**平台即服务（PaaS）**与**基础设施即服务（IaaS）**的对比，以及针对机器学习应用的监控和警报等特定主题，利用为Go语言构建的工具。
- en: Re-validating
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重新验证
- en: It is rare to put a model into production that never requires updating or re-training.
    A recommender system may need regular re-training as user preferences shift. An
    image recognition model for car makes and models may need re-training as more
    models come onto the market. A behavioral forecasting tool that produces one model
    for each device in an IoT population may need continuous monitoring to ensure
    that each model still satisfies the desired accuracy criterion, and to retrain
    those that are not.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型投入生产而无需更新或重新训练的情况很少见。推荐系统可能需要定期重新训练，因为用户偏好会发生变化。用于汽车制造商和型号的图像识别模型可能需要随着市场上更多模型的推出而重新训练。为物联网群体中的每个设备生成一个模型的预测行为工具可能需要持续监控，以确保每个模型仍然满足所需的准确度标准，并对那些不满足标准的模型进行重新训练。
- en: The re-validation process is a continuous process where the accuracy of the
    model is tested and, if it is deemed to have decreased, an automated or manual
    process is triggered to re-train it, ensuring that the results are always optimal.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 重新验证过程是一个持续的过程，其中测试模型的准确性，如果认为其准确性已降低，则触发自动或手动过程以重新训练它，确保结果始终是最优的。
- en: Summary
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced ML and the different types of ML problems. We
    argued for Go as a language to develop ML applications. Then, we outlined the
    ML development life cycle, the process of creating and taking to production an
    ML application.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了机器学习以及不同类型的机器学习问题。我们主张使用Go语言来开发机器学习应用。然后，我们概述了机器学习开发的生命周期，创建并部署机器学习应用的过程。
- en: In the next chapter, we will explain how to set up a development environment
    for ML applications and Go.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将解释如何为机器学习应用和Go设置开发环境。
- en: Further readings
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[https://www.crunchbase.com/hub/machine-learning-companies](https://www.crunchbase.com/hub/machine-learning-companies),
    retrieved on February 9, 2019.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.crunchbase.com/hub/machine-learning-companies](https://www.crunchbase.com/hub/machine-learning-companies)，于2019年2月9日检索。'
- en: '[https://www.ft.com/content/133dc9c8-90ac-11e8-9609-3d3b945e78cf](https://www.ft.com/content/133dc9c8-90ac-11e8-9609-3d3b945e78cf).
    *Machine Learning will be the global engine of growth*.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.ft.com/content/133dc9c8-90ac-11e8-9609-3d3b945e78cf](https://www.ft.com/content/133dc9c8-90ac-11e8-9609-3d3b945e78cf)。*机器学习将成为全球增长的动力*。'
- en: '[https://news.crunchbase.com/news/venture-funding-ai-machine-learning-levels-off-tech-matures/](https://news.crunchbase.com/news/venture-funding-ai-machine-learning-levels-off-tech-matures/).
    Retrieved on February 9, 2019.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://news.crunchbase.com/news/venture-funding-ai-machine-learning-levels-off-tech-matures/](https://news.crunchbase.com/news/venture-funding-ai-machine-learning-levels-off-tech-matures/)。于2019年2月9日检索。'
- en: '[https://www.economist.com/science-and-technology/2018/02/15/for-artificial-intelligence-to-thrive-it-must-explain-itself](https://www.economist.com/science-and-technology/2018/02/15/for-artificial-intelligence-to-thrive-it-must-explain-itself).
    Retrieved on February 9, 2019.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.economist.com/science-and-technology/2018/02/15/for-artificial-intelligence-to-thrive-it-must-explain-itself](https://www.economist.com/science-and-technology/2018/02/15/for-artificial-intelligence-to-thrive-it-must-explain-itself)。于2019年2月9日检索。'
- en: '[https://www.nytimes.com/column/machine-learning](https://www.nytimes.com/column/machine-learning).
    Retrieved on February 9th 2019.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.nytimes.com/column/machine-learning](https://www.nytimes.com/column/machine-learning)。于2019年2月9日检索。'
- en: See for example *Google Trends for Machine Learning*. [https://trends.google.com/trends/explore?date=all&amp;geo=US&amp;q=machine%20learning](https://trends.google.com/trends/explore?date=all&geo=US&q=machine%20learning).
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 例如，请参阅*Google Trends for Machine Learning*。[https://trends.google.com/trends/explore?date=all&geo=US&q=machine%20learning](https://trends.google.com/trends/explore?date=all&geo=US&q=machine%20learning)。
- en: R. Kohavi and F. Provost, *Glossary of Terms, Machine Learning*, vol. 30, no.
    2–3, pp. 271–274, 1998\. 30, no. 2–3, pp. 271–274, 1998.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: R. Kohavi和F. Provost，*《机器学习术语表》*，第30卷第2-3期，第271-274页，1998年。30，第2-3期，第271-274页，1998年。
- en: 'Turing, Alan (October 1950). *Computing Machinery and Intelligence*. Mind.
    59 (236): 433–460\. doi:10.1093/mind/LIX.236.433\. Retrieved 8 June 2016.016.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图灵，艾伦（1950年10月）。*《计算机与智能》*。Mind. 59（236）：433–460。doi:10.1093/mind/LIX.236.433。于2016年6月8日检索。
- en: '[https://www.forbes.com/sites/bernardmarr/2016/12/06/what-is-the-difference-between-artificial-intelligence-and-machine-learning/](https://www.forbes.com/sites/bernardmarr/2016/12/06/what-is-the-difference-between-artificial-intelligence-and-machine-learning/).
    Retrieved on February 9, 2019.'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.forbes.com/sites/bernardmarr/2016/12/06/what-is-the-difference-between-artificial-intelligence-and-machine-learning/](https://www.forbes.com/sites/bernardmarr/2016/12/06/what-is-the-difference-between-artificial-intelligence-and-machine-learning/)。检索日期：2019年2月9日。'
- en: '[https://talks.golang.org/2012/splash.article](https://talks.golang.org/2012/splash.article).
    Retrieved February 9, 2019.'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://talks.golang.org/2012/splash.article](https://talks.golang.org/2012/splash.article)。检索日期：2019年2月9日。'
- en: '[https://talks.golang.org/2012/splash.article](https://talks.golang.org/2012/splash.article).
    Retrieved February 9,h 2019.'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://talks.golang.org/2012/splash.article](https://talks.golang.org/2012/splash.article)。检索日期：2019年2月9日。'
- en: '[https://insights.stackoverflow.com/survey/2018/](https://insights.stackoverflow.com/survey/2018/).
    Retrieved February 9, 2019.'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://insights.stackoverflow.com/survey/2018/](https://insights.stackoverflow.com/survey/2018/)。检索日期：2019年2月9日。'
- en: '[https://github.com/cloudflare](https://github.com/cloudflare). Retrieved February
    9, 2019.'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://github.com/cloudflare](https://github.com/cloudflare)。检索日期：2019年2月9日。'
- en: '[https://github.com/uber](https://github.com/uber). Retrieved February 9, 2019.'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://github.com/uber](https://github.com/uber)。检索日期：2019年2月9日。'
- en: '[https://github.com/dailymotion](https://github.com/dailymotion). Retrieved
    February 9, 2019.'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://github.com/dailymotion](https://github.com/dailymotion)。检索日期：2019年2月9日。'
- en: '[https://github.com/medium](https://github.com/medium). Retrieved February
    9, 2019.'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://github.com/medium](https://github.com/medium)。检索日期：2019年2月9日。'
- en: '[https://github.com/sjwhitworth/golearn](https://github.com/sjwhitworth/golearn).
    Retrieved on 10, February 2019.'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://github.com/sjwhitworth/golearn](https://github.com/sjwhitworth/golearn)。检索日期：2019年2月10日。'
- en: See the MNIST dataset hosted at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
    Retrieved February 10, 2019.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看托管在[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)的MNIST数据集。检索日期：2019年2月10日。
- en: See [https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/](https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/)
    for an example. Retrieved February 10, 2019.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下示例：[https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/](https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/)。检索日期：2019年2月10日。
- en: '[http://cognitivemedium.com/rmnist](http://cognitivemedium.com/rmnist). Retrieved
    February 10, 2019.'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[http://cognitivemedium.com/rmnist](http://cognitivemedium.com/rmnist)。检索日期：2019年2月10日。'
- en: '*Regression Models to Predict Corrected Weight, Height and Obesity Prevalence
    From Self-Reported Data*: data from BRFSS 1999-2007\. Int J Obes (Lond). 2010
    Nov; 34(11):1655-64\. doi: 10.1038/ijo.2010.80\. Epub 2010 Apr 13.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*从自我报告数据中预测校正体重、身高和肥胖患病率的回归模型*：来自BRFSS 1999-2007的数据。Int J Obes (Lond)。2010年11月；34(11)：1655-64。doi：10.1038/ijo.2010.80。Epub
    2010年4月13日。'
- en: '[https://deepmind.com/blog/alphago-zero-learning-scratch/](https://deepmind.com/blog/alphago-zero-learning-scratch/).
    Retrieved February 10th, 2019.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://deepmind.com/blog/alphago-zero-learning-scratch/](https://deepmind.com/blog/alphago-zero-learning-scratch/)。检索日期：2019年2月10日。'
- en: '*Focal Loss for Dense Object Detection*. Lin et al. ICCV 2980-2988\. Pre-print
    available at [https://arxiv.org/pdf/1708.02002.pdf](https://arxiv.org/pdf/1708.02002.pdf).'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*密集目标检测中的焦点损失*。Lin等人。ICCV 2980-2988。预印本可在[https://arxiv.org/pdf/1708.02002.pdf](https://arxiv.org/pdf/1708.02002.pdf)找到。'
