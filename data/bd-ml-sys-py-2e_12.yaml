- en: Chapter 12. Bigger Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章. 更大的数据
- en: 'It''s not easy to say what big data is. We will adopt an operational definition:
    when data is so large that it becomes cumbersome to work with, we will talk about
    **big data**. In some areas, this might mean petabytes of data or trillions of
    transactions: data which will not fit into a single hard drive. In other cases,
    it may be one hundred times smaller, but still difficult to work with.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 很难界定什么是大数据。我们将采用一种操作性定义：当数据变得庞大到难以处理时，我们称之为**大数据**。在某些领域，这可能意味着拍字节级的数据或万亿级的交易数据：这些数据无法完全存储在单个硬盘中。在其他情况下，它可能只有一百倍小，但仍然难以处理。
- en: Why has data itself become an issue? While computers keep getting faster and
    have more memory, the size of the data has grown as well. In fact, data has grown
    faster than computational speed and few algorithms scale linearly with the size
    of the input data—taken together, this means that data has grown faster than our
    ability to process it.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么数据本身成为了一个问题？虽然计算机的处理速度不断提高，内存也在增加，但数据的规模也在不断增长。事实上，数据的增长速度快于计算速度，而且很少有算法能够随着输入数据规模的增加而线性扩展——综合来看，这意味着数据的增长速度超过了我们处理它的能力。
- en: 'We will first build on some of the experience of the previous chapters and
    work with what we can call medium data setting (not quite big data, but not small
    either). For this, we will use a package called **jug**, which allows us to perform
    the following tasks:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先基于前几章的一些经验，处理我们可以称之为中等数据规模的问题（不是大数据，但也不算小）。为此，我们将使用一个叫做**jug**的包，它使我们能够执行以下任务：
- en: Break up your pipeline into tasks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将你的管道分解为任务
- en: Cache (memoize) intermediate results
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存（*缓存*）中间结果
- en: Make use of multiple cores, including multiple computers on a grid
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用多个核心，包括网格上的多台计算机
- en: The next step is to move to true *big data* and we will see how to use the cloud
    for computation purpose. In particular, you will learn about the Amazon Web Services
    infrastructure. In this section, we introduce another Python package called StarCluster
    to manage clusters.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是转向真正的*大数据*，我们将看到如何使用云计算。特别地，你将了解 Amazon Web Services 基础设施。在这一部分，我们介绍了另一个名为
    StarCluster 的 Python 包来管理集群。
- en: Learning about big data
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习大数据
- en: 'The expression "big data" does not mean a specific amount of data, neither
    in the number of examples nor in the number of gigabytes, terabytes, or petabytes
    occupied by the data. It means that data has been growing faster than processing
    power. This implies the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '"大数据"这一表达并不意味着特定数量的数据，无论是数据样本的数量，还是数据占用的千兆字节、太字节或拍字节的数量。它意味着数据的增长速度快于处理能力的提升。这意味着以下几点：'
- en: Some of the methods and techniques that worked well in the past now need to
    be redone or replaced as they do not scale well to the new size of the input data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过去有效的方法和技术现在需要重新做或替换，因为它们无法很好地扩展到新的输入数据规模。
- en: Algorithms cannot assume that all the input data can fit in RAM
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法不能假设所有输入数据都能装入内存。
- en: Managing data becomes a major task in itself
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理数据本身成为了一项主要任务
- en: Using computer clusters or multicore machines becomes a necessity and not a
    luxury
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用计算机集群或多核机器已经不再是奢侈，而是必要。
- en: 'This chapter will focus on this last piece of the puzzle: how to use multiple
    cores (either on the same machine or on separate machines) to speed up and organize
    your computations. This will also be useful in other medium-sized data tasks.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点讲解这一拼图的最后一块：如何利用多个核心（无论是在同一台机器上还是在不同机器上）来加速和组织你的计算。这对于其他中等规模的数据任务也会有帮助。
- en: Using jug to break up your pipeline into tasks
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 jug 将你的管道分解为任务
- en: 'Often, we have a simple pipeline: we preprocess the initial data, compute features,
    and then call a machine learning algorithm with the resulting features.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常有一个简单的管道：我们对初始数据进行预处理，计算特征，然后用计算出的特征调用机器学习算法。
- en: 'Jug is a package developed by Luis Pedro Coelho, one of the authors of this
    book. It''s open source (using the liberal MIT License) and can be useful in many
    areas, but was designed specifically around data analysis problems. It simultaneously
    solves several problems, for example:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Jug 是由本书作者之一 Luis Pedro Coelho 开发的一个包。它是开源的（使用自由的 MIT 许可），在许多领域都能派上用场，但它是专门围绕数据分析问题设计的。它同时解决了多个问题，例如：
- en: It can *memoize* results to disk (or a database), which means that if you ask
    it to compute something you have already computed before, the result is instead
    read from disk.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以将结果*缓存*到磁盘（或数据库），这意味着如果你要求它计算已经计算过的内容，结果将直接从磁盘读取。
- en: It can use multiple cores or even multiple computers on a cluster. Jug was also
    designed to work very well in batch computing environments, which use queuing
    systems such as **PBS** (**Portable Batch System**), **LSF** (**Load Sharing Facility**),
    or **Grid Engine**. This will be used in the second half of the chapter as we
    build online clusters and dispatch jobs to them.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以使用多个核心，甚至在集群中的多台计算机上运行。Jug的设计也非常适合批处理计算环境，这些环境使用排队系统，如**PBS**（**Portable
    Batch System**）、**LSF**（**Load Sharing Facility**）或**Grid Engine**。这将在本章后半部分使用，我们将构建在线集群并向它们分配任务。
- en: An introduction to tasks in jug
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: jug中的任务简介
- en: 'Tasks are the basic building block of jug. A task is composed of a function
    and values for its arguments. Consider this simple example:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 任务是jug的基本构建块。一个任务由一个函数和其参数值组成。考虑这个简单的例子：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this chapter, the code examples will generally have to be typed in script
    files. Thus, they will not be shown with the `>>>` marker. Commands that should
    be typed at the shell will be indicated by preceding them with `$`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，代码示例通常需要键入到脚本文件中。因此，它们不会显示`>>>`标记。应该在shell中输入的命令会以美元符号（`$`）作为前缀。
- en: 'A task could be "call double with argument 3". Another task would be "call
    double with argument 642.34". Using jug, we can build these tasks as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一个任务可以是“调用double，参数为3”。另一个任务可以是“调用double，参数为642.34”。使用jug，我们可以按如下方式构建这些任务：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Save this to a file called `jugfile.py` (which is just a regular Python file).
    Now, we can run `jug execute` to run the tasks. This is something you type on
    the command line, not at the Python prompt, so we show it marked with a dollar
    sign (`$`):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 将其保存为名为`jugfile.py`的文件（这只是一个常规的Python文件）。现在，我们可以运行`jug execute`来执行这些任务。这是你在命令行中输入的，而不是在Python提示符下输入的，因此我们用美元符号（`$`）标记它：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You will also get some feedback on the tasks (jug will say that two tasks named
    `double` were run). Run `jug execute` again and it will tell you that it did nothing!
    It does not need to. In this case, we gained little, but if the tasks took a long
    time to compute, it would have been very useful.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你还会收到一些关于任务的反馈（jug会显示两个名为`double`的任务被执行）。再次运行`jug execute`，它会告诉你它什么也没做！其实它不需要做任何事情。在这种情况下，我们并没有获得太多收益，但如果任务计算时间很长，这个缓存将非常有用。
- en: You may notice that a new directory also appeared on your hard drive named `jugfile.jugdata`
    with a few weirdly named files. This is the memoization cache. If you remove it,
    `jug execute` will run all your tasks again.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，在硬盘上出现了一个名为`jugfile.jugdata`的新目录，并且里面有一些奇怪命名的文件。这是记忆化缓存。如果你删除它，`jug
    execute`将会重新运行所有任务。
- en: Often, it's good to distinguish between pure functions, which simply take their
    inputs and return a result, from more general functions that can perform actions
    (such as reading from files, writing to files, accessing global variables, modify
    their arguments, or anything that the language allows). Some programming languages,
    such as Haskell, even have syntactic ways to distinguish pure from impure functions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，区分纯函数和更一般的函数是有益的，纯函数只是接受输入并返回结果，而一般函数可以执行一些动作（例如从文件中读取、写入文件、访问全局变量、修改其参数，或任何该语言允许的操作）。一些编程语言，比如Haskell，甚至有语法方法来区分纯函数和不纯函数。
- en: 'With jug, your tasks do not need to be perfectly pure. It''s even recommended
    that you use tasks to read in your data or write out your results. However, accessing
    and modifying global variables will not work well: the tasks may be run in any
    order in different processors. The exceptions are global constants, but even this
    may confuse the memoization system (if the value is changed between runs). Similarly,
    you should not modify the input values. Jug has a debug mode (use `jug execute
    --debug`), which slows down your computation, but will give you useful error messages
    if you make this sort of mistake.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用jug时，你的任务不需要完全纯粹。甚至建议你使用任务来读取数据或写入结果。然而，访问和修改全局变量将不能很好地工作：任务可能在不同的处理器上以任何顺序执行。全局常量除外，但即使是常量，也可能会干扰记忆化系统（如果值在执行过程中发生变化）。类似地，你不应该修改输入值。jug有一个调试模式（使用`jug
    execute --debug`），虽然它会减慢计算速度，但如果你犯了类似的错误，它会给你有用的错误信息。
- en: 'The preceding code works, but is a bit cumbersome. You are always repeating
    the `Task(function, argument)` construct. Using a bit of Python magic, we can
    make the code even more natural as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码是有效的，但有些繁琐。你总是在重复使用`Task(function, argument)`这个构造。利用一些Python技巧，我们可以使代码看起来更加自然，如下所示：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Except for the use of `TaskGenerator`, the preceding code could be a standard
    Python file! However, using `TaskGenerator`, it actually creates a series of tasks
    and it is now possible to run it in a way that takes advantage of multiple processors.
    Behind the scenes, the decorator transforms your functions so that they do not
    actually execute when called, but create a `Task` object. We also take advantage
    of the fact that we can pass tasks to other tasks and this results in a dependency
    being generated.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用`TaskGenerator`，前面的代码实际上可以是一个标准的Python文件！然而，使用`TaskGenerator`，它实际上创建了一系列任务，现在可以以一种利用多个处理器的方式来运行它。在幕后，装饰器将你的函数转化为在调用时不执行，而是创建一个`Task`对象。我们还利用了可以将任务传递给其他任务的事实，这会生成一个依赖关系。
- en: You may have noticed that we added a few `sleep(4)` calls in the preceding code.
    This simulates running a long computation. Otherwise, this example is so fast
    that there is no point in using multiple processors.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，我们在前面的代码中添加了一些`sleep(4)`调用。这是为了模拟运行一个长时间的计算。否则，这个示例运行得非常快，根本没有使用多个处理器的必要。
- en: 'We start by running `jug status`, which results in the output shown in the
    following screenshot:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过运行`jug status`来开始，结果如下图所示：
- en: '![An introduction to tasks in jug](img/2772OS_12_10.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![任务在jug中的介绍](img/2772OS_12_10.jpg)'
- en: 'Now, we start two processes simultaneously (using the `&` operator in the background):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们同时启动两个进程（在后台使用`&`操作符）：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we run `jug status` again:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们再次运行`jug status`：
- en: '![An introduction to tasks in jug](img/2772OS_12_11.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![任务在jug中的介绍](img/2772OS_12_11.jpg)'
- en: We can see that the two initial double operators are running at the same time.
    After about 8 seconds, the whole process will finish and the `output.txt` file
    will be written.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，两个初始的双重操作符正在同时运行。大约8秒后，整个过程将完成，`output.txt` 文件将被写入。
- en: 'By the way, if your file was called anything other than `jugfile.py`, you would
    then have to specify it explicitly on the command line. For example, if your file
    was called `analysis.py`, you would run the following command:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，如果你的文件名不是`jugfile.py`，你就需要在命令行上显式指定它。例如，如果你的文件名是`analysis.py`，你应该运行以下命令：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This is the only disadvantage of not using the name `jugfile.py`. So, feel free
    to use more meaningful names.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是不使用`jugfile.py`名称的唯一缺点。所以，尽管使用更有意义的名称吧。
- en: Looking under the hood
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看引擎盖下
- en: How does jug work? At the basic level, it's very simple. A `Task` is a function
    plus its argument. Its arguments may be either values or other tasks. If a task
    takes other tasks, there is a dependency between the two tasks (and the second
    one cannot be run until the results of the first task are available).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: jug是如何工作的？从基本层面上来说，它非常简单。一个`Task`是一个函数加上它的参数。它的参数可以是值，也可以是其他任务。如果一个任务依赖于其他任务，那么这两个任务之间就有了依赖关系（并且第二个任务在第一个任务的结果可用之前无法运行）。
- en: 'Based on this, jug recursively computes a hash for each task. This hash value
    encodes the whole computation to get the result. When you run `jug execute`, for
    each task, there is a little loop that runs the logic depicted in the following
    flowchart:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，jug会递归地计算每个任务的哈希值。这个哈希值编码了整个计算过程，以获得结果。当你运行`jug execute`时，对于每个任务，会有一个小循环执行以下流程图中展示的逻辑：
- en: '![Looking under the hood](img/2772OS_12_12.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![查看引擎盖下](img/2772OS_12_12.jpg)'
- en: The default backend writes the file to disk (in this funny directory named `jugfile.jugdata/`).
    Another backend is available, which uses a Redis database. With proper locking,
    which jug takes care of, this also allows for many processors to execute tasks;
    each process will independently look at all the tasks and run the ones that have
    not run yet and then write them back to the shared backend. This works on either
    the same machine (using multicore processors) or in multiple machines as long
    as they all have access to the same backend (for example, using a network disk
    or the Redis databases). In the second half of this chapter, we will discuss computer
    clusters, but for now let's focus on multiple cores.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的后端将文件写入磁盘（在这个名为`jugfile.jugdata/`的有趣目录中）。另外，还有一个后端可用，使用Redis数据库。通过适当的锁定，jug会处理这个问题，这也允许多个处理器执行任务；每个进程将独立查看所有任务，并运行那些尚未执行的任务，然后将它们写回共享的后端。这在同一台机器（使用多核处理器）或多台机器上都可以运行，只要它们都能访问相同的后端（例如，使用网络磁盘或Redis数据库）。在本章的后半部分，我们将讨论计算机集群，但现在我们先专注于多个核心。
- en: You can also understand why it's able to memoize intermediate results. If the
    backend already has the result of a task, it's not run again. On the other hand,
    if you change the task, even in minute ways (by altering one of the parameters),
    its hash will change. Therefore, it will be rerun. Furthermore, all tasks that
    depend on it will also have their hashes changed and they will be rerun as well.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以理解为什么它能够记忆中间结果。如果后端已经有某个任务的结果，它就不会再执行。如果你更改了任务，即使是微小的更改（例如修改了某个参数），其哈希值也会改变。因此，任务会被重新执行。此外，所有依赖于该任务的任务也会改变它们的哈希值，并且会被重新执行。
- en: Using jug for data analysis
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用jug进行数据分析
- en: Jug is a generic framework, but it's ideally suited for medium-scale data analysis.
    As you develop your analysis pipeline, it's good to have intermediate results
    automatically saved. If you have already computed the preprocessing step before
    and are only changing the features you compute, you do not want to recompute the
    preprocessing step. If you have already computed the features, but want to try
    combining a few new ones into the mix, you also do not want to recompute all your
    other features.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Jug是一个通用框架，但它非常适合中等规模的数据分析。在开发分析管道时，最好让中间结果自动保存。如果你之前已经计算过预处理步骤，并且只是在更改计算的特征，你就不希望重新计算预处理步骤。如果你已经计算过特征，但希望尝试将一些新的特征组合起来，你也不希望重新计算所有其他特征。
- en: Jug is also specifically optimized to work with NumPy arrays. Whenever your
    tasks return or receive NumPy arrays, you are taking advantage of this optimization.
    Jug is another piece of this ecosystem where everything works together.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Jug还特别优化了与NumPy数组的协作。每当你的任务返回或接收NumPy数组时，你就利用了这种优化。Jug是这个生态系统中的另一部分，所有内容都在一起工作。
- en: 'We will now look back at [Chapter 10](ch10.html "Chapter 10. Computer Vision"),
    *Computer Vision*. In that chapter, we learned how to compute features on images.
    Remember that the basic pipeline consisted of the following features:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们回顾一下[第10章](ch10.html "第10章. 计算机视觉")，*计算机视觉*。在那一章中，我们学习了如何计算图像的特征。记住，基本管道包括以下特征：
- en: Loading image files
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载图像文件
- en: Computing features
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算特征
- en: Combining these features
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合并这些特征
- en: Normalizing the features
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 归一化特征
- en: Creating a classifier
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建分类器
- en: We are going to redo this exercise, but this time with the use of jug. The advantage
    of this version is that it's now possible to add a new feature or classifier without
    having to recompute all of the pipeline.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重新进行这个练习，但这次将使用jug。这个版本的优势在于，现在可以在不需要重新计算整个管道的情况下，添加新的特征或分类器。
- en: 'We start with a few imports as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先进行以下几个导入：
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we define the first task generators and feature computation functions:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们定义第一个任务生成器和特征计算函数：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `features` module we import is the one from [Chapter 10](ch10.html "Chapter 10. Computer
    Vision"), *Computer Vision*.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入的`features`模块来自[第10章](ch10.html "第10章. 计算机视觉")，*计算机视觉*。
- en: Note
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: We write functions that take the filename as input instead of the image array.
    Using the full images would also work, of course, but this is a small optimization.
    A filename is a string, which is small if it gets written to the backend. It's
    also very fast to compute a hash if needed. It also ensures that the images are
    only loaded by the processes that need them.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编写的函数将文件名作为输入，而不是图像数组。当然，使用完整的图像也是可行的，但这是一个小的优化。文件名是字符串，在写入后端时相对较小。如果需要计算哈希值，也非常快速。此外，这样可以确保只有需要图像的进程才会加载它们。
- en: 'We can use `TaskGenerator` on any function. This is true even for functions,
    which we did not write, such as `np.array`, `np.hstack`, or the following command:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在任何函数上使用`TaskGenerator`。即使是我们没有编写的函数，例如`np.array`、`np.hstack`，或者下面的命令，这也成立：
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: One small inconvenience of using jug is that we must always write functions
    to output the results to files, as shown in the preceding examples. This is a
    small price to pay for the extra convenience of using jug.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用jug的一个小不便之处是，我们必须始终编写函数将结果输出到文件，如前面的示例所示。这是使用jug的额外便利性所付出的一个小代价。
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Note that we are only importing `sklearn` inside this function. This is a small
    optimization. This way, `sklearn` is only imported when it''s really needed:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们仅在此函数内部导入`sklearn`。这是一个小优化。这样，只有在真正需要时，`sklearn`才会被导入：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, we write and call a function to print out all results. It expects
    its argument to be a list of pairs with the name of the algorithm and the results:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们编写并调用一个函数来输出所有结果。它期望其参数是一个包含算法名称和结果的对列表：
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'That''s it. Now, on the shell, run the following command to run this pipeline
    using jug:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。现在，在 shell 中运行以下命令，通过 jug 运行这个管道：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Reusing partial results
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复用部分结果
- en: For example, let's say you want to add a new feature (or even a set of features).
    As we saw in [Chapter 10](ch10.html "Chapter 10. Computer Vision"), *Computer
    Vision*, this is easy to do by changing the feature computation code. However,
    this would imply recomputing all the features again, which is wasteful, particularly,
    if you want to test new features and techniques quickly.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你想添加一个新功能（甚至是一组功能）。正如我们在[第10章](ch10.html "第10章。计算机视觉")中看到的，*计算机视觉*，通过更改特征计算代码是很容易做到的。然而，这将意味着需要重新计算所有特征，这样是浪费的，尤其是当你想快速测试新特征和技术时。
- en: 'We now add a set of features, that is, another type of texture feature called
    linear binary patterns. This is implemented in mahotas; we just need to call a
    function, but we wrap it in `TaskGenerator`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在添加一组特征，也就是另一种叫做线性二值模式的纹理特征。这在 mahotas 中已实现；我们只需要调用一个函数，但我们将其封装在 `TaskGenerator`
    中：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We replace the previous loop to have an extra function call:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们替换了之前的循环，增加了一个额外的函数调用：
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We call accuracy with these newer features:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这些较新的特征来计算准确度：
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now, when you run `jug execute` again, the new features will be computed, but
    the old features will be loaded from the cache. This is when jug can be very powerful.
    It ensures that you always get the results you want while saving you from unnecessarily
    recomputing cached results. You will also see that adding this feature set improves
    on the previous methods.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当你再次运行 `jug execute` 时，新的特征将被计算出来，但旧的特征将从缓存中加载。这就是 jug 强大的地方。它确保你始终得到你想要的结果，同时避免不必要地重新计算缓存的结果。你还会看到，添加这组特征集改善了之前的方法。
- en: 'Not all features of jug could be mentioned in this chapter, but here is a summary
    of the most potentially interesting ones we didn''t cover in the main text:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 本章未能提及 jug 的所有功能，但以下是我们未在正文中涵盖的一些可能感兴趣的功能总结：
- en: '`jug invalidate`: This declares that all results from a given function should
    be considered invalid and in need of recomputation. This will also recompute any
    downstream computation, which depended (even indirectly) on the invalidated results.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jug invalidate`：这声明给定函数的所有结果应被视为无效，并需要重新计算。这还将重新计算任何依赖于（即使是间接依赖）无效结果的下游计算。'
- en: '`jug status --cache`: If `jug status` takes too long, you can use the `--cache`
    flag to cache the status and speed it up. Note that this will not detect any changes
    to the jugfile, but you can always use `--cache --clear` to remove the cache and
    start again.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jug status --cache`：如果 `jug status` 运行时间过长，你可以使用 `--cache` 标志来缓存状态并加快速度。请注意，这不会检测
    jugfile 的任何更改，但你可以随时使用 `--cache --clear` 来清除缓存并重新开始。'
- en: '`jug cleanup`: This removes any extra files in the memoization cache. This
    is a garbage collection operation.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jug cleanup`：这将删除备忘缓存中的所有额外文件。这是一个垃圾回收操作。'
- en: Note
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: There are other, more advanced features, which allow you to look at values that
    have been computed inside the jugfile. Read up on features such as barriers in
    the jug documentation online at [http://jug.rtfd.org](http://jug.rtfd.org).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他更高级的功能，允许你查看在 jugfile 内部已计算的值。请阅读 jug 文档中的有关屏障等功能，网址为 [http://jug.rtfd.org](http://jug.rtfd.org)。
- en: Using Amazon Web Services
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用亚马逊 Web 服务
- en: When you have a lot of data and a lot of computation to be performed, you might
    start to crave more computing power. Amazon ([http://aws.amazon.com](http://aws.amazon.com))
    allows you to rent computing power by the hour. Thus, you can access a large amount
    of computing power without having to precommit by purchasing a large number of
    machines (including the costs of managing the infrastructure). There are other
    competitors in this market, but Amazon is the largest player, so we briefly cover
    it here.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有大量数据和大量计算需要执行时，你可能会开始渴望更多的计算能力。亚马逊（[http://aws.amazon.com](http://aws.amazon.com)）允许你按小时租用计算能力。这样，你可以在不需要提前购买大量机器（包括管理基础设施成本）的情况下，访问大量的计算能力。市场上还有其他竞争者，但亚马逊是最大的玩家，因此我们在此简单介绍。
- en: '**Amazon Web Services** (**AWS**) is a large set of services. We will focus
    only on the **Elastic Compute Cloud** (**EC2**) service. This service offers you
    virtual machines and disk space, which can be allocated and deallocated quickly.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**亚马逊网络服务**（**AWS**）是一个大型服务集。我们将只关注**弹性计算云**（**EC2**）服务。此服务为您提供虚拟机和磁盘空间，可以快速分配和释放。'
- en: There are three modes of use. First is a reserved mode, whereby you prepay to
    have cheaper per-hour access, a fixed per-hour rate, and a variable rate, which
    depends on the overall compute market (when there is less demand, the costs are
    lower; when there is more demand, the prices go up).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用有三种模式。第一种是预留模式，您通过预付费获得更便宜的每小时访问费用，固定的每小时费用，以及一个变化的费用，这取决于整体计算市场（当需求较少时，费用较低；当需求较多时，价格会上涨）。
- en: On top of this general system, there are several types of machines available
    with varying costs, from a single core to a multicore system with a lot of RAM
    or even graphical processing units (GPUs). We will later see that you can also
    get several of the cheaper machines and build yourself a virtual cluster. You
    can also choose to get a Linux or Windows server (with Linux being slightly cheaper).
    In this chapter, we will work on our examples on Linux, but most of this information
    will be valid for Windows machines as well.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个通用系统的基础上，有几种不同类型的机器可供选择，成本各异，从单核到具有大量内存或甚至图形处理单元（GPU）的多核系统。稍后我们会看到，您还可以获取几台较便宜的机器并构建一个虚拟集群。您还可以选择获取Linux或Windows服务器（Linux略便宜）。在本章中，我们将在Linux上操作示例，但大部分信息对于Windows机器同样适用。
- en: For testing, you can use a single machine in the **free tier**. This allows
    you to play around with the system, get used to the interface, and so on. Note,
    though, that this machine contains a slow CPU.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于测试，您可以使用**免费层**中的单台机器。这允许您操作系统，熟悉界面等。请注意，这台机器的CPU较慢。
- en: The resources can be managed through a web interface. However, it's also possible
    to do so programmatically and to write scripts that allocate virtual machines,
    format hard disks, and perform all operations that are possible through the web
    interface. In fact, while the web interface changes very frequently (and some
    of the screenshots we show in the book may be out of date by the time it goes
    to press), the programmatic interface is more stable and the general architecture
    has remained stable since the service was introduced.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 资源可以通过网页界面进行管理。但是，也可以通过编程方式进行管理，并编写脚本来分配虚拟机、格式化硬盘并执行所有通过网页界面可能执行的操作。事实上，虽然网页界面变化频繁（本书中展示的一些截图可能在出版时已经过时），但编程接口更加稳定，且自服务推出以来，整体架构保持稳定。
- en: Access to AWS services is performed through a traditional username/password
    system, although Amazon calls the username an *access key* and the password a
    *secret key*. They probably do so to keep it separate from the username/password
    you use to access the web interface. In fact, you can create as many access/secret
    key pairs as you wish and give them different permissions. This is helpful for
    a larger team where a senior user with access to the full web panel can create
    other keys for developers with fewer privileges.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 访问AWS服务通过传统的用户名/密码系统进行，尽管亚马逊将用户名称为*访问密钥*，密码称为*秘密密钥*。他们这样做可能是为了将其与用于访问网页界面的用户名/密码分开。事实上，您可以创建任意多的访问/秘密密钥对，并为其分配不同的权限。这对于较大的团队非常有帮助，团队中的高级用户可以访问完整的网页面板，进而为权限较少的开发人员创建其他密钥。
- en: Note
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Amazon.com has several regions. These correspond to physical regions of the
    world: West coast US, East coast US, several Asian locations, a South American
    one, and two European ones. If you will be transferring data, it''s best to keep
    it close to where you will be transferring to and from. Additionally, keep in
    mind that if you are handling user information, there may be regulatory issues
    regulating their transfer to another jurisdiction. In this case, do check with
    an informed counsel on the implications of transferring data about European customers
    to the US or any other similar transfer.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊公司有多个区域。这些区域对应世界上的物理位置：美国西海岸、美国东海岸、几个亚洲位置、一个南美位置以及两个欧洲位置。如果您要传输数据，最好将数据保持在接收和发送的地方附近。此外，请记住，如果您处理用户信息，可能会有关于将数据传输到另一个司法管辖区的监管问题。在这种情况下，请咨询一位知情的律师，了解将关于欧洲客户的数据传输到美国或其他类似的转移所涉及的法律问题。
- en: Amazon Web Services is a very large topic and there are various books exclusively
    available to cover AWS. The purpose of this chapter is to give you an overall
    impression of what is available and what is possible with AWS. In the practical
    spirit of this book, we do this by working through examples, but we will not exhaust
    all possibilities.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊云服务是一个非常庞大的话题，专门覆盖AWS的书籍有很多。本章的目的是让你对AWS所提供的服务和可能实现的功能有一个整体印象。本书的实践精神就是通过示例来实现这一目标，但我们并不会涵盖所有可能性。
- en: Creating your first virtual machines
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建你的第一个虚拟机
- en: The first step is to go to [http://aws.amazon.com/](http://aws.amazon.com/)
    and create an account. These steps are similar to any other online service. A
    single machine is free, but to get more, you will need a credit card. In this
    example, we will use a few machines, so it may cost you a few dollars if you want
    to run through it. If you are not ready to take out a credit card just yet, you
    can certainly read the chapter to learn what AWS provides without going through
    the examples. Then you can make a more informed decision on whether to sign up.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是访问[http://aws.amazon.com/](http://aws.amazon.com/)并创建一个账户。这些步骤与任何其他在线服务相似。一个机器是免费的，但如果你需要更多的机器，你将需要一张信用卡。在本示例中，我们将使用几台机器，因此如果你想跟着做，可能会花费你一些费用。如果你还不准备提供信用卡，你当然可以先阅读这一章，了解AWS提供的服务，而不需要亲自操作示例。然后你可以做出更有信息的决定，看看是否注册。
- en: 'Once you sign up for AWS and log in, you will be taken to the console. Here,
    you will see the many services that AWS provides, as depicted in the following
    screenshot:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你注册AWS并登录，你将进入控制台。在这里，你将看到AWS提供的众多服务，如下图所示：
- en: '![Creating your first virtual machines](img/2772OS_12_01.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![创建你的第一个虚拟机](img/2772OS_12_01.jpg)'
- en: 'We pick and click on **EC2** (the top element on the leftmost column—this is
    the panel shown as it was when this book was written. Amazon regularly makes minor
    changes, so you may see something slightly different from what we present in the
    book). We now see the EC2 management console, as shown in the following screenshot:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择并点击**EC2**（左侧栏中最顶部的元素——这是本书写作时显示的面板。亚马逊会定期进行小的更改，所以你看到的可能与我们书中的稍有不同）。现在我们看到了EC2管理控制台，如下图所示：
- en: '![Creating your first virtual machines](img/2772OS_12_02.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![创建你的第一个虚拟机](img/2772OS_12_02.jpg)'
- en: In the top-right corner, you can pick your region (see the Amazon regions information
    box). Note that *you will only see information about the region that you have
    selected at the moment*. Thus, if you mistakenly select the wrong region (or have
    machines running in multiple regions), your machines may not appear (this seems
    to be a common pitfall of using the EC2 web management console).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在右上角，你可以选择你的区域（请参见亚马逊区域信息框）。注意，*你只会看到你当前选择的区域的信息*。因此，如果你错误地选择了错误的区域（或者有多个区域的机器在运行），你的机器可能不会出现（这似乎是使用EC2网页管理控制台时常见的陷阱）。
- en: 'In EC2 parlance, a running server is called an **instance**. We select **Launch
    Instance**, which leads to the following screen asking us to select the operating
    system to use:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在EC2术语中，正在运行的服务器称为**实例**。我们选择**启动实例**，这将进入下一个屏幕，要求我们选择要使用的操作系统：
- en: '![Creating your first virtual machines](img/2772OS_12_03.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![创建你的第一个虚拟机](img/2772OS_12_03.jpg)'
- en: 'Select the **Amazon Linux** option (if you are familiar with one of the other
    offered Linux distributions, such as Red Hat, SUSE, or Ubuntu, you can also select
    one of these, but the configurations will be slightly different). Now that you
    have selected the software, you will need to select the hardware. In the next
    screen, you will be asked to select which type of machine to use:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 选择**Amazon Linux**选项（如果你熟悉其他提供的Linux发行版，比如Red Hat、SUSE或Ubuntu，你也可以选择其中一个，但配置会有所不同）。现在你已经选择了软件，接下来需要选择硬件。在下一个屏幕中，你将被要求选择要使用的机器类型：
- en: '![Creating your first virtual machines](img/2772OS_12_04.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![创建你的第一个虚拟机](img/2772OS_12_04.jpg)'
- en: 'We will start with one instance of the **t2.micro** type (the **t1.micro**
    type was an older, even less powerful machine). This is the smallest possible
    machine and it''s free. Keep clicking on **Next** and accept all of the defaults
    until you come to the screen mentioning a key pair:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个**t2.micro**类型的实例开始（**t1.micro**类型是较老的、性能更弱的机器）。这是最小的机器，并且是免费的。不断点击**下一步**并接受所有默认设置，直到你看到提到密钥对的屏幕：
- en: '![Creating your first virtual machines](img/2772OS_12_06.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![创建你的第一个虚拟机](img/2772OS_12_06.jpg)'
- en: We will pick the name `awskeys` for the key pair. Then check **Create a new
    key pair**. Name the key pair file `awskeys.pem`. Download and save this file
    somewhere safe! This is the SSH (Secure Shell) key that will enable you to log
    in to your cloud machine. Accept the remaining defaults and your instance will
    launch.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为密钥对选择 `awskeys` 这个名字。然后勾选 **Create a new key pair**。将密钥对文件命名为 `awskeys.pem`。下载并将此文件保存在一个安全的位置！这是
    SSH（安全外壳）密钥，允许您登录到云端机器。接受其余默认设置，您的实例将会启动。
- en: 'You will now need to wait a few minutes for your instance to come up. Eventually,
    the instance will be shown in green with the status as **running**:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您需要等待几分钟，直到您的实例启动完成。最终，实例将显示为绿色，并且状态为 **running**：
- en: '![Creating your first virtual machines](img/2772OS_12_08.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![创建您的第一个虚拟机](img/2772OS_12_08.jpg)'
- en: 'In the preceding screenshot, you should see the Public IP which can be used
    to log in to the instance as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，您应该能看到公共 IP 地址，可以用来登录实例，具体如下：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Therefore, we will be calling the `ssh` command and passing it the key files
    that we downloaded earlier as the identity (using the `-i` option). We are logging
    in as user `ec2-user` at the machine with the IP address as 54.93.165.5\. This
    address will, of course, be different in your case. If you choose another distribution
    for your instance, the username may also change. In this case, try logging in
    as `root`, `ubuntu` (for Ubuntu distribution), or `fedora` (for fedora distribution).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将调用 `ssh` 命令，并将之前下载的密钥文件作为身份验证文件传递给它（使用 `-i` 选项）。我们作为 `ec2-user` 用户，登录到
    IP 地址为 54.93.165.5 的机器。这个地址在您的情况下当然会有所不同。如果您为实例选择了其他发行版，用户名也可能会变化。在这种情况下，您可以尝试以
    `root`、`ubuntu`（对于 Ubuntu 发行版）或 `fedora`（对于 Fedora 发行版）登录。
- en: 'Finally, if you are running a Unix-style operating system (including Mac OS),
    you may have to tweak its permissions by calling the following command:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您正在运行 Unix 风格的操作系统（包括 macOS），您可能需要通过以下命令调整其权限：
- en: '[PRE17]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This sets the read/write permission for the current user only. SSH will otherwise
    give you an ugly warning.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这仅为当前用户设置读写权限。否则，SSH 会给您一个丑陋的警告。
- en: 'Now you should be able to log in to your machine. If everything is okay, you
    should see the banner, as shown in the following screenshot:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您应该能够登录到您的机器。如果一切正常，您应该能看到如下面截图所示的横幅：
- en: '![Creating your first virtual machines](img/2772OS_12_09.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![创建您的第一个虚拟机](img/2772OS_12_09.jpg)'
- en: 'This is a regular Linux box where you have `sudo` permission: you can run any
    command as the superuser by prefixing it with `sudo`. You can run the `update`
    command it recommends to get your machine up to speed.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个常规的 Linux 机器，您拥有 `sudo` 权限：通过在命令前加上 `sudo`，您可以以超级用户身份运行任何命令。您可以运行系统推荐的 `update`
    命令来让您的机器保持最新状态。
- en: Installing Python packages on Amazon Linux
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Amazon Linux 上安装 Python 包
- en: 'If you prefer another distribution, you can use your knowledge of that distribution
    to install Python, NumPy, and others. Here, we will do it on the standard Amazon
    distribution. We start by installing several basic Python packages as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您更喜欢其他发行版，您可以利用您对该发行版的了解来安装 Python、NumPy 等包。在这里，我们将在标准的 Amazon 发行版上进行操作。我们首先安装几个基本的
    Python 包，具体如下：
- en: '[PRE18]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To compile mahotas, we will also need a C++ compiler:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了编译 mahotas，我们还需要一个 C++ 编译器：
- en: '[PRE19]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Finally, we install `git` to make sure that we can get the latest version of
    the code for the book:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们安装 `git`，以确保能够获取到本书的最新代码：
- en: '[PRE20]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In this system, pip is installed as `python-pip`. For convenience, we will
    use pip to upgrade itself. We will then use pip to install the necessary packages
    as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在该系统中，pip 被安装为 `python-pip`。为了方便起见，我们将使用 pip 升级它自身。然后，我们将使用 pip 安装必要的包，具体如下：
- en: '[PRE21]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: At this point, you can install any other package you wish using pip.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您可以使用 pip 安装任何其他您希望安装的包。
- en: Running jug on our cloud machine
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在我们的云机器上运行 jug
- en: 'We can now download the data and code for the book using this sequence of commands:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用以下命令序列来下载本书的数据和代码：
- en: '[PRE22]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, we run this following command:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们运行以下命令：
- en: '[PRE23]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This would work just fine, but we would have to wait a long time for the results.
    Our free tier machine (of type t2.micro) is not very fast and only has a single
    processor. So, we will *upgrade our machine*!
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以正常工作，但我们将不得不等待很长时间才能看到结果。我们的免费级别机器（t2.micro 类型）速度较慢，且仅有一个处理器。因此，我们将 *升级我们的机器*！
- en: We go back to the EC2 console, and right-click on the running instance to get
    the pop-up menu. We need to first stop the instance. This is the virtual machine
    equivalent to powering off. You can stop your machines at any time. At this point,
    you stop paying for them. Note that you are still using disk space, which also
    has a cost, billed separately. You can terminate the instance, which will also
    destroy the disk. This loses any information saved on the machine.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们返回到 EC2 控制台，右键单击正在运行的实例以获得弹出菜单。我们需要首先停止该实例。这相当于关闭虚拟机。你可以随时停止你的机器，停止后就不再为其付费。请注意，你仍在使用磁盘空间，这部分会单独计费。你也可以终止实例，这样会销毁磁盘，丢失机器上保存的所有信息。
- en: Once the machine is stopped, the **Change instance type** option becomes available.
    Now, we can select a more powerful instance, for example, a **c1.xlarge** instance
    with eight cores. The machine is still off, so you need to start it again (the
    virtual equivalent to booting up).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦机器停止，**更改实例类型** 选项将变得可用。现在，我们可以选择一个更强大的实例，例如具有八个核心的 **c1.xlarge** 实例。机器仍然是关闭的，所以你需要重新启动它（相当于虚拟机的开机）。
- en: Tip
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: AWS offers several instance types at different price points. As this information
    is constantly being revised as more powerful options are introduced and prices
    change (generally, getting cheaper), we cannot give you many details in the book,
    but you can find the most up-to-date information on Amazon's website.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 提供了几种不同价格的实例类型。由于这些信息会随着更强大的选项引入和价格变化（通常是变便宜）而不断更新，我们无法在书中提供太多细节，但你可以在 Amazon
    网站上找到最新的信息。
- en: We need to wait for the instance to come back up. Once it has, look up its IP
    address in the same fashion as we did before. When you change instance types,
    your instance will get a new address assigned to it.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要等待实例重新启动。一旦它恢复，按照之前的方式查找其 IP 地址。当你更改实例类型时，实例会被分配一个新的地址。
- en: Tip
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: You can assign a fixed IP to an instance using Amazon.com's Elastic IPs functionality,
    which you will find on the left-hand side of the EC2 console. This is useful if
    you find yourself creating and modifying instances very often. There is a small
    cost associated with this feature.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 Amazon.com 的弹性 IP 功能为实例分配固定 IP，弹性 IP 在 EC2 控制台的左侧可以找到。如果你经常创建和修改实例，这会非常有用。使用该功能会有少量费用。
- en: 'With eight cores, you can run eight jug processes simultaneously, as illustrated
    in the following code:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有八个核心，你可以同时运行八个 jug 进程，如下面的代码所示：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Use `jug status` to check whether these eight jobs are, in fact, running. After
    your jobs are finished (which should now happen pretty fast), you can stop the
    machine and downgrade it again to a **t2.micro** instance to save money. The micro
    instance can be used for free (within certain limits), while the **c1.xlarge**
    one we used costs 0.064 US dollars per hour (as of February 2015—check the AWS
    website for up-to-date information).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `jug status` 检查这八个任务是否正在运行。任务完成后（这应该会很快），你可以停止机器并将其降级回 **t2.micro** 实例以节省费用。微型实例可以免费使用（在某些限制范围内），而我们使用的
    **c1.xlarge** 实例则需要每小时 0.064 美元（截至 2015 年 2 月—请查阅 AWS 网站获取最新信息）。
- en: Automating the generation of clusters with StarCluster
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 StarCluster 自动生成集群
- en: As we just learned, we can spawn machines using the web interface, but it quickly
    becomes tedious and error prone. Fortunately, Amazon has an API. This means that
    we can write scripts, which perform all the operations we discussed earlier, automatically.
    Even better, others have already developed tools that can be used to mechanize
    and automate many of the processes you want to perform with AWS.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们刚刚学到的，我们可以使用 Web 界面创建机器，但这很快变得乏味且容易出错。幸运的是，Amazon 提供了一个 API。这意味着我们可以编写脚本，自动执行我们之前讨论的所有操作。更好的是，其他人已经开发了工具，可以用来机制化并自动化你想要在
    AWS 上执行的许多流程。
- en: 'A group at MIT developed exactly such a tool called StarCluster. It happens
    to be a Python package, so you can install it with Python tools as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 麻省理工学院的一个小组开发了这样一个工具，名为 StarCluster。它恰好是一个 Python 包，所以你可以使用 Python 工具按照如下方式安装它：
- en: '[PRE25]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: You can run this from an Amazon machine or from your local machine. Either option
    will work.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从 Amazon 机器或本地机器上运行此操作。两种选择都可以使用。
- en: 'We will need to specify what our cluster will look like. We do so by editing
    a configuration file. We generate a template configuration file by running the
    following command:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要指定集群的配置。我们通过编辑配置文件来实现这一点。我们通过运行以下命令生成模板配置文件：
- en: '[PRE26]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Then pick the option of generating the configuration file in `~/.starcluster/config`.
    Once this is done, we will manually edit it.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然后选择在`~/.starcluster/config`中生成配置文件的选项。完成后，我们将手动编辑它。
- en: Tip
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Keys, keys, and more keys**'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**密钥，密钥，再来一点密钥**'
- en: There are three completely different types of keys that are important when dealing
    with AWS. First, there is a standard username/password combination, which you
    use to log in to the website. Second, there is the SSH key system, which is a
    public/private key system implemented with files; with your public key file, you
    can log in to remote machines. Third, there is the AWS access key/secret key system,
    which is just a form of username/password that allows you to have multiple users
    on the same account (including adding different permissions to each one, but we
    will not cover these advanced features in this book).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理AWS时，有三种完全不同类型的密钥非常重要。首先是标准的用户名/密码组合，用于登录网站。其次是SSH密钥系统，它是一个通过文件实现的公钥/私钥系统；通过公钥文件，您可以登录远程机器。第三是AWS访问密钥/秘密密钥系统，它只是一个用户名/密码的形式，允许您在同一账户中拥有多个用户（包括为每个用户添加不同的权限，但本书不涉及这些高级功能）。
- en: To look up our access/secret keys, we go back to the AWS Console, click on our
    name on the top-right, and select **Security Credentials**. Now at the bottom
    of the screen, there should be our access key, which may look something like **AAKIIT7HHF6IUSN3OCAA**,
    which we will use as an example in this chapter.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要查找我们的访问/密钥，返回AWS控制台，点击右上角的用户名，选择**安全凭证**。现在在屏幕底部应该会看到我们的访问密钥，它可能类似于**AAKIIT7HHF6IUSN3OCAA**，我们将在本章中使用它作为示例。
- en: 'Now, edit the configuration file. This is a standard `.ini` file: a text file
    where sections start by having their names in brackets and options are specified
    in the `name=value` format. The first section is the `aws info` section and you
    should copy and paste your keys here:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，编辑配置文件。这是一个标准的`.ini`文件：一个文本文件，其中每个部分以括号中的名称开始，选项则以`name=value`格式指定。第一个部分是`aws
    info`部分，您需要将密钥复制并粘贴到这里：
- en: '[PRE27]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now we come to the fun part, that is, defining a cluster. StarCluster allows
    you to define as many different clusters as you wish. The starting file has one
    called smallcluster. It''s defined in the `cluster smallcluster` section. We will
    edit it to read as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是有趣的部分，即定义集群。StarCluster允许您根据需要定义任意多个集群。初始文件中有一个名为smallcluster的集群。它在`cluster
    smallcluster`部分中定义。我们将编辑它，使其如下所示：
- en: '[PRE28]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This changes the number of nodes to 16 instead of the default of two. We can
    additionally specify which type of instance each node will be and what the initial
    image is (remember, an image is used to initialized the virtual hard disk, which
    defines what operating system you will be running and what software is installed).
    StarCluster has a few predefined images, but you can also build your own.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把节点数从默认的两个节点更改为16个。我们还可以指定每个节点的实例类型，以及初始映像是什么（记住，映像用于初始化虚拟硬盘，它定义了您将运行的操作系统和已安装的软件）。StarCluster有一些预定义的映像，但您也可以自己创建。
- en: 'We need to create a new SSH key with the following command:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要使用以下命令创建一个新的SSH密钥：
- en: '[PRE29]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now that we have configured a sixteen node cluster and set up the keys, let''s
    try it out:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经配置了一个16节点的集群并设置了密钥，让我们试试：
- en: '[PRE30]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This may take a few minutes as it allocates seventeen new machines. Why seventeen
    when our cluster is only sixteen nodes? StarCluster always creates a master node.
    All of these nodes have the same filesystem, so anything we create on the master
    node will also be seen by the worker nodes. This also means that we can use jug
    on these clusters.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能需要几分钟，因为它会分配17台新机器。为什么是17台，而不是我们的集群只有16个节点？StarCluster始终会创建一个主节点。所有这些节点都共享相同的文件系统，因此我们在主节点上创建的任何内容都将被工作节点看到。这也意味着我们可以在这些集群上使用jug。
- en: 'These clusters can be used as you wish, but they come pre-equipped with a job
    queue engine, which makes it ideal for batch processing. The process of using
    them is simple:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这些集群可以按您的需求使用，但它们预先配备了一个作业队列引擎，这使得它们非常适合批处理。使用它们的过程非常简单：
- en: You log in to the master node.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您登录到主节点。
- en: You prepare your scripts on the master (or better yet, have them prepared before
    hand).
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您在主节点上准备脚本（或者更好的是，提前准备好它们）。
- en: You submit jobs to the queue. A job can be any Unix command. The scheduler will
    find free nodes and run your job.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将作业提交到队列中。作业可以是任何Unix命令。调度程序将寻找空闲节点并运行您的作业。
- en: You wait for the jobs to finish.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您等待作业完成。
- en: You read the results on the master node. You can also now kill all the slave
    nodes to save money. In any case, do not leave your system running when you do
    not need it anymore! Otherwise, this will cost you (in dollars-and-cents).
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以在主节点上读取结果。您现在也可以终止所有从节点以节省费用。无论如何，在您不再需要时不要让系统持续运行！否则，这将花费您（以美元和美分）。
- en: 'Before logging in to the cluster, we will copy our data to it (remember we
    had earlier cloned the repository onto `BuildingMachineLearningSystemsWithPython`):'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在登录到集群之前，我们将数据复制到其中（请记住，我们之前已经将存储库克隆到`BuildingMachineLearningSystemsWithPython`）：
- en: '[PRE31]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We used the `$dir` variable to make the command line fit in a single line.
    We can log in to the master node with a single command:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`$dir`变量使命令行适应单行。我们可以用一条命令登录到主节点：
- en: '[PRE32]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We could also have looked up the address of the machine that was generated and
    used an `ssh` command as we did earlier, but using the preceding command, it does
    not matter what the address was, as StarCluster takes care of it behind the scenes
    for us.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以查找生成的机器地址，并像之前那样使用`ssh`命令，但使用上述命令，无论地址是什么，StarCluster都会在幕后为我们处理它。
- en: As we said earlier, StarCluster provides a batch queuing system for its clusters;
    you write a script to perform your actions, put it on the queue, and it will run
    in any available node.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所说，StarCluster为其集群提供了批处理队列系统；您编写一个脚本来执行操作，将其放入队列，它将在任何可用节点上运行。
- en: 'At this point, we need to install some packages again. Fortunately, StarCluster
    has already done half the work. If this was a real project, we would set up a
    script to perform all the initialization for us. StarCluster can do this. As this
    is a tutorial, we just run the installation step again:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们需要再次安装一些包。幸运的是，StarCluster已经完成了一半的工作。如果这是一个真实的项目，我们将设置一个脚本来为我们执行所有的初始化工作。StarCluster可以做到这一点。由于这是一个教程，我们只需再次运行安装步骤：
- en: '[PRE33]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We can use the same jugfile system as before, except that now, instead of running
    it directly on the master, we schedule it on the cluster.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像以前一样使用相同的`jugfile`系统，只是现在，不再直接在主节点上运行，而是在集群上进行调度。
- en: 'First, write a very simple wrapper script as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，编写一个非常简单的包装脚本如下：
- en: '[PRE34]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Call it `run-jugfile.sh` and use `chmod +x run-jugfile.sh` to give it executable
    permission. Now, we can schedule sixteen jobs on the cluster by using the following
    command:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 将其命名为`run-jugfile.sh`并使用`chmod +x run-jugfile.sh`赋予它可执行权限。现在，我们可以使用以下命令在集群上安排十六个作业：
- en: '[PRE35]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This will create 16 jobs, each of which will run the `run-jugfile.sh` script,
    which we will simply call jug. You can still use the master as you wish. In particular,
    you can, at any moment, run `jug status` and see the status of the computation.
    In fact, jug was developed in exactly such an environment, so it works very well
    in it.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建16个作业，每个作业将运行`run-jugfile.sh`脚本，我们简称为jug。您仍然可以按照自己的意愿使用主节点。特别是，您随时可以运行`jug
    status`来查看计算的状态。事实上，jug就是在这样的环境中开发的，因此在这种环境中非常有效。
- en: 'Eventually, the computation will finish. At this point, we need to first save
    our results. Then, we can kill off all the nodes. We create a directory `~/results`
    and copy our results here:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，计算将完成。此时，我们需要首先保存结果。然后，我们可以终止所有节点。我们在`~/results`目录下创建一个目录，并将结果复制到此处：
- en: '[PRE36]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now, log off the cluster back to our worker machine:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，从集群注销回到我们的工作机器：
- en: '[PRE37]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, we are back at our AWS machine (notice the `$` sign in the next code examples).
    First, we copy the results back to this computer using the `starcluster get` command
    (which is the mirror image of `put` we used before):'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们回到我们的AWS机器（请注意下一个代码示例中的`$`符号）。首先，我们使用`starcluster get`命令将结果复制回这台计算机（这是我们之前使用`put`命令的镜像）：
- en: '[PRE38]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Finally, we should kill all the nodes to save money as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了节省费用，我们应该关闭所有节点如下：
- en: '[PRE39]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Note
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that terminating will really destroy the filesystem and all your results.
    In our case, we have copied the final results to safety manually. Another possibility
    is to have the cluster write to a filesystem, which is not allocated and destroyed
    by StarCluster, but is available to you on a regular instance; in fact, the flexibility
    of these tools is immense. However, these advanced manipulations could not all
    fit in this chapter.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，终止操作将真正销毁文件系统和所有结果。在我们的情况下，我们已经手动将最终结果复制到了安全位置。另一个可能性是让集群写入一个不被StarCluster分配和销毁的文件系统，但在常规实例上对您可用；事实上，这些工具的灵活性是巨大的。然而，这些高级操作不可能全部在本章中展示。
- en: StarCluster has excellent documentation online at [http://star.mit.edu/cluster/](http://star.mit.edu/cluster/),
    which you should read for more information about all the possibilities of this
    tool. We have seen only a small fraction of the functionality and used only the
    default settings here.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: StarCluster 在 [http://star.mit.edu/cluster/](http://star.mit.edu/cluster/) 上有出色的在线文档，你应该阅读以了解更多关于该工具的所有可能性。我们这里只展示了其功能的很小一部分，并且只使用了默认设置。
- en: Summary
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We saw how to use jug, a little Python framework to manage computations in a
    way that takes advantage of multiple cores or multiple machines. Although this
    framework is generic, it was built specifically to address the data analysis needs
    of its author (who is also an author of this book). Therefore, it has several
    aspects that make it fit in with the rest of the Python machine learning environment.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了如何使用 jug，一个小型 Python 框架来管理计算，以便利用多个核心或多台机器。虽然这个框架是通用的，但它是专门为其作者（本书的另一位作者）解决数据分析需求而构建的。因此，它有多个方面使其适配
    Python 机器学习环境。
- en: You also learned about AWS, the Amazon Cloud. Using cloud computing is often
    a more effective use of resources than building in-house computing capacity. This
    is particularly true if your needs are not constant and are changing. StarCluster
    even allows for clusters that automatically grow as you launch more jobs and shrink
    as they terminate.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 你还了解了 AWS，即亚马逊云。使用云计算通常比建设内部计算能力更有效，尤其是在需求不稳定且不断变化的情况下。StarCluster 甚至允许集群在你启动更多任务时自动扩展，在任务终止时自动缩减。
- en: This is the end of the book. We have come a long way. You learned how to perform
    classification when we labeled data and clustering when we do not. You learned
    about dimensionality reduction and topic modeling to make sense of large datasets.
    Towards the end, we looked at some specific applications (such as music genre
    classification and computer vision). For implementations, we relied on Python.
    This language has an increasingly expanding ecosystem of numeric computing packages
    built on top of NumPy. Whenever possible, we relied on scikit-learn, but used
    other packages when necessary. Due to the fact that they all use the same basic
    data structure (the NumPy multidimensional array), it's possible to mix functionality
    from different packages seamlessly. All of the packages used in this book are
    open source and available for use in any project.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 本书结束了。我们已经走过了很长的路。你学习了如何在标注数据时进行分类，在未标注数据时进行聚类。你了解了降维和主题建模，以便理解大数据集。接着，我们看了一些具体的应用（例如音乐流派分类和计算机视觉）。在实现中，我们依赖于
    Python 语言。该语言拥有一个越来越庞大的数值计算包生态，建立在 NumPy 基础上。只要可能，我们依赖于 scikit-learn，但在必要时也会使用其他包。由于这些包都使用相同的基本数据结构（NumPy
    多维数组），因此可以无缝地混合不同包的功能。本书中使用的所有包都是开源的，可以用于任何项目。
- en: Naturally, we did not cover every machine learning topic. In the Appendix, we
    provide pointers to a selection of other resources that will help interested readers
    learn more about machine learning.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，我们并没有涵盖所有机器学习话题。在附录中，我们提供了一些其他资源的指引，帮助感兴趣的读者进一步学习机器学习。
- en: Appendix A. Where to Learn More Machine Learning
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录 A. 如何进一步学习机器学习
- en: We are at the end of our book and now take a moment to look at what else is
    out there that could be useful for our readers.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已接近本书结尾，现在花点时间看看其他可能对读者有用的资源。
- en: There are many wonderful resources out there to learn more about machine learning—way
    too much to cover them all here. The following list can therefore represent only
    a small, and very biased, sampling of the resources the authors think are best
    at the time of writing.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 网上有许多极好的资源可以用来进一步学习机器学习——多到我们无法在这里全部覆盖。因此，以下列表只能代表一小部分，并且是作者在写作时认为最好的资源，可能带有一定的偏向性。
- en: Online courses
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在线课程
- en: Andrew Ng is a professor at Stanford who runs an online course in machine learning
    as a massive open online course at Coursera ([http://www.coursera.org](http://www.coursera.org)).
    It is free of charge, but may represent a significant time investment.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Andrew Ng 是斯坦福大学的教授，他在 Coursera ([http://www.coursera.org](http://www.coursera.org))
    上开设了一门机器学习的在线课程，作为一门大型开放在线课程。这是免费的，但可能需要投入大量时间。
- en: Books
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 书籍
- en: This book is focused on the practical side of machine learning. We did not present
    the thinking behind the algorithms or the theory that justifies them. If you are
    interested in that aspect of machine learning, then we recommend *Pattern Recognition
    and Machine Learning* by Christopher Bishop. This is a classical introductory
    text in the field. It will teach you the nitty-gritty of most of the algorithms
    we used in this book.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 本书侧重于机器学习的实际应用方面。我们没有呈现算法背后的思考过程，也没有讲解理论依据。如果你对机器学习的这一方面感兴趣，我们推荐Christopher
    Bishop的*《模式识别与机器学习》*。这是该领域的经典入门书籍，将教你大多数本书中使用的算法的细节。
- en: 'If you want to move beyond the introduction and learn all the gory mathematical
    details, then *Machine Learning: A Probabilistic Perspective* by Kevin P. Murphy
    is an excellent option ([www.cs.ubc.ca/~murphyk/MLbook](http://www.cs.ubc.ca/~murphyk/MLbook)).
    It''s very recent (published in 2012) and contains the cutting edge of ML research.
    This 1100 page book can also serve as a reference as very little of machine learning
    has been left out.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想深入了解所有复杂的数学细节，那么Kevin P. Murphy的*《机器学习：一种概率视角》*是一个很好的选择 ([www.cs.ubc.ca/~murphyk/MLbook](http://www.cs.ubc.ca/~murphyk/MLbook))。这本书出版于2012年，非常新颖，涵盖了机器学习研究的前沿。其1100页内容也可以作为参考书，因为几乎没有遗漏任何机器学习的内容。
- en: Question and answer sites
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问答网站
- en: MetaOptimize ([http://metaoptimize.com/qa](http://metaoptimize.com/qa)) is a
    machine learning question and answer website where many very knowledgeable researchers
    and practitioners interact.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: MetaOptimize ([http://metaoptimize.com/qa](http://metaoptimize.com/qa)) 是一个机器学习问答网站，许多非常有经验的研究者和从业者在此互动。
- en: Cross Validated ([http://stats.stackexchange.com](http://stats.stackexchange.com))
    is a general statistics question and answer site, which often features machine
    learning questions as well.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: Cross Validated ([http://stats.stackexchange.com](http://stats.stackexchange.com))
    是一个通用的统计学问答网站，经常有关于机器学习的问题。
- en: As mentioned in the beginning of the book, if you have questions specific to
    particular parts of the book, feel free to ask them at TwoToReal ([http://www.twotoreal.com](http://www.twotoreal.com)).
    We try to be as quick as possible to jump in and help as best as we can.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 正如书中开头提到的，如果你对书中的某些部分有疑问，可以随时在TwoToReal ([http://www.twotoreal.com](http://www.twotoreal.com))
    提问。我们尽量尽快回答并提供帮助。
- en: Blogs
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 博客
- en: 'Here is an obviously non-exhaustive list of blogs, which are interesting to
    someone working in machine learning:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出的是一份显然不完全的博客列表，适合从事机器学习工作的人阅读：
- en: 'Machine Learning Theory: [http://hunch.net](http://hunch.net)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '机器学习理论: [http://hunch.net](http://hunch.net)'
- en: The average pace is approximately one post per month. Posts are more theoretical.
    They offer additional value in brain teasers.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平均发布频率约为每月一篇，内容更具理论性，提供了额外的大脑挑战。
- en: 'Text & Data Mining by practical means: [http://textanddatamining.blogspot.de](http://textanddatamining.blogspot.de)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '实践中的文本与数据挖掘: [http://textanddatamining.blogspot.de](http://textanddatamining.blogspot.de)'
- en: Average pace is one post per month, very practical, always surprising approaches.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平均发布频率为每月一篇，内容非常实用，提供总是令人惊讶的独特方法。
- en: 'Edwin Chen''s Blog: [http://blog.echen.me](http://blog.echen.me)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Edwin Chen''s Blog: [http://blog.echen.me](http://blog.echen.me)'
- en: The average pace is one post per month, providing more applied topics.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平均发布频率为每月一篇，内容涵盖更多实际应用话题。
- en: 'Machined Learnings: [http://www.machinedlearnings.com](http://www.machinedlearnings.com)'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Machined Learnings: [http://www.machinedlearnings.com](http://www.machinedlearnings.com)'
- en: The average pace is one post per month, providing more applied topics.
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平均发布频率为每月一篇，内容涵盖更多实际应用话题。
- en: 'FlowingData: [http://flowingdata.com](http://flowingdata.com)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'FlowingData: [http://flowingdata.com](http://flowingdata.com)'
- en: The average pace is one post per day, with the posts revolving more around statistics.
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 平均发布频率为每天一篇，文章内容更多围绕统计学展开。
- en: 'Simply Statistics: [http://simplystatistics.org](http://simplystatistics.org)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Simply Statistics: [http://simplystatistics.org](http://simplystatistics.org)'
- en: Several posts per month, focusing on statistics and big data.
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每月发布几篇文章，内容侧重于统计学和大数据。
- en: 'Statistical Modeling, Causal Inference, and Social Science: [http://andrewgelman.com](http://andrewgelman.com)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '统计建模、因果推断与社会科学: [http://andrewgelman.com](http://andrewgelman.com)'
- en: One post per day with often funny reads when the author points out flaws in
    popular media, using statistics.
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每天发布一篇文章，内容通常有趣，作者通过统计数据指出流行媒体的缺陷。
- en: Data sources
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据来源
- en: If you want to play around with algorithms, you can obtain many datasets from
    the Machine Learning Repository at the University of California at Irvine (UCI).
    You can find it at [http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想尝试各种算法，可以从加州大学尔湾分校（UCI）的机器学习库中获取许多数据集。你可以在[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)找到它。
- en: Getting competitive
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变得具有竞争力
- en: An excellent way to learn more about machine learning is by trying out a competition!
    Kaggle ([http://www.kaggle.com](http://www.kaggle.com)) is a marketplace of ML
    competitions and was already mentioned in the introduction. On the website, you
    will find several different competitions with different structures and often cash
    prizes.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 了解更多关于机器学习的绝佳方式是尝试一个竞赛！Kaggle ([http://www.kaggle.com](http://www.kaggle.com))
    是一个机器学习竞赛的市场，在介绍中已经提到过。在这个网站上，你会发现多个不同结构和通常带有现金奖励的竞赛。
- en: 'The supervised learning competitions almost always follow the following format:
    you (and every other competitor) are given access to labeled training data and
    testing data (without labels). Your task is to submit predictions for testing
    data. When the competition closes, whoever has the best accuracy wins. The prizes
    range from glory to cash.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习竞赛几乎总是遵循以下格式：你（以及每位其他参赛者）都可以访问带标签的训练数据和无标签的测试数据。你的任务是提交对测试数据的预测。当竞赛结束时，准确率最高的人获胜。奖品从荣耀到现金不等。
- en: Of course, winning something is nice, but you can gain a lot of useful experience
    just by participating. So, you have to stay tuned after the competition is over
    as participants start sharing their approaches in the forum. Most of the time,
    winning is not about developing a new algorithm, but cleverly preprocessing, normalizing,
    and combining existing methods.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，赢得一些东西很好，但只要参与，你就可以获得许多有用的经验。因此，在竞赛结束后，你必须继续关注，因为参与者开始在论坛上分享他们的方法。大多数情况下，获胜并不是关于开发新算法，而是巧妙地预处理、归一化和组合现有方法。
- en: All that was left out
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 所有被遗漏的内容
- en: 'We did not cover every machine learning package available for Python. Given
    the limited space, we chose to focus on scikit-learn. However, there are other
    options and we list a few of them here:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有涵盖Python中所有可用的机器学习包。考虑到空间有限，我们选择专注于scikit-learn。但是，还有其他选择，我们在这里列出了一些：
- en: 'MDP toolkit ([http://mdp-toolkit.sourceforge.net](http://mdp-toolkit.sourceforge.net)):
    Modular toolkit for data processing'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MDP工具包 ([http://mdp-toolkit.sourceforge.net](http://mdp-toolkit.sourceforge.net))：用于数据处理的模块化工具包
- en: 'PyBrain ([http://pybrain.org](http://pybrain.org)): Python-based Reinforcement
    Learning, Artificial Intelligence, and Neural Network Library'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyBrain ([http://pybrain.org](http://pybrain.org))：基于Python的强化学习、人工智能和神经网络库
- en: 'Machine Learning Toolkit (Milk) ([http://luispedro.org/software/milk](http://luispedro.org/software/milk)):
    This package was developed by one of the authors of this book and covers some
    algorithms and techniques that are not included in scikit-learn'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习工具包（Milk）([http://luispedro.org/software/milk](http://luispedro.org/software/milk))：这个包由本书的一位作者开发，涵盖了一些scikit-learn中未包含的算法和技术。
- en: 'Pattern ([http://www.clips.ua.ac.be/pattern](http://www.clips.ua.ac.be/pattern)):
    A package that combines web mining, natural language processing, and machine learning,
    having wrapper APIs for Google, Twitter, and Wikipedia.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pattern ([http://www.clips.ua.ac.be/pattern](http://www.clips.ua.ac.be/pattern))：一个结合了网页挖掘、自然语言处理和机器学习的包，具有Google、Twitter和Wikipedia的包装API。
- en: A more general resource is [http://mloss.org](http://mloss.org), which is a
    repository of open source machine learning software. As is usually the case with
    repositories such as this one, the quality varies between excellent well maintained
    software and projects that were one-offs and then abandoned. It may be worth checking
    out whether your problem is very specific and none of the more general packages
    address it.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更通用的资源是[http://mloss.org](http://mloss.org)，这是一个开源机器学习软件库。像这样的库通常情况下，质量从优秀且维护良好的软件到一次性项目然后被抛弃的项目不等。如果你的问题非常具体，而通用包没有解决方案，这可能值得一看。
- en: Summary
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We are now truly at the end. We hope you enjoyed the book and feel well equipped
    to start your own machine learning adventure.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们真的到了尽头。希望你喜欢这本书，并且感觉已经准备好开始自己的机器学习冒险了。
- en: We also hope you learned the importance of carefully testing your methods. In
    particular, the importance of using correct cross-validation method and not report
    training test results, which are an over-inflated estimate of how good your method
    really is.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也希望你理解仔细测试方法的重要性。特别是，使用正确的交叉验证方法的重要性，以及不要报告训练测试结果，因为这些结果通常是对你方法真正效果的过高估计。
