- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Utilizing Qlik AutoML
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用 Qlik AutoML
- en: Qlik AutoML leverages the power of artificial intelligence and automation to
    empower users of all skill levels to build and deploy machine learning models,
    without the need for extensive coding or data science backgrounds. By automating
    repetitive tasks and providing intelligent recommendations, Qlik AutoML streamlines
    the entire machine learning workflow, making it accessible to a broader audience.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Qlik AutoML 利用人工智能和自动化的力量，让所有技能水平的用户都能构建和部署机器学习模型，而无需广泛的编码或数据科学背景。通过自动化重复性任务并提供智能推荐，Qlik
    AutoML 简化了整个机器学习工作流程，使其对更广泛的受众变得可访问。
- en: In this chapter, we will delve into the world of Qlik AutoML, exploring its
    capabilities, benefits, and practical applications. We will provide a comprehensive
    overview of the underlying concepts and techniques that enable Qlik AutoML to
    automate the machine learning process. Moreover, we will guide you through the
    step-by-step implementation of AutoML models within the Qlik ecosystem, highlighting
    its seamless integration with the Qlik Sense analytics platform.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨 Qlik AutoML 的世界，了解其功能、优势和实际应用。我们将全面概述支持 Qlik AutoML 自动化机器学习过程的底层概念和技术。此外，我们将指导您在
    Qlik 生态系统中逐步实现 AutoML 模型，突出其与 Qlik Sense 分析平台的无缝集成。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Features of Qlik AutoML
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qlik AutoML 的功能
- en: Using Qlik AutoML in a cloud environment
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在云环境中使用 Qlik AutoML
- en: Creating and monitoring a machine learning model with Qlik AutoML
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Qlik AutoML 创建和监控机器学习模型
- en: Connecting Qlik AutoML to an on-premises environment
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Qlik AutoML 连接到本地环境
- en: Best practices with Qlik AutoML
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Qlik AutoML 的最佳实践
- en: Features of Qlik AutoML
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Qlik AutoML 的功能
- en: 'Qlik AutoML is a tool within the Qlik Sense analytics platform that automates
    the process of building and deploying machine learning models. It simplifies the
    machine learning workflow and allows users to create predictive models, without
    requiring in-depth knowledge of data science or programming. Some of the key features
    of Qlik AutoML include the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Qlik AutoML 是 Qlik Sense 分析平台中的一个工具，它自动化了构建和部署机器学习模型的过程。它简化了机器学习工作流程，并允许用户创建预测模型，而无需深入了解数据科学或编程。Qlik
    AutoML 的一些关键特性包括以下内容：
- en: '**Automated model selection**: Qlik AutoML automatically selects the best machine
    learning algorithm based on data and the prediction task, saving users from manually
    exploring and comparing different algorithms.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动模型选择**：Qlik AutoML 根据数据和预测任务自动选择最佳的机器学习算法，从而节省用户手动探索和比较不同算法的时间。'
- en: '**Hyperparameter tuning**: Qlik AutoML optimizes the hyperparameters of the
    selected machine learning model to improve its performance and accuracy. Hyperparameter
    tuning helps fine-tune the model’s behavior and makes it more effective in making
    predictions.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超参数调整**：Qlik AutoML 优化所选机器学习模型的超参数，以提高其性能和准确性。超参数调整有助于微调模型的行为，使其在预测方面更加有效。'
- en: '**Cross-validation**: Qlik AutoML uses cross-validation techniques to evaluate
    the performance of models. It splits data into multiple subsets and trains and
    tests the models on different combinations, providing more robust performance
    metrics.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交叉验证**：Qlik AutoML 使用交叉验证技术来评估模型的性能。它将数据分成多个子集，并在不同的组合上训练和测试模型，从而提供更稳健的性能指标。'
- en: '**Model evaluation**: Qlik AutoML provides various performance metrics to evaluate
    models, such as accuracy, precision, recall, and the F1 score. These metrics help
    users assess the model’s predictive power and choose the best-performing model
    for their use case.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型评估**：Qlik AutoML 提供各种性能指标来评估模型，例如准确率、精确率、召回率和 F1 分数。这些指标帮助用户评估模型的预测能力，并选择最适合其用例的最佳性能模型。'
- en: '**Model deployment**: Once the model is built and selected, Qlik AutoML enables
    easy deployment within the Qlik Sense environment. Users can seamlessly integrate
    the predictive models into their existing Qlik apps and dashboards for real-time
    insights and decision-making.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署**：一旦模型构建并选定，Qlik AutoML 就可以在 Qlik Sense 环境中轻松部署。用户可以将预测模型无缝集成到现有的 Qlik
    应用和仪表板中，以实现实时洞察和决策。'
- en: Note
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Some of the features (including hyperparameter optimization and the prediction
    API) will require a paid tier of Qlik AutoML. Also, the number of deployments,
    concurrent tasks, and dataset limits are defined by license tier. Specific tier
    limits should be verified by Qlik Sales.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一些功能（包括超参数优化和预测API）将需要Qlik AutoML的付费级别。此外，部署数量、并发任务和数据集限制由许可证级别定义。具体的许可证级别限制应由Qlik销售部门核实。
- en: Qlik AutoML aims to democratize machine learning and empower business users
    to leverage advanced analytics capabilities, without extensive technical expertise.
    In [*Chapter 4*](B19863_04.xhtml#_idTextAnchor061), we looked at the general concepts
    in creating a good machine learning solution.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Qlik AutoML旨在使机器学习民主化，并赋予业务用户利用高级分析能力的能力，而无需广泛的技术专业知识。在[*第4章*](B19863_04.xhtml#_idTextAnchor061)中，我们探讨了创建良好的机器学习解决方案的一般概念。
- en: 'As you might remember from that chapter, there are three types of machine learning
    problems that Qlik AutoML can solve:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从那章中记得的，Qlik AutoML可以解决三种类型的机器学习问题：
- en: '**Binary classification**: Any question that can be answered with a yes or
    no'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二元分类**：任何可以用是或否回答的问题'
- en: '**Multi-class classification**: Questions where there could be multiple outcome
    choices'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多类分类**：可能有多个结果选择的问题'
- en: '**Regression/numeric**: Predicting a number at a future point'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归/数值型**：预测未来某个点的数值'
- en: Qlik AutoML is available as part of the Qlik Cloud offering. In the following
    section, we will get familiar with the actual process of getting a deployed, production-ready
    model from our training data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Qlik AutoML作为Qlik Cloud服务的一部分提供。在下一节中，我们将熟悉从我们的训练数据中获得部署、生产就绪模型的实际过程。
- en: Using Qlik AutoML in a cloud environment
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在云环境中使用Qlik AutoML
- en: 'There are several steps when deploying a machine learning model using Qlik
    AutoML. These steps are illustrated in the following diagram:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Qlik AutoML部署机器学习模型时，有几个步骤。这些步骤在下图中展示：
- en: '![Figure 8.1: The AutoML workflow](img/B19863_08_01.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1：AutoML工作流程](img/B19863_08_01.jpg)'
- en: 'Figure 8.1: The AutoML workflow'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1：AutoML工作流程
- en: As you might remember from our earlier chapters, the first step of every machine
    learning project is to define a business problem and question, followed by the
    steps required for data cleaning, preparation, and modeling. Typically, data cleaning
    and transformation part can take up 80–90% of the time spent on a project.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从我们前面的章节中记得的，每个机器学习项目的第一步是定义业务问题和问题，然后是数据清洗、准备和建模所需的步骤。通常，数据清洗和转换部分可以占用项目80-90%的时间。
- en: Once we have a machine-learning-ready dataset, we will continue by creating
    a machine learning experiment.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了机器学习准备好的数据集，我们将继续创建机器学习实验。
- en: In automated machine learning, the process of training machine learning algorithms
    on a specific dataset and target is automated. When you create an experiment and
    load your dataset, the system automatically examines and prepares data for machine
    learning. It provides you with statistics and insights about each column, aiding
    in the selection of a target variable. Once the training begins, multiple algorithms
    analyze the data, searching for patterns.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动化机器学习中，对特定数据集和目标的机器学习算法进行训练的过程是自动化的。当您创建一个实验并加载您的数据集时，系统会自动检查并准备数据以供机器学习使用。它为您提供了关于每一列的统计信息和洞察，有助于选择目标变量。一旦开始训练，多个算法分析数据，寻找模式。
- en: Upon completion of the training process, you can assess the performance of the
    generated machine learning models using scores and rankings. By adjusting parameters
    and repeating the training, you can generate multiple versions of the models.
    After carefully evaluating the options, you can choose the model that performs
    best on your dataset. An experiment can have multiple versions, each using one
    or more algorithms, and one experiment can result in several machine learning
    deployments.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程完成后，您可以使用分数和排名来评估生成的机器学习模型的性能。通过调整参数并重复训练，您可以生成多个模型版本。在仔细评估选项后，您可以选择在您的数据集上表现最佳的模型。一个实验可以有多个版本，每个版本使用一个或多个算法，一个实验可以导致多个机器学习部署。
- en: Simply, during the experiment phase, we will fine-tune the model and try to
    achieve the best possible accuracy. Once we are happy with the model, we can deploy
    it into production and start utilizing it in our analysis. We will go through
    each of these steps in our hands-on example in the following section.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，在实验阶段，我们将微调模型并尝试达到最佳可能的准确度。一旦我们对模型满意，我们就可以将其部署到生产环境中，并开始在我们的分析中使用它。我们将在下一节的动手示例中逐一介绍这些步骤。
- en: Creating and monitoring a machine learning model with Qlik AutoML
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Qlik AutoML创建和监控机器学习模型
- en: In this section, we will create an actual implementation using Qlik AutoML.
    We will utilize the famous Iris dataset that we have already used in this book.
    The data preparation part for Iris dataset is already done, so we can jump into
    the model training and experiment part directly.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用Qlik AutoML创建一个实际实现。我们将利用本书中已经使用过的著名Iris数据集。Iris数据集的数据准备部分已经完成，因此我们可以直接进入模型训练和实验部分。
- en: Note
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can find the datasets used in this example in the GitHub repository for
    this book.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在本书的GitHub仓库中找到本例中使用的数据集。
- en: Note
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Only users with Professional entitlement can create experiments.This is a limitation
    at the license level.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 只有拥有专业权限的用户才能创建实验。这是许可证级别的一个限制。
- en: Let’s assume that we have already uploaded the `iris` dataset into our cloud
    tenant. Now, we will start to define a business question. This question defines
    what we would like to achieve from our machine learning model.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已将`iris`数据集上传到我们的云租户。现在，我们将开始定义一个业务问题。这个问题定义了我们希望从机器学习模型中实现的目标。
- en: 'As we know, the Iris dataset consists of measurements of four features of three
    different species of Iris flowers. These features are as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，Iris数据集包含了三种不同品种的Iris花的四个特征的测量值。这些特征如下：
- en: '**Sepal length**: The length of the sepal, which is the outermost part of the
    flower that protects the petals'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**花瓣宽度**: 花瓣的宽度'
- en: '**Sepal width**: The width of the sepal'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**花瓣宽度**: 花瓣的宽度'
- en: '**Petal length**: The length of the petals, which are the colorful leaf-like
    structures inside the flower'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**花瓣长度**: 花瓣的长度，这些是花内部五彩斑斓的叶状结构'
- en: '**Petal width**: The width of the petals'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**花瓣宽度**: 花瓣的宽度'
- en: 'The dataset contains 150 instances or samples, with 50 samples for each of
    the three Iris species – `setosa`, `versicolor`, and `virginica`. To define a
    machine learning question to predict species in the Iris dataset, we will frame
    it as a multi-class classification problem. Here is a sample question that we
    will form before our investigation:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含150个实例或样本，其中每种Iris品种（`setosa`、`versicolor`和`virginica`）各有50个样本。为了定义一个机器学习问题来预测Iris数据集中的物种，我们将将其构建为一个多类分类问题。以下是我们将在调查之前形成的样本问题：
- en: Given the measurements of sepal length, sepal width, petal length, and petal
    width, can we accurately classify the species of Iris flowers into setosa, versicolor,
    or virginica?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 给定花瓣长度、花瓣宽度、花瓣长度和花瓣宽度的测量值，我们能否准确地将Iris花的品种分类为setosa、versicolor或virginica？
- en: In this case, the machine learning task involves training a model to learn the
    patterns and relationships between the input features (sepal length, sepal width,
    petal length, and petal width) and the corresponding output classes (`setosa`,
    `versicolor`, and `virginica`). The goal is to develop a predictive model that
    can accurately classify new instances of iris flowers into one of the three species,
    based on their measurements. AutoML will choose the best-performing model for
    us, based on the selected target and variables.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，机器学习任务涉及训练一个模型来学习输入特征（花瓣长度、花瓣宽度、花瓣长度和花瓣宽度）与相应的输出类别（`setosa`、`versicolor`和`virginica`）之间的模式和关系。目标是开发一个预测模型，能够根据它们的测量值，准确地将新的Iris花实例分类为三种品种之一。AutoML将根据选定的目标和变量为我们选择表现最佳的模型。
- en: 'We will begin the actual model creation by creating a new machine learning
    experiment. To do that, select **+ Add new** � **New ML experiment**, as shown
    in the following screenshot:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过创建一个新的机器学习实验来开始实际的模型创建。为此，选择**+ 添加新** → **新ML实验**，如图下所示：
- en: '![Figure 8.2: A new machine learning experiment](img/B19863_08_02.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图8.2：一个新的机器学习实验](img/B19863_08_02.jpg)'
- en: 'Figure 8.2: A new machine learning experiment'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2：一个新的机器学习实验
- en: A new window will open. Insert a name for your new experiment, and select a
    space for it. In my example, I will call the experiment `Iris exp`. Select **Create**
    to proceed.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 将打开一个新窗口。为您的实验插入一个名称，并选择一个空间。在我的例子中，我将实验命名为`Iris exp`。选择**创建**以继续。
- en: 'Then, you can select a dataset for training. Select `iris.csv`, which we uploaded
    earlier to our tenant. A preview window will open. In this window, we will define
    our target field. It will also give us important information about the dataset.
    You should see a preview window like the following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以选择一个用于训练的数据集。选择我们之前上传到我们的租户的`iris.csv`。将打开一个预览窗口。在这个窗口中，我们将定义我们的目标字段。它还将给我们提供关于数据集的重要信息。您应该看到一个类似于以下预览窗口：
- en: '![Figure 8.3: Schema view in the machine learning experiment wizard](img/B19863_08_03.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图8.3：机器学习实验向导中的模式视图](img/B19863_08_03.jpg)'
- en: 'Figure 8.3: Schema view in the machine learning experiment wizard'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3：机器学习实验向导中的模式视图
- en: You are currently in `String` for the `species` field and `Float (Double)` for
    other fields.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 您目前处于`species`字段的`String`和`Float (Double)`字段的`Float (Double)`。
- en: 'All columns have been recognized as `Numeric` or `Categorical` fields. This
    can be changed for each field if needed. We can also see from the `Insights` column
    that our “species” feature has been automatically one-hot encoded. If there are
    any warnings related to some of the features, we can also see these. The following
    information is presented in the `Insights` column:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 所有列都已识别为`数值`或`分类`字段。如果需要，可以分别为每个字段进行更改。我们还可以从`洞察`列中看到，我们的“物种”特征已被自动进行独热编码。如果有任何与某些特征相关的警告，我们也可以看到。以下信息在`洞察`列中展示：
- en: '**Constant**: The column has the same value for all rows. The column can’t
    be used as a target or included feature. This is a pre-set limitation in Qlik
    AutoML to prevent incorrect results.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常数**：该列的所有行都具有相同的值。该列不能用作目标或包含的特征。这是Qlik AutoML中预设的限制，以防止出现错误的结果。'
- en: '**One-hot encoded**: The feature type is categorical, and the column has fewer
    than 14 unique values.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**独热编码**：特征类型为分类，且该列有少于14个唯一值。'
- en: '**Impact encoded**: The feature type is categorical, and the column has 14
    or more unique values.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**影响编码**：特征类型为分类，且该列有14个或更多唯一值。'
- en: '**High cardinality**: The column has too many unique values and can negatively
    affect model performance if used as a feature. The column can’t be used as a target.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高基数**：该列有太多唯一值，如果用作特征可能会对模型性能产生负面影响。该列不能用作目标。'
- en: '`null` values. The column can’t be used as a target or included feature.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`null`值。该列不能用作目标或包含的特征。'
- en: '**Underrepresented class**: The column has a class with fewer than 10 rows.
    Column can’t be used as a target but can be included as a feature.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代表性不足的类别**：该列有一个少于10行的类别。列不能用作目标，但可以作为特征包含在内。'
- en: 'Before selecting our target field, we can change our view to **data view**.
    You can do this from the top-right corner of the data preview area. You should
    see the following view:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择我们的目标字段之前，我们可以将我们的视图更改为**数据视图**。您可以从数据预览区域右上角进行此操作。您应该看到以下视图：
- en: '![Figure 8.4: Data view in the machine learning experiment wizard](img/B19863_08_04.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图8.4：机器学习实验向导中的数据视图](img/B19863_08_04.jpg)'
- en: 'Figure 8.4: Data view in the machine learning experiment wizard'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4：机器学习实验向导中的数据视图
- en: In this view, we can investigate the data content more. We will see a mini-chart
    representing the distribution of data in each numerical field, as well as the
    distribution in categorical fields. We will also get information about the distinct
    and `null` values.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在此视图中，我们可以更深入地研究数据内容。我们将看到表示每个数值字段中数据分布的迷你图表，以及分类字段中的分布。我们还将获得有关唯一和`null`值的信息。
- en: 'Let’s now change back to schema view and select our `species` feature as a
    target. To do this, select `species`, as shown in the following screenshot:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们切换回模式视图，并将我们的`species`特征作为目标选择。为此，选择`species`，如以下截图所示：
- en: '![Figure 8.5: Target selection](img/B19863_08_05.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图8.5：目标选择](img/B19863_08_05.jpg)'
- en: 'Figure 8.5: Target selection'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5：目标选择
- en: 'All the other features are automatically included in our experiment. In this
    case, we want to keep all features included, but typically, we might want to drop
    some of the fields. On the right side, we can see the summary information about
    the experiment:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 所有其他特征都将自动包含在我们的实验中。在这种情况下，我们希望保留所有特征，但通常我们可能想要删除一些字段。在右侧，我们可以看到关于实验的摘要信息：
- en: '![Figure 8.6: The experiment summary](img/B19863_08_06.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.6：实验摘要](img/B19863_08_06.jpg)'
- en: 'Figure 8.6: The experiment summary'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6：实验摘要
- en: First, we get a summary of our training data. We will see the total amount of
    cells, columns, and rows in a dataset and how many of those have been included
    in the experiment. In our case, all data is included, since we decided to keep
    all the features in our experiment.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们得到训练数据的摘要。我们将看到数据集中的总单元格数、列数和行数，以及有多少被包含在实验中。在我们的案例中，所有数据都被包含在内，因为我们决定保留实验中的所有特征。
- en: Now, we can see some information about our target. We can also change the target
    before running our experiment. In this case, our target is `species`. The following
    section will give us a summary of the selected features. We will select all the
    features from our data as part of our experiment.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看到一些关于我们的目标的信息。我们也可以在运行实验之前更改目标。在这种情况下，我们的目标是 `species`。下一节将给出所选特征的摘要。我们将选择数据集中的所有特征作为实验的一部分。
- en: In the algorithm section, we can see that AutoML has identified our model to
    be a multiclass classification, based on our target field. We can decide to exclude
    some algorithms from our experiment if we want. Typically, it is recommended to
    keep all algorithms included.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在算法部分，我们可以看到 AutoML 根据我们的目标字段将我们的模型识别为多类分类。如果我们想的话，我们可以决定排除实验中的一些算法。通常，建议保留所有包含的算法。
- en: Under model optimization, we can enable hyperparameter optimization and set
    the maximum time for our experiment to run optimization. Hyperparameter optimization
    will create a series of models from a methodical search for the optimal combination
    of algorithm hyperparameters, maximizing model performance. An experiment can
    take a long time to run if this option is enabled, but results can be more accurate.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型优化部分，我们可以启用超参数优化并设置实验运行优化的最大时间。启用此选项时，超参数优化将创建一系列模型，通过系统地搜索算法超参数的最佳组合，以最大化模型性能。如果启用此选项，实验可能需要很长时间才能运行，但结果可能更准确。
- en: 'Ultimately, we will get a reminder of the preprocessing steps that AutoML will
    take care of for us. These are as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们将得到 AutoML 将为我们处理的预处理步骤的提醒。具体如下：
- en: '`null` values in features that have at least 50% of the values populated. Depending
    on each feature’s data type, AutoML selects `MEAN` or `OTHER` imputation.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征中至少有 50% 的值被填充的 `null` 值。根据每个特征的数据类型，AutoML 选择 `MEAN` 或 `OTHER` 填充。
- en: '**Encoding categorical features**: AutoML automatically converts your categorical
    features to numerical values so that algorithms can effectively process and learn
    from your categorical training data. For features with 13 or fewer values, AutoML
    uses one-hot encoding. For features with 14 or more values, AutoML uses impact
    encoding.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**编码分类特征**: AutoML 自动将你的分类特征转换为数值，以便算法能够有效地处理和从你的分类训练数据中学习。对于有 13 个或更少值的特征，AutoML
    使用独热编码。对于有 14 个或更多值的特征，AutoML 使用影响编码。'
- en: '**Feature scaling**: AutoML uses feature scaling to normalize the range of
    independent variables in your training data. AutoML calculates the mean and standard
    deviation for each column, and then it calculates the number of standard deviations
    away from the mean for each row.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征缩放**: AutoML 使用特征缩放来规范化训练数据中独立变量的范围。AutoML 计算每一列的均值和标准差，然后计算每一行与均值的标准差数。'
- en: '**Automatic holdout of training data**: AutoML extracts 20% of your training
    dataset to be used for final model evaluation. AutoML *holds* that data until
    after model training, when it is used to evaluate the performance of the model.
    The benefit of holdout data is that it is not seen by the model during training
    (unlike cross-validation data), so it is ideal to validate model performance.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自动保留训练数据**: AutoML 从你的训练数据集中提取 20% 的数据用于最终模型评估。AutoML 在模型训练完成后才会保留这些数据，用于评估模型的性能。保留数据的优点是，在训练过程中模型不会看到这些数据（与交叉验证数据不同），因此非常适合验证模型性能。'
- en: '**Five-fold cross-validation**: After applying the previous preprocessing steps,
    AutoML randomly sorts your remaining training data into five distinct groups called
    “folds” for use in cross-validation. AutoML tests each fold against a model trained
    using the other four folds. In other words, each trained model is tested on a
    piece of data that the model has never seen before.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**五折交叉验证**：在应用之前的预处理步骤之后，AutoML 将剩余的训练数据随机排序成五个不同的组，称为“折”，用于交叉验证。AutoML 将每个折与使用其他四个折训练的模型进行测试。换句话说，每个训练模型都在模型从未见过的数据上进行了测试。'
- en: 'We are now ready with our experiment setup and can proceed by selecting **Run
    experiment**. The actual model preprocessing and training phase will start; it
    will take a while to finish. After the experiment has finished running the models,
    we will see the **Model metrics** screen, as shown in the following screenshot:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经准备好了实验设置，可以通过选择 **运行实验** 来继续。实际的模型预处理和训练阶段将开始；完成需要一段时间。实验完成后，我们将看到 **模型指标**
    屏幕，如下面的截图所示：
- en: '![Figure 8.7: Model metrics](img/B19863_08_07.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.7：模型指标](img/B19863_08_07.jpg)'
- en: 'Figure 8.7: Model metrics'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7：模型指标
- en: 'We can see that the top-performing model was the XGBoost Classification algorithm,
    with an `F1 Macro` score of `0.967`. We also get information about the `F1 Micro`,
    `F1` `Weighted`, and `Accuracy` scores. We covered the meaning of the F1 score
    in the first chapter. The difference between the micro, macro, and weighted F1
    scores is the following:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，表现最好的模型是 XGBoost 分类算法，其 `F1 Macro` 得分为 `0.967`。我们还获得了关于 `F1 Micro`、`F1
    Weighted` 和 `Accuracy` 得分的信息。我们在第一章中介绍了 F1 分数的含义。微、宏和加权 F1 分数之间的区别如下：
- en: Macro F1 is the averaged F1 value for each class without weighting (all classes
    are treated equally).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 宏 F1 是每个类别的平均 F1 值，不进行加权（所有类别都同等对待）。
- en: Micro F1 is the F1 value calculated across the entire confusion matrix. Calculating
    the micro F1 score is equivalent to calculating the global precision or global
    recall.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微 F1 是在整个混淆矩阵上计算的 F1 值。计算微 F1 分数等同于计算全局精确度或全局召回率。
- en: Weighted F1 corresponds to the binary classification F1\. It is calculated for
    each class and then combined as a weighted average, considering the number of
    records for each class.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加权 F1 对应于二分类 F1。它为每个类别计算，然后作为一个加权平均值组合，考虑每个类别的记录数量。
- en: As you might remember, accuracy measures how often a model makes a correct prediction
    on average. In our case, the accuracy score is 0.967, meaning that our model is
    correct ~97% of cases.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能记得，准确度衡量模型平均上正确预测的频率。在我们的例子中，准确度得分为 0.967，这意味着我们的模型在 97% 的情况下是正确的。
- en: 'Under `Hyperparameters`, we can also investigate the model parameters. For
    our top-performing model, these look like the following:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `超参数` 下，我们还可以调查模型参数。对于我们的最佳模型，这些参数看起来如下：
- en: '![Figure 8.8: Hyperparameters for XGBoost classification](img/B19863_08_08.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.8：XGBoost 分类超参数](img/B19863_08_08.jpg)'
- en: 'Figure 8.8: Hyperparameters for XGBoost classification'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8：XGBoost 分类超参数
- en: These are meant to give us more detailed information about the model. Parameters
    are algorithm-specific.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这些旨在为我们提供关于模型的更详细信息。参数是算法特定的。
- en: 'Now, we will take a closer look at the **Permutation importance** and **SHAP
    importance** diagrams. We explored the basic concept of both diagrams in [*Chapter
    1*](B19863_01.xhtml#_idTextAnchor014). The following figure shows an example of
    the diagrams:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将更仔细地研究 **排列重要性** 和 **SHAP 重要性** 图表。我们在 [*第一章*](B19863_01.xhtml#_idTextAnchor014)
    中探讨了这两个图表的基本概念。以下图显示了图表的示例：
- en: '![Figure 8.9: The Permutation importance and SHAP importance diagrams](img/B19863_08_09.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.9：排列重要性和 SHAP 重要性的图表](img/B19863_08_09.jpg)'
- en: 'Figure 8.9: The Permutation importance and SHAP importance diagrams'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9：排列重要性和 SHAP 重要性的图表
- en: As you might remember, permutation importance is a measure of how important
    a feature is to the overall prediction of a model. Basically, it describes how
    the model would be affected if you removed its ability to learn from that feature.
    AutoML uses the scikit-learn toolkit to calculate permutation importance.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能记得，排列重要性是衡量一个特征对模型整体预测重要性的度量。基本上，它描述了如果移除模型从该特征学习的能力，模型会受到怎样的影响。AutoML 使用
    scikit-learn 工具包来计算排列重要性。
- en: SHAP importance is a method used to interpret the predictions of machine learning
    models. It provides insights into the contribution of each feature to the prediction
    for a specific instance, or a group of instances. Basically, it represents how
    a feature influences the prediction of a single row, relative to the other features
    in that row and to the average outcome in the dataset. SHAP importance is measured
    at the row level, and AutoML uses various algorithms to calculate the SHAP importance
    score.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP重要性是一种用于解释机器学习模型预测的方法。它提供了关于每个特征对特定实例或一组实例预测贡献的见解。基本上，它表示一个特征相对于该行中的其他特征以及数据集的平均结果对单个行预测的影响。SHAP重要性在行级别进行衡量，AutoML使用各种算法来计算SHAP重要性分数。
- en: 'From the preceding graphs, we can see that **petal_length** is an important
    feature in our prediction, both in terms of permutation and SHAP importance. In
    multiclass problems, we can also investigate the SHAP importance for each class.
    Let’s investigate our SHAP values for each feature by class. Change a graph type
    using the drop-down menu on the SHAP chart, and select **Feature SHAP by class**.
    You should see the following graph:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图表中，我们可以看到**花瓣长度**是我们预测中的一个重要特征，无论是从排列还是SHAP重要性来看。在多类问题中，我们还可以调查每个类的SHAP重要性。让我们通过类别来调查每个特征的SHAP值。使用SHAP图表上的下拉菜单更改图表类型，并选择**按类别特征SHAP**。你应该会看到以下图表：
- en: '![Figure 8.10: SHAP by class](img/B19863_08_10.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图8.10：按类别SHAP](img/B19863_08_10.jpg)'
- en: 'Figure 8.10: SHAP by class'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.10：按类别SHAP
- en: From the preceding graph, we can see that **petal_length** can be used to distinguish
    **setosa** from **versicolor** and **virginica**. Other features are then used
    to determine the species further. We can also see the SHAP importance for each
    specific class if we change the graph type from the drop-down menu.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图表中，我们可以看到**花瓣长度**可以用来区分**setosa**、**versicolor**和**virginica**。其他特征随后用于进一步确定物种。如果我们从下拉菜单更改图表类型，我们还可以看到每个特定类的SHAP重要性。
- en: 'If we want to change our experiment, we can select **Configure v2** and modify
    the parameters for it. In this case, we are happy with our model. To deploy our
    model, we can select **Deploy**. We can provide a name for our model if we are
    not happy with the autogenerated one and decide a space for it. AutoML autofills
    some details about the model in the **Description** field. Make sure that the
    **Enable real-time API access** option is enabled, and select **Deploy**. Then,
    select **Open** from the popup, and you should get redirected to our new machine
    learning model. You should then see a view like the following:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想更改我们的实验，我们可以选择**配置v2**并修改其参数。在这种情况下，我们对我们的模型感到满意。要部署我们的模型，我们可以选择**部署**。如果我们对自动生成的模型不满意，我们可以为其提供一个名称并决定其所在的空间。AutoML会在**描述**字段中自动填充有关模型的一些细节。确保**启用实时API访问**选项已启用，并选择**部署**。然后，从弹出窗口中选择**打开**，你应该会被重定向到我们新的机器学习模型。你应该会看到以下视图：
- en: '![Figure 8.11: The deployed machine learning model](img/B19863_08_11.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图8.11：已部署的机器学习模型](img/B19863_08_11.jpg)'
- en: 'Figure 8.11: The deployed machine learning model'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11：已部署的机器学习模型
- en: On the left-hand side, you can see a schema for the deployed model. The schema
    will tell us what kind of data our model expects when using it for predictions.
    On the right side, we can see details about our model. The other two tabs will
    give us information about predictions that were run manually and the `REST` endpoint
    connectivity. Take a closer look at these, and return to schema view when you
    are done.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧，你可以看到一个已部署模型的架构图。这个架构图会告诉我们，当使用模型进行预测时，模型期望我们提供什么类型的数据。在右侧，我们可以看到我们模型的详细信息。其他两个标签页将提供关于手动运行预测和`REST`端点连接性的信息。仔细查看这些信息，完成后返回架构视图。
- en: We can use our model directly by selecting **Create prediction** and uploading
    a CSV or other data file for our model. This way, we will get our results stored
    as a file in Qlik Cloud. There is also a possibility to schedule predictions and
    apply dynamic naming for result files. However, a more robust way to utilize our
    new model is to use it through a data connector. Let’s take a closer look into
    that next.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过选择**创建预测**并上传模型所需的CSV或其他数据文件来直接使用我们的模型。这样，我们的结果将作为文件存储在Qlik Cloud中。还有可能安排预测并动态命名结果文件。然而，更稳健地利用我们新模型的方法是通过数据连接器使用它。让我们接下来更详细地看看这一点。
- en: 'For our application, we will use another dataset called `iris_test.csv`. To
    begin, upload the file to Qlik Cloud. Create a new Qlik application, and add the
    `iris_test` data to it. Now, we will add the `id` field into our test data. To
    do that, you can use the following code:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的应用程序，我们将使用另一个名为`iris_test.csv`的数据集。首先，将文件上传到Qlik Cloud。创建一个新的Qlik应用程序，并将`iris_test`数据添加到其中。现在，我们将`id`字段添加到我们的测试数据中。为此，你可以使用以下代码：
- en: '[PRE0]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Our `iris_test.csv` dataset is randomly generated to mimic the characteristics
    of the original `iris` dataset and does not represent the actual data. It should
    be only used for demonstration purposes.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`iris_test.csv`数据集是随机生成的，以模拟原始`iris`数据集的特征，并不代表实际数据。它应仅用于演示目的。
- en: 'Now, we will create a connection to our deployed machine learning model. Select
    **Create new connection** under the data connections, and then select **Qlik AutoML**.
    A view like the following will open:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将创建与我们的部署机器学习模型的连接。在数据连接下选择**创建新连接**，然后选择**Qlik AutoML**。将打开一个如下视图：
- en: '![Figure 8.12: A data connection to the machine learning model](img/B19863_08_12.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图8.12：机器学习模型的连接数据](img/B19863_08_12.jpg)'
- en: 'Figure 8.12: A data connection to the machine learning model'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12：机器学习模型的连接数据
- en: Select our deployed model from the `predictions`. Select **Include SHAP** and
    **Include Errors**, since we want our result table to also include these columns.
    SHAP is not available for every algorithm, but it is a good practice to select
    it. If it’s not available, it will not appear in the results table. In our case,
    these values are not available.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 从`predictions`中选择我们的部署模型。选择**包含SHAP**和**包含错误**，因为我们希望我们的结果表也包含这些列。SHAP不是每个算法都可用，但选择它是良好的实践。如果不可用，它将不会出现在结果表中。在我们的情况下，这些值不可用。
- en: 'In `id`. This is a field that ties the generated predictions and our original
    data together. We generated the `id` field in our data earlier. Provide a name
    for your data connection, and click **Save**. You should see a new data connection
    appear in your application; let’s use it. Click **Select data**, as shown in the
    following screenshot:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在`id`。这是一个将生成的预测和我们的原始数据联系在一起的字段。我们在之前的数据中生成了`id`字段。为你的数据连接提供一个名称，然后点击**保存**。你应该在你的应用程序中看到一个新数据连接出现；让我们使用它。点击**选择数据**，如下截图所示：
- en: '![Figure 8.13: Select data in the AutoML connection](img/B19863_08_13.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图8.13：在AutoML连接中选择数据](img/B19863_08_13.jpg)'
- en: 'Figure 8.13: Select data in the AutoML connection'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.13：在AutoML连接中选择数据
- en: 'The data selection wizard will appear, as shown in the following screenshot:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 将出现数据选择向导，如下截图所示：
- en: '![Figure 8.14: The data selection wizard](img/B19863_08_14.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图8.14：数据选择向导](img/B19863_08_14.jpg)'
- en: 'Figure 8.14: The data selection wizard'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.14：数据选择向导
- en: 'In the `iris`. This is our original dataset, which we will use to get predictions.
    Select the `predictions` table under the **Tables** section. This is our results
    table. There is no preview available, but you can see the script generated. Select
    **Insert script**. We can now see that our connector generated the following script:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在`iris`。这是我们原始数据集，我们将用它来获取预测。在**表**部分下选择`predictions`表。这是我们的结果表。没有预览可用，但你可以看到生成的脚本。选择**插入脚本**。我们现在可以看到我们的连接器生成了以下脚本：
- en: '[PRE1]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Basically, our connector uses the API to send the `iris` table into our machine
    learning model and gets the prediction table back. It takes the connection name
    as a parameter and our data table (`iris`) as an input. We can now load our application
    and investigate the data model viewer. You should see a data model like the following:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，我们的连接器使用API将`iris`表发送到我们的机器学习模型，并返回预测表。它以连接名称作为参数，并将我们的数据表（`iris`）作为输入。我们现在可以加载我们的应用程序并调查数据模型查看器。你应该看到一个如下所示的数据模型：
- en: '![Figure 8.15: The data model](img/B19863_08_15.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图8.15：数据模型](img/B19863_08_15.jpg)'
- en: 'Figure 8.15: The data model'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.15：数据模型
- en: As we can see, our connector returned a predictions table that is connected
    to our original data table, using `id` as a key. The predictions table contains
    the actual prediction, a possible error message for each row, and the probability
    for every Iris species.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们的连接器返回了一个与我们的原始数据表通过`id`作为键连接的预测表。预测表包含实际预测、每行的可能错误消息以及每个鸢尾花物种的概率。
- en: 'Now, we will investigate our prediction results further. Create a new sheet,
    and add the following elements to it:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将进一步调查我们的预测结果。创建一个新的工作表，并向其中添加以下元素：
- en: A filter pane, with all our features on the top.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个过滤器面板，顶部包含所有我们的特征。
- en: A scatter plot, with `Avg(petal_width)` on the *y* axis and `Avg(petal_length)`
    on the *x* axis and `Id` as a bubble. Color by dimension, and select `species_predicted`
    as the coloring dimension.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个散点图，`Avg(petal_width)`在*y*轴上，`Avg(petal_length)`在*x*轴上，`Id`作为气泡。按维度着色，并选择`species_predicted`作为着色维度。
- en: A table containing all our features.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含所有特征的表格。
- en: A bar chart, with `Count(species_predicted)` as the bar height and `species_predicted`
    as the dimension.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个柱状图，`Count(species_predicted)`作为柱高，`species_predicted`作为维度。
- en: Four KPI objects that we will configure later.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们稍后将要配置的四个KPI对象。
- en: Four variable inputs, with text and an image container on the left side of each
    of them.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 四个变量输入，每个输入的左侧都有一个文本和图像容器。
- en: 'You should end up with a layout like the following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该得到以下布局：
- en: '![Figure 8.16: The application layout](img/B19863_08_16.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图8.16：应用程序布局](img/B19863_08_16.jpg)'
- en: 'Figure 8.16: The application layout'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.16：应用程序布局
- en: Note
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can find the complete application in the GitHub repository for this book.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在本书的GitHub仓库中找到完整的应用程序。
- en: As you can see from the results, we have managed to predict the species with
    our model. If we look at the scatter plot, it seems that our model gives good
    results, keeping in mind that our data is randomly generated. As a last step,
    we will create a simulation that will utilize the API of our model.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从结果中看到的那样，我们已经使用我们的模型成功预测了物种。如果我们查看散点图，似乎我们的模型给出了良好的结果，考虑到我们的数据是随机生成的。作为最后一步，我们将创建一个将利用我们模型API的模拟。
- en: 'We will start by creating the following variables:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先创建以下变量：
- en: '[PRE2]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Make `0` the default value for each variable. Since we have already created
    our variable input and labels, we can assign the variables into inputs and type
    the correct labels into place. You should end up with the following view:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 将每个变量的默认值设为`0`。由于我们已经创建了变量输入和标签，我们可以将变量分配到输入中，并将正确的标签输入到相应位置。最终您应该得到以下视图：
- en: '![Figure 8.17: The simulation view](img/B19863_08_17.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图8.17：模拟视图](img/B19863_08_17.jpg)'
- en: 'Figure 8.17: The simulation view'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.17：模拟视图
- en: 'Now, we will set up the KPI objects. Select the first KPI, and type `Prediction`
    as a label. Enter the following formula in the **Expression** field:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将设置KPI对象。选择第一个KPI，并将标签输入为`Prediction`。在**表达式**字段中输入以下公式：
- en: '[PRE3]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This syntax might look familiar. We used the same principle in our earlier example
    with R. AutoML connector utilizes advanced analytics integration syntax.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这种语法可能看起来很熟悉。我们在之前的R示例中使用了相同的原则。AutoML连接器利用了高级分析集成语法。
- en: 'With the advanced analytics integration, we have two sets of script functions:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 通过高级分析集成，我们有两组脚本函数：
- en: '**ScriptEval**: After the hypercube has been aggregated, all rows in the specified
    columns are sent to the connector. The response expected is a single column. If
    multiple columns are returned, the first column that has the same number of rows
    as the input will be picked. The rows in the returned column must be in the same
    order as the input.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ScriptEval**：在超立方体聚合后，指定列中的所有行都发送到连接器。期望的响应是单列。如果返回多个列，则将选择与输入行数相同的第一个列。返回列中的行必须与输入的顺序相同。'
- en: '`ScriptAggr` is called with many dimensions.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ScriptAggr`使用多个维度调用。'
- en: 'For both the preceding sets, there are four different functions based on the
    data types:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前面提到的两个集合，有四种基于数据类型的函数：
- en: '`ScriptEval(Script, Field 1, [Field n])`: The input fields and the response
    must be numeric.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ScriptEval(Script, Field 1, [Field n])`: 输入字段和响应必须是数值。'
- en: '`ScriptEvalStr(Script, Field 1, [Field n])`: The input fields and the response
    must be a string.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ScriptEvalStr(Script, Field 1, [Field n])`: 输入字段和响应必须是字符串。'
- en: '`ScriptEvalEx(DataTypes, Script, Field 1, [Field n])`: The input fields can
    be either string or numeric, the first parameter is a string of the datatypes,
    and the response must be numeric.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ScriptEvalEx(DataTypes, Script, Field 1, [Field n])`: 输入字段可以是字符串或数值，第一个参数是数据类型的字符串，响应必须是数值。'
- en: '`ScriptEvalExStr(DataTypes, Script, Field 1, [Field n])`: The input fields
    can be either string or numeric, the first parameter is a string of the datatypes,
    and the response must be string.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ScriptEvalExStr(DataTypes, Script, Field 1, [Field n])`: 输入字段可以是字符串或数值，第一个参数是数据类型的字符串，响应必须是字符串。'
- en: We used the `ScriptEvalExStr` function in the preceding example and defined
    the data types of our input fields, since they are numeric but the response is
    a string (`'NNNN'` for numerical fields).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们使用了`ScriptEvalExStr`函数，并定义了输入字段的数据类型，因为它们是数值型的，但响应是字符串（数值字段为`'NNNN'`）。
- en: 'Note that our script also contains the details of the connection to be used:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到我们的脚本还包含了要使用的连接的详细信息：
- en: '[PRE4]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The connection name refers to the data connector that we created earlier. We
    have also determined the column that we want to get from the model. In our case,
    it is `species_predicted`. Selecting a correct return value is important. You
    can see all the possible fields – for example, from the data manager – if you
    have also used the model during the data load.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 连接名称指的是我们之前创建的数据连接器。我们还确定了要从模型中获取的列。在我们的例子中，它是`species_predicted`。选择正确的返回值很重要。如果您在数据加载期间也使用了模型，您可以看到所有可能的字段——例如，从数据管理器中。
- en: In the last part of our script, we will pass the variable values as input to
    our model. The names should match the names of our model schema. That’s why we
    will use the `as` operator to rename the variables.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们脚本的最后部分，我们将变量值作为输入传递给我们的模型。名称应与我们的模型模式名称匹配。这就是为什么我们将使用`as`运算符来重命名变量。
- en: After configuring the KPI object, you should see `setosa` appear as a value.
    Since all our variables are defined to be `0`, our model will give a prediction
    based on that information.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置KPI对象之后，你应该会看到`setosa`作为一个值出现。由于我们所有的变量都被定义为`0`，我们的模型将根据这些信息进行预测。
- en: 'Add the following configurations to the three remaining KPI objects:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下配置添加到剩余的三个KPI对象中：
- en: '**Label**: Setosa'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签**：Setosa'
- en: '**Script**:'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**脚本**：'
- en: '[PRE5]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Label**: Versicolor'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签**：Versicolor'
- en: '**Script**:'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**脚本**：'
- en: '[PRE6]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Label**: Virginica'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签**：Virginica'
- en: '**Script**:'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**脚本**：'
- en: '[PRE7]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As you might have noticed, the script is nearly the same in all our KPIs. We
    define the output by changing the value of the return column from the model. This
    way, we will get the probabilities for each species.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已经注意到的，我们的脚本在所有KPI中几乎相同。我们通过改变模型返回列的值来定义输出。这样，我们将获得每个物种的概率。
- en: Try to modify the values in input fields, and you should get a prediction and
    probabilities for each of the species in real time.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试修改输入字段中的值，你应该会实时获得每个物种的预测和概率。
- en: We have now successfully finished the application and learned how to utilize
    Qlik AutoML in a cloud environment, using both load-time and real-time integration.
    In the following section, we will look at setting up an on-premises environment
    to integrate with Qlik AutoML.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经成功完成了应用程序，并学习了如何在云环境中使用Qlik AutoML，同时使用加载时和实时集成。在下一节中，我们将探讨设置本地环境以与Qlik
    AutoML集成的过程。
- en: Connecting Qlik AutoML to an on-premises environment
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Qlik AutoML连接到本地环境
- en: Qlik AutoML is a cloud tool that integrates tightly with a cloud tenant. However,
    it is possible to utilize the features from an on-premises environment. It is
    important to note that since Qlik AutoML still runs in a cloud environment, all
    data is also passed into the Qlik Cloud tenant. This approach is not suitable
    if the data can’t leave the on-premises environment. The connection is encrypted
    and secure, and Qlik Cloud has all the major security certifications. It is also
    important to note that this approach will require a valid license for Qlik Cloud.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: Qlik AutoML是一个与云租户紧密集成的云工具。然而，可以利用本地环境的特性。需要注意的是，由于Qlik AutoML仍然在云环境中运行，所有数据也会传递到Qlik
    Cloud租户。如果数据不能离开本地环境，则此方法不适用。连接是加密和安全的，Qlik Cloud拥有所有主要的安全认证。还需要注意的是，此方法将需要有效的Qlik
    Cloud许可证。
- en: Note
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'More information about Qlik Cloud security and compliance is available at the
    Qlik Trust site: [https://www.qlik.com/us/trust](https://www.qlik.com/us/trust)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Qlik Cloud安全和合规性的更多信息可在Qlik信任网站上找到：[https://www.qlik.com/us/trust](https://www.qlik.com/us/trust)
- en: 'We can see the basic architecture of integrating AutoML with an on-premises
    environment in the following diagram:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下图中看到将AutoML与本地环境集成的基本架构：
- en: '![Figure 8.18: Qlik AutoML – on-premises and SaaS integration](img/B19863_08_18.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图8.18：Qlik AutoML – 本地与SaaS集成](img/B19863_08_18.jpg)'
- en: 'Figure 8.18: Qlik AutoML – on-premises and SaaS integration'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.18：Qlik AutoML – 本地与SaaS集成
- en: In the preceding diagram, we have our on-premises environment at the bottom.
    We will handle most of the data loads in the on-premises environment in this architecture.
    After preparing a machine-learning-ready dataset, we can utilize Qlik Data Gateway,
    the Qlik CLI, or manually upload to a cloud tenant. This data can be supplemented
    using data coming from other cloud sources. When our training data is in the cloud,
    training the machine learning model will involve the same process from the previous
    section. It is also possible to automate the whole process using tasks, application
    automation, and the Qlik CLI. Once the model is trained, we can then utilize the
    prediction API directly from the on-premises environment.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，我们的本地环境位于底部。在这个架构中，我们将在这个本地环境中处理大部分数据加载。在准备了一个机器学习准备好的数据集之后，我们可以利用 Qlik
    数据网关、Qlik CLI 或手动上传到云租户。这些数据可以使用来自其他云源的数据进行补充。当我们的训练数据在云中时，训练机器学习模型将涉及上一节中相同的流程。还可以使用任务、应用程序自动化和
    Qlik CLI 自动化整个流程。一旦模型训练完成，我们就可以直接从本地环境利用预测 API。
- en: Specific details about implementing the described environment are different
    in each organization. The preceding diagram can be used as a rough reference,
    but specific implementation should be planned case by case.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 关于实现所述环境的特定细节在每个组织中都不同。前面的图可以作为粗略的参考，但具体的实现应针对每个案例进行规划。
- en: The goal of this section was to give some ideas about the usage of Qlik AutoML
    in hybrid scenarios. In the following section, we will investigate some of the
    best practices when working with Qlik AutoML.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是提供一些关于在混合场景中使用 Qlik AutoML 的想法。在下一节中，我们将探讨一些使用 Qlik AutoML 的最佳实践。
- en: Best practices with Qlik AutoML
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Qlik AutoML 的最佳实践
- en: 'There are some general guidelines and best practices when working with Qlik
    AutoML. Following these practices and principles will make it easier to get accurate
    results and handle the machine learning project flow. The general principles include
    the following:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 Qlik AutoML 时，有一些通用的指南和最佳实践。遵循这些实践和原则将使您更容易获得准确的结果并处理机器学习项目流程。一般原则包括以下内容：
- en: '**Define the problem**: Clearly define the problem you are trying to solve
    with Qlik AutoML. Identify the variables you want to predict, and understand the
    available data. This is one of the most important best practices.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定义问题**：明确定义您使用 Qlik AutoML 尝试解决的问题。确定您想要预测的变量，并了解可用的数据。这是最重要的最佳实践之一。'
- en: '**Prepare and clean the data**: Ensure that your data is in a format suitable
    for analysis. This may involve cleaning missing values, handling outliers, transforming
    variables, cleaning duplicates, and making sure the data is well formatted. This
    is typically the most time-consuming part of machine learning projects.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准备和清理数据**：确保您的数据适合分析。这可能涉及清理缺失值、处理异常值、转换变量、清理重复项，并确保数据格式良好。这通常是机器学习项目中耗时最长的部分。'
- en: '**Feature engineering**: Explore and create meaningful features from your raw
    data. Qlik AutoML can automate some feature engineering tasks, but it’s still
    important to understand your data and apply domain knowledge to generate relevant
    features.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程**：从原始数据中探索和创建有意义的特征。Qlik AutoML 可以自动化一些特征工程任务，但仍然重要的是要了解您的数据并将领域知识应用于生成相关特征。'
- en: '**Interpretability and explainability**: Understand and interpret the results
    of your models. Qlik AutoML provides tools to interpret generated models, and
    understands the contribution of different features to the predictions.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性和可说明性**：理解和解释您模型的成果。Qlik AutoML 提供了解释生成的模型的工具，并了解不同特征对预测的贡献。'
- en: '**Validation and evaluation**: Use proper evaluation metrics to assess the
    performance of your models. Qlik AutoML can provide default metrics, but always
    cross-validate results when possible.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证和评估**：使用适当的评估指标来评估您模型的性能。Qlik AutoML 可以提供默认指标，但始终在可能的情况下交叉验证结果。'
- en: '**Monitoring and maintenance**: Continuously monitor the performance of your
    models in production. Update and retrain the models periodically as new data becomes
    available.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控和维护**：持续监控生产中模型的性能。当有新数据可用时，定期更新和重新训练模型。'
- en: '**Iterative process**: Machine learning is an iterative process, so be prepared
    to refine and improve your models based on feedback and new insights.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代过程**：机器学习是一个迭代过程，因此请准备好根据反馈和新见解对您的模型进行优化和改进。'
- en: Qlik AutoML is a powerful tool to build machine learning models in an automated
    way, and it can make it easier for end users to understand complex models. When
    utilizing the tool, and keeping in mind the basic principles described previously,
    organizations can get more out of their data. Remember that no machine learning
    tool is a magic box that can solve all the business problems in the world. The
    better you prepare the problem definition and training data, the more accurate
    results you will get from a model.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Qlik AutoML 是一个强大的工具，可以以自动化的方式构建机器学习模型，并且它可以使最终用户更容易理解复杂的模型。在利用该工具时，并牢记之前描述的基本原则，组织可以从他们的数据中获得更多。记住，没有任何机器学习工具是一个可以解决世界上所有商业问题的魔法盒子。你准备的问题定义和训练数据越好，从模型中获得的结果就越准确。
- en: Summary
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discovered the usage of Qlik AutoML. We first learned what
    the tool will provide for users and what its key features are. We built our first
    machine learning model with Qlik AutoML using the famous Iris dataset. In this
    section, we discovered how to run experiments and deploy a model from experimentation.
    We also discovered how to utilize the model in a Qlik application, both during
    a data load and in real time. We learned from different metrics how our model
    performed.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们发现了 Qlik AutoML 的用法。我们首先学习了该工具将为用户带来什么以及它的关键特性是什么。我们使用著名的 Iris 数据集，用
    Qlik AutoML 构建了我们第一个机器学习模型。在本节中，我们发现了如何运行实验并从实验中部署模型。我们还发现了如何在 Qlik 应用程序中利用模型，无论是在数据加载期间还是在实时中。我们从不同的指标中学习了我们的模型表现如何。
- en: In the latter part of this chapter, we took a quick look at an on-premises environment.
    We learned how to utilize Qlik AutoML in hybrid scenarios and how to set up our
    environment in these use cases. We also discovered some of the best practices
    to be used with Qlik AutoML.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后半部分，我们快速浏览了本地环境。我们学习了如何在混合场景中利用 Qlik AutoML 以及如何在这些用例中设置我们的环境。我们还发现了与 Qlik
    AutoML 一起使用的最佳实践。
- en: In the following chapter, we will dive deep into data visualization. We will
    discover the techniques to visualize machine-learning-related data and investigate
    the use of some of the lesser-used graph types. We will also learn about common
    charts and visualizations, and we will discover some of the settings and configurations
    that will help us get the most out of our data.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨数据可视化。我们将发现可视化机器学习相关数据的技术，并调查一些较少使用的图形类型的使用。我们还将了解常见的图表和可视化，并发现一些可以帮助我们充分利用数据的设置和配置。
