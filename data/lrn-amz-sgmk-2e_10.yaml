- en: 'Chapter 8: Using Your Algorithms and Code'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第八章：使用你的算法和代码
- en: In the previous chapter, you learned how to train and deploy models with built-in
    frameworks such as **scikit-learn** and **TensorFlow**. Thanks to **script mode**,
    these frameworks make it easy to use your own code, without having to manage any
    training or inference containers.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了如何使用内置框架（如 **scikit-learn** 和 **TensorFlow**）进行模型的训练和部署。通过 **脚本模式**，这些框架使你能够轻松使用自己的代码，而无需管理任何训练或推理容器。
- en: In some cases, your business or technical environment could make it difficult
    or even impossible to use these containers. Maybe you need to be in full control
    of how containers are built. Maybe you'd like to implement your own prediction
    logic. Maybe you're working with a framework or language that's not natively supported
    by SageMaker.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，你的业务或技术环境可能使得使用这些容器变得困难，甚至不可能使用。也许你需要完全控制容器的构建方式，也许你希望实现自己的预测逻辑，或者你正在使用
    SageMaker 本身不原生支持的框架或语言。
- en: In this chapter, you'll learn how to tailor training and inference containers
    to your own needs. You'll also learn how to train and deploy your own custom code,
    using either the SageMaker SDK directly or command-line open source tools.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何根据自己的需求定制训练和推理容器。你还将学习如何使用 SageMaker SDK 或命令行开源工具来训练和部署你自己的自定义代码。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding how SageMaker invokes your code
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 SageMaker 如何调用你的代码
- en: Customizing built-in framework containers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定制内置框架容器
- en: Building custom training containers with the SageMaker Training Toolkit
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 SageMaker 训练工具包构建自定义训练容器
- en: Building fully custom containers for training and inference with Python and
    R
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 和 R 构建完全自定义的训练和推理容器
- en: Training and deploying with your custom Python code on MLflow
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自定义 Python 代码在 MLflow 上进行训练和部署
- en: Building fully custom containers for SageMaker Processing
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为 SageMaker 处理构建完全自定义容器
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need an AWS account to run the examples included in this chapter. If
    you haven't got one already, please point your browser at [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    to create it. You should also familiarize yourself with the AWS Free Tier ([https://aws.amazon.com/free/](https://aws.amazon.com/free/)),
    which lets you use many AWS services for free within certain usage limits.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你将需要一个 AWS 账户才能运行本章中的示例。如果你还没有 AWS 账户，请访问[https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)创建一个。你还应该熟悉
    AWS 免费套餐（[https://aws.amazon.com/free/](https://aws.amazon.com/free/)），它允许你在一定的使用限制内免费使用许多
    AWS 服务。
- en: You will need to install and configure the AWS **Command-Line Interface** (**CLI**)
    for your account ([https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要为你的账户安装并配置 AWS **命令行界面**（**CLI**）（[https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)）。
- en: You will need a working Python 3.x environment. Installing the Anaconda distribution
    ([https://www.anaconda.com/](https://www.anaconda.com/)) is not mandatory but
    strongly encouraged as it includes many projects that we will need (Jupyter, `pandas`,
    `numpy`, and more).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要一个正常工作的 Python 3.x 环境。安装 Anaconda 发行版（[https://www.anaconda.com/](https://www.anaconda.com/)）不是强制性的，但强烈推荐，因为它包含了我们需要的许多项目（Jupyter、`pandas`、`numpy`
    等）。
- en: You will need a working Docker installation. You'll find installation instructions
    and documentation at [https://docs.docker.com](https://docs.docker.com).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你将需要一个正常工作的 Docker 安装环境。你可以在[https://docs.docker.com](https://docs.docker.com)找到安装说明和文档。
- en: The code examples included in this book are available on GitHub at [https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition](https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition).
    You will need to install a Git client to access them ([https://git-scm.com/](https://git-scm.com/)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中包含的代码示例可以在 GitHub 上找到：[https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition](https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition)。你需要安装
    Git 客户端来访问这些示例（[https://git-scm.com/](https://git-scm.com/)）。
- en: Understanding how SageMaker invokes your code
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 SageMaker 如何调用你的代码
- en: 'When we worked with built-in algorithms and frameworks, we didn''t pay much
    attention to how SageMaker actually invoked the training and deployment code.
    After all, that''s what "built-in" means: grab what you need off the shelf and
    get to work.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用内置算法和框架时，并没有太多关注 SageMaker 实际上是如何调用训练和部署代码的。毕竟，“内置”意味着：直接拿来需要的工具并开始工作。
- en: Of course, things are different if we want to use our own custom code and containers.
    We need to understand how they interface with SageMaker so that we implement them
    exactly right.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果我们想使用自定义代码和容器，情况就不一样了。我们需要了解它们如何与SageMaker接口，以便我们能够准确地实现它们。
- en: In this section, we'll discuss this interface in detail. Let's start with the
    file layout.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将详细讨论这一接口。让我们从文件布局开始。
- en: Understanding the file layout inside a SageMaker container
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解SageMaker容器内的文件布局
- en: To make our life simpler, SageMaker estimators automatically copy hyperparameters
    and input data inside training containers. Likewise, they automatically copy the
    trained model (and any checkpoints) from the container to S3\. At deployment time,
    they do the reverse operation, copying the model from S3 into the container.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化我们的工作，SageMaker估算器会自动将超参数和输入数据复制到训练容器中。同样，它们会自动将训练好的模型（以及任何检查点）从容器复制到S3。在部署时，它们会执行反向操作，将模型从S3复制到容器中。
- en: 'As you can imagine, this requires a file layout convention:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想，这要求遵循文件布局约定：
- en: Hyperparameters are stored as a JSON dictionary in `/opt/ml/input/config/hyperparameters.json`.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数以JSON字典形式存储在`/opt/ml/input/config/hyperparameters.json`中。
- en: Input channels are stored in `/opt/ml/input/data/CHANNEL_NAME`. We saw in the
    previous chapter that the channel names match the ones passed to the `fit()` API.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入通道存储在`/opt/ml/input/data/CHANNEL_NAME`中。我们在前一章中看到，通道名称与传递给`fit()` API的名称匹配。
- en: The model should be saved in and loaded from `/opt/ml/model`.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型应保存在`/opt/ml/model`中，并从该位置加载。
- en: Hence, we'll need to use these paths in our custom code. Now, let's see how
    the training and deployment code is invoked.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要在自定义代码中使用这些路径。现在，让我们看看如何调用训练和部署代码。
- en: Understanding the options for custom training
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解自定义训练选项
- en: In [*Chapter 7*](B17705_07_Final_JM_ePub.xhtml#_idTextAnchor130), *Extending
    Machine Learning Services Using Built-In Frameworks*, we studied script mode and
    how SageMaker uses it to invoke our training script. This feature is enabled by
    additional Python code present in the framework containers, namely, the SageMaker
    Training Toolkit ([https://github.com/aws/sagemaker-training-toolkit](https://github.com/aws/sagemaker-training-toolkit)).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第7章*](B17705_07_Final_JM_ePub.xhtml#_idTextAnchor130)，*使用内置框架扩展机器学习服务*中，我们研究了脚本模式以及SageMaker如何使用它来调用我们的训练脚本。此功能由框架容器中额外的Python代码启用，即SageMaker训练工具包（[https://github.com/aws/sagemaker-training-toolkit](https://github.com/aws/sagemaker-training-toolkit)）。
- en: In a nutshell, this training toolkit copies the entry point script, its hyperparameters,
    and its dependencies inside the container. It also copies data from the input
    channels inside the container. Then, it invokes the entry point script. Curious
    minds can read the code at `src/sagemaker_training/entry_point.py`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，训练工具包将入口脚本、其超参数和依赖项复制到容器内。它还将从输入通道中复制数据到容器中。然后，它会调用入口脚本。有好奇心的朋友可以阅读`src/sagemaker_training/entry_point.py`中的代码。
- en: 'When it comes to customizing your training code, you have the following options:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在自定义训练代码时，你有以下选项：
- en: Customize an existing framework container, adding only your extra dependencies
    and code. Script mode and the framework estimator will be available.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义现有的框架容器，只添加你额外的依赖和代码。脚本模式和框架估算器将可用。
- en: Build a custom container based solely on the SageMaker Training Toolkit. Script
    mode and the generic `Estimator` module will be available, but you'll have to
    install everything else.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于SageMaker训练工具包构建自定义容器。脚本模式和通用的`Estimator`模块将可用，但你需要安装其他所有依赖。
- en: Build a fully custom container. If you want to start from a blank page or don't
    want any extra code inside your container, this is the way to go. You'll train
    with the generic `Estimator` module, and script mode won't be available. Your
    training code will be invoked directly (more on this later).
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个完全自定义的容器。如果你想从头开始，或者不想在容器中添加任何额外的代码，这是最合适的选择。你将使用通用的`Estimator`模块进行训练，并且脚本模式将不可用。你的训练代码将直接调用（稍后会详细说明）。
- en: Understanding the options for custom deployment
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解自定义部署选项
- en: 'Framework containers include additional Python code for deployment. Here are
    the repositories for the most popular frameworks:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 框架容器包括用于部署的额外Python代码。以下是最流行框架的仓库：
- en: '**TensorFlow**: [https://github.com/aws/sagemaker-tensorflow-serving-container](https://github.com/aws/sagemaker-tensorflow-serving-container).
    Models are served with **TensorFlow Serving** ([https://www.tensorflow.org/tfx/guide/serving](https://www.tensorflow.org/tfx/guide/serving)).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow**: [https://github.com/aws/sagemaker-tensorflow-serving-container](https://github.com/aws/sagemaker-tensorflow-serving-container)。模型通过**TensorFlow
    Serving**提供服务 ([https://www.tensorflow.org/tfx/guide/serving](https://www.tensorflow.org/tfx/guide/serving))。'
- en: '**PyTorch**: [https://github.com/aws/sagemaker-pytorch-inference-toolkit](https://github.com/aws/sagemaker-pytorch-inference-toolkit).
    Models are served with **TorchServe** ([https://pytorch.org/serve](https://pytorch.org/serve)).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PyTorch**: [https://github.com/aws/sagemaker-pytorch-inference-toolkit](https://github.com/aws/sagemaker-pytorch-inference-toolkit)。模型通过**TorchServe**提供服务
    ([https://pytorch.org/serve](https://pytorch.org/serve))。'
- en: '**Apache MXNet**: [https://github.com/aws/sagemaker-mxnet-inference-toolkit](https://github.com/aws/sagemaker-mxnet-inference-toolkit).
    Models are served with the **Multi-Model Server** ([https://github.com/awslabs/multi-model-server](https://github.com/awslabs/multi-model-server)),
    integrated into the **SageMaker Inference Toolkit** ([https://github.com/aws/sagemaker-inference-toolkit](https://github.com/aws/sagemaker-inference-toolkit)).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache MXNet**: [https://github.com/aws/sagemaker-mxnet-inference-toolkit](https://github.com/aws/sagemaker-mxnet-inference-toolkit)。模型通过**多模型服务器**提供服务
    ([https://github.com/awslabs/multi-model-server](https://github.com/awslabs/multi-model-server))，并集成到**SageMaker
    推理工具包**中 ([https://github.com/aws/sagemaker-inference-toolkit](https://github.com/aws/sagemaker-inference-toolkit))。'
- en: '**Scikit-learn**: [https://github.com/aws/sagemaker-scikit-learn-container](https://github.com/aws/sagemaker-scikit-learn-container).
    Models are served with the Multi-Model Server.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scikit-learn**: [https://github.com/aws/sagemaker-scikit-learn-container](https://github.com/aws/sagemaker-scikit-learn-container)。模型通过多模型服务器提供服务。'
- en: '**XGBoost**: [https://github.com/aws/sagemaker-xgboost-container](https://github.com/aws/sagemaker-xgboost-container).
    Models are served with the Multi-Model Server.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**XGBoost**: [https://github.com/aws/sagemaker-xgboost-container](https://github.com/aws/sagemaker-xgboost-container)。模型通过多模型服务器提供服务。'
- en: 'Just like for training, you have three options:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 就像训练一样，你有三个选项：
- en: Customize an existing framework container. Models will be served using the existing
    inference logic.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义现有的框架容器。模型将使用现有的推理逻辑提供服务。
- en: Build a custom container based solely on the SageMaker Inference Toolkit. Models
    will be served by the Multi-Model Server.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于 SageMaker 推理工具包构建自定义容器。模型将由多模型服务器提供服务。
- en: Build a fully custom container, doing away with any inference logic and implementing
    your own instead.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个完全自定义的容器，去掉任何推理逻辑，改为实现自己的推理逻辑。
- en: 'Whether you use a single container for training and deployment or two different
    containers is up to you. A lot of different factors come into play: who builds
    the containers, who runs them, and so on. Only you can decide what the best option
    for your particular setup is.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是使用单一容器进行训练和部署，还是使用两个不同的容器，都取决于你。许多不同的因素会影响决策：谁构建容器、谁运行容器等等。只有你能决定对你的特定设置来说，哪个选项是最佳的。
- en: Now, let's run some examples!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们运行一些示例吧！
- en: Customizing an existing framework container
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义现有框架容器
- en: 'Of course, we could simply write a Dockerfile referencing one of the Deep Learning
    Containers images ([https://github.com/aws/deep-learning-containers/blob/master/available_images.md](https://github.com/aws/deep-learning-containers/blob/master/available_images.md))
    and add our own commands. See the following example:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们也可以简单地写一个 Dockerfile，引用其中一个深度学习容器镜像 ([https://github.com/aws/deep-learning-containers/blob/master/available_images.md](https://github.com/aws/deep-learning-containers/blob/master/available_images.md))，并添加我们自己的命令。请参见以下示例：
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Instead, let's customize and rebuild the **PyTorch** training and inference
    containers on our local machine. The process is similar to other frameworks.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，让我们在本地机器上自定义并重新构建**PyTorch**训练和推理容器。这个过程与其他框架类似。
- en: Build environment
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 构建环境
- en: Docker needs to be installed and running. To avoid throttling when pulling base
    images, I recommend that you create a `docker login` or **Docker Desktop**.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 需要安装并运行 Docker。为了避免在拉取基础镜像时受到限制，建议你创建一个`docker login`或**Docker Desktop**。
- en: 'To avoid bizarre dependency issues (I''m looking at you, macOS), I also recommend
    that you build images on an `m5.large` should suffice), but please make sure to
    provision more storage than the default 8 GB. I recommend 64 GB. You also need
    to make sure that the **IAM** role for the instance allows you to push and pull
    EC2 images. If you''re unsure how to create and connect to an EC2 instance, this
    tutorial will get you started: [https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免奇怪的依赖问题（我在看你，macOS），我还建议你在`m5.large`实例上构建镜像（应该足够），但请确保分配的存储空间超过默认的8GB。我推荐64GB。你还需要确保该EC2实例的**IAM**角色允许你推送和拉取EC2镜像。如果你不确定如何创建并连接到EC2实例，可以参考这个教程：[https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html)。
- en: Setting up your build environment on EC2
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在EC2上设置构建环境
- en: 'We will get started using the following steps:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下步骤开始：
- en: 'Once your EC2 instance is up, we connect to it with `ssh`. We first install
    Docker and add the `ec2-user` to the `docker` group. This will allow us to run
    Docker commands as a non-root user:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你的EC2实例启动，我们通过`ssh`连接到它。首先，我们安装Docker，并将`ec2-user`添加到`docker`组。这将允许我们以非root用户身份运行Docker命令：
- en: '[PRE1]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In order to apply this permission change, we log out and log in again.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了应用此权限更改，我们登出并重新登录。
- en: 'We make sure that `docker` is running and we log in to Docker Hub:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们确保`docker`正在运行，并登录到Docker Hub：
- en: '[PRE2]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We install `git`, Python 3, and `pip`:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们安装`git`、Python 3和`pip`：
- en: '[PRE3]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Our EC2 instance is now ready, and we can move on to building containers.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的EC2实例现在已经准备好，我们可以继续构建容器。
- en: Building training and inference containers
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建训练和推理容器
- en: 'This can be done using the following steps:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过以下步骤完成：
- en: 'We clone the `deep-learning-containers` repository, which centralizes all training
    and inference code for TensorFlow, PyTorch, Apache MXNet, and Hugging Face, and
    adds convenient scripts to build their containers:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们克隆`deep-learning-containers`仓库，该仓库集中管理TensorFlow、PyTorch、Apache MXNet和Hugging
    Face的所有训练和推理代码，并添加了便捷的脚本来构建这些容器：
- en: '[PRE4]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We set environment variables for our account ID, the region we''re running
    in, and the name of a new repository we''re going to create in Amazon ECR:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为我们的账户ID、运行所在的区域以及我们将在Amazon ECR中创建的新仓库的名称设置环境变量：
- en: '[PRE5]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We create the repository in Amazon ECR, and we log in. Please refer to the
    documentation for details ([https://docs.aws.amazon.com/ecr/index.html](https://docs.aws.amazon.com/ecr/index.html)):'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在Amazon ECR中创建仓库并登录。有关详细信息，请参阅文档（[https://docs.aws.amazon.com/ecr/index.html](https://docs.aws.amazon.com/ecr/index.html)）：
- en: '[PRE6]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We create a virtual environment, and we install the Python requirements:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个虚拟环境，并安装Python依赖：
- en: '[PRE7]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here, we''d like to build the training and inference containers for PyTorch
    1.8, on both the CPU and GPU. We can find the corresponding Docker files in `pytorch/training/docker/1.8/py3/`
    and customize them to our needs. For example, we could pin Deep Graph Library
    to version 0.6.1:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们想要为PyTorch 1.8构建训练和推理容器，支持CPU和GPU。我们可以在`pytorch/training/docker/1.8/py3/`找到相应的Docker文件，并根据需要进行定制。例如，我们可以将Deep
    Graph Library固定为版本0.6.1：
- en: '[PRE8]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Once we''ve edited the Docker files, we take a look at the build configuration
    file for the latest PyTorch version (`pytorch/buildspec.yml`). We decide to customize
    image tags to make sure each image is clearly identifiable:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑完Docker文件后，我们查看最新PyTorch版本的构建配置文件（`pytorch/buildspec.yml`）。我们决定自定义镜像标签，以确保每个镜像都能清楚地识别：
- en: '[PRE9]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, we run the setup script and launch the build process:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们运行设置脚本并启动构建过程：
- en: '[PRE10]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After a little while, all four images are built (plus an example image), and
    we can see them in our local Docker:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 稍等片刻，所有四个镜像（加上一个示例镜像）都已构建完成，我们可以在本地Docker中看到它们：
- en: '[PRE11]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can also see them in our ECR repository, as shown in the following screenshot:![Figure
    8.1 – Viewing images in ECR
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们也可以在ECR仓库中看到它们，如下图所示：![图8.1 – 在ECR中查看镜像
- en: '](img/B17705_08_1.jpg)'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_08_1.jpg)'
- en: Figure 8.1 – Viewing images in ECR
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图8.1 – 在ECR中查看镜像
- en: 'The images are now available with the SageMaker SDK. Let''s train with our
    new CPU image. All we have to do is pass its name in the `image_uri` parameter
    of the `PyTorch` estimator. Please note that we can remove `py_version` and `framework_version`:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在这些镜像可以通过SageMaker SDK使用。让我们用新的CPU镜像进行训练。我们只需要将其名称传递给`PyTorch`估算器的`image_uri`参数即可。请注意，我们可以去掉`py_version`和`framework_version`：
- en: '[PRE12]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As you can see, it's pretty easy to customize Deep Learning Containers. Now,
    let's go one level deeper and work only with the training toolkit.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，定制深度学习容器非常简单。现在，让我们深入一步，仅使用训练工具包进行操作。
- en: Using the SageMaker Training Toolkit with scikit-learn
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用带有 scikit-learn 的 SageMaker 训练工具包
- en: In this example, we're going to build a custom Python container with the SageMaker
    Training Toolkit. We'll use it to train a scikit-learn model on the Boston Housing
    dataset, using script mode and the `SKLearn` estimator.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用 SageMaker 训练工具包构建一个自定义 Python 容器。我们将使用它在波士顿房价数据集上训练一个 scikit-learn
    模型，使用脚本模式和 `SKLearn` 估算器。
- en: 'We need three building blocks:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要三个构建模块：
- en: The training script. Since script mode will be available, we can use exactly
    the same code as in the scikit-learn example from [*Chapter 7*](B17705_07_Final_JM_ePub.xhtml#_idTextAnchor130),
    *Extending Machine Learning Services Using Built-In Frameworks*.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练脚本。由于脚本模式将可用，我们可以使用与 [*第7章*](B17705_07_Final_JM_ePub.xhtml#_idTextAnchor130)
    中的 scikit-learn 示例完全相同的代码，*使用内置框架扩展机器学习服务*。
- en: We need a Dockerfile and Docker commands to build our custom container.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要一个 Dockerfile 和 Docker 命令来构建自定义容器。
- en: We also need an `SKLearn` estimator configured to use our custom container.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还需要一个配置为使用我们自定义容器的 `SKLearn` 估算器。
- en: 'Let''s take care of the container:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来处理容器：
- en: 'A Dockerfile can get quite complicated. No need for that here! We start from
    the official Python 3.7 image available on Docker Hub ([https://hub.docker.com/_/python](https://hub.docker.com/_/python)).
    We install scikit-learn, `numpy`, `pandas`, `joblib`, and the SageMaker Training
    Toolkit:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个 Dockerfile 可能会变得相当复杂，但这里我们不需要这么做！我们从 Docker Hub 上提供的官方 Python 3.7 镜像开始 ([https://hub.docker.com/_/python](https://hub.docker.com/_/python))。我们安装
    scikit-learn、`numpy`、`pandas`、`joblib` 和 SageMaker 训练工具包：
- en: '[PRE13]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We build the image with the `docker build` command, tagging it as `sklearn-customer:sklearn`:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 `docker build` 命令构建镜像，并将其标记为 `sklearn-customer:sklearn`：
- en: '[PRE14]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once the image is built, we find its identifier:'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 镜像构建完成后，我们可以找到其标识符：
- en: '[PRE15]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Using the AWS CLI, we create a repository in Amazon ECR to host this image,
    and we log in to the repository:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 AWS CLI，我们在 Amazon ECR 中创建一个仓库来托管这个镜像，并登录到该仓库：
- en: '[PRE16]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Using the image identifier, we tag the image with the repository identifier:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用镜像标识符，我们用仓库标识符标记镜像：
- en: '[PRE17]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We push the image to the repository:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将镜像推送到仓库：
- en: '[PRE18]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The image is now ready for training with a SageMaker estimator.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，镜像已经准备好用于使用 SageMaker 估算器进行训练。
- en: 'We define an `SKLearn` estimator, setting the `image_uri` parameter to the
    name of the container we just created:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义一个 `SKLearn` 估算器，将 `image_uri` 参数设置为我们刚创建的容器的名称：
- en: '[PRE19]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We set the location of the training channel and launch the training as usual.
    In the training log, we see that our code is indeed invoked with script mode:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们设置训练通道的位置，并像往常一样启动训练。在训练日志中，我们看到我们的代码确实以脚本模式被调用：
- en: '[PRE20]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As you can see, it's easy to customize training containers. Thanks to the SageMaker
    Training Toolkit, you can work just as with a built-in framework container. We
    used scikit-learn here, and you can do the same with all other frameworks.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，定制训练容器非常简单。得益于 SageMaker 训练工具包，你可以像使用内置框架容器一样工作。我们这里使用了 scikit-learn，你也可以对其他所有框架做同样的操作。
- en: However, we cannot use this container for deployment, as it doesn't contain
    any model-serving code. We should add bespoke code to launch a web app, which
    is exactly what we're going to do in the next example.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们不能将这个容器用于部署，因为它不包含任何模型服务代码。我们应该添加定制代码来启动一个 Web 应用程序，这正是我们在下一个示例中要做的。
- en: Building a fully custom container for scikit-learn
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为 scikit-learn 构建完全自定义的容器
- en: In this example, we're going to build a fully custom container without any AWS
    code. We'll use it to train a scikit-learn model on the Boston Housing dataset,
    using a generic `Estimator` module. With the same container, we'll deploy the
    model thanks to a Flask web application.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将构建一个完全自定义的容器，里面没有任何 AWS 代码。我们将使用它在波士顿房价数据集上训练一个 scikit-learn 模型，使用通用的
    `Estimator` 模块。使用相同的容器，我们将通过 Flask Web 应用程序部署该模型。
- en: We'll proceed in a logical way, first taking care of the training, and then
    updating the code to handle deployment.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按逻辑步骤进行操作，首先处理训练，然后更新代码以处理部署。
- en: Training with a fully custom container
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用完全自定义容器进行训练
- en: 'Since we can''t rely on script mode anymore, the training code needs to be
    modified. This is what it looks like, and you''ll easily figure out what''s happening
    here:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不能再依赖脚本模式，因此需要修改训练代码。这就是修改后的代码，你很容易就能理解它是怎么回事：
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Using the standard file layout for SageMaker containers, we read hyperparameters
    from their JSON file. Then, we load the dataset, train the model, and save it
    at the correct location.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SageMaker 容器的标准文件布局，我们从 JSON 文件中读取超参数。然后，我们加载数据集，训练模型，并将其保存在正确的位置。
- en: There's another very important difference, and we have to dive a bit into Docker
    to explain it. SageMaker will run the training container as `docker run <IMAGE_ID>
    train`, passing the `train` argument to the entry point of the container.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个非常重要的区别，我们需要深入了解 Docker 来解释它。SageMaker 将以 `docker run <IMAGE_ID> train`
    运行训练容器，并将 `train` 参数传递给容器的入口点。
- en: If your container has a predefined entry point, the `train` argument will be
    passed to it, say, `/usr/bin/python train`. If your container doesn't have a predefined
    entry point, `train` is the actual command that will be run.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的容器有预定义的入口点，`train` 参数将会传递给它，比如 `/usr/bin/python train`。如果容器没有预定义的入口点，`train`
    就是将要执行的实际命令。
- en: 'To avoid annoying issues, I recommend that your training code ticks the following
    boxes:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免烦人的问题，我建议你的训练代码满足以下要求：
- en: Name it `train`—no extension, just `train`.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命名为 `train`——没有扩展名，只是 `train`。
- en: Make it executable.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使其可执行。
- en: Make sure it's in the `PATH` value.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保它在 `PATH` 值中。
- en: The first line of the script should define the path to the interpreter, for
    example, `#!/usr/bin/env python`.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 脚本的第一行应该定义解释器的路径，例如 `#!/usr/bin/env python`。
- en: This should guarantee that your training code is invoked correctly whether your
    container has a predefined entry point or not.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该能保证无论你的容器是否有预定义的入口点，都能正确调用你的训练代码。
- en: 'We''ll take care of this in the Dockerfile, starting from an official Python
    image. Note that we''re not installing the SageMaker Training Toolkit any longer:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 Dockerfile 中处理这个问题，从官方的 Python 镜像开始。注意，我们不再安装 SageMaker 训练工具包：
- en: '[PRE22]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The name of the script is correct. It's executable, and `/usr/bin` is in `PATH`.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本名称正确。它是可执行的，且 `/usr/bin` 在 `PATH` 中。
- en: 'We should be all set—let''s create our custom container and launch a training
    job with it:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该准备好了——让我们创建自定义容器并用它启动训练任务：
- en: 'We build and push the image, using a different tag:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们构建并推送镜像，使用不同的标签：
- en: '[PRE23]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We update our notebook code to use the generic `Estimator` module:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们更新笔记本代码，使用通用的 `Estimator` 模块：
- en: '[PRE24]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We train as usual.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们照常进行训练。
- en: Now let's add code to deploy this model.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们添加代码来部署这个模型。
- en: Deploying a fully custom container
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署完全自定义容器
- en: Flask is a highly popular web framework for Python ([https://palletsprojects.com/p/flask](https://palletsprojects.com/p/flask)).
    It's simple and well documented. We're going to use it to build a simple prediction
    API hosted in our container.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Flask 是一个非常流行的 Python Web 框架（[https://palletsprojects.com/p/flask](https://palletsprojects.com/p/flask)）。它简单且文档齐全。我们将用它来构建一个托管在容器中的简单预测
    API。
- en: Just like for our training code, SageMaker requires that the deployment script
    is copied inside the container. The image will be run as `docker run <IMAGE_ID>
    serve`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们的训练代码一样，SageMaker 要求将部署脚本复制到容器内。镜像将以 `docker run <IMAGE_ID> serve` 运行。
- en: HTTP requests will be sent to port `8080`. The container must provide a `/ping`
    URL for health checks and an`/invocations` URL for prediction requests. We'll
    use CSV as the input format.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP 请求将发送到端口 `8080`。容器必须提供 `/ping` URL 进行健康检查，并提供 `/invocations` URL 处理预测请求。我们将使用
    CSV 格式作为输入。
- en: 'Hence, your deployment code needs to tick the following boxes:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你的部署代码需要满足以下要求：
- en: Name it `serve`—no extension, just `serve`.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命名为 `serve`——没有扩展名，只是 `serve`。
- en: Make it executable.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使其可执行。
- en: Make sure it's in `PATH`.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保它在 `PATH` 中。
- en: Make sure port `8080` is exposed by the container.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保容器暴露了端口`8080`。
- en: Provide code to handle the `/ping` and `/invocations` URLs.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供代码处理 `/ping` 和 `/invocations` URL。
- en: 'Here''s the updated Dockerfile. We install Flask, copy the deployment code,
    and open port `8080`:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这是更新后的 Dockerfile。我们安装 Flask，复制部署代码，并开放端口 `8080`：
- en: '[PRE25]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This is how we could implement a simple prediction service with Flask:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们如何用 Flask 实现一个简单的预测服务：
- en: 'We import the required modules. We load the model from `/opt/ml/model` and
    initialize the Flask application:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入所需的模块。我们从 `/opt/ml/model` 加载模型并初始化 Flask 应用程序：
- en: '[PRE26]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We implement the `/ping` URL for health checks, by simply returning HTTP code
    200 (OK):'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实现 `/ping` URL 来进行健康检查，方法是简单地返回 HTTP 代码 200（OK）：
- en: '[PRE27]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We implement the `/invocations` URL. If the content type is not `text/csv`,
    we return HTTP code 415 (Unsupported Media Type). If it is, we decode the request
    body and store it in a file-like memory buffer. Then, we read the CSV samples,
    predict them, and send the results:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实现了`/invocations` URL。如果内容类型不是`text/csv`，我们返回HTTP代码415（不支持的媒体类型）。如果是，我们解码请求体并将其存储在文件样式的内存缓冲区中。然后，我们读取CSV样本，进行预测，并发送结果：
- en: '[PRE28]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'At startup, the script launches the Flask app on port `8080`:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在启动时，脚本在8080端口上启动Flask应用程序：
- en: '[PRE29]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: That's not too difficult, even if you're not yet familiar with Flask.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 即使您还不熟悉Flask，这也不算太难。
- en: We rebuild and push the image, and then we train again with the same estimator.
    No change is required here.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们重新构建并推送镜像，然后使用相同的评估器再次进行训练。这里不需要进行任何更改。
- en: 'We deploy the model:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们部署模型：
- en: '[PRE30]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Reminder
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提醒
- en: If you see some weird behavior here (the endpoint not deploying, cryptic error
    messages, and so on), Docker is probably hosed. `sudo service docker restart`
    should fix most problems. Cleaning `tmp*` cruft in `/tmp` may also help.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您在这里看到一些奇怪的行为（端点未部署、密秘的错误消息等），Docker可能出了问题。`sudo service docker restart`应该能解决大多数问题。在`/tmp`中清理`tmp*`可能也会有所帮助。
- en: 'We prepare a couple of test samples, set the content type to `text/csv`, and
    invoke the prediction API:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们准备了一些测试样本，将内容类型设置为`text/csv`，并调用预测API：
- en: '[PRE31]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'You should see something similar to this. The API has been successfully invoked:'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该会看到类似于此的内容。API已成功调用：
- en: '[PRE32]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'When we''re done, we delete the endpoint:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，我们删除端点：
- en: '[PRE33]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: In the next example, we're going to train and deploy a model using the R environment.
    This will give us an opportunity to step out of the Python world for a bit. As
    you will see, things are not really different.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个例子中，我们将使用R环境来训练和部署模型。这将让我们有机会暂时离开Python世界。正如您将看到的那样，事情并没有真正不同。
- en: Building a fully custom container for R
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个完全自定义的R容器
- en: R is a popular language for data exploration and analysis. In this example,
    we're going to build a custom container to train and deploy a linear regression
    model on the Boston Housing dataset.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: R是一种用于数据探索和分析的流行语言。在本例中，我们将构建一个自定义容器，以在波士顿房屋数据集上训练和部署线性回归模型。
- en: The overall process is similar to building a custom container for Python. Instead
    of using Flask to build our prediction API, we'll use `plumber` ([https://www.rplumber.io](https://www.rplumber.io)).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程与为Python构建自定义容器类似。我们将使用`plumber`而不是Flask来构建我们的预测API：
- en: Coding with R and plumber
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用R和plumber进行编码
- en: 'Don''t worry if you''re not familiar with R. This is a really simple example,
    and I''m sure you''ll be able to follow along:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对R不太熟悉，不要担心。这是一个非常简单的例子，我相信你能跟上：
- en: 'We write a function to train our model. It loads the hyperparameters and the
    dataset from the conventional paths. It normalizes the dataset if we requested
    it:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们编写一个函数来训练我们的模型。它从常规路径加载超参数和数据集。如果我们请求的话，它会对数据集进行标准化：
- en: '[PRE34]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'It trains a linear regression model, taking all features into account to predict
    the median house price (the `medv` column). Finally, it saves the model in the
    right place:'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 它训练一个线性回归模型，考虑所有特征来预测房屋的中位数价格（`medv`列）。最后，它将模型保存在正确的位置：
- en: '[PRE35]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We write a function to serve predictions. Using `plumber` annotations, we define
    a `/ping` URL for health checks and an`/invocations` URL for predictions:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们编写一个函数来提供预测服务。使用`plumber`注解，我们为健康检查定义了`/ping` URL，为预测定义了`/invocations` URL：
- en: '[PRE36]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Putting these two pieces together, we write a main function that will serve
    as the entry point for our script. SageMaker will pass either a `train` or `serve`
    command-line argument, and we''ll call the corresponding function in our code:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这两个部分结合在一起，我们编写一个主函数，它将作为我们脚本的入口点。SageMaker将传递`train`或`serve`命令行参数，并在我们的代码中调用相应的函数：
- en: '[PRE37]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This is all of the R code that we need. Now, let's take care of the container.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们需要的所有R代码。现在，让我们来处理容器。
- en: Building a custom container
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建自定义容器
- en: 'We need to build a custom container storing the R runtime, as well as our script.
    The Dockerfile is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要构建一个自定义容器，存储R运行时和我们的脚本。Dockerfile如下所示：
- en: 'We start from an official R image in **Docker Hub** and add the dependencies
    we need (these are the ones I needed on my machine; your mileage may vary):'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从**Docker Hub**的官方R镜像开始，并添加我们需要的依赖项（这些是我在我的机器上需要的；您的情况可能有所不同）：
- en: '[PRE38]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Then, we copy our code inside the container and define the main function as
    its explicit entry point:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将我们的代码复制到容器中，并将主函数定义为其显式入口点：
- en: '[PRE39]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We create a new repository in ECR. Then, we build the image (this could take
    a while and involve compilation steps) and push it:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在ECR中创建一个新仓库。然后，我们构建镜像（这可能需要一段时间，并涉及编译步骤），并推送它：
- en: '[PRE40]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We're all set, so let's train and deploy.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一切准备就绪，让我们开始训练并部署。
- en: Training and deploying a custom container on SageMaker
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在SageMaker上训练和部署自定义容器
- en: 'Jumping to a Jupyter notebook, we use the SageMaker SDK to train and deploy
    our container:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 跳转到Jupyter笔记本，我们使用SageMaker SDK训练并部署我们的容器：
- en: 'We configure an `Estimator` module with our custom container:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们配置一个带有自定义容器的`Estimator`模块：
- en: '[PRE41]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Once the training job is complete, we deploy the model as usual:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦训练任务完成，我们像往常一样部署模型：
- en: '[PRE42]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Finally, we read the full dataset (why not?) and send it to the endpoint:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们读取完整的数据集（为什么不呢？）并将其发送到端点：
- en: '[PRE43]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The output should look like this:'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该像这样：
- en: '[PRE44]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'When we''re done, we delete the endpoint:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，我们删除端点：
- en: '[PRE45]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Whether you're using Python, R, or something else, it's reasonably easy to build
    and deploy your own custom container. Still, you need to build your own little
    web application, which is something you may neither know how to do nor enjoy doing.
    Wouldn't it be nice if we had a tool that took care of all of that pesky container
    and web stuff?
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用Python、R，还是其他语言，构建和部署你自己的自定义容器都相对容易。然而，你仍然需要构建自己的网站应用程序，这可能是你既不知道如何做，也不喜欢做的事。如果我们有一个工具来处理所有这些麻烦的容器和网站问题，那该多好？
- en: 'As a matter of fact, there is one: **MLflow**.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，确实有一个平台：**MLflow**。
- en: Training and deploying with your own code on MLflow
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用你自己的代码在MLflow上进行训练和部署
- en: MLflow is an open source platform for machine learning ([https://mlflow.org](https://mlflow.org)).
    It was initiated by Databricks ([https://databricks.com](https://databricks.com)),
    who also brought us **Spark**. MLflow has lots of features, including the ability
    to deploy Python-trained models on SageMaker.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow是一个开源机器学习平台（[https://mlflow.org](https://mlflow.org)）。它由Databricks（[https://databricks.com](https://databricks.com)）发起，Databricks还为我们带来了**Spark**。MLflow有许多功能，包括能够将Python训练的模型部署到SageMaker。
- en: This section is not intended to be an MLflow tutorial. You can find documentation
    and examples at [https://www.mlflow.org/docs/latest/index.html](https://www.mlflow.org/docs/latest/index.html).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 本节并非旨在作为MLflow教程。你可以在[https://www.mlflow.org/docs/latest/index.html](https://www.mlflow.org/docs/latest/index.html)找到文档和示例。
- en: Installing MLflow
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装MLflow
- en: 'On our local machine, let''s set up a virtual environment for MLflow and install
    the required libraries. The following example was tested with MLflow 1.17:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地机器上，让我们为MLflow设置一个虚拟环境并安装所需的库。以下示例是在MLflow 1.17上测试的：
- en: 'We first initialize a new virtual environment named `mlflow-example`. Then,
    we activate it:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先初始化一个名为`mlflow-example`的新虚拟环境。然后，我们激活它：
- en: '[PRE46]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We install MLflow and the libraries required by our training script:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们安装了MLflow和训练脚本所需的库：
- en: '[PRE47]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Finally, we download the Direct Marketing dataset we already used with XGBoost
    in [*Chapter 7*](B17705_07_Final_JM_ePub.xhtml#_idTextAnchor130), *Extending Machine
    Learning Services Using Built-In Frameworks*:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们下载已经在[*第7章*](B17705_07_Final_JM_ePub.xhtml#_idTextAnchor130)中使用过的直接营销数据集，*使用内置框架扩展机器学习服务*：
- en: '[PRE48]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: The setup is complete. Let's train the model.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 设置完成。让我们开始训练模型。
- en: Training a model with MLflow
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用MLflow训练模型
- en: 'The training script sets the MLflow experiment for this run so that we may
    log metadata (hyperparameters, metrics, and so on). Then, it loads the dataset,
    trains an XGBoost classifier, and logs the model:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 训练脚本为此次运行设置了MLflow实验，以便我们可以记录元数据（超参数、指标等）。然后，它加载数据集，训练一个XGBoost分类器，并记录模型：
- en: '[PRE49]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The `load_dataset()` function does what its name implies and logs several parameters:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '`load_dataset()`函数按其名称所示执行，并记录多个参数：'
- en: '[PRE50]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Let''s train the model and visualize its results in the MLflow web application:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们训练模型并在MLflow Web应用程序中可视化其结果：
- en: 'Inside the virtual environment we just created on our local machine, we run
    the training script just like any Python program:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们刚刚在本地机器上创建的虚拟环境中，我们像运行任何Python程序一样运行训练脚本：
- en: '[PRE51]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We launch the MLflow web application:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们启动MLflow Web应用程序：
- en: '[PRE52]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Pointing our browser at [http://localhost:5000](http://localhost:5000), we
    see information on our run, as shown in the following screenshot:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们将浏览器指向[http://localhost:5000](http://localhost:5000)时，我们可以看到运行的信息，如下图所示：
- en: '![Figure 8.2 – Viewing our job in MLflow'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.2 – 在MLflow中查看我们的任务'
- en: '](img/B17705_08_2.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17705_08_2.jpg)'
- en: Figure 8.2 – Viewing our job in MLflow
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 在MLflow中查看我们的任务
- en: The training was successful. Before we can deploy the model on SageMaker, we
    must build a SageMaker container. As it turns out, it's the simplest thing.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 训练成功了。在我们将模型部署到 SageMaker 之前，我们必须构建一个 SageMaker 容器。事实证明，这是一件非常简单的事。
- en: Building a SageMaker container with MLflow
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 MLflow 构建 SageMaker 容器
- en: 'All it takes is a single command on our local machine:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 只需在本地机器上执行一个命令：
- en: '[PRE53]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: MLflow will automatically build a Docker container compatible with SageMaker,
    with all required dependencies. Then, it creates a repository in Amazon ECR named
    `mlflow-pyfunc` and pushes the image to it. Obviously, this requires your AWS
    credentials to be properly set up. MLflow will use the default region configured
    by the AWS CLI.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 会自动构建一个与 SageMaker 兼容的 Docker 容器，并包含所有所需的依赖项。然后，它会在 Amazon ECR 中创建一个名为
    `mlflow-pyfunc` 的仓库，并将镜像推送到该仓库。显然，这需要你正确设置 AWS 凭证。MLflow 将使用 AWS CLI 配置的默认区域。
- en: 'Once this command completes, you should see the image in ECR, as shown in the
    following screenshot:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这个命令完成，你应该会在 ECR 中看到镜像，如下图所示：
- en: '![Figure 8.3 – Viewing our container in ECR'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.3 – 查看我们的容器在 ECR 中](img/B17705_08_3.jpg)'
- en: '](img/B17705_08_3.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17705_08_3.jpg)'
- en: Figure 8.3 – Viewing our container in ECR
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – 查看我们的容器在 ECR 中
- en: Our container is now ready for deployment.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的容器现在已经准备好部署了。
- en: Deploying a model locally with MLflow
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在本地部署模型使用 MLflow
- en: 'We will deploy our model using the following steps:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下步骤部署我们的模型：
- en: 'We can deploy our model locally with a single command, passing its run identifier
    (visible in the MLflow URL for the run) and the HTTP port to use. This fires up
    a local web application based on `gunicorn`:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过一个命令在本地部署我们的模型，传递其运行标识符（可以在 MLflow 运行的 URL 中看到）和要使用的 HTTP 端口。这将启动一个基于
    `gunicorn` 的本地 Web 应用程序：
- en: '[PRE54]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'You should see something similar to this:'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该看到类似这样的内容：
- en: '[PRE55]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Our prediction code is quite straightforward. We load CSV samples from the
    dataset, convert them into JSON format, and send them to the endpoint using the
    `requests` library, a popular Python library for HTTP ([https://requests.readthedocs.io](https://requests.readthedocs.io)):'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的预测代码非常简单。我们从数据集加载 CSV 样本，将它们转换为 JSON 格式，并使用 `requests` 库发送到端点。`requests`
    是一个流行的 Python HTTP 库（[https://requests.readthedocs.io](https://requests.readthedocs.io)）：
- en: '[PRE56]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Running this code in another shell invokes the local model and prints out predictions:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在另一个 shell 中运行此代码，调用本地模型并输出预测结果：
- en: '[PRE57]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: When we're done, we terminate the local server with *Ctrl* + *C*.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，我们使用 *Ctrl* + *C* 终止本地服务器。
- en: Now that we're confident that our model works locally, we can deploy it on SageMaker.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们确信我们的模型在本地可以正常工作，我们可以将它部署到 SageMaker。
- en: Deploying a model on SageMaker with MLflow
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 MLflow 在 SageMaker 上部署模型
- en: 'This is a one-liner again:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这又是一个一行命令：
- en: 'We need to pass an application name, the model path, and the name of the SageMaker
    role. You can use the same role you''ve used in previous chapters:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要传递一个应用程序名称、模型路径和 SageMaker 角色的名称。你可以使用你在前几章中使用过的相同角色：
- en: '[PRE58]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'After a few minutes, the endpoint is in service. We invoke it with the following
    code. It loads the test dataset and sends the first 10 samples in JSON format
    to the endpoint named after our application:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 几分钟后，端点进入服务状态。我们使用以下代码调用它。它加载测试数据集，并将前 10 个样本以 JSON 格式发送到以我们的应用程序命名的端点：
- en: '[PRE59]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Wait a minute! We are not using the SageMaker SDK. What's going on here?
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 等一下！我们没有使用 SageMaker SDK。这是怎么回事？
- en: In this example, we're dealing with an existing endpoint, not an endpoint that
    we created by fitting an estimator and deploying a predictor.
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个例子中，我们处理的是一个现有的端点，而不是通过拟合估算器并部署预测器创建的端点。
- en: We could still rebuild a predictor using the SageMaker SDK, as we'll see in
    [*Chapter 11*](B17705_11_Final_JM_ePub.xhtml#_idTextAnchor237), *Deploying Machine
    Learning Models*. Instead, we use our good old friend `boto3`, the AWS SDK for
    Python. We first invoke the `describe_endpoint()` API to check that the endpoint
    is in service. Then, we use the `invoke_endpoint()` API to…invoke the endpoint!
    For now, we don't need to know more.
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们仍然可以使用 SageMaker SDK 重新构建一个预测器，正如我们将在 [*第 11 章*](B17705_11_Final_JM_ePub.xhtml#_idTextAnchor237)
    中看到的那样，*部署机器学习模型*。不过，我们使用了我们亲爱的老朋友 `boto3`，AWS 的 Python SDK。我们首先调用 `describe_endpoint()`
    API 来检查端点是否在服务中。然后，我们使用 `invoke_endpoint()` API 来……调用端点！现在，我们暂时不需要了解更多。
- en: 'We run the prediction code on our local machine, and it produces the following
    output:'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在本地机器上运行预测代码，输出结果如下：
- en: '[PRE60]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'When we''re done, we delete the endpoint with the MLflow CLI. This cleans up
    all resources created for deployment:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，我们使用 MLflow CLI 删除端点。这会清理为部署创建的所有资源：
- en: '[PRE61]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: The development experience with MLflow is pretty simple. It also has plenty
    of other features you may want to explore.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 使用MLflow的开发经验非常简单。它还有许多其他功能，您可能想要探索。
- en: So far, we've run examples for training and prediction. There's another area
    of SageMaker that lets us use custom containers, **SageMaker Processing**, which
    we studied in [*Chapter 2*](B17705_02_Final_JM_ePub.xhtml#_idTextAnchor030), *Handling
    Data Preparation Techniques*. To close this chapter, let's build a custom Python
    container for SageMaker Processing.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经运行了训练和预测的示例。SageMaker还有一个领域可以让我们使用自定义容器，**SageMaker Processing**，我们在[*第二章*](B17705_02_Final_JM_ePub.xhtml#_idTextAnchor030)中研究了它，*处理数据准备技术*。为了结束这一章，让我们为SageMaker
    Processing构建一个自定义的Python容器。
- en: Building a fully custom container for SageMaker Processing
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为SageMaker处理构建一个完全自定义的容器
- en: 'We''ll reuse the news headlines example from [*Chapter 6*](B17705_06_Final_JM_ePub.xhtml#_idTextAnchor108),
    *Training Natural Processing Models*:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重用来自[*第六章*](B17705_06_Final_JM_ePub.xhtml#_idTextAnchor108)的新闻头条示例，*训练自然语言处理模型*：
- en: 'We start with a Dockerfile based on a minimal Python image. We install dependencies,
    add our processing script, and define it as our entry point:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从一个基于最小Python镜像的Dockerfile开始。我们安装依赖项，添加处理脚本，并将其定义为我们的入口点：
- en: '[PRE62]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'We build the image and tag it as `sm-processing-custom:latest`:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们构建镜像并将其标记为`sm-processing-custom:latest`：
- en: '[PRE63]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Using the AWS CLI, we create a repository in Amazon ECR to host this image,
    and we log in to the repository:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用AWS CLI，我们在Amazon ECR中创建一个存储库来托管这个镜像，并登录到该存储库：
- en: '[PRE64]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Using the image identifier, we tag the image with the repository identifier:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用镜像标识符，我们用存储库标识符为镜像打标签：
- en: '[PRE65]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'We push the image to the repository:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将镜像推送到存储库：
- en: '[PRE66]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Moving to a Jupyter notebook, we configure a generic `Processor` object with
    our new container, which is the equivalent of the generic `Estimator` module we
    used for training. Accordingly, no `framework_version` parameter is required:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换到Jupyter笔记本，我们使用新的容器配置一个通用的`Processor`对象，它相当于我们用于训练的通用`Estimator`模块。因此，不需要`framework_version`参数：
- en: '[PRE67]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Using the same `ProcessingInput` and `ProcessingOutput` objects, we run the
    processing job. As our processing code is now stored inside the container, we
    don''t need to pass a `code` parameter as we did with `SKLearnProcessor`:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用相同的`ProcessingInput`和`ProcessingOutput`对象，我们运行处理作业。由于我们的处理代码现在存储在容器内，我们不需要像使用`SKLearnProcessor`时那样传递`code`参数：
- en: '[PRE68]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Once the training job is complete, we can fetch its outputs in S3.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦训练作业完成，我们可以在S3中获取其输出。
- en: This concludes our exploration of custom containers in SageMaker. As you can
    see, you can pretty much run anything as long as it fits inside a Docker container.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们对SageMaker中自定义容器的探索。如您所见，只要它适合Docker容器，几乎可以运行任何东西。
- en: Summary
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: Built-in frameworks are extremely useful, but sometimes you need something a
    little—or very—different. Whether starting from built-in containers or from scratch,
    SageMaker lets you build your training and deployment containers exactly the way
    you want them. Freedom for all!
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 内置框架非常有用，但有时您需要一些稍微——或完全——不同的东西。无论是从内置容器开始还是从头开始，SageMaker让您可以完全按照自己的需求构建训练和部署容器。自由为所有人！
- en: In this chapter, you learned how to customize Python and R containers for data
    processing, training, and deployment. You saw how you could use them with the
    SageMaker SDK and its usual workflow. You also learned about MLflow, a nice open
    source tool that lets you train and deploy models using a CLI.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学习了如何为数据处理、训练和部署定制Python和R容器。您还看到了如何使用SageMaker SDK及其常规工作流程来使用这些容器。您还了解了MLflow，这是一个非常好的开源工具，允许您使用CLI训练和部署模型。
- en: 'This concludes our extensive coverage of modeling options in SageMaker: built-in
    algorithms, built-in frameworks, and custom code. In the next chapter, you''ll
    learn about SageMaker features that help you to scale your training jobs.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们对SageMaker建模选项的广泛介绍：内置算法、内置框架和自定义代码。在下一章中，您将学习SageMaker的功能，帮助您扩展训练作业。
