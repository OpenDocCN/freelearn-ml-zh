- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: We are living on the verge of a new era of computing, an era where computers
    are becoming more of a companion than a tool. The devices we carry in our pockets
    will soon better understand our world and us a lot better, and this will have
    a profound impact on how we interact with and use them.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正处于一个新时代的计算边缘，在这个时代，计算机更多地成为我们的伴侣而不是工具。我们口袋里的设备将很快更好地理解我们的世界和我们自己，这将对我们如何与之互动和使用它们产生深远的影响。
- en: But right now, a lot of these exciting advancements are stuck in the labs of
    researchers and not in the hands of designers and developers, making them usable
    and accessible to users. This is not because the details are locked away; on the
    contrary, in most cases they are freely available.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 但目前，许多这些令人兴奋的进步都停留在研究人员的实验室里，而不是设计师和开发者的手中，这使得它们对用户可用和可访问。这并不是因为细节被锁起来；相反，在大多数情况下，它们是免费可用的。
- en: This gap is somewhat due to our contentment with sticking to what we know, having
    the user do all the work, making them tap on the buttons. If nothing else, I hope
    this book makes you curious about what is out there and how it can be used to
    create new experiences, or improve existing ones.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这种差距部分是由于我们满足于坚持我们所知道的，让用户做所有的工作，让他们点击按钮。如果其他什么都没有，我希望这本书能让你对现有的东西感到好奇，以及如何用它来创造新的体验，或者改善现有的体验。
- en: Within the pages of this book, you will find a series of examples to help you
    build an understanding of how deep neural networks work and how they can be applied.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的页面上，您将找到一系列示例，帮助您了解深度神经网络的工作原理以及它们如何被应用。
- en: This book focuses on a set of models for a better understanding of images and
    photos, specifically looking at how they can be adapted and applied on the iOS
    platform. This narrow focus of image-based models and the iOS platform is intentional;
    I find that the visual nature of images makes the concepts easier to, well, visualize,
    and the iPhone provides the perfect candidate and environment for experimentation.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本书专注于一系列模型，以更好地理解图像和照片，特别是研究它们如何在 iOS 平台上进行适配和应用。这种基于图像的模型和 iOS 平台的狭窄关注是有意为之的；我发现图像的视觉性质使得概念更容易可视化，而
    iPhone 提供了完美的候选者和实验环境。
- en: So, as you go through this book, I encourage you to start thinking about new
    ways of how these models can be used and what new experiences you could create.
    With that being said, let's get started!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当你阅读这本书时，我鼓励你开始思考这些模型的新用途以及你可以创造的新体验。话虽如此，让我们开始吧！
- en: Who this book is for
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书面向的对象
- en: This book will appeal to three broad groups of people. The first are intermediate
    iOS developers who are interested in learning and applying **machine learning**
    (**ML**); some exposure to ML concepts may be beneficial but are not essential
    as this book covers the intuition behind the concepts and models used throughout
    it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将吸引三个广泛的读者群体。第一群是中级 iOS 开发者，他们对学习和应用**机器学习**（**ML**）感兴趣；对 ML 概念的一些了解可能有益，但并非必需，因为本书涵盖了其中使用的概念和模型背后的直觉。
- en: The second group are those who have experience in ML but not in iOS development
    and are looking for a resource to help them to get the grips with Core ML; for
    this group, it is recommended to complement this book with a book that covers
    the fundamentals of iOS development.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 第二群是有 ML 经验但没有 iOS 开发经验的人，他们正在寻找资源来帮助他们掌握 Core ML；对于这一群体，建议与一本涵盖 iOS 开发基础的书一起阅读。
- en: The last group are experienced iOS developers and ML practitioners who are curious
    to see how various models have been applied in the context of the iOS platform.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 第三群是经验丰富的 iOS 开发者和 ML 实践者，他们好奇地想看看各种模型在 iOS 平台背景下的应用情况。
- en: What this book covers
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖的内容
- en: '[Chapter 1](7d4f641f-7137-4a8a-ae6e-2bb0e2a6db5c.xhtml), *Introduction to Machine
    Learning*, provides a brief introduction to ML, including some explanation of
    the core concepts, the types of problems, algorithms, and general workflow of
    creating and using a ML models. The chapter concludes by exploring some examples
    where ML is being applied.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[第一章](7d4f641f-7137-4a8a-ae6e-2bb0e2a6db5c.xhtml)，*机器学习简介*，简要介绍了 ML，包括一些对核心概念、问题类型、算法以及创建和使用
    ML 模型的一般工作流程的解释。本章通过探讨一些 ML 正在被应用的例子结束。'
- en: '[Chapter 2](e62127d6-36b4-4a52-8878-52de22374010.xhtml), *Introduction to Apple
    Core ML*, introduces Core ML, discussing what it is, what it is not, and the general
    workflow for using it.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[第二章](e62127d6-36b4-4a52-8878-52de22374010.xhtml)，*苹果核心 ML 简介*，介绍了 Core ML，讨论了它是什么，它不是什么，以及使用它的一般工作流程。'
- en: '[Chapter 3](5cf26de5-5f92-4d1d-8b83-3e28368df233.xhtml), *Recognizing Objects
    in the World*, walks through building a Core ML application from start to finish.
    By the end of the chapter, we would have been through the whole process of obtaining
    a model, importing it into the project, and making use of it.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[第3章](5cf26de5-5f92-4d1d-8b83-3e28368df233.xhtml)，*识别世界中的物体*，从零开始构建Core ML应用程序。到本章结束时，我们将完成获取模型、将其导入项目以及使用它的整个过程。'
- en: '[Chapter 4](a89287b3-5c90-4f77-801f-371f7a8f2d36.xhtml), *Emotion Detection
    with CNNs*, explores the possibilities of computers understanding us better, specifically
    our mood. We start by building our intuition of how ML can learn to infer your
    mood, and then put this to practice by building an application that does just
    that. We also use this as an opportunity to introduce the Vision framework and
    see how it complements Core ML.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[第4章](a89287b3-5c90-4f77-801f-371f7a8f2d36.xhtml)，*使用CNN进行情感检测*，探讨了计算机更好地理解我们的可能性，特别是我们的情绪。我们首先建立机器学习如何推断你的情绪的直觉，然后通过构建一个执行此操作的应用程序来将其付诸实践。我们还利用这个机会介绍Vision框架，并了解它如何补充Core
    ML。'
- en: '[Chapter 5](6365f272-41e9-4511-a564-dc0f8db5d3ca.xhtml), *Locating Objects
    in the World*, goes beyond recognizing a single object to being able to recognize
    and locate multiple objects within a single image through object detection. After
    building our understanding of how it works, we move on to applying it to a visual
    search application that filters not only by object but also by composition of
    objects. In this chapter, we''ll also get an opportunity to extend Core ML by
    implementing customer layers.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[第5章](6365f272-41e9-4511-a564-dc0f8db5d3ca.xhtml)，*在世界上定位物体*，不仅限于识别单个物体，而且能够通过物体检测在单个图像中识别和定位多个物体。在理解其工作原理后，我们将将其应用于一个视觉搜索应用程序，该应用程序不仅根据物体进行过滤，还根据物体的组合进行过滤。在本章中，我们还将有机会通过实现自定义层来扩展Core
    ML。'
- en: '[Chapter 6](40971e0d-b260-42e1-a9fb-5c4a56b0ebb2.xhtml), *Creating Art with
    Style Transfer*, uncovers the secrets behind the popular photo effects application,
    Prisma. We start by discussing how a model can be taught to differentiate between
    the style and content of an image, and then go on to build a version of  Prisma
    that applies a style from one image to another. We wrap up this chapter by looking
    at ways to optimize the model.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](40971e0d-b260-42e1-a9fb-5c4a56b0ebb2.xhtml)，*使用风格迁移创建艺术*，揭示了流行的照片效果应用程序Prisma背后的秘密。我们首先讨论如何训练模型区分图像的风格和内容，然后继续构建一个将一种图像的风格应用到另一种图像上的Prisma版本。在本章的最后，我们将探讨优化模型的方法。'
- en: '[Chapter 7](8c90b4c8-30dc-4096-88f5-d9705f13f147.xhtml), *Assisted Drawing
    with CNNs*, walks through building an application that can recognize a users sketch
    using the same concepts that have been introduced in previous chapters. Once what
    the user is trying to sketch has been recognized, we look at how we can find similar
    substitutes using the feature vectors from a CNN.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](8c90b4c8-30dc-4096-88f5-d9705f13f147.xhtml)，*使用CNN辅助绘图*，介绍了如何构建一个应用程序，该程序可以使用之前章节中介绍的概念来识别用户的草图。一旦识别出用户试图绘制的对象，我们将探讨如何使用CNN的特征向量找到类似的替代品。'
- en: '[Chapter 8](9be42b58-ce74-4863-8a3c-7ae3060cdc14.xhtml), *Assisted Drawing
    with RNNs*, builds on the previous chapter and explores replacing the the **convolution
    neural network** (**CNN**) with a **recurrent neural network** (**RNN**) for sketch
    classification, thus introducing RNNs and showing how they can be applied to images.
    Along with a discussion on learning sequences, we will also delve into the details
    of how to download and compile Core ML models remotely.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[第8章](9be42b58-ce74-4863-8a3c-7ae3060cdc14.xhtml)，*使用RNNs辅助绘图*，在上一章的基础上，探讨了用**卷积神经网络**（**CNN**）替换**循环神经网络**（**RNN**）进行草图分类，从而引入RNNs并展示它们如何应用于图像。除了讨论学习序列，我们还将深入了解如何远程下载和编译Core
    ML模型。'
- en: '[Chapter 9](a5ab58d1-0d7c-45e7-aea0-e9da1a7f3f4e.xhtml), *Object Segmentation
    Using CNNs*, walks through building an *ActionShot* photography application. And
    in doing so, we introduce another model and accompanying concepts, and get some
    hands-on experience of preparing and processing data.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9章](a5ab58d1-0d7c-45e7-aea0-e9da1a7f3f4e.xhtml)，*使用CNN进行物体分割*，介绍了构建*ActionShot*摄影应用程序的过程。在这个过程中，我们引入了另一个模型和相关概念，并获得了准备和处理数据的实际经验。'
- en: '[Chapter 10](d358bddb-d137-4dfb-abcd-b6f9647edf9f.xhtml), *An Introduction
    to Create ML*, is the last chapter. We introduce Create ML, a framework for creating
    and training Core ML models within Xcode using Swift. By the end of this chapter,
    you will know how to quickly create, train, and deploy a custom models.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[第10章](d358bddb-d137-4dfb-abcd-b6f9647edf9f.xhtml)，*《创建ML简介*》，是最后一章。我们介绍了Create
    ML，这是一个在Xcode中使用Swift创建和训练Core ML模型的框架。到本章结束时，你将了解如何快速创建、训练和部署自定义模型。'
- en: To get the most out of this book
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 要充分利用本书
- en: 'To be able to follow through the examples in this book, you will need the following
    software:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够跟随本书中的示例，您需要以下软件：
- en: macOS 10.13 or higher
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: macOS 10.13或更高版本
- en: Xcode 9.2 or higher
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xcode 9.2或更高版本
- en: iOS 11.0 or higher (device and simulator)
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: iOS 11.0或更高版本（设备和模拟器）
- en: 'For the examples that are dependent on Core ML 2, you will need the following
    software:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于依赖于Core ML 2的示例，您需要以下软件：
- en: macOS 10.14
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: macOS 10.14
- en: Xcode 10.0 beta
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xcode 10.0测试版
- en: iOS 12 (device and simulator)
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: iOS 12（设备和模拟器）
- en: 'It''s recommended that you use [https://notebooks.azure.com](https://notebooks.azure.com)
    (or some other Jupyter notebook service provider) to follow the examples using
    the Core ML Tools Python package, but those wanting to run locally or train their
    model will need the following software:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 建议您使用[https://notebooks.azure.com](https://notebooks.azure.com)（或任何其他Jupyter笔记本服务提供商）来使用Core
    ML Tools Python包跟随示例，但那些想要本地运行或训练模型的人需要以下软件：
- en: Python 2.7
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 2.7
- en: Jupyter Notebooks 1.0
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jupyter Notebooks 1.0
- en: TensorFlow 1.0.0 or higher
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 1.0.0或更高版本
- en: NumPy 1.12.1 or higher
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy 1.12.1或更高版本
- en: Core ML Tools 0.9 (and 2.0 for Core ML 2 examples)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Core ML Tools 0.9（以及Core ML 2示例的2.0版本）
- en: Download the example code files
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from your account at [www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can visit [www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files emailed directly to you.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[www.packtpub.com](http://www.packtpub.com)的账户下载本书的示例代码文件。如果您在其他地方购买了本书，您可以访问[www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件直接通过电子邮件发送给您。
- en: 'You can download the code files by following these steps:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下步骤下载代码文件：
- en: Log in or register at [www.packtpub.com](http://www.packtpub.com/support).
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[www.packtpub.com](http://www.packtpub.com/support)登录或注册。
- en: Select the SUPPORT tab.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择SUPPORT标签页。
- en: Click on Code Downloads & Errata.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击代码下载与勘误。
- en: Enter the name of the book in the Search box and follow the onscreen instructions.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索框中输入本书的名称，并遵循屏幕上的说明。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 文件下载后，请确保使用最新版本解压缩或提取文件夹：
- en: WinRAR/7-Zip for Windows
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows上的WinRAR/7-Zip
- en: Zipeg/iZip/UnRarX for Mac
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mac上的Zipeg/iZip/UnRarX
- en: 7-Zip/PeaZip for Linux
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linux上的7-Zip/PeaZip
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Machine-Learning-with-Core-ML](https://github.com/PacktPublishing/Machine-Learning-with-Core-ML). In
    case there's an update to the code, it will be updated on the existing GitHub
    repository.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本书代码包也托管在GitHub上，地址为[https://github.com/PacktPublishing/Machine-Learning-with-Core-ML](https://github.com/PacktPublishing/Machine-Learning-with-Core-ML)。如果代码有更新，它将在现有的GitHub仓库中更新。
- en: We also have other code bundles from our rich catalog of books and videos available
    at **[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)**.
    Check them out!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有其他来自我们丰富图书和视频目录的代码包，可在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)找到。查看它们吧！
- en: Download the color images
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载彩色图像
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [http://www.packtpub.com/sites/default/files/downloads/MachineLearningwithCoreML_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/MachineLearningwithCoreML_ColorImages.pdf).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一份包含本书中使用的截图/图表彩色图像的PDF文件。您可以从这里下载：[http://www.packtpub.com/sites/default/files/downloads/MachineLearningwithCoreML_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/MachineLearningwithCoreML_ColorImages.pdf)。
- en: Conventions used
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用了多种文本约定。
- en: '`CodeInText`: Indicates code words in text, database table names, folder names,
    filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.
    Here is an example: "At the top of the class, we have the `VideoCaptureDelegate` protocol
    defined."'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`CodeInText`：表示文本中的代码词汇、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter昵称。以下是一个示例：“在课程顶部，我们定义了`VideoCaptureDelegate`协议。”'
- en: 'A block of code is set as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望引起您对代码块中特定部分的注意时，相关的行或项目将以粗体显示：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: "Select System info from the Administration panel."'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示新术语、重要词汇或屏幕上看到的词汇。例如，菜单或对话框中的文字会以这种方式显示。以下是一个示例：“从管理面板中选择系统信息。”'
- en: Warnings or important notes appear like this.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要提示如下所示。
- en: Tips and tricks appear like this.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 技巧和窍门如下所示。
- en: Get in touch
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。
- en: '**General feedback**: Email `feedback@packtpub.com` and mention the book title
    in the subject of your message. If you have questions about any aspect of this
    book, please email us at `questions@packtpub.com`.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：请发送电子邮件至 `feedback@packtpub.com`，并在邮件主题中提及书籍标题。如果您对本书的任何方面有疑问，请通过
    `questions@packtpub.com` 发送电子邮件给我们。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：尽管我们已经尽最大努力确保内容的准确性，但错误仍然可能发生。如果您在这本书中发现了错误，我们将不胜感激，如果您能向我们报告此错误。请访问
    [www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的书籍，点击勘误提交表单链接，并输入详细信息。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the Internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packtpub.com` with a
    link to the material.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果您在互联网上发现任何形式的我们作品的非法副本，我们将不胜感激，如果您能提供位置地址或网站名称。请通过 `copyright@packtpub.com`
    联系我们，并提供材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com/).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您想成为一名作者**：如果您在某个领域有专业知识，并且对撰写或参与一本书籍感兴趣，请访问 [authors.packtpub.com](http://authors.packtpub.com/).'
- en: Reviews
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评论
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请留下评论。一旦您阅读并使用了这本书，为何不在您购买它的网站上留下评论？潜在读者可以查看并使用您的客观意见来做出购买决定，Packt公司可以了解您对我们产品的看法，我们的作者也可以看到他们对书籍的反馈。谢谢！
- en: For more information about Packt, please visit [packtpub.com](https://www.packtpub.com/).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解Packt的更多信息，请访问 [packtpub.com](https://www.packtpub.com/).
