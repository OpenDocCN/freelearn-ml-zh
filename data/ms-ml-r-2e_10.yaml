- en: Market Basket Analysis, Recommendation Engines, and Sequential Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 购物篮分析、推荐引擎和序列分析
- en: It's much easier to double your business by doubling your conversion rate than
    by doubling your traffic.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 通过加倍转换率来加倍你的业务，比通过加倍流量要容易得多。
- en: '- Jeff Eisenberg, CEO of BuyerLegends.com'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- BuyerLegends.com 首席执行官 杰夫·艾森伯格'
- en: I don't see smiles on the faces of people at Whole Foods.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我没在 Whole Foods 的人脸上看到笑容。
- en: '- Warren Buffett'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '- 沃伦·巴菲特'
- en: One would have to live on the dark side of the moon in order to not observe
    each and every day the results of the techniques that we are about to discuss
    in this chapter. If you visit [www.amazon.com](http://www.amazon.com), watch movies
    on [www.netflix.com](http://www.netflix.com), or visit any retail website, you
    will be exposed to terms such as "related products", "because you watched...",
    "customers who bought *x* also bought *y*", or "recommended for you", at every
    twist and turn. With large volumes of historical real-time or near real-time information,
    retailers utilize the algorithms discussed here to attempt to increase both the
    buyer's quantity and value of their purchases.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 要不观察我们即将在本章讨论的每种技术每天的结果，人们就得住在月亮的阴暗面。如果你访问 [www.amazon.com](http://www.amazon.com)，在
    [www.netflix.com](http://www.netflix.com) 观看电影，或者访问任何零售网站，你都会在每个角落遇到诸如“相关产品”、“因为你观看了...”、“购买
    *x* 的顾客也购买了 *y*”或“为您推荐”等术语。有了大量历史实时或接近实时信息，零售商利用这里讨论的算法试图增加买家的购买数量和价值。
- en: 'The techniques to do this can be broken down into two categories: association
    rules and recommendation engines. Association rule analysis is commonly referred
    to as market basket analysis as one is trying to understand what items are purchased
    together. With recommendation engines, the goal is to provide a customer with
    other items that they will enjoy based on how they have rated previously viewed
    or purchased items.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这些技巧的方法可以分为两类：关联规则和推荐引擎。关联规则分析通常被称为购物篮分析，因为人们试图了解哪些商品是共同购买的。在推荐引擎中，目标是根据客户之前评分的观看或购买的商品提供他们可能会喜欢的其他商品。
- en: Another technique a business can use is to understand the sequence in which
    you purchase or use their products and services. This is called sequential analysis.
    A very common implementation of this methodology is to understand how customers
    click through various webpages and/or links.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种企业可以使用的技巧是了解你购买或使用他们产品和服务的时间顺序。这被称为序列分析。这种方法的非常常见的实现方式是了解客户如何点击各种网页和/或链接。
- en: In the examples coming up, we will endeavor to explore how R can be used to
    develop such algorithms. We will not cover their implementation, as that is outside
    the scope of this book. We will begin with a market basket analysis of purchasing
    habits at a grocery store, then dig into building a recommendation engine on website
    reviews, and finally, analyze the sequence of web pages.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的例子中，我们将努力探索如何使用 R 开发这样的算法。我们不会涵盖它们的实现，因为这超出了本书的范围。我们将从一个杂货店的购买习惯的购物篮分析开始，然后深入构建基于网站评论的推荐引擎，最后分析网页的顺序。
- en: An overview of a market basket analysis
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 购物篮分析概述
- en: Market basket analysis is a data mining technique that has the purpose of finding
    the optimal combination of products or services and allows marketers to exploit
    this knowledge to provide recommendations, optimize product placement, or develop
    marketing programs that take advantage of cross-selling. In short, the idea is
    to identify which items go well together, and profit from it.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 购物篮分析是一种数据挖掘技术，其目的是找到产品或服务的最佳组合，并允许营销人员利用这种知识提供推荐、优化产品摆放或开发利用交叉销售的营销计划。简而言之，想法是识别哪些商品搭配得好，并从中获利。
- en: You can think of the results of the analysis as an `if...then` statement. If
    a customer buys an airplane ticket, then there is a 46 percent probability that
    they will buy a hotel room, and if they go on to buy a hotel room, then there
    is a 33 percent probability that they will rent a car.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以把分析的结果看作一个 `if...then` 语句。如果一个顾客购买了飞机票，那么他们购买酒店房间的概率是 46%，如果他们继续购买酒店房间，那么他们租车的概率是
    33%。
- en: 'However, it is not just for sales and marketing. It is also being used in fraud
    detection and healthcare; for example, if a patient undergoes treatment A, then
    there is a 26 percent probability that they might exhibit symptom X. Before going
    into the details, we should have a look at some terminology, as it will be used
    in the example:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它不仅用于销售和营销。它还被用于欺诈检测和医疗保健；例如，如果一个患者接受了治疗A，那么他们可能会表现出症状X的概率为26%。在进入细节之前，我们应该看看一些术语，因为它们将在示例中使用：
- en: '**Itemset**: This is a collection of one or more items in the dataset.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**项集**：这是数据集中一个或多个项目的集合。'
- en: '**Support**: This is the proportion of the transactions in the data that contain
    an itemset of interest.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持度**：这是数据中包含感兴趣项集的交易比例。'
- en: '**Confidence**: This is the conditional probability that if a person purchases
    or does x, they will purchase or do y; the act of doing x is referred to as the
    *antecedent* or Left-Hand Side (LHS), and y is the *consequence* or Right-Hand
    Side (RHS).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**置信度**：这是如果一个人购买了或做了x，他们将会购买或做y的条件概率；做x的行为被称为*前提*或左侧（LHS），而y是*结果*或右侧（RHS）。'
- en: '**Lift**: This is the ratio of the support of x occurring together with y divided
    by the probability that x and y occur if they are independent. It is the **confidence**
    divided by the probability of x times the probability of y; for example, say that
    we have the probability of x and y occurring together as 10 percent and the probability
    of x is 20 percent and y is 30 percent, then the lift would be 10 percent (20
    percent times 30 percent) or 16.67 percent.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提升度**：这是x和y同时发生的支持度与它们独立发生的概率之比。它是**置信度**除以x的概率乘以y的概率；例如，如果我们有x和y同时发生的概率为10%，x的概率为20%，y的概率为30%，那么提升度将是10%（20%乘以30%）或16.67%。'
- en: 'The package in R that you can use to perform a market basket analysis is **arules:
    Mining Association Rules and Frequent Itemsets**. The package offers two different
    methods of finding rules. Why would one have different methods? Quite simply,
    if you have massive datasets, it can become computationally expensive to examine
    all the possible combinations of the products. The algorithms that the package
    supports are **apriori** and **ECLAT**. There are other algorithms to conduct
    a market basket analysis, but apriori is used most frequently, and so, that will
    be our focus.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '你可以在R中使用的用于执行市场篮子分析的包是**arules: Mining Association Rules and Frequent Itemsets**。该包提供两种不同的查找规则的方法。为什么会有不同的方法？简单地说，如果你有大量数据集，检查所有可能的产品组合可能会变得计算成本高昂。该包支持的算法是**apriori**和**ECLAT**。还有其他算法可以进行市场篮子分析，但apriori使用得最频繁，因此，我们将重点关注它。'
- en: 'With apriori, the principle is that, if an itemset is frequent, then all of
    its subsets must also be frequent. A minimum frequency (support) is determined
    by the analyst prior to executing the algorithm, and once established, the algorithm
    will run as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在apriori中，原则是，如果一个项集是频繁的，那么它的所有子集也必须是频繁的。最小频率（支持度）是在执行算法之前由分析师确定的，一旦确定，算法将按以下方式运行：
- en: Let *k=1* (the number of items)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 令 *k=1*（项目数量）
- en: Generate itemsets of a length that are equal to or greater than the specified
    support
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成等于或大于指定支持度的项集长度
- en: Iterate *k + (1...n)*, pruning those that are infrequent (less than the support)
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代 *k + (1...n)*，剪枝那些不频繁的（小于支持度）
- en: Stop the iteration when no new frequent itemsets are identified
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当没有新的频繁项集被识别时停止迭代
- en: Once you have an ordered summary of the most frequent itemsets, you can continue
    the analysis process by examining the confidence and lift in order to identify
    the associations of interest.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了最频繁项集的有序摘要，你可以通过检查置信度和提升度来继续分析过程，以识别感兴趣的关联。
- en: Business understanding
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 商业理解
- en: For our business case, we will focus on identifying the association rules for
    a grocery store. The dataset will be from the `arules` package and is called `Groceries`.
    This dataset consists of actual transactions over a 30-day period from a real-world
    grocery store and consists of 9,835 different purchases. All the items purchased
    are put into one of 169 categories, for example, bread, wine, meat, and so on.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的业务案例，我们将专注于识别杂货店的关联规则。数据集将来自`arules`包，称为`Groceries`。这个数据集包含了一个现实世界杂货店30天内的实际交易，包括9,835种不同的购买。所有购买的物品都被放入169个类别中的一个，例如，面包、酒、肉类等等。
- en: Let's say that we are a start-up microbrewery trying to make a headway in this
    grocery outlet and want to develop an understanding of what potential customers
    will purchase along with beer. This knowledge may just help us in identifying
    the right product placement within the store or support a cross-selling campaign.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们是一家初创精酿啤酒厂，试图在这家杂货店取得突破，并希望了解潜在顾客会与啤酒一起购买什么。这种知识可能正好帮助我们确定店内正确的产品摆放位置，或者支持交叉销售活动。
- en: Data understanding and preparation
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据理解和准备
- en: 'For this analysis, we will only need to load two packages, as well as the `Groceries`
    dataset:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这次分析，我们只需要加载两个包，以及`Groceries`数据集：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This dataset is structured as a sparse matrix object, known as the `transaction`
    class.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集的结构是一个稀疏矩阵对象，称为`transaction`类。
- en: So, once the structure is that of the class transaction, our standard exploration
    techniques will not work, but the `arules` package offers us other techniques
    to explore the data. On a side note, if you have a data frame or matrix and want
    to convert it to the `transaction` class, you can do this with a simple syntax,
    using the `as()` function.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一旦结构变成交易类，我们的标准探索技术将不再适用，但`arules`包为我们提供了其他探索数据的技术。顺便提一下，如果你有一个数据框或矩阵，并想将其转换为`transaction`类，你可以使用简单的语法，通过`as()`函数实现。
- en: 'The following code is for illustrative purposes only, so do not run it:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码仅用于说明，请勿运行：
- en: '`> # transaction.class.name <- as(current.data.frame,"transactions")`.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`> # transaction.class.name <- as(current.data.frame,"transactions")`。'
- en: 'The best way to explore this data is with an item frequency plot using the
    `itemFrequencyPlot()` function in the `arules` package. You will need to specify
    the transaction dataset, the number of items with the highest frequency to plot,
    and whether or not you want the relative or absolute frequency of the items. Let''s
    first look at the absolute frequency and the top `10` items only:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 探索这些数据最好的方式是使用`arules`包中的`itemFrequencyPlot()`函数制作项目频率图。你需要指定交易数据集、要绘制频率最高的项目数量，以及是否需要绘制项目的相对或绝对频率。让我们首先查看绝对频率和前`10`个商品：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下：
- en: '![](img/image_10_01.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_01.png)'
- en: 'The top item purchased was **whole milk** with roughly **2**,**500** of the
    9,836 transactions in the basket. For a relative distribution of the top 15 items,
    let''s run the following code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 购买最多的商品是**全脂牛奶**，在9,836笔交易中有大约**2,500**笔。为了显示前15个商品的相对分布，让我们运行以下代码：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following is the output of the preceding command:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下：
- en: '![](img/image_10_02.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_02.png)'
- en: Alas, here we see that beer shows up as the 13th and 15th most purchased item
    at this store. Just under 10 percent of the transactions had purchases of **bottled
    beer** and/or **canned beer**.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 殊不知，在这里我们看到啤酒作为第13和第15大购买商品出现在这家商店。大约10%的交易包含了**瓶装啤酒**和/或**罐装啤酒**的购买。
- en: For the purpose of this exercise, this is all we really need to do, therefore,
    we can move right on to the modeling and evaluation.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个练习的目的，我们实际上需要做的就这么多，因此，我们可以直接进入建模和评估阶段。
- en: Modeling and evaluation
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建模和评估
- en: 'We will start by mining the data for the overall association rules before moving
    on to our rules for beer specifically. Throughout the modeling process, we will
    use the apriori algorithm, which is the appropriately named `apriori()` function
    in the `arules` package. The two main things that we will need to specify in the
    function is the dataset and parameters. As for the parameters, you will need to
    apply judgment when specifying the minimum support, confidence, and the minimum
    and/or maximum length of basket items in an itemset. Using the item frequency
    plots, along with trial and error, let''s set the minimum support at 1 in 1,000
    transactions and minimum confidence at 90 percent. Additionally, let''s establish
    the maximum number of items to be associated as four. The following is the code
    to create the object that we will call `rules`:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先挖掘数据以获取整体关联规则，然后再转向针对啤酒的具体规则。在整个建模过程中，我们将使用apriori算法，这是`arules`包中名为`apriori()`的适当命名的函数。在函数中，我们需要指定的主要两件事是数据集和参数。至于参数，在指定最小支持度、置信度以及项目集的最小和/或最大长度时，你需要运用判断力。使用项目频率图，结合试错法，我们将最小支持度设置为1000笔交易中的1，最小置信度设置为90%。此外，我们将关联的项目数量上限设置为四个。以下是我们将创建的名为`rules`的对象的代码：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Calling the object shows how many rules the algorithm produced:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 调用对象显示了算法产生的规则数量：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'There are a number of ways to examine the rules. The first thing that I recommend
    is to set the number of displayed digits to only two, with the `options()` function
    in base R. Then, sort and inspect the top five rules based on the lift that they
    provide, as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以检查规则。我首先推荐的是，使用基础R中的`options()`函数将显示的数字位数设置为仅两位。然后，根据它们提供的提升度对前五条规则进行排序和检查，如下所示：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Lo and behold, the rule that provides the best overall lift is the purchase
    of `liquor` and `red wine` on the probability of purchasing `bottled beer`. I
    have to admit that this is pure chance and not intended on my part. As I always
    say, it is better to be lucky than good. Although, it is still not a very common
    transaction with a support of only 1.9 per 1,000.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 看看，提供最佳整体提升度的规则是购买`酒`和`红酒`的概率，基于购买`瓶装啤酒`。我必须承认，这完全是巧合，并不是我故意为之。正如我经常说的，幸运比好更重要。尽管如此，这仍然不是一个非常常见的交易，支持率仅为每1,000次交易中有1.9次。
- en: 'You can also sort by the support and confidence, so let''s have a look at the
    first `5` `rules` `by="confidence"` in descending order, as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以按支持和置信度排序，所以让我们看看按`confidence`降序排列的前`5`条`规则`，如下所示：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can see in the table that `confidence` for these transactions is 100 percent.
    Moving on to our specific study of beer, we can utilize a function in `arules`
    to develop cross tabulations--the `crossTable()` function--and then examine whatever
    suits our needs. The first step is to create a table with our dataset:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在表中看到，这些交易的`confidence`为100%。继续到我们具体的啤酒研究，我们可以利用`arules`中的函数来开发交叉表——`crossTable()`函数——然后检查任何适合我们需求的内容。第一步是创建一个包含我们的数据集的表：
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'With `tab` created, we can now examine the joint occurrences between the items.
    Here, we will look at just the first three rows and columns:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `tab` 创建后，我们现在可以检查项目之间的联合出现情况。在这里，我们将只查看前三个行和列：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'As you might imagine, shoppers only selected liver loaf 50 times out of the
    9,835 transactions. Additionally, of the `924` times, people gravitated toward
    `sausage`, `10` times they felt compelled to grab `liver loaf`. (Desperate times
    call for desperate measures!) If you want to look at a specific example, you can
    either specify the row and column number or just spell that item out:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想，购物者在9,835次交易中只选择了50次肝肉饼。此外，在`924`次中，人们倾向于选择`香肠`，`10`次他们感到不得不抓取`肝肉饼`。（在绝望的时刻需要采取绝望的措施！）如果你想查看一个具体的例子，你可以指定行和列号，或者只拼写那个项目：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This tells us that there were `792` transactions of `bottled beer`. Let''s
    see what the joint occurrence between `bottled beer` and `canned beer` is:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们有`792`次交易是`瓶装啤酒`。让我们看看`瓶装啤酒`和`罐装啤酒`之间的联合出现情况：
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: I would expect this to be low as it supports my idea that people lean toward
    drinking beer from either a bottle or a can. I strongly prefer a bottle. It also
    makes a handy weapon to protect oneself from all these ruffian protesters like
    Occupy Wallstreet and the like.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我预计这会很低，因为它支持我的观点，即人们倾向于从瓶装或罐装中喝酒。我强烈偏好瓶装。这也使得它成为一件方便的武器，可以用来保护自己免受所有这些流氓抗议者，如占领华尔街和类似的人。
- en: 'We can now move on and derive specific rules for `bottled beer`. We will again
    use the `apriori()` function, but this time, we will add a syntax around `appearance`.
    This means that we will specify in the syntax that we want the left-hand side
    to be items that increase the probability of a purchase of `bottled beer`, which
    will be on the right-hand side. In the following code, notice that I''ve adjusted
    the `support` and `confidence` numbers. Feel free to experiment with your own
    settings:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以继续前进，并推导出针对`瓶装啤酒`的具体规则。我们再次使用`apriori()`函数，但这次，我们将在`appearance`周围添加语法。这意味着我们将在语法中指定，我们想要左侧是增加购买`瓶装啤酒`概率的项目，这些项目将位于右侧。在下面的代码中，请注意我已经调整了`support`和`confidence`数字。请随意尝试你自己的设置：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We find ourselves with only `4` association rules. We have seen one of them
    already; now let''s bring in the other three rules in descending order by lift:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现自己只有`4`条关联规则。我们已经看到了其中之一；现在让我们按提升度降序引入其他三条规则：
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In all of the instances, the purchase of `bottled beer` is associated with
    booze, either `liquor` and/or `red wine` , which is no surprise to anyone. What
    is interesting is that `white wine` is not in the mix here. Let''s take a closer
    look at this and compare the joint occurrences of `bottled beer` and types of
    wine:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些实例中，购买 `瓶装啤酒` 与酒精饮料相关联，无论是 `烈酒` 和/或 `红酒`，这对任何人来说都不足为奇。有趣的是，这里没有 `白葡萄酒`。让我们更仔细地看看这一点，并比较
    `瓶装啤酒` 和葡萄酒类型的联合出现：
- en: '[PRE13]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: It's interesting that 25 percent of the time, when someone purchased `red wine`,
    they also purchased `bottled beer`; but with `white wine`, a joint purchase only
    happened in 12 percent of the instances. We certainly don't know why in this analysis,
    but this could potentially help us to determine how we should position our product
    in this grocery store. Another thing before we move on is to look at a plot of
    the rules. This is done with the `plot()` function in the `arulesViz` package.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，25% 的时间，当有人购买 `红酒` 时，他们也购买了 `瓶装啤酒`；但与 `白葡萄酒` 相比，联合购买只发生在 12% 的情况下。我们当然不知道在这个分析中为什么，但这可能有助于我们确定如何在这个杂货店定位我们的产品。在我们继续之前，还有一个事情要看看规则的图。这是通过
    `arulesViz` 包中的 `plot()` 函数完成的。
- en: 'There are many graphic options available. For this example, let''s specify
    that we want a `graph`, showing `lift`, and the rules provided and shaded by `confidence`.
    The following syntax will provide this accordingly:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多图形选项可用。对于这个例子，让我们指定我们想要一个 `图形`，显示 `提升` 和由 `信心` 提供和阴影的规则。以下语法将相应地提供：
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following is the output of the preceding command:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的输出是前面命令的结果：
- en: '![](img/image_10_03.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_10_03.png)'
- en: This graph shows that **liquor**/**red wine** provides the best **lift** and
    the highest level of **confidence** with both the **size** of the circle and its
    shading.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 此图显示，**烈酒**/**红酒**在圆圈的大小及其阴影方面提供了最佳的**提升**和最高的**信心**水平。
- en: What we've just done in this simple exercise is show how easy it is with R to
    conduct a market basket analysis. It doesn't take much imagination to figure out
    the analytical possibilities that one can include with this technique, for example,
    in corporate customer segmentation, longitudinal purchase history, and so on,
    as well as how to use it in ad displays, co-promotions, and so on. Now let's move
    on to a situation where customers rate items, and learn how to build and test
    recommendation engines.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个简单的练习中所做的是展示使用 R 进行市场篮子分析是多么容易。想象一下，使用这种技术可以包括哪些分析可能性，例如，在企业客户细分、纵向购买历史等方面，以及如何将其用于广告展示、联合促销等。现在让我们转向一个客户对商品进行评分的情况，并学习如何构建和测试推荐引擎。
- en: An overview of a recommendation engine
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐引擎概述
- en: 'We will now focus on situations where users have provided rankings or ratings
    on previously viewed or purchased items. There are two primary categories of designing
    recommendation systems: *collaborative filtering and content-based* (Ansari, Essegaier,
    and Kohli, 2000). The former category is what we will concentrate on, as this
    is the focus of the `recommenderlab` R package that we will be using.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将关注用户对先前查看或购买的商品提供排名或评分的情况。设计推荐系统有两个主要类别：*协同过滤和基于内容的*（Ansari, Essegaier,
    和 Kohli, 2000）。我们将重点关注前者，因为这是我们将要使用的 `recommenderlab` R 包的重点。
- en: For content-based approaches, the concept is to link user preferences with item
    attributes. These attributes may be things such as the genre, cast, or storyline
    for a movie or TV show recommendation. As such, recommendations are based entirely
    on what the user provides as ratings; there is no linkage to what anyone else
    recommends. This has the advantage over content-based approaches in that when
    a new item is added, it can be recommended to a user if it matches their profile,
    instead of relying on other users to rate it first (the so-called "first rater
    problem"). However, content-based methods can suffer when limited content is available,
    either because of the domain or when a new user enters the system. This can result
    in non-unique recommendations, that is, poor recommendations (Lops, Gemmis, and
    Semeraro, 2011).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于内容的推荐方法，其概念是将用户偏好与项目属性相联系。这些属性可能包括电影或电视剧推荐的类型、演员阵容或剧情。因此，推荐完全基于用户提供的评分；没有与其他人推荐的关联。这比基于内容的推荐方法有优势，因为当添加新项目时，如果它与用户的个人资料匹配，就可以向用户推荐，而不是依赖其他用户首先对其进行评分（所谓的“第一个评分者问题”）。然而，当可用的内容有限时，基于内容的方法可能会受到影响，无论是由于领域限制还是当新用户进入系统时。这可能导致非唯一的推荐，即较差的推荐（Lops,
    Gemmis, and Semeraro, 2011）。
- en: In collaborative filtering, the recommendations are based on the many ratings
    provided by some or all of the individuals in the database. Essentially, it tries
    to capture the wisdom of the crowd.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在协同过滤中，推荐基于数据库中某些或所有个体的许多评分。本质上，它试图捕捉大众的智慧。
- en: 'For collaborative filtering, we will focus on the following four methods:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于协同过滤，我们将关注以下四种方法：
- en: '**User-based collaborative filtering** (**UBCF**)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于用户的协同过滤**（**UBCF**）'
- en: '**Item-based collaborative filtering** (**IBCF**)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于项目的协同过滤**（**IBCF**）'
- en: '**Singular value decomposition** (**SVD**)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**奇异值分解**（**SVD**）'
- en: '**Principal components analysis** (**PCA**)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主成分分析**（**PCA**）'
- en: We will look at these methods briefly before moving on to the business case.
    It is also important to understand that `recommenderlab` was not designed to be
    used as a real-world implementation tool, but rather as a laboratory tool in order
    to research algorithms provided in the package as well as algorithms that you
    wish to experiment with on your own.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续研究案例之前，我们将简要地探讨这些方法。重要的是要理解，`recommenderlab`并非设计为用于实际应用工具，而是一个实验室工具，用于研究包中提供的算法以及您希望自行实验的算法。
- en: User-based collaborative filtering
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于用户的协同过滤
- en: In UBCF, the algorithm finds *missing ratings for a user by first finding a
    neighborhood of similar users and then aggregating the ratings of these users
    to form a prediction* (Hahsler, 2011). The neighborhood is determined by selecting
    either the KNN that is the most similar to the user we are making predictions
    for or by some similarity measure with a minimum threshold. The two similarity
    measures available in `recommenderlab` are **pearson correlation coefficient**
    and **cosine similarity**. I will skip the formulas for these measures as they
    are readily available in the package documentation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在UBCF中，算法首先找到与目标用户最相似的用户邻域，然后汇总这些用户的评分以形成预测（Hahsler, 2011）。邻域是通过选择与目标用户最相似的KNN或通过某种最小阈值的相似度度量来确定的。`recommenderlab`中可用的两种相似度度量是**皮尔逊相关系数**和**余弦相似度**。我将跳过这些度量的公式，因为它们在包的文档中很容易找到。
- en: Once the neighborhood method is decided on, the algorithm identifies the neighbors
    by calculating the similarity measure between the individual of interest and their
    neighbors on only those items that were rated by both. Through a scoring scheme,
    say, a simple average, the ratings are aggregated in order to make a predicted
    score for the individual and item of interest.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦决定了邻域方法，算法通过仅计算感兴趣个体与其邻居在共同评分的项目上的相似度来识别邻居。通过评分方案，例如简单的平均，汇总评分以对感兴趣的个人和项目做出预测评分。
- en: 'Let''s look at a simple example. In the following matrix, there are six individuals
    with ratings on four movies, with the exception of my rating for *Mad Max*. Using
    *k=1*, the nearest neighbor is **Homer**, with **Bart** a close second; even though
    **Flanders** hated the **Avengers** as much as I did. So, using Homer''s rating
    for **Mad Max**, which is **4**, the predicted rating for me would also be a **4**:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个简单的例子。在以下矩阵中，有六个人对四部电影进行了评分，除了我对 *Mad Max* 的评分。使用 *k=1*，最近的邻居是 **Homer**，其次是
    **Bart**；尽管 **弗兰德斯**和我一样讨厌 **复仇者联盟**。因此，使用Homer对 **Mad Max** 的评分，即 **4**，对我的预测评分也将是
    **4**：
- en: '![](img/image_10_04.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图片10_04](img/image_10_04.png)'
- en: There are a number of ways to weigh the data and/or control the bias. For instance,
    **Flanders** is quite likely to have lower ratings than the other users, so normalizing
    the data where the new rating score is equal to the user rating for an item minus
    the average for that user for all the items is likely to improve the rating accuracy.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以衡量数据并/或控制偏差。例如，**弗兰德斯**的用户评分很可能比其他用户低，因此，在数据标准化时，将新的评分分数设置为用户对某项物品的评分减去该用户对所有物品的平均评分，可能会提高评分的准确性。
- en: The weakness of UBCF is that, to calculate the similarity measure for all the
    possible users, the entire database must be kept in memory, which can be quite
    computationally expensive and time-consuming.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: UBCF的弱点在于，为了计算所有可能用户的相似度度量，必须将整个数据库保留在内存中，这可能会非常计算量大且耗时。
- en: Item-based collaborative filtering
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于物品的协同过滤
- en: As you might have guessed, IBCF uses the similarity between the items and not
    users to make a recommendation. *The assumption behind this approach is that users
    will prefer items that are similar to other items they like* (Hahsler, 2011).
    The model is built by calculating a pairwise similarity matrix of all the items.
    The popular similarity measures are Pearson correlation and cosine similarity.
    To reduce the size of the similarity matrix, one can specify to retain only the
    k-most similar items. However, limiting the size of the neighborhood may significantly
    reduce the accuracy, leading to poorer performance versus UCBF.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所猜，IBCF使用物品之间的相似性而不是用户之间的相似性来做出推荐。*这种方法的假设是，用户将更喜欢与他们喜欢的其他物品相似的物品*（Hahsler，2011）。模型是通过计算所有物品的双边相似度矩阵来构建的。流行的相似度度量包括皮尔逊相关性和余弦相似性。为了减少相似度矩阵的大小，可以指定仅保留k个最相似的物品。然而，限制邻域的大小可能会显著降低准确性，导致性能不如UCBF。
- en: 'Continuing with our simplified example, if we examine the following matrix,
    with *k=1* the item most similar to **Mad Max** is **American Sniper**, and we
    can thus take that rating as the prediction for **Mad Max**, as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 继续我们的简化示例，如果我们检查以下矩阵，当 *k=1* 时，与 **Mad Max** 最相似的项目是 **美国狙击手**，因此我们可以将那个评分作为
    **Mad Max** 的预测，如下所示：
- en: '![](img/image_10_05.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片10_05](img/image_10_05.png)'
- en: Singular value decomposition and principal components analysis
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单值分解和主成分分析
- en: It is quite common to have a dataset where the number of users and items number
    in the millions. Even if the rating matrix is not that large, it may be beneficial
    to reduce the dimensionality by creating a smaller (lower-rank) matrix that captures
    most of the information in the higher-dimension matrix. This may potentially allow
    you to capture important latent factors and their corresponding weights in the
    data. Such factors could lead to important insights, such as the movie genre or
    book topics in the rating matrix. Even if you are unable to discern meaningful
    factors, the techniques may filter out the noise in the data.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集中，用户和物品的数量数以百万计的情况相当常见。即使评分矩阵不是那么大，通过创建一个较小的（低秩）矩阵来捕捉高维矩阵中的大部分信息，可能也有利于降低维度。这可能会潜在地允许你捕捉数据中的重要潜在因素及其对应的权重。这些因素可能导致重要的见解，例如评分矩阵中的电影类型或书籍主题。即使你无法识别有意义的因素，这些技术也可能过滤掉数据中的噪声。
- en: One issue with large datasets is that you will likely end up with a sparse matrix
    that has many ratings missing. One weakness of these methods is that they will
    not work on a matrix with missing values, which must be imputed. As with any data
    imputation task, there are a number of techniques that one can try and experiment
    with, such as using the mean, median, or code as zeroes. The default for `recommenderlab`
    is to use the median.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据集的一个问题是，你可能会得到一个稀疏矩阵，其中包含许多缺失的评分。这些方法的弱点是它们不能在包含缺失值的矩阵上工作，这些缺失值必须被估计。与任何数据估计任务一样，有几种技术可以尝试和实验，例如使用平均值、中位数或用零编码。`recommenderlab`的默认值是使用中位数。
- en: 'So, what is SVD? It is simply a method for matrix factorization, and can help
    transform a set of correlated features to a set of uncorrelated features. Say
    that you have a matrix called **A**. This matrix will factor into three matrices:
    **U**, **D**, and **V^T**. U is an orthogonal matrix, D is a non-negative, diagonal
    matrix, and V^T is a transpose of an orthogonal matrix. Now, let''s look at our
    rating matrix and walk through an example using R.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，SVD是什么？它是一种矩阵分解的方法，可以帮助将一组相关特征转换为不相关特征的一组。比如说，你有一个名为**A**的矩阵。这个矩阵将分解为三个矩阵：**U**、**D**和**V^T**。U是一个正交矩阵，D是一个非负的对角矩阵，V^T是一个正交矩阵的转置。现在，让我们看看我们的评分矩阵，并使用R来通过一个例子进行说明。
- en: 'The first thing that we will do is recreate the rating matrix (think of it
    as matrix **A**, as shown in the following code):'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要做的是重新创建评分矩阵（可以将其视为矩阵**A**，如下面的代码所示）：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, we will use the `svd()` function in base R to create the three matrices
    described above, which R calls `$d`, `$u`, and `$v`. You can think of the `$u`
    values as an individual''s loadings on that factor and `$v` as a movie''s loadings
    on that dimension. For example, `Mad Max` loads on dimension one at -0.116 (1st
    row, 4th column):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用基础R中的`svd()`函数来创建上述三个矩阵，R将其称为`$d`、`$u`和`$v`。你可以将`$u`值视为个体在该因子上的载荷，而`$v`值则视为电影在该维度上的载荷。例如，`Mad
    Max`在第一个维度上的载荷为-0.116（第1行，第4列）：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'It is easy to explore how much variation is explained by reducing the dimensionality.
    Let''s sum the diagonal numbers of `$d`, then look at how much of the variation
    we can explain with just two factors, as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 探索通过降低维度可以解释多少变化是很容易的。让我们先求出`$d`的对角线数字之和，然后看看我们只用两个因子就能解释多少变化，如下所示：
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'With two of the four factors, we are able to capture just over 85 percent of
    the total variation in the full matrix. You can see the scores that the reduced
    dimensions would produce. To do this, we will create a function. (Many thanks
    to the [www.stackoverflow.com](http://www.stackoverflow.com) respondents who helped
    me put this function together.) This function will allow us to specify the number
    of factors that are to be included for a prediction. It calculates a rating value
    by multiplying the `$u` matrix times the `$v` matrix times the `$d` matrix:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用四个因子中的两个，我们能够捕捉到整个矩阵中超过85%的总变化。你可以看到减少维度将产生的分数。为此，我们将创建一个函数。（非常感谢[www.stackoverflow.com](http://www.stackoverflow.com)上的响应者，他们帮助我把这个函数组合起来。）这个函数将允许我们指定要包含在预测中的因子数量。它通过将`$u`矩阵乘以`$v`矩阵再乘以`$d`矩阵来计算评分值：
- en: '[PRE18]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'By specifying `n=4` and calling the function, we can recreate the original
    rating matrix:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 通过指定`n=4`并调用该函数，我们可以重新创建原始的评分矩阵：
- en: '[PRE19]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Alternatively, we can specify `n=2` and examine the resulting matrix:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以指定`n=2`并检查得到的矩阵：
- en: '[PRE20]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: So, with SVD, you can reduce the dimensionality and possibly identify the meaningful
    latent factors.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用SVD，你可以降低维度，并可能识别出有意义的潜在因子。
- en: If you went through the prior chapter, you will see the similarities with PCA.
    In fact, the two are closely related and often used interchangeably as they both
    utilize matrix factorization. You may be asking what is the difference? In short,
    PCA is based on the covariance matrix, which is symmetric. This means that you
    start with the data, compute the covariance matrix of the centered data, diagonalize
    it, and create the components.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经阅读了前一章，你会看到与PCA的相似之处。事实上，这两个方法是密切相关的，并且经常可以互换使用，因为它们都利用矩阵分解。你可能想知道它们之间的区别？简而言之，PCA基于协方差矩阵，它是对称的。这意味着你从数据开始，计算中心化数据的协方差矩阵，对其进行对角化，并创建成分。
- en: 'Let''s apply a portion of the PCA code from the prior chapter to our data in
    order to see how the difference manifests itself:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将前一章中的一部分PCA代码应用到我们的数据中，以查看差异如何体现出来：
- en: '[PRE21]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: You can see that PCA is easier to interpret. Notice how `American Sniper` and
    `Mad Max` have high loadings on the first component, while only `Avengers` has
    a high loading on the second component. Additionally, these two components account
    for 94 percent of the total variance in the data.  It is noteworthy to include
    that, in the time between the first and second editions of this book, PCA has
    become unavailable.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到主成分分析（PCA）更容易解释。注意《美国狙击手》和《疯狂的麦克斯》在第一个成分上有很高的载荷，而只有《复仇者联盟》在第二个成分上有很高的载荷。此外，这两个成分解释了数据中94%的总方差。值得注意的是，在这本书的第一版和第二版之间，主成分分析（PCA）已经不可用。
- en: Having applied a simplistic rating matrix to the techniques of collaborative
    filtering, let's move on to a more complex example using real-world data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在将简单的评分矩阵应用于协同过滤技术之后，让我们通过使用真实世界数据的一个更复杂的例子继续前进。
- en: Business understanding and recommendations
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 商业理解和建议
- en: This business case is a joke, literally. Maybe it is more appropriate to say
    a bunch of jokes, as we will use the `Jester5k` data from the `recommenderlab`
    package. This data consists of 5,000 ratings on 100 jokes sampled from the Jester
    Online Joke Recommender System. It was collected between April 1999 and May 2003,
    and all the users have rated at least 36 jokes (Goldberg, Roeder, Gupta, and Perkins,
    2001). Our goal is to compare the recommendation algorithms and select the best
    one.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这个案例实际上是一个笑话。也许更恰当的说法是一系列笑话，因为我们将从`recommenderlab`包中使用`Jester5k`数据。这些数据包括从Jester在线笑话推荐系统抽取的100个笑话的5,000个评分。这些数据收集于1999年4月至2003年5月之间，所有用户至少评分了36个笑话（Goldberg,
    Roeder, Gupta, and Perkins, 2001）。我们的目标是比较推荐算法并选择最佳算法。
- en: As such, I believe it is important to lead off with a statistical joke to put
    one in the proper frame of mind. I'm not sure of how to properly provide attribution
    for this one, but it is popular all over the Internet.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我认为以一个统计笑话开头是很重要的，以使人们处于正确的思维框架。我不确定如何正确地提供这个笑话的归属，但它在互联网上很受欢迎。
- en: A statistician's wife had twins. He was delighted. He rang the minister who
    was also delighted. "Bring them to church on Sunday and we'll baptize them", said
    the minister. "No", replied the statistician. "Baptize one. We'll keep the other
    as a control."
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一个统计学家妻子生了双胞胎。他很高兴。他给牧师打电话，牧师也很高兴。“周日把他们带到教堂，我们将为他们施洗”，牧师说。“不”，统计学家回答说。“施洗一个。我们将保留另一个作为对照组。”
- en: Data understanding, preparation, and recommendations
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据理解、准备和推荐
- en: 'The one library that we will need for this exercise is `recommenderlab`. The
    package was developed by the Southern Methodist University''s Lyle Engineering
    Lab, and they have an excellent website with supporting documentation at [https://lyle.smu.edu/IDA/recommenderlab/](https://lyle.smu.edu/IDA/recommenderlab/):'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这个练习中需要的唯一库是`recommenderlab`。这个包是由南卫理公会大学的Lyle工程实验室开发的，他们有一个支持文档优秀的网站，网址为[https://lyle.smu.edu/IDA/recommenderlab/](https://lyle.smu.edu/IDA/recommenderlab/)：
- en: '[PRE22]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The rating matrix contains `362106` total ratings. It is quite easy to get
    a list of a user''s ratings. Let''s look at user number `10`. The following output
    is abbreviated for the first five jokes:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 评分矩阵包含`362106`个总评分。获取用户评分列表相当容易。让我们看看用户编号`10`。以下输出仅包含前五个笑话的摘要：
- en: '[PRE23]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You can also look at the mean rating for a user (user `10`) and/or the mean
    rating for a specific joke (joke `1`), as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以查看用户（用户`10`）的平均评分或特定笑话（笑话`1`）的平均评分，如下所示：
- en: '[PRE24]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'One method to get a better understanding of the data is to plot the ratings
    as a histogram, both the raw data and after normalization. We will do this with
    the `getRating()` function from `recommenderlab`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 了解数据的一种方法是绘制评分直方图，包括原始数据和归一化后的数据。我们将使用`recommenderlab`中的`getRating()`函数来完成这项工作：
- en: '[PRE25]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下：
- en: '![](img/image_10_06.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_06.png)'
- en: 'The `normalize()` function in the package centers the data by subtracting the
    mean of the ratings of the joke from that joke''s rating. As the preceding distribution
    is slightly biased towards the positive ratings, normalizing the data can account
    for this, thus yielding a more normal distribution but still showing a slight
    skew towards the positive ratings, as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 包中的`normalize()`函数通过从笑话的评分中减去评分的平均值来对数据进行中心化。由于前面的分布略微偏向正面评分，因此对数据进行归一化可以解决这个问题，从而产生一个更正常的分布，但仍然略微偏向正面评分，如下所示：
- en: '[PRE26]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The following is the output of the preceding command:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为前一个命令的输出：
- en: '![](img/image_10_07.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_07.png)'
- en: 'Before modeling and evaluation, it is quite easy to create the `train` and
    `test` datasets with the `recommenderlab` package with the `evaluationScheme()`
    function. Let''s do an 80/20 split of the data for the `train` and `test` sets.
    You can also choose k-fold cross-validation and bootstrap resampling if you desire.
    We will also specify that for the `test` set, the algorithm will be given 15 ratings.
    This means that the other rating items will be used to compute the error. Additionally,
    we will specify what the threshold is for a good rating; in our case, greater
    than or equal to `5`:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在建模和评估之前，使用`recommenderlab`包的`evaluationScheme()`函数创建`train`和`test`数据集非常容易。让我们将数据分成80/20的`train`和`test`集。你也可以选择k折交叉验证和自助重采样，如果你希望的话。我们还将指定对于`test`集，算法将给出15个评分。这意味着其他评分项将用于计算误差。此外，我们将指定良好评分的阈值；在我们的情况下，大于或等于`5`：
- en: '[PRE27]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'With the `train` and `test` data established, we will now begin to model and
    evaluate the different recommenders: user-based, item-based, popular, SVD, PCA,
    and random.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在建立了`train`和`test`数据后，我们现在将开始建模和评估不同的推荐器：基于用户的、基于项目的、流行的、SVD、PCA和随机的。
- en: Modeling, evaluation, and recommendations
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建模、评估和推荐
- en: 'In order to build and test our recommendation engines, we can use the same
    function, `Recommender()`, merely changing the specification for each technique.
    In order to see what the package can do and explore the parameters available for
    all six techniques, you can examine the registry. Looking at the following IBCF,
    we can see that the default is to find 30 neighbors using the cosine method with
    the centered data while the missing data is not coded as a zero:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建和测试我们的推荐引擎，我们可以使用相同的函数`Recommender()`，只需更改每个技术的指定即可。为了了解这个包能做什么以及探索所有六种技术可用的参数，你可以检查注册表。查看以下IBCF，我们可以看到默认情况下是使用余弦方法找到30个邻居，数据是中心化的，而缺失数据没有编码为零：
- en: '[PRE28]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Here is how you can put together the algorithms based on the `train` data.
    For simplicity, let''s use the default algorithm settings. You can adjust the
    parameter settings by simply including your changes in the function as a list:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何根据`train`数据组合算法的。为了简单起见，让我们使用默认的算法设置。你可以通过在函数中简单地包含一个包含你的更改的列表来调整参数设置：
- en: '[PRE29]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, using the `predict()` and `getData()` functions, we will get the predicted
    ratings for the 15 items of the `test` data for each of the algorithms, as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用`predict()`和`getData()`函数，我们将为每个算法获取`test`数据中15个项目的预测评分，如下所示：
- en: '[PRE30]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We will examine the error between the predictions and unknown portion of the
    `test` data using the `calcPredictionAccuracy()` function. The output will consist
    of `RMSE`, `MSE`, and `MAE` for all the methods. We''ll examine `UBCF` by itself.
    After creating the objects for all five methods, we can build a table by creating
    an object with the `rbind()` function and giving names to the rows with the `rownames()`
    function:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`calcPredictionAccuracy()`函数检查预测与`test`数据未知部分之间的误差。输出将包括所有方法的`RMSE`、`MSE`和`MAE`。我们将单独检查`UBCF`。在为所有五种方法创建对象后，我们可以通过创建一个带有`rbind()`函数的对象并使用`rownames()`函数给行命名来构建一个表格：
- en: '[PRE31]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We can see in the output that the user-based and popular algorithms slightly
    outperform IBCF and SVD and all outperform random predictions.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在输出中看到，基于用户和流行的算法略优于IBCF和SVD，并且所有算法都优于随机预测。
- en: There is another way to compare methods using the `evaluate()` function. Making
    comparisons with `evaluate()` allows one to examine additional performance metrics
    as well as performance graphs. As the UBCF and Popular algorithms performed the
    best, we will look at them along with IBCF.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`evaluate()`函数还有另一种比较方法。使用`evaluate()`进行比较允许一个人检查额外的性能指标以及性能图表。由于UBCF和Popular算法表现最好，我们将与IBCF一起查看。
- en: 'The first task in this process is to create a list of the algorithms that we
    want to compare, as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程中的第一个任务是创建一个我们想要比较的算法列表，如下所示：
- en: '[PRE32]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'For this example, let''s compare the top `5`, `10`, and `15` joke recommendations:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，让我们比较前`5`、`10`和`15`个笑话推荐：
- en: '[PRE33]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Note that by executing the command, you will receive an output on how long
    it took to run the algorithm. We can now examine the performance using the `avg()`
    function:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，通过执行命令，你将收到关于算法运行时间的输出。现在我们可以使用`avg()`函数来检查性能：
- en: '[PRE34]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Note that the performance metrics for `POPULAR` and `UBCF` are nearly the same.
    One could say that the simpler-to-implement popular-based algorithm is probably
    the better choice for a model selection.  We can plot and compare the results
    as **Receiver Operating Characteristic Curves** (**ROC**), comparing `TPR` and
    `FPR` or precision/recall, as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`POPULAR`和`UBCF`的性能指标几乎相同。可以说，更易于实现的基于流行的算法可能是模型选择的更好选择。我们可以绘制并比较结果作为**接收者操作特征曲线**（**ROC**），比较`TPR`和`FPR`或精度/召回率，如下所示：
- en: '[PRE35]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The following is the output of the preceding command:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为前一个命令的输出结果：
- en: '![](img/image_10_08.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_08.png)'
- en: 'To get the precision/recall curve plot you only need to specify `"prec"` in
    the `plot` function:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取精度/召回率曲线图，你只需在`plot`函数中指定`"prec"`：
- en: '[PRE36]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下：
- en: '![](img/image_10_09.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_09.png)'
- en: You can clearly see in the plots that the popular-based and user-based algorithms
    are almost identical and outperform the item-based one. The `annotate=TRUE` parameter
    provides numbers next to the point that corresponds to the number of recommendations
    that we called for in our evaluation.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从图中清楚地看到，基于流行和基于用户的算法几乎相同，并且优于基于项目的算法。`annotate=TRUE`参数在对应于我们评估中要求的推荐数量的点上提供了数字。
- en: 'This was simple, but what are the actual recommendations from a model for a
    specific individual? This is quite easy to code as well. First, let''s build a
    `"popular"` recommendation engine on the full dataset. Then, we will find the
    top five recommendations for the first two raters. We will use the `Recommend()`
    function and apply it to the whole dataset, as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这很简单，但模型对特定个体的实际推荐是什么？这也很容易编写代码。首先，让我们在完整数据集上构建一个`"popular"`推荐引擎。然后，我们将找到前两个评分者的前五个推荐。我们将使用`Recommend()`函数并将其应用于整个数据集，如下所示：
- en: '[PRE37]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, we just need to get the top five recommendations for the first two raters
    and produce them as a list:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们只需要为前两个评分者获取前五个推荐并将它们作为列表生成：
- en: '[PRE38]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'It is also possible to see a rater''s specific rating score for each of the
    jokes by specifying this in the `predict()` syntax and then putting it in a matrix
    for review. Let''s do this for ten individuals (raters `300` through `309`) and
    three jokes (`71` through `73`):'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以通过在`predict()`语法中指定并放入一个矩阵进行审查来查看每个笑话的评分者的具体评分。让我们为十个人（评分者`300`至`309`）和三个笑话（`71`至`73`）做这个：
- en: '[PRE39]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The numbers in the matrix indicate the predicted rating scores for the jokes
    that the individual rated, while the NAs indicate those that the user did not
    rate.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵中的数字表示个人评分的笑话的预测评分，而NA表示用户未评分的笑话。
- en: 'Our final effort on this data will show how to build recommendations for those
    situations where the ratings are binary, that is, good or bad or 1 or 0\. We will
    need to turn the ratings into this binary format with 5 or greater as a 1 and
    less than 5 as 0\. This is quite easy to do with `Recommenderlab` using the `binarize()`
    function and specifying `minRating=5`:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这组数据上的最终努力将展示如何为评分是二元的那些情况构建推荐，也就是说，好或坏或1或0。我们需要将评分转换为这种二进制格式，5或以上为1，低于5为0。使用`Recommenderlab`的`binarize()`函数并指定`minRating=5`来做这件事非常简单：
- en: '[PRE40]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, we will need to have our data reflect the number of ratings equal to one
    in order to match what we need the algorithm to use for the training. For argument''s
    sake, let''s go with greater than 10\. The code to create the subset of the necessary
    data is shown in the following lines:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要让我们的数据反映等于一的评分数量，以便与算法用于训练的需求相匹配。为了方便起见，让我们选择大于10。创建必要数据子集的代码如下所示：
- en: '[PRE41]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'You will need to create `evaluationScheme`. In this instance, we will go with
    `cross-validation`. The default k-fold in the function is `10`, but we can also
    safely go with `k=5`, which will reduce our computation time:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要创建`evaluationScheme`。在这个例子中，我们将选择`cross-validation`。函数中的默认k折是`10`，但我们也可以安全地选择`k=5`，这将减少我们的计算时间：
- en: '[PRE42]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'For comparison purposes, the algorithms under evaluation will include `random`,
    `popular`, and `UBCF`:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较目的，评估的算法将包括`random`、`popular`和`UBCF`：
- en: '[PRE43]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'It is now time to build our model, as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候构建我们的模型了，如下所示：
- en: '[PRE44]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Forgoing the table of performance metrics, let''s take a look at the plots:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略性能指标表，让我们看看图表：
- en: '[PRE45]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下：
- en: '![](img/image_10_10.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_10.png)'
- en: '[PRE46]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令的输出如下：
- en: '![](img/image_10_11.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_11.png)'
- en: The user-based algorithm slightly outperforms the popular-based one, but you
    can clearly see that they are both superior to any random recommendation. In our
    business case, it will come down to the judgment of the decision-making team as
    to which algorithm to implement.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 基于用户的算法略优于基于流行度的算法，但您可以清楚地看到，它们都优于任何随机推荐。在我们的业务案例中，这取决于决策团队的判断，决定实施哪种算法。
- en: Sequential data analysis
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列数据分析
- en: There are known knowns. These are things we know that we know. There are known
    unknowns. That is to say, there are things that we know we don't know. But there
    are also unknown unknowns. There are things we don't know we don't know.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 有已知的已知。这是我们已知我们知道的事情。有已知的未知。也就是说，有我们知道我们不知道的事情。但也有未知的未知。有我们不知道我们不知道的事情。
- en: '- Donald Rumsfeld, Former Secretary of Defense'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '- 唐纳德·拉姆斯菲尔德，前国防部长'
- en: The very first business question I came across after the 1st edition was published
    revolved around product sequential analysis. The team worked on complicated Excel
    spreadsheets and pivot tables, along with a bunch of SAS code, to produce insights.
    After coming across this problem, I explored what could be done with R and was
    pleasantly surprised to stumble into the `TraMineR` package, specifically designed
    for just such a task. I believe the application of R to the problem would have
    greatly simplified the analysis.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 第一版发布后，我遇到的第一个商业问题是关于产品序列分析。团队使用复杂的Excel电子表格和交叉表，以及一大堆SAS代码，来产生洞察。在遇到这个问题后，我探索了使用R能做什么，并很高兴地偶然发现了专门为此类任务设计的`TraMineR`包。我相信将R应用于这个问题将大大简化分析。
- en: The package was designed for the social sciences, but it can be used in just
    about every situation where you want to mine and learn how observation's states
    evolve over discrete periods or events (longitudinal data). A classic use would
    be as in the case mentioned above where you want to understand the order in which
    customers purchase products. This would facilitate a recommendation engine of
    sorts where you can create the probability of the next purchase, as I've heard
    it being referred to as a next logical product offer. Another example could be
    in healthcare, examining the order that a patient receives treatments and/or medications,
    or even physician prescribing habits. I've worked on such tasks, creating simple
    and complex Markov chains to build models and create forecasts. Indeed, `TraMineR`
    allows the creation of Markov chain transition matrices to support such models.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 该包是为社会科学设计的，但它可以用于几乎任何您想要挖掘和学习观察状态在离散时间段或事件（纵向数据）中如何演变的情况。一个经典的使用案例就是上述提到的案例，您想了解客户购买产品的顺序。这将有助于创建某种推荐引擎，您可以创建下一次购买的几率，正如我听说它被称为下一个逻辑产品推荐。另一个例子可能是医疗保健领域，检查患者接受治疗和/或药物或甚至医生的处方习惯。我从事过这样的任务，创建简单和复杂的马尔可夫链来构建模型和创建预测。确实，`TraMineR`允许创建马尔可夫链转换矩阵来支持此类模型。
- en: 'The code we will examine does the hard work of creating, counting, and plotting
    the various combinations of transitions over time, also incorporating covariates.
    That will be our focus, but keep in mind that one can also build a dissimilarity
    matrix for clustering. The core features covered in the practical exercise will
    consist of the following:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要检查的代码负责创建、计数和绘制随时间变化的转换的各种组合，同时也包含了协变量。这将是我们的重点，但请记住，也可以构建一个用于聚类的相似度矩阵。实际练习中涵盖的核心特征将包括以下内容：
- en: Transition rates
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换率
- en: duration within each state
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个状态内的持续时间
- en: Sequence frequency
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列频率
- en: Let's get started.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Sequential analysis applied
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列分析应用
- en: 'For this exercise, I''ve created an artificial dataset; to follow along, you
    can download it from GitHub:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个练习，我创建了一个人工数据集；为了跟随，您可以从中下载它：[https://github.com/datameister66/data/blob/master/sequential.csv](https://github.com/datameister66/data/blob/master/sequential.csv)
- en: '[https://github.com/datameister66/data/blob/master/sequential.csv](https://github.com/datameister66/data/blob/master/sequential.csv)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/datameister66/data/blob/master/sequential.csv](https://github.com/datameister66/data/blob/master/sequential.csv)'
- en: 'There are also datasets available with the package and tutorials are available.
    My intent was to create something new that mirrored situations I have encountered.
    I developed it completely from random (with some supervision), so it does not
    match any real world data. It consists of 5,000 observations, with each observation,
    the history of a customer and nine variables:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 该包还提供了数据集和教程。我的意图是创建一些反映我所遇到的情况的新内容。我完全是从随机（在某种程度上有监督）中开发出来的，所以它不匹配任何真实世界的数据。它由5,000个观测值组成，每个观测值包含一个客户的购买历史和九个变量：
- en: Cust_segment--a factor variable indicating the customer's assigned segment (see
    [Chapter 8](f3f7c511-1b7f-4500-ba78-dd208b227ae0.xhtml), *Cluster Analysis*)
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cust_segment--一个表示客户分配细分市场的因子变量（见[第8章](f3f7c511-1b7f-4500-ba78-dd208b227ae0.xhtml)，*聚类分析*）
- en: Eight discrete purchase events named `Purchase1` through `Purchase8`; remember,
    these are events and not time-based, which is to say that a customer could have
    purchased all eight products at the same time, but in a specific order
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有八个离散的购买事件，命名为`Purchase1`至`Purchase8`；记住，这些是事件而不是基于时间的，也就是说，一个客户可以在同一时间购买所有八个产品，但顺序是特定的
- en: Within each purchase variable are the generic names of the product, seven possible
    products to be exact. They are named `Product_A` through `Product_G`.  What are
    these products? Doesn't matter! Use your imagination or apply it to your own situation.
    If a customer only purchased one product, then `Purchase1` would contain the name
    of that product and the other variables would be NULL.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个购买变量中都有产品的通用名称，确切地说有七个可能的产品。它们被命名为`Product_A`至`Product_G`。这些产品是什么？没关系！发挥你的想象力或者将其应用于你自己的情况。如果客户只购买了一个产品，那么`Purchase1`将包含该产品的名称，其他变量将为NULL。
- en: 'Here we load the file as a dataframe. The structure output is abbreviated for
    clarity:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将文件加载为数据框。为了清晰起见，输出结构被缩写：
- en: '[PRE47]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Time for some exploration of the data, starting with a table of the customer
    segment counts and a count of the first product purchased:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候探索数据了，从客户细分市场计数表和首次购买产品计数开始：
- en: '[PRE48]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '`Segment1` is the largest segment, and the most purchased initial product is
    `Product A`. However, is it the most purchased product overall? This code will
    provide the answer:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`Segment1`是最大的细分市场，最常购买的初始产品是`Product A`。然而，它是整体上最常购买的产品吗？这段代码将提供答案：'
- en: '[PRE49]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Yes, `ProductA` is the most purchased. The count of NULL values is 22,390.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，`ProductA`是最常购买的产品。NULL值的计数为22,390。
- en: 'Now you may be wondering if we can just build some summaries without much trouble,
    and that is surely the case. Here, I put the `count()` and `arrange()` functions
    from the `dplyr` package to good use to examine the frequency of sequences between
    the first and second purchase:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可能想知道我们是否可以轻松地构建一些总结，这当然是可以的。在这里，我充分利用了`dplyr`包中的`count()`和`arrange()`函数来检查第一次和第二次购买之间的序列频率：
- en: '[PRE50]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: We see that the most frequent sequences are the purchase of `ProductA` followed
    by another purchase of `ProductA`, along with the purchase of `ProductD` followed
    by no additional purchases. What is interesting is the frequency of similar product
    purchases.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，最频繁的序列是购买`ProductA`后再次购买`ProductA`，以及购买`ProductD`后没有其他购买。有趣的是类似产品购买的频率。
- en: 'We can now begin further examination using the `TraMineR` package. To begin,
    the data needs to be put into an object of class sequence with the `seqdef()`
    function. This should consist of only the sequences and not any covariates. Also,
    you can specify the distance of tick marks in plotting functions with `xstep =
    n`. In our case, we will have a tick mark for every event:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用`TraMineR`包开始进一步的检查。首先，需要使用`seqdef()`函数将数据放入序列类对象中。这应该只包含序列，不包含任何协变量。此外，您可以使用`xstep
    = n`在绘图函数中指定刻度的距离。在我们的情况下，我们将为每个事件有一个刻度：
- en: '[PRE51]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We can now explore the data further. Let''s look at the index plot, which produces
    the sequences of the first 10 observations. You can use indices with the data
    to examine as many observations and event periods as you wish:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以进一步探索数据。让我们看一下索引图，它产生了前10个观测值的序列。您可以使用索引与数据一起检查您想要的任何观测值和事件周期：
- en: '[PRE52]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下：
- en: '![](img/image_10_12.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_10_12.png)'
- en: 'One can plot all observations with `seqIplot()`, but given the size of the
    data, it doesn''t produce anything meaningful. A plot of distribution by state
    is more meaningful:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`seqIplot()`绘制所有观察结果，但鉴于数据量的大小，它不会产生任何有意义的结果。按状态分布的分布图更有意义：
- en: '[PRE53]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下：
- en: '![](img/image_10_13.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_13.png)'
- en: 'With this plot, it is easy to see the distribution of product purchases by
    state. We can also group this plot by segments and determine whether there are
    differences:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个图，很容易看到按州划分的产品购买分布。我们还可以按段分组此图，以确定是否存在差异：
- en: '[PRE54]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下：
- en: '![](img/image_10_14.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_14.png)'
- en: 'Here, we clearly see that `Segment2` has a higher proportion of `ProductA`
    purchases than the other segments. Another way to see that insight is with the
    modal plot:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以清楚地看到`Segment2`的`ProductA`购买比例高于其他段。另一种看到这个见解的方法是使用模式图：
- en: '[PRE55]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下：
- en: '![](img/image_10_15.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_15.png)'
- en: 'This is interesting. Around 50% of `Segment2` purchased `ProductA` first, while
    segment 4''s most frequent initial purchase was `ProductD`. Another plot that
    may be of interest, but I believe not in this case, is the mean time plot. It
    plots the average "time" spent in each state. Since we are not time-based, it
    doesn''t make sense, but I include for your consideration:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这很有趣。大约50%的`Segment2`首先购买了`ProductA`，而段4最频繁的初始购买是`ProductD`。另一个可能感兴趣的图，但我认为在这个案例中不是，是平均时间图。它绘制了每个状态的“平均时间”。由于我们不是基于时间的，这没有意义，但我包括供您考虑：
- en: '[PRE56]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Let''s supplement our preceding code and look further at the transition of
    sequences. This code creates an object of sequences, then narrows that down to
    those sequences with an occurrence of at least 5%, then plots the top 10 sequences:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们补充前面的代码，进一步观察序列的转换。此代码创建了一个序列对象，然后将其缩小到至少出现5%的序列，然后绘制前10个序列：
- en: '[PRE57]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The output of the preceding command is as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个命令的输出如下：
- en: '![](img/image_10_17.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_10_17.png)'
- en: Note that the plot shows the percentage frequency of the sequences through the
    eight transition states. If you want to narrow that down to, say, the first two
    transitions, you would do that in the `seqecreate()` function using indices.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，该图显示了通过八个转换状态的序列百分比频率。如果您想将其缩小到，比如说，前两个转换，您可以在`seqecreate()`函数中使用索引来完成：
- en: 'Finally, let''s see how you can use the data to create a transition matrix.
    This matrix shows the probability of transitioning from one state to the next.
    In our case, it provides the probability of purchasing the next product. As I
     mentioned before, this can also be used in a Markov chain simulation to develop
    a forecast. That is outside the scope of this chapter, but if you are interested
    I recommend having a look at the `markovchain` package in R and its tutorial on
    how to implement the procedure. Two possible transition matrices are available.
    One that incorporates the overall probability through all states and another that
    develops a transition matrix from one state to the next, that is, time-varying
    matrices. This code shows how to develop the former. To produce the latter, just
    specify `"time.varying = TRUE"` in the function:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看如何使用数据创建转换矩阵。这个矩阵显示了从一个状态转换到下一个状态的概率。在我们的案例中，它提供了购买下一个产品的概率。正如我之前提到的，这也可以用于马尔可夫链模拟来制定预测。但这超出了本章的范围，但如果您对此感兴趣，我建议您查看R中的`markovchain`包及其关于如何实现该过程的教程。有两个可能的转换矩阵可用。一个包含通过所有状态的整体概率，另一个从状态到下一个状态发展转换矩阵，即时间变化的矩阵。此代码显示了如何开发前者。要生成后者，只需在函数中指定`"time.varying
    = TRUE"`：
- en: '[PRE58]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The output shows rows 2 through 4 and columns 1 through 3\. The matrix shows
    us that the probability of having Product A and the next purchase being `ProductA`
    is almost 42%, while it is 19% to not purchase another product, and 17% to purchase
    `ProductB`. The final output we will examine is the probability of not purchasing
    another product for each prior purchase:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了第2行至第4行和第1列至第3列。矩阵显示，拥有产品A并且下一次购买也是`ProductA`的概率几乎是42%，而不购买其他产品的概率是19%，购买`ProductB`的概率是17%。我们将要检查的最后一个输出是每个先前购买不购买其他产品的概率：
- en: '[PRE59]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Of course, the matrix shows that the probability of not purchasing another product
    after not purchasing is 100%. Also notice that the probability of not purchasing
    after acquiring Product D is 33%. Implications for Segment4? Perhaps.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，矩阵显示，在未购买产品后不购买产品的概率是100%。请注意，在获得产品D后不购买的概率是33%。对Segment4有何影响？或许有。
- en: What is fascinating is that this analysis was done with only a few lines of
    code and didn't require the use of Excel or some expensive visualization software.
    Have longitudinal data? Give sequential analysis a try!
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 令人着迷的是，这项分析仅用了几行代码，并且不需要使用Excel或一些昂贵的可视化软件。你有纵向数据吗？尝试进行序列分析吧！
- en: Summary
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, the goal was to provide an introduction to how to use R in
    order to build and test association rule mining (market basket analysis) and recommendation
    engines. Market basket analysis is trying to understand what items are purchased
    together. With recommendation engines, the goal is to provide a customer with
    other items that they will enjoy based on how they have rated previously viewed
    or purchased items. It is important to understand the R package that we used (`recommenderlab`)
    for recommendation is not designed for implementation, but to develop and test
    algorithms. The other thing examined here was longitudinal data and mining it
    to learn valuable insights, in our case, the order in which customers purchased
    our products. Such an analysis has numerous applications, from marketing campaigns
    to healthcare.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，目标是介绍如何使用R来构建和测试关联规则挖掘（篮子分析）和推荐引擎。篮子分析试图了解哪些商品是共同购买的。在推荐引擎中，目标是根据客户之前评价的查看或购买的商品，向客户提供他们可能会喜欢的其他商品。了解我们使用的R包（`recommenderlab`）对于推荐来说，它不是为实施而设计的，而是用于开发和测试算法。这里还考察了纵向数据，并从中学习有价值的见解，在我们的案例中，是客户购买我们产品的顺序。这种分析有众多应用，从市场营销活动到医疗保健。
- en: We are now going to shift gears back to supervised learning. In the next chapter,
    we are going to cover some of the most exciting and important methods in practical
    machine learning, that is multi-class classification and creating ensemble models,
    something that is very easy to do in R with recent package releases.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将转换到监督学习。在下一章中，我们将介绍一些实际机器学习中最激动人心且重要的方法，即多类分类和创建集成模型，这在R语言中通过最近的包发布变得非常容易操作。
