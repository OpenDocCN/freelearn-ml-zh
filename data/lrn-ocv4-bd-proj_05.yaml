- en: Automated Optical Inspection, Object Segmentation, and Detection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动光学检测、对象分割和检测
- en: In [Chapter 4](ceaab6b4-2f4a-45e4-9f5d-2544c75bd405.xhtml), *Delving into Histogram
    and Filters*, we learned about histograms and filters, which allow us to understand
    image manipulation and create a photo application.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 4 章](ceaab6b4-2f4a-45e4-9f5d-2544c75bd405.xhtml)，*深入直方图和滤波器*，我们学习了直方图和滤波器，它们使我们能够理解图像处理并创建一个照片应用程序。
- en: In this chapter, we are going to introduce the basic concepts of object segmentation
    and detection. This means isolating the objects that appear in an image for future
    processing and analysis.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍对象分割和检测的基本概念。这意味着隔离图像中出现的对象，以便进行未来的处理和分析。
- en: 'This chapter introduces the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了以下主题：
- en: Noise removal
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 噪声去除
- en: Light/background removal basics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 光/背景去除基础
- en: Thresholding
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阈值化
- en: Connected components for object segmentation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象分割的连通组件
- en: Finding contours for object segmentation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找对象分割的轮廓
- en: Many industries use complex computer vision systems and hardware. Computer vision
    tries to detect problems and minimize errors produced in the production process,
    improving the quality of final products.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 许多行业使用复杂的计算机视觉系统和硬件。计算机视觉试图检测生产过程中产生的问题并最小化错误，从而提高最终产品的质量。
- en: In this sector, the name for this computer vision task is **Automated Optical
    Inspection** (**AOI**). This name appears in the inspection of printed circuit
    board manufacturers, where one or more cameras scan each circuit to detect critical
    failures and quality defects. This nomenclature was used in other manufacturing
    industries so that they could use optical camera systems and computer vision algorithms
    to increase product quality. Nowadays, optical inspection using different camera
    types (infrared or 3D cameras), depending on the requirements, and complex algorithms
    are used in thousands of industries for different purposes such as defect detection,
    classification, and so on.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域，这个计算机视觉任务的名称是 **自动光学检测**（**AOI**）。这个名称出现在印刷电路板制造商的检测中，其中一台或多台相机扫描每个电路以检测关键故障和质量缺陷。这种命名法在其他制造业中也得到了应用，以便它们可以使用光学相机系统和计算机视觉算法来提高产品质量。如今，根据需求使用不同类型的相机（红外或
    3D 相机）进行光学检测，并结合复杂的算法，在成千上万的行业中用于不同的目的，如缺陷检测、分类等。
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires familiarity with the basic C++ programming language.
    All of the code that''s used in this chapter can be downloaded from the following
    GitHub link: [https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_05](https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_05).
    The code can be executed on any operating system, though it is only tested on
    Ubuntu.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要熟悉基本的 C++ 编程语言。本章中使用的所有代码都可以从以下 GitHub 链接下载：[https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_05](https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_05)。代码可以在任何操作系统上执行，尽管它仅在
    Ubuntu 上进行了测试。
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，了解代码的实际应用：
- en: '[http://bit.ly/2DRbMbz](http://bit.ly/2DRbMbz)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2DRbMbz](http://bit.ly/2DRbMbz)'
- en: Isolating objects in a scene
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 场景中对象的隔离
- en: In this chapter, we are going to introduce the first step in an AOI algorithm
    and try to isolate different parts or objects in a scene. We are going to take
    the example of the object detection and classification of three object types (screw,
    packing ring, and nut) and develop them in this chapter and [Chapter 6](83822325-00be-4874-813c-b90097030d85.xhtml),
    *Learning Object Classification*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍 AOI 算法的第一步，并尝试隔离场景中的不同部分或对象。我们将以三种对象类型（螺丝、包装环和螺母）的对象检测和分类为例，并在本章以及
    [第 6 章](83822325-00be-4874-813c-b90097030d85.xhtml)，*学习对象分类* 中进行开发。
- en: 'Imagine that we are in a company that produces these three objects. All of
    them are in the same carrier tape. Our objective is to detect each object in the
    carrier tape and classify each one to allow a robot to put each object on the
    correct shelf:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 想象我们是一家生产这三种产品的公司。所有这些都在同一载体胶带上。我们的目标是检测载体胶带上的每个对象，并对每个对象进行分类，以便机器人将每个对象放在正确的货架上：
- en: '![](img/91eceec6-11d9-4b16-820d-cf0197e6f02c.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/91eceec6-11d9-4b16-820d-cf0197e6f02c.png)'
- en: In this chapter, we are going to learn how to isolate each object and detect
    its position in the image in pixels. In the next chapter, we are going to learn
    how to classify each isolated object to recognize if it is a nut, screw, or a
    packing ring.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何隔离每个对象并在像素中检测其位置。在下一章中，我们将学习如何对每个隔离对象进行分类，以识别它是否是螺母、螺丝或包装环。
- en: 'In the following screenshot, we show our desired result, where there are a
    few objects in the left image. In the right image, we have drawn each one in a
    different color, showing different features such as area, height, width, and contour
    size:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下屏幕截图中，我们展示了我们期望的结果，其中左图中有几个对象。在右图中，我们用不同的颜色标记了每个对象，以显示不同的特征，如面积、高度、宽度和轮廓大小：
- en: '![](img/530371fc-0a24-4292-84d5-06ddbc6015e5.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/530371fc-0a24-4292-84d5-06ddbc6015e5.png)'
- en: 'To reach this result, we are going to follow different steps that allow us
    to understand and organize our algorithms better. We can see these steps in the
    following diagram:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了达到这个结果，我们将遵循不同的步骤，这将使我们更好地理解和组织我们的算法。我们可以在以下图表中看到这些步骤：
- en: '![](img/b95b6820-afcb-47af-8838-0c76b82a8b8a.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b95b6820-afcb-47af-8838-0c76b82a8b8a.png)'
- en: Our application will be divided into two chapters. In this chapter, we are going
    to develop and understand the preprocessing and segmentation steps. In [Chapter
    6](83822325-00be-4874-813c-b90097030d85.xhtml), *Learning Object Classification*,
    we are going to extract the characteristics of each segmented object and train
    our machine learning system/algorithm on how to recognize each object class.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的应用程序将分为两个章节。在本章中，我们将开发并理解预处理和分割步骤。在[第6章](83822325-00be-4874-813c-b90097030d85.xhtml)“学习对象分类”中，我们将提取每个分割对象的特征，并在如何识别每个对象类别上训练我们的机器学习系统/算法。
- en: 'Our preprocessing steps will be divided into three more subsets:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将预处理步骤分为三个更小的子集：
- en: '**Noise Removal**'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**噪声去除**'
- en: '**Light Removal**'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**光去除**'
- en: '**Binarization**'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二值化**'
- en: 'In the segmentation step, we are going to use two different algorithms:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在分割步骤中，我们将使用两种不同的算法：
- en: Contour detection
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮廓检测
- en: '**Connected components** extraction (labeling)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**连通组件**提取（标记）'
- en: 'We can see these steps and the application flow in the following diagram:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下图表和应用流程图中看到这些步骤：
- en: '![](img/620e2715-7061-4e32-92a5-19d5b9a3f671.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/620e2715-7061-4e32-92a5-19d5b9a3f671.png)'
- en: Now, it's time to start the preprocessing step so that we can get the best **Binarization**
    image by removing the noise and lighting effects. This minimizes any possible
    detection errors.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候开始预处理步骤，以便我们可以通过去除噪声和光照效果来获得最佳的**二值化**图像。这最小化了任何可能的检测错误。
- en: Creating an application for AOI
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个用于AOI的应用
- en: 'To create our new application, we require a few input parameters. When a user
    executes the application, all of them are optional, excluding the input image
    to process. The input parameters are as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建我们的新应用程序，我们需要一些输入参数。当用户运行应用程序时，所有这些参数都是可选的，除了要处理的输入图像。输入参数如下：
- en: Input image to process
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要处理的输入图像
- en: Light image pattern
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 光图像模式
- en: Light operation, where a user can choose between difference or divide operations
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 光操作，用户可以在差分或除法操作之间进行选择
- en: If the user sets `0` as a value, the difference operation is applied
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户将`0`设置为值，则应用差分操作
- en: If the user set `1` as a value, the division operation is applied
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户将`1`设置为值，则应用除法操作
- en: Segmentation, where the user can choose between connected components with or
    without statistics and find contour methods
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分割，用户可以在带有或不带有统计的连通组件和查找轮廓方法之间进行选择
- en: If the user sets `1` as the input value, the connected components method for
    segment is applied
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户将`1`设置为输入值，则应用分割的连通组件方法
- en: If the user sets `2` as the input value, the connected components method with
    the statistics area is applied
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户将`2`设置为输入值，则应用带有统计区域的连通组件方法
- en: If the user sets `3` as the input value, the find contours method is applied
    for Segmentation
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户将`3`设置为输入值，则应用查找轮廓方法进行分割
- en: 'To enable this user selection, we are going to use the `command line parser`
    class with the following keys:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启用此用户选择，我们将使用具有以下键的`命令行解析器`类：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We are going to use the `command line parser` class in the `main` function
    by checking the parameters. The `CommandLineParser` is explained in [Chapter 2](37cf2702-b8c6-41ff-a935-fd4030f8ce64.xhtml),
    *An Introduction to the Basics of OpenCV*, in the *Reading videos and cameras*
    section:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 `main` 函数中通过检查参数来使用 `command line parser` 类。`CommandLineParser` 在 *OpenCV
    基础入门* 的 *读取视频和摄像头* 部分的 [第 2 章](37cf2702-b8c6-41ff-a935-fd4030f8ce64.xhtml) 中有解释：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After parsing our command-line user data, we need to check the input image
    has been loaded correctly. We then load the image and check it has data:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在解析我们的命令行用户数据后，我们需要检查输入图像是否已正确加载。然后我们加载图像并检查它是否有数据：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now, we are ready to create our AOI process of segmentation. We are going to
    start with the preprocessing task.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备创建我们的 AOI 分割过程。我们将从预处理任务开始。
- en: Preprocessing the input image
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预处理输入图像
- en: This section introduces some of the most common techniques that we can apply
    for preprocessing images in the context of object segmentation/detection. The
    preprocessing is the first change we make to a new image before we start working
    and extracting the information we require from it. Normally, in the preprocessing
    step, we try to minimize the image noise, light conditions, or image deformation
    due to a camera lens. These steps minimize errors while detecting objects or segments
    in our image.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了我们可以在对象分割/检测的上下文中应用的一些最常见的预处理图像技术。预处理是在我们开始工作并从图像中提取所需信息之前对新的图像所做的第一个更改。通常，在预处理步骤中，我们试图最小化图像噪声、光照条件或由于相机镜头引起的图像变形。这些步骤在检测图像中的对象或区域时最小化错误。
- en: Noise removal
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 噪声去除
- en: If we don't remove the noise, we can detect more objects than we expect because
    noise is normally represented as small points in the image and can be segmented
    as an object. The sensor and scanner circuit normally produces this noise. This
    variation of brightness or color can be represented in different types, such as
    Gaussian noise, spike noise, and shot noise.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不去除噪声，我们可以检测到比预期更多的对象，因为噪声通常在图像中表示为小点，并且可以作为对象进行分割。传感器和扫描仪电路通常产生这种噪声。这种亮度或颜色的变化可以表示为不同的类型，如高斯噪声、尖峰噪声和闪烁噪声。
- en: 'There are different techniques that can be used to remove the noise. Here,
    we are going to use a smooth operation, but depending on the type of noise, some
    are better than others. A median filter is normally used for removing salt-and-pepper
    noise; for example, consider the following image:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同的技术可以用来去除噪声。在这里，我们将使用平滑操作，但根据噪声的类型，有些方法比其他方法更好。中值滤波器通常用于去除椒盐噪声；例如，考虑以下图像：
- en: '![](img/578318f1-5c92-42a9-a75a-fb6c2d6cee45.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/578318f1-5c92-42a9-a75a-fb6c2d6cee45.png)'
- en: 'The preceding image is the original input with salt-and-pepper noise. If we
    apply a median blur, we get an awesome result in which we lose small details.
    For example, we lose the borders of the screw, but we maintain perfect edges.
    See the result in the following image:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图像是带有椒盐噪声的原始输入图像。如果我们应用中值模糊，我们会得到一个很棒的结果，但我们失去了小的细节。例如，我们失去了螺丝的边缘，但我们保持了完美的边缘。请看以下图像中的结果：
- en: '![](img/ee868769-9c8d-4a81-b863-80c4c3455735.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee868769-9c8d-4a81-b863-80c4c3455735.png)'
- en: 'If we apply a box filter or Gaussian filter, the noise is not removed but made
    smooth, and the details of the objects are lost and smoothened too. See the following
    image for the result:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们应用盒式滤波器或高斯滤波器，噪声不会被去除，而是变得平滑，对象的细节也会丢失并变得平滑。请看以下图像中的结果：
- en: '![](img/ddc55313-3189-4ceb-b113-ec491c19868e.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ddc55313-3189-4ceb-b113-ec491c19868e.png)'
- en: 'OpenCV brings us the `medianBlur` function, which requires three parameters:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 为我们带来了 `medianBlur` 函数，该函数需要三个参数：
- en: An input image with the `1`, `3`, or `4` channel's image. When the kernel size
    is bigger than `5`, the image depth can only be `CV_8U`.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有 `1`、`3` 或 `4` 通道的输入图像。当核心大小大于 `5` 时，图像深度只能为 `CV_8U`。
- en: An output image, which is the resulting image on applying median blur with the
    same type and depth as the input.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个输出图像，它是应用中值模糊后的结果图像，其类型和深度与输入图像相同。
- en: Kernel size, which is an aperture size greater than `1` and odd, for example,
    3, 5, 7, and so on.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心大小，它是一个大于 `1` 且为奇数的孔径大小，例如，3、5、7 等等。
- en: 'The following code is used to remove noise:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码用于去除噪声：
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Removing the background using the light pattern for segmentation
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用光模式进行分割以去除背景
- en: 'In this section, we are going to develop a basic algorithm that will enable
    us to remove the background using a light pattern. This preprocessing gives us
    better segmentation. The input image without noise is as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将开发一个基本算法，使我们能够使用光线模式去除背景。这种预处理使我们获得更好的分割。无噪声的输入图像如下：
- en: '![](img/c86fa656-74fa-4826-abe4-7fc224178280.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c86fa656-74fa-4826-abe4-7fc224178280.png)'
- en: 'If we apply a basic threshold, we will obtain an image result like this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们应用一个基本的阈值，我们将获得如下图像结果：
- en: '![](img/b3f80307-88d1-41d1-a11b-87e56bf39eef.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b3f80307-88d1-41d1-a11b-87e56bf39eef.png)'
- en: 'We can see that the top image artifact has a lot of white noise. If we apply
    a light pattern and background removal technique, we can obtain an awesome result
    in which we can see that there are no artifacts in the top of image, like the
    previous threshold operation, and we will obtain better results when we have to
    segment. We can see the result of background removal and thresholding in the following
    image:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，顶部图像的伪影有很多白色噪声。如果我们应用光线模式和背景去除技术，我们可以获得一个很棒的结果，其中我们可以看到图像顶部没有伪影，就像之前的阈值操作一样，并且在我们需要分割时，我们将获得更好的结果。我们可以在以下图像中看到背景去除和阈值的结果：
- en: '![](img/0e37e0ca-7254-44ac-ac6f-b57b85ad9de5.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0e37e0ca-7254-44ac-ac6f-b57b85ad9de5.png)'
- en: 'Now, how can we remove the light from our image? This is very simple: we only
    need a picture of our scenario without any objects, taken from exactly the same
    position and under the same lighting conditions that the other images were taken
    under; this is a very common technique in AOI because the external conditions
    are supervised and well-known. The image result for our case is similar to the
    following image:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们如何从我们的图像中去除光线？这非常简单：我们只需要一张没有任何物体的场景图片，从与其他图像相同的精确位置和相同的照明条件下拍摄；这是AOI中一个非常常见的技巧，因为外部条件是受监督和已知的。我们案例的图像结果类似于以下图像：
- en: '![](img/f3ed20a6-9d23-4926-aba8-d79d7a9a950c.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f3ed20a6-9d23-4926-aba8-d79d7a9a950c.png)'
- en: 'Now, using a simple mathematical operation, we can remove this light pattern.
    There are two options for removing it:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过简单的数学运算，我们可以去除这种光线模式。去除光线模式有两种选择：
- en: Difference
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 差值
- en: Division
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除法
- en: 'The difference option is the simplest approach. If we have the light pattern
    `L` and the image picture `I`, the resulting removal `R` is the difference between
    them:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是最简单的方法。如果我们有光线模式 `L` 和图像图片 `I`，结果去除 `R` 是它们之间的差值：
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This division is a bit more complex, but simple at the same time. If we have
    the light pattern matrix `L` and the image picture matrix `I`, the result removal
    `R` is as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这种除法稍微复杂一些，但同时也很简单。如果我们有光线模式矩阵 `L` 和图像图片矩阵 `I`，结果去除 `R` 如下：
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this case, we divide the image by the light pattern, and we have the assumption
    that if our light pattern is white and the objects are darker than the background
    carrier tape, then the image pixel values are always the same or lower than the
    light pixel values. The result we obtain from `I/L` is between `0` and `1`. Finally,
    we invert the result of this division to get the same color direction range and
    multiply it by `255` to get values within the range of `0-255`.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将图像除以光线模式，我们假设如果我们的光线模式是白色，而物体比背景载体胶带暗，那么图像像素值总是与光线像素值相同或更低。从 `I/L`
    获得的结果在 `0` 和 `1` 之间。最后，我们将这个除法的结果取反，以获得相同颜色的方向范围，并将其乘以 `255` 以获得 `0-255` 范围内的值。
- en: 'In our code, we are going to create a new function called `removeLight` with
    the following parameters:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的代码中，我们将创建一个名为 `removeLight` 的新函数，具有以下参数：
- en: An input image to remove the light/background
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要去除光线/背景的输入图像
- en: A light pattern, `Mat`
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个光线模式，`Mat`
- en: A method, with a `0` value for difference and `1` for division
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个方法，差值为 `0`，除法为 `1`
- en: 'The result is a new image matrix without light/background. The following code
    implements the removal of the background through the use of the light pattern:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个新的图像矩阵，没有光线/背景。以下代码通过使用光线模式实现去除背景：
- en: '[PRE6]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Let's explore this. After creating the `aux` variable to save the result, we
    select the method chosen by the user and pass the parameter to the function. If
    the method that was selected is `1`, we apply the division method.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一下。在创建用于保存结果的 `aux` 变量后，我们选择用户选择的方法并将参数传递给函数。如果选择的方法是 `1`，则应用除法方法。
- en: 'The division method requires a 32-bit float of images to allow us to divide
    the images and not truncate the numbers into integers. The first step is to convert
    the image and light pattern mat to floats of 32 bits. To convert images of this
    format, we can use the `convertTo` function of the `Mat` class. This function
    accepts four parameters; the output converted image and the format you wish to
    convert to the required parameters, but you can define alpha and beta parameters,
    which allow you to scale and shift the values following the next function, where
    *O* is the output image and *I* the input image:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 除法方法需要一个32位浮点图像，这样我们才能除以图像，而不会将数字截断为整数。第一步是将图像和光模式`mat`转换为32位浮点。为了转换这种格式的图像，我们可以使用`Mat`类的`convertTo`函数。这个函数接受四个参数；输出转换后的图像和您希望转换到的格式，但您可以定义alpha和beta参数，这些参数允许您根据以下函数缩放和移动值，其中*O*是输出图像，*I*是输入图像：
- en: '*O*(*x*,*y*)=*cast*<*Type*>(*α* * *I*(*x*,*y*)+*β*)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*O*(*x*,*y*)=*cast*<*Type*>(*α* * *I*(*x*,*y*)+*β*)'
- en: 'The following code changes the image to 32-bit float:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将图像转换为32位浮点：
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, we can carry out the mathematical operations on our matrix as we described,
    by dividing the image by the pattern and inverting the result:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以按照我们描述的方式在我们的矩阵上执行数学运算，通过将图像除以图案并反转结果：
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, we have the result but it is required to return it to an 8-bit depth image,
    and then use the convert function as we did previously to convert the image''s
    `mat` and scale from `0` to `255` using the alpha parameter:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经得到了结果，但需要将其返回到8位深度图像，然后使用我们之前使用的转换函数，通过alpha参数将图像的`mat`和缩放从`0`到`255`：
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, we can return the `aux` variable with the result. For the difference method,
    the development is very easy because we don''t have to convert our images; we
    only need to apply the difference between the pattern and image and return it.
    If we don''t assume that the pattern is equal to or greater than an image, then
    we will require a few checks and truncate values that can be less than `0` or
    greater than `255`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以返回带有结果的`aux`变量。对于差分方法，开发非常简单，因为我们不需要转换我们的图像；我们只需要应用图案和图像之间的差值并返回它。如果我们不假设图案等于或大于图像，那么我们将需要一些检查并截断可能小于`0`或大于`255`的值：
- en: '[PRE10]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following images are the results of applying the image light pattern to
    our input image:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像是应用图像光模式到我们的输入图像的结果：
- en: '![](img/462bbbc5-adf9-4030-bc5c-58d0e3883a95.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/462bbbc5-adf9-4030-bc5c-58d0e3883a95.png)'
- en: 'In the results that we obtain, we can check how the light gradient and the
    possible artifacts are removed. But what happens when we don''t have a light/background
    pattern? There are a few different techniques to obtain this; we are going to
    present the most basic one here. Using a filter, we can create one that can be
    used, but there are better algorithms to learn about the background of images
    where the pieces appear in different areas. This technique sometimes requires
    a background estimation image initialization, where our basic approach can play
    very well. These advanced techniques will be explored in [Chapter 8](58a72603-be5a-465f-aa7b-fc8ab1aae596.xhtml),
    *Video Surveillance, Background Modeling, and Morphological Operations*. To estimate
    the background image, we are going to use a blur with a large kernel size applied
    to our input image. This is a common technique used in **optical character recognition**
    *(***OCR**), where the letters are thin and small relative to the whole document,
    allowing us to do an approximation of the light patterns in the image. We can
    see the light/background pattern reconstruction in the left-hand image and the
    ground truth in the right-hand:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们获得的结果中，我们可以检查光梯度以及可能的伪影是如何被移除的。但是，当我们没有光/背景图案时会发生什么？有几种不同的技术可以获取这种图案；我们在这里将要展示最基本的一种。使用过滤器，我们可以创建一个可用的图案，但还有更好的算法来学习图像背景，其中图像的各个部分出现在不同的区域。这种技术有时需要背景估计图像初始化，而我们的基本方法可以发挥很好的作用。这些高级技术将在[第8章](58a72603-be5a-465f-aa7b-fc8ab1aae596.xhtml)，*视频监控、背景建模和形态学操作*中进行探讨。为了估计背景图像，我们将对我们的输入图像应用一个具有大核大小的模糊。这是一种在**光学字符识别**（***OCR**）中常用的技术，其中字母相对于整个文档来说又薄又小，这使得我们能够对图像中的光模式进行近似。我们可以在左侧图像中看到光/背景图案重建，在右侧图像中看到真实情况：
- en: '![](img/49a8a85d-84fb-4670-8638-9fe58368fb37.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/49a8a85d-84fb-4670-8638-9fe58368fb37.png)'
- en: 'We can see that there are minor differences in the light patterns, but this
    result is enough to remove the background. We can also see the result in the following
    image when using different images. In the following image, the result of applying
    the image difference between the original input image and the estimated background
    image computed with the previous approach is depicted:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到光模式之间存在一些细微的差异，但这个结果足以移除背景。我们还可以在以下图像中看到使用不同图像时的结果。在以下图像中，展示了使用先前方法计算出的原始输入图像与估计背景图像之间的图像差的结果：
- en: '![](img/be080517-2a8e-4778-8751-3a22adc85bc5.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/be080517-2a8e-4778-8751-3a22adc85bc5.png)'
- en: 'The `calculateLightPattern` function creates this light pattern or background
    approximation:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`calculateLightPattern` 函数创建此光模式或背景近似：'
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This basic function applies a blur to an input image by using a big kernel size
    relative to the image size. From the code, it is **one-third** of the original
    width and height.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此基本函数通过使用相对于图像大小的大内核大小对输入图像应用模糊。从代码中可以看出，它是原始宽度和高度的**三分之一**。
- en: Thresholding
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阈值化
- en: 'After removing the background, we only have to binarize the image for future
    segmentation. We are going to do this with threshold. `Threshold` is a simple
    function that sets each pixel''s values to a maximum value (255, for example).
    If the pixel''s value is greater than the **threshold** value or if the pixel''s
    value is lower than the **threshold** value, it will be set to a minimum (0):'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在移除背景后，我们只需要对图像进行二值化，以便进行未来的分割。我们将使用阈值来完成这项工作。`阈值`是一个简单的函数，它将每个像素的值设置为最大值（例如，255）。如果像素的值大于**阈值**值或小于**阈值**值，它将被设置为最小值（0）：
- en: '![](img/d1576ef1-198b-4e9f-ab66-1f109349699f.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d1576ef1-198b-4e9f-ab66-1f109349699f.png)'
- en: 'Now, we are going to apply the `threshold` function using two different `threshold`
    values: we will use a 30 `threshold` value when we remove the light/background
    because all non-interesting regions are black. This is because we apply background
    removal. We will also a medium value `threshold` (140) when we do not use a light
    removal method, because we have a white background. This last option is used to
    allow us to check the results with and without background removal:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用两个不同的`阈值`值应用`阈值`函数：当我们移除光/背景时，我们将使用30的`阈值`值，因为所有非感兴趣区域都是黑色的。这是因为我们应用了背景移除。当不使用光移除方法时，我们也将使用一个中等值`阈值`（140），因为我们有一个白色背景。这个最后的选项用于允许我们检查有和无背景移除的结果：
- en: '[PRE12]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, we are going to continue with the most important part of our application:
    the segmentation. We are going to use two different approaches or algorithms here:
    connected components and find contours.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将继续到我们应用程序最重要的部分：分割。在这里，我们将使用两种不同的方法或算法：连接组件和查找轮廓。
- en: Segmenting our input image
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分割我们的输入图像
- en: 'Now, we are going to introduce two techniques to segment our threshold image:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将介绍两种技术来分割我们的阈值图像：
- en: Connected components
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接组件
- en: Find contours
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找轮廓
- en: With these two techniques, we are allowed to extract each **region of interest**
    (**ROI**) of our image where our targets objects appear. In our case, these are
    the nut, screw, and ring.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两种技术，我们可以提取图像中感兴趣的区域（**ROI**），其中我们的目标对象出现。在我们的案例中，这些是螺母、螺丝和环。
- en: The connected components algorithm
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接组件算法
- en: 'The connected component algorithm is a very common algorithm that''s used to
    segment and identify parts in binary images. The connected component is an iterative
    algorithm with the purpose of labeling an image using eight or four connectivity
    pixels. Two pixels are connected if they have the same value and are neighbors.
    In an image, each pixel has eight neighbor pixels:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 连接组件算法是一个非常常见的算法，用于在二值图像中分割和识别部分。连接组件是一个迭代算法，其目的是使用八个或四个连通像素对图像进行标记。如果两个像素具有相同的值并且是邻居，则它们是连通的。在图像中，每个像素有八个相邻像素：
- en: '![](img/b60dde12-2347-4af3-b0a1-063963874bee.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b60dde12-2347-4af3-b0a1-063963874bee.png)'
- en: 'Four-connectivity means that only the **2**, **4**, **5**, and **7** neighbors
    can be connected to the center if they have the same value as the center pixel.
    With eight-connectivity, the **1**, **2**, **3**, **4**, **5**, **6**, **7**,
    and **8** neighbors can be connected if they have the same value as the center
    pixel. We can see the differences in the following example from a four- and eight-connectivity
    algorithm. We are going to apply each algorithm to the next binarized image. We
    have used a small **9 x 9** image and zoomed in to show how connected components
    work and the differences between four- and eight-connectivity:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 四连通性意味着如果中心像素的值与中心像素相同，则只有 **2**、**4**、**5** 和 **7** 个邻居可以连接到中心。在八连通性中，如果中心像素的值与中心像素相同，则
    **1**、**2**、**3**、**4**、**5**、**6**、**7** 和 **8** 个邻居可以连接。我们可以在以下示例中看到四连通性和八连通性算法之间的差异。我们将应用每个算法到下一个二值化图像。我们使用了一个小的
    **9 x 9** 图像并放大以显示连通组件的工作原理以及四连通性和八连通性之间的差异：
- en: '![](img/26a8c0f5-f584-4d8b-b660-12eb8b7261f2.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/26a8c0f5-f584-4d8b-b660-12eb8b7261f2.png)'
- en: 'The four-connectivity algorithm detects two objects; we can see this in the
    left image. The eight-connectivity algorithm detects only one object (the right
    image) because two diagonal pixels are connected. Eight-connectivity takes care
    of diagonal connectivity, which is the main difference compared with four-connectivity,
    since this where only vertical and horizontal pixels are considered. We can see
    the result in the following image, where each object has a different gray color
    value:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 四连通性算法检测到两个对象；我们可以在左边的图像中看到这一点。八连通性算法只检测到一个对象（右边的图像），因为两个对角像素是连通的。八连通性考虑了对角连通性，这是与四连通性的主要区别，因为四连通性只考虑垂直和水平像素。我们可以在以下图像中看到结果，其中每个对象都有不同的灰度颜色值：
- en: '![](img/b40375cf-b26e-4e47-bb95-189154b06334.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b40375cf-b26e-4e47-bb95-189154b06334.png)'
- en: 'OpenCV brings us the connected components algorithm with two different functions:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 通过两个不同的函数为我们带来了连通组件算法：
- en: '`connectedComponents` (image, labels, connectivity= `8`, type= `CV_32S`)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`connectedComponents` (image, labels, connectivity= `8`, type= `CV_32S`)'
- en: '`connectedComponentsWithStats` (image, labels, stats, centroids, connectivity=
    `8`, type= `CV_32S`)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`connectedComponentsWithStats` (image, labels, stats, centroids, connectivity=
    `8`, type= `CV_32S`)'
- en: 'Both functions return an integer with the number of detected labels, where
    label `0` represents the background. The difference between these two functions
    is basically the information that is returned. Let''s check the parameters of
    each one. The `connectedComponents` function gives us the following parameters:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 两个函数都返回一个整数，表示检测到的标签数，其中标签 `0` 表示背景。这两个函数之间的区别基本上是返回的信息。让我们检查每个函数的参数。`connectedComponents`
    函数给出了以下参数：
- en: '**Image**: The input image to be labeled.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Image**: 要标记的输入图像。'
- en: '**Labels**: An output mat that''s the same size as the input image, where each
    pixel has the value of its label, where all OS represents the background, pixels
    with `1` value represent the first connected component object, and so on.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Labels**: 一个输出矩阵，其大小与输入图像相同，其中每个像素的值为其标签的值，其中所有 OS 表示背景，值为 `1` 的像素表示第一个连通组件对象，依此类推。'
- en: '**Connectivity**: Two possible values, `8` or `4`, that represent the connectivity
    we want to use.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Connectivity**: 两个可能的值，`8` 或 `4`，表示我们想要使用的连通性。'
- en: '**Type**: The type of label image we want to use. Only two types are allowed:
    `CV32_S` and `CV16_U`. By default, this is `CV32_S`.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Type**: 我们想要使用的标签图像的类型。只允许两种类型：`CV32_S` 和 `CV16_U`。默认情况下，这是 `CV32_S`。'
- en: 'The `connectedComponentsWithStats` function has two more parameters defined.
    These are stats and centroids:'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`connectedComponentsWithStats` 函数定义了两个额外的参数。这些是 stats 和 centroids：'
- en: '**Stats**: This is an output parameter that gives us the following statistical
    values for each label (background inclusive):'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Stats**: 这是一个输出参数，它为我们提供了每个标签（包括背景）的以下统计值：'
- en: '`CC_STAT_LEFT`: The leftmost `x` coordinate of the connected component object'
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CC_STAT_LEFT`: 连通组件对象的左侧 `x` 坐标'
- en: '`CC_STAT_TOP`: The topmost `y` coordinate of the connected component object'
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CC_STAT_TOP`: 连通组件对象的顶部 `y` 坐标'
- en: '`CC_STAT_WIDTH`: The width of the connected component object defined by its
    bounding box'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CC_STAT_WIDTH`: 由其边界框定义的连通组件对象的宽度'
- en: '`CC_STAT_HEIGHT`: The height of the connected component object defined by its
    bounding box'
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CC_STAT_HEIGHT`: 由其边界框定义的连通组件对象的高度'
- en: '`CC_STAT_AREA`: The number of pixels (area) of the connected component object'
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CC_STAT_AREA`: 连通组件对象的像素数（面积）'
- en: '**Centroids**: The centroid points to the float type for each label, inclusive
    of the background that''s considered for another connected component.'
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**质心**：质心指向每个标签的浮点类型，包括被认为属于另一个连通分量的背景。'
- en: In our example application, we are going to create two functions so that we
    can apply these two OpenCV algorithms. We will then show the user the obtained
    result in a new image with colored objects in the basic connected component algorithm.
    If we select the connected component with the stats method, we are going to draw
    the respective calculated area that returns this function over each object.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例应用程序中，我们将创建两个函数，以便我们可以应用这两个OpenCV算法。然后，我们将以带有彩色对象的新的图像形式向用户展示获得的结果，在基本的连通分量算法中。如果我们选择使用stats方法的连通分量，我们将绘制每个对象返回的相应计算面积。
- en: 'Let''s define the basic drawing for the connected component function:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义连通分量函数的基本绘图：
- en: '[PRE13]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'First of all, we call the OpenCV `connectedComponents` function, which returns
    the number of objects detected. If the number of objects is less than two, this
    means that only the background object is detected, and then we don''t need to
    draw anything and we can finish. If the algorithm detects more than one object,
    we show the number of objects that have been detected on the console:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们调用OpenCV的`connectedComponents`函数，它返回检测到的对象数量。如果对象的数量少于两个，这意味着只检测到了背景对象，那么我们不需要绘制任何东西，可以直接结束。如果算法检测到多个对象，我们将在控制台上显示检测到的对象数量：
- en: '[PRE14]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, we are going to draw all detected objects in a new image with different
    colors. After this, we need to create a new black image with the same input size
    and three channels:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用不同的颜色在新的图像中绘制所有检测到的对象。之后，我们需要创建一个与输入大小相同且具有三个通道的新黑色图像：
- en: '[PRE15]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We will loop over each label, except for the `0` value, because this is the
    background:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将遍历每个标签，除了`0`值，因为这是背景：
- en: '[PRE16]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To extract each object from the label image, we can create a mask for each
    `i` label using a comparison and save this in a new image:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从标签图像中提取每个对象，我们可以为每个`i`标签创建一个掩码，使用比较并保存到新图像中：
- en: '[PRE17]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Finally, we set a pseudo-random color to the output image using the `mask`:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用`mask`将伪随机颜色设置到输出图像上：
- en: '[PRE18]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'After looping all of the images, we have all of the detected objects with different
    colors in our output and we only have to show the output image in a window:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在遍历所有图像之后，我们将在输出中看到不同颜色的所有检测到的对象，我们只需要在窗口中显示输出图像：
- en: '[PRE19]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This is the result in which each object is painted with different colors or
    a gray value:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果，其中每个对象都被涂上不同的颜色或灰度值：
- en: '![](img/c1ba4e5a-e7ba-4e3e-b50f-1feb158a6dab.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c1ba4e5a-e7ba-4e3e-b50f-1feb158a6dab.png)'
- en: 'Now, we are going to explain how to use the connected components with the `stats`
    OpenCV algorithm and show some more information in the resultant image. The following
    function implements this functionality:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将解释如何使用带有`stats` OpenCV算法的连通分量，并在结果图像中显示更多信息。以下函数实现了这个功能：
- en: '[PRE20]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s understand this code. As we did in the non-stats function, we call the
    connected components algorithm, but here, we do this using the `stats` function,
    checking whether we detected more than one object:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来理解这段代码。正如我们在非统计函数中所做的那样，我们调用连通分量算法，但在这里，我们使用`stats`函数来完成，检查是否检测到多个对象：
- en: '[PRE21]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we have two more output results: the stats and centroid variables. Then,
    for each detected label, we are going to show the centroid and area through the
    command line:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有两个额外的输出结果：stats和centroid变量。然后，对于每个检测到的标签，我们将通过命令行显示质心和面积：
- en: '[PRE22]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You can check the call to the stats variable to extract the area using the
    column constant `stats.at<int>(I, CC_STAT_AREA)`. Now, like before, we paint the
    object labeled with `i` over the output image:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过调用stats变量并使用列常量`stats.at<int>(I, CC_STAT_AREA)`来检查提取面积。现在，就像之前一样，我们在输出图像上绘制标签为`i`的对象：
- en: '[PRE23]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, in the centroid position of each segmented object, we want to draw
    some information (such as the area) on the resultant image. To do this, we use
    the stats and centroid variables using the `putText` function. First, we have
    to create a `stringstream` so that we can add the stats area information:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在每个分割对象的质心位置，我们想在结果图像上绘制一些信息（例如面积）。为此，我们使用`putText`函数和stats以及centroid变量。首先，我们必须创建一个`stringstream`，以便我们可以添加stats面积信息：
- en: '[PRE24]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Then, we need to use `putText`, using the centroid as the text position:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要使用`putText`，使用质心作为文本位置：
- en: '[PRE25]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The result for this function is as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数的结果如下：
- en: '![](img/10e79360-47ac-4ae7-83c2-67547df40016.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10e79360-47ac-4ae7-83c2-67547df40016.png)'
- en: The findContours algorithm
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`findContours` 算法'
- en: 'The `findContours` algorithm is one of the most used OpenCV algorithms in regards
    to segment objects. This is because this algorithm was included in OpenCV from
    version 1.0 and gives developers more information and descriptors, including shapes,
    topological organizations, and so on:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`findContours` 算法是 OpenCV 中用于分割对象最常用的算法之一。这是因为该算法自 OpenCV 1.0 版本起就被包含在内，为开发者提供了更多信息和解描述符，包括形状、拓扑组织等：'
- en: '[PRE26]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Let''s explain each parameter:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释每个参数：
- en: '**Image**: Input binary image.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像**：输入二值图像。'
- en: '**Contours**: A contour''s output where each detected contour is a vector of
    points.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**轮廓**：轮廓的输出，其中每个检测到的轮廓都是一个点的向量。'
- en: '**Hierarchy**: This is the optional output vector where the hierarchy of contours
    is saved. This is the topology of the image where we can get the relations between
    each contour. The hierarchy is represented as a vector of four indices, which
    are (next contour, previous contour, first child, parent contour). Negative indices
    are given where the given contour has no relationship with other contours. A more
    detailed explanation can be found at [https://docs.opencv.org/3.4/d9/d8b/tutorial_py_contours_hierarchy.html](https://docs.opencv.org/3.4/d9/d8b/tutorial_py_contours_hierarchy.html).'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**层次结构**：这是一个可选的输出向量，其中保存了轮廓的层次结构。这是图像的拓扑结构，我们可以从中获取每个轮廓之间的关系。层次结构以四个索引的向量表示，分别是（下一个轮廓、前一个轮廓、第一个子轮廓、父轮廓）。如果给定的轮廓与其他轮廓没有关系，则给出负索引。更详细的解释可以在[https://docs.opencv.org/3.4/d9/d8b/tutorial_py_contours_hierarchy.html](https://docs.opencv.org/3.4/d9/d8b/tutorial_py_contours_hierarchy.html)找到。'
- en: '**Mode**: This method is used to retrieve the contours:'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模式**：此方法用于检索轮廓：'
- en: '`RETR_EXTERNAL` retrieves only the external contours.'
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RETR_EXTERNAL` 仅检索外部轮廓。'
- en: '`RETR_LIST` retrieves all contours without establishing the hierarchy.'
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RETR_LIST` 检索所有轮廓而不建立层次结构。'
- en: '`RETR_CCOMP` retrieves all contours with two levels of hierarchy, external
    and holes. If another object is inside one hole, this is put at the top of the
    hierarchy.'
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RETR_CCOMP` 检索所有轮廓，具有两个级别的层次结构，即外部轮廓和孔洞。如果另一个对象在孔洞内部，则将其放在层次结构的顶部。'
- en: '`RETR_TREE` retrieves all contours, creating a full hierarchy between contours.'
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RETR_TREE` 检索所有轮廓，并在轮廓之间创建完整的层次结构。'
- en: '**Method**: This allows us to use the approximation method for retrieving the
    contour''s shapes:'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方法**：这允许我们使用近似方法来检索轮廓的形状：'
- en: If `CV_CHAIN_APPROX_NONE` is set, then this does not apply any approximation
    to the contours and stores the contour's points.
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果设置 `CV_CHAIN_APPROX_NONE`，则不对轮廓应用任何近似，并存储轮廓的点。
- en: '`CV_CHAIN_APPROX_SIMPLE` compresses all horizontal, vertical, and diagonal
    segments, storing only the start and end points.'
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CV_CHAIN_APPROX_SIMPLE` 压缩所有水平、垂直和对角线段，仅存储起点和终点。'
- en: '`CV_CHAIN_APPROX_TC89_L1` and `CV_CHAIN_APPROX_TC89_KCOS` apply the **Telchin**
    **chain** **approximation** algorithm.'
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CV_CHAIN_APPROX_TC89_L1` 和 `CV_CHAIN_APPROX_TC89_KCOS` 应用 **Telchin** **链**
    **近似** 算法。'
- en: '**Offset**: This is an optional point value to shift all contours. This is
    very useful when we are working in an ROI and need to retrieve global positions.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏移**：这是一个可选的点值，用于移动所有轮廓。当我们在一个 ROI 中工作并需要检索全局位置时，这非常有用。'
- en: 'Note: The input image is modified by the `findContours` function. Create a
    copy of your image before sending it to this function if you need it.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：输入图像会被 `findContours` 函数修改。如果您需要它，请在发送到该函数之前创建图像的副本。
- en: 'Now that we know the parameters of the `findContours` function, let''s apply
    this to our example:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了 `findContours` 函数的参数，让我们将其应用到我们的例子中：
- en: '[PRE27]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Let's explain our implementation, line by line.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐行解释我们的实现。
- en: 'In our case, we don''t need any hierarchy, so we are only going to retrieve
    the external contours of all possible objects. To do this, we can use the `RETR_EXTERNAL`
    mode and basic contour encoding by using the `CHAIN_APPROX_SIMPLE` method:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们不需要任何层次结构，所以我们只将检索所有可能对象的轮廓。为此，我们可以使用 `RETR_EXTERNAL` 模式和基本的轮廓编码，通过使用
    `CHAIN_APPROX_SIMPLE` 方法：
- en: '[PRE28]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Like the connected component examples we looked at before, first we check how
    many contours we have retrieved. If there are none, then we exit our function:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们之前查看的连通组件示例一样，首先我们检查我们检索了多少个轮廓。如果没有，则退出我们的函数：
- en: '[PRE29]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Finally, we draw the contour for each detected object. We draw this in our
    output image with different colors. To do this, OpenCV gives us a function to
    draw the result of the find contours image:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们为每个检测到的对象绘制轮廓。我们用不同的颜色在我们的输出图像中绘制这些轮廓。为此，OpenCV为我们提供了一个函数来绘制find contours图像的结果：
- en: '[PRE30]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `drawContours` function allows the following parameters:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`drawContours`函数允许以下参数：'
- en: '**Image**: The output image to draw the contours.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像**：绘制轮廓的输出图像。'
- en: '**Contours**: The vector of contours.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**轮廓**：轮廓的向量。'
- en: '**Contour index**: A number indicating the contour to draw. If this is negative,
    all contours are drawn.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**轮廓索引**：一个表示要绘制的轮廓的数字。如果这是负数，则绘制所有轮廓。'
- en: '**Color**: The color to draw the contour.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**颜色**：绘制轮廓的颜色。'
- en: '**Thickness**: If it is negative, the contour is filled with the chosen color.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**厚度**：如果是负数，则轮廓用所选颜色填充。'
- en: '**Line type**: This specifies whether we want to draw with anti-aliasing or
    another drawing method.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线型**：这指定了我们是否想要使用抗锯齿或其他绘图方法进行绘制。'
- en: '**Hierarchy**: This is an optional parameter that is only needed if you want
    to draw some of the contours.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**层次**：这是一个可选参数，仅在需要绘制一些轮廓时才需要。'
- en: '**Max Level**: This is an optional parameter that is only taken into account
    when the hierarchy parameter is available. If it is set to `0`, only the specified
    contour is drawn. If it is `1`, the function draws the current contour and the
    nested contours too. If it is set to `2`, then the algorithm draws all of the
    specified contour hierarchy.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大层级**：这是一个可选参数，仅在存在层次参数时才考虑。如果设置为`0`，则只绘制指定的轮廓。如果设置为`1`，则函数绘制当前轮廓及其嵌套轮廓。如果设置为`2`，则算法绘制所有指定的轮廓层级。'
- en: '**Offset**: This is an optional parameter for shifting the contours.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏移**：这是一个可选参数，用于移动轮廓。'
- en: 'The result of our example can be seen in the following image:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果可以在以下图像中看到：
- en: '![](img/eea4536f-0250-4228-8f2f-27ddc44bf863.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![图像](img/eea4536f-0250-4228-8f2f-27ddc44bf863.png)'
- en: Summary
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored the basics of object segmentation in a controlled
    situation where a camera takes pictures of different objects. Here, we learned
    how to remove background and light to allow us to binarize our image better, thus
    minimizing the noise. After binarizing the image, we learned about three different
    algorithms that we can use to divide and separate each object of one image, allowing
    us to isolate each object to manipulate or extract features.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了在受控情况下进行对象分割的基本知识，其中相机拍摄不同对象的图片。在这里，我们学习了如何去除背景和光线，以便我们更好地二值化图像，从而最小化噪声。在二值化图像后，我们了解了三种不同的算法，我们可以使用这些算法来分割和分离图像中的每个对象，使我们能够隔离每个对象以进行操作或提取特征。
- en: 'We can see this whole process in the following image:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下图像中看到整个流程：
- en: '![](img/617ededa-c684-4f4c-b460-2d1fe8d99849.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图像](img/617ededa-c684-4f4c-b460-2d1fe8d99849.png)'
- en: Finally, we extracted all of the objects on an image. You will need to do this
    to continue with the next chapter, where we are going to extract characteristics
    of each of these objects to train a machine learning system.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们从图像中提取了所有对象。您需要这样做才能继续下一章，在下一章中，我们将提取这些对象的特征以训练机器学习系统。
- en: In the next chapter, we are going to predict the class of any objects in an
    image and then call a robot or any other system to pick any of them, or detect
    an object that is not in the correct carrier tape. We will then look at notifying
    a person to pick it up.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将预测图像中任何对象的类别，然后调用机器人或其他系统来挑选其中任何一个，或者检测不在正确载体带上的对象。然后我们将查看通知某人将其取走。
