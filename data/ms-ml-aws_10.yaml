- en: Implementing Deep Learning Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现深度学习算法
- en: Deep learning is an area of machine learning that has gained significantly in
    terms of popularity in recent years. Deep learning, which is also referred to
    as deep structured learning or hierarchical learning refers to using multiple
    layers of artificial neural networks to train from data. Over the last few years,
    it has become possible to perform certain tasks, such as image recognition, better
    than human beings.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是近年来在受欢迎程度上显著增长的机器学习领域。深度学习，也被称为深度结构学习或分层学习，指的是使用多层人工神经网络从数据中训练。在过去的几年里，已经能够执行某些任务，如图像识别，比人类做得更好。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章中涵盖以下主题：
- en: Understanding deep learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解深度学习
- en: Applications of deep learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习的应用
- en: Understanding deep neural networks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解深度神经网络
- en: Understanding convolutional neural networks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解卷积神经网络
- en: Understanding deep learning
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解深度学习
- en: Deep learning algorithms have gained in popularity over the last decade. Technologies
    such as self-driving cars, speech recognition, and robotics have improved significantly
    on account of deep learning algorithms. Deep learning has helped researchers to
    significantly reduce the number of errors when training models to perform such
    tasks and also surpassed humans in performing certain tasks. However, what is
    most interesting is that deep learning algorithms are inspired by how human brains
    work.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习算法在过去十年中获得了流行。自动驾驶汽车、语音识别和机器人技术等技术由于深度学习算法的改进而取得了显著进步。深度学习帮助研究人员在训练模型执行此类任务时显著减少了错误数量，并在某些任务上超越了人类。然而，最有趣的是，深度学习算法的灵感来源于人类大脑的工作方式。
- en: Let's take an example of image recognition. We see objects and are able to recognize
    them based on past experiences of when we saw these objects. However, let's break
    this process down into what exactly happens. First, light hits the object, enters
    our eye, and hits the retina. The retina is a sensory membrane that converts this
    light into nerve signals. This signal is then passed through various layers behind
    the retina to the brain. Our brain identifies the number of objects that exist in
    the scene before our eyes. Based on past references, our brain can identify the
    objects.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以图像识别为例。我们看到物体并能够根据我们过去看到这些物体的经验来识别它们。然而，让我们分解这个过程，看看具体发生了什么。首先，光线击中物体，进入我们的眼睛，并击中视网膜。视网膜是一种感觉膜，将光线转换为神经信号。然后，这个信号通过视网膜后面的各个层级传递到大脑。我们的大脑识别在我们眼前场景中存在的物体数量。根据过去的参考，我们的大脑可以识别这些物体。
- en: There is no one process of us looking at the object and recognizing it. There
    are various levels of abstractions between when the light enters our eyes and
    when our brain identifies the object. There is no specific process when our brain
    stops and decides what features in the signal it is trying to interpret. Such
    a feature extraction process occurs automatically.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察物体并识别它的过程中没有单一的过程。从光线进入我们的眼睛到我们的大脑识别物体之间有各种抽象层级。当我们的大脑停止并决定它试图解释的信号中的哪些特征时，没有特定的过程。这样的特征提取过程是自动发生的。
- en: Deep learning algorithms also follow a similar process. Deep learning breaks
    the tasks of getting the data into the various layers of abstractions, such that
    each layer interprets the input data, and provides a meaningful output for the
    next layer of abstraction. For example, in image recognition tasks, the input
    may be a set of pixels from the image. In the first layer, the pixels can be processed
    to find edges in the image. In the second layer, this information regarding edges
    can be processed to detect corners between these edges. In the next layer, these
    corners and edges can be used to detect objects in the image. And the next layer
    may predict what each object is. These layers of abstractions do not need to be
    defined by us, but can train automatically by themselves.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习算法也遵循一个类似的过程。深度学习将获取数据到各个抽象层级的任务分解，使得每一层解释输入数据，并为下一层抽象提供有意义的输出。例如，在图像识别任务中，输入可能是一组来自图像的像素。在第一层，像素可以被处理以找到图像中的边缘。在第二层，关于边缘的信息可以被处理以检测这些边缘之间的角。在下一层，这些角和边缘可以被用来检测图像中的对象。下一层可能预测每个对象是什么。这些抽象层不需要我们定义，但可以自动训练。
- en: In algorithms such as Naive Bayes and linear regression, we always used hand-crafted
    features. We already had analysts look at the incoming dataset and define feature
    sets based on the data. We labeled each category as categorical or continuous.
    However, in deep learning methodologies, we only require datasets with simple
    features and use layers of abstractions to create additional abstract features.
    Hence, in tasks such as image recognition, where the datasets are sets of pixels,
    traditional algorithms would need help in identifying objects in the images before
    they can learn how to classify them. We would also have to extract features from
    the objects, such as color and size before we can feed these features to the classification
    models. However, for deep learning algorithms, we use pixels of the image as input
    to the algorithm with labeled objects such that the deep learning models can identify
    when errors are made and undertake self-correction.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在诸如朴素贝叶斯和线性回归等算法中，我们总是使用手工制作的特征。我们已经有分析师查看传入的数据集，并根据数据定义特征集。我们将每个类别标记为分类或连续。然而，在深度学习方法中，我们只需要具有简单特征的数据集，并使用抽象层来创建额外的抽象特征。因此，在如图像识别这样的任务中，数据集是像素集，传统算法在学会如何分类之前需要帮助识别图像中的对象。我们还需要从对象中提取特征，如颜色和大小，然后才能将这些特征输入到分类模型中。然而，对于深度学习算法，我们使用图像的像素作为算法的输入，并带有标记的对象，这样深度学习模型就可以识别错误并执行自我纠正。
- en: Deep learning algorithms can perform both supervised and unsupervised learning
    algorithms.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习算法可以执行监督学习和无监督学习算法。
- en: Applications of deep learning
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习的应用
- en: We will present examples of popular deep learning algorithm applications in
    this section.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示一些流行的深度学习算法应用实例。
- en: Self-driving cars
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动驾驶汽车
- en: Self-driving cars have become a mainstay in the auto industry, with every major
    company investing in building the next generation of self-driving cars. Most companies
    offer some level of autopilot capabilities in their latest cars. These algorithms
    are mostly powered by deep learning algorithms. Let's take a look at how self-driving
    algorithms are developed using deep learning.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 自动驾驶汽车已成为汽车行业的主流，每个主要公司都在投资建设下一代自动驾驶汽车。大多数公司在其最新车型中提供一定程度的自动驾驶功能。这些算法主要是由深度学习算法驱动的。让我们看看如何使用深度学习开发自动驾驶算法。
- en: The task of the self-driving algorithm is to analyze the conditions on the road
    and react to them correctly in order to drive the car from the origin to the destination
    address. The input for this algorithm is the video feed they receive from the
    cameras fitted on all sides of the car. The output of the algorithm is the signals
    to the steering wheel, accelerator, and brakes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 自动驾驶算法的任务是分析道路状况并正确地对其做出反应，以便将汽车从起点开到目的地地址。这个算法的输入是他们从汽车四面安装的摄像头接收到的视频流。算法的输出是转向、油门和刹车的信号。
- en: This task is extremely complicated since the driver needs to make split-second
    decisions when dealing with road conditions. The driver not only has to remember
    which turns to take in order to reach the destination or the speed limits on the
    road, but also has to monitor the movements of other cars on the road and pedestrians
    who may cross the roads.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个任务极其复杂，因为驾驶员在处理道路状况时需要做出瞬间的决策。驾驶员不仅需要记住到达目的地需要转弯的位置或道路上的速度限制，还必须监控道路上其他车辆和可能横穿道路的行人。
- en: Creating a rules-based algorithm for such a task is very difficult as there
    are a vast number of permutations that can occur on the road. Moreover, generating
    any labeled dataset with well-defined features is also difficult since the number
    of situations that could arise is very hard to label in a comprehensive dataset.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为此类任务创建基于规则的算法非常困难，因为道路上可能发生的大量排列组合。此外，生成具有良好定义特征的任何标记数据集也很困难，因为可能出现的情景数量很难在一个全面的数据集中进行标记。
- en: Deep learning algorithms are perfect in such situations because automatically
    extracting features from the video feed and training the models based on a reward
    function helps us to abstract the issues in self-driving cars. We can set the
    input of the deep learning algorithm as the pixels in the video feed and the reward
    function as our progress toward the destination while obeying all traffic rules.
    Simulators are used to train these models. Such simulations mimic the actual conditions
    on the road.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习算法在这种情况下非常完美，因为从视频流中自动提取特征并根据奖励函数训练模型可以帮助我们抽象自动驾驶汽车中的问题。我们可以将深度学习算法的输入设置为视频流中的像素，将奖励函数设置为在遵守所有交通规则的同时向目的地前进的进度。模拟器用于训练这些模型。这种模拟模仿了道路上的实际条件。
- en: Deep learning algorithms can automatically determine how to generate the layers
    of abstractions to translate the pixels from the video feed to detecting edges
    and objects, similar to image recognition models. Once the objects are detected,
    based on the mistakes and corrections made by the car, we train the models to
    learn how to output the accelerator, brakes, and steering wheel instructions.
    Initially, when running the models, self-driving cars make mistakes and crash
    into objects. However, with sufficient iterations, deep learning models can learn
    how to avoid such mistakes and drive on a predetermined path. Thus, without extracting
    the features manually from the video feeds, and without generating any structured
    datasets, deep learning algorithms can automatically learn to achieve certain
    objectives.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习算法可以自动确定如何生成抽象层的层次，将视频流中的像素转换为检测边缘和对象，类似于图像识别模型。一旦检测到对象，基于汽车所做的错误和纠正，我们训练模型学习如何输出油门、刹车和方向盘指令。最初，在运行模型时，自动驾驶汽车会犯错误并撞到物体。然而，经过足够的迭代，深度学习模型可以学会如何避免这样的错误，并在预定的路线上行驶。因此，无需从视频流中手动提取特征，也不需要生成任何结构化数据集，深度学习算法可以自动学习实现某些目标。
- en: Learning to play video games using a deep learning algorithm
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度学习算法学习玩视频游戏
- en: Another popular example of using deep learning is to train a machine to play
    computer games. Researchers across the world tested their deep learning algorithms
    by training models to play 2D platforming titles, such as Super Mario. The input
    to the model is the pixels on the screen, while the output generated by the model
    is a sequence of controller instructions that control the characters and finish
    the objectives in the game.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的另一个流行例子是训练机器玩电脑游戏。世界各地的研究人员通过训练模型来玩2D平台游戏，如超级马里奥，来测试他们的深度学习算法。模型的输入是屏幕上的像素，而模型生成的输出是一系列控制器指令，这些指令控制角色并在游戏中完成目标。
- en: We do not need to teach deep learning models that this is a video game and that
    a character named Mario has to jump on platforms to finish the levels. We just
    have to define a reward function such that if the character moves to the next
    platform without dying, we reward the deep learning model, and if the character
    dies, we penalize the model. As mentioned before, the deep learning model automatically
    divides the problem into multiple levels of abstractions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要教深度学习模型这是款视频游戏，以及有一个名叫马里奥的角色需要跳上平台来完成关卡。我们只需要定义一个奖励函数，使得如果角色在没有死亡的情况下移动到下一个平台，我们就奖励深度学习模型，如果角色死亡，我们就惩罚模型。如前所述，深度学习模型会自动将问题划分为多个抽象层次。
- en: The model learns how to detect edges and platforms on the screen automatically.
    It starts by making random movements with the character and quickly learns how
    the pixels on the screen are manipulated when different controller buttons are
    pushed. Based on the movements of the character, the model learns how to move
    the main character forward. Similar to the self-driving car, it will also automatically
    learn that touching certain objects on the screen leads to a penalty, and jumping
    on certain edges on the screen leads to the player falling into pits. Hence, based
    on these reward functions giving feedback to the model, the model learns how to
    navigate the obstacles in the level to move the player in the right direction.
    With further training, it can also learn how to solve puzzles in the game.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 模型学习如何自动检测屏幕上的边缘和平台。它首先通过角色进行随机移动，并迅速学习当按下不同的控制器按钮时屏幕上的像素是如何被操作的。基于角色的移动，模型学习如何使主要角色前进。类似于自动驾驶汽车，它也会自动学习触摸屏幕上的某些物体会导致惩罚，以及跳上屏幕上的某些边缘会导致玩家掉入坑中。因此，基于这些给模型提供反馈的奖励函数，模型学习如何导航关卡中的障碍物，将玩家移动到正确的方向。经过进一步训练，它还可以学习如何解决游戏中的谜题。
- en: Thus, just by providing the screen pixels to the deep learning model, we can
    train a machine to play video games. You see examples of these implementations
    everywhere around you. Soon, machines will learn how to solve complex puzzles
    by thinking rationally based on these machine learning models.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，只需向深度学习模型提供屏幕像素，我们就可以训练一台机器来玩电子游戏。你可以在周围看到这些实现的例子。不久，机器将学会如何通过基于这些机器学习模型的理性思考来解决复杂的谜题。
- en: Understanding deep learning algorithms
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解深度学习算法
- en: In the next section, we study one of the most popular deep learning algorithm,
    called deep neural networks.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将研究最流行的深度学习算法之一，称为深度神经网络。
- en: Before we look at what deep neural networks are, we will study what neural networks
    are. Then, we will learn what deep neural network algorithms are and why they
    are an improvement over neural networks. Finally, we will study convolutional
    neural networks—which is a variant of neural networks that is used in the field
    of image recognition – and show how we can automatically learn layers of abstractions
    from the pixels in the image.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探讨深度神经网络之前，我们将研究神经网络是什么。然后，我们将学习深度神经网络算法是什么，以及为什么它们比神经网络有改进。最后，我们将研究卷积神经网络——这是在图像识别领域使用的一种神经网络变体——并展示我们如何能够从图像的像素中自动学习抽象层。
- en: Neural network algorithms
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络算法
- en: Neural network algorithms are machine learning algorithms that are inspired
    by biological neural network algorithms. Neural networks mimic how our neurons
    in our brain work. They have input nodes where the information is fed into the
    network, and an output layer that transmits a specific action or prediction. 
    Neural networks define a structure in which the information of the machine learning
    model is stored.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络算法是受生物神经网络算法启发的机器学习算法。神经网络模仿我们大脑中的神经元是如何工作的。它们有输入节点，信息被输入到网络中，以及一个输出层，它传输特定的动作或预测。神经网络定义了一个结构，其中存储了机器学习模型的信息。
- en: 'The following screenshot shows a neural network structure:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了神经网络结构：
- en: '![](img/35bde629-dac9-4460-94ed-060bcbd1ea8c.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![神经网络结构](img/35bde629-dac9-4460-94ed-060bcbd1ea8c.png)'
- en: The input features from a dataset are fed into neural network input nodes. For
    example, if we have a dataset that has features such as temperature, cloud conditions,
    and wind speed, and our task is to predict whether it will rain on a given day,
    then such features are fed to the neural networks as input. These features can
    either be in binary or continuous values. Note that each input feature corresponds
    to one input node.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 来自数据集的输入特征被输入到神经网络输入节点中。例如，如果我们有一个包含诸如温度、云条件和风速等特征的数据库，并且我们的任务是预测某一天是否会下雨，那么这些特征就被作为输入输入到神经网络中。这些特征可以是二进制或连续值。请注意，每个输入特征对应一个输入节点。
- en: The information regarding the model is stored on the edges and the nodes in
    the hidden layer. There are various algorithms that can be used to train neural
    networks. Most algorithms iteratively pass input parameters in the neural network
    and predict the values of output nodes based on the weights in the hidden nodes.
    Based on the error in prediction, these weights are adjusted to improve the model.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的信息存储在隐藏层中的边和节点上。有各种算法可以用来训练神经网络。大多数算法迭代地在神经网络中传递输入参数，并根据隐藏节点中的权重预测输出节点的值。基于预测中的误差，这些权重被调整以改进模型。
- en: The output nodes correspond to the expected actions or predictions that the
    neural network algorithms need to make. Our aim is to train the weights in the
    hidden nodes such that the values of the output nodes are accurate.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 输出节点对应于神经网络算法需要做出的预期动作或预测。我们的目标是训练隐藏节点中的权重，使得输出节点的值是准确的。
- en: Thus, the neural networks are loosely based on biological neurons that can process
    an input signal and produce an output based on the function of that neuron.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，神经网络松散地基于可以处理输入信号并基于该神经元的函数产生输出的生物神经元。
- en: Activation function
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 激活函数
- en: 'Now, let''s look at how a neural network algorithm is trained to calculate
    the weights of each hidden node. Before we begin training a neural network model,
    we need to define how each hidden node will process the input signal and produce
    an output. The function that is used to calculate the output of a hidden node
    based on an input function is called the activation function. Activation functions
    define the range of output that can be generated by the hidden nodes. In its simplest
    form, an activation function can be a step function where the node output is either
    0 or 1 based on the input. A simple example in our weather dataset is this: if
    the sky is cloudy, the output of a hidden node might be 1 as a prediction for
    rain, and if the sky is sunny, the output of the hidden node is 0.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看神经网络算法是如何训练来计算每个隐藏节点的权重的。在我们开始训练神经网络模型之前，我们需要定义每个隐藏节点将如何处理输入信号并产生输出。用于根据输入函数计算隐藏节点输出的函数称为激活函数。激活函数定义了隐藏节点可以生成的输出范围。在其最简单形式中，激活函数可以是一个步骤函数，其中节点输出基于输入是0或1。在我们天气数据集中的简单例子是这样的：如果天空多云，隐藏节点的输出可能是1，作为预测降雨的预测，如果天空晴朗，隐藏节点的输出是0。
- en: 'Such a step activation function is defined as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的步骤激活函数定义为以下：
- en: '![](img/acd1e5b4-e4c8-4df9-ae16-3f31e8894833.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/acd1e5b4-e4c8-4df9-ae16-3f31e8894833.png)'
- en: Similarly, if we plan to use a logistic or sigmoid step function, the range
    of the output is from ![](img/d7e0e539-96f2-4292-99c6-b3f9d32dfb17.png) to ![](img/b4885d2d-91c3-4e88-b502-486e8f1c328c.png).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，如果我们计划使用逻辑或Sigmoid步骤函数，输出范围从 ![](img/d7e0e539-96f2-4292-99c6-b3f9d32dfb17.png)
    到 ![](img/b4885d2d-91c3-4e88-b502-486e8f1c328c.png)。
- en: 'A logistic step function is defined as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑步骤函数定义为以下：
- en: '![](img/e798e20d-a315-44ea-b02a-5622a5093094.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e798e20d-a315-44ea-b02a-5622a5093094.png)'
- en: Based on the learning algorithm we are using, we can select activation functions.
    Most machine learning libraries that support neural network learning also support
    using various activation functions.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们使用的学习算法，我们可以选择激活函数。大多数支持神经网络学习的机器学习库也支持使用各种激活函数。
- en: Each edge between nodes is assigned a weight, ![](img/a429fa77-3a96-4f6c-b5a9-10c02fbfcf13.png),
    such that that link is between neuron ![](img/a6be5976-da28-4d11-b71a-d2de022f2237.png)
    and neuron ![](img/4df7fbb5-6c92-4af8-bee5-cd62dd730db6.png).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点之间的边都分配一个权重， ![](img/a429fa77-3a96-4f6c-b5a9-10c02fbfcf13.png)，使得该链接位于神经元
    ![](img/a6be5976-da28-4d11-b71a-d2de022f2237.png) 和神经元 ![](img/4df7fbb5-6c92-4af8-bee5-cd62dd730db6.png)
    之间。
- en: Backpropagation
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反向传播
- en: Once we have established the weights of the connections in the neural networks
    and the activation function, a neural network is able to effectively produce an
    output based on a given input. However, this is an untrained neural network, and
    an algorithm is needed to modify and adapt a neural network based on the errors
    it makes when predicting an output.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了神经网络中连接的权重和激活函数，神经网络就能够根据给定的输入有效地产生输出。然而，这是一个未训练的神经网络，需要一个算法根据它在预测输出时犯的错误来修改和调整神经网络。
- en: The weight updates for backpropagation using stochastic gradient descent can
    be executed using the following equation.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用随机梯度下降进行反向传播的权重更新可以使用以下方程执行。
- en: The backpropagation algorithm is one of the popular mechanisms that can achieve
    this outcome. Backpropagation algorithms define a methodology for how the errors
    in the output can be propagated through the connections by modifying the values
    of the connections. The intuition behind the algorithm is very simple. Consider
    a child touching a very hot pan and learning not to touch pans that are situated
    on top of a stove. The child makes a mistake, but learns from it and avoids making
    the same mistake again. Backpropagation algorithms also allow neural networks
    to make errors. The difference between the predicted output and the expected output
    can be calculated using formulas, such as mean squared errors. Once we quantify
    the error, we can use algorithms, such as gradient descent, to determine how to
    modify the weights of the connections. We also used the algorithm of gradient
    descent for the linear regression algorithm in [Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml),
    *Predicting House Value with Regression Algorithms*. The backpropagation process
    is similar to how we learn the coefficients for the linear regression algorithm.
    However, instead of learning the values of the regressors, we are estimating the
    value of the weights of the connections in neural networks.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播算法是能够实现这一结果的流行机制之一。反向传播算法定义了一种方法，通过修改连接的值，如何将输出中的错误传播到连接中。算法背后的直觉非常简单。考虑一个孩子触摸到一个非常热的平底锅并学会不要触摸放在炉子上的锅。孩子犯了一个错误，但从中学习并避免再次犯同样的错误。反向传播算法也允许神经网络犯错误。预测输出和期望输出之间的差异可以使用公式计算，例如均方误差。一旦我们量化了错误，我们就可以使用梯度下降等算法来确定如何修改连接的权重。我们还使用了梯度下降算法来处理[第3章](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml)中的线性回归算法，*使用回归算法预测房价*。反向传播过程类似于我们学习线性回归算法系数的方式。然而，我们不是学习回归器的值，而是在神经网络中估计连接权重的值。
- en: 'The weight updates for backpropagation using stochastic gradient descent can
    be done using the following equation:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用随机梯度下降进行反向传播的权重更新可以使用以下方程进行：
- en: '![](img/c5fced8c-865f-4de2-8e1f-d0654113d681.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c5fced8c-865f-4de2-8e1f-d0654113d681.png)'
- en: In this equation, ![](img/32b3cd5d-7509-4e2d-85e4-642e50c14c76.png) is the learning
    rate of the neural network. This is a tunable parameter and defines how quickly
    the neural network can adapt to the training dataset. The weight, ![](img/522994fb-177e-42c8-b77f-e17be8d6b0fc.png),
    is calculated based on the previous weight of the connection. The value of change
    in the weight is determined by the learning rate, which is the difference between
    the error, the previous weight, and a stochastic term.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方程中，![](img/32b3cd5d-7509-4e2d-85e4-642e50c14c76.png)是神经网络的 学习率。这是一个可调参数，定义了神经网络能够多快适应训练数据集。权重![](img/522994fb-177e-42c8-b77f-e17be8d6b0fc.png)是基于连接的先前权重计算的。权重变化值由学习率决定，即错误、先前权重和一个随机项之间的差异。
- en: We iterate over the training data by passing it through the neural network and
    modifying the weights of the connections during each iteration. The weights are
    modified such that the error rates reduce with each iteration. Although stochastic
    gradient descent does not achieve a global maxima, it is effective in training
    a neural network to reduce errors. We terminate the iteration when the error is
    below a certain acceptable value, or it converges such that the improvements in
    accuracy are minimal.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过将训练数据传递到神经网络中并在每次迭代中修改连接的权重来遍历训练数据。权重被修改，以便每次迭代时错误率都会降低。尽管随机梯度下降不能达到全局最大值，但它对于训练神经网络以减少错误是有效的。当错误低于某个可接受的值或收敛到准确性改进最小的时候，我们终止迭代。
- en: Neural networks can be used to train supervised learning as well as unsupervised
    learning.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络可以用于训练监督学习以及无监督学习。
- en: Introduction to deep neural networks
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度神经网络简介
- en: A **deep neural network** (**DNN**) is a variant of neural networks where we
    use more than one hidden layer. The data has to pass through more than one hidden
    layer for a network to qualify as a deep neural network. This adds complexity
    to the neural network model as it drastically increases the connections in the
    network, and thus the learning time.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度神经网络**（**DNN**）是神经网络的一种变体，其中我们使用一个以上的隐藏层。数据必须通过一个以上的隐藏层，网络才能被认定为深度神经网络。这增加了神经网络模型的复杂性，因为它极大地增加了网络中的连接，从而增加了学习时间。'
- en: 'A representation of a deep neural network is shown here:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了深度神经网络的一个表示：
- en: '![](img/f037847a-0051-4af1-8315-8a3782c17290.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f037847a-0051-4af1-8315-8a3782c17290.png)'
- en: However, having additional hidden layers also allows the network to pass the
    input data through multiple layers of pattern recognition. Each hidden layer gets
    the input from the previous hidden layers. Hence, they can recognize more complex
    patterns than the previous layers. This happens as the previous layers aggregate,
    and recombines the features from the previous layers. This is called the feature
    hierarchy. The features that are deeper in the DNN can recognize more complex
    patterns. Hence, DNN is more capable of handling datasets with complex patterns.
    Moreover, since the hidden layers automatically generate these layers of abstractions,
    domain expertise is not required for feature extraction. For example, in image
    recognition, we do not need to label the edges of objects in the image since initial
    layers can learn to identify edges, while deeper layers learn to identify the
    objects that may be generated by those edges.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，增加额外的隐藏层也允许网络通过多个层次的模式识别传递输入数据。每个隐藏层都从前一个隐藏层接收输入。因此，它们可以识别比前一层更复杂的模式。这是因为在之前的层中，特征被聚合和重新组合。这被称为特征层次。DNN中更深层的特征可以识别更复杂的模式。因此，DNN更擅长处理具有复杂模式的数据库。此外，由于隐藏层自动生成这些抽象层，因此不需要领域专业知识进行特征提取。例如，在图像识别中，我们不需要对图像中物体的边缘进行标记，因为初始层可以学会识别边缘，而深层层则学会识别可能由这些边缘生成的物体。
- en: Deep learning and DNN are popular buzzwords that data scientists hear about
    in the industry. For most applications, such as self-driving cars or robotics,
    DNN is synonymous with  artificial intelligence. Due to the advances in GPU architectures,
    which suit the generation of these DNN structures, such algorithms are not able
    to process large datasets in order to train highly accurate machine learning algorithms.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习和DNN是数据科学家在业界经常听到的热门词汇。对于大多数应用，如自动驾驶汽车或机器人技术，DNN与人工智能同义。由于GPU架构的进步，这些DNN结构的生成非常适合，因此这些算法无法处理大量数据集以训练高度准确的机器学习算法。
- en: Understanding convolutional neural networks
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解卷积神经网络
- en: In this section, we will take a look at a variant of DNNs, where the structure
    of the network is modified for image recognition tasks.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨一种DNNs的变体，其中网络结构被修改以适应图像识别任务。
- en: In the neural networks that we've discussed in this chapter so far, we've seen
    that all the input layers are one dimensional. However, images are two-dimensional.
    To capture how images are fed to a neural network for training, we have to modify
    the structure of the input layer. Traditional algorithms require humans to label
    the edges of the objects in the image. **Convolutional neural networks** (**CNNs**)
    can automatically detect the objects in the image with enough training and, based
    on the labels of the image, they can learn how to identify objects in the images
    without explicitly labeling the edges in the image.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章迄今为止讨论的神经网络中，我们看到了所有输入层都是一维的。然而，图像是二维的。为了捕捉图像如何被输入神经网络进行训练，我们必须修改输入层的结构。传统算法需要人类对图像中物体的边缘进行标记。**卷积神经网络**（**CNNs**）可以通过足够的训练自动检测图像中的物体，并且根据图像的标签，它们可以学习如何在不显式标记图像边缘的情况下识别图像中的物体。
- en: CNNs require a preprocessing phase where the image has to be prepared into a
    specific data structure that is used as an input for feed-forward DNNs. The first
    task in the preprocessing phase is to break the picture down into smaller images,
    such that we do not lose any information from the image. The inspiration for a
    CNN comes from the organization of the visual cortex in humans. Our neurons respond
    to visuals that are seen in a specific field of vision. This is called the local
    receptive field. These local receptive fields overlap with each other. Similarly,
    in CNN, we take an image as an input and represent overlapping subsections of
    an image as local receptive fields.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: CNNs需要一个预处理阶段，其中图像必须被准备成特定的数据结构，该结构用作前馈DNNs的输入。预处理阶段的第一项任务是分解图片成更小的图像，这样我们就不丢失图像中的任何信息。CNN的灵感来源于人类视觉皮层的组织。我们的神经元对特定视野中看到的视觉做出反应。这被称为局部感受野。这些局部感受野相互重叠。同样，在CNN中，我们以图像作为输入，并将图像的重叠子区域表示为局部感受野。
- en: 'The following diagram shows how a sliding window is used to generate feature
    maps from an image using the concept of local receptive fields:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了如何使用局部感受野的概念，通过滑动窗口从图像中生成特征图：
- en: '![](img/c1946649-c3b8-4274-a761-557c7b803208.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c1946649-c3b8-4274-a761-557c7b803208.png)'
- en: The advantage of using this methodology is that it eliminates the issues of
    size and position of an object in an image. For example, imagine there is a cat
    in the image. Based on our training examples, we have labeled images with pictures
    of cats. Using local receptive fields, we detect that cat and label the feature
    map as having a picture of a cat in the image. In a new image, irrespective of
    the location of the cat in the image, we will find a feature map that has an image
    of a cat, since we create multiple sub-images using this sliding window approach.
    This layer of feature maps generated from the image is called the convolutional
    layer.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法的优点是它消除了图像中对象的大小和位置问题。例如，想象图像中有一只猫。根据我们的训练示例，我们已对包含猫的图片进行了标记。使用局部感受野，我们检测到这只猫并将特征图标记为图像中有猫的图片。在新的图像中，无论猫在图像中的位置如何，我们都会找到一个包含猫的图像的特征图，因为我们使用这种滑动窗口方法创建了多个子图像。从图像中生成的这一层特征图被称为卷积层。
- en: We can also generate multiple feature maps from the same set of pixels by applying
    various filters to the process. For example, we can apply color filters to the
    pixels and generate three feature maps from the same set of pixels. As a data
    scientist, you would have to design the CNNs based on the amount of information
    that you want to extract from the image, as well as the amount of processing power
    that we can use when generating these networks.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过应用各种过滤器到过程中，从同一组像素生成多个特征图。例如，我们可以应用颜色过滤器到像素，并从同一组像素生成三个特征图。作为一个数据科学家，你必须根据你想要从图像中提取的信息量以及我们生成这些网络时可以使用的处理能力来设计CNN。
- en: Once the convolution layers are generated, we create condensed feature maps
    from the image by using a process called pooling. This helps us to represent the
    feature maps in smaller feature maps. There are two popular pooling processes
    that can be applied when condensing a feature map. In a max-pooling approach,
    reduce the dimensionality of the feature map by only selecting the maximum value
    from each grid.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦生成了卷积层，我们通过使用称为池化的过程从图像中创建压缩特征图。这有助于我们以更小的特征图来表示特征图。在压缩特征图时，可以应用两种流行的池化过程。在最大池化方法中，通过仅从每个网格中选择最大值来降低特征图的维度。
- en: 'The following screenshot shows how max-pooling takes the maximum value from
    each feature map and reduces the dimensionality of the feature map from a matrix
    of 4x4 to 2x2:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了最大池化如何从每个特征图中取最大值，并将特征图的维度从4x4矩阵降低到2x2：
- en: '![](img/41c66ced-bf18-4abb-8cce-5b139cfa8c26.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/41c66ced-bf18-4abb-8cce-5b139cfa8c26.png)'
- en: 'Another type of pooling is called average pooling, which is where we select
    the average of the values in a grid when pooling the data. The following diagram
    shows how average pooling works:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种池化类型称为平均池化，这是在池化数据时选择网格中值的平均值。以下图表展示了平均池化是如何工作的：
- en: '![](img/9b974661-46fb-4bca-892e-bb72c9ee45f8.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9b974661-46fb-4bca-892e-bb72c9ee45f8.png)'
- en: Max-pooling is generally preferred over average pooling as it acts as a noise
    suppressant and removes the non-dominant features when reducing the dimensionality
    of a feature map. Similar to a convolutional layer, a pooling layer can also use
    overlapping windows to create a smaller feature map. Note that these decisions
    can be made based on the level of detail you want to capture from an image.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 最大池化通常比平均池化更受欢迎，因为它在降低特征图维度时起到噪声抑制的作用，并移除了非主导特征。与卷积层类似，池化层也可以使用重叠窗口来创建更小的特征图。请注意，这些决策可以根据你想要从图像中捕获的细节程度来做出。
- en: Another component of a CNN is the convolution layer. When we design a CNN, a
    set of images might determine what feature maps we extract from the image. However,
    based on the application, we would want to extract different features from the
    images. For example, if our image recognition software is detecting charts generated
    by a seismometer (a device that detects earthquakes), our feature maps would have
    black and white graphs, where our algorithm needs to be sensitive to detecting
    the edges in time-series. In such cases, we can design a convolution kernel that
    can translate certain patterns in a feature graph into another feature graph that
    can annotate such patterns. Similarly, if you are processing colored images with
    objects, creating three feature maps for each color, detecting edges, and then
    merging the feature maps, is helpful. Thus, convolutional layers help scientists
    who design such neural networks to adapt them to specific applications. We are
    not going to explain the details of how convolution layers can be set up, as most
    libraries allow you to use predesigned CNNs to apply to your applications.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的另一个组成部分是卷积层。当我们设计CNN时，一组图像可能会决定我们从图像中提取哪些特征图。然而，根据应用需求，我们可能希望从图像中提取不同的特征。例如，如果我们的图像识别软件正在检测由地震仪（一种检测地震的设备）生成的图表，我们的特征图将包含黑白图表，其中我们的算法需要对时间序列中的边缘进行敏感检测。在这种情况下，我们可以设计一个卷积核，将特征图中的一定模式转换为另一个可以注释这些模式的特征图。同样，如果你正在处理带有对象的彩色图像，为每种颜色创建三个特征图，检测边缘，然后合并特征图，这很有帮助。因此，卷积层帮助设计此类神经网络的科学家根据特定应用对其进行调整。我们不会解释如何设置卷积层的细节，因为大多数库都允许你使用预设计的CNN应用于你的应用。
- en: 'Thus, using local receptive fields, convolution layers, and pooling, we construct
    the following structure to flatten an image into input for a DNN:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过使用局部感受野、卷积层和池化操作，我们构建以下结构将图像展平为DNN的输入：
- en: '![](img/8a319ddb-08cb-417b-9c4a-7656c72a8025.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8a319ddb-08cb-417b-9c4a-7656c72a8025.png)'
- en: An image is translated into feature maps using the first layer of convolution
    by employing the local perceptive fields methodology. Then, we reduce the dimensions
    of the feature maps by pooling the data, so as to reduce the dimensionality of
    feature maps from 20x20 to 10x10\. In the next phase, we translate the pooled
    feature maps into more feature maps based on a kernel we might have selected.
    These kernels may translate the feature maps that detect straight lines or intersections.
    We then pool the output of the convolution layer into 4x4 feature maps. At this
    point, the original image is translated into information that is specific to the
    task of a DNN. These feature maps represent the spatial components of the images
    too. The DNN then trains based on this data and learns to predict output based
    on what the feature maps may represent.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用局部感受野方法，第一层卷积将图像转换为特征图。然后，我们通过池化数据来减少特征图的维度，将特征图的维度从20x20减少到10x10。在下一阶段，我们根据可能选择的核将池化后的特征图转换为更多的特征图。这些核可能将检测直线或交叉的特征图转换为其他特征图。然后，我们将卷积层的输出池化到4x4特征图。此时，原始图像被转换为DNN任务特定信息。这些特征图也代表了图像的空间成分。然后，DNN根据这些数据训练，并学习根据特征图可能表示的内容来预测输出。
- en: Summary
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explained what deep learning means and how it is applied
    in real-world applications. We also studied applications, such as self-driving
    cars and a video game bot, and how they can automatically learn how to perform
    tasks using deep learning. We explained what neural networks are and how DNNs
    are an improved version of them. We also studied a variant of DNNs, called CNNs
    and presented the various components of a CNN.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们解释了深度学习的含义以及它在现实世界中的应用。我们还研究了应用案例，例如自动驾驶汽车和视频游戏机器人，以及它们如何使用深度学习自动学习执行任务。我们解释了神经网络是什么，以及DNN是如何改进它们的。我们还研究了DNN的一个变体，称为CNN，并介绍了CNN的各个组成部分。
- en: Our aim in this chapter was to provide you with information about deep learning
    algorithms so that you could understand how they can be applied in the real world.
    Although we did not dive deep into the mathematics of deep learning, or provide
    all details on concepts such as activation function, we hope that you gained a
    working knowledge in the field of deep learning. For those curious minds out there,
    there is a vast amount of ongoing research in this field and we implore you to
    learn more about the algorithms that you are interested in.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是向您提供有关深度学习算法的信息，以便您了解它们如何在现实世界中应用。尽管我们没有深入探讨深度学习的数学原理，也没有提供关于激活函数等概念的所有细节，但我们希望您在深度学习领域获得了实际的知识。对于那些好奇心旺盛的人，这个领域正在进行着大量的研究，我们敦促您更多地了解您感兴趣的算法。
- en: In the next chapter, we will look at how deep learning can be implemented using
    popular technologies, such as TensorFlow and MXNet. This knowledge will help you
    to implement a large array of deep learning algorithms.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨如何使用流行的技术，如TensorFlow和MXNet，来实现深度学习。这些知识将帮助您实现一系列深度学习算法。
- en: Exercises
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: If you own a smartphone, you have a lot of apps on your phone that employ deep
    learning. Explore which apps on your phone use one of the algorithms listed in
    this chapter and examine how to design such an algorithm.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你拥有一部智能手机，你的手机上就有很多应用使用了深度学习。探索你的手机上哪些应用使用了本章中列出的算法之一，并研究如何设计这样的算法。
- en: List the various components of CNN and design a CNN that would detect the features
    of a human face.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出CNN的各种组件，并设计一个能够检测人脸特征的CNN。
