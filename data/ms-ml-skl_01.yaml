- en: Chapter 1. The Fundamentals of Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 机器学习的基础
- en: In this chapter we will review the fundamental concepts in machine learning.
    We will discuss applications of machine learning algorithms, the supervised-unsupervised
    learning spectrum, uses of training and testing data, and model evaluation. Finally,
    we will introduce scikit-learn, and install the tools required in subsequent chapters.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将回顾机器学习中的基本概念。我们将讨论机器学习算法的应用、监督学习与无监督学习的广谱、训练数据和测试数据的使用以及模型评估。最后，我们将介绍scikit-learn，并安装接下来章节所需的工具。
- en: Our imagination has long been captivated by visions of machines that can learn
    and imitate human intelligence. While visions of general artificial intelligence
    such as Arthur C. Clarke's HAL and Isaac Asimov's Sonny have yet to be realized,
    software programs that can acquire new knowledge and skills through experience
    are becoming increasingly common. We use such machine learning programs to discover
    new music that we enjoy, and to quickly find the exact shoes we want to purchase
    online. Machine learning programs allow us to dictate commands to our smartphones
    and allow our thermostats to set their own temperatures. Machine learning programs
    can decipher sloppily-written mailing addresses better than humans, and guard
    credit cards from fraud more vigilantly. From investigating new medicines to estimating
    the page views for versions of a headline, machine learning software is becoming
    central to many industries. Machine learning has even encroached on activities
    that have long been considered uniquely human, such as writing the sports column
    recapping the Duke basketball team's loss to UNC.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 长久以来，我们的想象力被能够学习并模仿人类智慧的机器所吸引。虽然像阿瑟·克拉克的HAL和艾萨克·阿西莫夫的Sonny这样的通用人工智能的愿景尚未实现，但可以通过经验获得新知识和技能的软件程序变得越来越常见。我们使用这些机器学习程序来发现我们喜欢的新音乐，快速找到我们想在网上购买的鞋子。机器学习程序使我们能够对智能手机发出命令，并让我们的恒温器自动调整温度。机器学习程序能够比人类更好地解读潦草的邮寄地址，并更警惕地防止信用卡欺诈。从研究新药物到估算新闻标题版本的页面浏览量，机器学习软件正在成为许多行业的核心。机器学习甚至渗透到长期以来被认为是人类独有的活动中，比如撰写回顾杜克大学篮球队输给北卡罗来纳大学的体育专栏。
- en: Machine learning is the design and study of software artifacts that use past
    experience to make future decisions; it is the study of programs that learn from
    data. The fundamental goal of machine learning is to *generalize*, or to induce
    an unknown rule from examples of the rule's application. The canonical example
    of machine learning is spam filtering. By observing thousands of emails that have
    been previously labeled as either spam or ham, spam filters learn to classify
    new messages.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是设计和研究利用过去经验做出未来决策的软件工具；它是研究从数据中学习的程序。机器学习的根本目标是*归纳*，即从规则应用的示例中推导出一个未知的规则。机器学习的经典例子是垃圾邮件过滤。通过观察成千上万封已标记为垃圾邮件或正常邮件的电子邮件，垃圾邮件过滤器学会了对新邮件进行分类。
- en: Arthur Samuel, a computer scientist who pioneered the study of artificial intelligence,
    said that machine learning is "the study that gives computers the ability to learn
    without being explicitly programmed." Throughout the 1950s and 1960s, Samuel developed
    programs that played checkers. While the rules of checkers are simple, complex
    strategies are required to defeat skilled opponents. Samuel never explicitly programmed
    these strategies, but through the experience of playing thousands of games, the
    program learned complex behaviors that allowed it to beat many human opponents.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能研究的先驱计算机科学家阿瑟·塞缪尔曾说过，机器学习是“赋予计算机在没有明确编程的情况下学习能力的研究。”在1950年代和1960年代，塞缪尔开发了可以下跳棋的程序。虽然跳棋的规则很简单，但要击败经验丰富的对手，需要复杂的策略。塞缪尔并没有明确编程这些策略，而是通过与成千上万场游戏的经验，程序学会了复杂的行为，使它能够击败许多人类对手。
- en: 'A popular quote from computer scientist Tom Mitchell defines machine learning
    more formally: "A program can be said to learn from experience *E* with respect
    to some class of tasks *T* and performance measure *P*, if its performance at
    tasks in *T*, as measured by *P*, improves with experience *E*." For example,
    assume that you have a collection of pictures. Each picture depicts either a dog
    or cat. A task could be sorting the pictures into separate collections of dog
    and cat photos. A program could learn to perform this task by observing pictures
    that have already been sorted, and it could evaluate its performance by calculating
    the percentage of correctly classified pictures.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机科学家Tom Mitchell的名言更正式地定义了机器学习：“一个程序可以说是通过经验*E*在某些任务类*T*和性能度量*P*上学习，如果它在*T*中的任务表现，按照*P*度量，随着经验*E*的增加而得到改进。”例如，假设你有一组图片，每张图片描绘的是狗或猫。一个任务可能是将图片分类为狗和猫的不同集合。程序可以通过观察已经分类的图片来学习执行此任务，并通过计算正确分类的图片百分比来评估其性能。
- en: We will use Mitchell's definition of machine learning to organize this chapter.
    First, we will discuss types of experience, including **supervised** learning
    and **unsupervised** learning. Next, we will discuss common tasks that can be
    performed by machine learning systems. Finally, we will discuss performance measures
    that can be used to assess machine learning systems.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Mitchell的机器学习定义来组织本章内容。首先，我们将讨论经验的类型，包括**监督**学习和**无监督**学习。接下来，我们将讨论机器学习系统可以执行的常见任务。最后，我们将讨论可以用来评估机器学习系统的性能度量。
- en: Learning from experience
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从经验中学习
- en: Machine learning systems are often described as learning from experience either
    with or without supervision from humans. In supervised learning problems, a program
    predicts an output for an input by learning from pairs of labeled inputs and outputs;
    that is, the program learns from examples of the right answers. In unsupervised
    learning, a program does not learn from labeled data. Instead, it attempts to
    discover patterns in the data. For example, assume that you have collected data
    describing the heights and weights of people. An example of an unsupervised learning
    problem is dividing the data points into groups. A program might produce groups
    that correspond to men and women, or children and adults.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统通常被描述为通过经验进行学习，可能有或没有人类的监督。在监督学习问题中，程序通过学习一对对标注的输入和输出，预测输入的输出；也就是说，程序通过正确答案的示例来学习。在无监督学习中，程序不通过标注数据来学习，而是尝试发现数据中的模式。例如，假设你收集了描述人们身高和体重的数据。一个无监督学习问题的例子是将数据点分组。程序可能会将数据分为男性和女性，或者儿童和成人。
- en: Now assume that the data is also labeled with the person's sex. An example of
    a supervised learning problem is inducing a rule to predict whether a person is
    male or female based on his or her height and weight. We will discuss algorithms
    and examples of supervised and unsupervised learning in the following chapters.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设数据也标注了个人的性别。一个监督学习问题的例子是根据一个人的身高和体重来预测他或她是男性还是女性。我们将在接下来的章节中讨论监督学习和无监督学习的算法和示例。
- en: Supervised learning and unsupervised learning can be thought of as occupying
    opposite ends of a spectrum. Some types of problems, called **semi-supervised**
    learning problems, make use of both supervised and unsupervised data; these problems
    are located on the spectrum between supervised and unsupervised learning. An example
    of semi-supervised machine learning is reinforcement learning, in which a program
    receives feedback for its decisions, but the feedback may not be associated with
    a single decision. For example, a reinforcement learning program that learns to
    play a side-scrolling video game such as *Super Mario Bros.* may receive a reward
    when it completes a level or exceeds a certain score, and a punishment when it
    loses a life. However, this supervised feedback is not associated with specific
    decisions to run, avoid Goombas, or pick up fire flowers. While this book will
    discuss semi-supervised learning, we will focus primarily on supervised and unsupervised
    learning, as these categories include most the common machine learning problems.
    In the next sections, we will review supervised and unsupervised learning in more
    detail.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习和无监督学习可以被认为处于一个光谱的两端。一些问题类型，被称为**半监督**学习问题，既利用监督数据也利用无监督数据；这些问题位于监督学习和无监督学习之间的光谱上。半监督机器学习的一个例子是强化学习，其中程序根据其决策获得反馈，但反馈可能与单个决策无关。例如，一个学习玩横版滚动视频游戏（如*超级马里奥兄弟*）的强化学习程序，当它完成一个关卡或超过某个分数时，可能会获得奖励，而当它失去生命时，则会受到惩罚。然而，这种监督反馈与特定决策（例如是否奔跑、避开食人蘑菇或捡起火焰花）无关。尽管本书会讨论半监督学习，我们将主要关注监督学习和无监督学习，因为这两个类别涵盖了大多数常见的机器学习问题。在接下来的章节中，我们将更详细地回顾监督学习和无监督学习。
- en: A supervised learning program learns from labeled examples of the outputs that
    should be produced for an input. There are many names for the output of a machine
    learning program. Several disciplines converge in machine learning, and many of
    those disciplines use their own terminology. In this book, we will refer to the
    output as the **response variable**. Other names for response variables include
    dependent variables, regressands, criterion variables, measured variables, responding
    variables, explained variables, outcome variables, experimental variables, labels,
    and output variables. Similarly, the input variables have several names. In this
    book, we will refer to the input variables as **features**, and the phenomena
    they measure as **explanatory variables**. Other names for explanatory variables
    include predictors, regressors, controlled variables, manipulated variables, and
    exposure variables. Response variables and explanatory variables may take real
    or discrete values.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习程序通过从标记的示例中学习，了解输入应产生的输出。机器学习程序的输出有许多不同的名称。机器学习涉及多个学科，许多学科都有自己的术语。本书中，我们将输出称为**响应变量**。响应变量的其他名称包括因变量、回归变量、标准变量、测量变量、响应变量、解释变量、结果变量、实验变量、标签和输出变量。类似地，输入变量也有多个名称。本书中，我们将输入变量称为**特征**，它们所测量的现象称为**解释变量**。解释变量的其他名称包括预测变量、回归变量、控制变量、操控变量和暴露变量。响应变量和解释变量可以取实数值或离散值。
- en: The collection of examples that comprise supervised experience is called a **training
    set**. A collection of examples that is used to assess the performance of a program
    is called a **test set**. The response variable can be thought of as the answer
    to the question posed by the explanatory variables. Supervised learning problems
    learn from a collection of answers to different questions; that is, supervised
    learning programs are provided with the correct answers and must learn to respond
    correctly to unseen, but similar, questions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 包含监督经验的示例集合被称为**训练集**。用于评估程序性能的示例集合被称为**测试集**。响应变量可以被看作是由解释变量提出的问题的答案。监督学习问题通过学习不同问题的答案来学习；也就是说，监督学习程序提供了正确的答案，并且必须学会对未见过的但相似的问题做出正确回应。
- en: Machine learning tasks
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习任务
- en: Two of the most common supervised machine learning tasks are **classification**
    and **regression**. In classification tasks the program must learn to predict
    discrete values for the response variables from one or more explanatory variables.
    That is, the program must predict the most probable category, class, or label
    for new observations. Applications of classification include predicting whether
    a stock's price will rise or fall, or deciding if a news article belongs to the
    politics or leisure section. In regression problems the program must predict the
    value of a continuous response variable. Examples of regression problems include
    predicting the sales for a new product, or the salary for a job based on its description.
    Similar to classification, regression problems require supervised learning.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 两个最常见的监督学习任务是**分类**和**回归**。在分类任务中，程序必须学习从一个或多个解释变量预测响应变量的离散值。也就是说，程序必须预测新观察值的最可能类别、类或标签。分类的应用包括预测某只股票价格是上涨还是下跌，或者决定一篇新闻文章是属于政治还是休闲版块。在回归问题中，程序必须预测一个连续响应变量的值。回归问题的例子包括预测新产品的销量，或者根据工作描述预测工资。与分类类似，回归问题也需要监督学习。
- en: A common unsupervised learning task is to discover groups of related observations,
    called **clusters**, within the training data. This task, called **clustering**
    or cluster analysis, assigns observations to groups such that observations within
    groups are more similar to each other based on some similarity measure than they
    are to observations in other groups. Clustering is often used to explore a dataset.
    For example, given a collection of movie reviews, a clustering algorithm might
    discover sets of positive and negative reviews. The system will not be able to
    label the clusters as "positive" or "negative"; without supervision, it will only
    have knowledge that the grouped observations are similar to each other by some
    measure. A common application of clustering is discovering segments of customers
    within a market for a product. By understanding what attributes are common to
    particular groups of customers, marketers can decide what aspects of their campaigns
    need to be emphasized. Clustering is also used by Internet radio services; for
    example, given a collection of songs, a clustering algorithm might be able to
    group the songs according to their genres. Using different similarity measures,
    the same clustering algorithm might group the songs by their keys, or by the instruments
    they contain.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的无监督学习任务是发现训练数据中相关观察值的组，称为**簇**。这个任务被称为**聚类**或聚类分析，它将观察值分配到组中，使得同一组内的观察值在某种相似性度量下，比与其他组的观察值更为相似。聚类通常用于探索数据集。例如，给定一组电影评论，聚类算法可能会发现正面和负面评论的集合。系统无法将这些簇标记为“正面”或“负面”；在没有监督的情况下，它只能知道这些分组的观察值在某种度量下是相似的。聚类的一个常见应用是发现市场中某个产品的顾客细分。通过了解哪些特征是特定顾客群体的共同点，市场营销人员可以决定他们的营销活动需要强调哪些方面。聚类也被互联网广播服务使用；例如，给定一组歌曲，聚类算法可能会根据歌曲的流派将它们分组。使用不同的相似性度量，同一个聚类算法可能会根据歌曲的调性，或者它们包含的乐器来分组歌曲。
- en: '**Dimensionality** **reduction** is another common unsupervised learning task.
    Some problems may contain thousands or even millions of explanatory variables,
    which can be computationally costly to work with. Additionally, the program''s
    ability to generalize may be reduced if some of the explanatory variables capture
    noise or are irrelevant to the underlying relationship. Dimensionality reduction
    is the process of discovering the explanatory variables that account for the greatest
    changes in the response variable. Dimensionality reduction can also be used to
    visualize data. It is easy to visualize a regression problem such as predicting
    the price of a home from its size; the size of the home can be plotted on the
    graph''s *x* axis, and the price of the home can be plotted on the *y* axis. Similarly,
    it is easy to visualize the housing price regression problem when a second explanatory
    variable is added. The number of bathrooms in the house could be plotted on the
    z axis, for instance. A problem with thousands of explanatory variables, however,
    becomes impossible to visualize.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**降维**是另一种常见的无监督学习任务。有些问题可能包含成千上万甚至百万个解释变量，而处理这些变量可能需要大量的计算资源。此外，如果某些解释变量捕捉到噪声或与潜在关系无关，程序的泛化能力可能会降低。降维是发现那些对响应变量变化贡献最大的解释变量的过程。降维还可以用于数据可视化。回归问题如预测房屋价格与房屋大小之间的关系就很容易进行可视化；房屋的大小可以绘制在图表的*x*轴上，房屋的价格可以绘制在*y*轴上。同样，当添加第二个解释变量时，住房价格回归问题也很容易进行可视化。例如，房屋的浴室数量可以绘制在z轴上。然而，当问题涉及成千上万的解释变量时，就变得无法可视化了。'
- en: Training data and test data
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练数据和测试数据
- en: The observations in the training set comprise the experience that the algorithm
    uses to learn. In supervised learning problems, each observation consists of an
    observed response variable and one or more observed explanatory variables.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集中的观察值构成了算法用来学习的经验。在监督学习问题中，每个观察值由一个观察到的响应变量和一个或多个观察到的解释变量组成。
- en: The test set is a similar collection of observations that is used to evaluate
    the performance of the model using some performance metric. It is important that
    no observations from the training set are included in the test set. If the test
    set does contain examples from the training set, it will be difficult to assess
    whether the algorithm has learned to generalize from the training set or has simply
    memorized it. A program that generalizes well will be able to effectively perform
    a task with new data. In contrast, a program that memorizes the training data
    by learning an overly complex model could predict the values of the response variable
    for the training set accurately, but will fail to predict the value of the response
    variable for new examples.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集是一个类似的观察集合，用于通过某些性能指标评估模型的表现。重要的是，测试集不能包含来自训练集的任何观察。如果测试集中包含了训练集中的示例，那么就很难评估算法是否学会了从训练集中泛化，还是仅仅记住了它。一个能够很好地泛化的程序将能够有效地使用新数据执行任务。相反，一个通过学习过于复杂的模型记住训练数据的程序，可能能够准确预测训练集中的响应变量的值，但对于新示例的响应变量预测会失败。
- en: Memorizing the training set is called **over-fitting**. A program that memorizes
    its observations may not perform its task well, as it could memorize relations
    and structures that are noise or coincidence. Balancing memorization and generalization,
    or over-fitting and under-fitting, is a problem common to many machine learning
    algorithms. In later chapters we will discuss regularization, which can be applied
    to many models to reduce over-fitting.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆训练集被称为**过拟合**。一个记住其观察结果的程序可能无法很好地完成任务，因为它可能会记住噪声或偶然的关系和结构。平衡记忆和泛化，或者过拟合和欠拟合，是许多机器学习算法共同面临的问题。在后续章节中，我们将讨论正则化，它可以应用于许多模型以减少过拟合。
- en: In addition to the training and test data, a third set of observations, called
    a **validation** or **hold-out set**, is sometimes required. The validation set
    is used to tune variables called **hyperparameters**, which control how the model
    is learned. The program is still evaluated on the test set to provide an estimate
    of its performance in the real world; its performance on the validation set should
    not be used as an estimate of the model's real-world performance since the program
    has been tuned specifically to the validation data. It is common to partition
    a single set of supervised observations into training, validation, and test sets.
    There are no requirements for the sizes of the partitions, and they may vary according
    to the amount of data available. It is common to allocate 50 percent or more of
    the data to the training set, 25 percent to the test set, and the remainder to
    the validation set.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 除了训练数据和测试数据之外，有时还需要一个第三组数据，称为**验证集**或**保留集**。验证集用于调整称为**超参数**的变量，这些变量控制模型的学习方式。程序仍然会在测试集上进行评估，以提供其在现实世界中的表现估计；其在验证集上的表现不应作为模型在现实世界中的表现估计，因为程序已经专门针对验证数据进行了调整。通常，将一个监督学习数据集划分为训练集、验证集和测试集。对分区大小没有严格要求，大小可以根据可用数据量的不同而有所变化。通常会将50％或更多的数据分配给训练集，25％分配给测试集，其余部分分配给验证集。
- en: Some training sets may contain only a few hundred observations; others may include
    millions. Inexpensive storage, increased network connectivity, the ubiquity of
    sensor-packed smartphones, and shifting attitudes towards privacy have contributed
    to the contemporary state of big data, or training sets with millions or billions
    of examples. While this book will not work with datasets that require parallel
    processing on tens or hundreds of machines, the predictive power of many machine
    learning algorithms improves as the amount of training data increases. However,
    machine learning algorithms also follow the maxim "garbage in, garbage out." A
    student who studies for a test by reading a large, confusing textbook that contains
    many errors will likely not score better than a student who reads a short but
    well-written textbook. Similarly, an algorithm trained on a large collection of
    noisy, irrelevant, or incorrectly labeled data will not perform better than an
    algorithm trained on a smaller set of data that is more representative of problems
    in the real world.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一些训练集可能只包含几百个观察值，而其他的可能包含数百万个。廉价存储、网络连接的增加、配备传感器的智能手机的普及以及对隐私态度的转变，共同促成了当今大数据的状态，或是包含数百万或数十亿个样本的训练集。虽然本书不会使用需要在几十或上百台机器上进行并行处理的数据集，但许多机器学习算法的预测能力会随着训练数据量的增加而提升。然而，机器学习算法也遵循“垃圾进，垃圾出”的原则。一个通过阅读一本庞大且充满错误的教材来备考的学生，可能不会比一个阅读一本简洁但写得很好的教材的学生考得更好。同样，一个在大量嘈杂、无关或标签错误的数据上训练的算法，也不会比在一个较小且更能代表现实问题的数据集上训练的算法表现得更好。
- en: 'Many supervised training sets are prepared manually, or by semi-automated processes.
    Creating a large collection of supervised data can be costly in some domains.
    Fortunately, several datasets are bundled with scikit-learn, allowing developers
    to focus on experimenting with models instead. During development, and particularly
    when training data is scarce, a practice called **cross-validation** can be used
    to train and validate an algorithm on the same data. In cross-validation, the
    training data is partitioned. The algorithm is trained using all but one of the
    partitions, and tested on the remaining partition. The partitions are then rotated
    several times so that the algorithm is trained and evaluated on all of the data.
    The following diagram depicts cross-validation with five partitions or **folds**:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 许多监督学习数据集是手动准备的，或者通过半自动化过程生成的。在某些领域，创建一个大型监督数据集可能是非常昂贵的。幸运的是，scikit-learn提供了几个数据集，允许开发者专注于模型的实验开发。在开发过程中，尤其是当训练数据稀缺时，一种称为**交叉验证**的做法可以用来在相同的数据上训练和验证算法。在交叉验证中，训练数据被划分。算法使用除一个分区之外的所有分区进行训练，并在剩余的分区上进行测试。然后，这些分区会旋转多次，以便算法能在所有数据上进行训练和评估。下图展示了包含五个分区或**折叠**的交叉验证：
- en: '![Training data and test data](img/8365OS_01_01.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![训练数据和测试数据](img/8365OS_01_01.jpg)'
- en: The original dataset is partitioned into five subsets of equal size, labeled
    **A** through **E**. Initially, the model is trained on partitions **B** through
    **E**, and tested on partition **A**. In the next iteration, the model is trained
    on partitions **A**, **C**, **D**, and **E**, and tested on partition **B**. The
    partitions are rotated until models have been trained and tested on all of the
    partitions. Cross-validation provides a more accurate estimate of the model's
    performance than testing a single partition of the data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集被划分为五个大小相等的子集，标记为**A**到**E**。最初，模型在**B**到**E**的分区上进行训练，并在**A**分区上进行测试。在下一轮中，模型在**A**、**C**、**D**和**E**的分区上进行训练，并在**B**分区上进行测试。分区将轮换，直到模型在所有分区上进行过训练和测试。交叉验证提供了比单一数据分区测试更准确的模型性能估计。
- en: Performance measures, bias, and variance
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能指标、偏差和方差
- en: 'Many metrics can be used to measure whether or not a program is learning to
    perform its task more effectively. For supervised learning problems, many performance
    metrics measure the number of prediction errors. There are two fundamental causes
    of prediction error: a model''s **bias** and its **variance**. Assume that you
    have many training sets that are all unique, but equally representative of the
    population. A model with a high bias will produce similar errors for an input
    regardless of the training set it was trained with; the model biases its own assumptions
    about the real relationship over the relationship demonstrated in the training
    data. A model with high variance, conversely, will produce different errors for
    an input depending on the training set that it was trained with. A model with
    high bias is inflexible, but a model with high variance may be so flexible that
    it models the noise in the training set. That is, a model with high variance over-fits
    the training data, while a model with high bias under-fits the training data.
    It can be helpful to visualize bias and variance as darts thrown at a dartboard.
    Each dart is analogous to a prediction from a different dataset. A model with
    high bias but low variance will throw darts that are far from the bull''s eye,
    but tightly clustered. A model with high bias and high variance will throw darts
    all over the board; the darts are far from the bull''s eye and each other.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多指标可以用来衡量一个程序是否在更有效地执行任务。对于监督学习问题，许多性能指标衡量的是预测错误的数量。预测错误有两个根本原因：模型的**偏差**和**方差**。假设你有许多训练集，它们都是唯一的，但在代表性上都相等。如果一个模型的偏差很大，那么无论用哪个训练集进行训练，它都会对某个输入产生类似的错误；模型会偏向自己对真实关系的假设，而不是训练数据中展示的关系。相反，如果一个模型的方差很大，它会根据训练集的不同而对某个输入产生不同的错误。高偏差的模型缺乏灵活性，而高方差的模型可能过于灵活，以至于将训练集中的噪声也拟合进去。也就是说，一个高方差的模型会过拟合训练数据，而高偏差的模型则会欠拟合训练数据。可以通过将偏差和方差比作投掷飞镖来帮助理解。每一支飞镖类似于来自不同数据集的一个预测。一个高偏差但低方差的模型会将飞镖投向远离靶心的地方，但飞镖会聚集在一起。一个高偏差和高方差的模型会将飞镖投向四处；飞镖既远离靶心，又互相分散。
- en: 'A model with low bias and high variance will throw darts that are closer to
    the bull''s eye, but poorly clustered. Finally, a model with low bias and low
    variance will throw darts that are tightly clustered around the bull''s eye, as
    shown in the following diagram:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一个低偏差和高方差的模型会将飞镖投向更接近靶心的地方，但飞镖聚集得不好。最后，一个低偏差和低方差的模型会将飞镖投向紧紧聚集在靶心周围的地方，如下图所示：
- en: '![Performance measures, bias, and variance](img/8365OS_01_02.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![性能指标、偏差和方差](img/8365OS_01_02.jpg)'
- en: Ideally, a model will have both low bias and variance, but efforts to decrease
    one will frequently increase the other. This is known as the **bias-variance trade-off**.
    We will discuss the biases and variances of many of the models introduced in this
    book.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，模型既具有低偏差又具有低方差，但减少其中一个往往会增加另一个。这被称为**偏差-方差权衡**。我们将在本书中讨论许多模型的偏差和方差。
- en: Unsupervised learning problems do not have an error signal to measure; instead,
    performance metrics for unsupervised learning problems measure some attributes
    of the structure discovered in the data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习问题没有错误信号可供测量；相反，无监督学习问题的性能指标衡量的是数据中发现的结构的一些属性。
- en: Most performance measures can only be calculated for a specific type of task.
    Machine learning systems should be evaluated using performance measures that represent
    the costs associated with making errors in the real world. While this may seem
    obvious, the following example describes the use of a performance measure that
    is appropriate for the task in general but not for its specific application.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数性能衡量标准只能针对特定类型的任务进行计算。机器学习系统应该使用能够代表现实世界中错误成本的性能衡量标准进行评估。虽然这看起来显而易见，但以下例子描述了使用一种适合一般任务但不适用于具体应用的性能衡量标准。
- en: Consider a classification task in which a machine learning system observes tumors
    and must predict whether these tumors are malignant or benign. **Accuracy**, or
    the fraction of instances that were classified correctly, is an intuitive measure
    of the program's performance. While accuracy does measure the program's performance,
    it does not differentiate between malignant tumors that were classified as being
    benign, and benign tumors that were classified as being malignant. In some applications,
    the costs associated with all types of errors may be the same. In this problem,
    however, failing to identify malignant tumors is likely to be a more severe error
    than mistakenly classifying benign tumors as being malignant.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个分类任务，其中机器学习系统观察肿瘤，并必须预测这些肿瘤是恶性还是良性。**准确率**，即被正确分类的实例所占的比例，是程序性能的直观衡量标准。虽然准确率能够衡量程序的表现，但它并不能区分被误判为良性的恶性肿瘤和被误判为恶性的良性肿瘤。在某些应用中，所有类型错误的成本可能是一样的。然而，在这个问题中，未能识别恶性肿瘤可能比将良性肿瘤错误分类为恶性肿瘤更为严重。
- en: We can measure each of the possible prediction outcomes to create different
    views of the classifier's performance. When the system correctly classifies a
    tumor as being malignant, the prediction is called a **true positive**. When the
    system incorrectly classifies a benign tumor as being malignant, the prediction
    is a **false positive**. Similarly, a **false negative** is an incorrect prediction
    that the tumor is benign, and a **true negative** is a correct prediction that
    a tumor is benign. These four outcomes can be used to calculate several common
    measures of classification performance, including **accuracy**, **precision**,
    and **recall**.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以测量每一种可能的预测结果，以创建对分类器性能的不同视角。当系统正确地将肿瘤分类为恶性时，这种预测被称为**真正例**。当系统错误地将良性肿瘤分类为恶性时，这种预测是**假正例**。类似地，**假负例**是将肿瘤错误预测为良性，而**真负例**是正确预测肿瘤为良性。这四种结果可以用来计算几个常见的分类性能衡量标准，包括**准确率**、**精确度**和**召回率**。
- en: 'Accuracy is calculated with the following formula, where *TP* is the number
    of true positives, *TN* is the number of true negatives, *FP* is the number of
    false positives, and *FN* is the number of false negatives:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率通过以下公式计算，其中*TP*是正确预测为恶性肿瘤的数量，*TN*是正确预测为良性肿瘤的数量，*FP*是错误预测为恶性肿瘤的数量，*FN*是错误预测为良性肿瘤的数量：
- en: '![Performance measures, bias, and variance](img/8365OS_01_03.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![性能衡量标准、偏差和方差](img/8365OS_01_03.jpg)'
- en: 'Precision is the fraction of the tumors that were predicted to be malignant
    that are actually malignant. Precision is calculated with the following formula:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度是预测为恶性肿瘤中，实际为恶性的比例。精确度通过以下公式计算：
- en: '![Performance measures, bias, and variance](img/8365OS_01_04.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![性能衡量标准、偏差和方差](img/8365OS_01_04.jpg)'
- en: 'Recall is the fraction of malignant tumors that the system identified. Recall
    is calculated with the following formula:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率是系统识别出的恶性肿瘤的比例。召回率通过以下公式计算：
- en: '![Performance measures, bias, and variance](img/8365OS_01_05.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![性能衡量标准、偏差和方差](img/8365OS_01_05.jpg)'
- en: In this example, precision measures the fraction of tumors that were predicted
    to be malignant that are actually malignant. Recall measures the fraction of truly
    malignant tumors that were detected.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，精确度衡量的是被预测为恶性的肿瘤中，实际为恶性的比例。召回率衡量的是实际恶性肿瘤中被检测出的比例。
- en: The precision and recall measures could reveal that a classifier with impressive
    accuracy actually fails to detect most of the malignant tumors. If most tumors
    are benign, even a classifier that never predicts malignancy could have high accuracy.
    A different classifier with lower accuracy and higher recall might be better suited
    to the task, since it will detect more of the malignant tumors.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 精度和召回率度量可能揭示一个具有令人印象深刻的准确率的分类器实际上未能检测出大多数恶性肿瘤。如果大多数肿瘤是良性的，即使是一个从不预测恶性的分类器，也可能具有很高的准确率。一个不同的分类器，尽管准确率较低，但召回率较高，可能更适合此任务，因为它能检测到更多的恶性肿瘤。
- en: Many other performance measures for classification can be used; we will discuss
    some, including metrics for multilabel classification problems, in later chapters.
    In the next chapter, we will discuss some common performance measures for regression
    tasks.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他用于分类的性能度量方法可以使用；我们将在后续章节中讨论一些，包括多标签分类问题的度量标准。在下一章中，我们将讨论回归任务的一些常见性能度量标准。
- en: An introduction to scikit-learn
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: scikit-learn 简介
- en: Since its release in 2007, scikit-learn has become one of the most popular open
    source machine learning libraries for Python. scikit-learn provides algorithms
    for machine learning tasks including classification, regression, dimensionality
    reduction, and clustering. It also provides modules for extracting features, processing
    data, and evaluating models.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 自 2007 年发布以来，scikit-learn 已成为最流行的 Python 开源机器学习库之一。scikit-learn 提供了用于机器学习任务的算法，包括分类、回归、降维和聚类。它还提供了提取特征、处理数据和评估模型的模块。
- en: Conceived as an extension to the SciPy library, scikit-learn is built on the
    popular Python libraries NumPy and matplotlib. NumPy extends Python to support
    efficient operations on large arrays and multidimensional matrices. matplotlib
    provides visualization tools, and SciPy provides modules for scientific computing.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 作为 SciPy 库的扩展而构思，基于流行的 Python 库 NumPy 和 matplotlib。NumPy 扩展了 Python，使其能够高效地操作大型数组和多维矩阵。matplotlib
    提供了可视化工具，SciPy 提供了科学计算模块。
- en: scikit-learn is popular for academic research because it has a well-documented,
    easy-to-use, and versatile API. Developers can use scikit-learn to experiment
    with different algorithms by changing only a few lines of the code. scikit-learn
    wraps some popular implementations of machine learning algorithms, such as LIBSVM
    and LIBLINEAR. Other Python libraries, including NLTK, include wrappers for scikit-learn.
    scikit-learn also includes a variety of datasets, allowing developers to focus
    on algorithms rather than obtaining and cleaning data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 因为拥有文档齐全、易于使用和多功能的 API，在学术研究中非常流行。开发人员可以通过只改变几行代码，利用 scikit-learn
    实验不同的算法。scikit-learn 封装了某些流行的机器学习算法实现，例如 LIBSVM 和 LIBLINEAR。其他 Python 库，包括 NLTK，也为
    scikit-learn 提供了封装。scikit-learn 还包含各种数据集，使开发人员可以专注于算法，而无需担心数据的获取和清理。
- en: Licensed under the permissive BSD license, scikit-learn can be used in commercial
    applications without restrictions. Many of scikit-learn's algorithms are fast
    and scalable to all but massive datasets. Finally, scikit-learn is noted for its
    reliability; much of the library is covered by automated tests.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 作为许可宽松的 BSD 许可证下的开源软件，scikit-learn 可以在商业应用中不受限制地使用。scikit-learn 的许多算法速度快且可扩展，适用于几乎所有的数据集，除了极大的数据集。最后，scikit-learn
    以其可靠性著称；库中的大部分内容都由自动化测试覆盖。
- en: Installing scikit-learn
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 scikit-learn
- en: 'This book is written for version 0.15.1 of scikit-learn; use this version to
    ensure that the examples run correctly. If you have previously installed scikit-learn,
    you can retrieve the version number with the following code:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本书是为 scikit-learn 版本 0.15.1 编写的；请使用该版本以确保示例能够正确运行。如果您之前已安装过 scikit-learn，可以通过以下代码检索版本号：
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you have not previously installed scikit-learn, you can install it from a
    package manager or build it from the source. We will review the installation processes
    for Linux, OS X, and Windows in the following sections, but refer to [http://scikit-learn.org/stable/install.html](http://scikit-learn.org/stable/install.html)
    for the latest instructions. The following instructions only assume that you have
    installed Python 2.6, Python 2.7, or Python 3.2 or newer. Go to [http://www.python.org/download/](http://www.python.org/download/)
    for instructions on how to install Python.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你之前没有安装过scikit-learn，可以通过包管理器安装它，或者从源代码构建它。我们将在接下来的章节中回顾Linux、OS X和Windows的安装过程，但可以参考[http://scikit-learn.org/stable/install.html](http://scikit-learn.org/stable/install.html)获取最新的安装说明。以下说明仅假设你已经安装了Python
    2.6、Python 2.7或Python 3.2或更高版本。前往[http://www.python.org/download/](http://www.python.org/download/)获取安装Python的说明。
- en: Installing scikit-learn on Windows
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Windows上安装scikit-learn
- en: scikit-learn requires Setuptools, a third-party package that supports packaging
    and installing software for Python. Setuptools can be installed on Windows by
    running the bootstrap script at [https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py](https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn需要Setuptools，这是一个支持Python软件打包和安装的第三方包。可以通过运行[https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py](https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py)中的引导脚本，在Windows上安装Setuptools。
- en: Windows binaries for the 32- and 64-bit versions of scikit-learn are also available.
    If you cannot determine which version you need, install the 32-bit version. Both
    versions depend on NumPy 1.3 or newer. The 32-bit version of NumPy can be downloaded
    from [http://sourceforge.net/projects/numpy/files/NumPy/](http://sourceforge.net/projects/numpy/files/NumPy/).
    The 64-bit version can be downloaded from [http://www.lfd.uci.edu/~gohlke/pythonlibs/#scikit-learn](http://www.lfd.uci.edu/~gohlke/pythonlibs/#scikit-learn).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以获取适用于32位和64位版本的Windows二进制文件。如果无法确定需要哪一版本，请安装32位版本。两个版本都依赖于NumPy 1.3或更高版本。32位版本的NumPy可以从[http://sourceforge.net/projects/numpy/files/NumPy/](http://sourceforge.net/projects/numpy/files/NumPy/)下载。64位版本可以从[http://www.lfd.uci.edu/~gohlke/pythonlibs/#scikit-learn](http://www.lfd.uci.edu/~gohlke/pythonlibs/#scikit-learn)下载。
- en: A Windows installer for the 32-bit version of scikit-learn can be downloaded
    from [http://sourceforge.net/projects/scikit-learn/files/](http://sourceforge.net/projects/scikit-learn/files/).
    An installer for the 64-bit version of scikit-learn can be downloaded from [http://www.lfd.uci.edu/~gohlke/pythonlibs/#scikit-learn](http://www.lfd.uci.edu/~gohlke/pythonlibs/#scikit-learn).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从[http://sourceforge.net/projects/scikit-learn/files/](http://sourceforge.net/projects/scikit-learn/files/)下载32位版本的Windows安装程序。可以从[http://www.lfd.uci.edu/~gohlke/pythonlibs/#scikit-learn](http://www.lfd.uci.edu/~gohlke/pythonlibs/#scikit-learn)下载64位版本的安装程序。
- en: scikit-learn can also be built from the source code on Windows. Building requires
    a C/C++ compiler such as MinGW ([http://www.mingw.org/](http://www.mingw.org/)),
    NumPy, SciPy, and Setuptools.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以从源代码在Windows上构建scikit-learn。构建需要一个C/C++编译器，如MinGW（[http://www.mingw.org/](http://www.mingw.org/)）、NumPy、SciPy和Setuptools。
- en: 'To build, clone the Git repository from [https://github.com/scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn)
    and execute the following command:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建，请从[https://github.com/scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn)克隆Git仓库，并执行以下命令：
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Installing scikit-learn on Linux
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Linux上安装scikit-learn
- en: There are several options to install scikit-learn on Linux, depending on your
    distribution. The preferred option to install scikit-learn on Linux is to use
    `pip`. You may also install it using a package manager, or build scikit-learn
    from its source.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux上安装scikit-learn有多种选择，具体取决于你的发行版。推荐的安装scikit-learn的方式是使用`pip`。你也可以使用包管理器进行安装，或者从源代码构建scikit-learn。
- en: 'To install scikit-learn using `pip`, execute the following command:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`pip`安装scikit-learn，请执行以下命令：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To build scikit-learn, clone the Git repository from [https://github.com/scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn).
    Then install the following dependencies:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建scikit-learn，请从[https://github.com/scikit-learn/scikit-learn](https://github.com/scikit-learn/scikit-learn)克隆Git仓库。然后安装以下依赖项：
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Navigate to the repository''s directory and execute the following command:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 导航到仓库目录并执行以下命令：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Installing scikit-learn on OS X
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在OS X上安装scikit-learn
- en: 'scikit-learn can be installed on OS X using Macports:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用Macports在OS X上安装scikit-learn：
- en: '[PRE5]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If Python 2.7 is installed, run the following command:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果安装了Python 2.7，请运行以下命令：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'scikit-learn can also be installed using `pip` with the following command:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn也可以使用`pip`通过以下命令进行安装：
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Verifying the installation
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证安装
- en: 'To verify that scikit-learn has been installed correctly, open a Python console
    and execute the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证scikit-learn是否已正确安装，请打开Python控制台并执行以下命令：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To run scikit-learn''s unit tests, first install the `nose` library. Then execute
    the following:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行scikit-learn的单元测试，首先安装`nose`库。然后执行以下命令：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Congratulations! You've successfully installed scikit-learn.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已成功安装scikit-learn。
- en: Installing pandas and matplotlib
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装pandas和matplotlib
- en: pandas is an open source library that provides data structures and analysis
    tools for Python. pandas is a powerful library, and several books describe how
    to use pandas for data analysis. We will use a few of panda's convenient tools
    for importing data and calculating summary statistics.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: pandas是一个开源库，为Python提供数据结构和分析工具。pandas是一个强大的库，许多书籍描述了如何使用pandas进行数据分析。我们将使用pandas的一些便利工具来导入数据和计算汇总统计信息。
- en: 'pandas can be installed on Windows, OS X, and Linux using `pip` with the following
    command:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: pandas可以在Windows、OS X和Linux上使用`pip`通过以下命令进行安装：
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'pandas can also be installed on Debian- and Ubuntu-based Linux distributions
    using the following command:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: pandas也可以在基于Debian和Ubuntu的Linux发行版上通过以下命令进行安装：
- en: '[PRE11]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'matplotlib is a library used to easily create plots, histograms, and other
    charts with Python. We will use it to visualize training data and models. matplotlib
    has several dependencies. Like pandas, matplotlib depends on NumPy, which should
    already be installed. On Debian- and Ubuntu-based Linux distributions, matplotlib
    and its dependencies can be installed using the following command:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: matplotlib是一个用于轻松创建图表、直方图和其他图形的Python库。我们将使用它来可视化训练数据和模型。matplotlib有几个依赖项。像pandas一样，matplotlib依赖于NumPy，NumPy应该已经安装好。在基于Debian和Ubuntu的Linux发行版上，可以通过以下命令安装matplotlib及其依赖项：
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Binaries for OS X and Windows can be downloaded from [http://matplotlib.org/downloads.html](http://matplotlib.org/downloads.html).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: OS X和Windows的二进制文件可以从[http://matplotlib.org/downloads.html](http://matplotlib.org/downloads.html)下载。
- en: Summary
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter we defined machine-learning as the design and study of programs
    that can improve their performance of a task by learning from experience. We discussed
    the spectrum of supervision in experience. At one end of the spectrum is supervised
    learning, in which a program learns from inputs that are labeled with their corresponding
    outputs. At the opposite end of the spectrum is unsupervised learning, in which
    the program must discover hidden structure in unlabeled data. Semi-supervised
    approaches make use of both labeled and unlabeled training data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将机器学习定义为设计和研究能够通过从经验中学习来提高任务表现的程序。我们讨论了经验中监督的范围。在这个范围的一个端点是监督学习，在这种学习方式下，程序通过带有相应输出标签的输入来学习。范围的另一端是无监督学习，在这种学习方式下，程序必须在没有标签的数据中发现隐藏的结构。半监督方法则结合了带标签和不带标签的训练数据。
- en: We discussed common types of machine learning tasks and reviewed example applications.
    In classification tasks the program must predict the value of a discrete response
    variable from the explanatory variables. In regression tasks the program must
    predict the value of a continuous response variable from the explanatory variables.
    In regression tasks, the program must predict the value of a continuous response
    variable from the explanatory variables. Unsupervised learning tasks include clustering,
    in which observations are organized into groups according to some similarity measure
    and dimensionality reduction, which reduces a set of explanatory variables to
    a smaller set of synthetic features that retain as much information as possible.
    We also reviewed the bias-variance trade-off and discussed common performance
    measures for different machine learning tasks.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了常见的机器学习任务类型，并回顾了示例应用。在分类任务中，程序必须根据解释变量预测离散响应变量的值。在回归任务中，程序必须根据解释变量预测连续响应变量的值。在回归任务中，程序必须根据解释变量预测连续响应变量的值。无监督学习任务包括聚类，其中根据某种相似度度量将观测值组织成组；以及降维，它将一组解释变量减少为一组较小的合成特征，同时尽可能保留更多信息。我们还回顾了偏差-方差权衡，并讨论了不同机器学习任务的常见性能衡量标准。
- en: We also discussed the history, goals, and advantages of scikit-learn. Finally,
    we prepared our development environment by installing scikit-learn and other libraries
    that are commonly used in conjunction with it. In the next chapter, we will discuss
    the regression task in more detail, and build our first machine learning model
    with scikit-learn.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了 scikit-learn 的历史、目标和优势。最后，我们通过安装 scikit-learn 和其他常用的配套库来准备我们的开发环境。在下一章中，我们将更详细地讨论回归任务，并使用
    scikit-learn 构建我们的第一个机器学习模型。
