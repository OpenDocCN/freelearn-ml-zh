- en: Chapter 11. Stereo Vision and 3D Reconstruction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章 立体视觉和3D重建
- en: In this chapter, we are going to learn about stereo vision and how we can reconstruct
    the 3D map of a scene. We will discuss epipolar geometry, depth maps, and 3D reconstruction.
    We will learn how to extract 3D information from stereo images and build a point
    cloud.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习立体视觉以及我们如何重建场景的3D地图。我们将讨论极线几何、深度图和3D重建。我们将学习如何从立体图像中提取3D信息并构建点云。
- en: 'By the end of this chapter, you will know:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将知道：
- en: What is stereo correspondence
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是立体对应
- en: What is epipolar geometry
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是极线几何
- en: What is a depth map
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是深度图
- en: How to extract 3D information
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何提取3D信息
- en: How to build and visualize the 3D map of a given scene
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建和可视化给定场景的3D地图
- en: What is stereo correspondence?
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是立体对应？
- en: When we capture images, we project the 3D world around us on a 2D image plane.
    So technically, we only have 2D information when we capture those photos. Since
    all the objects in that scene are projected onto a flat 2D plane, the depth information
    is lost. We have no way of knowing how far an object is from the camera or how
    the objects are positioned with respect to each other in the 3D space. This is
    where stereo vision comes into the picture.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们捕捉图像时，我们将周围的3D世界投影到2D图像平面上。所以从技术上讲，当我们捕捉这些照片时，我们只有2D信息。由于场景中的所有物体都投影到一个平坦的2D平面上，深度信息就丢失了。我们无法知道物体距离摄像机的距离或物体在3D空间中的相对位置。这就是立体视觉发挥作用的地方。
- en: Humans are very good at inferring depth information from the real world. The
    reason is that we have two eyes positioned a couple of inches from each other.
    Each eye acts as a camera and we capture two images of the same scene from two
    different viewpoints, that is, one image each using the left and right eyes. So,
    our brain takes these two images and builds a 3D map using stereo vision. This
    is what we want to achieve using stereo vision algorithms. We can capture two
    photos of the same scene using different viewpoints, and then match the corresponding
    points to obtain the depth map of the scene.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 人类非常擅长从现实世界中推断深度信息。原因是我们的两只眼睛相距几英寸。每只眼睛都像是一个摄像机，我们从两个不同的视角捕捉同一场景的两个图像，即左眼和右眼各捕捉一个图像。因此，我们的大脑通过立体视觉使用这两张图像构建一个3D地图。这是我们希望通过立体视觉算法实现的目标。我们可以使用不同的视角捕捉同一场景的两个照片，然后匹配相应的点以获得场景的深度图。
- en: 'Let''s consider the following image:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下图像：
- en: '![What is stereo correspondence?](img/B04554_11_01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![什么是立体对应？](img/B04554_11_01.jpg)'
- en: 'Now, if we capture the same scene from a different angle, it will look like
    this:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们从不同的角度捕捉相同的场景，它将看起来像这样：
- en: '![What is stereo correspondence?](img/B04554_11_02.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![什么是立体对应？](img/B04554_11_02.jpg)'
- en: 'As you can see, there is a large amount of movement in the positions of the
    objects in the image. If you consider the pixel coordinates, the values of the
    initial position and final position will differ by a large amount in these two
    images. Consider the following image:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，图像中物体的位置有大量的移动。如果你考虑像素坐标，这两个图像中初始位置和最终位置的值将有很大的差异。考虑以下图像：
- en: '![What is stereo correspondence?](img/B04554_11_03.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![什么是立体对应？](img/B04554_11_03.jpg)'
- en: 'If we consider the same line of distance in the second image, it will look
    like this:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在第二张图像中考虑相同的距离线，它将看起来像这样：
- en: '![What is stereo correspondence?](img/B04554_11_04.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![什么是立体对应？](img/B04554_11_04.jpg)'
- en: 'The difference between **d1** and **d2** is large. Now, let''s bring the box
    closer to the camera:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**d1** 和 **d2** 之间的差异很大。现在，让我们将盒子靠近摄像机：'
- en: '![What is stereo correspondence?](img/B04554_11_05.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![什么是立体对应？](img/B04554_11_05.jpg)'
- en: 'Now, let''s move the camera by the same amount as we did earlier, and capture
    the same scene from this angle:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将摄像机移动与之前相同，并从这个角度捕捉相同的场景：
- en: '![What is stereo correspondence?](img/B04554_11_06.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![什么是立体对应？](img/B04554_11_06.jpg)'
- en: 'As you can see, the movement between the positions of the objects is not much.
    If you consider the pixel coordinates, you will see that the values are close
    to each other. The distance in the first image would be:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，物体位置之间的移动并不大。如果你考虑像素坐标，你会看到它们的值很接近。第一张图像中的距离将是：
- en: '![What is stereo correspondence?](img/B04554_11_07.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![什么是立体对应？](img/B04554_11_07.jpg)'
- en: 'If we consider the same line of distance in the second image, it will be as
    shown in the following image:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在第二张图像中考虑相同的距离线，它将如下所示：
- en: '![What is stereo correspondence?](img/B04554_11_08.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![什么是立体对应？](img/B04554_11_08.jpg)'
- en: 'The difference between **d3** and **d4** is small. We can say that the absolute
    difference between **d1** and **d2** is greater than the absolute difference between
    **d3** and **d4**. Even though the camera moved by the same amount, there is a
    big difference between the apparent distances between the initial and final positions.
    This happens because we can bring the object closer to the camera; the apparent
    movement decreases when you capture two images from different angles. This is
    the concept behind stereo correspondence: we capture two images and use this knowledge
    to extract the depth information from a given scene.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**d3** 和 **d4** 之间的差异很小。我们可以说，**d1** 和 **d2** 之间的绝对差异大于 **d3** 和 **d4** 之间的绝对差异。尽管相机移动了相同的距离，但初始位置和最终位置之间的视距差异很大。这是因为我们可以将物体移得更近；从不同角度捕捉两个图像时，视距的明显变化会减小。这是立体对应背后的概念：我们捕捉两个图像，并利用这些知识从给定的场景中提取深度信息。'
- en: What is epipolar geometry?
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是极线几何？
- en: 'Before discussing epipolar geometry, let''s discuss what happens when we capture
    two images of the same scene from two different viewpoints. Consider the following
    figure:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论极线几何之前，让我们讨论一下当我们从两个不同的视角捕捉同一场景的两个图像时会发生什么。考虑以下图示：
- en: '![What is epipolar geometry?](img/B04554_11_09.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![什么是极线几何？](img/B04554_11_09.jpg)'
- en: 'Let''s see how it happens in real life. Consider the following image:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在现实生活中它是如何发生的。考虑以下图像：
- en: '![What is epipolar geometry?](img/B04554_11_10.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![什么是极线几何？](img/B04554_11_10.jpg)'
- en: 'Now, let''s capture the same scene from a different viewpoint:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从不同的视角捕捉相同的场景：
- en: '![What is epipolar geometry?](img/B04554_11_11.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![什么是极线几何？](img/B04554_11_11.jpg)'
- en: Our goal is to match the keypoints in these two images to extract the scene
    information. The way we do this is by extracting a matrix that can associate the
    corresponding points between two stereo images. This is called the **fundamental
    matrix**.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是将这两幅图像中的关键点匹配起来，以提取场景信息。我们这样做是通过提取一个矩阵，该矩阵可以关联两个立体图像之间的对应点。这被称为 **基础矩阵**。
- en: 'As we saw in the camera figure earlier, we can draw lines to see where they
    meet. These lines are called **epipolar lines**. The point at which the epipolar
    lines converge is called epipole. If you match the keypoints using SIFT, and draw
    the lines towards the meeting point on the left image, it will look like this:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前在相机图示中看到的，我们可以画线来看它们在哪里相交。这些线被称为 **极线**。极线相交的点称为极点。如果你使用 SIFT 匹配关键点，并画出指向左图会合点的线条，它将看起来像这样：
- en: '![What is epipolar geometry?](img/B04554_11_12.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![什么是极线几何？](img/B04554_11_12.jpg)'
- en: 'Following are the matching feature points in the right image:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在右图中的匹配特征点：
- en: '![What is epipolar geometry?](img/B04554_11_13.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![什么是极线几何？](img/B04554_11_13.jpg)'
- en: 'The lines are epipolar lines. If you take the second image as the reference,
    they will appear as shown in the next image:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些线条是极线。如果你以第二幅图像为参考，它们将看起来如下：
- en: '![What is epipolar geometry?](img/B04554_11_14.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![什么是极线几何？](img/B04554_11_14.jpg)'
- en: 'Following are the matching feature points in the first image:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在第一张图像中的匹配特征点：
- en: '![What is epipolar geometry?](img/B04554_11_15.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![什么是极线几何？](img/B04554_11_15.jpg)'
- en: 'It''s important to understand epipolar geometry and how we draw these lines.
    If two frames are positioned in 3D, then each epipolar line between the two frames
    must intersect the corresponding feature in each frame and each of the camera
    origins. This can be used to estimate the pose of the cameras with respect to
    the 3D environment. We will use this information later on, to extract 3D information
    from the scene. Let''s take a look at the code:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 理解极线几何以及我们如何绘制这些线条非常重要。如果两个帧在三维空间中定位，那么两个帧之间的每条极线都必须与每个帧中相应的特征点和每个相机的原点相交。这可以用来估计相机相对于三维环境的姿态。我们将在稍后使用这些信息，从场景中提取三维信息。让我们看看代码：
- en: '[PRE0]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s see what happens if we use the **SURF** feature extractor. The lines
    in the left image will look like this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如果我们使用 **SURF** 特征提取器会发生什么。左图中的线条将看起来像这样：
- en: '![What is epipolar geometry?](img/B04554_11_16.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![什么是极线几何？](img/B04554_11_16.jpg)'
- en: 'Following are the matching feature points in the right image:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在右图中的匹配特征点：
- en: '![What is epipolar geometry?](img/B04554_11_17.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![什么是极线几何？](img/B04554_11_17.jpg)'
- en: 'If you take the second image as the reference, you will see something like
    the following image:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您以第二幅图像为参考，您将看到以下类似图像：
- en: '![What is epipolar geometry?](img/B04554_11_18.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![什么是极线几何？](img/B04554_11_18.jpg)'
- en: 'These are the matching feature points in the first image:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是第一幅图像中的匹配特征点：
- en: '![What is epipolar geometry?](img/B04554_11_19.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![什么是极线几何？](img/B04554_11_19.jpg)'
- en: Why are the lines different as compared to SIFT?
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与SIFT相比，为什么线条不同？
- en: SURF detects a different set of feature points, so the corresponding epipolar
    lines differ as well. As you can see in the images, there are more feature points
    detected when we use SURF. Since we have more information than before, the corresponding
    epipolar lines will also change accordingly.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: SURF检测到一组不同的特征点，因此相应的极线线也相应地不同。正如您在图像中看到的那样，当我们使用SURF时，检测到的特征点更多。由于我们比以前有更多信息，相应的极线线也会相应地改变。
- en: Building the 3D map
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建3D地图
- en: 'Now that we are familiar with epipolar geometry, let''s see how to use it to
    build a 3D map based on stereo images. Let''s consider the following figure:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经熟悉了极线几何，让我们看看如何使用它根据立体图像构建3D地图。让我们考虑以下图：
- en: '![Building the 3D map](img/B04554_11_20.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![构建3D地图](img/B04554_11_20.jpg)'
- en: The first step is to extract the disparity map between the two images. If you
    look at the figure, as we go closer to the object from the cameras along the connecting
    lines, the distance decreases between the points. Using this information, we can
    infer the distance of each point from the camera. This is called a depth map.
    Once we find the matching points between the two images, we can find the disparity
    by using epipolar lines to impose epipolar constraints.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是从两幅图像中提取视差图。如果您看图，当我们沿着连接线从摄像机靠近物体时，点之间的距离减小。使用这些信息，我们可以推断每个点与摄像机的距离。这被称为深度图。一旦我们在两幅图像中找到匹配点，我们就可以使用极线线来施加极线约束，从而找到视差。
- en: 'Let''s consider the following image:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下图像：
- en: '![Building the 3D map](img/B04554_11_21.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![构建3D地图](img/B04554_11_21.jpg)'
- en: 'If we capture the same scene from a different position, we get the following
    image:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从不同的位置捕捉相同的场景，我们会得到以下图像：
- en: '![Building the 3D map](img/B04554_11_22.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![构建3D地图](img/B04554_11_22.jpg)'
- en: 'If we reconstruct the 3D map, it will look like this:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们重建3D地图，它将看起来像这样：
- en: '![Building the 3D map](img/B04554_11_23.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![构建3D地图](img/B04554_11_23.jpg)'
- en: 'Bear in mind that these images were not captured using perfectly aligned stereo
    cameras. That''s the reason the 3D map looks so noisy! This is just to demonstrate
    how we can reconstruct the real world using stereo images. Let''s consider an
    image pair captured using stereo cameras that are properly aligned. Following
    is the left view image:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这些图像不是使用完美对齐的立体相机拍摄的。这就是3D地图看起来如此嘈杂的原因！这只是为了展示我们如何使用立体图像重建现实世界。让我们考虑使用正确对齐的立体相机捕获的图像对。以下为左侧视图图像：
- en: '![Building the 3D map](img/B04554_11_24.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![构建3D地图](img/B04554_11_24.jpg)'
- en: 'Next is the corresponding right view image:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是相应的右侧视图图像：
- en: '![Building the 3D map](img/B04554_11_25.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![构建3D地图](img/B04554_11_25.jpg)'
- en: 'If you extract the depth information and build the 3D map, it will look like
    this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您提取深度信息并构建3D地图，它将看起来像这样：
- en: '![Building the 3D map](img/B04554_11_26.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![构建3D地图](img/B04554_11_26.jpg)'
- en: 'Let''s rotate it to see if the depth is right for the different objects in
    the scene:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们旋转它，看看场景中不同物体的深度是否正确：
- en: '![Building the 3D map](img/B04554_11_27.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![构建3D地图](img/B04554_11_27.jpg)'
- en: You need a software called **MeshLab** to visualize the 3D scene. We'll discuss
    about it soon. As we can see in the preceding images, the items are correctly
    aligned according to their distance from the camera. We can intuitively see that
    they are arranged in the right way, including the tilted position of the mask.
    We can use this technique to build many interesting things.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要一个名为**MeshLab**的软件来可视化3D场景。我们很快就会讨论它。正如我们在前面的图像中看到的那样，项目根据它们与摄像机的距离正确对齐。我们可以直观地看到它们以正确的方式排列，包括面具的倾斜位置。我们可以使用这项技术来构建许多有趣的东西。
- en: 'Let''s see how to do it in OpenCV-Python:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在OpenCV-Python中实现它：
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To visualize the output, you need to download MeshLab from [http://meshlab.sourceforge.net](http://meshlab.sourceforge.net).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化输出，您需要从[http://meshlab.sourceforge.net](http://meshlab.sourceforge.net)下载MeshLab。
- en: Just open the `output.ply` file using MeshLab and you'll see the 3D image. You
    can rotate it to get a complete 3D view of the reconstructed scene. Some of the
    alternatives to MeshLab are Sketchup on OS X and Windows, and Blender on Linux.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 只需使用MeshLab打开`output.ply`文件，你就能看到3D图像。你可以旋转它以获得重建场景的完整3D视图。MeshLab的一些替代品包括OS
    X和Windows上的Sketchup，以及Linux上的Blender。
- en: Summary
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about stereo vision and 3D reconstruction. We discussed
    how to extract the fundamental matrix using different feature extractors. We learned
    how to generate the disparity map between two images, and use it to reconstruct
    the 3D map of a given scene.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了立体视觉和3D重建。我们讨论了如何使用不同的特征提取器提取基本矩阵。我们学习了如何生成两张图像之间的视差图，并使用它来重建给定场景的3D地图。
- en: In the next chapter, we are going to discuss augmented reality, and how we can
    build a cool application where we overlay graphics on top of real world objects
    in a live video.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论增强现实，以及我们如何构建一个酷炫的应用程序，在这个应用程序中，我们可以在实时视频上叠加图形到现实世界物体之上。
