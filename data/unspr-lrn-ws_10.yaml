- en: 9\. Hotspot Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9. 热点分析
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we will perform hotspot analysis. We will also visualize the
    results of hotspot analysis. We will use kernel density estimation, which is the
    most popular algorithm for building distributions using a collection of observations.
    We will build kernel density estimation models. We will describe the fundamentals
    behind probability density functions. By the end of the chapter, you should be
    able to leverage Python libraries to build multi-dimensional density estimation
    models and work with geo-spatial data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将进行热点分析，并可视化热点分析的结果。我们将使用核密度估计，这是构建分布时最常用的算法，使用的是一组观察值。我们将构建核密度估计模型，并描述概率密度函数背后的基本原理。在本章结束时，你应该能够利用
    Python 库构建多维密度估计模型，并处理地理空间数据。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: In the preceding chapter, we explored market basket analysis. Market basket
    analysis, as you hopefully recall, is an algorithm that seeks to understand the
    relationships between all the items and groups of items in transaction data. These
    relationships are then leveraged to help retailers optimize store layouts, more
    accurately order inventory, and adjust prices without shrinking the number of
    items in each transaction. We now change directions to explore hotspot modeling.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们探讨了市场篮子分析。市场篮子分析，正如你希望记得的那样，是一种算法，旨在理解交易数据中所有项目和项目组之间的关系。这些关系随后被用来帮助零售商优化店铺布局、更加准确地订货库存，并在不减少每笔交易中的商品数量的情况下调整价格。现在，我们将转向探索热点建模。
- en: 'Let''s consider an imaginary scenario: a new disease has begun spreading through
    numerous communities in the country that you live in and the government is trying
    to figure out how to confront this health emergency. Critical to any plan to confront
    this health emergency is epidemiological knowledge, including where the patients
    are located and how the disease is moving. The ability to locate and quantify
    problem areas (which are classically referred to as hotspots) can help health
    professionals, policy makers, and emergency response teams craft the most effective
    and efficient strategies for combating the disease. This scenario highlights one
    of the many applications of hotspot modeling.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个假设场景：一种新的疾病开始在你所在国家的多个社区中蔓延，政府正在努力寻找应对这一公共卫生紧急情况的方法。应对这一健康危机的关键是流行病学知识，包括患者所在的位置以及疾病的传播情况。定位和量化问题区域（通常称为热点）能够帮助卫生专业人员、政策制定者和应急响应团队制定最有效和高效的抗疫策略。这个场景突出了热点建模的众多应用之一。
- en: '**Hotspot modeling** is an approach that is used to identify how a population
    is distributed across a geographical area; for example, how the population of
    individuals infected with the previously mentioned disease is spread across the
    country. The creation of this distribution relies on the availability of representative
    sample data. Note that the population can be anything definable in geographical
    terms, which includes, but is not limited to, crime, disease-infected individuals,
    people with certain demographic characteristics, or hurricanes:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**热点建模**是一种用于识别一个群体在地理区域分布情况的方法；例如，如何将之前提到的疾病感染者的群体分布在全国各地。创建这种分布依赖于代表性样本数据的可用性。请注意，群体可以是任何在地理学上可定义的事物，包括但不限于犯罪、感染疾病的个体、具有某些人口特征的人群或飓风等：'
- en: '![Figure 9.1: A fabricated example of fire location data showing some potential
    hotspots'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.1：一个虚构的火灾位置数据示例，展示了一些潜在的热点区域'
- en: '](img/B15923_09_01.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15923_09_01.jpg)'
- en: 'Figure 9.1: A fabricated example of fire location data showing some potential
    hotspots'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1：一个虚构的火灾位置数据示例，展示了一些潜在的热点区域
- en: Hotspot analysis is incredibly popular, and this is mainly because of how easy
    it is to visualize and interpret the results. Newspapers, websites, blogs, and
    TV shows all leverage hotspot analysis to support the arguments, chapters, and
    topics included in or on them. While it might not be as well-known as the most
    popular machine learning models, the main hotspot analysis algorithm, known as
    **kernel density estimation**, is arguably one of the most widely used analytical
    techniques. People even perform kernel density estimation mentally on a daily
    basis without knowing it. Kernel density estimation is a hotspot analysis technique
    that is used to estimate the true population distribution of specific geographical
    events. Before getting into the algorithm itself, we need to briefly review spatial
    statistics and probability density functions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 热点分析非常流行，这主要是因为它在可视化和解释结果方面非常容易。报纸、网站、博客和电视节目都利用热点分析来支持其中的论点、章节和话题。尽管它可能不像最流行的机器学习模型那样广为人知，但主要的热点分析算法，即**核密度估计**，无疑是最广泛使用的分析技术之一。人们甚至在日常生活中不自觉地进行核密度估计。核密度估计是一种热点分析技术，用于估计特定地理事件的真实人口分布。在深入了解算法本身之前，我们需要简要回顾一下空间统计学和概率密度函数。
- en: Spatial Statistics
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 空间统计学
- en: '**Spatial statistics** is the branch of statistics that focuses on the analysis
    of data that has spatial properties, including geographic or topological coordinates.
    It is similar to time series analysis in that the goal is to analyze data that
    changes across some dimension. In the case of time series analysis, the dimension
    across which the data changes is time, whereas in the spatial statistics case,
    the data changes across the spatial dimension. There are a number of techniques
    that are included under the spatial statistics umbrella, but the technique we
    are concerned with here is kernel density estimation. As is the goal of most statistical
    analyses, in spatial statistics, we are trying to take samples of geographic data
    and use them to generate insights and make predictions. The analysis of earthquakes
    is one arena in which spatial statistical analyses are commonly deployed. By collecting
    earthquake location data, maps that identify areas of high and low earthquake
    likelihood can be generated, which can help scientists determine both where future
    earthquakes are likely to occur and what to expect in terms of intensity.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**空间统计学**是统计学的一个分支，专注于分析具有空间属性的数据，包括地理或拓扑坐标。它与时间序列分析类似，目标是分析在某个维度上变化的数据。在时间序列分析中，数据变化的维度是时间，而在空间统计学中，数据则在空间维度上发生变化。空间统计学涵盖了多种技术，其中我们这里关注的技术是核密度估计。与大多数统计分析的目标相同，在空间统计学中，我们试图通过采集地理数据样本来生成洞察并做出预测。地震分析是空间统计分析常用的一个领域。通过收集地震位置数据，可以生成显示高低地震概率区域的地图，这可以帮助科学家确定未来地震可能发生的地点以及地震强度的预期。'
- en: Probability Density Functions
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概率密度函数
- en: Kernel density estimation uses the idea of the **Probability Density Function**
    (**PDF**), which is one of the foundational concepts in statistics. The probability
    density function is a function that describes the behavior of a continuous **random
    variable**. That is, it expresses the likelihood, or probability, that the random
    variable takes on some range of values. Consider the heights of males in the United
    States as an example. Using the probability density function of the heights of
    males in the United States, we could calculate the probability that some United
    States-based male is between 1.9 and 1.95 meters tall.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 核密度估计采用了**概率密度函数**（**PDF**）的思想，这是统计学中的基本概念之一。概率密度函数是描述连续**随机变量**行为的函数。也就是说，它表达了随机变量取某个范围内值的可能性或概率。以美国男性身高为例，利用美国男性身高的概率密度函数，我们可以计算出某位美国男性身高在1.9米到1.95米之间的概率。
- en: '![Figure 9.2: The standard normal distribution'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.2：标准正态分布'
- en: '](img/B15923_09_02.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15923_09_02.jpg)'
- en: 'Figure 9.2: The standard normal distribution'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2：标准正态分布
- en: Possibly the most popular density function in statistics is the standard normal
    distribution, which is simply the normal distribution centered at zero with a
    standard deviation equal to one.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学中最常见的密度函数可能是标准正态分布，它就是以零为中心，标准差为一的正态分布。
- en: Instead of the density function, what is typically available to statisticians
    or data scientists are randomly collected sample values coming from a population
    distribution that is unknown. This is where kernel density estimation comes in;
    it is a technique that is used for estimating the unknown probability density
    function of a random variable using sample data. The following figure represents
    a simple, but somewhat more reasonable example of a distribution that we would
    want to estimate with kernel density estimation. We would take some number of
    observations (sample data points) and use those observations to create a smooth
    distribution that mimics the true underlying distribution that is unknown to us.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与密度函数不同，统计学家或数据科学家通常获得的是来自未知总体分布的随机收集的样本值。这时，核密度估计就派上了用场；它是一种利用样本数据估计随机变量未知概率密度函数的技术。下图表示了一个简单但更合理的分布示例，这是我们希望通过核密度估计来估计的分布。我们会选择一些观察值（样本数据点），并使用这些观察值来创建一个平滑的分布，模拟我们无法知晓的真实底层分布。
- en: '![Figure 9.3: A mixture of three normal distributions'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.3：三种正态分布的混合'
- en: '](img/B15923_09_03.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15923_09_03.jpg)'
- en: 'Figure 9.3: A mixture of three normal distributions'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3：三种正态分布的混合
- en: Using Hotspot Analysis in Business
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在商业中使用热点分析
- en: We have already mentioned some of the ways in which hotspot modeling can be
    leveraged to meaningfully impact industry. When reporting on infectious diseases,
    health organizations and media companies typically use hotspot analysis to communicate
    where the diseases are located and the likelihood of contracting the disease based
    on geographic location. Using hotspot analysis, this information could be reliably
    computed and disseminated. Hotspot analysis is great for dealing with health data
    because the visualizations are very straightforward. This means that the chances
    of data being misinterpreted either intentionally or unintentionally are relatively
    low.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提到了一些热点建模可以有效影响行业的方法。在报告传染病时，卫生组织和媒体公司通常会使用热点分析来传达疾病的地理分布和根据地理位置感染该疾病的可能性。通过使用热点分析，这些信息可以可靠地计算和传播。热点分析非常适用于处理健康数据，因为可视化非常直观。这意味着数据被故意或无意误解的可能性相对较低。
- en: Hotspot analysis can also be used to predict where certain events are likely
    to occur geographically. One research area that is leveraging the predictive capabilities
    of hotspot analysis more and more are the environmental sciences, which includes
    the study of natural disasters and extreme weather events. Earthquakes, for example,
    are notorious for being difficult to predict, because the time between significant
    earthquakes can be large, and the machinery needed to track and measure earthquakes
    to the degree required to make these predictions is relatively new.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 热点分析也可以用来预测某些事件可能发生的地理位置。越来越多的研究领域正在利用热点分析的预测能力，其中包括自然灾害和极端天气事件的研究。以地震为例，由于重大地震之间的时间间隔可能很长，而且需要跟踪和测量地震的设备相对较新，因此地震预测一直以难度大著称。
- en: In terms of public policy and resource deployment, hotspot analysis can be very
    impactful when dealing with the analysis of population demographics. Determining
    where resources, both monetary and personnel, should be deployed can be challenging;
    however, given that resources are often demographic-specific, hotspot analysis
    is a useful technique since it can be used to determine the distribution of certain
    demographic characteristics. By demographic characteristics we mean that we could
    find the geographic distribution of high school graduates, immigrants from a specific
    global region, or individuals making $100,000 or more annually.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在公共政策和资源部署方面，热点分析在处理人口统计学分析时非常有影响力。确定资源（包括金钱和人员）应该部署到哪里可能是具有挑战性的；然而，鉴于资源通常是人口特定的，热点分析是一种有用的技术，因为它可以用来确定特定人口特征的分布。我们所说的人口特征是指我们可以找到高中毕业生、来自特定全球地区的移民，或者年收入达到或超过$100,000的人的地理分布。
- en: The number of applications of hotspot modeling are virtually endless. We have
    here only discussed three of the major ones.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 热点建模的应用几乎是无穷无尽的。我们这里只讨论了其中的三种主要应用。
- en: Kernel Density Estimation
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 核密度估计
- en: One of the main methodological approaches to hotspot analysis is kernel density
    estimation. Kernel density estimation builds an estimated density using sample
    data and two parameters known as the **kernel function** and the **bandwidth value**.
    The estimated density is, like any distribution, essentially a guideline for the
    behavior of a random variable. Here, we mean how frequently the random variable
    takes on any specific value, {x1, ….., xn}. When dealing with hotspot analysis
    where the data is typically geographic, the estimated density answers the question
    *How frequently do specific longitude and latitude pairs appear for a given event?*
    If a specific longitude and latitude pair {xlongitude, xlatitude} and other nearby
    pairs occur with high frequency, then the estimated density built using the sample
    data will show that the area around the aforementioned longitude and latitude
    pair occurs with high likelihood.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 热点分析的主要方法之一是核密度估计。核密度估计通过样本数据和两个参数（即**核函数**和**带宽值**）构建估计的密度。估计的密度像任何分布一样，本质上是随机变量行为的指导。这里的意思是，随机变量在任何特定值{x1,
    ….., xn}上出现的频率。在处理通常是地理数据的热点分析时，估计的密度回答了这个问题：*给定事件的特定经纬度对出现的频率如何？* 如果某个特定经纬度对{xlongitude,
    xlatitude}以及附近的其他经纬度对出现的频率很高，那么使用样本数据构建的估计密度将显示出上述经纬度对周围区域的出现概率较高。
- en: Kernel density estimation is referred to as a smoothing algorithm because a
    smooth curve is drawn over the sample data, which, if the data is a representative
    sample, can be a good estimate of the true population density function. Stated
    another way, when it is done correctly, kernel density estimation aims to remove
    the noise that is inherent in sampled data, but is not a feature of the total
    population. The only assumption of the model is that the data truly belongs to
    some interpretable and meaningful density from which insights can be derived and
    acted upon. That is, there exists a true underlying distribution. We assume that
    the sample data contains clusters of data points and that these clusters align
    to regions of high likelihood in the true population. A benefit of creating a
    quality estimate of the true population density is that the estimated density
    can then be used to sample more data from the population.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 核密度估计被称为一种平滑算法，因为它在样本数据上绘制了一条平滑曲线。如果数据是一个具有代表性的样本，这条曲线可以很好地估计真实的总体密度函数。换句话说，当核密度估计方法正确应用时，它旨在去除样本数据中固有的噪声，而这些噪声并不是总体特征。该模型的唯一假设是数据确实属于某种可解释且有意义的密度，从中可以获得见解并付诸实践。也就是说，存在一个真实的潜在分布。我们假设样本数据中包含数据点簇，这些簇与真实总体中的高概率区域对齐。创建真实总体密度的高质量估计的一个好处是，估计的密度可以用于从总体中采样更多的数据。
- en: 'Following this brief introduction, you probably have the following two questions:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一简短的介绍之后，您可能会有以下两个问题：
- en: What is the bandwidth value?
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是带宽值？
- en: What is the kernel function?
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是核函数？
- en: We answer both of these questions next.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将回答这两个问题。
- en: The Bandwidth Value
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带宽值
- en: The most crucial parameter in kernel density estimation is called the **bandwidth
    value** and its impact on the quality of the estimate cannot be overestimated.
    A high-level definition of the bandwidth value is that it is a value that determines
    the degree of smoothing. If the bandwidth value is low, then the estimated density
    will feature limited smoothing, which means that the density will capture all
    the noise in the sample data. If the bandwidth value is high, then the estimated
    density will be very smooth. An overly smooth density will remove characteristics
    of the true density from the estimated density, which are legitimate and not noise.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 核密度估计中最关键的参数被称为**带宽值**，它对估计质量的影响不容小觑。带宽值的高阶定义是它决定了平滑的程度。如果带宽值较低，则估计的密度会呈现有限的平滑，这意味着密度将捕捉到样本数据中的所有噪声。如果带宽值较高，则估计的密度将非常平滑。过于平滑的密度会去除估计密度中的真实密度特征，而这些特征是合法的，而不是噪声。
- en: In more statistical parlance, the bandwidth parameter controls the bias-variance
    trade-off. That is, high variance is the result of low bandwidth values because
    the density is sensitive to the variance of the sample data. Low bandwidth values
    limit any ability the model may have had to adapt to and work around gaps in the
    sample data that are not present in the population. A density estimated using
    a low bandwidth value will tend to overfit the data (this is also known as an
    under-smoothed density). When high bandwidth values are used, then the resulting
    density is underfit and the estimated density has a high bias (this is also known
    as an over-smoothed density).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 用更统计学的术语来说，带宽参数控制着偏差-方差的权衡。也就是说，低带宽值会导致高方差，因为密度对样本数据的方差非常敏感。低带宽值会限制模型适应和解决样本数据中不存在于总体中的空隙的能力。使用低带宽值估计的密度往往会过度拟合数据（这也称为欠平滑的密度）。当使用高带宽值时，结果密度会发生欠拟合，估计密度的偏差较大（这也称为过度平滑的密度）。
- en: Note
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'In all the subsequent exercises and activities, the output could vary slightly
    from what is shown below. This is because of the following: differences in sampled
    data can lead to slightly different output and the `sklearn` and `seaborn` libraries
    have some non-deterministic elements that could cause the results to change from
    run to run.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有随后的练习和活动中，输出可能会略有不同于下文所示的结果。原因如下：数据样本的差异可能会导致输出略有不同，而且`sklearn`和`seaborn`库中有一些非确定性元素，可能导致结果在每次运行时有所不同。
- en: 'Exercise 9.01: The Effect of the Bandwidth Value'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 9.01：带宽值的影响
- en: 'In this exercise, we will fit nine different models with nine different bandwidth
    values to sample data created in the exercise. The goal here is to solidify our
    understanding of the impact the bandwidth parameter can have and make clear that
    if an accurate estimated density is sought, then the bandwidth value needs to
    be selected with care. Note that finding an optimal bandwidth value will be the
    topic of the next section. All exercises will be done in a Jupyter notebook utilizing
    Python 3; ensure that all package installation is done using `pip`. The easiest
    way to install the `basemap` module from `mpl_toolkits` is by using *Anaconda*.
    Instructions for downloading and installing *Anaconda* can be found at the beginning
    of this book:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用九个不同的带宽值拟合九个不同的模型，来处理本练习中创建的样本数据。此处的目标是巩固我们对带宽参数影响的理解，并明确指出，如果要得到准确的估计密度，带宽值需要谨慎选择。请注意，寻找最佳带宽值将是下一节的主题。所有练习都将在使用Python
    3的Jupyter笔记本中完成；请确保通过`pip`安装所有必要的包。安装`mpl_toolkits`中的`basemap`模块最简单的方法是使用*Anaconda*。有关下载和安装*Anaconda*的说明，请参见本书开头：
- en: Load all of the libraries that are needed for the exercises in this chapter.
    The `basemap` library is used to create graphics involving location data. All
    the other libraries have been used previously in this title.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载本章所需的所有库。`basemap`库用于创建涉及位置数据的图形。其他所有库都在本书的前面部分使用过。
- en: '[PRE0]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create some sample data (`vals`) by mixing three normal distributions. In addition
    to the sample data, define the true density curve (`true_density`) and the range
    over which the data will be plotted (`x_vec`):'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过混合三个正态分布来创建一些样本数据（`vals`）。除了样本数据外，还需要定义真实的密度曲线（`true_density`）和数据将被绘制的范围（`x_vec`）：
- en: '[PRE1]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Define a list of tuples that will guide the creation of the multiplot graphic.
    Each tuple contains the row and column indices of the specific subplot, and the
    bandwidth value used to create the estimated density in that particular subplot.
    Note that, for the sake of this exercise, the bandwidth values are picked randomly,
    but there is some strategy that goes into picking optimal bandwidth values. We
    will dig more into this in the next section.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个元组列表，用于指导多图形的创建。每个元组包含特定子图的行和列索引，以及用于在该子图中创建估计密度的带宽值。请注意，为了本练习的方便，带宽值是随机选择的，但实际上选择最佳带宽值是有一定策略的。我们将在下一节深入探讨这一点。
- en: '[PRE2]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create nine plots each using a different bandwidth value. The first plot, with
    the index of (0, 0), will have the lowest bandwidth value and the last plot, with
    the index of (2, 2), will have the highest. These values are not the absolute
    lowest or absolute highest bandwidth values, rather they are only the minimum
    and maximum of the list defined in the previous step:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建九个图，每个图使用不同的带宽值。第一个图（索引为(0, 0)）将使用最低的带宽值，最后一个图（索引为(2, 2)）将使用最高的带宽值。这些值不是绝对的最小或最大带宽值，而只是前一步骤中定义的列表中的最小值和最大值：
- en: '[PRE3]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output is as follows:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.4: A 3 x 3 matrix of subplots'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.4：一个3 x 3矩阵的子图'
- en: '](img/B15923_09_04.jpg)'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_04.jpg)'
- en: 'Figure 9.4: A 3 x 3 matrix of subplots'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4：一个3 x 3矩阵的子图
- en: Notice that the estimated density curve in the ninth subplot (where the bandwidth
    is 5) clearly underfits the data. As the bandwidth values increase, the estimated
    density becomes smoother until it noticeably underfits the data. Visually, it
    looks like the optimal bandwidth may be around `1.6`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在第九个子图中（带宽为5的地方），估计的密度曲线明显不足以拟合数据。随着带宽值的增加，估计的密度变得更加平滑，直到它明显不足以拟合数据。从视觉效果来看，最优带宽值可能约为`1.6`。
- en: Note
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该特定部分的源代码，请参考 [https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ)。
- en: You can also run this example online at [https://packt.live/38DbmTo](https://packt.live/38DbmTo).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在网上运行此示例，网址为 [https://packt.live/38DbmTo](https://packt.live/38DbmTo)。
- en: You must execute the entire Notebook in order to get the desired result.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须执行整个Notebook才能获得预期的结果。
- en: The next step is to design an algorithm to identify the optimal bandwidth value,
    so that the estimated density is the most reasonable and, therefore, the most
    reliable and actionable.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是设计一个算法来识别最优带宽值，以使估计的密度最合理，从而是最可靠且可操作的。
- en: Selecting the Optimal Bandwidth
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择最优带宽
- en: As mentioned in the preceding exercise, we can come quite close to selecting
    the optimal bandwidth by simply comparing several densities visually. However,
    this is neither the most efficient method of selecting parameter values nor the
    most reliable.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面练习中提到的，我们可以通过简单地通过视觉比较几种密度来接近选择最优带宽。然而，这既不是选择参数值的最有效方法，也不是最可靠的方法。
- en: There are two standard approaches to optimizing the bandwidth value, and both
    of these will appear in future exercises and activities. The first approach is
    a plug-in method (or a formulaic approach) that is deterministic and not optimized
    on the sample data. Plug-in methods are generally much faster to implement, simpler
    to code, and easier to explain. However, these methods have one big downside,
    which is that their accuracy tends to suffer compared to approaches that are optimized
    on the sample data. These methods also have distributional assumptions. The most
    popular plug-in methods are Silverman's Rule and Scott's Rule. Explaining these
    rules in detail is beyond the scope of this text, not necessary for fully understanding
    kernel density estimation, and would require some tricky mathematical work, so
    we will skip any further exploration here. That being said, if interested, there
    are a number of great sources publicly available that explain these rules at various
    levels of detail. By default, the `seaborn` package (which will be used in future
    exercises) uses Scott's Rule as the method to determine the bandwidth value.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 优化带宽值有两种标准方法，这两种方法都会出现在未来的练习和活动中。第一种方法是插件法（或公式化方法），它是确定性的，并且没有在样本数据上进行优化。插件法通常实现速度更快，编码更简单，解释也更容易。然而，这些方法有一个大缺点，那就是与在样本数据上进行优化的方法相比，它们的准确性往往较低。这些方法还存在分布假设。最流行的插件方法是Silverman法则和Scott法则。详细解释这些法则超出了本文的范围，并且对于完全理解核密度估计并非必需，且需要一些复杂的数学工作，因此我们将跳过进一步的探讨。不过，如果有兴趣，公开的许多优秀资源都详细解释了这些法则，并且有不同深度的说明。默认情况下，`seaborn`包（将在未来的练习中使用）使用Scott法则作为确定带宽值的方法。
- en: The second, and arguably the more robust, approach to finding an optimal bandwidth
    value is by searching a predefined grid of bandwidth values. Grid search is an
    empirical approach that is used frequently in machine learning and predictive
    modeling to optimize model hyperparameters. The process starts by defining the
    bandwidth grid, which is simply the collection of bandwidth values to be evaluated.
    The bandwidth grid is chosen at random. Use each bandwidth value in the grid to
    create an estimated density; then, score the estimated density using the pseudo-log-likelihood
    value. The optimal bandwidth value is that which has the maximum pseudo-log-likelihood
    value. Think of the pseudo-log-likelihood value as the probability of getting
    data points where we got data points and the probability of not getting points
    where we did not get any data points. Ideally, both of these probabilities would
    be large. Consider the case where the probability of getting data points where
    we did get points is low. In this situation, the implication would be that the
    data points in the sample were anomalous because, under the true distribution,
    getting points where we did would not be expected with a high likelihood value.
    The pseudo-log-likelihood value is an evaluation metric that plays the same role
    as the accuracy score in classification problems and root mean squared error in
    regression problems.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找最优带宽值的第二种方法，也是更强健的方法，是通过搜索一个预定义的带宽值网格。网格搜索是一种经验性方法，在机器学习和预测建模中经常用来优化模型的超参数。该过程从定义带宽网格开始，带宽网格就是要评估的一系列带宽值。带宽网格是随机选择的。使用网格中的每个带宽值来创建估计密度；然后，使用伪对数似然值来评分估计密度。最优带宽值是具有最大伪对数似然值的那个带宽值。可以把伪对数似然值看作是获得数据点的概率，数据点出现在我们希望的地方，而没有数据点出现的地方的概率。理想情况下，这两个概率应该都很大。考虑一种情况，即获得数据点的概率很低，这意味着样本中的数据点可能是异常的，因为在真实分布下，我们不会期望在某个地方获得数据点，且其高概率值不成立。伪对数似然值是一种评估指标，其作用与分类问题中的准确度分数和回归问题中的均方根误差相同。
- en: Let's now implement the grid search approach to optimize the bandwidth value.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们实现网格搜索方法来优化带宽值。
- en: 'Exercise 9.02: Selecting the Optimal Bandwidth Using Grid Search'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 9.02：使用网格搜索选择最优带宽
- en: In this exercise, we will create an estimated density for the sample data created
    in *Exercise 9.01*, *The Effect of the Bandwidth Value* with an optimal bandwidth
    value identified using grid search and cross-validation. To run the grid search
    with cross-validation, we will leverage `sklearn`, which we have used throughout
    this book.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将为*练习 9.01*中的样本数据创建一个估计的密度，*带宽值的影响*，并通过网格搜索和交叉验证确定一个最优带宽值。为了执行网格搜索和交叉验证，我们将使用`sklearn`，这是我们在本书中一直使用的工具。
- en: Note
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This exercise is a continuation of *Exercise 9.01*, *The Effect of the Bandwidth
    Value* as we are using the same sample data and continuing our exploration of
    the bandwidth value.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习是*练习 9.01*，*带宽值的影响*的延续，因为我们使用的是相同的样本数据，并继续探讨带宽值的影响。
- en: 'Define a grid of bandwidth values and the grid search cross-validation model.
    Ideally, the leave-one-out approach to cross-validation should be used, but for
    the sake of having the model run in a reasonable amount of time, we will do a
    10-fold cross-validation. Fit the model on the sample data, as follows:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义带宽值网格和网格搜索交叉验证模型。理想情况下，应该使用留一交叉验证方法，但为了使模型在合理的时间内运行，我们将使用10折交叉验证。将模型拟合到样本数据，如下所示：
- en: '[PRE4]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output is as follows:'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.5: Output of cross-validation model'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.5：交叉验证模型的输出'
- en: '](img/B15923_09_05.jpg)'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_05.jpg)'
- en: 'Figure 9.5: Output of cross-validation model'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.5：交叉验证模型的输出
- en: Extract the optimal bandwidth value from the model. The `best_params_` function
    extracts from the model object the best performing parameters in the grid.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从模型中提取最优带宽值。`best_params_`函数从模型对象中提取网格中表现最好的参数。
- en: '[PRE5]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The optimal bandwidth value should be approximately `1.6`. We can interpret
    the optimal bandwidth value as the bandwidth value producing the maximum pseudo-log-likelihood
    value. Note that depending on the values included in the grid, the optimal bandwidth
    value can change.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最优带宽值应大约为`1.6`。我们可以将最优带宽值解释为产生最大伪对数似然值的带宽值。请注意，根据网格中包含的值，最优带宽值可能会发生变化。
- en: 'Plot the histogram of the sample data overlaid by both the true and estimated
    densities. In this case, the estimated density will be the optimal estimated density:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制样本数据的直方图，并叠加真实密度和估计密度。在这种情况下，估计的密度将是最佳估计密度：
- en: '[PRE6]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is as follows:'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.6: A histogram of the random sample'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.6：随机样本的直方图](img/B15923_09_06.jpg)'
- en: '](img/B15923_09_06.jpg)'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_06.jpg)'
- en: 'Figure 9.6: A histogram of the random sample'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.6：随机样本的直方图
- en: In this histogram, the true density and the optimal estimated density are overlaid.
    The estimated density is neither overfit or underfit to any noticeable degree
    and it definitely captures the three clusters. Arguably, it could map to the true
    density better, but this is just an estimated density generated by a model that
    is limited by the dataset provided.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这张直方图中，真实密度和最佳估计密度重叠显示。估计密度没有明显的过拟合或欠拟合，且能够很好地捕捉到三个聚类。可以说，它可能更好地贴合真实密度，但这仅仅是由模型根据给定的数据集生成的估计密度。
- en: Note
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 若要访问此特定部分的源代码，请参考 [https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ)。
- en: You can also run this example online at [https://packt.live/38DbmTo](https://packt.live/38DbmTo).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在线运行这个示例，地址是 [https://packt.live/38DbmTo](https://packt.live/38DbmTo)。
- en: You must execute the entire Notebook in order to get the desired result.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须执行整个 Notebook 才能得到预期的结果。
- en: 'Let''s now move onto the second question: what is the kernel function and what
    role does it play?'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们进入第二个问题：什么是核函数，它在其中扮演什么角色？
- en: Kernel Functions
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核函数
- en: The other parameter to be set is the kernel function. The kernel is a non-negative
    function that controls the shape of the density. Like topic models, we are working
    in a non-negative environment because it does not make sense to have negative
    likelihoods or probabilities. The kernel function controls the shape of the estimated
    density by weighting the points in a systematic way. This systematic methodology
    for weighting is fairly simple; data points that are in close proximity to many
    other data points are up-weighted, whereas data points that are alone or far away
    from any other data points are down-weighted. Up-weighted data points will correspond
    to points of higher likelihood in the final estimated density.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要设置的参数是核函数。核函数是一个非负函数，它控制密度的形状。像主题模型一样，我们在一个非负环境中工作，因为出现负的似然性或概率是没有意义的。核函数通过以系统的方式加权数据点来控制估计密度的形状。这种加权的系统方法相对简单；与许多其他数据点接近的数据点会被加权，而那些孤立或远离其他数据点的数据点会被减权。被加权的数据点在最终估计的密度中将对应于较高的似然点。
- en: 'Many functions can be used as kernels, but six frequent choices are Gaussian,
    Tophat, Epanechnikov, Exponential, Linear, and Cosine. Each of these functions
    represents a unique distributional shape. Note that in each of the formulas the
    parameter, *h*, represents the bandwidth value:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用许多函数作为核函数，但六种常见的选择是高斯（Gaussian）、顶帽（Tophat）、埃潘尼切科夫（Epanechnikov）、指数（Exponential）、线性（Linear）和余弦（Cosine）。这些函数各自代表了不同的分布形状。请注意，在每个公式中，参数
    *h* 代表带宽值：
- en: 'Gaussian: Each observation has a bell-shaped weight.![Figure 9.7: The formula
    for the Gaussian kernel'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高斯：每个观察值具有钟形权重。![图 9.7：高斯核函数的公式](img/B15923_09_07.jpg)
- en: '](img/B15923_09_07.jpg)'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_07.jpg)'
- en: 'Figure 9.7: The formula for the Gaussian kernel'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.7：高斯核函数的公式
- en: 'Tophat: Each observation has a rectangular-shaped weight.![Figure 9.8: The
    formula for the Tophat kernel'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶帽：每个观察值具有矩形的权重。![图 9.8：顶帽核函数的公式](img/B15923_09_08.jpg)
- en: '](img/B15923_09_08.jpg)'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_08.jpg)'
- en: 'Figure 9.8: The formula for the Tophat kernel'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.8：顶帽核函数的公式
- en: 'Epanechnikov: Each observation has a mound-shaped weight.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 埃潘尼切科夫：每个观察值具有丘状的权重。
- en: '![Figure 9.9: The formula for the Epanechnikov kernel'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.9：埃潘尼切科夫核函数的公式](img/B15923_09_11.jpg)'
- en: '](img/B15923_09_09.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15923_09_09.jpg)'
- en: 'Figure 9.9: The formula for the Epanechnikov kernel'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.9：埃潘尼切科夫核函数的公式
- en: 'Exponential: Each observation has a triangular-shaped weight. The sides of
    the triangle are concave.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指数：每个观察值具有三角形的权重，三角形的边是凹形的。
- en: '![Figure 9.10: The formula for the Exponential kernel'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.10：指数核函数的公式](img/B15923_09_10.jpg)'
- en: '](img/B15923_09_10.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15923_09_10.jpg)'
- en: 'Figure 9.10: The formula for the Exponential kernel'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.10：指数核函数的公式
- en: 'Linear: Each observation has a triangular-shaped weight.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性：每个观察值具有三角形的权重。
- en: '![Figure 9.11: The formula for the Linear kernel'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.11：线性核函数的公式](img/B15923_09_09.jpg)'
- en: '](img/B15923_09_11.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15923_09_11.jpg)'
- en: 'Figure 9.11: The formula for the Linear kernel'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.11：线性核的公式
- en: 'Cosine: Each observation has a mound-shaped weight. This mound-shape is narrower
    at the top than the Epanechnikov kernel.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 余弦核：每个观测值都有一个圆顶形的权重。这个圆顶形比埃潘尼科夫核在顶部更窄。
- en: '![Figure 9.12: The formula for the Cosine kernel'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.12：余弦核的公式'
- en: '](img/B15923_09_12.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15923_09_12.jpg)'
- en: 'Figure 9.12: The formula for the Cosine kernel'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.12：余弦核的公式
- en: 'Here are the distributional shapes of the six kernel functions:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是六个核函数的分布形状：
- en: '![Figure 9.13: The general shapes of the six kernel functions'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.13：六个核函数的整体形状'
- en: '](img/B15923_09_13.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15923_09_13.jpg)'
- en: 'Figure 9.13: The general shapes of the six kernel functions'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.13：六个核函数的整体形状
- en: The choice of kernel function is not completely insignificant, but it is definitely
    not nearly as important as the choice of bandwidth value. A reasonable course
    of action would be to use the gaussian kernel for all density estimation problems,
    which is what we will do in the following exercises and activities.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 核函数的选择并非完全无关紧要，但它肯定不像带宽值的选择那么重要。一个合理的做法是，对于所有密度估计问题，都使用高斯核，这也是我们在接下来的练习和活动中所做的。
- en: 'Exercise 9.03: The Effect of the Kernel Function'
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 9.03：核函数的影响
- en: We will demonstrate how the choice of kernel function affects the quality of
    the density estimate. Like we did when exploring the bandwidth value effect, we
    will hold all other parameters constant, use the same data generated in the first
    two exercises, and run six different kernel density estimation models using the
    six kernel functions previously specified. Clear differences should be noticeable
    between the six estimated densities, but these differences should be slightly
    less dramatic than the differences between the densities estimated using the different
    bandwidth values. Note that this exercise should be executed in the same notebook
    as the previous exercises.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示核函数的选择如何影响密度估计的质量。就像我们在探索带宽值效应时做的那样，我们将保持其他所有参数不变，使用在前两次练习中生成的相同数据，并使用之前指定的六个核函数运行六个不同的核密度估计模型。六个估计的密度之间应该能看到明显的差异，但这些差异应该比使用不同带宽值估计的密度之间的差异稍微小一些。请注意，本练习应在与之前练习相同的Notebook中执行。
- en: 'Define a list of tuples along the same lines as the one defined previously.
    Each tuple includes the row and column indices of the subplot, and the kernel
    function to be used to create the density estimation:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个元组列表，格式与之前定义的相同。每个元组包含子图的行和列索引，以及用于创建密度估计的核函数：
- en: '[PRE7]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Fit and plot six kernel density estimation models using a different kernel
    function for each. To truly understand the differences between the kernel functions,
    we will set the bandwidth value to the optimal bandwidth value found in *Exercise
    9.02*, *Selecting the Optimal Bandwidth Using Grid Search* and not adjust it:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用不同的核函数拟合并绘制六个核密度估计模型。为了真正理解核函数之间的差异，我们将带宽值设置为在*练习 9.02*中找到的最优带宽值，即*使用网格搜索选择最优带宽*，并且不调整它：
- en: '[PRE8]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output is as follows:'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.14: A 3 x 2 matrix of subplots'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.14：一个 3 x 2 的子图矩阵'
- en: '](img/B15923_09_14.jpg)'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_14.jpg)'
- en: 'Figure 9.14: A 3 x 2 matrix of subplots'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.14：一个 3 x 2 的子图矩阵
- en: Out of the six kernel functions, the gaussian kernel produced the most reasonable
    estimated density. Beyond that, notice that the difference between the estimated
    densities with different kernels is less than the difference between the estimated
    densities with different bandwidth values. This goes to the previously made claim
    that the bandwidth value is the more important parameter and should be the focus
    during the model building process.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在六个核函数中，高斯核生成了最合理的估计密度。除此之外，注意到不同核函数估计的密度之间的差异小于不同带宽值估计的密度之间的差异。这印证了之前的观点，即带宽值是更重要的参数，应在模型构建过程中作为重点。
- en: Note
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ)。
- en: You can also run this example online at [https://packt.live/38DbmTo](https://packt.live/38DbmTo).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/38DbmTo](https://packt.live/38DbmTo)在线运行此示例。
- en: You must execute the entire Notebook in order to get the desired result.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 必须执行整个Notebook才能获得所需的结果。
- en: With our understanding mostly formed, let's discuss the derivation of kernel
    density estimation at a high-level.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们大致理解的基础上，让我们讨论核密度估计的推导过程。
- en: Kernel Density Estimation Derivation
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核密度估计推导
- en: Let's skip the formal mathematical derivation in favor of the popular derivation
    by intuition. Kernel density estimation turns each data point in the sample into
    its own distribution whose width is controlled by the bandwidth value. The individual
    distributions are then summed to create the desired density estimate. This concept
    is fairly easy to demonstrate; however, before doing that in the next exercise,
    let's try to think through it in an abstract way. For geographic regions containing
    many sample data points, the individual densities will overlap and, through the
    process of summing those densities, will create points of higher likelihood in
    the estimated density. Similarly, for geographic regions containing few to no
    sample data points, the individual densities will not overlap and, therefore,
    will correspond to points of lower likelihood in the estimated density.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们跳过正式的数学推导，转而采用直观的流行推导方法。核密度估计将每个样本数据点转化为其自身的分布，其宽度由带宽值控制。然后，将这些个体分布相加，生成所需的密度估计。这一概念相对容易展示；然而，在接下来的练习中，我们在进行演示之前，先尝试从抽象的角度进行思考。对于包含许多样本数据点的地理区域，个体密度将会重叠，并通过相加这些密度，产生在估计密度中更高的可能性点。类似地，对于包含少量或没有样本数据点的地理区域，个体密度将不会重叠，因此在估计密度中会对应较低的可能性点。
- en: 'Exercise 9.04: Simulating the Derivation of Kernel Density Estimation'
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习9.04：模拟核密度估计的推导
- en: The goal here is to demonstrate the concept of summing individual distributions
    to create an overall estimated density for a random variable. We will establish
    the concept incrementally by starting with one sample data point and then work
    up too many sample data points. Additionally, different bandwidth values will
    be applied, so our understanding of the effect of the bandwidth value on these
    individual densities will further solidify. Note that this exercise should be
    done in the same notebook as all the other exercises.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目标是展示将个体分布相加，创建随机变量的整体估计密度的概念。我们将通过从一个样本数据点开始，逐步建立这一概念，并逐渐增加样本数据点的数量。此外，还会应用不同的带宽值，因此我们对带宽值对这些个体密度影响的理解将进一步巩固。请注意，本练习应与所有其他练习一起在同一个笔记本中完成。
- en: 'D Hotspot Analysis efine a function that will evaluate the normal distribution.
    The input values are the grid representing the range of the random variable, `X`,
    the sampled data point, `m`, and the bandwidth, `b`:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: D 热点分析定义一个函数，用于评估正态分布。输入值包括表示随机变量`X`范围的网格、采样数据点`m`和带宽`b`：
- en: '[PRE9]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Plot a single sample data point as a histogram and as an individual density
    with varying bandwidth values:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将一个样本数据点绘制为直方图，并显示其在不同带宽值下的个体密度：
- en: '[PRE10]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output is as follows:'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.15: Showing one data point and its individual density at various
    bandwidth values'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.15：显示一个数据点及其在不同带宽值下的个体密度'
- en: '](img/B15923_09_15.jpg)'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_15.jpg)'
- en: 'Figure 9.15: Showing one data point and its individual density at various bandwidth
    values'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.15：显示一个数据点及其在不同带宽值下的个体密度
- en: Here, we see what has already been established, which is that lower bandwidth
    values produce very narrow densities that tend to overfit the data.
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到已经建立的结论：较低的带宽值会产生非常狭窄的密度，往往会导致过拟合数据。
- en: 'Reproduce the work done in *Step 2*, but now scale up to 16 data points:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复执行*步骤2*中的工作，但这次将数据点规模扩展到16个：
- en: '[PRE11]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.16: Plotting the data points'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.16：绘制数据点'
- en: '](img/B15923_09_16.jpg)'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_16.jpg)'
- en: 'Figure 9.16: Plotting the data points'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.16：绘制数据点
- en: The preceding image shows 16 data points, their individual densities at various
    bandwidth values, and the sum of their individual densities.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图像展示了16个数据点，它们在不同带宽值下的个体密度，以及它们个体密度的总和。
- en: Again, unsurprisingly, the plot utilizing the smallest bandwidth value features
    a wildly overfit estimated density. That is, the estimated density captures all
    the noise in the sample data. Of these three densities, the second one, where
    the bandwidth value was set to `0.35`, is the most reasonable.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，毫不意外，利用最小带宽值的图表展示了一个过度拟合的估计密度。也就是说，估计的密度捕捉了样本数据中的所有噪声。在这三种密度中，第二种密度（带宽值设置为`0.35`）是最合理的。
- en: Note
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 若要访问该特定部分的源代码，请参考[https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ)。
- en: You can also run this example online at [https://packt.live/38DbmTo](https://packt.live/38DbmTo).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/38DbmTo](https://packt.live/38DbmTo)上在线运行此示例。
- en: You must execute the entire Notebook in order to get the desired result.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须执行整个Notebook才能获得所需的结果。
- en: 'Activity 9.01: Estimating Density in One Dimension'
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 9.01：在一维中估计密度
- en: In this activity, we will be generating some fake sample data and estimating
    the density function using kernel density estimation. The bandwidth value will
    be optimized using grid search cross-validation. The goal is to solidify our understanding
    of this useful methodology by running the model in a simple one-dimensional case.
    We will once again leverage Jupyter notebooks to do our work.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，我们将生成一些伪造的样本数据，并使用核密度估计估算密度函数。带宽值将通过网格搜索交叉验证进行优化。目标是通过在简单的一维情况下运行模型来巩固我们对这种有用方法的理解。我们将再次利用Jupyter笔记本来完成工作。
- en: Imagine that the sample data we will be creating describes the price of homes
    in a state in the United States. Momentarily ignore the values in the following
    sample data. The question is, *what does the distribution of home prices look
    like, and can we extract the probability of a house having a price that falls
    in some specific range?* These questions and more are answerable using kernel
    density estimation.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们将创建的样本数据描述的是美国某州的房屋价格。暂时忽略以下样本数据中的数值。问题是，*房价的分布是什么样的？我们能否提取出某个特定价格区间内房屋的概率？*
    这些问题以及更多问题可以通过核密度估计来解答。
- en: 'Here are the steps to complete the activity:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是完成活动的步骤：
- en: Open a new notebook and install all the necessary libraries.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的笔记本并安装所有必要的库。
- en: Sample 1,000 data points from the standard normal distribution. Add 3.5 to each
    of the last 625 values of the sample (that is, the indices between 375 and 1,000).
    Set a random state of 100 using `numpy.random.RandomState` to guarantee the same
    sampled values, and then randomly generate the data points using the `rand.randn(1000)`
    call.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从标准正态分布中抽取1,000个数据点。在样本的最后625个值上加上3.5（即索引在375到1,000之间）。使用`numpy.random.RandomState`设置随机状态为100，以保证相同的样本值，然后使用`rand.randn(1000)`调用随机生成数据点。
- en: Plot the 1,000-point sample data as a histogram and add a scatterplot below
    it.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将1,000个数据点样本数据绘制为直方图，并在其下方添加散点图。
- en: Define a grid of bandwidth values. Then, define and fit a grid search cross-validation
    algorithm.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个带宽值网格。然后，定义并拟合一个网格搜索交叉验证算法。
- en: Extract the optimal bandwidth value.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取最佳带宽值。
- en: Replot the histogram from *Step 3* and overlay the estimated density.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从*步骤 3*重新绘制直方图并叠加估计的密度。
- en: 'The output will be as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 9.17: A histogram of the random sample with the optimal estimated
    density overlaid'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.17：叠加最佳估计密度的随机样本直方图'
- en: '](img/B15923_09_17.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15923_09_17.jpg)'
- en: 'Figure 9.17: A histogram of the random sample with the optimal estimated density
    overlaid'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.17：叠加最佳估计密度的随机样本直方图
- en: Note
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: The solution for this activity can be found on page 501.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第501页找到。
- en: Hotspot Analysis
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 热点分析
- en: To start, hotspots are areas of higher concentrations of data points, such as
    particular neighborhoods where the crime rate is abnormally high or swaths of
    the country that are impacted by an above-average number of tornadoes. Hotspot
    analysis is the process of finding these hotspots, should any exist, in a population
    using sampled data. This process is generally done by leveraging kernel density
    estimation.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 一开始，热点是数据点高度集中的区域，例如犯罪率异常高的特定社区，或受异常数量的龙卷风影响的国家大片区域。热点分析是通过抽样数据，在一个人群中寻找这些可能存在的热点。这个过程通常通过利用核密度估计来完成。
- en: 'Hotspot analysis can be described in four high-level steps:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 热点分析可以分为四个高层次的步骤：
- en: '**Collect the data**: The data should include the locations of the objects
    or events. As we have briefly mentioned, the amount of data needed to run and
    achieve actionable results is relatively flexible. The optimal state is to have
    a sample dataset that is representative of the population.'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**收集数据**：数据应包括物体或事件的位置。正如我们简要提到的，运行并实现可操作结果所需的数据量是相对灵活的。最佳状态是拥有一个能代表总体的样本数据集。'
- en: '**Identify the base map**: The next step is to identify which base map would
    best suit the analytical and presentational needs of the project. On this base
    map, the results of the model will be overlaid, so that the locations of the hotspots
    can be easily articulated in much more digestible terms, such as city, neighborhood,
    or region.'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**识别基础地图**：下一步是识别哪种基础地图最适合项目的分析和展示需求。在这张基础地图上，模型的结果将被叠加，以便能更清晰地表达热点的位置，使用更易于理解的术语，如城市、邻里或区域。'
- en: '**Execute the model**: In this step, you select and execute one or multiple
    methodologies of extracting spatial patterns to identify hotspots. For us, this
    method will be – no surprise – kernel density estimation.'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**执行模型**：在这一步骤中，你需要选择并执行一种或多种空间模式提取方法，以识别热点。对我们来说，这个方法将是——毫不奇怪——核密度估计。'
- en: '**Create the visualization**: The hotspot maps are generated by overlaying
    the model results on the base map to support whatever business questions are outstanding.'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建可视化**：热点地图通过将模型结果叠加在基础地图上生成，以支持未解决的业务问题。'
- en: One of the principal issues with hotspot analysis from a usability standpoint
    is that the statistical significance of a hotspot is not particularly easy to
    ascertain. Most questions about statistical significance revolve around the existence
    of the hotspots. That is, do the fluctuations in likelihood of occurrence actually
    amount to statistically significant fluctuations? It is important to note that
    statistical significance is not required to perform kernel density estimation
    and that we will not be dealing with significance at all going forward.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 从可用性角度来看，热点分析的主要问题之一是，热点的统计显著性并不容易确定。大多数关于统计显著性的问题围绕热点的存在展开。也就是说，发生概率的波动是否真的构成了统计上显著的波动？需要注意的是，进行核密度估计并不需要统计显著性，我们在接下来的工作中将完全不涉及显著性。
- en: While the term hotspot is traditionally reserved to describe a cluster of location
    data points, it is not limited to location data. Any data type can have hotspots
    regardless of whether or not they are referred to as hotspots. In one of the following
    exercises, we will model some non-location data to find hotspots, which will be
    regions of the feature space having a high or low likelihood of occurrence.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然“热点”一词传统上用于描述位置数据点的聚集，但它并不限于位置数据。任何数据类型都可能有热点，不管它们是否被称为热点。在接下来的练习中，我们将对一些非位置数据进行建模，以寻找热点，这些热点将是特征空间中具有高或低发生概率的区域。
- en: 'Exercise 9.05: Loading Data and Modeling with Seaborn'
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 9.05：加载数据并使用 Seaborn 建模
- en: In this exercise, we will work with the `seaborn` library to fit and visualize
    kernel density estimation models. This is done on both location and non-location
    data. Before getting into the modeling, we load the data, which is the California
    housing dataset that comes with `sklearn`, that has been provided in csv form.
    The file needs to be downloaded from the GitHub repository and saved on your local
    machine. Taken from the United States census in 1990, this dataset describes the
    housing situation in California during that time. One row of data describes one
    census block group. The definition of a census block group is irrelevant to this
    exercise, so we will bypass the definition here in favor of more hands-on coding
    and modeling. It is important to mention that all the variables are aggregated
    to the census block. For example, `MedInc` is the median income of households
    in each census block. Additional information on this dataset is available at [https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset](https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用 `seaborn` 库来拟合并可视化核密度估计模型。这将应用于位置数据和非位置数据。在进行建模之前，我们需要加载数据，该数据是来自
    `sklearn` 的加州住房数据集，并以 CSV 格式提供。文件需要从 GitHub 仓库下载并保存在本地计算机上。该数据集取自 1990 年的美国人口普查，描述了当时加州的住房情况。每一行数据描述一个普查区块组。普查区块组的定义对于本练习并不重要，因此我们将在此跳过定义，专注于更多的实践编码和建模。需要强调的是，所有变量都已经按普查区块进行了汇总。例如，`MedInc`
    是每个普查区块中家庭的中位数收入。有关此数据集的更多信息，请访问 [https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset](https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset)。
- en: 'Load the California housing dataset using `california_housing.csv`. Print the
    first five rows of the data frame:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `california_housing.csv` 加载加州住房数据集。打印数据框的前五行：
- en: '[PRE12]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The path of the file depends on the location of the file on your system.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 文件的路径取决于文件在系统中的位置。
- en: 'The output is as follows:'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.18: The first five rows of the California housing dataset from sklearn'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.18：来自sklearn的加利福尼亚州房屋数据集的前五行'
- en: '](img/B15923_09_18.jpg)'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_18.jpg)'
- en: 'Figure 9.18: The first five rows of the California housing dataset from sklearn'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.18：来自sklearn的加利福尼亚州房屋数据集的前五行
- en: 'Filter the data frame on the `HouseAge` feature, which is the median home age
    of each census block. Keep only the rows with `HouseAge` less than or equal to
    15 and name the data frame `dfLess15`. Print out the first five rows of the data
    frame, then reduce the data frame down to just the longitude and latitude features:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据`HouseAge`特征过滤数据框，该特征是每个普查区块的房屋中位数年龄。仅保留`HouseAge`小于或等于15的行，并将数据框命名为`dfLess15`。打印数据框的前五行，然后将数据框缩减为仅包含经度和纬度特征：
- en: '[PRE13]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is as follows:'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.19: The first five rows of the filtered dataset'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.19：过滤后的数据集前五行'
- en: '](img/B15923_09_19.jpg)'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_19.jpg)'
- en: 'Figure 9.19: The first five rows of the filtered dataset'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.19：过滤后的数据集前五行
- en: 'Use `seaborn` to fit and visualize the kernel density estimation model built
    on the longitude and latitude data points. There are four inputs to the model,
    which are the names of the two columns over which the estimated density is sought
    (that is, the longitude and latitude), the data frame to which those columns belong,
    and the method of density estimation (that is, the `kde` or kernel density estimation):'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`seaborn`对基于经度和纬度数据点构建的核密度估计模型进行拟合和可视化。该模型有四个输入参数：需要估计密度的两个列的名称（即经度和纬度）、这些列所属的数据框，以及密度估计方法（即`kde`或核密度估计）：
- en: '[PRE14]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output is as follows:'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.20: A joint plot'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.20：联合图'
- en: '](img/B15923_09_20.jpg)'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_20.jpg)'
- en: 'Figure 9.20: A joint plot'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.20：联合图
- en: Note
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The graph might differ as the estimation is not exactly the same every time.
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图表可能有所不同，因为每次的估计都不完全相同。
- en: This joint plot contains both the two-dimensional estimated density plus the
    marginal densities for the dfLess15 dataset.
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个联合图包含了二维估计密度以及`dfLess15`数据集的边际密度。
- en: If we overlay these results on a map of California, we will see that the hotspots
    are southern California, including Los Angeles and San Diego, the bay area, including
    San Francisco, and to a small degree the area known as the central valley. A benefit
    of this `seaborn` graphic is that we get the two-dimensional estimated density
    and the marginal densities for both longitude and latitude.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们将这些结果叠加到加利福尼亚州的地图上，我们会看到热点区域集中在南加利福尼亚，包括洛杉矶和圣地亚哥，湾区，包括旧金山，以及在一定程度上被称为中央山谷的区域。这个`seaborn`图形的一个优点是，我们可以获得二维的估计密度图，并且分别展示了经度和纬度的边际密度。
- en: 'Create another filtered data frame based on the `HouseAge` feature; this time
    keep only the rows with `HouseAge` greater than 40 and name the data frame `dfMore40`.
    Additionally, remove all the columns other than longitude and latitude. Then,
    print the first five rows of the data frame:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于`HouseAge`特征创建另一个过滤后的数据框；这次仅保留`HouseAge`大于40的行，并将数据框命名为`dfMore40`。此外，移除除经度和纬度之外的所有列。然后，打印数据框的前五行：
- en: '[PRE15]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output is as follows:'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.21: The top of the dataset filtered'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.21：过滤后的数据集顶部'
- en: '](img/B15923_09_21.jpg)'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_21.jpg)'
- en: 'Figure 9.21: The top of the dataset filtered'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.21：过滤后的数据集顶部
- en: 'Repeat the process from *Step 3*, but using this new filtered data frame:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*步骤 3*中的过程，但使用这个新的过滤后的数据框：
- en: '[PRE16]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output is as follows:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.22: The joint plot'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.22：联合图'
- en: '](img/B15923_09_22.jpg)'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_22.jpg)'
- en: 'Figure 9.22: The joint plot'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.22：联合图
- en: This joint plot contains both the two-dimensional estimated density plus the
    marginal densities for the dfMore40 dataset.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个联合图包含了二维估计密度以及`dfMore40`数据集的边际密度。
- en: This estimated density is much more compact in that the data is clustered almost
    entirely in two areas. Those areas are Los Angeles and the bay area. Comparing
    this to the plot in *Step 3*, we notice that housing development has spread out
    across the state. Additionally, newer housing developments occur with much higher
    frequencies in a larger number of census blocks.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个估计密度要紧凑得多，因为数据几乎完全聚集在两个区域。这些区域分别是洛杉矶和湾区。与*步骤 3*中的图表对比，我们注意到房屋开发已经扩展到整个州。此外，新的住房开发在更多的普查区块中出现的频率也显著提高。
- en: 'Let''s again create another filtered data frame. This time only keeping rows
    where `HouseAge` is less than or equal to five and name the data frame `dfLess5`.
    Plot `Population` and `MedInc` as a scatterplot, as follows:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们再创建另一个过滤后的数据框。这次仅保留`HouseAge`小于或等于五的行，并将数据框命名为`dfLess5`。绘制`Population`和`MedInc`的散点图，如下所示：
- en: '[PRE17]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is as follows:'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.23: Scatterplot of the median income against population'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.23：中位收入与人口的散点图'
- en: '](img/B15923_09_23.jpg)'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_23.jpg)'
- en: 'Figure 9.23: Scatterplot of the median income against population'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.23：中位收入与人口的散点图
- en: This is the scatterplot of the median income against population for values of
    five or less in the `HouseAge` column.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是`HouseAge`列中值小于或等于五的中位收入与人口的散点图。
- en: 'Use yet another `seaborn` function to fit a kernel density estimation model.
    The optimal bandwidth is found using Scott''s Rule. Replot the histogram and overlay
    the estimated density, as follows:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用另一个`seaborn`函数拟合核密度估计模型。使用Scott法则找到最佳带宽。重新绘制直方图，并叠加估算的密度，如下所示：
- en: '[PRE18]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output is as follows:'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.24: The same scatterplot as created in step 6 with the estimated
    density overlaid'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.24：与步骤6中创建的相同散点图，叠加了估算的密度'
- en: '](img/B15923_09_24.jpg)'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_24.jpg)'
- en: 'Figure 9.24: The same scatterplot as created in step 6 with the estimated density
    overlaid'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.24：与步骤6中创建的相同散点图，叠加了估算的密度
- en: Here, the estimated density shows that census blocks with smaller populations
    have lower median incomes at higher likelihoods than they have high median incomes.
    The point of this step is to showcase how kernel density estimation can be used
    on non-location data. A plot like this is typically referred to as a contour plot.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，估算的密度显示，人口较少的普查区块相比于拥有较高中位收入的区块，更有可能拥有较低的中位收入。这个步骤的重点是展示如何在非位置数据上使用核密度估计。像这样的图通常被称为等高线图。
- en: Note
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该部分的源代码，请参阅[https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ)。
- en: You can also run this example online at [https://packt.live/38DbmTo](https://packt.live/38DbmTo).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在[https://packt.live/38DbmTo](https://packt.live/38DbmTo)在线运行此示例。
- en: You must execute the entire Notebook in order to get the desired result.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须执行整个笔记本才能获得预期的结果。
- en: When presenting the results of hotspot analysis, some type of map should be
    involved since hotspot analysis is generally done on location data. Acquiring
    maps on which estimated densities can be overlaid is not an easy process. Due
    to copyright issues, we will use very basic maps, called basemaps, on which we
    can overlay our estimated densities. It will be left to you to extend the knowledge
    you acquire in this chapter to fancier and more detailed maps. Mapping environments
    can also be complicated and time-consuming to download and install.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在展示热点分析结果时，通常需要涉及某种类型的地图，因为热点分析通常是在位置数据上进行的。获取可以叠加估算密度的地图并不是一件容易的事。由于版权问题，我们将使用非常基础的地图，称为底图，在其上叠加我们的估算密度。将留给你自己扩展本章所学的知识，去处理更复杂和更详细的地图。地图环境也可能很复杂，下载和安装起来很耗时。
- en: 'Exercise 9.06: Working with Basemaps'
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 9.06：与底图一起工作
- en: This exercise leverages the `basemap` module of `mpl_toolkits`. `basemap` is
    a mapping library, which can be used to create basic maps or outlines of geographic
    regions. These maps can have the results of kernel density estimation overlaid,
    so that we can clearly see where the hotspots are located.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习使用了`mpl_toolkits`的`basemap`模块。`basemap`是一个地图绘制库，可以用来创建基础地图或地理区域的轮廓。这些地图可以叠加核密度估计的结果，从而清晰地展示热点位置。
- en: First, check whether `basemap` is installed by running `import mpl_toolkits.basemap`
    in a Jupyter notebook. If it loads without error, then you are ready and need
    to take no further action. If the call fails, then install `basemap` using `pip`
    by running `python3 -m pip install basemap`. You should be good to go after restarting
    any already-open notebooks. Note that the `pip` installation will only work if
    Anaconda is installed.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在Jupyter笔记本中运行`import mpl_toolkits.basemap`检查`basemap`是否已安装。如果没有错误加载，说明你已经准备好了，不需要采取任何进一步的操作。如果调用失败，请通过运行`python3
    -m pip install basemap`使用`pip`安装`basemap`。重新启动任何已打开的笔记本后，你应该可以正常使用。请注意，`pip`安装仅在已安装Anaconda的情况下有效。
- en: The goal of this exercise is to remodel and replot the location data from *Exercise
    9.05*, *Loading Data and Modeling with Seaborn*, using the kernel density estimation
    functions of `sklearn` and the mapping capabilities of `basemap`. Extract the
    longitude and latitude values from the filtered data frame called `dfLess15` to
    work through the steps. Note that this exercise should be done in the same notebook
    as all the other exercises.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的目标是重新建模并重新绘制*练习 9.05*中的位置数据，*使用Seaborn加载数据与建模*，使用`sklearn`的核密度估计功能和`basemap`的映射功能。从过滤后的数据框`dfLess15`中提取经度和纬度值，按步骤进行操作。请注意，本练习应与其他所有练习在同一个笔记本中完成。
- en: 'Form the grid of locations over which the estimated density will be laid. The
    grid of locations is the two-dimensional location equivalent of the one-dimensional
    vector defining the range of the random variable in *Exercise 9.01*, *The Effect
    of the Bandwidth Value*:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建位置网格，以便在其上铺设估计的密度。位置网格是*练习 9.01*中定义随机变量范围的一维向量的二维位置等效物：
- en: '[PRE19]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is as follows:'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.25: The x and y components of the grid representing the dfLess15
    dataset'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.25：表示dfLess15数据集的网格的x和y分量'
- en: '](img/B15923_09_25.jpg)'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_25.jpg)'
- en: 'Figure 9.25: The x and y components of the grid representing the dfLess15 dataset'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.25：表示dfLess15数据集的网格的x和y分量
- en: 'Define and fit a kernel density estimation model. Set the bandwidth value to
    0.05\. Then create likelihood values for each point on the location grid:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义并拟合一个核密度估计模型。将带宽值设置为0.05。然后为位置网格上的每个点创建可能性值：
- en: '[PRE20]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output of kernel density estimation model is as follows:'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 核密度估计模型的输出结果如下：
- en: '[PRE21]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Fit the trained model on the `xy` grid and print the shape as follows:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练好的模型拟合到`xy`网格上，并打印出形状，如下所示：
- en: '[PRE22]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is as follows:'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE23]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Notice that if you print out the shape of the likelihood values, it is 3,287
    rows by 3,287 columns, which is 10,804,369 likelihood values. This is the same
    number of values in the preestablished longitude and latitude grid, called `xy15`.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，如果你打印出可能性值的形状，它是3,287行 × 3,287列，即10,804,369个可能性值。这与预设的经度和纬度网格`xy15`中的值数相同。
- en: 'Create an outline of California and overlay the estimated density computed
    in *Step 2*:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建加利福尼亚州的轮廓，并叠加*步骤 2*中计算的估计密度：
- en: '[PRE24]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is as follows:'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.26: The estimated density of dfLess15 overlaid onto an outline of
    California'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.26：将dfLess15的估计密度叠加到加利福尼亚州的轮廓上'
- en: '](img/B15923_09_26.jpg)'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_26.jpg)'
- en: 'Figure 9.26: The estimated density of dfLess15 overlaid onto an outline of
    California'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.26：将dfLess15的估计密度叠加到加利福尼亚州的轮廓上
- en: The `0.05` value was set to purposefully overfit the data slightly. You'll notice
    that instead of the larger clusters that made up the density in *Exercise 9.05,*
    *Loading Data and Modeling with Seaborn* the estimated density here is made up
    of much smaller clusters. This slightly overfit density might be a bit more helpful
    than the previous version of the density because it gives you a clearer view of
    where the high likelihood census blocks are truly located. One of the high-likelihood
    areas in the previous density was southern California, but southern California
    is a huge area with an enormous population and many municipalities. Bear in mind
    that when using the results for business decisions, certain levels of specificity
    might be required and should be provided if the sample data can support results
    with that level of specificity or granularity.
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`0.05`的值是故意设置为略微过拟合数据。你会注意到，与*练习 9.05*中的较大聚类（构成密度的部分）不同，*使用Seaborn加载数据与建模*中的估计密度由许多更小的聚类组成。这种略微过拟合的密度可能比之前版本的密度更有帮助，因为它能更清晰地显示高概率的普查区块的确切位置。之前密度中一个高概率区域是南加州，但南加州是一个面积庞大、人口众多且有许多市政区的地方。请记住，在使用这些结果做商业决策时，可能需要某些特定的精确度，且如果样本数据能支持该级别的精确度或细化结果，应该提供相关信息。'
- en: 'Repeat *Step 1*, but with the `dfMore40` data frame:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*步骤 1*，但使用`dfMore40`数据框：
- en: '[PRE25]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output is as follows:'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.27: The x and y components of the grid representing the dfMore40
    dataset'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.27：表示dfMore40数据集的网格的x和y分量'
- en: '](img/B15923_09_27.jpg)'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15923_09_27.jpg)'
- en: 'Figure 9.27: The x and y components of the grid representing the dfMore40 dataset'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.27：表示dfMore40数据集的网格的x和y分量
- en: 'Repeat *Step 2* using the grid established in *Step 4*:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*步骤 4*中建立的网格重复*步骤 2*：
- en: '[PRE26]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Repeat *Step 3* using the estimated density computed in *Step 5*:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*步骤 5*中计算出的估算密度重复执行*步骤 3*：
- en: '[PRE27]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is as follows:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.28: The estimated density of dfMore40 overlaid onto an outline of
    California'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.28：估算的 dfMore40 密度叠加在加利福尼亚州的轮廓上'
- en: '](img/B15923_09_28.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15923_09_28.jpg)'
- en: 'Figure 9.28: The estimated density of dfMore40 overlaid onto an outline of
    California'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.28：估算的 dfMore40 密度叠加在加利福尼亚州的轮廓上
- en: Note
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该特定部分的源代码，请参考[https://packt.live/2UOHbTZ](https://packt.live/2UOHbTZ)。
- en: You can also run this example online at [https://packt.live/38DbmTo](https://packt.live/38DbmTo).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/38DbmTo](https://packt.live/38DbmTo)上在线运行这个示例。你必须执行整个
    Notebook 才能获得预期的结果。
- en: This estimated density is again a redo of the one that we did in *Exercise 9.05*,
    *Loading Data and Modeling with Seaborn*. While the density from *Step 3* will
    provide more detail for a person interested in real estate or the census, this
    density does not actually look that different from its corollary density in *Exercise
    9.05*, *Loading Data and Modeling with Seaborn*. The clusters are primarily around
    Los Angeles and San Francisco with almost no points anywhere else.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这个估算密度实际上是我们在*练习 9.05*，*加载数据与使用 Seaborn 建模*中所做的密度的重新计算。虽然*步骤 3*中的密度能为那些对房地产或人口普查感兴趣的人提供更多细节，但这个密度与*练习
    9.05*中对应的密度实际上看起来没有太大不同。热点主要集中在洛杉矶和旧金山，几乎没有其他地方的点。
- en: 'Activity 9.02: Analyzing Crime in London'
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 9.02：分析伦敦的犯罪数据
- en: In this activity, we will perform hotspot analysis with kernel density estimation
    on London crime data from [https://data.police.uk/data/](https://data.police.uk/data/).
    Due to the difficulties of working with map data, we will visualize the results
    of the analysis using `seaborn`. However, if you feel brave and were able to run
    all the plots in *Exercise 9.06*, *Working with Basemaps* you are encouraged to
    try using maps.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将使用来自[https://data.police.uk/data/](https://data.police.uk/data/)的伦敦犯罪数据，通过核密度估计进行热点分析。由于处理地图数据的难度较大，我们将使用`seaborn`来可视化分析结果。然而，如果你觉得勇敢，并且已经能够运行*练习
    9.06*，*与底图一起工作*中的所有图形，那么鼓励你尝试使用地图。
- en: The motivation for performing hotspot analysis on this crime data is two-fold.
    We are asked first to determine where certain types of crimes are occurring in
    high likelihood, so that police resources can be allocated for maximum impact.
    Then, as a follow up, we are asked to ascertain whether the hotspots for certain
    types of crime are changing over time. Both of these questions are answerable
    using kernel density estimation.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 对该犯罪数据进行热点分析的动机有两个方面。首先，我们被要求确定某些类型的犯罪发生的高概率位置，以便能够最大化警力资源的分配。接着，作为后续工作，我们需要确定某些类型的犯罪热点是否随着时间变化而发生变化。这两个问题都可以通过使用核密度估计来解答。
- en: Note
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This dataset is sourced from [https://data.police.uk/data/](https://data.police.uk/data/).
    It contains public sector information licensed under the Open Government License
    v3.0.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集来自[https://data.police.uk/data/](https://data.police.uk/data/)。它包含根据开放政府许可证
    v3.0 许可的公共部门信息。
- en: You can also download it from the Packt GitHub at [https://packt.live/2JIWs2z](https://packt.live/2JIWs2z).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以从 Packt 的 GitHub 下载，链接为[https://packt.live/2JIWs2z](https://packt.live/2JIWs2z)。
- en: Alternatively, to download the data directly from the source, go to the preceding
    police website, check the box for `Metropolitan Police Service`, and then set
    the date range to `July 2018` to `Dec 2018`. Next, click `Generate file` followed
    by `Download now` and name the downloaded file `metro-jul18-dec18`. Make sure
    that you know how or can retrieve the path to the downloaded directory.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，若要直接从源网站下载数据，请访问前述的警察网站，勾选`Metropolitan Police Service`，然后设置日期范围为`2018年7月`至`2018年12月`。接着，点击`生成文件`，然后点击`立即下载`，并将下载的文件命名为`metro-jul18-dec18`。确保你知道如何或能够找到下载目录的路径。
- en: This dataset contains public sector information licensed under the Open Government
    License v3.0.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包含根据开放政府许可证 v3.0 许可的公共部门信息。
- en: 'Here are the steps to complete the activity:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此活动的步骤如下：
- en: Load the crime data. Use the path where you saved the downloaded directory,
    create a list of the year-month tags, use the `read_csv` command to load the individual
    files iteratively, and then concatenate these files together.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载犯罪数据。使用你保存下载目录的路径，创建一个包含年月标签的列表，使用`read_csv`命令逐个加载文件，然后将这些文件连接在一起。
- en: Print diagnostics of the complete (six months) and concatenated dataset.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印完整（六个月）和合并数据集的诊断信息。
- en: Subset the data frame down to four variables (`Longitude`, `Latitude`, `Month`,
    and `Crime type`).
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据框缩减为四个变量（`经度`，`纬度`，`月份`，和`犯罪类型`）。
- en: Using the `jointplot` function from `seaborn`, fit and visualize three kernel
    density estimation models for bicycle theft in July, September, and December 2018.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`seaborn`中的`jointplot`函数，为2018年7月、9月和12月的自行车盗窃案件拟合并可视化三个核密度估计模型。
- en: Repeat *Step 4*; this time, use shoplifting crimes for the months of August,
    October, and November 2018.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*步骤 4*；这次，使用2018年8月、10月和11月的盗窃案件数据。
- en: Repeat *Step 5*; this time, use burglary crimes for the months of July, October,
    and December 2018.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*步骤 5*；这次，使用2018年7月、10月和12月的入室盗窃案件数据。
- en: 'The output from the last part of *Step 6* will be as follows:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 6* 最后部分的输出如下：'
- en: '![Figure 9.29: The estimated joint and marginal densities for burglaries in
    December 2018'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.29：2018年12月入室盗窃案件的估计联合和边际密度'
- en: '](img/B15923_09_29.jpg)'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15923_09_29.jpg)'
- en: 'Figure 9.29: The estimated joint and marginal densities for burglaries in December
    2018'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.29：2018年12月入室盗窃案件的估计联合和边际密度
- en: To clarify one more time, the densities found in this activity should have been
    overlaid on maps so that we could see exactly what areas these densities cover.
    Attempting to overlay the results on maps on your own would be encouraged if you
    have the appropriate mapping platforms at your disposal. If not, you could go
    to the mapping services available online and use the longitude and latitude pairs
    to gain insight into the specific locations.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 再次澄清，活动中得到的密度应该已经叠加在地图上，以便我们能清楚地看到这些密度覆盖了哪些区域。如果你有合适的地图平台，建议尝试自己将结果叠加到地图上。如果没有，你可以访问在线地图服务，使用经纬度对来了解具体位置。
- en: Note
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 505.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第505页找到。
- en: Summary
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Kernel density estimation is a classic statistical technique that is in the
    same family of techniques as the histogram. It allows the user to extrapolate
    out from sample data to make insights and predictions about the population of
    particular objects or events. This extrapolation comes in the form of a probability
    density function, which is nice because the results read as likelihoods or probabilities.
    The quality of this model is dependent on two parameters: the bandwidth value
    and the kernel function. As discussed, the most crucial component of leveraging
    kernel density estimation successfully is the setting of an optimal bandwidth.
    Optimal bandwidths are most frequently identified using grid search cross-validation
    with pseudo-log-likelihood as the scoring metric. What makes kernel density estimation
    great is both its simplicity and its applicability to so many fields.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 核密度估计是一种经典的统计技术，属于与直方图相同类别的技术。它允许用户从样本数据中外推，以对特定对象或事件的总体做出洞察和预测。这种外推以概率密度函数的形式呈现，这很好，因为结果可以以可能性或概率的形式解读。该模型的质量依赖于两个参数：带宽值和核函数。如前所述，成功使用核密度估计的最关键部分是设置最优带宽。最优带宽通常通过使用网格搜索交叉验证和伪对数似然作为评分标准来确定。核密度估计的优点在于其简洁性和广泛的适用性。
- en: It is routine to find kernel density estimation models in criminology, epidemiology,
    meteorology, and real estate to only name a few. Regardless of your area of business,
    kernel density estimation should be applicable.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 核密度估计模型在犯罪学、流行病学、气象学和房地产等领域中非常常见，仅举几例。无论你从事哪个行业，核密度估计都应该是适用的。
- en: Between supervised and unsupervised learning, unsupervised learning is undoubtedly
    the least used and appreciated learning category. But this should not be the case.
    Supervised learning techniques are limited and most of the available data does
    not fit well with regression and classification. Expanding your skill set to include
    unsupervised learning techniques means that you will be able to leverage different
    datasets, answer business problems in more creative ways, and even enhance your
    existing supervised learning models. This text by no means exhausts all the unsupervised
    learning algorithms, but serves as a good start to pique your interest and drive
    continued learnings.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习和无监督学习之间，无监督学习无疑是最少使用和最不被重视的学习类别。但情况不应该是这样的。监督学习技术是有限的，并且大多数可用数据并不适合回归和分类。扩展你的技能集，学习无监督学习技术，意味着你将能够利用不同的数据集，以更具创意的方式解决业务问题，甚至增强你现有的监督学习模型。本文并不详尽介绍所有无监督学习算法，但它是一个很好的起点，可以激发你的兴趣，并推动你继续学习。
