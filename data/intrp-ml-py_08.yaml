- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Interpreting NLP Transformers
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释NLP Transformer
- en: In the last chapter, we learned about applying explanation methods to a specific
    type of deep learning model architecture, convolutional neural networks. In this
    chapter, we will provide some tools to do the same with the transformer model
    architecture. Transformer models are becoming increasingly popular, and their
    most common use case is **Natural Language Processing** (**NLP**). We broached
    the subject of NLP in *Chapter 5*, *Local Model-Agnostic Interpretation Methods*.
    In this chapter, we will do so too but with transformer-specific methods and tools.
    First, we will discuss how to visualize attention mechanisms, followed by interpreting
    integrated gradient attributions, and lastly, exploring the Swiss Army knife that
    is the **Learning Interpretability Tool** (**LIT**).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何将解释方法应用于特定类型的深度学习模型架构，即卷积神经网络。在本章中，我们将提供一些工具来对Transformer模型架构执行相同的操作。Transformer模型越来越受欢迎，它们最常见的使用案例是**自然语言处理**（**NLP**）。我们在*第五章*，*局部模型无关解释方法*中提到了NLP。在本章中，我们也将这样做，但使用Transformer特定的方法和工具。首先，我们将讨论如何可视化注意力机制，然后是解释集成梯度属性，最后是探索瑞士军刀般的**学习可解释性工具**（**LIT**）。
- en: 'These are the main topics we will cover:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖的主要主题包括：
- en: Visualizing attention with BertViz
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用BertViz可视化注意力
- en: Interpreting token attributions with integrated gradients
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用集成梯度解释标记属性
- en: LIME, counterfactuals, and other possibilities with the LIT
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME、反事实和其他LIT的可能性
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter’s example uses the `mldatasets`, `pandas`, `numpy` , `torch`, `transformers`
    , `bertviz`, `captum`, and `lit-nlp` libraries. Instructions on how to install
    all these libraries are in the *Preface*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的示例使用了`mldatasets`、`pandas`、`numpy`、`torch`、`transformers`、`bertviz`、`captum`和`lit-nlp`库。如何安装所有这些库的说明在*序言*中。
- en: 'The code for this chapter is located here: [https://packt.link/Yzf2L](https://packt.link/Yzf2L)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码位于此处：[https://packt.link/Yzf2L](https://packt.link/Yzf2L)
- en: The mission
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使命
- en: You are a data scientist working for a yet-to-launch startup in New York City.
    This startup aims to establish itself as the go-to place to find the best, newest,
    and most exciting culinary destinations in the city!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你是一名在纽约市一家即将推出的初创公司工作的数据科学家。这家初创公司旨在成为寻找城市中最佳、最新和最激动人心的美食目的地的首选之地！
- en: The aim is to move beyond the typical structured data about restaurants and
    delve deep into the vast array of textual data available online, from social media
    sites to directory websites. The startup believes that while ratings might provide
    a simplistic quantification of experiences, reviews contain richer details and
    can offer multidimensional insights into what makes a restaurant special.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是超越关于餐厅的典型结构化数据，深入挖掘网络上丰富的文本数据，从社交媒体网站到目录网站。初创公司认为，虽然评分可能提供对体验的简单量化，但评论包含更丰富的细节，可以提供多维度见解，了解什么使餐厅变得特别。
- en: Reviews express detailed sentiments that capture diverse user experiences, unlike
    ratings, which provide a singular, non-comparative perspective. By harnessing
    the granularity present in reviews, the startup can tailor its recommendations
    to cater to various audience segments with greater precision.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 评论表达详细的情感，捕捉多样化的用户体验，与提供单一、非比较视角的评分不同。通过利用评论中的粒度，初创公司可以更精确地定制其推荐，以满足各种受众群体。
- en: Your team has been discussing how to leverage sentiment analysis on reviews
    to determine how to best look for the feelings that exemplify the experience users
    look for in the recommender system. Binary sentiment analysis (positive/negative)
    does not offer the nuances required to distinguish between usual and unique experiences,
    or those catering to specific groups such as travelers, families, or couples.
    Also, the startup founders believe that the dining experience is multifaceted.
    An experience that might be seen as “positive” could range from “comforting and
    nostalgic” to “thrilling and adventurous.” Distinguishing these nuances will empower
    the recommender system to be more personalized and effective.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你们团队一直在讨论如何利用评论中的情感分析来确定如何最好地寻找体现用户在推荐系统中寻求体验感受的情感。二元情感分析（正面/负面）无法提供区分通常和独特体验，或针对特定群体（如旅行者、家庭或情侣）所需的细微差别。此外，初创公司的创始人认为用餐体验是多方面的。一种可能被视为“正面”的体验可能从“温馨而怀旧”到“刺激而冒险”。区分这些细微差别将使推荐系统能够更加个性化且有效。
- en: 'Your manager encountered a sentiment classification model that has 27 categories
    trained with a dataset called GoEmotions, published by Google. GoEmotions offers
    a more detailed classification of sentiments, capturing the richness of human
    emotions more effectively than binary classification models. However, the lead
    strategist decided there were too many classifications and decided to group them
    into a different emotion taxonomy called Ekman (see *Figure 8.1*):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你的经理遇到了一个情感分类模型，该模型使用名为GoEmotions的数据集进行训练，该数据集由谷歌发布。GoEmotions提供了一种更详细的情感分类，比二元分类模型更有效地捕捉人类情感的丰富性。然而，首席策略师决定分类太多，决定将它们分组到另一个名为埃克曼的不同情绪分类法中（参见*图8.1*）：
- en: '![](img/B18406_08_01.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_08_01.png)'
- en: 'Figure 8.1: The Taxonomy of Emotions'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1：情绪分类法
- en: Ekman’s taxonomy of emotions is a classification system developed by psychologist
    Paul Ekman, which identifies six basic emotions that he believed to be universally
    experienced in all human cultures. These six emotions are joy, sadness, fear,
    anger, disgust, and surprise. Ekman suggested that these are fundamental emotions
    that are hard-wired into our brains and expressed in the same way by people all
    around the world, regardless of their culture. These emotions can be identified
    through specific facial expressions, and understanding them can help in fields
    like psychology, communication, and sociology. Ekman’s taxonomy offers a more
    concise set of emotion categories while still preserving the nuances. This makes
    the interpretation more manageable and actionable for the development team and
    other stakeholders. However, we’ve had to keep neutral, which cannot be classified
    into any Ekman category.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 埃克曼的情绪分类法是由心理学家保罗·埃克曼开发的一种分类系统，它识别出六种基本情绪，他认为这些情绪在所有人类文化中都是普遍体验到的。这六种情绪是快乐、悲伤、恐惧、愤怒、厌恶和惊讶。埃克曼提出，这些是基本情绪，它们被硬编码在我们的大脑中，并且世界各地的人们都以相同的方式表达，无论他们的文化如何。这些情绪可以通过特定的面部表情来识别，理解它们可以帮助心理学、沟通和社会学等领域。埃克曼的分类法提供了一套更简洁的情绪类别，同时仍然保留了细微差别。这使得对情绪的解释对开发团队和其他利益相关者来说更加可管理和可操作。然而，我们不得不保持中立，这不能归类到任何埃克曼类别中。
- en: Now, the next step is to interpret the GoEmotions Ekman classifier model with
    the Tripadvisor review dataset to understand what the model learned and uncover
    patterns that could be useful to the development of the recommender system. It’s
    an open-ended task. The general goal is to understand the patterns the model has
    identified in the reviews and how these correlate with Ekman’s categories. However,
    this path could lead to many findings or a dead-end. Leadership stressed that
    data scientists, like yourself, would have to use their judgment to find opportunities
    in data exploration and model interpretation.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，下一步是使用Tripadvisor评论数据集来解释GoEmotions Ekman分类器模型，以了解模型学到了什么，并揭示可能对推荐系统开发有用的模式。这是一个开放性的任务。一般目标是理解模型在评论中识别出的模式以及这些模式如何与埃克曼的分类相对应。然而，这条路径可能导致许多发现或陷入死胡同。领导层强调，像你这样的数据科学家必须运用他们的判断力，在数据探索和模型解释中寻找机会。
- en: By uncovering these patterns, the startup can fine-tune its algorithm to look
    for reviews that resonate with these emotions. The insights can also guide restaurant
    partnerships, marketing strategies, and feature enhancements to the platform.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通过揭示这些模式，初创公司可以微调其算法，寻找与这些情绪产生共鸣的评论。这些见解还可以指导餐厅合作、营销策略和平台功能增强。
- en: The approach
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法
- en: 'You have decided to take a three-prong approach:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你决定采取三管齐下的方法：
- en: You will look under the hood of the transformer model to visualize attention
    weights with BertViz to find relevant patterns in those mechanisms.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将深入到转换器模型的内部，使用BertViz可视化注意力权重，以寻找这些机制中的相关模式。
- en: Then, you’ll produce saliency maps where attributions are color-coded for each
    token in reviews of interest, using the integrated gradients method.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你将生成显著性图，其中每个感兴趣的评论中的每个标记的归因都使用集成梯度法进行着色编码。
- en: Lastly, you’ll examine counterfactuals with the LIT.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，你将使用LIT来检验反事实情况。
- en: You hope that you can deliver some actionable insights to the leadership team
    with these steps.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你希望这些步骤能够向领导团队提供一些可操作的见解。
- en: The preparations
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'You will find the code for this example here: [https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/master/08/ReviewSentiment.ipynb](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/master/08/ReviewSentiment.ipynb)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到这个示例的代码：[https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/master/08/ReviewSentiment.ipynb](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/tree/master/08/ReviewSentiment.ipynb)
- en: Loading the libraries
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载库
- en: 'To run this example, you need to install the following libraries:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此示例，您需要安装以下库：
- en: '`mldatasets` to load the dataset'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mldatasets` 用于加载数据集'
- en: '`pandas` and `numpy` to manipulate it'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas` 和 `numpy` 用于操作'
- en: '`torch` (PyTorch) and `transformers` to load and configure the model'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch`（PyTorch）和 `transformers` 用于加载和配置模型'
- en: '`bertviz`, `captum`, and `lit-nlp` to generate and visualize the model interpretations'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bertviz`、`captum` 和 `lit-nlp` 用于生成和可视化模型解释'
- en: 'You should load all of them first:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该首先加载所有这些库：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, we work on data understanding and preparations.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们进行数据处理和理解。
- en: Understanding and preparing the data
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解和准备数据
- en: 'We load the data like this into a DataFrame we call `reviews_df`:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据这样加载到我们称为 `reviews_df` 的 DataFrame 中：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'There should be over 380,000 records and 12 columns. We can verify this is
    the case with `info()`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 应该有超过 380,000 条记录和 12 列。我们可以使用 `info()` 来验证这一点：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The output checks out. There are no missing values. However, there are only
    three numeric features, one date, and all the rest are object data types because
    they are mostly text. Given that this chapter focuses on NLP, this shouldn’t come
    as a surprise. Let’s examine the data dictionary to understand what we will use
    from this DataFrame.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 输出检查无误。没有缺失值。然而，只有三个数值特征，一个日期，其余的都是对象数据类型，因为它们大多是文本。鉴于本章重点介绍 NLP，这并不令人惊讶。让我们检查数据字典，以了解我们将从该
    DataFrame 中使用什么。
- en: The data dictionary
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据字典
- en: 'These are the 12 columns in the DataFrame, most of which are there for reference:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是 DataFrame 中的 12 列，其中大部分是为了参考：
- en: '`review_id`: ID – a unique identifier for the review (only for reference)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`review_id`: ID – 评论的唯一标识符（仅作参考）'
- en: '`author_id`: ID – a unique identifier for the author (only for reference)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`author_id`: ID – 作者的唯一标识符（仅作参考）'
- en: '`restaurant_name`: text – the name of the restaurant (only for reference)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`restaurant_name`: 文本 – 餐厅的名称（仅作参考）'
- en: '`url_restaurant`: **URL** – **Uniform Resource Identifier** to locate the web
    page where the restaurant review is located (only for reference)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`url_restaurant`: **URL** – **统一资源标识符**，用于定位包含餐厅评论的网页（仅作参考）'
- en: '`review_date`: date – the date when the review was made (only for reference)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`review_date`: 日期 – 评论制作的日期（仅作参考）'
- en: '`review_title`: text – the title the author wrote for the review'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`review_title`: 文本 – 作者为评论写的标题'
- en: '`review_preview`: text – the preview generated for the review'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`review_preview`: 文本 – 为审查生成的预览'
- en: '`review_full`: text – the full review written by the author'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`review_full`: 文本 – 作者撰写的完整评论'
- en: '`rating`: ordinal – a rating given by the author to the establishment (a 1–5
    rating scale)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rating`: 序数 – 作者对场所给出的评级（1–5 级别）'
- en: '`positive_sentiment`: binary – whether the review has a positive sentiment
    according to a binary sentiment model (positive/negative)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`positive_sentiment`: 二进制 – 根据二元情感模型，评论是否有积极情感（积极/消极）'
- en: '`label`: categorical – the predicted emotion by the GoEmotions classifier (according
    to the Ekman seven-class classification: joy, neutral, sadness, disgust, fear,
    anger, and surprise)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`label`: 分类 – GoEmotions 分类器预测的情绪（根据 Ekman 七类分类：快乐、中性、悲伤、厌恶、恐惧、愤怒和惊讶）'
- en: '`score`: continuous – the predicted probability that the review belongs to
    the predicted class'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score`: 连续 – 预测评论属于预测类别的概率'
- en: 'It’s a multi-class model, so it predicted scores for each class. However, we
    only stored the `score` of the most probable class (`label`). Therefore, the last
    two columns represent the output of the model. As for the input, let’s examine
    the first three rows to illustrate it:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个多分类模型，因此它为每个类别预测了分数。然而，我们只存储了最可能类别的 `score`（标签）。因此，最后两列代表模型的输出。至于输入，让我们检查前三行来说明：
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](img/B18406_08_02.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_08_02.png)'
- en: 'Figure 8.2: The first three reviews of the dataset'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2：数据集的前三个评论
- en: 'It’s the first two columns in *Figure 8.2*, `review_title` and `review_full`,
    that represent the input for the model. It does so as a single piece of text,
    so when we discuss *the review*, we are referring to a string that concatenates
    both with a colon and space, separating them like this: *Disappointing: Food was
    mediocre at best. The lamb chops are an image they feature on the websites opening
    page*.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图8.2*的前两列中，`review_title`和`review_full`代表模型的输入。它将它们作为一段单独的文本，因此当我们讨论*评论*时，我们指的是将这两个字符串通过冒号和空格连接起来的字符串，如下所示：*令人失望：食物最多只是平庸。羊排是他们网站上首页展示的图片*。
- en: But these are not the only columns that could matter in an analysis. We could,
    of course, analyze reviews by author, restaurant, date, and so on, and even connect
    restaurants to specific coordinates on a map to understand how sentiment varies
    geographically. This is all very interesting. However, we won’t go into any detail
    here because although it might be relevant to the general mission of sentiment
    analysis, it will divert from the technical topic of this chapter, which is interpreting
    transformer models.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 但这些并不是分析中唯一可能重要的列。我们当然可以按作者、餐厅、日期等分析评论，甚至将餐厅与地图上的特定坐标连接起来，以了解情感在地理上的变化。这一切都非常有趣。然而，我们不会在这里深入探讨，因为尽管这可能对情感分析的一般任务相关，但它会偏离本章的技术主题，即解释Transformer模型。
- en: Nonetheless, we will explore some features that are highly correlated with the
    model outcomes, which are the `rating` provided by the author and the outcome
    of the binary sentiment analysis model (`positive_sentiment`). You would definitely
    expect these to match because reviews are generally consistent with the ratings
    — that is, a positive review will have a higher rating than a negative one. Likewise,
    some emotions are more positive than negative.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们将探索一些与模型结果高度相关的特征，即作者提供的`评分`和二元情感分析模型的`正面情感`结果。你肯定期望这些会匹配，因为评论通常与评分一致——也就是说，正面评论的评分会比负面评论高。同样，一些情绪比负面情绪更积极。
- en: 'To understand these correlations a bit better, let’s aggregate the reviews
    to get an average `rating` and `positive_sentiment` for each emotion like this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这些相关性，让我们将评论汇总起来，为每种情绪计算平均`评分`和`正面情感`，如下所示：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The above code will produce the output in *Figure 8.3*:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将在*图8.3*中生成输出：
- en: '![](img/B18406_08_03.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_08_03.png)'
- en: 'Figure 8.3: A summary table of the emotions predicted for the review dataset'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3：预测的评论数据集情绪的汇总表
- en: As you can appreciate in *Figure 8.3*, the majority of the 380,000 reviews are
    placed in the joy label or class. Joy is a positive emotion, so it makes sense
    that our binary sentiment classifier classified over 90% of them as positive and
    that the average rating for joyous reviews is nearly 4.5\. The DataFrame is sorted
    by the average rating because it’s not a product of a model (which could be wrong),
    so it can perhaps give us the clearest indication of what predicted emotions the
    end users perceive to be the most positive. And as you go down in the list, you
    have positive emotions first, followed by neutral, and then the negative ones.
    Please note that the percentage of reviews that was deemed to be positive by the
    binary classifier is somewhat consistent with the same order provided by the average
    rating.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*图8.3*中可以看到的，380,000条评论中的大多数都被放在了“喜悦”标签或类别中。喜悦是一种积极的情绪，因此我们的二元情感分类器将超过90%的它们分类为正面，并且喜悦评论的平均评分几乎为4.5。DataFrame按平均评分排序，因为它不是模型（可能出错）的结果，所以它可能给我们提供最清晰的预测情绪的指示，即最终用户认为最积极的情绪。随着你向下查看列表，首先是积极的情绪，然后是中性的，最后是负面的。请注意，二元分类器认为正面评论的百分比与平均评分提供的相同顺序大致一致。
- en: On the other hand, the average score for each label tells us how confident the
    predictions are on average that it belongs to said label. Joy, sadness, and surprise
    are the most confident. Since the multi-class predictions are seven numbers that
    add up to 1, an average score of 56.6% for anger is an indication that many predictions
    in which anger is the most probable emotion will have other emotions with a sizable
    probability – perhaps even emotions that may seem incompatible. We will put a
    pin on this because it would be interesting to explore this later.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，每个标签的平均分数告诉我们平均来说预测有多自信它属于该标签。快乐、悲伤和惊讶是最自信的。由于多类预测是七个加起来等于1的数字，愤怒的平均分数为56.6%表明，在愤怒是最可能情绪的许多预测中，其他情绪也可能有很大的概率——甚至可能是看似不兼容的情绪。我们将对此进行标记，因为这将会很有趣，以后可以探索这个问题。
- en: Another fascinating interpretation you can make of *Figure 8.3* is that a large
    proportion of surprise is negative, despite it being supposedly perceived to be
    a positive emotion. Also, with an average rating lower than 4, there are probably
    quite a few negative ratings weighing them down. We won’t explore the data in
    this chapter, but indeed, there are plenty of negative reviews that embody a sentiment
    of surprise. In light of this finding and for the sake of adapting to the mission,
    let’s say you presented this to your bosses, and they decided it made sense to
    focus on surprise because market research shows that people love to find and be
    surprised by “hidden gems.” Therefore, it’s critical that a recommendation engine
    can help unearth any restaurants that are positively surprising, while suppressing
    any that are consistently negatively surprising.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以对*图8.3*做出另一个有趣的解释，即尽管惊讶通常被认为是一种积极的情绪，但其中很大一部分是负面的。此外，平均评分低于4，可能有很多负面评分拖累了它们。我们不会在本章中探索数据，但确实有很多表达惊讶情绪的负面评论。鉴于这一发现，为了适应任务，假设你向老板展示了这一点，他们决定关注惊讶是有道理的，因为市场研究显示人们喜欢发现和被“隐藏的宝藏”所惊喜。因此，一个推荐引擎能够帮助挖掘任何令人惊喜的餐厅，同时抑制那些持续令人失望的餐厅，这是至关重要的。
- en: Loading the model
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载模型
- en: 'Later on, we will be randomly selecting from our dataset, so in order to do
    that consistently, it’s best to set a random seed. It’s always good practice to
    initialize the seed in all the pertinent libraries, even though in this case it
    won’t make a difference for PyTorch inference operations:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将从我们的数据集中随机选择，为了保持一致性，最好设置一个随机种子。在所有相关的库中初始化种子总是好的做法，尽管在这种情况下，它对PyTorch推理操作没有影响：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, let’s define a `device` variable because if you have a CUDA-enabled GPU,
    model inference will perform quicker. Then, we will load the tokenizer (`goemotions_tok`)
    and model (`goemotions_mdl`) from Hugging Face using the `from_pretrained` function.
    Lastly, we will move all the weights and biases to your device with the `model.to(device)`
    function and set the model to evaluation mode with `model.eval()`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们定义一个`device`变量，因为如果你有一个CUDA支持的GPU，模型推理将执行得更快。然后，我们将使用`from_pretrained`函数从Hugging
    Face加载分词器（`goemotions_tok`）和模型（`goemotions_mdl`）。最后，我们将使用`model.to(device)`函数将所有权重和偏差移动到你的设备上，并使用`model.eval()`将模型设置为评估模式：
- en: '[PRE6]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once the model is loaded, we always inspect its architecture with `print(goemotions_mdl)`.
    However, architecturally, in broad terms, what may matter most when interpreting
    transformer models is how many layers and attention heads they have. We can inspect
    that easily with the following snippet:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 模型加载后，我们总是使用`print(goemotions_mdl)`检查其架构。然而，在解释Transformer模型时，从广义上讲，最重要的是它们有多少层和注意力头。我们可以使用以下代码片段轻松检查：
- en: '[PRE7]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It should say that there are 12 layers and 12 attention heads. In the next section,
    we will dive into understanding how the attention mechanism works, and how to
    visualize the layers and heads with BertViz.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 应该说明的是，有12层和12个注意力头。在下一节中，我们将深入了解注意力机制的工作原理，以及如何使用BertViz可视化层和头：
- en: Visualizing attention with BertViz
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用BertViz可视化注意力
- en: What is attention? Let’s imagine you’re reading a book and come across a sentence
    that mentions a character you’ve read about earlier, but you’ve forgotten some
    details about them. Instead of going back and reading everything from the start,
    you’d likely skim through previous pages, focusing specifically on the parts that
    talk about this character. Your mind gives “attention” to the relevant information
    while filtering out the less relevant parts.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力是什么？让我们想象你正在阅读一本书，遇到一个提到你之前读过的角色的句子，但你忘记了关于他们的某些细节。你不太可能从头开始重新阅读，而是可能会快速浏览前面的页面，专注于具体讨论这个角色的部分。你的大脑会给予相关信息“注意力”，同时过滤掉不那么相关的部分。
- en: The attention mechanism in models like transformers works in a similar way.
    When processing information, it doesn’t treat all pieces of data equally. Instead,
    it “pays attention” to the most relevant parts, giving them more importance in
    the context of the current task. This ability to selectively focus on specific
    parts helps the model understand complex patterns and relationships in the data.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 变换器模型（如BERT）中的注意力机制以类似的方式工作。在处理信息时，它不会平等地对待所有数据片段。相反，它“关注”最相关的部分，在当前任务的上下文中给予它们更多的重视。这种选择性地关注特定部分的能力有助于模型理解数据中的复杂模式和关系。
- en: 'Transformers are made up of two main components: the encoder and the decoder.
    Each component leverages attention mechanisms, but they do so differently:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 变换器由两个主要组件组成：编码器和解码器。每个组件都利用注意力机制，但它们以不同的方式使用：
- en: '**Encoder**: The encoder’s job is to understand the input data. It does this
    by using an attention mechanism to figure out how each part of the input (like
    a word in a sentence) relates to all other parts. This allows the encoder to create
    a rich representation of the input that captures the relationships and context
    within it. It’s like reading a sentence and understanding what each word means
    in the context of that sentence.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编码器**: 编码器的任务是理解输入数据。它通过使用注意力机制来确定输入的每个部分（如句子中的一个单词）如何与其他所有部分相关联。这使得编码器能够创建一个丰富的输入表示，捕捉其中的关系和上下文。这就像阅读一个句子并理解在这个句子中每个单词的含义。'
- en: '**Decoder**: Once the encoder has created this representation, the decoder
    uses it to produce the output. The decoder also uses an attention mechanism, but
    it uses it in two ways. First, it pays attention to the encoder’s representation
    to understand what the input was. Second, it pays attention to its own previous
    outputs to make sure the current output is consistent with what it has produced
    so far. It’s like writing a sentence that makes sense based on what you read and
    what you’ve already written.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解码器**: 一旦编码器创建了这种表示，解码器就会使用它来生成输出。解码器还使用注意力机制，但以两种方式使用。首先，它关注编码器的表示来理解输入是什么。其次，它关注自己的先前输出，以确保当前输出与其迄今为止产生的输出一致。这就像根据你所读的和已经写下的内容来写一个有意义的句子。'
- en: 'However, not all transformer models have both components. In essence, the use
    case determines which parts of the transformer are needed:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并非所有变换器模型都具有这两个组件。本质上，用例决定了变换器需要哪些部分：
- en: '**Encoder models** (like BERT): These models only use the encoder component
    of the transformer. They are typically used for tasks that involve understanding
    the input data, like sentiment analysis (determining whether a text is positive
    or negative), named entity recognition (identifying people, organizations, and
    locations in text), or other classification tasks. This is because the encoder’s
    job is to create a representation of the input data that captures the relationships
    and context within it.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编码器模型**（如BERT）：这些模型只使用变换器的编码器组件。它们通常用于涉及理解输入数据的任务，如情感分析（确定文本是积极的还是消极的）、命名实体识别（在文本中识别人、组织和地点）或其他分类任务。这是因为编码器的任务是创建一个表示输入数据的表示，捕捉其中的关系和上下文。'
- en: '**Decoder models** (like GPT, LLaMa, etc.): These are used for tasks that involve
    generating new data, like text generation. The decoder part of the transformer
    ensures the generated output is consistent with what has been produced so far.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解码器模型**（如GPT、LLaMa等）：这些用于涉及生成新数据的任务，如文本生成。变换器的解码器部分确保生成的输出与迄今为止产生的输出一致。'
- en: '**Encoder-decoder models** (like FLAN): These are used for tasks that involve
    transforming one piece of data into another, like translation. The encoder understands
    the input, and the decoder generates the output.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编码器-解码器模型**（如 FLAN）：这些用于涉及将一块数据转换为另一块数据的任务，如翻译。编码器理解输入，解码器生成输出。'
- en: Now that we have covered attention models, let’s dive into BERT.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经涵盖了注意力模型，那么让我们深入探讨 BERT。
- en: '**BERT**, which stands for **Bidirectional Encoder Representations from Transformers**,
    is a type of transformer model developed by Google. It’s used to understand and
    analyze text data in a wide variety of languages. BERT is a transformer model
    that reads text bidirectionally to understand the context of words better. It
    only uses the encoder part of the transformer because its job is to understand
    text, not generate it. This makes BERT very effective for a wide range of tasks
    that involve understanding text.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**BERT**，代表**来自转换器的双向编码器表示**，是由 Google 开发的一种转换器模型。它用于理解和分析各种语言的文本数据。BERT 是一种读取文本双向以更好地理解单词上下文的转换器模型。它只使用转换器的编码部分，因为它的任务是理解文本，而不是生成文本。这使得
    BERT 对于涉及理解文本的广泛任务非常有效。'
- en: So, our BERT transformer model has 12 layers and 12 attention heads. But what
    do these do, and how do they work?
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的 BERT 转换器模型有 12 层和 12 个注意力头。但这些是什么，它们是如何工作的呢？
- en: '**BERT layers**: The 12 hidden layers are BERT layers, and these are a stack
    of other layers that make up this encoder transformer. Much like with convolutional
    layers in a CNN, like the one we examined in *Chapter 7*, *Visualizing Convolutional
    Neural Networks*, BERT layers represent layers of abstraction. As the input data
    progresses through layers, the model learns increasingly abstract representations
    of the data. In the context of text, the lower layers might capture basic syntactic
    information, like the role of a word in a sentence. As you move up through the
    layers, they tend to capture higher-level semantics, such as overall sentence
    meaning or themes. The number of layers, called the depth of the model, often
    correlates with its ability to understand context and represent complex relationships.
    However, more layers also require more computational resources and might be more
    prone to overfitting if not enough data is available.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BERT 层**：12 个隐藏层是 BERT 层，这些层是构成这个编码器转换器的其他层的堆叠。与我们在*第 7 章*中检查的 CNN 中的卷积层类似，*可视化卷积神经网络*，BERT
    层代表抽象层。随着输入数据通过层传递，模型学习数据的越来越抽象的表示。在文本的上下文中，底层可能捕获基本句法信息，如单词在句子中的作用。随着你向上移动到层，它们倾向于捕获更高级别的语义，如整体句子意义或主题。层的数量，称为模型的深度，通常与其理解上下文和表示复杂关系的能力相关。然而，更多的层也需要更多的计算资源，并且如果没有足够的数据，可能会更容易过拟合。'
- en: '**Attention head**: The self-attention mechanism is the heart of any transformer
    model. The attention head has several self-attention mechanisms working in parallel.
    Inside the **multi-head self-attention mechanism**, there are multiple independent
    attention heads working in parallel. Each attention head learns to focus on different
    parts of the input data (like different relationships between tokens, which are
    usually the words). Having multiple attention heads allows the model to capture
    various types of relationships simultaneously. For example, one head might focus
    on the relationship between adjectives and nouns, while another might capture
    verb-subject relationships. After each head computes its own attention-weighted
    value representation, the outputs from all heads are concatenated and linearly
    transformed to produce the final value representation for the next layer.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**注意力头**：自注意力机制是任何转换器模型的核心。注意力头包含几个并行工作的自注意力机制。在**多头自注意力机制**内部，有多个独立的注意力头并行工作。每个注意力头都学会关注输入数据的不同部分（如不同标记之间的关系，这些通常是指单词）。拥有多个注意力头允许模型同时捕捉各种类型的关系。例如，一个头可能关注形容词和名词之间的关系，而另一个头可能捕捉动词-主语关系。在每个头计算其自己的注意力加权值表示之后，所有头的输出被连接起来并线性转换，以产生下一层的最终值表示。'
- en: 'Let’s use some real reviews to examine the inner workings of the GoEmotions
    model. To that end, we will take four sample reviews and print out their details
    using the following code. While we are at it, we will save the sample reviews
    in a dictionary (`sample_reviews_dict`) so we can reference them later:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用一些真实的评论来检查GoEmotions模型的内部工作原理。为此，我们将取四个样本评论，并使用以下代码打印它们的详细信息。在此过程中，我们将样本评论保存到字典（`sample_reviews_dict`）中，以便以后参考：
- en: '[PRE8]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](img/B18406_08_04.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_08_04.png)'
- en: 'Figure 8.4: A few sample surprise reviews in the dataset'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4：数据集中的一些样本惊喜评论
- en: As you can see in *Figure 8.4*, the commonality between all the review samples
    is surprise, both negative and positive.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*图8.4*中看到的，所有评论样本的共同点是惊喜，无论是积极的还是消极的。
- en: Next, we will leverage BertViz, which, despite the name, can visualize attention
    for encoder-only transformer models (like BERT and all variants), decoder-only
    transformers (like GPT and all variants), and encoder-decoder transformers (like
    T5). It’s very flexible, but it’s important to note that it’s an interactive tool,
    so the print screens represented by the figures in this section won’t do it justice.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将利用BertViz，尽管名字叫这个名字，但它可以可视化仅编码器transformer模型（如BERT及其所有变体）、仅解码器transformer（如GPT及其所有变体）以及编码器-解码器transformer（如T5）的注意力。它非常灵活，但重要的是要注意，它是一个交互式工具，所以本节中用图表示的打印屏幕并不能完全体现其功能。
- en: 'Next, we will create a function that, with the tokenizer, model, and a tuple
    of sentences, can create two different kinds of BertViz visualizations:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个函数，该函数使用分词器、模型和句子元组，可以创建两种不同的BertViz可视化：
- en: '[PRE9]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To visualize attention, we will need to take a pair of input `sentences` and
    encode them with our tokenizer (`inputs`). Then, we extract the token IDs for
    these inputs (`input_ids`) and values, which indicate what sentence each token
    belongs to (`token_type_ids`) – in other words, `0` for the first sentence and
    `1` for the second sentence. We then pass the inputs (`input_ids` and `token_type_ids`)
    to the model and extract the `attention` weights. Finally, there are two BertViz
    visualizers, `head_view` and `model_view`, and for them to work, all we need is
    the `attention` weights produced by our inputs, the token IDs converted to `tokens`,
    and the position for when the second sentence begins (`sentence_b_start`).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化注意力，我们需要取一对输入`句子`并使用我们的分词器（`inputs`）对它们进行编码。然后，我们提取这些输入的标记ID（`input_ids`）和值，这些值表示每个标记属于哪个句子（`token_type_ids`）——换句话说，`0`代表第一句话，`1`代表第二句话。然后，我们将输入（`input_ids`和`token_type_ids`）传递给模型并提取`attention`权重。最后，有两个BertViz可视化器，`head_view`和`model_view`，为了使它们工作，我们只需要我们的输入产生的`attention`权重，将标记ID转换为`tokens`，以及第二句话开始的`position`（`sentence_b_start`）。
- en: Next, we will visualize attention throughout the model with the *model view*.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用`model view`在整个模型中可视化注意力。
- en: Plotting all attention with the model view
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用模型视图绘制所有注意力
- en: '[PRE10]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The preceding lines of code create a large plot, like the one portrayed in
    *Figure 8.5*:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码创建了一个大图，就像*图8.5*中描绘的那样：
- en: '![](img/B18406_08_05.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_08_05.png)'
- en: 'Figure 8.5: The model view for the 1st sample review for 2nd Avenue Deli'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5：2nd Avenue Deli的第一个样本评论的模型视图
- en: '*Figure 8.5* is a 12 x 12 grid with every attention head in the BERT model.
    We can click on any attention head to see both sentences in the BERT input, with
    lines drawn between them to represent the attention weights from one token (left)
    to another (right). We can select “Sentence A -> Sentence A”, “Sentence A -> Sentence
    B,” and every combination in between to view only a subset of all the attention
    weights. Lines for weights closest to one appear as very opaque, while weights
    close to zero show as transparent to the point of not being visible at all.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8.5*是一个12 x 12的网格，其中包含了BERT模型中的每个注意力头。我们可以点击任何注意力头来查看BERT输入中的两个句子，它们之间有线条相连，代表从左边的标记（一个句子）到右边的标记（另一个句子）的注意力权重。我们可以选择“Sentence
    A -> Sentence A”、“Sentence A -> Sentence B”以及所有介于两者之间的组合，以查看所有注意力权重的一个子集。权重接近一的线条看起来非常不透明，而接近零的权重则显示为透明，以至于几乎看不见。'
- en: 'At a glance, we can tell that some attention heads have more lines, thicker
    lines, or lines that seem to go more in one direction than another. We can click
    on individual attention heads to examine them individually – for instance:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一眼就能看出，有些注意力头有更多的线条、更粗的线条，或者看起来比另一个方向更明显的线条。我们可以点击单个注意力头来单独检查它们——例如：
- en: '**Layer 1 Head 11** is mostly attention, moving forward from one token to the
    following token in the same sentence. This is a very common pattern and makes
    complete logical sense because we read English left to right and understand it
    mostly in that order, although there are, of course, other patterns that are undoubtedly
    in the attention heads. We also see evidence of another common pattern, which
    is one or several tokens with attention weights toward the `[CLS]` token. The
    `[CLS]` token is a special token that is prepended to every input sequence when
    using BERT-like models for classification tasks. It’s often used to get the aggregate
    representation of the entire sequence for classification. This means that for
    this particular attention head, the token serves a purpose in the classification
    decision. This can be especially insightful when trying to understand which words
    in a sequence the model deems critical for classification decisions. When attention
    goes from a separator token `[SEP]` to the classification token `[CLS]`, it could
    be seen as the model recognizing the end of a context or sentence and reflecting
    its semantic conclusion, to perhaps influence the classification decision.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**层1头部11** 主要关注，从同一句子中的一个标记移动到下一个标记。这是一个非常常见的模式，并且完全符合逻辑，因为我们从左到右阅读英语，并且主要按照这个顺序理解它，尽管当然还有其他无疑在注意力头部中的模式。我们还看到了另一个常见模式的证据，即一个或多个标记对
    `[CLS]` 标记具有注意力权重。`[CLS]` 标记是一个特殊的标记，在为分类任务使用类似 BERT 的模型时，会添加到每个输入序列的开头。它通常用于获取整个序列的聚合表示，以便进行分类。这意味着对于这个特定的注意力头部，标记在分类决策中起着作用。当注意力从分隔符标记
    `[SEP]` 转移到分类标记 `[CLS]` 时，这可以被视为模型识别上下文或句子的结束，并反映其语义结论，从而可能影响分类决策。'
- en: '**Layer 9 Head** seems to perform a more complicated task, which is to relate
    words to “great” and “surprised,” even across sentences. This is another common
    pattern where connecting words predict a word.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**层9头部** 似乎执行一个更复杂的任务，即关联单词与“伟大”和“惊讶”，甚至跨越句子。这是另一个常见模式，其中连接的单词预测一个单词。'
- en: Take note of patterns in the attention heads, and notice a few others, like
    attention moving backward in a sentence, or connecting synonyms. Then, change
    the zero in `sample_reviews_dict[0]` to one, two, or three to see if the attention
    heads show the same pattern. The samples are quite different, but if the attention
    heads are not doing the same thing, chances are they are doing something remarkably
    similar. However, for the bigger picture, it’s probably best to squint your eyes
    and see what kind of patterns are evident across different layers.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 注意注意力头部中的模式，并注意一些其他模式，比如句子中的注意力向后移动，或者连接同义词。然后，将 `sample_reviews_dict[0]` 中的零改为一、二或三，看看注意力头部是否显示相同的模式。样本相当不同，但如果注意力头部没有做相同的事情，那么它们可能正在做非常相似的事情。然而，对于更大的图景，最好眯起眼睛，看看不同层中明显的模式。
- en: Next, we will make this task easier with the head view.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过头部视图使这个任务变得更简单。
- en: Diving into layer attention with the head view
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过头部视图深入层注意力
- en: 'We can start by choosing the first sample with the following code:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下代码开始选择第一个样本：
- en: '[PRE12]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We can select any of the 12 layers (0–11). Line transparency means the same
    thing it did with the model view. However, the difference is we can isolate individual
    token attention weights by clicking on them, so when we select any token on the
    left, we’ll see lines connect with tokens on the right. Also, color-coded boxes
    will appear on the right, representing how much attention weight is in each of
    the 12 attention heads.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择12层中的任何一层（0-11）。线条透明度意味着与模型视图相同的意思。然而，区别在于我们可以通过点击它们来隔离单个标记的注意力权重，因此当我们选择左侧的任何标记时，我们会看到线条与右侧的标记相连。此外，右侧将出现彩色编码的方框，表示每个12个注意力头部中每个的注意力权重。
- en: 'And if we happen to select any token on the right, we’ll get all the attention
    that is directed to it from the left tokens. In *Figure 8.6*, we can see examples
    of how several of the sample sentences would appear:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们恰好选择右侧的任何标记，我们将获得来自左侧标记的所有指向它的注意力。在 *图8.6* 中，我们可以看到几个样本句子如何出现：
- en: '![](img/B18406_08_06.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_08_06.png)'
- en: 'Figure 8.6: The head view for samples 1, 2, and 4'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6：样本1、2和4的头部视图
- en: In *Figure 8.6*, see how we can drill down on patterns just as we did with model
    view. For instance, we can examine different patterns of attention, from related
    words that are next to each other (“great sandwich” and “albeit quite expensive”)
    to those that have a relationship only in the context of the sentence (“sandwich”
    and “expensive”), or even across sentences (“bad” and “ignored,” “chef,” and “menu”).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图8.6*中，看看我们如何像处理模型视图一样深入挖掘模式。例如，我们可以检查不同的注意力模式，从相邻的相关的单词（“伟大的三明治”和“尽管相当昂贵”）到仅在句子上下文中存在关系的那些（“三明治”和“昂贵”），甚至跨句子（“坏”和“被忽视的”，“厨师”和“菜单”）。
- en: By doing this, we can realize that visualizing attention heads is not just for
    curiosity’s sake but can also help us understand how a model connects the dots
    between words, thus accomplishing a downstream task like classification. Perhaps
    this can help us understand what to do next, whether it’s to fine-tune the model
    further with underrepresented words and situations, or prepare the data differently
    to stop the model from getting confused by a particular word or set of words.
    However, given the complexity of attention heads finding model issues, this can
    be like looking for a needle in a haystack. We only started with layers and attention
    heads in this chapter because it provides an intuitive way of understanding how
    transformers encode relationships between tokens.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样做，我们可以意识到可视化注意力头不仅仅是出于好奇，还可以帮助我们理解模型如何将单词之间的点连接起来，从而完成下游任务，如分类。也许这可以帮助我们了解下一步该做什么，无论是进一步微调模型以包含代表性不足的单词和情况，还是以不同的方式准备数据，以防止模型被特定的单词或一组单词所困惑。然而，考虑到注意力头的复杂性，寻找模型问题就像在
    haystack 中找针一样。我们之所以在本章中从层和注意力头开始，是因为它提供了一种直观的方式来理解变压器如何编码标记之间的关系。
- en: A better way to start would be with attributions. An attribution method is a
    method that will compute how much a part of an input contributed to a model’s
    prediction for that input. In the case of images in *Chapter 7*, *Visualizing
    Convolutional Neural Networks*, the part of the input we compute attributions
    for is pixels. For text, the equivalent would be tokens, which in this case are
    made up of (mostly) words, so next, we will generate token attributions.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更好的开始方式是使用归因。归因方法是一种将计算输入的一部分对模型预测的贡献程度的方法。在第7章中，关于*可视化卷积神经网络*的图像中，我们计算归因的输入部分是像素。对于文本，等效的部分是标记，在这种情况下，由（主要是）单词组成，所以接下来，我们将生成标记归因。
- en: Interpreting token attributions with integrated gradients
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用集成梯度解释标记归因
- en: 'Integrated gradients is a popular method, and in *Chapter 7*, we explained
    and leveraged it to produce attributions for each pixel in an image. The method
    has the same steps:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 集成梯度是一种流行的方法，在*第7章*中，我们解释并利用它为图像中的每个像素生成归因。该方法具有相同的步骤：
- en: '**Choose a baseline input**: The baseline represents no information. For images,
    it is usually a solid black image. For text, this could be a sentence with all
    words replaced by a placeholder like `[PAD]` or just an empty sentence.'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择一个基线输入**：基线代表没有信息。对于图像，通常是一个纯黑色图像。对于文本，这可能是一个所有单词都被占位符如`[PAD]`替换的句子，或者只是一个空句子。'
- en: '**Gradually change this baseline input** into your actual input sentence (e.g.,
    the review), step by step. At each step, you change a little bit of the baseline
    toward the actual input.'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**逐步将这个基线输入**变为实际的输入句子（例如，评论），一步一步地。在每一步中，你将基线稍微改变一点，使其接近实际输入。'
- en: '**Compute output changes**: For each step, calculate how much the model’s prediction
    changes.'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算输出变化**：对于每一步，计算模型预测的变化量。'
- en: '**Sum up all these changes** for each word in the sentence. This gives you
    a score for each word, indicating how much it contributed to the model’s final
    prediction.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**总结句子中每个单词的所有变化**。这将为每个单词提供一个分数，表示它对模型最终预测的贡献程度。'
- en: 'However, before we can use integrated gradients, it’s best that we define a
    transformer pipeline that tokenizes the input and performs inference on the model
    in one step:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们能够使用集成梯度之前，最好定义一个将输入分词并在一步中执行模型推理的变压器管道：
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You can test the `goemotions` pipeline like this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以这样测试`goemotions`管道：
- en: '[PRE14]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'It should output the following list of lists of dictionaries:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 应该输出以下列表的列表字典：
- en: '[PRE15]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see, in the first list, there are two predictions (one for each text),
    and each prediction has a list with seven dictionaries, with one that has the
    score for each class. Since the dictionaries are sorted from the highest score
    to the lowest, you can tell that the first restaurant review was mostly predicted
    as disgust and the second as joy at 66%, but there was also a sizable amount of
    surprise.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，在第一个列表中，有两个预测（每个文本一个），每个预测都有一个包含七个字典的列表，其中一个字典包含每个类别的分数。由于字典是按最高分数到最低分数排序的，您可以判断第一个餐厅评论主要被预测为厌恶，第二个评论为喜悦，占66%，但也有相当数量的惊讶。
- en: 'Next, we will create a function that can take any DataFrame row with our review
    and our transformer, and generate and output attributions for every prediction
    with over 10% probability:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个函数，该函数可以接受任何包含我们的评论和我们的转换器的DataFrame行，并为每个超过10%概率的预测生成和输出归因：
- en: '[PRE16]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'It may seem complicated by the amount of code, but there are plenty of steps
    that are relatively straightforward when explained individually. We will start
    with model inference and work our way down:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然代码量看起来很复杂，但单独解释时，有很多步骤相对简单。我们将从模型推理开始，逐步进行：
- en: '**Get predictions**: This is a very straightforward step. It just feeds the
    `text` into the pipeline (`pline`). It takes only the first item returned (`[0]`)
    because it only anticipates one prediction being inputted and, thus, returned
    by the pipeline. The next few lines show what the model does if the function **receives**
    a `sample_df`, which it only really needs to sort the predictions in the order
    of the best rating on average.'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**获取预测结果**：这是一个非常直接的步骤。它只需将`text`输入到管道（`pline`）中。它只取返回的第一个项目（`[0]`），因为它只预期输入并由此通过管道返回一个预测。接下来的几行显示了如果函数**接收**到`sample_df`，模型会做什么，它实际上只需要按平均最佳评分的顺序对预测进行排序。'
- en: '**Process predictions**: Here, the code makes sure predictions are sorted and
    in tuples for easier iteration in the `for` loop that follows later.'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**处理预测**：在这里，代码确保预测被排序并放入元组中，以便在后续的`for`循环中更容易迭代。'
- en: '**Initialize integrated gradients**: A forward function is defined, which takes
    inputs and returns the model’s output for a given position, as well as a layer
    for which the attributions will be calculated, which in this case is the embedding
    layer. Then, an instance of `LayerIntegratedGradients` (`lig`) is initialized
    with the forward function and the specified layer.'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**初始化集成梯度**：定义了一个正向函数，它接受输入并返回给定位置的模型输出，以及一个用于计算归因的层，在这个例子中是嵌入层。然后，使用正向函数和指定的层初始化一个`LayerIntegratedGradients`（`lig`）实例。'
- en: '**Prepare tokens and baseline**: First, the text is tokenized and converted
    into a tensor, which is then moved to the specified device. Then, the token IDs
    are converted back to `tokens` for potential visualization or analysis. A `baseline`
    is created for the integrated gradients method. It consists of `[CLS][ token at
    the start, ]{custom-style="P - Code"}[SEP][ token at the end, and ]{custom-style="P
    - Code"}[PAD][ tokens in the middle matching the length of the input ]{custom-style="P
    - Code"}text`.'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准备标记和基线**：首先，对文本进行标记并转换为张量，然后将其移动到指定的设备。然后，将标记ID转换回`tokens`，以供潜在的视觉化或分析使用。为集成梯度方法创建一个`baseline`。它由`[CLS][
    token at the start, ]{custom-style="P - Code"}[SEP][ token at the end, and ]{custom-style="P
    - Code"}[PAD][ tokens in the middle matching the length of the input ]{custom-style="P
    - Code"}text`组成。'
- en: '**Iterate over every prediction**: Here’s the `for` loop that iterates over
    every prediction as long as the probability is over 10%, as defined by `max_prob_threshold`.
    Within the `for` loop, we:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**遍历每个预测**：这是一个`for`循环，它遍历每个预测，只要概率超过由`max_prob_threshold`定义的10%，我们将在循环中进行以下操作：'
- en: '**Set the target class**: Integrated gradients is a directed attribution method,
    so we need to know what `target` class to generate attributions for; therefore,
    we need the ID that was used internally by the model for the predicted class.'
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置目标类别**：集成梯度是一种有向归因方法，因此我们需要知道为哪个`target`类别生成归因；因此，我们需要模型内部用于预测类别的ID。'
- en: '**Get the attributions**: Using the very same Captum `attribute` method we
    used in *Chapter 7*, we generate the IG attributions for the tokenized version
    of our text (`inputs`), the `baselines`, the `target`, and decide whether to return
    a delta (a measure of approximation error) of the IG method (`return_convergence_delta`).'
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**获取归因**：使用与*第7章*中使用的相同的Captum `attribute`方法，我们为我们的文本（`inputs`）、基线、目标和决定是否返回IG方法的增量（一个近似误差的度量）生成IG归因。'
- en: '**Post-process the attributions**: the attributions returned by the IG method
    are of the shape (`num_inputs`, `sequence_length`, `embedding_dim`), where `embedding_dim=768`
    for this model, `sequence_length` corresponds to the number of tokens in the input,
    and `num_inputs=1` because we only perform one attribution at a time. So each
    token’s embedding has an attribution score, but what we need is one attribution
    per token. Therefore, these scores are summed across the embedding dimension to
    get a single attribution value for each token in the sequence. Then, the attributions
    are normalized, ensuring that the attributions have a magnitude between 0 and
    1 and are in a comparable scale. Finally, the attributions are detached from the
    computation graph, moved to the CPU, and converted to a `numpy` array for further
    processing or visualization.'
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**后处理归因**：IG方法返回的归因形状为 (`num_inputs`, `sequence_length`, `embedding_dim`)，其中对于此模型，`embedding_dim=768`，`sequence_length`对应输入中的标记数量，而`num_inputs=1`，因为我们一次只执行一个归因。因此，每个标记的嵌入都有一个归因分数，但我们需要的每个标记一个归因。因此，这些分数在嵌入维度上求和，以得到序列中每个标记的单个归因值。然后，对归因进行归一化，确保归因的幅度在0到1之间，并且处于可比较的尺度。最后，将归因从计算图中分离出来，移动到CPU，并转换为`numpy`数组以进行进一步处理或可视化。'
- en: '**Generate and append the Visualization Data Record**: Captum has a method
    called `VisualizationDataRecord`, which creates a record of each attribution for
    visualization purposes, so what we do in this step is create these records with
    the attributions, deltas, tokens, and metadata related to the prediction. It then
    appends this data record to a list.'
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生成并附加可视化数据记录**：Captum有一个名为`VisualizationDataRecord`的方法，用于创建每个归因的记录以供可视化，因此在这一步中，我们使用这些归因、增量、标记和与预测相关的元数据创建这些记录。然后，将此数据记录附加到列表中。'
- en: '**Display the list of Visualization Data Records**: leverage `visualize_text`
    to display the list of records.'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**显示可视化数据记录列表**：利用`visualize_text`显示记录列表。'
- en: 'Now, let’s create some samples to perform integrated gradient attributions
    on:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一些样本以执行集成梯度归因：
- en: '[PRE17]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the above snippet, we take all surprise reviews with a probability over 90%,
    but to ensure that they are negative, we will select a negative sentiment and
    a rating below three. Then, we will take a random sample of 10 reviews from these.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码片段中，我们选取所有概率超过90%的惊喜评论，但为了确保它们是负面的，我们将选择一个负面情感和低于三的评分。然后，我们将从这些评论中随机抽取10条。
- en: Next, we will iterate across every review in this list and generate some visualizations.
    A few others are shown in the screenshot in *Figure 8.7:*
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将遍历列表中的每个评论并生成一些可视化。其他一些可视化显示在*图8.7*的屏幕截图上：
- en: '[PRE18]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](img/B18406_08_07.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_08_07.png)'
- en: 'Figure 8.7: IG visualizations for negative surprises'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7：IG可视化对于负面惊喜
- en: As we can see in *Figure 8.7*, the surprise prediction is attributed to words
    like “shocked,” “realized,” and “mystery” and phrases like “not sure how.” These
    all make sense because they indicate that something is unknown. Naturally, there
    are also a few cases where the word “surprise” or “surprised” is all it takes
    to get a surprise prediction. However, sometimes it’s not that simple. In the
    last one, it’s not one word that appears to indicate surprise but many words,
    saying to the effect that something doesn’t add up. More specifically, these visitors
    from London were very surprised that a deli in New York City was so expensive.
    Please note that the color coding for “Negative” and “Positive” doesn’t mean that
    a word is negative or positive but, rather, it’s weighting against (negatively)
    or in favor (positively) of the attribution label.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图8.7*所示，惊喜预测归因于“震惊”、“意识到”和“神秘”等单词，以及“不确定如何”等短语。这些都很有意义，因为它们表明某件事是未知的。自然地，也有一些情况，单词“surprise”或“surprised”就足以得到惊喜预测。然而，有时事情并不那么简单。在最后一个例子中，并不是一个单词似乎表明了惊喜，而是许多单词，大意是某件事不协调。更具体地说，这些来自伦敦的游客对纽约市的一家熟食店如此昂贵感到非常惊讶。请注意，“负面”和“正面”的颜色编码并不意味着一个单词是负面的或正面的，而是它对（负面）或有利于（正面）归因标签的权重。
- en: 'Next, we are going to repeat code similar to what we ran to generate IG explanations
    for a sample of surprise negative reviews, but this time for positive reviews.
    To ensure that they are positive, we will use ratings above 4\. This time, we
    will make sure to remove any reviews with the word “surprise” from the samples
    just to make things interesting:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将重复运行与生成样本惊喜负面评论的IG解释相似的代码，但这次是为了正面评论。为了确保它们是正面的，我们将使用4分以上的评分。这次，我们将确保从样本中移除包含“惊喜”一词的任何评论，以使事情更有趣：
- en: '[PRE19]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The preceding code will produce the visualizations in *Figure 8.8*.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码将在*图8.8*中生成可视化。
- en: '![](img/B18406_08_08.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图8.8](img/B18406_08_08.png)'
- en: Figure 8.8\. IG visualizations for positive surprises
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8：积极惊喜的IG可视化
- en: '*Figure 8.8* shows how the words “perplexed” and “unbelievable,” as well as
    the phrase “couldn’t believe how” indicate surprise. There are also a few cases
    of tokens weighing negatively against the surprise prediction. For instance, for
    the last restaurant, having “something for everyone” doesn’t make it very surprising.
    Also, you’ll note the Japanese restaurant in the middle is predicted to embody
    both surprise and joy emotions. It’s interesting how some words correlate with
    one emotion but not so much with another, and sometimes they indicate the opposite,
    like the “hard” in “it’s very hard to find a place” indicating surprise but not
    joy.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8.8*展示了“困惑”和“难以置信”等单词，以及“难以置信的是”这样的短语如何表明惊喜。还有一些情况，标记对惊喜预测有负面影响。例如，对于最后一家餐厅，“适合每个人”并不使其非常令人惊讶。此外，您会注意到中间的日本餐厅被预测为同时体现惊喜和快乐情绪。有趣的是，有些单词与一种情绪相关，但与另一种情绪不太相关，有时它们甚至表示相反的意思，比如“很难找到地方”中的“hard”表示惊喜但不表示快乐。'
- en: 'Finding reviews with mixed sentiments like the Japanese restaurant might hold
    some answers to why some reviews are hard to classify entirely with one sentiment.
    So, now, we will produce some positive and negative mixed review samples. We can
    easily do so by making sure that the score for the predicted label is never over
    50%:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 找到像日本餐厅这样的混合情感评论可能有助于解释为什么有些评论难以完全用单一情感进行分类。因此，现在我们将生成一些正负混合评论样本。我们可以通过确保预测标签的分数永远不会超过50%来轻松做到这一点：
- en: '[PRE20]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The preceding code will produce the IG visualization and polar line plot in
    *Figure 8.9*:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码将在*图8.9*中生成IG可视化和极线图：
- en: '![](img/B18406_08_09.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图8.9](img/B18406_08_09.png)'
- en: 'Figure 8.9: IG visualizations for mixed sentiment reviews'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9：混合情感评论的IG可视化
- en: '*Figure 8.9* portrays how this review for a sandwich shop appears to have joy,
    fear, and neutral emotions. The words “terrific” and “friendly” connect with joy,
    but they don’t with neutral. However, strangely, the word “terrific” also correlates
    with fear. Perhaps it has to do with the WordPiece tokenization performed on the
    word. Note that “terrific” appears as three subword tokens, te, ##rri, and ##fic.
    This probably happened because the original corpus used to train the model (the
    Reddit comments) didn’t have enough frequency for “terrific” to include it as
    a standalone word, but these subwords did. The downside to this technique is that
    it’s possible that the “te” and “rri” tokens are used often for words like “terrifying,”
    and “fic” in other scary words like “horrific” and “mortific.” On the other hand,
    “fic” appears in “magnificent” and “beneficial.” So what happens is that despite
    the contextual embeddings, the subword tokens can cause some ambiguities.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8.9*展示了这家三明治店的评论似乎表现出快乐、恐惧和中性情绪。单词“terrific”和“friendly”与快乐相连，但与中性不相干。然而，奇怪的是，“terrific”这个词也与恐惧相关。也许这与对这个词进行的WordPiece分词有关。注意，“terrific”以三个子词标记出现，分别是te、##rri和##fic。这很可能是因为用于训练模型的原语料库（Reddit评论）中“terrific”这个词的频率不够高，无法将其作为独立单词包含，但这些子词却包含了。这种技术的缺点是，可能“te”和“rri”标记经常用于像“terrifying”这样的单词，以及像“horrific”和“mortific”这样的其他可怕单词中的“fic”。另一方面，“fic”出现在“magnificent”和“beneficial”中。所以，尽管有上下文嵌入，子词标记可能会引起一些歧义。'
- en: We can now run the same code as before but for `neg_mixed_samp_df`, to examine
    other examples and make our own conclusions. Next, we can expand our XAI NLP-specific
    toolset with the LIT.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以运行与之前相同的代码，但针对`neg_mixed_samp_df`，以检查其他示例并得出自己的结论。接下来，我们可以使用LIT扩展我们的XAI
    NLP特定工具集。
- en: LIME, counterfactuals, and other possibilities with the LIT
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LIT、反事实以及其他可能性
- en: The LIT is an open-source platform developed by the **People+AI Research** (**PAIR**)
    initiative to visualize and understand NLP models. PAIR developed the What-If
    Tool featured in *Chapter 6*, *Anchors and Counterfactual Explanations*.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: LIT是一个由**People+AI Research**（**PAIR**）倡议开发的开源平台，用于可视化和理解NLP模型。PAIR开发了第6章中特色展示的“如果工具”（What-If
    Tool）。
- en: 'LIT provides an interactive and visual interface to delve deep into NLP model
    behavior. With LIT, users can:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: LIT提供了一个交互式和可视化的界面，以便深入探究NLP模型的行为。使用LIT，用户可以：
- en: Identify types of examples where a model underperforms.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别模型表现不佳的示例类型。
- en: Determine reasons behind specific model predictions.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定特定模型预测背后的原因。
- en: Test the model’s consistency under textual variations, like style, verb tense,
    or pronoun gender.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试模型在文本变化（如风格、动词时态或代词性别）下的一致性。
- en: LIT offers various built-in capabilities, including salience maps, attention
    visualization, metrics calculations, and counterfactual generation. However, it
    also supports customization, allowing the addition of specialized interpretability
    techniques, visualizations, and more.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: LIT提供了各种内置功能，包括显著性图、注意力可视化、指标计算和反事实生成。然而，它也支持定制，允许添加专门的解释性技术、可视化等。
- en: Although LIT’s primary focus is textual language data, it also supports models
    that operate on image and tabular data. It’s compatible with a range of machine
    learning frameworks, including TensorFlow and PyTorch. The tool can run both as
    a standalone server and within notebook environments like Colab, Jupyter, and
    Google Cloud Vertex AI notebooks.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LIT的主要关注点是文本语言数据，但它也支持在图像和表格数据上操作的模式。它与包括TensorFlow和PyTorch在内的多种机器学习框架兼容。该工具可以作为独立服务器运行，也可以在Colab、Jupyter和Google
    Cloud Vertex AI笔记本等笔记本环境中运行。
- en: 'In order to work with any custom dataset, LIT provides a `Dataset` subclass
    to create a LIT-compatible dataset loader. You must include an `__init__`, which
    loads the dataset, and a spec function, which specifies the data types returned
    in the dataset, while the `lit_nlp.api.types` provide a way to ensure that LIT
    recognizes each feature in your dataset. In this case, we provide the review (`TextSegment`),
    the label (`CategoryLabel`) with the seven labels, and two additional categories,
    which can be used for slicing and binning:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与任何自定义数据集一起工作，LIT提供了一个`Dataset`子类来创建一个兼容LIT的数据集加载器。您必须包含一个`__init__`，它加载数据集，以及一个spec函数，它指定数据集中返回的数据类型，而`lit_nlp.api.types`提供了一种确保LIT识别您数据集中的每个特征的方法。在这种情况下，我们提供了评论（`TextSegment`），标签（`CategoryLabel`）以及七个标签，以及两个额外的类别，这些类别可用于切片和分箱：
- en: '[PRE22]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To make LIT flexible to accommodate any model, there is a `Model` subclass
    to make a LIT-compatible model loader. It also needs the `__init__` function to
    initialize the model, as well as a `predict_minibatch` function to predict with
    it. To this end, we also need to create specs for both the inputs (`input_spec`)
    and outputs (`output_spec`) of the `predict` function. In this case, we enter
    a review (of type `TextSegment`) and return probabilities of type `MulticlassPreds`.
    Remember that the output of the model is not always consistent, since each prediction
    is arranged from the highest to the lowest score. Note that in order to make the
    output of `predict_minibatch` comply with the `MulticlassPreds`, we have to arrange
    the probabilities as a list corresponding to the labels (`GE_LABELS`), in the
    same order provided to `vocab`:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使LIT能够适应任何模型，有一个`Model`子类来创建一个LIT兼容的模型加载器。它还需要`__init__`函数来初始化模型，以及一个`predict_minibatch`函数来使用它进行预测。为此，我们还需要为`predict`函数的输入（`input_spec`）和输出（`output_spec`）创建规范。在这种情况下，我们输入一个评论（类型为`TextSegment`），并返回类型为`MulticlassPreds`的概率。请注意，模型的输出并不总是一致的，因为每个预测都是从最高分到最低分排列的。注意，为了使`predict_minibatch`的输出符合`MulticlassPreds`，我们必须将概率作为与标签（`GE_LABELS`）相对应的列表排列，与提供给`vocab`的顺序相同：
- en: '[PRE23]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'OK, so now we have the two classes we need for LIT to function. The GoEmotions
    model initializer (`GEModel`) takes the model (`goemotions_mdl`) and tokenizer
    (`goemotions_tok`). We put these in a dictionary because LIT can take more than
    one model and more than one dataset to compare them. For the dataset, to make
    it load quickly, we will use 100 samples (`samples100_df`), made up of the four
    10-sample DataFrames we have created so far, plus 60 additional random samples
    from the entire reviews dataset. Then, we just input our 100-sample DataFrame
    into the GoEmotions dataset initializer (`GEDataset`) and place it into our datasets
    dictionary as `NYCRestaurants`. Lastly, we create the widget (`notebook.LitWidget`)
    by inputting our model and datasets dictionaries and `render` it. Please note
    that if you want to run this outside of a notebook environment, you can use the
    `Server` command to have it run on a LIT server:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们拥有了LIT运行所需的两个类。GoEmotions模型初始化器（`GEModel`）接收模型（`goemotions_mdl`）和分词器（`goemotions_tok`）。我们将这些放入字典中，因为LIT可以接受多个模型和多个数据集进行比较。对于数据集，为了使其快速加载，我们将使用100个样本（`samples100_df`），由我们迄今为止创建的四个10样本DataFrame组成，再加上从整个评论数据集中随机抽取的60个额外样本。然后，我们将我们的100样本DataFrame输入到GoEmotions数据集初始化器（`GEDataset`）中，并将其放置到我们的数据集字典中，命名为`NYCRestaurants`。最后，我们通过输入我们的模型和数据集字典以及`render`它来创建小部件（`notebook.LitWidget`）。请注意，如果您想在笔记本环境之外运行此代码，可以使用`Server`命令使其在LIT服务器上运行：
- en: '[PRE24]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](img/B18406_08_10.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_08_10.png)'
- en: 'Figure 8.10: Notebook view with the Predictions tab open'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.10：打开预测标签的笔记本视图
- en: 'As you can appreciate in *Figure 8.10*, LIT has:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在*图8.10*中可以看到的，LIT具有：
- en: A top bar with a dropdown to select the model and dataset (but you can’t here
    because there’s only one of each) and three different views (**simple**, **default**,
    and **notebook**). **notebook** is selected by default.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个顶部栏，有一个下拉菜单用于选择模型和数据集（但在这里您不能选择，因为每种只有一个）和三种不同的视图（**简单**、**默认**和**笔记本**）。**笔记本**是默认选项。
- en: A selection bar to select datapoints and see which ones are pinned.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个选择栏，用于选择数据点和查看哪些被固定。
- en: A tab bar with three tabs (**Predictions**, **Explanations**, and **Analysis**).
    By default, **Predictions** is selected, and this tab has **Data Table** to the
    left, where you can select and pin individual datapoints, and the **Classification
    Results** pane to the right.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个标签栏，有三个标签（**预测**、**解释**和**分析**）。默认情况下，**预测**被选中，此标签页左侧有**数据表**，您可以在其中选择和固定单个数据点，右侧有**分类结果**面板。
- en: 'Even though the **notebook** view has much more going on than the **simple**
    view, it lacks many features available in the **default** view. From now on, we
    will examine the **default** view depicted in *Figure 8.11*:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管**笔记本**视图比**简单**视图有更多功能，但它缺少**默认**视图中许多可用的功能。从现在开始，我们将检查*图8.11*中描述的**默认**视图：
- en: '![](img/B18406_08_11.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_08_11.png)'
- en: 'Figure 8.11: The default view with the Predictions tab open'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11：打开预测标签的默认视图
- en: 'As you can see in *Figure 8.11*, the default view has two permanent panes,
    with the **Data Table** and **Datapoint Editor** in the top pane and the tabs
    in the bottom pane. It’s not a great layout for a small notebook cell, but it
    can let you easily pin, select, and edit datapoints while also performing tasks
    on them in the tabs below. Note also that there are more than three tabs. We will
    briefly explain each one:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在*图8.11*中看到的，默认视图有两个永久窗格，顶窗格中有**数据表**和**数据点编辑器**，底窗格中有标签页。这不是一个小笔记本单元格的好布局，但它可以让你轻松固定、选择和编辑数据点，同时在下面的标签页上执行任务。注意，标签页不止三个。我们将简要解释每个标签页：
- en: '**Predictions**: This lets you see classification results for selected and
    pinned datapoints. Note that it denotes the predicted label with a “P” and the
    ground truth with a “T.” However, since we didn’t train the model with this dataset,
    the label provided is no different than the one predicted, but this can prove
    very useful for examining misclassifications. To the right of the **Classification
    Results**, we have **Scalars**, which allows us to compare scores for the pinned
    and selected datapoints with all others in the dataset.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测**: 这让你可以看到所选和固定的数据点的分类结果。注意，它用“P”表示预测标签，用“T”表示真实标签。然而，由于我们没有用这个数据集训练模型，提供的标签与预测的标签没有区别，但这可以证明在检查错误分类时非常有用。在**分类结果**的右侧，我们有**标量**，这允许我们比较固定和所选数据点的分数与数据集中所有其他数据点的分数。'
- en: '**Explanations**: Here, we can use a number of explanation/attribution methods
    on our datapoints, such as LIME and integrated gradients.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解释**: 在这里，我们可以对我们的数据点使用多种解释/归因方法，例如LIME和集成梯度。'
- en: '**Salience Clustering**: We perform attributions on many datapoints and cluster
    the results to understand how tokens are clustered. We won’t go into details here,
    given that we only are using a dataset of 100.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**显著性聚类**: 我们对许多数据点进行归因，并将结果聚类以了解标记是如何聚类的。鉴于我们只使用100个数据集，我们不会在这里详细介绍。'
- en: '**Metrics**: Had we been using a training dataset with ground truth labels,
    this tab would be very useful because it can slice and bin performance metrics
    in many ways.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指标**: 如果我们使用带有真实标签的训练数据集，这个标签页将非常有用，因为它可以以多种方式切片和分组性能指标。'
- en: '**Counterfactuals**: Much like with *Chapter 6*, the concept of counterfactuals
    is the same here, which is working out what feature (a token in this case) you
    can change in such a way that you modify the model outcome (the predicted label).
    There are several counterfactual finding methods provided.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反事实**: 与*第6章*类似，这里的反事实概念是相同的，即找出你可以改变的特征（在这种情况下是一个标记），这样就可以修改模型结果（预测标签）。这里提供了几种反事实发现方法。'
- en: 'So, we will work our way down this list, excluding **Salience Clustering**
    and **Predictions** (which we already explained in *Figure 8.11*), so next, we
    will take a look at **Explanations**, as shown in *Figure 8.12*:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将按顺序处理这个列表，排除**显著性聚类**和**预测**（我们已经在*图8.11*中解释过），所以接下来，我们将查看**解释**，如图*8.12*所示：
- en: '![](img/B18406_08_12.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_08_12.png)'
- en: 'Figure 8.12: LIME explanation compared between pinned and selected reviews
    in the Explanations tab'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12：在“解释”标签页中，比较了固定和选择的评论的LIME解释
- en: '*Figure 8.12* shows how LIME explanations vary between the pinned and selected
    datapoint. LIME was previously covered in *Chapter 5*, *Local Model-Agnostic Interpretation
    Methods*, and in the context of NLP no less. It’s the same here. Incidentally,
    although there are at least four methods available, including integrated gradients,
    only LIME will work with this model. The reason for this is that LIME is a model-agnostic
    permutation-based method that doesn’t need to access any of the intrinsic parameters
    of the model, but the rest of the methods aren’t model-agnostic. And if you recall,
    our `GEModel` doesn’t expose any of the intrinsic parameters. If we wanted to
    leverage gradient-based methods like IG within LIT, we would need to not use the
    pipeline and then specify the input and output in such a way that token embeddings
    are exposed. There are some examples on the LIT website that can help you accomplish
    this.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8.12*展示了LIME解释在固定数据和选定点之间的差异。LIME之前在*第5章*，*局部模型无关解释方法*中，以及在NLP的背景下都有涉及。这里也是一样。顺便提一下，尽管至少有四种方法可用，包括积分梯度，但只有LIME能与这个模型一起工作。这是因为LIME是一种模型无关的基于排列的方法，它不需要访问模型的所有内在参数，而其他方法不是模型无关的。如果你还记得，我们的`GEModel`没有暴露任何内在参数。如果我们想在LIT中使用基于梯度的方法如IG，我们就需要不使用管道，然后以这种方式指定输入和输出，即暴露标记嵌入。LIT网站上有一些示例可以帮助你完成这项工作。'
- en: 'Next, we will take a look at the **Metrics** tab, as seen in *Figure 8.13*:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看**指标**选项卡，如图8.13所示：
- en: '![](img/B18406_08_13.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_08_13.png)'
- en: 'Figure 8.13: Confusion Matrix in the Metrics tab'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.13：指标选项卡中的混淆矩阵
- en: In *Figure 8.13*, in the **Metrics** panel, there usually would be informative
    metrics for the entire dataset, the selection you have made, and any additional
    facets you may define. However, if you expand the tab, you’ll always see 100%
    accuracy for this dataset because there’s no ground truth. Perhaps the **Confusion**
    **Matrix** panel to the right is more informative in this case because we can
    see a cross tab between labels and rating, or labels and positive, since we defined
    both rating and positive as `CategoryLabel`s. Please note that, technically, it’s
    not a confusion matrix because it doesn’t compare a predicted sentiment label
    against the corresponding true label, but you can see how much agreement there
    is between the predicted label and the rating.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图8.13*中的**指标**面板中，通常会有关于整个数据集、你所做的选择以及你可能定义的任何附加维度的信息性指标。然而，如果你展开选项卡，你总是会看到这个数据集的100%准确率，因为没有真实标签。也许右侧的**混淆矩阵**面板在这种情况下更有信息性，因为我们可以看到标签和评分，或标签和正面的交叉表，因为我们定义了评分和正为`CategoryLabel`。请注意，从技术上讲，这并不是一个混淆矩阵，因为它没有将预测情感标签与相应的真实标签进行比较，但你可以看到预测标签和评分之间有多少一致性。
- en: 'Finally, let’s examine the **Counterfactuals** tab, depicted in *Figure 8.14*:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们检查**反事实**选项卡，如图8.14所示：
- en: '![](img/B18406_08_14.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_08_14.png)'
- en: 'Figure 8.14: Generating ablation flip counterfactuals in the Counterfactuals
    tab'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.14：在反事实选项卡中生成消融翻转反事实
- en: The **Counterfactuals** tab in *Figure 8.14* provides several methods to change
    the input in such a way that the predicted label is modified. Not all methods
    will work with `GEModel`, given how some counterfactual methods are model-agnostic
    and others require intrinsic parameters. Here, we use ablation flip, a model-agnostic
    method, to ablate (remove) tokens from the inputs. Ablation flip simply tries
    dropping tokens from the input to figure out which one changes the prediction.
    As you can see, the first one removed “Not” from “review,” and the second removed
    “impressed.”
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8.14*中的**反事实**选项卡提供了几种方法来改变输入，从而修改预测标签。由于一些反事实方法是模型无关的，而其他方法需要内在参数，因此并非所有方法都适用于`GEModel`。在这里，我们使用模型无关的方法消融翻转，从输入中移除标记。消融翻转简单地尝试从输入中删除标记，以找出哪个标记改变了预测。正如你所看到的，第一个移除的是“Not”从“review”中，第二个移除的是“impressed”。'
- en: 'With counterfactuals, you can test that the subword tokens in te ##rri ##fic
    (as depicted in *Figure 8.9*) indeed cause ambiguity when they are added and ablated
    in many different contexts. For instance, you can remove one token at a time from
    te ##rri ##fic from a review that is deemed to have a neutral or negative sentiment
    by the model, seeing if the prediction changes in a positive direction. You can
    also replace all three tokens with a synonym like “magnificent.”'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '通过反事实，你可以测试在 te ##rri ##fic（如图 8.9 所示）中添加和删除子词标记是否会在许多不同的上下文中引起歧义。例如，你可以从被认为具有中性或负面情绪的评论中逐个移除
    te ##rri ##fic 中的一个标记，看看预测是否向积极方向改变。你也可以用“magnificent”这样的同义词替换所有三个标记。'
- en: Mission accomplished
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务完成
- en: It was pretty evident from the summary table (*Figure 8.3*), and confirmed with
    the integrated gradients and, to some degree, the attention visualization exercise,
    that many of the Ekman emotions are hard to discern from the reviews, with fear,
    disgust, anger, and sadness producing many mixed sentiment reviews. And these
    hard ones are all negative emotions.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 从摘要表（*图 8.3*）中很明显，并且通过集成梯度和一定程度上的注意力可视化练习得到证实，许多 Ekman 情绪在评论中难以辨别，恐惧、厌恶、愤怒和悲伤产生了许多混合情绪的评论。而这些难以辨别的都是负面情绪。
- en: Also, many emotions in both the GoEmotions and Ekman taxonomy don’t matter as
    much in the context of a recommendation engine, so it makes sense to consider
    consolidating some of the negative emotions and, given the ambiguity with the
    surprise category being sometimes positive and sometimes negative, splitting them
    to include curiosity and confusion.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在 GoEmotions 和 Ekman 分类法中，许多情绪在推荐引擎的上下文中并不重要，因此考虑合并一些负面情绪是有意义的。鉴于惊喜类别有时是积极的，有时是消极的，因此将它们拆分以包括好奇心和困惑是有道理的。
- en: Another important finding was that, given the many consistent patterns you found,
    surprise is not as hard to classify and yet a critical emotion to predict. However,
    there are good surprises and bad surprises. And given the right training data,
    a model can likely differentiate both with high precision. We can ensure that
    tokenization never separates words that convey emotions for the training corpus.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的发现是，鉴于你发现的许多一致模式，惊喜并不难分类，但却是预测的关键情绪。然而，有好的惊喜和坏的惊喜。并且，在适当的训练数据下，模型很可能以高精度区分两者。我们可以确保标记化永远不会将传达情感的单词分开。
- en: Summary
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: After reading this chapter, you should understand how to leverage BertViz to
    visualize transformer models, layers, and attention heads, and how to use Captum’s
    attribution methods, more specifically integrated gradients, and the Visualization
    Data Record to see what tokens are responsible for a predicted label. Finally,
    you should have a solid grasp of how to get started with the LIT. In the next
    chapter, we will look at interpreting multi-variate time-series models.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读本章后，你应该了解如何利用 BertViz 可视化变压器模型、层和注意力头，以及如何使用 Captum 的归因方法，特别是集成梯度，以及可视化数据记录来查看哪些标记负责预测的标签。最后，你应该对如何开始使用
    LIT 有一个扎实的掌握。在下一章中，我们将探讨解释多元时间序列模型。
- en: Further reading
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Vig, J., 2019, *A Multiscale Visualization of Attention in the Transformer
    Model*. ArXiv: [https://arxiv.org/abs/1906.05714](https://arxiv.org/abs/1906.05714)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vig, J., 2019, *Transformer 模型中的注意力多尺度可视化*。ArXiv：[https://arxiv.org/abs/1906.05714](https://arxiv.org/abs/1906.05714)
- en: 'Kokhlikyan, N., Miglani, V., Martin, M., Wang, E., Alsallakh, B., Reynolds,
    J., Melnikov, A., Kliushkina, N., Araya, C., Yan, S., & Reblitz-Richardson, O.,
    2020, *Captum: A unified and generic model interpretability library for PyTorch*.
    ArXiv: [https://arxiv.org/abs/2009.07896](https://arxiv.org/abs/2009.07896)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kokhlikyan, N., Miglani, V., Martin, M., Wang, E., Alsallakh, B., Reynolds,
    J., Melnikov, A., Kliushkina, N., Araya, C., Yan, S., & Reblitz-Richardson, O.,
    2020, *Captum：PyTorch 的一个统一和通用的模型可解释性库*。ArXiv：[https://arxiv.org/abs/2009.07896](https://arxiv.org/abs/2009.07896)
- en: 'Tenney, I., Wexler, J., Bastings, J., Bolukbasi, T., Coenen, A., Gehrmann,
    S., Jiang, E., Pushkarna, M., Radebaugh, C., Reif, E., & Yuan, A., 2020, *The
    Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis
    for NLP Models.* Conference on Empirical Methods in Natural Language Processing:
    [https://arxiv.org/abs/2008.05122](https://arxiv.org/abs/2008.05122)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tenney, I., Wexler, J., Bastings, J., Bolukbasi, T., Coenen, A., Gehrmann, S.,
    Jiang, E., Pushkarna, M., Radebaugh, C., Reif, E., & Yuan, A., 2020, *《语言可解释性工具：NLP
    模型的可扩展、交互式可视化和分析工具》。实证自然语言处理方法会议：[https://arxiv.org/abs/2008.05122](https://arxiv.org/abs/2008.05122)
- en: Learn more on Discord
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Discord 上了解更多信息
- en: 'To join the Discord community for this book – where you can share feedback,
    ask the author questions, and learn about new releases – follow the QR code below:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 要加入本书的 Discord 社区——在那里您可以分享反馈、向作者提问，并了解新书发布——请扫描下面的二维码：
- en: '[https://packt.link/inml](Chapter_8.xhtml)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/inml](Chapter_8.xhtml)'
- en: '![](img/QR_Code107161072033138125.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code107161072033138125.png)'
