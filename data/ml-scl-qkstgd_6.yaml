- en: Scala for Recommender System
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于推荐系统的Scala
- en: 'In this chapter, we will learn about different approaches for developing recommender
    systems. Then we will learn how to develop a book recommendation system. Technically,
    it will be a model-based recommendation engine based on **alternating least squares**
    (**ALS**) and matrix factorization algorithms. We will use Spark MLlib-based implementation
    of these algorithms in Scala. In a nutshell, we will learn the following topics
    throughout this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习开发推荐系统的不同方法。然后我们将学习如何开发一个书籍推荐系统。技术上，它将是一个基于**交替最小二乘法**（**ALS**）和矩阵分解算法的模型推荐引擎。我们将使用基于Spark
    MLlib的这些算法的Scala实现。简而言之，我们将在本章中学习以下主题：
- en: Overview of recommendation systems
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统概述
- en: Similarity-based recommender system
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于相似度的推荐系统
- en: Content-based recommender system
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于内容的推荐系统
- en: Collaborative approaches
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协同方法
- en: Hybrid recommendation systems
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合推荐系统
- en: Developing a model-based book recommendation system
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发基于模型的书籍推荐系统
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Make sure Scala 2.11.x and Java 1.8.x are installed and configured on your machine.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 确保Scala 2.11.x和Java 1.8.x已安装并配置在您的机器上。
- en: 'The code files of this chapters can be found on GitHub:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在GitHub上找到：
- en: '[https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter06](https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter06)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter06](https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter06)'
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频以查看代码的实际应用：
- en: '[http://bit.ly/2UQTFHs](http://bit.ly/2UQTFHs)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2UQTFHs](http://bit.ly/2UQTFHs)'
- en: Overview of recommendation systems
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统概述
- en: A recommender system is an information filtering approach, which predicts the
    rating given by a user to an item. Then the item for which the predicted rating
    is high will be recommended to the user. Recommender systems are now being used
    more or less everywhere for recommending movies, music, news, books, research
    articles, products, videos, books, news, Facebook friends, restaurants, routes,
    search queries, social tags, products, collaborators, jokes, restaurants, garments,
    financial services, Twitter pages, Android/iOS apps, hotels, life insurance, and
    even partners, in online dating sites.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统是一种信息过滤方法，它预测用户对项目的评分。然后，预测评分高的项目将被推荐给用户。推荐系统现在在推荐电影、音乐、新闻、书籍、研究文章、产品、视频、书籍、新闻、Facebook朋友、餐厅、路线、搜索查询、社交标签、产品、合作伙伴、笑话、餐厅、服装、金融服务、Twitter页面、Android/iOS应用、酒店、人寿保险，甚至在在线约会网站上被或多或少地使用。
- en: Types of recommender systems
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统的类型
- en: 'There are a couple of ways to develop recommendation engines that typically
    produce a list of recommendations, such as similarity-based, content-based, collaborative,
    and hybrid recommendation systems as shown in the following figure:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 开发推荐引擎有几种方法，通常会产生一个推荐列表，如以下图中所示的基于相似度、基于内容、协同和混合推荐系统：
- en: '![](img/93b9d48f-85a5-4b79-890a-02b006f94013.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/93b9d48f-85a5-4b79-890a-02b006f94013.png)'
- en: We will discuss the similarity-based, content-based, collaborative, and hybrid
    recommendation systems. Then based on their pros and cons, we will see a hands-on
    example showing how to develop a book recommendation system.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论基于相似度、基于内容、协同和混合推荐系统。然后基于它们的优缺点，我们将通过一个实际示例展示如何开发一个书籍推荐系统。
- en: Similarity-based recommender systems
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于相似度的推荐系统
- en: There are two main types of similarity-based approaches: **user-user similarity** and **user-item
    similarity**. These can be used to build recommendation systems. To use a user-user
    item similarity approach, first construct a user-user similarity matrix. It will
    then pick items that are already liked by similar users and, finally, it recommends
    items for a specific user.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 基于相似度的两种主要方法：**用户-用户相似度**和**用户-项目相似度**。这些方法可以用来构建推荐系统。要使用用户-用户项目相似度方法，首先构建一个用户-用户相似度矩阵。然后它会选择那些被相似用户喜欢的项目，最后为特定用户推荐项目。
- en: 'Suppose we want to develop a book recommender system: naturally, there will
    be many book users (readers) and a list of books. For the sake of brevity, let''s
    pick the following machine learning-related books as the representative ones for
    the readers:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要开发一个图书推荐系统：自然地，会有许多图书用户（读者）和一系列图书。为了简洁起见，让我们选择以下与机器学习相关的图书作为读者的代表：
- en: '![](img/69c226c2-7250-47a8-8cb5-082aad603327.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/69c226c2-7250-47a8-8cb5-082aad603327.png)'
- en: 'Then a user-user similarity based recommender system will recommend books based
    on a similarity measure using some similarity measure techniques. For example,
    the cosine similarity is calculated as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，基于用户-用户相似度的推荐系统将根据某些相似度度量技术使用相似度度量来推荐图书。例如，余弦相似度的计算如下：
- en: '![](img/c323a530-2bcd-4011-bda4-da9331fdb21b.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c323a530-2bcd-4011-bda4-da9331fdb21b.png)'
- en: 'In the preceding equation, *A* and *B* represent two users. If the similarity
    threshold is greater than or equal to a defined threshold, users *A* and *B* will
    most likely have similar preferences:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，*A* 和 *B* 代表两个用户。如果相似度阈值大于或等于定义的阈值，用户 *A* 和 *B* 很可能具有相似偏好：
- en: '![](img/f1ba9bfb-4880-4978-b3ea-84d2ba8c7696.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f1ba9bfb-4880-4978-b3ea-84d2ba8c7696.png)'
- en: 'However, user-user similarity based recommender systems are not robust. There
    are several reasons for that:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，基于用户-用户相似度的推荐系统并不稳健。有以下几个原因：
- en: User preferences and tastes usually change over time
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户偏好和口味通常会随时间变化
- en: They are computationally very expensive because of the similarity calculation
    for so many cases from very sparse matrix calculation
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于需要从非常稀疏的矩阵计算中计算许多案例的相似度，因此它们在计算上非常昂贵
- en: 'Amazon and YouTube have millions of subscribed users, so any user-user utility
    matrix that you created would be a very sparse one. One workaround is using item-item
    similarity, which also computes an item-item utility matrix, finding similar items
    and, finally, recommending similar items, just like in the following diagram:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊和YouTube拥有数百万的订阅用户，因此你创建的任何用户-用户效用矩阵都将是一个非常稀疏的矩阵。一种解决方案是使用项目-项目相似度，这也会计算出一个项目-项目效用矩阵，找到相似的项目，最后推荐相似的项目，就像以下图示：
- en: '![](img/84c05ecb-de09-4eb0-9f9f-f0b3b82aaa71.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/84c05ecb-de09-4eb0-9f9f-f0b3b82aaa71.png)'
- en: This approach has one advantage over the user-user similarity approach, which
    is that usually the ratings on a given item do not change very significantly after
    an initial period. Let's take as an example the book *The Hundred Page Machine
    Learning Book*, which has already got a very good rating on Amazon even though
    it was released just a few months ago. So, even if over the next few months a
    few people give it lower ratings, its ratings would not change much after the
    initial period.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法与用户-用户相似度方法相比有一个优点，即通常在初始阶段之后，给定项目的评分不会发生很大的变化。以《百页机器学习书》为例，尽管它只发布了几个月，但在亚马逊上已经获得了非常好的评分。因此，即使在未来几个月内，有几个人给出了较低的评分，其评分在初始阶段之后也不会有太大变化。
- en: Interestingly, this is also an assumption that the ratings will not change very
    significantly over time. However, this assumption works very well in cases where
    the number of users is much higher than the number of items.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，这也是一个假设，即评分在一段时间内不会发生很大的变化。然而，这个假设在用户数量远多于项目数量的情况下非常有效。
- en: Content-based filtering approaches
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于内容的过滤方法
- en: 'Content-based filtering approaches are based on classical machine learning
    techniques such as classification or regression. This type of system learns how
    to represent an item (book) *I[j]* and a user *U[i]*. Then, a separate feature
    matrix for both *I[j]* and *U[i]* are created before combining them as a feature
    vector. Then the feature vector is fed into a classification or regression model
    for the training. This way, the ML model generates the label *L[ij]*, which is
    interestingly the corresponding rating given by the user *U[i]* on the item *I[j]*:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 基于内容的过滤方法基于经典的机器学习技术，如分类或回归。这类系统学习如何表示一个项目（图书）*I[j]* 和一个用户 *U[i]*。然后，在将它们组合为特征向量之前，为
    *I[j]* 和 *U[i]* 创建单独的特征矩阵。然后，将特征向量输入到训练的分类或回归模型中。这样，ML模型生成标签 *L[ij]*，这有趣的是用户 *U[i]*
    对项目 *I[j]* 给出的相应评分：
- en: '![](img/ba7ca2d2-16e1-40ec-8d6c-3256f282ac04.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ba7ca2d2-16e1-40ec-8d6c-3256f282ac04.png)'
- en: A general warning is that the features should be created so they have direct
    impact on the rating (**Labels**). This means features should be as dependent
    as possible to avoid correlations.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一个一般的警告是，应该创建特征，以便它们对评分（**标签**）有直接影响。这意味着特征应该尽可能依赖，以避免相关性。
- en: Collaborative filtering approaches
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协同过滤方法
- en: 'The idea of collaborative filtering is that when we have many users who liked
    some items, then those items can be recommended to users who have not seen them
    yet. Suppose we have four readers and four books, as shown in the following diagram:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤的想法是，当我们有很多喜欢某些物品的用户时，这些物品可以推荐给尚未看到它们的用户。假设我们有四位读者和四本书，如下面的图所示：
- en: '![](img/ee87495c-ed5a-4fae-89b7-875fdb402475.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ee87495c-ed5a-4fae-89b7-875fdb402475.png)'
- en: Also, imagine all of these users have bought item 1 (that is, **Predictive Analytics
    with TensorFlow**) and item 2 (that is, **Deep Learning with TensorFlow**). Now,
    suppose **User 4** has read items 1, 2, and 3 and say both **User 1** and **User
    2** have bought item 3 (that is, **Mastering Machine Learning Algorithms**). However,
    since **User 4** has not seen item 4 (that is, **Python Machine Learning**) yet,
    **User 3** can recommend it to him.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，想象所有这些用户都购买了物品1（即**使用TensorFlow进行预测分析**）和物品2（即**使用TensorFlow进行深度学习**）。现在，假设**用户4**阅读了物品1、2和3，而**用户1**和**用户2**购买了物品3（即**精通机器学习算法**）。然而，由于**用户4**尚未看到物品4（即**Python机器学习**），**用户3**可以向他推荐它。
- en: So, the basic assumption is that users who have recommended an item previously
    tend to give recommendations in the future, too. If this assumption does not hold
    any longer, then a collaborative filtering recommender system cannot be build.
    This is probably the reason collaborative filtering approaches suffer from cold
    start, scalability, and sparsity problems.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，基本假设是，之前推荐过物品的用户倾向于在将来也给出推荐。如果这个假设不再成立，那么就无法构建协同过滤推荐系统。这可能是协同过滤方法遭受冷启动、可扩展性和稀疏性问题的主要原因。
- en: '**Cold start**: Collaborative filtering approaches can get stuck and cannot
    make recommendation especially when a large amount of data about users is missing
    in the uer-item matrix.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**冷启动**：协同过滤方法可能会陷入困境，无法进行推荐，尤其是在用户-物品矩阵中缺少大量用户数据时。'
- en: The utility matrix
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 效用矩阵
- en: 'Suppose we have a group of users who show a preference for a set of books. The
    higher a user''s preference for a book, the higher the rating would be, between
    1 and 10. Let''s try to understand the problem using a matrix, with rows representing
    users and columns representing books:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一组用户，他们偏好一组书籍。用户对书籍的偏好越高，评分就越高，介于1到10之间。让我们尝试使用矩阵来理解这个问题，其中行代表用户，列代表书籍：
- en: '![](img/f2f5a4e2-cda6-43ec-bd76-c2075b7c81b7.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f2f5a4e2-cda6-43ec-bd76-c2075b7c81b7.png)'
- en: Let's assume that ratings range from 1 to 10, with 10 being the highest level
    of preference. Then, in the preceding table, a user (row 1) gives a rating of **7**
    for the first book (column 1) and rates the second book as a **6**. Also, there
    are many empty cells that indicate users have not given any ratings for those
    books.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 假设评分范围从1到10，10是最高偏好级别。那么，在先前的表中，用户（第1行）对第一本书（第1列）给出了**7**的评分，对第二本书评分为**6**。还有许多空单元格，表示用户没有对那些书籍进行任何评分。
- en: This matrix is often called a user-item or utility matrix, where each row represents
    a user and each column represents an item (book), while a cell represents the
    corresponding rating given by the user to that item.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个矩阵通常被称为用户-物品或效用矩阵，其中每一行代表一个用户，每一列代表一个物品（书籍），而单元格代表用户对该物品给出的相应评分。
- en: In practice, the utility matrix is *very sparse* because a large number of cells
    are empty. The reason is that we have so many items and it is almost impossible
    for a single user to give ratings to all of the items. Even if a user rates 10%
    of the items, the other 90% of the cells of this matrix will still be empty. These
    empty cells often represented by NaN, which means not a number, although in our
    example utility matrix we used **?**. This sparsity often creates computational
    complexity. Let me give you an example.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，效用矩阵非常稀疏，因为大量单元格是空的。原因是物品数量众多，单个用户几乎不可能对所有物品进行评分。即使一个用户对10%的物品进行了评分，这个矩阵的其他90%的单元格仍然为空。这些空单元格通常用NaN表示，即不是一个数字，尽管在我们的效用矩阵示例中我们使用了**？**。这种稀疏性通常会创建计算复杂性。让我给你举个例子。
- en: 'Suppose there are 1 million users (*n*) and only 10,000 items (movies, *m*),
    which is *10,000,000 * 10,000* or *10^(11)*, a very large number. Now, even if
    a user has rated 10 books, this means that the total number of given ratings will
    be *10 * 1 million = 10⁷*. The sparsity of this matrix can be calculated as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有100万用户（*n*）和10,000个项目（电影，*m*），这是*10,000,000 * 10,000*或*10^(11)*，一个非常大的数字。现在，即使一个用户评了10本书，这也意味着总的评分数量将是*10
    * 1百万 = 10⁷*。这个矩阵的稀疏度可以计算如下：
- en: '*S[m ]= Number of empty cells / Total number of cells = (10^(10 )- 10⁷)/10^(10) =
    0.9999*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*S[m ]= 空单元格数 / 总单元格数 = (10^(10 )- 10⁷)/10^(10) = 0.9999*'
- en: This means 99.99% of the cells will still be empty.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着99.99%的单元格仍然为空。
- en: Model-based book recommendation system
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于模型的书籍推荐系统
- en: 'In this section, we will show how to develop a model-based book recommendation
    system with the Spark MLlib library. Books and the corresponding ratings were
    downloaded from this link: [http://www2.informatik.uni-freiburg.de/~cziegler/BX/](http://www2.informatik.uni-freiburg.de/~cziegler/BX/).
    There are three CSV files:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示如何使用Spark MLlib库开发一个基于模型的书籍推荐系统。书籍及其对应的评分是从以下链接下载的：[http://www2.informatik.uni-freiburg.de/~cziegler/BX/](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)。这里有三个CSV文件：
- en: '`BX-Users.csv`: Contains user''s demographic data and each user is specified
    with user IDs (`User-ID`).'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BX-Users.csv`: 包含用户的统计数据，每个用户都指定了用户ID（`User-ID`）。'
- en: '`BX-Books.csv`: Book related information such as `Book-Title`, `Book-Author`,
    `Year-Of-Publication`, and `Publisher` are there. Each book is identified by an
    ISBN. Also, `Image-URL-S`, `Image-URL-M`, and `Image-URL-L` are given.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BX-Books.csv`: 包含书籍相关信息，如`Book-Title`、`Book-Author`、`Year-Of-Publication`和`Publisher`。每本书都有一个ISBN标识。此外，还提供了`Image-URL-S`、`Image-URL-M`和`Image-URL-L`。'
- en: '`BX-Book-Ratings.csv`: Contains the rating specified by the `Book-Rating` column.
    Ratings are on a scale from `1` to `10` (higher values denoting higher appreciation),
    or implicit, expressed by `0`.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BX-Book-Ratings.csv`: 包含由`Book-Rating`列指定的评分。评分在`1`到`10`的范围内（数值越高表示越高的评价），或者隐式表达为`0`。'
- en: Before we jump into the coding part, we need to know a bit more about the matrix
    factorization techniques such as **singular value decomposition** (**SVD**). SVD
    can be used to transform both the item and the user entries into the same potential
    space, which represents the interaction between users and items. The rationale
    behind matrix decomposition is that potential features represent how users score
    items.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入编码部分之前，我们需要了解一些关于矩阵分解技术，如**奇异值分解**（**SVD**）的更多信息。SVD可以将项目和用户条目转换到相同的潜在空间，这代表了用户和项目之间的交互。矩阵分解背后的原理是潜在特征表示用户如何评分项目。
- en: Matrix factorization
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 矩阵分解
- en: 'So, given the description of the users and the items, the task here is to predict
    how the user will rate those items that have not yet been rated. More formally,
    if a user *U[i]* likes item *V[1]*, *V[5]*, and *V[7]*,then the task is to recommend item *V[j]*
    touser *U[i]* that they will most probably like too as shown in the following
    figure:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，给定用户和项目的描述，这里的任务是预测用户将如何评分那些尚未评分的项目。更正式地说，如果用户*U[i]*喜欢项目*V[1]*、*V[5]*和*V[7]*，那么任务就是向用户*U[i]*推荐他们可能也会喜欢的项目*V[j]*，如图所示：
- en: '![](img/0b3f2bf8-844f-4507-84ab-348d3d4761b0.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0b3f2bf8-844f-4507-84ab-348d3d4761b0.png)'
- en: 'Once we have such an application, the idea is that each time we receive new
    data, we update it to the training dataset and then update the model obtained
    by ALS training, where the collaborative filtering method is used. To handle the
    user-book utility matrix, a low-rank matrix factorization algorithm is used:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了这样的应用，我们的想法是每次我们收到新的数据时，我们将其更新到训练数据集，然后更新通过ALS训练获得的模型，其中使用了协同过滤方法。为了处理用户-书籍效用矩阵，使用了一个低秩矩阵分解算法：
- en: '![](img/ac9c10e4-2d13-4adf-b0d3-b2ca554b7793.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ac9c10e4-2d13-4adf-b0d3-b2ca554b7793.png)'
- en: 'Since not all the books are rated by all the users, not all of the entries
    in this matrix are known. The collaborative filtering approach discussed in a
    preceding section comes to this party as the savior. Well, using collaborative
    filtering, we can solve an optimization problem to approximate the ratings matrix
    by factorizing **User factors (V)** and **Book factors (V)**, which can be depicted
    as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于并非所有书籍都被所有用户评分，这个矩阵中的并非所有条目都是已知的。前面章节中讨论的协同过滤方法在这里作为救星出现。嗯，使用协同过滤，我们可以解决一个优化问题，通过分解**用户因素（V**）和**书籍因素（V**）来近似评分矩阵，如下所示：
- en: '![](img/0a51be14-29cc-47b8-9d99-df5b82413cda.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0a51be14-29cc-47b8-9d99-df5b82413cda.png)'
- en: 'These two matrices are selected such that the error for the users-book pairs
    (in the case of known rating) gets minimized. The ALS algorithm first fills the
    user matrix with random values (between 1 and 10, in our case) and then optimizes
    those values such that the error is minimized. Then the ALS holds the book matrix
    as fixed and optimizes the value of the user''s matrix using the following mathematical
    equation:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个矩阵被选择，使得用户-书籍对（在已知评分的情况下）的错误最小化。ALS算法首先用随机值（在我们的案例中是1到10之间）填充用户矩阵，然后优化这些值以使错误最小化。然后ALS将书籍矩阵保持固定，并使用以下数学方程优化用户矩阵的值：
- en: '![](img/ac538922-4a7c-4f11-a300-a0753fda7574.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ac538922-4a7c-4f11-a300-a0753fda7574.png)'
- en: Spark MLlib supports a model-based collaborative filtering approach. In such
    an approach, users and items are described by a small set of latent factors for
    predicting missing entries of a user-item utility matrix. As described earlier,
    the ALS algorithms can learn those latent factors in an iterative way. The ALS
    algorithm accepts six parameters, namely `numBlocks`, `rank`, `iterations`, `lambda`,
    `implicitPrefs`, and `alpha`. `numBlocks` is number of blocks required to parallelize
    the computation. The `rank` parameter is the number of latent factors. The `iterations` parameter
    is the number of iterations by which ALS will get converged. The `lambda` parameter
    signifies the regularization parameter. The `implicitPrefs` parameter means that
    we want to use explicit feedback from the other users, and, finally, `alpha` is
    the baseline confidence in preference observations.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Spark MLlib支持基于模型的协同过滤方法。在这种方法中，用户和物品由一组小的潜在因素来描述，以预测用户-物品效用矩阵中缺失的条目。如前所述，ALS算法可以通过迭代方式学习这些潜在因素。ALS算法接受六个参数，即`numBlocks`、`rank`、`iterations`、`lambda`、`implicitPrefs`和`alpha`。`numBlocks`是并行计算所需的块数。`rank`参数是潜在因素的数量。`iterations`参数是ALS收敛所需的迭代次数。`lambda`参数表示正则化参数。`implicitPrefs`参数表示我们希望使用其他用户的显式反馈，最后，`alpha`是偏好观察的基线置信度。
- en: Exploratory analysis
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索性分析
- en: 'In this subsection, we will perform some exploratory analysis about the ratings,
    books, and related statistics. This analysis will help us understand the data
    well:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们将对评分、书籍和相关统计进行一些探索性分析。这种分析将帮助我们更好地理解数据：
- en: '[PRE0]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following code segments show you the DataFrame of books from the `BX-Books.csv`
    file:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了来自`BX-Books.csv`文件的书籍DataFrame：
- en: '[PRE1]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following is the output:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为输出结果：
- en: '![](img/b53d3eed-f4cf-4aef-aae8-c735fa8a3887.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b53d3eed-f4cf-4aef-aae8-c735fa8a3887.png)'
- en: 'Let''s see how many distinct books there are:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看有多少独特的书籍：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following is the output:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为输出结果：
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This information will be valuable for a later case, so that we can know how
    many books are missing ratings in the rating dataset. To register both datasets,
    we can use the following code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息对于后续案例将非常有价值，这样我们就可以知道在评分数据集中有多少书籍缺少评分。为了注册这两个数据集，我们可以使用以下代码：
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will help to make the in-memory querying faster by creating a temporary
    view as a in-memory table. Let''s check the ratings-related statistics. Just use
    the following code lines:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这将通过创建一个临时视图作为内存中的表来加快内存查询速度。让我们检查与评分相关的统计信息。只需使用以下代码行：
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You should find `Got 1149780 ratings from 105283 users on 340556 books`. Now,
    let''s get the maximum and minimum ratings along with the count of users who have
    rated a book:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该找到“从105283个用户对340556本书进行了1149780次评分”。现在，让我们获取最大和最小评分，以及评分书籍的用户数量：
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The preceding code should generate the max and min ratings, along with the
    count of users who have rated a book:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码应该生成最大和最小评分，以及评分书籍的用户数量：
- en: '![](img/6e045a60-3e6f-43a5-acb9-ba01529b0d7f.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6e045a60-3e6f-43a5-acb9-ba01529b0d7f.png)'
- en: 'Now, to get further insight we need to know more about the users and their
    ratings, which can be done by finding the top ten most active users and how many
    times they have rated a book:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了获得更深入的洞察，我们需要更多地了解用户及其评分，这可以通过找到最活跃的十个用户以及他们为书籍评分的次数来实现：
- en: '[PRE7]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding lines of code should show the top ten most active users and how
    many times they have rated a book:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码行应该显示最活跃的十个用户以及他们为书籍评分的次数：
- en: '![](img/db26d027-5dc4-4dfa-bac8-2497f66622dd.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/db26d027-5dc4-4dfa-bac8-2497f66622dd.png)'
- en: 'Now let''s have a look at a particular user, and find the books that, say,
    user `130554` rated higher than `5`:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们查看一个特定的用户，并找到那些用户`130554`评分高于`5`的书籍：
- en: '[PRE8]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'As described, the preceding line of code should show the name of all the movies
    rated by user 130554 giving more than 5 ratings:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如描述，上述代码行应显示用户130554评分超过5分的所有电影名称：
- en: '![](img/e0775743-029d-4fe2-a3ee-0f1de8052f07.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e0775743-029d-4fe2-a3ee-0f1de8052f07.png)'
- en: Prepare training and test rating data
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备训练和测试评分数据
- en: 'The following code splits ratings RDD into training data RDD (60%) and test
    data RDD (40%). The second parameter (that is `1357L`) is the *seed*, which is
    typically used for the purpose of reproducibility:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将评分RDD分割为训练数据RDD（60%）和测试数据RDD（40%）。第二个参数（即`1357L`）是*种子*，通常用于可重复性目的：
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You will see that there are 689,144 ratings in the training DataFrame and 345,774
    ratings in the test DataFrame. The ALS algorithm requires an RDD of ratings for
    the training. The following code illustrates the way to build the recommendation
    model using APIs:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到训练DataFrame中有689,144个评分，测试DataFrame中有345,774个评分。ALS算法需要训练的评分RDD。以下代码展示了如何使用API构建推荐模型：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`trainRatingsRDD` is an RDD of ratings that contains `UserID`, `ISBN`, and
    the corresponding ratings from the training dataset that we prepared in the preceding
    step. Similarly, we prepared another RDD from the test DataFrame:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`trainRatingsRDD`是一个包含`UserID`、`ISBN`以及对应评分的RDD，这些评分来自我们在前一步准备的训练数据集。同样，我们还从测试DataFrame中准备了一个另一个RDD：'
- en: '[PRE11]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Based on the `trainRatingsRDD`, we build an ALS user model by adding the maximal
    iteration, a number of blocks, alpha, rank, lambda, seed, and implicit preferences.
    This method is generally used for analyzing and predicting missing ratings of
    specific users:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 基于上述`trainRatingsRDD`，我们通过添加最大迭代次数、块的数量、alpha、rank、lambda、seed和隐式偏好来构建一个ALS用户模型。这种方法通常用于分析和预测特定用户的缺失评分：
- en: '[PRE12]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, we iterated the model for learning `10` times. With this setting,
    we got good prediction accuracy. Readers are recommended to apply hyperparameter
    tuning to find the optimum values for these parameters. In order to evaluate the
    quality of the model, we compute the **root mean squared error** (**RMSE**). The
    following code calculates the RMSE value for the model that was developed with
    the help of the training set:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们迭代模型进行学习`10`次。在这个设置下，我们得到了良好的预测准确度。建议读者应用超参数调整以找到这些参数的最佳值。为了评估模型的质量，我们计算**均方根误差**（**RMSE**）。以下代码计算了使用训练集开发的模型的RMSE值：
- en: '[PRE13]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'For the preceding setting, we get the following output:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上述设置，我们得到以下输出：
- en: '[PRE14]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The preceding method computes the RMSE to evaluate the model. The lower the
    RMSE, the better the model and its prediction capability is, which goes as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 前述方法计算RMSE来评估模型。RMSE越低，模型及其预测能力越好，如下所示：
- en: '[PRE15]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, let''s do some movie recommendations for a specific user. Let''s get
    the top ten book predictions for user `276747`:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们为特定用户做一些电影推荐。让我们获取用户`276747`的前十本书的预测：
- en: '[PRE16]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We get the following output:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '[PRE17]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We believe that the performance of the preceding model could be increased more.
    However, as far as we know, there is no model tuning facility available for the
    MLlib-based ALS algorithm.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信前述模型的表现可以进一步提高。然而，据我们所知，MLlib基于的ALS算法没有可用的模型调整功能。
- en: Interested readers should refer to [https://spark.apache.org/docs/preview/ml-collaborative-filtering.html](https://spark.apache.org/docs/preview/ml-collaborative-filtering.html) for
    more on tuning the ML-based ALS models.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 想要了解更多关于调整基于ML的ALS模型的信息的读者应参考[https://spark.apache.org/docs/preview/ml-collaborative-filtering.html](https://spark.apache.org/docs/preview/ml-collaborative-filtering.html)
- en: Adding new user ratings and making new predictions
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加新的用户评分和进行新的预测
- en: 'We can create a sequence of a new user ID, the ISBN of the book, and the rating
    predicted in the previous step:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个新用户ID、书的ISBN和上一步预测的评分的序列：
- en: '[PRE18]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now we add them to the data we will use to train our recommender model. We
    use Spark''s `union()` transformation for this:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将它们添加到我们将用于训练推荐模型的原始数据中。我们使用Spark的`union()`转换来完成这个操作：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Finally, we train the ALS model using all the parameters we selected before
    (when using the small dataset):'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用之前（在小数据集使用时）选定的所有参数来训练ALS模型：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We will need to repeat that every time a user adds new ratings. Ideally, we
    will do this in batches, and not for every single rating that comes into the system
    for every user. Then we can again make recommendations for other users such as
    `276724`, whose ratings about books were missing previously:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 每当用户添加新的评分时，我们都需要重复这个过程。理想情况下，我们将批量处理，而不是为每个用户系统中每个单独的评分进行处理。然后我们可以再次为其他用户，例如之前缺少评分的`276724`，提供推荐：
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following is the output:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为输出结果：
- en: '[PRE22]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, we compute the RMSE:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算RMSE：
- en: '[PRE23]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following is the output:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为输出结果：
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Summary
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have learned different approaches for recommender systems,
    such as similarity-based, content-based, collaborative filtering, and hybrid.
    Additionally, we discussed the downsides of these approaches. Then we implemented
    an end-to-end book recommendation system, which is a model-based recommendation
    with Spark. We have also seen how to interoperate between ALS and matrix factorization
    to efficiently handle a utility matrix.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了推荐系统的不同方法，例如基于相似度、基于内容、协同过滤和混合。此外，我们还讨论了这些方法的缺点。然后我们实现了一个端到端的书籍推荐系统，这是一个基于Spark的模型推荐系统。我们还看到了如何高效地处理效用矩阵，通过在ALS和矩阵分解之间进行交互操作。
- en: In the next chapter, we will explain some basic concepts of **d****eep learning**
    (**DL**), which is one of the emerging branches of ML. We will briefly discuss
    some of the most well known and widely used neural network architectures. Then,
    we will look at various features of DL frameworks and libraries.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将解释**深度学习**（**DL**）的一些基本概念，它是机器学习（ML）的一个新兴分支。我们将简要讨论一些最著名和最广泛使用的神经网络架构。然后，我们将探讨深度学习框架和库的各种特性。
- en: Then we will see how to prepare a programming environment, before moving on
    to coding with some open source DL libraries, such as **Deeplearning4j** (**DL4J**). Finally, we
    will solve a real-life problem using two neural network architectures, called **multilayer
    perceptron** (**MLP**) and **long short-term memory** (**LSTM**).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将了解如何准备编程环境，在开始使用一些开源深度学习库（如**Deeplearning4j**（**DL4J**））进行编码之前。最后，我们将使用两种神经网络架构，即**多层感知器**（**MLP**）和**长短期记忆**（**LSTM**），来解决一个现实生活中的问题。
