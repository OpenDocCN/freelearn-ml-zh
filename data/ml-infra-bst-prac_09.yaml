- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Feature Engineering for Numerical and Image Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数值和图像数据的特征工程
- en: In most cases, when we design large-scale machine learning systems, the types
    of data we get require more processing than just visualization. This visualization
    is only for the design and development of machine learning systems. During deployment,
    we can monitor the data, as we discussed in the previous chapters, but we need
    to make sure that we use optimized data for inference.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，当我们设计大规模机器学习系统时，我们得到的数据类型需要比仅仅可视化更多的处理。这种可视化仅用于机器学习系统的设计和开发。在部署期间，我们可以监控数据，正如我们在前几章中讨论的那样，但我们需要确保我们使用优化的数据来进行推理。
- en: Therefore, in this chapter, we’ll focus on feature engineering – finding the
    right features that describe our data closer to the problem domain rather than
    closer to the data itself. Feature engineering is a process where we extract and
    transform variables from raw data so that we can use them for predictions, classifications,
    and other machine learning tasks. The goal of feature engineering is to analyze
    and prepare the data for different machine learning tasks, such as making predictions
    or classifications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本章中，我们将专注于特征工程——找到描述我们的数据更接近问题域而不是数据本身的正确特征。特征工程是一个从原始数据中提取和转换变量的过程，以便我们可以使用它们进行预测、分类和其他机器学习任务。特征工程的目标是分析和准备数据，以便用于不同的机器学习任务，如预测或分类。
- en: In this chapter, we’ll focus on the feature engineering process for numerical
    and image data. We’ll start by going through the typical methods, such as **principal
    component analysis** (**PCA**), which we used previously for visualization. Then,
    we’ll cover more advanced methods, such as **t-student distribution stochastic
    network embedding** (**t-SNE**) and **independent component analysis** (**ICA**).
    What we’ll end up with is the use of autoencoders as a dimensionality reduction
    technique for both numerical and image data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于数值和图像数据的特征工程过程。我们将从介绍典型的方法开始，例如我们之前用于可视化的**主成分分析**（**PCA**）。然后，我们将介绍更高级的方法，例如**t-学生分布随机网络嵌入**（**t-SNE**）和**独立成分分析**（**ICA**）。最终，我们将使用自编码器作为数值和图像数据的降维技术。
- en: 'In this chapter, we’ll cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Feature engineering process fundamentals
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程过程的基本原理
- en: PCA and similar methods
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PCA和类似方法
- en: Autoencoders for numerical and image data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于数值和图像数据的自编码器
- en: Feature engineering
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程
- en: Feature engineering is the process of transforming raw data into numerical values
    that can be used in machine learning algorithms. For example, we can transform
    raw data about software defects (for example, their description, the characteristics
    of the module they come from, and so on) into a table of numerical values that
    we can use for machine learning. The raw numerical values, as we saw in the previous
    chapter, are the result of quantifying entities that we use as sources of data.
    They are the results of applying measurement instruments to the data. Therefore,
    by definition, they are closer to the problem domain rather than the solution
    domain.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程是将原始数据转换为可用于机器学习算法的数值的过程。例如，我们可以将有关软件缺陷的原始数据（例如，它们的描述、它们所属模块的特征等）转换成我们可以用于机器学习的数值表。正如我们在上一章中看到的，原始数值是我们对作为数据来源的实体进行量化的结果。它们是应用测量仪器到数据的结果。因此，根据定义，它们更接近问题域而不是解决方案域。
- en: The features, on the other hand, quantify the raw data and contain only the
    information that is important for the machine learning task at hand. We use these
    features to make sure that we find the patterns in the data during training that
    we can then use during deployment. If we look at this process from the perspective
    of measurement theory, this process changes the abstraction level of the data.
    If we look at this process from a statistical perspective, this is the process
    of removing noise and reducing the dimensions of the data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，特征量化了原始数据，并且只包含对当前机器学习任务重要的信息。我们使用这些特征来确保我们在训练期间找到数据中的模式，然后可以在部署期间使用这些模式。如果我们从测量理论的角度来看这个过程，这个过程改变了数据的抽象级别。如果我们从统计学的角度来看这个过程，这是一个去除噪声和降低数据维度的过程。
- en: In this chapter, we’ll focus on the process of reducing the dimensions of the
    data and denoising the image data using advanced methods such as autoencoders.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点关注使用诸如自动编码器等高级方法来降低数据维度和去噪图像数据的过程。
- en: '*Figure 7**.1* presents where feature extraction is placed in a typical machine
    learning pipeline. This pipeline was presented in [*Chapter 2*](B19548_02.xhtml#_idTextAnchor023):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7**.1* 展示了特征提取在典型机器学习流程中的位置。这个流程在[*第 2 章*](B19548_02.xhtml#_idTextAnchor023)中介绍过：'
- en: '![Figure 7.1 – Feature engineering in a typical machine learning pipeline](img/B19548_07_1.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.1 – 典型机器学习流程中的特征工程](img/B19548_07_1.jpg)'
- en: Figure 7.1 – Feature engineering in a typical machine learning pipeline
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – 典型机器学习流程中的特征工程
- en: 'This figure shows that the features are as close to the clean and validated
    data as possible, so we need to rely on the techniques from the previous chapters
    to visualize the data and reduce the noise. The next activity, after feature engineering,
    is modeling the data, as presented in *Figure 7**.2*. This figure shows a somewhat
    simplified view of the entire pipeline. This was also presented in [*Chapter 2*](B19548_02.xhtml#_idTextAnchor023):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 此图显示特征尽可能接近干净和验证过的数据，因此我们需要依赖前几章中的技术来可视化数据并减少噪声。特征工程之后的下一个活动是建模数据，如图 *7**.2*
    所示。此图展示了整个流程的某种简化视图。这也在[*第 2 章*](B19548_02.xhtml#_idTextAnchor023)中介绍过：
- en: '![Figure 7.2 – A typical machine learning pipeline. A somewhat simplified view
    from Chapter 2](img/B19548_07_2.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.2 – 典型机器学习流程。来自第 2 章的某种简化视图](img/B19548_07_2.jpg)'
- en: Figure 7.2 – A typical machine learning pipeline. A somewhat simplified view
    from [*Chapter 2*](B19548_02.xhtml#_idTextAnchor023)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – 典型机器学习流程。来自[*第 2 章*](B19548_02.xhtml#_idTextAnchor023)的某种简化视图
- en: We covered modeling previously, so let’s dive deeper into the feature extraction
    process. Since numerical and image data are somewhat similar from this perspective,
    we’ll discuss them together in this chapter. Text data is different and therefore
    we have devoted the next chapter to it.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已经讨论过建模，所以让我们更深入地探讨特征提取过程。由于数值数据和图像数据从这个角度来看有些相似，所以我们将在本章一起讨论它们。文本数据是不同的，因此我们将在下一章中专门讨论它。
- en: My first best practice in this chapter, however, is related to the link between
    feature extraction and models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，本章我的第一个最佳实践与特征提取和模型之间的联系相关。
- en: 'Best practice #39'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #39'
- en: Use feature engineering techniques if the data is complex, but the task is simple
    – for example, creating a classification model.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据复杂但任务简单，例如创建一个分类模型，请使用特征工程技术。
- en: If the data is complex and the task is complex, try to use complex but capable
    models, such as the transformer models presented later in this book. An example
    of such a task can be code completion when the model finished creating a piece
    of a program that a programmer started to write. Simplifying complex data for
    simpler models allows us to increase the explainability of the trained models
    because we, as AI engineers, are more involved in the process through data wrangling.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据复杂且任务复杂，尝试使用复杂但功能强大的模型，例如本书后面介绍的变压器模型。这类任务的例子可以是当模型完成了一个程序员开始编写的程序的一部分时进行代码补全。简化复杂数据以适应更简单的模型，可以使我们增加训练模型的可解释性，因为我们作为人工智能工程师，在数据整理过程中更加参与。
- en: Feature engineering for numerical data
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数值数据的特征工程
- en: We’ll introduce feature engineering for numerical data by using the same technique
    that we used previously but for visualizing data – PCA.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过使用之前用于可视化数据的技术来介绍数值数据的特征工程 – 主成分分析（PCA）。
- en: PCA
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PCA
- en: 'PCA is used to transform a set of variables into components that are supposed
    to be independent of one another. The first component should explain the variability
    of the data or be correlated with most of the variables. *Figure 7**.3* illustrates
    such a transformation:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 用于将一组变量转换成相互独立的部分。第一个部分应该解释数据的变异性或与大多数变量相关。*图 7**.3* 说明了这种转换：
- en: '![Figure 7.3 – Graphical illustration of the PCA transformation from two dimensions
    to two dimensions](img/B19548_07_3.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3 – 从二维到二维的 PCA 变换的图形说明](img/B19548_07_3.jpg)'
- en: Figure 7.3 – Graphical illustration of the PCA transformation from two dimensions
    to two dimensions
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3 – 从二维到二维的 PCA 变换的图形说明
- en: This figure contains two axes – the blue ones, which are the original coordinates,
    and the orange ones, which are the imaginary axes and provide the coordinates
    for the principal components. The transformation does not change the values of
    the *x* and *y* axes and instead finds such a transformation that the axes align
    with the data points. Here, we can see that the transformed *Y* axis aligns better
    with the data points than the original *Y* axis.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图包含两个轴——蓝色的轴是原始坐标轴，橙色的轴是想象中的轴，为主成分提供坐标。转换不会改变*x*和*y*轴的值，而是找到这样的转换，使得轴与数据点对齐。在这里，我们可以看到转换后的*Y*轴比原始的*Y*轴更好地与数据点对齐。
- en: 'Now, let’s execute a bit of code that can read the data and make such a PCA
    transformation. In this example, the data has six dimensions – that is, six variables:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们执行一些代码，这些代码可以读取数据并执行这种PCA转换。在这个例子中，数据有六个维度——也就是说，六个变量：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding code fragment reads the data and shows that it has six dimensions.
    Now, let’s create the PCA transformation. First, we must remove the dependent
    variable in our dataset – `Defect`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码片段读取数据并显示它有六个维度。现在，让我们创建PCA转换。首先，我们必须从我们的数据集中移除依赖变量`Defect`：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, we must import the PCA transformation and execute it. We want to find
    a transformation from the five variables (six minus the `Defect` variable) to
    three dimensions. The number of dimensions is completely arbitrary, but since
    we used two in the previous chapters, let’s use more this time:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须导入PCA转换并执行它。我们希望从五个变量（减去`Defect`变量后的六个变量）转换到三个维度。维度的数量完全是任意的，但因为我们之前章节中使用了两个维度，所以这次让我们使用更多：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The resulting DataFrame – `dfDataAnt13PCA` – contains the values of the transformed
    variables. They are as independent from one another as possible (linearly independent).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的DataFrame——`dfDataAnt13PCA`——包含了转换后变量的值。它们尽可能独立于彼此（线性独立）。
- en: I would like to emphasize the general scheme of how we work with this kind of
    data transformation because that is a relatively standard way of doing things.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我想强调一下我们如何处理这类数据转换的一般方案，因为这是一种相对标准的做事方式。
- en: First, we instantiate the transformation module and provide the arguments. In
    most cases, the arguments are plenty, but there is one, `n_components`, that describes
    how many components we want to have.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们实例化转换模块并提供参数。在大多数情况下，参数很多，但有一个参数`n_components`，它描述了我们希望有多少个组件。
- en: Second, we use the `fit_transform()` function to train the classifier and transform
    it into these components. We use these two operations together, simply because
    these transformations are data-specific. There is no need to train the transformation
    on one data and apply it to another one.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，我们使用`fit_transform()`函数来训练分类器并将其转换成这些组件。我们使用这两个操作一起，仅仅是因为这些转换是针对特定数据的。没有必要在一个数据上训练转换，然后应用到另一个数据上。
- en: 'What we can also do with PCA, which we cannot do with other types of transformations,
    is check how much variability each component explains – that is, how well the
    components align with the data. We can do this with the following code:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用PCA做的，而其他类型的转换做不到的是，检查每个组件解释了多少变异性——也就是说，组件与数据对齐得有多好。我们可以用以下代码来做这件事：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This code fragment results in the diagram presented in *Figure 7**.4*:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码片段产生了*图7**.4*所示的图表：
- en: '![Figure 7.4 – Variability explained by the principal components](img/B19548_07_4.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图7.4 – 主成分解释的变异性](img/B19548_07_4.jpg)'
- en: Figure 7.4 – Variability explained by the principal components
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 – 主成分解释的变异性
- en: This figure shows that the first component is the most important one – that
    is, it explains the largest amount of variability. This variability can be seen
    as the amount of information that the data contains. In the case of this dataset,
    the first component explains about 80% of the variability and the second one almost
    20%. This means that our dataset has one dominating dimension and some dispersion
    of the data along a second dimension. The third dimension is almost non-existent.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图显示第一个组件是最重要的——也就是说，它解释了最大的变异性。这种变异性可以看作是数据包含的信息量。在这个数据集的例子中，第一个组件解释了大约80%的变异性，第二个组件几乎解释了20%。这意味着我们的数据集有一个主导维度，以及数据在第二个维度上的分散。第三个维度几乎不存在。
- en: This is where my next best practice comes in.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我的下一个最佳实践所在。
- en: 'Best practice #40'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #40'
- en: Use PCA if the data is somehow linearly separable and on similar scales.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据在某种程度上是线性可分的，并且处于相似的比例，请使用 PCA。
- en: If the data is linear, or multilinear, PCA makes a large difference for training
    the model. However, if the data is not linear, use a more complex model, such
    as t-SNE.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据是线性的，或者多线性的，PCA 对于训练模型有很大的帮助。然而，如果数据不是线性的，请使用更复杂的模型，例如 t-SNE。
- en: t-SNE
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: t-SNE
- en: As a transformation, PCA works well when data is linearly separable to some
    extent. In practice, this means that the coordinate system can be positioned in
    such a way that most of the data is on one of its axes. However, not all data
    is like that. One example of data that is not like that is data that can be visualized
    as a circle – it is equally distributed along both axes.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种转换，PCA 在数据在某种程度上线性可分时工作得很好。在实践中，这意味着坐标系可以定位得使大部分数据位于其轴之一上。然而，并非所有数据都如此。一个这样的数据例子是可以被可视化为圆的数据
    – 它在两个轴上均匀分布。
- en: To reduce the dimensions of non-linear data, we can use another technique –
    t-SNE. This kind of dimensionality reduction technique is based on extracting
    the activation values of a neural network, which is trained to fit the input data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了降低非线性数据的维度，我们可以使用另一种技术 – t-SNE。这种降维技术基于提取一个神经网络的激活值，该神经网络被训练以拟合输入数据。
- en: 'The following code fragment creates such a t-SNE transformation of the data.
    It follows the same schema that was described for the PCA and it also reduces
    the dimensions to three:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段创建了对数据进行 t-SNE 转换。它遵循了之前描述的 PCA 的相同架构，并且也将维度降低到三个：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The resulting DataFrame – `dfDataAnt13TSNE` – contains the transformed data.
    Unfortunately, the t-SNE transformation does not allow us to get the value of
    the explained variability, simply because this concept does not exist for such
    a transformation. However, we can visualize it. The following figure presents
    a 3D projection of the three components:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的 DataFrame – `dfDataAnt13TSNE` – 包含了转换后的数据。不幸的是，t-SNE 转换不允许我们获取解释变异性的值，因为这种概念对于这种转换来说并不存在。然而，我们可以可视化它。以下图展示了三个成分的
    3D 投影：
- en: '![Figure 7.5 – Visualization of the t-SNE components. Green dots represent
    defect-free components and red dots represent components with defects](img/B19548_07_5.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.5 – t-SNE 成分的可视化。绿色点代表无缺陷成分，红色点代表有缺陷的成分](img/B19548_07_5.jpg)'
- en: Figure 7.5 – Visualization of the t-SNE components. Green dots represent defect-free
    components and red dots represent components with defects
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5 – t-SNE 成分的可视化。绿色点代表无缺陷成分，红色点代表有缺陷的成分
- en: Here is my next best practice for this chapter.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我在本章中的下一个最佳实践。
- en: 'Best practice #41'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #41'
- en: Use t-SNE if you do not know the properties of the data and the dataset is large
    (more than 1,000 data points).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对数据的属性不了解，并且数据集很大（超过 1,000 个数据点），请使用 t-SNE。
- en: t-SNE is a very good and robust transformation. It works particularly well for
    large datasets – that is, those that consist of hundreds of data points. One of
    the challenges, however, is that there is no interpretation of the components
    that t-SNE delivers. We should also know that the best results from t-SNE require
    hyperparameters to be tuned carefully.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: t-SNE 是一个非常好且稳健的转换。它特别适用于大型数据集 – 即那些包含数百个数据点的数据集。然而，一个挑战是，t-SNE 提供的成分没有解释。我们还应该知道，t-SNE
    的最佳结果需要仔细调整超参数。
- en: ICA
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ICA
- en: We can use another kind of transformation here – ICA. This transformation works
    in such a way that it finds the least correlated data points and separates them.
    It’s been historically used in the medical domain to remove disturbances and artifacts
    from high-frequency **electroencephalography** (**EEG**) signals. An example of
    such a disturbance is the 50 - Hz electrical power signal.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用另一种类型的转换 – ICA。这种转换以这种方式工作，即它找到最不相关的数据点并将它们分离。它在历史上被用于医疗领域，以从高频 **脑电图**（**EEG**）信号中去除干扰和伪影。这种干扰的一个例子是
    50 - Hz 的电力信号。
- en: 'However, it can be used for any kind of data. The following code fragment illustrates
    how ICA can be used for the same dataset that we used in the previous transformations:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它可以用于任何类型的数据。以下代码片段说明了如何使用 ICA 对我们在之前转换中使用过的相同数据集进行处理：
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'ICA needs to result in fewer components than the original data, although we
    only used three in the preceding code fragment. The visualization of these components
    is presented in the following figure:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ICA需要产生比原始数据更少的组件，尽管在前面的代码片段中我们只使用了三个。以下图示展示了这些组件的可视化：
- en: '![Figure 7.6 – Visualization of the dataset transformed using ICA](img/B19548_07_6.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图7.6 – 使用ICA转换的数据集的可视化](img/B19548_07_6.jpg)'
- en: Figure 7.6 – Visualization of the dataset transformed using ICA
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 – 使用ICA转换的数据集的可视化
- en: In *Figure 7**.6*, green components are the ones without defects and the red
    ones contain defects.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图7*.6中，绿色组件是没有缺陷的，而红色组件含有缺陷。
- en: Locally linear embedding
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局部线性嵌入
- en: A technique that is somewhat in between t-SNE and PCA (or ICA) is known as **locally
    linear embedding** (**LLE**). This technique assumes that neighboring nodes are
    placed close to one another on some kind of virtual plane. The algorithm trains
    a neural network in such a way that it preserves the distances between the neighboring
    nodes.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一种介于t-SNE和PCA（或ICA）之间的技术被称为**局部线性嵌入**（**LLE**）。这种技术假设相邻节点在某种虚拟平面上彼此靠近。算法以这种方式训练一个神经网络，即它保留了相邻节点之间的距离。
- en: 'The following code fragment illustrates how to use the LLE technique:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段说明了如何使用LLE技术：
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This fragment results in a similar DataFrame to the previous algorithms. Here
    is the visualization:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个片段的结果与之前算法的DataFrame相似。以下是可视化：
- en: '![Figure 7.7 – Visualization of the LLE components](img/B19548_07_7.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图7.7 – LLE组件的可视化](img/B19548_07_7.jpg)'
- en: Figure 7.7 – Visualization of the LLE components
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 – LLE组件的可视化
- en: All the techniques we’ve discussed so far are flexible and allow us to indicate
    how many components we need in the transformed data. However, sometimes, the problem
    is that we do not know how many components we need.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今为止讨论的所有技术都是灵活的，允许我们指明在转换后的数据中需要多少个组件。然而，有时问题在于我们不知道需要多少个组件。
- en: Linear discriminant analysis
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性判别分析
- en: '**Linear discriminant analysis** (**LDA**) is a technique that results in as
    many components as we have in our dataset. This means that the number of columns
    in our dataset is the same as the number of components that LDA provides. This,
    in turn, means that we need to define one of the variables as the dependent one
    for the algorithm to work.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性判别分析**（**LDA**）是一种技术，其结果与我们的数据集中拥有的组件数量相同。这意味着我们数据集中的列数与LDA提供的组件数相同。这反过来又意味着我们需要定义一个变量作为算法的依赖变量。'
- en: 'The LDA algorithm finds a projection of the dataset on a lower dimensional
    space in such a way that it separates the data in the classes of the dependent
    variable. Therefore, we need one. The following code fragment illustrates the
    use of LDA on our dataset:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: LDA算法以这种方式在低维空间中对数据集进行投影，使得它能够将数据分离到依赖变量的类别中。因此，我们需要一个。以下代码片段说明了在数据集上使用LDA的方法：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The resulting DataFrame contains only one component as we have only one dependent
    variable in our dataset.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 结果DataFrame只包含一个组件，因为我们数据集中只有一个依赖变量。
- en: Autoencoders
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动编码器
- en: In recent years, a new technique for feature extraction has been gaining popularity
    – autoencoders. Autoencoders are special kinds of neural networks that are designed
    to transform data from one type of data into another. Usually, they are used to
    recreate the input data in a slightly modified form. For example, they can be
    used to remove noise from images or change images to use different styles of brushes.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，一种新的特征提取技术越来越受欢迎——自动编码器。自动编码器是一种特殊的神经网络，旨在将一种类型的数据转换成另一种类型的数据。通常，它们被用来以略微修改的形式重建输入数据。例如，它们可以用来去除图像中的噪声或将图像转换为使用不同画笔风格的图像。
- en: 'Autoencoders are quite generic and can be used for other kinds of data, which
    we’ll learn about in the remainder of this chapter (for example, for image data).
    *Figure 7**.8* presents the conceptual model of autoencoders. They consist of
    two parts – an encoder and a decoder. The role of the encoder is to transform
    the input data – an image in this example – into an abstract representation. This
    abstract representation is stored in a specific layer (or layers), which is called
    the bottleneck. The role of the bottleneck is to store such properties of the
    input data that allow the decoder to recreate the data. The role of the decoder
    is to take the abstract representation of the data from the bottleneck layer and
    re-create the input data as best as possible:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 自动编码器非常通用，可以用于其他类型的数据，我们将在本章的剩余部分学习这些内容（例如，用于图像数据）。*图7.8*展示了自动编码器的概念模型。它由两部分组成——编码器和解码器。编码器的作用是将输入数据——在这个例子中是一个图像——转换成抽象表示。这种抽象表示存储在特定的层（或几层），称为瓶颈。瓶颈的作用是存储允许解码器重建数据的输入数据的属性。解码器的作用是从瓶颈层获取数据的抽象表示，并尽可能好地重建输入数据：
- en: '![Figure 7.8 – Conceptual visualization of an autoencoder. Here, the input
    data is in the form of an image](img/B19548_07_8.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图7.8 – 自动编码器的概念可视化。这里，输入数据是图像的形式](img/B19548_07_8.jpg)'
- en: Figure 7.8 – Conceptual visualization of an autoencoder. Here, the input data
    is in the form of an image
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 – 自动编码器的概念可视化。这里，输入数据是图像的形式
- en: Since autoencoders are trained to recreate the data as best as possible, the
    bottleneck values are generally believed to be a good internal representation
    of the input data. It is such a good representation that it allows us to discriminate
    between different input data points.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 由于自动编码器被训练以尽可能好地重建数据，瓶颈值通常被认为是对输入数据的良好内部表示。这种表示如此之好，以至于它允许我们区分不同的输入数据点。
- en: The bottleneck values are also very flexible. As opposed to the techniques presented
    previously, there is no limit on how many features we can extract. If we need
    to, we can even extract more features than we have columns in our dataset, although
    it does not make much sense.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 瓶颈值也非常灵活。与之前介绍的技术不同，我们没有限制可以提取多少特征。如果我们需要，我们甚至可以提取比我们数据集中列数更多的特征，尽管这样做没有太多意义。
- en: So, let’s construct a pipeline for extracting features from an autoencoder that’s
    designed to learn the representation of the defect data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们构建一个用于从设计用来学习缺陷数据表示的自动编码器中提取特征的管道：
- en: 'The following code fragment illustrates reading the dataset and removing the
    defect column from it:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段展示了如何读取数据集并从中移除有缺陷的列：
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In addition to the removal of the column, we need to scale the data so that
    the autoencoder has a good chance of recognizing small patterns in all columns:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 除了移除列之外，我们还需要对数据进行缩放，以便自动编码器有很好的机会识别所有列中的小模式：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, we can create the encoder part of our autoencoder, which is shown in the
    following code fragment:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以创建我们的自动编码器的编码器部分，它将在下面的代码片段中展示：
- en: '[PRE10]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding code creates two levels of the autoencoder since our data is
    quite simple. Now, the interesting part is the bottleneck, which can be created
    by running the following code:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码创建了自动编码器的两个级别，因为我们的数据相当简单。现在，有趣的部分是瓶颈，可以通过运行以下代码来创建：
- en: '[PRE11]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In our case, the bottleneck is very narrow – only three neurons – as the dataset
    is rather small and it is not very complex. In the next part, when we use the
    autoencoder for images, we will see that the bottleneck can be much wider. The
    general idea is that wider bottlenecks allow us to capture more complex dependencies
    in the data. For example, for color images, we need more neurons as we need to
    capture colors, while for grayscale images, we need narrower bottlenecks.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，瓶颈非常窄——只有三个神经元——因为数据集相对较小，且并不复杂。在下一部分，当我们使用自动编码器处理图像时，我们将看到瓶颈可以更宽。一般的思想是，更宽的瓶颈允许我们捕捉数据中的更复杂依赖关系。例如，对于彩色图像，我们需要更多的神经元，因为我们需要捕捉颜色，而对于灰度图像，我们需要更窄的瓶颈。
- en: 'Finally, we can create the decoder part of the autoencoder by using the following
    code:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用以下代码创建自动编码器的解码器部分：
- en: '[PRE12]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The last part of the construction process is to put these three parts together
    – the encoder, the bottleneck, and the decoder. We can use the following code
    for this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 构造过程的最后一部分是将这三个部分放在一起——编码器、瓶颈和解码器。我们可以使用以下代码来完成这项工作：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'At this point, we have constructed our autoencoder. We’ve defined its layers
    and the bottleneck. Now, the autoencoder must be trained to understand how to
    represent our data. We can do this using the following code:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经构建了我们的自动编码器。我们已经定义了其层和瓶颈。现在，自动编码器必须被训练以理解如何表示我们的数据。我们可以使用以下代码来完成：
- en: '[PRE14]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Please note that we use the same data as input and as validation since we need
    to train the encoder to re-create the same data as accurately as possible, given
    the size of the bottleneck. After training the encoder model, we can use it to
    extract the bottleneck values from the model. We can do this by defining a submodel
    and using it for input data:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们使用相同的数据作为输入和验证，因为我们需要训练编码器尽可能准确地重新创建相同的数据，考虑到瓶颈层的大小。在训练编码器模型后，我们可以使用它来从模型中提取瓶颈层的值。我们可以通过定义一个子模型并使用它作为输入数据来完成：
- en: '[PRE15]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The outcome of executing this code is a vector of three values – the bottleneck
    values of the autoencoder.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此代码的结果是一个包含三个值的向量——自动编码器的瓶颈值。
- en: My next best practice in this chapter is related to the use of autoencoders.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我在本章中的下一个最佳实践与自动编码器的使用相关。
- en: 'Best practice #42'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #42'
- en: Use autoencoders for numerical data when the dataset is really large since autoencoders
    are complex and require a lot of data for training.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据集非常大时，使用自动编码器对数值数据进行处理，因为自动编码器复杂且需要大量数据进行训练。
- en: Since the quality of the features is a function of how well the autoencoder
    is trained, we need to make sure that the training dataset is large. Therefore,
    autoencoders are often used for image data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 由于特征的质量是自动编码器训练效果的一个函数，我们需要确保训练数据集足够大。因此，自动编码器通常用于图像数据。
- en: Feature engineering for image data
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像数据的特征工程
- en: One of the most prominent feature extraction methods for image data is the use
    of **convolutional neural networks** (**CNNs**) and extracting embeddings from
    these networks. In recent years, a new type of this kind of neural network was
    introduced – autoencoders. Although we can use autoencoders for all kinds of data,
    they are particularly well-suited for images. So, let’s construct an autoencoder
    for the MNIST dataset and extract bottleneck values from it.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像数据，最突出的特征提取方法之一是使用**卷积神经网络**（**CNNs**）并从这些网络中提取嵌入。近年来，引入了这种类型神经网络的一种新类型——自动编码器。虽然我们可以使用自动编码器处理各种数据，但它们特别适合图像。因此，让我们为MNIST数据集构建一个自动编码器，并从中提取瓶颈层的值。
- en: 'First, we need to download the MNIST dataset using the following code fragment:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要使用以下代码片段下载MNIST数据集：
- en: '[PRE16]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we can construct the encoder part by using the following code. Please
    note that there is one extra layer in the encoder part. The goal of this layer
    is to transform a two-dimensional image into a one-dimensional input array – to
    flatten the image:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用以下代码构建编码器部分。请注意，编码器部分有一个额外的层。该层的目的是将二维图像转换为一维输入数组——即展平图像：
- en: '[PRE17]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we can construct our bottleneck. In this case, the bottleneck can be much
    wider as the images are more complex (and there are more of them) than the array
    of numerical values of modules, which we used in the previous autoencoder:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以构建我们的瓶颈层。在这种情况下，瓶颈层可以更宽，因为图像比我们之前在自动编码器中使用的模块数值数组更复杂（而且数量更多）：
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The decoder part is very similar to the previous example, with one extra layer
    that re-creates the image from its flat representation:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器部分与之前的例子非常相似，但有一个额外的层，该层可以从其扁平表示中重新创建图像：
- en: '[PRE19]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, we can compile and train the autoencoder:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以编译和训练自动编码器：
- en: '[PRE20]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Finally, we can extract the bottleneck values from the model:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以从模型中提取瓶颈层的值：
- en: '[PRE21]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now, the resulting array of values is much larger – it has 32 values, the same
    number of neurons that we have in our bottleneck.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，结果值的数组要大得多——它有32个值，与我们瓶颈层中的神经元数量相同。
- en: The number of neurons in the bottleneck is essentially arbitrary. Here’s a best
    practice for selecting the number of neurons.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 瓶颈层中的神经元数量基本上是任意的。以下是选择神经元数量的最佳实践。
- en: 'Best practice #43'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #43'
- en: Start with a small number of neurons in the bottleneck – usually one third of
    the number of columns. If the autoencoder does not learn, increase the number
    gradually.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在瓶颈层开始时使用较少的神经元数量——通常是列数的三分之一。如果自动编码器没有学习，可以逐渐增加数量。
- en: There is no specific reason why I chose 1/3rd of the number of columns, just
    experience. You can start from the opposite direction – make the bottleneck layer
    as wide as the input – and decrease gradually. However, having the same number
    of features as the number of columns is not why we use feature extraction in the
    first place.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择1/3的列数并没有具体的原因，只是基于经验。你可以从相反的方向开始——将瓶颈层做得和输入层一样宽——然后逐渐减小。然而，拥有与列数相同数量的特征并不是我们最初使用特征提取的原因。
- en: Summary
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, our focus was on feature extraction techniques. We explored
    how we can use dimensionality reduction techniques and autoencoders to reduce
    the number of features in order to make machine learning models more effective.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们的重点是特征提取技术。我们探讨了如何使用降维技术和自动编码器来减少特征数量，以便使机器学习模型更加有效。
- en: However, numerical and image data are only two examples of data. In the next
    chapter, we continue with the feature engineering methods, but for textual data,
    which is more common in contemporary software engineering.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，数值和图像数据只是数据类型中的两个例子。在下一章中，我们将继续介绍特征工程方法，但对于文本数据，这在当代软件工程中更为常见。
- en: References
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Zheng, A. and A. Casari, Feature engineering for machine learning: principles
    and techniques for data scientists. 2018: O’Reilly* *Media, Inc*'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Zheng, A. 和 A. Casari，机器学习特征工程：数据科学家原理与技术。2018年：O’Reilly* *媒体公司*'
- en: '*Heaton, J. An empirical analysis of feature engineering for predictive modeling.
    In SoutheastCon 2016\.* *2016\. IEEE.*'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Heaton, J. 对预测建模中特征工程的经验分析。在2016年东南会议\.* *2016年，IEEE。*'
- en: '*Staron, M. and W. Meding, Software Development Measurement Programs. Springer.
    https://doi.org/10.1007/978-3-319-91836-5\. Vol. 10\.* *2018\. 3281333.*'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Staron, M. 和 W. Meding，软件开发度量计划。Springer。https://doi.org/10.1007/978-3-319-91836-5\.
    第10卷\.* *2018年，3281333.*'
- en: '*Abran, A., Software metrics and software metrology. 2010: John Wiley &* *Sons.*'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Abran, A.，软件度量与软件计量学。2010年：John Wiley &* *Sons。*'
- en: '*Meng, Q., et al. Relational autoencoder for feature extraction. In 2017 International
    joint conference on neural networks (IJCNN).* *2017\. IEEE.*'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Meng, Q.，等人。关系自动编码器用于特征提取。在2017年国际神经网络联合会议（IJCNN）。* *2017年，IEEE。*'
- en: '*Masci, J., et al. Stacked convolutional auto-encoders for hierarchical feature
    extraction. In Artificial Neural Networks and Machine Learning, ICANN 2011: 21st
    International Conference on Artificial Neural Networks, Espoo, Finland, June 14-17,
    2011, Proceedings, Part I 21\.* *2011\. Springer.*'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Masci, J.，等人。用于层次特征提取的堆叠卷积自动编码器。在人工神经网络与机器学习，ICANN 2011：第21届国际人工神经网络会议，芬兰埃斯波，2011年6月14-17日，第21卷\.*
    *2011年，Springer。*'
- en: '*Rumelhart, D.E., G.E. Hinton, and R.J. Williams, Learning representations
    by back-propagating errors. nature, 1986\. 323(6088):* *p. 533-536.*'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Rumelhart, D.E.，G.E. Hinton，和R.J. Williams，通过反向传播错误学习表示。自然，1986年，323(6088)：*
    *p. 533-536.*'
- en: '*Mosin, V., et al., Comparing autoencoder-based approaches for anomaly detection
    in highway driving scenario images. SN Applied Sciences, 2022\. 4(12):* *p. 334.*'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Mosin, V.，等人，比较基于自动编码器的高速公路驾驶场景图像异常检测方法。SN 应用科学，2022年，4(12)：* *p. 334.*'
