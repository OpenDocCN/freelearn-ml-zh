- en: Chapter 11. Processing Video Sequences
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章 处理视频序列
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下食谱：
- en: Reading video sequences
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取视频序列
- en: Processing the video frames
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理视频帧
- en: Writing video sequences
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 写入视频序列
- en: Tracking feature points in a video
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在视频中跟踪特征点
- en: Extracting the foreground objects in a video
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从视频中提取前景对象
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Video signals constitute a rich source of visual information. They are made
    of a sequence of images, called **frames**, that are taken at regular time intervals
    (specified as the **frame rate**, generally expressed in frames per second) and
    show a scene in motion. With the advent of powerful computers, it is now possible
    to perform advanced visual analysis on video sequences—sometimes at rates close
    to, or even faster than, the actual video frame rate. This chapter will show you
    how to read, process, and store video sequences.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 视频信号构成了丰富的视觉信息来源。它们由一系列图像组成，称为**帧**，这些图像以固定的时间间隔（指定为**帧率**，通常以每秒帧数表示）拍摄，并显示一个动态场景。随着强大计算机的出现，现在可以在视频序列上执行高级视觉分析——有时接近或甚至超过实际视频帧率。本章将向您展示如何读取、处理和存储视频序列。
- en: We will see that once the individual frames of a video sequence have been extracted,
    the different image processing functions presented in this book can be applied
    to each of them. In addition, we will also look at a few algorithms that perform
    a temporal analysis of the video sequence, compare adjacent frames to track objects,
    or cumulate image statistics over time in order to extract foreground objects.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到，一旦提取了视频序列的各个帧，本书中介绍的不同图像处理函数可以应用于每一帧。此外，我们还将探讨一些执行视频序列时间分析的算法，比较相邻帧以跟踪对象，或随时间累积图像统计信息以提取前景对象。
- en: Reading video sequences
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取视频序列
- en: In order to process a video sequence, we need to be able to read each of its
    frames. OpenCV has put in place an easy-to-use framework that can help us perform
    frame extraction from video files or even from USB or IP cameras. This recipe
    shows you how to use it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理视频序列，我们需要能够读取其每一帧。OpenCV提供了一个易于使用的框架，可以帮助我们从视频文件或甚至从USB或IP摄像头中提取帧。本食谱将展示如何使用它。
- en: How to do it...
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Basically, all you need to do in order to read the frames of a video sequence
    is create an instance of the `cv::VideoCapture` class. You then create a loop
    that will extract and read each video frame. Here is a basic `main` function that
    displays the frames of a video sequence:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，为了读取视频序列的帧，你需要创建一个`cv::VideoCapture`类的实例。然后创建一个循环来提取和读取每个视频帧。以下是一个基本的`main`函数，用于显示视频序列的帧：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A window will appear on which the video will play as shown in the following
    screenshot:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 将出现一个窗口，视频将在其中播放，如下面的截图所示：
- en: '![How to do it...](img/00186.jpeg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/00186.jpeg)'
- en: How it works...
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'To open a video, you simply need to specify the video filename. This can be
    done by providing the name of the file in the constructor of the `cv::VideoCapture`
    object. It is also possible to use the open method if the `cv::VideoCapture object`
    has already been created. Once the video is successfully opened (this can be verified
    through the `isOpened` method), it is possible to start the frame extraction.
    It is also possible to query the `cv::VideoCapture` object for information associated
    with the video file by using its get method with the appropriate flag. In the
    preceding example, we obtained the frame rate using the `CV_CAP_PROP_FPS` flag.
    Since it is a generic function, it always returns a double even if another type
    would be expected in some cases. For example, the total number of frames in the
    video file would be obtained (as an integer) as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要打开视频，你只需指定视频文件名。这可以通过在`cv::VideoCapture`对象的构造函数中提供文件名来实现。如果已经创建了`cv::VideoCapture对象`，也可以使用open方法。一旦视频成功打开（可以通过`isOpened`方法进行验证），就可以开始帧提取。还可以使用`cv::VideoCapture`对象的get方法及其适当的标志来查询与视频文件关联的信息。在先前的示例中，我们使用`CV_CAP_PROP_FPS`标志获取了帧率。由于它是一个通用函数，它总是返回一个双精度浮点数，即使在某些情况下预期返回其他类型。例如，视频文件中的总帧数（作为一个整数）可以通过以下方式获取：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Have a look at the different flags that are available in the OpenCV documentation
    in order to find out what information can be obtained from the video.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 查看OpenCV文档中可用的不同标志，以了解可以从视频中获取哪些信息。
- en: 'There is also a `set` method that allows you to input parameters into the `cv::VideoCapture`
    instance. For example, you can request to move to a specific frame using the `CV_CAP_PROP_POS_FRAMES`
    flag:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个 `set` 方法，允许您向 `cv::VideoCapture` 实例输入参数。例如，您可以使用 `CV_CAP_PROP_POS_FRAMES`
    标志请求移动到特定的帧：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can also specify the position in milliseconds using `CV_CAP_PROP_POS_MSEC`,
    or you can specify the relative position inside the video using `CV_CAP_PROP_POS_AVI_RATIO`
    (with 0.0 corresponding to the beginning of the video and 1.0 to the end). The
    method returns `true` if the requested parameter setting is successful. Note that
    the possibility to get or set a particular video parameter largely depends on
    the codec that is used to compress and store the video sequence. If you are unsuccessful
    with some parameters, that could be simply due to the specific codec you are using.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用 `CV_CAP_PROP_POS_MSEC` 指定毫秒位置，或者使用 `CV_CAP_PROP_POS_AVI_RATIO` 指定视频内部的相对位置（0.0
    对应视频的开始，1.0 对应视频的结束）。如果请求的参数设置成功，该方法返回 `true`。请注意，获取或设置特定视频参数的可能性很大程度上取决于用于压缩和存储视频序列的编解码器。如果您在某些参数上失败，那可能仅仅是由于您使用的特定编解码器。
- en: 'Once the captured video is successfully opened, the frames can be sequentially
    obtained by repetitively calling the `read` method as we did in the example of
    the previous section. One can equivalently call the overloaded reading operator:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦成功打开捕获的视频，可以通过重复调用 `read` 方法来按顺序获取帧，就像我们在上一节示例中所做的那样。也可以等价地调用重载的读取操作符：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'It is also possible to call the two basic methods:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以调用两个基本方法：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Also note how, in our example, we introduced a delay in displaying each frame.
    This is done using the `cv::waitKey` function. Here, we set the delay at a value
    that corresponds to the input video frame rate (if `fps` is the number of frames
    per second, then `1000/fps` is the delay between two frames in milliseconds).
    You can obviously change this value to display the video at a slower or faster
    speed. However, if you are going to display the video frames, it is important
    that you insert such a delay if you want to make sure that the window has sufficient
    time to refresh (since it is a process of low priority, it will never refresh
    if the CPU is too busy). The `cv::waitKey` function also allows us to interrupt
    the reading process by pressing any key. In such a case, the function returns
    the ASCII code of the key that is pressed. Note that if the delay specified to
    the `cv::waitKey` function is `0`, then it will wait indefinitely for the user
    to press a key. This is very useful if someone wants to trace a process by examining
    the results frame by frame.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，在我们的示例中，我们如何在显示每一帧时引入延迟。这是通过使用 `cv::waitKey` 函数实现的。在这里，我们设置延迟为一个与输入视频帧率相对应的值（如果
    `fps` 是每秒的帧数，那么两个帧之间的延迟（以毫秒为单位）是 `1000/fps`）。显然，您可以更改此值以以较慢或较快的速度显示视频。然而，如果您打算显示视频帧，如果您想确保窗口有足够的时间刷新（因为这是一个低优先级的过程，如果CPU太忙，它将永远不会刷新），那么插入这样的延迟是很重要的。`cv::waitKey`
    函数还允许我们通过按任意键来中断读取过程。在这种情况下，函数返回按下的键的ASCII码。请注意，如果指定给 `cv::waitKey` 函数的延迟是 `0`，那么它将无限期地等待用户按下一个键。这对于某人想要通过逐帧检查结果来跟踪过程非常有用。
- en: The final statement calls the `release` method, which will close the video file.
    However, this call is not required since `release` is also called by the `cv::VideoCapture`
    destructor.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一条语句调用 `release` 方法，这将关闭视频文件。然而，这个调用不是必需的，因为 `release` 也会在 `cv::VideoCapture`
    析构函数中被调用。
- en: It is important to note that in order to open the specified video file, your
    computer must have the corresponding codec installed; otherwise, `cv::VideoCapture`
    will not be able to decode the input file. Normally, if you are able to open your
    video file with a video player on your machine (such as Windows Media Player),
    then OpenCV should also be able to read this file.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，为了打开指定的视频文件，您的计算机必须安装相应的编解码器；否则，`cv::VideoCapture` 将无法解码输入文件。通常情况下，如果您能够使用机器上的视频播放器（如Windows
    Media Player）打开视频文件，那么OpenCV也应该能够读取此文件。
- en: There's more...
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: You can also read the video stream capture of a camera that is connected to
    your computer (a USB camera, for example). In this case, you simply specify an
    ID number (an integer) instead of a filename to the `open` function. Specifying
    `0` for the ID will open the default installed camera. In this case, the role
    of the `cv::waitKey` function that stops the processing becomes essential, since
    the video stream from the camera will be infinitely read.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以读取连接到计算机的摄像头（例如USB摄像头）的视频流捕获。在这种情况下，您只需将ID号（一个整数）指定给`open`函数，而不是文件名。将ID指定为`0`将打开默认安装的摄像头。在这种情况下，`cv::waitKey`函数停止处理的作用变得至关重要，因为来自摄像头的视频流将被无限读取。
- en: 'Finally, it is also possible to load a video from the Web. In this case, all
    you have to do is provide the correct address, for example:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，也可以从网络加载视频。在这种情况下，您只需提供正确的地址，例如：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: See also
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Writing video sequences* recipe in this chapter has more information on
    video codecs.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中关于*写入视频序列*的菜谱提供了更多关于视频编解码器的信息。
- en: The [http://ffmpeg.org/](http://ffmpeg.org/) website presents a complete open
    source and cross-platform solution for audio/video reading, recording, converting,
    and streaming. The OpenCV classes that manipulate video files are built on top
    of this library.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://ffmpeg.org/](http://ffmpeg.org/) 网站提供了一个完整的开源和跨平台解决方案，用于音频/视频的读取、录制、转换和流式传输。处理视频文件的OpenCV类是建立在上述库之上的。'
- en: Processing the video frames
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理视频帧
- en: In this recipe, our objective is to apply some processing function to each of
    the frames of a video sequence. We will do this by encapsulating the OpenCV video
    capture framework into our own class. Among other things, this class will allow
    us to specify a function that will be called each time a new frame is extracted.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们的目标是将一些处理函数应用于视频序列的每一帧。我们将通过封装OpenCV视频捕获框架到我们自己的类中来实现这一点。除此之外，此类将允许我们指定一个函数，每次提取新帧时都会调用该函数。
- en: How to do it...
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'What we want is to be able to specify a processing function (a callback function)
    that will be called for each frame of a video sequence. This function can be defined
    as receiving a `cv::Mat` instance and outputting a processed frame. Therefore,
    in our framework, the processing function must have the following signature to
    be a valid callback:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要的是能够指定一个处理函数（回调函数），该函数将为视频序列的每一帧调用。此函数可以定义为接收一个`cv::Mat`实例并输出一个处理后的帧。因此，在我们的框架中，处理函数必须具有以下签名才能成为有效的回调：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As an example of such a processing function, consider the following simple
    function that computes the Canny edges of an input image:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 作为此类处理函数的示例，考虑以下简单的函数，该函数计算输入图像的Canny边缘：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Our `VideoProcessor` class encapsulates all aspects of a video-processing task.
    Using this class, the procedure will be to create a class instance, specify an
    input video file, attach the callback function to it, and then start the process.
    Programmatically, these steps are accomplished using our proposed class, as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`VideoProcessor`类封装了视频处理任务的各个方面。使用此类，步骤将是创建一个类实例，指定一个输入视频文件，将其回调函数附加到它，然后开始处理。程序上，这些步骤是通过我们提出的类完成的，如下所示：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If this code is run, then two windows will play the input video and the output
    result at the original frame rate (a consequence of the delay introduced by the
    `setDelay` method). For example, considering the input video for which a frame
    is shown in the previous recipe, the output window will look as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果运行此代码，则两个窗口将以原始帧率播放输入视频和输出结果（这是由`setDelay`方法引入的延迟的结果）。例如，考虑前一个菜谱中显示的输入视频的帧，输出窗口将如下所示：
- en: '![How to do it...](img/00187.jpeg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/00187.jpeg)'
- en: How it works...
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'As we did in other recipes, our objective was to create a class that encapsulates
    the common functionalities of a video-processing algorithm. As one might expect,
    the class includes several member variables that control the different aspects
    of the video frame processing:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在其他菜谱中所做的那样，我们的目标是创建一个封装视频处理算法常见功能的类。正如预期的那样，该类包括几个成员变量，用于控制视频帧处理的各个方面：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The first member variable is the `cv::VideoCapture` object. The second attribute
    is the `process` function pointer that will point to the callback function. This
    function can be specified using the corresponding setter method:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个成员变量是`cv::VideoCapture`对象。第二个属性是`process`函数指针，它将指向回调函数。此函数可以使用相应的setter方法指定：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following method opens the video file:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下方法打开视频文件：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'It is generally interesting to display the frames as they are processed. Therefore,
    two methods are used to create the display windows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在处理帧时显示帧是很有趣的。因此，使用了两个方法来创建显示窗口：
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The main method, called `run`, is the one that contains the frame extraction
    loop:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 主方法，名为 `run`，包含帧提取循环：
- en: '[PRE13]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This method uses a `private` method that reads the frames:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法使用一个 `private` 方法来读取帧：
- en: '[PRE14]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `run` method proceeds by first calling the `read` method of the `cv::VideoCapture`
    OpenCV class. There is then a series of operations that are executed, but before
    each of them is invoked, a check is made to determine whether it has been requested.
    The input window is displayed only if an input window name has been specified
    (using the `displayInput` method); the callback function is called only if one
    has been specified (using `setFrameProcessor`). The output window is displayed
    only if an output window name has been defined (using `displayOutput`); a delay
    is introduced only if one has been specified (using `setDelay` method). Finally,
    the current frame number is checked if a stop frame has been defined (using `stopAtFrameNo`).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`run` 方法首先调用 `cv::VideoCapture` OpenCV 类的 `read` 方法。然后执行一系列操作，但在调用每个操作之前，都会进行检查以确定是否已请求执行。只有当指定了输入窗口名称（使用
    `displayInput` 方法）时，才会显示输入窗口；只有当指定了回调函数（使用 `setFrameProcessor`）时，才会调用该函数。只有当定义了输出窗口名称（使用
    `displayOutput`）时，才会显示输出窗口；只有当指定了延迟（使用 `setDelay` 方法）时，才会引入延迟。最后，如果定义了停止帧（使用 `stopAtFrameNo`），则会检查当前帧号。'
- en: 'One might also wish to simply open and play the video file (without calling
    the callback function). Therefore, we have two methods that specify whether or
    not we want the callback function to be called:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 可能还希望简单地打开并播放视频文件（不调用回调函数）。因此，我们有两个方法来指定是否调用回调函数：
- en: '[PRE15]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, the class also offers us the possibility to stop at a certain frame
    number:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，该类还提供了在特定帧号处停止的可能性：
- en: '[PRE16]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The class also contains a number of getter and setter methods that are basically
    just a wrapper over the general `set` and `get` methods of the `cv::VideoCapture`
    framework.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 该类还包含了一些getter和setter方法，它们基本上只是 `cv::VideoCapture` 框架的通用 `set` 和 `get` 方法的包装器。
- en: There's more...
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Our `VideoProcessor` class is there to facilitate the deployment of a video-processing
    module. Few additional refinements can be made to it.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `VideoProcessor` 类旨在简化视频处理模块的部署。对此类可以进行的额外改进很少。
- en: Processing a sequence of images
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理一系列图像
- en: 'Sometimes, the input sequence is made of a series of images that are individually
    stored in distinct files. Our class can be easily modified to accommodate such
    input. You just need to add a member variable that will hold a vector of image
    filenames and its corresponding iterator:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，输入序列由一系列单独存储在各自文件中的图像组成。我们的类可以很容易地修改以适应此类输入。你只需要添加一个成员变量，它将保存一个包含图像文件名的向量及其对应的迭代器：
- en: '[PRE17]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'A new `setInput` method is used to specify the filenames to be read:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新的 `setInput` 方法来指定要读取的文件名：
- en: '[PRE18]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `isOpened` method becomes as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`isOpened` 方法变为以下内容：'
- en: '[PRE19]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The last method that needs to be modified is the private `readNextFrame` method
    that will read from the video or from the vector of filenames, depending on the
    input that has been specified. The test is that if the vector of image filenames
    is not empty, then that is because the input is an image sequence. The call to
    `setInput` with a video filename clears this vector:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 需要修改的最后一个方法是私有的 `readNextFrame` 方法，它将根据指定的输入从视频或文件名向量中读取。测试是如果图像文件名向量不为空，则说明输入是图像序列。使用视频文件名调用
    `setInput` 清除此向量：
- en: '[PRE20]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Using a frame processor class
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用帧处理器类
- en: 'In an object-oriented context, it might make more sense to use a frame processing
    class instead of a frame processing function. Indeed, a class would give the programmer
    much more flexibility in the definition of a video-processing algorithm. We can,
    therefore, define an interface that any class that wishes to be used inside the
    `VideoProcessor` will need to implement:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在面向对象的环境中，使用帧处理类而不是帧处理函数可能更有意义。确实，一个类会给程序员在视频处理算法定义上提供更多的灵活性。因此，我们可以定义一个接口，任何希望被用于
    `VideoProcessor` 内部的类都需要实现：
- en: '[PRE21]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'A setter method allows you to input a `FrameProcessor` instance to the `VideoProcessor`
    framework and assign it to the added member variable `frameProcessor` that is
    defined as a pointer to a `FrameProcessor` object:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一个setter方法允许您将一个`FrameProcessor`实例输入到`VideoProcessor`框架中，并将其分配给定义为`FrameProcessor`对象指针的添加成员变量`frameProcessor`：
- en: '[PRE22]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'When a frame processor class instance is specified, it invalidates any frame
    processing function that could have been set previously. The same obviously applies
    if a frame processing function is specified instead. The `while` loop of the `run`
    method is modified to take into account this modification:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当指定帧处理器类实例时，它将使之前可能设置的任何帧处理函数无效。如果指定了帧处理函数，则显然也是如此。`run`方法的`while`循环被修改以考虑这种修改：
- en: '[PRE23]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: See also
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Tracking feature points in a video* recipe in this chapter gives you an
    example of how to use the `FrameProcessor` class interface.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中关于*视频中的跟踪特征点*的食谱为您提供了一个如何使用`FrameProcessor`类接口的示例。
- en: Writing video sequences
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 写入视频序列
- en: 'In the previous recipes, we learned how to read a video file and extract its
    frames. This recipe will show you how to write frames and, therefore, create a
    video file. This will allow us to complete the typical video-processing chain:
    reading an input video stream, processing its frames, and then storing the results
    in a new video file.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的食谱中，我们学习了如何读取视频文件并提取其帧。本食谱将向您展示如何写入帧，从而创建视频文件。这将使我们能够完成典型的视频处理链：读取输入视频流，处理其帧，然后将结果存储在新视频文件中。
- en: How to do it...
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Writing video files in OpenCV is done using the `cv::VideoWriter` class. An
    instance is constructed by specifying the filename, the frame rate at which the
    generated video should play, the size of each frame, and whether or not the video
    will be created in color:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中，使用`cv::VideoWriter`类来写入视频文件。通过指定文件名、生成视频应播放的帧率、每帧的大小以及视频是否以彩色创建来构造一个实例：
- en: '[PRE24]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In addition, you must specify the way you want the video data to be saved. This
    is the `codec` argument; this will be discussed at the end of this recipe.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您必须指定您想要保存视频数据的方式。这是`codec`参数；这将在本食谱的末尾讨论。
- en: 'Once the video file is opened, frames can be added to it by repetitively calling
    the `write` method:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦打开视频文件，就可以通过重复调用`write`方法将其添加到文件中：
- en: '[PRE25]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Using the `cv::VideoWriter` class, our `VideoProcessor` class introduced in
    the previous recipe can easily be expanded in order to give it the ability to
    write video files. A simple program that will read a video, process it, and write
    the result to a video file would then be written as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`cv::VideoWriter`类，我们前面介绍的`VideoProcessor`类可以很容易地扩展，以便具有写入视频文件的能力。一个简单的程序将读取视频，处理它，并将结果写入视频文件，如下所示：
- en: '[PRE26]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Proceeding as we did in the preceding recipe, we also want to give the user
    the possibility to write the frames as individual images. In our framework, we
    adopt a naming convention that consists of a prefix name followed by a number
    made of a given number of digits. This number is automatically incremented as
    frames are saved. Then, to save the output result as a series of images, you would
    change the preceding statement with this one:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 按照前面食谱中的做法，我们还想给用户提供将帧作为单独图像写入的可能性。在我们的框架中，我们采用一个命名约定，它由一个前缀名称后跟一个由给定数量的数字组成的数字组成。这个数字在保存帧时会自动增加。然后，要将输出结果保存为一系列图像，您可以将前面的语句更改为以下语句：
- en: '[PRE27]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Using the specified number of digits, this call will create the `bikeOut000.jpg`,
    `bikeOut001.jpg`, and `bikeOut002.jpg` files, and so on.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指定的数字位数，这个调用将创建`bikeOut000.jpg`、`bikeOut001.jpg`和`bikeOut002.jpg`等文件。
- en: How it works...
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s now describe how to modify our `VideoProcessor` class in order to give
    it the ability to write video files. First, a `cv::VideoWriter` variable member
    must be added to our class (plus a few other attributes):'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们描述如何修改我们的`VideoProcessor`类，以便给它写入视频文件的能力。首先，必须向我们的类中添加一个`cv::VideoWriter`变量成员（以及一些其他属性）：
- en: '[PRE28]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'An extra method is used to specify (and open) the output video file:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一个额外的方法用于指定（并打开）输出视频文件：
- en: '[PRE29]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'A private method, called the `writeNextFrame` method, handles the frame writing
    procedure (in a video file or as a series of images):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 一个名为`writeNextFrame`的私有方法处理帧写入过程（在视频文件中或作为一系列图像）：
- en: '[PRE30]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'For the case where the output is made of individual image files, we need an
    additional setter method:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输出由单个图像文件组成的情况，我们需要一个额外的setter方法：
- en: '[PRE31]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Finally, a new step is then added to the video capture loop of the `run` method:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在`run`方法的视频捕获循环中添加了一个新步骤：
- en: '[PRE32]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: There's more...
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多内容...
- en: When a video is written to a file, it is saved using a codec. A **codec** is
    a software module that is capable of encoding and decoding video streams. The
    codec defines both the format of the file and the compression scheme that is used
    to store the information. Obviously, a video that has been encoded using a given
    codec must be decoded with the same codec. For this reason, four-character codes
    have been introduced to uniquely identified codecs. This way, when a software
    tool needs to write a video file, it determines the codec to be used by reading
    the specified four-character code.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当视频写入文件时，它使用编解码器进行保存。**编解码器**是一个能够编码和解码视频流的软件模块。编解码器定义了文件的格式以及用于存储信息的压缩方案。显然，使用给定编解码器编码的视频必须使用相同的编解码器进行解码。因此，引入了四字符代码来唯一标识编解码器。这样，当软件工具需要写入视频文件时，它通过读取指定的四字符代码来确定要使用的编解码器。
- en: The codec four-character code
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编解码器四字符代码
- en: 'As the name suggests, the four-character code is made up of four ASCII characters
    that can also be converted into an integer by appending them together. Using the
    `CV_CAP_PROP_FOURCC` flag of the get method of an opened `cv::VideoCapture` instance,
    you can obtain this code of an opened video file. We can define a method in our
    `VideoProcessor` class to return the four-character code of an input video:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，四字符代码由四个ASCII字符组成，也可以通过将它们连接起来转换为整数。使用已打开的`cv::VideoCapture`实例的`get`方法的`CV_CAP_PROP_FOURCC`标志，你可以获取打开视频文件的此代码。我们可以在我们的`VideoProcessor`类中定义一个方法来返回输入视频的四字符代码：
- en: '[PRE33]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The `get` method always returns a `double` value that is then casted into an
    integer. This integer represents the code from which the four characters can be
    extracted using a `union` data structure. If we open our test video sequence,
    then we have the following statements:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`get`方法始终返回一个`double`值，然后将其转换为整数。这个整数代表可以从`union`数据结构中提取四个字符的代码。如果我们打开我们的测试视频序列，那么我们将有以下语句：'
- en: '[PRE34]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'From the preceding statements, we obtain the following:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的陈述中，我们得到以下结论：
- en: '[PRE35]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'When a video file is written, the codec must be specified using its four-character
    code. This is the second parameter in the `open` method of the `cv::VideoWriter`
    class. You can use, for example, the same one as the input video (this is the
    default option in our `setOutput` method). You can also pass the value `-1` and
    the method will pop up a window that will ask you to select one codec from the
    list of available codecs, as shown here:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当写入视频文件时，必须使用其四字符代码指定编解码器。这是`cv::VideoWriter`类`open`方法的第二个参数。例如，你可以使用与输入视频相同的编解码器（这是我们在`setOutput`方法中的默认选项）。你也可以传递值`-1`，方法将弹出一个窗口，让你从可用编解码器列表中选择一个编解码器，如图所示：
- en: '![The codec four-character code](img/00188.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![编解码器四字符代码](img/00188.jpeg)'
- en: The list you will see on this window corresponds to the list of installed codecs
    on your machine. The code of the selected codec is then automatically sent to
    the `open` method.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在该窗口看到的列表对应于你机器上安装的编解码器列表。然后，所选编解码器的代码将自动发送到`open`方法。
- en: See also
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The [https://www.xvid.com/](https://www.xvid.com/) website offers you an open
    source video codec library based on the MPEG-4 standard for video compression.
    Xvid also has a competitor called DivX, which offers proprietary but free codec
    and software tools.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.xvid.com/](https://www.xvid.com/)网站提供了一个基于MPEG-4标准的开源视频编解码器库。Xvid还有一个竞争对手叫做DivX，它提供专有但免费的编解码器和软件工具。'
- en: Tracking feature points in a video
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视频中的特征点跟踪
- en: This chapter is about reading, writing, and processing video sequences. The
    objective is to be able to analyze a complete video sequence. As an example, in
    this recipe, you will learn how to perform temporal analysis of the sequence in
    order to track feature points as they move from frame to frame.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍的是读取、写入和处理视频序列。目标是能够分析完整的视频序列。例如，在本食谱中，你将学习如何执行序列的时间分析，以跟踪特征点从一帧移动到另一帧。
- en: How to do it...
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: To start the tracking process, the first thing to do is to detect the feature
    points in an initial frame. You then try to track these points in the next frame.
    Obviously, since we are dealing with a video sequence, there is a good chance
    that the object on which the feature points are found has moved (this motion can
    also be due to camera movement). Therefore, you must search around a point's previous
    location in order to find its new location in the next frame. This is what accomplishes
    the `cv::calcOpticalFlowPyrLK` function. You input two consecutive frames and
    a vector of feature points in the first image; the function returns a vector of
    new point locations. To track points over a complete sequence, you repeat this
    process from frame to frame. Note that as you follow the points across the sequence,
    you will unavoidably lose track of some of them such that the number of tracked
    feature points will gradually reduce. Therefore, it could be a good idea to detect
    new features from time to time.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始跟踪过程，首先要做的是在初始帧中检测特征点。然后，你尝试在下一帧中跟踪这些点。显然，因为我们处理的是视频序列，所以找到特征点的对象很可能已经移动了（这种运动也可能是由相机移动引起的）。因此，你必须在一个点的先前位置周围搜索，以找到它在下一帧中的新位置。这正是`cv::calcOpticalFlowPyrLK`函数所完成的。你输入两个连续帧和第一个图像中的特征点向量；该函数返回一个新点位置向量。为了在整个序列中跟踪点，你需要从一帧重复这个过程到下一帧。请注意，当你沿着序列跟踪点时，你不可避免地会失去一些点，因此跟踪的特征点数量将逐渐减少。因此，不时地检测新特征可能是个好主意。
- en: 'We will now take benefit of the framework we defined in the previous recipes
    and we will define a class that implements the `FrameProcessor` interface introduced
    in the *Processing the video frames* recipe of this chapter. The data attributes
    of this class include the variables that are required to perform both the detection
    of feature points and their tracking:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将利用之前菜谱中定义的框架，并定义一个实现本章“处理视频帧”菜谱中引入的`FrameProcessor`接口的类。这个类的数据属性包括执行特征点检测和跟踪所需的变量：
- en: '[PRE36]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Next, we define the `process` method that will be called for each frame of
    the sequence. Basically, we need to proceed as follows. First, feature points
    are detected if necessary. Next, these points are tracked. You reject points that
    you cannot track or you no longer want to track. You are now ready to handle the
    successfully tracked points. Finally, the current frame and its points become
    the previous frame and points for the next iteration. Here is how to do this:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义`process`方法，它将为序列中的每一帧调用。基本上，我们需要按以下步骤进行。首先，如果需要，检测特征点。然后，跟踪这些点。你拒绝那些无法跟踪或不再想要跟踪的点。现在，你准备好处理成功跟踪到的点。最后，当前帧及其点成为下一次迭代的上一帧和点。以下是这样做的方法：
- en: '[PRE37]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'This method makes use of four utility methods. It should be easy for you to
    change any of these methods in order to define a new behavior for your own tracker.
    The first of these methods detects the feature points. Note that we already discussed
    the `cv::goodFeatureToTrack` function in the first recipe of [Chapter 8](part0058_split_000.html#page
    "Chapter 8. Detecting Interest Points"), *Detecting Interest Points*:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法使用了四个实用方法。你应该很容易更改这些方法中的任何一个，以定义你自己的跟踪器的新行为。这些方法中的第一个是检测特征点。请注意，我们已经在[第8章](part0058_split_000.html#page
    "第8章. 检测兴趣点")的第一个菜谱中讨论了`cv::goodFeatureToTrack`函数，*检测兴趣点*：
- en: '[PRE38]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The second method determines whether new feature points should be detected:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个方法确定是否应该检测新的特征点：
- en: '[PRE39]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The third method rejects some of the tracked points based on a criteria defined
    by the application. Here, we decided to reject points that do not move (in addition
    to those that cannot be tracked by the `cv::calcOpticalFlowPyrLK` function):'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个方法根据应用程序定义的标准拒绝一些跟踪到的点。在这里，我们决定拒绝那些没有移动的点（除了那些无法通过`cv::calcOpticalFlowPyrLK`函数跟踪的点）：
- en: '[PRE40]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Finally, the fourth method handles the tracked feature points by drawing all
    of the tracked points with a line that joins them to their initial position (that
    is, the position where they were detected the first time) on the current frame:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，第四个方法通过在当前帧上用线将跟踪到的点连接到它们的初始位置（即它们第一次被检测到的位置）来处理跟踪到的特征点：
- en: '[PRE41]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'A simple main function to track feature points in a video sequence would then
    be written as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的用于跟踪视频序列中特征点的main函数可以写成如下：
- en: '[PRE42]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The resulting program will show you the evolution of the moving tracked features
    over time. Here are, for example, two such frames at two different instants. In
    this video, the camera is fixed. The young cyclist is, therefore, the only moving
    object. Here is the result that is obtained after a few frames have been processed:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的程序将显示随时间推移移动跟踪特征点的演变。例如，以下是两个不同时刻的两个这样的帧。在这个视频中，摄像机是固定的。因此，年轻的自行车手是唯一的移动对象。这里是经过几帧处理后的结果：
- en: '![How to do it...](img/00189.jpeg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/00189.jpeg)'
- en: 'A few seconds later, we obtain the following frame:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 几秒钟后，我们获得以下帧：
- en: '![How to do it...](img/00190.jpeg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/00190.jpeg)'
- en: How it works...
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何工作...
- en: 'To track feature points from frame to frame, we must locate the new position
    of a feature point in the subsequent frame. If we assume that the intensity of
    the feature point does not change from one frame to the next one, we are looking
    for a displacement *(u,v)* as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从一帧跟踪到另一帧的特征点，我们必须定位后续帧中特征点的新位置。如果我们假设特征点的强度从一个帧到下一个帧没有变化，我们正在寻找一个位移 *(u,v)*
    如下：
- en: '![How it works...](img/00191.jpeg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00191.jpeg)'
- en: 'Here, *I* [*t*] and *I* [*t+1*] are the current frame and the one at the next
    instant, respectively. This constant intensity assumption generally holds for
    small displacement in images that are taken at two nearby instants. We can then
    use the Taylor expansion in order to approximate this equation by an equation
    that involves the image derivatives:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*I* [*t*] 和 *I* [*t+1*] 分别是当前帧和下一个时刻的帧。这个恒定强度假设通常适用于在两个相邻时刻拍摄的图像中的小位移。然后我们可以使用泰勒展开来近似这个方程，通过涉及图像导数的方程来实现：
- en: '![How it works...](img/00192.jpeg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00192.jpeg)'
- en: 'This latter equation leads us to another equation (as a consequence of the
    constant intensity assumption that cancels the two intensity terms):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 后者方程引出另一个方程（这是由于恒定强度假设抵消了两个强度项的结果）：
- en: '![How it works...](img/00193.jpeg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00193.jpeg)'
- en: This well-known constraint is the fundamental **optical flow** constraint equation.
    This constraint is exploited by the so-called Lukas-Kanade feature-tracking algorithm
    that also makes an additional assumption that the displacement of all points in
    the neighborhood of the feature point is the same. We can, therefore, impose the
    optical flow constraint for all of these points with a unique *(u,v)* unknown
    displacement. This gives us more equations than the number of unknowns (2), and
    therefore, we can solve this system of equations in a mean-square sense. In practice,
    it is solved iteratively and the OpenCV implementation also offers us the possibility
    to perform this estimation at a different resolution in order to make the search
    more efficient and more tolerant to larger displacement. By default, the number
    of image levels is `3` and the window size is `15`. These parameters can obviously
    be changed. You can also specify the termination criteria, which define the conditions
    that stop the iterative search. The sixth parameter of `cv::calcOpticalFlowPyrLK`
    contains the residual mean-square error that can be used to assess the quality
    of the tracking. The fifth parameter contains binary flags that tell us whether
    tracking the corresponding point was considered successful or not.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这个众所周知的约束是基本的**光流**约束方程。这个约束被所谓的卢卡斯-卡纳达特征跟踪算法所利用，该算法还做出了一个额外的假设，即特征点周围所有点的位移是相同的。因此，我们可以对所有这些点施加光流约束，使用一个独特的
    *(u,v)* 未知位移。这给我们提供了比未知数（2）更多的方程，因此，我们可以以均方误差的方式求解这个方程组。在实践中，它是通过迭代求解的，OpenCV实现还提供了在不同分辨率下执行此估计的可能性，以提高搜索效率和对较大位移的容忍度。默认情况下，图像级别数量为
    `3`，窗口大小为 `15`。这些参数显然可以更改。您还可以指定终止条件，这些条件定义了停止迭代搜索的条件。`cv::calcOpticalFlowPyrLK`
    的第六个参数包含用于评估跟踪质量的残差均方误差。第五个参数包含二进制标志，告诉我们是否认为跟踪相应的点是成功的。
- en: The preceding description represents the basic principles behind the Lukas-Kanade
    tracker. The current implementation contains other optimizations and improvements
    that make the algorithm more efficient in the computation of the displacement
    of a large number of feature points.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 上述描述代表了卢卡斯-卡纳达跟踪器背后的基本原理。当前的实现包含其他优化和改进，使得算法在计算大量特征点位移时更加高效。
- en: See also
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '[Chapter 8](part0058_split_000.html#page "Chapter 8. Detecting Interest Points"),
    *Detecting Interest Points*, has a discussion on feature point detection.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第8章](part0058_split_000.html#page "第8章. 检测兴趣点"), 《检测兴趣点》一节对特征点检测进行了讨论。'
- en: The classic article by B. Lucas and T. Kanade, *An Iterative Image Registration
    Technique with an Application to Stereo Vision* in *Int. Joint Conference in Artificial
    Intelligence, pp. 674-679, 1981*, describes the original feature point tracking
    algorithm.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B. Lucas和T. Kanade的经典文章《一种迭代图像配准技术及其在立体视觉中的应用》发表于1981年的《国际人工智能联合会议》，介绍了原始的特征点跟踪算法。
- en: The article by J. Shi and C. Tomasi, *Good Features to Track in IEEE Conference
    on Computer Vision and Pattern Recognition*, pp. 593-600, 1994, describes an improved
    version of the original feature point tracking algorithm.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: J. Shi和C. Tomasi的文章《在IEEE计算机视觉和模式识别会议上的良好跟踪特征》发表于1994年，描述了原始特征点跟踪算法的改进版本。
- en: Extracting the foreground objects in a video
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从视频中提取前景物体
- en: When a fixed camera observes a scene, the background remains mostly unchanged.
    In this case, the interesting elements are the moving objects that evolve inside
    this scene. In order to extract these foreground objects, we need to build a model
    of the background, and then compare this model with a current frame in order to
    detect any foreground objects. This is what we will do in this recipe. Foreground
    extraction is a fundamental step in intelligent surveillance applications.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个固定相机观察一个场景时，背景保持基本不变。在这种情况下，有趣的因素是场景内部移动的物体。为了提取这些前景物体，我们需要建立一个背景模型，然后将其与当前帧进行比较，以检测任何前景物体。这正是本食谱要做的。前景提取是智能监控应用中的基本步骤。
- en: 'If we had an image of the background of the scene (that is, a frame that contains
    no foreground objects) at our disposal, then it would be easy to extract the foreground
    of a current frame through a simple image difference:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们手头有一幅场景背景的图像（即，一个不包含前景物体的框架），那么通过简单的图像差异就可以轻松地提取当前帧的前景：
- en: '[PRE43]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Each pixel for which this difference is high enough would then be declared as
    a foreground pixel. However, most of the time, this background image is not readily
    available. Indeed, it could be difficult to guarantee that no foreground objects
    are present in a given image, and in busy scenes, such situations might rarely
    occur. Moreover, the background scene often evolves over time because, for instance,
    the lighting condition changes (for example, from sunrise to sunset) or because
    new objects can be added or removed from the background.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于差异足够高的每个像素，将其宣布为前景像素。然而，大多数情况下，这种背景图像并不容易获得。实际上，很难保证给定图像中没有前景物体，在繁忙的场景中，这种情况可能很少发生。此外，背景场景通常会随着时间的推移而变化，例如，由于光照条件的变化（例如，从日出到日落）或因为新的物体可以添加到背景或从背景中移除。
- en: Therefore, it is necessary to dynamically build a model of the background scene.
    This can be done by observing the scene for a period of time. If we assume that
    most often, the background is visible at each pixel location, then it could be
    a good strategy to simply compute the average of all of the observations. However,
    this is not feasible for a number of reasons. First, this would require a large
    number of images to be stored before computing the background. Second, while we
    are accumulating images to compute our average image, no foreground extraction
    will be done. This solution also raises the problem of when and how many images
    should be accumulated to compute an acceptable background model. In addition,
    the images where a given pixel is observing a foreground object would have an
    impact on the computation of the average background.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有必要动态地建立一个背景场景的模型。这可以通过观察场景一段时间来实现。如果我们假设大多数情况下，背景在每个像素位置都是可见的，那么简单地计算所有观察的平均值可能是一个好的策略。然而，由于多种原因，这并不可行。首先，这需要在计算背景之前存储大量的图像。其次，当我们积累图像来计算平均图像时，不会进行前景提取。这种解决方案还提出了何时以及需要积累多少图像来计算可接受的背景模型的问题。此外，观察到一个像素正在观察前景物体的图像将对平均背景的计算产生影响。
- en: 'A better strategy is to dynamically build the background model by regularly
    updating it. This can be accomplished by computing what is called a **running
    average** (also called **moving average**). This is a way to compute the average
    value of a temporal signal that takes into account the latest received values.
    If pt is the pixel value at a given time *t* and *μ* [*t-1*] is the current average
    value, then this average is updated using the following formula:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的策略是动态地通过定期更新来构建背景模型。这可以通过计算所谓的 **运行平均数**（也称为 **移动平均数**）来实现。这是一种计算时间信号平均值的方法，它考虑了最新接收到的值。如果
    pt 是给定时间 *t* 的像素值，而 *μ* [*t-1*] 是当前的平均值，那么这个平均值将使用以下公式进行更新：
- en: '![Extracting the foreground objects in a video](img/00194.jpeg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![从视频中提取前景对象](img/00194.jpeg)'
- en: The *α* parameter is called the **learning rate**, and it defines the influence
    of the current value over the currently estimated average. The larger this value
    is, the faster the running average will adapt to changes in the observed values.
    To build a background model, one just has to compute a running average for every
    pixel of the incoming frames. The decision to declare a foreground pixel is then
    simply based on the difference between the current image and the background model.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*α* 参数被称为 **学习率**，它定义了当前值对当前估计平均值的影响。这个值越大，运行平均数就越快适应观察值的变化。为了构建背景模型，只需要对输入帧的每个像素计算运行平均数。然后，声明前景像素的决定仅基于当前图像与背景模型之间的差异。'
- en: How to do it...
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s build a class that will learn about a background model using moving
    averages and that will extract foreground objects by subtraction. The required
    attributes are the following:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建一个类，它将使用移动平均数来学习背景模型，并通过减法提取前景对象。所需的属性如下：
- en: '[PRE44]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The main process consists of comparing the current frame with the background
    model and then updating this model:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 主要过程包括将当前帧与背景模型进行比较，然后更新此模型：
- en: '[PRE45]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Using our video-processing framework, the foreground extraction program will
    be built as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的视频处理框架，前景提取程序将按以下方式构建：
- en: '[PRE46]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'One of the resulting binary foreground images that will be displayed is as
    follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 将显示的一个结果二值前景图像如下：
- en: '![How to do it...](img/00195.jpeg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00195.jpeg)'
- en: How it works...
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Computing the running average of an image is easily accomplished through the
    `cv::accumulateWeighted` function that applies the running average formula to
    each pixel of the image. Note that the resulting image must be a floating point
    image. This is why we had to convert the background model into a background image
    before comparing it with the current frame. A simple thresholded absolute difference
    (computed by `cv::absdiff` followed by `cv::threshold`) extracts the foreground
    image. Note that we then used the foreground image as a mask to cv`::accumulateWeighte`d
    in order to avoid the updating of pixels declared as foreground. This works because
    our foreground image is defined as being false (that is, `0`) at foreground pixels
    (which also explains why the foreground objects are displayed as black pixels
    in the resulting image).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 `cv::accumulateWeighted` 函数计算图像的运行平均数是很容易实现的，该函数将运行平均数公式应用于图像的每个像素。请注意，结果图像必须是一个浮点图像。这就是为什么我们不得不在将背景模型与当前帧比较之前将其转换为背景图像。一个简单的阈值绝对差（通过
    `cv::absdiff` 后跟 `cv::threshold` 计算）提取前景图像。请注意，我们随后使用前景图像作为掩码来应用 `cv::accumulateWeighted`，以避免更新被声明为前景的像素。这是因为我们的前景图像在前景像素上被定义为假（即，`0`），这也解释了为什么前景对象在结果图像中显示为黑色像素。
- en: Finally, it should be noted that, for simplicity, the background model that
    is built by our program is based on the gray-level version of the extracted frames.
    Maintaining a color background would require the computation of a running average
    in some color space. However, the main difficulty in the presented approach is
    to determine the appropriate value for the threshold that would give good results
    for a given video.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，应该注意的是，为了简化，我们程序构建的背景模型基于提取帧的灰度版本。保持彩色背景将需要计算某种颜色空间中的运行平均数。然而，在所提出的方法中，主要困难是确定适当的阈值，以便为给定的视频提供良好的结果。
- en: There's more...
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The preceding simple method to extract foreground objects in a scene works well
    for simple scenes that show a relatively stable background. However, in many situations,
    the background scene might fluctuate in certain areas between different values,
    thus causing frequent false foreground detections. These might be due to, for
    example, a moving background object (for example, tree leaves) or a glaring effect
    (for example, on the surface of water). Casted shadows also pose a problem since
    they are often detected as part of a moving object. In order to cope with these
    problems, more sophisticated background modeling methods have been introduced.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 之前提取场景中前景对象的方法对于显示相对稳定背景的简单场景效果很好。然而，在许多情况下，背景场景可能在某些区域之间波动，从而造成频繁的错误前景检测。这些可能是由例如移动的背景对象（例如树叶）或刺眼的效果（例如水面上）引起的。投射的阴影也造成问题，因为它们通常被检测为移动对象的一部分。为了应对这些问题，已经引入了更复杂的背景建模方法。
- en: The Mixture of Gaussian method
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高斯混合方法
- en: One of these algorithms is the **Mixture of Gaussian** method. It proceeds in
    a way that is similar to the method presented in this recipe but adds a number
    of improvements.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法之一是**高斯混合**方法。它的过程与本文献中介绍的方法类似，但增加了一些改进。
- en: First, the method maintains more than one model per pixel (that is, more than
    one running average). This way, if a background pixel fluctuates between, let's
    say, two values, two running averages are then stored. A new pixel value will
    be declared as the foreground only if it does not belong to any of the most frequently
    observed models. The number of models used is a parameter of the method and a
    typical value is `5`.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，该方法为每个像素维护多个模型（即多个运行平均值）。这样，如果一个背景像素在两个值之间波动，例如，就会存储两个运行平均值。只有当新的像素值不属于观察到的最频繁的任何模型时，才会将其宣布为前景。所使用的模型数量是该方法的参数，一个典型值是`5`。
- en: 'Second, not only is the running average maintained for each model, but also
    for the running variance. This is computed as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，不仅为每个模型维护运行平均值，还维护运行方差。计算方法如下：
- en: '![The Mixture of Gaussian method](img/00196.jpeg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![高斯混合方法](img/00196.jpeg)'
- en: These computed averages and variances are used to build a Gaussian model from
    which the probability of a given pixel value to belong to the background can be
    estimated. This makes it easier to determine an appropriate threshold since it
    is now expressed as a probability rather than an absolute difference. Consequently,
    in areas where the background values have larger fluctuations, a greater difference
    will be required to declare a foreground object.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这些计算出的平均值和方差被用来构建高斯模型，从这个模型中可以估计给定像素值属于背景的概率。这使得确定合适的阈值变得更加容易，因为它现在是以概率的形式表达，而不是绝对差值。因此，在背景值波动较大的区域，需要更大的差异才能宣布存在前景对象。
- en: Finally, when a given Gaussian model is not hit sufficiently often, it is excluded
    as being part of the background model. Reciprocally, when a pixel value is found
    to be outside the currently maintained background models (that is, it is a foreground
    pixel), a new Gaussian model is created. If in the future this new model becomes
    a hit, then it becomes associated with the background.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当给定的高斯模型不足以被击中时，它被排除在背景模型之外。相反，当发现像素值位于当前维护的背景模型之外（即它是前景像素）时，会创建一个新的高斯模型。如果将来这个新模型被击中，那么它就与背景相关联。
- en: 'This more sophisticated algorithm is obviously more complex to implement than
    our simple background/foreground segmentor. Fortunately, an OpenCV implementation
    exists, called `cv::BackgroundSubtractorMOG`, and is defined as a subclass of
    the more general `cv::BackgroundSubtractor` class. When used with its default
    parameter, this class is very easy to use:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这个更复杂的算法显然比我们简单的背景/前景分割器更难实现。幸运的是，存在一个名为`cv::BackgroundSubtractorMOG`的OpenCV实现，它被定义为更通用`cv::BackgroundSubtractor`类的子类。当使用其默认参数时，这个类非常容易使用：
- en: '[PRE47]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: As it can be seen, it is just a matter of creating the class instance and calling
    the method that simultaneously updates the background and returns the foreground
    image (the extra parameter being the learning rate). Also note that the background
    model is computed in color here. The method implemented in OpenCV also includes
    a mechanism to reject shadows by checking whether the observed pixel variation
    is simply caused by a local change in brightness (if so, then it is probably due
    to a shadow) or whether it also includes some change in chromaticity.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这仅仅是创建类实例并调用同时更新背景并返回前景图像（额外参数为学习率）的方法的问题。此外，请注意，这里的背景模型是按颜色计算的。OpenCV中实现的方法还包括一个机制，通过检查观察到的像素变化是否仅仅是由于亮度（如果是，那么可能是由于阴影）的局部变化来拒绝阴影。
- en: A second implementation is also available and is simply called `cv::BackgroundSubtractorMOG2`.
    One of the improvements is that the number of appropriate Gaussian models per
    pixel to be used is now determined dynamically. You can use this in place of the
    previous one in the preceding example. You should run these different methods
    on a number of videos in order to appreciate their respective performances. In
    general, you will observe that `cv::BackgroundSubtractorMOG2` is much faster.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个实现版本也可用，简单称为`cv::BackgroundSubtractorMOG2`。其中一个改进是现在动态确定每个像素点使用的适当高斯模型数量。您可以用它替换前面示例中的上一个版本。您应该在多个视频上运行这些不同的方法，以便欣赏它们各自的性能。一般来说，您会观察到`cv::BackgroundSubtractorMOG2`要快得多。
- en: See also
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The article by C. Stauffer and W.E.L. Grimson, *Adaptive Background Mixture
    Models for Real-Time Tracking*, in *Conf. on Computer Vision and Pattern Recognition,
    1999*, gives you a more complete description of the Mixture of Gaussian algorithm.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C. Stauffer和W.E.L. Grimson撰写的文章《Adaptive Background Mixture Models for Real-Time
    Tracking》，发表于1999年的*Conf. on Computer Vision and Pattern Recognition*，为您提供了对高斯混合算法的更完整描述。
