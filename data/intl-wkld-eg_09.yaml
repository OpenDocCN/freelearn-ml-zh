- en: '*Chapter 7*: Machine Learning Workloads at the Edge'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第七章*: 边缘的机器学习工作负载'
- en: The growth of edge computing is not only driven by advancements in computationally
    efficient hardware devices but also by the advent of different software technologies
    that were only available on the cloud (or on-premises infrastructure) a decade
    back. For example, think of smartphones, smartwatches, or personal assistants
    such as **Amazon Alexa** that bring a mix of powerful hardware and software capabilities
    to consumers. Capabilities such as unlocking your phone or garage doors using
    facial recognition, having a conversation with Alexa using natural language, or
    riding an autonomous car have become the new normal. Thus, a need for cyber-physical
    systems to build intelligence throughout their lifetime based on continuous learning
    from their surroundings has become key for various workloads in today's world.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算的增长不仅是由计算效率高的硬件设备的进步推动的，也是由十年前仅在云（或本地基础设施）上可用的不同软件技术的出现推动的。例如，想想智能手机、智能手表或个人助理，如**亚马逊Alexa**，它们将强大的硬件和软件能力带给消费者。使用面部识别解锁手机或车库门、与Alexa使用自然语言进行对话或驾驶自动驾驶汽车已经成为新常态。因此，基于从周围环境持续学习而构建智能的物理-数字系统对于当今世界各种工作负载来说已经成为关键。
- en: It's important to realize that most of the top technology companies (such as
    *Apple*, *Amazon*, *Google*, and *Meta*, formerly *Facebook*) use **machine learning**
    (**ML**) and have made it more accessible to consumers through their products.
    It's not a new technology, either, and has been used by industry sectors such
    as financial, healthcare, and industrial settings for a long time. In this chapter,
    we will focus on how ML capabilities can be leveraged for any **internet of things**
    (**IoT**) workload.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要认识到，大多数顶级科技公司（如*苹果*、*亚马逊*、*谷歌*和*Meta*，前称*Facebook*）都使用**机器学习**（**ML**）并通过他们的产品使消费者更容易接触到它。这也不是一项新技术，它已经被金融、医疗和工业等领域的行业使用很长时间了。在本章中，我们将关注如何利用机器学习能力为任何**物联网**（**IoT**）工作负载提供支持。
- en: We will continue to work on the connected hub solution and learn how to develop
    ML capabilities on the **edge** (aka a **Greengrass** device). In the previous
    chapters, you have already learned about processing different types of data on
    the edge, and now, it's time to learn how different ML models can perform inference
    on this data to derive intelligent insights on the edge.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续致力于连接的枢纽解决方案，并学习如何在**边缘**（即**Greengrass**设备）上开发机器学习能力。在前几章中，你已经学习了如何在边缘处理不同类型的数据，现在，是时候学习不同的机器学习模型如何对数据进行推理，以在边缘得出智能见解。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Defining ML for IoT workloads
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义适用于物联网工作负载的机器学习
- en: Designing an ML workflow in the cloud
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在云中设计机器学习工作流程
- en: Hands-on with ML workflow architecture
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实践机器学习工作流程架构
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The technical requirements for this chapter are the same as those outlined in
    [*Chapter 2*](B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032), *Foundations of
    Edge Workloads*. See the full requirements in that chapter.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的技术要求与在[*第七章*](B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032)“边缘工作负载基础”中概述的要求相同。详见该章节中的完整要求。
- en: Defining ML for IoT workloads
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义适用于物联网工作负载的机器学习
- en: ML technologies are no longer technologies of the future— they have transformed
    the lives of millions of people in the last few decades. So, what is ML?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习技术不再是未来的技术——在过去的几十年里，它已经改变了数百万人的生活方式。那么，什么是机器学习？
- en: '"Machine Learning is the field of study that gives computers the ability to
    learn without being explicitly programmed."'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: “机器学习是研究计算机在没有明确编程的情况下学习能力的领域。”
- en: – Arthur Samuel, 1959
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: – 亚瑟·塞缪尔，1959年
- en: Let's look at some real-world examples of ML applications for IoT workloads
    from the **consumer** and **industrial** segments.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些来自**消费者**和**工业**领域的真实世界机器学习应用物联网工作负载的例子。
- en: 'First, here are some examples from the consumer segment:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，这里有一些来自消费者领域的例子：
- en: Smartphones or smartwatches that can identify your daily habits and provide
    recommendations related to fitness or productivity
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够识别你的日常习惯并提供与健身或生产力相关的建议的智能手机或智能手表
- en: Personal assistants (such as Alexa, Google, and Siri) that you can interact
    with in a natural way for different needs such as controlling your lights and
    **heating, ventilation, and air conditioning** (**HVAC**)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以以自然方式与之互动的个人助理（如Alexa、Google和Siri），用于控制灯光和**供暖、通风和空调**（**HVAC**）等不同需求
- en: Smart cameras that can monitor your surroundings and detect unexpected behaviors
    or threats
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以监控您的周围环境并检测意外行为或威胁的智能摄像头
- en: Smart garages that can recognize your car through its visual attributes, license
    plates, or even drivers' faces
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以通过其视觉属性、车牌或甚至驾驶员的面部识别您的汽车的智能车库
- en: Self-driving cars that can continuously become smarter in identifying driving
    patterns, objects, and pedestrians in traffic
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够持续变得更聪明，以识别交通中的驾驶模式、物体和行人的自动驾驶汽车
- en: 'Here are some examples from the industrial segment:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些来自工业领域的例子：
- en: Smart factories that enable better optimization of **overall equipment effectiveness**
    (**OEE**)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够更好地优化**总体设备效率**（**OEE**）的智能工厂
- en: Better worker safety and productivity in different industrial plants, warehouses,
    or working sites
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同的工业工厂、仓库或工作场所提高工人的安全和生产力
- en: Real-time **quality control** (**QC**) using **computer vision** (**CV**) or
    audio to identify defects
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**计算机视觉**（**CV**）或音频进行实时**质量控制**（**QC**）以识别缺陷
- en: Improving supply chain to reduce waste and enhance customer experience such
    as 1 hour or 15 mins delivery (with drones) from Amazon.com
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改善供应链以减少浪费并提高客户体验，例如从Amazon.com进行1小时或15分钟的送货（使用无人机）
- en: To build the aforementioned capabilities, customers have used different ML frameworks
    and algorithms. For the sake of brevity, we are not going to cover every ML framework
    that exists today. We believe it's an area of data science that doesn't fit into
    the daily responsibilities of an IoT practitioner. But if you are interested in
    diving deeper, there are many books on ML/**artificial intelligence** (**AI**)
    available. Thus, our focus in this chapter will be to learn a bit about the history
    and core concepts of ML systems, and the approach to integrating ML with IoT and
    edge workloads.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建上述能力，客户使用了不同的机器学习框架和算法。为了简洁起见，我们不会涵盖今天存在的每一个机器学习框架。我们认为这是数据科学的一个领域，它不适合物联网实践者的日常职责。但如果你有兴趣深入了解，有许多关于机器学习/人工智能（**AI**）的书籍。因此，本章的重点将是学习一些关于机器学习系统历史和核心概念的知识，以及将机器学习与物联网和边缘工作负载集成的途径。
- en: What is the history of ML?
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习的历史是什么？
- en: 'Today, as humans, we can communicate with machines of different kinds (from
    mobiles to self-driving cars) using voice, vision, or touch. This would not have
    been possible without the adoption of ML technologies. This is just the beginning,
    and ML will be more accessible in the years to come to transform our lives in
    different ways. You can take a quick tour through the history of this amazing
    technology in this article published by *Forbes*: [https://www.forbes.com/sites/bernardmarr/2016/02/19/a-short-history-of-machine-learning-every-manager-should-read/?sh=1ca6cea115e7](https://www.forbes.com/sites/bernardmarr/2016/02/19/a-short-history-of-machine-learning-every-manager-should-read/?sh=1ca6cea115e7).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，作为人类，我们可以通过声音、视觉或触觉与各种机器（从手机到自动驾驶汽车）进行交流。没有机器学习技术的采用，这是不可能的。这只是开始，未来几年机器学习将变得更加易于访问，以不同的方式改变我们的生活。您可以通过这篇由《福布斯》杂志发表的文章快速了解这项令人惊叹的技术的历史：[https://www.forbes.com/sites/bernardmarr/2016/02/19/a-short-history-of-machine-learning-every-manager-should-read/?sh=1ca6cea115e7](https://www.forbes.com/sites/bernardmarr/2016/02/19/a-short-history-of-machine-learning-every-manager-should-read/?sh=1ca6cea115e7)。
- en: Beyond the research community, technology companies such as Amazon.com, Google,
    and others also started adopting ML technologies in the late 1990s. For example,
    Amazon.com used ML algorithms to learn about the reading preferences of their
    customers and built a model to notify them of new book releases matching their
    interests or genres. Google used ML for their search engine, Microsoft used it
    for identifying spam in emails, and so on. Since then, this technology has been
    adopted by many other industries for a plethora of use cases.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究界之外，像Amazon.com、Google和其他技术公司也在20世纪90年代末开始采用机器学习技术。例如，Amazon.com使用机器学习算法来了解其客户的阅读偏好，并建立了一个模型来通知他们发布的新书，这些新书符合他们的兴趣或类型。Google将其用于搜索引擎，Microsoft用于识别电子邮件中的垃圾邮件，等等。从那时起，这项技术已被许多其他行业用于各种用例。
- en: Now that we have learned a bit about the background of ML, let's now try to
    understand the foundation of ML.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对机器学习的背景有所了解，让我们现在尝试理解机器学习的基础。
- en: What are the different types of ML systems?
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习系统有哪些不同类型？
- en: 'Similar to distributed data systems, where there are different kinds of technologies
    to process different types of data, ML systems also come in different flavors.
    If we classify them into broader categories, the distinction can be described
    in this way:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 与分布式数据系统类似，其中存在不同类型的技术来处理不同类型的数据，机器学习系统也有不同的种类。如果我们将它们分类到更广泛的类别中，区别可以这样描述：
- en: '**Supervised ML (SML)**—In this method of ML, the model is trained with a labeled
    dataset and requires human supervision (or a teacher). For example, let''s consider
    a scenario where we need a connected hub solution to identify different objects
    such as cats, dogs, humans (or seasonal birds?) who might have intruded onto your
    premises. Thus, the images are required to be labeled by a human (or humans),
    and the models will be trained on that data using a classification algorithm before
    they are ready (that is, the models) to predict the outcomes. In the following
    screenshot, you can see some objects are already labeled while the rest are not.
    So, humans are required to do their due diligence with labeling for the model
    to be effective:'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督式机器学习（SML）**—在这种机器学习方法中，模型使用标记的数据集进行训练，并需要人类监督（或教师）。例如，让我们考虑一个场景，我们需要一个连接的枢纽解决方案来识别可能入侵您场所的不同对象，如猫、狗、人类（或季节性鸟类？）。因此，需要由人类（或人类）对图像进行标记，然后在模型准备好（即，模型）预测结果之前，使用分类算法在该数据上对模型进行训练。在下面的屏幕截图中，您可以看到一些对象已经标记，而其余的尚未标记。因此，人类需要做好标记工作，以便模型有效：'
- en: '![Figure 7.1 – A labeled training set of image classification'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.1 – 一个标记的图像分类训练集'
- en: '](img/B17595_07_01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_07_01.jpg)'
- en: Figure 7.1 – A labeled training set of image classification
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1 – 一个标记的图像分类训练集
- en: The length of the training and the volume and quality of the data will determine
    the accuracy of the model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的长度以及数据量和质量将决定模型的准确性。
- en: '**Unsupervised ML (UML)**—In this method of ML, the model is trained with an
    unlabeled dataset and requires no human supervision (or self-teaching). For example,
    let''s consider that you have a new intruder on your premises, such as a deer,
    a wolf (or a tiger?), and you expect the model to detect that as an anomaly and
    notify you. In the following screenshot, you can see that none of the images is
    labeled and the model is required to figure out the anomaly on its own:'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督式机器学习（UML）**—在这种机器学习方法中，模型使用未标记的数据集进行训练，并且不需要人类监督（或自我教学）。例如，让我们考虑你场所上的一个新入侵者，如鹿、狼（或老虎？），你希望模型将其检测为异常并通知你。在下面的屏幕截图中，您可以看到没有任何图像被标记，模型需要自己找出异常：'
- en: '![Figure 7.2 – An unlabeled training set of image classification'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.2 – 一个未标记的图像分类训练集'
- en: '](img/B17595_07_02.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_07_02.jpg)'
- en: Figure 7.2 – An unlabeled training set of image classification
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 – 一个未标记的图像分类训练集
- en: Considering the training dataset did not have pictures of a deer, a wolf, or
    a tiger, the model needs to be smart enough to identify that as an **anomaly**
    (or a novelty detection) using algorithms such as **random forest**.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到训练数据集中没有鹿、狼或老虎的图片，模型需要足够智能，能够使用如**随机森林**等算法将其识别为**异常**（或新颖性检测）。
- en: '**Semi-supervised ML (SSML)**—In this method of ML, the model is trained with
    a dataset that is a mix of unlabeled and labeled data (think of on-demand teaching
    where you need to learn most of the content on your own). So, let''s consider
    a scenario where you collected pictures of your guests from a party thrown at
    your home. Different guests show up in different photos and most of them are not
    labeled, which is the unsupervised part of the algorithm (such as **clustering**).
    Now, as the host of the party, if you label the unique individuals once in the
    dataset, the ML model can immediately recognize those individuals in other pictures
    on its own, as shown in the following diagram:'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**半监督式机器学习（SSML）**—在这种机器学习方法中，模型使用的是混合了未标记和标记数据的集合（想想按需教学，你需要自己学习大部分内容）。让我们考虑一个场景，你收集了在家举办的派对上的客人照片。不同的客人在不同的照片中出现，其中大多数未标记，这是算法的无监督部分（如**聚类**）。现在，作为派对的主持人，如果你在数据集中一次性标记了独特的人物，机器学习模型可以立即在其它照片中识别出这些人物，如下面的图所示：'
- en: '![Figure 7.3 – SSML'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.3 – SSML'
- en: '](img/B17595_07_03.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_07_03.jpg)'
- en: Figure 7.3 – SSML
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 – SSML
- en: This might be very useful if you want to search photos of individuals or families
    and share these with them (who cares about photos of other families, huh?).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能非常有用，如果你想要搜索个人或家庭的照片并与他们分享（谁在乎其他家庭的照片呢？）
- en: '**Reinforcement learning (RL)**—In this method of ML, the model is trained
    to make a sequence of decisions in an environment and maximize a long-term objective.
    The model learns through an iterative process of trial and error. An agent such
    as a physical or virtual device uses this model to take actions guided by a policy
    at a given environment state and reaches a new state. This makes the agent eligible
    for a reward (positive or negative), and the agent continues to iterate on this
    process until it leads to the most optimal long-term rewards. The entire life
    cycle of an agent progressing from an initial state to a final state is called
    an **episode**.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习（RL）**—在这种机器学习方法中，模型被训练在环境中做出一系列决策并最大化长期目标。模型通过试错法的迭代过程进行学习。一个物理或虚拟设备等代理使用此模型在给定环境状态下采取行动，达到新的状态。这使得代理有资格获得奖励（正面或负面），代理将继续迭代这个过程，直到它导致最优化长期奖励。代理从初始状态到最终状态的全部生命周期被称为一个**剧集**。'
- en: 'For example, using RL, you can train a robot to take pictures of all guests
    from a party thrown at your home. The robot will stay on a specific track and
    capture images from that environment. It will receive a positive reward if it
    stays on track and captures acceptable images and a negative reward for going
    off track or capturing distorted snaps. As it continues to iterate through this
    process, eventually it will learn how to maximize its long-term objectives of
    capturing glorious images. The following diagram reflects this process of RL:'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，使用RL，你可以训练一个机器人拍摄你家中举办的派对上所有宾客的照片。机器人将保持在特定的轨道上，并从该环境中捕捉图像。如果它保持在轨道上并捕捉到可接受的图像，它将获得正面奖励；如果它偏离轨道或捕捉到扭曲的快照，它将获得负面奖励。随着它继续迭代这个过程，最终它将学会如何最大化其长期目标，即捕捉到辉煌的图像。以下图表反映了这个RL过程：
- en: '![Figure 7.4 – RL'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.4 – RL'
- en: '](img/B17595_07_04.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_07_04.jpg)'
- en: Figure 7.4 – RL
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 – RL
- en: We have explained a broader category of ML in the preceding diagram; however,
    there is a plethora of frameworks and algorithms that are beyond the scope of
    this book. So, in the next section, we will focus on the most common ones that
    can apply to data generated from IoT and edge workloads.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面图表中解释了机器学习的一个更广泛的类别；然而，有许多框架和算法超出了本书的范围。因此，在下一节中，我们将重点关注最常见的一些，这些可以应用于物联网和边缘工作负载生成数据。
- en: Taxonomy of ML with IoT workloads
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 物联网工作负载的机器学习分类法
- en: 'The three most common uses of ML in IoT are in the fields of classification,
    regression, and clustering, as depicted in the following diagram:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习在物联网中最常见的三个应用领域是分类、回归和聚类，如下所示：
- en: '![Figure 7.5 – Summarized taxonomy of ML algorithms'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.5 – 机器学习算法的总结分类法'
- en: '](img/B17595_07_05.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_07_05.jpg)'
- en: Figure 7.5 – Summarized taxonomy of ML algorithms
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 – 机器学习算法的总结分类法
- en: 'Let''s discuss the nomenclature in the preceding diagram in more detail, as
    follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地讨论前面图表中的命名法，如下所示：
- en: '**Classification**—Classification is an SML technique where you start with
    a set of observed values and derive some conclusion about unknown data. In the
    real world, classification can be used in image classification, speech recognition,
    drugs classification, sentiment analysis, biometric identification, and more.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**—分类是一种监督学习技术，你从一组观察到的值开始，并从未知数据中得出一些结论。在现实世界中，分类可以用于图像分类、语音识别、药物分类、情感分析、生物识别识别等。'
- en: '**Regression**—Regression is an SML technique where you can predict a continuous
    value. The prediction happens by estimating the relationship between the dependent
    variable (*Y*) and one or more independent variables (*X*) using a best-fit straight
    line. In the real world, regression can be applied to forecasting the temperature
    tomorrow, the price of energy utilization, the price of gold, and so on.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**—回归是一种监督学习技术，你可以预测一个连续值。预测是通过估计因变量（*Y*）与一个或多个自变量（*X*）之间的关系，使用最佳拟合直线来实现的。在现实世界中，回归可以应用于预测明天的温度、能源利用价格、金价等。'
- en: '**Clustering**—Clustering is a UML algorithm where you can group unlabeled
    data points. This is used very often for statistical analysis. The grouping of
    unlabeled data points in a dataset is performed by identifying data points in
    a dataset that share common properties and features. In the real world, this algorithm
    can be applied to market segmentation, medical imaging, anomaly detection, and
    social network analysis.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**——聚类是一种UML算法，你可以将未标记的数据点分组。这通常用于统计分析。数据集中未标记数据点的分组是通过识别具有共同属性和特征的数据点来实现的。在现实世界中，这个算法可以应用于市场细分、医学成像、异常检测和社会网络分析。'
- en: In the hands-on lab section of this chapter, you will learn how to use a classification
    algorithm to classify objects (such as cars and pets).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的动手实验室部分，你将学习如何使用分类算法来分类对象（例如汽车和宠物）。
- en: Why is ML accessible at the edge today?
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么机器学习今天可以在边缘访问？
- en: We have already introduced you to three laws of edge computing in [*Chapter
    6*](B17595_06_Final_SS_ePub.xhtml#_idTextAnchor119), *Processing and Consuming
    Data on the Cloud:* *Law of Physics* (latency-sensitive use cases), *Law of Economics*
    (cost-sensitive use cases), and *Law of the Land* (data-sensitive use cases).
    Based on these laws, we can identify various use cases in today's world, especially
    related to IoT and the edge, where it makes a lot of sense to process and generate
    insights from the data locally on the device or the gateway itself rather than
    publishing them continuously to the cloud.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[*第6章*](B17595_06_Final_SS_ePub.xhtml#_idTextAnchor119)中向您介绍了边缘计算的三个定律：*物理定律*（对延迟敏感的使用案例）、*经济定律*（对成本敏感的使用案例）和*土地定律*（对数据敏感的使用案例）。基于这些定律，我们可以识别当今世界中的各种使用案例，特别是与物联网和边缘相关的情况，在这些情况下，在设备或网关本地处理和生成数据洞察是非常有意义的，而不是持续将其发布到云端。
- en: However, the constraint is the limited resources (such as **central processing
    unit** (**CPU**), **graphics processing unit** (**GPU**), memory, network, and
    energy) available on these edge devices or gateways. Thus, it is recommended to
    take advantage of the computing power of the cloud to build and train ML models
    using the preferred framework (such as **MXNET**, **TensorFlow**, **PyTorch**,
    **Caffe**, or **Gluon**) and then deploy the model to the edge for inferencing.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，限制是这些边缘设备或网关上可用的有限资源（例如**中央处理器**（**CPU**）、**图形处理器**（**GPU**）、内存、网络和能源）。因此，建议利用云的计算能力，使用首选框架（例如**MXNET**、**TensorFlow**、**PyTorch**、**Caffe**或**Gluon**）构建和训练机器学习模型，然后将模型部署到边缘进行推理。
- en: For example, if there is a lot of noisy data generated in a smart home from
    a baby crying, a dog barking, or construction noises from the surroundings, the
    ML model can identify that as noisy data, trigger any specified action locally—such
    as an alert to check on the baby or the pet—but avoid publishing those data points
    to the cloud. In that way, a large amount of intermittent data that's of less
    long-term value can be filtered out at the site itself.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果在一个智能家居中产生了大量由婴儿啼哭、狗吠或周围建筑噪音产生的嘈杂数据，机器学习模型可以将其识别为嘈杂数据，在本地触发任何指定的操作——例如提醒检查婴儿或宠物——但避免将这些数据点发布到云端。这样，大量间歇性数据可以在现场本身被过滤掉，这些数据对长期价值较小。
- en: ML at the edge is an evolving space and there are many emerging frameworks and
    hardware offerings available today from different vendors, a few of which are
    listed in the following tables.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘机器学习是一个不断发展的领域，今天有来自不同供应商的许多新兴框架和硬件产品可供选择，其中一些列在下面的表格中。
- en: 'Here are common ML frameworks for the edge:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出了边缘常见的机器学习框架：
- en: '![Figure 7.6 – Common ML frameworks for the edge'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.6 – 在边缘常见的机器学习框架'
- en: '](img/B17595_07_Table1.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_07_Table1.jpg](img/B17595_07_Table1.jpg)'
- en: Figure 7.6 – Common ML frameworks for the edge
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 – 在边缘常见的机器学习框架
- en: 'Here are common hardware stacks for performing ML at the edge:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出了在边缘执行机器学习常见的硬件堆栈：
- en: '![Figure 7.7 – Common hardware stacks for performing ML at the edge'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.7 – 在边缘执行机器学习常见的硬件堆栈'
- en: '](img/B17595_07_Table2.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_07_Table2.jpg](img/B17595_07_Table2.jpg)'
- en: Figure 7.7 – Common hardware stacks for performing ML at the edge
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 – 在边缘执行机器学习常见的硬件堆栈
- en: You are already using Raspberry Pi as the underlying hardware for the different
    labs in this book. In the *Hands-on with ML architecture* section, you will learn
    how to train Apache MXNET-based ML models in the cloud and deploy them at the
    edge for inferencing. With this background, let's discuss how to get started with
    building ML applications for the edge.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经在本书的不同实验室中使用了树莓派作为底层硬件。在*动手实践机器学习架构*部分，您将学习如何在云中训练基于Apache MXNET的机器学习模型，并在边缘进行推理部署。有了这个背景，让我们讨论如何开始构建边缘机器学习应用。
- en: Designing an ML workflow in the cloud
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在云中设计机器学习工作流程
- en: 'ML is an **end-to-end** (**E2E**) iterative process consisting of multiple
    phases. As we explain the different phases throughout the rest of the book, we
    will align to the general guidelines provided by **Cross Industry Standard Process
    for Data Mining** (**CRISP-DM**) consortium. The CRISP-DM reference model was
    conceived in late 1996 by three pioneers of the emerging data mining market and
    continued to evolve through participation from multiple organizations and service
    suppliers across various industry segments. The following diagram shows the different
    phases of the CRISP-DM reference model:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个**端到端**（**E2E**）的迭代过程，由多个阶段组成。正如我们在本书的其余部分解释的不同阶段，我们将与**跨行业数据挖掘标准流程**（**CRISP-DM**）联盟提供的一般指南保持一致。CRISP-DM参考模型于1996年底由三位新兴数据挖掘市场的先驱提出，并在多个行业细分市场的组织和供应商的参与下不断演变。以下图表显示了CRISP-DM参考模型的不同阶段：
- en: '![Figure 7.8 – Phases of the CRISP-DM reference model (redrawn from https://www.the-modeling-agency.com/crisp-dm.pdf)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.8 – CRISP-DM参考模型阶段（重绘自https://www.the-modeling-agency.com/crisp-dm.pdf）]'
- en: '](img/B17595_07_08.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_07_08.jpg]'
- en: Figure 7.8 – Phases of the CRISP-DM reference model (redrawn f[rom https://www.the-modeling-agency.com/crisp-dm](https://www.the-modeling-agency.com/crisp-dm.pdf).pdf)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 – CRISP-DM参考模型阶段（重绘自https://www.the-modeling-agency.com/crisp-dm.pdf）
- en: 'This model is still considered a baseline and a proven tool for conducting
    successful data mining projects as its application is neutral and applies well
    to a wide variety of ML pipelines and workloads. Using the preceding reference
    model (*Figure 7.5*) as the foundation, the life cycle of an ML project can be
    expanded to the following activities:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型仍被视为一个基线，是一个成功进行数据挖掘项目的证明工具，因为其应用是中立的，并且适用于广泛的机器学习管道和工作负载。以先前的参考模型（*图7.5*）为基础，机器学习项目的生命周期可以扩展到以下活动：
- en: '![Figure 7.9 – Life cycle of an ML project'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.9 – 机器学习项目生命周期]'
- en: '](img/B17595_07_Table3.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_07_Table3.jpg]'
- en: Figure 7.9 – Life cycle of an ML project
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9 – 机器学习项目生命周期
- en: 'The workflow of the preceding ML activities can be visually depicted as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 上述机器学习活动的流程可以直观地表示如下：
- en: '![Figure 7.10 – E2E ML process'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.10 – 端到端机器学习流程]'
- en: '](img/B17595_07_10.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_07_10.jpg]'
- en: Figure 7.10 – E2E ML process
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10 – 端到端机器学习流程
- en: In the following section, we will elaborate on these concepts in detail by using
    an image classification scenario for your connected home.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将通过使用您连接家居中的图像分类场景来详细阐述这些概念。
- en: Business understanding and problem framing
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 业务理解和问题界定
- en: The first phase is working backward from the use case and understanding the
    requirements from a business perspective. Once that's clear, the business context
    gets translated to the technical requirements (such as the need for ML technologies)
    to achieve the required business outcomes. Does this concept sound familiar? If
    yes, congrats—you were able to relate to the concepts of **domain-driven design**
    (**DDD**), introduced in [*Chapter 6*](B17595_06_Final_SS_ePub.xhtml#_idTextAnchor119),
    *Processing and Consuming Data on the Cloud*. The ML capabilities can be treated
    as just another bounded context with its own set of ubiquitous languages.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个阶段是从用例反向工作，从业务角度理解需求。一旦这一点明确，业务背景就会转化为技术需求（例如对机器学习技术的需求），以实现所需的企业成果。这个概念听起来熟悉吗？如果是的话，恭喜您——您已经能够将*第6章*中介绍的**领域驱动设计**（**DDD**）的概念与这些概念联系起来，*在云上处理和消费数据*。机器学习能力可以被视为另一个有自己一套通用语言的边界上下文。
- en: 'But problem-solving using ML can be different, and here is a great quote from
    Peter Norvig (Director of Research at Google) on that:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 但使用机器学习解决问题可能会有所不同，以下是从谷歌研究总监彼得·诺维格（Peter Norvig）那里摘录的关于这一点的精彩引言：
- en: '"Machine Learning changes the way you think about a problem. The focus shifts
    from a mathematical science to a natural science, running experiments and using
    statistics, not logic, to analyze its results."'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '"机器学习改变了你对问题的思考方式。焦点从数学科学转向自然科学，通过进行实验和使用统计学方法，而不是逻辑，来分析其结果。"'
- en: 'An organization needs to clearly identify whether the business problem they
    are trying to solve is an ML problem. If the problem can be solved using traditional
    programming methods, building ML models might be overkill. For example, if you
    plan to forecast the future revenue of your business for a specific quarter based
    on historical data, traditional analytical methods might be sufficient. But if
    you start factoring prediction of other variables such as weather, competitor
    campaigns, promotions, economy, this becomes a better fit for an ML problem. So,
    as a rule of thumb, always try to start your ML journey with the following questions:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一个组织需要清楚地确定他们试图解决的商业问题是否是机器学习问题。如果问题可以使用传统的编程方法解决，那么构建机器学习模型可能就是过度了。例如，如果你计划根据历史数据预测特定季度的未来收入，传统的分析方法可能就足够了。但如果你开始考虑其他变量的预测，如天气、竞争对手的活动、促销、经济状况，这更适合机器学习问题。所以，作为一个经验法则，始终尝试用以下问题开始你的机器学习之旅：
- en: '*What problem is my organization or product facing?*'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*我的组织或产品面临什么问题？*'
- en: Let's consider a scenario where you are trying to solve the problem of securing
    your family, pets, and neighbors from incoming traffic around your parking space.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们考虑一个场景，你试图解决的问题是保护你的家人、宠物和邻居免受停车空间周围来车的影响。
- en: '*Would it be a good problem to solve using ML or classic analytics methods?*'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用机器学习或经典分析方法解决这个问题是否合适？*'
- en: Here, a connected **Home Base Solutions** (**HBS**) hub is required to identify
    any living things in the parking space when a vehicle approaches or departs the
    area. This problem cannot be solved using a classic analytics method because you
    won't have the schedule available for every visitor, neighbor, or delivery van
    for your area. Thus, the hub can detect the movement of a vehicle(s) using motion
    sensors, capture different images from the surroundings (using the installed camera),
    and run real-time inferences to detect any objects around it. If that's found,
    it will alert the driver, kids, or pets in real time and avoid accidents.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这种情况下，需要一个连接的**家庭基站解决方案**（**HBS**）中心来识别车辆接近或离开区域时停车空间中的任何生物。这个问题不能使用经典的分析方法来解决，因为你不会为该区域的每个访客、邻居或送货卡车提供时间表。因此，中心可以使用运动传感器检测车辆（的）移动，从周围环境（使用安装的摄像头）捕获不同的图像，并运行实时推理来检测其周围的任何物体。如果发现物体，它将实时警告司机、孩子或宠物，从而避免事故。
- en: Earlier, computer vision (CV) models relied on raw pixel data as an input, but
    this was found to be inefficient due to several other factors such as different
    backgrounds behind the object, lighting, camera angle, or focus. Thus, image classification
    is clearly an ML problem.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以前，计算机视觉（CV）模型依赖于原始像素数据作为输入，但由于物体背后的不同背景、光照、相机角度或焦点等几个其他因素，这被发现效率低下。因此，图像分类显然是一个机器学习问题。
- en: '*If it''s an ML problem, do I have enough data of optimal quality?*'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如果是机器学习问题，我是否有足够数量和质量的数据？*'
- en: Considering the objects in scope here are generic—such as humans, cats, or cars—we
    can rely on public datasets such as **Caltech-256**. This dataset contains more
    than 30,000 images of 256 different types of objects.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 考虑到这里的对象是通用的——例如人类、猫或汽车——我们可以依赖公共数据集，如**Caltech-256**。这个数据集包含256种不同类型的超过30,000张图像。
- en: 'This is often the most common question we come across: *How much data is enough
    for training?* It really depends.'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这通常是我们遇到的最常见问题：*多少数据足够用于训练？* 这真的取决于。
- en: You should have at least a few thousand data points for basic linear models,
    and hundreds of thousands for neural networks (such as with image classification,
    as previously mentioned). More data of optimal quality enables the model to predict
    smarter. If you have less data or data of poor quality, the recommendation is
    to consider a purpose-built AI service non-ML solution first. I often like to
    quote that with data, it's always *garbage in = garbage out*. Thus, if you have
    questionable data quality, it is of less value to a classic analytics method or
    an ML process. Additionally, an ML process is more expensive as you will waste
    a lot of time and resources and incur costs to train models with questionable
    performance.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于基本的线性模型，您至少需要有几千个数据点，对于神经网络（如前面提到的图像分类）则需要数十万个。更多高质量的数据使模型能够更智能地预测。如果您数据较少或数据质量较差，建议首先考虑专用的AI服务非机器学习解决方案。我经常引用，有数据，总是“垃圾输入=垃圾输出”。因此，如果您有可疑的数据质量，对经典分析方法或机器学习过程的价值较小。此外，机器学习过程成本更高，因为您将浪费大量时间和资源，并因训练性能可疑的模型而承担成本。
- en: 'Now, let''s assume that you have met the preceding requirements and identified
    that the problem you are trying to solve is truly an ML one. In that case, you
    can choose the following best practices to summarize the problem framing:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们假设您已经满足了前面的要求，并确定您试图解决的问题确实是一个机器学习问题。在这种情况下，您可以选择以下最佳实践来总结问题框架：
- en: Formulate the ML problem into a set of questions with its respective inputs
    and desired outputs.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将机器学习问题表述为一系列问题，每个问题都有相应的输入和期望的输出。
- en: Define tangible performance metrics for the project, such as accuracy, prediction,
    or latency.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为项目定义可衡量的性能指标，例如准确性、预测或延迟。
- en: Establish the definition of success for the project.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确立项目的成功定义。
- en: Frame a strategy for data sourcing and data annotation.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制定数据来源和数据标注的策略。
- en: Start simple—build a model that is easy to interpret, test, debug, and manage.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从简单开始——构建一个易于解释、测试、调试和管理的模型。
- en: Data collection or integration
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据收集或集成
- en: 'In this of the E2E ML process, you will identify a dataset that will feed as
    an input to the ML pipeline and evaluate the appropriate means to collect that.
    In the previous chapters, you have learned that for different IoT use cases, AWS
    provides a number of ways to ingest the raw data in bulk or in real time. In other
    real-world scenarios, if you have **petabytes** (**PB**) of historical data in
    your cloud platform or data centers from IoT devices and **information technology**
    (**IT**) systems, there are multiple ways to transfer that to a data lake in the
    cloud, as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个端到端机器学习流程中，您将确定一个数据集，该数据集将作为输入提供给机器学习管道，并评估收集该数据的方法。在前面的章节中，您已经了解到对于不同的物联网用例，AWS提供了多种方法来批量或实时地摄取原始数据。在其他现实场景中，如果您在云平台或数据中心中有来自物联网设备和信息技术系统的**PB**（PB）的历史数据，有多种方法可以将这些数据传输到云中的数据湖，如下所示：
- en: Transfer over the public internet
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过公共互联网传输
- en: Transfer over a private network using a dedicated fiber channel setup from your
    data centers to AWS using AWS Direct Connect
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用从您的数据中心到AWS的专用光纤通道设置在私有网络上传输
- en: Transfer using hardware devices such as AWS Snowball, AWS Snowmobile, or AWS
    Snowcone, as it will take less time than transfering over the public internet
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用硬件设备如AWS Snowball、AWS Snowmobile或AWS Snowcone进行迁移，因为它比通过公共互联网传输所需时间更短。
- en: Fun Fact
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有趣的事实
- en: Transporting data through snow devices is very similar to how you return a package
    to Amazon.com! You get hardware with an E-link screen acting as the return label,
    where the data can be loaded and shipped back to AWS data centers. If you have
    **exabytes** (**EB**) of data, AWS can even send you a truck for data transportation
    referred to as an AWS snowmobile. Please refer to the AWS documentation, *How
    to get started with AWS Snow Family* ([https://docs.aws.amazon.com/snowball/index.html](https://docs.aws.amazon.com/snowball/index.html)),
    to understand the required steps.
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过雪设备传输数据与您将包裹退回Amazon.com的方式非常相似！您会得到带有E-link屏幕的硬件，充当退货标签，数据可以加载并运回AWS数据中心。如果您有**EB**（EB）的数据，AWS甚至可以为您提供一辆用于数据传输的卡车，称为AWS
    Snowmobile。请参阅AWS文档，*如何开始使用AWS Snow Family* ([https://docs.aws.amazon.com/snowball/index.html](https://docs.aws.amazon.com/snowball/index.html))，以了解所需的步骤。
- en: 'Again, consider the scenario of developing an ML model to identify vehicles
    approaching a parking-space area. Here, you can use a training dataset from a
    public data repository such as **Caltech**, as you mostly require generic images
    of kids, pets, and moving objects such as cars and trucks to be classified. There
    will be two datasets in scope, as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，考虑开发一个用于识别驶向停车位区域的车辆机器学习模型的场景。在这里，您可以使用来自公共数据仓库（如**Caltech**）的训练数据集，因为您主要需要用于分类的通用图像，包括孩子、宠物以及移动物体，如汽车和卡车。将有两个数据集在范围内，如下所示：
- en: '**Training dataset**—Public dataset from Caltech to be hosted on a data lake
    (**Amazon Simple Storage Service** (**Amazon S3**))'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据集**—Caltech 的公共数据集，将托管在数据湖上（**Amazon Simple Storage Service**（**Amazon
    S3**））'
- en: '**Inferencing dataset**—Generated in real time on the hub'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理数据集**—在实时中心生成'
- en: 'The following code enables the downloading of two datasets from a public data
    repository:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码可以启用从公共数据仓库下载两个数据集：
- en: '![Figure 7.11 – Data understanding'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.11 – 数据理解'
- en: '](img/B17595_07_11.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17595_07_11.jpg](img/B17595_07_11.jpg)'
- en: Figure 7.11 – Data understanding
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11 – 数据理解
- en: For a different use case where a public dataset is not an option, your organization
    needs to have enough data points with optimal quality.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个公共数据集不可用的不同用例，您的组织需要拥有足够数量且质量最优的数据点。
- en: 'A summary of best practices for this phase is provided here:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提供了该阶段最佳实践的总结：
- en: Define the various sources of data that you will use as an input to the ML pipeline
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义您将用作机器学习管道输入的各种数据源
- en: Determine the form of data to be used as an input (that is, raw versus transformed)
    to the pipeline
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定要用于管道输入的数据形式（即，原始数据与转换数据）
- en: Use data lineage mechanisms to ensure that the data location and source are
    cataloged if required for further processing
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据血缘机制确保数据位置和来源被编目，如果需要进一步处理的话
- en: Use different AWS-managed services to collect, store, and process the data without
    additional heavy lifting
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用不同的 AWS 管理服务来收集、存储和处理数据，无需额外繁重的工作
- en: Data preparation
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备
- en: '**Data preparation** is a key step in the pipeline as the ML models cannot
    perform optimally if the underlying data is not cleaned, curated, and validated.
    With IoT workloads, since the edge devices are co-existing in a physical environment
    with humans (over being hosted in a physical data center), the amount of noisy
    data generated can be substantial. In addition, as the dataset continues to grow
    from the connected ecosystem, data validation through schema comparisons can help
    detect if the data structure in newly obtained datasets has changed (for example,
    when a feature is deprecated). You can also detect if your data has started to
    drift—that is, the underlying statistics of the incoming data are different from
    the initial dataset used to train the model. Drift can happen due to an underlying
    trend or seasonality of the data or other factors.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据准备**是管道中的关键步骤，因为如果底层数据未经清理、整理和验证，机器学习模型无法表现最佳。在物联网工作负载中，由于边缘设备与人类在物理环境中共存（而不是托管在物理数据中心），产生的噪声数据量可能很大。此外，随着数据集从连接的生态系统持续增长，通过模式比较进行数据验证可以帮助检测新获得的数据集中的数据结构是否发生变化（例如，当某个特征被弃用时）。您还可以检测数据是否开始漂移——也就是说，传入数据的潜在统计信息与用于训练模型的初始数据集不同。漂移可能由于数据的潜在趋势或季节性或其他因素引起。'
- en: 'Thus, the general recommendation is to start the data preparation with a small,
    statistically valid sample that can be iteratively improved with different strategies,
    such as the following:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一般建议从一个小型、统计上有效的样本开始数据准备，可以通过不同的策略（如下所示）迭代改进：
- en: Checking for data anomalies
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查数据异常
- en: Checking for changes in the data schema
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查数据模式的变化
- en: Checking for statistics of the different dataset versions
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查不同数据集版本的统计数据
- en: Checking for data integrity, and so on
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查数据完整性，等等
- en: AWS provides a number of ways to help you prepare data at scale. You have already
    played with **AWS Glue** in [*Chapter 5*](B17595_05_Final_SS_ePub.xhtml#_idTextAnchor090),
    *Ingesting and Streaming Data from the Edge*. If you remember, AWS Glue allows
    you to manage the life cycle of data—such as to discover, clean, transform, and
    catalog. Once the data treatment is complete and the data quality meets the required
    standard, it can be fed as an input to an ML process.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: AWS提供了多种方法来帮助你大规模地准备数据。你已经在[*第5章*](B17595_05_Final_SS_ePub.xhtml#_idTextAnchor090)，“从边缘摄取和流式传输数据”中玩过**AWS
    Glue**。如果你还记得，AWS Glue允许你管理数据生命周期，例如发现、清理、转换和编目。一旦数据处理完成，数据质量达到所需标准，就可以将其作为机器学习过程的输入。
- en: In this chapter, we have introduced you to a different problem statement though,
    which is dealing with an unstructured dataset (aka images). Considering you are
    using a public dataset that's already labeled, you will only split the dataset
    into a training and a validation subset. The most common approach used by data
    scientists is to split the available data into a training and a test dataset,
    which is generally 70-30 (%) or 80-20 (%).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们向您介绍了一个不同的问题陈述，即处理非结构化数据集（即图像）。考虑到你正在使用一个已经标记的公共数据集，你将只将数据集分成训练集和验证集。数据科学家最常用的方法是将可用数据分成训练集和测试集，这通常是70-30（%）或80-20（%）。
- en: 'The following code enables the splitting of two datasets from a public data
    repository:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码可以启用从公共数据存储库中拆分两个数据集：
- en: '![Figure 7.12 – Data preparation'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.12 – 数据准备'
- en: '](img/B17595_07_12.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.12 – 数据准备'
- en: Figure 7.12 – Data preparation
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.12 – 数据准备
- en: In the real world, though, you may not have clean or labeled data. Thus, you
    can leverage services such as **Amazon SageMaker Ground Truth**, which has an
    inbuilt capability to label data (such as images, text, audio, video) automatically
    along with easy access to public and private human labelers. This is useful if
    you lack in-house ML skills or are cost-sensitive to hiring data science professionals.
    Ground Truth uses an ML model to automatically label the raw data and produce
    high-quality training datasets at a fraction of a cost. But if the model fails
    to label the data confidently, it will route the problem to humans for resolution.
    Another aspect of data preparation is to understand the patterns in your dataset.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，你可能没有干净或标记好的数据。因此，你可以利用像**Amazon SageMaker Ground Truth**这样的服务，它具有自动标记数据（如图像、文本、音频、视频）的内建能力，同时可以轻松访问公共和私人的人类标记者。如果你缺乏内部机器学习技能或者对雇佣数据科学专业人士的成本敏感，这将非常有用。Ground
    Truth使用机器学习模型自动标记原始数据，并以极低成本生成高质量的训练数据集。但如果模型无法自信地标记数据，它将把问题转交给人类来解决。数据准备的一个方面是理解你的数据集中的模式。
- en: 'A summary of best practices for this phase is provided here:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 本阶段最佳实践的总结如下：
- en: Profile your data through discovery and transformation.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过发现和转换来分析你的数据。
- en: Choose the right tool for the right job (such as data labeling versus tuning).
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择合适的工具来完成合适的工作（例如数据标记与调整）。
- en: Understand the patterns from data compositions.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据组成中理解模式。
- en: Data visualization and analytics
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据可视化和分析
- en: In this phase, you can continue the data exploration through various analytics
    and visualization tools to assess the data fitment for ML training post profiling.
    You can continue to leverage services such as Amazon Athena, Amazon Quicksight,
    and others introduced to you in [*Chapter 6*](B17595_06_Final_SS_ePub.xhtml#_idTextAnchor119),
    *Processing and Consuming Data on the Cloud*.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你可以通过各种分析和可视化工具继续数据探索，以评估数据在分析后的适合度，用于机器学习训练。你可以继续利用像Amazon Athena、Amazon
    Quicksight等在[*第6章*](B17595_06_Final_SS_ePub.xhtml#_idTextAnchor119)，“在云上处理和消费数据”中介绍的服务。
- en: Feature engineering (FE)
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程（FE）
- en: In this phase, your responsibilities as IoT professionals are very limited.
    This is where the data scientists will determine the unique attributes in the
    dataset that can be useful in training the ML model. You can think of rows as
    observations and columns as properties (or attributes). As data scientists, your
    goal is to identify the columns that matter in solving a specific business problem
    (aka features). For example, with image classification, the color or brand of
    a car is not a key feature to determine it as a vehicle. This process of selecting
    and transforming variables to ensure the creation of an optimized ML model is
    referred to as **FE**. Thus, the key objective of FE is to curate data in a form
    that an ML algorithm can use to extract patterns and infer better results.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，作为物联网专业人士，您的责任非常有限。这是数据科学家将确定数据集中可用于训练 ML 模型的独特属性的地方。您可以将行视为观测值，将列视为属性（或属性）。作为数据科学家，您的目标是识别在解决特定业务问题（即特征）中起作用的列。例如，在图像分类中，汽车的颜色或品牌不是确定其为车辆的关键特征。这个过程，即选择和转换变量以确保创建优化的
    ML 模型，被称为 **FE**。因此，FE 的关键目标是整理数据，使其以 ML 算法可以用来提取模式和推断更好结果的形式。
- en: 'Let''s break down the different phases of FE, as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按以下方式分解 FE 的不同阶段：
- en: '**Feature creation** to identify the attributes from a dataset relevant to
    the problem in scope, such as height and width of the pixels for images'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征创建**，以识别与特定问题相关的数据集属性，例如图像的像素高度和宽度'
- en: '**Feature transformation** for data compatibility or quality transformation,
    such as resizing inputs to a fixed size or converting non-numeric to numeric data'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征转换**，用于数据兼容性或质量转换，例如将输入调整到固定大小或将非数值数据转换为数值数据'
- en: '**Feature extraction** to determine a reduced set of features that offers the
    most value'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征提取**，确定一组提供最大价值的特征'
- en: '**Feature selection** to filter redundant features from a dataset by observing
    variance of correlation thresholds'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征选择**，通过观察相关阈值方差来过滤数据集中的冗余特征'
- en: If the number of features in a dataset becomes substantially large compared
    to the observations it can generate, the ML model may suffer from a problem called
    **overfitting**. On the other hand, if the number of features is limited, the
    model may infer a lot of incorrect predictions. This problem is referred to as
    **underfitting**. In other words, the model has trained well on the test data
    but is unable to apply the generalization to new or unseen datasets. Thus, feature
    extraction can help optimize a set of features for ML processing that are sufficient
    to generate a comprehensive version of the original set. Other than reducing the
    overfitting risk, feature extraction also speeds up the training through data
    compression and accuracy improvements. Different feature extraction techniques
    include **Principal Component Analysis** (**PCA**), **Independent Component Analysis**
    (**ICA**), **Linear Discriminant Analysis** (**LDA**), and **Canonical Correlation
    Analysis** (**CCA**).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集中的特征数量与它可以生成的观测值相比变得非常大，ML 模型可能会遭受称为 **过拟合** 的问题。另一方面，如果特征数量有限，模型可能会做出很多错误的预测。这个问题被称为
    **欠拟合**。换句话说，模型在测试数据上训练得很好，但无法将泛化应用于新的或未见过的数据集。因此，特征提取可以帮助优化一组特征，这些特征足以生成原始集的全面版本。除了减少过拟合风险外，特征提取还可以通过数据压缩和精度改进来加速训练。不同的特征提取技术包括
    **主成分分析**（**PCA**）、**独立成分分析**（**ICA**）、**线性判别分析**（**LDA**）和 **典型相关分析**（**CCA**）。
- en: AWS provides a number of ways to help you perform FE on your dataset at scale
    in an iterative way. For example, Amazon SageMaker as a managed service provides
    a hosted **Jupyter** notebook environment where you can use scikit-learn libraries
    to perform FE. If your organization is already invested in an **extract, transform,
    load** (**ETL**) framework such as AWS Glue, **AWS Glue DataBrew**, or a managed
    Hadoop framework such as **Amazon Elastic MapReduce** (**Amazon EMR**), the data
    scientists can perform FE and transformation there, prior to leveraging SageMaker
    to train and deploy the models.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 提供了多种方式，以帮助您以迭代的方式在您的数据集上进行大规模的特征工程（FE）。例如，Amazon SageMaker 作为一项托管服务，提供了一个托管
    **Jupyter** 笔记本环境，您可以在其中使用 scikit-learn 库进行 FE。如果您的组织已经投资于 **提取、转换、加载**（**ETL**）框架，如
    AWS Glue、**AWS Glue DataBrew**，或托管 Hadoop 框架，如 **Amazon Elastic MapReduce**（**Amazon
    EMR**），数据科学家可以在那里进行 FE 和转换，在利用 SageMaker 训练和部署模型之前。
- en: Another option is using **Amazon SageMaker Processing**. This feature provides
    a fully managed environment for running analytics jobs for FE and model evaluation
    at scale, along with incorporating various security and compliance requirements.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选项是使用**Amazon SageMaker Processing**。此功能提供了一个完全管理的环境，用于在规模上运行分析作业以及模型评估，同时满足各种安全和合规要求。
- en: 'Here is a summary of best practices for this phase:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是这个阶段最佳实践的总结：
- en: Evaluate the attributes from the dataset that fit the *feature* paradigm
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估数据集中符合*特征*范式的属性
- en: Consider features that are useful to solve the problem at hand and remove redundant
    ones
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑对解决当前问题有用的特征，并删除冗余的特征
- en: Build an iteration mechanism to explore new features or feature combinations
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立一个迭代机制来探索新的特征或特征组合
- en: Model training
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练
- en: 'The key activities in this phase include choosing an ML algorithm that''s appropriate
    for your problem and then training the model with the preprocessed data (aka features)
    from the earlier phases. We have already introduced you to the ML algorithms that
    are most common for IoT workloads in the *Taxonomy of ML with IoT workloads* section.
    Let''s dive a bit deeper into those algorithms, as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段的关键活动包括选择适合您问题的机器学习算法，然后使用前期预处理的数据（即特征）来训练模型。我们已经在“机器学习与物联网工作负载的分类”部分向您介绍了最常用于物联网工作负载的机器学习算法。让我们更深入地探讨这些算法，如下所示：
- en: '**Classification**—Classification can be applied in two ways; that is, binomial
    or multiclass. Binomial is useful when you have a set of observed values around
    two groups or categories, such as dog versus cat, or email being spam or not spam.
    Multiclass includes more than two groups or categories such as a set of flowers
    —roses, lilies, orchids, or tulips. Different classification techniques include
    decision trees, random forests, logistic regression, and naive Bayes.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**——分类可以以两种方式应用；即二分类或多分类。二分类在您有两个组或类别的观察值时很有用，例如狗与猫，或电子邮件是否为垃圾邮件。多分类包括两个以上的组或类别，如一组花朵——玫瑰、百合、兰花或郁金香。不同的分类技术包括决策树、随机森林、逻辑回归和朴素贝叶斯。'
- en: '**Regression**—Classification is used to predict a discrete value, whereas
    regression is used to predict a continuous variable. Regression can be applied
    in three ways: *least square method*, *linear*, or *logistic*.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**——分类用于预测离散值，而回归用于预测连续变量。回归可以以三种方式应用：*最小二乘法*、*线性*或*逻辑回归*。'
- en: '**Clustering**—*K-means* is a very popular clustering algorithm generally used
    to assign a group to unlabeled data. This algorithm is fast and scalable as it
    uses a methodology to assign each group by computing the distance between the
    data point and each group center.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**——*K-means*是一个非常流行的聚类算法，通常用于将组分配给未标记的数据。此算法速度快且可扩展，因为它使用一种方法通过计算数据点与每个组中心之间的距离来分配每个组。'
- en: 'In the safety scenario around the parking space cited earlier, we are using
    a multiclass classification algorithm, since we expect the model to classify multiple
    categories of objects, such as humans (specially kids), cars, and animals (such
    as cats, dogs, and rabbits). AWS services such as SageMaker do the undifferentiated
    heavy lifting of creating and managing the underlying infrastructure required
    for the training. You can choose different types of instances, such as CPU- or
    GPU-enabled. In the following example, you only specify an instance type of `ml.p2.xlarge`
    along with other required parameters such as `volume` and `instance_count`, and
    SageMaker does the rest, using the estimator interface for instantiating and managing
    the infrastructure:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面提到的停车位安全场景中，我们正在使用多类分类算法，因为我们期望模型能够对多个类别的对象进行分类，例如人类（特别是儿童）、汽车和动物（如猫、狗和兔子）。AWS服务如SageMaker负责创建和管理训练所需的基础设施的重型工作。您可以选择不同类型的实例，例如启用CPU或GPU的实例。在下面的示例中，您只需指定实例类型为`ml.p2.xlarge`，以及其他所需的参数，如`volume`和`instance_count`，SageMaker将完成其余工作，使用估算器接口来实例化和管理基础设施：
- en: '![Figure 7.13 – ML training infrastructure'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.13 – 机器学习训练基础设施'
- en: '](img/B17595_07_13.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_07_13.jpg)'
- en: Figure 7.13 – ML training infrastructure
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.13 – 机器学习训练基础设施
- en: You will be using the **MXNet framework** in this chapter, but SageMaker allows
    most other ML frameworks, such as TensorFlow, PyTorch, and Gluon, to train your
    model.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将使用**MXNet框架**，但SageMaker允许使用大多数其他机器学习框架，如TensorFlow、PyTorch和Gluon来训练您的模型。
- en: 'Please note that model optimization is a critical aspect of ML where you need
    to train a model with different sets of parameters to identify the most performant
    one. SageMaker hyperparameter tuning jobs help to optimize the models using Bayesian
    optimization or random search techniques. As you can see in the following example,
    the model is getting trained using hyperparameters such as batch size and shape
    to solve your business problem:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，模型优化是机器学习的一个关键方面，您需要使用不同参数集训练模型，以确定性能最佳的一个。SageMaker 超参数调优作业帮助使用贝叶斯优化或随机搜索技术来优化模型。正如以下示例所示，模型正在使用批大小和形状等超参数进行训练，以解决您的业务问题：
- en: '![Figure 7.14 – ML training parameters'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.14 – 机器学习训练参数'
- en: '](img/B17595_07_14.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_07_14.jpg)'
- en: Figure 7.14 – ML training parameters
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14 – 机器学习训练参数
- en: To make this process of model training easier and cost-effective for organizations
    new to ML, SageMaker supports automatic model tuning (through **Autopilot**) to
    automatically perform these actions on your behalf. It's also possible to use
    your custom ML algorithm as a container image and train it using SageMaker. For
    example, if you already have a homegrown image classification model that doesn't
    use any of the SageMaker-supported ML frameworks, you can use your model as a
    container image and retrain it in SageMaker without starting from scratch. SageMaker
    also offers a monitoring and debugging capability that allows clear visibility
    to the training metrics.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使组织在机器学习方面的新手更容易且成本效益更高地进行模型训练，SageMaker 支持自动模型调优（通过**自动飞行**），以自动代表您执行这些操作。您还可以使用自定义机器学习算法作为容器镜像，并使用
    SageMaker 进行训练。例如，如果您已经有一个自制的图像分类模型，它不使用任何 SageMaker 支持的机器学习框架，您可以使用您的模型作为容器镜像，并在
    SageMaker 中重新训练它，而不需要从头开始。SageMaker 还提供监控和调试功能，允许清晰地查看训练指标。
- en: 'Here is a summary of best practices of this phase:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 本阶段最佳实践的总结如下：
- en: Choose the right algorithm and training parameters for your data or let the
    managed services choose these for you
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为您的数据选择合适的算法和训练参数，或者让托管服务为您选择这些参数
- en: Ensure the dataset is segregated into training and test sets
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保数据集被分割成训练集和测试集
- en: Apply incremental learning to build the most optimized model
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用增量学习以构建最优化模型
- en: Monitor the training metrics to ensure the model performance doesn't degrade
    over time
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控训练指标以确保模型性能不会随时间退化
- en: Model evaluation and deployment
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估和部署
- en: In this phase, the model is evaluated to assess if it solves the business problem
    in context. If it doesn't, you can build multiple models with different business
    rules or methodologies (such as a different algorithm, other training parameters,
    and so on) until you find the optimized model that meets the business KPIs. Data
    scientists may often uncover inferences for other business problems in this phase
    as they test the model(s) against a real application. In order to evaluate the
    model, it can be tested against *historical data* (aka offline evaluation) or
    *live data* (aka online evaluation). Once the ML algorithm passes the evaluation,
    the next step is to deploy the model(s) to production.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，模型被评估以确定它是否解决了业务问题。如果没有，您可以构建多个具有不同业务规则或方法（例如不同的算法、其他训练参数等）的模型，直到找到满足业务关键绩效指标的最优模型。数据科学家在测试模型（们）针对实际应用时，常常在这个阶段发现其他业务问题的推论。为了评估模型，它可以与*历史数据*（即离线评估）或*实时数据*（即在线评估）进行测试。一旦机器学习算法通过评估，下一步就是将模型（们）部署到生产环境中。
- en: 'The scenario for IoT/edge workloads gets a bit tricky, though, if your use
    cases primarily deal with offline processing and inferencing on the edge. In that
    case, you don''t have access to the scale of the cloud, and thus the best practice
    is often to further optimize the models. **SageMaker Neo** can be useful in this
    scenario, as it allows you to train your model once and run anywhere in the cloud
    or at the edge. With this service, you can compile the model in most common frameworks
    (such as MXNET, TensorFlow, PyTorch, Keras) and deploy the optimized version on
    a target platform of your choice (such as hardware from Intel, NXP, NVIDIA, Apple,
    and so on). The following code helps to optimize the model based on different
    parameters such as OS and Architecture:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 物联网/边缘工作负载的场景可能会变得有些棘手，尤其是当你的用例主要涉及在边缘进行离线处理和推理时。在这种情况下，你无法访问云的规模，因此最佳实践通常是进一步优化模型。**SageMaker
    Neo**在这种情况下可能很有用，因为它允许你一次训练模型，然后在云中的任何地方或边缘运行。使用这项服务，你可以在大多数常见的框架（如MXNET、TensorFlow、PyTorch、Keras）中编译模型，并在你选择的平台（如英特尔、NXP、NVIDIA、苹果等硬件）上部署优化版本。以下代码有助于根据不同的参数（如操作系统和架构）优化模型：
- en: '![Figure 7.15 – Optimizing the model with SageMaker Neo'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 7.15 – 使用SageMaker Neo优化模型'
- en: '](img/B17595_07_15.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_07_15.jpg]'
- en: Figure 7.15 – Optimizing the model with SageMaker Neo
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 7.15 – 使用SageMaker Neo优化模型
- en: 'The way SageMaker Neo works is, its compiler uses an ML model under the hood
    to apply the best available performance for your model on the respective edge
    platform or device. Neo can optimize models to perform up to 25 times faster with
    no loss in accuracy and requires as little as one-tenth of the footprint compared
    to a non-optimized model. But how? Let''s explore, as follows:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Neo的工作方式是，其编译器在底层使用ML模型来为相应的边缘平台或设备上的模型应用最佳性能。Neo可以将模型优化到比非优化模型快25倍，且精度不受损失，并且所需的内存占用仅为非优化模型的十分之一。但这是如何实现的呢？让我们继续探索，如下所示：
- en: Neo has a compiler and a runtime component.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neo具有编译器和运行时组件。
- en: The Neo compiler has an **application programming interface** (**API**) that
    can read models developed using various frameworks. Once the read operation is
    complete, it converts the framework-specific functions and operations into a framework-agnostic
    intermediate representation.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neo编译器有一个**应用程序编程接口**（**API**），可以读取使用各种框架开发的模型。一旦读取操作完成，它将框架特定的函数和操作转换为框架无关的中间表示。
- en: Once the conversion is complete, it then starts performing a set of optimizations.
    As a result of this optimization, binary code is generated and persisted to a
    shared object library, along with the model definition and parameters that are
    stored in separate files.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换完成后，它开始执行一系列优化。由于这种优化的结果，生成了二进制代码，并将其持久化到共享对象库中，同时模型定义和参数存储在单独的文件中。
- en: Finally, Neo runtime APIs for the supported target platform can load and execute
    this compiled model to offer the required performance boost.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，Neo运行时API可以加载并执行此编译模型，以提供所需性能提升。
- en: 'As you can imagine, this optimization is powerful for edge devices as they
    are resource-constrained. The following screenshot diagrammatically represents
    how you can deploy an optimized model in your production environment. In the *Hands-on
    with ML architecture* section of this chapter, you will learn how to deploy a
    model trained with SageMaker Neo:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想，这种优化对资源受限的边缘设备来说非常强大。以下截图以图解方式表示了如何在生产环境中部署优化模型。在本章的“动手实践ML架构”部分，你将学习如何使用SageMaker
    Neo部署训练的模型：
- en: '![ Figure 7.16 – Optimizing the ML model for the hardware'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '![ Figure 7.16 – 为硬件优化ML模型'
- en: '](img/B17595_07_16.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_07_16.jpg]'
- en: Figure 7.16 – Optimizing the ML model for the hardware
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 7.16 – 为硬件优化ML模型
- en: Once the model is deployed, you need to monitor the performance metrics over
    time. This is because it's pretty common for models to function less effectively
    as the real-world data may start to differ from the data that was used to train
    the model. The SageMaker Model Monitor service can help detect deviations and
    alert you, the data scientists, or ML operators, to take remedial action.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部署后，你需要监控性能指标随时间的变化。这是因为模型在实际数据开始与用于训练模型的数据不同时，其功能可能会变得不那么有效是很常见的。SageMaker模型监控服务可以帮助检测偏差，并提醒数据科学家或ML操作员采取补救措施。
- en: 'Here is a summary of best practices for this phase:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是这个阶段最佳实践的总结：
- en: Evaluate if the model performance meets the business goals
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估模型性能是否符合业务目标
- en: Identify the inferencing method required for your models (offline versus online)
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定您的模型所需的推理方法（离线与在线）
- en: Deploy the model on the cloud with automatic scaling options or on the edge
    with hardware-specific optimization
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在云上部署模型，使用自动扩展选项，或在边缘使用针对特定硬件的优化
- en: Monitor the model performance in production to identify drift and perform remediations
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控生产中的模型性能，以识别漂移并执行修复
- en: ML design principles
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习设计原则
- en: 'Now that you have learned about the common activities in an ML workflow, let''s
    summarize the design principles from the steps explained in the preceding section,
    as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了机器学习工作流程中的常见活动，让我们总结前述章节中解释的步骤设计原则，如下：
- en: Work backward from the use case to identify if it's a problem that needs ML
    or that can be solved using a classic analytical approach.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从用例逆向工作，以确定是否需要机器学习或可以使用经典分析方法解决的问题。
- en: Collect enough data of optimal quality to have accurate ML models.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集足够数量和高质量的数据，以构建准确的机器学习模型。
- en: 'Perform profiling to understand the data relationships and compositions. Remember:
    *garbage in = garbage out*, thus data preparation is key in an ML process.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行性能分析以了解数据关系和组成。记住：*垃圾输入=垃圾输出*，因此数据准备在机器学习过程中至关重要。
- en: Start with a small set of features (aka attributes) to solve a specific business
    problem and evolve through experimentation.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以一小组特征（即属性）开始，解决特定的业务问题，并通过实验进行演变。
- en: Consider using different sets of data for training, evaluating, and inferencing
    purposes.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑使用不同的数据集进行训练、评估和推理。
- en: Evaluate the accuracy of the models and continue to iterate until it's optimal
    for the business problem in context.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估模型的准确性，并继续迭代，直到它对业务问题最优化。
- en: Determine if the model needs to inference on real-time (online) or historical
    (offline) data.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定模型是否需要在实时（在线）或历史（离线）数据上进行推理。
- en: Host different variants of the model on the cloud or on the edge and identify
    the most optimal one against real-world data.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在云上或边缘托管模型的多个变体，并针对实际数据确定最优化的一种。
- en: Continuously monitor the metrics from the deployed models for accuracy, remediation,
    and improvement.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续监控已部署模型的指标，以进行准确性、修复和改进。
- en: Leverage managed services for offloading the heavy lifting of managing the underlying
    infrastructure.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用托管服务来减轻管理底层基础设施的繁重工作。
- en: Automate the different activities of the pipeline as much as possible, such
    as data preparation, model training, evaluation, hosting, monitoring, and alerting.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽可能自动化管道的不同活动，如数据准备、模型训练、评估、托管、监控和警报。
- en: ML anti-patterns for IoT workloads
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 物联网工作负载的机器学习反模式
- en: 'Similar to any other distributed solutions, IoT workloads based on ML have
    anti-patterns as well. Here are some of them:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何其他分布式解决方案类似，基于机器学习的物联网工作负载也有反模式。以下是一些例子：
- en: '**Don''t put all your eggs in one basket**—The E2E ML process includes many
    activities and thus requires different personas such as the following:'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不要把所有的鸡蛋放在一个篮子里**——端到端机器学习过程包括许多活动，因此需要以下不同角色：'
- en: '*Data engineer*—For data preparation, designing ETL (or ELT) processes'
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据工程师*——用于数据准备、设计 ETL（或 ELT）流程'
- en: '*Data scientists*—For building, training, and optimizing the models'
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据科学家*——用于构建、训练和优化模型'
- en: '*Development-operations (DevOps* or *MLOps) engineers*—For building a scalable
    and repeatable machine learning infrastructure built with operating and monitoring
    mechanisms'
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开发运维（DevOps* 或 *MLOps）工程师*——用于构建具有操作和监控机制的可扩展和可重复的机器学习基础设施'
- en: '*IoT engineers*—For building a cloud-to-edge deployment pipeline along with
    integration from the IoT gateway to different backend services'
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*物联网工程师*——用于构建从物联网网关到不同后端服务的云到边缘部署管道'
- en: In summary, expecting a single resource to perform all these activities at scale
    will lead to the failure of the project.
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 总结来说，期望单一资源在规模上执行所有这些活动将导致项目失败。
- en: '**Don''t assume the requirements; get aligned**—A plethora of tools is available
    for analytical and ML purposes and each has its pros and cons. For example, consider
    the following:'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不要假设需求；保持一致**——有大量工具可用于分析和机器学习目的，每个工具都有其优缺点。例如，考虑以下：'
- en: Both **R** and **Python** are popular programming languages for developing ML
    systems. In general, business analysts or statisticians will prefer R or other
    commercial solutions (such as **MATLAB**), while data scientists will choose Python.
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**R** 和 **Python** 都是开发机器学习系统的流行编程语言。一般来说，业务分析师或统计学家会倾向于使用 R 或其他商业解决方案（如 **MATLAB**），而数据科学家会选择
    Python。'
- en: Similarly, data scientists may have their preferred ML framework, such as TensorFlow
    over PyTorch. Choosing different languages or frameworks has downstream impacts—for
    example, the edge hardware may need to support the respective version or libraries
    required for inferencing the ML model.
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同样，数据科学家可能有自己的首选机器学习框架，例如 TensorFlow 而不是 PyTorch。选择不同的语言或框架会产生下游影响——例如，边缘硬件可能需要支持用于推理机器学习模型的相应版本或库。
- en: Thus, it's important for all the different personas engaged in ML activities
    to stay aligned on the business and technical requirements.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，对于所有参与机器学习活动的不同角色来说，保持对业务和技术要求的统一至关重要。
- en: '**Plan for technical debt**—ML systems for IoT workloads are prone to accruing
    technical debt due to their data dependencies from IoT sources that are often
    unreliable due to their noisiness. This may also happen due to dependencies on
    other upstreams having inconsistent data. For example, consider the following:'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规划技术债务**—由于机器学习系统依赖于通常由于噪声而不太可靠的物联网来源的数据，因此它们容易积累技术债务。这也可能由于对其他上游数据不一致的依赖而发生。例如，考虑以下情况：'
- en: If the composition of any feature (or a few) changes substantially, it will
    lead the model to behave differently in the real world. This problem is also referred
    to as the **training-serving skew**, where there is a discrepancy in how you handle
    data in the training and serving pipelines.
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果任何特征（或几个特征）的组成发生实质性变化，它将导致模型在现实世界中的行为不同。这个问题也被称为**训练-服务偏差**，即你在训练和服务管道中处理数据的方式存在差异。
- en: The reason ML workloads are different from traditional IT systems is their behavior
    can be determined only through real data over unit testing with a small sample.
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习工作负载与传统 IT 系统不同的原因是，只有通过在单元测试中使用小样本的真实数据，才能确定其行为。
- en: Thus, it's key to monitor the accuracy of the model, optimize it iteratively
    based on the knowledge of the gathered data, and redeploy.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，监控模型的准确性、根据收集到的数据知识迭代优化并重新部署是关键。
- en: Hands-on with ML architecture
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践机器学习架构
- en: 'In this section, you will deploy a solution on a connected HBS hub that will
    require you to build and train ML models on the cloud and then deploy them to
    the edge for inferencing. The following screenshot shows the architecture of the
    lab with the highlighted steps *(1-5)* that you will complete:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将在一个连接的 HBS 节点上部署一个解决方案，这将要求你在云端构建和训练机器学习模型，然后将它们部署到边缘进行推理。以下截图显示了实验室的架构，其中突出显示了你需要完成的步骤（1-5）：
- en: '![Figure 7.17 – Hands-on ML architecture'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.17 – 实践机器学习架构'
- en: '](img/B17595_07_17.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_07_17.jpg)'
- en: Figure 7.17 – Hands-on ML architecture
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.17 – 实践机器学习架构
- en: 'Your objectives include the following, which are highlighted as distinct steps
    in the preceding architecture:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 你的目标包括以下内容，这些内容在先前的架构中以不同的步骤突出显示：
- en: Build the ML workflow using Amazon SageMaker
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker 构建机器学习工作流程
- en: Deploy the ML model from the cloud to the edge using AWS IoT Greengrass
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AWS IoT Greengrass 将机器学习模型从云端部署到边缘
- en: Perform ML inferencing on the edge and visualize the results
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在边缘执行机器学习推理并可视化结果
- en: 'The following table shows the list of components you will use during the lab:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了你在实验室中将要使用的组件列表：
- en: '![Figure 7.18 – Hands-on lab components'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.18 – 实践实验室组件'
- en: '](img/B17595_07_Table4.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_07_Table4.jpg)'
- en: Figure 7.18 – Hands-on lab components
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.18 – 实践实验室组件
- en: Building the ML workflow
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建机器学习工作流程
- en: In this section, you will build, train, and test the ML model using Amazon SageMaker
    Studio.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将使用 Amazon SageMaker Studio 构建、训练和测试机器学习模型。
- en: Note
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Training models using Amazon SageMaker will incur additional cost. If you want
    to save on that, please use a trained ML model available in GitHub for your platform
    and skip to the next section, that is, Deploying the model from cloud to the edge.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker 训练模型将产生额外的成本。如果你想要节省这部分成本，请使用 GitHub 上为你平台提供的已训练机器学习模型，并跳到下一节，即从云端部署模型到边缘。
- en: 'Amazon Sagemaker Studio is a web-based **integrated development environment**
    (**IDE**) that enables data scientists (or ML engineers) with a single-stop shop
    for all things ML. To train the model, you will use a public dataset from Caltech
    that has a collection of over 30,000 images across 256 object categories. Let''s
    begin. Proceed as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Sagemaker Studio是一个基于Web的**集成开发环境**（**IDE**），它为数据科学家（或ML工程师）提供了一个一站式商店，用于所有ML相关事务。为了训练模型，你将使用Caltech提供的公共数据集，该数据集包含256个物体类别中超过30,000张图片。让我们开始。按照以下步骤操作：
- en: Please navigate to the **Amazon SageMaker** console and select **SageMaker Domain
    Studio** (from the left pane). If this is the first time you are interacting with
    the studio, you will be prompted to complete a one-time setup. Please choose **Quick
    setup,** click **Submit,** choose **Default VPC with a subnet (s) of your choice**,
    then click **Save and continue**.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请导航到**Amazon SageMaker**控制台，并从左侧面板选择**SageMaker Domain Studio**。如果你第一次与工作室交互，你将需要完成一次性的设置。请选择**快速设置**，点击**提交**，选择**默认VPC及其子网（s）**，然后点击**保存并继续**。
- en: It will take a few minutes for the studio to be set up. Please wait until the
    status shows **Ready** and then click **Launch app** -> **Studio**.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置工作室需要几分钟时间。请等待状态显示为**Ready**，然后点击**启动应用** -> **工作室**。
- en: This should open up the SageMaker Studio (aka Jupyter console) for you. In case
    you are new to Jupyter, consider this as an IDE for developing ML models similar
    to Eclipse, Visual Studio, and so on, used for developing distributed applications.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这应该会为你打开SageMaker Studio（也称为Jupyter控制台）。如果你是Jupyter的新手，可以将它视为类似于Eclipse、Visual
    Studio等用于开发分布式应用的IDE。
- en: Please upload the Jupyter notebook (`Image-Classification*.ipynb`) and the `synset.txt`
    file from the `chapter7/notebook` folder using the **Upload file** button in the
    top-left pane.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请使用左上角的**上传文件**按钮，从`chapter7/notebook`文件夹上传`Image-Classification*.ipynb`和`synset.txt`文件。
- en: Double-click to open the Jupyter notebook and choose the Python runtime and
    kernel, as shown in the following screenshot:![Figure 7.19 – Jupyter notebook
    kernel
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 双击打开Jupyter笔记本，并选择Python运行时和内核，如下面的截图所示：![图7.19 – Jupyter笔记本内核
- en: '](img/B17595_07_19.jpg)'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B17595_07_19.jpg)'
- en: Figure 7.19 – Jupyter notebook kernel
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.19 – Jupyter笔记本内核
- en: Choosing a kernel is a critical step as it provides you with the appropriate
    runtime for training the ML model. Update the kernel (top right) to choose the
    GPU runtime for training the ML model. Since you will be processing images, a
    GPU runtime is preferable. After choosing the kernel, the Jupyter notebook will
    have the following kernel and configuration:![Figure 7.20 – Choosing a kernel
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择内核是一个关键步骤，因为它为你提供了训练ML模型所需的适当运行时。更新内核（右上角）以选择用于训练ML模型的GPU运行时。由于你将处理图像，因此GPU运行时更合适。选择内核后，Jupyter笔记本将具有以下内核和配置：![图7.20
    – 选择内核
- en: '](img/B17595_07_20.jpg)'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B17595_07_20.jpg)'
- en: Figure 7.20 – Choosing a kernel
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.20 – 选择内核
- en: Now, navigate through the code slowly. Please ensure you read the text preceding
    the code to better understand the functioning of each of these blocks.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，请慢慢浏览代码。请确保阅读代码前的文本，以便更好地理解每个这些块的功能。
- en: Click the `*`) adjacent to the block. The asterisk implies that the code is
    still running. Please wait for that to disappear before you proceed:![Figure 7.21
    – Running the steps
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击与代码块相邻的`*`)。星号表示代码仍在运行。请在继续之前等待它消失：![图7.21 – 运行步骤
- en: '](img/B17595_07_21.jpg)'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B17595_07_21.jpg)'
- en: Figure 7.21 – Running the steps
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.21 – 运行步骤
- en: 'If you go through all the steps till the end, you will be able to complete
    the following steps:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你完成所有步骤直到最后，你将能够完成以下步骤：
- en: Downloading a training dataset
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载训练数据集
- en: Preparing and preprocessing the data
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备和预处理数据
- en: Splitting the dataset into training and test samples
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集拆分为训练样本和测试样本
- en: Training the model using the appropriate framework and parameters
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用适当的框架和参数训练模型
- en: Optimizing the model for the edge hardware
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 优化边缘硬件上的模型
- en: Hosting the model artifacts on the Amazon S3 repository
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Amazon S3存储库上托管模型工件
- en: The model training can take up to 10 minutes to complete. After the training,
    you have an ML model that's trained using the MXNet framework and is capable of
    performing classification on 256 different objects.
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型训练可能需要10分钟才能完成。训练完成后，你将拥有一个使用MXNet框架训练的ML模型，该模型能够对256个不同的物体进行分类。
- en: Please navigate through the S3 bucket (`sagemaker-<region>-<accountid>/ic-fulltraining/`).
    Copy the S3 `DLR-resnet50-*-cpu-ImageClassification.zip`), as you will need it
    in the next section.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请导航到S3存储桶（`sagemaker-<region>-<accountid>/ic-fulltraining/`）。复制S3的`DLR-resnet50-*-cpu-ImageClassification.zip`文件，因为您将在下一节中使用它。
- en: Now that the model is trained on the cloud, you will deploy it on the edge using
    Greengrass for near-real-time inferencing.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已经在云端训练，您将使用Greengrass将其部署到边缘进行近实时推理。
- en: Deploying the model from cloud to the edge
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从云端到边缘部署模型
- en: As an IoT practitioner, deploying the model from the cloud to the edge is the
    step you will primarily be involved in. This is the transition point, where the
    ML or data science team provides a model that needs to be pushed to a fleet of
    devices on the edge. Although it's possible to automate these steps in the real
    world using a **continuous integration/continuous deployment (CI/CD)** pipeline,
    you will do it manually to learn the process in detail.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 作为物联网从业者，将模型从云端部署到边缘是您将主要参与的步骤。这是过渡点，ML或数据科学团队提供了一个需要推送到边缘设备集群的模型。虽然在现实世界中可以使用**持续集成/持续部署（CI/CD）**管道自动化这些步骤，但您将手动进行以详细了解该过程。
- en: Similar to the components you have created in the earlier chapters for deploying
    different processes on the edge (such as publisher, subscriber, aggregator), deploying
    an ML resource needs the same approach. We will create a component that includes
    the ML model trained in the previous section. We will continue to use the AWS
    console for continuity.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 与您在前面章节中创建的用于在边缘部署不同过程（如发布者、订阅者、聚合器）的组件类似，部署ML资源需要相同的方法。我们将创建一个包含在上一节中训练的ML模型的组件。我们将继续使用AWS控制台以保持一致性。
- en: Note
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Greengrass provides a sample image classification model component that you toyed
    with in [*Chapter 4*](B17595_04_Final_SS_ePub.xhtml#_idTextAnchor073), *Extending
    the Cloud to the Edge*. Here, you are learning how to modify existing model components
    with your custom resources. In the real world, you may even have to create a new
    model component from scratch, where you can follow a similar process.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: Greengrass提供了一个示例图像分类模型组件，您在[*第4章*](B17595_04_Final_SS_ePub.xhtml#_idTextAnchor073)，“将云扩展到边缘”中已经尝试过。在这里，您正在学习如何使用您自定义的资源修改现有的模型组件。在现实世界中，您甚至可能需要从头开始创建一个新的模型组件，您可以遵循类似的过程。
- en: 'Let''s begin. Proceed as follows:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始。按照以下步骤进行：
- en: Please navigate to the `chapter7/recipe` folder. Now, let's update the recipe
    to point to the trained model. Please replace the URI (marked with an arrow) with
    the S3 URI copied in *Step 10* of the *Building the ML workflow* section, as illustrated
    in the following screenshot. If you have skipped the earlier section and used
    a trained model from GitHub, please manually upload the model to the S3 bucket
    of your choice and update the S3 URI in the recipe accordingly:![Figure 7.22 –
    Recipe configuration
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请导航到`chapter7/recipe`文件夹。现在，让我们更新食谱以指向训练好的模型。请将URI（带有箭头标记）替换为在*构建ML工作流*部分的*步骤10*中复制的S3
    URI，如图中所示。如果您跳过了前面的部分并使用了GitHub上的训练模型，请手动将模型上传到您选择的S3存储桶，并相应地更新食谱中的S3 URI：![图7.22
    – 配置食谱
- en: '](img/B17595_07_22.jpg)'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17595_07_22.jpg)'
- en: Figure 7.22 – Recipe configuration
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.22 – 配置食谱
- en: Click **Create component** to finish creating the model resource. This model
    should appear on the **My components** tab of the **Components** page.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建组件**以完成模型资源的创建。此模型应出现在**组件**页面上的**我的组件**标签页中。
- en: Now, you need to create an inferencing component. This is the resource that
    triggers the model on the edge and publishes the results to the cloud.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您需要创建一个推理组件。这是触发边缘上的模型并发布结果到云的资源。
- en: Note
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Greengrass provides a sample image classification inferencing component, `aws.greengrass.DLRImageClassification`,
    that you already played with in [*Chapter 4*](B17595_04_Final_SS_ePub.xhtml#_idTextAnchor073),
    *Extending the Cloud to the Edge*. Here, you are learning how to use the same
    inferencing component to work with your custom ML model. In the real world, you
    may have to create a new inferencing component from scratch with a modified manifest
    file, as you just did with the model.
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Greengrass提供了一个示例图像分类推理组件，`aws.greengrass.DLRImageClassification`，您已经在[*第4章*](B17595_04_Final_SS_ePub.xhtml#_idTextAnchor073)，“将云扩展到边缘”中尝试过。在这里，您正在学习如何使用相同的推理组件与您的自定义机器学习模型一起工作。在现实世界中，您可能需要创建一个新的推理组件，从头开始，并使用修改后的清单文件，就像您刚才对模型所做的那样。
- en: 'On the `variant.DLR.ImageClassification.ModelStore`: ML model trained through
    SageMaker. You can choose this from the `aws.greengrass.DLRImageClassification`:
    Inferencing script for the ML model. You can choose this from the `variant.DLR`:
    Runtime required for the ML inferencing. You can choose this from the **Public
    Component** tab.'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `variant.DLR.ImageClassification.ModelStore`：通过 SageMaker 训练的机器学习模型。您可以从 `aws.greengrass.DLRImageClassification`
    中选择此选项：机器学习模型的推理脚本。您可以从 `variant.DLR` 中选择此选项：机器学习推理所需的运行时。您可以从 **公共组件** 选项卡中选择此选项。
- en: On the **Select Components** page, ensure the components shown in the following
    screenshot are chosen, and then click **Next**:![Figure 7.23 – Greengrass component
    dependencies
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **选择组件** 页面上，确保选择了以下屏幕截图所示的组件，然后点击 **下一步**：![图 7.23 – Greengrass 组件依赖关系
- en: '](img/B17595_07_23.jpg)'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17595_07_23.jpg](img/B17595_07_23.jpg)'
- en: Figure 7.23 – Greengrass component dependencies
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.23 – Greengrass 组件依赖关系
- en: On the `aws.greengrass.DLRImageClassification` component. This will enable the
    **Configure component** option; click on that.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `aws.greengrass.DLRImageClassification` 组件上。这将启用 **配置组件** 选项；点击它。
- en: 'Update the **Configuration to merge** section (right pane) with the following
    configuration and click on **Confirm**:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下配置更新 **合并配置** 部分（右侧面板）并点击 **确认**：
- en: '[PRE0]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Keep all the other options as default in the following screens and choose **Deploy**.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下屏幕中保持所有其他选项为默认设置，并选择 **部署**。
- en: Let's now move on to the next section.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续下一节。
- en: Performing ML inferencing on the edge and validating results
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在边缘执行机器学习推理并验证结果
- en: 'So, by now, the models are built, trained, and deployed on Greengrass. The
    images to be inferred are stored in the following directory:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，到目前为止，模型已在 Greengrass 上构建、训练和部署。要推理的图像存储在以下目录中：
- en: '![](img/B17595_07_24.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![img/B17595_07_24.jpg](img/B17595_07_24.jpg)'
- en: Figure 7.24 – Images directory on Greengrass hub
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.24 – Greengrass 中心上的图像目录
- en: Similar to the cat image, you can deploy other images as well (such as dogs,
    humans, and so on) and configure the inferencing component to infer on them.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 与猫图像类似，您还可以部署其他图像（如狗、人类等），并配置推理组件对它们进行推理。
- en: 'Let''s visualize the inferencing results that are being published from the
    edge to the cloud. These results are key in assessing if the model is performing
    at the expected accuracy level. We''ll proceed as follows:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们可视化从边缘发布到云端的推理结果。这些结果对于评估模型是否在预期的准确率水平上运行至关重要。我们将按以下步骤进行：
- en: 'First, let''s check if the component status shows as running and also check
    the Greengrass log to verify that there are no exceptions. Here''s the code we''ll
    need to do this:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们检查组件状态是否显示为正在运行，并检查 Greengrass 日志以验证没有异常。我们将需要以下代码来完成此操作：
- en: '[PRE1]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If there are no errors, please navigate to the AWS IoT console, choose **Test**,
    and then choose **MQTT test client**.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有错误，请导航到 AWS IoT 控制台，选择 **测试**，然后选择 **MQTT 测试客户端**。
- en: 'Under `ml/dlr/image-classification`. Click **Subscribe** to view the results,
    which should look like this:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `ml/dlr/image-classification` 下。点击 **订阅** 查看结果，结果应该看起来像这样：
- en: '![Figure 7.25 – Inferenced results from ML'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.25 – 机器学习推理结果'
- en: '](img/B17595_07_25.jpg)'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_07_25.jpg](img/B17595_07_25.jpg)'
- en: Figure 7.25 – Inferenced results from ML
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.25 – 机器学习推理结果
- en: If you get stuck or require help, please refer to the **Troubleshooting** section
    in GitHub.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您遇到困难或需要帮助，请参阅 GitHub 中的 **故障排除** 部分。
- en: Congratulations on finishing the hands-on section of this chapter! Now, your
    connected **HBS hub** is equipped with ML capabilities that can operate in both
    online and offline conditions and can classify humans, pets, and vehicles in your
    parking-space area.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您完成本章的动手实践部分！现在，您的连接 **HBS 中心** 已配备机器学习能力，可以在在线和离线条件下运行，并能在您的停车位区域内对人类、宠物和车辆进行分类。
- en: Challenge Zone (Optional)
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战区域（可选）
- en: Can you figure out how to act on the inference results published to AWS IoT
    Core? This will be useful to automatically trigger an announcement through notifications/alarms
    for cautioning kids/pets strolling in the parking-space area.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 您能想出如何对发布到 AWS IoT Core 的推理结果采取行动吗？这将有助于自动通过通知/警报触发公告，以警告在停车位区域内散步的孩子们/宠物。
- en: '**Hint**: You need to define a routing logic in the IoT Rules Engine to push
    the results through a notification service.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示**：您需要在 IoT 规则引擎中定义路由逻辑，以便通过通知服务推送结果。'
- en: Isn't it incredible that you have now learned how to build ML capabilities for
    IoT workloads on the edge? It's time for a well-deserved break! Let's wrap up
    this chapter with a quick summary and a set of questions.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何在边缘为物联网工作负载构建机器学习能力，这不是很神奇吗？现在是时候好好休息一下了！让我们通过快速总结和一系列问题来结束这一章。
- en: Summary
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you were introduced to ML concepts relevant to IoT workloads.
    You learned how to design ML pipelines, along with optimizing models for IoT workloads.
    You implemented an edge-to-cloud architecture to perform inferences on unstructured
    data (images). Finally, you validated the workflow by visualizing the inferencing
    results from the edge for additional insights.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了与物联网工作负载相关的机器学习概念。你学习了如何设计机器学习管道，以及针对物联网工作负载优化模型。你实现了边缘到云的架构，以对非结构化数据（图像）进行推理。最后，你通过可视化边缘的推理结果来验证工作流程，以获得更多见解。
- en: In the next chapter, you will learn how to implement DevOps and MLOps practices
    to achieve operational efficiency for IoT edge workloads deployed at scale.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何实施 DevOps 和 MLOps 实践，以实现大规模部署的物联网边缘工作负载的运营效率。
- en: Knowledge check
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 知识检查
- en: 'Before moving on to the next chapter, test your knowledge by answering these
    questions. The answers can be found at the end of the book:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入下一章之前，通过回答以下问题来测试你的知识。答案可以在书的末尾找到：
- en: 'True or false: Two types of ML algorithms exist: supervised and unsupervised.'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 判断对错：存在两种类型的机器学习算法：监督学习和无监督学习。
- en: Can you recall the four types of ML systems and their significance?
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能回忆起四种机器学习系统的类型及其重要性吗？
- en: 'True or false: K-means is a classification algorithm.'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 判断对错：K-means 是一种分类算法。
- en: Can you put the three phases of the ML project life cycle in the right order?
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能将机器学习项目生命周期的三个阶段按正确顺序排列吗？
- en: Can you think of at least two common frameworks used for training ML models?
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能想到至少两种用于训练机器学习模型的常用框架吗？
- en: What is the AWS service used for deploying trained models from the cloud to
    the edge?
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用于将训练好的模型从云端部署到边缘的 AWS 服务是什么？
- en: 'True or False: AWS IoT Greengrass only supports custom components for image
    classification problems.'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 判断对错：AWS IoT Greengrass 只支持用于图像分类问题的自定义组件。
- en: Can you tell me about one anti-pattern for ML with IoT workloads?
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能告诉我关于机器学习与物联网工作负载的一个反模式吗？
- en: References
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Take a look at the following resources for additional information on the concepts
    discussed in this chapter:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下资源，以获取本章讨论的概念的更多信息：
- en: 'CRISP: [https://www.datascience-pm.com/crisp-dm-2/](https://www.datascience-pm.com/crisp-dm-2/%0D)'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'CRISP: [https://www.datascience-pm.com/crisp-dm-2/](https://www.datascience-pm.com/crisp-dm-2/%0D)'
- en: '*A Short History of Machine Learning*: [https://www.forbes.com/sites/bernardmarr/2016/02/19/a-short-history-of-machine-learning-every-manager-should-read/?sh=1ca6cea115e7](https://www.forbes.com/sites/bernardmarr/2016/02/19/a-short-history-of-machine-learning-every-manager-should-read/?sh=1ca6cea115e7%0D)'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习简史*：[https://www.forbes.com/sites/bernardmarr/2016/02/19/a-short-history-of-machine-learning-every-manager-should-read/?sh=1ca6cea115e7](https://www.forbes.com/sites/bernardmarr/2016/02/19/a-short-history-of-machine-learning-every-manager-should-read/?sh=1ca6cea115e7%0D)'
- en: '*Machine Learning on AWS*: [https://aws.amazon.com/machine-learning/](https://aws.amazon.com/machine-learning/%0D)'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AWS 上的机器学习*：[https://aws.amazon.com/machine-learning/](https://aws.amazon.com/machine-learning/%0D)'
- en: 'ML with AWS IoT services: [https://aws.amazon.com/blogs/iot/category/artificial-intelligence/sagemaker/](https://aws.amazon.com/blogs/iot/category/artificial-intelligence/sagemaker/%0D)'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习与 AWS 物联网服务：[https://aws.amazon.com/blogs/iot/category/artificial-intelligence/sagemaker/](https://aws.amazon.com/blogs/iot/category/artificial-intelligence/sagemaker/%0D)
- en: '*Using AWS IoT Greengrass Version 2 with Amazon SageMaker Neo and NVIDIA DeepStream
    Applications*: [https://aws.amazon.com/blogs/iot/using-aws-iot-greengrass-version-2-with-amazon-sagemaker-neo-and-nvidia-deepstream-applications/](https://aws.amazon.com/blogs/iot/using-aws-iot-greengrass-version-2-with-amazon-sagemaker-neo-and-nvidia-deepstream-applications/%0D)'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 AWS IoT Greengrass 版本 2 与 Amazon SageMaker Neo 和 NVIDIA DeepStream 应用程序*：[https://aws.amazon.com/blogs/iot/using-aws-iot-greengrass-version-2-with-amazon-sagemaker-neo-and-nvidia-deepstream-applications/](https://aws.amazon.com/blogs/iot/using-aws-iot-greengrass-version-2-with-amazon-sagemaker-neo-and-nvidia-deepstream-applications/%0D)'
- en: 'Well-Architected Framework for ML: [https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/machine-learning-lens.html](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/machine-learning-lens.html%0D)'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习架构框架：[https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/machine-learning-lens.html](https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/machine-learning-lens.html%0D)
- en: 'Learn from AWS through **Machine Learning University** (**MLU**): [https://aws.amazon.com/machine-learning/mlu/](https://aws.amazon.com/machine-learning/mlu/)'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过**机器学习大学**（**MLU**）学习AWS：[https://aws.amazon.com/machine-learning/mlu/](https://aws.amazon.com/machine-learning/mlu/)
