- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Deploying and Monitoring Machine Learning Models
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署和监控机器学习模型
- en: In previous chapters, we learned a lot about different models and techniques.
    Understanding the concepts and building a machine learning model is only the beginning
    of the journey toward realizing its true value. The successful deployment and
    ongoing monitoring of these models are crucial to ensuring their effectiveness
    and reliability in real-world scenarios.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们学习了关于不同模型和技术的很多知识。理解概念和构建机器学习模型只是实现其实际价值的旅程的开始。这些模型的成功部署和持续监控对于确保它们在实际场景中的有效性和可靠性至关重要。
- en: Ensuring that a model performs optimally, seamlessly integrates with existing
    systems, and adapts to evolving requirements requires a comprehensive understanding
    of the deployment process and the associated considerations. In the context of
    the Qlik platform, most of the typical pain points are handled by the platform
    itself and the design of the components, but there are still things we have to
    bear in mind.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 确保模型表现最佳、无缝集成到现有系统中，并适应不断变化的需求，需要对部署过程及其相关考虑因素有全面的了解。在Qlik平台的情况下，大多数典型痛点都由平台本身和组件的设计处理，但仍有一些事情我们需要牢记。
- en: Once a machine learning model is deployed, it is vital to continuously monitor
    its performance to identify potential issues, maintain accuracy, and safeguard
    against unforeseen failures. Monitoring provides insights into the model’s behavior,
    helps detect data drift or concept drift, and facilitates the identification of
    performance degradation over time. By proactively monitoring and analyzing key
    metrics, organizations can make informed decisions regarding model maintenance,
    retraining, and updates as required to ensure reliable and up-to-date predictions.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦部署了机器学习模型，持续监控其性能以识别潜在问题、保持准确性和防范意外故障至关重要。监控可以提供关于模型行为的洞察，帮助检测数据漂移或概念漂移，并促进识别随时间推移的性能下降。通过主动监控和分析关键指标，组织可以做出有关模型维护、重新训练和更新的明智决策，以确保可靠的和最新的预测。
- en: 'In this chapter, we will get familiar with the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将熟悉以下主要主题：
- en: Building a model in an on-premises environment using Advanced Analytics Integration
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用高级分析集成在本地环境中构建模型
- en: Monitoring and debugging models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控和调试模型
- en: This chapter focuses on on-premises environments. We will see how to deploy
    and monitor models using Qlik AutoML in our next chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点介绍本地环境。我们将在下一章中看到如何使用Qlik AutoML部署和监控模型。
- en: Building a model in an on-premises environment using the Advanced Analytics
    connection
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用高级分析连接在本地环境中构建模型
- en: In [*Chapter 5*](B19863_05.xhtml#_idTextAnchor071), we prepared an environment
    for R and Python using the Advanced Analytics connection with Qlik. In this chapter,
    we are going to utilize this same environment. This exercise will use R specifically.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第5章*](B19863_05.xhtml#_idTextAnchor071)中，我们使用Qlik的高级分析连接为R和Python准备了一个环境。在本章中，我们将利用这个相同的环境。这个练习将特别使用R。
- en: 'In general, there are two ways to utilize the Advanced Analytics connection
    with Qlik applications. These are the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，有两种方式可以利用Qlik应用程序的高级分析连接。以下是这两种方式：
- en: '**Live connection**: A live connection interacts with the third-party machine
    learning environment from the user interface while the user interacts with the
    application. A live connection enables *what-if* scenarios, simulations, and similar
    use cases. It is best for light models that do not require extensive training.
    The idea behind live connections is explained in the following diagram:'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时连接**：实时连接在用户与应用程序交互的同时与第三方机器学习环境进行交互。实时连接允许进行“如果...将会怎样”的场景、模拟和类似用例。它最适合不需要大量训练的轻量级模型。实时连接背后的理念在以下图中解释：'
- en: '![Figure 7.1: Advanced Analytics connection](img/B19863_05_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图7.1：高级分析连接](img/B19863_05_01.jpg)'
- en: 'Figure 7.1: Advanced Analytics connection'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：高级分析连接
- en: '**Load time connection**: A load time connection is a one-time prediction model
    run that takes place when a Qlik load script is executed. When the Advanced Analytics
    connection is utilized during load time, the results are saved into a table in
    the Qlik data model. These results can be then utilized when creating an application.
    A load time connection is suitable for use cases that only require one predicted
    value. For example, if we are predicting the future value of the sales of a product
    and would like to save the prediction in the data model for later analysis, a
    load time connection is used. It is also good for models that require extensive
    training. It is possible to combine a live connection with a load time connection
    to predict some values when data is loaded and utilize scenario analysis interactively.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加载时连接**：加载时连接是在执行 Qlik 加载脚本时进行的一次性预测模型运行。当在加载时使用高级分析连接时，结果将保存到 Qlik 数据模型中的一个表中。然后，可以在创建应用程序时使用这些结果。加载时连接适用于只需要一个预测值的用例。例如，如果我们正在预测产品未来的销售额并希望将预测保存到数据模型中以供以后分析，则使用加载时连接。它也适用于需要大量训练的模型。可以将实时连接与加载时连接结合使用，在数据加载时预测一些值，并交互式地利用情景分析。'
- en: Note
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'A prepared model can be saved and reused during load time or in live mode.
    This way we can save some time during deployment if the parameters of a model
    haven’t changed and it is known to have performed well previously. To save a model
    in R, for example, we can use the following commands:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好的模型可以在加载时或实时模式下保存和重用。这样，如果模型的参数没有变化并且已知之前表现良好，我们可以在部署过程中节省一些时间。例如，要在 R 中保存一个模型，我们可以使用以下命令：
- en: 'Using the `saveRDS()` and `readRDS()` functions: This method allows you to
    save any R object, including machine learning models, to a file using the `saveRDS()`
    function and reload it using `readRDS()`.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `saveRDS()` 和 `readRDS()` 函数：此方法允许您使用 `saveRDS()` 函数将任何 R 对象（包括机器学习模型）保存到文件中，并使用
    `readRDS()` 函数重新加载它。
- en: 'Using the `save()` and `load()` functions: The `save()` function allows you
    to save multiple R objects, including models, to a file in binary format, which
    can be loaded using the `load()` function.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `save()` 和 `load()` 函数：`save()` 函数允许您将多个 R 对象（包括模型）保存到二进制格式的文件中，可以使用 `load()`
    函数加载这些文件。
- en: 'Using specific package functions: Some machine learning packages in R provide
    their own dedicated functions for saving and loading models. For example, if you’re
    using the `caret` package, you can use the `saveModel()` and `loadModel()` functions.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用特定包的函数：R 中的某些机器学习包提供了用于保存和加载模型的专用函数。例如，如果你正在使用 `caret` 包，你可以使用 `saveModel()`
    和 `loadModel()` 函数。
- en: In the next hands-on example, we will utilize the Advanced Analytics connection
    during load time and create a simple K-means clustering model. To begin with,
    we should have our R environment running and our `Sales Multi Table.xlsx` loaded
    in the Qlik application with the prepared data model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个动手示例中，我们将利用加载时的高级分析连接并创建一个简单的 K-means 聚类模型。首先，我们应该确保我们的 R 环境正在运行，并且 `Sales
    Multi Table.xlsx` 在 Qlik 应用程序中已加载，并带有准备好的数据模型。
- en: In the following example, we would like to create clusters based on product
    categories, sales, and average discounts to examine how different product categories
    will produce sales compared to given discounts. We will also create a slicer to
    control the number of clusters presented.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们希望根据产品类别、销售额和平均折扣创建聚类，以检查不同的产品类别与给定的折扣相比会产生怎样的销售额。我们还将创建一个切片器来控制显示的聚类数量。
- en: 'We will begin by creating a simple layout for our application. We will add
    a scatter plot object, a bar chart, a filter pane, a slicer for variables, and
    two KPI objects to the sheet. It should look like the following screenshot:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先为我们的应用程序创建一个简单的布局。我们将向工作表添加散点图对象、柱状图、筛选面板、变量切片器和两个关键绩效指标（KPI）对象。它应该看起来像以下屏幕截图：
- en: '![Figure 7.2: Layout for clustering example](img/B19863_07_02.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.2：聚类示例布局](img/B19863_07_02.jpg)'
- en: 'Figure 7.2: Layout for clustering example'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2：聚类示例布局
- en: 'To add a slicer for variable input, the dashboard extension bundle needs to
    be installed. Create a variable named `clusters` and set its default value to
    `4`. The settings for the variable and variable input are presented respectively
    in the following screenshots:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加用于变量输入的切片器，需要安装仪表板扩展包。创建一个名为 `clusters` 的变量，并将其默认值设置为 `4`。变量及其输入的设置分别在下述屏幕截图中进行展示：
- en: '![Figure 7.3: Variable settings](img/B19863_07_03.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3：变量设置](img/B19863_07_03.jpg)'
- en: 'Figure 7.3: Variable settings'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：变量设置
- en: '![Figure 7.4: Variable input settings](img/B19863_07_04.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.4：变量输入设置](img/B19863_07_04.jpg)'
- en: 'Figure 7.4: Variable input settings'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4：变量输入设置
- en: 'Next, we configure our scatter plot and start creating our cluster model. Begin
    by adding `ProductName` as a dimension, `sum(Sales)` as the *x*-axis measure,
    and `avg(Discount)` as the *y*-axis measure. This should produce the following
    graph:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们配置我们的散点图并开始创建我们的聚类模型。首先添加 `ProductName` 作为维度，`sum(Sales)` 作为 *x* 轴度量，`avg(Discount)`
    作为 *y* 轴度量。这将产生以下图表：
- en: '![Figure 7.5: Scatter plot with dimensions and measures](img/B19863_07_05.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.5：具有维度和度量的散点图](img/B19863_07_05.jpg)'
- en: 'Figure 7.5: Scatter plot with dimensions and measures'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5：具有维度和度量的散点图
- en: We would like the bubble color to be defined using the cluster model from R.
    Let’s start by selecting **Appearance** � **Colors and legend**. Turn off the
    auto coloring and select **Color** **by expression**.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望使用 R 的聚类模型来定义气泡颜色。让我们先选择 **外观** - **颜色和图例**。关闭自动着色并选择 **按表达式** 颜色。
- en: 'Enter the following formula in the **Expression** field:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **表达式** 字段中输入以下公式：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding code starts with the `R.ScriptEval` function, which tells the
    Qlik engine that the expression should be executed using the Advanced Analytics
    connection. `R` is the connection name and `ScriptEval` is the function used in
    this example. In total, the following expression types are supported by the R
    **server-side** **extension** (**SSE**):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码以 `R.ScriptEval` 函数开始，它告诉 Qlik 引擎表达式应该使用高级分析连接执行。`R` 是连接名称，`ScriptEval`
    是本例中使用的函数。总共，以下表达式类型由 R **服务器端** **扩展** （**SSE**） 支持：
- en: '| **Function Name** | **Function Type** | **Argument Type** | **Return Type**
    |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| **函数名称** | **函数类型** | **参数类型** | **返回类型** |'
- en: '| ScriptEval | Scalar, Tensor | Numeric | Numeric |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| ScriptEval | 标量，张量 | 数值 | 数值 |'
- en: '| ScriptEvalStr | Scalar, Tensor | String | String |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| ScriptEvalStr | 标量，张量 | 字符串 | 字符串 |'
- en: '| ScriptAggr | Aggregation | Numeric | Numeric |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| ScriptAggr | 聚合 | 数值 | 数值 |'
- en: '| ScriptAggrStr | Aggregation | String | String |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| ScriptAggrStr | 聚合 | 字符串 | 字符串 |'
- en: '| ScriptEvalEx | Scalar, Tensor | Numeric or String | Numeric |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| ScriptEvalEx | 标量，张量 | 数值或字符串 | 数值 |'
- en: '| ScriptEvalExStr | Scalar, Tensor | Numeric or String | String |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| ScriptEvalExStr | 标量，张量 | 数值或字符串 | 字符串 |'
- en: '| ScriptAggrEx | Aggregation | Numeric or String | Numeric |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| ScriptAggrEx | 聚合 | 数值或字符串 | 数值 |'
- en: '| ScriptAggrExStr | Aggregation | Numeric or String | String |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| ScriptAggrExStr | 聚合 | 数值或字符串 | 字符串 |'
- en: '| ScriptEvalEx | Scalar, Tensor | Numeric or String | Numeric |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| ScriptEvalEx | 标量，张量 | 数值或字符串 | 数值 |'
- en: 'Table 7.1: Functions supported by the R SSE'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7.1：R SSE 支持的函数
- en: 'After the initial function call, we can write our actual R code. In the preceding
    example, we use the k-means function to calculate the cluster number for each
    of our products. The last two lines are data taken from Qlik and passed to the
    R environment. The Qlik engine creates a dataframe named *q* that contains the
    data sent. In this case, it contains our aggregated sales as `q$sales` and our
    discount as `q$discount`. We are using our previously created variable clusters
    to describe the number of clusters in our code. The following is a step-by-step
    breakdown of the code:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始函数调用之后，我们可以编写实际的 R 代码。在上面的例子中，我们使用 k-means 函数计算每个产品的聚类数。最后两行是从 Qlik 传递到 R
    环境的数据。Qlik 引擎创建了一个名为 *q* 的数据框，其中包含发送的数据。在这种情况下，它包含我们的聚合销售额 `q$sales` 和我们的折扣 `q$discount`。我们使用之前创建的变量聚类来描述代码中的聚类数量。以下是对代码的逐步分解：
- en: '`q$id <- 1:nrow(q)`: This line creates a new column in the `q` dataframe called
    `id` and assigns it values from `1` to the number of rows in `0071`. This column
    is used to preserve the original row order during sorting and clustering.'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`q$id <- 1:nrow(q)`: 这一行在 `q` 数据框中创建了一个名为 `id` 的新列，并给它分配从 `1` 到 `0071` 行数的值。这个列用于在排序和聚类过程中保留原始行顺序。'
- en: '`F2 <- q[order(q$sales, q$discount), ]`: Here, the `q` dataframe is sorted
    in ascending order based on the `sales` column first, and then within each `sales`
    value, it is sorted based on the `discount` column. The sorted data is stored
    in the `F2` dataframe.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`F2 <- q[order(q$sales, q$discount), ]`: 这里，`q` 数据框根据 `sales` 列按升序排序，然后在每个
    `sales` 值内部，根据 `discount` 列排序。排序后的数据存储在 `F2` 数据框中。'
- en: '`F3 <- data.frame(sales = F2$sales, discount = F2$discount)`: This line creates
    a new `F3` dataframe that contains only the `sales` and `discount` columns from
    `F2`. It essentially extracts those two columns for further processing.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`F3 <- data.frame(sales = F2$sales, discount = F2$discount)`: 这行代码创建了一个新的`F3`数据框，其中只包含来自`F2`的`sales`和`discount`列。这实际上是从这两个列中提取数据以进行进一步处理。'
- en: '`rows <- nrow(F2)`: This line calculates the number of rows in the `F2` dataframe
    and assigns it to the `rows` variable.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rows <- nrow(F2)`: 这行代码计算`F2`数据框中的行数，并将其分配给`rows`变量。'
- en: '`if(rows >= clusters) { ... } else { ... }`: This is an if-else statement that
    checks whether the number of rows in `F2` is greater than or equal to the value
    of the `clusters` variable. If it is, clustering is performed; otherwise, a default
    value of `1` is assigned to all rows.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`if(rows >= clusters) { ... } else { ... }`: 这是一个if-else语句，它检查`F2`中的行数是否大于或等于`clusters`变量的值。如果是，则执行聚类；否则，将默认值`1`分配给所有行。'
- en: '`set.seed(5)`: This line sets a seed value for reproducible results in the
    clustering algorithm. The seed value of `5` is used in this case.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`set.seed(5)`: 这行代码为聚类算法的可重复结果设置了一个种子值。在这种情况下，使用的是`5`这个种子值。'
- en: '`clusterdata <- kmeans(F3, clusters, nstart = 20)`: This line applies the k-means
    clustering algorithm to the `F3` dataframe. The `clusters` variable determines
    the number of clusters to be formed, and `nstart = 20` specifies the number of
    times the algorithm will be restarted with different initial cluster assignments.'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`clusterdata <- kmeans(F3, clusters, nstart = 20)`: 这行代码将k-means聚类算法应用于`F3`数据框。`clusters`变量确定要形成的聚类数量，而`nstart
    = 20`指定算法将以不同的初始聚类分配重新启动的次数。'
- en: '`df <- data.frame(rowid = F2$id, data = clusterdata$cluster)`: Here, a new
    `df` dataframe is created with two columns, `rowid` and `data`. The `rowid` column
    contains the original row identifiers from `F2`, and the `data` column contains
    the cluster assignments obtained from the `clusterdata` object.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`df <- data.frame(rowid = F2$id, data = clusterdata$cluster)`: 在这里，创建了一个新的`df`数据框，包含两个列，`rowid`和`data`。`rowid`列包含来自`F2`的原始行标识符，而`data`列包含从`clusterdata`对象获得的聚类分配。'
- en: '`out <- df[order(df$rowid), ]`: This line rearranges the rows of the `df` dataframe
    in the original row order by sorting based on the `rowid` column. The sorted dataframe
    is stored in the `out` variable.'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`out <- df[order(df$rowid), ]`: 这行代码根据`rowid`列对`df`数据框的行进行排序，以原始行顺序重新排列。排序后的数据框存储在`out`变量中。'
- en: '`out$data`: Finally, this line retrieves the `data` column from the `out` dataframe,
    which represents the cluster assignments or the default value of `1` for each
    row.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`out$data`: 最后，这行代码从`out`数据框中检索`data`列，它代表聚类分配或每行的默认值`1`。'
- en: Qlik takes the data field from the `out` dataframe and assigns values to each
    product name. We can then use the cluster number as our color dimension in our
    scatter plot.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Qlik从`out`数据框中获取数据字段，并将值分配给每个产品名称。然后，我们可以使用聚类编号作为我们的散点图中的颜色维度。
- en: 'To get visible results, we should disable the **The expression is a color code**
    setting and select **Diverging classes** as the color scheme. The result with
    five clusters (you can use the slicer to set the variable value to five) should
    look like the following screenshot:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得可见的结果，我们应该禁用**表达式是颜色代码**设置，并选择**发散类别**作为颜色方案。具有五个聚类（您可以使用切片器将变量值设置为五）的结果应类似于以下截图：
- en: '![Figure 7.6: Scatterplot with clusters as color](img/B19863_07_06.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图7.6：以聚类为颜色的散点图](img/B19863_07_06.jpg)'
- en: 'Figure 7.6: Scatterplot with clusters as color'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6：以聚类为颜色的散点图
- en: As you can see, we have five different groups of items that have similar characteristics
    in terms of total sales and the average discount applied. The cluster number can
    be seen if you hover over the single bubble.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们有五组具有相似特征的项目，这些特征包括总销售额和平均折扣。如果将鼠标悬停在单个气泡上，可以看到聚类编号。
- en: Note
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Using master items is always encouraged. In production environments, clusters
    should be created as master items. This way, changes made to the model will be
    inherited by all graphs.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 始终鼓励使用主项。在生产环境中，聚类应作为主项创建。这样，对模型所做的更改将继承到所有图表中。
- en: 'As a final step, we can finish our layout. Insert **sum(Sales)** and **avg(Discount)**
    into KPI objects and take some dimensions into filter pane. Finally, add sales
    by product name into bar chart. You should get a view that looks like the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，我们可以完成我们的布局。将**sum(Sales)**和**avg(Discount)**插入KPI对象中，并将一些维度添加到筛选面板中。最后，将按产品名称划分的销售数据添加到柱状图中。您应该得到一个类似于以下截图的视图：
- en: '![Figure 7.7: Final layout](img/B19863_07_07.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图7.7：最终布局](img/B19863_07_07.jpg)'
- en: 'Figure 7.7: Final layout'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7：最终布局
- en: We have now successfully created our first model using R and Advanced Analytics
    Integration. Next, we will take a closer look at debugging and monitoring. We
    will implement another model with a slightly more advanced use case in [*Chapter
    10*](B19863_10.xhtml#_idTextAnchor124).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经成功使用R和高级分析集成创建了第一个模型。接下来，我们将更详细地查看调试和监控。我们将在[*第10章*](B19863_10.xhtml#_idTextAnchor124)中实现一个具有稍微更高级用例的另一个模型。
- en: Monitoring and debugging models
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控和调试模型
- en: Debugging a model during development is a crucial development step. With Advanced
    Analytics Integration in on-premises environments, we have several options to
    debug our model and figure out how it is performing.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发过程中调试模型是一个关键的开发步骤。在本地环境中，通过高级分析集成，我们有几种选项来调试我们的模型并了解其性能。
- en: 'The first and most logical place to start debugging in an interactive scenario
    is to look at the chart output. If there is something wrong with the code, you
    will get an error message here. In the following example, we can see that a library
    called `forecast` is missing from the environment:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在交互式场景中，开始调试的第一个和最合逻辑的地方是查看图表输出。如果代码有问题，你将在这里得到错误信息。在以下示例中，我们可以看到环境中缺少名为`forecast`的库：
- en: '![Figure 7.8: Error message in chart](img/B19863_07_08.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图7.8：图表中的错误信息](img/B19863_07_08.jpg)'
- en: 'Figure 7.8: Error message in chart'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8：图表中的错误信息
- en: 'Sometimes, you may need more comprehensive information or debug prints from
    the actual R code. Since R is running as a service, there is no easy way to get
    debug prints during execution. You can, however, use file writing. Returning to
    our previous `Rserve` example, adding the following code will produce a file called
    `debug.txt` in our `Rserve` home folder (the added code is shown in **bold**):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，你可能需要从实际的R代码中获得更全面的信息或调试打印。由于R作为服务运行，在执行过程中没有简单的方法来获取调试打印。然而，你可以使用文件写入。回到我们之前的`Rserve`示例，添加以下代码将在我们的`Rserve`主文件夹中生成一个名为`debug.txt`的文件（添加的代码用**粗体**标出）：
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The preceding code will print a summary of the `q` dataframe and a sample of
    it using the `capture.output` function. The result file will look like the following:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将使用`capture.output`函数打印`q`数据框的摘要及其样本：
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can define the file path in the file parameter if so desired. If a path
    is not defined, the file will be written to the `Rserve` home directory. An example
    path is `C:\Program Files\R\R-4.3.0\library\Rserve\libs\x64`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要定义文件路径，可以在文件参数中定义。如果没有定义路径，文件将被写入到`Rserve`的主目录。一个示例路径是`C:\Program Files\R\R-4.3.0\library\Rserve\libs\x64`。
- en: 'If you need to debug the operation of the bridge component, there are log files
    stored in the `/logs` folder under the root directory of the server-side extension.
    Log files are created and stored daily. If there is something wrong with the code
    execution, these log files are a good way to start debugging. You can also monitor
    the returned data and execution times using these log files. The following is
    some sample input written during the execution of our clustering example:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要调试桥接组件的操作，服务器端扩展的根目录下的`/logs`文件夹中存储有日志文件。日志文件是按天创建和存储的。如果代码执行有问题，这些日志文件是开始调试的好方法。你还可以使用这些日志文件监控返回的数据和执行时间。以下是在我们的聚类示例执行期间编写的部分样本输入：
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The preceding log entry first gives us some information about incoming requests
    from the Qlik engine. It details which user is making the call and from what application.
    It also tells us the cardinality of the data. This information is important when
    evaluating performance.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 上述日志条目首先为我们提供了来自Qlik引擎的传入请求的一些信息。它详细说明了哪个用户正在调用以及从哪个应用程序。它还告诉我们数据的基数。当评估性能时，这些信息很重要。
- en: Next, we get information about the function used and the parameters passed from
    Qlik. It will also print the entire code into the log if `DEBUG-level` is enabled.
    Finally, we get information about the total execution time and the rows returned.
    These log entries are a good starting point when evaluating model performance.
    More comprehensive performance metrics can be written into the model code and
    evaluated using the method described previously in this section.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们获取从Qlik传递的函数和参数信息。如果启用了`DEBUG-level`，它还会将整个代码打印到日志中。最后，我们获取关于总执行时间和返回行数的信息。这些日志条目是评估模型性能的好起点。更全面的性能指标可以写入模型代码，并使用本节之前描述的方法进行评估。
- en: Summary
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we took a closer look at model creation and deployment using
    Advanced Analytics Integration and the server-side R extension in an on-premises
    environment (having done the initial environment setup in [*Chapter 5*](B19863_05.xhtml#_idTextAnchor071)).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们更详细地探讨了使用高级分析集成和本地环境中的服务器端R扩展来创建和部署模型。在[*第五章*](B19863_05.xhtml#_idTextAnchor071)中完成了初始环境设置之后。
- en: We started our journey in this chapter by getting familiar with the two concepts
    of utilizing Advanced Analytics Integration. We then took a closer look at an
    on-the-fly data analytics use case and created a k-means clustering example with
    real-time integration with R.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章的开始部分通过熟悉利用高级分析集成的两个概念来开启我们的旅程。然后，我们深入研究了即时数据分析用例，并创建了一个与R实时集成的k-means聚类示例。
- en: We built a simple dashboard to support our analysis and took a deeper look at
    the Advanced Analytics Integration syntax. In the latter part of this chapter,
    we learned how to debug and monitor our models running in on-premises environments.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了一个简单的仪表板来支持我们的分析，并深入研究了高级分析集成的语法。在本章的后半部分，我们学习了如何在本地环境中调试和监控我们的模型。
- en: In the next chapter, we will shift our focus toward Qlik AutoML. We will learn
    the implementation model used with AutoML and how to utilize this tool both in
    Qlik Cloud and on-premises. We will also learn how to deploy and monitor models
    using AutoML.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将我们的重点转向Qlik AutoML。我们将学习与AutoML一起使用的实现模型，以及如何在Qlik Cloud和本地环境中利用这个工具。我们还将学习如何使用AutoML部署和监控模型。
