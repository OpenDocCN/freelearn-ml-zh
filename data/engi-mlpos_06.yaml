- en: 'Chapter 5: Model Evaluation and Packaging'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 章：模型评估和打包
- en: In this chapter, we will learn in detail about ML model evaluation and interpretability
    metrics. This will enable us to have a comprehensive understanding of the performance
    of ML models after training them. We will also learn how to package the models
    and deploy them for further use (such as in production systems). We will study
    in detail how we evaluated and packaged the models in the previous chapter and
    explore new ways of evaluating and explaining the models to ensure a comprehensive
    understanding of the trained models and their potential usability in production
    systems.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将详细了解机器学习模型的评估和可解释性指标。这将使我们能够在训练模型后全面了解其性能。我们还将学习如何打包模型并将它们部署以供进一步使用（例如在生产系统中）。我们将详细研究我们在上一章中如何评估和打包模型，并探索评估和解释模型的新方法，以确保对训练模型及其在生产系统中潜在可用性的全面理解。
- en: 'We begin this chapter by learning various ways of measuring, evaluating, and
    interpreting the model''s performance. We look at multiple ways of testing the
    models for production and packaging ML models for production and inference. An
    in-depth study of the ML models'' evaluation will be carried out as you will be
    presented with a framework to assess any kind of ML model and package it for production.
    Get ready to build a solid foundation in terms of evaluation and get ML models
    ready for production. For this, we are going to cover the following main topics
    in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从学习各种测量、评估和解释模型性能的方法开始本章。我们探讨测试模型以用于生产以及打包机器学习模型以用于生产和推理的多种方式。随着你将获得一个评估任何类型机器学习模型并将其打包用于生产的框架，我们将对机器学习模型的评估进行深入研究。准备好在评估方面打下坚实的基础，并使机器学习模型为生产做好准备。为此，我们将在本章中涵盖以下主要内容：
- en: Model evaluation and interpretability metrics
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型评估和可解释性指标
- en: Production testing methods
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产测试方法
- en: Why package ML models?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么需要打包机器学习模型？
- en: How to package ML models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何打包机器学习模型
- en: Inference ready models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可推理模型
- en: Model evaluation and interpretability metrics
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估和可解释性指标
- en: Acquiring data and training ML models is a good start toward creating business
    value. After training models, it is vital to measure the models' performance and
    understand why and how a model is predicting or performing in a certain way. Hence,
    model evaluation and interpretability are essential parts of the MLOps workflow.
    They enable us to understand and validate the ML models to determine the business
    value they will produce. As there are several types of ML models, there are numerous
    evaluation techniques as well.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 获取数据和训练机器学习模型是创造商业价值的好起点。在训练模型后，衡量模型性能并理解模型为何以及如何以某种方式预测或表现至关重要。因此，模型评估和可解释性是
    MLOps 工作流程中的关键部分。它们使我们能够理解和验证机器学习模型，以确定它们将产生的商业价值。由于存在多种类型的机器学习模型，因此有大量的评估技术。
- en: 'Looking back at [*Chapter 2*](B16572_02_Final_JM_ePub.xhtml#_idTextAnchor028),
    *Characterizing Your Machine Learning Problem*, where we studied various types
    of models categorized as learning models, hybrid models, statistical models, and
    **HITL** (**Human-in-the-loop**) models, we will now discuss different metrics
    to evaluate these models. Here are some of the key model evaluation and interpretability
    techniques as shown in *Figure 5.1*. These have become standard in research and
    industry for evaluating model performance and justifying model performance:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾[*第 2 章*](B16572_02_Final_JM_ePub.xhtml#_idTextAnchor028)，“描述你的机器学习问题”，其中我们研究了被归类为学习模型、混合模型、统计模型和**HITL**（**人机交互**）模型的各种类型的模型，我们现在将讨论评估这些模型的不同指标。以下是*图
    5.1*中显示的一些关键模型评估和可解释性技术。这些已成为研究和工业界评估模型性能和证明模型性能的标准：
- en: '![Figure 5.1 – Model evaluation and interpretation taxonomy'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.1 – 模型评估和解释分类法'
- en: (The techniques in this taxonomy can be applied to almost any business problem
    when carefully navigated, selected, and executed.)](img/B16572_05_01.jpg)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: （当谨慎导航、选择和执行时，此分类法中的技术几乎可以应用于任何商业问题。）](img/B16572_05_01.jpg)
- en: Figure 5.1 – Model evaluation and interpretation taxonomy
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 – 模型评估和解释分类法
- en: (The techniques in this taxonomy can be applied to almost any business problem
    when carefully navigated, selected, and executed.)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: （当谨慎导航、选择和执行时，此分类法中的技术几乎可以应用于任何商业问题。）
- en: Learning models' metrics
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习模型指标
- en: '**Learning models** are of two types – supervised learning (supervised learning
    models or algorithms are trained based on labeled data) and unsupervised learning
    (unsupervised learning models or algorithms can learn from unlabeled data).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习模型**分为两种类型 – 监督学习（监督学习模型或算法基于标记数据进行训练）和无监督学习（无监督学习模型或算法可以从未标记的数据中学习）。'
- en: As we have studied in previous chapters, examples of supervised learning algorithms
    include classification (random forest, support vector machine, and so on) and
    regression (linear regression, logistic regression, and so on) algorithms. On
    the other hand, examples of unsupervised learning include clustering (k-means,
    DBSCAN, Gaussian mixture models, and more) and dimensionality reduction (PCA,
    random forest, forward and backward feature elimination, and so on) algorithms.
    In order to measure these algorithms efficiently, the following are examples of
    some commonly used and efficient metrics.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的章节中所研究的，监督学习算法的例子包括分类（随机森林、支持向量机等）和回归（线性回归、逻辑回归等）算法。另一方面，无监督学习的例子包括聚类（k
    均值、DBSCAN、高斯混合模型等）和降维（PCA、随机森林、前向和后向特征消除等）算法。为了有效地衡量这些算法，以下是一些常用且高效的指标示例。
- en: Supervised learning models
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督学习模型
- en: Supervised learning models train on labeled data. In the training data, the
    outcome of the input is marked or known. Hence, a model is trained to learn to
    predict the outcome when given an input based on the labeled data. After training
    the model, it is important to gauge the model's potential and performance. Here
    are some metrics to gauge supervised models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习模型在标记数据上训练。在训练数据中，输入的结果被标记或已知。因此，模型被训练来学习根据标记数据预测输入的结果。在训练模型后，评估模型潜力和性能是很重要的。以下是一些评估监督模型的指标。
- en: Cross-validation
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 交叉验证
- en: 'Evaluating an ML model is vital to understanding its behaviour and this can
    be tricky. Normally, the dataset is split into two sub-sets: the training and
    the test sets. First, the training set is used to train the model, and then the
    test set is used to test the model. After this, the model''s performance is evaluated
    to determine the error using metrics such as the accuracy percentage of the model
    on test data.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 评估机器学习模型对于理解其行为至关重要，这可能会很棘手。通常，数据集被分成两个子集：训练集和测试集。首先，使用训练集来训练模型，然后使用测试集来测试模型。之后，评估模型的表现以确定错误，可以使用如模型在测试数据上的准确率百分比等指标。
- en: 'This methodology is not reliable and comprehensive because accuracy for one
    test set can be different from another test set. To avoid this problem, cross-validation
    provides a solution by fragmenting or splitting the dataset into folds and ensuring
    that each fold is used as a test set at some point, as shown in *Figure 5.2*:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法并不可靠也不全面，因为一个测试集的准确性可能不同于另一个测试集。为了避免这个问题，交叉验证通过将数据集分割成多个折（片段）并提供解决方案，确保每个折在某个时刻被用作测试集，如图
    *图 5.2* 所示：
- en: '![Figure 5.2 – K-Fold cross-validation'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.2 – K 折交叉验证'
- en: '](img/B16572_05_02.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_05_02.jpg)'
- en: Figure 5.2 – K-Fold cross-validation
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – K 折交叉验证
- en: There are multiple cross-validation methods, including stratified cross-validation,
    leave-one-out cross-validation, and K-fold cross-validation. K-fold cross-validation
    is widely used and is worth noting as this technique involves splitting the dataset
    into k folds/fragments and then using each fold as a test set in successive iterations.
    This process is useful because each iteration has a unique test set on which accuracy
    is measured. Then, the accuracy for each iteration is used to find the average
    test results (calculated by simply taking the average of all test results).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 存在多种交叉验证方法，包括分层交叉验证、留一法交叉验证和 K 折交叉验证。K 折交叉验证被广泛使用，并且值得注意，因为这种技术涉及将数据集分割成 k 折/片段，然后在连续迭代中使用每个折作为测试集。这个过程很有用，因为每个迭代都有一个独特的测试集，用于测量准确性。然后，使用每个迭代的准确性来找到平均测试结果（通过简单地取所有测试结果的平均值来计算）。
- en: Average accuracy acquired by cross-validation is a more reliable and comprehensive
    metric than the conventional accuracy measure. For example, in *Figure 5.2*, we
    can see five iterations. Each of these iterations has a unique test set, and upon
    testing accuracy for each iteration and averaging all accuracies, we get an average
    accuracy for the model using K-fold cross-validation. It is worth noting that
    K-fold is not a good choice if you have a very large training dataset or if the
    model requires a large amount of time, CPU, and/or GPU processing for running.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通过交叉验证获得的平均准确度比传统的准确度度量更可靠和全面。例如，在*图5.2*中，我们可以看到五个迭代。这些迭代中的每一个都有一个独特的测试集，通过测试每个迭代的准确度并平均所有准确度，我们得到使用K折交叉验证的模型平均准确度。值得注意的是，如果你有一个非常大的训练数据集，或者模型需要大量的时间、CPU和/或GPU处理，那么K折可能不是一个好的选择。
- en: Precision
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 精确度
- en: When a classifier is trained, precision can be a vital metric in quantifying
    positive class predictions made by the classifier that are actually true and belong
    to the positive class. Precision quantifies the number of correct positive predictions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个分类器被训练时，精确度可以是一个在量化分类器做出的实际属于正类的正确正类预测中的关键指标。精确度量化了正确预测的正例数量。
- en: For example, let's say we have trained a classifier to predict cats and dogs
    from images. Upon inferring the trained model on the test images, the model is
    used for predicting/detecting dogs from images (in other words, dogs being the
    positive class). Precision, in this case, quantifies the number of correct dog
    predictions (positive predictions).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们训练了一个分类器，用于从图像中预测猫和狗。在将训练好的模型应用于测试图像后，该模型用于从图像中预测/检测狗（换句话说，狗是正类）。在这种情况下，精确度量化了正确预测狗的数量（正类预测）。
- en: Precision is calculated as the ratio of correctly predicted positive examples
    to the total number of predicted positive examples.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度是正确预测的正例数量与预测的正例总数之比。
- en: '*Precision = TruePositives / (TruePositives + FalsePositives)*'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*精确度 = 真正例 / (真正例 + 假正例)*'
- en: '**Precision** focuses on minimizing false positives. High precision ranges
    from 0 to 1, and it relates to a low false positive rate. The higher the precision,
    the better it is; for example, an image classifier model that predicts whether
    a cancer patient requires chemotherapy treatment. If the model predicts that a
    patient should be submitted for chemotherapy when it is not really necessary,
    this can be very harmful as the effects of chemotherapy can be detrimental when
    not required. This case is a dangerous false positive. A high-precision score
    will result in fewer false positives, while having a low-precision score will
    result in a high number of false positives. Hence, regarding the chemotherapy
    treatment the prediction model should have a high-precision score.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确度**专注于最小化误报。精确度范围从0到1，它与低误报率相关。精确度越高，越好；例如，一个预测癌症患者是否需要化疗治疗的图像分类器模型。如果模型预测患者应该接受化疗，而实际上并不需要，这可能会非常有害，因为化疗在不必要的情况下可能会产生有害的副作用。这种情况是一个危险的误报。高精确度得分将导致误报数量减少，而低精确度得分将导致误报数量增加。因此，关于化疗治疗，预测模型应该有一个高精确度得分。'
- en: Recall
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 召回率
- en: When a classifier is trained, recall can be used to quantify the positive class
    predictions established from the total number of positive examples in the dataset.
    Recall measures the number of correct positive predictions made out of the total
    number of positive predictions that could have been made. Recall provides evidence
    of missed positive predictions, unlike precision, which only tells us the correct
    positive predictions out of the total number of positive predictions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个分类器被训练时，召回率可以用来量化从数据集中所有正例总数中建立的正类预测。召回率衡量的是在可能做出的所有正类预测中，正确预测的数量。与仅告诉我们总预测中正确预测数量的精确度不同，召回率提供了遗漏正类预测的证据。
- en: For example, take the same example discussed earlier, where we trained a classifier
    to predict cats and dogs from images. Upon inferring the trained model on the
    test images, the model is used for predicting/detecting dogs from images (in other
    words, dogs being the positive class). Recall, in this case, quantifies the number
    of missed dog predictions (positive predictions).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑之前讨论过的相同例子，我们训练了一个分类器从图像中预测猫和狗。在将训练好的模型应用于测试图像后，该模型用于从图像中预测/检测狗（换句话说，狗是正类）。在这种情况下，召回率量化了遗漏的狗预测数量（正预测）。
- en: In this fashion, recall provides an empirical indication of the coverage of
    the positive class.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式，召回率提供了对正类覆盖率的经验性指示。
- en: '*Recall = TruePositives / (TruePositives + FalseNegatives)*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*召回率 = 真阳性 / (真阳性 + 假阴性)*'
- en: '**Recall** focuses on minimizing false negatives. High recall relates to a
    low false negative rate. The higher the recall, the better it is. For example,
    a model that analyzes the profile data from a passenger in an airport tries to
    predict whether that passenger is a potential terrorist. In this case, it is more
    secure to have false positives than false negatives. If the models predict that
    an innocent person is a terrorist, this could be checked following a more in-depth
    investigation. But if a terrorist passes, a number of lives could be in danger.
    In this case, it is more secure to have false negatives than false positives as
    false negatives can be checked with the help of an in-depth investigation. Recall
    should be high to avoid false negatives. In this case, having a high recall score
    is prioritized over high precision.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**召回率**关注的是最小化假阴性。高召回率与低假阴性率相关。召回率越高，越好。例如，一个分析机场乘客个人资料的模型试图预测该乘客是否是潜在的恐怖分子。在这种情况下，有假阳性比有假阴性更安全。如果模型预测一个无辜的人是恐怖分子，这可以通过更深入的调查来检查。但如果恐怖分子通过了，许多生命可能会处于危险之中。在这种情况下，有假阴性比有假阳性更安全，因为可以通过深入的调查研究来检查假阴性。召回率应该很高，以避免假阴性。在这种情况下，高召回率比高精确率更重要。'
- en: F-score
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: F-score
- en: In a case where we need to avoid both high false positives and high false negatives,
    f-score is a useful measure for reaching this state. F-measure provides a way
    to consolidate both precision and recall into single metrics that reflect both
    properties.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们需要避免高假阳性和高假阴性的情况下，f-score是一个有用的度量，可以帮助我们达到这种状态。F-measure提供了一种将精确度和召回率合并为单一指标的方法，该指标反映了这两个属性。
- en: Neither precision nor recall portrays the whole story.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度和召回率都不能完全描述整个情况。
- en: 'We can have the best precision with terrible recall, or alternatively, F-measure
    expresses both precision and recall. It is measured according to the following
    formula:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以拥有最好的精确度，但召回率却很糟糕，或者换句话说，F-measure同时表达了精确度和召回率。它是根据以下公式来衡量的：
- en: '*F-Measure = (2 * Precision * Recall) / (Precision + Recall)*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*F-Measure = (2 * Precision * Recall) / (Precision + Recall)*'
- en: The harmonic mean of your precision and recall is the F-measure. In most cases,
    you must choose between precision and recall. The harmonic mean rapidly decreases
    if you optimize your classifier to favor one and disfavor the other. When both
    precision and recall are similar, it is at its best; for example, a model that
    predicts cancer early by taking as input a patient's images and blood exams. In
    this real scenario, this could bring a lot of unnecessary costs to a hospital
    and possible harm to a patient's health if the model outputs a high number of
    false positives. On the other hand, if the model fails to detect genuine cancer
    patients, a number of lives would be in danger. In such cases, we need to avoid
    both high false positives and high false negatives and here, the f-score is a
    useful measure for avoiding high false positives and false negatives. F-score
    measures between 0 and 1\. The higher the f-score, the better it is. We can expect
    a smaller number of false positives and false negatives with a high f-score.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度和召回率的调和平均值是F-measure。在大多数情况下，你必须在这两者之间做出选择。如果你优化你的分类器以偏向一方而忽视另一方，调和平均值会迅速下降。当精确度和召回率相似时，它处于最佳状态；例如，一个通过输入患者的图像和血液检查来预测癌症早期的模型。在这个真实场景中，如果模型输出大量假阳性，可能会给医院带来很多不必要的成本，并可能对患者的健康造成伤害。另一方面，如果模型未能检测到真正的癌症患者，许多生命就会处于危险之中。在这种情况下，我们需要避免高假阳性和高假阴性，而在这里，f-score是一个避免高假阳性和假阴性的有用度量。F-score的值在0到1之间。f-score越高，越好。我们可以期待在f-score较高的情况下，假阳性和假阴性的数量会更少。
- en: Confusion matrix
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'The confusion matrix is a metric that reports the performance of classification
    models on a set of test data samples for which prediction values are pre-known.
    It is a metric in matrix form where a confusion matrix is an N X N matrix, and
    N is the number of classes being predicted. For example, let''s say we have two
    classes to predict (binary classification), then N=2, and, as a result, we will
    have a 2 X 2 matrix, like the one shown here in *Figure 5.3*:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵是一个指标，它报告了分类模型在一系列已知预测值的测试数据样本上的性能。它是一个矩阵形式的指标，其中混淆矩阵是一个N X N矩阵，N是预测的类别数量。例如，假设我们有两个类别要预测（二元分类），那么N=2，因此我们将有一个2
    X 2的矩阵，就像这里在*图5.3*中所示：
- en: '![Figure 5.3 – Confusion matrix for binary classification'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.3 – 二元分类的混淆矩阵'
- en: '](img/B16572_05_03.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_05_03.jpg)'
- en: Figure 5.3 – Confusion matrix for binary classification
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – 二元分类的混淆矩阵
- en: '*Figure 5.3* is an example of a confusion matrix for binary classification
    between diabetic and non diabetic patients. There are 181 test data samples on
    which predictions are made to classify patient data samples into diabetic and
    non diabetic categories. Using a confusion matrix, you can get critical insights
    to interpret the model''s performance. For instance, at a glance, you will know
    how many predictions made are actually true and how many are false positives.
    Such insights are invaluable for interpreting the model''s performance in many
    cases. Here are what these terms mean in the context of the confusion matrix:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5.3*是糖尿病和非糖尿病患者之间二元分类混淆矩阵的一个例子。有181个测试数据样本，对这些样本进行了预测，以将患者数据样本分类为糖尿病和非糖尿病类别。使用混淆矩阵，你可以获得对模型性能的深入见解。例如，一眼就能看出有多少预测是真实的，有多少是假阳性。这种见解在许多情况下对解释模型性能非常有价值。以下是在混淆矩阵的上下文中这些术语的含义：'
- en: '**True positives** (**TP**): These are cases predicted to be **yes** and are
    actually **yes** as per test data samples.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阳性**（**TP**）：这些案例预测为**是**，并且根据测试数据样本实际上也是**是**。'
- en: '**True negatives** (**TN**): These are the cases predicted to be **no** and
    these cases are actually **no** as per test data samples.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阴性**（**TN**）：这些案例预测为**无**，并且根据测试数据样本实际上也是**无**。'
- en: '**False positives** (**FP**): The model predicted **yes**, but they are **no**
    as per test data samples. This type of error is known as a **Type I error**.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性**（**FP**）：模型预测**是**，但根据测试数据样本实际上是**否**。这种错误被称为**I型错误**。'
- en: '**False negatives** (**FN**): The model predicted **no**, but they are **yes**
    as per test data samples. This type of error is known as a **Type II error**.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性**（**FN**）：模型预测**否**，但根据测试数据样本实际上是**是**。这种错误被称为**II型错误**。'
- en: 'In *Figure 5.3*, the following applies:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图5.3*中，以下适用：
- en: The *x*-axis represents the predictions made by the ML models.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x*轴代表由机器学习模型做出的预测。'
- en: The *y*-axis represents the actual labels.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y*轴代表实际的标签。'
- en: The first and fourth boxes in the matrix (diagonal boxes) depict the correctly
    predicted images.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵中的第一和第四个方框（对角线方框）描述了正确预测的图像。
- en: The second and third boxes in the matrix represent false predictions.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵中的第二和第三个方框代表假预测。
- en: In the first box, (**Non Diabetic** x **Non Diabetic**), 108 data samples (**True
    negatives** – **TN**) were predicted to be **Non Diabetic** (correct predictions).
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第一个方框中，（**非糖尿病** x **非糖尿病**），108个数据样本（**真阴性** – **TN**）被预测为**非糖尿病**（正确预测）。
- en: In the fourth box, (**Diabetes** x **Diabetes**), 36 data samples (**True positives**
    – **TP**) were predicted correctly.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第四个方框中，（**糖尿病** x **糖尿病**），36个数据样本（**真阳性** – **TP**）被正确预测。
- en: The rest of the images in the second box (**Cats** x **Dogs**) 11 images are
    false positives.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个方框（**猫** x **狗**）中的其余图片，11张是假阳性。
- en: The third box (**Dogs** x **Cats**), which has 26 images, contains false negatives.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个方框（**狗** x **猫**），包含26张图片，包含假阴性。
- en: The confusion matrix can provide a big picture of the predictions made on the
    test data samples and such insights are significant in terms of interpreting the
    performance of the model. The confusion matrix is the *de facto* error analysis
    metric for classification problems, as most other metrics are derived from this
    one.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵可以提供对测试数据样本上做出的预测的整体图景，这种见解在解释模型性能方面具有重要意义。混淆矩阵是分类问题的**事实上的**错误分析指标，因为大多数其他指标都是从这个指标派生出来的。
- en: AUC-ROC
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AUC-ROC
- en: 'A different perspective for observing model performance can enable us to interpret
    model performance and fine-tune it to derive better results. ROC and AUC curves
    can enable such insights. Let''s see how the **Receiver Operating Characteristic**
    (**ROC**) curve can enable us to interpret model performance. The ROC curve is
    a graph exhibiting the performance of a classification model at all classification
    thresholds. The graph uses two parameters to depict the model''s performance:
    **True Positive Rate** (**TPR**=*TP/TP+FN*) and **False Positive Rate** (**FPR**=*FPFP+TN*).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于观察模型性能的不同视角可以使我们能够解释模型性能并微调它以获得更好的结果。ROC和AUC曲线可以提供这样的洞察。让我们看看**受试者工作特征**（**ROC**）曲线如何帮助我们解释模型性能。ROC曲线是一个图表，展示了分类模型在所有分类阈值下的性能。该图表使用两个参数来描述模型性能：**真正例率**（**TPR**=`TP/TP+FN`）和**假正例率**（**FPR**=`FP/FP+TN`）。
- en: 'The following diagram shows a typical ROC curve:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了一个典型的ROC曲线：
- en: '![Figure 5.4 – ROC-AUC curve'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.4 – ROC-AUC曲线](img/B16572_05_04.jpg)'
- en: '](img/B16572_05_04.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图B16572_05_04.jpg](img/B16572_05_04.jpg)'
- en: Figure 5.4 – ROC-AUC curve
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 – ROC-AUC曲线
- en: An ROC curve depicts the TPR versus FPR for different thresholds for classification.
    Lowering the threshold for classification enables more items to be classified
    as positive, which in turn increases both false positives and true positives.
    The **Area Under the Curve** (**AUC**) is a metric used to quantify the effectiveness
    or ability of a classifier to distinguish between classes and is used to summarize
    the ROC curve.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ROC曲线描述了不同分类阈值下的TPR与FPR。降低分类阈值可以使更多项目被分类为阳性，这反过来又增加了假正例和真正例。**曲线下面积**（**AUC**）是一个用于量化分类器区分类别有效性和能力的指标，并用于总结ROC曲线。
- en: The AUC value varies from `0` to `1`, and the classifier is able to correctly
    distinguish between all the positive and negative class points if the AUC value
    is `1`, and the classifier is unable to correctly distinguish between all the
    positive and negative class points if the AUC value is `0`. When the AUC value
    is `0.5` (without manually setting a threshold), then this is a random classifier.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: AUC值从`0`到`1`不等，如果AUC值为`1`，则分类器能够正确地区分所有正类和负类样本点；如果AUC值为`0`，则分类器无法正确地区分所有正类和负类样本点。当AUC值为`0.5`（未手动设置阈值）时，则这是一个随机分类器。
- en: AUC helps us to rank predictions according to their accuracy, but it does not
    give us absolute values. Hence it is scale-independent. Additionally, AUC is independent
    of the classification threshold. The classification threshold chosen does not
    matter when using AUC as AUC estimates the quality of the model's predictions
    irrespective of what classification threshold is chosen.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: AUC帮助我们根据预测的准确性对预测进行排序，但它不提供绝对值。因此，它是无尺度的。此外，AUC与分类阈值无关。选择的分类阈值在使用AUC时并不重要，因为AUC估计模型预测的质量，而不考虑选择的分类阈值。
- en: The Matthew's Correlation Coefficient
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 马修斯相关系数
- en: 'Brian Matthews developed the **Matthews correlation coefficient** (**MCC**)
    in 1975 as a method for model evaluation. It calculates the discrepancies between
    real and expected values. It is an extension of confusion matrix results to measure
    the inefficiency of a classifier. TP, TN, FP, and FN are the four entries in a
    confusion matrix. These entries are factored into the coefficient:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 布莱恩·马修斯于1975年开发了**马修斯相关系数**（**MCC**）作为模型评估的方法。它计算实际值和预期值之间的差异。它是将混淆矩阵结果扩展到衡量分类器无效性的一个方法。TP、TN、FP和FN是混淆矩阵中的四个条目。这些条目被纳入系数中：
- en: '![](img/Formula_01.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![公式_01.jpg](img/Formula_01.jpg)'
- en: 'This measure results in high scores only when a prediction returns good rates
    for all these four categories. The MCC score ranges from `-1` to `+1`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这个度量仅在预测返回所有这四个类别的良好比率时才会产生高分数。MCC得分范围从`-1`到`+1`：
- en: '`1` is the best agreement between actuals and predictions.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1`是实际值和预测值之间最佳的一致性。'
- en: When the score is `0`, this means there is no agreement at all between actuals
    and predictions. The prediction is random with respect to actuals.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当得分为`0`时，这意味着实际值和预测值之间没有任何一致性。预测相对于实际值是随机的。
- en: For example, an MCC score of `0.12` suggests that the classifier is very random.
    If it is `0.93`, this suggests that the classifier is good. MCC is a useful metric
    for helping to measure the ineffectiveness of a classifier.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，MCC得分为`0.12`表明分类器非常随机。如果它是`0.93`，这表明分类器很好。MCC是一个有用的指标，有助于衡量分类器的无效性。
- en: Unsupervised learning models
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无监督学习模型
- en: Unsupervised learning models or algorithms can learn from unlabeled data. Unsupervised
    learning can be used to mine insights and identify patterns from unlabeled data.
    Unsupervised algorithms are widely used for clustering or anomaly detection without
    relying on any labels. Here are some metrics for gauging the performance of unsupervised
    learning algorithms.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习模型或算法可以从未标记的数据中学习。无监督学习可以用于从未标记的数据中挖掘见解和识别模式。无监督算法广泛用于聚类或异常检测，而不依赖于任何标签。以下是评估无监督学习算法性能的一些指标。
- en: The Rand index
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 兰德指数
- en: The Rand index is a metric for evaluating the quality of the clustering technique.
    It depicts the degree of similarity between the clusters. The Rand index measures
    the percentage of correct decisions. Decisions assign a pair of data points (for
    example, documents) to the same cluster.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 兰德指数是评估聚类技术质量的指标。它描述了簇之间的相似度。兰德指数衡量正确决策的百分比。决策将一对数据点（例如，文档）分配到同一个簇。
- en: If `N` data points exist, the total number of *decisions = N(N-1)/2*, which
    denotes the pair of data points involved in the decision.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存在 `N` 个数据点，决策的总数等于 `N(N-1)/2`，这表示参与决策的数据点对。
- en: '*Rand index = TP + TN / TP + FP + FN + TN*'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*兰德指数 = TP + TN / TP + FP + FN + TN*'
- en: Purity
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 纯度
- en: '`1`, and bad clustering has a purity value close to `0`. *Figure 5.5* is a
    visual representation of an example of calculating *purity*, as explained below:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`1`，不良聚类的纯度值接近 `0`。*图 5.5* 是计算 *纯度* 的示例的视觉表示，如下所述：'
- en: '![Figure 5.5 – Clusters after clustering'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.5 – 聚类后的簇'
- en: '](img/B16572_05_05.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_05_05.jpg)'
- en: Figure 5.5 – Clusters after clustering
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 – 聚类后的簇
- en: 'Purity is an external evaluation criterion regarding cluster quality. In *Figure
    5.5*, the majority class and the number of members of the majority class for the
    three clusters are as follows: green drops x 5 (cluster 1), red dots x 5 (cluster
    2), and crosses x 4 (cluster 3). Hence, purity is (1/17) x (5 + 5 + 3) = ~0.76.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 纯度是关于簇质量的外部评估标准。在 *图 5.5* 中，三个簇的多数类及其成员数量如下：绿色滴点 x 5（簇 1），红色点 x 5（簇 2），交叉 x
    4（簇 3）。因此，纯度为 (1/17) x (5 + 5 + 3) = ~0.76。
- en: The Silhouette coefficient
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 轮廓系数
- en: 'For clustering algorithms, determining the quality of clusters is important.
    To determine the quality or goodness of the clusters, the silhouette score, or
    silhouette coefficient, is used as a metric. Its value ranges from `-1` to `1`.
    When clusters are clearly distinguishable or well apart from one another, then
    the silhouette score is `1`. On the contrary, `-1` means clusters are wrongly
    allocated, and `0` means clusters are indifferent from one another. This is how
    the silhouette score is calculated:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 对于聚类算法，确定簇的质量是很重要的。为了确定簇的质量或好坏，使用轮廓分数或轮廓系数作为指标。其值范围从 `-1` 到 `1`。当簇之间明显可区分或彼此远离时，轮廓分数为
    `1`。相反，`-1` 表示簇分配错误，`0` 表示簇彼此之间没有区别。这就是计算轮廓分数的方法：
- en: '*Silhouette Score = (b-a)/max(a,b)*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*轮廓分数 = (b-a)/max(a,b)*'
- en: '`a` = the average distance between each point within a cluster (average intra-cluster
    distance).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`a` = 簇内每个点之间的平均距离（平均簇内距离）。'
- en: '`b` = the average distance between all clusters (average inter-cluster distance).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`b` = 所有簇之间的平均距离（平均簇间距离）。'
- en: Hybrid models' metrics
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混合模型的指标
- en: 'There have been rapid developments in ML by combining conventional methods
    to develop hybrid methods to solve diverse business and research problems. Hybrid
    models include semi-supervised, self-supervised, multi-instance, multi-task, reinforcement,
    ensemble, transfer, and federated learning models. To evaluate and validate these
    models, a range of metrics are used depending on the use case and model type.
    It is good to know these metrics to be able to use the right metrics as per the
    model you will develop and evaluate in the future. Here are the metrics for evaluating
    hybrid models:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合传统方法开发混合方法来解决各种商业和研究问题，机器学习（ML）已经取得了快速发展。混合模型包括半监督、自监督、多实例、多任务、强化、集成、迁移和联邦学习模型。为了评估和验证这些模型，根据用例和模型类型使用一系列指标。了解这些指标对于能够根据您未来将开发和评估的模型使用正确的指标是有好处的。以下是评估混合模型的指标：
- en: Human versus machine test
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人类与机器测试
- en: 'Zeal to reach human-level performance is quite common while training and testing
    ML and deep learning models. In order to validate the models and conclude that
    the models have reached or surpassed human-level performance, human versus machine
    experiments are performed on tasks. The same task is implemented using an ML model
    and the human performance is evaluated against the ML model''s performance. There
    are various metrics for evaluating human versus machine performance according
    to the context and tasks. Some examples are mentioned here:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练和测试机器学习和深度学习模型时，渴望达到人类水平的表现是非常常见的。为了验证模型并得出结论，即模型已达到或超过了人类水平的表现，会在任务上执行人机对比实验。使用机器学习模型实现相同任务，并将人类的表现与机器学习模型的表现进行评估。根据上下文和任务，有各种评估人机表现的指标。以下是一些例子：
- en: '**Bilingual evaluation understudy** (**BLEU**) is a method for assessing the
    quality of text for the task of machine translation from one language to another.
    The quality of text generated by a machine translation algorithm is compared to
    the output of a human. The evaluation is done to observe how close a machine translation
    is to a professional human translation.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**双语评估辅助工具**（**BLEU**）是一种评估机器翻译从一种语言到另一种语言任务文本质量的方法。机器翻译算法生成的文本质量与人类输出进行比较。评估的目的是观察机器翻译与专业人类翻译的接近程度。'
- en: '**Recall-Oriented Understudy for Gisting Evaluation** (**ROUGE**) is a human
    versus machine performance evaluation metric used to evaluate tasks such as automatic
    summarization and machine translation. This metric compares an automatically generated
    summary or translation versus summary/translations produced by humans.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于检索的摘要评估辅助工具**（**ROUGE**）是一种人机性能评估指标，用于评估自动摘要和机器翻译等任务。此指标比较自动生成的摘要或翻译与人类生成的摘要/翻译。'
- en: The Turing test
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 图灵测试
- en: 'The Turing test was engineered by the famous Alan Turing. He referred to it
    as the imitation game in the 1950s. The Turing test is a test of a machine to
    evaluate its ability to exhibit intelligent behavior similar to that of a human.
    In another sense, the Turing test is also a test to evaluate the ability of a
    machine to fool a human into believing a task done by machine is human-like or
    done by a human. For instance, we can see the Turing test in operation in *Figure
    5.6*, where a text-based interaction is happening between the human interrogator,
    X, and a computer or machine subject (Bob), and the interrogator, X, and a human
    subject (Alice):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图灵测试是由著名的艾伦·图灵设计的。他在 1950 年代将其称为模仿游戏。图灵测试是评估机器展现与人类类似智能行为能力的测试。从另一个角度来看，图灵测试也是评估机器欺骗人类，使人类相信机器完成的任务类似于人类或由人类完成的测试。例如，我们可以在
    *图 5.6* 中看到图灵测试的操作，其中人类审问者 X 与计算机或机器受试者（Bob）以及人类受试者（Alice）之间正在进行基于文本的交互：
- en: '![Figure 5.6 – Turing test'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.6 – 图灵测试'
- en: '](img/B16572_05_06.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_05_06.jpg)'
- en: Figure 5.6 – Turing test
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 – 图灵测试
- en: During the Turing test, the human interrogator, X, performs a series of interactions,
    both with Bob (computer) and Alice (human) with an intent to distinguish between
    the human and the machine correctly. The machine passes the Turing test if/when
    the interrogator cannot distinguish them correctly or mistakes the machine for
    a human (Bob for Alice).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在图灵测试中，人类审问者 X 进行一系列交互，包括与 Bob（计算机）和 Alice（人类）的交互，目的是正确地区分人类和机器。如果审问者无法正确区分它们，或者错误地将机器误认为是人类（Bob
    误认为是 Alice），则机器通过图灵测试。
- en: Reward per return
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 每次返回的奖励
- en: Reinforcement learning models are hybrid models that involve continuous learning
    mechanisms between the agent and operating environment in order to achieve pre-defined
    goals. The agent learns based on rewards earned for efficient or optimal steps
    toward reaching a goal. When the goal is optimal control, you will want to measure
    the agent by how well it does at the task. To quantify how well the agent performs
    the task, the aggregate measures of reward, such as total reward per episode (otherwise
    known as "return") or mean reward per time step, can be used to assess and optimize
    control for the agent with respect to the environment and the goals.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习模型是混合模型，涉及代理和操作环境之间的连续学习机制，以实现预定义的目标。代理根据达到目标的有效或最优步骤所获得的奖励进行学习。当目标是最佳控制时，你将希望根据代理在任务中的表现来衡量它。为了量化代理执行任务的好坏，可以使用奖励的聚合度量，如每集的总奖励（也称为“回报”）或每时间步的平均奖励，来评估和优化代理相对于环境和目标的控制。
- en: Regret
  id: totrans-113
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 后悔
- en: Regret is a commonly used metric for hybrid models such as reinforcement learning
    models. At each time step, you calculate the difference between the reward of
    the optimal decision and the decision taken by your algorithm. Cumulative regret
    is then calculated by summing this up. The minimum regret is 0 with the optimal
    policy. The smaller the regret, the better an algorithm has performed.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 后悔是用于强化学习等混合模型的一个常用指标。在每一步，你计算最优决策的奖励与你的算法所采取的决策之间的差异。然后通过累加这些差异来计算累积后悔。最优策略下的最小后悔为0。后悔越小，算法的表现越好。
- en: 'Regret enables the actions of the agent to be assessed with respect to the
    best policy for the optimal performance of the agent as shown in *Figure 5.7*.
    The shaded region in red is the regret:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 后悔使代理的行动能够根据如图5.7所示的代理最佳性能的最佳策略进行评估。红色阴影区域是后悔：
- en: '![Figure 5.7 – Regret for reinforcement learning'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.7 – 强化学习的后悔'
- en: Shapely Additive Explanations (SHAP)](img/B16572_05_07.jpg)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Shapely Additive Explanations (SHAP)](img/B16572_05_07.jpg)
- en: Figure 5.7 – Regret for reinforcement learning
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 – 强化学习的后悔
- en: SHapley Additive exPlanations (SHAP)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: SHapley Additive exPlanations (SHAP)
- en: 'Model interpretability and explaining why the model is making certain decisions
    or predictions can be vital in a number of business problems or industries. Using
    techniques discussed earlier, we can interpret the model''s performance, but there
    are still some gray areas, such as deep learning models, which are black-box models.
    It is noticeable in general that these models can be trained to achieve great
    results or accuracies on test data, but it is hard to say why. In such scenarios,
    **SHapley Additive exPlanations** (**SHAP**) can be useful to decode what is happening
    with the predicted results and which feature predictions correlate to the most.
    SHAP was proposed in this paper (at NIPS): [http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions).'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可解释性和解释模型为何做出某些决策或预测在许多商业问题或行业中至关重要。使用前面讨论的技术，我们可以解释模型的表现，但仍有一些灰色区域，例如深度学习模型，这些是黑盒模型。一般来说，这些模型可以在测试数据上训练以实现很好的结果或准确性，但很难解释原因。在这种情况下，**SHapley
    Additive exPlanations**（SHAP）可以用来解码预测结果中发生的事情以及哪些特征预测与最重要的特征相关。SHAP在本文（NIPS会议）中提出：[http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions)。
- en: 'SHAP works both for classification and regression models. The primary goal
    of SHAP is to explain the model output prediction by computing the contribution
    of each feature. The SHAP explanation method uses Shapley values to explain the
    feature importance for model outputs or predictions. Shapley values are computed
    from cooperative game theory, and these values range from `-1` to `1`. Shapley
    values describe the distribution of model outputs among the features, as shown
    in *Figure 5.8*:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP适用于分类和回归模型。SHAP的主要目标是通过对每个特征的贡献进行计算来解释模型输出预测。SHAP解释方法使用Shapley值来解释模型输出或预测的特征重要性。Shapley值来自合作博弈论，这些值介于`-1`到`1`之间。Shapley值描述了模型输出在特征之间的分布，如图5.8所示：
- en: '![Figure 5.8 – Shapley values bar chart depicting feature importance'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.8 – 描述特征重要性的Shapley值条形图'
- en: '](img/B16572_05_08.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_05_08.jpg)'
- en: Figure 5.8 – Shapley values bar chart depicting feature importance
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 – 描述特征重要性的Shapley值条形图
- en: 'There are several SHAP explainer techniques, such as SHAP Tree Explainer, SHAP
    Deep Explainer, SHAP Linear Explainer, and SHAP Kernel Explainer. Depending on
    the use case, these explainers can provide useful information on model predictions
    and help us to understand black-box models. Read more here: [https://christophm.github.io/interpretable-ml-book/shap.html](https://christophm.github.io/interpretable-ml-book/shap.html)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种 SHAP 解释器技术，例如 SHAP 树解释器、SHAP 深度解释器、SHAP 线性解释器和 SHAP 内核解释器。根据用例，这些解释器可以为模型预测提供有用的信息，帮助我们理解黑盒模型。更多信息请参阅：[https://christophm.github.io/interpretable-ml-book/shap.html](https://christophm.github.io/interpretable-ml-book/shap.html)
- en: MIMIC explainer
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: MIMIC 解释器
- en: Mimic explainer is an approach mimicking black-box models by training an interpretable
    global surrogate model. These trained global surrogate models are interpretable
    models that are trained to approximate the predictions of any black-box model
    as accurately as possible. By using the surrogate model, a black-box model can
    be gauged or interpreted as follows.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Mimic 解释器是一种通过训练一个可解释的全局代理模型来模仿黑盒模型的方法。这些训练好的全局代理模型是可解释模型，旨在尽可能准确地近似任何黑盒模型的预测。通过使用代理模型，可以对黑盒模型进行评估或解释，如下所示。
- en: 'The following steps are implemented to train a surrogate model:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤用于训练代理模型：
- en: To train a surrogate model, start by selecting a dataset, X. This dataset can
    be the same as the one used for training the black-box model or it can be another
    dataset of similar distributions depending on the use case.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要训练一个代理模型，首先选择一个数据集 X。这个数据集可以是用于训练黑盒模型的同一个数据集，也可以是另一个具有相似分布的数据集，具体取决于用例。
- en: Get the predictions of the black-box model for the selected dataset, X.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取所选数据集 X 的黑盒模型预测。
- en: Select an interpretable model type (linear model, decision tree, random forest,
    and so on).
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个可解释模型类型（线性模型、决策树、随机森林等）。
- en: Using the dataset, X, and its predictions, train the interpretable model.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用数据集 X 和其预测结果来训练可解释模型。
- en: Now you have a trained surrogate model. Kudos!
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经训练了一个代理模型。恭喜！
- en: Evaluate how well the surrogate model has reproduced predictions of the black-box
    model, for example, using R-square or F-score.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估代理模型再现黑盒模型预测的能力，例如，使用 R 平方或 F 分数。
- en: Get an understanding of black-box model predictions by interpreting the surrogate
    model.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过解释代理模型来理解黑盒模型的预测。
- en: 'The following interpretable models can be used as surrogate models: **Light
    Gradient boosting model** (**LightGBM**), linear regression, stochastic gradient
    descent, or random forest and decision tree.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下可解释模型可以用作代理模型：**轻梯度提升模型**（**LightGBM**）、线性回归、随机梯度下降或随机森林和决策树。
- en: Surrogate models can enable ML solution developers to gauge and understand the
    black-box model's performance.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 代理模型可以使机器学习解决方案开发者评估和理解黑盒模型的表现。
- en: Permutation feature importance explainer (PFI)
  id: totrans-138
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 置换特征重要性解释器（PFI）
- en: '**Permutation Feature Importance** (**PFI**) is a technique used to explain
    classification and regression models. This technique is useful for interpreting
    and understanding a feature to model output or prediction correlation. PFI is
    an alternative to SHAP. It works by randomly assessing one feature at a time for
    the entire dataset and calculating the change in performance evaluation metrics.
    The change in performance metric is evaluated for each feature; the more significant
    the change, the more important the feature is.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**置换特征重要性**（**PFI**）是一种用于解释分类和回归模型的技术。这项技术对于解释和理解特征与模型输出或预测的相关性非常有用。PFI 是 SHAP
    的替代方案。它通过随机评估整个数据集中的一次特征，并计算性能评估指标的变化来实现。对每个特征的性能指标变化进行评估；变化越显著，该特征就越重要。'
- en: PFI can describe the overall behavior of any model, but does not explain individual
    predictions of the model. PFI is an alternative to SHAP, but is still quite different
    as PFI is based on the decrease in performance of the model, while SHAP is based
    on the magnitude of feature attributions.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: PFI 可以描述任何模型的整体行为，但并不解释模型的单个预测。PFI 是 SHAP 的替代方案，但两者仍有很大不同，因为 PFI 基于模型性能的下降，而
    SHAP 基于特征归因的幅度。
- en: Statistical models' metrics
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统计模型指标
- en: 'As we learned in [*Chapter 2*](B16572_02_Final_JM_ePub.xhtml#_idTextAnchor028),
    *Characterizing Your Machine Learning Problem*, there are three types of statistical
    models: inductive learning, deductive learning, and transduction learning. Statistical
    models offer a good degree of interpretability.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[*第二章*](B16572_02_Final_JM_ePub.xhtml#_idTextAnchor028)“描述你的机器学习问题”中学习到的，存在三种类型的统计模型：归纳学习、演绎学习和转换学习。统计模型提供了良好的可解释性。
- en: Mean
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 均值
- en: 'The mean, or average, is the central value of the dataset. It is calculated
    by summing all the values and dividing the sum by the number of values:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 均值，或平均值，是数据集的中心值。它是通过将所有值相加，然后除以值的数量来计算的：
- en: '*mean = x1 + x2 + x3 +.... + xn / n*'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*均值 = x1 + x2 + x3 + ... + xn / n*'
- en: Standard deviation
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 标准差
- en: The standard deviation measures the dispersion of the values in the dataset.
    The lower the standard deviation, the closer the data points to the mean. A widely
    spread dataset would have a higher standard deviation.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 标准差衡量数据集中值的分散程度。标准差越低，数据点就越接近均值。分布广泛的数据集会有更高的标准差。
- en: Bias
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 偏差
- en: Bias measures the strength (or rigidity) of the mapping function between the
    independent (input) and dependent (output) variables. The stronger the assumptions
    of the model regarding the functional form of the mapping, the greater the bias.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差衡量了映射函数（自变量和因变量之间的映射）的强度（或刚性）。模型对映射函数功能形式的假设越强，偏差就越大。
- en: 'High bias is helpful when the underlying true (but unknown) model has matching
    properties as the assumptions of the mapping function. However, you could get
    completely off-track if the underlying model does not exhibit similar properties
    as the functional form of the mapping. For example, the assumption that there
    is a linear relationship in the variables when in reality it is highly non-linear
    and it would lead to a bad fit:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 当基础的真实（但未知）模型与映射函数的假设具有匹配属性时，高偏差是有帮助的。然而，如果基础模型没有表现出与映射功能形式相似的属性，你可能会完全偏离轨道。例如，当变量之间实际上具有高度非线性关系时，假设变量之间存在线性关系会导致不良拟合：
- en: '**Low bias**: Weak assumptions with regard to the functional form of the mapping
    of inputs to outputs'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低偏差**：对输入到输出映射的功能形式有弱假设'
- en: '**High bias**: Strong assumptions with regard to the functional form of the
    mapping of inputs to outputs'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高偏差**：对输入到输出映射的功能形式有强假设'
- en: 'The bias is always a positive value. Here is an additional resource for learning
    more about bias in ML. This article offers a broader explanation: [https://kourentzes.com/forecasting/2014/12/17/the-bias-coefficient-a-new-metric-for-forecast-bias/](https://kourentzes.com/forecasting/2014/12/17/the-bias-coefficient-a-new-metric-for-forecast-bias/).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差始终是正值。以下是一个关于机器学习偏差的更多学习资源的链接：[https://kourentzes.com/forecasting/2014/12/17/the-bias-coefficient-a-new-metric-for-forecast-bias/](https://kourentzes.com/forecasting/2014/12/17/the-bias-coefficient-a-new-metric-for-forecast-bias/)。
- en: Variance
  id: totrans-154
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 方差
- en: The variance of the model is the degree to which the model's performance changes
    when it is fitted on different training data. The impact of the specifics on the
    model is captured by the variance.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的方差是模型在拟合不同训练数据时的性能变化的程度。模型的具体影响通过方差来捕捉。
- en: A high variance model will change a lot with even small changes in the training
    dataset. On the other hand, a low variance model wouldn't change much even with
    large changes in the training dataset. The variance is always positive.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 高方差模型会对训练数据集的微小变化产生很大变化。另一方面，低方差模型即使在训练数据集发生较大变化时也不会有太大变化。方差始终为正值。
- en: R-squared
  id: totrans-157
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: R-squared
- en: R-squared, also known as the coefficient of determination, measures the variation
    in the dependent variable that can be explained by the model. It is calculated
    as the explained variation divided by the total variation. In simple terms, R-squared
    measures how close the data points are to the fitted regression line.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: R-squared，也称为确定系数，衡量模型可以解释的因变量的变化。它是通过解释变异除以总变异来计算的。简单来说，R-squared衡量数据点与拟合回归线之间的接近程度。
- en: The value of R-squared lies between `0` and `1`. A low R-squared value indicates
    that most of the variation in the response variable is not explained by the model,
    but by other factors not included in it. In general, you should aim for a higher
    R-squared value because this indicates that the model better fits the data.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: R-squared的值介于`0`和`1`之间。R-squared值低表示响应变量的大部分变化不是由模型解释的，而是由未包含在内的其他因素解释的。通常，你应该追求更高的R-squared值，因为这表明模型更好地拟合数据。
- en: RMSE
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: RMSE
- en: The **root mean square error** (**RMSE**) measures the difference between the
    predicted values of the model and the observed (true) values.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**均方根误差**（RMSE）衡量模型预测值与观测（真实）值之间的差异。'
- en: Options are many, and you need to choose the right metric for real-world production
    scenarios to have well-justified evaluations; for example, why a data scientist
    or a data science team might want to select one evaluation metric over another,
    for instance, R-squared over mean for a regression problem. It depends on the
    use case and type of data.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 选项很多，你需要选择正确的指标来对现实世界的生产场景进行有充分理由的评价；例如，为什么数据科学家或数据科学团队可能想要选择一个评估指标而不是另一个，例如，对于回归问题，选择R-squared而不是平均数。这取决于用例和数据类型。
- en: HITL model metrics
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HITL模型指标
- en: There are two types of **HITL** models – human reinforcement learning and active
    learning models. In these models, human-machine collaboration fosters the algorithm
    to mimic human-like behaviors and outcomes. A key driver for these ML solutions
    is the human in the loop. Humans validate, label, and retrain the models to maintain
    the accuracy of the model.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种类型的**HITL**模型——人类强化学习模型和主动学习模型。在这些模型中，人机协作促进算法模仿人类的行为和结果。这些机器学习解决方案的关键驱动因素是人在回路中。人类验证、标记和重新训练模型以保持模型的准确性。
- en: Human bias
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人类偏差
- en: 'Just like the human brain, ML systems are subject to cognitive bias. Human
    cognitive biases are processes that disrupt your decision making and reasoning
    ability, ending up in the production of errors. Human bias occurrences include
    stereotyping, selective perception, the bandwagon effect, priming, affirmation
    predisposition, observational selection bias, and the speculator''s false notion.
    In many cases, it is vital to avoid such biases for ML systems in order to make
    rational and optimal decisions. This will make ML systems more pragmatic than
    humans if we manage to deduce human bias and rectify it. This will be especially
    useful in HITL-based systems. Using bias testing, three types of human biases
    can be identified and worked upon to maintain the ML system''s decision making
    such that it is free from human bias. These three human biases are as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 就像人脑一样，机器学习系统也受到认知偏差的影响。人类的认知偏差是干扰你的决策和推理能力的过程，最终导致错误。人类的偏差包括刻板印象、选择性感知、从众效应、启动效应、确认偏误、观察选择偏差和投机者的错误观念。在许多情况下，为了避免这些偏差对于机器学习系统来说至关重要，以便做出理性和最优的决策。如果我们能够推断出人类的偏差并纠正它，这将使机器学习系统比人类更实用。这将在基于HITL的系统中将特别有用。使用偏差测试，可以识别并解决三种类型的人类偏差，以保持机器学习系统的决策不受人类偏差的影响。以下三种人类偏差如下：
- en: '**Interaction bias**'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**交互偏差**'
- en: When an ML system is fed a dataset containing entries of one particular type,
    an interaction bias is introduced that prevents the algorithm from recognizing
    any other types of entries. This type of bias can be identified in inference testing
    for trained models. Methods such as SHAP and PFI can be useful in identifying
    feature bias.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个机器学习系统被喂入包含特定类型条目的数据集时，会引入一个交互偏差，这阻止算法识别任何其他类型的条目。这种偏差可以在训练模型的推理测试中识别出来。SHAP和PFI等方法在识别特征偏差方面可能很有用。
- en: '**Latent bias**'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '**潜在偏差**'
- en: Latent bias is experienced when multiple examples in the training set have a
    characteristic that stands out. Then, the ones without that characteristic fail
    to be recognized by the algorithm. For example, recently, the Amazon HR algorithm
    for selecting people based on applications for roles within the company showed
    bias against women, the reason being latent bias.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练集中有多个示例具有突出特征时，会体验到潜在偏差。然后，没有这种特征的示例未能被算法识别。例如，最近，亚马逊人力资源算法在根据公司内部角色的申请选择人员时，对女性存在偏见，原因是潜在偏差。
- en: '**Selection bias**'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择偏差**'
- en: Selection bias is introduced to an algorithm when the selection of data for
    analysis is not properly randomized. For example, in designing a high-performance
    face recognition system, it is vital to include all possible types of facial structures
    and shapes and from all ethnic and geographical samples, so as to avoid selection
    bias. Selection bias can be identified by methods such as SHAP or PFI to observe
    model feature bias.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 当分析数据的选择没有适当随机化时，算法中会引入选择偏差。例如，在设计高性能的人脸识别系统时，包括所有可能的面部结构和形状，以及来自所有种族和地理样本的数据至关重要，以避免选择偏差。可以通过SHAP或PFI等方法识别选择偏差，以观察模型特征偏差。
- en: Optimal policy
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最佳策略
- en: In the case of human reinforcement learning, the goal of the system is to maximize
    the rewards of the action in the current state. In order to maximize the rewards
    for actions, optimal policy can be used as a metric to gauge the system. The optimal
    policy is the policy where the action that maximizes the reward/return of the
    current state is chosen. The optimal policy is the metric or state that is ideal
    for a system to perform at its best. In a human reinforcement learning-based system,
    a human operator or teacher sets the optimal policy as the goal of the system
    is to reach human-level performance.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在人类强化学习的情况下，系统的目标是最大化当前状态的动作奖励。为了最大化动作的奖励，可以使用最佳策略作为衡量系统的指标。最佳策略是在当前状态下选择最大化奖励/回报的动作的策略。最佳策略是系统表现最佳的理想指标或状态。在基于人类强化学习的系统中，操作员或教师将最佳策略设置为系统的目标，即达到人类水平的表现。
- en: Rate of automation
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动化率
- en: Automation is the process of automatically producing goods or getting a task
    done through the use of robots or algorithms with no direct human assistance.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化是通过使用机器人或算法自动生产商品或完成任务的过程，无需直接人工辅助。
- en: The level of automation of an ML system can be calculated using the rate of
    automation of the total tasks. It is basically the percentage of tasks fully automated
    by the system, and these tasks do not require any human assistance. It shows what
    percentage of tasks are fully automated out of all the tasks. For example, AlphaGo,
    by DeepMind, has achieved 100% automation to operate on its own to defeat human
    world champion players.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用总任务的自动化率来计算ML系统的自动化程度。这基本上是系统完全自动化的任务百分比，这些任务不需要任何人工辅助。它显示了所有任务中完全自动化的任务百分比。例如，DeepMind的AlphaGo实现了100%的自动化，可以独立运行以击败人类世界冠军选手。
- en: Risk rate
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 风险率
- en: The probability of an ML model performing errors is known as the error rate.
    The error rate is calculated based on the model's performance for production systems.
    The lower the error rate, the better it is for an ML system. The goal of a human
    in the loop is to reduce the error rate and teach the ML model to function at
    its most optimal.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型执行错误的概率称为错误率。错误率是基于模型在生产系统中的性能计算的。错误率越低，对ML系统越好。人在回路的目标是降低错误率，并教会ML模型以最佳状态运行。
- en: Production testing methods
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产测试方法
- en: As there are various businesses in operation, so are different types of production
    systems serving these businesses. In this section, we look into the different
    types of production systems or setups commonly used and how to test them.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 由于运营着各种不同的企业，因此服务于这些企业的生产系统类型也各不相同。在本节中，我们将探讨常用的不同类型的生产系统或配置，以及如何测试它们。
- en: Batch testing
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批量测试
- en: Batch testing validates your model by performing testing in an environment that
    is different from its training environment. Batch testing is carried out on a
    set of samples of data to test model inference using metrics of choice, such as
    accuracy, RMSE, or f1-score. Batch testing can be done in various types of computes,
    for example, in the cloud, or on a remote server or a test server. The model is
    usually served as a serialized file, and the file is loaded as an object and inferred
    on test data.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 批量测试通过在一个与训练环境不同的环境中进行测试来验证您的模型。批量测试是在一组数据样本上进行的，以使用选择的指标（如准确率、RMSE或f1分数）测试模型推理。批量测试可以在各种计算环境中进行，例如在云端、远程服务器或测试服务器上。模型通常以序列化文件的形式提供，文件被加载为对象并在测试数据上进行推理。
- en: A/B testing
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A/B测试
- en: 'You will surely have come across A/B testing. It is often used in service design
    (websites, mobile apps, and so on) and for assessing marketing campaigns. For
    instance, it is used to evaluate whether a specific change in the design or tailoring
    content to a specific audience positively affects business metrics such as user
    engagement, the click-through rate, or the sales rate. A similar technique is
    applied in testing ML models using A/B testing. When models are tested using A/B
    testing, the test will answer important questions such as the following:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 你肯定遇到过 A/B 测试。它常用于服务设计（网站、移动应用等）和评估营销活动。例如，它用于评估特定的设计更改或针对特定受众定制内容是否对业务指标（如用户参与度、点击率或销售率）产生积极影响。类似的技术在
    A/B 测试中测试机器学习模型时也得到应用。当使用 A/B 测试测试模型时，测试将回答以下重要问题：
- en: Does the new model B work better in production than the current model A?
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新模型 B 在生产中是否比当前模型 A 工作得更好？
- en: Which of the two models' nominees work better in production to drive positive
    business metrics?
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个模型候选者中哪一个在产品中工作得更好，可以推动积极的业务指标？
- en: To evaluate the results of A/B testing, statistical techniques are used based
    on the business or operations to determine which model will perform better in
    production. A/B testing is usually conducted in this manner, and real-time or
    live data is fragmented or split into two sets, Set A and Set B. Set A data is
    routed to the old model, and Set B data is routed to the new model. In order to
    evaluate whether the new model (model B) performs better than the old model (model
    A), various statistical techniques can be used to evaluate model performance (for
    example, accuracy, precision, recall, f-score, and RMSE), depending on the business
    use case or operations. Depending on a statistical analysis of model performance
    in correlation to business metrics (a positive change in business metrics), a
    decision is made to replace the new model with the old one or determine which
    model is better.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 A/B 测试的结果，根据业务或操作使用统计技术来确定哪个模型在生产中表现更好。A/B 测试通常以这种方式进行，实时或实时数据被分割成两个集合，集合
    A 和集合 B。集合 A 的数据被路由到旧模型，而集合 B 的数据被路由到新模型。为了评估新模型（模型 B）是否比旧模型（模型 A）表现更好，可以使用各种统计技术来评估模型性能（例如，准确率、精确率、召回率、f
    分数和 RMSE），具体取决于业务用例或操作。根据模型性能与业务指标的相关性统计分析（业务指标的正向变化），做出决定，用旧模型替换新模型或确定哪个模型更好。
- en: A/B testing is performed methodically using statistical hypothesis testing,
    and this hypothesis validates two sides of a coin – the null hypothesis and the
    alternate hypothesis. The null hypothesis asserts that the new model does not
    increase the average value of the monitoring business metrics. The alternate hypothesis
    asserts that the new model improves the average value of the monitoring business
    metrics. Ultimately, A/B testing is used to evaluate whether *the new model drives
    a significant boost in specific business metrics*. There are various types of
    A/B testing, depending on business use cases and operations, for example, `Z-test`,
    `G-test` (I recommend knowing about these and others), and others. Choosing the
    right A/B test and metrics to evaluate can be a win-win for your business and
    ML operations.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: A/B 测试是通过统计假设检验有系统地进行的，这个假设验证了硬币的两面——零假设和备择假设。零假设断言新模型不会增加监控业务指标的平均值。备择假设断言新模型提高了监控业务指标的平均值。最终，A/B
    测试用于评估新模型是否*显著提升了特定的业务指标*。根据业务用例和操作，A/B 测试有多种类型，例如`Z-test`、`G-test`（我建议了解这些以及其他类型），等等。选择正确的
    A/B 测试和评估指标可以为您的业务和机器学习操作带来双赢。
- en: Stage test or shadow test
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阶段性测试或影子测试
- en: Before deploying a model for production, which would then lead to making business
    decisions, it can be valuable to replicate a production-like environment (staging
    environment) to test the model's performance. This is especially important for
    testing the robustness of the model and assessing its performance on real-time
    data. It could be facilitated by deploying the develop branch or a model to be
    tested on a staging server and inferring the same data as the production pipeline.
    The only shortcoming here will be that end users will not see the results of the
    develop branch or business decisions will not be made in the staging server. The
    results of the staging environment will statistically be evaluated using suitable
    metrics (for example, accuracy, precision, recall, f-score, and RMSE) to determine
    the robustness and performance of the model in correlation to business metrics.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在将模型部署到生产环境之前，这将导致做出业务决策，复制类似生产环境（预发布环境）以测试模型的性能可能是有价值的。这对于测试模型的鲁棒性和评估其在实时数据上的性能尤为重要。可以通过在预发布服务器上部署开发分支或待测试模型，并推断与生产流水线相同的数据来实现。唯一的缺点是最终用户将看不到开发分支的结果，或者在预发布服务器上不会做出业务决策。预发布环境的结果将使用合适的指标（例如，准确率、精确率、召回率、F分数和RMSE）进行统计评估，以确定模型与业务指标相关的鲁棒性和性能。
- en: Testing in CI/CD
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CI/CD中的测试
- en: 'Implementing testing as part of CI/CD pipelines can be rewarding in terms of
    automating and evaluating (based on set criteria) the model''s performance. CI/CD
    pipelines can be set up in multiple ways depending on the operations and architecture
    in place, for instance:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 将测试作为CI/CD流水线的一部分实施可以在自动化和评估（基于设定的标准）模型性能方面带来回报。CI/CD流水线可以根据现有的操作和架构以多种方式设置，例如：
- en: Upon a successful run of an ML pipeline, CI/CD pipelines can trigger a new model's
    A/B test in the staging environment.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在成功运行机器学习流水线后，CI/CD流水线可以在预发布环境中触发新模型的A/B测试。
- en: When a new model is trained, it is beneficial to set up a dataset separate from
    the test set to measure its performance against suitable metrics, and this step
    can be fully automated.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当训练新模型时，将数据集与测试集分开以测量其对合适指标的绩效是有益的，并且这一步骤可以完全自动化。
- en: CI/CD pipelines can periodically trigger ML pipelines at a set time in a day
    to train a new model, which uses live or real-time data to train a new model or
    fine-tune an existing model.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CI/CD流水线可以定期在一天中的特定时间触发机器学习流水线，以训练新模型，该模型使用实时或实时数据来训练新模型或微调现有模型。
- en: CI/CD pipelines can monitor the ML model's performance of the deployed model
    in production, and this can be triggered or managed using time-based triggers
    or manual triggers (initiated by team members responsible for quality assurance).
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CI/CD流水线可以监控生产环境中部署的机器学习模型的性能，并且这可以通过基于时间的触发器或手动触发器（由负责质量保证的团队成员发起）来触发或管理。
- en: CI/CD pipelines can provision two or more staging environments to perform A/B
    testing on unique datasets to perform more diverse and comprehensive testing.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CI/CD流水线可以为执行A/B测试在独特的数据集上提供两个或更多预发布环境，以进行更多样化和全面的测试。
- en: These are a variety of scenarios, and depending on requirements, CI/CD pipelines
    offer various workflows and operations tailored to the needs of the business and
    tech requirements. Selecting an efficient architecture and CI/CD process can augment
    tech operations and team performance overall. CI/CD testing can augment and automate
    testing to great lengths.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是各种场景，根据需求，CI/CD流水线提供各种工作流程和操作，以满足业务和技术需求。选择高效的架构和CI/CD流程可以增强技术操作和团队的整体表现。CI/CD测试可以极大地增强和自动化测试。
- en: Why package ML models?
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么需要打包机器学习模型？
- en: MLOps enables a systematic approach to train and evaluate models. After models
    are trained and evaluated, the next steps are to bring them to production. As
    we know, ML doesn't work like traditional software engineering, which is deterministic
    in nature and where a piece of code or module is imported into the existing system
    and it works. Engineering ML solutions is non-deterministic and involves serving
    ML models to make predictions or analyze data.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps使训练和评估模型的方法系统化。在模型训练和评估之后，下一步是将它们部署到生产环境中。众所周知，机器学习（ML）不像传统的软件工程那样是确定性的，在软件工程中，一段代码或模块被导入现有系统并运行。工程化机器学习解决方案是非确定性的，涉及提供机器学习模型进行预测或分析数据。
- en: 'In order to serve the models, they need to be packed into software artifacts
    to be shipped to the testing or production environments. Usually, these software
    artifacts are packaged into a file or a bunch of files or containers. This allows
    the software to be environment- and deployment-agnostic. ML models need to be
    packaged for the following reasons:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供服务，它们需要被打包成软件工件，以便发送到测试或生产环境。通常，这些软件工件被打包成一个文件或一组文件或容器。这使得软件与环境无关，与部署无关。机器学习模型需要打包的原因如下：
- en: Portability
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可移植性
- en: Packaging ML models into software artifacts enables them to be shipped or transported
    from one environment to another. This can be done by shipping a file or bunch
    of files or a container. Either way, we can transport the artifacts and replicate
    the model in various setups. For example, a packaged model can be deployed in
    a virtual machine or serverless setup.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 将机器学习模型打包成软件工件使它们能够从一个环境运输或传输到另一个环境。这可以通过发送一个文件或一组文件或一个容器来完成。无论哪种方式，我们都可以传输工件并在各种设置中复制模型。例如，打包的模型可以部署在虚拟机或无服务器设置中。
- en: Inference
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理
- en: ML inference is a process that involves processing real-time data using ML models
    to calculate an output, for example, a prediction or numerical score. The purpose
    of packaging ML models is to be able to serve the ML models in real time for ML
    inference. Effective ML model packaging (for example, a serialized model or container)
    can facilitate deployment and serve the model to make predictions and analyze
    data in real time or in batches.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习推理是一个涉及使用机器学习模型处理实时数据以计算输出（例如，预测或数值分数）的过程。打包机器学习模型的目的在于能够实时提供服务以进行机器学习推理。有效的机器学习模型打包（例如，序列化模型或容器）可以促进部署，并将模型用于实时或批量预测和分析数据。
- en: Interoperability
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 互操作性
- en: ML model interoperability is the ability of two or more models or components
    to exchange information and to use exchanged information in order to learn or
    fine-tune from each other and perform operations with efficiency. Exchanged information
    can be in the form of data or software artifacts or model parameters. Such information
    enables models to fine-tune, retrain, or adapt to various environments from the
    experience of other software artifacts in order to perform and be efficient. Packaging
    ML models is the foundation for enabling ML model interoperability.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的互操作性是指两个或多个模型或组件交换信息，并使用交换的信息相互学习或微调，以及以高效的方式执行操作的能力。交换的信息可以是数据或软件工件或模型参数。此类信息使模型能够根据其他软件工件的经验进行微调、重新训练或适应各种环境，以执行操作并提高效率。将机器学习模型打包是使机器学习模型互操作性的基础。
- en: Deployment agnosticity
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署无关性
- en: Packaging ML models into software artifacts such as serialized files or containers
    enables the models to be shipped and deployed in various runtime environments,
    such as in a virtual machine, a container serverless environment, a streaming
    service, microservices, or batch services. It opens opportunities for portability
    and deployment agnosticity using the same software artifacts that an ML model
    is packaged in.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 将机器学习模型打包成软件工件，如序列化文件或容器，使模型能够在各种运行时环境中运输和部署，例如在虚拟机、容器化无服务器环境、流服务、微服务或批量服务中。这为使用机器学习模型打包的相同软件工件提供了可移植性和部署无关性的机会。
- en: How to package ML models
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何打包机器学习模型
- en: ML models can be packaged in various ways depending on business and tech requirements
    and as per operations for ML. ML models can be packaged and shipped in three ways,
    as discussed in the following sub-sections.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 根据业务和技术需求以及机器学习的操作，机器学习模型可以以多种方式打包。机器学习模型可以通过以下子节中讨论的三种方式打包和发货。
- en: Serialized files
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 序列化文件
- en: Serialization is a vital process for packaging an ML model as it enables model
    portability, interoperability, and model inference. Serialization is the method
    of converting an object or a data structure (for example, variables, arrays, and
    tuples) into a storable artefact, for example, into a file or a memory buffer
    that can be transported or transmitted (across computer networks). The main purpose
    of serialization is to reconstruct the serialized file into its previous data
    structure (for example, a serialized file into an ML model variable) in a different
    environment. This way, a newly trained ML model can be serialized into a file
    and exported into a new environment where it can de-serialized back into an ML
    model variable or data structure for ML inferencing. A serialized file does not
    save or include any of the previously associated methods or implementation. It
    only saves the data structure as it is in a storable artefact such as a file.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 序列化是打包机器学习模型的一个关键过程，因为它使得模型具有可移植性、互操作性以及模型推理能力。序列化是将对象或数据结构（例如，变量、数组和元组）转换为可存储的工件的方法，例如，转换为文件或内存缓冲区，可以传输或传输（跨计算机网络）。序列化的主要目的是在不同的环境中将序列化的文件重新构建为其之前的数据结构（例如，将序列化文件转换为机器学习模型变量）。这样，一个新训练的机器学习模型可以被序列化到一个文件中，并导出到新的环境中，在那里它可以反序列化为机器学习模型变量或数据结构，用于机器学习推理。序列化文件不保存或包含任何之前关联的方法或实现。它只保存数据结构在可存储的工件（如文件）中的状态。
- en: 'Here are some popular serialization formats in *figure 5.1*:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是*图 5.1*中的一些流行的序列化格式：
- en: '![Table 5.1 – Popular ML model serialization formats'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '![表 5.1 – 流行的机器学习模型序列化格式'
- en: '](img/Table_01.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Table_01.jpg)'
- en: Table 5.1 – Popular ML model serialization formats
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5.1 – 流行的机器学习模型序列化格式
- en: All these serialized formats (except ONNX) have one problem in common, the problem
    of interoperability. To address that, ONNX is developed as an open source project
    supported by Microsoft, Baidu, Amazon, and other big companies. This enables a
    model to be trained using one framework (for example, in scikit-learn) and then
    retrained again using TensorFlow. This has become a game changer for industrialized
    AI as models can be rendered interoperable and framework-independent.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些序列化格式（除了ONNX）都存在一个共同问题，即互操作性问题。为了解决这个问题，ONNX被开发为一个由微软、百度、亚马逊等大公司支持的开源项目。这使得一个模型可以使用一个框架（例如，在scikit-learn中）进行训练，然后再次使用TensorFlow进行重新训练。这对于工业化的AI来说是一个变革性的进步，因为模型可以变得可互操作和框架无关。
- en: ONNX has unlocked new avenues, such as federated learning and transfer learning.
    Serialized models enable portability and also batch inferencing (batch inference,
    or offline inference, is the method of generating predictions on a batch of data
    points or samples) in different environments.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ONNX解锁了新的途径，如联邦学习和迁移学习。序列化模型使得在不同环境中具有可移植性，并支持批量推理（批量推理或离线推理是在一组数据点或样本上生成预测的方法）。
- en: Packetizing or containerizing
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据打包或容器化
- en: We often encounter diverse environments for production systems. Every environment
    possesses different challenges when it comes to deploying ML models, in terms
    of compatibility, robustness, and scalability. These challenges can be avoided
    by standardizing some processes or modules and containers are a great way to standardize
    ML models and software modules.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常遇到各种生产系统的环境。在部署机器学习模型时，每个环境都会面临不同的挑战，包括兼容性、鲁棒性和可扩展性。通过标准化某些流程或模块，可以避免这些挑战，容器化是标准化机器学习模型和软件模块的绝佳方式。
- en: A container is a standard unit of software made up of code and all its dependencies.
    It enables the quick and reliable operation of applications from one computing
    environment to another. It enables the software to be environment- and deployment-agnostic.
    Containers are managed and orchestrated by Docker. Docker has become an industry
    standard at developing and orchestrating containers.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 容器是由代码及其所有依赖项组成的软件标准单元。它使得应用程序能够快速且可靠地在不同的计算环境中运行。它使得软件与环境无关、部署无关。容器由Docker管理和编排。Docker已经成为开发和编排容器的行业标准。
- en: 'Docker is an open source ([https://opensource.com/resources/what-open-source](https://opensource.com/resources/what-open-source))
    tool. It has been developed to make it convenient to build, deploy, and run applications
    by using containers. By using containers, a developer can package an application
    with its components and modules, such as files, libraries, and other dependencies,
    and deploy it as one package. Containers are a reliable way to run applications
    using a Linux OS with customized settings. Docker containers are built using Dockerfiles,
    which are used to containerize an application. After building a Docker image,
    a Docker container is built. A Docker container is an application running with
    custom settings as orchestrated by the developer. *Figure 5.8* shows the process
    of building and running a Docker container from a Dockerfile. A Dockerfile is
    built into a Docker image, which is then run as a Docker container:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: Docker是一个开源([https://opensource.com/resources/what-open-source](https://opensource.com/resources/what-open-source))工具。它被开发出来，使得使用容器构建、部署和运行应用程序变得方便。通过使用容器，开发者可以将应用程序及其组件和模块（如文件、库和其他依赖项）打包成一个包，并部署它。容器是使用具有自定义设置的Linux
    OS运行应用程序的可靠方式。Docker容器是通过Dockerfile构建的，Dockerfile用于容器化应用程序。在构建Docker镜像后，会构建一个Docker容器。Docker容器是一个以开发者编排的方式运行具有自定义设置的应用程序。*图5.8*展示了从Dockerfile构建和运行Docker容器的过程。Dockerfile被构建成一个Docker镜像，然后作为Docker容器运行：
- en: '![Figure 5.9 – Docker artifacts'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.9 – Docker artifacts](Figure 5.9 – Docker artifacts)'
- en: '](img/B16572_05_09.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16572_05_09.jpg](img/B16572_05_09.jpg)'
- en: Figure 5.9 – Docker artifacts
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9 – Docker工件
- en: 'A Dockerfile, Docker image, and a Docker container are foundational components
    for building and running containers. These are each described here:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile、Docker镜像和Docker容器是构建和运行容器的基石组件。这些组件的描述如下：
- en: '**Dockerfile**: A Dockerfile is a text document containing a set of Docker
    commands ordered by the developer to build a Docker image. Docker is able to read
    the Dockerfile and build a Docker image.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dockerfile**：Dockerfile是一个文本文件，其中包含了一组按开发者顺序排列的Docker命令，用于构建Docker镜像。Docker能够读取Dockerfile并构建Docker镜像。'
- en: '**Docker image**: This is a sequential collection of execution parameters to
    use within a collection of root filesystems within a container during runtime.
    Docker images are like a snapshot of containers. Containers are constructed from
    Docker images.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker镜像**：这是在容器运行时在容器内的根文件系统中使用的一系列执行参数的有序集合。Docker镜像就像是容器的快照。容器是由Docker镜像构建的。'
- en: '**Docker container**: Containers are constructed from Docker images. A container
    is a runtime instance of a Docker image.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker容器**：容器是由Docker镜像构建的。容器是Docker镜像的运行时实例。'
- en: ML models can be served in Docker containers for robustness, scalability, and
    deployment agnosticity. In later chapters, we will deploy ML models using Docker
    for the purpose of hands-on experience, hence, it is good to have a general understanding
    of this tool.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型可以在Docker容器中提供服务，以实现健壮性、可扩展性和部署无关性。在后续章节中，我们将使用Docker部署ML模型以获得实践经验，因此，了解这个工具是很重要的。
- en: Microservice generation and deployment
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微服务的生成和部署
- en: Microservices enable the collection of services that are independently deployable.
    Each of these services is highly maintainable, testable, and loosely coupled.
    Microservices are orchestrated by architecture that is organized around business
    capabilities to enable a system to serve business needs. For example, Spotify
    has transitioned from a monolithic complex system to a microservices-based system.
    It was done by splitting the complex system into fragmented services, with specific
    goals such as a search engine, content tagging, content classification, user behavioral
    analytics for a recommendation engine, and autogenerated playlists. Fragmented
    microservices are now developed by a dedicated team. Each microservice is isolated
    and less dependent on one another. This way, it is easier to develop and maintain.
    The company can be consistent with customer service and continuously improve without
    putting the service down.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务使得独立部署的服务集合成为可能。这些服务每个都易于维护、测试和松散耦合。微服务通过围绕业务能力组织的架构进行编排，以使系统能够满足业务需求。例如，Spotify已经从单体复杂系统过渡到基于微服务的系统。这是通过将复杂系统拆分为碎片化服务来实现的，具体目标包括搜索引擎、内容标记、内容分类、推荐引擎的用户行为分析以及自动生成的播放列表。碎片化的微服务现在由专门的团队开发。每个微服务都是隔离的，相互之间依赖较少。这样，开发和维护变得更加容易。公司可以保持客户服务的连贯性，并持续改进，而无需中断服务。
- en: Typically, a microservice is generated by tailoring serialized files into a
    containerized Docker image. These Docker images can then be deployed and orchestrated
    into any Docker - supported environment. Deploying and managing Docker images
    can be performed using container management tools, such as Kubernetes. Docker
    enables extreme portability and interoperability, Docker images can be easily
    deployed to any popular cloud service, such as Google Cloud, Azure, or AWS. Docker
    images can be deployed and managed to any Docker corporate server or data center
    or real-time environment as long as it supports Docker.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，通过将序列化文件定制为容器化的 Docker 镜像来生成微服务。这些 Docker 镜像可以随后部署并编排到任何支持 Docker 的环境中。可以使用容器管理工具，如
    Kubernetes，来部署和管理 Docker 镜像。Docker 实现了极端的可移植性和互操作性，Docker 镜像可以轻松部署到任何流行的云服务，例如
    Google Cloud、Azure 或 AWS。只要支持 Docker，Docker 镜像就可以部署和管理到任何 Docker 企业服务器或数据中心或实时环境中。
- en: 'Microservices can be served in a REST API format, and this is a popular way
    to serve ML models. Some Python frameworks, such as Flask, Django, and FastAPI,
    have become popular in enabling ML models to serve as REST API microservices.
    To facilitate robust and scalable system operations, software developers can sync
    with Dockerized microservices via a REST API. To orchestrate Docker-based microservice
    deployments on Kubernetes-supported infrastructure, Kubeflow is a good option.
    It is cloud-agnostic and can be run on-premises or on local machines. Besides
    that, Kubeflow is based on Kubernetes, but keeps the Kubernetes details and difficulties
    inside a box. Kubeflow is a robust way of serving a model. This is a tool worth
    exploring: [https://www.kubeflow.org/docs/started/kubeflow-overview/](https://www.kubeflow.org/docs/started/kubeflow-overview/).'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务可以以 REST API 格式提供服务，这是提供机器学习模型的一种流行方式。一些 Python 框架，如 Flask、Django 和 FastAPI，已成为使机器学习模型作为
    REST API 微服务提供服务的流行选择。为了促进稳健和可扩展的系统操作，软件开发人员可以通过 REST API 与 Docker 化的微服务同步。为了在
    Kubernetes 支持的基础设施上编排基于 Docker 的微服务部署，Kubeflow 是一个好的选择。它是云无关的，可以在本地或本地机器上运行。除此之外，Kubeflow
    基于 Kubernetes，但将 Kubernetes 的细节和困难封装在一个盒子里。Kubeflow 是提供模型的一种稳健方式。这是一个值得探索的工具：[https://www.kubeflow.org/docs/started/kubeflow-overview/](https://www.kubeflow.org/docs/started/kubeflow-overview/)。
- en: Inference ready models
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备好的推理模型
- en: 'We have previously worked on a business problem to predict the weather at a
    port. To build a solution for this business problem, data processing and ML model
    training were performed, followed by serializing models. Now, in this section,
    we explore how inference is done on the serialized model. This section''s code
    is available from the attached Jupyter notebook in the chapter''s corresponding
    folder in the book''s GitHub repository. Here are the instructions for running
    the code:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前曾针对一个业务问题进行过预测港口天气的工作。为了解决这个业务问题，我们进行了数据处理和机器学习模型训练，然后序列化模型。现在，在本节中，我们将探讨如何在序列化模型上执行推理。本节的代码可在书籍
    GitHub 仓库中对应章节的文件夹中附带的 Jupyter 笔记本中找到。以下是运行代码的说明：
- en: Log in to the Azure portal again.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次登录到 Azure 门户。
- en: From `MLOps_WS` workspace, and then click on the `MLOps_WS` workspace.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `MLOps_WS` 工作区，然后点击 `MLOps_WS` 工作区。
- en: In the **Manage** section, click on the **Compute** section, and then select
    the machine created in [*Chapter 4*](B16572_04_Final_JM_ePub.xhtml#_idTextAnchor074),
    *Machine Learning Pipelines*. Click on the **Start** button to start the instance.
    When the VM is ready, click on the JupyterLab link.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **管理** 部分，点击 **计算** 部分，然后选择在 [*第 4 章*](B16572_04_Final_JM_ePub.xhtml#_idTextAnchor074)
    中创建的机器，*机器学习管道*。点击 **启动** 按钮以启动实例。当虚拟机准备就绪时，点击 JupyterLab 链接。
- en: Now, in JupyterLab, navigate to the chapter's corresponding folder (`05_model_evaluation_packaging`)
    and open the notebook (`model_evaluation_packaging.ipynb`).
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在 JupyterLab 中，导航到章节对应的文件夹（`05_model_evaluation_packaging`）并打开笔记本（`model_evaluation_packaging.ipynb`）。
- en: Connecting to the workspace and importing model artifacts
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接到工作区并导入模型工件
- en: 'First, we import the requisite packages, connect to the ML workspace using
    the `Workspace()` function, and then download the serialized scaler and model
    to perform predictions. `Scaler` will be used to scale input data into the same
    scale of data that was used for model training. The `Model` file is serialized
    in ONNX format. Both the `Scaler` and `Model` files are imported using the `Model()`
    function:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入必要的包，使用`Workspace()`函数连接到ML工作区，然后下载序列化的缩放器和模型以进行预测。`Scaler`将用于将输入数据缩放到与模型训练所使用的数据相同的尺度。`Model`文件以ONNX格式序列化。`Scaler`和`Model`文件都使用`Model()`函数导入：
- en: '[PRE0]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: After running this code, you will see new files downloaded in the left panel
    in the JupyterLab window.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码后，你将在JupyterLab窗口的左侧面板中看到下载的新文件。
- en: Loading model artifacts for inference
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载推理模型工件
- en: 'We open and load the `Scaler` and `Model` files into variables that can be
    used for ML model inference. `Scaler` is read and loaded into a variable using
    pickle, and the ONNX runtime is used to load the ONNX file using `InferenceSession()`
    for making ML model predictions as follows:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`Scaler`和`Model`文件打开并加载到变量中，以便用于ML模型推理。`Scaler`使用pickle读取并加载到变量中，并使用`InferenceSession()`加载ONNX文件，以便进行ML模型预测，如下所示：
- en: '[PRE1]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ML model inference
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ML模型推理
- en: 'To perform ML model inference, scale the test data and set it up for inference
    using the `fit_transform()` method. Now, perform inference on the test data by
    using the ONNX session and run `sess.run()` by passing the input data, `test_data`,
    in `float` `32` format. Lastly, print the results of model inference:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行ML模型推理，使用`fit_transform()`方法缩放测试数据并设置推理。现在，使用ONNX会话对测试数据进行推理，通过传递输入数据`test_data`，以`float`
    `32`格式运行`sess.run()`。最后，打印模型推理的结果：
- en: '[PRE2]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: With these steps, we have successfully downloaded the serialized model, loaded
    it to a variable, and performed inference on a test data sample. The expected
    result of the block code is the value `1`.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些步骤，我们已经成功下载了序列化的模型，将其加载到变量中，并在测试数据样本上进行了推理。代码块预期的结果是值`1`。
- en: Summary
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have explored the various methods to evaluate and interpret
    ML models. We have learned about production testing methods and the importance
    of packaging models, why and how to package models, and the various practicalities
    and tools for packaging models for ML model inference in production. Lastly, to
    understand the workings of packaging and de-packaging serialized models for inference,
    we performed the hands-on implementation of ML model inference using serialized
    models on test data.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了评估和解释ML模型的多种方法。我们学习了生产测试方法以及打包模型的重要性，为什么以及如何打包模型，以及用于生产中ML模型推理的打包模型的实用性和工具。最后，为了理解打包和解包序列化模型以进行推理的工作原理，我们通过在测试数据上使用序列化模型进行了ML模型推理的动手实现。
- en: In the next chapter, we will learn more about deploying your ML models. Fasten
    your seatbelts and get ready to deploy your models to production!
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习更多关于部署您的ML模型的知识。系好安全带，准备好将您的模型部署到生产环境中！
