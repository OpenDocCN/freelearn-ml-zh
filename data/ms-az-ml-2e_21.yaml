- en: '*Chapter 17*: Preparing for a Successful ML Journey'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第17章*：为成功的ML之旅做好准备'
- en: Congratulations, you've made it – what an incredible journey you've been on!
    By now, you should have learned how to preprocess data in the cloud, experiment
    with **ML** models, train deep learning models and recommendation engines on auto-scaling
    clusters, optimize models, and deploy them wherever you want. And you should know
    how to add a cherry to the top of the cake by operationalizing all of these steps
    through **MLOps**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你，你已经成功了——你经历了多么不可思议的旅程！到现在，你应该已经学会了如何在云中预处理数据，实验**ML**模型，在自动扩展集群上训练深度学习模型和推荐引擎，优化模型，并将它们部署到你想要的地方。你应该知道如何通过**MLOps**将这些步骤操作化，为蛋糕增添一抹亮色。
- en: In this last chapter, we will recap some important revelations we learned during
    this journey. It's easy to get lost or overwhelmed by technological and algorithmic
    choices. You could dive deep into modeling, infrastructure, or monitoring without
    getting any closer to having a good predictive model.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一章，我们将回顾我们在这次旅程中学到的一些重要启示。很容易在技术和算法选择中迷失或感到不知所措。你可能会深入研究建模、基础设施或监控，但可能离拥有一个好的预测模型更远。
- en: In the first section, we will remind you that ML is mostly about data. Artificial
    intelligence should probably be called data cleansing and labeling, but of course,
    this doesn't sound as good as AI. You will come to understand that your data is
    key to great performance, so it's what you should care about the most. Your data
    is all that matters!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一部分，我们将提醒你，ML主要关于数据。人工智能可能应该被称为数据清洗和标注，但当然，这听起来没有AI那么好。你会明白你的数据是出色性能的关键，所以你最应该关心的是这个。你的数据就是一切！
- en: In the following section, we will show you how to start your ML projects. We
    will do this by providing you with some guidance and making a point about the
    importance of a clean base infrastructure and thoughtful monitoring.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将向你展示如何开始你的ML项目。我们将通过提供一些指导并强调干净的基础设施和深思熟虑的监控的重要性来实现这一点。
- en: After that, we will reiterate the importance of automation and how new technologies
    will take us further into the world of **machine learning as a service** (**MLaaS**).
    It is always great to understand where technology is heading and in the case of
    ML, it is meta-learning and systems that already automatically suggest fitting
    models and stack them to achieve good predictive performance. And what is left
    when modeling is fully automated? Exactly – your data!
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将重申自动化的重要性以及新技术将如何带我们进一步进入**机器学习即服务**（**MLaaS**）的世界。了解技术的发展方向总是很好的，在机器学习的情况下，它是元学习和系统，它们已经自动建议合适的模型并将它们堆叠起来以实现良好的预测性能。当建模完全自动化时，剩下的是什么？正是——你的数据！
- en: Following that, we will talk about the constant change and evolution of cloud
    services while focusing on PaaS offerings. We will look at why PaaS solutions
    are built and what their foundation is. This will help you understand how best
    to prepare for change and why you are still betting on the right foundation, despite
    ever-changing services.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，我们将讨论云服务的持续变化和演变，同时关注PaaS服务。我们将探讨为什么PaaS解决方案被构建以及它们的基石是什么。这将帮助你了解如何最好地准备应对变化，以及为什么尽管服务不断变化，你仍然在正确的基石上押注。
- en: 'Finally, we will talk about a topic we have mostly ignored throughout this
    book. We will talk about some questions you should think about before starting
    any ML project: Should you do it? Will the results of your model have a grave
    impact on people''s lives? You may have guessed it: we will talk about **ethics**
    in terms of data processing. With a more and more connected world, you shouldn''t
    misuse the personal data of others, you shouldn''t build models that are extremely
    biased toward certain groups of people, and you shouldn''t influence people''s
    lives negatively with your deployed solution.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将讨论在这本书中我们主要忽略的一个主题。我们将讨论在开始任何ML项目之前你应该思考的一些问题：你应该这样做吗？你模型的成果会对人们的生活产生严重影响吗？你可能已经猜到了：我们将从数据处理的角度讨论**伦理**。在一个越来越互联的世界中，你不应该滥用他人的个人信息，你不应该构建对某些群体极端有偏见的模型，你不应该通过你的部署解决方案负面地影响人们的生活。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Remembering the importance of data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记住数据的重要性
- en: Starting with a thoughtful infrastructure
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从一个深思熟虑的基础设施开始
- en: Automating recurrent tasks
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化重复性任务
- en: Expecting constant change
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期持续变化
- en: Thinking about your responsibility
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思考你的责任
- en: Remembering the importance of data
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记住数据的重要性
- en: Many algorithmic problems for predictions and model fitting are hard to model,
    compute, and optimize using classic optimization algorithms or complex heuristics.
    Supervised machine learning provides a powerful new way to solve the most complex
    problems using optimization and a ton of labeled training data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 许多用于预测和模型拟合的算法问题难以使用经典优化算法或复杂启发式方法进行建模、计算和优化。监督式机器学习提供了一种利用优化和大量标记训练数据解决最复杂问题的强大新方法。
- en: Some may think you just should throw a metric ton of data at a model. Imagine
    that you have thousands of pictures of the same bird from every possible angle.
    A trained model based on those pictures would probably not be very predictive
    for classifying different bird families.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人可能认为你只需将大量数据扔给模型。想象一下，你有成千上万张同一只鸟从每个可能角度的照片。基于这些照片训练的模型可能对分类不同的鸟类家族的预测并不具有很高的预测性。
- en: Choosing the Right Data Samples for Your Model
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为你的模型选择合适的数据样本
- en: A trained model will increase in quality when it's using highly distinct data
    samples and data samples that are useful in the context of what your model should
    predict.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型使用高度独特的数据样本和对你模型应预测的上下文有用的数据样本时，其质量会提高。
- en: So, when you're working with ML algorithms, you need to remember that models
    are powered by the training data you provide them with, as well as their training
    labels. Good data is the key to good performance.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当你使用机器学习算法工作时，你需要记住，模型是由你提供给它们的训练数据和训练标签驱动的。好的数据是良好性能的关键。
- en: 'Knowing this, let''s reiterate the key takeaways when it comes to working with
    data and training ML models:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这一点，让我们再次强调在处理数据和训练机器学习模型时的关键要点：
- en: '**Spend most of your time wrangling the data**: As we discussed at the beginning
    of this book, in most ML projects, you''ll spend about 80% of your time on data
    analysis, preprocessing, and feature engineering. Understanding your data inside
    and out is critical to developing a successful predictive model. Think about it
    this way: the only thing that makes you stand out from your competition is your
    data. Most likely, your competitors have access to a similar set of algorithms,
    optimizations, and compute infrastructure that you do. The only thing they don''t
    have is your data and your skill to take apart this data (hopefully). Hence, this
    is where your secret to success lies: in interpreting, cleaning, modeling, and
    preparing your data for high-quality predictions.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大部分时间用于处理数据**：正如我们在本书开头讨论的那样，在大多数机器学习项目中，你将花费大约80%的时间进行数据分析、预处理和特征工程。彻底理解你的数据对于开发成功的预测模型至关重要。这样想：使你与众不同的唯一东西就是你的数据。很可能，你的竞争对手可以访问与你类似的算法、优化和计算基础设施。他们唯一没有的是你的数据和你的技能来分析这些数据（希望如此）。因此，这就是你成功的关键所在：在解释、清理、建模和准备你的数据以进行高质量预测。'
- en: '**Emphasize the engineering of your features**: The biggest opportunity you
    get to increase the predictive baseline performance of any of your models is to
    improve your underlying dataset through better feature engineering or by adding
    more predictive features. Don''t get lost trying to tune and stack the model.
    Rather, spend most of your time and resources on data preprocessing and feature
    engineering. Feature engineering is where you can shine and win the prediction
    game. Are you dealing with dates? Pull in other data sources, such as local and
    global holidays, and nearby events; add relative dates, such as days before a
    holiday, days before a weekend, and so on. Are you dealing with locations, cities,
    or countries? Here, you should pull in demographic data, political data, or geographic
    data. You get the point.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强调特征工程**：你获得的最大机会是提高任何模型的基础预测性能，这可以通过改进你的基础数据集，通过更好的特征工程或添加更多预测性特征来实现。不要迷失在尝试调整和堆叠模型的过程中。相反，你应该把大部分的时间和资源投入到数据预处理和特征工程中。特征工程是你可以发光和赢得预测游戏的地方。你正在处理日期吗？引入其他数据源，例如当地和全球的节假日以及附近的事件；添加相对日期，例如节假日前的天数，周末前的天数等等。你正在处理位置、城市或国家吗？在这里，你应该引入人口统计数据、政治数据或地理数据。你明白这个意思。'
- en: '**Do not get sidetracked with model tuning**: There is only so much that your
    model can do. Yes, you can stack multiple models, tune and optimize them, optimize
    for different metrics, and so on. However, your biggest leverage is your data.
    A good plan for any ML model is to start with a very simple baseline model. Are
    you working with categorical data? If so, choose a gradient-boosted tree ensemble
    and stick with the default parameters. Are you predicting continuous values? If
    so, choose a logistic regression model. Start small and make sure you get your
    data right before you start to fiddle with your model.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不要被模型调优分散注意力**：你的模型能做的事情是有限的。是的，你可以堆叠多个模型，调整和优化它们，针对不同的指标进行优化，等等。然而，你的最大优势是你的数据。任何机器学习模型的好计划都是从一个非常简单的基础模型开始。你是在处理分类数据吗？如果是这样，选择梯度提升树集成，并坚持默认参数。你是在预测连续值吗？如果是这样，选择逻辑回归模型。从小处着手，确保你在开始调整模型之前，你的数据是正确的。'
- en: '**Always start with a baseline model**: Use a baseline model and start to build
    all your automation, infrastructure, and metrics around it. It''s worth noting
    that a baseline model should perform better than a random approach. Once the pipeline
    has finished, you can dive into the data, add new data, perform better feature
    engineering, deploy again, test, and re-iterate. Reducing your model to a primitive
    baseline model is a difficult step, but it will help you succeed in managing your
    priorities during the first phase of the project. Why is the baseline model approach
    so important? Because it sets your mindset for an iterative project, where you
    constantly measure, add data, retrain, and improve your model. Your model will
    require retraining and you need to measure when this is the case. To retrain,
    you will need new training data.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**始终从基础模型开始**：使用基础模型，并围绕它构建所有自动化、基础设施和指标。值得注意的是，基础模型应该比随机方法表现更好。一旦管道完成，你就可以深入数据，添加新数据，进行更好的特征工程，再次部署，测试，并重新迭代。将你的模型简化为原始的基础模型是一个困难的步骤，但它将帮助你成功管理项目第一阶段的工作重点。为什么基础模型方法如此重要？因为它为迭代项目设定了你的心态，在这个项目中，你不断地测量、添加数据、重新训练并改进你的模型。你的模型将需要重新训练，你需要测量何时需要这样做。为了重新训练，你需要新的训练数据。'
- en: '**Continuously collect new, relevant data samples**: In a perfect setup, you
    would install a continuous data collection pipeline that collects new training
    data and training labels directly from your current product. Does your model predict
    search relevance? Collect search queries and the clicked results. Does your model
    predict fraud? Collect new data and the results of manually verified fraud cases.
    Does your model predict hashtags? Track the predictions and let your users change
    them if they''re not accurate. In all these examples, we continuously track relevant
    training data that we can use for constant retraining and fine-tuning. Having
    this constant stream of training data could be the competitive advantage for your
    business that sets you up for success. Hence, when you oversee an ML project,
    think about how you are going to retrain the model in the future.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续收集新的、相关的数据样本**：在一个完美的设置中，你会安装一个持续的数据收集管道，直接从你的当前产品中收集新的训练数据和训练标签。你的模型预测搜索相关性吗？收集搜索查询和点击结果。你的模型预测欺诈吗？收集新的数据和手动验证的欺诈案例的结果。你的模型预测标签吗？跟踪预测，并让用户在它们不准确时更改它们。在这些所有例子中，我们持续跟踪相关的训练数据，我们可以用这些数据不断重新训练和微调。拥有这种持续的训练数据流可能是你业务的竞争优势，让你为成功做好准备。因此，当你监督一个机器学习项目时，考虑你将如何在未来重新训练模型。'
- en: Besides following these technical rules to handle an ML project, it is of utmost
    importance to understand the business side of your company. Such a project typically
    requires an interdisciplinary team of people to succeed. Therefore, it is vital
    to get C-level buy-in for a complete company data strategy. Data is your fuel,
    and it is typically distributed throughout the company in a vast amount of data
    silos, controlled by different departments. As you probably need access to a lot
    of these sources to implement and improve ML models, it is of utmost importance
    to have the authority to access and use that data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 除了遵循这些技术规则来处理机器学习项目外，了解你公司的业务方面至关重要。这样的项目通常需要一个跨学科团队才能成功。因此，获得公司数据策略的C级支持至关重要。数据是你的燃料，它通常以大量数据孤岛的形式分散在公司的各个部门。你可能需要访问大量这些来源来实现和改进机器学习模型，因此，拥有访问和使用这些数据的权限至关重要。
- en: This often requires a mental shift in most companies, as data from different
    departments needs to be combined and analyzed to be used in predictions. Hence,
    data quality matters, data lineage is important so that you can understand where
    it came from, timeliness is important, and correctness is essential. So, make
    sure that data is a first-class citizen in your company that gets the support,
    love, and care it deserves.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常需要大多数公司进行思维上的转变，因为来自不同部门的数据需要结合和分析，以便用于预测。因此，数据质量很重要，数据来源很重要，这样你才能了解它来自哪里，及时性很重要，正确性是必不可少的。所以，确保数据在你的公司中得到应有的支持、关爱和照顾。
- en: Now that we've reiterated these important facts about data processing, let's
    talk about the environment you are working with.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经重申了关于数据处理的重要事实，让我们谈谈你正在工作的环境。
- en: Starting with a thoughtful infrastructure
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从一个深思熟虑的基础设施开始
- en: Successfully applied ML projects depend on an iterative approach to tackle data
    collection, data cleansing, feature engineering, and modeling. After a successful
    deployment and rollout, you should go back to the beginning, keep an eye on your
    metrics, and collect more data. By now, it should be clear that you will repeat
    some of your development and deployment steps in the life cycle of your ML project.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 成功应用的机器学习项目依赖于迭代的方法来处理数据收集、数据清洗、特征工程和建模。在成功部署和推广后，你应该回到起点，关注你的指标，并收集更多数据。现在应该很清楚，你将在机器学习项目的生命周期中重复一些开发和部署步骤。
- en: Getting the infrastructure and environment for your ML project right from the
    beginning will save you a lot of trouble down the road. One key to a successful
    infrastructure is automation and versioning, as we discussed in the previous chapter.
    So, we recommend that you take a few extra days to set up your infrastructure
    and automation and register your datasets, models, and environments from within
    Azure Machine Learning.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从一开始就正确设置你的机器学习项目的基础设施和环境将为你节省很多麻烦。成功基础设施的一个关键在于自动化和版本控制，正如我们在上一章中讨论的那样。因此，我们建议你花几天时间来设置你的基础设施和自动化，并在Azure机器学习中注册你的数据集、模型和环境。
- en: The same can be said for monitoring. To make educated decisions about whether
    your model is working as intended, whether the training data is still accurate,
    or whether the resource utilization is high enough, you need accurate metrics.
    Adding metrics to a project after deployment is quite tricky. Therefore, you should
    be aware of what you want to measure and what you want to be alerted on beforehand.
    Take some extra time at the beginning of your project to think about the metrics
    that you are going to track.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这同样适用于监控。为了做出明智的决定，比如你的模型是否按预期工作，训练数据是否仍然准确，或者资源利用率是否足够高，你需要准确的指标。在部署后添加指标相当棘手。因此，你应该事先了解你想要衡量什么，以及你想要提前被提醒什么。在你的项目开始时，花些额外的时间思考你将要跟踪的指标。
- en: Finally, prioritizing infrastructure while working on the data and models is
    hard. If you can afford the luxury to split these into separate teams for ML infrastructure,
    modeling, and data, then this may not be at the top of your mind. However, this
    is often not the case. To avoid this prioritization issue, we recommend starting
    with a simple baseline model and defining your infrastructure automation based
    on this simple model.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在处理数据和模型的同时优先考虑基础设施是困难的。如果你能承担将它们分成单独的团队进行机器学习基础设施、建模和数据工作的奢侈，那么这可能不是你首要考虑的事情。然而，这种情况通常并不存在。为了避免这种优先级问题，我们建议从简单的基线模型开始，并基于这个简单的模型定义你的基础设施自动化。
- en: 'Let''s look at the steps you should perform when you''re starting your ML project:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当你开始你的机器学习项目时应该执行哪些步骤：
- en: '**Choose a baseline model**: Pick the simplest model with default parameters
    for your use case, a small set of training data, and the most important engineered
    features.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择一个基线模型**：为你的用例选择具有默认参数的最简单模型，一小部分训练数据以及最重要的工程特征。'
- en: '**Build a simple pipeline**: Put all these model training steps into a pipeline
    that builds your model automatically and deploys it into a staging environment.
    The great thing about this approach is that you automatically prioritize infrastructure
    and always output a deployed scoring service. This will set you up for success.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建一个简单的流水线**：将这些模型训练步骤放入一个流水线中，自动构建你的模型并将其部署到预发布环境中。这种方法的优点在于你自动优先考虑基础设施，并且始终输出一个已部署的评分服务。这将为你成功奠定基础。'
- en: '**Dive into the data**: Make sure you understand the data and its quality,
    how to fill in missing values, and how to pre-process features. You can add additional
    data and work on feature engineering to turn your raw input data into interpretable
    data. If you pick a good baseline model, this work should greatly improve the
    performance of the baseline and give your colleagues a scoring service API to
    use with the new service.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**深入数据**：确保你理解数据及其质量，如何填充缺失值，以及如何预处理特征。你可以添加额外的数据，并从事特征工程，将你的原始输入数据转换为可解释的数据。如果你选择了一个好的基线模型，这项工作应该会极大地提高基线模型的性能，并给你的同事提供一个评分服务API，以便与新的服务一起使用。'
- en: '**Experiment with more complex models**: Once you are confident that you have
    built a solid data pipeline, you can tackle modeling, including model selection,
    training, validation, optimization, and stacking. Again, you should be able to
    see incremental improvements that can be measured and continuously deployed to
    any QA environment. Once your performance is good enough, roll out the service
    to your customers and start collecting metrics and more training data.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实验更复杂的模型**：一旦你确信你已经建立了一个稳固的数据管道，你就可以着手建模，包括模型选择、训练、验证、优化和堆叠。再次强调，你应该能够看到可以衡量并持续部署到任何QA环境中的渐进式改进。一旦你的性能足够好，就可以将服务推广给你的客户，并开始收集指标和更多训练数据。'
- en: '**Monitor cloud usage**: When you develop using compute infrastructure in the
    cloud, it is easy to quickly spend a few thousand dollars for a couple of unused
    or underutilized virtual machines. We recommend that you regularly check the number
    of machines and their utilization. If something is not being used anymore, scale
    or shut it down. Remember that the cloud''s number-one benefit is scalable infrastructure.
    So, please take advantage of it.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**监控云使用**：当你使用云中的计算基础设施进行开发时，很容易迅速花费几千美元用于一些未使用或利用率低的虚拟机。我们建议你定期检查机器的数量及其利用率。如果某些东西不再被使用，就进行扩展或关闭。请记住，云的最大好处是可扩展的基础设施。所以，请充分利用它。'
- en: Following this guidance will help you set up a clean and monitored infrastructure
    that you can evolve along the way.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循这些指导原则将帮助你建立一个干净且可监控的基础设施，你可以在这个过程中不断演进。
- en: Now that we've talked about the base infrastructure you should set up, let's
    talk about automation again.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了你应该设置的基础设施，让我们再次谈谈自动化。
- en: Automating recurrent tasks
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化重复性任务
- en: Training an ML model is a complex iterative process that includes data preparation,
    feature engineering, model selection, optimization, and deployment. Above all,
    an enterprise-grade end-to-end ML pipeline needs to be reproducible, interpretable,
    secure, and automated, which poses an additional challenge for most companies
    in terms of know-how, costs, and infrastructure requirements.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 训练机器学习模型是一个复杂且迭代的流程，包括数据准备、特征工程、模型选择、优化和部署。最重要的是，一个企业级的端到端机器学习管道需要是可重复的、可解释的、安全的和自动化的，这对大多数公司来说在知识、成本和基础设施要求方面都提出了额外的挑战。
- en: In the previous chapters, we learned the ins and outs of this process, so we
    can confirm that there is nothing simple or easy about it. Tuning a feature engineering
    approach will affect model training; the missing value strategy during data cleansing
    will influence the optimization process.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们学习了这个过程的方方面面，因此我们可以确认它没有什么是简单或容易的。调整特征工程方法会影响模型训练；数据清洗过程中的缺失值策略将影响优化过程。
- en: 'Above all, the information that''s captured by your model is rarely constant,
    so most ML models require frequent retraining and deployments. This leads to a
    whole new requirement for MLOps: a DevOps pipeline for ML to ensure continuous
    integration and continuous deployment of your data, pipelines, and models.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你的模型所捕获的信息很少是恒定的，因此大多数机器学习模型都需要频繁的重训练和部署。这导致了对MLOps的新要求：一个用于机器学习的DevOps管道，以确保数据的持续集成和持续部署。
- en: Automated ML helps simplify this complex iterative process by automating many
    of these challenges. Instead of manually tuning the input data, then selecting,
    optimizing, and deploying an ML model manually, an automated service just requires
    the input data, as well as a few business-related configurations, such as the
    type of prediction to train.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化机器学习通过自动化许多这些挑战来简化这个复杂且迭代的流程。而不是手动调整输入数据，然后手动选择、优化和部署机器学习模型，自动化服务只需要输入数据，以及一些与业务相关的配置，例如要训练的预测类型。
- en: 'Therefore, using tools such as Azure DevOps and Azure Machine Learning pipelines
    greatly reduces errors and system downtime and frees the user from performing
    a bunch of manual tasks. In addition, services such as Azure Automated Machine
    Learning allows users to optimize ML training and even stack multiple models to
    improve prediction performance. The biggest benefit of this is that the user can
    focus on the most important part of the ML process: understanding, acquiring,
    and cleaning the data.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用Azure DevOps和Azure机器学习管道等工具可以大大减少错误和系统停机时间，并使用户从执行大量手动任务中解放出来。此外，Azure自动机器学习等服务允许用户优化机器学习训练，甚至堆叠多个模型以提高预测性能。最大的好处是用户可以专注于机器学习过程最重要的部分：理解、获取和清理数据。
- en: In many cases, automated ML services will outperform manually trained models
    while requiring significantly less in terms of training and operation costs. The
    reason for this is that many tasks, such as choosing the correct categorical embedding,
    handling imbalanced data, selecting the best model, finding the best parameters,
    and combining multiple models to improve performance, can be systematically optimized
    as opposed to being chosen manually.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，自动机器学习服务将优于手动训练的模型，同时显著降低训练和运营成本。原因在于许多任务，如选择正确的分类嵌入、处理不平衡数据、选择最佳模型、找到最佳参数以及结合多个模型以提高性能，可以系统地优化，而不是手动选择。
- en: Every major cloud provider offers mature services so that you can perform automated
    ML in the cloud and functionalities to deploy these models conveniently. Automated
    ML is a great way to save time and costs while providing your existing employees
    with the tools needed for training complex end-to-end ML pipelines. This makes
    automated ML a real service – MLaaS.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 每个主要的云服务提供商都提供成熟的服务，以便您可以在云中执行自动机器学习，并方便地部署这些模型。自动机器学习是一种节省时间和成本的同时，为现有员工提供训练复杂端到端机器学习管道所需工具的绝佳方式。这使得自动机器学习成为一种真正的服务——机器学习即服务（MLaaS）。
- en: Speaking about tooling, let's talk about the changes you need to keep up with
    when you're working with modern cloud systems.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到工具，让我们谈谈当您使用现代云系统时需要跟上的一些变化。
- en: Expecting constant change
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 期待持续变化
- en: Everything is in a constant state of change. 15 years ago, only a few people
    ever heard about neural networks and machine learning. Today, you have access
    to a vast amount of ML libraries, programs, and cloud services. Every day, new
    progress is made to automate ML tasks and improve ML modeling. Just think about
    the voice assistants you may use and what is happening with self-driving vehicles.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都处于持续变化的状态。15年前，只有少数人听说过神经网络和机器学习。今天，您可以访问大量的机器学习库、程序和云服务。每天，都在取得新的进展，以自动化机器学习任务并改进机器学习建模。只需想想您可能使用的语音助手以及自动驾驶汽车正在发生的事情。
- en: 'Due to this, you are in for a whole bunch of constant changes being made to
    ML libraries and their tooling. This is especially true in a cloud environment,
    where updates can quickly be pushed out to the userbase compared to licensed software.
    As we learned previously, looking at the big cloud providers, their services can
    typically be divided into the following categories:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个原因，您将面临对机器学习库及其工具进行的大量持续变化。这在云环境中尤其如此，与许可软件相比，更新可以快速推送到用户群体。正如我们之前所学的，查看大型云服务提供商，他们的服务通常可以分为以下几类：
- en: '**Infrastructure as a Service** (**IaaS**): IaaS services are all-infrastructure
    abstractions such as virtual machines (compute), disks (storage), and networking.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施即服务**（**IaaS**）：IaaS服务是所有基础设施抽象，如虚拟机（计算）、磁盘（存储）和网络。'
- en: '**Platform as a Service** (**PaaS**): PaaS services are platforms built on
    top of these components with additional functionality that exposes a service while
    hiding the underlying infrastructure and operating system.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平台即服务**（**PaaS**）：PaaS服务是在这些组件之上构建的平台，具有额外的功能，可以暴露服务同时隐藏底层基础设施和操作系统。'
- en: '**Software as a Service** (**SaaS**): SaaS services, in contrast, are exposed
    through a UI and don''t give you any access to the underlying software and hardware
    stack.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**软件即服务**（**SaaS**）：与PaaS服务相反，SaaS服务通过用户界面暴露，不提供对底层软件和硬件堆栈的任何访问。'
- en: Azure Machine Learning is a great example of a PaaS offering as it combines
    different infrastructure services, UIs, and SDKs to give you great new features
    and full access to the underlying services, such as blob storage, training clusters,
    and container registries while putting the operating system out of sight in most
    cases. On your monthly Azure bill, you will see that you spend most of your money
    on infrastructure services when using a PaaS solution.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Azure机器学习是一个很好的PaaS服务的例子，因为它结合了不同的基础设施服务、UI和SDK，为你提供了全新的功能，并提供了对底层服务的完全访问，例如blob存储、训练集群和容器注册表，而在大多数情况下，操作系统则被置于幕后。在你的每月Azure账单上，你会发现当你使用PaaS解决方案时，你大部分的钱都花在了基础设施服务上。
- en: While the underlying infrastructure builds the foundation for all cloud services,
    they are not likely to change drastically over the next few years. New improvements
    will make their way to the market that typically concentrate on throughput levels
    and network security. Still, you shouldn't expect major changes to be made to
    the existing APIs. In addition, these offerings are not likely to be discontinued
    since they are the backbone of many services.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然底层基础设施为所有云服务奠定了基础，但它们在接下来的几年内不太可能发生剧烈变化。新的改进将进入市场，通常集中在吞吐量水平和网络安全上。尽管如此，你不应该期望对现有API进行重大更改。此外，这些服务不太可能被终止，因为它们是许多服务的基石。
- en: The same is not true for PaaS services. They are designed to answer the requests
    of customers regarding an abstracted solution so that they are freed from implementing
    tons of boilerplate code and handling the lower-level infrastructure details of
    a solution. How many times have you seen a feature of Azure Machine Learning and
    thought, *Hey, I could easily implement this on my own*? This is certainly true,
    but you may want someone else to solve this simple thing so that you can concentrate
    on the complex problems you are trying to solve. And that's why PaaS exists in
    the first place.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于PaaS服务来说，情况并非如此。它们被设计用来回答客户关于抽象解决方案的需求，这样他们就可以免于编写大量的样板代码和处理解决方案的低级基础设施细节。你有多少次看到Azure机器学习的一个功能，心想，“嘿，我完全可以自己实现这个功能”？这当然是对的，但你可能希望有人帮你解决这个简单的问题，这样你就可以专注于你试图解决的复杂问题。这就是PaaS最初存在的原因。
- en: However, the downside with customer-driven needs is that those needs and usage
    patterns are constantly evolving. New use cases are cropping up (such as MLOps)
    that ask for new services or extensions to existing services to be supported.
    Hence, you should always expect that PaaS will change over time.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，客户驱动的需求带来的不利之处在于，这些需求和用法模式始终在不断发展。新的用例（如MLOps）不断出现，需要支持新的服务或对现有服务的扩展。因此，你应该始终期待PaaS会随着时间的推移而变化。
- en: If you were to look at the first version of this book, you would find that nearly
    half of the code and features that were shown in that version were either deprecated,
    replaced by something new, or merged with other parts of the Azure Machine Learning
    service. Depending on when you are reading this book, you may have found discrepancies
    between the features or APIs that we are describing here and the current APIs
    and features in Azure.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看这本书的第一版，你会发现其中近一半的代码和功能要么已经弃用，要么被新的东西所取代，或者与Azure机器学习服务的其他部分合并。根据你阅读这本书的时间，你可能已经发现我们在这里描述的功能或API与Azure当前API和功能之间存在差异。
- en: If you were understandably confused and asked yourself how this book could already
    be out of date, we want to assure you that what we are presenting is the right
    technology to bet on. PaaS offerings in general and MLaaS offerings specifically
    undergo massive changes and improvements all the time. Expect change!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感到困惑是可以理解的，并问自己这本书怎么会已经过时了，我们想向你保证，我们展示的是正确的技术，值得下注。PaaS服务总体上，以及MLaaS服务具体来说，总是在经历巨大的变化和改进。期待变化！
- en: 'Let''s look at some possible changes you may encounter over time:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看你可能随着时间的推移会遇到的一些可能的变更：
- en: '**Expect names to change**: This is probably the most common change. Companies
    are notoriously bad at naming products, and Azure and all other cloud providers
    are no exception. This may look like a big change or inconvenience, but it is
    nothing more than changing the name of a service or component or hiding it somewhere
    else in the cloud platform. In the past few years, a lot of changes were made
    to ML regarding Azure. There was a service called **Azure Machine Learning Studio
    (classic)**, which mostly survived as the **Designer** in Azure Machine Learning.
    There were – and still are – services called **Azure Batch**, **Azure BatchAI**,
    and **AML Compute**, which offered mostly the same functionality as the compute
    cluster for batch inference you will now find in Azure Machine Learning. Simply
    put, do not let yourself get distracted by this. Expect some interesting new names
    to pop up for the functionality that you know and love.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预期名称会发生变化**：这可能是最常见的变更。公司通常在命名产品方面做得不好，Azure和其他所有云服务提供商也不例外。这可能看起来像是一个很大的变化或不便，但实际上只是更改服务或组件的名称，或者将其隐藏在云平台的其他地方。在过去的几年里，针对Azure的机器学习（ML）进行了许多变更。曾经有一个名为**Azure
    Machine Learning Studio (classic)**的服务，它主要作为Azure机器学习中的**Designer**存在。曾经有，现在仍然有名为**Azure
    Batch**、**Azure BatchAI**和**AML Compute**的服务，它们提供了与您现在在Azure机器学习中找到的批推理计算集群大致相同的功能。简单来说，不要让自己被这些变化分散注意力。预期会出现一些有趣的新名称，用于您所熟悉和喜爱的功能。'
- en: '**Expect the UIs to change**: This is the most visible change and is quite
    common in cloud offerings of late. Many services get revamped UIs, some get integrated
    into the Azure UI, and some get placed in a separate application. Expect some
    functionality to be exposed only in one UI and not another. Most often, however,
    a new UI means that just the same or similar functionality is accessible through
    a new interface. This is one of the reasons why we trained you to work so much
    with the Python API or the Azure CLI instead of the graphical interface.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预期UI会发生变化**：这是最明显的变化，在最近的云服务中相当常见。许多服务都得到了全新的UI，一些被整合到Azure UI中，还有一些被放置在单独的应用程序中。预期某些功能可能只在一个UI中暴露，而在另一个UI中则不暴露。然而，通常情况下，新的UI意味着相同或类似的功能可以通过新的界面访问。这也是我们为什么训练你更多地使用Python
    API或Azure CLI而不是图形界面工作的原因之一。'
- en: '**Expect classes and packages to change in the SDKs**: Most APIs of most cloud
    providers for ML solutions are constantly evolving. Azure has invested a lot of
    money in its ML service, so change is inevitable. A good way to prepare for this
    change is to abstract code into specific implementations that can be swapped out
    easily with new functionality. Another good practice is to be cautious with library
    updates, but also don''t stay behind the most recent version for too long.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预期SDK中的类和包会发生变化**：大多数云服务提供商的机器学习解决方案的API都在不断演变。Azure在它的机器学习服务上投入了大量的资金，因此变化是不可避免的。为应对这种变化，一个很好的做法是将代码抽象成特定的实现，这样就可以轻松地用新功能替换。另一个好的做法是对库更新保持谨慎，但也不要落后于最新版本太久。'
- en: Do you agree that change is the only constant, given all these circumstances?
    Just keep in mind that all PaaS solutions are ultimately built on an underlying
    infrastructure, which provides a rock-solid foundation for your computing, storage,
    and networking.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否同意，在这些情况下，变化是唯一的不变因素？请记住，所有PaaS解决方案最终都是建立在底层基础设施之上的，这为你的计算、存储和网络提供了坚实的基础。
- en: 'So, remember: despite the constant change, you are building on the right foundation!'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，请记住：尽管变化不断，你是在正确的基石上构建！
- en: 'Having talked about most of the things you should consider while using a cloud
    platform for ML, let''s talk about something far more important: data ethics.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论了在使用云平台进行机器学习时应考虑的大部分内容之后，让我们谈谈一个更加重要的话题：数据伦理。
- en: Thinking about your responsibility
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考虑到你的责任
- en: 'In this final section of this book, we want to take a step back from models,
    deployments, and optimization to talk about a much more important topic: ethics
    when it comes to handling data or what is today known as **responsible AI/ML**.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的最后一节，我们想要从模型、部署和优化中退一步，来谈谈一个更加重要的主题：处理数据时的伦理，或者今天所知的**负责任的AI/ML**。
- en: In [*Chapter 1*](B17928_01_ePub.xhtml#_idTextAnchor015), *Understanding the
    End-to-End Machine Learning Process*, we talked about **bias** in data, how it
    can be introduced willingly or unwillingly into a dataset, and what you have to
    look out for. This is but one small piece of the puzzle to reflect how you are
    gathering data and how your trained model can negatively influence other people's
    lives.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第一章*](B17928_01_ePub.xhtml#_idTextAnchor015)《理解端到端机器学习过程》中，我们讨论了数据中的**偏差**，它如何有意或无意地被引入数据集中，以及你需要注意什么。这只是反映你如何收集数据以及你的训练模型如何对他人生活产生负面影响的一个小小拼图。
- en: Imagine that you are training an ML model to suggest to a bank teller that the
    customer in front of him is allowed to receive a loan and what kind of interest
    rate the customer is allowed to have on that loan. Using an automated system to
    make this decision can be a blessing or a curse. If there is an inherent bias
    in most of the bank tellers of a company and you build a fair model, then this
    will probably be a blessing. However, if your model is based on the previous decisions
    of those bank tellers, you must be on the lookout for a lot of bias in your data.
    If not, you may create an even more unfair world because now, your ML system is
    in charge. A fair teller giving out the loan, even though they may understand
    that there is a bias in your ML system, is now probably not allowed to overrule
    it.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你正在训练一个机器学习模型，建议银行柜员允许面前的客户获得贷款，以及客户可以获得的贷款利率。使用自动化系统做出这个决定可能是一种祝福或诅咒。如果公司的大多数银行柜员存在固有的偏差，而你构建了一个公平的模型，那么这可能会是一种祝福。然而，如果你的模型基于那些银行柜员的先前决策，你必须密切关注你的数据中的大量偏差。如果不这样做，你可能会创造一个更加不公平的世界，因为现在，你的机器学习系统负责。一个公平的柜员发放贷款，即使他们可能了解你的机器学习系统中存在偏差，现在可能也不允许他们推翻它。
- en: There are far worse examples than this one, but this should give you a good
    idea of what we want to talk about.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有比这更糟糕的例子，但这应该能给你一个很好的概念，了解我们想要讨论的内容。
- en: 'Generally speaking, we can group the responsibilities you have into the following
    categories:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，我们可以将你的责任分为以下几类：
- en: '**Interpretability**: How well can you explain your model and the results it
    generates?'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性**：你如何解释你的模型及其生成的结果？'
- en: '**Fairness**: How well can you ensure fairness by eliminating bias in the data?'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公平性**：你如何通过消除数据中的偏差来确保公平性？'
- en: '**Privacy**: How well are the **personally identifiable information** (**PII**)
    of individuals being safeguarded in your underlying data and model? Who has access
    to it?'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐私**：在你的基础数据和模型中，个人的**可识别信息**（**PII**）得到了多好的保护？谁可以访问它？'
- en: '**Compliance**: How well documented is everything you work with and have access
    to? How do you track who is using your data or model?'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合规性**：你所使用和可以访问的每一件事物都有多好的文档记录？你是如何追踪谁在使用你的数据或模型的？'
- en: Let's have a more detailed look at what you have to watch out for and what tooling
    is offered through Azure Machine Learning to accommodate you while you're doing
    this.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看你需要注意的事项，以及Azure机器学习提供的哪些工具可以帮助你在进行这项工作时得到支持。
- en: Interpreting a model
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解释模型
- en: Any deployed ML model is a black box. We send input and receive output in the
    form of a prediction or classification through the model. Therefore, it is hard
    for stakeholders to understand why and why not a system makes certain decisions.
    To alleviate this situation, you can apply new tooling to explain your model.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 任何部署的机器学习模型都是一个黑盒。我们通过模型发送输入并接收以预测或分类形式呈现的输出。因此，利益相关者很难理解为什么系统会做出某些决策以及为什么不会。为了缓解这种情况，你可以应用新的工具来解释你的模型。
- en: 'But before we talk about tooling and approaches to explain an ML model, let''s
    group models into two categories:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们讨论解释机器学习模型的工具和方法之前，让我们将模型分为两类：
- en: '**Black-box models**: Models where the calculations are so complex that we
    do not know how the decision came to be.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黑盒模型**：计算如此复杂，以至于我们不知道决策是如何形成的。'
- en: '**Glass-box models**: Models where the result can be relatively easily explained
    and calculated. Think about linear regression models, for example.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**玻璃箱模型**：结果可以相对容易地解释和计算的模型。例如，考虑线性回归模型。'
- en: Glass-box models tend to be simpler, so the trade-off seems to be between explainability
    and complexity (and therefore, possibly accuracy). But if your model handles a
    whole bunch of personal information, you will want to know how the model comes
    to its conclusion.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 玻璃盒模型通常更简单，所以权衡似乎是在可解释性和复杂性（因此，可能是准确性）之间。但如果您的模型处理大量个人信息，您将想知道模型是如何得出结论的。
- en: 'Therefore, the need for an explainer arises that can interpret black-box models,
    called the **Black Box Explainer**. The following are the two most well-known
    explainers:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，出现了对黑盒模型进行解释的需求，这种解释器被称为**黑盒解释器**。以下是最为知名的两种解释器：
- en: '**Shapley Additive Explanations** (**SHAP**): This is a game theory approach
    that''s applied to ML models and is used primarily for explainability. This family
    of methods assumes every feature in a model as a **player** in a game. Based on
    this assumption, you can use the so-called **Shapley values** to calculate the
    average contribution of a feature value to a prediction. Simply put, this is done
    by adding and removing features from **coalitions**, which in game theory is the
    group of players cooperating. SHAP can be used for any type of model, but it is
    well defined for linear regression, trees, ensemble trees, and deep learning with
    TensorFlow or Keras. Furthermore, it can explain individual predictions, not only
    explanations on a global scale. You can read more about SHAP in its open source
    release ([https://github.com/slundberg/shap](https://github.com/slundberg/shap)).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Shapley增量解释**（**SHAP**）：这是一种将博弈论应用于机器学习模型的方法，主要用于可解释性。这个方法族假设模型中的每个特征都是一个游戏中的**玩家**。基于这个假设，您可以使用所谓的**Shapley值**来计算特征值对预测的平均贡献。简单来说，这是通过向**联盟**中添加和删除特征来完成的，在博弈论中，联盟是合作的一组玩家。SHAP可以用于任何类型的模型，但它对线性回归、树、集成树以及使用TensorFlow或Keras的深度学习有很好的定义。此外，它还可以解释单个预测，而不仅仅是全局层面的解释。您可以在其开源版本中了解更多关于SHAP的信息([https://github.com/slundberg/shap](https://github.com/slundberg/shap))。'
- en: '**Local Interpretable Model-agnostic Explanations** (**LIME**): This is a method
    that creates a so-called surrogate glass-box model based on any black-box classifier
    model. A surrogate model tries to mimic the behavior of an underlying model while
    reducing its complexity. This is done by training a linear model in the vicinity
    of a particular instance. Users can then look at this newly created glass-box
    model to understand the black-box model''s outputs for this neighborhood or subset
    of predictions. Therefore, LIME can explain individual predictions of the black-box
    model. You can read more about LIME in its open source release ([https://github.com/marcotcr/lime](https://github.com/marcotcr/lime)).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局部可解释模型无关解释**（**LIME**）：这是一种创建所谓的代理玻璃盒模型的方法，基于任何黑盒分类器模型。代理模型试图模仿底层模型的行为，同时降低其复杂性。这是通过在特定实例附近训练一个线性模型来实现的。用户可以查看这个新创建的玻璃盒模型，以了解黑盒模型对这个邻域或预测子集的输出。因此，LIME可以解释黑盒模型的单个预测。您可以在其开源版本中了解更多关于LIME的信息([https://github.com/marcotcr/lime](https://github.com/marcotcr/lime))。'
- en: These are the techniques you can use to interpret black-box models. To alleviate
    the situation with glass-box models a bit, Microsoft Research is working on an
    ML model called **Explainable Boosting Machine** (**EBM**) that is as accurate
    as gradient boosting while still being completely explainable. Their original
    paper can be found at [https://arxiv.org/abs/2106.09680](https://arxiv.org/abs/2106.09680).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是您可以用来解释黑盒模型的技术。为了稍微缓解玻璃盒模型的情况，微软研究院正在开发一个名为**可解释提升机**（**EBM**）的机器学习模型，它在准确度上与梯度提升相当，同时仍然完全可解释。他们的原始论文可以在[https://arxiv.org/abs/2106.09680](https://arxiv.org/abs/2106.09680)找到。
- en: To try out these explainers, you can either use these packages directly in your
    project or you can use the `azureml-interpret` package ([https://docs.microsoft.com/en-us/python/api/azureml-interpret](https://docs.microsoft.com/en-us/python/api/azureml-interpret))
    from the Azure ML SDK. This package gives you access to the **Interpret Community
    SDK** ([https://github.com/interpretml/interpret-community](https://github.com/interpretml/interpret-community)).
    Have a read through the explainer that's available on that package.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 要尝试这些解释器，您可以直接在项目中使用这些包，或者您可以使用来自Azure ML SDK的`azureml-interpret`包([https://docs.microsoft.com/en-us/python/api/azureml-interpret](https://docs.microsoft.com/en-us/python/api/azureml-interpret))。这个包为您提供了访问**Interpret
    Community SDK**([https://github.com/interpretml/interpret-community](https://github.com/interpretml/interpret-community))的权限。您可以阅读该包上可用的解释器。
- en: 'If you want to try this out, have a look at the following guide: [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml).
    When you were looking at the Azure Machine Learning studio pages throughout all
    the hands-on exercises in this book, you may have noticed a tab called **Explanations**
    in the training runs and models. When you''re using this package, you can add
    the results of the explainers to your training runs and view the visuals online
    afterward.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想尝试一下，可以查看以下指南：[https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml)。当你在这本书的所有动手练习中查看Azure
    Machine Learning工作室页面时，你可能已经注意到训练运行和模型中有一个名为**解释**的标签。当你使用这个包时，你可以将解释器的结果添加到训练运行中，并在之后在线查看视觉效果。
- en: For further reading, have a look at the **InterpretML** project ([https://interpret.ml/docs/intro.html](https://interpret.ml/docs/intro.html)),
    which provides an overview of the different types of explainers.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 想要进一步阅读，可以查看**InterpretML**项目([https://interpret.ml/docs/intro.html](https://interpret.ml/docs/intro.html))，该项目提供了不同类型解释器的概述。
- en: Now that we have an idea of how to interpret the results of our models, let's
    look at fairness.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了如何解释我们模型的结果，让我们来看看公平性。
- en: Fairness in model training
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练中的公平性
- en: 'One of the major tools for analyzing the fairness of a model is called **Fairlearn**
    ([https://fairlearn.org/](https://fairlearn.org/)). To define if a model behaves
    fairly, the algorithms and metrics in the Fairlearn package look for two types
    of harm that can be done, as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 分析模型公平性的主要工具之一称为**Fairlearn**([https://fairlearn.org/](https://fairlearn.org/))。为了定义模型是否公平，Fairlearn包中的算法和指标寻找两种可能造成的损害，如下所示：
- en: '**Allocation harm**: A model or system withholds opportunities, resources,
    or information. This would fit our previous example, where we discussed an ML
    system giving out loans to individuals.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分配损害**：一个保留机会、资源或信息的模型或系统。这符合我们之前的例子，其中我们讨论了一个ML系统向个人发放贷款。'
- en: '**Quality-of-service harm**: A model or system that does not withhold something
    but behaves differently toward different groups.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务质量损害**：一个不保留任何东西但对待不同群体行为不同的模型或系统。'
- en: 'To assess the fairness in a given model, two constructs are used, assessment
    metrics and mitigation algorithms. These can be classified as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估给定模型的公平性，使用了两种结构，评估指标和缓解算法。这些可以按以下方式分类：
- en: '**Assessment metrics**: Metrics can be calculated for a single model by comparing
    multiple models and for models that have been created through the mitigation algorithms.
    They span from simple metrics calculating the recall rate of a model up to adding
    grouping information to the mix to analyze the model results. Further information
    is available here: [https://fairlearn.org/main/user_guide/assessment.html](https://fairlearn.org/main/user_guide/assessment.html).'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估指标**：可以通过比较多个模型为单个模型计算指标，也可以为通过缓解算法创建的模型计算指标。它们包括从计算模型召回率等简单指标到添加分组信息以分析模型结果。更多信息请参阅[https://fairlearn.org/main/user_guide/assessment.html](https://fairlearn.org/main/user_guide/assessment.html)。'
- en: '**Reduction algorithms**: These build a new standard black-box model from a
    re-weighted training dataset after the assessment. Users can tweak this through
    different model runs to find the optimum trade-off between accuracy and fairness.
    Further information is available here: [https://fairlearn.org/main/user_guide/mitigation.html#reductions](https://fairlearn.org/main/user_guide/mitigation.html#reductions).'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少算法**：这些算法在评估后从重新加权的训练数据集中构建一个新的标准黑盒模型。用户可以通过不同的模型运行来调整，以找到准确性和公平性之间的最佳权衡。更多信息请参阅[https://fairlearn.org/main/user_guide/mitigation.html#reductions](https://fairlearn.org/main/user_guide/mitigation.html#reductions)。'
- en: '**Post-processing algorithms**: These algorithms take the original model and
    the sensitive feature to calculate a transformation to be applied to the prediction
    of the model. Through this process, we avoid retraining the original model.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**后处理算法**：这些算法将原始模型和敏感特征结合起来计算应用于模型预测的转换。通过这个过程，我们避免了重新训练原始模型。'
- en: 'Be aware that packages such as Fairlearn are still in development. Since deciding
    on fairness is not a simple topic, do not only rely on such tooling. When you''re
    thinking about the types of biases you can introduce, be reflective on what you
    are doing and use tools like these to get more insights. The developers of Fairlearn
    pointed the following out:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，像Fairlearn这样的包仍在开发中。由于决定公平性不是一个简单的话题，不要仅依赖于这样的工具。当你思考可以引入的类型偏见时，要反思你所做的事情，并使用这些工具来获得更多见解。Fairlearn的开发者指出了以下几点：
- en: '"Fairness is fundamentally a sociotechnical challenge. Many aspects of fairness,
    such as justice and due process, are not captured by quantitative fairness metrics.
    Furthermore, there are many quantitative fairness metrics which cannot all be
    satisfied simultaneously. Our goal is to enable humans to assess different mitigation
    strategies and then make trade-offs appropriate to their scenario."'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: “公平性本质上是一个社会技术挑战。许多关于公平性的方面，如正义和正当程序，都无法通过定量公平指标来捕捉。此外，还有许多定量公平指标无法同时满足。我们的目标是使人类能够评估不同的缓解策略，并根据他们的场景做出适当的权衡。”
- en: For a guide on how to use the Fairlearn package with Azure Machine Learning
    and how to upload your results, go to [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何使用Fairlearn包与Azure机器学习结合使用以及如何上传您的结果的指南，请访问[https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-fairness-aml)。
- en: Finally, let's learn how to handle privacy and compliance with Azure Machine
    Learning.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们学习如何使用Azure机器学习处理隐私和合规性。
- en: Handling PII data and compliance requirements
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理PII数据和合规要求
- en: With the dawn of legislation such as the **General Data Protection Regulation**
    (**GDPR**) in Europe and the **California Consumer Privacy Act** (**CCPA**) in
    California, businesses are now in a predicament. Besides having clear instructions
    on how PII data can be utilized, they are also often required to store audit trails
    of any action that involved this data, from a user up to an employee of the company
    accessing this data.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 随着欧洲的**通用数据保护条例**（**GDPR**）和加州的**加州消费者隐私法案**（**CCPA**）等立法的出台，企业现在处于困境。除了有明确的指导说明如何利用PII数据外，他们通常还要求存储涉及此数据的任何行动的审计跟踪，从用户到访问此数据的公司员工。
- en: Therefore, it is very important to have the tooling to support this effort.
    Most Azure services have security measures in place to deal with external intruders
    and to build multi-tenant applications, helping customers avoid seeing the PII
    data of others. Still, the ones administrating the system have access to this
    clear text data in most organizations. And the same is true for someone building
    an ML model. In addition, databases on Azure can typically log any access and
    build an audit trail for review. But what about the ML modeling pipeline or deployment
    pipeline? Who can see the data in which form and at which point?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，拥有支持这一努力的工具非常重要。大多数Azure服务都设有安全措施来应对外部入侵者并构建多租户应用程序，帮助客户避免看到他人的PII数据。然而，在大多数组织中，系统管理员通常可以访问这些明文数据。对于构建机器学习模型的人来说也是如此。此外，Azure上的数据库通常可以记录任何访问并建立审计跟踪以供审查。但机器学习建模管道或部署管道又如何呢？谁能在什么形式和什么时间点看到数据？
- en: 'All these questions need to be answered. Let''s look at some of the available
    tooling and research that''s being done in this area:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些问题都需要得到解答。让我们看看一些可用的工具和在这个领域正在进行的研究：
- en: '**Differential privacy**: This mechanism is used to add noise or randomness
    to data to make the data of a person unidentifiable. In doing so, we can still
    build an accurate model on a slightly changed dataset. Be aware that this is not
    referring to obvious PII data, such as your name or email address. To give you
    something to think about: you can likely be identified directly by the version
    of the browser and the installed browser add-ons you are using. This method was
    implemented in a package called **SmartNoise** ([https://github.com/opendp/smartnoise-core](https://github.com/opendp/smartnoise-core)),
    which you can use in your ML projects. Additional information about this topic
    can be found here: [https://docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy](https://docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy).'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**差分隐私**: 该机制用于向数据添加噪声或随机性，以使个人的数据无法识别。这样做，我们仍然可以在略微改变的数据集上构建一个准确模型。请注意，这并不是指明显的
    PII 数据，例如你的姓名或电子邮件地址。为了让你思考一下：你很可能会直接通过你使用的浏览器版本和安装的浏览器插件被识别。这种方法在名为 **SmartNoise**
    ([https://github.com/opendp/smartnoise-core](https://github.com/opendp/smartnoise-core))
    的软件包中实现，你可以在你的机器学习项目中使用它。有关此主题的更多信息，请参阅[https://docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy](https://docs.microsoft.com/en-us/azure/machine-learning/concept-differential-privacy)。'
- en: '**Homomorphic encryption**: This allows computation to be done on encrypted
    data without allowing access to a decryption key. Only the results of the computation
    need to be decrypted with a secret key. So far, even using encrypted data and
    decrypting it with a key was bothersome, since running encryption on TBs of data
    was time-consuming. Now, this technology, which has been researched by Microsoft,
    is available through the **Microsoft SEAL** project ([https://www.microsoft.com/en-us/research/project/microsoft-seal/](https://www.microsoft.com/en-us/research/project/microsoft-seal/)).
    Furthermore, you can learn how to use this method with an inferencing web service
    by following the guide at [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal).'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**同态加密**: 这允许在加密数据上执行计算，而不允许访问解密密钥。只需要用秘密密钥解密计算结果。到目前为止，即使使用加密数据并使用密钥解密，也相当麻烦，因为对
    TB 级数据运行加密是耗时的。现在，这项由微软研究的技术，通过 **Microsoft SEAL** 项目 ([https://www.microsoft.com/en-us/research/project/microsoft-seal/](https://www.microsoft.com/en-us/research/project/microsoft-seal/))
    提供使用。此外，你可以通过遵循[https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal)上的指南来学习如何使用这个方法与推理网络服务一起使用。'
- en: '**Datasheets for models**: This provides guidelines for documenting ML assets
    and their life cycles. To be compliant with regulations and also just to work
    cleanly, a guideline called **ABOUT ML** ([https://partnershiponai.org/paper/about-ml-reference-document/](https://partnershiponai.org/paper/about-ml-reference-document/))
    can be adapted. A view of how to adapt this guideline in the context of Azure
    Machine Learning can be found here: [https://github.com/microsoft/MLOps/blob/master/pytorch_with_datasheet/model_with_datasheet.ipynb](https://github.com/microsoft/MLOps/blob/master/pytorch_with_datasheet/model_with_datasheet.ipynb).'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型数据表**: 这提供了记录机器学习资产及其生命周期的指南。为了符合法规并且工作得更加整洁，可以采用名为 **关于机器学习** 的指南 **ABOUT
    ML** ([https://partnershiponai.org/paper/about-ml-reference-document/](https://partnershiponai.org/paper/about-ml-reference-document/))。在
    Azure 机器学习环境中如何采用此指南的示例可以在此找到：[https://github.com/microsoft/MLOps/blob/master/pytorch_with_datasheet/model_with_datasheet.ipynb](https://github.com/microsoft/MLOps/blob/master/pytorch_with_datasheet/model_with_datasheet.ipynb)。'
- en: Keep an eye on these topics as they develop since failure to comply with these
    regulations can have dire consequences.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 请密切关注这些主题的发展，因为未能遵守这些法规可能会产生严重的后果。
- en: As you have seen, all the packages we've discussed in this section are still
    in alpha or beta stages since the topics of interpretability, fairness, and privacy
    are relatively new in the context of ML. For a decade, ML was more of a research
    topic than a real-life production environment. Nowadays, solutions that build
    on ML have found their way into our daily lives. Therefore, we need to take a
    step back and start asking if we can let machines decide for us without questioning
    their validity.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，我们在这个章节中讨论的所有包都还处于alpha或beta阶段，因为可解释性、公平性和隐私性在机器学习背景下相对较新。在过去十年中，机器学习更多的是一个研究课题，而不是实际的生产环境。如今，基于机器学习的解决方案已经融入了我们的日常生活。因此，我们需要退一步，开始思考我们是否可以不质疑其有效性就让机器为我们做决定。
- en: So, when you're running your next ML project that is bound for production, bring
    these topics into the discussion since they need to be handled from the beginning.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当你运行下一个注定要投入生产的ML项目时，将这些话题带入讨论，因为它们需要从一开始就得到处理。
- en: Summary
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we looked at a few things from a much higher level by covering
    data, infrastructure, monitoring, automation, change management, and ethics. We
    hope that our coverage of these topics made sense to you after reading this book.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们通过涵盖数据、基础设施、监控、自动化、变更管理和伦理等方面，从更高的层次审视了一些内容。我们希望你在阅读这本书后，对这些话题的理解是合理的。
- en: It is important to understand that your data will control and influence everything,
    so making data a first-class citizen in your company is the first important step.
    Hiring a *VP of Data* and defining standards on data quality, lineage, and discoverability
    are just a few of the measures you can take.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要理解，你的数据将控制和影响一切，因此，将数据作为你公司的一等公民是第一步重要的举措。雇佣一个*数据副总裁*并定义数据质量、血缘和可发现性的标准只是你可以采取的一些措施。
- en: 'Looking at automatization, we saw that Automated Machine Learning will run
    the world in a couple of years. The idea is quite simple: a trained meta-model
    will always be better at proposing, training, optimizing, and stacking models
    for higher predictive performance than humans. This makes total sense. It is just
    another parameter optimization step that also includes the model architecture.
    Another interesting thought is that Automated Machine Learning will offer true
    MLaaS to users who aren''t ML-savvy. Maybe a prediction column will be provided
    in Excel, or an ML transformation step in Power BI, meaning regular Office users
    can suddenly harness the power of ML through spreadsheet applications.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动化方面，我们看到自动化机器学习将在几年内统治世界。这个想法很简单：一个训练好的元模型在提出、训练、优化和堆叠模型以实现更高的预测性能方面将始终优于人类。这完全说得通。这只是另一个参数优化步骤，也包括模型架构。另一个有趣的思考是，自动化机器学习将为不熟悉机器学习的人提供真正的MLaaS。也许Excel中会提供一个预测列，或者在Power
    BI中有一个机器学习转换步骤，这意味着普通的Office用户可以通过电子表格应用程序突然利用机器学习的力量。
- en: We also mentioned that change is inevitable when working with PaaS in the cloud.
    This is because PaaS solutions are designed to implement typical customer solutions
    and drive you toward consuming more infrastructure services. As customer needs
    evolve, so do these PaaS offerings. Hence, a good takeaway is to not get too attached
    to product names, UIs, or SDK packages.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提到，在云中使用PaaS时，变化是不可避免的。这是因为PaaS解决方案旨在实施典型的客户解决方案，并推动你消费更多的基础设施服务。随着客户需求的变化，这些PaaS提供的产品也会随之变化。因此，一个很好的经验法则是不要过于依赖产品名称、UI或SDK包。
- en: Finally, we understood the importance of ethics in data handling. We discussed
    the topics of building models that can be explained, assessing the fairness of
    our models, and how we can safeguard the personal data of individuals from ourselves
    and others.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们理解了在数据处理中伦理的重要性。我们讨论了构建可解释的模型、评估我们模型公平性以及如何保护个人数据不受我们自己和其他人侵害的话题。
- en: We hope you have enjoyed this book and learned how to master ML and Azure Machine
    Learning. However, the rabbit hole is far deeper than this book. So, keep on learning,
    as we also will. Reach out to us on social media and tell us what you've learned,
    what you liked, and what could be improved in this book. We would love to hear
    your feedback.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望你喜欢这本书，并学会了如何掌握机器学习和Azure机器学习。然而，这个兔子洞比这本书深得多。所以，继续学习吧，我们也会这样做。在社交媒体上联系我们，告诉我们你学到了什么，你喜欢什么，以及这本书中可以改进的地方。我们非常乐意听到你的反馈。
- en: Until then, happy machine learning!
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在那时之前，祝大家机器学习愉快！
