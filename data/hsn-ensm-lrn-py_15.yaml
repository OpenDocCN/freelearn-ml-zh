- en: Predicting Bitcoin Prices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测比特币价格
- en: Bitcoin and other cryptocurrencies have attracted the attention of many parties
    over the years, mainly due to their explosion in price levels, as well as the
    business opportunities that blockchain technologies offer. In this chapter, we
    will attempt to predict the next day's Bitcoin (BTC) price using historical data.
    There are many sources that offer cryptocurrency's historical price data. We will
    use Yahoo finance data, available at [https://finance.yahoo.com/quote/BTC-USD/history/](https://finance.yahoo.com/quote/BTC-USD/history/).
    In this chapter, we will focus on predicting future prices and leveraging that
    knowledge to invest in bitcoin.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，比特币和其他加密货币吸引了许多方的关注，主要是由于其价格水平的爆炸性增长以及区块链技术所提供的商业机会。在本章中，我们将尝试使用历史数据预测第二天的比特币（BTC）价格。有许多来源提供加密货币的历史价格数据。我们将使用来自雅虎财经的数据，地址为[https://finance.yahoo.com/quote/BTC-USD/history/](https://finance.yahoo.com/quote/BTC-USD/history/)。本章将重点预测未来价格，并利用这些知识进行比特币投资。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Time series data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列数据
- en: Voting
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 投票
- en: Stacking
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆叠
- en: Bagging
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 装袋法
- en: Boosting
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升法
- en: Random forests
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will require basic knowledge of machine learning techniques and algorithms.
    Furthermore, a knowledge of python conventions and syntax is required. Finally,
    familiarity with the NumPy library will greatly help the reader to understand
    some custom algorithm implementations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要具备基本的机器学习技术和算法知识。此外，还需要了解Python的语法和惯例。最后，熟悉NumPy库将极大帮助读者理解一些自定义算法实现。
- en: 'The code files of this chapter can be found on GitHub:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在 GitHub 上找到：
- en: '[https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter10](https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter10)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter10](https://github.com/PacktPublishing/Hands-On-Ensemble-Learning-with-Python/tree/master/Chapter10)'
- en: Check out the following video to see the Code in Action: [http://bit.ly/2JOsR7d](http://bit.ly/2JOsR7d).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，观看代码示例：[http://bit.ly/2JOsR7d](http://bit.ly/2JOsR7d)。
- en: Time series data
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列数据
- en: Time series data is concerned with data instances in which each instance relates
    to a specific point in time or interval. How often we measure the variable of
    choice defines the time series' sampling frequency. For example, atmospheric temperature
    differs throughout the day and throughout the year. We can choose to measure the
    temperature every hour, so we have an hourly frequency, or we can choose to measure
    it each day, so we have a daily frequency. In finance, it is not unusual to have
    frequencies that are between major time intervals; this could be every 10 minutes
    (10m frequency) or every 4 hours (4h frequency). Another interesting characteristic
    of time series is that there is usually a correlation between instances that refer
    to proximal time points.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据关注的是每个实例与特定时间点或时间间隔相关的数据实例。我们选择测量变量的频率定义了时间序列的采样频率。例如，大气温度在一天中以及一整年中都有不同。我们可以选择每小时测量一次温度，从而得到每小时的频率，或者选择每天测量一次温度，从而得到每天的频率。在金融领域，采样频率介于主要时间间隔之间并不罕见；例如，可以是每10分钟一次（10分钟频率）或每4小时一次（4小时频率）。时间序列的另一个有趣特点是，通常相邻时间点之间的数据实例存在相关性。
- en: 'This is called **autocorrelation**. For example, the atmospheric temperature
    cannot vary by a great magnitude between consecutive minutes. Furthermore, this
    enables us to utilize earlier data points to predict future data points. An example
    of temperatures (an average of 3 hours) for Athens and Greece for the years 2016–2019
    is provided in figure. Notice how most temperatures are relatively close to the
    previous day''s temperature, even though there are variations. Furthermore, we
    see a repeating pattern of hot and cold months (seasons), which is called seasonality:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这叫做**自相关**。例如，大气温度在连续的几分钟内不能发生很大的变化。此外，这使我们能够利用早期的数据点来预测未来的数据点。下面是2016年至2019年期间雅典和希腊的温度（3小时平均）示例。请注意，尽管温度有所变化，但大多数温度都相对接近前一天的温度。此外，我们看到热月和冷月（季节）的重复模式，这就是所谓的季节性：
- en: '![](img/b95a1076-0053-49d1-93bb-3973b7a8adfc.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b95a1076-0053-49d1-93bb-3973b7a8adfc.png)'
- en: Temperatures for Athens, Greece 2016–2019
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 2016–2019年雅典，希腊的温度
- en: 'To examine the level of correlation between different points in time, we utilize
    the **autocorrelation function** (**ACF**). ACF measures the linear correlation
    between a data point and previous points (called **lags**). In the following figure,
    the ACF for the temperature data (resampled as the month''s average) is provided.
    It indicates a strong positive correlation with the first lag. This means that
    a month''s temperature cannot deviate much from the previous month, which is logical.
    For example, December and January are cold months, and usually, their average
    temperatures are closer than December and March, for example. Furthermore, there
    is a strong negative correlation between lags 5 and 6, indicating that a cold
    winter results in a hot summer and vice versa:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查不同时间点之间的相关性水平，我们利用**自相关函数**（**ACF**）。ACF 衡量数据点与前一个数据点之间的线性相关性（称为**滞后**）。下图展示了温度数据（按月平均重新采样）的自相关函数（ACF）。它显示出与第一个滞后的强正相关性。这意味着一个月的温度不太可能与前一个月相差太大，这是合乎逻辑的。例如，12月和1月是寒冷的月份，它们的平均温度通常比12月和3月更接近。此外，第5和第6滞后之间存在强烈的负相关性，表明寒冷的冬季导致炎热的夏季，反之亦然：
- en: '![](img/4c446b11-ddeb-42b5-8471-c3ce092915e5.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4c446b11-ddeb-42b5-8471-c3ce092915e5.png)'
- en: ACF for the temperature data
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 温度数据的自相关函数（ACF）
- en: Bitcoin data analysis
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比特币数据分析
- en: Bitcoin data is very different from temperature data. Temperatures have more
    or less the same value for the same month of each year. This indicates that the
    distribution of temperatures does not change over time. Time series that exhibit
    this behavior are called **stationary**. This allows for relatively easy modeling
    with time series analysis tools, such as **auto regressive** (**AR**), **moving
    average** (**MA**), and **auto regressive integrated moving average** (**ARIMA**)
    models. Financial data is usually non-stationary, as seen in the daily Bitcoin
    close data, depicted in figure. This means that the data does not exhibit the
    same behavior throughout its entire history, but instead its behavior varies.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 比特币数据与温度数据有很大不同。温度在每年的相同月份基本保持相似值。这表明温度的分布随着时间变化并未发生改变。表现出这种行为的时间序列被称为**平稳**时间序列。这使得使用时间序列分析工具，如**自回归**（**AR**）、**滑动平均**（**MA**）和**自回归积分滑动平均**（**ARIMA**）模型进行建模相对简单。财务数据通常是非平稳的，正如下图中所示的每日比特币收盘数据所示。这意味着数据在其历史的整个过程中并未表现出相同的行为，而是行为在变化。
- en: Financial data usually provides open (the first price for the day), high (the
    highest price for the day), low (the lowest price for the day), and close (the
    last price for the day) values.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 财务数据通常提供开盘价（当天的第一笔价格）、最高价（当天的最高价格）、最低价（当天的最低价格）和收盘价（当天的最后一笔价格）。
- en: 'There are clear trends in the data (time intervals where the price, on average,
    increases or decreases), as well as heteroskedasticity (variable variance over
    time). One way to identify stationarity is to study the ACF function.If there
    is a very strong correlation between lags of a very high order that do not decay,
    the time series is most probably non-stationary. The ACF for the BTC data is also
    provided, showing weakly decaying correlations:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中存在明显的趋势（价格在某些时间间隔内平均上升或下降），以及异方差性（随时间变化的可变方差）。识别平稳性的一种方法是研究自相关函数（ACF）。如果存在非常强的高阶滞后之间的相关性且不衰减，则该时间序列很可能是非平稳的。下图展示了比特币数据的自相关函数（ACF），显示出相关性衰减较弱：
- en: '![](img/129b0c46-e882-4541-a670-1d541ddf4316.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/129b0c46-e882-4541-a670-1d541ddf4316.png)'
- en: BTC/USD prices for mid-2014 to present
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 2014年中期至今的比特币/USD价格
- en: 'The following figure depicts the ACF for BTC. We can clearly see that the correlations
    do not drop for very high lag values:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了比特币的自相关函数（ACF）。我们可以清楚地看到，在非常高的滞后值下，相关性并没有显著下降：
- en: '![](img/6922b6d5-ebf1-4adb-baaf-c350a321c8ea.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6922b6d5-ebf1-4adb-baaf-c350a321c8ea.png)'
- en: ACF for BTC data
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 比特币数据的自相关函数（ACF）
- en: 'Take a look at the following formula:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 请看以下公式：
- en: '![](img/11504a16-70f1-401c-a372-b973ab8ac221.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/11504a16-70f1-401c-a372-b973ab8ac221.png)'
- en: Where *p* is the percentage change, *t[n ]*is the price at time *n*, and *tn-1*
    is the price at time *n-1*. By applying the transformation to the data, we get
    a time series that is stationary, but less correlated.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *p* 是百分比变化，*t[n]* 是时间 *n* 时的价格，*tn-1* 是时间 *n-1* 时的价格。通过对数据进行转化，我们得到一个平稳但相关性较弱的时间序列。
- en: 'The following figure shows the plots for the data, and the ACF and the average
    30-day standard deviation are provided:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了数据的图形，并提供了自相关函数（ACF）和平均30天标准差：
- en: '![](img/3d5ca1aa-f104-46e5-b543-34423bdd6d24.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d5ca1aa-f104-46e5-b543-34423bdd6d24.png)'
- en: Transformed data
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 转换后的数据
- en: '![](img/95c24465-fecb-4957-a51e-cdffdd6030cd.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95c24465-fecb-4957-a51e-cdffdd6030cd.png)'
- en: Rolling 30-day standard deviation and ACF for transformed data
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动30天标准差和转换数据的自相关函数（ACF）
- en: Establishing a baseline
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立基准
- en: 'In order to establish a baseline, we will try to model the data using linear
    regression. Although it is a time series, we will not directly take time into
    account. Instead, we will utilize sliding windows of size *S* to generate features
    at each time point and use those features to predict the next point. Next, we
    will move the window one step forward in time to include the true value of the
    data point we predicted and discard the oldest data point inside the window. We
    will continue this process until all data points have been predicted. This is
    called walk-forward validation. One drawback is that we cannot predict the first
    *S* data points, as we do not have enough data to generate features for them.
    Another point of concern is that we need to re-train the model *L*-*S* times,
    in which *L* is the total number of points in the time series. A graphical representation
    of the first two steps is provided in the following figure:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了建立基准，我们将尝试使用线性回归建模数据。虽然这是一个时间序列，我们不会直接考虑时间。相反，我们将使用大小为*S*的滑动窗口在每个时间点生成特征，并利用这些特征预测下一个数据点。接下来，我们将时间窗口向前移动一步，以包含我们预测的真实数据点的值，并丢弃窗口中的最旧数据点。我们将继续这个过程，直到所有数据点都被预测。这叫做向前验证。一个缺点是我们无法预测前*S*个数据点，因为我们没有足够的数据来生成它们的特征。另一个问题是我们需要重新训练模型*L*-*S*次，其中*L*是时间序列中的数据点总数。以下图展示了前两个步骤的图示：
- en: '![](img/fc41a330-90f5-468a-8c7e-79c5d9d43514.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fc41a330-90f5-468a-8c7e-79c5d9d43514.png)'
- en: Walk-forward validation procedure, first two steps. The procedure continues
    for the whole time series.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 向前验证程序的前两个步骤。该程序会继续应用于整个时间序列。
- en: 'First, we load the required libraries and data from the `BTC-USD.csv` file.
    We also set the seed for a NumPy random number generator:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从`BTC-USD.csv`文件加载所需的库和数据。我们还设置了NumPy随机数生成器的种子：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We then clean the data by removing entries that contain NaN values, using `data.dropna()`,
    parse the dates using `pd.to_datetime`, and set the dates as an index. Finally,
    we calculate the percentage differences of `Close` values (and discard the first
    value, as it is a NaN) and save the Pandas series'' length:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过使用`data.dropna()`删除包含NaN值的条目，使用`pd.to_datetime`解析日期，并将日期设置为索引，来清理数据。最后，我们计算`Close`值的百分比差异（并丢弃第一个值，因为它是NaN），并保存Pandas系列的长度：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We have created a function that generates the features at each data point.
    Features are essentially the different percentages at previous lags. Thus, to
    fill a dataset''s feature with values, we only have to shift the data forward
    by as many points as the lags indicate. Any features that do not have available
    data to calculate lags, will have a value of zero. The following figureshows a
    toy example of a time series containing the numbers 1, 2, 3, and 4:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个函数，用于在每个数据点生成特征。特征本质上是前几个滞后的不同百分比。因此，为了用值填充数据集的特征，我们只需将数据向前移动滞后点数即可。任何没有可用数据计算滞后的特征，其值将为零。以下图示了一个包含数字1、2、3和4的时间序列的示例：
- en: '![](img/425b19c2-be6f-4814-814d-a7089a444894.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/425b19c2-be6f-4814-814d-a7089a444894.png)'
- en: How lag features are filled
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 滞后特征的填充方式
- en: 'The actual function, to fill lag *t*, selects all of the data from the time
    series except for the last *t* and places it in the corresponding feature, starting
    from index *t*. We chose to use the past 20 days as there does not seem to be
    any significant linear correlations after that point. Furthermore, we scale the
    features and targets by a factor of 100 and round them to 8 decimal points. This
    is important, as it allows the reproducibility of results. If the data is not
    rounded, overflow errors introduce stochasticity to the results, as shown in the
    following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的函数，填充滞后*t*，选择时间序列中的所有数据，除了最后的*t*，并将其放入相应的特征中，从索引*t*开始。我们选择使用过去20天的数据，因为在那之后似乎没有显著的线性相关性。此外，我们将特征和目标缩放100倍，并四舍五入到8位小数。这一点很重要，因为它确保了结果的可重复性。如果数据没有四舍五入，溢出错误会给结果带来随机性，如下所示：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, we execute the walk-forward validation. We chose a training window
    of 150 points, which equates to roughly 5 months. Given the data''s nature and
    volatility, it provides a good trade-off between having a large enough train set
    and capturing recent market behaviors. A larger window would include market conditions
    that no longer reflect reality. A shorter window would provide too little data
    and would be prone to overfitting. We measure our model''s predictive quality
    by utilizing the mean squared error between our predictions and the original percentage
    differences:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们执行前向验证。我们选择了150个点的训练窗口，大约相当于5个月。考虑到数据的特性和波动性，这提供了一个良好的折衷，既能保证训练集足够大，又能捕捉到近期的市场行为。更大的窗口将包括不再反映现实的市场条件。更短的窗口则提供的数据过少，容易导致过拟合。我们通过利用预测值与原始百分比差异之间的均方误差来衡量我们模型的预测质量：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Simple linear regression might produce an MSE of 18.41\. We could also attempt
    to reconstruct the time series by multiplying each data point by (1 + prediction)
    to get the next predicted point. Furthermore, we could attempt to take advantage
    of the dataset''s nature and simulate trading activity. Each time the prediction
    is greater than +0.5% change, we invest 100 USD in buying Bitcoins. If we have
    Bitcoins in our possession and the prediction is lower than -0.5%, we sell the
    Bitcoins at the current market close. To assess the quality of our model as a
    trading strategy, we utilize a simplified **Sharpe** ratio, which is calculated
    as the ratio of mean returns (percentage profits) over the standard deviation
    of the returns. Higher Sharpe values indicate a better trading strategy. The formula
    utilized here is calculated as follows. Usually, an alternative **safe** return
    percentage is subtracted from the expected return, but as we only want to compare
    the models we will generate with each other, we''ll omit it:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 简单线性回归可能产生一个均方误差（MSE）为18.41。我们还可以尝试通过将每个数据点乘以（1 + 预测值）来重建时间序列，以获得下一个预测值。此外，我们可以尝试利用数据集的特点来模拟交易活动。每次预测值大于+0.5%的变化时，我们投资100美元购买比特币。如果我们持有比特币并且预测值低于-0.5%，则在当前市场收盘时卖出比特币。为了评估我们模型作为交易策略的质量，我们使用简化的**夏普**比率，计算方式是将平均回报率（百分比利润）与回报的标准差之比。较高的夏普值表示更好的交易策略。这里使用的公式如下。通常，预期回报会减去一个替代的**安全**回报百分比，但由于我们仅希望比较我们将生成的模型，因此将其省略：
- en: '![](img/292cc638-9c04-4f53-85ce-75ca3ccaf8e2.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/292cc638-9c04-4f53-85ce-75ca3ccaf8e2.png)'
- en: 'When utilized as a trading strategy, linear regression is able to produce a
    Sharpe value of 0.19\. The following figure indicates the trades and profits generated
    by our model. The blue triangles indicate time points at which the strategy bought
    Bitcoins worth 100 USD and the red triangles indicate the time points at which
    it sold the previously bought Bitcoins:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作为交易策略使用时，线性回归能够产生0.19的夏普值。下图显示了我们的模型生成的交易和利润。蓝色三角形表示策略购买100美元比特币的时间点，红色三角形表示策略卖出之前购买的比特币的时间点：
- en: '![](img/2be506f8-c88d-449b-b6ce-7802d6e07a5f.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2be506f8-c88d-449b-b6ce-7802d6e07a5f.png)'
- en: Profits and entry/exit points of our model
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模型的利润和进出点
- en: In the rest of this chapter, we will try to improve the MSE and Sharpe values
    by utilizing the ensemble methods we presented in the previous chapters.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将通过利用前几章介绍的集成方法来改进均方误差（MSE）和夏普值。
- en: The simulator
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟器
- en: 'Here, we''ll provide a brief explanation of how the simulator works. It is
    implemented as a function that accepts our standard Pandas DataFrame data and
    the model''s predictions as inputs. First, we''ll define the buying threshold
    and the stake size (how much money we invest in each buy), as well as placeholder
    variables. The variables will be used to store the true and predicted time series,
    as well as the profits of our model (`balances`). Furthermore, we define the `buy_price` variable, which
    stores the price at which we bought the Bitcoins. If the price is `0`, we assume
    that we do not hold any Bitcoins. The `buy_points` and `sell_points` lists indicate
    the points in time when we bought or sold the Bitcoins and are used only for plotting.
    Furthermore, we store the starting index, which is equivalent to the sliding window''s
    size as shown in the following example:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将简要解释模拟器的工作原理。它作为一个函数实现，接受我们的标准Pandas数据框和模型预测作为输入。首先，我们将定义买入阈值和投资额度（我们在每次买入时投资的金额），以及占位符变量。这些变量将用于存储真实和预测的时间序列，以及我们模型的利润（`balances`）。此外，我们定义了`buy_price`变量，它存储我们购买比特币时的价格。如果价格为`0`，我们假设我们没有持有任何比特币。`buy_points`和`sell_points`列表表示我们买入或卖出比特币的时间点，仅用于绘图。此外，我们还存储了起始索引，这相当于滑动窗口的大小，如以下示例所示：
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, for each point, we store the actual and predicted values. If the predicted
    value is greater than 0.5 and we do not hold any Bitcoins, we buy 100 USD worth
    of Bitcoins. If the predicted value is less than -0.5 and we have already bought
    Bitcoins, we sell them at the current close value. We add the current profit (or
    loss) to our balances, cast the true and predicted values as NumPy arrays, and
    produce the plots:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，对于每个点，我们存储实际值和预测值。如果预测值大于0.5且我们没有持有任何比特币，我们将买入价值100美元的比特币。如果预测值小于-0.5且我们已经购买了比特币，我们将以当前的收盘价将其卖出。我们将当前的利润（或亏损）添加到我们的余额中，将真实值和预测值转换为NumPy数组，并生成图表：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Voting
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 投票
- en: 'We will try to combine three basic regression algorithms by voting to improve
    the MSE of the simple regression. To combine the algorithms, we will utilize the
    average of their predictions. Thus, we code a simple class that creates a dictionary
    of base learners and handles their training and prediction averaging. The main
    logic is the same as with the custom voting classifier we implemented in [Chapter
    3](ad9aa66b-7b30-4779-8914-0ff58140b3e8.xhtml), *Voting*:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试通过投票将三种基本回归算法结合起来，以提高简单回归的MSE。为了组合这些算法，我们将利用它们预测值的平均值。因此，我们编写了一个简单的类，用于创建基本学习器的字典，并处理它们的训练和预测平均。主要逻辑与我们在[第3章](ad9aa66b-7b30-4779-8914-0ff58140b3e8.xhtml)实现的自定义投票分类器*Voting*相同：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The predictions are stored in a NumPy matrix, in which each row corresponds
    to a single instance and each column corresponds to a single base learner. The
    row-averaged values are the ensemble''s output, as shown here:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 预测结果存储在一个NumPy矩阵中，其中每一行对应一个实例，每一列对应一个基本学习器。行平均值即为集成的输出，如下所示：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We chose to utilize a support vector machine, a K-Nearest Neighbors Regressor,
    and a linear regression as a base learners, as they provide diverse learning paradigms.
    To utilize the ensemble, we first import the required modules:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了支持向量机、K近邻回归器和线性回归作为基本学习器，因为它们提供了多样的学习范式。为了使用这个集成，我们首先导入所需的模块：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, in the code we presented earlier, we replace the `lr = LinearRegression()` line with
    the following:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在我们之前展示的代码中，我们将`lr = LinearRegression()`这一行替换为以下代码：
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: By adding the two additional regressors, we are able to reduce the MSE to 16.22
    and produce a Sharpe value of 0.22.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通过增加两个额外的回归器，我们能够将MSE减少到16.22，并产生0.22的夏普值。
- en: Improving voting
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进投票
- en: 'Although our results are better than linear regression, we can further improve
    them by removing the linear regression, thus, leaving the base learners as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的结果优于线性回归，但我们仍然可以通过去除线性回归进一步改善结果，从而仅保留基本学习器，如下所示：
- en: '[PRE10]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This further improves the MSE, reducing it to 15.71\. If we utilize this model
    as a trading strategy, we can achieve a Sharpe value of 0.21; considerably better
    than simple linear regression. The following table summarizes our results:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这进一步改善了MSE，将其减少到15.71。如果我们将这个模型作为交易策略使用，可以实现0.21的夏普值；比简单的线性回归要好得多。下表总结了我们的结果：
- en: '| **Metric** | **SVR-KNN** | **SVR-LR-KNN** |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| **Metric** | **SVR-KNN** | **SVR-LR-KNN** |'
- en: '| **MSE** | 15.71 | 16.22 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| **MSE** | 15.71 | 16.22 |'
- en: '| **Sharpe** | 0.21 | 0.22 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| **Sharpe** | 0.21 | 0.22 |'
- en: Voting ensemble results
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 投票集成结果
- en: Stacking
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 堆叠
- en: 'Moving on to more complex ensembles, we will utilize stacking to combine basic
    regressors more efficiently. Using `StackingRegressor` from [Chapter 4](49a05219-d6cb-4893-aaac-49280842b647.xhtml), *Stacking*,
    we will try to combine the same algorithms as we did with voting. First, we modify
    the `predict` function of our ensemble (to allow for single-instance prediction)
    as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用堆叠法来更有效地结合基本回归器。使用[第4章](49a05219-d6cb-4893-aaac-49280842b647.xhtml)中的`StackingRegressor`，*堆叠*，我们将尝试与投票法一样组合相同的算法。首先，我们修改我们的集成的`predict`函数（以允许单实例预测），如下所示：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Again, we modify the code to use the stacking regressor, as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们修改代码以使用堆叠回归器，如下所示：
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this setup, the ensemble yields a model with an MSE of 16.17 and a Sharpe
    value of 0.21.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种设置下，集成方法生成的模型具有16.17的均方误差（MSE）和0.21的夏普比率。
- en: Improving stacking
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进堆叠法
- en: 'Our results are slightly worse than the final Voting ensemble, so we will attempt
    to improve them by removing the linear regression, as we did with the voting ensemble.
    By doing so, we can slightly improve our model, achieving an MSE of 16.16 and
    a Sharpe value of 0.22\. Comparing it to voting, stacking is slightly better as
    part of an investing strategy (the same Sharpe value and a slightly better MSE),
    although it is unable to achieve the same level of predictive accuracy. Its results
    are summarized in the following table:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果略逊于最终的投票集成，因此我们将尝试通过去除线性回归来改进它，就像我们在投票集成中做的那样。通过这样做，我们可以稍微改善模型，达到16.16的均方误差（MSE）和0.22的夏普比率。与投票法相比，堆叠法作为一种投资策略略好一些（相同的夏普比率和略微更好的MSE），尽管它无法达到相同水平的预测准确度。其结果总结在下表中：
- en: '| **Metric** | **SVR-KNN** | **SVR-LR-KNN** |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| **指标** | **SVR-KNN** | **SVR-LR-KNN** |'
- en: '| **MSE** | 16.17 | 16.16 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| **MSE** | 16.17 | 16.16 |'
- en: '| **Sharpe** | 0.21 | 0.22 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| **夏普比率** | 0.21 | 0.22 |'
- en: Stacking results
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠法结果
- en: Bagging
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自助法（Bagging）
- en: 'Usually, when fitting predictive models onto financial data, variance is our
    main problem. Bagging is a very useful tool to counter variance; thus, we hope
    that it will be able to produce better performing models compared to simple voting
    and stacking. To utilize bagging, we will use scikit''s `BaggingRegressor`, presented
    in [Chapter 5](a0e9eea5-bc95-4d15-9679-fafce5718525.xhtml), *Bagging*. To implement
    it in our experiment, we simply call it using `lr = BaggingRegressor()` instead
    of the previous regressors. This results in an MSE of 19.45 and a Sharpe of 0.09\.
    The following figure depicts the profits and trades that our model generates:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在将预测模型拟合到金融数据时，方差是我们面临的主要问题。自助法是对抗方差的非常有用的工具；因此，我们希望它能够比简单的投票法和堆叠法生成表现更好的模型。为了利用自助法，我们将使用scikit的`BaggingRegressor`，该方法在[第5章](a0e9eea5-bc95-4d15-9679-fafce5718525.xhtml)中介绍，*自助法*。为了在我们的实验中实现它，我们只需使用`lr
    = BaggingRegressor()`来替代之前的回归器。这样做的结果是均方误差（MSE）为19.45，夏普比率为0.09。下图展示了我们的模型所生成的利润和交易：
- en: '![](img/c0e89628-fedc-4663-935e-94dc46540cde.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c0e89628-fedc-4663-935e-94dc46540cde.png)'
- en: Bagging profits and trades
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 自助法的利润和交易
- en: Improving bagging
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进自助法
- en: We can further improve bagging as its performance is worse than any previous
    model. First, we can experiment with shallow trees, which will further reduce
    variance in the ensemble. By utilizing trees with a maximum depth of `3`, using
    `lr = BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=3))`, we
    can improve the model's performance, generating an MSE of 17.59 and a Sharpe value
    of 0.15\. Further restricting the trees' growth to `max_depth=1`, allows the model
    to achieve an MSE of 16.7 and a Sharpe value of 0.27\. If we examine the model's
    trading plots, we observe a reduction in the number of trades, as well as a considerable
    improvement in performance during periods in which Bitcoin's price significantly
    drops. This indicates that the model can filter noise from actual signals more
    efficiently.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进一步改进自助法，因为它的表现比任何之前的模型都差。首先，我们可以尝试浅层决策树，这将进一步减少集成中的方差。通过使用最大深度为`3`的决策树，使用`lr
    = BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=3))`，我们可以改进模型的性能，得到16.17的均方误差（MSE）和0.15的夏普比率。进一步将树的生长限制为`max_depth=1`，可以使模型达到16.7的MSE和0.27的夏普比率。如果我们检查模型的交易图，我们会观察到交易数量的减少，以及在比特币价格大幅下跌的时期性能的显著改善。这表明该模型能够更有效地*从实际信号中过滤噪声*。
- en: 'The reduction in variance has indeed helped our model to improve its performance:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 方差的减少确实帮助了我们的模型提高了性能：
- en: '![](img/acf5e8a5-4203-4c40-a5d2-ce2033618a61.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/acf5e8a5-4203-4c40-a5d2-ce2033618a61.png)'
- en: Final Bagging profits and trades
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最终自助法的利润和交易
- en: 'The following table summarizes the results for the various bagging models we
    tested:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 下表总结了我们测试的各种袋装模型的结果：
- en: '| **Metric** | **DT_max_depth=1** | **DT_max_depth=3** | **DT** |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| **指标** | **DT_max_depth=1** | **DT_max_depth=3** | **DT** |'
- en: '| **MSE** | 16.70 | 17.59 | 19.45 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| **MSE** | 16.70 | 17.59 | 19.45 |'
- en: '| **Sharpe** | 0.27 | 0.15 | 0.09 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| **Sharpe** | 0.27 | 0.15 | 0.09 |'
- en: 'Table 3: Bagging results'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：袋装结果
- en: Boosting
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升
- en: One of the most powerful ensemble learning techniques is boosting. It allows
    complicated models to be generated. In this section, we will utilize XGBoost to
    model our time series data. As there are many degrees of freedom (hyperparameters)
    when modeling with XGBoost, we expect some level of fine-tuning to be needed to
    achieve satisfactory results. By replacing our example's regressor with `lr =
    XGBRegressor()`, we can utilize XGBoost and fit it onto our data. This results
    in an MSE of 19.20 and a Sharpe value of 0.13.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最强大的集成学习技术之一是提升。它能够生成复杂的模型。在本节中，我们将利用XGBoost来建模我们的时间序列数据。由于在使用XGBoost建模时有许多自由度（超参数），我们预计需要一些微调才能取得令人满意的结果。通过将示例中的回归器替换为`lr
    = XGBRegressor()`，我们可以使用XGBoost并将其拟合到我们的数据上。这将产生一个MSE为19.20，Sharpe值为0.13的结果。
- en: 'Figure depicts the profits and trades generated by the model. Although the
    Sharpe value is lower than for other models, we can see that it continues to generate
    profit, even during periods in which the Bitcoin price drops:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图表展示了模型生成的利润和交易。虽然Sharpe值低于其他模型，但我们可以看到，即使在比特币价格下跌的时期，它仍然能持续生成利润：
- en: '![](img/27b520e4-28f1-4251-b82c-50d9b794fc52.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/27b520e4-28f1-4251-b82c-50d9b794fc52.png)'
- en: Trades generated by the Boosting model
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 由提升模型生成的交易
- en: Improving boosting
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进提升方法
- en: Due to the out-of-sample performance and the frequency at which boosting is
    bought and sold, we can assume it is overfitting the training data. Therefore,
    we'll will try to regularize its learning. The first step is to limit the maximum
    depth of individual trees. We start by imposing an upper limit of 2, using `max_depth=2`.
    This slightly improves our model, yielding an MSE of 19.14 and a Sharpe value
    of 0.17\. Further limiting the overfitting capabilities of the model by using
    only 10 base learners (`n_estimators=10`), the model achieves additional improvement.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 由于样本外的表现以及提升模型的买入和卖出频率，我们可以假设它在训练数据上发生了过拟合。因此，我们将尝试对其学习进行正则化。第一步是限制单个树的最大深度。我们首先施加一个上限为2的限制，使用`max_depth=2`。这略微改善了我们的模型，得到了一个MSE值为19.14，Sharpe值为0.17。通过进一步限制模型的过拟合能力，仅使用10个基学习器（`n_estimators=10`），模型进一步得到了提升。
- en: 'The MSE of the model is reduced to 16.39 and the Sharpe value is increased
    to 0.21\. Adding an L1 regularization term of 0.5 (`reg_alpha=0.5`) only reduces
    the MSE to 16.37\. We have come to a point where further fine-tuning will not
    contribute much performance to our model. At this point, our regressor looks like
    this:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的MSE降低至16.39，Sharpe值提高至0.21。添加一个L1正则化项0.5（`reg_alpha=0.5`）只将MSE减少至16.37。我们已经到了一个点，进一步的微调不会对模型性能贡献太大。在这个阶段，我们的回归模型如下所示：
- en: '[PRE13]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Given the capabilities of XGBoost, we will try to increase the amount of information
    available to the model. We will increase the available feature lags to 30 and
    add a rolling mean of the previous 15 lags to the features. To do this, we modify
    the feature creation section of the code as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于XGBoost的能力，我们将尝试增加模型可用的信息量。我们将把可用特征滞后增加到30，并将之前15个滞后的滚动均值添加到特征中。为此，我们将修改代码中的特征创建部分，如下所示：
- en: '[PRE14]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This increases the trading performance of our model, achieving a Sharpe value
    of 0.32—the highest of all of the models, while it also increases its MSE to 16.78\.
    The trades generated by this model are depicted in figure and in the table that
    follows. It is interesting to note that the number of buys has greatly reduced,
    a behavior that bagging also exhibited when we managed to improve its performance
    as an investment strategy:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这增加了我们模型的交易表现，达到了0.32的Sharpe值——所有模型中最高，同时MSE也增加到了16.78。此模型生成的交易如图和后续的表格所示。值得注意的是，买入的次数大大减少，这种行为也是袋装方法在我们改进其作为投资策略时所展现的：
- en: '![](img/0e1ed186-97e3-4188-bddb-daf4bd6207c1.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0e1ed186-97e3-4188-bddb-daf4bd6207c1.png)'
- en: Final boosting model performance
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最终提升模型性能
- en: '| **Metric** | **md=2/ne=10/reg=0.5+data** | **md=2/ne=10/reg=0.5** | **md=2/ne=10**
    | **md=2** | **xgb** |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| **指标** | **md=2/ne=10/reg=0.5+data** | **md=2/ne=10/reg=0.5** | **md=2/ne=10**
    | **md=2** | **xgb** |'
- en: '| **MSE** | 16.78 | 16.37 | 16.39 | 19.14 | 19.20 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| **MSE** | 16.78 | 16.37 | 16.39 | 19.14 | 19.20 |'
- en: '| **Sharpe** | 0.32 | 0.21 | 0.21 | 0.17 | 0.13 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| **Sharpe** | 0.32 | 0.21 | 0.21 | 0.17 | 0.13 |'
- en: Metrics for all boosting models
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 所有增强模型的度量
- en: Random forests
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林
- en: Finally, we will utilize random forests to model our data. Although we expect
    that the ensemble to be able to utilize the information from additional lags and
    the rolling average, we will start with only 20 lags and the return percentages
    as inputs. Thus, our initial regressor is simply `RandomForestRegressor()`. This
    results in a model that does not perform very well. Its MSE is 19.02 and its Sharpe
    value is 0.11.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用随机森林来建模数据。尽管我们预计集成方法能够利用额外滞后期和滚动平均的所有信息，但我们将首先仅使用20个滞后期和回报百分比作为输入。因此，我们的初始回归器仅为`RandomForestRegressor()`。这导致了一个表现不太理想的模型，MSE为19.02，Sharpe值为0.11。
- en: 'The following figure depicts the trades that the model generates:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了模型生成的交易：
- en: '![](img/7b9348f6-e878-4eb9-befc-ce907de295e9.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7b9348f6-e878-4eb9-befc-ce907de295e9.png)'
- en: Trades of random forest model
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林模型的交易
- en: Improving random forest
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进随机森林
- en: 'In an attempt to improve our model, we try to restrict its overfitting capabilities,
    imposing a maximum depth of `3` for each tree. This results in considerable performance
    improvement as the model achieves an MSE of 17.42 and a Sharpe value of 0.17\.
    Further restricting the maximum depth to `2` improves the MSE score slightly more
    to 17.13, but reduces its Sharpe value to 0.16\. Finally, increasing the ensemble''s
    size to 50, using `n_estimators=50`, produces a considerably better model, with
    an MSE of 16.88 and a Sharpe value of 0.23\. As we have only used the original
    feature set (20 lags of return percentages), we wish to also experiment with the
    expanded dataset we utilized in the boosting section. By adding the 15-day rolling
    average, as well as increasing the number of available lags to 30, the model can
    increase its Sharpe value to 0.24, although its MSE also increases to 18.31\.
    The trades generated by the model are depicted in figure:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改进我们的模型，我们尝试限制其过拟合能力，给每棵树设置最大深度为`3`。这大大提高了模型的性能，模型达到了MSE值为17.42和Sharpe值为0.17。进一步将最大深度限制为`2`，虽然使MSE得分稍微提高到17.13，但Sharpe值下降至0.16。最后，将集成模型的大小增加到50，使用`n_estimators=50`，生成了一个性能大幅提升的模型，MSE为16.88，Sharpe值为0.23。由于我们仅使用了原始特征集（20个回报百分比的滞后期），我们希望尝试在增强部分使用的扩展数据集。通过添加15日滚动平均值，并将可用滞后期数量增加到30，模型的Sharpe值提高到0.24，尽管MSE也上升到18.31。模型生成的交易如图所示：
- en: '![](img/8b6ca443-a5e6-4393-abba-2496fe75180d.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b6ca443-a5e6-4393-abba-2496fe75180d.png)'
- en: Random forest's results with the expanded dataset
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用扩展数据集的随机森林结果
- en: 'The model''s results are summarized in the following table:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的结果总结如下表：
- en: '| **Metric** | **md=2/ne=50+data** | **md=2/ne=50** | **md=2** | **md=3** |
    **RF** |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| **Metric** | **md=2/ne=50+data** | **md=2/ne=50** | **md=2** | **md=3** |
    **RF** |'
- en: '| **MSE** | 18.31 | 16.88 | 17.13 | 17.42 | 19.02 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| **MSE** | 18.31 | 16.88 | 17.13 | 17.42 | 19.02 |'
- en: '| **Sharpe** | 0.24 | 0.23 | 0.16 | 0.17 | 0.11 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| **Sharpe** | 0.24 | 0.23 | 0.16 | 0.17 | 0.11 |'
- en: Metrics for all random forest models
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 所有随机森林模型的度量
- en: Summary
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we tried to model historical Bitcoin prices using all of the
    ensemble methods presented in earlier chapters of this book. As with most datasets,
    there are many decisions that affect a model's quality. Data preprocessing and
    feature engineering are some of the most important factors, especially when the
    dataset's nature does not allow direct modeling of the data. Time series datasets
    fall into this category, in which the construction of appropriate features and
    targets is required. By transforming our non-stationary time series to stationary,
    we improved the algorithm's ability to model the data.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们尝试使用本书前几章介绍的所有集成方法来建模历史比特币价格。与大多数数据集一样，模型质量受多种决策的影响。数据预处理和特征工程是其中最重要的因素，尤其是当数据集的性质不允许直接建模时。时间序列数据集就属于这种情况，需要构建适当的特征和目标。通过将我们的非平稳时间序列转化为平稳序列，我们提高了算法对数据建模的能力。
- en: To assess the quality of our models, we used the MSE of return percentages,
    as well as the Sharpe ratio (in which we assumed that the model was utilized as
    a trading strategy). When MSE is concerned, the best performing ensemble proved
    to be the simple voting ensemble. The ensemble consisted of an SVM and KNN regressor,
    without any hyperparameter fine-tuning, achieving an MSE of 15.71\. As a trading
    strategy, XGBoost proved to be the best ensemble, achieving a Sharpe value of
    0.32\. Although not exhaustive, this chapter has explored the possibilities and
    techniques used in time series modeling using ensemble learning methods.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估我们模型的质量，我们使用了收益百分比的均方误差（MSE），以及夏普比率（我们假设模型被用作交易策略）。在涉及到MSE时，表现最佳的集成模型是简单投票集成。该集成包括一个SVM和KNN回归器，没有进行超参数调优，实现了一个MSE值为15.71。作为交易策略，XGBoost被证明是最佳集成模型，实现了一个夏普值为0.32。尽管不全面，本章探索了使用集成学习方法进行时间序列建模的可能性和技术。
- en: In the next chapter, we will leverage the capabilities of ensemble learning
    methods, in order to predict the sentiment of various tweets.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将利用集成学习方法的能力，以预测各种推特的情感。
