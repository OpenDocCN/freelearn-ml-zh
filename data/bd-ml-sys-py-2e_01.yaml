- en: Chapter 1. Getting Started with Python Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章. Python机器学习入门
- en: Machine learning teaches machines to learn to carry out tasks by themselves.
    It is that simple. The complexity comes with the details, and that is most likely
    the reason you are reading this book.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习教会机器自主完成任务。就这么简单。复杂性体现在细节上，而这很可能是你正在阅读本书的原因。
- en: 'Maybe you have too much data and too little insight. You hope that using machine
    learning algorithms you can solve this challenge, so you started digging into
    the algorithms. But after some time you were puzzled: Which of the myriad of algorithms
    should you actually choose?'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 或许你有太多的数据，却缺乏足够的洞察力。你希望通过使用机器学习算法来解决这个挑战，于是你开始深入研究这些算法。但经过一段时间后，你感到困惑：你到底应该选择哪一种成千上万的算法？
- en: 'Alternatively, maybe you are in general interested in machine learning and
    for some time you have been reading blogs and articles about it. Everything seemed
    to be magic and cool, so you started your exploration and fed some toy data into
    a decision tree or a support vector machine. However, after you successfully applied
    it to some other data, you wondered: Was the whole setting right? Did you get
    the optimal results? And how do you know whether there are no better algorithms?
    Or whether your data was the right one?'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，也许你对机器学习总体感兴趣，一段时间以来一直在阅读相关的博客和文章。一切看起来都像是魔法和酷炫的东西，于是你开始了探索，并将一些玩具数据输入到决策树或支持向量机中。然而，在成功应用它到一些其他数据后，你开始疑惑：整个设置是正确的吗？你得到了最优的结果吗？你怎么知道是否没有更好的算法？或者你的数据是正确的吗？
- en: Welcome to the club! Both of us (authors) were at those stages looking for information
    that tells the stories behind the theoretical textbooks about machine learning.
    It turned out that much of that information was "black art" not usually taught
    in standard text books. So in a sense, we wrote this book to our younger selves.
    A book that not only gives a quick introduction into machine learning, but also
    teaches lessons we learned along the way. We hope that it will also give you a
    smoother entry to one of the most exciting fields in Computer Science.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎加入这个俱乐部！我们（作者）也曾处于那样的阶段，寻找一些能讲述机器学习理论教材背后故事的信息。事实证明，很多这些信息是“黑魔法”，通常不会在标准教科书中教授。所以从某种意义上来说，我们写这本书是为了我们年轻时的自己。这本书不仅提供了机器学习的快速入门介绍，还教会了我们一路上学到的经验教训。我们希望它能为你顺利进入计算机科学中最激动人心的领域之一提供帮助。
- en: Machine learning and Python – a dream team
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习和Python —— 一个梦幻组合
- en: The goal of machine learning is to teach machines (software) to carry out tasks
    by providing them a couple of examples (how to do or not do the task). Let's assume
    that each morning when you turn on your computer, you do the same task of moving
    e-mails around so that only e-mails belonging to the same topic end up in the
    same folder. After some time, you might feel bored and think of automating this
    chore. One way would be to start analyzing your brain and write down all rules
    your brain processes while you are shuffling your e-mails. However, this will
    be quite cumbersome and always imperfect. While you will miss some rules, you
    will over-specify others. A better and more future-proof way would be to automate
    this process by choosing a set of e-mail meta info and body/folder name pairs
    and let an algorithm come up with the best rule set. The pairs would be your training
    data, and the resulting rule set (also called model) could then be applied to
    future e-mails that we have not yet seen. This is machine learning in its simplest
    form.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的目标是通过提供一些示例（如何做或不做任务），来教会机器（软件）执行任务。假设每天早晨，当你打开电脑时，你都会做同样的任务，将电子邮件进行整理，以便只有属于同一主题的电子邮件会出现在同一个文件夹中。经过一段时间后，你可能会感到厌烦，并想要自动化这个繁琐的工作。一个方法是开始分析你的大脑，并写下你在整理电子邮件时处理的所有规则。然而，这会相当繁琐，并且永远不完美。在这个过程中，你会漏掉一些规则，或者过度指定其他规则。一个更好且更具未来适应性的方式是通过选择一组电子邮件元信息和正文/文件夹名称对来自动化这个过程，然后让一个算法得出最佳规则集。这些对就是你的训练数据，最终得到的规则集（也称为模型）可以应用于我们未曾见过的未来电子邮件。这就是最简单形式的机器学习。
- en: Of course, machine learning (often also referred to as Data Mining or Predictive
    Analysis) is not a brand new field in itself. Quite the contrary, its success
    over the recent years can be attributed to the pragmatic way of using rock-solid
    techniques and insights from other successful fields like statistics. There the
    purpose is for us humans to get insights into the data, for example, by learning
    more about the underlying patterns and relationships. As you read more and more
    about successful applications of machine learning (you have checked out [www.kaggle.com](http://www.kaggle.com)
    already, haven't you?), you will see that applied statistics is a common field
    among machine learning experts.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，机器学习（通常也称为数据挖掘或预测分析）本身并不是一个全新的领域。恰恰相反，它近年来的成功可以归因于将其他成功领域（如统计学）中的扎实技术和见解应用到实际中的务实方法。在统计学中，目的是帮助我们人类从数据中获取洞见，例如，通过了解潜在的模式和关系。随着你阅读越来越多关于机器学习成功应用的内容（你已经查看了[www.kaggle.com](http://www.kaggle.com)，对吧？），你会发现应用统计学在机器学习专家中是一个常见的领域。
- en: As you will see later, the process of coming up with a decent ML approach is
    never a waterfall-like process. Instead, you will see yourself going back and
    forth in your analysis, trying out different versions of your input data on diverse
    sets of ML algorithms. It is this explorative nature that lends itself perfectly
    to Python. Being an interpreted high-level programming language, it seems that
    Python has been designed exactly for this process of trying out different things.
    What is more, it does this even fast. Sure, it is slower than C or similar statically
    typed programming languages. Nevertheless, with the myriad of easy-to-use libraries
    that are often written in C, you don't have to sacrifice speed for agility.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你稍后会看到的，提出一个合适的机器学习方法的过程从来不是一个瀑布式的过程。相反，你会看到自己在分析中来回反复，不断尝试不同版本的输入数据和多种机器学习算法。正是这种探索性的特点使得
    Python 成为完美的选择。作为一种解释型高级编程语言，Python 看起来就是为这一过程而设计的，用于不断尝试不同的方式。更重要的是，它的执行速度也相当快。确实，它比
    C 或其他类似的静态类型编程语言慢，但由于有大量易于使用的库（许多都是用 C 编写的），你无需为灵活性牺牲速度。
- en: What the book will teach you (and what it will not)
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书将教你什么（以及不教你什么）
- en: 'This book will give you a broad overview of what types of learning algorithms
    are currently most used in the diverse fields of machine learning, and where to
    watch out when applying them. From our own experience, however, we know that doing
    the "cool" stuff, that is, using and tweaking machine learning algorithms such
    as support vector machines, nearest neighbor search, or ensembles thereof, will
    only consume a tiny fraction of the overall time of a good machine learning expert.
    Looking at the following typical workflow, we see that most of the time will be
    spent in rather mundane tasks:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将为你提供一个广泛的概述，介绍当前在机器学习各个领域中最常用的学习算法类型，以及在应用它们时需要注意的地方。然而，从我们的经验来看，我们知道，做一些“酷”的事情，也就是使用和调整像支持向量机、最近邻搜索或其集成算法等机器学习算法，只会消耗一个优秀机器学习专家时间的一小部分。通过观察下面的典型工作流程，我们看到大部分时间会花费在一些相对平凡的任务上：
- en: Reading in the data and cleaning it
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取数据并进行清洗
- en: Exploring and understanding the input data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索和理解输入数据
- en: Analyzing how best to present the data to the learning algorithm
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析如何最好地将数据呈现给学习算法
- en: Choosing the right model and learning algorithm
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择正确的模型和学习算法
- en: Measuring the performance correctly
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确衡量性能
- en: When talking about exploring and understanding the input data, we will need
    a bit of statistics and basic math. However, while doing that, you will see that
    those topics that seemed to be so dry in your math class can actually be really
    exciting when you use them to look at interesting data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到探索和理解输入数据时，我们将需要一些统计学和基础数学知识。然而，你会发现，在应用这些知识时，那些在数学课上看似枯燥的内容，实际上在用来观察有趣数据时会变得非常令人兴奋。
- en: The journey starts when you read in the data. When you have to answer questions
    such as how to handle invalid or missing values, you will see that this is more
    an art than a precise science. And a very rewarding one, as doing this part right
    will open your data to more machine learning algorithms and thus increase the
    likelihood of success.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 旅程从读取数据开始。当你需要回答如何处理无效或缺失值等问题时，你会发现这更像是一门艺术，而非精确的科学。这是一个非常有意义的过程，因为做对这一部分将使你的数据可以被更多的机器学习算法使用，从而提高成功的可能性。
- en: With the data being ready in your program's data structures, you will want to
    get a real feeling of what animal you are working with. Do you have enough data
    to answer your questions? If not, you might want to think about additional ways
    to get more of it. Do you even have too much data? Then you probably want to think
    about how best to extract a sample of it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据已经准备好并存在于程序的数据结构中时，你会希望对正在处理的数据有一个更直观的了解。你有足够的数据来回答你的问题吗？如果没有，你可能需要考虑其他方法来获得更多数据。你是否拥有过多的数据？那你可能需要考虑如何从中提取一个合适的样本。
- en: Often you will not feed the data directly into your machine learning algorithm.
    Instead you will find that you can refine parts of the data before training. Many
    times the machine learning algorithm will reward you with increased performance.
    You will even find that a simple algorithm with refined data generally outperforms
    a very sophisticated algorithm with raw data. This part of the machine learning
    workflow is called **feature engineering**, and is most of the time a very exciting
    and rewarding challenge. You will immediately see the results of being creative
    and intelligent.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你不会直接将数据输入到机器学习算法中。相反，你会发现你可以在训练之前对数据的某些部分进行优化。很多时候，机器学习算法会通过提升性能来回报你。你甚至会发现，经过优化的数据所使用的简单算法通常比使用原始数据的复杂算法表现更好。机器学习工作流中的这一部分被称为**特征工程**，它通常是一个非常令人兴奋且有回报的挑战。你会立刻看到创意和智慧所带来的成果。
- en: Choosing the right learning algorithm, then, is not simply a shootout of the
    three or four that are in your toolbox (there will be more you will see). It is
    more a thoughtful process of weighing different performance and functional requirements.
    Do you need a fast result and are willing to sacrifice quality? Or would you rather
    spend more time to get the best possible result? Do you have a clear idea of the
    future data or should you be a bit more conservative on that side?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 选择正确的学习算法并不仅仅是从你工具箱中选择三四个算法进行比较（你将会看到更多的选择）。这更像是一个深思熟虑的过程，需要权衡不同的性能和功能需求。你是否需要快速的结果并愿意牺牲质量？还是你宁愿花更多时间以获得尽可能最好的结果？你是否对未来的数据有明确的想法，还是应该在这方面保持更保守一些？
- en: Finally, measuring the performance is the part where most mistakes are waiting
    for the aspiring machine learner. There are easy ones, such as testing your approach
    with the same data on which you have trained. But there are more difficult ones,
    when you have imbalanced training data. Again, data is the part that determines
    whether your undertaking will fail or succeed.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，衡量性能是大多数机器学习新手容易犯错的地方。有一些错误是简单的，比如用训练数据来测试你的方法。但也有更复杂的错误，尤其是当你有不平衡的训练数据时。同样，数据是决定你尝试是否成功的关键部分。
- en: We see that only the fourth point is dealing with the fancy algorithms. Nevertheless,
    we hope that this book will convince you that the other four tasks are not simply
    chores, but can be equally exciting. Our hope is that by the end of the book,
    you will have truly fallen in love with data instead of learning algorithms.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到只有第四点涉及到复杂的算法。尽管如此，我们希望这本书能够说服你，其他四个任务不仅仅是日常琐事，它们同样可以令人兴奋。我们的希望是，到书的最后，你会真正爱上数据，而不仅仅是学习算法。
- en: To that end, we will not overwhelm you with the theoretical aspects of the diverse
    ML algorithms, as there are already excellent books in that area (you will find
    pointers in the Appendix). Instead, we will try to provide an intuition of the
    underlying approaches in the individual chapters—just enough for you to get the
    idea and be able to undertake your first steps. Hence, this book is by no means
    *the definitive guide* to machine learning. It is more of a starter kit. We hope
    that it ignites your curiosity enough to keep you eager in trying to learn more
    and more about this interesting field.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们不会给你带来过多的理论性内容，关于各种机器学习算法的优秀书籍已经涵盖了这些内容（你可以在附录中找到相关书目）。相反，我们将尽力在每个章节中提供对基本方法的直观理解——只需让你了解基本概念，并能够迈出第一步。因此，这本书绝非*机器学习的终极指南*。它更像是一个入门工具包。我们希望它能激发你的好奇心，让你迫不及待地去学习更多关于这个有趣领域的知识。
- en: In the rest of this chapter, we will set up and get to know the basic Python
    libraries NumPy and SciPy and then train our first machine learning using scikit-learn.
    During that endeavor, we will introduce basic ML concepts that will be used throughout
    the book. The rest of the chapters will then go into more detail through the five
    steps described earlier, highlighting different aspects of machine learning in
    Python using diverse application scenarios.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将设置并了解基本的 Python 库 NumPy 和 SciPy，然后使用 scikit-learn 训练我们的第一个机器学习模型。在这个过程中，我们将介绍一些基本的机器学习概念，这些概念将在整本书中使用。接下来的章节将通过前面提到的五个步骤，详细介绍使用
    Python 进行机器学习的不同方面，并结合不同的应用场景。
- en: What to do when you are stuck
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当你遇到困境时该怎么办
- en: We try to convey every idea necessary to reproduce the steps throughout this
    book. Nevertheless, there will be situations where you are stuck. The reasons
    might range from simple typos over odd combinations of package versions to problems
    in understanding.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尽力传达书中每个步骤所需的思想。然而，仍然会有一些情况让你卡住。原因可能从简单的拼写错误、奇怪的包版本组合到理解问题不一而足。
- en: 'In this situation, there are many different ways to get help. Most likely,
    your problem will already be raised and solved in the following excellent Q&A
    sites:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，有很多不同的方式可以获得帮助。很可能，你的问题已经在以下优秀的问答网站中提出并得到解决：
- en: '[http://metaoptimize.com/qa](http://metaoptimize.com/qa): This Q&A site is
    laser-focused on machine learning topics. For almost every question, it contains
    above average answers from machine learning experts. Even if you don''t have any
    questions, it is a good habit to check it out every now and then and read through
    some of the answers.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://metaoptimize.com/qa](http://metaoptimize.com/qa)：这个问答网站专注于机器学习话题。几乎每个问题都包含来自机器学习专家的超出平均水平的回答。即使你没有任何问题，偶尔去浏览一下，阅读一些回答也是一个好习惯。'
- en: '[http://stats.stackexchange.com](http://stats.stackexchange.com): This Q&A
    site is named Cross Validated, similar to MetaOptimize, but is focused more on
    statistical problems.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://stats.stackexchange.com](http://stats.stackexchange.com)：这个问答网站名为 Cross
    Validated，类似于 MetaOptimize，但更侧重于统计学问题。'
- en: '[http://stackoverflow.com](http://stackoverflow.com): This Q&A site is much
    like the previous ones, but with broader focus on general programming topics.
    It contains, for example, more questions on some of the packages that we will
    use in this book, such as SciPy or matplotlib.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://stackoverflow.com](http://stackoverflow.com)：这个问答网站和前面提到的类似，但它的焦点更广，涵盖了通用的编程话题。例如，它包含了我们在本书中将使用的一些包的问题，比如
    SciPy 或 matplotlib。'
- en: '`#machinelearning` on [https://freenode.net/](https://freenode.net/): This
    is the IRC channel focused on machine learning topics. It is a small but very
    active and helpful community of machine learning experts.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [https://freenode.net/](https://freenode.net/) 上的 `#machinelearning`：这是一个专注于机器学习话题的IRC频道。它是一个规模较小但非常活跃且乐于助人的机器学习专家社区。
- en: '[http://www.TwoToReal.com](http://www.TwoToReal.com): This is the instant Q&A
    site written by the authors to support you in topics that don''t fit in any of
    the preceding buckets. If you post your question, one of the authors will get
    an instant message if he is online and be drawn in a chat with you.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.TwoToReal.com](http://www.TwoToReal.com)：这是作者们创建的即时问答网站，旨在帮助你解决不适合前面所列类别的主题。如果你发布问题，作者中的一位如果在线，将会立即收到消息，并与你进行在线聊天。'
- en: As stated in the beginning, this book tries to help you get started quickly
    on your machine learning journey. Therefore, we highly encourage you to build
    up your own list of machine learning related blogs and check them out regularly.
    This is the best way to get to know what works and what doesn't.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如同一开始所述，本书试图帮助你快速入门机器学习。因此，我们强烈鼓励你建立自己的机器学习相关博客列表，并定期查看。这是了解什么有效、什么无效的最佳方式。
- en: The only blog we want to highlight right here (more in the Appendix) is [http://blog.kaggle.com](http://blog.kaggle.com),
    the blog of the Kaggle company, which is carrying out machine learning competitions.
    Typically, they encourage the winners of the competitions to write down how they
    approached the competition, what strategies did not work, and how they arrived
    at the winning strategy. Even if you don't read anything else, this is a must.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里想特别提到的唯一一个博客（更多内容见附录）是 [http://blog.kaggle.com](http://blog.kaggle.com)，这是
    Kaggle 公司的博客，Kaggle 正在进行机器学习竞赛。通常，他们会鼓励竞赛的获胜者写下他们是如何接近竞赛的，哪些策略行不通，以及他们是如何得出获胜策略的。即使你不阅读其他任何内容，这也是必读的。
- en: Getting started
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始
- en: Assuming that you have Python already installed (everything at least as recent
    as 2.7 should be fine), we need to install NumPy and SciPy for numerical operations,
    as well as matplotlib for visualization.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你已经安装了Python（至少是2.7及更新版本应该没问题），接下来我们需要安装NumPy和SciPy进行数值运算，以及安装matplotlib用于可视化。
- en: Introduction to NumPy, SciPy, and matplotlib
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NumPy、SciPy和matplotlib简介
- en: Before we can talk about concrete machine learning algorithms, we have to talk
    about how best to store the data we will chew through. This is important as the
    most advanced learning algorithm will not be of any help to us if it will never
    finish. This may be simply because accessing the data is too slow. Or maybe its
    representation forces the operating system to swap all day. Add to this that Python
    is an interpreted language (a highly optimized one, though) that is slow for many
    numerically heavy algorithms compared to C or FORTRAN. So we might ask why on
    earth so many scientists and companies are betting their fortune on Python even
    in highly computation-intensive areas?
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论具体的机器学习算法之前，必须先讨论如何最好地存储我们需要处理的数据。这很重要，因为即使是最先进的学习算法，如果永远无法完成，也对我们没有任何帮助。这可能是因为数据访问速度过慢，或者它的表示形式迫使操作系统整天进行交换。再加上Python是解释型语言（尽管它是高度优化的），在许多数值计算密集型算法中，相比于C或FORTRAN，它运行较慢。那么，我们不禁要问，为什么那么多科学家和公司在高度计算密集的领域依然押注Python呢？
- en: The answer is that, in Python, it is very easy to off-load number crunching
    tasks to the lower layer in the form of C or FORTRAN extensions. And that is exactly
    what NumPy and SciPy do ([http://scipy.org/Download](http://scipy.org/Download)).
    In this tandem, NumPy provides the support of highly optimized multidimensional
    arrays, which are the basic data structure of most state-of-the-art algorithms.
    SciPy uses those arrays to provide a set of fast numerical recipes. Finally, matplotlib
    ([http://matplotlib.org/](http://matplotlib.org/)) is probably the most convenient
    and feature-rich library to plot high-quality graphs using Python.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是，在Python中，将数字运算任务转交给低层的C或FORTRAN扩展是非常容易的。而这正是NumPy和SciPy的作用所在（[http://scipy.org/Download](http://scipy.org/Download)）。在这个配合下，NumPy提供了高度优化的多维数组支持，这些数组是大多数先进算法的基本数据结构。SciPy利用这些数组提供了一组快速的数值算法。最后，matplotlib（[http://matplotlib.org/](http://matplotlib.org/)）可能是使用Python绘制高质量图形最便捷且功能最丰富的库。
- en: Installing Python
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装Python
- en: Luckily, for all major operating systems, that is, Windows, Mac, and Linux,
    there are targeted installers for NumPy, SciPy, and matplotlib. If you are unsure
    about the installation process, you might want to install Anaconda Python distribution
    (which you can access at [https://store.continuum.io/cshop/anaconda/](https://store.continuum.io/cshop/anaconda/)),
    which is driven by Travis Oliphant, a founding contributor of SciPy. What sets
    Anaconda apart from other distributions such as Enthought Canopy (which you can
    download from [https://www.enthought.com/downloads/](https://www.enthought.com/downloads/))
    or Python(x,y) (accessible at [http://code.google.com/p/pythonxy/wiki/Downloads](http://code.google.com/p/pythonxy/wiki/Downloads)),
    is that Anaconda is already fully Python 3 compatible—the Python version we will
    be using throughout the book.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，对于所有主要的操作系统——即Windows、Mac和Linux——都有针对NumPy、SciPy和matplotlib的专用安装包。如果你不确定安装过程，可以考虑安装Anaconda
    Python发行版（可以通过[https://store.continuum.io/cshop/anaconda/](https://store.continuum.io/cshop/anaconda/)访问），该发行版由SciPy的创始贡献者Travis
    Oliphant主导。Anaconda与其他发行版（如Enthought Canopy，下载地址：[https://www.enthought.com/downloads/](https://www.enthought.com/downloads/)）或Python(x,y)（访问地址：[http://code.google.com/p/pythonxy/wiki/Downloads](http://code.google.com/p/pythonxy/wiki/Downloads)）的不同之处在于，Anaconda已经完全兼容Python
    3——这是我们将在本书中使用的Python版本。
- en: Chewing data efficiently with NumPy and intelligently with SciPy
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用NumPy高效处理数据，并使用SciPy智能处理
- en: Let's walk quickly through some basic NumPy examples and then take a look at
    what SciPy provides on top of it. On the way, we will get our feet wet with plotting
    using the marvelous Matplotlib package.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速浏览一些基本的NumPy示例，然后看看SciPy在其基础上提供了什么。在这个过程中，我们将借助精彩的Matplotlib包进行绘图，迈出第一步。
- en: For an in-depth explanation, you might want to take a look at some of the more
    interesting examples of what NumPy has to offer at [http://www.scipy.org/Tentative_NumPy_Tutorial](http://www.scipy.org/Tentative_NumPy_Tutorial).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要深入了解，你可能想看看NumPy提供的一些更有趣的示例，访问[http://www.scipy.org/Tentative_NumPy_Tutorial](http://www.scipy.org/Tentative_NumPy_Tutorial)。
- en: You will also find the *NumPy Beginner's Guide - Second Edition*, *Ivan Idris*,
    by Packt Publishing, to be very valuable. Additional tutorial style guides can
    be found at [http://scipy-lectures.github.com](http://scipy-lectures.github.com),
    and the official SciPy tutorial at [http://docs.scipy.org/doc/scipy/reference/tutorial](http://docs.scipy.org/doc/scipy/reference/tutorial).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你还会发现 *NumPy 初学者指南 - 第二版*，*Ivan Idris*，由 Packt Publishing 出版，非常有价值。更多的教程风格指南可以在
    [http://scipy-lectures.github.com](http://scipy-lectures.github.com) 找到，官方的 SciPy
    教程请访问 [http://docs.scipy.org/doc/scipy/reference/tutorial](http://docs.scipy.org/doc/scipy/reference/tutorial)。
- en: Note
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: In this book, we will use NumPy in version 1.8.1 and SciPy in version 0.14.0.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中，我们将使用版本 1.8.1 的 NumPy 和版本 0.14.0 的 SciPy。
- en: Learning NumPy
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习 NumPy
- en: 'So let''s import NumPy and play a bit with it. For that, we need to start the
    Python interactive shell:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们导入 NumPy 并稍微玩一下它。为此，我们需要启动 Python 交互式 shell：
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'As we do not want to pollute our namespace, we certainly should not use the
    following code:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不想污染我们的命名空间，当然不应该使用以下代码：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Because, for instance, `numpy.array` will potentially shadow the array package
    that is included in standard Python. Instead, we will use the following convenient
    shortcut:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 因为例如，`numpy.array` 可能会与标准 Python 中包含的数组包发生冲突。因此，我们将使用以下方便的快捷方式：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: So, we just created an array like we would create a list in Python. However,
    the NumPy arrays have additional information about the shape. In this case, it
    is a one-dimensional array of six elements. No surprise so far.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们刚刚创建了一个数组，就像我们在 Python 中创建一个列表一样。然而，NumPy 数组有额外的形状信息。在这个例子中，它是一个包含六个元素的一维数组，到目前为止没什么意外。
- en: 'We can now transform this array to a two-dimensional matrix:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以将这个数组转换为一个二维矩阵：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The funny thing starts when we realize just how much the NumPy package is optimized.
    For example, doing this avoids copies wherever possible:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的事情发生在我们意识到 NumPy 包的优化程度时。例如，执行这一步可以尽可能避免复制：
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In this case, we have modified value `2` to `77` in `b`, and immediately see
    the same change reflected in `a` as well. Keep in mind that whenever you need
    a true copy, you can always perform:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将 `b` 中的值 `2` 修改为 `77`，并立即看到 `a` 中也反映了相同的变化。请记住，任何时候你需要一个真正的副本时，可以随时执行：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note that here, `c` and `a` are totally independent copies.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`c` 和 `a` 是完全独立的副本。
- en: 'Another big advantage of NumPy arrays is that the operations are propagated
    to the individual elements. For example, multiplying a NumPy array will result
    in an array of the same size with all of its elements being multiplied:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 数组的另一个大优点是操作会传播到各个元素。例如，乘以一个 NumPy 数组将生成一个与原数组大小相同的新数组，所有元素都被相乘：
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Similarly, for other operations:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，对于其他操作：
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Contrast that to ordinary Python lists:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 将其与普通的 Python 列表进行对比：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Of course by using NumPy arrays, we sacrifice the agility Python lists offer.
    Simple operations such as adding or removing are a bit complex for NumPy arrays.
    Luckily, we have both at our hands and we will use the right one for the task
    at hand.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，使用 NumPy 数组时，我们牺牲了 Python 列表所提供的灵活性。像添加或移除这样的简单操作对于 NumPy 数组来说稍显复杂。幸运的是，我们手头有两者，并且可以根据实际任务使用合适的工具。
- en: Indexing
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 索引
- en: Part of the power of NumPy comes from the versatile ways in which its arrays
    can be accessed.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 的一大优势来自于其数组的多种访问方式。
- en: 'In addition to normal list indexing, it allows you to use arrays themselves
    as indices by performing:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 除了常规的列表索引外，它还允许你使用数组本身作为索引，方法是执行：
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Together with the fact that conditions are also propagated to individual elements,
    we gain a very convenient way to access our data:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 结合条件也会传播到各个元素这一事实，我们获得了一种非常方便的方式来访问数据：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'By performing the following command, this can be used to trim outliers:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行以下命令，可以用来修剪异常值：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As this is a frequent use case, there is the special clip function for it,
    clipping the values at both ends of an interval with one function call:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个常见的用例，因此有一个专门的裁剪函数来处理它，可以通过一次函数调用将值限制在区间的两端：
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Handling nonexisting values
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理不存在的值
- en: 'The power of NumPy''s indexing capabilities comes in handy when preprocessing
    data that we have just read in from a text file. Most likely, that will contain
    invalid values that we will mark as not being a real number using `numpy.NAN`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 强大的索引功能在处理我们刚从文本文件中读取的数据时非常有用。通常，这些数据会包含无效值，我们可以使用 `numpy.NAN` 来标记它们为非真实数字：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Comparing the runtime
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 比较运行时间
- en: Let's compare the runtime behavior of NumPy compared with normal Python lists.
    In the following code, we will calculate the sum of all squared numbers from 1
    to 1000 and see how much time it will take. We perform it 10,000 times and report
    the total time so that our measurement is accurate enough.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较一下NumPy和普通Python列表的运行时行为。在以下代码中，我们将计算从1到1000的所有平方数之和，并查看需要多少时间。我们执行10,000次，并报告总时间，以确保我们的测量足够准确。
- en: '[PRE14]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We make two interesting observations. Firstly, by just using NumPy as data
    storage (Naive NumPy) takes 3.5 times longer, which is surprising since we believe
    it must be much faster as it is written as a C extension. One reason for this
    is that the access of individual elements from Python itself is rather costly.
    Only when we are able to apply algorithms inside the optimized extension code
    is when we get speed improvements. The other observation is quite a tremendous
    one: using the `dot()` function of NumPy, which does exactly the same, allows
    us to be more than 25 times faster. In summary, in every algorithm we are about
    to implement, we should always look how we can move loops over individual elements
    from Python to some of the highly optimized NumPy or SciPy extension functions.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们做出了两个有趣的观察。首先，仅仅将NumPy作为数据存储（朴素的NumPy）就花费了3.5倍的时间，这令人惊讶，因为我们原以为它应该更快，因为它是作为C扩展写的。一个原因是从Python本身访问单个元素是非常昂贵的。只有当我们能够在优化过的扩展代码中应用算法时，才会获得速度的提升。另一个观察是相当令人震惊的：使用NumPy的`dot()`函数，尽管它做的是完全相同的事情，却让我们的速度提高了25倍以上。总之，在我们即将实现的每一个算法中，我们都应该始终检查如何将Python中的单个元素循环转移到一些高度优化的NumPy或SciPy扩展函数中。
- en: However, the speed comes at a price. Using NumPy arrays, we no longer have the
    incredible flexibility of Python lists, which can hold basically anything. NumPy
    arrays always have only one data type.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种速度是有代价的。使用NumPy数组时，我们不再拥有Python列表那种几乎可以存储任何东西的极大灵活性。NumPy数组始终只有一种数据类型。
- en: '[PRE15]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'If we try to use elements of different types, such as the ones shown in the
    following code, NumPy will do its best to coerce them to be the most reasonable
    common data type:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试使用不同类型的元素，如以下代码所示，NumPy会尽力将它们转换为最合理的公共数据类型：
- en: '[PRE16]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Learning SciPy
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习SciPy
- en: On top of the efficient data structures of NumPy, SciPy offers a magnitude of
    algorithms working on those arrays. Whatever numerical heavy algorithm you take
    from current books on numerical recipes, most likely you will find support for
    them in SciPy in one way or the other. Whether it is matrix manipulation, linear
    algebra, optimization, clustering, spatial operations, or even fast Fourier transformation,
    the toolbox is readily filled. Therefore, it is a good habit to always inspect
    the `scipy` module before you start implementing a numerical algorithm.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在NumPy高效数据结构的基础上，SciPy提供了大量针对这些数组工作的算法。无论你从当前的数值计算书籍中挑选出哪种数值密集型算法，你很可能会以某种方式在SciPy中找到它的支持。无论是矩阵操作、线性代数、优化、聚类、空间操作，甚至是快速傅里叶变换，工具箱已经很充实。因此，在开始实现一个数值算法之前，养成检查`scipy`模块的好习惯。
- en: 'For convenience, the complete namespace of NumPy is also accessible via SciPy.
    So, from now on, we will use NumPy''s machinery via the SciPy namespace. You can
    check this easily comparing the function references of any base function, such
    as:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便，NumPy的完整命名空间也可以通过SciPy访问。所以，从现在开始，我们将通过SciPy命名空间使用NumPy的工具。你可以通过比较任何基本函数的函数引用轻松检查这一点，例如：
- en: '[PRE17]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The diverse algorithms are grouped into the following toolboxes:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这些多样化的算法被分组到以下工具箱中：
- en: '| SciPy packages | Functionalities |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| SciPy包 | 功能 |'
- en: '| --- | --- |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `cluster` |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `cluster` |'
- en: Hierarchical clustering (`cluster.hierarchy`)
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层次聚类（`cluster.hierarchy`）
- en: Vector quantization / k-means (`cluster.vq`)
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量量化 / k-means (`cluster.vq`)
- en: '|'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| `constants` |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| `constants` |'
- en: Physical and mathematical constants
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物理和数学常数
- en: Conversion methods
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换方法
- en: '|'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| `fftpack` | Discrete Fourier transform algorithms |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| `fftpack` | 离散傅里叶变换算法 |'
- en: '| `integrate` | Integration routines |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| `integrate` | 积分例程 |'
- en: '| `interpolate` | Interpolation (linear, cubic, and so on) |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| `interpolate` | 插值（线性插值、三次插值等） |'
- en: '| `io` | Data input and output |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| `io` | 数据输入和输出 |'
- en: '| `linalg` | Linear algebra routines using the optimized BLAS and LAPACK libraries
    |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| `linalg` | 使用优化过的BLAS和LAPACK库的线性代数例程 |'
- en: '| `ndimage` | *n*-dimensional image package |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| `ndimage` | *n*维图像包 |'
- en: '| `odr` | Orthogonal distance regression |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| `odr` | 正交距离回归 |'
- en: '| `optimize` | Optimization (finding minima and roots) |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| `optimize` | 优化（寻找最小值和根） |'
- en: '| `signal` | Signal processing |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| `signal` | 信号处理 |'
- en: '| `sparse` | Sparse matrices |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| `sparse` | 稀疏矩阵 |'
- en: '| `spatial` | Spatial data structures and algorithms |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| `spatial` | 空间数据结构和算法 |'
- en: '| `special` | Special mathematical functions such as Bessel or Jacobian |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| `special` | 特殊数学函数，如贝塞尔函数或雅可比函数 |'
- en: '| `stats` | Statistics toolkit |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| `stats` | 统计工具包 |'
- en: The toolboxes most interesting to our endeavor are `scipy.stats`, `scipy.interpolate`,
    `scipy.cluster`, and `scipy.signal`. For the sake of brevity, we will briefly
    explore some features of the stats package and leave the others to be explained
    when they show up in the individual chapters.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们工作最感兴趣的工具包是`scipy.stats`、`scipy.interpolate`、`scipy.cluster`和`scipy.signal`。为了简洁起见，我们将简要探索一下stats包的一些功能，其余的将在各个章节中介绍。
- en: Our first (tiny) application of machine learning
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们的第一个（微小的）机器学习应用
- en: Let's get our hands dirty and take a look at our hypothetical web start-up,
    MLaaS, which sells the service of providing machine learning algorithms via HTTP.
    With increasing success of our company, the demand for better infrastructure increases
    to serve all incoming web requests successfully. We don't want to allocate too
    many resources as that would be too costly. On the other side, we will lose money,
    if we have not reserved enough resources to serve all incoming requests. Now,
    the question is, when will we hit the limit of our current infrastructure, which
    we estimated to be at 100,000 requests per hour. We would like to know in advance
    when we have to request additional servers in the cloud to serve all the incoming
    requests successfully without paying for unused ones.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们动手操作，看看我们的假设性网络初创公司MLaaS，该公司通过HTTP提供机器学习算法服务。随着公司成功的不断增加，需求也在增长，需要更好的基础设施来成功地处理所有的网络请求。我们不希望分配过多资源，因为那样成本过高。另一方面，如果我们没有预留足够的资源来处理所有的请求，我们将会亏损。那么，问题来了，我们什么时候会达到当前基础设施的限制，我们预计这个限制是每小时100,000个请求。我们希望提前知道何时需要在云端申请更多的服务器，以便在不为未使用的资源付费的情况下，成功地处理所有传入请求。
- en: Reading in the data
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 读取数据
- en: We have collected the web stats for the last month and aggregated them in `ch01/data/web_traffic.tsv`
    (`.tsv` because it contains tab-separated values). They are stored as the number
    of hits per hour. Each line contains the hour consecutively and the number of
    web hits in that hour.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经收集了过去一个月的网络统计数据，并将其汇总在`ch01/data/web_traffic.tsv`中（`.tsv`因为它包含制表符分隔的值）。它们按每小时的点击次数存储。每行包含连续的小时和该小时的网页点击次数。
- en: 'The first few lines look like the following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 前几行如下所示：
- en: '![Reading in the data](img/2772OS_01_09.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![读取数据](img/2772OS_01_09.jpg)'
- en: 'Using SciPy''s `genfromtxt()`, we can easily read in the data using the following
    code:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SciPy的`genfromtxt()`，我们可以轻松地读取数据，代码如下：
- en: '[PRE18]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We have to specify tab as the delimiter so that the columns are correctly determined.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须指定制表符作为分隔符，以便正确地确定各列。
- en: 'A quick check shows that we have correctly read in the data:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 快速检查显示我们已经正确读取了数据：
- en: '[PRE19]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As you can see, we have 743 data points with two dimensions.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们有743个数据点，包含两个维度。
- en: Preprocessing and cleaning the data
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理和清理
- en: 'It is more convenient for SciPy to separate the dimensions into two vectors,
    each of size 743\. The first vector, `x`, will contain the hours, and the other,
    `y`, will contain the Web hits in that particular hour. This splitting is done
    using the special index notation of SciPy, by which we can choose the columns
    individually:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 对SciPy来说，将维度分成两个大小为743的向量更加方便。第一个向量`x`包含小时，另一个向量`y`包含该小时的网页点击数。这个拆分是通过SciPy的特殊索引表示法完成的，利用该方法我们可以单独选择列：
- en: '[PRE20]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: There are many more ways in which data can be selected from a SciPy array. Check
    out [http://www.scipy.org/Tentative_NumPy_Tutorial](http://www.scipy.org/Tentative_NumPy_Tutorial)
    for more details on indexing, slicing, and iterating.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 从SciPy数组中选择数据有很多方法。有关索引、切片和迭代的更多细节，请查看[http://www.scipy.org/Tentative_NumPy_Tutorial](http://www.scipy.org/Tentative_NumPy_Tutorial)。
- en: 'One caveat is still that we have some values in `y` that contain invalid values,
    `nan`. The question is what we can do with them. Let''s check how many hours contain
    invalid data, by running the following code:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 一个警告是，我们的`y`中仍然包含一些无效值，`nan`。问题是我们该如何处理这些值。让我们通过运行以下代码来检查有多少小时包含无效数据：
- en: '[PRE21]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As you can see, we are missing only 8 out of 743 entries, so we can afford
    to remove them. Remember that we can index a SciPy array with another array. `Sp.isnan(y)`
    returns an array of Booleans indicating whether an entry is a number or not. Using
    `~`, we logically negate that array so that we choose only those elements from
    `x` and `y` where `y` contains valid numbers:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们只有743个数据项中的8个缺失，因此我们可以去掉它们。记住，我们可以用另一个数组来索引一个SciPy数组。`Sp.isnan(y)`返回一个布尔数组，指示某个数据项是否为数字。通过使用`~`，我们可以逻辑取反这个数组，从而只选择那些`y`中包含有效数字的`x`和`y`元素：
- en: '[PRE22]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To get the first impression of our data, let''s plot the data in a scatter
    plot using matplotlib. matplotlib contains the pyplot package, which tries to
    mimic MATLAB''s interface, which is a very convenient and easy to use one as you
    can see in the following code:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得数据的初步印象，我们使用matplotlib绘制数据的散点图。matplotlib包含了pyplot包，它试图模仿MATLAB的界面，正如你在以下代码中看到的，这是一种非常方便且易于使用的接口：
- en: '[PRE23]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You can find more tutorials on plotting at [http://matplotlib.org/users/pyplot_tutorial.html](http://matplotlib.org/users/pyplot_tutorial.html).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[http://matplotlib.org/users/pyplot_tutorial.html](http://matplotlib.org/users/pyplot_tutorial.html)找到更多关于绘图的教程。
- en: 'In the resulting chart, we can see that while in the first weeks the traffic
    stayed more or less the same, the last week shows a steep increase:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在结果图表中，我们可以看到，在前几周流量大致保持不变，而最后一周显示了急剧增加：
- en: '![Preprocessing and cleaning the data](img/2772OS_01_01.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![预处理和清洗数据](img/2772OS_01_01.jpg)'
- en: Choosing the right model and learning algorithm
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择合适的模型和学习算法
- en: 'Now that we have a first impression of the data, we return to the initial question:
    How long will our server handle the incoming web traffic? To answer this we have
    to do the following:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对数据有了初步印象，我们回到最初的问题：我们的服务器能够处理多少的 Web 流量？为了回答这个问题，我们需要做以下几点：
- en: Find the real model behind the noisy data points.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出噪声数据点背后的真实模型。
- en: Following this, use the model to extrapolate into the future to find the point
    in time where our infrastructure has to be extended.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用该模型推测未来，找出我们需要扩展基础设施的时间点。
- en: Before building our first model…
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在构建我们的第一个模型之前……
- en: 'When we talk about models, you can think of them as simplified theoretical
    approximations of complex reality. As such there is always some inferiority involved,
    also called the approximation error. This error will guide us in choosing the
    right model among the myriad of choices we have. And this error will be calculated
    as the squared distance of the model''s prediction to the real data; for example,
    for a learned model function `f`, the error is calculated as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论模型时，你可以将它们视为复杂现实的简化理论近似。作为这样的一种模型，总是涉及到某种程度的不足，也叫做近似误差。这个误差将引导我们在众多选择中选出合适的模型。这个误差将通过计算模型预测与真实数据之间的平方距离来计算；例如，对于一个学习过的模型函数`f`，误差的计算如下：
- en: '[PRE24]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The vectors `x` and `y` contain the web stats data that we have extracted earlier.
    It is the beauty of SciPy's vectorized functions that we exploit here with `f(x)`.
    The trained model is assumed to take a vector and return the results again as
    a vector of the same size so that we can use it to calculate the difference to
    `y`.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 向量`x`和`y`包含了我们之前提取的Web统计数据。这正是我们在这里利用SciPy的矢量化函数`f(x)`的美妙之处。假设训练过的模型接受一个向量并返回相同大小的结果向量，这样我们就可以用它来计算与`y`的差异。
- en: Starting with a simple straight line
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从一条简单的直线开始
- en: 'Let''s assume for a second that the underlying model is a straight line. Then
    the challenge is how to best put that line into the chart so that it results in
    the smallest approximation error. SciPy''s `polyfit()` function does exactly that.
    Given data `x` and `y` and the desired order of the polynomial (a straight line
    has order 1), it finds the model function that minimizes the error function defined
    earlier:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们假设潜在的模型是一条直线。那么，挑战在于如何将这条直线最佳地放入图表中，以使得近似误差最小。SciPy的`polyfit()`函数正是用来做这个的。给定数据`x`和`y`以及所需的多项式阶数（直线是阶数为1），它会找到一个模型函数，最小化先前定义的误差函数：
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The `polyfit()` function returns the parameters of the fitted model function,
    `fp1`. And by setting `full=True`, we also get additional background information
    on the fitting process. Of this, only residuals are of interest, which is exactly
    the error of the approximation:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`polyfit()`函数返回拟合模型函数的参数`fp1`。通过设置`full=True`，我们还可以获得拟合过程的额外背景信息。其中，只有残差是我们关心的，它正是近似的误差：'
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This means the best straight line fit is the following function
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着最好的直线拟合是以下函数：
- en: '[PRE27]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We then use `poly1d()` to create a model function from the model parameters:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用`poly1d()`从模型参数创建一个模型函数：
- en: '[PRE28]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We have used `full=True` to retrieve more details on the fitting process. Normally,
    we would not need it, in which case only the model parameters would be returned.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`full=True`来获取更多的拟合过程细节。通常我们不需要这样做，在这种情况下，只会返回模型参数。
- en: 'We can now use `f1()` to plot our first trained model. In addition to the preceding
    plotting instructions, we simply add the following code:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用`f1()`来绘制我们训练的第一个模型。除了前面绘图的指令外，我们只需添加以下代码：
- en: '[PRE29]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This will produce the following plot:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下图表：
- en: '![Starting with a simple straight line](img/2772OS_01_02.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![从简单的直线开始](img/2772OS_01_02.jpg)'
- en: It seems like the first 4 weeks are not that far off, although we clearly see
    that there is something wrong with our initial assumption that the underlying
    model is a straight line. And then, how good or how bad actually is the error
    of 317,389,767.34?
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来前4周的预测误差并不大，尽管我们明显看到最初假设潜在模型是直线的假设存在问题。那么，317,389,767.34的误差到底有多大呢？
- en: The absolute value of the error is seldom of use in isolation. However, when
    comparing two competing models, we can use their errors to judge which one of
    them is better. Although our first model clearly is not the one we would use,
    it serves a very important purpose in the workflow. We will use it as our baseline
    until we find a better one. Whatever model we come up with in the future, we will
    compare it against the current baseline.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 误差的绝对值通常单独使用意义不大。然而，在比较两个竞争模型时，我们可以使用它们的误差来判断哪个模型更好。尽管我们的第一个模型显然不是我们会使用的，但它在工作流程中具有非常重要的作用。在我们找到一个更好的模型之前，它将作为我们的基准。未来我们提出的任何新模型，都将与当前的基准模型进行比较。
- en: Towards some advanced stuff
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向更高级的内容迈进
- en: 'Let''s now fit a more complex model, a polynomial of degree 2, to see whether
    it better understands our data:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们拟合一个更复杂的模型，一个2次方的多项式，看看它是否能更好地理解我们的数据：
- en: '[PRE30]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'You will get the following plot:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你将得到以下图表：
- en: '![Towards some advanced stuff](img/2772OS_01_03.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![向更高级的内容迈进](img/2772OS_01_03.jpg)'
- en: 'The error is 179,983,507.878, which is almost half the error of the straight
    line model. This is good but unfortunately this comes with a price: We now have
    a more complex function, meaning that we have one parameter more to tune inside
    `polyfit()`. The fitted polynomial is as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 误差为179,983,507.878，几乎是直线模型误差的一半。这是好的，但不幸的是，这也有一个代价：我们现在拥有了一个更复杂的函数，这意味着我们在`polyfit()`中需要调整更多的参数。拟合的多项式如下：
- en: '[PRE31]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: So, if more complexity gives better results, why not increase the complexity
    even more? Let's try it for degrees 3, 10, and 100.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果增加复杂度能带来更好的结果，为什么不进一步增加复杂度呢？让我们尝试3次方、10次方和100次方的情况。
- en: '![Towards some advanced stuff](img/2772OS_01_04.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![向更高级的内容迈进](img/2772OS_01_04.jpg)'
- en: 'Interestingly, we do not see `d=53` for the polynomial that had been fitted
    with 100 degrees. Instead, we see lots of warnings on the console:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们没有在拟合了100次方的多项式中看到`d=53`。相反，我们在控制台上看到了大量的警告：
- en: '[PRE32]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This means because of numerical errors, polyfit cannot determine a good fit
    with 100 degrees. Instead, it figured that 53 must be good enough.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着由于数值误差，polyfit无法以100次方确定一个好的拟合。相反，它认为53次方已经足够好了。
- en: 'It seems like the curves capture and better the fitted data the more complex
    they get. And also, the errors seem to tell the same story:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来曲线捕捉并改进拟合数据的能力随着其复杂度的增加而增强。错误也似乎讲述了同样的故事：
- en: '[PRE33]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: However, taking a closer look at the fitted curves, we start to wonder whether
    they also capture the true process that generated that data. Framed differently,
    do our models correctly represent the underlying mass behavior of customers visiting
    our website? Looking at the polynomial of degree 10 and 53, we see wildly oscillating
    behavior. It seems that the models are fitted too much to the data. So much that
    it is now capturing not only the underlying process but also the noise. This is
    called **overfitting**.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仔细观察拟合曲线后，我们开始怀疑它们是否也捕捉到了生成这些数据的真实过程。换句话说，我们的模型是否正确地表示了客户访问我们网站时的潜在行为？查看10次方和53次方的多项式，我们看到的行为是剧烈波动的。似乎模型过度拟合了数据，甚至不仅捕捉到了潜在的过程，还包括了噪声。这种现象称为**过拟合**。
- en: 'At this point, we have the following choices:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们有以下选择：
- en: Choosing one of the fitted polynomial models.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择拟合的多项式模型之一。
- en: Switching to another more complex model class. Splines?
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 切换到另一种更复杂的模型类别。样条曲线？
- en: Thinking differently about the data and start again.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以不同的角度重新思考数据并重新开始。
- en: Out of the five fitted models, the first order model clearly is too simple,
    and the models of order 10 and 53 are clearly overfitting. Only the second and
    third order models seem to somehow match the data. However, if we extrapolate
    them at both borders, we see them going berserk.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在五个拟合模型中，一阶模型显然过于简单，而10阶和53阶的模型显然是过拟合的。只有二阶和三阶模型似乎在某种程度上与数据匹配。然而，如果我们在两个边界进行外推，就会看到它们变得异常。
- en: Switching to a more complex class seems also not to be the right way to go.
    What arguments would back which class? At this point, we realize that we probably
    have not fully understood our data.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 切换到更复杂的类别似乎也不是正确的选择。有哪些理由支持选择哪种类别？此时，我们意识到我们可能还没有完全理解我们的数据。
- en: Stepping back to go forward – another look at our data
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回退再前进——重新审视我们的数据
- en: 'So, we step back and take another look at the data. It seems that there is
    an inflection point between weeks 3 and 4\. So let''s separate the data and train
    two lines using week 3.5 as a separation point:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们回退并再次审视数据。看起来在第3周和第4周之间存在一个拐点。那么让我们分离数据并使用第3.5周作为分割点来训练两条线：
- en: '[PRE34]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: From the first line, we train with the data up to week 3, and in the second
    line we train with the remaining data.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 从第一条线开始，我们使用第3周的数据进行训练，而在第二条线中我们使用剩余的数据进行训练。
- en: '![Stepping back to go forward – another look at our data](img/2772OS_01_05.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![回退再前进——重新审视我们的数据](img/2772OS_01_05.jpg)'
- en: Clearly, the combination of these two lines seems to be a much better fit to
    the data than anything we have modeled before. But still, the combined error is
    higher than the higher order polynomials. Can we trust the error at the end?
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这两条线的组合比我们之前所拟合的任何模型更能符合数据。但即便如此，组合误差仍然高于高阶多项式。我们能信任最终的误差吗？
- en: Asked differently, why do we trust the straight line fitted only at the last
    week of our data more than any of the more complex models? It is because we assume
    that it will capture future data better. If we plot the models into the future,
    we see how right we are (**d=1** is again our initial straight line).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 换个角度问，为什么我们更相信只在数据最后一周拟合的直线，而不是任何更复杂的模型？这是因为我们假设它能更好地捕捉未来的数据。如果我们将模型预测到未来，我们可以看到我们是否正确（**d=1**再次是我们最初的直线）。
- en: '![Stepping back to go forward – another look at our data](img/2772OS_01_06.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![回退再前进——重新审视我们的数据](img/2772OS_01_06.jpg)'
- en: The models of degree 10 and 53 don't seem to expect a bright future of our start-up.
    They tried so hard to model the given data correctly that they are clearly useless
    to extrapolate beyond. This is called overfitting. On the other hand, the lower
    degree models seem not to be capable of capturing the data good enough. This is
    called **underfitting**.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 10阶和53阶的模型似乎并不看好我们创业公司的未来。它们为了正确拟合给定的数据付出了极大的努力，结果显然无法用于外推。这就是所谓的过拟合。另一方面，低阶模型似乎无法充分捕捉数据的特征。这就是所谓的**欠拟合**。
- en: So let's play fair to models of degree 2 and above and try out how they behave
    if we fit them only to the data of the last week. After all, we believe that the
    last week says more about the future than the data prior to it. The result can
    be seen in the following psychedelic chart, which further shows how badly the
    problem of overfitting is.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们对二阶及以上的模型保持公正，尝试仅将它们拟合到最后一周的数据。毕竟，我们认为最后一周比之前的数据更能反映未来。结果可以在下面这张充满迷幻色彩的图表中看到，它进一步展示了过拟合问题有多严重。
- en: '![Stepping back to go forward – another look at our data](img/2772OS_01_07.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![回退再前进——重新审视我们的数据](img/2772OS_01_07.jpg)'
- en: 'Still, judging from the errors of the models when trained only on the data
    from week 3.5 and later, we still should choose the most complex one (note that
    we also calculate the error only on the time after the inflection point):'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，从仅使用第3.5周及之后的数据进行训练时模型的误差来看，我们仍然应该选择最复杂的模型（注意，我们也只计算了拐点之后的误差）：
- en: '[PRE35]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Training and testing
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练与测试
- en: If we only had some data from the future that we could use to measure our models
    against, then we should be able to judge our model choice only on the resulting
    approximation error.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一些来自未来的数据可以用来评估我们的模型，那么我们应该仅根据由此产生的逼近误差来判断我们的模型选择。
- en: Although we cannot look into the future, we can and should simulate a similar
    effect by holding out a part of our data. Let's remove, for instance, a certain
    percentage of the data and train on the remaining one. Then we used the held-out
    data to calculate the error. As the model has been trained not knowing the held-out
    data, we should get a more realistic picture of how the model will behave in the
    future.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们无法预测未来，但我们可以并且应该通过保留部分数据来模拟类似的效果。比如，去除一定比例的数据，并在剩余数据上进行训练。然后，我们使用保留的数据计算误差。由于模型在训练时未看到这些保留的数据，因此我们应该能够更真实地了解模型在未来的表现。
- en: 'The test errors for the models trained only on the time after inflection point
    now show a completely different picture:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 仅在拐点后时间段内训练的模型的测试误差现在显示出完全不同的图景：
- en: '[PRE36]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Have a look at the following plot:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 请看以下图表：
- en: '![Training and testing](img/2772OS_01_08.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![训练与测试](img/2772OS_01_08.jpg)'
- en: 'It seems that we finally have a clear winner: The model with degree 2 has the
    lowest test error, which is the error when measured using data that the model
    did not see during training. And this gives us hope that we won''t get bad surprises
    when future data arrives.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们终于有了明确的结果：二次函数模型具有最低的测试误差，这是指使用模型在训练过程中未见过的数据进行测量时的误差。这给了我们希望，未来的数据到来时我们不会遇到不好的惊讶。
- en: Answering our initial question
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回答我们最初的问题
- en: Finally we have arrived at a model which we think represents the underlying
    process best; it is now a simple task of finding out when our infrastructure will
    reach 100,000 requests per hour. We have to calculate when our model function
    reaches the value 100,000.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们得出了一个我们认为最能代表底层过程的模型；现在只需要简单地计算出我们的基础设施何时将达到每小时100,000次请求。我们需要计算何时我们的模型函数值会达到100,000。
- en: Having a polynomial of degree 2, we could simply compute the inverse of the
    function and calculate its value at 100,000\. Of course, we would like to have
    an approach that is applicable to any model function easily.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们有一个二次多项式，我们可以简单地计算函数的反函数，并在100,000时计算它的值。当然，我们希望有一种适用于任何模型函数的方法。
- en: This can be done by subtracting 100,000 from the polynomial, which results in
    another polynomial, and finding its root. SciPy's `optimize` module has the function
    `fsolve` that achieves this, when providing an initial starting position with
    parameter `x0`. As every entry in our input data file corresponds to one hour,
    and we have 743 of them, we set the starting position to some value after that.
    Let `fbt2` be the winning polynomial of degree 2.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过从多项式中减去100,000来实现，结果得到另一个多项式，并找到它的根。SciPy的`optimize`模块有一个`fsolve`函数，可以通过提供初始起始位置参数`x0`来实现这一目标。由于我们输入数据文件中的每个条目对应一个小时，总共有743个小时，因此我们将起始位置设置为该时间段之后的某个值。让`fbt2`成为二次多项式模型。
- en: '[PRE37]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: It is expected to have 100,000 hits/hour at week 9.616071, so our model tells
    us that, given the current user behavior and traction of our start-up, it will
    take another month until we have reached our capacity threshold.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 预计在第9.616071周时，每小时将达到100,000次点击。因此，我们的模型告诉我们，鉴于当前的用户行为和我们初创公司的发展势头，再过一个月我们将达到容量阈值。
- en: Of course, there is a certain uncertainty involved with our prediction. To get
    a real picture of it, one could draw in more sophisticated statistics to find
    out about the variance we have to expect when looking farther and farther into
    the future.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们的预测存在一定的不确定性。为了获得更真实的预测结果，可以引入更复杂的统计方法，以找出我们在未来的预测中需要预期的方差。
- en: And then there are the user and underlying user behavior dynamics that we cannot
    model accurately. However, at this point, we are fine with the current predictions.
    After all, we can prepare all time-consuming actions now. If we then monitor our
    web traffic closely, we will see in time when we have to allocate new resources.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，还有用户和底层用户行为的动态，这是我们无法准确建模的。然而，在这一点上，我们对当前的预测是满意的。毕竟，我们现在可以准备所有耗时的操作。如果我们紧密监控网站流量，我们将及时看到何时需要分配新资源。
- en: Summary
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Congratulations! You just learned two important things, of which the most important
    one is that as a typical machine learning operator, you will spend most of your
    time in understanding and refining the data—exactly what we just did in our first
    tiny machine learning example. And we hope that this example helped you to start
    switching your mental focus from algorithms to data. Then you learned how important
    it is to have the correct experiment setup and that it is vital to not mix up
    training and testing.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！你刚刚学到了两个重要的东西，其中最重要的一点是，作为一个典型的机器学习操作员，你将花费大部分时间来理解和优化数据——正是我们在第一个小型机器学习示例中所做的。我们希望这个示例能帮助你开始将注意力从算法转向数据。接着，你学到了正确的实验设置有多么重要，且避免混淆训练和测试数据是至关重要的。
- en: Admittedly, the use of polynomial fitting is not the coolest thing in the machine
    learning world. We have chosen it to not distract you by the coolness of some
    shiny algorithm when we conveyed the two most important messages we just summarized
    earlier.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 诚然，使用多项式拟合在机器学习领域并不是最炫酷的事情。我们选择它是为了在传达我们之前总结的两个最重要的信息时，不让你被某些闪亮算法的酷炫分散注意力。
- en: So, let's move to the next chapter in which we will dive deep into scikit-learn,
    the marvelous machine learning toolkit, give an overview of different types of
    learning, and show you the beauty of feature engineering.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们进入下一章，在其中我们将深入探讨 scikit-learn 这一神奇的机器学习工具包，概述不同类型的学习，并展示特征工程的美妙。
