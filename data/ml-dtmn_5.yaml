- en: Advanced Ways of Improving Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高模型的高级方法
- en: First, we learned to build a model, then we performed diagnostic analysis on
    it. Then, we determined how accurate the model was, and in this chapter, we will
    extend our model-building skills. We will learn how to not view a model as an
    endpoint, but as a starting position to move forward toward improving models.
    Basically, we will learn how to improve individual models by building more than
    one model. We have several ways in which we can do that, and we are going to talk
    about them in detail.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们学习了如何构建模型，然后对其进行了诊断分析。接着，我们确定了模型的准确性，在本章中，我们将扩展我们的模型构建技能。我们将学习如何不将模型视为终点，而是将其视为向前推进以改进模型的起点。基本上，我们将学习如何通过构建多个模型来提高单个模型的性能。我们有几种方法可以实现这一点，我们将在详细讨论它们。
- en: 'The topics that will be covered in this chapter are as follows. These are also
    the ways in which we can improve individual models:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题。这些也是我们可以提高单个模型的方法：
- en: Combining models
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型合并
- en: Propensity scores
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 倾向得分
- en: Meta-level modeling
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元级建模
- en: Error modeling
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误建模
- en: Boosting and bagging
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升和袋装
- en: Continuous outcomes
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续结果
- en: Combining models
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型合并
- en: There are several ways in which models can be combined. We are going to look
    at each method in this section.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以通过多种方式结合。在本节中，我们将逐一探讨每种方法。
- en: Combining by voting
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过投票合并
- en: Let's use an example to understand this method of combining models.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子来理解这种模型合并的方法。
- en: 'Consider that we have run three models and created a table like this:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经运行了三个模型并创建了一个如下所示的表格：
- en: '![](img/c7806c54-cba4-4c04-be11-4115f2e18485.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c7806c54-cba4-4c04-be11-4115f2e18485.png)'
- en: We have the confidence for each model and its prediction. Let's see how we can
    combine these models.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有每个模型的置信度和其预测。让我们看看我们如何合并这些模型。
- en: If we take a look at the first row, we can see that each of these models is
    predicting that a person is going to leave. Hence, if we combine the predictions,
    we are still predicting that the person is going to leave. The confidence value,
    or the final confidence, is acquired by adding up the confidence values of all
    the models and dividing by the number of total models, three in our case.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看第一行，我们可以看到这些模型中的每一个都预测一个人将要离开。因此，如果我们合并预测，我们仍然预测这个人将要离开。置信度值，或最终置信度，是通过将所有模型的置信度值相加，然后除以模型的总数（在我们的例子中是三个）来获得的。
- en: If we look at the second row, we can see that two of these models predict that
    the person is going to leave; and one model is predicting that the person is going
    to stay; we can infer that the combined prediction will be that the person will
    leave. Here, we calculate the confidence values by adding up the confidence of
    the models that predicted the combined prediction, Leave, divided by the total
    number of models, which is three. Hence, the final confidence value is low in
    the second row.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看第二行，我们可以看到其中两个模型预测这个人将要离开；而有一个模型预测这个人将要留下；我们可以推断出合并的预测将是这个人将要离开。在这里，我们通过将预测合并预测的模型的置信度相加，然后除以模型的总数（在我们的例子中是三个），来计算置信度值。因此，第二行的最终置信度值较低。
- en: This is combining models by voting, where only the predictions that occur a
    number of times are  considered for combining.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过投票合并模型，其中只考虑发生多次的预测进行合并。
- en: Combining by highest confidence
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过最高置信度合并
- en: 'This is another method of combining models. Consider the following table, for
    example:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一种合并模型的方法。例如，考虑以下表格：
- en: '![](img/4fd27279-8af9-4997-8b9d-50401e224256.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4fd27279-8af9-4997-8b9d-50401e224256.png)'
- en: In this example, we won't consider what the model is predicting; instead, we
    will just focus on high confidence values. If we look at the first row, each of
    the models has predicted Leave. But Model 1 has the highest confidence, and so
    the combined prediction is taken as Leave and the final confidence is the highest
    confidence acquired.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们不会考虑模型预测的内容；相反，我们只关注高置信度值。如果我们查看第一行，每个模型都预测了“离开”。但模型1的置信度最高，因此合并的预测被采纳为“离开”，最终置信度是获得的最高的置信度。
- en: If we look at the second row, the model with highest confidence is Model 3 and
    it has predicted that the person is going to stay, and hence, the combined prediction
    becomes Stay and the final confidence becomes the highest confidence.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看第二行，置信度最高的模型是模型3，它预测这个人将要留下，因此合并的预测变为“留下”，最终置信度变为最高的置信度。
- en: Implementing combining models
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现合并模型
- en: 'Follow these steps to see how we can combine different models:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤查看我们如何组合不同的模型：
- en: Get Electronics_Data on Canvas.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在画布上获取Electronics_Data。
- en: Connect the dataset to a Partition node from the Field Ops palette.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集连接到字段操作面板中的分区节点。
- en: Split the data into training and testing datasets, we have done before.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为训练集和测试集，我们之前已经做过。
- en: Connect the Partition node to the Neural Net model and run this model with a
    random seed set to `5000` and run it.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将分区节点连接到神经网络模型，并使用随机种子设置为`5000`运行此模型。
- en: We will now build a **support vector machine** (**SVM**) model. As we are heading
    towards combining models, we will go to the Partition node and connect it with
    an SVM model from the Modeling palette.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将构建一个**支持向量机**（**SVM**）模型。随着我们朝着组合模型的方向前进，我们将前往分区节点，并从建模面板将其与一个SVM模型连接起来。
- en: Run the SVM model by recalling the edits we had made in the Expert tab from
    [Chapter 2](f4f20b86-4417-4c0c-a8b2-d0be16f28e20.xhtml), *Getting Started with
    Machine Learning*. Go to the Expert tab, select the mode as Expert. Change the
    Regularization parameter, C and set it to `5`, the middle value, and change the
    Kernel type to Polynomial, as that's what gave us an accurate and consistent model
    earlier on using the same data. Also, change the Degree value to `2`. We are changing
    the parameters to these values because we acquired proper results earlier when
    we first saw a demonstration of this model in [Chapter 2](f4f20b86-4417-4c0c-a8b2-d0be16f28e20.xhtml),
    *Getting Started with Machine Learning*. Click on Run.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过回忆我们在[第2章](f4f20b86-4417-4c0c-a8b2-d0be16f28e20.xhtml)，“机器学习入门”中做出的编辑来运行SVM模型。转到专家标签，选择模式为专家。更改正则化参数C，将其设置为`5`，中间值，并将核类型更改为多项式，因为我们之前使用相同的数据获得了准确且一致模型。还将度值更改为`2`。我们更改这些参数是因为我们在第一次看到此模型演示时获得了适当的结果。[第2章](f4f20b86-4417-4c0c-a8b2-d0be16f28e20.xhtml)，“机器学习入门”。点击运行。
- en: Connect both the SVM and the Neural Net model that were generated.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接生成的SVM模型和神经网络模型。
- en: Go to the Output palette and connect the generated SVM model to a Table.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往输出面板，并将生成的SVM模型连接到表格。
- en: 'Run the table using the Run icon on top. You will see the following:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用顶部的运行图标运行表格。您将看到以下内容：
- en: '![](img/a3ce3b75-6b27-4fa9-89f5-aa5333160068.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a3ce3b75-6b27-4fa9-89f5-aa5333160068.png)'
- en: In this, you can see the results from the partition node, the predictions from
    the Neural Net model, its confidence, and even the predictions from the SVM model
    and its confidence. You can close this window.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以查看分区节点的结果，神经网络模型的预测，其置信度，甚至SVM模型的预测及其置信度。您可以关闭此窗口。
- en: We will now analyze the model by connecting the SVM-generated model to an Analysis
    node from the Output palette.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将通过将SVM生成的模型连接到输出面板中的分析节点来分析模型。
- en: 'Edit the Analysis node, check the Coincidence matrices, and click on Run. You
    will see the following results:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑分析节点，检查巧合矩阵，并点击运行。您将看到以下结果：
- en: '![](img/b60dd1dc-71dc-4780-a089-f9d88ef0c7c8.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b60dd1dc-71dc-4780-a089-f9d88ef0c7c8.png)'
- en: We can see how well each of the models has performed. If you scroll down, you
    can see that the models have agreed 88% of the time on predictions in the training
    dataset, and about 87% of the time in the testing dataset. When these models agreed,
    they were actually correct a fair amount of the time. This brings us to evaluate
    the possibility of combining these two models.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到每个模型的表现如何。如果您向下滚动，您可以看到模型在训练数据集中的预测上有88%的时间达成一致，在测试数据集中大约有87%的时间达成一致。当这些模型达成一致时，它们实际上在相当多的时间里是正确的。这使我们评估将这两个模型组合的可能性。
- en: We are now moving on to combine the models. We will first combine using Modeler,
    but we will also see how we can combine models outside of a modeler.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在开始将模型进行组合。我们首先将使用模型器进行组合，但也会看看我们如何在模型器之外组合模型。
- en: Combining models in Modeler
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在模型器中组合模型
- en: 'For combining models within a modeler, follow these steps:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要在模型器内组合模型，请按照以下步骤操作：
- en: Go to the SVM model and connect it to the Ensemble node from the Field Ops palette.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往SVM模型，并从字段操作面板将其连接到集成节点。
- en: 'Let''s edit the Ensemble node. The Ensemble node knows that it is combining
    the results of two models as it shows two models in ensemble. Choose the Target
    field for Ensemble as the Status from the drop-down button on the right. If the
    Filter out fields generated by ensemble models is checked, it will filter out
    the already generated fields from the previous models, hence, we will deselect
    it. Next, select the Ensemble method. This is a list 0f ways in which we can combine
    the model. Here, we will select Voting as we have already seen this. We will talk
    about the propensity scores later on in this chapter. Then we have to select what
    happens when there is a tie; here, we will select Highest confidence as we have
    seen this too and click on OK, as shown in the following screenshot:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们编辑Ensemble节点。Ensemble节点知道它正在组合两个模型的结果，因为它在Ensemble中显示了两个模型。将Ensemble的目标字段选择为右侧下拉按钮中的Status。如果选中了“过滤掉由Ensemble模型生成的字段”，它将过滤掉先前模型中已生成的字段，因此我们将取消选中它。接下来，选择Ensemble方法。这是一个我们可以组合模型的方式列表。在这里，我们将选择投票，因为我们已经看到过这个了。我们将在本章后面讨论倾向得分。然后我们必须选择在出现平局时会发生什么；在这里，我们将选择最高置信度，因为我们也看到了这一点，然后点击OK，如图所示：
- en: '![](img/bd87ac6b-18d5-476e-9b22-8ab613e75eeb.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd87ac6b-18d5-476e-9b22-8ab613e75eeb.png)'
- en: 'Let''s see the results of our combination. For this, connect the Ensemble node
    to the Analysis node and click on the Run button on top. The following will be
    the results:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看组合的结果。为此，将Ensemble节点连接到分析节点，并点击顶部的运行按钮。以下将是结果：
- en: '![](img/f1151314-0192-4a57-9166-298e5263210e.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f1151314-0192-4a57-9166-298e5263210e.png)'
- en: First, we have the results of the Neural Net model, followed by the results
    of the SVM model and then finally, we can see the results of the combined model.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们有神经网络模型的结果，然后是SVM模型的结果，最后我们可以看到组合模型的结果。
- en: We can see that the overall accuracy in the testing dataset is 82%, which means
    that there is a slight improvement. We were able to improve the accuracy by combining
    two models by 2% which is great as a starting point. Let's see how we can combine
    models from outside of Modeler.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到在测试数据集中整体准确率为82%，这意味着略有改进。我们通过组合两个模型将准确率提高了2%，这是一个很好的起点。让我们看看我们如何从模型器外部组合模型。
- en: Combining models outside Modeler
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在模型器外部组合模型
- en: This method can be used when you are using any data-mining software other than
    SPSS Modeler.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用除SPSS Modeler之外的其他数据挖掘软件时，可以使用这种方法。
- en: 'Let''s see how to do that:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何做到这一点：
- en: Go to the Field Ops palette and connect the SVM-generated model to a Derive
    node.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往字段操作调色板，并将SVM生成的模型连接到派生节点。
- en: We will use the Derive node to create a new field. We will edit this node and
    name it `Combined_Prediction`.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用派生节点来创建一个新的字段。我们将编辑此节点并将其命名为`Combined_Prediction`。
- en: Derive this field as a Conditional. You will see an `if-else` condition.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此字段派生为条件。你会看到一个`if-else`条件。
- en: Let's tell Modeler that if the predictions from all the models are equal then
    the combined prediction will be that prediction itself. To do this, let's add
    an expression in the first `if` condition as, the prediction from the Neural Net
    model, $N-Status select = the prediction of the SVM model, $S-Status; go to the
    `Then` condition, click on the expression builder and select, the prediction of
    the Neural Net model, $N-Status or alternatively, you can even select a prediction
    from the SVM model.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们告诉模型器，如果所有模型的预测都相等，那么组合预测将是那个预测本身。为此，让我们在第一个`if`条件中添加一个表达式，即神经网络模型的预测，$N-Status
    select = SVM模型的预测，$S-Status；转到`Then`条件，点击表达式构建器并选择，神经网络模型的预测，$N-Status，或者你也可以选择SVM模型的预测。
- en: 'Write in the `Else` condition, this statement: You can select the variable
    names from the list:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Else`条件中写下这个语句：你可以从列表中选择变量名：
- en: '![](img/b2e480d6-9a22-49f4-a1ff-3eada9573d36.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b2e480d6-9a22-49f4-a1ff-3eada9573d36.png)'
- en: This statement means that we will select the **Highest confidence** from any
    of the models if the predictions of the two models do not match. And if the confidence
    of the prediction from the Neural Net model is higher than that of the SVM model,
    then we will go with the prediction of the Neural Net model. Otherwise, if the
    confidence of the prediction of the SVM model is higher than the Neural Net model,
    then we will go with the SVM model. But, if both the conditions don't satisfy,
    then we will put a `0`, and then we have to end with an `endif` statement. Click
    on OK.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个声明意味着，如果两个模型的预测不匹配，我们将选择任何模型中的**最高置信度**。如果神经网络模型的预测置信度高于SVM模型，那么我们将选择神经网络模型的预测。否则，如果SVM模型的预测置信度高于神经网络模型，那么我们将选择SVM模型。但是，如果两个条件都不满足，那么我们将放置一个`0`，然后我们必须以`endif`语句结束。点击确定。
- en: 'Connect the Combined_prediction node to the Table mode and let''s see the results
    take a look at the results, as shown in the following screenshot:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将组合预测节点连接到表格模式，让我们看看结果，如下面的截图所示：
- en: '![](img/2d884fe8-d782-4865-96c7-cbc9412229c0.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![截图](img/2d884fe8-d782-4865-96c7-cbc9412229c0.png)'
- en: Here, in the 12th row, we can see that the neural network predicted a customer
    as Churned whereas the SVM predicted it as Current, but as the confidence of the
    Neural Net prediction was higher, the combined prediction was picked as Churned.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，第12行，我们可以看到神经网络预测客户为流失，而SVM预测为当前客户，但由于神经网络预测的置信度更高，所以组合预测被选为流失。
- en: You can analyze this model and see for yourself that the numbers that will be
    acquired will be similar to the numbers that we had using the Ensemble node.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以分析这个模型，看看自己获得的数据将与我们使用集成节点获得的数据相似。
- en: This is how we combined two models to improve accuracy and we saw how we can
    get the combined results from the two models. You can try this out with three
    or more models. You will be amazed at how well combining models can work. We will
    now see another advanced method to improve the model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们将两个模型结合以提高准确性的方法，我们也看到了如何从两个模型中获得组合结果。你可以尝试使用三个或更多模型。你会对模型结合的效果感到惊讶。现在我们将看到另一种提高模型的高级方法。
- en: Using propensity scores
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用倾向得分
- en: Propensity scores are very useful because they tell you the likelihood of something
    happening. Confidence values for models reflect confidence in our predictions
    so a high degree of confidence doesn't help us determine if we're going to have
    a customer that's going to stay or leave a company, instead it indicates the confidence
    that we have in our prediction. Sometimes it's helpful to modify the confidence
    value so that a high confidence value means a prediction that a person is going
    to leave and a low confidence value indicates that a person is going to stay.
    Basically, we end up creating a propensity to leave score which would be helpful
    so that we could make interventions, different marketing efforts, and so on.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 倾向得分非常有用，因为它们告诉你某件事情发生的可能性。模型的置信度值反映了我们对预测的信心，所以高置信度并不能帮助我们确定客户是否会留在公司或离开公司，相反，它表明我们对预测的信心。有时修改置信度值是有帮助的，这样高置信度值意味着预测一个人会离开，而低置信度值则表示一个人会留下。基本上，我们最终创建了一个倾向离开得分，这将有助于我们进行干预，不同的营销努力等等。
- en: 'Consider this table, for example:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以这个表格为例：
- en: '![](img/2579696c-ecb3-4400-9829-07f9c8de4441.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![截图](img/2579696c-ecb3-4400-9829-07f9c8de4441.png)'
- en: We have two values for Leaving and two values for Staying, each with the confidence
    values that we have in those predictions. In this example, let's assume that we
    are trying to calculate the propensity of losing a customer. We will create a
    propensity score; this means that when a person is predicted to leave, the propensity
    score is the same thing as a confidence value. So you can see that for the first
    person, we're predicting they are going to leave, and as we have a high degree
    of confidence in that prediction, therefore the propensity score is pretty high.
    For the second person, we're predicting they are also going to leave, but the
    confidence in that prediction is not quite as high, so therefore, we can see that
    the propensity score is not quite so high either.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两个离开值和两个停留值，每个值都有我们对这些预测的置信度。在这个例子中，让我们假设我们正在尝试计算失去客户的倾向性。我们将创建一个倾向性分数；这意味着当一个人被预测要离开时，倾向性分数与置信值是同一回事。所以你可以看到，对于第一个人，我们预测他们将离开，由于我们对这个预测有很高的信心，因此倾向性分数相当高。对于第二个人，我们预测他们也将离开，但我们对这个预测的信心并不那么高，因此，我们可以看到倾向性分数也不是那么高。
- en: While predicting the opposite, if we are predicting that a third person is going
    to stay but the confidence in that prediction is not very great, really what we're
    doing is taking 1 minus the confidence value of the opposite of what we really
    want, and that ends up being the propensity score. Finally, in the last example,
    we have a person that we're predicting is going to stay. The confidence in that
    prediction is extremely high, so therefore, the likelihood of that person leaving
    is very low.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当预测相反的情况时，如果我们预测第三个人将留下，但我们对这个预测的信心并不很大，实际上我们正在做的是取我们真正想要的相反的置信度值的1减去，这最终就是倾向性分数。最后，在最后一个例子中，我们预测一个人将留下。我们对这个预测的信心极高，因此，这个人离开的可能性非常低。
- en: 'The following figure sums up the propensity formulas:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表总结了倾向性公式：
- en: '![](img/e55068c9-388b-4aa2-909a-bc9207fcfeed.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e55068c9-388b-4aa2-909a-bc9207fcfeed.png)'
- en: In essence, what propensity scores do is modify confidence values so that you
    can see the likelihood of something happening. So, if you could put them all on
    some kind of spectrum it would be possible to see, for example, that there are
    some people for whom there is a high degree of confidence that they are going
    to leave, so maybe there's not much that we can do about that. We have another
    group of people for whom we have a high degree of confidence that they're going
    to stay, so the propensity of them leaving is pretty low. Again, we may not necessarily
    need to worry about them that much, but maybe the people we need to focus on are
    the people in the middle, because they're the predictions that are not quite as
    extreme, and so we cannot be quite as confident about those predictions. Potentially,
    we can do something with that group. We might be able to change their minds, or
    something like that, and that's how propensity scores can be used.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，倾向性分数所做的就是修改置信值，以便您可以查看某事发生的可能性。所以，如果您能将它们都放在某种光谱上，就可以看到，例如，有一些人对他们将要离开的信心程度很高，所以我们可能对此无能为力。我们还有另一组人对他们将要留下的信心程度很高，因此他们离开的倾向性很低。再次强调，我们可能不必过于担心他们，但可能我们需要关注的是中间的人，因为他们不是那么极端的预测，所以我们不能对那些预测有太大的信心。潜在地，我们可以对那组人做些事情。我们可能能够改变他们的想法，或者类似的事情，这就是倾向性分数的用途。
- en: Implementations of propensity scores
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 倾向性分数的实现
- en: 'To see how we can use propensity scores to our advantage, follow these steps:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解我们如何利用倾向性分数来获得优势，请按照以下步骤操作：
- en: Get your dataset on the canvas and connect it to a Partition node, dividing
    the dataset into two parts.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的数据集放在画布上，并将其连接到一个分区节点，将数据集分为两部分。
- en: Connect the Partition node to a Chaid model from the Modeling tab. You could
    use any model here, but let's use this as it will be used in our next example
    as well.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将分区节点连接到建模选项卡中的Chaid模型。您可以使用任何模型，但让我们使用这个，因为它也将在我们的下一个示例中使用。
- en: 'Chaid will build a decision tree model. To edit, go to the Model Options tab,
    where there is a section that asks for Propensity Scores. There are two types;
    a raw propensity score is for the training dataset and the adjusted propensity
    score is for the testing or validation dataset. We will select the raw propensity
    score for now:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Chaid将构建一个决策树模型。要编辑，请转到“模型选项”选项卡，其中有一个要求输入倾向得分的部分。有两种类型；原始倾向得分用于训练数据集，调整后的倾向得分用于测试或验证数据集。我们现在将选择原始倾向得分：
- en: '![](img/ea658e0a-6679-404c-bd44-55cdab3879ba.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ea658e0a-6679-404c-bd44-55cdab3879ba.png)'
- en: Click on Run. Connect the generated model to a Table node from the Output palette
    and run the Table. Observe the Table and see that we have another variable added
    known as the propensity score, and when a customer is predicted to be churned,
    and if their confidence score is low, the propensity score is *1-confidence* of
    what we really want. But for the Current customer, we have a propensity score
    similar to the confidence value.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“运行”。将生成的模型连接到输出调色板中的表节点，并运行表。观察表，你会看到添加了另一个变量，称为倾向得分。当预测客户将流失时，如果他们的置信度得分低，倾向得分就是我们所期望的*1-置信度*。但对于当前客户，我们有一个与置信度值相似的倾向得分。
- en: 'If you wish to see a graphical representation of this, connect the generated
    model, to the Histogram node from the Graphs palette. Edit the Histogram, in the
    field box, and select the propensity score variable:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想看到这个过程的图形表示，将生成的模型连接到图形调色板中的直方图节点。编辑直方图，在字段框中，并选择倾向得分变量：
- en: '![](img/008e5975-611e-4434-b90f-bc3b849a06f0.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/008e5975-611e-4434-b90f-bc3b849a06f0.png)'
- en: 'Click on Run to see the following:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“运行”以查看以下内容：
- en: '![](img/af0b244e-277b-4e36-8912-7227ecc4091b.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/af0b244e-277b-4e36-8912-7227ecc4091b.png)'
- en: 'Notice that the propensity scores will range from 0.0 to 1.0\. But the confidence
    values have only two values, and they have a range from 0.5 to 1.0\. To see this
    again, go to the histogram and from the Fields option, select the Confidence variable,
    then click on Run. You will see the following:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，倾向得分将在0.0到1.0之间变化。但置信度值只有两个值，它们的范围在0.5到1.0之间。要再次查看，请转到直方图，从“字段”选项中选择置信度变量，然后点击“运行”。你会看到以下内容：
- en: '![](img/b681f5ae-ebc6-4856-904e-f648f623f24b.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b681f5ae-ebc6-4856-904e-f648f623f24b.png)'
- en: Hence, we transformed the confidence values into a propensity score and now
    that propensity score is giving us information about the likelihood, in this case,
    of somebody staying as a customer. We could have done it the other way, where
    we were finding the propensity score for the likelihood of losing a customer,
    but we could just invert those scores and it would end up creating that for us.
    In any case, we can use those propensity scores now to do something with them,
    to see which customers are the most likely ones that we're going to lose, for
    example, or those which we're going to keep. However you want to look at it, you
    know which people that are very likely to be lost and so it may not be possible
    to do anything with them. Those people that were in the middle might not be lost,
    so maybe a little more could be done for them to try to keep them as customers
    and try to understand them better.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将置信度值转换为倾向得分，现在这个倾向得分正在给我们提供关于某人可能继续作为客户的可能性信息。我们本可以反过来做，即寻找客户流失的可能性的倾向得分，但我们只需反转这些得分，它就会为我们创建出相应的结果。无论如何，我们现在可以使用这些倾向得分来做些事情，比如查看哪些客户最有可能流失，或者哪些我们将保留的客户。无论如何你看待这个问题，你知道哪些人很可能流失，因此可能无法对他们做任何事情。那些处于中间状态的人可能不会流失，所以可能需要做更多的工作来尝试保留他们作为客户，并更好地了解他们。
- en: Meta-level modeling
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 元级建模
- en: Meta-level modeling is building a model based on predictions or results from
    another model. In the previous example, we saw how to create propensity scores
    for our **Chaid** model. In this section, we will see how you can extract results
    from the **Chaid** model and feed them into a Neural Net model, and this will
    enable us to improve the results from a Neural Net model.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 元级建模是基于另一个模型的预测或结果来构建模型。在之前的例子中，我们看到了如何为我们的**Chaid**模型创建倾向得分。在本节中，我们将看到如何从**Chaid**模型中提取结果并将其输入到神经网络模型中，这将使我们能够改进神经网络模型的结果。
- en: 'To do this, follow these steps:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，请按照以下步骤操作：
- en: Connect the partition node to the Neural Net node from the modeling palette.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将分区节点连接到建模调色板中的神经网络节点。
- en: Run the Neural Net model by changing the Random seed to `5000` from the Advanced
    options under the Build tab and click on Run. Now connect the generated Chaid
    model to the generated Neural Net model.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在“构建”标签页的高级选项中将随机种子从`5000`更改，运行神经网络模型。现在将生成的Chaid模型连接到生成的神经网络模型。
- en: Now, use the Analysis node to see the level of accuracy of these models.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用分析节点查看这些模型的准确度水平。
- en: 'You will get the following results:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将得到以下结果：
- en: '![](img/2651538a-9c6c-4ee8-91de-6ebc5e1320dd.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2651538a-9c6c-4ee8-91de-6ebc5e1320dd.png)'
- en: We can see that the accuracy of both the models is somewhat similar, so now
    we will move on to build a different kind of Neural Net model.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，这两个模型的准确性有些相似，所以现在我们将继续构建不同类型的神经网络模型。
- en: 'We will take the results from the Chaid model and feed them to the Neural Net
    model. The Neural Net model will then use the results, along with all other individual
    predictors, to try to capture more than Chaid:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从Chaid模型的结果中提取数据，并将其输入到神经网络模型中。然后，神经网络模型将使用这些结果，以及所有其他单个预测因子，尝试捕捉比Chaid更多的信息：
- en: Right-click on the generated Neural Net model and delete it.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击生成的神经网络模型并删除它。
- en: Connect the generated Chaid model to a Type node from the Field Ops palette.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将生成的Chaid模型连接到字段操作调色板中的类型节点。
- en: 'Scroll the Type node edit box to the bottom and set the confidence value variable
    of the Chaid model to None:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将类型节点编辑框滚动到最底部，并将Chaid模型的置信度变量设置为“无”：
- en: '![](img/9e2551b6-5c03-4b33-ba82-8f24d44ffa44.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9e2551b6-5c03-4b33-ba82-8f24d44ffa44.png)'
- en: Click on OK.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“确定”。
- en: Connect the Type node to the Neural Net model that we already have on the canvas
    and run it using the Random seed of `5000`.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将类型节点连接到画布上已有的神经网络模型，并使用随机种子`5000`运行它。
- en: 'If you take a look at the results of the new model, you can see that the most
    important predictors are the propensity scores from the Chaid model:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你查看新模型的结果，你可以看到最重要的预测因子来自Chaid模型的倾向得分：
- en: '![](img/662317dc-0e1c-44dd-8227-a0aad09f451b.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/662317dc-0e1c-44dd-8227-a0aad09f451b.png)'
- en: 'Connect the the generated Chaid model to Analysis node and run the analysis
    to get the following result:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将生成的Chaid模型连接到分析节点并运行分析，以获得以下结果：
- en: '![](img/0e52a752-684d-434d-b926-aa86c7e606bb.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0e52a752-684d-434d-b926-aa86c7e606bb.png)'
- en: In this example, we can see that in the Neural Net model, we got a 1% increase
    in accuracy if we fed the results from the Chaid model.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们可以看到，在神经网络模型中，如果我们从Chaid模型中提供结果，我们的准确性提高了1%。
- en: Error modeling
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 错误建模
- en: Error modeling is another form of meta-level modeling but in this case we will
    be modeling cases where there were errors in our predictions. In this way, we
    can increase the accuracy of that prediction. Using an example, we will walk through
    how to do error modeling.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 错误建模是元级建模的另一种形式，但在这个案例中，我们将建模预测中存在错误的情况。这样，我们可以提高预测的准确性。通过一个例子，我们将介绍如何进行错误建模。
- en: 'Consider the following scenario, for example:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下场景，例如：
- en: '![](img/cb0683df-a373-4da4-a23a-bc5a6ed14f84.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/cb0683df-a373-4da4-a23a-bc5a6ed14f84.png)'
- en: 'Here, we have a dataset named `LoyalTrain`. This is just a training dataset;
    we have our testing and validation dataset at a different place and will build
    a model only on the training dataset. Theer is also a Type node and a Neural Net
    model, where we are predicting the variable loyal. Run the Analysis node to see
    the results as shown in the following screenshot:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们有一个名为`LoyalTrain`的数据集。这只是一个训练数据集；我们的测试和验证数据集在另一个地方，我们只将在训练数据集上构建模型。还有一个类型节点和一个神经网络模型，我们在这里预测忠诚变量。运行分析节点查看以下截图所示的结果：
- en: '![](img/ded52372-c6cc-4205-bd25-f4177e98e3bf.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ded52372-c6cc-4205-bd25-f4177e98e3bf.png)'
- en: 'You can see that there are two categories in the outcome variable: people are
    either predicted to stay or to leave. You can also see that correct predictions
    were made in 79% of the cases. Mistakes were made in 21% of the cases. In total,
    there were 236 errors.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，结果变量中有两个类别：人们要么被预测为留下，要么被预测为离开。你还可以看到，在79%的情况下做出了正确的预测。在21%的情况下犯了错误。总共犯了236个错误。
- en: 'From this example, you can also see that the Neural Net model was copied and
    placed in another part of the stream. A new variable, `CORRECT`, was also made
    using a Derive node. Let''s take a look at what''s happened here, as shown in
    the following screenshot:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个例子中，你也可以看到，神经网络模型被复制并放置在流的另一部分。还使用一个派生节点创建了一个新的变量，`CORRECT`。让我们看看这里发生了什么，如下面的截图所示：
- en: '![](img/65e71ad2-fd93-46aa-a021-10af29b15c8b.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/65e71ad2-fd93-46aa-a021-10af29b15c8b.png)'
- en: Here, we have created a new field as `CORRECT`, and we have kept its values
    as `True` and `False`. We are telling Modeler here that if it finds a variable,
    LOYAL, and if it is equal to the prediction of LOYAL, then the value is True;
    otherwise, it is False.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个新的字段作为`CORRECT`，并保持其值为`True`和`False`。我们在这里告诉模型器，如果它找到一个变量LOYAL，并且如果它等于LOYAL的预测，则该值为True；否则，为False。
- en: 'If you run the Distribution node placed above it, you will see the following
    results:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行位于其上方的“分布”节点，你将看到以下结果：
- en: '![](img/424119fa-4336-4b65-b2a6-0bca6ad9afdd.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/424119fa-4336-4b65-b2a6-0bca6ad9afdd.png)'
- en: 'Next, we will use the Type node to instantiate the data, after which we can
    use a C5.0 decision tree model that looks at the data in a very different way.
    Here we have built a C5.0 model that is trying to predict if we are getting a
    correct or an incorrect prediction. Click on the generated C5.0 model to see its
    results, as shown in the following screenshot:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用类型节点实例化数据，之后我们可以使用一个以非常不同的方式查看数据的C5.0决策树模型。在这里，我们构建了一个C5.0模型，试图预测我们得到的是正确还是错误的预测。点击生成的C5.0模型以查看其结果，如下截图所示：
- en: '![](img/f708e93e-ff03-4077-b682-f45bc2d54d56.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f708e93e-ff03-4077-b682-f45bc2d54d56.png)'
- en: In this example, we can see that we have 14 rows with 4 rule(s) for a False
    prediction, that is, when we are predicting incorrectly, and 10 rule(s) for True
    values when we are predicting correctly.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们可以看到有14行，其中包含4条规则用于错误预测，即当我们预测错误时，以及10条规则用于正确值，即当我们预测正确时。
- en: 'You can expand the rules and click on the **%** sign above them to get the
    following results:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以展开规则并点击它们上面的**%**符号，以获得以下结果：
- en: '![](img/8c58a081-e865-4c1a-9e5a-a2565ae64a1a.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8c58a081-e865-4c1a-9e5a-a2565ae64a1a.png)'
- en: 'In this example, the first rule basically states that if you''re male and you''re
    using fewer than 1 minute of international calls, fewer than 1 minute of long-distance
    calls, and your status is single, we are predicting that we will have a value
    of False. If you want to see the numbers, click on the % sign, where you will
    see the following results:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，第一条规则基本上表明，如果你是男性，你使用少于1分钟的国外通话时间，少于1分钟的长途通话时间，并且你的状态是单身，我们预测我们将有一个False的值。如果你想查看数字，请点击%符号，你将看到以下结果：
- en: '![](img/b1a3a44a-e41d-486b-9ab1-3b8384d450ec.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b1a3a44a-e41d-486b-9ab1-3b8384d450ec.png)'
- en: As shown in the preceding screenshot, first rule had 22 people, and the accuracy
    of predictions relating to them was around 82%.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一张截图所示，第一条规则有22人，与他们相关的预测准确性大约为82%。
- en: 'From this, we can see that there are certain kinds of mistakes cropping up
    while we are making the predictions. We might therefore need to use another kind
    of model instead of a Neural Net model. To do this, click on the Generate option
    and select the Rule Trace Node, as shown in the following screenshot:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个结果中，我们可以看到在预测过程中出现了某些类型的错误。因此，我们可能需要使用另一种类型的模型而不是神经网络模型。为此，点击生成选项并选择规则跟踪节点，如下截图所示：
- en: '![](img/a1f3277c-c8a4-426e-8cbc-8177a04d7f4f.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a1f3277c-c8a4-426e-8cbc-8177a04d7f4f.png)'
- en: 'This step created the FALSE_TRUE node that you can see in the example scenario
    as the Start icon. This creates all of our rules. If you wish to take a look inside
    it, click on the Start + icon on the Tools tab, where you should see the following
    result:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤创建了一个名为FALSE_TRUE的节点，你可以在示例场景中看到它作为启动图标。这创建了我们的所有规则。如果你想查看其内部，请点击工具选项卡上的启动+图标，你应该会看到以下结果：
- en: '![](img/d42de6f6-3fb3-4c61-8eab-ec70ecae1c8b.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d42de6f6-3fb3-4c61-8eab-ec70ecae1c8b.png)'
- en: 'Let''s now take a look at the first rule. Click on the expression builder in
    that rule, as shown in the following screenshot:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看第一条规则。点击该规则中的表达式构建器，如下截图所示：
- en: '![](img/f58fb2fe-48ac-48da-b8f5-ebddab672ba6.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f58fb2fe-48ac-48da-b8f5-ebddab672ba6.png)'
- en: Here, the rule appears to state that if you're male and you're using fewer than
    1 minute of international calls, fewer than 1 minute of long-distance calls, and
    your status is also single, we're predicting that you're going to have a value
    of False. You can see the accuracy in that prediction.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，规则似乎表明，如果你是男性，你使用少于1分钟的国外通话时间，少于1分钟的长途通话时间，并且你的状态也是单身，我们预测你将有一个False的值。你可以看到这个预测的准确性。
- en: 'Go back using the Start icon. Here, we have the classify node, `Split`. Let''s
    see what we have done so far, as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用启动图标返回。在这里，我们有分类节点“分割”。让我们看看我们到目前为止做了什么，如下所示：
- en: '![](img/4f68ae73-f951-4022-9aed-dd9c01b17c94.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4f68ae73-f951-4022-9aed-dd9c01b17c94.png)'
- en: 'We have taken the variable RULE and clicked on Get, which gave us all of these
    different original values of False, which we renamed to Incorrect and all the
    values of True, which were renamed to Correct, and then we had just the Correct
    Predictions:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了变量 RULE 并点击了“获取”，这给我们提供了所有这些不同的原始值，我们将它们重命名为“不正确”，以及所有“True”的值，我们将它们重命名为“正确”，然后我们只有“正确预测”：
- en: '![](img/ec547e81-6ddc-42f5-a169-323d8d890d41.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ec547e81-6ddc-42f5-a169-323d8d890d41.png)'
- en: 'We have now built the Neural Net model. If you run the Analysis node of the
    generated Neural Net model from the Correct Predictions, you should see the following
    results:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经构建了神经网络模型。如果你从“正确预测”中运行生成的神经网络模型的“分析”节点，你应该看到以下结果：
- en: '![](img/28266a65-c6fd-40af-9336-4a1d478b1a18.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/28266a65-c6fd-40af-9336-4a1d478b1a18.png)'
- en: Remember that the overall accuracy of the earlier model was around 79%, which
    has now improved to around 84%.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，早期模型的总体准确率约为 79%，现在已提高到约 84%。
- en: 'We have also done the same thing for incorrect predictions in a separate field
    from the Type node. Let''s have a look at that, as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也在类型节点的一个单独字段中为不正确的预测做了同样的事情。让我们看看如下：
- en: '![](img/40117de4-64a4-460f-8f66-48277f984a9e.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/40117de4-64a4-460f-8f66-48277f984a9e.png)'
- en: 'We built a C5.0 model for incorrect predictions, so let''s take a look at its
    analysis, as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为不正确的预测构建了一个 C5.0 模型，让我们看看它的分析，如下所示：
- en: '![](img/dec38d60-e165-4cb6-a00c-cc4a4e5ade56.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/dec38d60-e165-4cb6-a00c-cc4a4e5ade56.png)'
- en: The C5.0 model has done a great job at predicting the incorrect values where
    the Neural Net model didn't work well; we now have an overall accuracy of 89%.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: C5.0 模型在预测神经网络模型表现不佳的不正确值方面做得很好；我们现在有 89% 的总体准确率。
- en: Let's sum up what we did here. We had a dataset that we split into correct and
    incorrect results and separately modeled each one to give us fewer errors than
    we used one model.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下我们在这里做了什么。我们有一个数据集，我们将其分为正确和错误的结果，并分别对每个结果进行建模，以给我们比使用一个模型更少的错误。
- en: 'Now we need to combine the predictions from the two models. For this, go to
    the Error 2 Stream from the Streams tab at the right, as shown in the following
    screenshot:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要结合两个模型的预测。为此，请转到右侧的“流”选项卡中的“错误 2 流”，如下面的截图所示：
- en: '![](img/265f52b9-f13d-4e27-86bf-33cdaf06c82f.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/265f52b9-f13d-4e27-86bf-33cdaf06c82f.png)'
- en: 'Here, we have combined the predictions of both the models and have used a Derive
    node Prediction, as shown in the following screenshot:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们结合了两个模型的预测，并使用了一个派生节点“预测”，如下面的截图所示：
- en: '![](img/1322cc1a-1431-48df-87cd-08f70911f8a7.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1322cc1a-1431-48df-87cd-08f70911f8a7.png)'
- en: Here, we have specified that if a prediction is correct, the prediction of the
    Neural Net model should be opted for. If a prediction is incorrect, we should
    opt for the prediction of the C5.0 model.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们指定如果预测是正确的，则选择神经网络模型的预测。如果预测是不正确的，我们应该选择 C5.0 模型的预测。
- en: 'Then, having added the Matrix node, run the following:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，添加了矩阵节点后，运行以下操作：
- en: '![](img/c07fa06b-e595-4f41-bb43-ec56a34afbc5.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c07fa06b-e595-4f41-bb43-ec56a34afbc5.png)'
- en: What we can see in the preceding screenshot is that we have correctly predicted
    that 437 people will leave with 118 errors, and that 498 people will stay with
    just 55 errors. This means there is a total number of 173 errors.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，我们可以看到我们正确预测了 437 人将离开，有 118 个错误，以及 498 人将留下，只有 55 个错误。这意味着总共有 173 个错误。
- en: Our original model made 236 errors, so we have brought down the number of errors
    by a great extent. Just by using two different models for different groups of
    people and by combining them with, we have produced an output with 63 fewer errors.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的原模型犯了 236 个错误，所以我们极大地减少了错误数量。仅仅通过为不同的人群使用两个不同的模型并将它们结合起来，我们就产生了一个包含 63 个更少错误的输出。
- en: This is error modeling. In error modelling you can build one model, see what
    the results look like, and then decide from there whether to build two or three
    models for different types of people, because it can't be assumed that one size
    fits all. Therefore, we can build different kinds of models, feed different types
    of data to those models, and then ultimately combine the results of each model
    to produce a final prediction that can end up having fewer errors in terms of
    the predictive modeling undertaken.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这是错误建模。在错误建模中，你可以构建一个模型，看看结果如何，然后决定是否为不同类型的人构建两个或三个模型，因为不能假设一个模型适用于所有人。因此，我们可以构建不同类型的模型，向这些模型提供不同类型的数据，然后最终将每个模型的结果结合起来，生成一个最终预测，这个预测在预测建模方面可能包含更少的错误。
- en: Boosting and bagging
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升和袋装
- en: The idea behind boosting is that by building successive models that are built
    to predict the misclassifications of earlier models you're performing a form of
    error modeling. Bagging, on the other hand, is sampling with replacement. With
    this method, new training datasets are generated which are of the same size as
    the original dataset. For our example in this section, will be using a bootstrap
    sample.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 提升背后的想法是通过构建一系列旨在预测先前模型误分类的连续模型，你正在进行一种错误建模。另一方面，袋装是带替换的抽样。使用这种方法，将生成新的训练数据集，其大小与原始数据集相同。在本节的例子中，我们将使用自助抽样。
- en: In this example, we're going to see how to do boosting and bagging, which are
    two methods of improving a model.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将了解如何进行提升和袋装，这两种方法都是提高模型性能的方法。
- en: Boosting
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升功能
- en: 'Let''s see how to do boosting with the following steps:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何按照以下步骤进行提升：
- en: Get your data on a canvas and partition it.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据放在画布上并对其进行分区。
- en: Create a Neural Net model for the data.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为数据创建一个神经网络模型。
- en: Run the Neural Net model with a Random seed set to `5000`.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以随机种子设置为`5000`运行神经网络模型。
- en: Connect an Analysis node and run it with Coincidence matrices checked – you
    will see that the testing accuracy is 81% and the overall accuracy is 80%.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接一个分析节点并运行它，同时勾选巧合矩阵——你会看到测试准确率为81%，整体准确率为80%。
- en: Now, boost the Neural Net model. For this, go to the Neural Net model and edit
    it. Go to Objectives under Build options and click on Enhance model accuracy (boosting).
    Boosting can be used with any size of dataset. The idea here is that we're building
    successive models that are built to predict the misclassifications of earlier
    models. So, basically, we end up building a model. There'll be some errors, so
    a second model should be built where the errors of the first model are given more
    weight so that we're able to understand them better. Then, when we build a second
    model, there are going to be errors, so we end up building a third model where
    the errors of the second model are given more weight again so that we try to understand
    them better, and so forth. Whenever you're doing boosting and bagging, you always
    have to make sure you have a training and a testing dataset because there's a
    very good chance that you're going to capitalize on chance, and that you might
    find sample-specific information because we're focusing on the errors that we're
    finding within that specific sample. We'll now click on Run.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，提升神经网络模型。为此，转到神经网络模型并对其进行编辑。在构建选项下转到目标，然后点击增强模型准确性（提升）。提升可以与任何大小的数据集一起使用。这里的想法是我们正在构建一系列连续的模型，这些模型旨在预测先前模型的误分类。所以，基本上，我们最终构建了一个模型。会有一些错误，因此应该构建第二个模型，在这个模型中，第一个模型的错误被赋予更高的权重，以便我们更好地理解它们。然后，当我们构建第二个模型时，将会有错误，所以我们最终构建第三个模型，在这个模型中，第二个模型的错误再次被赋予更高的权重，以便我们试图更好地理解它们，以此类推。无论何时进行提升和袋装，你都必须确保你有训练集和测试集，因为你有很大的机会利用机会，你可能会发现样本特定的信息，因为我们专注于我们在特定样本中发现的错误。我们现在将点击运行。
- en: 'Let''s take a look at our generated model:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看我们生成的模型：
- en: '![](img/5ce2de68-ad80-4cbd-a5e4-5ce279231e75.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ce2de68-ad80-4cbd-a5e4-5ce279231e75.png)'
- en: 'The first tab that we have here in our generated model is showing us what the
    Ensemble model looks like: that''s combining the 10 models that we''ve created.
    You can see its overall accuracy is about 98%: that''s the model that''s been
    chosen as the best model. You can also see what the reference model is—that would
    be the first model that was built—and then you can see the naive model and, really,
    that''s no model, that''s just where we''re predicting the mode or the most common
    response.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们生成的模型中，第一个标签显示的是集成模型的外观：这是结合了我们创建的10个模型。你可以看到其整体准确率约为98%：这是被选为最佳模型的模型。你还可以看到参考模型是什么——那将是第一个构建的模型——然后你可以看到朴素模型，实际上，那根本不是模型，那只是我们预测众数或最常见响应的地方。
- en: 'Let''s go down to the second icon:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们下滑到第二个图标：
- en: '![](img/ddc7969a-8722-4c53-988a-aadd7f4b0c58.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ddc7969a-8722-4c53-988a-aadd7f4b0c58.png)'
- en: Here, you can see the Predictor Importance. Across the 10 models that we ended
    up building, we can see that the Premier variable was the most important predictor
    and then you can see what the other predictors were in terms of their order of
    importance. This is the same kind of information that we would see typically with
    a general Neural Net model, but this information comes from across all the different
    models that we built.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到预测因子的重要性。在最终构建的10个模型中，我们可以看到“Premier”变量是最重要的预测因子，然后你可以看到其他预测因子的重要性顺序。这与我们通常在一般神经网络模型中看到的信息类似，但这个信息来自我们构建的所有不同模型。
- en: 'If we go down to the next icon we can see Predictor Frequency:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们向下滚动到下一个图标，我们可以看到预测因子频率：
- en: '![](img/e237b5dd-1edb-4a38-b606-72bb67c75bb2.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e237b5dd-1edb-4a38-b606-72bb67c75bb2.png)'
- en: This shows us how frequently each one of the different predictors was used in
    the model. For a Neural Net model this is not so interesting because Neural Net
    models generally do not drop predictors, but if we had a decision tree model,
    for example, this could be a little more interesting because there you do drop
    predictors.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了在模型中每个不同预测因子被使用的频率。对于神经网络模型来说，这并不那么有趣，因为神经网络模型通常不会丢弃预测因子，但如果我们有一个决策树模型，例如，这可能就更有趣一些，因为在那里你会丢弃预测因子。
- en: 'Let''s go down to the next tab:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们向下滚动到下一个标签页：
- en: '![](img/3c80ce0a-da3c-4de0-a374-28f0a6c19119.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3c80ce0a-da3c-4de0-a374-28f0a6c19119.png)'
- en: The preceding screenshot is showing us the level of accuracy of the model. You
    can see that it flattens out and, at some point, there's no longer much of an
    improvement. In this case, it's a gradual increase in terms of accuracy. Sometimes,
    in some models, you see perhaps five models that there's a huge jump in accuracy
    and then it just stabilizes. Maybe you wouldn't necessarily need to build any
    more models. In our case, we ended up building 10 models. Our overall accuracy
    was extremely high. If we had seen much lower accuracy, perhaps because we saw
    a gradual increase, maybe we would want to use 15 models instead of 10, for example.
    That's where you would see this kind of information.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 上述截图显示了模型的准确度水平。你可以看到它趋于平稳，在某个点上，改进不再明显。在这种情况下，准确度是逐渐提高的。有时，在某些模型中，你会看到大约五个模型准确度有巨大的跳跃，然后它就稳定了。也许你不必再构建更多的模型。在我们的案例中，我们最终构建了10个模型。我们的整体准确度极高。如果我们看到准确度很低，可能是因为我们看到了逐渐的提高，也许我们想要使用15个模型而不是10个，例如。这就是你将看到这种信息的地方。
- en: 'Let''s scroll down a little further and let''s see the final table:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们再向下滚动一点，看看最后的表格：
- en: '![](img/02ba2c0d-ac25-4f39-8f20-ff527d686dff.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/02ba2c0d-ac25-4f39-8f20-ff527d686dff.png)'
- en: Here, we can see the number of predictors and we can also see the number of
    cases that we had in the model as well. Finally, we see the number of synapses,
    which are basically the number of weights or the number of connections that we
    have within this model. So, you can see how well each one of these individual
    models is doing. Each new version of a model is giving more weight to where we
    had more errors in the data and that's basically the idea here.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到预测因子的数量，我们还可以看到模型中的案例数量。最后，我们看到突触的数量，这基本上是我们在这个模型中拥有的权重或连接的数量。因此，你可以看到每个单独的模型表现如何。每个模型的新版本都在数据中错误较多的地方赋予更多的权重，这正是这里的理念。
- en: Run the Analysis node, finally, and you can see that for the training dataset
    the overall accuracy was about 98%. But in the testing dataset the overall accuracy
    was about 80% that's what we really care about, the testing dataset. In this case,
    we see that there's a big difference between training and testing and that's generally
    going to be the situation when talking about boosting models.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后运行分析节点，你可以看到对于训练数据集，整体准确度大约为98%。但在测试数据集中，整体准确度大约为80%，这是我们真正关心的，即测试数据集。在这种情况下，我们可以看到训练和测试之间存在很大差异，这通常在讨论提升模型时会出现。
- en: Make sure that whatever result you get is really worth it, and that it's really
    an improvement over just running the model on its own. In this case, when we just
    ran one model, remember that the overall accuracy on the testing data set was
    at about 80%; that's what we have here. So really, boosting didn't do much for
    us in this particular situation. In other situations, it certainly can, but again
    you want really to be able to weigh that, and in this case boost seemed to be
    probably not really worth it for us in this situation.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你得到的结果确实值得，并且它确实比单独运行模型有所改进。在这种情况下，当我们只运行一个模型时，请记住，测试数据集的整体准确率大约在80%左右；这就是我们在这里看到的情况。所以，在这个特定情况下，提升并没有给我们带来太多好处。在其他情况下，它当然可以，但再次强调，你真的需要能够权衡这一点，在这种情况下，提升似乎对我们来说在这个情况下并不真正值得。
- en: Bagging
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Bagging
- en: 'Let''s go back into the Neural Net model and, this time, what we''re going
    to do is bagging instead of boosting:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到神经网络模型，这次我们将进行Bagging而不是提升：
- en: Go over to the Objectives tab and select Enhance model stability – it's sampling
    with replacement. Do not do bagging when you have small datasets or outliers.
    The main idea behind bagging is that new training datasets are generated that
    are of the same size as the original training dataset and this is done by using
    sampling with replacement. We're actually bootstrapping in this kind of situation.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到目标选项卡并选择增强模型稳定性——这是有放回的抽样。当数据集较小或存在异常值时，不要进行Bagging。Bagging背后的主要思想是生成新的训练数据集，其大小与原始训练数据集相同，这是通过使用有放回的抽样来实现的。在这种情况下，我们实际上是在进行自助抽样。
- en: Click on Run for the model.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击运行模型。
- en: 'Let''s take a look at our generated model. This is the model that we ended
    up building:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来看看我们生成的模型。这是我们最终构建的模型：
- en: '![](img/41820b52-d713-4c53-b7bf-2c47a2c0e7dd.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/41820b52-d713-4c53-b7bf-2c47a2c0e7dd.png)'
- en: Notice that the combining rule is achieved by voting but there are other ways
    in which we can combine models and, in fact, we can choose the option to show
    all the combining rules. We won’t see the details for all the models because the
    screenshots are the same as with boosting.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，组合规则是通过投票实现的，但我们可以用其他方法来组合模型，实际上，我们可以选择显示所有组合规则。我们不会看到所有模型的详细信息，因为截图与提升树相同。
- en: 'Run the Analysis node to get the following results:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行分析节点以获取以下结果：
- en: '![](img/4467c320-7c2c-4511-9d45-ecf3360f8c61.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4467c320-7c2c-4511-9d45-ecf3360f8c61.png)'
- en: We can see that, by doing the bagging, we got a 4% increase in accuracy.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，通过进行Bagging，我们的准确率提高了4%。
- en: We will now see how to predict continuous outcomes.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将看到如何预测连续结果。
- en: Predicting continuous outcomes
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测连续结果
- en: Until now, we have spent all of our time talking about categorical outcomes
    and most of those examples apply to continuous outcomes, but in this section we're
    going to focus exclusively on continuous outcome variables.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在谈论分类结果，而大多数这些例子也适用于连续结果，但在这个部分，我们将专门关注连续结果变量。
- en: 'As I mentioned previously, when we''re talking about continuous outcome predictions
    or variables, everything that we''ve talked about in this book still applies:
    the main difference, though, is going to be in terms of how we end up combining
    predictions.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如我之前提到的，当我们谈论连续结果预测或变量时，这本书中提到的所有内容仍然适用：不过，主要区别将在于我们最终如何组合预测。
- en: 'Here, in this example, we can see that we built three models and we have predictions
    from each one of those models:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们可以看到我们构建了三个模型，并且从每个模型中都有预测结果：
- en: '![](img/ad40d5e6-8fe5-40fd-bc5f-7e856ee27814.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad40d5e6-8fe5-40fd-bc5f-7e856ee27814.png)'
- en: When we want to combine the predictions, all we do is take a mathematical average.
    The mean of these previous models ends up being the combined prediction because
    we're not predicting individual categories as we were when we had a categorical
    outcome variable. Instead, we're predicting actual numeric values and if we want
    to combine predictions from these different models, all we do, simply, is take
    the average of the models. For example, in the first row, the first model predicted
    a value of 7, the next model predicted a value of 9, and the third model predicted
    8\. We take those values, we add them up, we divide them by the number of models,
    and the combined prediction ends up being a value of 8\. That's the way you would
    combine your models.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要合并预测时，我们只是做一个数学平均。这些先前模型的平均值最终成为合并预测，因为我们不是像在具有分类结果变量时那样预测单个类别。相反，我们预测实际的数值，如果我们想从这些不同的模型中合并预测，我们简单地做的就是取这些模型的平均值。例如，在第一行，第一个模型预测的值为7，下一个模型预测的值为9，第三个模型预测的值为8。我们取这些值，将它们加起来，然后除以模型的数量，合并预测最终得到的值是8。这就是你合并模型的方法。
- en: But when we have continuous outcome variables, we do not have a confidence value,
    so we don't need to worry about the actual confidence values for those kind of
    models.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 但是当我们有连续的结果变量时，我们没有置信度值，所以我们不需要担心这些类型模型的实际置信度值。
- en: In this example, we're going to use the bank dataset. Bring it onto the canvas.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用银行数据集。将其拖到画布上。
- en: 'Let''s just take a look at what that data looks like:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些数据看起来是什么样子：
- en: '![](img/18a8aa3b-bba8-444d-87c8-02eae8cf61f7.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/18a8aa3b-bba8-444d-87c8-02eae8cf61f7.png)'
- en: As you can see, there are several fields. We will predict a variable, salnow,
    that's our target variable based on a beginning salary, gender, the amount of
    time that someone has worked at this organization, their age, their level of education,
    the number of years that they have worked prior to coming to this organization,
    the job category that they're in, whether they're from a minority, and then the
    interaction of race and gender.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，有几个字段。我们将预测一个变量，salnow，这是我们基于起始工资、性别、某人在该组织工作的时间、年龄、教育水平、他们来该组织之前工作过的年数、他们所在的职位类别、他们是否来自少数族裔以及种族和性别的交互作用的目标变量。
- en: Partition the dataset and go on to create a Neural Net model. Run the Neural
    Net model with default settings. Take a look at the newly generated model.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集分区，然后继续创建一个神经网络模型。使用默认设置运行神经网络模型。查看新生成的模型。
- en: Let's also build the SVM model just as we have done before. We will compare
    the results of both the models.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也像以前一样构建SVM模型。我们将比较两个模型的预测结果。
- en: 'This is the output for the SVM model:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这是SVM模型的输出：
- en: '![](img/03c2bef9-241f-4f8f-b2a5-117d41fde46f.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/03c2bef9-241f-4f8f-b2a5-117d41fde46f.png)'
- en: Connect the two generated models and connect the SVM model to a Table and run
    the table.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 将两个生成的模型连接起来，并将SVM模型连接到表格上并运行表格。
- en: Scroll towards the end and you can see a Partition node and predictions of the
    two models. Notice that there are no confidence values for these continuous outcome
    variables.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动到末尾，您可以看到一个分区节点和两个模型的预测。请注意，这些连续结果变量没有置信度值。
- en: 'This also means that we won''t get the propensity scores for these models either.
    Bring an Analysis node and connect the SVM model to the Analysis node and run
    it:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这也意味着我们也不会得到这些模型的倾向得分。引入一个分析节点，并将SVM模型连接到分析节点并运行它：
- en: '![](img/58d64813-3dec-4fb2-9ba9-5d2a57a92a97.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/58d64813-3dec-4fb2-9ba9-5d2a57a92a97.png)'
- en: The analysis is a little bit different than what we used to get with the categorical
    variables. You can see that there is a Minimum Error, and a Maximum Error for
    both the training and the testing datasets. The model has done a worst job in
    over- or under-predicting the values.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 分析与以前我们用分类变量得到的分析略有不同。您可以看到，对于训练集和测试集，都有最小误差和最大误差。模型在预测值过高或过低方面做得最差。
- en: Mean Error is just averaging of the errors. The best way to look at the accuracy
    of these models is by looking at the Mean Absolute Error. As you can see, we have
    a lower value for the training dataset as compared to the testing dataset. These
    values need to be similar. You can see the mean absolute value for the SVM model.
    You can also see the Standard Deviation. This needs to be as small as possible
    because this shows that we have less variation in the model. Another criterion
    is the correlation coefficient. That is extremely high for both the datasets;
    these values must be similar to each other. People use linear coefficients to
    validate the usefulness of a model, but sometimes we don't have linear relationships.
    So, in such cases, we will use the mean absolute error value as the best measure
    of assessing how the model is performing. **Occurrences** are the number of cases
    that we have for each dataset.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 均值误差只是误差的平均值。查看这些模型准确性的最佳方式是查看平均绝对误差。如您所见，与测试数据集相比，训练数据集的值较低。这些值需要相似。您可以看到SVM模型的平均绝对值。您还可以看到标准差。这个值需要尽可能小，因为这表明我们在模型中具有更少的变异。另一个标准是相关系数。对于这两个数据集，这个值都极高；这些值必须彼此相似。人们使用线性系数来验证模型的有用性，但有时我们并没有线性关系。因此，在这种情况下，我们将使用平均绝对误差值作为评估模型表现的最佳度量。**发生次数**是每个数据集的案例数量。
- en: 'Let''s now combine the model:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们结合模型：
- en: Connect the last generated node to an ensemble node from the Field Ops palette.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将最后生成的节点连接到字段操作调色板中的集成节点。
- en: Edit the Ensemble node. Deselect the Filter out field and click OK.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑集成节点。取消选择“过滤出”字段并点击确定。
- en: Connect the Ensemble node to the Table node already present and run the Table.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将集成节点连接到已存在的表节点并运行表。
- en: You can see that we have predictions from the SVM, Neural Net, and if we average
    those two, we have the predictions from the combined model. We also have our standard
    errors as well. For those who are not using modeler, a Derive node can be used
    to calculate the averages of these models and get a combined result.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以看到来自SVM、神经网络以及如果我们平均这两个，我们就有综合模型的预测。我们还有我们的标准误差。对于那些不使用模型器的人来说，可以使用派生节点来计算这些模型的平均值并得到综合结果。
- en: 'To see the results, connect the Ensembles node to an Analysis node and run
    it:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看结果，将集成节点连接到分析节点并运行它：
- en: '![](img/ce42d8e1-d88d-47ea-90ef-56caf40e7293.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ce42d8e1-d88d-47ea-90ef-56caf40e7293.png)'
- en: This was an example of how we can work with continuous variables.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个如何处理连续变量的例子。
- en: Summary
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we saw how we can make additional advance operations on models
    to get better results. Hopefully, you have a deeper insight into how data is fetched
    to train a machine and how we can make a better model by training it on different
    types of data.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了如何对模型进行额外的先进操作以获得更好的结果。希望您对数据如何被提取来训练机器以及我们如何通过在不同类型的数据上训练来创建更好的模型有了更深的理解。
