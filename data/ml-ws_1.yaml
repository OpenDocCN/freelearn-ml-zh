- en: 1\. Introduction to Scikit-Learn
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. Scikit-Learn简介
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: 'This chapter introduces the two main topics of this book: machine learning
    and scikit-learn. By reading this book, you will learn about the concept and application
    of machine learning. You will also learn about the importance of data in machine
    learning, as well as the key aspects of data preprocessing to solve a variety
    of data problems. This chapter will also cover the basic syntax of scikit-learn.
    By the end of this chapter, you will have a firm understanding of scikit-learn''s
    syntax so that you can solve simple data problems, which will be the starting
    point for developing machine learning solutions.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了本书的两个主要主题：机器学习和 scikit-learn。通过阅读本书，你将学习到机器学习的概念和应用。你还将了解数据在机器学习中的重要性，以及数据预处理的关键方面，以解决各种数据问题。本章还将涵盖
    scikit-learn 的基本语法。通过本章的学习，你将对 scikit-learn 的语法有一个坚实的理解，从而能够解决简单的数据问题，这将成为开发机器学习解决方案的起点。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: '**Machine learning** (**ML**), without a doubt, is one of the most relevant
    technologies nowadays as it aims to convert information (data) into knowledge
    that can be used to make informed decisions. In this chapter, you will learn about
    the different applications of ML in today''s world, as well as the role that data
    plays. This will be the starting point for introducing different data problems
    throughout this book that you will be able to solve using scikit-learn.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）无疑是当今最重要的技术之一，因为它旨在将信息（数据）转化为可以用于做出明智决策的知识。在本章中，你将学习到机器学习在当今世界中的不同应用，以及数据在其中所扮演的角色。这将成为本书中介绍不同数据问题的起点，你将能够通过使用
    scikit-learn 来解决这些问题。'
- en: Scikit-learn is a well-documented and easy-to-use library that facilitates the
    application of ML algorithms by using simple methods, which ultimately enables
    beginners to model data without the need for deep knowledge of the math behind
    the algorithms. Additionally, thanks to the ease of use of this library, it allows
    the user to implement different approximations (that is, create different models)
    for a data problem. Moreover, by removing the task of coding the algorithm, scikit-learn
    allows teams to focus their attention on analyzing the results of the model to
    arrive at crucial conclusions.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn 是一个文档齐全且易于使用的库，通过使用简单的方法促进了机器学习算法的应用，最终使初学者能够在无需深入了解算法背后的数学知识的情况下进行数据建模。此外，得益于这个库的易用性，它使得用户能够为数据问题实现不同的近似方法（即创建不同的模型）。更重要的是，通过去除编写算法代码的任务，scikit-learn
    使得团队能够将注意力集中在分析模型结果上，以得出关键结论。
- en: Spotify, a world-leading company in the field of music streaming, uses scikit-learn
    because it allows them to implement multiple models for a data problem, which
    are then easily connected to their existing development. This process improves
    the process of arriving at a useful model, while allowing the company to plug
    them into their current app with little effort.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Spotify，作为全球领先的音乐流媒体公司，使用 scikit-learn，因为它允许他们为数据问题实施多个模型，并且这些模型可以轻松地与现有开发系统进行连接。这个过程改进了获得有用模型的过程，同时使公司能够以极少的努力将这些模型接入现有应用中。
- en: On the other hand, [booking.com](http://booking.com) uses scikit-learn due to
    the wide variety of algorithms that the library offers, which allows them to fulfill
    the different data analysis tasks that the company relies on, such as building
    recommendation engines, detecting fraudulent activities, and managing the customer
    service team.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面， [booking.com](http://booking.com) 使用 scikit-learn，是因为该库提供了种类繁多的算法，使他们能够完成公司依赖的各种数据分析任务，例如构建推荐引擎、检测欺诈活动以及管理客户服务团队。
- en: Considering the preceding points, this chapter also explains scikit-learn and
    its main uses and advantages, and then moves on to provide a brief explanation
    of the scikit-learn **Application Programming Interface** (**API**) syntax and
    features. Additionally, the process of representing, visualizing, and normalizing
    data will be shown. The aforementioned information will help us to understand
    the different steps that need to be taken to develop a ML model.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于上述要点，本章还将解释 scikit-learn 及其主要用途和优点，并简要介绍 scikit-learn **应用程序接口**（**API**）的语法和功能。此外，还将展示数据表示、可视化和标准化的过程。上述信息将帮助我们理解开发机器学习模型所需采取的不同步骤。
- en: In the following chapters in this book, you will explore the main ML algorithms
    that can be used to solve real-life data problems. You will also learn about different
    techniques that you can use to measure the performance of your algorithms and
    how to improve them accordingly. Finally, you will explore how to make use of
    a trained model by saving it, loading it, and creating APIs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的接下来的章节中，你将探索可以用于解决现实数据问题的主要机器学习算法。你还将学习不同的技术，用于衡量算法的性能，并了解如何相应地改进它们。最后，你将探索如何通过保存、加载模型并创建API来使用训练好的模型。
- en: Introduction to Machine Learning
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习简介
- en: '**Machine learning** (**ML**) is a subset of **Artificial Intelligence** (**AI**)
    that consists of a wide variety of algorithms capable of learning from the data
    that is being fed to them, without being specifically programmed for a task. This
    ability to learn from data allows the algorithms to create models that are capable
    of solving complex data problems by finding patterns in historical data and improving
    them as new data is fed to the models.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）是**人工智能**（**AI**）的一个子集，包含了多种能够从输入数据中学习的算法，而不需要为特定任务进行编程。这种从数据中学习的能力使得算法能够创建模型，通过在历史数据中寻找模式并随着新数据的输入不断改进模型，从而解决复杂的数据问题。'
- en: These different ML algorithms use different approximations to solve a task (such
    as probability functions), but the key element is that they are able to consider
    a countless number of variables for a particular data problem, making the final
    model better at solving the task than humans are. The models that are created
    using ML algorithms are created to find patterns in the input data so that those
    patterns can be used to make informed predictions in the future.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些不同的机器学习算法使用不同的近似方法来解决任务（例如概率函数），但关键是它们能够考虑大量变量来解决特定的数据问题，使得最终的模型在解决任务时比人类更有效。通过机器学习算法创建的模型旨在从输入数据中寻找模式，以便在未来做出更有根据的预测。
- en: Applications of ML
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习的应用
- en: 'Some of the popular tasks that can be solved using ML algorithms are price/demand
    predictions, product/service recommendation, and data filtering, among others.
    The following is a list of real-life examples of such tasks:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的可以通过机器学习算法解决的任务包括价格/需求预测、产品/服务推荐以及数据过滤等。以下是这些任务的现实生活中的一些例子：
- en: '**On-demand price prediction**: Companies whose services vary in price according
    to demand can use ML algorithms to predict future demand and determine whether
    they will have the capability to meet it. For instance, in the transportation
    industry, if future demand is low (low season), the price for flights will drop.
    On the other hand, is demand is high (high season), flights are likely to increase
    in price.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**按需价格预测**：服务价格随着需求变化的公司可以使用机器学习算法预测未来的需求，并确定是否有能力满足这一需求。例如，在交通运输行业，如果未来的需求低（淡季），航班价格将下降。相反，如果需求高（旺季），航班价格可能会增加。'
- en: '**Recommendations in entertainment**: Using the music that you currently use,
    as well as that of the people similar to you, ML algorithms can construct models
    capable of suggesting new records that you may like. That is also the case of
    video streaming applications, as well as online bookstores.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**娱乐推荐**：利用你当前使用的音乐以及与自己相似的人的音乐，机器学习算法能够构建模型，建议你可能喜欢的新专辑。这同样适用于视频流媒体应用程序和在线书店。'
- en: '**Email filtering**: ML has been used for a while now in the process of filtering
    incoming emails in order to separate spam from your desired emails. Lately, it
    also has the capability to sort unwanted emails into more categories, such as
    social and promotions.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电子邮件过滤**：机器学习已经被应用于过滤来信，将垃圾邮件与你想要的邮件分开。最近，它还能够将不需要的邮件分类为更多的类别，如社交邮件和促销邮件。'
- en: Choosing the Right ML Algorithm
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择合适的机器学习算法
- en: When it comes to developing ML solutions, it is important to highlight that,
    more often than not, there is no one solution for a data problem, much like there
    is no algorithm that fits all data problems. According to this and considering
    that there is a large quantity of algorithms in the field of ML, choosing the
    right one for a certain data problem is often the turning point that separates
    outstanding models from mediocre ones.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发机器学习解决方案时，需要强调的是，往往没有单一的解决方案可以解决所有的数据问题，就像没有适用于所有数据问题的算法一样。基于这一点，考虑到机器学习领域存在大量算法，选择适合特定数据问题的算法往往是区分优秀模型和普通模型的转折点。
- en: 'The following steps can help narrow down the algorithms to just a few:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤可以帮助将算法范围缩小到几个：
- en: '**Understand your data**: Considering that data is the key to being able to
    develop any ML solutions, the first step should always be to understand it in
    order to be able to filter out any algorithm that is unable to process such data.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**了解你的数据**：鉴于数据是能够开发任何机器学习解决方案的关键，第一步始终应该是理解数据，以便能够筛选掉无法处理这些数据的算法。'
- en: For instance, considering the quantity of features and observations in your
    dataset, it is possible to determine whether an algorithm capable of producing
    outstanding results with a small dataset is required. The number of instances/features
    to consider a dataset small depends on the data problem, the quantity of the outputs,
    and so on. Moreover, by understanding the types of fields in your dataset, you
    will also be able to determine whether you need an algorithm capable of working
    with categorical data.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，考虑到数据集中特征和观察值的数量，可以确定是否需要一种能够在小型数据集上产生优秀结果的算法。判断数据集是否较小，取决于数据问题、输出的数量等因素。此外，通过理解数据集中字段的类型，你还可以判断是否需要能够处理分类数据的算法。
- en: '`A`) algorithms. On the other hand, datasets without a target feature are known
    as unlabeled data and are solved using unsupervised learning algorithms (`B`).'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`A`) 算法。另一方面，没有目标特征的数据集被称为无标签数据，并通过无监督学习算法（`B`）解决。'
- en: 'Moreover, the output data (the form of output that you expect from the model)
    also plays a key role in determining the algorithms to be used. If the output
    from the model needs to be a continuous number, the task to be solved is a regression
    problem (`C`). On the other hand, if the output is a discrete value (a set of
    categories, for instance), the task at hand is a classification problem (`D`).
    Finally, if the output is a subgroup of observations, the process to be performed
    is a clustering task (`E`):'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，输出数据（你期望从模型中获得的输出形式）也在决定使用哪些算法时发挥着关键作用。如果模型的输出需要是一个连续的数值，则任务是回归问题（`C`）。另一方面，如果输出是一个离散值（例如一组类别），则任务是分类问题（`D`）。最后，如果输出是一组观察值的子集，那么需要执行的是聚类任务（`E`）：
- en: '![Figure 1.1: Demonstrating the division of tasks'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.1：展示任务划分'
- en: '](img/B15781_01_01.jpg)'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_01_01.jpg)'
- en: 'Figure 1.1: Demonstrating the division of tasks'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.1：展示任务划分
- en: This division of tasks will be explored in more detail in the *Supervised and
    Unsupervised Learning* section of this chapter.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本章的*监督学习与无监督学习*部分将对任务的划分进行更详细的探讨。
- en: '**Choose a set of algorithms**: Once the preceding steps have been performed,
    it is possible to filter out the algorithms that perform well over the input data
    and that are able to arrive at the desired outcome. Depending on your resources
    and time limitations, you should choose from this list of apt algorithms the ones
    that you want to test out over your data problem, considering that it is always
    a good practice to try more than one algorithm.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择一组算法**：一旦完成前述步骤，就可以筛选出那些在输入数据上表现良好并能够达到预期结果的算法。根据你的资源和时间限制，你应该从这些合适的算法中选择一些进行测试，考虑到尝试多种算法始终是一个好习惯。'
- en: These steps will be explained in more detail in the next chapter using a real-life
    data problem as an example.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤将在下一章中通过一个实际数据问题作为例子进行更详细的解释。
- en: Scikit-Learn
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scikit-Learn
- en: Created in 2007 by David Cournapeau as part of a Google Summer of Code project,
    scikit-learn is an open source Python library made to facilitate the process of
    building models based on built-in ML and statistical algorithms, without the need
    for hardcoding. The main reasons for its popular use are its complete documentation,
    its easy-to-use API, and the many collaborators who work every day to improve
    the library.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn由David Cournapeau于2007年作为Google Summer of Code项目的一部分创建，是一个开源的Python库，旨在简化基于内置机器学习和统计算法构建模型的过程，无需手动编写代码。它广受欢迎的主要原因是其完整的文档、易于使用的API以及众多致力于每天改进该库的合作者。
- en: Note
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can find the documentation for scikit-learn at [http://scikit-learn.org](http://scikit-learn.org).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[http://scikit-learn.org](http://scikit-learn.org)找到scikit-learn的文档。
- en: Scikit-learn is mainly used to model data, and not as much to manipulate or
    summarize data. It offers its users an easy-to-use, uniform API to apply different
    models with little learning effort, and no real knowledge of the math behind it
    is required.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn主要用于对数据建模，而不是用于处理或总结数据。它为用户提供了一个易于使用、统一的API，可以用很少的学习成本应用不同的模型，而无需深入了解背后的数学原理。
- en: Note
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Some of the math topics that you need to know about to understand the models
    are linear algebra, probability theory, and multivariate calculus. For more information
    on these models, visit [https://towardsdatascience.com/the-mathematics-of-machine-learning-894f046c568](https://towardsdatascience.com/the-mathematics-of-machine-learning-894f046c568).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这些模型，你需要了解一些数学知识，包括线性代数、概率论和多元微积分。有关这些模型的更多信息，请访问[https://towardsdatascience.com/the-mathematics-of-machine-learning-894f046c568](https://towardsdatascience.com/the-mathematics-of-machine-learning-894f046c568)。
- en: The models that are available in the scikit-learn library fall into two categories,
    that is, supervised and unsupervised, both of which will be explained in depth
    later in this chapter. This form of category classification will help to determine
    which model to use for a particular dataset to get the most information out of
    it.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在scikit-learn库中可用的模型分为两类，即监督学习和无监督学习，本文稍后将对这两类进行深入解释。这种分类方式有助于确定在特定数据集上使用哪种模型，以获取最大的信息量。
- en: 'Besides its main use for predicting future behavior in supervised learning
    problems and clustering data in unsupervised learning problems, scikit-learn is
    also used for the following reasons:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在监督学习问题中用于预测未来行为以及在无监督学习问题中进行数据聚类，scikit-learn还用于以下几个方面：
- en: To carry out cross-validation and performance metrics analysis to understand
    the results that have been obtained from the model, and thereby improve its performance
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行交叉验证和性能指标分析，以了解从模型中获得的结果，并从而提升其性能。
- en: To obtain sample datasets to test algorithms on them
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取样本数据集以在其上测试算法
- en: To perform feature extraction to extract features from images or text data
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行特征提取，从图像或文本数据中提取特征
- en: Although scikit-learn is considered the preferred Python library for beginners
    in the world of ML, there are several large companies around the world that use
    it because it allows them to improve their products or services by applying the
    models to already existing developments. It also permits them to quickly implement
    tests on new ideas.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管scikit-learn被认为是机器学习领域初学者首选的Python库，但全球有许多大公司也在使用它，因为它能通过将模型应用于现有开发来改进产品或服务。同时，它也允许公司快速对新想法进行测试。
- en: 'Some of the leading companies that are using scikit-learn are as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一些主要使用scikit-learn的公司如下：
- en: 'Spotify: One of the most popular music streaming applications, Spotify makes
    use of scikit-learn mainly due to the wide variety of algorithms that the framework
    offers, as well as how easy it is to implement the new models into their current
    developments. Scikit-learn has been used as part of its music recommendation model.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spotify：作为最受欢迎的音乐流媒体应用之一，Spotify主要使用scikit-learn，原因是该框架提供了丰富的算法选择，同时也很容易将新模型集成到现有开发中。scikit-learn已被应用于其音乐推荐模型。
- en: 'Booking.com: From developing recommendation systems to preventing fraudulent
    activities, among many other solutions, this travel metasearch engine has been
    able to use scikit-learn to explore a large number of algorithms that allow the
    creation of state-of-the-art models.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Booking.com：从开发推荐系统到防止欺诈活动，及许多其他解决方案，这个旅行元搜索引擎能够利用scikit-learn探索大量算法，从而创建最先进的模型。
- en: 'Evernote: This note-taking and management app uses scikit-learn to tackle several
    of the steps required to train a classification model, from data exploration to
    model evaluation.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Evernote：这款笔记记录和管理应用程序使用 scikit-learn 来处理训练分类模型所需的多个步骤，从数据探索到模型评估。
- en: 'Change.org: Thanks to the framework''s ease of use and variety of algorithms,
    this non-profit organization has been able to create email marketing campaigns
    that reach millions of readers around the world.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Change.org：由于该框架易于使用且算法种类繁多，这家非营利组织能够创建电子邮件营销活动，触及全球数百万读者。
- en: Note
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: You can visit [http://scikit-learn.org/stable/testimonials/testimonials.html](http://scikit-learn.org/stable/testimonials/testimonials.html)
    to discover other companies that are using scikit-learn and see what they are
    using it for.
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以访问 [http://scikit-learn.org/stable/testimonials/testimonials.html](http://scikit-learn.org/stable/testimonials/testimonials.html)
    以了解其他使用 scikit-learn 的公司，并查看它们如何使用该库。
- en: In conclusion, scikit-learn is an open source Python library that uses an API
    to apply most ML tasks (both supervised and unsupervised) to data problems. Its
    main use is for modeling data so that predictions can be made about unseen observations;
    nevertheless, it should not be limited to that as the library also allows users
    to predict outcomes based on the model being trained, as well as to analyze the
    performance of the model, among other features.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，scikit-learn 是一个开源的 Python 库，它通过 API 将大多数机器学习任务（包括有监督和无监督）应用于数据问题。它的主要用途是对数据建模，从而可以对未见过的观察数据做出预测；然而，它的功能不限于此，因为该库还允许用户根据正在训练的模型预测结果，并分析模型的性能等。
- en: Advantages of Scikit-Learn
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Scikit-learn 的优势
- en: 'The following is a list of the main advantages of using scikit-learn for ML
    purposes:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用 scikit-learn 进行机器学习的主要优势：
- en: '**Ease of use**: Scikit-learn is characterized by a clean API, with a small
    learning curve in comparison to other libraries, such as TensorFlow or Keras.
    The API is popular for its uniformity and straightforward approach. Users of scikit-learn
    do not necessarily need to understand the math behind the models.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易用性**：与其他库（如 TensorFlow 或 Keras）相比，scikit-learn 以简洁的 API 和较小的学习曲线为特点。该 API
    以其统一性和直接性而受到欢迎。使用 scikit-learn 的用户不一定需要理解模型背后的数学原理。'
- en: '**Uniformity**: Its uniform API makes it very easy to switch from model to
    model as the basic syntax that''s required for one model is the same for others.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统一性**：它统一的 API 使得从一个模型切换到另一个模型非常容易，因为不同模型所需的基本语法是相同的。'
- en: '**Documentation/tutorials**: The library is completely backed up by documentation,
    which is effortlessly accessible and easy to understand. Additionally, it also
    offers step-by-step tutorials that cover all of the topics required to develop
    any ML project.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档/教程**：该库完全由文档支持，文档易于访问且易于理解。此外，它还提供了逐步教程，涵盖了开发任何机器学习项目所需的所有主题。'
- en: '**Reliability and collaborations**: As an open source library, scikit-learn
    benefits from the input of multiple collaborators who work each day to improve
    its performance. This participation from many experts from different contexts
    helps to develop not only a more complete library but also a more reliable one.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可靠性和协作**：作为一个开源库，scikit-learn 受益于多个合作者的贡献，他们每天都在为其性能改进而努力。来自不同背景的专家的参与，不仅帮助开发了一个更完整的库，也使得库更加可靠。'
- en: '**Coverage**: As you scan the list of components that the library has, you
    will discover that it covers most ML tasks, ranging from supervised models such
    as performing a regression task to unsupervised models such as the ones used to
    cluster data into subgroups. Moreover, due to its many collaborators, new models
    tend to be added in relatively short amounts of time.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**覆盖范围**：当你浏览该库所包含的组件时，你会发现它涵盖了大多数机器学习任务，从有监督的回归任务到无监督的聚类任务。更重要的是，由于拥有众多合作者，新模型通常会在相对较短的时间内加入。'
- en: Disadvantages of Scikit-Learn
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Scikit-learn 的缺点
- en: 'The following is a list of the main disadvantages of using scikit-learn for
    ML purposes:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用 scikit-learn 进行机器学习的主要缺点：
- en: '**Inflexibility**: Due to its ease of use, the library tends to be inflexible.
    This means that users do not have much liberty in parameter tuning or model architecture,
    such as with the Gradient Boost algorithm and neural networks. This becomes an
    issue as beginners move to more complex projects.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不灵活性**：由于易于使用，这个库往往缺乏灵活性。这意味着用户在参数调优或模型架构方面的自由度较低，例如在梯度提升算法和神经网络中。这对于初学者在处理更复杂项目时会成为一个问题。'
- en: '**Not good for deep learning**: The performance of the library falls short
    when tackling complex ML projects. This is especially true for deep learning,
    as scikit-learn does not support deep neural networks with the necessary architecture
    or power.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不适合深度学习**：当处理复杂的机器学习项目时，该库的表现不足。尤其是在深度学习方面，因为 scikit-learn 不支持具有必要架构或计算能力的深度神经网络。'
- en: Note
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Deep learning is a part of ML and is based on the concept of artificial neural
    networks. It uses a sequence of layers to extract valuable information (features)
    from the input data. In subsequent sections of this book, you will learn about
    neural networks, which is the starting point of being able to develop deep learning
    solutions.
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一部分，基于人工神经网络的概念。它通过一系列层次从输入数据中提取有价值的信息（特征）。在本书的后续章节中，您将学习到神经网络，这是能够开发深度学习解决方案的起点。
- en: In general terms, scikit-learn is an excellent beginner's library as it requires
    little effort to learn its use and has many complementary materials thought to
    facilitate its application. Due to the contributions of several collaborators,
    the library stays up to date and is applicable to most current data problems.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，scikit-learn 是一个优秀的入门级库，因为它学习使用起来几乎不需要任何努力，并且有许多辅助材料来帮助其应用。由于多位贡献者的努力，该库保持更新并适用于大多数当前的数据问题。
- en: On the other hand, it is a simple library that's not fit for more complex data
    problems such as deep learning. Likewise, it is not recommended for users who
    wish to take their abilities to a higher level by playing with the different parameters
    that are available in each model.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，它是一个简单的库，不适合处理更复杂的数据问题，例如深度学习。同样，它也不推荐给那些希望通过调整每个模型中可用的不同参数来提升能力的用户。
- en: Other Frameworks
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他框架
- en: 'Other popular ML frameworks are as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 其他流行的机器学习框架如下：
- en: 'TensorFlow: Google''s open source framework for ML, which to this day is still
    the most popular among data scientists. It is typically integrated with Python
    and is very good for developing deep learning solutions. Due to its popularity,
    the information that''s available on the internet about the framework makes it
    very easy to develop different solutions, not to mention that it is backed by
    Google.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow：谷歌的开源机器学习框架，至今仍是数据科学家中最受欢迎的框架。它通常与 Python 集成，并且非常适合开发深度学习解决方案。由于其广泛的流行性，网络上关于该框架的信息使得开发不同的解决方案变得非常容易，更不用说它有
    Google 的支持。
- en: 'PyTorch: This was primarily developed by Facebook''s AI Research lab as an
    open source deep learning framework. Although it is a fairly new framework (released
    in 2017), it has grown in popularity due to its ease of use and Pythonic nature.
    It allows easy code debugging thanks to the use of dynamic graph computations.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch：该框架由 Facebook 的 AI 研究实验室主要开发，是一个开源深度学习框架。尽管它是一个相对较新的框架（发布于2017年），但由于其易用性和
    Python 特性，它的流行度逐渐上升。得益于动态图计算，它使得代码调试变得非常简单。
- en: 'Keras: This is an open source deep learning framework that''s typically good
    for those who are just starting out. Due to its simplicity, it is less flexible
    but ideal for prototyping simple concepts. Similar to scikit-learn, it has its
    own easy-to-use API.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras：这是一个开源深度学习框架，通常适合刚入门的人。由于其简洁性，灵活性较差，但非常适合原型设计简单的概念。与 scikit-learn 类似，它也有自己易于使用的
    API。
- en: Data Representation
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据表示
- en: The main objective of ML is to build models by interpreting data. To do so,
    it is highly important to feed the data in a way that is readable by the computer.
    To feed data into a scikit-learn model, it must be represented as a table or matrix
    of the required dimensions, which we will discuss in the following section.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的主要目标是通过解释数据来构建模型。为了做到这一点，必须以计算机能够读取的方式输入数据。为了将数据输入到 scikit-learn 模型中，数据必须以表格或矩阵的形式表示，并且具有所需的维度，这将在接下来的章节中讨论。
- en: Tables of Data
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据表
- en: Most tables that are fed into ML problems are two-dimensional, meaning that
    they contain rows and columns. Conventionally, each row represents an observation
    (an instance), whereas each column represents a characteristic (feature) of each
    observation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 输入到机器学习问题中的大多数表格是二维的，这意味着它们包含行和列。通常，每一行代表一个观测值（一个实例），而每一列代表每个观测值的一个特征。
- en: 'The following table is a fragment of a sample dataset of scikit-learn. The
    purpose of the dataset is to differentiate from among three types of iris plants
    based on their characteristics. Hence, in the following table, each row embodies
    a plant and each column denotes the value of that feature for every plant:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格是一个scikit-learn示例数据集的片段。该数据集的目的是根据植物的特征区分三种不同类型的鸢尾花。因此，在下表中，每一行代表一棵植物，每一列表示该植物在每个特征上的值：
- en: '![Figure 1.2: A table showing the first 10 instances of the iris dataset'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.2：展示鸢尾花数据集前10个实例的表格'
- en: '](img/B15781_01_02.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_01_02.jpg)'
- en: 'Figure 1.2: A table showing the first 10 instances of the iris dataset'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2：展示鸢尾花数据集前10个实例的表格
- en: From the preceding explanation, by reviewing the first row of the preceding
    table, it is possible to determine that the observation corresponds to that of
    a plant with a sepal length of `5.1`, a sepal width of `3.5`, a petal length of
    `1.4`, and a petal width of `0.2`. The plant belongs to the `setosa` species.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的说明来看，通过查看前表的第一行，可以确定该观测值对应的是一棵花萼长度为`5.1`、花萼宽度为`3.5`、花瓣长度为`1.4`、花瓣宽度为`0.2`的植物。这棵植物属于`setosa`种类。
- en: Note
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When feeding images to a model, the tables become three-dimensional, where the
    rows and columns represent the dimensions of the image in pixels, while the depth
    represents its color scheme. If you are interested, feel free to find out more
    about *convolutional neural networks*.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当将图像输入到模型时，表格变为三维，其中行和列表示图像的像素维度，而深度则表示其颜色模式。如果你感兴趣，可以了解更多关于*卷积神经网络*的内容。
- en: Data in tables are also known as structured data. Unstructured data, on the
    other hand, refers to everything else that cannot be stored in a table-like database
    (that is, in rows and columns). This includes images, audio, videos, and text
    (such as emails or reviews). To be able to feed unstructured data into an ML algorithm,
    the first step should be to transform it into a format that the algorithm can
    understand (tables of data). For instance, images are converted into matrices
    of pixels, and text is encoded into numeric values.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 表格中的数据也称为结构化数据。另一方面，非结构化数据指的是无法存储在类似表格的数据库中的所有其他数据（即，不是以行和列的形式）。这包括图像、音频、视频和文本（如电子邮件或评论）。为了能够将非结构化数据输入到机器学习算法中，第一步应该是将其转化为算法可以理解的格式（即表格数据）。例如，图像被转换为像素矩阵，文本被编码为数值。
- en: Features and Target Matrices
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征和目标矩阵
- en: For many data problems, one of the features of your dataset will be used as
    a `setosa` species. Therefore, it is important to learn how to separate the target
    matrix from the features matrix.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多数据问题，数据集中的一个特征将作为`setosa`种类来使用。因此，学习如何将目标矩阵与特征矩阵分开非常重要。
- en: '`[n_i, n_f]`, where `n_i` denotes the number of instances (such as the universe
    of persons in the dataset) and `n_f` denotes the number of features (such as the
    demographics of each person). Generally, the features matrix is stored in a variable
    named `X`.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`[n_i, n_f]`，其中`n_i`表示实例的数量（例如数据集中的人群），`n_f`表示特征的数量（例如每个人的基本信息）。通常，特征矩阵存储在一个名为`X`的变量中。'
- en: Note
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Pandas is an open source library built for Python. It was created to tackle
    different tasks related to data manipulation and analysis. Likewise, NumPy an
    open source Python library and is used to manipulate large multi-dimensional arrays.
    It was also created with a large set of mathematical functions to operate over
    such arrays.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas是一个为Python构建的开源库。它的创建目的是解决与数据操作和分析相关的各种任务。同样，NumPy是一个开源的Python库，用于操作大型多维数组。它还为这些数组提供了大量的数学函数。
- en: '`n_i` (the number of instances). Nevertheless, there are some occasions where
    multiple targets are required, so the dimensions of the matrix become `[n_i, n_t]`,
    where `n_t` is the number of targets to consider.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_i`（实例的数量）。然而，在某些情况下，需要多个目标，因此矩阵的维度变为`[n_i, n_t]`，其中`n_t`是需要考虑的目标数量。'
- en: Similar to the features matrix, the target matrix is usually created as a NumPy
    array or a Pandas series. The values of the target array may be discrete or continuous.
    Generally, the target matrix is stored in a variable named `Y`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 与特征矩阵类似，目标矩阵通常创建为NumPy数组或Pandas系列。目标数组的值可以是离散的或连续的。通常，目标矩阵存储在名为`Y`的变量中。
- en: 'Exercise 1.01: Loading a Sample Dataset and Creating the Features and Target
    Matrices'
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习1.01：加载示例数据集并创建特征和目标矩阵
- en: Note
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: All of the exercises and activities in this book will be primarily developed
    in Jupyter Notebooks. It is recommended to keep a separate Notebook for different
    assignments, unless advised otherwise. Also, to load a sample dataset, the `seaborn`
    library will be used, as it displays the data as a table. Other ways to load data
    will be explained in later sections.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的所有练习和活动将主要在Jupyter Notebooks中进行。建议为不同的作业保持单独的Notebook，除非另有说明。另外，要加载一个示例数据集，将使用`seaborn`库，它会将数据以表格形式显示。其他加载数据的方法将在后续章节中讲解。
- en: 'In this exercise, we will be loading the `tips` dataset from the `seaborn`
    library and creating features and target matrices using it. Follow these steps
    to complete this exercise:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将从`seaborn`库加载`tips`数据集，并使用它创建特征和目标矩阵。按照以下步骤完成此练习：
- en: Note
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For the exercises and activities within this chapter, ensure that you have Python
    3.7, Seaborn 0.9, Jupyter 6.0, Matplotlib 3.1, NumPy 1.18, and Pandas 0.25 installed
    on your system.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的练习和活动要求系统中安装Python 3.7、Seaborn 0.9、Jupyter 6.0、Matplotlib 3.1、NumPy 1.18和Pandas
    0.25。
- en: 'Open a Jupyter Notebook to complete this exercise. In the Command Prompt or
    Terminal, navigate to the desired path and use the following command:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter Notebook来完成这个练习。在命令提示符或终端中，导航到所需路径并使用以下命令：
- en: '[PRE0]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Load the `tips` dataset using the `seaborn` library. To do so, you need to
    import the `seaborn` library and then use the `load_dataset()` function, as shown
    in the following code:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`seaborn`库加载`tips`数据集。为此，你需要导入`seaborn`库，然后使用`load_dataset()`函数，如下代码所示：
- en: '[PRE1]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As we can see from the preceding code, after importing the library, a nickname
    is given to facilitate its use with the script.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如我们从前面的代码中看到的，导入库后，会给它起一个别名，以方便在脚本中使用。
- en: The `load_dataset()` function loads datasets from an online repository. The
    data from the dataset is stored in a variable named `tips`.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`load_dataset()`函数从在线库加载数据集。数据集中的数据存储在名为`tips`的变量中。'
- en: 'Create a variable, `X`, to store the features. Use the `drop()` function to
    include all of the features but the target, which in this case is named `tip`.
    Then, print out the top 10 instances of the variable:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量`X`，用于存储特征。使用`drop()`函数包含除目标以外的所有特征，在本例中目标列为`tip`。然后，打印出该变量的前10个实例：
- en: '[PRE2]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The printed output should look as follows:'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果应该如下所示：
- en: '![Figure 1.3: A table showing the first 10 instances of the features matrix'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.3：显示特征矩阵前10个实例的表格'
- en: '](img/B15781_01_03.jpg)'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_01_03.jpg)'
- en: 'Figure 1.3: A table showing the first 10 instances of the features matrix'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.3：显示特征矩阵前10个实例的表格
- en: 'Print the shape of your new variable using the `X.shape` command:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`X.shape`命令打印出新变量的形状：
- en: '[PRE3]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output is as follows:'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下所示：
- en: '[PRE4]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The first value indicates the number of instances in the dataset (`244`), while
    the second value represents the number of features (`6`).
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一个值表示数据集中的实例数（`244`），第二个值表示特征数（`6`）。
- en: 'Create a variable, `Y`, that will store the target values. There is no need
    to use a function for this. Use indexing to grab only the desired column. Indexing
    allows you to access a section of a larger element. In this case, we want to grab
    the column named `tip`. Then, we need to print out the top 10 values of the variable:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量`Y`，用于存储目标值。无需使用函数来完成此操作。通过索引来提取所需的列。索引允许你访问更大元素的某一部分。在这个例子中，我们想要提取名为`tip`的列。然后，我们需要打印出该变量的前10个值：
- en: '[PRE5]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The printed output should look as follows:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果应该如下所示：
- en: '![Figure 1.4: A screenshot showing the first 10 instances of the target matrix'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.4：显示目标矩阵前10个实例的截图'
- en: '](img/B15781_01_04.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_01_04.jpg)'
- en: 'Figure 1.4: A screenshot showing the first 10 instances of the target matrix'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.4：显示目标矩阵前10个实例的截图
- en: 'Print the shape of your new variable using the `Y.shape` command:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Y.shape`命令打印出新变量的形状：
- en: '[PRE6]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is as follows:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下所示：
- en: '[PRE7]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The shape should be one-dimensional with a length equal to the number of instances
    (`244`).
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 形状应该是一维的，长度等于实例的数量（`244`）。
- en: Note
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Y5dgZH](https://packt.live/2Y5dgZH).
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 若要访问此特定部分的源代码，请参考[https://packt.live/2Y5dgZH](https://packt.live/2Y5dgZH)。
- en: You can also run this example online at [https://packt.live/3d0Hsco](https://packt.live/3d0Hsco).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例，网址是[https://packt.live/3d0Hsco](https://packt.live/3d0Hsco)。你必须执行整个
    Notebook 才能得到期望的结果。
- en: With that, you have successfully created the features and target matrices of
    a dataset.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 到此，你已经成功创建了数据集的特征矩阵和目标矩阵。
- en: Generally, the preferred way to represent data is by using two-dimensional tables,
    where the rows represent the number of observations, also known as instances,
    and the columns represent the characteristics of those instances, commonly known
    as features.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，表示数据的首选方式是使用二维表格，其中行代表观察的数量，也称为实例，列代表这些实例的特征，通常称为特征。
- en: For data problems that require target labels, the data table needs to be partitioned
    into a features matrix and a target matrix. The features matrix will contain the
    values of all features but the target, for each instance, making it a two-dimensional
    matrix. On the other hand, the target matrix will only contain the value of the
    target feature for all entries, making it a one-dimensional matrix.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要目标标签的数据问题，数据表需要分为特征矩阵和目标矩阵。特征矩阵将包含每个实例的所有特征值，但不包括目标值，因此它是一个二维矩阵。另一方面，目标矩阵将仅包含所有条目的目标特征值，因此它是一个一维矩阵。
- en: 'Activity 1.01: Selecting a Target Feature and Creating a Target Matrix'
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 1.01：选择目标特征并创建目标矩阵
- en: You want to analyze the Titanic dataset to see the survival rate of the passengers
    on different decks and see if you can prove a hypothesis stating that passengers
    on the lower decks were less likely to survive. In this activity, we will attempt
    to load a dataset and create the features and target matrices by choosing the
    appropriate target feature for the objective at hand.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你想分析泰坦尼克号数据集，查看不同甲板上乘客的生存率，并验证是否可以证明下层甲板的乘客更难幸存。此活动中，我们将尝试加载数据集并通过选择合适的目标特征来创建特征矩阵和目标矩阵，以实现我们的目标。
- en: Note
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To choose the target feature, remember that the target should be the outcome
    that we want to interpret the data for. For instance, if we want to know what
    features play a role in determining a plant's species, the species should be the
    target value.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 选择目标特征时，请记住目标应该是我们想要解释数据的结果。例如，如果我们想知道哪些特征在确定植物种类中起作用，那么物种应该是目标值。
- en: 'Follow these steps to complete this activity:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成此活动：
- en: 'Load the `titanic` dataset using the `seaborn` library. The first couple of
    rows should look like this:![Figure 1.5: A table showing the first 10 instances
    of the Titanic dataset'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`seaborn`库加载`titanic`数据集。前几行应该是这样的：![图 1.5：展示泰坦尼克号数据集前 10 个实例的表格
- en: '](img/B15781_01_05.jpg)'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_01_05.jpg)'
- en: 'Figure 1.5: A table showing the first 10 instances of the Titanic dataset'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.5：展示泰坦尼克号数据集前 10 个实例的表格
- en: Select your preferred target feature for the goal of this activity.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择你偏好的目标特征以完成本活动的目标。
- en: Create both the features matrix and the target matrix. Make sure that you store
    the data from the features matrix in a variable, `X`, and the data from the target
    matrix in another variable, `Y`.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建特征矩阵和目标矩阵。确保将特征矩阵的数据存储在变量`X`中，将目标矩阵的数据存储在另一个变量`Y`中。
- en: 'Print out the shape of each of the matrices, which should match the following
    values:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出每个矩阵的形状，应该与以下值匹配：
- en: '[PRE8]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 210.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第 210 页找到。
- en: Data Preprocessing
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: Data preprocessing is a very critical step for developing ML solutions as it
    helps make sure that the model is not trained on biased data. It has the capability
    to improve a model's performance, and it is often the reason why the same algorithm
    for the same data problem works better for a programmer that has done an outstanding
    job preprocessing the dataset.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理是开发机器学习解决方案中的关键步骤，因为它有助于确保模型不会在偏差数据上训练。它能够提高模型的性能，而且通常是同一算法在同一数据问题上能为进行良好数据预处理的程序员带来更好效果的原因。
- en: For the computer to be able to understand the data proficiently, it is necessary
    to not only feed the data in a standardized way but also make sure that the data
    does not contain outliers or noisy data, or even missing entries. This is important
    because failing to do so might result in the algorithm making assumptions that
    are not true to the data. This will cause the model to train at a slower pace
    and to be less accurate due to misleading interpretations of data.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让计算机能够有效理解数据，不仅需要以标准化的方式输入数据，还需要确保数据中不包含异常值或噪声数据，甚至没有缺失条目。这一点很重要，因为如果做不到这一点，算法可能会做出与数据不符的假设。这将导致模型训练速度变慢，并且由于对数据的误导性解释，准确性较低。
- en: Moreover, data preprocessing does not end there. Models do not work the same
    way, and each one makes different assumptions. This means that we need to preprocess
    the data in terms of the model that is going to be used. For example, some models
    accept only numerical data, whereas others work with nominal and numerical data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，数据预处理不仅仅止于此。模型的工作方式各不相同，每个模型有不同的假设。这意味着我们需要根据将要使用的模型来预处理数据。例如，有些模型仅接受数值型数据，而其他模型则可以处理名义数据和数值数据。
- en: To achieve better results during data preprocessing, a good practice is to transform
    (preprocess) the data in different ways and then test the different transformations
    in different models. That way, you will be able to select the right transformation
    for the right model. It is worth mentioning that data preprocessing is likely
    to help any data problem and any ML algorithm, considering that just by standardizing
    the dataset, a better training speed is achieved.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在数据预处理中获得更好的结果，一种良好的做法是以不同的方式转换（预处理）数据，然后在不同的模型中测试这些不同的转换。这样，你就能选择适合特定模型的正确转换方式。值得一提的是，数据预处理有可能帮助解决任何数据问题和任何机器学习算法，考虑到仅仅通过标准化数据集，就能提高训练速度。
- en: Messy Data
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 杂乱数据
- en: Data that is missing information or that contains outliers or noise is considered
    to be **messy data**. Failing to perform any preprocessing to transform the data
    can lead to poorly created models of the data, due to the introduction of bias
    and information loss. Some of the issues with data that should be avoided will
    be explained here.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 缺少信息或包含异常值或噪音的数据被视为**杂乱数据**。如果未进行任何预处理来转换数据，可能会导致数据模型构建不佳，因为引入了偏差和信息丢失。这里将解释一些应避免的数据问题。
- en: Missing Values
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缺失值
- en: 'Both the features and instances of a dataset can have missing values. Features
    where a few instances have values, as well as instances where there are no values
    for any feature, are considered **missing data**:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的特征和实例可能都有缺失值。对于某些特征，只有少数实例有值，而对于某些实例，所有特征的值都缺失，这些都被视为**缺失数据**：
- en: '![Figure 1.6: Example of missing values'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.6：缺失值示例'
- en: '](img/B15781_01_06.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_01_06.jpg)'
- en: 'Figure 1.6: Example of missing values'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6：缺失值示例
- en: The preceding image displays an instance (Instance 8) with no values for any
    of the features, which makes it useless, and a feature (Feature 8) with seven
    missing values out of the 10 instances, which means that the feature cannot be
    used to find patterns among the instances, considering that most of them don't
    have a value for the feature.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 上图展示了一个实例（实例 8），该实例在所有特征上都没有值，因此它没有任何用处；另外还有一个特征（特征 8），它在 10 个实例中有 7 个缺失值，这意味着该特征无法用于发现实例之间的模式，因为大多数实例没有该特征的值。
- en: Conventionally, a feature missing more than 5 to 10% of its values is considered
    to be missing data (also known as a feature with high absence rate), and so it
    needs to be dealt with. On the other hand, all instances that have missing values
    for all features should be eliminated as they do not provide any information to
    the model and, on the contrary, may end up introducing bias.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，缺失超过 5% 到 10% 的值的特征被认为是缺失数据（也称为高缺失率特征），因此需要处理。另一方面，所有特征的值都缺失的实例应被删除，因为它们没有为模型提供任何信息，反而可能引入偏差。
- en: 'When dealing with a feature with a high absence rate, it is recommended to
    either eliminate it or fill it with values. The most popular ways to replace the
    missing values are as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 处理具有高缺失率的特征时，建议要么删除该特征，要么用值填充它。替换缺失值的最常见方法如下：
- en: '**Mean imputation**: Replacing missing values with the mean or median of the
    features'' available values'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均值填充**：用特征的可用值的均值或中位数来替代缺失值'
- en: '**Regression imputation**: Replacing missing values with the predicted values
    that have been obtained from a regression function'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归插补**：用从回归函数中获得的预测值替代缺失值。'
- en: Note
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: A regression function refers to the statistical model that's used to estimate
    a relationship between a dependent variable and one or more independent variables.
    A regression function can be linear, logistic, polynomial, and so on.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 回归函数是指用于估计因变量与一个或多个自变量之间关系的统计模型。回归函数可以是线性、逻辑回归、 polynomial 等。
- en: While mean imputation is a simpler approach to implement, it may introduce bias
    as it evens out all the instances. On the other hand, even though the regression
    approach matches the data to its predicted value, it may end up overfitting the
    model (that is, creating models that learn the training data too well and are
    not fit to deal with new unseen data) as all the values that are introduced follow
    a function.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管均值插补是一种更简单的实现方法，但它可能会引入偏差，因为它会使所有实例趋于一致。另一方面，虽然回归方法将数据与其预测值匹配，但它可能会导致模型过拟合（即创建一个过于适应训练数据、无法处理新数据的模型），因为所有引入的值都遵循一个函数。
- en: Lastly, when the missing values are found in a text feature such as gender,
    the best course of action would be to either eliminate them or replace them with
    a class labeled as *uncategorized* or something similar. This is mainly because
    it is not possible to apply either mean or regression imputation to text.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当缺失值出现在如性别等文本特征中时，最好的做法是要么删除它们，要么用标记为 *未分类* 或类似的类别来替代它们。这主要是因为无法对文本应用均值插补或回归插补。
- en: Labeling missing values with a new category (*uncategorized*) is mostly done
    when eliminating them would remove an important part of the dataset, and hence
    would not be an appropriate course of action. In this case, even though the new
    label may have an effect on the model, depending on the rationale that's used
    to label the missing values, leaving them empty would be an even worse alternative
    as it would cause the model to make assumptions on its own.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 将缺失值标记为新类别（*未分类*）通常是在删除缺失值会去除数据集中重要部分时采取的做法，因此不适合删除它们。在这种情况下，尽管新标签可能会对模型产生影响，但根据标记缺失值时使用的理由，留空可能是一个更差的选择，因为它会导致模型自行做出假设。
- en: Note
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'To learn more about how to detect and handle missing values, visit the following
    page: [https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4](https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4).'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于如何检测和处理缺失值的信息，请访问以下页面：[https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4](https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4)。
- en: Outliers
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异常值
- en: '**Outliers** are values that are far from the mean. This means that if the
    values from a feature follow a Gaussian distribution, the outliers are located
    at the tails.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**异常值**是指远离均值的值。这意味着如果一个特征的值符合高斯分布，则异常值位于分布的尾部。'
- en: Note
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: A Gaussian distribution (also known as a normal distribution) has a bell-shaped
    curve, given that there is an equal number of values above and below the mean.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯分布（也称为正态分布）具有钟形曲线，因为该分布中大于和小于均值的数值数量相等。
- en: 'Outliers can be global or local. The former group represents those values that
    are far from the entire set of values for a feature. For example, when analyzing
    data from all members of a neighborhood, a global outlier would be a person who
    is 180 years old (as shown in the following diagram (`A`)). The latter, on the
    other hand, represents values that are far from a subgroup of values of that feature.
    For the same example that we saw previously, a local outlier would be a college
    student who is 70 years old (`B`), which would normally differ from other college
    students in that neighborhood:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值可以是全球性（global）或局部性（local）。前者代表那些与特征值集相距较远的值。例如，当分析某个邻里所有成员的数据时，一个全球异常值可能是一个
    180 岁的人（如下面的图示 (`A`) 所示）。而局部异常值则代表那些与某个特征的子集相距较远的值。以我们之前看到的例子为例，一个局部异常值可能是一个 70
    岁的大学生（`B`），这通常会与该邻里中的其他大学生不同：
- en: '![Figure 1.7: An image depicting global and local outliers in a dataset'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.7：展示数据集中全球性和局部异常值的图像'
- en: '](img/B15781_01_07.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_01_07.jpg)'
- en: 'Figure 1.7: An image depicting global and local outliers in a dataset'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7：展示数据集中全球性和局部异常值的图像
- en: Considering both examples that have been given, outliers do not evaluate whether
    the value is possible. While a person aged 180 years is not plausible, a 70-year-old
    college student might be a possibility, yet both are categorized as outliers as
    they can both affect the performance of the model.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到上述两个例子，异常值并不会评估值是否可能。虽然一个 180 岁的人不现实，但一个 70 岁的大学生是有可能的，然而这两者都被归类为异常值，因为它们都可能影响模型的表现。
- en: A straightforward approach to detect outliers consists of visualizing the data
    to determine whether it follows a Gaussian distribution, and if it does, classifying
    those values that fall between three to six standard deviations away from the
    mean as outliers. Nevertheless, there is not an exact rule to determine an outlier,
    and the decision to select the number of standard deviations is subjective and
    will vary from problem to problem.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 检测异常值的一个直接方法是通过可视化数据来判断它是否符合高斯分布，如果符合，则将落在距离均值三到六个标准差以外的值归类为异常值。然而，并没有一个确定的规则来判断一个异常值，选择标准差数量的决定是主观的，并且会根据不同问题有所变化。
- en: For example, if the dataset is reduced by 40% by setting three standard deviations
    as the parameter to rule out values, it would be appropriate to change the number
    of standard deviations to four.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果通过设置三个标准差为参数来排除值，数据集减少了40%，那么将标准差的数量调整为四个可能更为合适。
- en: On the other hand, when dealing with text features, detecting outliers becomes
    even trickier as there are no standard deviations to use. In this case, counting
    the occurrences of each class value would help to determine whether a certain
    class is indispensable or not. For instance, in clothing sizes, having a size
    XXS that represents less than 5% of the entire dataset might not be necessary.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在处理文本特征时，检测异常值变得更加棘手，因为没有标准差可以使用。在这种情况下，计算每个类别值的出现次数将有助于判断某个类别是否不可或缺。例如，在服装尺码中，如果
    XXS 尺码的比例小于整个数据集的 5%，可能就不需要它。
- en: 'Once the outliers have been detected, there are three common ways to handle
    them:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦异常值被检测出来，处理它们的三种常见方法如下：
- en: '**Delete the outlier**: For outliers that are true values, it is best to completely
    delete them to avoid skewing the analysis. This may also be a good idea for outliers
    that are mistakes, that is, if the number of outliers is too large to perform
    further analysis to assign a new value.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**删除异常值**：对于真实的异常值，最好将它们完全删除，以避免扭曲分析。对于那些错误的异常值，如果它们的数量太大，以至于无法进行进一步分析来赋予新值，删除它们也是一个好主意。'
- en: '**Define a top**: Defining a top may also be useful for true values. For instance,
    if you realize that all values above a certain threshold behave the same way,
    you can consider topping that value with a threshold.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定义一个上限**：为真实值定义一个上限也可能是有用的。例如，如果你意识到所有超过某个阈值的值都表现得相同，你可以考虑将该值设置为一个上限。'
- en: '**Assign a new value**: If the outlier is clearly a mistake, you can assign
    a new value using one of the techniques that we discussed for missing values (mean
    or regression imputation).'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**赋予一个新值**：如果异常值显然是错误的，你可以使用我们讨论过的处理缺失值的方法之一（均值或回归插补）为其赋予一个新值。'
- en: The decision to use each of the preceding approaches depends on the outlier
    type and number. Most of the time, if the number of outliers represents a small
    proportion of the total size of the dataset, there is no point in treating the
    outlier in any way other than deleting it.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述每种方法的决策取决于异常值的类型和数量。大多数时候，如果异常值的数量占数据集总量的比例较小，那么除了删除它们之外，别无他法。
- en: Note
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Noisy data corresponds to values that are not correct or possible. This includes
    numerical (outliers that are mistakes) and nominal values (for example, a person's
    gender misspelled as "fimale"). Like outliers, noisy data can be treated by deleting
    the values completely or by assigning them a new value.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声数据指的是那些不正确或不可能的值。这包括数值型（错误的异常值）和名义型值（例如，一个人的性别被拼写成 "fimale"）。像异常值一样，噪声数据可以通过完全删除这些值或赋予它们一个新值来处理。
- en: 'Exercise 1.02: Dealing with Messy Data'
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.02：处理杂乱数据
- en: 'In this exercise, we will be using the `tips` dataset from seaborn as an example
    to demonstrate how to deal with messy data. Follow these steps to complete this
    exercise:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用 seaborn 的 `tips` 数据集作为示例，演示如何处理杂乱的数据。按照以下步骤完成这个练习：
- en: Open a Jupyter Notebook to implement this exercise.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 Jupyter Notebook 来实现这个练习。
- en: 'Import all the required elements. Next, load the `tips` dataset and store it
    in a variable called `tips`. Use the following code:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必需的元素。接下来，加载 `tips` 数据集并将其存储在名为 `tips` 的变量中。使用以下代码：
- en: '[PRE9]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, create a variable called `size` to store the values of that feature from
    the dataset. As this dataset does not contain any missing data, we will convert
    the top 16 values of the `size` variable into missing values. Print out the top
    20 values of the `age` variable:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建一个名为 `size` 的变量来存储数据集中该特征的值。由于此数据集不包含任何缺失数据，我们将 `size` 变量的前 16 个值转换为缺失值。打印
    `age` 变量的前 20 个值：
- en: '[PRE10]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output will appear as follows:'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 1.8: A screenshot showing the first 20 instances of the age variable'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.8：展示了年龄变量前 20 个实例的截图'
- en: '](img/B15781_01_08.jpg)'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_01_08.jpg)'
- en: 'Figure 1.8: A screenshot showing the first 20 instances of the age variable'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.8：展示了年龄变量前 20 个实例的截图
- en: As you can see, the feature contains the `NaN` values that we introduced.
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，该特征包含我们引入的 `NaN` 值。
- en: 'Check the shape of the `size` variable:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `size` 变量的形状：
- en: '[PRE11]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE12]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, count the number of `NaN` values to determine how to handle them. Use
    the `isnull()` function to find the `NaN` values, and use the `sum()` function
    to sum them all:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，计算 `NaN` 值的数量以确定如何处理它们。使用 `isnull()` 函数找到 `NaN` 值，并使用 `sum()` 函数将它们全部加起来：
- en: '[PRE13]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is as follows:'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE14]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The participation of the `NaN` values in the total size of the variable is 6.55%,
    which can be calculated by dividing the number of missing values by the length
    of the feature (16/244). Although this is not high enough to consider removing
    the entire feature, there is a need to handle the missing values.
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`NaN` 值在变量总大小中的参与率为 6.55%，可以通过将缺失值数量除以特征长度（16/244）来计算。虽然这个比例不高到足以考虑移除整个特征，但确实需要处理缺失值。'
- en: 'Let''s choose the mean imputation methodology to replace the missing values.
    To do so, compute the mean of the available values, as follows:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们选择均值插补方法来替换缺失值。为此，计算可用值的均值，如下所示：
- en: '[PRE15]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The mean comes out as `3`.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 均值为 `3`。
- en: Note
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The mean value (`2.55`) was rounded to its nearest integer since the `size`
    feature is a measure of the number of persons attending a restaurant.
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于 `size` 特征是一个衡量参加餐厅的人数的指标，因此将均值值 `2.55` 四舍五入到最接近的整数。
- en: 'Replace all missing values with the mean. Use the `fillna()` function, which
    takes every missing value and replaces it with the value that is defined inside
    the parenthesis. To check that the values have been replaced, print the first
    10 values again:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用均值替换所有缺失值。使用 `fillna()` 函数，该函数接受每个缺失值并用括号内定义的值替换它。再次打印前 10 个值来检查是否已替换：
- en: '[PRE16]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: When `inplace` is set to `True`, the original DataFrame is modified. Failing
    to set the parameter to `True` will leave the original dataset unmodified. According
    to this, by setting `inplace` to `True`, it is possible to replace the `NaN` values
    for the mean.
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当 `inplace` 设置为 `True` 时，原始 DataFrame 将被修改。如果未将参数设置为 `True`，则将保留原始数据集的未修改状态。根据此设置
    `inplace` 为 `True`，可以替换 `NaN` 值为均值。
- en: 'The printed output is as follows:'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 打印输出如下所示：
- en: '![Figure 1.9: A screenshot depicting the first 20 instances of the age variable'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.9：展示了年龄变量前 20 个实例的截图'
- en: '](img/B15781_01_09.jpg)'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_01_09.jpg)'
- en: 'Figure 1.9: A screenshot depicting the first 20 instances of the age variable'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.9：展示了年龄变量前 20 个实例的截图
- en: As shown in the preceding screenshot, the value of the top instances has changed
    from `NaN` to `3`, which is the mean that was calculated previously.
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如前面的截图所示，顶部实例的值已从 `NaN` 更改为先前计算的均值 `3`。
- en: 'Use Matplotlib to graph a histogram of the `age` variable. Use Matplotlib''s
    `hist()` function, as per the following code:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Matplotlib 绘制 `age` 变量的直方图。使用 Matplotlib 的 `hist()` 函数，如下所示的代码：
- en: '[PRE17]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The histogram should look as follows. As we can see, its distribution is Gaussian-like:'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 直方图应如下所示。正如我们所见，其分布类似于高斯分布：
- en: '![Figure 1.10: A screenshot depicting the histogram of the size variable'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.10：展示了大小变量的直方图'
- en: '](img/B15781_01_10.jpg)'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_01_10.jpg)'
- en: 'Figure 1.10: A screenshot depicting the histogram of the size variable'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.10：展示了大小变量的直方图的截图
- en: Discover the outliers in the data. Let's use three standard deviations as the
    measure to calculate the minimum and maximum values.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发现数据中的异常值。让我们使用三个标准偏差作为度量标准来计算最小和最大值。
- en: 'As we discussed previously, the min value is determined by calculating the
    mean of all of the values and subtracting three standard deviations from it. Use
    the following code to set the min value and store it in a variable named `min_val`:'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如前所述，最小值是通过计算所有值的均值并从中减去三倍标准差来确定的。使用以下代码设置最小值，并将其存储在名为`min_val`的变量中：
- en: '[PRE18]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The min value is around `-0.1974`. According to the min value, there are no
    outliers at the left tail of the Gaussian distribution. This makes sense, given
    that the distribution is tilted slightly to the left.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最小值约为`-0.1974`。根据最小值，左尾的高斯分布没有异常值。这是有道理的，因为分布略微偏向左侧。
- en: 'Opposite to the min value, for the max value, the standard deviations are added
    to the mean to calculate the higher threshold. Calculate the max value, as shown
    in the following code, and store it in a variable named `max_val`:'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与最小值相反，对于最大值，标准差被加到均值上，以计算更高的阈值。计算最大值，如下所示的代码，并将其存储在名为`max_val`的变量中：
- en: '[PRE19]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The max value, which comes to around `5.3695`, determines that instances with
    a size above 5.36 represent outliers. As you can see in the preceding diagram,
    this also makes sense as those instances are far away from the bell of the Gaussian
    distribution.
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最大值约为`5.3695`，它确定了大小大于5.36的实例为异常值。正如你在前面的图中所看到的，这也很有意义，因为这些实例远离高斯分布的钟形曲线。
- en: Count the number of instances that are above the maximum value to decide how
    to handle them, as per the instructions given here.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 统计大于最大值的实例数量，以决定如何处理它们，按照这里给出的指示进行。
- en: 'Using indexing, obtain the values in `size` that are above the max threshold
    and store them in a variable called `outliers`. Then, count the outliers using
    `count()`:'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用索引获取`size`中高于最大阈值的值，并将其存储在名为`outliers`的变量中。然后，使用`count()`计算异常值的数量：
- en: '[PRE20]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The output shows that there are `4` outliers.
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示有`4`个异常值。
- en: 'Print out the outliers and check that the correct values were stored, as follows:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出异常值并检查是否正确存储了相应的值，如下所示：
- en: '[PRE21]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is as follows:'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 1.11: Printing the outliers'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.11：打印异常值'
- en: '](img/B15781_01_11.jpg)'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_01_11.jpg)'
- en: 'Figure 1.11: Printing the outliers'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.11：打印异常值
- en: As the number of outliers is small, and they correspond to true outliers, they
    can be deleted.
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于异常值的数量较少，并且它们确实是异常值，因此可以将其删除。
- en: Note
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: For this exercise, we will be deleting the instances from the `size` variable
    to understand the complete procedure of dealing with outliers. However, later,
    the deletion of outliers will be handled while considering all of the features
    so that we can delete the entire instance, not just the size values.
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于这个练习，我们将删除`size`变量中的实例，以了解处理异常值的完整过程。然而，稍后在考虑所有特征时，将处理异常值的删除，以便删除整个实例，而不仅仅是删除大小值。
- en: 'Redefine the values stored in `size` by using indexing to include only values
    below the max threshold. Then, print the shape of `size`:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用索引重新定义`size`中存储的值，只包含低于最大阈值的值。然后，打印`size`的形状：
- en: '[PRE22]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is as follows:'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE23]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As you can see, the shape of `size` (calculated in *Step 4*) has been reduced
    by four, which was the number of outliers.
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，`size`的形状（在*步骤4*中计算）已经减少了四个，这正是异常值的数量。
- en: Note
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/30Egk0o](https://packt.live/30Egk0o).
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/30Egk0o](https://packt.live/30Egk0o)。
- en: You can also run this example online at [https://packt.live/3d321ow](https://packt.live/3d321ow).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/3d321ow](https://packt.live/3d321ow)在线运行这个示例。你必须执行整个Notebook才能获得期望的结果。
- en: You have successfully cleaned a Pandas series. This process serves as a guide
    for cleaning a dataset later on.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功清理了一个Pandas系列。这一过程为稍后的数据集清理提供了指南。
- en: To summarize, we have discussed the importance of preprocessing data, as failing
    to do so may introduce bias in the model, which affects the training time of the
    model and its performance. Some of the main forms of messy data are missing values,
    outliers, and noise.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们讨论了数据预处理的重要性，因为如果没有预处理，可能会在模型中引入偏差，进而影响模型的训练时间和性能。数据杂乱的主要表现形式包括缺失值、异常值和噪声。
- en: 'Missing values, as their name suggests, are those values that are left empty
    or null. When dealing with many missing values, it is important to handle them
    by deleting them or by assigning new values. Two ways to assign new values were
    also discussed: mean imputation and regression imputation.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值，顾名思义，是指那些空缺或为null的值。在处理大量缺失值时，重要的是通过删除或分配新值来处理它们。两种分配新值的方法也已讨论过：均值插补和回归插补。
- en: Outliers are values that fall far from the mean of all the values of a feature.
    One way to detect outliers is by selecting all the values that fall outside the
    mean plus/minus three/six standard deviations. Outliers may be mistakes (values
    that are not possible) or true values, and they should be handled differently.
    While true outliers may be deleted or topped, mistakes should be replaced with
    other values when possible.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 离群值是指与某一特征所有值的均值相差很远的值。检测离群值的一种方法是选择所有超出均值加/减三倍/六倍标准差的值。离群值可能是错误值（不可能的值）或真实值，它们应当采取不同的处理方式。真实的离群值可能会被删除或修正，而错误值则应尽可能用其他值替换。
- en: Finally, noisy data corresponds to values that are, regardless of their proximity
    to the mean, mistakes or typos in the data. They can be of numeric, ordinal, or
    nominal types.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，噪声数据是指那些无论与均值的接近程度如何，都是数据中的错误或拼写错误的值。它们可以是数值型、序数型或名义型的。
- en: Note
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Please remember that numeric data is always represented by numbers that can
    be measured, nominal data refers to text data that does not follow a rank, and
    ordinal data refers to text data that follows a rank or order.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，数值数据总是由可以测量的数字表示，名义数据是指不遵循顺序的文本数据，而有序数据是指遵循某种顺序或等级的文本数据。
- en: Dealing with Categorical Features
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理类别特征
- en: '**Categorical features** are features that comprise discrete values typically
    belonging to a finite set of categories. Categorical data can be nominal or ordinal.
    Nominal refers to categories that do not follow a specific order, such as music
    genre or city names, whereas ordinal refers to categories with a sense of order,
    such as clothing sizes or level of education.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '**类别特征**是包含离散值的特征，这些值通常属于有限的类别集合。类别数据可以是名义的或有序的。名义数据指的是不遵循特定顺序的类别，例如音乐类型或城市名称，而有序数据指的是具有顺序感的类别，例如服装尺码或教育水平。'
- en: Feature Engineering
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程
- en: Even though improvements in many ML algorithms have enabled the algorithms to
    understand categorical data types such as text, the process of transforming them
    into numeric values facilitates the training process of the model, which results
    in faster running times and better performance. This is mainly due to the elimination
    of semantics available in each category, as well as the fact that the conversion
    into numeric values allows you to scale all of the features of the dataset equally,
    as will be explained in subsequent sections of this chapter.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多机器学习算法的改进使得算法能够理解类别数据类型（如文本），但将它们转换为数值值的过程有助于模型的训练，从而提高运行速度和性能。这主要是因为消除了每个类别中可用的语义信息，以及将数据转换为数值值后，可以平等地缩放数据集中的所有特征，正如本章后续部分所解释的那样。
- en: 'How does it work? Feature engineering generates a label encoding that assigns
    a numeric value to each category; this value will then replace the category in
    the dataset. For example, a variable called `genre` with the classes `pop`, `rock`,
    and `country` can be converted as follows:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 它是如何工作的？特征工程生成一个标签编码，将一个数字值分配给每个类别；然后该值将替换数据集中的类别。例如，一个名为`genre`的变量，具有`pop`、`rock`和`country`类别，可以按如下方式转换：
- en: '![Figure 1.12: An image illustrating how feature engineering works'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.12：一张展示特征工程如何工作的图片'
- en: '](img/B15781_01_12.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_01_12.jpg)'
- en: 'Figure 1.12: An image illustrating how feature engineering works'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.12：一张展示特征工程如何工作的图片
- en: 'Exercise 1.03: Applying Feature Engineering to Text Data'
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.03：将特征工程应用于文本数据
- en: In this exercise, we will be converting the text features of the `tips` dataset
    into numerical data.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将把`tips`数据集的文本特征转换为数值数据。
- en: Note
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Use the same Jupyter Notebook that you created for the previous exercise.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 使用你为之前的练习创建的相同Jupyter Notebook。
- en: 'Follow these steps to complete this exercise:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成本练习：
- en: 'Import scikit-learn''s `LabelEncoder()` class, as well as the `pandas` library,
    as follows:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入scikit-learn的`LabelEncoder()`类，以及`pandas`库，如下所示：
- en: '[PRE24]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Convert each of the text features into numeric values using the class that
    was imported previously (`LabelEncoder`):'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用之前导入的类（`LabelEncoder`）将每个文本特征转换为数值：
- en: '[PRE25]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As per the preceding code snippet, the first step is to instantiate the `LabelEncoder`
    class by typing in the first line of code. Second, for each of the categorical
    features, we use the built-in `fit_transform()` method from the class, which will
    assign a numeric value to each category and output the result.
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据前面的代码片段，第一步是通过键入第一行代码实例化`LabelEncoder`类。第二步，对于每个类别特征，我们使用该类的内置`fit_transform()`方法，该方法将为每个类别分配一个数值并输出结果。
- en: 'Print out the top values of the `tips` dataset:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出`tips`数据集的前几个值：
- en: '[PRE26]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output is as follows:'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 1.13: A screenshot depicting the first five instances of the tips
    dataset'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.13：显示tips数据集前五个实例的截图'
- en: '](img/B15781_01_13.jpg)'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_01_13.jpg)'
- en: 'Figure 1.13: A screenshot depicting the first five instances of the tips dataset'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.13：显示tips数据集前五个实例的截图
- en: As you can see, the text categories of the categorical features have been converted
    into numeric values.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，类别特征的文本类别已被转换为数值。
- en: Note
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/30GWJgb](https://packt.live/30GWJgb).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 若要访问此部分的源代码，请参见[https://packt.live/30GWJgb](https://packt.live/30GWJgb)。
- en: You can also run this example online at [https://packt.live/3e2oaVu](https://packt.live/3e2oaVu).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/3e2oaVu](https://packt.live/3e2oaVu)上在线运行此示例。你必须执行整个Notebook，才能得到所需的结果。
- en: You have successfully converted text data into numeric values.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地将文本数据转换为数值。
- en: While improvements in ML have made dealing with text features easier for some
    algorithms, it is best to convert them into numeric values. This is mainly important
    as it eliminates the complexity of dealing with semantics, not to mention that
    it gives us the flexibility to change from model to model, without any limitations.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管机器学习的进展使得一些算法处理文本特征变得更加容易，但最好将其转换为数值。这一点尤其重要，因为它消除了处理语义时的复杂性，更不用说它为我们提供了从一个模型切换到另一个模型的灵活性，且没有任何限制。
- en: Text data conversion is done via feature engineering, where every text category
    is assigned a numeric value that replaces it. Furthermore, even though this can
    be done manually, there are powerful built-in classes and methods that facilitate
    this process. One example of this is the use of scikit-learn's `LabelEncoder`
    class.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据的转换是通过特征工程完成的，其中每个文本类别都被分配了一个替代它的数值。此外，尽管可以手动完成此过程，但也有一些强大的内置类和方法可以简化这个过程。一个例子就是使用scikit-learn的`LabelEncoder`类。
- en: Rescaling Data
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据重缩放
- en: Rescaling data is important because even though the data may be fed to a model
    using different scales for each feature, the lack of homogeneity can cause the
    algorithm to lose its ability to discover patterns from the data due to the assumptions
    it has to make to understand it, thereby slowing down the training process and
    negatively affecting the model's performance.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 数据重缩放很重要，因为即使数据可以用不同的尺度传递给模型，每个特征的尺度不一致也可能导致算法失去从数据中发现模式的能力，因为它需要做出假设来理解数据，从而使得训练过程变慢并且对模型的性能产生负面影响。
- en: Data rescaling helps the model run faster, without any burden or responsibility
    to learn from the invariance present in the dataset. Moreover, a model trained
    over equally scaled data assigns the same weights (level of importance) to all
    parameters, which allows the algorithm to generalize to all features and not just
    to those with higher values, irrespective of their meaning.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 数据重缩放帮助模型更快地运行，且无需为学习数据集中的不变性承担任何负担或责任。此外，在均匀缩放数据上训练的模型会对所有参数分配相同的权重（重要性等级），这使得算法能够泛化到所有特征，而不仅仅是那些值较高的特征，无论它们的含义如何。
- en: An example of a dataset with different scales is one that contains different
    features, one measured in kilograms, another measuring temperature, and another
    counting the number of children. Even though the values of each attribute are
    true, the scale of each one of them highly differs from that of the other. For
    example, while the values in kilograms can go higher than 100, the children count
    will typically not go higher than 10.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 一个具有不同尺度的数据集示例是包含不同特征的集合，其中一个特征以千克为单位，另一个测量温度，另一个则统计孩子数量。尽管每个属性的数值都是正确的，但它们的尺度差异很大。例如，千克的数值可以超过
    100，而孩子的数量通常不会超过 10。
- en: Two of the most popular ways to rescale data are **data normalization** and
    **data standardization**. There is no rule on selecting the methodology to transform
    data to scale it, as all datasets behave differently. The best practice is to
    transform the data using two or three rescaling methodologies and test the algorithms
    in each one of them in order to choose the one that best fits the data based on
    its performance.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 两种最常用的重缩放数据方法是 **数据归一化** 和 **数据标准化**。没有固定的规则来选择数据转换的重缩放方法，因为所有数据集的表现不同。最佳实践是使用两种或三种重缩放方法转换数据，并在每种方法上测试算法，从而选择最适合数据的算法，依据其性能表现。
- en: Rescaling methodologies are to be used individually. When testing different
    rescaling methodologies, the transformation of data should be done independently.
    Each transformation can be tested over a model, and the best suited one should
    be chosen for further steps.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 重缩放方法应该单独使用。在测试不同的重缩放方法时，数据的转换应独立进行。每个转换可以在模型上进行测试，然后选择最适合的一个用于后续步骤。
- en: '**Normalization**: Data normalization in ML consists of rescaling the values
    of all features so that they lie in a range between 0 and 1 and have a maximum
    length of one. This serves the purpose of equating attributes of different scales.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '**归一化**：机器学习中的数据归一化是指将所有特征的值重缩放，使其落在 0 到 1 之间，并且最大长度为 1。这样做的目的是将不同尺度的属性统一化。'
- en: 'The following equation allows you to normalize the values of a feature:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 以下公式允许你对特征值进行归一化：
- en: '![Figure 1.14: The normalization equation'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.14：归一化公式'
- en: '](img/B15781_01_14.jpg)'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_01_14.jpg)'
- en: 'Figure 1.14: The normalization equation'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.14：归一化公式
- en: Here, *z*i corresponds to the *i*th normalized value and *x* represents all
    values.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*z*i 代表第 *i* 个归一化值，*x* 代表所有值。
- en: '**Standardization**: This is a rescaling technique that transforms the data
    into a Gaussian distribution with a mean equal to 0 and a standard deviation equal
    to 1\.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '**标准化**：这是一种重缩放技术，它将数据转换为均值为 0，标准差为 1 的高斯分布。'
- en: 'One simple way of standardizing a feature is shown in the following equation:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化特征的一种简单方法如下公式所示：
- en: '![Figure 1.15: The standardization equation'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.15：标准化公式'
- en: '](img/B15781_01_15.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_01_15.jpg)'
- en: 'Figure 1.15: The standardization equation'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.15：标准化公式
- en: Here, *z*i corresponds to the *i*th standardized value and *x* represents all
    values.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*z*i 代表第 *i* 个标准化值，*x* 代表所有值。
- en: 'Exercise 1.04: Normalizing and Standardizing Data'
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.04：数据归一化与标准化
- en: This exercise covers the normalization and standardization of data, using the
    `tips` dataset as an example.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习涉及数据的归一化和标准化，以 `tips` 数据集为例。
- en: Note
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Use the same Jupyter Notebook that you created for the previous exercise.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 使用你为前一个练习创建的相同 Jupyter Notebook。
- en: 'Follow these steps to complete this exercise:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成此练习：
- en: 'Using the `tips` variable, which contains the entire dataset, normalize the
    data using the normalization formula and store it in a new variable called `tips_normalized`.
    Print out the top 10 values:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用包含整个数据集的 `tips` 变量，采用归一化公式对数据进行归一化，并将结果存储在一个名为 `tips_normalized` 的新变量中。打印前
    10 个值：
- en: '[PRE27]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is as follows:'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 1.16: A screenshot displaying the first 10 instances of the tips_normalized
    variable'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.16：显示 `tips_normalized` 变量前 10 个实例的截图'
- en: '](img/B15781_01_16.jpg)'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_01_16.jpg)'
- en: 'Figure 1.16: A screenshot displaying the first 10 instances of the tips_normalized
    variable'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.16：显示 `tips_normalized` 变量前 10 个实例的截图
- en: As shown in the preceding screenshot, all of the values have been converted
    into their equivalents in a range between 0 and 1\. By performing normalization
    for all of the features, the model will be trained on features of the same scale.
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如前面的截图所示，所有的数值都已转换为介于 0 和 1 之间的等效值。通过对所有特征进行归一化，模型将在相同尺度的特征上进行训练。
- en: 'Again, using the `tips` variable, standardize the data using the formula for
    standardization and store it in a variable called `tips_standardized`. Print out
    the top 10 values:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次使用 `tips` 变量，使用标准化公式对数据进行标准化，并将其存储在名为 `tips_standardized` 的变量中。打印出前 10 个值：
- en: '[PRE28]'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output is as follows:'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 1.17: A screenshot displaying the first 10 instances of the tips_standardized
    variable'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.17：显示 `tips_standardized` 变量前 10 个实例的截图'
- en: '](img/B15781_01_17.jpg)'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_01_17.jpg)'
- en: 'Figure 1.17: A screenshot displaying the first 10 instances of the tips_standardized
    variable'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.17：显示 `tips_standardized` 变量前 10 个实例的截图
- en: Compared to normalization, in standardization, the values distribute normally
    around zero.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 与归一化相比，标准化中，数值会围绕零正态分布。
- en: Note
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/30FKsbD](https://packt.live/30FKsbD).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此部分的源代码，请参考 [https://packt.live/30FKsbD](https://packt.live/30FKsbD)。
- en: You can also run this example online at [https://packt.live/3e3cW2O](https://packt.live/3e3cW2O).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在网上运行这个示例，网址是 [https://packt.live/3e3cW2O](https://packt.live/3e3cW2O)。你必须执行整个
    Notebook 才能获得预期结果。
- en: You have successfully applied rescaling methods to your data.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 你已成功地将重缩放方法应用于数据。
- en: In conclusion, we have covered the final step in data preprocessing, which consists
    of rescaling data. This process was done in a dataset with features of different
    scales, with the objective of homogenizing the way data is represented to facilitate
    the comprehension of the data by the model.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们已经涵盖了数据预处理中的最后一步，即数据的重缩放。这个过程是在具有不同尺度特征的数据集上进行的，目的是统一数据的表示方式，以便模型能够更好地理解数据。
- en: Failing to rescale data will cause the model to train at a slower pace and may
    negatively affect the performance of the model.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不对数据进行重缩放，模型将以更慢的速度进行训练，并可能会负面影响模型的性能。
- en: 'Two methodologies for data rescaling were explained in this topic: normalization
    and standardization. On one hand, normalization transforms the data to a length
    of one (from 0 to 1). On the other hand, standardization converts the data into
    a Gaussian distribution with a mean of 0 and a standard deviation of 1.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 本主题中解释了两种数据重缩放方法：归一化和标准化。一方面，归一化将数据转换为一个长度为 1 的范围（从 0 到 1）。另一方面，标准化将数据转换为具有均值
    0 和标准差 1 的高斯分布。
- en: Given that there is no rule for selecting the appropriate rescaling methodology,
    the recommended course of action is to transform the data using two or three rescaling
    methodologies independently, and then train the model with each transformation
    to evaluate the methodology that behaves the best.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有选择适当重缩放方法的固定规则，推荐的做法是独立地使用两到三种重缩放方法对数据进行转换，然后用每种转换训练模型，评估哪种方法表现最佳。
- en: 'Activity 1.02: Pre-processing an Entire Dataset'
  id: totrans-340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 1.02：对整个数据集进行预处理
- en: 'You are continuing to work for the safety department at a cruise company. As
    you did great work selecting the ideal target feature to develop the study, the
    department has decided to commission you for preprocessing the dataset as well.
    For this purpose, you need to use all the techniques you learned about previously
    to preprocess the dataset and get it ready for model training. The following steps
    serve to guide you in that direction:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 你继续为一家邮轮公司的安全部门工作。由于你在选择理想的目标特征以开展研究方面表现出色，部门决定委托你负责数据集的预处理工作。为此，你需要使用之前学习的所有技术来预处理数据集，并将其准备好用于模型训练。以下步骤将指导你朝着这个方向前进：
- en: 'Import `seaborn` and the `LabelEncoder` class from scikit-learn. Next, load
    the Titanic dataset and create the features matrix, including the following features:
    `sex`, `age`, `fare`, `class`, `embark_town`, and `alone`.'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `seaborn` 和来自 scikit-learn 的 `LabelEncoder` 类。接下来，加载 Titanic 数据集，并创建包含以下特征的特征矩阵：`sex`、`age`、`fare`、`class`、`embark_town`
    和 `alone`。
- en: Note
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: For this activity, the features matrix has been created using only six features
    since some of the other features were redundant for this study. For example, there
    is no need to keep both `sex` and `gender`.
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于这个活动，特征矩阵仅使用了六个特征，因为其他一些特征对于本研究是冗余的。例如，不需要同时保留 `sex` 和 `gender`。
- en: Check for missing values and outliers in all the features of the features matrix
    (`X`). Choose a methodology to handle them.
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查特征矩阵（`X`）中所有特征的缺失值和异常值。选择一种方法来处理它们。
- en: Convert all text features into their numeric representations.
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有文本特征转换为它们的数值表示。
- en: Rescale your data, either by normalizing or standardizing it.
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对数据进行重新缩放，方法是通过归一化或标准化。
- en: Note
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 211.
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以在第211页找到。
- en: 'Expected Output: Results may vary, depending on the choices you make. However,
    you must be left with a dataset with no missing values, outliers, or text features,
    and with the data rescaled.'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出：结果可能会有所不同，取决于你的选择。然而，你必须确保最终得到一个没有缺失值、异常值或文本特征的数据集，并且数据已重新缩放。
- en: Scikit-Learn API
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scikit-Learn API
- en: The objective of the scikit-learn API is to provide an efficient and unified
    syntax to make ML accessible to non-ML experts, as well as to facilitate and popularize
    its use among several industries.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn API 的目标是提供高效且统一的语法，使机器学习变得更加易于非机器学习专家使用，同时促进和普及其在多个行业中的应用。
- en: How Does It Work?
  id: totrans-353
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: Although it has many collaborators, the scikit-learn API was built and has been
    updated by considering a set of principles that prevent framework code proliferation,
    where different code performs similar functionalities. On the contrary, it promotes
    simple conventions and consistency. Due to this, the scikit-learn API is consistent
    among all models, and once the main functionalities have been learned, it can
    be used widely.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有许多合作者，scikit-learn API 是在考虑一组原则的基础上构建并持续更新的，这些原则防止了框架代码的过度繁殖，即不同的代码执行相似的功能。相反，它提倡简单的约定和一致性。因此，scikit-learn
    API 在所有模型中保持一致，一旦掌握了主要功能，就可以广泛应用。
- en: 'The scikit-learn API is divided into three complementary interfaces that share
    a common syntax and logic: the estimator, the predictor, and the transformer.
    The estimator interface is used for creating models and fitting the data into
    them; the predictor, as its name suggests, is used to make predictions based on
    the models that were trained previously; and finally, the transformer is used
    for converting data.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn API 被分为三个互补的接口，它们共享相同的语法和逻辑：估算器、预测器和转换器。估算器接口用于创建模型并将数据拟合到模型中；预测器，顾名思义，用于基于已训练的模型进行预测；最后，转换器用于转换数据。
- en: Estimator
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 估算器
- en: This is considered to be the core of the entire API, as it is the interface
    in charge of fitting the models to the input data. It works by instantiating the
    model to be used and then applies a `fit()` method, which triggers the learning
    process so that it builds a model based on the data.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 这被认为是整个 API 的核心，因为它负责将模型拟合到输入数据中。它通过实例化要使用的模型，然后应用 `fit()` 方法来触发学习过程，从而根据数据构建模型。
- en: 'The `fit()` method receives the training data as arguments in two separate
    variables: the features matrix and the target matrix (conventionally called `X_train`
    and `Y_train`). For unsupervised models, this method only takes in the first argument
    (`X_train`).'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '`fit()` 方法接收两个单独的变量作为训练数据的参数：特征矩阵和目标矩阵（通常分别称为 `X_train` 和 `Y_train`）。对于无监督模型，该方法仅接收第一个参数（`X_train`）。'
- en: This method creates the model trained to the input data, which can later be
    used for predicting.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法创建经过训练的模型，用于后续的预测。
- en: Some models take other arguments besides the training data, which are also called
    **hyperparameters**. These hyperparameters are initially set to their default
    values but can be tuned to improve the performance of the model, which will be
    discussed in later sections.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 一些模型除了训练数据外，还需要其他参数，这些参数也被称为 **超参数**。这些超参数最初设置为默认值，但可以调整以提高模型的性能，具体内容将在后续章节中讨论。
- en: 'The following is an example of a model being trained:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个模型训练的示例：
- en: '[PRE29]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'First, it is required that you import the type of algorithm to be used from
    scikit-learn; for example, a Gaussian NaÏve Bayes algorithm (which will be further
    explored in *Chapter 4*, *Supervised Learning Algorithms: Predicting Annual Income*)
    for classification. It is always good practice to import only the algorithm to
    be used, and not the entire library, as this will ensure that your code runs faster.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，需要从 scikit-learn 导入要使用的算法类型；例如，用于分类的高斯朴素贝叶斯算法（将在*第4章*，*监督学习算法：预测年收入*中进一步探讨）。通常最好只导入需要使用的算法，而不是整个库，因为这样可以确保代码运行得更快。
- en: Note
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'To find the syntax for importing a different model, use the documentation of
    scikit-learn. Go to the following link, click the algorithm that you wish to implement,
    and you will find the instructions there: [http://scikit-learn.org/stable/user_guide.html](http://scikit-learn.org/stable/user_guide.html).'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 要查找导入不同模型的语法，请参阅 scikit-learn 的文档。访问以下链接，点击你想实现的算法，你将在那里找到相关说明：[http://scikit-learn.org/stable/user_guide.html](http://scikit-learn.org/stable/user_guide.html)。
- en: The second line of code oversees the instantiation of the model and stores it
    in a variable. Lastly, the model is fitted to the input data.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 第二行代码负责实例化模型并将其存储在一个变量中。最后，将模型拟合到输入数据上。
- en: 'In addition to this, the estimator also offers other complementary tasks, as
    follows:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，估算器还提供其他辅助任务，如下所示：
- en: Feature extraction, which involves transforming input data into numerical features
    that can be used for ML purposes.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征提取，涉及将输入数据转换为可用于机器学习目的的数值特征。
- en: Feature selection, which selects the features in your data that contribute to
    the prediction output of the model.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征选择，用于选择对模型预测结果有贡献的数据特征。
- en: Dimensionality reduction, which takes high-dimensional data and converts it
    into a lower dimension.
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降维技术，将高维数据转换为低维数据。
- en: Predictor
  id: totrans-371
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测器
- en: As explained previously, the predictor takes the model created by the estimator
    and uses it to perform predictions on unseen data. In general terms, for supervised
    models, it feeds the model a new set of data, usually called `X_test`, to get
    a corresponding target or label based on the parameters that were learned while
    training the model.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，预测器使用估算器创建的模型，并利用该模型对未见过的数据进行预测。一般而言，对于监督模型，它将新的数据集（通常称为 `X_test`）输入模型，以便根据训练模型时学到的参数得到相应的目标或标签。
- en: Moreover, some unsupervised models can also benefit from the predictor. While
    this method does not output a specific target value, it can be useful to assign
    a new instance to a cluster.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些无监督模型也可以从预测器中受益。虽然该方法不会输出特定的目标值，但它可以用于将一个新实例分配到一个聚类中。
- en: 'Following the preceding example, the implementation of the predictor can be
    seen as follows:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的示例，预测器的实现如下所示：
- en: '[PRE30]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We apply the `predict()` method to the previously trained model and input the
    new data as an argument to the method.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 `predict()` 方法应用于之前训练好的模型，并将新的数据作为参数输入该方法。
- en: In addition to predicting, the predictor can also implement methods that are
    in charge of quantifying the confidence of the prediction (that is, a numeric
    value representative of the level of performance of the model). These performance
    measures vary from model to model, but their main objective is to determine how
    far the prediction is from reality. This is done by taking an `X_test` with its
    corresponding `Y_test` and comparing it to the predictions made with the same
    `X_test`.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 除了预测外，预测器还可以实现一些方法，这些方法负责量化预测的置信度（即，代表模型性能水平的数值）。这些性能度量因模型而异，但其主要目的是确定预测与现实之间的差距。通过使用带有相应
    `Y_test` 的 `X_test` 数据，并将其与使用相同 `X_test` 进行的预测进行比较，来实现这一目标。
- en: Transformer
  id: totrans-378
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转换器
- en: As we saw previously, data is usually transformed before being fed to a model.
    Considering this, the API contains a `transform()` method that allows you to perform
    some preprocessing techniques.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，数据通常在输入模型之前进行转换。考虑到这一点，API 包含一个 `transform()` 方法，允许你执行一些预处理技术。
- en: It can be used both as a starting point to transform the input data of the model
    (`X_train`), as well as further along to modify data that will be fed to the model
    for predictions. This latter application is crucial to get accurate results as
    it ensures that the new data follows the same distribution as the data that was
    used to train the model.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以作为转换模型输入数据（`X_train`）的起点，也可以进一步用于修改将提供给模型进行预测的数据。后者的应用至关重要，因为它确保新数据遵循与训练模型时相同的分布，从而获得准确的结果。
- en: 'The following is an example of a transformer that normalizes the values of
    the training data:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个转换器的示例，用于对训练数据的值进行归一化处理：
- en: '[PRE31]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The `StandardScaler` class standardizes the data that it receives as arguments.
    As you can see, after importing and instantiating the transformer (that is, `StandardScaler`),
    it needs to be fit to the data to then effectively transform it:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '`StandardScaler` 类对其接收到的数据进行标准化。如您所见，在导入并实例化转换器（即 `StandardScaler`）后，需要对数据进行拟合，以便有效地进行转换：'
- en: '[PRE32]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The advantage of the transformer is that once it has been applied to the training
    dataset, it stores the values used for transforming the training data; this can
    be used to transform the test dataset to the same distribution, as seen in the
    preceding snippet.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 转换器的优点在于，一旦它被应用到训练数据集上，它会存储用于转换训练数据的值；这些值可以用于将测试数据集转换为相同的分布，正如前面的代码片段所示。
- en: In conclusion, we discussed one of the main benefits of using scikit-learn,
    which is its API. This API follows a consistent structure that makes it easy for
    non-experts to apply ML algorithms.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们讨论了使用 scikit-learn 的主要优势之一——其 API。这个 API 遵循一致的结构，使得非专家也能轻松应用机器学习算法。
- en: To model an algorithm on scikit-learn, the first step is to instantiate the
    model's class and fit it to the input data using an estimator, which is usually
    done by calling the `fit()` method of the class. Finally, once the model has been
    trained, it is possible to predict new values using the predictor by calling the
    `predict()` method of the class.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在 scikit-learn 上建模的第一步是实例化模型的类，并通过估算器将其拟合到输入数据，通常是通过调用类的 `fit()` 方法来完成的。最后，一旦模型训练完成，就可以通过调用类的
    `predict()` 方法，使用预测器来预测新值。
- en: Additionally, scikit-learn also has a transformer interface that allows you
    to transform data as needed. This is useful for performing preprocessing methods
    over the training data, which can then also be used to transform the testing data
    to follow the same distribution.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，scikit-learn 还提供了一个转换器接口，允许根据需要转换数据。这对于在训练数据上执行预处理方法非常有用，预处理后，测试数据也可以按相同的分布进行转换。
- en: Supervised and Unsupervised Learning
  id: totrans-389
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习与无监督学习
- en: 'ML is divided into two main categories: supervised and unsupervised learning.'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习分为两大类：监督学习和无监督学习。
- en: Supervised Learning
  id: totrans-391
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习
- en: 'Supervised learning consists of understanding the relationship between a given
    set of features and a target value, also known as a **label** or **class**. For
    instance, it can be used for modeling the relationship between a person''s demographic
    information and their ability to pay loans, as shown in the following table:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的核心是理解给定特征集与目标值之间的关系，这个目标值也称为**标签**或**类别**。例如，它可以用于建模一个人的人口统计信息与其偿还贷款能力之间的关系，如下表所示：
- en: '![Figure 1.18: The relationship between a person’s demographic information
    and the ability to pay loans'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.18：一个人的人口统计信息与偿还贷款能力之间的关系'
- en: '](img/B15781_01_18.jpg)'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_01_18.jpg)'
- en: 'Figure 1.18: The relationship between a person''s demographic information and
    the ability to pay loans'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.18：一个人的人口统计信息与偿还贷款能力之间的关系
- en: Models trained to foresee these relationships can then be applied to predict
    labels for new data. As we can see from the preceding example, a bank that builds
    such a model can then input data from loan applicants to determine if they are
    likely to pay back the loan.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 通过训练来预测这些关系的模型可以应用于预测新数据的标签。正如我们从前面的例子中看到的，建立了这样一个模型的银行可以将贷款申请者的数据输入到模型中，从而确定他们是否可能按时偿还贷款。
- en: These models can be further divided into classification and regression tasks,
    which are explained as follows.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型可以进一步分为分类任务和回归任务，具体解释如下。
- en: '**Classification tasks** are used to build models out of data with discrete
    categories as labels; for instance, a classification task can be used to predict
    whether a person will pay a loan. You can have more than two discrete categories,
    such as predicting the ranking of a horse in a race, but they must be a finite
    number.'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类任务**用于从具有离散类别标签的数据中构建模型；例如，分类任务可以用于预测一个人是否会偿还贷款。你可以有多个离散类别，比如预测赛马的排名，但这些类别必须是有限的。'
- en: 'Most classification tasks output the prediction as the probability of an instance
    to belong to each output label. The assigned label is the one with the highest
    probability, as can be seen in the following diagram:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数分类任务将预测输出为实例属于每个输出标签的概率。分配的标签是具有最高概率的标签，如下图所示：
- en: '![Figure 1.19: An illustration of a classification algorithm'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.19：分类算法的示意图'
- en: '](img/B15781_01_19.jpg)'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_01_19.jpg)'
- en: 'Figure 1.19: An illustration of a classification algorithm'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.19：分类算法的示意图
- en: 'Some of the most common classification algorithms are as follows:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 一些最常见的分类算法如下：
- en: '**Decision trees**: This algorithm follows a tree-like architecture that simulates
    the decision process following a series of decisions, considering one variable
    at a time.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策树**：该算法遵循树状架构，模拟通过一系列决策来做出决策的过程，每次考虑一个变量。'
- en: '**Naïve Bayes classifier**: This algorithm relies on a group of probabilistic
    equations based on Bayes'' theorem, which assumes independence among features.
    It has the ability to consider several attributes.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**朴素贝叶斯分类器**：该算法依赖于一组基于贝叶斯定理的概率方程，假设特征之间是独立的。它能够考虑多个属性。'
- en: '**Artificial neural networks** (**ANNs**): These replicate the structure and
    performance of a biological neural network to perform pattern recognition tasks.
    An ANN consists of interconnected neurons, laid out with a set architecture. They
    pass information to one another until a result is achieved.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工神经网络（ANN）**：这些模拟生物神经网络的结构和性能，以执行模式识别任务。人工神经网络由相互连接的神经元组成，按照一定的架构布局。它们相互传递信息，直到得到结果。'
- en: '**Regression tasks**, on the other hand, are used for data with continuous
    quantities as labels; for example, a regression task can be used for predicting
    house prices. This means that the value is represented by a quantity and not by
    a set of possible outputs. Output labels can be of integer or float types:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归任务**则用于具有连续数量标签的数据；例如，回归任务可以用于预测房价。这意味着输出值由一个数量表示，而不是一组可能的输出。输出标签可以是整数或浮动类型：'
- en: The most popular algorithm for regression tasks is **linear regression**. It
    consists of only one independent feature (x) whose relationship with its dependent
    feature (y) is linear. Due to its simplicity, it is often overlooked, even though
    it performs very well for simple data problems.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最常用的回归任务算法是**线性回归**。它仅包含一个独立特征（x），其与依赖特征（y）之间的关系是线性的。由于其简单性，通常被忽视，尽管它在处理简单数据问题时表现得非常好。
- en: Other, more complex, regression algorithms include **regression trees** and
    **support vector regression**, as well as **ANNs** once again.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他更复杂的回归算法包括**回归树**、**支持向量回归**，以及再次使用的**人工神经网络（ANN）**。
- en: Unsupervised Learning
  id: totrans-410
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习
- en: 'Unsupervised learning consists of fitting the model to the data without any
    relationship with an output label, also known as unlabeled data. This means that
    algorithms in this category try to understand the data and find patterns in it.
    For instance, unsupervised learning can be used to understand the profile of people
    belonging to a neighborhood, as shown in the following diagram:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习是指将模型拟合到数据中，而不与输出标签存在任何关系，这也被称为无标签数据。这意味着该类别的算法试图理解数据并发现其中的模式。例如，无监督学习可以用来了解属于某个社区的人的特征，如下图所示：
- en: '![Figure 1.20: An illustration of how unsupervised algorithms can be used to
    understand the profiles of people'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.20：无监督算法如何用于了解人群特征的示意图'
- en: '](img/B15781_01_20.jpg)'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_01_20.jpg)'
- en: 'Figure 1.20: An illustration of how unsupervised algorithms can be used to
    understand the profiles of people'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.20：无监督算法如何用于了解人群特征的示意图
- en: When applying a predictor to these algorithms, no target label is given as output.
    The prediction, which is only available for some models, consists of placing the
    new instance into one of the subgroups of data that have been created. Unsupervised
    learning is further divided into different tasks, but the most popular one is
    clustering, which will be discussed next.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用预测器到这些算法时，输出中没有给出目标标签。预测只对某些模型可用，它将新实例放入已创建的数据子组中。无监督学习进一步划分为不同的任务，但最受欢迎的任务是聚类，接下来将讨论这一点。
- en: '**Clustering tasks** involve creating groups of data (clusters) while complying
    with the condition that instances from one group differ visibly from the instances
    within the other groups. The output of any clustering algorithm is a label, which
    assigns the instance to the cluster of that label:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类任务**涉及创建数据组（簇），同时遵守这样一个条件：一个组中的实例与其他组中的实例在视觉上有明显区别。任何聚类算法的输出是一个标签，将实例分配到该标签的簇中：'
- en: '![Figure 1.21: A diagram representing clusters of multiple sizes'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.21：一个表示多种大小簇的图示'
- en: '](img/B15781_01_21.jpg)'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_01_21.jpg)'
- en: 'Figure 1.21: A diagram representing clusters of multiple sizes'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.21：一个表示多种大小簇的图示
- en: The preceding diagram shows a group of clusters, each of a different size, based
    on the number of instances that belong to each cluster. Considering this, even
    though clusters do not need to have the same number of instances, it is possible
    to set the minimum number of instances per cluster to avoid overfitting the data
    into tiny clusters of very specific data.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图示展示了一组簇，每个簇的大小不同，基于属于每个簇的实例数量。考虑到这一点，尽管簇不需要具有相同数量的实例，但可以设置每个簇的最小实例数量，以避免将数据过拟合到非常具体的小簇中。
- en: 'Some of the most popular clustering algorithms are as follows:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 一些最受欢迎的聚类算法如下：
- en: '**k-means**: This focuses on separating the instances into n clusters of equal
    variance by minimizing the sum of the squared distances between two points.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**k均值**：该算法通过最小化两个点之间的平方距离之和，将实例分成n个方差相等的簇。'
- en: '**Mean-shift clustering**: This creates clusters by using centroids. Each instance
    becomes a candidate for centroid to be the mean of the points in that cluster.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均值漂移聚类**：通过使用质心来创建簇。每个实例都成为质心的候选者，质心是该簇中所有点的均值。'
- en: '**Density-Based Spatial Clustering of Applications with Noise (DBSCAN)**: This
    determines clusters as areas with a high density of points, separated by areas
    with low density.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于密度的空间聚类（DBSCAN）**：它通过密度较高的点区域来确定簇，簇之间由密度较低的区域分隔。'
- en: Summary
  id: totrans-425
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: ML consists of constructing models that are able to convert data into knowledge
    that can be used to make decisions, some of which are based on complicated mathematical
    concepts to understand data. Scikit-learn is an open source Python library that
    is meant to facilitate the process of applying these models to data problems,
    without much complex math knowledge required.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）包括构建能够将数据转化为可以用来做决策的知识的模型，其中一些模型基于复杂的数学概念来理解数据。Scikit-learn是一个开源的Python库，旨在简化将这些模型应用于数据问题的过程，无需过多的复杂数学知识。
- en: This chapter explained the key steps of preprocessing your input data, from
    separating the features from the target, to dealing with messy data and rescaling
    the values of the data. All these steps should be performed before diving into
    training a model as they help to improve the training times, as well as the performance
    of the models.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 本章解释了预处理输入数据的关键步骤，从将特征与目标分开，到处理杂乱数据以及重新缩放数据值。在开始训练模型之前，应该执行所有这些步骤，因为它们有助于提高训练速度以及模型的表现。
- en: 'Next, the different components of the scikit-learn API were explained: the
    estimator, the predictor, and the transformer. Finally, this chapter covered the
    difference between supervised and unsupervised learning, and the most popular
    algorithms of each type of learning were introduced.'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，解释了scikit-learn API的不同组件：估计器、预测器和转换器。最后，本章讲解了监督学习和无监督学习之间的区别，并介绍了每种学习类型中最受欢迎的算法。
- en: With all of this in mind, in the next chapter, we will focus on detailing the
    process of implementing an unsupervised algorithm for a real-life dataset.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，在下一章中，我们将重点详细说明如何为实际数据集实现一个无监督算法。
