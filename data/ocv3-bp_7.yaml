- en: Chapter 6. Efficient Person Identification Using Biometric Properties
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 利用生物特征属性进行高效人员识别
- en: The rise of digital media is greater than ever. People are placing more and
    more of their personal information on digital carriers like laptops, smartphones,
    and tablets. However, many of these systems do not provide efficient identification
    and authentication systems to ensure that strangers cannot access your personal
    data. This is where biometrics-based identification systems come into play and
    try to make your data more secure and less vulnerable to malicious people.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数字媒体的兴起比以往任何时候都要大。人们将越来越多的个人信息放在笔记本电脑、智能手机和平板电脑等数字载体上。然而，许多这些系统并没有提供有效的身份识别和验证系统来确保陌生人无法访问你的个人数据。这就是基于生物特征的识别系统发挥作用并试图使你的数据更加安全、减少对恶意人员的脆弱性的地方。
- en: These identification systems can be used to lock down your computer, avoid people
    getting into a secure room, and so on, but, with technology improving each day,
    we are only one step away from further digitalizing our personal lives. How about
    using your facial expressions to unlock your door? How about opening your car
    with your fingerprint? The possibilities are endless.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这些识别系统可以用来锁定你的电脑，防止人们进入安全房间等，但随着技术的每日进步，我们离进一步数字化我们的个人生活只有一步之遥。用你的面部表情来解锁门怎么样？用你的指纹打开汽车怎么样？可能性是无限的。
- en: Many techniques and algorithms are already available in open source computer
    vision and machine learning packages like OpenCV to efficiently use these personal
    identification properties. Of course, this opens up the possibility for enthusiastic
    computer vision programmers to create many different applications based on these
    techniques.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 许多技术和算法已经在开源计算机视觉和机器学习包（如OpenCV）中可用，可以有效地使用这些个人识别属性。当然，这也为热衷于计算机视觉的程序员创造了基于这些技术的许多不同应用的可能性。
- en: In this chapter, we will focus on techniques that use individual biometrics
    in order to create personal authentication systems that outperform standard available
    login systems based on passwords. We will take a deeper look at iris and fingerprint
    recognition, face detection, and face recognition.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将关注使用个人生物特征的技术，以便创建超越基于密码的标准登录系统的个人身份验证系统。我们将更深入地探讨虹膜和指纹识别、人脸检测和人脸识别。
- en: We will first discuss the main principles behind each biometric technique, and
    then we'll show an implementation based on the OpenCV 3 library. For some of the
    biometrics, we will make use of the available open source frameworks out there.
    All datasets used to demonstrate the techniques are available for free online
    for research purposes. However, if you want to apply them to a commercial application,
    be sure to check their licenses!
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先讨论每种生物特征技术背后的主要原则，然后我们将基于OpenCV 3库展示一个实现示例。对于某些生物特征，我们将利用现有的开源框架。所有用于展示技术的数据集都免费在线提供，用于研究目的。然而，如果你想要将它们应用于商业应用，请务必检查它们的许可证！
- en: Finally, we will illustrate how you can combine several biometric classifications
    to increase the chance of successfully identifying a specific person based on
    the probability of the individual biometrics.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将说明如何结合几种生物特征分类来增加基于个人生物特征的特定人员成功识别的概率。
- en: At the end of this chapter, you will be able to create a fully functional identification
    system that will help you to avoid your personal details being stolen by any malicious
    party out there.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，你将能够创建一个完全功能化的识别系统，这将帮助你避免个人详细信息被任何恶意方窃取。
- en: Biometrics, a general approach
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生物特征，一种通用方法
- en: The general idea behind identifying a person using a biometric property is the
    same for all biometrics out there. There are several steps that we should follow
    in the correct order if we want to achieve decent results. Moreover, we will point
    out some major points inside these general steps that will help you improve your
    recognition rate with extreme measures.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用生物特征属性识别人员的通用思想对所有现有的生物特征都是相同的。如果我们想要获得良好的结果，我们应该遵循正确的顺序进行几个步骤。此外，我们还将指出这些一般步骤中的几个重要点，这将帮助你通过极端措施提高识别率。
- en: Step 1 – getting a good training dataset and applying application-specific normalization
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1步 – 获取良好的训练数据集并应用应用特定的归一化
- en: The key to most biometric identification systems is to collect a system training
    dataset that is representative of the problem for which you will actually use
    the system. Research has proven that there is something called **dataset bias**,
    which means that if you train a system on a training set with a specific setup,
    environmental factors, and recording devices, and then apply that system to a
    test set which has been taken from a completely different setup with different
    environmental factors (like lighting sources) and different recording devices,
    then this will produce a decrease in performance of up to 25%. This is a very
    large setback in performance, since you want to make sure that your identification
    system runs with top performance.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数生物特征识别系统的关键是收集一个代表你将实际使用该系统的问题的系统训练数据集。研究已经证明，存在一种称为**数据集偏差**的现象，这意味着如果你在一个具有特定设置、环境因素和记录设备的训练集上训练一个系统，然后将该系统应用于从完全不同的设置、不同的环境因素（如光源）和不同的记录设备中获取的测试集，那么这将会导致性能下降高达25%。这是一个很大的性能损失，因为你想要确保你的识别系统以最佳性能运行。
- en: 'Therefore, there are several things to consider when creating your training
    set for your identification system:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在创建你的识别系统的训练集时，有几个方面需要考虑：
- en: You should only collect training data with the **known setup** that will be
    used when applying the biometric recognition. This means that you need to decide
    on hardware before you start training models and classifiers.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该只收集在应用生物特征识别时将使用的**已知设置**的训练数据。这意味着在开始训练模型和分类器之前，你需要决定硬件。
- en: For biometric login systems, it is important to **constrain your data** as much
    as possible. If you can eliminate lighting changes, different background setups,
    movement, non-equal positioning, and so on, then you can drastically improve the
    performance of your application.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于生物特征登录系统，尽可能多地**约束你的数据**是很重要的。如果你可以消除光照变化、不同的背景设置、运动、非等距定位等问题，那么你可以极大地提高你应用程序的性能。
- en: Try to **normalize your data** orientation-wise. If you align all your training
    data to the same position, you avoid introducing undesired variance in a single
    person's description of the biometric. Research in this field has proven that
    this can increase recognition rates by more than 15%!
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽量**规范化你的数据方向**。如果你将所有训练数据对齐到相同的位置，你就可以避免在单个生物特征描述中引入不希望出现的方差。该领域的研究已经证明，这可以提高识别率超过15%！
- en: Use **multiple training instances** of a single biometric and use the average
    biometric description for authenticating a person. Single-shot training systems
    have the downside that slight differences between two biometric recordings have
    a large influence on the classification rate. Single-shot learning is still a
    very active research topic, and there is yet to be found a very stable solution
    to this problem.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用单个生物特征的**多个训练实例**，并使用平均生物特征描述来验证一个人的身份。单次训练系统的一个缺点是，两个生物特征记录之间的细微差异会对分类率产生很大的影响。单次学习仍然是一个非常活跃的研究课题，并且尚未找到一个非常稳定的解决方案来解决这个问题。
- en: How to apply this normalization for specific techniques will be discussed in
    the corresponding subtopics; for example, in the case of face recognition, since
    it can actually depend a lot on the techniques used. Once you get a good training
    set, with sufficient samples, you are ready to move to the second step.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如何将这种归一化应用于特定技术将在相应的子主题中进行讨论；例如，在人脸识别的情况下，它实际上可能很大程度上取决于所使用的技术。一旦你获得了一个好的训练集，包含足够的样本，你就可以准备进行第二步了。
- en: Note
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Keep in mind that there will be cases where applying constraints is not always
    a good way to go. Consider a laptop login system based on biometric features that
    only works with the lights on like face detection and recognition. That system
    would not work when somebody was working in a dark room. In that case, you would
    reconsider your application and ensure that there were enough biometric checks
    irrelevant to the changing light. You could even check the light intensity yourself
    through the webcam and disable the face check if you could predict that it would
    fail.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，在某些情况下，应用约束并不总是一个好的选择。考虑一个基于生物特征特征的笔记本电脑登录系统，该系统仅在灯光打开时（如人脸检测和识别）工作。当有人在黑暗的房间里工作时，该系统将无法工作。在这种情况下，你需要重新考虑你的应用程序，并确保有足够的与光照变化无关的生物特征检查。你甚至可以通过网络摄像头检查光强度，如果可以预测人脸检查会失败，则禁用人脸检查。
- en: The simplification of the application and circumstances involves simplifying
    the algorithm discussed in this chapter, leading to better performance in these
    constrained scenarios.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 应用和情境的简化涉及简化本章讨论的算法，从而在这些受限场景中提高性能。
- en: Step 2 – creating a descriptor of the recorded biometric
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步 – 创建记录的生物特征的描述符
- en: 'Once you get the required training data to build your biometric identification
    system, it is important to find a way to uniquely describe each biometric parameter
    for each individual. This description is called a "unique feature vector" and
    it has several benefits compared to the original recorded image:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你收集到构建你的生物识别系统的所需训练数据，找到一种独特描述每个个体的生物参数的方法就变得很重要。这种描述被称为“独特特征向量”，与原始记录图像相比，它具有几个优点：
- en: 'A full scale RGB image with high resolution (which is used a lot in biometrics
    recording) contains a lot of data. If we applied the classification to the complete
    image it would be:'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个全尺寸的高分辨率RGB图像（这在生物识别记录中用得很多）包含大量数据。如果我们对整个图像进行分类，它将是：
- en: Computationally very expensive.
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算成本非常高。
- en: Not as unique as desired, since regions over different persons can be identical
    or very similar.
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并非像期望的那样独特，因为不同人的区域可以是相同的或非常相似的。
- en: It reduces the important and unique information in an input image to a sparse
    representation based on keypoints which are unique features of each image.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将输入图像中的重要且独特的信息减少到基于关键点的稀疏表示，这些关键点是每个图像的独特特征。
- en: Again, how you construct the feature descriptor depends on which biometric you
    want to use to authenticate. Some approaches are based on Gabor filter banks,
    local binary pattern descriptions, and keypoint descriptors such as SIFT, SURF,
    and ORB. The possibilities are, again, endless. It all depends on getting the
    best description for your application. We will make suggestions for each biometric,
    but a more exhaustive search will need to be done to find the best solution for
    your application.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，你如何构建特征描述符取决于你想要用于验证的哪种生物识别。一些方法基于高博滤波器组、局部二值模式描述和SIFT、SURF、ORB等关键点描述符。可能性，再次，是无限的。这完全取决于为你的应用找到最好的描述。我们将为每种生物识别提供建议，但为了找到最适合你应用的解决方案，还需要进行更彻底的搜索。
- en: Step 3 – using machine learning to match the retrieved feature vector
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3步 – 使用机器学习匹配检索到的特征向量
- en: Each feature vector created from step 2 needs to be unique to ensure that a
    machine learning technique based on these feature vectors can differentiate between
    the biometrics of different test subjects. Therefore, it is important to have
    a descriptor with enough dimensions. Machine learning techniques are way better
    at separating data in high dimensional spaces than humans are, while they fail
    at separating data at low dimension feature spaces, for which a human brain outperforms
    the system.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从第2步创建的每个特征向量都需要是唯一的，以确保基于这些特征向量的机器学习技术能够区分不同测试对象的生物特征。因此，拥有足够维度的描述符非常重要。机器学习技术在分离高维空间中的数据方面比人类要好得多，而在低维特征空间中分离数据时，人类大脑的表现优于系统。
- en: Selecting the best machine learning approach is very cumbersome. In principle,
    different techniques offer similar results, but getting the best one is a game
    of trial and error. You can apply parameter optimization inside each machine learning
    approach to get even better results. This optimization would be too detailed for
    this chapter. People interested in this should take a deeper look at **hyper parameter
    optimization** techniques.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 选择最佳的机器学习方法是件非常繁琐的事情。原则上，不同的技术可以提供相似的结果，但找到最佳方案则是一场试错的游戏。你可以在每个机器学习方法内部应用参数优化以获得更好的结果。这种优化对于本章来说过于详细。对此感兴趣的人应该深入了解**超参数优化**技术。
- en: Note
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Some interesting publications about this hyper parameter optimization problem
    can be found below:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 下面可以找到一些关于这个超参数优化问题的有趣出版物：
- en: Bergstra J. S., Bardenet R., Bengio Y., and Kégl B. (2011), *Algorithms for
    hyper-parameter optimization*, in Advances in Neural Information Processing Systems
    (pp. 2546-2554).
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bergstra J. S., Bardenet R., Bengio Y. 和 Kégl B. (2011), *超参数优化的算法*, 在《神经信息处理系统进展》(第2546-2554页)。
- en: Bergstra J. and Bengio Y. (2012), *Random search for hyper-parameter optimization*,
    The Journal of Machine Learning Research, 13(1), 281-305.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bergstra J. 和 Bengio Y. (2012), *超参数优化的随机搜索*, 《机器学习研究杂志》, 13(1), 281-305。
- en: Snoek J., Larochelle H., and Adams R. P. (2012), *Practical Bayesian optimization
    of machine learning algorithms*, in Advances in Neural Information Processing
    Systems (pp. 2951-2959).
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Snoek J., Larochelle H., and Adams R. P. (2012), *《机器学习算法的实用贝叶斯优化》*，收录于《神经信息处理系统进展》（第2951-2959页）。
- en: 'There are many machine learning techniques in OpenCV 3\. Some of the most frequently
    used techniques can be found below in order of complexity:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 3中有很多机器学习技术。以下是一些最常用的技术，按复杂度排序：
- en: '**Similarity matching** using distance metrics.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相似度匹配**使用距离度量。'
- en: '**K-Nearest neighbors search**: A multi (K) class classification based on distance
    (Euclidean, Hamming, and so on) calculations between feature vectors in a high
    dimensional space.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**K-最近邻搜索**：基于高维空间中特征向量之间的距离（欧几里得、汉明等）计算的多（K）类分类。'
- en: '**Naïve Bayes classifier**: A binary classifier that uses Bayesian learning
    to differentiate between different classes.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**朴素贝叶斯分类器**：一种使用贝叶斯学习来区分不同类别的二元分类器。'
- en: '**Support vector machines**: Mostly used as a binary classifier learning approach,
    but can be adapted to a multi-class classifier system. This approach depends on
    the separation of data in high dimensional spaces by looking for optimal separation
    plains between training data clouds and separating margins.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持向量机**：主要用作二元分类学习方法，但可以适应多类分类系统。这种方法依赖于通过在高维空间中寻找训练数据云和分离边缘之间的最优分离平面来分离数据。'
- en: '**Boosting and random forests**: Techniques that combine several weak classifiers
    or learners into a complex model able to separate binary and multi-class problems.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提升和随机森林**：将多个弱分类器或学习器组合成一个复杂模型的技术，能够分离二元和多类问题。'
- en: '**Artificial neural networks**: A group of techniques that use the power of
    combining huge amounts of neurons (like the small cells in the brain) that learn
    connections and decisions based on examples. Due to their steeper learning curve
    and complex optimization steps, we will discard their use in this chapter.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工神经网络**：一组利用大量神经元（如大脑中的小细胞）的强大能力，通过示例学习连接和决策的技术。由于它们的学习曲线更陡峭，优化步骤复杂，因此在本章中我们将放弃使用它们。'
- en: Note
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you are interested in using neural networks for your classification problems,
    then take a look at this OpenCV documentation page:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对你的分类问题感兴趣，想使用神经网络，那么请查看这个OpenCV文档页面：
- en: '[http://docs.opencv.org/master/d0/dce/classcv_1_1ml_1_1ANN__MLP.html](http://docs.opencv.org/master/d0/dce/classcv_1_1ml_1_1ANN__MLP.html)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://docs.opencv.org/master/d0/dce/classcv_1_1ml_1_1ANN__MLP.html](http://docs.opencv.org/master/d0/dce/classcv_1_1ml_1_1ANN__MLP.html)'
- en: Step 4 – think about your authentication process
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4步 – 思考你的认证过程
- en: Once you have a machine learning technique that outputs a classification for
    your input feature vector, you need to retrieve a certainty. This certainty is
    needed to be sure how certain a classification result is. For example, if a certain
    output has a match for both entry 2 and entry 5 in a database, then you will need
    to use the certainty to be sure of which of the two matches you should continue
    with.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有一个对输入特征向量输出分类的机器学习技术，你需要检索一个确定性。这个确定性是确保分类结果确定性的必要条件。例如，如果某个输出在数据库中与条目2和条目5都有匹配，那么你需要使用确定性来确保你应该继续哪一个匹配。
- en: Here, it is also important to think about how your authentication system will
    operate. It can either be a one-versus-one approach, where you match each database
    entry with your test sample until you get a high enough matching score, or a one-versus-all
    approach, where you match the complete database, then look at the retrieved score
    for each match and take the best match possible.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，考虑你的认证系统如何运行也很重要。它可以是逐一匹配的方法，即匹配每个数据库条目与你的测试样本，直到获得足够高的匹配分数，或者是一对多方法，即匹配整个数据库，然后查看每个匹配的检索分数，并选择最佳匹配。
- en: One-versus-one can be seen as an iterative version of one-versus-all. They usually
    use the same logic; the difference is in the data structure used during the comparison.
    The one-versus-all approach requires a more complex way of storing and indexing
    the data, while one-versus-one uses a more brute-force approach.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一对一可以看作是一对多的一种迭代版本。它们通常使用相同的逻辑；区别在于比较过程中使用的数据结构。一对多方法需要更复杂的数据存储和索引方式，而一对一则使用更直接的暴力方法。
- en: Note
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Keep in mind that both techniques can yield different results due to the fact
    that a false positive match is always possible in machine learning.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，由于机器学习中总是可能发生假阳性匹配，这两种技术可能会产生不同的结果。
- en: Imagine an input test query for your system. Using one-versus-one matching,
    you would stop analyzing the database when you had a high enough match. However,
    if further down the road there was a match yielding an even higher score, then
    this one would be discarded. With the one-versus-all approach, this could be avoided,
    so in many cases it is better to apply this one-versus-all approach.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你系统的输入测试查询。使用一对一对匹配，当你达到足够高的匹配度时，你会停止分析数据库。然而，如果在更远的地方有一个产生更高分数的匹配，那么这个匹配将被丢弃。使用一对多方法，这可以避免，因此在许多情况下，应用一对多方法更好。
- en: To give an example of which approach to use in a given case, imagine a door
    to a secret lab. If you want to check if a person is allowed to enter the lab,
    then a one-versus-all approach is required to make sure that you match all database
    entries and that the highest matching score has a certainty above a certain threshold.
    However, if this final secret lab door is only used to select who is already allowed
    to enter the room, then a one-versus-one approach is sufficient.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了举例说明在特定情况下应使用哪种方法，想象一个通往秘密实验室的门。如果你想检查一个人是否有权进入实验室，那么需要一个一对多方法来确保匹配所有数据库条目，并且最高匹配分数的确定性高于某个阈值。然而，如果这个最后的秘密实验室门仅用于选择已经允许进入房间的人，那么一对一方法就足够了。
- en: In order to avoid problems with two individuals who have very similar descriptors
    for a single biometric, multiple biometrics are combined to reduce the occurrence
    of false positive detections. This will be discussed further at the end of this
    chapter, when we combine multiple biometrics in an effective authentication system.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免两个个体对单一生物特征有非常相似描述符的问题，通常会结合多个生物特征以减少假阳性检测的发生。这一点将在本章末尾进一步讨论，当我们在一个有效的身份验证系统中结合多个生物特征时。
- en: Face detection and recognition
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸检测和识别
- en: Most existing authentication systems start by detecting a face and trying to
    recognize it by matching it to a database of known people who use the system.
    This subsection will take a closer look at that. We will not dive into every single
    parameter of the software.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现有的身份验证系统都是从检测人脸并尝试将其与使用该系统的已知人员数据库匹配开始的。本小节将更详细地探讨这一点。我们不会深入研究软件的每一个参数。
- en: Note
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you want more information about complete face detection and the recognition
    pipeline for both people and cats, then take a look at one of the PacktPub books
    called *OpenCV for Secret Agents*. It looks at the complete process in more detail.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要关于完整的人脸检测以及人和猫的识别流程的更多信息，那么请查看PacktPub出版的一本名为*OpenCV for Secret Agents*的书。它更详细地探讨了整个过程。
- en: If you want a very detailed explanation of the parameters used for the face
    detection interface in OpenCV based on the cascade classification pipeline from
    Viola and Jones, then I suggest going to [Chapter 5](part0043_split_000.html#190862-940925703e144daa867f510896bffb69
    "Chapter 5. Generic Object Detection for Industrial Applications"), *Generic Object
    Detection for Industrial Applications*, which discusses the interface generalized
    for generic object detection.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要关于基于Viola和Jones级联分类管道的OpenCV人脸检测接口参数的非常详细的解释，那么我建议你去看[第5章](part0043_split_000.html#190862-940925703e144daa867f510896bffb69
    "第5章。工业应用中的通用目标检测")，*工业应用中的通用目标检测*，它讨论了用于通用目标检测的通用接口。
- en: Whenever you are focusing on an authentication system, you want to make sure
    that you are familiar with the different sub-tasks that need to be applied, as
    seen in the figure *An example of face detection software and the cut-out face
    region* in the section *Face detection using the Viola and Jones boosted cascade
    classifier algorithm*.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 无论何时你在关注一个身份验证系统，你都要确保你熟悉需要应用的不同子任务，正如在“使用Viola和Jones提升级联分类器算法进行人脸检测”一节中图*人脸检测软件及其裁剪的人脸区域*所示。
- en: You should start by using a **general face detector**. This is used to find
    faces in any given input; for example, from your webcam. We will use the Viola
    and Jones face detector inside OpenCV, trained with a cascade classifier based
    on AdaBoost.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你应该从使用一个**通用人脸检测器**开始。这是用来在任意输入中找到人脸的；例如，从你的网络摄像头中。我们将使用OpenCV中的Viola和Jones人脸检测器，它基于AdaBoost的级联分类器进行训练。
- en: Secondly, you should perform some normalization on the image. In our case, we
    will apply some grayscaling, histogram equalization, and some alignment based
    on eye and mouth detection.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其次，您应该在图像上执行一些归一化操作。在我们的案例中，我们将应用一些灰度化、直方图均衡化以及基于眼和嘴检测的对齐。
- en: Finally, the data needs to be passed to a face recognizer interface. We will
    discuss the different options briefly (LBPH, Eigenfaces, and Fisherfaces) and
    walk you through it. This will return the selected user from the database we use
    to match to.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，需要将数据传递到人脸识别接口。我们将简要讨论不同的选项（LBPH、Eigenfaces和Fisherfaces），并带您了解整个过程。这将返回数据库中用于匹配的选定用户。
- en: We will discuss the possible advantages, disadvantages, and risks of possible
    approaches at all stages. We will also suggest several open source packages that
    give you the chance to further optimize the approach if you want to.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在所有阶段讨论可能的方法的优势、劣势和风险。我们还将建议几个开源软件包，如果您想进一步优化方法，这将给您机会。
- en: Note
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Software for this subsection can be found at the following location:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 本小节的软件可以在以下位置找到：
- en: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/)'
- en: Face detection using the Viola and Jones boosted cascade classifier algorithm
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Viola和Jones增强级联分类器算法进行人脸检测
- en: Most webcam setups nowadays provide a high resolution RGB image as input. However,
    keep in mind that, for all OpenCV based operations, OpenCV formats the input as
    a BGR image. Therefore, we should apply some pre-processing steps to the output
    image before applying a face detector.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在大多数网络摄像头设置都提供高分辨率的RGB图像作为输入。然而，请注意，对于所有基于OpenCV的操作，OpenCV都将输入格式化为BGR图像。因此，在应用人脸检测器之前，我们应该对输出图像进行一些预处理步骤。
- en: Start by converting the image to a grayscale image. The Viola and Jones approach
    uses a HAAR wavelet or local binary pattern-based features, which are both independent
    of color. Both feature types look for regions of changing pixel intensities. Therefore,
    we can omit this extra color information and reduce the amount of data that needs
    to be processed.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先将图像转换为灰度图像。Viola和Jones方法使用HAAR小波或基于局部二值模式的特征，这两种特征都不依赖于颜色。这两种特征类型都寻找像素强度变化的区域。因此，我们可以省略额外的颜色信息，并减少需要处理的数据量。
- en: Reduce the resolution of the image. This depends on the webcam output format
    but, keeping in mind that processing time increases exponentially with increasing
    resolution, a ratio of 640x360 is more than enough for face detection.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降低图像的分辨率。这取决于网络摄像头的输出格式，但考虑到处理时间会随着分辨率的增加而指数级增加，640x360的比率对于人脸检测来说已经足够。
- en: Apply **histogram equalization** to the image to cover invariance under different
    illuminations. Basically, this operation tries to flatten the intensity histogram
    of the complete image. The same was done when training the detection models in
    OpenCV 3 and doing the same works here.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将**直方图均衡化**应用于图像以覆盖不同光照下的不变性。基本上，这个操作试图使整个图像的强度直方图平坦化。在OpenCV 3中训练检测模型时也进行了同样的操作。
- en: Note
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: It is always good to use different input and output containers for algorithms,
    since inline operations tend to do very nasty things to the output. Avoid problems
    by declaring an extra variable if you are not sure that inline replacement is
    supported.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于算法，始终使用不同的输入和输出容器是好的，因为内联操作往往会非常恶劣地处理输出。如果您不确定内联替换是否受支持，通过声明一个额外的变量来避免问题。
- en: 'The following code snippet illustrates this behavior:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段说明了这种行为：
- en: '[PRE0]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once you have done all the preprocessing, you can apply the following code
    to have an operational face detector on your input image:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成所有预处理后，您可以将以下代码应用于输入图像以获得一个可操作的人脸检测器：
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can now draw the retrieved rectangles on top of the image to visualize the
    detections.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以在图像上绘制检索到的矩形来可视化检测。
- en: Note
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you want to know more about used parameters or retrieved detections, have
    a look at [Chapter 5](part0043_split_000.html#190862-940925703e144daa867f510896bffb69
    "Chapter 5. Generic Object Detection for Industrial Applications"), *Generic Object
    Detection for Industrial Applications*, which discusses this interface in much
    more detail.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解更多关于使用参数或检索到的检测信息，请查看[第5章](part0043_split_000.html#190862-940925703e144daa867f510896bffb69
    "第5章。工业应用中的通用目标检测")，《工业应用中的通用目标检测》，其中更详细地讨论了此接口。
- en: 'The face detections will look like the figure below:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸检测将看起来像下面的图：
- en: '![Face detection using the Viola and Jones boosted cascade classifier algorithm](img/00097.jpeg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![使用Viola和Jones提升级联分类器算法进行人脸检测](img/00097.jpeg)'
- en: An example of face detection software and the cut-out face region
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸检测软件示例及其裁剪的人脸区域
- en: Finally, you should cut out the detected face regions so that they can be passed
    to the interfaces that will process the image. The best approach is to grab these
    face regions from the original resized image, as seen in the preceding figure,
    and not from the visualization matrix, to avoid the red border being cut out and
    polluting the face image.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您应该裁剪检测到的人脸区域，以便将它们传递给将处理图像的接口。最佳方法是从原始调整大小的图像中获取这些人脸区域，如图中所示，而不是从可视化矩阵中获取，以避免裁剪掉红色边框并污染人脸图像。
- en: '[PRE2]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The software for executing this face detection can be found at:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此人脸检测的软件可以在以下位置找到：
- en: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_detection/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_detection/).'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_detection/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_detection/).'
- en: Data normalization on the detected face regions
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在检测到的人脸区域上进行数据归一化
- en: If you are only interested in a basic test setup, then face normalization steps
    are not really necessary. They are mainly used for improving the quality of your
    face recognition software.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您只对基本的测试设置感兴趣，那么人脸归一化步骤实际上并不是必需的。它们主要用于提高您的人脸识别软件的质量。
- en: A good way to start is to reduce the amount of variation in the image. You can
    already apply conversion to grayscale and histogram equalization to remove information
    from the image, as described in the previous subtopic. This would be enough if
    you wanted a simple test setup, but it would require the person to keep their
    head positioned in the same way as the training data was grabbed for that person.
    If not, then the slight variation in the data due to a different head position
    would be enough to trigger a false positive match with another person in the database.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的开始方法是减少图像中的变化量。您已经可以应用转换为灰度图和直方图均衡化来从图像中移除信息，如前一个子主题中所述。如果您只想进行简单的测试设置，这将是足够的，但需要人员保持与为该人员抓取训练数据时相同的位置。如果不是这样，那么由于头部位置不同而产生的数据微小变化就足以触发与数据库中另一人的错误匹配。
- en: To avoid this, and to increase the quality of the following face recognition
    system, we propose applying face alignment. This can be done in several ways.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种情况，并提高以下人脸识别系统的质量，我们建议应用人脸对齐。这可以通过几种方式完成。
- en: As a basic approach, one could run an eye and mouth detector based on the existing
    OpenCV detectors, and use the centers of the detections as a way to align faces.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为一种基本方法，可以运行基于现有OpenCV检测器的眼和嘴检测器，并使用检测的中心作为对齐人脸的方式。
- en: Note
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For a very detailed explanation, refer to chapter 8 of *Mastering OpenCV* by
    Shervan Emami ([https://github.com/MasteringOpenCV/code/tree/master/Chapter8_FaceRecognition](https://github.com/MasteringOpenCV/code/tree/master/Chapter8_FaceRecognition)).
    He discusses several ways to align faces using eye detection.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于非常详细的解释，请参阅Shervan Emami所著的《精通OpenCV》第8章（[https://github.com/MasteringOpenCV/code/tree/master/Chapter8_FaceRecognition](https://github.com/MasteringOpenCV/code/tree/master/Chapter8_FaceRecognition)）。他讨论了使用眼检测对人脸进行对齐的几种方法。
- en: Also, have a look at the section *Finding the face region in the image* in [Chapter
    3](part0029_split_000.html#RL0A1-940925703e144daa867f510896bffb69 "Chapter 3. Recognizing
    Facial Expressions with Machine Learning"), *Recognizing Facial Expressions with
    Machine Learning*.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，请参阅[第3章](part0029_split_000.html#RL0A1-940925703e144daa867f510896bffb69 "第3章。使用机器学习识别面部表情")，《使用机器学习识别面部表情》中关于“在图像中找到人脸区域”的部分。
- en: A more advanced approach would be to apply a facial landmark detector and use
    all those points to normalize and align the faces.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高级的方法是应用面部特征点检测器，并使用所有这些点来归一化和对齐面部。
- en: Note
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you are interested in more advanced techniques, take a look at the flandmark
    library ([http://cmp.felk.cvut.cz/~uricamic/flandmark/](http://cmp.felk.cvut.cz/~uricamic/flandmark/)).
    More information about using the facial landmark techniques can be found in [Chapter
    3](part0029_split_000.html#RL0A1-940925703e144daa867f510896bffb69 "Chapter 3. Recognizing
    Facial Expressions with Machine Learning"), *Recognizing Facial Expressions with
    Machine Learning*, which discusses how to install this library, configure the
    software, and then run it on any given face image.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您对更高级的技术感兴趣，请查看flandmark库（[http://cmp.felk.cvut.cz/~uricamic/flandmark/](http://cmp.felk.cvut.cz/~uricamic/flandmark/)）。有关使用面部特征点技术的更多信息，请参阅[第3章](part0029_split_000.html#RL0A1-940925703e144daa867f510896bffb69
    "第3章。使用机器学习识别面部表情"), *使用机器学习识别面部表情*，该章节讨论了如何安装此库、配置软件，并在任何给定的面部图像上运行它。
- en: 'A good discussion about face alignment can be found at the following OpenCV
    Q&A forum: [http://answers.opencv.org/question/24670/how-can-i-align-face-images/](http://answers.opencv.org/question/24670/how-can-i-align-face-images/).
    Multiple active forum users have gathered their OpenCV knowledge to come up with
    a very promising alignment technique, based on basic facial landmark techniques.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 关于面部对齐的良好讨论可以在以下OpenCV Q&A论坛找到：[http://answers.opencv.org/question/24670/how-can-i-align-face-images/](http://answers.opencv.org/question/24670/how-can-i-align-face-images/)。多个活跃的论坛用户聚集了他们的OpenCV知识，提出了一种基于基本面部特征点技术的非常有前景的对齐技术。
- en: 'The most basic alignment can be carried out by using the following approach:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的对齐可以通过以下方法实现：
- en: Start by detecting the two eyes using the provided eye cascades.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先使用提供的眼脸级联检测两个眼睛。
- en: Find the center points of both eye detections.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到两个眼睛检测的中心点。
- en: Calculate the angle between both eyes.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算双眼之间的角度。
- en: Rotate the image around its own center.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 围绕图像自身的中心旋转图像。
- en: 'The following code does this:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码执行此操作：
- en: '[PRE3]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This will generate an Eigenface-based model ready for training, which will use
    all eigenvectors (which could be slow) and without a certainty threshold. To be
    able to use them, you need to use an overloaded interface of the face recognizer.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个基于特征向量的模型，准备进行训练，该模型将使用所有特征向量（可能较慢）且没有确定性阈值。为了能够使用它们，您需要使用面部识别器的重载接口。
- en: '`Ptr<` `BasicFaceRecognizer > face_model = createEigenFaceRecognizer(20);`'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Ptr<BasicFaceRecognizer> face_model = createEigenFaceRecognizer(20);`'
- en: '`Ptr<` `BasicFaceRecognizer > face_model = createEigenFaceRecognizer(20, 100.0);`'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Ptr<BasicFaceRecognizer> face_model = createEigenFaceRecognizer(20, 100.0);`'
- en: Here, you need to make a decision on what you actually want to achieve. The
    training will be fast with a low number of eigenvectors, but the accuracy will
    be lower. To increase the accuracy, increase the number of eigenvectors used.
    Getting the correct number of eigenvectors is quite cumbersome since it depends
    a lot on the training data used. As a heuristic, you could train a recognizer
    with a low number of eigenvectors, test the recognition rate on a test set, and
    then increase the number of eigenvectors as long as you do not reach the recognition
    rate goal.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您需要决定您实际上想要实现什么。使用少量特征向量进行训练将很快，但准确性会较低。为了提高准确性，增加使用的特征向量的数量。由于它很大程度上取决于训练数据，因此获取正确的特征向量数量相当繁琐。作为一个启发式方法，您可以使用少量特征向量训练一个识别器，在测试集上测试识别率，然后只要您没有达到识别率目标，就增加特征向量的数量。
- en: 'Then, the model can be learned with the following code:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以使用以下代码学习模型：
- en: '[PRE5]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If you want to have a bit more information on the prediction, like the prediction
    confidence, then you can replace the last line with:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想获得更多关于预测的信息，例如预测置信度，那么您可以替换最后一行：
- en: '[PRE6]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This is a basic setup. The things that you need to remember to improve the
    quality of your model are:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个基本设置。为了提高您模型的质量，您需要记住以下事项：
- en: Generally the more training faces of a person you have, the better a new sample
    of that person will be recognized. However, keep in mind that your training samples
    should contain as many different situations as possible, regarding lighting conditions,
    facial hair, attributes, and so on.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常，一个人拥有的训练人脸越多，对该人的新样本识别效果越好。然而，请注意，您的训练样本应包含尽可能多的不同情况，包括照明条件、面部毛发、属性等。
- en: Increasing the number of eigenvectors used for projecting increases accuracy,
    but it also makes the algorithm slower. Finding a good trade-off is very important
    for your application.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加用于投影的特征向量的数量可以提高准确性，但也会使算法变慢。为你的应用找到一个好的折衷方案非常重要。
- en: To avoid fraud getting in by the best match from the database principle, you
    can use the confidence scores to threshold out matches that are not secure enough
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了避免通过数据库中的最佳匹配原则引入欺诈，你可以使用置信度分数来阈值化掉不够安全的匹配项
- en: Note
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you want to do further research on the algorithm specifics, I suggest reading
    a paper that describes the technique in more detail:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想进一步研究算法的细节，我建议阅读一篇更详细描述该技术的论文：
- en: Turk, Matthew, and Alex P. Pentland. "Face recognition using eigenfaces" Computer
    Vision and Pattern Recognition, 1991\. Proceedings CVPR'91., IEEE Computer Society
    Conference on. IEEE, 1991.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Turk, Matthew, 和 Alex P. Pentland. "使用特征脸进行人脸识别" 计算机视觉与模式识别，1991年。CVPR'91会议论文集，IEEE计算机协会。1991年。
- en: 'If you want to play along with the internal data of the Eigenface-based model,
    you can retrieve interesting information using the following code:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要与基于Eigenface模型的内部数据进行交互，你可以使用以下代码检索有趣的信息：
- en: '[PRE7]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Some output results on the samples that we used for testing can be seen in the
    figure below. Remember that, if you want to show these images, you will need to
    transform them to the [0 255] range. The OpenCV 3 FaceRecognizer guide shows clearly
    how you should do this. The jet color space is often used to visualize Eigenfaces
    data.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 下面这张图中展示了我们在测试中使用的样本的一些输出结果。记住，如果你想展示这些图像，你需要将它们转换到[0 255]的范围内。OpenCV 3 FaceRecognizer指南清楚地说明了你应该如何进行这一操作。喷射色彩空间常用于可视化Eigenfaces数据。
- en: Note
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The complete and detailed OpenCV 3 FaceRecognizer interface guide can be found
    at the following web page, and discusses further use of these parameters in more
    depth than this chapter:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 完整且详细的OpenCV 3 FaceRecognizer接口指南可以在以下网页找到，并深入讨论了这些参数的进一步使用，比本章更详细。
- en: '[http://docs.opencv.org/master/da/d60/tutorial_face_main.html](http://docs.opencv.org/master/da/d60/tutorial_face_main.html)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://docs.opencv.org/master/da/d60/tutorial_face_main.html](http://docs.opencv.org/master/da/d60/tutorial_face_main.html)'
- en: '![Eigenface decomposition through PCA](img/00099.jpeg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![通过PCA进行Eigenface分解](img/00099.jpeg)'
- en: The first ten Eigenfaces visualized in their most common color spaces, grayscale
    and JET. Note the influence of the background.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在最常见的色彩空间中可视化前十个Eigenfaces，包括灰度和JET。注意背景的影响。
- en: Linear discriminant analysis using the Fisher criterion
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Fisher准则的线性判别分析
- en: The downside of using the Eigenface decomposition is that the transformation
    is optimal if you think about the pure reconstruction of the given data, however,
    the technique does not take into account class labels. This could lead to a case
    where the axes of maximal variance are actually created by external sources rather
    than the faces themselves. In order to cope with this problem, the technique of
    using LDA, or linear discriminant analysis, was introduced, based on the Fisher
    criterion. This minimizes variance within a single class, while maximizing variance
    between classes at the same time, which makes the technique more robust in the
    long run.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Eigenface分解的缺点是，如果你考虑的是给定数据的纯重建，那么这种变换是最佳的，然而，该技术并没有考虑到类别标签。这可能导致最大方差轴实际上是由外部来源而不是人脸本身创建的情况。为了应对这个问题，引入了基于Fisher准则的LDA（线性判别分析）技术。这最小化了单个类别的方差，同时最大化类别之间的方差，从而使技术在长期内更加稳健。
- en: 'The software for executing this face detection can be found at:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此人脸检测的软件可以在以下位置找到：
- en: Note
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_fisher/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_fisher/)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_fisher/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_fisher/)'
- en: 'To build a LDA face recognizer interface using the Fisher criteria, you should
    use the following code snippet in OpenCV 3:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Fisher准则构建LDA人脸识别器接口，你应该在OpenCV 3中使用以下代码片段：
- en: '[PRE8]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If you want to get more specific properties of the model, this can be achieved
    with property-specific functions, as depicted below. Remember that, if you want
    to show these images, you will need to transform them to the [0 255] range. The
    bone color space is often used to visualize Fisherfaces data.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要获取模型更具体的属性，可以通过属性特定的函数来实现，如下所示。记住，如果你想展示这些图像，你需要将它们转换到[0 255]的范围内。骨骼颜色空间常用于可视化Fisherfaces数据。
- en: '![Linear discriminant analysis using the Fisher criterion](img/00100.jpeg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![使用Fisher准则的线性判别分析](img/00100.jpeg)'
- en: The first 10 Fisherface dimensions, visualized in their most common color spaces,
    grayscale and BONE.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的颜色空间中可视化的前10个Fisherface维度，包括灰度和BONE。
- en: Note
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that the background influence is minimal for these Fisherfaces compared
    to the previous Eigenfaces technique. This is the main advantage of Fisherfaces
    over Eigenfaces.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，与之前的Eigenfaces技术相比，这些Fisherfaces的背景影响最小。这是Fisherfaces相对于Eigenfaces的主要优势。
- en: 'It is nice to know that both Eigenfaces and Fisherfaces support the reconstruction
    of any given input inside the Eigenspace or Fisherspace at a certain point in
    mapping onto the dimensions selected. This is done by applying the following code:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 很好知道，Eigenfaces 和 Fisherfaces 都支持在映射到选定的维度时，在某个点上重建任何给定输入到特征空间或Fisher空间内。这是通过以下代码实现的：
- en: '[PRE9]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The software for executing this face detection can be found at:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此人脸检测的软件可以在以下位置找到：
- en: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_projection/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_projection/)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_projection/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_projection/)'
- en: This will result in the output shown in the figure below. We re-project one
    of the test subjects at different stages in the Eigenspace, subsequently adding
    25 eigenvectors to the representation. Here, you can clearly see that we have
    succeeded in reconstructing the individual in 12 steps. We can apply a similar
    procedure to the Fisherfaces. However, due to the fact that Fisherfaces have lower
    dimensionality, and the fact that we only look for features to distinguish between
    labels, we cannot expect a reconstruction that is as pure as it is with Eigenfaces.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下图所示的输出。我们在特征空间的不同阶段重新投影一个测试对象，随后向表示中添加25个特征向量。在这里，你可以清楚地看到我们成功地在12步中重建了个体。我们可以对Fisherfaces应用类似的程序。然而，由于Fisherfaces的维度较低，并且我们只寻找用于区分标签的特征，我们无法期望重建的效果像Eigenfaces那样纯净。
- en: '![Linear discriminant analysis using the Fisher criterion](img/00101.jpeg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![使用Fisher准则的线性判别分析](img/00101.jpeg)'
- en: Reprojection result for both Eigenfaces and Fisherfaces
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Eigenfaces和Fisherfaces的重投影结果
- en: Note
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you want to do further research on the algorithm specifics, I suggest reading
    a paper that describes the technique in more detail:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想进一步研究算法的细节，我建议阅读一篇更详细描述该技术的论文：
- en: 'Belhumeur Peter N., João P. Hespanha, and David J. Kriegman, *Eigenfaces vs.
    fisherfaces: Recognition using class specific linear projection*, Pattern Analysis
    and Machine Intelligence, IEEE Transactions on 19.7 (1997): 711-720.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 'Belhumeur Peter N.，João P. Hespanha，David J. Kriegman，*Eigenfaces vs. Fisherfaces:
    Recognition using class specific linear projection*，Pattern Analysis and Machine
    Intelligence，IEEE Transactions on 19.7 (1997): 711-720。'
- en: Local binary pattern histograms
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 局部二值模式直方图
- en: Instead of simply reducing the dimensionality to universal axes, another approach
    is the use of local feature extraction. By looking at local features rather than
    a complete global description of the feature, researchers have tried to cope with
    problems like partial occlusion, illumination, and small sample size. The use
    of local binary pattern intensity histograms is a technique that looks at local
    face information rather than looking at global face information for a single individual.
    Local binary patterns have their origin in texture analysis and have proven to
    be efficient at face recognition by focusing on very specific local textured areas.
    This measure is more prone to changing lighting conditions than the previous techniques.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 除了简单地降低到通用轴的维度之外，另一种方法是使用局部特征提取。通过观察局部特征而不是特征的完整全局描述，研究人员试图应对部分遮挡、光照和样本量小等问题。使用局部二值模式强度直方图是一种观察局部面部信息而不是观察单个个体的全局面部信息的技术。这种度量比之前的技术更容易受到光照条件变化的影响。
- en: Note
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The software for executing this face detection can be found at:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此面部检测的软件可以在以下位置找到：
- en: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_LBPH/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_LBPH/)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_LBPH/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_recognition_LBPH/)'
- en: The LBPH features are illustrated below. They clearly show a more local feature
    description than Eigenfaces or Fisherfaces.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了LBPH特征。它们清楚地表明，与Eigenfaces或Fisherfaces相比，它们提供了更局部化的特征描述。
- en: '![Local binary pattern histograms](img/00102.jpeg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![局部二值模式直方图](img/00102.jpeg)'
- en: Example face image and its ELBP projection
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 示例面部图像及其ELBP投影
- en: Note
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The software for executing this LBPH face projection can be found at:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此LBPH面部投影的软件可以在以下位置找到：
- en: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_to_ELBP/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_to_ELBP/)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_to_ELBP/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/face/face_to_ELBP/)'
- en: 'To build a LBP face recognizer interface using histograms of local binary patterns,
    you should use the following code snippet in OpenCV 3:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用局部二值模式直方图构建LBP面部识别接口，你应该在OpenCV 3中使用以下代码片段：
- en: '[PRE10]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The LBPH interface also has an overload function, but this time related to
    the structure of the LBPH pattern and not the projection axes. This can be seen
    below:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: LBPH接口还有一个重载函数，但这次与LBPH模式的结构有关，而不是投影轴。这可以从下面看到：
- en: '[PRE11]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Again, the function can operate with or without a threshold being set in advance.
    Getting or setting the parameters of the model can also be done using the specific
    getter and setter functions.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，该函数可以在预先设置阈值的情况下或不设置阈值的情况下运行。获取或设置模型参数也可以通过特定的获取器和设置器函数来完成。
- en: Note
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you want to do further research on the algorithm specifics, I suggest reading
    a paper that describes the technique in more detail:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想进一步研究算法的细节，我建议阅读一篇更详细描述该技术的论文：
- en: Ahonen Timo, Abdenour Hadid, and Matti Pietikäinen, *Face recognition with local
    binary patterns*, Computer vision-eccv 2004, Springer Berlin Heidelberg, 2004\.
    469-481.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Ahonen Timo, Abdenour Hadid, 和 Matti Pietikäinen, 《基于局部二值模式的面部识别》, 计算机视觉-eccv
    2004, Springer Berlin Heidelberg, 2004. 469-481.
- en: We provided functionality for each of the above three interfaces, also calculating
    the number of test samples classified correctly and the ones classified incorrectly,
    as shown below. In the case of LBPH, this means that we have a correct classification
    rate on the test samples of 96.25%, which is quite amazing with the very limited
    training data of only eight samples per person.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为上述三个接口都提供了功能，也计算了正确分类和错误分类的测试样本数量，如下所示。在LBPH的情况下，这意味着我们在测试样本上有96.25%的正确分类率，这对于只有每人八个样本的非常有限的训练数据来说是非常惊人的。
- en: '![Local binary pattern histograms](img/00103.jpeg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![局部二值模式直方图](img/00103.jpeg)'
- en: The number of correctly classified samples is outputted after each run.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 每次运行后都会输出正确分类样本的数量。
- en: The problems with facial recognition in its current OpenCV 3 based implementation
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当前基于OpenCV 3的实现中面部识别的问题
- en: 'The techniques discussed enable us to recognize a face and link it to a person
    in the dataset. However, there are still some problems with this system that should
    be addressed:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论的技术使我们能够识别一个面部并将其与数据集中的某个人联系起来。然而，这个系统仍然存在一些需要解决的问题：
- en: When using the Eigenfaces system, it is a general rule that the more Eigenvectors
    you use, the better the system will become, and the higher the accuracy will be.
    Defining how many dimensions you need to get a decent recognition result is frustrating,
    since it depends on how the data is presented to the system. The more variation
    there is in the original data, the more challenging the task will be, and thus
    the more dimensions you will need. The experiments of Philipp Wagner have shown
    that, in the AT&T database, about 300 Eigenvectors should be enough.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当使用特征脸系统时，一个普遍的规则是，你使用的特征向量越多，系统就会变得越好，准确性也会更高。定义你需要多少维度才能得到一个不错的识别结果是令人沮丧的，因为这取决于数据是如何呈现给系统的。原始数据中的变化越多，任务就越具挑战性，因此你需要更多的维度。Philipp
    Wagner的实验表明，在AT&T数据库中，大约300个特征向量应该足够了。
- en: You can apply thresholding to both Eigenfaces and Fisherfaces. This is a must
    if you want to be certain of classification accuracy. If you do not apply this,
    then the system will basically return the best match. If a given person is not
    part of the dataset, then you want to avoid this, and that can be done by calling
    the interface with a threshold value!
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以将阈值法应用于特征脸和Fisher脸。如果你想确保分类的准确性，这是必须的。如果你不应用这个方法，那么系统基本上会返回最佳匹配。如果给定的人不是数据集的一部分，那么你想要避免这种情况，可以通过调用带有阈值值的接口来实现！
- en: Keep in mind that, with all face recognition systems, if you train them with
    data in one setup and test them with data containing completely different situations
    and setups, then the drop in accuracy will be huge.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请记住，对于所有面部识别系统，如果你用一种设置中的数据训练它们，然后用包含完全不同情况和设置的数据测试它们，那么准确性的下降将会很大。
- en: If you build a recognition system based on 2D image information, then frauds
    will be able to hack it by simply printing a 2D image of the person and presenting
    it to the system. In order to avoid this, either include 3D knowledge or add extra
    biometrics.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你基于2D图像信息构建一个识别系统，那么欺诈者只需简单地打印出该人的2D图像并将其展示给系统，就能破解它。为了避免这种情况，要么包含3D知识，要么添加额外的生物识别信息。
- en: Note
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'More information on adding 3D information to avoid fraud attempts can be found
    in the following publications:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于添加3D信息以避免欺诈尝试的信息可以在以下出版物中找到：
- en: Akarun Lale, B. Gokberk, and Albert Ali Salah, *3D face recognition for biometric
    applications*, Signal Processing Conference, 2005 13th European. IEEE, 2005.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Akarun Lale, B. Gokberk, 和 Albert Ali Salah，*3D面部识别在生物识别应用中的研究*，信号处理会议，2005年第13届欧洲IEEE，2005年。
- en: 'Abate Andrea F., et al, *2D and 3D face recognition: A survey*, Pattern Recognition
    Letters 28.14 (2007): 1885-1906.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Abate Andrea F. 等，*2D和3D面部识别：综述*，模式识别快报28.14（2007）：1885-1906。
- en: However, this topic is too specific and complex for the scope of this chapter,
    and will thus not be discussed further.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个主题过于具体和复杂，超出了本章的范围，因此将不再进一步讨论。
- en: Fingerprint identification, how is it done?
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指纹识别，它是如何进行的？
- en: 'In the previous section, we discussed the use of the first biometric, which
    is the face of the person trying to log in to the system. However, since we mentioned
    that using a single biometric is risky, it is better to add secondary biometric
    checks to the system, like a fingerprint. There are several off-the-shelf fingerprint
    scanners that are quite cheap and return you a scanned image. However, you will
    still have to write your own registration software for these scanners, and this
    can be done with OpenCV. Examples of such fingerprint images can be found below:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了使用第一个生物识别技术，即尝试登录系统的个人的面部。然而，由于我们提到使用单一生物识别技术是危险的，因此最好向系统中添加二级生物识别检查，比如指纹。市面上有几种相当便宜的现成指纹扫描仪，它们可以返回扫描图像。然而，你仍然需要为这些扫描仪编写自己的注册软件，这可以使用OpenCV完成。以下是一些指纹图像的示例：
- en: '![Fingerprint identification, how is it done?](img/00104.jpeg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![指纹识别，它是如何进行的？](img/00104.jpeg)'
- en: Examples of single individual thumbprints from different scanners
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 不同扫描仪的单个指纹示例
- en: 'This dataset can be downloaded from the FVC2002 competition website released
    by the University of Bologna. The website ([http://bias.csr.unibo.it/fvc2002/databases.asp](http://bias.csr.unibo.it/fvc2002/databases.asp))
    contains four databases of fingerprints available for public download in the following
    format:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集可以从博洛尼亚大学发布的FVC2002竞赛网站下载。网站([http://bias.csr.unibo.it/fvc2002/databases.asp](http://bias.csr.unibo.it/fvc2002/databases.asp))包含四个指纹数据库，可供公众以下格式下载：
- en: Four fingerprint capturing devices, DB1 - DB4
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 四个指纹捕获设备，DB1 - DB4
- en: For each device, the prints of 10 individuals are available
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个设备，有10个人的指纹可用
- en: For each person, eight different positions of prints were recorded
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个人，记录了八个不同的指纹位置
- en: We will use this publicly available dataset to build our system. We will focus
    on the first capturing device, using up to four fingerprints from each individual
    for training the system and making an average descriptor of the fingerprint. Then,
    we will use the other four fingerprints to evaluate our system and make sure that
    the person is still recognized by our system.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这个公开可用的数据集来构建我们的系统。我们将专注于第一个捕获设备，使用每个个体的最多四个指纹来训练系统并制作指纹的平均描述符。然后，我们将使用其他四个指纹来评估我们的系统，并确保人员仍然可以通过我们的系统被识别。
- en: You can apply the same approach to the data grabbed from the other devices if
    you want to investigate the difference between a system that captures binary images
    and one that captures grayscale images. However, we will provide techniques for
    doing the binarization yourself.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想研究捕获二值图像的系统与捕获灰度图像的系统之间的差异，可以将相同的方法应用于从其他设备获取的数据。然而，我们将提供进行二值化的技术。
- en: Implementing the approach in OpenCV 3
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在OpenCV 3中实现该方法
- en: Note
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The complete fingerprint software for processing fingerprints obtained from
    a fingerprint scanner can be found at:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 处理从指纹扫描仪获取的指纹的完整指纹软件可以在以下位置找到：
- en: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/fingerprint/fingerprint_process/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/fingerprint/fingerprint_process/)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/fingerprint/fingerprint_process/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/fingerprint/fingerprint_process/)'
- en: 'In this subsection, we will describe how you can implement this approach in
    the OpenCV interface. We start by grabbing the image from the fingerprint system
    and applying binarization. This enables us to remove any noise from the image,
    as well as helping us to make the contrast better between the skin and the wrinkled
    surface of the finger:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们将描述如何在OpenCV界面中实现这种方法。我们首先从指纹系统获取图像并应用二值化。这使我们能够从图像中去除任何噪声，同时帮助我们更好地区分皮肤和手指皱褶表面的对比度：
- en: '[PRE12]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The Otsu thresholding will automatically choose the best generic threshold for
    the image to obtain a good contrast between foreground and background information.
    This is because the image contains a bimodal distribution (which means that we
    have an image with two peak histograms) of pixel values. For that image, we can
    take an approximate value in the middle of those peaks as the threshold value
    (for images that are not bimodal, binarization won't be accurate). Otsu allows
    us to avoid using a fixed threshold value, making the system more compatible with
    capturing devices. However, we do acknowledge that, if you only have one capturing
    device, then playing around with a fixed threshold value may result in a better
    image for that specific setup. The result of the thresholding can be seen below.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: Otsu阈值化将自动选择最佳通用阈值，以在前景和背景信息之间获得良好的对比度。这是因为图像包含双峰分布（这意味着我们有一个具有两个峰值直方图的图像）的像素值。对于该图像，我们可以取那些峰值中间的近似值作为阈值值（对于非双峰分布的图像，二值化将不准确）。Otsu允许我们避免使用固定的阈值值，使系统更兼容捕获设备。然而，我们也承认，如果您只有一个捕获设备，那么尝试使用固定的阈值值可能对特定设置产生更好的图像。阈值化的结果如下所示。
- en: In order to make the thinning from the next skeletization step as effective
    as possible, we need to invert the binary image.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使从下一个骨骼化步骤的细化尽可能有效，我们需要反转二值图像。
- en: '![Implementing the approach in OpenCV 3](img/00105.jpeg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![在OpenCV 3中实现该方法](img/00105.jpeg)'
- en: Comparison of grayscale and binarized fingerprint images
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 灰度化和二值化指纹图像的比较
- en: Once we have a binary image, we are ready to calculate our feature points and
    feature point descriptors. However, in order to improve the process a bit more,
    it is better to skeletize the image. This will create more unique and stronger
    interest points. The following piece of code can apply the skeletization on top
    of the binary image. The skeletization is based on the Zhang-Suen line-thinning
    approach.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有一个二值图像，我们就准备好计算我们的特征点和特征点描述符。然而，为了进一步提高过程，最好是进行图像骨架化。这将创建更多独特且更强的兴趣点。以下代码片段可以在二值图像上应用骨架化。骨架化基于Zhang-Suen线细化方法。
- en: Note
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Special thanks to `@bsdNoobz` of the OpenCV Q&A forum, who supplied this iteration
    approach.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢OpenCV Q&A论坛的`@bsdNoobz`，他提供了这种迭代方法。
- en: '[PRE13]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The code above can then simply be applied to our previous steps by calling
    the thinning function on top of our previous binary-generated image. The code
    for this is:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码可以简单地应用于我们之前的步骤，通过在之前生成的二值图像上调用细化函数。此代码如下：
- en: '[PRE14]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This will result in the following output:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下输出：
- en: '![Implementing the approach in OpenCV 3](img/00106.jpeg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![在OpenCV 3中实现此方法](img/00106.jpeg)'
- en: Comparison of binarized and thinned fingerprint images using skeletization techniques
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 使用骨架化技术比较二值化和细化指纹图像
- en: When we get this skeleton image, the next step is to look for crossing points
    on the ridges of the fingerprint, called minutiae points. We can do this with
    a keypoint detector that looks for large changes in local contrast, like the Harris
    corner detector. Since the Harris corner detector is able to detect strong corners
    and edges, it is ideal for the fingerprint problem, where the most important minutiae
    are short edges and bifurcations—the positions where edges come together.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们得到这个骨架图像时，下一步是寻找指纹脊上的交叉点，称为特征点。我们可以使用一个寻找局部对比度大变化的特征点检测器来完成这项工作，就像Harris角检测器。由于Harris角检测器能够检测到强角和边缘，它非常适合指纹问题，其中最重要的特征点是短边缘和分叉——边缘汇合的位置。
- en: Note
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'More information about minutiae points and Harris corner detection can be found
    in the following publications:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 关于特征点和Harris角检测的更多信息可以在以下出版物中找到：
- en: Ross Arun A., Jidnya Shah, and Anil K. Jain, *Toward reconstructing fingerprints
    from minutiae points*, Defense and Security. International Society for Optics
    and Photonics, 2005.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Ross Arun A.，Jidnya Shah，和Anil K. Jain，*从特征点重建指纹*，国防和安全。国际光学和光子学学会，2005。
- en: Harris Chris and Mike Stephens, *A combined corner and edge detector*, Alvey
    vision conference, Vol. 15, 1988.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: Harris Chris和Mike Stephens，*一种结合角和边缘检测器*，Alvey视觉会议，第15卷，1988。
- en: Calling the Harris Corner operation on a skeletonized and binarized image in
    OpenCV is quite straightforward. The Harris corners are stored as positions corresponding
    with their cornerness response value in the image. If we want to detect points
    with a certain cornerness, then we should simply threshold the image.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中对骨架化和二值化图像调用Harris角操作相当直接。Harris角以与图像中其角响应值相对应的位置存储。如果我们想检测具有特定角响应的点，那么我们只需简单地阈值化图像。
- en: '[PRE15]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We now have a map with all the available corner responses rescaled to the range
    of [0 255] and stored as float values. We can now manually define a threshold
    which will generate a good number of keypoints for our application. Playing around
    with this parameter could improve performance in other cases. This can be done
    by using the following code snippet:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个地图，其中包含所有可用的角响应，已重新缩放到[0 255]的范围，并以浮点值存储。我们现在可以手动定义一个阈值，这将为我们应用程序生成大量关键点。调整此参数可能会在其他情况下提高性能。这可以通过以下代码片段来完成：
- en: '[PRE16]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Implementing the approach in OpenCV 3](img/00107.jpeg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![在OpenCV 3中实现此方法](img/00107.jpeg)'
- en: Comparison of thinned fingerprints and the Harris corner response, as well as
    the selected Harris corners
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 细化指纹与Harris角响应以及所选Harris角的比较
- en: Now that we have a list of keypoints, we need to create some sort of formal
    descriptor of the local region around each keypoint to be able to uniquely identify
    it from other keypoints.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有一个关键点列表，我们需要为每个关键点周围的区域创建某种形式的正式描述符，以便能够从其他关键点中唯一地识别它。
- en: Note
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '[Chapter 3](part0029_split_000.html#RL0A1-940925703e144daa867f510896bffb69
    "Chapter 3. Recognizing Facial Expressions with Machine Learning"), *Recognizing
    Facial Expressions with Machine Learning*, discusses in more detail the wide range
    of keypoints out there. In this chapter, we will mainly focus on the process.
    Feel free to adapt the interface to other keypoint detectors and descriptors out
    there, for better or for worse performance.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '[第3章](part0029_split_000.html#RL0A1-940925703e144daa867f510896bffb69 "第3章。使用机器学习识别面部表情")，*使用机器学习识别面部表情*，更详细地讨论了现有的广泛关键点。在本章中，我们将主要关注过程。请随意调整界面以适应其他关键点检测器和描述符，无论结果好坏。'
- en: 'Since we have an application where the orientation of the thumb can differ
    (since it is not in a fixed position), we want a keypoint descriptor that is good
    at handling these slight differences. One of the most common descriptors for this
    is the SIFT descriptor, which stands for **scale invariant feature transform**.
    However, SIFT is not under a BSD license, which can pose problems when used in
    commercial software. A good alternative in OpenCV is the ORB descriptor. You can
    implement it in the following way:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的应用中拇指的方向可能不同（因为它不在固定位置），我们希望有一个关键点描述符能够很好地处理这些细微差异。这种描述符中最常见的一个是SIFT描述符，代表**尺度不变特征变换**。然而，SIFT不在BSD许可之下，这在使用商业软件时可能会引起问题。在OpenCV中，一个好的替代品是ORB描述符。你可以按照以下方式实现它：
- en: '[PRE17]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This enables us to calculate only the descriptors using the ORB approach, since
    we already retrieved the location of the keypoints using the Harris corner approach.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够仅使用ORB方法计算描述符，因为我们已经使用Harris角方法检索了关键点的位置。
- en: At this point, we can retrieve a descriptor for each detected keypoint of any
    given fingerprint. The descriptors matrix contains a row for each keypoint containing
    the representation.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们可以为任何给定指纹的每个检测到的关键点检索一个描述符。描述符矩阵包含每个关键点的一行，包含其表示。
- en: Let's start with the example in which we have just one reference image for each
    fingerprint. We then have a database containing a set of feature descriptors for
    the training persons in the database. We have a single new entry, consisting of
    multiple descriptors for the keypoints found at registration time. We now have
    to match these descriptors to the descriptors stored in the database, to see which
    one has the best match.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从只有一个参考图像的指纹的例子开始。然后我们有一个包含数据库中训练人员的特征描述符的数据库。我们有一个单一的新条目，由在注册时找到的关键点的多个描述符组成。现在我们必须将这些描述符与数据库中存储的描述符进行匹配，以查看哪一个匹配得最好。
- en: The simplest way to do this is to perform brute-force matching using the hamming
    distance criteria between descriptors of different keypoints.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这一点的最简单方法是通过使用不同关键点描述符之间的汉明距离标准进行暴力匹配。
- en: '[PRE18]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We now have all the matches stored as DMatch objects. This means that, for each
    matching couple, we will have the original keypoint, the matched keypoint, and
    a floating point score between both matches, representing the distance between
    the matched points.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将所有匹配存储为DMatch对象。这意味着，对于每一对匹配，我们将有原始关键点、匹配关键点和两个匹配之间的浮点分数，表示匹配点之间的距离。
- en: This seems pretty straightforward. We take a look at the number of matches that
    have been returned by the matching process and weigh them by their Euclidean distance
    in order to add some certainty. We then look for the matching process that yielded
    the biggest score. This will be our best match, and the match we want to return
    as the selected one from the database.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来相当直接。我们查看匹配过程返回的匹配数量，并按它们的欧几里得距离进行加权，以增加一些确定性。然后我们寻找产生最大分数的匹配过程。这将是我们最佳匹配，也是我们想要从数据库中返回的所选匹配。
- en: If you want to avoid an imposter getting assigned to the best matching score,
    you can add a manual threshold on top of the scoring to avoid matches and ignore
    those that are not good enough. However, it is possible that, if you increase
    the score too much, people with little change will be rejected from the system,
    if, for example, someone cuts their finger and thus changes their pattern drastically.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想避免冒名顶替者被分配到最佳匹配分数，你可以在评分之上添加一个手动阈值，以避免匹配并忽略那些不够好的匹配。然而，如果你将分数提高太多，那些变化很小的人可能会被系统拒绝，例如，如果有人割伤了手指，从而剧烈改变了他们的模式。
- en: '![Implementing the approach in OpenCV 3](img/00108.jpeg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![在OpenCV 3中实现此方法](img/00108.jpeg)'
- en: The fingerprint matching process visualized
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 指纹匹配过程的可视化
- en: Iris identification, how is it done?
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虹膜识别，是如何进行的？
- en: 'The last biometric that we will use is the output of an iris scan. Considering
    our setup, there might be several ways to grab iris data:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要使用的最后一种生物识别技术是虹膜扫描的输出。考虑到我们的设置，可能有几种方法来抓取虹膜数据：
- en: We can separate the face and apply an eye detector using face detection, which
    can be done with a high-resolution camera. We can use the resulting regions to
    perform iris segmentation and classification.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用面部检测来分离面部，并使用高分辨率摄像头应用眼部检测器。我们可以使用得到的区域来进行虹膜分割和分类。
- en: We can use a specific eye camera, which grabs an eye image to be classified.
    This can be done either with RGB or NIR.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用特定的眼部摄像头，它抓取用于分类的眼部图像。这可以通过RGB或近红外（NIR）来实现。
- en: 'Since the first approach is prone to a lot of problems, such as the resulting
    eye image having a low resolution, a more common approach is to use a separate
    eye camera that grabs the eye. This is the method that we will use in this chapter.
    An example of a captured eye in both the RGB (visible colors) and NIR (near infra-red)
    spectrums is visualized below:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 由于第一种方法容易遇到很多问题，如生成的眼部图像分辨率低，更常见的方法是使用单独的眼部摄像头来抓取眼部图像。这是我们本章将使用的方法。以下是RGB（可见颜色）和NIR（近红外）光谱中捕获的眼部图像的示例：
- en: '![Iris identification, how is it done?](img/00109.jpeg)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![虹膜识别，是如何进行的？](img/00109.jpeg)'
- en: An example of both a RGB and a NIR iris-based image
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基于RGB和NIR的虹膜图像示例
- en: 'Using NIR images helps us in several ways:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 使用近红外图像可以帮助我们以多种方式：
- en: First of all, color information is omitted, since a lot of conditions like external
    sources of light can influence color information when grabbing the iris image.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，由于在抓取虹膜图像时，许多条件如外部光源等都会影响颜色信息，因此我们省略了颜色信息。
- en: Secondly, the pupil center becomes clearer and fully black, which allows us
    to use techniques that depend on this for segmenting the pupil center.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，瞳孔中心变得更加清晰且完全为黑色，这使得我们可以使用依赖于这一点的技术来分割瞳孔中心。
- en: Thirdly, the available structure is maintained, under different lighting conditions,
    due to the NIR spectrum.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三，由于近红外光谱，即使在不同的光照条件下，可用的结构也能得到保持。
- en: Finally, the outer border of the iris region is clearer, and thus more easily
    separable.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，虹膜区域的边缘更加清晰，因此更容易分离。
- en: We will use data from the CASIA eye dataset for the iris recognition, which
    can be found at [http://biometrics.idealtest.org/](http://biometrics.idealtest.org/).
    This dataset is publicly available for research and non-commercial purposes, and
    access can be requested through the site. A small part of it can be found in our
    software repository, where we have a right and a left eye from one individual,
    which we can now treat as two people since no two irises are identical. We have
    10 samples for each eye, of which we will use eight to train and two to test.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用CASIA眼部数据集的数据进行虹膜识别，该数据集可在[http://biometrics.idealtest.org/](http://biometrics.idealtest.org/)找到。该数据集可供研究和非商业用途免费使用，并且可以通过网站申请访问。我们软件仓库中有一小部分数据，其中包含一个人的左右眼，由于没有两个虹膜是相同的，我们可以将它们视为两个人。每个眼睛有10个样本，我们将使用其中的8个进行训练，2个进行测试。
- en: The approach that we will implement for iris recognition is based on the technique
    suggested by John Daugman. The technique is widely accepted and used in commercial
    systems, and has thus proven its quality.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要实现的虹膜识别方法基于约翰·道格曼（John Daugman）提出的技术。这项技术被广泛接受并在商业系统中使用，从而证明了其质量。
- en: Note
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The original paper written by John Daugman can be found at: [http://www.cl.cam.ac.uk/~jgd1000/irisrecog.pdf](http://www.cl.cam.ac.uk/~jgd1000/irisrecog.pdf)'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 约翰·道格曼（John Daugman）撰写的原始论文可以在以下网址找到：[http://www.cl.cam.ac.uk/~jgd1000/irisrecog.pdf](http://www.cl.cam.ac.uk/~jgd1000/irisrecog.pdf)
- en: Implementing the approach in OpenCV 3
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在OpenCV 3中实现此方法
- en: The first step in getting the iris information is segmenting out the actual
    eye region, containing both the iris and the pupil. We apply a series of operations
    on top of our data to achieve the desired result. This process is necessary to
    keep only the desired data and remove all the redundant eye data that is still
    around.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 获取虹膜信息的第一步是分割出包含虹膜和瞳孔的实际眼部区域。我们在数据上应用一系列操作以实现所需的结果。这个过程是必要的，以保留所需数据并移除所有多余的眼部数据。
- en: 'We first try to get the pupil. The pupil is the darkest area in NIR images,
    and this information can be used to our advantage. The following steps will lead
    us to the pupil area in an eye image:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先尝试获取瞳孔。瞳孔是近红外图像中最暗的区域，这些信息可以为我们带来优势。以下步骤将引导我们找到眼图中的瞳孔区域：
- en: First, we need to apply segmentation to the darkest regions. We can use the
    `inRange()` image, since the values in which the pupil lie are specific to the
    capturing system. However, due to the fact that they all use NIR, the end result
    will be identical for each separate system.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们需要对最暗的区域进行分割。我们可以使用`inRange()`图像，因为瞳孔所在的位置值对于捕获系统是特定的。然而，由于它们都使用近红外(NIR)，最终结果对于每个独立的系统将是相同的。
- en: Then, we apply contour detection to get the outer border of the pupil. We make
    sure that we get the biggest contour from just the outer contours so that we only
    keep one region.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们应用轮廓检测以获取瞳孔的外边缘。我们确保只从外部轮廓中获取最大的轮廓，这样我们只保留一个区域。
- en: Note
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you want to improve performance, you can also look for the bright spots of
    the IR LED first, remove them from the region, and then run the contour detection.
    This will improve robustness when IR LED spots are close to the pupil border.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想提高性能，你也可以先寻找红外LED的亮点，将它们从区域中移除，然后再运行轮廓检测。当红外LED亮点靠近瞳孔边缘时，这将提高鲁棒性。
- en: 'The code for the complete process of a single iris can be found at: [https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_processing/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_processing/)'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 单个虹膜的完整过程代码可以在以下位置找到：[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_processing/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_processing/)
- en: 'This behavior can be achieved by using the following code snippet:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下代码片段可以实现这种行为：
- en: '[PRE19]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![Implementing the approach in OpenCV 3](img/00110.jpeg)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![在OpenCV 3中实现方法](img/00110.jpeg)'
- en: '[PRE20]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![Implementing the approach in OpenCV 3](img/00111.jpeg)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![在OpenCV 3中实现方法](img/00111.jpeg)'
- en: An example of the retrieved Hough Circle result, which gives us the outer border
    of the iris region, for both the left and right eyes.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 左眼和右眼的Hough圆检测结果的示例，它给出了虹膜区域的外边缘
- en: 'Once we have succeeded in finding the outer contour, it is pretty straightforward
    to mask the iris region from the original input, as shown in the figure below:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们成功找到外轮廓，从原始输入中掩码虹膜区域就非常直接了，如图所示：
- en: '![Implementing the approach in OpenCV 3](img/00112.jpeg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![在OpenCV 3中实现方法](img/00112.jpeg)'
- en: An example of the masked iris image
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个掩码虹膜图像的示例
- en: 'We now have our region of interest, meaning only the iris region, as shown
    in the above figure. We acknowledge that there could still be some partial whiskers
    inside the region, but for now we will simply ignore them. Now, we want to encode
    this iris image into a feature vector for comparison. There are two steps still
    to take to reach that level:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了感兴趣的区域，即只有虹膜区域，如图所示。我们承认该区域内可能仍有一些部分胡须，但现阶段我们将简单地忽略它们。现在，我们希望将这个虹膜图像编码成一个特征向量以进行比较。为了达到这个水平，我们还需要进行两个步骤：
- en: Unwrapping of the iris pattern from a polar coordinate system to a Cartesian
    coordinate system for further processing
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将虹膜图案从极坐标系展开到笛卡尔坐标系以进行进一步处理
- en: Applying encoding to the iris image and matching it against a database of known
    representations
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将虹膜图像进行编码并与已知表示的数据库进行匹配
- en: 'We start by providing a code snippet that will unwrap the desired iris region
    from the retrieved final result:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先提供一个代码片段，该代码片段将展开从检索到的最终结果中所需的虹膜区域：
- en: '[PRE22]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This will result in the following conversion, which gives us the radial unwrapping
    of the iris region, as shown in the figure below:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下转换，它给出了如图所示的虹膜区域的径向展开：
- en: '![Implementing the approach in OpenCV 3](img/00113.jpeg)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![在OpenCV 3中实现方法](img/00113.jpeg)'
- en: An example of the radially unwrapped iris image for both the left and right
    eyes
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 左眼和右眼的径向展开虹膜图像示例
- en: This radial unwrapping is done for all the eight training images that we have
    for each eye and for the two testing images that we also have for each eye. The
    Daugman approach applies phase quadrant modulation to encode the iris pattern.
    However, this is not yet implemented in OpenCV and is too complex for this chapter.
    Therefore, we decided to look for an available OpenCV implementation that could
    be used to match the irises. A good approach is to use the local binary pattern
    histogram comparison, since we are looking for something that can identify local
    textures, and this was also used for face recognition.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 这种径向展开是对每个眼睛的八个训练图像以及我们也有每个眼睛的两个测试图像进行的。Daugman方法通过相位象限调制来编码虹膜模式。然而，这尚未在OpenCV中实现，并且对于本章来说过于复杂。因此，我们决定寻找一个可用的OpenCV实现，可以用来匹配虹膜。一个好的方法是用局部二值模式直方图比较，因为我们正在寻找能够识别局部纹理的东西，这也在人脸识别中得到了应用。
- en: Note
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Software for unwrapping a complete set of iris images can be found at:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在以下位置找到用于展开完整套虹膜图像的软件：
- en: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_processing_batch/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_processing_batch/)'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_processing_batch/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_processing_batch/)'
- en: 'Software for creating the matching interface can be found at:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 创建匹配界面的软件可以在以下位置找到：
- en: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_recognition/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_recognition/)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_recognition/](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_6/source_code/iris/iris_recognition/)'
- en: 'Finally, encoding works as follows in OpenCV 3:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在OpenCV 3中编码的工作方式如下：
- en: '[PRE23]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We count the testing results again, which yields the result shown in the figure
    below:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次计算测试结果，得到下图中所示的结果：
- en: '![Implementing the approach in OpenCV 3](img/00114.jpeg)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![在OpenCV 3中实现方法](img/00114.jpeg)'
- en: Encoded iris image and the corresponding iris code visualized.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 编码的虹膜图像及其相应的虹膜代码可视化。
- en: Combining the techniques to create an efficient people-registration system
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结合技术创建高效的人员注册系统
- en: 'The previous sections each discussed a specific biometric property. Now, let''s
    combine all this information to create an efficient identification system. The
    approach that we will implement follows the structure described in the figure
    below:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 前几节分别讨论了特定的生物识别属性。现在，让我们结合所有这些信息来创建一个高效的识别系统。我们将实现的方法遵循下图中描述的结构：
- en: '![Combining the techniques to create an efficient people-registration system](img/00115.jpeg)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![结合技术创建高效的人员注册系统](img/00115.jpeg)'
- en: People authentication pipeline
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 人员认证流程
- en: 'As shown above, the first step is to use a camera interface to check if there
    actually is a person in front of the camera. This is done by performing face detection
    on the input image. We also test to see if the other biometric systems are active.
    This leaves us two checks that need to be performed:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，第一步是使用相机界面检查相机前是否真的有一个人。这是通过对输入图像执行人脸检测来完成的。我们还测试了其他生物识别系统是否处于活动状态。这留下了两个需要执行的检查：
- en: Check if the iris scanner is in use. This, of course, depends on the system
    used. If it depends on the eye retrieved from the face detection, this check should
    be ignored. If the eye is retrieved using an actual eye scanner, then there should
    at least be an eye detected to give a positive signal.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查虹膜扫描仪是否在使用中。这当然取决于所使用的系统。如果它依赖于从人脸检测中检索到的眼睛，则此检查应被忽略。如果使用实际的眼球扫描仪检索眼睛，那么至少应该检测到一个眼睛以给出一个积极的信号。
- en: Check if the fingerprint scanner is active. Do we actually have a finger available
    for taking a fingerprint picture? This is checked by applying background subtraction
    to the empty scene. If a finger is in place, then there should be a response to
    the background-foreground subtraction.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查指纹扫描仪是否处于活动状态。我们是否真的有可用于获取指纹图像的手指？这是通过对空场景应用背景减法来检查的。如果手指到位，那么应该对背景前景减法有响应。
- en: Of course, we are aware that some of these systems use pressure-based detection
    to find a hand or finger. In such cases, you do not have to perform this check
    yourself, but let the system decide whether to proceed or not.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们知道其中一些系统使用基于压力的检测来找到手或手指。在这种情况下，你不必自己执行此检查，而是让系统决定是否继续。
- en: 'Once we have all the systems, we can start the individual recognition systems
    described in previous sections. They will all output the identity of a known person
    from the common database that was constructed for this purpose. Then, all these
    outcomes are given to the smart majority voting. This system checks for several
    things:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了所有系统，我们就可以开始之前章节中描述的个别识别系统。它们将输出已知人员的身份，这些人员是从为这个目的构建的公共数据库中输出的。然后，将这些结果提交给智能多数投票。这个系统会检查几个方面：
- en: It checks if the biometric system checks actually succeeded, by returning their
    match from the database. If not, a person is not granted access and the system
    asks to reconfirm the failing biometrics.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它通过从数据库返回匹配结果来检查生物识别系统是否实际成功。如果没有，则不允许人员进入，系统会要求重新确认失败的生物识别信息。
- en: If the system has to measure biometrics more than three times in a row, the
    system jams and doesn't work until the owner of the system unlocks it. This is
    to avoid a bug in the current interface that exploits the system and tries to
    get in.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果系统需要连续三次以上测量生物识别信息，系统会卡住，直到系统所有者解锁它才会工作。这是为了避免当前界面中利用系统并试图进入的漏洞。
- en: If the biometric checks work, a smart majority voting is applied to the results.
    This means that if two biometrics identify person A but one biometric identifies
    person B, then the output result will still be person A. If that person is marked
    as the owner, then the system will allow access.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果生物识别检查成功，则对结果应用智能多数投票。这意味着如果两个生物识别识别到A个人，但一个生物识别识别到B个人，则输出结果仍然是A个人。如果那个人被标记为所有者，则系统将允许访问。
- en: Based on the individual software provided with the separate subtopics, it should
    be quite straightforward to combine them into a single interface.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据提供的各个子主题的独立软件，将它们组合成一个单一界面应该相当直接。
- en: If the system still fails (this is a case study, not a 100% failproof system),
    there are several things that can be done to achieve the desired results.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果系统仍然失败（这是一个案例研究，不是一个100%万无一失的系统），可以采取一些措施来实现预期结果。
- en: You should try to improve the detection and matching quality of each separate
    biometric. This can be done by supplying better training data, experimenting with
    different feature extraction methods or different feature comparison methods,
    as discussed in the introduction to the chapter. The variety of combinations is
    endless, so go ahead and give it a try.
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该尝试提高每个单独生物识别的检测和匹配质量。这可以通过提供更好的训练数据、尝试不同的特征提取方法或不同的特征比较方法来实现，如本章引言中所述。组合的种类无穷无尽，所以大胆尝试吧。
- en: You should try to give each biometric a certainty score on its output. Since
    we have multiple systems voting for the identity of a person, we could take into
    account their certainty on single classifications. For example, when running a
    database, matching the distance to the best match can be wrapped to a scale range
    of [0 100] to give a certainty percentage. We can then multiply the vote of each
    biometric by its weight and do a smart-weighted majority voting.
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该尝试为每个生物识别输出分配一个置信度分数。由于我们有多个系统投票确认一个人的身份，我们可以考虑它们在单个分类上的置信度。例如，当运行数据库时，匹配到最佳匹配的距离可以转换为[0
    100]的刻度范围，以给出置信度百分比。然后我们可以将每个生物识别的投票乘以其权重，并进行智能加权多数投票。
- en: Summary
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned that an authentication system can be more than
    a simple face recognition interface by using multiple biometric properties of
    the person trying to authenticate. We showed you how to perform iris and fingerprint
    recognition using the OpenCV library to make a multi-biometric authentication
    system. One can add even more biometrics to the system, since the possibilities
    are endless.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解到，通过使用尝试认证的人的多个生物识别属性，认证系统可以不仅仅是简单的面部识别界面。我们展示了如何使用OpenCV库执行虹膜和指纹识别，以创建一个多生物识别认证系统。可以添加更多的生物识别到系统中，因为可能性是无限的。
- en: The focus of the chapter was to get people interested in the power of biometrics
    and the endless possibilities of the OpenCV library. If you feel inspired by this,
    do experiment further and share your thoughts with the community.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点是激发人们对生物识别技术力量和OpenCV库无限可能性的兴趣。如果你因此受到启发，不妨进一步实验，并与社区分享你的想法。
- en: Note
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'I would like to thank the users of the OpenCV Q&A discussion forum who helped
    me to push the limits when I hit brick walls. I would explicitly like to thank
    the following users for their directions: Berak, Guanta, Theodore, and GilLevi.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 我要感谢OpenCV问答讨论论坛的用户们，在我遇到难题时，他们帮助我突破了限制。我特别想感谢以下用户提供的指导：Berak、Guanta、Theodore和GilLevi。
