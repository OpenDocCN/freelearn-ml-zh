- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Case Study 1 – Computer Vision
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究1 – 计算机视觉
- en: In this chapter, you will be introduced to a multitude of industrial applications
    of computer vision. You will discover some of the key problems that were successfully
    solved using computer vision. In parallel to this, you will grasp the major issues
    with traditional computer vision solutions. Additionally, you will explore and
    comprehend thought-provoking examples of using synthetic data to improve computer
    vision solutions in practice.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解计算机视觉在众多工业应用中的多样性。您将发现一些使用计算机视觉成功解决的问题。与此并行，您将掌握传统计算机视觉解决方案的主要问题。此外，您将探索并理解使用合成数据在实际中改进计算机视觉解决方案的引人深思的例子。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Industrial revolutions – computer vision as a solution
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工业革命——计算机视觉作为解决方案
- en: Synthetic data and computer vision – examples from industry
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合成数据和计算机视觉——行业中的例子
- en: Transforming industries – the power of computer vision
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转型产业 – 计算机视觉的力量
- en: In this section, we’ll briefly discuss the main four industrial revolutions
    as they help us to better comprehend the historical context of AI, data, and computer
    vision. Then, we will learn why computer vision is becoming an integral component
    of our modern industries.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将简要讨论主要的四次工业革命，因为它们有助于我们更好地理解人工智能、数据和计算机视觉的历史背景。然后，我们将了解为什么计算机视觉正成为我们现代工业的一个不可或缺的组成部分。
- en: The four waves of the industrial revolution
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工业革命的四波
- en: '**Industrial revolution** refers to a global and rapid transformation in the
    economy. Usually, this transformation brings and utilizes new inventions, discoveries,
    and technologies to make manufacturing and production processes more efficient.
    The history of the industrial revolutions can be summarized into four stages:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**工业革命**指的是全球经济发生的全球性和快速转变。通常，这种转变会带来并利用新的发明、发现和技术，使制造和生产过程更加高效。工业革命的历史可以总结为四个阶段：'
- en: '![Figure 10.1 – Industrial revolutions](img/Figure_10_01_B18494.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图10.1 – 工业革命](img/Figure_10_01_B18494.jpg)'
- en: Figure 10.1 – Industrial revolutions
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – 工业革命
- en: Next, let’s discuss each of the industrial revolutions shown in *Figure 10**.1*
    in greater depth.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们更深入地讨论图10.1*中展示的每一次工业革命。
- en: Industry 1.0
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工业1.0
- en: This refers to the first industrial revolution, which happened in the early
    19th century. It supplemented, supported, and enhanced existing labor processes
    by incorporating machinery; animals and manual labor were mostly replaced with
    water and steam engines. It was a great shift toward using machinery to carry
    out mostly the same tasks but more efficiently. This opened the door for new industries,
    such as iron production, which significantly influenced the development of industries
    such as construction, transportation, and manufacturing. Industry 1.0 changed
    the way products were produced, which laid the foundation for the next revolution
    in industry.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这指的是第一次工业革命，发生在19世纪初。它通过引入机械来补充、支持和增强现有的劳动过程；动物和手工劳动大多被水和蒸汽机所取代。这是一次向使用机械执行大多数相同任务但更高效的大转变。这为新的工业打开了大门，如铁的生产，这对建筑、交通和制造业的发展产生了重大影响。工业1.0改变了产品的生产方式，为下一次工业革命奠定了基础。
- en: Industry 2.0
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工业2.0
- en: Electricity was the major driver of the substantial shift in production that
    happened with Industry 2.0\. Assembly line production and the widespread adoption
    of electricity as a power source facilitated mass production. In parallel to that,
    the great advancement in steelmaking and production enabled the building of more
    sophisticated and powerful machinery. This set the stage for the following industrial
    revolution.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 电是工业2.0时期生产发生重大转变的主要驱动力。装配线生产和电力作为动力源的广泛应用促进了大规模生产。与此并行，钢铁制造和生产的大幅进步使得更复杂、更强大的机械得以建造。这为随后的工业革命奠定了基础。
- en: Industry 3.0
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工业3.0
- en: Electricity was one of the discoveries that changed our civilization dramatically,
    including communication and industry. With mass production, which is considered
    one of the main themes of Industry 2.0, there was an urgent need for automation
    to minimize errors and maximize efficiency. Thus, computers were utilized by manufacturers
    to achieve yet more precise and efficient productions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 电力是我们文明发生重大变化的发现之一，包括通信和工业。随着大规模生产，这被认为是工业2.0的主要主题之一，迫切需要自动化以最小化错误并最大化效率。因此，制造商利用计算机来实现更加精确和高效的生产。
- en: Industry 4.0
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工业4.0
- en: The digital transformations of most industries, great competition between global
    companies, and scarce resources all opened the door for cyber-physical systems
    and thus **smart factories**. Consequently, AI, robotics, and **big data** started
    to attract more attention in industry and academia. Since the main properties
    of this industrial revolution are great efficiency, customized products, and services,
    ML and data are the gems of achieving these aims.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数行业的数字化转型、全球公司之间的激烈竞争以及资源稀缺都为网络物理系统和因此**智能工厂**打开了大门。因此，人工智能、机器人和**大数据**开始吸引工业和学术界更多的关注。由于这次工业革命的主要特性是高效率、定制产品和服务的个性化，机器学习和数据是实现这些目标的关键宝石。
- en: Next, we will see why computer vision is the backbone of many of our current
    industries.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看到为什么计算机视觉是许多我们当前行业的基础。
- en: Industry 4.0 and computer vision
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工业4.0和计算机视觉
- en: 'Computer vision is an interdisciplinary field that enables machines to understand
    images. Computer vision is an essential component of our current industrial revolution.
    It has been widely applied for quality control, safety assurance, predictive maintenance,
    and other essential and critical applications. Next, let’s discuss the main uses
    of computer vision in the following fields:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉是一个跨学科领域，它使机器能够理解图像。计算机视觉是我们当前工业革命的一个基本组成部分。它已被广泛应用于质量控制、安全保障、预测性维护和其他基本且关键的应用。接下来，让我们讨论计算机视觉在以下领域的应用：
- en: Manufacturing
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制造业
- en: Autonomous driving
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动驾驶
- en: Healthcare
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 医疗保健
- en: Agriculture
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 农业
- en: Surveillance and security
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控和安全
- en: Manufacturing
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 制造业
- en: In manufacturing industries, human error can cause significant delays that affect
    the entire production pipeline. It may even cause damage to machines and infrastructures,
    injuries, and death. Computer vision comes as a solution to complement, support,
    or replace the human element in the process. Computer vision can be utilized to
    guide the assembly and manufacturing processes to achieve higher throughput with
    lower costs and higher quality.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在制造业中，人为错误可能导致整个生产流程的重大延误。它甚至可能损坏机器和基础设施，造成伤害和死亡。计算机视觉作为一种解决方案，可以补充、支持或替代过程中的人类因素。计算机视觉可用于指导组装和制造过程，以实现更高的吞吐量、更低的成本和更高的质量。
- en: Contact lens manufacturers worked with *ADLINK* and *LEDA* that have used computer
    vision to automate the contact lens inspection process. This task was usually
    performed by human inspectors where thousands of lenses were visually inspected
    each day. It was a time-consuming process where errors were not avoidable. By
    deploying ADLINK and LEDA’s computer vision-based solution, the company which
    manufactures contact lenses was able to make its inspection process 3 times more
    accurate and 50 times faster! Their novel solution removes the human element from
    the process, which substantially increases the scalability and quality of the
    inspection process. For more information about this use case, please refer to
    *ADLINK and LEDA Technology Create AI-Enabled Contact Lens Inspection* *Solution*
    ([https://data.embeddedcomputing.com/uploads/articles/whitepapers/13328.pdf](https://data.embeddedcomputing.com/uploads/articles/whitepapers/13328.pdf)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 软镜制造商与*ADLINK*和*LEDA*合作，他们已经使用计算机视觉自动化了软镜检验过程。这项任务通常由人工检验员完成，每天要检查数千个镜片。这是一个耗时且错误难以避免的过程。通过部署ADLINK和LEDA基于计算机视觉的解决方案，制造软镜的公司能够使其检验过程准确度提高3倍，速度提高50倍！他们的创新解决方案从过程中移除了人为因素，这大大提高了检验过程的可扩展性和质量。有关此用例的更多信息，请参阅*ADLINK和LEDA技术创造人工智能驱动的软镜检验解决方案*([https://data.embeddedcomputing.com/uploads/articles/whitepapers/13328.pdf](https://data.embeddedcomputing.com/uploads/articles/whitepapers/13328.pdf))。
- en: Autonomous driving
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动驾驶
- en: This is one of the main sectors that is closely associated with computer vision.
    **Autonomous driving** technology can reduce human errors in driving and thus
    minimize accidents, injuries, and death. In 2022, the number of road traffic fatalities
    exceeded 46,200 cases in the US ([https://www.statista.com/statistics/192575/road-traffic-fatalities-in-the-united-states](https://www.statista.com/statistics/192575/road-traffic-fatalities-in-the-united-states)).
    Thus, computer vision presents a promising safe, efficient, and productive solution.
    Self-driving companies such as *Tesla*, *Waymo*, and *Mobileye* have already started
    utilizing computer vision for lane detection and tracking, pedestrian detection,
    object recognition, and traffic sign detection and recognition. As you may guess,
    the failure of such computer vision algorithms can cause damage to property, severe
    injuries, or death. Thus, training and developing a robust computer vision algorithm
    is a hot topic for ML researchers and is gaining more momentum and receiving more
    attention.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这是与计算机视觉紧密相关的主要领域之一。**自动驾驶**技术可以减少驾驶中的人为错误，从而最大限度地减少事故、伤害和死亡。2022年，美国道路交通事故死亡人数超过46,200起([https://www.statista.com/statistics/192575/road-traffic-fatalities-in-the-united-states](https://www.statista.com/statistics/192575/road-traffic-fatalities-in-the-united-states))。因此，计算机视觉提供了一个有希望的安全、高效和富有成效的解决方案。像
    *特斯拉*、*Waymo* 和 *Mobileye* 这样的自动驾驶公司已经开始利用计算机视觉进行车道检测和跟踪、行人检测、物体识别和交通标志检测与识别。正如你可能猜到的，这样的计算机视觉算法的失败可能导致财产损失、严重伤害或死亡。因此，训练和发展稳健的计算机视觉算法是机器学习研究人员的热门话题，并且正在获得更多的动力和关注。
- en: '**Tesla cars** have developed a computer vision system based on neural networks
    that takes video inputs from different cameras. Then, it processes the visual
    information and predicts the road layout, static objects, pedestrians, and other
    vehicles in the scene. For more information, please refer to *Tesla – AI &* *Robotics*
    ([https://www.tesla.com/AI](https://www.tesla.com/AI)).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**特斯拉汽车** 开发了一个基于神经网络的计算机视觉系统，该系统从不同的摄像头获取视频输入。然后，它处理视觉信息并预测场景中的道路布局、静态物体、行人和其他车辆。更多信息，请参阅
    *Tesla – AI &* *Robotics* ([https://www.tesla.com/AI](https://www.tesla.com/AI))。'
- en: '**Aurora Driver** is a computer vision system that can be utilized for autonomous
    driving. The system learns to fuse information collected from various sensors,
    such as lidar, radar, and cameras, to provide an understanding of the driving
    environment. For more information, check out *Perception at Aurora: No measurement
    left* *behind* ([https://blog.aurora.tech/engineering/perception-at-aurora-no-measurement-left-behind](https://blog.aurora.tech/engineering/perception-at-aurora-no-measurement-left-behind)).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**Aurora Driver** 是一个可用于自动驾驶的计算机视觉系统。该系统学会融合来自各种传感器收集的信息，例如激光雷达、雷达和摄像头，以提供对驾驶环境的理解。更多信息，请参阅
    *Perception at Aurora: No measurement left* *behind* ([https://blog.aurora.tech/engineering/perception-at-aurora-no-measurement-left-behind](https://blog.aurora.tech/engineering/perception-at-aurora-no-measurement-left-behind))。'
- en: Next, let’s move on to computer vision applications in the healthcare sector.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们转向医疗保健领域的计算机视觉应用。
- en: Healthcare
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 医疗保健
- en: Computer vision revolutionized the field of healthcare thanks to its great ability
    to analyze large amounts of patient data and provide quick, accurate, and efficient
    diagnoses. Computer vision algorithms can assist healthcare practitioners, surgeons,
    and physicians in making accurate and timely decisions that can reduce costs,
    improve treatments and operations, and reduce human errors.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其分析大量患者数据并提供快速、准确和高效诊断的强大能力，计算机视觉彻底改变了医疗保健领域。计算机视觉算法可以帮助医疗保健从业者、外科医生和医生做出准确和及时的决定，从而降低成本、改善治疗和手术，并减少人为错误。
- en: A multitude of healthcare providers have already started harnessing computer
    vision’s potential in this field. Let’s highlight two examples from *Viz.ai* and
    *Paige*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 许多医疗保健提供商已经开始利用计算机视觉在该领域的潜力。让我们突出 *Viz.ai* 和 *Paige* 中的两个例子。
- en: '**Viz.ai** utilizes computer vision algorithms to identify signs of a stroke
    by analyzing patients’ medical images. They deploy these algorithms to efficiently
    analyze **Computerized Tomography** (**CT**) and **Magnetic Resonance Imaging**
    (**MRI**) scans and notify neurologists if a sign of a stroke is present to take
    the appropriate action.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**Viz.ai** 利用计算机视觉算法通过分析患者的医学图像来识别中风迹象。他们将算法部署到高效分析 **计算机断层扫描** (**CT**) 和
    **磁共振成像** (**MRI**)，如果发现中风迹象，就会通知神经科医生采取适当的行动。'
- en: '**Paige** is another company that has deployed computer vision to improve diagnostics
    and predictive tests of pathologists. In a recent study by *Yale Medicine* on
    the effectiveness of Paige Prostate (the name of their computer vision tool),
    1,876 predictions by this system classified as “suspicious” were reviewed by professional
    pathologists. The study concluded that only 31.4% of biopsies had to be reviewed
    by pathologists. Thus, this tool can indeed improve the productivity of pathologists.
    Additionally, it demonstrated that this tool could improve the detection of prostate
    cancer especially when being reviewed by non-genitourinary specialized pathologists.
    For more details, refer to *An independent assessment of AI for prostate cancer*
    *detection* ([https://paige.ai/case-study/an-independent-assessment-of-ai-for-prostate-cancer-detection](https://paige.ai/case-study/an-independent-assessment-of-ai-for-prostate-cancer-detection)).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**派吉**是另一家已部署计算机视觉来改善病理学家诊断和预测测试的公司。在耶鲁医学院最近的一项关于派吉前列腺（他们计算机视觉工具的名称）有效性的研究中，1,876个由该系统分类为“可疑”的预测被专业病理学家审查。该研究得出结论，只有31.4%的活检需要由病理学家审查。因此，这个工具确实可以提高病理学家的生产力。此外，它还表明，这个工具可以提高前列腺癌的检测率，尤其是在非泌尿生殖系统专业病理学家审查时。更多详情，请参阅*独立评估AI在前列腺癌*检测中的应用([https://paige.ai/case-study/an-independent-assessment-of-ai-for-prostate-cancer-detection](https://paige.ai/case-study/an-independent-assessment-of-ai-for-prostate-cancer-detection))。'
- en: In the following section, let’s examine computer vision applications in the
    agriculture field.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，让我们考察计算机视觉在农业领域的应用。
- en: Agriculture
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 农业
- en: A recent report published by the **Food Security Information Network** (**FSIN**)
    titled *Global Report on Food Crises 2023* ([https://www.fsinplatform.org/sites/default/files/resources/files/GRFC2023-hi-res.pdf](https://www.fsinplatform.org/sites/default/files/resources/files/GRFC2023-hi-res.pdf))
    raised a red flag about the current and future food insecurity in 58 countries.
    The report highlighted that almost 250 million people were facing severe food
    insecurity in 2022, which was a large increase from 2021, when the number was
    around 190 million. According to experts, the situation is just going to become
    worse in the future.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 食品安全信息网络（**FSIN**）最近发布的一份题为*2023年全球粮食危机报告*的报告([https://www.fsinplatform.org/sites/default/files/resources/files/GRFC2023-hi-res.pdf](https://www.fsinplatform.org/sites/default/files/resources/files/GRFC2023-hi-res.pdf))对58个国家的当前和未来粮食不安全情况提出了警告。报告强调，2022年约有2.5亿人面临严重的粮食不安全，这比2021年的约1.9亿人有所增加。据专家们说，未来情况只会变得更糟。
- en: Many companies, such as *Taranis* and *Prospera,* utilize computer vision to
    guide farmers to better optimize resources, analyze crop data, continuously monitor
    crops, and detect potential issues, such as pests and diseases. Let’s talk in
    more detail about Taranis and Prospera.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 许多公司，如*塔兰尼斯*和*普罗斯佩拉*，利用计算机视觉引导农民更好地优化资源，分析作物数据，持续监测作物，并检测潜在问题，如害虫和疾病。让我们更详细地谈谈塔兰尼斯和普罗斯佩拉。
- en: '**Taranis** is a company focused on developing technologies that help agriculture
    businesses and farmers to improve their crop quality, yield, and profit. It utilizes
    drones and computer vision to analyze farms and make the treatment more efficient.
    The technology developed is used to efficiently control large farms at the leaf
    level, which is almost impossible without computer vision. For more information,
    please refer to the company website ([https://www.taranis.com](https://www.taranis.com)).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**塔兰尼斯**是一家专注于开发帮助农业企业和农民提高作物质量、产量和利润的技术公司。它利用无人机和计算机视觉来分析农场，使治疗更加高效。该技术开发的成果被用于在叶级水平上高效控制大型农场，这在没有计算机视觉的情况下几乎是无法实现的。如需更多信息，请参阅公司网站([https://www.taranis.com](https://www.taranis.com))。'
- en: '**Prospera** is another company that relies on computer vision to support farmers.
    The technology helps them control pivots, pumps, and other aspects of the irrigation
    system. Additionally, it continuously monitors crop health and instantly detects
    any issues. For more details, refer to the company website ([https://prospera.ag](https://prospera.ag)).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**普罗斯佩拉**是另一家依赖计算机视觉来支持农民的公司。这项技术帮助他们控制旋转器、泵和其他灌溉系统的方面。此外，它持续监测作物健康，并立即检测任何问题。更多详情，请参阅公司网站([https://prospera.ag](https://prospera.ag))。'
- en: As you may expect, these key traditional computer vision solutions can be further
    enhanced by utilizing synthetic data as a complementary or alternative to real
    data. Now, let’s delve into the main issues with these computer vision solutions,
    stemming from their significant reliance on real data.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所预期的那样，这些关键的传统计算机视觉解决方案可以通过利用合成数据作为真实数据的补充或替代来进一步改进。现在，让我们深入了解这些计算机视觉解决方案的主要问题，这些问题源于它们对真实数据的重大依赖。
- en: 'As we have discussed in previous chapters, computer vision algorithms that
    are based on real data usually suffer from the following issues:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的章节中讨论的那样，基于真实数据的计算机视觉算法通常存在以下问题：
- en: Insufficient training data
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据不足
- en: Data quality issues and bias
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据质量问题及偏差
- en: Limited variability
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变化性有限
- en: In the next section, you will learn how and why industries have started incorporating
    synthetic data in their computer vision-based solutions.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将了解为什么和如何行业开始在其基于计算机视觉的解决方案中采用合成数据。
- en: Surveillance and security
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控和安全
- en: 'One of the main key capabilities of computer vision is accurately and efficiently
    analyzing visual information, such as images and videos. For example, it can be
    leveraged for the following aims:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉的主要关键能力之一是准确且高效地分析视觉信息，如图像和视频。例如，它可以用于以下目的：
- en: Detecting unusual behaviors
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测异常行为
- en: Identifying suspicious people, items, or actions
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别可疑人员、物品或行为
- en: License plate recognition
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 车牌识别
- en: 'Biometric identification: face, iris, palm print, vein, voice, and fingerprint
    recognition'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生物识别识别：面部、虹膜、掌纹、静脉、声音和指纹识别
- en: Thus, computer vision can be leveraged to prevent unauthorized access, protect
    people and assets, and identify security threats and risks in real time. Computer
    vision is used these days to ensure public safety. For example, it is used in
    airports, public transport, streets, parks, and other public spaces. Many companies
    have been successfully deploying computer vision for security and surveillance
    problems, such as Hikvision ([https://www.hikvision.com](https://www.hikvision.com)),
    Avigilon ([https://www.avigilon.com](https://www.avigilon.com)), Verkada ([https://www.verkada.com](https://www.verkada.com)),
    Huawei, Google, Microsoft, and Amazon. Let’s delve into one interesting case study
    with Fujitsu and its interesting use of computer vision to monitor and smooth
    traffic flows in Montreal.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，计算机视觉可以用来防止未经授权的访问，保护人员和资产，并在实时中识别安全威胁和风险。如今，计算机视觉被用于确保公共安全。例如，它在机场、公共交通、街道、公园和其他公共场所得到应用。许多公司已经成功地将计算机视觉用于安全和监控问题，例如海康威视([https://www.hikvision.com](https://www.hikvision.com))、大华([https://www.avigilon.com](https://www.avigilon.com))、Verkada([https://www.verkada.com](https://www.verkada.com))、华为、谷歌、微软和亚马逊。让我们深入了解一个有趣的案例研究，即富士通及其在蒙特利尔监控和优化交通流量方面的有趣应用。
- en: The city of Montreal struggled with many issues related to traffic flow because
    of factors such as limited entry and exit points, insufficient road infrastructure,
    and an inadequate traffic management system. As a solution, Fujitsu proposed a
    computer vision-based solution for most traffic issues. The system collects data
    from CCTV cameras, more than 2,500 traffic lights, and other sensors. Then, the
    system makes a real-time decision to optimize the traffic flow. The computer vision-based
    solution has reduced travel time, air pollution, and other traffic-related issues.
    For more details, please refer to *Smoothing traffic flows with AI* *analysis*
    ([https://www2.fujitsu.com/global/customer-stories/cs-city-of-montreal-20210701](https://www2.fujitsu.com/global/customer-stories/cs-city-of-montreal-20210701)).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 蒙特利尔市因入口和出口点有限、道路基础设施不足以及交通管理系统不完善等因素，在交通流量方面遇到了许多问题。作为解决方案，富士通提出了一种基于计算机视觉的解决方案来解决大多数交通问题。该系统从监控摄像头、超过2,500个交通信号灯和其他传感器收集数据。然后，系统做出实时决策以优化交通流量。基于计算机视觉的解决方案降低了旅行时间、空气污染和其他与交通相关的问题。更多详情请参阅*使用AI平滑交通流量*分析([https://www2.fujitsu.com/global/customer-stories/cs-city-of-montreal-20210701](https://www2.fujitsu.com/global/customer-stories/cs-city-of-montreal-20210701))。
- en: Synthetic data and computer vision – examples from industry
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据和计算机视觉 - 行业中的例子
- en: In this section, you will learn about and understand how companies have just
    started using synthetic data-based computer vision solutions to stand out from
    competitors and overcome real data limitations and issues.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将了解并理解公司如何刚刚开始使用基于合成数据的计算机视觉解决方案来脱颖而出并克服真实数据限制和问题。
- en: Neurolabs using synthetic data in retail
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Neurolabs在零售中使用合成数据
- en: 'According to *Getting Availability Right: Bringing Out-of-Stocks Under Control*
    ([https://www.oliverwyman.com/content/dam/oliver-wyman/global/en/2014/aug/2012_CEU_POV_Getting%20Availability%20Right_ENG.pdf](https://www.oliverwyman.com/content/dam/oliver-wyman/global/en/2014/aug/2012_CEU_POV_Getting%20Availability%20Right_ENG.pdf)),
    out-of-stock items cause heavy financial losses and dissatisfied customers. The
    consequences can be dramatic on businesses and revenues. At the same time, collecting
    and annotating large-scale real data for this task is an expensive and time-consuming
    process. Neurolabs, an ML company specializing in providing solutions in retail
    automation, investigated an elegant solution using synthetic data for this issue.
    They utilized Unity and their own synthetic data generator to generate 1,200 images
    of 129 unique **Stock Keeping Units** (**SKUs**) on shelves. The dataset is named
    CPGDet-129 and can be downloaded from this link ([https://dl.orangedox.com/SampleRetailSyntheticDataset](https://dl.orangedox.com/SampleRetailSyntheticDataset))
    . Additionally, for more details about the dataset and license, please refer to
    the GitHub repository ([https://github.com/neurolaboratories/reshelf-detection](https://github.com/neurolaboratories/reshelf-detection)).
    The dataset was automatically generated and labeled. Moreover, it specifically
    supports object detection tasks. Training a state-of-the-art object detection
    algorithm on their synthetic dataset alone, without using any real data, they
    were able to achieve 60% **Mean Average Precision** (**mAP**) on a real test dataset.
    mAP is a metric used to tell us how accurate the object detection model is at
    predicting the bounding boxes around the objects of interest. Higher values of
    the mAP score indicate that our model is making accurate predictions.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 根据《*正确获取可用性：控制缺货*》([https://www.oliverwyman.com/content/dam/oliver-wyman/global/en/2014/aug/2012_CEU_POV_Getting%20Availability%20Right_ENG.pdf](https://www.oliverwyman.com/content/dam/oliver-wyman/global/en/2014/aug/2012_CEU_POV_Getting%20Availability%20Right_ENG.pdf))，缺货商品会导致严重的财务损失和客户不满。对企业和收入的影响可能非常显著。同时，收集和标注大规模真实数据对于这项任务来说是一个昂贵且耗时的过程。Neurolabs，一家专注于提供零售自动化解决方案的机器学习公司，研究了使用合成数据解决这一问题的优雅方案。他们利用Unity和自己的合成数据生成器生成了129种独特**库存单位**（**SKU**）在货架上的1,200张图像。该数据集命名为CPGDet-129，可以从以下链接下载([https://dl.orangedox.com/SampleRetailSyntheticDataset](https://dl.orangedox.com/SampleRetailSyntheticDataset))。此外，有关数据集和许可的更多详细信息，请参阅GitHub仓库([https://github.com/neurolaboratories/reshelf-detection](https://github.com/neurolaboratories/reshelf-detection))。该数据集是自动生成并标注的。此外，它专门支持目标检测任务。仅使用他们的合成数据集进行最先进的对象检测算法训练，而不使用任何真实数据，他们在真实测试数据集上实现了60%的**平均精度均值**（**mAP**）。mAP是一个指标，用于告诉我们目标检测模型在预测感兴趣对象周围的边界框时的准确性。mAP分数越高，表明我们的模型做出的预测越准确。
- en: This is a perfect example showing how synthetic data can be deployed to solve
    complex computer vision problems in practice.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个完美的例子，展示了合成数据如何在实践中解决复杂的计算机视觉问题。
- en: For more details, please refer to [https://neurolabs.medium.com/using-neurolabs-retail-specific-synthetic-dataset-in-production-bbfdd3c653d5](https://neurolabs.medium.com/using-neurolabs-retail-specific-synthetic-dataset-in-production-bbfdd3c653d5)
    and [https://www.neurolabs.ai/post/using-neurolabs-retail-specific-synthetic-dataset-in-production](https://www.neurolabs.ai/post/using-neurolabs-retail-specific-synthetic-dataset-in-production).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 更多详细信息，请参阅[https://neurolabs.medium.com/using-neurolabs-retail-specific-synthetic-dataset-in-production-bbfdd3c653d5](https://neurolabs.medium.com/using-neurolabs-retail-specific-synthetic-dataset-in-production-bbfdd3c653d5)和[https://www.neurolabs.ai/post/using-neurolabs-retail-specific-synthetic-dataset-in-production](https://www.neurolabs.ai/post/using-neurolabs-retail-specific-synthetic-dataset-in-production)。
- en: Microsoft using synthetic data alone for face analysis
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微软仅使用合成数据进行面部分析
- en: Face analysis such as face parsing and landmark localization is fundamental
    for modern industry. The applications range from security and advertising to medical
    diagnosis. Using synthetic data for face analysis seems inescapable as annotating
    real images for these tasks not only is extremely hard but also brings ethical
    and privacy issues. You can refer to [*Chapter 3*](B18494_03.xhtml#_idTextAnchor049),
    where we discussed these issues.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 面部分析，如面部解析和地标定位，对于现代工业至关重要。应用范围从安全和广告到医疗诊断。使用合成数据进行面部分析似乎不可避免，因为对这些任务标注真实图像不仅极其困难，而且还会带来伦理和隐私问题。您可以参考[*第3章*](B18494_03.xhtml#_idTextAnchor049)，其中我们讨论了这些问题。
- en: 'Microsoft is one of the pioneer companies in face recognition technologies.
    They have many years of research and development in this area. *Face API* is just
    one example ([https://azure.microsoft.com/en-gb/products/cognitive-services/face](https://azure.microsoft.com/en-gb/products/cognitive-services/face)).
    Their recent work, titled *Fake it till you make it: face analysis in the wild
    using synthetic data alone* ([https://openaccess.thecvf.com/content/ICCV2021/papers/Wood_Fake_It_Till_You_Make_It_Face_Analysis_in_the_ICCV_2021_paper.pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wood_Fake_It_Till_You_Make_It_Face_Analysis_in_the_ICCV_2021_paper.pdf)),
    is an excellent demonstration of how synthetic data can be deployed in computer
    vision.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '微软是面部识别技术领域的先驱公司之一。他们在该领域进行了多年的研发。*Face API*只是其中的一个例子([https://azure.microsoft.com/en-gb/products/cognitive-services/face](https://azure.microsoft.com/en-gb/products/cognitive-services/face))。他们最近的工作，题为*Fake
    it till you make it: face analysis in the wild using synthetic data alone*([https://openaccess.thecvf.com/content/ICCV2021/papers/Wood_Fake_It_Till_You_Make_It_Face_Analysis_in_the_ICCV_2021_paper.pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wood_Fake_It_Till_You_Make_It_Face_Analysis_in_the_ICCV_2021_paper.pdf))，是合成数据如何在计算机视觉中得到应用的绝佳展示。'
- en: The researchers in this work first procedurally generated photorealistic synthetic
    faces. They used a template face and then randomized the hair, clothes, expression,
    and, essentially, identity. They simulated these faces in random environments.
    The synthetic dataset they have generated contains 100,000 synthetic faces with
    ground-truth annotations, including 2D dense face landmarks and per-pixel face
    parts semantic segmentation.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作中的研究人员首先以程序化方式生成了逼真的合成人脸。他们使用了一个模板人脸，然后随机化了头发、衣服、表情以及本质上的人脸特征。他们在随机环境中模拟了这些人脸。他们生成的合成数据集包含带有真实值标注的10万个合成人脸，包括2D密集人脸地标和每像素人脸部分语义分割。
- en: They trained face parsing and landmark localization ML models on their generated
    synthetic data alone without using any real images. Their experimental results
    show that the trained ML models were able to achieve superior results on real
    datasets. For example, their synthetic-data-trained ML model was able to predict
    10 times more landmarks as compared to real-data-trained ML ones. They claim that
    this success is due to the superiority of their synthetic training data. They
    emphasize that it is impossible for human annotators to accurately label that
    many landmarks in practice. Additionally, they show that their synthetic data
    generation pipeline can be easily adapted to generate synthetic training data
    for other computer vision tasks, such as eye-tracking. They simply add a virtual
    eye-tracking camera and generate training images with the corresponding ground
    truth. To download the dataset, you can refer to their GitHub repository ([https://microsoft.github.io/FaceSynthetics](https://microsoft.github.io/FaceSynthetics)).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 他们仅使用他们生成的合成数据训练了人脸解析和地标定位的机器学习模型，而没有使用任何真实图像。他们的实验结果表明，训练好的机器学习模型在真实数据集上能够实现更优的结果。例如，与使用真实数据训练的机器学习模型相比，他们的合成数据训练的机器学习模型能够预测出10倍多的地标。他们声称这种成功归功于他们合成训练数据的优越性。他们强调，在实际操作中，人类标注者很难准确标注那么多的地标。此外，他们还表明，他们的合成数据生成流程可以很容易地适应生成其他计算机视觉任务（如眼动追踪）的合成训练数据。他们只需添加一个虚拟眼动追踪相机，并生成带有相应真实值的训练图像。要下载数据集，您可以参考他们的GitHub仓库([https://microsoft.github.io/FaceSynthetics](https://microsoft.github.io/FaceSynthetics))。
- en: Synthesis AI using synthetic data for virtual try-on
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用合成数据进行虚拟试穿的合成AI
- en: 'Virtual fashion is gaining more momentum because it provides a sustainable
    solution that, unlike traditional fashion, reduces cost and effort. Additionally,
    it provides a scalable and more personalized solution for companies and customers.
    Furthermore, it opens more opportunities for creativity, collaboration, and social
    impact. For this industry to flourish and achieve the intended outcomes, computer
    vision technologies need to excel at a number of tasks, such as pose estimation,
    semantic segmentation, visual object detection, and tracking. *Synthesis AI* proposed
    an elegant solution by using synthetic photorealistic 3D humans with huge variations
    in body type, gender, ethnicity, age, height, and other attributes. They were
    able to generate depth maps, surface normals, segmentation maps, and many other
    annotations. For more details, please refer to *Synthesis AI Virtual Try-on* ([https://synthesis.ai/applications/virtual-try-on](https://synthesis.ai/applications/virtual-try-on)).
    Additionally, they experimentally demonstrated the usability of the generated
    synthetic data for a number of tasks, such as face segmentation, background matting,
    and facial landmark detection. They found that fine-tuning on real data after
    pretraining on synthetic data achieves the best results as compared to training
    on real data or synthetic data alone or even a mixture of both. To explore the
    case study in more detail, please refer to *Synthetic Data Case Studies: It Just*
    *Works* ([https://synthesis.ai/2021/06/17/synthetic-data-case-studies-it-just-works](https://synthesis.ai/2021/06/17/synthetic-data-case-studies-it-just-works)).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟时尚正在获得更多动力，因为它提供了一种可持续的解决方案，与传统的时尚不同，它降低了成本和努力。此外，它为公司和客户提供了可扩展和更加个性化的解决方案。更进一步，它为创意、协作和社会影响开辟了更多机会。为了使该行业蓬勃发展并实现预期目标，计算机视觉技术需要在多个任务上表现出色，例如姿态估计、语义分割、视觉物体检测和跟踪。*合成AI*通过使用具有巨大体型、性别、种族、年龄、身高和其他属性变化的合成逼真3D人类，提出了一种优雅的解决方案。他们能够生成深度图、表面法线、分割图和许多其他注释。更多详情，请参阅*合成AI虚拟试穿*([https://synthesis.ai/applications/virtual-try-on](https://synthesis.ai/applications/virtual-try-on))。此外，他们通过实验证明了生成的合成数据在许多任务中的可用性，例如人脸分割、背景抠图和面部特征点检测。他们发现，在合成数据上预训练后，在真实数据上进行微调，与仅使用真实数据或合成数据训练，甚至两者的混合训练相比，可以达到最佳结果。要更详细地了解案例研究，请参阅*合成数据案例研究：它就是*
    *有效* ([https://synthesis.ai/2021/06/17/synthetic-data-case-studies-it-just-works](https://synthesis.ai/2021/06/17/synthetic-data-case-studies-it-just-works))).
- en: Summary
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In summary, you were introduced to various industrial applications of computer
    vision. You learned why and how computer vision is shaping the future of our modern
    industry. Moreover, you explored two case studies of companies that started to
    utilize synthetic data for their computer vision-based solutions.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 总结
- en: In the next chapter, you will delve into another set of interesting case studies
    in the field of natural language processing.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将深入探讨自然语言处理领域另一组有趣的案例研究。
