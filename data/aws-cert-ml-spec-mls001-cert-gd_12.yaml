- en: '*Chapter 9*: Amazon SageMaker Modeling'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第9章*：Amazon SageMaker建模'
- en: 'In the previous chapter, we learned several methods of model optimization and
    evaluation techniques. We also learned various ways of storing data, processing
    data, and applying different statistical approaches to data. So, how can we now
    build a pipeline for this? Well, we can read data, process data, and build machine
    learning models on the processed data. But what if my first machine learning model
    does not perform well? Can I fine-tune my model? The answer is *Yes*; you can
    perform nearly everything using Amazon SageMaker. In this chapter, we will walk
    you through the following topics using Amazon SageMaker:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了多种模型优化和评估技术的方法。我们还学习了各种存储数据、处理数据和将不同的统计方法应用于数据的方式。那么，我们如何现在构建一个管道呢？嗯，我们可以读取数据、处理数据，并在处理后的数据上构建机器学习模型。但如果我的第一个机器学习模型表现不佳怎么办？我能微调我的模型吗？答案是*是的*；你可以使用Amazon
    SageMaker执行几乎所有操作。在本章中，我们将使用Amazon SageMaker带您了解以下主题：
- en: Understanding different instances of Amazon SageMaker
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Amazon SageMaker的不同实例
- en: Cleaning and preparing data in Jupyter Notebook in Amazon SageMaker
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Amazon SageMaker的Jupyter Notebook中清理和准备数据
- en: Model training in Amazon SageMaker
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Amazon SageMaker中进行模型训练
- en: Using SageMaker's built-in machine learning algorithms
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SageMaker内置的机器学习算法
- en: Writing custom training and inference code in SageMaker
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在SageMaker中编写自定义训练和推理代码
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can download the data used in this chapter's examples from GitHub at [https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-9](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-9).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从GitHub下载本章示例中使用的数据，链接为[https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-9](https://github.com/PacktPublishing/AWS-Certified-Machine-Learning-Specialty-MLS-C01-Certification-Guide/tree/master/Chapter-9)。
- en: Creating notebooks in Amazon SageMaker
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Amazon SageMaker中创建笔记本
- en: If you're working with machine learning, then you need to perform actions such
    as storing data, processing data, preparing data for model training, model training,
    and deploying the model for inference. They are not easy, and each of these stages
    requires a machine to perform the task. With Amazon SageMaker, life becomes much
    easier when carrying out these steps.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从事机器学习工作，那么你需要执行诸如存储数据、处理数据、准备数据用于模型训练、模型训练以及将模型部署用于推理等操作。这些操作并不容易，每个阶段都需要机器来完成这些任务。使用Amazon
    SageMaker，执行这些步骤时生活变得更加简单。
- en: What is Amazon SageMaker?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是Amazon SageMaker？
- en: SageMaker provides training instances to train a model using the data and provides
    endpoint instances to infer by using the model. It also provides notebook instances,
    running Jupyter Notebooks, to clean and understand the data. If you're happy with
    your cleaning process, then you should store them in S3 as part of the staging
    for training. You can launch training instances to consume this training data
    and produce a machine learning model. The machine learning model can be stored
    in S3, and endpoint instances can consume the model to produce results for end
    users.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker提供训练实例来使用数据训练模型，并提供端点实例来使用模型进行推理。它还提供笔记本实例，运行Jupyter Notebook，以清理和理解数据。如果你对你的清理过程满意，那么你应该将它们存储在S3中，作为训练的预置部分。你可以启动训练实例来消耗这些训练数据并生成机器学习模型。机器学习模型可以存储在S3中，端点实例可以消耗模型为最终用户提供结果。
- en: 'If you draw this in a block diagram, then it will look similar to *Figure 9.1*:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将其绘制成框图，那么它将看起来类似于*图9.1*：
- en: '![Figure 9.1 – A pictorial representation of the different layers of the Amazon
    SageMaker instances'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.1 – Amazon SageMaker实例不同层的图示'
- en: '](img/B16735_09_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_09_01.jpg)'
- en: Figure 9.1 – A pictorial representation of the different layers of the Amazon
    SageMaker instances
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 – Amazon SageMaker实例不同层的图示
- en: 'Now, let''s take a look at the Amazon SageMaker console and get a better feel
    for it. Once you log in to your AWS account and go to Amazon SageMaker, you will
    see something similar to *Figure 9.2*:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看Amazon SageMaker控制台，并更好地了解它。一旦你登录到你的AWS账户并进入Amazon SageMaker，你会看到类似于*图9.2*的内容：
- en: '![Figure 9.2 – A quick look at the SageMaker console'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.2 – 快速查看SageMaker控制台'
- en: '](img/B16735_09_02.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_09_02.jpg)'
- en: Figure 9.2 – A quick look at the SageMaker console
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 – 快速查看SageMaker控制台
- en: There are three different sections, including **Notebook**, **Training**, and
    **Inference**, which have been expanded in *Figure 9.2* so that we can dive in
    and understand them better.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 文档分为三个不同的部分，包括**笔记本**、**训练**和**推理**，这些部分在*图9.2*中进行了扩展，以便我们能够深入理解。
- en: '**Notebook** has three different options that you can use:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**笔记本**有三个不同的选项可供使用：'
- en: '**Notebook instances**: This helps us to create, open, start, and stop notebook
    instances. These instances are responsible for running Jupyter Notebooks. They
    allow us to choose the instance type based on the workload of the use case. The
    best practice is to use a notebook instance to orchestrate the data pipeline for
    processing a large dataset. For example, making a call from a notebook instance
    to AWS Glue for ETL services or Amazon EMR to run Spark applications. If you''re
    asked to create a secured notebook instance outside AWS, then you need to take
    care of endpoint security, network security, launching the machine, managing storage
    on it, and managing Jupyter Notebook applications running on the instance. The
    user does not need to manage any of these with SageMaker.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**笔记本实例**：这有助于我们创建、打开、启动和停止笔记本实例。这些实例负责运行Jupyter笔记本。它们允许我们根据用例的工作负载选择实例类型。最佳实践是使用笔记本实例来编排处理大型数据集的数据管道。例如，从笔记本实例调用AWS
    Glue进行ETL服务或Amazon EMR运行Spark应用程序。如果你被要求在AWS外部创建一个安全的笔记本实例，那么你需要注意端点安全、网络安全、启动机器、管理实例上的存储以及管理实例上运行的Jupyter
    Notebook应用程序。用户不需要使用SageMaker管理任何这些。'
- en: '`pip install` or a `conda install`. However, as soon as the notebook instance
    is terminated, the customization will be lost. To avoid such a scenario, you can
    customize your notebook instance through a script provided through `/home/ec2-user/anaconda3/envs/`
    and customize the specific environment as required.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip install`或`conda install`。然而，一旦笔记本实例终止，自定义设置就会丢失。为了避免这种情况，你可以通过`/home/ec2-user/anaconda3/envs/`提供的脚本来自定义笔记本实例，并根据需要自定义特定环境。'
- en: '**Git repositories**: AWS CodeCommit, GitHub, or any other Git server can be
    associated with the notebook instance for the persistence of your notebooks. If
    access is given, then the same notebook can be used by other developers to collaborate
    and save in a source control fashion. Git repositories can either be added separately
    by using this option or they can be associated with a notebook instance during
    the creation.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Git仓库**：AWS CodeCommit、GitHub或任何其他Git服务器都可以与笔记本实例关联，以便持久化你的笔记本。如果提供了访问权限，则其他开发者可以使用相同的笔记本进行协作并以源控制方式保存。Git仓库可以通过此选项单独添加，或者可以在创建笔记本实例时与之关联。'
- en: 'As you can see in *Figure 9.2*, **Training** offers **Algorithms**, **Training
    jobs**, and **Hyperparameter tuning jobs**. Let''s understand their usage:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在*图9.2*中看到的，**训练**提供了**算法**、**训练作业**和**超参数调整作业**。让我们了解它们的用法：
- en: '**Algorithms**: This is the first step toward deciding on an algorithm that
    we are going to run on our cleaned data. You can either choose a custom algorithm
    or create a custom algorithm based on the use case. Otherwise, you can run SageMaker
    algorithms on the cleaned data.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**算法**：这是决定在清洗后的数据上运行算法的第一步。你可以选择一个自定义算法，或者根据用例创建一个自定义算法。否则，你可以在清洗后的数据上运行SageMaker算法。'
- en: '**Training jobs**: You can create training jobs from a notebook instance via
    API calls. You can set the number of instances, input the data source details,
    perform checkpoint configuration, and output data configuration. Amazon SageMaker
    manages the training instances and stores the model artifacts as output in the
    specified location. Both incremental training (that is, to train the model from
    time to time for better results) and managed spot training (that is, to reduce
    costs) can also be achieved.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练作业**：你可以通过API调用从笔记本实例创建训练作业。你可以设置实例数量，输入数据源详细信息，执行检查点配置，以及输出数据配置。Amazon
    SageMaker管理训练实例，并将模型工件作为输出存储在指定的位置。既可以实现增量训练（即，为了获得更好的结果而定期训练模型），也可以实现托管Spot训练（即，为了降低成本）。'
- en: '**Hyperparameter tuning jobs**: Usually, hyperparameters are set for an algorithm
    prior to the training process. During the training process, we let the algorithm
    figure out the best values for these parameters. With hyperparameter tuning, we
    obtain the best model that has the best value of hyperparameters. This can be
    done through a console or via API calls. The same can be orchestrated from a notebook
    instance too.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超参数调整工作**：通常，在训练过程之前，算法的超参数被设置好。在训练过程中，我们让算法找出这些参数的最佳值。通过超参数调整，我们可以获得具有最佳超参数值的最佳模型。这可以通过控制台或通过API调用完成。同样，也可以从笔记本实例中执行。'
- en: '**Inference** has many offerings and is evolving every day:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**推理**提供了许多服务，并且每天都在不断发展：'
- en: '**Compilation jobs**: If your model is trained using a machine learning framework
    such as Keras, MXNet, ONNX, PyTorch, TFLite, TensorFlow, or XGBoost, and your
    model artifacts are available on a S3 bucket, then you can choose either **Target
    device** or **Target platform**. Target device is used to deploy your model, such
    as an AWS SageMaker machine learning instance or an AWS IoT Greengrass device.
    Target platform is used to decide the operating system, architecture, and accelerator
    on which you want your model to run. You can also store the compiled module in
    your S3 bucket for future use. This essentially helps you in cross-platform model
    deployment.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编译工作**：如果你的模型使用Keras、MXNet、ONNX、PyTorch、TFLite、TensorFlow或XGBoost等机器学习框架进行训练，并且你的模型工件存储在S3桶中，那么你可以选择**目标设备**或**目标平台**。目标设备用于部署你的模型，例如AWS
    SageMaker机器学习实例或AWS IoT Greengrass设备。目标平台用于确定你希望模型运行的操作系统、架构和加速器。你还可以将编译模块存储在你的S3桶中，以供将来使用。这实际上有助于你在跨平台模型部署中。'
- en: '**Model packages**: These are used to create deployable SageMaker models. You
    can create your own algorithm, package it using the model package APIs, and publish
    it to AWS Marketplace.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型包**：这些用于创建可部署的SageMaker模型。你可以创建自己的算法，使用模型包API打包它，并将其发布到AWS Marketplace。'
- en: '**Models**: Models are created using model artifacts. They are similar to mathematical
    equations with variables; that is, you input the values for the variables and
    get an output. These models are stored in S3 and will be used for inference by
    the endpoints.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**：模型是通过模型工件创建的。它们类似于带有变量的数学方程式；也就是说，你输入变量的值，得到一个输出。这些模型存储在S3中，并将由端点用于推理。'
- en: '`VariantWeight` API to make the endpoints serve 80% of the request with the
    older model and 20% of the request with the new model. This is the most common
    production scenario where the data changes rapidly and the model needs to be trained
    and tuned periodically. Another possible use case is to test the model results
    with live data, then a certain percentage of the requests can be routed to the
    new model, and the results can be monitored to testify the accuracy of the model
    on real-time unseen data.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`VariantWeight` API可以使端点用旧模型处理80%的请求，用新模型处理20%的请求。这是数据变化迅速且模型需要定期训练和调整的最常见生产场景。另一个可能的用例是使用实时数据测试模型结果，然后可以将一定比例的请求路由到新模型，并监控结果以验证模型在实时未见数据上的准确性。'
- en: '**Endpoints**: These are used to create an URL to which the model is exposed
    and can be requested to give the model results as a response.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端点**：这些用于创建一个URL，模型可以通过该URL暴露并请求模型结果作为响应。'
- en: '`InputFilter`, `JoinSource`, `OutputFilter` APIs can be used to associate input
    records with output results.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`InputFilter`、`JoinSource`、`OutputFilter` API可以用来关联输入记录与输出结果。'
- en: Now, we have got an overview of Amazon SageMaker. Let's put our knowledge to
    work in the next section.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经对Amazon SageMaker有了概述。让我们在下一节中将我们的知识付诸实践。
- en: Important note
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 重要注意事项
- en: The Amazon SageMaker console keeps changing. There's a possibility that when
    you're reading this book, the console might look different.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker控制台在不断变化。有可能在你阅读这本书的时候，控制台的外观可能有所不同。
- en: Getting hands-on with Amazon SageMaker notebook instances
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Amazon SageMaker笔记本实例上动手实践
- en: 'The very first step, in this section, is to create a Jupyter Notebook, and
    this requires a notebook instance. Let''s start by creating a notebook instance,
    as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，第一步是创建一个Jupyter Notebook，这需要一个笔记本实例。让我们首先创建一个笔记本实例，如下所示：
- en: Sign in to your AWS account.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录您的AWS账户。
- en: Navigate to **Services** > **Amazon SageMaker**.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 **服务** > **Amazon SageMaker**。
- en: In the left navigation pane, click on **Notebook instances** and then click
    on the **Create notebook instance** button.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧导航面板中，点击 **笔记本实例**，然后点击 **创建笔记本实例** 按钮。
- en: Provide a `notebookinstance` and leave the `ml.t2.medium setting`. In the `Create
    a new role` in **IAM role**. You will be asked to specify the bucket name. For
    the purpose of this example, it's chosen as any bucket.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供一个 `notebookinstance` 并保留 `ml.t2.medium` 设置。在 **IAM 角色** 的 **创建新角色** 中。您将被要求指定存储桶名称。为了本例的目的，它被选为任何存储桶。
- en: Following the successful creation of a role, you should see something similar
    to *Figure 9.3*:![Figure 9.3 – Amazon SageMaker role creation
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在角色成功创建后，您应该看到类似于 *图 9.3* 的内容：![图 9.3 – Amazon SageMaker 角色创建
- en: '](img/B16735_09_03.jpg)'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16735_09_03.jpg)'
- en: Figure 9.3 – Amazon SageMaker role creation
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.3 – Amazon SageMaker 角色创建
- en: Leave everything else in its default setting and click on the **Create notebook
    instance** button.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其他所有设置保留为默认值，然后点击 **创建笔记本实例** 按钮。
- en: Once the instance is in the `InService` state, select the instance. Click on
    the **Actions** drop-down menu and choose **Open Jupyter**. This opens your Jupyter
    Notebook.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦实例处于 `InService` 状态，选择实例。点击 **操作** 下拉菜单并选择 **打开 Jupyter**。这将打开您的 Jupyter Notebook。
- en: Now, we are all set to run our Jupyter Notebook on the newly created instance.
    We will perform **Exploratory Data Analysis** (**EDA**) and plot different types
    of graphs to visualize the data. Once we are familiar with the Jupyter Notebook,
    we will build some models to predict house prices in Boston. We will apply the
    algorithms that we have learned in previous chapters and compare them to find
    the best model that offers the best prediction according to our data. Let's dive
    in.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好在新建的实例上运行我们的 Jupyter Notebook。我们将执行 **探索性数据分析** (**EDA**) 并绘制不同类型的图表来可视化数据。一旦我们熟悉了
    Jupyter Notebook，我们将构建一些模型来预测波士顿的房价。我们将应用之前章节中学到的算法，并将它们进行比较，以找到根据我们的数据提供最佳预测的最佳模型。让我们开始吧。
- en: 'In the Jupyter Notebook, click on **New** and select **Terminal**. Run the
    following commands in Command Prompt to download the codes to the instance:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Jupyter Notebook 中，点击 **新建** 并选择 **终端**。在命令提示符中运行以下命令以将代码下载到实例：
- en: '[PRE0]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once the Git repository is cloned to the SageMaker notebook instance, type `exit`
    into Command Prompt to quit. Now, your code is ready to execute.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦 Git 仓库被克隆到 SageMaker 笔记本实例，在命令提示符中输入 `exit` 以退出。现在，您的代码已准备好执行。
- en: Navigate to `Chapter-9` in the Jupyter Notebook's **Files** section, as shown
    in *Figure 9.4*:![Figure 9.4 – Jupyter Notebook
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Jupyter Notebook 的 **文件** 部分导航到 `Chapter-9`，如图 *9.4* 所示：![图 9.4 – Jupyter
    Notebook
- en: '](img/B16735_09_04.jpg)'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16735_09_04.jpg)'
- en: Figure 9.4 – Jupyter Notebook
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.4 – Jupyter Notebook
- en: Click on the first notebook in *1.*`Boston-House-Price-SageMaker-Notebook-Instance-Example.ipynb`.
    It will prompt you to choose the kernel for the notebook. Please select `conda_python3`,
    as shown in *Figure 9.5*:![Figure 9.5 – Jupyter Notebook kernel selection
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 *1.* 中的第一个笔记本 `Boston-House-Price-SageMaker-Notebook-Instance-Example.ipynb`。它将提示您选择笔记本的内核。请选择
    `conda_python3`，如图 *9.5* 所示：![图 9.5 – Jupyter Notebook 内核选择
- en: '](img/B16735_09_05.jpg)'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16735_09_05.jpg)'
- en: Figure 9.5 – Jupyter Notebook kernel selection
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.5 – Jupyter Notebook 内核选择
- en: From the notebook, navigate to **Kernel** > **Restart & Clear Output**. Click
    on the play icon to run the cells one after another. Please ensure you have run
    each individual cell and inspect the output from each execution/run.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从笔记本中导航到 **内核** > **重启 & 清除输出**。点击播放图标依次运行单元格。请确保您已运行每个单独的单元格并检查每个执行/运行的输出。
- en: You can experiment by adding cells and deleting cells to familiarize yourself
    with the Jupyter Notebook operations. In one of the paragraphs, there is a bash
    command that allows you to install the `xgboost` libraries from the notebook.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过添加和删除单元格来实验，以便熟悉 Jupyter Notebook 的操作。在其中一个段落中，有一个 bash 命令允许您从笔记本中安装 `xgboost`
    库。
- en: The final cell explains how we have compared the different scores of various
    modeling techniques to draw a conclusion mathematically. *Figure 9.6* clearly
    shows that the best model to predict house prices in Boston is XGBoost:![Figure
    9.6 – Comparing the models
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个单元格解释了我们是怎样比较不同建模技术的不同分数来得出数学结论的。*图 9.6* 清楚地显示了预测波士顿房价的最佳模型是 XGBoost：![图
    9.6 – 比较模型
- en: '](img/B16735_09_06.jpg)'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16735_09_06.jpg)'
- en: Figure 9.6 – Comparing the models
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.6 – 比较模型
- en: Once you've completed the execution of this notebook, please feel free to shut
    down the kernel and stop your notebook instance from the SageMaker console. This
    is the best practice to save on cost.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您完成此笔记本的执行，请随时从 SageMaker 控制台关闭内核并停止您的笔记本实例。这是节省成本的最佳实践。
- en: In the next hands-on section, we will familiarize ourselves with Amazon SageMaker's
    training and inference instances. We will also use the Amazon SageMaker API to
    make this process easier. We will use the same notebook instance as we did in
    the previous example.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节的实际操作中，我们将熟悉 Amazon SageMaker 的训练和推理实例。我们还将使用 Amazon SageMaker API 使此过程更简单。我们将使用与之前示例相同的笔记本实例。
- en: Getting hands-on with Amazon SageMaker's training and inference instances
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亲身体验 Amazon SageMaker 的训练和推理实例
- en: 'In this section, we will learn about training a model and hosting the model
    to generate predicted results. Let''s dive in by using the notebook instance from
    the previous example:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何训练模型并将模型托管以生成预测结果。让我们通过使用之前示例中的笔记本实例来深入了解：
- en: Sign in to your AWS account at [https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/notebook-instances](https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/notebook-instances).
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 [https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/notebook-instances](https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/notebook-instances)
    登录您的 AWS 账户。
- en: Click on `InService`, open it in a new tab, as shown in *Figure 9.7*:![Figure
    9.7 – The InService instance
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `InService`，在新标签页中打开它，如图 *图 9.7* 所示：![图 9.7 – InService 实例
- en: '](img/B16735_09_07.jpg)'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B16735_09_07.jpg]'
- en: Figure 9.7 – The InService instance
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.7 – InService 实例
- en: Navigate to the tab named SageMaker Examples in the Jupyter Notebook home page.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Jupyter Notebook 主页中导航到名为 SageMaker 示例的标签页。
- en: Select the `k_nearest_neighbors_covtype.ipynb` notebook. Click on **Use** and
    create a copy.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 `k_nearest_neighbors_covtype.ipynb` 笔记本。点击 **使用** 并创建一个副本。
- en: When you run the following paragraph, as shown n *Figure 9.8*, you can also
    check a training job in **Training** > **Training jobs** of the SageMaker home
    page:![Figure 9.8 – The SageMaker fit API call
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当您运行以下段落，如图 n *图 9.8* 所示时，您还可以在 SageMaker 主页的 **训练** > **训练作业** 中检查一个训练作业：![图
    9.8 – SageMaker fit API 调用
- en: '](img/B16735_09_08.jpg)'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B16735_09_08.jpg]'
- en: Figure 9.8 – The SageMaker fit API call
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.8 – SageMaker fit API 调用
- en: The training job looks similar to *Figure 9.9*. It launches an ECS container
    in the backend and uses the IAM execution role created in the previous example
    to run the training job for this request:![Figure 9.9 – Training obs
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练作业看起来类似于 *图 9.9*。它在后端启动一个 ECS 容器，并使用在先前的示例中创建的 IAM 执行角色为此请求运行训练作业：![图 9.9
    – 训练 obs
- en: '](img/B16735_09_09.jpg)'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B16735_09_09.jpg]'
- en: Figure 9.9 – Training obs
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.9 – 训练 obs
- en: If you go inside and check the logs in CloudWatch, it gives you more details
    about the containers and the steps they performed. As a machine learning engineer,
    it's worth going in and checking the CloudWatch metrics for Algorithm.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您进入并检查 CloudWatch 中的日志，它会为您提供有关容器及其执行步骤的更多详细信息。作为一名机器学习工程师，进入并检查 CloudWatch
    的 Algorithm 指标是值得的。
- en: Now, if you run the following paragraph, as shown in *Figure 9.10*, in the notebook,
    then it will create an endpoint configuration and an endpoint where the model
    from the earlier training job is deployed.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，如果您在笔记本中运行以下段落，如图 *图 9.10* 所示，那么它将创建一个端点配置和一个端点，其中部署了早期训练作业中的模型。
- en: I have changed the instance type to save on cost. It is the instance or the
    machine that will host your model. Please choose your instance wisely. We will
    learn about choosing instance types in the next section. I have also changed `endpoint_name`
    so that it can be recognized easily:![Figure 9.10 – Creating the predictor object
    with endpoint details
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我已将实例类型更改为节省成本。这是将托管您的模型的实例或机器。请明智地选择您的实例。我们将在下一节中学习如何选择实例类型。我还已更改 `endpoint_name`
    以便易于识别：![图 9.10 – 使用端点详细信息创建预测对象
- en: '](img/B16735_09_010.jpg)'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B16735_09_010.jpg]'
- en: Figure 9.10 – Creating the predictor object with endpoint details
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.10 – 使用端点详细信息创建预测对象
- en: Navigate to **Inference** > **Endpoints**. This will show you the endpoint that
    was created as a result of the previous paragraph execution. This endpoint has
    a configuration and can be navigated and traced through **Inference** > **Endpoint
    Configurations**.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 **推理** > **端点**。这将显示由上一段执行创建的端点。此端点具有配置，可以通过 **推理** > **端点配置** 进行导航和跟踪。
- en: If you view the **Inference** section in the notebook, you will notice that
    it uses the test data to predict results. It uses the predictor object from the
    SageMaker API to make predictions. The predictor object contains the endpoint
    details, model name, and instance type.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您在笔记本中查看**推理**部分，您会注意到它使用测试数据来预测结果。它使用SageMaker API的预测器对象进行预测。预测器对象包含端点详情、模型名称和实例类型。
- en: The API call to the endpoint occurs in the **Inference** section, and it is
    authenticated via the IAM role with which the notebook instance is created. The
    same API calls can be traced through CloudWatch invocation metrics.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 端点的API调用发生在**推理**部分，并且通过创建笔记本实例时使用的IAM角色进行身份验证。相同的API调用可以通过CloudWatch调用指标进行追踪。
- en: Finally, running the `delete_endpoint` method in the notebook will delete the
    endpoint. To delete the endpoint configurations, navigate to **Inference** > **Endpoint
    Configurations** and select the configuration on the screen. Click on **Actions**
    > **Delete** > **Delete**.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在笔记本中运行`delete_endpoint`方法将删除端点。要删除端点配置，请导航到**推理** > **端点配置**并选择屏幕上的配置。点击**操作**
    > **删除** > **删除**。
- en: Now, please feel free to shut down the kernel and stop your notebook instance
    from the SageMaker console. This is the best practice to save on cost.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，请随意关闭内核并从SageMaker控制台停止您的笔记本实例。这是节省成本的最佳实践。
- en: In this section, we learned about using the notebook instance, training instances,
    inference endpoints, and endpoint configurations to clean our data, train models,
    and generate predicted results from them. In the next section, we will learn about
    model tuning.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何使用笔记本实例、训练实例、推理端点和端点配置来清理我们的数据、训练模型以及从它们生成预测结果。在下一节中，我们将学习模型调整。
- en: Model tuning
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型调整
- en: In [*Chapter 8*](B16735_08_Final_VK_ePub.xhtml#_idTextAnchor162), *Evaluating
    and Optimizing Models*, you learned many important concepts about model tuning.
    Let's now explore this topic from a practical perspective.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第8章*](B16735_08_Final_VK_ePub.xhtml#_idTextAnchor162)，“评估和优化模型”，您学习了关于模型调整的许多重要概念。现在，让我们从实际的角度来探讨这个话题。
- en: 'In order to tune a model on SageMaker, we have to call `create_hyper_parameter_tuning_job`
    and pass the following main parameters:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在SageMaker上调整模型，我们必须调用`create_hyper_parameter_tuning_job`并传递以下主要参数：
- en: '`HyperParameterTuningJobName`: This is the name of the tuning job. It is useful
    to track the training jobs that have been started on behalf of your tuning job.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HyperParameterTuningJobName`: 这是调整作业的名称。这对于跟踪代表您的调整作业已启动的训练作业很有用。'
- en: '`HyperParameterTuningJobConfig`: Here, you can configure your tuning options.
    For example, which parameters you want to tune, the range of values for them,
    the type of optimization (such as random search or Bayesian search), the maximum
    number of training jobs you want to spin up, and more.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HyperParameterTuningJobConfig`: 在这里，您可以配置您的调整选项。例如，您想要调整哪些参数，它们的值范围，优化的类型（例如随机搜索或贝叶斯搜索），您想要启动的最大训练作业数量，等等。'
- en: '`TrainingJobDefinition`: Here, you can configure your training job. For example,
    the data channels, the output location, the resource configurations, the evaluation
    metrics, and the stop conditions.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TrainingJobDefinition`: 在这里，您可以配置您的训练作业。例如，数据通道、输出位置、资源配置、评估指标和停止条件。'
- en: In SageMaker, the main metric that we want to use to evaluate the models to
    select the best one is known as an **objective metric**.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在SageMaker中，我们想要用来评估模型并选择最佳模型的主要指标被称为**目标指标**。
- en: In the following example, we are configuring `HyperParameterTuningJobConfig`
    for a decision tree-based algorithm. We want to check the best configuration for
    a **max_depth** hyperparameter, which is responsible for controlling the depth
    of the tree.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们正在为基于决策树的算法配置`HyperParameterTuningJobConfig`。我们想要检查**max_depth**超参数的最佳配置，该参数负责控制树的深度。
- en: 'In `IntegerParameterRanges`, we have to specify the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在`IntegerParameterRanges`中，我们必须指定以下内容：
- en: The hyperparameter name
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数名称
- en: The minimum value that we want to test
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要测试的最小值
- en: The maximum value that we want to test
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要测试的最大值
- en: Important note
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要注意事项
- en: Each type of hyperparameter must fit in one of the parameter ranges sections,
    such as categorical, continuous, or integer parameters.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每种超参数类型必须适合参数范围部分之一，例如分类、连续或整数参数。
- en: In `ResourceLimits`, we are specifying the number of training jobs along with
    the number of parallel jobs that we want to run. Remember that the goal of the
    tuning process is to execute many training jobs with different hyperparameter
    settings. This is so that the best one will be selected for the final model. That's
    why we have to specify these training job execution rules.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `ResourceLimits` 中，我们指定了要运行的训练作业数量以及并行作业的数量。请记住，调优过程的目标是执行具有不同超参数设置的多个训练作业，以便从中选择最佳的一个用于最终模型。这就是为什么我们必须指定这些训练作业执行规则。
- en: 'We then set up our search strategy in `Strategy` and, finally, set up the objective
    function in `HyperParameterTuningJobObjective`:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们然后在 `Strategy` 中设置我们的搜索策略，最后在 `HyperParameterTuningJobObjective` 中设置目标函数：
- en: '[PRE1]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The second important configuration we need to set is `TrainingJobDefinition`.
    Here, we have to specify all the details regarding the training jobs that will
    be executed. One of the most important settings is the `TrainingImage` setting,
    which refers to the container that will be started to execute the training processes.
    This container, as expected, must have your training algorithm implemented.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要设置的第二个重要配置是 `TrainingJobDefinition`。在这里，我们必须指定将要执行的训练作业的所有详细信息。最重要的设置之一是
    `TrainingImage` 设置，它指的是将启动以执行训练过程的容器。正如预期的那样，这个容器必须实现你的训练算法。
- en: 'Here, we present an example of a built-in algorithm, **eXtreme Gradient Boosting**,
    so that you can set the training image as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们提供了一个内置算法的示例，**eXtreme Gradient Boosting**，以便你可以按照以下方式设置训练镜像：
- en: '[PRE2]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, you can go ahead and set your training definitions:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以继续设置你的训练定义：
- en: '[PRE3]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we have to specify the data input configuration, which is also known
    as the data channels. In the following section of code, we are setting up two
    data channels – train and validation:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须指定数据输入配置，这通常称为数据通道。在下面的代码部分，我们正在设置两个数据通道 – 训练和验证：
- en: '[PRE4]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We also need to specify where the results will be stored:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要指定结果将存储的位置：
- en: '[PRE5]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, we set the resource configurations, roles, static parameters, and
    stopping conditions. In the following section of code, we want to use two instances
    of type `ml.c4.2xlarge` with 10 GB of storage:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们设置了资源配置、角色、静态参数和停止条件。在下面的代码部分，我们想要使用两个类型为 `ml.c4.2xlarge` 且具有 10 GB 存储的实例：
- en: '[PRE6]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Important note
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Please note that we are using other variables in this configuration file, `bucket`
    and `prefix`, which should be replaced by your bucket name and prefix key (if
    needed), respectively. We are also referring to `s3_input_train` and `s3_input_validation`,
    which are two variables that point to the train and validation datasets in S3.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在这个配置文件中使用了其他变量，`bucket` 和 `prefix`，分别应该替换为你的存储桶名称和前缀键（如果需要）。我们还引用了 `s3_input_train`
    和 `s3_input_validation`，这两个变量指向 S3 中的训练和验证数据集。
- en: 'Once you have set your configurations, you can spin up the tuning process:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你设置了配置，你就可以启动调优过程：
- en: '[PRE7]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Next, let's find out how to track the execution of this process.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们了解一下如何跟踪此过程的执行。
- en: Tracking your training jobs and selecting the best model
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟踪训练作业和选择最佳模型
- en: 'Once you have started the tuning process, there are two additional steps that
    you might want to check: tracking the process of tuning and selecting the winner
    model (that is, the one with the best set of hyperparameters).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你开始了调优过程，你可能还想检查两个额外的步骤：跟踪调优过程和选择最佳模型（即具有最佳超参数集的模型）。
- en: 'In order to find your training jobs, you should go to the SageMaker console
    and navigate to **Hyperparameter training jobs**. You will then find a list of
    executed tuning jobs, including yours:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到你的训练作业，你应该前往 SageMaker 控制台，导航到 **超参数训练作业**。然后，你会找到一个已执行调优作业的列表，包括你的作业：
- en: '![Figure 9.11 – Finding your tuning job'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.11 – 找到你的调优作业'
- en: '](img/B16735_09_011.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16735_09_011.jpg]'
- en: Figure 9.11 – Finding your tuning job
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.11 – 找到你的调优作业
- en: 'If you access your tuning job, by clicking under its name, you will find a
    summary page, which includes the most relevant information regarding the tuning
    process. Under the **Training jobs** tab, you will see all of the training jobs
    that have been executed:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你通过点击其名称访问你的调优作业，你将找到一个摘要页面，其中包含有关调优过程的最相关信息。在 **训练作业** 选项卡下，你会看到所有已执行的训练作业：
- en: '![Figure 9.12 – Summary of the training jobs in the tuning process'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.12 – 调优过程中的训练作业摘要'
- en: '](img/B16735_09_012.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16735_09_012.jpg]'
- en: Figure 9.12 – Summary of the training jobs in the tuning process
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.12 – 调优过程中训练作业的总结
- en: 'Finally, if you click on the **Best training job** tab, you will find the best
    set of hyperparameters for your model, including a handy button to create a new
    model based on those best hyperparameters that have just been found:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果你点击**最佳训练作业**标签页，你将找到适合你模型的最佳超参数集，包括一个方便的按钮，可以根据刚刚找到的最佳超参数创建一个新模型：
- en: '![Figure 9.13 – Finding the best set of hyperparameters'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.13 – 寻找最佳超参数集](img/B16735_09_013.jpg)'
- en: '](img/B16735_09_013.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ']'
- en: Figure 9.13 – Finding the best set of hyperparameters
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.13 – 寻找最佳超参数集
- en: As you can see, SageMaker is very intuitive, and once you know the main concepts
    behind model optimization, playing with SageMaker should be easier. By now, we
    have understood how to use SageMaker for our specific needs. In the next section,
    we will explore how to select the instance type for various use cases and the
    security of our notebooks.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，SageMaker 非常直观，一旦你了解了模型优化的主要概念，使用 SageMaker 应该会更容易。到目前为止，我们已经了解了如何根据我们的特定需求使用
    SageMaker。在下一节中，我们将探讨如何为各种用例选择实例类型以及笔记本的安全性。
- en: Choosing instance types in Amazon SageMaker
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Amazon SageMaker 中选择实例类型
- en: SageMaker is a pay-for-usage model. There is no minimum fee for it.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 是一种按使用付费的模式。它没有最低费用。
- en: When we think about instances on SageMaker, it all starts with an EC2 instance.
    This instance is responsible for all your processing. It's a managed EC2 instance.
    These instances won't show up in the EC2 console and cannot be SSHed either. The
    instance type starts with `ml`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑 SageMaker 上的实例时，一切始于一个 EC2 实例。这个实例负责你所有的处理。这是一个托管的 EC2 实例。这些实例不会出现在 EC2
    控制台中，也不能通过 SSH 访问。实例类型以 `ml` 开头。
- en: 'SageMaker offers instances of the following families:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 提供以下系列的实例：
- en: 'The **t** family: This is a burstable CPU family. With this family, you get
    a normal ratio of CPU and memory. This means that if you have a long-running training
    job, then you lose performance over time as you spend the CPU credits. If you
    have very small jobs, then they are cost-effective. For example, if you want a
    notebook instance to launch training jobs, then this family is the most relevant
    and cost-effective.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**t** 系列族：这是一个可扩展 CPU 系列。使用这个系列，你得到正常的 CPU 和内存比例。这意味着如果你有一个长时间运行的训练作业，那么随着时间的推移，由于你花费了
    CPU 信用额度，你的性能会下降。如果你有非常小的作业，那么它们是成本效益的。例如，如果你想启动一个笔记本实例来运行训练作业，那么这个系列是最相关和成本效益的。'
- en: 'The **m** family: In the previous family, we saw that CPU credits are consumed
    faster due to their burstable nature. If you have a long-running machine learning
    job that requires constant throughput, then this is the right family. It comes
    with a similar CPU and memory ratio as the **t** family.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**m** 系列族：在之前的系列中，我们看到了由于它们的可扩展性，CPU 信用额度消耗得更快。如果你有一个需要恒定吞吐量的长时间运行的机器学习作业，那么这就是正确的系列。它提供了与
    **t** 系列类似的 CPU 和内存比例。'
- en: 'The **r** family: This is a memory-optimized family. *When do we need this?*
    Well, imagine a use case where you have to load the data in memory and do some
    data engineering on the data. In this scenario, you will require more memory and
    your job will be memory-optimized.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**r** 系列族：这是一个内存优化的系列族。*我们何时需要这个？* 好吧，想象一个需要将数据加载到内存中并对数据进行一些数据工程用例。在这种情况下，你需要更多的内存，你的工作将是内存优化的。'
- en: 'The **c** family: **c** family instances are compute-optimized. This is a requirement
    for jobs that need higher compute power and less memory to store the data. If
    you refer to the following table, C5.2x large has 8 vCPU and 16 GiB memory, which
    makes it compute-optimized with less memory. For example, a use case needs to
    be tested on a fewer number of records and it is compute savvy, then this instance
    family is the to-go option to get some sample records from a huge dataframe and
    test your algorithm.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**c** 系列族：**c** 系列实例是计算优化的。这是需要更高计算能力和较少内存来存储数据的工作的要求。如果你参考以下表格，C5.2x large
    有 8 个 vCPU 和 16 GiB 内存，这使得它具有较少内存的计算优化。例如，一个用例需要在较少的记录上进行测试，并且它很擅长计算，那么这个实例系列就是从巨大的数据框中获取一些样本记录并测试你的算法的最佳选择。'
- en: 'The **p** family: This is a GPU family that supports accelerated computing
    jobs such as training and inference. Notably, **p** family instances are ideal
    for handling large, distributed training jobs, and this leads to less time required
    to train. As a result, this becomes cost-effective. The P3/P3dn GPU compute instance
    can go up to 1 petaFLOP per second compute with up to 256 GB of GPU memory and
    100 Gbps (gigabits) of networking with 8x NVIDIA v100 GPUs. They are highly optimized
    for training and are not fully utilized for inference.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**p**系列：这是一个支持加速计算作业（如训练和推理）的GPU系列。值得注意的是，**p**系列实例非常适合处理大型、分布式训练作业，这导致训练时间减少。因此，这变得具有成本效益。P3/P3dn
    GPU计算实例的每秒计算能力可达1 petaFLOP，配备高达256 GB的GPU内存和100 Gbps（千兆比特）的联网速度，使用8x NVIDIA v100
    GPU。它们高度优化于训练，并不完全用于推理。'
- en: 'The **g** family: For cost-effective, small-scale training jobs, **g** family
    GPU instances are ideal. G4 has the lowest cost per inference for GPU instances.
    It uses T4 NVIDIA GPUs. The G4 GPU compute instance goes up to 520 TeraFLOPs of
    compute time with 8x NVIDIA T4 GPUs. This instance family is the best for simple
    networks.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**g**系列：对于成本效益高、小规模训练作业，**g**系列GPU实例是理想的。G4具有GPU实例中最低的推理成本。它使用T4 NVIDIA GPU。G4
    GPU计算实例的算力可达520万亿次，配备8x NVIDIA T4 GPU。这个实例系列最适合简单网络。'
- en: 'In the following table, 2x large instance types have been taken from each family
    for a visual comparison between the CPU and memory ratio:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下表格中，每个系列都选取了2x大型实例类型，以便于比较CPU和内存比率：
- en: '![Table 9.1 – A table showing the CPU and memory ratio of different instance
    types'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '![Table 9.1 – A table showing the CPU and memory ratio of different instance
    types]'
- en: '](img/B16735_09_Table_1.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16735_09_Table_1.jpg]'
- en: Table 9.1 – A table showing the CPU and memory ratio of different instance types
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.1 – 一个显示不同实例类型CPU和内存比率的表格
- en: Important note
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: To remember this easily, you can think of T for Tiny, M for Medium, C for Compute,
    and P and G for GPU. CPU family instance types are T, M, R, and C. GPU family
    instance types are P and G.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于记忆，你可以将T视为Tiny（小型），M视为Medium（中型），C视为Compute（计算），P和G视为GPU。CPU系列实例类型是T、M、R和C。GPU系列实例类型是P和G。
- en: Choosing the right instance type for a training job
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择训练作业的正确实例类型
- en: There is no rule of thumb to decide the instance type that you require. It changes
    based on the size of the data, the complexity of the network, the machine learning
    algorithm, and several other factors such as time and cost. Asking the right question
    will save money and make it cost-effective.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 没有决定所需实例类型的经验法则。它根据数据的大小、网络的复杂性、机器学习算法以及时间、成本等其他因素而变化。提出正确的问题将节省金钱并使其具有成本效益。
- en: If the deciding factor is *Instance Size*, then classifying the problem for
    CPU or GPU is the right step. Once that is done, then it is good to consider whether
    it can be multi-GPU or multi-CPU. That would solve your question about distributed
    training. This also solves your *Instance Count* factor. If it's compute-intensive,
    then it would be wise to check the memory requirements too.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果决定因素是*实例大小*，那么将问题分类为CPU或GPU是正确的步骤。一旦这样做，那么考虑是否可以多GPU或多CPU就很好了。这将解决你的分布式训练问题。这也解决了你的*实例数量*因素。如果是计算密集型，那么检查内存需求也是明智的。
- en: The next deciding factor is *Instance Family*. The right questions here would
    be, *Is it optimized for time and cost?* In the previous step, we have already
    figured out the problem to be solved in either the CPU or GPU, and this narrows
    down the selection process. Now, let's learn about inference jobs.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个决定因素是*实例系列*。这里正确的问题应该是，“它是为了时间和成本优化的吗？”在前一步中，我们已经确定了要解决的问题是在CPU还是GPU上，这缩小了选择过程。现在，让我们了解推理作业。
- en: Choosing the right instance type for an inference job
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择推理作业的正确实例类型
- en: The majority of the cost and complexity of machine learning in production is
    inference. Usually, inference runs on a single input in real time. They are usually
    less compute/memory-intensive. They have to be highly available as they run all
    the time and serve the end user requests or are integrated as part of an application.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中，机器学习的成本和复杂性主要在于推理。通常，推理在实时运行单个输入。它们通常计算/内存密集度较低。由于它们一直运行并服务于最终用户请求或作为应用程序的一部分集成，因此它们必须高度可用。
- en: You can choose any of the instance types that we learned about recently based
    on the workload. Other than that, AWS has **Inf1** and **Elastic Inference** type
    instances for inference. Elastic inference allows you to attach a fraction of
    a GPU instance to any CPU instance.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以根据工作负载选择我们最近了解到的任何实例类型。除此之外，AWS还提供**Inf1**和**Elastic Inference**类型的实例用于推理。Elastic
    Inference允许您将GPU实例的一部分附加到任何CPU实例上。
- en: Let's look at an example where an application is integrated with inference jobs,
    then the requirement of CPU and memory for the application is different from the
    inference jobs. For those use cases, you need to choose the right instance type
    and size. In such scenarios, it is good to have a separation between your application
    fleets and inference fleets. This might require some management. If such management
    is a problem for your requirement, then choose elastic inference, where both the
    application and inference jobs can be colocated. This means that you can host
    multiple models on the same fleet, and you can load all of these different models
    on different accelerators in memory and concurrent requests can be served.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个示例，其中应用程序与推理作业集成，那么应用程序对CPU和内存的需求与推理作业不同。对于这些用例，您需要选择正确的实例类型和大小。在这种情况下，在您的应用程序集群和推理集群之间保持分离是好的。这可能需要一些管理。如果这种管理对您的需求来说是个问题，那么选择弹性推理，其中应用程序和推理作业可以放置在一起。这意味着您可以在同一集群上托管多个模型，并且您可以在内存中的不同加速器上加载所有这些不同的模型，并且可以同时处理并发请求。
- en: It's always recommended that you run some examples in a lower environment before
    deciding on your instance types and family in the production environment. In the
    next section, we will dive into and understand the different ways of securing
    our Amazon SageMaker notebooks.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定生产环境中的实例类型和家族之前，始终建议您在较低的环境中运行一些示例。在下一节中，我们将深入了解并理解保护我们的Amazon SageMaker笔记本的不同方法。
- en: Securing SageMaker notebooks
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护SageMaker笔记本
- en: 'If you are reading this section of the chapter, then you have already learned
    how to use notebook instances, which type of training instances should be chosen,
    and how to configure and use endpoints. Now, let''s learn about securing those
    instances. The following aspects will help to secure the instances:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在阅读本章的这一部分，那么您已经学习了如何使用笔记本实例，应该选择哪种类型的训练实例，以及如何配置和使用端点。现在，让我们学习如何保护这些实例。以下方面将有助于保护实例：
- en: '**Encryption**: When we say or think about securing via encryption, then it
    is all about the data. But what does this mean? It means protecting data at rest
    using encryption, protecting data in transit with encryption, and using KMS for
    better role separation and internet traffic privacy through TLS 1.2 encryption.
    SageMaker instances can be launched with encrypted volumes by using an AWS-managed
    KMS key. This helps you to secure the Jupyter Notebook server by default.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加密**：当我们说或想到通过加密来保护时，这完全是关于数据。但这意味着什么？这意味着使用加密保护静态数据，使用加密保护传输中的数据，并使用KMS通过TLS
    1.2加密更好地进行角色分离和互联网流量隐私。可以使用AWS管理的KMS密钥启动加密卷的SageMaker实例。这有助于您默认保护Jupyter Notebook服务器。'
- en: '`RootAccess` field to `Disabled` when you call `CreateNotebookInstance` or
    `UpdateNotebookInstance`. The data scientist will have access to their user space
    and can install Python packages. However, they cannot sudo into the root user
    and make changes to the operating system.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您调用`CreateNotebookInstance`或`UpdateNotebookInstance`时，将`RootAccess`字段设置为`Disabled`。数据科学家将能够访问他们的用户空间并安装Python包。然而，他们不能sudo进入root用户并更改操作系统。
- en: '**IAM role**: During the launch of a notebook instance, it is necessary to
    create an IAM role for execution or to use an existing role for execution. This
    is used to launch the service-managed EC2 instance with an instance profile associated
    with the role. This role will restrict the API calls based on the policies attached
    to this role.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IAM角色**：在启动笔记本实例时，创建一个IAM角色用于执行或使用现有的角色进行执行是必要的。这用于启动与角色关联的实例配置文件的服务管理EC2实例。此角色将根据附加到该角色的策略限制API调用。'
- en: '**VPC connection**: When you launch a SageMaker notebook instance, by default,
    it gets created within the SageMaker Service Account, which has a service-managed
    VPC, and it will, by default, have access to the internet via an internet gateway,
    and that gateway is managed by the service. If you are only dealing with AWS-related
    services, then it is recommended that you launch a SageMaker notebook instance
    in your VPC within a private subnet and with a well-customized security group.
    The AWS services can be invoked or used from this notebook instance via VPC endpoints
    attached to that VPC. The best practice is to control them via endpoint policies
    for better API controls. This ensures the restriction on data egress outside your
    VPC and secured environment. In order to capture all the network traffic, you
    can turn on the VPC flow logs, which can be monitored and tracked via CloudWatch.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VPC 连接**：当您启动 SageMaker 笔记本实例时，默认情况下，它将在 SageMaker 服务账户中创建，该账户拥有服务管理的 VPC，并且默认情况下将通过互联网网关访问互联网，该网关由服务管理。如果您只处理
    AWS 相关的服务，那么建议您在您的 VPC 私有子网中启动 SageMaker 笔记本实例，并使用一个精心定制的安全组。您可以通过连接到该 VPC 的 VPC
    端点从该笔记本实例调用或使用 AWS 服务。最佳实践是通过端点策略来控制它们，以实现更好的 API 控制。这确保了数据流出您 VPC 和安全环境的外部限制。为了捕获所有网络流量，您可以开启
    VPC 流量日志，这些日志可以通过 CloudWatch 进行监控和跟踪。'
- en: '`EnableNetworkIsolation` parameter to `True` when you are calling `CreateTrainingJob`,
    `CreateHyperParameterTuningJob`, or `CreateModel`. Network isolation can be used
    along with the VPC, which ensures that containers cannot make any outbound network
    calls.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在调用 `CreateTrainingJob`、`CreateHyperParameterTuningJob` 或 `CreateModel` 时，将
    `EnableNetworkIsolation` 参数设置为 `True`。网络隔离可以与 VPC 一起使用，这确保了容器不能进行任何出站网络调用。
- en: '**Connecting a private network to your VPC**: You can launch your SageMaker
    notebook instance inside the private subnet of your VPC. This can access data
    from your private network by communicating to the private network, which can be
    done by connecting your private network to your VPC by using Amazon VPN or AWS
    Direct Connect.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将私有网络连接到您的 VPC**：您可以在您的 VPC 私有子网中启动您的 SageMaker 笔记本实例。这样可以通过与私有网络通信来访问您的私有网络数据，这可以通过使用
    Amazon VPN 或 AWS Direct Connect 将您的私有网络连接到您的 VPC 来实现。'
- en: In this section, we learned about several ways in which we can secure our SageMaker
    notebooks. In the next section, we will learn about creating SageMaker pipelines
    with Lambda Functions.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了多种保护我们的 SageMaker 笔记本的方法。在下一节中，我们将学习如何使用 Lambda 函数创建 SageMaker 管道。
- en: Creating alternative pipelines with Lambda Functions
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Lambda 函数创建替代管道
- en: Indeed, SageMaker is an awesome platform that you can use to create training
    and inference pipelines. However, we can always work with different services to
    come up with similar solutions. One of these services that we will learn about
    next is known as **Lambda Functions**.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，SageMaker 是一个很棒的平台，您可以使用它来创建训练和推理管道。然而，我们总是可以与不同的服务合作，提出类似的解决方案。我们接下来将要了解的一种服务被称为
    **Lambda 函数**。
- en: AWS Lambda is a serverless compute service where you can literally run a function
    as a service. In other words, you can concentrate your efforts on just writing
    your function. Then, you just need to tell AWS how to run it (that is, the environment
    and resource configurations), so all the necessary resources will be provisioned
    to run your code and then discontinued once it is completed.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda 是一种无服务器计算服务，您可以在其中将一个函数作为服务运行。换句话说，您可以将精力集中在仅编写您的函数上。然后，您只需告诉 AWS
    如何运行它（即环境和服务配置），所有必要的资源都将配置以运行您的代码，并在完成后取消配置。
- en: Throughout [*Chapter 6*](B16735_06_Final_VK_ePub.xhtml#_idTextAnchor115), *AWS
    Services for Data Processing*, you explored how Lambda Functions integrate with
    many different services, such as Kinesis and AWS Batch. Indeed, AWS did a very
    good job of integrating Lambda with 140 services (and the list is constantly increasing).
    That means that when you are working with a specific AWS service, you will remember
    that it is likely to integrate with Lambda.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第 6 章*](B16735_06_Final_VK_ePub.xhtml#_idTextAnchor115) *数据处理 AWS 服务* 中，您探讨了
    Lambda 函数如何与许多不同的服务集成，例如 Kinesis 和 AWS Batch。事实上，AWS 在将 Lambda 与 140 个服务（且列表持续增加）集成方面做得非常好。这意味着当您与特定的
    AWS 服务合作时，您会记得它很可能与 Lambda 集成。
- en: It is important to bear this in mind because Lambda Functions can really expand
    your possibilities to create scalable and integrated architectures. For example,
    you can trigger a Lambda Function when a file is uploaded to S3 in order to preprocess
    your data before loading it to Redshift. Alternatively, you can create an API
    that triggers a Lambda Function at each endpoint execution. Again, the possibilities
    are endless with this powerful service.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这很重要，因为 Lambda 函数真的可以扩大你创建可扩展和集成架构的可能性。例如，你可以在文件上传到 S3 时触发 Lambda 函数，以便在将其加载到
    Redshift 之前预处理数据。或者，你可以创建一个 API，在每个端点执行时触发 Lambda 函数。再次强调，这个强大的服务可能性无限。
- en: It is also useful to know that you can write your function in different programming
    languages, such as Node.js, Python, Go, Java, and more. Your function does not
    necessarily have to be triggered by another AWS service, that is, you can trigger
    it manually for your web or mobile application, for example.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 还有用处的是，你知道你可以用不同的编程语言编写你的函数，例如 Node.js、Python、Go、Java 等。你的函数不一定要由另一个 AWS 服务触发，也就是说，你可以手动触发它，例如用于你的网页或移动应用程序。
- en: When it comes to deployment, you can upload your function as a ZIP file or as
    a container image. Although this is not ideal for an automated deployment process,
    coding directly into the AWS Lambda console is also possible.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到部署时，你可以将你的函数作为 ZIP 文件或容器镜像上传。虽然这不适合自动化部署过程，但直接在 AWS Lambda 控制台中编码也是可能的。
- en: 'As with any other service, this one also has some downsides that you should
    be aware of:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何其他服务一样，这个服务也有一些你应该知道的缺点：
- en: 'Memory allocation for your function: This is from 128 MB to 10,240 MB (AWS
    has recently increased this limit from 3 GB to 10 GB, as stated previously).'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为你的函数分配的内存：这是从 128 MB 到 10,240 MB（AWS 最近已将此限制从 3 GB 增加到 10 GB，如前所述）。
- en: 'Function timeout: This is a maximum of 900 seconds (15 minutes).'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数超时：这是最多 900 秒（15 分钟）。
- en: 'Function layer: This is a maximum of 5 layers.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数层：这是最多 5 层。
- en: 'Burst concurrency: This is from 500 to 3,000, depending on the region.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爆发并发：这取决于地区，从 500 到 3,000。
- en: 'Deployment package size: This is 250 MB unzipped, including layers.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署包大小：这是 250 MB 解压后的大小，包括层。
- en: 'Container image code package size: This is 10 GB.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器镜像代码包大小：这是 10 GB。
- en: 'Available space in the `/tmp` directory: This is 512 MB.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/tmp` 目录的可用空间：这是 512 MB。'
- en: Before going for Lambda Functions, make sure these restrictions fit your use
    case. Bringing Lambda Functions closer to your scope of alternative pipelines
    for SageMaker, one potential use of Lambda is to create inference pipelines for
    our models.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试 Lambda 函数之前，请确保这些限制适合你的用例。将 Lambda 函数与 SageMaker 的替代管道范围更接近，Lambda 的一种潜在用途是为我们的模型创建推理管道。
- en: As you know, SageMaker has a very handy `.deploy()` method that will create
    endpoints for model inference. This is so that you can call to pass the input
    data in order to receive predictions back. Here, we can create this inference
    endpoint by using the API gateway and Lambda Functions.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，SageMaker 有一个非常方便的 `.deploy()` 方法，它将为模型推理创建端点。这样，你可以调用它来传递输入数据，以便接收预测结果。在这里，我们可以通过使用
    API 网关和 Lambda 函数来创建这个推理端点。
- en: In case you don't need an inference endpoint and you just want to make predictions
    and store results somewhere (in a batch fashion), then all we need is a Lambda
    Function, which is able to fetch the input data, instantiate the model object,
    make predictions, and store the results in the appropriated location. Of course,
    it does this by considering all the limitations that we have discussed earlier.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不需要推理端点，只想进行预测并将结果存储在某个地方（批量方式），那么我们需要的只是一个 Lambda 函数，它能够获取输入数据，实例化模型对象，进行预测，并将结果存储在适当的位置。当然，它是通过考虑我们之前讨论的所有限制来做到这一点的。
- en: Alright, now that we have a good background about Lambda and some use cases,
    let's take a look at the most important configurations that we should be aware
    of for the exam.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们已经对 Lambda 和一些用例有了很好的了解，让我们来看看我们应该在考试中注意的最重要配置。
- en: Creating and configuring a Lambda Function
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建和配置 Lambda 函数
- en: First of all, you should know that you can create a Lambda Function in different
    ways, such as via the AWS CLI (Lambda API reference), the AWS Lambda console,
    or even deployment frameworks (for example, *the serverless framework*).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你应该知道你可以用不同的方式创建 Lambda 函数，例如通过 AWS CLI（Lambda API 参考）、AWS Lambda 控制台，甚至是部署框架（例如，*无服务器框架*）。
- en: Serverless frameworks are usually provider and programming language-independent.
    In other words, they usually allow you to choose where you want to deploy a serverless
    infrastructure from a variate list of cloud providers and programming languages.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器框架通常是供应商和编程语言无关的。换句话说，它们通常允许你从一系列云提供商和编程语言中选择你想要部署无服务器基础设施的位置。
- en: Important note
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'The concept of serverless architecture is not specific to AWS. In fact, many
    cloud providers offer other services that are similar to AWS Lambda Functions.
    That''s why these serverless frameworks have been built: to help developers and
    engineers to deploy their services, wherever they want, including AWS. This is
    unlikely to come up in your exam, but it is definitely something that you should
    know so that you are aware of different ways in which to solve your challenges
    as a data scientist or data engineer.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器架构的概念并不仅限于 AWS。实际上，许多云提供商提供与其他 AWS Lambda 函数类似的服务。这就是为什么构建了这些无服务器框架：帮助开发者和工程师将他们的服务部署到他们想要的地方，包括
    AWS。这可能在你的考试中不会出现，但它绝对是你应该知道的事情，这样你就可以意识到作为数据科学家或数据工程师解决挑战的不同方式。
- en: Since we want to pass the AWS Machine Learning Specialty exam, here, we have
    taken the approach to walk through the AWS Lambda console. This is so that you
    will become more familiar with their interface and the most important configuration
    options.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们想要通过 AWS 机器学习专业考试，因此在这里我们采取了遍历 AWS Lambda 控制台的方法。这样做是为了让你更熟悉他们的界面和最重要的配置选项。
- en: 'When you navigate to the Lambda console and request a new Lambda Function,
    AWS will provide you with some starting options:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当你导航到 Lambda 控制台并请求一个新的 Lambda 函数时，AWS 将为你提供一些起始选项：
- en: 'Author from scratch: This is if you want to create your function from scratch.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从零开始：如果你想要从头开始创建你的函数。
- en: 'Use a blueprint: This is if you want to create your function from a sample
    code and configuration preset for common use cases.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用蓝图：如果你想要从示例代码和配置预设的常见用例中创建你的函数。
- en: 'Container image: This is if you want to select a container image to deploy
    your function.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器镜像：如果你想要选择一个容器镜像来部署你的函数。
- en: 'Browse serverless app repository: This is if you want to deploy a sample Lambda
    application from the AWS Serverless Application Repository.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 浏览无服务器应用程序存储库：如果你想要从 AWS 无服务器应用程序存储库部署一个示例 Lambda 应用程序。
- en: 'Starting from scratch, the next step is to set up your Lambda configurations.
    AWS splits these configurations between basic and advanced settings. In the basic
    configuration, you will set your function name, runtime environment, and permissions.
    *Figure 9.14* shows these configurations:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 从零开始，下一步是设置你的 Lambda 配置。AWS 将这些配置分为基本和高级设置。在基本配置中，你将设置你的函数名称、运行时环境和权限。*图 9.14*
    展示了这些配置：
- en: '![Figure 9.14 – Creating a new Lambda Function from the AWS Lambda console'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.14 – 从 AWS Lambda 控制台创建新的 Lambda 函数]'
- en: '](img/B16735_09_014.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16735_09_014.jpg]'
- en: Figure 9.14 – Creating a new Lambda Function from the AWS Lambda console
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.14 – 从 AWS Lambda 控制台创建新的 Lambda 函数]'
- en: 'Here, we have a very important configuration that you should remember during
    your exam: the **execution role**. Your Lambda Function might need permissions
    to access other AWS resources, such as S3, Redshift, and more. The execution role
    grants permissions to your Lambda Function so that it can access resources as
    needed.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有一个在考试期间你应该记住的非常重要的配置：**执行角色**。你的 Lambda 函数可能需要访问其他 AWS 资源的权限，例如 S3、Redshift
    等。执行角色授予你的 Lambda 函数所需的权限，以便它可以根据需要访问资源。
- en: You have to remember that your VPC and security group configurations will also
    interfere with how your Lambda Function runs. For example, if you want to create
    a function that needs internet access to download something, then you have to
    deploy this function in a VPC with internet access. The same logic applies to
    other resources, such as access to relational databases, Kinesis, Redshift, and
    more.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须记住，你的 VPC 和安全组配置也会影响你的 Lambda 函数的运行方式。例如，如果你想创建一个需要互联网访问来下载内容的函数，那么你必须在这个有互联网访问的
    VPC 中部署这个函数。同样的逻辑也适用于其他资源，例如访问关系型数据库、Kinesis、Redshift 等。
- en: Furthermore, in order to properly configure a Lambda Function, we have to, at
    least, write its code, set the execution role, and make sure the VPC and security
    group configurations match our needs. Next, let's take a look at other configurations.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了正确配置Lambda函数，我们至少需要编写其代码，设置执行角色，并确保VPC和安全组配置符合我们的需求。接下来，让我们看看其他配置。
- en: Completing your configurations and deploying a Lambda Function
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完成你的配置并部署Lambda函数
- en: Once your Lambda is created in the AWS console, you can set additional configurations
    before deploying the function. One of these configurations is the event trigger.
    As we mentioned earlier, your Lambda Function can be triggered from a variety
    of services or even manually.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你在AWS控制台中创建了Lambda，你可以在部署函数之前设置额外的配置。其中之一就是事件触发器。如我们之前提到的，你的Lambda函数可以从各种服务触发，甚至可以手动触发。
- en: Important note
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: A very common example of a trigger is **Event Bridge**. This is an AWS service
    where you can schedule the execution of your function.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常常见的触发器示例是**事件桥接**。这是一个AWS服务，你可以在这里安排你的函数执行。
- en: Depending on the event trigger you choose, your function will have access to
    different event metadata. For example, if your function is triggered by a **PUT**
    event on S3 (for example, someone uploads a file to a particular S3 bucket), then
    your function will receive the metadata associated with this event, for example,
    bucket name and object key. Other types of triggers will give you different types
    of event metadata!
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你选择的触发器类型，你的函数将能够访问不同的事件元数据。例如，如果你的函数是由S3上的**PUT**事件触发的（例如，有人上传文件到特定的S3存储桶），那么你的函数将接收到与该事件相关的元数据，例如存储桶名称和对象键。其他类型的触发器将提供不同类型的事件元数据！
- en: 'You have access to those metadata through the event parameter that belongs
    to the signature of the entry point of your function. Not clear enough? OK, let''s
    see how your function code should be declared, as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过属于你函数入口点签名的event参数访问这些元数据。不够清楚吗？好吧，让我们看看你的函数代码应该如何声明，如下所示：
- en: '[PRE8]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, `lambda_handler` is the method that represents the entry point of your
    function. When it is triggered, this method will be called, and it will receive
    the event metadata associated with the event trigger (through the `event` parameter).
    That's how you have access to the information associated with the underlying event
    that has triggered your function! The `event` parameter is a JSON-like object.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`lambda_handler` 是代表你的函数入口点的方法。当它被触发时，这个方法将被调用，并且它将通过 `event` 参数接收与事件触发相关的事件元数据。这就是你如何访问与触发你的函数的底层事件相关的信息！`event`
    参数是一个类似JSON的对象。
- en: If you want to test your function, but you don't want to trigger it directly
    from the underlying event, that is no problem; you can use **test events**. They
    simulate the underlying event by preparing a JSON object that will be passed to
    your function.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要测试你的函数，但又不想直接从底层事件触发它，那没问题；你可以使用**测试事件**。它们通过准备一个将被传递给函数的JSON对象来模拟底层事件。
- en: '*Figure 9.15* shows a very intuitive example. Let''s suppose you have created
    a function that is triggered when a user uploads a file to S3 and now you want
    to test your function. You can either upload a file to S3 (which forces the trigger)
    or create a test event.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9.15* 展示了一个非常直观的例子。假设你创建了一个函数，当用户上传文件到S3时会触发该函数，现在你想要测试你的函数。你可以上传一个文件到S3（这将强制触发器）或者创建一个测试事件。'
- en: 'By creating a test event, you can prepare a JSON object that simulates the
    S3-put event and then pass this object to your function:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 通过创建一个测试事件，你可以准备一个模拟S3-put事件的JSON对象，然后将此对象传递给你的函数：
- en: '![Figure 9.15 – Creating a test event from the Lambda console'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.15 – 从Lambda控制台创建测试事件'
- en: '](img/B16735_09_015.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_09_015.jpg)'
- en: Figure 9.15 – Creating a test event from the Lambda console
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.15 – 从Lambda控制台创建测试事件
- en: 'Another type of configuration you can set is an **environment variable**, which
    will be available on your function. *Figure 9.16* shows how to add environment
    variables in a Lambda Function:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以设置的一种配置类型是**环境变量**，这些变量将在你的函数中可用。*图9.16* 展示了如何在Lambda函数中添加环境变量：
- en: '![Figure 9.16 – Adding environment variables to a Lambda Function'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.16 – 向Lambda函数添加环境变量'
- en: '](img/B16735_09_016.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_09_016.jpg)'
- en: Figure 9.16 – Adding environment variables to a Lambda Function
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.16 – 向Lambda函数添加环境变量
- en: 'You can always come back to these basic configurations to make adjustments
    as necessary. *Figure 9.17* shows what you will find in the basic configurations
    section:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以随时返回这些基本配置进行必要的调整。*图9.17*显示了基本配置部分的内容：
- en: '![Figure 9.17 – Changing the basic configurations of a Lambda Function'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.17 – 修改Lambda函数的基本配置](img/B16735_09_017.jpg)'
- en: '](img/B16735_09_017.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.17 – 修改Lambda函数的基本配置](img/B16735_09_017.jpg)'
- en: Figure 9.17 – Changing the basic configurations of a Lambda Function
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.17 – 修改Lambda函数的基本配置
- en: In terms of monitoring, by default, Lambda Functions produce a **CloudWatch**
    Logs stream and standard metrics. You can access log information by navigating
    through your Lambda Function monitoring section and clicking on *View logs in
    CloudWatch*.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在监控方面，Lambda函数默认会生成一个**CloudWatch**日志流和标准指标。您可以通过浏览Lambda函数监控部分并点击“在CloudWatch中查看日志”来访问日志信息。
- en: In CloudWatch, each Lambda Function will have a **Log group** and, inside that
    Log group, many **Log streams**. Log streams store the execution logs of the associated
    function. In other words, a log stream is a sequence of logs that share the same
    source, which, in this case, is your Lambda Function. A log group is a group of
    log streams that share the same retention, monitoring, and access control settings.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在CloudWatch中，每个Lambda函数都将有一个**日志组**，在该日志组内部有许多**日志流**。日志流存储相关函数的执行日志。换句话说，日志流是一系列共享相同来源的日志，在这种情况下，来源是您的Lambda函数。日志组是一组共享相同保留、监控和访问控制设置的日志流。
- en: We are reaching the end of this section, but not the end of this topic on Lambda
    Functions. As we mentioned earlier, this AWS service has a lot of use cases and
    integrates with many other services. In the next section, we will take a look
    at another AWS service that will help us to orchestrate executions of Lambda Functions.
    These are known as **AWS Step Functions**.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将结束本节，但还没有结束关于Lambda函数的主题。正如我们之前提到的，这项AWS服务有很多用例，并与许多其他服务集成。在下一节中，我们将探讨另一个AWS服务，它将帮助我们编排Lambda函数的执行。这些被称为**AWS
    Step Functions**。
- en: Working with Step Functions
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与Step Functions一起工作
- en: Step Functions is an AWS service that allows you to create workflows in order
    to orchestrate the execution of Lambda Functions. This is so that you can connect
    them in a sort of event sequence, known as **steps**. These steps are grouped
    in a **state machine**.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Step Functions是AWS的一项服务，允许您创建工作流程以编排Lambda函数的执行。这样，您可以按事件序列将它们连接起来，这些序列被称为**步骤**。这些步骤被分组在一个**状态机**中。
- en: Step Functions incorporates retry functionality so that you can configure your
    pipeline to proceed only after a particular step has succeeded. The way you set
    these retry configurations is by creating a **retry policy**.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: Step Functions集成了重试功能，这样您就可以配置您的管道仅在特定步骤成功后继续执行。您设置这些重试配置的方式是创建一个**重试策略**。
- en: Important note
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Just like the majority of AWS services, AWS Step Functions also integrates with
    other services, not only AWS Lambda.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 就像AWS的大多数服务一样，AWS Step Functions也与其他服务集成，而不仅仅是AWS Lambda。
- en: Creating a state machine is relatively simple. All you have to do is navigate
    to the AWS Step Functions console, then create a new state machine. On the *Create
    state machine* page, you can specify whether you want to create your state machine
    from scratch, from a template, or whether you just want to run a sample project.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 创建状态机相对简单。您只需导航到AWS Step Functions控制台，然后创建一个新的状态机。在“创建状态机”页面上，您可以指定您是否想从头开始创建状态机、从模板创建，或者只是运行一个示例项目。
- en: AWS will help you with this state machine creation, so even if you choose to
    create it from scratch, you will find code snippets for a variate list of tasks,
    such as AWS Lambda invocation, SNS topic publication, running Athena queries,
    and more.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: AWS将帮助您创建状态机，因此即使您选择从头开始创建，您也会找到用于各种任务的代码片段，例如AWS Lambda调用、SNS主题发布、运行Athena查询等。
- en: 'For the sake of demonstration, we will create a very simple, but still helpful,
    example of how to use Step Functions to execute a Lambda Function with the retry
    option activated:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示，我们将创建一个非常简单但仍然有用的示例，说明如何使用带有重试选项激活的Step Functions执行Lambda函数：
- en: '[PRE9]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the preceding example, we created a state machine with two steps:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们创建了一个包含两个步骤的状态机：
- en: 'Invoke Lambda function: This will start the execution of your underlying Lambda.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用Lambda函数：这将启动底层Lambda的执行。
- en: 'Example: This is a simple pass task just to show you how to connect a second
    step in the pipeline.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例：这是一个简单的传递任务，只是为了向您展示如何在管道中连接第二个步骤。
- en: 'In the first step, we have also set up a retry policy, which will try to re-execute
    this task if there are any failures. We are setting up the interval (in seconds)
    to try again and to show here the number of attempts. *Figure 9.18* shows the
    state machine:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，我们还设置了一个重试策略，如果出现任何失败，它将尝试重新执行此任务。我们设置间隔（以秒为单位）以再次尝试，并在此显示尝试次数。*图9.18*显示了状态机：
- en: '![Figure 9.18 – The state machine'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.18 – 状态机'
- en: '](img/B16735_09_018.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_09_018.jpg)'
- en: Figure 9.18 – The state machine
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.18 – 状态机
- en: We have now reached the end of this section and the end of this chapter. Next,
    let's summarize what we have learned.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经到达了这个部分和这一章的结尾。接下来，让我们总结一下我们学到了什么。
- en: Summary
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the usage of SageMaker for creating notebook
    instances and training instances. As we went through we learned how to use SageMaker
    for hyperparameter tuning jobs. As the security of our assets in AWS is an essential
    part, we learned about the various ways to secure SageMaker instances. With hands-on
    practices, we created Step Functions and orchestrated our pipeline using AWS Lambda.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用SageMaker创建笔记本实例和训练实例。随着我们的学习，我们学习了如何使用SageMaker进行超参数调整作业。由于我们资产在AWS的安全性是至关重要的，我们学习了各种保护SageMaker实例的方法。通过动手实践，我们创建了步骤函数，并使用AWS
    Lambda编排我们的管道。
- en: AWS products are evolving every day to help us solve our IT problems. It's not
    easy to remember all the product names. The only way to learn is through practice.
    When you're solving a problem or building a product, then focus on the different
    technological areas of your product. Those areas can be an AWS service, for example,
    scheduling jobs, logging, tracing, monitoring metrics, autoscaling, and more.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 每天都有AWS产品在不断发展，帮助我们解决IT问题。记住所有产品名称并不容易。唯一的学习方式是通过实践。当您解决问题或构建产品时，请专注于您产品的不同技术领域。这些领域可以是AWS服务，例如，安排作业、日志记录、跟踪、监控指标、自动扩展等。
- en: Compute time, storage, and networking are the baselines. It is recommended that
    you practice some examples for each of these services. Referring to the AWS documentation
    for clarifying any doubts is also the best option. It is always important to design
    your solutions in a cost-effective way, so exploring the cost-effective way to
    use these services is equally important as building the solution. I wish you all
    the best!
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 计算时间、存储和网络是基础。建议您为每个服务练习一些示例。参考AWS文档以澄清任何疑问也是最佳选择。始终重要的是以经济高效的方式设计您的解决方案，因此探索使用这些服务的经济高效方式与构建解决方案同样重要。祝大家一切顺利！
- en: Questions
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: Which of the following models are supervised algorithms? Select two options.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪些模型是监督算法？选择两个选项。
- en: A. Clustering
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. 聚类
- en: B. Classification
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. 分类
- en: C. Association rule mining
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: C. 关联规则挖掘
- en: D. Regression
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: D. 回归
- en: You would like to turn your Amazon SageMaker machine learning models and endpoints
    into customer-facing applications. You decide to put these on a single web server
    that can be accessed by customers via a browser. However, you realize that the
    web server is not inherently scalable; if it receives a lot of traffic, it could
    run out of CPU or memory. How can you make this approach more scalable and secure?
    Select three answers.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您希望将您的Amazon SageMaker机器学习模型和端点转换为面向客户的应用程序。您决定将这些放在一个可以通过浏览器访问的单个Web服务器上。然而，您意识到Web服务器本身不具有可扩展性；如果它收到大量流量，可能会耗尽CPU或内存。您如何使这种方法更具可扩展性和安全性？选择三个答案。
- en: A. Create an IAM role, so the webserver can access the SageMaker endpoints.
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. 创建IAM角色，以便Web服务器可以访问SageMaker端点。
- en: B. Deploy a load balancer and set up autoscaling.
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. 部署负载均衡器并设置自动扩展。
- en: C. Make all customers IAM users so that they can access SageMaker.
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: C. 将所有客户都设置为IAM用户，以便他们可以访问SageMaker。
- en: D. Keep the operating system and language runtimes for the web server patch
    secured.
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: D. 保持Web服务器的操作系统和语言运行时安全更新。
- en: For the preceding situation, what would be a better AWS service to automate
    server and operating system maintenance, capacity provisioning, and automatic
    scaling?
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于前述情况，哪个AWS服务更适合自动化服务器和操作系统维护、容量配置和自动扩展？
- en: A. AWS Lambda
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. AWS Lambda
- en: B. AWS Fargate
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. AWS Fargate
- en: C. AWS ELB
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: C. AWS ELB
- en: Amazon SageMaker is a fully managed service that enables you to quickly and
    easily integrate machine learning-based models into your applications. It also
    provides services such as notebook, training, and endpoint instances to help you
    get the job done.
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Amazon SageMaker 是一项完全托管的服务，它使您能够快速轻松地将基于机器学习的模型集成到您的应用程序中。它还提供笔记本、训练和端点实例等服务，以帮助您完成任务。
- en: A. TRUE
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. 正确
- en: B. FALSE
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. 错误
- en: 'Chose three correct statements from the following:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下陈述中选择三个正确的：
- en: A. Notebook instances clean and understand data.
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. 笔记本实例清理和理解数据。
- en: B. Training instances use data to train the model.
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. 训练实例使用数据来训练模型。
- en: C. Endpoint instances use models to produce inferences.
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: C. 端点实例使用模型进行推理。
- en: D. Notebook instances clean, understand, and build models.
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: D. 笔记本实例清理、理解和构建模型。
- en: E. Training instances are used to predict results.
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: E. 训练实例用于预测结果。
- en: What is the first step of creating a notebook?
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建笔记本的第一步是什么？
- en: A. Give it a name.
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. 给它一个名字。
- en: B. Choose a kernel.
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. 选择一个核。
- en: C. Starting developing code in paragraph format.
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: C. 以段落格式开始编写代码。
- en: Linear learner and XGBoost algorithms can be used in supervised learning models
    such as regression and classification.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性学习者和 XGBoost 算法可用于监督学习模型，如回归和分类。
- en: A. TRUE
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. 正确
- en: B. FALSE
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. 错误
- en: Which of these statements about hyperparameter tuning is true?
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于超参数调整的以下哪个陈述是正确的？
- en: A. Hyperparameter tuning is a guaranteed way to improve your model.
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: A. 超参数调整是提高您模型的一种保证方法。
- en: B. Hyperparameter tuning does not require any input values.
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: B. 超参数调整不需要任何输入值。
- en: C. Hyperparameter tuning uses regression to choose the best value to test.
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: C. 超参数调整使用回归来选择最佳测试值。
- en: D. Hyperparameter tuning is an unsupervised machine learning regression problem.
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: D. 超参数调整是一个无监督的机器学习回归问题。
- en: Answers
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 答案
- en: 1\. B and D
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. B 和 D
- en: 2\. A, B, and D
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. A, B, 和 D
- en: 3\. A
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. A
- en: 4\. A
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. A
- en: 5\. A, B, and C
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. A, B, 和 C
- en: 6\. B
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 6\. B
- en: 7\. A
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 7\. A
- en: 8\. C
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 8\. C
