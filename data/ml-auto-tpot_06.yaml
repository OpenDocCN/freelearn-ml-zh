- en: '*Chapter 4*: Exploring Classification with TPOT'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第4章*：使用TPOT探索分类'
- en: In this chapter, you'll continue going through hands-on examples of automated
    machine learning. You will learn how to handle classification tasks with TPOT
    in an automated manner by going through three complete datasets.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将继续学习自动化机器学习的实际示例。你将通过三个完整的数据集，学习如何以自动化的方式使用TPOT处理分类任务。
- en: We will cover essential topics such as dataset loading, cleaning, necessary
    data preparation, and exploratory data analysis. Then, we'll dive deep into classification
    with TPOT. You will learn how to train and evaluate automated classification models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖如数据集加载、清理、必要的数据准备和探索性数据分析等基本主题。然后，我们将深入探讨使用TPOT的分类。你将学习如何训练和评估自动化分类模型。
- en: Before training models automatically, you will see how good models can be obtained
    with basic classification algorithms, such as logistic regression. This model
    will serve as the baseline that TPOT needs to outperform.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动训练模型之前，你将看到如何通过基本分类算法，如逻辑回归，获得良好的模型。这个模型将作为TPOT需要超越的基准。
- en: 'This chapter will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Applying automated classification modeling to the Iris dataset
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将自动化分类建模应用于Iris数据集
- en: Applying automated classification modeling to the Titanic dataset
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将自动化分类建模应用于Titanic数据集
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: To complete this chapter, You will need to have Python and TPOT installed in
    your computer with Python and TPOT installed. Refer to [*Chapter 2*](B16954_02_Final_SK_ePub.xhtml#_idTextAnchor036),
    *Deep Dive into TPOT*, for detailed instructions on environment setup. If the
    concept of classification is entirely new to you, refer to [*Chapter 1*](B16954_01_Final_SK_ePub.xhtml#_idTextAnchor014),
    *Machine Learning and the Idea of Automation*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成本章，你需要在计算机上安装Python和TPOT。有关环境设置的详细说明，请参阅[*第2章*](B16954_02_Final_SK_ePub.xhtml#_idTextAnchor036)，*深入TPOT*。如果你对分类的概念完全陌生，请参阅[*第1章*](B16954_01_Final_SK_ePub.xhtml#_idTextAnchor014)，*机器学习和自动化思想*。
- en: 'You can download the source code and dataset for this chapter here: [https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter04](https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter04)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在此处下载本章的源代码和数据集：[https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter04](https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter04)
- en: Applying automated classification models to the iris dataset
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将自动化分类模型应用于Iris数据集
- en: Let's start simple, with one of the most basic datasets out there – the Iris
    dataset ([https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set)).
    The challenge here won't be to build an automated model but to build a model that
    can outperform the baseline model. The Iris dataset is so simple that even the
    most basic classification algorithm can achieve high accuracy.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从最基础的、最基本的数据集之一——Iris数据集([https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set))开始。这里的挑战不是构建一个自动化模型，而是构建一个能够超越基准模型的模型。Iris数据集如此简单，以至于即使是最基本的分类算法也能达到高准确率。
- en: 'Because of that, you should focus on getting the classification basics down
    in this section. You''ll have enough time to worry about performance later:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个原因，你应该在这个部分专注于掌握分类的基础知识。你将有足够的时间担心性能问题：
- en: As with the regression section, the first thing you should do is import the
    required libraries and load the dataset. You'll need `n``umpy`, `pandas`, `matplotlib`,
    and `seaborn` for starters. The `matplotlib.rcParams` module is imported to tweak
    the default stylings.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与回归部分一样，你应该做的第一件事是导入所需的库并加载数据集。一开始你需要`n`umpy`、`pandas`、`matplotlib`和`seaborn`。导入`matplotlib.rcParams`模块以调整默认样式。
- en: 'Here''s the code snippet for library imports and dataset loading:'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是库导入和数据集加载的代码片段：
- en: '[PRE0]'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'And here is the output returned by the `head()` function:'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是`head()`函数返回的输出：
- en: '![Figure 4.1 – Head of the Iris dataset'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.1 – Iris数据集的头部'
- en: '](img/B16954_04_01.jpg)'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_01.jpg)'
- en: Figure 4.1 – Head of the Iris dataset
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.1 – Iris数据集的头部
- en: Great – just what we need to get started.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 太好了——这正是我们开始所需的。
- en: 'The next step is to check if data quality is good enough to be passed to a
    machine learning algorithm. The first step here is to check for missing values.
    The following code snippet does just that:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是检查数据质量是否足够好，可以传递给机器学习算法。这里的第一个步骤是检查缺失值。以下代码片段正是这样做的：
- en: '[PRE1]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output is shown in the following figure:'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示在以下图中：
- en: '![Figure 4.2 – Missing value counts per column for the Iris dataset'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.2 – 爱丽丝数据集每列缺失值计数'
- en: '](img/B16954_04_02.jpg)'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_04_02.jpg)'
- en: Figure 4.2 – Missing value counts per column for the Iris dataset
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.2 – 爱丽丝数据集每列缺失值计数
- en: There seem to be no missing values, so we can proceed.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 看起来没有缺失值，因此我们可以继续。
- en: Let's now check for class distribution in the target variable. This refers to
    the number of instances belonging to each class – `setosa`, `virginica`, and `versicolor`,
    in this case. Machine learning models are known to perform poorly if a severe
    class imbalance is present.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来检查目标变量的类别分布。这指的是属于每个类别的实例数量——在这个例子中是`setosa`、`virginica`和`versicolor`。已知如果存在严重的类别不平衡，机器学习模型的表现会较差。
- en: 'The following code snippet visualizes the class distribution:'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段可视化类别分布：
- en: '[PRE2]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The visualization is shown in the following figure:'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可视化显示在以下图中：
- en: '![Figure 4.3 – Iris dataset target variable distribution'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.3 – 爱丽丝数据集目标变量分布'
- en: '](img/B16954_04_03.jpg)'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_04_03.jpg)'
- en: Figure 4.3 – Iris dataset target variable distribution
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.3 – 爱丽丝数据集目标变量分布
- en: The Iris dataset is as nice as they come – so once again, nothing for us to
    do preparation-wise.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 爱丽丝数据集非常完美——所以，在准备方面，我们再次没有什么可做的。
- en: The final step in the data exploratory analysis and preparation is to check
    for correlation. A high correlation between features typically means there's some
    redundancy in the dataset, at least to a degree.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据探索分析和准备的最后一步是检查相关性。特征之间的高度相关性通常意味着数据集中存在一些冗余，至少在某种程度上。
- en: 'The following code snippet plots a correlation matrix with annotations:'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段绘制了一个带有注释的相关矩阵：
- en: '[PRE3]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The correlation matrix is shown in the following figure:'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相关矩阵显示在以下图中：
- en: '![Figure 4.4 – Correlation matrix of the Iris dataset'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.4 – 爱丽丝数据集的相关矩阵'
- en: '](img/B16954_04_04.jpg)'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_04_04.jpg)'
- en: Figure 4.4 – Correlation matrix of the Iris dataset
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.4 – 爱丽丝数据集的相关矩阵
- en: As expected, there's a strong correlation between most of the features.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如预期的那样，大多数特征之间存在强烈的关联。
- en: You're now familiar with the Iris dataset, which means we can move on to modeling
    the next.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，你已经熟悉了爱丽丝数据集，这意味着我们可以继续进行建模。
- en: Let's build a baseline model with a logistic regression algorithm first. It
    will serve as a starting model that TPOT needs to outperform.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们使用逻辑回归算法构建一个基线模型。它将作为一个起始模型，TPOT需要超越它。
- en: 'The first step in the process is the train/test split. The following code snippet
    does just that, and it also prints the number of instances in both sets:'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该过程的第一步是训练/测试集划分。下面的代码片段正是这样做的，并且还打印了两个集合中的实例数量：
- en: '[PRE4]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The number of instances is shown in the following figure:'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实例数量显示在以下图中：
- en: '![Figure 4.5 – Number of instances in train and test sets'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.5 – 训练集和测试集中的实例数量'
- en: '](img/B16954_04_05.jpg)'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_04_05.jpg)'
- en: Figure 4.5 – Number of instances in train and test sets
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.5 – 训练集和测试集中的实例数量
- en: Let's build the baseline model next.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，让我们构建基线模型。
- en: 'As mentioned earlier, we''ll use logistic regression for the job. The code
    snippet below fits a logistic regression model, makes the predictions on the test
    set, and prints a confusion matrix of actual and predicted values:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，我们将使用逻辑回归来完成这项工作。下面的代码片段拟合了一个逻辑回归模型，在测试集上进行了预测，并打印了实际值和预测值的混淆矩阵：
- en: '[PRE5]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The corresponding confusion matrix is shown in the following figure:'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相应的混淆矩阵显示在以下图中：
- en: '![Figure 4.6 – Logistic regression confusion matrix for the Iris dataset'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.6 – 爱丽丝数据集的逻辑回归混淆矩阵'
- en: '](img/B16954_04_06.jpg)'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_04_06.jpg)'
- en: '[PRE6]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The accuracy score is shown in the following image:'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 准确率得分显示在以下图像中：
- en: '![Figure 4.7 – Accuracy on the test set with logistic regression for the Iris
    dataset'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.7 – 使用逻辑回归在爱丽丝数据集测试集上的准确率'
- en: '](img/B16954_04_07.jpg)'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_04_07.jpg)'
- en: Figure 4.7 – Accuracy on the test set with logistic regression for the Iris
    dataset
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.7 – 使用逻辑回归在爱丽丝数据集测试集上的准确率
- en: And there you have it – 97% accuracy and only a single misclassification out
    of the box, with the simplest classification algorithm. Let's see if TPOT can
    outperform that next.
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如此一来——97%的准确率，并且只有一个错误分类，这是使用最简单的分类算法。让我们看看TPOT是否能在下一步超越它。
- en: 'Let''s build an automated classification model next. We''ll optimize for accuracy
    and train for 10 minutes – similar to what we did in [*Chapter 3*](B16954_03_Final_SK_ePub.xhtml#_idTextAnchor051),
    *Exploring Regression with TPOT*. The code snippet below imports TPOT, instantiates
    a pipeline optimizer, and trains the model on the training datasets:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们接下来构建一个自动分类模型。我们将优化准确率并训练10分钟——类似于我们在[*第3章*](B16954_03_Final_SK_ePub.xhtml#_idTextAnchor051)，*使用TPOT探索回归*中所做的。下面的代码片段导入TPOT，实例化一个管道优化器，并在训练数据集上训练模型：
- en: '[PRE7]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'TPOT managed to fit 18 generations on my machine, which are shown in the following
    figure:'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: TPOT在我的机器上成功拟合了18代，如下所示：
- en: '![](img/B16954_04_08.jpg)'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B16954_04_08.jpg)'
- en: Figure 4.8 – Output of a TPOT pipeline optimization on the Iris dataset
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.8 – 对Iris数据集进行TPOT管道优化的输出
- en: 'Let''s see if training an automated model managed to increase accuracy. You
    can use the following snippet to obtain the accuracy score:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看训练一个自动模型是否能够提高准确性。您可以使用以下代码片段来获取准确率分数：
- en: '[PRE8]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The accuracy score is shown in the following figure:'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 准确率分数如下所示：
- en: '![Figure 4.9 – Accuracy on the test set with an automated model for the Iris
    dataset'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.9 – 使用自动模型对Iris数据集测试集的准确性'
- en: '](img/B16954_04_09.jpg)'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_09.jpg)'
- en: Figure 4.9 – Accuracy on the test set with an automated model for the Iris dataset
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.9 – 使用自动模型对Iris数据集测试集的准确性
- en: As you can see, the accuracy on the test set didn't improve. If you were to
    make a scatter plot of the target variable and features, you would see some overlap
    for the *virginica* and *versicolor* classes. That's most likely the case here,
    and no amount of training would manage to correctly classify this single instance.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，测试集上的准确率没有提高。如果您绘制目标变量和特征之间的散点图，您会看到*virginica*和*versicolor*类之间有一些重叠。这很可能是这种情况，而且无论训练多久都无法正确分类这个单独的实例。
- en: 'There''s only two things left to do here, and both are optional. The first
    one is to see what TPOT declared as an optimal pipeline after 10 minutes of training.
    The following code snippet will output that pipeline to the console:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里只剩下两件事要做，而且都是可选的。第一件事是查看TPOT在10分钟训练后宣布的最佳管道。以下代码片段将输出该管道到控制台：
- en: '[PRE9]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The corresponding pipeline is shown in the following figure:'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相应的管道如下所示：
- en: '![Figure 4.10 – Optimal TPOT pipeline for the Iris dataset'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.10 – Iris数据集的优化TPOT管道'
- en: '](img/B16954_04_10.jpg)'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_10.jpg)'
- en: Figure 4.10 – Optimal TPOT pipeline for the Iris dataset
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.10 – Iris数据集的优化TPOT管道
- en: 'As always, you can also export the pipeline with the `export()` function:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如同往常，您也可以使用`export()`函数导出管道：
- en: '[PRE10]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The entire Python code is shown in the following figure:'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 整个Python代码如下所示：
- en: '![Figure 4.11 – Python code for an optimal TPOT pipeline for the Iris dataset'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.11 – Iris数据集优化TPOT管道的Python代码'
- en: '](img/B16954_04_11.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16954_04_11.jpg)'
- en: Figure 4.11 – Python code for an optimal TPOT pipeline for the Iris dataset
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11 – Iris数据集优化TPOT管道的Python代码
- en: And there you have it – your first fully automated classification model with
    TPOT. Yes, the dataset was as basic as they come, but the principle always remains
    the same. We'll make automated models on a more complex dataset next, so there
    will be time to get your hands dirty.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 由此，您就拥有了一个使用TPOT的完全自动化的分类模型。是的，数据集非常基础，但原则始终如一。我们将在更复杂的数据集上构建自动模型，这样您就有机会深入研究了。
- en: Applying automated classification modeling to the titanic dataset
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将自动分类建模应用于Titanic数据集
- en: We're now going to apply automated TPOT classification modeling to a slightly
    more complicated dataset. You'll get your hands dirty with the Titanic dataset
    ([https://gist.githubusercontent.com/michhar/2dfd2de0d4f8727f873422c5d959fff5/raw/fa71405126017e6a37bea592440b4bee94bf7b9e/titanic.csv](https://gist.githubusercontent.com/michhar/2dfd2de0d4f8727f873422c5d959fff5/raw/fa71405126017e6a37bea592440b4bee94bf7b9e/titanic.csv))
    – a dataset containing various attributes and descriptions of passengers who did
    and did not survive the Titanic accident.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将应用自动TPOT分类建模到一个稍微复杂一些的数据集上。您将有机会使用Titanic数据集（[https://gist.githubusercontent.com/michhar/2dfd2de0d4f8727f873422c5d959fff5/raw/fa71405126017e6a37bea592440b4bee94bf7b9e/titanic.csv](https://gist.githubusercontent.com/michhar/2dfd2de0d4f8727f873422c5d959fff5/raw/fa71405126017e6a37bea592440b4bee94bf7b9e/titanic.csv)）——一个包含幸存和未幸存的乘客的各种属性和描述的数据集。
- en: The goal is to build an automated model capable of predicting whether a passenger
    would have survived the accident, based on various input features, such as passenger
    class, gender, age, cabin, number of siblings, spouses, parents, and children,
    among other features.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是构建一个自动化的模型，能够根据各种输入特征预测乘客是否会在事故中幸存，例如乘客等级、性别、年龄、船舱、兄弟姐妹、配偶、父母和孩子的数量，以及其他特征。
- en: 'We''ll start by loading the libraries and the dataset next:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来将加载库和数据集：
- en: As always, the first step is to load in the libraries and the dataset. You'll
    need `numpy`, `pandas`, `matplotlib`, and `seaborn` to get you started. The `Matplotlib.rcParams`
    module is also imported, just to make the visualizations a bit more appealing.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 和往常一样，第一步是加载库和数据集。您需要`numpy`、`pandas`、`matplotlib`和`seaborn`来开始。`Matplotlib.rcParams`模块也被导入，只是为了使可视化更加吸引人。
- en: 'The following code snippet imports the libraries, loads in the dataset, and
    displays the first five rows:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段导入库，加载数据集，并显示前五行：
- en: '[PRE11]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Calling the `head()` function returns the first five rows of the dataset. They
    are shown in the following figure:'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调用`head()`函数返回数据集的前五行。它们在以下图中显示：
- en: '![Figure 4.12 – Head of the Titanic dataset'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.12 – 泰坦尼克号数据集的前五行'
- en: '](img/B16954_04_12.jpg)'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_04_12.jpg)'
- en: Figure 4.12 – Head of the Titanic dataset
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.12 – 泰坦尼克号数据集的前五行
- en: You can now proceed with the exploratory data analysis and preparation.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您现在可以继续进行探索性数据分析和准备。
- en: 'The first step in the exploratory data analysis and preparation is to check
    for missing values. The following code line does just that:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 探索性数据分析与准备的第一步是检查缺失值。以下代码行正是如此：
- en: '[PRE12]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding line of code reports back the number of missing values per column
    in the dataset, as shown in the following figure:'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上一行代码报告了数据集中每列的缺失值数量，如下所示：
- en: '![Figure 4.13 – Missing values count per column for the Titanic dataset'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.13 – 泰坦尼克号数据集每列缺失值计数'
- en: '](img/B16954_04_13.jpg)'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_04_13.jpg)'
- en: Figure 4.13 – Missing values count per column for the Titanic dataset
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.13 – 泰坦尼克号数据集每列缺失值计数
- en: As you can see, there are a lot of missing values present in the dataset. Most
    of the missing values are in the `Age` and `Cabin` attributes. It's easy to understand
    for `Cabin` – the value is missing if the passenger didn't have their own cabin.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，数据集中存在许多缺失值。大多数缺失值出现在`Age`和`Cabin`属性中。对于`Cabin`来说很容易理解——如果乘客没有自己的船舱，则值会缺失。
- en: We'll deal with these missing values later, but for now, let's shift our focus
    to data visualization, so you can better understand the dataset.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们稍后会处理这些缺失值，但现在，让我们将重点转向数据可视化，这样您可以更好地理解数据集。
- en: To avoid code duplication, let's define a single function for displaying a bar
    chart. The function shows a bar chart with column counts on top of the bars. It
    also allows you to specify for which dataset column you want to draw a bar chart,
    values for the title, *x*-axis label, and *y*-axis label, and also offsets for
    the counts.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了避免代码重复，让我们定义一个单独的函数来显示条形图。该函数显示条形图，条形上方有列计数。它还允许您指定要为哪个数据集列绘制条形图，标题的值，*x*轴标签，以及*y*轴标签，还有计数的偏移量。
- en: 'You can find the code for this function here:'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以在此处找到该函数的代码：
- en: '[PRE13]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: You'll use this function extensively during the next couple of pages. The goal
    is to visualize how categorical variables are distributed, so you can get a better
    understanding of the dataset.
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您将在接下来的几页中广泛使用此函数。目标是可视化分类变量的分布，以便您更好地理解数据集。
- en: To start, let's visualize how many passengers have survived and how many haven't.
    The previously declared `make_bar_chart()` function comes in handy for the job.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们可视化有多少乘客幸存，有多少没有幸存。之前声明的`make_bar_chart()`函数对这项工作很有帮助。
- en: 'The following code snippet makes the visualization:'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段进行可视化：
- en: '[PRE14]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The visualization is displayed in the following figure:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可视化显示在以下图中：
- en: '![Figure 4.14 – Target class distribution for the Titanic dataset'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.14 – 泰坦尼克号数据集的目标类别分布'
- en: '](img/B16954_04_14.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_04_14.jpg)'
- en: Figure 4.14 – Target class distribution for the Titanic dataset
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.14 – 泰坦尼克号数据集的目标类别分布
- en: As you can see, most of the passengers didn't survive the Titanic accident.
    This information alone doesn't tell you much because you don't know how many passengers
    survived per gender, passenger class, and other attributes.
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，大多数乘客在泰坦尼克号事故中没有幸存。仅凭这一信息并不能告诉你太多，因为你不知道每个性别、乘客舱位和其他属性的乘客中有多少人幸存。
- en: You can use the `make_bar_chart()` function to make this type of visualization.
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以使用 `make_bar_chart()` 函数来创建此类可视化。
- en: Let's continue our data visualization journey by visualizing the number of passengers
    in each passenger class. You can use the same `make_bar_chart()` function for
    this visualization. Just make sure to change the parameters accordingly.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们继续我们的数据可视化之旅，通过可视化每个乘客舱位的乘客数量。你可以使用相同的 `make_bar_chart()` 函数进行此可视化。只需确保相应地更改参数。
- en: 'The following code snippet visualizes the number of passengers per passenger
    class. The lower the class number, the better – a more expensive ticket, better
    service, and who knows, maybe a higher chance of survival:'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段可视化了每个乘客舱位的乘客数量。舱位号码越低，越好——票价更高，服务更好，也许生存的机会也更高：
- en: '[PRE15]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The visualization is shown in the following figure:'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可视化显示在下图中：
- en: '![Figure 4.15 – Number of passengers per passenger class'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.15 – 按乘客舱位划分的乘客数量'
- en: '](img/B16954_04_15.jpg)'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_15.jpg)'
- en: Figure 4.15 – Number of passengers per passenger class
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.15 – 按乘客舱位划分的乘客数量
- en: As you can see, most of the passengers belong to the third class. This is expected,
    as there were more workers on board than rich people.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，大多数乘客属于三等舱。这是预期的，因为船上的工人比富人多。
- en: For the next step in the data visualization phase, let's see how the `Sex` attribute
    is distributed. This will give us insight into whether there were more women or
    men on board and how large the difference was.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据可视化阶段的下一步，让我们看看 `Sex` 属性是如何分布的。这将让我们了解船上有更多的女性还是男性，以及差异有多大。
- en: 'The following code snippet makes the visualization:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段创建了此可视化：
- en: '[PRE16]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The visualization is shown in the following figure:'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可视化显示在下图中：
- en: '![Figure 4.16 – Number of passengers per gender'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.16 – 按性别划分的乘客数量'
- en: '](img/B16954_04_16.jpg)'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_16.jpg)'
- en: Figure 4.16 – Number of passengers per gender
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.16 – 按性别划分的乘客数量
- en: As you can see, there were definitely more men aboard. This is connected with
    the conclusion made in the previous visualization, where we concluded that there
    were many workers on board.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，船上的男性肯定更多。这与前一个可视化中得出的结论有关，我们得出结论，船上有许多工人。
- en: Most of the workers are male, so this visualization makes sense.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大多数工人是男性，所以这种可视化是有意义的。
- en: Let's take a little break from the bar charts and visualize a continuous variable
    for change. The goal is to make a histogram of the `Fare` attribute, which will
    show the distribution of the amounts paid for the ticket.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从条形图休息一下，可视化一个连续变量以展示变化。目标是创建 `Fare` 属性的直方图，这将显示支付船票金额的分布。
- en: 'The following code snippet draws a histogram for the mentioned attribute:'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段为所提到的属性绘制直方图：
- en: '[PRE17]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The histogram is shown in the following figure:'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 直方图显示在下图中：
- en: '![Figure 4.17 – Distribution of the Fare variable'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.17 – 船票变量分布'
- en: '](img/B16954_04_17.jpg)'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_17.jpg)'
- en: Figure 4.17 – Distribution of the Fare variable
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.17 – 船票变量分布
- en: It looks like most of the passengers paid 30 dollars or less for a ticket. As
    always, there are extreme cases. It seems like a single passenger paid around
    500 dollars for the trip. Not a wise decision, taking into consideration how things
    ended.
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 看起来大多数乘客支付了30美元或更少的船票。像往常一样，总有一些极端情况。似乎有一位乘客支付了大约500美元的旅行费用。考虑到事情的结果，这并不是一个明智的决定。
- en: Let's do something a bit different now. The `Name` attribute is more or less
    useless in this format. But if you take a closer look, you can see that every
    value in the mentioned attribute is formatted identically.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来做点不同的事情。`Name` 属性在这个格式中或多或少是无用的。但如果你仔细观察，你可以看到提到的属性中的每个值都是格式化的。
- en: This means we can keep the single word after the first comma and store it in
    a new variable. We'll call this variable `Title` because it represents passenger
    titles (for example, Mr., Miss., and so on).
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这意味着我们可以保留第一个逗号之后的单字并将其存储在一个新变量中。我们将这个变量称为 `Title`，因为它代表乘客头衔（例如，先生、小姐等）。
- en: 'The following code snippet extracts the Title value to a new attribute and
    uses the `make_bar_chart()` function to visually represent different titles among
    Titanic passengers:'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的代码片段提取了头衔值到一个新的属性，并使用`make_bar_chart()`函数来直观地表示泰坦尼克号乘客中的不同头衔：
- en: '[PRE18]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The results are shown in the following figure:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示在下述图中：
- en: '![Figure 4.18 – Distribution of the passenger titles'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.18 – 乘客头衔分布'
- en: '](img/B16954_04_18.jpg)'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_18.jpg)'
- en: Figure 4.18 – Distribution of the passenger titles
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.18 – 乘客头衔分布
- en: Once again, these are expected results. Most of the passengers have common titles,
    such as Mr. and Miss. There's just a handful of them with unique titles. You could
    leave this column as is or turn it into a binary column – the value is zero if
    a title is common, and one otherwise. You'll see how to do that next.
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些是预期的结果。大多数乘客都有常见的头衔，例如先生和小姐。只有少数人拥有独特的头衔。您可以保留这个列不变，或者将其转换为二进制列——如果头衔是常见的，则值为零，否则为之一。您将在下一部分看到如何做到这一点。
- en: That's about enough with regards to the exploratory data analysis. We've made
    quite a few visualizations, but you can always make more on your own.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于探索性数据分析，就到这里吧。我们已经做了很多可视化，但您总是可以自己再做更多。
- en: 'It''s now time to prepare the dataset for machine learning. The steps are described
    here:'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在是时候为机器学习准备数据集了。步骤在这里描述：
- en: a) Drop the columns that are of no use – `Ticket` and `PassengerId`. The first
    one is just a collection of dummy letters and numbers and is of no use for predictive
    modeling. The second one is an arbitrary ID, most likely generated with a database
    sequence. You can remove both by calling the `drop()` function.
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 删除无用的列——`Ticket`和`PassengerId`。第一个只是一个假字母和数字的集合，对预测建模没有用。第二个是一个任意ID，很可能是用数据库序列生成的。可以通过调用`drop()`函数删除这两个。
- en: b) Remap values in the `Sex` attribute to integers. The textual values *male*
    and *female* can't be passed to a machine learning algorithm directly. Some form
    of conversion is a must – so replace males with 0 and females with 1\. The `replace()`
    function is the perfect candidate for the job.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 将`Sex`属性中的值重新映射为整数。文本值*male*和*female*不能直接传递给机器学习算法。某种形式的转换是必须的——因此用0替换男性，用1替换女性。`replace()`函数是这项工作的完美候选人。
- en: c) Use the previously generated `Title` column and convert it into a binary
    one – the value is zero if the title is common (for example, Mr., Miss., and Mrs.)
    and one otherwise. You can then rename the column to something a bit more appropriate,
    such as `Title_Unusal`. The `Name` column isn't needed anymore, so delete it.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 使用之前生成的`Title`列并将其转换为二进制列——如果头衔是常见的（例如，先生、小姐和夫人），则值为零，否则为之一。然后可以将该列重命名为更合适的东西，例如`Title_Unusal`。`Name`列不再需要，因此可以删除它。
- en: d) Handle missing values in the `Cabin` column by turning this attribute into
    a binary one – the value is zero if the value for the cabin is missing, and one
    otherwise. Name this new column `Cabin_Known`. After that, you can delete the
    `Cabin` column because it's not needed anymore, and it can't be passed to a machine
    learning model.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 通过将此属性转换为二进制列来处理`Cabin`列中的缺失值——如果船舱的值为缺失，则值为零，否则为之一。将这个新列命名为`Cabin_Known`。之后，可以删除`Cabin`列，因为它不再需要，并且不能传递给机器学习模型。
- en: e) Create dummy variables with the `Embarked` attribute. This attribute indicates
    the port on which the passengers entered the ship. You be the judge of whether
    this attribute is even necessary, but we'll keep it for TPOT to decide. After
    declaring dummy variables, concatenate them to the original dataset and delete
    the `Embarked` column.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e) 使用`Embarked`属性创建虚拟变量。该属性表示乘客进入船的港口。您将是判断这个属性是否必要的法官，但我们将保留它供TPOT决定。在声明虚拟变量后，将它们连接到原始数据集，并删除`Embarked`列。
- en: f) Handle missing values in the `Age` attribute somehow. There are many sophisticated
    methods, such as *KNN imputing* or *MissForest imputing*, but for simplicity's
    sake, just impute the missing values with a simple average.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: f) 以某种方式处理`Age`属性中的缺失值。有许多复杂的方法，例如*KNN插补*或*MissForest插补*，但为了简单起见，只需用简单平均值来插补缺失值。
- en: 'The following code snippet shows you how to apply all of the mentioned transformations:'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的代码片段显示了如何应用所有提到的转换：
- en: '[PRE19]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You can take a peek at the prepared dataset by examining the following figure:'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以通过查看下述图来预览准备好的数据集：
- en: '![Figure 4.19 – Prepared Titanic dataset'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.19 – 准备好的泰坦尼克号数据集'
- en: '](img/B16954_04_19.jpg)'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_19.jpg)'
- en: Figure 4.19 – Prepared Titanic dataset
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.19 – 准备好的泰坦尼克号数据集
- en: And that's all you have to do with regard to data preparation. Scaling/standardization
    is not required, as TPOT will decide whether that step is necessary.
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于数据准备，这就是你需要做的。不需要缩放/标准化，因为 TPOT 将决定这一步是否必要。
- en: We'll begin with predictive modeling shortly – just one step remains.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们很快就会开始预测建模——只剩下一步了。
- en: 'Before you can train a classification model, you''ll have to split the dataset
    into training and testing subsets. Keep in mind the `random_state` parameter –
    use the same value if you want the same data split:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你能够训练一个分类模型之前，你必须将数据集分成训练和测试子集。记住 `random_state` 参数——如果你想得到相同的数据分割，请使用相同的值：
- en: '[PRE20]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The last code line prints the number of instances in training and testing subsets.
    You can see the numbers in the following figure:'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后一条代码行打印了训练和测试子集中的实例数量。你可以在以下图中看到这些数字：
- en: '![Figure 4.20 – Number of instances in training and testing sets (Titanic)'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.20 – 训练集和测试集中实例的数量（泰坦尼克号）'
- en: '](img/B16954_04_20.jpg)'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_20.jpg)'
- en: Figure 4.20 – Number of instances in training and testing sets (Titanic)
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.20 – 训练和测试集中实例的数量（泰坦尼克号）
- en: Now you're ready to train predictive models.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，你已经准备好训练预测模型了。
- en: 'Let''s start with a baseline model – logistic regression. We''ll train it on
    the train set and evaluate it on the test set. The following code snippet trains
    the model and prints the confusion matrix:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从基线模型开始——逻辑回归。我们将在训练集上训练它，并在测试集上评估它。以下代码片段训练模型并打印混淆矩阵：
- en: '[PRE21]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You can see the confusion matrix in the following figure:'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在以下图中看到混淆矩阵：
- en: '![Figure 4.21 – Logistic regression confusion matrix (Titanic)'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.21 – 逻辑回归混淆矩阵（泰坦尼克号）'
- en: '](img/B16954_04_21.jpg)'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_21.jpg)'
- en: Figure 4.21 – Logistic regression confusion matrix (Titanic)
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.21 – 逻辑回归混淆矩阵（泰坦尼克号）
- en: It looks like there's the same number of false positives and false negatives
    (23). If we take ratios into account, there are more false negatives. In translation,
    the baseline model is more likely to say that the passenger survived even if they
    didn't.
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 看起来错误肯定和错误否定（23）的数量相同。如果我们考虑比率，错误否定更多。在翻译中，基线模型更有可能说乘客幸存了，即使他们没有。
- en: Interpreting the confusion matrix is great, but what if you want to look at
    a concrete number instead? Since this is a classification problem, you could use
    accuracy. But there's a "better" metric – **F1 score**. The value for this metric
    ranges between 0 and 1 (higher is better) and represents a harmonic mean between
    precision and recall.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解读混淆矩阵很好，但如果你想看一个具体的数字呢？由于这是一个分类问题，你可以使用准确率。但有一个“更好”的指标——**F1 分数**。这个指标的值在 0
    到 1 之间（越高越好），它代表了精确率和召回率之间的调和平均值。
- en: 'Here''s how to calculate it with Python:'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是如何用 Python 计算它的示例：
- en: '[PRE22]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The value of the F1 score on the test set is shown in the following figure:'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测试集上 F1 分数的值显示在以下图中：
- en: '![Figure 4.22 – Logistic regression F1 score on the test set (Titanic)'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.22 – 测试集中逻辑回归 F1 分数（泰坦尼克号）'
- en: '](img/B16954_04_22.jpg)'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_22.jpg)'
- en: Figure 4.22 – Logistic regression F1 score on the test set (Titanic)
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.22 – 测试集中逻辑回归 F1 分数（泰坦尼克号）
- en: The value of 0.74 isn't bad for a baseline model. Can TPOT outperform it? Let's
    train an automated model and see what happens.
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于基线模型来说，0.74 的分数并不差。TPOT 能否超越它？让我们训练一个自动模型看看会发生什么。
- en: In a similar fashion as before, we'll train an automated classification model
    for 10 minutes. Instead of accuracy, we'll optimize for the F1 score. By doing
    so, we can compare the F1 scores of an automated model with the baseline one.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与之前类似，我们将训练一个自动分类模型 10 分钟。我们将优化 F1 分数而不是准确率。通过这样做，我们可以比较自动模型和基线模型的 F1 分数。
- en: 'The following code snippet trains the model on the training set:'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段在训练集上训练模型：
- en: '[PRE23]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'In the following figure, you can see the output printed in the notebook during
    training. TPOT managed to train for 7 generations in 10 minutes, and the score
    increases as the model is training:'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下图中，你可以看到训练期间在笔记本中打印的输出。TPOT 在 10 分钟内成功训练了 7 代，随着模型的训练，分数在增加：
- en: '![Figure 4.23 – TPOT pipeline optimization output (Titanic)'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.23 – TPOT 管道优化输出（泰坦尼克号）'
- en: '](img/B16954_04_23.jpg)'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_23.jpg)'
- en: Figure 4.23 – TPOT pipeline optimization output (Titanic)
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.23 – TPOT 管道优化输出（泰坦尼克号）
- en: You are free to leave the model to train for longer than 10 minutes. Still,
    this time frame should be enough to outperform the baseline model.
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以自由地将模型训练时间延长至 10 分钟以上。尽管如此，这个时间框架应该足以优于基线模型。
- en: Let's take a look at the value of the F1 score on the test set now. Remember,
    anything above 0.7415 means TPOT outperformed the baseline model.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看测试集中 F1 分数的值。记住，任何高于 0.7415 的值都意味着 TPOT 的表现优于基线模型。
- en: 'The following code snippet prints the F1 score:'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段打印出 F1 分数：
- en: '[PRE24]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The corresponding F1 score is shown in the following figure:'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对应的 F1 分数如下所示：
- en: '![Figure 4.24 – TPOT optimized model F1 score on the test set (Titanic)'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.24 – TPOT 优化模型在测试集上的 F1 分数（泰坦尼克号）'
- en: '](img/B16954_04_24.jpg)'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_24.jpg)'
- en: Figure 4.24 – TPOT optimized model F1 score on the test set (Titanic)
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.24 – TPOT 优化模型在测试集上的 F1 分数（泰坦尼克号）
- en: It looks like TPOT outperformed the baseline model – as expected.
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 看起来 TPOT 的表现优于基线模型——正如预期的那样。
- en: 'In case you''re more trustworthy of basic metrics, such as accuracy, here''s
    how you can compare it between baseline and automated models:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您更信任基本指标，例如准确率，以下是您如何在基线模型和自动化模型之间进行比较的方法：
- en: '[PRE25]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Corresponding accuracy scores are shown in the following figure:'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对应的准确率分数如下所示：
- en: '![Figure 3.25 – Accuracies of the baseline model and TPOT optimized model on
    the test set (Titanic)'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.25 – 基线模型和 TPOT 优化模型在测试集上的准确率（泰坦尼克号）'
- en: '](img/B16954_04_25.jpg)'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_25.jpg)'
- en: Figure 3.25 – Accuracies of the baseline model and TPOT optimized model on the
    test set (Titanic)
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.25 – 基线模型和 TPOT 优化模型在测试集上的准确率（泰坦尼克号）
- en: As you can see, the simple accuracy metric tells a similar story – the model
    built by TPOT is still better than the baseline one.
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，简单的准确率指标讲述了一个相似的故事——由 TPOT 构建的模型仍然优于基线模型。
- en: 'We are near the end of this practical example. There are two optional things
    left to do. The first one is to take a look at the optimal pipeline. You can obtain
    it with the following line of code:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接近这个实战例子的尾声。还有两个可选的事情要做。第一个是查看最佳管道。您可以使用以下代码行获取它：
- en: '[PRE26]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The optimal pipeline is shown in the following figure:'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最佳管道如下所示：
- en: '![Figure 4.26 – TPOT optimized pipeline (Titanic)'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.26 – TPOT 优化后的管道（泰坦尼克号）'
- en: '](img/B16954_04_26.jpg)'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_04_26.jpg)'
- en: Figure 4.26 – TPOT optimized pipeline (Titanic)
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.26 – TPOT 优化后的管道（泰坦尼克号）
- en: As you can see, TPOT used extreme gradient boosting to solve this classification
    problem.
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，TPOT 使用极端梯度提升来解决这个分类问题。
- en: 'Finally, you can convert the optimal pipeline into Python code. Doing so makes
    the process of sharing the code that much easier. You can find the code for doing
    so here:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，您可以将最佳管道转换为 Python 代码。这样做使得代码共享的过程变得更加容易。您可以在以下位置找到相应的代码：
- en: '[PRE27]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The full source code for the automated pipeline is shown in the following figure:'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动化管道的完整源代码如下所示：
- en: '![Figure 4.27 – Source code for the optimized TPOT pipeline (Titanic)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.27 – 优化后的 TPOT 管道源代码（泰坦尼克号）'
- en: '](img/B16954_04_27.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16954_04_27.jpg)'
- en: Figure 4.27 – Source code for the optimized TPOT pipeline (Titanic)
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.27 – 优化后的 TPOT 管道源代码（泰坦尼克号）
- en: And that does it for solving classification problems on the Titanic dataset
    in an automated fashion. You've now built two fully automated classification machine
    learning solutions. Let's wrap up this chapter next.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就完成了在泰坦尼克号数据集上以自动化方式解决分类问题的任务。您现在已经构建了两个完全自动化的分类机器学习解决方案。让我们接下来总结这一章。
- en: Summary
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This was the second hands-on chapter in the book. You've learned how to solve
    classification machine learning tasks in an automated fashion with two in-depth
    examples on well-known datasets. Without any kind of doubt, you are now ready
    to use TPOT to solve any type of classification problem.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本书的第二个实战章节。您已经学会了如何使用两个深入实例在知名数据集上以自动化方式解决分类机器学习任务。毫无疑问，您现在可以使用 TPOT 解决任何类型的分类问题。
- en: By now, you know how to solve regression and classification tasks. But what
    about parallel training? What about neural networks? The following chapter, [*Chapter
    5*](B16954_05_Final_SK_ePub.xhtml#_idTextAnchor065)*, Parallel Training with TPOT
    and Dask*, will teach you what parallel training is and how to utilize it with
    TPOT. Later, in [*Chapter 6*](B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073),
    *Getting Started with Deep Learning – Crash Course in Neural Networks*, you'll
    reinforce your knowledge of basic deep learning and neural networks. As the icing
    on the cake, you'll learn how to use deep learning with TPOT in [*Chapter 7*](B16954_07_Final_SK_ePub.xhtml#_idTextAnchor086),
    *Neural Network Classifier with TPOT*.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你已经知道如何解决回归和分类任务。但关于并行训练和神经网络呢？接下来的第五章，[*第五章*](B16954_05_Final_SK_ePub.xhtml#_idTextAnchor065)*，使用TPOT和Dask的并行训练*，将教你什么是并行训练以及如何使用TPOT来实现它。稍后，在[*第六章*](B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073)，*深度学习入门
    – 神经网络快速课程*中，你将巩固你对基本深度学习和神经网络的知识。作为甜点，你将在[*第七章*](B16954_07_Final_SK_ePub.xhtml#_idTextAnchor086)，*使用TPOT的神经网络分类器*中学习如何使用TPOT进行深度学习。
- en: Please feel encouraged to practice solving classification problems automatically
    with tools and techniques covered in this chapter.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 请鼓励自己使用本章介绍的工具和技术自动解决分类问题。
- en: Q&A
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问答
- en: Can you explore the distribution of a categorical variable with bar charts?
    Explain.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能探索分类变量的分布情况吗？请解释。
- en: Explain the confusion matrix and the terms true positive, true negative, false
    positive, and false negative.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释混淆矩阵以及真阳性、真阴性、假阳性和假阴性的术语。
- en: What is precision? Explain by giving a practical example.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是精确率？请通过一个实际例子来解释。
- en: What is recall? Explain by giving a practical example.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是召回率？请通过一个实际例子来解释。
- en: What's the difference between accuracy and F1 score? When would you use F1 over
    accuracy?
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准确率和F1分数有什么区别？在什么情况下你会使用F1而不是准确率？
- en: What does "1" in the F1 score mean? Can this number be altered? What happens
    in that scenario?
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: F1分数中的“1”代表什么？这个数字可以被改变吗？在那个情况下会发生什么？
- en: During training, does TPOT output the value of your scoring metric for the train
    set or the test set? Explain.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练过程中，TPOT输出的是训练集还是测试集的评分指标值？请解释。
