- en: '*Chapter 3*: Fundamental Workflow – Data to Deployable Model'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第三章*：基本工作流程 - 数据到可部署模型'
- en: In this chapter, we will walk through a minimal model-building workflow for
    H2O at scale. We will refer to this as the *fundamental workflow* because it omits
    the wide range of functionality and user choices to build accurate, trusted models
    while nevertheless touching on the main steps.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍 H2O 在大规模下的最小模型构建工作流程。我们将称之为“基本工作流程”，因为它省略了广泛的功能和用户选择，以构建准确、可信的模型，同时仍然涉及主要步骤。
- en: The fundamental workflow will serve as a basis to build your understanding of
    H2O technology and coding steps so that in the next part of the book you can dive
    fully into advanced techniques to build state-of-the-art models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 基本工作流程将作为构建你对 H2O 技术和编码步骤理解的基础，以便在本书的下一部分，你可以深入探讨高级技术以构建最先进的模型。
- en: 'To develop the fundamental workflow, we will cover the following main topics
    in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开发基本工作流程，我们将在本章中涵盖以下主要主题：
- en: Use case and data overview
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用例和数据概述
- en: The fundamental workflow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本工作流程
- en: Variation points – alternatives and extensions to the fundamental workflow
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变异点 - 基本工作流程的替代方案和扩展
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, we will focus on using Enterprise Steam to launch H2O clusters
    on an enterprise server cluster. Enterprise Steam technically is not required
    to launch H2O clusters but enterprise stakeholders typically view Enterprise Steam
    as a security, governance, and administrator requirement for implementing H2O
    in enterprise environments.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，我们将专注于使用企业级蒸汽在企业服务器集群上启动 H2O 集群。从技术上讲，启动 H2O 集群并不需要企业级蒸汽，但企业利益相关者通常将企业级蒸汽视为在企业环境中实施
    H2O 的安全、治理和管理要求。
- en: Enterprise Steam requires a license purchased from H2O.ai. If your organization
    does not have an instance of Enterprise Steam installed, you can access Enterprise
    Steam and an enterprise server cluster through a temporary trial license of the
    larger H2O platform. Alternatively, for ease of conducting the exercises in this
    book, you may wish to launch H2O clusters as a sandbox in your local environment
    (for example, on your laptop or desktop workstation) and bypass the use of Enterprise
    Steam.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 企业级蒸汽需要从 H2O.ai 购买的许可证。如果你的组织没有安装企业级蒸汽的实例，你可以通过更大的 H2O 平台的临时试用许可证访问企业级蒸汽和企业服务器集群。或者，为了方便进行本书中的练习，你可能希望在本地环境中（例如，在你的笔记本电脑或台式工作站上）启动
    H2O 集群作为沙盒，并绕过使用企业级蒸汽。
- en: See [*Appendix*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268) *– Alternative
    Methods to Launch H2O Clusters for this Book* to help you decide on how you wish
    to launch H2O clusters for the exercises in this book and how to set up your environment
    to do so.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅[*附录*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268) *– 为本书启动 H2O
    集群的替代方法*，以帮助你决定你希望如何为本书的练习启动 H2O 集群，以及如何设置你的环境以实现这一点。
- en: 'Enterprise Steam: Enterprise Environment versus Coding Exercises in the Book'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 企业级蒸汽：企业环境与本书中的编码练习
- en: Enterprise stakeholders typically view Enterprise Steam as a security, governance,
    and administrator requirement for implementing H2O in enterprise environments.
    This chapter shows how data scientists use Enterprise Steam in this enterprise
    context. Enterprise Steam, however, requires an H2O.ai license to implement and
    will not be available to all readers of this book.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 企业利益相关者通常将企业级蒸汽视为在企业环境中实施 H2O 的安全、治理和管理要求。本章展示了数据科学家如何在这个企业环境中使用企业级蒸汽。然而，企业级蒸汽需要
    H2O.ai 许可证才能实施，并且不会对所有本书的读者开放。
- en: A simple sandbox (non-enterprise) experience is to use H2O exclusively on your
    local environment (laptop or workstation) and this does not require Enterprise
    Steam. Coding exercises in subsequent chapters will leverage the local sandbox
    environment but also can be performed using Enterprise Steam as demonstrated in
    this chapter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的沙盒（非企业）体验是在你的本地环境（笔记本电脑或工作站）上仅使用 H2O，这不需要企业级蒸汽。后续章节中的编码练习将利用本地沙盒环境，但也可以像本章中展示的那样使用企业级蒸汽进行。
- en: Note that the distinction between the data scientist workflow with and without
    Enterprise Steam is isolated to the first step of the workflow (launching the
    H2O cluster) and will be made clearer later in this chapter. See also [*Appendix*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268)
    *– Alternative Methods to Launch H2O Clusters*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，数据科学家工作流程（有或没有企业蒸汽）的区别仅限于工作流程的第一步（启动 H2O 集群），将在本章的后面部分变得更加清晰。另请参阅 [*附录*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268)
    *– 启动 H2O 集群的替代方法*。
- en: Use case and data overview
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用例和数据概述
- en: 'To demonstrate the fundamental workflow, we will implement a binary classification
    problem where we predict the likelihood that a loan will default or not. The dataset
    we use in this chapter can be found at [https://github.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/blob/main/chapt3/loans-lite.csv](https://github.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/blob/main/chapt3/loans-lite.csv).
    (This is a simplified version of the Kaggle *Lending Club Loan* dataset: [https://www.kaggle.com/imsparsh/lending-club-loan-dataset-2007-2011](https://www.kaggle.com/imsparsh/lending-club-loan-dataset-2007-2011).)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示基本工作流程，我们将实现一个二元分类问题，其中我们预测贷款是否会违约。本章中使用的数据集可以在 [https://github.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/blob/main/chapt3/loans-lite.csv](https://github.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/blob/main/chapt3/loans-lite.csv)
    找到。（这是 Kaggle *Lending Club Loan* 数据集的简化版本：[https://www.kaggle.com/imsparsh/lending-club-loan-dataset-2007-2011](https://www.kaggle.com/imsparsh/lending-club-loan-dataset-2007-2011)。）
- en: We are using a simplified version of the dataset to streamline the workflow
    in this chapter. In *Part 2, Building State-of-the-Art Models at Scale*, we will
    develop this use case using advanced H2O model-building capabilities on the original
    loan dataset.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中使用数据集的简化版本来简化工作流程。在 *第 2 部分，大规模构建最先进的模型* 中，我们将使用原始贷款数据集上的高级 H2O 模型构建功能来开发此用例。
- en: The fundamental workflow
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本工作流程
- en: 'Our fundamental workflow will proceed through the following steps:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的基本工作流程将通过以下步骤进行：
- en: Launching the H2O cluster (Enterprise Steam UI)
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 H2O 集群（企业蒸汽 UI）
- en: Connecting to the H2O cluster (your IDE from this point onward)
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接到 H2O 集群（从现在起使用你的 IDE）
- en: Building the model
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建模型
- en: Evaluating and explaining the model
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估和解释模型
- en: Exporting the model for production deployment
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导出模型以进行生产部署
- en: Shutting down the H2O cluster
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭 H2O 集群
- en: Step 1 – launching the H2O cluster
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 1 步 – 启动 H2O 集群
- en: This step is done from the Enterprise Steam UI. You will select whether you
    want an H2O-3 or Sparkling Water cluster and then you will configure the H2O cluster
    behavior, such as the duration of idle time before it times out and terminates
    and whether you want to save the state at termination so you can restart the cluster
    and pick up where you left off (this must be enabled by the administrator). Nicely,
    Enterprise Steam will auto-size the H2O cluster (number of nodes, memory per node,
    CPUs) based on your data size.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤是在企业蒸汽 UI 中完成的。您将选择是否要使用 H2O-3 或汽水集群，然后您将配置 H2O 集群的行为，例如在超时并终止之前空闲时间的长度，以及您是否希望在终止时保存状态以便您可以重新启动集群并从上次离开的地方继续（这必须由管理员启用）。此外，企业蒸汽将根据您的数据大小自动调整
    H2O 集群的大小（节点数量、每个节点的内存、CPU）。
- en: Logging in to Steam
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 登录 Steam
- en: Open a web browser and go to `https://steam-url:9555/login` and log in to Enterprise
    Steam, where `steam-url` is the URL of your specific Steam instance. (Your administrator
    may have changed the port number, but typically it is `9555` as shown in the URL.)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 打开网页浏览器并访问 `https://steam-url:9555/login` 登录企业蒸汽，其中 `steam-url` 是您特定蒸汽实例的 URL。（您的管理员可能已更改端口号，但通常如
    URL 所示为 `9555`。）
- en: Selecting an H2O for H2O-3 (versus Sparkling Water) cluster
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择 H2O-3（与汽水）集群
- en: Here, we will launch an H2O-3 cluster (and not Sparkling Water, which we will
    do in the next part of the book), so click on the **H2O** link in the left panel
    and then click **LAUNCH NEW CLUSTER**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将启动一个 H2O-3 集群（而不是我们在本书下一部分将执行的汽水，点击左侧面板中的 **H2O** 链接，然后点击 **启动新集群**）。
- en: Configuring the H2O-3 cluster
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置 H2O-3 集群
- en: 'This brings us to the following form, which you will configure:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这将带我们到以下表单，您将进行配置：
- en: '![Figure 3.1 – UI to launch an H2O-3 cluster on Kubernetes'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.1 – 在 Kubernetes 上启动 H2O-3 集群的 UI'
- en: '](img/B16721_03_01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_03_01.jpg)'
- en: Figure 3.1 – UI to launch an H2O-3 cluster on Kubernetes
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – 在 Kubernetes 上启动 H2O-3 集群的 UI
- en: For now, we will ignore most configurations. These will be covered more fully
    in [*Chapter 11*](B16721_11_Final_SK_ePub.xhtml#_idTextAnchor207), *The Administrator
    and Operations Views*, where Enterprise Steam is overviewed in detail. Note that
    the configuration page uses the term *H2O cluster* to represent an H2O-3 cluster
    specifically, whereas in this book we use the term H2O cluster to represent either
    an H2O-3 or Sparkling Water cluster.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们将忽略大多数配置。这些配置将在[*第 11 章*](B16721_11_Final_SK_ePub.xhtml#_idTextAnchor207)《管理员和操作视图》中更全面地介绍，其中详细概述了企业蒸汽。请注意，配置页面使用术语
    *H2O 集群* 来特别表示 H2O-3 集群，而在这本书中，我们使用术语 H2O 集群来表示 H2O-3 或 Sparkling Water 集群。
- en: Note on the "Configuring the H2O-3 cluster" Screenshot
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 关于“配置 H2O-3 集群”截图的说明
- en: Details on the screen shown in *Figure 3.1* will vary depending on whether the
    H2O cluster is launched on a Kubernetes environment or on a YARN-based Hadoop
    or Spark environment. Details will also vary based on whether the H2O cluster
    is an H2O-3 cluster or a Sparkling Water cluster. In all cases, however, the fundamental
    concepts of H2O cluster size (number of nodes, CPU/GPU per node, and memory per
    node) and maximum idle/uptime are common throughout.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 3.1* 中显示的屏幕细节将根据 H2O 集群是在 Kubernetes 环境上启动还是在基于 YARN 的 Hadoop 或 Spark 环境上启动而有所不同。细节也会根据
    H2O 集群是 H2O-3 集群还是 Sparkling Water 集群而有所不同。然而，在所有情况下，H2O 集群尺寸（节点数量、每个节点的 CPU/GPU
    和每个节点的内存）以及最大空闲/运行时间的基本概念是通用的。
- en: 'Give your cluster a name and for **DATASET PARAMETERS**, click **Set parameters**
    to arrive at the following popup:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 给您的集群起一个名字，对于 **DATASET PARAMETERS**（数据集参数），点击 **Set parameters**（设置参数）将出现以下弹出窗口：
- en: '![Figure 3.2 – Popup to automatically size the H2O-3 cluster'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.2 – 自动调整 H2O-3 集群的弹出窗口'
- en: '](img/B16721_03_02.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_03_02.jpg)'
- en: Figure 3.2 – Popup to automatically size the H2O-3 cluster
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – 自动调整 H2O-3 集群的弹出窗口
- en: The inputs here are used by Enterprise Steam to auto-size your H2O cluster (that
    is, to determine the number of H2O nodes and memory allocated for each node and
    CPU allocations for each node). Recall the *key concepts* of an H2O cluster as
    presented in the previous chapter.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这里输入的参数将由企业蒸汽用于自动调整您的 H2O 集群（即确定 H2O 节点的数量以及每个节点的内存分配和每个节点的 CPU 分配）。回想一下前一章中介绍的
    H2O 集群的**关键概念**。
- en: Waiting briefly for the cluster to start
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 稍等片刻，等待集群启动
- en: The **STATUS** field in the UI will state **Starting**, signifying that the
    H2O cluster is being launched on the enterprise server cluster. This will take
    a minute or two. When the status changes to **Running**, your H2O cluster is ready
    to use.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: UI 中的 **STATUS** 字段将显示 **Starting**，表示 H2O 集群正在企业服务器集群上启动。这需要一分钟左右。当状态变为 **Running**
    时，您的 H2O 集群即可使用。
- en: Viewing details of the cluster
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查看集群详细信息
- en: Let's first learn a few things about the cluster by clicking on **Actions**
    and then **Detail**. This generates a popup describing the cluster.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先通过点击 **Actions**（操作）然后 **Detail**（详情）来了解一些关于集群的信息。这将生成一个描述集群的弹出窗口。
- en: Notice in this case that **Number of nodes** is **6** and **Memory per node**
    is **48 GB** as auto-sized by Enterprise Steam for a dataset size of 50 GB, as
    shown in *Figure 3.1*. Recall from the *H2O key concepts* section in the previous
    chapter that our dataset is partitioned and distributed in memory across this
    number of H2O cluster nodes on the enterprise server cluster and that compute
    is done in parallel on these H2O nodes.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 注意在本例中，**节点数量**是 **6**，**每个节点的内存**是 **48 GB**，这是企业蒸汽为 50 GB 的数据集大小自动调整的结果，如
    *图 3.1* 所示。回想一下前一章中 *H2O 关键概念* 部分的内容，我们的数据集被分割并分布在这企业服务器集群上的 H2O 集群节点内存中，计算在这些
    H2O 节点上并行进行。
- en: Note on H2O Cluster Sizing
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 H2O 集群尺寸的说明
- en: In general, an H2O cluster is sized so the total memory allocated to the cluster
    (that is, the product of *N* H2O nodes and *X* GB memory per node) is roughly
    5 times the size of the uncompressed dataset that will be used for model building.
    The calculation minimizes the number of nodes (that is, fewer nodes with more
    memory per node is better).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，H2O 集群的尺寸是如此调整，即分配给集群的总内存（即 *N* 个 H2O 节点和每个节点 *X* GB 内存之积）大约是用于模型构建的未压缩数据集大小的
    5 倍。这种计算方式最小化了节点数量（即，每个节点内存更多而节点更少是更好的）。
- en: Enterprise Steam will calculate this sizing based on your description of the
    dataset, but alternatively, you can size the cluster yourself through the Enterprise
    Steam UI. The total memory allocated to the H2O cluster will be released when
    the H2O cluster is terminated.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Enterprise Steam将根据你对数据集的描述来计算这个大小，但你可以通过Enterprise Steam UI自行调整集群大小。当H2O集群终止时，分配给H2O集群的总内存将被释放。
- en: Note that the Enterprise Steam administrator sets the minimum and maximum configuration
    values a user may have when launching an H2O cluster (see *Figure 3.1*) and thus
    the maximum H2O cluster size a user may launch. These boundaries set by the administrator
    can be configured differently for different users.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Enterprise Steam管理员设置了用户在启动H2O集群时可能拥有的最小和最大配置值（见*图3.1*），因此用户可能启动的最大H2O集群大小。管理员设置的这些边界可以为不同的用户配置不同。
- en: Step 2 – connecting to the H2O cluster
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步 – 连接到H2O集群
- en: This and all subsequent steps are from your IDE. We will use a Jupyter notebook
    and write code in Python (though other options include writing H2O in R, Java,
    or Scala using your preferred IDE).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤以及所有后续步骤都是在你的IDE中进行的。我们将使用Jupyter笔记本，并用Python编写代码（尽管其他选项包括使用你喜欢的IDE编写R、Java或Scala版本的H2O）。
- en: 'Open the notebook and connect to the H2O cluster you launched in Enterprise
    Steam by writing the following code:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 打开笔记本，通过编写以下代码连接到你在Enterprise Steam中启动的H2O集群：
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You have now connected to the H2O cluster and can start building models. Note
    that after you connect, you will see H2O cluster details similar to those viewed
    from the Enterprise Steam UI when you configured the cluster before launching.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经连接到H2O集群，可以开始构建模型。请注意，连接后，你会看到与你在启动集群前在Enterprise Steam UI中查看的类似的H2O集群详细信息。
- en: 'Let''s understand what the code is doing:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解代码正在做什么：
- en: You referenced the `h2osteam` and `h2o` Python libraries that were downloaded
    from H2O and implemented in the IDE environment. (The `h2o` library is not used
    by the code shown here but will be used by subsequent model building steps that
    follow.)
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你引用了从H2O下载并实现在你IDE环境中的`h2osteam`和`h2o` Python库。（`h2o`库在此代码中未使用，但将在随后的模型构建步骤中使用。）
- en: Then you logged into the Enterprise Steam server via the `h2osteam` API (library).
    You used the same URL, username, and password that was used to log in to the UI
    of Enterprise Steam.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，你通过`h2osteam` API（库）登录到Enterprise Steam服务器。你使用了与登录Enterprise Steam UI相同的URL、用户名和密码。
- en: You then retrieved your H2O cluster information from Enterprise Steam via the
    `h2osteam` API.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你通过`h2osteam` API从Enterprise Steam检索了你的H2O集群信息。
- en: Note that you are using `H2oKubernetesClient` here because you are connecting
    to an H2O cluster launched on a Kubernetes environment. If, alternatively, your
    enterprise environment is Hadoop or Spark, you use `H2oClient` or `SparklingClient`,
    respectively.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，你在这里使用`H2oKubernetesClient`，因为你正在连接到在Kubernetes环境中启动的H2O集群。如果你所在的企业环境是Hadoop或Spark，你将分别使用`H2oClient`或`SparklingClient`。
- en: You connected to your H2O cluster using `cluster.connect()` and passed the cluster
    information to the `h2o` API. Note that you did not have to specify any URL to
    the H2O cluster because Steam returned this behind the scenes with `H2oKubernetesClient().get_cluster("cluster-name")`.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你使用`cluster.connect()`连接到你的H2O集群，并将集群信息传递给`h2o` API。请注意，你不需要指定任何H2O集群的URL，因为Steam在幕后通过`H2oKubernetesClient().get_cluster("cluster-name")`返回了它。
- en: Creating an H2O Sandbox Environment
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建H2O沙盒环境
- en: 'If you want to create a small H2O sandbox on your local machine instead of
    using Enterprise Steam and your enterprise server cluster, simply implement the
    following two lines of code from your IDE:'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你想在本地机器上创建一个小的H2O沙盒环境，而不是使用Enterprise Steam和你的企业服务器集群，只需在你的IDE中实现以下两行代码：
- en: '`import h2o`'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`import h2o`'
- en: '`h2o.init()`'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`h2o.init()`'
- en: The result is identical to performing *steps 1–2* using Enterprise Steam, except
    that it launches an H2O cluster with one node on your local machine and connects
    to it.
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果与使用Enterprise Steam执行*步骤1-2*相同，只是它在你本地机器上启动了一个节点的H2O集群并连接到它。
- en: Whether connecting to an H2O cluster in your enterprise environment or on your
    local machine, you can now write model-building steps identically from your IDE
    against the respective cluster. For the sandbox, you will be constrained, of course,
    to much smaller data volumes because of its small cluster size of one node with
    low memory.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 无论是在企业环境中连接到H2O集群还是在本地机器上，你现在都可以从你的IDE中针对相应的集群以相同的方式编写模型构建步骤。对于沙盒，由于它的集群大小只有一个节点且内存较低，你当然会受到数据量较小的限制。
- en: Step 3 – building the model
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3步 – 构建模型
- en: Now that we have connected to our H2O cluster, it is time to build the model.
    From this point onward, you will be using the `h2o` API to communicate with the
    H2O cluster to which you launched and connected.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经连接到我们的H2O集群，是时候构建模型了。从这一点开始，你将使用`h2o` API与启动并连接到的H2O集群进行通信。
- en: Here in our fundamental workflow, we will take a minimal approach to import
    data, clean it, engineer features from it, and then train the model.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的基本工作流程中，我们将采取最小化方法导入数据，清理它，从中提取特征，然后训练模型。
- en: Importing the data
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入数据
- en: 'The loans dataset is loaded from the source into the H2O-3 cluster memory using
    the `h2o.import_file` command as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 从源数据加载到H2O-3集群内存中的贷款数据集使用`h2o.import_file`命令如下：
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `loans.dim` line gives us the number of rows and columns and `loans.head()`
    displays the first 10 rows. Quite simple data exploration for now.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '`loans.dim`行给出了行数和列数，`loans.head()`显示了前10行。目前来说，这是一个相当简单的数据探索。'
- en: Note that the dataset is now partitioned and distributed in memory across the
    H2O cluster. From our coding standpoint in the IDE, it is treated as a single
    two-dimensional data structure of columns and rows called an **H2OFrame**.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，现在数据集已经分区并在H2O集群的内存中分布。从我们在IDE中的编码角度来看，它被视为一个称为**H2OFrame**的单个二维数据结构，由列和行组成。
- en: Cleaning the data
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 清理数据
- en: 'Let''s perform one simple data cleaning step. The target or response column
    is called `bad_loan` and it holds values of either 0 or 1 for good and bad loans
    respectively. We need to transform the integers in this column to categorical
    values, as shown next:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行一个简单的数据清理步骤。目标或响应列称为`bad_loan`，它包含0或1的值，分别代表良好和坏账。我们需要将此列中的整数转换为分类值，如下所示：
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Engineering new features from the original data
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从原始数据中工程化新特征
- en: 'Feature engineering is often considered the *secret sauce* in building a superior
    predictive model. For our purposes now, we will do basic feature engineering by
    extracting year and month as separate features from the `issue_d` column, which
    holds day, month, and year as a single value:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程通常被认为是构建优秀预测模型的*秘密配方*。就我们的目的而言，我们将通过从`issue_d`列中提取年份和月份作为单独的特征来进行基本的特征工程，该列包含作为单个值的日、月和年：
- en: '[PRE13]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We have just created two new categorical columns in our `loans` dataset: `issue_d_year`
    and `issue_d_month`.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在`loans`数据集中创建了两个新的分类列：`issue_d_year`和`issue_d_month`。
- en: Model training
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练
- en: 'We will next train a model to predict bad loans. We first split our data into
    `train` and `test`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来将训练一个模型来预测坏账。我们首先将数据分为`train`和`test`：
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We now need to identify which columns we will use to predict whether a loan
    is bad or not. We will do this by removing two columns from the current loans
    H2OFrame, which hold the cleaned and engineered data:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要确定我们将使用哪些列来预测贷款是否坏账。我们将通过从当前的贷款H2OFrame中移除两列来完成此操作，这些列包含已清理和工程化的数据：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note that we removed `bad_loan` from the columns used as features because this
    is what we are predicting. We also removed `issue_d` because we engineered new
    features from this and do not want it as a predictor.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们已从用作特征的列中移除了`bad_loan`，因为这正是我们正在预测的。我们还移除了`issue_d`，因为我们从这个列中工程化了新的特征，不希望它作为预测因子。
- en: 'Next, let''s create an XGBoost model to predict loan default:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们创建一个XGBoost模型来预测贷款违约：
- en: '[PRE19]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Step 4 – evaluating and explaining the model
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4步 – 评估和解释模型
- en: 'Let''s evaluate the performance of the model that we just trained:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们评估我们刚刚训练的模型性能：
- en: '[PRE30]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The output of `perf` shows details on model performance, including model metrics
    such as MSE, Logloss, AUC, and others, as well as a confusion matrix, maximum
    metrics thresholds, and a gains/lift table.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`perf`的输出显示了模型性能的详细信息，包括模型度量，如MSE、Logloss、AUC等，以及混淆矩阵、最大度量阈值和收益/提升表。'
- en: 'Now let''s look at one simple view of model explainability by generating variable
    importance from the model result:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过从模型结果生成变量重要性来查看模型可解释性的一个简单视图：
- en: '[PRE32]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The output of `explain` shows the variable importance of the trained model run
    against the test dataset. This is a table listing how strongly each feature contributed
    to the model.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`explain`的输出显示了针对测试数据集运行的训练模型的变量重要性。这是一个列出每个特征对模型贡献强度的表格。'
- en: H2O's model explainability capabilities go much further than variable importance,
    as we shall see later in the book.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: H2O的模型可解释性能力远不止变量重要性，正如我们将在本书后面看到的那样。
- en: Step 5 – exporting the model's scoring artifact
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5步 – 导出模型的评分工件
- en: 'Now let''s generate and export the model as a scoring artifact that can be
    deployed to a production environment by the DevOps group:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们生成并导出模型作为评分工件，该工件可以由DevOps团队部署到生产环境：
- en: '[PRE34]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In the real world, of course, we would train many models and compare their performance
    and explainability to evaluate which (if any) should make it to production.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，当然，我们会训练许多模型，比较它们的性能和可解释性，以评估哪些（如果有的话）应该进入生产。
- en: Step 6 – shutting down the cluster
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第6步 – 关闭集群
- en: 'When your work is complete, shut down the H2O-3 cluster to free up the resources
    that were reserved by it:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的工作完成时，关闭H2O-3集群以释放它所保留的资源：
- en: '[PRE35]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Variation points – alternatives and extensions to the fundamental workflow
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变异点 – 基本工作流程的替代方案和扩展
- en: The fundamental workflow we developed here is a simple example. For each step
    we performed, there are multiple alternatives and extensions to what has been
    shown. All of *Part 2:, Building State-of-the-Art Models at Scale,* is dedicated
    to understanding these alternatives and elaborations and to putting them together
    to build superior models at scale.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里开发的基本工作流程是一个简单的例子。对于我们所执行的每个步骤，都有多个替代方案和扩展，这些方案和扩展超出了所展示的内容。所有*第二部分：大规模构建最先进的模型*都是致力于理解这些替代方案和扩展，并将它们组合起来构建更高级的模型。
- en: Let's first touch on some key variation points here.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先简要讨论一些关键变异点。
- en: Launching an H2O cluster using the Enterprise Steam API versus the UI (step
    1)
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用企业级Steam API与UI启动H2O集群（步骤1）
- en: In our example, we used the convenience of the Enterprise Steam UI to configure
    and launch an H2O cluster. Alternatively, we could have used the Steam API from
    our IDE to do so. See the full H2O Enterprise Steam API documentation at [https://docs.h2o.ai/enterprise-steam/latest-stable/docs/python-docs/index.html](https://docs.h2o.ai/enterprise-steam/latest-stable/docs/python-docs/index.html)
    for the Python API and [https://docs.h2o.ai/enterprise-steam/latest-stable/docs/r-docs/index.html](https://docs.h2o.ai/enterprise-steam/latest-stable/docs/r-docs/index.html)
    for the R API.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们利用企业级Steam UI的便利性来配置和启动一个H2O集群。或者，我们也可以使用IDE中的Steam API来完成这项工作。有关Python
    API的完整H2O企业级Steam API文档，请参阅[https://docs.h2o.ai/enterprise-steam/latest-stable/docs/python-docs/index.html](https://docs.h2o.ai/enterprise-steam/latest-stable/docs/python-docs/index.html)，有关R
    API的文档，请参阅[https://docs.h2o.ai/enterprise-steam/latest-stable/docs/r-docs/index.html](https://docs.h2o.ai/enterprise-steam/latest-stable/docs/r-docs/index.html)。
- en: By launching the H2O cluster from our IDE, we therefore could have completed
    all of *steps 1–6* of our workflow exclusively from the IDE.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过从我们的IDE启动H2O集群，我们可以完全从IDE完成工作流程的所有*步骤1-6*。
- en: Launching an H2O-3 versus Sparkling Water cluster (step 1)
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动H2O-3集群与Sparkling Water集群（步骤1）
- en: In our example, we launched an H2O-3 cluster. We could alternatively launch
    an H2O Sparkling Water cluster. As we will see, Sparkling Water clusters have
    the same capability set as H2O-3 clusters but with the additional ability to integrate
    Spark code and Spark DataFrames with H2O code and H2O DataFrames. This is particularly
    powerful when leveraging Spark for advanced data exploration and data munging
    before building models in H2O.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们启动了一个H2O-3集群。我们可以选择启动一个H2O Sparkling Water集群。正如我们将看到的，Sparkling Water集群具有与H2O-3集群相同的性能集，但增加了与H2O代码和H2O
    DataFrames集成的Spark代码和Spark DataFrames的能力。这在利用Spark进行高级数据探索和数据预处理，然后在H2O中构建模型时尤其强大。
- en: Implementing Enterprise Steam or not (steps 1–2)
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实施企业级Steam或否（步骤1-2）
- en: 'Know that Enterprise Steam is not a requirement for launching and connecting
    to an enterprise server cluster: it is possible for a data scientist to use only
    the `h2o` (and not `h2osteam`) API in the IDE to configure, launch, and connect
    to an enterprise server cluster, but this is low-level coding and configuration
    and requires detailed integration information. Importantly, this approach lacks
    sound enterprise security, governance, and integration practices.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Enterprise Steam 不是启动和连接到企业服务器集群的必要条件：数据科学家可以在 IDE 中仅使用 `h2o`（而不是 `h2osteam`）API
    来配置、启动和连接到企业服务器集群，但这是一种低级编码和配置，需要详细的集成信息。重要的是，这种方法缺乏健全的企业安全、治理和集成实践。
- en: In the enterprise setting, Enterprise Steam is viewed as essential to centralize,
    manage, and govern H2O technology and H2O users in the enterprise server cluster
    environment. These capabilities are elaborated on in [*Chapter 11*](B16721_11_Final_SK_ePub.xhtml#_idTextAnchor207),
    *The Administrator and Operations Views*.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业环境中，Enterprise Steam 被视为集中管理、治理企业服务器集群环境中的 H2O 技术和 H2O 用户的关键。这些功能在第 11 章[*](B16721_11_Final_SK_ePub.xhtml#_idTextAnchor207)中进行了详细阐述，*管理员和操作视图*。
- en: Using a personal access token to log in to Enterprise Steam (step 2)
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用个人访问令牌登录到 Enterprise Steam（步骤 2）
- en: For *Step 2 – connecting to the H2O cluster*, we authenticated to Enterprise
    Steam from our IDE using the Enterprise Steam API. In the example code, we used
    a clear text password (which was the same password used to log into the Enterprise
    Steam UI). This is not secure if, for example, you shared the notebook.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 2 – 连接到 H2O 集群**中，我们使用 Enterprise Steam API 从我们的 IDE 认证到 Enterprise Steam。在示例代码中，我们使用了明文密码（这是用于登录
    Enterprise Steam UI 的相同密码）。如果你分享了笔记本，这就不安全了。
- en: Alternatively, and more securely, you can use a **Personal Access Token** (**PAT**)
    as the API login password to Enterprise Steam. A PAT can be generated as often
    as you wish, with each newly generated PAT revoking the previous one. Thus, if
    you shared a Jupyter notebook with your login credentials using a PAT as your
    password, the recipient of the notebook would not know your Enterprise Steam UI
    login password and could not authenticate via the API using the revoked password
    in your shared notebook. You can take the PAT one step further and implement it
    as an environment variable outside the IDE.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，更安全的方法是，你可以使用**个人访问令牌**（PAT）作为 API 登录密码连接到 Enterprise Steam。PAT 可以根据需要频繁生成，每个新生成的
    PAT 都会吊销之前的令牌。因此，如果你使用 PAT 作为密码与登录凭证共享 Jupyter 笔记本，笔记本的接收者将不知道你的 Enterprise Steam
    UI 登录密码，并且无法使用你共享笔记本中的吊销密码通过 API 进行认证。你可以进一步将 PAT 实现为 IDE 外部的环境变量。
- en: Enterprise Steam lets you generate a PAT from the UI. To generate a PAT, log
    in to Enterprise Steam UI, click **Configurations,** and follow the brief token
    workflow. Copy the result (a long string) for use in your current notebook or
    script or to set it as an environment variable.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: Enterprise Steam 允许你从 UI 生成一个 Personal Access Token（PAT）。要生成 PAT，请登录到 Enterprise
    Steam UI，点击**配置**，然后遵循简短的令牌工作流程。复制结果（一个长字符串）用于当前笔记本或脚本，或将其设置为环境变量。
- en: Building the model (step 3)
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建模型（步骤 3）
- en: H2O offers a much more powerful model-building experience than what was shown
    in our fundamental workflow. This larger experience is touched on here and explored
    fully in *Part 2, Building State-of-the-Art Models at Scale*.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 提供的模型构建体验比我们基本工作流程中展示的要强大得多。这里简要介绍了这一更大的体验，并在**第 2 部分，大规模构建最先进的模型**中进行了全面探讨。
- en: Language and IDE
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语言和 IDE
- en: We are writing H2O code in Python in a Jupyter notebook. You can also choose
    R for the Enterprise Steam API and use the Python or R IDE of your choice. Additionally,
    you can use H2O's UI-rich IDE called **H2O Flow** to perform the full workflow
    or to quickly understand aspects of an H2O cluster workflow that is progressing
    from your own IDE.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 Jupyter 笔记本中使用 Python 编写 H2O 代码。你也可以选择 R 作为 Enterprise Steam API，并使用你选择的
    Python 或 R IDE。此外，你可以使用 H2O 的 UI 丰富的 IDE，称为 **H2O Flow**，以执行完整的工作流程或快速了解从你自己的
    IDE 中正在进行的 H2O 集群工作流程的各个方面。
- en: Importing data
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入数据
- en: Data can be imported from many sources into H2O clusters, including cloud object
    storage (for example, S3 or Azure Delta Lake), database tables (via JDBC), HDFS,
    and more. Additionally, source files can have many formats, including Parquet,
    ORC, ARFF, and more.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以从许多来源导入到 H2O 集群中，包括云对象存储（例如，S3 或 Azure Delta Lake）、数据库表（通过 JDBC）、HDFS 等。此外，源文件可以有多种格式，包括
    Parquet、ORC、ARFF 等。
- en: Cleaning data and engineering features
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 清洗数据和特征工程
- en: H2O-3 has capabilities for basic data manipulation (for example, changing column
    types, combining or slicing rows or columns, group by, impute, and so on).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: H2O-3具有基本数据操作的能力（例如，更改列类型、合并或切片行或列、按组分组、插补等）。
- en: Recall that launching a Sparkling Water cluster gives us full H2O-3 capabilities
    with the addition of Spark's more powerful data exploration and engineering capabilities.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，启动Sparkling Water集群为我们提供了完整的H2O-3功能，并增加了Spark更强大的数据探索和工程能力。
- en: Model training
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练
- en: In our fundamental workflow, we explored only one type of model (XGBoost) while
    changing only a few default parameters. H2O-3 (and its Sparkling Water extension)
    has an extensive list of both supervised and unsupervised learning algorithms
    and a wide range of parameters and hyperparameters to set to your specification.
    In addition, these algorithms can be combined powerfully into an AutoML workflow
    that explores multiple models and hyperparameter space and arranges the resulting
    best models on a leaderboard. You also have control over cross-validation techniques,
    checkpointing, retraining, and reproducibility.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的基本工作流程中，我们只探索了一种类型的模型（XGBoost），同时只更改了几个默认参数。H2O-3（及其Sparkling Water扩展）拥有广泛的监督学习和无监督学习算法列表，以及一系列参数和超参数，可以设置为您的要求。此外，这些算法可以强大地组合到AutoML工作流程中，探索多个模型和超参数空间，并在排行榜上排列结果最佳模型。您还可以控制交叉验证技术、检查点、重新训练和可重复性。
- en: Evaluating and explaining the model (step 4)
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估和解释模型（步骤4）
- en: H2O has numerous explainability methods and visualizations for both local (individual)
    and global (model-level) explainability, including residual analysis, variable
    importance heatmaps, Shapley summaries, **Partial Dependence Plots** (**PDPs**),
    and **Individual Conditional Expectation** (**ICE**).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: H2O拥有针对局部（个体）和全局（模型级）可解释性的众多解释方法和可视化工具，包括残差分析、变量重要性热图、Shapley摘要、**部分依赖图**（**PDPs**）和**个体条件期望**（**ICE**）。
- en: Exporting the model's scoring artifact (step 5)
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导出模型的评分工件（步骤5）
- en: Once you export the model's scoring artifact (called an H2O MOJO), it is ready
    for DevOps to deploy and monitor in live scoring environments. It likely will
    enter the organization's CI/CD process. We will pick it up at this point in *Part
    3, Deploying Your Models to Production Environments*.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦导出模型的评分工件（称为H2O MOJO），它就准备好在实时评分环境中由DevOps部署和监控。它很可能会进入组织的CI/CD流程。我们将在*第3部分，将您的模型部署到生产环境*中这一点上继续。
- en: Shutting down the cluster (step 6)
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关闭集群（步骤6）
- en: 'You can shut down your cluster from your IDE as shown in our example workflow.
    If you noticed, when configuring your cluster in Enterprise Steam, however, there
    are two configurations that automate the shutdown process: **MAXIMUM IDLE TIME**
    and **MAXIMUM UPTIME**. The first shuts down the cluster after it has not been
    used for the configured amount of time. The second shuts down the cluster after
    it has been up for the configured amount of time. Shutting down clusters (manually
    or automatically) saves resources for others using the enterprise server cluster.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从您的IDE中按照我们的示例工作流程关闭您的集群。然而，如果您注意到，在企业级Steam中配置您的集群时，有两个配置可以自动化关闭过程：**最大空闲时间**和**最大运行时间**。第一个在配置的时间未使用后关闭集群。第二个在集群运行了配置的时间后关闭集群。关闭集群（手动或自动）可以为使用企业服务器集群的其他人节省资源。
- en: The administrator assigns minimum and maximum values for these auto-terminate
    configurations. Note that when enabled by administrators, Enterprise Steam saves
    all models and DataFrames when the H2O cluster has been auto-terminated. You can
    restart the cluster later and pick up where the cluster terminated.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 管理员为这些自动终止的配置分配了最小和最大值。请注意，当管理员启用时，企业级Steam会在H2O集群自动终止时保存所有模型和数据框。您可以在稍后重新启动集群并从集群终止的地方继续。
- en: Summary
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned how to launch an H2O cluster and build a model
    on it from your IDE. This fundamental workflow is a bare skeleton that you will
    flesh out much more fully with a deep set of advanced H2O model-building techniques
    that we will now learn in *Part 2, Building State-of-the-Art Models at Scale,*
    of the book.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学习了如何在您的IDE中启动H2O集群并在其上构建模型。这个基本工作流程是一个裸骨架，您将在本书的*第2部分，大规模构建最先进的模型*中，通过一系列高级H2O模型构建技术对其进行更全面的完善。
- en: We will start this advanced journey in the next chapter by overviewing these
    capabilities before using them.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章开始这段高级旅程，在开始使用这些功能之前先概述它们。
