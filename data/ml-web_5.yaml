- en: Chapter 5. Recommendation Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。推荐系统
- en: Recommendation systems find their natural application whenever a user is exposed
    to a wide choice of products or services that they cannot evaluate in a reasonable
    timeframe. These engines are an important part of an e-commerce business because
    they assist the clients on the web to facilitate the task of deciding the appropriate
    items to buy or choose over a large number of candidates not relevant to the end
    user. Typical examples are Amazon, Netflix, eBay, and Google Play stores that
    suggest each user the items they may like to buy using the historical data they
    have collected. Different techniques have been developed in the past 20 years
    and we will focus on the most important (and employed) methods used in the industry
    to date, specifying the advantages and disadvantages that characterize each of
    these methods. The recommendation systems are classified in **Content-based Filtering**
    ( **CBF** ) and **Collaborative Filtering** ( **CF** ) techniques and other different
    approaches (association rules, the log-likelihood method, and hybrid methods)
    will be discussed together with different ways to evaluate their accuracy. The
    methods will be tested on the MovieLens database (from [http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)
    ) consisting of 100,000 movie ratings (1 to 5 values) from 943 users on 1,682
    movies. Each user has at least 20 ratings and each movie has a list of genres
    that it belongs to. All the codes shown in this chapter are available, as usual,
    at [https://github.com/ai2010/machine_learning_for_the_web/tree/master/chapter_5](https://github.com/ai2010/machine_learning_for_the_web/tree/master/chapter_5)
    in the `rec_sys_methods.ipynb` file.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统在用户面临大量产品或服务选择，且无法在合理时间内进行评估时，自然地找到了其应用场景。这些引擎是电子商务业务的重要组成部分，因为它们帮助网络上的客户在众多与最终用户无关的候选物品中决定购买或选择的适当物品。典型的例子包括亚马逊、Netflix、eBay和Google
    Play商店，它们使用收集的历史数据向每个用户推荐他们可能喜欢的商品。在过去20年中，已经开发出了不同的技术，我们将重点关注迄今为止工业界使用的重要（和常用）方法，并具体说明每种方法的优缺点。推荐系统被归类为**基于内容的过滤**（**CBF**）和**协同过滤**（**CF**）技术，以及其他不同的方法（关联规则、对数似然方法和混合方法）将一起讨论，以及评估它们准确性的不同方式。这些方法将在MovieLens数据库上进行测试（来自[http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)），该数据库包含来自943个用户对1,682部电影（1到5的评分）的10万条评分。每个用户至少有20条评分，每部电影都有一个属于其的类别列表。本章中展示的所有代码，如往常一样，可在[https://github.com/ai2010/machine_learning_for_the_web/tree/master/chapter_5](https://github.com/ai2010/machine_learning_for_the_web/tree/master/chapter_5)的`rec_sys_methods.ipynb`文件中找到。
- en: We will start by introducing the main matrix used to arrange the dataset employed
    by the recommendation system and the metric measures typically used before starting
    to discuss the algorithms in the following sections.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先介绍用于安排推荐系统使用的数据集的主要矩阵以及通常在讨论以下章节中的算法之前使用的度量指标。
- en: Utility matrix
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 效用矩阵
- en: 'The data used in a recommendation system is divided in two categories: the
    users and the items. Each user likes certain items, and the rating value *r[ij]*
    (from 1 to 5) is the data associated with each user *i* and item *j* and represents
    how much the user appreciates the item. These rating values are collected in matrix,
    called utility matrix *R* , in which each row *i* represents the list of rated
    items for user *i* while each column *j* lists all the users who have rated item
    *j* . In our case, the data folder `ml-100k` contains a file called `u.data` (and
    also `u.item` with the list of movie titles) that has been converted into a Pandas
    DataFrame (and saved into a `csv, utilitymatrix.csv` ) by the following script:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统中使用的数据分为两类：用户和物品。每个用户喜欢某些物品，评分值*r[ij]*（从1到5）是与每个用户*i*和物品*j*相关联的数据，表示用户对物品的欣赏程度。这些评分值收集在矩阵中，称为效用矩阵*R*，其中每一行*i*代表用户*i*的评分物品列表，而每一列*j*列出所有对物品*j*进行过评分的用户。在我们的案例中，数据文件夹`ml-100k`包含一个名为`u.data`的文件（以及包含电影标题列表的`u.item`），该文件已被以下脚本转换为Pandas
    DataFrame（并保存到`csv, utilitymatrix.csv`）：
- en: '![Utility matrix](img/Image00452.jpg)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![效用矩阵](img/Image00452.jpg)'
- en: 'The output of the first two lines is as follows:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 前两行的输出如下：
- en: '![Utility matrix](img/Image00453.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![效用矩阵](img/Image00453.jpg)'
- en: 'Each column name, apart from the first (which is the user id), defines the
    name of the movie and the ID of the movie in the MovieLens database (separated
    by a semicolon). The `0` values represent the missing values and we expect to
    have a large number of them because the users evaluated far fewer than 1,600 movies.
    Note that the movies with less than 50 ratings have been removed from the utility
    matrix, so the number of columns is 604 (603 movies rated more than 50 times).
    The goal of the recommendation system is to predict these values, but for some
    techniques to work properly it will be necessary for us to initially set these
    values (imputation). Usually, two imputation approaches are used: ratings average
    per user or ratings average per item, and both of them are implemented in the
    following function:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 除了第一个（用户 ID）之外，每个列名定义了电影的名称和 MovieLens 数据库中电影的 ID（由分号分隔）。`0` 值表示缺失值，我们预计会有大量缺失值，因为用户评估的电影远少于
    1,600 部。请注意，评分少于 50 次的电影已被从效用矩阵中删除，因此列数为 604（603 部电影被评分超过 50 次）。推荐系统的目标是预测这些值，但对于某些技术要正常工作，我们最初需要设置这些值（插补）。通常，使用两种插补方法：按用户平均评分或按项目平均评分，这两种方法都在以下函数中实现：
- en: '![Utility matrix](img/Image00454.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![效用矩阵](img/Image00454.jpg)'
- en: This function will be called by many of the algorithms implemented in this chapter,
    so we decided to discuss it here as a reference for future use. Furthermore, in
    this chapter the utility matrix *R* will have dimensions *N* × *M* with *N* number
    of users and *M* number of items. Due to the recurrent use of the similarity measures
    by different algorithms, we will define the most commonly used definitions hereafter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数将由本章实现的大多数算法调用，因此我们决定在此处讨论它，作为未来使用的参考。此外，在本章中，效用矩阵 *R* 将具有 *N* × *M* 的维度，其中
    *N* 为用户数量，*M* 为项目数量。由于不同算法反复使用相似度度量，以下我们将定义最常用的定义。
- en: Similarities measures
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相似度度量
- en: 'In order to compute similarity *s* between two different vectors *x* and *y*
    , which can be users (rows of utility matrix) or items (columns of utility matrix),
    two measures are typically used:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算两个不同向量 *x* 和 *y* 之间的相似度 *s*，这些向量可以是用户（效用矩阵的行）或项目（效用矩阵的列），通常使用两种度量：
- en: 'Cosine similarity: ![Similarities measures](img/Image00455.jpg)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 余弦相似度：![相似度度量](img/Image00455.jpg)
- en: 'Pearson correlation: ![Similarities measures](img/Image00456.jpg) , where *x*
    and *y* are the averages of the two vectors.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 皮尔逊相关系数：![相似度度量](img/Image00456.jpg)，其中 *x* 和 *y* 是两个向量的平均值。
- en: 'Note that the two measures coincide if the average is 0\. We can now start
    discussing the different algorithms, starting from the CF category. The following
    `sim()` function will be used to evaluate the similarity between two vectors:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果平均值为 0，则两个度量是一致的。现在我们可以开始讨论不同的算法，从协同过滤类别开始。以下 `sim()` 函数将用于评估两个向量之间的相似度：
- en: '![Similarities measures](img/Image00457.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![相似度度量](img/Image00457.jpg)'
- en: The `SciPy` library has been used to compute both similarities (note that the
    cosine scipy definition is the opposite of what has been defined previously, so
    the value is subtracted from 1).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`SciPy` 库已被用于计算相似度（请注意，余弦相似度的 SciPy 定义与之前定义的相反，因此值从 1 中减去）。'
- en: Collaborative Filtering methods
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协同过滤方法
- en: This class of methods is based on the idea that any user will like items appreciated
    by other users similar to them. In simple terms, the fundamental hypothesis is
    that a user *A* , who is similar to user *B* , will likely rate an item as *B*
    did rather than in another way. In practice, this concept is implemented by either
    comparing the taste of different user's and inferring the future rating for a
    given user using the most similar users taste (memory-based) or by extracting
    some rating patterns from what the users like (model-based) and trying to predict
    the future rating following these patterns. All these methods require a large
    amount of data to work because the recommendations to a given user rely on how
    many similar users can be found in the data. This problem is called **cold start**
    and it is very well studied in literature, which usually suggests using some hybrid
    method between CF and CBF to overcome the issue. In our MovieLens database example
    we assume we have enough data to avoid the cold start problem. Other common problems
    of CF algorithms are the scalability, because the computation grows with the number
    of users and products (it may be necessary some parallelization technique), and
    the sparsity of the utility matrix due to small number of items that any user
    usually rates (imputation is usually an attempt to handle the problem).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这类方法基于这样的想法：任何用户都会喜欢其他类似用户喜欢的项目。简单来说，基本假设是，与用户 *B* 相似用户 *A* 很可能将项目评分与 *B* 相同，而不是其他方式。在实践中，这个概念通过比较不同用户的品味并使用最相似用户的品味来推断给定用户的未来评分（基于记忆）或通过从用户喜欢的项目中提取一些评分模式并尝试遵循这些模式来预测未来评分来实现。所有这些方法都需要大量的数据才能工作，因为给定的用户的推荐依赖于数据中可以找到多少相似用户。这个问题被称为
    **冷启动**，在文献中得到了很好的研究，通常建议使用CF和CBF之间的某种混合方法来克服这个问题。在我们的MovieLens数据库示例中，我们假设我们有足够的数据来避免冷启动问题。CF算法的常见问题还包括可扩展性，因为计算量随着用户和产品的数量增加（可能需要一些并行化技术），以及由于任何用户通常评分的项目数量较少而导致的效用矩阵稀疏性（插补通常是处理问题的尝试）。
- en: Memory-based Collaborative Filtering
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于记忆的协同过滤
- en: This subclass employs the utility matrix to calculate either the similarity
    between users or items. The methods suffer from scalability and cold start issues,
    but when they are applied to a large or too small utility matrix, they are currently
    used in many commercial systems today. We are going to discuss user-based Collaborative
    Filtering and iteFiased Collaborative Filtering hereafter.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个子类使用效用矩阵来计算用户之间的相似度或项目之间的相似度。这些方法存在可扩展性和冷启动问题，但当它们应用于大型或过小的效用矩阵时，它们目前在许多商业系统中被广泛使用。我们将在此后讨论基于用户的协同过滤和基于项目的协同过滤。
- en: User-based Collaborative Filtering
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于用户的协同过滤
- en: The approach uses a `k-NN` method (see [Chapter 3](text00024.html#page "Chapter 3. Supervised
    Machine Learning") , *Supervised Machine Learning* ) to find the users whose past
    ratings are similar to the ratings of the chosen user so that their ratings can
    be combined in a weighted average to return the current user's missing ratings.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法使用 `k-NN` 方法（见[第3章](text00024.html#page "第3章. 监督机器学习")，*监督机器学习*）来找到过去评分与所选用户评分相似的用户的评分，以便可以将它们的评分组合成一个加权平均值来返回当前用户的缺失评分。
- en: 'The algorithm is as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 算法如下：
- en: 'For any given user *i* and item not yet rated *j* :'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何给定的用户 *i* 和尚未评分的项目 *j*：
- en: Find the *K* that is most similar users that have rate *j* using a similarity
    metric *s* .
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用相似度指标 *s* 找到与具有评分 *j* 的用户最相似的 *K* 个用户。
- en: Calculate the predicted rating for each item *j* not yet rated by *i* as a weighted
    average over the ratings of the users *K* :![User-based Collaborative Filtering](img/Image00458.jpg)
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算用户 *i* 尚未评分的每个项目 *j* 的预测评分，作为用户 *K* 的评分加权平均值：![基于用户的协同过滤](img/Image00458.jpg)
- en: 'Here ![User-based Collaborative Filtering](img/Image00459.jpg) are the average
    ratings for users *i* and *k* to compensate for subjective judgment (some users
    are generous and some are picky) and *s(i* , *k)* is the similarity metric, as
    seen in the previous paragraph. Note that we can even normalize by the spread
    of the ratings per user to compare more homogeneous ratings:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里 ![基于用户的协同过滤](img/Image00459.jpg) 是用户 *i* 和 *k* 的平均评分，以补偿主观判断（一些用户慷慨，一些用户挑剔）和
    *s(i* , *k)* 是相似度指标，如前一段所述。注意，我们甚至可以通过每个用户的评分分布进行归一化，以比较更均匀的评分：
- en: '![User-based Collaborative Filtering](img/Image00460.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![基于用户的协同过滤](img/Image00460.jpg)'
- en: Here, σ[i] and σ[k] are the standard deviations of ratings of users *i* and
    *k* .
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，σ[i] 和 σ[k] 分别是用户 *i* 和 *k* 的评分标准差。
- en: This algorithm has as an input parameter, the number of neighbors, *K* but usually
    a value between `20` and `50` is sufficient in most applications. The Pearson
    correlation has been found to return better results than cosine similarity, probably
    because the subtraction of the user ratings means that the correlation formula
    makes the users more comparable. The following code is used to predict the missing
    ratings of each user.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法有一个输入参数，即邻居数量 *K*，但在大多数应用中通常 `20` 到 `50` 之间的值就足够了。皮尔逊相关系数被发现比余弦相似度返回更好的结果，这可能是由于用户评分的减去使得相关公式使得用户更具有可比性。以下代码用于预测每个用户的缺失评分。
- en: The `u_vec` represents the user ratings values from which the most similar other
    users *K* are found by the function `FindKNeighbours` . `CalcRating` just computes
    the predicted rating using the formula discussed earlier (without the spreading
    correction). Note that in case the utility matrix is so sparse that no neighbors
    are found, the mean rating of the user is predicted. It may happen that the predicted
    rating is beyond `5` or below `1` , so in such situations the predicted rating
    is set to `5` or `1` respectively.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`u_vec` 代表用户评分值，通过 `FindKNeighbours` 函数找到最相似的其他用户 *K*。`CalcRating` 仅使用前面讨论过的公式（没有传播校正）计算预测评分。请注意，如果效用矩阵非常稀疏以至于没有找到邻居，则预测评分是用户的平均评分。可能发生的情况是预测评分超过
    `5` 或低于 `1`，因此在这种情况下，预测评分分别设置为 `5` 或 `1`。'
- en: '![User-based Collaborative Filtering](img/Image00461.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![基于用户的协同过滤](img/Image00461.jpg)'
- en: Item-based Collaborative Filtering
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于物品的协同过滤
- en: This approach is conceptually the same as user-based CF except that the similarity
    is calculated on the items rather than the users. Since most of the time the number
    of users can become much larger than the number of items, this method offers a
    more scalable recommendation system because the items' similarities can be precomputed
    and they will not change much when new users arrive (if the number of users *N*
    is significantly large).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法在概念上与基于用户的 CF 相同，只是相似度是在物品上而不是在用户上计算的。由于大多数情况下用户的数量可以远远大于物品的数量，因此这种方法提供了一种更可扩展的推荐系统，因为物品的相似度可以预先计算，并且当新用户到来时不会改变太多（如果用户数量
    *N* 显著很大）。
- en: 'The algorithm for each user *i* and item *j* is as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个用户 *i* 和物品 *j* 的算法如下：
- en: Find the *K* most similar items using a similarity metric *s* that *i* has already
    rated.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用相似度指标 *s* 来找到 *K* 个与 *i* 已经评分的物品最相似的物品。
- en: Calculate the predicted rating as a weighted average of the ratings of the *K*
    items:![Item-based Collaborative Filtering](img/Image00462.jpg)
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测评分计算为 *K* 个物品评分的加权平均值：![基于物品的协同过滤](img/Image00462.jpg)
- en: Note that the similarity metric may have a negative value, so we need to restrict
    the summation to only positive similarities in order to have meaningful (that
    is, positive) *P[ij]* (the relative ordering of items will be correct anyway if
    we are only interested in the best item to recommend instead of the ratings).
    Even in this case, a *K* value between `20` and `50` is usually fine in most applications.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，相似度指标可能具有负值，因此我们需要将求和限制在只有正相似度上，以便具有意义（即正的）*P[ij]*（如果我们只对推荐最佳物品感兴趣而不是评分，那么物品的相对顺序将始终是正确的）。即使在这种情况，大多数应用中
    `20` 到 `50` 之间的 *K* 值通常就足够了。
- en: 'The algorithm is implemented using a class, as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法使用一个类实现，如下所示：
- en: '![Item-based Collaborative Filtering](img/Image00463.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![基于物品的协同过滤](img/Image00463.jpg)'
- en: 'The constructor of the class `CF_itembased` calculates the item similarity
    matrix `simmatrix` to use any time we want to evaluate missing ratings for a user
    through the function `CalcRatings` . The function `GetKSimItemsperUser` finds
    *K* : most similar users to the chosen user (given by `u_vec` ) and `CalcRating`
    just implements the weighted average rating calculations discussed previously.
    Note that in case no neighbors are found, the rating is set to the average or
    the item''s ratings.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 类 `CF_itembased` 的构造函数计算用于评估用户缺失评分的 `simmatrix` 物品相似度矩阵，任何需要通过 `CalcRatings`
    函数评估缺失评分时都可以使用。函数 `GetKSimItemsperUser` 找到与选定用户（由 `u_vec` 给出）最相似的 *K* 个用户，而 `CalcRating`
    仅实现前面讨论过的加权平均评分计算。请注意，如果没有找到邻居，则评分设置为平均值或物品的评分。
- en: Simplest item-based Collaborative Filtering – slope one
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最简单的基于物品的协同过滤 – 斜率一
- en: 'Instead of computing the similarity using the metric discussed previously,
    a very simple but effective method can be used. We can compute a matrix *D* in
    which each entry *d[ij]* is the average difference between the ratings of items
    *i* and *j* :'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是使用之前讨论的度量来计算相似度，可以使用一个非常简单但有效的方法。我们可以计算一个矩阵 *D*，其中每个条目 *d[ij]* 是项目 *i* 和
    *j* 评分的平均差异：
- en: '![Simplest item-based Collaborative Filtering – slope one](img/Image00464.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![最简单的基于物品的协同过滤 – 斜率一](img/Image00464.jpg)'
- en: Here, ![Simplest item-based Collaborative Filtering – slope one](img/Image00465.jpg)
    is a variable that counts if the user *k* has rated both *i* and *j* items, so
    ![Simplest item-based Collaborative Filtering – slope one](img/Image00466.jpg)
    is the number of users who have rated both *i* and *j* items.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![最简单的基于物品的协同过滤 – 斜率一](img/Image00465.jpg) 是一个变量，用于计算用户 *k* 是否对 *i* 和 *j*
    两个项目都进行了评分，因此 ![最简单的基于物品的协同过滤 – 斜率一](img/Image00466.jpg) 是对 *i* 和 *j* 两个项目都进行了评分的用户数量。
- en: 'Then the algorithm is as explained in the *Item-based Collaborative Filtering*
    section. For each user *i* and item *j* :'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然后算法如 *基于物品的协同过滤* 部分所述。对于每个用户 *i* 和项目 *j*：
- en: Find the *K* items with the smallest differences from *j* , ![Simplest item-based
    Collaborative Filtering – slope one](img/Image00467.jpg) (the `*` indicates the
    possible index values, but for simplicity we relabel them from `1` to *K* ).
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到与项目 *j* 差异最小的 *K* 个项目，![最简单的基于物品的协同过滤 – 斜率一](img/Image00467.jpg)（`*` 表示可能的索引值，但为了简单起见，我们将它们重新标记为
    `1` 到 *K*）。
- en: Compute the predicted rating as a weighted average:![Simplest item-based Collaborative
    Filtering – slope one](img/Image00468.jpg)
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算预测评分作为加权平均值：![最简单的基于物品的协同过滤 – 斜率一](img/Image00468.jpg)
- en: 'Although this algorithm is much simpler than the other CF algorithms, it often
    matches their accuracy, is computationally less expensive, and is easy to implement.
    The implementation is very similar to the class used for item-based CF:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个算法比其他协同过滤算法要简单得多，但它通常与它们的准确性相匹配，计算成本更低，且易于实现。其实现方式与用于基于物品的协同过滤的类非常相似：
- en: '![Simplest item-based Collaborative Filtering – slope one](img/Image00469.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![最简单的基于物品的协同过滤 – 斜率一](img/Image00469.jpg)'
- en: 'The only difference is the matrix: now `difmatrix` is used to calculate the
    differences *d(i* , *j)* between items *i* , *j* , as explained earlier, and the
    function `GetKSimItemsperUser` now looks for the smallest `difmatrix` values to
    determine the *K* nearest neighbors. Since it is possible (although unlikely)
    that two items have not been rated by at least one user, `difmatrix` can have
    undefined values that are set to `1000` by default. Note that it is also possible
    that the predicted rating is beyond `5` or below `1` , so in such situations the
    predicted rating must be set to `5` or `1` appropriately.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的区别是矩阵：现在使用 `difmatrix` 来计算项目 *i* 和 *j* 之间的差异 *d(i, j)*，如前所述，而函数 `GetKSimItemsperUser`
    现在寻找最小的 `difmatrix` 值以确定 *K* 个最近邻。由于两个项目至少没有被一个用户评分的可能性（尽管可能性不大），`difmatrix` 可以有未定义的值，默认设置为
    `1000`。请注意，预测评分也可能超过 `5` 或低于 `1`，因此在这种情况下，必须适当地将预测评分设置为 `5` 或 `1`。
- en: Model-based Collaborative Filtering
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于模型的协同过滤
- en: This class of methods uses the utility matrix to generate a model to extract
    the pattern of how the users rate the items. The pattern model returns the predicted
    ratings, filling or approximating the original matrix (matrix factorization).Various
    models have been studied in the literature and we will discuss particular *matrix
    factorization* algorithms—the **Singular Value Decomposition** ( **SVD** , also
    with expectation maximization), the **Alternating Least Square** ( **ALS** ),
    the **Stochastic Gradient Descent** ( **SGD** ), and the general **Non-negative
    matrix factorization** ( **NMF** ) class of algorithms.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这类方法使用效用矩阵生成一个模型来提取用户如何评分项目的模式。模式模型返回预测评分，填充或近似原始矩阵（矩阵分解）。文献中已经研究了各种模型，我们将讨论特定的
    *矩阵分解* 算法——**奇异值分解**（**SVD**，也带有期望最大化），**交替最小二乘法**（**ALS**），**随机梯度下降**（**SGD**），以及一般的**非负矩阵分解**（**NMF**）算法类。
- en: Alternative least square (ALS)
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 替代最小二乘法（ALS）
- en: 'This is the simplest method to factorize the matrix *R* . Each user and each
    item can be represented in a feature space of dimension *K* so that:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这是分解矩阵 *R* 的最简单方法。每个用户和每个项目都可以在 *K* 维的特征空间中表示，以便：
- en: '![Alternative least square (ALS)](img/Image00470.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![替代最小二乘法（ALS）](img/Image00470.jpg)'
- en: 'Here, *P N×K* is the new matrix of users in the feature space, and *Q M×K*
    is the projection of the items in the same space. So the problem is reduced to
    minimize a regularized cost function *J* :'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*P N×K* 是特征空间中的新用户矩阵，而 *Q M×K* 是同一空间中物品的投影。因此，问题被简化为最小化正则化成本函数 *J*：
- en: '![Alternative least square (ALS)](img/Image00471.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![替代最小二乘法 (ALS)](img/Image00471.jpg)'
- en: 'Here, λ is the regularization parameter, which is useful to avoid overfitting
    by penalizing the learned parameters and ensuring that the magnitudes of the vectors
    *p[i]* and *[q] ^T [j]* are not too large. The matrix entries *Mc[ij]* are needed
    to check that the pair of user *i* and item *j* are actually rated, so *Mc[ij]*
    is `1` if *r[ij] >0* , and it''s `0` otherwise. Setting the derivatives of *J*
    to `0` for each user vector *p[i]* and item vector *q[j]* , we obtain the following
    two equations:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，λ 是正则化参数，它通过惩罚学习到的参数并确保向量 *p[i]* 和 *[q] ^T [j]* 的大小不是太大，从而有助于避免过拟合。矩阵条目
    *Mc[ij]* 用于检查用户 *i* 和物品 *j* 是否确实进行了评分，因此当 *r[ij] >0* 时，*Mc[ij]* 为 `1`，否则为 `0`。将每个用户向量
    *p[i]* 和物品向量 *q[j]* 的 *J* 的导数设为 `0`，我们得到以下两个方程：
- en: '![Alternative least square (ALS)](img/Image00472.jpg)![Alternative least square
    (ALS)](img/Image00473.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![替代最小二乘法 (ALS)](img/Image00472.jpg)![替代最小二乘法 (ALS)](img/Image00473.jpg)'
- en: 'Here *R[i]* and *Mc[i]* refer to the row *i* of the matrices *R* and *Mc* ,
    and *R[j]* and *Mc[j]* refer to the column *j* of the matrices *Mc* and *R* .
    Alternating the fixing of the matrix *P* , *Q* , the previous equations can be
    solved directly using a least square algorithm and the following function implements
    the ALS algorithm in Python:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*R[i]* 和 *Mc[i]* 分别指矩阵 *R* 和 *Mc* 的第 *i* 行，而 *R[j]* 和 *Mc[j]* 分别指矩阵 *Mc*
    和 *R* 的第 *j* 列。交替固定矩阵 *P* 和 *Q*，前述方程可以直接使用最小二乘算法解决，以下函数实现了 Python 中的 ALS 算法：
- en: '![Alternative least square (ALS)](img/Image00474.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![替代最小二乘法 (ALS)](img/Image00474.jpg)'
- en: The matrix *Mc* is called `mask` , the variable `l` represents the regularization
    parameter lambda and is set to `0.001` by default, and the least square problem
    has been solved using the `linalg.solve` function of the `Numpy` library. This
    method usually is less precise than both **Stochastic Gradient Descent** ( **SGD**
    ) and **Singular Value Decomposition** ( **SVD** ) (see the following sections)
    but it is very easy to implement and easy to parallelize (so it can be fast).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 *Mc* 被称为 `mask`，变量 `l` 代表正则化参数 λ，默认设置为 `0.001`，最小二乘问题已使用 `Numpy` 库的 `linalg.solve`
    函数解决。这种方法通常比 **随机梯度下降** ( **SGD** ) 和 **奇异值分解** ( **SVD** ) (参见以下章节) 都要精确，但它非常容易实现且易于并行化（因此可以快速）。
- en: Stochastic gradient descent (SGD)
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 随机梯度下降 (SGD)
- en: 'This method also belongs to the matrix factorization subclass because it relies
    on the approximation of the utility matrix *R* as:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法也属于矩阵分解子类，因为它依赖于对效用矩阵 *R* 的近似：
- en: '![Stochastic gradient descent (SGD)](img/Image00475.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![随机梯度下降 (SGD)](img/Image00475.jpg)'
- en: 'Here, the matrices *P(N×K)* and *Q(M×K)* represent the users and the items
    in a latent feature space of *K* dimensions. Each approximated rating ![Stochastic
    gradient descent (SGD)](img/Image00476.jpg) can be expressed as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，矩阵 *P(N×K)* 和 *Q(M×K)* 分别代表具有 *K* 维潜在特征空间中的用户和物品。每个近似的评分 ![随机梯度下降 (SGD)](img/Image00476.jpg)
    可以表示如下：
- en: '![Stochastic gradient descent (SGD)](img/Image00477.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![随机梯度下降 (SGD)](img/Image00477.jpg)'
- en: 'The matrix ![Stochastic gradient descent (SGD)](img/Image00478.jpg) is found,
    solving the minimization problem of the regularized squared errors *e² [ij] *
    as with the ALS method (cost function *J* as in [Chapter 3](text00024.html#page
    "Chapter 3. Supervised Machine Learning") , *Supervised Machine Learning* ):'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 找到了矩阵 ![随机梯度下降 (SGD)](img/Image00478.jpg)，解决正则化平方误差 *e² [ij] * 的最小化问题，就像 ALS
    方法一样（成本函数 *J* 如 [第 3 章](text00024.html#page "第 3 章. 监督机器学习") ，*监督机器学习* ）：
- en: '![Stochastic gradient descent (SGD)](img/Image00479.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![随机梯度下降 (SGD)](img/Image00479.jpg)'
- en: 'This minimization problem is solved using the gradient descent (see [Chapter
    3](text00024.html#page "Chapter 3. Supervised Machine Learning") , *Supervised
    Machine Learning* ):'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这个最小化问题使用梯度下降法解决（参见 [第 3 章](text00024.html#page "第 3 章. 监督机器学习") ，*监督机器学习* ）：
- en: '![Stochastic gradient descent (SGD)](img/Image00480.jpg)![Stochastic gradient
    descent (SGD)](img/Image00481.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![随机梯度下降 (SGD)](img/Image00480.jpg)![随机梯度下降 (SGD)](img/Image00481.jpg)'
- en: 'Here, α is the learning rate (see [Chapter 3](text00024.html#page "Chapter 3. Supervised
    Machine Learning") , *Supervised Machine Learning* ) and ![Stochastic gradient
    descent (SGD)](img/Image00482.jpg) . The technique finds *R* alternating between
    the two previous equations (fixing *q[kj] * and solving *P[ik] * , and vice versa)
    until convergence. SGD is usually easier to parallelize (so it can be faster)
    than SVD (see the following section) but is less precise at finding good ratings.
    The implementation in Python of this method is given by the following script:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，α 是学习率（见[第 3 章](text00024.html#page "第 3 章. 监督机器学习")，*监督机器学习*）和![随机梯度下降
    (SGD)](img/Image00482.jpg)。该技术通过在两个先前方程之间交替寻找 *R*（固定 *q[kj]* 并求解 *P[ik]*，反之亦然）直到收敛。SGD
    通常比 SVD（见下一节）更容易并行化（因此可能更快），但在找到良好评分方面不太精确。此方法的 Python 实现如下脚本：
- en: '![Stochastic gradient descent (SGD)](img/Image00483.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![随机梯度下降 (SGD)](img/Image00483.jpg)'
- en: This SGD function has default parameters that are learning rate *α = 0.0001*
    , regularization parameter *λ = l =0.001* , maximum number of iterations `1000`
    , and convergence tolerance `tol = 0.001` . Note also that the items not rated
    (`0` rating values) are not considered in the computation, so an initial filling
    (imputation) is not necessary when using this method.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 SGD 函数具有默认参数，学习率 *α = 0.0001*，正则化参数 *λ = l = 0.001*，最大迭代次数 `1000`，以及收敛容忍度
    `tol = 0.001`。注意，未评分的项目（评分值为 `0`）在计算中不被考虑，因此在使用此方法时不需要进行初始填充（插补）。
- en: Non-negative matrix factorization (NMF)
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 非负矩阵分解 (NMF)
- en: 'This is a group of methods that finds the decomposition of the matrix *R* again
    as a product of two matrices *P* ( *N* × *K* ) and *Q* ( *M* × *K* ) (where *K*
    is a dimension of the feature space), but their elements are required to be non-negative.
    The general minimization problem is as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一组方法，它们将矩阵 *R* 的分解再次视为两个矩阵 *P*（ *N* × *K* ）和 *Q*（ *M* × *K* ）（其中 *K* 是特征空间的维度）的乘积，但它们的元素必须是非负的。一般最小化问题如下：
- en: '![Non-negative matrix factorization (NMF)](img/Image00484.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![非负矩阵分解 (NMF)](img/Image00484.jpg)'
- en: 'Here, α is a parameter that defines which regularization term to use (`0` squared,
    `1` a lasso regularization, or a mixture of them) and λ is the regularization
    parameter. Several techniques have been developed to solve this problem, such
    as projected gradient, coordinate descent, and non-negativity constrained least
    squares. It is beyond the scope of this book to discuss the details of these techniques,
    but we are going to use the coordinate descent method implemented in `sklearn
    NFM` wrapped in the following function:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，α 是一个参数，用于定义要使用哪种正则化项（`0` 为平方正则化，`1` 为 lasso 正则化，或它们的混合），λ 是正则化参数。已经开发了几种技术来解决此问题，例如投影梯度、坐标下降和非负约束最小二乘。本书的范围不包括讨论这些技术的细节，但我们将使用以下函数中实现的坐标下降方法：
- en: '![Non-negative matrix factorization (NMF)](img/Image00485.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![非负矩阵分解 (NMF)](img/Image00485.jpg)'
- en: Note that an imputation may be performed before the actual factorization takes
    place and that the function `fit_transform` returns the *P* matrix while the *Q^T*
    matrix is stored in the `nmf.components_` object. The *α* value is assumed to
    be `0` (squared regularization) and *λ = l =0.01* by default. Since the utility
    matrix has positive values (ratings), this class of methods is certainly a good
    fit to predict these values.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在因子分解实际发生之前可能已经进行了插补，并且函数 `fit_transform` 返回的是 *P* 矩阵，而 *Q^T* 矩阵存储在 `nmf.components_`
    对象中。默认情况下，*α* 值被假定为 `0`（平方正则化），*λ = l = 0.01*。由于效用矩阵具有正值（评分），这类方法无疑非常适合预测这些值。
- en: Singular value decomposition (SVD)
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 奇异值分解 (SVD)
- en: 'We have already discussed this algorithm in [Chapter 2](text00020.html#ch02
    "Chapter 2. Unsupervised Machine Learning") , *Unsupervised Machine Learning*
    , as a dimensionality reduction technique to approximate a matrix by decomposition
    into matrices *U* , Σ, *V* (you should read the related section in [Chapter 2](text00020.html#ch02
    "Chapter 2. Unsupervised Machine Learning") , *Unsupervised Machine Learning*
    , for further technical details). In this case, SVD is used as a matrix factorization
    technique, but an imputation method is required to initially estimate the missing
    data for each user; typically, the average of each utility matrix row (or column)
    or a combination of both (instead of leaving the zero values) is used. Apart from
    directly applying the SVD to the utility matrix, another algorithm that exploits
    an expectation-maximization (see [Chapter 2](text00020.html#ch02 "Chapter 2. Unsupervised
    Machine Learning") , *Unsupervised Machine Learning* ) can be used as follows,
    starting from the matrix ![Singular value decomposition (SVD)](img/Image00486.jpg)
    :'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[第2章](text00020.html#ch02 "第2章。无监督机器学习")中讨论了此算法，作为降维技术，通过分解为矩阵*U*、Σ、*V*来近似矩阵（你应该阅读[第2章](text00020.html#ch02
    "第2章。无监督机器学习")中的相关部分，以获取更多技术细节）。在这种情况下，SVD被用作矩阵分解技术，但需要一种插补方法来初始估计每个用户的缺失数据；通常，使用每个效用矩阵行（或列）的平均值或两者的组合（而不是保留零值）。除了直接将SVD应用于效用矩阵外，还可以使用以下算法，利用期望最大化（见[第2章](text00020.html#ch02
    "第2章。无监督机器学习")，*无监督机器学习*），从矩阵![奇异值分解（SVD）](img/Image00486.jpg)开始：
- en: '**m-step** : Perform ![Singular value decomposition (SVD)](img/Image00487.jpg)'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**m步**：执行![奇异值分解（SVD）](img/Image00487.jpg)'
- en: '**e-step** : ![Singular value decomposition (SVD)](img/Image00488.jpg)'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**e步**：![奇异值分解（SVD）](img/Image00488.jpg)'
- en: 'This procedure is repeated until the sum of squared errors ![Singular value
    decomposition (SVD)](img/Image00489.jpg) is less than a chosen tolerance. The
    code that implements this algorithm and the simple SVD factorization is as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此过程重复进行，直到平方误差之和![奇异值分解（SVD）](img/Image00489.jpg)小于所选容忍度。实现此算法和简单SVD分解的代码如下：
- en: '![Singular value decomposition (SVD)](img/Image00490.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![奇异值分解（SVD）](img/Image00490.jpg)'
- en: Note that the SVD is given by the `sklearn` library and both imputation average
    methods (user ratings' average and item ratings' average) have been implemented,
    although the function default is *none* , which means that the zero values are
    left as initial values. For the expect-maximization SVD, the other default parameters
    are the convergence tolerance (0.0001) and the maximum number of iterations (10,000).
    This method (especially with expectation-maximization) is slower than the ALS,
    but the accuracy is generally higher. Also note that the SVD method decomposes
    the utility matrix subtracted by the user ratings' mean since this approach usually
    performs better (the user ratings' mean is then added after the SVD matrix has
    been computed).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，奇异值分解（SVD）由`sklearn`库提供，并且两种插补平均方法（用户评分平均值和项目评分平均值）都已实现，尽管默认函数是*无*，这意味着零值保留为初始值。对于期望最大化SVD，其他默认参数是收敛容忍度（0.0001）和最大迭代次数（10,000）。这种方法（尤其是与期望最大化结合使用）比ALS慢，但准确性通常更高。另外请注意，SVD方法通过减去用户评分平均值来分解效用矩阵，因为这种方法通常表现更好（然后将在SVD矩阵计算后添加用户评分平均值）。
- en: We finish remarking that SVD factorization can also be used in memory-based
    CF to compare users or items in the reduced space (matrix *U* or *V^T* ) and then
    the ratings are taken from the original utility matrix (SVD with k-NN approach).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们完成备注，SVD分解也可以用于基于记忆的CF，在降维空间（矩阵*U*或*V^T*）中比较用户或项目，然后从原始效用矩阵中获取评分（使用k-NN方法的SVD）。
- en: CBF methods
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CBF方法
- en: 'This class of method relies on the data that describes the items, which is
    then used to extract the features of the users. In our MovieLens example, each
    movie *j* has a set of *G* binary fields to indicate if it belongs to one of the
    following genres: unknown, action, adventure, animation, children''s, comedy,
    crime, documentary, drama, fantasy, film noir, horror, musical, mystery, romance,
    sci-fi, thriller, war, or western.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这类方法依赖于描述项目的数据，然后用于提取用户的特征。在我们的MovieLens示例中，每部电影*j*都有一个包含*G*个二进制字段的一组，以指示它是否属于以下类型之一：未知、动作、冒险、动画、儿童、喜剧、犯罪、纪录片、剧情、奇幻、黑色电影、恐怖、音乐剧、悬疑、浪漫、科幻、惊悚、战争或西部。
- en: 'Based on these features (genres), each movie is described by a binary vector
    *m[j]* with *G* dimensions (number of movie genres) with entries equal to `1`
    for all the genres contained in movie *j* , or `0` otherwise. Given the `dataframe`
    that stores the utility matrix called `dfout` in the *Utility matrix* section
    mentioned earlier, these binary vectors *m[j]* are collected from the MoviesLens
    `database` into a dataframe using the following script:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些特性（类型），每部电影由一个具有*G*维度的二进制向量*m[j]*描述（电影类型的数量），其中包含电影*j*中包含的所有类型的条目等于`1`，否则为`0`。给定存储在*效用矩阵*部分提到的`dfout`效用矩阵的`dataframe`，这些二进制向量*m[j]*通过以下脚本从MovieLens
    `数据库`收集到一个dataframe中：
- en: '![CBF methods](img/Image00491.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![CBF方法](img/Image00491.jpg)'
- en: The movies content matrix has been saved in the `movies_content.csv` file ready
    to be used by the CBF methods.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 电影内容矩阵已保存在`movies_content.csv`文件中，以便CBF方法使用。
- en: The goal of the content-based recommendation system is to generate the user's
    profile with the same fields to indicate how much the user likes each genre. The
    problem with this method is that the content description of the item is not always
    available, so it is not always possible to employ this technique in the e-commerce
    environment. The advantage is that the recommendations to a specific user are
    independent of the other users' ratings, so it does not suffer from cold start
    problems due to an insufficient number of users' ratings for particular items.
    Two approaches are going to be discussed to find the best recommendation methodologies.
    The first methodology simply generates the user's profile associated with the
    average ratings of the movies seen by each user to each genre and the cosine similarity
    is used to find the movies most similar to the user preferences. The second methodology
    is a regularized linear regression model to generate the user's profile features
    from the ratings and the movie features so that the ratings of the movies not
    yet seen by each user can be predicted using these users' profiles.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 内容推荐系统的目标是生成具有相同字段的用户配置文件，以指示用户喜欢每个类型的程度。这种方法的问题在于项目的描述内容并不总是可用，因此在电子商务环境中并不总是可以采用这种技术。优点是针对特定用户的推荐不受其他用户评分的影响，因此不会因为特定项目的用户评分不足而遭受冷启动问题。将讨论两种方法来找到最佳的推荐方法。第一种方法简单地生成与每个用户观看的每部电影的平均评分相关的用户配置文件，并使用余弦相似度找到与用户偏好最相似的电影。第二种方法是一个正则化线性回归模型，用于从评分和电影特征生成用户配置文件特征，以便可以使用这些用户配置文件预测每个用户尚未观看的电影的评分。
- en: Item features average method
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 项目特征平均方法
- en: 'The approach is really simple and we are going to explain it using the features
    that describe the movies in the MovieLens example, as discussed previously. The
    objective of the method is to generate the movie genres'' preferences vector ![Item
    features average method](img/Image00492.jpg) for each user *i* (length equal to
    *G* ). This is done by calculating the average rating ![Item features average
    method](img/Image00493.jpg) and each genre entry *g* ; ![Item features average
    method](img/Image00494.jpg) is given by the sum of ratings of the movies seen
    by user *i* ( *Mi* ) containing the genre *g* , minus the average ![Item features
    average method](img/Image00493.jpg) and divided by the number of movies containing
    genre *g* :'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法真的很简单，我们将使用之前讨论过的MovieLens示例中描述电影的特性来解释它。该方法的目标是为每个用户*i*（长度等于*G*）生成电影类型的偏好向量![项目特征平均方法](img/Image00492.jpg)。这是通过计算平均评分![项目特征平均方法](img/Image00493.jpg)和每个类型条目*g*来完成的；![项目特征平均方法](img/Image00494.jpg)由用户*i*（*Mi*）观看的包含类型*g*的电影的评分总和减去平均![项目特征平均方法](img/Image00493.jpg)，然后除以包含类型*g*的电影数量：
- en: '![Item features average method](img/Image00495.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![项目特征平均方法](img/Image00495.jpg)'
- en: Here, *I[kg]* is 1 if the movie *k* contains genre *g* ; otherwise it is `0`
    .
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*I[kg]*如果电影*k*包含类型*g*则为1；否则为`0`。
- en: 'The vectors ![Item features average method](img/Image00496.jpg) are then compared
    to the binary vectors m *j* using the cosine similarity and the movies with the
    highest similarity values are recommended to the user *i* . The implementation
    of the method is given by the following Python class:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将向量![项目特征平均方法](img/Image00496.jpg)与二进制向量m*j*使用余弦相似度进行比较，并将相似度值最高的电影推荐给用户*i*。该方法的实现由以下Python类给出：
- en: '![Item features average method](img/Image00497.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![项目特征平均方法](img/Image00497.jpg)'
- en: The constructor stores the list of the movie titles in `Movieslist` and the
    movie features in the `Movies` vector, and the `GetRecMovies` function generates
    the user genres' preferences vector, that is, ![Item features average method](img/Image00496.jpg)
    (applying the preceding formula) called `features_u` , and returns the most similar
    items to this vector.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 构造函数将电影标题列表存储在 `Movieslist` 中，并将电影特征存储在 `Movies` 向量中，`GetRecMovies` 函数生成用户类型的偏好向量，即![项目特征平均方法](img/Image00496.jpg)（应用前面的公式）称为
    `features_u`，并返回与该向量最相似的项目。
- en: Regularized linear regression method
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则化线性回归方法
- en: 'The method learns the movie preferences of the users as parameters ![Regularized
    linear regression method](img/Image00498.jpg) of a linear model, with ![Regularized
    linear regression method](img/Image00499.jpg) , where *N* is the number of users
    and *G* is the number of features (movie genres) of each item. We add an intercept
    value on the user parameters *θ[i] (θ[i0] = 1* ) and also the movie vector *m[j]
    * that has the same value *m[j0] =1* , and so ![Regularized linear regression
    method](img/Image00500.jpg) . To learn the vectors of parameters q * [i] * , we
    solve the following regularized minimization problem:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法通过线性模型的参数![正则化线性回归方法](img/Image00498.jpg)学习用户的电影偏好，其中![正则化线性回归方法](img/Image00499.jpg)，其中
    *N* 是用户的数量，*G* 是每个项目的特征（电影类型）的数量。我们在用户参数 *θ[i] (θ[i0] = 1* ) 上添加一个截距值，以及具有相同值
    *m[j0] =1* 的电影向量 *m[j] *，因此![正则化线性回归方法](img/Image00500.jpg)。为了学习参数向量 q * [i] *，我们解决以下正则化最小化问题：
- en: '![Regularized linear regression method](img/Image00501.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![正则化线性回归方法](img/Image00501.jpg)'
- en: Here, *I[ij]* is `1` ; that is, user *i* watched the movie, otherwise *j* is
    `0` and λ is the regularization parameter (see [Chapter 3](text00024.html#page
    "Chapter 3. Supervised Machine Learning") , *Supervised Machine Learning* ).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*I[ij]* 是 `1`；即用户 *i* 观看了该电影，否则 *j* 是 `0`，λ 是正则化参数（参见[第3章](text00024.html#page
    "第3章. 监督机器学习")，*监督机器学习*）。
- en: 'The solution is given by applying gradient descent (see [Chapter 3](text00024.html#page
    "Chapter 3. Supervised Machine Learning") , *Supervised Machine Learning* ). For
    each user *i* :'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '解决方案是通过应用梯度下降法得到的（参见[第3章](text00024.html#page "第3章. 监督机器学习")，*监督机器学习*）。对于每个用户
    *i* :'
- en: '![Regularized linear regression method](img/Image00502.jpg) (k=0)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![正则化线性回归方法](img/Image00502.jpg) (k=0)'
- en: '![Regularized linear regression method](img/Image00503.jpg) (k>0)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![正则化线性回归方法](img/Image00503.jpg) (k>0)'
- en: Since we are adding `1` entry to the movie and user vectors respectively, the
    distinction between learning the intercept parameter ( *k=0* ) and the others
    is necessary (there is no possibility of overfitting on the intercept, so no need
    to regularize on it). After the parameters q *[i]* are learned, the recommendation
    is performed by simply applying for any missing rating *r[ij]* in the formula
    ![Regularized linear regression method](img/Image00504.jpg) .
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在电影和用户向量中分别添加了 `1` 个条目，因此区分学习截距参数（ *k=0* ）和其他参数是必要的（截距参数上没有过拟合的可能性，因此不需要对其进行正则化）。在参数
    q *[i]* 学习完成后，推荐通过简单地应用公式![正则化线性回归方法](img/Image00504.jpg)中的任何缺失评分 *r[ij]* 来执行。
- en: 'The method is implemented by the following code:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法通过以下代码实现：
- en: '![Regularized linear regression method](img/Image00505.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![正则化线性回归方法](img/Image00505.jpg)'
- en: The constructor of the class `CBF_regression` just performs the gradient descent
    to find the parameters *θ[i]* (called `Pmatrix` ) while the function `CalcRatings`
    finds the most similar rating vector in the stored utility matrix *R* (in case
    the user is not present in the utility matrix) and then it uses the corresponding
    parameters' vector to predict the missing ratings.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 类 `CBF_regression` 的构造函数仅执行梯度下降以找到参数 *θ[i]*（称为 `Pmatrix`），而函数 `CalcRatings`
    在存储的效用矩阵 *R* 中找到最相似的评分向量（如果用户不在效用矩阵中），然后使用相应的参数向量来预测缺失的评分。
- en: Association rules for learning recommendation system
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习推荐系统的关联规则
- en: 'Although this method is not used often in many commercial recommendation systems,
    association rules learning is certainly a method worth knowing about because of
    historical data reasons, and it can be employed to solve a wide range of problems
    in real-world examples. The main concept of this method is to find relationships
    among items based on some statistical measure of the occurrences of the items
    in the database of transactions *T* (for example, a transaction could be the movies
    seen by a user *i* or the products bought by *i* ). More formally, a rule could
    be *{item1,item2} => {item3}* , that is, a set of items *({item1,item2})* implies
    the presence of another set *({item3})* . Two definitions are used to characterize
    each *X=>Y* rule:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种方法在许多商业推荐系统中并不常用，但由于历史数据的原因，关联规则学习确实是一种值得了解的方法，因为它可以应用于解决现实世界中的各种问题。这种方法的主要概念是基于交易数据库
    *T* 中项目的发生频率的某些统计度量来寻找项目之间的关系（例如，一个交易可以是用户 *i* 看过的电影或 *i* 购买的商品）。更正式地说，一条规则可以是
    *{item1,item2} => {item3}*，即项目集合 *({item1,item2})* 意味着另一个项目集合 *({item3})* 的存在。使用两个定义来表征每个
    *X=>Y* 规则：
- en: '**Support** : Given a set of items *X* , the support *supp(X)* is the portion
    of transactions that contains the set *X* over the total transactions.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持度**：给定一个项目集合 *X*，支持度 *supp(X)* 是包含集合 *X* 的交易在总交易中的比例。'
- en: '**Confidence** : It is the fraction of transactions that contains the set *X*
    that also contains the set *Y: conf(X=>Y)=supp(X U Y)/supp(X)* . Note that the
    confidence *conf(X=>Y)* can have a very different value than *conf(Y=>X)* .'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**置信度**：它是包含集合 *X* 的交易中同时包含集合 *Y* 的交易的比例：conf(X=>Y)=supp(X U Y)/supp(X)*。请注意，置信度
    *conf(X=>Y)* 可以与 *conf(Y=>X)* 有非常不同的值。'
- en: 'Support represents the frequency of a certain rule on the transaction database,
    while the confidence indicates the probability that set *Y* will occur if set
    *X* is present. In other words, the support value is chosen to filter the number
    of rules we want to mine from the database (the higher the support, the fewer
    rules will satisfy the condition), while the confidence can be thought of as a
    *similarity* metric between sets *X* and *Y* . In the case of the movie recommendation
    system, the transaction database can be generated from the utility matrix *R*
    considering the movies each user likes, and we look for rules composed by sets
    *X* and *Y* that contain only one item (movie). These rules are collected in a
    matrix, `ass_matrix` , in which each entry *ass_matrixij* represents the confidence
    of the rule *i =>j* . The recommendations for the given user are obtained by simply
    multiplying the `ass_matrix` by his ratings `u_vec` : ![Association rules for
    learning recommendation system](img/Image00506.jpg) , and sorting all the values
    ![Association rules for learning recommendation system](img/Image00507.jpg) by
    the largest value corresponding to the most recommended movie to the least. Therefore,
    this method does not predict the ratings, but the list of movie recommendations;
    however, it is fast and it also works well with a sparse utility matrix. Note
    that to find all the possible combinations of items to form sets X and Y as fast
    as possible, two algorithms have been developed in the literature: *apriori* and
    *fp-growth* (not discussed here since we only require rules with one item per
    set *X* and *Y* ).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度表示交易数据库中某个规则的频率，而置信度表示在集合 *X* 存在的情况下，集合 *Y* 发生的概率。换句话说，支持度值被选择用来过滤从数据库中挖掘的规则数量（支持度越高，满足条件的规则越少），而置信度可以被视为集合
    *X* 和 *Y* 之间的 *相似度* 指标。在电影推荐系统的案例中，交易数据库可以通过考虑每个用户喜欢的电影来从效用矩阵 *R* 中生成，我们寻找由集合
    *X* 和 *Y* 组成的只包含一个项目（电影）的规则。这些规则收集在一个矩阵 `ass_matrix` 中，其中每个条目 `ass_matrix[i][j]`
    代表规则 *i => j* 的置信度。给定用户的推荐通过简单地乘以他的评分 `u_vec` 得到：![学习推荐系统的关联规则](img/Image00506.jpg)，然后按最大值对应的最推荐电影到最少推荐电影的顺序对所有值进行排序：![学习推荐系统的关联规则](img/Image00507.jpg)。因此，这种方法并不预测评分，而是提供电影推荐列表；然而，它速度快，并且与稀疏效用矩阵配合得很好。请注意，为了尽可能快地找到形成集合
    X 和 Y 的所有可能的项目组合，文献中已经开发了两种算法：*apriori* 和 *fp-growth*（这里没有讨论，因为我们只需要每个集合 *X* 和
    *Y* 中有一个项目的规则）。
- en: 'The class that implements the method is as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 实现该方法的类如下：
- en: '![Association rules for learning recommendation system](img/Image00508.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![学习推荐系统的关联规则](img/Image00508.jpg)'
- en: The class constructor takes as input parameters the utility matrix `Umatrix`
    , the movie titles list `Movieslist` , the support `min_support` , confidence
    `min_confidence` thresholds (default `0.1` ), and the `likethreshold` , which
    is the minimum rating value to consider a movie in a transaction (default `3`
    ). The function `combine_lists` finds all the possible rules, while `filterSet`
    just reduces the rules to the subset that satisfies the minimum support threshold.
    `calc_confidence_matrix` fills the `ass_matrix` with the confidence value that
    satisfies the minimum threshold (otherwise `0` is set by default) and `GetRecItems`
    returns the list of recommended movies given the user ratings `u_vec` .
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 类构造函数接受效用矩阵 `Umatrix`、电影标题列表 `Movieslist`、支持度 `min_support`、置信度 `min_confidence`
    阈值（默认 `0.1`）以及 `likethreshold` 作为输入参数，这是在事务中考虑电影的最小评分值（默认 `3`）。函数 `combine_lists`
    找到所有可能的规则，而 `filterSet` 只将规则减少到满足最小支持度阈值的子集。`calc_confidence_matrix` 用满足最小阈值的置信度值填充
    `ass_matrix`（否则默认设置为 `0`），而 `GetRecItems` 返回根据用户评分 `u_vec` 提供的推荐电影列表。
- en: Log-likelihood ratios recommendation system method
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对数似然比推荐系统方法
- en: The **log-likelihood ratio** ( **LLR** ) is a measure of how two events *A*
    and *B* are unlikely to be independent but occur together more than by chance
    (more than the single event frequency). In other words, the LLR indicates where
    a significant co-occurrence might exist between two events *A* and *B* with a
    frequency higher than a normal distribution (over the two events variables) would
    predict.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**对数似然比**（**LLR**）是衡量两个事件 *A* 和 *B* 不太可能是独立的，但比偶然发生（比单个事件频率更高）更可能一起发生的一个度量。换句话说，LLR
    指示两个事件 *A* 和 *B* 之间可能存在显著的共现，其频率高于正常分布（在两个事件变量上）预测的频率。'
- en: 'It has been shown by Ted Dunning ([http://tdunning.blogspot.it/2008/03/surprise-and-coincidence.html](http://tdunning.blogspot.it/2008/03/surprise-and-coincidence.html)
    ) that the LLR can be expressed based on binomial distributions for events A and
    B using a matrix *k* with the following entries:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 泰德·邓宁（[http://tdunning.blogspot.it/2008/03/surprise-and-coincidence.html](http://tdunning.blogspot.it/2008/03/surprise-and-coincidence.html)）已经证明，LLR
    可以基于事件 A 和 B 的二项分布，使用具有以下条目的矩阵 *k* 来表示：
- en: '|   | A | Not A |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '|    | A | 非 A |'
- en: '| --- | --- | --- |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **B** | *k11* | *k12* |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| **B** | *k11* | *k12* |'
- en: '| **Not B** | *k21* | *k22* |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| **非 B** | *k21* | *k22* |'
- en: '![Log-likelihood ratios recommendation system method](img/Image00509.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![对数似然比推荐系统方法](img/Image00509.jpg)'
- en: Here, ![Log-likelihood ratios recommendation system method](img/Image00510.jpg)
    and ![Log-likelihood ratios recommendation system method](img/Image00511.jpg)
    is the **Shannon** entropy that measures the information contained in the vector
    *p* .
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![对数似然比推荐系统方法](img/Image00510.jpg) 和 ![对数似然比推荐系统方法](img/Image00511.jpg)
    是衡量向量 *p* 中包含的信息的**香农熵**。
- en: 'Note: ![Log-likelihood ratios recommendation system method](img/Image00512.jpg)
    is also called the **Mutual Information** ( **MI** ) of the two event variables
    *A* and *B* , measuring how the occurrence of the two events depend on each other.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：![对数似然比推荐系统方法](img/Image00512.jpg)也称为两个事件变量 *A* 和 *B* 的**互信息**（**MI**），衡量两个事件的发生如何相互依赖。
- en: This test is also called *G2* , and it has been proven effective to detect co-occurrence
    of rare events (especially in text analysis), so it's useful with sparse databases
    (or a utility matrix, in our case).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这个测试也称为 *G2*，并且已被证明在检测罕见事件的共现（特别是在文本分析中）方面非常有效，因此对于稀疏数据库（或在我们的情况下的效用矩阵）非常有用。
- en: 'In our case, the events *A* and *B* are the like or dislike of two movies *A*
    and *B* by a user, where the event of *like a movie* is defined when the rating
    is greater than `3` (and vice versa for dislike). Therefore, the implementation
    of the algorithm is given by the following class:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，事件 *A* 和 *B* 是用户对电影 *A* 和 *B* 的喜欢或不喜欢，其中“喜欢电影”的事件定义为评分大于 `3`（反之亦然，对于不喜欢）。因此，算法的实现由以下类给出：
- en: '![Log-likelihood ratios recommendation system method](img/Image00513.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![对数似然比推荐系统方法](img/Image00513.jpg)'
- en: The constructor takes as input the utility matrix, the movie titles list, and
    the `likethreshold` that is used to define if a user likes a movie or not (default
    `3` ). The function `loglikelihood_ratio` generates the matrix with all the LLR
    values for each pair of movies *i* and *j* calculating the matrix *k* (`calc_k`
    ) and the corresponding LLR (`calc_llr` ). The function `GetRecItems` returns
    the recommended movie list for the user with ratings given by `u_vec` (the method
    does not predict the rating values).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 构造函数接受效用矩阵、电影标题列表和 `likethreshold` 作为输入，该阈值用于定义用户是否喜欢一部电影（默认值为 `3`）。函数 `loglikelihood_ratio`
    生成包含每个电影对 *i* 和 *j* 的所有 LLR 值的矩阵，计算矩阵 *k* (`calc_k`) 和相应的 LLR (`calc_llr`)。函数
    `GetRecItems` 返回具有 `u_vec`（该方法不预测评分值）给出的评分的用户推荐电影列表。
- en: Hybrid recommendation systems
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混合推荐系统
- en: 'This is a class of methods that combine both CBF and CF in a single recommender
    to achieve better results. Several approaches have been tried and can be summarized
    in the following categories:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一类方法，它们在单个推荐器中结合了协同过滤（CBF）和内容过滤（CF）以实现更好的结果。已经尝试了多种方法，可以总结为以下几类：
- en: '**Weighted** : The CBF and CF predicted ratings are combined in to some weighted
    mean.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加权**：将协同过滤和内容过滤预测的评分组合成一个加权平均值。'
- en: '**Mixed** : CF and CBF predicted movies are found separately and then merged
    in to a single list.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合**：分别找到协同过滤和内容过滤预测的电影，然后合并成一个单一列表。'
- en: '**Switched** : Based on certain criteria, the CF predictions or CBF predictions
    are used.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**切换**：基于某些标准，使用协同过滤预测或内容过滤预测。'
- en: '**Feature combination** : CF and CBF features are considered together to find
    the most similar users or items.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征组合**：将协同过滤和内容过滤的特征一起考虑，以找到最相似的用户或物品。'
- en: '**Feature augmentation** : Similar to feature combination, but the additional
    features are used to predict some ratings and then the main recommender uses these
    ratings to produce the recommendation list. For example, Content-Boosted Collaborative
    Filtering learns the ratings of unrated movies by a content-based model and then
    a collaborative approach is employed to define the recommendations.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征增强**：类似于特征组合，但使用额外的特征来预测某些评分，然后主要推荐器使用这些评分来生成推荐列表。例如，内容增强协同过滤通过基于内容的模型学习未评分电影的评分，然后采用协同方法来定义推荐。'
- en: 'As an example, we implement two hybrid feature combination methods merging
    an item''s features CBF method with a user-based CF method. The first method employs
    a user-based CF to the expanded utility matrix that now also contains the average
    rating per genre per user. The Python class is as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们实现了两种混合特征组合方法，将物品的协同过滤方法与基于用户的协同过滤方法相结合。第一种方法使用基于用户的协同过滤到扩展效用矩阵中，该矩阵现在还包含每个用户每个类型的平均评分。Python
    类如下：
- en: '![Hybrid recommendation systems](img/Image00514.jpg)![Hybrid recommendation
    systems](img/Image00515.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![混合推荐系统](img/Image00514.jpg)![混合推荐系统](img/Image00515.jpg)'
- en: The constructor generates the expanded utility matrix with the movies' genres
    average rating features associated to each user, `Umatrix_mfeats` . The function
    `CalcRatings` finds the K-NN using the Pearson correlation comparing the expanded
    feature vectors of the users. The second method applies and SVD factorization
    to the expanded utility matrix that contains the genre preferences for each user.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 构造函数生成与每个用户关联的电影类型平均评分特征的扩展效用矩阵 `Umatrix_mfeats`。函数 `CalcRatings` 通过比较用户的扩展特征向量使用皮尔逊相关系数找到
    K-NN。第二种方法将奇异值分解（SVD）应用于包含每个用户类型偏好的扩展效用矩阵。
- en: '![Hybrid recommendation systems](img/Image00516.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![混合推荐系统](img/Image00516.jpg)'
- en: As the SVD method, the ratings are subtracted with the user rating's average,
    and genre preferences are subtracted from the same user rating's average.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 与奇异值分解（SVD）方法一样，评分减去用户评分的平均值，类型偏好也减去相同的用户评分的平均值。
- en: Evaluation of the recommendation systems
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统的评估
- en: 'We have discussed all of the most relevant methods used in the commercial environment
    to date. The evaluation of a recommendation system can be executed offline (using
    only the data in the utility matrix) or online (using the utility matrix data
    and the new data provided in real time by each user using the website). The online
    evaluation procedures are discussed in [Chapter 7](text00050.html#page "Chapter 7. Movie
    Recommendation System Web Application") , *Movie Recommendation System Web Application*
    , together with a proper online movie recommendation system website. In this section,
    we will evaluate the performances of the methods using two offline tests often
    used to evaluate recommendation systems: root mean square error on ratings and
    ranking accuracy. For all the evaluations in which k-fold cross-validation (see
    [Chapter 3](text00024.html#page "Chapter 3. Supervised Machine Learning") , *Supervised
    Machine Learning* ) is applicable, a 5-fold cross-validation has been performed
    to obtain more objective results. The utility matrix has been divided in to 5
    folds using the following function:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了迄今为止在商业环境中使用的所有最相关的方法。推荐系统的评估可以离线执行（仅使用效用矩阵中的数据）或在线执行（使用效用矩阵数据以及每个用户通过网站实时提供的新的数据）。在线评估过程在
    [第 7 章](text00050.html#page "第 7 章。电影推荐系统网络应用")，*电影推荐系统网络应用* 中讨论，其中包括一个合适的在线电影推荐系统网站。在本节中，我们将使用两个常用于评估推荐系统的离线测试来评估方法的性能：评分的均方根误差和排名准确性。对于所有适用
    k 折交叉验证（见 [第 3 章](text00024.html#page "第 3 章。监督机器学习")，*监督机器学习*）的评估，已执行 5 折交叉验证以获得更客观的结果。效用矩阵已使用以下函数分为
    5 折：
- en: '![Evaluation of the recommendation systems](img/Image00517.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![推荐系统的评估](img/Image00517.jpg)'
- en: Here `df` is a data frame object that stores the utility matrix and *k* is the
    number of folds. In the validation set, for each user ratings' vector `u_vec`
    , half of the ratings have been hidden so that the real value can be predicted.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`df` 是一个存储效用矩阵的数据框对象，而 *k* 是折数。在验证集中，对于每个用户评分向量 `u_vec`，一半的评分已被隐藏，以便可以预测真实值。
- en: '![Evaluation of the recommendation systems](img/Image00518.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![推荐系统的评估](img/Image00518.jpg)'
- en: '`u_vals` stores the values to predict while `u_test` contains the ratings for
    testing the algorithms. Before we start to compare the different algorithms with
    the different measures, we load the utility matrix and the movie content matrix
    into data frames and split the data into 5 folds for cross-validation.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`u_vals` 存储预测的值，而 `u_test` 包含用于测试算法的评分。在我们开始比较不同算法的不同度量之前，我们将效用矩阵和电影内容矩阵加载到数据框中，并将数据分为
    5 折以进行交叉验证。'
- en: '![Evaluation of the recommendation systems](img/Image00519.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![推荐系统的评估](img/Image00519.jpg)'
- en: '`df_vals` contains the validation sets so the `HideRandomRatings` function
    presented in this section needs to be applied.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`df_vals` 包含验证集，因此需要应用本节中介绍的 `HideRandomRatings` 函数。'
- en: '![Evaluation of the recommendation systems](img/Image00520.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![推荐系统的评估](img/Image00520.jpg)'
- en: The data available in the `movies` matrix, the `movieslist` list, and the data
    frames `df_trains` , `vals_vecs_folds` , `tests_vecs_folds` are now ready to be
    used for training and validating all the methods discussed in the previous sections.
    We can start evaluating the **root mean square error** ( **RMSE** ).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在 `movies` 矩阵、`movieslist` 列表和数据框 `df_trains`、`vals_vecs_folds`、`tests_vecs_folds`
    中的数据已准备好用于训练和验证前几节中讨论的所有方法。我们可以开始评估 **均方根误差** ( **RMSE** )。
- en: Root mean square error (RMSE) evaluation
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 均方根误差 (RMSE) 评估
- en: 'This validation technique is applicable only on CF methods and linear regression
    CBF since the predicted ratings are generated only by these algorithms. Given
    each rating *rij* in `u_vals` in the validation sets, the predicted rating ![Root
    mean square error (RMSE) evaluation](img/Image00521.jpg) is calculated using each
    method and the root mean square error is obtained:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这种验证技术仅适用于 CF 方法和线性回归 CBF，因为这些算法仅生成预测评分。对于验证集中 `u_vals` 中的每个评分 *rij*，使用每种方法计算预测评分
    ![均方根误差 (RMSE) 评估](img/Image00521.jpg)，并得到均方根误差：
- en: RMSE = ![Root mean square error (RMSE) evaluation](img/Image00522.jpg)
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: RMSE = ![均方根误差 (RMSE) 评估](img/Image00522.jpg)
- en: Here, *Nval* is the number of ratings in the `u_vals` vectors. The presence
    of the square factor in this formula highly penalizes the large errors, so the
    methods with low RMSE (best values) are characterized by small errors spread over
    all the predicted ratings instead of large errors on few ratings, like the mean
    absolute error MAE=![Root mean square error (RMSE) evaluation](img/Image00523.jpg)
    would prefer.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*Nval*是`u_vals`向量中的评分数量。此公式中的平方因子极大地惩罚了大的误差，因此具有低RMSE（最佳值）的方法的特征是所有预测评分上的小误差分布，而不是像平均绝对误差MAE=![均方根误差（RMSE）评估](img/Image00523.jpg)所偏好的那样在少数评分上有大的误差。
- en: 'The code to calculate the RMSE for the memory-based CF user-based and item-based
    methods is as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 计算基于记忆的CF用户和基于物品的CF方法的RMSE的代码如下：
- en: '![Root mean square error (RMSE) evaluation](img/Image00524.jpg)![Root mean
    square error (RMSE) evaluation](img/Image00525.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![均方根误差（RMSE）评估](img/Image00524.jpg)![均方根误差（RMSE）评估](img/Image00525.jpg)'
- en: For each method, the SE function is called to compute the error for each fold
    and then the total RMSE of the folds is obtained.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每种方法，调用SE函数来计算每个折叠的错误，然后获得折叠的总RMSE。
- en: 'Using 5 nearest-neighbors for item-based CF with slope one and 20 for user-based
    CF, the methods have the following errors:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 使用5个最近邻进行基于物品的CF（斜率一）和20个用户基于CF，这些方法有以下误差：
- en: '| Method | RMSE | Number of Predicted Ratings |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | RMSE | 预测评分数量 |'
- en: '| --- | --- | --- |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **CF user-based** | 1.01 | 39,972 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| **基于CF用户** | 1.01 | 39,972 |'
- en: '| **CF item-based** | 1.03 | 39,972 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| **基于CF物品** | 1.03 | 39,972 |'
- en: '| **Slope one** | 1.08 | 39,972 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| **斜率一** | 1.08 | 39,972 |'
- en: '| **CF-CBF user-based** | 1.01 | 39,972 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| **CF-CBF用户** | 1.01 | 39,972 |'
- en: All have similar RMSE values but the best method is item-based Collaborative
    Filtering.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方法都具有相似的RMSE值，但最佳方法是基于物品的协同过滤。
- en: 'For the model-based methods, instead of not hidden validation ratings, `u_test`
    are included in the utility matrix for training and then the RMSE is calculated
    using the following script:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于模型的方法，而不是隐藏验证评分，`u_test`被包含在效用矩阵中进行训练，然后使用以下脚本来计算RMSE：
- en: '![Root mean square error (RMSE) evaluation](img/Image00526.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![均方根误差（RMSE）评估](img/Image00526.jpg)'
- en: 'The code calculates the RMSE only for CBF regression and SVD, and the reader
    can easily replicate the code to calculate the error for the other algorithms
    since most of the required code is just commented (SVD expect-maximization, SGD,
    ALS, and NMF). The results are shown in the following table ( *K* dimension feature
    space):'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码仅计算CBF回归和SVD的RMSE，读者可以轻松复制代码来计算其他算法的错误，因为大部分所需代码只是被注释了（SVD期望最大化，SGD，ALS和NMF）。结果如下表所示（
    *K* 维特征空间）：
- en: '| Method | RMSE | Number Predicted Ratings |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | RMSE | 预测评分数量 |'
- en: '| --- | --- | --- |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| CBF linear regression(a= 0.01, l =0.0001, its=50) | 1.09 | 39,972 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| CBF线性回归(a= 0.01, l =0.0001, its=50) | 1.09 | 39,972 |'
- en: '| SGD ( K=20, 50 its, a =0.00001, l=0.001) | 1.35 | 39,972 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| SGD ( K=20, 50 its, a =0.00001, l=0.001) | 1.35 | 39,972 |'
- en: '| ALS ( K=20, 50 its, l =0.001) | 2.58 | 39,972 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| ALS ( K=20, 50 its, l =0.001) | 2.58 | 39,972 |'
- en: '| SVD (`imputation` =`useraverage` , *K* =20) | 1.02 | 39,972 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| SVD (`imputation` =`useraverage` , *K* =20) | 1.02 | 39,972 |'
- en: '| SVD EM (`imputation` =`itemaverage` , iterations=30, *K* =20) | 1.03 | 39,972
    |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| SVD EM (`imputation` =`itemaverage` , iterations=30, *K* =20) | 1.03 | 39,972
    |'
- en: '| HYBRID SVD (`imputation` =`useraverage` , *K* =20) | 1.01 | 39,972 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| HYBRID SVD (`imputation` =`useraverage` , *K* =20) | 1.01 | 39,972 |'
- en: '| NMF ( *K* =20 `imputation` =`useraverage` ) | 0.97 | 39,972 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| NMF ( *K* =20 `imputation` =`useraverage` ) | 0.97 | 39,972 |'
- en: As expected, the ALS and SGD are the worst methods but they are discussed because
    they are instructive from a didactic point of view (they are also slow because
    the implementation is not as optimized as the methods from `sklearn` library).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期，ALS和SGD是最差的方法，但它们被讨论是因为从教学角度来看它们是有指导意义的（它们也较慢，因为实现没有像`sklearn`库中的方法那样优化）。
- en: All the others have similar results. However, just note that the hybrid methods
    have slightly better results than the corresponding SVD and CF user-based algorithms.
    Note that the movies to predict are chosen randomly so the results may vary.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 所有其他方法的结果都相似。然而，请注意，混合方法的结果略优于相应的SVD和基于用户的CF算法。请注意，要预测的电影是随机选择的，因此结果可能会有所不同。
- en: Classification metrics
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类度量
- en: 'The rating error RMSE does not really indicate the quality of a method but
    is an academic measure that is not really used in a commercial environment. The
    goal of a website is to present content that is relevant to the user regardless
    of the exact rating the user gives. In order to evaluate the relevance of the
    recommended items, the `precision` , `recall` , and `f1` (see [Chapter 2](text00020.html#ch02
    "Chapter 2. Unsupervised Machine Learning") , *Unsupervised Machine Learning*
    ) measures are used where the correct predictions are the items with ratings greater
    than 3\. These measures are calculated on the first 50 items returned by each
    algorithm (if the algorithm return a recommended list or the 50 items with the
    highest predicted ratings for the other methods). The function that calculates
    the measures is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 评分误差RMSE并不能真正反映方法的优劣，而是一个在商业环境中并不真正使用的学术度量。网站的目标是呈现与用户相关的内容，而不管用户给出的确切评分是多少。为了评估推荐项目的相关性，使用了`精确度`、`召回率`和`f1`（见[第2章](text00020.html#ch02
    "第2章. 无监督机器学习")，*无监督机器学习*）度量，其中正确的预测是评分大于3的项目。这些度量是在每个算法返回的前50个项目（如果算法返回推荐列表或预测评分最高的其他方法的50个项目）上计算的。计算这些度量的函数如下：
- en: '![Classification metrics](img/Image00527.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![分类度量](img/Image00527.jpg)'
- en: 'Here, Boolean `ratingsval` indicates if the method returns ratings or recommended
    list. We use the function `ClassificationMetrics` in the same way we compute the
    RMSE for all the methods, so the actual code to evaluate the measures is not shown
    (you can write it as an exercise). The following table summarizes the results
    for all the methods ( *neighs* is number of nearest-neighbors, *K* dimension feature
    space):'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，布尔值`ratingsval`表示该方法是否返回评分或推荐列表。我们使用`ClassificationMetrics`函数的方式与计算所有方法的RMSE相同，因此实际评估度量的代码没有显示（你可以将其作为练习来编写）。以下表格总结了所有方法的总结结果（*邻居数*是最近邻的数量，*K*是特征空间的维度）：
- en: '| Method | Precision | Recall | f1 | Number of Predicted Ratings |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 精确度 | 召回率 | f1 | 预测评分数量 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| CF user-based ( *neighs* =20) | 0.6 | 0.18 | 0.26 | 39,786 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| CF基于用户 ( *邻居数* =20) | 0.6 | 0.18 | 0.26 | 39,786 |'
- en: '| CBFCF user-based ( *neighs* =20) | 0.6 | 0.18 | 0.26 | 39,786 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| CBFCF基于用户 ( *邻居数* =20) | 0.6 | 0.18 | 0.26 | 39,786 |'
- en: '| HYBRID SVD ( *K* =20, `imputation` =`useraverage` ) | 0.54 | 0.12 | 0.18
    | 39,786 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| HYBRID SVD ( *K* =20, `填充` =`用户平均` ) | 0.54 | 0.12 | 0.18 | 39,786 |'
- en: '| CF item-based ( *neighs* =5) | 0.57 | 0.15 | 0.22 | 39,786 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| CF基于项 ( *邻居数* =5) | 0.57 | 0.15 | 0.22 | 39,786 |'
- en: '| Slope one ( *neighs* =5) | 0.57 | 0.17 | 0.24 | 39,786 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| Slope one ( *邻居数* =5) | 0.57 | 0.17 | 0.24 | 39,786 |'
- en: '| SVD EM ( *K* =20, iterations=30, `imputation` =`useraverage` ) | 0.58 | 0.16
    | 0.24 | 39,786 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| SVD EM ( *K* =20, 迭代次数=30, `填充` =`用户平均` ) | 0.58 | 0.16 | 0.24 | 39,786 |'
- en: '| SVD ( *K* =20, `imputation` =`itemaverage` ) | 0.53 | 0.12 | 0.18 | 39,786
    |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| SVD ( *K* =20, `填充` =`项目平均` ) | 0.53 | 0.12 | 0.18 | 39,786 |'
- en: '| CBF regression (a = 0.01, l =0.0001, iterations=50) | 0.54 | 0.13 | 0.2 |
    39,786 |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| CBF回归 (a = 0.01, l =0.0001, 迭代次数=50) | 0.54 | 0.13 | 0.2 | 39,786 |'
- en: '| SGD (K=20, a =0.00001, l =0.001) | 0.52 | 0.12 | 0.18 | 39,786 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| SGD (K=20, a =0.00001, l =0.001) | 0.52 | 0.12 | 0.18 | 39,786 |'
- en: '| ALS ( *K* =20, λ =0.001, iterations=50) | 0.57 | 0.15 | 0.23 | 39,786 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| ALS ( *K* =20, λ =0.001, 迭代次数=50) | 0.57 | 0.15 | 0.23 | 39,786 |'
- en: '| CBF average | 0.56 | 0.12 | 0.19 | 39,786 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| CBF平均 | 0.56 | 0.12 | 0.19 | 39,786 |'
- en: '| LLR | 0.63 | 0.3 | 0.39 | 39,786 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| LLR | 0.63 | 0.3 | 0.39 | 39,786 |'
- en: '| NMF ( *K* =20, λ =0.001, `imputation` =`ssss` ) | 0.53 | 0.13 | 0.19 | 39,786
    |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| NMF ( *K* =20, λ =0.001, `填充` =`ssss` ) | 0.53 | 0.13 | 0.19 | 39,786 |'
- en: '| Association rules | 0.68 | 0.31 | 0.4 | 39,786 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 关联规则 | 0.68 | 0.31 | 0.4 | 39,786 |'
- en: From the results you can see that the best method is association rules, and
    there is good precision also for the LLR, hybrid CBFCF user-based, and CF user-based
    methods. Note that the results may vary since the movies to predict have been
    randomly chosen.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 从结果中可以看出，最佳方法是关联规则，LLR、混合CBFCF基于用户和基于用户的CF方法也有很好的精度。请注意，由于预测的电影是随机选择的，因此结果可能会有所不同。
- en: Summary
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the most commonly used recommendation system methods
    from Collaborative Filtering and content-based filtering to two simple hybrid
    algorithms. Note also that in the literature are present *modal* recommendation
    systems in which different data (user gender, demographics, views, locations,
    devices, and so on) are incorporated in to the same algorithm. These methods are
    more advanced and more different data is needed to use them.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了从协同过滤和基于内容的过滤到两种简单混合算法的最常用推荐系统方法。注意，在文献中还有包含不同数据（用户性别、人口统计、观点、位置、设备等）的*模态*推荐系统。这些方法更高级，需要更多数据来使用它们。
- en: In [Chapter 7](text00050.html#page "Chapter 7. Movie Recommendation System Web
    Application") , *Movie Recommendation System Web Application* , we will implement
    a web recommendation system using the methods discussed in this chapter, but before
    that we will present the Django framework to build web applications in [Chapter
    6](text00046.html#ch06 "Chapter 6. Getting Started with Django") , *Getting Started
    with Django* .
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](text00050.html#page "第7章. 电影推荐系统网络应用")，*电影推荐系统网络应用*，我们将使用本章讨论的方法实现一个网络推荐系统，但在那之前，我们将在[第6章](text00046.html#ch06
    "第6章. Django入门")，*Django入门*中介绍Django框架来构建网络应用。
- en: 读累了记得休息一会哦~
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读累了记得休息一会哦~
- en: '**公众号：古德猫宁李**'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '**公众号：古德猫宁李**'
- en: 电子书搜索下载
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电子书搜索下载
- en: 书单分享
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 书单分享
- en: 书友学习交流
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 书友学习交流
- en: '**网站：**[沉金书屋 https://www.chenjin5.com](https://www.chenjin5.com)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**网站：**[沉金书屋](https://www.chenjin5.com)'
- en: 电子书搜索下载
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电子书搜索下载
- en: 电子书打包资源分享
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电子书打包资源分享
- en: 学习资源分享
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习资源分享
