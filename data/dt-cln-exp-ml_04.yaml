- en: '*Chapter 3*: Identifying and Fixing Missing Values'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第三章*：识别和修复缺失值'
- en: I think I speak for many data scientists when I say that rarely is there something
    so seemingly small and trivial that is as of much consequence as the missing value.
    We spend a good deal of our time worrying about missing values because they can
    have a dramatic, and surprising, effect on our analysis. This is most likely to
    happen when missing values are not random – that is, when they are correlated
    with a feature or target. For example, let's say we are doing a longitudinal study
    of earnings, but individuals with lower education are more likely to skip the
    earnings question each year. There is a decent chance that this will bias our
    parameter estimate for education.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当我说，很少有看似微小且微不足道的事情像缺失值那样具有如此重大的影响时，我想我代表了许多数据科学家。我们花费大量时间担心缺失值，因为它们可能会对我们的分析产生戏剧性和出人意料的效应。这种情况最有可能发生在缺失值不是随机的情况下——也就是说，当它们与一个特征或目标相关时。例如，假设我们正在进行一项关于收入的纵向研究，但受教育程度较低的人更有可能在每年跳过收入问题。这有可能导致我们对教育参数估计的偏差。
- en: Of course, identifying missing values is not even half of the battle. We then
    need to decide how to handle them. Do we remove any observation with a missing
    value for one or more features? Do we impute a value based on a sample-wide statistic
    such as the mean? Or do we assign a value based on a more targeted statistic,
    such as the mean for those in a certain class? Do we think of this differently
    for time series or longitudinal data where the nearest temporal value may make
    the most sense? Or should we use a more complex multivariate technique for imputing
    values, perhaps based on linear regression or **k-nearest neighbors** (**KNN**)?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，识别缺失值甚至不是战斗的一半。接下来，我们需要决定如何处理它们。我们是否要删除具有一个或多个特征缺失值的任何观测值？我们是否基于样本的统计量，如平均值，来插补一个值？或者我们是否基于更具体的统计量，如某个特定类别的平均值，来分配一个值？我们是否认为对于时间序列或纵向数据，最近的时序值可能最有意义？或者我们应该使用更复杂的多元技术来插补值，比如基于线性回归或**k近邻**（**KNN**）？
- en: The answer to all of these questions is *yes*. At some point, we will want to
    use each of these techniques. We will want to be able to answer why or why not
    to all of these possibilities when making a final choice about missing value imputation.
    Each will make sense, depending on the situation.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些问题的答案都是*是的*。在某个时候，我们将想要使用这些技术中的每一个。当我们做出关于缺失值插补的最终选择时，我们希望能够回答为什么或为什么不选择所有这些可能性。根据具体情况，每个答案都有意义。
- en: In this chapter, we'll look at techniques for identifying missing values for
    each feature or target, and for observations where values for a large number of
    the features are absent. Then, we will explore strategies for imputing values,
    such as setting values to the overall mean, to the mean for a given category,
    or forward filling. We will also examine multivariate techniques for imputing
    values for missing values and discuss when they are appropriate.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨识别每个特征或目标缺失值的技巧，以及对于大量特征值缺失的观测值的策略。然后，我们将探讨插补值的策略，例如将值设置为整体平均值、给定类别的平均值或前向填充。我们还将检查用于插补缺失值的多元技术，并讨论它们何时适用。
- en: 'Specifically, in this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，在本章中，我们将涵盖以下主题：
- en: Identifying missing values
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别缺失值
- en: Cleaning missing values
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清理缺失值
- en: Imputing values with regression
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用回归进行值插补
- en: Using KNN imputation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用KNN插补
- en: Using random forest for imputation
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用随机森林进行插补
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter will rely heavily on the pandas and NumPy libraries, but you don't
    require any prior knowledge of these. If you have installed Python from a scientific
    distribution, such as Anaconda or WinPython, these libraries are probably already
    installed. We will also be using the `statsmodels` library for linear regression,
    and machine learning algorithms from `sklearn` and `missingpy`. If you need to
    install any of these packages, you can do so by running `pip install [package
    name]` from a terminal window or Windows PowerShell.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将大量依赖pandas和NumPy库，但你不需要对这些库有任何先前的知识。如果你从科学发行版，如Anaconda或WinPython安装了Python，这些库可能已经安装好了。我们还将使用`statsmodels`库进行线性回归，以及来自`sklearn`和`missingpy`的机器学习算法。如果你需要安装这些包中的任何一个，你可以通过在终端窗口或Windows
    PowerShell中运行`pip install [package name]`来安装。
- en: Identifying missing values
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别缺失值
- en: Since identifying missing values is such an important part of an analyst's workflow,
    any tool we use needs to make it easy to regularly check for such values. Fortunately,
    pandas makes it quite simple to identify missing values.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由于识别缺失值是分析师工作流程中如此重要的一个部分，我们使用的任何工具都需要使其能够轻松地定期检查这些值。幸运的是，pandas 使得识别缺失值变得相当简单。
- en: We will be working with the `weeksworked16` and `weeksworked17` for weeks worked
    in 2016 and 2017, respectively.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将处理 `weeksworked16` 和 `weeksworked17`，分别代表 2016 年和 2017 年的工作周数。
- en: Note
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We will also work with the COVID-19 data again. This dataset has one observation
    for each country that specifies the total COVID-19 cases and deaths, as well as
    some demographic data for each country.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将再次处理 COVID-19 数据。这个数据集为每个国家提供了一个观测值，指定了总 COVID-19 病例和死亡人数，以及每个国家的某些人口统计数据。
- en: 'Follow these steps to identify our missing values:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤来识别我们的缺失值：
- en: 'Let''s start by loading the NLS and COVID-19 data:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从加载 NLS 和 COVID-19 数据开始：
- en: '[PRE0]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we count the number of missing values for columns that we may use as
    features. We can use the `isnull` method to test whether each feature value is
    missing. It will return `True` if the value is missing and `False` if not. Then,
    we can use `sum` to count the number of `True` values since `sum` will treat each
    `True` value as 1 and each `False` value as 0\. We use `axis=0` to sum over the
    rows for each column:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们计算可能用作特征的列的缺失值数量。我们可以使用 `isnull` 方法来测试每个特征值是否缺失。如果值缺失，则返回 `True`，如果不缺失则返回
    `False`。然后，我们可以使用 `sum` 来计算 `True` 值的数量，因为 `sum` 将每个 `True` 值视为 1，每个 `False` 值视为
    0。我们使用 `axis=0` 来对每个列的行进行求和：
- en: '[PRE1]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As we can see, 33 of the 221 countries have null values for `aged_65_older`.
    We have `life_expectancy` for almost all countries.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，221 个国家中有 33 个国家的 `aged_65_older` 有空值。我们几乎对所有国家的 `life_expectancy` 都有数据。
- en: 'If we want the number of missing values for each row, we can specify `axis=1`
    when summing. The following code creates a Series, `demovarsmisscnt`, with the
    number of missing values for the demographic features for each country. 181 countries
    have values for all of the features, 11 are missing values for four of the five
    features, and three are missing values for all of the features:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们想要每行的缺失值数量，我们可以在求和时指定 `axis=1`。以下代码创建了一个 Series，`demovarsmisscnt`，包含每个国家人口统计特征的缺失值数量。181
    个国家所有特征都有值，11 个国家缺失五个特征中的四个，三个国家缺失所有特征：
- en: '[PRE2]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let''s take a look at a few of the countries with four or more missing values.
    There is very little demographic data available for these countries:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看有四个或更多缺失值的几个国家。这些国家的人口统计数据非常少：
- en: '[PRE3]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let''s also check missing values for total cases and deaths. 29 countries have
    missing values for cases per million in population, and 36 have missing deaths
    per million:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们也检查一下总病例和死亡病例的缺失值。29 个国家在每百万人口中的病例数有缺失值，36 个国家每百万死亡人数有缺失值：
- en: '[PRE4]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We should also get a sense of which countries are missing both. 29 countries
    are missing both cases and deaths, and we only have both for 185 countries:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还应该了解哪些国家同时缺失这两个数据。29 个国家同时缺失病例和死亡数据，而我们只有 185 个国家同时拥有这两个数据：
- en: '[PRE5]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Sometimes, we have logical missing values that we need to transform into actual
    missing values. This happens when the dataset designers use valid values as codes
    for missing values. These are often values such as 9, 99, or 999, based on the
    allowable number of digits for the variable. Or it might be a more complicated
    coding scheme where there are codes for different reasons for there being missings.
    For example, in the NLS dataset, the codes reveal why the respondent did not provide
    an answer for a question: `-3` is an invalid skip, `-4` is a valid skip, and `-5`
    is a non-interview.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们会有逻辑缺失值，需要将其转换为实际缺失值。这发生在数据集设计者使用有效值作为缺失值的代码时。这些值通常是 9、99 或 999 等数值，基于变量的允许数字位数。或者可能是一个更复杂的编码方案，其中存在不同原因导致的缺失值的代码。例如，在
    NLS 数据集中，代码揭示了受访者为什么没有回答某个问题的原因：`-3` 是无效跳过，`-4` 是有效跳过，而 `-5` 是非访谈。
- en: 'The last four columns in the NLS DataFrame have data at the highest grade completed
    for the respondent''s mother and father, parental income, and mother''s age when
    the respondent was born. Let''s examine logical missings for those columns, starting
    with the highest grade that was completed for the respondent''s mother:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NLS DataFrame 的最后四列包含受访者母亲和父亲完成的最高学历、家庭收入以及受访者出生时母亲的年龄的数据。让我们从受访者母亲完成的最高的学历开始，检查这些列的逻辑缺失值：
- en: '[PRE6]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'There are 523 invalid skips and 165 valid skips. Let''s look at a few individuals
    that have at least one of these non-response values for these four features:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有523个无效跳过和165个有效跳过。让我们看看这四个特征中至少有一个非响应值的几个个体：
- en: '[PRE7]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'For our analysis, the reason why there is a non-response is not important.
    Let''s just count the number of non-responses for each of the features, regardless
    of the reason for the non-response:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们的分析，非响应的原因并不重要。让我们只计算每个特征的非响应数量，无论非响应的原因是什么：
- en: '[PRE8]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We should set these values to `missing` before using these features in our
    analysis. We can use `replace` to set all the values between -5 and -1 to `missing`.
    When we check for actual missings, we get the expected counts:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用这些特征进行分析之前，我们应该将这些值设置为`missing`。我们可以使用`replace`将-5到-1之间的所有值设置为`missing`。当我们检查实际缺失值时，我们得到预期的计数：
- en: '[PRE9]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This section demonstrated some very handy pandas techniques for identifying
    the number of missing values for each feature, as well as observations with a
    large number of missing values. We also learned how to find logical missing values
    and convert them into actual missings. Next, we'll take our first look at cleaning
    missing values.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 本节展示了识别每个特征的缺失值数量以及具有大量缺失值的观测值的一些非常有用的pandas技术。我们还学习了如何查找逻辑缺失值并将它们转换为实际缺失值。接下来，我们将首次探讨清理缺失值。
- en: Cleaning missing values
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清理缺失值
- en: 'In this section, we''ll go over some of the most straightforward approaches
    for handling missing values. This includes dropping observations where there are
    missing values; assigning a sample-wide summary statistic, such as the mean, to
    the missing values; and assigning values based on the mean value for an appropriate
    subset of the data:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍一些处理缺失值的最直接方法。这包括删除存在缺失值的观测值；将样本的汇总统计量，如平均值，分配给缺失值；以及根据数据适当子集的平均值分配值：
- en: 'Let''s load the NLS data and select some of the educational data:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载NLS数据并选择一些教育数据：
- en: '[PRE10]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can use the techniques we explored in the previous section to identify missing
    values. `schoolrecord.isnull().sum(axis=0)` gives us the number of missing values
    for each feature. The overwhelming majority of observations have missing values
    for `satverbal`, with 7,578 out of 8,984\. Only 31 observations have missing values
    for `highestdegree`:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用在前一节中探讨的技术来识别缺失值。`schoolrecord.isnull().sum(axis=0)`为我们提供了每个特征的缺失值数量。绝大多数观测值在`satverbal`上存在缺失值，共有7,578个，占8,984个观测值中的大部分。只有31个观测值在`highestdegree`上存在缺失值：
- en: '[PRE11]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can create a Series, `misscnt`, that specifies the number of missing features
    for each observation with `misscnt = schoolrecord.isnull().sum(axis=1)`. 946 observations
    have seven missing values for the educational data, while 11 are missing values
    for all eight features:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以创建一个Series，`misscnt`，它指定了每个观测值的缺失特征数量，`misscnt = schoolrecord.isnull().sum(axis=1)`。946个观测值在教育数据上有七个缺失值，而11个观测值的所有八个特征都缺失：
- en: '[PRE12]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s also take a look at a few observations with seven or more missing values.
    It looks like `highestdegree` is often the one feature that is present, which
    is not surprising, given that we have already discovered that `highestdegree`
    is rarely missing:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们再看看一些具有七个或更多缺失值的观测值。看起来`highestdegree`通常是唯一存在的特征，这并不令人惊讶，因为我们已经发现`highestdegree`很少缺失：
- en: '[PRE13]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s drop observations that have missing values for seven or more features
    out of eight. We can accomplish this by setting the `thresh` parameter of `dropna`
    to `2`. This will drop observations that have fewer than two non-missing values;
    that is, 0 or 1 non-missing values. We get the expected number of observations
    after using `dropna`; that is, 8,984 - 946 - 11 = 8,027:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们删除在八个特征中至少有七个缺失值的观测值。我们可以通过将`dropna`的`thresh`参数设置为`2`来实现这一点。这将删除具有少于两个非缺失值的观测值；也就是说，0个或1个非缺失值。使用`dropna`后，我们得到预期的观测值数量；即，8,984
    - 946 - 11 = 8,027：
- en: '[PRE14]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: There are a fair number of missing values for `gpaoverall` – that is, 2,980
    – though we have valid values for two-thirds of observations ((8,984 – 2,980)/8,984).
    We might be able to salvage this as a feature if we do a good job of imputing
    the missing values. This is likely more desirable than just removing these observations.
    We do not want to lose that data if we can avoid it, particularly if individuals
    with missing `gpaoverall` are different from others in ways that will matter for
    our predictions.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`gpaoverall`有相当数量的缺失值——即2,980个——尽管我们有三分之二的观测值是有效的（(8,984 - 2,980)/8,984）。如果我们能很好地填充缺失值，我们可能能够将其作为特征挽救。这比仅仅删除这些观测值更可取。如果我们能避免，我们不想失去这些数据，尤其是如果缺失`gpaoverall`的个体在其他方面与我们预测相关的方面有所不同。'
- en: 'The most straightforward approach is to assign the overall mean for `gpaoverall`
    to the missing values. The following code uses the pandas Series `fillna` method
    to assign all missing values of `gpaoverall` to the mean value of the Series.
    The first argument to `fillna` is the value you want for all missing values –
    in this case, `schoolrecord.gpaoverall.mean()`. Note that we need to remember
    to set the `inplace` parameter to `True` to overwrite the existing values:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最直接的方法是将`gpaoverall`的整体平均值分配给缺失值。以下代码使用pandas Series的`fillna`方法将`gpaoverall`的所有缺失值分配给Series的平均值。`fillna`的第一个参数是你想要为所有缺失值设置的值——在这种情况下，`schoolrecord.gpaoverall.mean()`。请注意，我们需要记住将`inplace`参数设置为`True`以覆盖现有值：
- en: '[PRE15]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The mean has not changed. However, there is a substantial reduction in the standard
    deviation, from 61.6 to 53.3\. This is one of the disadvantages of using the dataset's
    mean for all missing values.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 平均值没有变化。然而，标准差有显著下降，从61.6下降到53.3。这是使用数据集的平均值填充所有缺失值的一个缺点。
- en: 'The NLS data also has a fair number of missing values for `wageincome`. The
    following code shows that 3,893 observations have missing values:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NLS数据中`wageincome`也有相当数量的缺失值。以下代码显示有3,893个观测值有缺失值：
- en: '[PRE16]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Rather than assigning the mean value of `wageincome` to the missings, we could
    use another common technique for imputing values: we could assign the nearest
    non-missing value from a preceding observation. The `ffill` option of `fillna`
    will do this for us:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们与其将`wageincome`的平均值分配给缺失值，不如使用另一种常见的值填充技术：我们可以将前一个观测值中的最近非缺失值分配给缺失值。`fillna`的`ffill`选项会为我们完成这项工作：
- en: '[PRE17]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We could have done a backward fill instead by setting the `method` parameter
    of `fillna` to `bfill`. This sets missing values to the nearest following value.
    This produces the following output:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过将`fillna`的`method`参数设置为`bfill`来执行向后填充。这会将缺失值设置为最近的后续值。这会产生以下输出：
- en: '[PRE18]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If missing values are randomly distributed, then forward or backward filling
    has one advantage over using the mean: it is more likely to approximate the distribution
    of the non-missing values for the feature. Notice that the standard deviation
    did not drop substantially.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果缺失值是随机分布的，那么向前填充或向后填充与使用平均值相比有一个优点：它更有可能近似该特征的非缺失值的分布。请注意，标准差并没有大幅下降。
- en: There are times when it makes sense to base our imputation of values on the
    mean or median value for similar observations; say, those that have the same value
    for a related feature. If we are imputing values for feature X1, and X1 is correlated
    with X2, we can use the relationship between X1 and X2 to impute a value for X1
    that may make more sense than the dataset's mean. This is pretty straightforward
    when X2 is categorical. In this case, we can impute the mean value of X1 for the
    associated value of X2\.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，基于相似观测值的平均值或中位数来填充值是有意义的；比如说，那些对于相关特征具有相同值的观测值。如果我们正在为特征X1填充值，而X1与X2相关，我们可以利用X1和X2之间的关系来为X1填充一个可能比数据集的平均值更有意义的值。当X2是分类变量时，这通常很简单。在这种情况下，我们可以为X2的关联值填充X1的平均值。
- en: 'In the NLS DataFrame, weeks worked in 2017 correlates with the highest degree
    earned. The following code shows how the mean value of weeks worked changes with
    degree attainment. The mean for weeks worked is 39, but it is much lower for those
    without a degree (28.72) and much higher for those with a professional degree
    (47.20). In this case, it may be a better choice to assign 28.72 to the missing
    values for weeks worked for individuals who have not attained a degree, rather
    than 39:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在NLS DataFrame中，2017年的工作周数与获得的最高学位相关。以下代码显示了工作周数的平均值如何随着学位获得而变化。工作周数的平均值是39，但没有学位的人（28.72）要低得多，而有专业学位的人（47.20）要高得多。在这种情况下，将28.72分配给未获得学位的个人缺失的工作周数，而不是39，可能是一个更好的选择：
- en: '[PRE19]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following code assigns the mean value of weeks worked across observations
    with the same degree attainment level, for those observations missing weeks worked.
    We do this by using `groupby` to create a groupby DataFrame, `groupby([''highestdegree''])[''weeksworked17'']`.
    Then, we use `fillna` within `apply` to fill those missing values with the mean
    for the highest degree group. Notice that we make sure to only do this imputation
    for observations where the highest degree is not missing, `~nls97.highestdegree.isnull()`.
    We will still have missing values for observations that are missing both the highest
    degree and weeks worked:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码将缺失工作周数的观测值的平均工作周数分配给具有相同学位获得水平的观测值。我们通过使用`groupby`创建一个按`highestdegree`分组的DataFrame，即`groupby(['highestdegree'])['weeksworked17']`来实现这一点。然后，我们在`apply`中使用`fillna`来填充这些缺失值，用最高学位组的平均值来填充。请注意，我们确保只对最高学位不缺失的观测值进行插补，`~nls97.highestdegree.isnull()`。对于既缺失最高学位又缺失工作周数的观测值，我们仍然会有缺失值：
- en: '[PRE20]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: These imputation strategies – removing observations with missing values, assigning
    a dataset's mean or median, using forward or backward filling, or using a group
    mean for a correlated feature – are fine for many predictive analytics projects.
    They work best when the missing values are not correlated with the target. When
    that is true, imputing values allows us to retain the other information from those
    observations without biasing our estimates.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这些插补策略——删除缺失值的观测值、分配数据集的平均值或中位数、使用前向或后向填充，或使用相关特征的组均值——对于许多预测分析项目来说都是可行的。当缺失值与目标不相关时，它们效果最好。当这一点成立时，插补值允许我们保留这些观测值的其他信息，而不会对我们的估计产生偏差。
- en: Sometimes, however, that is not the case and more complicated imputation strategies
    are required. The next few sections will explore multivariate techniques for cleaning
    missing data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时情况并非如此，需要更复杂的插补策略。接下来的几节将探讨清理缺失数据的多变量技术。
- en: Imputing values with regression
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用回归插补值
- en: We ended the previous section by assigning a group mean to the missing values
    rather than the overall sample mean. As we discussed, this is useful when the
    feature that determines the groups is correlated with the feature that has the
    missing values. Using regression to impute values is conceptually similar to this,
    but we typically use it when the imputation will be based on two or more features.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一个部分结束时，将组均值分配给缺失值，而不是整体样本均值。正如我们讨论的那样，当确定组的特征与具有缺失值的特征相关时，这很有用。使用回归来插补值在概念上与此相似，但我们通常在插补将基于两个或更多特征时使用它。
- en: Regression imputation replaces a feature's missing values with values predicted
    by a regression model of correlated features. This particular kind of imputation
    is known as deterministic regression imputation since the imputed values all lie
    on the regression line, and no error or randomness is introduced.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 回归插补用相关特征的回归模型预测的值来替换一个特征的缺失值。这种特定类型的插补被称为确定性回归插补，因为插补值都位于回归线上，没有引入错误或随机性。
- en: One potential drawback of this approach is that it can substantially reduce
    the variance of the feature with missing values. We can use stochastic regression
    imputation to address this drawback. We will explore both approaches in this section.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的潜在缺点是它可能会显著降低具有缺失值的特征的方差。我们可以使用随机回归插补来解决这个问题。在本节中，我们将探讨这两种方法。
- en: 'The `wageincome` feature in the NLS dataset has several missing values. We
    can use linear regression to impute values. The wage income value is the reported
    earnings for 2016:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: NLS数据集中的`wageincome`特征有几个缺失值。我们可以使用线性回归来插补值。工资收入值是2016年报告的 earnings：
- en: Let's start by loading the NLS data again and checking for missing values for
    `wageincome` and features that might be correlated with `wageincome`. We also
    load the `statsmodels` library.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从再次加载 NLS 数据开始，并检查 `wageincome` 以及可能与 `wageincome` 相关的特征是否存在缺失值。我们还会加载 `statsmodels`
    库。
- en: 'The `info` method tells us that we are missing values for `wageincome` for
    nearly 3,000 observations. There are fewer missing values for the other features:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`info` 方法告诉我们，对于近 3,000 个观测值，我们缺少 `wageincome` 的值。其他特征的缺失值较少：'
- en: '[PRE21]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s convert the `highestdegree` feature into a numeric value. This will
    make the analysis we''ll be doing in the rest of this section easier:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将 `highestdegree` 特征转换为数值。这将使我们在本节剩余部分进行的分析更容易：
- en: '[PRE22]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As we''ve already discovered, we need to replace logical missing values for
    `parentincome` with actual missings. After that, we can run some correlations.
    Each of the features has some correlation with `wageincome`, particularly `hdegnum`:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如我们已经发现的，我们需要将 `parentincome` 的逻辑缺失值替换为实际缺失值。之后，我们可以进行一些相关性分析。每个特征都与 `wageincome`
    有关联，特别是 `hdegnum`：
- en: '[PRE23]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We should check whether observations with missing values for wage income are
    different in some important way from those with non-missing values. The following
    code shows that these observations have significantly lower degree attainment
    levels, parental income, and weeks worked. This is a clear case where assigning
    the overall mean would not be the best choice:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该检查对于工资收入存在缺失值的观测值是否在某些重要方面与那些没有缺失值的观测值不同。以下代码显示，这些观测值的学位获得水平、父母收入和工作周数显著较低。这是一个整体均值分配不是最佳选择的情况：
- en: '[PRE24]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let''s try regression imputation instead. Let''s start by cleaning up the data
    a little bit more. We can replace the missing `weeksworked16` and `parentincome`
    values with their means. We should also collapse `hdegnum` into those attaining
    less than a college degree, those with a college degree, and those with a post-graduate
    degree. We can set those up as dummy variables, with 0 or 1 values when they''re
    `False` or `True`, respectively. This is a tried and true method for treating
    categorical data in regression analysis as it allows us to estimate different
    *y* intercepts based on group membership:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们尝试回归插补。首先，让我们进一步清理数据。我们可以用平均值替换缺失的 `weeksworked16` 和 `parentincome` 值。我们还应该将
    `hdegnum` 合并到那些获得低于大学学位、拥有大学学位和拥有研究生学位的人群中。我们可以将它们设置为虚拟变量，当它们为 `False` 或 `True`
    时分别具有 0 或 1 的值。这是在回归分析中处理分类数据的一个经过验证的方法，因为它允许我们根据组别估计不同的 *y* 截距：
- en: '[PRE25]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: scikit-learn has preprocessing features that can help us with tasks like these.
    We will cover some of them in the next chapter.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: scikit-learn 具有预处理功能，可以帮助我们完成这类任务。我们将在下一章中介绍其中的一些。
- en: 'Next, we define a function, `getlm`, to run a linear model using the `statsmodels`
    module. This function has parameters for the name of the target or dependent variable,
    `ycolname`, and the names of the features or independent variables, `xcolnames`.
    Much of the work is done by the `fit` method of `statsmodels`; that is, `OLS(y,
    X).fit()`:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个函数 `getlm`，用于使用 `statsmodels` 模块运行线性模型。此函数具有目标或因变量名称的参数 `ycolname`
    和特征或自变量名称的参数 `xcolnames`。大部分工作是由 `statsmodels` 的 `fit` 方法完成的；即 `OLS(y, X).fit()`：
- en: '[PRE26]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, we can use the `getlm` function to get the parameter estimates and the
    model summary. All of the coefficients are positive and significant at the 95%
    level since they have `pvalues` less than 0.05\. As expected, wage income increases
    with the number of weeks worked and with parental income. Having a college degree
    gives a nearly $16K boost to earnings, compared with not having a college degree.
    A post-graduate degree bumps up the earnings prediction even more – almost $37K
    more than for those with less than a college degree:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 `getlm` 函数来获取参数估计和模型摘要。所有系数在 95% 的置信水平上都是正值且显著的，因为它们的 `pvalues` 小于
    0.05。正如预期的那样，工资收入随着工作周数和父母收入的增加而增加。拥有大学学位与没有大学学位相比，可以增加近 16K 的收入。研究生学位甚至能将收入预测提升更多——比那些低于大学学位的人多近
    37K：
- en: '[PRE27]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We can use this model to impute values for wage income where they are missing.
    We need to add a constant for the predictions since our model included a constant.
    We can convert the predictions into a DataFrame and then join it with the rest
    of the NLS data. Then, we can create a new wage income feature, `wageincomeimp`,
    that gets the predicted value when wage income is missing, and the original wage
    income value otherwise. Let''s also take a look at some of the predictions to
    see whether they make sense:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用这个模型来插补工资收入缺失处的值。由于我们的模型包含一个常数，我们需要为预测添加一个常数。我们可以将预测转换为DataFrame，然后将其与NLS数据的其余部分合并。然后，我们可以创建一个新的工资收入特征，`wageincomeimp`，当工资收入缺失时获取预测值，否则获取原始工资收入值。让我们也看看一些预测，看看它们是否有意义：
- en: '[PRE28]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We should look at some summary statistics for our prediction and compare those
    with the actual wage income values. The mean for the imputed wage income feature
    is lower than the original wage income mean. This is not surprising since, as
    we have seen, individuals with missing wage income have lower values for positively
    correlated features. What is surprising is the sharp reduction in the standard
    deviation. This is one of the drawbacks of deterministic regression imputation:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该查看我们预测的一些汇总统计信息，并将其与实际工资收入值进行比较。插补的工资收入特征的均值低于原始工资收入均值。这并不奇怪，因为我们已经看到，工资收入缺失的个体在正相关特征上的值较低。令人惊讶的是标准差的急剧下降。这是确定性回归插补的一个缺点：
- en: '[PRE29]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Stochastic regression imputation adds a normally distributed error to the predictions
    based on the residuals from our model. We want this error to have a mean of 0
    with the same standard deviation as our residuals. We can use NumPy's normal function
    for that with `np.random.normal(0, lm.resid.std(), nls97.shape[0])`. The `lm.resid.std()`
    parameter gets us the standard deviation of the residuals from our model. The
    final parameter value, `nls97.shape[0]`, indicates how many values to create;
    in this case, we want a value for every row in our data.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机回归插补基于我们模型的残差向预测中添加一个正态分布的错误。我们希望这个错误具有0的均值和与残差相同的方差。我们可以使用NumPy的正常函数来实现这一点，`np.random.normal(0,
    lm.resid.std(), nls97.shape[0])`。`lm.resid.std()`参数获取我们模型残差的方差。最后一个参数值，`nls97.shape[0]`，表示要创建多少个值；在这种情况下，我们希望为数据中的每一行创建一个值。
- en: 'We can join those values with our data and then add the error, `randomadd`,
    to our prediction:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些值与我们的数据合并，然后向我们的预测中添加错误，`randomadd`：
- en: '[PRE30]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This should increase the variance but not have much of an effect on the mean.
    Let''s confirm this:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这应该会增加方差，但不会对均值产生太大影响。让我们来确认这一点：
- en: '[PRE31]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: That seemed to have worked. Our stochastic prediction has pretty much the same
    standard deviation as the original wage income feature.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎已经起作用了。我们的随机预测与原始工资收入特征的方差几乎相同。
- en: Regression imputation is a good way to take advantage of all the data we have
    to impute values for a feature. It is often superior to the imputation methods
    we examined in the previous section, particularly when missing values are not
    random. If we use stochastic regression imputation, we will not artificially reduce
    our variance.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 回归插补是利用我们拥有的所有数据为特征插补值的好方法。它通常优于我们在上一节中检查的插补方法，尤其是在缺失值不是随机的情况下。如果我们使用随机回归插补，我们不会人为地降低我们的方差。
- en: Before we started using machine learning for this work, this was our go-to multivariate
    approach for imputation. We now have the option of using algorithms such as KNN
    for this task, which has advantages over regression imputation in some cases.
    KNN imputation, unlike regression imputation, does not assume a linear relationship
    between features, or that those features are normally distributed. We will explore
    KNN imputation in the next section.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用机器学习进行这项工作之前，这是我们用于插补的多变量方法的首选。现在我们有选择使用KNN等算法进行这项任务，在某些情况下，这种方法比回归插补具有优势。与回归插补不同，KNN插补不假设特征之间存在线性关系，或者那些特征是正态分布的。我们将在下一节中探讨KNN插补。
- en: Using KNN imputation
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用KNN插补
- en: KNN is a popular machine learning technique because it is intuitive, easy to
    run, and yields good results when there are not a large number of features and
    observations. For the same reasons, it is often used to impute missing values.
    As its name suggests, KNN identifies the k observations whose features are most
    similar to each observation. When it's used to impute missing values, KNN uses
    the nearest neighbors to determine what fill values to use.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: KNN是一种流行的机器学习技术，因为它直观、易于运行，并且在特征和观测数不是很多时能产生良好的结果。出于同样的原因，它通常用于插补缺失值。正如其名称所暗示的，KNN识别出与每个观测值特征最相似的k个观测值。当它用于插补缺失值时，KNN使用最近邻来确定要使用的填充值。
- en: 'We can use KNN imputation to do the same imputation we did in the previous
    section on regression imputation:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用KNN插补来完成与上一节回归插补相同的插补：
- en: 'Let''s start by importing `KNNImputer` from scikit-learn and loading the NLS
    data again:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从导入scikit-learn的`KNNImputer`并再次加载NLS数据开始：
- en: '[PRE32]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, we must prepare the features. We collapse degree attainment into three
    categories – less than college, college, and post-college degree – with each category
    represented by a different dummy variable. We must also convert the logical missing
    values for parent income into actual missings:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须准备特征。我们将学位获得合并为三个类别 – 大专以下、大学和大学后学位 – 每个类别由不同的虚拟变量表示。我们还必须将父母收入的逻辑缺失值转换为实际缺失值：
- en: '[PRE33]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let''s create a DataFrame that contains just the wage income and a few correlated
    features:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个只包含工资收入和一些相关特征的DataFrame：
- en: '[PRE34]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We are now ready to use the `fit_transform` method of the KNN imputer to get
    values for all the missing values in the passed DataFrame, `wagedata`. `fit_transform`
    returns a NumPy array that contains all the non-missing values from `wagedata`,
    plus the imputed ones. We can convert this array into a DataFrame using the same
    index as `wagedata`. This will make it easy to join the data in the next step.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已准备好使用KNN插补器的`fit_transform`方法来获取传递的DataFrame `wagedata`中所有缺失值的值。`fit_transform`返回一个包含`wagedata`中所有非缺失值以及插补值的NumPy数组。我们可以使用与`wagedata`相同的索引将此数组转换为DataFrame。这将使在下一步中合并数据变得容易。
- en: Note
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: We will use this technique throughout this book when we're working with the
    NumPy arrays that are returned when we use scikit-learn's `transform` and `fit_transform`
    methods.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将在整本书中使用这种技术，当我们使用scikit-learn的`transform`和`fit_transform`方法处理NumPy数组时。
- en: 'We need to specify the value to use for the number of nearest neighbors, for
    k. We use a general rule of thumb for determining k – the square root of the number
    of observations divided by 2 (*sqrt(N)/2*). That gives us 47 for k in this case:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要指定用于最近邻数量的值，即k。我们使用一个经验法则来确定k – 将观测数的平方根除以2 (*sqrt(N)/2*)。在这种情况下，k为47：
- en: '[PRE35]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, we must join the imputed wage income and weeks worked columns with the
    original NLS wage data and make a few observations. Notice that, with KNN imputation,
    we did not need to do any pre-imputation for missing values of correlated features
    (with regression imputation, we set weeks worked and parent income to their dataset
    means). That does mean, however, that KNN imputation will return an imputation,
    even when there is not a lot of information, such as with `101122` for `personid`
    in the following code block:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们必须将插补的工资收入和工作周数列与原始NLS工资数据合并，并做出一些观察。请注意，使用KNN插补时，我们不需要对相关特征的缺失值进行任何预插补（使用回归插补时，我们将工作周数和父母收入设置为数据集的平均值）。但这确实意味着，即使没有很多信息，KNN插补也会返回一个插补值，例如以下代码块中的`personid`的`101122`：
- en: '[PRE36]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let''s take a look at the summary statistics for the original and imputed features.
    Not surprisingly, the imputed wage income''s mean is lower than the original mean.
    As we discovered in the previous section, observations with missing wage incomes
    have lower degree attainment, weeks worked, and parental income. We also lose
    some of the variance in wage income:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来看看原始特征和插补特征的汇总统计。不出所料，插补工资收入的平均值低于原始平均值。正如我们在上一节中发现的，缺失工资收入的观测值在学位获得、工作周数和父母收入方面较低。我们还在工资收入中失去了一些方差：
- en: '[PRE37]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: KNN does imputations without making any assumptions about the distribution of
    the underlying data. With regression imputation, the standard assumptions for
    linear regression apply – that is, that there is a linear relationship between
    features and that they are distributed normally. If this is not the case, KNN
    is likely a better approach for imputation.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: KNN 填充时不假设底层数据的分布。在回归填充中，线性回归的标准假设适用——也就是说，特征之间存在线性关系，并且它们是正态分布的。如果情况不是这样，KNN
    可能是更好的填充方法。
- en: Despite these advantages, KNN imputation does have limitations. First, we must
    tune the model with an initial assumption about a good value for k, sometimes
    informed by little more than our knowledge of the size of the dataset. KNN is
    also computationally expensive and may be impractical for very large datasets.
    Finally, KNN imputation may not perform well when the correlation is weak between
    the feature to be imputed and the predictor features. An alternative to KNN for
    imputation, random forest imputation, can help us avoid the disadvantages of both
    KNN and regression imputation. We will explore random forest imputation in the
    next section.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这些优点，KNN 填充确实存在局限性。首先，我们必须根据对 k 的一个良好初始假设来调整模型，有时这个假设仅基于我们对数据集大小的了解。KNN 计算成本高，可能不适合非常大的数据集。最后，当要填充的特征与预测特征之间的相关性较弱时，KNN
    填充可能表现不佳。作为 KNN 填充的替代方案，随机森林填充可以帮助我们避免 KNN 和回归填充的缺点。我们将在下一节中探讨随机森林填充。
- en: Using random forest for imputation
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用随机森林进行填充
- en: Random forest is an ensemble learning method. It uses bootstrap aggregating,
    also known as bagging, to improve model accuracy. It makes predictions by repeatedly
    taking the mean of multiple trees, yielding progressively better estimates. We
    will use the `MissForest` algorithm in this section, which is an application of
    the random forest algorithm to find missing value imputation.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是一种集成学习方法。它使用自助聚合，也称为 bagging，来提高模型精度。它通过重复多次取多棵树的平均值来进行预测，从而得到越来越好的估计。在本节中，我们将使用
    `MissForest` 算法，这是随机森林算法的一个应用，用于寻找缺失值填充。
- en: '`MissForest` starts by filling in the median or mode (for continuous or categorical
    features, respectively) for missing values, then uses random forest to predict
    values. Using this transformed dataset, with missing values replaced with initial
    predictions, `MissForest` generates new predictions, perhaps replacing the initial
    prediction with a better one. `MissForest` will typically go through at least
    four iterations of this process.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`MissForest` 首先填充缺失值的均值或众数（对于连续或分类特征分别适用），然后使用随机森林来预测值。使用这个转换后的数据集，将缺失值替换为初始预测，`MissForest`
    生成新的预测，可能用更好的预测来替换初始预测。`MissForest` 通常会经历至少四次这样的迭代过程。'
- en: 'Running `MissForest` is even easier than using the KNN imputer, which we used
    in the previous section. We will impute values for the same wage income data that
    we worked with previously:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `MissForest` 甚至比使用我们在上一节中使用的 KNN 填充器还要简单。我们将为之前处理过的相同工资收入数据填充值：
- en: 'Let''s start by importing the `MissForest` module and loading the NLS data:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们先导入 `MissForest` 模块并加载 NLS 数据：
- en: '[PRE38]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Note
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: We need to address a conflict in the name of `sklearn.neighbors._base`, which
    can be either `sklearn.neighbors._base` or `sklearn.neighbors.base`, depending
    on your version of scikit-learn. At the time of writing, `MissForest` uses the
    older name.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们需要解决 `sklearn.neighbors._base` 名称冲突的问题，它可以是 `sklearn.neighbors._base` 或 `sklearn.neighbors.base`，具体取决于您使用的
    scikit-learn 版本。在撰写本文时，`MissForest` 使用的是旧名称。
- en: 'Let''s do the same data cleaning that we did in the previous section:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们进行与上一节相同的数据清理：
- en: '[PRE39]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now, we are ready to run `MissForest`. Notice that this process is quite similar
    to our process of using the KNN imputer:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好运行 `MissForest`。请注意，这个过程与我们使用 KNN 填充器的过程非常相似：
- en: '[PRE40]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Let''s take a look at a few of our imputed values and some summary statistics.
    The imputed values have a lower mean. This is not surprising, given that we have
    already learned that the missing values are not distributed randomly, that individuals
    with lower degree attainment and weeks worked are more likely to have missing
    values for wage income:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们查看一些填充值和一些汇总统计信息。填充值的均值较低，这是预料之中的，因为我们已经了解到缺失值不是随机分布的，拥有较低学历和较少工作周数的人更有可能缺少工资收入的数据：
- en: '[PRE41]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '`MissForest` uses the random forest algorithm to generate highly accurate predictions.
    Unlike KNN, it doesn''t need to be tuned with an initial value for k. It also
    is computationally less expensive than KNN. Perhaps most importantly, random forest
    imputation is less sensitive to low or very high correlation among features, though
    that was not an issue in this example.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`MissForest`使用随机森林算法生成高度准确的预测。与KNN不同，它不需要用k的初始值进行调优。它也比KNN计算成本更低。也许最重要的是，随机森林插补对特征之间低或非常高的相关性不太敏感，尽管在本例中这不是一个问题。'
- en: Summary
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored the most popular approaches for missing value imputation
    and discussed the advantages and disadvantages of each approach. Assigning an
    overall sample mean is not usually a good approach, particularly when observations
    with missing values are different from other observations in important ways. We
    can also substantially reduce our variance. Forward or backward filling allows
    us to maintain the variance in our data, but it works best when the proximity
    of observations is meaningful, such as with time series or longitudinal data.
    In most non-trivial cases, we will want to use a multivariate technique, such
    as regression, KNN, or random forest imputation.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了缺失值插补最流行的方法，并讨论了每种方法的优缺点。分配一个总体样本均值通常不是一个好的方法，尤其是在缺失值的观测与其他观测在重要方面不同时。我们还可以显著减少我们的方差。前向填充或后向填充允许我们保持数据中的方差，但它在观测的邻近性有意义时效果最好，例如时间序列或纵向数据。在大多数非平凡情况下，我们将希望使用多元技术，例如回归、KNN或随机森林插补。
- en: So far, we haven't touched on the important issue of data leakage and how to
    create separate training and testing datasets. To avoid data leakage, we need
    to work with training data independently of the testing data as soon as we begin
    our feature engineering. We will look at feature engineering in more detail in
    the next chapter. There, we will encode, transform, and scale features, while
    also being careful to separate the training and testing data.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们还没有涉及到数据泄露的重要问题以及如何创建独立的训练和测试数据集。为了避免数据泄露，我们需要在开始特征工程时独立于测试数据工作训练数据。我们将在下一章更详细地研究特征工程。在那里，我们将编码、转换和缩放特征，同时也要小心地将训练数据和测试数据分开。
