- en: Chapter 7. Detecting Face Parts and Overlaying Masks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章：检测面部部位和叠加口罩
- en: In the previous chapter, we learned about object classification and how machine
    learning can be used to achieve it. In this chapter, we will learn how to detect
    and track different face parts. We will start the discussion by understanding
    the face detection pipeline and how it's built from the ground up. We will then
    use this framework to detect face parts, such as eyes, ears, mouth, and nose.
    We will then learn how to overlay funny masks on these face parts in a live video.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了对象分类以及如何使用机器学习来实现它。在本章中，我们将学习如何检测和跟踪不同的面部部位。我们将从理解面部检测流程及其从底层构建的方式开始讨论。然后，我们将使用这个框架来检测面部部位，如眼睛、耳朵、嘴巴和鼻子。接下来，我们将学习如何在实时视频中将这些面部部位叠加有趣的口罩。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Working with Haar cascades
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Haar级联进行工作
- en: Integral images and why we need them
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整数图像及其必要性
- en: Building a generic face detection pipeline
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建通用的面部检测流程
- en: Detecting and tracking face parts, such as eyes, ears, nose, and mouth in a
    live video stream from the webcam
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在网络摄像头实时视频流中检测和跟踪面部部位，如眼睛、耳朵、鼻子和嘴巴
- en: Automatically overlaying facemasks, sunglasses, and a funny nose on a person's
    face in a video
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在视频中自动叠加面部口罩、太阳镜和有趣的鼻子
- en: Understanding Haar cascades
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Haar级联
- en: 'Haar cascades are cascade classifiers that are based on Haar features. What
    is a cascade classifier? It is simply a concatenation of a set of weak classifiers
    that can be used to create a strong classifier. Now, what do we mean by *weak*
    and *strong* classifiers? Weak classifiers are classifiers whose performances
    are limited. They don''t have the ability to classify everything correctly. If
    you keep the problem really simple, they might perform at an acceptable level.
    Strong classifiers, on the other hand, are really good at classifying our data
    correctly. We will see how it all comes together in the next couple of paragraphs.
    Another important part of Haar cascades is *Haar features*. These features are
    simple summations of rectangles and differences of those areas across the image.
    Let''s consider the following figure:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Haar级联是基于Haar特征的级联分类器。什么是级联分类器？它简单地说是一系列弱分类器的串联，这些弱分类器可以用来创建一个强分类器。那么，我们所说的*弱*和*强*分类器是什么意思呢？弱分类器是性能有限的分类器。它们没有正确分类所有事物的能力。如果你把问题简化到极致，它们可能达到可接受的水平。另一方面，强分类器在正确分类我们的数据方面非常出色。我们将在接下来的几段中看到这一切是如何结合在一起的。Haar级联的另一个重要部分是*Haar特征*。这些特征是矩形及其在图像中不同区域差值的简单求和。让我们考虑以下图示：
- en: '![Understanding Haar cascades](img/B04283_07_01.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![理解Haar级联](img/B04283_07_01.jpg)'
- en: If we want to compute the Haar features of the region ABCD, we just need to
    compute the difference between the white pixels and the colored pixels in that
    region. As shown in in the preceding four figures, we use different patterns to
    build Haar features. There are a lot of other patterns that are used as well.
    We do this at multiple scales to make the system scale invariant. When we say
    *multiple scales*, we just scale the image down to compute the same features again.
    This way, we can make it robust against size variations of a given object.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要计算区域ABCD的Haar特征，我们只需要计算该区域中白色像素和彩色像素之间的差异。如图所示，我们使用不同的模式来构建Haar特征。还有许多其他模式也被用作此目的。我们在多个尺度上这样做，以使系统对给定对象的尺寸变化具有鲁棒性。当我们说*多个尺度*时，我们只是将图像缩小以再次计算相同的特征。这样，我们可以使其对给定对象的尺寸变化具有鲁棒性。
- en: Note
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: As it turns out, this concatenation system is a very good method to detect objects
    in an image. In 2001, *Paul Viola* and *Michael Jones* published a seminal paper
    where they described a fast and effective method for object detection. If you
    are curious to learn more about it, you can check out their paper at [http://www.cs.ubc.ca/~lowe/425/slides/13-ViolaJones.pdf](http://www.cs.ubc.ca/~lowe/425/slides/13-ViolaJones.pdf).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，这种串联系统是检测图像中对象的一种非常好的方法。在2001年，*保罗·维奥拉*和*迈克尔·琼斯*发表了一篇开创性的论文，其中他们描述了一种快速有效的对象检测方法。如果你对此感兴趣，可以查看他们的论文：[http://www.cs.ubc.ca/~lowe/425/slides/13-ViolaJones.pdf](http://www.cs.ubc.ca/~lowe/425/slides/13-ViolaJones.pdf)。
- en: Let's dive deeper into it to understand what they actually did. They basically
    described an algorithm that uses a boosted cascade of simple classifiers. This
    system is used to build a strong classifier that can perform really well. Why
    did they use these simple classifiers instead of complex classifiers that can
    be more accurate? Well, using this technique, they were able to avoid the problem
    of having to build a single classifier that can perform with high precision. These
    single-step classifiers tend to be complex and computationally intensive. The
    reason why their technique works so well is because the simple classifiers can
    be weak learners, which means that they don't need to be complex.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨，了解它们实际上做了什么。他们基本上描述了一个使用简单分类器增强级联的算法。这个系统用于构建一个能够真正表现良好的强大分类器。为什么他们使用这些简单分类器而不是更准确、更复杂的分类器呢？嗯，使用这种技术，他们能够避免构建一个能够以高精度执行的单个分类器的问题。这些单步分类器往往很复杂且计算密集。他们的技术之所以如此有效，是因为简单分类器可以是弱学习器，这意味着它们不需要很复杂。
- en: Consider the problem of building a table detector. We want to build a system
    that will automatically learn what a table looks like. Based on this knowledge,
    it should be able to identify whether there is a table in any given image. To
    build this system, the first step is to collect images that can be used to train
    our system. There are a lot of techniques available in the machine learning world
    that can be used to train a system like this. Keep in mind that we need to collect
    a lot of table and non-table images if we want our system to perform well. In
    machine learning lingo, table images are called **positive** samples and the non-table
    images are called **negative** samples. Our system will ingest this data and then
    learn to differentiate between these two classes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑构建表格检测器的问题。我们希望构建一个能够自动学习表格外观的系统。基于这个知识，它应该能够识别任何给定图像中是否存在表格。为了构建这个系统，第一步是收集可以用来训练我们系统的图像。在机器学习领域有许多技术可以用来训练这样的系统。记住，如果我们想让我们的系统表现良好，我们需要收集大量的表格和非表格图像。在机器学习的术语中，表格图像被称为**正样本**，而非表格图像被称为**负样本**。我们的系统将摄取这些数据，然后学习区分这两类。
- en: In order to build a real-time system, we need to keep our classifier nice and
    simple. The only concern is that simple classifiers are not very accurate. If
    we try to make them more accurate, then they will end up being computationally
    intensive and hence slow. This kind of trade-off between accuracy and speed is
    very common in machine learning. So, we will overcome this problem by concatenating
    a bunch of weak classifiers to create a strong and unified classifier. We don't
    need the weak classifiers to be very accurate. To ensure the quality of the overall
    classifier, *Viola* and *Jones* have described a nifty technique in the cascading
    step. You can go through the paper to understand the complete system.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建一个实时系统，我们需要保持我们的分类器既简洁又简单。唯一的问题是简单的分类器并不非常准确。如果我们试图使它们更准确，那么它们最终会变得计算密集，从而变慢。这种在准确性和速度之间的权衡在机器学习中非常常见。因此，我们将通过连接多个弱分类器来创建一个强大且统一的分类器来克服这个问题。我们不需要弱分类器非常准确。为了确保整体分类器的质量，*Viola*
    和 *Jones* 在级联步骤中描述了一种巧妙的技术。你可以阅读这篇论文来了解完整的系统。
- en: Now that we understand the general pipeline, let's see how to build a system
    that can detect faces in a live video. The first step is to extract features from
    all the images. In this case, the algorithms need these features to learn and
    understand what faces look like. They used Haar features in their paper to build
    the feature vectors. Once we extract these features, we pass them through a cascade
    of classifiers. We just check all the different rectangular subregions and keep
    discarding the ones that don't have faces in them. This way, we arrive at the
    final answer quickly to see whether a given rectangle contains a face or not.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了整个流程，让我们看看如何构建一个能够在实时视频中检测人脸的系统。第一步是从所有图像中提取特征。在这种情况下，算法需要这些特征来学习和理解人脸的外观。他们在论文中使用了Haar特征来构建特征向量。一旦我们提取了这些特征，我们就将它们通过一系列分类器。我们只是检查所有不同的矩形子区域，并丢弃其中没有人脸的子区域。这样，我们就可以快速得出结论，看给定的矩形是否包含人脸。
- en: What are integral images?
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是积分图？
- en: 'In order to extract these Haar features, we need to calculate the sum of the
    pixel values enclosed in many rectangular regions of the image. To make it scale
    invariant, we need to compute these areas at multiple scales (that is, for various
    rectangle sizes). If implemented naively, this would be a very computationally
    intensive process. We would have to iterate over all the pixels of each rectangle,
    including reading the same pixels multiple times if they are contained in different
    overlapping rectangles. If you want to build a system that can run in real time,
    you cannot spend so much time in computation. We need to find a way to avoid this
    huge redundancy during the area computation because we iterate over the same pixels
    multiple times. To avoid this, we can use something called **integral images**.
    These images can be initialized in a linear time (by iterating only twice over
    the image) and can then be provided with the sum of pixels inside any rectangle
    of any size by reading only four values. To understand it better, let''s take
    a look at the following figure:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提取这些Haar特征，我们需要计算图像中许多矩形区域内像素值的总和。为了使其尺度不变，我们需要在多个尺度（即不同矩形大小）上计算这些面积。如果天真地实现，这将是一个非常计算密集的过程。我们必须遍历每个矩形的所有像素，包括如果它们包含在不同的重叠矩形中，则多次读取相同的像素。如果你想要构建一个可以在实时运行的系统，你不能在计算上花费这么多时间。我们需要找到一种方法来避免在面积计算中的这种巨大冗余，因为我们多次遍历相同的像素。为了避免这种情况，我们可以使用一种称为**积分图像**的东西。这些图像可以在线性时间内初始化（通过只遍历图像两次）并且可以通过读取仅四个值来提供任何大小矩形内像素的总和。为了更好地理解它，让我们看一下下面的图：
- en: '![What are integral images?](img/B04283_07_02.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![什么是积分图像？](img/B04283_07_02.jpg)'
- en: 'If we want to calculate the area of any rectangle in our image, we don''t have
    to iterate through all the pixels in that region. Let''s consider a rectangle
    formed by the top-left point in the image and any point P as the opposite corner.
    Let A[P] denote the area of this rectangle. For example, in the preceding figure,
    A[B] denotes the area of the 5 X 2 rectangle formed by taking the top-left point
    and B as opposite corners. Let''s take a look at the following figure for clarity
    purposes:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想在我们的图像中计算任何矩形的面积，我们不必遍历该区域的所有像素。让我们考虑由图像中的左上角点和任何点P作为对角线顶点形成的矩形。让我们用A[P]表示这个矩形的面积。例如，在前面图中，A[B]表示由左上角点和B作为对角线顶点形成的5
    X 2矩形的面积。为了更清晰地说明，让我们看一下下面的图：
- en: '![What are integral images?](img/B04283_07_03.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![什么是积分图像？](img/B04283_07_03.jpg)'
- en: 'Let''s take a look at the top-left diagram in the preceding figure. The colored
    pixels indicate the area between the top-left pixel and point A. This is denoted
    by A[A]. The remaining diagrams are denoted by their respective names: A[B], A[C],
    and A[D]. Now, if we want to calculate the area of the rectangle ABCD, as shown
    in the preceding figure, we will use the following formula:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下前面图中的左上角图。彩色像素表示从左上角像素到点A之间的区域。这表示为A[A]。其余的图分别用它们各自的名字表示：A[B]、A[C]和A[D]。现在，如果我们想计算前面图中所示矩形ABCD的面积，我们将使用以下公式：
- en: Area of the rectangle ABCD = A[C] – (A[B] + A[D] - A[A])
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 矩形ABCD的面积 = A[C] – (A[B] + A[D] - A[A])
- en: What's so special about this particular formula? As we know, extracting Haar
    features from the image includes computing these summations, and we would have
    to do it for a lot of rectangles at multiple scales in the image. A lot of these
    calculations are repetitive because we would be iterating over the same pixels
    over and over again. It is so slow that building a real-time system wouldn't be
    feasible. Hence, we need this formula. As you can see, we don't have to iterate
    over the same pixels multiple times. If we want to compute the area of any rectangle,
    all the values on the right-hand side of the previous equation are readily available
    in our integral image. We just use pick up the right values, substitute them in
    the previous equation, and extract the features.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定公式有什么特别之处呢？正如我们所知，从图像中提取Haar特征包括计算这些求和，而且我们不得不在图像中的多个尺度上对很多矩形进行计算。这些计算中的许多都是重复的，因为我们不得不反复遍历相同的像素。这非常慢，以至于构建实时系统将不可行。因此，我们需要这个公式。正如你所见，我们不必多次遍历相同的像素。如果我们想计算任何矩形的面积，上一个方程右侧的所有值都在我们的积分图像中
    readily available。我们只需取出正确的值，将它们代入上一个方程，并提取特征。
- en: Overlaying a facemask in a live video
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在实时视频中叠加人脸面具
- en: 'OpenCV provides a nice face detection framework. We just need to load the cascade
    file and use it to detect the faces in an image. When we capture a video stream
    from the webcam, we can overlay funny masks on top of our faces. It will look
    something like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV提供了一个优秀的面部检测框架。我们只需要加载级联文件，并使用它来检测图像中的面部。当我们从摄像头捕获视频流时，我们可以在我们的脸上叠加有趣的口罩。它看起来可能像这样：
- en: '![Overlaying a facemask in a live video](img/B04283_07_04.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![在实时视频中叠加口罩](img/B04283_07_04.jpg)'
- en: 'Let''s take a look at the main parts of the code to see how to overlay the
    preceding mask on top of the face in the input video stream. The complete code
    is available in the downloadable code bundle provided along with this book:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看代码的主要部分，看看如何将前面的口罩叠加到输入视频流中的脸部上方。完整的代码包含在本书提供的可下载代码包中：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s see what happened here. We start reading input frames from the webcam
    and resize it to our size of choice. The captured frame is a color image and face
    detection works on grayscale images. So, we convert it to grayscale and equalize
    the histogram. Why do we need to equalize the histogram? We need to do this in
    order to compensate for any kind of issues, such as lighting, saturation, and
    so on. If the image is too bright or too dark, the detection will be poor. So,
    we need to equalize the histogram to ensure that our image has a healthy range
    of pixel values:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这里发生了什么。我们从摄像头读取输入帧，并将其调整到我们选择的大小。捕获的帧是一个彩色图像，而人脸检测是在灰度图像上进行的。因此，我们将其转换为灰度并均衡直方图。为什么我们需要均衡直方图？我们需要这样做是为了补偿任何类型的问题，例如光照、饱和度等。如果图像太亮或太暗，检测效果会差。因此，我们需要均衡直方图，以确保我们的图像具有健康的像素值范围：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'At this point, we know where the face is. So, we extract the region of interest
    to overlay the mask in the right position:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们知道脸部的位置。因此，我们提取感兴趣的区域，以便在正确的位置叠加口罩：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We isolated the pixels associated with the face mask. Now, we want to overlay
    the mask in such a way that it doesn''t look like a rectangle. We want the exact
    boundaries of the overlaid object so that it looks natural. Let''s go ahead and
    overlay the mask now:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经隔离了与脸部口罩相关的像素。现在，我们想要以不像是矩形的方式叠加口罩。我们想要叠加对象的精确边界，使其看起来自然。现在我们就来叠加口罩：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: What happened in the code?
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码中发生了什么？
- en: 'The first thing to note is that this code takes two input arguments: the face
    cascade `xml` file and the mask image. You can use the `haarcascade_frontalface_alt.xml`
    and `facemask.jpg` files that are provided. We need a classifier model that can
    be used to detect faces in an image, and OpenCV provides a prebuilt xml file that
    can be used for this purpose. We use the `faceCascade.load()`function to load
    the `xml` file and also check whether the file has been loaded correctly.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要注意的是，此代码接受两个输入参数：面部级联`xml`文件和口罩图像。你可以使用提供的`haarcascade_frontalface_alt.xml`和`facemask.jpg`文件。我们需要一个分类器模型，它可以用来检测图像中的面部，OpenCV提供了一个预构建的xml文件，可用于此目的。我们使用`faceCascade.load()`函数加载`xml`文件，并检查文件是否已正确加载。
- en: We initiate the video capture object to capture the input frames from the webcam.
    We then convert it to grayscale to run the detector. The `detectMultiScale` function
    is used to extract the boundaries of all the faces in the input image. We may
    have to scale down the image according to our needs, so the second argument in
    this function takes care of this. This scaling factor is the jump that we take
    at each scale. Since we need to look for faces at multiple scales, the next size
    will be 1.1 times bigger than the current size. The last parameter is a threshold
    that specifies the number of adjacent rectangles that are needed to keep the current
    rectangle. It can be used to increase the robustness of the face detector.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始化视频捕获对象以捕获摄像头输入的帧。然后我们将其转换为灰度以运行检测器。`detectMultiScale`函数用于提取输入图像中所有面部的边界。我们可能需要根据需要缩小图像，因此该函数的第二个参数负责这一点。这个缩放因子是我们每次缩放时采取的跳跃。由于我们需要在多个尺度上查找面部，下一个大小将是当前大小的1.1倍。最后一个参数是一个阈值，它指定了需要保留当前矩形的相邻矩形数量。它可以用来增加面部检测器的鲁棒性。
- en: We start the `while` loop and keep detecting the face in every frame until the
    user presses the *Esc* key. Once we detect a face, we need to overlay a mask on
    it. We may have to modify the dimensions slightly to ensure that the mask fits
    nicely. This customization is slightly subjective and it depends on the mask that's
    being used. Now that we have extracted the region of interest, we need to place
    our mask on top of this region. If we overlay the mask with its white background,
    it will look weird. We need to extract the exact curvy boundaries of the mask
    and overlay it. We want the skull-mask pixels to be visible and the remaining
    area to be transparent.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们启动`while`循环，并在用户按下*Esc*键之前，在每一帧中持续检测人脸。一旦我们检测到人脸，我们就需要在其上叠加一个掩码。我们可能需要稍微调整尺寸以确保掩码贴合得很好。这种定制略为主观，并且取决于所使用的掩码。现在我们已经提取了感兴趣区域，我们需要在这个区域上方放置我们的掩码。如果我们用带有白色背景的掩码叠加，看起来会很奇怪。我们需要提取掩码的确切曲线边界并叠加它。我们希望颅骨掩码像素可见，而剩余区域透明。
- en: As we can see, the input mask has a white background. So, we create a mask by
    applying a threshold to the mask image. Using trial and error, we can see that
    a threshold of 240 works well. In the image, all the pixels with an intensity
    value greater than 240 will become 0, and all the others will become 255\. As
    far as the region of interest is concerned in the image, we need to black out
    all the pixels in this region. To do this, we simply use the inverse of the mask
    that was just created. In the last step, we just add the masked versions to produce
    the final output image.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，输入掩码有一个白色背景。因此，我们通过对掩码图像应用阈值来创建掩码。通过试错法，我们可以看到240的阈值效果很好。在图像中，所有强度值大于240的像素将变为0，而其他所有像素将变为255。至于图像中的感兴趣区域，我们需要将这个区域内的所有像素变黑。为此，我们只需使用刚刚创建的掩码的逆掩码即可。在最后一步，我们将掩码版本相加以生成最终的输出图像。
- en: Get your sunglasses on
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 戴上你的太阳镜
- en: Now that we understand how to detect faces, we can generalize this concept to
    detect different parts of the face. We will use an eye detector to overlay sunglasses
    in a live video. It's important to understand that the Viola-Jones framework can
    be applied to any object. The accuracy and robustness will depend on the uniqueness
    of the object. For example, a human face has very unique characteristics, so it's
    easy to train our system to be robust. On the other hand, an object such as a
    towel is too generic, and there are no distinguishing characteristics as such.
    So, it's more difficult to build a robust towel detector.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了如何检测人脸，我们可以将这个概念推广到检测人脸的不同部分。我们将使用眼睛检测器在实时视频中叠加太阳镜。重要的是要理解Viola-Jones框架可以应用于任何对象。准确性和鲁棒性将取决于对象的独特性。例如，人脸具有非常独特的特征，因此很容易训练我们的系统以使其鲁棒。另一方面，像毛巾这样的对象过于通用，没有这样的区分特征。因此，构建鲁棒的毛巾检测器会更困难。
- en: 'Once you build the eye detector and overlay glasses on top of it, it will look
    something like this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你构建了眼睛检测器并在其上方叠加眼镜，它看起来会是这样：
- en: '![Get your sunglasses on](img/B04283_07_05.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![戴上你的太阳镜](img/B04283_07_05.jpg)'
- en: 'Let''s take a look at the main parts of the code:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看代码的主要部分：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As we can see here, we run the eye detector only in the face region. We don''t
    need to search the entire image for eyes because we know that the eyes will always
    be on your face:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们只在面部区域运行眼睛检测器。我们不需要在整个图像中搜索眼睛，因为我们知道眼睛总是在你的脸上：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We detect the eyes and store them only when we find both of them. We then use
    their coordinates to determine which one is the left eye and the right eye:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检测眼睛，并且只有在找到两只眼睛时才将它们存储起来。然后我们使用它们的坐标来确定哪只是左眼哪只是右眼：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the preceding code, we adjusted the size of the sunglasses to fit the scale
    of our faces in the webcam:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们调整了太阳镜的大小以适应我们在网络摄像头中的人脸比例：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Looking inside the code
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看代码内部
- en: If you notice, the flow of the code looks similar to the face detection code
    that we discussed earlier. We load the face detection cascade classifier as well
    as the eye detection cascade classifier. Now why do we need to load the face cascade
    classifier when we are detecting the eyes? Well, we don't really need to use the
    face detector, but it helps us limit our search for the eyes' location. We know
    that the eyes are always located on somebody's face, so we can limit the eye detection
    to the face region. The first step would be to detect the face and then run our
    eye detector code on this region. Since we would be operating on a smaller region,
    it would be faster and more efficient.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你注意到，代码的流程看起来与我们之前讨论的人脸检测代码相似。我们加载了人脸检测级联分类器以及眼睛检测级联分类器。那么，为什么在检测眼睛时我们需要加载人脸级联分类器呢？好吧，我们实际上并不需要使用人脸检测器，但它帮助我们限制了对眼睛位置的搜索。我们知道眼睛总是位于某人的脸上，因此我们可以将眼睛检测限制在面部区域。第一步是检测人脸，然后在这个区域上运行我们的眼睛检测代码。由于我们将在较小的区域上操作，这将更快、更高效。
- en: For each frame, we start by detecting the face. We then go ahead and detect
    the location of the eyes by operating on this region. After this step, we need
    to overlay the sunglasses. To do this, we need to resize the sunglasses' image
    to make sure that it fits our face. To get the proper scale, we can consider the
    distance between the two eyes that are being detected. We overlay the sunglasses
    only when we detect both the eyes. That's why we first run the eye detector, collect
    all the centers, and then overlay the sunglasses. Once we have this, we just need
    to overlay the sunglasses' mask. The principle used for masking is very similar
    to the principle that we used to overlay the facemask. You may have to customize
    the sizing and position of the sunglasses depending on what you want. You can
    play around with different types of sunglasses to see what they look like.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一帧，我们首先检测人脸。然后我们继续在这个区域上检测眼睛的位置。在这个步骤之后，我们需要叠加太阳镜。为了做到这一点，我们需要调整太阳镜图像的大小，确保它适合我们的脸。为了得到正确的比例，我们可以考虑被检测到的两只眼睛之间的距离。我们只在检测到两只眼睛时叠加太阳镜。这就是为什么我们首先运行眼睛检测器，收集所有中心点，然后叠加太阳镜。一旦我们有了这个，我们只需要叠加太阳镜的面具。用于面具的原则与我们用来叠加面部面具的原则非常相似。你可能需要根据你的需求自定义太阳镜的大小和位置。你可以尝试不同的太阳镜类型，看看它们看起来如何。
- en: Tracking your nose, mouth, and ears
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪你的鼻子、嘴巴和耳朵
- en: 'Now that you know how to track different things using the framework, you can
    try tracking your nose, mouth, and ears as well. Let''s use a nose detector to
    overlay a funny nose on top:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了如何使用框架跟踪不同的事物，你可以尝试跟踪你的鼻子、嘴巴和耳朵。让我们使用一个鼻子检测器在上方叠加一个有趣的鼻子：
- en: '![Tracking your nose, mouth, and ears](img/B04283_07_06.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![跟踪你的鼻子、嘴巴和耳朵](img/B04283_07_06.jpg)'
- en: You can refer to the code files for a complete implementation of this detector.
    There are cascade files called `haarcascade_mcs_nose.xml`, `haarcascade_mcs_mouth.xml`,
    `haarcascade_mcs_leftear.xml`, and `haarcascade_mcs_rightear.xml` that can be
    used to track the different face parts. So, you can play around with them and
    try to overlay a moustache or Dracula ears on yourself!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以参考代码文件以获取此检测器的完整实现。有一些级联文件名为`haarcascade_mcs_nose.xml`、`haarcascade_mcs_mouth.xml`、`haarcascade_mcs_leftear.xml`和`haarcascade_mcs_rightear.xml`，可以用来跟踪不同的面部部位。因此，你可以玩弄它们，尝试给自己叠加一个胡须或德古拉耳朵！
- en: Summary
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed Haar cascades and integral images. We learned
    how the face detection pipeline is built. We learned how to detect and track faces
    in a live video stream. We discussed how to use the face detection framework to
    detect various face parts, such as eyes, ears, nose, and mouth. We also learned
    how to overlay masks on top on the input image using the results of the face parts
    detection.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了Haar级联和积分图像。我们学习了如何构建人脸检测流程。我们学习了如何在实时视频流中检测和跟踪人脸。我们讨论了如何使用人脸检测框架来检测各种面部部位，例如眼睛、耳朵、鼻子和嘴巴。我们还学习了如何使用面部部位检测的结果在输入图像上叠加面具。
- en: In the next chapter, we will learn about video surveillance, background removal,
    and morphological image processing.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习关于视频监控、背景去除和形态学图像处理的内容。
