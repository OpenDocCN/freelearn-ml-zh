- en: '*Chapter 7*: Discovering Exoplanets with XGBoost'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第7章*：利用XGBoost发现外星行星'
- en: In this chapter, you will journey through the stars in an attempt to discover
    exoplanets with `XGBClassifier` as your guide.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将穿越星际，尝试使用`XGBClassifier`来发现外星行星。
- en: The reason for this chapter is twofold. The first is that it's important to
    gain practice in a top-to-bottom study using XGBoost since for all practical purposes,
    that is what you will normally do with XGBoost. Although you may not discover
    exoplanets with XGBoost on your own, the strategies that you implement here, which
    include choosing the correct scoring metric and carefully fine-tuning hyperparameters
    with that scoring metric in mind, apply to any practical use of XGBoost. The second
    reason for this particular case study is that it's essential for all machine learning
    practitioners to be proficient at competently handling imbalanced datasets, which
    is the key theme of this particular chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的有两个。首先，掌握从头到尾使用XGBoost进行分析的实践经验非常重要，因为在实际应用中，这正是你通常需要做的事情。尽管你可能无法凭借XGBoost独立发现外星行星，但本章中你所实施的策略，包括选择正确的评分指标并根据该指标精心调整超参数，适用于XGBoost的任何实际应用。第二个原因是，本案例研究非常重要，因为所有机器学习从业者必须熟练处理不平衡数据集，这是本章的关键主题。
- en: Specifically, you will gain new skills in using the `scale_pos_weight`, and
    more. Getting the best results from `XGBClassifier` will require careful analysis
    of the imbalanced data and clear expectations of the goal at hand. In this chapter,
    `XGBClassifier` is the centerpiece of a top-to-bottom study analyzing light data
    to predict exoplanets in the universe.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，你将掌握使用`scale_pos_weight`等技能。要从`XGBClassifier`中获得最佳结果，需要仔细分析数据的不平衡性，并明确手头的目标。在本章中，`XGBClassifier`是贯穿始终的核心工具，用来分析光数据并预测宇宙中的外星行星。
- en: 'In this chapter, we cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: Searching for exoplanets
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找外星行星
- en: Analyzing the confusion matrix
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析混淆矩阵
- en: Resampling imbalanced data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重采样不平衡数据
- en: Tuning and scaling XGBClassifier
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调优和缩放XGBClassifier
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The code for this chapter may be found at [https://github.com/PacktPublishing/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/tree/master/Chapter07](https://github.com/PacktPublishing/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/tree/master/Chapter07).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在[https://github.com/PacktPublishing/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/tree/master/Chapter07](https://github.com/PacktPublishing/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/tree/master/Chapter07)找到。
- en: Searching for exoplanets
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找外星行星
- en: In this section, we'll begin the search for exoplanets by analyzing the Exoplanets
    dataset. We'll provide historical context for the discovery of exoplanets before
    attempting to detect them via plotting and observing light graphs. Plotting time
    series is a valuable machine learning skill that may be used to gain insights
    into any time series datasets. Finally, we'll make initial predictions using machine
    learning before revealing a glaring shortcoming.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过分析外星行星数据集来开始寻找外星行星。我们将在尝试通过绘制和观察光图来探测外星行星之前，提供外星行星发现的历史背景。绘制时间序列是一个有价值的机器学习技能，可以用来洞察任何时间序列数据集。最后，在揭示一个明显的缺陷之前，我们将利用机器学习做出初步预测。
- en: Historical background
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 历史背景
- en: Astronomers have been gathering information from light since antiquity. With
    the advent of the telescope, astronomical knowledge surged in the 17th century.
    The combination of telescopes and mathematical models empowered 18th-century astronomers
    to predict planetary locations and eclipses within our own solar system with great
    precision.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 自古以来，天文学家就一直在从光线中收集信息。随着望远镜的出现，天文学知识在17世纪迎来了飞跃。望远镜与数学模型的结合使得18世纪的天文学家能够精确预测我们太阳系内的行星位置和日食现象。
- en: In the 20th century, astronomical research continued with more advanced technology
    and more complex mathematics. Planets revolving around other stars, called exoplanets,
    were discovered in the habitable zone. A planet in the habitable zone means that
    the exoplanet's location and size are comparable to Earth, and therefore it's
    a candidate for harboring liquid water and life.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪，天文学研究随着技术的进步和数学的复杂化不断发展。围绕其他恒星运转的行星——外星行星——被发现位于宜居区。位于宜居区的行星意味着该外星行星的位置和大小与地球相当，因此它可能存在液态水和生命。
- en: These exoplanets are not viewed directly via telescopes, rather they are inferred
    through periodic changes in starlight. An object that periodically revolves around
    a star that is large enough to block a detectable fraction of starlight is by
    definition a planet. Discovering exoplanets from starlight requires measuring
    light fluctuations over extended intervals of time. Since the change in light
    is often very minute, it's not easy to determine whether an exoplanet is actually
    present.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这些外行星不是通过望远镜直接观测的，而是通过恒星光的周期性变化来推测的。周期性围绕一颗恒星旋转、足够大以阻挡可检测的恒光的一部分的物体，按定义是行星。从恒光中发现外行星需要在较长时间内测量光的波动。由于光的变化通常非常微小，因此很难判断是否确实存在外行星。
- en: In this chapter, we are going to predict whether stars have exoplanets with
    XGBoost.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将使用XGBoost预测恒星是否有外行星。
- en: The Exoplanet dataset
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 外行星数据集
- en: You previewed the Exoplanet dataset in [*Chapter 4*](B15551_04_Final_NM_ePUB.xhtml#_idTextAnchor093),
    *From Gradient Boosting to XGBoost*, to uncover the time advantage that XGBoost
    has over comparable ensemble methods for large datasets. In this chapter, we will
    take a deeper look at the Exoplanet dataset.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你在 [*第4章*](B15551_04_Final_NM_ePUB.xhtml#_idTextAnchor093)《从梯度提升到XGBoost》中预览了外行星数据集，揭示了XGBoost在处理大数据集时相较于其他集成方法的时间优势。本章将更深入地了解外行星数据集。
- en: This Exoplanet dataset is taken from *NASA Kepler Space Telescope*, *Campaign
    3*, *Summer 2016*. Information about the data source is available on Kaggle at
    [https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data](https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data).
    Of all the stars in the dataset, 5,050 do not have exoplanets, while 37 have exoplanets.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这个外行星数据集来自于 *NASA Kepler太空望远镜*，*第3次任务*，*2016年夏季*。关于数据源的信息可以在 Kaggle 上找到，链接为
    [https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data](https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data)。在数据集中的所有恒星中，5,050颗没有外行星，而37颗有外行星。
- en: The 300+ columns and 5,000+ rows equal 1.5 million plus entries. When multiplied
    by 100 XGBoost trees, this is 150 million plus data points. To expedite matters,
    we start with a subset of the data. Starting with a subset is a common practice
    when dealing with large datasets, to save time.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 超过300列和5000多行数据，总共有超过150万条数据点。当乘以100棵XGBoost树时，总共有1.5亿多个数据点。为了加速处理，我们从数据的一个子集开始。使用子集是处理大数据集时的常见做法，以节省时间。
- en: '`pd.read_csv` contains an `nrows` parameter, used to limit the number of rows.
    Note that `nrows=n` selects the first *n* rows of the dataset. Depending on the
    data structure, additional code may be required to ensure that the subset is representative
    of the whole. Let''s get started.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.read_csv` 包含一个 `nrows` 参数，用于限制行数。请注意，`nrows=n` 会选择数据集中的前 *n* 行。根据数据结构，可能需要额外的代码来确保子集能够代表整个数据集。我们开始吧。'
- en: 'Import `pandas`, then load `exoplanets.csv` with `nrows=400`. Then view the
    data:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 `pandas`，然后用 `nrows=400` 加载 `exoplanets.csv`。然后查看数据：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output should appear as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 7.1 – Exoplanet DataFrame](img/B15551_07_01.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.1 – 外行星数据框](img/B15551_07_01.jpg)'
- en: Figure 7.1 – Exoplanet DataFrame
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – 外行星数据框
- en: The large number of columns (**3198**) listed underneath the DataFrame makes
    sense. When looking for periodic changes in light, you need enough data points
    to find periodicity. The revolutions of planets within our own solar system range
    from 88 days (Mercury) to 165 years (Neptune). If exoplanets are to be detected,
    data points must be examined frequently enough so as not to miss the transit of
    the planet when the planet orbits in front of the star.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框下列出的大量列（**3198**列）是有道理的。在寻找光的周期性变化时，需要足够的数据点来发现周期性。我们太阳系内的行星公转周期从88天（水星）到165年（海王星）不等。如果要检测外行星，必须频繁检查数据点，以便不会错过行星在恒星前面经过的瞬间。
- en: Since there are only 37 exoplanet stars, it's important to know how many exoplanet
    stars are contained in the subset.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由于只有37颗外行星恒星，因此了解子集中包含了多少颗外行星恒星是很重要的。
- en: 'The `.value_counts()` method determines the number of each value in a particular
    column. Since we are interested in the `LABEL` column, the number of exoplanet
    stars may be found using the following code:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`.value_counts()` 方法用于确定特定列中每个值的数量。由于我们关注的是 `LABEL` 列，可以使用以下代码查找外行星恒星的数量：'
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output is as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: All exoplanet stars are included in our subset. As `.head()` reveals, the exoplanet
    stars are at the beginning.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的子集包含了所有的外行星恒星。如 `.head()` 所示，外行星恒星位于数据的开头。
- en: Graphing the data
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 绘制数据图表
- en: The expectation is that when an exoplanet blocks light from a star, the light
    flux goes down. If drops in flux occur periodically, an exoplanet is likely the
    reason since, by definition, a planet is a large object orbiting a star.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 期望的是，当外行星遮挡了恒星的光时，光通量会下降。如果光通量下降是周期性的，那么很可能是外行星在起作用，因为根据定义，行星是绕恒星运行的大型天体。
- en: 'Let''s visualize the data by graphing:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过绘图来可视化数据：
- en: 'Import `matplotlib`, `numpy`, and `seaborn`, then set `seaborn` to the dark
    grid as follows:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`matplotlib`、`numpy`和`seaborn`，然后将`seaborn`设置为暗网格，如下所示：
- en: '[PRE3]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: When plotting light fluctuations, the `LABEL` column is not of interest. The
    `LABEL` column will be our target column for machine learning.
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在绘制光变曲线时，`LABEL`列不感兴趣。`LABEL`列将作为我们机器学习的目标列。
- en: Tip
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示
- en: '`seaborn` is recommended to improve your `matplotlib` graphs. The `sns.set()`
    default provides a nice light-gray background with a white grid. Furthermore,
    many standard graphs, such as `plt.hist()`, look more aesthetically pleasing with
    this Seaborn default in place. For more information on Seaborn, check out [https://seaborn.pydata.org/](https://seaborn.pydata.org/).'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 推荐使用`seaborn`来改进你的`matplotlib`图表。`sns.set()`默认设置提供了一个漂亮的浅灰色背景和白色网格。此外，许多标准图表，如`plt.hist()`，在应用Seaborn默认设置后看起来更加美观。有关Seaborn的更多信息，请访问[https://seaborn.pydata.org/](https://seaborn.pydata.org/)。
- en: 'Now, let''s split the data into `X`, the predictor columns (which we will graph),
    and `y`, the target column. Note that for the Exoplanet dataset, the target column
    is the first column, not the last:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将数据拆分为`X`（预测列，我们将绘制它们）和`y`（目标列）。请注意，对于外行星数据集，目标列是第一列，而不是最后一列：
- en: '[PRE4]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now write a function called `light_plot`, which takes as input the index of
    the data (the row) that plots all data points as *y* coordinates (the light flux),
    and the number of observations as *x* coordinates. Use appropriate labels for
    the graph as follows:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在编写一个名为`light_plot`的函数，该函数以数据的索引（行号）为输入，将所有数据点绘制为*y*坐标（光通量），并将观测次数作为*x*坐标。图表应使用以下标签：
- en: '[PRE5]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, call the function to plot the first index. This star has been classified
    as an exoplanet star:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，调用函数绘制第一个索引。这颗恒星已被分类为外行星恒星：
- en: '[PRE6]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here is the expected graph for our first light plot:'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是我们第一个光曲线图的预期图表：
- en: '![Figure 7.2 – Light plot 0\. Periodic drops in light are present](img/B15551_07_02.jpg)'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 7.2 – 光曲线 0\. 存在周期性光通量下降](img/B15551_07_02.jpg)'
- en: Figure 7.2 – Light plot 0\. Periodic drops in light are present
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.2 – 光曲线 0\. 存在周期性光通量下降
- en: There are clear drops in the data that occur periodically. However, concluding
    that an exoplanet is present is not obvious from this graph alone.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据中存在明显的周期性下降。然而，仅凭这张图表，无法明确得出有外行星存在的结论。
- en: 'By comparison, contrast this plot with the 37th index, the first non-exoplanet
    star in the dataset:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 做个对比，将这个图与第37个索引的图进行比较，后者是数据集中第一个非外行星恒星：
- en: '[PRE7]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here is the expected graph for the 37th index:'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是第37个索引的预期图表：
- en: '![Figure 7.3 – Light plot 37](img/B15551_07_03.jpg)'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 7.3 – 光曲线 37](img/B15551_07_03.jpg)'
- en: Figure 7.3 – Light plot 37
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.3 – 光曲线 37
- en: Increases and decreases in light are present, but not over the entire range.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 存在光强度的增加和减少，但不是贯穿整个范围。
- en: There are clear drops in the data, but they are not periodic throughout the
    graph. The frequency of the drops does not recur consistently. Based on this evidence
    alone, it's not enough to determine the presence of an exoplanet.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据中确实存在明显的下降，但它们在整个图表中并不是周期性的。下降的频率并没有一致地重复。仅凭这些证据，还不足以确定是否存在外行星。
- en: 'Here is the second light plot of an exoplanet star:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是外行星恒星的第二个光曲线图：
- en: '[PRE8]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here is the expected graph for the first index:'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是第一个索引的预期图表：
- en: '![Figure 7.4 – Clear periodic drops indicate the presence of an exoplanet](img/B15551_07_04.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.4 – 明显的周期性下降表明存在外行星](img/B15551_07_04.jpg)'
- en: Figure 7.4 – Clear periodic drops indicate the presence of an exoplanet
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4 – 明显的周期性下降表明存在外行星
- en: The plot shows clear periodicity with large drops in light flux making an exoplanet
    extremely likely! If all the plots were this clear, machine learning would be
    unnecessary. As the other plots reveal, concluding that an exoplanet is present
    is usually not this clear.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图表显示出明显的周期性，且光通量有大幅下降，这使得外行星的存在极为可能！如果所有图表都如此清晰，机器学习就不再必要。正如其他图表所示，得出外行星存在的结论通常没有这么明确。
- en: The purpose here is to highlight the data and the difficulty of classifying
    exoplanets based on visual graphs alone. Astronomers use different methods to
    classify exoplanets, and machine learning is one such method.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目的是突出数据的特点以及仅凭视觉图表分类系外行星的难度。天文学家使用不同的方法来分类系外行星，而机器学习就是其中的一种方法。
- en: Although this dataset is a time series, the goal is not to predict light flux
    for the next unit of time, but rather to classify the star based on all the data.
    In this respect, machine learning classifiers may be used to predict whether a
    given star hosts an exoplanet. The idea is to train the classifier on the provided
    data, which may in turn be used to predict exoplanets on new data. In this chapter,
    we attempt to classify the exoplanets within the data using `XGBClassifier`. Before
    we move on to classify the data, we must first prepare the data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个数据集是一个时间序列，但目标不是预测下一个时间单位的光通量，而是基于所有数据来分类恒星。在这方面，机器学习分类器可以用来预测给定的恒星是否有系外行星。这个思路是用提供的数据来训练分类器，进而用它来预测新数据中的系外行星。在本章中，我们尝试使用`XGBClassifier`来对数据中的系外行星进行分类。在开始分类数据之前，我们必须先准备数据。
- en: Preparing data
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备数据
- en: 'We witnessed in the previous section that not all graphs are clear enough to
    determine the existence of an exoplanet. This is where machine learning may be
    of great benefit. To begin, let''s prepare the data for machine learning:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前一节中已经看到，并非所有图表都足够清晰，无法仅凭图表来确定系外行星的存在。这正是机器学习可以大有帮助的地方。首先，让我们为机器学习准备数据：
- en: 'First, we need the dataset to be numerical with no null values. Check the data
    types and null values using `df.info()`:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要确保数据集是数值型的且没有空值。使用`df.info()`来检查数据类型和空值：
- en: '[PRE9]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here is the expected output:'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '[PRE10]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The subset contains 3,197 floats, and 1 int, so all columns are numerical. No
    information is provided about null values due to the large number of columns.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 子集包含3,197个浮点数和1个整数，因此所有列都是数值型的。由于列数较多，因此没有提供关于空值的信息。
- en: 'We can use the `.sum()` method twice on `.null()` to sum all null values, once
    to sum the null values in each column, and the second time to sum all columns:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以对`.null()`方法使用`.sum()`两次，第一次是对每一列的空值求和，第二次是对所有列的空值求和：
- en: '[PRE11]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The expected output is as follows:'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '[PRE12]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Since there are no null values and the data is numerical, we will proceed with
    machine learning.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据中没有空值，并且数据是数值型的，我们将继续进行机器学习。
- en: Initial XGBClassifier
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始的XGBClassifier
- en: 'To start building an initial XGBClassifier, take the following steps:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始构建初始的XGBClassifier，请按照以下步骤操作：
- en: 'Import `XGBClassifier` and `accuracy_score`:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`XGBClassifier`和`accuracy_score`：
- en: '[PRE13]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Split the model into a training and test set:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拆分为训练集和测试集：
- en: '[PRE14]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Build and score the model using `booster=''gbtree''`, `objective=''binary:logistic''`,
    and `random_state=2` as parameters:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`booster='gbtree'`、`objective='binary:logistic'`和`random_state=2`作为参数构建并评分模型：
- en: '[PRE15]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The score is as follows:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 评分如下：
- en: '[PRE16]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Correctly classifying 89% of stars seems like a good starting point, but there
    is one glaring issue.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 正确分类89%的恒星看起来是一个不错的起点，但有一个明显的问题。
- en: Can you figure it out?
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你能弄明白吗？
- en: Imagine that you present your model to your astronomy professor. Assuming your
    professor is well-trained in data analysis, your professor would respond, "I see
    that you obtained 89% accuracy, but exoplanets represent 10% of the data, so how
    do you know your results aren't better than a model that predicts no exoplanets
    100% of the time?"
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你向天文学教授展示了你的模型。假设你的教授在数据分析方面受过良好训练，教授可能会回应：“我看到你得到了89%的准确率，但系外行星仅占数据的10%，那么你怎么知道你的结果不是比一个总是预测没有系外行星的模型更好呢？”
- en: Therein lies the issue. If the model determines that no stars contain exoplanets,
    its accuracy will be approximately 90% since 9 out of 10 stars do not contain
    exoplanets.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是问题所在。如果模型判断没有恒星包含系外行星，它的准确率将约为90%，因为10颗恒星中有9颗不包含系外行星。
- en: '*With imbalanced data, accuracy isn''t enough.*'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*对于不平衡的数据，准确度并不够。*'
- en: Analyzing the confusion matrix
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析混淆矩阵
- en: A confusion matrix is a table that summarizes the correct and incorrect predictions
    of a classification model. The confusion matrix is ideal for analyzing imbalanced
    data because it provides more information on which predictions are correct, and
    which predictions are wrong.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵是一个表格，用来总结分类模型的正确预测和错误预测。混淆矩阵非常适合分析不平衡数据，因为它提供了哪些预测正确，哪些预测错误的更多信息。
- en: 'For the Exoplanet subset, here is the expected output for a perfect confusion
    matrix:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于外行星子集，以下是完美混淆矩阵的预期输出：
- en: '[PRE17]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: When all positive entries are on the left diagonal, the model has 100% accuracy.
    A perfect confusion matrix here predicts 88 non-exoplanet stars and 12 exoplanet
    stars. Notice that the confusion matrix does not provide labels, but in this case,
    labels may be inferred based on the size.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有正例条目都位于左对角线时，模型的准确度为 100%。在此情况下，完美的混淆矩阵预测了 88 个非外行星恒星和 12 个外行星恒星。请注意，混淆矩阵不提供标签，但在这种情况下，可以根据大小推断标签。
- en: Before getting into further detail, let's see the actual confusion matrix using
    scikit-learn.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入细节之前，让我们使用 scikit-learn 查看实际的混淆矩阵。
- en: confusion_matrix
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: confusion_matrix
- en: 'Import `confusion_matrix` from `sklearn.metrics` as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 从 `sklearn.metrics` 导入 `confusion_matrix`，代码如下：
- en: '[PRE18]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Run `confusion_matrix` with `y_test` and `y_pred` as inputs (variables obtained
    in the previous section), making sure to put `y_test` first:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `y_test` 和 `y_pred` 作为输入运行 `confusion_matrix`（这些变量在上一部分中获得），确保将 `y_test`
    放在前面：
- en: '[PRE19]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE20]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The numbers on the diagonals of the confusion matrix reveal `86` correct non-exoplanet-star
    predictions and only `3` correct exoplanet star predictions.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵对角线上的数字揭示了 `86` 个正确的非外行星恒星预测，以及仅 `3` 个正确的外行星恒星预测。
- en: In the upper-right corner of the matrix, the number `2` reveals that two non-exoplanet-stars
    were misclassified as exoplanet stars. Similarly, in the bottom-left corner of
    the matrix, the number `9` reveals that `9` exoplanet stars were misclassified
    as non-exoplanet-stars.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在矩阵的右上角，数字 `2` 显示有两个非外行星恒星被误分类为外行星恒星。同样，在矩阵的左下角，数字 `9` 显示有 `9` 个外行星恒星被误分类为非外行星恒星。
- en: When analyzed horizontally, 86 of 88 non-exoplanet stars were correctly classified,
    while only 3 of 12 exoplanet stars were correctly classified.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 横向分析时，88 个非外行星恒星中有 86 个被正确分类，而 12 个外行星恒星中只有 3 个被正确分类。
- en: As you can see, the confusion matrix reveals important details of the model's
    predictions that an accuracy score is unable to pick up on.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，混淆矩阵揭示了模型预测的重要细节，而准确度得分无法捕捉到这些细节。
- en: classification_report
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: classification_report
- en: 'The various percentages from the numbers revealed in the confusion matrix in
    the previous section are contained within a classification report. Let''s view
    the classification report:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一部分中混淆矩阵所揭示的各种百分比数值包含在分类报告（classification report）中。让我们查看分类报告：
- en: 'Import `classification_report` from `sklearn.metrics`:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `sklearn.metrics` 导入 `classification_report`：
- en: '[PRE21]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Place `y_test` and `y_pred` inside `clasification_report`, making sure to put
    `y_test` first. Then place `classification_report` inside the global print function
    to keep the output aligned and easy to read:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `y_test` 和 `y_pred` 放入 `classification_report` 中，确保将 `y_test` 放在前面。然后将 `classification_report`
    放入全局打印函数中，以确保输出对齐且易于阅读：
- en: '[PRE22]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here is the expected output:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '[PRE23]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: It's important to understand what the preceding scores mean, so let's review
    them one at a time.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 了解上述得分的含义很重要，让我们逐一回顾它们。
- en: Precision
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 精确度（Precision）
- en: Precision gives the predictions of the positive cases (2s) that are actually
    correct. It's technically defined in terms of true positives and false positives.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度给出了正类预测（2s）中实际上是正确的预测。它在技术上是通过真正例和假正例来定义的。
- en: True positives
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 真正例（True Positives）
- en: 'Here are a definition and example of true positives:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关于真正例的定义和示例：
- en: Definition – Number of labels correctly predicted as positive.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义 – 正确预测为正类的标签数。
- en: Example – 2s are correctly predicted as 2s.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例 – 2 被正确预测为 2。
- en: False positives
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 假正例（False Positives）
- en: 'Here are a definition and example of false positives:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关于假正例的定义和示例：
- en: Definition – Number of positive labels incorrectly predicted as negative.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义 – 错误地预测为负类的正标签数。
- en: Example – For exoplanet stars, 2s are incorrectly predicted as 1s.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例 – 对于外行星恒星，2 被错误地预测为 1。
- en: 'The definition of precision is most often referred to in its mathematical form
    as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度的定义通常以其数学形式表示如下：
- en: '![](img/Formula_07_001.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_07_001.jpg)'
- en: Here TP stands for true positive and FP stands for false positive.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，TP 代表真正例（True Positive），FP 代表假正例（False Positive）。
- en: 'In the Exoplanet dataset, we have the following two mathematical forms:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在外行星数据集中，我们有以下两种数学形式：
- en: '![](img/Formula_07_002.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_07_002.png)'
- en: and
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![](img/Formula_07_003.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_07_003.png)'
- en: Precision gives the percentage of correct predictions for each target class.
    Now let's review other key scoring metrics that the classification report reveals.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 精确率给出了每个目标类的正确预测百分比。接下来，让我们回顾分类报告中揭示的其他关键评分指标。
- en: Recall
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 召回率
- en: Recall gives you the percentage of positive cases that your predictions uncovered.
    Recall is the number of true positives divided by the true positives plus false
    negatives.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率给出了你的预测发现的正样本的百分比。召回率是正确预测的正样本数量除以真正例加上假负例的总和。
- en: False negatives
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 虚假负例
- en: 'Here are a definition and example of false negatives:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是虚假负例的定义和示例：
- en: Definition – Number of labels incorrectly predicted as negative.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义 – 错误预测为负类的标签数量。
- en: Example – For exoplanet star predictions, 2s are incorrectly predicted as 1s.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例 – 对于外行星星的预测，2类被错误地预测为1类。
- en: 'In mathematical form, this looks as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 数学形式如下所示：
- en: '![](img/Formula_07_004.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_07_004.png)'
- en: Here TP stands for true positive and FN stands for false negative.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这里TP代表真正例（True Positive），FN代表假负例（False Negative）。
- en: 'In the Exoplanet dataset, we have the following:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在外行星数据集中，我们有以下内容：
- en: '![](img/Formula_07_005.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_07_005.jpg)'
- en: and
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![](img/Formula_07_006.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_07_006.jpg)'
- en: Recall tells you how many of the positive cases were found. In the exoplanet
    case, only 25% of exoplanets have been found.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率告诉你找到了多少正样本。在外行星的例子中，只有25%的外行星被找到了。
- en: F1 score
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F1分数
- en: The F1 score is the harmonic mean between precision and recall. The harmonic
    mean is used because precision and recall are based on different denominators
    and the harmonic mean evens them out. When precision and recall are equally important,
    the F1 score is best. Note that the F1 score ranges from 0 to 1 with 1 being the
    highest.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数是精确率和召回率的调和平均值。使用调和平均值是因为精确率和召回率基于不同的分母，调和平均值将它们统一起来。当精确率和召回率同等重要时，F1分数是最优的。请注意，F1分数的范围从0到1，1为最高分。
- en: Alternative scoring methods
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替代评分方法
- en: Precision, recall, and the F1 score are alternative scoring methods provided
    by scikit-learn. A list of standard scoring methods may be found in the official
    documentation at [https://scikit-learn.org/stable/modules/model_evaluation.html](https://scikit-learn.org/stable/modules/model_evaluation.html).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 精确率、召回率和F1分数是scikit-learn提供的替代评分方法。标准评分方法的列表可以在官方文档中找到：[https://scikit-learn.org/stable/modules/model_evaluation.html](https://scikit-learn.org/stable/modules/model_evaluation.html)。
- en: Tip
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Accuracy is often not the best choice for classification datasets. Another popular
    scoring method is `roc_auc_score`, the area under the curve of the receiving operator
    characteristic. As with most classification scoring methods, the closer to 1,
    the better the results. See [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score)
    for more information.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类数据集，准确率通常不是最佳选择。另一种常见的评分方法是`roc_auc_score`，即接收者操作特征曲线下面积。与大多数分类评分方法一样，越接近1，结果越好。更多信息请参见[https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score)。
- en: When choosing a scoring method, it's critical to understand the goal. The goal
    in the Exoplanet dataset is to find exoplanets. This is obvious. What is not obvious
    is how to select the best scoring method to achieve the desired results.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 选择评分方法时，了解目标至关重要。外行星数据集的目标是找到外行星。这一点是显而易见的。但并不明显的是，如何选择最佳评分方法以实现期望的结果。
- en: 'Imagine two different scenarios:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 想象两种不同的情境：
- en: 'Scenario 1: Of the 4 exoplanet stars the machine learning model predicts, 3
    are actually exoplanet stars: 3/4 = 75% precision.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 场景1：机器学习模型预测的4颗外行星星中，实际为外行星的有3颗：3/4 = 75% 精确率。
- en: 'Scenario 2: Of the 12 exoplanet stars, the model correctly predicts 8 exoplanet
    stars (8/12 = 66% recall).'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 场景2：在12颗外行星星中，模型正确预测了8颗外行星星（8/12 = 66% 召回率）。
- en: Which is more desirable?
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 哪种情况更为理想？
- en: The answer is that it depends. Recall is ideal for flagging potential positive
    cases (exoplanets) with the goal of finding them all. Precision is ideal for ensuring
    that the predictions (exoplanets) are indeed positive.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是这取决于情况。召回率适合用于标记潜在的正样本（如外行星），目的是尽可能找到所有的正样本。精确率则适用于确保预测的正样本（外行星）确实是正样本。
- en: Astronomers are unlikely to announce that an exoplanet has been discovered just
    because a machine learning model says so. They are more likely to carefully examine
    potential exoplanet stars before confirming or refuting the claim based on additional
    evidence.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 天文学家不太可能仅仅因为机器学习模型说发现了外星行星就宣布这一发现。他们更可能在确认或否定这一发现之前，仔细检查潜在的外星行星，并根据额外的证据作出判断。
- en: Assuming that the goal of the machine learning model is to find as many exoplanets
    as possible, recall is an excellent choice. Why? Recall tells us how many of the
    12 exoplanet stars have been found (2/12, 5/12, 12/12). Let's try to find them
    all.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 假设机器学习模型的目标是尽可能多地找到外星行星，召回率是一个极好的选择。为什么？召回率告诉我们找到了多少颗外星行星（例如：2/12、5/12、12/12）。让我们尝试找到所有的外星行星。
- en: Precision note
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 精确率说明
- en: A higher percentage of precision does not indicate more exoplanet stars. For
    instance, a recall of 1/1 is 100%, but it only finds one exoplanet.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 更高的精确率并不意味着更多的外星行星。例如，1/1的召回率是100%，但只发现了一颗外星行星。
- en: recall_score
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: recall_score
- en: 'As indicated in the previous section, we will proceed with recall as the scoring
    method for the Exoplanet dataset to find as many exoplanets as possible. Let''s
    begin:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一节所述，我们将使用召回率作为评分方法，针对外星行星数据集寻找尽可能多的外星行星。让我们开始吧：
- en: 'Import `recall_score` from `sklearn.metrics`:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn.metrics`导入`recall_score`：
- en: '[PRE24]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: By default, `recall_score` reports the recall score of the positive class, typically
    labeled `1`. It is unusual for the positive class to be labeled `2` and for the
    negative class to be labeled `1` as is the case with the Exoplanet dataset.
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 默认情况下，`recall_score`报告的是正类的召回率，通常标记为`1`。在外星行星数据集中，正类标记为`2`，负类标记为`1`，这比较少见。
- en: 'To obtain the `recall_score` value of exoplanet stars, input `y_test` and `y_pred`
    as parameters for `recall_score` along with `pos_label=2`:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了获得外星行星的`recall_score`值，输入`y_test`和`y_pred`作为`recall_score`的参数，并设置`pos_label=2`：
- en: '[PRE25]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The score of exoplanet stars is as follows:'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 外星行星的评分如下：
- en: '[PRE26]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This is the same percentage given by the classification report under the recall
    score of `2`, which is the exoplanet stars. Going forward, instead of using `accuracy_score`,
    we will use `recall_score` with the preceding parameters as our scoring metric.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这是由分类报告中召回率为`2`时给出的相同百分比，即外星行星。接下来，我们将不再使用`accuracy_score`，而是使用`recall_score`及其前述参数作为我们的评分指标。
- en: Next, let's learn about resampling, an important strategy for improving the
    scores of imbalanced datasets.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们了解一下重新采样，它是改善失衡数据集得分的重要策略。
- en: Resampling imbalanced data
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重新采样失衡数据
- en: Now that we have an appropriate scoring method to discover exoplanets, it's
    time to explore strategies such as resampling, undersampling, and oversampling
    for correcting the imbalanced data causing the low recall score.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个适当的评分方法来发现外星行星，接下来是探索如重新采样、欠采样和过采样等策略，以纠正导致低召回率的失衡数据。
- en: Resampling
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新采样
- en: One strategy to counteract imbalanced data is to resample the data. It's possible
    to undersample the data by reducing rows of the majority class and to oversample
    the data by repeating rows of the minority class.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 应对失衡数据的一种策略是重新采样数据。可以通过减少多数类的行数来进行欠采样，或通过重复少数类的行数来进行过采样。
- en: Undersampling
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 欠采样
- en: Our exploration began by selecting 400 rows from 5,087\. This is an example
    of undersampling since the subset contains fewer rows than the original.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的探索从从5,087行中选取了400行开始。这是一个欠采样的例子，因为子集包含的行数比原始数据少。
- en: Let's write a function that allows us to undersample the data by any number
    of rows. This function should return the recall score so that we can see how undersampling
    changes the results. We will begin with the scoring function.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来编写一个函数，使其能够按任意行数对数据进行欠采样。这个函数应该返回召回率评分，这样我们就能看到欠采样如何改变结果。我们将从评分函数开始。
- en: The scoring function
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评分函数
- en: The following function takes XGBClassifier and the number of rows as input and
    produces the confusion matrix, classification report, and recall score of exoplanet
    stars as output.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数接收XGBClassifier和行数作为输入，输出外星行星的混淆矩阵、分类报告和召回率。
- en: 'Here are the steps:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是步骤：
- en: 'Define a function, `xgb_clf`, that takes `model`, the machine learning model,
    and `nrows`, the number of rows, as input:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数`xgb_clf`，它接收`model`（机器学习模型）和`nrows`（行数）作为输入：
- en: '[PRE27]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Load the DataFrame with `nrows`, then split the data into `X` and `y` and training
    and test sets:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`nrows`加载DataFrame，然后将数据分成`X`和`y`，并划分训练集和测试集：
- en: '[PRE28]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Initialize the model, fit the model to the training set, and score it with
    the test set using `y_test`, `y_pred`, and `pos_label=2` for `recall_score` as
    input:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化模型，将模型拟合到训练集，并使用 `y_test`、`y_pred` 和 `pos_label=2` 作为 `recall_score` 的输入对测试集进行评分：
- en: '[PRE29]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Print the confusion matrix and classification report, and return the score:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印混淆矩阵和分类报告，并返回评分：
- en: '[PRE30]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Now, we can undersample the number of rows and see how the scores change.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过欠采样减少行数，并观察评分的变化。
- en: Undersampling nrows
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 欠采样 nrows
- en: 'Let''s start by doubling `nrows` to `800`. This is still undersampling since
    the original dataset has `5087` rows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先将 `nrows` 加倍至 `800`。这仍然是欠采样，因为原始数据集有 `5087` 行：
- en: '[PRE31]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This is the expected output:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '[PRE32]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Despite the near-perfect recall for non-exoplanet stars, the confusion matrix
    reveals that only 1 of 10 exoplanet stars have been recalled.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管非外行星星体的召回率几乎完美，但混淆矩阵显示只有 10 个外行星星体中的 1 个被召回。
- en: 'Next, decrease `nrows` from `400` to `200`:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将 `nrows` 从 `400` 减少到 `200`：
- en: '[PRE33]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This is the expected output:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '[PRE34]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This is a little better. By decreasing `n_rows` the recall has gone up.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果稍微好一些。通过减少 `nrows`，召回率有所提高。
- en: Let's see what happens if we balance the classes precisely. Since there are
    37 exoplanet-stars, 37 non-exoplanet stars balance the data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如果我们精确平衡类会发生什么。由于有 37 个外行星星体，37 个非外行星星体就能平衡数据。
- en: 'Run the `xgb_clf` function with `nrows=74`:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `nrows=74` 运行 `xgb_clf` 函数：
- en: '[PRE35]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This is the expected output:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '[PRE36]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: These results are respectable, even though the subset is much smaller.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管子集要小得多，但这些结果仍然令人满意。
- en: Next, let's see what happens when we apply the strategy of oversampling.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看当我们应用过采样策略时会发生什么。
- en: Oversampling
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过采样
- en: Another resampling technique is oversampling. Instead of eliminating rows, oversampling
    adds rows by copying and redistributing the positive cases.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种重采样技术是过采样。与其删除行，过采样通过复制和重新分配正类样本来增加行数。
- en: Although the original dataset has over 5,000 rows, we continue to use `nrows=400`
    as our starting point to expedite the process.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管原始数据集有超过 5000 行，但我们仍然使用 `nrows=400` 作为起点，以加快过程。
- en: When `nrows=400`, the ratio of positive to negative cases is 10 to 1\. We need
    10 times as many positive cases to obtain a balance.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 当 `nrows=400` 时，正类与负类样本的比例为 10:1。为了获得平衡，我们需要 10 倍数量的正类样本。
- en: 'Our strategy is as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的策略如下：
- en: Create a new DataFrame that copies the positive cases nine times.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个新的 DataFrame，复制正类样本九次。
- en: Concatenate a new DataFrame with the original to obtain a 10-10 ratio.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将新的 DataFrame 与原始数据框连接，得到 10:10 的比例。
- en: Before proceeding, a warning is in order. If the data is resampled before splitting
    it into training and test sets, the recall score will be inflated. Can you see
    why?
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，需要做一个警告。如果在拆分数据集成训练集和测试集之前进行重采样，召回评分将会被夸大。你能看出为什么吗？
- en: When resampling, nine copies will be made of the positive cases. After splitting
    this data into training and test sets, copies are likely contained in both sets.
    So, the test set will contain most of the same data points as the training set.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在重采样时，将对正类样本进行九次复制。将数据拆分为训练集和测试集后，复制的样本可能会同时出现在两个数据集中。因此，测试集将包含大多数与训练集相同的数据点。
- en: 'The appropriate strategy is to split the data into a training and test set
    first and then to resample the data. As done previously, we can use `X_train`,
    `X_test`, `y_train`, and `y_test`. Let''s start:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 合适的策略是先将数据拆分为训练集和测试集，然后再进行重采样。如前所述，我们可以使用 `X_train`、`X_test`、`y_train` 和 `y_test`。让我们开始：
- en: 'Merge `X_train` and `y_train` on the left and right index with `pd.merge` as
    follows:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pd.merge` 按照左索引和右索引合并 `X_train` 和 `y_train`，如下所示：
- en: '[PRE37]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Create a DataFrame, `new_df`, using `np.repeat` that includes the following:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `np.repeat` 创建一个包含以下内容的 DataFrame，`new_df`：
- en: 'a) The values of the positive cases: `df_train[df_train[''LABEL'']==2.values`.'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 正类样本的值：`df_train[df_train['LABEL']==2.values`。
- en: b) The number of copies – in this case, `9`
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 复制的次数——在本例中为 `9`
- en: 'c) The `axis=0` parameter to specify that we are working with columns:'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `axis=0` 参数指定我们正在处理列：
- en: '[PRE38]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Copy the column names:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制列名：
- en: '[PRE39]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Concatenate the DataFrames:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并 DataFrame：
- en: '[PRE40]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Verify that `value_counts` is as expected:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证 `value_counts` 是否如预期：
- en: '[PRE41]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The expected output is as follows:'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '[PRE42]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Split `X` and `y` using the resampled DataFrame:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用重采样后的 DataFrame 拆分 `X` 和 `y`：
- en: '[PRE43]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Fit the model on the resampled training set:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在重采样后的训练集上拟合模型：
- en: '[PRE44]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Score the model with `X_test` and `y_test`. Include the confusion matrix and
    classification report in your result:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`X_test`和`y_test`对模型进行评分。将混淆矩阵和分类报告包括在结果中：
- en: '[PRE45]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The score is as follows:'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 得分如下：
- en: '[PRE46]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: By appropriately holding out a test set to begin with, oversampling achieves
    33.3% recall, a score that is twice as strong as the 17% obtained earlier, although
    still much too low.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 通过适当地留出测试集，过采样达到了33.3%的召回率，这个得分是之前17%的一倍，尽管仍然太低。
- en: Tip
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: '`imblearn`, which must be downloaded to use. I achieved the same results as
    SMOTE using the preceding resampling code.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '`imblearn`，必须下载才能使用。我通过前面的重采样代码实现了与SMOTE相同的结果。'
- en: Since resampling has produced modest gains at best, it's time to adjust the
    hyperparameters of XGBoost.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 由于重采样的效果最多只能带来适度的提升，是时候调整XGBoost的超参数了。
- en: Tuning and scaling XGBClassifier
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整和缩放XGBClassifier
- en: In this section, we will fine-tune and scale XGBClassifier to obtain the best
    possible `recall_score` value for the Exoplanets dataset. First, you will adjust
    weights using `scale_pos_weight`, then you will run grid searches to find the
    best combination of hyperparameters. In addition, you will score models for different
    subsets of the data before consolidating and analyzing the results.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将微调并缩放XGBClassifier，以获得外星行星数据集的最佳`recall_score`值。首先，您将使用`scale_pos_weight`调整权重，然后运行网格搜索以找到最佳的超参数组合。此外，您将为不同的数据子集评分，然后整合并分析结果。
- en: Adjusting weights
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整权重
- en: In [*Chapter 5*](B15551_05_Final_NM_ePUB.xhtml#_idTextAnchor117), *XGBoost Unveiled*,
    you used the `scale_pos_weight` hyperparameter to counteract imbalances in the
    Higgs boson dataset. `Scale_pos_weight` is a hyperparameter used to scale the
    *positive* weight. The emphasis here on *positive* is important because XGBoost
    assumes that a target value of `1` is *positive* and a target value of `0` is
    *negative*.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第五章*](B15551_05_Final_NM_ePUB.xhtml#_idTextAnchor117)，*XGBoost揭秘*中，你使用了`scale_pos_weight`超参数来解决Higgs玻色子数据集中的不平衡问题。`scale_pos_weight`是一个用来调整*正*类权重的超参数。这里强调的*正*是非常重要的，因为XGBoost假设目标值为`1`的是*正*类，目标值为`0`的是*负*类。
- en: In the Exoplanet dataset, we have been using the default `1` as negative and
    `2` as positive as provided by the dataset. We will now switch to `0` as negative
    and `1` as positive using the `.replace()` method.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在外星行星数据集中，我们一直使用数据集提供的默认值`1`为负类，`2`为正类。现在，我们将使用`.replace()`方法将其改为`0`为负类，`1`为正类。
- en: replace
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: replace
- en: 'The `.replace()` method may be used to reassign values. The following code
    replaces `1` with `0` and `2` with `1` in the `LABEL` column:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '`.replace()`方法可以用来重新分配值。以下代码在`LABEL`列中将`1`替换为`0`，将`2`替换为`1`：'
- en: '[PRE47]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: If the two lines of code were reversed, all column values would end up as 0
    since all 2s would become 1s, and then all 1s would become 0s. In programming,
    order matters!
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两行代码顺序颠倒，所有列值都会变成0，因为所有的2都会变成1，然后所有的1会变成0。在编程中，顺序非常重要！
- en: 'Verify the counts using the `value_counts` method:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`value_counts`方法验证计数：
- en: '[PRE48]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Here is the expected output:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是预期的输出：
- en: '[PRE49]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The positive cases are now labeled `1` and the negative cases are labeled `0`.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 正类现在标记为`1`，负类标记为`0`。
- en: scale_pos_weight
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: scale_pos_weight
- en: 'It''s time to build a new `XGBClassifier` with `scale_pos_weight=10` to account
    for the imbalance in the data:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候构建一个新的`XGBClassifier`，并设置`scale_pos_weight=10`，以解决数据中的不平衡问题：
- en: 'Split the new DataFrame into `X`, the predictor columns, and `y`, the target
    columns:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将新的DataFrame拆分为`X`，即预测列和`y`，即目标列：
- en: '[PRE50]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Split the data into training and test sets:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集和测试集：
- en: '[PRE51]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Build, fit, predict, and score `XGBClassifier` with `scale_pos_weight=10`.
    Print out the confusion matrix and the classification report to view the complete
    results:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建、拟合、预测并评分`XGBClassifier`，设置`scale_pos_weight=10`。打印出混淆矩阵和分类报告以查看完整结果：
- en: '[PRE52]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Here is the expected output:'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里是预期的输出：
- en: '[PRE53]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The results are the same as our resampling method from the previous section.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 结果与上一节的重采样方法相同。
- en: The oversampling method that we implemented from scratch gives the same predictions
    as `XGBClassifier` with `scale_pos_weight`.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从头开始实现的过采样方法给出的预测结果与`scale_pos_weight`的`XGBClassifier`一致。
- en: Tuning XGBClassifier
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整XGBClassifier
- en: It's time to see whether hyperparameter fine-tuning can increase precision.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候看看超参数微调是否能够提高精度了。
- en: It's standard to use `GridSearchCV` and `RandomizedSearchCV` when fine-tuning
    hyperparameters. Both require cross-validation of two or more folds. We have yet
    to implement cross-validation since our initial models did not perform well and
    it's computationally expensive to test multiple folds on large datasets.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调超参数时，标准做法是使用 `GridSearchCV` 和 `RandomizedSearchCV`。两者都需要进行两折或更多折的交叉验证。由于我们的初始模型效果不佳，并且在大型数据集上进行多折交叉验证计算成本高昂，因此我们尚未实施交叉验证。
- en: A balanced approach is to use `GridSearchCV` and `RandomizedSearchCV` with two
    folds to save time. To ensure consistent results, `StratifiedKFold` ([*Chapter
    6*](B15551_06_Final_NM_ePUB.xhtml#_idTextAnchor136), *XGBoost Hyperparameters*)
    is recommended. We will begin with the baseline model.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 一种平衡的方法是使用 `GridSearchCV` 和 `RandomizedSearchCV`，并采用两个折叠来节省时间。为了确保结果一致，推荐使用
    `StratifiedKFold`（[*第6章*](B15551_06_Final_NM_ePUB.xhtml#_idTextAnchor136)， *XGBoost
    超参数*）。我们将从基准模型开始。
- en: The baseline model
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基准模型
- en: 'Here are the steps to build a baseline model that implements the same k-fold
    cross-validation as grid searches:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是构建基准模型的步骤，该模型实现了与网格搜索相同的 k 折交叉验证：
- en: 'Import `GridSearchCV`, `RandomizedSearchCV`, `StratifiedKFold`, and `cross_val_score`:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `GridSearchCV`、`RandomizedSearchCV`、`StratifiedKFold` 和 `cross_val_score`：
- en: '[PRE54]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Intialize `StratifiedKFold` as `kfold` with `n_splits=2` and `shuffle=True`:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `StratifiedKFold` 初始化为 `kfold`，参数为 `n_splits=2` 和 `shuffle=True`：
- en: '[PRE55]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Initialize `XGBClassifier` with `scale_pos_weight=10` since there are 10 times
    as many negative cases as positive cases:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `scale_pos_weight=10` 初始化 `XGBClassifier`，因为负类样本是正类样本的 10 倍：
- en: '[PRE56]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Score the model using `cross_val_score` with `cv=kfold` and `score=''recall''`
    as parameters, then display the scores:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cross_val_score` 对模型进行评分，参数为 `cv=kfold` 和 `score='recall'`，然后显示得分：
- en: '[PRE57]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The scores are as follows:'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分数如下：
- en: '[PRE58]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The scores are a little worse with cross-validation. When there are very few
    positive cases, it makes a difference which rows end up in the training and test
    sets. Different implementations of `StratifiedKFold` and `train_test_split` may
    lead to different results.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 使用交叉验证后，得分稍微差一些。当正例非常少时，训练集和测试集中的行的选择会产生差异。`StratifiedKFold` 和 `train_test_split`
    的不同实现可能导致不同的结果。
- en: grid_search
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网格搜索
- en: 'We''ll now implement a variation of the `grid_search` function from [*Chapter
    6*](B15551_06_Final_NM_ePUB.xhtml#_idTextAnchor136), *XGBoost Hyperparameters*,
    to fine-tune hyperparameters:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实现来自 [*第6章*](B15551_06_Final_NM_ePUB.xhtml#_idTextAnchor136) 的 `grid_search`
    函数的一个变体， *XGBoost 超参数*，以便微调超参数：
- en: 'The new function takes the same dictionary of parameters as input, along with
    a random option that uses `RandomizedSearchCV`. In addition, `X` and `y` are provided
    as default parameters for use with other subsets and the scoring method is recall
    as follows:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新函数将参数字典作为输入，同时还提供一个使用 `RandomizedSearchCV` 的随机选项。此外，`X` 和 `y` 被作为默认参数提供，用于其他子集，并且评分方法为召回率，具体如下：
- en: '[PRE59]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Let''s run the grid searches excluding defaults to try and improve scores.
    Here are some initial grid searches along with their results:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们运行不使用默认设置的网格搜索，试图提高得分。以下是一些初始的网格搜索及其结果：
- en: 'a) Grid search 1:'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 网格搜索 1：
- en: '[PRE60]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Results:'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果：
- en: '[PRE61]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'b) Grid search 2:'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 网格搜索 2：
- en: '[PRE62]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Results:'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果：
- en: '[PRE63]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'c) Grid search 3:'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 网格搜索 3：
- en: '[PRE64]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Results:'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果：
- en: '[PRE65]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'd) Grid search 4:'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 网格搜索 4：
- en: '[PRE66]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Results:'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果：
- en: '[PRE67]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'e) Grid search 5:'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e) 网格搜索 5：
- en: '[PRE68]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Results:'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果：
- en: '[PRE69]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Changing `learning_rate` , `max_depth`, and `gamma` has resulted in gains.
    Let''s try to combine them by narrowing the range:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 改变 `learning_rate` 、`max_depth` 和 `gamma` 取得了提升。让我们通过缩小范围来尝试将它们组合起来：
- en: '[PRE70]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The score is as follows:'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分数如下：
- en: '[PRE71]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'It''s also worth trying `max_delta_step`, which XGBoost only recommends for
    imbalanced datasets. The default is 0 and increasing the steps results in a more
    conservative model:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还值得尝试 `max_delta_step`，XGBoost 仅建议在不平衡数据集上使用。默认值为 0，增加步骤会导致模型更加保守：
- en: '[PRE72]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The score is as follows:'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分数如下：
- en: '[PRE73]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'As a final strategy, we combine `subsample` with all the column samples in
    a random search:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为最终策略，我们通过在随机搜索中结合 `subsample` 和所有列样本：
- en: '[PRE74]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The score is as follows:'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分数如下：
- en: '[PRE75]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Instead of continuing with this subset of data that contains `400` rows, let's
    switch to the balanced subset (undersampled) that contains `74` rows to compare
    results.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 不继续使用包含 `400` 行数据的这个数据子集，而是切换到包含 `74` 行数据的平衡子集（欠采样），以比较结果。
- en: The balanced subset
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 平衡子集
- en: The balanced subset of `74` rows has the least amount of data points. It's also
    the fastest to test.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 包含 `74` 行数据的平衡子集数据点最少，它也是测试最快的。
- en: '`X` and `y` need to be explicitly defined since they were last used for the
    balanced subset inside a function. The new definitions for `X_short` and `y_short`
    are given as follows:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`X`和`y`最后一次是在函数内为平衡子集定义的，因此需要显式地定义它们。`X_short`和`y_short`的新定义如下：
- en: '[PRE76]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'After a few grid searches, combining `max_depth` and `colsample_bynode` gave
    the following results:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 经过几次网格搜索后，结合`max_depth`和`colsample_bynode`给出了以下结果：
- en: '[PRE77]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The score is as follows:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 分数如下：
- en: '[PRE78]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: This is an improvement.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个改进。
- en: It's time to try hyperparameter fine-tuning on all the data.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候在所有数据上尝试超参数微调了。
- en: Fine-tuning all the data
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微调所有数据
- en: 'The issue with implementing the `grid_search` function on all the data is time.
    Now that we are at the end, it''s time to run the code and take breaks as the
    computer sweats:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有数据上实现`grid_search`函数的问题是时间。现在我们已经接近尾声，到了运行代码并在计算机“出汗”时休息的时刻：
- en: 'Read all the data into a new DataFrame, `df_all`:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有数据读入一个新的DataFrame，`df_all`：
- en: '[PRE79]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Replace the 1s with 0s and the 2s with 1s:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将1替换为0，将2替换为1：
- en: '[PRE80]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Split the data into `X` and `y`:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为`X`和`y`：
- en: '[PRE81]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Verify `value_counts` of the `''LABEL''` column:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证`'LABEL'`列的`value_counts`：
- en: '[PRE82]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'The output is as follows:'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE83]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Scale the weights by dividing the negative class by the positive class:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将负类除以正类来缩放权重：
- en: '[PRE84]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Score a baseline model for all the data with `XGBClassifier` and `scale_pos_weight=weight`:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`XGBClassifier`和`scale_pos_weight=weight`对所有数据进行基准模型评分：
- en: '[PRE85]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'The output is as follows:'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE86]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: This score is awful. Presumably, the classifier is scoring a high percentage
    of accuracy, despite the low recall.
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个分数很糟糕。可能是分类器在准确率上得分很高，尽管召回率很低。
- en: 'Let''s try optimizing hyperparameters based on the most successful results
    thus far:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们尝试基于迄今为止最成功的结果优化超参数：
- en: '[PRE87]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'The score is as follows:'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分数如下：
- en: '[PRE88]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: This is much better than the initial score with all the data.
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这比使用所有数据时的初始分数要好得多。
- en: 'Let''s try combining hyperparameters:'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们尝试结合超参数：
- en: '[PRE89]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'The score is as follows:'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分数如下：
- en: '[PRE90]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: This is better, though not as strong as the undersampled dataset scored earlier.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经有所改善，但不如之前对欠采样数据集的得分强。
- en: With the score on all the data starting lower and taking more time, a question
    naturally arises. Are the machine learning models better on the smaller subsets
    for the Exoplanet dataset?
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在所有数据上的分数起始较低且需要更多时间，自然而然会产生一个问题。对于系外行星数据集，机器学习模型在较小的子集上是否表现更好？
- en: Let's find out.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看。
- en: Consolidating results
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 整合结果
- en: 'It''s tricky to consolidate results with different datasets. We have been working
    with the following subsets:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 将不同的数据集进行结果整合是很棘手的。我们一直在处理以下子集：
- en: 5,050 rows – approx. 54% recall
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5,050行 – 大约54%的召回率
- en: 400 rows – approx. 54% recall
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 400行 – 大约54%的召回率
- en: 74 rows – approx. 68% recall
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 74行 – 大约68%的召回率
- en: The best results obtained have included `learning_rate=0.001`, `max_depth=2`,
    and `colsample_bynode=0.5`.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 获得的最佳结果包括`learning_rate=0.001`，`max_depth=2`和`colsample_bynode=0.5`。
- en: Let's train a model on *all 37 exoplanet stars*. This means the test results
    will come from data points that the model has already trained on. Normally, this
    is not a good idea. In this case, however, the positive cases are very few and
    it may be instructive to see how the smaller subsets test on the positive cases
    it has not seen before.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在*所有37个系外行星恒星*上训练一个模型。这意味着测试结果将来自模型已经训练过的数据点。通常，这不是一个好主意。然而，在这种情况下，正例非常少，看看模型如何在它以前没有见过的正例上进行测试，可能会很有启发。
- en: 'The following function takes `X`, `y`, and the machine learning model as input.
    The model is fit on the data provided, then predictions are made on the entire
    dataset. Finally, `recall_score`, `confusion matrix`, and `classification report`
    are all printed:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数以`X`、`y`和机器学习模型为输入。模型在提供的数据上进行拟合，然后对整个数据集进行预测。最后，打印出`recall_score`、`confusion
    matrix`和`classification report`：
- en: '[PRE91]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Let's run the function for each of our three subsets. Of the three strongest
    hyperparameters, it turns out that `colsample_bynode` and `max_depth` give the
    best results.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为我们的三个子集运行函数。在三种最强的超参数中，事实证明`colsample_bynode`和`max_depth`给出了最佳结果。
- en: Let's start with the smallest number of rows, where the number of exoplanet
    stars and non-exoplanet stars match.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 从行数最少的地方开始，其中系外行星恒星和非系外行星恒星的数量相匹配。
- en: 74 rows
  id: totrans-387
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 74行
- en: 'Let''s begin with 74 rows:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从74行开始：
- en: '[PRE92]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'The output is as follows:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE93]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: All 37 exoplanet stars were correctly identified, but 1,462 non-exoplanet stars
    were misclassified! Despite 100% recall, the precision is 2%, and the F1 score
    is 5%. Low precision and a low F1 score are a risk when tuning for recall only.
    In practice, an astronomer would have to sort through 1,462 potential exoplanet
    stars to find 37\. This is unacceptable.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 所有37颗外行星恒星都被正确识别，但1462颗非外行星恒星被错误分类！尽管召回率达到了100%，但精确度只有2%，F1得分为5%。仅仅调优召回率会带来低精度和低F1得分的风险。实际上，天文学家需要筛选出1462颗潜在的外行星恒星，才能找到这37颗。这是不可接受的。
- en: Now let's see what happens when we train on 400 rows.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看在400行数据上训练时会发生什么。
- en: 400 rows
  id: totrans-394
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 400行
- en: 'In the case of 400 rows, we use the `scale_pos_weight=10` hyperparameter to
    balance the data:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在400行数据的情况下，我们使用`scale_pos_weight=10`超参数来平衡数据：
- en: '[PRE94]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'The output is as follows:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE95]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: Again, all 37 exoplanet stars were correctly classified for 100% recall, but
    149 non-exoplanet stars were incorrectly classified, for a precision of 20%. In
    this case, an astronomer would need to sort through 186 stars to find the 37 exoplanet
    stars.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，所有37颗外行星恒星都被正确分类，达到了100%的召回率，但149颗非外行星恒星被错误分类，精确度为20%。在这种情况下，天文学家需要筛选出186颗恒星，才能找到这37颗外行星恒星。
- en: Finally, let's train on all the data.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们在所有数据上进行训练。
- en: 5,050 rows
  id: totrans-401
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5050行
- en: 'In the case of all the data, set `scale_pos_weight` equal to the `weight` variable,
    as previously defined:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有数据的情况下，将`scale_pos_weight`设置为与先前定义的`weight`变量相等：
- en: '[PRE96]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'The output is as follows:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE97]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: Amazing. All predictions, recall and precision, are 100% perfect. In this highly
    desirable case, an astronomer would find all of the exoplanet stars without having
    to sift through any bad data.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 惊人。所有预测、召回率和精确度都完美达到了100%。在这种高度理想的情况下，天文学家无需筛选不良数据，就能找到所有的外行星恒星。
- en: Keep in mind, however, that these scores are based on the training data, not
    on unseen test data, which is mandatory to build a strong model. In other words,
    although the model fits the training data perfectly, it's unlikely to generalize
    this well to new data. These numbers, however, are valuable.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 但请记住，这些得分是基于训练数据，而非未见过的测试数据，而后者是构建强大模型的必要条件。换句话说，尽管模型完美地拟合了训练数据，但它不太可能对新数据进行良好的泛化。然而，这些数字仍然有价值。
- en: Based on this result, since the machine learning model performs impressively
    on the training set and modestly at best on the test set, the variance is likely
    too high. Additionally, more trees and more rounds of fine-tuning may be required
    to pick up on nuanced patterns within the data.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个结果，由于机器学习模型在训练集上表现出色，但在测试集上的表现最多只是适中，方差可能过高。此外，可能需要更多的树和更多轮次的精调，以便捕捉数据中的细微模式。
- en: Analyzing results
  id: totrans-409
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析结果
- en: 'When scored on the training set, the tuned models delivered perfect recall
    but varied considerably on the precision. Here are the takeaways:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练集上评分时，经过调优的模型提供了完美的召回率，但精确度差异较大。以下是关键要点：
- en: Using precision without recall or the F1 score can result in suboptimal models.
    By using the classification report, more details are revealed.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅使用精确度而不考虑召回率或F1得分，可能会导致次优模型。通过使用分类报告，能揭示更多细节。
- en: Over-emphasizing high scores from small subsets is not advised.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不建议过度强调小子集的高得分。
- en: When test scores are low, but training scores are high on imbalanced datasets,
    deeper models with extensive hyperparameter fine-tuning is advised.
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当测试得分较低，而训练得分较高时，建议在不平衡数据集上使用更深的模型并进行广泛的超参数调优。
- en: 'A survey of kernels, publicly displayed notebooks put forward by Kaggle users,
    at [https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data/kernels](https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data/kernels)
    for the Exoplanet dataset reveals the following:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle用户发布的公开笔记本中对内核的调查，位于[https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data/kernels](https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data/kernels)，展示了以下内容：
- en: Many users fail to understand that a high accuracy score is easy to obtain and
    virtually meaningless with highly imbalanced data.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多用户未能理解，尽管高准确率得分容易获得，但在高度不平衡的数据下，它几乎没有意义。
- en: Users posting precision are generally posting from 50 to 70 percent, and users
    posting recall are posting 60 to 100 percent (a user with 100% recall has 55%
    precision), indicating the challenges and limitations of this dataset.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布精确度的用户通常发布的是50%到70%之间的数据，而发布召回率的用户通常发布的是60%到100%之间（一个100%召回率的用户精确度为55%），这表明了该数据集的挑战和局限性。
- en: When you present your results to your astronomy professor, wiser to the limitations
    of imbalanced data, you conclude that your model performs with 70% recall at best,
    and that 37 exoplanet stars are not enough to build a robust machine learning
    model to find life on other planets. Your XGBClassifier, however, will allow astronomers
    and others trained in data analysis to use machine learning to decide which stars
    to focus on in the universe to discover the next exoplanets in orbit.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 当您向天文学教授展示您的结果时，您已经更加了解不平衡数据的局限性，您得出结论，您的模型最佳的召回率为 70%，而 37颗外行星恒星不足以构建一个强大的机器学习模型来寻找其他行星上的生命。然而，您的
    XGBClassifier 将使天文学家和其他经过数据分析训练的人能够使用机器学习来决定在宇宙中应集中关注哪些恒星，以发现下一个处于轨道上的外行星。
- en: Summary
  id: totrans-418
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you surveyed the universe with the Exoplanet dataset to discover
    new planets, and potentially new life. You built multiple XGBClassifiers to predict
    when exoplanet stars are the result of periodic changes in light. With only 37
    exoplanet stars and 5,050 non-exoplanet stars, you corrected the imbalanced data
    by undersampling, oversampling, and tuning XGBoost hyperparameters including `scale_pos_weight`.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，您使用外行星数据集对宇宙进行了调查，旨在发现新的行星，甚至可能发现新的生命。您构建了多个 XGBClassifier 来预测外行星恒星是否由光的周期性变化所引起。在仅有
    37颗外行星恒星和 5,050颗非外行星恒星的情况下，您通过欠采样、过采样和调整 XGBoost 超参数（包括 `scale_pos_weight`）来纠正数据的不平衡。
- en: You analyzed results using the confusion matrix and the classification report.
    You learned key differences between various classification scoring metrics, and
    why for the Exoplanet dataset accuracy is virtually worthless, while a high recall
    is ideal, especially when combined with high precision for a good F1 score. Finally,
    you realized the limitations of machine learning models when the data is extremely
    varied and imbalanced.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 您使用混淆矩阵和分类报告分析了结果。您学习了各种分类评分指标之间的关键差异，并且理解了为什么在外行星数据集中，准确率几乎没有价值，而高召回率是理想的，尤其是当与高精度结合时，能够得到一个好的
    F1 分数。最后，您意识到，当数据极其多样化且不平衡时，机器学习模型的局限性。
- en: After this case study, you have the necessary background and skills to fully
    analyze imbalanced datasets with XGBoost using `scale_pos_weight`, hyperparameter
    fine-tuning, and alternative classification scoring metrics.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个案例研究，您已具备了使用 XGBoost 完整分析不平衡数据集所需的背景知识和技能，掌握了 `scale_pos_weight`、超参数微调和替代分类评分指标的使用。
- en: In the next chapter, you will greatly expand your range of XGBoost by applying
    alternative XGBoost base learners beyond gradient boosted trees. Although gradient
    boosted trees are often the best option, XGBoost comes equipped with linear base
    learners, dart base learners, and even random forests, all coming next!
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将通过应用不同于梯度提升树的其他 XGBoost 基学习器，大大扩展您对 XGBoost 的应用范围。尽管梯度提升树通常是最佳选择，但 XGBoost
    配备了线性基学习器、DART 基学习器，甚至是随机森林，接下来都会介绍！
