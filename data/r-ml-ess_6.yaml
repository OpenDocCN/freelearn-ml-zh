- en: Chapter 6. Step 3 – Validating the Results
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 第3步 – 验证结果
- en: In the previous chapter, we estimated the language of new countries starting
    from their flag. For this purpose, we used KNN algorithm that is a supervised
    learning algorithm. We built KNN and measured its accuracy cross validating the
    estimated language. In this chapter, we will see how to measure the accuracy in
    a more reliable way and we will tune the KNN parameters to improve its performance.
    To be able to do the tasks in this chapter, it's not necessary for you to have
    read the previous chapter, although it is recommended so that you can order to
    understand how the KNN algorithm works.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们从新国家的国旗开始估计其语言。为此，我们使用了KNN算法，这是一种监督学习算法。我们构建了KNN并通过对估计的语言进行交叉验证来测量其准确性。在本章中，我们将了解如何以更可靠的方式测量准确性，并将调整KNN参数以提高其性能。为了能够完成本章的任务，你不需要阅读上一章，尽管这样做是推荐的，这样你可以理解KNN算法是如何工作的。
- en: 'In this chapter, you will learn how to:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何：
- en: Validate the accuracy of an algorithm
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证算法的准确性
- en: Tune the algorithm parameters
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整算法参数
- en: Select the most relevant data features
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择最相关的数据特征
- en: Optimize the parameters and the features together
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化参数和特征
- en: Validating a machine learning model
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证机器学习模型
- en: Starting from a table describing the countries, flags and their language, the
    KNN estimates a new country language starting from its flag attributes. In this
    chapter, we will evaluate the performance of KNN.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 从描述国家、国旗及其语言的表格开始，KNN根据国旗属性估计新国家的语言。在本章中，我们将评估KNN的性能。
- en: Measuring the accuracy of an algorithm
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测量算法的准确性
- en: We have already evaluated the algorithm accuracy by cross validating the estimated
    language. First, we split the data in two parts that are the training set and
    the test set. Then, we built the KNN algorithm using the training set in order
    to estimate the test set countries' language. Counting how many times the estimated
    language was correct, we defined an accuracy index as the percentage of correct
    guesses. The accuracy depends on which data we put into the test set. Since we
    randomly defined the training set countries, the accuracy changes every time we
    repeat the cross validation. Then, the result of this approach is not reliable.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过交叉验证估计的语言来评估了算法的准确性。首先，我们将数据分为两部分，即训练集和测试集。然后，我们使用训练集构建KNN算法来估计测试集国家的语言。计算估计语言正确的次数，我们定义了一个准确度指数，即正确猜测的百分比。准确度取决于我们放入测试集的数据。由于我们随机定义了训练集国家，每次重复交叉验证时准确度都会改变。因此，这种方法的结果不可靠。
- en: The target of this chapter is to evaluate KNN using a reliable technique in
    the sense that the accuracy doesn't change validating the same model twice. Repeating
    the train/set split and the validation many times, almost every country will be
    in both the training and the test set at least once. We can compute the average
    accuracy and it will take account of all the countries in both the training and
    the test sets. After a few iterations, the average accuracy will be reliable since
    it won't significantly change increasing the number of iterations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是使用一种可靠的技术来评估KNN，即准确性在验证同一模型两次时不会改变。重复进行训练/测试集分割和验证多次，几乎每个国家至少会在训练集和测试集中出现一次。我们可以计算平均准确性，并将考虑训练集和测试集中的所有国家。经过几次迭代后，平均准确性将变得可靠，因为增加迭代次数不会显著改变它。
- en: 'Before evaluating KNN, we need to load the `kknn` and `data.table` packages:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估KNN之前，我们需要加载`kknn`和`data.table`包：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can define a function building and cross validating KNN using a defined
    set of parameters and data so that we can quickly evaluate the algorithm with
    any configuration. Since the R commands are similar to the previous chapter, we
    will go quickly through them. The input of the functions is:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以定义一个函数，构建和交叉验证KNN，使用一组定义好的参数和数据，这样我们可以快速评估任何配置的算法。由于R命令与上一章类似，我们将快速浏览它们。函数的输入是：
- en: A table containing the data
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含数据的表格
- en: A vector containing the name of the features that we use
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含我们使用的特征名称的向量
- en: KNN parameters
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: KNN参数
- en: 'The steps are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤如下：
- en: Define which rows belong to the training and test sets. We build `indexTrain`,
    which is a vector specifying which rows will be in the training set. We set a
    probability of 10 percent for a flag to be in the test set. In [Chapter 5](ch05.html
    "Chapter 5. Step 2 – Applying Machine Learning Techniques"), *Step 2 – Applying
    Machine Learning Techniques*, we set a probability of 20 percent, but in this
    chapter we will repeat the validation many times, so 10 percent is enough.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义哪些行属于训练集和测试集。我们构建`indexTrain`，这是一个向量，指定哪些行将包含在训练集中。我们将测试集的标志设置为10%的概率。在[第5章](ch05.html
    "第5章。步骤2 – 应用机器学习技术")中，*步骤2 – 应用机器学习技术*，我们将概率设置为20%，但在这章中我们将多次重复验证，所以10%就足够了。
- en: Starting from `indexTrain`, extract the rows going into `dtTrain` and into `dtTest`.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`indexTrain`开始，提取进入`dtTrain`和`dtTest`的行。
- en: Define the formula defining the features and the attribute to predict.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义定义特征和预测属性的公式。
- en: Build KNN using the input parameters.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用输入参数构建KNN。
- en: Define the `languageFitted` vector containing the estimated language of the
    test set.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义包含测试集估计语言的`languageFitted`向量。
- en: Count how many times `languageFitted` is the same as the real language.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算多少次`languageFitted`与真实语言相同。
- en: Compute the accuracy index as the number of times the predicted language and
    the real language match, divided by the number of countries in the test set.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算准确率指数，即预测语言和实际语言匹配的次数除以测试集中国家的数量。
- en: 'This is the R code to build the function. The comments reflect the numbered
    bullet points, as shown:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是构建函数的R代码。注释反映了编号的要点，如下所示：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, `validateKnn` is the starting point to validate the KNN algorithm.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`validateKnn`是验证KNN算法的起点。
- en: Defining the average accuracy
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义平均准确率
- en: 'In order to use `validateKnn`, we need to define the input, as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用`validateKnn`，我们需要定义输入，如下所示：
- en: 'The data table with the features, as shown:'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征的数据表，如下所示：
- en: '[PRE2]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The vector containing all the possible features to include in KNN:'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含所有可能包含在KNN中的特征的向量：
- en: '[PRE3]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The KNN parameters that can either be set or left as their defaults.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: KNN参数可以是设置的，也可以保留为默认值。
- en: 'Now, we have all the elements to be able to use `validateKnn`. We can use a
    random subset of them, for instance, the first 10 features. With regard to the
    parameters, we can leave all of them to their default, except `k` that is equal
    to `8`, as shown:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了使用`validateKnn`所需的所有元素。我们可以使用它们的随机子集，例如，前10个特征。至于参数，我们可以将它们全部保留为默认值，除了`k`等于`8`，如下所示：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Running `validateKnn` more than once, we can notice that the result changes
    every time, as expected. However, now we can define another function running `validateKnn`
    multiple times. Then, we compute the accuracy average and use it as a reliable
    performance index. Our new function is called `cvKnn` because it cross validates
    KNN a defined number of times.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 多次运行`validateKnn`，我们可以注意到每次的结果都不同，这是预期的。然而，现在我们可以定义另一个函数，该函数运行`validateKnn`多次。然后，我们计算准确率平均值，并将其用作可靠的性能指标。我们的新函数称为`cvKnn`，因为它交叉验证KNN定义的次数。
- en: The `cvKnn` arguments are the data table, the number of iterations, the feature
    names, and the KNN parameters. Let's start defining the data table and the number
    of iterations. All the other input is the same as `validateKnn`. In order to have
    clear and compact code, we can use the ellipsis (...) specifying that we can add
    other arguments. Then, we can pass these arguments to any function using the ellipsis
    again. This means that when we will call `validateKnn`, we can use `validateKnn(...)`
    to specify that any extra argument of `cvKnn` will be an input for `validateKnn`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`cvKnn`参数是数据表、迭代次数、特征名称和KNN参数。让我们开始定义数据表和迭代次数。所有其他输入与`validateKnn`相同。为了使代码清晰紧凑，我们可以使用省略号(...)指定我们可以添加其他参数。然后，我们可以再次使用省略号将这些参数传递给任何函数。这意味着当我们调用`validateKnn`时，我们可以使用`validateKnn(...)`来指定`cvKnn`的任何额外参数都将作为`validateKnn`的输入。'
- en: 'The function steps are:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 函数步骤如下：
- en: Defining an empty vector `arrayPercCorrect` that will contain the accuracies.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个空的向量`arrayPercCorrect`，它将包含准确率。
- en: Running `validateKnn` and defining `arrayPercCorrect`, which contains the accuracy.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`validateKnn`并定义`arrayPercCorrect`，它包含准确率。
- en: Adding the accuracy `arrayPercCorrect` to `arrayPercCorrect`.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将准确率`arrayPercCorrect`添加到`arrayPercCorrect`中。
- en: 'This is the code that builds the function:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是构建函数的代码：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we can use `cvKnn` to build and validate KNN 500 times. Then, we compute
    the average accuracy as a KNN performance index:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`cvKnn`构建和验证KNN 500次。然后，我们计算平均准确率作为KNN性能指标：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We define `percCorrectMean`, which can be used as an accuracy index.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义`percCorrectMean`，它可以作为准确率指标。
- en: Visualizing the average accuracy computation
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化平均准确率计算
- en: 'In order to see how much the result changed at any iteration, we can compare
    each step''s accuracy with their average. First, we build a chart with the accuracies
    using `plot` and the parameters are:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看到结果在任意迭代时的变化程度，我们可以将每个步骤的准确率与平均值进行比较。首先，我们使用`plot`构建一个包含准确率的图表，参数如下：
- en: '`x`: This is the vector that we want to plot (`arrayPercCorrect`).'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：这是我们想要绘制的向量（`arrayPercCorrect`）。'
- en: '`ylim`: This is the accuracy that is a number between 0 and 1\. With `ylim
    = c(0, 1)`, we specify that the region that we visualize is between 0 and 1.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ylim`：这是介于0和1之间的准确率。通过`ylim = c(0, 1)`，我们指定可视化的区域在0和1之间。'
- en: '`xlab` and `ylab`: These are the axis labels.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlab`和`ylab`：这是坐标轴标签。'
- en: '`main`: This is the title.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`main`：这是标题。'
- en: 'The code is as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In order to compare the accuracies with their average, we can display the average
    by drawing a red dashed horizontal line with `abline`, as shown:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将准确率与平均值进行比较，我们可以通过绘制一条红色的虚线水平线来显示平均值，如下所示：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can visualize the values'' range by drawing a horizontal line for both the
    minimum and the maximum range, as shown:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过为最小值和最大值范围绘制水平线来可视化值的范围，如下所示：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The plot obtained is as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图表如下：
- en: '![Visualizing the average accuracy computation](img/7740OS_06_01.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![可视化平均准确率计算](img/7740OS_06_01.jpg)'
- en: The accuracy varies a lot from one iteration to another and the range is between
    0 percent and 70 percent. As expected, a single accuracy is completely unreliable.
    What about the average among 500 iterations? How many iterations do we need to
    have a stable result?
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率从一个迭代到另一个迭代变化很大，范围在0%到70%之间。正如预期的那样，单个准确率是完全不可靠的。500次迭代中的平均值怎么样？我们需要多少次迭代才能得到一个稳定的结果？
- en: We can visualize the accuracy index at the first iteration, then the average
    among the first two iterations, then the average among the first three, and so
    on. If at any point the average stops changing, we don't need to go any further.
    By building a chart we can observe how many iterations it takes to reach a stable
    average.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以可视化第一次迭代的准确率指标，然后是前两次迭代的平均值，然后是前三次迭代的平均值，依此类推。如果在任何点上平均值不再变化，我们就不需要再继续了。通过构建图表，我们可以观察到达到稳定平均值所需的迭代次数。
- en: 'First, let''s define `arrayCumulate` containing the cumulated average that
    is the partial average until each iteration, as shown:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义包含累积平均值的`arrayCumulate`，这是直到每个迭代的局部平均值，如下所示：
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Using the same commands as before, we build a new chart. The only new argument
    is `type=''l''` and it specifies that we display a line instead of points. In
    order to zoom into the area with the averages, we remove the `ylim` argument,
    as shown:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用与之前相同的命令，我们构建一个新的图表。唯一的新的参数是`type='l'`，它指定我们显示的是线而不是点。为了放大平均值所在的区域，我们移除了`ylim`参数，如下所示：
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The plot obtained is as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图表如下：
- en: '![Visualizing the average accuracy computation](img/7740OS_06_02.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![可视化平均准确率计算](img/7740OS_06_02.jpg)'
- en: We can notice that the accuracy is nearly stable after the 100 iterations. Assuming
    that it won't change too much with different parameter configuration, we can use
    100 iterations to validate the KNN algorithm.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以注意到，准确率在100次迭代后几乎保持稳定。假设它不会因不同的参数配置而变化太多，我们可以使用100次迭代来验证KNN算法。
- en: In this section, we have seen how to automatically evaluate a model performance
    using a specific set of features and some defined parameters. In the following
    sections, we will use this function to optimize the model's performance.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了如何使用一组特定的特征和一些定义的参数自动评估模型性能。在接下来的章节中，我们将使用这个函数来优化模型性能。
- en: Tuning the parameters
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整参数
- en: 'This section shows you how to improve the performance of KNN by tuning its
    parameters. We are dealing with the *k* parameter that defines the number of neighbors.
    Use these steps to identify the *k* parameter performing best:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 本节向您展示如何通过调整参数来提高KNN的性能。我们处理的是定义邻居数量的*k*参数。使用以下步骤来识别表现最佳的*k*参数：
- en: 'Define which values of *k* we will test. The KNN works locally, in the sense
    that given a new country flag it identifies just a few similar flags. How many
    of them should we use at most? Since there are less than 200 flags in total, we
    don''t want to use more than 50 flags. Then, we should test each *k* between 1
    and 50 and we can define `arrayK` containing the options:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义我们将测试的 *k* 值。KNN 在本地工作，也就是说，给定一个新的国家国旗，它只识别几个相似的国旗。我们最多应该使用多少个？由于总共有不到200个国旗，我们不希望使用超过50个国旗。然后，我们应该测试1到50之间的每个
    *k*，并可以定义包含选项的 `arrayK`：
- en: '[PRE12]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Define the number of iterations. For each *k* in `arrayK`, we need to build
    and validate the KNN a sufficiently high amount of times defined by `nIterations`.
    In the previous chapter, we learned that we need at least 100 iterations to have
    a meaningful KNN accuracy:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义迭代次数。对于 `arrayK` 中的每个 *k*，我们需要构建和验证 KNN，次数足够高，由 `nIterations` 定义。在前一章中，我们了解到我们需要至少100次迭代才能得到有意义的
    KNN 准确性：
- en: '[PRE13]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Evaluate the accuracy for each *k*.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估每个 *k* 的准确性。
- en: Choose the *k* that maximizes the accuracy.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择最大化准确性的 *k*。
- en: The last two steps are more detailed and we will explore them in depth.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两个步骤更详细，我们将深入探讨。
- en: 'In order to measure the accuracy for each *k*, we define `dtAccuracyK` as an
    empty data table that will contain the accuracies. Then, we use a `for` loop to
    run KNN with each *k* in *arrayK* and add the new results. The steps are as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测量每个 *k* 的准确性，我们定义 `dtAccuracyK` 为一个空的数据表，它将包含准确性。然后，我们使用 `for` 循环运行每个 `arrayK`
    中的 *k* 的 KNN 并添加新结果。步骤如下：
- en: Run and validate KNN using `cvKnn`.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cvKnn` 运行和验证 KNN。
- en: Define the rows that we will add to `dtAccuracyK` containing the accuracy and
    the *k*.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义要添加到 `dtAccuracyK` 的行，包含准确性和 *k*。
- en: 'Add the new rows to `dtAccuracyK` using `rbind`:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `rbind` 将新行添加到 `dtAccuracyK`：
- en: '[PRE14]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, let''s take a look at `result.head(dtAccuracyK)`:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看 `result.head(dtAccuracyK)`：
- en: '[PRE15]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Each row of `dtAccuracyK` contains an iteration of KNN. The first column displays
    the accuracy and the second column displays the *k* used in the iteration.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`dtAccuracyK` 的每一行都包含 KNN 的一个迭代。第一列显示准确性，第二列显示迭代中使用的 *k*。'
- en: 'In order to visualize the results, we can use `plot`. The two dimensions that
    we want to visualize are the *k* and the accuracy. The input is as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化结果，我们可以使用 `plot`。我们想要可视化的两个维度是 *k* 和准确性。输入如下：
- en: '`x`, `y`: These are the plot dimensions that are the `k` and `accuracy` columns'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`，`y`：这些是图表维度，分别是 `k` 和 `accuracy` 列'
- en: '`xlab`, `ylab`: These are the axis labels that are `k` and `accuracy`'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xlab`，`ylab`：这些是轴标签，分别是 `k` 和 `accuracy`'
- en: '`main`: This is the chart title'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`main`：这是图表标题'
- en: '`ylim`: These are the *y* region limits that are `0` and `1`'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ylim`：这些是 *y* 区域限制，分别是 `0` 和 `1`'
- en: '`col`: This is the color of the points that is gray, in order to put emphasis
    on the black points that we will add later'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`col`：这是点的颜色，为灰色，以便强调我们稍后要添加的黑点'
- en: 'The code is as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The plot obtained is as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图表如下：
- en: '![Tuning the parameters](img/7740OS_06_03.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![调整参数](img/7740OS_06_03.jpg)'
- en: Tip
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: You can also use `type = 'str(dtCvK)'` instead of `type = 'o'`.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用 `type = 'str(dtCvK)'` 而不是 `type = 'o'`。
- en: 'We cannot notice any relevant difference depending on *k*. The reason is that
    the accuracy varies a lot from one iteration to another. In order to identify
    *k* performing better, we can compute the average performance for each *k*. We
    call the new data table `dtCvK` because we''re cross validating the model, as
    shown:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法注意到任何与 *k* 相关的差异。原因是准确性从一个迭代到另一个迭代变化很大。为了识别表现更好的 *k*，我们可以计算每个 *k* 的平均性能。我们称新的数据表为
    `dtCvK`，因为我们正在交叉验证模型，如下所示：
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here, `dtCvK` contains the average accuracy of each *k*. We can add it to the
    chart using points that is a function adding the new points to the current chart.
    In order to make the points more visible, we display full points using `pch =
    16`, as shown:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`dtCvK` 包含每个 *k* 的平均准确性。我们可以使用添加新点到当前图表的函数将它们添加到图表中。为了使点更明显，我们使用 `pch =
    16` 显示完整点，如下所示：
- en: '[PRE18]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The plot is as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图表如下：
- en: '![Tuning the parameters](img/7740OS_06_04.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![调整参数](img/7740OS_06_04.jpg)'
- en: 'The average accuracies vary across the *k*, but it is hard to notice the difference
    because it is always around 0.3 to 0.4\. In order to see the difference more clearly,
    we can plot just the average without visualizing the *y* limits, as shown:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 平均准确性随 *k* 变化，但很难注意到差异，因为它始终在 0.3 到 0.4 之间。为了更清楚地看到差异，我们可以只绘制平均值而不可视化 *y* 限制，如下所示：
- en: '[PRE19]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Tip
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: You can also use `type = 'str(dtCvK)'` instead of type = `'o'`.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用 `type = 'str(dtCvK)'` 而不是 `type = 'o'`。
- en: 'We can identify the *k* performing best and add it to the chart using `abline`:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以识别表现最佳的 *k* 并使用 `abline` 将其添加到图表中：
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Tip
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: You can also use `kOpt <- 27` instead of `kOpt <- dtCvK[accuracy == max(accuracy),
    k]`.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用 `kOpt <- 27` 而不是 `kOpt <- dtCvK[accuracy == max(accuracy), k]`。
- en: 'The plot obtained is as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图如下：
- en: '![Tuning the parameters](img/7740OS_06_05.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![调整参数](img/7740OS_06_05.jpg)'
- en: The optimal *k* is 27 and the KNN performs very well if the *k* is in the 22
    to 30 range.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳 *k* 值为 27，如果 *k* 在 22 到 30 的范围内，KNN 的表现非常好。
- en: In this chapter, we identified *k* performing at its best. However, there are
    still other parameters that we haven't optimized, such as the distance method.
    In addition, we can improve the algorithm selecting the features to include and
    we will explore it in the next section.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们确定了表现最佳的 *k*。然而，还有一些其他参数我们没有优化，例如距离方法。此外，我们可以通过选择要包含的特征来改进算法，我们将在下一节中探讨。
- en: Selecting the data features to include in the model
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择要包含在模型中的数据特征
- en: In the previous section, we set a KNN parameter maximizing the performance.
    Another tuning option is to define which data we use to build the model. Our table
    describes the flags using 37 features and we included all of them in the model.
    However, KNN might perform better including only a subset of them.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们设置了一个最大化性能的 KNN 参数。另一个调整选项是定义我们用于构建模型的数据。我们的表格描述了使用 37 个特征的标志，并将它们全部包含在模型中。然而，KNN
    可能仅包括其中的一小部分时表现更好。
- en: The easiest way to select the features is to use a filter (as anticipated in
    the *Ranking the features using a filter or a dimensionality reduction* section
    in [Chapter 4](ch04.html "Chapter 4. Step 1 – Data Exploration and Feature Engineering"),
    *Step 1 – Data Exploration and Feature Engineering*) that estimates the impact
    of each feature and includes only the most relevant features. After ranking all
    the features on the basis of their relevance, we can define the `n` parameters
    specifying how many of them we include in the model. Then, we can maximize the
    accuracy depending on `n`, using an approach similar to the previous section.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 选择特征的最简单方法是使用过滤器（如在第 4 章的 *使用过滤器或降维对特征进行排序* 部分中预期的那样，[第 4 章](ch04.html "第 4
    章。步骤 1 – 数据探索和特征工程")，*步骤 1 – 数据探索和特征工程*），该过滤器估计每个特征的影响，并仅包含最相关的特征。在根据相关性对所有特征进行排序后，我们可以定义
    `n` 参数，指定我们在模型中包含多少个这样的特征。然后，我们可以根据 `n` 最大化准确性，使用与上一节类似的方法。
- en: 'The first step is defining how to rank the features. We can use the information
    gain ratio filter that estimated the impact of each feature ignoring the others.
    We have already talked about the information gain ratio and its limitations (refer
    to the *Ranking the features using a filter or a dimensionality reduction* section
    in [Chapter 4](ch04.html "Chapter 4. Step 1 – Data Exploration and Feature Engineering"),
    *Step 1 – Data Exploration and Feature Engineering*) and we will use the same
    R commands, as shown:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是定义如何对特征进行排序。我们可以使用信息增益率过滤器来估计每个特征的影响，同时忽略其他特征。我们已讨论过信息增益率及其局限性（请参阅第 4 章的
    *使用过滤器或降维对特征进行排序* 部分，[第 4 章](ch04.html "第 4 章。步骤 1 – 数据探索和特征工程")，*步骤 1 – 数据探索和特征工程*），我们将使用相同的
    R 命令，如下所示：
- en: '[PRE21]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Here, `arrayFeatures` contains the features sorted by relevance. Now, we can
    build the model choosing the top *n* features. The options for *n* are the numbers
    between `1` and the total number of features, and we define `arrayN` containing
    them, as shown:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`arrayFeatures` 包含按相关性排序的特征。现在，我们可以通过选择前 *n* 个特征来构建模型。*n* 的选项是介于 `1` 和特征总数之间的数字，我们定义
    `arrayN` 来包含它们，如下所示：
- en: '[PRE22]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In order to store the accuracy of each iteration, we define `dtAccuracyN` as
    an empty data table and we iteratively add the rows using a `for` loop. The steps
    are as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了存储每次迭代的准确性，我们定义 `dtAccuracyN` 为一个空数据表，并使用 `for` 循环迭代地添加行。步骤如下：
- en: Validate KNN using `cvKnn` and store the accuracies in `arrayAccuracy`. We set
    the *k* parameter equal to `kOpt (27)`, that is, the optimal *k* defined in the
    previous section.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cvKnn` 验证 KNN 并将准确性存储在 `arrayAccuracy` 中。我们将 *k* 参数设置为 `kOpt (27)`，即上一节中定义的最佳
    *k*。
- en: Define the `rowsAccuracyN` data table with the rows to add.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义包含要添加行的 `rowsAccuracyN` 数据表。
- en: Add the new rows to `dtAccuracyN` using `rbind`.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `rbind` 将新行添加到 `dtAccuracyN`。
- en: 'This is the code generating the `for` loop:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这是生成 `for` 循环的代码：
- en: '[PRE23]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here, `dtAccuracyN` contains each iteration accuracy, depending on *n*. We
    can build a chart containing all the accuracies and their average across different
    values of *n*, by using the following steps:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`dtAccuracyN`包含每个迭代的准确率，取决于*n*。我们可以通过以下步骤构建一个包含所有准确率和它们在不同*n*值上的平均值的图表：
- en: 'Build a chart displaying the accuracy at each iteration:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 建立一个显示每次迭代的准确率的图表：
- en: '[PRE24]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Starting from `dtAccuracyN`, compute the average accuracy for each iteration:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`dtAccuracyN`开始，计算每个迭代的平均准确率：
- en: '[PRE25]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Add the points with the average accuracy to the chart:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将平均准确率的点添加到图表中：
- en: '[PRE26]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The plot obtained is as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图如下：
- en: '![Selecting the data features to include in the model](img/7740OS_06_06.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![选择模型中包含的数据特征](img/7740OS_06_06.jpg)'
- en: 'The chart shows that we achieved the best accuracies using high values of *n*.
    In order to identify the best *n*, we can plot just their averages. Then, we define
    `nOpt` that is the *n* performing best and we add a red vertical line corresponding
    to it, as shown:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图表显示，我们使用高值的*n*实现了最佳准确率。为了确定最佳的*n*，我们可以仅绘制它们的平均值。然后，我们定义`nOpt`，即表现最佳的*n*，并添加一个对应的红色垂直线，如图所示：
- en: '[PRE27]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The plot obtained is as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图如下：
- en: '![Selecting the data features to include in the model](img/7740OS_06_07.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![选择模型中包含的数据特征](img/7740OS_06_07.jpg)'
- en: The number of features performing best is **15** and the performance decreases
    slowly after this point.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 表现最好的特征数量是**15**，在此之后性能缓慢下降。
- en: In the chart, we can notice that there are some points in which the accuracy
    decreases a lot adding a new feature (for example, **3**, **11**, **13**). In
    these points, we are adding a feature that decreases the performance. What if
    we just decide not to include it? We can start building the model using the most
    relevant feature only, and then add the second most relevant feature. If the performance
    improves, we keep the second feature; otherwise, we discard it. After that, we
    do the same with the third feature and we repeat this until we have added or discarded
    each feature. This approach is called wrapper and it allows us to define a better
    feature set than the filter.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在图表中，我们可以注意到有些点在添加新特征时准确率会大幅下降（例如，**3**，**11**，**13**）。在这些点上，我们添加的特征降低了性能。如果我们决定不包含它会怎样呢？我们可以仅使用最相关的特征来构建模型，然后添加第二个最相关的特征。如果性能有所提高，我们保留第二个特征；否则，我们丢弃它。之后，我们用同样的方法处理第三个特征，并重复此过程，直到我们添加或丢弃了每个特征。这种方法被称为包装器，它允许我们定义比过滤器更好的特征集。
- en: In this section, we identified the best *n* and the best *k*, so we use them
    to build KNN with a good performance.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们确定了最佳的*n*和最佳的*k*，因此我们使用它们来构建具有良好性能的KNN。
- en: Tuning features and parameters together
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一起调整特征和参数
- en: In the previous two sections, we identified the best *k* using all the features
    (`n=37`). Then, using the optimal *k*, we identified the best *n*. What if the
    algorithm performs better with `k=30` and `n=25`? We haven't explored that combination
    as well as many other options, so there might be a combination performing better
    than `k=27` and `n=15`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两个部分中，我们使用所有特征（`n=37`）确定了最佳*k*。然后，使用最佳的*k*，我们确定了最佳的*n*。如果算法在`k=30`和`n=25`时表现更好，会怎样呢？我们还没有充分探索这个组合以及许多其他选项，所以可能存在比`k=27`和`n=15`表现更好的组合。
- en: In order to identify the best option, the most simple approach is to test all
    the alternatives. However, if there are too many possible combinations between
    the variables, we don't have enough computational power to test all of them. In
    that case, we can identify the optimal parameters using optimization algorithms
    such as the gradient descend.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定最佳选项，最简单的方法是测试所有备选方案。然而，如果变量之间存在太多的可能组合，我们可能没有足够的计算能力来测试所有这些组合。在这种情况下，我们可以使用梯度下降等优化算法来确定最佳参数。
- en: 'Fortunately, in our case, we are tuning only two parameters and we can test
    just a part of their possible values. For instance, if we choose 20 values of
    *n* and 20 values of *k*, we have 400 combinations. In order to do that, we carry
    out the following steps:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，在我们的案例中，我们只需要调整两个参数，并且可以测试它们可能值的一部分。例如，如果我们选择20个*n*的值和20个*k*的值，我们就有400种组合。为了做到这一点，我们执行以下步骤：
- en: 'Define the options for *k*. Include all features, the KNN had the best performance
    with `k=26` and it performed badly after `40`. However, setting a lower *n*, things
    may change, so we need to test all the possible *k*. In order to limit the number
    of options, we can limit our testing to the odd numbers. Let''s generate all the
    odd numbers between 1 and 49 using `seq`. The `from` and `to` arguments define
    the start and end of the sequence. The `by` argument defines the increment that
    is 2 to generate the odd numbers. Using `seq`, we build `arrayK` containing all
    the options for *k*, as shown:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 *k* 的选项。包括所有特征，KNN 在 `k=26` 时表现最佳，之后 `40` 就表现不佳。然而，设置较低的 *n*，情况可能会改变，因此我们需要测试所有可能的
    *k*。为了限制选项数量，我们可以将测试限制在奇数。让我们使用 `seq` 生成 1 到 49 之间的所有奇数。`from` 和 `to` 参数定义序列的开始和结束。`by`
    参数定义增量，为 2 以生成奇数。使用 `seq`，我们构建包含所有 *k* 选项的 `arrayK`，如下所示：
- en: '[PRE28]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Define the options for *n*. We have already seen that the algorithm performs
    very badly using just a small feature set, so we can test *n* between 10 and the
    total number of features, that is, 37\. Similar to *k*, we include only the odd
    numbers:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 *n* 的选项。我们已经看到，算法仅使用少量特征集时表现非常糟糕，因此我们可以测试 *n* 的值在 10 到特征总数之间，即 37。与 *k* 类似，我们只包括奇数：
- en: '[PRE29]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Generate all the possible combinations between *k* and *n*. For this purpose,
    we can use `expand.grid`. Given two or more vectors, `expand.grid` generates a
    data frame with all their possible combinations. In our case, we generate a `k`
    column starting from `arrayK` and a `n` column starting from `arrayN`, as shown:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成 *k* 和 *n* 之间所有可能的组合。为此，我们可以使用 `expand.grid`。给定两个或多个向量，`expand.grid` 生成一个包含它们所有可能组合的数据框。在我们的情况下，我们生成一个从
    `arrayK` 开始的 `k` 列和一个从 `arrayN` 开始的 `n` 列，如下所示：
- en: '[PRE30]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Convert `dfParameters` into a data table:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `dfParameters` 转换为数据表：
- en: '[PRE31]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, we can take a look at `dtParameters` using `head`:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 `head` 查看 `dtParameters`：
- en: '[PRE32]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Here, `dtParameters` contains a row for each of the 350 combinations. We need
    to determine the accuracies and store them in a new column called `accuracy`.
    In order to do that, we use a `for` loop running over the rows. The `iConfig`
    variable is the row index defined as a number between 1 and the number of rows
    `nrow(dtParameters)`. There are different combinations, so it might take a while
    to run this part of the code. After each iteration we build the model using the
    parameters contained in the row that are:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`dtParameters` 包含每个 350 种组合的行。我们需要确定准确度并将它们存储在一个名为 `accuracy` 的新列中。为了做到这一点，我们使用一个遍历行的
    `for` 循环。`iConfig` 变量是行索引，定义为介于 1 和 `nrow(dtParameters)` 行数之间的数字。存在不同的组合，因此这部分代码可能需要一段时间才能运行。在每次迭代后，我们使用行中包含的参数构建模型：
- en: '**k**: This has the `dtParameters[iConfig, k]` parameter'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**k**：这具有 `dtParameters[iConfig, k]` 参数'
- en: '**n**: This has the `dtParameters[iConfig, n]` parameter'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**n**：这具有 `dtParameters[iConfig, n]` 参数'
- en: 'Consider the following code:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下代码：
- en: '[PRE33]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, we can compute the `arrayAccuracy` average and add it to `dtParameters`:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以计算 `arrayAccuracy` 平均值并将其添加到 `dtParameters`：
- en: '[PRE34]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Each row of `dtParameters` contains a parameter set and its related accuracy.
    In order to view the accuracies in a more convenient way, we can build a matrix
    whose rows correspond to `n` and whose columns correspond to `k`. Each element
    of the matrix displays the accuracy. In order to build the matrix, we can use
    `reshape`, as shown:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`dtParameters` 的每一行包含一个参数集及其相关的准确度。为了更方便地查看准确度，我们可以构建一个矩阵，其行对应于 `n`，列对应于 `k`。矩阵的每个元素显示准确度。为了构建矩阵，我们可以使用
    `reshape`，如下所示：'
- en: '[PRE35]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The `reshape` syntax is quite complex. In our case, that matrix that we want
    to build is in a `wide` format, so we need to specify `direction = "wide"`. The
    other arguments define the columns that we use and they are:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '`reshape` 语法相当复杂。在我们的情况下，我们想要构建的矩阵是 `wide` 格式，因此我们需要指定 `direction = "wide"`。其他参数定义我们使用的列，它们是：'
- en: '`v.names`: This column defines the matrix values (the accuracies)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`v.names`：此列定义矩阵值（准确度）'
- en: '`idvar`: This column defines the matrix rows (the values of `n`)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`idvar`：此列定义矩阵行（`n` 的值）'
- en: '`timevar`: This column defines the matrix columns (the values of `k`)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timevar`：此列定义矩阵列（`k` 的值）'
- en: 'Using `reshape`, we can build the `dfAccuracy` data frame, as shown:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `reshape`，我们可以构建如所示的 `dfAccuracy` 数据框：
- en: '[PRE36]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The `n` column contains the *n* parameter and we remove it in order to have
    a data frame with the accuracy only. Then, we convert the data frame into a matrix,
    as shown:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`n` 列包含 *n* 参数，我们将其删除以获得仅包含准确度的数据框。然后，我们将数据框转换为矩阵，如下所示：'
- en: '[PRE37]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, we can specify `n` and `k` as the row names and column names respectively,
    as shown:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将 `n` 和 `k` 分别指定为行名和列名，如下所示：
- en: '[PRE38]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'In order to visualize the accuracy depending on the parameters, we can build
    a heat map that is a chart representing the matrix. The two chart dimensions are
    `k` and `n` and the color represents the value. We can build this chart using
    `image`:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化参数的准确率，我们可以构建一个热图，这是一个表示矩阵的图表。两个图表维度是 `k` 和 `n`，颜色代表值。我们可以使用 `image` 构建这个图表：
- en: '[PRE39]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The arguments that we use are:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的参数是：
- en: '`z`: This is the matrix'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`z`：这是一个矩阵'
- en: '`x` and `y`: These are the dimension names, contained in `arrayN` and `arrayK`'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x` 和 `y`：这些是维度名称，包含在 `arrayN` 和 `arrayK` 中'
- en: '`xLab` and `yLab`: These are the axis labels'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xLab` 和 `yLab`：这些是坐标轴标签'
- en: '`col`: This is the vector of colors that we display (we can use the `heat.colors`
    function)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`col`：这是我们显示的颜色向量（我们可以使用 `heat.colors` 函数）'
- en: 'Consider the following code:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下代码：
- en: '[PRE40]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The plot obtained is as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图如下：
- en: '![Tuning features and parameters together](img/7740OS_06_08.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![一起调整特征和参数](img/7740OS_06_08.jpg)'
- en: A high accuracy is represented by the pale yellow color and a low accuracy is
    represented by the red color. We can notice that we achieved the best accuracy
    with *k* in the 9 to 19 range and *n* in the 29 to 33 range. The worst performance
    is when *n* is low and *k* is high.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 高准确率用浅黄色表示，低准确率用红色表示。我们可以注意到，我们在 `k` 在9到19范围内和 `n` 在29到33范围内达到了最佳准确率。最差性能发生在
    `n` 低而 `k` 高的情况下。
- en: 'Let''s see what the best performing combination is. Consider the following
    code:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看最佳性能组合是什么。考虑以下代码：
- en: '[PRE41]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The best combination is `k=11` and `n=33` and we were not able to identify it
    maximizing the parameters separately. The reason is that the KNN performs well
    with `k=11` only if we don't include all the features.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳组合是 `k=11` 和 `n=33`，我们无法通过单独最大化参数来识别它。原因是，只有当我们不包括所有特征时，KNN才会在 `k=11` 时表现良好。
- en: In this section, we saw a simple way to optimize two parameters. In other contexts,
    we need more advanced techniques.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了一种优化两个参数的简单方法。在其他情况下，我们需要更高级的技术。
- en: A limit of this approach is that we tuned only two parameters. We can achieve
    better performances tuning other KNN parameters such as the distance method.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的局限性在于我们只调整了两个参数。我们可以通过调整其他KNN参数（如距离方法）来达到更好的性能。
- en: Summary
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to evaluate the performance of a model as the
    average accuracy of the prediction. We understood how to determine an accurate
    cross-validation index expressing the accuracy. Starting from the cross-validation
    index, we tuned the parameters. In addition, we learned how to select the features
    using a filter or a frapper and how to tune features and parameters at the same
    time. This chapter described the last part of building a machine learning solution
    and the next chapter shows an overview of some of the most important machine learning
    techniques.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何将模型的性能评估为预测的平均准确率。我们了解了如何确定表示准确率的准确交叉验证指数。从交叉验证指数开始，我们调整了参数。此外，我们还学习了如何使用过滤器或frapper选择特征，以及如何同时调整特征和参数。本章描述了构建机器学习解决方案的最后部分，下一章将概述一些最重要的机器学习技术。
