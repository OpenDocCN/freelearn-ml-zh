- en: Chapter 10. Evaluating Model Performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章：评估模型性能
- en: When only the wealthy could afford education, tests and exams did not evaluate
    students' potential. Instead, teachers were judged for parents who wanted to know
    whether their children had learned enough to justify the instructors' wages. Obviously,
    this has changed over the years. Now, such evaluations are used to distinguish
    between high- and low-achieving students, filtering them into careers and other
    opportunities.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当只有富人能负担得起教育时，测试和考试并没有评估学生的潜力。相反，教师是根据家长的要求来评判的，家长们希望知道他们的孩子是否学到了足够的知识，以证明教员的薪水。显然，随着时间的推移，这种情况发生了变化。现在，这些评估被用来区分高成就和低成就的学生，并将他们筛选到职业和其他机会中。
- en: Given the significance of this process, a great deal of effort is invested in
    developing accurate student assessments. Fair assessments have a large number
    of questions that cover a wide breadth of topics and reward true knowledge over
    lucky guesses. They also require students to think about problems they have never
    faced before. Correct responses therefore indicate that students can generalize
    their knowledge more broadly.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这个过程的重要性，投入了大量精力来开发准确的学生评估。公平的评估有大量的问题，覆盖广泛的主题，奖励真实的知识而不是运气猜测。它们还要求学生思考他们之前从未遇到过的问题。因此，正确的回答表明学生能够更广泛地概括他们的知识。
- en: The process of evaluating machine learning algorithms is very similar to the
    process of evaluating students. Since algorithms have varying strengths and weaknesses,
    tests should distinguish among the learners. It is also important to forecast
    how a learner will perform on future data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 评估机器学习算法的过程与评估学生的过程非常相似。由于算法有不同的优缺点，测试应该能够区分不同的学习者。预测学习者在未来数据上的表现也同样重要。
- en: 'This chapter provides the information needed to assess machine learners, such
    as:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了评估机器学习者所需的信息，例如：
- en: The reasons why predictive accuracy is not sufficient to measure performance,
    and the performance measures you might use instead
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么预测准确率不足以衡量性能，以及你可以使用的其他性能度量
- en: Methods to ensure that the performance measures reasonably reflect a model's
    ability to predict or forecast unseen cases
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保性能度量合理反映模型预测或预测未见过案例的能力的方法
- en: How to use R to apply these more useful measures and methods to the predictive
    models covered in the previous chapters
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用R语言将这些更有用的度量和方法应用到前几章中讨论的预测模型上
- en: Just as the best way to learn a topic is to attempt to teach it to someone else,
    the process of teaching and evaluating machine learners will provide you with
    greater insight into the methods you've learned so far.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 就像学习某个主题的最佳方式是尝试将其教授给别人一样，教学和评估机器学习者的过程将为你提供更多关于迄今为止所学方法的洞察。
- en: Measuring performance for classification
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 衡量分类的性能
- en: In the previous chapters, we measured classifier accuracy by dividing the proportion
    of correct predictions by the total number of predictions. This indicates the
    percentage of cases in which the learner is right or wrong. For example, suppose
    that for 99,990 out of 100,000 newborn babies a classifier correctly predicted
    whether they were a carrier of a treatable but potentially fatal genetic defect.
    This would imply an accuracy of 99.99 percent and an error rate of only 0.01 percent.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们通过将正确预测的比例除以预测的总数来衡量分类器的准确性。这表示学习者在多少情况下是正确的或错误的。例如，假设在100,000名新生儿中，有99,990名婴儿的基因缺陷是否携带被分类器正确预测。这样的话，准确率将是99.99%，错误率仅为0.01%。
- en: At first glance, this appears to be an extremely accurate classifier. However,
    it would be wise to collect additional information before trusting your child's
    life to the test. What if the genetic defect is found in only 10 out of every
    100,000 babies? A test that predicts *no defect* regardless of the circumstances
    will be correct for 99.99 percent of all cases, but incorrect for 100 percent
    of the cases that matter most. In other words, even though the predictions are
    extremely accurate, the classifier is not very useful to prevent treatable birth
    defects.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，这似乎是一个极其准确的分类器。然而，在将你孩子的生命交给该测试之前，最好先收集更多的信息。如果这种基因缺陷仅在每10万个婴儿中有10个发现，怎么办？无论在什么情况下，始终预测*没有缺陷*的测试对99.99%的所有案例都是正确的，但对100%最重要的案例却是错误的。换句话说，尽管预测非常准确，但这个分类器对于防止可治疗的出生缺陷并没有多大帮助。
- en: Tip
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: This is one consequence of the **class imbalance problem**, which refers to
    the trouble associated with data having a large majority of records belonging
    to a single class.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这是**类别不平衡问题**的一个后果，指的是数据中大多数记录属于同一类别所带来的问题。
- en: Though there are many ways to measure a classifier's performance, the best measure
    is always the one that captures whether the classifier is successful at its intended
    purpose. It is crucial to define the performance measures for utility rather than
    raw accuracy. To this end, we will begin exploring a variety of alternative performance
    measures derived from the confusion matrix. Before we get started, however, we
    need to consider how to prepare a classifier for evaluation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有许多方法可以衡量分类器的性能，但最好的衡量标准总是能够捕捉分类器在其预期目标上是否成功的标准。定义性能度量时，关键是要以效用为导向，而非单纯的准确率。为此，我们将开始探索从混淆矩阵中衍生出的各种替代性性能度量方法。然而，在我们开始之前，我们需要考虑如何准备分类器进行评估。
- en: Working with classification prediction data in R
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 R 中处理分类预测数据
- en: The goal of evaluating a classification model is to have a better understanding
    of how its performance will extrapolate to future cases. Since it is usually unfeasible
    to test a still-unproven model in a live environment, we typically simulate future
    conditions by asking the model to classify a dataset made of cases that resemble
    what it will be asked to do in the future. By observing the learner's responses
    to this examination, we can learn about its strengths and weaknesses.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 评估分类模型的目标是更好地理解其性能如何推断到未来的案例。由于在实际环境中测试一个尚未验证的模型通常是不可行的，我们通常通过要求模型对一个包含类似未来任务的案例的数据集进行分类，从而模拟未来的情况。通过观察学习者对这一检验的回应，我们可以了解其优点和缺点。
- en: 'Though we''ve evaluated classifiers in the prior chapters, it''s worth reflecting
    on the types of data at our disposal:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在前面的章节中评估了分类器，但值得反思一下我们所拥有的数据类型：
- en: Actual class values
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际类别值
- en: Predicted class values
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测类别值
- en: Estimated probability of the prediction
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测的估计概率
- en: 'The actual and predicted class values may be self-evident, but they are the
    key to evaluation. Just like a teacher uses an answer key to assess the student''s
    answers, we need to know the correct answer for a machine learner''s predictions.
    The goal is to maintain two vectors of data: one holding the correct or actual
    class values, and the other holding the predicted class values. Both vectors must
    have the same number of values stored in the same order. The predicted and actual
    values may be stored as separate R vectors or columns in a single R data frame.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 实际值和预测的类别值可能是显而易见的，但它们是评估的关键。就像老师用答案解析来评估学生的答案一样，我们需要知道机器学习者预测的正确答案。目标是保持两个数据向量：一个存储正确或实际的类别值，另一个存储预测的类别值。这两个向量必须包含相同数量的值，并按相同的顺序排列。预测值和实际值可以存储为独立的
    R 向量，或者在一个 R 数据框中作为列存储。
- en: 'Obtaining this data is easy. The actual class values come directly from the
    target feature in the test dataset. Predicted class values are obtained from the
    classifier built upon the training data, and applied to the test data. For most
    machine learning packages, this involves applying the `predict()` function to
    a model object and a data frame of test data, such as: `predicted_outcome <- predict(model,
    test_data)`.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 获取这些数据很容易。实际的类别值直接来自测试数据集中的目标特征。预测类别值是通过基于训练数据构建的分类器来获取的，并应用于测试数据。对于大多数机器学习包来说，这通常涉及对模型对象和测试数据框应用`predict()`函数，例如：`predicted_outcome
    <- predict(model, test_data)`。
- en: Until now, we have only examined classification predictions using these two
    vectors of data. Yet most models can supply another piece of useful information.
    Even though the classifier makes a single prediction about each example, it may
    be more confident about some decisions than others. For instance, a classifier
    may be 99 percent certain that an SMS with the words "free" and "ringtones" is
    spam, but is only 51 percent certain that an SMS with the word "tonight" is spam.
    In both cases, the classifier classifies the message as spam, but it is far more
    certain about one decision than the other.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们仅仅使用这两个数据向量来检查分类预测。然而，大多数模型可以提供另一个有用的信息。即使分类器对每个样本做出单一的预测，它对于某些决策的信心可能会高于其他决策。例如，分类器可能有
    99% 的把握认为包含“免费”和“铃声”字样的短信是垃圾短信，但对含有“今晚”字样的短信只有 51% 的把握是垃圾短信。在这两种情况下，分类器都会将消息归类为垃圾短信，但对其中一个决策的信心远高于另一个。
- en: '![Working with classification prediction data in R](img/B03905_10_01.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![在R中处理分类预测数据](img/B03905_10_01.jpg)'
- en: Studying these internal prediction probabilities provides useful data to evaluate
    a model's performance. If two models make the same number of mistakes, but one
    is more capable of accurately assessing its uncertainty, then it is a smarter
    model. It's ideal to fid a learner that is extremely confident when making a correct
    prediction, but timid in the face of doubt. The balance between confidence and
    caution is a key part of model evaluation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 研究这些内部预测概率可以提供有用的数据来评估模型的表现。如果两个模型犯了相同数量的错误，但其中一个能够更准确地评估其不确定性，那么这个模型更为智能。理想情况下，应该找到一个在做出正确预测时非常自信，而在面对不确定时则保持谨慎的学习者。信心与谨慎之间的平衡是模型评估的关键部分。
- en: Unfortunately, obtaining internal prediction probabilities can be tricky because
    the method to do so varies across classifiers. In general, for most classifiers,
    the `predict()` function is used to specify the desired type of prediction. To
    obtain a single predicted class, such as spam or ham, you typically set the `type
    = "class"` parameter. To obtain the prediction probability, the `type` parameter
    should be set to one of `"prob"`, `"posterior"`, `"raw"`, or `"probability"` depending
    on the classifier used.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，获取内部预测概率可能有些棘手，因为不同的分类器获取预测概率的方法不同。通常，对于大多数分类器，`predict()`函数用于指定所需的预测类型。要获取单一预测类别（如垃圾邮件或正常邮件），通常需要将`type
    = "class"`参数设置为该值。要获取预测概率，`type`参数应根据所使用的分类器设置为`"prob"`、`"posterior"`、`"raw"`或`"probability"`之一。
- en: Tip
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Nearly all of the classifiers presented in this book will provide prediction
    probabilities. The `type` parameter is included in the syntax box introducing
    each model.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中介绍的几乎所有分类器都会提供预测概率。在每个模型的语法框中都会包含`type`参数。
- en: 'For example, to output the predicted probabilities for the C5.0 classifier
    built in [Chapter 5](ch05.html "Chapter 5. Divide and Conquer – Classification
    Using Decision Trees and Rules"), *Divide and Conquer – Classification Using Decision
    Trees and Rules*, use the `predict()` function with `type = "prob"` as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要输出在[第5章](ch05.html "第5章. 分治法 – 使用决策树和规则进行分类")中构建的C5.0分类器的预测概率，可以使用`predict()`函数，并设置`type
    = "prob"`，如下所示：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To further illustrate the process of evaluating learning algorithms, let''s
    look more closely at the performance of the SMS spam classification model developed
    in [Chapter 4](ch04.html "Chapter 4. Probabilistic Learning – Classification Using
    Naive Bayes"), *Probabilistic Learning – Classification Using Naive Bayes*. To
    output the naive Bayes predicted probabilities, use `predict()` with `type = "raw"`
    as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步说明评估学习算法的过程，让我们更详细地看看在[第4章](ch04.html "第4章. 概率学习 – 使用朴素贝叶斯分类")中开发的SMS垃圾邮件分类模型的表现，*概率学习
    – 使用朴素贝叶斯分类*。要输出朴素贝叶斯的预测概率，可以使用`predict()`函数，并设置`type = "raw"`，如下所示：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In most cases, the `predict()` function returns a probability for each category
    of the outcome. For example, in the case of a two-outcome model like the SMS classifier,
    the predicted probabilities might be a matrix or data frame as shown here:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，`predict()`函数会为每个结果类别返回一个概率。例如，在像SMS分类器这样的二分类模型中，预测的概率可能是一个矩阵或数据框，如下所示：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Each line in this output shows the classifier's predicted probability of `spam`
    and `ham`, which always sum up to 1 because these are the only two outcomes. While
    constructing an evaluation dataset, it is important to ensure that you are using
    the correct probability for the class level of interest. To avoid confusion, in
    the case of a binary outcome, you might even consider dropping the vector for
    one of the two alternatives.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 输出中的每一行显示了分类器对`垃圾邮件`和`正常邮件`的预测概率，这两个概率的总和始终为1，因为这是唯一的两个可能结果。在构建评估数据集时，确保你使用的是与所关注类别级别相符的正确概率非常重要。为了避免混淆，在二分类情况下，甚至可以考虑去掉其中一个类别的预测向量。
- en: For convenience during the evaluation process, it can be helpful to construct
    a data frame containing the predicted class values, actual class values, as well
    as the estimated probabilities of interest.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便评估过程，可以构建一个数据框，包含预测的类别值、实际类别值，以及感兴趣的估计概率。
- en: Tip
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: The steps required to construct the evaluation dataset have been omitted for
    brevity, but are included in this chapter's code on the Packt Publishing website.
    To follow along with the examples here, download the `sms_results.csv` file, and
    load to a data frame using the `sms_results <- read.csv("sms_results.csv")` command.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 构建评估数据集的步骤为了简洁起见已被省略，但它们包含在本章的代码中，可以在 Packt Publishing 网站上找到。要跟随本示例操作，请下载`sms_results.csv`文件，并使用`sms_results
    <- read.csv("sms_results.csv")`命令将其加载到数据框中。
- en: 'The `sms_results` data frame is simple. It contains four vectors of 1,390 values.
    One vector contains values indicating the actual type of SMS message (`spam` or
    `ham`), one vector indicates the naive Bayes model''s predicted type, and the
    third and fourth vectors indicate the probability that the message was `spam`
    or `ham`, respectively:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`sms_results`数据框非常简单，它包含四个向量，包含1,390个值。一个向量包含表示实际短信类型（`spam`或`ham`）的值，一个向量表示朴素贝叶斯模型的预测类型，第三个和第四个向量分别表示消息是`spam`或`ham`的概率：'
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: For these six test cases, the predicted and actual SMS message types agree;
    the model predicted their status correctly. Furthermore, the prediction probabilities
    suggest that model was extremely confident about these predictions, because they
    all fall close to zero or one.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这六个测试案例，预测值与实际的短信类型一致；模型正确地预测了它们的状态。此外，预测的概率表明模型对这些预测极其自信，因为它们的值都接近零或一。
- en: 'What happens when the predicted and actual values are further from zero and
    one? Using the `subset()` function, we can identify a few of these records. The
    following output shows test cases where the model estimated the probability of
    `spam` somewhere between 40 and 60 percent:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当预测值和实际值远离零和一时，会发生什么？使用`subset()`函数，我们可以找出一些这样的记录。以下输出显示了模型预测的`spam`概率介于 40
    到 60 百分比之间的测试案例：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'By the model''s own admission, these were cases in which a correct prediction
    was virtually a coin flip. Yet all three predictions were wrong—an unlucky result.
    Let''s look at a few more cases where the model was wrong:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模型自己的说明，这些是正确预测几乎等同于掷硬币的情况。然而，所有三个预测都是错误的——这是一个不幸的结果。让我们再看看几个模型错误的案例：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: These cases illustrate the important fact that a model can be extremely confident
    and yet it can be extremely wrong. All six of these test cases were `spam` that
    the classifier believed to have no less than a 98 percent chance of being `ham`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这些案例说明了一个重要的事实：模型可以非常有信心，但也可能极其错误。所有这六个测试案例都是`spam`，而分类器认为它们被判定为`ham`的概率不低于
    98%。
- en: In spite of such mistakes, is the model still useful? We can answer this question
    by applying various error metrics to the evaluation data. In fact, many such metrics
    are based on a tool we've already used extensively in the previous chapters.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些错误，这个模型是否仍然有用呢？我们可以通过对评估数据应用各种错误度量来回答这个问题。事实上，许多这样的度量是基于我们在前几章中已广泛使用的工具。
- en: A closer look at confusion matrices
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更深入地看混淆矩阵
- en: A **confusion** **matrix** is a table that categorizes predictions according
    to whether they match the actual value. One of the table's dimensions indicates
    the possible categories of predicted values, while the other dimension indicates
    the same for actual values. Although we have only seen 2 x 2 confusion matrices
    so far, a matrix can be created for models that predict any number of class values.
    The following figure depicts the familiar confusion matrix for a two-class binary
    model as well as the 3 x 3 confusion matrix for a three-class model.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**混淆** **矩阵**是一个表格，用于根据预测值是否与实际值匹配来对预测进行分类。表格的一个维度表示预测值的可能类别，另一个维度表示实际值的类别。尽管我们至今只见过
    2 x 2 的混淆矩阵，但也可以为预测任何类别值的模型创建矩阵。下图展示了熟悉的二分类模型的混淆矩阵，以及三类模型的 3 x 3 混淆矩阵。'
- en: 'When the predicted value is the same as the actual value, it is a correct classification.
    Correct predictions fall on the diagonal in the confusion matrix (denoted by **O**).
    The off-diagonal matrix cells (denoted by **X**) indicate the cases where the
    predicted value differs from the actual value. These are incorrect predictions.
    The performance measures for classification models are based on the counts of
    predictions falling on and off the diagonal in these tables:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当预测值与实际值相同，说明是正确分类。正确的预测会出现在混淆矩阵的对角线上（用**O**表示）。对角线外的矩阵单元格（用**X**表示）表示预测值与实际值不同的情况，这些是错误预测。分类模型的性能度量是基于这些表格中对角线上的预测数和对角线外的预测数：
- en: '![A closer look at confusion matrices](img/B03905_10_02.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![更深入地看混淆矩阵](img/B03905_10_02.jpg)'
- en: The most common performance measures consider the model's ability to discern
    one class versus all others. The class of interest is known as the **positive**
    class, while all others are known as **negative**.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的性能衡量指标考虑的是模型区分一个类别与所有其他类别的能力。关注类别被称为**正类**，而所有其他类别被称为**负类**。
- en: Tip
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: The use of the terms positive and negative is not intended to imply any value
    judgment (that is, good versus bad), nor does it necessarily suggest that the
    outcome is present or absent (such as birth defect versus none). The choice of
    the positive outcome can even be arbitrary, as in cases where a model is predicting
    categories such as sunny versus rainy or dog versus cat.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用“正类”和“负类”这些术语并不意味着任何价值判断（即好与坏），也不一定表示结果是存在或不存在（例如，出生缺陷与否）。正类的选择甚至可以是任意的，比如在模型预测“晴天与雨天”或“狗与猫”等类别的情况下。
- en: 'The relationship between the positive class and negative class predictions
    can be depicted as a 2 x 2 confusion matrix that tabulates whether predictions
    fall into one of the four categories:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正类和负类预测之间的关系可以通过一个 2 x 2 的混淆矩阵来表示，矩阵记录了预测是否属于以下四个类别之一：
- en: '**True Positive (TP)**: Correctly classified as the class of interest'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正（TP）**：正确地分类为关注类别'
- en: '**True Negative (TN)**: Correctly classified as not the class of interest'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真负（TN）**：正确地分类为非关注类别'
- en: '**False Positive (FP)**: Incorrectly classified as the class of interest'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假正（FP）**：错误地分类为关注类别'
- en: '**False Negative (FN)**: Incorrectly classified as not the class of interest'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假负（FN）**：错误地分类为非关注类别'
- en: 'For the spam classifier, the positive class is `spam`, as this is the outcome
    we hope to detect. We can then imagine the confusion matrix as shown in the following
    diagram:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于垃圾邮件分类器，正类是 `spam`，因为这是我们希望检测的结果。我们可以将混淆矩阵想象为以下示意图所示：
- en: '![A closer look at confusion matrices](img/B03905_10_03.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![更深入地看混淆矩阵](img/B03905_10_03.jpg)'
- en: The confusion matrix, presented in this way, is the basis for many of the most
    important measures of model's performance. In the next section, we'll use this
    matrix to have a better understanding of what is meant by accuracy.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式呈现的混淆矩阵是许多重要模型性能指标的基础。在接下来的部分，我们将使用该矩阵更好地理解准确率的含义。
- en: Using confusion matrices to measure performance
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用混淆矩阵衡量性能
- en: 'With the 2 x 2 confusion matrix, we can formalize our definition of prediction
    **accuracy** (sometimes called the **success rate**) as:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 2 x 2 混淆矩阵，我们可以形式化定义预测的**准确率**（有时称为**成功率**）为：
- en: '![Using confusion matrices to measure performance](img/B03905_10_04.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![使用混淆矩阵衡量性能](img/B03905_10_04.jpg)'
- en: In this formula, the terms *TP*, *TN*, *FP*, and *FN* refer to the number of
    times the model's predictions fell into each of these categories. The accuracy
    is therefore a proportion that represents the number of true positives and true
    negatives, divided by the total number of predictions.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在此公式中，*TP*、*TN*、*FP* 和 *FN* 指的是模型预测落入这些类别的次数。因此，准确率是一个比例，表示真正例和真负例的数量，除以总预测数量。
- en: 'The **error rate** or the proportion of the incorrectly classified examples
    is specified as:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**错误率**或错误分类示例的比例定义为：'
- en: '![Using confusion matrices to measure performance](img/B03905_10_05.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![使用混淆矩阵衡量性能](img/B03905_10_05.jpg)'
- en: Notice that the error rate can be calculated as one minus the accuracy. Intuitively,
    this makes sense; a model that is correct 95 percent of the time is incorrect
    5 percent of the time.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，错误率可以通过 1 减去准确率来计算。直观上，这是有道理的；一个 95% 正确的模型，其错误率为 5%。
- en: 'An easy way to tabulate a classifier''s predictions into a confusion matrix
    is to use R''s `table()` function. The command to create a confusion matrix for
    the SMS data is shown as follows. The counts in this table could then be used
    to calculate accuracy and other statistics:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 将分类器的预测结果汇总到混淆矩阵中，一种简便的方法是使用 R 的 `table()` 函数。创建 SMS 数据混淆矩阵的命令如下所示。该表格中的计数值可以用于计算准确率和其他统计数据：
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you like to create a confusion matrix with a more informative output, the
    `CrossTable()` function in the `gmodels` package offers a customizable solution.
    If you recall, we first used this function in [Chapter 2](ch02.html "Chapter 2. Managing
    and Understanding Data"), *Managing and Understanding Data*. If you didn't install
    the package at that time, you will need to do so using the `install.packages("gmodels")`
    command.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想创建一个更具信息性的混淆矩阵输出，`gmodels`包中的`CrossTable()`函数提供了一个可定制的解决方案。如果你还记得，我们在[第2章](ch02.html
    "第2章. 管理与理解数据")，*管理与理解数据*中首次使用了这个函数。如果你当时没有安装这个包，你需要使用`install.packages("gmodels")`命令进行安装。
- en: 'By default, the `CrossTable()` output includes proportions in each cell that
    indicate the cell count as a percentage of table''s row, column, or overall total
    counts. The output also includes row and column totals. As shown in the following
    code, the syntax is similar to the `table()` function:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`CrossTable()`的输出包括每个单元格中的比例，表示该单元格的计数占表格的行、列或总体总计的百分比。输出结果还包括行和列的总计。如下面的代码所示，语法与`table()`函数类似：
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The result is a confusion matrix with a wealth of additional detail:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个包含大量附加细节的混淆矩阵：
- en: '![Using confusion matrices to measure performance](img/B03905_10_06.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![使用混淆矩阵来衡量性能](img/B03905_10_06.jpg)'
- en: We've used `CrossTable()` in several of the previous chapters, so by now you
    should be familiar with the output. If you ever forget how to interpret the output,
    simply refer to the key (labeled `Cell Contents`), which provides the definition
    of each number in the table cells.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前几章中已经使用了`CrossTable()`，所以现在你应该对输出结果比较熟悉。如果你忘记了如何解读输出结果，只需参考关键部分（标记为`Cell
    Contents`），它提供了表格单元格中每个数字的定义。
- en: 'We can use the confusion matrix to obtain the accuracy and error rate. Since
    the accuracy is *(TP + TN) / (TP + TN + FP + FN)*, we can calculate it using following
    command:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用混淆矩阵来获得准确率和误差率。由于准确率是*(TP + TN) / (TP + TN + FP + FN)*，我们可以使用以下命令来计算它：
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can also calculate the error rate *(FP + FN) / (TP + TN + FP + FN)* as:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以计算误差率*(FP + FN) / (TP + TN + FP + FN)*，方法如下：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This is the same as one minus accuracy:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这与准确度的补集相同：
- en: '[PRE10]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Although these calculations may seem simple, it is important to practice thinking
    about how the components of the confusion matrix relate to one another. In the
    next section, you will see how these same pieces can be combined in different
    ways to create a variety of additional performance measures.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些计算看起来很简单，但重要的是要练习思考混淆矩阵的各个组成部分是如何相互关联的。在接下来的章节中，你将看到如何将这些组件以不同方式组合，从而创建各种附加的性能度量。
- en: Beyond accuracy – other measures of performance
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 除了准确度——其他的性能度量
- en: Countless performance measures have been developed and used for specific purposes
    in disciplines as diverse as medicine, information retrieval, marketing, and signal
    detection theory, among others. Covering all of them could fill hundreds of pages
    and makes a comprehensive description infeasible here. Instead, we'll consider
    only some of the most useful and commonly cited measures in the machine learning
    literature.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 无数的性能度量已经为特定目的在诸如医学、信息检索、市场营销和信号检测理论等领域开发并使用。涵盖所有这些度量将填满数百页，因此在这里进行全面描述是不可行的。相反，我们将只考虑机器学习文献中最常用和最常引用的一些度量。
- en: The Classification and Regression Training package `caret` by Max Kuhn includes
    functions to compute many such performance measures. This package provides a large
    number of tools to prepare, train, evaluate, and visualize machine learning models
    and data. In addition to its use here, we will also employ `caret` extensively
    in [Chapter 11](ch11.html "Chapter 11. Improving Model Performance"), *Improving
    Model Performance*. Before proceeding, you will need to install the package using
    the `install.packages("caret")` command.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Max Kuhn的分类与回归训练包`caret`包括计算许多此类性能度量的函数。该包提供了大量的工具，用于准备、训练、评估和可视化机器学习模型和数据。除了在这里的使用外，我们还将在[第11章](ch11.html
    "第11章. 提升模型性能")，*提升模型性能*中广泛使用`caret`。在继续之前，你需要使用`install.packages("caret")`命令安装该包。
- en: Tip
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'For more information on `caret`, please refer to: Kuhn M. Building predictive
    models in R using the caret package. *Journal of Statistical* Software. 2008;
    28.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`caret`的更多信息，请参考：Kuhn M. 使用caret包在R中构建预测模型。*统计学期刊*软件。2008年；28。
- en: 'The `caret` package adds yet another function to create a confusion matrix.
    As shown in the following command, the syntax is similar to `table()`, but with
    a minor difference. Because `caret` provides measures of model performance that
    consider the ability to classify the positive class, a `positive` parameter should
    be specified. In this case, since the SMS classifier is intended to detect `spam`,
    we will set `positive = "spam"` as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`caret` 包提供了另一个函数来创建混淆矩阵。如下命令所示，其语法与 `table()` 类似，但有一个小的差异。因为 `caret` 提供了考虑到分类正类能力的模型性能度量，所以应指定
    `positive` 参数。在本例中，由于 SMS 分类器旨在检测 `spam`，我们将设置 `positive = "spam"`，如下所示：'
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This results in the following output:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下输出：
- en: '![Beyond accuracy – other measures of performance](img/B03905_10_07.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![超越准确性 – 其他性能度量](img/B03905_10_07.jpg)'
- en: At the top of the output is a confusion matrix much like the one produced by
    the `table()` function, but transposed. The output also includes a set of performance
    measures. Some of these, like accuracy, are familiar, while many others are new.
    Let's take a look at few of the most important metrics.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 输出顶部是一个混淆矩阵，类似于 `table()` 函数生成的矩阵，但它被转置了。输出还包括一组性能度量。其中一些，如准确性，是我们熟悉的，而许多其他度量则是新的。让我们看看几个最重要的指标。
- en: The kappa statistic
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kappa 统计量
- en: The **kappa statistic** (labeled `Kappa` in the previous output) adjusts accuracy
    by accounting for the possibility of a correct prediction by chance alone. This
    is especially important for datasets with a severe class imbalance, because a
    classifier can obtain high accuracy simply by always guessing the most frequent
    class. The kappa statistic will only reward the classifier if it is correct more
    often than this simplistic strategy.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kappa 统计量**（在之前的输出中标记为`Kappa`）通过考虑仅凭随机猜测就能做出正确预测的可能性来调整准确性。这对于具有严重类别不平衡的数据集尤为重要，因为分类器只需始终猜测最频繁的类别就能获得高准确率。Kappa
    统计量只有在分类器的正确率超过这种简单策略时，才会给予奖励。'
- en: 'Kappa values range from 0 to a maximum of 1, which indicates perfect agreement
    between the model''s predictions and the true values. Values less than one indicate
    imperfect agreement. Depending on how a model is to be used, the interpretation
    of the kappa statistic might vary. One common interpretation is shown as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Kappa 值的范围从 0 到最大值 1，表示模型预测与真实值之间的完美协议。值小于 1 表示协议不完全。根据模型的使用方式，Kappa 统计量的解释可能有所不同。以下是常见的解释：
- en: Poor agreement = less than 0.20
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 差的协议 = 小于 0.20
- en: Fair agreement = 0.20 to 0.40
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公平协议 = 0.20 到 0.40
- en: Moderate agreement = 0.40 to 0.60
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中等协议 = 0.40 到 0.60
- en: Good agreement = 0.60 to 0.80
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 良好的协议 = 0.60 到 0.80
- en: Very good agreement = 0.80 to 1.00
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常好的协议 = 0.80 到 1.00
- en: It's important to note that these categories are subjective. While a "good agreement"
    may be more than adequate to predict someone's favorite ice cream flavor, "very
    good agreement" may not suffice if your goal is to identify birth defects.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，这些类别是主观的。虽然“良好的协议”可能足以预测某人最喜欢的冰淇淋口味，但如果目标是识别出生缺陷，单凭“非常好的协议”可能不足够。
- en: Tip
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'For more information on the previous scale, refer to: Landis JR, Koch GG. The
    measurement of observer agreement for categorical data. *Biometrics*. 1997; 33:159-174.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 有关前述量表的更多信息，请参阅：Landis JR, Koch GG. The measurement of observer agreement for
    categorical data. *Biometrics*. 1997; 33:159-174.
- en: 'The following is the formula to calculate the kappa statistic. In this formula,
    *Pr(a)* refers to the proportion of the actual agreement and *Pr(e)* refers to
    the expected agreement between the classifier and the true values, under the assumption
    that they were chosen at random:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是计算 Kappa 统计量的公式。在这个公式中，*Pr(a)* 指的是实际协议的比例，而 *Pr(e)* 指的是在假设随机选择的情况下，分类器与真实值之间的期望协议：
- en: '![The kappa statistic](img/B03905_10_08.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![Kappa 统计量](img/B03905_10_08.jpg)'
- en: Tip
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'There is more than one way to define the kappa statistic. The most common method
    described here uses **Cohen''s kappa coefficient**, as described in the paper:
    Cohen J. A coefficient of agreement for nominal scales. *Education and Psychological
    Measurement*. 1960; 20:37-46.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 Kappa 统计量的方法不止一种。这里描述的最常见方法使用 **Cohen 的 Kappa 系数**，该方法在论文中有所阐述：Cohen J. A
    coefficient of agreement for nominal scales. *Education and Psychological Measurement*.
    1960; 20:37-46.
- en: 'These proportions are easy to obtain from a confusion matrix once you know
    where to look. Let''s consider the confusion matrix for the SMS classification
    model created with the `CrossTable()` function, which is repeated here for convenience:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这些比例可以通过混淆矩阵轻松获得，一旦你知道该从哪里查找。让我们考虑使用`CrossTable()`函数创建的SMS分类模型的混淆矩阵，为了方便起见，这里重复显示：
- en: '![The kappa statistic](img/B03905_10_09.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![kappa统计量](img/B03905_10_09.jpg)'
- en: 'Remember that the bottom value in each cell indicates the proportion of all
    instances falling into that cell. Therefore, to calculate the observed agreement
    *Pr(a)*, we simply add the proportion of all instances where the predicted type
    and actual SMS type agree. Thus, we can calculate *Pr(a)* as:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，每个单元格底部的值表示所有实例中落入该单元格的比例。因此，计算观察到的一致性*Pr(a)*时，我们只需将预测类型与实际短信类型一致的所有实例的比例相加。这样，我们可以计算*Pr(a)*如下：
- en: '[PRE12]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: For this classifier, the observed and actual values agree 97.4 percent of the
    time—you will note that this is the same as the accuracy. The kappa statistic
    adjusts the accuracy relative to the expected agreement *Pr(e)*, which is the
    probability that the chance alone would lead the predicted and actual values to
    match, under the assumption that both are selected randomly according to the observed
    proportions.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个分类器，观察值和实际值有97.4%的时间是一致的——你会注意到这与准确度是相同的。kappa统计量根据预期一致性*Pr(e)*调整了准确度，*Pr(e)*是指在假设两者都是根据观察到的比例随机选择的前提下，仅凭运气，预测值和实际值匹配的概率。
- en: 'To find these observed proportions, we can use the probability rules we learned
    in [Chapter 4](ch04.html "Chapter 4. Probabilistic Learning – Classification Using
    Naive Bayes"), *Probabilistic Learning – Classification Using Naive Bayes*. Assuming
    two events are independent (meaning that one does not affect the other), probability
    rules note that the probability of both occurring is equal to the product of the
    probabilities of each one occurring. For instance, we know that the probability
    of both choosing ham is:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到这些观察到的比例，我们可以使用我们在[第4章](ch04.html "Chapter 4. Probabilistic Learning – Classification
    Using Naive Bayes")中学到的概率规则，*概率学习 – 使用朴素贝叶斯分类*。假设两个事件是独立的（意味着一个事件不会影响另一个事件），概率规则指出，两者同时发生的概率等于每个事件发生概率的乘积。例如，我们知道两者都选择正常邮件的概率是：
- en: '*Pr(actual type is ham) * Pr(predicted type is ham)*'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*Pr(实际类型是正常邮件) * Pr(预测类型是正常邮件)*'
- en: 'The probability of both choosing spam is:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 两者都选择垃圾邮件的概率是：
- en: '*Pr(actual type is spam) * Pr(predicted type is spam)*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*Pr(实际类型是垃圾邮件) * Pr(预测类型是垃圾邮件)*'
- en: The probability that the predicted or actual type is spam or ham can be obtained
    from the row or column totals. For instance, *Pr(actual type is ham) = 0.868*
    and *Pr(predicted type is ham) = 0.888*.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 预测类型或实际类型是垃圾邮件（spam）或正常邮件（ham）的概率可以从行或列的总计中获得。例如，*Pr(实际类型是正常邮件) = 0.868* 和 *Pr(预测类型是正常邮件)
    = 0.888*。
- en: '*Pr(e)* is calculated as the sum of the probabilities that by chance the predicted
    and actual values agree that the message is either spam or ham. Recall that for
    mutually exclusive events (events that cannot happen simultaneously), the probability
    of either occurring is equal to the sum of their probabilities. Therefore, to
    obtain the final *Pr(e)*, we simply add both products, as shown in the following
    commands:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*Pr(e)*是通过计算预测值和实际值因运气而一致的概率之和来计算的，无论消息是垃圾邮件还是正常邮件。回想一下，对于互斥事件（不能同时发生的事件），发生任意一个的概率等于它们各自概率的总和。因此，为了获得最终的*Pr(e)*，我们只需将两个乘积相加，如以下命令所示：'
- en: '[PRE13]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Since *Pr(e)* is 0.786, by chance alone, we would expect the observed and actual
    values to agree about 78.6 percent of the time.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 由于*Pr(e)*是0.786，单纯依靠运气，我们预期观察值与实际值大约有78.6%的时间是一致的。
- en: 'This means that we now have all the information needed to complete the kappa
    formula. Plugging the *Pr(a)* and *Pr(e)* values into the kappa formula, we find:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们现在拥有了完成kappa公式所需的所有信息。将*Pr(a)*和*Pr(e)*值代入kappa公式中，我们得到：
- en: '[PRE14]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The kappa is about 0.88, which agrees with the previous `confusionMatrix()`
    output from `caret` (the small difference is due to rounding). Using the suggested
    interpretation, we note that there is very good agreement between the classifier's
    predictions and the actual values.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: kappa大约是0.88，这与`caret`的`confusionMatrix()`输出一致（小差异是由于四舍五入）。根据建议的解释，我们注意到分类器的预测与实际值之间有很好的一致性。
- en: 'There are a couple of R functions to calculate kappa automatically. The `Kappa()`
    function (be sure to note the capital ''K'') in the Visualizing Categorical Data
    (`vcd)` package uses a confusion matrix of predicted and actual values. After
    installing the package by typing `install.packages("vcd")`, the following commands
    can be used to obtain kappa:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个 R 函数可以自动计算 kappa。Visualizing Categorical Data (`vcd`) 包中的 `Kappa()` 函数（请注意大写的
    'K'）使用预测值和实际值的混淆矩阵。在安装该包后（使用命令 `install.packages("vcd")`），可以使用以下命令获取 kappa 值：
- en: '[PRE15]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We're interested in the unweighted kappa. The value 0.88 matches what we expected.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关心的是不带权的 kappa。值 0.88 与我们预期的相符。
- en: Tip
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: The weighted kappa is used when there are varying degrees of agreement. For
    example, using a scale of cold, cool, warm, and hot, a value of warm agrees more
    with hot than it does with the value of cold. In the case of a two-outcome event,
    such as spam and ham, the weighted and unweighted kappa statistics will be identical.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 加权 kappa 用于存在不同程度一致性的情况。例如，使用“冷、凉、温暖、热”这样的尺度时，温暖与热的值更为接近，而与冷的值差异较大。在二分类事件中，例如垃圾邮件和正常邮件，带权和不带权的
    kappa 统计量将是相同的。
- en: 'The `kappa2()` function in the Inter-Rater Reliability (`irr`) package can
    be used to calculate kappa from the vectors of predicted and actual values stored
    in a data frame. After installing the package using the `install.packages("irr")`
    command, the following commands can be used to obtain kappa:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Inter-Rater Reliability (`irr`) 包中的 `kappa2()` 函数可以用来计算存储在数据框中的预测值和实际值向量的 kappa。安装该包（使用
    `install.packages("irr")` 命令）后，可以使用以下命令获取 kappa 值：
- en: '[PRE16]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `Kappa()` and `kappa2()` functions report the same kappa statistic, so use
    whichever option you are more comfortable with.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`Kappa()` 和 `kappa2()` 函数报告相同的 kappa 统计量，因此你可以选择更熟悉的函数。'
- en: Tip
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Be careful not to use the built-in `kappa()` function. It is completely unrelated
    to the kappa statistic reported previously!
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 小心不要使用内置的 `kappa()` 函数。它与之前报告的 kappa 统计量完全无关！
- en: Sensitivity and specificity
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 灵敏度和特异性
- en: 'Finding a useful classifier often involves a balance between predictions that
    are overly conservative and overly aggressive. For example, an e-mail filter could
    guarantee to eliminate every spam message by aggressively eliminating nearly every
    ham message at the same time. On the other hand, guaranteeing that no ham message
    is inadvertently filtered might require us to allow an unacceptable amount of
    spam to pass through the filter. A pair of performance measures captures this
    tradeoff: sensitivity and specificity.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找一个有用的分类器通常涉及在过于保守和过于激进的预测之间做出平衡。例如，一个电子邮件过滤器可以通过激进地过滤几乎所有的正常邮件来确保删除每一封垃圾邮件。另一方面，为了确保不误过滤正常邮件，可能需要允许不可接受的垃圾邮件通过过滤器。一对性能度量捕捉了这种权衡：灵敏度和特异性。
- en: 'The **sensitivity** of a model (also called the **true positive rate**) measures
    the proportion of positive examples that were correctly classified. Therefore,
    as shown in the following formula, it is calculated as the number of true positives
    divided by the total number of positives, both correctly classified (the true
    positives) as well as incorrectly classified (the false negatives):'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的**灵敏度**（也叫做**真正率**）衡量的是正例中被正确分类的比例。因此，如下公式所示，它是通过将真正例数除以所有正例的总数（包括正确分类的真正例和错误分类的假负例）来计算的：
- en: '![Sensitivity and specificity](img/B03905_10_10.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![灵敏度和特异性](img/B03905_10_10.jpg)'
- en: 'The **specificity** of a model (also called the **true negative rate**) measures
    the proportion of negative examples that were correctly classified. As with sensitivity,
    this is computed as the number of true negatives, divided by the total number
    of negatives—the true negatives plus the false positives:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的**特异性**（也叫做**真负率**）衡量的是负例中被正确分类的比例。与灵敏度类似，这个值是通过将真负例数除以所有负例的总数（包括真负例和假正例）来计算的：
- en: '![Sensitivity and specificity](img/B03905_10_11.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![灵敏度和特异性](img/B03905_10_11.jpg)'
- en: 'Given the confusion matrix for the SMS classifier, we can easily calculate
    these measures by hand. Assuming that spam is the positive class, we can confirm
    that the numbers in the `confusionMatrix()` output are correct. For example, the
    calculation for sensitivity is:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 给定短信分类器的混淆矩阵，我们可以轻松手动计算这些度量。假设垃圾邮件为正类，我们可以确认 `confusionMatrix()` 输出中的数字是正确的。例如，灵敏度的计算公式如下：
- en: '[PRE17]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Similarly, for specificity we can calculate:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，对于特异性，我们可以计算：
- en: '[PRE18]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `caret` package provides functions to calculate sensitivity and specificity
    directly from the vectors of predicted and actual values. Be careful that you
    specify the `positive` or `negative` parameter appropriately, as shown in the
    following lines:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`caret` 包提供了从预测值和实际值的向量直接计算灵敏度和特异性（sensitivity and specificity）的函数。请小心地指定 `positive`
    或 `negative` 参数，如下所示：'
- en: '[PRE19]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Sensitivity and specificity range from 0 to 1, with values close to 1 being
    more desirable. Of course, it is important to find an appropriate balance between
    the two—a task that is often quite context-specific.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 灵敏度和特异性范围从0到1，接近1的值更为理想。当然，找到两者之间的适当平衡是很重要的——这一任务通常是特定于上下文的。
- en: For example, in this case, the sensitivity of 0.831 implies that 83.1 percent
    of the spam messages were correctly classified. Similarly, the specificity of
    0.997 implies that 99.7 percent of the nonspam messages were correctly classified
    or, alternatively, 0.3 percent of the valid messages were rejected as spam. The
    idea of rejecting 0.3 percent of valid SMS messages may be unacceptable, or it
    may be a reasonable trade-off given the reduction in spam.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在这种情况下，0.831的灵敏度意味着83.1%的垃圾短信被正确分类。类似地，0.997的特异性意味着99.7%的非垃圾短信被正确分类；或者，0.3%的有效短信被误判为垃圾短信。拒绝0.3%的有效短信可能是不可接受的，或者考虑到垃圾短信减少，这可能是一个合理的权衡。
- en: Sensitivity and specificity provide tools for thinking about such trade-offs.
    Typically, changes are made to the model and different models are tested until
    you find one that meets a desired sensitivity and specificity threshold. Visualizations,
    such as those discussed later in this chapter, can also assist with understanding
    the trade-off between sensitivity and specificity.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 灵敏度和特异性为思考这种权衡提供了工具。通常，通过对模型进行修改并测试不同的模型，直到找到一个满足期望的灵敏度和特异性阈值的模型。可视化工具（如本章稍后讨论的内容）也有助于理解灵敏度和特异性之间的权衡。
- en: Precision and recall
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 精准度与召回率
- en: 'Closely related to sensitivity and specificity are two other performance measures
    related to compromises made in classification: precision and recall. Used primarily
    in the context of information retrieval, these statistics are intended to provide
    an indication of how interesting and relevant a model''s results are, or whether
    the predictions are diluted by meaningless noise.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 与灵敏度和特异性密切相关的，还有两个与分类妥协相关的性能度量：精准度和召回率。它们主要用于信息检索领域，旨在提供模型结果的相关性和有趣性指示，或者判断预测是否被无意义的噪声稀释。
- en: The **precision** (also known as the **positive predictive value**) is defined
    as the proportion of positive examples that are truly positive; in other words,
    when a model predicts the positive class, how often is it correct? A precise model
    will only predict the positive class in cases that are very likely to be positive.
    It will be very trustworthy.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**精准度**（也称为**正预测值**）定义为真正的正例所占比例；换句话说，当模型预测为正类时，它有多大的准确性？一个精准的模型只会在非常可能为正的情况下预测为正类，因此它非常值得信赖。'
- en: Consider what would happen if the model was very imprecise. Over time, the results
    would be less likely to be trusted. In the context of information retrieval, this
    would be similar to a search engine such as Google returning unrelated results.
    Eventually, users would switch to a competitor like Bing. In the case of the SMS
    spam filter, high precision means that the model is able to carefully target only
    the spam while ignoring the ham.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果模型非常不精准，会发生什么。随着时间的推移，结果的可信度会降低。在信息检索的背景下，这类似于一个像Google这样的搜索引擎返回无关的结果。最终，用户会转向像Bing这样的竞争对手。在短信垃圾过滤器的案例中，高精准度意味着模型能够精确地识别垃圾短信，同时忽略非垃圾短信。
- en: '![Precision and recall](img/B03905_10_12.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![精准度与召回率](img/B03905_10_12.jpg)'
- en: On the other hand, **recall** is a measure of how complete the results are.
    As shown in the following formula, this is defined as the number of true positives
    over the total number of positives. You may have already recognized this as the
    same as sensitivity. However, in this case, the interpretation differs slightly.
    A model with a high recall captures a large portion of the positive examples,
    meaning that it has wide breadth. For example, a search engine with a high recall
    returns a large number of documents pertinent to the search query. Similarly,
    the SMS spam filter has a high recall if the majority of spam messages are correctly
    identified.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**召回率**是衡量结果完整性的一个指标。如以下公式所示，召回率定义为真阳性数占所有阳性数的比例。你可能已经认识到这与灵敏度相同。然而，在这种情况下，解释略有不同。一个具有高召回率的模型捕捉到了大量的正例，这意味着它具有广泛的覆盖范围。例如，一个具有高召回率的搜索引擎会返回大量与搜索查询相关的文档。同样，短信垃圾邮件过滤器具有高召回率时，意味着大多数垃圾短信都能被正确识别。
- en: '![Precision and recall](img/B03905_10_13.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![精确度与召回率](img/B03905_10_13.jpg)'
- en: 'We can calculate precision and recall from the confusion matrix. Again, assuming
    that `spam` is the positive class, the precision is:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从混淆矩阵中计算精确度和召回率。再次假设`spam`是正类，精确度为：
- en: '[PRE20]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The recall is:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率为：
- en: '[PRE21]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The `caret` package can be used to compute either of these measures from the
    vectors of predicted and actual classes. Precision uses the `posPredValue()` function:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`caret`包可以用来从预测和实际类别的向量中计算这些度量之一。精确度使用`posPredValue()`函数：'
- en: '[PRE22]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'While recall uses the `sensitivity()` function that we used earlier:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率使用我们之前使用的`sensitivity()`函数：
- en: '[PRE23]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Similar to the inherent trade-off between sensitivity and specificity, for most
    of the real-world problems, it is difficult to build a model with both high precision
    and high recall. It is easy to be precise if you target only the low-hanging fruit—the
    easy to classify examples. Similarly, it is easy for a model to have high recall
    by casting a very wide net, meaning that the model is overly aggressive in identifying
    the positive cases. In contrast, having both high precision and recall at the
    same time is very challenging. It is therefore important to test a variety of
    models in order to find the combination of precision and recall that will meet
    the needs of your project.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于灵敏度和特异性之间的固有权衡，对于大多数实际问题而言，很难构建一个同时具有高精确度和高召回率的模型。如果你只针对简单的、容易分类的样本，保持精确度就变得容易。同样，如果一个模型通过使用一个非常宽泛的筛选标准来捕捉尽可能多的正例，那么它的召回率会很高。在这种情况下，模型会过于激进地识别正样本。相比之下，同时具备高精度和高召回率非常具有挑战性。因此，测试多种模型以找到精度和召回率的最佳组合，以满足项目需求是至关重要的。
- en: The F-measure
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: F-measure
- en: 'A measure of model performance that combines precision and recall into a single
    number is known as the **F-measure** (also sometimes called the **F[1] score**
    or **F-score**). The F-measure combines precision and recall using the **harmonic
    mean**, a type of average that is used for rates of change. The harmonic mean
    is used rather than the common arithmetic mean since both precision and recall
    are expressed as proportions between zero and one, which can be interpreted as
    rates. The following is the formula for the F-measure:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 一种结合了精确度和召回率的模型性能度量方法称为**F-measure**（有时也叫**F[1]分数**或**F-score**）。F-measure通过**调和平均数**将精确度和召回率结合起来，调和平均数是一种用于变化率的平均值类型。由于精确度和召回率都表示为介于零和一之间的比例，可以解释为比率，因此使用调和平均数而非常见的算术平均数。以下是F-measure的公式：
- en: '![The F-measure](img/B03905_10_14.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![F-measure图示](img/B03905_10_14.jpg)'
- en: 'To calculate the F-measure, use the precision and recall values computed previously:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算F-measure，请使用之前计算的精确度和召回率值：
- en: '[PRE24]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This comes out exactly the same as using the counts from the confusion matrix:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这个计算结果与使用混淆矩阵中的计数值完全相同：
- en: '[PRE25]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Since the F-measure describes the model performance in a single number, it provides
    a convenient way to compare several models side by side. However, this assumes
    that equal weight should be assigned to precision and recall, an assumption that
    is not always valid. It is possible to calculate F-scores using different weights
    for precision and recall, but choosing the weights could be tricky at the best
    and arbitrary at worst. A better practice is to use measures such as the F-score
    in combination with methods that consider a model's strengths and weaknesses more
    globally, such as those described in the next section.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 由于F度量在一个数字中描述了模型的性能，它提供了一种方便的方式来并排比较多个模型。然而，这假设了精确度和召回率应该赋予相同的权重，这一假设并不总是有效。可以使用不同的权重来计算F分数，但选择权重可能在最好的情况下比较棘手，最坏的情况下则显得任意。更好的做法是将像F分数这样的度量与更全面考虑模型优缺点的方法结合使用，如下一节中描述的方法。
- en: Visualizing performance trade-offs
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化性能权衡
- en: Visualizations are helpful to understand the performance of machine learning
    algorithms in greater detail. Where statistics such as sensitivity and specificity
    or precision and recall attempt to boil model performance down to a single number,
    visualizations depict how a learner performs across a wide range of conditions.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化有助于更详细地理解机器学习算法的性能。当统计数据如敏感性和特异性，或精确度和召回率试图将模型性能简化为一个数字时，可视化则描绘了学习者在各种条件下的表现。
- en: Because learning algorithms have different biases, it is possible that two models
    with similar accuracy could have drastic differences in how they achieve their
    accuracy. Some models may struggle with certain predictions that others make with
    ease, while breezing through the cases that others cannot get right. Visualizations
    provide a method to understand these trade-offs, by comparing learners side by
    side in a single chart.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 由于学习算法有不同的偏差，两个模型可能在准确率相似的情况下，在实现准确率的方式上存在巨大的差异。有些模型可能在一些预测上遇到困难，而其他模型则轻松完成这些预测，同时对于其他模型无法正确预测的情况表现得游刃有余。可视化提供了一种理解这些权衡的方法，通过将多个学习者并排比较在一个图表中。
- en: The `ROCR` package provides an easy-to-use suite of functions for visualizing
    for visualizing the performance of classification models. It includes functions
    for computing large set of the most common performance measures and visualizations.
    The `ROCR` website at [http://rocr.bioinf.mpi-sb.mpg.de/](http://rocr.bioinf.mpi-sb.mpg.de/)
    includes a list of the full set of features as well as several examples on visualization
    capabilities. Before continuing, install the package using the `install.packages("ROCR")`
    command.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`ROCR`包提供了一套易于使用的函数，用于可视化分类模型的性能。它包括用于计算常见性能度量和可视化的大量函数。`ROCR`官网 [http://rocr.bioinf.mpi-sb.mpg.de/](http://rocr.bioinf.mpi-sb.mpg.de/)
    列出了完整的功能集以及多个可视化功能示例。继续之前，请使用`install.packages("ROCR")`命令安装该包。'
- en: Tip
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'For more information on the development of ROCR, see : Sing T, Sander O, Beerenwinkel
    N, Lengauer T. ROCR: visualizing classifier performance in R. *Bioinformatics*.
    2005; 21:3940-3941.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 有关ROCR开发的更多信息，请参见：Sing T, Sander O, Beerenwinkel N, Lengauer T. ROCR：在R中可视化分类器性能。*生物信息学*。2005；21：3940-3941。
- en: To create visualizations with `ROCR`, two vectors of data are needed. The first
    must contain the predicted class values, and the second must contain the estimated
    probability of the positive class. These are used to create a prediction object
    that can be examined with the plotting functions of `ROCR`.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`ROCR`创建可视化，需要两个数据向量。第一个必须包含预测的类别值，第二个必须包含正类的估计概率。这些数据用于创建预测对象，然后可以通过`ROCR`的绘图功能进行检查。
- en: 'The prediction object for the SMS classifier requires the classifier''s estimated
    spam probabilities and the actual class labels. These are combined using the `prediction()`
    function in the following lines:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: SMS分类器的预测对象需要分类器的垃圾邮件概率估计值和实际类别标签。这些数据通过`prediction()`函数结合在以下几行中：
- en: '[PRE26]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Next, the `performance()` function will allow us to compute measures of performance
    from the `prediction` object we just created, which can then be visualized using
    the R `plot()` function. Given these three steps, a large variety of useful visualizations
    can be created.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，`performance()`函数将允许我们从刚刚创建的`prediction`对象中计算性能度量，然后可以使用R的`plot()`函数进行可视化。通过这三步，可以创建多种有用的可视化图。
- en: ROC curves
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ROC曲线
- en: The **Receiver Operating Characteristic (ROC) curve** is commonly used to examine
    the trade-off between the detection of true positives, while avoiding the false
    positives. As you might suspect from the name, ROC curves were developed by engineers
    in the field of communications. Around the time of World War II, radar and radio
    operators used ROC curves to measure a receiver's ability to discriminate between
    true signals and false alarms. The same technique is useful today to visualize
    the efficacy of machine learning models.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**接收者操作特征（ROC）曲线**通常用于检验在避免假阳性的同时，检测真实阳性的权衡。正如你可能从名称中猜到的，ROC曲线最初由通信领域的工程师开发。在二战时期，雷达和无线电操作员使用ROC曲线来衡量接收器区分真实信号和假警报的能力。今天，这一技术在可视化机器学习模型的有效性时依然非常有用。'
- en: 'The characteristics of a typical ROC diagram are depicted in the following
    plot. Curves are defined on a plot with the proportion of true positives on the
    vertical axis and the proportion of false positives on the horizontal axis. Because
    these values are equivalent to sensitivity and (1 – specificity), respectively,
    the diagram is also known as a sensitivity/specificity plot:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 典型ROC图的特征如下面的图所示。曲线定义在一个图上，纵轴表示真实阳性比例，横轴表示假阳性比例。由于这些值分别等同于灵敏度和（1 – 特异性），因此该图也被称为灵敏度/特异性图：
- en: '![ROC curves](img/B03905_10_15.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![ROC曲线](img/B03905_10_15.jpg)'
- en: The points comprising ROC curves indicate the true positive rate at varying
    false positive thresholds. To create the curves, a classifier's predictions are
    sorted by the model's estimated probability of the positive class, with the largest
    values first. Beginning at the origin, each prediction's impact on the true positive
    rate and false positive rate will result in a curve tracing vertically (for a
    correct prediction) or horizontally (for an incorrect prediction).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 组成ROC曲线的点表示在不同假阳性阈值下的真实阳性率。为了创建这些曲线，分类器的预测结果按模型对正类的估计概率排序，最大的值排在前面。从原点开始，每个预测对真实阳性率和假阳性率的影响将导致曲线向上（对于正确预测）或向右（对于错误预测）延伸。
- en: To illustrate this concept, three hypothetical classifiers are contrasted in
    the previous plot. First, the diagonal line from the bottom-left to the top-right
    corner of the diagram represents a **classifier with no predictive value**. This
    type of classifier detects true positives and false positives at exactly the same
    rate, implying that the classifier cannot discriminate between the two. This is
    the baseline by which other classifiers may be judged. ROC curves falling close
    to this line indicate models that are not very useful. The **perfect classifier**
    has a curve that passes through the point at a 100 percent true positive rate
    and 0 percent false positive rate. It is able to correctly identify all of the
    positives before it incorrectly classifies any negative result. Most real-world
    classifiers are similar to the test classifier and they fall somewhere in the
    zone between perfect and useless.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一概念，前面的图中对比了三种假设的分类器。首先，从图的左下角到右上角的对角线代表一个**没有预测价值的分类器**。这种分类器以相同的速度检测到真实阳性和假阳性，意味着分类器无法区分二者。这是其他分类器评判的基准线。接近此线的ROC曲线表示模型没有太大用处。**完美分类器**的曲线通过一个点，表示100%的真实阳性率和0%的假阳性率。它能够在错误分类任何负结果之前正确识别所有的正结果。大多数现实世界的分类器与测试分类器类似，它们的表现位于完美分类器和无用分类器之间。
- en: 'The closer the curve is to the perfect classifier, the better it is at identifying
    positive values. This can be measured using a statistic known as the **area under
    the ROC curve** (abbreviated **AUC**). The AUC treats the ROC diagram as a two-dimensional
    square and measures the total area under the ROC curve. AUC ranges from 0.5 (for
    a classifier with no predictive value) to 1.0 (for a perfect classifier). A convention
    to interpret AUC scores uses a system similar to academic letter grades:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 曲线越接近完美分类器，越能更好地识别正值。这可以通过一个统计量来衡量，称为**ROC曲线下面积**（简称**AUC**）。AUC将ROC图作为一个二维方形，并测量ROC曲线下的总面积。AUC的值范围从0.5（表示分类器没有预测价值）到1.0（表示完美分类器）。解释AUC分数的惯例使用一个类似于学术字母评分的系统：
- en: '**A**: Outstanding = 0.9 to 1.0'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A**：优秀 = 0.9 到 1.0'
- en: '**B**: Excellent/good = 0.8 to 0.9'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**B**：优秀/良好 = 0.8 到 0.9'
- en: '**C**: Acceptable/fair = 0.7 to 0.8'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C**：可接受/一般 = 0.7 到 0.8'
- en: '**D**: Poor = 0.6 to 0.7'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**D**：差 = 0.6 到 0.7'
- en: '**E**: No discrimination = 0.5 to 0.6'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**E**：无区分能力 = 0.5 到 0.6'
- en: As with most scales similar to this, the levels may work better for some tasks
    than others; the categorization is somewhat subjective.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数类似的量表一样，某些任务可能比其他任务更适合使用这些等级；这种分类是有一定主观性的。
- en: Tip
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: It's also worth noting that two ROC curves may be shaped very differently, yet
    have an identical AUC. For this reason, an AUC alone can be misleading. The best
    practice is to use AUC in combination with qualitative examination of the ROC
    curve.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得注意的是，两个ROC曲线的形状可能截然不同，但AUC却相同。正因为如此，单独使用AUC可能会产生误导。最佳做法是结合AUC和ROC曲线的定性检查一起使用。
- en: 'Creating ROC curves with the `ROCR` package involves building a `performance`
    object from the `prediction` object we computed earlier. Since ROC curves plot
    true positive rates versus false positive rates, we simply call the `performance()`
    function while specifying the `tpr` and `fpr` measures, as shown in the following
    code:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`ROCR`包创建ROC曲线涉及从我们之前计算的`prediction`对象中构建一个`performance`对象。由于ROC曲线绘制的是真实正例率与假正例率之间的关系，我们只需调用`performance()`函数并指定`tpr`和`fpr`这两个度量值，如下代码所示：
- en: '[PRE27]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Using the `perf` object, we can visualize the ROC curve with R''s `plot()`
    function. As shown in the following code lines, many of the standard parameters
    to adjust the visualization can be used, such as `main` (to add a title), `col`
    (to change the line color), and `lwd` (to adjust the line width):'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`perf`对象，我们可以通过R的`plot()`函数可视化ROC曲线。如以下代码所示，可以使用许多标准参数来调整可视化效果，例如`main`（添加标题）、`col`（改变线条颜色）和`lwd`（调整线条宽度）：
- en: '[PRE28]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Although the `plot()` command is sufficient to create a valid ROC curve, it
    is helpful to add a reference line to indicate the performance of a classifier
    with no predictive value.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管`plot()`命令足以创建有效的ROC曲线，但添加参考线来指示一个没有预测价值的分类器的表现会更有帮助。
- en: 'To plot such a line, we''ll use the `abline()` function. This function can
    be used to specify a line in the slope-intercept form, where `a` is the intercept
    and `b` is the slope. Since we need an identity line that passes through the origin,
    we''ll set the intercept to `a=0` and the slope to `b=1`, as shown in the following
    plot. The `lwd` parameter adjusts the line thickness, while the `lty` parameter
    adjusts the type of line. For example, `lty = 2` indicates a dashed line:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了绘制这样的曲线，我们将使用`abline()`函数。这个函数可以用来指定一个斜截式方程，其中`a`是截距，`b`是斜率。由于我们需要一条通过原点的单位线，我们将截距设置为`a=0`，斜率设置为`b=1`，如下图所示。`lwd`参数调整线条的粗细，而`lty`参数调整线条的类型。例如，`lty
    = 2`表示虚线：
- en: '[PRE29]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The end result is an ROC plot with a dashed reference line:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果是带有虚线参考线的ROC图：
- en: '![ROC curves](img/B03905_10_16.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![ROC 曲线](img/B03905_10_16.jpg)'
- en: 'Qualitatively, we can see that this ROC curve appears to occupy the space at
    the top-left corner of the diagram, which suggests that it is closer to a perfect
    classifier than the dashed line representing a useless classifier. To confirm
    this quantitatively, we can use the ROCR package to calculate the AUC. To do so,
    we first need to create another `performance` object, this time specifying `measure
    = "auc"` as shown in the following code:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 从定性上看，我们可以看到这条ROC曲线似乎占据了图表的左上角区域，这表明它比表示无用分类器的虚线更接近一个完美的分类器。为了定量验证这一点，我们可以使用ROCR包来计算AUC。为此，我们首先需要创建另一个`performance`对象，这次指定`measure
    = "auc"`，如下代码所示：
- en: '[PRE30]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Since `perf.auc` is an R object (specifically known as an S4 object), we need
    to use a special type of notation to access the values stored within. S4 objects
    hold information in positions known as slots. The `str()` function can be used
    to see all of an object''s slots:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`perf.auc`是一个R对象（具体来说是S4对象），我们需要使用特殊的符号来访问其中存储的值。S4对象在被称为槽位的位置存储信息。可以使用`str()`函数查看一个对象的所有槽位：
- en: '[PRE31]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Notice that slots are prefixed with the `@` symbol. To access the AUC value,
    which is stored as a list in the `y.values` slot, we can use the `@` notation
    along with the `unlist()` function, which simplifies lists to a vector of numeric
    values:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，槽位前面有`@`符号。在访问存储在`y.values`槽位中的AUC值时，我们可以使用`@`符号和`unlist()`函数，后者将列表简化为数值向量：
- en: '[PRE32]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The AUC for the SMS classifier is 0.98, which is extremely high. But how do
    we know whether the model is just as likely to perform well for another dataset?
    In order to answer such questions, we need to have a better understanding of how
    far we can extrapolate a model's predictions beyond the test data.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: SMS分类器的AUC为0.98，这非常高。但是我们怎么知道该模型是否同样能够在另一个数据集上表现良好呢？为了回答这些问题，我们需要更好地理解我们能够将模型的预测结果从测试数据外推的范围。
- en: Estimating future performance
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 估计未来表现
- en: Some R machine learning packages present confusion matrices and performance
    measures during the model building process. The purpose of these statistics is
    to provide insight about the model's **resubstitution error**, which occurs when
    the training data is incorrectly predicted in spite of the model being built directly
    from this data. This information can be used as a rough diagnostic to identify
    obviously poor performers.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 一些R语言机器学习包在构建模型过程中会显示混淆矩阵和性能度量。这些统计数据的目的是提供关于模型**重新替换误差**的见解，这种误差发生在即使模型直接从训练数据构建，训练数据仍被错误预测时。这些信息可以用作粗略的诊断工具，以识别明显表现不佳的模型。
- en: The resubstitution error is not a very useful marker of future performance.
    For example, a model that used rote memorization to perfectly classify every training
    instance with zero resubstitution error would be unable to generalize its predictions
    to data it has never seen before. For this reason, the error rate on the training
    data can be extremely optimistic about a model's future performance.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 重新替换误差并不是一个非常有用的未来性能指标。例如，一个通过死记硬背完美分类每个训练实例并且零重新替换误差的模型，将无法将其预测泛化到从未见过的数据上。因此，训练数据上的错误率可能对模型未来的表现过于乐观。
- en: Instead of relying on resubstitution error, a better practice is to evaluate
    a model's performance on data it has not yet seen. We used this approach in previous
    chapters when we split the available data into a set for training and a set for
    testing. In some cases, however, it is not always ideal to create training and
    test datasets. For instance, in a situation where you have only a small pool of
    data, you might not want to reduce the sample any further.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 与其依赖重新替换误差，更好的做法是评估模型在它尚未见过的数据上的表现。我们在前几章中使用了这种方法，将可用数据分为训练集和测试集。然而，在某些情况下，创建训练集和测试集并不总是理想的。例如，在只有一小部分数据的情况下，你可能不希望再进一步减少样本量。
- en: Fortunately, there are other ways to estimate a model's performance on unseen
    data. The `caret` package we used to calculate performance measures also offers
    a number of functions to estimate future performance. If you are following the
    R code examples and haven't already installed the `caret` package, please do so.
    You will also need to load the package to the R session, using the `library(caret)`
    command.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，还有其他方法可以估计模型在未见数据上的表现。我们用来计算性能度量的`caret`包也提供了多个函数来估计未来的表现。如果你正在跟随R语言代码示例并且尚未安装`caret`包，请安装它。你还需要将该包加载到R会话中，使用`library(caret)`命令。
- en: The holdout method
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保留法
- en: The procedure of partitioning data into training and test datasets that we used
    in previous chapters is known as the **holdout method**. As shown in the following
    diagram, the **training dataset** is used to generate the model, which is then
    applied to the **test dataset** to generate predictions for evaluation. Typically,
    about one-third of the data is held out for testing, and two-thirds is used for
    training, but this proportion can vary depending on the amount of available data.
    To ensure that the training and test data do not have systematic differences,
    their examples are randomly divided into the two groups.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前几章中使用的将数据划分为训练集和测试集的过程被称为**保留法**。如下面的图示所示，**训练集**用于生成模型，然后将其应用于**测试集**以生成预测结果并进行评估。通常，大约三分之一的数据用于测试，三分之二用于训练，但这个比例可以根据可用数据的多少而有所不同。为了确保训练数据和测试数据没有系统性的差异，它们的样本会被随机地分配到两个组中。
- en: '![The holdout method](img/B03905_10_17.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![保留法](img/B03905_10_17.jpg)'
- en: For the holdout method to result in a truly accurate estimate of the future
    performance, at no time should the performance on the test dataset be allowed
    to influence the model. It is easy to unknowingly violate this rule by choosing
    the best model based upon the results of repeated testing. For example, suppose
    we built several models on the training data, and selected the one with the highest
    accuracy on the test data. Because we have cherry-picked the best result, the
    test performance is not an unbiased measure of the performance on unseen data.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使保留法真正准确地估计未来的性能，在任何时候都不应让测试数据集上的表现影响模型。很容易不知不觉地违反这一规则，通过反复测试选择最佳模型。例如，假设我们在训练数据上构建了多个模型，并选择了在测试数据上表现最好的那个。因为我们已经挑选了最佳结果，所以测试性能并不能公正地衡量在未见数据上的表现。
- en: To avoid this problem, it is better to divide the original data so that in addition
    to the training datasets and the test datasets, a **validation dataset** is available.
    The validation dataset would be used for iterating and refining the model or models
    chosen, leaving the test dataset to be used only once as a final step to report
    an estimated error rate for future predictions. A typical split between training,
    test, and validation would be 50 percent, 25 percent, and 25 percent, respectively.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这个问题，最好将原始数据分割，以便除了训练数据集和测试数据集之外，还可以有一个**验证数据集**。验证数据集将用于迭代和优化所选择的模型，留出测试数据集仅在最后一步使用，用于报告未来预测的估计误差率。训练、测试和验证的典型分割比例是50%、25%和25%。
- en: '![The holdout method](img/B03905_10_18.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![保留法](img/B03905_10_18.jpg)'
- en: Tip
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: A keen reader will note that holdout test data was used in the previous chapters
    to both evaluate models and improve model performance. This was done for illustrative
    purposes, but it would indeed violate the rule as stated previously. Consequently,
    the model performance statistics shown were not valid estimates of future performance
    on unseen data and the process could have been more accurately termed validation.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 一位敏锐的读者会注意到，前几章中使用了保留测试数据集来评估模型并提高模型性能。这样做是为了说明问题，但确实违反了前面提到的规则。因此，所展示的模型性能统计数据并不是对未来在未见数据上的性能的有效估计，整个过程应该更准确地称为验证。
- en: A simple method to create holdout samples uses random number generators to assign
    records to partitions. This technique was first used in [Chapter 5](ch05.html
    "Chapter 5. Divide and Conquer – Classification Using Decision Trees and Rules"),
    *Divide and Conquer – Classification Using Decision Trees and Rules* to create
    training and test datasets.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 创建保留样本的一种简单方法是使用随机数生成器将记录分配到不同的分区中。这个技术最早在[第5章](ch05.html "第5章. 分而治之 – 使用决策树和规则进行分类")，*分而治之
    – 使用决策树和规则进行分类*中，用于创建训练数据集和测试数据集。
- en: Tip
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: If you'd like to follow along with the following examples, download the `credit.csv`
    dataset from the Packt Publishing website, and load to a data frame using the
    `credit <- read.csv("credit.csv")` command.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望跟随以下的示例进行操作，可以从Packt出版网站下载`credit.csv`数据集，并使用`credit <- read.csv("credit.csv")`命令将其加载到数据框中。
- en: Suppose we have a data frame named credit with 1000 rows of data. We can divide
    it into three partitions as follows. First, we create a vector of randomly ordered
    row IDs from 1 to 1000 using the `runif()` function, which by default generates
    a specified number of random values between 0 and 1\. The `runif()` function gets
    its name from the random uniform distribution, which was discussed in [Chapter
    2](ch02.html "Chapter 2. Managing and Understanding Data"), *Managing and Understanding
    Data*.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个名为credit的数据框，包含1000行数据。我们可以按如下方式将其分为三个分区。首先，使用`runif()`函数创建一个随机排序的行ID向量，范围从1到1000。`runif()`函数默认生成指定数量的0到1之间的随机值。`runif()`函数的名称来源于随机均匀分布，这一点在[第2章](ch02.html
    "第2章. 管理和理解数据")，*管理和理解数据*中已有讨论。
- en: '[PRE33]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The `order()` used here returns a vector indicating the rank order of the 1,000
    random numbers. For example, `order(c(0.5, 0.25, 0.75, 0.1))` returns the sequence
    `4 2 1 3` because the smallest number (0.1) appears fourth, the second smallest
    (0.25) appears second, and so on.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的`order()`返回一个向量，表示1,000个随机数的排名顺序。例如，`order(c(0.5, 0.25, 0.75, 0.1))`返回序列`4
    2 1 3`，因为最小的数（0.1）排在第四，第二小的（0.25）排在第二，依此类推。
- en: 'We can use the resulting random IDs to divide the `credit` data frame into
    500, 250, and 250 records comprising the training, validation, and test datasets:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用生成的随机ID将`credit`数据框分成包含500、250和250条记录的训练、验证和测试数据集：
- en: '[PRE34]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: One problem with holdout sampling is that each partition may have a larger or
    smaller proportion of some classes. In certain cases, particularly those in which
    a class is a very small proportion of the dataset, this can lead a class to be
    omitted from the training dataset. This is a significant problem, because the
    model will not be able to learn this class.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 留出抽样的一个问题是每个分区可能具有某些类的较大或较小比例。在某些情况下，特别是某些类在数据集中占很小比例的情况下，这可能导致某个类在训练数据集中被省略。这是一个重大问题，因为模型将无法学习该类。
- en: In order to reduce the chance of this occurring, a technique called **stratified
    random sampling** can be used. Although in the long run a random sample should
    contain roughly the same proportion of each class value as the full dataset, stratified
    random sampling guarantees that the random partitions have nearly the same proportion
    of each class as the full dataset, even when some classes are small.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少这种情况发生的机会，可以使用一种称为**分层随机抽样**的技术。尽管从长远来看，随机样本应该包含与整个数据集相同比例的每个类值，但分层随机抽样确保随机分区几乎与整个数据集中每个类的比例相同，即使某些类很小。
- en: 'The `caret` package provides a `createDataPartition()` function that will create
    partitions based on stratified holdout sampling. The code to create a stratified
    sample of training and test data for the `credit` dataset is shown in the following
    commands. To use the function, a vector of the class values must be specified
    (here, `default` refers to whether a loan went into default) in addition to a
    parameter `p`, which specifies the proportion of instances to be included in the
    partition. The `list = FALSE` parameter prevents the result from being stored
    in the list format:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '`caret`包提供了一个`createDataPartition()`函数，该函数基于分层留出抽样创建分区。以下是为`credit`数据集创建分层样本的代码示例。要使用该函数，必须指定一个类值向量（这里的`default`指的是贷款是否违约），以及一个参数`p`，指定要包含在分区中的实例比例。`list
    = FALSE`参数防止结果以列表格式存储：'
- en: '[PRE35]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The `in_train` vector indicates row numbers included in the training sample.
    We can use these row numbers to select examples for the `credit_train` data frame.
    Similarly, by using a negative symbol, we can use the rows not found in the `in_train`
    vector for the `credit_test` dataset.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '`in_train`向量指示包含在训练样本中的行号。我们可以使用这些行号从`credit_train`数据框中选择示例。类似地，通过使用负号，我们可以使用未在`in_train`向量中找到的行号来获取`credit_test`数据集。'
- en: Although it distributes the classes evenly, stratified sampling does not guarantee
    other types of representativeness. Some samples may have too many or few difficult
    cases, easy-to-predict cases, or outliers. This is especially true for smaller
    datasets, which may not have a large enough portion of such cases to be divided
    among training and test sets.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管分层抽样可以均匀分布类别，但不能保证其他类型的代表性。一些样本可能包含太多或太少的难例、易于预测的案例或异常值。对于较小的数据集尤其如此，这些案例可能没有足够大的部分可以在训练和测试集之间划分。
- en: In addition to potentially biased samples, another problem with the holdout
    method is that substantial portions of data must be reserved to test and validate
    the model. Since these data cannot be used to train the model until its performance
    has been measured, the performance estimates are likely to be overly conservative.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 除了可能存在偏倚的样本外，留出法的另一个问题是必须保留大量数据用于测试和验证模型。由于这些数据在评估模型性能之前不能用于训练模型，因此性能估计可能过于保守。
- en: Tip
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Since models trained on larger datasets generally perform better, a common practice
    is to retrain the model on the full set of data (that is, training plus test and
    validation) after a final model has been selected and evaluated.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 由于通常在较大数据集上训练的模型表现更好，一种常见的做法是在选择和评估最终模型后，重新在整套数据（即训练加测试和验证）上训练模型。
- en: A technique called **repeated holdout** is sometimes used to mitigate the problems
    of randomly composed training datasets. The repeated holdout method is a special
    case of the holdout method that uses the average result from several random holdout
    samples to evaluate a model's performance. As multiple holdout samples are used,
    it is less likely that the model is trained or tested on nonrepresentative data.
    We'll expand on this idea in the next section.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 一种叫做**重复留出法**的技术有时被用来减轻随机组成的训练数据集所带来的问题。重复留出法是留出法的一种特殊情况，它通过使用几个随机留出样本的平均结果来评估模型的表现。由于使用了多个留出样本，因此模型训练或测试时使用非代表性数据的可能性较小。我们将在下一节中详细讨论这个概念。
- en: Cross-validation
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉验证
- en: The repeated holdout is the basis of a technique known as **k-fold cross-validation**
    (or **k-fold CV**), which has become the industry standard for estimating model
    performance. Rather than taking repeated random samples that could potentially
    use the same record more than once, k-fold CV randomly divides the data into *k*
    to completely separate random partitions called **folds**.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 重复留出法是一个叫做**k折交叉验证**（或**k-fold CV**）技术的基础，这已经成为估计模型表现的行业标准。与反复进行随机抽样（可能会多次使用相同的记录）不同，k折交叉验证将数据随机划分为*k*个完全独立的随机分区，称为**折叠**。
- en: Although *k* can be set to any number, by far, the most common convention is
    to use **10-fold cross-validation** (10-fold CV). Why 10 folds? The reason is
    that the empirical evidence suggests that there is little added benefit in using
    a greater number. For each of the 10 folds (each comprising 10 percent of the
    total data), a machine learning model is built on the remaining 90 percent of
    data. The fold's matching 10 percent sample is then used for model evaluation.
    After the process of training and evaluating the model has occurred for 10 times
    (with 10 different training/testing combinations), the average performance across
    all the folds is reported.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管*k*可以设置为任何数字，但迄今为止，最常见的约定是使用**10折交叉验证**（10-fold CV）。为什么是10个折叠？原因在于经验数据表明，使用更多折叠的好处并不显著。对于每个10折中的折叠（每个折叠包含总数据的10%），机器学习模型会在剩余的90%数据上进行训练。然后，使用与折叠匹配的10%样本进行模型评估。经过10次训练和评估（10种不同的训练/测试组合）后，报告所有折叠的平均表现。
- en: Tip
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: An extreme case of k-fold CV is the **leave-one-out method**, which performs
    k-fold CV using a fold for each of the data's examples. This ensures that the
    greatest amount of data is used to train the model. Although this may seem useful,
    it is so computationally expensive that it is rarely used in practice.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: k折交叉验证的一个极端情况是**留一法**，它使用数据的每个示例作为一个折叠来进行k折交叉验证。这确保了最大限度地利用数据来训练模型。尽管这看起来很有用，但由于计算成本极高，它在实际中很少使用。
- en: 'Datasets for cross-validation can be created using the `createFolds()` function
    in the `caret` package. Similar to the stratified random holdout sampling, this
    function will attempt to maintain the same class balance in each of the folds
    as in the original dataset. The following is the command to create 10 folds:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的交叉验证可以通过`caret`包中的`createFolds()`函数来创建。与分层随机留出采样类似，这个函数会尝试在每个折叠中保持与原始数据集相同的类别平衡。以下是创建10个折叠的命令：
- en: '[PRE36]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The result of the `createFolds()` function is a list of vectors storing the
    row numbers for each of the requested `k = 10` folds. We can peek at the contents,
    using `str()`:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '`createFolds()`函数的结果是一个向量列表，存储着每个请求的`k = 10`个折叠的行号。我们可以通过`str()`查看其内容：'
- en: '[PRE37]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Here, we see that the first fold is named `Fold01` and stores `100` integers,
    indicating the 100 rows in the credit data frame for the first fold. To create
    training and test datasets to build and evaluate a model, an additional step is
    needed. The following commands show how to create data for the first fold. We''ll
    assign the selected 10 percent to the test dataset, and use the negative symbol
    to assign the remaining 90 percent to the training dataset:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到第一个折叠被命名为`Fold01`，并存储了`100`个整数，表示第一个折叠中的信用数据框中的100行。为了创建训练集和测试集以构建和评估模型，还需要额外的步骤。以下命令展示了如何为第一个折叠创建数据。我们将选定的10%分配给测试数据集，并使用负号将剩余的90%分配给训练数据集：
- en: '[PRE38]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: To perform the full 10-fold CV, this step would need to be repeated a total
    of 10 times; building a model and then calculating the model's performance each
    time. At the end, the performance measures would be averaged to obtain the overall
    performance. Thankfully, we can automate this task by applying several of the
    techniques we've learned earlier.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行完整的 10 次交叉验证（10-fold CV），此步骤需要重复 10 次；每次都要构建模型并计算模型的表现。最后，所有表现指标会被平均，以获得整体性能。幸运的是，我们可以通过应用之前学到的几种技术来自动化这一过程。
- en: 'To demonstrate the process, we''ll estimate the kappa statistic for a C5.0
    decision tree model of the credit data using 10-fold CV. First, we need to load
    some R packages: `caret` (to create the folds), `C50` (for the decision tree),
    and `irr` (to calculate kappa). The latter two packages were chosen for illustrative
    purposes; if you desire, you can use a different model or a different performance
    measure along with the same series of steps.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示该过程，我们将使用 10 次交叉验证估计信用数据的 C5.0 决策树模型的卡帕统计量。首先，我们需要加载一些 R 包：`caret`（用于创建折叠）、`C50`（用于决策树）和
    `irr`（用于计算卡帕）。后两个包是为了示例目的选择的；如果你愿意，也可以使用其他模型或其他性能指标，沿用相同的步骤。
- en: '[PRE39]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Next, we''ll create a list of 10 folds as we have done previously. The `set.seed()`
    function is used here to ensure that the results are consistent if the same code
    is run again:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将像之前一样创建一个包含 10 个折叠的列表。这里使用 `set.seed()` 函数来确保如果再次运行相同的代码，结果是一致的：
- en: '[PRE40]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Finally, we will apply a series of identical steps to the list of folds using
    the `lapply()` function. As shown in the following code, because there is no existing
    function that does exactly what we need, we must define our own function to pass
    to `lapply()`. Our custom function divides the credit data frame into training
    and test data, builds a decision tree using the `C5.0()` function on the training
    data, generates a set of predictions from the test data, and compares the predicted
    and actual values using the `kappa2()` function:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用 `lapply()` 函数对折叠列表应用一系列相同的步骤。如以下代码所示，由于没有现成的函数可以完美满足我们的需求，我们必须定义自己的函数并传递给
    `lapply()`。我们自定义的函数将信用数据框分为训练数据和测试数据，使用 `C5.0()` 函数在训练数据上构建决策树，从测试数据生成一组预测，并使用
    `kappa2()` 函数比较预测值和实际值：
- en: '[PRE41]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The resulting kappa statistics are compiled into a list stored in the `cv_results`
    object, which we can examine using `str()`:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的卡帕统计量被编译成一个列表，存储在 `cv_results` 对象中，我们可以使用 `str()` 函数检查它：
- en: '[PRE42]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'There''s just one more step remaining in the 10-fold CV process: we must calculate
    the average of these 10 values. Although you will be tempted to type `mean(cv_results)`,
    because `cv_results` is not a numeric vector, the result would be an error. Instead,
    use the `unlist()` function, which eliminates the list structure, and reduces
    `cv_results` to a numeric vector. From here, we can calculate the mean kappa as
    expected:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 10 次交叉验证过程只剩下最后一步：我们必须计算这 10 个值的平均值。虽然你可能会倾向于输入 `mean(cv_results)`，但是由于 `cv_results`
    不是一个数值向量，这样会导致错误。相反，应该使用 `unlist()` 函数，它可以消除列表结构，将 `cv_results` 转化为数值向量。然后，我们就可以像预期的那样计算平均卡帕值：
- en: '[PRE43]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: This kappa statistic is fairly low, corresponding to "fair" on the interpretation
    scale, which suggests that the credit scoring model performs only marginally better
    than random chance. In the next chapter, we'll examine automated methods based
    on 10-fold CV that can assist us in improving the performance of this model.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这个卡帕统计量相对较低，对应于解释尺度中的“公平”，这表明信用评分模型的表现仅略优于随机猜测。在下一章中，我们将研究基于 10 次交叉验证的自动化方法，帮助我们提升该模型的表现。
- en: Tip
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Perhaps the current gold standard method to reliably estimate model performance
    is **repeated k-fold CV**. As you might guess from the name, this involves repeatedly
    applying k-fold CV and averaging the results. A common strategy is to perform
    10-fold CV ten times. Although it is computationally intensive, it provides a
    very robust estimate.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 也许目前最可靠的模型性能估计方法是 **重复的 k 折交叉验证（repeated k-fold CV）**。正如你从名字中猜到的那样，这涉及到反复应用
    k 折交叉验证，并平均结果。一种常见的策略是进行 10 次 10 折交叉验证。尽管这种方法计算量大，但它提供了一个非常稳健的估计。
- en: Bootstrap sampling
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自助抽样
- en: A slightly less frequently used alternative to k-fold CV is known as **bootstrap
    sampling**, the **bootstrap** or **bootstrapping** for short. Generally speaking,
    these refer to the statistical methods of using random samples of data to estimate
    the properties of a larger set. When this principle is applied to machine learning
    model performance, it implies the creation of several randomly selected training
    and test datasets, which are then used to estimate performance statistics. The
    results from the various random datasets are then averaged to obtain a final estimate
    of future performance.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 一种使用频率稍低的替代方法是**自助采样**（bootstrap sampling），简称**bootstrap**或**自助法**。一般而言，这些指的是使用数据的随机样本来估计较大数据集属性的统计方法。当这个原理应用于机器学习模型的性能时，它意味着创建几个随机选择的训练集和测试集，然后用它们来估计性能统计数据。来自不同随机数据集的结果会被平均，最终得到对未来性能的估计。
- en: So, what makes this procedure different from k-fold CV? Whereas cross-validation
    divides the data into separate partitions in which each example can appear only
    once, the bootstrap allows examples to be selected multiple times through a process
    of **sampling with replacement**. This means that from the original dataset of
    *n* examples, the bootstrap procedure will create one or more new training datasets
    that will also contain *n* examples, some of which are repeated. The corresponding
    test datasets are then constructed from the set of examples that were not selected
    for the respective training datasets.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这个过程与k折交叉验证有何不同呢？交叉验证将数据划分为不同的分区，其中每个示例只能出现一次，而自助法通过**有放回采样**允许示例被多次选择。这意味着，从原始的*n*个示例的数据集中，自助法程序将创建一个或多个新的训练数据集，这些数据集也包含*n*个示例，其中一些是重复的。相应的测试数据集则从未被选入相应训练数据集的示例集中构建。
- en: Using sampling with replacement as described previously, the probability that
    any given instance is included in the training dataset is 63.2 percent. Consequently,
    the probability of any instance being in the test dataset is 36.8 percent. In
    other words, the training data represents only 63.2 percent of available examples,
    some of which are repeated. In contrast to 10-fold CV, which uses 90 percent of
    the examples for training, the bootstrap sample is less representative of the
    full dataset.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面描述的带有替代的采样方法，任何给定实例被包含在训练数据集中的概率为63.2%。因此，任何实例出现在测试数据集中的概率为36.8%。换句话说，训练数据仅代表了63.2%的可用示例，其中一些是重复的。与使用90%示例用于训练的10折交叉验证（10-fold
    CV）相比，自助法样本对完整数据集的代表性较差。
- en: 'Because a model trained on only 63.2 percent of the training data is likely
    to perform worse than a model trained on a larger training set, the bootstrap''s
    performance estimates may be substantially lower than what would be obtained when
    the model is later trained on the full dataset. A special case of bootstrapping
    known as the **0.632 bootstrap** accounts for this by calculating the final performance
    measure as a function of performance on both the training data (which is overly
    optimistic) and the test data (which is overly pessimistic). The final error rate
    is then estimated as:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 因为仅在63.2%的训练数据上训练的模型可能会比在更大训练集上训练的模型表现差，所以自助法的性能估计可能比后来在完整数据集上训练模型时的结果低得多。自助法的一个特例，称为**0.632自助法**，通过将最终的性能度量计算为训练数据（过于乐观）和测试数据（过于悲观）性能的函数来考虑这一点。最终的误差率可以通过以下方式估算：
- en: '![Bootstrap sampling](img/B03905_10_19.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![自助采样](img/B03905_10_19.jpg)'
- en: One advantage of bootstrap over cross-validation is that it tends to work better
    with very small datasets. Additionally, bootstrap sampling has applications beyond
    performance measurement. In particular, in the next chapter we'll learn how the
    principles of bootstrap sampling can be used to improve model performance.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 自助法相较于交叉验证的一个优点是它在非常小的数据集上表现得更好。此外，自助采样不仅用于性能测量，还有其他应用。特别是在下一章中，我们将学习如何利用自助采样的原理来提高模型性能。
- en: Summary
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter presented a number of the most common measures and techniques for
    evaluating the performance of machine learning classification models. Although
    accuracy provides a simple method to examine how often a model is correct, this
    can be misleading in the case of rare events because the real-life cost of such
    events may be inversely proportional to how frequently they appear.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了评估机器学习分类模型性能的几种常见度量和技术。尽管准确度提供了一种简单的方法来检查模型的正确性，但在稀有事件的情况下，这可能会误导，因为此类事件的实际成本可能与它们出现的频率成反比。
- en: A number of measures based on confusion matrices better capture the balance
    among the costs of various types of errors. Closely examining the tradeoffs between
    sensitivity and specificity, or precision and recall can be a useful tool for
    thinking about the implications of errors in the real world. Visualizations such
    as the ROC curve are also helpful to this end.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 基于混淆矩阵的多个度量方法更好地捕捉了各种错误类型成本之间的平衡。仔细审视灵敏度与特异性，或者精确度与召回率之间的权衡，可能是思考现实世界中错误影响的一个有用工具。像ROC曲线这样的可视化工具也有助于这一点。
- en: It is also worth mentioning that sometimes the best measure of a model's performance
    is to consider how well it meets, or doesn't meet, other objectives. For instance,
    you may need to explain a model's logic in simple language, which would eliminate
    some models from consideration. Additionally, even if it performs very well, a
    model that is too slow or difficult to scale to a production environment is completely
    useless.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得一提的是，有时评估一个模型性能的最佳标准是考虑它在满足或未能满足其他目标方面的表现。例如，你可能需要用简单的语言解释模型的逻辑，这将排除一些模型的考虑范围。此外，即使一个模型表现非常好，如果它太慢或难以在生产环境中扩展，那么它也是完全没有用的。
- en: An obvious extension of measuring performance is to identify automated ways
    to find the best models for a particular task. In the next chapter, we will build
    upon our work so far to investigate ways to make smarter models by systematically
    iterating, refining, and combining learning algorithms.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 测量性能的一个明显扩展是找到自动化方法，为特定任务寻找最佳模型。在下一章中，我们将基于目前的工作，研究通过系统地迭代、优化和结合学习算法来构建更智能模型的方法。
