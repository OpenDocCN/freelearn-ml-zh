- en: 3\. Linear Regression
  id: totrans-0
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3\. 线性回归
- en: Overview
  id: totrans-1
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter covers regression problems and analysis, introducing us to linear
    regression, as well as multiple linear regression and gradient descent. By the
    end of this chapter, you will be able to distinguish between regression and classification
    problems. You will be able to implement gradient descent in linear regression
    problems, and also apply it to other model architectures. You will also be able
    to use linear regression to construct a linear model for data in an x-y plane,
    evaluate the performance of linear models, and use the evaluation to choose the
    best model. In addition, you will be able to execute feature engineering to create
    dummy variables for constructing complicated linear models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖回归问题及其分析，介绍了线性回归、多个线性回归和梯度下降法。到本章结束时，你将能够区分回归问题和分类问题。你将能够在回归问题中实现梯度下降法，并将其应用于其他模型架构。你还将能够使用线性回归为x-y平面中的数据构建线性模型，评估线性模型的性能，并利用评估结果选择最佳模型。此外，你还将能够执行特征工程，创建虚拟变量，以构建复杂的线性模型。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 介绍
- en: In Chapter 1, Fundamentals, and Chapter 2, Exploratory Data Analysis and Visualization,
    we introduced the concept of supervised machine learning in Python and the essential
    techniques required for loading, cleaning, exploring, and visualizing raw data
    sources. We discussed the importance of fully understanding the data before moving
    on to further analysis, as well as how the initial data preparation process can
    sometimes account for the majority of the time spent on the project as a whole.
    In particular, we considered correlations among all the variables, finding and
    addressing missing values, and understanding the shape of data via histograms,
    bar plots, and density plots. In this chapter, we will delve into the model building
    process and will construct our first supervised machine learning solution using
    linear regression.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章《基础知识》和第二章《探索性数据分析与可视化》中，我们介绍了Python中有监督机器学习的概念，以及加载、清理、探索和可视化原始数据源所需的基本技术。我们讨论了在进行进一步分析之前，全面理解数据的重要性，以及初步数据准备过程有时可能占据整个项目大部分时间的问题。特别地，我们考虑了所有变量之间的相关性、寻找并处理缺失值，以及通过直方图、条形图和密度图理解数据的形态。在本章中，我们将深入探讨模型构建过程，并使用线性回归构建我们的第一个有监督机器学习解决方案。
- en: Regression and Classification Problems
  id: totrans-5
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 回归与分类问题
- en: We discussed two distinct methods, supervised learning and unsupervised learning,
    in Chapter 1, Fundamentals. Supervised learning problems aim to map input information
    to a known output value or label, but there are two further subcategories to consider.
    Supervised learning problems can be further divided into regression or classification
    problems. Regression problems, which are the subject of this chapter, aim to predict
    or model continuous values, for example, predicting the temperature tomorrow in
    degrees Celsius, from historical data, or forecasting future sales of a product
    on the basis of its sales history. In contrast, classification problems, rather
    than returning a continuous value, predict membership of one or more of a specified
    number of classes or categories. The example supervised learning problem in Chapter
    1, Fundamentals, where we wanted to determine or predict whether a hairstyle was
    from the 1960s or 1980s, is a good example of a supervised classification problem.
    There, we attempted to predict whether a hairstyle was from one of two distinct
    groups or classes, class 1 being the 1960s and class 2 being the 1980s. Other
    classification problems include predicting whether a passenger of the Titanic
    survived, or the classic MNIST problem (http://yann.lecun.com/exdb/mnist/). (MNIST
    is a database of 70,000 labeled images of handwritten digits 0 through 9\. The
    task in classifying examples from MNIST is to take one of the 70,000 input images
    and predict or classify which digit, 0-9, is written in the image. The model must
    predict the membership of the image in one of 10 different classes.)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第 1 章《基础》中讨论了两种不同的方法：监督学习和无监督学习。监督学习问题旨在将输入信息映射到已知的输出值或标签，但还有两个子类别需要考虑。监督学习问题可以进一步分为回归问题或分类问题。本章的回归问题旨在预测或建模连续值，例如，从历史数据中预测明天的温度（以摄氏度为单位），或基于产品的销售历史预测未来的产品销售额。相对而言，分类问题则不是返回一个连续值，而是预测属于一个或多个指定类别或类的成员身份。第
    1 章《基础》中提到的监督学习问题示例，就是想要判断发型是属于 1960 年代还是 1980 年代，这是一个良好的监督分类问题示例。在那里，我们试图预测发型是属于两个不同类别中的一个，其中类别
    1 为 1960 年代，类别 2 为 1980 年代。其他分类问题包括预测泰坦尼克号乘客是否生还，或经典的 MNIST 问题（http://yann.lecun.com/exdb/mnist/）。(MNIST
    是一个包含 70,000 张标注过的手写数字图像的数据库，数字从 0 到 9。MNIST 分类任务是从这 70,000 张输入图像中选取一张，预测或分类该图像中写的是哪一个数字（0
    到 9）。该模型必须预测该图像属于 10 个不同类别中的哪一个。)
- en: The Machine Learning Workflow
  id: totrans-7
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 机器学习工作流
- en: 'Before we begin with regression problems, we will first look at the six major
    stages involved in creating any machine learning model, supervised regression
    or otherwise. These stages are as follows:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始讨论回归问题之前，我们首先需要了解创建任何机器学习模型（无论是监督回归还是其他类型模型）所涉及的六个主要阶段。这些阶段如下：
- en: Business understanding
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 商业理解
- en: Data understanding
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据理解
- en: Data preparation
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备
- en: Modeling
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 建模
- en: Evaluation
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 评估
- en: Deployment
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 部署
- en: 'This workflow is described by a well-known open industry standard called CRISP-DM
    (cross-industry standard process for data mining) and can be viewed as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 该工作流由一个知名的开放行业标准 CRISP-DM（跨行业数据挖掘标准流程）描述，可以如下查看：
- en: '![Figure 3.1: CRISP-DM Workflow'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.1：CRISP-DM 工作流'
- en: '](img/image-K3TDNA00.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-K3TDNA00.jpg)'
- en: 'Figure 3.1: CRISP-DM Workflow'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：CRISP-DM 工作流
- en: It is advised that you ensure you are completely confident in your understanding
    of this pipeline and of what is described in this section, as each of these stages
    is critical in achieving good model performance as well as meeting the needs of
    the business. Here, we review the key aspects of each stage.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 建议确保完全理解这个流程以及本节所描述的内容，因为每个阶段对于实现良好的模型性能和满足业务需求至关重要。在这里，我们回顾每个阶段的关键要素。
- en: Business Understanding
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 商业理解
- en: The first stage of any data analysis and modeling project is not to jump into
    the data or building, but rather to understand why we are analyzing the data and
    what the impact of our models and conclusions on the business will be. As an individual
    working with the data, you may not have all the domain knowledge needed for this
    stage; the solution is to spend time engaging with the stakeholders in the business
    who know the pain points and business goals. It's very important not to underestimate
    this stage. Also note from the flowchart that there is feedback between the business
    understanding and data understanding stages, as well as from the evaluation stage
    to the business understanding stage. In other words, these are ongoing stages
    and you should endeavor to continuously discover as much as you can about the
    business aspects of the problem on which you are working. In the initial work
    in this phase, you should also formulate a preliminary overall plan for the project.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 任何数据分析和建模项目的第一阶段并不是直接跳入数据或建模，而是理解我们为什么要分析这些数据，以及我们的模型和结论对业务的影响是什么。作为数据处理人员，你可能没有这阶段所需的全部领域知识；解决方案是花时间与业务中的利益相关者进行互动，他们了解痛点和业务目标。不要低估这一阶段的重要性。从流程图中还可以看到，业务理解阶段和数据理解阶段之间有反馈流动，评估阶段也会反馈到业务理解阶段。换句话说，这些都是持续进行的阶段，你应当尽力不断发现更多关于你所研究问题的业务方面的信息。在这一阶段的初步工作中，你还应该制定一个初步的整体项目计划。
- en: Data Understanding
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据理解
- en: In most real projects, there are multiple potential data sources that may vary
    over time. This stage is intended to acquire data and understand it enough to
    choose data for the solution of the problem. This could result in determining
    a need for more data. The basic steps are to determine what data is available
    initially and make a data inventory. Then, review the data, which may include
    reading it into Python and doing an assessment of the data quality; the common
    issues of missing values, anomalous values, and so on can be uncovered here and
    discussed with the business team to determine the best actions. Although methods
    to impute (fill in by means of a calculation) missing values are widely described
    in popular literature, you should not jump immediately to applying tools to "fix"
    problems in the data—the goal here is to understand them and review the appropriate
    actions with the business stakeholders. Note that it may be more appropriate to
    discard data instances with missing values than to impute them or undertake a
    process to find the missing values.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数实际项目中，可能会有多个潜在的数据来源，并且这些数据来源可能随着时间的推移而变化。本阶段的目的是获取数据，并对其有足够的了解，以便选择解决问题所需的数据。这可能导致确定需要更多数据。基本步骤是先确定初始可用数据，并制作数据清单。接着，审查数据，这可能包括将数据读取到Python中并评估数据质量；常见的问题如缺失值、异常值等可以在此阶段发现，并与业务团队讨论，确定最佳的处理方案。尽管流行文献中广泛描述了填补缺失值的方法，但你不应立即跳到使用工具“修复”数据中的问题——此阶段的目标是理解这些问题，并与业务利益相关者讨论合适的解决方案。请注意，可能比填补缺失值或进行填补过程更合适的做法是直接舍弃缺失值的数据实例。
- en: In addition to the data inventory, a key output of this stage is a report describing
    the data, what has been found, and expected actions. To get to that output, some
    EDA (Exploratory Data Analysis) is needed, as was described in Chapter 2, Exploratory
    Data Analysis and Visualization.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据清单外，本阶段的一个关键输出是描述数据、所发现内容和预期行动的报告。为了得到这个输出，需要进行一些EDA（探索性数据分析），正如在第二章《探索性数据分析与可视化》中所描述的那样。
- en: Data Preparation
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据准备
- en: In data preparation, we use the data determined to be appropriate from the prior
    stage and apply any cleaning and transformations that are needed for it to be
    used in modeling. This was the focus of a significant component of Chapter 1,
    Fundamentals, and thus will not be the subject of further analysis in this section.
    It is important, however, that the criticality of the data specification, collection,
    and cleaning/tidying process is well understood. We cannot expect to produce a
    high-performing system if the input data is sub-optimal. One common phrase that
    you should always remember with regard to data quality is garbage in, garbage
    out. If you use poor quality data, you are going to produce poor quality results.
    In our hairstyle example, we are looking for a sample size at least in the order
    of hundreds, ideally thousands that has been correctly labeled as either from
    the 1960s or 1980s. We do not want samples that have been incorrectly labeled
    or are even from either era.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据准备阶段，我们使用从前一阶段确定为合适的数据，并对其进行清洗和转换，使其能够用于建模。这是第一章《基础》中的一个重要部分，因此在本节中不会进一步分析。然而，重要的是要充分理解数据规范、收集和清理/整理过程的关键性。如果输入数据不理想，我们无法期望产生高性能的系统。关于数据质量的一个常用词句是“垃圾进，垃圾出”。如果你使用低质量的数据，就会得到低质量的结果。在我们的发型示例中，我们希望样本大小至少为数百个，理想情况下应为数千个，并且这些样本已正确标注为1960年代或1980年代的样本。我们不希望使用错误标注或甚至不属于这两个年代的样本。
- en: Note that during data preparation, it is entirely possible to discover additional
    aspects of the data and that additional visualization may be required during the
    process to get to the dataset for modeling.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在数据准备过程中，完全有可能发现数据的额外方面，并且在此过程中可能需要进行额外的可视化，以便得到用于建模的数据集。
- en: Modeling
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 建模
- en: 'The modeling stage is comprised of two sub-stages: model architecture specification
    and model training.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 建模阶段包括两个子阶段：模型架构规范和模型训练。
- en: 'Model architecture specification: These may be iteratively related in more
    complex projects. In many cases, there are multiple possible model types (such
    as linear regression, artificial neural network, gradient boosting, and others)
    that may be applicable to the problem at hand. Thus, it is sometimes beneficial
    to investigate more than one model architecture and to do that, the models must
    be trained and compared in terms of their predictive capability.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 模型架构规范：在更复杂的项目中，这些步骤可能是迭代相关的。在许多情况下，可能有多种模型类型（如线性回归、人工神经网络、梯度提升等）适用于当前问题。因此，有时调查不止一个模型架构是有益的，并且为了做到这一点，必须训练并比较这些模型的预测能力。
- en: 'Training: The second sub-stage of modeling is training, wherein we use the
    existing data and known outcomes in a process to "learn" the parameters of the
    candidate model. Here, we must establish the design and execution of the training
    process; the details of that will vary, depending on the model architecture chosen
    and the scale of the input data. For example, for very large datasets, we may
    have to stream or flow the data through the training process as the data is too
    large for the computer memory, while for smaller data, we can simply use the data
    all at once.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 训练：建模的第二个子阶段是训练，在这个阶段，我们使用现有的数据和已知的结果，通过一个过程“学习”候选模型的参数。在这里，我们必须建立训练过程的设计和执行；这些细节将根据选择的模型架构和输入数据的规模而有所不同。例如，对于非常大的数据集，我们可能需要将数据流式传输或流动通过训练过程，因为数据太大，无法完全存入计算机内存，而对于较小的数据集，我们可以一次性使用所有数据。
- en: Evaluation
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估
- en: The next stage of the workflow is the evaluation of the model, which yields
    the final performance metric. This is the mechanism through which we know whether
    the model is worth publishing, is better than a previous version, or whether it
    has been effectively translated across programming languages or development environments.
    We will cover some of these metrics in more detail in Chapter 7, Model Evaluation,
    and, as such, this will not be discussed in detail at this stage. Just keep in
    mind that whatever approach is used, it needs to be capable of consistently reporting
    and independently measuring the performance of the model against the metric using
    an appropriate sample from the data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程的下一阶段是对模型进行评估，得出最终的性能指标。这是我们判断模型是否值得发布、是否比以前的版本更好，或者是否已经在不同的编程语言或开发环境之间有效迁移的机制。我们将在第七章《模型评估》中更详细地讨论一些这些指标，因此在此阶段不会详细展开。只需要记住，无论使用何种方法，都需要能够一致地报告并独立地衡量模型相对于指标的表现，且需要使用适当的样本来自数据中进行评估。
- en: Deployment
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 部署
- en: In a complete data analytics workflow, most models, once developed, need to
    be deployed in order to be used. Deployment is critical in some applications,
    such as where a model might underlie a recommendation system on an e-commerce
    site, and the model has to be redeployed to the web application each time it is
    updated. Deployment can take many forms, from simply sharing a Jupyter notebook,
    to automated code updates to a website on a code commit, to a master repository.
    Although important, deployment is beyond the scope of this book and we won't address
    it much going forward.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个完整的数据分析工作流程中，大多数模型一旦开发完成，就需要进行部署以供使用。部署在某些应用中至关重要，例如，在电子商务网站上，模型可能作为推荐系统的基础，每次更新时，模型必须重新部署到
    Web 应用程序中。部署的形式多种多样，从简单地共享 Jupyter notebook，到在代码提交时自动更新网站代码，再到主仓库。尽管部署非常重要，但它超出了本书的范围，我们不会在接下来的内容中深入讨论。
- en: Before moving on to regression modeling, let's do some final data preparation
    exercises. For this purpose, we have created a synthetic dataset of recorded air
    temperatures from the years 1841 to 2010, which is available in the accompanying
    code bundle of this book or on GitHub at https://packt.live/2Pu850C. This dataset
    is composed of values designed to demonstrate the subject matter of this chapter
    and should not be mistaken for data collected from a scientific study.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入回归建模之前，让我们做一些最终的数据准备练习。为此，我们创建了一个合成的数据集，记录了从 1841 年到 2010 年的空气温度数据，该数据集可在本书附带的代码包中或在
    GitHub 上找到，网址为 https://packt.live/2Pu850C。该数据集包含的数值旨在展示本章的主题，不能与科学研究中收集的数据混淆。
- en: 'Exercise 3.01: Plotting Data with a Moving Average'
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习 3.01：使用移动平均法绘制数据
- en: 'As we discussed in Chapter 1, Fundamentals, and in the preceding section, a
    thorough understanding of the dataset being used is critical if a high-performing
    model is to be built. So, with this in mind, let''s use this exercise to load,
    plot, and interrogate the data source:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第一章《基础知识》中讨论的，以及在前面的章节中提到的，充分理解所使用的数据集对于构建高性能的模型至关重要。所以，考虑到这一点，让我们通过这个练习加载、绘制并查询数据源：
- en: 'Import the numpy, pandas, and matplotlib packages:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 numpy、pandas 和 matplotlib 包：
- en: import numpy as np
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: import pandas as pd
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: import pandas as pd
- en: import matplotlib.pyplot as plt
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: import matplotlib.pyplot as plt
- en: 'Use the pandas read_csv function to load the CSV file containing the synth_temp.csv
    dataset, and then display the first five lines of data:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 pandas 的 read_csv 函数加载包含 synth_temp.csv 数据集的 CSV 文件，并显示前五行数据：
- en: df = pd.read_csv('../Datasets/synth_temp.csv')
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: df = pd.read_csv('../Datasets/synth_temp.csv')
- en: df.head()
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: df.head()
- en: 'The output will be as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.2: The first five rows'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.2：前五行'
- en: '](img/image-EASY3Z4X.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-EASY3Z4X.jpg)'
- en: 'Figure 3.2: The first five rows'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：前五行
- en: 'For our purposes, we don''t want to use all this data, but let''s look at how
    many points there are per year. Create a print statement to output the number
    of points for the years 1841, 1902, and 2010, and make a simple plot of the number
    of points per year:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的目的，我们不希望使用所有这些数据，但让我们看一下每年有多少个数据点。创建一个打印语句，输出 1841 年、1902 年和 2010 年的点数，并制作一个简单的图表，显示每年的数据点数：
- en: take a quick look at the number of data points per year
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速查看每年数据点的数量
- en: print('There are ' + str(len(df.loc[df['Year'] == 1841])) \
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: print('There are ' + str(len(df.loc[df['Year'] == 1841])) \
- en: + ' points in 1841\n' + 'and ' \
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: + ' points in 1841\n' + 'and ' \
- en: + str(len(df.loc[df['Year'] == 2010])) \
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: + str(len(df.loc[df['Year'] == 2010])) \
- en: + ' points in 2010\n' + 'and ' \
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: + ' 2010年的数据点\n' + '以及 ' \
- en: + str(len(df.loc[df['Year'] == 1902])) \
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: + str(len(df.loc[df['Year'] == 1902])) \
- en: + ' points in 1902')
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: + ' 1902年的数据点']
- en: seeing there are different numbers of points, let's do a quick chart
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 看到每年有不同数量的数据点，做个快速图表看看
- en: fig, ax = plt.subplots()
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: fig, ax = plt.subplots()
- en: ax.plot(df['Year'].unique(), [len(df.loc[df['Year'] == i]) \
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot(df['Year'].unique(), [len(df.loc[df['Year'] == i]) \
- en: for i in df['Year'].unique()])
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: for i in df['Year'].unique()])
- en: plt.show()
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The output will be as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.3: Different number of points per year'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.3：每年数据点数量不同'
- en: '](img/image-UHLA56I2.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-UHLA56I2.jpg)'
- en: 'Figure 3.3: Different number of points per year'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3：每年数据点数量不同
- en: We see varying numbers of points per year. Also note that we don't have the
    information on exactly when in each year the various points were measured. If
    that were important, we would want to ask the appropriate business stakeholder
    if the information could be obtained.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到每年的数据点数量不同。还需要注意的是，我们没有关于每年各个数据点测量时间的确切信息。如果这很重要，我们可能需要询问相关业务负责人是否能获得这些信息。
- en: 'Let''s slice the DataFrame to remove all rows through 1901, as we can see that
    there is much less data in those years:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们切片 DataFrame，去除所有1901年及之前的数据，因为我们可以看到这些年份的数据较少：
- en: slice 1902 and forward
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从1902年开始切片
- en: df = df.loc[df.Year > 1901]
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: df = df.loc[df.Year > 1901]
- en: df.head()
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: df.head()
- en: 'The output will be as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.4: Subset of data from 1902 onward'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.4：1902年及以后数据的子集'
- en: '](img/image-0RI5ICIW.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-0RI5ICIW.jpg)'
- en: 'Figure 3.4: Subset of data from 1902 onward'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4：1902年及以后数据的子集
- en: 'Make a quick plot to visualize the data:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 快速绘制图表以可视化数据：
- en: quick plot to understand what we have so far
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速绘制图表以了解目前为止的情况
- en: fig, ax = plt.subplots()
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: fig, ax = plt.subplots()
- en: ax.scatter(df.Year, df.RgnAvTemp)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(df.Year, df.RgnAvTemp)
- en: plt.show()
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The output will be as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.5: Basic visualization of raw data after filtering dates'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.5：过滤日期后的原始数据基本可视化'
- en: '](img/image-MN04Y5R9.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-MN04Y5R9.jpg)'
- en: 'Figure 3.5: Basic visualization of raw data after filtering dates'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5：过滤日期后的原始数据基本可视化
- en: 'We can see that there is quite a range for each year. Group the data by year
    and use the agg method of the DataFrame to create annual averages. This works
    around the issue that we have multiple points at unknown dates in each year, but
    uses all the data:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到每年有相当大的差异。将数据按年分组，使用 DataFrame 的 agg 方法来创建年度平均值。这绕过了我们每年都有多个未知日期的数据点的问题，但仍然使用了所有数据：
- en: roll up by year
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按年汇总
- en: df_group_year = (df.groupby('Year').agg('mean')\
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year = (df.groupby('Year').agg('mean')\
- en: '.rename(columns = {''RgnAvTemp'' : ''AvgTemp''}))'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '.rename(columns = {''RgnAvTemp'' : ''AvgTemp''}))'
- en: print(df_group_year.head())
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: print(df_group_year.head())
- en: print(df_group_year.tail())
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: print(df_group_year.tail())
- en: 'The output will be as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.6: Yearly average data'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.6：每年平均数据'
- en: '](img/image-22CX18VC.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-22CX18VC.jpg)'
- en: 'Figure 3.6: Yearly average data'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6：每年平均数据
- en: 'As before, perform a quick visualization, as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 和以前一样，进行快速可视化，方法如下：
- en: visualize result of averaging over each year
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化按年份平均的结果
- en: fig, ax = plt.subplots()
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: fig, ax = plt.subplots()
- en: ax.scatter(df_group_year.index, df_group_year['AvgTemp'])
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(df_group_year.index, df_group_year['AvgTemp'])
- en: plt.show()
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The data will now appear as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 数据现在将如下所示：
- en: '![Figure 3.7: Yearly average data'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.7：每年平均数据'
- en: '](img/image-0TF4WTD6.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-0TF4WTD6.jpg)'
- en: 'Figure 3.7: Yearly average data'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7：每年平均数据
- en: 'Given that the data is still noisy, a moving average filter can provide a useful
    indicator of the overall trend. A moving average filter simply computes the average
    over the last N values and assigns this average to the Nth sample. Compute the
    values for a moving average signal for the temperature measurements using a window
    of 10 years:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据仍然有噪声，移动平均滤波器可以提供一个有用的整体趋势指示器。移动平均滤波器简单地计算最近N个值的平均值，并将此平均值分配给第N个样本。使用10年的窗口计算温度测量的移动平均值：
- en: window = 10
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: window = 10
- en: smoothed_df = \
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: smoothed_df = \
- en: pd.DataFrame(df_group_year.AvgTemp.rolling(window).mean())
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: pd.DataFrame(df_group_year.AvgTemp.rolling(window).mean())
- en: smoothed_df.colums = 'AvgTemp'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: smoothed_df.colums = 'AvgTemp'
- en: print(smoothed_df.head(14))
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: print(smoothed_df.head(14))
- en: print(smoothed_df.tail())
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: print(smoothed_df.tail())
- en: 'We will obtain the following output:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到以下输出：
- en: '![Figure 3.8: 10-year moving average temperatures'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.8：10年移动平均温度'
- en: '](img/image-VGGD9MD5.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-VGGD9MD5.jpg)'
- en: 'Figure 3.8: 10-year moving average temperatures'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8：10年移动平均温度
- en: 'Notice that the first 9 samples are NaN, which is because of the size of the
    moving average filter window. The window size is 10, hence, 9 (10-1) samples are
    required to generate the first average, and thus the first 9 samples are NaN.
    There are additional options to the rolling() method that can extend the values
    to the left or right, or allow the early values to be based on fewer points. In
    this case, we''ll just filter them out:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前9个样本为 NaN，这是因为移动平均滤波器窗口的大小。窗口大小是 10，因此需要 9 个样本（10-1）来生成第一个平均值，因此前9个样本为
    NaN。rolling() 方法有额外的选项，可以将值延伸到左侧或右侧，或允许基于更少的点计算早期值。在这种情况下，我们将只过滤掉它们：
- en: filter out the NaN values
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过滤掉 NaN 值
- en: smoothed_df = smoothed_df[smoothed_df['AvgTemp'].notnull()]
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: smoothed_df = smoothed_df[smoothed_df['AvgTemp'].notnull()]
- en: quick plot to understand what we have so far
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速绘制图表以了解目前的进展
- en: fig, ax = plt.subplots()
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: fig, ax = plt.subplots()
- en: ax.scatter(smoothed_df.index, smoothed_df['AvgTemp'])
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(smoothed_df.index, smoothed_df['AvgTemp'])
- en: plt.show()
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The output will be as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 3.9: Visualization of preprocessed temperature data'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.9：预处理温度数据的可视化'
- en: '](img/image-Q3RS2M7V.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-Q3RS2M7V.jpg)'
- en: 'Figure 3.9: Visualization of preprocessed temperature data'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.9：预处理温度数据的可视化
- en: 'Finally, plot the measurements by year along with the moving average signal:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，按年份绘制测量数据以及移动平均信号：
- en: fig = plt.figure(figsize=(10, 7))
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: fig = plt.figure(figsize=(10, 7))
- en: ax = fig.add_axes([1, 1, 1, 1]);
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ax = fig.add_axes([1, 1, 1, 1]);
- en: Raw data
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原始数据
- en: raw_plot_data = df[df.Year > 1901]
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: raw_plot_data = df[df.Year > 1901]
- en: ax.scatter(raw_plot_data.Year, \
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(raw_plot_data.Year, \
- en: raw_plot_data.RgnAvTemp, \
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: raw_plot_data.RgnAvTemp, \
- en: label = 'Raw Data', c = 'blue', s = 1.5)
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: label = '原始数据', c = 'blue', s = 1.5)
- en: Annual averages
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 年度平均
- en: annual_plot_data = df_group_year\
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: annual_plot_data = df_group_year\
- en: .filter(items = smoothed_df.index, axis = 0)
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: .filter(items = smoothed_df.index, axis = 0)
- en: ax.scatter(annual_plot_data.index, \
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(annual_plot_data.index, \
- en: annual_plot_data.AvgTemp, \
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: annual_plot_data.AvgTemp, \
- en: label = 'Annual average', c = 'k')
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: label = '年度平均', c = 'k')
- en: Moving averages
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 移动平均
- en: ax.plot(smoothed_df.index, smoothed_df.AvgTemp, \
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot(smoothed_df.index, smoothed_df.AvgTemp, \
- en: c = 'r', linestyle = '--', \
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: c = 'r', linestyle = '--', \
- en: label = f'{window} year moving average')
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: label = f'{window} 年移动平均')
- en: ax.set_title('Mean Air Temperature Measurements', fontsize = 16)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_title('平均空气温度测量', fontsize = 16)
- en: make the ticks include the first and last years
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使刻度包括第一个和最后一个年份
- en: tick_years = [1902] + list(range(1910, 2011, 10))
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: tick_years = [1902] + list(range(1910, 2011, 10))
- en: ax.set_xlabel('Year', fontsize = 14)
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlabel('年份', fontsize = 14)
- en: ax.set_ylabel('Temperature ($^\circ$C)', fontsize = 14)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylabel('温度 ($^\circ$C)', fontsize = 14)
- en: ax.set_xticks(tick_years)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xticks(tick_years)
- en: ax.tick_params(labelsize = 12)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ax.tick_params(labelsize = 12)
- en: ax.legend(fontsize = 12)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ax.legend(fontsize = 12)
- en: plt.show()
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The output will be as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 3.10: Annual average temperature overlaid on the 10-year moving average'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.10：年度平均温度与10年移动平均叠加图'
- en: '](img/image-7Y65GJJM.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-7Y65GJJM.jpg)'
- en: 'Figure 3.10: Annual average temperature overlaid on the 10-year moving average'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.10：年度平均温度与10年移动平均叠加图
- en: 'We can improve the plot by focusing on the part we are most interested in,
    the annual average values, by adjusting the y scale. This is an important aspect
    of most visualizations in that the scale should be optimized to convey the most
    information to the reader:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过调整 y 轴的尺度，专注于我们最感兴趣的部分——年度平均值，从而改进图表。这是大多数可视化中的一个重要方面，即尺度应优化以向读者传递最有用的信息：
- en: fig = plt.figure(figsize=(10, 7))
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: fig = plt.figure(figsize=(10, 7))
- en: ax = fig.add_axes([1, 1, 1, 1]);
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ax = fig.add_axes([1, 1, 1, 1]);
- en: Raw data
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原始数据
- en: raw_plot_data = df[df.Year > 1901]
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: raw_plot_data = df[df.Year > 1901]
- en: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
- en: label = 'Raw Data', c = 'blue', s = 1.5)
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: label = '原始数据', c = 'blue', s = 1.5)
- en: Annual averages
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 年度平均
- en: annual_plot_data = df_group_year\
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: annual_plot_data = df_group_year\
- en: .filter(items = smoothed_df.index, axis = 0)
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: .filter(items = smoothed_df.index, axis = 0)
- en: ax.scatter(annual_plot_data.index, annual_plot_data.AvgTemp, \
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(annual_plot_data.index, annual_plot_data.AvgTemp, \
- en: label = 'Annual average', c = 'k')
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: label = '年度平均', c = 'k')
- en: Moving averages
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 移动平均
- en: ax.plot(smoothed_df.index, smoothed_df.AvgTemp, c = 'r', \
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot(smoothed_df.index, smoothed_df.AvgTemp, c = 'r', \
- en: linestyle = '--', \
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: linestyle = '--', \
- en: label = f'{window} year moving average')
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: label = f'{window} 年移动平均')
- en: ax.set_title('Mean Air Temperature Measurements', fontsize = 16)
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_title('平均空气温度测量', fontsize = 16)
- en: make the ticks include the first and last years
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使刻度包括第一个和最后一个年份
- en: tick_years = [1902] + list(range(1910, 2011, 10))
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: tick_years = [1902] + list(range(1910, 2011, 10))
- en: ax.set_xlabel('Year', fontsize = 14)
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlabel('年份', fontsize = 14)
- en: ax.set_ylabel('Temperature ($^\circ$C)', fontsize = 14)
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylabel('温度 ($^\circ$C)', fontsize = 14)
- en: ax.set_ylim(17, 20)
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylim(17, 20)
- en: ax.set_xticks(tick_years)
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xticks(tick_years)
- en: ax.tick_params(labelsize = 12)
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ax.tick_params(labelsize = 12)
- en: ax.legend(fontsize = 12)
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ax.legend(fontsize = 12)
- en: plt.show()
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The final plot should appear as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 最终图表应如下所示：
- en: '![Figure 3.11: Final plot of raw data, annual averages, and smoothed data'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.11：原始数据、年均值和平滑数据的最终图表'
- en: '](img/image-7Q9XR9QF.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-7Q9XR9QF.jpg)'
- en: 'Figure 3.11: Final plot of raw data, annual averages, and smoothed data'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.11：原始数据、年均值和平滑数据的最终图表
- en: Looking at Figure 3.11, we can immediately make a few interesting observations.
    First, the temperature remained relatively consistent from the year 1902 to about
    1950, after which there is an increasing trend through to the end of the data.
    Second, there is scatter or noise in the measurements, even after averaging within
    each year. Third, there appears to be a shift at 1960, which might represent a
    change in measurement methods or some other factor; we might want to follow up
    with the business team to understand this more fully.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 看图 3.11，我们可以立即得出几个有趣的观察结果。首先，温度从1902年到大约1950年保持相对一致，之后温度趋势上升直到数据结束。其次，测量值中即使在每年平均后仍然存在波动或噪声。第三，1960年左右似乎有一个变化，这可能代表测量方法的变化或其他因素；我们可能需要与业务团队进一步沟通以更全面地了解这一点。
- en: Finally, note that the moving average values tend to be to the right of the
    raw data during periods in which there are trends. This is a direct result of
    the default parameters in the rolling() method; each moving average value is the
    average of 9 points to the left and the current point.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，请注意，在存在趋势的时期，移动平均值通常位于原始数据的右侧。这是滚动()方法中默认参数的直接结果；每个移动平均值是当前点和其左侧9个点的平均值。
- en: Note
  id: totrans-189
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to https://packt.live/316S0o6.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问本节的源代码，请参阅 https://packt.live/316S0o6。
- en: You can also run this example online at https://packt.live/2CmpJPZ. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 https://packt.live/2CmpJPZ 在线运行这个示例。你必须执行整个Notebook才能得到期望的结果。
- en: 'Activity 3.01: Plotting Data with a Moving Average'
  id: totrans-192
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 活动 3.01：使用移动平均绘制数据
- en: For this activity, we have acquired a dataset of weather information from Austin,
    Texas (austin_weather.csv), available in the accompanying source code, and will
    be looking at the changes in average daily temperature. We will plot a moving
    average filter for this dataset.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次活动中，我们获取了来自德克萨斯州奥斯丁的天气信息数据集（austin_weather.csv），该数据集可以在随附的源代码中找到，我们将查看日均温度的变化情况。我们将为此数据集绘制一个移动平均滤波器。
- en: Note
  id: totrans-194
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The original dataset can be found here: https://www.kaggle.com/grubenm/austin-weather'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集可以在这里找到：https://www.kaggle.com/grubenm/austin-weather
- en: 'The steps to be performed are as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 需要执行的步骤如下：
- en: Import pandas and matplotlib.pyplot.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 导入pandas和matplotlib.pyplot。
- en: Load the dataset into a pandas DataFrame from the CSV file.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集从CSV文件加载到pandas DataFrame中。
- en: We only need the Date and TempAvgF columns; remove all others from the dataset.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要日期和TempAvgF列；请从数据集中删除所有其他列。
- en: Initially, we will only be interested in the first year's data, so we need to
    extract that information only.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，我们只关注第一年的数据，因此需要提取该信息。
- en: Create a column in the DataFrame for the year value and extract the year value
    as an integer from the strings in the Date column and assign these values to the
    Year column.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在DataFrame中创建一个列来存储年份值，并从Date列中的字符串中提取年份值，将这些值分配到Year列中。
- en: Repeat this process to extract the month values and store the values as integers
    in the Month column.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 重复此过程以提取月份值，并将这些值作为整数存储在Month列中。
- en: Repeat this process one more time to store the day values as integers in the
    Day column.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 再次重复此过程，将日值存储为Day列中的整数。
- en: Copy the first year's worth of data to a DataFrame.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 将第一年的数据复制到DataFrame中。
- en: Compute a 20-day moving average filter.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 计算20天的移动平均滤波器。
- en: Plot the raw data and moving average signal, with the x axis being the day number
    in the year.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制原始数据和移动平均信号，x轴表示年份中的天数。
- en: 'The output should be as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 3.12: Temperature data overlaid on the 20-day moving average'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.12：温度数据叠加在20天移动平均线上'
- en: '](img/image-EZE2LD9E.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-EZE2LD9E.jpg)'
- en: 'Figure 3.12: Temperature data overlaid on the 20-day moving average'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.12：温度数据叠加在20天移动平均线上
- en: Note
  id: totrans-211
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found via this link.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的解答可以通过这个链接找到。
- en: You have learned how to load data from a CSV file, how to remove columns that
    are not required, how to extract information from text fields containing dates
    as strings, how to smooth data using a moving average, and how to visualize the
    results.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学习了如何从CSV文件加载数据，如何删除不需要的列，如何从包含日期的文本字段中提取信息，如何使用移动平均法平滑数据，以及如何可视化结果。
- en: Linear Regression
  id: totrans-214
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 线性回归
- en: 'We will start our investigation into regression models with the selection of
    a linear model. Linear models, while being a great first choice due to their intuitive
    nature, are also very powerful in their predictive power, assuming datasets contain
    some degree of linear or polynomial relationship between the input features and
    values. The intuitive nature of linear models often arises from the ability to
    view data as plotted on a graph and observe a trending pattern in the data with,
    say, the output (the y-axis value for the data) trending positively or negatively
    with the input (the x-axis value). The fundamental components of linear regression
    models are also often learned during high school mathematics classes. You may
    recall that the equation of a straight line is defined as follows:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过选择线性模型开始对回归模型的研究。线性模型是一个非常好的初步选择，因为它们具有直观的性质，而且在预测能力上也非常强大，前提是数据集包含一定程度的线性或多项式关系，输入特征和输出值之间有某种联系。线性模型的直观性质通常源于能够将数据绘制在图表上，并观察数据中呈现出的趋势模式，例如，输出（数据的y轴值）与输入（x轴值）呈正相关或负相关。线性回归模型的基本组件通常也在高中数学课程中学习过。你可能还记得，直线的方程定义如下：
- en: '![Figure 3.13: Equation of a straight line'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.13：直线方程'
- en: '](img/image-4J4XXS00.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-4J4XXS00.jpg)'
- en: 'Figure 3.13: Equation of a straight line'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13：直线方程
- en: Here, x is the input value and y is the corresponding output or predicted value.
    The parameters of the model are the slope of the line (the change in the y values
    divided by the change in x, also called the gradient), noted by β1 in the equation,
    as well as the y-intercept value, β1, which indicates where the line crosses the
    y axis. With such a model, we can provide values for the β1 and β0 parameters
    to construct a linear model.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，x是输入值，y是相应的输出或预测值。模型的参数包括直线的斜率（y值的变化除以x的变化，也叫梯度），在方程中用β1表示，以及y截距值β1，表示直线与y轴交点的位置。通过这样的模型，我们可以提供β1和β0参数的值来构建一个线性模型。
- en: 'For example, y = 1+ 2 * x has a slope of 2, indicating that the changes in
    the y values are at a rate of twice that of x; the line crosses the y intercept
    at 1, as you can see in the following diagram:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，y = 1 + 2 * x的斜率为2，这意味着y值的变化速度是x值的两倍；该直线在y轴的截距为1，以下图所示：
- en: '![Figure 3.14: Parameters of a straight line and linear model'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.14：直线参数和线性模型'
- en: '](img/image-MGXYYY7W.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-MGXYYY7W.jpg)'
- en: 'Figure 3.14: Parameters of a straight line and linear model'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14：直线参数和线性模型
- en: So, we have an understanding of the parameters that are required to define a
    straight line, but this isn't really doing anything particularly interesting.
    We just dictated the parameters of the model to construct a line. What we want
    to do is take a dataset and construct a model that best describes a dataset. In
    terms of the previous section, we want to choose the model architecture as a linear
    model, and then train the model to find the best values of β0 and β1\. As mentioned
    before, this dataset needs to have something that approximates a linear relationship
    between the input features and output values for a linear model to be a good choice.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们了解了定义直线所需的参数，但这并没有做什么特别有趣的事情。我们只是规定了模型的参数来构建一条直线。我们想要做的是，使用一个数据集来构建一个最能描述该数据集的模型。根据上一节的内容，我们希望选择线性模型作为模型架构，然后训练模型来找到最佳的β0和β1值。如前所述，这个数据集需要具有某种程度的线性关系，才能使线性模型成为一个好的选择。
- en: Least Squares Method
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 最小二乘法
- en: Many of the various techniques used in machine learning actually significantly
    pre-date the use of machine learning as a description. Some embody elements of
    statistics, and others have been used in the sciences to "fit" data for a very
    long time. The least squares method of finding the equation of a straight line
    that best represents a set of data is one of these, originally created in the
    early 1800s. The method can be used to illustrate many key ideas of the supervised
    learning of regression models, and so we'll start with it here.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中使用的许多技术其实早在机器学习作为描述出现之前就已经存在。有些技术体现了统计学的元素，而其他技术则已经在科学中被用来“拟合”数据很长时间。最小二乘法用于找出最能代表一组数据的直线方程，这就是其中之一，最早创建于
    19 世纪初。这种方法可以用来说明监督学习回归模型的许多关键概念，因此我们将在这里从它开始。
- en: The least squares method focuses on minimizing the square of the error between
    the predicted y values and the actual y values. The idea of minimizing an error
    is fundamental in machine learning and is the basis for essentially all learning algorithms.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法侧重于最小化预测的 y 值与实际 y 值之间的误差平方。最小化误差的思想是机器学习中的基本概念，也是几乎所有学习算法的基础。
- en: Although simple linear regression using the least squares method can be written
    down as simple algebraic expressions, most packages (like scikit-learn) will have
    more general optimization methods "under the hood."
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管使用最小二乘法的简单线性回归可以写成简单的代数表达式，但大多数包（如 scikit-learn）在“幕后”会有更通用的优化方法。
- en: The Scikit-Learn Model API
  id: totrans-229
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Scikit-Learn 模型 API
- en: 'The scikit-learn API uses a similar code pattern irrespective of the type of
    model being constructed. The general flow is:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn API 使用类似的代码模式，无论构建的是何种类型的模型。通用流程是：
- en: Import the class for the model type you want to use.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 导入你想要使用的模型类型的类。
- en: Here, we will use from sklearn.linear_model import LinearRegression.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用 `from sklearn.linear_model import LinearRegression`。
- en: Instantiate an instance of the model class. This is where hyperparameters are
    set. For simple linear regression, we can use defaults.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化模型类的一个实例。此处将设置超参数。对于简单的线性回归，我们可以使用默认值。
- en: Use the fit method with the x and y data we want to model.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 使用拟合方法并应用我们想要建模的 x 和 y 数据。
- en: Inspect the results, get metrics, and then visualize them.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 检查结果，获取指标，然后进行可视化。
- en: Let's use this workflow to create a linear regression model in the next exercise.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这个工作流程，在下一个练习中创建一个线性回归模型。
- en: 'Exercise 3.02: Fitting a Linear Model Using the Least Squares Method'
  id: totrans-237
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习 3.02：使用最小二乘法拟合线性模型
- en: 'In this exercise, we will construct our first linear regression model using
    the least squares method to visualize the air temperatures over a yearly timeframe
    and evaluate the performance of the model using evaluation metrics:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用最小二乘法构建第一个线性回归模型，来可视化每年时间范围内的气温，并使用评估指标评估模型的表现：
- en: Note
  id: totrans-239
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'We will be using the same synth_temp.csv dataset as in Exercise 3.01: Plotting
    Data with a Moving Average.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与练习 3.01 中相同的 synth_temp.csv 数据集：使用移动平均法绘制数据。
- en: 'Import the LinearRegression class from the linear_model module of scikit-learn,
    along with the other packages we need:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 从 scikit-learn 的 `linear_model` 模块导入 `LinearRegression` 类，并导入我们需要的其他包：
- en: import pandas as pd
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: import pandas as pd
- en: import matplotlib.pyplot as plt
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: import matplotlib.pyplot as plt
- en: from sklearn.linear_model import LinearRegression
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`from sklearn.linear_model import LinearRegression`'
- en: 'Load the data. For this exercise, we''ll use the same synthetic temperature
    data as was used previously:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据。对于本练习，我们将使用之前使用的相同的合成温度数据：
- en: load the data
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据
- en: df = pd.read_csv('../Datasets/synth_temp.csv')
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: df = pd.read_csv('../Datasets/synth_temp.csv')
- en: 'Repeat the preprocessing of the data from before:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 重复之前的数据预处理过程：
- en: slice 1902 and forward
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 切片从 1902 年开始
- en: df = df.loc[df.Year > 1901]
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: df = df.loc[df.Year > 1901]
- en: roll up by year
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按年份进行汇总
- en: 'df_group_year = df.groupby([''Year'']).agg({''RgnAvTemp'' : ''mean''})'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 'df_group_year = df.groupby([''Year'']).agg({''RgnAvTemp'' : ''mean''})'
- en: df_group_year.head(12)
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year.head(12)
- en: add the Year column so we can use that in a model
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加年列，以便我们可以在模型中使用它。
- en: df_group_year['Year'] = df_group_year.index
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year['Year'] = df_group_year.index
- en: df_group_year = \
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year = \
- en: 'df_group_year.rename(columns = {''RgnAvTemp'' : ''AvTemp''})'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 'df_group_year.rename(columns = {''RgnAvTemp'' : ''AvTemp''})'
- en: df_group_year.head()
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year.head()
- en: 'The data should appear as follows:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 数据应如下所示：
- en: '![Figure 3.15: Data after preprocessing'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.15：预处理后的数据](img/image-RJBJLLG8.jpg)'
- en: '](img/image-RJBJLLG8.jpg)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-RJBJLLG8.jpg)'
- en: 'Figure 3.15: Data after preprocessing'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.15：预处理后的数据
- en: 'Instantiate the LinearRegression class. Then, we can fit the model using our
    data. Initially, we will just fit the temperature data to the years. In the following
    code, note that the method requires the x data to be a 2D array and that we are
    passing only the year. We also need to use the reshape method and, in the (-1,
    1) parameters, -1 means that "the value is inferred from the length of the array
    and remaining dimensions":'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化 LinearRegression 类。然后，我们可以使用我们的数据来拟合模型。最初，我们只会将温度数据拟合到年份。在以下代码中，请注意该方法要求
    x 数据为 2D 数组，并且我们仅传递了年份。我们还需要使用 reshape 方法，并且在 (-1, 1) 参数中，-1 表示“该值从数组的长度和剩余维度中推断出来”：
- en: construct the model and inspect results
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建模型并检查结果
- en: linear_model = LinearRegression(fit_intercept = True)
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: linear_model = LinearRegression(fit_intercept = True)
- en: linear_model.fit(df_group_year['Year'].values.reshape((-1, 1)), \
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: linear_model.fit(df_group_year['Year'].values.reshape((-1, 1)), \
- en: df_group_year.AvTemp)
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year.AvTemp)
- en: print('model slope = ', linear_model.coef_[0])
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: print('模型斜率 = ', linear_model.coef_[0])
- en: print('model intercept = ', linear_model.intercept_)
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: print('模型截距 = ', linear_model.intercept_)
- en: r2 = linear_model.score(df_group_year['Year']\
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: r2 = linear_model.score(df_group_year['Year']\
- en: .values.reshape((-1, 1)), \
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: .values.reshape((-1, 1)), \
- en: df_group_year.AvTemp)
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year.AvTemp)
- en: print('r squared = ', r2)
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: print('r平方 = ', r2)
- en: Note
  id: totrans-274
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'Refer to the following link for more reading on scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 scikit-learn 的更多阅读，请参考以下链接： [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
- en: 'The output will be as follows:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.16: Results from using the fit method'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.16：使用拟合方法的结果](img/image-CEGQBU5B.jpg)'
- en: '](img/image-CEGQBU5B.jpg)'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-CEGQBU5B.jpg)'
- en: 'Figure 3.16: Results from using the fit method'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.16：使用拟合方法的结果
- en: 'Note the use of the score method, which is a method of the model object, to
    obtain the r2 value. This metric, called the coefficient of determination, is
    a widely used metric for linear regression. The closer r2 is to 1, the more closely
    our model is predicting the data. There are multiple formulas that can be used
    to compute r2\. Here is an example:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 注意使用 score 方法，这是模型对象的方法，用于获得 r2 值。这个度量叫做决定系数，是线性回归中广泛使用的度量。r2 越接近 1，说明我们的模型对数据的预测越精确。有多个公式可以用来计算
    r2。这里有一个例子：
- en: '![Figure 3.17: Calculation of r2'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.17：r2 计算](img/image-ZH6EW0LQ.jpg)'
- en: '](img/image-ZH6EW0LQ.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-ZH6EW0LQ.jpg)'
- en: 'Figure 3.17: Calculation of r2'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.17：r2 计算
- en: From Figure 3.17, you can get some understanding of r2 by noting that the numerator
    sums the errors from the predictions, while the denominator sums the variation
    of the data from the mean. Thus, r2 increases as the prediction errors get smaller.
    It's important to emphasize here that r2 is just a measure of "goodness of fit"—in
    this case, how well a simple straight line fits the given data. In more complex,
    real-world supervised learning problems, we would use a more robust approach to
    optimize the model and choose the best/final model. In particular, in general,
    we evaluate the model on data not used to train it, because evaluating it on the
    training data would give an overly optimistic measure of performance. This will
    be discussed in Chapter 7, Model Evaluation.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 从图 3.17 中，你可以通过注意到分子是预测误差的总和，而分母是数据与均值的变动之和，来对 r2 有一些理解。因此，随着预测误差的减小，r2 会增大。这里需要强调的是，r2
    只是“拟合优度”的一个度量——在本例中，指的是简单的直线如何拟合给定的数据。在更复杂的现实世界监督学习问题中，我们会使用更稳健的方法来优化模型并选择最佳/最终模型。特别是，一般情况下，我们会在未用于训练的数据上评估模型，因为在训练数据上评估会给出过于乐观的性能度量。第七章《模型评估》将讨论这一点。
- en: 'To visualize the results, we need to pass some data to the predict method of
    the model. A simple way to do that is to just reuse the data we used to fit the model:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化结果，我们需要将一些数据传递给模型的 predict 方法。一个简单的方法是直接重用我们用来拟合模型的数据：
- en: generate predictions for visualization
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成可视化预测
- en: pred_X = df_group_year.loc[:, 'Year']
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: pred_X = df_group_year.loc[:, 'Year']
- en: pred_Y = linear_model.predict(df_group_year['Year']\
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: pred_Y = linear_model.predict(df_group_year['Year']\
- en: .values.reshape((-1, 1)))
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: .values.reshape((-1, 1)))
- en: 'Now, we have everything we need to visualize the result:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经拥有可视化结果所需的一切：
- en: fig = plt.figure(figsize=(10, 7))
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: fig = plt.figure(figsize=(10, 7))
- en: ax = fig.add_axes([1, 1, 1, 1]);
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: ax = fig.add_axes([1, 1, 1, 1]);
- en: Raw data
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原始数据
- en: raw_plot_data = df[df.Year > 1901]
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: raw_plot_data = df[df.Year > 1901]
- en: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
- en: label = 'Raw Data', c = 'red', s = 1.5)
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: label = '原始数据', c = 'red', s = 1.5)
- en: Annual averages
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 年度平均值
- en: ax.scatter(df_group_year.Year, df_group_year.AvTemp, \
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(df_group_year.Year, df_group_year.AvTemp, \
- en: label = 'Annual average', c = 'k', s = 10)
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: label = '年平均', c = 'k', s = 10)
- en: linear fit
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性拟合
- en: ax.plot(pred_X, pred_Y, c = "blue", linestyle = '-.', \
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot(pred_X, pred_Y, c = "blue", linestyle = '-.', \
- en: linewidth = 4, label = 'linear fit')
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: linewidth = 4, label = '线性拟合')
- en: ax.set_title('Mean Air Temperature Measurements', fontsize = 16)
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_title('平均气温测量', fontsize = 16)
- en: make the ticks include the first and last years
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使刻度包含第一个和最后一个年份
- en: tick_years = [1902] + list(range(1910, 2011, 10))
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: tick_years = [1902] + list(range(1910, 2011, 10))
- en: ax.set_xlabel('Year', fontsize = 14)
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlabel('年份', fontsize = 14)
- en: ax.set_ylabel('Temperature ($^\circ$C)', fontsize = 14)
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylabel('温度 ($^\circ$C)', fontsize = 14)
- en: ax.set_ylim(15, 21)
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylim(15, 21)
- en: ax.set_xticks(tick_years)
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xticks(tick_years)
- en: ax.tick_params(labelsize = 12)
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: ax.tick_params(labelsize = 12)
- en: ax.legend(fontsize = 12)
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: ax.legend(fontsize = 12)
- en: plt.show()
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The output will be as follows:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.18: Linear regression – a first simple linear model'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.18：线性回归 - 第一个简单的线性模型'
- en: '](img/image-AEK3FF8A.jpg)'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-AEK3FF8A.jpg)'
- en: 'Figure 3.18: Linear regression – a first simple linear model'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.18：线性回归 - 第一个简单的线性模型
- en: From Figure 3.18, it's evident that a straight line isn't a very good model
    of the data. We'll return to this issue after an activity.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 从图 3.18 中可以看出，直线并不是数据的一个很好的模型。我们将在一个活动之后回到这个问题。
- en: Note
  id: totrans-318
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to https://packt.live/2NwANg1.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 https://packt.live/2NwANg1。
- en: You can also run this example online at https://packt.live/2Z1qQfT. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 https://packt.live/2Z1qQfT 上在线运行这个示例。你必须执行整个 Notebook 才能得到预期的结果。
- en: We have seen how to load in some data, import the LinearRegression class from
    scikit-learn, and use the fit, score, and predict methods to construct a model,
    look at a performance metric, and then visualize the results. Along the way, we
    introduced the least squares method, gave some of the mathematical background,
    and showed how some of the calculations work.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何加载一些数据，如何从 scikit-learn 导入 LinearRegression 类，并使用 fit、score 和 predict
    方法构建模型，查看性能指标，并可视化结果。在此过程中，我们介绍了最小二乘法，给出了一些数学背景，并展示了部分计算过程。
- en: We saw that for our synthetic temperature data, a linear model doesn't fit the
    data all that well. That's okay. In most cases, it is good practice to generate
    a baseline model early on in the project to serve as a benchmark against which
    the performance of more sophisticated models can be compared. So we can consider
    the linear model we developed here to be a naïve baseline model.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，对于我们的合成温度数据，线性模型并不完全适合这些数据。没关系。在大多数情况下，早期生成一个基准模型是一个好习惯，这个模型可以作为更复杂模型性能的比较基准。因此，我们可以将这里开发的线性模型视为一个简单的基准模型。
- en: Before continuing, it is important to note that when reporting the performance
    of machine learning models, the data used to train the model is not to be used
    to evaluate it, as it will give an optimistic view of the model's performance.
    We will cover the concept of validation, which includes evaluating and reporting
    model performance, in Chapter 7, Model Evaluation. For the purpose of this chapter,
    however, we will use the training data to check the model's performance; just
    remember that once you have completed Chapter 7, Model Evaluation, you will know
    better.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，需要注意的是，当报告机器学习模型的性能时，训练模型所使用的数据不能用于评估模型性能，因为这会给出模型性能的过于乐观的视角。我们将在第 7 章《模型评估》中讨论验证的概念，包括评估和报告模型性能。然而，本章中我们将使用训练数据来检查模型性能；只要记住，在完成第
    7 章《模型评估》后，你会更清楚如何做。
- en: 'Activity 3.02: Linear Regression Using the Least Squares Method'
  id: totrans-324
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 活动 3.02：使用最小二乘法进行线性回归
- en: For this activity, we will use the Austin, Texas weather dataset that we used
    in the previous activity. We will plot a linear regression model using the least
    squares method for the dataset.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个活动，我们将使用在前一个活动中使用的德克萨斯州奥斯汀的天气数据集。我们将使用最小二乘法为该数据集绘制线性回归模型。
- en: 'The steps to be performed are as follows:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行的步骤如下：
- en: 'Import the requisite packages, classes, and suchlike. Refer to Exercise 3.02:
    Fitting a Linear Model Using the Least Squares Method if necessary.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 导入必要的包、类等。如果需要，请参阅练习 3.02：使用最小二乘法拟合线性模型。
- en: Load the data from the csv (austin_weather.csv).
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 从 csv 文件加载数据（austin_weather.csv）。
- en: Inspect the data (using the head() and tail() methods).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 检查数据（使用 head() 和 tail() 方法）。
- en: 'The output for df.head() will be as follows:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: df.head()的输出将如下所示：
- en: '![Figure 3.19: Output for df.head()'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.19：df.head()的输出](img/image-3A1PPP86.jpg)'
- en: '](img/image-UPOYLJPO.jpg)'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-UPOYLJPO.jpg)'
- en: 'Figure 3.19: Output for df.head()'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.19：df.head()的输出
- en: 'The output for df.tail() will be as follows:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: df.tail()的输出将如下所示：
- en: '![Figure 3.20: Output for df.tail()'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.20：df.tail()的输出](img/image-3A1PPP86.jpg)'
- en: '](img/image-LPNVRK9C.jpg)'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-LPNVRK9C.jpg)'
- en: 'Figure 3.20: Output for df.tail()'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.20：df.tail()的输出
- en: Drop everything except the Date and TempAvgF columns.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 删除除 Date 和 TempAvgF 列以外的所有列。
- en: Create new Year, Month, and Day columns and populate them by parsing the Date
    column.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 创建新的 Year、Month 和 Day 列，并通过解析 Date 列来填充它们。
- en: Create a new column for a moving average and populate it with a 20-day moving
    average of the TempAvgF column.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的列用于移动平均，并用 TempAvgF 列的 20 天移动平均值填充它。
- en: Slice one complete year of data to use in a model. Ensure the year doesn't have
    missing data due to the moving average. Also, create a column for Day_of_Year
    (it should start at 1).
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 切割出一整年的数据用于模型训练。确保该年份的数据没有因移动平均而缺失。此外，创建一个 Day_of_Year 列（应从 1 开始）。
- en: Create a scatterplot of the raw data (the original TempAvgF column) and overlay
    it with a line for the 20-day moving average.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个散点图，显示原始数据（原始 TempAvgF 列），并在其上叠加 20 天移动平均线。
- en: 'The plot will be as follows:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 绘图将如下所示：
- en: '![Figure 3.21: Raw data with the 20-day moving average overlaid'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.21：原始数据与叠加的 20 天移动平均](img/image-3A1PPP86.jpg)'
- en: '](img/image-5VDXTR6A.jpg)'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-5VDXTR6A.jpg)'
- en: 'Figure 3.21: Raw data with the 20-day moving average overlaid'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.21：原始数据与叠加的 20 天移动平均
- en: Create a linear regression model using the default parameters, that is, calculate
    a y intercept for the model and do not normalize the data.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 使用默认参数创建线性回归模型，即计算模型的 y 截距，并且不对数据进行归一化。
- en: Now fit the model, where the input data is the day number for the year (1 to
    365) and the output is the average temperature. Print the parameters of the model
    and the r2 value.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 现在拟合模型，其中输入数据是年份的天数（1 到 365），输出是平均温度。打印模型的参数和 r² 值。
- en: 'The results should be as follows:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应如下所示：
- en: 'model slope: [0.04304568]'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '模型斜率: [0.04304568]'
- en: 'model intercept: 62.23496914044859'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '模型截距: 62.23496914044859'
- en: 'model r squared: 0.09549593659736466'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '模型 r² 值: 0.09549593659736466'
- en: Generate predictions from the model using the same x data.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的 x 数据从模型中生成预测。
- en: Create a new scatterplot, as before, adding an overlay of the predictions of
    the model.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的散点图，像之前一样，添加模型预测的叠加图层。
- en: '![Figure 3.22: Raw data, 20-day moving average, and linear fit'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.22：原始数据、20 天移动平均和线性拟合](img/image-LPNVRK9C.jpg)'
- en: '](img/image-3A1PPP86.jpg)'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-3A1PPP86.jpg)'
- en: 'Figure 3.22: Raw data, 20-day moving average, and linear fit'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.22：原始数据、20 天移动平均和线性拟合
- en: Note
  id: totrans-358
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found via this link.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以通过此链接找到。
- en: Building on the previous exercise, you have seen how to load and use the LinearRegression
    class from scikit-learn and the fit, score, and predict methods. Not surprisingly,
    a simple linear model that produces a straight line isn't the best model for this
    data. In later exercises, we will investigate ways in which we might address that.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 基于之前的练习，你已经了解了如何加载并使用 scikit-learn 中的 LinearRegression 类，以及 fit、score 和 predict
    方法。不出所料，产生直线的简单线性模型并不是该数据的最佳模型。在后续练习中，我们将探讨可能的改进方法。
- en: You have learned how to load data, structure it for the scikit-learn API, and
    use the LinearRegression class to fit a simple line to the data. It is evident
    that this is a poor model for this data, so we will explore ways to improve our
    model, beginning with the next topic, Linear Regression with Categorical Variables.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学会了如何加载数据、将其结构化以适应 scikit-learn API，并使用 LinearRegression 类将一条简单的直线拟合到数据上。显然，这对该数据来说是一个不理想的模型，因此我们将探索改进模型的方法，从下一个话题“具有分类变量的线性回归”开始。
- en: Linear Regression with Categorical Variables
  id: totrans-362
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 具有分类变量的线性回归
- en: 'There is an aspect of the model architecture selection phase that somewhat
    overlaps the data preparation phase: feature engineering. Broadly, feature engineering
    involves creating additional features (columns in our case) and using them in
    the model to improve model performance. Features may be engineered by transforming
    existing features (such as taking the logarithm and square root) or may be generated
    in some way and added to the dataset. As an example of the latter, we can extract
    the month, the day of the month, the day of the week, and so on from the date
    information in a dataset. Although a new feature such as the month could be a
    numeric value, in the majority of cases in supervised learning, simply using a
    numeric value of such a feature is not best practice. A simple idea would be as
    follows: if we code January to December as 1 to 12, a model might give more weight
    to December since it is 12 times larger than January. Also, when the date changes
    from December back to January, there would be an artificial step change in the
    value. Thus, such a feature is considered to be nominal categorical. Nominal categorical
    variables are features with multiple possible values but where the ordering of
    the values does not contain any information, and could even be misleading. There
    are also categorical variables that do have an implied order, which are called
    ordinal categorical variables. Examples include "tiny," "small," "medium," "large,"
    "extra-large," and "huge."'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 模型架构选择阶段有一个方面与数据准备阶段有些重叠：特征工程。广义上讲，特征工程涉及创建附加的特征（在我们这里是列），并将它们用于模型中以提高模型性能。特征可以通过转换现有特征（例如取对数或平方根）来工程化，或者以某种方式生成并添加到数据集中。举个后者的例子，我们可以从数据集中的日期信息中提取出月份、日期、星期几等。虽然像月份这样的新特征可以是一个数值，但在大多数监督学习的情况下，简单地使用这种特征的数值并不是最佳实践。一个简单的思路是：如果我们将1月到12月编码为1到12，那么模型可能会给12月更多的权重，因为12月比1月大12倍。此外，当日期从12月切换回1月时，值会发生人为的阶跃变化。因此，这样的特征被认为是名义类别的。名义类别变量是具有多个可能值的特征，但这些值的顺序不包含任何信息，甚至可能会误导。还有一些类别变量确实有隐含的顺序，它们被称为有序类别变量。例如，“小”、“中”、“大”、“特大”和“巨大”等。
- en: To handle either type of categorical data in most machine learning models, we
    still have to convert it to numbers. The general approach to such a conversion
    is called encoding. A very powerful but easy to understand encoding method is
    to convert a categorical feature using one-hot encoding.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理大多数机器学习模型中的任何类型的类别数据，我们仍然需要将其转换为数字。这种转换的通用方法叫做编码。一种非常强大但易于理解的编码方法是使用独热编码将类别特征转换为数值。
- en: 'When using one-hot encoding, each possible value of the categorical feature
    becomes a column. In the column corresponding to a given value, a 1 is entered
    if that instance of data had the feature at that value, otherwise, a 0 is entered.
    An example will make this much clearer, as seen in the following figure:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 使用独热编码时，类别特征的每个可能值都会变成一列。在对应于给定值的列中，如果该数据实例在该值下具有该特征，则输入1，否则输入0。一个例子会让这一点更加清晰，如下图所示：
- en: '![Figure 3.23: One-hot encoding of a nominal categorical column'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.23：名义类别列的独热编码'
- en: '](img/image-QM4YDGVR.jpg)'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-QM4YDGVR.jpg)'
- en: 'Figure 3.23: One-hot encoding of a nominal categorical column'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.23：名义类别列的独热编码
- en: So, by creating these columns and inserting the ones in the appropriate locations,
    we let the model "know" about the presence of the nominal categorical variable,
    but don't give extra weight to any given value. In the example in Figure 3.23,
    if we were trying to model dog life expectancy, before using one-hot encoding,
    we only had diet and weight as predictors. After applying one-hot encoding, we
    would expect to get a better model, since our intuition would be that some breeds
    live longer than others, all other factors being equal. In the following exercise,
    we'll see how to use encoding to leverage the power of linear models to model
    complex behavior.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过创建这些列并在适当的位置插入1，我们让模型“知道”名义类别变量的存在，但不会对任何特定值赋予额外的权重。在图3.23中的例子中，如果我们试图模拟狗的预期寿命，在使用独热编码之前，我们只有饮食和体重作为预测因素。应用独热编码后，我们预计能够得到一个更好的模型，因为我们的直觉是：在其他因素相等的情况下，一些犬种比其他犬种活得更久。在接下来的练习中，我们将看到如何使用编码来利用线性模型的强大能力来模拟复杂的行为。
- en: Note
  id: totrans-370
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'There are a number of other possible ways to encode categorical variables;
    see, for example, A Comparative Study of Categorical Variable Encoding Techniques
    for Neural Network Classifiers: https://pdfs.semanticscholar.org/0c43/fb9cfea23e15166c58e24106ce3605b20229.pdf'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他可能的编码分类变量的方法；例如，参见《神经网络分类器的分类变量编码技术比较研究》：https://pdfs.semanticscholar.org/0c43/fb9cfea23e15166c58e24106ce3605b20229.pdf
- en: In some cases, the best method may depend on the type of model being used. For
    example, linear regression has a requirement that none of the features are linearly
    dependent on any others (we will discuss this further later in this chapter).
    One-hot encoding actually introduces this problem, because the nth category can
    actually be determined from the other n-1 categories—intuitively, in Figure 3.23,
    if beagle, boxer, chihuahua, collie, and german shepherd are all 0, then miniature
    dachshund will be 1 (note that we are assuming that an instance may not have more
    than one valid category). Thus, in linear regression, we use a slightly different
    encoding called dummy variables. The only difference between dummy variables and
    one-hot encoding is that we drop one of the n columns to eliminate the dependence.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，最佳方法可能取决于所使用的模型类型。例如，线性回归要求特征之间没有线性依赖（我们将在本章后面进一步讨论）。独热编码实际上会引入这个问题，因为第
    n 类别实际上可以通过其他 n-1 类别来确定——直观地，在图 3.23 中，如果比格犬、拳师犬、吉娃娃、柯利犬和德国牧羊犬都是 0，那么迷你杜宾犬就是 1（假设一个实例不可能有多个有效类别）。因此，在进行线性回归时，我们使用稍有不同的编码方法，即虚拟变量。虚拟变量和独热编码的唯一区别是我们去掉了
    n 个列中的一个，从而消除了依赖关系。
- en: 'Exercise 3.03: Introducing Dummy Variables'
  id: totrans-373
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习 3.03：引入虚拟变量
- en: In this exercise, we will introduce dummy variables into our linear regression
    model to improve its performance.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将向线性回归模型中引入虚拟变量，以提高其性能。
- en: 'We will be using the same synth_temp dataset as was used in the previous exercise:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与之前练习相同的 synth_temp 数据集：
- en: 'Import the required packages and classes:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 导入所需的包和类：
- en: import pandas as pd
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: import pandas as pd
- en: import numpy as np
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: import matplotlib.pyplot as plt
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: import matplotlib.pyplot as plt
- en: from sklearn.linear_model import LinearRegression
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.linear_model import LinearRegression
- en: 'Load the data:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据：
- en: load data
  id: totrans-382
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据
- en: df = pd.read_csv('../Datasets/synth_temp.csv')
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: df = pd.read_csv('../Datasets/synth_temp.csv')
- en: 'Slice the DataFrame from 1902 onward, and then compute yearly averages:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 从1902年起切片数据框，然后计算每年的平均值：
- en: slice 1902 and forward
  id: totrans-385
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从1902年起切片
- en: print(df.head())
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: print(df.head())
- en: df = df.loc[df.Year > 1901]
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: df = df.loc[df.Year > 1901]
- en: print(df.head())
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: print(df.head())
- en: 'The output will be as follows:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.24: Output after slicing 1902'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.24：切片1902后的输出'
- en: '](img/image-2MOLJ3LE.jpg)'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-2MOLJ3LE.jpg)'
- en: 'Figure 3.24: Output after slicing 1902'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.24：切片1902后的输出
- en: roll up by year
  id: totrans-393
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按年份汇总
- en: df_group_year = df.groupby(['Year', 'Region'])\
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year = df.groupby(['Year', 'Region'])\
- en: .agg({'RgnAvTemp':'mean'})
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: .agg({'RgnAvTemp':'mean'})
- en: '"""'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: note that the .droplevel() method removes the multiindex
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，.droplevel() 方法会移除多重索引
- en: added by the .agg() method() to make things simpler
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 .agg() 方法添加（）以简化操作
- en: later on in our analysis
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 后续分析中
- en: '"""'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: print(df_group_year.head(12))
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: print(df_group_year.head(12))
- en: print(df_group_year.tail(12))
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: print(df_group_year.tail(12))
- en: 'The data should appear as follows:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 数据应如下所示：
- en: '![Figure 3.25: Annual average temperature by region'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.25：按地区划分的年均温度'
- en: '](img/image-SO0LPKV6.jpg)'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-SO0LPKV6.jpg)'
- en: 'Figure 3.25: Annual average temperature by region'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.25：按地区划分的年均温度
- en: 'Add a Year column using the index (which is in calendar years) level 0, and
    the Region column using the index level 1:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 使用索引（即年份）级别 0 和地区列（即索引级别 1）来添加 Year 列和 Region 列：
- en: add the region column so we can use that for dummy variables
  id: totrans-408
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加地区列，以便我们可以用它来创建虚拟变量
- en: df_group_year['Region'] = df_group_year.index.get_level_values(1)
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year['Region'] = df_group_year.index.get_level_values(1)
- en: add the Year column so we can use that in a model
  id: totrans-410
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加 Year 列，以便我们可以在模型中使用它
- en: df_group_year['Year'] = df_group_year.index.get_level_values(0)
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year['Year'] = df_group_year.index.get_level_values(0)
- en: reset the index on the long axis
  id: totrans-412
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重置长轴上的索引
- en: df_group_year = df_group_year.droplevel(0, axis = 0)
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year = df_group_year.droplevel(0, axis = 0)
- en: df_group_year = df_group_year.reset_index(drop = True)
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year = df_group_year.reset_index(drop = True)
- en: 'Perhaps the temperature levels or variation differs by region. Let''s look
    at the overall average temperatures for each region:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 也许温度水平或变化因地区而异。让我们看一下每个地区的整体平均温度：
- en: inspect data by region
  id: totrans-416
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按地区检查数据
- en: region_temps = df_group_year.groupby('Region').agg({'RgnAvTemp':'mean'})
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: region_temps = df_group_year.groupby('Region').agg({'RgnAvTemp':'mean'})
- en: colors = ['red', 'green', 'blue', 'black', 'lightcoral', \
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: colors = ['red', 'green', 'blue', 'black', 'lightcoral', \
- en: '''palegreen'',''skyblue'', ''lightslategray'', ''magenta'', \'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '''palegreen'',''skyblue'', ''lightslategray'', ''magenta'', \'
- en: '''chartreuse'', ''lightblue'', ''olive'']'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '''chartreuse'', ''lightblue'', ''olive'']'
- en: fig = plt.figure(figsize=(10, 7))
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: fig = plt.figure(figsize=(10, 7))
- en: ax = fig.add_axes([1, 1, 1, 1])
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: ax = fig.add_axes([1, 1, 1, 1])
- en: ax.bar(region_temps.index, region_temps.RgnAvTemp, \
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: ax.bar(region_temps.index, region_temps.RgnAvTemp, \
- en: color = colors, alpha = 0.5)
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: color = colors, alpha = 0.5)
- en: ax.set_title('Mean Air Temperature Measurements', fontsize = 16)
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_title('平均空气温度测量值', fontsize = 16)
- en: ax.set_xlabel('Region', fontsize = 14)
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlabel('区域', fontsize = 14)
- en: ax.set_ylabel('Temperature ($^\circ$C)', fontsize = 14)
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylabel('温度 ($^\circ$C)', fontsize = 14)
- en: ax.tick_params(labelsize = 12)
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: ax.tick_params(labelsize = 12)
- en: plt.show()
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The result should appear as follows:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应如下所示：
- en: '![Figure 3.26: Overall average temperature by region'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.26: 各区域的整体平均温度'
- en: '](img/image-ZOU2B3CJ.jpg)'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-ZOU2B3CJ.jpg)'
- en: 'Figure 3.26: Overall average temperature by region'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3.26: 各区域的整体平均温度'
- en: We see that, on average, the regions vary from one another by as many as 5 degrees.
    Thus, it might benefit the model to take the region into account. To do that,
    we will create dummy variables from the Region column.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，平均而言，区域之间的温差可达 5 度。因此，考虑区域可能对模型有益。为此，我们将从 Region 列创建虚拟变量。
- en: 'Pandas has a DataFrame method called get_dummies() that we can use for our
    needs. First, we create a new DataFrame with the new columns. Note that they are
    already populated with zeros and ones. We then concatenate the dummy variable
    columns to our data and drop the Region column as it is now redundant:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 有一个名为 get_dummies() 的 DataFrame 方法，我们可以用它来满足我们的需求。首先，我们创建一个包含新列的新 DataFrame。请注意，它们已经填充了零和一。然后，我们将虚拟变量列与数据合并，并删除
    Region 列，因为它现在是冗余的：
- en: convert the categorical variable 'region' to dummy vars
  id: totrans-436
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将分类变量 'region' 转换为虚拟变量
- en: dummy_cols = pd.get_dummies(df_group_year.Region, \
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: dummy_cols = pd.get_dummies(df_group_year.Region, \
- en: drop_first = True)
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: drop_first = True)
- en: df_group_year = pd.concat([df_group_year, dummy_cols], axis = 1)
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year = pd.concat([df_group_year, dummy_cols], axis = 1)
- en: print(df_group_year.head())
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: print(df_group_year.head())
- en: print(df_group_year.tail())
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: print(df_group_year.tail())
- en: 'The result should be as follows:'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应如下所示：
- en: '![Figure 3.27: Addition of dummy variables for the region'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.27: 添加区域的虚拟变量'
- en: '](img/image-MJQ1MBKO.jpg)'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-MJQ1MBKO.jpg)'
- en: 'Figure 3.27: Addition of dummy variables for the region'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3.27: 添加区域的虚拟变量'
- en: Note that in the get_dummies method, we set the drop_first = True parameter
    to remove one of the columns, as discussed earlier.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在 get_dummies 方法中，我们设置了 drop_first = True 参数以删除其中一列，正如前面讨论的那样。
- en: 'We now create a linear model, as before, using the Year column and all the
    dummy columns:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在创建一个线性模型，和之前一样，使用 Year 列和所有虚拟列：
- en: linear_model = LinearRegression(fit_intercept = True)
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: linear_model = LinearRegression(fit_intercept = True)
- en: linear_model.fit(df_group_year.loc[:, 'Year':'L'], \
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: linear_model.fit(df_group_year.loc[:, 'Year':'L'], \
- en: df_group_year.RgnAvTemp)
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year.RgnAvTemp)
- en: r2 = linear_model.score(df_group_year.loc[:, 'Year':'L'], \
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: r2 = linear_model.score(df_group_year.loc[:, 'Year':'L'], \
- en: df_group_year.RgnAvTemp)
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year.RgnAvTemp)
- en: print('r squared ', r2)
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: print('r 平方 ', r2)
- en: 'The output will be as follows:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: r squared 0.7778768442731825
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: r 平方 0.7778768442731825
- en: 'The r2 value is much higher than before, which looks promising. Generate predictions
    from the DataFrame with the dummy variables, and then visualize everything on
    a plot:'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: r2 值比之前高得多，看起来很有前景。从包含虚拟变量的 DataFrame 生成预测结果，然后将所有内容可视化到图表中：
- en: construct data to predict from model
  id: totrans-457
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建用于预测的模型数据
- en: pred_X = df_group_year.drop(['RgnAvTemp', 'Region'], axis = 1)
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: pred_X = df_group_year.drop(['RgnAvTemp', 'Region'], axis = 1)
- en: pred_Y = linear_model.predict(pred_X.values)
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: pred_Y = linear_model.predict(pred_X.values)
- en: preds = pd.concat([df_group_year.RgnAvTemp, \
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: preds = pd.concat([df_group_year.RgnAvTemp, \
- en: df_group_year.Region, \
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year.Region, \
- en: pred_X, pd.Series(pred_Y)], axis = 1)
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: pred_X, pd.Series(pred_Y)], axis = 1)
- en: 'preds.rename(columns = {0 : ''pred_temp''}, inplace = True)'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 'preds.rename(columns = {0 : ''pred_temp''}, inplace = True)'
- en: print(preds.head())
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: print(preds.head())
- en: 'The data should appear as follows:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 数据应如下所示：
- en: '![Figure 3.28: Predictions from the new model'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.28: 新模型的预测结果'
- en: '](img/image-FALLIFO0.jpg)'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-FALLIFO0.jpg)'
- en: 'Figure 3.28: Predictions from the new model'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3.28: 新模型的预测结果'
- en: 'For plotting, we''ll reduce the clutter by sampling from the predictions:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 为了绘图，我们通过从预测结果中抽样来减少杂乱：
- en: define a sample of the raw data and predictions
  id: totrans-470
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义原始数据和预测值的样本
- en: set a seed so results are repeatable
  id: totrans-471
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置随机种子，以确保结果可重复
- en: np.random.seed(42)
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: np.random.seed(42)
- en: plot_data = preds.sample(n = 100)
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: plot_data = preds.sample(n = 100)
- en: fig = plt.figure(figsize=(10, 7))
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: fig = plt.figure(figsize=(10, 7))
- en: ax = fig.add_axes([1, 1, 1, 1])
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: ax = fig.add_axes([1, 1, 1, 1])
- en: Raw data
  id: totrans-476
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原始数据
- en: raw_plot_data = plot_data
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: raw_plot_data = plot_data
- en: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
- en: label = 'Raw Data', c = 'red', s = 1.5)
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: label = 'Raw Data', c = 'red', s = 1.5)
- en: Annual averages
  id: totrans-480
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 年度平均值
- en: annual_plot_data = df_group_year.groupby('Year').agg('mean')
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: annual_plot_data = df_group_year.groupby('Year').agg('mean')
- en: ax.scatter(annual_plot_data.index, annual_plot_data.RgnAvTemp, \
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(annual_plot_data.index, annual_plot_data.RgnAvTemp, \
- en: label = 'Annual average', c = 'k', s = 10)
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: label = 'Annual average', c = 'k', s = 10)
- en: 'Let''s also visualize the linear fit results:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也可视化线性拟合结果：
- en: fit_data = plot_data
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: fit_data = plot_data
- en: 'for i in range(len(plot_data.Region.unique())):'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(len(plot_data.Region.unique())):'
- en: region = plot_data.Region.unique()[i]
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: region = plot_data.Region.unique()[i]
- en: plot_region = fit_data.loc[fit_data.Region == region, :]
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: plot_region = fit_data.loc[fit_data.Region == region, :]
- en: ax.scatter(plot_region.Year, plot_region.pred_temp, \
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(plot_region.Year, plot_region.pred_temp, \
- en: edgecolor = colors[i], facecolor = "none", \
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: edgecolor = colors[i], facecolor = "none", \
- en: s = 80, label = region)
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: s = 80, label = region)
- en: draw faint lines connecting the raw to the predicted
  id: totrans-492
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制连接原始数据和预测值的虚线
- en: 'for i in fit_data.index:'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in fit_data.index:'
- en: ax.plot([fit_data.Year[i], fit_data.Year[i]], \
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot([fit_data.Year[i], fit_data.Year[i]], \
- en: '[fit_data.pred_temp[i], fit_data.RgnAvTemp[i]], \'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '[fit_data.pred_temp[i], fit_data.RgnAvTemp[i]], \'
- en: '''-'', linewidth = 0.1, c = "red")'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '''-'', linewidth = 0.1, c = "red")'
- en: ax.set_title('Mean Air Temperature Measurements', fontsize = 16)
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_title('Mean Air Temperature Measurements', fontsize = 16)
- en: make the ticks include the first and last years
  id: totrans-498
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使刻度包括第一年和最后一年
- en: tick_years = [1902] + list(range(1910, 2011, 10))
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: tick_years = [1902] + list(range(1910, 2011, 10))
- en: ax.set_xlabel('Year', fontsize = 14)
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlabel('Year', fontsize = 14)
- en: ax.set_ylabel('Temperature ($^\circ$C)', fontsize = 14)
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylabel('Temperature ($^\circ$C)', fontsize = 14)
- en: ax.set_ylim(15, 21)
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylim(15, 21)
- en: ax.set_xticks(tick_years)
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xticks(tick_years)
- en: ax.tick_params(labelsize = 12)
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: ax.tick_params(labelsize = 12)
- en: ax.legend(fontsize = 12)
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: ax.legend(fontsize = 12)
- en: plt.show()
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: Note
  id: totrans-507
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: For error-free execution, you should run the cell only after writing the code
    for both steps 9 and 10.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保无错误执行，您应在编写步骤 9 和 10 的代码后再运行该单元。
- en: 'The plot should appear as follows:'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制结果应如下所示：
- en: '![Figure 3.29: Predictions from the new model'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.29：新模型的预测'
- en: '](img/image-R8RM4U48.jpg)'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-R8RM4U48.jpg)'
- en: 'Figure 3.29: Predictions from the new model'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.29：新模型的预测
- en: What we can see is that the model is predicting different levels for different
    regions, which, while still not wholly following the trend, accounts for much
    more of the variation than before.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，模型正在为不同区域预测不同的水平，尽管仍未完全跟随趋势，但相比之前，它已能解释更多的变异性。
- en: 'Let''s now finish by plotting just one region to get a feel for how well the
    model works:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过绘制一个区域来结束，以便了解模型的效果：
- en: let's plot just one region
  id: totrans-515
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们先绘制一个区域
- en: region_B = preds.loc[preds.B == 1, :]
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: region_B = preds.loc[preds.B == 1, :]
- en: np.random.seed(42)
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: np.random.seed(42)
- en: plot_data = region_B.sample(n = 50)
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: plot_data = region_B.sample(n = 50)
- en: fig = plt.figure(figsize=(10, 7))
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: fig = plt.figure(figsize=(10, 7))
- en: ax = fig.add_axes([1, 1, 1, 1])
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: ax = fig.add_axes([1, 1, 1, 1])
- en: Raw data
  id: totrans-521
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原始数据
- en: ax.scatter(plot_data.Year, plot_data.RgnAvTemp, \
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(plot_data.Year, plot_data.RgnAvTemp, \
- en: label = 'Raw Data', c = 'red', s = 1.5)
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: label = 'Raw Data', c = 'red', s = 1.5)
- en: ax.scatter(plot_data.Year, plot_data.pred_temp, \
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(plot_data.Year, plot_data.pred_temp, \
- en: label = "Predictions", facecolor = "none", \
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: label = "Predictions", facecolor = "none", \
- en: edgecolor = "blue", s = 80)
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: edgecolor = "blue", s = 80)
- en: 'Draw faint lines connecting the raw to the predicted values:'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制连接原始数据和预测值的虚线：
- en: 'for i in plot_data.index:'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in plot_data.index:'
- en: ax.plot([plot_data.Year[i], plot_data.Year[i]], \
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot([plot_data.Year[i], plot_data.Year[i]], \
- en: '[plot_data.pred_temp[i], plot_data.RgnAvTemp[i]], \'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: '[plot_data.pred_temp[i], plot_data.RgnAvTemp[i]], \'
- en: '''-'', linewidth = 0.1, c = "red")'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: '''-'', linewidth = 0.1, c = "red")'
- en: make the ticks include the first and last years
  id: totrans-532
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使刻度包括第一年和最后一年
- en: tick_years = [1902] + list(range(1910, 2011, 10))
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: tick_years = [1902] + list(range(1910, 2011, 10))
- en: ax.set_xlabel('Year', fontsize = 14)
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlabel('Year', fontsize = 14)
- en: ax.set_ylabel('Temperature ($^\circ$C)', fontsize = 14)
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylabel('Temperature ($^\circ$C)', fontsize = 14)
- en: ax.set_ylim(16, 21)
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylim(16, 21)
- en: ax.set_xticks(tick_years)
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xticks(tick_years)
- en: ax.tick_params(labelsize = 12)
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: ax.tick_params(labelsize = 12)
- en: ax.legend(fontsize = 12)
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: ax.legend(fontsize = 12)
- en: plt.show()
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: Note
  id: totrans-541
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: For error-free execution, you should run the cell only after writing the code
    for both steps 11 and 12.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保无错误执行，您应在编写步骤 11 和 12 的代码后再运行该单元。
- en: 'The result should be as follows:'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应如下所示：
- en: '![Figure 3.30: Predictions for region B'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.30：B区域的预测'
- en: '](img/image-58ZV8PPQ.jpg)'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-58ZV8PPQ.jpg)'
- en: 'Figure 3.30: Predictions for region B'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.30：B区域的预测
- en: Note
  id: totrans-547
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to https://packt.live/2YogxDt.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 若要访问此特定部分的源代码，请参见https://packt.live/2YogxDt。
- en: You can also run this example online at https://packt.live/311LDCx. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过https://packt.live/311LDCx在线运行这个示例。你必须执行整个Notebook才能获得所需结果。
- en: We now have an improved model that follows much of the variation in the data.
    However, we can see that we have still not captured the change in trend that is
    apparent around 1960\. To address that, we'll explore using linear regression
    to fit a model by using the powers of the x data, known as a polynomial model.
    First, you will practice using dummy variables using the Austin temperature dataset.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有了一个改进的模型，它能够跟随数据的大部分变化。然而，我们可以看到，仍然没有捕捉到大约在1960年左右出现的趋势变化。为了解决这个问题，我们将探索使用线性回归通过使用x数据的幂（即多项式模型）来拟合模型。首先，你将通过使用奥斯汀温度数据集来练习使用虚拟变量。
- en: 'Activity 3.03: Dummy Variables'
  id: totrans-551
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 活动3.03：虚拟变量
- en: For this activity, we will use the Austin, Texas, weather dataset that we used
    in the previous activity. In this activity, we will use dummy variables to enhance
    our linear regression model for this dataset.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这项活动，我们将使用在前一项活动中使用的奥斯汀（德州）天气数据集。在本次活动中，我们将使用虚拟变量来增强该数据集的线性回归模型。
- en: 'The steps to be performed are as follows:'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 需要执行的步骤如下：
- en: Load the LinearRegression class from scikit-learn, along with the fit, score,
    and predict methods, as well as pandas and matplotlib. pyplot.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 从scikit-learn加载LinearRegression类，以及fit、score和predict方法，还需要导入pandas和matplotlib.pyplot。
- en: Load the austin_weather.csv dataset, drop all but the Date and TempAvgF columns,
    and create Year, Month, and Day columns from the data.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 加载austin_weather.csv数据集，删除除Date和TempAvgF列以外的所有列，并从数据中创建Year、Month和Day列。
- en: Create a 20-day moving average column and populate it, and then slice the first
    complete year of data (days 1 through 365—this will be the year 2015). After slicing,
    reset the index of the DataFrame (Pandas core method, reset_index). Now, create
    a Day_of_Year column and populate it (keep in mind that the first day should be
    1, not 0).
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个20天的移动平均列并填充数据，然后切片出完整的第一年数据（从第1天到第365天—即2015年）。切片后，重置数据框的索引（使用Pandas核心方法reset_index）。现在，创建一个Day_of_Year列并填充数据（请记住，第一天应为1，而不是0）。
- en: Plot the raw data and moving average against Day_of_Year.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制原始数据和移动平均线相对于Day_of_Year的图表。
- en: 'The plot should appear as follows:'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 图表应如下所示：
- en: '![Figure 3.31: Austin temperatures and moving average'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.31：奥斯汀气温和移动平均线'
- en: '](img/image-MF5YIEM2.jpg)'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-MF5YIEM2.jpg)'
- en: 'Figure 3.31: Austin temperatures and moving average'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.31：奥斯汀气温和移动平均线
- en: Now, investigate whether adding the month to the model could improve the model.
    To do this, create a dummy_vars DataFrame using the pandas get_dummies method
    on the Month column of the DataFrame, and then rename the dummy columns Jan through
    Dec. Now, concatenate dummy_vars to the DataFrame in a new DataFrame called df_one_year.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，研究将月份添加到模型中是否能够改进模型。为此，使用pandas的get_dummies方法对数据框的Month列创建一个dummy_vars数据框，并将虚拟列重命名为Jan至Dec。现在，将dummy_vars合并到新的数据框df_one_year中。
- en: Display the DataFrame and confirm that the dummy columns are present.
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 显示数据框并确认虚拟列已存在。
- en: Use a least squares linear regression model and fit the model to the Day_of_Year
    values and the dummy variables to predict TempAvgF.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 使用最小二乘法线性回归模型，并将模型拟合到Day_of_Year值和虚拟变量上，以预测TempAvgF。
- en: Get the model parameters and the r2 value. The r2 value should be much larger
    than in the previous activity.
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 获取模型参数和r2值。r2值应该比前一项活动中的值大得多。
- en: Using the Day_of_Year values and the dummy variables, predict the temperature
    for the df_one_year data.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Day_of_Year值和虚拟变量，预测df_one_year数据中的温度。
- en: Plot the raw data, the 20-day moving average, and the new prediction.
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制原始数据、20天移动平均线和新的预测值。
- en: 'The output will be as follows:'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.32: Linear regression results with month dummy variables'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.32：使用月份虚拟变量的线性回归结果'
- en: '](img/image-E96FFRA8.jpg)'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-E96FFRA8.jpg)'
- en: 'Figure 3.32: Linear regression results with month dummy variables'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.32：使用月份虚拟变量的线性回归结果
- en: Note
  id: totrans-572
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found via this link.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 本次活动的解决方案可以通过此链接找到。
- en: You have learned how to use the scikit-learn API with the LinearRegression class
    to fit data augmented with dummy variables. The get_dummies pandas method was
    used to generate additional variable columns encoding the months to improve the
    model. A useful property of the new model is that it accounts for the seasonal
    variation in temperature, as well as any overall trend. However, it is rather
    piecewise, which may or may not meet the business needs for prediction.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学习了如何使用 scikit-learn API 中的 LinearRegression 类来拟合包含虚拟变量的数据。使用 get_dummies
    pandas 方法生成了额外的变量列来编码月份，以改进模型。新模型的一个有用特性是，它考虑了温度的季节性变化，以及任何整体趋势。然而，它是相当分段的，这可能不完全符合预测的业务需求。
- en: At this stage, you should be comfortable with basic linear regression as well
    as using the scikit-learn interface and the get_dummies pandas method. We have
    also touched on a few visualization points and introduced the idea of feature
    engineering in the context of using dummy variables. We will now move on to polynomial
    regression, which takes feature engineering in a different direction while still
    leveraging the power of linear regression.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该已经对基本的线性回归以及使用 scikit-learn 接口和 get_dummies pandas 方法感到熟悉。我们还介绍了一些可视化的要点，并在使用虚拟变量的背景下引入了特征工程的概念。接下来我们将介绍多项式回归，它将特征工程带入一个不同的方向，同时仍然利用线性回归的强大功能。
- en: Polynomial Models with Linear Regression
  id: totrans-576
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 线性回归的多项式模型
- en: 'Linear regression models are not constrained to straight-line linear models.
    We can fit some more complicated models using the exact same techniques. In the
    synthetic temperature data, we can see an upward curve in the trend. Therefore,
    in addition to any overall (linear in time) trend, there may be a trend related
    to a positive power of time. If we build a model using integer powers of the independent
    variable, this is called polynomial regression. For powers up to 2, the equation
    would be as follows. Note that we refer to the order of the polynomial as the
    highest power, so this is a polynomial of order 2:'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型并不限于直线线性模型。我们可以使用完全相同的技术拟合一些更复杂的模型。在合成的温度数据中，我们可以看到趋势的上升曲线。因此，除了任何整体（随时间变化的线性）趋势外，可能还存在与时间的正幂相关的趋势。如果我们使用自变量的整数幂来构建模型，这就叫做多项式回归。对于幂次为
    2 的情况，方程式如下所示。注意，我们将多项式的阶数称为最高幂次，因此这是一个阶数为 2 的多项式：
- en: '![Figure 3.33: Equation of a polynomial of order 2'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.33：二阶多项式的方程'
- en: '](img/image-O76ZRUSK.jpg)'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-O76ZRUSK.jpg)'
- en: 'Figure 3.33: Equation of a polynomial of order 2'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.33：二阶多项式的方程
- en: The addition of this squared term transforms the trendline from a straight line
    to one that has curvature. In general, polynomial models can be very powerful
    to fit given data, but they may not extrapolate very well outside the range of
    the data. This would be an example of overfitting and is especially true as the
    order of the polynomial increases.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 添加这个平方项将趋势线从直线转变为具有曲率的线。一般来说，多项式模型在拟合给定数据时可能非常强大，但它们可能无法很好地在数据范围之外进行外推。这将是过拟合的一个例子，尤其是在多项式阶数增加时，这一点尤为明显。
- en: 'Therefore, in general, you should make limited use of polynomial regression
    and keep the order low, unless there is a clear business case or a known underlying
    model that indicates doing otherwise:'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通常情况下，除非有明确的业务需求或已知的潜在模型表明需要采取不同方法，否则你应该有限地使用多项式回归，并保持阶数较低：
- en: '![Figure 3.34: Plot of y versus x for the second order polynomial'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.34：二阶多项式的 y 与 x 的关系图'
- en: '](img/image-9Y4YPB9U.jpg)'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-9Y4YPB9U.jpg)'
- en: 'Figure 3.34: Plot of y versus x for the second order polynomial'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.34：二阶多项式的 y 与 x 的关系图
- en: Note that here, we are looking at a simple model where there is only one feature,
    the variable x. In more complex cases, we might have several features. The number
    of terms in the equation will increase quickly as the number of features increases.
    To construct a polynomial, regression packages such as scikit-learn offer methods
    to automatically generate polynomial features (for example, sklearn.preprocessing.PolynomialFeatures).
    Here, we will build a simple polynomial model manually to illustrate the approach.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这里我们正在查看一个简单的模型，其中只有一个特征变量 x。在更复杂的情况下，我们可能有多个特征。随着特征数量的增加，方程中的项数会迅速增加。为了构建多项式，像
    scikit-learn 这样的回归包提供了自动生成多项式特征的方法（例如，sklearn.preprocessing.PolynomialFeatures）。在这里，我们将手动构建一个简单的多项式模型，以说明这一方法。
- en: 'Exercise 3.04: Polynomial Models with Linear Regression'
  id: totrans-587
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习 3.04：线性回归的多项式模型
- en: 'In order to fit a polynomial model using linear regression, we need to create
    the features raised to the desired powers. Recall the earlier discussion on feature
    engineering; we are going to engineer new features, which are the original independent
    variables raised to a power:'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用线性回归拟合多项式模型，我们需要创建提升到所需幂次的特征。回顾一下之前关于特征工程的讨论；我们将创建新的特征，即将原始自变量提升到一个幂次：
- en: 'Beginning with the synth_temp.csv data, load the packages and classes, and
    then preprocess the data as before:'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 从synth_temp.csv数据开始，加载包和类，然后像以前一样预处理数据：
- en: import pandas as pd
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: import pandas as pd
- en: import matplotlib.pyplot as plt
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: import matplotlib.pyplot as plt
- en: from sklearn.linear_model import LinearRegression
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.linear_model import LinearRegression
- en: load the data
  id: totrans-593
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据
- en: df = pd.read_csv('../Datasets/synth_temp.csv')
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: df = pd.read_csv('../Datasets/synth_temp.csv')
- en: slice 1902 and forward
  id: totrans-595
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从1902年及以后开始切片
- en: df = df.loc[df.Year > 1901]
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: df = df.loc[df.Year > 1901]
- en: roll up by year
  id: totrans-597
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按年汇总
- en: 'df_group_year = df.groupby([''Year'']).agg({''RgnAvTemp'' : ''mean''})'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 'df_group_year = df.groupby([''Year'']).agg({''RgnAvTemp'' : ''mean''})'
- en: 'Now, we add the Year column using the index, and then calculate a Year2 column
    by raising the Year column to the power of 2:'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用索引添加Year列，然后通过将Year列的值平方来计算Year2列：
- en: add the Year column so we can use that in a model
  id: totrans-600
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加Year列，以便我们可以在模型中使用它
- en: df_group_year['Year'] = df_group_year.index
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year['Year'] = df_group_year.index
- en: df_group_year = df_group_year\
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year = df_group_year\
- en: '.rename(columns = {''RgnAvTemp'' : ''AvTemp''})'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: '.rename(columns = {''RgnAvTemp'' : ''AvTemp''})'
- en: add a Year**2 column to build a polynomial model of degree 2
  id: totrans-604
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加一个Year**2列，构建二次多项式模型
- en: df_group_year['Year2'] = df_group_year['Year']**2
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year['Year2'] = df_group_year['Year']**2
- en: print(df_group_year.head())
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: print(df_group_year.head())
- en: print(df_group_year.tail())
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: print(df_group_year.tail())
- en: 'The result is as follows:'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 3.35: Yearly temperature data with the year and the year to the second
    power'
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.35：带有年份和年份平方的年度温度数据'
- en: '](img/image-GOFHTDW8.jpg)'
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-GOFHTDW8.jpg)'
- en: 'Figure 3.35: Yearly temperature data with the year and the year to the second
    power'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.35：带有年份和年份平方的年度温度数据
- en: 'Fit the data to the model. This time, we will need to provide two sets of values
    as the inputs to the model, Year and Year2, which is equivalent to passing x and
    x2 to the polynomial equation. As we are providing two columns of data, we do
    not need to reshape the input data as it will be provided as an N x 2 array by
    default. The target y value remains the same:'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据拟合到模型中。这次，我们需要提供两组值作为模型的输入，Year和Year2，相当于将x和x2传递给多项式方程。由于我们提供了两列数据，因此不需要重塑输入数据，它将默认作为一个N
    x 2的数组提供。目标y值保持不变：
- en: construct the model and inspect results
  id: totrans-613
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建模型并检查结果
- en: linear_model = LinearRegression(fit_intercept = True)
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: linear_model = LinearRegression(fit_intercept = True)
- en: linear_model.fit(df_group_year.loc[:, ['Year', 'Year2']], \
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: linear_model.fit(df_group_year.loc[:, ['Year', 'Year2']], \
- en: df_group_year.AvTemp)
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year.AvTemp)
- en: print('model coefficients = ', linear_model.coef_)
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: print('模型系数 = ', linear_model.coef_)
- en: print('model intercept = ', linear_model.intercept_)
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: print('模型截距 = ', linear_model.intercept_)
- en: r2 = linear_model.score(df_group_year.loc[:, ['Year', 'Year2']], \
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: r2 = linear_model.score(df_group_year.loc[:, ['Year', 'Year2']], \
- en: df_group_year.AvTemp)
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year.AvTemp)
- en: print('r squared = ', r2)
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: print('r平方 = ', r2)
- en: 'The output will be as follows:'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: model coefficients = [-1.02981369e+00 2.69257683e-04]
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 模型系数 = [-1.02981369e+00 2.69257683e-04]
- en: model intercept = 1002.0087338444181
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 模型截距 = 1002.0087338444181
- en: r squared = 0.9313996496373635
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: r平方 = 0.9313996496373635
- en: 'The model has improved on the dummy variable method, but let''s visualize the
    results to see whether it is a more reasonable fit. First, generate predictions.
    Here, we take an additional step to extend the predictions out to the next 10
    years to see whether those predictions appear reasonable. In most supervised learning
    problems, the end goal is to predict values for previously unknown data. As our
    model simply uses the Year and Year2 variables, we can generate a list of year
    values and then square them as before, for the next 10 years:'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在虚拟变量方法上有所改进，但让我们通过可视化结果来看看它是否更合理。首先，生成预测结果。这里，我们额外采取一步，将预测延伸到未来10年，看看这些预测是否合理。在大多数监督学习问题中，最终目标是预测以前未知的数据值。由于我们的模型仅使用Year和Year2变量，我们可以生成一个年份值的列表，然后像之前一样平方它们，预测未来10年的温度：
- en: generate predictions for visualization
  id: totrans-627
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成可视化的预测
- en: pred_X = df_group_year.loc[:, ['Year', 'Year2']]
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: pred_X = df_group_year.loc[:, ['Year', 'Year2']]
- en: pred_Y = linear_model.predict(pred_X)
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: pred_Y = linear_model.predict(pred_X)
- en: generate predictions for the next 10 years
  id: totrans-630
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成未来10年的预测
- en: pred_X_future = pd.DataFrame(list(range(2011, 2021)))\
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: pred_X_future = pd.DataFrame(list(range(2011, 2021)))\
- en: '.rename(columns = {0 : ''Year''})'
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: '.rename(columns = {0 : ''Year''})'
- en: pred_X_future['Year2'] = pred_X_future['Year']**2
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: pred_X_future['Year2'] = pred_X_future['Year']**2
- en: pred_Y_future = linear_model.predict(pred_X_future)
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: pred_Y_future = linear_model.predict(pred_X_future)
- en: 'Now, create a visualization:'
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建一个可视化：
- en: fig = plt.figure(figsize=(10, 7))
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: fig = plt.figure(figsize=(10, 7))
- en: ax = fig.add_axes([1, 1, 1, 1]);
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: ax = fig.add_axes([1, 1, 1, 1]);
- en: Raw data
  id: totrans-638
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原始数据
- en: raw_plot_data = df
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: raw_plot_data = df
- en: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
- en: label = 'Raw Data', c = 'red', s = 1.5)
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: label = '原始数据', c = 'red', s = 1.5)
- en: Annual averages
  id: totrans-642
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 年度平均
- en: ax.scatter(df_group_year.Year, df_group_year.AvTemp, \
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(df_group_year.Year, df_group_year.AvTemp, \
- en: label = 'Annual average', c = 'k', s = 10)
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: label = '年度平均', c = 'k', s = 10)
- en: linear fit
  id: totrans-645
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性拟合
- en: ax.plot(pred_X.Year, pred_Y, c = "blue", linestyle = '-.', \
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot(pred_X.Year, pred_Y, c = "blue", linestyle = '-.', \
- en: linewidth = 4, label = 'linear fit')
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: linewidth = 4, label = '线性拟合')
- en: 'Visualize the future predictions:'
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化未来预测：
- en: ax.plot(pred_X_future.Year, pred_Y_future, c = "purple", \
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot(pred_X_future.Year, pred_Y_future, c = "purple", \
- en: linestyle = '--', linewidth = 4, \
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: linestyle = '--', linewidth = 4, \
- en: label = 'future predictions')
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: label = '未来预测')
- en: ax.set_title('Mean Air Temperature Measurements', fontsize = 16)
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_title('平均气温测量', fontsize = 16)
- en: make the ticks include the first and last years
  id: totrans-653
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使得刻度包含首尾年份
- en: tick_years = [1902] + list(range(1910, 2021, 10))
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: tick_years = [1902] + list(range(1910, 2021, 10))
- en: ax.set_xlabel('Year', fontsize = 14)
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlabel('年份', fontsize = 14)
- en: ax.set_ylabel('Temperature ($^\circ$C)', fontsize = 14)
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylabel('温度 ($^\circ$C)', fontsize = 14)
- en: ax.set_ylim(15, 21)
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylim(15, 21)
- en: ax.set_xticks(tick_years)
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xticks(tick_years)
- en: ax.tick_params(labelsize = 12)
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: ax.tick_params(labelsize = 12)
- en: ax.legend(fontsize = 12)
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: ax.legend(fontsize = 12)
- en: plt.show()
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The result is as follows:'
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 3.36: Linear regression using a second order polynomial model'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.36：使用二次多项式模型的线性回归'
- en: '](img/image-627EP11X.jpg)'
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-627EP11X.jpg)'
- en: 'Figure 3.36: Linear regression using a second order polynomial model'
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.36：使用二次多项式模型的线性回归
- en: Note
  id: totrans-666
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to https://packt.live/3fSusaR.
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考 https://packt.live/3fSusaR.
- en: You can also run this example online at https://packt.live/2BulmCd. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个例子，访问 https://packt.live/2BulmCd。你必须执行整个笔记本才能获得期望的结果。
- en: Referring to Figure 3.36, we can see the performance benefit in using the polynomial
    model, with the trendline almost following the 10-year moving average. This is
    a reasonably good fit given the amount of noise in the yearly average raw data.
    In such a case, it should not be expected that the model will fit the data perfectly.
    If our model was to perfectly fit the observed examples, there would be a very
    strong case for overfitting the data, leading to poor predictive power with unseen
    examples. As an example, imagine we fitted a 10th order polynomial to this data.The
    resulting model would wiggle up and down and might be moving up or down very steeply
    at the last data point, which would lead to poor predictions. In this case, using
    order 2, we see that the future trend seems reasonable, although that remains
    to be demonstrated.
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 参考图3.36，我们可以看到使用多项式模型的性能优势，趋势线几乎跟随10年移动平均。这是一个相对较好的拟合，因为每年平均的原始数据有一定噪声。在这种情况下，不应期望模型能够完美地拟合数据。如果我们的模型能够完美地拟合观察到的样本，那么就有很强的过拟合数据的风险，导致对未知样本的预测能力差。例如，假设我们对这些数据进行了10阶多项式拟合。结果模型会在数据点上上下波动，最后一个数据点可能会非常陡峭地上升或下降，这将导致糟糕的预测。在这种情况下，使用二阶多项式拟合，我们可以看到未来的趋势似乎是合理的，尽管这仍然需要验证。
- en: 'Activity 3.04: Feature Engineering with Linear Regression'
  id: totrans-670
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 活动 3.04：使用线性回归进行特征工程
- en: We have tried a standard linear model as well as a model including dummy variables.
    In this activity, we will create some periodic features to try and get a better
    fit for the data. Periodic features are derived from functions that repeat over
    some range of the independent variable. In Figure 3.37, we can see that the data
    at the beginning of the year is near the same values and, in between, the temperature
    increases and then decreases. This is intuitively reasonable because we know that
    in temperate climates, there is an annual temperature cycle. Thus, we might improve
    the model if we include features that are periodic on a time scale of 1 year.
    We can construct sine and cosine functions that have the desired behavior.
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试了标准线性模型以及包含虚拟变量的模型。在这项工作中，我们将创建一些周期特征，试图更好地拟合数据。周期特征源自在独立变量某个范围内重复的函数。在图3.37中，我们可以看到，年初的数据接近相同的值，而在中间，温度先升高然后降低。这在直觉上是合理的，因为我们知道在温带气候中，存在一年一度的温度周期。因此，如果我们在1年的时间尺度上包含周期性特征，可能会改进模型。我们可以构造正弦和余弦函数，其行为符合所需。
- en: 'When fitting a model with engineered periodic features, we face an additional
    challenge to determine how to line up the periodic cycle of the features to the
    actual data. You can think of this as a time offset in this case, which we don''t
    know a priori. You could also think of the offset as a hyperparameter—fitting
    the model does not give us the value so we have to find the best value in some
    other way. In the following diagram, the needed offset is Δt:'
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: 当拟合一个含有工程周期特征的模型时，我们面临一个额外的挑战，即确定如何将特征的周期循环与实际数据对齐。在这种情况下，您可以将其视为时间偏移量，这是我们事先不知道的。您也可以将偏移量视为超参数——拟合模型并不会给出这个值，因此我们必须以其他方式找到最佳值。在下图中，所需的偏移量为Δt：
- en: '![Figure 3.37: Some data exhibiting periodic behavior versus time and a candidate
    function to fit to the data'
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.37：展示随时间周期性行为的一些数据及适合数据的候选函数'
- en: '](img/image-ARY05UEQ.jpg)'
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-ARY05UEQ.jpg)'
- en: 'Figure 3.37: Some data exhibiting periodic behavior versus time and a candidate
    function to fit to the data'
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.37：展示随时间周期性行为的一些数据及适合数据的候选函数
- en: 'Fortunately, if we use sine and cosine functions for our features, there is
    a way to address this. It is a mathematical fact that any given sine function
    at a single period, such as the raw data in Figure 3.37, can be expressed as a
    linear combination of a sine and cosine function of the same period. In the next
    figure, we show a sine and cosine function, each with a period of 365 days, and
    the raw data from Figure 3.37\. We also show a linear combination of the sine
    and cosine function that matches the raw data very well. Thus, to fit a sine (or
    cosine) function to our data, we simply need to engineer two features, one as
    the sine of the time, and the other as the cosine of the time. The linear regression
    will then find the best coefficients just like any other feature. Note that this
    implies we know the period:'
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，如果我们使用正弦和余弦函数作为我们的特征，有一种方法可以解决这个问题。这是一个数学事实，即任何给定的正弦函数在单一周期内（如图3.37中的原始数据）可以表示为相同周期的正弦和余弦函数的线性组合。在下一张图中，我们展示了一个周期为365天的正弦和余弦函数以及图3.37中的原始数据。我们还展示了与原始数据非常匹配的正弦和余弦函数的线性组合。因此，要将正弦（或余弦）函数拟合到我们的数据中，我们只需设计两个特征，一个是时间的正弦值，另一个是时间的余弦值。线性回归然后将找到最佳系数，就像处理任何其他特征一样。请注意，这意味着我们知道周期是多少：
- en: '![Figure 3.38: A linear combination of a sine and cosine function will match
    a sine function shifted by an unknown time offset](img/image-ZZ6QZXDQ.jpg)'
  id: totrans-677
  prefs: []
  type: TYPE_IMG
  zh: '![图3.38：正弦和余弦函数的线性组合将匹配一个经未知时间偏移量移动的正弦函数](img/image-ZZ6QZXDQ.jpg)'
- en: 'Figure 3.38: A linear combination of a sine and cosine function will match
    a sine function shifted by an unknown time offset'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.38：正弦和余弦函数的线性组合将匹配一个经未知时间偏移量移动的正弦函数
- en: 'The last thing we need to know is how to formulate the sine and cosine functions.
    For this, we can use the NumPy methods, sin and cos. We know we want a period
    of 1 year, and our data is in days. The correct way to write a sine function with
    a 365-day period is as follows:'
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后需要知道的是如何构建正弦和余弦函数。为此，我们可以使用NumPy方法sin和cos。我们知道我们需要1年的周期，而我们的数据是按天计算的。编写一个具有365天周期的正弦函数的正确方法如下所示：
- en: '![Figure 3.39: A sine function with a period of 365 days'
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.39：周期为365天的正弦函数'
- en: '](img/image-FJVEVWL7.jpg)'
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.36：部分数据在时间上表现出周期性行为及拟合数据的候选函数'
- en: 'Figure 3.39: A sine function with a period of 365 days'
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.39：周期为365天的正弦函数
- en: 'Alternatively, in Python a sine function with a 365-day period is as follows:'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，在Python中，具有365天周期的正弦函数如下：
- en: '![Figure 3.40: A Python series with a period of 365 days'
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.40: 一个周期为365天的Python系列](img/image-3RARL1CB.jpg)'
- en: '](img/image-4MALZ9L4.jpg)'
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.41: 在线性回归模型中使用正弦和余弦特征的预期结果](img/image-4MALZ9L4.jpg)'
- en: 'Figure 3.40: A Python series with a period of 365 days'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.40：一个周期为365天的Python系列
- en: 'Now, let''s proceed with the activity to use a periodic function to fit the
    Austin temperature data. The steps to be performed are as follows:'
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续进行使用周期函数来拟合奥斯汀温度数据的活动。要执行的步骤如下：
- en: Load the packages and classes (numpy, pandas, LinearRegression, and matplotlib).
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 加载软件包和类（numpy、pandas、LinearRegression 和 matplotlib）。
- en: Perform the preprocessing as before, through to the step where the Day_of_Year
    column is created.
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 执行与之前相同的预处理，直到创建Day_of_Year列的步骤。
- en: Add a column for the sine of Day_of_Year and another for the cosine of Day_of_Year.
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: 添加一个Day_of_Year的正弦列和一个余弦列。
- en: Perform a linear regression of the average temperature versus the Day_of_Year
    and the sine and cosine features.
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 对平均温度与Day_of_Year以及正弦和余弦特征进行线性回归。
- en: Print the parameters of the model and the r2 score.
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 打印模型的参数和r2分数。
- en: Generate predictions using the new features.
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新特征生成预测。
- en: Visualize the raw data and the new model.
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化原始数据和新模型。
- en: 'The output will be as follows:'
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 3.41: Expected result using the sine and cosine features in the linear
    regression model'
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.41: 在线性回归模型中使用正弦和余弦特征的预期结果](img/image-4MALZ9L4.jpg)'
- en: '](img/image-3RARL1CB.jpg)'
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.40: 一个周期为365天的Python系列](img/image-3RARL1CB.jpg)'
- en: 'Figure 3.41: Expected result using the sine and cosine features in the linear
    regression model'
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.41：在线性回归模型中使用正弦和余弦特征的预期结果
- en: You have by now learned that we can engineer features by applying functions
    to existing features, such as polynomial functions or periodic functions. You
    have seen how to construct period functions using sine and cosine functions to
    fit an arbitrary sine or cosine function. In this case, we assumed a period of
    365 days, which is reasonable based on the annual weather cycle of temperate regions
    on Earth. In an actual business case, we may not be certain of the period, or
    there might be more than one cycle occurring at the same time (such as weekly,
    monthly, and quarterly cycles in sales). In addition, using functions such as
    polynomials and sines/cosines can easily lead to overfitting, resulting in very
    poor extrapolation.
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经了解到我们可以通过将函数应用于现有特征来工程化特征，例如多项式函数或周期函数。您已经看到如何使用正弦和余弦函数构建周期函数以适应任意正弦或余弦函数。在这种情况下，我们假设了365天的周期，这是基于地球温带地区的年度气候周期而合理的。在实际业务案例中，我们可能不确定周期，或者可能同时存在多个周期（例如销售中的每周、每月和每季度周期）。此外，使用多项式和正弦/余弦等函数很容易导致过拟合，从而导致非常差的外推。
- en: Note
  id: totrans-700
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found via this link.
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过此链接找到此活动的解决方案。
- en: In Figure 3.41, we see that the new model smoothly varies during the year, returning
    at the end of the year to a value near the beginning. Since we already knew that
    there is an overall trend during the year, this model, because it includes the
    Day_of_Year feature, shows that the temperature at the end of the year is somewhat
    higher than at the beginning. In terms of feature engineering, we could consider
    using the date (converting it to, say, an integer) and fitting the model over
    more than 1 year's worth of data to try and capture longer-term trends.
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: 在图3.41中，我们看到新模型在一年内平稳变化，并在年末返回接近年初的值。由于我们已经知道一年中存在总体趋势，这个模型因包含Day_of_Year特征，显示出年末的温度比年初略高。在特征工程方面，我们可以考虑使用日期（将其转换为整数）并在超过1年的数据上拟合模型，以捕捉长期趋势。
- en: Generic Model Training
  id: totrans-703
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通用模型训练
- en: The least squares method of constructing a linear regression model is a useful
    and accurate method of training, assuming that the dimensionality of the dataset
    is low and that the system memory is sufficiently large to be able to manage the
    dataset.
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: 构建线性回归模型的最小二乘法是一种有用且准确的训练方法，假设数据集的维度较低，并且系统内存足够大以管理数据集。
- en: In recent times, large datasets have become more readily available, with universities,
    governments, and even some companies releasing large datasets for free online;
    as such, it may be relatively easy to exceed system memory when using the least
    squares method of regression modeling. In this situation, we will need to employ
    a different method of training the algorithm, such as gradient descent, which
    is not as susceptible to high dimensionality, allows large datasets to be trained,
    and avoids the use of memory-intensive matrix operations.
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型数据集变得更加容易获取，许多大学、政府，甚至一些公司都将大型数据集免费发布到网上；因此，在使用最小二乘法回归建模时，可能会相对容易超过系统内存。在这种情况下，我们需要采用不同的训练方法，比如梯度下降，这种方法不容易受到高维度的影响，可以处理大规模数据集，并且避免使用内存密集型的矩阵运算。
- en: 'Before we look at gradient descent in a little more detail, we will revisit
    the process of training a model in a more general form, as most training methods,
    including gradient descent, adhere to this generic process. The following is an
    overview of the parameter update loop of the model training process:'
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们更详细地探讨梯度下降之前，我们将以更一般的形式回顾一下模型训练的过程，因为大多数训练方法，包括梯度下降，都是遵循这个通用过程的。以下是模型训练过程中的参数更新循环概述：
- en: '![Figure 3.42: Generic model parameter update loop'
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.42：通用模型参数更新循环'
- en: '](img/image-64VSZ15N.jpg)'
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-64VSZ15N.jpg)'
- en: 'Figure 3.42: Generic model parameter update loop'
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.42：通用模型参数更新循环
- en: The training process involves the repeated exposure of the model and its parameters
    (including hyperparameters) to a set of sample training data and passing the predicted
    values issued by the model to a specified cost or error function. The cost function
    is, with some of the hyperparameters, what determines how to calculate the updates
    in the "update parameters" block in Figure 3.42.
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程包括将模型及其参数（包括超参数）反复暴露于一组样本训练数据，并将模型预测出的值传递给指定的代价或误差函数。代价函数与某些超参数一起，决定了如何计算“更新参数”模块中的更新，如图3.42所示。
- en: The cost function is used to determine how close the model is to its target
    values and a measure of progress throughout the training process. However, the
    cost function is also used to determine the parameter updates, in combination
    with some of the hyperparameters. For example, in our linear regression case,
    the cost function is the mean squared error.
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: 代价函数用于确定模型与目标值之间的接近程度，并作为训练过程中进展的衡量标准。然而，代价函数也与一些超参数一起用于确定参数更新。例如，在我们的线性回归案例中，代价函数是均方误差。
- en: 'The least squares method, which we showed as a method to build a linear regression
    model, minimizes the MSE, hence, least squares. We can therefore update our diagram
    of the training process to the following:'
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法，我们展示为构建线性回归模型的一种方法，最小化均方误差（MSE），因此称为最小二乘法。因此，我们可以将训练过程的图示更新为以下内容：
- en: '![Figure 3.43: Generic training process'
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.43：通用训练过程'
- en: '](img/image-8U511IE7.jpg)'
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-8U511IE7.jpg)'
- en: 'Figure 3.43: Generic training process'
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.43：通用训练过程
- en: Gradient Descent
  id: totrans-716
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 梯度下降
- en: The process of gradient descent can be summarized as a means of updating the
    parameters of the model proportionally and in response to an error within the
    system, as defined by the cost function. There are a number of cost functions
    that can be selected, depending on the type of model being fitted or the problem
    being solved. We will select the simple, but effective, mean squared error cost
    function.
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降的过程可以总结为一种根据系统中的误差，通过代价函数更新模型参数的方式。可以选择多种代价函数，具体取决于拟合的模型类型或解决的问题。我们将选择简单但有效的均方误差代价函数。
- en: 'Recall that the equation of a straight line can be written as follows:'
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，直线方程可以写作如下：
- en: '![Figure 3.44: Equation of a straight line'
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.44：直线方程'
- en: '](img/image-X27Z7BC9.jpg)'
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-X27Z7BC9.jpg)'
- en: 'Figure 3.44: Equation of a straight line'
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.44：直线方程
- en: 'The following figure is a plot of the cost function, J, for ranges of values,
    β0 and β1\. The optimal set of parameters are those for which the cost function
    is a minimum, and this point is called the global minima of the cost function.
    We can then make an analogy with trying to find the lowest point in a valley while
    hiking. Intuitively, wherever we are standing, if we are not at the bottom, then
    we are on a slope, and to get to the bottom, we would head downhill. Thus, the
    slope is the gradient, and finding the minimum is gradient descent:'
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了代价函数 J 在 β0 和 β1 范围值下的图像。最优的参数集是代价函数最小的参数，这个点被称为代价函数的全局最小值。我们可以将其类比为在徒步旅行中寻找山谷中最低点的过程。直观地说，不管我们站在何处，如果不在底部，那么我们正站在斜坡上，要到达底部，就需要朝下坡走。因此，斜坡就是梯度，而找到最小值的过程就是梯度下降：
- en: '![Figure 3.45: Visual depiction of gradient descent in a simple two-parameter
    linear regression case'
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.45：简单的两参数线性回归中梯度下降的可视化表现'
- en: '](img/image-SO29HL5F.jpg)'
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-SO29HL5F.jpg)'
- en: 'Figure 3.45: Visual depiction of gradient descent in a simple two-parameter
    linear regression case'
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.45：简单的两参数线性回归中梯度下降的可视化表现
- en: As you can see in the preceding figure, on each training cycle, the parameters
    β0 and β1 are updated to move in the direction of the steepest slope (the gradient),
    and eventually, the minimum of J(β) is found.
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，在每个训练周期中，参数 β0 和 β1 会更新，以朝着最陡峭的斜坡（梯度）方向移动，最终找到 J(β) 的最小值。
- en: 'Let''s look at the gradient descent algorithm in greater detail:'
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地了解梯度下降算法：
- en: Gradient descent starts by taking an initial, random guess at the values for
    all β. Note that in some models, this step, called initialization, may be constrained
    by choosing a particular distribution from which the initial values are sampled.
    The choice of initialization may be considered a hyperparameter and can affect
    the final outcome, especially in complicated models such as artificial neural
    networks. Most methods implemented in Python have good defaults, and it is common
    to use the defaults.
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降从对所有 β 值进行初始随机猜测开始。注意，在某些模型中，这一步骤，称为初始化，可能会通过选择某个特定的分布来约束初始值的采样。初始化的选择可以被视为一个超参数，并且可能会影响最终结果，尤其是在像人工神经网络这样的复杂模型中。大多数
    Python 实现的方法都有很好的默认值，使用默认值是很常见的做法。
- en: A prediction for each of the samples in the training set is made using the random
    values for β, and the cost function J(β) is then computed.
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 β 的随机值为训练集中的每个样本做出预测，然后计算代价函数 J(β)。
- en: The values for β are then updated, making a small adjustment proportional to
    the error, in an attempt to minimize the error. In general, it is not the best
    approach to try to move all the way from the current β values to the values that
    would minimize J(β) because the loss surface may not be smooth as shown in Figure
    3.45\. Most real loss surfaces, even in three dimensions, have multiple peaks
    and valleys. For more complicated cost function surfaces, there are multiple minima,
    called local minima, and the lowest of all the minima is the global minima. Non-convex
    cost functions may present challenges in finding the global minima, and a lot
    of effort in the research community has been devoted to finding ways to efficiently
    find the global minima of non-convex surfaces. The hyperparameter learning rate,
    denoted by γ, is used to adjust the step size on each pass of the training.
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，β 值会被更新，进行一个与误差成比例的小调整，以尽量减少误差。通常，尝试直接从当前 β 值跳到能够最小化 J(β) 的值并不是最好的方法，因为如图
    3.45 所示，损失面可能并不平滑。大多数实际的损失面，即使在三维空间中，也有多个峰值和谷值。对于更复杂的代价函数面，存在多个最小值，称为局部最小值，所有最小值中的最低点就是全局最小值。非凸代价函数可能会在找到全局最小值时带来挑战，研究界在高效寻找非凸表面全局最小值方面投入了大量努力。超参数学习率，用
    γ 表示，用于在每次训练时调整步长。
- en: 'This process is visualized in the following graph, simplified to two dimensions:'
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程在以下图表中进行了可视化，简化为二维：
- en: '![Figure 3.46: Gradient descent process'
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.46：梯度下降过程'
- en: '](img/image-LQZKETFG.jpg)'
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-LQZKETFG.jpg)'
- en: 'Figure 3.46: Gradient descent process'
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.46：梯度下降过程
- en: In this simplified case, using a low learning rate leads to Path A, and we get
    stuck in a local minimum. Path C results from a very high learning rate and does
    not converge. Path B uses an intermediate learning rate value and converges to
    the global minimum.
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简化的情况下，使用较低的学习率导致路径 A，并且我们陷入局部最小值。路径 C 是由于非常高的学习率而不收敛。路径 B 使用中间的学习率值，并收敛到全局最小值。
- en: As a general hint for setting the learning rate, start larger, say around 0.1,
    and if a solution cannot be found, that is, the error is an NaN or is varying
    wildly, reduce the learning rate by a factor of 10\. Once a learning rate is found
    that allows a relatively smooth decrease of the cost function versus epochs, other
    hyperparameters, including the learning rate, can be tested to achieve the best
    results.
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 作为设置学习率的一般提示，开始较大，例如约为 0.1，如果找不到解决方案，即错误为 NaN 或波动剧烈，则将学习率降低为 10 的因子。一旦找到允许误差随着
    epoch 相对平稳下降的学习率，可以测试其他超参数，包括学习率，以达到最佳结果。
- en: 'While this process may sound complicated, it isn''t anywhere near as scary
    as it looks. Gradient descent can be summarized by making a one-time-only guess
    at the values for the parameters, calculating the error in the guess, making small
    adjustments to the parameters, and continually repeating the process until the
    error converges at a minimum value. To reinforce our understanding, let''s look
    at a more concrete example. We will use gradient descent to train the original
    linear regression model we constructed in Exercise 3.02: Fitting a Linear Model
    Using the Least Squares Method, replacing the least squares method with gradient
    descent.'
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个过程听起来复杂，但实际上并不像看起来那么可怕。梯度下降可以通过一次性猜测参数值、计算猜测误差、对参数进行微小调整并持续重复此过程直到误差在最小值处收敛来概括。为了加强我们的理解，让我们看一个更具体的例子。我们将使用梯度下降来训练我们在练习
    3.02 中构建的原始线性回归模型：使用最小二乘法拟合线性模型，将最小二乘法替换为梯度下降。
- en: 'Exercise 3.05: Linear Regression with Gradient Descent'
  id: totrans-738
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习 3.05：使用梯度下降进行线性回归
- en: 'In this exercise, we will implement a gradient descent algorithm manually.
    We will start with the synth_temp.csv data, as before:'
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将手动实现梯度下降算法。我们将使用如前所述的 synth_temp.csv 数据：
- en: 'Import the packages and classes as before:'
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样导入包和类：
- en: import pandas as pd
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: import pandas as pd
- en: import numpy as np
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: import matplotlib.pyplot as plt
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: import matplotlib.pyplot as plt
- en: from sklearn.metrics import r2_score
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.metrics import r2_score
- en: Before we can start the gradient descent process, we need to implement some
    key functions.
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始梯度下降过程之前，我们需要实现一些关键函数。
- en: 'Write a function to define our linear model. This is where the advantage of
    using the shortened form of the linear model comes in handy. We can use linear
    algebra multiplication between the parameters (β) and the input values, x:'
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个函数来定义我们的线性模型。这里使用线性代数乘法将参数（β）和输入值 x 之间的乘积形式，这是使用简化形式的线性模型的优势所在。
- en: model function
  id: totrans-747
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型函数
- en: 'def h_x(Beta, X):'
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: 'def h_x(Beta, X):'
- en: calculate the matrix dot product of X and the Betas
  id: totrans-749
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算 X 和 Betas 的矩阵点积
- en: return np.dot(Beta, X).flatten()
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: 返回 np.dot(Beta, X).flatten()
- en: 'We also need to write a function to evaluate the cost function, J(β):'
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要编写一个评估成本函数 J(β) 的函数：
- en: cost function
  id: totrans-752
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成本函数
- en: 'def J_beta(pred, true):'
  id: totrans-753
  prefs: []
  type: TYPE_NORMAL
  zh: 'def J_beta(pred, true):'
- en: mean squared error
  id: totrans-754
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 均方误差
- en: return np.mean((pred - true) ** 2)
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
  zh: return np.mean((pred - true) ** 2)
- en: 'Finally, we need to implement the function to update the parameters:'
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要实现更新参数的函数：
- en: update function
  id: totrans-757
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新函数
- en: 'def update(pred, true, X, gamma):'
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: 'def update(pred, true, X, gamma):'
- en: return gamma * np.sum((true - pred) * X, axis = 1)
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: 返回 gamma * np.sum((true - pred) * X, axis = 1)
- en: 'Next, load the data, slicing from 1902 forward, computing the annual averages,
    and adding the Year column:'
  id: totrans-760
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，加载数据，从 1902 年起切片，计算年均值，并添加年份列：
- en: load the data
  id: totrans-761
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 载入数据
- en: df = pd.read_csv('../Datasets/synth_temp.csv')
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
  zh: df = pd.read_csv('../Datasets/synth_temp.csv')
- en: slice 1902 and forward
  id: totrans-763
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 切片 1902 年及以后
- en: df = df.loc[df.Year > 1901]
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: df = df.loc[df.Year > 1901]
- en: roll up by year
  id: totrans-765
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按年份卷起
- en: 'df_group_year = df.groupby([''Year'']).agg({''RgnAvTemp'' : ''mean''})'
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
  zh: 'df_group_year = df.groupby([''Year'']).agg({''RgnAvTemp'' : ''mean''})'
- en: add the Year column so we can use that in a model
  id: totrans-767
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加年份列以便在模型中使用
- en: df_group_year['Year'] = df_group_year.index
  id: totrans-768
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year['Year'] = df_group_year.index
- en: df_group_year = \
  id: totrans-769
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year = \
- en: 'df_group_year.rename(columns = {''RgnAvTemp'' : ''AvTemp''})'
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
  zh: 'df_group_year.rename(columns = {''RgnAvTemp'' : ''AvTemp''})'
- en: Now, we will build the training data. First, we need to scale the data to between
    0 and 1 before using gradient descent. Some machine learning algorithms can work
    well with raw data (such as regular linear regression), but when using gradient
    descent, if the variables have very different scales, then the gradient values
    will be much larger in the axes of some of the parameters than others. Left unscaled,
    the data in raw form could distort the descent along the cost function surface,
    skewing the results. Intuitively, in our case, the Year data is in the order of
    thousands, while the AvTemp data is in the order of tens. Thus, the Year variable
    would dominate in terms of its influence on the parameters.
  id: totrans-771
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将构建训练数据。首先，我们需要在使用梯度下降之前，将数据缩放到 0 到 1 之间。某些机器学习算法可以处理原始数据（如常规线性回归），但在使用梯度下降时，如果变量的尺度差异很大，那么某些参数的梯度值将远大于其他参数的梯度值。如果数据没有缩放，原始数据可能会扭曲成本函数表面上的下降，从而偏移结果。直观地讲，在我们的例子中，Year
    数据的量级是千，而 AvTemp 数据的量级是十。因此，Year 变量会在参数的影响力上占主导地位。
- en: 'There are a variety of scaling methods used in machine learning. Examples are
    normalization to a specific range (such as (0, 1) or (-1, 1)), and standardization
    (where the data is scaled to a mean of 0 and standard deviation of 1). Here, we
    will normalize both the x and y data to the range (0, 1):'
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中使用了多种缩放方法。例如，将数据归一化到特定范围（如（0, 1）或（-1, 1）），以及标准化（将数据缩放到均值为 0，标准差为 1）。在这里，我们将
    x 和 y 数据归一化到范围（0, 1）：
- en: scale the data and add the X0 series
  id: totrans-773
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对数据进行缩放并添加 X0 序列
- en: X_min = df_group_year.Year.min()
  id: totrans-774
  prefs: []
  type: TYPE_NORMAL
  zh: X_min = df_group_year.Year.min()
- en: X_range = df_group_year.Year.max() - df_group_year.Year.min()
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: X_range = df_group_year.Year.max() - df_group_year.Year.min()
- en: Y_min = df_group_year.AvTemp.min()
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: Y_min = df_group_year.AvTemp.min()
- en: Y_range = df_group_year.AvTemp.max() - df_group_year.AvTemp.min()
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: Y_range = df_group_year.AvTemp.max() - df_group_year.AvTemp.min()
- en: scale_X = (df_group_year.Year - X_min) / X_range
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: scale_X = (df_group_year.Year - X_min) / X_range
- en: 'train_X = pd.DataFrame({''X0'' : np.ones(df_group_year.shape[0]), \'
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: 'train_X = pd.DataFrame({''X0'' : np.ones(df_group_year.shape[0]), \'
- en: '''X1'' : scale_X}).transpose()'
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: '''X1'' : scale_X}).transpose()'
- en: train_Y = (df_group_year.AvTemp - Y_min) / Y_range
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: train_Y = (df_group_year.AvTemp - Y_min) / Y_range
- en: print(train_X.iloc[:, :5])
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: print(train_X.iloc[:, :5])
- en: print(train_Y[:5])
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
  zh: print(train_Y[:5])
- en: 'The output should appear as follows:'
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 3.47: Normalized data for gradient descent'
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.47：用于梯度下降的归一化数据'
- en: '](img/image-EROBZLC5.jpg)'
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-EROBZLC5.jpg)'
- en: 'Figure 3.47: Normalized data for gradient descent'
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.47：用于梯度下降的归一化数据
- en: Note that the train_Y values are the true values, also called ground truth.
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，train_Y 的值是真实值，也称为真实标签（ground truth）。
- en: 'As we have learned, we need to initialize the parameter values. Note that we
    use the NumPy random.seed() method with a constant value. Setting random.seed
    will reproduce the same results every time you run the notebook. This is useful
    during model development and while exploring hyperparameters so that you can see
    the impact of changes you make versus the impact of the random initialization.
    The reshape() method is used to put the data into the correct matrix form:'
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所学，我们需要初始化参数值。请注意，我们使用带有常数值的 NumPy `random.seed()` 方法。设置 `random.seed` 将在每次运行笔记本时重现相同的结果。在模型开发过程中以及探索超参数时，这非常有用，因为你可以看到所做更改的影响，而不是随机初始化的影响。`reshape()`
    方法用于将数据转化为正确的矩阵形式：
- en: initialize Beta and the learning rate gamma
  id: totrans-790
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始化 Beta 和学习率 gamma
- en: np.random.seed(42)
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
  zh: np.random.seed(42)
- en: Beta = np.random.randn(2).reshape((1, 2)) * 0.1
  id: totrans-792
  prefs: []
  type: TYPE_NORMAL
  zh: Beta = np.random.randn(2).reshape((1, 2)) * 0.1
- en: print('initial Beta\n', Beta)
  id: totrans-793
  prefs: []
  type: TYPE_NORMAL
  zh: print('初始 Beta\n', Beta)
- en: 'The values should look something like the following:'
  id: totrans-794
  prefs: []
  type: TYPE_NORMAL
  zh: 值应如下所示：
- en: initial Beta [[ 0.04967142 -0.01382643]]
  id: totrans-795
  prefs: []
  type: TYPE_NORMAL
  zh: 初始 Beta [[ 0.04967142 -0.01382643]]
- en: 'We also need to set a couple of hyperparameters, the learning rate, gamma,
    and the maximum number of times that we will go through the training cycle (epochs):'
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要设置一些超参数，包括学习率 gamma 和训练周期的最大次数（epochs）：
- en: gamma = 0.0005
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: gamma = 0.0005
- en: max_epochs = 100
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: max_epochs = 100
- en: 'Make an initial prediction and calculate the error or cost in that prediction
    using the defined h_x and J_beta functions:'
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: 做出初步预测并使用定义的 h_x 和 J_beta 函数计算该预测的误差或成本：
- en: y_pred = h_x(Beta, train_X)
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: y_pred = h_x(Beta, train_X)
- en: print('Initial cost J(Beta) = ' + str(J_beta(y_pred, train_Y)))
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
  zh: print('初始成本 J(Beta) = ' + str(J_beta(y_pred, train_Y)))
- en: 'The output will be as follows:'
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: Initial cost J(Beta) = 0.18849128813354338
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
  zh: 初始成本 J(Beta) = 0.18849128813354338
- en: 'We are now ready to use a loop to iterate through the training. Here, we are
    storing the epoch and cost values so that we can visualize them later. Also, we
    are printing out the cost function and epoch every 10 epochs:'
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备使用循环来迭代训练过程。在这里，我们存储了epoch和cost值，以便稍后进行可视化。同时，我们每10个epoch输出一次成本函数和epoch的值：
- en: epochs = []
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
  zh: epochs = []
- en: costs = []
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
  zh: costs = []
- en: 'for epoch in range(max_epochs):'
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
  zh: 'for epoch in range(max_epochs):'
- en: Beta += update(y_pred, train_Y, train_X, gamma)
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
  zh: Beta += update(y_pred, train_Y, train_X, gamma)
- en: y_pred = h_x(Beta, train_X)
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: y_pred = h_x(Beta, train_X)
- en: cost = J_beta(y_pred, train_Y)
  id: totrans-810
  prefs: []
  type: TYPE_NORMAL
  zh: cost = J_beta(y_pred, train_Y)
- en: 'if epoch % 10 == 0:'
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: 'if epoch % 10 == 0:'
- en: print('New cost J(Beta) = ' + str(round(cost, 3)) \
  id: totrans-812
  prefs: []
  type: TYPE_NORMAL
  zh: print('新成本 J(Beta) = ' + str(round(cost, 3)) \
- en: + ' at epoch ' + str(epoch))
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
  zh: + ' 在第 ' + str(epoch) + ' 轮')
- en: epochs.append(epoch)
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
  zh: epochs.append(epoch)
- en: costs.append(cost)
  id: totrans-815
  prefs: []
  type: TYPE_NORMAL
  zh: costs.append(cost)
- en: 'The output will be as follows:'
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.48: Training results every 10 epochs'
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.48：每10个epoch的训练结果'
- en: '](img/image-W414240J.jpg)'
  id: totrans-818
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-W414240J.jpg)'
- en: 'Figure 3.48: Training results every 10 epochs'
  id: totrans-819
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.48：每10个epoch的训练结果
- en: Observe in Figure 3.48 the relatively rapid decrease in the cost function in
    the first 20 cycles, before the improvement slows down. This is a very typical
    pattern for gradient descent training when the learning rate is at a reasonable
    value.
  id: totrans-820
  prefs: []
  type: TYPE_NORMAL
  zh: 在图3.48中观察到，成本函数在前20个周期内快速下降，然后改进速度放缓。这是梯度下降训练中的典型模式，尤其是当学习率处于合理值时。
- en: 'Visualize the training history:'
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化训练历史：
- en: plot training history
  id: totrans-822
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制训练历史
- en: fig = plt.figure(figsize=(10, 7))
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: fig = plt.figure(figsize=(10, 7))
- en: ax = fig.add_axes([1, 1, 1, 1])
  id: totrans-824
  prefs: []
  type: TYPE_NORMAL
  zh: ax = fig.add_axes([1, 1, 1, 1])
- en: ax.plot(epochs, costs)
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot(epochs, costs)
- en: ax.tick_params(labelsize = 14)
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
  zh: ax.tick_params(labelsize = 14)
- en: ax.set_ylabel('Cost Function J(' + r'$\theta$' + ')', \
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylabel('成本函数 J(' + r'$\theta$' + ')', \
- en: fontsize = 18)
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: fontsize = 18)
- en: ax.set_xlabel('Epoch', fontsize = 18)
  id: totrans-829
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlabel('Epoch', fontsize = 18)
- en: plt.show()
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The output will be as follows:'
  id: totrans-831
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.49: Plot of the cost function versus epoch for the first 100 epochs'
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.49：成本函数与epoch的关系图（前100个epoch）'
- en: '](img/image-YH54C9TH.jpg)'
  id: totrans-833
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-YH54C9TH.jpg)'
- en: 'Figure 3.49: Plot of the cost function versus epoch for the first 100 epochs'
  id: totrans-834
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.49：成本函数与epoch的关系图（前100个epoch）
- en: In Figure 3.49, we can see that the cost function was still decreasing when
    we stopped the updates. Thus, we could rerun the training with a larger max_epochs
    hyperparameter and see whether the results improved.
  id: totrans-835
  prefs: []
  type: TYPE_NORMAL
  zh: 在图3.49中，我们可以看到，当我们停止更新时，成本函数仍在下降。因此，我们可以通过增大max_epochs超参数重新运行训练，看看结果是否有所改善。
- en: 'Use the r2_score function from sklearn.metrics, which we imported earlier,
    to compute the R-squared score for the model trained using gradient descent:'
  id: totrans-836
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们之前导入的sklearn.metrics中的r2_score函数，计算使用梯度下降训练的模型的R平方值：
- en: calculate the r squared value
  id: totrans-837
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算r平方值
- en: r2 = r2_score(train_Y, y_pred)
  id: totrans-838
  prefs: []
  type: TYPE_NORMAL
  zh: r2 = r2_score(train_Y, y_pred)
- en: print('r squared = ', r2)
  id: totrans-839
  prefs: []
  type: TYPE_NORMAL
  zh: print('r squared = ', r2)
- en: 'The output should be similar to the following:'
  id: totrans-840
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应与以下内容类似：
- en: r squared = 0.5488427996385263
  id: totrans-841
  prefs: []
  type: TYPE_NORMAL
  zh: r squared = 0.5488427996385263
- en: Note that you could vary the learning rate and max epochs parameters to see
    the impact on the training history and the r2 value.
  id: totrans-842
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，您可以调整学习率和最大epoch参数，观察它们对训练历史和r2值的影响。
- en: 'Now, we generate predictions using the training data so that we can visualize
    the resulting model. In this cell, we first predict using the scaled training
    data since the model coefficients are based on the scaled inputs, and then we
    scale the results back to "real" values using the (Y_min and Y_range) values we
    saved earlier in the scaling process. Note the use of our model function, h_x,
    to generate the predictions. Also, for convenience, we replace pred_X with the
    original year values for use in visualization:'
  id: totrans-843
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用训练数据生成预测值，以便可视化结果模型。在这个单元格中，我们首先使用缩放后的训练数据进行预测，因为模型系数是基于缩放输入的，然后使用我们在缩放过程中保存的(Y_min和Y_range)值将结果还原为“实际”值。请注意，我们使用我们的模型函数h_x来生成预测值。另外，为了方便起见，我们将pred_X替换为原始年份值，用于可视化：
- en: generate predictions for visualization
  id: totrans-844
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成预测以便可视化
- en: pred_X = train_X
  id: totrans-845
  prefs: []
  type: TYPE_NORMAL
  zh: pred_X = train_X
- en: make predictions
  id: totrans-846
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进行预测
- en: pred_Y = h_x(Beta, pred_X)
  id: totrans-847
  prefs: []
  type: TYPE_NORMAL
  zh: pred_Y = h_x(Beta, pred_X)
- en: scale predictions back to real values
  id: totrans-848
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将预测值还原为实际值
- en: pred_Y = (pred_Y * Y_range) + Y_min
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
  zh: pred_Y = (pred_Y * Y_range) + Y_min
- en: replace the X with the original values
  id: totrans-850
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 替换X为原始值
- en: pred_X = df_group_year['Year']
  id: totrans-851
  prefs: []
  type: TYPE_NORMAL
  zh: pred_X = df_group_year['Year']
- en: 'One impact of doing the regression with scaled data is that the β values are
    relative to the scaled data, not the original data. In many cases, we would like
    to obtain the unscaled parameter values. In particular, in linear regression,
    the unscaled coefficients are interpretable as the unit change in the dependent
    variable for a unit change in the variable associated with the parameter. Specifically,
    in our case here, β1 is the "slope" of the line and represents the change in average
    annual temperature for a change of 1 year. We can now calculate the parameters
    of the unscaled model:'
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
  zh: 使用缩放数据进行回归的一个影响是，β 值是相对于缩放后的数据，而不是原始数据。在许多情况下，我们希望得到未缩放的参数值。特别是在线性回归中，未缩放的系数可以解释为自变量每单位变化时因变量的变化。例如，在我们的案例中，β1
    是直线的“斜率”，表示每增加 1 年，平均年气温的变化。我们现在可以计算未缩放模型的参数：
- en: scale the coefficients back to real values
  id: totrans-853
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将系数缩放回实际值
- en: Beta0 = (Y_min + Y_range * Beta[0, 0] \
  id: totrans-854
  prefs: []
  type: TYPE_NORMAL
  zh: Beta0 = (Y_min + Y_range * Beta[0, 0] \
- en: '- Y_range * Beta[0, 1] * X_min / X_range)'
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
  zh: '- Y_range * Beta[0, 1] * X_min / X_range)'
- en: Beta1 = Y_range * Beta[0, 1] / X_range
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
  zh: Beta1 = Y_range * Beta[0, 1] / X_range
- en: 'Visualize the results:'
  id: totrans-857
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化结果：
- en: fig = plt.figure(figsize=(10, 7))
  id: totrans-858
  prefs: []
  type: TYPE_NORMAL
  zh: fig = plt.figure(figsize=(10, 7))
- en: ax = fig.add_axes([1, 1, 1, 1])
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
  zh: ax = fig.add_axes([1, 1, 1, 1])
- en: Raw data
  id: totrans-860
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原始数据
- en: raw_plot_data = df
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: raw_plot_data = df
- en: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
  id: totrans-862
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
- en: label = 'Raw Data', c = 'red', s = 1.5)
  id: totrans-863
  prefs: []
  type: TYPE_NORMAL
  zh: label = '原始数据', c = 'red', s = 1.5)
- en: Annual averages
  id: totrans-864
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 年度平均
- en: ax.scatter(df_group_year.Year, df_group_year.AvTemp, \
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(df_group_year.Year, df_group_year.AvTemp, \
- en: label = 'Annual average', c = 'k', s = 10)
  id: totrans-866
  prefs: []
  type: TYPE_NORMAL
  zh: label = '年度平均', c = 'k', s = 10)
- en: linear fit
  id: totrans-867
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性拟合
- en: ax.plot(pred_X, pred_Y, c = "blue", linestyle = '-.', \
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot(pred_X, pred_Y, c = "blue", linestyle = '-.', \
- en: linewidth = 4, label = 'linear fit')
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: linewidth = 4, label = '线性拟合')
- en: 'Put the model on the plot:'
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型绘制到图表上：
- en: ax.text(1902, 20, 'Temp = ' + str(round(Beta0, 2)) \
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
  zh: ax.text(1902, 20, 'Temp = ' + str(round(Beta0, 2)) \
- en: +' + ' + str(round(Beta1, 4)) + ' * Year', \
  id: totrans-872
  prefs: []
  type: TYPE_NORMAL
  zh: +' + ' + str(round(Beta1, 4)) + ' * Year', \
- en: fontsize = 16, backgroundcolor = 'white')
  id: totrans-873
  prefs: []
  type: TYPE_NORMAL
  zh: fontsize = 16, backgroundcolor = 'white')
- en: ax.set_title('Mean Air Temperature Measurements', fontsize = 16)
  id: totrans-874
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_title('平均气温测量', fontsize = 16)
- en: make the ticks include the first and last years
  id: totrans-875
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使刻度包含第一个和最后一个年份
- en: tick_years = [1902] + list(range(1910, 2011, 10))
  id: totrans-876
  prefs: []
  type: TYPE_NORMAL
  zh: tick_years = [1902] + list(range(1910, 2011, 10))
- en: ax.set_xlabel('Year', fontsize = 14)
  id: totrans-877
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlabel('年份', fontsize = 14)
- en: ax.set_ylabel('Temperature ($^\circ$C)', fontsize = 14)
  id: totrans-878
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylabel('温度 ($^\circ$C)', fontsize = 14)
- en: ax.set_ylim(15, 21)
  id: totrans-879
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylim(15, 21)
- en: ax.set_xticks(tick_years)
  id: totrans-880
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xticks(tick_years)
- en: ax.tick_params(labelsize = 12)
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
  zh: ax.tick_params(labelsize = 12)
- en: ax.legend(fontsize = 12)
  id: totrans-882
  prefs: []
  type: TYPE_NORMAL
  zh: ax.legend(fontsize = 12)
- en: plt.show()
  id: totrans-883
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: Note
  id: totrans-884
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: For error-free execution, you should run the cell only after writing the code
    for both steps 15 and 16.
  id: totrans-885
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保无错误执行，你应该在编写完步骤 15 和 16 的代码后再运行该单元。
- en: 'The output will be as follows:'
  id: totrans-886
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.50: Mean air temperature measurements using gradient descent'
  id: totrans-887
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.50：使用梯度下降法测量的平均气温'
- en: '](img/image-PLI7QRI3.jpg)'
  id: totrans-888
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-PLI7QRI3.jpg)'
- en: 'Figure 3.50: Mean air temperature measurements using gradient descent'
  id: totrans-889
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.50：使用梯度下降法测量的平均气温
- en: Note
  id: totrans-890
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to https://packt.live/3diOR76.
  id: totrans-891
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该特定部分的源代码，请参考 https://packt.live/3diOR76。
- en: You can also run this example online at https://packt.live/2YWvviZ. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在 https://packt.live/2YWvviZ 在线运行这个例子。你必须执行整个笔记本，才能得到期望的结果。
- en: 'You have just trained your first model with gradient descent. This is an important
    step as this simple tool can be used to construct more complicated models such
    as logistic regression and neural network models. We must first, however, note
    one important observation: the r-squared value produced by the gradient descent
    model is not as high as the least squares model, and the equation of the line
    is different.'
  id: totrans-893
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚用梯度下降法训练了你的第一个模型。这是一个重要的步骤，因为这个简单的工具可以用来构建更复杂的模型，如逻辑回归和神经网络模型。然而，我们首先必须注意一个重要的观察：梯度下降模型产生的
    r-squared 值不如最小二乘法模型高，而且线的方程也不同。
- en: That being said, there are many more options available to modify the gradient
    descent process, including different types of gradient descent algorithms and
    more advanced uses of learning rate and the way the data is supplied during training.
    These modifications fall outside the scope of this book, as an entire book could
    be written on the gradient descent process and methods for improving performance.
    With enough experimentation, we would be able to match the two results to any
    arbitrary level of precision, but in this case, that would not be an effective
    use of time.
  id: totrans-894
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，梯度下降过程还有更多的选项可以调整，包括不同类型的梯度下降算法、更高级的学习率使用方法以及在训练过程中如何提供数据。这些修改超出了本书的范围，因为一本书可以专门讨论梯度下降过程及其性能优化方法。通过足够的实验，我们可以将两个结果匹配到任意精度，但在本案例中，这样做并不是高效的时间利用。
- en: 'In this exercise, we implemented gradient descent directly; however, we would
    not typically use this implementation, but instead leverage an existing, highly
    optimized package. The scikit-learn method of gradient descent contains a number
    of optimizations and can be used in only a few lines of code. The following is
    from the scikit-learn documentation (refer to https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html):
    "SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated
    each sample at a time and the model is updated along the way with a decreasing
    strength schedule (aka learning rate)."'
  id: totrans-895
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们直接实现了梯度下降；然而，我们通常不会使用这种实现，而是利用现有的高效优化包。scikit-learn 的梯度下降方法包含了许多优化，并且只需几行代码即可使用。以下内容来自
    scikit-learn 文档（参考 https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html）：“SGD
    代表随机梯度下降：每次估计一个样本的损失梯度，模型会在过程中按递减强度（即学习率）更新。”
- en: In our examples so far, we have used all the data directly in the linear regression
    method or used all the data for every update in our implementation by means of
    gradient descent. However, with gradient descent, we have total control over when
    to update our estimates of the parameters.
  id: totrans-896
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在我们的示例中，我们直接使用了所有数据进行线性回归方法，或者通过梯度下降方法在每次更新时使用所有数据。然而，使用梯度下降时，我们可以完全控制何时更新我们对参数的估计。
- en: 'Exercise 3.06: Optimizing Gradient Descent'
  id: totrans-897
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习 3.06：优化梯度下降
- en: In this exercise, we will use the scikit-learn module SGDRegressor, which utilizes
    stochastic gradient descent to train models.
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用 scikit-learn 模块中的 SGDRegressor，它利用随机梯度下降来训练模型。
- en: 'In this exercise, we start with the synth_temp.csv data, as before:'
  id: totrans-899
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们从 synth_temp.csv 数据开始，和之前一样：
- en: 'Import the packages and classes as before, adding SGDRegressor:'
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
  zh: 如之前一样导入所需的包和类，并添加 SGDRegressor：
- en: import pandas as pd
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: import pandas as pd
- en: import numpy as np
  id: totrans-902
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: import matplotlib.pyplot as plt
  id: totrans-903
  prefs: []
  type: TYPE_NORMAL
  zh: import matplotlib.pyplot as plt
- en: from sklearn.metrics import r2_score
  id: totrans-904
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 sklearn.metrics 导入 r2_score
- en: from sklearn.linear_model import SGDRegressor
  id: totrans-905
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 sklearn.linear_model 导入 SGDRegressor
- en: 'Load the data and carry out the same preprocessing and scaling as before:'
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据并进行与之前相同的预处理和标准化：
- en: load the data
  id: totrans-907
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据
- en: df = pd.read_csv('../Datasets/synth_temp.csv')
  id: totrans-908
  prefs: []
  type: TYPE_NORMAL
  zh: df = pd.read_csv('../Datasets/synth_temp.csv')
- en: slice 1902 and forward
  id: totrans-909
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 1902 年开始切片
- en: df = df.loc[df.Year > 1901]
  id: totrans-910
  prefs: []
  type: TYPE_NORMAL
  zh: df = df.loc[df.Year > 1901]
- en: roll up by year
  id: totrans-911
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按年份汇总
- en: 'df_group_year = df.groupby([''Year'']).agg({''RgnAvTemp'' : ''mean''})'
  id: totrans-912
  prefs: []
  type: TYPE_NORMAL
  zh: 'df_group_year = df.groupby([''Year'']).agg({''RgnAvTemp'' : ''mean''})'
- en: add the Year column so we can use that in a model
  id: totrans-913
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加 Year 列，以便在模型中使用该列
- en: df_group_year['Year'] = df_group_year.index
  id: totrans-914
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year['Year'] = df_group_year.index
- en: df_group_year = df_group_year\
  id: totrans-915
  prefs: []
  type: TYPE_NORMAL
  zh: df_group_year = df_group_year\
- en: '.rename(columns = {''RgnAvTemp'' : ''AvTemp''})'
  id: totrans-916
  prefs: []
  type: TYPE_NORMAL
  zh: '.rename(columns = {''RgnAvTemp'' : ''AvTemp''})'
- en: scale the data
  id: totrans-917
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准化数据
- en: X_min = df_group_year.Year.min()
  id: totrans-918
  prefs: []
  type: TYPE_NORMAL
  zh: X_min = df_group_year.Year.min()
- en: X_range = df_group_year.Year.max() - df_group_year.Year.min()
  id: totrans-919
  prefs: []
  type: TYPE_NORMAL
  zh: X_range = df_group_year.Year.max() - df_group_year.Year.min()
- en: Y_min = df_group_year.AvTemp.min()
  id: totrans-920
  prefs: []
  type: TYPE_NORMAL
  zh: Y_min = df_group_year.AvTemp.min()
- en: Y_range = df_group_year.AvTemp.max() - df_group_year.AvTemp.min()
  id: totrans-921
  prefs: []
  type: TYPE_NORMAL
  zh: Y_range = df_group_year.AvTemp.max() - df_group_year.AvTemp.min()
- en: scale_X = (df_group_year.Year - X_min) / X_range
  id: totrans-922
  prefs: []
  type: TYPE_NORMAL
  zh: scale_X = (df_group_year.Year - X_min) / X_range
- en: train_X = scale_X.ravel()
  id: totrans-923
  prefs: []
  type: TYPE_NORMAL
  zh: train_X = scale_X.ravel()
- en: train_Y = ((df_group_year.AvTemp - Y_min) / Y_range).ravel()
  id: totrans-924
  prefs: []
  type: TYPE_NORMAL
  zh: train_Y = ((df_group_year.AvTemp - Y_min) / Y_range).ravel()
- en: 'We instantiate the model by calling SGDRegressor, and pass the hyperparameters.
    Here, we set the NumPy random.seed method and, as we are not passing a seed or
    method to SGDRegressor, it uses the NumPy random generator:'
  id: totrans-925
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过调用 SGDRegressor 来实例化模型，并传递超参数。在这里，我们设置了 NumPy random.seed 方法，且由于我们没有为 SGDRegressor
    提供种子或方法，它将使用 NumPy 随机生成器：
- en: create the model object
  id: totrans-926
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建模型对象
- en: np.random.seed(42)
  id: totrans-927
  prefs: []
  type: TYPE_NORMAL
  zh: np.random.seed(42)
- en: model = SGDRegressor(loss = 'squared_loss', max_iter = 100, \
  id: totrans-928
  prefs: []
  type: TYPE_NORMAL
  zh: model = SGDRegressor(loss = 'squared_loss', max_iter = 100, \
- en: learning_rate = 'constant', eta0 = 0.0005, \
  id: totrans-929
  prefs: []
  type: TYPE_NORMAL
  zh: learning_rate = 'constant', eta0 = 0.0005, \
- en: tol = 0.00009, penalty = 'none')
  id: totrans-930
  prefs: []
  type: TYPE_NORMAL
  zh: tol = 0.00009, penalty = 'none')
- en: 'We fit the model by calling the fit method of the model object:'
  id: totrans-931
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过调用模型对象的 fit 方法来拟合模型：
- en: fit the model
  id: totrans-932
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拟合模型
- en: model.fit(train_X.reshape((-1, 1)), train_Y)
  id: totrans-933
  prefs: []
  type: TYPE_NORMAL
  zh: model.fit(train_X.reshape((-1, 1)), train_Y)
- en: 'The output should be as follows, echoing the parameters used in the call:'
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示，回显调用中使用的参数：
- en: '![Figure 3.51: Output from calling the fit method on the model object'
  id: totrans-935
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.51：调用模型对象的 fit 方法后的输出'
- en: '](img/image-PDO68833.jpg)'
  id: totrans-936
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-PDO68833.jpg)'
- en: 'Figure 3.51: Output from calling the fit method on the model object'
  id: totrans-937
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.51：调用模型对象的 fit 方法后的输出
- en: 'We now want to retrieve the coefficients from the model and rescale them as
    in the previous exercise so that we can compare the results directly:'
  id: totrans-938
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在想要从模型中提取系数，并像之前的练习那样将其重新缩放，以便可以直接比较结果：
- en: Beta0 = (Y_min + Y_range * model.intercept_[0] \
  id: totrans-939
  prefs: []
  type: TYPE_NORMAL
  zh: Beta0 = (Y_min + Y_range * model.intercept_[0] \
- en: '- Y_range * model.coef_[0] * X_min / X_range)'
  id: totrans-940
  prefs: []
  type: TYPE_NORMAL
  zh: '- Y_range * model.coef_[0] * X_min / X_range)'
- en: Beta1 = Y_range * model.coef_[0] / X_range
  id: totrans-941
  prefs: []
  type: TYPE_NORMAL
  zh: Beta1 = Y_range * model.coef_[0] / X_range
- en: print(Beta0)
  id: totrans-942
  prefs: []
  type: TYPE_NORMAL
  zh: print(Beta0)
- en: print(Beta1)
  id: totrans-943
  prefs: []
  type: TYPE_NORMAL
  zh: print(Beta1)
- en: 'The output should be as follows:'
  id: totrans-944
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '-0.5798539884018439'
  id: totrans-945
  prefs: []
  type: TYPE_NORMAL
  zh: '-0.5798539884018439'
- en: '0.009587734834970016'
  id: totrans-946
  prefs: []
  type: TYPE_NORMAL
  zh: '0.009587734834970016'
- en: 'As before, we now generate predictions, and then use the r2_score function
    to calculate r2\. Note that since we are using a scikit-learn method, we use the
    predict method on the model object to return predictions:'
  id: totrans-947
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们现在生成预测结果，然后使用 r2_score 函数计算 r2。请注意，由于我们使用的是 scikit-learn 方法，我们通过模型对象的
    predict 方法来返回预测结果：
- en: generate predictions
  id: totrans-948
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成预测结果
- en: pred_X = df_group_year['Year']
  id: totrans-949
  prefs: []
  type: TYPE_NORMAL
  zh: pred_X = df_group_year['Year']
- en: pred_Y = model.predict(train_X.reshape((-1, 1)))
  id: totrans-950
  prefs: []
  type: TYPE_NORMAL
  zh: pred_Y = model.predict(train_X.reshape((-1, 1)))
- en: calculate the r squared value
  id: totrans-951
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算 r squared 值
- en: r2 = r2_score(train_Y, pred_Y)
  id: totrans-952
  prefs: []
  type: TYPE_NORMAL
  zh: r2 = r2_score(train_Y, pred_Y)
- en: print('r squared = ', r2)
  id: totrans-953
  prefs: []
  type: TYPE_NORMAL
  zh: print('r squared = ', r2)
- en: 'The result will be something similar to the following:'
  id: totrans-954
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将类似于以下内容：
- en: r squared = 0.5436475116024911
  id: totrans-955
  prefs: []
  type: TYPE_NORMAL
  zh: r squared = 0.5436475116024911
- en: 'Finally, we rescale the predictions back to actual temperatures for visualization:'
  id: totrans-956
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将预测结果重新缩放回实际温度以进行可视化：
- en: scale predictions back to real values
  id: totrans-957
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将预测结果缩放回实际值
- en: pred_Y = (pred_Y * Y_range) + Y_min
  id: totrans-958
  prefs: []
  type: TYPE_NORMAL
  zh: pred_Y = (pred_Y * Y_range) + Y_min
- en: 'Now, visualize the results:'
  id: totrans-959
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，展示结果：
- en: fig = plt.figure(figsize=(10, 7))
  id: totrans-960
  prefs: []
  type: TYPE_NORMAL
  zh: fig = plt.figure(figsize=(10, 7))
- en: ax = fig.add_axes([1, 1, 1, 1])
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
  zh: ax = fig.add_axes([1, 1, 1, 1])
- en: Raw data
  id: totrans-962
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原始数据
- en: raw_plot_data = df
  id: totrans-963
  prefs: []
  type: TYPE_NORMAL
  zh: raw_plot_data = df
- en: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
  id: totrans-964
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(raw_plot_data.Year, raw_plot_data.RgnAvTemp, \
- en: label = 'Raw Data', c = 'red', s = 1.5)
  id: totrans-965
  prefs: []
  type: TYPE_NORMAL
  zh: label = '原始数据', c = 'red', s = 1.5)
- en: Annual averages
  id: totrans-966
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 年度平均值
- en: ax.scatter(df_group_year.Year, df_group_year.AvTemp, \
  id: totrans-967
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(df_group_year.Year, df_group_year.AvTemp, \
- en: label = 'Annual average', c = 'k', s = 10)
  id: totrans-968
  prefs: []
  type: TYPE_NORMAL
  zh: label = '年度平均', c = 'k', s = 10)
- en: linear fit
  id: totrans-969
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性拟合
- en: ax.plot(pred_X, pred_Y, c = "blue", linestyle = '-.', \
  id: totrans-970
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot(pred_X, pred_Y, c = "blue", linestyle = '-.', \
- en: linewidth = 4, label = 'linear fit')
  id: totrans-971
  prefs: []
  type: TYPE_NORMAL
  zh: linewidth = 4, label = '线性拟合')
- en: put the model on the plot
  id: totrans-972
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将模型绘制在图上
- en: ax.text(1902, 20, 'Temp = ' + str(round(Beta0, 2)) +' + ' \
  id: totrans-973
  prefs: []
  type: TYPE_NORMAL
  zh: ax.text(1902, 20, '温度 = ' + str(round(Beta0, 2)) +' + ' \
- en: + str(round(Beta1, 4)) + ' * Year', fontsize = 16)
  id: totrans-974
  prefs: []
  type: TYPE_NORMAL
  zh: + str(round(Beta1, 4)) + ' * 年份', fontsize = 16)
- en: ax.set_title('Mean Air Temperature Measurements', fontsize = 16)
  id: totrans-975
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_title('平均空气温度测量', fontsize = 16)
- en: make the ticks include the first and last years
  id: totrans-976
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使刻度包括第一个和最后一个年份
- en: tick_years = [1902] + list(range(1910, 2011, 10))
  id: totrans-977
  prefs: []
  type: TYPE_NORMAL
  zh: tick_years = [1902] + list(range(1910, 2011, 10))
- en: ax.set_xlabel('Year', fontsize = 14)
  id: totrans-978
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlabel('年份', fontsize = 14)
- en: ax.set_ylabel('Temperature ($^\circ$C)', fontsize = 14)
  id: totrans-979
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylabel('温度 ($^\circ$C)', fontsize = 14)
- en: ax.set_ylim(15, 21)
  id: totrans-980
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylim(15, 21)
- en: ax.set_xticks(tick_years)
  id: totrans-981
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xticks(tick_years)
- en: ax.tick_params(labelsize = 12)
  id: totrans-982
  prefs: []
  type: TYPE_NORMAL
  zh: ax.tick_params(labelsize = 12)
- en: ax.legend(fontsize = 12)
  id: totrans-983
  prefs: []
  type: TYPE_NORMAL
  zh: ax.legend(fontsize = 12)
- en: plt.show()
  id: totrans-984
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The output will be as follows:'
  id: totrans-985
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.52: Gradient descent results of linear fit using the scikit-learn
    interface'
  id: totrans-986
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.52：使用 scikit-learn 接口进行线性拟合的梯度下降结果'
- en: '](img/image-37FGFWB9.jpg)'
  id: totrans-987
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-37FGFWB9.jpg)'
- en: 'Figure 3.52: Gradient descent results of linear fit using the scikit-learn
    interface'
  id: totrans-988
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.52：使用 scikit-learn 接口进行线性拟合的梯度下降结果
- en: Note
  id: totrans-989
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to https://packt.live/2zWIadm.
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考 https://packt.live/2zWIadm。
- en: You can also run this example online at https://packt.live/3eqhroj. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在 https://packt.live/3eqhroj 上在线运行此示例。您必须执行整个 Notebook 才能得到期望的结果。
- en: "Compare this graph to the one constructed using the manual implementation of\
    \ gradient descent. Notice the similarities: this provides us with confidence\
    \ that both implementations of gradient descent are correct. However, we now have\
    \ the use of all the power of the scikit-learn implementation of SGD. For more\
    \ complex problems, this could be critical to success. For example, you may have\
    \ noticed that SGDRegressor supports regularization methods, but we did not use\
    \ them. Some regularization methods add an adjustment to the cost function equation\
    \ to apply a penalty (a factor to make a parameter smaller) to parameter values\
    \ that are large in comparison to others. There are other methods available specific\
    \ to some models (for example, artificial neural networks have several additional\
    \ regularization approaches that can be used). One important use of regularization\
    \ is to reduce overfitting, which we have touched on but has not been present\
    \ in the simple models we have used so far. Further discussion relating to regularization\
    \ can be found in Chapter 6, \LEnsemble Modeling."
  id: totrans-992
  prefs: []
  type: TYPE_NORMAL
  zh: 将此图与使用梯度下降手动实现构建的图进行比较。注意相似之处：这让我们确信两种梯度下降实现都是正确的。然而，现在我们可以利用 scikit-learn 实现
    SGD 的全部功能。对于更复杂的问题，这可能至关重要。例如，您可能已经注意到 SGDRegressor 支持正则化方法，但我们没有使用它们。一些正则化方法向成本函数方程添加调整，以对相对较大的参数值（使参数变小的因子）施加惩罚。有其他方法专门适用于某些模型（例如，人工神经网络有几种额外的正则化方法可供使用）。正则化的一个重要用途是减少过拟合，尽管到目前为止我们使用的简单模型中不存在过拟合问题。有关正则化的进一步讨论可在第
    6 章“集成建模”中找到。
- en: 'Activity 3.05: Gradient Descent'
  id: totrans-993
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 活动 3.05：梯度下降
- en: 'In this activity, we will implement the same model as Activity 3.02: Linear
    Regression Using the Least Squares Method; however, we will use the gradient descent
    process.'
  id: totrans-994
  prefs: []
  type: TYPE_NORMAL
  zh: '在此活动中，我们将实现与“活动 3.02: 使用最小二乘法进行线性回归”相同的模型，但我们将使用梯度下降过程。'
- en: 'The steps to be performed are as follows:'
  id: totrans-995
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行的步骤如下：
- en: 'Import the modules and classes; in this case:'
  id: totrans-996
  prefs: []
  type: TYPE_NORMAL
  zh: 导入模块和类；在本例中：
- en: import pandas as pd
  id: totrans-997
  prefs: []
  type: TYPE_NORMAL
  zh: import pandas as pd
- en: import numpy as np
  id: totrans-998
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: import matplotlib.pyplot as plt
  id: totrans-999
  prefs: []
  type: TYPE_NORMAL
  zh: import matplotlib.pyplot as plt
- en: from sklearn.metrics import r2_score
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.metrics import r2_score
- en: from sklearn.linear_model import SGDRegressor
  id: totrans-1001
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.linear_model import SGDRegressor
- en: Load the data (austin_weather.csv) and preprocess up to the point of creating
    the Day_of_Year column and slicing one full year (2015).
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据（austin_weather.csv），并预处理以创建 Day_of_Year 列并切片一整年（2015 年）。
- en: Create scaled X and Y data, scaling between 0 and 1 in each case.
  id: totrans-1003
  prefs: []
  type: TYPE_NORMAL
  zh: 创建经过缩放的 X 和 Y 数据，每种情况都在 0 和 1 之间进行缩放。
- en: Instantiate a model using SGDRegressor. Remember to set the NumPy random.seed()
    method.
  id: totrans-1004
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SGDRegressor 实例化模型。记得设置 NumPy 的 random.seed() 方法。
- en: Fit the model.
  id: totrans-1005
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合模型。
- en: Extract the rescaled model coefficients, Theta0 and Theta1, and print them.
  id: totrans-1006
  prefs: []
  type: TYPE_NORMAL
  zh: 提取经过重新缩放的模型系数 Theta0 和 Theta1，并将它们打印出来。
- en: Generate predictions using the scaled data, use the r2_score method to get the
    r2 value of the fit, and then print out r2.
  id: totrans-1007
  prefs: []
  type: TYPE_NORMAL
  zh: 使用缩放数据生成预测，使用 r2_score 方法获取拟合的 r2 值，然后打印出 r2。
- en: Rescale the predictions to use for plotting.
  id: totrans-1008
  prefs: []
  type: TYPE_NORMAL
  zh: 重新缩放预测值以用于绘图。
- en: Create a visualization with the raw data, the 20-day moving averages, and the
    new linear fit line. Include the model equation on the chart.
  id: totrans-1009
  prefs: []
  type: TYPE_NORMAL
  zh: 创建可视化图表，显示原始数据、20 天移动平均线以及新的线性拟合线。在图表上包含模型方程式。
- en: 'The output should be as follows:'
  id: totrans-1010
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 3.53: Optimized gradient descent predicted trendline'
  id: totrans-1011
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.53：优化的梯度下降预测趋势线'
- en: '](img/image-MRZHKBBI.jpg)'
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-MRZHKBBI.jpg)'
- en: 'Figure 3.53: Optimized gradient descent predicted trendline'
  id: totrans-1013
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.53：优化的梯度下降预测趋势线
- en: Note
  id: totrans-1014
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found via this link.
  id: totrans-1015
  prefs: []
  type: TYPE_NORMAL
  zh: 可通过此链接找到此活动的解决方案。
- en: By now, you should be comfortable using the scikit-learn SGDRegressor interface
    as well as understanding the basic process of gradient descent. You should also
    have some idea as to when using SGD is preferred over, say, standard linear regression.
  id: totrans-1016
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您应该已经熟悉使用 scikit-learn 的 SGDRegressor 接口以及理解梯度下降的基本过程。您还应该对何时使用 SGD 而不是标准线性回归有一些想法。
- en: We have now covered data smoothing and simple linear regression, have developed
    a gradient descent algorithm by hand, and used the scikit-learn SGDRegressor interface
    to apply gradient descent to linear regression. You've seen how to do some feature
    engineering with dummy variables, polynomial features, and sine/cosine features.
    You may have noticed along the way that most of the code is used to prepare the
    data and visualize results. This is not unusual for machine learning—understanding
    and working with data is generally the largest task, and critical to success.
    We'll now move on to another application of regression, multiple linear regression.
  id: totrans-1017
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经覆盖了数据平滑和简单线性回归，手动实现了梯度下降算法，并使用 scikit-learn 的 SGDRegressor 接口将梯度下降应用于线性回归。你已经看到如何使用虚拟变量、和多项式特征以及正弦/余弦特征进行一些特征工程。你可能会注意到，大部分代码是用来准备数据和可视化结果的。对于机器学习来说，这并不奇怪——理解和处理数据通常是最重要的任务，并且对成功至关重要。接下来我们将讨论回归的另一个应用——多元线性回归。
- en: Multiple Linear Regression
  id: totrans-1018
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多元线性回归
- en: 'We have already covered regular linear regression, as well as linear regression
    with polynomial and other terms, and considered training them with both the least
    squares method and gradient descent. This section of the chapter considers an
    additional type of linear regression: multiple linear regression, where more than
    one variable (or feature) is used to construct the model. In fact, we have already
    used multiple linear regression without calling it as such—when we added dummy
    variables, and again when we added the sine and cosine terms, we were fitting
    multiple x variables to predict the single y variable.'
  id: totrans-1019
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经涵盖了常规线性回归，以及带有多项式和其他项的线性回归，并考虑了用最小二乘法和梯度下降法训练它们。本章的这一部分考虑了一种额外的线性回归类型：多元线性回归，其中使用多个变量（或特征）来构建模型。事实上，我们已经在不明确提及的情况下使用了多元线性回归——当我们添加虚拟变量时，或者再添加正弦和余弦项时，我们实际上是在拟合多个
    x 变量以预测单一的 y 变量。
- en: 'Let''s consider a simple example of where multiple linear regression naturally
    arises as a modeling solution. Suppose you were shown the following chart, which
    is the total annual earnings of a hypothetical tech worker over a long career.
    You can see that over time, their pay increased, but there are some odd jumps
    and changes in the data slope:'
  id: totrans-1020
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个简单的例子，说明多元线性回归如何自然成为建模的解决方案。假设你看到以下图表，它显示了一个假设的技术工人在长期职业生涯中的年度总收入。你可以看到，随着时间推移，他们的收入在增加，但数据中有一些异常的跳跃和斜率变化：
- en: '![Figure 3.54: Earnings over the career of a hypothetical worker'
  id: totrans-1021
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.54：假设工人职业生涯中的收入'
- en: '](img/image-ZO5PBBF9.jpg)'
  id: totrans-1022
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-ZO5PBBF9.jpg)'
- en: 'Figure 3.54: Earnings over the career of a hypothetical worker'
  id: totrans-1023
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.54：假设工人职业生涯中的收入
- en: 'You might guess that this worker changed jobs from time to time, causing some
    of the jumps. However, suppose from the data we are given, the compensation is
    the multiplication of their average hours per week each year and an hourly rate.
    Well, intuitively, the total in each year would be the product of the total hours
    worked and the rate. Instead of a simple linear model of income versus year, we
    could build a multiple linear model using year, rate, and hours per week to predict
    the totals. In this hypothetical case, using multiple linear regression versus
    simple linear regression results in the following chart:'
  id: totrans-1024
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能猜测这位工人时常换工作，导致了收入的波动。然而，假设根据我们得到的数据，薪酬是每年每周平均工作小时数与小时工资的乘积。直观地讲，每年的总收入应当是总工作小时数与小时工资的乘积。我们可以构建一个多元线性模型，使用年份、工资和每周工作小时数来预测总收入，而不是简单的收入与年份的线性模型。在这个假设的情况下，使用多元线性回归与简单线性回归相比，结果如下图所示：
- en: '![Figure 3.55: Simple linear regression versus multiple linear regression on
    a hypothetical dataset'
  id: totrans-1025
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.55：简单线性回归与多元线性回归在假设数据集上的比较'
- en: '](img/image-FVHX4WL6.jpg)'
  id: totrans-1026
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-FVHX4WL6.jpg)'
- en: 'Figure 3.55: Simple linear regression versus multiple linear regression on
    a hypothetical dataset'
  id: totrans-1027
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.55：简单线性回归与多元线性回归在假设数据集上的比较
- en: The red circles appear to be a more satisfying model than the simple blue line.
    There are still features in the data not explained—perhaps there were bonuses
    or retirement fund matches in some years, and perhaps there are other things we
    are unaware of in relation to the data. Nonetheless, it makes sense to use multiple
    x variables in such a case.
  id: totrans-1028
  prefs: []
  type: TYPE_NORMAL
  zh: 红色圆圈似乎比简单的蓝色线条更能满足模型需求。数据中仍然存在一些未被解释的特征——也许在某些年份有奖金或退休基金配对，或者与数据相关的其他因素我们尚不清楚。尽管如此，在这种情况下，使用多个
    x 变量是合理的。
- en: Before moving on, let's cover a few details. We will be using the corr() method
    in pandas, which takes a DataFrame and calculates the pairwise correlation among
    all the variables. There are two key things that we will be investigating in the
    following exercise. First, when executing regression with multiple x variables,
    if any of the variables are highly correlated, this can cause issues with the
    model. This problem is known as multicollinearity and can cause the coefficient
    estimates to be unstable to small changes in the data or the model. In an extreme
    case, where one variable is actually a linear combination of other variables,
    the model can become singular; in some methods, the coefficient for one of the
    linearly dependent variables may be returned as Inf, or other errors may result.
    Secondly, we would also like to know whether the variables will have any impact
    on predictions. Let's solve an exercise to understand this better.
  id: totrans-1029
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们先讨论一些细节。我们将使用 pandas 中的 `corr()` 方法，它接受一个 DataFrame 并计算所有变量之间的成对相关性。在接下来的练习中，我们将研究两个关键问题。首先，当执行多元回归时，如果某些变量之间高度相关，可能会导致模型出现问题。这个问题被称为多重共线性，它可能导致系数估计对数据或模型的微小变化不稳定。在极端情况下，如果一个变量实际上是其他变量的线性组合，模型可能变得奇异；在某些方法中，线性相关的变量的系数可能会返回为
    Inf，或者出现其他错误。其次，我们还希望了解这些变量是否会对预测结果产生影响。让我们通过解决一个练习来更好地理解这一点。
- en: 'Exercise 3.07: Multiple Linear Regression'
  id: totrans-1030
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '练习 3.07: 多元线性回归'
- en: 'For this exercise, we will use a UCI dataset that has the power output of a
    combined cycle power plant and several possible explanatory variables:'
  id: totrans-1031
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个练习，我们将使用一个 UCI 数据集，它包含一个组合循环电厂的功率输出和几个可能的解释变量：
- en: Note
  id: totrans-1032
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The original data and description are available from https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant
  id: totrans-1033
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据和描述文件可从 https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant
    获得
- en: 'Alternatively, you can find the data in our repository here: https://packt.live/2Pu850C'
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您也可以在我们的存储库中找到数据： https://packt.live/2Pu850C
- en: 'Load the modules and classes; note that we are adding seaborn here to be used
    in some visualizations:'
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
  zh: 加载模块和类；注意，我们在这里添加了 seaborn，以便在一些可视化中使用：
- en: import pandas as pd
  id: totrans-1036
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 pandas 为 pd
- en: import numpy as np
  id: totrans-1037
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 numpy 为 np
- en: import matplotlib.pyplot as plt
  id: totrans-1038
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 matplotlib.pyplot 为 plt
- en: import seaborn as sns
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 seaborn 为 sns
- en: from sklearn.linear_model import LinearRegression
  id: totrans-1040
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 sklearn.linear_model 的导入 LinearRegression
- en: 'Load and inspect the data:'
  id: totrans-1041
  prefs: []
  type: TYPE_NORMAL
  zh: 加载并检查数据：
- en: Note
  id: totrans-1042
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The triple-quotes ( """ ) shown in the code snippet below are used to denote
    the start and end points of a multi-line code comment. Comments are added into
    code to help explain specific bits of logic.
  id: totrans-1043
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段中的三引号（"""）用于表示多行代码注释的开始和结束。注释用于帮助解释代码中的特定逻辑。
- en: '"""'
  id: totrans-1044
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: load and inspect data
  id: totrans-1045
  prefs: []
  type: TYPE_NORMAL
  zh: 加载并检查数据
- en: from the description file
  id: totrans-1046
  prefs: []
  type: TYPE_NORMAL
  zh: 来自描述文件
- en: (https://archive.ics.uci.edu/ml/machine-learning-databases/00294/)
  id: totrans-1047
  prefs: []
  type: TYPE_NORMAL
  zh: (https://archive.ics.uci.edu/ml/machine-learning-databases/00294/)
- en: 'the variables are:'
  id: totrans-1048
  prefs: []
  type: TYPE_NORMAL
  zh: 变量包括：
- en: 'note: some var names are incorrect in the description file'
  id: totrans-1049
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：描述文件中某些变量名称不正确
- en: Ambient Temperature (AT)
  id: totrans-1050
  prefs: []
  type: TYPE_NORMAL
  zh: 环境温度 (AT)
- en: Ambient Pressure (AP)
  id: totrans-1051
  prefs: []
  type: TYPE_NORMAL
  zh: 环境压力 (AP)
- en: Relative Humidity (RH)
  id: totrans-1052
  prefs: []
  type: TYPE_NORMAL
  zh: 相对湿度 (RH)
- en: Exhaust Vacuum (V)
  id: totrans-1053
  prefs: []
  type: TYPE_NORMAL
  zh: 排气真空 (V)
- en: and the dependent variable is
  id: totrans-1054
  prefs: []
  type: TYPE_NORMAL
  zh: 因变量是
- en: net hourly electrical energy output (PE)
  id: totrans-1055
  prefs: []
  type: TYPE_NORMAL
  zh: 每小时净电能输出 (PE)
- en: '"""'
  id: totrans-1056
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: power_data = pd.read_csv\
  id: totrans-1057
  prefs: []
  type: TYPE_NORMAL
  zh: power_data = pd.read_csv\
- en: ('../Datasets/combined_cycle_power_plant.csv')
  id: totrans-1058
  prefs: []
  type: TYPE_NORMAL
  zh: ('../Datasets/combined_cycle_power_plant.csv')
- en: print(power_data.shape)
  id: totrans-1059
  prefs: []
  type: TYPE_NORMAL
  zh: print(power_data.shape)
- en: print(power_data.head())
  id: totrans-1060
  prefs: []
  type: TYPE_NORMAL
  zh: print(power_data.head())
- en: missings = power_data.isnull().sum()
  id: totrans-1061
  prefs: []
  type: TYPE_NORMAL
  zh: missings = power_data.isnull().sum()
- en: print(missings)
  id: totrans-1062
  prefs: []
  type: TYPE_NORMAL
  zh: print(missings)
- en: 'The result should appear as follows:'
  id: totrans-1063
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应如下所示：
- en: '![Figure 3.56: The combined power cycle dataset has no missing values'
  id: totrans-1064
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.56: 组合动力循环数据集没有缺失值'
- en: '](img/image-B6OMOHPM.jpg)'
  id: totrans-1065
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-B6OMOHPM.jpg)'
- en: 'Figure 3.56: The combined power cycle dataset has no missing values'
  id: totrans-1066
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3.56: 组合动力循环数据集没有缺失值'
- en: 'Since we have not used this data before, let''s do some very quick EDA. First,
    we''ll look at the correlation among all the variables:'
  id: totrans-1067
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们之前没有使用过这个数据，让我们进行一些快速的 EDA（探索性数据分析）。首先，我们将查看所有变量之间的相关性：
- en: '"""'
  id: totrans-1068
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: quick EDA
  id: totrans-1069
  prefs: []
  type: TYPE_NORMAL
  zh: 快速 EDA
- en: correlation analysis
  id: totrans-1070
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性分析
- en: '"""'
  id: totrans-1071
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: corr = power_data.corr()
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
  zh: corr = power_data.corr()
- en: mask for heatmap in seaborn
  id: totrans-1073
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于 seaborn 中热图的掩码
- en: mask = np.ones((power_data.shape[1], power_data.shape[1]))
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
  zh: mask = np.ones((power_data.shape[1], power_data.shape[1]))
- en: mask = [[1 if j< i else 0 \
  id: totrans-1075
  prefs: []
  type: TYPE_NORMAL
  zh: mask = [[1 if j< i else 0 \
- en: for j in range(corr.shape[0])] \
  id: totrans-1076
  prefs: []
  type: TYPE_NORMAL
  zh: for j in range(corr.shape[0])] \
- en: for i in range(corr.shape[1])]
  id: totrans-1077
  prefs: []
  type: TYPE_NORMAL
  zh: for i in range(corr.shape[1])]
- en: fig, ax = plt.subplots(figsize = (10, 7))
  id: totrans-1078
  prefs: []
  type: TYPE_NORMAL
  zh: fig, ax = plt.subplots(figsize = (10, 7))
- en: '"""'
  id: totrans-1079
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: plot the correlation matrix as a heatmap
  id: totrans-1080
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制相关矩阵的热图
- en: blanking out the upper triangle (duplicates)
  id: totrans-1081
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏上三角形（重复项）
- en: '"""'
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: sns.heatmap(corr, cmap = 'jet_r', square = True, linewidths = 0.5, \
  id: totrans-1083
  prefs: []
  type: TYPE_NORMAL
  zh: sns.heatmap(corr, cmap = 'jet_r', square = True, linewidths = 0.5, \
- en: center = 0, annot = True, mask = mask, \
  id: totrans-1084
  prefs: []
  type: TYPE_NORMAL
  zh: center = 0, annot = True, mask = mask, \
- en: 'annot_kws = {"size" : 12}, \'
  id: totrans-1085
  prefs: []
  type: TYPE_NORMAL
  zh: 'annot_kws = {"size" : 12}, \'
- en: xticklabels = power_data.columns, \
  id: totrans-1086
  prefs: []
  type: TYPE_NORMAL
  zh: xticklabels = power_data.columns, \
- en: yticklabels = power_data.columns)
  id: totrans-1087
  prefs: []
  type: TYPE_NORMAL
  zh: yticklabels = power_data.columns)
- en: plt.show()
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The chart should appear as follows:'
  id: totrans-1089
  prefs: []
  type: TYPE_NORMAL
  zh: 该图表应如下所示：
- en: '![Figure 3.57: Correlation chart of variables'
  id: totrans-1090
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.57：变量相关性图表](img/image-J58CFLEM.jpg)'
- en: '](img/image-JMMJK0S2.jpg)'
  id: totrans-1091
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-JMMJK0S2.jpg)'
- en: 'Figure 3.57: Correlation chart of variables'
  id: totrans-1092
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.57：变量相关性图表
- en: In the preceding data, the strongest correlation among the x variables is the
    0.84 between V and AT. Hence, there should be no multicollinearity here.
  id: totrans-1093
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的数据中，x变量之间最强的相关性是V和AT之间的0.84。因此，这里应该没有多重共线性问题。
- en: We would like some indication that the x variables will impact on the thing
    we are trying to predict, PE. In the last row of the chart, we can see a significant
    correlation between PE and all the other variables, which is a good indicator
    they will all be valuable in the model. If there were a very large number of features,
    we might be interested in dropping variables that are less important in terms
    of reducing noise in the model. However, these correlation coefficients are only
    pairwise and even if we saw a low correlation, more work would be required to
    justify removing a variable.
  id: totrans-1094
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望能够显示出x变量会影响我们试图预测的目标变量PE。在图表的最后一行，我们可以看到PE与所有其他变量之间有显著的相关性，这是它们在模型中都将是有价值的一个良好指示。如果特征非常多，我们可能会考虑删除一些在减少模型噪音方面不太重要的变量。然而，这些相关系数只是成对的，即使我们看到低相关性，也需要更多的工作来证明删除某个变量的合理性。
- en: Regarding the visualization, we are using the seaborn heatmap function to generate
    the plot. Because the correlation values are symmetric, the correlation between,
    say, AT and V is the same as V and AT. Therefore, the upper-right triangle of
    the grid would mirror the lower-left triangle, so the heatmap method provides
    a way to blank any squares we want. This is accomplished with the mask variable
    in the call, which takes a matrix the same shape as the correlation matrix, and
    blanks any squares corresponding to False values in the mask. We used a nested
    list comprehension to put the False values (integer 0) into the mask.
  id: totrans-1095
  prefs: []
  type: TYPE_NORMAL
  zh: 关于可视化，我们使用了seaborn的热图功能来生成图表。由于相关值是对称的，比如AT和V之间的相关性与V和AT之间的相关性是相同的。因此，网格的右上三角形会与左下三角形镜像，所以热图方法提供了一种方式来隐藏我们想要忽略的方块。我们通过mask变量实现这一点，mask是一个与相关矩阵形状相同的矩阵，并隐藏任何在mask中对应为False值的方块。我们使用了嵌套的列表推导式来将False值（整数0）放入mask中。
- en: Finally, note that the values along the diagonal are all 1; by definition, a
    variable is perfectly correlated to itself. You might see examples where these
    squares are used to plot the variable distributions or other valuable information,
    as well as using the upper-right (or lower-left) triangle squares for additional
    information, such as the plots in the next step.
  id: totrans-1096
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，请注意对角线上的值都是1；根据定义，一个变量与自身的相关性是完美的。你可能会看到这些方块用于绘制变量分布或其他有价值的信息，同时，右上（三角形）或左下（三角形）部分的方块可以用于额外的信息，例如下一步中的图表。
- en: 'Use the seaborn pairplot to visualize the pairwise relationships among all
    the variables. This information augments the correlation plot and, as noted, is
    sometimes combined with it in a single grid:'
  id: totrans-1097
  prefs: []
  type: TYPE_NORMAL
  zh: 使用seaborn的pairplot来可视化所有变量之间的成对关系。这些信息可以补充相关图，并且如前所述，有时会将其与相关图合并成一个网格：
- en: (2) look at the pairwise variable relationships
  id: totrans-1098
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: (2) 查看成对的变量关系
- en: plot_grid = sns.pairplot(power_data)
  id: totrans-1099
  prefs: []
  type: TYPE_NORMAL
  zh: plot_grid = sns.pairplot(power_data)
- en: 'The result should appear as follows:'
  id: totrans-1100
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该如下所示：
- en: '![Figure 3.58: Seaborn pairplot of the data'
  id: totrans-1101
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.58：Seaborn数据的pairplot图](img/image-JMMJK0S2.jpg)'
- en: '](img/image-J58CFLEM.jpg)'
  id: totrans-1102
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-J58CFLEM.jpg)'
- en: 'Figure 3.58: Seaborn pairplot of the data'
  id: totrans-1103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.58：Seaborn数据的pairplot图
- en: By default, this chart shows the scatterplot of each variable against the other
    variables and the distributions of each variable along the diagonal. Note that
    the upper-right triangle is the mirror image of the lower-right triangle, and
    that the axes are flipped on each chart.
  id: totrans-1104
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，这个图表展示了每个变量与其他变量之间的散点图，并且每个变量沿对角线的分布。请注意，右上三角形是左下三角形的镜像，且每个图表的坐标轴是翻转的。
- en: Along the diagonal, we see the distributions of all the variables. We can see
    that the RH variable is skewed to the left; we could consider applying a transform
    to that column, such as numpy.log(power_data['RH']) or numpy.sqrt(power_data['RH']).
    For this exercise, we will leave them as is.
  id: totrans-1105
  prefs: []
  type: TYPE_NORMAL
  zh: 沿着对角线，我们可以看到所有变量的分布。我们可以看到RH变量向左偏斜；我们可以考虑对该列应用变换，例如numpy.log(power_data['RH'])或numpy.sqrt(power_data['RH'])。但在本次练习中，我们将保持原样。
- en: The other thing we can observe from this chart is the scatterplots along the
    bottom row; note that AT, which has the largest negative correlation to PE, shows
    a clear negative trend of PE versus AT, which intuitively makes sense. As we move
    to the right, the correlations become less strong, and that is consistent with
    the scatterplots. In the third chart, PE versus AP, we can see some indication
    of the positive correlation.
  id: totrans-1106
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图表中我们还可以观察到底部行的散点图；注意，AT与PE的负相关性最大，AT与PE的关系呈现出明显的负趋势，这在直观上是有意义的。向右移动时，相关性变得较弱，这与散点图一致。在第三张图中，PE与AP的关系，我们可以看到一些积极相关的迹象。
- en: 'Now, we structure the data for the linear regression model, fit the model,
    and get predictions and the r2 value. This is done in the same way as we did it
    in the previous exercises:'
  id: totrans-1107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将数据结构化以用于线性回归模型，拟合模型，并获得预测值和r2值。这与我们在之前的练习中做的方式相同：
- en: structure data
  id: totrans-1108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构化数据
- en: X_train = power_data.drop('PE', axis = 1)
  id: totrans-1109
  prefs: []
  type: TYPE_NORMAL
  zh: X_train = power_data.drop('PE', axis = 1)
- en: Y_train = power_data['PE']
  id: totrans-1110
  prefs: []
  type: TYPE_NORMAL
  zh: Y_train = power_data['PE']
- en: fit the model
  id: totrans-1111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拟合模型
- en: model = LinearRegression()
  id: totrans-1112
  prefs: []
  type: TYPE_NORMAL
  zh: model = LinearRegression()
- en: model.fit(X_train, Y_train)
  id: totrans-1113
  prefs: []
  type: TYPE_NORMAL
  zh: model.fit(X_train, Y_train)
- en: get predictions
  id: totrans-1114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取预测值
- en: Y_pred = model.predict(X_train)
  id: totrans-1115
  prefs: []
  type: TYPE_NORMAL
  zh: Y_pred = model.predict(X_train)
- en: r2 = model.score(X_train, Y_train)
  id: totrans-1116
  prefs: []
  type: TYPE_NORMAL
  zh: r2 = model.score(X_train, Y_train)
- en: print('model coefficients ' + str(model.coef_))
  id: totrans-1117
  prefs: []
  type: TYPE_NORMAL
  zh: print('模型系数 ' + str(model.coef_))
- en: print('r2 value ' + str(round(r2, 3)))
  id: totrans-1118
  prefs: []
  type: TYPE_NORMAL
  zh: print('r2值 ' + str(round(r2, 3)))
- en: 'The output should appear as follows:'
  id: totrans-1119
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果应如下所示：
- en: '![Figure 3.59: Results of the multiple linear regression fit'
  id: totrans-1120
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.59：多重线性回归拟合结果'
- en: '](img/image-RNX0761D.jpg)'
  id: totrans-1121
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-RNX0761D.jpg)'
- en: 'Figure 3.59: Results of the multiple linear regression fit'
  id: totrans-1122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.59：多重线性回归拟合结果
- en: The relatively high r2 value is a good sign that the model may be effective
    at predicting PE.
  id: totrans-1123
  prefs: []
  type: TYPE_NORMAL
  zh: 相对较高的r2值是模型在预测PE时可能有效的良好信号。
- en: 'With multiple linear regression, we can''t visualize the results easily as
    a plot of the predicted variable versus an x variable. However, a very powerful
    visualization that can be used in almost any situation is simply to plot the predicted
    value against the true value. It''s best to make this plot symmetric (the axis
    limits should be the same for x and y) for ease of interpretation—perfect predictions
    would then lie along the diagonal. We add a diagonal line to aid in visual interpretation:'
  id: totrans-1124
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多重线性回归，我们无法像绘制预测变量与x变量的图那样轻松地可视化结果。然而，有一个非常强大的可视化方法几乎可以在任何情况下使用，那就是将预测值与真实值绘制在一起。为了便于解释，最好使这个图对称（x和y的轴范围应相同）——完美的预测值应沿对角线分布。我们添加一条对角线以帮助视觉解释：
- en: fig, ax = plt.subplots(figsize=(10, 10))
  id: totrans-1125
  prefs: []
  type: TYPE_NORMAL
  zh: fig, ax = plt.subplots(figsize=(10, 10))
- en: set some limits
  id: totrans-1126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置一些限制
- en: PE_range = max(power_data.PE) - min(power_data.PE)
  id: totrans-1127
  prefs: []
  type: TYPE_NORMAL
  zh: PE_range = max(power_data.PE) - min(power_data.PE)
- en: plot_range = [min(power_data.PE) - 0.05 * PE_range, \
  id: totrans-1128
  prefs: []
  type: TYPE_NORMAL
  zh: plot_range = [min(power_data.PE) - 0.05 * PE_range, \
- en: max(power_data.PE) + 0.05 * PE_range]
  id: totrans-1129
  prefs: []
  type: TYPE_NORMAL
  zh: max(power_data.PE) + 0.05 * PE_range]
- en: ax.scatter(Y_train, Y_pred)
  id: totrans-1130
  prefs: []
  type: TYPE_NORMAL
  zh: ax.scatter(Y_train, Y_pred)
- en: ax.set_xlim(plot_range)
  id: totrans-1131
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlim(plot_range)
- en: ax.set_ylim(plot_range)
  id: totrans-1132
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylim(plot_range)
- en: ax.set_xlabel('Actual PE value', fontsize = 14)
  id: totrans-1133
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_xlabel('实际PE值', fontsize = 14)
- en: ax.set_ylabel('Predicted PE value', fontsize = 14)
  id: totrans-1134
  prefs: []
  type: TYPE_NORMAL
  zh: ax.set_ylabel('预测PE值', fontsize = 14)
- en: ax.plot(plot_range, plot_range, c = "black")
  id: totrans-1135
  prefs: []
  type: TYPE_NORMAL
  zh: ax.plot(plot_range, plot_range, c = "black")
- en: plt.show()
  id: totrans-1136
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The result is as follows:'
  id: totrans-1137
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 3.60: Predicted versus actual PE from multiple linear regression'
  id: totrans-1138
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.60：多重线性回归的预测值与实际PE值对比'
- en: '](img/image-M6OZ7IW5.jpg)'
  id: totrans-1139
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-M6OZ7IW5.jpg)'
- en: 'Figure 3.60: Predicted versus actual PE from multiple linear regression'
  id: totrans-1140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.60：多重线性回归的预测值与实际PE值对比
- en: Figure 3.60 indicates that the majority of predictions are along the diagonal.
    There are a few values that are predicted significantly higher than most, and
    we might want to investigate those particular points. In addition, at the highest
    values, the prediction tends to be too low on average, which may indicate that
    there is some feature engineering or other data we need in the model. Recall that
    we did not transform any of the variables; that would be useful to try here to
    see whether results subsequently improved. We will not pursue this further here.
  id: totrans-1141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.60 显示，大多数预测结果都位于对角线上。也有一些值的预测显著高于大多数，我们可能需要对这些特定点进行进一步调查。此外，在最高值处，预测通常偏低，这可能表明模型中缺少一些特征工程或其他数据。回想一下，我们没有对任何变量进行变换；在这里尝试进行变换可能会有所帮助，看是否能改进结果。我们在这里不会进一步探讨这个问题。
- en: Note
  id: totrans-1142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to https://packt.live/2CwfIzZ.
  id: totrans-1143
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考 [https://packt.live/2CwfIzZ](https://packt.live/2CwfIzZ)。
- en: You can also run this example online at https://packt.live/37UzZuK. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-1144
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行此示例，网址是 [https://packt.live/37UzZuK](https://packt.live/37UzZuK)。你必须执行整个
    Notebook 才能获得预期的结果。
- en: We have seen that using multiple linear regression is a powerful addition to
    the toolset, and is a very easy extension to methods we have already mastered.
    In fact, multiple linear regression can often perform as well or better than more
    complex models on regression problems. Although we are not covering it here, a
    benefit of using multiple linear regression versus, let's say, an artificial neural
    network is that the coefficients of the multiple linear regression model can be
    interpreted as the estimates of the effects on the predicted variable of each
    x variable; there are times when that interpretation is extremely valuable.
  id: totrans-1145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，使用多元线性回归是工具集中的一个强大补充，并且是我们已掌握的方法的一个非常简单的扩展。事实上，多元线性回归在回归问题中，往往能够与更复杂的模型表现得一样好甚至更好。尽管我们在这里没有讨论，但使用多元线性回归与人工神经网络相比的一个好处是，多元线性回归模型的系数可以解释为每个
    x 变量对预测变量的影响估计；在某些情况下，这种解释非常有价值。
- en: Summary
  id: totrans-1146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we took our first big leap into constructing machine learning
    models and making predictions with labeled datasets. We began our analysis by
    looking at a variety of different ways to construct linear models, starting with
    the precise least squares method, which is very good when modeling small amounts
    of data that can be processed using the available computer memory. The performance
    of linear models can be improved using dummy variables, which we created from
    categorical variables, adding additional features and context to the model. We
    then used linear regression analysis with a polynomial model to further improve
    performance, fitting a more natural curve to the dataset, and we investigated
    other non-linear feature engineering with the addition of sine and cosine series
    as predictors.
  id: totrans-1147
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们迈出了构建机器学习模型并使用带标签的数据集进行预测的第一步。我们通过查看多种构建线性模型的方式开始了分析，首先使用精确的最小二乘法，这是在使用现有计算机内存处理小量数据时非常有效的方法。线性模型的性能可以通过使用虚拟变量来提高，这些虚拟变量是由分类变量创建的，能够为模型添加额外的特征和背景。随后，我们使用带有多项式模型的线性回归分析来进一步提高性能，为数据集拟合更自然的曲线，并探讨了通过增加正弦和余弦序列作为预测变量的其他非线性特征工程。
- en: As a generalization from explicit linear regression, we implemented the gradient
    descent algorithm, which we noted, while not as precise as the least squares method
    (for a given number of iterations or epochs), would be able to process arbitrarily
    large datasets and larger numbers of variables. In addition, using generalized
    gradient descent introduces a number of other parameters, so-called hyperparameters,
    that can be optimized by us, the data scientists, to improve model performance.
    We deferred further investigation of model optimization to Chapter 7, Model Evaluation.
  id: totrans-1148
  prefs: []
  type: TYPE_NORMAL
  zh: 作为显式线性回归的一个概括，我们实现了梯度下降算法。正如我们所指出的，梯度下降虽然不像最小二乘法那样精确（对于给定的迭代次数或轮次），但能够处理任意大的数据集和更多的变量。此外，使用广义梯度下降引入了许多其他参数，即所谓的超参数，我们作为数据科学家可以对其进行优化，从而提高模型性能。我们将进一步的模型优化研究推迟到第七章《模型评估》。
- en: Now that we have a sound understanding of linear regression, we will look at
    autoregression models in depth in the next chapter.
  id: totrans-1149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对线性回归有了充分的理解，在下一章中我们将深入研究自回归模型。
