- en: '*Chapter 6*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第六章*'
- en: Model Evaluation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，你将能够：
- en: Explain the importance of evaluating models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释评估模型的重要性
- en: Evaluate regression and classification models using a number of metrics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多种指标评估回归和分类模型
- en: Choose the right metric for evaluating and tuning a model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择合适的评估指标来评估和调优模型
- en: Explain the importance of hold-out datasets and types of sampling
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释持出数据集的重要性和采样的类型
- en: Perform hyperparameter tuning to find the best model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行超参数调优以找到最佳模型
- en: Calculate feature importance and explain why they are important
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算特征重要性并解释它们为何重要
- en: This chapter introduces us to how we can improve a model's performance by using
    hyperparameters and model evaluation metrics.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了如何通过使用超参数和模型评估指标来提升模型性能。
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous three chapters, we discussed the two types of supervised learning
    problems, regression and classification, followed by ensemble models, which were
    built from a combination of base models. We built several models and discussed
    how and why they work.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的三章中，我们讨论了两种类型的监督学习问题——回归和分类，接着介绍了集成模型，它是由多个基础模型的组合构建而成。我们建立了几个模型，并讨论了它们的工作原理及原因。
- en: 'However, that is not enough to take a model to production. Model development
    is an iterative process, and the model training step is followed by validation
    and updating steps:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这还不足以将模型投入生产。模型开发是一个迭代过程，模型训练步骤之后是验证和更新步骤：
- en: '![Figure 6.1: Machine learning model development process'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.1：机器学习模型开发过程'
- en: '](img/C12622_06_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12622_06_01.jpg)'
- en: 'Figure 6.1: Machine learning model development process'
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.1：机器学习模型开发过程
- en: This chapter will explain the peripheral steps in the process shown in the preceding
    flowchart; we will discuss how to select the appropriate hyperparameters and how
    to perform model validation using the appropriate error metrics. Improving a model's
    performance happens by iteratively performing these two tasks.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将解释前面流程图中展示的外围步骤；我们将讨论如何选择合适的超参数，以及如何使用合适的误差指标进行模型验证。通过反复执行这两项任务，提升模型性能。
- en: But why is it important to evaluate your model? Say you've trained your model
    and provided some hyperparameters, made predictions, and found its accuracy. That's
    the gist of it, but how do you make sure that your model is performing to the
    best of its ability? We need to ensure that the performance measure that you've
    come up with is actually representative of the model and that it will indeed perform
    well on an unseen test dataset.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，为什么评估模型很重要呢？假设你已经训练好了模型，提供了一些超参数，做出了预测并找到了准确率。这就是其核心内容，但如何确保你的模型发挥出了最佳能力呢？我们需要确保你所制定的性能评估标准实际上能够代表模型，并且模型在未见过的测试数据集上也能够表现良好。
- en: 'The essential part about making sure that the model is the best version of
    itself comes after the initial training: the process of evaluating and improving
    the performance of the model. This chapter will take you through the essential
    techniques required when it comes to this.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 确保模型达到最佳状态的关键部分出现在初始训练之后：即评估和提升模型性能的过程。本章将引导你了解这一过程中所需的基本技术。
- en: In this chapter, we will first discuss why model evaluation is important, and
    introduce several evaluation metrics for both regression tasks and classification
    tasks that can be used to quantify the predictive performance of a model. This
    will be followed by a discussion on hold-out datasets and k-fold cross-validation
    and why it is imperative to have a test set that is independent of the validation
    set.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先讨论为什么模型评估如此重要，并介绍几种回归任务和分类任务的评估指标，这些指标可以用来量化模型的预测性能。接下来，我们将讨论持出数据集和
    k 折交叉验证，并解释为什么测试集必须独立于验证集。
- en: 'After this, we''ll look at tactics we can use to boost the performance of the
    model. In the previous chapter, we talked about how having a model with a high
    bias or a high variance can result in suboptimal performance, and how building
    an ensemble of models can help us build a robust system that makes more accurate
    predictions without increasing the overall variance. We also mentioned the following
    as techniques to avoid overfitting our model to the training data:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，我们将讨论可以用来提高模型表现的策略。在上一章中，我们谈到了如何一个具有高偏差或高方差的模型会导致表现不佳，以及如何通过构建集成模型来帮助我们建立一个更加稳健、更加准确的系统，而不增加整体方差。我们还提到了一些避免过拟合训练数据的技巧：
- en: '**To get more data**: A highly complex model can easily overfit to a small
    dataset but may not be able to as easily on a larger dataset.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**获取更多数据**：一个复杂的模型可能很容易在小数据集上过拟合，但在更大的数据集上却可能不容易过拟合。'
- en: '**Dimensionality reduction**: Reducing the number of features can help make
    the model less complex.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降维**：减少特征的数量有助于使模型变得不那么复杂。'
- en: '**Regularization**: A new term is added to the cost function in order to adjust
    the coefficients (especially the high-degree coefficients in linear regression)
    toward a small value.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正则化**：在代价函数中添加一个新项，以便调整系数（尤其是线性回归中的高阶系数）使其趋向于较小的值。'
- en: In this chapter, we'll introduce learning curves and validation curves as a
    way to see how variations in training and validation errors allow us to see whether
    the model needs more data, and where the appropriate level of complexity is. This
    will be followed by a section on hyperparameter tuning in an effort to boost performance,
    and a brief introduction to feature importance.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍学习曲线和验证曲线，作为查看训练误差和验证误差变化的方式，以帮助我们了解模型是否需要更多的数据，并找到合适的复杂度水平。接下来将介绍超参数调优，以提升模型表现，并简要介绍特征重要性。
- en: 'Exercise 49: Importing the Modules and Preparing Our Dataset'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 49：导入模块并准备我们的数据集
- en: 'In this exercise, we will load the data and models that we trained as part
    of *Chapter 5*, *Ensemble Modeling*. We will use the stacked linear regression
    model from *Activity 14: Stacking with Standalone and Ensemble Algorithms*, and
    the random forest classification model to predict the survival of passengers from
    *Exercise 45: Building the Ensemble Model Using Random Forest*:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '在本练习中，我们将加载在*第 5 章*（*集成建模*）中训练的数据和模型。我们将使用*活动 14: 使用独立和集成算法进行堆叠*中的堆叠线性回归模型，以及*练习
    45: 使用随机森林构建集成模型*中的随机森林分类模型来预测乘客的生存情况：'
- en: 'Import the relevant libraries:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入相关的库：
- en: '[PRE0]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Load the processed data files from *Chapter 5*, *Ensemble Modeling*. We will
    use pandas'' `read_csv()` method to read in our prepared datasets, which we will
    use in the exercises in this chapter. First, we''ll read the house price data:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从*第 5 章*（*集成建模*）加载处理后的数据文件。我们将使用pandas的`read_csv()`方法读取准备好的数据集，并在本章练习中使用它们。首先，我们将读取房价数据：
- en: '[PRE1]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We''ll see the following output:'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将看到以下输出：
- en: '![Figure 6.2: First five rows of house_prices](img/C12622_06_02.jpg)'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.2: 房价数据的前五行](img/C12622_06_02.jpg)'
- en: 'Figure 6.2: First five rows of house_prices'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.2: 房价数据的前五行'
- en: 'Next, we''ll read in the Titanic data:'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们将读取泰坦尼克号的数据：
- en: '[PRE2]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We''ll see the following output:'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将看到以下输出：
- en: '![Figure 6.3: First five rows of Titanic](img/C12622_06_03.jpg)'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.3: 泰坦尼克号数据的前五行](img/C12622_06_03.jpg)'
- en: 'Figure 6.3: First five rows of Titanic'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.3: 泰坦尼克号数据的前五行'
- en: 'Next, load the model files that we will use for the exercises in this chapter
    by using the `pickle` library to load them from a binary file:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用`pickle`库从二进制文件中加载我们将在本章练习中使用的模型文件：
- en: '[PRE3]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Let's begin.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Evaluation Metrics
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估指标
- en: 'Evaluating a machine learning model is an essential part of any project: once
    we have allowed our model to learn from the training data, the next step is to
    measure the performance of the model. We need to find a metric that can not only
    tell us how accurate the predictions made by the model are, but also allow us
    to compare the performance of a number of models so that we can select the one
    best suited for our use case.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 评估机器学习模型是任何项目中的关键部分：一旦我们让模型从训练数据中学习，下一步就是衡量模型的表现。我们需要找到一种度量标准，不仅能告诉我们模型的预测准确度，还能让我们比较多个模型的表现，从而选择最适合我们用例的模型。
- en: Defining a metric is usually one of the first things we should do when defining
    our problem statement and before we begin the EDA, since it's a good idea to plan
    ahead and think about how we intend to evaluate the performance of any model we
    build and how to judge whether it is performing optimally or not. Eventually,
    calculating the performance evaluation metric will fit into the machine learning
    pipeline.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 定义度量标准通常是我们在定义问题陈述和开始进行探索性数据分析（EDA）之前要做的第一件事，因为提前规划并思考我们打算如何评估构建的任何模型的性能以及如何判断模型是否达到最佳表现是个好主意。最终，计算性能评估度量将纳入机器学习管道中。
- en: Needless to say, evaluation metrics will be different for regression tasks and
    classification tasks, since the output values in the former are continuous while
    the outputs in the latter are categorical. In this section, we'll look at the
    different metrics we can use to quantify the predictive performance of a model.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 不用说，回归任务和分类任务的评估度量是不同的，因为前者的输出值是连续的，而后者的输出值是分类的。在这一部分，我们将探讨可以用来量化模型预测性能的不同度量标准。
- en: Regression
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回归
- en: For an input variable, *X*, a regression model gives us a predicted value,![](img/C12622_06_Eq1.png)
    , that can take on a range of values. The ideal scenario would be to have the
    model predict ![](img/C12622_06_Eq11.png) values that are as close as possible
    to the actual value of *y*. Therefore, the smaller the difference between the
    two, the better the model performs. Regression metrics mostly involve looking
    at the numerical difference between the predicted value and actual value (that
    is, the residual or error value) for each data point, and subsequently aggregating
    these differences in some way.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输入变量*X*，回归模型给出一个预测值，![](img/C12622_06_Eq1.png)，该值可以取一系列不同的值。理想的情况是模型能够预测出尽可能接近实际值*y*的![](img/C12622_06_Eq11.png)值。因此，两个值之间的差距越小，模型的表现就越好。回归度量通常涉及查看每个数据点的预测值与实际值之间的数值差异（即残差或误差值），然后以某种方式聚合这些差异。
- en: 'Let''s look at the following plot, which plots the actual and predicted values
    for every point *X*:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一下下图，它绘制了每个点*X*的实际值和预测值：
- en: '![Figure 6.4: Residuals between actual and predicted outputs in a linear regression
    problem](img/C12622_06_04.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图6.4：线性回归问题中的实际值与预测值之间的残差](img/C12622_06_04.jpg)'
- en: 'Figure 6.4: Residuals between actual and predicted outputs in a linear regression
    problem'
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.4：线性回归问题中的实际值与预测值之间的残差
- en: However, we can't just find the mean value of ![](img/C12622_06_Eq2.png) over
    all data points, since there could be data points that have a prediction error
    that is positive or negative, and the aggregate would ultimately end up canceling
    out a lot of the errors and severely overestimate the performance of the model.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们不能仅仅对所有数据点的![](img/C12622_06_Eq2.png)的均值进行计算，因为可能存在某些数据点，其预测误差为正或负，最终的总和将抵消掉许多误差，并严重高估模型的性能。
- en: 'Instead, we can consider the absolute error for each data point and find the
    **Mean Absolute Error** (**MAE**), which is given by the following formula:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可以考虑每个数据点的绝对误差，并计算**平均绝对误差**（**MAE**），其公式如下：
- en: '![Figure 6.5: Mean Absolute Error](img/C12622_06_05.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图6.5：平均绝对误差](img/C12622_06_05.jpg)'
- en: 'Figure 6.5: Mean Absolute Error'
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.5：平均绝对误差
- en: Here, ![](img/C12622_06_Eq3.png) and ![](img/C12622_06_Eq4.png) are the actual
    and predicted values, respectively, for the *i**th* data point.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/C12622_06_Eq3.png)和![](img/C12622_06_Eq4.png)分别是第*i*个数据点的实际值和预测值。
- en: MAE is a **linear scoring function**, which means that it gives each residual
    an equal weight when it aggregates the errors. The MAE can take on any value from
    zero to infinity and is indifferent to the direction (positive or negative) of
    errors. Since these are error metrics, a lower value (as close to zero as possible)
    is usually desirable.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: MAE 是一个**线性评分函数**，意味着在聚合误差时，它给每个残差赋予相等的权重。MAE的值可以从零到无穷大，并且不关心误差的方向（正误差或负误差）。由于这些是误差度量，通常希望其值越低（越接近零越好）。
- en: 'In order to not let the direction of the error affect the performance estimate,
    we can also take the square of the error terms. Taking the mean of the squared
    errors gives us the **Mean Squared Error** (**MSE**):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免误差方向影响性能评估，我们还可以对误差项进行平方处理。对平方误差取平均值即可得到**均方误差**（**MSE**）：
- en: '![Figure 6.6: Mean Squared Error](img/C12622_06_06.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图6.6：均方误差](img/C12622_06_06.jpg)'
- en: 'Figure 6.6: Mean Squared Error'
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.6：均方误差
- en: 'While the MAE has the same units as the target variable, *y*, the units for
    the MSE will be the squared unit of *y*, which may make the MSE slightly less
    interpretable while judging the model in real-world terms. However, if we take
    the square root of the MSE, we get the **Root Mean Squared Error** (**RMSE**):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 MAE 的单位与目标变量 *y* 相同，但 MSE 的单位将是 *y* 的平方单位，这可能使得在实际应用中判断 MSE 变得稍微不太直观。然而，如果我们对
    MSE 取平方根，就能得到 **均方根误差**（**RMSE**）：
- en: '![Figure 6.7: Root Mean Squared Error](img/C12622_06_07.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.7：均方根误差](img/C12622_06_07.jpg)'
- en: 'Figure 6.7: Root Mean Squared Error'
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.7：均方根误差
- en: Since the errors are squared before they are averaged, having even a few error
    values that are high can cause the RMSE value to significantly increase. This
    means that the RMSE is more useful than MAE for judging models in which we want
    to penalize large errors.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在计算平均值之前对误差进行了平方处理，哪怕只有少数几个误差值很高，也会导致 RMSE 值显著增大。这意味着在我们希望惩罚大误差的模型中，RMSE 比
    MAE 更有用。
- en: 'Since MAE and RMSE have the same units as the target variable, it can be hard
    to judge whether a particular value of the MAE or RMSE is good or bad, since there
    is no scale to refer to. A metric that is commonly used to overcome this problem
    is the **R****2** **Score**, or the **R-Squared Score**:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 MAE 和 RMSE 的单位与目标变量相同，因此判断 MAE 或 RMSE 的某个特定值好坏可能很困难，因为没有参考的标准。为了解决这个问题，常用的指标是
    **R²** **分数**，也叫 **R 平方分数**：
- en: '![Figure 6.8: R-Squared score](img/C12622_06_08.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.8：R 平方分数](img/C12622_06_08.jpg)'
- en: 'Figure 6.8: R-Squared score'
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.8：R 平方分数
- en: The R2 score has a lower limit of *-∞* and an upper limit of 1\. The base model
    predicts the target variable to be equal to the mean of the target values in the
    training dataset, that is, where ![](img/C12622_06_Eq41.png) is equal to ![](img/C12622_06_Eq5.png)
    for all values of *i*. Keeping this in mind, a negative value of R2 would be one
    where the trained model makes a prediction that is worse than the mean, and a
    value close to 1 would be achieved if the MSE of the model is close to zero.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: R2 分数的下限为 *-∞*，上限为 1。基础模型预测目标变量等于训练数据集中目标值的均值，即，对于所有 *i* 的值，![](img/C12622_06_Eq41.png)
    等于 ![](img/C12622_06_Eq5.png)。考虑到这一点，R2 的负值表示训练模型的预测结果比均值还要差，而接近 1 的值表示模型的均方误差（MSE）接近零时的情况。
- en: 'Exercise 50: Regression Metrics'
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 50：回归指标
- en: 'In this exercise, we will use the same model and processed dataset that we
    trained in *Activity 14: Stacking with Standalone and Ensemble Algorithms* in
    *Chapter 5*, *Ensemble Modeling*, to calculate regression metrics. We will use
    scikit-learn''s implementation of MAE and MSE:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将使用在 *第 5 章，集成建模* 中的 *活动 14：使用独立和集成算法进行堆叠* 训练过的相同模型和处理过的数据集，来计算回归指标。我们将使用
    scikit-learn 实现的 MAE 和 MSE：
- en: 'Import the metric functions:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入度量函数：
- en: '[PRE4]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Use the loaded model to predict the output on the given data. We will use the
    same features as we did in *Activity 14: Stacking with Standalone and Ensemble
    Algorithms* in *Chapter 5*, *Ensemble Modeling*, and use the model to make a prediction
    on the loaded dataset. The column we saved as *y* is the target variable and we
    will create *X* and *y* accordingly:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用加载的模型对给定数据进行预测。我们将使用与 *第 5 章，集成建模* 中 *活动 14：使用独立和集成算法进行堆叠* 相同的特征，使用该模型对加载的数据集进行预测。我们保存的
    *y* 列是目标变量，我们将相应地创建 *X* 和 *y*：
- en: '[PRE5]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Calculate the MAE, RMSE, and R2 scores. Let''s print the values of the MAE
    and the RMSE from the predicted values. Also print the R2 score for the model:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算 MAE、RMSE 和 R2 分数。我们将打印预测值的 MAE 和 RMSE 值，并打印模型的 R2 分数：
- en: '[PRE6]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output will be as follows:'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 6.9: Scores](img/C12622_06_09.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.9：分数](img/C12622_06_09.jpg)'
- en: 'Figure 6.9: Scores'
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.9：分数
- en: We can see that the RMSE is much higher than the MAE. This shows that there
    are some data points where the residuals are particularly high, which is being
    highlighted by the larger RMSE value. But the R2 score is very close to 1, indicating
    that the model actually has close to ideal performance compared to a base model,
    which would predict a mean value.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到 RMSE 明显高于 MAE。这表明某些数据点的残差特别大，这在较大的 RMSE 值中得到了突出表现。但 R2 分数接近 1，说明该模型相比于基础模型（基础模型预测的是均值）表现得几乎理想。
- en: Classification
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类
- en: For an input variable, *X*, a classification task gives us a predicted value,
    ![](img/C12622_06_Eq12.png), which can take on a limited set of values (two in
    the case of binary classification problems). Since the ideal scenario would be
    to predict a class for each data point that is the same as the actual class, there
    is no measure of how *close* or *far* the predicted class is from the actual class.
    Therefore, to judge the model's performance, it would be as simple as determining
    whether or not the model predicted the class correctly.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个输入变量*X*，分类任务给出了一个预测值，![](img/C12622_06_Eq12.png)，它可以取有限的几个值（在二分类问题中为两个值）。由于理想的情况是预测每个数据点的类别与实际类别相同，因此没有衡量*预测类别与实际类别*之间距离的指标。因此，要评判模型的表现，简单的方法就是判断模型是否正确地预测了类别。
- en: 'Judging a classification model''s performance can be done in two ways: using
    numerical metrics, or by plotting a curve and looking at the shape of the curve.
    Let''s explore both of these in greater detail.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 判断分类模型表现的方法有两种：使用数值指标，或通过绘制曲线并观察曲线的形状。让我们更详细地探讨这两种方法。
- en: '**Numerical Metrics**'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值指标**'
- en: 'The simplest and most basic way to judge the performance of the model is to
    calculate the proportion of the correct predictions to the total number of predictions,
    which gives us the **accuracy**:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 判断模型表现最简单且基本的方法是计算正确预测占总预测数的比例，这给出了**准确率**：
- en: '![Figure 6.10: Accuracy](img/C12622_06_10.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图6.10：准确率](img/C12622_06_10.jpg)'
- en: 'Figure 6.10: Accuracy'
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.10：准确率
- en: Although the accuracy metric is appropriate no matter the number of classes,
    the next few metrics are discussed keeping in mind a binary classification problem.
    Additionally, accuracy may not be the best metric to judge the performance of
    a classification task in many cases.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管准确率指标适用于任何类别数量的情况，但接下来的几个指标将以二分类问题为背景进行讨论。此外，准确率在许多情况下可能不是评估分类任务表现的最佳指标。
- en: 'Let''s look at an example of fraud detection: say the problem statement is
    to detect whether a particular email is fraudulent or not. Our dataset in this
    case is highly skewed (or imbalanced, that is, there are many more data points
    belonging to one class compared to the other class), with 100 out of 10,000 emails
    (1% of the total) having been classified as fraudulent (having class 1). Say we
    build two models:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个欺诈检测的例子：假设问题是检测一封邮件是否欺诈。在这种情况下，我们的数据集高度倾斜（或不平衡，也就是说，一类数据点的数量远大于另一类数据点），在10,000封邮件中有100封（总数的1%）被分类为欺诈（属于类别1）。假设我们构建了两个模型：
- en: The first model simply predicts each email as not being fraud, that is, each
    of the 10,000 emails is classified with the class 0\. In this case, 9,900 of the
    10,000 were classified correctly, which means the model has 99% accuracy.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个模型简单地将每封邮件预测为非欺诈，也就是说，10,000封邮件中的每一封都被归类为类别0。在这种情况下，10,000封邮件中有9,900封被正确分类，这意味着该模型的准确率为99%。
- en: The second model predicts the 100 fraud emails as being fraud, but also predicts
    another 100 emails incorrectly as fraud. In this case as well, 100 data points
    were misclassified out of 10,000, and the model has an accuracy of 99%.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个模型将100封欺诈邮件预测为欺诈，但同时也错误地将另外100封邮件预测为欺诈。在这种情况下，同样有100个数据点在10,000封邮件中被误分类，模型的准确率为99%。
- en: 'How do we compare these two models? The purpose of building a fraud detection
    model is to allow us to know *how well the fraud was detected*: it matters more
    that the fraudulent emails were correctly classified than if non-fraud emails
    were classified as fraudulent. Although both the models were equally high in accuracy,
    the second was actually more effective than the first.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何比较这两种模型？构建欺诈检测模型的目的是让我们了解*欺诈检测的效果*：比起非欺诈邮件被误分类为欺诈邮件，正确分类欺诈邮件更为重要。尽管这两个模型的准确率相同，但第二个模型实际上比第一个更有效。
- en: 'Since this cannot be captured using accuracy, we need the **confusion matrix**,
    a table with four different combinations of predicted and actual values that essentially
    gives us a summary of the prediction results of a classification problem:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 由于无法仅通过准确率捕获这一点，我们需要**混淆矩阵**，它是一个包含四种不同的预测值和实际值组合的表格，本质上为我们提供了分类问题预测结果的总结：
- en: '![Figure 6.11: Confusion matrix](img/C12622_06_11.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图6.11：混淆矩阵](img/C12622_06_11.jpg)'
- en: 'Figure 6.11: Confusion matrix'
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.11：混淆矩阵
- en: 'Here''s what the terms used in the matrix mean:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是矩阵中使用的术语的含义：
- en: '**True positives** and **true negatives**: These are the counts of the correctly
    predicted data points in the positive and negative classes respectively.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正例**和**真负例**：这些是分别在正类和负类中被正确预测的数据点数量。'
- en: '**False positives**: These are also known as **Type 1 errors** and refer to
    the count of the data points that actually belong to the negative class but were
    predicted to be positive. Continuing from the previous example, a false positive
    case would be if a normal email is classified as a fraudulent email.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假正例**：也称为**类型 1 错误**，指的是实际上属于负类但被预测为正类的数据点数量。从前面的例子继续，如果一个正常的邮件被分类为欺诈邮件，则为假正例。'
- en: '**False negatives**: These are also known as **Type 2 errors** and refer to
    the count of the data points that actually belong to the positive class but were
    predicted to be negative. An example of a false negative case would be if a fraudulent
    email was classified as not being one.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假负例**：也称为**类型 2 错误**，指的是实际上属于正类但被预测为负类的数据点数量。假负例的例子是，如果一封欺诈邮件被分类为非欺诈邮件。'
- en: 'Two extremely important metrics can be derived from a confusion matrix: **precision**
    and **recall**.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从混淆矩阵中可以推导出两个极其重要的指标：**精度**和**召回率**。
- en: '![Figure 6.12: Precision](img/C12622_06_12.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.12: 精度](img/C12622_06_12.jpg)'
- en: 'Figure 6.12: Precision'
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.12: 精度'
- en: '![Figure 6.13: Recall](img/C12622_06_13.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.13: 召回率](img/C12622_06_13.jpg)'
- en: 'Figure 6.13: Recall'
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.13: 召回率'
- en: While precision tells us how many of the actual positives were correctly predicted
    to be positive (from the results the model says are relevant, how many are actually
    relevant?), recall tells us how many of the predicted positives were actually
    positive (from the real relevant results, how many are included in the model's
    list of relevant results?). These two metrics are especially useful when there
    is an imbalance between the two classes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 精度告诉我们有多少实际的正例被正确地预测为正例（从模型认为相关的结果中，有多少实际是相关的？），而召回率告诉我们有多少预测为正例的结果实际上是正例（从真实的相关结果中，有多少被模型列入相关结果列表？）。这两个指标在类不平衡时尤其有用。
- en: 'There is usually a trade-off between the precision and recall of a model: if
    you have to recall all the relevant results, the model will generate more results
    that are not accurate, hence lowering the precision. On the other hand, having
    a higher percentage of relevant results from the generated results would involve
    including as few results as possible. In most cases, you would give a higher priority
    to either the precision or the recall, and this entirely depends on the problem
    statement. For example, since it matters more that all the fraudulent emails are
    correctly classified, recall would be an important metric that would need to be
    maximized.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的精度和召回率通常存在权衡：如果必须召回所有相关的结果，模型将生成更多不准确的结果，从而降低精度。另一方面，要确保生成的结果中有更高比例的相关结果，就需要尽量少生成结果。大多数情况下，你会优先考虑精度或召回率，这完全取决于问题的具体要求。例如，由于确保所有欺诈性邮件被正确分类更为重要，因此召回率将是一个需要最大化的关键指标。
- en: 'The next question that arises is how we take both precision and recall to evaluate
    our model using a single number instead of balancing two separate metrics. The
    **F****1** **score** combines the two into a single number that can be used as
    a fair judge of the model and is equal to the harmonic mean of precision and recall:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的问题是，如何使用一个单一的数值来评估模型，综合考虑精度和召回率，而不是单独平衡这两个指标。**F1** **分数**将两者合并成一个单一的数值，这个数值可以作为模型的公正评判标准，并且等于精度和召回率的调和平均值：
- en: '![Figure 6.14: F1 Score](img/C12622_06_14.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.14: F1 分数](img/C12622_06_14.jpg)'
- en: 'Figure 6.14: F1 Score'
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.14: F1 分数'
- en: 'The value of the F1 score will always lie between 0 (if either precision or
    recall is zero) and 1 (if both precision and recall are 1). The higher the score,
    the better the model''s performance is said to be. The F1 score gives equal weight
    to both measures and is a specific example of the general Fβ metric, where β can
    be adjusted to give more weight to either recall or precision using the following
    formula:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: F1 分数的值总是介于 0（如果精度或召回率为零）和 1（如果精度和召回率都为 1）之间。分数越高，说明模型的性能越好。F1 分数对两个指标赋予相等的权重，并且是一般
    Fβ 指标的一个特例，其中 β 可以调整，以便根据以下公式为召回率或精度赋予更多权重：
- en: '![Figure 6.15: F beta score](img/C12622_06_15.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.15: F β 值](img/C12622_06_15.jpg)'
- en: 'Figure 6.15: F beta score'
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.15: F β 值'
- en: A value of *β* *< 1* focuses more on precision, while taking *β* *> 1* focuses
    more on recall. The F1 score takes *β* *= 1* to give both equal weight.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*β* *< 1* 时，更注重精确度，而 *β* *> 1* 时，更注重召回率。F1 分数采用 *β* *= 1*，使两者权重相等。'
- en: '**Curve Plots**'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**曲线图**'
- en: Sometimes, instead of predicting the class, we have the class probabilities
    at our disposal. Say, in a binary classification task, the class probabilities
    of both the positive (class 1) and negative (class 0) classes will always add
    up to unity (or 1), which means that if we take the classification probability
    as equal to the probability of class 1 and apply a threshold, we can essentially
    use it as a cut-off value to either round up (to 1) or down (to 0), which will
    give the output class.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们不是预测类别，而是利用类别的概率值。举例来说，在一个二分类任务中，正类（类 1）和负类（类 0）的类别概率之和始终为 1（或 统一的 1），这意味着如果我们将分类概率视为类
    1 的概率，并应用一个阈值，我们可以本质上将其作为一个截止值，来进行四舍五入（为 1）或下舍（为 0），从而得到输出的类别。
- en: Usually, by varying the threshold, we can get data points that have classification
    probabilities closer to 0.5 from one class to another. For example, with a threshold
    of 0.5, a data point having a probability of 0.4 would be assigned class 0 and
    a data point having probability 0.6 would be assigned class 1\. But if we change
    the threshold to 0.35 or 0.65, both those data points would be classified as 1
    or 0.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，通过改变阈值，我们可以得到分类概率接近 0.5 的数据点，这些数据点从一个类别转到另一个类别。例如，当阈值为 0.5 时，具有 0.4 概率的数据点会被分配为类
    0，而具有 0.6 概率的数据点会被分配为类 1。但如果我们将阈值改为 0.35 或 0.65，这两个数据点都会被分类为 1 或 0。
- en: 'As it turns out, varying the probability changes the precision and recall values
    and this can be captured by plotting the **precision-recall curve**. The plot
    has precision on the *Y* axis and recall on the *X* axis, and for a range of thresholds
    starting from 0 to 1 plots each *(recall, precision)* point. Connecting these
    points gives us the curve. The following graph shows an example:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，改变概率会改变精确度和召回率的值，这可以通过绘制**精确度-召回率曲线**来捕捉。图表的*Y* 轴表示精确度，*X* 轴表示召回率，对于从 0
    到 1 的一系列阈值，图表绘制每一个（召回率，精确度）点。连接这些点便得到曲线。以下图显示了一个例子：
- en: '![Figure 6.16: Precision-recall curve](img/C12622_06_16.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.16：精确度-召回率曲线](img/C12622_06_16.jpg)'
- en: 'Figure 6.16: Precision-recall curve'
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.16：精确度-召回率曲线
- en: We know that in an ideal case, the values of precision and recall will be unity.
    This means that upon increasing the threshold from 0 to 1, the precision would
    stay constant at 1, but the recall would increase from 0 to 1 as more and more
    (relevant) data points would be classified correctly. Thus, in an ideal case,
    the precision-recall curve would essentially just be a square and the **area under
    the curve** (**AUC**) would be equal to one.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，在理想情况下，精确度和召回率的值将为 1。这意味着，当阈值从 0 增加到 1 时，精确度将保持为 1，但召回率会从 0 增加到 1，因为越来越多（相关的）数据点将被正确分类。因此，在理想情况下，精确度-召回率曲线基本上将是一个正方形，且**曲线下面积**（**AUC**）将等于
    1。
- en: Thus, we can see that, as with the F1 score, the AUC is another metric derived
    from the precision and recall behavior that uses a combination of their values
    to evaluate the performance of the model. We want the model to achieve an AUC
    as high and close to 1 as possible.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到，和 F1 分数一样，AUC 是另一个从精确度和召回率行为中得出的指标，它结合了精确度和召回率的值来评估模型的性能。我们希望模型的 AUC
    尽可能高，接近 1。
- en: 'The other main visualization technique for showing the performance of a classification
    model is the **Receiver Operating Characteristic** (**ROC**) curve. The ROC curve
    plots the relationship between the **True Positive Rate** (**TPR**) on the *Y*
    axis and the **False Positive Rate** (**FPR**) on the *X* axis across a varying
    classification probability threshold. TPR is exactly the same as the recall (and
    is also known as the **sensitivity** of the model), and FPR is an equal complement
    of the **specificity** (that is, *1 - FPR = Sensitivity*); both can be derived
    from the confusion matrix using these formulae:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 显示分类模型性能的另一个主要可视化技术是**接收者操作特征**（**ROC**）曲线。ROC 曲线绘制了**真正例率**（**TPR**）在*Y* 轴上的关系，以及**假正例率**（**FPR**）在*X*
    轴上的关系，随着分类概率阈值的变化。TPR 恰好等于召回率（也称为模型的**灵敏度**），而 FPR 是**特异性**的补集（即 *1 - FPR = 灵敏度*）；这两者都可以通过混淆矩阵使用以下公式推导：
- en: '![Figure 6.17: True positive rate](img/C12622_06_17.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.17：真正例率](img/C12622_06_17.jpg)'
- en: 'Figure 6.17: True positive rate'
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.17：真正例率
- en: '![Figure 6.18: False positive rate'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.18：假阳性率](img/C12622_06_18.jpg)'
- en: '](img/C12622_06_18.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12622_06_18.jpg)'
- en: 'Figure 6.18: False positive rate'
  id: totrans-127
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.18：假阳性率
- en: 'The following diagram shows an example of an ROC curve, plotted in the same
    way as the precision-recall curve: by varying the probability threshold such that
    each point on the curve represents a *(TPR, FPR)* data point corresponding to
    a specific probability threshold.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个ROC曲线的示例，其绘制方式与精度-召回曲线相同：通过改变概率阈值，使得曲线上的每个点代表一个*(TPR, FPR)*数据点，对应于一个特定的概率阈值。
- en: '![Figure 6.19: ROC curve](img/C12622_06_19.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图6.19：ROC曲线](img/C12622_06_19.jpg)'
- en: 'Figure 6.19: ROC curve'
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.19：ROC曲线
- en: ROC curves are more useful when the classes are fairly balanced, since they
    tend to present an overly optimistic picture of the model on datasets with a class
    imbalance via their use of true negatives in the false positive rate in the ROC
    curve (which is not present in the precision-recall curve).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当类别比较平衡时，ROC曲线更为有用，因为它们往往会在类别不平衡的数据集上呈现过于乐观的模型表现，尤其是在ROC曲线中的假阳性率使用了真正负例（而精度-召回曲线中没有此项）。
- en: 'Exercise 51: Classification Metrics'
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习51：分类指标
- en: 'In this exercise, we will use the random forest model we trained in *Chapter
    5*, *Ensemble Modeling,* and use its predictions to generate the confusion matrix
    and calculate the precision, recall, and F1 scores, as a way of rating our model.
    We will use scikit-learn''s implementations to calculate these metrics:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用在*第5章*《集成建模》中训练的随机森林模型，并使用其预测生成混淆矩阵，计算精度、召回率和F1得分，以此来评估我们的模型。我们将使用scikit-learn的实现来计算这些指标：
- en: 'Import the relevant libraries and functions:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入相关的库和函数：
- en: '[PRE7]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Use the model to predict classes for all data points. We will use the same
    features as we did earlier and use the random forest classifier to make a prediction
    on the loaded dataset. Every classifier in scikit-learn has a `.predict_proba()`
    function, which we will use here along with the standard `.predict()` function
    to give us the class probabilities and the classes respectively:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型对所有数据点进行类别预测。我们将使用与之前相同的特征，并使用随机森林分类器对加载的数据集进行预测。scikit-learn中的每个分类器都有一个`.predict_proba()`函数，我们将在这里使用它，并结合标准的`.predict()`函数来分别提供类别概率和预测的类别：
- en: '[PRE8]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Calculate the accuracy:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算准确率：
- en: '[PRE9]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output will be as follows:'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 6.20: Accuracy score](img/C12622_06_20.jpg)'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图6.20：准确率得分](img/C12622_06_20.jpg)'
- en: 'Figure 6.20: Accuracy score'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.20：准确率得分
- en: 'Print the confusion matrix:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印混淆矩阵：
- en: '[PRE10]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output will be as follows:'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 6.21: Confusion matrix](img/C12622_06_21.jpg)'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图6.21：混淆矩阵](img/C12622_06_21.jpg)'
- en: 'Figure 6.21: Confusion matrix'
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.21：混淆矩阵
- en: Here, we can see that the model seems to have a high number of false negatives,
    which means that we can expect the recall value for this model to be extremely
    low. Similarly, since the count of the false positives is just one, we can expect
    the model to have high precision.
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到模型似乎有较高的假阴性数量，这意味着我们可以预期该模型的召回率将非常低。类似地，由于假阳性的数量仅为一个，我们可以预期模型将具有较高的精度。
- en: 'Calculate the precision and recall:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算精度和召回率：
- en: '[PRE11]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output will be as follows:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 6.22: Precision and recall scores](img/C12622_06_22.jpg)'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图6.22：精度和召回得分](img/C12622_06_22.jpg)'
- en: 'Figure 6.22: Precision and recall scores'
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.22：精度和召回得分
- en: 'Calculate the F1 score:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算F1得分：
- en: '[PRE12]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output will be as follows:'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 6.23: F1 score](img/C12622_06_23.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图6.23：F1得分](img/C12622_06_23.jpg)'
- en: 'Figure 6.23: F1 score'
  id: totrans-158
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.23：F1得分
- en: We can see that, since the recall is extremely low, this is affecting the F1
    score as well, making it close to zero.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，由于召回率极低，这也影响了F1得分，使其接近零。
- en: Now that we have talked about the metrics we can use to measure the predictive
    performance of the model, let's talk about validation strategies, in which we
    will use a metric to evaluate the performance of the model in different cases
    and situations.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了可以用来衡量模型预测性能的指标，让我们谈谈验证策略，我们将使用这些指标来评估模型在不同情况下的表现。
- en: Splitting the Dataset
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集划分
- en: A common mistake made when determining how well a model is performing is to
    calculate the prediction error on the data that the model was trained on and conclude
    that a model performs really well on the basis of a high prediction accuracy on
    the training dataset.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估模型表现时，一个常见的错误是计算模型在训练数据上的预测误差，并基于训练数据集上的高预测准确率得出模型表现良好的结论。
- en: This means that we are trying to test the model on data that the model has already
    *seen*, that is, the model has already learned the behavior of the training data
    because it was exposed to it—if asked to predict the behavior of the training
    data again, it would undoubtedly perform well. And the better the performance
    on the training data, the higher the chances that the model knows the data *too
    well*, so much so that it has even learned the noise and behavior of outliers
    in the data.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们正在尝试在模型已经*见过*的数据上进行测试，也就是说，模型已经学到了训练数据的行为，因为它曾经接触过这些数据——如果要求模型再次预测训练数据的行为，它无疑会表现得很好。而且，模型在训练数据上的表现越好，就越有可能意味着模型对数据*了解得过于透彻*，甚至学会了数据中的噪声和异常值的行为。
- en: Now, high training accuracy results in a model having high variance, as we saw
    in the previous chapter. In order to get an unbiased estimate of the model's performance,
    we need to find its prediction accuracy on data it has not already been exposed
    to during training. This is where the hold-out dataset comes into the picture.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，高训练准确度会导致模型具有高方差，正如我们在前一章中看到的那样。为了获得模型性能的无偏估计，我们需要找出它在训练过程中没有接触过的数据上的预测准确度。这时，留出数据集就显得非常重要。
- en: Hold-out Data
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 留出数据
- en: The **hold-out dataset** refers to a sample of the dataset that has been held
    back from training the model on and is essentially *unseen* by the model. The
    hold-out data points will likely contain outliers and noisy data points that behave
    differently from those in the training dataset, given that noise is random. Thus,
    calculating the performance on the hold-out dataset would allow us to validate
    whether the model is overfitting or not, as well as giving us an unbiased view
    of the model's performance.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**留出数据集**是指从训练数据中剥离出的样本，这部分数据在训练过程中未被模型接触，因此它对模型来说是*未见过*的。由于噪声是随机的，留出数据点很可能包含异常值和噪声数据，这些数据的行为与训练数据集中的数据有所不同。因此，在留出数据集上计算模型的性能，可以帮助我们验证模型是否过拟合，并为我们提供对模型性能的无偏视角。'
- en: 'We began our previous chapter by splitting the Titanic dataset into training
    and validation sets. What is this validation dataset, and how is it different
    from a test dataset? We often see the terms validation set and test set used interchangeably—although
    they both characterize a hold-out dataset, there are some differences in purpose:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一章开始时将泰坦尼克号数据集拆分为训练集和验证集。那么，什么是验证数据集，它与测试数据集有何不同呢？我们经常看到“验证集”和“测试集”这两个术语互换使用——虽然它们都指代留出数据集，但在目的上存在一些差异：
- en: '**Validation data**: After the model learns from the training data, its performance
    is evaluated on the validation dataset. However, in order to get the model to
    perform the best it can, we need to fine-tune the model and iteratively evaluate
    the updated model''s performance repeatedly, and this is done on the validation
    dataset. The fine-tuned version of the model that performs best on the validation
    dataset is usually chosen to be the final model.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证数据**：在模型从训练数据中学习后，会在验证数据集上评估其性能。然而，为了让模型发挥最佳表现，我们需要对模型进行微调，并反复迭代评估更新后的模型性能，这一过程是在验证数据集上进行的。通常，表现最好的微调版本模型会被选为最终模型。'
- en: The model, thus, is exposed to the validation dataset multiple times, at each
    iteration of improvement, although does not essentially *learn* from the data.
    It can be said that the validation set does affect the model, although indirectly.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，模型在每次改进的迭代过程中都会接触到验证数据集，尽管本质上并没有*从数据中学习*。可以说，验证集间接地影响了模型。
- en: '**Test data**: The final model that was chosen is now evaluated on the test
    dataset. The performance measured on this dataset will be an unbiased measure
    that is reported as the final performance metric of the model. This final evaluation
    is done once the model has been completely trained on the combined training and
    validation datasets. There is no training or updating of the model performed after
    this metric has been calculated.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试数据**：选择的最终模型现在在测试数据集上进行评估。在该数据集上测得的性能将是一个无偏的度量，作为模型的最终性能指标。这一最终评估是在模型已经在合并后的训练集和验证集上完全训练后进行的。此后，模型不再进行训练或更新。'
- en: This means that the model is exposed to the test dataset only once, when calculating
    the final performance metric.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这意味着模型仅在计算最终性能指标时暴露于测试数据集一次。
- en: 'It should be kept in mind that the validation dataset should never be used
    to evaluate the final performance of the model: our estimate of the true performance
    of a model will be positively biased if the model has seen and been modified subsequently
    in an effort to specifically improve the performance on the validation set.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 应当记住，验证数据集绝不应被用来评估模型的最终性能：如果模型已经看到并被修改以特定提高在验证集上的表现，那么我们对模型真实性能的估计会存在正偏。
- en: 'Having a single hold-out validation dataset does have some limitations, however:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，单一的保留验证数据集确实存在一些局限性：
- en: Since the model is only validated once in each iteration of improvement, it
    might be difficult to capture the uncertainty in prediction using this single
    evaluation.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于模型在每次改进的迭代中只进行一次验证，因此使用这个单一评估可能难以捕捉预测中的不确定性。
- en: Dividing the data into training and validation sets decreases the size of the
    data upon which the model is trained, and this can lead to the model having high
    variance.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据划分为训练集和验证集会减少训练模型时使用的数据量，这可能导致模型具有较高的方差。
- en: The final model may *overfit* to this validation set since it was tuned in order
    to maximize performance on this dataset.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终模型可能会*过拟合*此验证集，因为它是根据此数据集的最大性能进行调优的。
- en: These challenges can be overcome if we use a validation technique called K-fold
    cross-validation instead of using a single validation dataset.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用称为K折交叉验证的验证技术，而不是仅使用单一验证数据集，这些挑战是可以克服的。
- en: K-Fold Cross-Validation
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: K折交叉验证
- en: 'K-fold cross-validation is a validation technique that helps us get an unbiased
    estimate of the model''s performance by essentially rotating the validation set
    in *k* folds. This is how it works:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: K折交叉验证是一种验证技术，它通过在*k*折中轮换验证集，帮助我们得到模型性能的无偏估计。其工作原理如下：
- en: First, we choose the value of *k* and divide the data into *k* subsets.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们选择*k*的值，并将数据划分为*k*个子集。
- en: Then, we set aside the first subset as the validation set and use the remaining
    data to train the model.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将第一子集作为验证集，剩余的数据用于训练模型。
- en: We measure the performance of the model on the validation subset.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在验证子集上衡量模型的性能。
- en: Then, we set aside the second subset as the validation subset and repeat the
    process.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将第二子集作为验证子集，并重复这一过程。
- en: Once we have done this *k* times, we aggregate the performance metric values
    over all the folds and present the final metric.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们完成这*k*次操作后，我们将所有折叠的性能度量值聚合，并呈现最终指标。
- en: 'The following figure explains this visually:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 下图直观地解释了这一过程：
- en: '![Figure 6.24: K-fold cross-validation](img/C12622_06_24.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图6.24：K折交叉验证](img/C12622_06_24.jpg)'
- en: 'Figure 6.24: K-fold cross-validation'
  id: totrans-187
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.24：K折交叉验证
- en: Although this method of validation is more computationally expensive, the benefits
    outweigh the costs. This approach makes sure that the model is validated on each
    example in the training dataset exactly once and that the performance estimate
    we achieve in the end is not biased in favor of a validation dataset, especially
    in the case of small datasets. A special case is **leave-one-out** cross-validation,
    where the value of *k* is equal to the number of data points.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种验证方法计算开销较大，但其优点超过了成本。这种方法确保模型在训练数据集中的每个示例上都得到验证一次，且最终得到的性能估计不偏向于验证集，尤其是在数据集较小的情况下。一个特例是**留一法**交叉验证，其中*k*的值等于数据点的数量。
- en: Sampling
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 采样
- en: 'Now that we''ve looked at the strategies for splitting the dataset for training
    and validating the model, let''s discuss how to allocate data points to these
    splits. There are two ways we can sample the data into the splits, and these are
    as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了用于划分数据集以进行模型训练和验证的策略，让我们讨论如何将数据点分配到这些划分中。我们可以通过两种方式对数据进行采样，这两种方式如下：
- en: '**Random sampling**: This is as simple as allocating random samples from the
    overall dataset into the training, validation, and/or test datasets. Randomly
    splitting the data only works when all the data points are independent of each
    other. For example, random splitting would not be the way to go if the data was
    in the form of a time-series, since the data points are ordered, and each depends
    on the previous one. Randomly splitting the data would destroy that order and
    not take into account this dependence.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机采样**：这就是将整体数据集中的随机样本分配到训练集、验证集和/或测试集的过程。随机划分数据只有在所有数据点彼此独立时才有效。例如，如果数据是时间序列形式，随机划分就不适用，因为数据点是有序的，每个数据点都依赖于前一个数据点。随机划分数据会破坏这个顺序，忽视这种依赖关系。'
- en: '**Stratified sampling**: This is a way to ensure that each subset has the same
    distribution of values of the target variable as the original dataset. For example,
    if the original dataset has two classes in the ratio 3:7, stratified sampling
    ensures that each subset will also contain the two classes in the ratio 3:7.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分层采样**：这是一种确保每个子集的目标变量的分布与原始数据集相同的方法。例如，如果原始数据集的两个类别的比例是 3:7，那么分层采样确保每个子集中的两个类别的比例也是
    3:7。'
- en: Stratified sampling is important since testing our model on a dataset with a
    different distribution of target values from the dataset on which the model was
    trained can give us a performance estimate that is not representative of the model's
    actual performance.
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分层采样很重要，因为在数据集的目标值分布与训练模型时的数据集不同的情况下，测试模型可能会得到一个无法代表模型实际性能的结果估计。
- en: The size of the train, validation, and test samples also plays an important
    role in the model evaluation process. Keeping aside a large dataset to test the
    final performance of the model on will help us get an unbiased estimate of the
    model's performance and reduce the variance in prediction, but if the test set
    is so large that it compromises the model's ability to train due to a lack of
    training data, this will severely affect the model as well. This is a consideration
    that is especially relevant for smaller datasets.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集、验证集和测试集的样本大小在模型评估过程中也起着重要作用。将一个较大的数据集留作最终模型性能测试，可以帮助我们获得对模型性能的无偏估计，并减少预测的方差，但如果测试集过大，以至于由于缺少训练数据影响了模型的训练能力，这将严重影响模型的表现。这个考虑特别适用于较小的数据集。
- en: 'Exercise 52: K-Fold Cross-Validation with Stratified Sampling'
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 52：使用分层采样的 K 折交叉验证
- en: 'In this exercise, we''ll implement K-fold cross-validation with stratified
    sampling on scikit-learn''s random forest classifier. The `StratifiedKFold` class
    in scikit-learn implements a combination of the cross-validation and sampling
    together in one class, and we will use this in our exercise:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将实现基于分层采样的 K 折交叉验证，使用 scikit-learn 的随机森林分类器。scikit-learn 中的 `StratifiedKFold`
    类实现了交叉验证和采样的结合，我们将在练习中使用它：
- en: 'Import the relevant classes. We will import scikit-learn''s `StratifiedKFold`
    class, which is a variation of `KFold` that returns stratified folds, along with
    the `RandomForestClassifier`:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入相关的类。我们将导入 scikit-learn 的 `StratifiedKFold` 类，这是 `KFold` 的一种变体，返回分层折叠，同时导入
    `RandomForestClassifier`：
- en: '[PRE13]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Prepare data for training and initialize the k-fold object. Here, we will use
    five folds to evaluate the model, and hence will give the `n_splits` parameter
    a value of `5`:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为训练准备数据并初始化 k 折交叉验证对象。在这里，我们将使用五个折叠来评估模型，因此将 `n_splits` 参数设置为 `5`：
- en: '[PRE14]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Train a classifier for each fold and record the score. The functioning of the
    `StratifiedKFold` class is similar to the `KFold` class that we used in the previous
    chapter, in *Exercise 48: Building a Stacked Model*: for each of the five folds,
    we will train on other four folds and predict on the fifth fold, and find the
    accuracy score for the predictions on the fifth fold. As we saw in the last chapter,
    the `skf.split()` function takes the dataset to split as input and returns an
    iterator comprising the index values used to subdivide the training data for training
    and validation for each row:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对每个折叠训练一个分类器并记录得分。`StratifiedKFold` 类的功能类似于我们在上一章中使用的 `KFold` 类，*练习 48：构建堆叠模型*：对于五个折叠中的每一个，我们将在其他四个折叠上进行训练，并在第五个折叠上进行预测，找到第五个折叠上的准确率得分。正如我们在上一章中看到的，`skf.split()`
    函数以数据集为输入，返回一个迭代器，包含用于划分训练数据进行训练和验证的每行索引值：
- en: '[PRE15]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output will be as follows:'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 6.25: Scores using random forest classifier](img/C12622_06_25.jpg)'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 6.25：使用随机森林分类器的得分](img/C12622_06_25.jpg)'
- en: 'Figure 6.25: Scores using random forest classifier'
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.25：使用随机森林分类器的得分
- en: 'Print the aggregated accuracy score:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印汇总的准确率得分：
- en: '[PRE16]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output will be as follows:'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 6.26: Mean accuracy score](img/C12622_06_26.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.26：平均准确率得分](img/C12622_06_26.jpg)'
- en: 'Figure 6.26: Mean accuracy score'
  id: totrans-210
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.26：平均准确率得分
- en: Performance Improvement Tactics
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能提升策略
- en: 'Performance improvement for supervised machine learning models is an iterative
    process, and a continuous cycle of updating and evaluation is usually required
    to get the perfect model. While the previous sections in this chapter dealt with
    the evaluation strategies, this section will talk about model updating: we will
    discuss some ways we can determine what our model needs to give it that performance
    boost, and how to make that change in our model.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 监督式机器学习模型的性能提升是一个迭代过程，通常需要持续更新和评估周期才能得到完美的模型。虽然本章前面的部分讨论了评估策略，本节将讨论模型更新：我们将探讨如何确定模型所需的性能提升，并如何在模型中做出这些改变。
- en: Variation in Train and Test Error
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练误差和测试误差的变化
- en: In the previous chapter, we introduced the concepts of underfitting and overfitting,
    and mentioned a few ways to overcome them, later introducing ensemble models.
    But we didn't talk about how to identify whether our model was underfitting or
    overfitting to the training data.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了欠拟合和过拟合的概念，并提到了几种克服它们的方法，随后介绍了集成模型。但是我们没有讨论如何识别我们的模型是否出现了欠拟合或过拟合的情况。
- en: It's usually useful to look at the learning and validation curves.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 通常来说，查看学习曲线和验证曲线是很有用的。
- en: '**Learning Curve**'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习曲线**'
- en: The learning curve shows the variation in the training and validation error
    with the training data increasing in size. By looking at the shape of the curves,
    we can get a good idea of whether or not more data will benefit the modeling and
    possibly improve the model's performance.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 学习曲线展示了随着训练数据量的增加，训练误差和验证误差的变化。通过观察曲线的形状，我们可以大致判断增加更多数据是否有利于建模，并可能改善模型的表现。
- en: 'Let''s look at the following figure: the dotted curve represents the validation
    error and the solid curve represents the training error. The plot on the left
    shows the two curves converging to an error value that is quite high. This means
    that the model has a high bias and adding more data isn''t likely to affect the
    model performance. So instead of wasting time and money collecting more data,
    all we need to do is increase model complexity.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下以下图表：虚线曲线表示验证误差，实线曲线表示训练误差。左侧的图表显示这两条曲线趋向于一个相对较高的误差值。这意味着模型存在较高的偏差，增加更多的数据很可能不会对模型的表现产生影响。因此，与其浪费时间和金钱去收集更多的数据，我们只需要增加模型的复杂度。
- en: 'On the other hand, the plot on the right shows a high difference between the
    training and test errors, even with an increasing number of data points in the
    training set. The wide gap indicates a high variance in the system, which means
    the model is overfitting. In this case, adding more data points will probably
    help the model generalize better:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，右侧的图表显示，即使训练集中的数据点数量增加，训练误差和测试误差之间的差距依然很大。这个宽广的差距表示系统的方差很高，也意味着模型过拟合。在这种情况下，增加更多的数据点可能有助于模型更好地进行泛化：
- en: '![Figure 6.27: Learning curve for increasing data size](img/C12622_06_27.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.27：数据量增加的学习曲线](img/C12622_06_27.jpg)'
- en: 'Figure 6.27: Learning curve for increasing data size'
  id: totrans-221
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.27：数据量增加的学习曲线
- en: 'But how will we recognize the perfect learning curve? When we have a model
    with low bias and low variance, we will see a curve like the one shown in the
    following figure. It shows a low training error (low bias) as well as a low gap
    between the validation and training curves (low variance) as they converge. In
    practice, the best possible learning curves we can see are those that converge
    to the value of some irreducible error value (which exists due to noise and outliers
    in the dataset):'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我们如何识别完美的学习曲线呢？当我们有一个低偏差和低方差的模型时，我们会看到像下面图示那样的曲线。它展示了低训练误差（低偏差），以及当验证曲线和训练曲线汇聚时，二者之间的低差距（低方差）。在实际操作中，我们能看到的最好的学习曲线是那些趋于某个不可减少的误差值的曲线（该误差值由于数据集中的噪声和异常值而存在）：
- en: '![Figure 6.28: Variation in training and validation error with an increasing
    training data size for a low bias and variance model](img/C12622_06_28.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.28: 低偏差和低方差模型随着训练数据量增大，训练和验证误差的变化](img/C12622_06_28.jpg)'
- en: 'Figure 6.28: Variation in training and validation error with an increasing
    training data size for a low bias and variance model'
  id: totrans-224
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.28: 低偏差和低方差模型随着训练数据量增大，训练和验证误差的变化'
- en: '**Validation Curve**'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**验证曲线**'
- en: 'As we have discussed previously, the goal of a machine learning model is to
    be able to generalize to unseen data. Validation curves allow us to find the ideal
    point between an underfitted and an overfitted model where the model would generalize
    well. In the previous chapter, we talked a bit about how model complexity affects
    prediction performance: we said that as we move from an overly simplistic to an
    overly complex model, we go from having an underfitted model with high bias and
    low variance to an overfitted model with a low bias and high variance.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，机器学习模型的目标是能够推广到未见过的数据。验证曲线可以帮助我们找到一个欠拟合和过拟合模型之间的理想点，在这个点上，模型能够良好地进行推广。在上一章中，我们讨论了模型复杂度如何影响预测性能：我们说，当我们从一个过于简单的模型走向一个过于复杂的模型时，我们会从一个具有高偏差和低方差的欠拟合模型，过渡到一个具有低偏差和高方差的过拟合模型。
- en: A validation curve shows the variation in training and validation error with
    a varying value of a model parameter that has some degree of control over the
    model's complexity—this could be the degree of the polynomial in linear regression,
    or the depth of a decision tree classifier.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 验证曲线显示了随着模型参数值变化，训练误差和验证误差的变化，这些模型参数在某种程度上控制着模型的复杂度——这可能是线性回归中的多项式的次数，或者是决策树分类器的深度。
- en: '![Figure 6.29: Variation in training and validation with increasing model complexity](img/C12622_06_29.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.29: 随着模型复杂度增加，训练和验证的变化](img/C12622_06_29.jpg)'
- en: 'Figure 6.29: Variation in training and validation with increasing model complexity'
  id: totrans-229
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 6.29: 随着模型复杂度增加，训练和验证的变化'
- en: The preceding figure shows how the validation and training error will vary with
    model complexity (of which the model parameter is an indicator). We can also see
    how the point in between the shaded regions is where the total error would be
    at a minimum, at the sweet spot between underfitting and overfitting. Finding
    this point will help us find the ideal value of the model's parameters that will
    help build a model with low bias as well as low variance.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图展示了随着模型复杂度变化（模型参数是其指示器之一），验证误差和训练误差如何变化。我们还可以看到，在阴影区域之间的某个点是总误差最小的地方，这个点位于欠拟合和过拟合之间的甜蜜点。找到这个点有助于我们找到理想的模型参数值，从而建立一个既具有低偏差又具有低方差的模型。
- en: Hyperparameter Tuning
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 超参数调优
- en: 'We''ve talked about hyperparameter tuning several times before this; now let''s
    discuss why it''s so important. First, it should be noted that model parameters
    are different from model hyperparameters: while the former are internal to the
    model and are learned from the data, the latter define the architecture of the
    model itself.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前多次谈到超参数调优，现在让我们讨论一下它为什么如此重要。首先，需要注意的是，模型参数与模型超参数是不同的：前者是模型内部的，并且是从数据中学习得到的，而后者则定义了模型本身的架构。
- en: 'Some examples of hyperparameters are as follows:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 一些超参数的示例如下：
- en: The degree of polynomial features to be used for a linear regressor
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于线性回归模型的多项式特征的次数
- en: The maximum depth allowed for a decision tree classifier
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许的决策树分类器的最大深度
- en: The number of trees to be included in a random forest classifier
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林分类器中包含的树木数量
- en: The learning rate used for the gradient descent algorithm
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于梯度下降算法的学习率
- en: 'The design choices that define the architecture of the model can make a huge
    difference in how well the model performs. Usually, the default values for the
    hyperparameters work, but getting the perfect combination of values for the hyperparameters
    can really give the predictive power of the model a boost as the default values
    may be completely inappropriate for the problem we are trying to model. In the
    following figure, we see how varying the values of two hyperparameters can cause
    such a difference in the model score:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 定义模型架构的设计选择可以显著影响模型的性能。通常，超参数的默认值可以工作，但是获取超参数的完美组合可以真正提升模型的预测能力，因为默认值可能完全不适合我们要建模的问题。在下图中，我们可以看到调整两个超参数值如何导致模型分数的巨大差异：
- en: '![Figure 6.30: Variation in model score (Z axis) across values of two model
    parameters (the X and Y axes)](img/C12622_06_30.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图6.30：模型分数（Z轴）随两个模型参数值（X和Y轴）变化的情况](img/C12622_06_30.jpg)'
- en: 'Figure 6.30: Variation in model score (Z axis) across values of two model parameters
    (the X and Y axes)'
  id: totrans-240
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.30：模型分数（Z轴）随两个模型参数值（X和Y轴）变化的情况
- en: Finding that perfect combination by exploring a range of possible values is
    what is referred to as **hyperparameter tuning**. Since there is no loss function
    we can use to maximize the model performance, tuning the hyperparameters generally
    just involves experimenting with different combinations and choosing the one that
    performs best during validation.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 通过探索一系列可能的值来找到完美组合，这就是所谓的**超参数调优**。由于没有损失函数可用于最大化模型性能，调整超参数通常只涉及尝试不同组合并选择在验证期间表现最佳的组合。
- en: 'There are a few ways in which we can go about tuning our model''s hyperparameters:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方式可以调整我们模型的超参数：
- en: '**Hand-tuning**: When we manually choose the values of our hyperparameters,
    this is known as hand-tuning. It is usually inefficient, since solving a high-dimensional
    optimization problem by hand can not only be slow, but also would not allow the
    model to reach its peak performance as we probably wouldn''t try out every single
    combination of hyperparameter values.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手动调整**：当我们手动选择超参数的值时，这被称为手动调整。这通常是低效的，因为通过手动解决高维优化问题不仅可能很慢，而且也不允许模型达到其性能峰值，因为我们可能不会尝试每个超参数值的所有组合。'
- en: '**Grid search**: Grid search involves training and evaluating a model for each
    combination of the hyperparameter values provided and selecting the combination
    that produces the best performing model. Since this involves performing an exhaustive
    sampling of the hyperparameter space, it is quite computationally expensive and
    hence inefficient.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网格搜索**：网格搜索涉及对提供的超参数值的每一组合进行训练和评估，并选择产生最佳性能模型的组合。由于这涉及对超参数空间进行详尽采样，因此计算成本相当高，效率低下。'
- en: '**Random search**: While the first method was deemed inefficient because too
    few combinations were tried, the second one was deemed so because too many combinations
    were tried. Random search aims to solve this by selecting a random subset of hyperparameter
    combinations from the grid (specified previously), and training and evaluating
    a model only for those. Alternatively, we can also provide a statistical distribution
    for each hyperparameter from which the values can be randomly sampled.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机搜索**：尽管第一种方法因尝试的组合过少而被认为效率低下，但第二种方法因尝试的组合过多而被认为效率低下。随机搜索旨在通过从网格中选择超参数组合的随机子集，并仅为这些组合训练和评估模型来解决这个问题。或者，我们还可以为每个超参数提供统计分布，从中随机抽样值。'
- en: 'The logic behind random search was proved by Bergstra and Bengio: if at least
    5% of the points on the grid yield a close-to-optimal solution, then random search
    with 60 trials will find that region with a high probability.'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随机搜索的逻辑已被Bergstra和Bengio证明：如果网格上至少有5%的点产生接近最优解，那么进行60次随机搜索将高概率找到该区域。
- en: Note
  id: totrans-247
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注
- en: You can read the paper by Bergstra and Bengio at [http://www.jmlr.org/papers/v13/bergstra12a.html](http://www.jmlr.org/papers/v13/bergstra12a.html).
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以阅读Bergstra和Bengio的论文，网址为[http://www.jmlr.org/papers/v13/bergstra12a.html](http://www.jmlr.org/papers/v13/bergstra12a.html)。
- en: '**Bayesian optimization**: The previous two methods involved independently
    experimenting with combinations of hyperparameter values and recording the model
    performance for each. However, Bayesian optimization iterates over experiments
    sequentially and allows us to use the results of a previous experiment to improve
    the sampling method for the next experiment.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯优化**：前两种方法涉及独立地实验不同超参数值的组合，并记录每个组合的模型性能。然而，贝叶斯优化是顺序地迭代实验，并允许我们利用先前实验的结果来改进下一个实验的采样方法。'
- en: 'Exercise 53: Hyperparameter Tuning with Random Search'
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习53：使用随机搜索进行超参数调优
- en: 'Using scikit-learn''s `RandomizedSearchCV` method, we can define a grid of
    hyperparameter ranges and randomly sample from the grid, performing K-fold cross-validation
    with each combination of values. In this exercise, we''ll perform hyperparameter
    tuning with the random search method:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 使用scikit-learn的`RandomizedSearchCV`方法，我们可以定义一个超参数范围的网格，并从网格中随机采样，使用每个超参数值组合执行K折交叉验证。在这个练习中，我们将使用随机搜索方法进行超参数调优：
- en: 'Import the class for random search:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入随机搜索类：
- en: '[PRE17]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Prepare data for training and initialize the classifier. Here, we will initialize
    our random forest classifier without passing any arguments, since this is just
    a base object that will be instantiated for each grid point on which to perform
    the random search:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为训练准备数据并初始化分类器。在这里，我们将初始化随机森林分类器，而不传递任何参数，因为这只是一个基础对象，稍后将在每个网格点上进行实例化并执行随机搜索：
- en: '[PRE18]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Specify the parameters to sample from. Here, we will list down the different
    values for each hyperparameter that we would like to have in the grid:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定需要采样的参数。在这里，我们将列出每个超参数的不同值，这些值将用于网格中：
- en: '[PRE19]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Run a randomized search. We initialize the random search object with the total
    number of trials we want to run, the parameter values dictionary, the scoring
    function, and the number of folds in the K-fold cross-validation. Then, we call
    the `.fit()` function to perform the search:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行随机搜索。我们用希望运行的试验总数、参数值字典、评分函数以及K折交叉验证中的折数来初始化随机搜索对象。然后，我们调用`.fit()`函数来执行搜索：
- en: '[PRE20]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Print scores and hyperparameters for the top five models. Convert the `results`
    dictionary into a pandas DataFrame and sort the values by `rank_test_score`. Then,
    for the first five rows, print the rank, mean validation score, and the hyperparameters:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印前五个模型的评分和超参数。将`results`字典转换为pandas DataFrame，并按`rank_test_score`对值进行排序。然后，对于前五行，打印排名、平均验证得分和超参数：
- en: '[PRE21]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output will be as follows:'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 6.31: Top five models’ scores and hyperparameters](img/C12622_06_31.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![图6.31：前五个模型的评分和超参数](img/C12622_06_31.jpg)'
- en: 'Figure 6.31: Top five models'' scores and hyperparameters'
  id: totrans-264
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.31：前五个模型的评分和超参数
- en: We can see that the model that performs best has only 70 trees, compared to
    the 160+ trees in the models ranked 2 to 4\. Also, the model ranked 5 only has
    10 trees and still has a performance comparable to that of the more complex models.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，表现最好的模型只有70棵树，而排名2到4的模型有160棵以上的树。此外，排名第5的模型只有10棵树，但其性能仍然与更复杂的模型相当。
- en: Feature Importance
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征重要性
- en: 'While it is essential to focus on model performance, it''s also important to
    understand how the features in our model contribute to the prediction:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然关注模型性能至关重要，但理解模型中各特征如何贡献于预测同样重要：
- en: We need to be able to explain the model and how different variables affect the
    prediction to the relevant stakeholders who might demand insight into why our
    model is successful.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要能够解释模型以及不同变量如何影响预测，以便向相关利益相关者说明为什么我们的模型成功。
- en: The data might be biased and training a model on this data could hurt the model's
    performance and result in biased model evaluation, in which case the ability to
    interpret the model by finding the important features and analyzing them will
    help debug the performance of the model.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可能存在偏差，在这些数据上训练模型可能会影响模型的性能，并导致模型评估出现偏差，在这种情况下，通过查找重要特征并分析它们来解释模型的能力将有助于调试模型的表现。
- en: In addition to the previous point, it must be noted that some model biases might
    just be socially or legally unacceptable. For example, if a model works well because
    it implicitly places high importance on a feature based on ethnicity, this might
    cause issues.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了前面提到的点之外，还必须注意，某些模型偏差可能在社会或法律上是不可接受的。例如，如果一个模型表现良好，因为它隐含地对基于种族的特征赋予了较高的重要性，这可能会引发问题。
- en: Besides these points, finding feature importance can also help in feature selection.
    If the data has high dimensionality and the trained model has high variance, removing
    features that have low importance is one way to achieve lowered variance through
    dimensionality reduction.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些要点，找出特征重要性还可以帮助特征选择。如果数据具有高维度，并且训练的模型具有高方差，那么删除那些重要性较低的特征是一种通过降维来降低方差的方法。
- en: 'Exercise 54: Feature Importance Using Random Forest'
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 54：使用随机森林计算特征重要性
- en: 'In this exercise, we will find the feature importance from the random forest
    model we loaded earlier:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从我们之前加载的随机森林模型中找出特征的重要性：
- en: 'Find feature importance. Let''s find the feature importance and save it in
    a pandas DataFrame with index equal to the column names, and sort this DataFrame
    in descending order:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出特征重要性。让我们找出特征的重要性，并将其保存在一个pandas DataFrame中，索引为列名，并按降序排列这个DataFrame：
- en: '[PRE22]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Plot the feature importance as a bar plot:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将特征重要性绘制为条形图：
- en: '[PRE23]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output will be as follows:'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 6.32: Histogram of features](img/C12622_06_32.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.32：特征直方图](img/C12622_06_32.jpg)'
- en: 'Figure 6.32: Histogram of features'
  id: totrans-280
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.32：特征直方图
- en: Here, we can see that the `Sex`, `Fare`, and `Pclass` features seem to have
    the highest importance, that is, they have the most effect on the target variable.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到`Sex`、`Fare`和`Pclass`特征似乎具有最高的重要性，也就是说，它们对目标变量的影响最大。
- en: 'Activity 15: Final Test Project'
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 15：最终测试项目
- en: 'In this activity, we''ll use the *IBM HR Analytics Employee Attrition & Performance*
    dataset (available at [https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset),
    and the accompanying source code at [https://github.com/TrainingByPackt/Supervised-Learning-with-Python](https://github.com/TrainingByPackt/Supervised-Learning-with-Python))
    to solve a classification problem wherein we have to predict whether or not an
    employee will leave the company given the features. In the employee attrition
    problem, we want to maximize our recall, that is, we want to be able to identify
    all employees that will leave, even at the cost of predicting that a good employee
    will leave: this will help HR take the appropriate action for these employees
    so that they don''t leave.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将使用*IBM HR Analytics 员工流失与绩效*数据集（可在[https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset)找到），以及相关的源代码（见[https://github.com/TrainingByPackt/Supervised-Learning-with-Python](https://github.com/TrainingByPackt/Supervised-Learning-with-Python)）来解决一个分类问题，在这个问题中，我们需要预测员工是否会离职。针对员工流失问题，我们的目标是最大化召回率，即我们希望能够识别所有即将离职的员工，即使这意味着预测一些表现良好的员工也会离职：这将帮助HR对这些员工采取适当的措施，防止他们离开。
- en: 'Each row in the dataset represents a single employee, and the target variable
    we have here is `Attrition`, which has two values: `1` and `0`, representing a
    *Yes* and *No* with respect to whether the corresponding employee left. We will
    use a gradient boosting classifier from scikit-learn to train the model. This
    activity is meant as a final project that will help consolidate the practical
    aspects of the concepts learned in this book, and particularly in this chapter.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的每一行代表一个员工，目标变量是`Attrition`，它有两个值：`1`和`0`，分别表示该员工是否离职，*是*和*否*。我们将使用来自scikit-learn的梯度提升分类器来训练模型。这个活动是作为一个最终项目，旨在帮助巩固本书以及本章所学的概念的实际应用。
- en: We will find the most optimal set of hyperparameters for the model by using
    random search with cross-validation. Then, we will build the final classifier
    using the gradient boosting algorithm on a portion of the dataset and evaluate
    its performance using the classification metrics we have learned about on the
    remaining portion of the dataset. We will use the mean absolute error as the evaluation
    metric for this activity.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过使用交叉验证的随机搜索来找到模型的最优超参数。然后，我们将在数据集的一部分上使用梯度提升算法构建最终的分类器，并使用我们学到的分类指标评估其在数据集剩余部分的表现。我们将使用平均绝对误差作为此次活动的评估指标。
- en: 'The steps to be performed are as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 需要执行的步骤如下：
- en: Import the relevant libraries.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入相关的库。
- en: Read the `attrition_train.csv` dataset.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取`attrition_train.csv`数据集。
- en: Read the `categorical_variable_values.json` file, which has details of categorical
    variables.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取`categorical_variable_values.json`文件，该文件包含了分类变量的详细信息。
- en: Process the dataset to convert all features to numerical values.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理数据集，将所有特征转换为数值型。
- en: Choose a base model and define the range of hyperparameter values corresponding
    to the model to be searched over for hyperparameter tuning.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择基础模型，并定义与模型对应的超参数值范围，以进行超参数调优。
- en: Define the parameters with which to initialize the `RandomizedSearchCV` object
    and use K-fold cross-validation to find the best model hyperparameters.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义初始化`RandomizedSearchCV`对象的参数，并使用K折交叉验证来找到最佳模型超参数。
- en: Split the dataset into training and validation sets and train a new model using
    the final hyperparameters on the training dataset.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集划分为训练集和验证集，并使用最终超参数在训练集上训练新模型。
- en: Calculate the accuracy, precision, and recall for predictions on the validation
    set, and print the confusion matrix.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算在验证集上的预测精度、精确度和召回率，并打印混淆矩阵。
- en: Experiment with varying thresholds to find the optimal point with high recall.
    Plot the precision-recall curve.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试调整不同的阈值，找到具有高召回率的最佳点。绘制精确度-召回率曲线。
- en: Finalize a threshold that will be used for predictions on the test dataset.
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定用于预测测试数据集的最终阈值。
- en: Read and process the test dataset to convert all features to numerical values.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取并处理测试数据集，将所有特征转换为数值型。
- en: Predict the final values on the test dataset.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试数据集上预测最终值。
- en: Note
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 373.
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第373页找到。
- en: Summary
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter discussed why model evaluation is important in supervised machine
    learning and looked at several important metrics that are used to evaluate regression
    and classification tasks. We saw that while regression models were fairly straightforward
    to evaluate, the performance of classification models could be measured in a number
    of ways, depending on what we want the model to prioritize. Besides numerical
    metrics, we also looked at how to plot precision-recall and ROC curves to better
    interpret and evaluate model performance.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了模型评估在监督学习中的重要性，并介绍了几种用于评估回归和分类任务的重要指标。我们看到，虽然回归模型的评估相对简单，但分类模型的性能可以通过多种方式进行衡量，具体取决于我们希望模型优先考虑的内容。除了数值指标，我们还探讨了如何绘制精确度-召回率曲线和ROC曲线，以更好地解读和评估模型性能。
- en: After this, we talked about why evaluating a model by calculating the prediction
    error on the data that the model was trained on was a bad idea, and how testing
    a model on data that it has already *seen* would lead to the model having a high
    variance. With this, we introduced the concept of having a hold-out dataset and
    why K-fold cross-validation is a useful strategy to have, along with sampling
    techniques that ensure that the model training and evaluation process remains
    unbiased.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们讨论了为什么通过计算模型在其训练数据上的预测误差来评估模型是一个不好的主意，以及如何在模型已经*见过*的数据上进行测试会导致模型具有高方差。通过这一点，我们引入了保持集数据集的概念，并解释了K折交叉验证为何是一个有用的策略，以及确保模型训练和评估过程保持无偏的采样技术。
- en: The last section on performance improvement tactics started with a discussion
    on learning and validation curves, and how they can be interpreted to drive the
    model development process towards a better-performing model. This was followed
    by a section on hyperparameter tuning as an effort to boost performance, and a
    brief introduction to feature importance.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 性能改进策略的最后一节从学习曲线和验证曲线的讨论开始，探讨了如何解读这些曲线来推动模型开发过程，最终提高模型性能。随后，我们介绍了超参数调优作为提升性能的一种方法，并简要介绍了特征重要性。
