- en: Predicting Numeric Outcomes with Linear Regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线性回归预测数值结果
- en: graph_from_dot_data() function on the Linear regression is used to predict a
    continuous numeric value from a set of input features. This machine learning algorithm
    is fundamental to statisticians when it comes to predicting numeric outcomes.
    Although advanced algorithms such as neural networks and deep learning have taken
    the place of linear regression in modern times, the algorithm is still key when
    it comes to providing you with the foundations for neural networks and deep learning.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行线性回归时，`graph_from_dot_data()`函数用于根据一组输入特征预测一个连续的数值。这一机器学习算法对于统计学家来说至关重要，尤其是在预测数值结果时。尽管像神经网络和深度学习这样的高级算法在现代已取代了线性回归，但这一算法依然是神经网络和深度学习的基础。
- en: The key benefit of building machine learning models with the linear regression
    algorithm, as opposed to neural networks and deep learning, is that it is highly
    interpretable. Interpretability helps you, as the machine learning practitioner,
    to understand how the different input variables behave when it comes to predicting
    output.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线性回归算法构建机器学习模型的关键好处，与神经网络和深度学习相比，它具有高度的可解释性。可解释性帮助您作为机器学习从业者理解不同的输入变量在预测输出时的行为。
- en: The linear regression algorithm is applied in the financial industry (in order
    to predict stock prices) and in the real estate industry (in order to predict
    housing prices). In fact, the linear regression algorithm can be applied in any
    field where there is a need to predict a numeric value, given a set of input features.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归算法被应用于金融行业（用于预测股票价格）和房地产行业（用于预测房价）。事实上，线性回归算法可以应用于任何需要根据一组输入特征预测数值的领域。
- en: 'In this chapter, you will learn about the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The inner mechanics of the linear regression algorithm
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归算法的内部机制
- en: Building and evaluating your first linear regression algorithm, using scikit-learn
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用scikit-learn构建并评估您的第一个线性回归算法
- en: Scaling your data for a potential performance improvement
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据进行缩放，以期提高性能
- en: Optimizing your linear regression model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化您的线性回归模型
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will be required to have Python 3.6 or greater, Pandas ≥ 0.23.4, Scikit-learn
    ≥ 0.20.0, and Matplotlib ≥ 3.0.0 installed on your system.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要在系统上安装Python 3.6或更高版本，Pandas ≥ 0.23.4，Scikit-learn ≥ 0.20.0和Matplotlib ≥
    3.0.0。
- en: 'The code files of this chapter can be found on GitHub:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在GitHub上找到：
- en: '[https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_05.ipynb](https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_05.ipynb)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_05.ipynb](https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_05.ipynb)'
- en: 'Check out the following video to see the code in action:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，查看代码的实际运行情况：
- en: '[http://bit.ly/2Ay95cJ](http://bit.ly/2Ay95cJ)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2Ay95cJ](http://bit.ly/2Ay95cJ)'
- en: The inner mechanics of the linear regression algorithm
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归算法的内部机制
- en: 'In its most fundamental form, the expression for the linear regression algorithm
    can be written as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归算法的最基本形式中，其表达式可以写成如下：
- en: '*![](img/f5050bc0-a8db-43a6-983e-d963e7b87ea5.png)*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](img/f5050bc0-a8db-43a6-983e-d963e7b87ea5.png)*'
- en: In the preceding equation, the output of the model is a numeric outcome. In
    order to obtain this numeric outcome, we require that each input feature be multiplied
    with a parameter called *Parameter1*, and we add the second parameter, *Parameter2*,
    to this result.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述方程中，模型的输出是一个数值结果。为了得到这个数值结果，我们要求每个输入特征与一个名为*参数1*的参数相乘，并在此结果上加上第二个参数*参数2*。
- en: 'So, in other words, our task is to find the values of the two parameters that
    can predict the value of the numeric outcome as accurately as possible. In visual
    terms, consider the following diagram:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们的任务是找到能够尽可能准确预测数值结果的两个参数值。用图形化的方式来表示，考虑以下图示：
- en: '![](img/f4c43234-60c1-4a0a-a28b-b9c0fba0b94c.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f4c43234-60c1-4a0a-a28b-b9c0fba0b94c.png)'
- en: Two-dimensional plot between the target and input feature
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 目标与输入特征之间的二维图
- en: The preceding diagram shows a two-dimensional plot between the target that we
    want to predict on the *y* axis (numeric output) and the input feature, which
    is along the *x* axis. The goal of linear regression is to find the optimal values
    of the two parameters mentioned in the preceding equation, in order to fit a line
    through the given set of points.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图示展示了一个二维图，其中目标变量（我们希望预测的内容）位于*y*轴上（数值型输出），输入特征位于*x*轴上。线性回归的目标是找到上述方程中提到的两个参数的最优值，从而将一条线拟合到给定的点集。
- en: This line is known as the **line of best fit**. A line of best fit is one that
    fits the given sets of points very well, so that it can make accurate predictions
    for us. Therefore, in order to find the optimal values of the parameters that
    will result in the line of best fit, we need to define a function that can do
    it for us.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这条线被称为**最佳拟合线**。最佳拟合线是指能够非常好地拟合给定数据点集的直线，以便可以为我们做出准确的预测。因此，为了找到能够生成最佳拟合线的参数的最优值，我们需要定义一个能够为我们完成此任务的函数。
- en: 'This function is known as the **loss function**. The goal of the loss function,
    as the name suggests, is to minimize the loss/errors as much as possible, so that
    we can obtain a line of best fit. In order to understand how this works, consider
    the following diagram:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数被称为**损失函数**。顾名思义，损失函数的目标是尽可能地最小化损失/误差，以便我们能够获得最佳拟合线。为了理解这个过程，请参考以下图示：
- en: '![](img/deeb026a-8eed-4df2-9931-dc9c7990f3a4.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/deeb026a-8eed-4df2-9931-dc9c7990f3a4.png)'
- en: Line of best fit
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳拟合线
- en: 'In the preceding diagram, the line is fit through the set of data points, and
    the features can be defined as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述图示中，线条被拟合到数据点集，特征可以定义如下：
- en: The distance between each point in the plot and the line is known as the **residual**.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个数据点到拟合线的距离被称为**残差**。
- en: The loss/error function is the sum of the squares of these residuals.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失/误差函数是这些残差的平方和。
- en: The goal of the linear regression algorithm is to minimize this value. The sum
    of the squares of the residuals is known as **ordinary least squares** (**OLS**).
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归算法的目标是最小化这个值。残差的平方和被称为**普通最小二乘法**（**OLS**）。
- en: Implementing linear regression in scikit-learn
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 scikit-learn 中实现线性回归
- en: 'In this section, you will implement your first linear regression algorithm
    in scikit-learn. To make this easy to follow, the section will be divided into
    three subsections, in which you will learn about the following topics:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将实现第一个线性回归算法，使用 scikit-learn。为了方便理解，本节将分为三个子节，分别讲解以下主题：
- en: Implementing and visualizing a simple linear regression model in two dimensions
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现并可视化一个简单的二维线性回归模型
- en: Implementing linear regression to predict the mobile transaction amount
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现线性回归以预测手机交易金额
- en: Scaling your data for a potential increase in performance
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据进行缩放，以提高可能的性能
- en: Linear regression in two dimensions
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二维线性回归
- en: 'In this subsection, you will learn how to implement your first linear regression
    algorithm, in order to predict the amount of a mobile transaction by using one
    input feature: the old balance amount of the account holder. We will be using
    the same fraudulent mobile transaction dataset that we used in [*Chapter 2*](08e4b04a-e866-4754-9b0b-1486016dce2c.xhtml),
    *Predicting Categories with K-Nearest Neighbors*, of this book.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一子节中，你将学习如何实现第一个线性回归算法，通过使用一个输入特征——账户持有者的旧余额，来预测手机交易的金额。我们将使用在本书的[*第2章*](08e4b04a-e866-4754-9b0b-1486016dce2c.xhtml)《使用K最近邻预测类别》中使用的相同欺诈性手机交易数据集。
- en: 'The first step is to read in the dataset and define the feature and target
    variable. This can be done by using the following code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是读取数据集并定义特征和目标变量。这可以通过以下代码来完成：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we will create a simple scatter plot between the amount of the mobile
    transaction on the *y* axis (which is the outcome of the linear regression model)
    and the old balance of the account holder along the *x* axis (which is the input
    feature). This can be done by using the following code:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个简单的散点图，展示手机交易金额在*y*轴上的数据（即线性回归模型的输出），以及账户持有者的旧余额沿*x*轴的数据（即输入特征）。这可以通过以下代码实现：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the preceding code, we use the `plt.scatter()` function to create a scatter
    plot between the featureon the *x* axis and the targeton the *y* axis. This results
    in the scatter plot illustrated in the following diagram:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述代码中，我们使用`plt.scatter()`函数创建了特征在* x * 轴上与目标在* y * 轴上之间的散点图。这样得到了以下图示中的散点图：
- en: '![](img/97a7b42f-9f3f-4193-9500-d1f4f02a58c7.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/97a7b42f-9f3f-4193-9500-d1f4f02a58c7.png)'
- en: Two-dimensional space of the linear regression model
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型的二维空间
- en: 'Now, we will fit a linear regression model into the two-dimensional space illustrated
    in the preceding diagram. Note that, in the preceding diagram, the data is not
    entirely linear. In order to do this, we use the following code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将线性回归模型拟合到前述图表中所示的二维空间中。请注意，在前述图表中，数据并非完全线性。为了实现这一点，我们使用以下代码：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This results in a line of best fit, as illustrated in the following diagram:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这会得到一条最佳拟合线，如下图所示：
- en: '![](img/b3b641d3-a7bc-462d-9263-31a9c7bca3c7.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b3b641d3-a7bc-462d-9263-31a9c7bca3c7.png)'
- en: Line of best fit
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳拟合线
- en: In the preceding code, first, we initialize a linear regression model and fit
    the training data into that model. Since we only have a single feature, we need
    to reshape the feature and target for scikit-learn. Next, we define the upper
    and lower limits of the *x* axis, which contains our feature variable.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述代码中，首先我们初始化一个线性回归模型，并将训练数据拟合到该模型中。由于我们只有一个特征，我们需要为scikit-learn调整特征和目标。接着，我们定义了包含特征变量的*
    x * 轴的上下限。
- en: Finally, we create a scatter plot between the feature and the target variable
    and include the line of best fit with the color red, as indicated in the preceding
    diagram.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们创建了特征与目标变量之间的散点图，并在前述图表中加入了红色的最佳拟合线。
- en: Using linear regression to predict mobile transaction amount
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线性回归预测移动交易金额
- en: Now that we have visualized how a simple linear regression model works in two
    dimensions, we can use the linear regression algorithm to predict the total amount
    of a mobile transaction, using all of the other features in our mobile transaction
    dataset.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经可视化了一个简单的线性回归模型在二维空间中的工作原理，我们可以利用线性回归算法，通过我们移动交易数据集中的所有其他特征来预测移动交易的总金额。
- en: 'The first step is to import our fraud prediction dataset into our workspace
    and divide it into training and test sets. This can be done by using the following
    code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将我们的欺诈预测数据集导入工作区，并将其分为训练集和测试集。这可以通过以下代码完成：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can now fit the linear regression model and evaluate the initial accuracy
    score of the model by using the following code:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以拟合线性回归模型，并通过以下代码评估模型的初始准确性分数：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the preceding code, first, we initialize a linear regression model, which
    we can then fit into the training data by using the `.fit()`function. Then, we
    evaluate the accuracy score on the test data by using the `.score()`function.
    This results in an accuracy score of 98%, which is fantastic!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述代码中，首先我们初始化一个线性回归模型，然后通过`.fit()`函数将其拟合到训练数据中。接着，我们通过`.score()`函数评估在测试数据上的准确性分数。最终，我们得到一个98%的准确性分数，这非常棒！
- en: Scaling your data
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据标准化
- en: 'Scaling your data and providing a level of standardization is a vital step
    in any linear regression pipeline, as it could offer a way to enhance the performance
    of your model. In order to scale the data, we use the following code:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据进行标准化处理并提供一定的标准化水平是任何线性回归管道中的关键步骤，因为它可以提高模型的表现。为了缩放数据，我们使用以下代码：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We use the same scaling pipeline that we used in all of the previous chapters.
    In the preceding code, we replace the model name with the linear regression model
    and evaluate the scaled accuracy scores on the test data.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用与之前章节相同的标准化管道。在前述代码中，我们将模型名称替换为线性回归模型，并评估在测试数据上的标准化准确性分数。
- en: In this case, scaling the data did not lead to any improvements in the accuracy
    score, but it is vital to implement scaling into your linear regression pipeline,
    as it does lead to an improvement in the accuracy scores in most cases.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，数据标准化并未带来准确性分数的提升，但将标准化引入线性回归管道中仍然至关重要，因为在大多数情况下，它会提升准确性分数。
- en: Model optimization
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型优化
- en: The fundamental objective of the linear regression algorithm is to minimize
    the loss/cost function. In order to do this, the algorithm tries to optimize the
    values of the coefficients of each feature (*Parameter1*),such that the loss function
    is minimized.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归算法的基本目标是最小化损失/代价函数。为了实现这一目标，算法尝试优化每个特征的系数值（*Parameter1*），使得损失函数最小化。
- en: Sometimes, this leads to overfitting, as the coefficients of each variable are
    optimized for the data that the variable is trained on. This means that your linear
    regression model will not generalize beyond your current training data very well.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，这会导致过拟合，因为每个变量的系数是针对其训练数据进行优化的。这意味着你的线性回归模型在训练数据之外的泛化能力较差。
- en: The process by which we penalize hyper-optimized coefficients in order to prevent
    this type of overfitting is called **regularization**.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过对超优化的系数进行惩罚，以防止过拟合的过程被称为**正则化**。
- en: 'There are two broad types of regularization methods, as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化方法大致可以分为两类，如下所示：
- en: Ridge regression
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 岭回归
- en: Lasso regression
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lasso回归
- en: In the following subsections, the two types of regularization techniques will
    be discussed in detail, and you will learn about how you can implement them into
    your model.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，将详细讨论这两种正则化技术，并介绍如何将它们应用到你的模型中。
- en: Ridge regression
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 岭回归
- en: 'The equation for ridge regression is as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归的公式如下：
- en: '![](img/2bf0db77-ab6c-43a2-bd5c-6c5afeef7676.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2bf0db77-ab6c-43a2-bd5c-6c5afeef7676.png)'
- en: In the preceding equation, the ridge loss function is equal to the ordinary
    least squares loss function, plus the product of the square of *Parameter1* of
    each feature and `alpha`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的公式中，岭回归的损失函数等于普通最小二乘法损失函数，加上每个特征的*Parameter1*的平方与`alpha`的乘积。
- en: '`alpha` is a parameter that we can optimize in order to control the amount
    by which the ridge loss function penalizes the coefficients, in order to prevent
    overfitting. Obviously, if `alpha` is equal to `0`, the ridge loss function is
    equal to the ordinary least squares loss function, thereby making no difference
    to the initial overfit model.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`alpha`是一个可以优化的参数，用于控制岭回归损失函数惩罚系数的程度，从而防止过拟合。显然，如果`alpha`等于`0`，则岭回归损失函数等同于普通最小二乘法损失函数，从而对最初的过拟合模型没有任何影响。'
- en: Therefore, optimizing this value of `alpha` provides the optimal model that
    can generalize beyond the data that it has trained on.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，优化这个`alpha`值可以提供一个最佳模型，使其能够在训练数据之外进行泛化。
- en: 'In order to implement ridge regression into the fraud prediction dataset, we
    use the following code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将岭回归应用于欺诈预测数据集，我们使用以下代码：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the preceding code, first, we read in the dataset and divide it into training
    and test sets (as usual). Next, we initialize a ridge regression model by using
    the `Ridge()` function, with the parameters of `alpha` set to `0` and `normalize`
    set to `True`, in order to standardize the data.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，首先我们读取数据集并将其分为训练集和测试集（如往常一样）。接下来，我们使用`Ridge()`函数初始化一个岭回归模型，并将`alpha`参数设置为`0`，`normalize`参数设置为`True`，以便对数据进行标准化。
- en: Next, the ridge model is fit into the training data, and the accuracy score
    is extracted from the test data. The accuracy of this model is exactly the same
    as the accuracy of the model that we built without the ridge regression as the
    parameter that controls how the model is optimized; `alpha` is set to `0`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将岭回归模型拟合到训练数据中，并从测试数据中提取准确率分数。这个模型的准确率与我们在没有使用岭回归作为优化模型的参数时构建的模型的准确率完全相同；`alpha`被设置为`0`。
- en: 'In order to obtain the optimal value of `alpha` with the `GridSearchCV` algorithm,
    we use the following code:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用`GridSearchCV`算法获得最佳的`alpha`值，我们使用以下代码：
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the preceding code, the following applies:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，以下内容适用：
- en: First, we initialize a ridge regression model, and then, we use the `GridSearchCV`
    algorithm to search for the optimal value of `alpha`, from a range of values.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们初始化一个岭回归模型，然后使用`GridSearchCV`算法从一系列值中搜索最佳的`alpha`值。
- en: After we obtain this optimal value of `alpha`, we build a new ridge regression
    model with this optimal value in the training data, and we evaluate the accuracy
    score on the test data.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在获得最佳的`alpha`值后，我们使用这个最佳值构建一个新的岭回归模型，并在训练数据中进行训练，然后评估测试数据上的准确率。
- en: Since our initial model was already well optimized, the accuracy score did not
    increase by an observable amount. However, on datasets with larger dimensions/features,
    ridge regression holds immense value for providing you with a model that generalizes
    well, without overfitting.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的初始模型已经得到了很好的优化，因此准确率分数没有明显增加。然而，在具有更大维度/特征的数据集上，岭回归对于提供一个不会过拟合且泛化良好的模型具有巨大的价值。
- en: 'In order to verify the results that the `GridSearchCV` algorithm has provided
    us with, we will construct a plot between the accuracy scores on the *y* axis
    and the different values of `alpha` along the *x* axis, for both the training
    and test data. In order to do this, we use the following code:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证`GridSearchCV`算法为我们提供的结果，我们将构建一个图表，y轴为准确率分数，x轴为不同的`alpha`值，分别针对训练数据和测试数据。为此，我们使用以下代码：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This results in the following output:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/15bc0a4c-ab68-41c0-8439-c4ec352b9748.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/15bc0a4c-ab68-41c0-8439-c4ec352b9748.png)'
- en: Accuracy versus alpha
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率与`alpha`的关系
- en: In the preceding plot, it is clear that a value of 0.01 or lower provides the
    highest value of accuracy for both the training and test data, and therefore,
    the results from the `GridSearchCV` algorithm make logical sense.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，可以明显看出，0.01或更低的值为训练数据和测试数据提供了最高的准确率，因此，`GridSearchCV`算法的结果是合乎逻辑的。
- en: In the preceding code, first, we initialize two empty lists, to store the accuracy
    scores for both the training and test data. We then evaluate the accuracy scores
    for both the training and test sets for different values of `alpha`, and we create
    the preceding plot.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，首先我们初始化两个空列表，用来存储训练数据和测试数据的准确率分数。然后，我们评估不同`alpha`值下的训练集和测试集准确率分数，并创建前面的图表。
- en: Lasso regression
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 套索回归
- en: 'The equation for lasso regression is as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 套索回归的方程如下：
- en: '![](img/d8213a04-3fa1-4d9c-9d65-d4d9f6ff399d.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d8213a04-3fa1-4d9c-9d65-d4d9f6ff399d.png)'
- en: In the preceding equation, the lasso loss function is equal to the ordinary
    least squares loss function plus the product of the absolute value of the coefficients
    of each feature and `alpha`.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述方程中，套索损失函数等于普通最小二乘损失函数加上每个特征系数的绝对值与`alpha`的乘积。
- en: '`alpha` is a parameter that we can optimize to control the amount by which
    the lasso loss function penalizes the coefficients, in order to prevent overfitting.
    Once again, if `alpha` is equal to `0`, the lasso loss function is equal to the
    ordinary least squares loss function, thereby making no difference to the initial
    overfit model.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`alpha`是一个我们可以优化的参数，用来控制套索损失函数对系数的惩罚程度，从而防止过拟合。再次说明，如果`alpha`等于`0`，套索损失函数就等于普通最小二乘损失函数，从而与最初的过拟合模型没有任何区别。'
- en: Therefore, optimizing this value of `alpha` provides the optimal model that
    generalizes well beyond the data that it has trained on.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，优化`alpha`值提供了一个最佳模型，使其能够很好地泛化到训练数据之外的数据。
- en: 'In order to implement lasso regression into the fraud prediction dataset, we
    use the following code:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将套索回归应用于欺诈预测数据集，我们使用以下代码：
- en: '[PRE9]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The preceding code is very similar to the code that we used to build the ridge
    regression model; the only difference is the `Lasso()`function which we use to
    initialize a lasso regression model. Additionally, the `warnings` package is used,
    in order to suppress the warning that is generated as we set the value of `alpha`
    to `0`.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码与我们用来构建岭回归模型的代码非常相似，唯一的不同是我们使用`Lasso()`函数来初始化套索回归模型。此外，使用了`warnings`包，以便在我们将`alpha`值设为`0`时抑制生成的警告。
- en: 'In order to optimize the value of `alpha`, we use the `GridSearchCV` algorithm.
    This is done by using the following code:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化`alpha`值，我们使用`GridSearchCV`算法。这是通过使用以下代码实现的：
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The preceding code is similar to the `alpha` optimization that we implemented
    for the ridge regression. Here, we use the lasso regression model instead of the
    ridge regression model.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码与我们为岭回归实现的`alpha`优化类似。在这里，我们使用套索回归模型，而不是岭回归模型。
- en: 'In order to verify the results of the `GridSearchCV` algorithm, we construct
    a plot between the accuracy scores and the value of `alpha` for the training and
    test sets. This is shown in the following code:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证`GridSearchCV`算法的结果，我们构建了一个图表，其中显示了训练集和测试集的准确率分数与`alpha`值的关系。具体代码如下：
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This results in the following output:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/f9b6f0c2-31c7-43c4-9f34-ad1679b7e0f3.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f9b6f0c2-31c7-43c4-9f34-ad1679b7e0f3.png)'
- en: Accuracy versus alpha
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性与 alpha 的关系
- en: All of the values of `alpha` provide the same values of accuracy scores, and
    we can thus pick the value given to us by the `GridSearchCV` algorithm.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的`alpha`值都提供相同的准确度分数，因此我们可以选择由`GridSearchCV`算法提供的值。
- en: Summary
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned about how the linear regression algorithm works
    internally, through key concepts such as residuals and ordinary least squares.
    You also learned how to visualize a simple linear regression model in two dimensions.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了线性回归算法的内部工作原理，通过残差和普通最小二乘等关键概念。你还学会了如何在二维空间中可视化简单的线性回归模型。
- en: We also covered implementing the linear regression model to predict the amount
    of a mobile transaction, along with scaling your data in an effective pipeline,
    to bring potential improvements to your performance.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还介绍了如何实现线性回归模型来预测移动交易的金额，并在有效的管道中对数据进行缩放，以带来潜在的性能提升。
- en: Finally, you learned how to optimize your model by using the concept of regularization,
    in the form of ridge and lasso regression.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你学会了如何通过使用正则化概念来优化你的模型，正则化形式为岭回归和套索回归。
