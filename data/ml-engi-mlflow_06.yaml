- en: '*Chapter 4*: Experiment Management in MLflow'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第4章*：MLflow中的实验管理'
- en: In this chapter, we will give you practical experience with stock predictions
    by creating different models and comparing metrics of different runs in MLflow.
    You will be guided in terms of how to use the MLflow experiment method so that
    different machine learning practitioners can share metrics and improve on the
    same model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过创建不同的模型并比较MLflow中不同运行的指标来为您提供股票预测的实际经验。您将指导如何使用MLflow实验方法，以便不同的机器学习从业者可以共享指标并改进同一模型。
- en: 'Specifically, we will look at the following topics in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将具体探讨以下主题：
- en: Getting started with the experiments module
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用实验模块
- en: Defining the experiment
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义实验
- en: Adding experiments
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加实验
- en: Comparing different models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较不同的模型
- en: Tuning your model with hyperparameter optimization
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用超参数优化调整您的模型
- en: At this stage, we currently have a baseline pipeline that acts based on a naïve
    heuristic. In this chapter, we will add to our set of skills the ability to experiment
    with multiple models and tune one specific model using MLflow.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们目前有一个基于朴素启发式的基线管道。在本章中，我们将通过MLflow添加我们的技能集，以便能够对多个模型进行实验，并调整一个特定模型。
- en: We will be delving into our **Psystock** company use case of a stock trading
    machine learning platform introduced in [*Chapter 2*](B16783_02_Final_SB_epub.xhtml#_idTextAnchor030),
    *Your Machine Learning Project*. In this chapter, we will add to our platform
    to compare multiple models and run experiments in the benchmark to be able to
    create a predictor for a specific stock and ticker.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将深入研究[*第2章*](B16783_02_Final_SB_epub.xhtml#_idTextAnchor030)中介绍的“您的机器学习项目”中的**Psystock**公司案例，这是一个股票交易机器学习平台。在本章中，我们将向我们的平台添加比较多个模型和运行基准实验的功能，以便能够为特定的股票和股票代码创建预测器。
- en: 'In data science functions, a common methodology is to develop a model for a
    specific model that involves the following three steps: creating baseline models
    with different model types, identifying the best performant model, and predicting
    with the best model.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学函数中，一种常见的方法是为特定模型开发一个模型，涉及以下三个步骤：创建不同模型类型的基线模型，确定表现最佳的模型，并使用最佳模型进行预测。
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you will need the following prerequisites:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，您需要以下先决条件：
- en: The latest version of Docker installed on your machine. If you don't already
    have it installed, please follow the instructions at [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/).
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在您的机器上安装了最新版本的Docker。如果您还没有安装，请按照[https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)中的说明进行操作。
- en: The latest version of Docker Compose installed. Please follow the instructions
    at [https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了最新版本的Docker Compose。请按照[https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/)中的说明进行操作。
- en: Access to Git in the command line and installed as described in [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在命令行中访问Git，并按照[https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)中的说明安装。
- en: Access to a bash terminal (Linux or Windows).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问bash终端（Linux或Windows）。
- en: Access to a browser.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问浏览器。
- en: Python 3.5+ installed.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了Python 3.5+。
- en: The latest version of your machine learning installed locally and described
    in [*Chapter 3*](B16783_03_Final_SB_epub.xhtml#_idTextAnchor066), *Your* *Data
    Science Workbench*.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您本地安装的最新机器学习版本，并在[*第3章*](B16783_03_Final_SB_epub.xhtml#_idTextAnchor066)，“您的数据科学工作台”中描述。
- en: Getting started with the experiments module
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用实验模块
- en: 'To get started with the technical modules, you will need to get started with
    the environment prepared for this chapter in the following folder: [https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter04](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter04)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用技术模块，您需要开始使用以下文件夹中为本章准备的环境：[https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter04](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter04)
- en: 'You should be able, at this stage, to execute the `make` command to build up
    your workbench with the dependencies needed to follow along with this chapter.
    You need next to type the following command to move to the right directory:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，您应该能够执行 `make` 命令来构建工作台，以便跟随本章的内容。接下来，您需要输入以下命令以移动到正确的目录：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To start the environment, you need to run the following command:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动环境，您需要运行以下命令：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The entry point to start managing experimentation in **MLflow** is the experiments
    interface illustrated in *Figure 4.1*:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 开始管理 **MLflow** 中的实验的入口是 *图 4.1* 中所示的实验界面：
- en: '2'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '2'
- en: '1'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '1'
- en: '![Figure 4.1 – The Experiments interface in MLflow'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 4.1 – MLflow 中的实验界面'
- en: '](img/B16783_04_01.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16783_04_01.jpg]'
- en: Figure 4.1 – The Experiments interface in MLflow
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – MLflow 中的实验界面
- en: On the left pane (1), you can manage and create experiments, and on the right
    (2), you can query details of a specific experiment.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧面板（1）中，您可以管理和创建实验，在右侧（2）中，您可以查询特定实验的详细信息。
- en: 'To create a new experiment, you need to click on the **+** button on the left
    pane and add the details of your experiment, as illustrated by *Figure 4.2*:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个新实验，您需要在左侧面板上点击 **+** 按钮，并添加您实验的详细信息，如图 *图 4.2* 所示：
- en: '![Figure 4.2 – Creating new experiments'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 4.2 – 创建新实验'
- en: '](img/B16783_04_02.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16783_04_02.jpg]'
- en: Figure 4.2 – Creating new experiments
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 创建新实验
- en: Having introduced at a high level the tracking server and the experiment management
    features, we will now proceed to use the features available on our workbench to
    tackle the challenges of the current chapter.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在简要介绍了跟踪服务器和实验管理功能之后，我们现在将使用工作台上的功能来应对本章的挑战。
- en: Defining the experiment
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义实验
- en: 'Using the machine learning problem framing methodology, we will now define
    the main components of our stock price prediction problem as defined for the chapter:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用机器学习问题框架方法，我们现在将定义本章中股票价格预测问题的主要组件：
- en: '![](img/B16783_04_Table_(1).jpg)![Table 4.1 – Machine learning problem framing
    recap'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16783_04_Table_(1).jpg]![表 4.1 – 机器学习问题框架回顾'
- en: '](img/B16783_04_Table_(2).jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16783_04_Table_(2).jpg]'
- en: Table 4.1 – Machine learning problem framing recap
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.1 – 机器学习问题框架回顾
- en: 'The **F-score** metric in machine learning is a measure of accuracy for binary
    classifiers and provides a good balance and trade-off between misclassifications
    (false positives or false negatives). Further details can be found on the Wikipedia
    page: [https://en.wikipedia.org/wiki/F-score](https://en.wikipedia.org/wiki/F-score).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的 **F-score** 指标是二元分类器的准确度度量，提供了在误分类（假阳性或假阴性）之间的良好平衡和权衡。更多详细信息可以在维基百科页面找到：[https://en.wikipedia.org/wiki/F-score](https://en.wikipedia.org/wiki/F-score)。
- en: Exploring the dataset
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索数据集
- en: As specified in our machine learning problem framing, we will use as input data
    the market observations for the period January-December 2020, as provided by the
    Yahoo data API.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的机器学习问题框架，我们将使用 2020 年 1 月至 12 月的市场观察数据作为输入数据，这些数据由 Yahoo 数据 API 提供。
- en: 'The following code excerpt, which uses the `pandas_datareader` module available
    in our workbench, allows us to easily retrieve the data that we want. The complete
    working notebook is available at [https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter04/gradflow/notebooks/retrieve_training_data.ipynb](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter04/gradflow/notebooks/retrieve_training_data.ipynb):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段，使用了我们工作台中的 `pandas_datareader` 模块，使我们能够轻松检索我们想要的数据。完整的笔记本可以在[https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter04/gradflow/notebooks/retrieve_training_data.ipynb](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter04/gradflow/notebooks/retrieve_training_data.ipynb)找到：
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For this particular problem, we will retrieve data from 2014 up to the end
    of 2020, as represented in the table provided in *Figure 4.3*. The table provides
    value information about High, Low, Open, and Close for the BTC stock of the trading
    section. This data will be used to train the models in the current chapter:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个特定问题，我们将从 2014 年检索数据，直到 2020 年底，如图 *图 4.3* 中提供的表格所示。该表格提供了交易部分 BTC 股票的高、低、开盘价和收盘价的价值信息。这些数据将用于本章中模型的训练：
- en: '![](img/B16783_04_03.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B16783_04_03.jpg]'
- en: Figure 4.3 – Listing the data retrieved from the source (Yahoo Finance)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – 列出从源（Yahoo Finance）检索的数据
- en: 'This data can easily be plotted by plotting one of the variables just to illustrate
    the continuous nature of the data:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过绘制其中一个变量来轻松绘制这些数据，以说明数据的连续性：
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To illustrate a bit more about the nature of the data, we can plot an excerpt
    of the data:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更详细地说明数据的性质，我们可以绘制数据的摘录：
- en: '![Figure 4.4 – Plot of one of the variables BTC Open retrieved from the source
    (Yahoo Finance)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.4 – 从源（雅虎财经）检索到的 BTC Open 变量的绘图]'
- en: '](img/B16783_04_04.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16783_04_04.jpg]'
- en: Figure 4.4 – Plot of one of the variables BTC Open retrieved from the source
    (Yahoo Finance)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – 从源（雅虎财经）检索到的 BTC Open 变量的绘图
- en: Having defined precisely what we will be experimenting with in this section,
    we will move to add new models to enable us to run experiments and compare among
    them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中明确定义我们将要实验的内容后，我们将添加新的模型，以便我们能够运行实验并在它们之间进行比较。
- en: The data for the required range was conveniently saved in a file under `Chapter04/gradflow/notebooks/training_data.csv`,
    for the period ranging from 2014 to 2020 inclusive, so it can be easily retrieved
    during the modeling phase.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 所需范围的数据方便地保存在 `Chapter04/gradflow/notebooks/training_data.csv` 文件中，时间范围从 2014
    年到 2020 年（含），因此可以在建模阶段轻松检索。
- en: Adding experiments
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加实验
- en: So, in this section, we will use the experiments module in **MLflow** to track
    the different runs of different models and post them in our workbench database
    so that the performance results can be compared side by side.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本节中，我们将使用 **MLflow** 的实验模块来跟踪不同模型的运行，并将它们发布到我们的工作台数据库中，以便可以并排比较性能结果。
- en: The experiments can actually be done by different model developers as long as
    they are all pointing to a shared MLflow infrastructure.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 实验实际上可以由不同的模型开发者进行，只要他们都指向共享的 MLflow 基础设施。
- en: To create our first, we will pick a set of model families and evaluate our problem
    on each of the cases. In broader terms, the major families for classification
    can be tree-based models, linear models, and neural networks. By looking at the
    metric that performs better on each of the cases, we can then direct tuning to
    the best model and use it as our initial model in production.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建我们的第一个模型，我们将选择一组模型家族，并在每个案例上评估我们的问题。从更广泛的角度来看，分类的主要家族可以是基于树的模型、线性模型和神经网络。通过查看在每个案例上表现更好的指标，我们然后可以将调整引导到最佳模型，并将其用作我们的初始生产模型。
- en: 'Our choice for this section includes the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中的选择包括以下内容：
- en: '**Logistic Classifier**: Part of the family of linear-based models and a commonly
    used baseline.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逻辑分类器**：线性模型家族的一部分，并且是常用的基线。'
- en: '**Xgboost**: This belongs to the family of tree boosting algorithms where many
    weak tree classifiers are assembled to produce a stronger model.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Xgboost**：这属于树提升算法家族，其中许多弱树分类器被组装成一个更强的模型。'
- en: '**Keras**: This type of model belongs to the neural network''s family and is
    generally indicated for situations where there is a lot of data available and
    relations are not linear between the features.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Keras**：这类模型属于神经网络家族，通常用于数据量很大且特征之间关系非线性的情况。'
- en: The steps to set up a new model are quite common and there will be overlapping
    and repeated code for each of the models. We will start next with a logistic regression-based
    classifier.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 设置新模型的步骤相当常见，每个模型都会有重叠和重复的代码。接下来，我们将从基于逻辑回归的分类器开始。
- en: Steps for setting up a logistic-based classifier
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置基于逻辑分类器的步骤
- en: In this sub-section, we will implement a logistic regression classifier in `scikit-learn`
    and train a model with our input data.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本子节中，我们将使用 `scikit-learn` 实现逻辑回归分类器，并使用我们的输入数据训练模型。
- en: 'The complete notebook for this model is available in the book''s repository
    and can be used to follow along in the `Chapter04/gradflow/notebooks/mlflow_run_logistic_regression.ipynb`
    file:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的完整笔记本可在本书的存储库中找到，并可用于在 `Chapter04/gradflow/notebooks/mlflow_run_logistic_regression.ipynb`
    文件中跟随：
- en: '`SKLearn` model, `LogisticRegression`, and the metrics functionality, `f1_score`,
    that will enable us to calculate the performance:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`SKLearn` 模型、`LogisticRegression` 和 `f1_score` 指标功能，这将使我们能够计算性能：'
- en: '[PRE4]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`training_data.csv` file:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`training_data.csv` 文件：'
- en: '[PRE5]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The data is split into training and testing using the `train_test_split` function,
    which takes one-third of the data for testing, with the remainder being used for
    training.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用 `train_test_split` 函数将数据分为训练集和测试集，其中三分之一的用于测试，其余用于训练。
- en: '`mlflow.set_experiment` method. This will create an experiment if it does not
    exist or associate your current run with an experiment. We use `mlflow.sklearn.autolog()`
    to enable the automated capabilities of MLflow to capture the metrics of our experiment:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`mlflow.set_experiment` 方法。这将创建一个实验（如果不存在）或将当前运行与一个实验关联。我们使用 `mlflow.sklearn.autolog()`
    启用 MLflow 的自动功能来捕获实验的指标：'
- en: '[PRE6]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`with`. The `mlflow.start_run` function is used to take care of registering
    your run with a specific `run_name` so that it can be identified and encloses
    the `fit` model, with evaluation code used to calculate the performance metrics
    of the `f1_score` experiment:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`with`。`mlflow.start_run` 函数用于处理将运行与特定的 `run_name` 注册，以便它可以被识别，并包含 `fit` 模型，以及用于计算
    `f1_score` 实验性能指标的评估代码：'
- en: '[PRE7]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Additionally, we need to log our specific metric, `f1_experiment_score`, with
    the `mlflow.log_metric` function. The main reason for adding our specific method
    is that for each model, the autologging functionality in **MLflow** uses the default
    metric used by each underlying framework and generally, these metrics don't match.
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，我们需要使用 `mlflow.log_metric` 函数记录我们特定的指标 `f1_experiment_score`。添加我们特定方法的主要原因是为每个模型，**MLflow**
    中的自动记录功能使用每个底层框架默认的指标，通常这些指标并不匹配。
- en: 'After executing all the steps relating to model development, we can now navigate
    to our run and visualize the log of the experiment. In *Figure 4.5*, you can see
    the specific parameters associated with logistic regression, durations, and all
    the parameters used on your run:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 执行所有与模型开发相关的步骤后，我们现在可以导航到我们的运行并可视化实验的日志。在 *图 4.5* 中，你可以看到与逻辑回归、持续时间以及你在运行中使用的所有参数相关的特定参数：
- en: '![Figure 4.5 – Logistic regression model details'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 4.5 – 逻辑回归模型细节'
- en: '](img/B16783_04_05.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16783_04_05.jpg](img/B16783_04_05.jpg)'
- en: Figure 4.5 – Logistic regression model details
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – 逻辑回归模型细节
- en: 'For `SKLearn` models, **MLflow** automatically logs confusion matrices and
    precision and recall curves that are very useful in detecting how well the model
    performed on training data. For instance, the *Figure 4.6* report will be stored
    in the artifacts of your run:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `SKLearn` 模型，**MLflow** 自动记录混淆矩阵和精确率和召回率曲线，这对于检测模型在训练数据上的表现非常有用。例如，*图 4.6*
    报告将存储在运行的艺术品中：
- en: '![Figure 4.6 – Confusion matrix metrics'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 4.6 – 混淆矩阵指标'
- en: '](img/B16783_04_06.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16783_04_06.jpg](img/B16783_04_06.jpg)'
- en: Figure 4.6 – Confusion matrix metrics
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 混淆矩阵指标
- en: MLflow provides built-in metrics for Sklearn, providing better visibility of
    the model produced during training without the developer needing to produce extra
    code.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 为 Sklearn 提供了内置的指标，这为训练过程中产生的模型提供了更好的可见性，而无需开发者编写额外的代码。
- en: Steps for setting up an XGBoost-based classifier
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置基于 XGBoost 的分类器的步骤
- en: We will now implement a gradient tree-based algorithm using the `XGBoost` library.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用 `XGBoost` 库实现基于梯度树的算法。
- en: 'The complete notebook for this model is available in the book''s repository
    and can be used to follow along in the `Chapter04/gradflow/notebooks/mlflow_run_xgboost.ipynb`
    file:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的完整笔记本可在本书的存储库中找到，并可用于在 `Chapter04/gradflow/notebooks/mlflow_run_xgboost.ipynb`
    文件中跟随：
- en: '**Importing dependencies**: The XGBoost library is imported alongside the metrics
    function:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**导入依赖项**：XGBoost 库与指标函数一起导入：'
- en: '[PRE8]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`training_data.csv` file.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`training_data.csv` 文件。'
- en: "`Baseline_Predictions`, and we need to give MLflow the instruction to automatically\
    \ \Llog the model through `mlflow.xgboost.autolog`:"
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Baseline_Predictions`，我们需要给 MLflow 指示通过 `mlflow.xgboost.autolog` 自动记录模型：'
- en: '[PRE9]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`f1_score`:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`f1_score`:'
- en: '[PRE10]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After executing all the steps relating to model development, we can now navigate
    to our run and visualize the log of the experiment. In *Figure 4.7*, you can see
    the specific parameters associated with `xgboost_model_baseline`, durations, and
    all the parameters used on your run:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 执行所有与模型开发相关的步骤后，我们现在可以导航到我们的运行并可视化实验的日志。在 *图 4.7* 中，你可以看到与 `xgboost_model_baseline`、持续时间以及你在运行中使用的所有参数相关的特定参数：
- en: '![Figure 4.7 – XGBoost classifier details in MLflow'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 4.7 – MLflow 中的 XGBoost 分类器细节'
- en: '](img/B16783_04_07.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16783_04_07.jpg](img/B16783_04_07.jpg)'
- en: Figure 4.7 – XGBoost classifier details in MLflow
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – MLflow 中的 XGBoost 分类器细节
- en: 'For XGBoost models, **MLflow** automatically logs feature information and importance.
    We can see in *Figure 4.8* the ranking of our features in the model stored in
    the *Artifacts* section of the workbench:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 XGBoost 模型，**MLflow** 自动记录特征信息和重要性。我们可以在 *图 4.8* 中看到模型存储在工作台 *艺术品* 部分的特征排名：
- en: '![Figure 4.8 – XGBoost feature importance on MLflow'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.8 – XGBoost 在 MLflow 上的特征重要性'
- en: '](img/B16783_04_08.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16783_04_08.jpg](img/B16783_04_08.jpg)'
- en: Figure 4.8 – XGBoost feature importance on MLflow
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – XGBoost 在 MLflow 上的特征重要性
- en: The feature importance graph in *Figure 4.8* allows the developer to have some
    insights into the internals of the model ascertained from the data. In this particular
    case, it seems that the second and seventh days of the 14 days in the input vector
    are the top two meaningful features. We will next implement a deep learning-based
    model.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4.8* 中的特征重要性图允许开发者从数据中了解模型的内部结构。在这种情况下，似乎输入向量的第 14 天的第 2 天和第 7 天是前两个有意义的特征。接下来，我们将实现一个基于深度学习的模型。'
- en: Steps for setting up a deep learning-based classifier
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于深度学习的分类器设置步骤
- en: In this section, we will implement a neural network algorithm to solve our classification
    problem.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现一个神经网络算法来解决我们的分类问题。
- en: 'The complete notebook for this model is available in the book''s repository
    and can be used to follow along in the Chapter04/gradflow/notebooks/mlflow_run_keras.ipynb
    file:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的完整笔记本位于本书的仓库中，可以在 Chapter04/gradflow/notebooks/mlflow_run_keras.ipynb 文件中找到以进行跟随：
- en: '`tensorflow`, as we are using it as a backend for `keras`:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`tensorflow`，因为我们将其用作 `keras` 的后端：'
- en: '[PRE11]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**Retrieving data**: Refer to Step 2 in the *Steps for setting up an XGBoost-based
    classifier* section.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**获取数据**：请参考 *设置基于 XGBoost 的分类器步骤* 部分的第 2 步。'
- en: '`Baseline_Predictions`, and we need to give MLflow the instruction to automatically
    log the model through `mlflow.tensorflow.autolog`:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Baseline_Predictions`，我们需要给 MLflow 指令，通过 `mlflow.tensorflow.autolog` 自动记录模型：'
- en: '[PRE12]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`Sklearn` or XGBoost classifiers, so we need to define the layers and architecture
    of the network. In this particular case, the `Sequential` architecture and the
    model need to be compiled as required by Tensorflow:'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Sklearn` 或 XGBoost 分类器，因此我们需要定义网络的层和架构。在这种情况下，需要按照 Tensorflow 的要求编译 `Sequential`
    架构和模型：'
- en: '[PRE13]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`run_name` and fitting the model followed by calculating the `f1_score` metrics:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`run_name`、拟合模型以及计算 `f1_score` 指标：'
- en: '[PRE14]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'For `keras` models, **MLflow** automatically logs a myriad of neural network-related
    data, namely, regarding optimizers and epoch and batch sizes, as well as other
    relevant information that can be seen in *Figure 4.9*:'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于 `keras` 模型，**MLflow** 会自动记录大量的神经网络相关数据，包括优化器、epoch 和批大小，以及其他在 *图 4.9* 中可以看到的相关信息：
- en: '![Figure 4.9 – Keras classifier model details'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.9 – Keras 分类器模型细节'
- en: '](img/B16783_04_09.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16783_04_09.jpg](img/B16783_04_09.jpg)'
- en: Figure 4.9 – Keras classifier model details
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – Keras 分类器模型细节
- en: Additionally, **TensorFlow** logs can be hooked into a TensorBoard. This is
    a TensorFlow built-in tool to provide visualizations and metrics for the machine
    learning workflow. Interfaces are created so that the model developer can leverage
    the native TensorFlow instrumentation and specialized visualization tooling.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，**TensorFlow** 日志可以连接到 TensorBoard。这是一个 TensorFlow 内置工具，用于提供机器学习工作流程的可视化和指标。创建了接口，以便模型开发者可以利用本地的
    TensorFlow 仪器和专业的可视化工具。
- en: Having set up our classifiers in our platform, in the next section, we are ready
    to compare the performance of the different classifiers developed using MLflow.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的平台上设置好分类器后，在下一节中，我们将准备好比较使用 MLflow 开发的不同分类器的性能。
- en: Comparing different models
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较不同模型
- en: 'We have run the experiments in this section for each of the models covered
    and verified all the different artifacts. Just by looking at our baseline experiment
    table, and by selecting the common custom metric, `f1_experiment_score`, we can
    see that the best performing model is the logistic regression-based model, with
    an F-score of 0.66:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中为每个覆盖的模型运行了实验，并验证了所有不同的工件。只需查看我们的基线实验表，并选择共同的定制指标 `f1_experiment_score`，我们就可以看到表现最好的模型是基于逻辑回归的模型，F
    分数为 0.66：
- en: '![](img/B16783_04_10.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16783_04_10.jpg)'
- en: Figure 4.10 – Comparing different model performance in terms of the goal metric
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – 从目标指标的角度比较不同模型性能
- en: 'Metrics can also be compared side by side, as shown in the excerpt in *Figure
    4.11*. On the left side, we have the `SKlearn` model, and on the right the XGBoost
    model, with the custom metrics of `f1_experiment_score`. We can see that the metrics
    provided by both are different and, hence, the reason for custom metrics when
    we have different models:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 指标也可以并排比较，如图 *图 4.11* 所示。在左侧，我们有 `SKlearn` 模型，在右侧是 XGBoost 模型，带有自定义的 `f1_experiment_score`
    指标。我们可以看到，两者提供的指标是不同的，因此当我们有不同模型时，自定义指标的原因：
- en: '![Figure 4.11 – Metrics of the Sklearn model'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.11 – Sklearn 模型的指标'
- en: '](img/B16783_04_11.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16783_04_11.jpg)'
- en: Figure 4.11 – Metrics of the Sklearn model
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11 – Sklearn 模型的指标
- en: After comparing the metrics, it becomes clear that the best model is logistic
    regression. To improve the model, in the next section, we will optimize its parameters
    with state-of-the-art techniques and use MLflow experiment features to achieve
    that.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 比较指标后，很明显最佳模型是逻辑回归。为了改进模型，在下一节中，我们将使用最先进的技术来优化其参数，并使用 MLflow 实验功能来实现这一点。
- en: Tuning your model with hyperparameter optimization
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用超参数优化调整模型
- en: Machine learning models have many parameters that allow the developer to improve
    performance and control the model that they are using, providing leverage to better
    fit the data and production use cases. Hyperparameter optimization is the systematic
    and automated process of identifying the optimal parameters for your machine learning
    model and is critical for the successful deployment of such a system.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型有许多参数，允许开发者提高性能并控制他们所使用的模型，提供更好的数据拟合和生产用例的杠杆。超参数优化是系统地、自动地识别机器学习模型最佳参数的过程，对于此类系统的成功部署至关重要。
- en: 'In the previous section, we identified the best family (in other words, `LogisticRegression`)
    model for our problem, so now it''s time to identify the right parameters for
    our model with MLflow. You can follow along in the following notebook in the project
    repository, Chapter04/gradflow/notebooks/hyperopt_optimization_logistic_regression_mlflow.ipynb:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们确定了针对我们问题的最佳模型族（换句话说，`LogisticRegression`），因此现在我们需要使用 MLflow 来确定我们模型的正确参数。您可以在项目仓库中的以下笔记本中跟随操作，位于
    Chapter04/gradflow/notebooks/hyperopt_optimization_logistic_regression_mlflow.ipynb：
- en: '`hyperopt` library, which contains multiple algorithms to help us carry out
    model tuning:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`hyperopt` 库，其中包含多个算法帮助我们进行模型调优：'
- en: '[PRE15]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '`f1_score` metric in our model. The way optimization works in `hyperopt` is
    through minimization, but in our case, we want the maximum possible `f1_score`
    metric. So, the way we define our loss (the function to minimize) is as the inverse
    of our `f1_score` metric, as in `loss = 1-fscore`, so the minimization of this
    function will represent the best `f1_score` metric. For each run of the model''s
    parameters, we will enclose it in an `mlflow.start_run(nested=True)` in such a
    way that each optimization iteration will be logged as a sub run of the main job,
    providing multiple advantages in terms of comparing metrics across runs:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们模型中的 `f1_score` 指标。在 `hyperopt` 中，优化是通过最小化来实现的，但在这个案例中，我们希望得到最大的 `f1_score`
    指标。因此，我们定义损失（最小化的函数）的方式是 `f1_score` 指标的倒数，即 `loss = 1-fscore`，这样这个函数的最小化将代表最佳的
    `f1_score` 指标。对于模型参数的每一次运行，我们将它包裹在 `mlflow.start_run(nested=True)` 中，这样每次优化迭代都会作为主任务的子运行被记录，从而在比较运行间的指标时提供多项优势：
- en: '[PRE16]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '`best` variable. The core function is the minimization represented by `fmin(fn
    = objective, space = space, algo = tpe.suggest, max_evals = MAX_EVALS, trials
    = bayes_trials)`, where we provide the parameter space and objective function
    as previously defined:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`best` 变量。核心功能是最小化，由 `fmin(fn = objective, space = space, algo = tpe.suggest,
    max_evals = MAX_EVALS, trials = bayes_trials)` 表示，其中我们提供了之前定义的参数空间和目标函数：'
- en: '[PRE17]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: After running the experiment for a few minutes, we can now review the experiments
    in `Hyperopt_Optimization` experiment:![Figure 4.12 – Listing all the nested runs
    of the hyperparameter tuning
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行实验几分钟之后，我们现在可以回顾 `Hyperopt_Optimization` 实验中的实验：![图 4.12 – 列出超参数调优的所有嵌套运行
- en: '](img/B16783_04_12.jpg)'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16783_04_12.jpg)'
- en: Figure 4.12 – Listing all the nested runs of the hyperparameter tuning
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.12 – 列出超参数调优的所有嵌套运行
- en: By clicking on the `training_f1_score` and the solver:![](img/B16783_04_13.jpg)
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击 `training_f1_score` 和求解器：![图片](img/B16783_04_13.jpg)
- en: Figure 4.13 – Listing all the nested runs of the hyperparameter tuning
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.13 – 列出超参数调优的所有嵌套运行
- en: 'We can easily compare in the same interface the different solvers and implications
    for our performance metric, providing further insights into our modeling phase:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以轻松地在同一界面中比较不同的求解器和对我们性能指标的影响，从而进一步了解我们的建模阶段：
- en: '![Figure 4.14 – Listing all the nested runs of the hyperparameter tuning'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.14 – 列出超参数调优的所有嵌套运行'
- en: '](img/B16783_04_14.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16783_04_14.jpg](img/B16783_04_14.jpg)'
- en: Figure 4.14 – Listing all the nested runs of the hyperparameter tuning
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14 – 列出超参数调优的所有嵌套运行
- en: We concluded this section by optimizing the parameters of the most performant
    model for our current problem. In the next chapter of the book, we will be using
    the information provided by the best model to delve into the life cycle of the
    model management in **MLflow**.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过优化当前问题的最有效模型的参数来结束本节。在本书的下一章中，我们将使用最佳模型提供的信息，深入探讨**MLflow**中模型管理的生命周期。
- en: Summary
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced the experiments component of MLflow. We got to
    understand the logging metrics and artifacts in MLflow. We detailed the steps
    to track experiments in MLflow.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了MLflow的实验组件。我们了解了MLflow中的日志指标和工件。我们详细说明了在MLflow中跟踪实验的步骤。
- en: In the final sections, we explored the use case of hyperparameter optimization
    using the concepts learned in the chapter.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后几节中，我们探讨了使用本章学到的概念进行超参数优化的用例。
- en: In the next chapter, we will focus on managing models with MLflow using the
    models developed in this chapter.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将专注于使用本章开发的模型，利用MLflow来管理模型。
- en: Further reading
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To consolidate your knowledge further, you can consult the documentation available
    at the following links:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步巩固你的知识，你可以查阅以下链接中的文档：
- en: https://www.mlflow.org/docs/latest/tracking.html
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.mlflow.org/docs/latest/tracking.html](https://www.mlflow.org/docs/latest/tracking.html)'
- en: h[ttps://en.wikipedia.org/wiki/Hyperparameter_optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization)
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://en.wikipedia.org/wiki/Hyperparameter_optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization)'
