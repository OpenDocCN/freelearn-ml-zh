- en: Model Creation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型创建
- en: 'We have now created several data sources based on the original `Titanic` dataset
    in S3\. We are ready to train and evaluate an Amazon ML prediction model. In Amazon
    ML, creating a model consists of the following:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经在S3上创建了几个基于原始“泰坦尼克号”数据集的数据源。我们准备训练和评估一个亚马逊机器学习预测模型。在亚马逊机器学习中，创建一个模型包括以下步骤：
- en: Selecting the training datasource
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择训练数据源
- en: Defining a recipe for data transformation
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义数据转换的配方
- en: Setting the parameters of the learning algorithm
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置学习算法的参数
- en: Evaluating the quality of the model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估模型的品质
- en: In this chapter, we will start by exploring the data transformations available
    in Amazon ML, and we will compare different recipes for the `Titanic` dataset.
    Amazon ML defines recipes by default depending on the nature of the data. We will
    investigate and challenge these default transformations.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先探索亚马逊机器学习中可用的数据转换，并将比较“泰坦尼克号”数据集的不同配方。亚马逊机器学习默认根据数据的性质定义配方。我们将调查并挑战这些默认转换。
- en: The model-building step is simple enough, and we will spend some time examining
    the available parameters. The model evaluation is where everything converges.
    The evaluation metrics are dependent on the type of the prediction at hand, regression,
    binary or multi-class classification. We will look at how these different evaluations
    are carried out. We will also download the model training logs to better understand
    what goes on under the Amazon ML hood when training the model. We will conclude
    the chapter by comparing the model evaluation for several data recipes and regularization
    strategies.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 模型构建步骤足够简单，我们将花一些时间检查可用的参数。模型评估是所有事情汇聚的地方。评估指标取决于预测的类型，回归、二分类或多分类分类。我们将探讨这些不同的评估是如何进行的。我们还将下载模型训练日志，以便更好地理解在亚马逊机器学习中训练模型时幕后发生了什么。我们将通过比较几个数据配方和正则化策略的模型评估来结束本章。
- en: 'The chapter is organized as follows:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章组织如下：
- en: Recipes
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配方
- en: Model parameters
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型参数
- en: Evaluations
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估
- en: Log analysis
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志分析
- en: Feature engineering, recipes, and regularization
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程、配方和正则化
- en: 'At the end of [Chapter 4](08d9b49a-a25c-4706-8846-36be9538b087.xhtml), *Loading
    and Preparing the Dataset,* we modified the schema to exclude three variables:
    `boat`, `body`, and `home.dest` from the original dataset and created a new datasource
    based on this schema. We will use this datasource to train the model.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](08d9b49a-a25c-4706-8846-36be9538b087.xhtml)“加载和准备数据集”的结尾，我们修改了模式，排除了原始数据集中的三个变量：“船”、“尸体”和“home.dest”，并基于此模式创建了一个新的数据源。我们将使用此数据源来训练模型。
- en: 'Go to your Amazon ML datasource dashboard; you should see three datasources:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 前往您的亚马逊机器学习数据源仪表板；您应该看到三个数据源：
- en: '![](img/B05028_05_01.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B05028_05_01.png)'
- en: 'Titanic train set: It is the original raw dataset with 14 variables'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 泰坦尼克号列车集：这是包含14个变量的原始原始数据集
- en: 'Titanic train set 11 variables: Has 11 variables; `boat`, `body` and `home.dest`
    have been removed from the schema'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 泰坦尼克号列车集11个变量：有11个变量；“船”、“尸体”和“home.dest”已从模式中删除
- en: 'Titanic train set extended: It is the cleaned up and extended dataset we obtained
    through SQL-based feature engineering.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 泰坦尼克号列车集扩展版：这是我们通过基于SQL的特征工程获得的清洗和扩展后的数据集。
- en: We will work with the `Titanic train set 11 variables` datasource. Before starting
    with the model creation, let’s first review what types of data transformations
    are available in Amazon ML.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用“泰坦尼克号列车集11个变量”数据源。在开始模型创建之前，让我们首先回顾一下在亚马逊机器学习中可用的数据转换类型。
- en: Transforming data with recipes
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用配方转换数据
- en: A crucial element of the data science workflow is feature engineering. Amazon
    ML offers certain data transformations via its data recipes. Note that although
    transformations are conceptually part of the ETL or data preparation phase of
    a predictive analytics workflow, in Amazon ML, data recipes are part of the model-building
    step and not of the initial datasource creation step. In this section, we start
    by reviewing the available data transformations in Amazon ML, and then we apply
    some of them to the `Titanic` dataset using the `Titanic train set 11 variables`
    datasource.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学工作流程的一个关键要素是特征工程。亚马逊机器学习通过其数据配方提供某些数据转换。请注意，尽管转换在概念上是预测分析工作流程的ETL或数据准备阶段的一部分，但在亚马逊机器学习中，数据配方是模型构建步骤的一部分，而不是初始数据源创建步骤的一部分。在本节中，我们首先回顾亚马逊机器学习中可用的数据转换，然后我们将使用“泰坦尼克号列车集11个变量”数据源将其中一些应用于“泰坦尼克号”数据集。
- en: Managing variables
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理变量
- en: 'Recipes are JSON-structured scripts that contains the following three sections
    in the given order:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 食谱是包含以下三个部分的JSON结构化脚本：按照给定顺序：
- en: Groups
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组
- en: Assignments
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配
- en: Outputs
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出
- en: 'An empty recipe instructing Amazon ML to take all the dataset variables into
    account for model training will be as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一个空食谱指示亚马逊机器学习考虑所有数据集变量进行模型训练，如下所示：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The recipe does not transform the data in any way.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该食谱不会以任何方式转换数据。
- en: The complete Amazon ML recipes documentation is available at [http://docs.aws.amazon.com/machine-learning/latest/dg/recipe-format-reference.html](http://docs.aws.amazon.com/machine-learning/latest/dg/recipe-format-reference.html).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的亚马逊机器学习食谱文档可在[http://docs.aws.amazon.com/machine-learning/latest/dg/recipe-format-reference.html](http://docs.aws.amazon.com/machine-learning/latest/dg/recipe-format-reference.html)找到。
- en: Grouping variables
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量分组
- en: 'Groups enable grouping of multiple variables to facilitate applying the same
    transformations to several variables. The groups section of the recipe has a naming
    function. Group definition follows this syntax:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 组允许将多个变量分组，以便于对多个变量应用相同的转换。食谱的组部分具有命名功能。组定义遵循以下语法：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Amazon ML has defined a set of default groups based on the type of the variables:
    `ALL_TEXT`, `ALL_NUMERIC`, `ALL_CATEGORICAL`, `ALL_BINARY`, and the `ALL_INPUTS`
    group for all the variables at once. Let''s look at a couple of examples.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊机器学习（Amazon ML）根据变量的类型定义了一组默认组：`ALL_TEXT`、`ALL_NUMERIC`、`ALL_CATEGORICAL`、`ALL_BINARY`，以及用于所有变量的`ALL_INPUTS`组。让我们看看几个例子。
- en: 'Consider the following example where we want to apply the same transformation
    (normalization) on the `age` and `fare` variables. We can define a group and name
    it `TO_BE_NORMALIZED`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下示例，我们想要对`age`和`fare`变量应用相同的转换（归一化）。我们可以定义一个组并命名为`TO_BE_NORMALIZED`：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Similarly, consider an e-mail spam detection context where for each e-mail,
    we have a header, a subject, and a body. We want to create N-grams of the e-mail
    title and body but not of the header; we can define a group composed of all text
    variables with the exception of specifically excluded ones. Here we create a group
    named `N_GRAM_TEXT` that combines all text variables except the header:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，考虑一个电子邮件垃圾邮件检测的上下文，其中对于每封电子邮件，我们有一个标题、一个主题和一个正文。我们想要创建电子邮件标题和正文的N-gram，但不包括标题；我们可以定义一个由所有文本变量组成的组，但排除特定的变量。在这里，我们创建一个名为`N_GRAM_TEXT`的组，它结合了除了标题之外的所有文本变量：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Naming variables with assignments
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分配命名变量
- en: The main purpose of assignments is naming facilitation. You can choose to name
    the transformed variable or group of variables in the assignments section or directly
    in the output section. Assignments are only for convenience and readability.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 分配的主要目的是命名便利。您可以选择在分配部分或直接在输出部分命名转换后的变量或变量组。分配只是为了方便和可读性。
- en: 'Assignments follow this syntax:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 分配遵循以下语法：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'For instance, you could rename and normalize the numeric variables as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以按如下方式重命名并归一化数值变量：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Or rename and process the subject and body of your e-mails:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 或者重命名并处理您的电子邮件的主题和正文：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You can also leave the assignments section empty and apply the transformations
    to the variables groups in the output section. In the end, it’s more a question
    of style and readability than anything else.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以留空分配部分，并将转换应用于输出部分的变量组。最后，这更多是一个关于风格和可读性的问题，而不是其他任何事情。
- en: Specifying outputs
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指定输出
- en: 'The outputs section is where you explicitly list all the variables that will
    be used for the model training. If you have defined a group with some of the variables
    but you still want the original variables to be accounted for, you need to explicitly
    list them. The assignment section declares a list composed of the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 输出部分是您明确列出所有用于模型训练的变量的地方。如果您已经定义了一个包含一些变量的组，但仍然希望原始变量被考虑在内，您需要明确列出它们。分配部分声明了一个由以下内容组成的列表：
- en: Groups
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组
- en: Assignments
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配
- en: Variables
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量
- en: Transformation (variable)
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量转换
- en: 'For instance, if you wanted the original body and subject of the e-mails as
    well as the `bigrams` you defined in assignments, you would need to declare the
    outputs as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您想要原始的电子邮件正文和主题，以及您在分配中定义的`bigrams`，您需要如下声明输出：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following outputs declaration declares all the text variables and adds
    the bigrams assignment defined earlier on:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出声明声明了所有文本变量，并添加了之前定义的大词组分配：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The recipe format reference page has other examples of combining groups, assignments,
    and outputs to create recipes: [http://docs.aws.amazon.com/machine-learning/latest/dg/recipe-format-reference.html](http://docs.aws.amazon.com/machine-learning/latest/dg/recipe-format-reference.html).
    We will now look at the available transformations.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 菜单格式参考页面提供了其他示例，展示了如何结合分组、分配和输出以创建菜单：[http://docs.aws.amazon.com/machine-learning/latest/dg/recipe-format-reference.html](http://docs.aws.amazon.com/machine-learning/latest/dg/recipe-format-reference.html)。现在我们将查看可用的转换。
- en: Data processing through seven transformations
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过七个转换进行数据处理
- en: 'Amazon ML offers the following seven transformations. Four transformations
    for text variables are as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon ML提供了以下七个转换。以下是对文本变量的四个转换：
- en: Lowercase transformation
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小写转换
- en: Remove punctuation transformation
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除标点符号转换
- en: N-gram transformation
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: N-gram转换
- en: '**Orthogonal sparse bigram (OSB)** transformation'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正交稀疏二元组（OSB**）转换'
- en: 'Two transformations for numeric variables are as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数值变量，以下有两种转换方式：
- en: Normalization transformation
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正态化转换
- en: Quantile binning transformation
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分位数装箱转换
- en: 'And one transformation for coupling text with categorical variables:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以及一种用于将文本与分类变量耦合的转换
- en: Cartesian product transformation
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卡尔丹产品转换
- en: These transformations are well explained on the Amazon ML documentation ([http://docs.aws.amazon.com/machine-learning/latest/dg/data-transformations-reference.html](http://docs.aws.amazon.com/machine-learning/latest/dg/data-transformations-reference.html)).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这些转换在Amazon ML文档中有很好的解释（[http://docs.aws.amazon.com/machine-learning/latest/dg/data-transformations-reference.html](http://docs.aws.amazon.com/machine-learning/latest/dg/data-transformations-reference.html)）。
- en: Using simple transformations
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用简单的转换
- en: The lowercase transformation takes a text variable as input and returns the
    text in lowercase: `Amazon ML is great for Predictive Analytics` is returned as
    `amazon ml is great for predictive analytics`. Syntax for lowercase transformation
    is `lowercase(text_variable)` or `lowercase(group_of_text_variables)`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 小写转换将文本变量作为输入，并返回小写文本：`Amazon ML is great for Predictive Analytics`返回为`amazon
    ml is great for predictive analytics`。小写转换的语法是`lowercase(text_variable)`或`lowercase(group_of_text_variables)`。
- en: The remove punctuation transformation also takes a text variable as input and
    removes all punctuation signs, with the exception of hyphens within words (`seat-belts`
    will remain as `seat-belts`). It is not possible to define your own set of punctuation
    signs. Syntax for the remove punctuation transformation is `no_punct(text_variable)`
    or `no_punct(group_of_text_variables)`.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 删除标点符号转换也接受文本变量作为输入，并删除所有标点符号，但单词内的连字符除外（`seat-belts`将保持为`seat-belts`）。无法定义自己的标点符号集合。删除标点符号转换的语法是`no_punct(text_variable)`或`no_punct(group_of_text_variables)`。
- en: The normalization transformation normalizes numeric variables to have a mean
    of zero and a variance of one. This is a useful transformation when numeric variables
    vary significantly in range. This transformation corresponds to the **z-score**
    normalization also known as  standardization and not to the min-max normalization
    (see [Chapter 2,](8ec21c70-b7f9-4bb2-bbfd-df8337db86a2.xhtml) *Machine Learning
    Definitions and Concepts*). Syntax for normalization transformation is `normalize(numeric_variable)`
    or `normalize(group_of_numeric_variables)`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 正态化转换将数值变量标准化，使其均值为零，方差为1。当数值变量的范围变化很大时，这种转换非常有用。这种转换对应于**z分数**标准化，也称为标准化，而不是最小-最大标准化（参见[第2章](8ec21c70-b7f9-4bb2-bbfd-df8337db86a2.xhtml)，*机器学习定义和概念*）。正态化转换的语法是`normalize(numeric_variable)`或`normalize(group_of_numeric_variables)`。
- en: Text mining
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本挖掘
- en: The N-gram and the **orthogonal sparse bigram** (**OSB**) transformations are
    the main text-mining transformations available in Amazon ML.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: N-gram和**正交稀疏二元组（OSB**）转换是Amazon ML中可用的主要文本挖掘转换。
- en: In text mining, the classic approach is called the **bag-of-words** approach.
    This approach boils down to discarding the order of the word in a given text and
    only considering the relative frequency of the words in the documents. Although
    it may seem to be overly simplistic, since the order of the words is essential
    to understand a message, this approach has given satisfying results in all types
    of natural language processing problems. A key part of the bag-of-words method,
    is driven by the need to extract the words from a given text. However, instead
    of considering single words as the only elements holding information, we could
    extract sequences of words. These sequences are called N-grams. Sequences of two
    words are called bigrams, for three words trigrams, and so forth. Single words
    are also called unigrams. N-grams are also called tokens and the process of extracting
    words, and N-grams from a text is called tokenization.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本挖掘中，经典的方法被称为**词袋模型**方法。这种方法简化为丢弃给定文本中单词的顺序，只考虑文档中单词的相对频率。尽管这种方法可能看起来过于简单，因为单词的顺序对于理解信息至关重要，但这种方法在所有类型的自然语言处理问题中都给出了令人满意的结果。词袋模型的关键部分是由从给定文本中提取单词的需求驱动的。然而，我们不仅可以将单个单词视为唯一的信息载体，还可以提取单词序列。这些序列被称为N-gram。两个单词的序列称为bigram，三个单词的序列称为trigram，依此类推。单个单词也称为unigram。N-gram也称为tokens，从文本中提取单词和N-gram的过程称为分词。
- en: 'For instance, consider the sentence: *The brown fox jumps over the dog*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下句子：“The brown fox jumps over the dog”
- en: '**Unigrams** are {*The, brown, fox, jumps, over, the, dog*}'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单语元**是：{*The, brown, fox, jumps, over, the, dog*}'
- en: '**Bigrams** are {*The brown, brown fox, fox jumps, jumps over, over the, the
    dog*}'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二元组**是：{*The brown, brown fox, fox jumps, jumps over, over the, the dog*}'
- en: '**Trigrams** are {*The brown fox, brown fox jumps, fox jumps over, jumps over
    the, over the dog*}'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**三元组**是：{*The brown fox, brown fox jumps, fox jumps over, jumps over the,
    over the dog*}'
- en: There is no rule or heuristic that would let you know if you need N-grams in
    your model or what order of N-grams would be the most beneficial for your model.
    It depends on the type of text you are dealing with. Only experimentation can
    tell.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 没有规则或启发式方法可以让你知道在你的模型中是否需要N-gram，或者N-gram的顺序对模型最有益。这取决于你处理文本的类型。只有实验才能告诉你。
- en: 'Amazon ML offers two tokenization transformations: N-gram and OSB.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon ML提供两种分词转换：N-gram和OSB。
- en: 'The **N-gram** transformation: Takes a text variable and an integer from 2
    to 10 and returns expected N-grams. Note that all text variables are, by default,
    tokenized as unigrams in Amazon ML. There is no need to explicitly specify unigrams
    in the recipe. `ngram(text_variable, n)` will produce bigrams for *n= 2*, trigrams
    for *n=3* and so forth.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**N-gram**转换：接受一个文本变量和一个整数（2到10之间），并返回预期的N-gram。请注意，在Amazon ML中，所有文本变量默认按unigram进行分词。在配方中不需要显式指定unigram。`ngram(text_variable,
    n)`将为 *n=2* 产生bigram，为 *n=3* 产生trigram，依此类推。'
- en: The **OSB** or orthogonal sparse bigram transformation is an extension on the
    bigram transformation (N*-gram* with *n=2*). Given a word in a text, compose pairs
    of words by associating the other words separated by *1,2, …, N* words from the
    initial word. *N* being the size of the OSB window.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**OSB**或正交稀疏二元组转换是bigram转换（N*-gram*，其中 *n=2*）的扩展。给定文本中的一个单词，通过将初始单词后隔1、2、…、N个单词的其他单词关联起来，组成单词对。*N*
    是OSB窗口的大小。'
- en: 'For instance, in the sentence *this is a limited time offer*, first consider
    the word *offer*. The OSBs for a window of four are: *time_offer*, *limited_<skip>_offer*,
    *a_<skip>_<skip>_offer*, *is_<skip>_<skip>_<skip>_offer*, *this_<skip>_<skip>_<skip>_<skip>_offer*.
    We build word pairs by skipping 1,2,..., N words each time.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在句子“这是一个限时优惠”中，首先考虑单词“优惠”。对于四个单词的窗口，OSB（One-Skip Bigram）为：*time_offer*、*limited_<skip>_offer*、*a_<skip>_<skip>_offer*、*is_<skip>_<skip>_<skip>_offer*、*this_<skip>_<skip>_<skip>_<skip>_offer*。我们通过每次跳过1、2、...、N个单词来构建单词对。
- en: The OSB transformation allows us to extract information about the context surrounding
    each word. For instance, the OSB *is_<skip>_<skip>_offer*, could be used to detect
    strings such as *is a special offer* as well as *is our best offer*. OSB extraction
    has been found to generally improve the performance of spam filtering algorithms.
    Syntax for OSB transformation is `osb(text_variable, N)`, with `N` the size of
    the window ranging from 2 to 10.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: OSB转换使我们能够提取关于每个单词周围上下文的信息。例如，OSB *is_<skip>_<skip>_offer* 可以用来检测如 *is a special
    offer* 以及 *is our best offer* 这样的字符串。研究发现，OSB提取通常可以提高垃圾邮件过滤算法的性能。OSB转换的语法是 `osb(text_variable,
    N)`，其中 `N` 是窗口大小，范围从2到10。
- en: It’s worth noting that some very standard text transformations are absent from
    Amazon ML recipes. Stemming and **Lemmatization** are used to regroup words with
    different endings to a common base form (for instance, *walking*, *walker* and
    *walked* would all be accounted for as *walk*) and are not offered in Amazon ML.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，一些非常标准的文本转换在Amazon ML食谱中缺失。词干提取和**词形还原**用于将不同结尾的单词重新组合到共同的基本形式（例如，*walking*，*walker*和*walked*都会被计算为*walk*）并且Amazon
    ML不提供这些功能。
- en: Similarly, removing very common words, known as *stopwords*, such as articles
    or prepositions (the, a, but, in, is, are, and so on) from a text is also a very
    standard text-mining transformation but is not an option in Amazon ML recipes.
    It is nonetheless possible that Amazon ML carries out similar transformations
    in the background without explicitly stating so. However, nothing in the available
    documentation indicates that to be the case.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，从文本中移除非常常见的单词，称为*停用词*，如冠词或介词（the, a, but, in, is, are等）也是一种非常标准的文本挖掘转换，但在Amazon
    ML食谱中不是可选项。然而，Amazon ML可能在后台执行类似的转换，但没有明确说明。然而，现有的文档中没有任何内容表明这是事实。
- en: Coupling variables
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 耦合变量
- en: The Cartesian product transformation combines two categorical or text variables
    into one. Consider, for instance, a dataset of books and for each book, their
    title and genre. We could imagine that the title of a book has some correlation
    with its genre, and creating a new `title_genre` variable would bring forth that
    relation.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 笛卡尔积转换将两个分类或文本变量合并为一个。例如，考虑一个包含书籍的数据集，对于每本书，它们的标题和类型。我们可以想象，一本书的标题与其类型之间可能存在某种相关性，创建一个新的`title_genre`变量可以揭示这种关系。
- en: 'Consider the following four books, their titles, and genres. Coupling the words
    in the title with the genre of the book adds extra information to the words in
    the title. Information that the model could use effectively. This is illustrated
    in the `title_genre` column in the following table:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下四本书，它们的标题和类型。将标题中的单词与书的类型耦合，为标题中的单词添加了额外的信息。这是模型可以有效地使用的。这在下表中的`title_genre`列中得到了说明：
- en: '| **Title** | **Genre** | **title_genre** |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| **标题** | **类型** | **title_genre** |'
- en: '| *All the Birds in the Sky* | scifi | {`all_scifi`, `birds_scifi`, `sky_scifi`}
    |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| *All the Birds in the Sky* | 科幻 | `{all_scifi, birds_scifi, sky_scifi}` |'
- en: '| *Robots and Empire* | scifi | `{robots_scifi`, `emprire_scifi`} |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| *Robots and Empire* | 科幻 | `{robots_scifi, empire_scifi}` |'
- en: '| *The Real Cool Killers* | crime | {`real_crime`, `cool_crime`, `killers_crime`}
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| *The Real Cool Killers* | 犯罪 | `{real_crime, cool_crime, killers_crime}`
    |'
- en: '| *Bullet in the Sky* | crime | {`bullet_crime`, `sky_crime`} |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| *Bullet in the Sky* | 犯罪 | `{bullet_crime, sky_crime}` |'
- en: The word sky now takes a different meaning if it's in the title of a crime novel: `sky_crime`
    or in the title of a SciFi novel: `sky_scifi`.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它出现在犯罪小说的标题中，单词sky现在有不同的含义：`sky_crime`或出现在科幻小说的标题中：`sky_scifi`。
- en: 'In the case of the `Titanic` dataset, we could couple the `sibsp` and `*parch*`
    variables (number of siblings and number of parents) by taking their cartesian
    products: `sibsp*parch` and come up with a new variable that distinguishes between
    passengers with (without) parents and few or no siblings from those with (without)
    parents and many siblings. Syntax is `cartesian(var1, var2)`.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Titanic`数据集的情况下，我们可以通过取它们的笛卡尔积来耦合`sibsp`和`*parch*`变量（兄弟姐妹数量和父母数量）：`sibsp*parch`，从而得到一个新的变量，该变量可以区分有（无）父母和兄弟姐妹较少或没有的乘客与有（无）父母和兄弟姐妹较多的乘客。语法是`cartesian(var1,
    var2)`。
- en: Binning numeric values
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分箱数值
- en: The final and most important transformation is quantile binning. The goal with
    quantile binning is to transform a numeric variable into a categorical one in
    order to better extract the relation between the variable and the prediction target.
    This is particularly useful in the presence of nonlinearities between a variable
    and the target. By splitting the original numeric variables values into *n* bins
    of equal size, it is possible to substitute each value by a corresponding bin.
    Since the number of bins is finite (from 2 to 1,000), the variable is now categorical.
    Syntax is `quantile_bin(var, N)` with `N` the number of bins.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最后也是最重要的转换是分位数分箱。分位数分箱的目标是将数值变量转换为分类变量，以便更好地提取变量与预测目标之间的关系。这在变量与目标之间存在非线性关系时特别有用。通过将原始数值变量的值分成大小相等的*n*个箱，可以将每个值替换为相应的箱。由于箱的数量是有限的（从2到1,000），变量现在是分类的。语法是`quantile_bin(var,
    N)`，其中`N`是箱的数量。
- en: There are two types of unsupervised binning, equal frequency and equal width
    binning. In equal frequency, each bin has the same number of samples, whereas
    in equal width binning, the variable range is split into N smaller ranges of equal
    width. Quantile binning usually refers to equal frequency binning.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种无监督分箱类型，等频分箱和等宽分箱。在等频分箱中，每个分箱具有相同数量的样本，而在等宽分箱中，变量范围被分成N个宽度相等的更小范围。分位数分箱通常指的是等频分箱。
- en: Categorizing continuous data is not always a good approach as you are, by definition,
    throwing away information that could be useful for the model. This page lists
    several other problems associated with binning: [http://biostat.mc.vanderbilt.edu/wiki/Main/CatContinuous](http://biostat.mc.vanderbilt.edu/wiki/Main/CatContinuous).
    However, Amazon ML seems to be quite fond of the quantile binning technique. In
    fact, of all the datasets we considered, Amazon ML always applied quantile binning
    to all the numeric variables, in the suggested recipe and often used large, sometimes
    very large, number of bins. For instance, the default transformation for the `fare`
    variable in the `Titanic` dataset was quantile binning with 500 bins although
    the variable only ranged from 0 to 512\. We compare the evaluations obtained by
    keeping the original numeric values versus applying quantile binning at the end
    of this chapter, *Keeping variables as numeric or applying quantile binning?*
    section Now that we’ve explored the available recipes, let’s look at how Amazon
    ML suggests we transform our `Titanic` dataset
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 将连续数据分类并不总是好的方法，因为你按照定义，正在丢弃可能对模型有用的信息。此页面列出了与分箱相关的一些其他问题：[http://biostat.mc.vanderbilt.edu/wiki/Main/CatContinuous](http://biostat.mc.vanderbilt.edu/wiki/Main/CatContinuous)。然而，亚马逊机器学习似乎非常喜欢分位数分箱技术。事实上，在我们考虑的所有数据集中，亚马逊机器学习总是对所有数值变量应用分位数分箱，在建议的食谱中，通常使用大量，有时是非常大量的分箱。例如，`Titanic`数据集中`fare`变量的默认转换是使用500个分箱的分位数分箱，尽管变量的范围仅从0到512。我们在本章的末尾比较了保留原始数值与在*保持变量为数值或应用分位数分箱？*部分应用分位数分箱所获得的评估结果。
- en: Creating a model
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建模型
- en: Amazon ML always suggests a recipe based on your datasource when you create
    a model. You can choose to use that recipe or to modify it. We will now create
    our first model and during that process analyze the recipe Amazon ML has generated
    for us.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建模型时，亚马逊机器学习会根据你的数据源建议一个食谱。你可以选择使用该食谱或对其进行修改。我们现在将创建我们的第一个模型，并在创建模型的过程中分析亚马逊机器学习为我们生成的食谱。
- en: Go to the model dashboard, and click on the Create new... | ML model button.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 前往模型仪表板，然后单击创建新... | 机器学习模型按钮。
- en: 'You will go through three screens:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你将经历三个屏幕：
- en: Select the datasource, choose the `Titanic train set with 11 variables`.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择数据源，选择`Titanic train set with 11 variables`。
- en: Amazon ML will validate the datasource and present a summary.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 亚马逊机器学习将验证数据源并展示摘要。
- en: 'Choose the default or Custom model creation; choose the custom path:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择默认或自定义模型创建；选择自定义路径：
- en: '![](img/B05028_05_02.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B05028_05_02.png)'
- en: 'The next screen is split between the attributes, their type and a sample of
    values on the left side, and the suggested recipe on the right side, as shown
    in the following screenshot:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个屏幕在属性、它们的类型和左侧的值样本之间分割，以及右侧的建议食谱，如下面的截图所示：
- en: '![](img/B05028_05_03.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B05028_05_03.png)'
- en: Editing the suggested recipe
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编辑建议的食谱
- en: This is where you can edit the recipe and replace it with a recipe of your own
    creation.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你可以编辑食谱并替换为你自己创建的食谱的地方。
- en: You can find all the JSON in this chapter in the book's GitHub repository, properly
    formatted and indented at [https://github.com/alexperrier/packt-aml/blob/master/ch5/recipes.json](https://github.com/alexperrier/packt-aml/blob/master/ch5/recipes.json).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本书的GitHub仓库中找到本章中所有的JSON文件，格式正确，缩进良好：[https://github.com/alexperrier/packt-aml/blob/master/ch5/recipes.json](https://github.com/alexperrier/packt-aml/blob/master/ch5/recipes.json)。
- en: 'The recipe is validated while you type. Anything not respecting the JSON format
    will result in the following error message: `Recipe must be valid JSON`. Some
    common errors include the following:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 食谱在您输入时进行验证。任何不遵守JSON格式的都会导致以下错误消息：“食谱必须是有效的JSON”。一些常见错误包括以下内容：
- en: Indentation is not respected
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩进不被尊重
- en: The last element between braces should not be followed by a comma
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大括号中的最后一个元素后面不应该跟有逗号
- en: All strings must be between double quotes
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有字符串都必须使用双引号括起来
- en: 'Manually formatting JSON text is not fun. This online JSON editor is very helpful:
    [http://www.cleancss.com/json-editor/](http://www.cleancss.com/json-editor/).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 手动格式化JSON文本并不有趣。这个在线JSON编辑器非常有帮助：[http://www.cleancss.com/json-editor/](http://www.cleancss.com/json-editor/)。
- en: Applying recipes to the Titanic dataset
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将食谱应用于泰坦尼克号数据集
- en: 'The recipe generated by Amazon ML for our dataset is as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊机器学习为我们生成的数据集的食谱如下：
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: All numeric values are quantile binned. No further processing is done on the
    text, binary, or categorical variables. The output section of the recipe shows
    that the numeric variables are replaced by the binned equivalent.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 所有数值都是分位数分箱。对文本、二进制或分类变量不进行进一步处理。食谱的输出部分显示，数值变量被替换为分箱等效值。
- en: 'Further comments can be made on this recipe:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 可以对这道食谱提出进一步的意见：
- en: The `sibsp` and `parch` variables are grouped together. First of all, both `sibsp`
    and `parch` have similar ranges, 0 to 9 and 0 to 8 respectively. It makes sense
    to have the same number of bins for both variables.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`sibsp`和`parch`变量分组在一起。首先，`sibsp`和`parch`都有相似的取值范围，分别是0到9和0到8。对这两个变量使用相同数量的分箱是有意义的。
- en: Why Amazon ML chose 50 bins for `sibsp` and `parch`, 100 bins for `age`, and
    10 bins for `fare` is less clear.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么亚马逊机器学习为`sibsp`和`parch`选择了50个分箱，为`age`选择了100个分箱，为`fare`选择了10个分箱，这一点不太清楚。
- en: We found that the number of bins was very sensitive to the data in the training
    set. Several versions of the initial datasets produced very different binning
    numbers. One constant in all our trials was that all the numeric values went through
    quantile binning with a rather high number of bins. In one instance, Amazon ML
    suggested 500 bins for the `fare` variable and 200 for the `age` variable. In
    both cases, we would have ended with a very small number of samples per bin since
    our total number of training sample consists of just 1,047 passengers. How Amazon
    ML calculates the optimal number of bins is not clear.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现分箱的数量对训练集中的数据非常敏感。几个版本的初始数据集产生了非常不同的分箱数量。我们所有试验中的一个常数是，所有的数值都通过具有相当高数量的分箱进行分位数分箱。在一种情况下，亚马逊机器学习建议`fare`变量使用500个分箱，`age`变量使用200个分箱。在这两种情况下，由于我们的总训练样本数只有1,047名乘客，我们每个分箱的样本数将非常少。亚马逊机器学习如何计算最优分箱数量并不清楚。
- en: 'There are other transformations Amazon ML could decide to apply to our `Titanic`
    dataset such as the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊机器学习还可以决定对我们的`泰坦尼克号`数据集应用以下其他转换：
- en: Extracting bigrams or OSBs from the passengers' titles
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从乘客的标题中提取二元组或OSB
- en: Coupling `sibsp` and `parch` with cartesian product transformation
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`sibsp`和`parch`与笛卡尔积转换结合
- en: Choosing between recipes and data pre-processing.
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在食谱和数据预处理之间进行选择。
- en: So far we have transformed our initial dataset via scripts and Amazon ML recipes.
    The two techniques are complementary. Some transformation and data manipulation
    can only be done by preprocessing the data. We did so in [Chapter 4,](08d9b49a-a25c-4706-8846-36be9538b087.xhtml) *Loading
    and Preparing the Dataset* with Athena and SQL. We could have achieved similar
    data processing with other scripting languages such as Python or R, which are
    most fruitful for creative feature engineering. SQL and scripts can also better
    deal with outliers and missing values — corrections that are not available with
    Amazon ML recipes.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经通过脚本和亚马逊机器学习食谱将我们的初始数据集进行了转换。这两种技术是互补的。一些转换和数据操作只能通过预处理数据来完成。我们在[第4章，](08d9b49a-a25c-4706-8846-36be9538b087.xhtml)
    *加载数据集和准备数据* 中使用Athena和SQL这样做。我们也可以使用其他脚本语言（如Python或R）来实现类似的数据处理，这些语言在创意特征工程方面最有成效。SQL和脚本还可以更好地处理异常值和缺失值——这些修正在亚马逊机器学习食谱中是不可用的。
- en: The goal of the Amazon ML transformations is to prepare the data for consumption
    by the Amazon ML algorithm, whereas scripted feature engineering is about cleaning
    up the data and creating new variables out of the original dataset.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊机器学习转换的目标是 为亚马逊机器学习算法准备数据，而脚本特征工程则是关于清理数据并从原始数据集中创建新变量。
- en: 'Although Amazon ML recipes are quite restrained, they offer an easy way to
    fiddle around with the dataset and quickly compare models based on different recipes.
    Creating a new model and associated evaluation from a given datasource and schema only
    takes a few clicks. And by choosing to write different recipes for each model,
    it becomes possible to experiment with a wide range of datasets. Recipes allow
    us to create a fast try-fail loop. The associated workflow becomes the following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然亚马逊机器学习食谱相当有限，但它们提供了一个简单的方法来调整数据集，并快速比较基于不同食谱的模型。从给定的数据源和模式创建新模型及其评估只需几点击。通过为每个模型选择不同的食谱，可以尝试广泛的数据库。食谱允许我们创建快速的尝试-失败循环。相关的流程如下：
- en: Specify the datasource.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定数据源。
- en: Experiment with different recipes.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试不同的食谱。
- en: Create or remove variables.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建或删除变量。
- en: Train and select the model associated to that recipe.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练并选择与该食谱关联的模型。
- en: Once the best recipe is found, then start optimizing the model parameters, regularization,
    passes, and memory.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦找到最佳食谱，就开始优化模型参数、正则化、遍历次数和内存。
- en: 'We can compare how we transformed the data with scripting (Athena and SQL)
    and with recipes:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以比较使用脚本（Athena和SQL）和使用食谱如何转换数据：
- en: '**Recipes:**'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**食谱：**'
- en: Removing features (`boat`, `body`, and `home.dest`). This can also be done via
    the schema or directly by removing the columns from the dataset CSV file.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除特征（`boat`、`body`和`home.dest`）。这也可以通过模式或直接从数据集CSV文件中删除列来完成。
- en: Cartesian product for an indication of family by aggregating `parch` and `sibsp`.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过聚合`parch`和`sibsp`来表示家庭的笛卡尔积。
- en: Normalization of numeric values (a possibility).
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值归一化（一种可能性）。
- en: Tokenization of all text variables, names, destinations, and so on.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对所有文本变量、名称、目的地等进行分词。
- en: Quantile binning of all numeric values; although the number of bins were large
    this transformation produced good results.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对所有数值进行分位数分箱；尽管分箱数量很大，但这种转换产生了良好的结果。
- en: '**Scripting (SQL):**'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**脚本（SQL）：**'
- en: Handling missing values for `age`: We replaced all missing values by the mean
    of the *age*
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理`年龄`的缺失值：我们将所有缺失值替换为*年龄*的平均值
- en: 'Text processing: We extracted `titles` from the `name` variables'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本处理：我们从`name`变量中提取了`titles`
- en: Created a new feature, the `family_size` as the sum of `parch` and `sibsp`
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了一个新的特征，即`family_size`，它是`parch`和`sibsp`的总和
- en: Extraction of the `deck` from the cabin number
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从船舱号中提取`deck`
- en: Both approaches are very complementary.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法都非常互补。
- en: Parametrizing the model
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参数化模型
- en: 'Now that our data has been prepared for the SGD algorithm, we are ready to
    set the parameters of our experiment. In a way similar to scientific experimentation,
    we will want to try out several sets of parameters to test several models and
    pick up the best one. The next screenshot shows where we actually specify our model
    parameters:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已经为SGD算法准备好了，我们准备设置实验参数。在某种程度上类似于科学实验，我们将尝试几组参数来测试几个模型，并选择最好的一个。下一张截图显示了实际上指定模型参数的位置：
- en: Model memory
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型内存
- en: Data passes
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据遍历
- en: Shuffling
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打乱顺序
- en: Regularization
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则化
- en: '![](img/B05028_05_04.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B05028_05_04.png)'
- en: Setting model memory
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置模型内存
- en: Model memory is related to the memory Amazon ML must set aside to build and
    evaluate your model. It is set, by default, to 100Mb. In the case of the `Titanic`
    dataset, the model memory was always below 1Mb as shown by the logs. Model memory
    is also used to set aside memory when dealing with streaming data.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 模型内存与亚马逊机器学习必须预留的内存有关，以构建和评估您的模型。默认设置为100Mb。在`泰坦尼克号`数据集的情况下，模型内存始终低于1Mb，如日志所示。模型内存还用于处理流数据时预留内存。
- en: Setting the number of data passes
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置数据遍历次数
- en: Amazon ML will use the training set of samples several times, each time shuffling
    it and using the new sequence to increase prediction. It's similar to squeezing
    a wet piece of cloth — each time you wring it, more water comes out of it. Set
    by default to 10 passes, it does not hurt to set it to the maximum value of a
    100 at the expense of a longer training time for the model and a higher cost of
    operation.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊机器学习将多次使用样本的训练集，每次都打乱它并使用新的序列来提高预测。这类似于挤压一块湿布——每次挤压，都会有更多的水出来。默认设置为10次遍历，将其设置为100的最大值不会伤害到模型，但会增加模型的训练时间和操作成本。
- en: Choosing regularization
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择正则化
- en: As seen in [Chapter 2,](8ec21c70-b7f9-4bb2-bbfd-df8337db86a2.xhtml) *Machine
    Learning Definitions and Concepts*, regularization makes your model more robust
    and allows it to better handle previously unseen data by reducing overfitting.
    The rule of thumb is to lower regularization if your evaluation score is poor
    (underfitting) and increase it if your model shows great performance on the training
    set but poor results on the evaluation set (overfitting).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第2章](8ec21c70-b7f9-4bb2-bbfd-df8337db86a2.xhtml)中所述，*机器学习定义和概念*，正则化可以使你的模型更加鲁棒，并允许它通过减少过拟合来更好地处理之前未见过的数据。经验法则是，如果你的评估分数不佳（欠拟合），则降低正则化；如果你的模型在训练集上表现出色，但在评估集上表现不佳（过拟合），则增加正则化。
- en: Creating an evaluation
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建评估
- en: 'Evaluations and models are independent in Amazon ML. You can train a model
    and carry out several evaluations by specifying different evaluation datasets.
    The evaluation page, shown in the following screenshot, lets you name and specify
    how the model will be evaluated:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在Amazon ML中，评估和模型是独立的。你可以通过指定不同的评估数据集来训练一个模型并执行多个评估。以下截图所示的评估页面允许你命名并指定如何评估模型：
- en: '![](img/B05028_05_05.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B05028_05_05.png)'
- en: As you know by now, to evaluate a model, you need to split your dataset into
    two parts, the training and the evaluation sets with a 70/30 split. The training
    part is used to train your model, while the evaluation part is used to evaluate
    the model. At this point, you can let Amazon ML split the dataset into training
    and evaluation or specify a different datasource for evaluation.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，为了评估一个模型，你需要将你的数据集分成两部分，即训练集和评估集，比例为70/30。训练部分用于训练你的模型，而评估部分用于评估模型。在这个阶段，你可以让Amazon
    ML自动将数据集分成训练集和评估集，或者指定一个不同的数据源用于评估。
- en: Recall that the initial `Titanic` file was ordered by class and passenger alphabetical
    order. Using this ordered dataset and splitting it without shuffling, that is,
    taking sequentially the first 70% samples, would give the model a very different
    data for the training and the evaluation sets. The evaluation would not be relevant.
    However, if your data is not already shuffled, you can tell Amazon ML to shuffle
    it. It is a good practice to let Amazon ML reshuffle your data by default just
    in case your own randomizing left some sequential patterns in the dataset.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，最初的`Titanic`文件是按阶级和乘客的字母顺序排序的。使用这个有序数据集并且不进行洗牌，即按顺序取前70%的样本，会给模型带来非常不同的训练集和评估集数据。这样的评估将不相关。然而，如果你的数据尚未洗牌，你可以告诉Amazon
    ML对其进行洗牌。让你的数据默认由Amazon ML重新洗牌是一个好习惯，以防你自己的随机化在数据集中留下了某些顺序模式。
- en: Amazon ML will make some verifications regarding your training and validation
    sets, checking that there is enough data for the validation, that the two sets
    follow similar distributions, and that the evaluation set has valid samples. Take
    a look at [http://docs.aws.amazon.com/machine-learning/latest/dg/evaluation-alerts.html](http://docs.aws.amazon.com/machine-learning/latest/dg/evaluation-alerts.html) for
    more information on Evaluation Alerts.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon ML将对你的训练集和验证集进行一些验证，检查验证集是否有足够的数据，两个集合是否遵循相似的分布，以及评估集是否有有效的样本。有关评估警报的更多信息，请参阅[http://docs.aws.amazon.com/machine-learning/latest/dg/evaluation-alerts.html](http://docs.aws.amazon.com/machine-learning/latest/dg/evaluation-alerts.html)。
- en: Note that if you choose to let Amazon ML split the data, it will create two
    new datasources titled in a way that lets you see how the split was performed.
    You can reuse these new datasources if you decide to test another model with different
    recipes or model parameters such as regularization.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果你选择让Amazon ML分割数据，它将创建两个新的数据源，并以一种方式命名，让你可以看到分割是如何进行的。如果你决定使用不同的配方或模型参数（如正则化）测试另一个模型，你可以重用这些新数据源。
- en: 'For instance:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '`Titanic.csv_[percentBegin=0, percentEnd=70, strategy=sequential]`'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Titanic.csv_[percentBegin=0, percentEnd=70, strategy=sequential]`'
- en: '`Titanic.csv_[percentBegin=70, percentEnd=100, strategy=random]`'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Titanic.csv_[percentBegin=70, percentEnd=100, strategy=random]`'
- en: Click on Review, make sure your model is as expected, and click on the final
    *Create ML model* button. Creating the model usually takes a few minutes.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“审查”，确保你的模型符合预期，然后点击最后的“创建ML模型”按钮。创建模型通常需要几分钟。
- en: Evaluating the model
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型
- en: At this point, Amazon ML will use the training set to train several models and
    the evaluation sets to select the best one.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，Amazon ML将使用训练集来训练多个模型，并使用评估集来选择最佳模型。
- en: Amazon ML runs several model training in parallel, each time trying new parameters
    and shuffling the training set at each new pass. Once the number of passes initially
    set has been exhausted or the algorithm has converged, whichever comes first,
    the model is considered trained. For each model it trains, Amazon ML uses it for
    prediction on the validation subset to obtain an evaluation score per model. Once
    all the models have been trained and evaluated this way, Amazon ML simply selects
    the one with the best evaluation score.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon ML并行运行多个模型训练，每次尝试新的参数并在每次新遍历时对训练集进行洗牌。一旦达到最初设置的遍历次数或算法收敛，以先到者为准，模型就被认为是训练好的。对于它训练的每个模型，Amazon
    ML都会用它对验证子集进行预测以获得每个模型的评估分数。一旦所有模型都以这种方式训练和评估，Amazon ML就会简单地选择评估分数最好的模型。
- en: The evaluation metric depends on the type of prediction at hand. AUC and `F1`
    score for classification (binary and multiclass), and RMSE for regression. How
    the evaluation results are displayed by Amazon ML also depends on the type of
    prediction at hand.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标取决于手头的预测类型。对于分类（二分类和多分类），是AUC和`F1`分数，对于回归是RMSE。Amazon ML如何显示评估结果也取决于手头的预测类型。
- en: We’ll start with evaluation for binary classification for our Titanic prediction,
    followed by the regression case with a new dataset related to Air traffic delays,
    and finally perform multiclass classification with the classic `Iris` dataset.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先评估我们的泰坦尼克号预测的二分类性能，接着是关于空中交通延误的新数据集的回归案例，最后使用经典的`Iris`数据集进行多分类分类。
- en: Evaluating binary classification
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估二分类
- en: Once your model is ready, click on the model's title from the service dashboard
    to access the model's result page, which contains the summary of the model, its
    settings and the evaluation results.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的模型准备就绪，点击服务仪表板上的模型标题，即可访问模型的结果页面，其中包含模型的摘要、设置和评估结果。
- en: The following screenshot shows that we obtained an *AUC* score of `0.880`, which
    is considered very good for most machine-learning applications. **AUC** stands
    for the **Area under the Curve** and was introduced in [Chapter 2](8ec21c70-b7f9-4bb2-bbfd-df8337db86a2.xhtml), *Machine
    Learning Definitions and Concepts*. It is the de-facto metric for classification
    problems.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的截图显示，我们获得了`0.880`的*AUC*分数，这在大多数机器学习应用中被认为是非常好的。**AUC**代表**曲线下面积**，在[第二章](8ec21c70-b7f9-4bb2-bbfd-df8337db86a2.xhtml)，“机器学习定义和概念”中介绍。它是分类问题的实际度量标准。
- en: 'The baseline for Binary classification is an AUC of 0.5, which is the score
    for a model that would randomly predict 0 or 1:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类的基线是0.5的AUC，这是随机预测0或1的模型的分数：
- en: '![](img/B05028_05_06.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05028_05_06.png)'
- en: 'Amazon ML validates the model by checking the following conditions and raising
    alerts in case the conditions are not met:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon ML通过检查以下条件来验证模型，并在条件不满足时发出警报：
- en: '![](img/B05028_05_07.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05028_05_07.png)'
- en: 'In our case, no alerts were raised:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，没有触发任何警报：
- en: The training and validation datasets were separate
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和验证数据集是分开的
- en: The validation dataset had a sufficient number of samples
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证数据集有足够的样本数量
- en: The validation and training sets shared the same schema
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证集和训练集共享相同的模式
- en: All samples of the validation set were valid and used for the evaluation, implying
    that the target was not missing for one or more samples
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证集的所有样本都是有效的，并用于评估，这意味着目标变量对于一个或多个样本没有缺失
- en: The distribution of the target variable was similar in the training and validation
    sets
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标变量的分布训练集和验证集中相似
- en: Most of these alerts will not happen if we let Amazon ML handle the training
    validation data split, but they might be more frequent if we provide the validation
    set ourselves.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们让Amazon ML处理训练和验证数据的拆分，大多数这些警报将不会发生，但如果我们自己提供验证集，它们可能会更频繁。
- en: The AUC score is not the only element Amazon ML gives us to evaluate the quality
    of our model. By clicking on the *Explore performance* link, we can analyze further
    the performance of our model.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: AUC分数不是Amazon ML给我们评估模型质量的唯一元素。通过点击*探索性能*链接，我们可以进一步分析我们模型的性能。
- en: Exploring the model performances
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索模型性能
- en: 'You may recall from [Chapter 2](8ec21c70-b7f9-4bb2-bbfd-df8337db86a2.xhtml):
    *Machine Learning Definitions and Concepts,* that in a binary classification context,
    a logistic regression model calculates for each sample to be predicted a probability
    — the probability of belonging to one class or the other. The model will not directly
    output the class of the sample to be predicted. The sample is assigned to one
    class or the other depending on whether the probability is below or above a certain
    threshold. By default, this threshold is set to 0.5\. Although the AUC score given
    by the evaluation does not depend on the value of the decision threshold, other
    classification metrics do. We can change the value of the threshold and see how
    that impacts our predictions.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得[第二章](8ec21c70-b7f9-4bb2-bbfd-df8337db86a2.xhtml)：*机器学习定义和概念*，在二元分类的情境下，逻辑回归模型为每个待预测样本计算一个概率——属于某一类或另一类的概率。模型不会直接输出待预测样本的类别。样本被分配到某一类或另一类，取决于概率是否低于或高于某个特定阈值。默认情况下，这个阈值设置为0.5。尽管评估给出的AUC分数不依赖于决策阈值的值，但其他分类指标则不然。我们可以改变阈值的值，看看这对我们的预测有何影响。
- en: The **Explore performance** page of the evaluation shows several other classification
    metrics as well as the confusion matrix of the model. The vertical bar in the
    graph below is a cursor that can slide left or right. By sliding the cursor, we
    increase or decrease the decision threshold used to classify a prediction sample
    as belonging to one class or another. As we move that cursor, the following metrics
    vary accordingly.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索性能**页面展示了评估中的几个其他分类指标以及模型的混淆矩阵。下面图表中的垂直条是一个可以左右滑动的光标。通过滑动光标，我们可以增加或减少用于将预测样本分类为某一类或另一类的决策阈值。随着光标的移动，以下指标相应变化。'
- en: False positive rate
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假正率
- en: 'Precision: proportion of predicted positives that are truly positives'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确率：预测为正例的真正正例比例
- en: Recall (the proportion of positives that are correctly identified)
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回忆率（正确识别的正例比例）
- en: Accuracy
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率
- en: 'For a threshold of *0.5*, we have the following sceenshot:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*0.5*的阈值，我们有以下截图：
- en: '![](img/B05028_05_08.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B05028_05_08.png)'
- en: 'If we lower the threshold to *0.4*, accuracy decreases while recall increases,
    as you can see in the following screenshot:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将阈值降低到*0.4*，准确率降低，而回忆率提高，如以下截图所示：
- en: '![](img/B05028_05_09.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B05028_05_09.png)'
- en: 'And if we raise the threshold to *0.7*, accuracy increases slightly while recall
    decreases:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将阈值提高到*0.7*，准确率略有提高，而回忆率降低：
- en: '![](img/B05028_05_10.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B05028_05_10.png)'
- en: In our context, the predictions are quite clearly separated between survived
    and did not survive values. Slightly changing the threshold does not have a huge impact
    on the metrics.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情境中，预测值在“存活”和“未存活”之间非常明显地区分开来。稍微改变阈值对指标的影响并不大。
- en: Evaluating linear regression
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估线性回归
- en: 'Amazon ML uses the standard metric RMSE for linear regression. RMSE is defined
    as the sum of the squares of the difference between the real values and the predicted
    values:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon ML使用标准的RMSE指标进行线性回归。RMSE定义为真实值与预测值之间差的平方和：
- en: '![](img/image_03_015.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_03_015.png)'
- en: Where *ŷ* are the predicted values and *y* the real values. The closer the predictions
    are to the real values, the lower the RMSE is; therefore, a lower RMSE is interpreted
    as a better predictive model.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*ŷ*是预测值，*y*是真实值。预测值越接近真实值，RMSE越低；因此，较低的RMSE被视为更好的预测模型。
- en: To demonstrate the evaluation in the regression context, we will consider a
    simplified version of the **Airlines delay** dataset available on Kaggle at [https://www.kaggle.com/giovamata/airlinedelaycauses](https://www.kaggle.com/giovamata/airlinedelaycauses).
    The full dataset is quite large (*~250Mb*). We extracted roughly *19,000* rows
    from the year 2008, filtering out cancelled flights. We also removed several variables
    that were too correlated with our target, which is the `Airdelay` variable. The
    resulting dataset and schema are available on GitHub at [https://github.com/alexperrier/packt-aml/tree/master/ch5](https://github.com/alexperrier/packt-aml/tree/master/ch5).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示回归背景下的评估，我们将考虑Kaggle上可用的**航空公司延误**数据集的简化版本，网址为[https://www.kaggle.com/giovamata/airlinedelaycauses](https://www.kaggle.com/giovamata/airlinedelaycauses)。完整的数据集相当大（*~250Mb*）。我们从2008年提取了大约*19,000*行数据，过滤掉了取消的航班。我们还删除了与我们的目标变量`Airdelay`高度相关的几个变量。结果数据集和模式可在GitHub上找到，网址为[https://github.com/alexperrier/packt-aml/tree/master/ch5](https://github.com/alexperrier/packt-aml/tree/master/ch5)。
- en: 'We upload the dataset to S3, create a datasource, train and evaluate a model
    and finally obtain an RMSE of 7.0557 with a baseline of 31.312. The baseline for
    regression is given by a model that always predicts the average of the target:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据集上传到S3，创建数据源，训练和评估模型，最终获得RMSE为7.0557，基线为31.312。回归的基线由一个总是预测目标平均值的模型给出：
- en: '![](img/B05028_05_14.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05028_05_14.png)'
- en: 'Exploring further, we obtain the following histograms of residuals. As we can
    see in the next screenshot, the errors are roughly bell-shaped and centered around
    *0*, meaning that our errors are half the time overestimating/underestimating
    the real values. All the information available in the dataset has been consumed
    by the model:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步探索，我们获得了以下残差直方图。如图所示，误差大致呈钟形，且围绕*0*中心，这意味着我们的误差有一半的时间高估/低估了真实值。数据集中所有可用的信息都被模型消耗了：
- en: '![](img/B05028_05_15.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05028_05_15.png)'
- en: Evaluating multiclass classification
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估多类分类
- en: The classic dataset for multiclass classification is the `Iris` dataset composed
    of three types of Iris flowers. This dataset is quite simple, very popular and
    using it to illustrate the performance of a platform as powerful as Amazon ML
    seems overkill. Luckily, there are another three class datasets composed of seeds.
    The seeds dataset is available at [https://archive.ics.uci.edu/ml/datasets/seeds](https://archive.ics.uci.edu/ml/datasets/seeds)
    and of course on the GitHub repository accompanying this book (as well as the
    schema).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 多类分类的经典数据集是包含三种鸢尾花类型的`Iris`数据集。这个数据集相当简单，非常受欢迎，使用它来展示像Amazon ML这样强大的平台似乎有些过度。幸运的是，还有另外三个由种子组成的三类数据集。种子数据集可在[https://archive.ics.uci.edu/ml/datasets/seeds](https://archive.ics.uci.edu/ml/datasets/seeds)找到，当然，也可以在本书的GitHub仓库中找到（以及模式）。
- en: The seed dataset has 210 samples distributed evenly among three different `seedTypes`
    and seven attributes. The dataset has an ID, which must be set to categorical,
    all attributes are NUMERIC, and the target is the `seedType.` We upload the dataset
    to S3, and create a datasource and a model.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 种子数据集有210个样本，均匀分布在三种不同的`seedTypes`和七个属性中。数据集有一个ID，必须设置为分类，所有属性都是数值型，目标是`seedType`。我们将数据集上传到S3，并创建数据源和模型。
- en: 'The metric for multiclass classification is the *F1* score defined as the harmonic
    mean of precision and recall:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 多类分类的指标是定义为精确率和召回率的调和平均值的*F1*分数：
- en: '![](img/B05028_05_13.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05028_05_13.png)'
- en: 'The baseline for a multiclass classification problem is the macro average *F1*
    score for a model that would always predict the most common class. In the case
    of the seed dataset, we obtain a *F1* score of 0.870 for baseline of 0.143:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 多类分类问题的基线是总是预测最常见类别的模型的宏平均*F1*分数。在种子数据集的情况下，我们获得了基线为0.143的*F1*分数为0.870：
- en: '![](img/B05028_05_11.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05028_05_11.png)'
- en: 'Performance exploration is not as developed as in the binary classification
    case. Amazon ML gives us the confusion matrix which shows, for each class, the
    ratio of correctly predicted samples over the real number of samples in that class:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 性能探索不如二分类案例那样发达。Amazon ML提供了混淆矩阵，它显示了每个类别中正确预测样本数与该类别实际样本数的比率：
- en: '![](img/B05028_05_12.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05028_05_12.png)'
- en: Analyzing the logs
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析日志
- en: For every operation it carries out, Amazon ML gives us access to the related
    logs. We can download and analyze the model training logs and infer a few things
    on how Amazon ML trains and selects the best model.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 对于它执行的每个操作，Amazon ML都为我们提供了相关的日志访问权限。我们可以下载并分析模型训练日志，并推断出Amazon ML如何训练和选择最佳模型。
- en: 'Go back to the last Titanic model, and in the summary part, click on the Download
    Log link. The log file is too long to be reproduced here but is available at [https://github.com/alexperrier/packt-aml/blob/master/ch5/titanic_training.log](https://github.com/alexperrier/packt-aml/blob/master/ch5/titanic_training.log):'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 返回到上一个泰坦尼克号模型，在摘要部分点击下载日志链接。日志文件太长无法在此处展示，但可在[https://github.com/alexperrier/packt-aml/blob/master/ch5/titanic_training.log](https://github.com/alexperrier/packt-aml/blob/master/ch5/titanic_training.log)找到：
- en: '![](img/B05028_05_16.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05028_05_16.png)'
- en: 'Amazon ML launches five versions of the SGD algorithm in parallel. Each version
    is called a learner and corresponds to a different value for the learning rate:
    0.01, 0.1,1, 10, and 100\. The following five metrics are calculated at each new
    pass of the algorithm:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon ML并行启动了五个版本的SGD算法。每个版本被称为学习者，对应于不同的学习率值：0.01、0.1、1、10和100。在算法的每次新迭代中，计算以下五个指标：
- en: Accuracy
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率
- en: Recall
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回忆
- en: Precision
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度
- en: F1-score
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F1分数
- en: AUC
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AUC
- en: The `negative-log-likelihood` is also calculated to assess whether the last
    iterations have brought significant improvement in reducing the residual error.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 还计算了`负对数似然`来评估最后几次迭代是否显著降低了残差误差。
- en: Optimizing the learning rate
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化学习率
- en: If you recall from [Chapter 2](8ec21c70-b7f9-4bb2-bbfd-df8337db86a2.xhtml), *Machine
    Learning Definitions and Concepts*, under the section *Regularization on linear
    models*, the **Stochastic Gradient Descent (SGD)** algorithm has a parameter called
    the learning rate.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还记得[第2章](8ec21c70-b7f9-4bb2-bbfd-df8337db86a2.xhtml)中的内容，即*机器学习定义和概念*部分下的*线性模型正则化*，**随机梯度下降（SGD）**算法有一个名为学习率的参数。
- en: The SGD is based on the idea of taking each new (block of) data sample to make
    little corrections to the linear regression model coefficients. At each iteration,
    the input data samples are used either on a sample-by-sample basis or on a block-by-block
    basis to estimate the best correction (the so-called gradient) to make to the
    linear regression coefficients to further reduce the estimation error. It has
    been shown that the SGD algorithm converges to an optimal solution for the linear
    regression weights. These corrections are multiplied by a parameter called the
    `learning rate` , which drives the amount of correction brought to the coefficients
    at each iteration.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: SGD基于这样的想法：每次迭代都使用新的（块）数据样本对线性回归模型的系数进行微调。在每次迭代中，输入数据样本要么逐个使用，要么分块使用，以估计对线性回归系数的最佳修正（所谓的梯度），以进一步减少估计误差。已经证明，SGD算法收敛到线性回归权重的最优解。这些修正乘以一个称为`学习率`的参数，该参数驱动每次迭代对系数进行的修正量。
- en: SGD calculations are low in computation costs. It's a fascinating yet simple
    algorithm that is used in many applications.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: SGD的计算成本较低。这是一个既迷人又简单的算法，被广泛应用于许多应用中。
- en: Imagine a marble in a bowl. Set the marble on the rim of the bowl and let it
    drop into the bowl with a circular movement. It will circle around the bowl while
    falling to the bottom. At the end of its descent, it will tend to circle around
    the bottom of the bowl and finally come to rest at the lowest point of the bowl.
    The SGD behaves similarly when you consider the marble as the prediction error
    at each iteration and the bottom of the bowl as the ultimate and most optimal
    coefficients that could be estimated. At each iteration, the prediction error
    becomes smaller on average. The error will not follow the most direct path to
    the bottom of the bowl like the marble does, nor will it reach the lowest most
    optimal solution, but on average, the predictions get better and the error decreases
    iteration after iteration. After a certain number of iterations, the error will
    approach its potential optimal minimum. How fast and how close it gets to the
    minimum error and the best coefficients depends directly on the value of the learning
    rate.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个在碗中的弹珠。将弹珠放在碗的边缘，然后让它以圆形运动的方式落入碗中。它在下落的过程中会围绕碗旋转。在其下降的末端，它倾向于围绕碗底旋转，并最终在碗的最低点停下来。当你将每个迭代的预测误差视为弹珠，将碗底视为可以估计的最终和最优化系数时，SGD的行为与此类似。在每次迭代中，预测误差的平均值会变小。误差不会像弹珠那样直接沿着碗底的最直接路径下降，也不会达到最低的最优化解，但平均而言，预测会更好，误差在迭代后会逐渐减少。经过一定次数的迭代后，误差将接近其潜在的最优最小值。它达到最小误差和最佳系数的速度有多快，以及它有多接近最小误差，这直接取决于学习率的值。
- en: The learning rate controls how much the weights are corrected at each iteration.
    The learning rate drives the convergence of the algorithm. The larger the learning
    rate, the faster the convergence and potentially, the larger the residual error
    once converged.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率控制每次迭代中权重被校正的程度。学习率驱动算法的收敛。学习率越大，收敛越快，一旦收敛，潜在的残差误差可能也越大。
- en: 'Thus, choosing an optimal learning rate will be a balance between the following:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，选择一个最优的学习率将在以下方面取得平衡：
- en: A faster convergence and poorer estimation
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更快的收敛和较差的估计
- en: A slower convergence and more accurate estimation
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更慢的收敛和更准确的估计
- en: However, if the learning rate is too small, the convergence can be too slow
    and take too long to reach an optimal solution. One standard strategy is to decrease
    the learning rate as the algorithm converges, thus ensuring a fast convergence
    at the beginning, which will slow down as the prediction error becomes slower.
    As the learning rate decreases, the coefficient estimation becomes more accurate.
    Small learning rates mean that the algorithm converges slowly, while higher values
    mean each new sample has a bigger impact on the correcting factor. Amazon ML does
    not use that strategy and keeps the learning rate constant. In Amazon ML, the
    learning rate is set for you. You cannot choose a value.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果学习率太小，收敛可能会太慢，并且需要太长时间才能达到最优解。一个标准的策略是随着算法的收敛而减小学习率，从而确保开始时快速收敛，随着预测误差的减小而减慢。随着学习率的减小，系数估计变得更加准确。小的学习率意味着算法收敛得慢，而高的值意味着每个新的样本对校正因子的影响更大。Amazon
    ML不使用那种策略，并保持学习率恒定。在Amazon ML中，学习率由系统设置。您不能选择一个值。
- en: Visualizing convergence
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化收敛
- en: 'By parsing the logs, we can extract the following convergence plots for our
    Titanic model:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解析日志，我们可以提取出我们泰坦尼克号模型的以下收敛图：
- en: '![](img/B05028_05_17.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B05028_05_17.png)'
- en: 'The previous screenshot of different plots shows four metrics: Accuracy, AUC,
    F1 score, and Precision for the five different values of the learning rate. The
    model was set to 50 passes with mild (10^-6) L2 regularization on the Titanic
    training dataset. We can see that, for all metrics, the best value for the learning
    rate is either 10 or 100, with a slight advantage for learning rate=100\. These
    values converge faster and reach better scores. The smallest learning rate (0.01)
    converges far slower. In our context, faster convergence and large learning rate
    values beat smaller rate values.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 之前不同图的截图显示了四个指标：准确率、AUC、F1分数和精确度，对应于五个不同学习率的值。模型被设置为在泰坦尼克号训练数据集上进行50次遍历，轻微的（10^-6）L2正则化。我们可以看到，对于所有指标，最佳的学习率值要么是10，要么是100，其中学习率=100略胜一筹。这些值收敛得更快，达到更好的分数。最小学习率（0.01）收敛得非常慢。在我们的情况下，更快的收敛和较大的学习率值优于较小的学习率值。
- en: The default number of passes when creating a model is *10*. We can see that
    10 iterations would not have been sufficient for the score to stabilize and converge.
    At the 10th iteration, the curves are barely out of the chaotic initialization
    phase.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 创建模型时的默认迭代次数是*10*。我们可以看到，10次迭代不足以使分数稳定和收敛。在第10次迭代时，曲线几乎还没有走出混沌初始化阶段。
- en: 'Looking at the negative log likelihood graph extracted from the logs, we also
    see that the best learner corresponds to a learning rate of 100 shown here by
    the curve with diamond shapes:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 从日志中提取的负对数似然图显示，最佳学习器对应于这里用带菱形形状的曲线表示的100学习率：
- en: '![](img/B05028_05_18.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05028_05_18.png)'
- en: One conclusion that can be made from these graphs is that you should not limit
    your model to the default 10 passes.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些图表中可以得出一个结论，那就是你不应该将你的模型限制在默认的10次迭代。
- en: These two convergence graphs are entirely dependent on the problem at hand.
    For a different dataset, we would have ended with entirely different graphs in
    terms of convergence rate, learning rate, and score achieved.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个收敛图完全取决于当前的问题。对于不同的数据集，我们可能会得到在收敛速度、学习率和达到的分数方面完全不同的图表。
- en: Impact of regularization
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则化的影响
- en: 'The following graph compares AUC for three different models:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表比较了三个不同模型的AUC：
- en: No regularization
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无正则化
- en: Mild regularization (10^-6)
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轻微正则化（10^-6）
- en: Aggressive regularization (10^-2)
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激进正则化（10^-2）
- en: '![](img/B05028_05_19.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05028_05_19.png)'
- en: We notice that there is no significant difference between having no regularization
    and having mild regularization. Aggressive regularization, however, has a direct
    impact on the model performance. The algorithm converges to a lower AUC, and the
    optimal learning rate is no longer 100 but 1.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，在没有正则化和轻微正则化之间没有显著的差异。然而，激进的正则化对模型性能有直接影响。算法收敛到一个较低的AUC，最佳学习率不再是100，而是1。
- en: 'Comparing the performance graph given by Amazon ML for mild and aggressive
    regularization, we see that although the scores (AUC, accuracy, and so on) are
    very similar in both cases, the difference lies with the certainty of the predictions.
    In the mild regularization case (left graph), the predictions are far apart. The
    probabilities or predictions that a sample is zero or one are very distinct. In
    the aggressive regularization case (right graph), this separation is far less
    obvious. The probabilities for samples to belong to one class versus the other
    are much closer. The decision boundary is less clear:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 比较亚马逊ML给出的轻微和激进正则化的性能图，我们看到尽管两种情况下的分数（AUC、准确率等）非常相似，但差异在于预测的确定性。在轻微正则化情况下（左图），预测值相差很远。样本为零或一的几率或预测非常明显。在激进正则化情况下（右图），这种分离远不那么明显。样本属于一个类别而不是另一个类别的概率要接近得多。决策边界不太清晰：
- en: '| **Mild regularization** | **Aggressive regularization** |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| **轻微正则化** | **激进正则化** |'
- en: '| ![](img/B05028_05_20.png) | ![](img/B05028_05_21.png) |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| ![](img/B05028_05_20.png) | ![](img/B05028_05_21.png) |'
- en: The goal of regularization being to decouple the performance of the model from
    the training data in order to reduce overfitting, it may well be that, on the
    held-out dataset on previously unseen data, heavy regularization would give better
    results and no regularization would perform worse than mild regularization. Less
    optimal performance in the training-validation phase is sometimes more robust
    during the real prediction phase. It’s important to keep in mind that performance
    in the validation phase does not always translate into performance in the prediction
    phase.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化的目标是使模型的性能与训练数据解耦，以减少过拟合。因此，在之前未见过的数据集上，重正则化可能会给出更好的结果，而没有正则化可能比轻微正则化表现更差。在训练-验证阶段不太理想的表现有时在真实预测阶段可能更稳健。重要的是要记住，验证阶段的表现并不总是转化为预测阶段的表现。
- en: Comparing different recipes on the Titanic dataset
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在泰坦尼克号数据集上比较不同的方法
- en: 'In this last section, we would like to compare several recipes and see if our
    SQL, based feature engineering drives a better model performance. In all our experimentation,
    the one thing that stood out with regards to the recipes Amazon ML suggested was
    that all the numeric variables ended up being categorized via quantile binning.
    The large number of bins was also in question. We compare the following scenarios
    on the `Titanic` dataset:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的最后，我们想比较几个配方，看看我们的基于 SQL 的特征工程是否可以驱动更好的模型性能。在我们所有的实验中，与 Amazon ML 建议的配方相关的一个突出特点是所有数值型变量最终都通过分位数分组进行了分类。分箱的数量也值得怀疑。我们在
    `Titanic` 数据集上比较以下场景：
- en: Suggested Amazon ML recipe
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建议的 Amazon ML 脚本
- en: Numeric values are kept as numeric. No quantile binning is involved in the recipe.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值型值保持为数值型。在脚本中不涉及分位数分组。
- en: The extended Titanic datasource we created in [Chapter 4](08d9b49a-a25c-4706-8846-36be9538b087.xhtml), *Loading
    and Preparing the Dataset* is used with the suggested Amazon ML recipe
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在[第 4 章](08d9b49a-a25c-4706-8846-36be9538b087.xhtml)，“加载数据集和准备数据”中创建的扩展泰坦尼克号数据源，与建议的
    Amazon ML 脚本一起使用
- en: We slightly modified the extended Titanic dataset that was used in [Chapter
    4](08d9b49a-a25c-4706-8846-36be9538b087.xhtml), *Loading and Preparing the Dataset:*
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对[第 4 章](08d9b49a-a25c-4706-8846-36be9538b087.xhtml)，“加载数据集和准备数据”中使用的扩展泰坦尼克号数据集进行了轻微修改：
- en: There was no need to have both `fare` and `log_fare`. We removed `fare`.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有必要同时拥有 `fare` 和 `log_fare`。我们移除了 `fare`。
- en: We manually corrected some titles that were not properly extracted from the
    names.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们手动纠正了一些标题，这些标题没有从名称中正确提取出来。
- en: The new extended dataset is available in the GitHub repository for his chapter
    as `ch5_extended_titanic_training.csv`.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的扩展数据集可在 GitHub 仓库的该章节中找到，作为 `ch5_extended_titanic_training.csv`。
- en: In all three cases, we apply L2 mild regularization.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有三种情况下，我们都应用了 L2 轻度正则化。
- en: Keeping variables as numeric or applying quantile binning?
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保持变量为数值型或应用分位数分组？
- en: 'We found that keeping all numeric variables as numeric and avoiding any quantile
    binning had a very direct and negative effect on the model performance. The overall
    score was far lower in the numeric case than in the quantile binning case: `AUC:
    0.81` for all numeric versus  `AUC: 0.88` for QB.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，将所有数值型变量保持为数值型并避免任何分位数分组对模型性能有非常直接且负面的影响。在数值型情况下，整体得分远低于分位数分组情况：所有数值型的
    `AUC` 为 0.81，而 QB 的 `AUC` 为 0.88。
- en: 'Looking at the convergence graph for the *All Numeric* model, it appears that
    the algorithm converged much more slowly than it had for the quantile binning
    model. It obviously had not converged after 50 passes, so we increased the number
    of passes to 100\. We also noticed that in the *All Numeric* case, the best learning
    rate was equal to 0.01, whereas in the quantile binning model, the best learning
    rate was much larger (10 or 100). A smaller learning rate induces a slower convergence
    rate:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 *All Numeric* 模型的收敛图，似乎算法的收敛速度比分位数分组模型慢得多。显然，在 50 次迭代后并未收敛，因此我们将迭代次数增加到 100
    次。我们还注意到，在 *All Numeric* 情况下，最佳学习率等于 0.01，而在分位数分组模型中，最佳学习率要大得多（10 或 100）。较小的学习率会导致收敛速度变慢：
- en: '![](img/B05028_05_22.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B05028_05_22.png)'
- en: 'We also see on the following performance charts that the quantile binning model
    separates the classes much better than the All Numeric model:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在以下性能图表中看到，分位数分组模型比所有数值型模型更好地分离了类别：
- en: '| **Quantile Binning 50 passes** | **All Numeric 100 Passes** |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| **分位数分组 50 次** | **所有数值型 100 次** |'
- en: '| ![](img/B05028_05_23.png) | ![](img/B05028_05_24.png) |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| ![](img/B05028_05_23.png) | ![](img/B05028_05_24.png) |'
- en: 'So quantile binning is definitely preferable to no quantile binning. What about
    our efforts to extend the initial dataset with new features? Well, somehow, our
    extended model did not produce better results than the initial dataset. Extracting
    the `title` from the `name`, replacing missing values for the `age`, and extracting
    the `deck` from the `cabin` did not generate an obviously better model:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，分位数分组肯定比不分位数分组更可取。那么，我们用新特征扩展初始数据集的努力如何呢？好吧，不知何故，我们的扩展模型并没有比初始数据集产生更好的结果。从
    `name` 中提取 `title`，为 `age` 替换缺失值，从 `cabin` 中提取 `deck` 并没有生成一个明显更好的模型：
- en: 'Original Titanic dataset: AUC 0.88'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始泰坦尼克号数据集：AUC 0.88
- en: 'Extended Titanic dataset with feature engineering: AUC 0.82'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展的泰坦尼克号数据集与特征工程：AUC 0.82
- en: Convergence and performance charts were similar for both models and are not
    reproduced here. Several factors can be at play here to explain why our improved
    dataset did not produce a better model, and further analysis would be required
    to understand which feature engineering had a positive impact on the model and
    which one did not. However, we will see in the next chapter that this may also
    have been dependent on the actual samples in the evaluation set. On average, the
    extended dataset generates better performances but for this particular trial,
    the associated model performed roughly the same as the one trained on the original
    dataset. The conclusion being that it is worth the effort to run several trials
    to assess the quality and performance of a model, and not rely on a unique trial
    where the particularities of the evaluation set may influence the comparison between
    models.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 两个模型的收敛和性能图表相似，此处不再重复。可能有几个因素在起作用，可以解释为什么我们的改进数据集没有产生更好的模型，需要进一步分析来了解哪些特征工程对模型有积极影响，哪些没有。然而，我们将在下一章中看到，这也可能取决于评估集中实际的样本。平均而言，扩展的数据集生成更好的性能，但在这个特定的试验中，相关的模型的表现与在原始数据集上训练的模型大致相同。结论是，运行多次试验以评估模型的质量和性能是值得的，而不是依赖于唯一的一次试验，因为评估集的特殊性可能会影响模型之间的比较。
- en: Parsing the model logs
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解析模型日志
- en: 'The convergence plots were obtained by parsing the Amazon ML model logs to
    extract the data into a CSV file that could be used later on to create plots.
    The process is simple and mostly based on command line scripting using the `grep`
    and the `sed` commands. We want to extract and parse the following lines from
    the log file:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 收敛图是通过解析 Amazon ML 模型日志，将数据提取到 CSV 文件中得到的，该文件可以用于后续创建图表。这个过程很简单，主要基于命令行脚本，使用
    `grep` 和 `sed` 命令。我们想要从日志文件中提取和解析以下行：
- en: '[PRE10]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'And convert them into a CSV format as follows:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 并将它们转换为 CSV 格式，如下所示：
- en: '| iteration | alpha | learner | accuracy | recall | precision | f1 | auc |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 迭代 | alpha | 学习者 | 准确率 | 召回率 | 精确率 | F1 | AUC |'
- en: '| 1 | 0.01 | 1050 | 0.5937 | 0.56 | 0.4828 | 0.5185 | 0.6015 |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.01 | 1050 | 0.5937 | 0.56 | 0.4828 | 0.5185 | 0.6015 |'
- en: The first step is to extract the right lines from the log file. We notice that
    they all contain the string `model-performance:`. We use grep to extract all the
    lines containing this string into a temporary file that we name `model_performance.tmp`.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是从日志文件中提取正确的行。我们注意到它们都包含字符串 `model-performance:`。我们使用 `grep` 命令提取包含此字符串的所有行到一个临时文件中，我们将其命名为
    `model_performance.tmp`。
- en: 'Copy-paste the log data from the Amazon ML Model page into a log file (`model.log`)
    and in the terminal run the following:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Amazon ML 模型页面上的日志数据复制粘贴到日志文件（`model.log`）中，然后在终端运行以下命令：
- en: '[PRE11]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The trick then is to replace the right sub-strings by commas using the `sed`
    command. The `sed` command follows this syntax:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用 `sed` 命令将正确的子字符串替换为逗号。`sed` 命令遵循以下语法：
- en: '[PRE12]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `-i.bak` option makes it possible to replace the string within the file
    itself without the need to create a temporary file.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '`-i.bak` 选项使得可以在文件内部替换字符串，而无需创建临时文件。'
- en: 'So, for instance, replacing the string `INFO: learner-id=` by a comma in the
    `model_performance.tmp` file is obtained by running the following line in a terminal:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '例如，将 `model_performance.tmp` 文件中的字符串 `INFO: learner-id=` 替换为逗号，可以通过在终端运行以下行来实现：'
- en: '[PRE13]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'With the following commands, most of the original log file will have been transformed
    into a CSV formatted file, which you can use as a base for visualizing the convergence
    of the Amazon ML model. The rest of the file cleaning can be done in a spreadsheet
    editor:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下命令，大部分原始日志文件已经被转换成 CSV 格式的文件，你可以将其用作可视化 Amazon ML 模型收敛的基础。其余的文件清理可以在电子表格编辑器中完成：
- en: '[PRE14]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'A similar pattern can be used to extract the negative log likelihood data from
    the Amazon ML model logs:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用类似的模式从 Amazon ML 模型日志中提取负对数似然数据：
- en: '[PRE15]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We end up with a CSV file with a row for each iteration and a column for the
    learning rate and each metric.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终得到一个 CSV 文件，其中每一行代表一个迭代，一列是学习率，以及每个指标。
- en: Summary
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we created predictive models in Amazon ML--from selecting
    the datasource, applying transformations to the initial data with recipes, and
    analyzing the performance of the trained model. The model performance exploration
    depends on the type of prediction problem at hand: binary, multi-classification,
    or regression. We also looked at the model logs for the Titanic dataset and learned
    how the SGD algorithm trains and selects the best model out of several different
    ones with different learning rates.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们在Amazon ML中创建了预测模型——从选择数据源，使用配方对初始数据进行转换，到分析训练模型的性能。模型性能的探索取决于手头的预测问题类型：二元分类、多分类或回归。我们还查看了泰坦尼克号数据集的模型日志，了解了SGD算法如何训练并从几个不同学习率的模型中选择最佳模型。
- en: Finally, we compared several data transformation strategies and their impact
    on the model performance and algorithm convergence in the context of the Titanic
    dataset. We found out that quantile binning of numeric values is a key strategy in
    boosting the convergence speed of the algorithm, which overall generated much
    better models.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在泰坦尼克号数据集的背景下比较了几种数据转换策略及其对模型性能和算法收敛性的影响。我们发现，数值的分位数分箱是提高算法收敛速度的关键策略，总体上产生了更好的模型。
- en: So far, these models and performance evaluation are all obtained on training
    data. That is data that is fully available to the model from the start. The raison d'être of
    these models is not to run on subsets of the training data, but to make robust
    predictions on previously unseen data.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，这些模型和性能评估都是在训练数据上获得的。这意味着模型从一开始就完全能够访问这些数据。这些模型的初衷不是在训练数据的子集上运行，而是在之前未见过的数据上做出稳健的预测。
- en: In the next chapter, we will apply these models on the held-out datasets we
    created in [Chapter 4](08d9b49a-a25c-4706-8846-36be9538b087.xhtml), *Loading and
    preparing the dataset,* to make real predictions.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将应用这些模型到我们在[第4章](08d9b49a-a25c-4706-8846-36be9538b087.xhtml)“加载数据集和准备数据”中创建的保留数据集上，以进行实际预测。
