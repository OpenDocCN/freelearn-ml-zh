- en: Predictive Modeling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测建模
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下食谱：
- en: Building a linear classifier using **support vector machines** (**SVMs**)
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**支持向量机**（**SVMs**）构建线性分类器
- en: Building a nonlinear classifier using SVMs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SVM构建非线性分类器
- en: Tackling class imbalance
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决类别不平衡问题
- en: Extracting confidence measurements
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取置信度测量
- en: Finding optimal hyperparameters
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找最优超参数
- en: Building an event predictor
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建事件预测器
- en: Estimating traffic
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 估计交通流量
- en: Simplifying a machine learning workflow using TensorFlow
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorFlow简化机器学习工作流程
- en: Implementing the stacking method
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现堆叠方法
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To address the recipes in this chapter, you need the following files (available
    on GitHub):'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理本章中的食谱，你需要以下文件（可在GitHub上找到）：
- en: '`svm.py`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`svm.py`'
- en: '`data_multivar.txt`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_multivar.txt`'
- en: '`svm_imbalance.py`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`svm_imbalance.py`'
- en: '`data_multivar_imbalance.txt`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_multivar_imbalance.txt`'
- en: '`svm_confidence.py`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`svm_confidence.py`'
- en: '`perform_grid_search.py`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`perform_grid_search.py`'
- en: '`building_event_binary.txt`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`building_event_binary.txt`'
- en: '`building_event_multiclass.txt`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`building_event_multiclass.txt`'
- en: '`` `event.py` ``'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`` `event.py` ``'
- en: '`traffic_data.txt`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`traffic_data.txt`'
- en: '`traffic.py`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`traffic.py`'
- en: '`IrisTensorflow.py`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IrisTensorflow.py`'
- en: '`stacking.py`'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stacking.py`'
- en: Introduction
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: '**Predictive modeling** is probably one of the most exciting fields in data
    analytics. It has gained a lot of attention in recent years due to massive amounts
    of data being available in many different verticals. It is very commonly used
    in areas concerning data mining to forecast future trends.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测建模**可能是数据分析中最激动人心的领域之一。近年来，由于许多不同领域中有大量数据可用，它受到了很多关注。它在数据挖掘领域非常常用，用于预测未来的趋势。'
- en: Predictive modeling is an analysis technique that is used to predict the future
    behavior of a system. It is a collection of algorithms that can identify the relationship
    between independent input variables and the target responses. We create a mathematical
    model, based on observations, and then use this model to estimate what's going
    to happen in the future.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 预测建模是一种分析技术，用于预测系统的未来行为。它是一系列算法，可以识别独立输入变量与目标响应之间的关系。我们根据观察创建一个数学模型，然后使用这个模型来估计未来会发生什么。
- en: In predictive modeling, we need to collect data with known responses to train
    our model. Once we create this model, we validate it using some metrics, and then
    use it to predict future values. We can use many different types of algorithms
    to create a predictive model. In this chapter, we will use SVMs to build linear
    and nonlinear models.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测建模中，我们需要收集已知响应的数据来训练我们的模型。一旦我们创建了该模型，我们将使用一些指标来验证它，然后使用它来预测未来的值。我们可以使用许多不同类型的算法来创建预测模型。在本章中，我们将使用SVM来构建线性和非线性模型。
- en: A predictive model is built using a number of features that are likely to influence
    the behavior of the system. For example, to estimate weather conditions, we may
    use various types of data, such as temperature, barometric pressure, precipitation,
    and other atmospheric processes. Similarly, when we deal with other types of systems,
    we need to decide what factors are likely to influence its behavior and include
    them as part of the feature vector before training our model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 预测模型是通过使用可能影响系统行为的多个特征构建的。例如，为了估计天气条件，我们可能使用各种类型的数据，如温度、气压、降水和其他大气过程。同样，当我们处理其他类型的系统时，我们需要决定哪些因素可能影响其行为，并在训练模型之前将它们作为特征向量的一部分包括在内。
- en: Building a linear classifier using SVMs
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SVM构建线性分类器
- en: SVMs are supervised learning models that we can use to create classifiers and
    regressors. An SVM solves a system of mathematical equations and finds the best
    separating boundary between two sets of points. Let's see how to build a linear
    classifier using an SVM.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: SVMs（支持向量机）是我们可以用来创建分类器和回归器的监督学习模型。SVM通过求解一组数学方程式，找到两个点集之间最佳分离边界。让我们看看如何使用SVM构建线性分类器。
- en: Getting ready
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Let''s visualize our data to understand the problem at hand. We will use the `svm.py`
    file for this. Before we build the SVM, let''s understand our data. We will use
    the `data_multivar.txt` file that''s already provided to you. Let''s see how to
    to visualize the data:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们可视化我们的数据，以理解当前的问题。我们将使用`svm.py`文件来完成这项工作。在我们构建SVM之前，让我们了解我们的数据。我们将使用已经提供给你的`data_multivar.txt`文件。让我们看看如何可视化数据：
- en: 'Create a new Python file and add the following lines to it (the full code is
    in the `svm.py` file which has already been provided to you):'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件，并向其中添加以下行（完整的代码在已经提供给你的`svm.py`文件中）：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We just imported a couple of packages and named the input file. Let''s look
    at the `load_data()` method:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只导入了一些包并命名了输入文件。让我们看看`load_data()`方法：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We need to separate the data into classes, as follows:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要将数据分离成类别，如下所示：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now that we have separated the data, let''s plot it:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经分离了数据，让我们绘制它：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If you run this code, you will see the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将看到以下内容：
- en: '![](img/2eaae6f7-a135-4d73-95d5-8f2391f2b33d.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2eaae6f7-a135-4d73-95d5-8f2391f2b33d.png)'
- en: The preceding consists of two types of points—**solid squares** and **empty
    squares**. In machine learning lingo, we say that our data consists of two classes.
    Our goal is to build a model that can separate the solid squares from the empty
    squares.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 前面包含两种类型的点——**实心方块**和**空心方块**。在机器学习的术语中，我们说我们的数据包含两个类别。我们的目标是构建一个可以将实心方块与空心方块分开的模型。
- en: How to do it...
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'In this recipe, we will learn how to build a linear classifier using SVMs:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将学习如何使用支持向量机（SVMs）构建线性分类器：
- en: 'We need to split our dataset into training and testing datasets. Add the following
    lines to the same Python file:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要将我们的数据集分成训练集和测试集。向同一Python文件中添加以下行：
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let''s initialize the SVM object using a `linear` kernel. Add the following
    lines to the file:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用`linear`核初始化SVM对象。向文件中添加以下行：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We are now ready to train the linear SVM classifier:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备好训练线性SVM分类器：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can now see how the classifier performs:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以看到分类器的表现：
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you run this code, you will get the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将得到以下内容：
- en: '![](img/f84ac53f-cb82-4d3a-8a16-0cf166e316fa.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f84ac53f-cb82-4d3a-8a16-0cf166e316fa.png)'
- en: The `plot_classifier` function is the same as we discussed in [Chapter 1](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml),
    *The Realm of Supervised Learning*. It has a couple of minor additions.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`plot_classifier`函数与我们在[第1章](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml)，“监督学习领域”中讨论的相同。它有一些小的补充。'
- en: You can check out the `utilities.py` file already provided to you for more details.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以查看已经提供给你的`utilities.py`文件以获取更多详细信息。
- en: 'Let''s see how this performs on the test dataset. Add the following lines to
    the `svm.py` file:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看它在测试数据集上的表现。向`svm.py`文件中添加以下行：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you run this code, you will see the following output:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将看到以下输出：
- en: '![](img/eddb9d17-57c0-4936-8873-7a962c1a6bfa.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/eddb9d17-57c0-4936-8873-7a962c1a6bfa.png)'
- en: As you can see, the classifier boundaries on the input data are clearly identified.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，分类器在输入数据上的边界被清楚地识别。
- en: 'Let''s compute the accuracy for the training set. Add the following lines to
    the same file:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们计算训练集的准确率。向同一文件中添加以下行：
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If you run this code, you will see the following on your Terminal:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在你的终端看到以下内容：
- en: '![](img/2acae4ae-b68e-4230-bee1-b7a3ed3c7da8.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2acae4ae-b68e-4230-bee1-b7a3ed3c7da8.png)'
- en: 'Finally, let''s see the classification report for the testing dataset:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们看看测试数据集的分类报告：
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If you run this code, you will see the following on the Terminal:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在终端看到以下内容：
- en: '![](img/cfadb22c-c1e3-4aa0-a941-5f64a3c06a70.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/cfadb22c-c1e3-4aa0-a941-5f64a3c06a70.png)'
- en: From the output screenshot where we visualized the data, we can see that the
    solid squares are completely surrounded by empty squares. This means that the
    data is not linearly separable. We cannot draw a nice straight line to separate
    the two sets of points! Hence, we need a nonlinear classifier to separate these
    datapoints.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们可视化数据的输出截图来看，我们可以看到实心方块被空心方块完全包围。这意味着数据不是线性可分的。我们无法画一条漂亮的直线来分离这两组点！因此，我们需要一个非线性分类器来分离这些数据点。
- en: How it works...
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: SVMs are a set of supervised learning methods that can be used for both classification
    and regression. Given two classes of linearly separable multidimensional patterns,
    among all the possible separating hyperplanes, the SVM algorithm determines the
    one able to separate the classes with the greatest possible margin. The margin
    is the minimum distance of the points in the two classes in the training set from
    the hyperplane identified.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: SVMs是一组监督学习方法，可用于分类和回归。对于两个线性可分的多维模式类别，在所有可能的分离超平面中，SVM算法确定能够以最大可能间隔分离类别的那个超平面。间隔是训练集中两个类别的点与识别的超平面的最小距离。
- en: 'Maximization of the margin is linked to generalization. If the training set
    patterns are classified with a large margin, you can hope that even test-set patterns
    close to the boundary between the classes are managed correctly. In the following,
    you can see three lines (**l1**, **l2**, and **l3**). Line **l1** does not separate
    the two classes, line **l2** separates them, but with a small margin, while line
    **l3** maximizes the distance between the two classes:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 边界的最大化与泛化能力相关。如果训练集的模式以大边界被分类，你可以希望即使测试集的模式接近类别之间的边界也能被正确处理。在下面的内容中，你可以看到三条线（**l1**、**l2**
    和 **l3**）。线 **l1** 无法分离两个类别，线 **l2** 可以分离它们，但边界较小，而线 **l3** 最大化两个类别之间的距离：
- en: '![](img/204252af-0a4c-4aa1-ac10-b13f0d018eb1.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/204252af-0a4c-4aa1-ac10-b13f0d018eb1.png)'
- en: SVMs can be used to separate classes that cannot be separated with a linear
    classifier. Object coordinates are mapped into a space called a **feature space**
    using non-linear functions, called **characteristic functions**. This space is
    highly multidimensional, in which the two classes can be separated with a linear
    classifier. So, the initial space is remapped in the new space, at which point
    the classifier is identified and then returned to the initial space.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: SVMs 可以用来分离那些线性分类器无法分离的类别。对象坐标通过称为**特征函数**的非线性函数映射到一个称为**特征空间**的空间中。这个空间是多维的，在这个空间中，两个类别可以用线性分类器分离。因此，初始空间被重新映射到新空间，此时分类器被识别，然后返回到初始空间。
- en: There's more…
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: '**SVMs** constitute a class of learning machines recently introduced in the
    literature. SVMs derive from concepts concerning the statistical theory of learning
    and present theoretical generalization properties. The theory that governs the
    functioning mechanisms of SVMs was introduced by Vapnik in 1965 (statistical learning
    theory), and was more recently perfected, in 1995, by Vapnik himself, and others.
    SVMs are one of the most widely used tools for pattern classification. Instead
    of estimating the probability densities of classes, Vapnik suggests directly solving
    the problem of interest, that is, to determine the decisional surfaces between
    the classes (classification boundaries).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**SVMs** 是文献中最近引入的一类学习机器。SVMs 来自于关于学习统计理论的观念，并具有理论上的泛化特性。SVMs 的功能机制所遵循的理论是由
    Vapnik 在 1965 年（统计学习理论）提出的，后来在 1995 年由 Vapnik 本人和其他人进一步完善。SVMs 是模式分类中最广泛使用的工具之一。Vapnik
    建议直接解决感兴趣的问题，即确定类别之间的决策表面（分类边界），而不是估计类别的概率密度。'
- en: See also
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Refer to the official documentation of the `sklearn.svm.SVC()` function: [https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考 `sklearn.svm.SVC()` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)
- en: Refer to *Support Vector Machine Tutorial* (from Columbia University): [http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf](http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf)
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考 *支持向量机教程*（哥伦比亚大学）：[http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf](http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf)
- en: Refer to *Support Vector Machines* - Lecture notes (by Andrew Ng from Stanford
    University): [http://cs229.stanford.edu/notes/cs229-notes3.pdf](http://cs229.stanford.edu/notes/cs229-notes3.pdf)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考 *支持向量机* - 讲义（由斯坦福大学的 Andrew Ng 提供）：[http://cs229.stanford.edu/notes/cs229-notes3.pdf](http://cs229.stanford.edu/notes/cs229-notes3.pdf)
- en: '*Tutorial on Support Vector Machine* (from Washington State University): [https://course.ccs.neu.edu/cs5100f11/resources/jakkula.pdf](https://course.ccs.neu.edu/cs5100f11/resources/jakkula.pdf)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*支持向量机教程*（华盛顿州立大学）：[https://course.ccs.neu.edu/cs5100f11/resources/jakkula.pdf](https://course.ccs.neu.edu/cs5100f11/resources/jakkula.pdf)'
- en: '*SVM Tutorial*: [http://web.mit.edu/zoya/www/SVM.pdf](http://web.mit.edu/zoya/www/SVM.pdf)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SVM 教程*：[http://web.mit.edu/zoya/www/SVM.pdf](http://web.mit.edu/zoya/www/SVM.pdf)'
- en: Building a nonlinear classifier using SVMs
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SVMs 构建非线性分类器
- en: An SVM provides a variety of options to build a nonlinear classifier. We need
    to build a nonlinear classifier using various kernels. In this recipe, let's consider
    two cases here. When we want to represent a curvy boundary between two sets of
    points, we can either do this using a polynomial function or a radial basis function.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 提供了多种选项来构建非线性分类器。我们需要使用各种核函数来构建非线性分类器。在这个例子中，让我们考虑两种情况。当我们想要表示两组点之间的曲线边界时，我们可以使用多项式函数或径向基函数来完成。
- en: Getting ready
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use the same file used in the previous recipe, *Building
    a linear classifier using SVMs*, but in this case, we will use a different kernel
    to deal with a markedly nonlinear problem.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用之前菜谱中使用的相同文件，即*使用SVM构建线性分类器*，但在这个情况下，我们将使用不同的核来处理一个明显非线性的问题。
- en: How to do it...
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s see how to build a nonlinear classifier using SVMs:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用SVM构建非线性分类器：
- en: 'For the first case, let''s use a polynomial kernel to build a nonlinear classifier.
    In the same Python file (`svm.py`), search for the following line:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于第一种情况，让我们使用多项式核来构建一个非线性分类器。在相同的Python文件（`svm.py`）中，查找以下行：
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Replace this line with the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 将此行替换为以下内容：
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This means that we use a polynomial function with `degree` as `3`. If we increase
    the degree, this means we allow the polynomial to be curvier. However, curviness
    comes at a cost, in the sense that it will take more time to train because it's
    more computationally expensive.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们使用一个`degree`为`3`的多项式函数。如果我们增加度数，这意味着我们允许多项式曲线更弯曲。然而，曲线的弯曲是有代价的，因为这意味着它将花费更多的时间来训练，因为它更昂贵。
- en: 'If you run this code now, you will get the following:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你现在运行此代码，你将得到以下结果：
- en: '![](img/95a043a1-9e6c-4225-81bb-f7ae523c53bf.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95a043a1-9e6c-4225-81bb-f7ae523c53bf.png)'
- en: 'You will also see the following classification report printed on your Terminal:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你还将在你的终端上看到以下分类报告：
- en: '![](img/753776b5-ad66-441d-9c1f-e34492074839.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/753776b5-ad66-441d-9c1f-e34492074839.png)'
- en: 'We can also use a radial basis function kernel to build a nonlinear classifier.
    In the same Python file, search for the following line:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以使用径向基函数核来构建一个非线性分类器。在相同的Python文件中，查找以下行：
- en: '[PRE13]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Replace this line with the following one:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此行替换为以下一行：
- en: '[PRE14]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If you run this code now, you will get the following:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你现在运行此代码，你将得到以下结果：
- en: '![](img/75773f4a-5e75-462d-b1b6-c41949ef9137.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/75773f4a-5e75-462d-b1b6-c41949ef9137.png)'
- en: 'You will also see the following classification report printed on your Terminal:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你还将在你的终端上看到以下分类报告：
- en: '![](img/fded2682-2b0a-4fff-86dd-6a1691409256.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fded2682-2b0a-4fff-86dd-6a1691409256.png)'
- en: How it works...
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we have used an SVM classifier to find the best separating boundary
    between a dataset of points by solving a system of mathematical equations. To
    address a nonlinear problem, we used Kernel methods. Kernel methods are thus named
    for Kernel functions, which are used to operate in the feature space without calculating
    data coordinates in space, but rather by calculating the internal product between
    images of all copies of data in the function space. The calculation of the internal
    product is often computationally cheaper than the explicit calculation of the
    coordinates. This method is called the **Kernel stratagem**.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用SVM分类器通过解决一组数学方程来找到点数据集的最佳分离边界。为了解决非线性问题，我们使用了核方法。核方法因此得名于核函数，这些函数用于在特征空间中操作，而不是通过计算函数空间中所有数据副本的图像之间的内积来计算数据坐标。内积的计算通常比显式计算坐标更便宜。这种方法被称为**核策略**。
- en: There's more…
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The main point of the SVM is that a generic problem can always be solved as
    long as you carefully choose the kernel and all its parameters—for example, going
    to make a total overfitting of the input dataset. The problem with this method
    is that it scales quite badly with the size of the dataset, as it is classically
    attributed to a D2 factor, even if, in this sense, faster implementations can
    be obtained by optimizing this aspect. The problem is identifying the best kernel
    and providing it with the best parameters.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: SVM的主要观点是，只要仔细选择核及其所有参数，就可以解决任何通用问题——例如，对输入数据集进行完全过拟合。这种方法的问题在于，它与数据集的大小成比例地扩展得相当差，因为它通常归因于D2因子，即使在这种情况下，通过优化这一方面可以获得更快的实现。问题在于确定最佳的核并提供最佳的参数。
- en: See also
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Support Vector Machines and Kernel Methods* (from Carnegie Mellon''s School
    of Computer Science): [https://www.cs.cmu.edu/~ggordon/SVMs/new-svms-and-kernels.pdf](https://www.cs.cmu.edu/~ggordon/SVMs/new-svms-and-kernels.pdf)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*支持向量机和核方法*（来自卡内基梅隆大学计算机科学学院）: [https://www.cs.cmu.edu/~ggordon/SVMs/new-svms-and-kernels.pdf](https://www.cs.cmu.edu/~ggordon/SVMs/new-svms-and-kernels.pdf)'
- en: '*Support Vector Machines and Kernel Methods* (from the Department of Computer
    Science, National Taiwan University): [https://www.csie.ntu.edu.tw/~cjlin/talks/postech.pdf](https://www.csie.ntu.edu.tw/~cjlin/talks/postech.pdf)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*支持向量机和核方法*（来自台湾大学计算机科学系）：[https://www.csie.ntu.edu.tw/~cjlin/talks/postech.pdf](https://www.csie.ntu.edu.tw/~cjlin/talks/postech.pdf)'
- en: Tackling class imbalance
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决类别不平衡问题
- en: Until now, we dealt with problems where we had a similar number of datapoints
    in all our classes. In the real world, we might not be able to get data in such
    an orderly fashion. Sometimes, the number of datapoints in one class is a lot
    more than the number of datapoints in other classes. If this happens, then the
    classifier tends to get biased. The boundary won't reflect the true nature of
    your data, just because there is a big difference in the number of datapoints
    between the two classes. Therefore, it is important to account for this discrepancy
    and neutralize it so that our classifier remains impartial.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们处理了所有类别中数据点数量相似的问题。在现实世界中，我们可能无法以如此有序的方式获取数据。有时，一个类别的数据点数量可能比其他类别的数据点数量多得多。如果发生这种情况，那么分类器往往会偏向。边界不会反映你数据的真实性质，只是因为两个类别之间数据点的数量存在很大差异。因此，考虑这种差异并中和它是很重要的，这样我们的分类器才能保持公正。
- en: Getting ready
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use a new dataset, named `data_multivar_imbalance.txt`, in
    which there are three values for each line; the first two represent the coordinates
    of the point, the third, the class to which the point belongs. Our aim is, once
    again, to build a classifier, but this time, we will have to face a data-balancing
    problem.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将使用一个新的数据集，名为`data_multivar_imbalance.txt`，其中每行有三个值；前两个代表点的坐标，第三个是该点所属的类别。我们的目标是，再次，构建一个分类器，但这次，我们必须面对数据平衡问题。
- en: How to do it...
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s see how to tackle class imbalance:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何解决类别不平衡问题：
- en: 'Let''s import the libraries:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入库：
- en: '[PRE15]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s load the data (`data_multivar_imbalance.txt`):'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载数据（`data_multivar_imbalance.txt`）：
- en: '[PRE16]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Let''s visualize the data. The code for visualization is exactly the same as
    it was in the previous recipe. You can also find it in the file named `svm_imbalance.py`,
    already provided to you:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们可视化数据。可视化代码与之前的食谱中完全相同。你还可以在名为`svm_imbalance.py`的文件中找到它，该文件已经提供给你：
- en: '[PRE17]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'If you run it, you will see the following:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行它，你会看到以下：
- en: '![](img/d0f0f3ab-87e7-4ebc-9320-b88eb858b978.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d0f0f3ab-87e7-4ebc-9320-b88eb858b978.png)'
- en: 'Let''s build an SVM with a linear kernel. The code is the same as it was in
    the previous recipe, *Building a nonlinear classifier using SVM**s*:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用线性核构建一个SVM。代码与之前的食谱中相同，*使用SVM构建非线性分类器*：
- en: '[PRE18]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s print a classification report:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们打印一个分类报告：
- en: '[PRE19]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'If you run it, you will see the following:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行它，你会看到以下：
- en: '![](img/a24acb1e-3b1a-4706-8c62-81a0e68375eb.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a24acb1e-3b1a-4706-8c62-81a0e68375eb.png)'
- en: 'You might wonder why there''s no boundary here! Well, this is because the classifier
    is unable to separate the two classes at all, resulting in 0% accuracy for `Class-0`.
    You will also see a classification report printed on your Terminal, as shown in
    the following screenshot:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可能会 wonder 为什么这里没有边界！Well, 这是因为分类器无法将两个类别分开，导致`Class-0`的准确率为0%。你还会在终端上看到打印出的分类报告，如下截图所示：
- en: '![](img/35bb2949-b30d-4e69-86b4-b332bcfc08d7.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/35bb2949-b30d-4e69-86b4-b332bcfc08d7.png)'
- en: 'As we expected, `Class-0` has 0% precision, so let''s go ahead and fix this!
    In the Python file, search for the following line:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如我们所预期，`Class-0`的精确率为0%，所以让我们继续解决这个问题！在Python文件中，搜索以下行：
- en: '[PRE20]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Replace the preceding line with the following:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将前面的行替换为以下内容：
- en: '[PRE21]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `class_weight` parameter will count the number of datapoints in each class
    to adjust the weights so that the imbalance doesn't adversely affect the performance.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`class_weight`参数将计算每个类别的数据点数量，以调整权重，使不平衡不会对性能产生不利影响。'
- en: 'You will get the following output once you run this code:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码后，你会得到以下输出：
- en: '![](img/24b86379-bcaf-4034-8595-1f224f6505a2.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/24b86379-bcaf-4034-8595-1f224f6505a2.png)'
- en: 'Let''s look at the classification report:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们查看分类报告：
- en: '![](img/2ef0355b-2065-4e8d-a8dd-c1445d6395ae.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2ef0355b-2065-4e8d-a8dd-c1445d6395ae.png)'
- en: As we can see, `Class-0` is now detected with nonzero percentage accuracy.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如我们所见，`Class-0`现在以非零百分比准确率被检测到。
- en: How it works...
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In this recipe, we have used a SVM classifier to find the best separating boundary
    between a dataset of points. To address a data-balancing problem, we once again
    used the linear Kernel method, but we implemented a `class_weight` keyword in
    the `fit` method. The `class_weight` variable is a dictionary in the form `{class_label:
    value}`, where `value` is a floating-point number greater than 0 that modifies
    the *C* parameter of the class `(class_label)`, setting it with a new value, obtained
    by multiplying the old *C* value with that specified in the value attribute (*C
    * value*).'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '在这个配方中，我们使用 SVM 分类器来找到点数据集之间的最佳分离边界。为了解决数据平衡问题，我们再次使用了线性核方法，但在 `fit` 方法中实现了一个
    `class_weight` 关键字。`class_weight` 变量是一个形式为 `{class_label: value}` 的字典，其中 `value`
    是一个大于 0 的浮点数，它修改了类 `(class_label)` 的 *C* 参数，将其设置为通过将旧的 *C* 值与值属性中指定的值相乘得到的新值 (*C
    * value*)。'
- en: There's more…
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: '*C* is a hyperparameter that determines the penalty for the incorrect classification
    of an observation. So, we used a weight for the classes to manage unbalanced classes. In
    this way, we will assign a new value of *C* to the classes, defined as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*C* 是一个超参数，它决定了观察到的错误分类的惩罚。因此，我们使用权重来管理不平衡的类别。这样，我们将为类别分配一个新的 *C* 值，定义如下：'
- en: '![](img/0290b38f-9856-45fd-bee8-b57fb1163007.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0290b38f-9856-45fd-bee8-b57fb1163007.png)'
- en: Where *C* is the penalty, *w[i]* is a weight inversely proportional to class
    i's frequency, and *C[i]* is the *C* value for class *i*. This method suggests
    increasing the penalty to classify the less represented classes so as to prevent
    them from being outclassed by the most represented class.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *C* 是惩罚，*w[i]* 是与类别 i 的频率成反比的权重，*C[i]* 是类别 *i* 的 *C* 值。这种方法建议增加对代表性较小的类别的惩罚，以防止它们被代表性最大的类别超越。
- en: In the `scikit-learn` library, when using SVC, we can set the values for *C[i]*
    automatically by setting `class_weight='balanced'`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `scikit-learn` 库中，当使用 SVC 时，我们可以通过设置 `class_weight='balanced'` 来自动设置 *C[i]*
    的值。
- en: See also
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Support Vector Machines*—official documentation of the `scikit-learn` library: [https://scikit-learn.org/stable/modules/svm.html](https://scikit-learn.org/stable/modules/svm.html)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*支持向量机*—`scikit-learn` 库的官方文档：[https://scikit-learn.org/stable/modules/svm.html](https://scikit-learn.org/stable/modules/svm.html)'
- en: Extracting confidence measurements
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取置信度测量
- en: It would be nice to know the confidence with which we classify unknown data.
    When a new datapoint is classified into a known category, we can train the SVM
    to compute the confidence level of that output as well. A *confidence level* refers
    to the probability that the value of a parameter falls within a specified range
    of values.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 很好知道我们以多大的置信度对未知数据进行分类。当一个新数据点被分类到已知类别时，我们可以训练 SVM 来计算该输出的置信水平。*置信水平*指的是参数值落在指定值范围内的概率。
- en: Getting ready
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use an SVM classifier to find the best separating boundary
    between a dataset of points. In addition, we will also perform a measure of the
    confidence level of the results obtained.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用 SVM 分类器来找到点数据集之间的最佳分离边界。此外，我们还将对获得的结果的置信水平进行测量。
- en: How to do it...
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s see how to extract confidence measurements:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何提取置信度测量：
- en: 'The full code is given in the `svm_confidence.py` file, already provided to
    you. We will discuss the code of the recipe here. Let''s define some input data:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完整的代码在 `svm_confidence.py` 文件中给出，已经提供给你。我们将在下面讨论这个配方的代码。让我们定义一些输入数据：
- en: '[PRE22]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'At this point, we split the data for training and testing, and then we will
    build the classifier:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一点上，我们将数据分为训练集和测试集，然后我们将构建分类器：
- en: '[PRE23]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Define the input datapoint:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义输入数据点：
- en: '[PRE24]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let''s measure the distance from the boundary:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们测量边界距离：
- en: '[PRE25]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You will see the following printed on your Terminal:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将在你的终端上看到以下内容：
- en: '![](img/d4f5f260-388d-4a8a-bd54-361368f0bb5d.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d4f5f260-388d-4a8a-bd54-361368f0bb5d.png)'
- en: 'The distance from the boundary gives us some information about the datapoint,
    but it doesn''t exactly tell us how confident the classifier is about the output
    tag. To do this, we need **Platt scaling**. This is a method that converts the
    distance measure into a probability measure between classes. Let''s go ahead and
    train an SVM using Platt scaling:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 边界距离给我们关于数据点的某些信息，但它并没有确切地告诉我们分类器对输出标签的置信度如何。为了做到这一点，我们需要 **Platt 缩放**。这是一种将距离度量转换为类别之间概率度量的方法。让我们继续使用
    Platt 缩放训练一个 SVM：
- en: '[PRE26]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `probability` parameter tells the SVM that it should train to compute the
    probabilities as well.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`probability` 参数告诉 SVM 它应该训练以计算概率。'
- en: 'Let''s train the classifier:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们训练分类器：
- en: '[PRE27]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let''s compute the confidence measurements for these input datapoints:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们计算这些输入数据点的置信度测量值：
- en: '[PRE28]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `predict_proba` function measures the confidence value.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict_proba` 函数测量置信值。'
- en: 'You will see the following on your Terminal:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将在你的终端上看到以下内容：
- en: '![](img/6568daab-8c90-42f1-9377-1ee2b73da4e1.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6568daab-8c90-42f1-9377-1ee2b73da4e1.png)'
- en: 'Let''s see where the points are with respect to the boundary:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看点相对于边界的位置：
- en: '[PRE29]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'If you run this, you will get the following:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行这个，你将得到以下结果：
- en: '![](img/9a4adf88-34c4-431f-ae20-d0e2f4b79423.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9a4adf88-34c4-431f-ae20-d0e2f4b79423.png)'
- en: How it works...
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, we built a classifier based on SVM. Once the classifier was
    obtained, we used a set of points to measure the distance of those points from
    the boundary and then measured the confidence levels for each of those points.
    When estimating a parameter, the simple identification of a single value is often
    not sufficient. It is therefore advisable to accompany the estimate of a parameter
    with a plausible range of values ​​for that parameter, which is defined as the
    confidence interval. It is therefore associated with a cumulative probability
    value that indirectly, in terms of probability, characterizes its amplitude with
    respect to the maximum values ​​assumed by the random variable that measures the
    probability that the random event described by that variable in question falls
    into this interval and is equal to this area graphically, subtended by the probability
    distribution curve of the random variable in that specific interval.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们基于 SVM 构建了一个分类器。一旦获得分类器，我们使用一组点来衡量这些点与边界的距离，然后为这些点中的每一个测量置信水平。在估计参数时，简单地识别一个值通常是不够的。因此，建议在估计参数的同时，给出该参数的合理值范围，这被定义为置信区间。因此，它与一个累积概率值相关联，间接地，从概率的角度来看，它描述了相对于随机变量最大值的幅度，该随机变量衡量的是随机事件落在该区间内的概率，并且等于该区间图形上由随机变量的概率分布曲线所围成的面积。
- en: There's more…
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: The confidence interval measures the reliability of a statistic, such as an
    opinion poll. For example, if 40% of the sample interviewed declare to choose
    a certain product, it can be inferred with a level of confidence of 99% that a
    percentage between 30 and 50 of the total consumer population will be expressed
    in favor of that product. From the same sample interviewed, with a 90% confidence
    interval, it can be assumed that the percentage of opinions favorable to that
    product is now between 37% and 43%.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间衡量一个统计量（如民意调查）的可靠性。例如，如果40%的受访样本表示选择某个产品，那么可以以99%的置信水平推断，总消费者人口中有30%到50%的比例将表示支持该产品。从同一受访样本中，以90%的置信区间，可以假设该产品受到好评的比例现在在37%到43%之间。
- en: See also
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Refer to the official documentation of the `sklearn.svm.SVC.decision_` function: [https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.decision_function](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.decision_function)
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参考 `sklearn.svm.SVC.decision_` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.decision_function](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.decision_function)
- en: Refer to *Probabilistic Outputs for Support Vector Machines and Comparisons
    to Regularized Likelihood Methods*: [https://www.researchgate.net/publication/2594015_Probabilistic_Outputs_for_Support_Vector_Machines_and_Comparisons_to_Regularized_Likelihood_Methods](https://www.researchgate.net/publication/2594015_Probabilistic_Outputs_for_Support_Vector_Machines_and_Comparisons_to_Regularized_Likelihood_Methods)
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考以下内容：*支持向量机概率输出及其与正则化似然方法的比较*：[https://www.researchgate.net/publication/2594015_Probabilistic_Outputs_for_Support_Vector_Machines_and_Comparisons_to_Regularized_Likelihood_Methods](https://www.researchgate.net/publication/2594015_Probabilistic_Outputs_for_Support_Vector_Machines_and_Comparisons_to_Regularized_Likelihood_Methods)
- en: Finding optimal hyperparameters
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找最优超参数
- en: As discussed in the previous chapter, hyperparameters are important for determining
    the performance of a classifier. Let's see how to extract optimal hyperparameters
    for SVMs.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，超参数对于确定分类器的性能很重要。让我们看看如何提取 SVM 的最优超参数。
- en: Getting ready
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In machine learning algorithms, various parameters are obtained during the learning
    process. In contrast, hyperparameters are set before the learning process begins.
    Given these hyperparameters, the training algorithm learns the parameters from
    the data. In this recipe, we will extract hyperparameters for a model based on
    an SVM algorithm using the grid search method.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习算法中，学习过程中会获得各种参数。相比之下，超参数是在学习过程开始之前设置的。给定这些超参数，训练算法从数据中学习参数。在这个菜谱中，我们将使用网格搜索方法从基于SVM算法的模型中提取超参数。
- en: How to do it...
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s see how to find optimal hyperparameters:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何找到最佳超参数：
- en: 'The full code is given in the `perform_grid_search.py` file that''s already
    provided to you. We start importing the libraries:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完整的代码在`perform_grid_search.py`文件中给出，该文件已经提供给你。我们开始导入库：
- en: '[PRE30]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, we load the data:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们加载数据：
- en: '[PRE31]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We split the data into a train and test dataset:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将数据分为训练集和测试集：
- en: '[PRE32]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now, we will use cross-validation here, which we covered in the previous recipes.
    Once you load the data and split it into training and testing datasets, add the
    following to the file:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将在这里使用交叉验证，这是我们之前菜谱中提到的。一旦你加载数据并将其分为训练集和测试集，请将以下内容添加到文件中：
- en: '[PRE33]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let''s define the metrics that we want to use:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义我们想要使用的度量标准：
- en: '[PRE34]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Let''s start the search for optimal hyperparameters for each of the metrics:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们开始搜索每个度量指标的最佳超参数：
- en: '[PRE35]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let''s look at the scores:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看分数：
- en: '[PRE36]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let''s print the best parameter set:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们打印最佳参数集：
- en: '[PRE37]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'If you run this code, you will see the following on your Terminal:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在你的终端看到以下内容：
- en: '[PRE38]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'As we can see in the preceding output, it searches for all the optimal hyperparameters.
    In this case, the hyperparameters are the type of `kernel,` the `C` value, and
    `gamma`. It will try out various combinations of these parameters to find the
    best parameters. Let''s test it out on the testing dataset:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述的输出所示，它搜索所有最佳超参数。在这种情况下，超参数是`kernel`的类型、`C`值和`gamma`。它将尝试这些参数的各种组合以找到最佳参数。让我们在测试数据集上测试它：
- en: '[PRE39]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'If you run this code, you will see the following on your Terminal:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在你的终端看到以下内容：
- en: '![](img/b4a7a2e2-2389-453e-8e2f-402da58c1b62.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b4a7a2e2-2389-453e-8e2f-402da58c1b62.png)'
- en: 'We have previously said that there are different techniques for optimizing
    hyperparameters. We''ll apply the `RandomizedSearchCV` method. To do this, just
    use the same data and change the classifier. To the code just seen, we add a further
    section:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们之前提到过，优化超参数有不同的技术。我们将应用`RandomizedSearchCV`方法。为此，只需使用相同的数据并更改分类器。在刚刚看到的代码中，我们添加了一个额外的部分：
- en: '[PRE40]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'If you run this code, you will see the following on your Terminal:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在你的终端看到以下内容：
- en: '[PRE41]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Let''s test it out on the testing dataset:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在测试数据集上测试它：
- en: '[PRE42]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The following results are returned:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '![](img/2f2ff1b0-4f29-447e-9c83-094d99c10f74.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2f2ff1b0-4f29-447e-9c83-094d99c10f74.png)'
- en: How it works...
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the previous recipe, *Building a nonlinear classifier using SVMs*, we repeatedly
    modified the kernel of the SVM algorithm to obtain an improvement in the classification
    of data. On the basis of the hyperparameter definition given at the beginning
    of the recipe, it is clear that the kernel represents a hyperparameter. In this
    recipe, we randomly set the value for this hyperparameter and checked the results
    to find out which value determines the best performance. However, a random selection
    of algorithm parameters may be inadequate.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的菜谱“使用SVM构建非线性分类器”中，我们反复修改SVM算法的核以获得数据分类的改进。基于菜谱开头给出的超参数定义，很明显，核代表一个超参数。在这个菜谱中，我们随机设置这个超参数的值并检查结果以找出哪个值决定了最佳性能。然而，随机选择算法参数可能是不够的。
- en: Furthermore, it is difficult to compare the performance of different algorithms
    by setting the parameters randomly, because an algorithm can perform better than
    another with a different set of parameters. And if the parameters are changed,
    the algorithm may have worse results than the other algorithms.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过随机设置参数来比较不同算法的性能是困难的，因为一个算法可能比另一个算法使用不同的参数集表现更好。而且如果参数改变，算法可能比其他算法有更差的结果。
- en: 'As a result, the random selection of parameter values ​​is not the best approach
    we can take to find the best performance for our model. On the contrary, it would
    be advisable to develop an algorithm that automatically finds the best parameters
    for a particular model. There are several methods for searching for hyperparameters,
    such as the following: grid search, randomized search, and Bayesian optimization.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，随机选择参数值不是我们找到模型最佳性能的最佳方法。相反，建议开发一个算法，该算法可以自动找到特定模型的最佳参数。寻找超参数的方法有几种，如下所示：网格搜索、随机搜索和贝叶斯优化。
- en: The grid search algorithm
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网格搜索算法
- en: The **grid search** algorithm does this by automatically looking for the set
    of hyperparameters that detracts from the best performance of the model.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '**网格搜索**算法通过自动寻找降低模型最佳性能的超参数集来实现这一点。'
- en: The `sklearn.model_selection.GridSearchCV()` function performs an exhaustive
    search over specified parameter values for an estimator. **Exhaustive search**
    (also named direct search, or brute force) is a comprehensive examination of all
    possibilities, and therefore represents an efficient solution method in which
    every possibility is tested to determine whether it is the solution.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.model_selection.GridSearchCV()`函数对估计器的指定参数值进行穷举搜索。**穷举搜索**（也称为直接搜索或暴力搜索）是对所有可能性的全面检查，因此代表了一种高效的方法，其中每个可能性都被测试以确定它是否是解决方案。'
- en: The randomized search algorithm
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机搜索算法
- en: Unlike the `GridSearchCV` method, not all parameter values are tested in this
    method, but the parameter settings are sampled in a fixed number. The parameter
    settings that are tested are set through the `n_iter` attribute. Sampling without
    replacement is performed if the parameters are presented as a list. If at least
    one parameter is supplied as a distribution, substitution sampling is used.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 与`GridSearchCV`方法不同，这种方法并不是测试所有参数值，而是以固定数量对参数设置进行采样。要测试的参数设置是通过`n_iter`属性设置的。如果参数以列表形式呈现，则执行无放回采样。如果至少提供一个参数作为分布，则使用替换采样。
- en: The Bayesian optimization algorithm
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯优化算法
- en: The aim of a Bayesian hyperparameter optimizer is to construct a probability
    model of the objective function and use it to select the hyperparameters that
    work best for use in the real objective function. Bayesian statistics allow us
    to foresee not only a value, but a distribution, and this is the success of this
    methodology.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯超参数优化器的目标是构建目标函数的概率模型，并使用它来选择最适合用于真实目标函数的超参数。贝叶斯统计学不仅允许我们预见一个值，还可以预见一个分布，这是这种方法成功的关键。
- en: The Bayesian method, when compared with the two methods already dealt with (grid
    search and random search), stores the results of the past evaluation, which it
    uses to form a probabilistic model that associates the hyperparameters with a
    probability of a score on the objective function.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 与已处理的两种方法（网格搜索和随机搜索）相比，贝叶斯方法存储过去评估的结果，并使用这些结果形成一个概率模型，将超参数与目标函数得分的概率相关联。
- en: 'This model is called a **surrogate** of the objective function and is much
    easier to optimize than the objective function itself. This result is obtained
    by following this procedure:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型被称为目标函数的**代理**，比目标函数本身更容易优化。通过以下程序获得此结果：
- en: A surrogate probability model of the objective function is constructed.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建目标函数的代理概率模型。
- en: The hyperparameters that give the best results on the surrogate are searched.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在代理上给出最佳结果的超参数被搜索。
- en: These hyperparameters are applied to the real objective function.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些超参数应用于真实的目标函数。
- en: The surrogate model is updated by incorporating the new results.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过结合新的结果来更新代理模型。
- en: Repeat steps 2–4 until you reach the pre-established iterations or the maximum
    time.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤2-4，直到达到预定的迭代次数或最大时间。
- en: In this way, the surrogate probability model is updated after each evaluation
    of the objective function. To use a Bayesian hyperparameter optimizer, several
    libraries are available: `scikit-optimize`, `spearmint`, and `SMAC3`.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式，在评估目标函数之后，代理概率模型被更新。要使用贝叶斯超参数优化器，有几种库可用：`scikit-optimize`、`spearmint`和`SMAC3`。
- en: There's more…
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多...
- en: Commonly, hyperparameters are all those values that can be freely set by the
    user, and that are generally optimized, maximizing the accuracy on the validation
    data with appropriate research. Even the choice of a technique rather than another
    can be seen as a categorical hyperparameter, which has as many values as the methods
    we can choose from.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，超参数是指那些用户可以自由设置的值，并且通常通过适当的研究进行优化，以在验证数据上最大化准确性。甚至选择一种技术而不是另一种技术也可以被视为一个分类超参数，其值与我们可选择的方法的数量一样多。
- en: See also
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The official documentation of the `sklearn.model_selection.GridSearchCV()` function:[ https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.model_selection.GridSearchCV()` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)'
- en: '*Hyperparameter optimization* (from Wikipedia): [https://en.wikipedia.org/wiki/Hyperparameter_optimization ](https://en.wikipedia.org/wiki/Hyperparameter_optimization)'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*超参数优化*（来自维基百科）：[https://zh.wikipedia.org/wiki/超参数优化](https://zh.wikipedia.org/wiki/超参数优化)'
- en: '*Spearmint Bayesian optimization* (from GitHub): [https://github.com/HIPS/Spearmint](https://github.com/HIPS/Spearmint)'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Spearmint 贝叶斯优化*（来自 GitHub）：[https://github.com/HIPS/Spearmint](https://github.com/HIPS/Spearmint)'
- en: 'The SMAC3 official documentation: [https://automl.github.io/SMAC3/stable/](https://automl.github.io/SMAC3/stable/)'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SMAC3 官方文档：[https://automl.github.io/SMAC3/stable/](https://automl.github.io/SMAC3/stable/)
- en: '*A Tutorial on Bayesian Optimization for Machine Learning* (from the School
    of Engineering and Applied Sciences, Harvard University): [https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf](https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf)'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习贝叶斯优化的教程*（来自哈佛大学工程与应用科学学院）：[https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf](https://www.iro.umontreal.ca/~bengioy/cifar/NCAP2014-summerschool/slides/Ryan_adams_140814_bayesopt_ncap.pdf)'
- en: Building an event predictor
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建事件预测器
- en: Let's apply all of this knowledge from this chapter to a real-world problem.
    We will build an SVM to predict the number of people going in and out of a building.
    The dataset is available at [https://archive.ics.uci.edu/ml/datasets/CalIt2+Building+People+Counts](https://archive.ics.uci.edu/ml/datasets/CalIt2+Building+People+Counts).
    We will use a slightly modified version of this dataset so that it's easier to
    analyze. The modified data is available in the `building_event_binary.txt` and
    the `building_event_multiclass.txt` files that are already provided to you. In
    this recipe, we will learn how to build an event predictor.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将本章中的所有这些知识应用到现实世界的问题中。我们将构建一个 SVM 来预测进出建筑的人数。数据集可在 [https://archive.ics.uci.edu/ml/datasets/CalIt2+Building+People+Counts](https://archive.ics.uci.edu/ml/datasets/CalIt2+Building+People+Counts)
    找到。我们将使用这个数据集的一个略微修改版本，以便更容易分析。修改后的数据可在提供的 `building_event_binary.txt` 和 `building_event_multiclass.txt`
    文件中找到。在这个菜谱中，我们将学习如何构建事件预测器。
- en: Getting ready
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备中
- en: 'Let''s understand the data format before we start building the model. Each
    line in `building_event_binary.txt` consists of six comma-separated strings. The
    ordering of these six strings is as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始构建模型之前，让我们先了解数据格式。`building_event_binary.txt` 中的每一行都由六个以逗号分隔的字符串组成。这六个字符串的顺序如下：
- en: Day
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天
- en: Date
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期
- en: Time
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间
- en: The number of people going out of the building
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 离开建筑的人数
- en: The number of people coming into the building
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进入建筑的人数
- en: '**The output indicating whether or not it''s an event**'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指示是否为事件的输出**'
- en: The first five strings form the input data, and our task is to predict whether
    or not an event is going on in the building.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 前五个字符串构成输入数据，我们的任务是预测建筑中是否正在发生事件。
- en: 'Each line in `building_event_multiclass.txt` consists of six comma-separated
    strings. This is more granular than the previous file, in the sense that the output
    is the exact type of event going on in the building. The ordering of these six
    strings is as follows:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '`building_event_multiclass.txt` 中的每一行也由六个以逗号分隔的字符串组成。这个文件比之前的文件更细粒度，因为输出是建筑中正在发生的确切事件类型。这六个字符串的顺序如下：'
- en: Day
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天
- en: Date
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期
- en: Time
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间
- en: The number of people going out of the building
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 离开建筑的人数
- en: The number of people coming into the building
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进入建筑的人数
- en: '**The output indicating the type of event**'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指示事件类型的输出**'
- en: The first five strings form the input data, and our task is to predict what
    type of event is going on in the building.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 前五个字符串形成输入数据，我们的任务是预测建筑物中正在进行的事件类型。
- en: How to do it...
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how to build an event predictor:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建一个事件预测器：
- en: 'We will use `event.py` that''s already provided to you for reference. Create
    a new Python file, and add the following lines:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用已经提供给你的`event.py`作为参考。创建一个新的Python文件，并添加以下行：
- en: '[PRE43]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We just loaded all the data into `X`.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只是将所有数据加载到了`X`中。
- en: 'Let''s convert the data into numerical form:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将数据转换为数值形式：
- en: '[PRE44]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Let''s train the SVM using the radial basis function, Platt scaling, and class
    balancing:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用径向基函数、Platt缩放和类别平衡来训练SVM：
- en: '[PRE45]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We are now ready to perform cross-validation:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备好进行交叉验证：
- en: '[PRE46]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Let''s test our SVM on a new datapoint:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在新的数据点上测试我们的SVM：
- en: '[PRE47]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'If you run this code, you will see the following output on your Terminal:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在你的终端上看到以下输出：
- en: '[PRE48]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'If you use the `building_event_multiclass.txt` file as the input data file
    instead of `building_event_binary.txt`, you will see the following output on your
    Terminal:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你使用`building_event_multiclass.txt`文件作为输入数据文件而不是`building_event_binary.txt`，你将在你的终端上看到以下输出：
- en: '[PRE49]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: How it works...
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we used data obtained from observations of people who flowed
    in and out of a building during 15 weeks, and at 48 time intervals per day. We
    therefore built a classifier able to predict the presence of an event such as
    a conference in the building, which determines an increase in the number of people
    present in the building for that period of time.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用了在15周内，每天48个时间间隔观察到的进入和离开建筑物的人的数据。因此，我们构建了一个能够预测建筑物中如会议等事件存在的分类器，这决定了在那个时间段内建筑物内人数的增加。
- en: There's more…
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: Later in the recipe, we used the same classifier on a different database to
    also predict the type of event that is held within the building.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在菜谱的后面，我们在不同的数据库上使用了相同的分类器来预测在建筑物内举行的活动类型。
- en: See also
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关内容
- en: The official documentation of the `sklearn.svm.SVC()` function: [https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.svm.SVC()` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)'
- en: 'The official documentation of the `sklearn.model_selection.cross_validate()`
    function: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate)'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.model_selection.cross_validate()` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate)'
- en: Estimating traffic
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 估算交通流量
- en: An interesting application of SVMs is to predict traffic, based on related data.
    In the previous recipe, we used an SVM as a classifier. In this recipe, we will
    use an SVM as a regressor to estimate the traffic.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: SVMs的一个有趣的应用是预测交通流量，基于相关数据。在之前的菜谱中，我们使用SVM作为分类器。在这个菜谱中，我们将使用SVM作为回归器来估算交通流量。
- en: Getting ready
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We will use the dataset available at [https://archive.ics.uci.edu/ml/datasets/Dodgers+Loop+Sensor](https://archive.ics.uci.edu/ml/datasets/Dodgers+Loop+Sensor).
    This is a dataset that counts the number of cars passing by during baseball games
    at the Los Angeles Dodgers home stadium. We will use a slightly modified form
    of that dataset so that it''s easier to analyze. You can use the `traffic_data.txt`
    file, already provided to you. Each line in this file contains comma-separated
    strings formatted in the following manner:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用在[https://archive.ics.uci.edu/ml/datasets/Dodgers+Loop+Sensor](https://archive.ics.uci.edu/ml/datasets/Dodgers+Loop+Sensor)可用的数据集。这是一个在洛杉矶道奇主场棒球比赛中统计经过的车辆数量的数据集。我们将使用该数据集的略微修改版，以便更容易分析。你可以使用已经提供给你的`traffic_data.txt`文件。该文件中的每一行都包含逗号分隔的字符串，格式如下：
- en: Day
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期
- en: Time
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间
- en: The opponent team
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对手队伍
- en: Whether or not a baseball game is going on
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有棒球比赛正在进行
- en: The number of cars passing by
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经过的车辆数量
- en: How to do it...
  id: totrans-310
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how to estimate traffic:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何估算交通流量：
- en: 'Let''s see how to build an SVM regressor. We will use `traffic.py` that''s
    already provided to you as a reference. Create a new Python file, and add the
    following lines:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看如何构建 SVM 回归器。我们将使用您已提供的作为参考的 `traffic.py`。创建一个新的 Python 文件，并添加以下行：
- en: '[PRE50]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: We loaded all the input data into `X`.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将所有输入数据加载到 `X` 中。
- en: 'Let''s encode this data:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们编码这些数据：
- en: '[PRE51]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Let''s build and train the SVM regressor using the radial basis function:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用径向基函数构建和训练 SVM 回归器：
- en: '[PRE52]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: In the preceding lines, the `C` parameter specifies the penalty for misclassification
    and `epsilon` specifies the limit within which no penalty is applied.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的行中，`C` 参数指定了误分类的惩罚，而 `epsilon` 指定了不应用惩罚的限制范围内。
- en: 'Let''s perform cross-validation to check the performance of the regressor:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们执行交叉验证以检查回归器的性能：
- en: '[PRE53]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Let''s test it on a datapoint:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在一个数据点上测试它：
- en: '[PRE54]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'If you run this code, you will see the following printed on your Terminal:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你运行此代码，你将在你的终端上看到以下输出：
- en: '[PRE55]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: How it works...
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we used data collected by a sensor on the 101 North Highway
    in Los Angeles, near the stadium where the Dodgers play. This position is sufficiently
    close to the stadium to detect the increase in traffic that occurs during a match.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用了在洛杉矶 101 号北高速公路上收集的数据，靠近道奇队比赛的球场。这个位置足够靠近球场，可以检测到比赛期间交通的增加。
- en: 'The observations were made over 25 weeks, over 288 time intervals per day (every
    5 minutes). We built a regressor based on the SVM algorithm to predict the presence
    of a baseball game at the Dodgers stadium. In particular, we can estimate the
    number of cars that pass that position on the basis of the value assumed by the
    following predictors: day, time, the opponent team, and whether or not a baseball
    game is going on.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 观察是在 25 周内进行的，每天有 288 个时间间隔（每 5 分钟一次）。我们基于 SVM 算法构建了一个回归器来预测道奇球场是否有棒球比赛。特别是，我们可以根据以下预测器的值估计通过该位置的汽车数量：日期、时间、对手球队以及是否正在进行棒球比赛。
- en: There's more…
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多...
- en: '**Support vector regression** (**SVR**) is based on the same principles as
    SVMs. In fact, SVR is adapted from SVMs, where the dependent variable is numeric
    rather than categorical. One of the main advantages of using SVR is that it is
    a nonparametric technique.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量回归**（**SVR**）与 SVMs 的原理相同。事实上，SVR 是从 SVMs 调整而来的，其中因变量是数值而不是分类的。使用 SVR
    的主要优点之一是它是一种非参数技术。'
- en: See also
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'The official documentation of the `sklearn.metrics.mean_absolute_error()` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.metrics.mean_absolute_error()` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)'
- en: '*Linear Regression and Support Vector Regression* (from the University of Adelaide):
    [https://cs.adelaide.edu.au/~chhshen/teaching/ML_SVR.pdf](https://cs.adelaide.edu.au/~chhshen/teaching/ML_SVR.pdf)'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*线性回归和支持向量回归*（来自阿德莱德大学）：[https://cs.adelaide.edu.au/~chhshen/teaching/ML_SVR.pdf](https://cs.adelaide.edu.au/~chhshen/teaching/ML_SVR.pdf)'
- en: Simplifying machine learning workflow using TensorFlow
  id: totrans-334
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 简化机器学习工作流程
- en: '**TensorFlow** is an open source numerical calculation library. The library
    was created by Google programmers. It provides all the tools necessary to build
    deep learning models and offers developers a black-box interface to program.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow** 是一个开源的数值计算库。该库由谷歌程序员创建。它提供了构建深度学习模型所需的所有工具，并为开发者提供了一个黑盒接口来编程。'
- en: Getting ready
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In this recipe, we will introduce the TensorFlow framework, using a simple
    neural network to classify the `iris` species. We will use the `iris` dataset,
    which has 50 samples from the following species:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将介绍 TensorFlow 框架，使用简单的神经网络来分类 `iris` 物种。我们将使用 `iris` 数据集，该数据集包含以下物种的
    50 个样本：
- en: Iris setosa
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爱丽丝·塞托萨
- en: Iris virginica
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爱丽丝·维吉尼卡
- en: Iris versicolor
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爱丽丝·维吉尼卡
- en: Four features are measured from each sample, namely the length and the width
    of the sepals and petals, in centimeters.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 从每个样本测量了四个特征，即花萼和花瓣的长度和宽度，单位为厘米。
- en: 'The following variables are contained:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 包含以下变量：
- en: Sepal length in cm
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花萼长度（厘米）
- en: Sepal width in cm
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花萼宽度（厘米）
- en: Petal length in cm
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花瓣长度（厘米）
- en: Petal width in cm
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花瓣宽度（厘米）
- en: 'Class: `setosa`, `versicolor`, or `virginica`'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别：`setosa`、`versicolor` 或 `virginica`
- en: How to do it...
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s see how to simplify machine learning workflow using TensorFlow:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用 TensorFlow 简化机器学习工作流程：
- en: 'We start, as always, by importing the libraries:'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们像往常一样，首先导入库：
- en: '[PRE56]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The first two libraries are imported only to load and split the data. The third
    library loads the `tensorflow` library.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个库仅用于加载数据和分割数据。第三个库加载了`tensorflow`库。
- en: 'Load the `iris` dataset:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载`iris`数据集：
- en: '[PRE57]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Load and split the features and classes:'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载并分割特征和类别：
- en: '[PRE58]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The data is split into 70% for training and 30% for testing. The `random_state=1` parameter
    is the seed used by the random number generator.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 数据被分为70%用于训练和30%用于测试。`random_state=1`参数是随机数生成器使用的种子。
- en: 'Now we will build a simple neural network with one hidden layer and 10 nodes:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将构建一个包含一个隐藏层和10个节点的简单神经网络：
- en: '[PRE59]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Then we fit the network:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们调整网络：
- en: '[PRE60]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'We will then make the predictions:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们将进行预测：
- en: '[PRE61]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Finally, we will calculate the `accuracy` metric of the model:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将计算模型的`accuracy`指标：
- en: '[PRE62]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The following result is returned:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE63]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: How it works...
  id: totrans-368
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we used the `tensorflow` library to build a simple neural network
    to classify iris species from four features measured. In this way, we saw how
    simple it is to implement a model based on a machine learning algorithm using
    the `tensorflow` library. This topic, and on deep neural networks in general,
    will be analyzed in detail in [Chapter 13](01c4a476-990c-40bf-8720-b8f71b2953d4.xhtml), *Deep
    Neural Networks*.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们使用了`tensorflow`库来构建一个简单的神经网络，用于从四个测量的特征中分类鸢尾花种类。这样，我们看到了如何使用`tensorflow`库实现基于机器学习算法的模型是多么简单。关于这个主题，以及一般深度神经网络，将在[第13章](01c4a476-990c-40bf-8720-b8f71b2953d4.xhtml)，“深度神经网络”中详细分析。
- en: There's more…
  id: totrans-370
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: TensorFlow provides native APIs in Python, C, C++, Java, Go, and Rust. The third-party
    APIs available are in C#, R, and Scala. Since October 2017, it has integrated
    eager execution functionality which allows the immediate execution of the operations
    referred to by Python.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow为Python、C、C++、Java、Go和Rust提供了原生API。可用的第三方API包括C#、R和Scala。自2017年10月起，它已集成即时执行功能，允许立即执行由Python引用的操作。
- en: See also
  id: totrans-372
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关内容
- en: The official documentation of the `tensorflow` library: [https://www.tensorflow.org/tutorials](https://www.tensorflow.org/tutorials)
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorflow`库的官方文档：[https://www.tensorflow.org/tutorials](https://www.tensorflow.org/tutorials)'
- en: '*Tensorflow for Deep Learning Research* (from Stanford University): [http://web.stanford.edu/class/cs20si/](http://web.stanford.edu/class/cs20si/)'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Tensorflow for Deep Learning Research*（来自斯坦福大学）：[http://web.stanford.edu/class/cs20si/](http://web.stanford.edu/class/cs20si/)'
- en: Implementing a stacking method
  id: totrans-375
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现堆叠方法
- en: 'A combination of different approaches leads to better results: this statement
    works in different aspects of our life and also adapts to algorithms based on
    machine learning. Stacking is the process of combining various machine learning
    algorithms. This technique is due to David H. Wolpert, an American mathematician,
    physicist, and computer scientist.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的方法组合可以带来更好的结果：这个说法在我们生活的不同方面都适用，并且也适用于基于机器学习的算法。堆叠是将各种机器学习算法组合的过程。这项技术归功于美国数学家、物理学家和计算机科学家David
    H. Wolpert。
- en: In this recipe, we will learn how to implement a stacking method.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将学习如何实现堆叠方法。
- en: Getting ready
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will use the `heamy` library to stack the two models that we just used in
    the previous recipes. The `heamy` library is a set of useful tools for competitive
    data science.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`heamy`库来堆叠我们在前一个配方中使用的两个模型。`heamy`库是一套用于竞争性数据科学的有用工具。
- en: How to do it...
  id: totrans-380
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s see how to implement a stacking method:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何实现堆叠方法：
- en: 'We start by importing the libraries:'
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先导入库：
- en: '[PRE64]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Load the `boston` dataset, already used in [Chapter 1](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml), *The
    Realm of Supervised Learning*, for the *Estimating housing prices* recipe:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载`boston`数据集，已在[第1章](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml)，“监督学习领域”，用于*估算房价*配方：
- en: '[PRE65]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Split the data:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分割数据：
- en: '[PRE66]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Let''s create the dataset:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建数据集：
- en: '[PRE67]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Now we can build the two models that we will use in the stacking procedure:'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以构建在堆叠过程中使用的两个模型：
- en: '[PRE68]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'It''s time to stack these models:'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是时候堆叠这些模型了：
- en: '[PRE69]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Now we will train a `LinearRegression` model on stacked data:'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将对堆叠数据进行`LinearRegression`模型的训练：
- en: '[PRE70]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Finally, we will calculate the results to validate the model:'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将计算结果以验证模型：
- en: '[PRE71]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: How it works...
  id: totrans-398
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Stacked generalization works by deducing the biases of the classifier/regressor
    relative to a supplied learning dataset. This deduction works by generalizing
    into a second space whose inputs are the hypotheses of the original generalizers
    and whose output is the correct hypothesis. When used with multiple generators,
    stacked generalization is an alternative to cross-validation.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠泛化通过推断分类器/回归器相对于提供的训练数据集的偏差来工作。这种推断是通过将原始泛化器的假设推广到第二个空间来实现的，该空间的输入是原始泛化器的假设，输出是正确的假设。当与多个生成器一起使用时，堆叠泛化是交叉验证的替代方案。
- en: There's more…
  id: totrans-400
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多信息...
- en: Stacking tries to exploit the advantages of each algorithm by ignoring or correcting
    their disadvantages. It can be seen as a mechanism that corrects errors in your
    algorithms. Another library to perform a stacking procedure is StackNet.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠泛化试图通过忽略或纠正它们的缺点来利用每个算法的优点。它可以被视为一种纠正你算法中错误的机制。另一个执行堆叠过程的库是 StackNet。
- en: '**StackNet** is a framework implemented in Java based on Wolpert''s stacked
    generalization on multiple levels to improve accuracy in machine learning predictive
    problems. The StackNet model functions as a neural network in which the transfer
    function takes the form of any supervised machine learning algorithm.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '**StackNet** 是一个基于 Wolpert 的多级堆叠泛化的 Java 框架，旨在提高机器学习预测问题中的准确性。StackNet 模型作为一个神经网络运行，其传递函数的形式可以是任何监督机器学习算法。'
- en: See also
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The official documentation of the `heamy` library:[ https://heamy.readthedocs.io/en/latest/index.html](https://heamy.readthedocs.io/en/latest/index.html)
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`heamy` 库的官方文档：[https://heamy.readthedocs.io/en/latest/index.html](https://heamy.readthedocs.io/en/latest/index.html)'
- en: 'The official documentation of the `StackNet` framework: [https://github.com/kaz-Anova/StackNet](https://github.com/kaz-Anova/StackNet)'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StackNet` 框架的官方文档：[https://github.com/kaz-Anova/StackNet](https://github.com/kaz-Anova/StackNet)'
- en: '*Stacked Generalization* by David H. Wolpert: [http://www.machine-learning.martinsewell.com/ensembles/stacking/Wolpert1992.pdf](http://www.machine-learning.martinsewell.com/ensembles/stacking/Wolpert1992.pdf)'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: David H. Wolpert 的《堆叠泛化》：[http://www.machine-learning.martinsewell.com/ensembles/stacking/Wolpert1992.pdf](http://www.machine-learning.martinsewell.com/ensembles/stacking/Wolpert1992.pdf)
