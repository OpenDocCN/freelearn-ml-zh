- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Labeling Image Data Using Rules
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用规则标注图像数据
- en: In this chapter, we will explore data labeling techniques tailored specifically
    for image classification, using Python. Our primary objective is to clarify the
    path you need to take to generate precise labels for these images in the dataset,
    relying on meticulously crafted rules founded upon various image properties. You
    will be empowered with the ability to dissect and decode images through manual
    inspection, harnessing the formidable Python ecosystem.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨专门针对图像分类的数据标注技术，使用Python实现。我们的主要目标是阐明你需要采取的路径来为这些图像生成精确的标签，这些标签基于精心设计的规则，这些规则基于各种图像属性。你将获得通过手动检查分解和解析图像的能力，利用强大的Python生态系统。
- en: 'In this chapter, you will learn the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习以下内容：
- en: How to create labeling rules based on manual inspection of image visualizations
    in Python
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何基于Python中对图像可视化的手动检查来创建标注规则
- en: How to create labeling rules based on the size and aspect ratio of images
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何基于图像的大小和宽高比来创建标注规则
- en: How to apply transfer learning to label image data, using pre-trained models
    such as **YOLO V3**
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用预训练模型如**YOLO V3**应用迁移学习来标注图像数据
- en: The overarching goal is to empower you with the ability to generate precise
    and reliable labels for your data. We aim to equip you with a versatile set of
    labeling strategies that can be applied across various machine learning projects.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 总体目标是赋予你生成精确和可靠数据标签的能力。我们的目标是为你提供一套通用的标注策略，这些策略可以应用于各种机器学习项目。
- en: We will also introduce transformations such as **shearing** and **flipping**
    for image labeling. We will provide you with the knowledge and techniques required
    to harness these transformations effectively, giving your labeling process a dynamic
    edge. we’ll delve into the intricacies of **size**, **aspect ratio**, **bounding
    box**, **polygon annotation**,and **polyline annotation**. You’ll learn how to
    derive labeling rules based on these quantitative image characteristics, providing
    a systematic and reliable approach to labeling data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将介绍用于图像标注的变换，如**剪切**和**翻转**。我们将提供所需的知识和技术，以有效地利用这些变换，给你的标注过程带来动态优势。我们将深入研究**大小**、**宽高比**、**边界框**、**多边形标注**和**折线标注**的复杂性。你将学习如何根据这些定量图像特征推导出标注规则，提供一种系统且可靠的标注数据的方法。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Complete code notebooks for the examples used in this chapter are available
    on GitHub at [https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python](https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的示例的完整代码笔记本可在GitHub上找到，网址为[https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python](https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python)。
- en: The sample image dataset used in this chapter is available on GitHub at [https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/images](https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/images).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的样本图像数据集可在GitHub上找到，网址为[https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/images](https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/images)。
- en: Labeling rules based on image visualization
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于图像可视化的标注规则
- en: Image classification is the process of categorizing an image into one or more
    classes based on its content. It is a challenging task due to the high variability
    and complexity of images. In recent years, machine learning techniques have been
    applied to image classification with great success. However, machine learning
    models require a large amount of labeled data to train effectively.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类是将图像根据其内容分类到一个或多个类别的过程。由于图像的高度可变性和复杂性，这是一个具有挑战性的任务。近年来，机器学习技术已被成功应用于图像分类。然而，机器学习模型需要大量的标注数据来有效训练。
- en: Image labeling using rules with Snorkel
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Snorkel的规则进行图像标注
- en: Snorkel is an open source data platform that provides a way to generate large
    amounts of labeled data using weak supervision techniques. Weak supervision allows
    you to label data with noisy or incomplete sources of supervision, such as heuristics,
    rules, or patterns.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Snorkel是一个开源数据平台，它提供了一种使用弱监督技术生成大量标注数据的方法。弱监督允许你使用噪声或不完整的监督源来标注数据，例如启发式方法、规则或模式。
- en: Snorkel primarily operates within the paradigm of weak supervision rather than
    traditional semi-supervised learning. Snorkel is a framework designed for weak
    supervision, where the labeling process may involve noisy, limited, or imprecise
    rules rather than a large amount of labeled data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Snorkel主要在弱监督范式内运行，而不是传统的半监督学习。Snorkel是一个为弱监督设计的框架，其中标记过程可能涉及噪声、有限或不精确的规则，而不是大量标记数据。
- en: In Snorkel, users create **labeling functions** (**LFs**) that express heuristic
    or rule-based labeling strategies. These LFs might not be perfect, and there can
    be conflicts or noise in the generated labels. Snorkel’s labeling model then learns
    to denoise and combine these weak labels to create more accurate and reliable
    labeling for the training data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在Snorkel中，用户创建**标记函数**（**LFs**），这些函数表达启发式或基于规则的标记策略。这些LFs可能并不完美，生成的标签中可能存在冲突或噪声。然后，Snorkel的标记模型学习去噪和组合这些弱标签，以创建更准确和可靠的训练数据标记。
- en: While semi-supervised learning typically involves having a small amount of labeled
    data and a large amount of unlabeled data, Snorkel focuses on the weak supervision
    scenario, allowing users to leverage various sources of noisy or incomplete supervision
    to train machine learning models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然半监督学习通常涉及少量标记数据和大量未标记数据，但Snorkel专注于弱监督场景，使用户能够利用各种噪声或不完整的监督源来训练机器学习模型。
- en: In summary, Snorkel is more aligned with the principles of weak supervision,
    where the emphasis is on handling noisy or imprecise labels generated by heuristic
    rules, rather than being strictly categorized as a semi-supervised learning framework.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，Snorkel更符合弱监督的原则，其中重点在于处理由启发式规则生成的噪声或不精确标签，而不是严格归类为半监督学习框架。
- en: In this section, we will explore the concept of weak supervision and how to
    generate labels using Snorkel.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨弱监督的概念以及如何使用Snorkel生成标签。
- en: Weak supervision
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 弱监督
- en: Weak supervision is a technique for generating large amounts of labeled data
    using noisy or incomplete sources of supervision. The idea is to use a set of
    LFs that generate noisy labels for each data point. These labels are then combined
    to generate a final label for each data point. The key advantage of weak supervision
    is that it allows you to generate labeled data quickly and at a low cost.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 弱监督是一种技术，用于使用噪声或不完整的监督源生成大量标记数据。其思想是使用一组LFs为每个数据点生成噪声标签。然后，将这些标签组合起来为每个数据点生成一个最终标签。弱监督的关键优势是它允许你快速且低成本地生成标记数据。
- en: Snorkel is a framework that provides a way to generate labels using weak supervision.
    It provides a set of tools to create LFs, combine them, and train a model to learn
    from the generated labels. Snorkel uses a technique called data programming to
    combine the LFs and generate a final label for each data point.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Snorkel是一个提供使用弱监督生成标签方法的框架。它提供了一套工具来创建LFs、组合它们，并训练一个模型从生成的标签中学习。Snorkel使用一种称为数据编程的技术来组合LFs并为每个数据点生成一个最终标签。
- en: An LF is a function that generates a noisy label for a data point. The label
    can be any value, including continuous or discrete values. In the context of image
    classification, an LF is a function that outputs a label of 1 if the image contains
    the object of interest, and 0 otherwise.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: LF是一个为数据点生成噪声标签的函数。标签可以是任何值，包括连续或离散值。在图像分类的背景下，LF是一个如果图像包含感兴趣的对象则输出标签1，否则输出0的函数。
- en: LFs are created using heuristics, rules, or patterns. The key idea is to define
    a set of rules that capture the relevant information for each data point.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: LFs是通过启发式、规则或模式创建的。关键思想是定义一组规则，以捕获每个数据点的相关信息。
- en: Now, let us see how to define the rules and an LF based on the manual visualization
    of an image’s object color for plant disease labeling.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何定义基于手动可视化图像对象颜色规则的规则和LF，用于植物疾病标记。
- en: Rules based on the manual visualization of an image’s object color
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于手动可视化图像对象颜色的规则
- en: In this section, let us see how we can use LFs that look for specific visual
    features that are characteristic of images of a plant’s leaves, which we are interested
    in classifying as “healthy” or “deceased”. For instance, we could use an LF that
    checks whether the image has a certain color distribution, or whether it contains
    specific shapes that are common in those images.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，让我们看看如何使用寻找特定视觉特征的LF，这些特征是植物叶子图像的典型特征，我们感兴趣的是将其分类为“健康”或“死亡”。例如，我们可以使用一个检查图像是否具有特定颜色分布或是否包含那些图像中常见的特定形状的LF。
- en: Snorkel’s LFs can be used to label images based on various properties, such
    as the presence of certain objects, colors, textures, and shapes. Here’s an example
    of Python code that uses Snorkel LFs to detect images based on their color distribution.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Snorkel的LF可以根据各种属性对图像进行标注，例如某些物体的存在、颜色、纹理和形状。以下是一个使用Snorkel LF根据颜色分布检测图像的Python代码示例。
- en: Creating labeling rules based on manual inspection of image visualizations is
    a manual process that often involves the expertise of a human annotator. This
    process is commonly used in scenarios where there is no existing labeled dataset,
    and you need to create labels for machine learning or analysis tasks.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 基于对图像可视化的手动检查创建标注规则是一个手动过程，通常需要人工标注员的专长。这个过程通常用于没有现有标注数据集的情况，你需要为机器学习或分析任务创建标签。
- en: 'Here’s a general outline of how you can create labeling rules based on the
    manual inspection of image visualizations in Python:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何在Python中基于对图像可视化的手动检查创建标注规则的一般概述：
- en: '**Collect a representative sample**: Begin by selecting a representative sample
    of images from your dataset. This sample should cover the range of variations
    and categories you want to classify.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**收集代表性样本**: 首先从你的数据集中选择一个代表性的图像样本。这个样本应涵盖你想要分类的变异和类别范围。'
- en: '**Define the labeling criteria**: Clearly define the criteria or rules to label
    images based on their visual properties. For example, if you’re classifying images
    to identify plant diseases from images of leaves, agricultural experts visually
    inspect leaf images for discoloration, spots, or unusual patterns. Rules can be
    defined based on the appearance and location of symptoms. We will use this example
    for our demonstration shortly.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定义标注标准**: 明确定义基于图像视觉属性进行标注的准则或规则。例如，如果你正在根据叶子图像对图像进行分类以识别植物疾病，农业专家会通过视觉检查叶子图像以寻找变色、斑点或异常图案。可以根据症状的外观和位置定义规则。我们将在接下来的演示中使用此示例。'
- en: '**Create a labeling interface**: You can use existing tools or libraries to
    create a labeling interface where human annotators can view images and apply labels
    based on the defined criteria. Libraries such as Labelbox and Supervisely or custom
    interfaces, using Python web frameworks such as Flask or Django, can be used for
    this purpose.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建标注界面**: 你可以使用现有的工具或库来创建一个标注界面，让人工标注员可以查看图像并根据定义的准则应用标签。例如，可以使用Labelbox和Supervisely等库或使用Python
    Web框架（如Flask或Django）自定义界面。'
- en: '**Annotate the images**: Have human annotators manually inspect each image
    in your sample and apply labels according to the defined criteria. This step involves
    the human annotators visually inspecting the images and making classification
    decisions, based on their expertise and the provided guidelines.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**标注图像**: 让人工标注员手动检查你的样本中的每张图像，并根据定义的准则应用标签。这一步骤涉及人工标注员根据他们的专长和提供的指南对图像进行视觉检查并做出分类决策。'
- en: '**Collect annotations**: Collect the annotations generated by the human annotators.
    Each image should have a corresponding label or class assigned based on the visual
    inspection.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**收集标注**: 收集由人工标注员生成的标注。每张图像应根据视觉检查分配相应的标签或类别。'
- en: '**Analyze and formalize rules**: After collecting a sufficient number of annotations,
    analyze the patterns and decisions made by the annotators. Try to formalize the
    decision criteria based on the annotations. For example, you might observe that
    images with certain visual features were consistently labeled as a specific class.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分析和正式化规则**: 收集足够的标注后，分析标注员做出的模式和决策。尝试根据标注正式化决策标准。例如，你可能观察到具有某些视觉特征的图像被一致地标注为特定类别。'
- en: '**Convert rules to code**: Translate the formalized decision criteria into
    code that can automatically classify images based on those rules. This code can
    be written in Python and integrated into your machine learning pipeline or analysis
    workflow.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**将规则转换为代码**：将正式化的决策标准转换为代码，该代码可以根据这些规则自动分类图像。此代码可以用Python编写，并集成到您的机器学习管道或分析工作流程中。'
- en: '**Test and validate rules**: Apply the automated labeling rules to a larger
    portion of your dataset to ensure that they generalize well. Validate the rules
    by comparing the automated labels with ground truth labels if available, or by
    reviewing a subset of the automatically labeled images manually.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**测试和验证规则**：将自动标签规则应用于数据集的更大部分，以确保它们具有良好的泛化能力。如果可用，通过比较自动标签与地面真实标签来验证规则，或者通过手动审查自动标签的子集。'
- en: '**Iterate and refine**: Iteratively refine the labeling rules based on feedback,
    error analysis, and additional manual inspection if necessary. This process may
    involve improving the rules, adding more criteria, or adjusting thresholds.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迭代和改进**：根据反馈、错误分析和必要时进行额外的手动检查，迭代地改进标签规则。这个过程可能包括改进规则、添加更多标准或调整阈值。'
- en: Creating labeling rules based on manual inspection is a labor-intensive process
    but can be essential to generate labeled data when no other options are available.
    The quality of your labeled dataset and the effectiveness of your rules depend
    on the accuracy and consistency of the human annotators, as well as the clarity
    of the defined criteria.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 基于手动检查创建标签规则是一个劳动密集型过程，但在没有其他选择时，生成标记数据可能是必不可少的。您标记数据集的质量和规则的有效性取决于人工标注员的准确性和一致性，以及定义标准的清晰度。
- en: Real-world applications
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实际应用
- en: 'Manual inspection of images for classification, along with the definition of
    rules or patterns, is common in various real-world applications. Here are some
    practical examples:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种实际应用中，手动检查图像进行分类，以及定义规则或模式是常见的。以下是一些实际示例：
- en: '**Medical** **image classification**:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医学图像分类**：'
- en: '**Example**: Classifying X-ray or MRI images as “normal” or “abnormal.”'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例**：将X射线或MRI图像分类为“正常”或“异常”。'
- en: '**Rules/patterns**: Radiologists visually inspect images for abnormalities,
    such as tumors, fractures, or anomalies in anatomy. Rules can be based on the
    presence, size, or location of these features.'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规则/模式**：放射科医生通过视觉检查图像以识别异常，如肿瘤、骨折或解剖学上的异常。规则可以基于这些特征的存在、大小或位置。'
- en: '**Plant** **disease detection**:'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**植物疾病检测**：'
- en: '**Example**: Identifying plant diseases from images of leaves.'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例**：从叶片图像中识别植物疾病。'
- en: '**Rules/patterns**: Agricultural experts visually inspect leaf images for discoloration,
    spots, or unusual patterns. Rules can be defined based on the appearance and location
    of symptoms.'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规则/模式**：农业专家通过视觉检查叶片图像以识别褪色、斑点或异常模式。可以根据症状的外观和位置定义规则。'
- en: '**Food** **quality inspection**:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**食品质量检查**：'
- en: '**Example**: Classifying food products as “fresh” or “spoiled” from images.'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例**：从图像中将食品产品分类为“新鲜”或“变质”。'
- en: '**Rules/patterns**: Food inspectors visually inspect images of fruits, vegetables,
    or packaged goods for signs of spoilage, mold, or other quality issues. Rules
    can be based on color, texture, or shape.'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规则/模式**：食品检查员通过视觉检查水果、蔬菜或包装商品的图像以识别腐烂、霉变或其他质量问题。规则可以基于颜色、质地或形状。'
- en: '**Defect detection** **in manufacturing**:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**制造缺陷检测**：'
- en: '**Example**: Detecting defects in manufactured products from images.'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例**：从图像中检测制造产品的缺陷。'
- en: '**Rules/patterns**: Quality control inspectors visually inspect images of products
    for defects such as cracks, scratches, or missing components. Rules can be defined
    based on the location and characteristics of defects.'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规则/模式**：质量控制检查员通过视觉检查产品图像以识别缺陷，如裂缝、划痕或缺失部件。可以根据缺陷的位置和特征定义规则。'
- en: '**Traffic** **sign recognition**:'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交通标志识别**：'
- en: '**Example**: Recognizing traffic signs from images captured by autonomous vehicles.'
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例**：从自动驾驶车辆捕获的图像中识别交通标志。'
- en: '**Rules/patterns**: Engineers visually inspect images for the presence of signs
    and their shapes, colors, and symbols. Rules can be defined based on these visual
    cues.'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规则/模式**：工程师通过视觉检查图像以识别其形状、颜色和符号等特征。可以根据这些视觉线索定义规则。'
- en: '**Wildlife monitoring**:'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**野生动物监测**：'
- en: '**Example**: Identifying and tracking animals in camera trap images.'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例**：从相机陷阱图像中识别和跟踪动物。'
- en: '**Rules/patterns**: Wildlife experts visually inspect images for the presence
    of specific animal species, their behavior, or the time of day. Rules can be based
    on the appearance and context of animals.'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规则/模式**：野生动物专家通过视觉检查图像以确定特定动物物种的存在、其行为或一天中的时间。规则可以基于动物的外观和上下文。'
- en: '**Historical** **document classification**:'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**历史文档分类**：'
- en: '**Example**: Classifying historical documents based on content or era.'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例**：根据内容或时代对历史文档进行分类。'
- en: '**Rules/patterns**: Archivists visually inspect scanned documents for handwriting
    style, language, content, or visual elements such as illustrations. Rules can
    be defined based on these characteristics.'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规则/模式**：档案保管员通过视觉检查扫描的文档的手写风格、语言、内容或视觉元素（如插图）。可以根据这些特征定义规则。'
- en: '**Security** **and surveillance**:'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全和监控**：'
- en: '**Example**: Identifying security threats or intruders in surveillance camera
    footage.'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**示例**：在监控摄像头录像中识别安全威胁或入侵者。'
- en: '**Rules/patterns**: Security personnel visually inspect video feeds for unusual
    behavior, suspicious objects, or unauthorized access. Rules can be defined based
    on these observations.'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规则/模式**：安全人员通过视频流视觉检查异常行为、可疑物体或未经授权的访问。可以根据这些观察结果定义规则。'
- en: In all these examples, experts or human annotators visually examine images,
    identify relevant patterns or features, and define rules or criteria for classification.
    These rules are often based on domain knowledge and experience. Once established,
    the rules can be used to create LFs and classify images automatically, assist
    in decision-making, or prioritize further analysis.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些例子中，专家或人工标注者通过视觉检查图像，识别相关模式或特征，并定义分类的规则或标准。这些规则通常基于领域知识和经验。一旦建立，这些规则可以用来创建LF并自动分类图像，协助决策或优先分析。
- en: A practical example of plant disease detection
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 植物疾病检测的一个实际例子
- en: Let us see the example LF for plant disease detection. In this code, we have
    created a rule to classify healthy and diseased plants, based on the color distribution
    of leaves. One rule is if `black_pixel_percentage` in the plant leaves is greater
    than the threshold value, then we classify that plant as a diseased plant.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看用于植物疾病检测的示例LF。在这段代码中，我们创建了一个规则来根据叶子的颜色分布将植物分类为健康或病态。一个规则是如果植物叶子中的`black_pixel_percentage`大于阈值值，那么我们将该植物分类为病态植物。
- en: The following are the two different types of plant leaves.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是两种不同的植物叶子类型。
- en: '![Figure 5.1 – Healthy and diseased plant leaves](img/B18944_05_2_Merged_(2).jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1 – 健康和病态植物叶子](img/B18944_05_2_Merged_(2).jpg)'
- en: Figure 5.1 – Healthy and diseased plant leaves
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – 健康和病态植物叶子
- en: 'We calculate the number of black color pixels in a leaf image and then calculate
    the percent of black pixels:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算叶子图像中黑色像素的数量，然后计算黑色像素的百分比：
- en: '*Percent of black pixels = count of black pixels in a leaf image/total number
    of pixels in a* *leaf image*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*黑色像素百分比 = 叶子图像中黑色像素的数量/叶子图像中总像素数量*'
- en: We are going to use the rule that if the black pixel percent in a plant leave
    image is greater than the threshold value (in this example, 10%), then we classify
    that plant as a diseased plant and label it as a “diseased plant.”
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下规则：如果一个植物叶子图像中的黑色像素百分比大于阈值值（在这个例子中，10%），那么我们将该植物分类为病态植物，并标记为“病态植物”。
- en: Similarly, if the black pixel percentage is less than 10%, then we classify
    that plant as a healthy plant and label it as a “healthy plant.”
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果黑色像素百分比小于10%，那么我们将该植物分类为健康植物，并标记为“健康植物”。
- en: 'The following code snippet shows how to calculate the black pixel percentage
    in an image using Python libraries:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了如何使用Python库计算图像中的黑色像素百分比：
- en: '[PRE0]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This line converts the original color image to grayscale using OpenCV’s `cvtColor`
    function. Grayscale images have only one channel (compared to the three channels
    in a color image), representing the intensity or brightness of each pixel. Converting
    to grayscale simplifies subsequent processing:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这一行将原始彩色图像转换为灰度图，使用OpenCV的`cvtColor`函数。灰度图像只有一个通道（与彩色图像中的三个通道相比），表示每个像素的强度或亮度。转换为灰度图简化了后续处理：
- en: '[PRE1]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this line, a thresholding operation is applied to the grayscale image, `gray_image`.
    Thresholding is a technique that separates pixels into two categories, based on
    their intensity values – those above a certain threshold and those below it. Here’s
    what each parameter means:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一行，对灰度图像`gray_image`应用了阈值操作。阈值是一种技术，根据像素的强度值将像素分为两类——高于某个阈值的像素和低于阈值的像素。以下是对每个参数的解释：
- en: '`gray_image`: The grayscale image to be thresholded.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gray_image`：要阈值化的灰度图像。'
- en: '`150`: The threshold value. Pixels with intensities greater than or equal to
    150 will be set to the maximum value (`255`), while pixels with intensities lower
    than 150 will be set to `0`.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`150`：阈值值。强度值大于或等于150的像素将设置为最大值（`255`），而强度值低于150的像素将设置为`0`。'
- en: '`255`: The maximum value to which pixels above the threshold are set.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`255`：高于阈值的像素设置的最大值。'
- en: '`cv2.THRESH_BINARY_INV`: The thresholding type. In this case, it’s set to “binary
    inverted,” which means that pixels above the threshold will become 0, and pixels
    below the threshold will become 255.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv2.THRESH_BINARY_INV`：阈值类型。在这种情况下，它设置为“二值反转”，这意味着高于阈值的像素将变为0，而低于阈值的像素将变为255。'
- en: 'The result of this thresholding operation is stored in `binary_image`, which
    is a binary image where regions with discoloration are highlighted:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此阈值操作的结果存储在`binary_image`中，这是一个突出显示褪色区域的二值图像：
- en: '[PRE2]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `cv2.countNonZero(binary_image)` function counts the number of non-zero
    (white) pixels in the binary image. Since we are interested in black pixels (discoloration),
    we subtract this count from the total number of pixels in the image.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv2.countNonZero(binary_image)`函数计算二值图像中非零（白色）像素的数量。由于我们感兴趣的是黑色像素（褪色），我们从图像中的总像素数中减去这个计数。'
- en: '`binary_image.size`: This is the total number of pixels in the binary image,
    which is equal to the width multiplied by the height.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`binary_image.size`：这是二值图像中的总像素数，等于宽度乘以高度。'
- en: By dividing the count of non-zero (white) pixels by the total number of pixels
    and multiplying by 100, we obtain the percentage of white pixels in the image.
    This percentage represents the extent of discoloration in the image.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将非零（白色）像素的计数除以总像素数并乘以100，我们得到图像中白色像素的百分比。这个百分比代表了图像中褪色的程度。
- en: 'To calculate the percentage of black pixels (discoloration), you can use the
    following code:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算黑色像素（褪色）的百分比，可以使用以下代码：
- en: '[PRE3]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Overall, this code snippet is a simple method to quantitatively measure the
    extent of discoloration in a grayscale image, by converting it into a binary image
    and calculating the percentage of black pixels. It can be useful for tasks such
    as detecting defects or anomalies in images. Adjusting the threshold value (in
    this case, 150) can change the sensitivity of the detection.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，这个代码片段是一种简单的方法，通过将其转换为二值图像并计算黑色像素的百分比来定量测量灰度图像褪色的程度。它可以用于检测图像中的缺陷或异常等任务。调整阈值值（在本例中为150）可以改变检测的灵敏度。
- en: Let us create the labeling function to classify the plant as `Healthy` or `Diseased`,
    based on the threshold value of `black_pixel_percentage` in the leaf images, as
    follows.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个标记函数，根据叶图像中`black_pixel_percentage`的阈值值将植物分类为`Healthy`或`Diseased`，如下所示。
- en: '[PRE4]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This LF returns labels `0` (a diseased plant) or `1` (a healthy plant) based
    on the *black* color pixels percentage in the image. The complete working code
    for this plant disease labeling is available in the GitHub repo.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 此LF根据图像中黑色像素百分比对标签`0`（患病植物）或`1`（健康植物）进行返回。此植物疾病标签的完整工作代码可在GitHub仓库中找到。
- en: In the next section, let us see how we can apply labels using image properties
    such as size and aspect ratio.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，让我们看看如何使用图像属性（如大小和宽高比）应用标签。
- en: Labeling images using rules based on properties
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于属性进行图像标记
- en: Let us see an example of Python code that demonstrates how to classify images
    using rules, based on image properties such as size and aspect ratio.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个Python代码示例，演示如何根据图像属性（如大小和宽高比）使用规则对图像进行分类。
- en: Here, we will define rules such as if the black color distribution is greater
    than 50% in leaves, then that is a diseased plant. Similarly, in case of detecting
    a bicycle with a person, if the aspect ratio of an image is greater than some
    threshold value, then that image has a bicycle with a person.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将定义规则，例如，如果叶子中的黑色颜色分布大于 50%，则该植物为病态植物。同样，在检测有行人的自行车时，如果图像的长宽比大于某个阈值，则该图像包含有行人的自行车。
- en: 'In computer vision and image classification, the **aspect ratio** refers to
    the ratio of the width to the height of an image or object. It is a measure of
    how elongated or stretched an object or image appears along its horizontal and
    vertical dimensions. Aspect ratio is often used as a feature or criterion in image
    analysis and classification. It’s worth noting that aspect ratio alone is often
    not sufficient for classification, and it is typically used in conjunction with
    other features, such as **contour height**, **texture**, and **edge**, to achieve
    accurate classification results. Image properties such as bounding boxes, polygon
    annotations, and polyline annotations are commonly used in computer vision tasks
    for object detection and image segmentation. These properties help you to label
    and annotate objects within an image. Here’s an explanation of each feature along
    with Python code examples to demonstrate how to work with them:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉和图像分类中，**长宽比**指的是图像或对象宽度与高度的比例。它是衡量对象或图像在水平和垂直维度上拉长或拉伸程度的度量。长宽比常用于图像分析和分类中的特征或标准。值得注意的是，长宽比本身通常不足以进行分类，它通常与其他特征一起使用，如**轮廓高度**、**纹理**和**边缘**，以实现准确的分类结果。边界框、多边形标注和多段线标注等图像属性常用于计算机视觉任务中的对象检测和图像分割。这些属性帮助您在图像中对对象进行标注。以下是每个特征的说明以及演示如何使用它们的
    Python 代码示例：
- en: Bounding boxes
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 边界框
- en: 'A bounding box is a rectangular region that encloses an object of interest
    within an image. It is defined by four values – (`x_min`, `y_min`) for the top-left
    corner and (`x_max`, `y_max`) for the bottom-right corner. Bounding boxes are
    often used for object detection and localization. Here is an example of Python
    code to create and manipulate bounding boxes:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 边界框是包围图像中感兴趣对象的矩形区域。它由四个值定义——(`x_min`, `y_min`) 表示左上角，(`x_max`, `y_max`) 表示右下角。边界框通常用于对象检测和定位。以下是一个创建和操作边界框的
    Python 代码示例：
- en: '[PRE5]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Polygon annotation
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多边形标注
- en: 'A polygon annotation is a set of connected vertices that outline the shape
    of an object in an image. It is defined by a list of (x, y) coordinates representing
    the vertices. Polygon annotations are used for detailed object segmentation. Here
    is some example Python code to work with polygon annotations:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 多边形标注是一组连接的顶点，用于在图像中勾勒出对象的形状。它由表示顶点的 (x, y) 坐标列表定义。多边形标注用于详细的对象分割。以下是一些用于处理多边形标注的
    Python 代码示例：
- en: '[PRE6]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Polyline annotations
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多段线标注
- en: 'A polyline annotation is a series of connected line segments defined by a list
    of (x, y) coordinates for each vertex. Polylines are often used to represent shapes
    with multiple line segments, such as roads or paths. Here is some Python code
    to work with polyline annotations:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 多段线标注是由每个顶点的 (x, y) 坐标列表定义的一系列连接线段。多段线通常用于表示由多个线段组成的形状，如道路或路径。以下是一些用于处理多段线标注的
    Python 代码示例：
- en: '[PRE7]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: These code examples demonstrate how to work with bounding boxes, polygon annotations,
    and polyline annotations in Python. You can use these concepts to create rules
    to label images in computer vision applications.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这些代码示例展示了如何在 Python 中处理边界框、多边形标注和多段线标注。您可以使用这些概念来创建规则，在计算机视觉应用中对图像进行标注。
- en: Now, let us see the following example of how we can use contour height to classify
    whether an image contains a person riding a bicycle or just shows a bicycle on
    its own.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看以下示例，了解我们如何使用轮廓高度来区分图像中是否包含骑自行车的行人或仅显示自行车的图像。
- en: Example 1 – image classification – a bicycle with and without a person
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 1 – 图像分类 – 有无行人的自行车
- en: '**Contour height**, in the context of image processing and computer vision,
    refers to the measurement of the vertical extent or size of an object’s outline
    or contour within an image. It is typically calculated by finding the minimum
    and maximum vertical positions (i.e., the topmost and bottommost points) of the
    object’s boundary or contour.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**轮廓高度**，在图像处理和计算机视觉的背景下，指的是测量图像中对象轮廓或轮廓的垂直范围或尺寸。它通常通过找到对象的边界或轮廓的最小和最大垂直位置（即最高点和最低点）来计算。'
- en: 'Here’s how contour height is generally determined:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是如何通常确定轮廓高度的：
- en: '**Contour detection**: The first step is to detect the contour of an object
    within an image. Contours are essentially the boundaries that separate an object
    from its background.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**轮廓检测**：第一步是在图像中检测对象的轮廓。轮廓基本上是分离对象与其背景的边界。'
- en: '**A bounding rectangle**: Once the contour is detected, a bounding rectangle
    (often referred to as the “**bounding box**”) is drawn around the contour. This
    rectangle encompasses the entire object.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**边界矩形**：一旦检测到轮廓，就会在轮廓周围绘制一个边界矩形（通常称为“**边界框**”）。这个矩形包含了整个对象。'
- en: '**Measurement**: To calculate the contour height, the vertical extent of the
    bounding rectangle is measured. This is done by finding the difference between
    the y coordinates (the vertical positions) of the top and bottom sides of the
    bounding rectangle.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**测量**：为了计算轮廓高度，测量边界矩形的垂直范围。这是通过找到边界矩形的顶部和底部边界的y坐标（垂直位置）之间的差异来完成的。'
- en: In summary, contour height provides information about the vertical size of an
    object within an image. It can be a useful feature for various computer vision
    tasks, such as object recognition, tracking, and dimension estimation.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，轮廓高度提供了关于图像中对象垂直尺寸的信息。它可以是各种计算机视觉任务的有用特征，例如物体识别、跟踪和尺寸估计。
- en: Let us see how we will use Python functions to detect the following images,
    based on contour height.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们将如何使用Python函数根据轮廓高度检测以下图像。
- en: '![](img/B18944_05_2_Merged_(1).jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18944_05_2_Merged_(1).jpg)'
- en: 'a: A bicycle with a person b: A bicycle without a person'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 'a: 有人的自行车 b: 无人的自行车'
- en: Figure 5.2 – A comparison of two images with regards to the contour height
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – 关于轮廓高度的两种图像的比较
- en: Here, the contour height of a person riding a bicycle in an image (*Figure 5**.2a*)
    is greater than the contour height of the image of a bicycle without a person
    (*Figure 5**.2b*).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，图像中骑自行车的轮廓高度（*图5**.2a*）大于无人的自行车图像的轮廓高度（*图5**.2b*）。
- en: 'Let us use the Python library CV2 Canny edge detector to detect the maximum
    contour height for the given image as, follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Python库CV2 Canny边缘检测器来检测给定图像的最大轮廓高度，如下所示：
- en: '[PRE8]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This function takes an image as input and returns the maximum contour height,
    found using the Canny edge detector:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数接受一个图像作为输入，并返回使用Canny边缘检测器找到的最大轮廓高度：
- en: '[PRE9]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Here, Python functions are used to find the contour height of the images. As
    seen in the images, the results show that the contour height of the person riding
    a bicycle image is greater than the contour height of the bicycle image. So, we
    can classify these two images by using a certain threshold value for the contour
    height, and if that is greater than that threshold value, then we classify the
    images as a bicycle with a person; otherwise, if the contour height is less than
    that threshold value, we classify those images as just showing a bicycle.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，使用Python函数来找到图像的轮廓高度。如图像所示，结果显示骑自行车的图像的轮廓高度大于无人的自行车图像的轮廓高度。因此，我们可以通过使用轮廓高度的某个阈值来对这些图像进行分类；如果大于该阈值，则将这些图像分类为带人的自行车；否则，如果轮廓高度小于该阈值，则将这些图像分类为仅显示自行车。
- en: As shown in the preceding LF, (we learned about labeling functions in [*Chapter
    2*](B18944_02.xhtml#_idTextAnchor043)) we can automate such image classification
    and object detection tasks using Python, and label the images as either a man
    riding a bicycle or just a bicycle.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述的LF所示，（我们在[*第二章*](B18944_02.xhtml#_idTextAnchor043)中学习了标签函数）我们可以使用Python自动化此类图像分类和对象检测任务，并将图像标记为骑自行车的男子或仅自行车。
- en: The complete code to find the contour height of the preceding two images is
    on GitHub.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 查找前两个图像轮廓高度的全部代码在GitHub上。
- en: By using a diverse set of LFs that capture different aspects of the image content,
    we can increase the likelihood that at least some of the functions will provide
    a useful way to distinguish between images that depict a bicycle, a bicycle with
    a person, or neither. The probabilistic label generated by the majority label
    voter model will then reflect the combined evidence provided by all of the LFs,
    and it can be used to make a more accurate classification decision.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用一组多样化的 LFs 来捕捉图像内容的各个方面，我们可以增加至少一些函数将提供一种有用的方式来区分描绘自行车的图像、带有人的自行车的图像或两者都不是的图像的可能性。然后，由多数投票模型生成的概率标签将反映所有
    LFs 提供的联合证据，并且可以用来做出更准确的分类决策。
- en: Example 2 – image classification – dog and cat images
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 2 – 图像分类 – 狗和猫图像
- en: Let us see another example of labeling images to classify dog or cat images,
    based on rules associated with properties.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看另一个基于属性相关规则的图像标记示例，用于分类狗或猫图像。
- en: The following are some rules to implement as LFs to detect images of dogs, based
    on pointy ears and snouts, the shape of the eyes, fur texture, and the shape of
    the body, as well as additional LFs to detect other features. The complete code
    for these functions is available on GitHub.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些规则，作为 LFs 来检测狗的图像，基于尖耳朵和鼻子的形状、眼睛的形状、毛发纹理和身体形状，以及检测其他特征的附加 LFs。这些函数的完整代码可在
    GitHub 上找到。
- en: '**Labeling function 1**: The rule is, if the image has pointy ears and a snout,
    label it as a dog:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**标签函数 1**：规则是，如果图像有尖耳朵和鼻子的形状，则将其标记为狗：'
- en: '[PRE10]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**Labeling function 2**: The rule is, if the image has oval-shaped eyes, label
    it as a cat:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**标签函数 2**：规则是，如果图像有椭圆形的眼睛，则将其标记为猫：'
- en: '[PRE11]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**Labeling function 3**: The rule is, if the image has a texture with high
    variance, label it as a dog:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**标签函数 3**：规则是，如果图像具有高方差的纹理，则将其标记为狗：'
- en: '[PRE12]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Labeling function 4**: The rule is, if the aspect ratio is close to 1 (indicating
    a more circular shape), label it as a cat:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**标签函数 4**：规则是，如果长宽比接近 1（表示更圆形的形状），则将其标记为猫：'
- en: '[PRE13]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `dog_features` LF looks for the presence of pointy ears and snouts in the
    image by examining specific regions of the blue channel. The `cat_features` LF
    looks for the presence of oval-shaped eyes in the green channel. The `dog_fur_texture`
    LF looks for high variance in the grayscale version of the image, which is often
    associated with dog fur texture. The `cat_body_shape` LF looks for a circular
    body shape in the image, which is often associated with cats.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`dog_features` LF 通过检查蓝色通道的特定区域来寻找图像中尖耳朵和鼻子的存在。`cat_features` LF 在绿色通道中寻找椭圆形眼睛的存在。`dog_fur_texture`
    LF 在图像的灰度版本中寻找高方差，这通常与狗的毛发纹理相关。`cat_body_shape` LF 在图像中寻找圆形的身体形状，这通常与猫相关。'
- en: These LFs could be combined with Snorkel to create a model and label the images.
    In the next section, let us see how we can apply labels using transfer learning.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 LFs 可以与 Snorkel 结合起来创建模型并标记图像。在下一节中，我们将看看如何使用迁移学习应用标签。
- en: Labeling images using transfer learning
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用迁移学习进行图像标记
- en: 'Transfer learning is a machine learning technique where a model trained on
    one task is adapted for a second related task. Instead of starting the learning
    process from scratch, transfer learning leverages knowledge gained from solving
    one problem and applies it to a different but related problem. This approach has
    become increasingly popular in deep learning and has several advantages:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是一种机器学习技术，其中在一个任务上训练的模型被调整用于第二个相关任务。而不是从头开始学习过程，迁移学习利用解决一个问题的知识，并将其应用于不同但相关的问题。这种方法在深度学习中变得越来越流行，并且具有几个优点：
- en: '**Faster training**: Transfer learning can significantly reduce the time and
    computational resources required to train a model. Instead of training a deep
    neural network from random initialization, you start with a pre-trained model,
    which already has learned features and representations.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更快的学习**：迁移学习可以显著减少训练模型所需的时间和计算资源。与其从随机初始化开始训练深度神经网络，你从已经学习到特征和表示的预训练模型开始。'
- en: '**Better generalization**: Models pre-trained on large datasets, such as ImageNet
    for image recognition, have learned general features that are useful for various
    related tasks. These features tend to generalize well to new tasks, leading to
    better performance.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更好的泛化**：在大型数据集上预训练的模型，如用于图像识别的 ImageNet，已经学习到了对各种相关任务有用的通用特征。这些特征往往很好地泛化到新任务中，从而提高了性能。'
- en: '**Lower data requirements**: Transfer learning can be especially beneficial
    when you have a limited amount of data for your target task. Pre-trained models
    can provide a head start, enabling effective learning with smaller datasets.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降低数据需求**：当您为您的目标任务有限的数据时，迁移学习特别有益。预训练模型可以提供一个起点，使使用较小的数据集进行有效学习成为可能。'
- en: '**Domain adaptation**: Transfer learning helps adapt models from one domain
    (e.g., natural images) to another (e.g., medical images). This is valuable when
    collecting data in the target domain is challenging.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域自适应**：迁移学习有助于将模型从一个领域（例如自然图像）迁移到另一个领域（例如医学图像）。当在目标领域收集数据具有挑战性时，这非常有价值。'
- en: Let us see an example of Python code to detect digits in handwritten MNIST images,
    using Snorkel LFs.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个使用 Snorkel LFs 检测手写 MNIST 图像中数字的 Python 代码示例。
- en: Example – digit classification using a pre-trained classifier
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 – 使用预训练分类器进行数字分类
- en: In this example, we will first load the MNIST dataset, using Keras, and then
    define an LF that uses a digit classification model to classify the digits in
    each image. We then load the MNIST images into a Snorkel dataset and apply the
    LF to generate labels for the specified digit. Finally, we visualize the labels
    using Snorkel’s viewer.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们首先使用 Keras 加载 MNIST 数据集，然后定义一个使用数字分类模型对每个图像中的数字进行分类的 LF。然后我们将 MNIST
    图像加载到 Snorkel 数据集中，并应用 LF 为指定的数字生成标签。最后，我们使用 Snorkel 的查看器可视化标签。
- en: 'Note that, in this example, we assume that you have already trained a digit
    classification model and saved it as a file named `digit_classifier.h5`. You can
    replace this with any other model of your choice. Also, make sure to provide the
    correct path to the model file. Finally, the labels generated by the LF will be
    `1` if the image has the specified digit, and `-1` if it doesn’t have it:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这个例子中，我们假设您已经训练了一个数字分类模型并将其保存为名为 `digit_classifier.h5` 的文件。您可以将其替换为您选择的任何其他模型。同时，请确保提供模型文件的正确路径。最后，LF
    生成的标签将是 `1` 如果图像具有指定的数字，否则是 `-1`：
- en: '[PRE14]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this block, TensorFlow is imported, along with specific modules needed to
    work with the MNIST dataset and pre-trained models.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在此块中，导入了 TensorFlow 以及与 MNIST 数据集和预训练模型一起工作的特定模块。
- en: 'The MNIST dataset is loaded into two sets – `x_test` contains the images, and
    `y_test` contains the corresponding labels. The training set is not used in this
    snippet:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST 数据集被加载到两个集合中 - `x_test` 包含图像，而 `y_test` 包含相应的标签。训练集在此代码片段中未使用：
- en: '[PRE15]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'A pre-trained model is loaded using the `load_model` function. Ensure to replace
    `mnist_model.h5` with the correct path to your pre-trained model file:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `load_model` 函数加载预训练模型。确保将 `mnist_model.h5` 替换为您的预训练模型文件的正确路径：
- en: '[PRE16]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The pixel values of the images are normalized to be in the range [0, 1] by
    converting the data type to `float32` and dividing by 255:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图像的像素值通过将数据类型转换为 `float32` 并除以 255 来归一化，使其位于 [0, 1] 范围内：
- en: '[PRE17]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The images are reshaped to match the input shape expected by the model, which
    is (`batch_size`, `height`, `width`, and `channels`):'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '图像被重塑以匹配模型期望的输入形状，即 (`batch_size`, `height`, `width`, 和 `channels`):'
- en: '[PRE18]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Predictions are made on the test dataset using the pre-trained model, and the
    predictions for the first image are printed:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预训练模型在测试数据集上做出预测，并打印出第一张图像的预测结果：
- en: '[PRE19]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Class labels for the MNIST digits (0–9) are created as strings and printed:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST 数字（0-9）的类别标签被创建为字符串并打印：
- en: '[PRE20]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The script iterates through the test dataset, printing the index of the maximum
    prediction value, the predicted digit, and the actual digit label for each image:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本遍历测试数据集，打印出每个图像的最大预测值索引、预测数字和实际数字标签：
- en: '[PRE21]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Here is the output:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '![Figure 5.3 – The output of digital classification](img/B18944_05_3.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.3 – 数字分类的输出](img/B18944_05_3.jpg)'
- en: Figure 5.3 – The output of digital classification
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 – 数字分类的输出
- en: Let us see another example of defining rules using a pre-trained classifier
    for image labeling. In the following example, we will use a pre-trained model,
    YOLO V3, to detect a person in the image, and then we will apply an LF to label
    the large set of image data.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看看另一个使用预训练分类器定义规则的示例。在下面的示例中，我们将使用预训练模型 YOLO V3 来检测图像中的人，然后我们将应用一个 LF 来标记大量图像数据。
- en: Example – person image detection using the YOLO V3 pre-trained classifier
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 – 使用 YOLO V3 预训练分类器进行人员图像检测
- en: 'Let’s get started with the code:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始编写代码：
- en: '[PRE22]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The predefined YOLO model and weights are open source and can be downloaded
    at [https://pjreddie.com/darknet/yolo](https://pjreddie.com/darknet/yolo):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 预定义的YOLO模型和权重是开源的，可以在[https://pjreddie.com/darknet/yolo](https://pjreddie.com/darknet/yolo)下载：
- en: '[PRE23]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: In this code, we use OpenCV to load the YOLO V3 model, its weights, and its
    configuration files. Then, we provide an input image, run a forward pass through
    the network, and process the detection results.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中，我们使用OpenCV加载YOLO V3模型、其权重和配置文件。然后，我们提供一个输入图像，通过网络进行前向传递，并处理检测结果。
- en: You’ll need to replace `"path/to/yolov3.cfg"`, `"path/to/coco.names"`, and `"path/to/image.jpg"`
    with the actual paths to your YOLOv3 configuration file, the class names file,
    and the image that you want to perform object detection on.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要将 `"path/to/yolov3.cfg"`、`"path/to/coco.names"` 和 `"path/to/image.jpg"` 替换为你的YOLOv3配置文件、类别名称文件和你要进行对象检测的图像的实际路径。
- en: Remember that YOLO V3 is a complex deep learning model designed for real-time
    object detection, and using it effectively often requires some knowledge of computer
    vision and deep learning concepts.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，YOLO V3是一个复杂的深度学习模型，旨在进行实时对象检测，有效地使用它通常需要一些计算机视觉和深度学习概念的知识。
- en: Example – bicycle image detection using the YOLO V3 pre-trained classifier
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 - 使用YOLO V3预训练分类器检测自行车图像
- en: 'The following is the code for this example:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是这个示例的代码：
- en: '[PRE24]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In summary, the code snippet utilizes a pre-trained Faster R-CNN model to perform
    object detection on an input image. It resizes the image, converts it to a tensor,
    and then extracts and processes the detection results. To specifically detect
    bicycles, you would need to filter the results based on the class labels provided
    by the model and check for the presence of bicycles in the detected objects.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，代码片段利用预训练的Faster R-CNN模型在输入图像上执行对象检测。它调整图像大小，将其转换为张量，然后提取并处理检测结果。要特别检测自行车，你需要根据模型提供的类别标签过滤结果，并检查检测到的对象中是否存在自行车。
- en: Now, let us explore how we can apply transformations on a given image dataset
    to generate additional synthetic data. Additional synthetic data helps in training
    and achieving more accurate results, as a model will learn about different positions
    of images.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探索如何将变换应用于给定的图像数据集以生成额外的合成数据。额外的合成数据有助于训练并实现更准确的结果，因为模型将学习图像的不同位置。
- en: Labeling images using transformations
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用变换标记图像
- en: In this section, let us see the different types of transformations that can
    be applied to images to generate synthetic data when there is a limited amount
    of data. In machine learning, shearing and flipping are often used as image augmentation
    techniques to increase the diversity of training data. It helps improve a model’s
    ability to recognize objects from different angles or orientations.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，让我们看看可以应用于图像的不同类型的变换，以在数据有限的情况下生成合成数据。在机器学习中，剪切和翻转通常用作图像增强技术，以增加训练数据的多样性。它有助于提高模型识别不同角度或方向的物体的能力。
- en: Shearing can be used in computer vision tasks to correct for perspective distortion
    in images. For example, it can be applied to rectify skewed text in scanned documents.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 剪切可以在计算机视觉任务中用于纠正图像中的透视失真。例如，它可以应用于校正扫描文档中倾斜的文本。
- en: '**Image shearing** is a transformation that distorts an image by moving its
    pixels in a specific direction. It involves shifting the pixels of an image along
    one of its axes while keeping the other axis unchanged. There are two primary
    types of shearing:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**图像剪切**是一种通过将像素移动到特定方向来扭曲图像的变换。它涉及沿图像的一个轴移动图像的像素，同时保持另一个轴不变。主要有两种剪切类型：'
- en: '**Horizontal shearing**: In this case, pixels are shifted horizontally, usually
    in a diagonal manner, causing an image to slant left or right'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**水平剪切**：在这种情况下，像素在水平方向上移动，通常以对角线方式移动，导致图像向左或向右倾斜'
- en: '**Vertical shearing**: Here, pixels are shifted vertically, causing an image
    to slant up or down'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垂直剪切**：在这里，像素在垂直方向上移动，导致图像向上或向下倾斜'
- en: To perform image shearing, you typically specify the amount of shear (the extent
    of distortion) and the direction (horizontal or vertical). The amount of shear
    is usually defined as a shear angle or shear factor.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行图像剪切，你通常指定剪切量（失真程度）和方向（水平或垂直）。剪切量通常定义为剪切角度或剪切因子。
- en: 'Image shearing is typically accomplished using a shear matrix. For example,
    in 2D computer graphics, a horizontal shear matrix might look like this:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图像剪切通常使用剪切矩阵来完成。例如，在2D计算机图形学中，一个水平剪切矩阵可能看起来像这样：
- en: '[PRE25]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Here, `shear_x` represents the amount of horizontal shearing applied.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`shear_x`表示应用的横向剪切量。
- en: By applying a random shearing transformation to an image, we can generate multiple
    versions of the image with slightly different pixel values. These variations can
    provide a useful way to identify visual patterns or features that are characteristic
    of an object.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对一个图像应用随机的剪切变换，我们可以生成具有略微不同像素值的多个图像版本。这些变化可以提供一种有用的方法来识别对象的特征性视觉模式或特征。
- en: Similarly, **image flipping** is another transformation that can be useful to
    identify flowers. By flipping an image horizontally or vertically, we can generate
    new versions of an image that may contain different visual patterns or features.
    For example, we could use an LF that checks whether an image is flipped along
    a certain axis, labeling images that are flipped as positively depicting flowers.
    This LF would be able to capture the fact that many flowers have bilateral symmetry,
    meaning that they look similar when mirrored along a particular axis.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，**图像翻转**是另一种可以用于识别花朵的变换。通过水平或垂直翻转图像，我们可以生成包含不同视觉模式或特征的新图像版本。例如，我们可以使用一个检查图像是否沿某一轴翻转的LF，将翻转的图像标注为正面描绘花朵。这个LF能够捕捉到许多花朵具有双边对称性的事实，这意味着它们沿特定轴翻转时看起来相似。
- en: Overall, by applying image transformations such as shearing or flipping, we
    can generate a larger number of labeled examples that capture different aspects
    of the image content. This can help to increase the accuracy of the classification
    model by providing more varied and robust training data.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，通过应用剪切或翻转等图像变换，我们可以生成更多标记的示例，这些示例可以捕捉到图像内容的各个方面。这有助于通过提供更多样化和稳健的训练数据来提高分类模型的准确性。
- en: We will further explore image transformation along with other data augmentation
    techniques and examples in the next chapter.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章进一步探讨图像变换以及其他数据增强技术和示例。
- en: Summary
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we embarked on an enlightening journey into the world of image
    labeling and classification. We began by mastering the art of creating labeling
    rules through manual inspection, tapping into the extensive capabilities of Python.
    This newfound skill empowers us to translate visual intuition into valuable data,
    a crucial asset in the realm of machine learning.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们开始了对图像标注和分类世界的启发之旅。我们首先通过手动检查掌握创建标注规则的艺术，利用Python的广泛功能。这项新技能使我们能够将视觉直觉转化为有价值的数据，这在机器学习的领域中是一种关键资产。
- en: As we delved deeper, we explored the intricacies of size, aspect ratio, bounding
    boxes, and polygon and polyline annotations. We learned how to craft labeling
    rules based on these quantitative image characteristics, ushering in a systematic
    and dependable approach to data labeling.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们进一步深入，我们探索了大小、宽高比、边界框和多边形及折线标注的复杂性。我们学习了如何根据这些定量图像特征制定标注规则，从而引入了一种系统化和可靠的标注方法。
- en: Our exploration extended to the transformative realm of image manipulation.
    We harnessed the potential of image transformations such as shearing and flipping,
    enhancing our labeling process with dynamic versatility.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的探索扩展到了图像处理的变革领域。我们利用了剪切和翻转等图像变换的潜力，通过动态灵活性增强了我们的标注过程。
- en: Furthermore, we applied our knowledge to real-world scenarios, classifying plant
    disease images using rule-based LFs. We honed our skills in predicting objects
    by leveraging aspect ratio and contour height, a valuable asset in scenarios such
    as identifying a person riding a bicycle. Additionally, we delved into the powerful
    domain of pre-trained models and transfer learning for image classification.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将我们的知识应用于现实世界的场景，通过基于规则的LF对植物病害图像进行分类。我们通过利用宽高比和轮廓高度来预测对象，提高了我们的技能，这在识别骑自行车的人等场景中是一种宝贵的资产。此外，我们还深入研究了预训练模型和迁移学习在图像分类中的强大领域。
- en: But our journey is far from over. In the upcoming chapter, we will dive even
    deeper into the realm of image data augmentation. We’ll explore advanced techniques
    and learn how to perform image classification using augmented data with **support
    vector machines** (**SVMs**) and **convolutional neural networks** (**CNNs**).
    Get ready for the next exciting chapter!
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们的旅程远未结束。在接下来的章节中，我们将更深入地探索图像数据增强的领域。我们将探讨高级技术，并学习如何使用增强数据通过**支持向量机**（**SVMs**）和**卷积神经网络**（**CNNs**）进行图像分类。准备好迎接下一章的精彩内容吧！
