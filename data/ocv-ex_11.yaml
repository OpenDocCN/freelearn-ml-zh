- en: Chapter 11. Text Recognition with Tesseract
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 11 章。使用 Tesseract 进行文本识别
- en: In the previous chapter, we covered the very basic OCR processing functions.
    Although they are quite useful for scanned or photographed documents, they are
    almost useless when dealing with text that casually appears in a picture.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了非常基本的 OCR 处理功能。虽然它们对于扫描或拍摄的文档非常有用，但当处理随意出现在图片中的文本时，它们几乎毫无用处。
- en: In this chapter, we'll explore the OpenCV 3.0 text module, which deals specifically
    with scene text detection. Using this API, it is possible to detect text that
    appears in a webcam video, or to analyze photographed images (like the ones in
    Street View or taken by a surveillance camera) to extract text information in
    real time. This allows a wide range of applications to be created, from accessibility
    to marketing and even robotics fields.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨 OpenCV 3.0 文本模块，该模块专门处理场景文本检测。使用此 API，可以检测出现在网络摄像头视频中的文本，或者分析照片图像（如街景或监控摄像头拍摄的图像）以实时提取文本信息。这允许创建从无障碍到营销甚至机器人领域的广泛应用。
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Understand what is scene text recognition
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解场景文本识别是什么
- en: Understand how the text API works
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解文本 API 的工作原理
- en: Use the OpenCV 3.0 text API to detect text
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OpenCV 3.0 文本 API 检测文本
- en: Extract the detected text to an image
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将检测到的文本提取到图像中
- en: Use the text API and Tesseract integration to identify letters
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用文本 API 和 Tesseract 集成来识别字母
- en: How the text API works
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本 API 的工作原理
- en: The text API implements the algorithm proposed by Lukás Neumann and Jiri Matas
    in the article called *Real-Time Scene Text Localization and Recognition* during
    the **CVPR** (**Computer Vision and Pattern Recognition)** Conference in 2012\.
    This algorithm represented a significant increase in scene text detection, performing
    the state-of-the art detection both in the CVPR database as well as in the Google
    Street View database.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 文本 API 实现了 Lukás Neumann 和 Jiri Matas 在 2012 年 CVPR（**计算机视觉和模式识别**）会议期间发表的名为
    *Real-Time Scene Text Localization and Recognition* 的文章中提出的算法。该算法在 CVPR 数据库以及
    Google Street View 数据库中都实现了场景文本检测的重大突破。
- en: Before we use the API, let's take a look at how this algorithm works under the
    hood, and how it addresses the scene text detection problem.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们使用 API 之前，让我们看看这个算法在底层是如何工作的，以及它是如何解决场景文本检测问题的。
- en: Note
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Remember** that the OpenCV 3.0 text API does not come with the standard OpenCV
    modules. It''s an additional module present in the OpenCV contribute package.
    If you need to install OpenCV using the Windows Installer, refer to [Chapter 1](ch01.html
    "Chapter 1. Getting Started with OpenCV"), *Getting Started with OpenCV*, which
    will help you install these modules.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**记住**，OpenCV 3.0 文本 API 不包含在标准 OpenCV 模块中。它是一个存在于 OpenCV 贡献包中的附加模块。如果你需要使用
    Windows 安装程序安装 OpenCV，请参阅[第 1 章](ch01.html "第 1 章。OpenCV 入门")，*OpenCV 入门*，这将帮助你安装这些模块。'
- en: The scene detection problem
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景检测问题
- en: 'Detecting text that randomly appears in a scene is a problem harder than it
    looks. There are several new variables when we compare them to identify scanned
    text, which are as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在场景中检测随机出现的文本是一个比看起来更难的问题。当我们将其与识别扫描文本进行比较时，有几个新的变量，如下所示：
- en: '**Tri-dimensionality**: The text can be in any scale, orientation, or perspective.
    Also, the text can be partially occluded or interrupted. There are literally thousands
    of possible regions where it can appear in the image.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**三维性**：文本可以以任何比例、方向或视角出现。此外，文本可能部分被遮挡或中断。实际上有成千上万的可能性，文本可以出现在图像中的任何区域。'
- en: '**Variety**: Text can be in several different fonts and colors. The font can
    have outline borders or not. The background can be a dark, light, or a complex
    image.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多样性**：文本可以以几种不同的字体和颜色出现。字体可以有轮廓边框或没有。背景可以是深色、浅色或复杂的图像。'
- en: '**Illumination and shadows**: The sunlight position and apparent color changes
    over the time. Different weather conditions such as fog or rain can generate noise.
    Illumination can be a problem even in closed spaces, since light reflects over
    colored objects and hits the text.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**光照与阴影**：阳光的位置和外观颜色会随时间变化。不同的天气条件，如雾或雨，可以产生噪声。即使在封闭空间中，光照也可能成为问题，因为光线会在彩色物体上反射并击中文本。'
- en: '**Blurring**: Text can appear in a region that is not prioritized by the auto
    focus lenses. Blurring is also common in moving cameras, in perspective text,
    or in the presence of fog.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模糊**：文本可能出现在自动对焦镜头不优先考虑的区域。在移动相机、透视文本或雾的存在下，模糊也很常见。'
- en: 'The following image, taken from Google Street View, illustrates these problems.
    Notice how several of these situations occur simultaneously in just a single image:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像来自谷歌街景，说明了这些问题。注意这些情况如何在单张图像中同时发生：
- en: '![The scene detection problem](img/B04283_11_01.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![场景检测问题](img/B04283_11_01.jpg)'
- en: Performing a text detection to deal with such situations may prove computationally
    expensive, since there are *2n* subsets of pixels where the text can be, *n* being
    the number of pixels in the image.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 执行文本检测以处理这种情况可能会证明计算成本很高，因为文本可以位于图像中像素的 *2n* 个子集中，其中 *n* 是图像中的像素数。
- en: 'In order to reduce the complexity, two strategies are commonly applied, which
    are as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了降低复杂性，通常采用两种策略，具体如下：
- en: Use a sliding window to search a subset of image rectangles. This strategy just
    reduces the number of subsets to a smaller amount. The amount of regions varies
    according to the complexity of text being considered. Algorithms that deal just
    with text rotation can use small values, as compared to the ones that also deal
    with rotation, skewing, perspective, and so on. The advantage of this approach
    is its simplicity, but it is usually limited to a narrow range of fonts, and often,
    to a lexicon of specific words.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用滑动窗口搜索图像矩形的子集。这种策略只是将子集的数量减少到更小的数量。区域的数量根据考虑的文本复杂性而变化。仅处理文本旋转的算法可以使用较小的值，而同时处理旋转、倾斜、透视等的算法则需要较大的值。这种方法的优点在于其简单性，但它通常局限于较窄的字体范围，并且通常局限于特定单词的词汇表。
- en: Use of the connected component analysis. This approach assumes that pixels can
    be grouped into regions where pixels have similar properties. These regions are
    supposed to have higher chances of being identified as characters. The advantage
    of this approach is that it does not depend on several text properties (orientation,
    scale, and fonts), and they also provide a segmentation region that can be used
    to crop text to the OCR. This was the approach used in the previous chapter.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用连通分量分析。这种方法假设像素可以被分组到具有相似属性的区域内。这些区域更有可能被识别为字符。这种方法的优点是它不依赖于多个文本属性（方向、缩放和字体），并且它们还提供了一个可以用于裁剪文本到OCR的分割区域。这是前一章中使用的方法。
- en: The OpenCV 3.0 algorithm uses the second one by performing the connected component
    analysis and searching for extremal regions.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV 3.0 算法通过执行连通分量分析和搜索极值区域来使用第二种策略。
- en: Extremal regions
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 极值区域
- en: 'Extremal regions are connected areas that are characterized by uniform intensity
    and surrounded by a contrast background. The stability of a region can be measured
    by calculating how resistant the region is to the thresholding variance. This
    variance can be measured with a simple algorithm:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 极值区域是由均匀强度特征和周围对比度背景所包围的连通区域。可以通过计算区域对阈值变化的抵抗程度来衡量区域稳定性。这种变化可以通过一个简单的算法来测量：
- en: Applying the threshold generates an image A. Detect its connected pixel regions
    (extremal regions).
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用阈值生成图像A。检测其连通像素区域（极值区域）。
- en: Increasing the threshold by a delta amount generates an image B. Detect its
    connected pixel regions (extremal regions).
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过增加一个阈值增量生成图像B。检测其连通像素区域（极值区域）。
- en: Compare image B with A. If a region in image A is similar to the same region
    in image B, then add it to the same branch in the tree. The criteria of similarity
    may vary from implementation to implementation, but it's usually related to the
    image area or general shape. If a region in image A appears to be split in image
    B, create two new branches in the tree for the new regions, and associate them
    with the previous branch.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像B与A进行比较。如果图像A中的某个区域与图像B中相同的区域相似，则将其添加到树中的同一分支。相似性的标准可能因实现而异，但通常与图像面积或一般形状有关。如果图像A中的某个区域在图像B中看起来被分割，则在树中为新的区域创建两个新的分支，并将它们与之前的分支关联。
- en: Set *A = B* and go back to step 2, until a maximum threshold is applied.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 *A = B* 并回到步骤2，直到应用最大阈值。
- en: 'This will assemble a tree of regions, as shown in the following figure:'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将组装一个区域树，如图所示：
- en: '![Extremal regions](img/B04283_11_02.jpg)'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![极值区域](img/B04283_11_02.jpg)'
- en: 'Image source: [http://docs.opencv.org/master/da/d56/group__text__detect.html#gsc.tab=0](http://docs.opencv.org/master/da/d56/group__text__detect.html#gsc.tab=0)'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图像来源：[http://docs.opencv.org/master/da/d56/group__text__detect.html#gsc.tab=0](http://docs.opencv.org/master/da/d56/group__text__detect.html#gsc.tab=0)
- en: The resistance to variance is determined by counting the number of nodes that
    are in the same level.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 防变异性是通过计算处于同一级别的节点数量来确定的。
- en: By analyzing this tree, it's also possible to determine the **MSERs** (**Maximally
    Stable Extremal Regions**), that is, the regions where the area remains stable
    in a wide variety of thresholds. In the previous image, it is clear that these
    areas will contain the letters *O*, *N*, and *Y*. The main disadvantage of MSERs
    is that they are weak in the presence of blur. OpenCV provides a MSER feature
    detector in the `feature2d` module.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析这棵树，还可以确定**MSERs（最大稳定极值区域**），即在广泛的各种阈值下区域面积保持稳定的区域。在上一张图像中，很明显这些区域将包含字母*O*、*N*和*Y*。MSERs的主要缺点是它们在模糊存在的情况下较弱。OpenCV在`feature2d`模块中提供了一个MSER特征检测器。
- en: Extremal regions are interesting because they are strongly invariant to illumination,
    scale, and orientation. They are also good candidates for text because they are
    also invariant of the type of font used, even when the font is styled. Each region
    can also be analyzed in order to determine its boundary ellipsis and have properties,
    such as affine transformation and area that can be numerically determined. Finally,
    it's worth mentioning that this entire process is fast, which makes it a very
    good candidate for real-time applications.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 极值区域很有趣，因为它们对光照、尺度和方向具有很强的不变性。它们也是文本的良好候选者，因为它们对字体类型也不敏感，即使字体有样式。每个区域也可以进行分析，以确定其边界椭圆和具有可数值确定的属性，如仿射变换和面积。最后，值得一提的是，整个过程非常快，这使得它非常适合实时应用。
- en: Extremal region filtering
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 极值区域过滤
- en: 'Although MSERs are a common approach to define which extremal regions are worth
    working with, the Neumann and Matas algorithm uses a different approach by submitting
    all extremal regions to a sequential classifier that is trained for character
    detection. This classifier works in the following two different stages:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然MSERs是定义哪些极值区域值得工作的常见方法，但Neumann和Matas算法通过将所有极值区域提交给一个用于字符检测的已训练的顺序分类器来采用不同的方法。这个分类器在以下两个不同的阶段工作：
- en: The first stage incrementally computes descriptors (the bounding box, perimeter,
    area, and Euler number) for each region. These descriptors are submitted to a
    classifier that estimates how probable the region is for it to be a character
    in the alphabet. Then, only the regions of high probability are selected to stage
    2.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一阶段逐步计算每个区域的描述符（边界框、周长、面积和欧拉数）。这些描述符提交给一个分类器，该分类器估计该区域是字母的概率。然后，只选择高概率的区域进入第二阶段。
- en: In this stage, the features of the whole area ratio, convex hull ratio, and
    the number of outer boundary inflexion points are calculated. This provides a
    more detailed information that allows the classifier to discard `nontext` characters,
    but they are also much slower to calculate.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个阶段，计算整个区域比率、凸包比率和外部边界拐点数量。这提供了更详细的信息，使分类器能够丢弃非文本字符，但它们的计算速度也较慢。
- en: In OpenCV, this process is implemented in an `ERFilter` class. It is also possible
    to use different image single-channel projections such as R, G, B, luminance,
    or grayscale conversion to increase the character recognition rates.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中，这个过程在`ERFilter`类中实现。也可以使用不同的图像单通道投影，如R、G、B、亮度或灰度转换，以提高字符识别率。
- en: 'Finally, all the characters must be grouped in text blocks (such as words or
    paragraphs). OpenCV 3.0 provides two algorithms for this purpose:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，所有字符必须分组到文本块中（如单词或段落）。OpenCV 3.0为此提供了两种算法：
- en: '**Prune Exhaustive Search**: This was also proposed by Mattas in 2011\. This
    algorithm does not need any previous training or classification, but is limited
    to a horizontally aligned text.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**剪枝穷举搜索**：这也是Mattas在2011年提出的。这个算法不需要任何先前的训练或分类，但仅限于水平对齐的文本。'
- en: '**Hierarchical Method for Oriented Text**: This deals with texts in any orientation,
    but needs a trained classifier.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**面向文本的分层方法**：这处理任何方向的文本，但需要一个训练好的分类器。'
- en: Note
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Since these operations require classifiers, it is also necessary to provide
    a trained set as an input. OpenCV3.0 provides some of these trained sets in the
    `sample` package. This also means that this algorithm is sensitive to the fonts
    used in classifier training.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些操作需要分类器，因此还需要提供一个训练集作为输入。OpenCV3.0在`sample`包中提供了一些这些训练集。这也意味着这个算法对分类器训练中使用的字体敏感。
- en: A demonstration of this algorithm can be seen in the video provided by Neumann
    at [https://youtu.be/ejd5gGea2Fo](https://youtu.be/ejd5gGea2Fo).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在Neumann提供的视频中看到这个算法的演示：[https://youtu.be/ejd5gGea2Fo](https://youtu.be/ejd5gGea2Fo)。
- en: Once the text is segmented, it just needs to be sent to an OCR, such as Tesseract,
    similar to what we did in the previous chapter. The only difference is that now
    we will use OpenCV text module classes to interact with Tesseract, since they
    provide a way to encapsulate the specific OCR engine we are using.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦文本被分割，只需将其发送到OCR，例如Tesseract，就像我们在上一章中所做的那样。唯一的区别是现在我们将使用OpenCV文本模块类与Tesseract交互，因为它们提供了一种封装我们使用特定OCR引擎的方法。
- en: Using the text API
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用文本API
- en: Enough of theory. It's time to see how the text module works in practice. Let's
    study how to use it to perform text detection, extraction, and identification.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 理论已经足够。现在是时候看看文本模块在实际中的应用了。让我们研究如何使用它来进行文本检测、提取和识别。
- en: Text detection
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本检测
- en: Let's start with creating a simple program to perform text segmentation using
    `ERFilters`. In this program, we will use the trained classifiers from text API
    samples. You can download them from the OpenCV repository, but they are also available
    in the book's companion code.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建一个简单的程序开始，使用`ERFilters`进行文本分割。在这个程序中，我们将使用文本API示例中的训练分类器。您可以从OpenCV仓库中下载它们，但它们也包含在本书的配套代码中。
- en: 'First, we start with including all the necessary `libs` and using:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从包含所有必要的`libs`和使用：
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Recall from our previous section that the `ERFilter` works separately in each
    image channel. So, we must provide a way to separate each desired channel in a
    different single `cv::Mat` channel. This is done by the `separateChannels` function:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 回想我们之前的部分，`ERFilter`在图像的每个通道中单独工作。因此，我们必须提供一种方法，在不同的单个`cv::Mat`通道中分离每个所需的通道。这是通过`separateChannels`函数完成的：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: First, we verify that the image is a single channel image (for example, a grayscale
    image). If that's the case, we just add this image and its negative to be processed.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们验证图像是否是单通道图像（例如，灰度图像）。如果是这样，我们只需添加这个图像及其负图像进行处理。
- en: 'Otherwise, we check whether it''s an RGB image. For colored images, we call
    the `computeNMChannels` to split the image in its several channels. The function
    is defined as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，我们检查它是否是RGB图像。对于彩色图像，我们调用`computeNMChannels`来将图像分割成其多个通道。该函数定义如下：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Its parameters are described as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 其参数描述如下：
- en: '`src`: This is the source input array. It should be a colored image of type
    8UC3.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`src`：这是源输入数组。它应该是一个8UC3类型的彩色图像。'
- en: '`channels`: This is a vector of mats that will be filled with the resulting
    channels.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`channels`：这是一个向量，其中将填充结果通道。'
- en: '`mode`: This defines the channels that will be computed. There are two possible
    values that can be used, which are as follows:'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mode`：这定义了将要计算的通道。可以使用两个可能的值，如下所示：'
- en: '`ERFILTER_NM_RGBLGrad`: This indicates that the algorithm uses an RGB color,
    lightness, and gradient magnitude as channels (default).'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERFILTER_NM_RGBLGrad`：这表示算法使用RGB颜色、亮度和梯度幅度作为通道（默认）。'
- en: '`ERFILTER_NM_IHSGrad`: This indicates that the image will be split by its intensity,
    hue, saturation, and gradient magnitude.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERFILTER_NM_IHSGrad`：这表示图像将通过其强度、色调、饱和度和梯度幅度进行分割。'
- en: We also append the negatives of all color components in the vector. Finally,
    if another kind of image is provided, the function will terminate the program
    with an error message.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在向量中附加了所有颜色成分的负图像。最后，如果提供了另一种类型的图像，函数将使用错误消息终止程序。
- en: Note
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Negatives are appended so the algorithms will cover both bright text on a dark
    background and dark text on a bright background. There is no point in adding a
    negative to the gradient magnitude.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 负图像被附加，以便算法可以覆盖亮背景上的暗文本和亮背景上的暗文本。没有必要将负图像添加到梯度幅度中。
- en: 'Let''s proceed to the `main` method. We''ll use the program to segment the
    `easel.png` image, which is provided with the source code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续到`main`方法。我们将使用程序来分割提供的`easel.png`图像：
- en: '![Text detection](img/B04283_11_03.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![文本检测](img/B04283_11_03.jpg)'
- en: 'This image was taken by a mobile phone camera, while I was walking on the street.
    Let''s code so that you can also use a different image easily by providing its
    name in the first program argument:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这张照片是由手机摄像头拍摄的，当时我正在街上行走。让我们编写代码，以便你可以通过在第一个程序参数中提供其名称来轻松地使用不同的图像：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we''ll convert the image to grayscale and separate its channels by calling
    the `separateChannels` function:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过调用`separateChannels`函数将图像转换为灰度并分离其通道：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If you want to work with all the channels in a colored image, just replace
    the first two lines of the preceding code with the following code:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在彩色图像中处理所有通道，只需将前面代码的前两行替换为以下代码：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will need to analyze six channels (RGB + inverted) instead of two (gray
    + inverted). Actually the processing time will increase much more than the improvements
    that we can `get.With` the channels in hand, we need to create `ERFilters` for
    both the stages of the algorithm. Luckily, the `opencv text` contribution module
    provides functions for this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要分析六个通道（RGB + 反转）而不是两个（灰度 + 反转）。实际上，处理时间将增加得比我们可以通过`get.With`这些通道获得的改进要多得多。有了这些通道在手，我们需要为算法的两个阶段创建`ERFilters`。幸运的是，`opencv
    text`贡献模块提供了相应的函数：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'For the first stage, we call the `loadClassifierNM1` function to load a previously
    trained classification model. The XML containing the training data is its only
    argument. Then, we call `createERFilterNM1` to create an instance of the `ERFilter`
    class that will perform the classification. The function has the following signature:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一阶段，我们调用`loadClassifierNM1`函数来加载一个之前训练好的分类模型。包含训练数据的XML文件是其唯一参数。然后，我们调用`createERFilterNM1`来创建一个`ERFilter`类的实例，该实例将执行分类。该函数具有以下签名：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The parameters are described as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 参数描述如下：
- en: '`cb`: This is the classification model. This is the same model that we loaded
    with the `loadCassifierNM1` function.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cb`：这是分类模型。这是与我们使用`loadCassifierNM1`函数加载的相同模型。'
- en: '`thresholdDelta`: This is the amount to be added to the threshold in each algorithm
    iteration. The default value is *1*, but we''ll use *15* in our example.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`thresholdDelta`：这是在每次算法迭代中要添加到阈值中的量。默认值是*1*，但我们在示例中会使用*15*。'
- en: '`minArea`: This is the minimum area of the ER where text can be found. This
    is measured in *%* of the image size. ERs with areas smaller than this are immediately
    discarded.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minArea`：这是可以找到文本的ER的最小面积。这也在图像大小的*%*中测量。面积小于此的ER将被立即丢弃。'
- en: '`maxArea`: This is the maximum area of the ER where text can be found. This
    is also measured in *%* of the image size. ERs with areas greater than this are
    immediately discarded.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxArea`：这是可以找到文本的ER的最大面积。这也在图像大小的*%*中测量。面积大于此的ER将被立即丢弃。'
- en: '`minProbability`: This is the minimum probability that a region must have to
    be a character in order to remain for the next stage.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minProbability`：这是一个区域必须具有的最小概率，才能被视为字符并保留到下一阶段。'
- en: '`nonMaxSupression`: This indicates that non-maximum suppression will be done
    in each branch probability.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nonMaxSupression`：这表示将在每个分支概率中执行非最大抑制。'
- en: '`minProbabilityDiff`: This is the minimum probability difference between the
    minimum and maximum extreme region.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minProbabilityDiff`：这是最小和最大极值区域之间的最小概率差异。'
- en: The process for the second stage is similar. We call `loadClassifierNM2` to
    load the classifier model for the second stage and `createERFilterNM2` to create
    the second stage classifier. This function only takes the loaded classification
    model and a minimum probability that a region must achieve to be considered a
    character as input parameters.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 第二阶段的处理过程类似。我们调用`loadClassifierNM2`来加载第二阶段的分类器模型，并调用`createERFilterNM2`来创建第二阶段的分类器。此函数仅接受加载的分类模型和一个区域必须达到的最小概率作为输入参数。
- en: 'So, let''s call these algorithms in each channel to identify all possible text
    regions:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们在每个通道中调用这些算法以识别所有可能的文本区域：
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the previous code, we used the `run` function of the `ERFilter` class. This
    function takes the following two arguments:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用了`ERFilter`类的`run`函数。此函数接受以下两个参数：
- en: '**The input channel**: This is the image to be processed.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入通道**：这是要处理的图像。'
- en: '**The regions**: In the first stage algorithm, this argument will be filled
    with the detected regions. In the second stage (performed by `filter2`), this
    argument must contain the regions selected in stage 1, which will be processed
    and filtered by stage 2.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**区域**：在第一阶段算法中，此参数将被填充为检测到的区域。在第二阶段（由`filter2`执行），此参数必须包含第一阶段中选择的区域，这些区域将在第二阶段进行处理和过滤。'
- en: Finally, we release both the filters, since they will not be needed anymore
    in the program.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们释放了这两个过滤器，因为程序中不再需要它们。
- en: 'The final segmentation step is to group all `ERRegions` into possible words
    and define their bounding boxes. This is done by calling the `erGrouping` function:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的分割步骤是将所有`ERRegions`分组到可能的单词中，并定义它们的边界框。这是通过调用`erGrouping`函数来完成的：
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This function has the following signature:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数具有以下签名：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s take a look at the definition of each parameter:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看每个参数的定义：
- en: '`img`: This is the original input image. You can refer to the following observations.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`img`：这是原始输入图像。你可以参考以下观察。'
- en: '`regions`: This is a vector of single-channel images where regions are extracted.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regions`：这是一个包含提取区域的单通道图像的向量。'
- en: '`groups`: This is an output vector of indexes of grouped regions. Each group
    region contains all extremal regions of a single word.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groups`：这是一个包含分组区域索引的输出向量。每个分组区域包含一个单词的所有极值区域。'
- en: '`groupRects`: This is a list of rectangles with the detected text regions.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupRects`：这是一个包含检测到的文本区域的矩形列表。'
- en: '`method`: This is a method of grouping. It can be as follows:'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`method`：这是分组的方法。它可以如下所示：'
- en: '`ERGROUPING_ORIENTATION_HORIZ`: This is the default value. This only generates
    groups with horizontally oriented text by performing an exhaustive search, as
    proposed originally by Neumann and Matas.'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERGROUPING_ORIENTATION_HORIZ`：这是默认值。它通过执行穷举搜索来仅生成水平方向的文本组，正如Neumann和Matas最初提出的那样。'
- en: '`ERGROUPING_ORIENTATION_ANY`: This generates groups with text in any orientation,
    using **Single Linkage Clustering** and **classifiers**. If you use this method,
    the filename of the classifier model must be provided in the next parameter.'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERGROUPING_ORIENTATION_ANY`：这会生成任何方向的文本组，使用**单链接聚类**和**分类器**。如果你使用这种方法，必须在下一个参数中提供分类器模型的文件名。'
- en: '`Filename`: This is the name of the classifier model. It is only needed if
    `ERGROUPING_ORIENTATION_ANY` is selected.'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Filename`：这是分类器模型的名称。只有在选择`ERGROUPING_ORIENTATION_ANY`时才需要。'
- en: '`minProbability`: This is the minimum detected probability of accepting a group.
    Also, it is only needed if the `ERGROUPING_ORIENTATION_ANY` is used.'
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minProbability`：这是接受一个组的最低检测概率。它也只有在使用`ERGROUPING_ORIENTATION_ANY`时才需要。'
- en: 'The code also provides a call to the second method, but it''s commented. You
    can switch between the two to test it. Just comment the previous call and uncomment
    this one:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 代码还提供了一个对第二个方法的调用，但它是注释掉的。你可以在这两个之间切换以测试它。只需注释掉上一个调用并取消注释这个调用：
- en: '[PRE11]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: For this call, we also used the default trained classifier provided in the text
    module sample package.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个调用，我们还使用了文本模块示例包中提供的默认训练好的分类器。
- en: 'Finally, we draw the region boxes and show the results:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们绘制区域框并显示结果：
- en: '[PRE12]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output of the program is shown in the following image:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的输出如下所示：
- en: '![Text detection](img/B04283_11_04.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![文本检测](img/B04283_11_04.jpg)'
- en: You can check the complete source code in the `detection.cpp` file.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在`detection.cpp`文件中查看完整的源代码。
- en: Note
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: While most OpenCV text module functions are written to support both grayscale
    and colored images as their input parameters, by the time this book was written,
    there were bugs that prevented using grayscale images in functions, such as erGrouping;
    for instance. Refer to [https://github.com/Itseez/opencv_contrib/issues/309](https://github.com/Itseez/opencv_contrib/issues/309).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数OpenCV文本模块函数都编写为支持灰度和彩色图像作为它们的输入参数，但在本书编写时，存在一些错误阻止了在诸如erGrouping之类的函数中使用灰度图像；例如。请参阅[https://github.com/Itseez/opencv_contrib/issues/309](https://github.com/Itseez/opencv_contrib/issues/309)。
- en: Always remember that the OpenCV contribute modules package is not as stable
    as the default `opencv` packages.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 总是记住，OpenCV贡献模块包不如默认的`opencv`包稳定。
- en: Text extraction
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本提取
- en: 'Now that we detected the regions, we must crop the text before we submit it
    to the OCR. We can simply use a function such as `getRectSubpix` or `Mat::copy`
    using each region rectangle as a **ROI** (**region of interest**), but since the
    letters are skewed, some undesired text may be cropped as well; for instance,
    this is what one of the regions will look like if we just extract the ROI based
    in its given rectangle:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经检测到了区域，在提交给OCR之前，我们必须裁剪文本。我们可以简单地使用一个函数，例如`getRectSubpix`或`Mat::copy`，使用每个区域矩形作为**ROI**（**感兴趣区域**），但由于字母是倾斜的，一些不需要的文本也可能被裁剪掉；例如，如果我们仅仅基于给定的矩形提取ROI，这个区域将看起来像这样：
- en: '![Text extraction](img/B04283_11_05.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![文本提取](img/B04283_11_05.jpg)'
- en: 'Fortunately, the `ERFilter` provides us with an object called `ERStat`, which
    contains pixels inside each extremal region. With these pixels, we can use the
    OpenCV `floodFill` function to reconstruct each letter. This function is capable
    of painting similar colored pixels based in a seed point, just like the `bucket`
    tool of most drawing applications. This is what the function signature looks like:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，`ERFilter`为我们提供了一个名为`ERStat`的对象，它包含每个极值区域内的像素。使用这些像素，我们可以使用OpenCV的`floodFill`函数来重建每个字母。这个函数能够根据种子点绘制类似颜色的像素，就像大多数绘图应用程序的“桶”工具一样。这个函数的签名如下：
- en: '[PRE13]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s understand these parameters and see how they can be used:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解这些参数以及它们如何使用：
- en: '`image`: This is the input image. We''ll use the channel image where the extremal
    region was taken. This is where the function normally does the flood fill, unless
    the `FLOODFILL_MASK_ONLY` is supplied. In this case, the image remains untouched
    and the drawing occurs in the mask. That''s exactly what we will do.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`：这是输入图像。我们将使用包含极值区域的通道图像。这是函数通常执行 flood fill 的地方，除非提供了`FLOODFILL_MASK_ONLY`。在这种情况下，图像保持不变，绘制发生在掩码上。这正是我们将要做的。'
- en: '`mask`: The mask must be an image two rows and columns greater than the input
    image. When flood fill draws a pixel, it verifies that the corresponding pixel
    in the mask is zero. In that case, it will draw and mark this pixel as one (or
    the other value passed in the flags). If the pixel is not zero, flood fill does
    not paint the pixel. In our case, we''ll provide a blank mask, so every letter
    will get painted in the mask.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mask`：掩码必须比输入图像多两行和两列。当 flood fill 绘制像素时，它会验证掩码中相应的像素是否为零。如果是这样，它将绘制并标记此像素为1（或通过标志传入的其他值）。如果像素不是零，flood
    fill 不会绘制像素。在我们的情况下，我们将提供一个空白掩码，因此每个字母都会在掩码中上色。'
- en: '`seedPoint`: This is the starting point. It''s similar to the place where you
    click when you want to use the "bucket" tool of a graphic application.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seedPoint`：这是起始点。它类似于当你想要使用图形应用程序的“桶”工具时点击的位置。'
- en: '`newVal`: This is the new value of the repainted pixels.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`newVal`：这是重新绘制像素的新值。'
- en: '`loDiff and upDiff`: These parameters represent the lower and upper difference
    between the pixels being processed and their neighbors. The neighbor will be painted
    if it falls in this range. If the `FLOODFILL_FIXED_RANGE` flag is used, the difference
    between the seed point and the pixels being processed will be used instead.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loDiff`和`upDiff`：这些参数表示正在处理的像素与其邻居之间的下限和上限差异。如果邻居落在这个范围内，它将被绘制。如果使用了`FLOODFILL_FIXED_RANGE`标志，则将使用种子点和正在处理的像素之间的差异。'
- en: '`rect`: This is the optional parameter that limits the region where the flood
    fill will be applied.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rect`：这是一个可选参数，它限制了 flood fill 将要应用的区域。'
- en: '`flags`: This value is represented by a bit mask.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flags`：这个值由一个位掩码表示。'
- en: The least significant eight bits of the flag contain a connectivity value. A
    value of 4 indicates that all the four edge pixels will be used, and a value of
    8 will indicates that diagonal pixels must also be taken into account. We'll use
    four for this parameter.
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标志的最低八位包含一个连通性值。值为4表示将使用所有四个边缘像素，而值为8则表示必须考虑对角像素。我们将为此参数使用4。
- en: The next 8 to 16 bits contain a value from 1 to 255 and are used to fill the
    mask. Since we want to fill the mask with white, we'll use 255 << 8 for this value.
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来的8到16位包含一个1到255之间的值，并用于填充掩码。由于我们希望用白色填充掩码，我们将使用`255 << 8`为此值。
- en: There are two more bits that can be set by adding the `FLOODFILL_FIXED_RANGE`
    and `FLOODFILL_MASK_ONLY` flags, as described earlier.
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有两个额外的位可以通过添加`FLOODFILL_FIXED_RANGE`和`FLOODFILL_MASK_ONLY`标志来设置，如前所述。
- en: 'We''ll create a function called `drawER`. This function will receive four parameters:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个名为`drawER`的函数。这个函数将接收四个参数：
- en: A vector with all processed channels
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含所有处理通道的向量
- en: The `ERStat` regions
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERStat`区域'
- en: The group that must be drawn
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须绘制的组
- en: The group rectangle
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组矩形
- en: 'This function will return an image with the word represented by this group.
    Let''s start with this function by creating the mask image and defining the flags:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将返回一个由这个组表示的单词的图像。让我们从这个函数开始，创建掩码图像并定义标志：
- en: '[PRE14]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, we''ll loop though each group. It''s necessary to find the region index
    and its stats. There''s a chance that this extreme region will be the root, which
    does not contain any points. In this case, we''ll just ignore it:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将遍历每个组。找到区域索引及其统计信息是必要的。有可能这个极端区域将是根，它不包含任何点。在这种情况下，我们将忽略它：
- en: '[PRE15]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, we can read the pixel coordinate from the `ERStat` object. It''s represented
    by the pixel number, counting from top to bottom, left to right. This linear index
    must be converted to a *row (y)* and *column (z)* notation, using a formula similar
    to the one that we discussed in [Chapter 2](ch02.html "Chapter 2. An Introduction
    to the Basics of OpenCV"), *An Introduction to the Basics of OpenCV*:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以从`ERStat`对象中读取像素坐标。它由像素编号表示，从上到下，从左到右计数。这个线性索引必须转换为一个类似我们在[第2章](ch02.html
    "第2章。OpenCV基础知识介绍")中讨论的公式，即*OpenCV基础知识介绍*的行（y）和列（z）表示法：
- en: '[PRE16]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Then, we can call the `floodFill` function. The `ERStat` object gives us the
    value that we need to use in the `loDiff` parameter:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以调用`floodFill`函数。`ERStat`对象为我们提供了在`loDiff`参数中需要使用的值：
- en: '[PRE17]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After we do this for all regions in the group, we''ll end it with an image
    a little bigger than the original one, with a black background and the word in
    white letters. Now, let''s crop just the area of the letters. Since the region
    rectangle was given, we start with defining it as our region of interest:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在对组中的所有区域都这样做之后，我们将以一个比原始图像略大的图像结束，背景为黑色，文字为白色。现在，让我们只裁剪字母区域。由于给出了区域矩形，我们首先将其定义为我们的感兴趣区域：
- en: '[PRE18]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, we''ll find all nonzero pixels. This is the value that we''ll use in
    the `minAreaRect` function to get the rotated rectangle around the letters. Finally,
    we borrow the previous chapter''s `deskewAndCrop` function to crop and rotate
    the image for us:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将找到所有非零像素。这是我们将在`minAreaRect`函数中使用以获取围绕字母的旋转矩形的值。最后，我们借用前一章的`deskewAndCrop`函数来为我们裁剪和旋转图像：
- en: '[PRE19]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This is the result of the process for the easel image:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这是画布图像处理的结果：
- en: '![Text extraction](img/B04283_11_06.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![文本提取](img/B04283_11_06.jpg)'
- en: Text recognition
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本识别
- en: In [Chapter 10](ch10.html "Chapter 10. Developing Segmentation Algorithms for
    Text Recognition"), *Developing Segmentation Algorithms for Text Recognition*,
    we used the Tesseract API directly to recognize the text regions. This time, we'll
    use OpenCV classes to accomplish the same goal.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第10章](ch10.html "第10章。开发文本识别的分割算法")，*开发文本识别的分割算法*中，我们直接使用Tesseract API来识别文本区域。这次，我们将使用OpenCV类来完成同样的目标。
- en: In OpenCV, all OCR-specific classes are derived from the `BaseOCR` virtual class.
    This class provides a common interface for the OCR execution method itself.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中，所有OCR特定的类都从`BaseOCR`虚拟类派生。这个类为OCR执行方法本身提供了一个通用接口。
- en: 'Specific implementations must inherit from this class. By default, the text
    module provides three different implementations: `OCRTesseract`, `OCRHMMDecoder`,
    and `OCRBeamSearchDecoder`.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 特定的实现必须从这个类继承。默认情况下，文本模块提供了三种不同的实现：`OCRTesseract`、`OCRHMMDecoder`和`OCRBeamSearchDecoder`。
- en: 'This hierarchy is depicted in the following class diagram:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 以下类图展示了这个层次结构：
- en: '![Text recognition](img/B04283_11_07.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![文本识别](img/B04283_11_07.jpg)'
- en: With this approach, we can separate the part of the code where the OCR mechanism
    is created from the execution itself. This makes it easier to change the OCR implementation
    in the future.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，我们可以将创建OCR机制的部分与执行本身分离。这使得将来更改OCR实现变得更加容易。
- en: 'So, let''s start with creating a method that decides which implementation we''ll
    use based on a string. We will currently support Tesseract. However, you can take
    a look at the chapter code where a demonstration with `HMMDecoder` is also provided.
    We are also accepting the OCR engine name in a string parameter, but we can improve
    our application flexibility by reading it from an external `JSON` or `XML` configuration
    file:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们从创建一个基于字符串决定我们将使用哪种实现的方法开始。我们目前将支持Tesseract。然而，你可以查看包含使用 `HMMDecoder`
    的演示的章节代码。我们还在字符串参数中接受OCR引擎名称，但我们可以通过从外部 `JSON` 或 `XML` 配置文件中读取它来提高我们应用程序的灵活性：
- en: '[PRE20]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You may notice that the function returns a `Ptr<BaseOCR>`. Now, take a look
    at the highlighted code. It calls the create method to initialize a Tesseract
    OCR instance. Let''s take a look at its official signature, since it allows several
    specific parameters:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到函数返回一个 `Ptr<BaseOCR>`。现在，看看高亮显示的代码。它调用创建方法来初始化一个Tesseract OCR实例。让我们看看它的官方签名，因为它允许几个特定的参数：
- en: '[PRE21]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s dissect each one of these parameters:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一分析这些参数：
- en: '`datapath`: This is the path to the `tessdata` files of the root directory.
    The path must end with a backslash `/` character. The `tessdata` directory contains
    the language files you installed. Passing `nullptr` to this parameter will make
    Tesseract search in its installation directory, which is the location where this
    folder is normally present. It''s common to change this value to `args[0]` when
    deploying an application and include the `tessdata` folder in your application
    path.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`datapath`: 这是根目录中 `tessdata` 文件的路径。路径必须以反斜杠 `/` 字符结尾。`tessdata` 目录包含你安装的语言文件。将
    `nullptr` 传递给此参数将使Tesseract在其安装目录中搜索，这是该文件夹通常所在的位置。在部署应用程序时，通常将此值更改为 `args[0]`
    并将 `tessdata` 文件夹包含在应用程序路径中。'
- en: '`language`: This is a three letter word with the language code (for example,
    eng for English, por for Portuguese, or hin for Hindi). Tesseract supports loading
    of multiple language codes using the + sign. So, passing *eng+por* will load both
    English and Portuguese languages. Of course, you can only use languages that you
    previously installed; otherwise, the loading will fail. A language configuration
    file can specify that two or more languages must be loaded together. To prevent
    this, you can use a tilde ~. For example, you can use *hin+~eng* to guarantee
    that English is not loaded with Hindi, even if it is configured to do so.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`language`: 这是一个由三个字母组成的单词，包含语言代码（例如，eng代表英语，por代表葡萄牙语，或hin代表印地语）。Tesseract支持使用加号加载多个语言代码。因此，传递
    *eng+por* 将加载英语和葡萄牙语。当然，你只能使用你之前安装的语言；否则，加载将失败。语言配置文件可以指定必须一起加载两个或多个语言。为了防止这种情况，你可以使用波浪号
    ~。例如，你可以使用 *hin+~eng* 来确保英语不会与印地语一起加载，即使配置了这样做。'
- en: '`whitelist`: This is the character set to be considered for recognition. If
    `nullptr` is passed, the characters will be `0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ`.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`whitelist`: 这是用于识别的字符集。如果传递 `nullptr`，则字符将是 `0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ`。'
- en: '`oem`: These are OCR algorithms that will be used. They can have one of the
    following values:'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oem`: 这些是将要使用的OCR算法。它们可以有以下值之一：'
- en: '`OEM_TESSERACT_ONLY`: This uses just Tesseract. It''s the fastest method, but
    it also has less precision.'
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OEM_TESSERACT_ONLY`: 这仅使用Tesseract。这是最快的方法，但精度较低。'
- en: '`OEM_CUBE_ONLY`: This uses the cube engine. It''s slower, but more precise.
    This will only work if your language was trained to support this engine mode.
    To check whether that''s the case, look for .`cube` files for your language in
    the `tessdata` folder. The support for English language is guaranteed.'
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OEM_CUBE_ONLY`: 这使用cube引擎。它较慢，但更精确。这只有在你的语言被训练以支持这种引擎模式时才会工作。要检查这一点，请查看 `tessdata`
    文件夹中你语言的 `.cube` 文件。对英语语言的支持是保证的。'
- en: '`OEM_TESSERACT_CUBE_COMBINED`: This combines both Tesseract and cube to achieve
    the best possible OCR classification. This engine has the best accuracy and the
    slowest execution time.'
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OEM_TESSERACT_CUBE_COMBINED`: 这结合了Tesseract和cube以实现最佳的OCR分类。这个引擎具有最高的准确性和最慢的执行时间。'
- en: '`OEM_DEFAULT`: This tries to infer the strategy based in the language `config`
    file, command line `config` file, or in the absence of both, uses `OEM_TESSERACT_ONLY`.'
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OEM_DEFAULT`: 这会尝试根据语言 `config` 文件、命令行 `config` 文件推断策略，或者在两者都缺失的情况下使用 `OEM_TESSERACT_ONLY`。'
- en: '`psmode`: This is the segmentation mode. The modes are as follows:'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`psmode`: 这是分割模式。模式如下：'
- en: '`PSM_OSD_ONLY`: Using this mode, Tesseract will just run its preprocessing
    algorithms to detect orientation and script detection.'
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_OSD_ONLY`：使用此模式，Tesseract将仅运行其预处理算法以检测方向和脚本检测。'
- en: '`PSM_AUTO_OSD`: This tells Tesseract to do automatic page segmentation with
    orientation and script detection.'
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_AUTO_OSD`：这告诉Tesseract进行自动页面分割，包括方向检测和脚本检测。'
- en: '`PSM_AUTO_ONLY`: This does page segmentation, but avoids doing orientation,
    script detection, or OCR. This is the default value.'
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_AUTO_ONLY`：此选项仅进行页面分割，但避免进行方向检测、脚本检测或OCR。这是默认值。'
- en: '`PSM_AUTO`: This does page segmentation and OCR, but avoids doing orientation
    or script detection.'
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_AUTO`：此选项进行页面分割和OCR，但避免进行方向或脚本检测。'
- en: '`PSM_SINGLE_COLUMN`: This assumes that the text of variable sizes is displayed
    in a single column.'
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_COLUMN`：这假设文本以单列的形式显示。'
- en: '`PSM_SINGLE_BLOCK_VERT_TEXT`: This treats the image as a single uniform block
    of a vertically aligned text.'
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_BLOCK_VERT_TEXT`：将图像视为一个垂直对齐的文本的单个统一块。'
- en: '`PSM_SINGLE_BLOCK`: This is a single block of text. This is the default configuration.
    We will use this flag since our preprocessing phase guarantees this condition.'
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_BLOCK`：这是一个单独的文本块。这是默认配置。我们将使用此标志，因为我们的预处理阶段保证了这一条件。'
- en: '`PSM_SINGLE_LINE`: This indicates that the image contains only one line of
    text.'
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_LINE`：这表示图像中只包含一行文本。'
- en: '`PSM_SINGLE_WORD`: This indicates that the image contains just one word.'
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_WORD`：这表示图像中只包含一个单词。'
- en: '`PSM_SINGLE_WORD_CIRCLE`: This informs that the image is a just one word disposed
    in a circle.'
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_WORD_CIRCLE`：这表示图像是一个单词，且该单词被放置在一个圆圈中。'
- en: '`PSM_SINGLE_CHAR`: This indicates that the image contains a single character.'
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PSM_SINGLE_CHAR`：这表示图像中包含单个字符。'
- en: For the last two parameters, the `#include tesseract` directory recommends you
    to use the constant names instead of directly inserting their values.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 对于最后两个参数，`#include tesseract` 目录建议您使用常量名称而不是直接插入它们的值。
- en: 'The last step is to add text detection to our `main` function. To do this,
    just add the following code to the end of the `main` method:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将文本检测添加到我们的 `main` 函数中。为此，只需将以下代码添加到 `main` 方法的末尾：
- en: '[PRE22]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In this code, we started by calling our `initOCR` method to create a Tesseract
    instance. Notice that the remaining code will not change if we choose a different
    OCR engine, since the run method signature is guaranteed by the `BaseOCR` class.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中，我们首先调用我们的 `initOCR` 方法来创建一个Tesseract实例。请注意，如果选择不同的OCR引擎，剩余的代码将不会改变，因为运行方法签名由
    `BaseOCR` 类保证。
- en: 'Next, we iterate over each detected `ERFilter` group. Since each group represents
    a different word, we:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们遍历每个检测到的 `ERFilter` 组。由于每个组代表不同的单词，我们：
- en: Call the previously created `drawER` function to create an image with the word.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用之前创建的 `drawER` 函数来创建包含单词的图像。
- en: Create a text string called `word`, and call the `run` function to recognize
    the word image. The recognized word will be stored in the string.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个名为 `word` 的文本字符串，并调用 `run` 函数来识别单词图像。识别出的单词将被存储在字符串中。
- en: Print the text string on the screen.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在屏幕上打印文本字符串。
- en: 'Let''s take a look at the run method signature. This method is defined in the
    `BaseOCR` class and will be equal for all specific OCR implementations, even the
    ones that might be implemented in the future:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 `run` 方法的签名。此方法在 `BaseOCR` 类中定义，对于所有特定的OCR实现都将相同，即使是在未来可能实现的一些实现：
- en: '[PRE23]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Of course, this is a pure virtual function that must be implemented by each
    specific class (such as the `OCRTesseract` class that we just used):'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这是一个纯虚拟函数，必须由每个特定类（如我们刚刚使用的 `OCRTesseract` 类）实现：
- en: '`image`: This is the input image. It must be an RGB or a grayscale image'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`：这是输入图像。它必须是RGB或灰度图像'
- en: '`component_rects`: We can provide a vector to be filled with the bounding box
    of each component (words or text lines) detected by the OCR engine'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`component_rects`：我们可以提供一个向量，该向量将被填充，包含OCR引擎检测到的每个组件（单词或文本行）的边界框'
- en: '`component_texts`: If given, this vector will be filled with the text strings
    of each component detected by the OCR'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`component_texts`：如果提供，此向量将被填充，包含OCR检测到的每个组件的文本字符串'
- en: '`component_confidences`: If given, the vector will be filled with floats and
    the confidence values of each component'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`component_confidences`：如果提供，该向量将被填充，包含每个组件（单词或文本行）的置信度值'
- en: '`component_level`: This defines what a component is. It may have the `OCR_LEVEL_WORD`
    (by default) or `OCR_LEVEL_TEXT_LINE` values'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`component_level`：这定义了组件是什么。它可能有 `OCR_LEVEL_WORD`（默认值）或 `OCR_LEVEL_TEXT_LINE`
    的值'
- en: Tip
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: If necessary, we prefer changing the component level to a word or line in the
    `run()` method instead of doing the same thing in the `psmode` parameter of the
    `create()` function. This is preferable since the `run` method will be supported
    by any OCR engine that decides to implement the `BaseOCR` class. Always remember
    that the `create()` method is where vendor specific configurations are set.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，我们更倾向于在`run()`方法中将组件级别更改为单词或行，而不是在`create()`函数的`psmode`参数中做同样的事情。这是更可取的，因为`run`方法将得到任何决定实现`BaseOCR`类的OCR引擎的支持。始终记住，`create()`方法是在设置供应商特定配置的地方。
- en: 'This is the program''s final output:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这是程序的最终输出：
- en: '![Text recognition](img/B04283_11_08.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![文本识别](img/B04283_11_08.jpg)'
- en: Despite a minor confusion with the `&` symbol, every word was perfectly recognized!
    You can check the complete source code in the `ocr.cpp` file, in the chapter code.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管对`&`符号有些小困惑，但每个单词都被完美识别了！您可以在章节代码中的`ocr.cpp`文件中查看完整的源代码。
- en: Summary
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we saw that scene text recognition is a far more difficult
    OCR situation than working with scanned texts. We studied how the text module
    addresses this problem with extremal region identification using the **Newmann
    and Matas** algorithm. We also saw how to use this API with the `floodfill` function
    to extract the text to an image and submit it to Tesseract OCR. Finally, we studied
    how the OpenCV text module integrates with Tesseract and other OCR engines, and
    how we can use its classes to identify what's written in the image.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解到场景文本识别比处理扫描文本的OCR情况要困难得多。我们研究了文本模块如何使用**Newmann和Matas**算法通过极值区域识别来解决这个问题。我们还看到了如何使用这个API和`floodfill`函数将文本提取到图像中，并将其提交给Tesseract
    OCR。最后，我们研究了OpenCV文本模块如何与Tesseract和其他OCR引擎集成，以及我们如何使用其类来识别图像中的文字。
- en: This ends our journey with OpenCV. From the beginning to the end of this book,
    we expected you to have a glance about the Computer Vision area and have a better
    understanding of how several applications work. We also sought to show you that,
    although OpenCV is quite an impressive library, the field is already full of opportunities
    for improvement and research.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这标志着我们使用OpenCV的旅程的结束。从这本书的开始到结束，我们希望您对计算机视觉领域有一个大致的了解，并对几个应用的工作原理有更好的理解。我们还试图向您展示，尽管OpenCV是一个非常令人印象深刻的库，但这个领域已经充满了改进和研究的机遇。
- en: Thank you for reading! No matter whether you use OpenCV for creating impressive
    commercial programs based on Computer Vision, or if you use it in a research that
    will change the world, we hope you will find this content useful. Just keep working
    with your skills—this was just the beginning!
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您的阅读！无论您是使用OpenCV来创建基于计算机视觉的令人印象深刻的商业程序，还是将其用于可能改变世界的科研，我们都希望您觉得这个内容有用。只需继续运用您的技能——这仅仅是开始！
