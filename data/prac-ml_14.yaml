- en: Chapter 14. New generation data architectures for Machine learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第14章 新一代机器学习数据架构
- en: This is our last chapter, and we will take a detour from our usual learning
    topics to cover some of the solution aspects of Machine learning. This is in an
    attempt to complete a practitioner's view on the implementation aspects of Machine
    learning solutions, covering more on the choice of platform for different business
    cases. Let's look beyond Hadoop, NoSQL, and other related solutions. The new paradigm
    is definitely a unified platform architecture that takes care of all the aspects
    of Machine learning, starting from data collection and preparation until the visualizations,
    with focus on all the key architecture drivers such as volume, sources, throughput,
    latency, extensibility, data quality, reliability, security, self-service, and
    cost.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的最后一章，我们将从我们通常的学习主题中偏离，来涵盖一些机器学习的解决方案方面。这是尝试完成实践者对机器学习解决方案实施方面的看法，涵盖更多关于不同业务案例平台选择的内容。让我们超越Hadoop、NoSQL和其他相关解决方案。新范式肯定是一个统一的平台架构，它关注机器学习的所有方面，从数据收集和准备到可视化，重点关注所有关键架构驱动因素，如数据量、来源、吞吐量、延迟、可扩展性、数据质量、可靠性、安全性、自助服务和成本。
- en: 'The following flowchart depicts different data architecture paradigms that
    will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 以下流程图展示了本章将涵盖的不同数据架构范例：
- en: '![New generation data architectures for Machine learning](img/B03980_14_01.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![新一代机器学习数据架构](img/B03980_14_01.jpg)'
- en: 'The topics listed here are covered in depth in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章深入探讨了以下主题：
- en: A brief history of how traditional data architectures were implemented and why
    they are found desirable in the current context of big data and analytics.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传统数据架构是如何实施以及为什么在大数据和分析的当前背景下被认为是可取的简要历史。
- en: An overview of the new-age data architecture requirements in the context of
    Machine learning that includes **Extract, Transform, and Load** (**ETL**), storage,
    processing and reporting, distribution, and the presentation of the insights.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在机器学习背景下，包括**提取、转换和加载**（**ETL**）、存储、处理和报告、分发以及洞察展示的新时代数据架构要求概述。
- en: An introduction to Lambda architectures that unifies strategies for batch and
    real-time processing with some examples.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda架构的介绍，这些架构统一了批处理和实时处理策略，并附带一些示例。
- en: An introduction to Polyglot Persistence and Polymorphic databases that unify
    data storage strategies that include structured, unstructured, and semi-structured
    data stores, and centralize the querying approach across data stores. An example
    of how the Greenplum database supports the same and how it integrates with Hadoop
    seamlessly.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Polyglot Persistence和Polymorphic数据库的介绍，这些数据库统一了包括结构化、非结构化和半结构化数据存储的数据存储策略，并集中了跨数据存储的查询方法。以下是如何Greenplum数据库支持这些策略以及它如何与Hadoop无缝集成的示例。
- en: Semantic Data Architectures include Ontologies Evolution, purpose, use cases,
    and technologies.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语义数据架构包括本体论演变、目的、用例和技术。
- en: Evolution of data architectures
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据架构演变
- en: We will start with understanding how data architectures traditionally have been
    followed by detailing the demands of modern machine learning or analytics platforms
    in the context of big data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从了解数据架构传统上是如何遵循的，然后详细说明在大数据背景下现代机器学习或分析平台的需求。
- en: Observation 1—Data stores were always for a purpose
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 观察一——数据存储始终有目的
- en: 'Traditionally, data architectures had a clear segregation of purpose, **OLTP**
    (**Online Transaction Processing**), typically known to be used for transactional
    needs, and **OLAP** (**Online Analytic Processing**) data stores that typically
    used for reporting and analytical needs. The following table elaborates the general
    differences:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，数据架构有明确的目的分隔，**OLTP**（**在线事务处理**），通常用于交易需求，以及**OLAP**（**在线分析处理**）数据存储，通常用于报告和分析需求。以下表格详细说明了一般差异：
- en: '|   | OLTP databases | OLAP databases |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '|   | OLTP数据库 | OLAP数据库 |'
- en: '| --- | --- | --- |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Definition** | This involves many small online transactions (INSERT, UPDATE,
    and DELETE). The fast query processing is the core requirement; maintaining data
    integrity, concurrency, and effectiveness is measured by the number of transactions
    per second. It''s usually characterized by a high-level of normalization. | This
    involves a relatively small volume of transactions. Complex Queries involves slicing
    and dicing of data. The data stored is usually aggregated, historical in nature,
    and mostly stored in multi-dimensional schemas (usually star schema). |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| **定义** | 这涉及许多小的在线事务（INSERT、UPDATE和DELETE）。快速查询处理是核心要求；通过每秒事务数来衡量数据完整性、并发性和有效性。它通常以高度规范化为特征。
    | 这涉及相对较小的事务量。复杂查询涉及数据的切片和切块。存储的数据通常是聚合的、历史性的，并且主要存储在多维模式中（通常是星型模式）。 |'
- en: '| **Data type** | Operational data | Integrated/consolidated/aggregated data
    |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| **数据类型** | 运营数据 | 集成/整合/聚合数据 |'
- en: '| **Source** | OLTP databases usually are the actual sources of data | OLAP
    databases consolidate data from various OLTP databases |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| **来源** | OLTP数据库通常是数据的实际来源 | OLAP数据库从各种OLTP数据库中整合数据 |'
- en: '| **Primary purpose** | This deals with the execution of day-to-day business
    processes/tasks | This serves decision-support |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| **主要用途** | 这涉及日常业务流程/任务的执行 | 这用于决策支持 |'
- en: '| **CUD** | This is short, fast inserts and updates initiated by users | Periodic
    long-running jobs are refreshing the data |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| **CUD** | 这是由用户发起的简短、快速的插入和更新 | 定期运行的长作业正在刷新数据 |'
- en: '| **Queries** | This usually works on smaller volumes of data and executes
    simpler queries | This often includes complex queries involving aggregations and
    slicing and dicing in the multi-dimensional structure |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| **查询** | 这通常在较小的数据量上工作，并执行简单的查询 | 这通常包括涉及聚合和多维结构切片和切块的复杂查询 |'
- en: '| **Throughput** | This is usually very fast due to relatively smaller data
    volumes and quicker running queries | This usually run in batches and in higher
    volumes, may take several hours depending on volumes |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| **吞吐量** | 由于数据量相对较小且查询运行速度快，这通常非常快 | 这通常以批量方式运行，在更高数据量下可能需要几个小时 |'
- en: '| **Storage Capacity** | Relatively small as historical data is archived |
    This requires larger storage space due to the volumes that are involved |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| **存储容量** | 由于历史数据归档，相对较小 | 由于涉及的数据量较大，这需要更大的存储空间 |'
- en: '| **Schema Design** | Highly normalized with many tables | This is typically
    de-normalized with fewer tables and the use of star and/or snowflake schemas |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| **模式设计** | 高度规范化，有许多表 | 这通常是去规范化，表较少，并使用星型和/或雪花模式 |'
- en: '| **Backup and Recovery** | This requires proper backup religiously; operational
    data is critical to run the business. Data loss is likely to entail significant
    monetary loss and legal liability | Instead of regular backups, some environments
    may consider simply reloading the OLTP data as a recovery method |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| **备份和恢复** | 这需要虔诚地进行适当的备份；运营数据对业务运营至关重要。数据丢失可能导致重大经济损失和法律责任 | 相比于常规备份，某些环境可能考虑仅重新加载OLTP数据作为恢复方法
    |'
- en: Observation 2—Data architectures were shared disk
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 观察二——数据架构是共享磁盘
- en: Shared disk data architecture refers to an architecture where there is a data
    disk that holds all the data, and each node in the cluster has access to this
    data for processing. All the data operations can be performed by any node at a
    given point in time, and in case two nodes attempt at persisting/writing a tuple
    at the same time, to ensure consistency, a disk-based lock or intended lock communication
    is passed on, thus affecting the performance. Further with an increase in the
    number of nodes, contention at the database level increases. These architectures
    are *write* limited as there is a need to handle the locks across the nodes in
    the cluster.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 共享磁盘数据架构指的是一种架构，其中有一个数据磁盘存储所有数据，集群中的每个节点都可以访问这些数据进行处理。所有数据操作都可以由任意节点在特定时间点执行，如果两个节点同时尝试持久化/写入一个元组，为了确保一致性，会传递基于磁盘的锁或预期的锁通信，从而影响性能。随着节点数量的增加，数据库级别的争用增加。这些架构是*写入*受限的，因为需要处理集群中节点间的锁。
- en: Even in the case of the reads, partitioning should be implemented effectively
    to avoid complete table scans. All the traditional RDBMS databases are the shared
    disk data architectures.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在读取的情况下，也应该有效地实施分区以避免完整表扫描。所有传统的RDBMS数据库都是共享磁盘数据架构。
- en: '![Evolution of data architectures](img/B03980_14_02.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![数据架构演变](img/B03980_14_02.jpg)'
- en: 'Observation 3—Traditional ETL architecture had limitations. The following list
    provides the details of these limitations:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 观察结果3——传统ETL架构存在局限性。以下列表提供了这些局限性的详细信息：
- en: Onboarding and integrating data were slow and expensive. Most of the ETL logic
    that exists today is custom coded and is tightly coupled with the database. This
    tight coupling also resulted in a problem where the existing logic code cannot
    be reused. Analytics and reporting requirements needed a different set of tuning
    techniques to be applied. Optimization for analytics was time-consuming and costly.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上线和整合数据既缓慢又昂贵。今天存在的许多ETL逻辑都是定制编码的，并且与数据库紧密耦合。这种紧密耦合也导致了一个问题，即现有的逻辑代码无法重用。分析和报告需求需要应用不同的调整技术。分析优化既耗时又昂贵。
- en: Data provenance was often poorly recorded. The data meaning was *lost in translation*.
    Post-onboarding, maintenance and analysis cost for the on-boarded data was usually
    very high. Recreating data lineage was manual, time-consuming, and error-prone.
    There was no strong auditing or record of the data transformations and were generally
    tracked in spreadsheets.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据来源通常记录不佳。数据含义在翻译中丢失。上线后的维护和分析成本通常非常高。重建数据血缘是手动、耗时且易出错的。没有强大的审计或记录数据转换，通常在电子表格中跟踪。
- en: The target data was difficult to consume. The optimization favors known analytics
    but was not well-suited to the new requirements. A one-size-fits-all canonical
    view was used rather than fit-for-purpose views, or lacks a conceptual model to
    consume easily the target data. It has been difficult to identify what data was
    available, how to get access, and how to integrate the data to answer a question.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标数据难以消费。优化倾向于已知分析，但并不适合新需求。使用的是一刀切的标准视图，而不是适合目的的视图，或者缺乏一个易于消费目标数据的概念模型。很难确定哪些数据可用，如何获取访问权限，以及如何整合数据来回答问题。
- en: Observation 4—Data was usually only structured
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 观察结果4——数据通常是结构化的
- en: Most of the time, the database was designed to fit the RDBMS models. If the
    incoming data was not actually structured, the ETLs would build a structure around
    for being stored in a standard OLTP or OLAP store.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，数据库的设计是为了适应关系数据库管理系统（RDBMS）模型。如果传入的数据实际上没有结构，ETLs就会构建一个结构以便存储在标准的OLTP或OLAP存储中。
- en: Observation 5—Performance and scalability
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 观察结果5——性能和可扩展性
- en: The optimization of a data store or a query was possible to an extent, given
    the infrastructure, and beyond a certain point, there was a need for a redesign.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定基础设施的情况下，数据存储或查询的优化在某种程度上是可能的，但超过一定点，就需要重新设计。
- en: Emerging perspectives & drivers for new age data architectures
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 新兴的数据架构视角与驱动因素
- en: Driver 1—*BIG* data intervention.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动因素1——*大数据*干预。
- en: 'We have defined big data and large dataset concepts in [Chapter 2](ch02.html
    "Chapter 2. Machine learning and Large-scale datasets"), *Machine learning and
    Large-scale datasets*. The data that is now being ingested and needs to be processed
    typically has the following characteristics:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第2章](ch02.html "第2章。机器学习和大规模数据集")“机器学习和大规模数据集”中定义了大数据和大型数据集的概念。现在正在被摄取并需要处理的数据通常具有以下特征：
- en: '**Source**: Depending upon the nature of the information, the source may be
    a real-time stream of data (for example, trade transactions), or batches of data
    containing updates since the last sync'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**来源**：根据信息的性质，来源可能是一个实时数据流（例如，交易交易），或者自上次同步以来包含更新的数据批次'
- en: '**Content**: The data may represent different types of information. Often,
    this information is related to other pieces of data and is needed to be connected'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容**：数据可能代表不同类型的信息。通常，这些信息与其他数据相关，需要连接'
- en: 'The following screenshot shows the types of data and different sources that
    need to be supported:'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图显示了需要支持的数据类型和不同来源：
- en: '![Emerging perspectives & drivers for new age data architectures](img/B03980_14_03.jpg)'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![新兴的数据架构视角与驱动因素](img/B03980_14_03.jpg)'
- en: '**Volume**: Depending upon the nature of the data, the volumes that are being
    processed may vary. For example, master data or the securities definition data
    are relatively fixed, whereas the transaction data is enormous compared to the
    other two.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**体积**：根据数据的性质，正在处理的数据量可能不同。例如，主数据或证券定义数据相对固定，而交易数据与其他两种相比是巨大的。'
- en: '**Lifecycle**: Master data has a fixed life and is rarely updated (such as,
    slowly changing dimensions). However, the transactional data has a very short
    life but needs to be available for analysis, audit, and so on for longer periods.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生命周期**：主数据有固定的生命周期，很少更新（例如，缓慢变化的维度）。然而，事务数据生命周期非常短，但需要长时间可用于分析、审计等。'
- en: '**Structure**: While most of the data is structured, there is an advent of
    unstructured data in the financial industry. It is becoming increasingly critical
    for financial systems to incorporate unstructured data as part of their IT architectures.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构**：虽然大部分数据是有结构的，但在金融行业中出现了非结构化数据的新趋势。对于金融系统来说，将非结构化数据纳入其IT架构中变得越来越关键。'
- en: 'The next chart depicts the complexity, velocity volume, and various aspects
    of each data source:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表展示了每个数据源的复杂性、速度、体积和各个方面：
- en: '![Emerging perspectives & drivers for new age data architectures](img/B03980_14_04.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![新时代数据架构的兴起视角与驱动因素](img/B03980_14_04.jpg)'
- en: 'Source: SoftServe'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：SoftServe
- en: Driver 2—Data platform requirements are advanced
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动因素2——数据平台需求高级
- en: The landscape of the new age-data platform requirements is drastically expanding,
    and the unified platforms are the happening ones. The next concept map explains
    it all. The core elements of data architectures include ETL (Extract, Transform,
    and Load), Storage, Reporting, Analytics, Visualization, and data distribution.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 新时代数据平台需求的地貌正在急剧扩张，统一平台是当前的热点。下一张概念图将详细解释这一点。数据架构的核心元素包括ETL（提取、转换和加载）、存储、报告、分析、可视化和数据分发。
- en: '![Emerging perspectives & drivers for new age data architectures](img/B03980_14_05.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![新时代数据架构的兴起视角与驱动因素](img/B03980_14_05.jpg)'
- en: Driver 3—Machine learning and analytics platforms now have a new purpose and
    definition
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动因素3——机器学习和分析平台现在有了新的目的和定义
- en: 'The evolution of analytics and it repurposing itself is depicted in the following
    diagram:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了分析的发展及其自我重塑：
- en: Historically, the focus was merely on reporting. Aggregated or preprocessed
    data is loaded into the warehouse to understand what has happened. This is termed
    as **Descriptive analytics** and was primarily a backward step.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 历史上，重点仅在于报告。汇总或预处理过的数据被加载到仓库中，以了解发生了什么。这被称为**描述性分析**，主要是向后一步。
- en: With the advent of ad-hoc data inclusion, the need was to understand why certain
    behavior happened. This is called **Diagnostic analytics** and is focused on understanding
    the root cause of the behavior, which is again based on the historical data.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着临时数据包含的出现，需要理解某些行为发生的原因。这被称为**诊断分析**，其重点是理解行为背后的根本原因，这又基于历史数据。
- en: Now, the demand has shifted, and the need is to understand what will happen.
    This is called **Predictive analytics,** and the focus is to predict the events
    based on the historical behavior.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，需求已经转变，需要理解将要发生什么。这被称为**预测分析**，其重点是根据历史行为预测事件。
- en: 'With the advent of real-time data, the focus is now on do we make it happen?
    This goes beyond predictive analytics where remediation is a part of something.
    The ultimate focus is to *Make it happen!* with the advent of real-time event
    access. The following diagram depicts the evolution of analytics w.r.t. the value
    and related complexity:'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着实时数据的出现，现在的重点是是否能够实现它？这超越了预测分析，其中补救措施是某个部分的一部分。最终的重点是随着实时事件访问的出现，*实现它*！以下图表展示了分析在价值及其相关复杂性方面的演变：
- en: '![Emerging perspectives & drivers for new age data architectures](img/B03980_14_06.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![新时代数据架构的兴起视角与驱动因素](img/B03980_14_06.jpg)'
- en: 'The next table differentiates the traditional analytics (BI) and the new age
    analytics:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个表格区分了传统分析（BI）和新时代分析：
- en: '| Area | Traditional analytics (BI) | New age analytics |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 区域 | 传统分析（BI） | 新时代分析 |'
- en: '| --- | --- | --- |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Scope** | Descriptive AnalyticsDiagnostic Analytics | Predictive AnalyticsData
    science |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| **范围** | 描述性分析诊断分析 | 预测分析数据科学 |'
- en: '| **Data** | Limited/Controlled volumesPreprocessed/ValidatedBasic models |
    Large volumesDiverse formats and heavy on varietyRaw data that are not pre-processedThe
    growing model complexity |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| **数据** | 有限/受控的量预处理/验证基本模型 | 大量数据多种格式和多样性预处理/验证过的数据增长模型复杂性 |'
- en: '| **Result** | Here, the focus is on retrospection and the root-cause analysis
    | Here, the focus is on prediction/insights and the accuracy of analysis |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| **结果** | 这里，重点是回顾和根本原因分析 | 这里，重点是预测/洞察力和分析的准确性 |'
- en: Driver 4—It is not all about historical and batch, it is real-time and instantaneous
    insights
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动因素 4—不仅仅关乎历史和批量，还有实时和即时洞察
- en: The data coming in lower volumes and higher velocity is what defines *real-time*.
    The new age analytics systems are expected to handle real-time, batch, and near
    real-time processing requests (these are scheduled and known as micro batches).
    The following graph depicts the properties of real-time and batch data characteristics
    with respect to volume, velocity, and variety being constant.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据量小、速度高是定义 *实时* 的关键。新一代分析系统预计将处理实时、批量以及近实时处理请求（这些是计划好的，被称为微批量）。以下图表描述了实时和批量数据特性在体积、速度和多样性保持恒定的情况下的属性。
- en: '![Emerging perspectives & drivers for new age data architectures](img/B03980_14_07.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![新兴视角和驱动因素，针对新一代数据架构](img/B03980_14_07.jpg)'
- en: Driver 5—Traditional ETL is unable to cope with *BIG* data
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动因素 5—传统的 ETL 无法应对 *大数据*
- en: 'The goal is to be able to lay out an ETL architecture strategy that can address
    the following problematic areas:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是能够制定一个 ETL 架构策略，以解决以下问题区域：
- en: Facilitates standardization in implementation—dealing with the need for one
    standard
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进实施标准化—处理一个标准的需求
- en: Supports building reusable components
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持构建可重用组件
- en: Building agnostic functions
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建无差别的函数
- en: Improving performance and scalability using parallel processing techniques
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用并行处理技术提高性能和可扩展性
- en: Reducing the total overall **cost of ownership** (**TCO**)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降低总体拥有成本（**TCO**）
- en: Building a specialized skill pool
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建专门的技能库
- en: 'The following table provides a comparative analysis of the key data loading
    pattern:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格提供了关键数据加载模式的比较分析：
- en: '|   | ETLExtract, Transform, and Load | ELTExtract, Load, and Transform | ETLTExtract,
    Transform, Load, and Transform |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '|   | ETL 提取、转换和加载 | ELT 提取、加载和转换 | ETLT 提取、转换、加载和转换 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **Overview** | This is a traditional technique for moving and transforming
    data in which an ETL engine is either separated from the source or the target
    DBMS performs the data transformations. | This is a technique for moving and transforming
    data from one location and formatting it to another instance and format. In this
    style of integration, the target DBMS becomes the transformation engine. | In
    this technique, transformations are partly done by the ETL engine and partly pushed
    to the destination DBMS. |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| **概述** | 这是一个传统的数据移动和转换技术，其中 ETL 引擎要么与源数据库分离，要么目标 DBMS 执行数据转换。 | 这是一个将数据从一处移动和转换到另一实例和格式的技术。在这种集成风格中，目标
    DBMS 成为转换引擎。 | 在这种技术中，转换部分由 ETL 引擎完成，部分推送到目标 DBMS。 |'
- en: '| **Highlights** | A heavy work of transformation is done in the ETL engine.It
    uses the integrated transformation functions.Transformation logic can be configured
    through the GUI.This is supported by Informatica. | A heavy work of transformation
    is handed over to the DBMS layer.Transformation logic runs closer to the data.It
    is supported by Informatica. | Transformation work is split between the ETL engine
    and the DBMS.It is supported by Informatica. |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| **高亮** | 在 ETL 引擎中进行了大量的转换工作。它使用集成的转换函数。转换逻辑可以通过 GUI 进行配置。这是由 Informatica
    支持的。 | 转换工作被委托给 DBMS 层。转换逻辑运行得更接近数据。这是由 Informatica 支持的。 | 转换工作在 ETL 引擎和 DBMS
    之间分配。这是由 Informatica 支持的。 |'
- en: '| **Benefits** | This is an easy, GUI-based configuration.The transformation
    logic is independent, outside the database, and is reusableThis works very well
    for granular, simple, function-oriented transformations that do not require any
    database calls.Can run on SMP or MPP hardware. | This leverages the RDBMS engine
    hardware for scalability.It always keeps all the data in RDBMS.It is parallelized
    according to the dataset, and the disk I/O is usually optimized at the engine
    level for faster throughput.It scales as long as the hardware and the RDBMS engine
    can continue to scale.Can achieve 3x to 4x the throughput rates on the appropriately
    tuned MPP RDBMS platform. | It can balance the workload or share the workload
    with the RDBMS. |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| **好处** | 这是一个基于图形用户界面的简单配置。转换逻辑独立，位于数据库之外，且可重用。这对于粒度细、简单、面向功能的转换非常有效，这些转换不需要任何数据库调用。可以在SMP或MPP硬件上运行。
    | 这利用了RDBMS引擎硬件以实现可扩展性。它始终将所有数据保留在RDBMS中。根据数据集进行并行化，并且通常在引擎级别优化磁盘I/O以实现更快的吞吐量。只要硬件和RDBMS引擎可以继续扩展，它就可以扩展。在适当调整的MPP
    RDBMS平台上可以实现3倍到4倍的吞吐量。 | 它可以平衡工作负载或与RDBMS共享工作负载。 |'
- en: '| **Risks** | This requires a higher processing power on the ETL side.The costs
    are higher.It consists of the complex transformations that would need reference
    data, which will slow down the process. | Transformation logic is tied to a database.The
    transformations that involve smaller volume and simple in nature will not gain
    many benefits. | This will still have a part of the transformation logic within
    the database. |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| **风险** | 这需要在ETL侧有更高的处理能力。成本更高。它包括需要参考数据的复杂转换，这将减慢处理过程。 | 转换逻辑与数据库相关联。涉及较小体积和简单性质的转换不会带来很多好处。
    | 这仍将在数据库内部包含一部分转换逻辑。 |'
- en: Fact 6—No "one" data model fits advanced or complex data processing requirements;
    there is a need for multi-data model platforms
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 事实6——没有“一个”数据模型适合高级或复杂的数据处理需求；需要多数据模型平台
- en: Different databases are designed to solve different problems. Using a single
    database engine for all of the requirements usually leads to non-performant solutions.
    RDBMSs are known to work well-transactional operations, OLAP databases for reporting,
    NoSQL for high-volume data processing, and storage. Some solutions unify these
    storages and provide an abstraction for querying across these stores.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的数据库被设计用来解决不同的问题。通常使用单个数据库引擎来满足所有需求会导致性能不佳的解决方案。RDBMS在事务操作方面表现良好，OLAP数据库用于报告，NoSQL用于高容量数据处理和存储。一些解决方案统一了这些存储，并为跨这些存储的查询提供了抽象。
- en: Modern data architectures for Machine learning
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 适用于机器学习的现代数据架构
- en: From this section onwards, we will cover some of the emergent data architectures,
    challenges that gave rise to architectures of this implementation architecture,
    some relevant technology stacks, and use cases where these architectures apply
    (as relevant) in detail.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 从本节开始，我们将详细介绍一些新兴的数据架构、导致这种实现架构的挑战、一些相关的技术堆栈以及这些架构适用的用例（如有相关）。
- en: Semantic data architecture
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语义数据架构
- en: 'Some of the facts covered in the emerging perspectives in the previous section
    give rise to the following core architecture drivers to build semantic data model
    driven data lakes that seamlessly integrate a larger data scope, which is analytics
    ready. The future of analytics is semantified. The goal here is to create a large-scale,
    flexible, standards-driven ETL architecture framework that models with the help
    of tools and other architecture assets to enable the following:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中提到的新兴观点中涵盖的一些事实引发了以下核心架构驱动因素，以构建语义数据模型驱动的数据湖，这些数据湖能够无缝集成更广泛的数据范围，并且为分析做好准备。分析的未来是语义化的。此处的目标是创建一个大规模、灵活、标准驱动的ETL架构框架，借助工具和其他架构资产进行建模，以实现以下功能：
- en: Enabling a common data architecture that can be a standard architecture.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使一个可以成为标准架构的通用数据架构。
- en: Dovetailing into the Ontology-driven data architecture and data lakes of the
    future (it is important to tie this architecture strategy with the data aggregation
    reference architecture). This will ensure there is a single data strategy that
    takes care of the data quality and data integration.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与未来基于本体驱动的数据架构和数据湖相结合（重要的是要将此架构策略与数据聚合参考架构相结合）。这将确保有一个单一的数据策略来处理数据质量和数据集成。
- en: Enabling product groups to integrate rapidly into the data architecture and
    deliver into and draw from the common data repository.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使产品团队能够快速集成到数据架构中，并将数据存入和从公共数据存储库中提取。
- en: Enabling ad-hoc analytics on need basis.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据需要启用即席分析。
- en: Reducing time needed to implement the new data aggregation, ingestion, and transformation.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少实施新的数据聚合、摄取和转换所需的时间。
- en: Enabling *any format to any format* model (a format-agnostic approach that involves
    data normalization sometimes).
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用“任何格式到任何格式”的模式（一种涉及数据规范化的格式无关方法）。
- en: Complying with emerging semantic standards. This will bring in the flexibility.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遵守新兴的语义标准。这将带来灵活性。
- en: Enabling the common IT management and reduction of the TCO.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使共同的IT管理成为可能并降低TCO。
- en: Enabling a consolidated cloud (that can be a proprietary) for the Broadridge
    Master Business Data Repository.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为Broadridge主业务数据存储库启用一个统一的云（这可能是一个专有的）。
- en: Enabling all the applications and products to "talk to a common language" and
    building the Broadridge data format.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使所有应用程序和产品能够“使用一种共同的语言”并构建Broadridge数据格式。
- en: Reduce, and in some cases eliminate, the proliferation of too many licenses,
    databases, implementations, stacks, and more.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少，在某些情况下消除，过多许可证、数据库、实施、堆栈等的泛滥。
- en: 'Data Semantification: It is important to analyze the underlying schemas in
    order to unlock the meaning from them. The semantification process is always iterative
    and evolves over the period of time. The metadata definitions in this context
    will be elaborated or expanded in this process.![Semantic data architecture](img/B03980_14_08.jpg)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据语义化：分析底层架构以从中提取意义是很重要的。语义化过程始终是迭代的，并随着时间的推移而发展。在此过程中，元数据定义将被详细阐述或扩展。![语义数据架构](img/B03980_14_08.jpg)
- en: Setting up an enterprise-wide aggregate data mart is not the solution to problems
    outlined previously. Even if such a data mart was set up, keeping it updated and
    in line with the rest of the projects would be a major problem. As stated earlier,
    the need is to lay out the common reference architecture of a system that can
    accumulate data from many sources without making any assumptions on how, where,
    or when this data will be used.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业范围内建立聚合数据集市并不是解决之前提出问题的方案。即使建立了这样的数据集市，保持其更新并与其他项目保持一致将是一个主要问题。正如之前所述，需要制定一个系统，该系统能够从多个来源积累数据，而不对数据的使用方式、地点或时间做出任何假设。
- en: There are two different advances in the field that we leverage to address the
    issues at an architecture level. These are the evolution of a data lake as an
    architecture pattern, and the emergence of Semantic Web and its growing relevance
    in e-business.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用该领域的两个不同进展来解决架构层面的问题。这些是数据湖作为架构模式的演变，以及语义网的兴起及其在电子商务中的日益相关性。
- en: The business data lake
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 业务数据湖
- en: The enterprise data lake gives the concept of an enterprise data warehouse a
    whole new dimension. While the approach with a data warehouse has always been
    to design a single schema and aggregate the minimum information needed to fulfill
    the schema, data lake turns both these premises of traditional data warehouse
    architectures on its head. The traditional data warehouse is designed for a specific
    purpose in mind (for example, analytics, reporting, and operational insights).
    The schema is designed accordingly, and the minimum information needed for the
    purpose is aggregated. This means that using this warehouse for any other objective
    is only incidental if at all, but it is not designed for such a use.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 企业数据湖为数据仓库的概念带来了全新的维度。虽然数据仓库的方法一直是设计一个单一架构并汇总满足该架构所需的最少信息，但数据湖颠覆了传统数据仓库架构的这两个前提。传统的数据仓库是为了特定的目的而设计的（例如，分析、报告和运营洞察）。架构相应设计，所需的最少信息被汇总。这意味着如果使用这个仓库实现其他目标，那只是偶然的，而不是其设计目的。
- en: The business data lake promotes the concept of an appropriate schema—the warehouse
    is not constrained by a fixed, predetermined schema. This allows the data lake
    to assimilate information as and when it becomes available in the organization.
    The important direct implication of this is that rather than assimilating the
    minimum information—the data lake can assimilate all the information produced
    in the organization. Since there are no assumptions made about what the data is,
    options remain open to use the information for any purpose in the future. This
    enables the data lake to power business agility by being able to serve newer ideas
    with the data that is already available in the data lake.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 商业数据湖促进了适当模式的概念——仓库不受固定、预定的模式的约束。这允许数据湖在组织内信息可用时吸收信息。这一重要直接影响是，而不是吸收最少的信息——数据湖可以吸收组织产生的所有信息。由于没有对数据是什么的假设，未来可以使用信息进行任何目的的选项仍然开放。这使得数据湖能够通过提供数据湖中已有的数据来支持新想法，从而提高业务敏捷性。
- en: 'The business data lake addresses the following concerns:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 商业数据湖解决了以下问题：
- en: How to handle unstructured data?
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何处理非结构化数据？
- en: How to link internal and external data?
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何链接内部和外部数据？
- en: How to adapt to the speed of business change?
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何适应业务变化的速度？
- en: How to remove the repetitive ETL cycle?
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何消除重复的ETL周期？
- en: How to support different levels of data quality and governance based on differing
    business demands?
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何根据不同的业务需求支持不同层次的数据质量和治理？
- en: How to let local business units take the initiative?
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何让本地业务单元采取主动？
- en: How to ensure the deliverance of platform and that it will it be adopted?
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何确保平台的交付并使其被采用？
- en: Semantic Web technologies
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语义网技术
- en: When using external data that are most often found on the web, the most important
    requirement is understanding the precise semantics of the data. Without this,
    the results cannot be trusted. Here, Semantic Web technologies come to the rescue,
    as they allow semantics ranging from very simple to very complex to be specified
    for any available resource. Semantic Web technologies do not only support capturing
    the passive semantics, but also support active inference and reasoning on the
    data.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用在网络上最常找到的外部数据时，最重要的要求是理解数据的精确语义。没有这一点，结果无法信任。在这里，语义网技术提供了帮助，因为它们允许为任何可用的资源指定从非常简单到非常复杂的语义。语义网技术不仅支持捕获被动的语义，还支持对数据进行主动的推理和推理。
- en: Semantic Web technologies allow data to be annotated with additional metadata
    (as RDF). One of the most fundamental capabilities that this adds is the **AAA
    principle** of Semantic Computing is—*Anyone can add anything about anything at
    any time*. As the information is made up of metadata, adding more metadata can
    enrich the information at any time.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 语义网技术允许数据被附加额外的元数据（作为RDF）。这种能力添加的最基本的能力之一是语义计算的**AAA原则**——*任何人都可以在任何时候添加关于任何事物的任何内容*。由于信息由元数据组成，因此可以随时添加更多元数据来丰富信息。
- en: Querying RDF data is done using SPARQL, which allows navigating complex relationship
    graphs to extract meaningful information from the data store. Reasoner (or an
    inference engine) works with the RDF metadata to deliver inferences at the top
    of the data. This allows the system to extract newer insights, which were originally
    not available in the incoming data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SPARQL查询RDF数据，它允许导航复杂的关系图，从数据存储中提取有意义的信息。推理器（或推理引擎）与RDF元数据一起工作，在数据顶部提供推理。这允许系统提取原本在传入数据中不可用的新的见解。
- en: Today, enormous amounts of information are becoming available over the web and
    over corporate and regulatory networks. However, access to all the available information
    remains limited as long as the information is stored separately without easy means
    to combine them from different sources.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，大量的信息正在通过互联网和公司及监管网络变得可用。然而，只要信息被分别存储，没有简单的方法将它们从不同的来源组合起来，对所有可用信息的访问仍然有限。
- en: 'This exacerbates the need for suitable methods to combine data from various
    sources. This is termed as the *cooperation of information systems*. This is defined
    as the ability to share, combine, and exchange information between heterogeneous
    sources in a transparent way to the end users. These heterogeneous sources are
    usually known to have always handled data in silos, and thus, they are inaccessible.
    To achieve data interoperability, the issues posed by data heterogeneity needs
    to be eliminated. Data sources can be heterogeneous in the following ways:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这加剧了对合适方法的需求，以结合来自各种来源的数据。这被称为“信息系统的合作”。这被定义为能够在透明的方式下，在最终用户之间共享、组合和交换异构源信息的能力。这些异构源通常被认为是始终在孤岛中处理数据，因此它们是不可访问的。为了实现数据互操作性，需要消除数据异质性提出的问题。数据源可以以下方式异构：
- en: '**Syntax**: Syntactic heterogeneity is caused by the use of different models
    or languages'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**句法**：句法异质性是由使用不同的模型或语言引起的'
- en: '**Schema**: Schematic heterogeneity results from structural differences'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模式**：模式异质性源于结构差异'
- en: '**Semantics**: Semantic heterogeneity is caused by different meanings or interpretations
    of data in various contexts![Semantic Web technologies](img/B03980_14_09.jpg)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义学**：语义异质性是由不同语境中数据的不同含义或解释所引起的![语义网技术](img/B03980_14_09.jpg)'
- en: 'Data integration provides the ability to manipulate data transparently across
    multiple data sources. Based on the architecture, there are two systems:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集成提供了在多个数据源之间透明地操作数据的能力。基于架构，存在两种系统：
- en: '**Central Data Integration**: A central data integration system usually has
    a global schema, which provides the user with a uniform interface to access information
    stored in the data sources.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中央数据集成**：中央数据集成系统通常具有全局模式，它为用户提供了一个统一的接口来访问存储在数据源中的信息。'
- en: '**Peer-to-peer**: In contrast, in a peer-to-peer data integration system, there
    are no general points of control on the data sources (or peers). Instead, any
    peer can accept user queries for the information distributed in the entire system.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对等网络**：相比之下，在对等网络数据集成系统中，数据源（或对等点）上没有一般性的控制点。相反，任何对等点都可以接受用户对整个系统中分布的信息的查询。'
- en: 'The cooperation of information systems is the ability to share, combine, and/or
    exchange information from multiple information sources, and the ability to access
    the integrated information by its final receivers transparently. The major problems
    that hinder the cooperation of information systems are the autonomy, the distribution,
    the heterogeneity, and the instability of information sources. In particular,
    we are interested in the heterogeneity problem that can be identified at several
    levels: the system, the syntactic, the structural, and the semantic heterogeneity.
    The cooperation of information systems has been extensively studied, and several
    approaches have been proposed to bridge the gap between heterogeneous information
    systems, such as: database translation, standardization, federation, mediation,
    and web services. These approaches provide appropriate solutions to the heterogeneity
    problem at syntactic and basic levels.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 信息系统的合作是指能够从多个信息源共享、组合和/或交换信息，以及最终接收者能够透明地访问集成信息的能力。阻碍信息系统合作的主要问题是信息源的自主性、分布、异质性和不稳定性。特别是，我们对可以在几个层面上识别的异质性问题感兴趣：系统、句法、结构和语义异质性。信息系统的合作已被广泛研究，并提出了几种方法来弥合异构信息系统之间的差距，例如：数据库转换、标准化、联邦、调解和Web服务。这些方法为句法和基本层面的异质性问题提供了适当的解决方案。
- en: However, in order to achieve semantic interoperability between heterogeneous
    information systems, the meaning of the information that is interchanged has to
    be understood in the systems. Semantic conflicts occur whenever two contexts do
    not use the same interpretation of the information.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了实现异构信息系统之间的语义互操作性，交换信息的含义必须在系统中被理解。每当两个语境不使用对信息的相同解释时，就会发生语义冲突。
- en: Therefore, in order to deal with semantic heterogeneity, there is a need for
    more semantic-specialized approaches, such as ontologies. In this chapter, our
    focus is to demonstrate how information systems can cooperate using semantics.
    In the next section, let us look at the constitution of semantic data architecture.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了处理语义异构性，需要更多语义专业化的方法，例如本体。在本章中，我们的重点是展示信息系统如何使用语义进行合作。在下一节中，让我们看看语义数据架构的构成。
- en: Ontology and data integration
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 本体和数据集成
- en: 'The diagram here represents the reference architecture for Semantic data architecture-based
    analytics:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 此图表示基于语义数据架构的参考架构：
- en: '![Ontology and data integration](img/B03980_14_10.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![本体和数据集成](img/B03980_14_10.jpg)'
- en: 'The key features of semantic data architecture are as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 语义数据架构的关键特性如下：
- en: '**Metadata representation**: Each of the sources can be represented as local
    ontologies supported by a meta-data dictionary to interpret the nomenclature.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据表示**：每个来源都可以表示为支持元数据字典以解释术语的本地本体。'
- en: '**Global conceptualization**: There will be a global ontology definition that
    maps the local ontologies and provides a single view or nomenclature for a common
    view.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全局概念化**：将有一个全局本体定义，它映射本地本体，并为共同视图提供单一视图或术语。'
- en: '**Generic querying**: There will be a support for querying at a local of a
    global ontology levels depending on the need and purpose of the consumer / client.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用查询**：将根据消费者/客户端的需求和目的，在本地或全局本体级别提供查询支持。'
- en: '**Materialised view**: A high level querying strategy that masks querying between
    nomenclatures and peer sources.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**物化视图**：一种高级查询策略，用于隐藏术语和同源之间的查询。'
- en: '**Mapping**: There will be support for defining the thesaurus based mapping
    between ontology attributes and values.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**映射**：将支持定义本体属性和值之间的术语表映射。'
- en: Vendors
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 供应商
- en: '| Type | Product/framework | Vendor |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 产品/框架 | 供应商 |'
- en: '| --- | --- | --- |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Open source and commercial versions | MarkLogic 8 is the NoSQL graph store
    that supports storing and processing RDF data formats and can serve as a triple
    store. | MarkLogic |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 开源和商业版本 | MarkLogic 8 是支持存储和处理 RDF 数据格式的 NoSQL 图存储，可以作为三元组存储。 | MarkLogic
    |'
- en: '| Open source and commercial versions | Stardog is the easiest and the most
    powerful graph database: search, query, reasoning, and constraints in a lightweight,
    pure Java system. | Stardog |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 开源和商业版本 | Stardog 是最简单且功能最强大的图数据库：在轻量级、纯 Java 系统中进行搜索、查询、推理和约束。 | Stardog
    |'
- en: '| Open source | 4Store is an efficient, scalable, and stable RDF database.
    | Garlik Ltd. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 开源 | 4Store 是一个高效、可扩展且稳定的 RDF 数据库。 | Garlik Ltd. |'
- en: '| Open source | Jena is a free and open source Java framework for building
    Semantic Web and Linked Data applications. | Apache |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 开源 | Jena 是一个用于构建语义网和链接数据应用的免费开源 Java 框架。 | Apache |'
- en: '| Open source | Sesame is a powerful Java framework for processing and handling
    RDF data. This includes creating, parsing, storing, inferencing, and querying
    of such data. It offers an easy-to-use API that can be connected to all the leading
    RDF storage solutions. | GPL v2 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 开源 | Sesame 是一个强大的 Java 框架，用于处理和操作 RDF 数据。这包括创建、解析、存储、推理和查询此类数据。它提供了一个易于使用的
    API，可以连接到所有领先的 RDF 存储解决方案。 | GPL v2 |'
- en: '| Open Source | Blazegraph is SYSTAP''s flagship graph database. It is specifically
    designed to support big graphs offering both Semantic Web (RDF/SPARQL) and graph
    database (TinkerPop, blueprints, and vertex-centric) APIs. | GPL v2 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 开源 | Blazegraph 是 SYSTAP 的旗舰图数据库。它专门设计用于支持大型图，提供语义网（RDF/SPARQL）和图数据库（TinkerPop、blueprints
    和以顶点为中心）API。 | GPL v2 |'
- en: Multi-model database architecture / polyglot persistence
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多模型数据库架构/多语言持久性
- en: We could never have imagined, even five years ago, that relational databases
    would become only a single kind of a database technology and not the database
    technology. Internet-scale data processing changed the way we process data.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 即使五年前，我们也无法想象关系数据库只会成为数据库技术的一种，而不是数据库技术本身。互联网规模的数据处理改变了我们处理数据的方式。
- en: The new generation architectures such as Facebook, Wikipedia, SalesForce, and
    so on, are found in principles and paradigms, which are radically different from
    the well-established theoretical foundations on which the current data management
    technologies are developed.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 新一代架构，如 Facebook、Wikipedia、SalesForce 等，在原则和范例上与当前数据管理技术发展的既定理论基础截然不同。
- en: 'The major architectural challenges of these architectures can be characterized
    next:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这些架构的主要架构挑战可以概括如下：
- en: 'Commoditizing information:'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息商品化：
- en: Apple App Store, SaaS, Ubiquitous Computing, Mobility, and the Cloud-Based Multi-Tenant
    architectures have unleashed, in business terms, an ability to commoditize information
    delivery. This model changes almost all the architecture decision making, as we
    now need to think in terms of what the "units of information" that can be offered
    and billed as services are, instead of thinking in terms of the TCO of the solution.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 苹果应用商店、SaaS、通用计算、移动性和基于云的多租户架构在商业术语上释放了商品化信息交付的能力。这种模型几乎改变了所有的架构决策，因为我们现在需要考虑的是可以提供并作为服务计费的信息“单元”，而不是考虑解决方案的总拥有成本（TCO）。
- en: 'Theoretical limitations of RDBMS:'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关系型数据库管理系统（RDBMS）的理论局限性：
- en: What Michael Stonebraker, an influential Database theorist, has been writing
    in recent times at the heart of the Internet Scale Architectures is a new theoretical
    model of data processing and management. The theories of database management are
    now more than three decades old, and when they were designed, they were designed
    for the mainframe-type computing environments and very unreliable electronic components.
    Nature and the capabilities of the systems and applications have since evolved
    significantly. With reliability becoming a quality attribute of the underlying
    environment, systems are composed of parallel processing cores, and the nature
    of data creation and usage has undergone tremendous change. In order to conceptualize
    solutions for these new environments, we need to approach the designing solution
    architectures from a computing perspective, not only from an engineering perspective.
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 影响力巨大的数据库理论家迈克尔·斯坦利布雷克（Michael Stonebraker）最近在互联网规模架构的核心所撰写的，是一个新的数据处理和管理理论模型。数据库管理的理论现在已有三十多年历史，当时它们是为大型机类型的计算环境和非常不可靠的电子组件而设计的。自然和系统以及应用的能力已经发生了显著变化。随着可靠性成为底层环境的质量属性，系统由并行处理核心组成，数据创建和使用的性质也发生了巨大变化。为了概念化这些新环境下的解决方案，我们需要从计算的角度来设计解决方案架构，而不仅仅是工程角度。
- en: 'Six major forces are driving the data revolution today. They are as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 六大主要力量正在推动今天的数据革命。它们如下：
- en: Massive Parallel Processing
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大规模并行处理
- en: Commoditized Information Delivery
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息交付商品化
- en: Ubiquitous Computing and Mobile Devices
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用计算和移动设备
- en: Non-RDBMS and Semantic Databases
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非RDBMS和语义数据库
- en: Community Computing
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社区计算
- en: Cloud Computing
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云计算
- en: Hadoop and MapReduce have unleashed massive parallel processing of data on a
    substantial basis and have made complex computing algorithms in a programmatic
    platform. This has changed analytics and BI forever. Similarly, web services and
    API-driven architectures have made information delivery commoditized on a substantial
    basis. Today, it is possible to build extremely large systems in such a way that
    each subsystem or component is a complete platform in itself, hosted and managed
    by a different entity altogether.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 和 MapReduce 在很大程度上释放了数据的并行处理能力，并在程序化平台上实现了复杂的计算算法。这永远地改变了分析和商业智能。同样，基于
    Web 服务和 API 驱动的架构在很大基础上实现了信息交付的商品化。如今，可以以这种方式构建极其庞大的系统，使得每个子系统或组件本身就是一个完整的平台，由完全不同的实体托管和管理。
- en: The previous innovations have changed the traditional Data Architecture completely.
    Especially, semantic computing and the ontology-driven modeling of information
    have turned data design on its head.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的创新已经完全改变了传统的数据架构。特别是，语义计算和基于本体论的信息建模已经彻底颠覆了数据设计。
- en: Philosophically, the data architecture is going through a factual underpinning.
    In traditional data models, we first design the *data model*—a fixed, design-time
    understanding of the world and its future. A data model fixes the meaning of data
    forever into a fixed structure.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 从哲学上讲，数据架构正在经历事实基础。在传统的数据模型中，我们首先设计*数据模型*——对世界及其未来的固定、设计时理解。数据模型将数据的含义永远固定在固定的结构中。
- en: A table is nothing but a category, a set of something. As a result, data has
    meaning only if we understand the set/category to which it belongs. For example,
    if we design an automobile processing system into some categories such as four-wheelers,
    two-wheelers, commercial vehicles, and so on, this division itself has some significant
    meaning embedded into it. The data that is stored in each of these categories
    does not reveal the *purpose of the design* that is embedded in the way the categories
    are designed. For example, another system might view the world of automobiles
    in terms of its drivetrain—electric, petroleum powered, nuclear powered, and more.
    This categorization itself reveals the purpose of the system in some manner, which
    is impossible to obtain from the attributes of any single record.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 表不过是一个类别，一组事物。因此，数据只有在理解它所属的集合/类别时才有意义。例如，如果我们把汽车处理系统设计成一些类别，如四轮车、两轮车、商用车辆等，这种划分本身就包含了一些重要的意义。存储在每个类别中的数据并不能揭示设计嵌入的方式中的*设计目的*。例如，另一个系统可能会从驱动方式的角度来看待汽车世界——电动、石油驱动、核驱动等。这种分类本身以某种方式揭示了系统的目的，这是无法从任何单个记录的属性中获得的。
- en: The term *polyglot* is typically used to define a person who can speak many
    languages. In the context of big data, this term refers to a set of applications
    that use many database technologies where each database technology solves a particular
    problem. The basic premise of this data architecture is that different database
    technologies solve various problems and since complex applications have many problems,
    picking one option to solve a particular issue is better than trying to solve
    all the problems using one option. When we talk about a data system, it is defined
    as a system that takes care of storage and querying of data, which has a runtime
    of several years and needs to address every possible hardware and maintenance
    complexities.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: “多语言”这个术语通常用来定义能够说多种语言的人。在大数据背景下，这个术语指的是一组使用多种数据库技术的应用程序，其中每种数据库技术解决特定的问题。这种数据架构的基本前提是不同的数据库技术解决各种问题，因为复杂的应用程序有很多问题，选择一个选项来解决特定问题比试图用一个选项解决所有问题更好。当我们谈论数据系统时，它被定义为负责数据存储和查询的系统，其运行时间可达数年，并需要解决所有可能的硬件和维护复杂性。
- en: 'Polyglot persistence data architecture is used when there is a complex problem,
    broken down into smaller problems and solved by applying different database models.
    This is followed by aggregating the results into a hybrid data storage platform
    followed by analysis. Some factors influencing the choice of database are as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当遇到复杂问题时，会采用多语言持久化数据架构，将问题分解成更小的部分，并通过应用不同的数据库模型来解决。随后将结果汇总到一个混合数据存储平台，并进行分析。影响数据库选择的一些因素如下：
- en: 'Factor 1—Data Models:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 因素1—数据模型：
- en: What type of data sources do we want to integrate?
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望整合哪些类型的数据源？
- en: How would we want to manipulate/analyze the data?
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望如何操作/分析数据？
- en: What is the volume, variety, and velocity of data?
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的量、种类和速度是多少？
- en: Examples—Relational, Key-Value, Column-Oriented, Document-Oriented, Graph, and
    so on.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例子—关系型、键值型、列式、文档型、图等。
- en: 'Factor 2—Consistency, availability, and partitioning (CAP):'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 因素2—一致性、可用性和分区（CAP）：
- en: '**Consistency**: Only one value of an object to each client (Atomicity)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性**：每个客户端的对象只有一个值（原子性）'
- en: '**Availability**: All objects are always available (Low Latency)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可用性**：所有对象始终可用（低延迟）'
- en: '**Partition tolerance**: Data is split into multiple network partitions (Clustering)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分区容错性**：数据被分割成多个网络分区（聚类）'
- en: 'CAP theorem requires us to choose any of the two features depicted here:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: CAP定理要求我们在这两个特性中选择任何一个：
- en: '![Multi-model database architecture / polyglot persistence](img/B03980_14_11.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![多模型数据库架构/多语言持久化](img/B03980_14_11.jpg)'
- en: 'The following diagram is an example of a system that has multiple applications
    with a data model built for its purpose:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表是一个示例系统，该系统具有多个应用程序，并为其目的构建了数据模型：
- en: '![Multi-model database architecture / polyglot persistence](img/B03980_14_12.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![多模型数据库架构/多语言持久化](img/B03980_14_12.jpg)'
- en: 'Source: ThoughtWorks'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：ThoughtWorks
- en: 'Some important aspects that affect this solution are listed next:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 影响此解决方案的一些重要方面如下：
- en: It is important that the proposed hybrid environment be clearly understood to
    ensure that it facilitates taking the right decision about data integration, analytics,
    data visibility, and others, and thus, how the solution fits into the entire big
    data and analytics implementation umbrella.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保提出的混合环境被清楚地理解，以确保它有助于做出关于数据集成、分析、数据可见性等方面的正确决策，从而确定解决方案如何融入整个大数据和数据分析实施框架。
- en: Since there is more than one data model, there will be a need for a unified
    platform that can interface with all the databases identified for solution and
    aggregation. This platform should address some bare minimum big data platform
    expectations like; fault tolerance high-availability, transactional integrity,
    data agility and reliability, scalability and performance are addressed.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于存在多个数据模型，因此将需要一个能够与为解决方案和聚合而指定的所有数据库接口的统一平台。这个平台应该解决一些大数据平台的基本期望，如：容错性、高可用性、事务完整性、数据敏捷性和可靠性、可扩展性和性能。
- en: 'Depending on the specific requirements, it is important for us to know/understand
    what sort of a data model works both: for the particular problem and the overall
    solution.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据具体要求，了解/理解哪种数据模型既适用于特定问题，也适用于整体解决方案，这一点非常重要。
- en: Data ingestion strategies address the real-time and batch data updates and how
    they can be made to work in the context of the multi-model database. Since there
    will be a variety of data stores, what will the **System of Record** (**SOR**)
    be? And how do we ensure that data across all the data sources is in sync or up-to-date?
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据摄取策略解决实时和批量数据更新，以及如何在多模型数据库的上下文中使其工作。由于将会有各种数据存储，**系统记录**（SOR）将是什么？我们如何确保所有数据源中的数据保持同步或是最新的？
- en: So overall, this is probably a big data challenge at its best. Multiple sources
    of data with very different structures need to be collected, integrated, and analyzed
    to solve a particular business problem. Then, the key is to identify whether the
    data needs to be pushed to the client on-demand or in real-time. And obviously,
    this type of problem cannot be solved easily or cost-effectively with one type
    of database technology. There could be some cases where a straightforward RDBMS
    could work, but in cases where there is non-relational data, there is a need for
    different persistence engines such as NoSQL. Similarly, for an e-commerce business
    problem, it is important that we have a highly available and a scalable data store
    for shopping cart functionality. However, to find products bought by a particular
    group, the same store cannot help. The need here is to go for a hybrid approach
    and have multiple data stores used in conjunction that is known as polyglot persistence.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这可能是最好的大数据挑战。需要收集、集成和分析多个来源的、结构非常不同的数据，以解决特定的商业问题。然后，关键是确定数据是否需要按需或实时推送到客户端。显然，这种类型的问题不能简单地或以成本效益的方式使用一种数据库技术来解决。在某些情况下，直接使用RDBMS可能可行，但在存在非关系型数据的情况下，需要不同的持久化引擎，如NoSQL。同样，对于电子商务业务问题，我们还需要一个高度可用和可扩展的数据存储，用于购物车功能。然而，要找到特定群体购买的产品，同一个存储无法提供帮助。这里的需求是采用混合方法，并使用多个数据存储联合使用，这被称为多语言持久化。
- en: Vendors
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 供应商
- en: '| Type | Product/framework | Vendor |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 产品/框架 | 供应商 |'
- en: '| --- | --- | --- |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Commercial | FoundationDB is a rock-solid database that gives NoSQL (Key-Value
    store) and SQL access. | FoundationDB |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 商业 | FoundationDB是一个坚如磐石的数据库，提供NoSQL（键值存储）和SQL访问。 | FoundationDB |'
- en: '| Open source | ArangoDB is an open source NoSQL solution with a flexible data
    model for documents, graphs, and key-values. | GPL v2 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 开源 | ArangoDB是一个开源的NoSQL解决方案，具有灵活的数据模型，适用于文档、图和键值。 | GPL v2 |'
- en: Lambda Architecture (LA)
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Lambda架构（LA）
- en: Lambda Architecture addresses one important aspect of Machine learning; that
    is, providing a unified platform for real-time and batch analytics. Most of the
    frameworks that we have seen until now support batch architecture (for example,
    Hadoop), in order to support real-time processing integration with specific frameworks
    (for example, Storm).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda架构解决了机器学习的一个重要方面；即提供一个统一平台，用于实时和批量分析。我们至今所见的大多数框架都支持批量架构（例如，Hadoop），以便支持与特定框架（例如，Storm）的实时处理集成。
- en: Nathan Marz introduced the concept of Lambda Architecture for a generic, scalable,
    and fault-tolerant data processing architecture that addresses a real-time stream-based
    processing and batch processing as a unified offering.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Nathan Marz提出了Lambda架构的概念，这是一个通用的、可扩展的、容错的数据处理架构，它将实时流处理和批量处理作为一个统一的解决方案。
- en: 'Lambda Architecture facilitates a data architecture that is highly fault-tolerant,
    both: against hardware failures and human mistakes. At the same time, it serves
    a broad range of uses and workloads, where low-latency reads and updates are required.
    The resulting system should be linearly scalable, and it should scale out rather
    than up.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda架构促进了一个高度容错的数据架构，既对抗硬件故障，也对抗人为错误。同时，它服务于广泛的用途和工作负载，在这些用途和工作负载中，需要低延迟的读取和更新。结果系统应该是线性可扩展的，并且应该向外扩展而不是向上扩展。
- en: 'Here''s how it looks from a high-level perspective:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，它看起来是这样的：
- en: '![Lambda Architecture (LA)](img/B03980_14_13.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![Lambda架构（LA）](img/B03980_14_13.jpg)'
- en: '**Data Layer**: All of the data entering the system is dispatched to both the
    batch layer and the speed layer for processing.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据层**：进入系统的所有数据都被分配到批量层和速度层进行处理。'
- en: '**Batch layer**: This manages master data and is responsible for batch pre-computation.
    It handles heavy volumes.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量层**：此层管理主数据，并负责批量预计算。它处理大量数据。'
- en: '**Speed layer**: Speed layer is responsible for handling recent data and compensates
    for the high latency of updates to the serving layer. On an average, this layer
    does not deal with large volumes.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度层**：速度层负责处理最近的数据，并补偿服务层更新的高延迟。平均而言，这一层不处理大量数据。'
- en: '**Serving layer**: Serving layer handles indexing the batch views and facilitates
    ad hoc querying demonstrating low-latency.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务层**：服务层处理批量视图的索引，并促进低延迟的即席查询。'
- en: '**Query function**: This combines the results from batch views and real-time
    views.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询函数**：此函数结合了批量视图和实时视图的结果。'
- en: Vendors
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Vendors
- en: '| Type | Product/framework | Vendor |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 产品/框架 | 供应商 |'
- en: '| --- | --- | --- |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Open source and commercial | Spring XD is a unified platform for a fragmented
    Hadoop ecosystem. It''s built at the top of the battle-tested open source projects,
    and dramatically simplifies the orchestration of big data workloads and data pipelines.
    | Pivotal (Spring Source) |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 开源和商业 | Spring XD是一个针对碎片化Hadoop生态系统的统一平台。它建立在经过实战检验的开源项目之上，极大地简化了大数据工作负载和数据管道的编排。
    | Pivotal (Spring Source) |'
- en: '| Open source | Apache Spark is a fast and conventional engine for big data
    processing with built-in modules for streaming, SQL, Machine learning, and graph
    processing. | Apache |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 开源 | Apache Spark是一个快速的传统大数据处理引擎，内置流、SQL、机器学习和图处理模块。 | Apache |'
- en: '| Open source | Oryx is a simple, real-time, and large-scale Machine learning
    infrastructure. | Apache (Cloudera) |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 开源 | Oryx是一个简单、实时和大规模的机器学习基础设施。 | Apache (Cloudera) |'
- en: '| Open source | The storm is a system used to process streaming data in the
    real time. | Apache (Hortonworks) |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 开源 | Storm是一个用于实时处理流数据的系统。 | Apache (Hortonworks) |'
- en: Summary
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this concluding chapter, our focus has been on the implementation aspects
    of Machine learning. We have understood what traditional analytics platforms have
    been and how they cannot fit the modern data requirements. You have also learned
    the architecture drivers that are promoting the new data architecture paradigms
    such as Lamda Architectures and polyglot persistence (multi-model database architecture),
    and how Semantic architectures help seamless data integration. With this chapter,
    you can assume that you are ready for implementing a Machine learning solution
    for any domain with an ability to not only identify what algorithms or models
    are to be applied to solve a learning problem, but also what platform solutions
    will address it in the best possible way.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的结尾，我们的重点是机器学习的实现方面。我们已经了解了传统分析平台是什么，以及它们如何无法满足现代数据需求。您还学习了推动新数据架构范式（如Lambda架构和多语言持久性[多模型数据库架构]）的架构驱动因素，以及语义架构如何帮助实现无缝数据集成。通过本章，您可以假设您已经准备好为任何领域实施机器学习解决方案，并且不仅能够识别出解决学习问题所需应用哪些算法或模型，而且还能找到最佳的平台解决方案。
