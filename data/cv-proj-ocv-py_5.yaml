- en: Handwritten Digit Recognition with scikit-learn and TensorFlow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用scikit-learn和TensorFlow进行手写数字识别
- en: In this chapter, we are going to learn how machine learning can be applied to
    computer vision projects, using a couple of different Python modules. We will
    also create and train a support vector machine that will actually perform our
    digit classification.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何将机器学习应用于计算机视觉项目，使用几个不同的Python模块。我们还将创建并训练一个支持向量机，它将实际执行我们的数字分类。
- en: 'In this chapter, we will be covering the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Acquiring and processing MNIST digit data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取和处理MNIST数字数据
- en: Creating and training a support vector machine
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和训练支持向量机
- en: Applying the support vector machine to new data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将支持向量机应用于新数据
- en: Introducing TensorFlow with digit classification
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍TensorFlow与数字分类
- en: Evaluating the results
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估结果
- en: Acquiring and processing MNIST digit data
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取和处理MNIST数字数据
- en: As mentioned, we will be covering handwritten digit recognition with scikit-learn
    and TensorFlow. Here, we're going to learn how machine learning can be applied
    to computer vision projects, and we're going to learn a couple of different ways
    and models, using a couple of different Python modules. Let's get started.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将使用scikit-learn和TensorFlow来处理手写数字识别。在这里，我们将学习如何将机器学习应用于计算机视觉项目，我们将学习几种不同的方法和模型，使用几个不同的Python模块。让我们开始吧。
- en: You have probably heard about machine learning. Here, we will be particularly
    talking about supervised machine learning, where we have a bunch of examples that
    we want to accomplish. So, rather than explicitly telling the computer what we
    want, we give an example.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经听说过机器学习。在这里，我们将特别讨论监督机器学习，其中我们有一系列想要完成的例子。所以，我们不是明确告诉计算机我们想要什么，而是给出一个例子。
- en: Let's take the case of the handwritten digits 0 through 9, which have labels
    that are created by humans indicating what those digits are supposed to be. So,
    rather than hand-coding features and explicitly telling the computer what the
    algorithm is, we are going to construct a model where we take those inputs, optimize
    some functions like a set of variables, and then train the computer to put the
    outputs to be what we want them to be.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以0到9的手写数字为例，这些数字由人类创建的标签指示它们应该是什么。因此，我们不是手动编码特征并明确告诉计算机算法，我们将构建一个模型，其中我们接受这些输入，优化一些函数，如一组变量，然后训练计算机将输出设置为我们所希望的。
- en: So, we will go through handwritten digits, starting with 0, 1, 2, 3, and so
    on. That's the general paradigm of machine learning, and we're going to cover
    three different algorithms here.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将从手写数字开始，从0、1、2、3等等开始。这是机器学习的一般范式，我们将在这里介绍三种不同的算法。
- en: So, let's start running some code.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们开始运行一些代码。
- en: 'Open up your Jupyter Notebook and, as we did in the previous chapter, let''s
    start fresh in this chapter. As you can observe in the following code, we will
    be importing our essential modules, such as `numpy`, which is the foundation of
    numerical computing in Python:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 打开你的Jupyter Notebook，就像我们在上一章中所做的那样，让我们在本章中从头开始。如您在以下代码中所观察到的，我们将导入我们的基本模块，例如`numpy`，它是Python中数值计算的基础：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see in the preceding code, we are importing `pyplot`, so that we
    can visualize what we are doing. We will also use a little bit of OpenCV for converting
    some images. We will also be using scikit-learn, which is abbreviated as `sklearn` in
    the actual module, while importing a support vector machine, as well as some tools
    that will give us our metrics. This will tell us how well things have actually
    worked. We will also be importing TensorFlow, with the abbreviation as `tf`, as
    we will be obtaining our data from it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在前面的代码中所见，我们正在导入`pyplot`，这样我们就可以可视化我们所做的事情。我们还将使用一点OpenCV来转换一些图像。我们还将使用scikit-learn，它在实际模块中缩写为`sklearn`，同时导入支持向量机，以及一些将给我们提供度量指标的工具。这将告诉我们事情实际上工作得有多好。我们还将导入TensorFlow，缩写为`tf`，因为我们将从其中获取我们的数据。
- en: 'One main advantage of scikit-learn and TensorFlow is that they have built-in
    functionality for getting digit recognition, which is such a common thing in computer
    vision and machine learning packages. So, you don''t need to go to websites and
    download it, and then write the lines yourself. It will be taken care of for you.
    Hence, scikit-learn actually has a good number of inbuilt datasets, some for computer
    vision, some for other tasks. It has a digit example, and we can then choose which
    datasets are available from the inbuilt datasets by writing `datasets` and then
    pressing *Tab*, as shown in the following screenshot:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn和TensorFlow的一个主要优势是它们内置了获取数字识别的功能，这在计算机视觉和机器学习包中是如此常见。因此，你不必去网站下载，然后自己编写这些行。它会为你处理。因此，scikit-learn实际上有相当多的内置数据集，一些用于计算机视觉，一些用于其他任务。它有一个数字示例，然后我们可以通过编写`datasets`并按*Tab*键来选择可用的内置数据集，如下面的截图所示：
- en: '![](img/e26c33b4-1d2f-4905-827a-a886bd59b62c.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e26c33b4-1d2f-4905-827a-a886bd59b62c.png)'
- en: 'Now, we have a list of inbuilt datasets. For example, you want to know `california_housing`
    prices; that is, you want estimated housing prices based on things like square
    footage and the number of bedrooms in the house—there''s a dataset for that. Some
    of this is image data, some is not. So, this might be something you want to check
    out if you want to experiment with different machine learning techniques, but
    for the `dataset.load_digits()` one, we have the following code that shows what
    it does:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个内置数据集的列表。例如，你想知道`california_housing`的价格；也就是说，你想根据房屋的平方英尺和卧室数量等因素估计房价——有一个数据集是针对这个的。其中一些是图像数据，一些不是。所以，如果你想尝试不同的机器学习技术，这可能是一个你想检查的项目，但对于`dataset.load_digits()`，我们有以下代码来展示它是如何工作的：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s break it down and understand the code. Firstly, we load an example image,
    just the first image in the set, as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解并理解这段代码。首先，我们加载一个示例图像，即集合中的第一个图像，如下所示：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The data is actually stored in images and it's an array of examples where each
    one is an 8 x 8 handwritten digit image.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 数据实际上存储在图像中，它是一个示例数组，其中每个示例都是一个8 x 8的手写数字图像。
- en: 'Next, we plot the image as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们按照以下方式绘制图像：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We should see the following output:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该看到以下输出：
- en: '![](img/c6d7d2c1-ee8a-456f-adcc-ef9f4da83ae8.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6d7d2c1-ee8a-456f-adcc-ef9f4da83ae8.png)'
- en: 'But I like to work with a slightly higher resolution example that we''re going
    to see from MNIST later. The lower resolution images are a little computationally
    faster to use because they''re smaller images. If we want to preprocess these
    images, these are stored as 8 x 8, and we need to convert each of them to a 1D
    array. We can do that easily using the `reshape` function, which we have used
    in our previous code:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我喜欢使用一个稍微高分辨率的示例，我们稍后会从MNIST中看到。低分辨率图像在计算上稍微快一些，因为它们是更小的图像。如果我们想要预处理这些图像，它们存储为8
    x 8，我们需要将每个图像转换为1D数组。我们可以通过使用`reshape`函数轻松地做到这一点，就像我们在之前的代码中做的那样：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will provide us with an output where, instead of an 8 x 8 array, we get
    a 1 x 64 array, as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为我们提供一个输出，其中，而不是8 x 8的数组，我们得到一个1 x 64的数组，如下所示：
- en: '![](img/1f1f2016-6359-475b-8c87-cc232bc53330.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1f1f2016-6359-475b-8c87-cc232bc53330.png)'
- en: 'Now, we are going to use the MNIST data that is available from the following
    website:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用以下网站可用的MNIST数据：
- en: '[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)'
- en: 'It is a fairly standard dataset. TensorFlow is nice enough to provide some
    functionality for getting that data, so you don''t have to go to the website and
    manually download it. We need to define `data_dir` and specify a location to save
    the data to. So, just create this `/tmp/tensorflow/mnist/input_data` directory
    and this will be fine, regardless of the operating system you''re running, and
    then we have some `input_data` that we imported from `tensorflow` and `read_data_sets`.
    Now, let''s run the following code:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个相当标准的数据集。TensorFlow足够好，提供了获取这些数据的功能，因此你不必去网站手动下载。我们需要定义`data_dir`并指定一个保存数据的位置。所以，只需创建这个`/tmp/tensorflow/mnist/input_data`目录，这将是好的，无论你运行的是哪种操作系统，然后我们有一些从`tensorflow`和`read_data_sets`导入的`input_data`。现在，让我们运行以下代码：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We should get the following output:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该得到以下输出：
- en: '![](img/3c828acb-7b21-4136-b8fe-34bce96b048e.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c828acb-7b21-4136-b8fe-34bce96b048e.png)'
- en: If you don't have the files, the code will download the gzip files and, if you
    do already have them, it just reads the existing gzip files and stores them in
    the `mnist` variable. `one_hot=True` ensures you get the labels, in terms of vectors,
    which means instead of being labeled with an American numerals like zero, one,
    two, three, four, and so on, it's going to be an array of mostly zeros. It's going
    to be an array of length 10, where everything is 0 except for one thing, which
    will be 1\. So, if we have, for example, 0, 1, 0, 0, 0, 0, and so on, that would
    represent a 1 and, if it was a 9, it would be all zeros until the last one, which
    would be a 1\. So, it's one useful way for machine learning to label an output. This
    is the way we got the data and we're going to be using it; it's more helpful for
    when we actually use TensorFlow, but for scikit-learn it actually does need the
    numerics.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有文件，代码将下载 gzip 文件，如果你已经有了，它将只读取现有的 gzip 文件并将它们存储在 `mnist` 变量中。`one_hot=True`
    确保你得到标签，以向量的形式表示，这意味着它不会用像零、一、二、三、四这样的美国数字来标记，而是一个主要由零组成的数组。它将是一个长度为 10 的数组，其中除了一个值为
    1 的元素外，其余都是 0。所以，如果我们有，例如，0, 1, 0, 0, 0, 0，等等，那将代表一个 1，如果它是 9，那么除了最后一个值为 1 的元素外，其余都是
    0。所以，这是机器学习标记输出的一个有用方法。这是我们获取数据的方式，我们将会使用它；这对于我们实际使用 TensorFlow 时更有帮助，但对于 scikit-learn
    实际上确实需要数值。
- en: 'Let''s understand the data before we dive in and do some actual machine learning.
    We have the `mnist` variable, and it''s already separated into training and testing
    data. With machine learning, you don''t want to train on all of your data; you
    don''t want to build your model with all of your data because then you won''t
    know how well it''s going to handle new data examples that it hasn''t seen before.
    What you want to do is split it into training data and testing data. So, the training
    data is going to build a model, and the test data is going to validate it. So,
    the splitting of the data is already done for us, just with the following variables:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入实际机器学习之前，让我们先了解数据。我们有 `mnist` 变量，它已经按照训练和测试数据分开。在机器学习中，你不想用所有数据来训练；你不想用所有数据来构建你的模型，因为那样你就不知道它将如何处理之前未见过的新的数据例子。你想要做的是将其分成训练数据和测试数据。所以，训练数据将用来构建模型，而测试数据将用来验证它。所以，数据的分割已经为我们完成，只需要以下变量：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Let's break down the code for better understanding.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解代码以更好地理解。
- en: 'Firstly, we load `train_data` from `train.images`, as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们按照以下方式从 `train.images` 加载 `train_data`：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We''re going to see what the shape is to understand it using `.shape`, as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `.shape` 来查看形状，以便理解它，如下所示：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you need to know the number of samples, we can extract that from the `shape`
    output, as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要知道样本数量，我们可以从 `shape` 输出中提取，如下所示：
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Again, it is a NumPy array, so all NumPy functions and features are there.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，它是一个 NumPy 数组，所以所有 NumPy 函数和特性都在那里。
- en: 'Then, execute the following code for `train_labels`:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，执行以下代码以获取 `train_labels`：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here, we just see where the `train.label` equals `1` and we extract that to
    create an array of those values, which will give us our `train_labels`. So, a
    1D array corresponds to the number of examples where it contains the actual output
    of each one. We'll see just an example; let's take `1000` out of `55000` training
    examples.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只查看 `train.label` 等于 `1` 的位置，并提取这些值以创建一个包含这些值的数组，这将给我们 `train_labels`。所以，一个一维数组对应于包含每个实际输出的例子数量。我们将只看一个例子；让我们从
    `55000` 个训练例子中取出 `1000` 个。
- en: 'Running this code gives us the following output:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码将给出以下输出：
- en: '![](img/3e3c2879-f179-4de7-94b3-99c325736b94.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3e3c2879-f179-4de7-94b3-99c325736b94.png)'
- en: '`784` is the number of pixels in the image and that''s because they are `28`
    by `28` squares, *28 x 28 = 784*. So, we have, `55000` examples `784` pixels,
    or we call them features, and then the `train_labels` is going to be of length
    `55000` and the other dimension is just `1`. Here''s an example. This data already
    comes in a 1D array, so that was why we used the `reshape` function and passed
    the `28` by `28` value, in order to convert it to an actual image that we can
    see.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`784` 是图像中的像素数，因为它们是 `28` x `28` 的方块，*28 x 28 = 784*。所以，我们有 `55000` 个例子，每个例子有
    `784` 个像素，或者我们称之为特征，然后 `train_labels` 的长度将是 `55000`，另一个维度只是 `1`。这里有一个例子。这些数据已经以
    1D 数组的形式提供，这就是为什么我们使用了 `reshape` 函数并传递了 `28` x `28` 的值，以便将其转换为我们可以看到的实际图像。'
- en: Great, our data is loaded and processed and is ready to be used, so we can begin
    actual machine learning. Now that our data is set up and ready to go, we can move
    on to our next section, in which we will create and train our support vector machine
    and perform our digit classification.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了，我们的数据已加载并处理完毕，准备使用，因此我们可以开始实际的机器学习。现在我们的数据已经设置好并准备就绪，我们可以继续到下一节，在那里我们将创建和训练我们的支持向量机，并执行我们的数字分类。
- en: Creating and training a support vector machine
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和训练支持向量机
- en: In this section, we're going to create and train a support vector machine that
    will actually perform our digit classification.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将创建并训练一个支持向量机，该机器将实际执行我们的数字分类。
- en: In the very first example, we're going to use scikit-learn, and we're going
    to use what's called a support vector machine, which is a very powerful, very
    versatile classic machine learning technique that can learn all kinds of functions
    and all kinds of mappings from inputs to outputs. We're going to do classification,
    which is mapping inputs as an array of pixels, and in our case we're going to
    classify each input into one of ten classes, corresponding to ten digits. But
    we can classify different kinds of things as continuous ordered functions, which
    is called regression, and that can be useful, for example, if you want to extract
    position or an area of volume where it doesn't just fit into a neat category.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个例子中，我们将使用scikit-learn，我们将使用所谓的支持向量机，这是一种非常强大、非常通用的经典机器学习技术，可以学习各种函数和从输入到输出的各种映射。我们将进行分类，即映射输入为一个像素数组，在我们的情况下，我们将把每个输入分类到十个类别之一，对应于十个数字。但我们可以将不同类型的事物分类为连续有序函数，这被称为回归，这可能很有用，例如，如果你想提取位置或体积区域，它不仅仅适合于一个整洁的分类。
- en: 'For this section, we''re going to be doing primarily classification. So, scikit-learn
    makes it very easy to create such a model. A support vector classifier can be
    called with `svm.SVC`, in which support vector machine came from `sklearn` package and
    we have this meta parameter for the model called `gamma`, just kind of an inverse
    radius, the area of influence of the sport vectors, as shown in the following
    code:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本节，我们将主要进行分类。因此，scikit-learn使得创建此类模型变得非常简单。可以使用`svm.SVC`调用支持向量分类器，其中支持向量机来自`sklearn`包，我们为模型有一个名为`gamma`的元参数，它类似于半径的倒数，是支持向量的影响区域，如下面的代码所示：
- en: '[PRE11]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: How the support vector machine works is not covered here, as there is plenty
    of literature available on that subject, and it's not absolutely necessary to
    understand it fully in order to learn it. Now, we're just going to see how we
    can apply this for some cases.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机的工作原理在此处没有涉及，因为关于这个主题有大量的文献，并且为了学习它，并不绝对有必要完全理解它。现在，我们只是看看我们如何将其应用于某些情况。
- en: The `gamma` parameter is something I recommend you experiment with as an exercise.
    We're going to start with a known `gamma` parameter that will work well for our
    case, namely `.001`, but you should learn about the other parameters that are
    available. I recommend going to [http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html](http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html) and
    again I recommend playing with this to see how it affects execution time and accuracy. But,
    what's important to take away here is that we can create our model with just one
    line. It defines the model but we haven't actually trained it. We haven't actually
    given any data and made it fit its parameters such that it will actually produce
    a desirable output. Now, if we feed it an image of five, it will say, that's OK,
    this is a 5\. So, in order to do that, we have to fit it.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`gamma`参数是我建议你作为练习进行实验的东西。我们将从一个已知的工作良好的`gamma`参数开始，即`.001`，但你应该了解其他可用的参数。我建议你访问[http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html](http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html)，并且我再次建议你尝试使用它来查看它如何影响执行时间和准确性。但是，这里重要的是我们要知道我们可以用一行代码创建我们的模型。它定义了模型，但我们实际上并没有训练它。我们实际上没有提供任何数据，也没有调整其参数，以便它能够产生期望的输出。现在，如果我们给它一个五的图像，它会说，没问题，这是一个5。所以，为了做到这一点，我们必须对其进行拟合。'
- en: In the preceding code, we have created our classifier and it's very simple: `classifier.
    fit`. We give it the `train_data` and the `train_labels` that we got from our
    previous code execution. Just a heads up, this execution is going to take a few
    minutes; it generally does. Usually, the training process is the slowest part
    of machine learning. That's typically the case but this shouldn't be too bad.
    This only takes a couple of minutes and, again, we're just using your training
    data so that we can verify that this will generalize to unseen cases.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们创建了我们的分类器，它非常简单：`classifier.fit`。我们给它我们从前一个代码执行中获得的`train_data`和`train_labels`。提前提醒一下，这个执行将需要几分钟；通常是这样的。通常，训练过程是机器学习中最慢的部分。这通常是情况，但这不应该太糟糕。这只需要几分钟，而且，我们再次只是使用您的训练数据，这样我们就可以验证这将对未见案例进行泛化。
- en: Now that we've seen our support vector machine and it's actually been trained,
    we can move on to our next section, where we apply the support vector machine
    to new data that it was not trained upon.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了我们的支持向量机，并且它实际上已经被训练了，我们可以继续到下一个部分，在那里我们将支持向量机应用于它未训练过的新的数据。
- en: Applying the support vector machine to new data
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将支持向量机应用于新数据
- en: Now that we have our trained support vector machine, we can actually apply the
    support vector machine to new data that hasn't been seen and see that our digit
    classifier is actually working.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了我们的训练支持向量机，我们可以实际上将支持向量机应用于未见过的新的数据，并看到我们的数字分类器实际上是否在起作用。
- en: 'After the cell has executed successfully and if everything worked correctly,
    we should see the following output:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 细胞执行成功并且如果一切正常工作，我们应该看到以下输出：
- en: '![](img/b80dd4a3-bab1-4049-b30c-1781e67d40e6.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b80dd4a3-bab1-4049-b30c-1781e67d40e6.png)'
- en: This is just the output from creating the support vector classifier. This just
    gives information about the metadata parameters that we used; we used what's known
    as a radial basis function kernel, and fitting the data did not produce any error
    messages. So, that means the code has worked. So, now we have our trained model,
    we want to see how well it's going to work on data that it hasn't seen.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是创建支持向量分类器的输出。这仅仅提供了我们使用的元数据参数的信息；我们使用了所谓的径向基函数核，拟合数据没有产生任何错误信息。所以，这意味着代码已经工作。所以，现在我们有了我们的训练模型，我们想看看它在它未见过的数据上表现如何。
- en: 'Now, we''re going to get our test data, as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将获取我们的测试数据，如下所示：
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We get our `mnist.test.images`, which is equal to `mnist.train.images`, and
    extract the labels the same way, by calling the `expected` variable, and then
    we're going to compute `predicted` from the `classifier` model, using `classifier.predict(test_data)`.
    So, this is going to take just a little bit of time to execute. After execution,
    there should be no error messages, which indicates that our prediction ran successfully.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获取`mnist.test.images`，它等于`mnist.train.images`，并以相同的方式提取标签，通过调用`expected`变量，然后我们将从`classifier`模型计算`predicted`，使用`classifier.predict(test_data)`。所以，这需要一点时间来执行。执行后，应该没有错误信息，这表明我们的预测运行成功。
- en: 'So, now we can see how well we did. We''re going to use the built-in metrics
    functions from scikit-learn. We''re going to record some of the metrics, such
    as *precision* and *recall*, and if you want to understand what those mean, I
    recommend the following Wikipedia article:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在我们可以看到我们做得怎么样。我们将使用scikit-learn的内置度量函数。我们将记录一些度量，例如*精确度*和*召回率*，如果您想了解这些含义，我推荐以下维基百科文章：
- en: '[https://en.wikipedia.org/wiki/Precision_and_recall_to_understand_metric_definitions](https://en.wikipedia.org/wiki/Precision_and_recall_to_understand_metric_definitions)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://zh.wikipedia.org/wiki/精确度与召回率](https://zh.wikipedia.org/wiki/%E7%B2%BE%E7%A1%AE%E5%BA%A6%E4%B8%8E%E5%9B%9E%E5%8F%94%E7%8E%87)'
- en: 'Just in short, they are different metrics for evaluating how well your machine
    learning algorithm did. Accuracy is probably the most common. It''s simple: the
    correct data points divided by the total. But there''s also precision recall that
    weighs the pros and cons with true positives, true negatives, false positives,
    and false negatives, and which one is the best depends on your application. It
    depends on which is worse between the false positive and the false negative and
    so forth and, on top of that, we''re going to output what''s known as a confusion
    matrix, which tells you which ones were successful and which ones were misclassified.
    Let''s run the following code:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，它们是评估你的机器学习算法表现如何的不同指标。准确率可能是最常用的。它是简单的：正确数据点除以总数。但也有精确率和召回率，它权衡了真实阳性、真实阴性、假阳性和假阴性，哪个是最好的取决于你的应用。它取决于假阳性和假阴性哪个更糟糕，以及如此等等。此外，我们还将输出所谓的混淆矩阵，它告诉你哪些是成功的，哪些被错误分类了。让我们运行以下代码：
- en: '[PRE13]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'It should give us the following output:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 它应该给出以下输出：
- en: '![](img/634bd8ef-8432-49da-b72a-381338a357ba.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/634bd8ef-8432-49da-b72a-381338a357ba.png)'
- en: 'OK, so we get the classification reports and we can see `precision`, `recall`,
    and another metric called `f1-score` that you can read about in that same Wikipedia
    article. In short, zero is the worst case and one is the best case. In the preceding
    screenshot, we can see `precision`, `recall`, and `f1-score` for the different
    digits and we can see we''re in the 90% range; it varies, which is OK. It depends
    on your application, but that might be good enough or that might be abysmally
    bad. It depends. We''re actually going to see how we can do better a little later
    on using a more powerful model. We can see that it generally worked. We look at
    the confusion matrix here, where the columns tell you what the actual value is
    and the rows tell you what the predicted value is. Ideally, we would see all large
    values along the diagonal and all zeroes otherwise. There''s always going to be
    some errors, we''re human beings so that''s going to happen but like I said, we''re
    going to see if we can do a little bit better, in vast majority of cases it did
    work. Now, we can see some example random outputs, where we had some digits as
    follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，所以我们得到了分类报告，我们可以看到`precision`（精确率）、`recall`（召回率）以及另一个称为`f1-score`的指标，你可以在同一篇维基百科文章中了解到这些。简而言之，零是最坏的情况，一是最理想的情况。在先前的屏幕截图中，我们可以看到不同数字的`precision`、`recall`和`f1-score`，我们可以看到我们处于90%的范围内；它有所变化，这是可以接受的。它取决于你的应用，但这可能已经足够好了，或者可能非常糟糕。这取决于。我们实际上稍后会看到如何使用更强大的模型做得更好。我们可以看到它总体上是有效的。我们来看看混淆矩阵，其中列告诉你实际值是什么，行告诉你预测值是什么。理想情况下，我们会看到对角线上的所有大值，其他地方都是零。总是会有一些错误，因为我们都是人类，所以这种情况会发生，但就像我说的，我们将看看是否可以做得更好，在大多数情况下，它确实有效。现在，我们可以看到一些随机输出的示例，其中有一些数字如下：
- en: '![](img/1677df97-8bed-4199-9ac3-bb9ac2f3ae4b.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1677df97-8bed-4199-9ac3-bb9ac2f3ae4b.png)'
- en: 'As we can see, all of the predictions are correct according to their images.
    OK, that''s all well and good but I kind of feel like I''m taking the computer''s
    word for it at this point. I''d like to throw my own data at it. I''d like to
    see how well this is really working, and this is something generally recommended
    with machine learning. You want to test it with your own data to really know if
    it''s working and, if nothing else, it''s much more satisfying. So, here is a
    little snippet of code that''s going to use Jupyter''s widget capabilities, its
    interactive capabilities:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，所有的预测都根据它们的图像是正确的。好吧，一切都很好，但我感觉我现在有点是在相信计算机的话了。我想用我自己的数据来测试它。我想看看这实际上工作得怎么样，这在机器学习中通常是一个推荐的步骤。你想要用你自己的数据来测试它，以便真正知道它是否在正常工作，而且，如果不是其他原因，这会让人感到更加满意。所以，这里有一小段代码，它将使用Jupyter的小部件功能，它的交互功能：
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: So, now we're actually going to create a little drawing widget. It's going to
    let us produce our own digits. Let's look at the code.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在我们实际上要创建一个小绘图小部件。它将允许我们生成自己的数字。让我们看看代码。
- en: 'Let''s import `Line2D` from `matpllotlib.line`, this is going to let us draw
    individual lines, like creating a kind of a vector image based on our mouse movements:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从`matplotlib.line`导入`Line2D`，这将允许我们绘制单独的线条，就像根据我们的鼠标移动创建一种矢量图像一样：
- en: '[PRE15]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We execute `%pylab notebook`; the percent sign indicates the following magic
    command:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行`%pylab notebook`；百分号表示以下魔法命令：
- en: '[PRE16]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: It's kind of a meta command within Jupyter and Pylab Notebook, and it loads
    a bunch of stuff into your namespace for plotting and numerics. It's not necessary
    because we already did that with NumPy and Matplotlib, but to enable the widgets,
    we use this command.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种Jupyter和Pylab笔记本中的元命令，它将大量内容加载到你的命名空间中用于绘图和数值计算。这不是必需的，因为我们已经用NumPy和Matplotlib做了这件事，但为了启用小部件，我们使用这个命令。
- en: 'Then, create this `Annotator` class, which contains call back for what happens
    if we move a mouse over our displayed image, as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，创建这个`Annotator`类，它包含当我们在显示的图像上移动鼠标时发生回调的代码，如下所示：
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We don't have to understand the `Annotator` class, but this might be something
    useful in the future if you want to make an annotation or draw something, and
    to seize a full snippet of code.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要理解`Annotator`类，但如果你将来想要进行标注或绘制某些内容，以及获取完整的代码片段，这可能会很有用。
- en: 'Then, we''re going to create a blank image, the same size as our images. It''s
    just going to be three RGBs for the time being. It just looks a little bit nicer,
    even though we''re going to make it black and white in the end, because that''s
    what our data is. Create the image as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将创建一个空白图像，大小与我们的图像相同。目前它只是三个RGB值。即使我们最终会将其变为黑白，因为它就是我们的数据。创建图像如下：
- en: '[PRE18]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, create a plot, show it, and hook up our `annotator` functions to that,
    as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建一个图表，显示它，并将我们的`annotator`函数连接到它，如下所示：
- en: '[PRE19]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After running the code, we should get the following output:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码后，我们应该得到以下输出：
- en: '![](img/7e873b37-046c-4f77-aaaf-caad496ca0d9.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7e873b37-046c-4f77-aaaf-caad496ca0d9.png)'
- en: 'So, let''s draw, say, the numeral three:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们画一下数字三：
- en: '![](img/3e1d18ae-a7b8-44d6-a4d5-27d8be21a696.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3e1d18ae-a7b8-44d6-a4d5-27d8be21a696.png)'
- en: 'Now, that''s sluggish you know, and isn''t exactly going to replace Photoshop,
    but this still beats going into a separate program and creating your image file,
    making sure it''s in the right format, saving it, and then writing code to load
    it and get it right. So, this will allow us to quickly play and experiment with
    our models. We just created a kind of array of lines, so we need to rasterize
    that and process it so that it looks more like actual handwritten digits, something
    that would come from either a scanned pencil drawing or a pressure-sensitive tablet.
    The following will do this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这有点慢，而且并不完全能替代Photoshop，但这种方法仍然比进入一个单独的程序创建图像文件、确保其格式正确、保存它，然后编写代码加载它并使其正确要快。因此，这将使我们能够快速地玩和实验我们的模型。我们刚刚创建了一种线数组，因此我们需要将其光栅化并处理，使其看起来更像实际的手写数字，这可能是来自扫描的铅笔草图或压力感应平板。以下是如何做到这一点：
- en: '[PRE20]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s look at the code. First, we create a blank image, as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看代码。首先，我们创建一个空白图像，如下所示：
- en: '[PRE21]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We iterate over the `xy` pairs that came from our `annotator` and then we''re
    going to draw lines there in raster format on our rasterized images, as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历来自`annotator`的`xy`对，然后我们将在光栅化图像上绘制线条，如下所示：
- en: '[PRE22]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then, we convert the image to a `float`, from range `0` to `1`, just like our
    input data, as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将图像转换为`float`类型，范围从`0`到`1`，就像我们的输入数据一样，如下所示：
- en: '[PRE23]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, we are going to bring it a little bit closer to `1`, because that''s
    just what our input images look like and what our model would be expecting:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将它稍微调整得更接近`1`，因为这就是我们的输入图像看起来像的，以及我们的模型所期望的：
- en: '[PRE24]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Then, we have our two-dimensional image but, of course, to run it through our
    model, we need to flatten it into `1` x `784`, so that''s what this `reshape`
    function does:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们有了二维图像，但当然，为了运行它通过我们的模型，我们需要将其展平为`1` x `784`，这就是`reshape`函数的作用：
- en: '[PRE25]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Then, we''re going to run that through our `classifier` and print the output
    as well. We will create a figure where we can see what our rasterized image looks
    like, as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将运行它通过我们的`classifier`，并打印输出。我们将创建一个图表，我们可以看到我们的光栅化图像如下所示：
- en: '[PRE26]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We should get the following output:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该得到以下输出：
- en: '![](img/64e0f2af-31ab-4e3d-8457-e65f326b3aaa.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/64e0f2af-31ab-4e3d-8457-e65f326b3aaa.png)'
- en: We drew a three and we predicted a `3`. Excellent. Let's try something else.
    Clear the previous output by hitting *Ctrl* + *Enter*, and we get a warning message;
    it's just telling us that it has clobbered some of the variables that were created.
    That's not a big deal. You can safely ignore that. Just a fair warning, your mileage
    may vary on this, depending on what your handwriting is like and what was in your
    training data. If you wanted this to work perfectly every time, or as close to
    that as possible, you want to train it probably on your own handwriting.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们画了一个三，预测结果是 `3`。太棒了。让我们尝试其他的东西。通过按 *Ctrl* + *Enter* 清除之前的输出，我们得到一个警告信息；它只是告诉我们它覆盖了一些创建的变量。这不是什么大问题。你可以安全地忽略它。只是提前提醒，你的使用效果可能会有所不同，这取决于你的书写风格和训练数据中的内容。如果你希望每次都能完美工作，或者尽可能接近完美，你可能需要在自己的书写上训练它。
- en: 'Let''s try a zero:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一个零：
- en: '![](img/54ef84b4-a1ba-4453-b443-57ad38f50a2d.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/54ef84b4-a1ba-4453-b443-57ad38f50a2d.png)'
- en: 'The following is the output:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '![](img/980d11b9-8013-4631-8cba-0c53e53a8f3a.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/980d11b9-8013-4631-8cba-0c53e53a8f3a.png)'
- en: So, here you can see an example of it not working. The prediction is supposed
    to be zero but the model predicted a three for some reason. It's possible that
    if you redraw it, it might work. So, again, your mileage may vary. Experiment
    with it. You can also play with the preprocessing, although this, as far as I
    can tell, works pretty well. But anyway, we can see that our model is, at least
    for the most part, working. So, that's going to be it for the scikit-learn support
    vector machines. Now, in our next section, we're going to introduce TensorFlow
    and perform digit classification with that.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以看到它不起作用的例子。预测应该是零，但模型不知何故预测了三。有可能如果你重新绘制它，它可能会工作。所以，再次提醒，你的使用效果可能会有所不同。你可以尝试实验，你也可以玩玩预处理，尽管据我所知，这工作得相当好。但无论如何，我们可以看到我们的模型至少在大部分情况下是正常工作的。所以，关于
    scikit-learn 支持向量机的内容就到这里了。现在，在我们下一节中，我们将介绍 TensorFlow 并使用它进行数字分类。
- en: Introducing TensorFlow with digit classification
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数字分类介绍 TensorFlow
- en: We're going to see TensorFlow in action and see how we can perform digit classification
    with a tractable amount of code. TensorFlow is Google's machine learning library,
    for numerical analysis in general. It is called TensorFlow because it supposedly
    flows tensors, where tensors are defined to be arrays of *n* dimensions. Tensors
    have a real geometric meaning that just multidimensional arrays don't necessarily
    classify, but we're just going to use that term. A tensor is just a multidimensional
    array.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到 TensorFlow 的实际应用，并了解如何用可管理的代码量进行数字分类。TensorFlow 是 Google 的机器学习库，用于一般的数值分析。它被称为
    TensorFlow，因为它据说可以流动张量，其中张量被定义为 *n* 维的数组。张量具有多维数组所不具备的真正几何意义，但我们只是使用这个术语。张量只是一个多维数组。
- en: 'Here, we''re going to do a simple `softmax` example. It''s a very simple model;
    you can visit TensorFlow''s own website ([https://www.tensorflow.org/get_started/mnist/beginners](https://www.tensorflow.org/get_started/mnist/beginners))
    for more information. Let''s have a look at the following code:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将进行一个简单的 `softmax` 示例。这是一个非常简单的模型；你可以访问 TensorFlow 的官方网站 ([https://www.tensorflow.org/get_started/mnist/beginners](https://www.tensorflow.org/get_started/mnist/beginners))
    获取更多信息。让我们看一下以下代码：
- en: '[PRE27]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In short, you're going to take your input data and you're going to multiply
    it by a matrix. The data has `784` points. Each point is going to have a matrix
    value and, for each of the `10` classes, you're going to compute an inner product
    by multiplying 784 × 784 and sum them up. There will be `10` outputs. It will
    be a 1 by 10 array, and you're going to add a bias variable to the output of the
    array and run it through the `softmax` function, which will convert it to something.
    The output of the matrix plus the bias will compute something in the range of
    `0` to `1`, which loosely corresponds to the probability of that data being in
    that class. For example, there might be a 0.4% probability or 40% probability
    of being a `1`, a 2% probability of being it `2`, and 90% probability of it being
    a `9`, and the output is going to be the maximum output of that.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，你将取你的输入数据，并将其乘以一个矩阵。数据有`784`个点。每个点都有一个矩阵值，对于`10`个类别中的每一个，你将通过乘以784 × 784并求和来计算一个内积。将会有`10`个输出。它将是一个1乘以10的数组，你将向数组的输出添加一个偏置变量，并通过`softmax`函数运行它，这将将其转换为某种东西。矩阵的输出加上偏置将计算一个在`0`到`1`范围内的值，这大致对应于该数据属于该类别的概率。例如，可能有一个0.4%的概率或40%的概率是`1`，2%的概率是`2`，90%的概率是`9`，输出将是那个最大输出。
- en: 'TensorFlow is very sophisticated. There''s a little bit more setup here than
    there was with the scikit-learn example. You can learn more about that on their
    own website. Now, let''s go through the following code in detail:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow非常复杂。这里的设置比scikit-learn示例中要复杂一些。你可以在他们的网站上了解更多信息。现在，让我们详细地通过以下代码：
- en: '[PRE28]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We've already done this in the previous example. Now, we're going to get the
    data from `data_dir`; make sure it's in our `mnist` variable.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在前面的例子中这样做过了。现在，我们将从`data_dir`获取数据；确保它在我们的`mnist`变量中。
- en: 'Then, we create the model where `x` corresponds to our input data and, although
    we''re not loading the data just yet, we just need to create a placeholder so
    TensorFlow knows where stuff is. We don''t need to know how many examples there
    are, and that''s what the `None` dimension corresponds to, but we do need to know
    how big each example is, which in this case is `784`. `W` is the matrix that''s
    going to multiply `x` classes to the inner product over the image, `784` *dot*
    `784`, and you do that `10` times. So, that corresponds to a 784/10 matrix, `10`
    being the number of classes; then, you add the `b` bias variable to that. The
    values of `W` and `b` are what TensorFlow is going to produce for us based on
    our inputs, and `y` defines the actual operation that''s going to be performed
    on our data from the matrix multiplication. We add the `b` bias variable to it
    as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建模型，其中`x`对应于我们的输入数据，尽管我们还没有加载数据，但我们只需要创建一个占位符，这样TensorFlow就知道东西在哪里了。我们不需要知道有多少个例子，这就是`None`维度的含义，但我们确实需要知道每个例子有多大，在这个例子中是`784`。`W`是乘以`x`类别的矩阵，对图像进行内积，`784`
    *点* `784`，你这样做`10`次。所以，这对应于一个784/10的矩阵，`10`是类别的数量；然后，你向那个添加`b`偏置变量。`W`和`b`的值是TensorFlow将根据我们的输入为我们产生的，`y`定义了对我们的数据进行矩阵乘法时实际要执行的操作。我们按照以下方式向它添加`b`偏置变量：
- en: '[PRE29]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We need to create a placeholder for our labeled data, as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为我们的标记数据创建一个占位符，如下所示：
- en: '[PRE30]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In order to do machine learning, you need a `loss` function or a `fitness`
    function, which tells you how well your model is doing given learning parameters
    like those given in `W` and `b`. Hence, we''re going to use something called `cross-entropy`;
    we''ll not go into much detail about `cross-entropy` but that''s going to give
    us some criteria for letting us know that we''re getting closer to a working model,
    as shown in the following lines of code:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行机器学习，你需要一个`损失`函数或`适应度`函数，它告诉你根据像`W`和`b`这样的学习参数，你的模型做得有多好。因此，我们将使用所谓的`交叉熵`；我们不会深入讨论`交叉熵`，但那将给我们一些标准，让我们知道我们正在接近一个工作的模型，如下面的代码行所示：
- en: '[PRE31]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: As we add more and more data, we're going to use what's known as `GradientDescentOptimizer`
    in order to minimize the error, minimize the cross entropy, and make our model
    fit as well as possible.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们添加越来越多的数据，我们将使用所谓的`GradientDescentOptimizer`来最小化误差，最小化交叉熵，并尽可能使我们的模型拟合得更好。
- en: 'In the following code, we''re actually going to start by creating an interactive
    session, as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们实际上将首先创建一个交互式会话，如下所示：
- en: '[PRE32]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We want to make it an interactive session so that we can use our model and buy
    new data to it afterwards. We're going to initialize `run()` and then we're going
    to compute the data in batches. TensorFlow is a very powerful program and it allows
    you to break up your data. We're not going to do it here, but you can run parallelized
    code fairly easily with it. Here, we're just going to iterate `1000` times and
    compete stuff in batches feeding in our training data.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望使其成为一个交互式会话，这样我们就可以在之后使用我们的模型并给它添加新数据。我们将初始化`run()`，然后我们将分批计算数据。TensorFlow是一个非常强大的程序，它允许你分割你的数据。我们在这里不会这样做，但你可以用它轻松地运行并行化代码。在这里，我们将迭代`1000`次，并在分批中输入我们的训练数据。
- en: 'After this runs, we''re going to see how well we did and just see where our
    predicted data is equal to the given labels to it. We can compute the `accuracy`
    by just seeing how many of the predictions were correct on average. Then, print
    that data, as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行之后，我们将看看我们做得如何，并查看我们的预测数据与给定的标签相等的部分。我们可以通过查看平均有多少预测是正确的来计算`accuracy`。然后，按照以下方式打印数据：
- en: '[PRE33]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The following is the output:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对应的输出：
- en: '![](img/4d8cf5fb-5bb4-4041-8402-1629d6cee9ee.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4d8cf5fb-5bb4-4041-8402-1629d6cee9ee.png)'
- en: Being a really simple model, it runs a lot faster and we can see that we got
    a little less than 92% accuracy. The code executed a lot faster, but a little
    bit less accurately than our **Support Vector Machine** (**SVM**), but that's
    OK. This code just provides a very simple example of how TensorFlow works.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个非常简单的模型，它运行得很快，我们可以看到我们得到了不到92%的准确率。代码执行得更快，但准确率略低于我们的**支持向量机**（**SVM**），但这没关系。这段代码只是提供了一个TensorFlow如何工作的非常简单的例子。
- en: 'You get a little bit more advanced momentarily, but let''s test the following
    code the way we did before:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 你会很快变得稍微高级一些，但让我们像之前一样测试以下代码：
- en: '[PRE34]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We get the following output:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了以下输出：
- en: '![](img/1af2c010-209e-41b9-913d-923e77aec493.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1af2c010-209e-41b9-913d-923e77aec493.png)'
- en: 'Our annotator is initiated and let''s put in a digit. Try a `3`:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始化了注释器，并输入一个数字。试一个`3`：
- en: '![](img/15a25209-0eed-4937-9a5a-7256ffe39d97.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](img/15a25209-0eed-4937-9a5a-7256ffe39d97.png)'
- en: 'Now, we''re going to preprocess the drawn digit and it''s almost the same code
    as before, which is going to go through the classes and possible classes for our
    data and see which one the TensorFlow `softmax` model thought was the best:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将对绘制的数字进行预处理，这几乎与之前的代码相同，它将遍历我们的数据及其可能的类别，看看TensorFlow的`softmax`模型认为哪个是最好的：
- en: '[PRE35]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'So, we''ll run the preceding block and, as shown, it predicts a `3` from a
    `3`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将运行前面的代码块，如图所示，它从`3`预测出`3`：
- en: '![](img/a71f2e2c-549b-42f8-9450-31496778a708.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a71f2e2c-549b-42f8-9450-31496778a708.png)'
- en: 'Sometimes it might not predict correctly, and that is unfortunately going to
    happen. So, there are two ways to improve that: train on your own handwriting
    or use a better model.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 有时它可能无法正确预测，这很遗憾。所以，有两种方法可以改进：在自己的手写数据上训练或使用更好的模型。
- en: We are going to move on to the most powerful model in this section. Here, we're
    going to just briefly touch on deep learning with, **convolutional neural networks**
    (**CNNs**). We are not covering the theory here. There's a lot to know about deep
    learning and multi-layered neural networks in general. Deep learning is a deep
    subject but, for this chapter, we're just going to see how we can actually apply
    state-of-the-art machine learning techniques to digit recognition with a relatively
    simple block of code.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将进入本节中最强大的模型。在这里，我们将简要介绍使用**卷积神经网络**（**CNNs**）的深度学习。这里我们不涉及理论。关于深度学习和多层神经网络有很多东西要了解。深度学习是一个深奥的主题，但在这个章节中，我们将看看我们如何实际上使用相对简单的代码块将最先进的机器学习技术应用于数字识别。
- en: 'So, we have a `deepnn(x)` function here that creates our deep neural network,
    finds our hidden layers or convolutional layers, pools, and so forth, and defines
    all our necessary stuff from our input:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们这里有一个`deepnn(x)`函数，它创建我们的深度神经网络，找到我们的隐藏层或卷积层，池化层等等，并定义了我们从输入所需的所有内容：
- en: '[PRE36]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '`deepnn` builds the graph for a deep net for classifying digits and `reshape` function
    is to be used within a convolutional neural net. The arguments used here are:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`deepnn`构建用于对数字进行分类的深度网络图，`reshape`函数是在卷积神经网络中使用。这里使用的参数是：'
- en: '`x`: An input tensor with the dimensions (`N_examples`, `784`), where `784`
    is the number of pixels in a standard MNIST image.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：一个具有维度（`N_examples`, `784`）的输入张量，其中`784`是标准MNIST图像中的像素数。'
- en: '`y`: A tensor of shape (`N_examples`, `10`), with values equal to the logic''s
    of classifying the digit into one of 10 classes (the digits 0-9). `keep_prob`
    is a scalar placeholder for the probability of dropout.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y`：一个形状为(`N_examples`, `10`)的张量，其值等于将数字分类到10个类别（数字0-9）的逻辑。`keep_prob`是一个表示dropout概率的标量占位符。'
- en: This returns a tuple (`y`, `keep_prob`). The last dimension is for *features*—there
    is only one here, since images are grayscale—it would be 3 for an RGB image, 4
    for RGBA, and so on.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回一个元组(`y`, `keep_prob`)。最后一个维度是用于*特征*的——这里只有一个，因为图像是灰度的——对于RGB图像将是3，对于RGBA将是4，依此类推。
- en: 'The first convolutional layer maps one grayscale image to `32` feature maps:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个卷积层将一个灰度图像映射到`32`个特征图：
- en: '[PRE37]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We have our functions that do convolutions, weight variables, bias variables,
    and so forth. Then, we have our main code here:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有执行卷积、权重变量、偏置变量等函数。然后，我们有这里的主要代码：
- en: '[PRE38]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The `mnist` variable gets the data in case we don't already have it. We define
    our placeholder for the input, and the outputs build the graph. We then define
    the `fitness` function and `cross-entropy` and create our graph. We have to be
    careful while creating the session; in the example on their website, they just
    created a normal session. We want an interactive session here, so that we can
    apply our model to our own generated data, and we're going to break this up into
    batches. We'll run it, and every `100` iterations it's going to tell us what exactly
    it's doing and then, at the end, it will tell us our accuracy.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`mnist`变量获取数据，以防我们还没有它。我们定义了输入的占位符，输出构建了图。然后我们定义了`fitness`函数和`cross-entropy`并创建了我们的图。在创建会话时我们必须小心；在他们网站的示例中，他们只是创建了一个正常的会话。我们希望有一个交互式会话，这样我们就可以将我们的模型应用于我们自己生成数据，并且我们将将其分成批次。我们将运行它，每`100`次迭代它将告诉我们它正在做什么，然后，在最后，它将告诉我们我们的准确率。'
- en: 'Let''s run the code and extract the data, and you can see the statistics as
    follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行代码并提取数据，你可以看到以下统计数据：
- en: '![](img/820ee86a-10a9-4c9d-bac7-d4e93158c64e.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/820ee86a-10a9-4c9d-bac7-d4e93158c64e.png)'
- en: It starts off with very bad training accuracy but it quickly gets up to over
    90% and shoots up to `1`. It's not exactly 100%, but that usually means it's something
    like 99%, so pretty close to `1`. This usually takes a few minutes. OK, now we
    have created our TensorFlow classifier.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 它开始时的训练准确率非常差，但很快就上升到超过90%，然后跃升至`1`。它并不完全是100%，但通常这意味着它大约是99%，所以非常接近`1`。这通常需要几分钟。好的，现在我们已经创建了我们的TensorFlow分类器。
- en: Evaluating the results
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估结果
- en: 'After we finished training, as we can see from the following screenshot, we
    get a result of over 99%, so that is significantly better than what we got with
    `softmax` or our SVM:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们完成训练后，如以下截图所示，我们得到了超过99%的结果，这比我们用`softmax`或我们的SVM得到的结果要好得多：
- en: '![](img/4eabb374-6994-4a4b-a598-fa2b2b9b38bd.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4eabb374-6994-4a4b-a598-fa2b2b9b38bd.png)'
- en: Deep learning is probably the most powerful machine learning technique, due
    to its ability to learn very complex pattern recognition. It's just dominating
    everything else for advanced computer vision, speech processing, and more—stuff
    that conventional machine learning techniques haven't been all that successful
    at. However, that doesn't necessarily mean that you want to use deep learning
    for everything. Deep learning generally acquires a large number of examples—many
    thousands, if not millions sometimes—and it can also be very computationally expensive.
    So, it's not always the best solution, although it is very powerful, as we have
    seen right here. So, 99% is about as good as you can get.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习可能是有史以来最强大的机器学习技术，因为它能够学习非常复杂的模式识别。它几乎统治了所有其他技术，包括高级计算机视觉、语音处理等——这些是传统机器学习技术不太成功的领域。然而，这并不意味着你想要在所有事情上都使用深度学习。深度学习通常需要大量示例——有时是数千甚至数百万个示例——并且它也可能非常计算密集。因此，它并不总是最佳解决方案，尽管它非常强大，正如我们在这里所看到的。所以，99%几乎就是你能得到的最佳结果。
- en: 'The following is the code to draw digits:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码用于绘制数字：
- en: '[PRE39]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The following code rasterizes and preprocesses the handwritten digit image:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将手写数字图像进行光栅化和预处理：
- en: '[PRE40]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'So, let''s test it again on our handwritten digit `0`:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们再次在我们的手写数字`0`上测试它：
- en: '![](img/1880122f-8b2d-4199-b02f-e02ef3c0a43b.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1880122f-8b2d-4199-b02f-e02ef3c0a43b.png)'
- en: Again, we have similar code for processing the vectorized image, and we're getting
    the output and raster form and running it through our model, doing `accuracy.eval`
    here. As we can see in the preceding screenshot, we've got a zero as expected,
    and that's perfect. So,  we're going to be talking more about deep learning with
    CNNs in the next chapters, but we've already seen how powerful it is with relatively
    little code and we were able to fly it towards our particular problem of digit
    recognition. Alright, so, with that, we're going to move on to our next chapter,
    which is [Chapter 6](c59fb392-c966-4da6-987a-625378474e71.xhtml), *Facial Feature
    Tracking and Classification with dlib*.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，我们处理矢量化图像的代码是相似的，我们得到了输出和光栅化形式，然后将其通过我们的模型，在这里进行 `accuracy.eval`。正如我们可以在前面的屏幕截图中所见，我们得到了预期的零，这是完美的。因此，在下一章中，我们将更多地讨论使用
    CNN 的深度学习，但我们已经看到，它只需要相对较少的代码就非常强大，并且我们能够将其应用于我们特定的数字识别问题。好的，那么，有了这个，我们将继续进入下一章，即[第6章](c59fb392-c966-4da6-987a-625378474e71.xhtml)，*使用
    dlib 进行面部特征跟踪和分类*。
- en: Summary
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to perform digit classification with TensorFlow
    using `softmax`. We learned how to acquire and process MNIST digit data. We then
    learned how to create and train a support vector machine, and apply it to new
    data.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用 TensorFlow 的 `softmax` 进行数字分类。我们学习了如何获取和处理 MNIST 数字数据。然后我们学习了如何创建和训练支持向量机，并将其应用于新数据。
- en: In the next chapter, we will learn facial feature tracking and classification
    using dlib.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习使用 dlib 进行面部特征跟踪和分类。
