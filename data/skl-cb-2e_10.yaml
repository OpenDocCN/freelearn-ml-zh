- en: Text and Multiclass Classification with scikit-learn
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用scikit-learn进行文本和多类分类
- en: 'This chapter will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下食谱：
- en: Using LDA for classification
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LDA进行分类
- en: Working with QDA – a nonlinear LDA
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用QDA（非线性LDA）进行工作
- en: Using SGD for classification
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SGD进行分类
- en: Classifying documents with Naive Bayes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯分类文档
- en: Label propagation with semi-supervised learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 半监督学习中的标签传播
- en: Using LDA for classification
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LDA进行分类
- en: '**Linear discriminant analysis** (**LDA**) attempts to fit a linear combination
    of features to predict an outcome variable. LDA is often used as a pre-processing
    step. We''ll walk through both methods in this recipe.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性判别分析**（**LDA**）试图通过特征的线性组合来预测结果变量。LDA通常用作预处理步骤。我们将在本例中演示这两种方法。'
- en: Getting ready
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做好准备
- en: 'In this recipe, we will do the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将执行以下操作：
- en: Grab stock data from Google.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Google获取股票数据。
- en: Rearrange it in a shape we're comfortable with.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其重新排列成我们习惯的形式。
- en: Create an LDA object to fit and predict the class labels.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建LDA对象以拟合和预测类别标签。
- en: Give an example of how to use LDA for dimensionality reduction.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给出一个如何使用LDA进行降维的例子。
- en: 'Before starting on step 1 and grabbing stock data from Google, install a version
    of pandas that supports the latest stock reader. Do so at an Anaconda command
    line by typing this:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始第1步并从Google获取股票数据之前，安装一个支持最新股票读取器的pandas版本。可以在Anaconda命令行中输入以下命令：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Note that your pandas version will be updated. If this is a problem, create
    a new environment for this pandas version. Now open a notebook and check whether
    the `pandas-datareader` imports correctly:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，你的pandas版本将会更新。如果这成为问题，可以为当前的pandas版本创建一个新的环境。现在打开一个notebook，检查`pandas-datareader`是否能够正确导入：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If it is imported correctly, no errors will show up.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果导入正确，将不会显示任何错误。
- en: How to do it...
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'In this example, we will perform an analysis similar to Altman''s Z-score.
    In his paper, Altman looked at a company''s likelihood of defaulting within two
    years based on several financial metrics. The following is taken from the Wikipedia
    page of Altman''s Z-score:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将执行类似于Altman Z分数的分析。在他的论文中，Altman根据几个财务指标分析了一家公司在两年内违约的可能性。以下内容摘自Altman
    Z分数的维基百科页面：
- en: '| **Z-score formula** | **Description** |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| **Z分数公式** | **描述** |'
- en: '| *T1 = Working capital / Total assets* | This measures liquid assets in relation
    to the size of the company. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| *T1 = 营运资本 / 总资产* | 该指标衡量公司的流动资产与公司规模的关系。 |'
- en: '| *T2 = Retained earnings / Total assets* | This measures profitability that
    reflects the company''s age and earning power. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| *T2 = 留存收益 / 总资产* | 该指标衡量盈利能力，反映了公司的年龄和盈利能力。 |'
- en: '| *T3 = Earnings before interest and taxes / Total assets* | This measures
    operating efficiency apart from tax and leveraging factors. It recognizes operating
    earnings as being important to long-term viability. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| *T3 = 息税前利润 / 总资产* | 该指标衡量税收和杠杆因素之外的运营效率。它认为运营盈利对公司长期生存至关重要。 |'
- en: '| *T4 = Market value of equity / Book value of total liabilities* | This adds
    market dimension that can show up a security price fluctuation as a possible red
    flag. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| *T4 = 股本市值 / 总负债账面价值* | 这增加了市场维度，可以揭示证券价格波动作为潜在的预警信号。 |'
- en: '| *T5 = Sales / Total assets* | This is the standard measure for total asset
    turnover (varies greatly from industry to industry). |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| *T5 = 销售额 / 总资产* | 这是衡量总资产周转率的标准指标（不同产业之间差异很大）。 |'
- en: 'Refer to the article, *Financial Ratios, Discriminant Analysis and the Prediction
    of Corporate Bankruptcy*, by Altman, Edward I. (September 1968), Journal of Finance:
    189–209.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 参考Altman, Edward I.（1968年9月）发表的文章《*财务比率、判别分析与公司破产预测*》，《金融学杂志》：189–209。
- en: In this analysis, we'll look at some financial data from Google via pandas.
    We'll try to predict whether a stock will be higher in exactly six months from
    today based on the current attribute of the stock. It's obviously nowhere near
    as refined as Altman's Z-score.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本分析中，我们将通过pandas查看来自Google的财务数据。我们将尝试预测基于当前股票属性，六个月后的股价是否会更高。显然，这远不如Altman的Z分数那样精确。
- en: 'Begin with a few imports and by storing the tickers you will use, the first
    date, and the last date of the data:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先进行几个导入，并存储你将使用的股票代码、数据的开始日期和结束日期：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, let''s pull the stock data:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们获取股票数据：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This data structure is a panel from pandas. It''s similar to an **online analytical
    processing** (**OLAP**) cube or a 3D dataframe. Let''s take a look at the data
    to get more familiar with the closes since that''s what we care about when comparing:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个数据结构是 pandas 中的一个面板。它类似于 **在线分析处理** (**OLAP**) 立方体或 3D 数据框。让我们来看一下数据，更加熟悉一下收盘价，因为在比较时，我们关心的就是这些：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following is the output:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '![](img/01c78109-cbbb-4a0e-8d89-ae29c7316169.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/01c78109-cbbb-4a0e-8d89-ae29c7316169.png)'
- en: Okay, so now we need to compare each stock price with its price in six months.
    If it's higher, we'll code it with one, and if not, we'll code it with zero.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那么现在我们需要将每只股票的价格与它六个月后的价格进行比较。如果更高，我们将其编码为 1，否则为 0。
- en: 'To do this, we''ll just shift the dataframe back by 180 days and compare:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为此，我们将数据框向后移动 180 天并进行比较：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The next thing we need to do is flatten out the dataset:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要做的是将数据集展开：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following is the output:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '![](img/a3ff74d1-9b3f-4e80-b603-1aeaf1ffe48e.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a3ff74d1-9b3f-4e80-b603-1aeaf1ffe48e.png)'
- en: 'Okay, so now we need to create matrices in NumPy. To do this, we''ll use the
    `patsy` library. This is a great library that can be used to create a design matrix
    in a fashion similar to R:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 好的，现在我们需要在 NumPy 中创建矩阵。为此，我们将使用 `patsy` 库。这是一个很棒的库，可以用来创建类似于 R 中的设计矩阵：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following is the output:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '![](img/6b83a26d-5dc5-4854-82e2-c18ba3daa2a5.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6b83a26d-5dc5-4854-82e2-c18ba3daa2a5.png)'
- en: The `patsy` is a very strong package; for example, suppose we want to apply
    pre-processing. In `patsy`, it's possible, like R, to modify the formula in a
    way that corresponds to modifications in the design matrix. It won't be done here,
    but if we want to scale the value to mean 0 and standard deviation 1, the function
    will be *scale(open) + scale(high)*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`patsy` 是一个非常强大的包；例如，假设我们想应用预处理。在 `patsy` 中，像 R 一样，我们可以修改公式，来对应设计矩阵中的修改。这里不会做，但如果我们想将值缩放到均值为
    0，标准差为 1，函数将是 *scale(open) + scale(high)*。'
- en: 'So, now that we have our dataset, let''s fit the LDA object:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经有了数据集，让我们来拟合 LDA 对象：
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can see that it''s not too bad when predicting against the dataset. Certainly,
    we will want to improve this with other parameters and test the model:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到，在预测数据集时表现得还不错。当然，我们还想通过其他参数来改进这个模型并进行测试：
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: These metrics describe how the model fits the data in various ways.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这些度量描述了模型以不同方式拟合数据的效果。
- en: 'The `precision` and `recall` parameters are fairly similar. In some ways, as
    shown in the following list, they can be thought of as conditional proportions:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`precision` 和 `recall` 参数非常相似。从某些方面来看，正如以下列表所示，它们可以被看作是条件比例：'
- en: '`precision`: Given that the model predicts a positive value, what proportion
    of it is correct? This is why an alternate name for precision is **positive predictive
    value** (**PPV**).'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`precision`：给定模型预测的正值，实际正确的比例是多少？这也是为什么 precision 的另一个名称是 **正预测值** (**PPV**)
    的原因。'
- en: '`recall`: Given that the state of one class is true, what proportion did we
    select? I say select because `recall` is a common metric in search problems. For
    example, there can be a set of underlying web pages that, in fact, relate to a
    search term—the proportion that is returned. In [Chapter 5](d2473ebe-f050-4e72-bbf9-fabe5d62d441.xhtml),
    *Linear Models - Logistic Regression*, you saw recall by another name, sensitivity.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recall`：在已知某一类别为真时，我们选择的比例是多少？我说选择是因为 `recall` 是搜索问题中常见的度量指标。例如，可能有一组与搜索词相关的网页——返回的比例。在[第
    5 章](d2473ebe-f050-4e72-bbf9-fabe5d62d441.xhtml)，*线性模型 - 逻辑回归*，你见过一个另一名称的 recall，叫做敏感度。'
- en: The `f1-score` parameter attempts to summarize the relationship between `recall`
    and `precision`.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`f1-score` 参数试图总结 `recall` 和 `precision` 之间的关系。'
- en: How it works...
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: LDA is actually fairly similar to clustering, which we did previously. We fit
    a basic model from the data. Then, once we have the model, we try to predict and
    compare the likelihoods of the data given in each class. We choose the option
    that is more likely.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: LDA 实际上与我们之前做的聚类非常相似。我们从数据中拟合了一个基本模型。然后，一旦我们拥有模型，就尝试预测并比较在每个类别中给定数据的似然性。我们选择那个更可能的选项。
- en: LDA is actually a simplification of **quadratic discernment analysis** (**QDA**),
    which we'll talk about in the next recipe. Here we assume that the covariance
    of each class is the same, but in QDA, this assumption is relaxed. Think about
    the connections between KNN and **Gaussian mixture models** (**GMM**) and the
    relationship there and here.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: LDA实际上是**二次判别分析**（**QDA**）的一种简化，我们将在下一个实例中讨论它。这里我们假设每个类别的协方差是相同的，但在QDA中，这个假设被放宽。想一想KNN与**高斯混合模型**（**GMM**）之间的联系，以及这里和那里之间的关系。
- en: Working with QDA – a nonlinear LDA
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用QDA —— 非线性LDA
- en: QDA is the generalization of a common technique such as quadratic regression.
    It is simply a generalization of a model to allow for more complex models to fit,
    though, like all things, when allowing complexity to creep in, we make our lives
    more difficult.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: QDA是一个常见技术的推广，如二次回归。它只是一个模型的推广，允许更多复杂的模型拟合，但像所有事物一样，当允许复杂性渗入时，我们也使自己的生活变得更加困难。
- en: Getting ready
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will expand on the last recipe and look at QDA via the QDA object.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在上一个实例的基础上扩展，并通过QDA对象来看QDA。
- en: We said we made an assumption about the covariance of the model. Here we will
    relax that assumption.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们说过我们对模型的协方差做了假设。这里我们将放宽这个假设。
- en: How to do it...
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'QDA is aptly a member of the `qda` module. Use the following commands to use
    QDA:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: QDA恰好是`qda`模块的成员。使用以下命令来使用QDA：
- en: '[PRE10]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As you can see, it's about equal on the whole. If we look back at the *Using
    LDA for classification* recipe, we can see large changes as opposed to the QDA
    object for class zero and minor differences for class one.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，整体上差不多。如果回顾*使用LDA进行分类*的实例，我们可以看到与QDA对象在类别零上的大变化，以及类别一上的细微差别。
- en: As we talked about in the last recipe, we essentially compare likelihoods here.
    But how do we compare likelihoods? Let's just use the price at hand to attempt
    to classify `is_higher`.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一个实例中所讨论的，我们基本上是在这里比较似然。但我们如何比较似然呢？我们不妨使用手头的价格来尝试分类`is_higher`。
- en: How it works...
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'We''ll assume that the closing price is log-normally distributed. In order
    to compute the likelihood for each class, we need to create the subsets of the
    closes as well as a training and test set for each class. We''ll use the built-in
    cross-validation methods:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设收盘价服从对数正态分布。为了计算每个类别的似然，我们需要创建收盘价的子集，并为每个类别准备训练集和测试集。我们将使用内置的交叉验证方法：
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now that we have likelihoods for both classes, we can compare and assign classes:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了两个类别的似然，可以进行比较并分配类别：
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Using SGD for classification
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SGD进行分类
- en: The **stochastic gradient descent** (**SGD**) is a fundamental technique used
    to fit a model for regression. There are natural connections between SGD for classification
    or regression.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机梯度下降**（**SGD**）是用于拟合回归模型的基本技术。SGD在分类或回归中的应用有自然的联系。'
- en: Getting ready
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In regression, we minimized a cost function that penalized for bad choices on
    a continuous scale, but for classification, we'll minimize a cost function that
    penalizes for two (or more) cases.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归分析中，我们最小化了一个惩罚错误选择的代价函数，它是在一个连续尺度上进行的，但对于分类问题，我们将最小化一个惩罚两个（或更多）情况的代价函数。
- en: How to do it...
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'First, let''s create some very basic data:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们创建一些非常基本的数据：
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Split the data into training and testing sets:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分割成训练集和测试集：
- en: '[PRE14]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Instantiate and train the classifier:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化并训练分类器：
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Measure the performance on the test set:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量测试集上的性能：
- en: '[PRE16]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: There's more...
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We can set the `class_weight` parameter to account for the varying amount of
    imbalance in a dataset.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以设置`class_weight`参数来考虑数据集中不同程度的不平衡。
- en: 'The hinge loss function is defined as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 合页损失函数定义如下：
- en: '![](img/5c055abe-eff5-4e39-bfb7-c5be9b0ccf45.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5c055abe-eff5-4e39-bfb7-c5be9b0ccf45.png)'
- en: 'Here, `t` is the true classification denoted as *+1* for one case and *-1*
    for the other. The vector of coefficients is denoted by *y* as fit from the model,
    and *x* is the value of interest. There is also an intercept for good measure.
    To put it another way:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`t`是真实分类，表示*+1*表示一个类别，*-1*表示另一个类别。系数向量由从模型中拟合的*y*表示，*x*是感兴趣的值。还有一个截距用于辅助计算。换句话说：
- en: '![](img/9bf8c9bd-dc17-4835-a57f-40dc47b94d64.png)![](img/3a8e922a-1339-4f03-a10e-eb7bf4ec001d.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9bf8c9bd-dc17-4835-a57f-40dc47b94d64.png)![](img/3a8e922a-1339-4f03-a10e-eb7bf4ec001d.png)'
- en: Classifying documents with Naive Bayes
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯分类文档
- en: Naive Bayes is a really interesting model. It's somewhat similar to KNN in the
    sense that it makes some assumptions that might oversimplify reality, but still
    it performs well in many cases.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯是一个非常有趣的模型。它有点类似于KNN，因为它做了一些假设，这些假设可能会过于简化现实，但在许多情况下仍然表现良好。
- en: Getting ready
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备好
- en: In this recipe, we'll use Naive Bayes to do document classification with `sklearn`.
    An example I have personal experience of is using a word that makes up an account
    descriptor in accounting, such as accounts payable, and determining if it belongs
    to the income statement, cash flow statement, or balance sheet.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实例中，我们将使用朴素贝叶斯进行文档分类，使用的是`sklearn`。我个人的一个例子是使用会计中的账户描述词汇，例如应付账款，来判断它属于损益表、现金流量表还是资产负债表。
- en: The basic idea is to use the word frequency from a labeled test corpus to learn
    the classifications of the documents. Then, we can turn it on a training set and
    attempt to predict the label.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 基本思想是使用标注测试语料库中的单词频率来学习文档的分类。然后，我们可以将其应用于训练集，并尝试预测标签。
- en: 'We''ll use the `newgroups` dataset within `sklearn` to play with the Naive
    Bayes model. It''s a non-trivial amount of data, so we''ll fetch it instead of
    loading it. We''ll also limit the categories to `rec.autos` and `rec.motorcycles`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`sklearn`中的`newgroups`数据集来玩转朴素贝叶斯模型。这是一个非平凡量的数据集，所以我们会直接获取它，而不是加载它。我们还将限制类别为`rec.autos`和`rec.motorcycles`：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now that we have new groups, we'll need to represent each document as a bag-of-words.
    This representation is what gives Naive Bayes its name. The model is naive because
    documents are classified without regard for any intradocument word covariance.
    This might be considered a flaw, but Naive Bayes has been shown to work reasonably
    well.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了新组，我们需要将每个文档表示为词袋模型。这种表示法也正是朴素贝叶斯名称的由来。该模型是“朴素”的，因为文档分类时并不考虑文档内部的词汇协方差。这可能被认为是一个缺陷，但事实证明，朴素贝叶斯在许多情况下都能合理有效地工作。
- en: 'We need to pre-process the data into a bag-of-words matrix. This is a sparse
    matrix that has entries when the word is present in the document. This matrix
    can become quite large, as illustrated:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将数据预处理成词袋矩阵。这是一个稀疏矩阵，当文档中存在某个单词时，就会有对应的条目。这个矩阵可能会变得非常大，如下所示：
- en: '[PRE18]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This matrix is a sparse matrix, which is the length of the number of documents
    by each word. The document and word value of the matrix are the frequency of the
    particular term:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这个矩阵是一个稀疏矩阵，它的维度是文档数量和每个单词的数量。矩阵中的文档和单词值是特定术语的频率：
- en: '[PRE19]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We''ll actually need the matrix as a dense array for the Naive Bayes object.
    So, let''s convert it back:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们需要将矩阵转换为稠密数组，以便用于朴素贝叶斯对象。所以，我们需要将其转换回来：
- en: '[PRE20]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Clearly, most of the entries are zero, but we might want to reconstruct the
    document counts as a sanity check:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，大多数条目都是零，但我们可能想要重新构建文档计数以进行合理性检查：
- en: '[PRE21]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, are these the examples in the first document? Let''s check that using
    the following command:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这些是第一个文档中的示例吗？我们可以使用以下命令来检查：
- en: '[PRE22]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: How to do it...
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Okay, so it took a bit longer than normal to get the data ready, but we're dealing
    with text data that isn't as quickly represented as a matrix as the data we're
    used to.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，准备数据比平常多花了一些时间，但我们处理的是文本数据，这些数据不像我们平常处理的矩阵数据那样可以迅速表示。
- en: 'However, now that we''re ready, we''ll fire up the classifier and fit our model:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然而，现在我们准备好了，就可以启动分类器并拟合我们的模型：
- en: '[PRE23]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Rename the sets `bow` and `newgroups.target` to `X` and `y` respectively. Before
    we fit the model, let''s split the dataset into a training and a test set:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`bow`和`newgroups.target`分别重命名为`X`和`y`。在拟合模型之前，我们先将数据集拆分为训练集和测试集：
- en: '[PRE24]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now that we fit a model on a test set and predicted the training set in an
    attempt to determine which categories go with which articles, let''s get a sense
    of the approximate accuracy:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们在测试集上拟合了一个模型，并试图预测训练集，以确定哪些类别与哪些文章相对应，让我们来看看大致的准确性：
- en: '[PRE25]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: How it works...
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The fundamental idea of Naive Bayes is that we can estimate the probability
    of a data point being a class, given the feature vector.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯的基本思想是，我们可以根据特征向量估算某个数据点属于某个类别的概率。
- en: This can be rearranged via the Bayes formula to give the **maximum a posteriori** (**MAP**)
    estimate for the feature vector. This MAP estimate chooses the class for which
    the feature vector's probability is maximized.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 通过贝叶斯公式可以重新排列，得到**最大后验**（**MAP**）估计特征向量。这个MAP估计选择了特征向量的概率最大化的类别。
- en: There's more...
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We can also extend Naive Bayes to do multiclass work. Instead of assuming a
    Gaussian likelihood, we'll use a multinomial likelihood.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以将朴素贝叶斯扩展到多类工作。我们不再假设高斯似然，而是使用多项式似然。
- en: 'First, let''s get a third category of data:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们获取第三类数据：
- en: '[PRE26]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We''ll need to vectorize this just like the class case:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要像处理分类问题一样对其进行向量化：
- en: '[PRE27]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Rename `mn_bow` and `mn_newgroups.target` to `X` and `y` respectively. Let''s
    create a train and a test set and train a multinomial Bayes model with the training
    data:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 将`mn_bow`和`mn_newgroups.target`分别重命名为`X`和`y`。让我们创建一个训练集和一个测试集，并使用训练数据训练一个多项式贝叶斯模型：
- en: '[PRE28]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Measure the model accuracy:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 测量模型准确度：
- en: '[PRE29]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: It's not completely surprising that we did well. We did fairly well in the dual
    class case, and since one will guess that the `talk.politics.guns` category is
    fairly orthogonal to the other two, we should probably do pretty well.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不完全令人惊讶，我们表现得相当不错。我们在双类情况下表现得相当好，而且由于有人猜测`talk.politics.guns`类别与其他两个类别相对独立，因此我们应该表现得相当好。
- en: Label propagation with semi-supervised learning
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 半监督学习中的标签传播
- en: Label propagation is a semi-supervised technique that makes use of labeled and
    unlabeled data to learn about unlabeled data. Quite often, data that will benefit
    from a classification algorithm is difficult to label. For example, labeling data
    might be very expensive, so only a subset is cost-effective to manually label.
    That said, there does seem to be slow but growing support for companies to hire
    taxonomists.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 标签传播是一种半监督技术，利用标记数据和未标记数据来学习未标记数据。通常，受益于分类算法的数据很难标记。例如，标记数据可能非常昂贵，因此只有一部分数据进行人工标记才是具有成本效益的。尽管如此，似乎有慢慢增长的趋势支持公司雇佣分类学家。
- en: Getting ready
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Another problem area is censored data. You can imagine a case where the frontier
    of time will affect your ability to gather labeled data. Say, for instance, you
    took measurements of patients and gave them an experimental drug. In some cases,
    you are able to measure the outcome of the drug if it happens fast enough, but
    you might want to predict the outcome of the drugs that have a slower reaction
    time. The drug might cause a fatal reaction for some patients and life-saving
    measures might need to be taken.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题领域是审查数据。你可以想象一个情况，时间的前沿将影响你收集标记数据的能力。例如，假设你对患者进行了测量并给他们服用了实验药物。在某些情况下，如果药物反应足够迅速，你可以测量药物的效果，但你可能还想预测反应较慢的药物的效果。药物可能对某些患者引起致命反应，可能需要采取挽救生命的措施。
- en: How to do it...
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 怎么做...
- en: 'In order to represent semi-supervised or censored data, we''ll need to do a
    little data pre-processing. First, we''ll walk through a simple example, and then
    we''ll move on to some more difficult cases:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了表示半监督或审查数据，我们需要进行一些数据预处理。首先，我们将通过一个简单的例子进行演示，然后再处理一些更复杂的情况：
- en: '[PRE30]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Due to the fact that we''ll be messing with the data, let''s make copies and
    add an unlabeled member to the target name''s copy. It''ll make it easier to identify
    the data later:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们将对数据进行修改，所以让我们创建副本并在目标名称的副本中添加一个未标记成员。这样以后更容易识别数据：
- en: '[PRE31]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, let''s update `y` with `-1`. This is the marker for the unlabeled case.
    This is also why we added unlabeled at the end of the names:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们用`-1`更新`y`。这表示未标记的情况。这也是我们在名称末尾添加未标记的原因：
- en: '[PRE32]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Our data now has a bunch of negative ones (`-1`) interspersed with the actual
    data:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的数据现在有一堆`-1`与实际数据交错在一起：
- en: '[PRE33]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We clearly have a lot of unlabeled data, and the goal now is to use the `LabelPropagation` method
    to predict the labels:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们显然有很多未标记的数据，现在的目标是使用`LabelPropagation`方法来预测标签：
- en: '[PRE34]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Measure the accuracy score:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量准确度评分：
- en: '[PRE35]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Not too bad, though we did use all the data, so it's kind of cheating. Also,
    the iris dataset is a fairly separated dataset.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 还不错，尽管我们使用了所有数据，这有点像作弊。另外，鸢尾花数据集是一个相对分离的数据集。
- en: Using the whole dataset is reminiscent of more traditional statistics. Making
    the choice of not measuring on a test set decreases our focus on prediction and
    encourages more understanding and interpretation of the whole dataset. As mentioned
    before, understanding versus black-box prediction distinguishes traditional statistics
    with machine learning.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 使用整个数据集让人联想到更传统的统计方法。选择不在测试集上进行测量减少了我们对预测的关注，鼓励我们更多地理解和解释整个数据集。如前所述，理解与黑箱预测的区别在于传统统计学和机器学习。
- en: 'While we''re at it, let''s look at `LabelSpreading`, the sister class of `LabelPropagation`.
    We''ll make the technical distinction between `LabelPropagation` and `LabelSpreading`
    in the *How it works..*. section of this recipe, but they are extremely similar:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，让我们来看一下 `LabelSpreading`，它是 `LabelPropagation` 的姊妹类。我们将在本节 *如何工作...* 中对
    `LabelPropagation` 和 `LabelSpreading` 做出技术性区分，但它们非常相似：
- en: '[PRE36]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The `LabelSpreading` is more robust and noisy as observed from the way it works:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`LabelSpreading` 比 `LabelPropagation` 更加鲁棒和抗噪声，正如它的工作方式所观察到的那样：'
- en: '[PRE37]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Measure the accuracy score:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 测量准确率得分：
- en: '[PRE38]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Don't consider the fact that the label-spreading algorithm missed one more as
    an indication and that it performs worse in general. The whole point is that we
    might give it some ability to predict well on the training set and to work on
    a wider range of situations.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 不要将标签传播算法遗漏的一个案例看作是它表现较差的标志。关键是我们可能赋予它一定的能力，使其在训练集上进行良好的预测，并能适用于更广泛的情况。
- en: How it works...
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'Label propagation works by creating a graph of the data points, with weights
    placed on the edge as per the following formula:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 标签传播通过创建一个数据点的图来工作，边缘上根据以下公式设置权重：
- en: '![](img/66959096-80b2-4bec-94d0-8b7253f9e092.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/66959096-80b2-4bec-94d0-8b7253f9e092.png)'
- en: The algorithm then works by labeled data points propagating their labels to
    the unlabeled data. This propagation is, in part, determined by edge weight.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法通过标记的数据点将其标签传播到未标记的数据点。这个传播过程在一定程度上由边缘权重决定。
- en: The edge weights can be placed in a matrix of transition probabilities. We can
    iteratively determine a good estimate of the actual labels.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘权重可以放置在一个转移概率矩阵中。我们可以通过迭代的方式来确定实际标签的良好估计值。
