- en: Chapter 8. Dimensionality Reduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章。维度缩减
- en: Building a useful predictive model requires analyzing an appropriate number
    of observations (or cases). This number will vary, based upon your project or
    your objective. Strictly speaking, the more *variations* (not necessarily the
    more *data*) analyzed, the better the outcome or results of the model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个有用的预测模型需要分析适当数量的观察（或案例）。这个数字将根据你的项目或目标而变化。严格来说，分析的*变化*（不一定是更多的*数据*）越多，模型的结果或结果就越好。
- en: This chapter will discuss the concept of reducing the size or amount of the
    data being observed without affecting the outcome of the analysis (or the success
    of the project), through various common approaches such as *correlation analysis*,
    *principal component analysis*, *independent component analysis*, *common factor
    analysis*, and *non-negative matrix factorization*.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将讨论通过各种常见方法（如*相关性分析*、*主成分分析*、*独立成分分析*、*共同因素分析*和*非负矩阵分解*）在不影响分析结果（或项目的成功）的情况下，缩减观察数据的大小或数量的概念。
- en: Let us begin by clarifying what is meant by dimensional reduction.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先从澄清“维度缩减”的含义开始。
- en: Defining DR
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义DR
- en: It is a most commonly accepted rule of thumb that it is difficult to understand
    or visualize data represented in or by more than three dimensions.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 人们普遍认为，难以理解或可视化超过三个维度的数据。
- en: '**Dimensional** (-**ity**) **reduction** is the process of attempting to reduce
    the number of random variables (or data dimensions) under statistical consideration,
    or perhaps better put: finding a lower-dimensional representation of the feature-set
    that is of interest.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**维度**（-**性**）**缩减**是指尝试减少在统计考虑下的随机变量（或数据维度）的数量，或者也许更好地说：找到对感兴趣的特性集的低维表示。'
- en: 'This allows the data scientist to:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得数据科学家可以：
- en: Avoid what is referred to as the curse of dimensionality
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免所谓的维度灾难
- en: Note
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The curse of dimensionality refers to a phenomenon that arises when attempting
    to analyze data in high-dimensional spaces (often with hundreds or thousands of
    dimensions) that do not occur in low-dimensional settings or everyday experience.
  id: totrans-10
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 维度灾难是指当尝试分析高维空间（通常具有数百或数千个维度）中的数据时出现的一种现象，而在低维设置或日常经验中并不存在。
- en: Reduce the amount of time and memory required for the proper analysis of the
    data
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少正确分析数据所需的时间和内存量
- en: Allow the data to be more easily visualized
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使数据更容易可视化
- en: Eliminate features irrelevant to the model's purpose
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消除与模型目的无关的特征
- en: Reduce model noise
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少模型噪声
- en: A useful (albeit perhaps over-used) conceptual example of data dimensional reduction
    is the case of a computer-generated face or faces or an image of a single human
    face, which is in fact made up of thousands of images of individual human faces.
    If we consider the attributes of each individual face, the data may become overwhelming;
    however, if we reduce the dimensionality of all those images into several principal
    components (eyes, nose, lips, and so on.), the data becomes somewhat more manageable.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据维度缩减的一个有用（尽管可能被过度使用）的概念示例是计算机生成的面孔或面孔或单个人类面孔的图像，实际上是由成千上万张单个人类面孔的图像组成的。如果我们考虑每个个体的面部特征，数据可能会变得难以处理；然而，如果我们将这些图像的维度缩减为几个主成分（眼睛、鼻子、嘴唇等），数据就会变得更容易管理。
- en: The following sections outline some of the most common methods and strategies
    for dimension reduction.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下各节概述了一些最常见的维度缩减方法和策略。
- en: Correlated data analyses
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关数据分析
- en: It is typical to think of the terms **dependence** and **association** as having
    the same meeting. These are used to qualify a relationship between two (or more)
    random variables or bivariate data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 人们通常认为术语**依赖性**和**关联性**具有相同的意义。这些术语用于描述两个（或更多）随机变量或双变量数据之间的关系。
- en: Note
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: A random variable is a variable quantity whose value depends on possible outcomes;
    bivariate data is data with two variables who may or may not have an exposed relationship.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量是一个变量量，其值取决于可能的结果；双变量数据是包含两个变量且可能或可能没有暴露关系的资料。
- en: '**Correlated data**, or data with correlation, describes a type of (typically
    linear) statistical relationship. A popular example of a correlation is product
    pricing, such as when the popularity of a product drives the manufacturer''s pricing
    strategies.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关数据**，或具有相关性的数据，描述了一种（通常是线性的）统计关系。相关性的一个流行例子是产品定价，例如当产品的受欢迎程度推动制造商的定价策略时。'
- en: Identifying correlations can be very useful as they can be a *predictive relationship*
    that can be exploited or used to reduce dimensionality within a population or
    data file.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 识别相关性非常有用，因为它们可以是可被利用或用于在人群或数据文件中降低维度的**预测关系**。
- en: Common examples of correlation and predictive relationships typically involve
    the weather, but another idea might be found at [http://www.nfl.com/](http://www.nfl.com/).
    If you are familiar with the national football league and have visited the site,
    then you'll know that each NFL team sells team-embolized merchandise and a team
    that's earned a winning season will most likely have higher product sales that
    year.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的相关性和预测关系例子通常涉及天气，但另一个想法可以在[http://www.nfl.com/](http://www.nfl.com/)找到。如果你熟悉国家橄榄球联盟并访问过该网站，那么你就会知道每个NFL球队都销售带有球队标志的商品，而赢得胜利赛季的球队那年很可能有更高的产品销售额。
- en: In this example, there is a *causal relationship*, because a team's winning
    season *causes* its fans to purchase more of their team merchandise. However,
    in general, the presence of a *correlation* is not sufficient to infer the presence
    of (even) a *causal relationship* (there will be more on this later in this chapter).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，存在一种**因果关系**，因为一支球队的胜利赛季**导致**其球迷购买更多球队商品。然而，通常来说，存在**相关性**并不足以推断出（甚至）存在**因果关系**（关于这一点，本章后面将有更多讨论）。
- en: Scatterplots
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 散点图
- en: As an aside, a *scatterplot* is often used to graphically represent the relationship
    between two variables and therefore is a great choice for visualizing correlated
    data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作为旁白，**散点图**常用于图形表示两个变量之间的关系，因此是可视化相关数据的绝佳选择。
- en: 'Using the R `plot` function, you can easily generate a pretty nice visual of
    our winning team example, shown as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用R的`plot`函数，你可以轻松生成我们获胜队伍示例的相当不错的视觉效果，如下所示：
- en: '![Scatterplots](img/00147.jpeg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![散点图](img/00147.jpeg)'
- en: Note
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: As other visualization options, boxplots and violin plots can also be used.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 作为其他可视化选项，箱线图和小提琴图也可以使用。
- en: As mentioned in the preceding graph, *correlation* describes or measures the
    level or extent to which two or more variables fluctuate *together* (in the preceding
    example, **Games Won** and **Merchandise Sold**).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所述，**相关性**描述或衡量两个或多个变量一起**波动**的水平或程度（在前面的例子中，**赢得的比赛**和**销售的纪念品**）。
- en: This measurement can be categorized as positive or negative, with a *positive
    correlation* showing the extent to which those variables increase or decrease
    in parallel, and a *negative correlation* showing the extent to which one variable
    increases as the other decreases.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这种测量可以归类为正相关性或负相关性，其中**正相关性**表明这些变量在平行增加或减少的程度，而**负相关性**表明一个变量增加时另一个变量减少的程度。
- en: A **correlation coefficient** is a statistical measure of the degree to which
    changes in the value of one variable will or can predict change to the value of
    another variable.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关系数**是衡量一个变量的值的变化将如何或可以预测另一个变量的值的变化程度的统计量。'
- en: When the variation of one variable *reliably predicts* a similar variation in
    another variable, there's often a predisposition to think that this means that
    the change in one causes the change in the other. However, *correlation* does
    not imply *causation*. [There may be, for example, an unknown factor that influences
    both variables similarly].
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个变量的变化可靠地预测另一个变量相似的变化时，人们往往会倾向于认为这意味着一个变量的变化导致另一个变量的变化。然而，**相关性**并不意味着**因果关系**。[例如，可能存在一个影响两个变量的未知因素]。
- en: To illustrate, think of a data correlation situation where television advertising
    has suggested that athletes who wear a certain brand of shoe run faster. However,
    those same athletes each employee personal trainers, which may be an influential
    factor.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，想象一下一种数据相关性情况，其中电视广告暗示穿某一品牌鞋的运动员跑得更快。然而，这些运动员每个人都聘请了个人教练，这可能是影响因素。
- en: So, correlation (or performing correlation analysis) is a *statistical technique*
    that can show whether and how strongly pairs of variables are related. When variables
    are identified that are strongly related, it makes statistical sense to remove
    one of them from the analysis; however, when pairs of variables appear related
    but have a *weaker* relationship, it's best to have both variables remain in the
    population.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，相关性（或进行相关性分析）是一种*统计技术*，可以显示变量对之间的相关程度以及是否存在相关性。当识别出强相关的变量时，从分析中移除其中一个变量在统计学上是有意义的；然而，当变量对看起来相关但关系较弱时，最好让两个变量都保留在总体中。
- en: For example, winning professional football teams and team merchandise sales
    are related in that teams with winning seasons frequently sell more merchandise.
    However, some teams have a stronger following then others and have high merchandise
    sales even when they lose more games than they win. Nonetheless, the average sales
    of a team winning more than 50% of its games is more than one losing 50% of their
    games, and teams winning more than 75% of their games exceed sales of those losing
    75% of their games, and so on. So, what is the effect of winning games on a team's
    merchandise sales? It can be difficult to determine, but determining correlation
    between the data points can tell you just how much of the variation in a team's
    performance is related to their merchandise sales.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，赢得职业足球比赛的球队和球队商品的销售是相关的，因为赛季赢得比赛的球队通常销售更多的商品。然而，一些球队比其他球队有更忠实的追随者，即使他们输的比赢的多，商品销售仍然很高。尽管如此，赢得超过50%比赛的球队的销售额平均要高于输掉50%比赛的球队，赢得超过75%比赛的球队销售额要超过输掉75%比赛的球队，依此类推。那么，赢得比赛对球队商品销售的影响是什么？这可能很难确定，但确定数据点之间的相关性可以告诉你一个球队的业绩变化中有多少与他们的商品销售相关。
- en: Although the correlation of *games won* and *merchandise sold* may be obvious,
    our example may contain *unsuspected data* correlations. You may also suspect
    there are additional correlations, but are not sure which are the strongest.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然赢得比赛和销售商品的相关性可能很明显，但我们的例子可能包含*未预料到的数据*相关性。你也可能怀疑存在其他相关性，但不确定哪一个是最强的。
- en: A well-planned, thorough correlation analysis on the data can lead to a greater
    understanding of your data; however, just like all statistical techniques, correlation
    is only appropriate for certain types of data. **Correlation works for quantifiable
    data** in which numbers are meaningful - usually quantities of some sort (such
    as products sold). It cannot be used for purely categorical data, such as an individual's
    gender, brand preference, or education level.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据进行周密、彻底的相关性分析可以加深你对数据的理解；然而，就像所有统计技术一样，相关性只适用于某些类型的数据。**相关性适用于可量化数据**，其中数字是有意义的——通常是某种数量（如销售的产品）。它不能用于纯粹分类数据，如个人的性别、品牌偏好或教育水平。
- en: Let's go on and look at causation a bit more closely.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续更详细地看看因果关系。
- en: Causation
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 因果关系
- en: It is very important to understand the concept of causation and how it compares
    to correlation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 理解因果关系及其与相关性的比较概念非常重要。
- en: Causation is defined in statistics as a variable that can cause change to or
    within another variable. The result of this effect can *always* be predicted,
    providing a clear relationship between variables that can be established with
    certainty.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，因果关系被定义为可以导致另一个变量或其内部发生变化的变量。这种效果的结果可以*总是*被预测，从而在变量之间建立一种可以确定的关系。
- en: 'Causation involves correlation, but correlation does not imply causation. Every
    variable somehow linked to another may appear to imply causation. This is not
    always so; linking one thing with another does not always prove that the result
    has been caused by the other. The rule of thumb is: only if you can directly link
    a variance or change of a variable to that of another, can you say it''s causation.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因果关系涉及相关性，但相关性并不一定意味着因果关系。每个与另一个变量有某种联系的变量可能看起来暗示了因果关系。这并不总是这样；将一件事与另一件事联系起来并不总是证明结果是由另一件事引起的。经验法则是：只有当你可以直接将一个变量的变化或变化与另一个变量的变化联系起来时，你才能说它是因果关系。
- en: The degree of correlation
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关系数的程度
- en: 'To have a way of indicating or quantifying a statistical relationship between
    variables, we use a number referred to as a *correlation coefficient*:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了表示或量化变量之间的统计关系，我们使用一个称为*相关系数*的数字：
- en: It ranges from -1.0 to +1.0
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的范围从-1.0到+1.0
- en: The closer it is to +1 or -1, the more closely the two variables are related
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它越接近+1或-1，两个变量之间的关系就越紧密
- en: If zero, there is *no relationship* between the variables it represents
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果为零，这意味着它所代表的变量之间没有 *关系*
- en: If positive, it means that, as one variable increases, the other increases
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果是正数，这意味着，当一个变量增加时，另一个变量也增加
- en: If negative, it means that, as one variable increases, the other decreases
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果是负数，这意味着，当一个变量增加时，另一个变量减少
- en: Reporting on correlation
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 报告相关性
- en: While correlation coefficients are normally reported simply as-is (a value between
    -1 and +1), they are often *squared* first to make them easier to understand.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然相关系数通常简单地报告（一个介于 -1 和 +1 之间的值），但它们通常首先被平方，以便更容易理解。
- en: If a correlation coefficient is *r*, then *r* *squared* (you remove the decimal
    point) equals the percentage of the variation in one variable that is related
    to the variation in the other. Given this, a correlation coefficient of .5 would
    mean that the variation percentage is 25%.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果相关系数是 *r*，那么 *r* 的平方（你移除小数点）等于一个变量的变化与另一个变量的变化相关的百分比。据此，相关系数为 .5 意味着变化百分比为
    25%。
- en: In an earlier section of this chapter, we looked at a simple visualization of
    a correlation between the number of games won and the sales of a team's merchandise.
    In practice, when creating a *correlation report*, you can also show a second
    figure – statistical significance. Adding significance will show the probability
    of error within the identified correlation information. Finally, since sample
    size can impact outcomes significantly, it is a good practice to also show the
    sample size.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的早期部分，我们查看了一个简单的可视化，展示了赢得比赛数量与一支球队商品销售额之间的相关性。在实践中，当创建 *相关性报告* 时，你也可以展示第二个图表——统计显著性。添加显著性将显示所识别的相关信息中的错误概率。最后，由于样本大小可能会对结果产生重大影响，因此展示样本大小也是一个好的做法。
- en: In summary, identifying correlations within the data being observed is a common
    and accepted method for accomplishing dimensionality reduction. Another method
    is *principal component analysis*, which we will cover in the next section.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，识别观察数据中的相关性是一种常见且被接受的方法来实现降维。另一种方法是 *主成分分析*，我们将在下一节中介绍。
- en: Principal component analysis
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主成分分析
- en: '**Principal component analysis** (**PCA**), is another popular statistical
    technique used for dimensional reduction in data.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**主成分分析**（**PCA**）是另一种流行的统计技术，用于数据降维。'
- en: Note
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: PCA is also called the Karhunen-Loeve `transform` method, and in fact, depending
    upon the audience, PCA has been said to be the most commonly used dimension reduction
    technique.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 也被称为 Karhunen-Loeve `变换` 方法，实际上，根据听众的不同，PCA 被说成是最常用的降维技术。
- en: PCA is a technique that attempts to not only reduce data dimensionality but
    also retain as much of the variation in the data as possible.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 是一种试图不仅降低数据维度，而且尽可能保留数据中变化的技术。
- en: Note
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Principal component analysis is an approach to factor analysis (which will be
    discussed later in this chapter) that considers the *total variance* in the data
    file.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析是因子分析（将在本章后面讨论）的一种方法，它考虑了数据文件中的 *总方差*。
- en: The process of PCA uses what is known as an *orthogonal transformation* process
    to convert a set of observations of possibly *correlated* variables into a set
    of values of linearly *uncorrelated* variables. These variables are then called
    **principal components**, or the data's principal modes of variation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 的过程使用所谓的 *正交变换* 过程将一组可能 *相关* 的变量的观察值转换为一组线性 *不相关* 的变量的值。这些变量被称为 **主成分**，或数据的变动的首要模式。
- en: Through the PCA effort, the number of principal components (or variables) should
    be **less than or equal to** the **number of original variables** or the number
    of original observations, thereby *reducing the data's independent dimensionality*
    (that is, dimensional reduction) or the number of independent dimensions.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 PCA 的努力，主成分（或变量）的数量应该 **小于或等于** 原始变量的数量或原始观察的数量，从而 *降低数据的独立维度*（即降维）或独立维度的数量。
- en: These principal components are defined and arranged such that the first principal
    component accounts for as much of the variability in the data as possible, and
    each succeeding principal component has the next highest variance possible subject
    to the constraint that it is orthogonal to the preceding components.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这些主成分被定义和排列，使得第一个主成分尽可能多地解释数据中的变异性，并且每个后续主成分都有可能的最大方差，前提是它必须与前一个成分正交。
- en: The general concept or objective for performing a *principal component analysis*
    is to observe that the same results will be obtained for affecting any of the
    independent variables upon the dependent variable, regardless of whether one models
    the effects of the variables individually.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 执行**主成分分析**的一般概念或目标是观察，无论是对独立变量还是对因变量产生影响，都会得到相同的结果，无论是否单独对变量的影响进行建模。
- en: PCA is mostly used as a tool when performing an *exploratory data analysis*,
    or data profiling, since its operation can be thought of as revealing the internal
    structure of the data in a way that best explains the variance in the data, but
    it can also be helpful in predictive modeling.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: PCA通常用作在执行**探索性数据分析**或数据概览时的工具，因为其操作可以被认为是以最佳方式揭示数据内部结构，从而解释数据的方差，但它也可以在预测建模中有所帮助。
- en: Note
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Data profiling** involves logically getting to know the data through query,
    experimentation, and review. Following the profiling process, you can then use
    the information you have collected to add context (and/or apply new perspectives)
    to the data. Adding context to data requires the manipulation of the data to perhaps
    reformat it, such as by adding calculations, aggregations or additional columns
    or re-ordering, and so on.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据概览**涉及通过查询、实验和审查逻辑地了解数据。在概览过程之后，你可以使用你收集到的信息为数据添加上下文（以及/或应用新的视角）。向数据添加上下文需要操作数据，例如通过添加计算、聚合或额外的列，以及重新排序等。'
- en: Principal component analysis or PCA is an alternative form of the common **factor
    analysis** (which will be discussed later in this chapter) process. Factor analysis
    typically incorporates more domain-specific assumptions about the underlying structure
    of the data being observed and solves eigenvectors of a slightly different matrix.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析或PCA是常见**因子分析**（将在本章后面讨论）的另一种形式。因子分析通常包含更多关于被观察数据潜在结构的特定领域假设，并解算一个略微不同的矩阵的特征向量。
- en: To understand, at a very high level, think of PCA as continually fitting an
    *n*-dimensional ellipsoid to a plotted data file, where each axis of the ellipsoid
    represents a *principal component* of that data. If some axis of the ellipsoid
    is small, then the variance along that axis is also small, and by omitting that
    axis (and its corresponding principal component) from the data file, we will lose
    only a commensurately small amount of information about our data file; otherwise,
    the axis (the principal component) stays, representing some degree of variation
    to the mean of the data file overall.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个非常高的层面上理解，可以将PCA想象为持续地为一个*n*-维椭球体拟合一个绘制的数据文件，其中椭球体的每个轴代表该数据的一个**主成分**。如果椭球体的某个轴很小，那么该轴上的方差也较小，通过从数据文件中省略该轴（及其对应的主成分），我们将只丢失关于数据文件的信息的一小部分；否则，该轴（主成分）将保留，代表数据文件整体均值的一些变异程度。
- en: Using R to understand PCA
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用R理解PCA
- en: Perhaps with less of effort and logic required to understand PCA, as described
    in the preceding paragraph, you can use the generic R function `princomp`.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一段所述，如果对PCA的理解不需要太多的努力和逻辑，你可以使用通用的R函数`princomp`。
- en: The `princomp` function is a way of simplifying a complex data file by exposing
    the sources of variations within the data using calculated standard deviations
    of the data file's principal components. This is best illustrated using the classic
    iris data file (provided when you install the R programming language).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`princomp`函数通过使用数据文件主成分的计算标准差来揭示数据中的变异来源，从而简化复杂的数据文件。这最好通过经典的iris数据文件（在安装R编程语言时提供）来说明。'
- en: 'The data file (partially shown in the following screenshot) contains flower
    attributes (petal width, petal length, sepal width, and sepal length) for over
    150 species of `iris`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 数据文件（部分显示在下述截图）包含超过150种`iris`的花朵属性（花瓣宽度、花瓣长度、萼片宽度和萼片长度）：
- en: '![Using R to understand PCA](img/00148.jpeg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![使用R理解PCA](img/00148.jpeg)'
- en: 'We should note that the `princomp` function cannot handle string data (which
    is okay since our PCA analysis is only interested in identifying the numerical
    variations of principal components), so we can save the first five columns of
    data to a new object named `pca` (dropping the column `Species`) by using the
    following R line of code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该注意，`princomp`函数无法处理字符串数据（这没关系，因为我们的PCA分析只对识别主成分的数值变化感兴趣），因此我们可以通过以下R代码行将数据的前五行保存到名为`pca`的新对象中（省略`Species`列）：
- en: '[PRE0]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we can use the R `summary` command on the `pca` object we just created.
    The output generated is shown as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用我们刚刚创建的`pca`对象上的R `summary`命令。生成的输出如下所示：
- en: '![Using R to understand PCA](img/00149.jpeg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![使用R理解PCA](img/00149.jpeg)'
- en: You can see from the previous image that 92.4% of the variation in the dataset
    is explained by the *first component alone*, and 97.8% is explained by the *first
    two components!*
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从前面的图像中看到，数据集中的92.4%的变化仅由**第一个成分**解释，而97.8%由**前两个成分**解释！
- en: 'To better understand, we can visualize the preceding observations by using
    the R `screeplot` function with our `pca` object, shown as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解，我们可以使用R的`screeplot`函数和我们的`pca`对象来可视化前面的观察结果，如下所示：
- en: '![Using R to understand PCA](img/00150.jpeg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![使用R理解PCA](img/00150.jpeg)'
- en: The `screeplot` function generates a screen plot displaying the proportion of
    the total variation in a data file that is explained by each of the components
    in a principal component analysis, showing how many of the principal components
    are needed to summarize the data.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`screeplot`函数生成一个屏幕图，显示在主成分分析中，每个组件解释的数据文件中总变异的比例，显示了需要多少主成分来总结数据。'
- en: 'Our generated visualization is as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生成的可视化如下：
- en: '![Using R to understand PCA](img/00151.jpeg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![使用R理解PCA](img/00151.jpeg)'
- en: The results of a PCA are usually deliberated in terms of the scores of each
    component (sometimes referred to as *factor scores*), which are the transformed
    variable values corresponding to a particular data point in a data file, and loadings,
    which are the weight by which each standardized original variable should be multiplied
    to get the component score.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: PCA的结果通常根据每个组件的得分（有时称为*因子得分*）来考虑，这些得分是对应于数据文件中特定数据点的转换变量值，以及加载，即每个标准化原始变量应该乘以的权重，以获得组件得分。
- en: 'We can use the R `loadings` and `scores` commands to view our loadings and
    scores information, shown as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用R的`loadings`和`scores`命令来查看我们的加载和得分信息，如下所示：
- en: '![Using R to understand PCA](img/00152.jpeg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![使用R理解PCA](img/00152.jpeg)'
- en: Independent component analysis
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 独立成分分析
- en: Yet another concept concerning dimension reduction is ICA, or **independent
    component analysis** (**ICA**). This is a process where there is an attempt to
    uncover or verify *statistically independent* variables or dimensions in high-dimensional
    data sources.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关于降维的概念是ICA，或**独立成分分析**（**ICA**）。这是一个尝试在高度数据源中揭示或验证**统计独立**变量或维度的过程。
- en: Using one selected ICA process, each variable or dimension in the data can be
    identified, examined for independence, and then selectively removed from, or retained
    in, the overall data analysis.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个选定的ICA过程，可以识别数据中的每个变量或维度，检查其独立性，然后选择性地从整体数据分析中移除或保留。
- en: Note
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If the reader takes time to perform any additional research on ICA, he/she will
    encounter the common example application called the cocktail party problem, which
    is listening in on one person's speech in a noisy room.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果读者花时间对ICA进行任何额外的研究，他/她将遇到一个常见的应用示例，称为鸡尾酒会问题，即在嘈杂的房间里监听一个人的讲话。
- en: Defining independence
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义独立性
- en: ICA attempts to find independent components in data by maximizing the *statistical
    independence* of the components. But just how is a variable's independence defined?
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ICA试图通过最大化组件的**统计独立性**来寻找数据中的独立成分。但变量独立性的定义究竟是什么呢？
- en: Components are *determined to be independent* if the realization of one does
    not affect the probability distribution of the other.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个变量的实现不影响另一个变量的概率分布，则**确定**这些组件是独立的。
- en: There are many acceptable ways to determine independence, and your choice will
    determine the form of the ICA algorithm used.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 确定独立性的方法有很多，你的选择将决定使用的ICA算法的形式。
- en: 'The two most widely used definitions of independence (for ICA) are:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 独立性的两种最广泛使用的定义（对于ICA）是：
- en: '**Minimization of mutual information** (**MMI**): Mutual information measures
    the information that two or more components share, measuring to what extent knowing
    one of these variables reduces uncertainty about the other. The less mutual information
    a component includes, the more independent the component is.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最小化互信息**（**MMI**）：互信息衡量两个或多个组件共享的信息，衡量知道这些变量中的一个变量在多大程度上减少了关于其他变量的不确定性。组件包含的互信息越少，该组件就越独立。'
- en: '**Non-Gaussianity Maximization** (**NGM**): Non-Gaussianity Maximization looks
    to avoid or reduce the average, or in other words, highlight variability (its
    level of independence) in a component.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非高斯最大化**（**NGM**）：非高斯最大化旨在避免或减少平均值，换句话说，突出一个成分中的可变性（其独立性的水平）。'
- en: ICA pre-processing
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ICA预处理
- en: Before applying any ICA logic to data, typical ICA methodologies use procedures
    such as *centering* and *whitening* as preprocessing steps in order to simplify
    and reduce the complexity of a problem and highlight features of data not readily
    explained by its average or co-variance.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在将任何ICA逻辑应用于数据之前，典型的ICA方法使用诸如*中心化*和*白化*等预处理步骤，以便简化并减少问题的复杂性，并突出数据中平均或协方差无法轻易解释的特征。
- en: In other words, before attempting to determine the level of a component independence,
    the data file may be reviewed and manipulated to make it more understandable using
    various preprocessing methods.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，在尝试确定成分独立性水平之前，可以使用各种预处理方法来审查和操作数据文件，使其更容易理解。
- en: Centering is the most basic preprocess method commonly used, which, true to
    its name, involves centering a data point (or *x*) by subtracting its mean, thus
    making it a zero-mean variable. Whitening, another preprocessing method, transforms
    a data point (*x*) linearly so that its components are uncorrelated and equal
    unity.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 中心化是最常用的基本预处理方法，正如其名所示，涉及通过减去其均值来中心化数据点（或*x*），从而使其成为一个零均值变量。白化是另一种预处理方法，它将数据点（*x*）线性变换，使其成分不相关且等于单位一。
- en: Factor analysis
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 因子分析
- en: '**Factor analysis** is yet another important statistical method used to determine
    and describe the data''s (or the data components'') variability between *observed*,
    correlated variables versus (a potentially) lower number of *unobserved* (or also
    referred to as *latent*) variables, or the data *factors*.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**因子分析**是另一种重要的统计方法，用于确定和描述数据（或数据成分）在*观测*、相关变量与（可能）较少的*未观测*（或也称为*潜在*）变量或数据*因子*之间的可变性。'
- en: Note
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '*Observed variables* are those variables for which you should have clearly
    defined measurements in a data file, whereas *unobserved variables* are those
    variables for which you do not have clearly defined measurements and that perhaps
    are inferred from certain observed variables within your data file.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '*观测变量*是指那些你应该在数据文件中有明确测量的变量，而*未观测变量*是指那些你没有明确测量的变量，也许是从数据文件中的某些观测变量中推断出来的。'
- en: 'In other words, we consider: Is it possible that variations in *six observed
    variables* reflect the same variations found in only *two unobserved variables*?'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们考虑：六种观测变量的变化是否反映了仅两种未观测变量中发现的相同变化？
- en: Factor analysis should/can be used when a data file includes a *large number
    of observed* variables that seem to reflect *a smaller number of unobserved variables*,
    giving us an opportunity for dimensional reduction, reducing the number of elements
    to be studied, and observing how they are interlinked.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据文件包含大量似乎反映较少未观测变量的*观测变量*时，可以使用因子分析，这为我们提供了降维的机会，减少了需要研究的项目数量，并观察它们是如何相互关联的。
- en: Overall, factor analysis involves using techniques to help yield a smaller number
    of linear combinations of variables that, even though there is a reduced number
    of variables, account for and explain the majority of the variance in the data's
    components.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，因子分析涉及使用技术来帮助产生更少的变量线性组合，尽管变量数量减少了，但它们解释了数据成分中的大部分方差。
- en: In short, performing a factor analysis on a data file attempts to search for
    *cooperative variations* in previously unobserved variables.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，对数据文件进行因子分析试图寻找先前未观测变量中的*协同变化*。
- en: Explore and confirm
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索和确认
- en: Typically, one would begin the exercise of factor analysis with an exploration
    of the data file, exploring probable underlying factor structures of a set(s)
    of the *data's observed variables* without imposing a predetermined outcome. This
    process is referred to as **exploratory factor analysis** (**EFA**).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，人们会从探索数据文件开始进行因子分析，探索一组*数据观测变量*的可能潜在因子结构，而不强加一个预定的结果。这个过程被称为**探索性因子分析**（**EFA**）。
- en: During the exploratory factor analysis phase, we attempt to determine the number
    of unobserved or hidden variables and come up with a means of explaining variation
    within the data using a smaller number of hidden variables; in other words, we
    are condensing the information required for observation.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索性因子分析阶段，我们试图确定未观察或隐藏变量的数量，并提出一种使用更少的隐藏变量来解释数据中变异的方法；换句话说，我们正在压缩观察所需的信息。
- en: Once determinations are made (one or more hypothesis is formed), one would then
    want to confirm (or test or validate) the factor structure that was revealed during
    the EFA process. This step is known widely as **confirmatory factor analysis**
    (**CFA**).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦做出确定（形成一个或多个假设），接下来就会想要确认（或测试或验证）在EFA过程中揭示的因子结构。这一步骤通常被称为**验证性因子分析**（**CFA**）。
- en: Using R for factor analysis
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用R进行因子分析
- en: As usual, the R programming language provides various ways of performing a proper
    factor analysis.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，R编程语言提供了多种执行适当因子分析的方法。
- en: 'For example, we have the R function `factanal`. This function performs a maximum-likelihood
    factor analysis on a numeric matrix. In its simplest form, this function needs
    *x* (your numeric matrix object) and the number of factors to be considered (or
    fitted):'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们有R函数`factanal`。此函数对一个数值矩阵执行最大似然因子分析。在其最简单形式中，此函数需要*x*（你的数值矩阵对象）和要考虑的因子数量（或拟合）：
- en: '[PRE1]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We can run a simple example here for clarification based upon the R documentation
    and a number of generic functions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这里运行一个简单的示例，以澄清基于R文档和许多通用函数。
- en: First, a *numeric matrix* is constructed by combining lists of random numeric
    values into six variables saved as R vectors (v1 through v6).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过将随机数值列表组合成六个变量（保存为R向量v1到v6）来构建一个*数值矩阵*。
- en: 'The R code is shown as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示，R代码：
- en: '[PRE2]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The next step is to create a numeric matrix from our six variables, calling
    it `m1`.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是从我们的六个变量创建一个数值矩阵，命名为`m1`。
- en: 'To accomplish this, we can use the R `cbind` function:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成此操作，我们可以使用R的`cbind`函数：
- en: '[PRE3]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following screenshot shows our code executed, along with a summary of our
    object `m1`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了我们的代码执行情况，以及我们的对象`m1`的摘要：
- en: '![Using R for factor analysis](img/00153.jpeg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![使用R进行因子分析](img/00153.jpeg)'
- en: The R function `summary` provides us with some interesting details about our
    six variables, such as the minimum and maximum values, median, and the mean.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: R函数`summary`为我们提供了关于我们六个变量的有趣细节，例如最小值和最大值、中位数和平均值。
- en: Now that we have a numeric matrix, we can *review the variances* between our
    six variables by running the R `cor` function.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个数值矩阵，我们可以通过运行R的`cor`函数来*审查*我们六个变量之间的方差。
- en: 'The following screenshot shows the output that is generated from the `cor`
    function:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了由`cor`函数生成的输出：
- en: '![Using R for factor analysis](img/00154.jpeg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![使用R进行因子分析](img/00154.jpeg)'
- en: Interesting information, but let's move on.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的信息，但让我们继续前进。
- en: Finally, we are now ready to use (the R function) `factanal`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们现在准备好使用（R函数）`factanal`。
- en: 'Again, using the function''s simplest form - simply providing the name of the
    data to analyze (`m1`) and the number of factors to consider (let''s use `3`)
    - the following output is generated for us:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，使用函数的最简单形式——只需提供要分析的数据名称（`m1`）和要考虑的因子数量（让我们使用`3`）——以下输出就为我们生成了：
- en: '![Using R for factor analysis](img/00155.jpeg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![使用R进行因子分析](img/00155.jpeg)'
- en: The output
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输出
- en: The R function `factanal` first calculates *uniqueness*. Uniqueness is the variance
    that is unique to each variable and not shared with other variables.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: R函数`factanal`首先计算*独特性*。独特性是每个变量独有的方差，不与其他变量共享。
- en: Factor *loadings* are also calculated and displayed in a *factor matrix*. The
    factor matrix is the matrix that contains the factor loadings of all the variables
    on all the factors extracted. The term factor loadings denotes the simple correlations
    between the factors and the variables, such as the correlation between the observed
    score and the unobserved score. Generally, the higher the better.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 因子*载荷*也被计算并显示在*因子矩阵*中。因子矩阵是包含所有变量在所有提取的因子上的因子载荷的矩阵。因子载荷表示因子与变量之间的简单相关，例如观察分数与未观察分数之间的相关。一般来说，越高越好。
- en: 'Notice the final message generated in the preceding screenshot:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 注意前一个截图生成的最终消息：
- en: '**The degrees of freedom for the model is 0 and the fit was 0.4755**'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型的自由度为0，拟合度为0.4755**'
- en: The number of *degrees of freedom* can be defined as the minimum number of independent
    coordinates that can specify the position of the system completely (therefore,
    a zero is not so good). So, if we experiment a bit by increasing the numbers of
    factors to four, we see that `factanal` is smart enough to tell us that, with
    only six variables, four is too many factors.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 自由度的数量可以定义为可以完全指定系统位置的独立坐标的最小数量（因此，零不是那么好）。所以，如果我们通过增加因素的数目到四个进行一点实验，我们会看到`factanal`足够聪明，能告诉我们，只有六个变量时，四个因素太多了。
- en: 'The following screenshot shows (globally) the output generated using four factors:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了使用四个因素生成的（全局）输出：
- en: '![The output](img/00156.jpeg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![输出](img/00156.jpeg)'
- en: 'Given the results shown, let us now try decreasing the number of factors to
    two:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 根据显示的结果，现在让我们尝试将因素的数目减少到两个：
- en: '![The output](img/00157.jpeg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![输出](img/00157.jpeg)'
- en: Notice that this time we see that two factors are sufficient.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这次我们看到两个因素就足够了。
- en: Based upon the preceding, the results of our simple factor analysis seem to
    have improved but does this mean that the number of variables could correctly
    describe the data?
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的内容，我们简单的因子分析结果似乎有所改善，但这是否意味着变量的数量可以正确地描述数据？
- en: Obviously, more data, more variables and more experimentation are required!
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，需要更多的数据、更多的变量和更多的实验！
- en: NNMF
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NNMF
- en: The term *factorization* refers to the process or act of factoring, which is
    the breakdown of an object into a result (of other objects, or *factors*) that,
    when multiplied together, equal the original. *Matrix* factorization then, is
    factorizing a matrix, or finding two (or more) matrices that will equal the original
    matrix when you multiply them.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 术语*分解*指的是分解的过程或行为，即把一个对象分解成其他对象（或*因子*）的结果，当它们相乘时等于原始对象。因此，*矩阵分解*就是分解矩阵，或者找到两个（或更多）矩阵，当它们相乘时等于原始矩阵。
- en: '**Non-negative matrix factorization** (**NMF**, **NNMF**) is using an algorithm
    to factorize a matrix into (usually) two matrices with the property that all three
    matrices have no negative elements. This non-negativity makes the resulting matrices
    easier to analyze.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '**非负矩阵分解**（**NMF**，**NNMF**）是使用算法将矩阵分解成（通常是）两个矩阵，这三个矩阵都具有没有负元素的特性。这种非负性使得生成的矩阵更容易分析。'
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we introduced the idea of (and purpose for) data *dimensional
    reduction*: reducing the total number of observations to consider when creating
    a predictive model.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了（数据）*降维*的概念及其目的：在创建预测模型时减少需要考虑的总观测数。
- en: The most common methods, strategies, and concepts for reduction were reviewed,
    including correlated data analysis, reporting on correlation, PCA, ICA, and factor
    analysis.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 对减少的最常见方法、策略和概念进行了回顾，包括相关数据分析、报告相关性、PCA、ICA和因子分析。
- en: In the next chapter, we think about how several trained models can work together
    as an ensemble, in order to produce a single model that is more powerful than
    the individual models involved.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们思考几个训练好的模型如何作为一个集成体一起工作，以产生一个比单个模型更强大的单一模型。
