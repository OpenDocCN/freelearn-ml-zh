- en: 03 Cassava Leaf Disease competition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 03 木薯叶病竞赛
- en: Join our book community on Discord
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我们的Discord书籍社区
- en: '[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/EarlyAccessCommunity](https://packt.link/EarlyAccessCommunity)'
- en: '![](img/file10.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](img/file10.png)'
- en: 'In this chapter we will leave the domain of tabular data and focus on image
    processing. In order to demonstrate the steps necessary to do well in classification
    competitions, we will use the data from the Cassava Leaf Disease contest:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将离开表格数据的领域，专注于图像处理。为了演示在分类竞赛中取得好成绩所需的步骤，我们将使用木薯叶病竞赛的数据：
- en: '[https://www.kaggle.com/competitions/cassava-leaf-disease-classification](https://www.kaggle.com/competitions/cassava-leaf-disease-classification)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/competitions/cassava-leaf-disease-classification](https://www.kaggle.com/competitions/cassava-leaf-disease-classification)'
- en: 'The first thing to do upon starting a Kaggle competition is to read the descriptions
    properly:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 开始参加Kaggle竞赛的第一件事是正确阅读描述：
- en: '*“As the second-largest provider of carbohydrates in Africa, cassava is a key
    food security crop grown by smallholder farmers because it can withstand harsh
    conditions. At least 80% of household farms in Sub-Saharan Africa grow this starchy
    root, but viral diseases are major sources of poor yields. With the help of data
    science, it may be possible to identify common diseases so they can be treated.”*'
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“作为非洲第二大碳水化合物供应商，木薯是小型农户种植的关键粮食安全作物，因为它能够承受恶劣条件。至少80%的撒哈拉以南非洲的家庭农场种植这种淀粉根，但病毒性疾病是产量低下的主要原因。借助数据科学，可能能够识别常见疾病，以便进行治疗。”*'
- en: So this competition relates to an actually important real-life problem - your
    mileage might vary, but in general it is useful to know that.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个竞赛与一个实际重要的现实生活问题相关——你的里程可能会有所不同，但一般来说，了解这一点是有用的。
- en: '*“Existing methods of disease detection require farmers to solicit the help
    of government-funded agricultural experts to visually inspect and diagnose the
    plants. This suffers from being labor-intensive, low-supply and costly. As an
    added challenge, effective solutions for farmers must perform well under significant
    constraints, since African farmers may only have access to mobile-quality cameras
    with low-bandwidth.”*'
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“现有的疾病检测方法要求农民寻求政府资助的农业专家的帮助，进行视觉检查和诊断植物。这既费时费力，供应不足，又昂贵。作为一个额外的挑战，有效的解决方案必须在重大限制下表现良好，因为非洲农民可能只能使用移动质量的相机和低带宽。”*'
- en: 'This paragraph - especially the last sentence - sets the expectations: since
    the data is coming from diverse sources, we are likely to have some challenges
    related to quality of the images and (possibly) distribution shift.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这段话——特别是最后一句话——设定了期望：由于数据来自不同的来源，我们可能会遇到一些与图像质量和（可能）分布偏移相关的挑战。
- en: '*“Your task is to classify each cassava image into four disease categories
    or a fifth category indicating a healthy leaf. With your help, farmers may be
    able to quickly identify diseased plants, potentially saving their crops before
    they inflict irreparable damage.”*'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“你的任务是将每个木薯图像分类到四个疾病类别或第五个表示健康叶片的类别。在你的帮助下，农民可能能够快速识别患病植物，从而在它们造成不可修复的损害之前挽救他们的作物。”*'
- en: 'This bit is rather important: it specifies that this is a classification competition,
    and the number of classes is small (5).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分相当重要：它指定这是一个分类竞赛，类别数量较少（5个）。
- en: With the introductory footwork out of the way, let us have a look at the data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成介绍性的准备工作后，让我们来看看数据。
- en: Understanding the data and metrics
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解数据和指标
- en: 'Upon entering the “Data” tab for this competition, we see the summary of the
    provided data:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 进入这个竞赛的“数据”标签页，我们看到提供的数据摘要：
- en: '![Figure 3.1: description of the Cassava competition dataset](img/file11.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1：木薯竞赛数据集描述](img/file11.png)'
- en: 'Figure 3.1: description of the Cassava competition dataset'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1：木薯竞赛数据集描述
- en: What can we make of that?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能从中得到什么？
- en: The data is in a fairly straightforward format, where the organisers even provided
    the mapping between disease names and numerical codes
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据格式相当直接，组织者甚至提供了疾病名称和数值代码之间的映射
- en: We have the data in tfrecord format, which is good news for anyone interested
    in using a TPU
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有tfrecord格式的数据，这对于任何有兴趣使用TPU的人来说是个好消息
- en: The provided test set is only a small subset and to be substituted with the
    full dataset at evaluation time. **This suggests that loading a previously trained
    model at evaluation time and using it for inference is a preferred strategy.**
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供的测试集只是一个小的子集，在评估时需要用完整的数据集替换。**这表明，在评估时加载先前训练的模型并使用它进行推理是一种更受欢迎的策略**。
- en: 'The evaluation metric was chosen to be categorization accuracy: [https://developers.google.com/machine-learning/crash-course/classification/accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy).
    This metric takes discrete values as inputs, which means potential ensembling
    strategies become somewhat more involved. Loss function is implemented during
    training to optimise a learning function and as long as we want to use methods
    based on gradient descent, this one needs to be continuous; evaluation metric,
    on the other hand, is used after training to measure overall performance and as
    such, can be discrete.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标被选为分类准确率：[https://developers.google.com/machine-learning/crash-course/classification/accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy)。这个指标接受离散值作为输入，这意味着潜在的集成策略变得稍微复杂一些。损失函数在训练期间实现，以优化学习函数，只要我们想使用基于梯度下降的方法，这个函数就需要是连续的；另一方面，评估指标在训练后用于衡量整体性能，因此可以是离散的。
- en: '**Exercise**: without building a model, write a code to conduct a basic EDA'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习**：不构建模型，编写代码进行基本的EDA'
- en: Compare the cardinality of classes in our classification problem
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较我们的分类问题中类的基数
- en: 'Normally, this would also be the moment to check for distribution shift: if
    the images are very different in train and test set, it is something that most
    certainly needs to be taken into account. However, since we do not have access
    to the complete dataset in this case, the step is omitted - please check Chapter
    1 for a discussion of adversarial validation, which is a popular technique for
    detecting concept drift between datasets.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这也是检查分布偏移的时刻：如果训练集和测试集中的图像非常不同，这肯定是需要考虑的事情。然而，由于在这种情况下我们没有访问完整的数据集，这一步被省略了——请参阅第一章，其中讨论了对抗性验证，这是一种检测数据集之间概念漂移的流行技术。
- en: Building a baseline model
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建基线模型
- en: 'We start our approach by building a baseline solution. The notebook running
    an end-to-end solution is available at:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从构建基线解决方案开始。运行端到端解决方案的笔记本可在以下位置找到：
- en: While hopefully useful as a starting point for other competitions you might
    want to try, it is more educational to follow the flow described in this section,
    i.e. copying the code cell by cell, so that you can understand it better (and
    of course improve on it - it is called a baseline solution for a reason).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然希望作为您可能想要尝试的其他比赛的起点是有用的，但遵循本节中描述的流程进行学习更有教育意义，即逐个复制代码单元格，这样您可以更好地理解它（当然，您也可以改进它——它之所以被称为基线解决方案，是有原因的）。
- en: '![Figure 3.2: the imports needed for our baseline solution](img/file12.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2：基线解决方案所需的导入](img/file12.png)'
- en: 'Figure 3.2: the imports needed for our baseline solution'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2：基线解决方案所需的导入
- en: 'We begin by importing the necessary packages - while personal differences in
    style are a natural thing, it is our opinion that gathering the imports in one
    place makes the code easier to maintain as the competition progresses and you
    move towards more elaborate solutions. In addition, we create a configuration
    class: a placeholder for all the parameters defining our learning process:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入必要的包——虽然个人风格差异是自然的事情，但我们的观点是，将导入集中在一个地方会使代码在比赛进展和向更复杂的解决方案过渡时更容易维护。此外，我们创建了一个配置类：所有定义我们学习过程参数的占位符：
- en: '![Figure 3.3: configuration class for our baseline solution](img/file13.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3：基线解决方案的配置类](img/file13.png)'
- en: 'Figure 3.3: configuration class for our baseline solution'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3：基线解决方案的配置类
- en: 'The components include:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 组件包括：
- en: The data folder is mostly useful if you train models outside of Kaggle sometimes
    (e.g. in Google Colab or on your local machine)
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据文件夹在您有时在Kaggle之外训练模型时非常有用（例如，在Google Colab或本地机器上）
- en: BATCH_SIZE is a parameter that sometimes needs adjusting if you want to optimise
    your training process (or make it possible at all, for large images in constrained
    memory environment)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BATCH_SIZE是一个参数，如果您想优化您的训练过程（或在受限制的内存环境中处理大图像时使其成为可能），有时需要调整
- en: 'Modifying EPOCHS is useful for debugging: start with small number of epochs
    to verify that your solution is running smoothly end-to-end and increase as you
    are moving towards a proper solution'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改 EPOCHS 对于调试很有用：从少量 EPOCHS 开始，以验证你的解决方案是否可以顺畅地从头到尾运行，并在你接近正确解决方案时增加
- en: TARGET_SIZE defines the size to which we want to rescale our images
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TARGET_SIZE 定义了我们想要将图像重新缩放的尺寸
- en: NCLASSES corresponds to the number of possible classes in our classification
    problem
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NCLASSES 对应于我们的分类问题中的可能类别数量
- en: 'A good practice for coding a solution is to encapsulate the important bits
    in functions - and creating our trainable model certainly qualifies as important:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 编码解决方案的一个好习惯是将重要的部分封装在函数中 - 而创建我们的可训练模型当然符合重要性的标准：
- en: '![Figure 3.4: function to create our model](img/file14.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 3.4: 创建我们的模型函数](img/file14.png)'
- en: 'Figure 3.4: function to create our model'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 'Figure 3.4: 创建我们的模型函数'
- en: 'Few remarks around this step:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 关于此步骤的一些简要说明：
- en: While more expressive options are available, it is practical to begin with a
    fast model that can quickly iterated upon; EfficientNet [https://paperswithcode.com/method/efficientnet](https://paperswithcode.com/method/efficientnet)
    architecture fits the bill quite well
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然有更多表达性的选项可用，但开始使用一个可以快速迭代的快速模型是实用的；EfficientNet [https://paperswithcode.com/method/efficientnet](https://paperswithcode.com/method/efficientnet)
    架构非常适合这个要求
- en: We add a pooling layer for regularisation purposes
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们添加一个池化层用于正则化目的
- en: Add a classification head - a Dense layer with CFG.NCLASSES indicating the number
    of possible results for the classifier
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加一个分类头 - 一个 Dense 层，其中 CFG.NCLASSES 表示分类器的可能结果数量
- en: Finally, we compile the model with loss and metric corresponding to the requirements
    for this competition.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们使用与此次比赛要求相对应的损失和指标来编译模型。
- en: '**Exercise**: Examine the possible choices for loss and metric - a useful guide
    is [https://keras.io/api/losses/](https://keras.io/api/losses/) What would the
    other reasonable options be?'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习**：检查损失和指标的可能选择 - 一个有用的指南是 [https://keras.io/api/losses/](https://keras.io/api/losses/)
    其他合理的选项是什么？'
- en: 'Next step is the data:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是数据：
- en: '![](img/file15.png)![Figure 3.5: setting up the data generator](img/file16.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![img/file15.png](img/file15.png)![Figure 3.5: 设置数据生成器](img/file16.png)'
- en: 'Figure 3.5: setting up the data generator'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 'Figure 3.5: 设置数据生成器'
- en: 'Next we setup the model - straightforward, thanks to the function we defined
    above:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们设置模型 - 由于我们定义了上述函数，所以非常直接：
- en: '![Figure 3.6: instantiating the model](img/file17.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 3.6: 实例化模型](img/file17.png)'
- en: 'Figure 3.6: instantiating the model'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 'Figure 3.6: 实例化模型'
- en: 'Before we proceed with training the model, we should dedicate some attention
    to callbacks:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始训练模型之前，我们应该关注回调：
- en: '![Figure 3.7: Model callbacks](img/file18.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 3.7: 模型回调](img/file18.png)'
- en: 'Figure 3.7: Model callbacks'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 'Figure 3.7: 模型回调'
- en: 'Some points worth mentioning:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的一些点：
- en: ModelCheckpoint is used to ensure we keep the weights for the best model only,
    where the optimality is decided on the basis of the metric to monitor (validation
    loss in this instance)
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ModelCheckpoint 用于确保我们只保留最佳模型的权重，其中最优性是基于要监控的指标（在本例中为验证损失）来决定的
- en: EarlyStopping helps us control the risk of overfitting by ensuring that the
    training is stopped if the validation loss does not improve (decrease) for a given
    number of epochs
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: EarlyStopping 通过确保在给定数量的 EPOCHS 内验证损失没有改善（下降）时停止训练，帮助我们控制过拟合的风险
- en: ReduceLROnPlateau is a schema for learning rate
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReduceLROnPlateau 是一个学习率方案
- en: '**Exercise**: what parameters would it make sense to modify in the above setup,
    and which ones can be left at their default values?'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习**：在上面的设置中，哪些参数值得修改，哪些可以保留为默认值？'
- en: 'With this setup, we can fit the model:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此设置，我们可以拟合模型：
- en: '![Figure 3.8: Fitting the model](img/file19.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 3.8: 拟合模型](img/file19.png)'
- en: 'Figure 3.8: Fitting the model'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 'Figure 3.8: 拟合模型'
- en: Once the training is complete, we can use the model to build the prediction
    of image class for each image in the test set. Recall that in this competition
    the public (visible) test set consisted of a single image and the size of the
    full one was unknown - hence the need for a slightly convoluted manner of constructing
    the submission dataframe
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练完成，我们可以使用该模型为测试集中的每个图像构建图像类别的预测。回想一下，在这个比赛中，公开（可见）的测试集仅包含一个图像，完整测试集的大小是未知的
    - 因此需要稍微复杂的方式来构建提交数据框
- en: '![Figure 3.9: Generating a submission](img/file20.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 3.9: 生成提交](img/file20.png)'
- en: 'Figure 3.9: Generating a submission'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 'Figure 3.9: 生成提交'
- en: In this section we have demonstrated how to start to compete in a competition
    focused on image classification - you can use this approach to move quickly from
    basic EDA to a functional submission. However, a rudimentary approach like this
    is unlikely to produce very competitive results. For this reason, in the next
    section we discuss more specialised techniques that were utilised in top scoring
    solutions.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了如何开始参加一个专注于图像分类的竞赛——你可以使用这种方法快速从基本的EDA（探索性数据分析）过渡到功能性的提交。然而，像这样的基础方法不太可能产生非常具有竞争力的结果。因此，在下一节中，我们将讨论在顶级得分解决方案中使用的更多专业技术。
- en: Learnings from top solutions
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 顶级解决方案的启示
- en: 'In this section we gather aspects from the top solutions that could allow us
    to rise above the level of the baseline solution. Keep in mind that the leaderboard
    (both public and private) in this competition were quite tight; this was a combination
    of a few factors:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们汇集了顶级解决方案的各个方面，这些方面可能使我们超越基线解决方案的水平。请注意，在这个竞赛中，排行榜（无论是公开的还是私人的）都非常紧密；这是几个因素的组合：
- en: The noisy data - it was easy to get to .89 accuracy by correctly identifying
    large part of the train data, and then each new correct one allowed for a tiny
    move upward
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 噪声数据——通过正确识别大部分训练数据，很容易达到0.89的准确率，然后每个新的正确识别都允许进行微小的提升
- en: The metric - accuracy can be tricky to ensemble
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标——准确率在集成中可能很棘手
- en: Limited size of the data
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据量有限
- en: Pretraining
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预训练
- en: 'First and most obvious remedy to the issue of limited data size was pretraining:
    using more data. The Cassava competition was held a year before as well:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 解决数据量有限问题的第一个也是最明显的补救措施是预训练：使用更多数据。木薯竞赛一年前也举行过：
- en: '[https://www.kaggle.com/competitions/cassava-disease/overview](https://www.kaggle.com/competitions/cassava-disease/overview)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/competitions/cassava-disease/overview](https://www.kaggle.com/competitions/cassava-disease/overview)'
- en: 'With minimal adjustments, the data from the 2019 edition could be leveraged
    in the context of the current one. Several competitors addressed the topic:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通过最小的调整，2019版的数据可以在当前版本中发挥作用。几位竞争者讨论了这个问题：
- en: 'Combined 2019 + 2020 dataset in TFRecords format was released in the forum:
    [https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/199131](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/199131)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在论坛上发布了2019 + 2020数据集的TFRecords格式：[https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/199131](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/199131)
- en: 'Winning solution from the 2019 edition served as a useful starting point: [https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/216985](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/216985)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2019版竞赛的获胜方案作为一个有用的起点：[https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/216985](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/216985)
- en: Generating predictions on 2019 data and using the pseudo-labels to augment the
    dataset was reported to yield some (minor) improvements [https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/203594](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/203594)
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在2019年的数据上生成预测并使用伪标签来扩充数据集据报道可以带来一些（轻微的）改进 [https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/203594](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/203594)
- en: TTA
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TTA（测试时间增强）
- en: 'The idea behind Test Time Augmentation (TTA) is to apply different transformations
    to the test image: rotations, flipping and translations. This creates a few different
    versions of the test image and we generate a prediction for each of them. The
    resulting class probabilities are then averaged to get a more confident answer.
    An excellent demonstration of this technique is given in a notebook by Andrew
    Khael: [https://www.kaggle.com/code/andrewkh/test-time-augmentation-tta-worth-it](https://www.kaggle.com/code/andrewkh/test-time-augmentation-tta-worth-it)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 测试时间增强（TTA）背后的想法是对测试图像应用不同的变换：旋转、翻转和平移。这创建了几个不同的测试图像版本，并为每个版本生成一个预测。然后将结果类概率平均，以获得更自信的答案。Andrew
    Khael在笔记本中提供了一个关于此技术的优秀演示：[https://www.kaggle.com/code/andrewkh/test-time-augmentation-tta-worth-it](https://www.kaggle.com/code/andrewkh/test-time-augmentation-tta-worth-it)
- en: 'TTA was used extensively by the top solutions in the Cassava competition, an
    excellent example being the top3 private LB result: [https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221150](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221150)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在Cassava竞赛中，顶级解决方案广泛使用了TTA，一个优秀的例子是顶级3的私人LB结果：[https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221150](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221150)
- en: Transformers
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Transformer
- en: 'While more known architectures like ResNext and EfficientNet were used a lot
    in the course of the competition, it was the addition of more novel ones that
    provided the extra edge to many competitors yearning for progress in a tightly
    packed leaderboard. Transformers emerged in 2017 as a revolutionary architecture
    for NLP (if somehow you missed the paper that started it all, here it is: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))
    and were such a spectacular success that inevitably many people started wondering
    if they could be applied to other modalities as well - vision being an obvious
    candidate. Aptly named Vision Transformer made one of its first appearances in
    a Kaggle competition in the Cassava contest. An excellent tutorial for ViT has
    been made public:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在竞赛过程中使用了更多的已知架构，如ResNext和EfficientNet，但正是添加了更多新颖的架构，为许多渴望在拥挤的排行榜上取得进步的竞争者提供了额外的优势。Transformer在2017年作为NLP（自然语言处理）的一次革命性架构出现（如果你错过了启动这一切的论文，这里就是：[https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)），并且取得了如此巨大的成功，以至于不可避免地许多人开始思考它们是否也可以应用于其他模态——视觉显然是一个明显的候选者。名为Vision
    Transformer的架构在Cassava竞赛中首次亮相。已经公开了一个关于ViT的优秀教程：
- en: '[https://www.kaggle.com/code/abhinand05/vision-transformer-vit-tutorial-baseline](https://www.kaggle.com/code/abhinand05/vision-transformer-vit-tutorial-baseline)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/code/abhinand05/vision-transformer-vit-tutorial-baseline](https://www.kaggle.com/code/abhinand05/vision-transformer-vit-tutorial-baseline)'
- en: 'Vision Transformer was an important component of the winning solution:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Vision Transformer是获胜解决方案的一个重要组成部分：
- en: '[https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221150](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221150)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221150](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221150)'
- en: Ensembling
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成学习
- en: 'The core idea of ensembling is very popular on Kaggle (see Chapter 9 of the
    Kaggle Book for a more elaborate description) and Cassava competition was no exception.
    As it turned out, combining diverse architectures was very beneficial (by averaging
    the class probabilities): EfficientNet, ResNext and ViT are sufficiently different
    from each other that their predictions complement each other. Another important
    angle was stacking, i.e. using models in two stages: the 3rd place solution combined
    predictions from multiple models and then applied LightGBM as a blender'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 集成学习的核心思想在Kaggle上非常流行（参见Kaggle书籍的第9章，以获取更详细的描述），Cassava竞赛也不例外。事实证明，结合不同的架构非常有益（通过平均类别概率）：EfficientNet、ResNext和ViT彼此之间足够不同，以至于它们的预测可以相互补充。另一个重要的角度是堆叠，即使用模型分两个阶段：第3名解决方案结合了多个模型的预测，然后应用LightGBM作为混合器
- en: '[https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/220751](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/220751)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/220751](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/220751)'
- en: 'The winning solution involved a different approach (with fewer models in the
    final blend), but relying on the same core logic:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 获胜解决方案采用了不同的方法（在最终混合中使用的模型较少），但依赖于相同的核心逻辑：
- en: '[https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221957](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221957)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221957](https://www.kaggle.com/competitions/cassava-leaf-disease-classification/discussion/221957)'
- en: Summary
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have described how to get started with a baseline solution
    for an image classification competition and discussed a diverse set of possible
    extensions for moving to a competitive (medal) zone.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们描述了如何开始使用基线解决方案参加图像分类竞赛，并讨论了多种可能的扩展方法，以进入竞争（获奖）区域。
