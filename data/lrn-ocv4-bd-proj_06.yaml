- en: Learning Object Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习对象分类
- en: In [Chapter 5](b788527c-5892-4547-8add-0864ccbd3f95.xhtml), *Automated Optical
    Inspection, Object Segmentation, and Detection*, we introduced the basic concepts
    of object segmentation and detection. This refers to isolating the objects that
    appear in an image for future processing and analysis. This chapter explains how
    to classify each of these isolated objects. To allow us to classify each object,
    we have to train our system to be capable of learning the required parameters
    so that it decide which specific label will be assigned to the detected object
    (depending on the different categories taken into account during the training
    phase).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](b788527c-5892-4547-8add-0864ccbd3f95.xhtml)《自动光学检测、对象分割和检测》中，我们介绍了对象分割和检测的基本概念。这指的是将图像中出现的对象隔离出来，以便进行未来的处理和分析。本章解释了如何对每个隔离的对象进行分类。为了使我们能够对每个对象进行分类，我们必须训练我们的系统，使其能够学习所需的参数，以便决定将哪个特定的标签分配给检测到的对象（取决于训练阶段考虑的不同类别）。
- en: This chapter introduces the basics concepts of machine learning to classify
    images with different labels. To do this, we are going to create a basic application
    based on the segmentation algorithm of [Chapter 5](b788527c-5892-4547-8add-0864ccbd3f95.xhtml),
    *Automated Optical Inspection, Object Segmentation, and Detection*. This segmentation
    algorithm extracts parts of images that contain unknown objects. For each detected object,
    we are going to extract different features that are going to be classified using
    a machine learning algorithm. Finally, we are going to show the obtained results
    using our user interface, together with the labels of each object detected in
    the input image.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了机器学习的基本概念，用于对具有不同标签的图像进行分类。为此，我们将基于[第5章](b788527c-5892-4547-8add-0864ccbd3f95.xhtml)的分割算法创建一个基本应用程序，该算法是*自动光学检测、对象分割和检测*。这个分割算法提取包含未知对象的图像部分。对于每个检测到的对象，我们将提取不同的特征，这些特征将使用机器学习算法进行分类。最后，我们将使用我们的用户界面展示获得的结果，包括输入图像中检测到的每个对象的标签。
- en: 'This chapter involves different topics and algorithms, including the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涉及不同的主题和算法，包括以下内容：
- en: Introduction to machine learning concepts
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习概念简介
- en: Common machine learning algorithms and processes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的机器学习算法和流程
- en: Feature extraction
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征提取
- en: support vector machines (SVM)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）
- en: Training and prediction
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和预测
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires familiarity with the basic C++ programming language. All
    of the code that's used in this chapter can be downloaded from the following GitHub
    link: [https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_06](https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_06). This
    code can be executed on any operating system, though it is only tested on Ubuntu.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要熟悉基本的C++编程语言。本章中使用的所有代码都可以从以下GitHub链接下载：[https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_06](https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_06)。此代码可以在任何操作系统上执行，尽管它仅在Ubuntu上进行了测试。
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，了解代码的实际应用：
- en: '[http://bit.ly/2KGD4CO](http://bit.ly/2KGD4CO)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2KGD4CO](http://bit.ly/2KGD4CO)'
- en: Introducing machine learning concepts
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍机器学习概念
- en: Machine learning is a concept that was defined by *Arthur Samuel* in 1959 as
    a field of study that gives computers the ability to learn without being explicitly
    programmed. *Tom M. Mitchel* provided a more formal definition for machine learning,
    in which he links the concept of samples with experience data, labels, and a performance
    measurement of algorithms.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个概念，由*Arthur Samuel*于1959年定义，它是一个研究领域，使计算机能够在没有明确编程的情况下学习。*Tom M. Mitchel*为机器学习提供了一个更正式的定义，其中他将样本的概念与经验数据、标签以及算法的性能测量联系起来。
- en: 'The **machine learning** definition by *Arthur Samuel* is referenced in *Some
    Studies in Machine Learning Using the Game of Checkers* in *IBM Journal of Research
    and Development* (*Volume*: *3*, *Issue*: *3*), *p*. *210*. It was also referenced
    in *The New Yorker* and *Office Management* in the same year.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在《IBM研究与发展杂志》的《使用国际象棋游戏进行机器学习研究》一文中，引用了*Arthur Samuel*对**机器学习**的定义，该文发表于同年《The
    New Yorker》和《Office Management》杂志，(*卷*：*3*，*期*：*3*，*页*：*210*)。
- en: The more formal definition from *Tom M. Mitchel* is referenced in *Machine Learning
    Book, McGray Hill 1997:* ([http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html](http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 *Tom M. Mitchel* 的更正式的定义在 *Machine Learning Book, McGray Hill 1997:* 中被引用（[http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html](http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)）。
- en: Machine learning involves pattern recognition and learning theory in artificial
    intelligence, and is related with computational statistics. It is used in hundreds
    of applications, such as **optical character recognition** (**OCR**), spam filtering,
    search engines, and thousands of computer vision applications, such as the example
    that we will develop in this chapter, where a machine learning algorithm tries
    to classify objects that appear in the input image.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习涉及人工智能中的模式识别和学习理论，与计算统计学相关。它被应用于数百个应用中，例如**光学字符识别**（**OCR**）、垃圾邮件过滤、搜索引擎，以及数千个计算机视觉应用，例如我们将在本章中开发的例子，其中机器学习算法试图对输入图像中出现的对象进行分类。
- en: 'Depending on how machine learning algorithms learn from the input data, we
    can divide them into three categories:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 根据机器学习算法从输入数据中学习的方式，我们可以将它们分为三类：
- en: '**Supervised learning**: The computer learns from a set of labeled data. The
    goal here is to learn the parameters of the model and rules that allow computers
    to map the relationship between data and output label results.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**：计算机从一组标记的数据中学习。这里的目的是学习模型的参数和规则，这些规则允许计算机将数据与输出标签之间的关系映射出来。'
- en: '**Unsupervised learning**: No labels are given and the computer tries to discover
    the input structure of the given data.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**：没有给出标签，计算机试图发现给定数据的输入结构。'
- en: '**Reinforcement learning**: The computer interacts with a dynamic environment,
    reaching their goal and learning from their mistakes.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习**：计算机与动态环境交互，达到目标并从错误中学习。'
- en: 'Depending on the results we wish to gain from our machine learning algorithm,
    we can categorize the results as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们希望从机器学习算法中获得的结果，我们可以将结果分类如下：
- en: '**Classification**: The space of the inputs can be divided into **N** classes,
    and the prediction results for a given sample are one of these training classes.
    This is one of the most used categories. A typical example can be email spam filtering,
    where there are only two classes: spam and non-spam. Alternatively, we can use
    OCR, where only N characters are available and each character is one class.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：输入空间可以划分为 **N** 个类别，给定样本的预测结果将是这些训练类别之一。这是最常用的类别之一。一个典型的例子是电子邮件垃圾邮件过滤，其中只有两个类别：垃圾邮件和非垃圾邮件。或者，我们可以使用OCR，其中只有N个字符可用，每个字符是一个类别。'
- en: '**Regression**: The output is a continuous value instead of a discrete value
    like a classification result. One example of regression could be the prediction
    of a house price given the house''s size, number of years since it was built,
    and location.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**：输出是一个连续值，而不是分类结果这样的离散值。回归的一个例子可能是根据房屋的大小、建造以来的年数和位置预测房价。'
- en: '**Clustering**: The input is to be divided into N groups, which is typically
    done using unsupervised training.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**：输入将被划分为 **N** 个组，这通常使用无监督训练来完成。'
- en: '**Density estimation**: Finds the (probability) distribution of inputs.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**密度估计**：找到输入的（概率）分布。'
- en: In our example, we are going to use a supervised learning and classification
    algorithm where a training dataset with labels is used to train the model and
    the result of the model's prediction is one of the possible labels. In machine
    learning, there are several approaches and methods for this. Some of the more
    popular ones include the following: **support vector machines** (**SVM**), **artificial
    neural networks** (**ANN**), clustering, k-nearest neighbors, decision trees,
    and deep learning. Almost all of these methods and approaches are supported, implemented,
    and well documented in OpenCV. In this chapter, we are going to explain support
    vector machines.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们将使用一个监督学习和分类算法，其中使用带有标签的训练数据集来训练模型，模型的预测结果将是可能的标签之一。在机器学习中，有几种方法和途径可以实现这一点。其中一些更受欢迎的方法包括以下内容：**支持向量机**（**SVM**）、**人工神经网络**（**ANN**）、聚类、k-最近邻、决策树和深度学习。几乎所有这些方法和途径都在OpenCV中得到支持、实现和良好记录。在本章中，我们将解释支持向量机。
- en: OpenCV machine learning algorithms
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCV机器学习算法
- en: 'OpenCV implements eight of these machine learning algorithms. All of them are
    inherited from the `StatModel` class:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV实现了这八种机器学习算法。所有这些算法都是继承自`StatModel`类：
- en: Artificial neural networks
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工神经网络
- en: Random trees
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机树
- en: Expectation maximization
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 期望最大化
- en: k-nearest neighbors
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k最近邻
- en: Logistic regression
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Normal Bayes classifiers
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正常贝叶斯分类器
- en: support vector machine
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Stochastic gradient descent SVMs
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机梯度下降SVMs
- en: Version 3 supports deep learning at a basic level, but version 4 is stable and
    more supported. We will delve into deep learning in detail in further chapters.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 版本3在基本级别上支持深度学习，但版本4更稳定且更受支持。我们将在后续章节中详细探讨深度学习。
- en: To get more information about each algorithm, read the OpenCV document page
    for machine learning at [http://docs.opencv.org/trunk/dc/dd6/ml_intro.html](http://docs.opencv.org/trunk/dc/dd6/ml_intro.html).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取有关每个算法的更多信息，请阅读OpenCV机器学习文档页面[http://docs.opencv.org/trunk/dc/dd6/ml_intro.html](http://docs.opencv.org/trunk/dc/dd6/ml_intro.html)。
- en: 'The following diagram shows the machine learning class hierarchy:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了机器学习类层次结构：
- en: '![](img/969f81a8-ad37-401b-9b90-f3c4dab87b48.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/969f81a8-ad37-401b-9b90-f3c4dab87b48.png)'
- en: The `StatModel` class is the base class for all machine learning algorithms.
    This provides the prediction and all the read and write functions that are very
    important for saving and reading our machine learning parameters and training
    data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`StatModel`类是所有机器学习算法的基类。这提供了预测以及所有非常重要的读写函数，用于保存和读取我们的机器学习参数和训练数据。'
- en: In machine learning, the most time-consuming and computing resource-consuming
    part is the training method. Training can take from seconds to weeks or months
    for large datasets and complex machine learning structures. For example, in deep
    learning, big neural network structures with more than 100,000 image datasets
    can take a long time to train. With deep learning algorithms, it is common to
    use parallel hardware processing such as GPUs with CUDA technology to decrease
    the computing time during training, or most new chip devices such as Intel Movidius.
    This means that we cannot train our algorithm each time we run our application,
    and therefore it's recommended to save our trained model with all of the parameters
    that have been learned. In future executions, we only have to load/read from our
    saved model without training, except if we need to update our model with more
    sample data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，最耗时和计算资源消耗的部分是训练方法。对于大型数据集和复杂的机器学习结构，训练可能需要从几秒到几周或几个月。例如，在深度学习中，包含超过10万个图像数据集的大型神经网络结构可能需要很长时间来训练。使用深度学习算法时，通常使用并行硬件处理，如具有CUDA技术的GPU，或大多数新的芯片设备，如Intel
    Movidius，以减少训练过程中的计算时间。这意味着我们每次运行应用程序时都不能训练我们的算法，因此建议保存我们已训练的模型，包括所有已学习的参数。在未来的执行中，我们只需要从保存的模型中加载/读取，除非我们需要用更多的样本数据更新我们的模型。
- en: '`StatModel` is the base class of all machine learning classes, such as SVM
    or ANN, except deep learning methods. `StatModel` is basically a virtual class
    that defines the two most important functions—`train` and `predict`. The `train`
    method is the main method that''s responsible for learning model parameters using
    a training dataset. This has the following three possible calls:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`StatModel`是所有机器学习类（如SVM或ANN）的基类，但不包括深度学习方法。`StatModel`基本上是一个虚拟类，它定义了两个最重要的函数——`train`和`predict`。`train`方法是负责使用训练数据集学习模型参数的主要方法。它有以下三种可能的调用方式：'
- en: '[PRE0]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The train function has the following parameters:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 训练函数有以下参数：
- en: '`TrainData`: Training data that can be loaded or created from the `TrainData`
    class. This class is new in OpenCV 3 and helps developers create training data
    and abstract from the machine learning algorithm. This is done because different
    algorithms require different types of structures of arrays for training and prediction,
    such as the ANN algorithm.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TrainData`：可以从`TrainData`类加载或创建的训练数据。这个类是OpenCV 3中的新功能，帮助开发者创建训练数据并从机器学习算法中抽象出来。这样做是因为不同的算法需要不同类型的数组结构进行训练和预测，例如ANN算法。'
- en: '`samples`: An array of training array samples such as training data in the
    format required by the machine learning algorithm.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`samples`：一个训练样本数组，例如机器学习算法所需的格式要求的训练数据。'
- en: '`layout`: `ROW_SAMPLE` (training samples are the matrix rows) or `COL_SAMPLE`
    (training samples are the matrix columns).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layout`: `ROW_SAMPLE`（训练样本是矩阵行）或`COL_SAMPLE`（训练样本是矩阵列）。'
- en: '`responses`: Vector of responses associated with the sample data.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`responses`：与样本数据关联的响应向量。'
- en: '`flags`: Optional flags defined by each method.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flags`：由每个方法定义的可选标志。'
- en: The last train method creates and trains a model of the `_TP` class type. The
    only classes accepted are the classes that implement a static create method with
    no parameters or with all default parameter values.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的训练方法创建并训练了一个`_TP`类类型的模型。唯一接受的类是实现了无参数或有所有默认参数值的静态创建方法的类。
- en: 'The `predict` method is much simpler and has only one possible call:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict`方法更简单，只有一个可能的调用：'
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The predict function has the following parameters:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 预测函数有以下参数：
- en: '`samples`: The input samples to predict results from the model can consist
    of any amount of data, whether single or multiple.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`samples`：用于从模型预测结果的输入样本可以由任何数量的数据组成，无论是单个还是多个。'
- en: '`results`: The results of each input row sample (computed by the algorithm
    from the previously trained model).'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`results`：每个输入行样本的结果（由算法从前一个训练模型计算得出）。'
- en: '`flags`: These optional flags are model-dependent. Some models, such as Boost,
    are recognized by the SVM `StatModel::RAW_OUTPUT` flag, which makes the method
    return the raw results (the sum), and not the class label.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flags`：这些可选标志与模型相关。一些模型，如Boost，通过SVM的`StatModel::RAW_OUTPUT`标志识别，这使得方法返回原始结果（总和），而不是类标签。'
- en: 'The `StatModel` class provides an interface for other very useful methods:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`StatModel`类为其他非常有用的方法提供了一个接口：'
- en: '`isTrained()` returns true if the model is trained'
  id: totrans-60
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`isTrained()` 如果模型已训练则返回true'
- en: '`isClassifier()` returns true if the model is a classifier, or false in the
    case of regression'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`isClassifier()` 如果模型是分类器则返回true，如果是回归则返回false'
- en: '`getVarCount()` returns the number of variables in training samples'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getVarCount()` 返回训练样本中的变量数量'
- en: '`save(const string& filename)` saves the model in the filename'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save(const string& filename)` 将模型保存到文件名'
- en: '`Ptr<_Tp> load(const string& filename)` loads the `<indexentry content="StatModel
    class:Ptr load(const string& filename)">` model from a filename, for example—`Ptr<SVM>
    svm = StatModel::load<SVM>("my_svm_model.xml")`'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Ptr<_Tp> load(const string& filename)` 从文件名加载模型，例如——`Ptr<SVM> svm = StatModel::load<SVM>("my_svm_model.xml")`'
- en: '`calcError(const Ptr<TrainData>& data, bool test, OutputArray resp)` calculates
    the error from test data, where the data is the training data. If the test parameter
    is true, the method calculates the error from a test subset of data; if its false,
    the method calculates the error from all training data. `resp` is the optional
    output result.'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`calcError(const Ptr<TrainData>& data, bool test, OutputArray resp)` 从测试数据计算错误，其中数据是训练数据。如果测试参数为true，则该方法从数据的测试子集计算错误；如果为false，则该方法从所有训练数据计算错误。`resp`是可选的输出结果。'
- en: Now, we are going to introduce how a basic application that uses machine learning
    in a computer vision application is constructed.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将介绍如何构建一个基本的计算机视觉应用，该应用使用机器学习。
- en: Computer vision and the machine learning workflow
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉和机器学习工作流程
- en: 'Computer vision applications with machine learning have a common basic structure.
    This structure is divided into different steps:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 带有机器学习的计算机视觉应用有一个共同的基本结构。这个结构被分为不同的步骤：
- en: '**Pre-process**'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预处理**'
- en: '**Segmentation**'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分割**'
- en: '**Feature extraction**'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征提取**'
- en: '**Classification result**'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分类结果**'
- en: '**P****ost-process**'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**后处理**'
- en: 'These are common in almost all computer vision applications, while others are
    omitted. In the following diagram, you can see the different steps that are involved:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这些在几乎所有的计算机视觉应用中都很常见，而其他一些则被省略了。在下面的图中，你可以看到涉及的不同步骤：
- en: '![](img/521ce802-ce25-4153-bd62-596f5840e17a.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/521ce802-ce25-4153-bd62-596f5840e17a.png)'
- en: Almost all computer vision applications start with a **Pre-process** applied
    to the input image, which consists of the removal of light and noise, filtering,
    blurring, and so on. After applying all pre-processing required to the input image,
    the second step is **Segmentation**. In this step, we have to extract the regions
    of interest in the image and isolate each one as a unique object of interest.
    For example, in a face detection system, we have to separate the faces from the
    rest of the parts in the scene. After detecting the objects inside the image,
    we continue to the next step. Here, we have to extract the features of each one;
    the features are normally a vector of characteristics of objects. A characteristic
    describes our objects and can be the area of an object, contour, texture pattern,
    pixels, and so on.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有计算机视觉应用程序都以对输入图像应用的**预处理**开始，这包括去除光线和噪声、过滤、模糊等。在将所有必要的预处理应用于输入图像之后，第二步是**分割**。在这一步中，我们必须从图像中提取感兴趣的区域，并将每个区域隔离为独特的感兴趣对象。例如，在人脸检测系统中，我们必须将人脸与场景中的其他部分分开。在检测到图像内的对象之后，我们继续下一步。在这里，我们必须提取每个对象的特征；特征通常是对象特征的向量。特征描述我们的对象，可以是对象的面积、轮廓、纹理图案、像素等。
- en: 'Now, we have the descriptor, also known as a feature vector or feature set,
    of our object. Descriptors are the features that describe an object, and we use
    these to train or predict a model. To do this, we have to create a large dataset
    of features where thousands of images are pre-processed. We then use the extracted
    features (image/object characteristics) such as area, size, and aspect ration,
    in the **Train** model function we choose. In the following diagram, we can see
    how a dataset is fed into a **Machine Learning Algorithm** to train and **generate**
    a **Model**:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了我们对象的描述符，也称为特征向量或特征集。描述符是描述对象的特征，我们使用这些特征来训练或预测模型。为此，我们必须创建一个包含数千张图像的大特征数据集。然后，我们在选择的**训练**模型函数中使用提取的特征（图像/对象特征），如面积、大小和宽高比。在以下图中，我们可以看到数据集是如何被输入到**机器学习算法**中以进行训练和**生成**模型的：
- en: '![](img/ff9a0fe6-976b-48b7-aaf7-bed6afbe594a.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ff9a0fe6-976b-48b7-aaf7-bed6afbe594a.png)'
- en: 'When we **Train** with a dataset, the **Model** learns all the parameters required
    to be able to predict when a new vector of features with an unknown label is given
    as input to our algorithm. In the following diagram, we can see how an unknown
    vector of features is used to **Predict** using the generated **Model**, thus
    returning the **Classification result** or regression:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用数据集进行**训练**时，**模型**学习所有必要的参数，以便能够在将未知标签的新特征向量作为输入提供给我们的算法时进行预测。在以下图中，我们可以看到如何使用生成的**模型**使用未知特征向量进行**预测**，从而返回**分类结果**或回归：
- en: '![](img/ddc7b6bc-9708-454e-9738-f97959badc3f.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ddc7b6bc-9708-454e-9738-f97959badc3f.png)'
- en: 'After predicting the result, the post-processing of output data is sometimes
    required, for example, merging multiple classifications to decrease the prediction
    error or merging multiple labels. A sample case in Optical Character recognition
    is where the **Classification result** is according to each predicted character,
    and by combining the results of character recognition, we construct a word. This
    means that we can create a post-processing method to correct errors in detected
    words. With this small introduction to machine learning for computer vision, we
    are going to implement our own application that uses machine learning to classify
    objects in a slide tape. We are going to use support vector machines as our classification
    method and explain how to use them. The other machine learning algorithms are
    used in a very similar way. The OpenCV documentation has detailed information
    about all of the machine learning algorithms at the following link: [https://docs.opencv.org/master/dd/ded/group__ml.html](https://docs.opencv.org/master/dd/ded/group__ml.html).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测结果之后，有时需要对输出数据进行后处理，例如，合并多个分类以减少预测误差或合并多个标签。在光学字符识别的一个示例中，**分类结果**是根据每个预测字符的，通过结合字符识别的结果，我们构建一个单词。这意味着我们可以创建一个后处理方法来纠正检测到的单词中的错误。通过这个对计算机视觉机器学习的简要介绍，我们将实现自己的应用程序，该程序使用机器学习来对幻灯片胶片中的对象进行分类。我们将使用支持向量机作为我们的分类方法，并解释如何使用它们。其他机器学习算法以非常相似的方式使用。OpenCV文档在以下链接中提供了有关所有机器学习算法的详细信息：[https://docs.opencv.org/master/dd/ded/group__ml.html](https://docs.opencv.org/master/dd/ded/group__ml.html)。
- en: Automatic object inspection classification example
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动对象检测分类示例
- en: 'In [Chapter 5](b788527c-5892-4547-8add-0864ccbd3f95.xhtml), *Automated Optical
    Inspection, Object Segmentation, and Detection*, we looked at an example of automatic
    object inspection segmentation where a carrier tape contained three different
    types of object: nuts, screws, and rings. With computer vision, we will be able
    to recognize each one of these so that we can send notifications to a robot or
    put each one in a different box. The following is a basic diagram of the carrier
    tape:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](b788527c-5892-4547-8add-0864ccbd3f95.xhtml)，*自动化光学检测、目标分割和检测*中，我们查看了一个自动对象检测分割的例子，其中载体胶带包含三种不同类型的对象：螺母、螺丝和环。通过计算机视觉，我们将能够识别这些对象中的每一个，以便我们可以向机器人发送通知或将每个对象放入不同的盒子中。以下是载体胶带的基本示意图：
- en: '![](img/8e9e15e5-03f9-44fa-a97e-16d176e4c291.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8e9e15e5-03f9-44fa-a97e-16d176e4c291.png)'
- en: 'In [Chapter 5](b788527c-5892-4547-8add-0864ccbd3f95.xhtml), *Automated Optical
    Inspection*, *Object Segmentation*, *and Detection*, we pre-processed the input
    images and extracted the regions of interest, isolating each object using different
    techniques. Now, we are going to apply all the concepts we explained in the previous
    sections in this example to extract features and classify each object, allowing
    the robot to put each one in a different box. In our application, we are only
    going to show the labels of each image, but we could send the positions in the
    image and the label to other devices, such as a robot. At this point, our goal
    is to give an input image with different objects, allowing the computer to detect
    the objects and show the objects'' names over each image, as demonstrated in the
    following images. However, to learn the steps of the whole process, we are going
    to train our system by creating a plot to show the feature distribution that we
    are going to use, and visualize it with different colors. We will also show the
    pre-processed input image, and the output classification result obtained. The
    final result looks as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](b788527c-5892-4547-8add-0864ccbd3f95.xhtml)，*自动化光学检测、目标分割和检测*中，我们预处理了输入图像并提取了感兴趣区域，使用不同的技术将每个对象隔离出来。现在，我们将应用在前几节中解释的所有概念，在这个例子中提取特征并对每个对象进行分类，使机器人能够将每个对象放入不同的盒子中。在我们的应用中，我们只将展示每个图像的标签，但我们可以将图像中的位置和标签发送到其他设备，例如机器人。在这个阶段，我们的目标是提供一个包含不同对象的输入图像，使计算机能够检测对象并在每个图像上显示对象的名称，如下面的图像所示。然而，为了学习整个过程的步骤，我们将通过创建一个展示我们将要使用的特征分布的图表来训练我们的系统，并用不同的颜色可视化它。我们还将展示预处理后的输入图像和获得的输出分类结果。最终结果如下：
- en: '![](img/58162061-407f-44aa-98c5-941e9a0a5ee7.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/58162061-407f-44aa-98c5-941e9a0a5ee7.png)'
- en: 'We are going to follow these steps for our example application:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将遵循以下步骤进行我们的示例应用：
- en: 'For each input image:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个输入图像：
- en: Preprocess the image
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理图像
- en: Segment the image
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分割图像
- en: 'For each object in an image:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于图像中的每个对象：
- en: Extract the features
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取特征
- en: Add the features to the training feature vector with a corresponding label (nut,
    screw, ring)
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将特征添加到训练特征向量中，并赋予相应的标签（螺母、螺丝、环）
- en: Create an SVM model.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建SVM模型。
- en: Train our SVM model with the training feature vector.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练特征向量训练我们的SVM模型。
- en: Preprocess the input image to classify each segmented object.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理输入图像以对每个分割的对象进行分类。
- en: Segment the input image.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分割输入图像。
- en: 'For each object detected:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于检测到的每个对象：
- en: Extract the features
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取特征
- en: Predict it with the SVM
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SVM进行预测
- en: model
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型
- en: Paint the result in the output image
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在输出图像上绘制结果
- en: For pre-processing and segmentation, we are going to use the code found in [Chapter
    5](b788527c-5892-4547-8add-0864ccbd3f95.xhtml), *Automated Optical Inspection*,
    *Object Segmentation*, *and Detection.* We are then going to explain how to extract
    the features and create the vectors required to **train** and **predict** our
    model.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 对于预处理和分割，我们将使用[第5章](b788527c-5892-4547-8add-0864ccbd3f95.xhtml)，*自动化光学检测、目标分割和检测*中找到的代码。然后我们将解释如何提取特征并创建训练和预测我们模型所需的向量。
- en: Feature extraction
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征提取
- en: 'The next thing we need to do is extract the features for each object. To understand
    the feature vector concept, we are going to extract very simple features in our
    example, as this is enough to get good results. In other solutions, we can get
    more complex features such as texture descriptors, contour descriptors, and so
    on. In our example, we only have nuts, rings, and screws in different positions
    and orientations in the image. The same object can be in any position of image
    and orientation, for example, the screw or the nut. We can see different orientations in
    the following image:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步，我们需要为每个对象提取特征。为了理解特征向量概念，在我们的示例中我们将提取非常简单的特征，因为这已经足够获得良好的结果。在其他解决方案中，我们可以获得更复杂的特征，如纹理描述符、轮廓描述符等。在我们的示例中，我们只有螺母、环和螺丝在图像中的不同位置和方向。相同的对象可以位于图像的任何位置和方向，例如，螺丝或螺母。我们可以在以下图像中看到不同的方向：
- en: '![](img/79ebe946-48c9-4941-8750-df622f1880ae.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/79ebe946-48c9-4941-8750-df622f1880ae.png)'
- en: 'We are going to explore some features or characteristics that could improve
    the accuracy of our machine learning algorithm. These possible characteristics
    of our different objects (nuts, screws, and rings) are as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要探索一些可能提高我们机器学习算法准确性的特征或特性。我们不同对象（如螺母、螺丝和环）的这些可能特性如下：
- en: The area of the object
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象的面积
- en: The aspect ratio, that is, the width divided by the height of the bounding rectangle
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 长宽比，即边界矩形的宽度除以高度
- en: The number of holes
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 孔洞的数量
- en: The number of contour sides
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮廓边的数量
- en: 'These characteristics can describe our objects very well, and if we use all
    of them, the classification error will be very small. However, in our implemented
    example, we are only going to use the first two characteristics, area and aspect
    ratio, for learning purposes, because we can plot these characteristics in a 2D
    graphic and show that these values correctly describe our objects. We can also
    show that we can visually differentiate between one kind of object and another
    in the graphic plot. To extract these features, we are going to use the black/white
    ROI image as input, where only one object appears in white with a black background.
    This input is the segmentation result of [Chapter 5](b788527c-5892-4547-8add-0864ccbd3f95.xhtml),
    *Automated Optical Inspection*, *Object Segmentation*, *and Detection*. We are
    going to use the `findCountours` algorithm for segmenting objects and create the
    `ExtractFeatures` function for this purpose, as we can see in the following code:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特性可以很好地描述我们的对象，如果我们使用所有这些特性，分类错误将会非常小。然而，在我们的实现示例中，我们只打算使用前两个特性，即面积和长宽比，用于学习目的，因为我们可以将这些特性绘制在二维图形中，并展示这些值正确地描述了我们的对象。我们还可以展示我们可以在图形图中直观地区分不同类型的对象。为了提取这些特征，我们将使用黑白ROI图像作为输入，其中只有一个对象以白色出现，背景为黑色。这个输入是[第5章](b788527c-5892-4547-8add-0864ccbd3f95.xhtml)，“自动光学检测”，“对象分割”和“检测”的分割结果。我们将使用`findContours`算法进行对象分割，并创建`ExtractFeatures`函数来完成这个目的，如下面的代码所示：
- en: '[PRE2]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let's explain the code that we use to extract features. We are going to create
    a function that has one image as input and return two vectors of the left and
    top position for each object detected in the image as a parameter. This data will
    be used for drawing the corresponding label over each object. The output of a
    function is a vector of vectors of floats. In other words, it is a matrix where
    each row contains the features of each object that's detected.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释我们用来提取特征的代码。我们将创建一个函数，它以一个图像作为输入，并返回一个参数，其中包含图像中检测到的每个对象的左和顶部位置的向量。这些数据将用于在每个对象上绘制相应的标签。函数的输出是一个浮点向量向量。换句话说，它是一个矩阵，其中每一行包含检测到的每个对象的特征。
- en: 'First, we have to create the output vector variable and the contours variable
    that are going to be used in our find contours algorithm segmentation. We also
    have to create a copy of our input image, because the `findCoutours` OpenCV functions
    modify the input image:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须创建输出向量变量和轮廓变量，这些变量将用于我们的`findContours`算法分割。我们还需要创建输入图像的副本，因为`findContours`
    OpenCV函数会修改输入图像：
- en: '[PRE3]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, we can use the `findContours` function to retrieve each object in an image.
    If we don''t detect any contour, we return an empty output matrix, as we can see
    in the following snippet:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`findContours`函数来检索图像中的每个对象。如果我们没有检测到任何轮廓，我们将返回一个空输出矩阵，如下面的代码片段所示：
- en: '[PRE4]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If objects are detected, for each contour we are going to draw the object in
    white on a black image (zero values). This will be done using `1` values, like
    a mask image. The following piece of code generates the mask image:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果检测到对象，对于每个轮廓，我们将在黑色图像（零值）上用白色绘制对象。这将使用 `1` 值完成，就像一个掩码图像。以下代码片段生成掩码图像：
- en: '[PRE5]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'It''s important to use the value of `1` to draw inside the shape because we
    can calculate the area by summing all of the values inside the contour, as shown
    in the following code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `1` 值在形状内部绘制是很重要的，因为我们可以通过计算轮廓内部所有值的总和来计算面积，如下代码所示：
- en: '[PRE6]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This area is our first feature. We are going to use this value as a filter
    to remove all possible small objects that we have to avoid. All objects with an
    area less than the minimum threshold area that we considered will be discarded.
    After passing the filter, we create the second feature and the aspect ratio of
    the object. This refers to the maximum of the width or height, divided by the
    minimum of the width or height. This feature can tell the difference between the
    screw and other objects easily. The following code describes how to calculate
    the aspect ratio:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这个区域是我们的第一个特征。我们将使用这个值作为过滤器，以移除所有可能的小对象，这些对象是我们需要避免的。所有面积小于我们考虑的最小阈值面积的对象都将被丢弃。通过过滤器后，我们创建第二个特征和对象的纵横比。这指的是宽度或高度的极大值除以宽度或高度的极小值。这个特征可以很容易地区分螺钉和其他对象。以下代码描述了如何计算纵横比：
- en: '[PRE7]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now we have the features, we only have to add them to the output vector. To
    do this, we will create a row vector of floats and add the values, followed by
    adding this row to the output vector, as shown in the following code:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了特征，我们只需将它们添加到输出向量中。为此，我们将创建一个浮点行向量并添加值，然后将其添加到输出向量中，如下代码所示：
- en: '[PRE8]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If the left and top parameters are passed, then add the top-left values to
    output the parameters:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果传递了左和上参数，则将左上角值添加到输出参数：
- en: '[PRE9]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, we are going to show the detected objects in a window for user feedback.
    When we finish processing all of the objects in the image, we are going to return
    the output feature vector, as described in the following code snippet:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将在一个窗口中显示检测到的对象，以便用户反馈。当我们处理完图像中的所有对象后，我们将返回输出特征向量，如下代码片段所示：
- en: '[PRE10]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now that we have extracted the features of each input image, we can continue
    with the next step.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经提取了每个输入图像的特征，我们可以继续下一步。
- en: Training an SVM model
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练 SVM 模型
- en: We are now going to use supervised learning and then obtain a set of images
    for each object and its corresponding label. There is no minimum number of images
    in the dataset; if we provide more images for the training process, we will get
    a better classification model (in most cases). However, for simple classifiers,
    it could be enough to train simple models. To do this, we created three folders
    (`screw`, `nut`, and `ring`), where all of the images of each type are placed
    together. For each image in the folder, we have to extract the features, add them
    to the `train` feature matrix and, at the same time, create a new vector with
    the labels for each row corresponding to each training matrix. To evaluate our
    system, we will split each folder into a number of images according to testing
    and training. We will leave around 20 images for testing and the others for training.
    We are then going to create two vectors of labels and two matrices for training
    and testing.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用监督学习，并为每个对象及其相应的标签获取一组图像。数据集中没有图像的最小数量；如果我们为训练过程提供更多图像，我们将得到更好的分类模型（在大多数情况下）。然而，对于简单的分类器，训练简单的模型可能就足够了。为此，我们创建了三个文件夹（`screw`、`nut`
    和 `ring`），其中每个类型的所有图像都放在一起。对于文件夹中的每张图像，我们必须提取特征，将它们添加到 `train` 特征矩阵中，同时创建一个新向量，其中每行对应于每个训练矩阵的标签。为了评估我们的系统，我们将根据测试和训练将每个文件夹分成一定数量的图像。我们将保留大约
    20 张图像用于测试，其余的用于训练。然后我们将创建两个标签向量和两个用于训练和测试的矩阵。
- en: 'Let''s go inside of our code. First, we have to create our model. We are going
    to declare the model out of all functions to be able to gain access to it as a
    global variable. OpenCV uses the `Ptr` template class for pointer management:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入代码内部。首先，我们需要创建我们的模型。我们将把模型声明在所有函数之外，以便能够将其作为全局变量访问。OpenCV 使用 `Ptr` 模板类来管理指针：
- en: '[PRE11]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After declaring the pointer to the new SVM model, we are going to create it
    and train it. We created the `trainAndTest` function for this purpose. The complete
    function code is as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在声明新的 SVM 模型指针之后，我们将创建它并进行训练。为此，我们创建了 `trainAndTest` 函数。完整的函数代码如下：
- en: '[PRE12]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, let''s explain the code. First of all, we have to create the required
    variables to store the training and testing data:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们解释一下代码。首先，我们必须创建所需的变量来存储训练和测试数据：
- en: '[PRE13]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'As we mentioned previously, we have to read all of the images from each folder,
    extract the features, and save them in our training and testing data. To do this,
    we are going to use the `readFolderAndExtractFeatures` function, as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，我们必须从每个文件夹中读取所有图像，提取特征，并将它们保存到我们的训练和测试数据中。为此，我们将使用 `readFolderAndExtractFeatures`
    函数，如下所示：
- en: '[PRE14]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `readFolderAndExtractFeatures` function uses the `VideoCapture` OpenCV
    function to read all of the images in a folder, including videos and camera frames.
    For each image that''s read, we extract the features and add them to the corresponding
    output vector:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`readFolderAndExtractFeatures` 函数使用 OpenCV 的 `VideoCapture` 函数读取文件夹中的所有图像，包括视频和相机帧。对于读取的每个图像，我们提取特征并将它们添加到相应的输出向量中：'
- en: '[PRE15]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'After filling all of the vectors with features and labels, we have to convert
    from vectors to an OpenCV `Mat` format so that we can send it to the training
    function:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在将所有向量填充好特征和标签之后，我们必须将它们从向量转换为 OpenCV `Mat` 格式，以便我们可以将其发送到训练函数：
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we are ready to create and train our machine learning model. As we stated
    previously, we are going to use the support vector machine for this. First, we
    are going to set up the basic model parameters, as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备创建和训练我们的机器学习模型。正如我们之前所述，我们将使用支持向量机来完成这项工作。首先，我们将设置基本模型参数，如下所示：
- en: '[PRE17]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We are now going to define the SVM type and kernel to use, as well as the criteria
    to stop the learning process. In our case, we are going to use a number of maximum
    iterations, stopping at 100 iterations. For more information about each parameter
    and what it does, check the OpenCV documentation at the following link:[ https://docs.opencv.org/master/d1/d2d/classcv_1_1ml_1_1SVM.html](https://docs.opencv.org/master/d1/d2d/classcv_1_1ml_1_1SVM.html).
    After creating the setup parameters, we are going to create the model by calling
    the `train` method and using `trainingDataMat` and response matrices as a `TrainData`
    object:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将定义要使用的 SVM 类型、核函数以及停止学习过程的准则。在我们的案例中，我们将使用最大迭代次数，并在 100 次迭代后停止。有关每个参数及其功能的更多信息，请查看以下链接中的
    OpenCV 文档：[https://docs.opencv.org/master/d1/d2d/classcv_1_1ml_1_1SVM.html](https://docs.opencv.org/master/d1/d2d/classcv_1_1ml_1_1SVM.html)。在创建设置参数后，我们将通过调用
    `train` 方法并使用 `trainingDataMat` 和响应矩阵作为 `TrainData` 对象来创建模型：
- en: '[PRE18]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We use the test vector (setting the `num_for_test` variable to greater than
    `0`) to obtain an approximation error of our model. To get the error estimation,
    we are going to predict all test vector features to obtain the SVM prediction
    results and compare these results to the original labels:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用测试向量（将 `num_for_test` 变量设置为大于 `0`）来获得模型的大致误差。为了获得误差估计，我们将预测所有测试向量特征以获得 SVM
    预测结果，并将这些结果与原始标签进行比较：
- en: '[PRE19]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We use the `predict` function by using the `testDataMat` features and a new
    `Mat` for prediction results. The `predict` function makes it possible to make
    multiple predictions at the same time, giving a matrix as the result instead of
    only one row or vector. After prediction, we only have to compute the differences
    of `testPredict` with our `testResponses` (the original labels). If there are
    differences, we only have to count how many there are and divide this by the total
    number of tests in order to calculate the error.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `predict` 函数，通过使用 `testDataMat` 特征和一个新的 `Mat` 来预测结果。`predict` 函数使得同时进行多个预测成为可能，结果是一个矩阵而不是只有一行或向量。预测后，我们只需要计算
    `testPredict` 与我们的 `testResponses`（原始标签）之间的差异。如果有差异，我们只需要计算有多少个差异，并将其除以测试的总数来计算误差。
- en: We can use the new `TrainData` class to generate the feature vectors, samples,
    and split our train data between test and train vectors.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用新的 `TrainData` 类来生成特征向量、样本，并将训练数据在测试和训练向量之间分割。
- en: 'Finally, we are going to show the training data in a 2D plot, where the *y*-axis
    is the aspect ratio feature and the *x*-axis is the area of objects. Each point
    has different colors and shapes (cross, square, and circle) that show each different
    kind of object, and we can clearly see the groups of objects in the following
    image:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将训练数据展示在二维图中，其中*Y*轴是长宽比特征，*X*轴是对象面积。每个点都有不同的颜色和形状（十字、正方形和圆形），表示不同的对象类型，我们可以清楚地看到以下图像中的对象组：
- en: '![](img/c0d5aeff-d753-4785-a611-f29df5d40c3f.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c0d5aeff-d753-4785-a611-f29df5d40c3f.png)'
- en: We are now very close to finishing our application sample. At this point, we
    have trained the SVM model; we can now use it for classification to detect the
    type of a new incoming and unknown feature vector. The next step is to predict
    an input image with unknown objects.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们非常接近完成我们的应用程序示例。在这个阶段，我们已经训练了SVM模型；现在我们可以用它来进行分类，以检测新到达的未知特征向量类型。下一步是预测包含未知对象的输入图像。
- en: Input image prediction
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 输入图像预测
- en: 'We are now ready to explain the main function, which loads the input image
    and predicts the objects that appear inside it. We are going to use something
    like the following picture as the input image. Here, multiple different objects appear in
    the image. We did not have the labels or names of these, but the computer must
    be able to identify them:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将解释主要功能，该功能加载输入图像并预测其中出现的对象。我们将使用以下图片作为输入图像。在这里，图像中出现了多个不同的对象。我们没有这些对象的标签或名称，但计算机必须能够识别它们：
- en: '![](img/4fda7040-c34d-4631-a829-c029286088f7.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4fda7040-c34d-4631-a829-c029286088f7.png)'
- en: 'As with all training images, we have to load and pre-process the input image,
    as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有训练图像一样，我们必须加载并预处理输入图像，如下所示：
- en: First, we load and convert the image into gray color values.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们加载并将图像转换为灰度值。
- en: 'Then, we apply the pre-processing tasks (as we learned in [Chapter 5](b788527c-5892-4547-8add-0864ccbd3f95.xhtml), *Automated
    Optical Inspect*ion, *Object Segmentation*, *and Detection)* using the `preprocessImage`
    function:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用`preprocessImage`函数应用预处理任务（如我们在[第5章](b788527c-5892-4547-8add-0864ccbd3f95.xhtml)，*自动光学检测*、*对象分割*和*检测)*：
- en: '[PRE20]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, we are going to extract the feature of vectors for all objects that appear
    in the image and the top-left positions of each one by using the `ExtractFeatures`
    that we previously described:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将使用之前描述的`ExtractFeatures`函数提取图像中所有出现的对象的特征以及每个对象的最左上角位置：
- en: '[PRE21]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We store each object we detect as a feature row and then convert each row as
    a `Mat` of one row and two features:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将检测到的每个对象存储为一个特征行，然后将每一行转换为包含一行和两个特征的`Mat`矩阵：
- en: '[PRE22]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'After this, we can predict the single object using the `predict` function of
    our `StatModel` SVM. The float result of the prediction is the label of the object
    detected. Then, to finish the application, we have to draw the label of each object
    that''s detected and classified over the output image:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以使用我们的`StatModel` SVM的`predict`函数预测单个对象。预测的浮点结果是检测到的对象的标签。然后，为了完成应用程序，我们必须在输出图像上绘制每个检测和分类的对象的标签：
- en: '[PRE23]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We are going to use a `stringstream` to store the text and a `Scalar` to store
    the color for each different label:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`stringstream`来存储文本，并使用`Scalar`来存储每个不同标签的颜色：
- en: '[PRE24]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We are also going to draw the label text over each object using its detected
    position in the `ExtractFeatures` function:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还将使用`ExtractFeatures`函数中检测到的位置在每个对象上绘制标签文本：
- en: '[PRE25]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Finally, we are going to draw our results in the output window:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将在输出窗口中绘制我们的结果：
- en: '[PRE26]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The final result of our application shows a window tiled with four screens.
    Here, the top-left image is the input training image, the top-right is the plot
    training image, the bottom left is the input image to analyze pre-processed images,
    and the bottom-right is the final result of the prediction:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用程序的最终结果显示了一个由四个屏幕组成的窗口。在这里，左上角的图像是输入训练图像，右上角是绘图训练图像，左下角是分析预处理图像的输入图像，右下角是预测的最终结果：
- en: '![](img/162298b6-6d4e-42e0-8019-c7467243b7fc.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/162298b6-6d4e-42e0-8019-c7467243b7fc.png)'
- en: Summary
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we learned about the basics of machine learning and applied
    them to a small sample application. This allowed us to understand the basic techniques
    that we can use to create our own machine learning application. Machine learning
    is complex and involves different techniques for each use case (supervised learning,
    unsupervised, clustering, and so on). We also learned how to create the most typical
    machine learning application, the supervised learning application, with SVM. The
    most important concepts in supervised machine learning are as follows: you must
    have an appropriate number of samples or a dataset, you must accurately choose
    the features that describe our objects (for more information on image features,
    go to [Chapter 8](58a72603-be5a-465f-aa7b-fc8ab1aae596.xhtml), *Video Surveillance*,
    *Background Modeling*, *and Morphological Operations*)*,* and you must choose
    a model that gives the best predictions.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了机器学习的基础知识，并将其应用于一个小型示例应用。这使得我们能够理解我们可以用来创建自己的机器学习应用的基本技术。机器学习是复杂的，涉及针对每个用例的不同技术（监督学习、无监督学习、聚类等）。我们还学习了如何使用SVM创建最典型的机器学习应用，即监督学习应用。监督机器学习中最重要的概念如下：你必须有适当数量的样本或数据集，你必须准确地选择描述我们的对象的特征（有关图像特征的更多信息，请参阅[第8章](58a72603-be5a-465f-aa7b-fc8ab1aae596.xhtml)，*视频监控*，*背景建模*，*和形态学操作*)，你必须选择一个给出最佳预测的模型。
- en: If we don't get the correct predictions, we have to check each one of these
    concepts to find the issue.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有得到正确的预测，我们必须检查这些概念中的每一个来找到问题所在。
- en: In the next chapter, we are going to introduce background subtraction methods,
    which are very useful for video surveillance applications where the background
    doesn't give us any interesting information and must be discarded so that we can
    segment the image to detect and analyze the image objects.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍背景减法方法，这对于视频监控应用非常有用，在这些应用中，背景不提供任何有趣的信息，必须被丢弃，以便我们可以分割图像以检测和分析图像对象。
