- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Machine Learning Models forÂ Time-Series
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ—¶é—´åºåˆ—çš„æœºå™¨å­¦ä¹ æ¨¡å‹
- en: Machine learning has come a long way in recent years, and this is reflected
    in the methods available to time-series predictions. We've introduced a few state-of-the-art
    machine learning methods for time-series in *Chapter 4*, *Introduction to Machine
    Learning for Time-Series*. In the current chapter, we'll introduce several more
    machine learning methods.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: è¿‘å¹´æ¥ï¼Œæœºå™¨å­¦ä¹ å–å¾—äº†é•¿è¶³çš„è¿›å±•ï¼Œè¿™ä¸€ç‚¹åœ¨æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•ä¸­å¾—åˆ°äº†ä½“ç°ã€‚æˆ‘ä»¬åœ¨*ç¬¬4ç« *ï¼Œ*æ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ å¯¼è®º*ä¸­ä»‹ç»äº†ä¸€äº›æœ€å…ˆè¿›çš„æ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»æ›´å¤šçš„æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚
- en: We'll go through methods that are commonly used as baseline methods, or that
    stand out in terms of either performance, ease of use, or their applicability.
    I'll introduce k-nearest neighbors with dynamic time warping and gradient boosting
    for time-series as a baseline and we'll go over other methods, such as Silverkite
    and gradient boosting. Finally, we'll go through an applied exercise with some
    of these methods.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä»‹ç»ä¸€äº›å¸¸ç”¨çš„åŸºå‡†æ–¹æ³•ï¼Œæˆ–è€…åœ¨æ€§èƒ½ã€æ˜“ç”¨æ€§æˆ–é€‚ç”¨æ€§æ–¹é¢è¡¨ç°çªå‡ºçš„ç®—æ³•ã€‚æˆ‘å°†ä»‹ç»åŸºäºåŠ¨æ€æ—¶é—´è§„æ•´å’Œæ¢¯åº¦æå‡çš„kè¿‘é‚»ç®—æ³•ä½œä¸ºåŸºå‡†ï¼Œæˆ‘ä»¬è¿˜å°†è®¨è®ºå…¶ä»–æ–¹æ³•ï¼Œå¦‚Silverkiteå’Œæ¢¯åº¦æå‡ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è¿›è¡Œä¸€ä¸ªåº”ç”¨ç»ƒä¹ ï¼Œä½¿ç”¨è¿™äº›æ–¹æ³•ä¸­çš„ä¸€äº›ã€‚
- en: 'We''re going to cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ¶µç›–ä»¥ä¸‹ä¸»é¢˜ï¼š
- en: More machine learning methods for time-series
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ›´å¤šçš„æ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ æ–¹æ³•
- en: K-nearest neighbors with dynamic time warping
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¸¦æœ‰åŠ¨æ€æ—¶é—´è§„æ•´çš„kè¿‘é‚»ç®—æ³•
- en: Silverkite
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Silverkite
- en: Gradient boosting
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¢¯åº¦æå‡
- en: Python exercise
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pythonç»ƒä¹ 
- en: If you are looking for a discussion of state-of-the-art machine learning algorithms,
    please refer to *Chapter 4*, *Introduction to Machine Learning for Time-Series*.
    The discussion of algorithms will assume some of the information of that chapter.
    The algorithms that we'll cover in the next sections are all highly competitive
    for forecasting and prediction tasks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³äº†è§£æœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œè¯·å‚é˜…*ç¬¬4ç« *ï¼Œ*æ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ å¯¼è®º*ã€‚æœ¬ç« çš„ç®—æ³•è®¨è®ºå°†å‡è®¾ä½ å·²ç»æŒæ¡äº†è¯¥ç« èŠ‚çš„ä¸€äº›å†…å®¹ã€‚æˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ä¸­ä»‹ç»çš„ç®—æ³•åœ¨é¢„æµ‹å’Œé¢„æŠ¥ä»»åŠ¡ä¸­éƒ½éå¸¸å…·æœ‰ç«äº‰åŠ›ã€‚
- en: We'll discuss algorithms here in more detail.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨è¿™é‡Œæ›´è¯¦ç»†åœ°è®¨è®ºè¿™äº›ç®—æ³•ã€‚
- en: More machine learning methods for time-series
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ›´å¤šçš„æ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ æ–¹æ³•
- en: The algorithms that we'll cover in this section are all highly competitive for
    forecasting and prediction tasks. If you are looking for a discussion of state-of-the-art
    machine learning algorithms, please refer to *Chapter 4*, *Introduction to Machine
    Learning for Time-Series*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨æœ¬èŠ‚ä¸­ä»‹ç»çš„ç®—æ³•åœ¨é¢„æµ‹å’Œé¢„æŠ¥ä»»åŠ¡ä¸­éƒ½å…·æœ‰é«˜åº¦ç«äº‰æ€§ã€‚å¦‚æœä½ æƒ³äº†è§£æœ€å…ˆè¿›çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œè¯·å‚é˜…*ç¬¬4ç« *ï¼Œ*æ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ å¯¼è®º*ã€‚
- en: In the aforementioned chapter, we've briefly discussed a few of these algorithms,
    butÂ we'll discuss them here in more detail and we will also introduce other algorithms
    that we haven't discussed before, such as Silverkite, gradient boosting, and k-nearest
    neighbors.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬ç®€è¦è®¨è®ºäº†å…¶ä¸­çš„ä¸€äº›ç®—æ³•ï¼Œä½†æˆ‘ä»¬å°†åœ¨è¿™é‡Œæ›´è¯¦ç»†åœ°è®²è§£å®ƒä»¬ï¼Œè¿˜ä¼šä»‹ç»ä¸€äº›æˆ‘ä»¬ä¹‹å‰æœªæ›¾è®¨è®ºè¿‡çš„ç®—æ³•ï¼Œå¦‚Silverkiteã€æ¢¯åº¦æå‡å’Œkè¿‘é‚»ã€‚
- en: We'll dedicate a separate practice section to a library that was released in
    2021, whichÂ is facebook's Kats. Kats provides many advanced features, including
    hyperparameter tuning and ensemble learning. On top of these features, they implement
    feature extraction based on the TSFresh library and include many models, including
    Prophet, SARIMA, and others. They claim that their hyperparameter tuning for time-series
    is about 6-20 times faster in benchmarks compared with otherÂ hyperparameter tuning
    algorithms.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä¸“é—¨è®¾ç½®ä¸€ä¸ªå®è·µéƒ¨åˆ†ï¼Œä»‹ç»ä¸€ä¸ª2021å¹´å‘å¸ƒçš„åº“â€”â€”Facebookçš„Katsã€‚Katsæä¾›äº†è®¸å¤šé«˜çº§åŠŸèƒ½ï¼ŒåŒ…æ‹¬è¶…å‚æ•°è°ƒä¼˜å’Œé›†æˆå­¦ä¹ ã€‚åœ¨è¿™äº›åŠŸèƒ½çš„åŸºç¡€ä¸Šï¼Œå®ƒä»¬å®ç°äº†åŸºäºTSFreshåº“çš„ç‰¹å¾æå–ï¼Œå¹¶åŒ…å«å¤šä¸ªæ¨¡å‹ï¼ŒåŒ…æ‹¬Prophetã€SARIMAç­‰ã€‚å®ƒä»¬å£°ç§°ï¼Œä¸å…¶ä»–è¶…å‚æ•°è°ƒä¼˜ç®—æ³•ç›¸æ¯”ï¼ŒKatsåœ¨æ—¶é—´åºåˆ—ä¸Šçš„è¶…å‚æ•°è°ƒä¼˜åœ¨åŸºå‡†æµ‹è¯•ä¸­å¿«äº†6åˆ°20å€ã€‚
- en: 'This graph provides an overview of the popularity of selected time-series machine
    learning libraries:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥å›¾å±•ç¤ºäº†æ‰€é€‰æ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ åº“çš„æµè¡Œåº¦æ¦‚è§ˆï¼š
- en: '![more_machine_learning-star_history.png](img/B17577_07_01.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![more_machine_learning-star_history.png](img/B17577_07_01.png)'
- en: 'Figure 7.1: Popularity of time-series machine learning libraries'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾7.1ï¼šæ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ åº“çš„æµè¡Œåº¦
- en: As of mid-2021, Kats and GreyKite have been released very recently, and although
    they have been garnering stars on GitHub, they haven't accumulated enough to rival
    TSFresh's popularity. I've included TSFresh even though it is a library for feature
    generation, and not prediction. I found it interesting to see how important it
    is in relation to other libraries that we use in this chapter. After TSFresh,
    SKTime is second, and it has been attracting a lot of stars over a relatively
    short time period.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆªè‡³2021å¹´ä¸­æœŸï¼ŒKatså’ŒGreyKiteåº“æœ€è¿‘æ‰å‘å¸ƒï¼Œå°½ç®¡å®ƒä»¬åœ¨GitHubä¸Šè·å¾—äº†è¶Šæ¥è¶Šå¤šçš„æ˜Ÿæ ‡ï¼Œä½†å®ƒä»¬çš„å—æ¬¢è¿ç¨‹åº¦è¿˜æœªèƒ½ä¸TSFreshç›¸æŠ—è¡¡ã€‚æˆ‘å°½ç®¡TSFreshæ˜¯ä¸€ä¸ªç‰¹å¾ç”Ÿæˆåº“ï¼Œè€Œéé¢„æµ‹åº“ï¼Œä½†è¿˜æ˜¯å°†å…¶åŒ…å«åœ¨å†…ï¼Œå› ä¸ºæˆ‘è§‰å¾—å®ƒåœ¨æœ¬ç« æ‰€ä½¿ç”¨çš„å…¶ä»–åº“ä¸­éå¸¸é‡è¦ã€‚TSFreshä¹‹åï¼ŒSKTimeæ’åç¬¬äºŒï¼Œå¹¶ä¸”åœ¨ç›¸å¯¹è¾ƒçŸ­çš„æ—¶é—´å†…å¸å¼•äº†å¤§é‡æ˜Ÿæ ‡ã€‚
- en: We'll use a few of these libraries in the practical examples in this chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« çš„å®é™…ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€äº›è¿™äº›åº“ã€‚
- en: Another important issue is validation, and it's worth covering this separately.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªé‡è¦çš„é—®é¢˜æ˜¯éªŒè¯ï¼Œå€¼å¾—å•ç‹¬è®¨è®ºè¿™ä¸ªé—®é¢˜ã€‚
- en: Validation
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éªŒè¯
- en: We've discussed validation before in *Chapter 4*, *Introduction to Machine Learning
    for Time-Series*. Often, in machine learning tasks, we use k-fold cross-validation,
    where splits of the data are performed pseudo-randomly, so the training and the
    test/validation datasets can come from any part of the data as long as it hasn't
    been used for training (**out-of-sample data**).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨*ç¬¬4ç« *ï¼Œ*æ—¶é—´åºåˆ—çš„æœºå™¨å­¦ä¹ å…¥é—¨*ä¸­å·²ç»è®¨è®ºè¿‡éªŒè¯ã€‚é€šå¸¸åœ¨æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨kæŠ˜äº¤å‰éªŒè¯ï¼Œå…¶ä¸­æ•°æ®çš„æ‹†åˆ†æ˜¯ä¼ªéšæœºè¿›è¡Œçš„ï¼Œå› æ­¤è®­ç»ƒé›†å’Œæµ‹è¯•/éªŒè¯é›†å¯ä»¥æ¥è‡ªæ•°æ®çš„ä»»ä½•éƒ¨åˆ†ï¼Œåªè¦è¿™äº›éƒ¨åˆ†æ²¡æœ‰è¢«ç”¨äºè®­ç»ƒï¼ˆ**æ ·æœ¬å¤–æ•°æ®**ï¼‰ã€‚
- en: With time-series data, this way of validation can lead to an overconfidence
    in the model's performance because, realistically, time-series tend to change
    over time according to trend, seasonality, and changes to the time-series characteristics.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ—¶é—´åºåˆ—æ•°æ®ï¼Œè¿™ç§éªŒè¯æ–¹æ³•å¯èƒ½ä¼šå¯¼è‡´å¯¹æ¨¡å‹æ€§èƒ½çš„è¿‡åº¦è‡ªä¿¡ï¼Œå› ä¸ºç°å®ä¸­ï¼Œæ—¶é—´åºåˆ—å¾€å¾€éšç€è¶‹åŠ¿ã€å­£èŠ‚æ€§å’Œæ—¶é—´åºåˆ—ç‰¹å¾çš„å˜åŒ–è€Œå˜åŒ–ã€‚
- en: Therefore, with time-series, validation is often performed in a so-called **walk-forward
    validation**. This means that we train the model on past data, and we'll test
    it on the newest slice of data. This will take out the optimistic bias and give
    us a more realistic estimate of performance once the model is deployed.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œåœ¨æ—¶é—´åºåˆ—ä¸­ï¼ŒéªŒè¯é€šå¸¸é‡‡ç”¨æ‰€è°“çš„**å‰å‘éªŒè¯ï¼ˆwalk-forward validationï¼‰**ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬åœ¨è¿‡å»çš„æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œç„¶ååœ¨æœ€æ–°çš„æ•°æ®ç‰‡æ®µä¸Šè¿›è¡Œæµ‹è¯•ã€‚è¿™å°†æ¶ˆé™¤è¿‡äºä¹è§‚çš„åå·®ï¼Œå¹¶åœ¨æ¨¡å‹éƒ¨ç½²åä¸ºæˆ‘ä»¬æä¾›æ›´ä¸ºç°å®çš„æ€§èƒ½è¯„ä¼°ã€‚
- en: 'In terms of training, validation, and test datasets, this means that we''ll
    adjust model parameters entirely on training and validation datasets, and we''ll
    benchmark our test based on a set of data that''s more advanced in time, as illustrated
    in the following diagram (source: Greykite library''s GitHub repository):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†æ–¹é¢ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å°†å®Œå…¨ä¾èµ–è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†æ¥è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œå¹¶ä¸”æˆ‘ä»¬å°†åŸºäºä¸€ä¸ªæ—¶é—´ä¸Šæ›´å…ˆè¿›çš„æ•°æ®é›†æ¥è¯„ä¼°æµ‹è¯•ï¼Œå…·ä½“å¦‚ä¸‹é¢çš„å›¾ç¤ºæ‰€ç¤ºï¼ˆæ¥æºï¼šGreykiteåº“çš„GitHubä»“åº“ï¼‰ï¼š
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/(A Document
    Being Saved By screencaptureui 20)/Screenshot 2021-06-06 at 21.39.47.png](img/B17577_07_02.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/(A Document
    Being Saved By screencaptureui 20)/Screenshot 2021-06-06 at 21.39.47.png](img/B17577_07_02.png)'
- en: 'Figure 7.2: Walk-forward validation'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾7.2ï¼šå‰å‘éªŒè¯
- en: In walk-forward validation, we train on an initial segment of the data and then
    test on a period after the training set. Next, we roll forward and repeat the
    process. This way, we have multiple out-of-sample periods and can combine the
    results over these periods. With walk-forward, we are less likely to suffer from
    overfitting.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‰å‘éªŒè¯ä¸­ï¼Œæˆ‘ä»¬å…ˆåœ¨æ•°æ®çš„åˆå§‹ç‰‡æ®µä¸Šè®­ç»ƒï¼Œç„¶ååœ¨è®­ç»ƒé›†ä¹‹åçš„æŸä¸ªæ—¶é—´æ®µè¿›è¡Œæµ‹è¯•ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å‘å‰æ¨è¿›å¹¶é‡å¤è¿™ä¸€è¿‡ç¨‹ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬æœ‰å¤šä¸ªæ ·æœ¬å¤–çš„æ—¶é—´æ®µï¼Œå¯ä»¥å°†è¿™äº›æ—¶é—´æ®µçš„ç»“æœè¿›è¡Œæ•´åˆã€‚é€šè¿‡å‰å‘éªŒè¯ï¼Œæˆ‘ä»¬ä¸å¤ªå¯èƒ½é­é‡è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚
- en: K-nearest neighbors with dynamic time warping
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŠ¨æ€æ—¶é—´è§„æ•´çš„Kè¿‘é‚»ç®—æ³•
- en: K-nearest neighbors is a well-known machine learning method (sometimes also
    going under the guise of case-based reasoning). In kNN, we can use a distance
    measure to find similar data points. We can then take the known labels of these
    nearest neighbors as the output and integrate them in some way using a function.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Kè¿‘é‚»æ˜¯ä¸€ä¸ªè‘—åçš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼ˆæœ‰æ—¶ä¹Ÿè¢«ç§°ä¸ºåŸºäºæ¡ˆä¾‹çš„æ¨ç†ï¼‰ã€‚åœ¨kNNä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è·ç¦»åº¦é‡æ¥æ‰¾åˆ°ç›¸ä¼¼çš„æ•°æ®ç‚¹ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™äº›æœ€è¿‘é‚»çš„å·²çŸ¥æ ‡ç­¾ä½œä¸ºè¾“å‡ºï¼Œå¹¶é€šè¿‡æŸç§å‡½æ•°å°†å®ƒä»¬æ•´åˆåœ¨ä¸€èµ·ã€‚
- en: '*Figure 7.3* illustrates the basic idea of kNN for classification (source â€“
    WikiMedia Commons: [https://commons.wikimedia.org/wiki/File:KnnClassification.svg](https://commons.wikimedia.org/wiki/File:KnnClassification.svg)):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ 7.3* å±•ç¤ºäº† kNN åˆ†ç±»çš„åŸºæœ¬æ€è·¯ï¼ˆæ¥æº â€“ WikiMedia Commons: [https://commons.wikimedia.org/wiki/File:KnnClassification.svg](https://commons.wikimedia.org/wiki/File:KnnClassification.svg)ï¼‰ï¼š'
- en: '![/Users/ben/Downloads/Machine-Learning for Time-Series with Python/knn.png](img/B17577_07_03.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![/Users/ben/Downloads/Machine-Learning for Time-Series with Python/knn.png](img/B17577_07_03.png)'
- en: 'Figure 7.3: K-nearest neighbor for classification'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 7.3ï¼šç”¨äºåˆ†ç±»çš„ K æœ€è¿‘é‚»
- en: We know a few data points already. In the preceding illustration, these points
    are indicated as squares and triangles, and they represent data points of two
    different classes, respectively. Given a new data point, indicated by a circle,
    we find the closest known data points to it. In this example, we find that the
    new point is similar to triangles, so we might assume that the new point is of
    the triangle class as well.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»çŸ¥é“ä¸€äº›æ•°æ®ç‚¹ã€‚åœ¨å‰é¢çš„ç¤ºæ„å›¾ä¸­ï¼Œè¿™äº›æ•°æ®ç‚¹åˆ†åˆ«ç”¨æ–¹å½¢å’Œä¸‰è§’å½¢è¡¨ç¤ºï¼Œä»£è¡¨äº†ä¸¤ä¸ªä¸åŒç±»åˆ«çš„æ•°æ®ç‚¹ã€‚ç»™å®šä¸€ä¸ªæ–°çš„æ•°æ®ç‚¹ï¼Œç”¨åœ†åœˆè¡¨ç¤ºï¼Œæˆ‘ä»¬æ‰¾åˆ°ä¸ä¹‹æœ€æ¥è¿‘çš„å·²çŸ¥æ•°æ®ç‚¹ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å‘ç°æ–°ç‚¹ä¸ä¸‰è§’å½¢ç›¸ä¼¼ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å‡è®¾æ–°ç‚¹ä¹Ÿå±äºä¸‰è§’å½¢ç±»ã€‚
- en: While this method is conceptually very simple, it often serves as a strong baseline
    method, or is sometimes even competitive with more sophisticated machine learning
    algorithms, even when we only compare the closest neighbor *(**ğ‘˜**=1)*.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡è¿™ç§æ–¹æ³•åœ¨æ¦‚å¿µä¸Šéå¸¸ç®€å•ï¼Œä½†å®ƒé€šå¸¸ä½œä¸ºä¸€ç§å¼ºåŸºçº¿æ–¹æ³•ï¼Œæˆ–è€…æœ‰æ—¶ç”šè‡³èƒ½ä¸æ›´å¤æ‚çš„æœºå™¨å­¦ä¹ ç®—æ³•ç«äº‰ï¼Œå³ä½¿æˆ‘ä»¬åªæ¯”è¾ƒæœ€æ¥è¿‘çš„é‚»å±…ï¼ˆ*ï¼ˆ**ğ‘˜**=1ï¼‰*ï¼‰ã€‚
- en: 'The important hyperparameters in this algorithm are:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç®—æ³•ä¸­çš„é‡è¦è¶…å‚æ•°æœ‰ï¼š
- en: The number of neighbors (k) you want to base your output on
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ å¸Œæœ›æ ¹æ®å…¶æ¥ç”Ÿæˆè¾“å‡ºçš„é‚»å±…æ•°ï¼ˆkï¼‰
- en: The integration function (for example, the average or the most frequent value)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é›†æˆå‡½æ•°ï¼ˆä¾‹å¦‚ï¼Œå¹³å‡å€¼æˆ–æœ€å¸¸è§å€¼ï¼‰
- en: The distance function to use to find the nearest data points
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºæ‰¾åˆ°æœ€è¿‘æ•°æ®ç‚¹çš„è·ç¦»å‡½æ•°
- en: We talked about dynamic time warping in *Chapter 4*, *Introduction to Machine
    Learning for Time-Series*, as a measure that can be used to compare the similarity
    (or, equivalently, the distance) between two time-series. These sequences can
    even be of different lengths. Dynamic time warping has proven itself to be an
    exceptionally strong distance measure for time-series.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨*ç¬¬ 4 ç« *ã€Š*æ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ å¯¼è®º*ã€‹ä¸­è®¨è®ºè¿‡åŠ¨æ€æ—¶é—´æ‰­æ›²ï¼ˆDynamic Time Warpingï¼‰ï¼Œå®ƒæ˜¯ä¸€ç§ç”¨äºæ¯”è¾ƒä¸¤æ¡æ—¶é—´åºåˆ—ç›¸ä¼¼æ€§ï¼ˆæˆ–ç­‰ä»·åœ°ï¼Œè·ç¦»ï¼‰çš„æ–¹æ³•ã€‚è¿™äº›åºåˆ—ç”šè‡³å¯ä»¥æœ‰ä¸åŒçš„é•¿åº¦ã€‚åŠ¨æ€æ—¶é—´æ‰­æ›²å·²ç»è¯æ˜è‡ªå·±æ˜¯ä¸€ä¸ªå¼‚å¸¸å¼ºå¤§çš„æ—¶é—´åºåˆ—è·ç¦»åº¦é‡ã€‚
- en: We can use kNN in combination with dynamic time warping as a distance measure
    to find similar time-series, and this method has proven itself hard to beat, although
    the state of the art has since surpassed it.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°† kNN å’ŒåŠ¨æ€æ—¶é—´æ‰­æ›²ç»“åˆèµ·æ¥ï¼Œä½œä¸ºä¸€ç§è·ç¦»åº¦é‡æ¥å¯»æ‰¾ç›¸ä¼¼çš„æ—¶é—´åºåˆ—ï¼Œè¿™ç§æ–¹æ³•å·²ç»è¯æ˜å…¶åœ¨æŸäº›æƒ…å†µä¸‹å¾ˆéš¾è¢«è¶…è¶Šï¼Œå°½ç®¡å½“å‰çš„æŠ€æœ¯å·²ç»è¶…è¿‡äº†å®ƒã€‚
- en: Silverkite
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Silverkite
- en: The Silverkite algorithm ships together with the Greykite library released by
    LinkedIn. It was explicitly designed with the goals in mind of being fast, accurate,
    and intuitive. The algorithm is described in a 2021 publication ("*A flexible
    forecasting model for production systems*", by Reza Hosseini and others).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Silverkite ç®—æ³•ä¸ LinkedIn å‘å¸ƒçš„ Greykite åº“ä¸€èµ·å‘å¸ƒã€‚å®ƒçš„è®¾è®¡ç›®æ ‡æ˜¯å¿«é€Ÿã€å‡†ç¡®ä¸”ç›´è§‚ã€‚è¯¥ç®—æ³•åœ¨ 2021 å¹´çš„æ–‡ç« ä¸­æœ‰æè¿°ï¼ˆã€Š*ç”Ÿäº§ç³»ç»Ÿçš„çµæ´»é¢„æµ‹æ¨¡å‹*ã€‹ï¼ŒReza
    Hosseini ç­‰äººï¼‰ã€‚
- en: According to LinkedIn, it can handle different kinds of trends and seasonalities
    such as hourly, daily, weekly, repeated events, and holidays, and short-range
    effects. Within LinkedIn, it is used for both short-term, for example, a 1-day
    head, and long-term forecast horizons, such as 1 year ahead.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ® LinkedInï¼Œå®ƒèƒ½å¤Ÿå¤„ç†å„ç§è¶‹åŠ¿å’Œå­£èŠ‚æ€§å› ç´ ï¼Œä¾‹å¦‚æ¯å°æ—¶ã€æ¯æ—¥ã€æ¯å‘¨ã€é‡å¤äº‹ä»¶ã€å‡æœŸä»¥åŠçŸ­æœŸæ•ˆåº”ã€‚åœ¨ LinkedIn å†…éƒ¨ï¼Œå®ƒæ—¢ç”¨äºçŸ­æœŸé¢„æµ‹ï¼Œä¾‹å¦‚
    1 å¤©çš„é¢„æµ‹ï¼Œä¹Ÿç”¨äºé•¿æœŸé¢„æµ‹ï¼Œä¾‹å¦‚ 1 å¹´åçš„é¢„æµ‹ã€‚
- en: Use cases within LinkedIn include optimizing budget decisions, setting business
    metric targets, and providing sufficient infrastructure to handle peak traffic.
    Furthermore, a use case has been to model recoveries from the COVID-19 pandemic.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ LinkedIn ä¸­çš„åº”ç”¨åœºæ™¯åŒ…æ‹¬ä¼˜åŒ–é¢„ç®—å†³ç­–ã€è®¾å®šä¸šåŠ¡æŒ‡æ ‡ç›®æ ‡ï¼Œä»¥åŠæä¾›è¶³å¤Ÿçš„åŸºç¡€è®¾æ–½æ¥åº”å¯¹å³°å€¼æµé‡ã€‚æ­¤å¤–ï¼Œä¸€ä¸ªåº”ç”¨åœºæ™¯æ˜¯å»ºæ¨¡ COVID-19
    å¤§æµè¡Œåçš„æ¢å¤æƒ…å†µã€‚
- en: 'The time-series is modeled as an additive composite of trends, change points,
    and seasonality, where seasonality includes holiday/event effects. The trend is
    then modeled as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¶é—´åºåˆ—è¢«å»ºæ¨¡ä¸ºè¶‹åŠ¿ã€å˜åŒ–ç‚¹å’Œå­£èŠ‚æ€§çš„åŠ æ€§ç»„åˆï¼Œå…¶ä¸­å­£èŠ‚æ€§åŒ…æ‹¬å‡æœŸ/äº‹ä»¶æ•ˆåº”ã€‚è¶‹åŠ¿éšåè¢«å»ºæ¨¡å¦‚ä¸‹ï¼š
- en: '![](img/B17577_07_001.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17577_07_001.png)'
- en: where K is the number of change points, and *t*[i] is the time index for the
    i-th change point. Therefore, ![](img/B17577_07_002.png) is an indicator function
    for the i-th change point. The function f(t) can be linear, square root, quadratic,
    any combination, or completely custom.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ K æ˜¯å˜åŒ–ç‚¹çš„æ•°é‡ï¼Œ*t*[i] æ˜¯ç¬¬ i ä¸ªå˜åŒ–ç‚¹çš„æ—¶é—´ç´¢å¼•ã€‚å› æ­¤ï¼Œ![](img/B17577_07_002.png) æ˜¯ç¬¬ i ä¸ªå˜åŒ–ç‚¹çš„æŒ‡ç¤ºå‡½æ•°ã€‚å‡½æ•°
    f(t) å¯ä»¥æ˜¯çº¿æ€§ã€å¹³æ–¹æ ¹ã€äºŒæ¬¡ã€ä»»æ„ç»„åˆæˆ–å®Œå…¨è‡ªå®šä¹‰ã€‚
- en: Silverkite also constructs indicator variables for holidays. Holidays can be
    specified by name or by country, or can even be completely custom.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Silverkite è¿˜æ„å»ºäº†å‡æœŸçš„æŒ‡ç¤ºå˜é‡ã€‚å‡æœŸå¯ä»¥é€šè¿‡åç§°æˆ–å›½å®¶æŒ‡å®šï¼Œç”šè‡³å¯ä»¥å®Œå…¨è‡ªå®šä¹‰ã€‚
- en: Change points can be specified manually or candidates can be automatically detected
    with a regression model and subsequently selected using the Adaptive Lasso algorithm
    (Hui Zhou, 2006).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å˜åŒ–ç‚¹å¯ä»¥æ‰‹åŠ¨æŒ‡å®šï¼Œæˆ–è€…å¯ä»¥é€šè¿‡å›å½’æ¨¡å‹è‡ªåŠ¨æ£€æµ‹å€™é€‰å˜åŒ–ç‚¹ï¼Œéšåä½¿ç”¨è‡ªé€‚åº” Lasso ç®—æ³•ï¼ˆHui Zhouï¼Œ2006ï¼‰è¿›è¡Œé€‰æ‹©ã€‚
- en: In addition to trend, seasonality, and holiday, Silverkite includes an autoregressive
    term that is calculated based on windowed averages rather than taking lags independently
    ("*Selecting a binary Markov model for a precipitation process*", by Reza Hosseini
    and others, 2011).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†è¶‹åŠ¿ã€å­£èŠ‚æ€§å’Œå‡æœŸï¼ŒSilverkite è¿˜åŒ…æ‹¬ä¸€ä¸ªè‡ªå›å½’é¡¹ï¼Œè¯¥é¡¹æ˜¯åŸºäºçª—å£å¹³å‡å€¼è®¡ç®—çš„ï¼Œè€Œä¸æ˜¯ç‹¬ç«‹åœ°å–æ»åé¡¹ï¼ˆã€Š*ä¸ºé™æ°´è¿‡ç¨‹é€‰æ‹©äºŒå…ƒé©¬å°”ç§‘å¤«æ¨¡å‹*ã€‹ï¼ŒReza
    Hosseini ç­‰ï¼Œ2011ï¼‰ã€‚
- en: 'This autoregressive term is specified using the Pasty library, using a formula
    mini-language, in a form like this string:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è‡ªå›å½’é¡¹ä½¿ç”¨ Pasty åº“æŒ‡å®šï¼Œä½¿ç”¨ç±»ä¼¼ä»¥ä¸‹å­—ç¬¦ä¸²çš„å…¬å¼è¿·ä½ è¯­è¨€å½¢å¼ï¼š
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this formula, y on the left-hand side is defined as the sum of three terms,
    `a`, `a:b`, and `np.log(x)`. The term `a:b` is an interaction between two factors,
    a and b. The model template itself in Pasty is highly customizable, so this interface
    provides a high degree of flexibility.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªå…¬å¼ä¸­ï¼Œå·¦ä¾§çš„ y å®šä¹‰ä¸ºä¸‰ä¸ªé¡¹çš„æ€»å’Œï¼Œ`a`ã€`a:b` å’Œ `np.log(x)`ã€‚é¡¹ `a:b` æ˜¯ä¸¤ä¸ªå› å­ a å’Œ b ä¹‹é—´çš„äº¤äº’ä½œç”¨ã€‚Pasty
    ä¸­çš„æ¨¡å‹æ¨¡æ¿æœ¬èº«å…·æœ‰é«˜åº¦çš„å¯å®šåˆ¶æ€§ï¼Œå› æ­¤è¯¥æ¥å£æä¾›äº†å¾ˆé«˜çš„çµæ´»æ€§ã€‚
- en: Finally, Silverkite comes with several model types, such as ridge regression,
    elastic net, and boosted trees, with supported loss functions, MSE, and quantile
    loss for robust regression.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼ŒSilverkite æä¾›äº†å‡ ç§æ¨¡å‹ç±»å‹ï¼Œå¦‚å²­å›å½’ã€å¼¹æ€§ç½‘å’Œæå‡æ ‘ï¼Œå¹¶æ”¯æŒæŸå¤±å‡½æ•°ï¼Œå¦‚å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰å’Œåˆ†ä½æ•°æŸå¤±ï¼Œç”¨äºç¨³å¥å›å½’ã€‚
- en: According to a LinkedIn benchmark on several datasets, Silverkite outperforms
    both auto-Arima (the pmdarima library) and Prophet in terms of prediction error.
    Yet, Silverkite was about four times as fast as Prophet, which we'll introduce
    in *Chapter 9*, *Probabilistic Models*.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ® LinkedIn å¯¹å¤šä¸ªæ•°æ®é›†çš„åŸºå‡†æµ‹è¯•ï¼ŒSilverkite åœ¨é¢„æµ‹è¯¯å·®æ–¹é¢ä¼˜äº auto-Arimaï¼ˆpmdarima åº“ï¼‰å’Œ Prophetã€‚ç„¶è€Œï¼ŒSilverkite
    çš„é€Ÿåº¦çº¦ä¸º Prophet çš„å››å€ï¼Œæˆ‘ä»¬å°†åœ¨ *ç¬¬9ç« *ï¼Œ*æ¦‚ç‡æ¨¡å‹* ä¸­ä»‹ç» Prophetã€‚
- en: Gradient boosting
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¢¯åº¦æå‡
- en: '**XGBoost** (short for **eXtreme Gradient Boosting**) is an efficient implementation
    of gradient boosting (Jerome Friedman, "*Greedy function approximation: a gradient
    boosting machine*", 2001) for classification and regression problems. Gradient
    boosting is also known as **Gradient Boosting Machine** (**GBM**) or **Gradient
    Boosted Regression Tree** (**GBRT**). A special case is LambdaMART for ranking
    applications. Apart from XGBoost; other implementations are Microsoft''s Light
    Gradient Boosting Machine (LightGBM), and Yandex''s Catboost.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**XGBoost**ï¼ˆå³**æé™æ¢¯åº¦æå‡**çš„ç¼©å†™ï¼‰æ˜¯æ¢¯åº¦æå‡çš„é«˜æ•ˆå®ç°ï¼ˆJerome Friedmanï¼Œã€Š*è´ªå©ªå‡½æ•°é€¼è¿‘ï¼šä¸€ç§æ¢¯åº¦æå‡æœºå™¨*ã€‹ï¼Œ2001ï¼‰ï¼Œç”¨äºåˆ†ç±»å’Œå›å½’é—®é¢˜ã€‚æ¢¯åº¦æå‡ä¹Ÿè¢«ç§°ä¸º**æ¢¯åº¦æå‡æœº**ï¼ˆ**GBM**ï¼‰æˆ–**æ¢¯åº¦æå‡å›å½’æ ‘**ï¼ˆ**GBRT**ï¼‰ã€‚ä¸€ä¸ªç‰¹ä¾‹æ˜¯ç”¨äºæ’åºåº”ç”¨çš„
    LambdaMARTã€‚é™¤äº† XGBoostï¼Œå…¶ä»–å®ç°åŒ…æ‹¬å¾®è½¯çš„è½»é‡çº§æ¢¯åº¦æå‡æœºï¼ˆLightGBMï¼‰å’Œ Yandex çš„ Catboostã€‚'
- en: Gradient Boosted Trees is an ensemble of trees. This is similar to Bagging algorithms
    such as Random Forest; however, since this is a boosting algorithm, each tree
    is computed to incrementally reduce the error. With each new iteration a tree
    is greedily chosen and its prediction is added to the previous predictions based
    on a weight term. There is also a regularization term that penalizes complexity
    and reduces overfitting, similar to the Regularized Greedy Forest (RGF).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢¯åº¦æå‡æ ‘æ˜¯æ ‘çš„é›†æˆã€‚è¿™ä¸ç±»ä¼¼äºéšæœºæ£®æ—çš„è¢‹è£…ç®—æ³•ç±»ä¼¼ï¼›ç„¶è€Œï¼Œç”±äºè¿™æ˜¯ä¸€ä¸ªæå‡ç®—æ³•ï¼Œæ¯æ£µæ ‘éƒ½ä¼šè¢«è®¡ç®—å‡ºæ¥ï¼Œé€æ­¥å‡å°‘è¯¯å·®ã€‚æ¯æ¬¡æ–°çš„è¿­ä»£éƒ½ä¼šè´ªå¿ƒåœ°é€‰æ‹©ä¸€æ£µæ ‘ï¼Œå¹¶å°†å…¶é¢„æµ‹å€¼åŸºäºæƒé‡é¡¹åŠ åˆ°å…ˆå‰çš„é¢„æµ‹å€¼ä¸­ã€‚è¿˜æœ‰ä¸€ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œç”¨äºæƒ©ç½šå¤æ‚æ€§å¹¶å‡å°‘è¿‡æ‹Ÿåˆï¼Œç±»ä¼¼äºæ­£åˆ™åŒ–è´ªå©ªæ£®æ—ï¼ˆRGFï¼‰ã€‚
- en: 'The **XGBoost** algorithm was published in 2016 by Tianqi Chen and Carlos Guestrin
    ("*XGBoost: A Scalable Tree Boosting System*") and pushed the envelope on many
    classification and regression benchmarks. It was used in many winning solutions
    to Kaggle problems. In fact, in 2015, of the 29 challenge-winning solutions, 17
    solutions used XGBoost.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**XGBoost**ç®—æ³•ç”±é™ˆå¤©å¥‡å’Œå¡æ´›æ–¯Â·æ ¼æ–¯ç‰¹æ—äº2016å¹´å‘å¸ƒï¼ˆ"*XGBoostï¼šä¸€ç§å¯æ‰©å±•çš„æ ‘æå‡ç³»ç»Ÿ*"ï¼‰ï¼Œå¹¶æ¨åŠ¨äº†è®¸å¤šåˆ†ç±»å’Œå›å½’åŸºå‡†çš„çªç ´ã€‚å®ƒè¢«ç”¨äºè®¸å¤šKaggleé—®é¢˜çš„è·èƒœè§£å†³æ–¹æ¡ˆã€‚äº‹å®ä¸Šï¼Œåœ¨2015å¹´ï¼Œ29ä¸ªæŒ‘æˆ˜è·èƒœè§£å†³æ–¹æ¡ˆä¸­ï¼Œæœ‰17ä¸ªè§£å†³æ–¹æ¡ˆä½¿ç”¨äº†XGBoostã€‚'
- en: It was designed to be highly scalable and features extensions of the gradient
    boosting algorithm for weighted quantiles, along with improvements for scalability
    and parallelization based on smarter caching patterns, sharding, and the handling
    of sparsity.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒçš„è®¾è®¡éå¸¸å…·æœ‰å¯æ‰©å±•æ€§ï¼Œå¹¶ä¸”æ‰©å±•äº†æ¢¯åº¦æå‡ç®—æ³•ï¼Œç”¨äºåŠ æƒåˆ†ä½æ•°ï¼Œå¹¶é€šè¿‡æ›´æ™ºèƒ½çš„ç¼“å­˜æ¨¡å¼ã€åˆ†ç‰‡ä»¥åŠå¯¹ç¨€ç–æ€§å¤„ç†çš„æ”¹è¿›ï¼Œæå‡äº†å¯æ‰©å±•æ€§å’Œå¹¶è¡ŒåŒ–æ€§èƒ½ã€‚
- en: As a special case of regression, XGBoost can be used for forecasting. In this
    scenario, the model is trained based on past values to predict future values,
    and this can be applied to univariate as well as multivariate time-series.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºå›å½’çš„ä¸€ä¸ªç‰¹ä¾‹ï¼ŒXGBoostå¯ä»¥ç”¨äºé¢„æµ‹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹åŸºäºè¿‡å»çš„å€¼è¿›è¡Œè®­ç»ƒï¼Œä»¥é¢„æµ‹æœªæ¥çš„å€¼ï¼Œè¿™å¯ä»¥åº”ç”¨äºå•å˜é‡å’Œå¤šå˜é‡æ—¶é—´åºåˆ—ã€‚
- en: Python exercise
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pythonç»ƒä¹ 
- en: Let's put into practice what we've learned in this chapter so far.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å°†æœ¬ç« è¿„ä»Šä¸ºæ­¢å­¦åˆ°çš„å†…å®¹ä»˜è¯¸å®è·µã€‚
- en: As for requirements, in this chapter, we'll be installing requirements for each
    section separately. The installation can be performed from the terminal, the notebook,
    or from the anaconda navigator.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è‡³äºä¾èµ–é¡¹ï¼Œåœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†åˆ†åˆ«ä¸ºæ¯ä¸ªéƒ¨åˆ†å®‰è£…ä¾èµ–ã€‚å¯ä»¥é€šè¿‡ç»ˆç«¯ã€ç¬”è®°æœ¬æˆ–Anaconda Navigatorè¿›è¡Œå®‰è£…ã€‚
- en: In a few of the following sections, we'll demonstrate classification in a forecast,
    so some of these approaches will not be comparable. The reader is invited to do
    forecasts and classification using each approach and then compare results.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¥ä¸‹æ¥çš„å‡ ä¸ªéƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•åœ¨é¢„æµ‹ä¸­è¿›è¡Œåˆ†ç±»ï¼Œå› æ­¤è¿™äº›æ–¹æ³•ä¸­çš„ä¸€äº›å¯èƒ½æ— æ³•è¿›è¡Œæ¯”è¾ƒã€‚æˆ‘ä»¬é‚€è¯·è¯»è€…ä½¿ç”¨æ¯ç§æ–¹æ³•è¿›è¡Œé¢„æµ‹å’Œåˆ†ç±»ï¼Œå¹¶è¿›è¡Œç»“æœæ¯”è¾ƒã€‚
- en: As a note of caution, both Kats and Greykite (at the time of writing) are very
    new libraries, so there might still be frequent changes to dependencies. They
    might pin your NumPy version or other commonly used libraries. Therefore, I'd
    recommend you install them in virtual environments separately for each section.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒKatså’ŒGreykiteï¼ˆåœ¨å†™ä½œæ—¶ï¼‰éƒ½æ˜¯éå¸¸æ–°çš„åº“ï¼Œå› æ­¤å®ƒä»¬çš„ä¾èµ–é¡¹å¯èƒ½è¿˜ä¼šé¢‘ç¹å˜åŒ–ã€‚å®ƒä»¬å¯èƒ½ä¼šé”å®šæ‚¨çš„NumPyç‰ˆæœ¬æˆ–å…¶ä»–å¸¸ç”¨åº“ã€‚å› æ­¤ï¼Œæˆ‘å»ºè®®æ‚¨ä¸ºæ¯ä¸ªéƒ¨åˆ†åˆ†åˆ«åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…è¿™äº›åº“ã€‚
- en: We'll go through this setup in the next section.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­è¯¦ç»†ä»‹ç»è¿™ä¸ªè®¾ç½®è¿‡ç¨‹ã€‚
- en: Virtual environments
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è™šæ‹Ÿç¯å¢ƒ
- en: In a Python virtual environment, all libraries, binaries, and scripts installed
    into it areÂ isolated from those installed in other virtual environments and from
    those installed in the system. This means that we can have different libraries,
    such as Kats and Greykite, installed without having to bother with compatibility
    issues between them or with other libraries installed on our computer.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Pythonè™šæ‹Ÿç¯å¢ƒä¸­ï¼Œå®‰è£…åˆ°å…¶ä¸­çš„æ‰€æœ‰åº“ã€äºŒè¿›åˆ¶æ–‡ä»¶å’Œè„šæœ¬éƒ½æ˜¯ä¸å…¶ä»–è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…çš„å†…å®¹ä»¥åŠç³»ç»Ÿä¸­å®‰è£…çš„å†…å®¹éš”ç¦»çš„ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥å®‰è£…ä¸åŒçš„åº“ï¼Œå¦‚Katså’ŒGreykiteï¼Œè€Œæ— éœ€æ‹…å¿ƒå®ƒä»¬ä¹‹é—´çš„å…¼å®¹æ€§é—®é¢˜ï¼Œæˆ–ä¸æˆ‘ä»¬è®¡ç®—æœºä¸Šå®‰è£…çš„å…¶ä»–åº“ä¹‹é—´çš„å…¼å®¹æ€§é—®é¢˜ã€‚
- en: Let's go through a quick tutorial introduction to using virtual environments
    with Jupyter notebooks using anaconda (similarly, you can use tools such as virtualenv
    orÂ pipenv).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç®€çŸ­çš„æ•™ç¨‹ï¼Œä»‹ç»å¦‚ä½•åœ¨ä½¿ç”¨Anacondaçš„Jupyterç¬”è®°æœ¬ä¸­ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼ˆç±»ä¼¼åœ°ï¼Œæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å¦‚virtualenvæˆ–pipenvç­‰å·¥å…·ï¼‰ã€‚
- en: In *Chapter 1*, *Introduction to Time-Series with Python*, we went through the
    installation of Anaconda, so we'll skip the installation. Please refer to that
    chapter orÂ go to conda.io for instructions.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*ç¬¬1ç« *ï¼Œ*ä½¿ç”¨Pythonè¿›è¡Œæ—¶é—´åºåˆ—åˆ†æç®€ä»‹*ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†Anacondaçš„å®‰è£…ï¼Œå› æ­¤æˆ‘ä»¬ä¼šè·³è¿‡è¿™éƒ¨åˆ†å®‰è£…ã€‚è¯·å‚è€ƒé‚£ä¸€ç« ï¼Œæˆ–è€…è®¿é—®conda.ioè·å–å®‰è£…è¯´æ˜ã€‚
- en: 'To create a virtual environment, you have to specify a name:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒï¼Œå¿…é¡»æŒ‡å®šä¸€ä¸ªåç§°ï¼š
- en: '[PRE1]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This will create an eponymous directory (`myenv`), where all libraries and scripts
    will be installed.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†åˆ›å»ºä¸€ä¸ªåŒåçš„ç›®å½•ï¼ˆ`myenv`ï¼‰ï¼Œå…¶ä¸­æ‰€æœ‰åº“å’Œè„šæœ¬å°†è¢«å®‰è£…ã€‚
- en: 'If we want to use this environment, we have to activate it first, which means
    that we set the `PATH` variable to include our newly created directory:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æƒ³ä½¿ç”¨è¿™ä¸ªç¯å¢ƒï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆæ¿€æ´»å®ƒï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦å°†`PATH`å˜é‡è®¾ç½®ä¸ºåŒ…æ‹¬æˆ‘ä»¬æ–°åˆ›å»ºçš„ç›®å½•ï¼š
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can now use tools such as pip, which will default to the one bundled with
    conda, or the conda command directly to install libraries.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åƒpipè¿™æ ·çš„å·¥å…·ï¼Œé»˜è®¤æƒ…å†µä¸‹å®ƒä¼šä½¿ç”¨ä¸condaæ†ç»‘åœ¨ä¸€èµ·çš„ç‰ˆæœ¬ï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨condaå‘½ä»¤æ¥å®‰è£…åº“ã€‚
- en: We can install Jupyter or Jupyter labs into our environment and then start it.
    This means that our Jupyter environment will include all dependencies as we've
    installed them in isolation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨ç¯å¢ƒä¸­å®‰è£… Jupyter æˆ– Jupyter Lab ç„¶åå¯åŠ¨å®ƒã€‚è¿™æ„å‘³ç€æˆ‘ä»¬çš„ Jupyter ç¯å¢ƒå°†åŒ…å«æ‰€æœ‰ä¾èµ–é¡¹ï¼Œå› ä¸ºæˆ‘ä»¬å·²å°†å®ƒä»¬å•ç‹¬å®‰è£…ã€‚
- en: Let's start with a kNN algorithm with dynamic time warping. As I've mentioned,
    thisÂ algorithm often serves as a decent baseline for comparisons.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ä¸€ä¸ªå¸¦æœ‰åŠ¨æ€æ—¶é—´è§„æ•´ï¼ˆDTWï¼‰çš„ kNN ç®—æ³•å¼€å§‹ã€‚æ­£å¦‚æˆ‘æåˆ°çš„ï¼Œè¿™ä¸ªç®—æ³•é€šå¸¸ä½œä¸ºä¸€ä¸ªä¸é”™çš„åŸºå‡†è¿›è¡Œæ¯”è¾ƒã€‚
- en: K-nearest neighbors with dynamic time warping in Python
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åŠ¨æ€æ—¶é—´è§„æ•´ï¼ˆDTWï¼‰çš„ k-è¿‘é‚»ç®—æ³•ï¼ˆkNNï¼‰åœ¨ Python ä¸­å®ç°
- en: In this section, we'll classify failures from force and torque measurements
    of a robot over time.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†åŸºäºæœºå™¨äººåœ¨ä¸€æ®µæ—¶é—´å†…çš„åŠ›å’Œæ‰­çŸ©æµ‹é‡æ¥åˆ†ç±»æ•…éšœã€‚
- en: We'll use a very simple classifier, kNN, and perhaps we should give a heads-up
    that this method involves taking point-wise distances, which can often be a bottleneck
    for computations.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªéå¸¸ç®€å•çš„åˆ†ç±»å™¨ï¼ŒkNNï¼Œå¹¶ä¸”æˆ–è®¸æˆ‘ä»¬åº”è¯¥æé†’ä¸€ä¸‹ï¼Œè¿™ç§æ–¹æ³•æ¶‰åŠåˆ°é€ç‚¹è®¡ç®—è·ç¦»ï¼Œè¿™é€šå¸¸ä¼šæˆä¸ºè®¡ç®—ç“¶é¢ˆã€‚
- en: In this section, we'll combine TSFresh's feature extraction in a pipeline with
    a kNN algorithm. The time-series pipeline can really help make things easy, as
    you'll find when reading the code snippets.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æŠŠ TSFresh çš„ç‰¹å¾æå–ä¸ kNN ç®—æ³•ç»“åˆåœ¨ä¸€ä¸ªç®¡é“ä¸­ã€‚æ—¶é—´åºåˆ—ç®¡é“ç¡®å®èƒ½å¸®åŠ©æˆ‘ä»¬ç®€åŒ–è¿‡ç¨‹ï¼Œæ­£å¦‚ä½ åœ¨é˜…è¯»ä»£ç ç‰‡æ®µæ—¶ä¼šå‘ç°çš„é‚£æ ·ã€‚
- en: 'Let''s install tsfresh and tslearn:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å®‰è£… tsfresh å’Œ tslearnï¼š
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We'll use the kNN classifier in tslearn. We could even have used the kNN classifier
    in scikit-learn, which allows a custom metric to be specified.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨ tslearn ä¸­ä½¿ç”¨ kNN åˆ†ç±»å™¨ã€‚æˆ‘ä»¬ç”šè‡³å¯ä»¥ä½¿ç”¨ scikit-learn ä¸­çš„ kNN åˆ†ç±»å™¨ï¼Œå®ƒå…è®¸æŒ‡å®šè‡ªå®šä¹‰çš„åº¦é‡æ ‡å‡†ã€‚
- en: 'In the example, we will download a dataset of robotic execution failures from
    the UCI machine learning repository and store it locally. This dataset contains
    force and torque measurements on a robot after failure detection. For each sample,
    the task is to classify whether the robot will report a failure:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä» UCI æœºå™¨å­¦ä¹ åº“ä¸‹è½½ä¸€ä¸ªæœºå™¨äººæ‰§è¡Œæ•…éšœçš„æ•°æ®é›†å¹¶å°†å…¶å­˜å‚¨åˆ°æœ¬åœ°ã€‚è¯¥æ•°æ®é›†åŒ…å«æ•…éšœæ£€æµ‹åçš„æœºå™¨äººåŠ›å’Œæ‰­çŸ©æµ‹é‡æ•°æ®ã€‚å¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œä»»åŠ¡æ˜¯åˆ†ç±»æœºå™¨äººæ˜¯å¦ä¼šæŠ¥å‘Šæ•…éšœï¼š
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The columns include the time and six time-series with signals from the sensors,
    `F_x`, `F_y`, `F_z`, `T_x`, `T_y`, and `T_z`. The target variable, `y`, which
    can take the values True or False, indicates if there was a failure.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—åŒ…æ‹¬æ—¶é—´å’Œå…­ä¸ªæ¥è‡ªä¼ æ„Ÿå™¨çš„æ—¶é—´åºåˆ—ä¿¡å·ï¼Œåˆ†åˆ«æ˜¯ `F_x`ã€`F_y`ã€`F_z`ã€`T_x`ã€`T_y` å’Œ `T_z`ã€‚ç›®æ ‡å˜é‡ `y`ï¼Œå…¶å€¼å¯ä»¥æ˜¯
    True æˆ– Falseï¼Œè¡¨ç¤ºæ˜¯å¦å‘ç”Ÿäº†æ•…éšœã€‚
- en: 'It''s always important to check the frequency of the two classes:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å§‹ç»ˆæ£€æŸ¥ä¸¤ä¸ªç±»åˆ«çš„é¢‘ç‡éå¸¸é‡è¦ï¼š
- en: '[PRE5]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The mean of y is 0.24.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: y çš„å‡å€¼æ˜¯ 0.24ã€‚
- en: 'We can then extract time-series features using TSFresh, as discussed in *Chapter
    3, Preprocessing Time-Series*. We can impute missing values and select features
    based on relevance to the target. In TSFresh, the p-value from a statistical test
    is used to calculate the feature significance:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ TSFresh æå–æ—¶é—´åºåˆ—ç‰¹å¾ï¼Œæ­£å¦‚åœ¨*ç¬¬3ç« ï¼Œæ—¶é—´åºåˆ—é¢„å¤„ç†*ä¸­è®¨è®ºçš„é‚£æ ·ã€‚æˆ‘ä»¬å¯ä»¥å¡«è¡¥ç¼ºå¤±å€¼ï¼Œå¹¶æ ¹æ®ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§é€‰æ‹©ç‰¹å¾ã€‚åœ¨
    TSFresh ä¸­ï¼Œç»Ÿè®¡æµ‹è¯•çš„ p å€¼è¢«ç”¨æ¥è®¡ç®—ç‰¹å¾çš„é‡è¦æ€§ï¼š
- en: '[PRE6]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can continue working with the `features_filtered` DataFrame, which contains
    our features â€“ sensor signals from before and TSFresh features.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ç»§ç»­ä½¿ç”¨ `features_filtered` DataFrameï¼Œå®ƒåŒ…å«æˆ‘ä»¬çš„ç‰¹å¾â€”â€”æ¥è‡ªä¼ æ„Ÿå™¨çš„ä¿¡å·å’Œ TSFresh ç‰¹å¾ã€‚
- en: 'Let''s find some good values for the number of neighbors by doing a grid search:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡è¿›è¡Œç½‘æ ¼æœç´¢æ¥æ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„é‚»å±…æ•°å€¼ï¼š
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We are using scikit-learn's `TimeSeriesSplit` to split the time-series. This
    is for the GridSearch.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨ä½¿ç”¨ scikit-learn çš„ `TimeSeriesSplit` æ¥åˆ’åˆ†æ—¶é—´åºåˆ—ã€‚è¿™æ˜¯ä¸ºäº†ç½‘æ ¼æœç´¢ï¼ˆGridSearchï¼‰ã€‚
- en: Alternatively, we could have just split based on an index.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä»…ä»…åŸºäºç´¢å¼•è¿›è¡Œæ‹†åˆ†ã€‚
- en: There are many parameters we could have tried, especially for the distance metric
    inÂ the kNN classifier. If you want to have a play with this, please see `TSLEARN_VALID_METRICS`
    for a complete list of metrics supported by tslearn.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°è¯•è®¸å¤šå‚æ•°ï¼Œç‰¹åˆ«æ˜¯åœ¨ kNN åˆ†ç±»å™¨ä¸­çš„è·ç¦»åº¦é‡ã€‚å¦‚æœä½ æƒ³å°è¯•ä¸€ä¸‹ï¼Œè¯·å‚é˜… `TSLEARN_VALID_METRICS` è·å– tslearn
    æ”¯æŒçš„åº¦é‡æ ‡å‡†çš„å®Œæ•´åˆ—è¡¨ã€‚
- en: Let's do a few forecasts of COVID cases. In the next section, we'll start with
    the Silverkite algorithm. Silverkite comes with the Greykite library released
    by LinkedInÂ in 2021\.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é¢„æµ‹ä¸€äº› COVID æ¡ˆä¾‹ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä» Silverkite ç®—æ³•å¼€å§‹ã€‚Silverkite æ˜¯ LinkedIn åœ¨ 2021 å¹´å‘å¸ƒçš„
    Greykite åº“çš„ä¸€éƒ¨åˆ†ã€‚
- en: Silverkite
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Silverkite
- en: At the time of writing, Greykite is in version 0.1.1 â€“ it's not fully stable
    yet. Its dependencies might conflict with newer versions of commonly used libraries,
    including Jupyter Notebooks. Do not worry though if you install the library in
    yourÂ virtual environment or on Google Colab.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å†™ä½œæ—¶ï¼ŒGreykiteçš„ç‰ˆæœ¬ä¸º0.1.1â€”â€”å®ƒå°šæœªå®Œå…¨ç¨³å®šã€‚å®ƒçš„ä¾èµ–é¡¹å¯èƒ½ä¸ä¸€äº›å¸¸ç”¨åº“çš„è¾ƒæ–°ç‰ˆæœ¬å‘ç”Ÿå†²çªï¼ŒåŒ…æ‹¬Jupyter Notebooksã€‚ä¸è¿‡ï¼Œå¦‚æœä½ åœ¨è™šæ‹Ÿç¯å¢ƒæˆ–Google
    Colabä¸­å®‰è£…è¯¥åº“ï¼Œä¸å¿…æ‹…å¿ƒã€‚
- en: 'Just go ahead and install the library with all its dependencies:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: åªéœ€å®‰è£…è¯¥åº“åŠå…¶æ‰€æœ‰ä¾èµ–é¡¹ï¼š
- en: '[PRE8]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now that Greykite is installed, we can use it.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨Greykiteå·²ç»å®‰è£…å¥½äº†ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒäº†ã€‚
- en: 'We''ll load up the COVID cases from the *Our World in Data* dataset, probably
    one of the best sources of available COVID data:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åŠ è½½æ¥è‡ª*Our World in Data*æ•°æ®é›†çš„COVIDç—…ä¾‹æ•°æ®ï¼Œå®ƒå¯èƒ½æ˜¯å¯ç”¨COVIDæ•°æ®ä¸­æœ€å¥½çš„æ¥æºä¹‹ä¸€ï¼š
- en: '[PRE9]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We are concentrating on cases in France.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸“æ³¨äºæ³•å›½çš„ç—…ä¾‹ã€‚
- en: 'We start by setting up the Greykite metadata parameters. We''ll then pass this
    object into the forecaster configuration:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆè®¾ç½®Greykiteçš„å…ƒæ•°æ®å‚æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æ­¤å¯¹è±¡ä¼ é€’ç»™é¢„æµ‹å™¨é…ç½®ï¼š
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Our time column is `date` and our value column is `new_cases`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ—¶é—´åˆ—æ˜¯`date`ï¼Œå€¼åˆ—æ˜¯`new_cases`ã€‚
- en: 'We''ll now create the `forecaster` object, which creates forecasts and stores
    the result:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å°†åˆ›å»º`forecaster`å¯¹è±¡ï¼Œå®ƒç”¨äºç”Ÿæˆé¢„æµ‹å¹¶å­˜å‚¨ç»“æœï¼š
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The forecast horizon is 90 days; we will forecast 90 days ahead. Our prediction
    interval is 95%. Both Silverkite and Prophet support quantifying uncertainty by
    means of prediction intervals. A coverage of 95% means that 95% of actuals should
    fall within the prediction interval. In Greykite, the _`components.uncertainty`
    model provides additional configuration options about uncertainty.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„æµ‹çš„æ—¶é—´è·¨åº¦ä¸º90å¤©ï¼›æˆ‘ä»¬å°†é¢„æµ‹æœªæ¥90å¤©ã€‚æˆ‘ä»¬çš„é¢„æµ‹åŒºé—´ä¸º95%ã€‚Silverkiteå’ŒProphetéƒ½æ”¯æŒé€šè¿‡é¢„æµ‹åŒºé—´æ¥é‡åŒ–ä¸ç¡®å®šæ€§ã€‚95%çš„è¦†ç›–ç‡æ„å‘³ç€95%çš„å®é™…å€¼åº”è¯¥è½åœ¨é¢„æµ‹åŒºé—´å†…ã€‚åœ¨Greykiteä¸­ï¼Œ_`components.uncertainty`æ¨¡å‹æä¾›äº†å…³äºä¸ç¡®å®šæ€§çš„é¢å¤–é…ç½®é€‰é¡¹ã€‚
- en: I've added a line to ignore warnings of the `UserWarning` type during training
    since otherwise, there are about 500 lines of warnings about 0s in the target
    column.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å·²ç»æ·»åŠ äº†ä¸€è¡Œä»£ç ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¿½ç•¥`UserWarning`ç±»å‹çš„è­¦å‘Šï¼Œå¦åˆ™ä¼šæœ‰å¤§çº¦500è¡Œå…³äºç›®æ ‡åˆ—ä¸­0å€¼çš„è­¦å‘Šã€‚
- en: 'Let''s plot the original time-series from the result object. We can overlay
    our forecasts:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ç»“æœå¯¹è±¡ä¸­ç»˜åˆ¶åŸå§‹æ—¶é—´åºåˆ—å›¾ï¼Œæˆ‘ä»¬å¯ä»¥å°†é¢„æµ‹ç»“æœå åŠ åœ¨å…¶ä¸Šï¼š
- en: '[PRE12]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Please leave out the `renderer` argument if you are not on Google Colab!
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¸æ˜¯åœ¨Google Colabä¸­ï¼Œè¯·ä¸è¦ä½¿ç”¨`renderer`å‚æ•°ï¼
- en: 'We get the following plot:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¾—åˆ°äº†ä»¥ä¸‹å›¾è¡¨ï¼š
- en: '![](img/B17577_07_04.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17577_07_04.png)'
- en: 'Figure 7.4: Forecast versus actual time-series (Silverkite)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 7.4ï¼šé¢„æµ‹ä¸å®é™…æ—¶é—´åºåˆ—ï¼ˆSilverkiteï¼‰
- en: 'The forecasts are in the `df` attribute of the `forecast` object:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç»“æœå­˜å‚¨åœ¨`forecast`å¯¹è±¡çš„`df`å±æ€§ä¸­ï¼š
- en: '[PRE13]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'These are the upper and lower confidence intervals of the forecasts:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯é¢„æµ‹ç»“æœçš„ä¸Šé™å’Œä¸‹é™ç½®ä¿¡åŒºé—´ï¼š
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_wsZ8St/Screenshot
    2021-08-30 at 21.25.06.png](img/B17577_07_05.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_wsZ8St/Screenshot
    2021-08-30 at 21.25.06.png](img/B17577_07_05.png)'
- en: 'Figure 7.5: Table of forecast versus actual time-series (Silverkite)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 7.5ï¼šé¢„æµ‹ä¸å®é™…æ—¶é—´åºåˆ—çš„è¡¨æ ¼ï¼ˆSilverkiteï¼‰
- en: 'We might want to get some performance metrics for our model. We can get the
    performance of the historical forecast on the holdout test set like this:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯èƒ½éœ€è¦è·å–ä¸€äº›å…³äºæ¨¡å‹çš„æ€§èƒ½æŒ‡æ ‡ã€‚æˆ‘ä»¬å¯ä»¥åƒè¿™æ ·è·å–å†å²é¢„æµ‹åœ¨ä¿ç•™æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½ï¼š
- en: '[PRE14]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Our performance metrics look like this:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ€§èƒ½æŒ‡æ ‡å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_UgQpeb/Screenshot
    2021-08-30 at 21.28.22.png](img/B17577_07_06.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_UgQpeb/Screenshot
    2021-08-30 at 21.28.22.png](img/B17577_07_06.png)'
- en: 'Figure 7.6: Performance metrics on the hold-out data (Silverkite)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 7.6ï¼šåœ¨ä¿ç•™æ•°æ®ä¸Šçš„æ€§èƒ½æŒ‡æ ‡ï¼ˆSilverkiteï¼‰
- en: I've truncated the metrics to the first five.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å·²å°†æŒ‡æ ‡ç¼©å‡ä¸ºå‰äº”ä¸ªã€‚
- en: 'We can apply our model conveniently to new data like this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æ–¹ä¾¿åœ°å°†æ¨¡å‹åº”ç”¨åˆ°æ–°çš„æ•°æ®ä¸Šï¼Œæ–¹æ³•å¦‚ä¸‹ï¼š
- en: '[PRE15]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The predictions look like this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_LxjFCi/Screenshot
    2021-08-30 at 21.31.08.png](img/B17577_07_07.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_LxjFCi/Screenshot
    2021-08-30 at 21.31.08.png](img/B17577_07_07.png)'
- en: 'Figure 7.7: Forecast DataFrame (Silverkite)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 7.7ï¼šé¢„æµ‹æ•°æ®æ¡†ï¼ˆSilverkiteï¼‰
- en: Please note that your result might vary.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæ‚¨çš„ç»“æœå¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚
- en: We can use other forecaster models by changing the `model_template` argument
    in the run configuration of the forecaster. For instance, we could set it to `ModelTemplateEnum.PROPHET.name`
    in order to take Facebook's Prophet model.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æ›´æ”¹é¢„æµ‹å™¨è¿è¡Œé…ç½®ä¸­çš„`model_template`å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å…¶ä»–é¢„æµ‹æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶è®¾ç½®ä¸º`ModelTemplateEnum.PROPHET.name`ï¼Œä»¥ä½¿ç”¨Facebookçš„Prophetæ¨¡å‹ã€‚
- en: This concludes our tour of Silverkite. Next, we will forecast by applying a
    supervised regression method with XGBoost. Let's do some gradient boosting!
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±ç»“æŸäº†æˆ‘ä»¬å¯¹Silverkiteçš„ä»‹ç»ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†é€šè¿‡åº”ç”¨XGBoostçš„ç›‘ç£å›å½’æ–¹æ³•è¿›è¡Œé¢„æµ‹ã€‚è®©æˆ‘ä»¬è¿›è¡Œä¸€äº›æ¢¯åº¦æå‡å§ï¼
- en: Gradient boosting
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¢¯åº¦æå‡
- en: We can use supervised machine learning for time-series forecasting as well.
    For this, we can use the dates and the previous values to predict the future.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨ç›‘ç£å¼æœºå™¨å­¦ä¹ è¿›è¡Œæ—¶é—´åºåˆ—é¢„æµ‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ—¥æœŸå’Œå‰æœŸå€¼æ¥é¢„æµ‹æœªæ¥ã€‚
- en: 'First, we need to install XGBoost:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…XGBoostï¼š
- en: '[PRE16]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We'll use the Yahoo daily closing data in this example, as in other practice
    sections ofÂ this chapter.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Yahooçš„æ¯æ—¥æ”¶ç›˜æ•°æ®ï¼Œå’Œæœ¬ç« å…¶ä»–å®è·µéƒ¨åˆ†ä¸€æ ·ã€‚
- en: Let's go through the preparation and modeling step by step.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥åœ°é€šè¿‡å‡†å¤‡å’Œå»ºæ¨¡è¿‡ç¨‹ã€‚
- en: We first need to featurize the data. Here, we'll do this by extracting date
    features, but please see the section on kNNs, where TSFresh's feature extraction
    is used instead. You might want to change this example by combining the two feature
    extraction strategies or by relying on TSFresh entirely.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆéœ€è¦å¯¹æ•°æ®è¿›è¡Œç‰¹å¾åŒ–ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬é€šè¿‡æå–æ—¥æœŸç‰¹å¾æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½†è¯·å‚è§kNNéƒ¨åˆ†ï¼Œåœ¨é‚£é‡Œæˆ‘ä»¬ä½¿ç”¨äº†TSFreshçš„ç‰¹å¾æå–ã€‚ä½ ä¹Ÿè®¸æƒ³é€šè¿‡ç»“åˆè¿™ä¸¤ç§ç‰¹å¾æå–ç­–ç•¥ï¼Œæˆ–å®Œå…¨ä¾èµ–TSFreshï¼Œæ¥æ”¹å˜è¿™ä¸ªç¤ºä¾‹ã€‚
- en: 'We will reload the new COVID cases from the *Our World in Data* dataset as
    before:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åƒä¹‹å‰ä¸€æ ·é‡æ–°åŠ è½½æ¥è‡ª*Our World in Data*æ•°æ®é›†çš„COVIDæ–°ç—…ä¾‹æ•°æ®ï¼š
- en: '[PRE17]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'For feature extraction, transformers are handy. A transformer is basically
    a class with `fit()` and `transform()` methods that can make the transformer adapt
    to a dataset and transform the data accordingly. Here''s the code for the `DateFeatures`
    transformer that annotates a dataset according to a date:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç‰¹å¾æå–ï¼Œè½¬æ¢å™¨éå¸¸æ–¹ä¾¿ã€‚è½¬æ¢å™¨åŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªç±»ï¼ŒåŒ…å«`fit()`å’Œ`transform()`æ–¹æ³•ï¼Œå¯ä»¥ä½¿è½¬æ¢å™¨é€‚åº”æ•°æ®é›†å¹¶ç›¸åº”åœ°è½¬æ¢æ•°æ®ã€‚ä»¥ä¸‹æ˜¯ç”¨äºæ ¹æ®æ—¥æœŸæ³¨é‡Šæ•°æ®é›†çš„`DateFeatures`è½¬æ¢å™¨çš„ä»£ç ï¼š
- en: '[PRE18]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This transformer is relatively simple in that it extracts a range of features
    for a date column such as hours, years, days, weekday, months, week of year, and
    quarter. These features can potentially be very powerful for describing or annotating
    the time-series data in a machine learning context.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè½¬æ¢å™¨ç›¸å¯¹ç®€å•ï¼Œå®ƒä¸ºæ—¥æœŸåˆ—æå–ä¸€ç³»åˆ—ç‰¹å¾ï¼Œä¾‹å¦‚å°æ—¶ã€å¹´ä»½ã€æ—¥æœŸã€æ˜ŸæœŸå‡ ã€æœˆä»½ã€å¹´åº¦å‘¨æ•°å’Œå­£åº¦ã€‚è¿™äº›ç‰¹å¾åœ¨æœºå™¨å­¦ä¹ ä¸Šä¸‹æ–‡ä¸­ï¼Œå¯èƒ½å¯¹æè¿°æˆ–æ³¨é‡Šæ—¶é—´åºåˆ—æ•°æ®éå¸¸æœ‰ç”¨ã€‚
- en: You can find the complete code for this example on GitHub. I am providing an
    additional transformer for cyclical features there that are omitted from this
    chapter.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥åœ¨GitHubä¸Šæ‰¾åˆ°è¿™ä¸ªç¤ºä¾‹çš„å®Œæ•´ä»£ç ã€‚æˆ‘æä¾›äº†ä¸€ä¸ªé¢å¤–çš„è½¬æ¢å™¨ï¼Œç”¨äºå¤„ç†ç« èŠ‚ä¸­æœªæ¶‰åŠçš„å‘¨æœŸæ€§ç‰¹å¾ã€‚
- en: 'We apply the transformers as follows to the `date` column of the DataFrame:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æŒ‰å¦‚ä¸‹æ–¹å¼åº”ç”¨è½¬æ¢å™¨åˆ°DataFrameçš„`date`åˆ—ï¼š
- en: '[PRE19]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `remainder="passthrough"` argument is set in case we want to provide additional
    exogenous features for prediction.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å¸Œæœ›ä¸ºé¢„æµ‹æä¾›é¢å¤–çš„å¤–ç”Ÿç‰¹å¾ï¼Œå¯ä»¥è®¾ç½®`remainder="passthrough"`å‚æ•°ã€‚
- en: 'We can define a pipeline of these preprocessing steps together with a model
    so that it can be fitted and applied to prediction:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªåŒ…å«è¿™äº›é¢„å¤„ç†æ­¥éª¤å’Œæ¨¡å‹çš„ç®¡é“ï¼Œè¿™æ ·å°±å¯ä»¥è¿›è¡Œæ‹Ÿåˆå¹¶åº”ç”¨äºé¢„æµ‹ï¼š
- en: '[PRE20]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The predictor is an XGBoost regressor. I didn't make much of an effort in terms
    of tweaking. The only parameter that we'll change is the number of estimators.
    We'll use an ensemble size (number of trees) of 1,000\.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„æµ‹å™¨æ˜¯ä¸€ä¸ªXGBoostå›å½’å™¨ã€‚æˆ‘åœ¨è°ƒæ•´æ–¹é¢å¹¶æ²¡æœ‰åšå¤ªå¤šå·¥ä½œã€‚å”¯ä¸€ä¼šæ”¹å˜çš„å‚æ•°æ˜¯ä¼°è®¡å™¨çš„æ•°é‡ã€‚æˆ‘ä»¬å°†ä½¿ç”¨1,000ä¸ªæ ‘çš„é›†æˆå¤§å°ï¼ˆå³æ ‘çš„æ•°é‡ï¼‰ã€‚
- en: 'Now it''s time to split the dataset into training and test sets. This includes
    two issues:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯æ—¶å€™å°†æ•°æ®é›†æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†äº†ã€‚è¿™åŒ…æ‹¬ä¸¤ä¸ªé—®é¢˜ï¼š
- en: We need to align the features with values ahead of time
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦æå‰å¯¹ç‰¹å¾å’Œæ•°å€¼è¿›è¡Œå¯¹é½
- en: We need to split the dataset into two by a cutoff time
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦æ ¹æ®æˆªæ­¢æ—¶é—´å°†æ•°æ®é›†æ‹†åˆ†ä¸ºä¸¤éƒ¨åˆ†
- en: 'Let''s first set the basic parameters for this. First, we want to predict into
    the future given a time horizon. Second, we need to decide how many data points
    we use for training and for testing:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆè®¾å®šåŸºæœ¬å‚æ•°ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¸Œæœ›åŸºäºæ—¶é—´èŒƒå›´é¢„æµ‹æœªæ¥ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬éœ€è¦å†³å®šç”¨äºè®­ç»ƒå’Œæµ‹è¯•çš„æ•°æ®ç‚¹æ•°é‡ï¼š
- en: '[PRE21]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We take 90% of points for training, and we predict 90 days into the future:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨90%çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¹¶é¢„æµ‹æœªæ¥90å¤©çš„æƒ…å†µï¼š
- en: '[PRE22]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This does both the alignment and horizon. Therefore, we have the datasets for
    testing and training, both with features and labels that we want to predict with
    XGBoost.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ—¢è¿›è¡Œäº†å¯¹é½ï¼Œä¹Ÿè®¾å®šäº†é¢„æµ‹èŒƒå›´ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æœ‰äº†ç”¨äºæµ‹è¯•å’Œè®­ç»ƒçš„æ•°æ®é›†ï¼Œä¸¤ä¸ªæ•°æ®é›†éƒ½åŒ…å«äº†æˆ‘ä»¬å¸Œæœ›ç”¨XGBoosté¢„æµ‹çš„ç‰¹å¾å’Œæ ‡ç­¾ã€‚
- en: Now we can train our XGBoost regression model to predict values within our HORIZON
    into the future based on the features we produced with our transformer and the
    current values.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥è®­ç»ƒæˆ‘ä»¬çš„XGBoostå›å½’æ¨¡å‹ï¼Œæ ¹æ®æˆ‘ä»¬é€šè¿‡è½¬æ¢å™¨ç”Ÿæˆçš„ç‰¹å¾å’Œå½“å‰å€¼ï¼Œé¢„æµ‹æœªæ¥HORIZONå†…çš„å€¼ã€‚
- en: 'We can fit our pipeline as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼æ‹Ÿåˆæˆ‘ä»¬çš„ç®¡é“ï¼š
- en: '[PRE23]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can see the following pipeline parameters:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä»¥ä¸‹ç®¡é“å‚æ•°ï¼š
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_VPuhp5/Screenshot
    2021-08-30 at 23.08.52.png](img/B17577_07_08.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_VPuhp5/Screenshot
    2021-08-30 at 23.08.52.png](img/B17577_07_08.png)'
- en: 'Figure 7.8: Pipeline parameters'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾7.8ï¼šç®¡é“å‚æ•°
- en: 'If we create a series of the dates from beginning to end, we can get the predictions
    of the model for the whole time period:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ä»å¼€å§‹åˆ°ç»“æŸåˆ›å»ºä¸€ä¸ªæ—¥æœŸç³»åˆ—ï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—æ•´ä¸ªæ—¶é—´æ®µå†…æ¨¡å‹çš„é¢„æµ‹ï¼š
- en: '[PRE24]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `predict()` method of the pipeline applied to `X_test` gives us the forecast:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: åº”ç”¨äº`X_test`çš„ç®¡é“çš„`predict()`æ–¹æ³•ä¸ºæˆ‘ä»¬æä¾›äº†é¢„æµ‹ç»“æœï¼š
- en: '[PRE25]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can do the same for the actual cases:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹Ÿå¯ä»¥å¯¹å®é™…ç—…ä¾‹åšåŒæ ·çš„æ“ä½œï¼š
- en: '[PRE26]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, we can contrast the forecast with the actual values, `y_test`, in a plot:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å›¾è¡¨å°†é¢„æµ‹ç»“æœä¸å®é™…å€¼`y_test`è¿›è¡Œå¯¹æ¯”ï¼š
- en: '[PRE27]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This is the plot we are getting:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬å¾—åˆ°çš„å›¾è¡¨ï¼š
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_Vnji3v/Screenshot
    2021-08-30 at 23.29.17.png](img/B17577_07_09.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_Vnji3v/Screenshot
    2021-08-30 at 23.29.17.png](img/B17577_07_09.png)'
- en: 'Figure 7.9: Forecast versus actual (XGBoost)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾7.9ï¼šé¢„æµ‹ä¸å®é™…å€¼å¯¹æ¯”ï¼ˆXGBoostï¼‰
- en: 'We can extract performance metrics over the test period like this:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æå–æµ‹è¯•æœŸé—´çš„æ€§èƒ½æŒ‡æ ‡ï¼š
- en: '[PRE28]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We should be seeing something like this:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„ç»“æœï¼š
- en: '[PRE29]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Next, we'll create an ensemble model for time-series forecasting in Kats.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åœ¨Katsä¸­åˆ›å»ºä¸€ä¸ªç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹çš„é›†æˆæ¨¡å‹ã€‚
- en: Ensembles with Kats
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Katsçš„é›†æˆæ–¹æ³•
- en: 'The Kats installation should be very easy in two steps. First, we install fbprophet,
    an old version of Facebook''s Prophet library:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Katsçš„å®‰è£…åº”è¯¥å¾ˆç®€å•ï¼Œåªéœ€ä¸¤ä¸ªæ­¥éª¤ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å®‰è£…Facebookçš„Prophetåº“çš„æ—§ç‰ˆæœ¬fbprophetï¼š
- en: '[PRE30]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now we install Kats with pip:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬ä½¿ç”¨pipå®‰è£…Katsï¼š
- en: '[PRE31]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Alternatively, on Colab, we can install Kats like this:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ï¼Œåœ¨Colabä¸Šï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·å®‰è£…Katsï¼š
- en: '[PRE32]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We''ll load the COVID cases dataset as before. Here''s just the last line:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åƒä¹‹å‰ä¸€æ ·åŠ è½½COVIDç—…ä¾‹æ•°æ®é›†ã€‚è¿™é‡Œåªå±•ç¤ºæœ€åä¸€è¡Œï¼š
- en: '[PRE33]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We'll configure our ensemble model, fit it, and then do a forecast.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é…ç½®é›†æˆæ¨¡å‹ï¼Œæ‹Ÿåˆå®ƒï¼Œç„¶åè¿›è¡Œé¢„æµ‹ã€‚
- en: 'First, the configuration of our ensemble:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆæ˜¯æˆ‘ä»¬çš„é›†æˆæ¨¡å‹çš„é…ç½®ï¼š
- en: '[PRE34]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Here, we include only two different models, but we could have included other
    and more models, and we could have defined better parameters. This is an example
    only; for a more realistic exercise, which I leave to the reader, I'd suggest
    adding ARIMA and Theta models. We need to define hyperparameters for each forecasting
    model.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œæˆ‘ä»¬åªåŒ…æ‹¬äº†ä¸¤ç§ä¸åŒçš„æ¨¡å‹ï¼Œä½†æˆ‘ä»¬æœ¬å¯ä»¥åŠ å…¥æ›´å¤šæ¨¡å‹ï¼Œä¹Ÿå¯ä»¥å®šä¹‰æ›´å¥½çš„å‚æ•°ã€‚è¿™åªæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼›å¯¹äºæ›´ç°å®çš„ç»ƒä¹ ï¼ˆæˆ‘ç•™ç»™è¯»è€…è‡ªå·±åšï¼‰ï¼Œæˆ‘å»ºè®®åŠ å…¥ARIMAå’ŒThetaæ¨¡å‹ã€‚æˆ‘ä»¬éœ€è¦ä¸ºæ¯ä¸ªé¢„æµ‹æ¨¡å‹å®šä¹‰è¶…å‚æ•°ã€‚
- en: 'We also need to create ensemble parameters that define how the ensemble aggregate
    is to be calculated and how the decomposition should work:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜éœ€è¦åˆ›å»ºé›†æˆå‚æ•°ï¼Œå®šä¹‰å¦‚ä½•è®¡ç®—é›†æˆèšåˆä»¥åŠå¦‚ä½•è¿›è¡Œåˆ†è§£ï¼š
- en: '[PRE35]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'To use a time-series with Kats, we have to convert our data from a DataFrame
    or series to a Kats time-series object. We can convert our COVID case data as
    follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åœ¨Katsä¸­ä½¿ç”¨æ—¶é—´åºåˆ—ï¼Œæˆ‘ä»¬å¿…é¡»å°†æ•°æ®ä»DataFrameæˆ–ç³»åˆ—è½¬æ¢ä¸ºKatsæ—¶é—´åºåˆ—å¯¹è±¡ã€‚æˆ‘ä»¬å¯ä»¥å¦‚ä¸‹è½¬æ¢æˆ‘ä»¬çš„COVIDç—…ä¾‹æ•°æ®ï¼š
- en: '[PRE36]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: What is important for the conversion is the fact that Kats can infer the frequency
    of the index. This can be tested with `pd.infer_freq()`. In our case, `pd.infer_freq(df["date"])`
    should return `D` for daily frequency.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: è½¬æ¢çš„å…³é”®æ˜¯Katsèƒ½å¤Ÿæ¨æ–­ç´¢å¼•çš„é¢‘ç‡ã€‚è¿™å¯ä»¥é€šè¿‡`pd.infer_freq()`è¿›è¡Œæµ‹è¯•ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œ`pd.infer_freq(df["date"])`åº”è¿”å›`D`ï¼Œè¡¨ç¤ºæ—¥é¢‘ç‡ã€‚
- en: 'Now we can create our `KatsEnsemble` and fit it:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥åˆ›å»ºæˆ‘ä»¬çš„`KatsEnsemble`å¹¶è¿›è¡Œæ‹Ÿåˆï¼š
- en: '[PRE37]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We can get separate predictions for each model using the `predict()` method.
    If we want to get the ensemble output, we have to call `aggregate()` after `predict()`:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`predict()`æ–¹æ³•ä¸ºæ¯ä¸ªæ¨¡å‹è·å–å•ç‹¬çš„é¢„æµ‹ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦è·å–é›†æˆè¾“å‡ºï¼Œå¿…é¡»åœ¨`predict()`ä¹‹åè°ƒç”¨`aggregate()`ï¼š
- en: '[PRE38]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We predict 90 days ahead. These predictions are stored as part of the model,
    so we don't need to capture the returned forecast. We can then aggregate the forecast
    from each model. Again, we don't need to get the returned DataFrame because this
    is stored inside the model object (`m.fcst_df`).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¢„æµ‹äº† 90 å¤©çš„æœªæ¥ã€‚è¿™äº›é¢„æµ‹ç»“æœä½œä¸ºæ¨¡å‹çš„ä¸€éƒ¨åˆ†è¢«å­˜å‚¨ï¼Œå› æ­¤æˆ‘ä»¬ä¸éœ€è¦æ•æ‰è¿”å›çš„é¢„æµ‹ç»“æœã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å°†æ¯ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœè¿›è¡Œèšåˆã€‚å†æ¬¡è¯´æ˜ï¼Œæˆ‘ä»¬ä¸éœ€è¦è·å–è¿”å›çš„
    DataFrameï¼Œå› ä¸ºå®ƒå·²ç»å­˜å‚¨åœ¨æ¨¡å‹å¯¹è±¡å†…éƒ¨ï¼ˆ`m.fcst_df`ï¼‰ã€‚
- en: 'In the end, we plot the aggregated DataFrame using a Kats convenience function:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ Kats çš„ä¾¿æ·å‡½æ•°ç»˜åˆ¶äº†èšåˆåçš„ DataFrameï¼š
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_Ou1y0x/Screenshot
    2021-08-30 at 23.38.36.png](img/B17577_07_10.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_Ou1y0x/Screenshot
    2021-08-30 at 23.38.36.png](img/B17577_07_10.png)'
- en: 'Figure 7.10: Kats ensemble model forecast'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 7.10ï¼šKats é›†æˆæ¨¡å‹é¢„æµ‹
- en: Since we can tweak this ensemble model by changing the base model parameter
    and adding new models, this can give us lots of room for improvement.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬å¯ä»¥é€šè¿‡æ›´æ”¹åŸºç¡€æ¨¡å‹å‚æ•°å’Œæ·»åŠ æ–°æ¨¡å‹æ¥è°ƒæ•´è¿™ä¸ªé›†æˆæ¨¡å‹ï¼Œå› æ­¤å®ƒä¸ºæˆ‘ä»¬æä¾›äº†å¤§é‡çš„æ”¹è¿›ç©ºé—´ã€‚
- en: It's time to conclude this chapter with a summary of what we've learned.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯æ—¶å€™æ€»ç»“ä¸€ä¸‹æœ¬ç« æˆ‘ä»¬æ‰€å­¦åˆ°çš„å†…å®¹äº†ã€‚
- en: Summary
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ€»ç»“
- en: 'In this chapter, we''ve discussed popular time-series machine learning libraries
    in Python. We then discussed and tried out a k-nearest neighbor algorithm with
    dynamic time warping for the classification of robotic failures. We talked about
    validation in time-series forecasting and we tried three different methods for
    forecasting COVID cases: Silverkite, Gradient Boosting with XGBoost, and ensembleÂ models
    in Kats.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« æˆ‘ä»¬è®¨è®ºäº† Python ä¸­æµè¡Œçš„æ—¶é—´åºåˆ—æœºå™¨å­¦ä¹ åº“ã€‚æ¥ç€ï¼Œæˆ‘ä»¬è®¨è®ºå¹¶å°è¯•äº†å¸¦æœ‰åŠ¨æ€æ—¶é—´è§„æ•´çš„ k æœ€è¿‘é‚»ç®—æ³•ï¼Œç”¨äºæœºå™¨æ•…éšœåˆ†ç±»ã€‚æˆ‘ä»¬è¿˜è°ˆåˆ°äº†æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„éªŒè¯ï¼Œå¹¶å°è¯•äº†ä¸‰ç§ä¸åŒçš„æ–¹æ³•æ¥é¢„æµ‹
    COVID-19 ç–«æƒ…ï¼šSilverkiteã€XGBoost æ¢¯åº¦æå‡ä»¥åŠ Kats ä¸­çš„é›†æˆæ¨¡å‹ã€‚
