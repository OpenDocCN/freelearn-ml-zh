- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Machine Learning Models for Time-Series
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列的机器学习模型
- en: Machine learning has come a long way in recent years, and this is reflected
    in the methods available to time-series predictions. We've introduced a few state-of-the-art
    machine learning methods for time-series in *Chapter 4*, *Introduction to Machine
    Learning for Time-Series*. In the current chapter, we'll introduce several more
    machine learning methods.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，机器学习取得了长足的进展，这一点在时间序列预测方法中得到了体现。我们在*第4章*，*时间序列机器学习导论*中介绍了一些最先进的时间序列机器学习方法。在本章中，我们将介绍更多的机器学习方法。
- en: We'll go through methods that are commonly used as baseline methods, or that
    stand out in terms of either performance, ease of use, or their applicability.
    I'll introduce k-nearest neighbors with dynamic time warping and gradient boosting
    for time-series as a baseline and we'll go over other methods, such as Silverkite
    and gradient boosting. Finally, we'll go through an applied exercise with some
    of these methods.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍一些常用的基准方法，或者在性能、易用性或适用性方面表现突出的算法。我将介绍基于动态时间规整和梯度提升的k近邻算法作为基准，我们还将讨论其他方法，如Silverkite和梯度提升。最后，我们将进行一个应用练习，使用这些方法中的一些。
- en: 'We''re going to cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: More machine learning methods for time-series
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多的时间序列机器学习方法
- en: K-nearest neighbors with dynamic time warping
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有动态时间规整的k近邻算法
- en: Silverkite
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Silverkite
- en: Gradient boosting
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度提升
- en: Python exercise
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python练习
- en: If you are looking for a discussion of state-of-the-art machine learning algorithms,
    please refer to *Chapter 4*, *Introduction to Machine Learning for Time-Series*.
    The discussion of algorithms will assume some of the information of that chapter.
    The algorithms that we'll cover in the next sections are all highly competitive
    for forecasting and prediction tasks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解最先进的机器学习算法，请参阅*第4章*，*时间序列机器学习导论*。本章的算法讨论将假设你已经掌握了该章节的一些内容。我们将在接下来的部分中介绍的算法在预测和预报任务中都非常具有竞争力。
- en: We'll discuss algorithms here in more detail.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里更详细地讨论这些算法。
- en: More machine learning methods for time-series
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多的时间序列机器学习方法
- en: The algorithms that we'll cover in this section are all highly competitive for
    forecasting and prediction tasks. If you are looking for a discussion of state-of-the-art
    machine learning algorithms, please refer to *Chapter 4*, *Introduction to Machine
    Learning for Time-Series*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本节中介绍的算法在预测和预报任务中都具有高度竞争性。如果你想了解最先进的机器学习算法，请参阅*第4章*，*时间序列机器学习导论*。
- en: In the aforementioned chapter, we've briefly discussed a few of these algorithms,
    but we'll discuss them here in more detail and we will also introduce other algorithms
    that we haven't discussed before, such as Silverkite, gradient boosting, and k-nearest
    neighbors.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述章节中，我们简要讨论了其中的一些算法，但我们将在这里更详细地讲解它们，还会介绍一些我们之前未曾讨论过的算法，如Silverkite、梯度提升和k近邻。
- en: We'll dedicate a separate practice section to a library that was released in
    2021, which is facebook's Kats. Kats provides many advanced features, including
    hyperparameter tuning and ensemble learning. On top of these features, they implement
    feature extraction based on the TSFresh library and include many models, including
    Prophet, SARIMA, and others. They claim that their hyperparameter tuning for time-series
    is about 6-20 times faster in benchmarks compared with other hyperparameter tuning
    algorithms.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将专门设置一个实践部分，介绍一个2021年发布的库——Facebook的Kats。Kats提供了许多高级功能，包括超参数调优和集成学习。在这些功能的基础上，它们实现了基于TSFresh库的特征提取，并包含多个模型，包括Prophet、SARIMA等。它们声称，与其他超参数调优算法相比，Kats在时间序列上的超参数调优在基准测试中快了6到20倍。
- en: 'This graph provides an overview of the popularity of selected time-series machine
    learning libraries:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 该图展示了所选时间序列机器学习库的流行度概览：
- en: '![more_machine_learning-star_history.png](img/B17577_07_01.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![more_machine_learning-star_history.png](img/B17577_07_01.png)'
- en: 'Figure 7.1: Popularity of time-series machine learning libraries'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：时间序列机器学习库的流行度
- en: As of mid-2021, Kats and GreyKite have been released very recently, and although
    they have been garnering stars on GitHub, they haven't accumulated enough to rival
    TSFresh's popularity. I've included TSFresh even though it is a library for feature
    generation, and not prediction. I found it interesting to see how important it
    is in relation to other libraries that we use in this chapter. After TSFresh,
    SKTime is second, and it has been attracting a lot of stars over a relatively
    short time period.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2021年中期，Kats和GreyKite库最近才发布，尽管它们在GitHub上获得了越来越多的星标，但它们的受欢迎程度还未能与TSFresh相抗衡。我尽管TSFresh是一个特征生成库，而非预测库，但还是将其包含在内，因为我觉得它在本章所使用的其他库中非常重要。TSFresh之后，SKTime排名第二，并且在相对较短的时间内吸引了大量星标。
- en: We'll use a few of these libraries in the practical examples in this chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的实际示例中，我们将使用一些这些库。
- en: Another important issue is validation, and it's worth covering this separately.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的问题是验证，值得单独讨论这个问题。
- en: Validation
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证
- en: We've discussed validation before in *Chapter 4*, *Introduction to Machine Learning
    for Time-Series*. Often, in machine learning tasks, we use k-fold cross-validation,
    where splits of the data are performed pseudo-randomly, so the training and the
    test/validation datasets can come from any part of the data as long as it hasn't
    been used for training (**out-of-sample data**).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第4章*，*时间序列的机器学习入门*中已经讨论过验证。通常在机器学习任务中，我们使用k折交叉验证，其中数据的拆分是伪随机进行的，因此训练集和测试/验证集可以来自数据的任何部分，只要这些部分没有被用于训练（**样本外数据**）。
- en: With time-series data, this way of validation can lead to an overconfidence
    in the model's performance because, realistically, time-series tend to change
    over time according to trend, seasonality, and changes to the time-series characteristics.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于时间序列数据，这种验证方法可能会导致对模型性能的过度自信，因为现实中，时间序列往往随着趋势、季节性和时间序列特征的变化而变化。
- en: Therefore, with time-series, validation is often performed in a so-called **walk-forward
    validation**. This means that we train the model on past data, and we'll test
    it on the newest slice of data. This will take out the optimistic bias and give
    us a more realistic estimate of performance once the model is deployed.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在时间序列中，验证通常采用所谓的**前向验证（walk-forward validation）**。这意味着我们在过去的数据上训练模型，然后在最新的数据片段上进行测试。这将消除过于乐观的偏差，并在模型部署后为我们提供更为现实的性能评估。
- en: 'In terms of training, validation, and test datasets, this means that we''ll
    adjust model parameters entirely on training and validation datasets, and we''ll
    benchmark our test based on a set of data that''s more advanced in time, as illustrated
    in the following diagram (source: Greykite library''s GitHub repository):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练、验证和测试数据集方面，这意味着我们将完全依赖训练和验证数据集来调整模型参数，并且我们将基于一个时间上更先进的数据集来评估测试，具体如下面的图示所示（来源：Greykite库的GitHub仓库）：
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/(A Document
    Being Saved By screencaptureui 20)/Screenshot 2021-06-06 at 21.39.47.png](img/B17577_07_02.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/(A Document
    Being Saved By screencaptureui 20)/Screenshot 2021-06-06 at 21.39.47.png](img/B17577_07_02.png)'
- en: 'Figure 7.2: Walk-forward validation'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：前向验证
- en: In walk-forward validation, we train on an initial segment of the data and then
    test on a period after the training set. Next, we roll forward and repeat the
    process. This way, we have multiple out-of-sample periods and can combine the
    results over these periods. With walk-forward, we are less likely to suffer from
    overfitting.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在前向验证中，我们先在数据的初始片段上训练，然后在训练集之后的某个时间段进行测试。接着，我们向前推进并重复这一过程。这样，我们有多个样本外的时间段，可以将这些时间段的结果进行整合。通过前向验证，我们不太可能遭遇过拟合的问题。
- en: K-nearest neighbors with dynamic time warping
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态时间规整的K近邻算法
- en: K-nearest neighbors is a well-known machine learning method (sometimes also
    going under the guise of case-based reasoning). In kNN, we can use a distance
    measure to find similar data points. We can then take the known labels of these
    nearest neighbors as the output and integrate them in some way using a function.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: K近邻是一个著名的机器学习方法（有时也被称为基于案例的推理）。在kNN中，我们可以使用距离度量来找到相似的数据点。然后，我们可以将这些最近邻的已知标签作为输出，并通过某种函数将它们整合在一起。
- en: '*Figure 7.3* illustrates the basic idea of kNN for classification (source –
    WikiMedia Commons: [https://commons.wikimedia.org/wiki/File:KnnClassification.svg](https://commons.wikimedia.org/wiki/File:KnnClassification.svg)):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.3* 展示了 kNN 分类的基本思路（来源 – WikiMedia Commons: [https://commons.wikimedia.org/wiki/File:KnnClassification.svg](https://commons.wikimedia.org/wiki/File:KnnClassification.svg)）：'
- en: '![/Users/ben/Downloads/Machine-Learning for Time-Series with Python/knn.png](img/B17577_07_03.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![/Users/ben/Downloads/Machine-Learning for Time-Series with Python/knn.png](img/B17577_07_03.png)'
- en: 'Figure 7.3: K-nearest neighbor for classification'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：用于分类的 K 最近邻
- en: We know a few data points already. In the preceding illustration, these points
    are indicated as squares and triangles, and they represent data points of two
    different classes, respectively. Given a new data point, indicated by a circle,
    we find the closest known data points to it. In this example, we find that the
    new point is similar to triangles, so we might assume that the new point is of
    the triangle class as well.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道一些数据点。在前面的示意图中，这些数据点分别用方形和三角形表示，代表了两个不同类别的数据点。给定一个新的数据点，用圆圈表示，我们找到与之最接近的已知数据点。在这个例子中，我们发现新点与三角形相似，因此我们可以假设新点也属于三角形类。
- en: While this method is conceptually very simple, it often serves as a strong baseline
    method, or is sometimes even competitive with more sophisticated machine learning
    algorithms, even when we only compare the closest neighbor *(**𝑘**=1)*.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种方法在概念上非常简单，但它通常作为一种强基线方法，或者有时甚至能与更复杂的机器学习算法竞争，即使我们只比较最接近的邻居（*（**𝑘**=1）*）。
- en: 'The important hyperparameters in this algorithm are:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法中的重要超参数有：
- en: The number of neighbors (k) you want to base your output on
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你希望根据其来生成输出的邻居数（k）
- en: The integration function (for example, the average or the most frequent value)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成函数（例如，平均值或最常见值）
- en: The distance function to use to find the nearest data points
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于找到最近数据点的距离函数
- en: We talked about dynamic time warping in *Chapter 4*, *Introduction to Machine
    Learning for Time-Series*, as a measure that can be used to compare the similarity
    (or, equivalently, the distance) between two time-series. These sequences can
    even be of different lengths. Dynamic time warping has proven itself to be an
    exceptionally strong distance measure for time-series.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第 4 章*《*时间序列机器学习导论*》中讨论过动态时间扭曲（Dynamic Time Warping），它是一种用于比较两条时间序列相似性（或等价地，距离）的方法。这些序列甚至可以有不同的长度。动态时间扭曲已经证明自己是一个异常强大的时间序列距离度量。
- en: We can use kNN in combination with dynamic time warping as a distance measure
    to find similar time-series, and this method has proven itself hard to beat, although
    the state of the art has since surpassed it.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将 kNN 和动态时间扭曲结合起来，作为一种距离度量来寻找相似的时间序列，这种方法已经证明其在某些情况下很难被超越，尽管当前的技术已经超过了它。
- en: Silverkite
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Silverkite
- en: The Silverkite algorithm ships together with the Greykite library released by
    LinkedIn. It was explicitly designed with the goals in mind of being fast, accurate,
    and intuitive. The algorithm is described in a 2021 publication ("*A flexible
    forecasting model for production systems*", by Reza Hosseini and others).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Silverkite 算法与 LinkedIn 发布的 Greykite 库一起发布。它的设计目标是快速、准确且直观。该算法在 2021 年的文章中有描述（《*生产系统的灵活预测模型*》，Reza
    Hosseini 等人）。
- en: According to LinkedIn, it can handle different kinds of trends and seasonalities
    such as hourly, daily, weekly, repeated events, and holidays, and short-range
    effects. Within LinkedIn, it is used for both short-term, for example, a 1-day
    head, and long-term forecast horizons, such as 1 year ahead.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 LinkedIn，它能够处理各种趋势和季节性因素，例如每小时、每日、每周、重复事件、假期以及短期效应。在 LinkedIn 内部，它既用于短期预测，例如
    1 天的预测，也用于长期预测，例如 1 年后的预测。
- en: Use cases within LinkedIn include optimizing budget decisions, setting business
    metric targets, and providing sufficient infrastructure to handle peak traffic.
    Furthermore, a use case has been to model recoveries from the COVID-19 pandemic.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LinkedIn 中的应用场景包括优化预算决策、设定业务指标目标，以及提供足够的基础设施来应对峰值流量。此外，一个应用场景是建模 COVID-19
    大流行后的恢复情况。
- en: 'The time-series is modeled as an additive composite of trends, change points,
    and seasonality, where seasonality includes holiday/event effects. The trend is
    then modeled as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列被建模为趋势、变化点和季节性的加性组合，其中季节性包括假期/事件效应。趋势随后被建模如下：
- en: '![](img/B17577_07_001.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17577_07_001.png)'
- en: where K is the number of change points, and *t*[i] is the time index for the
    i-th change point. Therefore, ![](img/B17577_07_002.png) is an indicator function
    for the i-th change point. The function f(t) can be linear, square root, quadratic,
    any combination, or completely custom.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 K 是变化点的数量，*t*[i] 是第 i 个变化点的时间索引。因此，![](img/B17577_07_002.png) 是第 i 个变化点的指示函数。函数
    f(t) 可以是线性、平方根、二次、任意组合或完全自定义。
- en: Silverkite also constructs indicator variables for holidays. Holidays can be
    specified by name or by country, or can even be completely custom.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Silverkite 还构建了假期的指示变量。假期可以通过名称或国家指定，甚至可以完全自定义。
- en: Change points can be specified manually or candidates can be automatically detected
    with a regression model and subsequently selected using the Adaptive Lasso algorithm
    (Hui Zhou, 2006).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 变化点可以手动指定，或者可以通过回归模型自动检测候选变化点，随后使用自适应 Lasso 算法（Hui Zhou，2006）进行选择。
- en: In addition to trend, seasonality, and holiday, Silverkite includes an autoregressive
    term that is calculated based on windowed averages rather than taking lags independently
    ("*Selecting a binary Markov model for a precipitation process*", by Reza Hosseini
    and others, 2011).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 除了趋势、季节性和假期，Silverkite 还包括一个自回归项，该项是基于窗口平均值计算的，而不是独立地取滞后项（《*为降水过程选择二元马尔科夫模型*》，Reza
    Hosseini 等，2011）。
- en: 'This autoregressive term is specified using the Pasty library, using a formula
    mini-language, in a form like this string:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 该自回归项使用 Pasty 库指定，使用类似以下字符串的公式迷你语言形式：
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this formula, y on the left-hand side is defined as the sum of three terms,
    `a`, `a:b`, and `np.log(x)`. The term `a:b` is an interaction between two factors,
    a and b. The model template itself in Pasty is highly customizable, so this interface
    provides a high degree of flexibility.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，左侧的 y 定义为三个项的总和，`a`、`a:b` 和 `np.log(x)`。项 `a:b` 是两个因子 a 和 b 之间的交互作用。Pasty
    中的模型模板本身具有高度的可定制性，因此该接口提供了很高的灵活性。
- en: Finally, Silverkite comes with several model types, such as ridge regression,
    elastic net, and boosted trees, with supported loss functions, MSE, and quantile
    loss for robust regression.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Silverkite 提供了几种模型类型，如岭回归、弹性网和提升树，并支持损失函数，如均方误差（MSE）和分位数损失，用于稳健回归。
- en: According to a LinkedIn benchmark on several datasets, Silverkite outperforms
    both auto-Arima (the pmdarima library) and Prophet in terms of prediction error.
    Yet, Silverkite was about four times as fast as Prophet, which we'll introduce
    in *Chapter 9*, *Probabilistic Models*.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 LinkedIn 对多个数据集的基准测试，Silverkite 在预测误差方面优于 auto-Arima（pmdarima 库）和 Prophet。然而，Silverkite
    的速度约为 Prophet 的四倍，我们将在 *第9章*，*概率模型* 中介绍 Prophet。
- en: Gradient boosting
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度提升
- en: '**XGBoost** (short for **eXtreme Gradient Boosting**) is an efficient implementation
    of gradient boosting (Jerome Friedman, "*Greedy function approximation: a gradient
    boosting machine*", 2001) for classification and regression problems. Gradient
    boosting is also known as **Gradient Boosting Machine** (**GBM**) or **Gradient
    Boosted Regression Tree** (**GBRT**). A special case is LambdaMART for ranking
    applications. Apart from XGBoost; other implementations are Microsoft''s Light
    Gradient Boosting Machine (LightGBM), and Yandex''s Catboost.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**XGBoost**（即**极限梯度提升**的缩写）是梯度提升的高效实现（Jerome Friedman，《*贪婪函数逼近：一种梯度提升机器*》，2001），用于分类和回归问题。梯度提升也被称为**梯度提升机**（**GBM**）或**梯度提升回归树**（**GBRT**）。一个特例是用于排序应用的
    LambdaMART。除了 XGBoost，其他实现包括微软的轻量级梯度提升机（LightGBM）和 Yandex 的 Catboost。'
- en: Gradient Boosted Trees is an ensemble of trees. This is similar to Bagging algorithms
    such as Random Forest; however, since this is a boosting algorithm, each tree
    is computed to incrementally reduce the error. With each new iteration a tree
    is greedily chosen and its prediction is added to the previous predictions based
    on a weight term. There is also a regularization term that penalizes complexity
    and reduces overfitting, similar to the Regularized Greedy Forest (RGF).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度提升树是树的集成。这与类似于随机森林的袋装算法类似；然而，由于这是一个提升算法，每棵树都会被计算出来，逐步减少误差。每次新的迭代都会贪心地选择一棵树，并将其预测值基于权重项加到先前的预测值中。还有一个正则化项，用于惩罚复杂性并减少过拟合，类似于正则化贪婪森林（RGF）。
- en: 'The **XGBoost** algorithm was published in 2016 by Tianqi Chen and Carlos Guestrin
    ("*XGBoost: A Scalable Tree Boosting System*") and pushed the envelope on many
    classification and regression benchmarks. It was used in many winning solutions
    to Kaggle problems. In fact, in 2015, of the 29 challenge-winning solutions, 17
    solutions used XGBoost.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**XGBoost**算法由陈天奇和卡洛斯·格斯特林于2016年发布（"*XGBoost：一种可扩展的树提升系统*"），并推动了许多分类和回归基准的突破。它被用于许多Kaggle问题的获胜解决方案。事实上，在2015年，29个挑战获胜解决方案中，有17个解决方案使用了XGBoost。'
- en: It was designed to be highly scalable and features extensions of the gradient
    boosting algorithm for weighted quantiles, along with improvements for scalability
    and parallelization based on smarter caching patterns, sharding, and the handling
    of sparsity.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 它的设计非常具有可扩展性，并且扩展了梯度提升算法，用于加权分位数，并通过更智能的缓存模式、分片以及对稀疏性处理的改进，提升了可扩展性和并行化性能。
- en: As a special case of regression, XGBoost can be used for forecasting. In this
    scenario, the model is trained based on past values to predict future values,
    and this can be applied to univariate as well as multivariate time-series.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 作为回归的一个特例，XGBoost可以用于预测。在这种情况下，模型基于过去的值进行训练，以预测未来的值，这可以应用于单变量和多变量时间序列。
- en: Python exercise
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python练习
- en: Let's put into practice what we've learned in this chapter so far.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将本章迄今为止学到的内容付诸实践。
- en: As for requirements, in this chapter, we'll be installing requirements for each
    section separately. The installation can be performed from the terminal, the notebook,
    or from the anaconda navigator.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 至于依赖项，在本章中，我们将分别为每个部分安装依赖。可以通过终端、笔记本或Anaconda Navigator进行安装。
- en: In a few of the following sections, we'll demonstrate classification in a forecast,
    so some of these approaches will not be comparable. The reader is invited to do
    forecasts and classification using each approach and then compare results.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几个部分中，我们将演示如何在预测中进行分类，因此这些方法中的一些可能无法进行比较。我们邀请读者使用每种方法进行预测和分类，并进行结果比较。
- en: As a note of caution, both Kats and Greykite (at the time of writing) are very
    new libraries, so there might still be frequent changes to dependencies. They
    might pin your NumPy version or other commonly used libraries. Therefore, I'd
    recommend you install them in virtual environments separately for each section.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，Kats和Greykite（在写作时）都是非常新的库，因此它们的依赖项可能还会频繁变化。它们可能会锁定您的NumPy版本或其他常用库。因此，我建议您为每个部分分别在虚拟环境中安装这些库。
- en: We'll go through this setup in the next section.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中详细介绍这个设置过程。
- en: Virtual environments
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 虚拟环境
- en: In a Python virtual environment, all libraries, binaries, and scripts installed
    into it are isolated from those installed in other virtual environments and from
    those installed in the system. This means that we can have different libraries,
    such as Kats and Greykite, installed without having to bother with compatibility
    issues between them or with other libraries installed on our computer.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python虚拟环境中，安装到其中的所有库、二进制文件和脚本都是与其他虚拟环境中安装的内容以及系统中安装的内容隔离的。这意味着我们可以安装不同的库，如Kats和Greykite，而无需担心它们之间的兼容性问题，或与我们计算机上安装的其他库之间的兼容性问题。
- en: Let's go through a quick tutorial introduction to using virtual environments
    with Jupyter notebooks using anaconda (similarly, you can use tools such as virtualenv
    or pipenv).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个简短的教程，介绍如何在使用Anaconda的Jupyter笔记本中使用虚拟环境（类似地，您也可以使用如virtualenv或pipenv等工具）。
- en: In *Chapter 1*, *Introduction to Time-Series with Python*, we went through the
    installation of Anaconda, so we'll skip the installation. Please refer to that
    chapter or go to conda.io for instructions.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第1章*，*使用Python进行时间序列分析简介*中，我们介绍了Anaconda的安装，因此我们会跳过这部分安装。请参考那一章，或者访问conda.io获取安装说明。
- en: 'To create a virtual environment, you have to specify a name:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个虚拟环境，必须指定一个名称：
- en: '[PRE1]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This will create an eponymous directory (`myenv`), where all libraries and scripts
    will be installed.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个同名的目录（`myenv`），其中所有库和脚本将被安装。
- en: 'If we want to use this environment, we have to activate it first, which means
    that we set the `PATH` variable to include our newly created directory:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想使用这个环境，我们必须首先激活它，这意味着我们需要将`PATH`变量设置为包括我们新创建的目录：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can now use tools such as pip, which will default to the one bundled with
    conda, or the conda command directly to install libraries.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用像pip这样的工具，默认情况下它会使用与conda捆绑在一起的版本，或者直接使用conda命令来安装库。
- en: We can install Jupyter or Jupyter labs into our environment and then start it.
    This means that our Jupyter environment will include all dependencies as we've
    installed them in isolation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在环境中安装 Jupyter 或 Jupyter Lab 然后启动它。这意味着我们的 Jupyter 环境将包含所有依赖项，因为我们已将它们单独安装。
- en: Let's start with a kNN algorithm with dynamic time warping. As I've mentioned,
    this algorithm often serves as a decent baseline for comparisons.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个带有动态时间规整（DTW）的 kNN 算法开始。正如我提到的，这个算法通常作为一个不错的基准进行比较。
- en: K-nearest neighbors with dynamic time warping in Python
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用动态时间规整（DTW）的 k-近邻算法（kNN）在 Python 中实现
- en: In this section, we'll classify failures from force and torque measurements
    of a robot over time.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将基于机器人在一段时间内的力和扭矩测量来分类故障。
- en: We'll use a very simple classifier, kNN, and perhaps we should give a heads-up
    that this method involves taking point-wise distances, which can often be a bottleneck
    for computations.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个非常简单的分类器，kNN，并且或许我们应该提醒一下，这种方法涉及到逐点计算距离，这通常会成为计算瓶颈。
- en: In this section, we'll combine TSFresh's feature extraction in a pipeline with
    a kNN algorithm. The time-series pipeline can really help make things easy, as
    you'll find when reading the code snippets.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将把 TSFresh 的特征提取与 kNN 算法结合在一个管道中。时间序列管道确实能帮助我们简化过程，正如你在阅读代码片段时会发现的那样。
- en: 'Let''s install tsfresh and tslearn:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们安装 tsfresh 和 tslearn：
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We'll use the kNN classifier in tslearn. We could even have used the kNN classifier
    in scikit-learn, which allows a custom metric to be specified.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 tslearn 中使用 kNN 分类器。我们甚至可以使用 scikit-learn 中的 kNN 分类器，它允许指定自定义的度量标准。
- en: 'In the example, we will download a dataset of robotic execution failures from
    the UCI machine learning repository and store it locally. This dataset contains
    force and torque measurements on a robot after failure detection. For each sample,
    the task is to classify whether the robot will report a failure:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将从 UCI 机器学习库下载一个机器人执行故障的数据集并将其存储到本地。该数据集包含故障检测后的机器人力和扭矩测量数据。对于每个样本，任务是分类机器人是否会报告故障：
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The columns include the time and six time-series with signals from the sensors,
    `F_x`, `F_y`, `F_z`, `T_x`, `T_y`, and `T_z`. The target variable, `y`, which
    can take the values True or False, indicates if there was a failure.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 列包括时间和六个来自传感器的时间序列信号，分别是 `F_x`、`F_y`、`F_z`、`T_x`、`T_y` 和 `T_z`。目标变量 `y`，其值可以是
    True 或 False，表示是否发生了故障。
- en: 'It''s always important to check the frequency of the two classes:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 始终检查两个类别的频率非常重要：
- en: '[PRE5]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The mean of y is 0.24.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: y 的均值是 0.24。
- en: 'We can then extract time-series features using TSFresh, as discussed in *Chapter
    3, Preprocessing Time-Series*. We can impute missing values and select features
    based on relevance to the target. In TSFresh, the p-value from a statistical test
    is used to calculate the feature significance:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用 TSFresh 提取时间序列特征，正如在*第3章，时间序列预处理*中讨论的那样。我们可以填补缺失值，并根据与目标变量的相关性选择特征。在
    TSFresh 中，统计测试的 p 值被用来计算特征的重要性：
- en: '[PRE6]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can continue working with the `features_filtered` DataFrame, which contains
    our features – sensor signals from before and TSFresh features.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续使用 `features_filtered` DataFrame，它包含我们的特征——来自传感器的信号和 TSFresh 特征。
- en: 'Let''s find some good values for the number of neighbors by doing a grid search:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过进行网格搜索来找到一个合适的邻居数值：
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We are using scikit-learn's `TimeSeriesSplit` to split the time-series. This
    is for the GridSearch.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用 scikit-learn 的 `TimeSeriesSplit` 来划分时间序列。这是为了网格搜索（GridSearch）。
- en: Alternatively, we could have just split based on an index.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们也可以仅仅基于索引进行拆分。
- en: There are many parameters we could have tried, especially for the distance metric
    in the kNN classifier. If you want to have a play with this, please see `TSLEARN_VALID_METRICS`
    for a complete list of metrics supported by tslearn.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以尝试许多参数，特别是在 kNN 分类器中的距离度量。如果你想尝试一下，请参阅 `TSLEARN_VALID_METRICS` 获取 tslearn
    支持的度量标准的完整列表。
- en: Let's do a few forecasts of COVID cases. In the next section, we'll start with
    the Silverkite algorithm. Silverkite comes with the Greykite library released
    by LinkedIn in 2021\.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们预测一些 COVID 案例。在下一节中，我们将从 Silverkite 算法开始。Silverkite 是 LinkedIn 在 2021 年发布的
    Greykite 库的一部分。
- en: Silverkite
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Silverkite
- en: At the time of writing, Greykite is in version 0.1.1 – it's not fully stable
    yet. Its dependencies might conflict with newer versions of commonly used libraries,
    including Jupyter Notebooks. Do not worry though if you install the library in
    your virtual environment or on Google Colab.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在写作时，Greykite的版本为0.1.1——它尚未完全稳定。它的依赖项可能与一些常用库的较新版本发生冲突，包括Jupyter Notebooks。不过，如果你在虚拟环境或Google
    Colab中安装该库，不必担心。
- en: 'Just go ahead and install the library with all its dependencies:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 只需安装该库及其所有依赖项：
- en: '[PRE8]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now that Greykite is installed, we can use it.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在Greykite已经安装好了，我们可以使用它了。
- en: 'We''ll load up the COVID cases from the *Our World in Data* dataset, probably
    one of the best sources of available COVID data:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将加载来自*Our World in Data*数据集的COVID病例数据，它可能是可用COVID数据中最好的来源之一：
- en: '[PRE9]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We are concentrating on cases in France.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们专注于法国的病例。
- en: 'We start by setting up the Greykite metadata parameters. We''ll then pass this
    object into the forecaster configuration:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先设置Greykite的元数据参数。然后，我们将此对象传递给预测器配置：
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Our time column is `date` and our value column is `new_cases`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的时间列是`date`，值列是`new_cases`。
- en: 'We''ll now create the `forecaster` object, which creates forecasts and stores
    the result:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将创建`forecaster`对象，它用于生成预测并存储结果：
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The forecast horizon is 90 days; we will forecast 90 days ahead. Our prediction
    interval is 95%. Both Silverkite and Prophet support quantifying uncertainty by
    means of prediction intervals. A coverage of 95% means that 95% of actuals should
    fall within the prediction interval. In Greykite, the _`components.uncertainty`
    model provides additional configuration options about uncertainty.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 预测的时间跨度为90天；我们将预测未来90天。我们的预测区间为95%。Silverkite和Prophet都支持通过预测区间来量化不确定性。95%的覆盖率意味着95%的实际值应该落在预测区间内。在Greykite中，_`components.uncertainty`模型提供了关于不确定性的额外配置选项。
- en: I've added a line to ignore warnings of the `UserWarning` type during training
    since otherwise, there are about 500 lines of warnings about 0s in the target
    column.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经添加了一行代码，在训练过程中忽略`UserWarning`类型的警告，否则会有大约500行关于目标列中0值的警告。
- en: 'Let''s plot the original time-series from the result object. We can overlay
    our forecasts:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从结果对象中绘制原始时间序列图，我们可以将预测结果叠加在其上：
- en: '[PRE12]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Please leave out the `renderer` argument if you are not on Google Colab!
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不是在Google Colab中，请不要使用`renderer`参数！
- en: 'We get the following plot:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了以下图表：
- en: '![](img/B17577_07_04.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17577_07_04.png)'
- en: 'Figure 7.4: Forecast versus actual time-series (Silverkite)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4：预测与实际时间序列（Silverkite）
- en: 'The forecasts are in the `df` attribute of the `forecast` object:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 预测结果存储在`forecast`对象的`df`属性中：
- en: '[PRE13]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'These are the upper and lower confidence intervals of the forecasts:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是预测结果的上限和下限置信区间：
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_wsZ8St/Screenshot
    2021-08-30 at 21.25.06.png](img/B17577_07_05.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_wsZ8St/Screenshot
    2021-08-30 at 21.25.06.png](img/B17577_07_05.png)'
- en: 'Figure 7.5: Table of forecast versus actual time-series (Silverkite)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5：预测与实际时间序列的表格（Silverkite）
- en: 'We might want to get some performance metrics for our model. We can get the
    performance of the historical forecast on the holdout test set like this:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能需要获取一些关于模型的性能指标。我们可以像这样获取历史预测在保留测试集上的性能：
- en: '[PRE14]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Our performance metrics look like this:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的性能指标如下所示：
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_UgQpeb/Screenshot
    2021-08-30 at 21.28.22.png](img/B17577_07_06.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_UgQpeb/Screenshot
    2021-08-30 at 21.28.22.png](img/B17577_07_06.png)'
- en: 'Figure 7.6: Performance metrics on the hold-out data (Silverkite)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6：在保留数据上的性能指标（Silverkite）
- en: I've truncated the metrics to the first five.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我已将指标缩减为前五个。
- en: 'We can apply our model conveniently to new data like this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以方便地将模型应用到新的数据上，方法如下：
- en: '[PRE15]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The predictions look like this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 预测结果如下所示：
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_LxjFCi/Screenshot
    2021-08-30 at 21.31.08.png](img/B17577_07_07.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_LxjFCi/Screenshot
    2021-08-30 at 21.31.08.png](img/B17577_07_07.png)'
- en: 'Figure 7.7: Forecast DataFrame (Silverkite)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7：预测数据框（Silverkite）
- en: Please note that your result might vary.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您的结果可能会有所不同。
- en: We can use other forecaster models by changing the `model_template` argument
    in the run configuration of the forecaster. For instance, we could set it to `ModelTemplateEnum.PROPHET.name`
    in order to take Facebook's Prophet model.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 通过更改预测器运行配置中的`model_template`参数，我们可以使用其他预测模型。例如，我们可以将其设置为`ModelTemplateEnum.PROPHET.name`，以使用Facebook的Prophet模型。
- en: This concludes our tour of Silverkite. Next, we will forecast by applying a
    supervised regression method with XGBoost. Let's do some gradient boosting!
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们对Silverkite的介绍。接下来，我们将通过应用XGBoost的监督回归方法进行预测。让我们进行一些梯度提升吧！
- en: Gradient boosting
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 梯度提升
- en: We can use supervised machine learning for time-series forecasting as well.
    For this, we can use the dates and the previous values to predict the future.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用监督式机器学习进行时间序列预测。为此，我们可以使用日期和前期值来预测未来。
- en: 'First, we need to install XGBoost:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要安装XGBoost：
- en: '[PRE16]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We'll use the Yahoo daily closing data in this example, as in other practice
    sections of this chapter.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用Yahoo的每日收盘数据，和本章其他实践部分一样。
- en: Let's go through the preparation and modeling step by step.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步地通过准备和建模过程。
- en: We first need to featurize the data. Here, we'll do this by extracting date
    features, but please see the section on kNNs, where TSFresh's feature extraction
    is used instead. You might want to change this example by combining the two feature
    extraction strategies or by relying on TSFresh entirely.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要对数据进行特征化。这里，我们通过提取日期特征来做到这一点，但请参见kNN部分，在那里我们使用了TSFresh的特征提取。你也许想通过结合这两种特征提取策略，或完全依赖TSFresh，来改变这个示例。
- en: 'We will reload the new COVID cases from the *Our World in Data* dataset as
    before:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将像之前一样重新加载来自*Our World in Data*数据集的COVID新病例数据：
- en: '[PRE17]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'For feature extraction, transformers are handy. A transformer is basically
    a class with `fit()` and `transform()` methods that can make the transformer adapt
    to a dataset and transform the data accordingly. Here''s the code for the `DateFeatures`
    transformer that annotates a dataset according to a date:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特征提取，转换器非常方便。转换器基本上是一个类，包含`fit()`和`transform()`方法，可以使转换器适应数据集并相应地转换数据。以下是用于根据日期注释数据集的`DateFeatures`转换器的代码：
- en: '[PRE18]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This transformer is relatively simple in that it extracts a range of features
    for a date column such as hours, years, days, weekday, months, week of year, and
    quarter. These features can potentially be very powerful for describing or annotating
    the time-series data in a machine learning context.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这个转换器相对简单，它为日期列提取一系列特征，例如小时、年份、日期、星期几、月份、年度周数和季度。这些特征在机器学习上下文中，可能对描述或注释时间序列数据非常有用。
- en: You can find the complete code for this example on GitHub. I am providing an
    additional transformer for cyclical features there that are omitted from this
    chapter.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在GitHub上找到这个示例的完整代码。我提供了一个额外的转换器，用于处理章节中未涉及的周期性特征。
- en: 'We apply the transformers as follows to the `date` column of the DataFrame:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按如下方式应用转换器到DataFrame的`date`列：
- en: '[PRE19]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `remainder="passthrough"` argument is set in case we want to provide additional
    exogenous features for prediction.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望为预测提供额外的外生特征，可以设置`remainder="passthrough"`参数。
- en: 'We can define a pipeline of these preprocessing steps together with a model
    so that it can be fitted and applied to prediction:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以定义一个包含这些预处理步骤和模型的管道，这样就可以进行拟合并应用于预测：
- en: '[PRE20]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The predictor is an XGBoost regressor. I didn't make much of an effort in terms
    of tweaking. The only parameter that we'll change is the number of estimators.
    We'll use an ensemble size (number of trees) of 1,000\.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 预测器是一个XGBoost回归器。我在调整方面并没有做太多工作。唯一会改变的参数是估计器的数量。我们将使用1,000个树的集成大小（即树的数量）。
- en: 'Now it''s time to split the dataset into training and test sets. This includes
    two issues:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候将数据集拆分为训练集和测试集了。这包括两个问题：
- en: We need to align the features with values ahead of time
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要提前对特征和数值进行对齐
- en: We need to split the dataset into two by a cutoff time
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要根据截止时间将数据集拆分为两部分
- en: 'Let''s first set the basic parameters for this. First, we want to predict into
    the future given a time horizon. Second, we need to decide how many data points
    we use for training and for testing:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 首先设定基本参数。首先，我们希望基于时间范围预测未来。其次，我们需要决定用于训练和测试的数据点数量：
- en: '[PRE21]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We take 90% of points for training, and we predict 90 days into the future:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用90%的数据进行训练，并预测未来90天的情况：
- en: '[PRE22]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This does both the alignment and horizon. Therefore, we have the datasets for
    testing and training, both with features and labels that we want to predict with
    XGBoost.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这既进行了对齐，也设定了预测范围。因此，我们有了用于测试和训练的数据集，两个数据集都包含了我们希望用XGBoost预测的特征和标签。
- en: Now we can train our XGBoost regression model to predict values within our HORIZON
    into the future based on the features we produced with our transformer and the
    current values.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以训练我们的XGBoost回归模型，根据我们通过转换器生成的特征和当前值，预测未来HORIZON内的值。
- en: 'We can fit our pipeline as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按如下方式拟合我们的管道：
- en: '[PRE23]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can see the following pipeline parameters:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到以下管道参数：
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_VPuhp5/Screenshot
    2021-08-30 at 23.08.52.png](img/B17577_07_08.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_VPuhp5/Screenshot
    2021-08-30 at 23.08.52.png](img/B17577_07_08.png)'
- en: 'Figure 7.8: Pipeline parameters'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8：管道参数
- en: 'If we create a series of the dates from beginning to end, we can get the predictions
    of the model for the whole time period:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从开始到结束创建一个日期系列，我们可以获得整个时间段内模型的预测：
- en: '[PRE24]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `predict()` method of the pipeline applied to `X_test` gives us the forecast:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 应用于`X_test`的管道的`predict()`方法为我们提供了预测结果：
- en: '[PRE25]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can do the same for the actual cases:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以对实际病例做同样的操作：
- en: '[PRE26]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, we can contrast the forecast with the actual values, `y_test`, in a plot:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过图表将预测结果与实际值`y_test`进行对比：
- en: '[PRE27]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This is the plot we are getting:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们得到的图表：
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_Vnji3v/Screenshot
    2021-08-30 at 23.29.17.png](img/B17577_07_09.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_Vnji3v/Screenshot
    2021-08-30 at 23.29.17.png](img/B17577_07_09.png)'
- en: 'Figure 7.9: Forecast versus actual (XGBoost)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9：预测与实际值对比（XGBoost）
- en: 'We can extract performance metrics over the test period like this:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下方式提取测试期间的性能指标：
- en: '[PRE28]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We should be seeing something like this:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该看到类似这样的结果：
- en: '[PRE29]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Next, we'll create an ensemble model for time-series forecasting in Kats.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在Kats中创建一个用于时间序列预测的集成模型。
- en: Ensembles with Kats
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kats的集成方法
- en: 'The Kats installation should be very easy in two steps. First, we install fbprophet,
    an old version of Facebook''s Prophet library:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Kats的安装应该很简单，只需两个步骤。首先，我们安装Facebook的Prophet库的旧版本fbprophet：
- en: '[PRE30]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now we install Kats with pip:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用pip安装Kats：
- en: '[PRE31]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Alternatively, on Colab, we can install Kats like this:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，在Colab上，我们可以这样安装Kats：
- en: '[PRE32]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We''ll load the COVID cases dataset as before. Here''s just the last line:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将像之前一样加载COVID病例数据集。这里只展示最后一行：
- en: '[PRE33]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We'll configure our ensemble model, fit it, and then do a forecast.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将配置集成模型，拟合它，然后进行预测。
- en: 'First, the configuration of our ensemble:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 首先是我们的集成模型的配置：
- en: '[PRE34]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Here, we include only two different models, but we could have included other
    and more models, and we could have defined better parameters. This is an example
    only; for a more realistic exercise, which I leave to the reader, I'd suggest
    adding ARIMA and Theta models. We need to define hyperparameters for each forecasting
    model.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们只包括了两种不同的模型，但我们本可以加入更多模型，也可以定义更好的参数。这只是一个示例；对于更现实的练习（我留给读者自己做），我建议加入ARIMA和Theta模型。我们需要为每个预测模型定义超参数。
- en: 'We also need to create ensemble parameters that define how the ensemble aggregate
    is to be calculated and how the decomposition should work:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要创建集成参数，定义如何计算集成聚合以及如何进行分解：
- en: '[PRE35]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'To use a time-series with Kats, we have to convert our data from a DataFrame
    or series to a Kats time-series object. We can convert our COVID case data as
    follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Kats中使用时间序列，我们必须将数据从DataFrame或系列转换为Kats时间序列对象。我们可以如下转换我们的COVID病例数据：
- en: '[PRE36]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: What is important for the conversion is the fact that Kats can infer the frequency
    of the index. This can be tested with `pd.infer_freq()`. In our case, `pd.infer_freq(df["date"])`
    should return `D` for daily frequency.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 转换的关键是Kats能够推断索引的频率。这可以通过`pd.infer_freq()`进行测试。在我们的案例中，`pd.infer_freq(df["date"])`应返回`D`，表示日频率。
- en: 'Now we can create our `KatsEnsemble` and fit it:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建我们的`KatsEnsemble`并进行拟合：
- en: '[PRE37]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We can get separate predictions for each model using the `predict()` method.
    If we want to get the ensemble output, we have to call `aggregate()` after `predict()`:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`predict()`方法为每个模型获取单独的预测。如果我们想要获取集成输出，必须在`predict()`之后调用`aggregate()`：
- en: '[PRE38]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We predict 90 days ahead. These predictions are stored as part of the model,
    so we don't need to capture the returned forecast. We can then aggregate the forecast
    from each model. Again, we don't need to get the returned DataFrame because this
    is stored inside the model object (`m.fcst_df`).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们预测了 90 天的未来。这些预测结果作为模型的一部分被存储，因此我们不需要捕捉返回的预测结果。然后，我们可以将每个模型的预测结果进行聚合。再次说明，我们不需要获取返回的
    DataFrame，因为它已经存储在模型对象内部（`m.fcst_df`）。
- en: 'In the end, we plot the aggregated DataFrame using a Kats convenience function:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们使用 Kats 的便捷函数绘制了聚合后的 DataFrame：
- en: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_Ou1y0x/Screenshot
    2021-08-30 at 23.38.36.png](img/B17577_07_10.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![/var/folders/80/g9sqgdws2rn0yc3rd5y3nd340000gp/T/TemporaryItems/NSIRD_screencaptureui_Ou1y0x/Screenshot
    2021-08-30 at 23.38.36.png](img/B17577_07_10.png)'
- en: 'Figure 7.10: Kats ensemble model forecast'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10：Kats 集成模型预测
- en: Since we can tweak this ensemble model by changing the base model parameter
    and adding new models, this can give us lots of room for improvement.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们可以通过更改基础模型参数和添加新模型来调整这个集成模型，因此它为我们提供了大量的改进空间。
- en: It's time to conclude this chapter with a summary of what we've learned.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候总结一下本章我们所学到的内容了。
- en: Summary
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we''ve discussed popular time-series machine learning libraries
    in Python. We then discussed and tried out a k-nearest neighbor algorithm with
    dynamic time warping for the classification of robotic failures. We talked about
    validation in time-series forecasting and we tried three different methods for
    forecasting COVID cases: Silverkite, Gradient Boosting with XGBoost, and ensemble models
    in Kats.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们讨论了 Python 中流行的时间序列机器学习库。接着，我们讨论并尝试了带有动态时间规整的 k 最近邻算法，用于机器故障分类。我们还谈到了时间序列预测中的验证，并尝试了三种不同的方法来预测
    COVID-19 疫情：Silverkite、XGBoost 梯度提升以及 Kats 中的集成模型。
