- en: 3\. Supervised Learning – Key Steps
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 监督学习 – 关键步骤
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, you will learn about key concepts for solving a supervised
    learning data problem. Starting from splitting the dataset to effectively create
    unbiased models that perform well on unseen data, you will learn how to measure
    the performance of the model in order to analyze it and take the necessary actions
    to improve it. By the end of this chapter, you will have a firm understanding
    of how to split a dataset, measure a model's performance, and perform error analysis.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍解决监督学习数据问题的关键概念。从数据集拆分开始，如何有效地创建不偏倚的模型，使其在未见数据上表现良好，你将学会如何衡量模型的性能，以便进行分析并采取必要的措施来改善模型。到本章结束时，你将牢固掌握如何拆分数据集、衡量模型性能和执行错误分析。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the preceding chapter, we saw how to solve data problems using unsupervised
    learning algorithms and applied the concepts that we learned about to a real-life
    dataset. We also learned how to compare the performance of various algorithms
    and studied two different metrics for performance evaluation.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们学习了如何使用无监督学习算法解决数据问题，并将所学的概念应用于真实数据集。我们还学习了如何比较不同算法的性能，并研究了两种性能评估指标。
- en: In this chapter, we will explore the main steps for working on a supervised
    machine learning problem. First, this chapter explains the different sets in which
    data needs to be split for training, validating, and testing your model. Next,
    the most common evaluation metrics will be explained. It is important to highlight
    that, among all the metrics available, only one should be selected as the evaluation
    metric of the study, and its selection should be made by considering the purpose
    of the study. Finally, we will learn how to perform error analysis, with the purpose
    of understanding what measures to take to improve the results of a model.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨解决监督学习问题的主要步骤。首先，本章将解释如何将数据拆分为训练集、验证集和测试集，以便对模型进行训练、验证和测试。接着，将解释最常见的评估指标。需要特别强调的是，在所有可用的评估指标中，应该仅选择一个作为研究的评估指标，并且其选择应基于研究的目的。最后，我们将学习如何进行错误分析，旨在了解采取何种措施来提高模型的结果。
- en: The previous concepts apply to both classification and regression tasks, where
    the former refers to problems where the output corresponds to a finite number
    of labels, while the latter deals with a continuous output number. For instance,
    a model that's created to determine whether a person will attend a meeting falls
    within the classification tasks group. On the other hand, a model that predicts
    the price of a product is solving a regression task.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 前述概念适用于分类任务和回归任务，前者指的是输出对应有限数量标签的问题，而后者处理连续输出的数值。例如，一个用来判断某人是否会参加会议的模型属于分类任务组。另一方面，一个预测产品价格的模型则是在解决回归任务。
- en: Supervised Learning Tasks
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习任务
- en: 'Differing from unsupervised learning algorithms, supervised learning algorithms
    are characterized by their ability to find relationships between a set of features
    and a target value (be it discrete or continuous). Supervised learning can solve
    two types of tasks:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 与无监督学习算法不同，监督学习算法的特点是能够找到一组特征与目标值之间的关系（无论目标值是离散的还是连续的）。监督学习可以解决两种类型的任务：
- en: '**Classification**: The objective of these tasks is to approximate a function
    that maps a set of features to a discrete set of outcomes. These outcomes are
    commonly known as class labels or categories. Each observation in the dataset
    should have a class label associated with it to be able to train a model that
    is capable of predicting such an outcome for future data.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：这些任务的目标是逼近一个函数，将一组特征映射到一个离散的结果集。这些结果通常称为类标签或类别。数据集中的每个观察值都应与一个类标签相关联，才能训练出能够为未来数据预测此类结果的模型。'
- en: An example of a classification task is one that uses demographical data to determine
    someone's marital status.
  id: totrans-10
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个分类任务的例子是使用人口统计数据来判断某人的婚姻状况。
- en: '**Regression**: Although in regression tasks a function is also created to
    map a relationship between some inputs and some targets, in regression tasks,
    the outcome is continuous. This means that the outcome is a real value that can
    be an integer or a float.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**：虽然在回归任务中也会创建一个函数来映射某些输入和某些目标之间的关系，但在回归任务中，结果是连续的。这意味着结果是一个实数值，可以是整数或浮动值。'
- en: An example of a regression task is using the different characteristics of a
    product to predict its price.
  id: totrans-12
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 回归任务的一个例子是使用产品的不同特征来预测其价格。
- en: Although many algorithms can be adapted to solve both of these tasks, it is
    important to highlight that there are some algorithms that don't, which is why
    it is important to know the task that we want to perform in order to choose the
    algorithm accordingly.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多算法可以被调整以解决这两项任务，但重要的是要强调，还是有些算法不能解决这两项任务，这就是为什么了解我们想要执行的任务是非常重要的，以便根据任务选择相应的算法。
- en: Next, we will explore several topics that are crucial for performing any supervised
    learning task.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨一些对于执行任何监督学习任务至关重要的主题。
- en: Model Validation and Testing
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型验证与测试
- en: With all the information now available online, it is easy for almost anybody
    to start working on a machine learning project. However, choosing the right algorithm
    for your data is a challenge when there are many options available. Due to this,
    the decision to use one algorithm over another is achieved through trial and error,
    where different alternatives are tested.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 随着现在网上有了大量信息，几乎任何人都可以轻松开始一个机器学习项目。然而，当有许多选项可供选择时，为你的数据选择合适的算法是一项挑战。正因如此，选择一个算法而非另一个算法的决策是通过反复试验实现的，其中会测试不同的替代方案。
- en: Moreover, the decision process to arrive at a good model covers not only the
    selection of the algorithm but also the tuning of its hyperparameters. To do this,
    a conventional approach is to divide the data into three parts (training, validation,
    and testing sets), which will be explained further in the next section.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，做出一个优秀模型的决策过程不仅包括选择算法，还包括调整其超参数。为此，传统的方法是将数据划分为三部分（训练集、验证集和测试集），接下来会进一步解释。
- en: Data Partitioning
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据划分
- en: '**Data partitioning** is a process involving dividing a dataset into three
    subsets so that each set can be used for a different purpose. This way, the development
    of a model is not affected by the introduction of bias. The following is an explanation
    of each subset:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据划分**是一个过程，涉及将数据集划分为三个子集，以便每个子集可用于不同的目的。通过这种方式，模型的开发不受引入偏差的影响。以下是每个子集的解释：'
- en: '**Training set**: As the name suggests, this is the portion of the dataset
    that''s used for training the model. It consists of the input data (the observations)
    paired with an outcome (the label class). This set can be used to train as many
    models as desired, using different algorithms. However, performance evaluation
    is not done on this set because, since this set was used to train the model, the
    measure would be biased.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练集**：顾名思义，这是用于训练模型的数据集部分。它由输入数据（观察值）与结果（标签类别）配对组成。这个集合可以用来训练任意数量的模型，使用不同的算法。然而，性能评估不会在此数据集上进行，因为由于该数据集用于训练模型，因此评估会有偏差。'
- en: '**Validation set**: Also known as the dev set, this set is used to perform
    an unbiased evaluation of each model while fine-tuning the hyperparameters. Performance
    evaluation is frequently done on this set of data to test different configurations
    of the hyperparameters.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证集**：也称为开发集，这个集合用于在微调超参数时对每个模型进行公正的评估。性能评估通常在这个数据集上进行，以测试不同的超参数配置。'
- en: Although the model does not learn from this data (it learns from the training
    set data), it is indirectly affected by the data in this set due to its participation
    in the process of deciding the changes to the hyperparameters.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尽管模型不会从这些数据中学习（它从训练集数据中学习），但由于它参与了决定超参数变化的过程，因此间接地受到了这个数据集的影响。
- en: After running different configurations of hyperparameters based on the performance
    of the model on the validation set, a winning model is selected for each algorithm.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在基于模型在验证集上的表现运行不同的超参数配置后，将为每个算法选择一个最优模型。
- en: '**Testing set**: This is used to perform the final evaluation of the model''s
    performance (after training and validation) on unseen data. This helps measure
    the performance of the model with real-life data for future predictions.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试集**：用于在模型训练和验证后对未见数据进行最终评估。这有助于衡量模型在现实数据中的表现，为未来的预测提供参考。'
- en: The testing set is also used to compare competing models. Considering that the
    training set was used to train different models and the validation set was used
    to fine-tune the hyperparameters of each model to select a winning configuration,
    the purpose of the testing set is to perform an unbiased comparison of the final models.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测试集也用于比较不同的模型。考虑到训练集用于训练不同的模型，而验证集用于微调每个模型的超参数并选择最佳配置，测试集的目的是对最终模型进行无偏比较。
- en: 'The following diagram shows the process of selecting the ideal model and using
    the sets mentioned previously:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了选择理想模型并使用前述数据集的过程：
- en: '![Figure 3.1: Dataset partition purposes'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.1：数据集划分目的'
- en: '](img/B15781_03_01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_03_01.jpg)'
- en: 'Figure 3.1: Dataset partition purposes'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：数据集划分目的
- en: 'The sections `A`–`D` shown in the preceding diagram are described as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 前面图示中显示的`A`–`D`部分描述如下：
- en: Section `A` refers to the process of training the model for the desired algorithms
    using the data contained in the training set.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Section `A`指的是使用训练集中包含的数据训练所需算法的过程。
- en: Section `B` represents the fine-tuning process of the hyperparameters of each
    model. The selection of the best configuration of hyperparameters is based on
    the performance of the model on the validation set.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Section `B`表示每个模型超参数的微调过程。最佳超参数配置的选择基于模型在验证集上的表现。
- en: Section `C` shows the process of selecting the final model by comparing the
    final configuration of each algorithm based on its performance on the testing
    set.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Section `C`展示了通过比较每个算法在测试集上的表现，选择最终模型的过程。
- en: Finally, section `D` represents the selected model that will be applied to real-life
    data for prediction.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，Section `D`表示选定的模型，它将应用于实际数据进行预测。
- en: 'Initially, machine learning problems were solved by only partitioning data
    into two sets: a training and a testing set. This approach consisted of using
    the training set to train the model, which is the same as the approach with three
    sets. However, the testing set was used for fine-tuning the hyperparameters as
    well as for determining the ultimate performance of the algorithm.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，机器学习问题通过将数据划分为两部分来解决：训练集和测试集。这种方法与三部分数据集的方法相似，但测试集既用于微调超参数，也用于确定算法的最终性能。
- en: Although this approach can also work, models that are created using this approach
    do not always perform equally well on unseen real-life data. This is mainly because,
    as mentioned previously, the use of the sets to fine-tune the hyperparameters
    indirectly introduces bias into the model.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种方法也能奏效，但使用这种方法创建的模型并不总是在未见过的实际数据上表现同样优秀。这主要是因为，如前所述，使用这些数据集来微调超参数间接地将偏差引入了模型中。
- en: Considering this, there is one way to achieve a less biased model while dividing
    the dataset into two sets, which is called a **cross-validation split**. We will
    explore this in the *Cross-Validation* section of this chapter.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，有一种方法可以在将数据集划分为两部分时实现更少偏差的模型，这就是所谓的**交叉验证划分**。我们将在本章的*交叉验证*部分深入探讨这一点。
- en: Split Ratio
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 划分比例
- en: 'Now that the purposes of the various sets are clear, it is important to clarify
    the split ratio in which data needs to be divided. Although there is no exact
    science for calculating the split ratio, there are a couple of things to consider
    when doing so:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 既然各种数据集的目的已经明确，接下来需要澄清数据划分的比例。虽然没有一种精确的科学方法来计算划分比例，但在进行划分时需要考虑以下几个因素：
- en: '**Size of the dataset**: Previously, when data was not easily available, datasets
    contained between 100 and 100,000 instances, and the conventionally accepted split
    ratio was 60/20/20% for the training, validation, and testing sets, respectively.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集的大小**：以前，由于数据不容易获取，数据集通常包含100到100,000个实例，公认的划分比例通常是60/20/20%，分别用于训练集、验证集和测试集。'
- en: With software and hardware improving every day, researchers can put together
    datasets that contain over a million instances. This capacity to gather huge amounts
    of data allows the split ratio to be 98/1/1%, respectively. This is mainly because
    the larger the dataset, the more data can be used for training a model, without
    compromising the amount of data left for the validation and testing sets.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随着软件和硬件的不断改进，研究人员能够构建包含超过百万个实例的数据集。能够收集如此庞大的数据量使得分割比例可以达到98/1/1%。这主要是因为数据集越大，能够用于训练模型的数据就越多，而不会影响留给验证集和测试集的数据量。
- en: '**The algorithm**: It is important to consider that some algorithms may require
    higher amounts of data to train a model, as is the case with neural networks.
    In this case, as with the preceding approaches, you should always opt for a larger
    training set.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**算法**：需要考虑的是，一些算法可能需要更多的数据来训练模型，例如神经网络。在这种情况下，像前述方法一样，应该始终选择更大的训练集。'
- en: On the other hand, some algorithms do not require the validation and testing
    sets to be split equally. For instance, a model with fewer hyperparameters can
    be easily tuned, which allows the validation set to be smaller than the testing
    set. However, if a model has many hyperparameters, you will need to have a larger
    validation set.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另一方面，一些算法不要求验证集和测试集必须平分。例如，一个具有较少超参数的模型可以容易地进行调整，这使得验证集可以小于测试集。然而，如果一个模型有许多超参数，则需要更大的验证集。
- en: Nevertheless, even though the preceding measures serve as a guide for splitting
    the dataset, it is always important to consider the distribution of your dataset
    and the purpose of the study. For instance, a model that is going to be used to
    predict an outcome on data with a different distribution than the one used to
    train the model, the real-life data, even if limited, must at least be a part
    of the testing set to make sure that the model will work for the desired purpose.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管前述措施可以作为划分数据集的指南，始终需要考虑数据集的分布以及研究的目的。例如，若一个模型将用于预测与训练模型时使用的数据分布不同的结果，尽管实际数据有限，至少也必须确保实际数据的一部分包含在测试集中，以确保该模型能达到预期目的。
- en: 'The following diagram displays the proportional partition of the dataset into
    three subsets. It is important to highlight that the training set must be larger
    than the other two, as it is the one to be used for training the model. Additionally,
    it is possible to observe that both the training and validation sets have an effect
    on the model, while the testing set is mainly used to validate the actual performance
    of the model with unseen data. Considering this, the training and validation sets
    must come from the same distribution:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了数据集按比例划分为三子集。需要特别指出的是，训练集必须大于其他两个子集，因为它是用于训练模型的。此外，可以观察到，训练集和验证集都会对模型产生影响，而测试集主要用于验证模型在未知数据上的实际表现。考虑到这一点，训练集和验证集必须来自相同的分布：
- en: '![Figure 3.2: Visualization of the split ratio'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.2：分割比例可视化'
- en: '](img/B15781_03_02.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_03_02.jpg)'
- en: 'Figure 3.2: Visualization of the split ratio'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：分割比例可视化
- en: 'Exercise 3.01: Performing a Data Partition on a Sample Dataset'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.01：对样本数据集进行数据划分
- en: 'In this exercise, we will be performing a data partition on the `wine` dataset
    using the split ratio method. The partition in this exercise will be done using
    the three-splits approach. Follow these steps to complete this exercise:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将使用分割比例法对`wine`数据集进行数据划分。此次练习的划分将采用三分法。按照以下步骤完成本次练习：
- en: Note
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: For the exercises and activities within this chapter, you will need to have
    Python 3.7, NumPy, Jupyter, Pandas, and scikit-learn installed on your system.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章的练习和活动，您需要在系统上安装Python 3.7、NumPy、Jupyter、Pandas和scikit-learn。
- en: 'Open a Jupyter Notebook to implement this exercise. Import the required elements,
    as well as the `load_wine` function from scikit-learn''s `datasets` package:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter Notebook以实现本次练习。导入所需的元素，以及scikit-learn的`datasets`包中的`load_wine`函数：
- en: '[PRE0]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The first line imports the function that will be used to load the dataset from
    scikit-learn. Next, `pandas` library is imported. Finally, the `train_test_split`
    function is imported, which will be in charge of partitioning the dataset. The
    function partitions the data into two subsets (a train and a test set). As the
    objective of this exercise is to partition data into three subsets, the function
    will be used twice to achieve the desired result.
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一行导入了将用于从 scikit-learn 加载数据集的函数。接下来，导入了 `pandas` 库。最后，导入了 `train_test_split`
    函数，它负责划分数据集。该函数将数据划分为两个子集（训练集和测试集）。由于本练习的目标是将数据划分为三个子集，因此该函数将被使用两次，以实现所需的结果。
- en: 'Load the `wine` toy dataset and store it in a variable named `data`. Use the
    following code snippet to do so:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载 `wine` 玩具数据集并将其存储在一个名为 `data` 的变量中。使用以下代码片段进行此操作：
- en: '[PRE1]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `load_wine` function loads the toy dataset provided by scikit-learn.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`load_wine` 函数加载的是 scikit-learn 提供的玩具数据集。'
- en: Note
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: 'To check the characteristics of the dataset, visit the following link: [https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html).'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要查看数据集的特征，请访问以下链接：[https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html)。
- en: The output from the preceding function is a dictionary-like object, which separates
    the features (callable as data) from the target (callable as target) into two
    attributes.
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面函数的输出是一个类似字典的对象，将特征（可以作为数据调用）与目标（可以作为目标调用）分为两个属性。
- en: 'Convert each attribute (data and target) into a Pandas DataFrame to facilitate
    data manipulation. Print the shape of both DataFrames:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个属性（数据和目标）转换为 Pandas DataFrame，以便进行数据操作。打印两个 DataFrame 的形状：
- en: '[PRE2]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output from the `print` function should be as follows:'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`print` 函数的输出应如下所示：'
- en: '[PRE3]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here, the values in the first parenthesis represent the shape of DataFrame `X`
    (known as the features matrix), while the values in the second parenthesis refer
    to the shape of DataFrame `Y` (known as the target matrix).
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，第一个括号中的值表示数据框 `X`（即特征矩阵）的形状，而第二个括号中的值表示数据框 `Y`（即目标矩阵）的形状。
- en: 'Perform your first split of the data using the `train_test_split` function.
    Use the following code snippet to do so:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `train_test_split` 函数进行数据的首次拆分。使用以下代码片段进行此操作：
- en: '[PRE4]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The inputs of the `train_test_split` function are the two matrices `(X,Y)` and
    the size of the test set, as a value between 0 and 1, which represents the proportion.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`train_test_split` 函数的输入是两个矩阵 `(X,Y)` 和测试集的大小，作为一个 0 到 1 之间的值，表示比例。'
- en: '[PRE5]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'By printing the shape of all four matrices, as per the preceding code snippet,
    it is possible to confirm that the size of the test subset (both `X` and `Y`)
    is 20% of the total size of the original dataset (150 * 0.2 = 35.6) rounded to
    an integer, while the size of the train set is the remaining 80%:'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过打印所有四个矩阵的形状，按照前面的代码片段，可以确认测试子集的大小（`X` 和 `Y`）是原始数据集总大小的 20%（150 * 0.2 = 35.6），四舍五入为整数，而训练集的大小是剩余的
    80%：
- en: '[PRE6]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To create a validation set (dev set), we will use the `train_test_split` function
    to divide the train sets we obtained in the previous step. However, to obtain
    a dev set that''s the same shape as the test set, it is necessary to calculate
    the proportion of the size of the test set over the size of the train set before
    creating a validation set. This value will be used as the `test_size` for the
    next step:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了创建验证集（dev 集），我们将使用 `train_test_split` 函数来拆分我们在前一步中获得的训练集。然而，为了得到与测试集相同形状的验证集，在创建验证集之前，需要计算测试集大小与训练集大小的比例。此比例将作为下一步的
    `test_size`：
- en: '[PRE7]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, `36` is the size of the test set we created in the previous step, while
    `142` is the size of the train set that will be further split. The result from
    this operation is around `0.25`, which can be verified using the `print` function.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，`36` 是我们在前一步中创建的测试集的大小，而 `142` 是将进一步拆分的训练集的大小。此操作的结果大约是 `0.25`，可以使用 `print`
    函数进行验证。
- en: 'Use the `train_test_split` function to divide the train set into two subsets
    (train and dev sets). Use the result from the operation in the previous step as
    the `test_size`:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `train_test_split` 函数将训练集分成两个子集（训练集和验证集）。使用前一步操作的结果作为 `test_size`：
- en: '[PRE8]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output of the `print` function is as follows:'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`print` 函数的输出如下：'
- en: '[PRE9]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2AtXAWS](https://packt.live/2AtXAWS).
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问该部分的源代码，请参阅[https://packt.live/2AtXAWS](https://packt.live/2AtXAWS)。
- en: You can also run this example online at [https://packt.live/2YECtsG](https://packt.live/2YECtsG).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你还可以在线运行这个示例，网址是[https://packt.live/2YECtsG](https://packt.live/2YECtsG)。你必须执行整个Notebook才能获得所需的结果。
- en: You have successfully split the dataset into three subsets to develop efficient
    machine learning projects. Feel free to test different split ratios.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地将数据集分成三个子集，以开发高效的机器学习项目。你可以自由地测试不同的划分比例。
- en: In conclusion, the split ratio to partition data is not fixed and should be
    decided by taking into account the amount of data available, the type of algorithm
    to be used, and the distribution of the data.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，数据划分的比例并不是固定的，应该根据可用数据的数量、要使用的算法类型以及数据的分布来决定。
- en: Cross-Validation
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉验证
- en: '**Cross-validation** is also a procedure that''s used to partition data by
    resampling the data that''s used to train and validate the model. It consists
    of a parameter, *K,* that represents the number of groups that the dataset will
    be divided into.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**交叉验证**也是一种通过重新抽样数据来划分数据的过程，这些数据用于训练和验证模型。它包含一个参数*K*，表示数据集将被划分为的组数。'
- en: 'Due to this, the procedure is also referred to as K-fold cross-validation,
    where *K* is usually replaced by a number of your choice. For instance, a model
    that''s created using a 10-fold cross-validation procedure signifies a model where
    data is divided into 10 subgroups. The procedure of cross-validation is illustrated
    in the following diagram:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此原因，该过程也称为K折交叉验证，其中*K*通常由你选择的数字代替。例如，使用10折交叉验证过程创建的模型意味着数据被分成10个子组。交叉验证过程在以下图表中进行了说明：
- en: '![Figure 3.3: Cross-validation procedure'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.3：交叉验证过程'
- en: '](img/B15781_03_03.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_03_03.jpg)'
- en: 'Figure 3.3: Cross-validation procedure'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3：交叉验证过程
- en: 'The preceding diagram displays the general procedure that''s followed during
    cross-validation:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表展示了交叉验证过程中遵循的一般步骤：
- en: Data is shuffled randomly, considering that the cross-validation process is repeated.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据会随机洗牌，考虑到交叉验证过程会被重复。
- en: Data is split into *K* subgroups.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据被划分为*K*个子组。
- en: The validation/testing set is selected as one of the subgroups that were created.
    The rest of the subgroups become the training set.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证集/测试集被选为其中一个子组，其余子组构成训练集。
- en: The model is trained on the training set, as usual. The model is evaluated using
    the validation/testing set.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型按常规在训练集上训练。模型使用验证集/测试集进行评估。
- en: The result from that iteration is saved. The parameters are tuned based on the
    results, and the process starts again by reshuffling the data. This process is
    repeated K number of times.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 来自该迭代的结果已被保存。根据结果调整参数，并通过重新洗牌数据开始新的过程。这个过程重复进行K次。
- en: According to the preceding steps, the dataset is divided into *K* sets and the
    model is trained *K* times. Each time, one set is selected as the validation set
    and the remaining sets are used for the training process.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前述步骤，数据集被分成*K*个子集，并且模型被训练*K*次。每次，选取一个子集作为验证集，剩余的子集用于训练过程。
- en: Cross-validation can be done using a three-split approach or a two-split one.
    For the former, the dataset is initially divided into training and testing sets,
    after which the training set is divided using cross-validation to create different
    configurations of training and validation sets. The latter approach, on the other
    hand, uses cross-validation on the entire dataset.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证可以通过三分法或二分法来完成。对于前者，数据集首先被分成训练集和测试集，然后使用交叉验证将训练集进一步划分，创建不同的训练集和验证集配置。后者则是在整个数据集上使用交叉验证。
- en: The popularity of cross-validation is due to its capacity to build "unbiased"
    models as it allows us to measure the performance of the algorithm on different
    segments of the dataset, which also provides us with an idea of its performance
    on unseen data. It is also popular because it allows you to build highly effective
    models out of a small dataset.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证之所以受欢迎，是因为它能够构建“无偏”的模型，因为它可以让我们衡量算法在数据集不同部分上的表现，这也让我们能了解算法在未见数据上的表现。它之所以流行，还因为它允许你在小数据集上构建高效的模型。
- en: There is no exact science to choosing the value for *K*, but it is important
    to consider that lower values for *K* tend to decrease variance and increase bias,
    while higher *K* values result in the opposite behavior. Also, the lower *K* is,
    the less expensive the processes, which results in faster running times.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 *K* 值并没有准确的科学依据，但需要考虑的是，较小的 *K* 值倾向于降低方差并增加偏差，而较大的 *K* 值则会产生相反的效果。此外，*K*
    值越小，过程的计算开销越小，从而运行时间更短。
- en: Note
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The concepts of variance and bias will be explained in the *Bias, Variance,
    and Data Mismatch* section.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 方差和偏差的概念将在*偏差、方差与数据不匹配*部分进行解释。
- en: 'Exercise 3.02: Using Cross-Validation to Partition the Train Set into a Training
    and a Validation Set'
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.02：使用交叉验证将训练集划分为训练集和验证集
- en: 'In this exercise, we will be performing a data partition on the `wine` dataset
    using the cross-validation method. Follow these steps to complete this exercise:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用交叉验证方法对 `wine` 数据集进行数据划分。按照以下步骤完成此练习：
- en: 'Open a Jupyter Notebook to implement this exercise and import all the required elements:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 Jupyter Notebook 来实现这个练习并导入所有需要的元素：
- en: '[PRE10]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The last line in the preceding code imports the `KFold` class from scikit-learn,
    which will be used to partition the dataset.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前述代码的最后一行导入了 `KFold` 类，它来自 scikit-learn，将用于划分数据集。
- en: 'Load the `wine` dataset as per the previous exercise and create the Pandas
    DataFrames containing the features and target matrices:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照之前的练习加载 `wine` 数据集，并创建包含特征和目标矩阵的 Pandas DataFrame：
- en: '[PRE11]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Split the data into training and testing sets using the `train_test_split`
    function, which you learned about in the previous exercise, using a `test_size`
    of 0.10:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `train_test_split` 函数将数据分为训练集和测试集，该函数在之前的练习中已经学习过，`test_size` 设置为 0.10：
- en: '[PRE12]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Instantiate the `KFold` class with a 10-fold configuration:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 10 折交叉验证配置实例化 `KFold` 类：
- en: '[PRE13]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Feel free to experiment with the values of `K` to see how the output shapes
    of this exercise vary.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随意尝试不同的 `K` 值，观察该练习输出的形状如何变化。
- en: 'Apply the `split` method to the data in `X`. This method will output the index
    of the instances to be used as training and validation sets. This method creates
    10 different split configurations. Save the output in a variable named `splits`:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对 `X` 中的数据应用 `split` 方法。此方法将输出用于训练和验证集的实例索引。该方法会创建 10 种不同的划分配置。将输出保存为名为 `splits`
    的变量：
- en: '[PRE14]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note that it is not necessary to run the `split` method on the data in `Y`,
    as the method only saves the index numbers, which will be the same for `X` and
    `Y`. The actual splitting is handled next.
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，不需要对 `Y` 中的数据运行 `split` 方法，因为该方法只保存索引号，这在 `X` 和 `Y` 中是相同的。实际的划分将在后续处理。
- en: 'Perform a `for` loop that will go through the different split configurations.
    In the loop body, create the variables that will hold the data for the training
    and validation sets. Use the following code snippet to do so:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行一个 `for` 循环，遍历不同的划分配置。在循环体内，创建用于存储训练集和验证集数据的变量。使用以下代码片段实现：
- en: '[PRE15]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `for` loop goes through `K` number of configurations. In the body of the
    loop, the data is split using the index numbers:'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`for` 循环会遍历 `K` 次配置。在循环体内，数据将根据索引号进行划分：'
- en: '[PRE16]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'By printing the shape of all the subsets, as per the preceding snippet, the
    output is as follows:'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过打印所有子集的形状，按照前述代码段，输出如下：
- en: '[PRE17]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The code to train and evaluate the model should be written inside the loop body,
    given that the objective of the cross-validation procedure is to train and validate
    the model using the different split configurations.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练和评估模型的代码应该写在循环体内，因为交叉验证过程的目标是使用不同的划分配置来训练和验证模型。
- en: You have successfully performed a cross-validation split on a sample dataset.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功对一个样本数据集进行了交叉验证划分。
- en: Note
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2N0lPi0](https://packt.live/2N0lPi0).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 若要访问此特定部分的源代码，请参考 [https://packt.live/2N0lPi0](https://packt.live/2N0lPi0)。
- en: You can also run this example online at [https://packt.live/2Y290tK](https://packt.live/2Y290tK).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 [https://packt.live/2Y290tK](https://packt.live/2Y290tK) 在线运行此示例。必须执行整个
    Notebook 才能获得预期结果。
- en: In conclusion, cross-validation is a procedure that's used to shuffle and split
    the data into training and validation sets so that the process of training and
    validating is done each time on a different set of data, thus achieving a model
    with low bias.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，交叉验证是一种用于对数据进行洗牌并将其拆分为训练集和验证集的过程，每次训练和验证过程都会在不同的数据集上进行，从而获得一个具有低偏差的模型。
- en: 'Activity 3.01: Data Partitioning on a Handwritten Digit Dataset'
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动3.01：手写数字数据集的数据分区
- en: 'Your company specializes in recognizing handwritten characters. It wants to
    improve the recognition of digits, which is why they have gathered a dataset of
    1,797 handwritten digits from 0 to 9\. The images have already been converted
    into their numeric representation, and so they have provided you with the dataset
    to split it into training/validation/testing sets. You can choose to either perform
    conventional splitting or cross-validation. Follow these steps to complete this
    activity:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 你的公司专注于识别手写字符。它希望提高数字的识别能力，因此他们收集了1797个从0到9的手写数字数据集。这些图像已经被转换为其数字表示，因此他们提供了该数据集供你将其拆分为训练/验证/测试集。你可以选择执行传统拆分或交叉验证。按照以下步骤完成此活动：
- en: Import all the required elements to split a dataset, as well as the `load_digits`
    function from scikit-learn to load the `digits` dataset.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入拆分数据集所需的所有元素，以及从scikit-learn中导入`load_digits`函数以加载`digits`数据集。
- en: Load the `digits` dataset and create Pandas DataFrames containing the features
    and target matrices.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载`digits`数据集并创建包含特征和目标矩阵的Pandas数据框。
- en: Take the conventional split approach, using a split ratio of 60/20/20%.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 采用传统的拆分方法，使用60/20/20%的拆分比例。
- en: Using the same DataFrames, perform a 10-fold cross-validation split.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用相同的数据框，执行10折交叉验证拆分。
- en: Note
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 228\. Feel free to try different
    parameters to arrive at different results.
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第228页找到。可以随意尝试不同的参数以得到不同的结果。
- en: Evaluation Metrics
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估指标
- en: Model evaluation is indispensable for creating effective models that not only
    perform well on the data that was used to train the model but also on unseen data.
    The task of evaluating the model is especially easy when dealing with supervised
    learning problems, where there is a ground truth that can be compared against
    the prediction of the model.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 模型评估对于创建有效模型是不可或缺的，这些模型不仅在用于训练模型的数据上表现良好，而且在未见过的数据上也能表现出色。评估模型的任务在处理监督学习问题时尤其容易，因为有一个可以与模型预测进行比较的真实值。
- en: Determining the accuracy percentage of the model is crucial for its application
    to unseen data that does not have a label class to compare to. For example, a
    model with an accuracy of 98% may allow the user to assume that the odds of having
    an accurate prediction are high, and hence the model should be trusted.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 确定模型的准确度百分比对于其应用于没有标签类的数据至关重要。例如，具有98%准确率的模型可能使用户认为预测准确的概率较高，因此应该信任该模型。
- en: The evaluation of performance, as mentioned previously, should be done on the
    validation set (dev set) to fine-tune the model, and on the test set to determine
    the expected performance of the selected model on unseen data.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，性能评估应该在验证集（开发集）上进行，以微调模型，并在测试集上进行，以确定所选模型在未见过的数据上的预期表现。
- en: Evaluation Metrics for Classification Tasks
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类任务的评估指标
- en: A classification task refers to a model where the class label is a discrete
    value, as mentioned previously. Considering this, the most common measure to evaluate
    the performance of such tasks is calculating the accuracy of the model, which
    involves comparing the actual prediction to the real value. Even though this may
    be an appropriate metric in many cases, there are several others to consider as
    well before choosing one.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 分类任务指的是类别标签为离散值的模型，正如之前提到的那样。考虑到这一点，评估此类任务性能的最常见衡量标准是计算模型的准确度，即比较实际预测值与真实值。尽管在许多情况下，这可能是一个合适的度量标准，但在选择一个之前，还需要考虑其他几种标准。
- en: Now, we will take a look at the different performance metrics.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将查看不同的性能评估指标。
- en: Confusion Matrix
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'The **confusion matrix** is a table that contains the performance of the model,
    and is described as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**混淆矩阵**是一个包含模型性能的表格，描述如下：'
- en: The columns represent the instances that belong to a predicted class.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列表示属于预测类别的实例。
- en: The rows refer to the instances that actually belong to that class (ground truth).
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行表示实际属于该类别的实例（真实情况）。
- en: 'The configuration that confusion matrices present allows the user to quickly
    spot the areas in which the model is having greater difficulty. Consider the following
    table:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵呈现的配置使得用户能够快速发现模型难度较大的领域。请看以下表格：
- en: '![Figure 3.4: A confusion matrix of a classifier that predicts whether a woman
    is pregnant'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.4：一个分类器的混淆矩阵，预测女性是否怀孕'
- en: '](img/B15781_03_04.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_03_04.jpg)'
- en: 'Figure 3.4: A confusion matrix of a classifier that predicts whether a woman
    is pregnant'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4：一个分类器的混淆矩阵，预测女性是否怀孕
- en: 'The following can be observed from the preceding table:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 从上述表格中可以观察到：
- en: By summing up the values in the first row, it is possible to know that there
    are 600 observations of pregnant women. However, from those 600 observations,
    the model predicted 556 as pregnant, and 44 as non-pregnant. Hence, the model's
    ability to predict that a woman is pregnant has a correctness level of 92.6%.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过对第一行的值求和，可以知道有600个孕妇观察值。然而，在这600个观察值中，模型预测556个为孕妇，44个为非孕妇。因此，模型预测女性怀孕的正确率为92.6%。
- en: Regarding the second row, there are also 600 observations of non-pregnant women.
    Out of those 600, the model predicted that 123 of them were pregnant, and 477
    were non-pregnant. The model successfully predicted non-pregnant women 79.5% of
    the time.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于第二行，也有600个非孕妇观察值。在这600个观察值中，模型预测123个为孕妇，477个为非孕妇。模型成功预测非孕妇的准确率为79.5%。
- en: Based on these statements, it is possible to conclude that the model performs
    at its worst when classifying observations that are not pregnant.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些陈述，可以得出结论，模型在分类非孕妇观察值时表现最差。
- en: 'Considering that the rows in a confusion matrix refer to the occurrence or
    non-occurrence of an event, and the columns refer to the model''s predictions,
    the values in the confusion matrix can be explained as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到混淆矩阵中的行表示事件的发生或未发生，列表示模型的预测，混淆矩阵中的值可以解释如下：
- en: '**True positives** (**TP**): Refers to the instances that the model correctly
    classified the event as positive—for example, the instances correctly classified
    as pregnant.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正例**（**TP**）：指模型正确将事件分类为正例的实例——例如，正确分类为孕妇的实例。'
- en: '**False positives** (**FP**): Refers to the instances that the model incorrectly
    classified the event as positive—for example, the non-pregnant instances that
    were incorrectly classified as pregnant.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假正例**（**FP**）：指模型错误地将事件分类为正例的实例——例如，错误分类为孕妇的非孕妇实例。'
- en: '**True negatives** (**TN**): Represents the instances that the model correctly
    classified the event as negative—for example, the instances correctly classified
    as non-pregnant.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真反例**（**TN**）：指模型正确将事件分类为负例的实例——例如，正确分类为非孕妇的实例。'
- en: '**False negatives** (**FN**): Refers to the instances that the model incorrectly
    classified the event as negative—for example, the pregnant instances that were
    incorrectly predicted as non-pregnant.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假反例**（**FN**）：指模型错误地将事件分类为负例的实例——例如，错误预测为非孕妇的孕妇实例。'
- en: 'The values in the confusion matrix can be demonstrated as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵中的值可以如下表示：
- en: '![Figure 3.5: A table showing confusion matrix values'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.5：显示混淆矩阵值的表格'
- en: '](img/B15781_03_05.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_03_05.jpg)'
- en: 'Figure 3.5: A table showing confusion matrix values'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5：显示混淆矩阵值的表格
- en: Accuracy
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准确率
- en: '**Accuracy**, as explained previously, measures the model''s ability to correctly
    classify all instances. Although this is considered to be one of the simplest
    ways of measuring performance, it may not always be a useful metric when the objective
    of the study is to minimize/maximize the occurrence of one class independently
    of its performance on other classes.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，**准确率**衡量模型正确分类所有实例的能力。尽管这被认为是衡量性能的最简单方法之一，但在研究的目标是最小化/最大化某一类事件的发生，而与其他类的性能无关时，它可能并不是一个有用的指标。
- en: 'The accuracy level of the confusion matrix from *Figure 3.4* is measured as
    follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3.4* 中混淆矩阵的准确率计算如下：'
- en: '![Figure 3.6: An equation showing the calculation for accuracy'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.6：显示准确率计算公式的方程式'
- en: '](img/B15781_03_06.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_03_06.jpg)'
- en: 'Figure 3.6: An equation showing the calculation for accuracy'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6：显示准确率计算公式的方程式
- en: Here, *m* is the total number of instances.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*m*是实例的总数。
- en: The `86%` accuracy refers to the overall performance of the model in classifying
    both class labels.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '`86%`的准确率指的是模型在分类两个类标签时的整体表现。'
- en: Precision
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 精确度
- en: 'This metric measures the model''s ability to correctly classify positive labels
    (the label that represents the occurrence of the event) by comparing it with the
    total number of instances predicted as positive. This is represented by the ratio
    between the *true positives* and the sum of the *true positives* and *false positives*,
    as shown in the following equation:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 该指标衡量模型正确分类正类标签（代表事件发生的标签）的能力，通过与预测为正类的实例总数进行比较。它由*真正例*和*真正例*与*假正例*的和的比例表示，如下公式所示：
- en: '![Figure 3.7: An equation showing the calculation for precision'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.7：展示精确度计算的公式'
- en: '](img/B15781_03_07.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_03_07.jpg)'
- en: 'Figure 3.7: An equation showing the calculation for precision'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7：展示精确度计算的公式
- en: The precision metric is only applicable to binary classification tasks, where
    there are only two class labels (for instance, true or false). It can also be
    applied to multiclass tasks considering that the classes are converted into two
    (for instance, predicting whether a handwritten number is a 6 or any other number),
    where one of the classes refers to the instances that have a condition while the
    other refers to those that do not.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度指标仅适用于二分类任务，其中只有两个类标签（例如，真或假）。它也可以应用于多类任务，前提是这些类被转换为两类（例如，预测手写数字是否为6或其他数字），其中一个类指的是具有某种条件的实例，另一个类则指不具有该条件的实例。
- en: For the example in *Figure 3.4*, the precision of the model is equal to 81.8%.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*图3.4*中的示例，模型的精确度为81.8%。
- en: Recall
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 召回率
- en: 'The recall metric measures the number of correctly predicted positive labels
    against all positive labels. This is represented by the ratio between *true positives*
    and the sum of *true positives* and *false negatives*:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率（recall）衡量的是正确预测为正类标签的数量与所有正类标签的比例。它由*真正例*和*假负例*的和的比例表示：
- en: '![Figure 3.8: An equation showing the calculation for recall'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.8：展示召回率计算的公式'
- en: '](img/B15781_03_08.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_03_08.jpg)'
- en: 'Figure 3.8: An equation showing the calculation for recall'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8：展示召回率计算的公式
- en: Again, this measure should be applied to two class labels. The value of recall
    for the example in *Figure 3.4* is 92.6%, which, when compared to the other two
    metrics, represents the highest performance of the model. The decision to choose
    one metric or the other will depend on the purpose of the study, which will be
    explained in more detail later.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，这一度量应应用于两个类标签。对于*图3.4*中的示例，召回率为92.6%，与其他两个指标相比，表示该模型的最高表现。选择某个指标将取决于研究的目的，稍后会更详细地解释。
- en: 'Exercise 3.03: Calculating Different Evaluation Metrics on a Classification
    Task'
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习3.03：在分类任务中计算不同的评估指标
- en: 'In this exercise, we will be using the breast cancer toy dataset to calculate
    the evaluation metrics using the scikit-learn library. Follow these steps to complete
    this exercise:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将使用乳腺癌玩具数据集，并使用scikit-learn库来计算评估指标。请按照以下步骤完成本次练习：
- en: 'Open a Jupyter Notebook to implement this exercise and import all the required elements:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Jupyter Notebook以实现本练习，并导入所有所需的元素：
- en: '[PRE18]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The fourth line imports the `tree` module from scikit-learn, which will be used
    to train a decision tree model on the training data in this exercise. The lines
    of code below that will import the different evaluation metrics that will be calculated
    during this exercise.
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第四行导入了`tree`模块，这是scikit-learn库中的一部分，将用于在本次练习的训练数据上训练决策树模型。下面的代码行将导入在本练习过程中计算的不同评估指标。
- en: 'The breast cancer toy dataset contains the final diagnosis (malignant or benign)
    of the analysis of masses found in the breasts of 569 women. Load the dataset
    and create features and target Pandas DataFrames, as follows:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 乳腺癌玩具数据集包含了对569名女性乳腺肿块分析的最终诊断（恶性或良性）。加载数据集并创建特征和目标Pandas DataFrame，如下所示：
- en: '[PRE19]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Split the dataset using the conventional split approach:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用传统的拆分方法来划分数据集：
- en: '[PRE20]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Note that the dataset is divided into two subsets (train and test sets) because
    the purpose of this exercise is to learn how to calculate the evaluation metrics
    using the scikit-learn package.
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，数据集被分成了两个子集（训练集和测试集），因为本次练习的目的是学习如何使用scikit-learn包计算评估指标。
- en: Note
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The `random_state` parameter is used to set a seed that will ensure the same
    results every time you run the code. This guarantees that you will get the same
    results as the ones reflected in this exercise. Different numbers can be used
    as the seed; however, use the same number as suggested in the exercises and activities
    of this chapter to get the same results as the ones shown here.
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`random_state`参数用于设置种子，确保每次运行代码时结果相同。这保证了你将获得与本练习中所示结果相同的结果。可以使用不同的数字作为种子；然而，为了获得与本章练习和活动中所示相同的结果，请使用建议的相同数字。'
- en: 'First, instantiate the `DecisionTreeClassifier` class from scikit-learn''s
    `tree` module. Next, train a decision tree on the train set. Finally, use the
    model to predict the class label on the test set. Use the following code to do
    this:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，从scikit-learn的`tree`模块实例化`DecisionTreeClassifier`类。接着，在训练集上训练决策树。最后，使用该模型在测试集上预测类别标签。使用以下代码实现：
- en: '[PRE21]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: First, the model is instantiated using a `random_state` to set a seed. Then,
    the `fit` method is used to train the model using the data from the train sets
    (both `X` and `Y`). Finally, the `predict` method is used to trigger the predictions
    on the data in the test set (only `X`). The data from `Y_test` will be used to
    compare the predictions with the ground truth.
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，使用`random_state`实例化模型以设置种子。然后，使用`fit`方法通过训练集的数据（包括`X`和`Y`）训练模型。最后，使用`predict`方法对测试集中的数据（仅`X`）进行预测。`Y_test`中的数据将用于将预测结果与真实值进行比较。
- en: Note
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: 'The steps for training a supervised learning model will be explained further
    in *Chapter 4*, *Supervised Learning Algorithms: Predicting Annual Income* and
    *Chapter 5*, *Artificial Neural Networks: Predicting Annual Income*.'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练监督学习模型的步骤将在*第4章*，*监督学习算法：预测年收入*，和*第5章*，*人工神经网络：预测年收入*中进一步讲解。
- en: 'Use scikit-learn to construct a confusion matrix, as follows:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用scikit-learn构建混淆矩阵，如下所示：
- en: '[PRE22]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The result is as follows, where the ground truth is measured against the prediction:'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下，其中将真实值与预测值进行比较：
- en: '[PRE23]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Calculate the accuracy, precision, and recall of the model by comparing `Y_test`
    and `Y_pred`:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过比较`Y_test`和`Y_pred`，计算模型的准确率、精确度和召回率：
- en: '[PRE24]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The results are displayed as follows:'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '[PRE25]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Given that the positive labels are those where the mass is malignant, it can
    be concluded that the instances that the model predicts as malignant have a high
    probability (96.6%) of being malignant, but for the instances predicted as benign,
    the model has a 17.15% (100%–82.85%) probability of being wrong.
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于正标签表示肿瘤为恶性，可以得出结论：模型预测为恶性的实例有96.6%的高概率为恶性，但对于预测为良性的实例，模型有17.15%（100%-82.85%）的错误概率。
- en: Note
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Yw0hiu](https://packt.live/2Yw0hiu).
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/2Yw0hiu](https://packt.live/2Yw0hiu)。
- en: You can also run this example online at [https://packt.live/3e4rRtE](https://packt.live/3e4rRtE).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/3e4rRtE](https://packt.live/3e4rRtE)在线运行此示例。你必须执行整个Notebook，才能获得期望的结果。
- en: You have successfully calculated evaluation metrics on a classification task.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功计算了分类任务的评估指标。
- en: Choosing an Evaluation Metric
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择评估指标
- en: There are several metrics that can be used to measure the performance of a model
    on classification tasks, and selecting the right one is key to building a model
    that performs exceptionally well for the purpose of the study.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种指标可用于衡量模型在分类任务中的表现，选择正确的指标是构建能够在研究目的上表现出色的模型的关键。
- en: Previously, the importance of understanding the purpose of the study was mentioned
    as a useful insight to determine the pre-processing techniques that need to be
    performed on the dataset. Moreover, the purpose of the study is also useful to
    determine the ideal metric for measuring the performance of the model.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 之前提到过，理解研究目的对于确定需要对数据集执行的预处理技术至关重要。此外，研究目的对于确定评估模型表现的理想指标也非常有帮助。
- en: Why is the purpose of the study important for selecting the evaluation metric?
    Because by understanding the main goal of the study, it is possible to decide
    whether it is important to focus our attention on the overall performance of the
    model or only on one of the class labels.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么研究的目的对选择评估度量标准很重要？因为通过了解研究的主要目标，可以决定是应该将注意力集中在模型的整体性能上，还是仅仅关注某一类标签的表现。
- en: For instance, a model that has been created to recognize when birds are present
    in a picture does not need to perform well in recognizing which other animals
    are present in the picture as long as it does not classify them as birds. This
    means that the model needs to focus on improving the performance of correctly
    classifying birds only.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个用于识别图像中是否有鸟类的模型，如果它能够正确地识别出图像中是否有鸟类，而不是错误地将其他动物识别为鸟类，那么这个模型就是一个好模型。因此，模型只需要关注于提高正确分类鸟类的性能。
- en: On the other hand, for a model that has been created to recognize handwritten
    characters, where no one character is more important than another, the ideal metric
    would be the one that measures the overall accuracy of the model.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，对于一个用于识别手写字符的模型，任何一个字符都不比其他字符更重要，理想的度量标准应该是衡量模型整体准确率的度量。
- en: What would happen if more than one metric was selected? It would become difficult
    to arrive at the best performance of the model, considering that measuring two
    metrics simultaneously can result in needing different approaches to improve results.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如果选择了多个度量标准会怎样？就会很难得出模型的最佳性能，因为同时衡量两个度量可能需要采用不同的方法来改进结果。
- en: Evaluation Metrics for Regression Tasks
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归任务的评估度量
- en: Considering that regression tasks are those where the final output is continuous,
    without a fixed number of output labels, the comparison between the ground truth
    and the prediction is based on the proximity of the values rather than on them
    having exactly the same values. For instance, when predicting house prices, a
    model that predicts a value of USD 299,846 for a house valued at USD 300,000 can
    be considered to be a good model.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到回归任务的最终输出是连续的，没有固定数量的输出标签，因此真实值与预测值之间的比较是基于数值的接近程度，而不是它们是否完全相同。例如，在预测房价时，一个模型预测某房屋的价格为299,846美元，而真实价格为300,000美元，这个模型可以被认为是一个好的模型。
- en: 'The two metrics most commonly used for evaluating the accuracy of continuous
    variables are the **Mean Absolute Error** (**MAE**) and the **Root Mean Squared
    Error** (**RMSE**), which are explained here:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 用于评估连续变量准确性的两种最常用度量标准是**平均绝对误差（MAE）**和**均方根误差（RMSE）**，它们在这里得到了说明：
- en: '**Mean Absolute Error**: This metric measures the average absolute difference
    between a prediction and the ground truth, without taking into account the direction
    of the error. The formula to calculate the MAE is as follows:'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均绝对误差（MAE）**：该度量衡量的是预测值与真实值之间的平均绝对差异，不考虑误差的方向。计算MAE的公式如下：'
- en: '![Figure 3.9: An equation showing the calculation of MAE'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.9：展示MAE计算的方程式](img/B15781_03_10.jpg)'
- en: '](img/B15781_03_09.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_03_09.jpg)'
- en: 'Figure 3.9: An equation showing the calculation of MAE'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9：展示MAE计算的方程式
- en: Here, *m* refers to the total number of instances, *y* is the ground truth,
    and *ŷ* is the predicted value.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*m*表示实例的总数，*y*是实际值，*ŷ*是预测值。
- en: '**Root Mean Squared Error**: This is a quadratic metric that also measures
    the average magnitude of error between the ground truth and the prediction. As
    its name suggests, the RMSE is the square root of the average of the squared differences,
    as shown in the following formula:![Figure 3.10: An equation showing the calculation
    of RMSE'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均方根误差（RMSE）**：这是一种二次度量，衡量的是真实值与预测值之间误差的平均大小。顾名思义，RMSE是平方差的平均值的平方根，如下方公式所示：![图3.10：展示RMSE计算的方程式](img/B15781_03_10.jpg)'
- en: '](img/B15781_03_10.jpg)'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_03_10.jpg)'
- en: 'Figure 3.10: An equation showing the calculation of RMSE'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10：展示RMSE计算的方程式
- en: Both these metrics express the average error, in a range from 0 to infinity,
    where the lower the value, the better the performance of the model. The main difference
    between these two metrics is that the MAE assigns the same weight of importance
    to all errors, while the RMSE squares the error, assigning higher weights to larger
    errors.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种度量标准都表达了从0到无穷大的平均误差，其中数值越低，模型性能越好。它们之间的主要区别在于，MAE对所有误差赋予相同的权重，而RMSE则对误差进行平方处理，从而赋予较大误差更高的权重。
- en: Considering this, the RMSE metric is especially useful in cases where larger
    errors should be penalized, meaning that outliers are taken into account in the
    measurement of performance. For instance, the RMSE metric can be used when a value
    that is off by 4 is more than twice as bad as being off by 2\. The MAE, on the
    other hand, is used when a value that is off by 4 is just twice as bad as a value
    off by 2.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，RMSE 指标在较大误差应受到惩罚的情况下特别有用，这意味着在性能度量中会考虑异常值。例如，当偏差为 4 的值比偏差为 2 的值差了两倍时，可以使用
    RMSE 指标。而 MAE 则在偏差为 4 的值仅是偏差为 2 的值两倍的情况下使用。
- en: 'Exercise 3.04: Calculating Evaluation Metrics on a Regression Task'
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.04：计算回归任务中的评估指标
- en: 'In this exercise, we will be calculating evaluation metrics on a model that
    was trained using linear regression. We will use the `boston` toy dataset for
    this purpose. Follow these steps to complete this exercise:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将计算一个使用线性回归训练的模型的评估指标。我们将使用 `boston` 玩具数据集来完成此任务。按照以下步骤完成此练习：
- en: 'Open a Jupyter Notebook to implement this exercise and import all the required
    elements, as follows:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 Jupyter Notebook 来实现此练习，并导入所有所需的元素，具体如下：
- en: '[PRE26]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The fourth line imports the `linear_model` module from scikit-learn, which will
    be used to train a linear regression model on the training dataset. The lines
    of code that follow import two performance metrics that will be evaluated in this exercise.
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第四行导入了 scikit-learn 中的 `linear_model` 模块，该模块将用于在训练数据集上训练一个线性回归模型。接下来的几行代码导入了将在本次练习中评估的两个性能指标。
- en: 'For this exercise, the `boston` toy dataset will be used. This dataset contains
    data about 506 house prices in Boston. Use the following code to load and split
    the dataset, the same as we did for the previous exercises:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本次练习将使用 `boston` 玩具数据集。该数据集包含波士顿 506 个房价的数据。使用以下代码加载并拆分数据集，与我们之前的练习相同：
- en: '[PRE27]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Train a linear regression model on the train set. Then, use the model to predict
    the class label on the test set, as follows:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上训练一个线性回归模型。然后，使用该模型在测试集上预测类标签，具体如下：
- en: '[PRE28]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: As a general explanation, the `LinearRegression` class from scikit-learn's `linear_model`
    module is instantiated first. Then, the `fit` method is used to train the model
    using the data from the train sets (both `X` and `Y`). Finally, the `predict`
    method is used to trigger the predictions on the data in the test set (only `X`).
    The data from `Y_test` will be used to compare the predictions to the ground truth.
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一般来说，首先会实例化 scikit-learn `linear_model` 模块中的`LinearRegression` 类。然后，使用 `fit`
    方法通过训练集的数据（包括 `X` 和 `Y`）来训练模型。最后，使用 `predict` 方法对测试集中的数据（仅 `X`）进行预测。`Y_test` 中的数据将用于将预测结果与真实值进行比较。
- en: 'Calculate both the MAE and RMSE metrics:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算 MAE 和 RMSE 两个指标：
- en: '[PRE29]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The results are displayed as follows:'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '[PRE30]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Note
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The scikit-learn library allows you to directly calculate the MSE. To calculate
    the RMSE, the square root of the value obtained from the `mean_squared_error()`
    function is calculated. By using the square root, we ensure that the values from
    MAE and RMSE are comparable.
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: scikit-learn 库允许你直接计算 MSE。为了计算 RMSE，需要计算从 `mean_squared_error()` 函数得到值的平方根。通过使用平方根，我们确保
    MAE 和 RMSE 的值是可以比较的。
- en: From the results, it is possible to conclude that the model performs well on
    the test set, considering that both values are close to zero. Nevertheless, this
    also means that the performance can still be improved.
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从结果可以得出结论，模型在测试集上的表现良好，考虑到两个值都接近零。然而，这也意味着性能仍然可以进一步提升。
- en: Note
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2YxVXiU](https://packt.live/2YxVXiU).
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 若要访问此特定部分的源代码，请参考 [https://packt.live/2YxVXiU](https://packt.live/2YxVXiU)。
- en: You can also run this example online at [https://packt.live/2N0Elqy](https://packt.live/2N0Elqy).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在线运行此示例，网址是 [https://packt.live/2N0Elqy](https://packt.live/2N0Elqy)。你必须执行整个
    Notebook 才能获得期望的结果。
- en: You have now successfully calculated evaluation metrics on a regression task
    that aimed to calculate the prices of houses based on their characteristics. In
    the next activity, we will calculate the performance of a classification model
    that was created to recognize handwritten characters.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经成功计算了回归任务中的评估指标，该任务旨在根据房屋的特征计算价格。在接下来的活动中，我们将计算一个分类模型的性能，该模型用于识别手写字符。
- en: 'Activity 3.02: Evaluating the Performance of the Model Trained on a Handwritten
    Dataset'
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 3.02：评估在手写数据集上训练的模型的表现
- en: 'You continue to work on creating a model to recognize handwritten digits. The
    team has built a model and they want you to evaluate the performance of the model.
    In this activity, you will calculate different performance evaluation metrics
    on a trained model. Follow these steps to complete this activity:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 你继续致力于创建一个识别手写数字的模型。团队已经构建了一个模型，他们希望你评估该模型的表现。在此活动中，你将计算训练模型的不同表现评估指标。按照以下步骤完成该活动：
- en: Import all the required elements to load and split a dataset in order to train
    a model and evaluate the performance of the classification tasks.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必需的元素以加载并拆分数据集，用于训练模型并评估分类任务的表现。
- en: Load the `digits` toy dataset from scikit-learn and create Pandas DataFrames
    containing the features and target matrices.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 scikit-learn 中加载 `digits` 玩具数据集，并创建包含特征和目标矩阵的 Pandas 数据框。
- en: Split the data into training and testing sets. Use 20% as the size of the testing
    set.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集和测试集。使用 20% 作为测试集的大小。
- en: Train a decision tree on the train set. Then, use the model to predict the class
    label on the test set.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上训练一个决策树。然后，使用该模型预测测试集上的类别标签。
- en: Note
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To train the decision tree, revisit *Exercise 3.04*, *Calculating Different
    Evaluation Metrics on a Classification Task*.
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要训练决策树，请回顾 *练习 3.04*，*计算分类任务的不同评估指标*。
- en: Use scikit-learn to construct a confusion matrix.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 构建混淆矩阵。
- en: Calculate the accuracy of the model.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算模型的准确率。
- en: Calculate the precision and recall. Considering that both the precision and
    recall can only be calculated on binary classification problems, we'll assume
    that we are only interested in classifying instances as the number `6` or `any
    other number`.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算精确度和召回率。考虑到精确度和召回率只能在二分类问题上计算，我们假设只关注将实例分类为数字 `6` 或 `其他任何数字`。
- en: To be able to calculate the precision and recall, use the following code to
    convert `Y_test` and `Y_pred` into a one-hot vector. A one-hot vector consists
    of a vector that only contains zeros and ones. For this activity, the 0 represents
    the *number 6*, while the 1 represents `any other number`. This converts the class
    labels (`Y_test` and `Y_pred`) into binary data, meaning that there are only two
    possible outcomes instead of 10 different ones.
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了能够计算精确度和召回率，使用以下代码将 `Y_test` 和 `Y_pred` 转换为一热向量。一个一热向量由仅包含零和一的向量组成。对于本活动，0
    代表 *数字 6*，而 1 代表 `任何其他数字`。这将类别标签（`Y_test` 和 `Y_pred`）转换为二进制数据，即只有两个可能的结果，而不是 10
    个不同的结果。
- en: 'Then, calculate the precision and recall using the new variables:'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，使用新变量计算精确度和召回率：
- en: '[PRE31]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'You should obtain the following values as the output:'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下值作为输出：
- en: '[PRE32]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 230.
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第 230 页找到。
- en: Error Analysis
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 错误分析
- en: Building an average model, as explained so far, is surprisingly easy through
    the use of the scikit-learn library. The key aspects of building an exceptional
    model come from the analysis and decision-making on the part of the researcher.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，通过使用 scikit-learn 库，构建一个平均模型是出乎意料的简单。构建一个优秀模型的关键方面来自研究人员的分析和决策。
- en: As we have seen so far, some of the most important tasks are choosing and pre-processing
    the dataset, determining the purpose of the study, and selecting the appropriate
    evaluation metric. After handling all of this and taking into account that a model
    needs to be fine-tuned in order to reach the highest standards, most data scientists
    recommend training a simple model, regardless of the hyperparameters, to get the
    study started.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们迄今所见，一些最重要的任务是选择和预处理数据集、确定研究目的以及选择合适的评估指标。在处理完这些内容并考虑到模型需要进行微调以达到最高标准后，大多数数据科学家建议训练一个简单的模型，无论超参数如何，以便开始研究。
- en: '**Error analysis** is then introduced as a very useful methodology to turn
    an average model into an exceptional one. As the name suggests, it consists of
    analyzing the errors among the different subsets of the dataset in order to target
    the condition that is affecting the model at a greater scale.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '**错误分析** 随后被引入，作为一种非常有用的方法论，将一个平均模型转化为一个卓越的模型。顾名思义，它包括分析数据集中不同子集的错误，以便定位影响模型的主要条件。'
- en: Bias, Variance, and Data Mismatch
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏差、方差和数据不匹配
- en: To understand the different conditions that may affect a machine learning model,
    it is important to understand what the **Bayes error** is. The Bayes error, also
    known as the **irreducible error**, is the lowest possible error rate that can
    be achieved.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解可能影响机器学习模型的不同条件，重要的是要理解**贝叶斯误差**是什么。贝叶斯误差，也称为**不可降低误差**，是可以达到的最低可能错误率。
- en: Before the improvements that were made in technology and artificial intelligence,
    the Bayes error was considered to be the lowest possible error achievable by humans
    (**human error**). For instance, for a process that most humans achieve with an
    error rate of 0.1, but top experts achieve with an error rate of 0.05, the Bayes
    error would be 0.05.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术和人工智能改进之前，贝叶斯误差被认为是人类可以达到的最低可能误差（**人为误差**）。例如，对于大多数人类以0.1的错误率完成的过程，但顶级专家以0.05的错误率完成的过程，贝叶斯误差将为0.05。
- en: However, the Bayes error has now been redefined as being the lowest possible
    error that machines can achieve, which is unknown considering that, as humans,
    we can only understand as far as human error goes. Due to this, when using the
    Bayes error to analyze errors, it is not possible to know the lowest limit once
    the model is below the human error.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现在贝叶斯误差被重新定义为机器可以达到的最低可能误差，这是未知的，考虑到我们作为人类只能理解到人类误差的程度。因此，当使用贝叶斯误差来分析错误时，一旦模型低于人类误差，就不可能知道最低限度。
- en: 'The following diagram is useful for analyzing the error rates among the different
    sets of data and determining the condition that is affecting the model in a greater
    proportion. The purpose of this diagram is to find the errors that differ to a
    greater extent from each other so that the model can be diagnosed and improved
    accordingly. It is important to highlight that the value of the error for each
    set is calculated by subtracting the evaluation metrics (for instance, the accuracy)
    of that set from 100%:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表有助于分析不同数据集之间的错误率，并确定对模型影响最大的条件。该图的目的是找出彼此之间错误差异最大的错误，以便相应地诊断和改进模型。重要的是强调，每个集合的错误值是通过从该集合的评估指标（例如准确率）减去100%来计算的：
- en: '![Figure 3.11: Error analysis methodology'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.11：错误分析方法论'
- en: '](img/B15781_03_11.jpg)'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_03_11.jpg)'
- en: 'Figure 3.11: Error analysis methodology'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.11：错误分析方法论
- en: 'Considering the preceding diagram, the process to perform error analysis is
    as follows:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑前述图表，执行错误分析的过程如下：
- en: The performance evaluation is calculated on all sets of data. This measure is
    used to calculate the error for each set.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算所有数据集的性能评估。此措施用于计算每个集合的错误。
- en: 'Starting from the bottom to the top, the difference is calculated as follows:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从底部到顶部开始计算差异如下：
- en: The dev set error (12%) is subtracted from the testing set error (12%). The
    resulting value (0%) is saved.
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将开发集误差（12%）减去测试集误差（12%）。得到的数值（0%）保存。
- en: The train-dev error (9%) is subtracted from the dev set error (12%). The resulting
    value (3%) is saved.
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将训练/开发集误差（9%）减去开发集误差（12%）。得到的数值（3%）保存。
- en: The training set error (8%) is subtracted from the train-dev error (9%). The
    resulting value (1%) is saved.
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将训练集误差（8%）减去训练/开发集误差（9%）。得到的数值（1%）保存。
- en: The Bayes error (2%) is subtracted from the training set error (8%). The resulting
    value (6%) is saved.
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将贝叶斯误差（2%）减去训练集误差（8%）。得到的数值（6%）保存。
- en: The bigger difference determines the condition that is most seriously affecting
    the model. In this case, the bigger difference occurs between the Bayes error
    and the training set error, which, as shown in the preceding diagram, determines
    that the model is suffering from *high bias*.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更大的差异确定最严重影响模型的条件。在本例中，更大的差异出现在贝叶斯误差和训练集误差之间，如前述图表所示，这表明模型正遭受*高偏差*的影响。
- en: Note
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注
- en: The train/dev set is a combination of data in the training and the validation
    (dev) sets. It is usually of the same shape as the dev set and contains the same
    amount of data from both sets.
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练/开发集是训练集和验证集（开发集）中数据的组合。它通常与开发集具有相同的形状，并包含来自两个集合的相同数量的数据。
- en: 'An explanation of each of the conditions is as follows, along with some techniques
    to avoid/fix them:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 下面解释每个条件及一些避免/修复它们的技术：
- en: '**High Bias**: Also known as underfitting, this occurs when the model is not
    learning from the training set, which translates into the model performing poorly
    for all three sets (training, validation, and testing sets), as well as for unseen data.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高偏差**：也称为欠拟合，这种情况发生在模型没有从训练集中学习时，导致模型在所有三种数据集（训练集、验证集和测试集）上表现较差，且对未见过的数据也表现不佳。'
- en: Underfitting is the easiest condition to detect and it usually requires changing
    to a different algorithm that may be a better fit for the data available. With
    regard to neural networks, it can typically be fixed by constructing a bigger
    network or by training for longer periods of time.
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 欠拟合是最容易检测到的情况，通常需要更换不同的算法，以更好地适应可用数据。对于神经网络而言，通常可以通过构建更大的网络或训练更长时间来解决。
- en: '**High Variance**: Also known as overfitting, this condition refers to the
    model''s inability to perform well on data that''s different than that of the
    training set. This basically means that the model has overfitted the training
    data by learning the details and outliers of the data, without making any generalizations.
    A model suffering from overfitting will not perform well on the dev or test sets,
    or on unseen data.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高方差**：也称为过拟合，这种情况指的是模型在处理与训练集不同的数据时表现不佳。这基本上意味着模型通过学习数据的细节和离群点来过拟合训练数据，而没有进行任何概括。一个遭受过拟合的模型在开发集、测试集或未见过的数据上表现不佳。'
- en: Overfitting can be fixed by tuning the different hyperparameters of the algorithm,
    often with the objective of simplifying the algorithm's approximation of the data.
    For instance, for decision trees, this can be addressed by pruning the tree to
    delete some of the details that were learned from the training data. In neural
    networks, on the other hand, this can be addressed by adding regularization techniques
    that seek to reduce some of the neuron's influence on the overall result.
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 过拟合可以通过调整算法的不同超参数来解决，通常目标是简化算法对数据的近似。例如，对于决策树，可以通过修剪树来删除一些从训练数据中学习到的细节来解决。另一方面，对于神经网络，可以通过添加正则化技术来减少神经元对整体结果的影响。
- en: Additionally, adding more data to the training set can also help the model avoid
    high variance, that is, increasing the dataset that's used for training the model.
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，向训练集添加更多数据也有助于模型避免高方差，即增加用于训练模型的数据集。
- en: '**Data mismatch**: This occurs when the training and validation sets do not
    follow the same distribution. This affects the model as although it generalizes
    based on the training data. This generalization does not describe the data that
    was found in the validation set. For instance, a model that''s created to describe
    landscape photographs may suffer from a data mismatch if it is trained using high-definition
    images, while the actual images that will be used once the model has been built
    are unprofessional.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据不匹配**：当训练集和验证集不遵循相同的分布时，就会发生数据不匹配。这会影响模型的表现，因为虽然它基于训练数据进行概括，但这种概括并不描述验证集中出现的数据。例如，若一个模型是用来描述风景照片的，但它是用高清图像训练的，而实际使用的图像是非专业的，这时就会出现数据不匹配问题。'
- en: Logically, the best way to avoid data mismatch is to make sure that the sets
    follow the same distribution. For example, you can do this by shuffling together
    the images from both sources (professional and unprofessional images) and then
    dividing them into the different sets.
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从逻辑上讲，避免数据不匹配的最佳方法是确保各数据集遵循相同的分布。例如，你可以通过将来自两个来源（专业和非专业图像）的图像一起打乱，然后将它们划分到不同的集合中来实现这一点。
- en: Nevertheless, in cases where there is not enough data that follows the same
    distribution of unseen data (data that will be used in the future), it is highly
    recommended to create the dev and test sets entirely out of that data and add
    the remaining data to the large training set. From the preceding example, the
    unprofessional images should be used to create the dev and test sets, adding the
    remaining ones to the training set, along with the professional images. This helps
    to train a model with a set that contains enough images to make a generalization,
    but it uses data with the same distribution as the unseen data to fine-tune the
    model.
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然而，在数据不足以遵循与未来未见数据（将来用于训练的数据）相同分布的情况下，强烈建议完全从这些数据中创建开发集和测试集，并将剩余的数据添加到大型训练集中。从前面的示例中，应该使用非专业图像来创建开发集和测试集，将剩余的图像与专业图像一起添加到训练集中。这有助于使用包含足够图像以进行泛化的训练集来训练模型，但它使用与未见数据分布相同的数据来微调模型。
- en: Finally, if the data from all sets comes from the same distribution, this condition
    actually refers to a problem of high variance and should be handled as such.
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，如果所有集合的数据来自相同的分布，那么这个条件实际上指的是一个高方差问题，应按照这种方式进行处理。
- en: '**Overfitting to the dev set**: Lastly, similar to the variance condition,
    this occurs when the model is not generalizing but instead is fitting the dev
    set too well.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对开发集的过拟合**：最后，类似于方差问题，当模型没有进行泛化，而是过度拟合开发集时，会发生这种情况。'
- en: It should be addressed using the same approaches that were explained for high variance.
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 应使用与前面解释的高方差问题相同的方法来处理该问题。
- en: In the next exercise, we will calculate the error rate of the model on the different
    sets of data, which can be used to perform error analysis.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，我们将计算模型在不同数据集上的错误率，这可用于进行错误分析。
- en: 'Exercise 3.05: Calculating the Error Rate on Different Sets of Data'
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.05：计算不同数据集上的错误率
- en: 'In this exercise, we will calculate error rates for a model that has been trained
    using a decision tree. We will use the breast cancer dataset for this purpose.
    Follow these steps to complete this exercise:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将计算使用决策树训练的模型的错误率。我们将使用乳腺癌数据集来完成此任务。按照以下步骤完成本次练习：
- en: 'Open a Jupyter Notebook to implement this exercise and import all the required
    elements to load and split the dataset. These will be used to train a model and
    evaluate its recall:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Jupyter Notebook 来实现本次练习，并导入所有需要的元素以加载和拆分数据集。这些将用于训练模型并评估其召回率：
- en: '[PRE33]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'For this exercise, the `breast cancer` dataset will be used. Use the following
    code to load the dataset and create the Pandas DataFrames containing the features
    and target matrices:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本次练习中，将使用 `乳腺癌` 数据集。使用以下代码加载数据集，并创建包含特征和目标矩阵的 Pandas DataFrame：
- en: '[PRE34]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Split the dataset into training, validation, and testing sets:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集拆分为训练集、验证集和测试集：
- en: '[PRE35]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The resulting shapes are as follows:'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果的形状如下：
- en: '[PRE36]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Create a train/dev set that combines data from both the training and validation sets:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个结合了训练集和验证集数据的训练/开发集：
- en: '[PRE37]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: First, a random seed is set to ensure the reproducibility of the results. Next,
    the NumPy `random.randint()` function is used to select random indices from the
    `X_train` set. To do that, 28 random integers are generated in a range between
    0 and the total length of `X_train`. The same process is used to generate the
    random indices of the dev set. Finally, a new variable is created to store the
    selected values of `X_train` and `X_dev`, as well as a variable to store the corresponding
    values from `Y_train` and `Y_dev`.
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，设置一个随机种子，以确保结果的可重复性。接下来，使用 NumPy `random.randint()` 函数从 `X_train` 集合中选择随机索引。为此，在
    0 到 `X_train` 总长度之间生成 28 个随机整数。相同的过程用于生成开发集的随机索引。最后，创建一个新变量来存储从 `X_train` 和 `X_dev`
    中选择的值，并创建一个变量来存储来自 `Y_train` 和 `Y_dev` 的相应值。
- en: The variables that have been created contain 25 instances/labels from the train
    set and 25 instances/labels from the dev set.
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 已创建的变量包含来自训练集的 25 个实例/标签和来自开发集的 25 个实例/标签。
- en: 'The resulting shapes of the sets are as follows:'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果集的形状如下：
- en: '[PRE38]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Train a decision tree on the train set, as follows:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上训练决策树，如下所示：
- en: '[PRE39]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Use the `predict` method to generate the predictions for all of your sets (train,
    train/dev, dev, and test). Next, considering that the objective of the study is
    to maximize the model''s ability to predict all malignant cases, calculate the
    recall scores for all predictions. Store all of the scores in a variable named
    `scores`:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `predict` 方法生成所有数据集（训练集、训练/开发集、开发集和测试集）的预测。接下来，考虑到本研究的目标是最大化模型预测所有恶性案例的能力，计算所有预测的召回率分数。将所有分数存储在名为
    `scores` 的变量中：
- en: '[PRE40]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The error rates for all of the sets of data are as follows:'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有数据集的误差率如下：
- en: '[PRE41]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'From the preceding values, the following table containing the error rates can
    be created:'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从上述值中，可以创建以下包含误差率的表格：
- en: '![Figure 3.12: Error rates for all sets of data'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.12：所有数据集的误差率'
- en: '](img/B15781_03_12.jpg)'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_03_12.jpg)'
- en: 'Figure 3.12: Error rates for all sets of data'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.12：所有数据集的误差率
- en: Here, the Bayes error was assumed as `0`, considering that the classification
    between a malignant and a benign mass is done by taking a biopsy of the mass.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，假设贝叶斯误差为 `0`，因为恶性肿瘤和良性肿瘤的分类是通过活检进行的。
- en: From the preceding table, it can be concluded that the model performs exceptionally
    well for the purpose of the study, considering that all error rates are close
    to 0, which is the lowest possible error.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 从上表可以得出结论，考虑到所有的误差率接近0，即最低可能的误差，该模型在研究目的上表现得非常出色。
- en: The highest difference in error rates is found between the train/dev set and
    the dev set, which refers to data mismatch. However, taking into account that
    all the datasets come from the same distribution, this condition is considered
    a high variance issue, where adding more data to the training set should help
    reduce the error rate.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 最高的误差率差异出现在训练集/开发集和开发集之间，这意味着数据不匹配。然而，考虑到所有数据集来自相同的分布，这种情况被认为是一个高方差问题，增加更多的数据到训练集中应该有助于减少误差率。
- en: Note
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: To access the source code for this specific section, please refer to [https://packt.live/3e4Toer](https://packt.live/3e4Toer).
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该部分的源代码，请参考 [https://packt.live/3e4Toer](https://packt.live/3e4Toer)。
- en: You can also run this example online at [https://packt.live/2UJzDkW](https://packt.live/2UJzDkW).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例，网址是 [https://packt.live/2UJzDkW](https://packt.live/2UJzDkW)。你必须执行整个Notebook才能得到预期的结果。
- en: You have successfully calculated the error rate of all the subsets of data.
    In the next activity, we will perform an error analysis to define the steps to
    be taken to improve the performance of a model that was created to recognize handwritten
    digits.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功计算出了所有数据子集的误差率。在接下来的活动中，我们将进行误差分析，以定义改进已创建的手写数字识别模型性能的步骤。
- en: 'Activity 3.03: Performing Error Analysis on a Model Trained to Recognize Handwritten
    Digits'
  id: totrans-346
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 3.03：对训练手写数字识别模型进行误差分析
- en: 'Based on the different metrics that you have provided to your team to measure
    the performance of the model, they have selected accuracy as the ideal metric.
    Considering this, your team has asked you to perform an error analysis to determine
    how the model could be improved. In this activity, you will perform an error analysis
    by comparing the error rate of the different sets in terms of the accuracy of
    the model. Follow these steps to achieve this:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你提供给团队的不同指标，他们已选择准确率作为理想的度量标准。考虑到这一点，你的团队要求你进行误差分析，以确定如何改进模型。在此活动中，你将通过比较不同数据集的误差率来进行误差分析，以评估模型的准确度。请按照以下步骤进行：
- en: Import the required elements to load and split a dataset. We will do this to
    train the model and measure its accuracy.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入加载和拆分数据集所需的元素。我们将这样做来训练模型并衡量其准确性。
- en: Load the `digits` toy dataset from scikit-learn and create Pandas DataFrames
    containing the features and target matrices.
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 scikit-learn 中加载 `digits` 玩具数据集，并创建包含特征和目标矩阵的 Pandas DataFrame。
- en: Split the data into training, validation, and testing sets. Use 0.1 as the size
    of the test set, and an equivalent number to build a validation set of the same
    shape.
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集、验证集和测试集。使用 0.1 作为测试集的大小，并构建一个大小相同的验证集。
- en: Create a train/dev set for both the features and target values that contains
    90 instances/labels of the train set and 90 instances/labels of the dev set.
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为特征和目标值创建一个包含90个训练集实例/标签和90个开发集实例/标签的训练/开发集。
- en: Train a decision tree on that training set data.
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集数据上训练一个决策树模型。
- en: Calculate the error rate for all sets of data in terms of the accuracy of the
    model and determine which condition is affecting the performance of the model.
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算所有数据集的错误率，评估模型的准确性，并确定哪些条件影响模型的表现。
- en: 'By completing this activity, you should obtain the following error rates:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此活动后，您应获得以下错误率：
- en: '![Figure 3.13: Expected error rates'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.13：预期的错误率'
- en: '](img/B15781_03_13.jpg)'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_03_13.jpg)'
- en: 'Figure 3.13: Expected error rates'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13：预期的错误率
- en: Note
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 233.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第233页找到。
- en: Summary
  id: totrans-360
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This chapter explained the different tasks that can be solved through supervised
    learning algorithms: classification and regression. Although both of these tasks''
    goal is to approximate a function that maps a set of features to an output, classification
    tasks have a discrete number of outputs, while regression tasks can have infinite
    continuous values as outputs.'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 本章解释了可以通过监督学习算法解决的不同任务：分类和回归。虽然这两种任务的目标都是近似一个将一组特征映射到输出的函数，但分类任务有离散的输出数量，而回归任务的输出可以是无限连续的值。
- en: 'When developing machine learning models to solve supervised learning problems,
    one of the main goals is for the model to be capable of generalizing so that it
    will be applicable to future unseen data, instead of just learning a set of instances
    very well but performing poorly on new data. Accordingly, a methodology for validation
    and testing was explained in this chapter, which involved splitting the data into
    three sets: a training set, a dev set, and a test set. This approach eliminates
    the risk of bias.'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发机器学习模型以解决监督学习问题时，主要目标之一是让模型具有良好的泛化能力，从而能够应用于未来未见的数据，而不仅仅是学习一组实例并在新数据上表现不佳。因此，本章解释了一种验证和测试的方法论，涉及将数据划分为三组：训练集、开发集和测试集。这种方法消除了偏差的风险。
- en: After this, we covered how to evaluate the performance of a model for both classification
    and regression problems. Finally, we covered how to analyze the performance of
    a model and perform error analysis on each of the sets to detect the condition
    affecting the model's performance.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们介绍了如何评估分类和回归问题中模型的表现。最后，我们讨论了如何分析模型的表现并对每个数据集进行错误分析，以检测影响模型表现的条件。
- en: In the next chapter, we will focus on applying different algorithms to a real-life
    dataset, with the underlying objective of applying the steps we learned about
    here to choose the best performing algorithm for the case study.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将重点应用不同的算法到实际的数据集，旨在将我们在本章学到的步骤应用于选择最适合此案例研究的算法。
