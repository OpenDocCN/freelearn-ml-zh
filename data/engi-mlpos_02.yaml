- en: 'Chapter 1: Fundamentals of an MLOps Workflow'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章：MLOps工作流程的基础
- en: '**Machine learning** (**ML**) is maturing from research to applied business
    solutions. However, the grim reality is that only 2% of companies using ML have
    successfully deployed a model in production to enhance their business processes,
    reported by DeepLearning.AI ([https://info.deeplearning.ai/the-batch-companies-slipping-on-ai-goals-self-training-for-better-vision-muppets-and-models-china-vs-us-only-the-best-examples-proliferating-patents](https://info.deeplearning.ai/the-batch-companies-slipping-on-ai-goals-self-training-for-better-vision-muppets-and-models-china-vs-us-only-the-best-examples-proliferating-patents)).
    What makes it so hard? And what do we need to do to improve the situation?'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）正从研究走向应用商业解决方案。然而，残酷的现实是，只有2%使用机器学习的企业成功地将模型部署到生产环境中以增强其业务流程，这是由DeepLearning.AI报告的（[https://info.deeplearning.ai/the-batch-companies-slipping-on-ai-goals-self-training-for-better-vision-muppets-and-models-china-vs-us-only-the-best-examples-proliferating-patents](https://info.deeplearning.ai/the-batch-companies-slipping-on-ai-goals-self-training-for-better-vision-muppets-and-models-china-vs-us-only-the-best-examples-proliferating-patents)）。这为什么会如此困难？我们还需要做什么来改善这种情况？'
- en: To get a solid understanding of this problem and its solution, in this chapter,
    we will delve into the evolution and intersection of software development and
    ML. We'll begin by reflecting on some of the trends in traditional software development,
    starting from the waterfall model to agile to DevOps practices, and how these
    are evolving to industrialize ML-centric applications. You will be introduced
    to a systematic approach to operationalizing AI using **Machine Learning Operations**
    (**MLOps**). By the end of this chapter, you will have a solid understanding of
    MLOps and you will be equipped to implement a generic MLOps workflow that can
    be used to build, deploy, and monitor a wide range of ML applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对这个问题及其解决方案有一个扎实的理解，在本章中，我们将深入探讨软件开发与机器学习（ML）的演变和交汇。我们将从传统的瀑布模型开始，反思传统软件开发的一些趋势，到敏捷开发再到DevOps实践，以及这些实践如何演变以实现以机器学习为中心的应用的工业化。您将了解到使用**机器学习操作**（**MLOps**）实现AI运营的系统方法。到本章结束时，您将对MLOps有一个扎实的理解，并准备好实施一个通用的MLOps工作流程，该工作流程可用于构建、部署和监控各种机器学习应用。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: The evolution of infrastructure and software development
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施和软件开发的发展
- en: Traditional software development challenges
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传统软件开发挑战
- en: Trends of ML adoption in software development
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件开发中机器学习采用的趋势
- en: Understanding MLOps
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解MLOps
- en: Concepts and workflow of MLOps
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLOps的概念和工作流程
- en: The evolution of infrastructure and software development
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础设施和软件开发的发展
- en: With the genesis of the modern internet age (around 1995), we witnessed a rise
    in software applications, ranging from operating systems such as Windows 95 to
    the Linux operating system and websites such as Google and Amazon, which have
    been serving the world (online) for over two decades. This has resulted in a culture
    of continuously improving services by collecting, storing, and processing a massive
    amount of data from user interactions. Such developments have been shaping the
    evolution of IT infrastructure and software development.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着现代互联网时代的起源（大约在1995年），我们见证了软件应用的兴起，从Windows 95这样的操作系统到Linux操作系统，再到Google和Amazon等网站，这些网站已经为世界（在线）服务了二十多年。这导致了通过收集、存储和处理来自用户交互的大量数据来不断改进服务的文化。这些发展正在塑造IT基础设施和软件开发的发展。
- en: Transformation in IT infrastructure has picked up pace since the start of this
    millennium. Since then, businesses have increasingly adopted cloud computing as
    it opens up new possibilities for businesses to outsource IT infrastructure maintenance
    while provisioning necessary IT resources such as storage and computation resources
    and services required to run and scale their operations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自本世纪初以来，IT基础设施的转型步伐加快。从那时起，企业越来越多地采用云计算，因为它为企业在外包IT基础设施维护的同时，提供了必要的IT资源，如存储和计算资源以及运行和扩展其运营所需的服务。
- en: Cloud computing offers on-demand provisioning and the availability of IT resources
    such as data storage and computing resources without the need for active management
    by the user of the IT resources. For example, businesses provisioning computation
    and storage resources do not have to manage these resources directly and are not
    responsible for keeping them running – the maintenance is outsourced to the cloud
    service provider.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 云计算提供了按需提供和IT资源（如数据存储和计算资源）的可用性，无需用户对IT资源进行主动管理。例如，提供计算和存储资源的公司无需直接管理这些资源，也不负责保持它们运行——维护工作外包给了云服务提供商。
- en: Businesses using cloud computing can reap benefits as there's no need to buy
    and maintain IT resources; it enables them to have less in-house expertise for
    IT resource maintenance and this allows businesses to optimize costs and resources.
    Cloud computing enables scaling on demand and users pay as per the usage of resources.
    As a result, we have seen companies adopting cloud computing as part of their
    businesses and IT infrastructures.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 使用云计算的企业可以从中获益，因为它们无需购买和维护IT资源；这使它们在IT资源维护方面的内部专业知识需求减少，从而允许企业优化成本和资源。云计算使按需扩展成为可能，用户按资源使用量付费。因此，我们看到许多公司已经开始将云计算作为其业务和IT基础设施的一部分。
- en: Cloud computing became popular in the industry from 2006 onward when Sun Microsystems
    launched Sun Grid in March 2006\. It is a hardware and data resource sharing service.
    This service was acquired by Oracle and was later named Sun Cloud. Parallelly,
    in the same year (2006), another cloud computing service was launched by Amazon
    called Elastic Compute Cloud. This enabled new possibilities for businesses to
    provision computation, storage, and scaling capabilities on demand. Since then,
    the transformation across industries has been organic toward adopting cloud computing.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 从2006年开始，云计算在业界变得流行，当时太阳微系统公司在2006年3月推出了Sun Grid。这是一个硬件和数据资源共享服务。这项服务被甲骨文公司收购，后来更名为Sun
    Cloud。同时，在同年（2006年），亚马逊推出了另一项名为弹性计算云（Elastic Compute Cloud）的云计算服务。这为企业在按需提供计算、存储和扩展能力方面开辟了新的可能性。从那时起，各行业向采用云计算的转变已经是有机发生的。
- en: In the last decade, many companies on a global and regional scale have catalyzed
    the cloud transformation, with companies such as Google, IBM, Microsoft, UpCloud,
    Alibaba, and others heavily investing in the research and development of cloud
    services. As a result, a shift from localized computing (companies having their
    own servers and data centers) to on-demand computing has taken place due to the
    availability of robust and scalable cloud services. Now businesses and organizations
    are able to provision resources on-demand on the cloud to satisfy their data processing
    needs.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，许多全球和区域性的公司推动了云转型，例如谷歌、IBM、微软、UpCloud、阿里巴巴等公司都在云计算服务的研发上进行了大量投资。因此，由于强大的可扩展云服务的可用性，从本地化计算（公司拥有自己的服务器和数据中心）向按需计算转变已经发生。现在，企业和组织能够在云上按需提供资源，以满足他们的数据处理需求。
- en: With these developments, we have witnessed **Moore's law** in operation, which
    states that the number of transistors on a microchip doubles every 2 years – though
    the cost of computers has halved, this has been true so far. Subsequently, some
    trends are developing as follows.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 随着这些发展，我们见证了**摩尔定律**在发挥作用，该定律指出，每两年微芯片上的晶体管数量翻一番——尽管计算机的成本减半，但这至今一直如此。随后，一些趋势正在如下发展。
- en: The rise of machine learning and deep learning
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习和深度学习的兴起
- en: Over the last decade, we have witnessed the adoption of ML in everyday life
    applications. Not only for esoteric applications such as **Dota** or **AlphaGo**,
    but ML has also made its way to pretty standard applications such as machine translation,
    image processing, and voice recognition.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，我们见证了机器学习在日常生活中的应用。不仅限于像**Dota**或**AlphaGo**这样的专业应用，机器学习也进入了相当标准的应用，如机器翻译、图像处理和语音识别。
- en: 'This adoption is powered by developments in infrastructure, especially in terms
    of the utilization of computation power. It has unlocked the potential of deep
    learning and ML.. We can observe deep learning breakthroughs correlated with computation
    developments in *Figure 1.1* (sourced from OpenAI: [https://openai.com/blog/ai-and-compute](https://openai.com/blog/ai-and-compute)):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这种采用得益于基础设施的发展，特别是在计算能力的利用方面。它释放了深度学习和机器学习的潜力。我们可以从*图1.1*（来源：OpenAI：[https://openai.com/blog/ai-and-compute](https://openai.com/blog/ai-and-compute)）中观察到与计算发展相关的深度学习突破：
- en: '![Figure 1.1 – Demand for deep learning over time supported by computation'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.1 – 随时间推移由计算支持的深度学习需求'
- en: '](img/B16572_01_01.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_01_01.jpg)'
- en: Figure 1.1 – Demand for deep learning over time supported by computation
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – 随时间推移由计算支持的深度学习需求
- en: These breakthroughs in deep learning are enabled by the exponential growth in
    computing, which increases around 35 times every 18 months. Looking ahead in time,
    with such demands we may hit roadblocks in terms of scaling up central computing
    for CPUs, GPUs, or TPUs. This has forced us to look at alternatives such as **distributed
    learning** where computation for data processing is distributed across multiple
    computation nodes. We have seen some breakthroughs in distributed learning, such
    as federated learning and edge computing approaches. Distributed learning has
    shown promise to serve the growing demands of deep learning.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习领域的这些突破得益于计算能力的指数级增长，大约每18个月增长35倍。展望未来，面对这样的需求，我们可能会在扩大CPU、GPU或TPU的中心计算规模方面遇到瓶颈。这迫使我们考虑替代方案，例如**分布式学习**，其中数据处理计算分布在多个计算节点上。我们已经看到了分布式学习的一些突破，例如联邦学习和边缘计算方法。分布式学习有望满足深度学习不断增长的需求。
- en: The end of Moore's law
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摩尔定律的终结
- en: Prior to 2012, AI results closely tracked Moore's law, with compute doubling
    every 2 years. Post-2012, compute has been doubling every 3.4 months (sourced
    from AI Index 2019 – [https://hai.stanford.edu/research/ai-index-2019](https://hai.stanford.edu/research/ai-index-2019)).
    We can observe from *Figure 1.1* that demand for deep learning and **high-performance
    computing** (**HPC**) has been increasing exponentially with around 35x growth
    in computing every 18 months whereas Moore's law is seen to be outpaced (2x every
    18 months). Moore's law is still applicable to the case of CPUs (single-core performance)
    but not to new hardware architectures such as GPUs and TPUs. This makes Moore's
    law obsolete and outpaced in contrast to current demands and trends.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在2012年之前，AI的结果与摩尔定律紧密相关，计算能力每两年翻一番。2012年之后，计算能力每3.4个月翻一番（来源：2019年AI指数 – [https://hai.stanford.edu/research/ai-index-2019](https://hai.stanford.edu/research/ai-index-2019)）。从*图1.1*中我们可以观察到，深度学习和高性能计算（HPC）的需求正以每18个月约35倍的速度呈指数增长，而摩尔定律似乎已经落后（每18个月翻一番）。摩尔定律仍然适用于CPU（单核性能）的情况，但不适用于GPU和TPU等新的硬件架构。这使得摩尔定律在当前需求和趋势面前变得过时和落后。
- en: AI-centric applications
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以AI为中心的应用程序
- en: 'Applications are becoming AI-centric – we see that across multiple industries.
    Virtually every application is starting to use AI, and these applications are
    running separately on distributed workloads such as **HPC**, **microservices**,
    and **big data**, as shown in *Figure 1.2*:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序正变得越来越以AI为中心——我们在多个行业中都能看到这一点。几乎每个应用程序都开始使用AI，并且这些应用程序正在分布式工作负载上分别运行，如图*图1.2*所示：**高性能计算**（HPC）、**微服务**和**大数据**：
- en: '![Figure 1.2 – Applications running on distributed workloads'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.2 – 在分布式工作负载上运行的应用程序'
- en: '](img/B16572_01_002.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_01_002.jpg)'
- en: Figure 1.2 – Applications running on distributed workloads
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – 在分布式工作负载上运行的应用程序
- en: By combining HPC and AI, we can enable the benefits of computation needed to
    train deep learning and ML models. With the overlapping of big data and AI, we
    can leverage extracting required data at scale for AI model training, and with
    the overlap of microservices and AI we can serve the AI models for inference to
    enhance business operations and impact. This way, distributed applications have
    become the new norm. Developing AI-centric applications at scale requires a synergy
    of distributed applications (HPC, microservices, and big data) and for this, a
    new way of developing software is required.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合高性能计算（HPC）和人工智能（AI），我们可以实现训练深度学习（deep learning）和机器学习（ML）模型所需的计算优势。随着大数据和AI的融合，我们可以利用大规模提取所需数据来训练AI模型，并且随着微服务（microservices）和AI的融合，我们可以为推理服务AI模型，以增强业务运营和影响。这样，分布式应用已成为新的常态。在规模上开发以AI为中心的应用需要分布式应用（HPC、微服务和大数据）的协同作用，为此，需要一种新的软件开发方式。
- en: Software development evolution
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 软件开发演变
- en: 'Software development has evolved hand in hand with infrastructural developments
    to facilitate the efficient development of applications using the infrastructure.
    Traditionally, software development started with the waterfall method of development
    where development is done linearly by gathering requirements to design and develop.
    The waterfall model has many limitations, which led to the evolution of software
    development over the years in the form of Agile methodologies and the DevOps method,
    as shown in *Figure 1.3*:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发与基础设施的发展同步演变，以促进使用该基础设施高效地开发应用程序。传统上，软件开发从瀑布模型开始，开发是线性的，从收集需求到设计和开发。瀑布模型有许多局限性，这导致了多年来软件开发以敏捷方法（Agile
    methodologies）和DevOps方法的形式演变，如图*图1.3*所示：
- en: '![Figure 1.3 – Software development evolution'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 1.3 – Software development evolution](img/Figure_1.3_Software_development_evolution.jpg)'
- en: '](img/B16572_01_003.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![B16572_01_003.jpg](img/B16572_01_003.jpg)'
- en: Figure 1.3 – Software development evolution
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – 软件开发演变
- en: The waterfall method
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 瀑布模型
- en: 'The **waterfall method** was used to develop software from the onset of the
    internet age (~1995). It is a non-iterative way of developing software. It is
    delivered in a unidirectional way. Every stage is pre-organized and executed one
    after another, starting from requirements gathering to software design, development,
    and testing. The waterfall method is feasible and suitable when requirements are
    well-defined, specific, and do not change over time. Hence this is not suitable
    for dynamic projects where requirements change and evolve as per user demands.
    In such cases, where there is continuous modification, the waterfall method cannot
    be used to develop software. These are the major disadvantages of waterfall development
    methods:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**瀑布模型**从互联网时代开始（约1995年）就被用来开发软件。这是一种非迭代的软件开发方式。它以单向的方式交付。每个阶段都是预先组织和执行的，从需求收集到软件设计、开发和测试。当需求明确、具体且不随时间变化时，瀑布模型是可行且合适的。因此，它不适合需求会变化和根据用户需求演变的动态项目。在这种情况下，如果存在持续的修改，就不能使用瀑布模型来开发软件。这些都是瀑布开发方法的主要缺点：'
- en: The entire set of requirements has to be given before starting the development;
    modifying them during or after the project development is not possible.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在开始开发之前必须给出整个需求集；在项目开发期间或之后修改它们是不可能的。
- en: There are fewer chances to create or implement reusable components.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很少有机会创建或实现可重用的组件。
- en: Testing can only be done after the development is finished. Testing is not intended
    to be iterable; it is not possible to go back and fix anything once it is done.
    Moreover, customer acceptance tests often introduced changes, resulting in a delay
    in delivery and high costs. This way of development and testing can have a negative
    impact on the project delivery timeline and costs.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试只能在开发完成后进行。测试不是可迭代的；一旦完成，就无法回去修复任何东西。此外，客户验收测试经常引入变化，导致交付延迟和成本高昂。这种开发和测试方式可能会对项目交付时间表和成本产生负面影响。
- en: Most of the time, users of the system are provisioned with a system based on
    the developer's understanding, which is not user-centric and can come short of
    meeting their needs.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数情况下，系统的用户都是基于开发者的理解来配置的，这种系统不是以用户为中心的，可能无法满足他们的需求。
- en: The Agile method
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 敏捷方法
- en: 'The **Agile method** facilitates an iterative and progressive approach to software
    development. Unlike the waterfall method, Agile approaches are precise and user-centric.
    The method is bidirectional and often involves end users or customers in the development
    and testing process so they have the opportunity to test, give feedback, and suggest
    improvements throughout the project development process and phases. Agile has
    several advantages over the waterfall method:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**敏捷方法**促进了软件开发的迭代和渐进式方法。与瀑布方法不同，敏捷方法精确且以用户为中心。该方法是双向的，通常涉及最终用户或客户参与开发和测试过程，以便他们在项目开发过程和阶段中有机会测试、提供反馈和提出改进建议。敏捷方法相对于瀑布方法有以下几个优点：'
- en: Requirements are defined before starting the development, but they can be modified
    at any time.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在开始开发之前定义需求，但它们可以在任何时候进行修改。
- en: It is possible to create or implement reusable components.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有可能创建或实现可重用组件。
- en: The solution or project can be modular by segregating the project into different
    modules that are delivered periodically.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决方案或项目可以通过将项目划分为不同的模块并定期交付来模块化。
- en: The users or customers can co-create by testing and evaluating developed solution
    modules periodically to ensure the business needs are satisfied. Such a user-centric
    process ensures quality outcomes focused on meeting customer and business needs.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户或客户可以通过定期测试和评估开发解决方案模块来共同创造，以确保满足业务需求。这样的以用户为中心的过程确保了关注满足客户和业务需求的质量结果。
- en: 'The following diagram shows the difference between **Waterfall** and **Agile**
    methodologies:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表显示了**瀑布**和**敏捷**方法之间的差异：
- en: '![Figure 1.4 – Difference between waterfall and agile methods'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.4 – 瀑布模型与敏捷方法之间的差异'
- en: '](img/B16572_01_004.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16572_01_004.jpg]'
- en: Figure 1.4 – Difference between waterfall and agile methods
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – 瀑布模型与敏捷方法之间的差异
- en: The DevOps method
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DevOps方法
- en: The **DevOps method** extends agile development practices by further streamlining
    the movement of software change through the *build*, *test*, *deploy*, and *delivery*
    stages. DevOps empowers cross-functional teams with the autonomy to execute their
    software applications driven by continuous integration, continuous deployment,
    and continuous delivery. It encourages collaboration, integration, and automation
    among software developers and IT operators to improve the efficiency, speed, and
    quality of delivering customer-centric software. DevOps provides a streamlined
    software development framework for designing, testing, deploying, and monitoring
    systems in production. DevOps has made it possible to ship software to production
    in minutes and to keep it running reliably.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**DevOps方法**通过进一步简化软件变更在**构建**、**测试**、**部署**和**交付**阶段之间的流动，扩展了敏捷开发实践。DevOps赋予跨职能团队执行由持续集成、持续部署和持续交付驱动的软件应用的自主权。它鼓励软件开发人员和IT操作人员之间的协作、集成和自动化，以提高以客户为中心的软件交付的效率、速度和质量。DevOps为设计、测试、部署和监控生产环境中的系统提供了一个简化的软件开发框架。DevOps使得软件能够在几分钟内发布到生产环境，并保持其稳定运行。'
- en: Traditional software development challenges
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统软件开发挑战
- en: In the previous section, we observed the shift in traditional software development
    from the waterfall model to agile and DevOps practices. Agile and DevOps practices
    have enabled companies to ship software reliably. DevOps has made it possible
    to ship software to production in minutes and to keep it running reliably. This
    approach has been so successful that many companies are already adopting it, so
    why can't we keep doing the same thing for ML applications?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们观察了传统软件开发从瀑布模型向敏捷和DevOps实践的转变。敏捷和DevOps实践使公司能够可靠地发布软件。DevOps使得软件能够在几分钟内发布到生产环境，并保持其稳定运行。这种方法如此成功，以至于许多公司已经开始采用它，那么为什么我们不能继续为机器学习应用做同样的事情呢？
- en: 'The leading cause is that there''s a fundamental difference between ML development
    and traditional software development: *Machine learning is not just code; it is
    code plus data*. A ML model is created by applying an algorithm (via code) to
    fit the data to result in a ML model, as shown in *Figure 1.5*:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 主要原因是机器学习开发与传统软件开发之间存在根本性的差异：*机器学习不仅仅是代码；它是代码加上数据*。一个机器学习模型是通过应用算法（通过代码）来拟合数据，从而生成一个机器学习模型，如图*1.5*所示：
- en: '![Figure 1.5 – Machine learning = data + code'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.5 – 机器学习 = 数据 + 代码'
- en: '](img/B16572_01_005.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16572_01_005.jpg]'
- en: Figure 1.5 – Machine learning = data + code
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 – 机器学习 = 数据 + 代码
- en: 'While code is meticulously crafted in the development environment, data comes
    from multiple sources for training, testing, and inference. It is robust and changing
    over time in terms of volume, velocity, veracity, and variety. To keep up with
    evolving data, code evolves over time. For perspective, their relationship can
    be observed as if code and data live in separate planes that share the time dimension
    but are independent in all other aspects. The challenge of an ML development process
    is to create a bridge between these two planes in a controlled way:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发环境中，代码被精心制作，而数据则来自多个来源，用于训练、测试和推理。数据在体积、速度、真实性和多样性方面随着时间的推移而变得强大且不断变化。为了跟上数据的发展，代码也会随着时间的推移而演变。为了有更直观的了解，它们之间的关系可以观察为代码和数据生活在不同的平面上，这些平面共享时间维度，但在所有其他方面都是独立的。ML开发过程的挑战在于以受控的方式在这两个平面之间建立桥梁：
- en: '![Figure 1.6 – Data and code progression over time'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.6 – 随时间推移的数据和代码进展'
- en: '](img/B16572_01_006.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_01_006.jpg)'
- en: Figure 1.6 – Data and code progression over time
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 – 随时间推移的数据和代码进展
- en: Data and code, with the progression of time, end up going in two directions
    with one objective of building and maintaining a robust and scalable ML system.
    This disconnect causes several challenges that need to be solved by anyone trying
    to put a ML model in production. It comes with challenges such as slow, brittle,
    fragmented, and inconsistent deployment, and a lack of reproducibility and traceability.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，数据和代码最终走向两个方向，目标都是构建和维护一个强大且可扩展的ML系统。这种脱节导致了许多挑战，任何试图将ML模型投入生产的人都必须解决这些挑战。它带来了诸如缓慢、脆弱、碎片化和不一致的部署，以及缺乏可重复性和可追溯性的挑战。
- en: 'To overcome these challenges, MLOps offers a systematic approach by bridging
    data and code together over the progression of time. This is the solution to challenges
    posed by traditional software development methods with regard to ML applications.
    Using the MLOps method, data and code progress over time in one direction with
    one objective of building and maintaining a robust and scalable ML system:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些挑战，MLOps通过在时间进程中将数据和代码结合起来，提供了一种系统性的方法。这是解决传统软件开发方法在ML应用方面所提出的挑战的解决方案。使用MLOps方法，数据和代码随着时间的推移在一个方向上进步，目标是构建和维护一个强大且可扩展的ML系统：
- en: '![Figure 1.7 – MLOps – data and code progressing together'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.7 – MLOps – 数据和代码共同进步'
- en: '](img/B16572_01_007.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_01_007.jpg)'
- en: Figure 1.7 – MLOps – data and code progressing together
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 – MLOps – 数据和代码共同进步
- en: MLOps facilitates ML model development, deployment, and monitoring in a streamlined
    and systematic approach. It empowers data science and IT teams to collaborate,
    validate, and govern their operations. All the operations executed by the teams
    are recorded or audited, end-to-end traceable, and repeatable. In the coming sections,
    we will learn how MLOps enables data science and IT teams to build and maintain
    robust and scalable ML systems.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps通过一种简化和系统化的方法促进ML模型的发展、部署和监控。它使数据科学和IT团队能够协作、验证和治理他们的操作。团队执行的所有操作都被记录或审计，端到端可追溯且可重复。在接下来的章节中，我们将学习MLOps如何使数据科学和IT团队能够构建和维护强大且可扩展的ML系统。
- en: Trends of ML adoption in software development
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件开发中机器学习采用的趋势
- en: 'Before we delve into the workings of the MLOps method and workflow, it is beneficial
    to understand the big picture and trends as to where and how MLOps is disrupting
    the world. As many applications are becoming AI-centric, software development
    is evolving to facilitate ML. ML will increasingly become part of software development,
    mainly due to the following reasons:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨MLOps方法和工作流程之前，了解MLOps在全球范围内如何颠覆以及其大图景和趋势是有益的。由于许多应用正变得以AI为中心，软件开发正在演变以促进ML。ML将越来越多地成为软件开发的一部分，主要原因如下：
- en: '**Investments**: In 2019, investments in global private AI clocked over $70
    billion, with start-up investments related to AI over $37 billion, M&A $34 billion,
    IPOs $5 billion, and minority stake valued at around $2 billion. The forecast
    for AI globally shows fast growth in market value as AI reached $9.5 billion in
    2018 and is anticipated to reach a market value of $118 billion by 2025\. It has
    been assessed that growth in economic activity resulting from AI until 2030 will
    be of high value and significance. Currently, the US attracts ~50% of global VC
    funding, China ~39%, and 11% goes to Europe.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**投资**：2019年，全球私人人工智能投资超过700亿美元，其中与人工智能相关的初创企业投资超过370亿美元，并购投资340亿美元，首次公开募股（IPO）50亿美元，以及约20亿美元的少数股权。全球人工智能的市场价值预测显示，随着2018年人工智能达到95亿美元，预计到2025年将达到1180亿美元。据评估，到2030年，由人工智能引发的经济活动增长将具有很高的价值和意义。目前，美国吸引了约50%的全球风险投资（VC），中国约39%，11%流向欧洲。'
- en: '**Big data**: Data is exponentially growing in volume, velocity, veracity,
    and variety. For instance, observations suggest data growing in volume at 61%
    per annum in Europe, and it is anticipated that four times more data will be created
    by 2025 than exists today. Data is a requisite raw material for developing AI.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大数据**：数据在量、速度、真实性和多样性方面呈指数级增长。例如，观察表明，在欧洲，数据量每年增长61%，预计到2025年，将比现在多出四倍的数据。数据是开发人工智能的必需原材料。'
- en: '**Infrastructural developments and adoption**: Moore''s law has been closely
    tracked and observed to have been realized prior to 2012\. Post-2012, compute
    has been doubling every 3.4 months.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施发展和采用**：摩尔定律一直被密切关注，并在2012年之前得以实现。2012年之后，计算能力每3.4个月翻一番。'
- en: '**Increasing research and development**: AI research has been prospering in
    quality and quantity. A prominent growth of 300% is observed in the volume of
    peer-reviewed AI papers from 1998 to 2018, summing up to 9% of published conference
    papers and 3% of peer-reviewed journal publications.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**研发增长**：人工智能研究在质量和数量上都在蓬勃发展。从1998年到2018年，同行评审的人工智能论文数量增长了300%，总计占已发表会议论文的9%和同行评审期刊发表的3%。'
- en: '**Industry**: Based on a surveyed report, 47% of large companies have reported
    having adopted AI in at least one function or business unit. In 2019, it went
    up to 58% and is expected to increase.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**产业**：根据一份调查报告，47%的大公司报告称至少在一个职能或业务单元中采用了人工智能。到2019年，这一比例上升至58%，预计还将继续增长。'
- en: Information
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 信息
- en: These points have been sourced from policy and investment recommendations for
    trustworthy AI – European commission ([https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence](https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence))
    and AI Index 2019 ([https://hai.stanford.edu/research/ai-index-2019](https://hai.stanford.edu/research/ai-index-2019)).
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些观点来源于对可信赖人工智能的政策和投资建议——欧洲委员会([https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence](https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence))和AI指数2019([https://hai.stanford.edu/research/ai-index-2019](https://hai.stanford.edu/research/ai-index-2019))。
- en: All these developments indicate a strong push toward the industrialization of
    AI, and this is possible by bridging industry and research. MLOps will play a
    key role in the industrialization of AI. If you invest in learning this method,
    it will give you a headstart in your company or team and you could be a catalyst
    for operationalizing ML and industrializing AI.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些发展都表明，人工智能的工业化进程正在加速，这是通过连接产业和研究实现的。MLOps将在人工智能的工业化中扮演关键角色。如果你投资学习这种方法，它将使你在公司或团队中领先一步，你可能会成为实现机器学习和工业化的催化剂。
- en: So far, we have learned about some challenges and developments in IT, software
    development, and AI. Next, we will delve into understanding MLOps conceptually
    and learn in detail about a generic MLOps workflow that can be used commonly for
    any use case. These fundamentals will help you get a firm grasp of MLOps.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了IT、软件开发和人工智能的一些挑战和发展。接下来，我们将从概念上深入了解MLOps，并详细学习一个通用的MLOps工作流程，该流程可以用于任何用例。这些基础知识将帮助你牢固掌握MLOps。
- en: Understanding MLOps
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解MLOps
- en: Software development is interdisciplinary and is evolving to facilitate ML.
    MLOps is an emerging method to fuse ML with software development by integrating
    multiple domains as MLOps combines ML, DevOps, and data engineering, which aims
    to build, deploy, and maintain ML systems in production reliably and efficiently.
    Thus, MLOps can be expounded by this intersection.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发是跨学科的，并且正在不断发展以促进机器学习。MLOps 是一种新兴的方法，通过整合多个领域（MLOps 结合了机器学习、DevOps 和数据工程），将机器学习与软件开发融合，旨在在生产环境中可靠且高效地构建、部署和维护机器学习系统。因此，MLOps
    可以通过这种交叉点来阐述。
- en: '![Figure 1.8 – MLOps intersection'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.8 – MLOps 交叉点'
- en: '](img/B16572_01_008.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_01_008.jpg)'
- en: Figure 1.8 – MLOps intersection
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8 – MLOps 交叉点
- en: 'To make this intersection (MLOps) operational, I have designed a modular framework
    by following the systematic *design science method proposed by Wieringa* ([https://doi.org/10.1007/978-3-662-43839-8](https://doi.org/10.1007/978-3-662-43839-8))
    to develop a workflow to bring these three together (Data Engineering, Machine
    Learning, and *DevOps*). Design science goes with the application of design to
    problems and context. Design science is the design and investigation of artifacts
    in a context. The artifact in this case is the MLOps workflow, which is designed
    iteratively by interacting with problem contexts (industry use cases for the application
    of AI):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个交叉点（MLOps）能够运行，我遵循了 Wieringa 提出的系统化**设计科学方法**([https://doi.org/10.1007/978-3-662-43839-8](https://doi.org/10.1007/978-3-662-43839-8))设计了一个模块化框架，以开发一个工作流程，将这三个领域（数据工程、机器学习和
    *DevOps*）结合起来。设计科学伴随着将设计应用于问题和情境。在这个案例中，工件是 MLOps 工作流程，它是通过迭代与问题情境（AI 应用案例的行业用例）交互而设计的。设计科学是在情境中对工件的设计和研究。在这个案例中，工件是
    MLOps 工作流程，它是通过迭代与问题情境（AI 应用的行业用例）交互而设计的：
- en: '![Figure 1.9 – Design science workflow'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.9 – 设计科学工作流程'
- en: '](img/B16572_01_009.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_01_009.jpg)'
- en: Figure 1.9 – Design science workflow
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9 – 设计科学工作流程
- en: In a structured and iterative approach, the implementation of two cycles (the
    design cycle and the empirical cycle) was done for qualitative and quantitative
    analysis for MLOps workflow design through iterations. As a result of these cycles,
    an MLOps workflow is developed and validated by applying it to multiple problem
    contexts, that is, tens of ML use cases (for example, anomaly detection, real-time
    trading, predictive maintenance, recommender systems, virtual assistants, and
    so on) across multiple industries (for example, finance, manufacturing, healthcare,
    retail, the automotive industry, energy, and so on). I have applied and validated
    this MLOps workflow successfully in various projects across multiple industries
    to operationalize ML. In the next section, we will go through the concepts of
    the MLOps workflow designed as a result of the design science process.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 采用结构化和迭代的方法，通过迭代对 MLOps 工作流程设计进行了定性和定量分析，包括两个周期（设计周期和经验周期）。这些周期导致开发并验证了一个 MLOps
    工作流程，通过将其应用于多个问题情境，即跨多个行业的数十个机器学习用例（例如，异常检测、实时交易、预测性维护、推荐系统、虚拟助手等）。我已经在多个行业的多个项目中成功应用并验证了这个
    MLOps 工作流程，以实施机器学习。在下一节中，我们将探讨设计科学过程的结果所设计的 MLOps 工作流程的概念。
- en: Concepts and workflow of MLOps
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLOps 的概念和工作流程
- en: 'In this section, we will learn about a generic MLOps workflow; it is the result
    of many design cycle iterations as discussed in the previous section. It brings
    together data engineering, ML, and DevOps in a streamlined fashion. *Figure 1.10*
    is a generic MLOps workflow; it is modular and flexible and can be used to build
    proofs of concept or to operationalize ML solutions in any business or industry:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解一个通用的 MLOps 工作流程；它是通过前述章节中讨论的许多设计周期迭代的结果。它以简化的方式将数据工程、机器学习和 DevOps
    结合起来。*图 1.10* 是一个通用的 MLOps 工作流程；它是模块化和灵活的，可用于构建概念验证或在任何商业或行业中实施机器学习解决方案：
- en: '![Figure 1.10 – MLOps workflow'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.10 – MLOps 工作流程'
- en: '](img/B16572_01_010.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_01_010.jpg)'
- en: Figure 1.10 – MLOps workflow
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.10 – MLOps 工作流程
- en: 'This workflow is segmented into two modules:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 此工作流程分为两个模块：
- en: '**MLOps pipeline** (build, deploy, and monitor) – the upper layer'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLOps 管道**（构建、部署和监控）– 上层'
- en: '**Drivers**: Data, code, artifacts, middleware, and infrastructure – mid and
    lower layers'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**驱动因素**：数据、代码、工件、中间件和基础设施 – 中下层'
- en: The upper layer is the MLOps pipeline (build, deploy, and monitor), which is
    enabled by drivers such as data, code, artifacts, middleware, and infrastructure.
    The MLOps pipeline is powered by an array of services, drivers, middleware, and
    infrastructure, and it crafts ML-driven solutions. By using this pipeline, a business
    or individual(s) can do quick prototyping, testing, and validating and deploy
    the model(s) to production at scale frugally and efficiently.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 上层是MLOps管道（构建、部署和监控），它由数据、代码、工件、中间件和基础设施等驱动程序启用。MLOps管道由一系列服务、驱动程序、中间件和基础设施提供动力，并构建ML驱动的解决方案。通过使用此管道，企业或个人可以快速进行原型设计、测试和验证，并以经济高效的方式将模型（s）部署到生产环境中。
- en: To understand the workings and implementation of the MLOps workflow, we will
    look at the implementation of each layer and step using a figurative business
    use case.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解MLOps工作流程的运作和实现，我们将通过一个比喻性的商业案例来查看每一层和每一步的实现。
- en: Discussing a use case
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论用例
- en: In this use case, we are to operationalize (prototyping and deploying for production)
    an image classification service to classify cats and dogs in a pet park in Barcelona,
    Spain. The service will identify cats and dogs in real time from the inference
    data coming from a CCTV camera installed in the pet park.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个用例中，我们需要将（原型设计和部署到生产环境）一个图像分类服务进行运营，以对位于西班牙巴塞罗那的宠物公园中的猫和狗进行分类。该服务将实时从安装在宠物公园的监控摄像头中获取的推理数据中识别猫和狗。
- en: 'The pet park provide you access to the data and infrastructure needed to operationalize
    the service:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 宠物公园为您提供访问数据和基础设施的权限，以实现服务的运营：
- en: '**Data**: The pet park has given you access to their data lake containing 100,000
    labeled images of cats and dogs, which we will use for training the model.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据**: 宠物公园已经为您提供了访问其数据湖的权限，其中包含10万张标记好的猫和狗的图片，我们将使用这些图片来训练模型。'
- en: '**Infrastructure**: Public cloud (IaaS).'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施**: 公共云（IaaS）。'
- en: This use case resembles a real-life use case for operationalizing ML and is
    used to explain the workings and implementation of the MLOps workflow. Remember
    to look for an explanation for the implementation of this use case at every segment
    and step of the MLOps workflow. Now, let's look at the workings of every layer
    and step in detail.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用例类似于实际生活中的ML运营用例，用于解释MLOps工作流程的运作和实现。请记住，在每个MLOps工作流程的每个部分和步骤中寻找对这个用例实现的解释。现在，让我们详细查看每一层和每一步的运作。
- en: The MLOps pipeline
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MLOps管道
- en: The MLOps pipeline is the upper layer, which performs operations such as build,
    deploy, and monitor, which work modularly in sync with each other. Let's look
    into each module's functionality.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps管道是上层，执行构建、部署和监控等操作，这些操作以模块化方式相互同步。让我们深入了解每个模块的功能。
- en: Build
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 构建
- en: 'The build module has the core ML pipeline, and this is purely for training,
    packaging, and versioning the ML models. It is powered by the required compute
    (for example, the CPU or GPU on the cloud or distributed computing) resources
    to run the ML training and pipeline:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 构建模块包含核心ML管道，这纯粹是为了训练、打包和版本控制ML模型。它由运行ML训练和管道所需的计算资源（例如，云或分布式计算中的CPU或GPU）提供动力：
- en: '![Figure 1.11 – MLOps – build pipeline'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.11 – MLOps – 构建管道'
- en: '](img/B16572_01_11.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_01_11.jpg)'
- en: Figure 1.11 – MLOps – build pipeline
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.11 – MLOps – 构建管道
- en: 'The pipeline works from left to right. Let''s look at the functionality of
    each step in detail:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 管道从左到右工作。让我们详细查看每一步的功能：
- en: '**Data ingestion**: This step is a trigger step for the ML pipeline. It deals
    with the volume, velocity, veracity, and variety of data by extracting data from
    various data sources (for example, databases, data warehouses, or data lakes)
    and ingesting the required data for the model training step. Robust data pipelines
    connected to multiple data sources enable it to perform **extract, transform,
    and load** (**ETL**) operations to provide the necessary data for ML training
    purposes. In this step, we can split and version data for model training in the
    required format (for example, the training or test set). As a result of this step,
    any experiment (that is, model training) can be audited and is back-traceable.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据摄取**: 这一步是ML管道的触发步骤。它通过从各种数据源（例如，数据库、数据仓库或数据湖）提取数据，并摄取模型训练步骤所需的必要数据来处理数据的量、速度、真实性和多样性。连接到多个数据源的健壮数据管道能够执行**提取、转换和加载**（**ETL**）操作，为ML训练提供必要的数据。在这一步中，我们可以根据所需格式（例如，训练集或测试集）对数据进行拆分和版本控制。因此，任何实验（即模型训练）都可以进行审计，并且可以回溯。'
- en: 'For a better understanding of the data ingestion step, here is the previously
    described use case implementation:'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了更好地理解数据摄取步骤，以下是之前描述的用例实现：
- en: '*Use case implementation*'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例实现*'
- en: 'As you have access to the pet park''s data lake, you can now procure data to
    get started. Using data pipelines (part of the data ingestion step), you do the
    following:'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于你有访问宠物公园数据湖的权限，你现在可以获取数据以开始。使用数据管道（数据摄取步骤的一部分），你执行以下操作：
- en: 1\. Extract, transform, and load 100,000 images of cats and dogs.
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 1. 提取、转换并加载10万张猫和狗的图片。
- en: 2\. Split and version this data into a train and test split (with an 80% and
    20% split).
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2. 将这些数据分割并版本化为训练集和测试集（80%和20%的分割）。
- en: Versioning this data will enable end-to-end traceability for trained models.
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对数据进行版本控制将使训练的模型实现端到端的可追溯性。
- en: Congrats – now you are ready to start training and testing the ML model using
    this data.
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 恭喜——现在你已准备好开始使用这些数据训练和测试机器学习模型。
- en: '**Model training**: After procuring the required data for ML model training
    in the previous step, this step will enable model training; it has modular scripts
    or code that perform all the traditional steps in ML, such as data preprocessing,
    feature engineering, and feature scaling before training or retraining any model.
    Following this, the ML model is trained while performing hyperparameter tuning
    to fit the model to the dataset (training set). This step can be done manually,
    but efficient and automatic solutions such as **Grid Search** or **Random Search**
    exist. As a result, all important steps of ML model training are executed with
    a ML model as the output of this step.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型训练**：在上一步骤中获取了用于机器学习模型训练所需的数据后，这一步骤将启用模型训练；它包含模块化脚本或代码，执行机器学习中的所有传统步骤，例如在训练或重新训练任何模型之前进行数据预处理、特征工程和特征缩放。随后，在执行超参数调整以使模型适应数据集（训练集）的过程中进行机器学习模型的训练。这一步骤可以手动完成，但存在如**网格搜索**或**随机搜索**等高效且自动的解决方案。因此，所有重要的机器学习模型训练步骤都通过这一步骤以机器学习模型作为输出执行。'
- en: '*Use case implementation*'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例实现*'
- en: 'In this step, we implement all the important steps to train the image classification
    model. The goal is to train a ML model to classify cats and dogs. For this case,
    we train a **convolutional neural network** (**CNN** – [https://towardsdatascience.com/wtf-is-image-classification-8e78a8235acb](https://towardsdatascience.com/wtf-is-image-classification-8e78a8235acb))
    for the image classification service. The following steps are implemented: data
    preprocessing, feature engineering, and feature scaling before training, followed
    by training the model with hyperparameter tuning. As a result, we have a CNN model
    to classify cats and dogs with 97% accuracy.'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这一步骤中，我们实现了训练图像分类模型的所有重要步骤。目标是训练一个机器学习模型来对猫和狗进行分类。为此案例，我们为图像分类服务训练了一个**卷积神经网络**（**CNN**
    – [https://towardsdatascience.com/wtf-is-image-classification-8e78a8235acb](https://towardsdatascience.com/wtf-is-image-classification-8e78a8235acb)）。以下步骤得到实现：训练前的数据预处理、特征工程和特征缩放，随后通过超参数调整训练模型。结果，我们得到了一个97%准确率的CNN模型来对猫和狗进行分类。
- en: '**Model testing**: In this step, we evaluate the trained model performance
    on a separated set of data points named test data (which was split and versioned
    in the data ingestion step). The inference of the trained model is evaluated according
    to selected metrics as per the use case. The output of this step is a report on
    the trained model''s performance.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型测试**：在这一步骤中，我们评估训练的模型在分离的数据点集（测试数据，在数据摄取步骤中分割并版本化）上的性能。根据用例选择指标评估训练模型的推理。这一步骤的输出是关于训练模型性能的报告。'
- en: '*Use case implementation*'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例实现*'
- en: We test the trained model on test data (we split data earlier in the *Data ingestion*
    step) to evaluate the trained model's performance. In this case, we look for precision
    and the recall score to validate the model's performance in classifying cats and
    dogs to assess false positives and true positives to get a realistic understanding
    of the model's performance. If and when we are satisfied with the results, we
    can proceed to the next step, or else reiterate the previous steps to get a decent
    performing model for the pet park image classification service.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在测试数据上测试训练的模型（我们在*数据摄取*步骤中较早分割了数据）以评估训练模型的性能。在这种情况下，我们寻找精确率和召回率来验证模型在分类猫和狗时的性能，以评估假阳性和真阳性，从而对模型性能有一个现实的理解。如果我们对结果满意，我们可以进入下一步，否则重复之前的步骤以获得一个适合宠物公园图像分类服务的良好性能模型。
- en: '**Model packaging**: After the trained model has been tested in the previous
    step, the model can be serialized into a file or containerized (using Docker)
    to be exported to the production environment.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型打包**：在前面步骤中对训练好的模型进行测试后，模型可以被序列化到文件或容器化（使用Docker）以导出到生产环境。'
- en: '*Use case implementation*'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例实现*'
- en: The model we trained and tested in the previous steps is serialized to an ONNX
    file and is ready to be deployed in the production environment.
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的步骤中训练和测试的模型被序列化为ONNX文件，并准备好在生产环境中部署。
- en: '**Model registering**: In this step, the model that was serialized or containerized
    in the previous step is registered and stored in the model registry. A registered
    model is a logical collection or package of one or more files that assemble, represent,
    and execute your ML model. For example, multiple files can be registered as one
    model. For instance, a classification model can be comprised of a vectorizer,
    model weights, and serialized model files. All these files can be registered as
    one single model. After registering, the model (all files or a single file) can
    be downloaded and deployed as needed.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型注册**：在这个步骤中，前面步骤中序列化或容器化的模型被注册并存储在模型注册表中。一个注册的模型是一个逻辑集合或包，它组装、表示和执行你的机器学习模型。例如，多个文件可以注册为一个模型。例如，一个分类模型可以由一个向量器、模型权重和序列化模型文件组成。所有这些文件都可以注册为一个单一模型。注册后，模型（所有文件或单个文件）可以根据需要下载和部署。'
- en: '*Use case implementation*'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例实现*'
- en: The serialized model in the previous step is registered on the model registry
    and is available for quick deployment into the pet park production environment.
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的步骤中序列化的模型已在模型注册表中注册，并可用于快速部署到宠物公园生产环境。
- en: By implementing the preceding steps, we successfully execute the ML pipeline
    designed for our use case. As a result, we have trained models on the model registry
    ready to be deployed in the production setup. Next, we will look into the workings
    of the deployment pipeline.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过实施前面的步骤，我们成功执行了为我们的用例设计的机器学习流程。因此，我们在模型注册表中训练了模型，准备在生产设置中部署。接下来，我们将探讨部署流程的工作原理。
- en: Deploy
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 部署
- en: 'The deploy module enables operationalizing the ML models we developed in the
    previous module (build). In this module, we test our model performance and behavior
    in a production or production-like (test) environment to ensure the robustness
    and scalability of the ML model for production use. *Figure 1.12* depicts the
    deploy pipeline, which has two components – production testing and production
    release – and the deployment pipeline is enabled by streamlined CI/CD pipelines
    connecting the development to production environments:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 部署模块使我们能够将前面模块（构建）中开发的机器学习模型进行操作化。在这个模块中，我们在生产环境或类似生产环境（测试）中对模型性能和行为进行测试，以确保机器学习模型在生产使用中的鲁棒性和可扩展性。*图1.12*
    描述了部署流程，该流程有两个组件 – 生产测试和生产发布 – 并且部署流程通过连接开发到生产环境的简化CI/CD管道来实现：
- en: '![Figure 1.12 – MLOps – deploy pipeline'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 1.12 – MLOps – deploy pipeline'
- en: '](img/B16572_01_12.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16572_01_12.jpg]'
- en: Figure 1.12 – MLOps – deploy pipeline
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.12 – MLOps – 部署流程
- en: 'It works from left to right. Let''s look at the functionality of each step
    in detail:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 它从左到右工作。让我们详细看看每个步骤的功能：
- en: '**Application testing**: Before deploying an ML model to production, it is
    vital to test its robustness and performance via testing. Hence we have the "application
    testing" phase where we rigorously test all the trained models for robustness
    and performance in a production-like environment called a test environment. In
    the application testing phase, we deploy the models in the test environment (pre-production),
    which replicates the production environment.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用测试**：在将机器学习模型部署到生产环境之前，通过测试来检验其鲁棒性和性能至关重要。因此，我们有一个“应用测试”阶段，在这个阶段，我们严格测试所有训练好的模型在类似生产环境的测试环境中对鲁棒性和性能。在应用测试阶段，我们在测试环境（预生产）中部署模型，该环境复制了生产环境。'
- en: The ML model for testing is deployed as an API or streaming service in the test
    environment to deployment targets such as Kubernetes clusters, container instances,
    or scalable virtual machines or edge devices as per the need and use case. After
    the model is deployed for testing, we perform predictions using test data (which
    is not used for training the model; test data is sample data from a production
    environment) for the deployed model, during which model inference in batch or
    periodically is done to test the model deployed in the test environment for robustness
    and performance.
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测试用的机器学习模型作为API或流式服务部署在测试环境中的部署目标，如Kubernetes集群、容器实例、可扩展的虚拟机或边缘设备，具体取决于需求和用例。在模型部署用于测试后，我们使用测试数据（这些数据未用于训练模型；测试数据是从生产环境中的样本数据）对部署的模型进行预测，在此期间对测试环境中部署的模型进行批量或定期推理以测试其鲁棒性和性能。
- en: The performance results are automatically or manually reviewed by a quality
    assurance expert. When the ML model's performance meets the standards, then it
    is approved to be deployed in the production environment where the model will
    be used to infer in batches or real time to make business decisions.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 性能结果由质量保证专家自动或手动审查。当机器学习模型的性能达到标准时，则批准其在生产环境中部署，在该环境中模型将被用于批量或实时推理以做出业务决策。
- en: '*Use case implementation*'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例实现*'
- en: We deploy the model as an API service on an on-premises computer in the pet
    park, which is set up for testing purposes. This computer is connected to a CCTV
    camera in the park to fetch real-time inference data to predict cats or dogs in
    the video frames. The model deployment is enabled by the CI/CD pipeline. In this
    step, we test the robustness of the model in a production-like environment, that
    is, whether the model is performing inference consistently, and an accuracy, fairness,
    and error analysis. At the end of this step, a quality assurance expert certifies
    the model if it meets the standards.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将模型作为API服务部署在宠物公园的本地计算机上，该计算机是为测试目的而设置的。该计算机连接到公园的CCTV摄像头，以获取实时推理数据来预测视频帧中的猫或狗。模型部署由CI/CD管道启用。在此步骤中，我们在类似生产的环境中测试模型的鲁棒性，即模型是否始终如一地进行推理，以及准确性、公平性和错误分析。在此步骤结束时，如果模型符合标准，则质量保证专家对模型进行认证。
- en: '**Production release**: Previously tested and approved models are deployed
    in the production environment for model inference to generate business or operational
    value. This production release is deployed to the production environment enabled
    by CI/CD pipelines.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生产发布**：之前测试和批准的模型部署在生产环境中进行模型推理以生成业务或运营价值。此生产发布由CI/CD管道部署到生产环境。'
- en: '*Use case implementation*'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例实现*'
- en: We deploy a previously tested and approved model (by a quality assurance expert)
    as an API service on a computer connected to CCTV in the pet park (production
    setup). This deployed model performs ML inference on the incoming video data from
    the CCTV camera in the pet park to classify cats or dogs in real time.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将之前经过测试和批准的模型（由质量保证专家进行）作为API服务部署在连接到宠物公园CCTV的计算机上（生产环境）。该部署模型对来自宠物公园CCTV摄像头的实时视频数据进行机器学习推理，以实时分类猫或狗。
- en: Monitor
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 监控
- en: 'The monitor module works in sync with the deploy module. Using explainable
    monitoring (discussed later in detail, in [*Chapter 11*](B16572_11_Final_JM_ePub.xhtml#_idTextAnchor206),
    *Key Principles for Monitoring Your ML System*), we can monitor, analyze, and
    govern the deployed ML application (ML model and application). Firstly, we can
    monitor the performance of the ML model (using pre-defined metrics) and the deployed
    application (using telemetry data). Secondly, model performance can be analyzed
    using a pre-defined explainability framework, and lastly, the ML application can
    be governed using alerts and actions based on the model''s quality assurance and
    control. This ensures a robust monitoring mechanism for the production system:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 监控模块与部署模块同步工作。使用可解释监控（将在[*第11章*](B16572_11_Final_JM_ePub.xhtml#_idTextAnchor206)，*监控您的机器学习系统的关键原则*）中详细讨论），我们可以监控、分析和治理部署的机器学习应用程序（机器学习模型和应用程序）。首先，我们可以监控机器学习模型（使用预定义的指标）和部署的应用程序（使用遥测数据）。其次，可以使用预定义的可解释性框架分析模型性能，最后，可以使用基于模型的质量保证和控制警报和操作来治理机器学习应用程序。这确保了生产系统的强大监控机制：
- en: '![Figure 1.13 – MLOps – monitor pipeline'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.13 – MLOps – 监控管道'
- en: '](img/B16572_01_13.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.13 – MLOps – 监控管道](img/B16572_01_13.jpg)'
- en: Figure 1.13 – MLOps – monitor pipeline
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.13 – MLOps – 监控管道
- en: 'Let''s see each of the abilities of the monitor module in detail:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细看看监控模块的每个能力：
- en: '**Monitor**: The monitoring module captures critical information to monitor
    data integrity, model drift, and application performance. Application performance
    can be monitored using telemetry data. It depicts the device performance of a
    production system over a period of time. With telemetry data such as accelerometer,
    gyroscope, humidity, magnetometer, pressure, and temperature we can keep a check
    on the production system''s performance, health, and longevity.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控**：监控模块捕获关键信息以监控数据完整性、模型漂移和应用性能。可以使用遥测数据来监控应用性能。它描绘了生产系统在一段时间内的设备性能。通过加速度计、陀螺仪、湿度、磁力计、压力和温度等遥测数据，我们可以监控生产系统的性能、健康和寿命。'
- en: '*Use case implementation*'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例实现*'
- en: In real time, we will monitor three things – data integrity, model drift, and
    application performance – for the deployed API service on the park's computer.
    Metrics such as accuracy, F1 score, precision, and recall are tracked to data
    integrity and model drift. We monitor application performance by tracking the
    telemetry data of the production system (the on-premises computer in the park)
    running the deployed ML model to ensure the proper functioning of the production
    system. Telemetry data is monitored to foresee any anomalies or potential failures
    and fix them in advance. Telemetry data is logged and can be used to assess production
    system performance over time to check its health and longevity.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在实时监控中，我们将监控公园计算机上部署的API服务的三个关键指标——数据完整性、模型漂移和应用性能。如准确性、F1分数、精确率和召回率等指标被跟踪以评估数据完整性和模型漂移。我们通过跟踪运行部署的机器学习模型的生产系统（公园中的本地计算机）的遥测数据来监控应用性能，以确保生产系统的正常运行。遥测数据被监控以预见任何异常或潜在的故障，并提前修复。遥测数据被记录，可以用来评估生产系统性能随时间的变化，以检查其健康和寿命。
- en: '**Analyze**: It is critical to analyze the model performance of ML models deployed
    in production systems to ensure optimal performance and governance in correlation
    to business decisions or impact. We use model explainability techniques to measure
    the model performance in real time. Using this, we evaluate important aspects
    such as model fairness, trust, bias, transparency, and error analysis with the
    intention of improving the model in correlation to business.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分析**：分析在生产系统中部署的机器学习模型的性能对于确保与业务决策或影响相关的最佳性能和治理至关重要。我们使用模型可解释性技术来实时衡量模型性能。利用这一点，我们评估模型公平性、可信度、偏差、透明度和错误分析等重要方面，目的是改善与业务相关的模型。'
- en: 'Over time, the statistical properties of the target variable we are trying
    to predict can change in unforeseen ways. This change is called "model drift,"
    for example, in a case where we have deployed a recommender system model to suggest
    suitable items for users. User behavior may change due to unforeseeable trends
    that could not be observed in historical data that was used for training the model.
    It is essential to consider such unforeseen factors to ensure deployed models
    provide the best and most relevant business value. When model drift is observed,
    then any of these actions should be performed:'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随着时间的推移，我们试图预测的目标变量的统计特性可能会以不可预见的方式发生变化。这种变化被称为“模型漂移”，例如，在我们部署推荐系统模型以向用户推荐合适的项目的情况下。由于无法观察到用于训练模型的历史数据中的不可预见趋势，用户行为可能会发生变化。考虑到这些不可预见因素，确保部署的模型提供最佳和最相关的业务价值至关重要。当观察到模型漂移时，应执行以下任何一项操作：
- en: a) The product owner or the quality assurance expert needs to be alerted.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 产品负责人或质量保证专家需要被通知。
- en: b) The model needs to be switched or updated.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 需要切换或更新模型。
- en: c) Re-training the pipeline should be triggered to re-train and update the model
    as per the latest data or needs.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 应触发管道的重新训练，以便根据最新的数据或需求重新训练和更新模型。
- en: '*Use case implementation*'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例实现*'
- en: We monitor the deployed model's performance in the production system (a computer
    connected to the CCTV in the pet park). We will analyze the accuracy, precision,
    and recall scores for the model periodically (once a day) to ensure the model's
    performance does not deteriorate below the threshold. When the model performance
    deteriorates below the threshold, we initiate system governing mechanisms (for
    example, a trigger to retrain the model).
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们监控在生产系统中部署的模型的表现（一个连接到宠物公园CCTV的电脑）。我们将定期（每天一次）分析模型的准确率、精确率和召回率，以确保模型的表现不会低于阈值。当模型的表现低于阈值时，我们将启动系统治理机制（例如，触发重新训练模型）。
- en: '**Govern**: Monitoring and analyzing is done to govern the deployed application
    to drive optimal performance for the business (or the purpose of the ML system).
    After monitoring and analyzing the production data, we can generate certain alerts
    and actions to govern the system. For example, the product owner or the quality
    assurance expert gets alerted when model performance deteriorates (for example,
    low accuracy, high bias, and so on) below a pre-defined threshold. The product
    owner initiates a trigger to retrain and deploy an alternative model. Lastly,
    an important aspect of governance is "compliance" with the local and global laws
    and rules. For compliance, model explainability and transparency are vital. For
    this, model auditing and reporting are done to provide end-to-end traceability
    and explainability for production models.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**治理**：监控和分析是为了治理部署的应用程序，以驱动业务（或机器学习系统的目的）的最佳性能。在监控和分析生产数据后，我们可以生成某些警报和行动来治理系统。例如，当模型的表现低于预先定义的阈值（例如，低准确率、高偏差等）时，产品负责人或质量保证专家会收到警报。产品负责人启动一个触发器来重新训练和部署替代模型。最后，治理的一个重要方面是“合规”与当地和全球的法律和规则。为了合规，模型的可解释性和透明度至关重要。为此，进行模型审计和报告，以提供生产模型端到端的可追溯性和可解释性。'
- en: '*Use case implementation*'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*用例实现*'
- en: We monitor and analyze the deployed model's performance in the production system
    (a computer connected to the CCTV in the pet park). Based on the analysis of accuracy,
    precision, and recall scores for the deployed model, periodically (once a day),
    alerts are generated when the model's performance deteriorates below the pre-defined
    threshold. The product owner of the park generates actions, and these actions
    are based on the alerts. For example, an alert is generated notifying the product
    owner that the production model is 30% biased to detect dogs more than cats. The
    product owner then triggers the model re-training pipeline to update the model
    using the latest data to reduce the bias, resulting in a fair and robust model
    in production. This way, the ML system at the pet park in Barcelona is well-governed
    to serve the business needs.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们监控和分析在生产系统中部署的模型的表现（一个连接到宠物公园CCTV的电脑）。基于对部署模型准确率、精确率和召回率的分析，定期（每天一次），当模型的表现低于预先定义的阈值时，会生成警报。公园的产品负责人会采取行动，这些行动基于警报。例如，生成一个警报通知产品负责人，生产模型检测狗比猫的偏差高达30%。然后，产品负责人触发模型重新训练流程，使用最新数据更新模型以减少偏差，从而在生产中实现公平且稳健的模型。这样，巴塞罗那宠物公园的机器学习系统得到了良好的治理，以满足业务需求。
- en: This brings us to the end of the MLOps pipeline. All models trained, deployed,
    and monitored using the MLOps method are end-to-end traceable and their lineage
    is logged in order to trace the origins of the model, which includes the source
    code the model used to train, the data used to train and test the model, and parameters
    used to converge the model. Full lineage is useful to audit operations or to replicate
    the model, or when a blocker is hit, the logged ML model lineage is useful to
    backtrack the origins of the model or to observe and debug the cause of the blocker.
    As ML models generate data in production during inference, this data can be tied
    to the model training and deployment lineage to ensure the end-to-end lineage,
    and this is important for certain compliance requirements. Next, we will look
    into key drivers enabling the MLOps pipeline.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这就带我们来到了 MLOps 管道的尽头。所有使用 MLOps 方法训练、部署和监控的模型都是端到端可追溯的，并且它们的血缘记录在案，以便追踪模型的起源，包括模型用于训练的源代码、用于训练和测试模型的数据以及用于收敛模型的参数。完整的血缘记录对于审计操作或复制模型非常有用，或者在遇到阻塞时，记录的
    ML 模型血缘记录有助于回溯模型的起源或观察和调试阻塞的原因。由于机器学习模型在推理过程中在生产中生成数据，这些数据可以与模型训练和部署血缘记录相关联，以确保端到端血缘记录，这对于某些合规性要求非常重要。接下来，我们将探讨使
    MLOps 管道得以实现的关键驱动因素。
- en: Drivers
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 驱动因素
- en: 'These are the key drivers for the MLOps pipeline: data, code, artifacts, middleware,
    and infrastructure. Let''s look into each of the drivers to get an overview of
    how they enable the MLOps pipeline:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是 MLOps 管道的驱动因素：数据、代码、工件、中间件和基础设施。让我们深入了解每个驱动因素，以了解它们如何使 MLOps 管道得以实现：
- en: '![Figure 1.14 – MLOps drivers'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.14 – MLOps 驱动因素'
- en: '](img/B16572_01_14.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B16572_01_14.jpg](img/B16572_01_14.jpg)'
- en: Figure 1.14 – MLOps drivers
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.14 – MLOps 驱动因素
- en: 'Each of the key drivers for the MLOps pipeline are defined as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps 管道的关键驱动因素如下定义：
- en: '**Data**: Data can be in multiple forms, such as text, audio, video, and images.
    In traditional software applications, data quite often tends to be structured,
    whereas, for ML applications, it can be structured or unstructured. To manage
    data in ML applications, data is handled in these steps: data acquisition, data
    annotation, data cataloging, data preparation, data quality checking, data sampling,
    and data augmentation. Each step involves its own life cycle. This makes a whole
    new set of processes and tools necessary for ML applications. For efficient functioning
    of the ML pipeline, data is segmented and versioned into training data, testing
    data, and monitoring data (collected in production, for example, model inputs,
    outputs, and telemetry data). These data operations are part of the MLOps pipeline.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据**：数据可以以多种形式存在，例如文本、音频、视频和图像。在传统的软件应用中，数据往往是有结构的，而对于机器学习应用来说，它可以是结构化的或非结构化的。为了管理机器学习应用中的数据，数据在这些步骤中处理：数据采集、数据标注、数据编目、数据准备、数据质量检查、数据抽样和数据增强。每个步骤都涉及它自己的生命周期。这使得为机器学习应用需要一套全新的流程和工具。为了使机器学习管道高效运行，数据被分割和版本化为训练数据、测试数据和监控数据（例如在生产中收集的模型输入、输出和遥测数据）。这些数据操作是
    MLOps 管道的一部分。'
- en: '**Code**: There are three essential modules of code that drive the MLOps pipeline:
    training code, testing code, and application code. These scripts or code are executed
    using the CI/CD and data pipelines to ensure the robust working of the MLOps pipeline.
    The source code management system (for example, using Git or Mercurial) will enable
    orchestration and play a vital role in managing and integrating seamlessly with
    CI, CD, and data pipelines. All of the code is staged and versioned in the source
    code management setup (for example, Git).'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码**：推动 MLOps 管道的三个基本代码模块是：训练代码、测试代码和应用代码。这些脚本或代码通过 CI/CD 和数据管道执行，以确保 MLOps
    管道的稳健运行。源代码管理系统（例如，使用 Git 或 Mercurial）将启用编排，并在管理和无缝集成 CI、CD 和数据管道中发挥关键作用。所有代码都在源代码管理设置中阶段化和版本化（例如，Git）。'
- en: '**Artifacts**: The MLOps pipeline generates artifacts such as data, serialized
    models, code snippets, system logs, ML model training, and testing metrics information.
    All these artifacts are useful for the successful working of the MLOps pipeline,
    ensuring its traceability and sustainability. These artifacts are managed using
    middleware services such as the model registry, workspaces, logging services,
    source code management services, databases, and so on.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工件**：MLOps管道生成诸如数据、序列化模型、代码片段、系统日志、机器学习模型训练和测试指标信息等工件。所有这些工件都对MLOps管道的成功运行非常有用，确保其可追溯性和可持续性。这些工件通过使用中间件服务（如模型注册、工作区、日志服务、源代码管理服务、数据库等）进行管理。'
- en: '**Middleware**: Middleware is computer software that offers services to software
    applications that are more than those available from the operating systems. Middleware
    services ensure multiple applications to automate and orchestrate processes for
    the MLOps pipeline. We can use a diverse set of middleware software and services
    depending on the use cases, for example, Git for source code management, VNets
    to enable the required network configurations, Docker for containerizing our models,
    and Kubernetes for container orchestration to automate application deployment,
    scaling, and management.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中间件**：中间件是向软件应用程序提供比操作系统提供的更多服务的计算机软件。中间件服务确保多个应用程序自动化和编排MLOps管道的过程。我们可以根据用例使用各种中间件软件和服务，例如，Git用于源代码管理，VNets用于启用所需的网络配置，Docker用于将我们的模型容器化，以及Kubernetes用于容器编排以自动化应用程序的部署、扩展和管理。'
- en: '**Infrastructure**: To ensure the successful working of the MLOps pipeline,
    we need essential compute and storage resources to train Test and deploy the ML
    models. Compute resources enable us to train, deploy and monitor our ML models.
    Two types of storages resources can facilitate ML operations, central storage
    and feature stores. A central storage stores the logs, artifacts, training, testing
    and monitoring data. A feature store is optional and complementary to central
    storage. It extracts, transforms and stores needed features for ML model training
    and inference using a feature pipeline. When it comes to the infrastructure, there
    are various options such as on-premises resources or **infrastructure as a service
    (IaaS)**, which is cloud services. These days, there are many cloud players providing
    IaaS, such as Amazon, Microsoft, Google, Alibaba, and so on. Having the right
    infrastructure for your use case will enable robust, efficient, and frugal operations
    for your team and company.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施**：为了确保MLOps管道的成功运行，我们需要必要的计算和存储资源来训练和部署机器学习模型。计算资源使我们能够训练、部署和监控我们的机器学习模型。有两种类型的存储资源可以促进机器学习操作，即中心存储和特征存储。中心存储存储日志、工件、训练、测试和监控数据。特征存储是可选的，与中心存储互补。它使用特征管道提取、转换和存储机器学习模型训练和推理所需的特征。在基础设施方面，有多种选择，例如本地资源或**基础设施即服务（IaaS）**，即云服务。如今，有许多云服务提供商提供IaaS，例如亚马逊、微软、谷歌、阿里巴巴等。为您的用例选择合适的基础设施将使您的团队和公司能够进行稳健、高效和节约的操作。'
- en: A fully automated workflow is achievable with smart optimization and synergy
    of all these drivers with the MLOps pipeline. Some direct advantages of implementing
    an automated MLOps workflow is a spike in IT teams' efficiency (by reducing the
    time spent by data scientists and developers on mundane and repeatable tasks)
    and the optimization of resources, resulting in cost reductions, and both of these
    are great for any business.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过智能优化和所有这些驱动因素与MLOps管道的协同作用，可以实现完全自动化的工作流程。实施自动化MLOps工作流程的一些直接优势是提高IT团队的效率（通过减少数据科学家和开发人员在日常和重复性任务上的时间）和资源的优化，从而降低成本，这对任何企业来说都是非常好的。
- en: Summary
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have learned about the evolution of software development
    and infrastructure to facilitate ML. We delved into the concepts of MLOps, followed
    by getting acquainted with a generic MLOps workflow that can be implemented in
    a wide range of ML solutions across multiple industries.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了软件开发和基础设施的演变，以促进机器学习的发展。我们深入探讨了MLOps的概念，随后熟悉了一个通用的MLOps工作流程，该工作流程可以应用于多个行业中的广泛机器学习解决方案。
- en: In the next chapter, you will learn how to characterize any ML problem into
    an MLOps-driven solution and start developing it using an MLOps workflow.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何将任何机器学习问题转化为由MLOps驱动的解决方案，并开始使用MLOps工作流程来开发它。
