- en: Getting Started with Machine Learning and ML.NET
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用机器学习和ML.NET
- en: By opening this book, you are taking the first step in disrupting your own knowledge
    by approaching solutions to complex problems with machine learning. You will be
    achieving this with the use of Microsoft's ML.NET framework. Having spent several
    years applying machine learning to cybersecurity, I'm confident that the knowledge
    you garner from this book will not only open career opportunities to you but also
    open up your thought processes and change the way you approach problems. No longer
    will you even approach a complex problem without thinking about how machine learning
    could possibly solve it.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 通过打开这本书，你正在通过使用微软的ML.NET框架，以机器学习的方法来接近解决复杂问题的解决方案，从而开始颠覆自己的知识。你将使用Microsoft's
    ML.NET框架来实现这一点。在将机器学习应用于网络安全领域度过了数年之后，我坚信，你从这本书中获得的知识不仅会为你打开职业机会，还会开启你的思维过程，改变你解决问题的方法。你将不再会面对复杂问题而不去思考机器学习如何可能解决它。
- en: 'Over the course of this book, you will learn about the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的整个过程中，你将学习以下内容：
- en: How and when to use five different algorithms that ML.NET provides
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何以及何时使用ML.NET提供的五种不同算法
- en: Real-world end-to-end examples demonstrating ML.NET algorithms
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展示ML.NET算法的实际应用端到端示例
- en: Best practices when training your models, building your training sets, and feature
    engineering
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型、构建训练集和特征工程的最佳实践
- en: Using pre-trained models in both TensorFlow and ONNX formats
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在TensorFlow和ONNX格式中使用预训练模型
- en: This book does assume that you have a reasonably solid understanding of C#.
    If you have other experience with a strongly typed object-oriented programming
    language such as C++ or Java, the syntax and design patterns are similar enough
    to not hinder your ability to follow the book. However, if this is your first
    deep dive into a strongly typed language such as C#, I strongly suggest picking
    up *Learn C# in 7 Days*,by Gaurav Aroraa, published byPackt Publishing, to get
    a quick foundation. In addition, no prior machine learning experience is required
    or expected, although a cursory understanding will accelerate your learning.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本书假设你有一个相当扎实的C#理解。如果你有其他使用强类型面向对象编程语言（如C++或Java）的经验，语法和设计模式足够相似，不会阻碍你阅读本书。然而，如果你是第一次深入研究强类型语言（如C#），我强烈建议你阅读Gaurav
    Aroraa所著的《Learn C# in 7 Days》，由Packt Publishing出版，以快速建立基础。此外，不需要或预期有先前的机器学习经验，尽管对机器学习有初步的了解将加速你的学习。
- en: 'In this chapter, we will cover the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: The importance of learning about machine learning today
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解机器学习的重要性
- en: The model-building process
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型构建过程
- en: Exploring types of learning
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索学习类型
- en: Exploring various machine learning algorithms
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索各种机器学习算法
- en: Introduction to ML.NET
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ML.NET简介
- en: By the end of the chapter, you should have a fundamental understanding of what
    it takes to build a model from start to finish, providing the basis for the remainder
    of the book.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该对从头到尾构建模型所需的基本要素有一个基本的理解，这为本书的其余部分提供了基础。
- en: The importance of learning about machine learning today
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解机器学习的重要性
- en: In recent years, machine learning and artificial intelligence have become an
    integral part of many of our lives in use cases as diverse as finding cancer cells
    in an MRI and facial and object recognition during a professional basketball game.
    Over the course of just the four years between 2013 and 2017, machine learning
    patents alone grew 34%, while spending is estimated to grow to $57.6B by 2021
    ([https://www.forbes.com/sites/louiscolumbus/2018/02/18/roundup-of-machine-learning-forecasts-and-market-estimates-2018/#794d6f6c2225](https://www.forbes.com/sites/louiscolumbus/2018/02/18/roundup-of-machine-learning-forecasts-and-market-estimates-2018/#794d6f6c2225)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近几年中，机器学习和人工智能已经成为我们生活中许多领域的不可或缺的一部分，这些领域包括在MRI中寻找癌细胞以及职业篮球比赛中的面部和物体识别。仅在2013年至2017年的短短四年中，机器学习专利就增长了34%，预计到2021年支出将增长到576亿美元（[https://www.forbes.com/sites/louiscolumbus/2018/02/18/roundup-of-machine-learning-forecasts-and-market-estimates-2018/#794d6f6c2225](https://www.forbes.com/sites/louiscolumbus/2018/02/18/roundup-of-machine-learning-forecasts-and-market-estimates-2018/#794d6f6c2225)）。
- en: Despite its status as a growing technology, the term machine learning was coined
    back in 1959 by Arthur Samuel—so what caused the 60-year gap before its adoption?
    Perhaps the two most significant factors were the availability of technology able
    to process model predictions fast enough, and the amount of data being captured
    every minute digitally. According to DOMO Inc, a study in 2017 concluded that
    2.5 quintillion bytes were generated daily and that at that time, 90% of the world's
    data was created between 2015 and 2017 ([https://www.domo.com/learn/data-never-sleeps-5?aid=ogsm072517_1&sf100871281=1](https://www.domo.com/learn/data-never-sleeps-5?aid=ogsm072517_1&sf100871281=1)).
    By 2025, it is estimated that 463 exabytes of data are going to be created daily
    ([https://www.visualcapitalist.com/how-much-data-is-generated-each-day/](https://www.visualcapitalist.com/how-much-data-is-generated-each-day/)),
    much of which will come from cars, videos, pictures, IoT devices, emails, and
    even devices that have not made the transition to the smart movement yet.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管机器学习是一个不断发展的技术，但“机器学习”这个术语是在1959年由亚瑟·塞缪尔提出的——那么是什么导致了60年的采用差距？可能最显著的两个因素是能够快速处理模型预测的技术可用性，以及每分钟以数字形式捕获的数据量。根据DOMO
    Inc的研究，2017年的一项研究得出结论，每天产生2.5泽字节的数据，当时，2015年至2017年间，全球90%的数据被创造出来([https://www.domo.com/learn/data-never-sleeps-5?aid=ogsm072517_1&sf100871281=1](https://www.domo.com/learn/data-never-sleeps-5?aid=ogsm072517_1&sf100871281=1))。到2025年，预计每天将产生463艾字节的数据，其中大部分将来自汽车、视频、图片、物联网设备、电子邮件，甚至尚未过渡到智能运动的设备([https://www.visualcapitalist.com/how-much-data-is-generated-each-day/](https://www.visualcapitalist.com/how-much-data-is-generated-each-day/))。
- en: The amount that data has grown in the last decade has led to questions about
    how a business or corporation can use such data for better sales forecasting,
    anticipating a customer's needs, or detecting malicious bytes in a file. Traditional
    statistical approaches could potentially require exponentially more staff to keep
    up with current demands, let alone scale with the data captured. Take, for instance,
    Google Maps. With Google's acquisition of Waze in 2013, users of Google Maps have
    been provided with extremely accurate routing suggestions based on the anonymized
    GPS data of its users. With this model, the more data points (in this case GPS
    data from smartphones), the better predictions Google can make for your travel.
    As we will discuss later in this chapter, quality datasets are a critical component
    of machine learning, especially in the case of Google Maps, where, without a proper
    dataset, the user experience would be subpar.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，数据量的增长引发了关于企业或公司如何利用这些数据来改善销售预测、预测客户需求或检测文件中的恶意字节的问题。传统的统计方法可能需要指数级增加员工人数才能跟上当前的需求，更不用说随着捕获的数据进行扩展了。以谷歌地图为例。2013年，谷歌收购了Waze，谷歌地图的用户因此得到了基于其用户匿名GPS数据的非常准确的路线建议。在这个模型下，数据点（在这种情况下是智能手机的GPS数据）越多，谷歌对你的旅行预测就越好。正如我们将在本章后面讨论的，高质量的数据库是机器学习的关键组成部分，尤其是在谷歌地图的情况下，如果没有合适的数据库，用户体验就会大打折扣。
- en: In addition, the speed of computer hardware, specifically specialized hardware
    tailored for machine learning, has also played a role. The use of **Application-Specific
    Integrated Circuits** (**ASICs**) has grown exponentially. One of the most popular
    ASICs on the market is the Google **Tensor Processing Unit** (**TPU**). Originally
    released in 2016, it has since gone through two iterations and provides cloud-based
    acceleration for machine learning tasks on Google Cloud Platform. Other cloud
    platforms, such as Amazon's AWS and Microsoft's Azure, also provide FPGAs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，计算机硬件的速度，特别是专门为机器学习定制的专用硬件，也发挥了作用。**应用特定集成电路**（**ASICs**）的使用呈指数增长。市场上最受欢迎的ASIC之一是谷歌的**张量处理单元**（**TPU**）。它最初于2016年发布，此后已经经过了两次迭代，并为谷歌云平台上的机器学习任务提供了基于云的加速。其他云平台，如亚马逊的AWS和微软的Azure，也提供了FPGA。
- en: Additionally, **Graphics Processing Units** (**GPUs**) from both AMD and NVIDIA are
    accelerating both cloud-based and local workloads, with ROCm Platform and CUDA-accelerated
    libraries respectively. In addition to accelerated workloads, typical professional
    GPUs offered by AMD and NVIDIA provide a much higher density of processors than
    the traditional CPU-only approach. For instance, the AMD Radeon Instinct MI60
    provides 4,096 stream processors. While not a full-fledged x86 core, it is not
    a one-to-one comparison, and the peak performance of double-precision floating-point
    tasks is rated at 7.373 TFLOPs compared to the 2.3 TFLOPs in AMD's extremely powerful
    EPYC 7742 server CPU. From a cost and scalability perspective, utilizing GPUs
    in even a workstation configuration would provide an exponential reduction in
    training time if the algorithms were accelerated to take advantage of the more
    specialized cores offered by AMD and NVIDIA. Fortunately, ML.NET provides GPU
    acceleration with little additional effort.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，来自 AMD 和 NVIDIA 的 **图形处理单元**（**GPU**）分别通过 ROCm 平台和 CUDA 加速库加速了基于云和本地的工作负载。除了加速工作负载外，AMD
    和 NVIDIA 提供的典型专业 GPU 比仅采用 CPU 的传统方法提供了更高的处理器密度。例如，AMD Radeon Instinct MI60 提供了
    4,096 个流处理器。虽然它不是一个完整的 x86 内核，但它也不是一对一的比较，双精度浮点任务的峰值性能被评为 7.373 TFLOPs，而 AMD 极其强大的
    EPYC 7742 服务器 CPU 的性能为 2.3 TFLOPs。从成本和可扩展性的角度来看，即使在工作站配置中利用 GPU，如果算法加速以利用 AMD
    和 NVIDIA 提供的更专业的核心，也会提供指数级的训练时间减少。幸运的是，ML.NET 提供了几乎不需要额外努力的 GPU 加速。
- en: From a software engineering career perspective, with this growth and demand
    far outpacing the supply, there has never been a better time to develop machine
    learning skills as a software engineer. Furthermore, software engineers also possess
    skills that traditional data scientists do not have – for instance, being able
    to automate tasks such as the model building process rather than relying on manual
    scripts. Another example of where a software engineer can provide more value is
    by adding both unit tests and efficacy tests as part of the full pipeline when
    training a model. In a large production application, having these automated tests
    is critical to avoid production issues.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从软件工程职业的角度来看，随着这种增长和需求远远超过供应，作为软件工程师开发机器学习技能从未有过更好的时机。此外，软件工程师还拥有传统数据科学家不具备的技能——例如，能够自动化模型构建过程等任务，而不是依赖于手动脚本。软件工程师可以提供更多价值的另一个例子是在训练模型时，将单元测试和有效性测试作为完整流程的一部分。在一个大型生产应用中，拥有这些自动化测试对于避免生产问题至关重要。
- en: Finally, in 2018, for the first time ever, data was considered more valuable
    than oil. As industries continue to adopt the use of data gathering and existing
    industries take advantage of the data they have, machine learning will be intertwined
    with the data. Machine learning to data is what refining plants are to oil.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在 2018 年，数据首次被认为比石油更有价值。随着行业继续采用数据收集的使用，现有行业利用他们拥有的数据，机器学习将与数据交织在一起。机器学习对数据的重要性就像炼油厂对石油的重要性一样。
- en: The model building process
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型构建过程
- en: 'Before diving into ML.NET, an understanding of core machine learning concepts
    is required. These concepts will help create a foundation for you to build on
    as we start building models and learning the various algorithms ML.NET provides
    over the course of this book. At a high level, producing a model is a complex
    process; however, it can be broken down into six main steps:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨 ML.NET 之前，了解核心机器学习概念是必要的。这些概念将为您构建基础，以便我们在本书的整个过程中开始构建模型并学习 ML.NET 提供的各种算法。从高层次来看，生成模型是一个复杂的过程；然而，它可以被分解为六个主要步骤：
- en: '![](img/d24862da-3f93-48e3-b3a7-45d10dede281.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d24862da-3f93-48e3-b3a7-45d10dede281.png)'
- en: Over the next few sections, we will go through each of these steps in detail
    to provide you with a clear understanding of how to perform each step and how
    each step relates to the overall machine learning process as a whole.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将详细讨论这些步骤，以向您提供如何执行每个步骤以及每个步骤如何与整个机器学习过程相关的清晰理解。
- en: Defining your problem statement
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义你的问题陈述
- en: Effectively, what problem are you attempting to solve? Being specific at this
    point is crucial as a less concise problem can lead to considerable re-work. For
    example, take the following problem statement: *Predicting the outcome of an election*.
    My first question upon hearing that problem statement would be, at what level?
    County, state, or national? Each level more than likely requires considerably
    more features and data to properly predict than the last. A better problem statement,
    especially early on in your machine learning journey, would be for a specific
    position at a county level, such as *Predicting the 2020 John Doe County Mayor*.
    With this more direct problem statement, your features and dataset are much more
    focused and more than likely attainable. Even with more experience in machine
    learning, proper scoping of your problem statement is critical. The five Ws of
    Who, What, When, Where, and Why should be followed to keep your statement concise.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你试图解决什么问题？在这个阶段保持具体至关重要，因为一个不够简洁的问题可能导致大量的返工。例如，考虑以下问题陈述：*预测选举结果*。当我听到这个问题陈述时，我的第一个问题会是，在哪个层面？县、州还是国家？每个层面可能需要比上一个层面更多的特征和数据来正确预测。在机器学习旅程的早期，一个更好的问题陈述可能是针对县一级的具体职位，例如*预测2020年约翰·多伊县市长*。有了这个更直接的问题陈述，你的特征和数据集将更加聚焦，并且更有可能实现。即使在机器学习方面有更多经验，正确界定你的问题陈述也是至关重要的。应遵循谁（Who）、什么（What）、何时（When）、何地（Where）和为什么（Why）的五个W，以保持你的陈述简洁。
- en: Defining your features
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义你的特征
- en: The second step in machine learning is defining your features. Think of features
    as components or attributes of the problem you wish to solve. In machine learning
    – specifically, when creating a new model – features are one of the biggest impacts
    on your model's performance. Properly thinking through your problem statement
    will promote an initial set of features that will drive differentiation between
    your dataset and model results. Going back to the Mayor example in the preceding
    section, what features would you consider data points for the citizen? Perhaps
    start by looking at the Mayor's competition and where he/she sits on issues in
    ways that differ from other candidates. These values could be turned into features
    and then made into a poll for citizens of John Doe County to answer. Using these
    data points would create a solid first pass at features. One aspect here that
    is also found in model building is running several iterations of feature engineering
    and model training, especially as your dataset grows. After model evaluation,
    *feature importance* is used to determine what features are actually driving your
    predictions. Occasionally, you will find that gut-instinct features can actually
    be inconsequential after a few iterations of model training and feature engineering.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的第二步是定义你的特征。将特征视为你希望解决的问题的组成部分或属性。在机器学习中——特别是在创建新模型时——特征对你的模型性能影响最大。正确思考你的问题陈述将促进一组初始特征，这将推动你的数据集和模型结果之间的差异化。回到前一部分的市长例子，你会考虑哪些数据点作为市民的特征？或许可以从市长竞选和他在问题上的立场与其他候选人不同的方式开始考虑。这些值可以转化为特征，然后制成民意调查供约翰·多伊县的市民回答。使用这些数据点将创建特征的第一阶段坚实基础。这里的一个方面也存在于模型构建中，即运行多个特征工程和模型训练迭代，尤其是在你的数据集增长时。在模型评估后，*特征重要性*用于确定哪些特征实际上在驱动你的预测。偶尔，你会发现，在经过几轮模型训练和特征工程后，直觉特征实际上可能无关紧要。
- en: In [Chapter 11](116bbc2d-9659-4d34-9b2b-26593e29f54a.xhtml), *Training and Building
    Production Models*, we will deep dive into best practices when defining features
    and common approaches to complex problems to obtain a solid first pass at feature
    engineering.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第11章](116bbc2d-9659-4d34-9b2b-26593e29f54a.xhtml)《训练和构建生产模型》中，我们将深入探讨在定义特征和解决复杂问题的常见方法时的最佳实践，以获得特征工程的第一阶段坚实基础。
- en: Obtaining a dataset
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据集
- en: As you can imagine, one of the most important aspects of the model building
    process is obtaining a high-quality dataset. A dataset is used to train the model
    on what the output should be in the case of the aforementioned case of supervised
    learning. In the case of unsupervised learning, labeling is required for the dataset.
    A common misconception when creating a dataset is that bigger is better. This
    is far from the truth in a lot of cases. Continuing the preceding example, what
    if all of the poll results answered the same way for every single question? At
    that point, your dataset is composed of all the same data points and your model
    will not be able to properly predict any of the other candidates. This outcome
    is called *overfitting*. A diverse but representative dataset is required for
    machine learning algorithms to properly build a production-ready model.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想，模型构建过程中最重要的方面之一是获取高质量的数据集。数据集用于在监督学习的情况下训练模型，以确定输出应该是什么。在无监督学习的情况下，需要对数据集进行标记。在创建数据集时，一个常见的误解是“越大越好”。在很多情况下，这远远不是事实。继续前面的例子，如果所有的民意调查结果对每个问题都给出了相同的回答，那会怎样？到那时，你的数据集将只包含相同的数据点，你的模型将无法正确预测任何其他候选人。这种情况被称为
    *过度拟合*。对于机器学习算法来说，需要一个多样化但具有代表性的数据集，才能正确构建一个生产就绪的模型。
- en: In [Chapter 11](116bbc2d-9659-4d34-9b2b-26593e29f54a.xhtml), *Training and Building
    Production Models*, we will deep dive into the methodology of obtaining quality
    datasets, looking at helpful resources, ways to manage your datasets, and transforming
    data, commonly referred to as data wrangling.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 11 章 [训练和构建生产模型](116bbc2d-9659-4d34-9b2b-26593e29f54a.xhtml)，我们将深入探讨获取高质量数据集的方法，查看有用的资源，管理你的数据集的方式，以及数据转换，通常称为数据清洗。
- en: Feature extraction and pipeline
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征提取和管道
- en: Once your features and datasets have been obtained, the next step is to perform
    feature extraction. Feature extraction, depending on the size of your dataset
    and your features, could be one of the most time-consuming elements of the model
    building process.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你获得了特征和数据集，下一步就是进行特征提取。特征提取，根据你的数据集大小和特征，可能是模型构建过程中最耗时的元素之一。
- en: For example, let's say that the results from the aforementioned fictitious John
    Doe County Election Poll had 40,000 responses. Each response was stored in a SQL
    database captured from a web form. Performing a SQL query, let's say you then
    returned all of the data into a CSV file, using which your model can be trained.
    At a high level, this is your feature extraction and pipeline. For more complex
    scenarios, such as predicting malicious web content or image classification, the
    extraction will include binary extraction of specific bytes in files. Properly
    storing this data to avoid having to re-run the extraction is crucial to iterating
    quickly (assuming the features did not change).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设上述虚构的约翰·多伊县选举民意调查的结果有 40,000 个回复。每个回复都存储在一个从网页表单捕获的 SQL 数据库中。执行一个 SQL 查询，比如说你将所有数据返回到一个
    CSV 文件中，然后使用这个文件来训练你的模型。从高层次来看，这就是你的特征提取和管道。对于更复杂的场景，例如预测恶意网络内容或图像分类，提取将包括文件中特定字节的二进制提取。正确存储这些数据以避免需要重新运行提取对于快速迭代至关重要（假设特征没有变化）。
- en: In Chapter 11, *Training and Building Production Models,* we will deep dive
    into ways to version your feature-extracted data and maintain control over your
    data, especially as your dataset grows in size.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 11 章 [训练和构建生产模型] 中，我们将深入探讨如何对你的特征提取数据进行版本控制并保持对数据集的控制，特别是随着数据集规模的增加。
- en: Model training
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练
- en: After feature extraction, you are now prepared to train your model. Model training
    with ML.NET, thankfully, is very straightforward. Depending on the amount of data
    extracted in the feature extraction phase, the complexity of the pipeline, and
    the specifications of the host machine, this step could take several hours to
    complete. When your pipeline becomes much larger and your model becomes more complex,
    you may find yourself requiring potentially more compute resources than your laptop
    or desktop can provide; tooling such as Spark exists to help you scale to *n*
    number of nodes.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征提取之后，你现在已经准备好训练你的模型了。幸运的是，使用 ML.NET 进行模型训练非常直接。根据特征提取阶段提取的数据量、管道的复杂性和主机机的规格，这一步可能需要几个小时才能完成。当你的管道变得非常大，你的模型变得更加复杂时，你可能发现自己需要比笔记本电脑或台式机能提供的更多计算资源；存在像
    Spark 这样的工具来帮助你扩展到 *n* 个节点。
- en: In Chapter 11, *Training and Building Production Models*, we will discuss tooling
    and tips for scaling this step using an easy-to-use open source project.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在第11章“训练和构建生产模型”中，我们将讨论使用易于使用的开源项目来扩展这一步骤的工具和技巧。
- en: Model evaluation
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估
- en: Once the model is trained, the last step is to evaluate the model. The typical
    approach to model evaluation is to *hold out* a portion of your dataset for evaluation.
    The idea behind this is to take known data, submit it to your trained model, and
    measure the efficacy of your model. The critical part of this step is to hold
    out a representative dataset of your data. If your holdout set is swayed one way
    or the other, then you will more than likely get a false sense of either high
    performance or low performance. In the next chapter, we will deep dive into the
    various scoring and evaluation metrics. ML.NET provides a relatively easy interface
    to evaluate a model; however, each algorithm has unique properties to verify,
    which we will review as we deep dive into the various algorithms.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练完成后，最后一步是评估模型。典型的模型评估方法是保留一部分数据集用于评估。其背后的想法是将已知数据提交给训练好的模型，并衡量模型的有效性。这一步骤的关键是保留一个具有代表性的数据集。如果你的保留集受到某种影响，那么你很可能会得到一个关于高绩效或低绩效的虚假印象。在下一章中，我们将深入探讨各种评分和评估指标。ML.NET提供了一个相对简单的接口来评估模型；然而，每个算法都有独特的属性需要验证，我们将在深入研究各种算法时进行回顾。
- en: Exploring types of learning
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索学习类型
- en: Now that you understand the steps that make up the model building process, the
    next major component to introduce is the two main types of learning. There are
    several other types of machine learning, such as reinforcement learning. However,
    for the scope of this book, we will focus on the two types used for the algorithms
    ML.NET provides—supervised learning and unsupervised learning. If you are curious
    about the other types of learning, check out *Machine Learning Algorithms*, Giuseppe
    Bonaccorso, Packt Publishing.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了构成模型构建过程的步骤，接下来要介绍的是两种主要的学习类型。还有其他几种机器学习类型，例如强化学习。然而，在本书的范围内，我们将专注于ML.NET提供的两种类型——监督学习和无监督学习。如果你对其他类型的学习感兴趣，可以查看Giuseppe
    Bonaccorso所著的《机器学习算法》，Packt出版社出版。
- en: Supervised learning
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习
- en: Supervised learning is the more common of the two types, and, as such, it is
    also used for most of the algorithms we will cover in this book. Simply put, supervised
    learning entails you, as the data scientist, passing the known outputs as part
    of the training to the model. Take, for instance, the election example discussed
    earlier in this chapter. With supervised learning, every data point in the election
    polls that is used as a feature along with whom they say will vote for, are sent
    to the model during training. This step is traditionally called **labeling** in
    classification algorithms, in which the output values will be one of the pre-training
    labels.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习是两种类型中更常见的一种，因此它也用于我们将在本书中涵盖的大多数算法。简单来说，监督学习意味着作为数据科学家，你将已知的输出作为训练的一部分传递给模型。以本章前面讨论的选举示例为例。在监督学习中，选举调查中用作特征的每个数据点，以及他们表示将投票给谁，都会在训练期间发送到模型。这一步骤在分类算法中传统上被称为**标记**，其输出值将是预训练标签之一。
- en: Unsupervised learning
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Conversely, in unsupervised learning, the typical use case is when figuring
    out the input and output labels proves to be difficult. Using the election scenario,
    when you are unsure of what features are really going to provide data points for
    the model to determine a voter's vote, unsupervised learning could provide value
    and insight. The benefit of this approach is that the algorithm of your choice
    determines what features drive your labeling. For instance, using a clustering
    algorithm such as k-means, you could submit all of the voter data points to the
    model. The algorithm would then be able to group voter data into clusters and
    predict unseen data. We will deep dive into unsupervised learning with clustering
    in Chapter 5*, Clustering Model*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，在无监督学习中，典型的用例是在确定输入和输出标签困难时。以选举场景为例，当你不确定哪些特征将真正为模型提供数据点以确定选民投票时，无监督学习可以提供价值和见解。这种方法的优点是，你选择的算法决定了驱动标签的特征。例如，使用k-means这样的聚类算法，你可以将所有选民数据点提交给模型。然后，算法能够将选民数据分组到簇中，并预测未见数据。我们将在第5章“聚类模型”中深入探讨无监督学习和聚类。
- en: Exploring various machine learning algorithms
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索各种机器学习算法
- en: 'At the heart of machine learning are the various algorithms used to solve complex
    problems. As mentioned in the introduction, this book will cover five algorithms:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的核心是用于解决复杂问题的各种算法。如引言中所述，本书将涵盖五种算法：
- en: Binary classification
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二元分类
- en: Regression
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归
- en: Anomaly detection
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常检测
- en: Clustering
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类
- en: Matrix factorization
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵分解
- en: Each will be the focus of a chapter later in the book, but for now, let's get
    a quick overview of them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 每个算法将在本书后面的章节中详细介绍，但在此，我们先对这些算法进行简要概述。
- en: Binary classification
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二元分类
- en: One of the easiest algorithms to understand is binary classification. Binary
    classification is a supervised machine learning algorithm. As the name implies,
    the output of a model trained with a binary classification algorithm will return
    a true or false conviction (as in 0 or 1). Problems best suited to a binary classification
    model include determining whether a comment is hateful or whether a file is malicious.
    ML.NET provides several binary classification model algorithms, which we will
    cover in Chapter 4, *Classification Model*, along with a working example of determining
    whether a file is malicious or not.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最容易理解的算法之一是二元分类。二元分类是一种监督式机器学习算法。正如其名，使用二元分类算法训练的模型将返回一个真或假的判断（如0或1）。最适合二元分类模型的问题包括判断一个评论是否仇恨或一个文件是否恶意。ML.NET提供了几个二元分类模型算法，我们将在第4章，*分类模型*中介绍，并附带一个判断文件是否恶意的示例。
- en: Regression
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归
- en: Another powerful yet easy-to-understand algorithm is regression. Regression
    is another supervised machine learning algorithm. Regression algorithms return
    a real value as opposed to a binary algorithm or ones that return from a set of
    specific values. You can think of regression algorithms as an algebra equation
    solver where there are a number of known values and the goal is to predict the
    one unknown value. Some examples of problems best suited to regression algorithms
    are predicting attrition, weather forecasting, stock market predictions, and house
    pricing, to name a few.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个强大且易于理解的算法是回归。回归是另一种监督式机器学习算法。与二元算法或返回特定值集合的算法不同，回归算法返回一个实数值。你可以将回归算法视为一个代数方程求解器，其中有许多已知值，目标是预测一个未知值。一些最适合回归算法的问题包括预测流失、天气预报、股市预测和房价等。
- en: In addition, there is a subset of regression algorithms called **logistic regression**
    models. Whereas a traditional linear regression algorithm, as described earlier,
    returns the predicted value, a logistic regression model will return the probability
    of the outcome occurring.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一组称为**逻辑回归**模型的回归算法子集。与前面描述的传统线性回归算法不同，逻辑回归模型将返回结果发生的概率。
- en: ML.NET provides several regression model algorithms, which we will cover in Chapter
    3, *Regression Model*.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ML.NET提供了几个回归模型算法，我们将在第3章，*回归模型*中介绍。
- en: Anomaly detection
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异常检测
- en: Anomaly detection, as the name implies, looks for unexpected events in the data
    submitted to the model. Data for this algorithm, as you can probably guess, requires
    data over a period of time. Anomaly detection in ML.NET looks at both spikes and
    change points. **Spikes**, as the name implies, are temporary, whereas **change
    points** are the starting points of a longer change.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测，正如其名，是在提交给模型的 数据中寻找意外事件。这个算法的数据，你可能猜得到，需要一段时间内的数据。ML.NET中的异常检测不仅考虑峰值，还考虑变化点。**峰值**，正如其名，是暂时的，而**变化点**是更长变化的开端。
- en: ML.NET provides an anomaly detection algorithm, which we will cover in Chapter
    6, *Anomaly Detection Model*.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ML.NET提供了一个异常检测算法，我们将在第6章，*异常检测模型*中介绍。
- en: Clustering
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: Clustering algorithms are unsupervised algorithms and offer a unique solution
    to problems where finding the closest match to related items is the desired solution.
    During the training of the data, the data is grouped based on the features, and
    then during the prediction, the closest match is chosen. Some examples of the
    use of clustering algorithms include file type classification and predicting customer
    choices.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类算法是无监督算法，为寻找相关项最接近匹配的问题提供了一种独特的解决方案。在数据训练过程中，数据根据特征分组，然后在预测过程中选择最接近的匹配项。聚类算法的用途示例包括文件类型分类和预测客户选择。
- en: ML.NET uses the k-means algorithm specifically, which we will deep dive into
    in Chapter 5, *Clustering Model*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ML.NET特别使用k-means算法，我们将在第5章“聚类模型”中深入探讨。
- en: Matrix factorization
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 矩阵分解
- en: Last but not least, the matrix factorization algorithm provides a powerful and
    easy-to-use algorithm for providing recommendations. This algorithm is tailored
    to problems where historical data is available and the problem to solve is predicting
    a selection from that data, such as movie or music predictions. Netflix's movie
    suggestion system uses a form of matrix factorization for its suggestions about
    what movies it thinks you will enjoy.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，矩阵分解算法提供了一个强大且易于使用的算法，用于提供推荐。此算法针对历史数据可用且需要解决的问题是从该数据中预测选择的情况，例如电影或音乐预测。Netflix
    的电影推荐系统就使用了矩阵分解来提供他们认为你会喜欢的电影建议。
- en: We will cover matrix factorization in detail in Chapter 7, *Matrix Factorization
    Model*.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第7章“矩阵分解模型”中详细介绍矩阵分解。
- en: What is ML.NET?
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 ML.NET？
- en: Now that you have a fairly firm understanding of the core machine learning concepts,
    we can now dive into Microsoft's ML.NET framework. ML.NET is Microsoft's premier
    machine learning framework. It provides an easy-to-use framework to train, create,
    and run models with relative ease all in the confines of the .NET ecosystem.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你对核心机器学习概念有了相当深入的理解，我们现在可以深入了解微软的ML.NET框架。ML.NET是微软的顶级机器学习框架。它提供了一个易于使用的框架，在.NET生态系统中轻松训练、创建和运行模型。
- en: Microsoft's ML.NET was announced and released (version 0.1) in May 2018 at Microsoft's
    developer conference BUILD in Seattle, Washington. The project itself is open
    source with an MIT License on GitHub ([https://github.com/dotnet/machinelearning](https://github.com/dotnet/machinelearning))
    and has seen a total of 17 updates since the first release at the time of writing.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的ML.NET于2018年5月在华盛顿州西雅图的微软开发者大会BUILD上宣布并发布（版本0.1）。该项目本身是开源的，在GitHub上拥有MIT许可证([https://github.com/dotnet/machinelearning](https://github.com/dotnet/machinelearning))，自首次发布以来，已经更新了17次。
- en: Some products using ML.NET internally at Microsoft include Chart Decisions in
    Excel, Slide Designs in PowerPoint, Windows Hello, and Azure Machine Learning.
    This emphasizes the production-readiness of ML.NET for your own production deployments.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在微软内部使用ML.NET的一些产品包括Excel中的Chart Decisions、PowerPoint中的幻灯片设计、Windows Hello和Azure机器学习。这强调了ML.NET在生产部署中的生产就绪性。
- en: ML.NET, from the outset, was designed and built to facilitate the use of machine
    learning for C# and F# developers using an architecture that would come naturally
    to someone familiar with .NET Framework. Until ML.NET arrived, there was not a
    full-fledged and supported framework where you could not only train but also run
    a model without leaving the .NET ecosystem. Google's TensorFlow, for instance,
    has an open-source wrapper written by Miguel de Icaza available on GitHub ([https://github.com/migueldeicaza/TensorFlowSharp](https://github.com/migueldeicaza/TensorFlowSharp));
    however, at the time of writing this book, most workflows require the use of Python
    to train a model, which can then be consumed by a C# wrapper to run a prediction.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ML.NET从一开始就被设计和构建，以方便C#和F#开发者使用机器学习，其架构对于熟悉.NET Framework的人来说是自然而然的。在ML.NET出现之前，没有一个完整的、受支持的框架，你不仅可以在.NET生态系统中训练模型，还可以运行模型。例如，Google的TensorFlow有一个由Miguel
    de Icaza编写的开源包装器，可在GitHub上找到([https://github.com/migueldeicaza/TensorFlowSharp](https://github.com/migueldeicaza/TensorFlowSharp))；然而，在撰写本书时，大多数工作流程都需要使用Python来训练模型，然后由C#包装器运行预测。
- en: 'In addition, Microsoft was intent on supporting all of the major platforms
    .NET developers have grown accustomed to publishing their applications in the
    last several years. Here are some examples of a few of the platforms, with the
    frameworks they targeted in parentheses:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，微软还致力于支持所有.NET开发者过去几年习惯于发布应用程序的主要平台。以下是一些平台的示例，括号中列出了它们的目标框架：
- en: Web (ASP.NET)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络端（ASP.NET）
- en: Mobile (Xamarin)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动端（Xamarin）
- en: Desktop (UWP, WPF, and WinForms)
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 桌面端（UWP、WPF和WinForms）
- en: Gaming (MonoGame and SharpDX)
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 游戏开发（MonoGame 和 SharpDX）
- en: IoT (.NET Core and UWP)
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物联网（.NET Core和UWP）
- en: Later in this book, we will implement several real-world applications on most
    of these platforms to demonstrate how to integrate ML.NET into various application
    types and platforms.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的后续部分，我们将在这大多数平台上实现几个现实世界的应用，以展示如何将 ML.NET 集成到各种应用类型和平台中。
- en: Technical details of ML.NET
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML.NET的技术细节
- en: With the release of ML.NET 1.4, the targeting of .NET Core 3.0 or later is recommended
    to take advantage of the hardware intrinsics added as part of .NET Core 3.0\.
    For those unfamiliar, .NET Core 2.x (and earlier) along with .NET Framework are
    optimized for CPUs with **Streaming** **SIMD** **Extensions **(**SSE**). Effectively,
    these instructions provide an optimized path for performing several CPU instructions
    on a dataset. This approach is referred to as **Single Instruction Multiple Data**
    (**SIMD**). Given that the SSE CPU extensions were first added in the Pentium
    III back in 1999 and later added by AMD in the Athlon XP in 2001, this has provided
    an extremely backward-compatible path. However, this also does not allow code
    to take advantage of all the advancements made in CPU extensions made in the last
    20 years. One such advancement is the **Advanced Vector Extensions** (**AVX**)
    available on most Intel and AMD CPUs created in 2011 or later.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 随着ML.NET 1.4的发布，推荐将目标设置为.NET Core 3.0或更高版本，以利用.NET Core 3.0作为一部分添加的硬件内建函数。对于那些不熟悉的人，.NET
    Core 2.x（以及更早版本）以及.NET Framework针对具有**流式** **单指令多数据**（**SIMD**）**扩展**（**SSE**）的CPU进行了优化。实际上，这些指令为在数据集上执行多个CPU指令提供了一条优化路径。这种方法被称为**单指令多数据**（**SIMD**）。鉴于SSE
    CPU扩展最初是在1999年的Pentium III中添加的，后来AMD在2001年的Athlon XP中添加，这提供了一条极其向后兼容的路径。然而，这也并不允许代码利用过去20年中CPU扩展的所有进步。其中一项进步是大多数2011年或之后创建的Intel和AMD
    CPU上可用的**高级向量扩展**（**AVX**）。
- en: This provides eight 32-bit operations in a single instruction, compared to the
    four SSE provides. As you can probably guess, machine learning can take advantage
    of this doubling of instructions. For CPUs in .NET Core 3 that are not supported
    yet (such as ARM), .NET Core 3 automatically falls back to a software-based implementation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这在单条指令中提供了八个32位操作，而SSE提供的是四个。正如你可能猜到的，机器学习可以利用这种指令数量的加倍。对于.NET Core 3中尚未支持（如ARM）的CPU，.NET
    Core 3会自动回退到基于软件的实现。
- en: Components of ML.NET
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML.NET组件
- en: As mentioned previously, ML.NET was designed to be intuitive for experienced
    .NET developers. The architecture and components are very similar to the patterns
    found in ASP.NET and WPF.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，ML.NET被设计成对经验丰富的.NET开发者直观。其架构和组件与ASP.NET和WPF中发现的模式非常相似。
- en: At the heart of ML.NET is the `MLContext` object. Similar to `AppContext` in
    a .NET application, `MLContext` is a singleton class. The `MLContext` object itself
    provides access to all of the trainer catalogs ML.NET offers (some are offered
    by additional NuGet packages). You can think of a trainer catalog in ML.NET as
    a specific algorithm such as binary classification or clustering.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ML.NET的核心是`MLContext`对象。类似于.NET应用程序中的`AppContext`，`MLContext`是一个单例类。`MLContext`对象本身提供了对ML.NET提供的所有训练目录的访问（其中一些由额外的NuGet包提供）。你可以将ML.NET中的训练目录视为一个特定的算法，例如二元分类或聚类。
- en: 'Here are some of the ML.NET catalogs:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是ML.NET的一些目录：
- en: Anomaly detection
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常检测
- en: Binary classification
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二元分类
- en: Clustering
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类
- en: Forecasting
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测
- en: Regression
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归
- en: Time series
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列
- en: These six groups of algorithms were reviewed earlier in this chapter and will
    be covered in more detail in subsequent dedicated chapters in this book.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这六个算法组在本章中已进行了回顾，并将在本书的后续专门章节中更详细地介绍。
- en: In addition, added recently in ML.NET 1.4 was the ability to import data directly
    from a database. This feature, while in preview at the time of writing, can facilitate
    not only an easier feature extraction process, but also expands the possibilities
    of making real-time predictions in an existing application or pipeline possible.
    All major databases are supported, including SQL Server, Oracle, SQLite, PostgreSQL,
    MySQL, DB2, and Azure SQL. We will explore this feature in Chapter 4, *Classification
    Model*, with a console application using a SQLite database.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，ML.NET 1.4最近添加了直接从数据库导入数据的功能。这个特性，尽管在撰写本文时处于预览状态，不仅可以简化特征提取过程，还可以扩展在现有应用程序或管道中进行实时预测的可能性。所有主要数据库都受到支持，包括SQL
    Server、Oracle、SQLite、PostgreSQL、MySQL、DB2和Azure SQL。我们将在第4章“分类模型”中探索这个特性，使用SQLite数据库的控制台应用程序。
- en: 'The following diagram presents the high-level architecture of ML.NET:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了ML.NET的高级架构：
- en: '![](img/0f58aa45-9a06-4e5a-8b4f-c83da9236fbd.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0f58aa45-9a06-4e5a-8b4f-c83da9236fbd.png)'
- en: 'Here, you can see an almost exact match to the traditional machine learning
    process. This was intentionally done to reduce the learning curve for those familiar
    with other frameworks. Each step in the architecture can be summarized as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以看到几乎与传统的机器学习过程完全一致。这是有意为之，以降低熟悉其他框架的人的学习曲线。架构中的每一步可以总结如下：
- en: '**IDataView**: This is used to store the loaded training data into memory.'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**IDataView**：这个接口用于将加载的训练数据存储到内存中。'
- en: '**Creating a Pipeline**: The pipeline creation maps the `IDataView` object
    properties to values to send to the model for training.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建管道**：管道创建将 `IDataView` 对象属性映射到值，以便发送给模型进行训练。'
- en: '**Fit()**: Regardless of the algorithm, after the pipeline has been created,
    calling `Fit()` kicks off the actual model training.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Fit()**：无论算法如何，在创建管道后，调用 `Fit()` 将启动实际的模型训练。'
- en: '**Save()**: As the name implies, this saves the model (in a binary format)
    to a file.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Save()**：正如其名所示，这个接口用于将模型（以二进制格式）保存到文件。'
- en: '**ITransformer**:This loads the model back into memory to run predictions.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ITransformer**：这个接口用于将模型重新加载到内存中以运行预测。'
- en: '**Evaluate()**: As the name implies, this evaluates the model ([Chapter 2](b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml), *Setting
    Up the ML.NET Environment* will dive further into the evaluation architecture).'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Evaluate()**：正如其名所示，这个接口用于评估模型（第 2 章 [设置 ML.NET 环境](b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml)将进一步探讨评估架构）。'
- en: Over the course of this book, we will dive into these methods more thoroughly.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的整个过程中，我们将更深入地探讨这些方法。
- en: Extensibility of ML.NET
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML.NET 的可扩展性
- en: 'Lastly, ML.NET, like most robust frameworks, provides considerable extensibility.
    Microsoft has since launched added extensibility support to be able to run the
    following externally trained model types, among others:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，ML.NET，像大多数健壮的框架一样，提供了相当大的可扩展性。微软随后推出了额外的可扩展性支持，以便能够运行以下外部训练的模型类型，以及其他类型：
- en: TensorFlow
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow
- en: ONNX
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ONNX
- en: Infer.Net
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Infer.Net
- en: CNTK
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNTK
- en: TensorFlow ([https://www.tensorflow.org/](https://www.tensorflow.org/)), as
    mentioned previously, is Google's machine learning framework with officially supported
    bindings for C++, Go, Java, and JavaScript. Additionally, TensorFlow can be accelerated
    with GPUs and, as previously mentioned, Google's own TPUs. In addition, like ML.NET,
    it offers the ability to run predictions on a wide variety of platforms, including
    iOS, Android, macOS, ARM, Linux, and Windows. Google provides several pre-trained
    models. One of the more popular models is the image classification model, which
    classifies objects in a submitted image. Recent improvements in ML.NET have enabled
    you to create your own image classifier based on that pre-trained model. We will
    be covering this scenario in detail in [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml),
    *Using TensorFlow with ML.NET*.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow ([https://www.tensorflow.org/](https://www.tensorflow.org/))，如前所述，是谷歌的机器学习框架，具有对
    C++、Go、Java 和 JavaScript 的官方支持绑定。此外，TensorFlow 可以通过 GPU 加速，正如之前提到的，还有谷歌自己的 TPUs。此外，类似于
    ML.NET，它还提供了在包括 iOS、Android、macOS、ARM、Linux 和 Windows 在内的广泛平台上运行预测的能力。谷歌提供了多个预训练模型。其中较受欢迎的一个模型是图像分类模型，它可以对提交的图像中的对象进行分类。ML.NET
    近期的一些改进使得您可以根据该预训练模型创建自己的图像分类器。我们将在第 12 章 [使用 TensorFlow 与 ML.NET](049e90c4-05b0-466d-af93-d56df861a843.xhtml)
    中详细讨论这一场景。
- en: ONNX ([https://onnx.ai/](https://onnx.ai/)), an acronym for Open Neural Network
    Exchange Format, is a widely used format in the data science field due to the
    ability to export to a common format. ONNX has converters for XGBoost, TensorFlow,
    scikit-learn, LibSVM, and CoreML, to name a few. Microsoft's native support of
    the ONNX format in ML.NET will not only allow better extensibility with existing
    machine learning pipelines but also increase the adoption of ML.NET in the machine
    learning world. We will utilize a pre-trained ONNX format model in [Chapter 13](788ee637-ad9b-4ddf-8018-b804d3004404.xhtml),
    *Using ONNX with ML.NET*.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ONNX ([https://onnx.ai/](https://onnx.ai/))，即 Open Neural Network Exchange Format
    的缩写，由于能够导出为通用格式，在数据科学领域被广泛使用。ONNX 具有XGBoost、TensorFlow、scikit-learn、LibSVM 和 CoreML
    等转换器。ML.NET 对 ONNX 格式的原生支持不仅将允许与现有的机器学习管道更好地扩展，还将增加 ML.NET 在机器学习世界中的采用率。我们将在第
    13 章 [使用 ONNX 与 ML.NET](788ee637-ad9b-4ddf-8018-b804d3004404.xhtml) 中使用预训练的 ONNX
    格式模型。
- en: Infer.Net is another open source Microsoft machine learning framework that focuses
    on probabilistic programming. You might be wondering what probabilistic programming
    is. At a high level, probabilistic programming handles the grey area where traditional
    variable types are definite, such as Booleans or integers. Probabilistic programming
    uses random variables that have a range of values that the result could be, akin
    to an array. The difference between a regular array and the variables in probabilistic
    programming is that for every value, there is a probability that the specific
    value would occur.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Infer.Net是另一个专注于概率编程的微软开源机器学习框架。你可能想知道概率编程是什么。从高层次来看，概率编程处理传统变量类型确定性的灰色区域，例如布尔值或整数。概率编程使用具有一系列可能结果的随机变量，类似于数组。常规数组和概率编程中的变量之间的区别在于，对于每个值，都有一个特定值发生的概率。
- en: 'A great real-world use of Infer.Net is the technology behind Microsoft''s TrueSkill. TrueSkill
    is a rating system that powers the matchmaking in *Halo* and *Gears of War*, where
    players are matched based on a multitude of variables, play types, and also, maps
    can all be attributed to how even two players are. While outside the scope of
    this book, a great whitepaper diving further into Infer.Net and probabilistic
    programming, in general, can be found here: [https://dotnet.github.io/infer/InferNet_Intro.pdf](https://dotnet.github.io/infer/InferNet_Intro.pdf).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Infer.Net的一个很好的实际应用是微软TrueSkill背后的技术。TrueSkill是一个评分系统，它为《光环》和《战争机器》中的匹配系统提供动力，玩家根据多种变量、游戏类型以及地图等因素进行匹配，甚至可以归因于两个玩家之间的匹配程度。虽然这超出了本书的范围，但一份深入探讨Infer.Net和概率编程（一般而言）的出色白皮书可以在这里找到：[https://dotnet.github.io/infer/InferNet_Intro.pdf](https://dotnet.github.io/infer/InferNet_Intro.pdf)。
- en: CNTK, also from Microsoft, which is short for Cognitive Toolkit, is a deep learning
    toolkit with a focus on neural networks. One of the unique features of CNTK is
    its use of describing neural networks via a directed graph. While outside the
    scope of this book (we will cover neural networks in Chapter 12 with TensorFlow),
    the world of feed-forward Deep Neural Networks, Convolutional Neural Networks,
    and Recurrent Neural Networks is extremely fascinating. To dive further into neural
    networks specifically, I would suggest *Hands-On Neural Network Programming with
    C#*, also from Packt.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: CNTK，也来自微软，其缩写为认知工具包，是一个专注于神经网络的深度学习工具包。CNTK的一个独特特性是它通过有向图来描述神经网络。虽然这超出了本书的范围（我们将在第12章使用TensorFlow介绍神经网络），但前馈深度神经网络、卷积神经网络和循环神经网络的世界非常迷人。要更深入地了解神经网络，我建议阅读《使用C#进行神经网络编程实践》，这也是Packt出版的一本书。
- en: Additional extensibility into Azure and other model support such as PyTorch
    ([https://pytorch.org/](https://pytorch.org/)) is on the roadmap, but no timeline
    has been established at the time of writing.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 将Azure和其他模型支持（如PyTorch [https://pytorch.org/](https://pytorch.org/））扩展到Azure的计划中，但在撰写本文时尚未确定时间表。
- en: Summary
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you have learned the importance of discovering machine learning.
    In addition, you have also learned the core concepts of machine learning, including
    the differences in learning and the various algorithms we will cover later in
    this book. You have also received an introduction to ML.NET. The core concepts
    in this chapter are the foundation for the rest of the book and we will be building
    on them with each subsequent chapter. In the next chapter, we will be setting
    up your environment and training your first model in ML.NET!
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了发现机器学习的重要性。此外，你还学习了机器学习的核心概念，包括学习和本书后面将要介绍的算法之间的差异。你还接受了ML.NET的简介。本章的核心概念是本书其余部分的基础，我们将在后续章节中在此基础上进行构建。在下一章中，我们将设置你的环境并在ML.NET中训练你的第一个模型！
