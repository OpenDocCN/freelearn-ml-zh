- en: What's Next?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 接下来是什么？
- en: We have come a long way. From the basics and steps for building **machine learning**
    (**ML**) models to actually developing numerous ML models for various real-world
    projects, we have covered a lot so far. After a brief introductory chapter, where
    we learned the basics of ML and the essential steps that go into building ML models,
    we started building ML models. In [Chapter 2](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470), *Spam
    Email Filtering* and [Chapter 3](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470), *Twitter
    Sentiment Analysis*, we discussed building classification models using text datasets.
    In [Chapter 4](part0045.html#1AT9A0-5ebdf09927b7492888e31e8436526470), *Foreign
    Exchange Rate Forecast* and [Chapter 5](part0056.html#1LCVG0-5ebdf09927b7492888e31e8436526470), *Fair
    Value of House and Property*, we used financial and real estate property data
    to build regression models. Then in [Chapter 6](part0073.html#25JP20-5ebdf09927b7492888e31e8436526470), *Customer
    Segmentation*, we covered how to use clustering algorithms to draw intuitive insights
    into customer behavior using the e-commerce dataset. In [Chapter 7](part0082.html#2E6E40-5ebdf09927b7492888e31e8436526470), *Music
    Genre Recommendation* and [Chapter 8](part0097.html#2SG6I0-5ebdf09927b7492888e31e8436526470),
    *Handwritten Digit Recognition*, we expanded our knowledge of building ML models
    to build music recommendation and image recognition models using music records
    and handwritten digit image data. In [Chapter 9](part0116.html#3EK180-5ebdf09927b7492888e31e8436526470),
    *Cyber Attack Detection* and [Chapter 10](part0132.html#3TSA80-5ebdf09927b7492888e31e8436526470), *Credit
    Card Fraud Detection* we built anomaly detection models for cyber attack detection
    and credit card fraud detection.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经走得很远了。从构建**机器学习**（**ML**）模型的基础和步骤，到实际为各种现实世界项目开发众多ML模型，我们已经覆盖了很多内容。在简要的介绍章节中，我们学习了ML的基础知识以及构建ML模型所必需的步骤，然后我们开始构建ML模型。在第2章[垃圾邮件过滤](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470)和第3章[推特情感分析](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470)中，我们讨论了使用文本数据集构建分类模型。在第4章[外汇汇率预测](part0045.html#1AT9A0-5ebdf09927b7492888e31e8436526470)和第5章[房屋和财产的公允价值](part0056.html#1LCVG0-5ebdf09927b7492888e31e8436526470)中，我们使用了金融和房地产数据来构建回归模型。然后在第6章[客户细分](part0073.html#25JP20-5ebdf09927b7492888e31e8436526470)中，我们介绍了如何使用聚类算法通过电子商务数据集来直观地洞察客户行为。在第7章[音乐流派推荐](part0082.html#2E6E40-5ebdf09927b7492888e31e8436526470)和第8章[手写数字识别](part0097.html#2SG6I0-5ebdf09927b7492888e31e8436526470)中，我们将构建ML模型的知识扩展到使用音乐记录和手写数字图像数据构建音乐推荐和图像识别模型。在第9章[网络攻击检测](part0116.html#3EK180-5ebdf09927b7492888e31e8436526470)和第10章[信用卡欺诈检测](part0132.html#3TSA80-5ebdf09927b7492888e31e8436526470)中，我们为网络攻击检测和信用卡欺诈检测构建了异常检测模型。
- en: In this chapter, we are going to review the types of ML model we have built,
    the projects we have worked on so far, and code snippets for training various
    ML models using the Accod.NET framework. We will also discuss some of the challenges
    when using and applying ML in real-life projects and situations. Lastly, we are
    going to cover some of the other software packages that can be used for future
    ML projects, as well as other common technologies that are frequently used by
    data scientists.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将回顾我们构建的ML模型类型、我们迄今为止参与的项目，以及使用Accod.NET框架训练各种ML模型的代码片段。我们还将讨论在现实世界项目和情况中使用和应用ML时的一些挑战。最后，我们将介绍一些可用于未来ML项目的其他软件包，以及数据科学家经常使用的其他常见技术。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: A review of what we have learned so far
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对我们迄今为止所学内容的回顾
- en: Real-life challenges in building ML models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建ML模型中的现实挑战
- en: Other common technologies used by data scientists
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家使用的其他常见技术
- en: Review
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾
- en: From the first chapter onward, we have discussed and covered a large amount
    of material. From discussing the basics of ML to building classification, regression,
    and clustering models, it is worth reviewing what we have done so far before we
    end this book. Let's review some of the essential concepts and code that will
    be helpful for your future C# ML projects.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 从第一章开始，我们已经讨论和覆盖了大量内容。从讨论ML的基础知识到构建分类、回归和聚类模型，在结束这本书之前回顾我们所做的一切是值得的。让我们回顾一些对您未来的C#
    ML项目有帮助的基本概念和代码。
- en: Steps for building ML models
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建ML模型的步骤
- en: 'As discussed in [Chapter 1](part0020.html#J2B80-5ebdf09927b7492888e31e8436526470), *Basics
    of Machine Learning Modeling*, it can be challenging for aspiring data scientists
    and ML engineers to understand the flow and approaches to building real-world
    ML models that will be used in production systems. We have discussed the steps
    for building machine learning models in detail in [Chapter 1](part0020.html#J2B80-5ebdf09927b7492888e31e8436526470),
    *Basics of Machine Learning Modeling*, and we have followed those steps in each
    of the projects that we have worked on so far. The following diagram should be
    a good recap of the essential steps in building real-world ML models:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第1章](part0020.html#J2B80-5ebdf09927b7492888e31e8436526470)“机器学习建模基础”中所述，对于有志于成为数据科学家和机器学习工程师的人来说，理解用于生产系统的现实世界机器学习模型的流程和方法可能具有挑战性。我们在[第1章](part0020.html#J2B80-5ebdf09927b7492888e31e8436526470)“机器学习建模基础”中详细讨论了构建机器学习模型的步骤，并且在我们迄今为止工作的每个项目中都遵循了这些步骤。以下图表应该是对构建现实世界机器学习模型的基本步骤的良好总结：
- en: '![](img/00189.jpeg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00189.jpeg)'
- en: As you should already, we always start a ML project with the problem definition.
    In this step, we define the problems that we are going to solve with ML and why
    we need ML models to solve such problems. This is also the step where we brainstorm
    our ideas and the prerequisites, such as the types of data required, as well as
    the types of learning algorithms that we are going to experiment with. Lastly,
    this is where we need to clearly define the success criteria for the project.
    We can define some evaluation metrics not only for the prediction performance
    of ML models, but also the execution performance of your models, especially if
    the models need to be run in a real-time system, and output the prediction results
    within a given time window.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所知，我们总是从问题定义开始一个机器学习项目。在这一步中，我们定义我们将用机器学习解决的问题以及为什么我们需要机器学习模型来解决这些问题。这也是我们构思想法和前提条件的步骤，例如所需数据的类型，以及我们将要实验的学习算法的类型。最后，这也是我们需要明确定义项目成功标准的步骤。我们可以定义一些评估指标，不仅用于评估机器学习模型的预测性能，还用于评估模型的执行性能，特别是如果模型需要在实时系统中运行，并在给定的时间窗口内输出预测结果。
- en: From the problem definition phase, we move on to the data collection step. For
    those projects that we have worked on in this book, we used publicly available
    data that was already compiled and labeled. However, in real-world situations,
    data might not be available to start with. In this case, we will have to come
    up with approaches to collect the data. For example, if we are planning to build
    ML models for user behavior predictions for users on our website or application,
    then we can collect user activities on the website or application. On the other
    hand, if we are building a credit model to score the credit worthiness of potential
    borrowers, most likely we will not be able to collect data ourselves. In this
    case, we will have to resort to third-party data vendors who sell credit-related
    data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 从问题定义阶段，我们进入数据收集步骤。对于本书中我们已工作的项目，我们使用了已经编译并标记的公开数据。然而，在现实世界中，数据可能一开始就不易获得。在这种情况下，我们必须想出收集数据的方法。例如，如果我们计划为网站或应用程序上的用户行为预测构建机器学习模型，那么我们可以收集网站或应用程序上的用户活动。另一方面，如果我们正在构建一个信用模型来评估潜在借款人的信用价值，那么我们很可能无法自行收集数据。在这种情况下，我们必须求助于销售信用相关数据的第三方数据供应商。
- en: Once we have gathered all of our data, the next thing we will have to do is
    prepare and analyze the data. During the data preparation step, we will need to
    validate the dataset by looking at the formats of the data fields, the existence
    of duplicate records, or the number of missing values. With these criteria checked,
    we can then start analyzing the data to see if there is any noticeable pattern
    in the dataset. If you recall, we typically analyzed the target variable distribution
    first and then we started analyzing the distributions of the features for each
    of the target classes to identify any noticeable patterns that could separate
    the target classes from each other. During the data analysis step, we focused
    on gaining some insights into the patterns in the data, as well as the structure
    of the data itself.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在收集了所有数据之后，接下来我们必须要做的是准备和分析数据。在数据准备步骤中，我们需要通过查看数据字段的格式、重复记录的存在或缺失值的数量来验证数据集。在检查了这些标准后，我们就可以开始分析数据，看看数据集中是否有任何明显的模式。如果你还记得，我们通常首先分析目标变量的分布，然后我们开始分析每个目标类别的特征分布，以识别任何可能将目标类别区分开来的明显模式。在数据分析步骤中，我们专注于深入了解数据中的模式，以及数据本身的结构。
- en: With insight and understanding of the data from the data analysis step, we can
    then start building features that will be used for our ML models. As Andrew Ng
    mentioned, applied ML is basically feature engineering. This is one of the most
    critical steps in building ML models and in determining the performance of our
    prediction models. If you recall, we discussed how to use one-hot encoding to
    transform text features into an encoded matrix of 1s and 0s for our text classification
    problems. We also discussed building time series features, such as moving averages
    and Bollinger Bands and using log transformations for highly skewed features,
    when we were building regression models. This feature engineering step is where
    we need to be creative.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据分析步骤中获得对数据的洞察和理解后，我们就可以开始构建用于我们的机器学习模型的特征。正如Andrew Ng所说，应用机器学习基本上是特征工程。这是构建机器学习模型和确定预测模型性能的最关键步骤之一。如果你还记得，我们讨论了如何使用one-hot编码将文本特征转换为1s和0s的编码矩阵，以解决我们的文本分类问题。我们还讨论了在构建回归模型时构建时间序列特征，如移动平均线和布林带，以及对于高度偏斜的特征使用对数变换。这个特征工程步骤是我们需要发挥创造力的地方。
- en: Once we have all the features ready, we can then move on to training and testing
    various learning algorithms. Depending on whether the target variable is continuous
    or categorical, we can decide whether to build a classification model or regression
    model. If you recall from previous projects, we trained and tested our models
    by using k-fold cross-validation or by splitting the dataset into two subsets
    and training with one group and testing with another hold-out group. Until we
    find the model that we are satisfied with, we will have to repeat the the previous
    steps. If we do not have enough data, we will have to go back to the data collection
    phase and try to collect more data for more accurate models. If we handled duplicate
    records or missing values poorly, we will have to go back to the data preparation
    step to clean up the data. If we can build more and better features, then repeating
    the feature engineering step can help by improving the performance of our ML models.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们准备好了所有特征，我们就可以继续训练和测试各种学习算法。根据目标变量是连续的还是分类的，我们可以决定是构建分类模型还是回归模型。如果你还记得以前的项目，我们通过使用k折交叉验证或通过将数据集分成两个子集，用一组数据进行训练，用另一组保留数据进行测试来训练和测试我们的模型。直到我们找到满意的模型，我们可能需要重复之前的步骤。如果我们没有足够的数据，我们可能需要回到数据收集阶段，尝试收集更多数据以构建更精确的模型。如果我们处理重复记录或缺失值不当，我们可能需要回到数据准备步骤来清理数据。如果我们能构建更多更好的特征，那么重复特征工程步骤可以通过提高我们的机器学习模型性能来帮助。
- en: The last step in building ML models is to deploy them to production systems.
    All the models should have been fully tested and validated by this point. It will
    be beneficial to have some monitoring tools in place before the deployment, so
    that the performance of the models can be monitored.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 构建机器学习模型的最后一步是将它们部署到生产系统中。到这一步，所有模型都应该已经过全面测试和验证。在部署前设置一些监控工具将是有益的，这样就可以监控模型的性能。
- en: We have followed these steps quite thoroughly throughout the chapters, so you
    will realize how comfortable and familiar with these steps you are when you start
    working on your future ML projects. However, there are a couple of essential steps
    that we could not fully cover in this book, such as the data collection and model
    deployment steps, so you should always keep in mind the importance and goals of
    those steps.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在整本书中都非常详细地遵循了这些步骤，所以当你开始着手未来的机器学习项目时，你会意识到你对这些步骤是多么的熟悉和舒适。然而，有一些关键步骤我们在这本书中并没有完全涵盖，比如数据收集和模型部署步骤，所以你应该始终牢记这些步骤的重要性和目标。
- en: Classification models
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类模型
- en: This first two ML models we built in [Chapter 2](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470), *Spam
    Email Filtering* and [Chapter 3](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470), *Twitter
    Sentiment Analysis*, were classification models. In [Chapter 2](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470), *Spam
    Email Filtering*, we built a classification model to classify emails into spam
    and ham (non-spam emails). In [Chapter 3](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470), *Twitter
    Sentiment Analysis*, we built a classification model for Twitter sentiment analysis,
    where the model classified each tweet into one of the three emotions—positive,
    negative, and neutral. Classification problems are common among ML projects. Building
    a model to predict whether a customer will buy an item in an online store is a
    classification problem. Building a model to predict whether a borrower will pay
    back his/her loan is also a classification problem.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第二章](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470)中构建的第一个两个机器学习模型，*垃圾邮件过滤*和[第三章](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470)中的*Twitter情感分析*，都是分类模型。在[第二章](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470)中的*垃圾邮件过滤*，我们构建了一个分类模型来将邮件分类为垃圾邮件和非垃圾邮件（非垃圾邮件）。在[第三章](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470)中的*Twitter情感分析*，我们构建了一个用于Twitter情感分析的分类模型，该模型将每条推文分类为三种情感之一——正面、负面和中性。分类问题在机器学习项目中很常见。构建一个模型来预测客户是否会在在线商店购买商品是一个分类问题。构建一个模型来预测借款人是否会偿还其贷款也是一个分类问题。
- en: If there are only two classes in the target variable, typically a positive outcome
    and a negative outcome, then we call it a binary classification. A good example
    of a binary classification problem is the spam email filtering project that we
    did in [Chapter 2](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470), *Spam
    Email Filtering*. If there are more than two classes in the target variable, then
    we call it a multi-class or multinomial classification. We had a case of having
    to classify a record into three different classes in the Twitter sentiment analysis
    project in [Chapter 3](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470), *Twitter
    Sentiment Analysis*; this was a good example of a multinomial classification problem.
    We had two more classification projects in this book. If you recall, we had eight
    different genres or classes in our target variable for the Music Genre Recommendation
    project in [Chapter 7](part0082.html#2E6E40-5ebdf09927b7492888e31e8436526470), *Music
    Genre Recommendation*, and we had 10 different digits in our target variable for
    the handwritten digit recognition project in [Chapter 8](part0097.html#2SG6I0-5ebdf09927b7492888e31e8436526470),
    *Handwritten Digit Recognition*.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果目标变量中只有两个类别，通常是正面结果和负面结果，那么我们称之为二元分类。二元分类的一个很好的例子是我们[第二章](part0028.html#QMFO0-5ebdf09927b7492888e31e8436526470)中做的垃圾邮件过滤项目。如果目标变量中有超过两个类别，那么我们称之为多类或多项式分类。在[第三章](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470)中的Twitter情感分析项目中，我们不得不将一条记录分类为三个不同的类别；这是一个多项式分类问题的良好例子。在这本书中我们还有两个更多的分类项目。如果你还记得，在我们的音乐流派推荐项目[第七章](part0082.html#2E6E40-5ebdf09927b7492888e31e8436526470)中，目标变量有八个不同的流派或类别，而在我们的手写数字识别项目[第八章](part0097.html#2SG6I0-5ebdf09927b7492888e31e8436526470)中，目标变量有十个不同的数字。
- en: We experimented with numerous learning algorithms, such as logistic regression,
    Naive Bayes, **Support Vector Machine** (**SVM**), random forest, and neural network,
    for the aforementioned classification projects. To remind you how to train these
    learning algorithms in C#, we will reiterate how we initialized some of those
    learning algorithms in C# using the Accord.NET framework.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对多种学习算法进行了实验，例如逻辑回归、朴素贝叶斯、**支持向量机**（**SVM**）、随机森林和神经网络，用于上述分类项目。为了提醒您如何在C#中训练这些学习算法，我们将重述如何使用Accord.NET框架在C#中初始化一些学习算法。
- en: 'The following code snippet shows how we can train a binary logistic regression
    classifier:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了我们如何训练一个二元逻辑回归分类器：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For multinomial classification problems, we trained a logistic regression classifier
    using the following code:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多项式分类问题，我们使用以下代码训练了一个逻辑回归分类器：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When building a Naive Bayes classifier, we used the following code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建朴素贝叶斯分类器时，我们使用了以下代码：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you recall, we used `NormalDistribution` when the features had continuous
    variables, as in the case of the Music Genre Recommendation project, where all
    the features were audio spectrum features and had continuous values. One the other
    hand, we used `BernoulliDistribution`, where the features can only take binary
    values (0 versus 1). In the case of the Twitter sentiment analysis project in
    [Chapter 3](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470), *Twitter Sentiment
    Analysis*, all the features we had could only take 0s or 1s.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还记得，当特征具有连续变量时，我们使用了`NormalDistribution`，例如在音乐流派推荐项目中，所有特征都是音频频谱特征，具有连续值。另一方面，我们使用了`BernoulliDistribution`，其中特征只能取二元值（0与1）。在[第3章](part0036.html#12AK80-5ebdf09927b7492888e31e8436526470)，“Twitter情感分析”项目中，我们拥有的所有特征只能取0或1。
- en: 'The following code shows how we could train a `RandomForestLearning` classifier:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了我们如何训练一个`RandomForestLearning`分类器：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you might already be known, we could tune hyperparameters, such as the number
    of trees in the random forest (`NumberOfTrees`), the proportion of variables that
    can be used at maximum by each tree (`CoverageRatio`), and the proportion of samples
    used to train each of the trees (`SampleRatio`), to find better performing random
    forest models.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已经知道，我们可以调整超参数，例如随机森林中的树的数量（`NumberOfTrees`）、每棵树最多可以使用的变量比例（`CoverageRatio`）以及训练每棵树使用的样本比例（`SampleRatio`），以找到性能更好的随机森林模型。
- en: 'We used the following code to train a SVM model:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下代码来训练一个SVM模型：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If you recall, we could use different kernels for SVMs. On top of the `Gaussian`
    kernel, we could use `Linear` and `Polynomial` kernels as well. Depending on the
    type of dataset you have, one kernel works better than the others and various
    kernels should be tried to find the best performing SVM model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还记得，我们可以为SVM使用不同的核函数。除了`高斯`核之外，我们还可以使用`线性`和`多项式`核。根据您拥有的数据集类型，一个核函数可能比其他核函数表现更好，因此应该尝试各种核函数以找到最佳性能的SVM模型。
- en: 'Lastly, we could train a neural network using the following code:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用以下代码来训练一个神经网络：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As you might recall from [Chapter 8](part0097.html#2SG6I0-5ebdf09927b7492888e31e8436526470), *Handwritten
    Digit Recognition*, we trained a neural network model by running it through the
    dataset multiple times (epochs). After each iteration or epoch, we noticed the
    error rate decreased, as the neural network learned more and more from the dataset.
    We also noticed that in each epoch, the rate of improvements in the error rate
    was in diminishing return, so after enough epochs there would be no significant
    improvement in the performance of a neural network model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能从[第8章](part0097.html#2SG6I0-5ebdf09927b7492888e31e8436526470)，“手写数字识别”中回忆起的那样，我们通过多次（多个epoch）运行数据集来训练一个神经网络模型。在每次迭代或epoch之后，我们注意到错误率下降，因为神经网络从数据集中学习得越来越多。我们还注意到，在每个epoch中，错误率提高的速率是递减的，所以经过足够的epochs后，神经网络模型的性能不会有显著提升。
- en: You can view the code samples at the following link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/ClassificationModelReview.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/ClassificationModelReview.cs).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下链接查看代码示例：[https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/ClassificationModelReview.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/ClassificationModelReview.cs)。
- en: Regression models
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归模型
- en: We have also developed multiple regression ML models. In [Chapter 4](part0045.html#1AT9A0-5ebdf09927b7492888e31e8436526470),
    *Foreign Exchange Rate Forecast*, we worked on the Foreign Exchange Rate Forecast
    project, where we built models that could predict future exchange rates between
    Euros and US dollars. In [Chapter 5](part0056.html#1LCVG0-5ebdf09927b7492888e31e8436526470), *Fair
    Value of House and Property*, we trained different ML models that could predict
    house prices for the Fair Value of House and Property project. Regression problems
    are also common in real-world ML projects. Building a model that predicts the
    lifetime value of a customer is a regression problem. Building a model that predicts
    the maximum amount of money that a potential borrower can borrow without going
    bankrupt is another regression problem.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还开发了多个回归机器学习模型。在[第 4 章](part0045.html#1AT9A0-5ebdf09927b7492888e31e8436526470)
    *外汇汇率预测*中，我们进行了外汇汇率预测项目，构建了可以预测欧元和美元之间未来汇率的模型。在[第 5 章](part0056.html#1LCVG0-5ebdf09927b7492888e31e8436526470)
    *房屋和财产公允价值*中，我们训练了不同的机器学习模型，可以预测房屋和财产公允价值项目的房价。回归问题在现实世界的机器学习项目中也很常见。构建一个预测客户终身价值的模型是一个回归问题。构建一个预测潜在借款人可以借到的最大金额而不破产的模型是另一个回归问题。
- en: We have explored numerous machine learning algorithms for regression projects
    in this book. We have experimented with linear regression and linear SVM models
    in [Chapter 4](part0045.html#1AT9A0-5ebdf09927b7492888e31e8436526470), *Foreign
    Exchange Rate Forecast* for the Foreign Exchange Rate Forecast project. We have
    also tried using different kernels, such as `Polynomial` and `Guassian` kernels,
    for SVM models in [Chapter 5](part0056.html#1LCVG0-5ebdf09927b7492888e31e8436526470), *Fair
    Value of House and Property* for the Fair Value of House and Property project.
    To remind you how to train these regression models in C#, we will reiterate how
    we could use C# and the Accord.NET framework to build these models.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们探讨了回归项目中多种机器学习算法。我们在[第 4 章](part0045.html#1AT9A0-5ebdf09927b7492888e31e8436526470)
    *外汇汇率预测*中尝试了线性回归和线性 SVM 模型。我们还在[第 5 章](part0056.html#1LCVG0-5ebdf09927b7492888e31e8436526470)
    *房屋和财产公允价值*中尝试了 SVM 模型的不同核，例如多项式核和高斯核。为了提醒您如何在 C# 中训练这些回归模型，我们将重述如何使用 C# 和 Accord.NET
    框架构建这些模型。
- en: 'The following code snippet shows how we can train a linear regression model:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了我们如何训练线性回归模型：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'When building a SVM with the linear kernel, we used the following code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用线性核构建 SVM 时，我们使用了以下代码：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As you might recall, `Epsilon`, `Tolerance`, and `UseComplexityHeuristic` are
    hyperparameters that can be tuned further for better model performance. When building
    a SVM model, we recommend you try various combinations of the hyperparameters
    to find the best performing model for your business case.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能记得的，`Epsilon`、`Tolerance` 和 `UseComplexityHeuristic` 是可以进一步调整以获得更好模型性能的超参数。在构建
    SVM 模型时，我们建议您尝试各种超参数组合，以找到最适合您业务案例的最佳性能模型。
- en: 'When we want to use a polynomial kernel for a SVM, we can use the following
    code:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要为 SVM 使用多项式核时，可以使用以下代码：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For a `Polynomial` kernel, you can tune the degree of a polynomial function.
    For example, for a second degree polynomial (quadratic) kernel, you can initialize
    the kernel with `new Polynomial(2)`. Similarly, for a fourth degree polynomial
    kernel, you can initialize the kernel with `new Polynomial(4)`. However, increasing
    the complexity of a kernel can result in overfitting, so you will need to take
    care when using a high-degree polynomial kernel for a SVM.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多项式核，您可以调整多项式函数的次数。例如，对于二次多项式（二次）核，您可以使用 `new Polynomial(2)` 初始化核。同样，对于四次多项式核，您可以使用
    `new Polynomial(4)` 初始化核。然而，增加核的复杂性可能导致过拟合，因此在使用高次数多项式核时需要小心。
- en: 'When we want to build a SVM with a Gaussian kernel, we can use the following
    code:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要使用高斯核构建 SVM 时，可以使用以下代码：
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can find the code samples for the aforementioned regression models at the
    following link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/RegressionModelReview.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/RegressionModelReview.cs).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下链接找到上述回归模型的代码示例：[https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/RegressionModelReview.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/RegressionModelReview.cs)。
- en: Clustering algorithms
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类算法
- en: We discussed one unsupervised learning algorithm, k-means clustering, and how
    it can be used to draw insights from an unlabeled dataset. In [Chapter 6](part0073.html#25JP20-5ebdf09927b7492888e31e8436526470),
    *Customer Segmentation*, we used the k-means clustering algorithm on an e-commerce
    dataset and we learned about different customer behaviors from the dataset. We
    have covered how to use clustering algorithms to build different customer segments,
    based on their purchase history, but there are many other applications of clustering
    algorithms. For example, clustering algorithms can also be used in image analysis,
    for example in partitioning images into sub-sections, and in bioinformatics, such
    as discovering groups of closely related genes (gene clustering).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了一种无监督学习算法，k-means聚类，以及它是如何从未标记的数据集中提取洞察力的。在[第6章](part0073.html#25JP20-5ebdf09927b7492888e31e8436526470)“客户细分”中，我们使用k-means聚类算法对电子商务数据集进行了分析，并从数据集中了解了不同的客户行为。我们已经介绍了如何根据购买历史使用聚类算法构建不同的客户细分，但聚类算法还有许多其他应用。例如，聚类算法也可以用于图像分析，例如将图像划分为子区域，以及在生物信息学中，如发现紧密相关的基因组（基因聚类）。
- en: 'We used the following code to build a k-means clustering algorithm using C#
    and the Accord.NET framework:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下代码使用C#和Accord.NET框架构建了一个k-means聚类算法：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As you might recall, we need to give the number of clusters we want to build
    to the `KMeans` class. One way to programmatically decide the best number of clusters
    that we discussed was to look at the Silhouette score, which measures how similar
    a data point is to its own cluster. Using this Silhouette score, you can iterate
    through different numbers for the number of clusters and then decide which one
    works the best for the given dataset.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所回忆的那样，我们需要向`KMeans`类提供我们想要构建的聚类数量。我们讨论的一种程序化决定最佳聚类数量的方法是通过查看轮廓分数，该分数衡量数据点与其自身聚类的相似程度。使用这个轮廓分数，您可以遍历不同的聚类数量，然后决定哪一个最适合给定的数据集。
- en: You can find the code samples for the k-means clustering algorithm at the following
    link: [https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/ClusteringAlgorithmReview.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/ClusteringAlgorithmReview.cs).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下链接找到k-means聚类算法的代码示例：[https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/ClusteringAlgorithmReview.cs](https://github.com/yoonhwang/c-sharp-machine-learning/blob/master/ch.11/ClusteringAlgorithmReview.cs)。
- en: Real-life challenges
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现实生活中的挑战
- en: 'It would be great if we could just build ML models for all of our business
    problems. However, that is normally not the case. Often, there are more challenges
    in getting to the model development phase than in actually building working models.
    We will discuss the following frequently appearing data science challenges when
    we are working on ML projects:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能为所有业务问题构建机器学习模型那将非常棒。然而，通常并非如此。在到达模型开发阶段时，往往比实际构建工作模型有更多的挑战。当我们从事机器学习项目时，我们将讨论以下经常出现的数据科学挑战：
- en: Data issues
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据问题
- en: Infrastructural issues
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施问题
- en: Explainability versus accuracy
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可解释性与准确性
- en: Data issues
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据问题
- en: Having the right data and enough data is the most important prerequisite for
    building a working ML model. However, often, this is the most difficult part in
    developing ML models for a few different reasons. We will discuss a few common
    challenges that many data scientists face in terms of issues related to data.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有正确的数据和足够的数据是构建一个有效的机器学习模型最重要的先决条件。然而，这通常是开发机器学习模型中最困难的部分，原因有很多。我们将讨论许多数据科学家在数据相关问题方面面临的几个常见挑战。
- en: First, the data needed might simply not exist. For example, think of a recently
    formed online retail store wanting to apply ML to understand or predict their
    customers' spending patterns. Since they are a new business with a small customer
    base, with not much historical purchase data, they will not have enough data for
    data scientists to work with. In this case, all they can do is wait for a better
    time to embark on ML projects, even if they have data scientists on their team.
    Their data scientists will simply not be able to build anything meaningful with
    a limited amount of data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，所需的数据可能根本不存在。例如，想象一家新成立的在线零售店想要应用机器学习来理解或预测其客户的消费模式。由于他们是一家新业务，客户基础小，历史购买数据不多，他们将没有足够的数据供数据科学家使用。在这种情况下，他们唯一能做的就是等待更好的时机开始机器学习项目，即使他们团队中有数据科学家。他们的数据科学家将无法用有限的数据构建出有意义的模型。
- en: Second, the dataset exists, but it is not accessible. This kind of problem happens
    often in big corporations. Due to security issues, accessing the data might have
    been restricted to certain subgroups of an organization. In this case, data scientists
    might have to go through multiple levels of approval from different departments
    or business entities or they might have to build a separate data pipeline, through
    which they can ingest the data that they need. This kind of issue typically means
    it takes a long time before data scientists can start working on the ML project
    that they wanted to work on.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，数据集存在，但无法访问。这类问题在大公司中经常发生。由于安全问题，访问数据可能仅限于组织的某些子组。在这种情况下，数据科学家可能需要通过不同部门或商业实体的多个级别审批，或者他们可能需要构建一个独立的数据管道，通过该管道他们可以摄取所需的数据。这类问题通常意味着数据科学家在开始他们想要从事的机器学习项目之前需要花费很长时间。
- en: Lastly, the data is segmented or too messy. Almost all of the time, the raw
    datasets that data scientists get include messy data and come from different data
    sources. There might be too many missing values or too many duplicate records
    in the data and data scientists will have to spend lots of time cleaning up the
    raw dataset. The data might be too unstructured. This typically happens when you
    work with text-heavy datasets. In this case, you might have to apply various text
    mining and **natural language processing** (**NLP**) techniques to clean up the
    data and make it usable for building ML models.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，数据是分割的或过于杂乱。几乎所有情况下，数据科学家获得的原始数据集都包含杂乱的数据，并来自不同的数据源。数据中可能有太多的缺失值或重复记录，数据科学家将不得不花费大量时间清理原始数据集。数据可能过于非结构化。这种情况通常发生在处理大量文本数据集时。在这种情况下，您可能需要应用各种文本挖掘和**自然语言处理**（**NLP**）技术来清理数据，使其可用于构建机器学习模型。
- en: Infrastructure issues
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础设施问题
- en: Training a ML model on a large dataset requires a large amount of memory and
    CPU resources. As we get bigger and bigger data, it is inevitable that we run
    into infrastructural issues. If you do not have enough memory resources for training
    ML models, you might end up getting *Out of Memory* exceptions after many hours
    or days of training models. If you do not have enough processing power, then training
    a complex ML model can take weeks and even months. Getting the right amount of
    computational resources is a real challenge in building ML models. As the data
    that is being used for ML grows faster than ever, the amount of computational
    resources required also grows significantly year after year.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型数据集上训练机器学习模型需要大量的内存和CPU资源。随着数据的规模越来越大，遇到基础设施问题几乎是不可避免的。如果您没有足够的内存资源来训练机器学习模型，您可能会在训练模型数小时或数天后遇到“内存不足”异常。如果您没有足够的处理能力，那么训练一个复杂的机器学习模型可能需要数周甚至数月。获得正确的计算资源是构建机器学习模型中的一个真正挑战。随着用于机器学习的数据增长速度比以往任何时候都快，所需的计算资源量也逐年显著增加。
- en: With the emerging popularity of cloud computing service providers, such as AWS,
    Google, and Microsoft Azure, it became easier to get the required computational
    resources. On any of those cloud computing platforms, you can easily request and
    use the amount of memory and CPUs that you need. However, as everything comes
    with a price, running ML jobs on those cloud platforms can cost lots of money.
    Depending on your budget, such costs can restrict how much computational resources
    you can use for your ML tasks, and it needs to be planned cleverly.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 随着云计算服务提供商，如AWS、谷歌和微软Azure的日益流行，获取所需的计算资源变得更加容易。在任何这些云计算平台上，您都可以轻松地请求和使用所需的内存和CPU数量。然而，任何事物都有代价，在这些云平台上运行机器学习任务可能会花费大量金钱。根据您的预算，这些成本可能会限制您为机器学习任务可用的计算资源量，因此需要巧妙地规划。
- en: Explainability versus accuracy
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释性与准确性
- en: The last common real-life challenge in ML is the trade-off between the explainability
    and accuracy of ML models. More traditional and linear models, such as logistic
    regression and linear regression models, are easy to explain in terms of the prediction
    output. We can extract the intercept and the coefficients of those linear models
    and we can get the prediction output using simple arithmetic operations. However,
    more complex models, such as random forest and SVM, are more difficult to use
    in terms of explaining the prediction output. Unlike logistic regression or linear
    regression models, we cannot deduce the prediction output from simple arithmetic
    operations. Those complex models work more like a black box. We know the input
    and the output, but what goes in between is a black box to us.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习领域最后一个常见的现实挑战是机器学习模型的可解释性和准确率之间的权衡。更传统和线性的模型，如逻辑回归和线性回归模型，在预测输出的解释上比较容易。我们可以提取这些线性模型的截距和系数，并通过简单的算术运算得到预测输出。然而，更复杂的模型，如随机森林和SVM，在解释预测输出方面更难使用。与逻辑回归或线性回归模型不同，我们不能通过简单的算术运算推导出预测输出。这些复杂模型更像是一个黑盒。我们知道输入和输出，但中间的过程对我们来说是一个黑盒。
- en: This kind of explainability issue among complex learning algorithms becomes
    a problem when users or auditors request explanations about the model behavior.
    If there is such a requirement for explainability, we will have to resort to more
    traditional linear models, even if more complex models perform better than those
    linear models.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户或审计员要求对模型行为进行解释时，这种复杂学习算法的可解释性问题成为一个问题。如果存在对可解释性的这种要求，我们可能不得不求助于更传统的线性模型，即使更复杂的模型在性能上优于这些线性模型。
- en: Other common technologies
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他常见技术
- en: As the field of ML and data science is evolving faster than ever, the number
    of new technologies being built is also growing at a fast pace. There are many
    resources and tools that help in building ML solutions and applications more easily
    and quickly. We are going to discuss a few technologies and tools that we recommend
    you get acquainted with for your future ML projects.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器学习和数据科学领域的发展速度比以往任何时候都要快，正在建设的新的技术数量也在以极快的速度增长。有许多资源和工具可以帮助我们更轻松、更快速地构建机器学习解决方案和应用。我们将讨论一些我们推荐您熟悉的技术和工具，以便您在未来的机器学习项目中使用。
- en: Other ML libraries
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他机器学习库
- en: The Accord.NET framework that we have used throughout this book is one of the
    most frequently used and well documented frameworks for ML. However, other libraries
    that are built for ML in C# are worth mentioning and taking a look at for your
    future ML projects.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这本书中使用的Accord.NET框架是机器学习中最常用且文档最完善的框架之一。然而，其他为C#编写的机器学习库也值得提及并关注您未来的机器学习项目。
- en: '**Encog** is a ML framework that can be used in Java and C#. It is very similar
    to the Accord.NET framework that we have been using, in the sense that is has
    a wide range of numerous ML algorithms available within the framework. This framework
    is well documented and has lots of sample code that can be referenced for your
    future machine learning projects. More information and documentation about the **Encog**
    framework can be found at the following link: [https://www.heatonresearch.com/encog/](https://www.heatonresearch.com/encog/).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**Encog**是一个可以在Java和C#中使用的机器学习框架。在某种程度上，它与我们所使用的Accord.NET框架非常相似，因为它在框架内提供了广泛的机器学习算法。这个框架有很好的文档，并且有很多示例代码可以参考，用于您的未来机器学习项目。关于**Encog**框架的更多信息可以在以下链接找到：[https://www.heatonresearch.com/encog/](https://www.heatonresearch.com/encog/)。'
- en: '**Weka** is another ML framework, but it is different from the Accord.NET framework
    in the sense that the **Weka** framework is specifically engineered for data mining.
    It is broadly used by many researchers and has good documentation and even a book
    that explains how to use **Weka** for data mining. Weka is written in Java, but
    it can also be used in C#. More information about the **Weka** framework can be
    found at the following link: [https://www.cs.waikato.ac.nz/~ml/index.html](https://www.cs.waikato.ac.nz/~ml/index.html).
    Also, information about how to use the **Weka** framework in C# can be found at
    the following link: [https://weka.wikispaces.com/Use%20WEKA%20with%20the%20Microsoft%20.NET%20Framework](https://weka.wikispaces.com/Use%20WEKA%20with%20the%20Microsoft%20.NET%20Framework).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**Weka** 是另一个机器学习框架，但它在意义上与 Accord.NET 框架不同，因为 **Weka** 框架是专门为数据挖掘而设计的。它被许多研究人员广泛使用，并且有良好的文档，甚至有一本书解释了如何使用
    **Weka** 进行数据挖掘。Weka是用 Java 编写的，但它也可以用于 C#。有关 **Weka** 框架的更多信息可以在以下链接中找到：[https://www.cs.waikato.ac.nz/~ml/index.html](https://www.cs.waikato.ac.nz/~ml/index.html)。你还可以在以下链接中找到有关如何在
    C# 中使用 **Weka** 框架的信息：[https://weka.wikispaces.com/Use%20WEKA%20with%20the%20Microsoft%20.NET%20Framework](https://weka.wikispaces.com/Use%20WEKA%20with%20the%20Microsoft%20.NET%20Framework)。'
- en: Lastly, you can always search in NuGet, the package manager for .NET, for any
    other machine learning frameworks for C#. Any library or package that is available
    on NuGet can easily be downloaded and referenced in your development environment.
    It is a good practice to search the following link for any packages you might
    need or that might be helpful for your future machine learning projects: [https://www.nuget.org/](https://www.nuget.org/).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以在 NuGet 中搜索任何其他用于 C# 的机器学习框架。任何在 NuGet 上可用的库或包都可以轻松下载并在你的开发环境中引用。搜索以下链接以查找你可能需要的或可能对你的未来机器学习项目有帮助的任何包是一个好习惯：[https://www.nuget.org/](https://www.nuget.org/)。
- en: Data visualization libraries and tools
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据可视化库和工具
- en: The next set of tools and packages that we are going to discuss is about data
    visualizations. ML and data visualization are an inseparable combination for data
    science. For any ML models that you build, you should be able to present your
    findings, model performance, and model results to users or business partners.
    Furthermore, for continuous model performance monitoring purposes, data visualization
    techniques are often used to identify any issues with the models in production
    systems or any potential deterioration in the model performance. As a result,
    many data visualization libraries were built to make data visualization tasks
    easier.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来要讨论的工具和包系列是关于数据可视化的。机器学习（ML）和数据可视化是数据科学中不可分割的组合。对于你构建的任何机器学习模型，你应该能够向用户或商业伙伴展示你的发现、模型性能和模型结果。此外，为了持续监控模型性能，数据可视化技术通常被用来识别生产系统中模型的任何问题或模型性能的任何潜在下降。因此，许多数据可视化库被构建出来以简化数据可视化任务。
- en: '**LiveCharts** is a .NET library for data visualization. We have used the Accord.NET
    framework''s charting libraries throughout this book, but for more complex plots,
    we recommend using **LiveCharts**. From basic charts, such as line and bar charts,
    to complex interactive charts, you can build various visualizations in C# relatively
    easily. The **LiveCharts** library has thorough documentation and lots of examples
    along with sample code. You can find more information about how to use **LiveCharts**
    for data visualizations at the following link: [https://lvcharts.net/](https://lvcharts.net/).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**LiveCharts** 是一个用于数据可视化的 .NET 库。在这本书中，我们一直使用 Accord.NET 框架的图表库，但对于更复杂的图表，我们推荐使用
    **LiveCharts**。从基本的图表，如折线图和柱状图，到复杂的交互式图表，你可以在 C# 中相对容易地构建各种可视化。**LiveCharts**
    库有详尽的文档和大量的示例以及示例代码。你可以在以下链接中找到有关如何使用 **LiveCharts** 进行数据可视化的更多信息：[https://lvcharts.net/](https://lvcharts.net/)。'
- en: 'Aside from the C#.NET library for data visualization tasks, there are two more
    data visualization tools that are frequently used in the data science community:
    **D3.js** and **Tableau**. **D3.js** is a JavaScript library for building and
    presenting charts on web pages. Often, this JavaScript library is used to create
    a dashboard for various data science and data visualization tasks. **Tableau**
    is a business intelligence tool, with which you can drag and drop to create various
    visualizations. This tool is frequently used to create a dashboard not only by
    data scientists, but also by non-data professionals. For more information about
    the **D3.js** library, you can follow this link: [https://d3js.org/](https://d3js.org/).
    For more information about Tableau, you can follow this link: [https://www.tableau.com/](https://www.tableau.com/).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 除了用于数据可视化任务的C#.NET库之外，在数据科学社区中还有两个经常使用的数据可视化工具：**D3.js**和**Tableau**。**D3.js**是一个用于在网页上构建和展示图表的JavaScript库。通常，这个JavaScript库被用来创建各种数据科学和数据可视化任务的仪表板。**Tableau**是一个商业智能工具，您可以使用它拖放创建各种可视化。这个工具不仅被数据科学家使用，还被非数据专业人士使用来创建仪表板。有关**D3.js**库的更多信息，您可以点击此链接：[https://d3js.org/](https://d3js.org/)。有关Tableau的更多信息，您可以点击此链接：[https://www.tableau.com/](https://www.tableau.com/)。
- en: Technologies for data processing
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据处理技术
- en: Lastly, we are going to discuss some commonly used technologies and tools for
    processing data. Throughout this book, we have mostly used CSV files as input
    for our ML modeling projects. We have used the Deedle framework to load, manipulate,
    and aggregate the data. However, often, the type of input data for ML projects
    varies. For some projects, the data might be stored in SQL databases. For other
    projects, the data might be stored across distributed filesystems. Furthermore,
    the source of the input data can even be from real-time streaming services. We
    will briefly discuss a few commonly used technologies for such cases and where
    to look for more detailed information in order for you to do further research.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将讨论一些常用的数据处理技术和工具。在这本书中，我们主要使用CSV文件作为机器学习建模项目的输入。我们使用了Deedle框架来加载数据、操作和汇总数据。然而，机器学习项目的输入数据类型往往各不相同。对于某些项目，数据可能存储在SQL数据库中。对于其他项目，数据可能存储在分布式文件系统中。此外，输入数据的来源甚至可能是实时流服务。我们将简要讨论在这种情况下常用的几种技术，以及如何查找更详细的信息，以便您进行进一步的研究。
- en: SQL databases, such as SQL Server or PostgreSQL, are the most commonly used
    technologies for data storage and data processing. Using the SQL language, data
    scientists can easily retrieve, manipulate, and aggregate data to process and
    prepare the data for their ML projects. As an aspiring data scientist, it will
    be beneficial for you to become more comfortable with using the SQL language for
    processing the data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: SQL数据库，如SQL Server或PostgreSQL，是数据存储和数据处理中最常用的技术。使用SQL语言，数据科学家可以轻松检索、操作和汇总数据，以处理和准备他们的机器学习项目所需的数据。作为一名有抱负的数据科学家，熟悉使用SQL语言来处理数据将是有益的。
- en: Another technology that is often used within the data science community is **Spark**,
    which is a cluster-computing framework. With **Spark**, you can process a large
    amount of data at scale. Using clusters of machines and distributing heavy computations
    across those machines, **Spark** helps in building scalable big data solutions.
    This technology is widely used among numerous organizations and companies, such
    as Netflix, Yahoo, and eBay, which have lots of data to process every day.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学社区中经常使用的一种技术是**Spark**，它是一个集群计算框架。使用**Spark**，您可以大规模处理大量数据。通过使用机器集群并将重计算分布到这些机器上，**Spark**有助于构建可扩展的大数据解决方案。这项技术在许多组织和公司中广泛使用，例如Netflix、Yahoo和eBay，这些公司每天都要处理大量数据。
- en: Lastly, there are numerous stream-processing technologies for real-time ML applications.
    One of the most popular ones is **Kafka**. This technology is often used when
    building real-time applications or data pipelines that need to continuously stream
    the data. In the case of building real-time ML applications, using a stream-processing
    technology, such as **Kafka**, will be essential for the successful delivery of
    a real-time ML product.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对于实时机器学习应用，存在众多流处理技术。其中最受欢迎的一种是**Kafka**。当构建需要持续流式传输数据的实时应用或数据管道时，这项技术经常被使用。在构建实时机器学习应用的情况下，使用流处理技术，如**Kafka**，对于成功交付实时机器学习产品将是必不可少的。
- en: Summary
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we reviewed what we have discussed so far in this book. We
    briefly went over the essential steps in building ML models. Then, we summarized
    and compiled the code to build various ML models in C# using the Accord.NET framework
    for classification, regression, and clustering problems. We have also discussed
    the real-life challenges that we could not cover in this book, but that you will
    most likely face when you start working on your future ML projects. We discussed
    challenges in accessing and compiling the data to build ML models, infrastructural
    challenges that will occur for big data, and the trade-offs between the explainability
    and accuracy of the ML models. Lastly, we covered some commonly used technologies
    that we recommend you get acquainted with for your future ML projects. The code
    libraries and tools that were mentioned in this chapter are only a subset of the
    tools that are available, and the commonly used tools and technologies are going
    to evolve year on year. We recommend you consistently research upcoming technologies
    for ML and data science.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了本书迄今为止所讨论的内容。我们简要地概述了构建机器学习模型的基本步骤。然后，我们总结并编写了使用 Accord.NET 框架在 C#
    中构建各种机器学习模型的代码。我们还讨论了在本书中未能涵盖但你在开始你的未来机器学习项目时很可能会遇到的现实挑战。我们讨论了访问和编译数据以构建机器学习模型时的挑战，大数据可能出现的架构挑战，以及机器学习模型的可解释性和准确性之间的权衡。最后，我们介绍了一些我们推荐你为未来的机器学习项目熟悉的常用技术。本章中提到的代码库和工具只是可用工具的一个子集，常用的工具和技术将逐年演变。我们建议你持续研究即将到来的机器学习与数据科学技术。
- en: We have covered various ML techniques, tools, and concepts throughout this book.
    As you have worked through this book from building basic classification and regression
    models to complex recommendation and image recognition systems, as well as anomaly
    detection models for real-world problems, I hope you have gained more confidence
    in building ML models for your future ML projects. I hope your journey throughout
    this book was worthwhile and meaningful, and that you have learned and gained
    many new and useful skills.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们涵盖了各种机器学习技术、工具和概念。随着你从构建基本的分类和回归模型到复杂的推荐系统和图像识别系统，以及针对现实问题的异常检测模型的学习，我希望你在构建未来机器学习项目中的机器学习模型方面获得了更多的信心。我希望你在本书中的旅程是值得和有意义的，并且你学到了许多新的和有用的技能。
