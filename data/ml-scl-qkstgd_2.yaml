- en: Scala for Regression Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scala回归分析
- en: 'In this chapter, we will learn regression analysis in detail. We will start
    learning from the regression analysis workflow followed by the **linear regression**
    (**LR**) and **generalized linear regression** (**GLR**) algorithms. Then we will
    develop a regression model for predicting slowness in traffic using LR and GLR
    algorithms and their Spark ML-based implementation in Scala. Finally, we will
    learn the hyperparameter tuning with cross-validation and the grid searching techniques.
    Concisely, we will learn the following topics throughout this end-to-end project:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将详细学习回归分析。我们将从回归分析工作流程开始学习，然后是**线性回归**（**LR**）和**广义线性回归**（**GLR**）算法。然后我们将使用LR和GLR算法及其在Scala中基于Spark
    ML的实现来开发一个预测交通拥堵速度的回归模型。最后，我们将学习使用交叉验证和网格搜索技术进行超参数调整。简而言之，我们将在整个端到端项目中学习以下主题：
- en: An overview of regression analysis
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归分析概述
- en: Regression analysis algorithms
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归分析算法
- en: Learning regression analysis through examples
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过示例学习回归分析
- en: Linear regression
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归
- en: Generalized linear regression
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广义线性回归
- en: Hyperparameter tuning and cross-validation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数调整和交叉验证
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Make sure Scala 2.11.x and Java 1.8.x are installed and configured on your machine.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 确保Scala 2.11.x和Java 1.8.x已安装并配置在您的机器上。
- en: 'The code files of this chapters can be found on GitHub:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在GitHub上找到：
- en: '[https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter02](https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter02)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter02](https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter02)'
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频以查看代码的实际应用：
- en: '[http://bit.ly/2GLlQTl](http://bit.ly/2GLlQTl)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2GLlQTl](http://bit.ly/2GLlQTl)'
- en: An overview of regression analysis
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归分析概述
- en: In the previous chapter, we already gained some basic understanding of the **machine
    learning** (**ML**) process, as we have seen the basic distinction between regression
    and classification. Regression analysis is a set of statistical processes for
    estimating the relationships between a set of variables called a dependent variable
    and one or multiple independent variables. The values of dependent variables depend
    on the values of independent variables.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们已经对**机器学习**（**ML**）过程有了基本的了解，因为我们已经看到了回归和分类之间的基本区别。回归分析是一组用于估计一组称为因变量的变量与一个或多个自变量之间关系的统计过程。因变量的值取决于自变量的值。
- en: 'A regression analysis technique helps us to understand this dependency, that
    is, how the value of the dependent variable changes when any one of the independent
    variables is changed, while the other independent variables are held fixed. For
    example, let''s assume that there will be more savings in someone''s bank when
    they grow older. Here, the amount of **Savings** (say in million $) depends on
    age (that is, **Age** in years, for example):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析技术帮助我们理解这种依赖关系，即当任何一个自变量改变时，因变量的值如何变化，而其他自变量保持不变。例如，假设当人们变老时，他们的银行账户中的储蓄会更多。在这里，**储蓄**的金额（比如说以百万美元为单位）取决于年龄（即**年龄**，例如以年为单位）：
- en: '| **Age (years)** | **Savings (million $)** |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| **年龄（年）** | **储蓄（百万美元）** |'
- en: '| 40 | 1.5 |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 40 | 1.5 |'
- en: '| 50 | 5.5 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 5.5 |'
- en: '| 60 | 10.8 |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 60 | 10.8 |'
- en: '| 70 | 6.7 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 70 | 6.7 |'
- en: So, we can plot these two values in a 2D plot, where the dependent variable
    (**Savings**) is plotted on the *y*-axis and the independent variable (**Age**)
    should be plotted on the *x*-axis. Once these data points are plotted, we can
    see correlations. If the theoretical chart indeed represents the impact of getting
    older on savings, then we'll be able to say that the older someone gets, the more
    savings there will be in their bank account.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以在一个二维图中绘制这两个值，其中因变量（**储蓄**）绘制在 *y* 轴上，而自变量（**年龄**）应该绘制在 *x* 轴上。一旦这些数据点被绘制出来，我们就可以看到相关性。如果理论图表确实代表了随着年龄增长对储蓄的影响，那么我们就能说，一个人越老，他们的银行账户中的储蓄就会越多。
- en: Now the question is how can we tell the degree to which age helps someone to
    get more money in their bank account? To answer this question, one can draw a
    line through the middle of all of the data points on the chart. This line is called
    the regression line, which can be calculated precisely using a regression analysis
    algorithm. A regression analysis algorithm takes either discrete or continuous
    (or both) input features and produces continuous values.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的问题是，我们如何判断年龄对某人银行账户中获取更多金钱的程度有多大？为了回答这个问题，可以在图表中所有数据点的中间画一条线。这条线被称为回归线，可以使用回归分析算法精确计算。回归分析算法接受离散或连续（或两者）输入特征，并产生连续值。
- en: A classification task is used for predicting the label of the class attribute,
    while a regression task is used for making a numeric prediction of the class attribute.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 分类任务用于预测类属性的标签，而回归任务用于对类属性进行数值预测。
- en: 'Making a prediction using such a regression model on unseen and new observations
    is like creating a data pipeline with multiple components working together, where
    we observe an algorithm''s performance in two stages: learning and inference.
    In the whole process and for making the predictive model a successful one, data
    acts as the first-class citizen in all ML tasks.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这样的回归模型对未见过的和新的观察进行预测，就像创建一个由多个组件协同工作的数据管道一样，我们观察到算法的性能分为两个阶段：学习和推理。在整个过程中，为了使预测模型成功，数据在所有机器学习任务中扮演着第一公民的角色。
- en: Learning
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习
- en: 'One of the important task at the learning stage is to prepare and convert the
    data into feature vectors (vectors of numbers out of each feature). Training data
    in feature vector format can be fed into the learning algorithms to train the
    model, which can be used for inferencing. Typically, and of course based on data
    size, running an algorithm may take hours (or even days) so that the features
    converge into a useful model as shown in the following diagram:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习阶段的一个重要任务是准备和转换数据，将其转换为特征向量（每个特征的数值向量）。以特征向量格式训练的数据可以输入到学习算法中，以训练模型，该模型可用于推理。通常，根据数据量的大小，运行算法可能需要数小时（甚至数天），以便特征收敛到一个有用的模型，如下面的图所示：
- en: '![](img/4e9cb443-9b8c-406f-b6ad-bd6718fbba96.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4e9cb443-9b8c-406f-b6ad-bd6718fbba96.png)'
- en: Learning and training a predictive model—it shows how to generate the feature
    vectors from the training data to train the learning algorithm that produces a
    predictive model
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 学习和训练预测模型——展示如何从训练数据生成特征向量以训练产生预测模型的算法
- en: Inferencing
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推理
- en: 'In the inference stage, the trained model is used for making intelligent use
    of the model, such as predicting from never-before-seen data, making recommendations,
    and deducing future rules. Typically, it takes less time compared to the learning
    stage and sometimes even in real time. Thus, inferencing is all about testing
    the model against new (that is, unobserved) data and evaluating the performance
    of the model itself, as shown in the following diagram:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理阶段，训练好的模型被用于智能地使用模型，例如从未见过的数据中进行预测、提供建议和推导未来规则。通常，与学习阶段相比，推理阶段所需时间更少，有时甚至可以实时进行。因此，推理主要是测试模型对新（即未观察到的）数据的性能，并评估模型本身的性能，如下面的图所示：
- en: '![](img/4c8a4f15-9b49-4993-8a42-50525807292c.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4c8a4f15-9b49-4993-8a42-50525807292c.png)'
- en: Inferencing from an existing model towards predictive analytics (feature vectors
    are generated from unknown data for making predictions)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 从现有模型进行推理以进行预测分析（从未知数据生成特征向量以进行预测）
- en: In summary, when using regression analysis the goal is to predict a continuous
    target variable. Now that we know how to construct a basic workflow for a supervised
    learning task, knowing a little about available regression algorithms will provide
    a bit more concrete information on how to apply these regression algorithms.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，当使用回归分析时，目标是预测一个连续的目标变量。现在我们知道了如何构建一个监督学习任务的基本工作流程，了解一些可用的回归算法将提供更多具体信息，了解如何应用这些回归算法。
- en: Regression analysis algorithms
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归分析算法
- en: 'There are numerous algorithms proposed and available, which can be used for
    the regression analysis. For example, LR tries to find relationships and dependencies
    between variables. It models the relationship between a continuous dependent variable
    *y* (that is, a label or target) and one or more independent variables, *x*, using
    a linear function. Examples of regression algorithms include the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 提出了许多算法，可用于回归分析。例如，LR 尝试寻找变量之间的关系和依赖性。它使用线性函数来模型化一个连续的因变量 *y*（即标签或目标）与一个或多个自变量
    *x* 之间的关系。回归算法的例子包括以下：
- en: '**Linear regression** (**LR**)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性回归**（**LR**）'
- en: '**Generalized linear regression** (**GLR**)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广义线性回归**（**GLR**）'
- en: '**Survival regression** (**SR**)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生存回归**（**SR**）'
- en: '**Isotonic regression** (**IR**)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**等调回归**（**IR**）'
- en: '**Decision tree regressor** (**DTR**)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策树回归器**（**DTR**）'
- en: '**Random forest regression** (**RFR**)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林回归**（**RFR**）'
- en: '**Gradient boosted trees regression** (**GBTR**)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度提升树回归**（**GBTR**）'
- en: 'We start by explaining regression with the simplest LR algorithm, which models
    the relationship between a dependent variable, *y*, which involves a linear combination
    of interdependent variables, *x*:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先用最简单的 LR 算法来解释回归，该算法模型化了一个因变量 *y* 与相关变量 *x* 之间的关系，其中 *x* 涉及到相关变量的线性组合：
- en: '![](img/11963a25-c48f-40da-a3e7-5f14b4f4ff65.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![img/11963a25-c48f-40da-a3e7-5f14b4f4ff65.png]'
- en: In the preceding equation letters, *β[0]* and *β[1]* are two constants for *y*-axis
    intercept and the slope of the line, respectively. LR is about learning a model,
    which is a linear combination of features of the input example (data points).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，字母 *β[0]* 和 *β[1]* 分别是 *y*-轴截距和直线的斜率的两个常数。LR 是关于学习一个模型，这个模型是输入示例（数据点）特征的线性组合。
- en: 'Take a look at the following graph and imagine that the red line is not there.
    We have a few dotted blue points (data points). Can we reasonably develop a machine
    learning (regression) model to separate most of them? Now, if we draw a straight
    line between two classes of data, those get almost separated, don''t they? Such
    a line (red in our case) is called the decision boundary, which is also called
    the regression line in the case of regression analysis (see the following example
    for more):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 看看下面的图表，想象一下红线不存在。我们有一些蓝色的点（数据点）。我们能否合理地开发一个机器学习（回归）模型来分离大多数点？现在，如果我们在这两类数据之间画一条直线，那些数据几乎被分开了，不是吗？这样的线（在我们的例子中是红色）被称为决策边界，在回归分析的情况下也称为回归线（以下例子中了解更多）：
- en: '![](img/ed09f3bd-c70c-461d-96d9-ceab36e4465d.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![img/ed09f3bd-c70c-461d-96d9-ceab36e4465d.png]'
- en: 'If we are given a collection of labeled examples, say ![](img/4bbeb78b-a1d8-46cf-a394-d26d3489e864.png), where
    *N* is the number of samples in the dataset, *x[i]* is the *D*-dimensional feature
    vector of the samples *i = 1, 2… N*, and *y[i]* is a real-valued *y ∈ R*, where
    *R* denotes the set of all real numbers called the target variable and every feature *x[i ]*is
    a real number. Then combining these, the next step is to build the following mathematical
    model, *f*:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们给定一组标记的示例，例如 ![img/4bbeb78b-a1d8-46cf-a394-d26d3489e864.png]，其中 *N* 是数据集中的样本数量，*x[i]*
    是样本 *i = 1, 2… N* 的 *D*-维特征向量，而 *y[i]* 是一个实值 *y ∈ R*，其中 *R* 表示所有实数的集合，称为目标变量，每个特征
    *x[i]* 是一个实数。然后结合这些，下一步是构建以下数学模型，*f*：
- en: '![](img/000a67b5-7349-4298-8ca3-3c8e63c0d435.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![img/000a67b5-7349-4298-8ca3-3c8e63c0d435.png]'
- en: Here, *w* is a *D*-dimensional parameterized vector and *b* is a real number.
    The notation *f[w,b]* signifies that the model *f* is parameterized by values
    *w* and *b*. Once we have a well-defined model, it can now be used for making
    a prediction of unknown *y* for a given *x,* that is, *y ← f[w,b ](x)*. However,
    there is an issue, as since the model is parametrized with two different values
    (*w*, *b*), this will mean the model tends to produce two different predictions
    when applied to the same sample, even when coming from the same distribution.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*w* 是一个 *D*-维参数化向量，而 *b* 是一个实数。符号 *f[w,b]* 表示模型 *f* 由值 *w* 和 *b* 参数化。一旦我们有一个定义良好的模型，现在就可以用它来预测给定
    *x* 的未知 *y*，即 *y ← f[w,b](x)*。然而，存在一个问题，因为模型由两个不同的值（*w*，*b*）参数化，这意味着当应用于相同的样本时，模型往往会产生两个不同的预测，即使它们来自相同的分布。
- en: 'Literally, it can be referred as an optimization problem—where the objective
    is to find the optimal (that is, minimum, for example) values ![](img/ee4deb14-39bd-475d-b9d7-77be4da025a6.png) such
    that the optimal values of parameters will mean the model tends to make more accurate
    predictions. In short, in the LR model, we intend to find the optimal values for ![](img/d17f18d1-2969-40c3-bc5c-9d45e3f90ca0.png)
    and ![](img/14c7a856-3f2d-47a4-9510-8404fb177d51.png) to minimize the following
    objective function:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 严格来说，它可以被称作一个优化问题——其目标是在满足参数最优值（即最小值，例如）的条件下找到最优值 ![图片](img/ee4deb14-39bd-475d-b9d7-77be4da025a6.png)
    ，这样参数的最优值将意味着模型倾向于做出更准确的预测。简而言之，在LR模型中，我们旨在找到 ![图片](img/d17f18d1-2969-40c3-bc5c-9d45e3f90ca0.png)
    和 ![图片](img/14c7a856-3f2d-47a4-9510-8404fb177d51.png) 的最优值以最小化以下目标函数：
- en: '![](img/a0097bfe-fc96-41dc-8b43-7da46a2d8f17.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a0097bfe-fc96-41dc-8b43-7da46a2d8f17.png)'
- en: 'In the preceding equation, the expression *(f [w,b] (X[i]) - y[i])²* is called
    the **loss function**, which is a measure of penalty (that is, error or loss)
    for giving the wrong prediction for sample *i*. This loss function is in the form
    of squared error loss. However, other loss functions can be used too, as outlined
    in the following equations:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，表达式 *(f [w,b] (X[i]) - y[i])²* 被称为**损失函数**，它是对于样本*i*给出错误预测的惩罚（即错误或损失）的度量。这个损失函数的形式是平方误差损失。然而，也可以使用其他损失函数，如下面的方程所示：
- en: '![](img/11416c4c-02dc-44cb-8170-db2194fe7101.png)![](img/c9bbc527-8893-436e-9f81-be0e0fc582b7.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/11416c4c-02dc-44cb-8170-db2194fe7101.png) ![图片](img/c9bbc527-8893-436e-9f81-be0e0fc582b7.png)'
- en: The **squared error** (**SE**) in equation 1 is called *L[2]* loss, which is
    the default loss function for the regression analysis task. On the other hand,
    the **absolute error** (**AE**) in equation (*2)* is called *L[1]* loss.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 方程1中的**平方误差**（**SE**）被称为*L[2]*损失，它是回归分析任务的默认损失函数。另一方面，方程(*2)*中的**绝对误差**（**AE**）被称为*L[1]*损失。
- en: In cases where the dataset has many outliers, using *L[1]* loss is recommend
    more than *L[2]*, because *L[1] *is more robust against outliers.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集有许多异常值的情况下，使用*L[1]*损失比*L[2]*更推荐，因为*L[1]*对异常值更鲁棒。
- en: All model-based learning algorithms have a loss function associated with them.
    Then we try to find the best model by minimizing the cost function. In our LR
    case, the cost function is defined by the average loss (also called empirical
    risk), which can be formulated as the average of all penalties obtained by fitting
    the model to the training data, which may contain many samples.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 所有基于模型的机器学习算法都与一个损失函数相关联。然后我们尝试通过最小化成本函数来找到最佳模型。在我们的线性回归（LR）案例中，成本函数由平均损失（也称为经验风险）定义，它可以表示为将模型拟合到训练数据（可能包含许多样本）所获得的全部惩罚的平均值。
- en: '*Figure 4* shows an example of simple linear regression. Let''s say the idea
    is to predict the amount of **Savings** versus **Age**. So, in this case, we have
    one independent variable *x* (that is, a set of 1D data points and, in our case,
    the **Age**) and one dependent variable, *y* (amount of **Savings (in millions
    $)**). Once we have a trained regression model, we can use this line to predict
    the value of the target *y[l]* for a new unlabeled input example, *x[l].* However,
    in the case of *D* -dimensional feature vectors (for example, *2D* or *3D*), it
    would be a plane (for *2D*) or a hyperplane (for *>=3D*):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4*展示了简单线性回归的一个例子。假设我们的想法是预测储蓄额与年龄的关系。因此，在这种情况下，我们有一个自变量*x*（即一组一维数据点和在我们的案例中，**年龄**）和一个因变量*y*（储蓄额，以百万美元计）。一旦我们有一个训练好的回归模型，我们可以使用这条线来预测新未标记输入示例的目标*y[l]*的值，即*x[l]*。然而，在*D*维特征向量（例如，*2D*或*3D*）的情况下，它将是一个平面（对于*2D*）或超平面（对于*>=3D*）：'
- en: '![](img/113ca892-0d37-4fd7-8dc6-0e149613c560.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/113ca892-0d37-4fd7-8dc6-0e149613c560.png)'
- en: 'Figure 4: A regression line separates data points to solve Age versus the amount
    of Savings: i) the left model separates data points based on training data: ii)
    the right model predicts for an unknown observation'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：一条回归线将数据点分开以解决年龄与储蓄额的关系：i) 左侧模型基于训练数据分离数据点；ii) 右侧模型对未知观察值进行预测
- en: 'Now you see why it is important to have the requirement that the regression
    hyperplane lies as close to the training examples as possible: if the blue line
    in *Figure 4* (the model on the right) is far away from the blue dots, the prediction
    *y[l]* is less likely to be correct. The best fit line, which is expected to pass
    through most of the data points, is the result of the regression analysis. However,
    in practice it does not pass through all of the data points because of the existence
    of regression errors.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以看到为什么要求回归超平面尽可能靠近训练样本是如此重要：如果 *图 4*（右侧的模型）中的蓝色线远离蓝色点，预测值 *y[l]* 就不太可能是正确的。最佳拟合线，预期将通过大多数数据点，是回归分析的结果。然而，在实践中，由于回归误差的存在，它并不通过所有数据点。
- en: Regression error is the distance between any data points (actual) and the line
    (predicted).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 回归误差是任何数据点（实际）与线（预测）之间的距离。
- en: Since solving a regression problem is itself an optimization problem, we expect
    a smaller margin for errors as possible because smaller errors contribute towards
    higher predictive accuracy, while predicting unseen observations. Although an
    LR algorithm is not so efficient in many cases, the nicest thing is that an LR
    model usually does not overfit, which is unlikely for a more complex model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由于解决回归问题本身就是一个优化问题，我们期望尽可能小的误差范围，因为较小的误差有助于提高预测准确性，同时预测未见过的观测值。尽管 LR 算法在许多情况下并不高效，但最好的一点是
    LR 模型通常不会过拟合，这对于更复杂的模型来说是不太可能的。
- en: In the previous chapter, we discussed overfitting (a phenomenon whereby a model
    that shows a model predicts very well during the training but makes more errors
    when applied to test set) and underfitting (if your training error is low and
    your validation error is high, then your model is most likely overfitting your
    training data). Often these two phenomena occur due to bias and variance.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了过拟合（一个现象，即模型在训练期间预测得非常好，但在应用于测试集时却犯了更多错误）和欠拟合（如果您的训练误差低而验证误差高，那么您的模型很可能是过拟合了训练数据）。这两种现象通常是由于偏差和方差引起的。
- en: Performance metrics
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能指标
- en: 'To measure the predictive performance of a regression model, several metrics
    are proposed and in use in terms of regression errors, which can be outlined as
    follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了衡量回归模型的预测性能，提出了几个基于回归误差的指标，可以概括如下：
- en: '**Mean squared error (MSE)**: It is the measure of the difference between the
    predicted and estimated values, that is, how close a fitted line is to data points.
    The smaller the MSE, the closer the fit is to the data.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均方误差 (MSE)**: 它是预测值和估计值之间差异的度量，即拟合线与数据点之间的接近程度。MSE 越小，拟合线与数据越接近。'
- en: '**Root mean squared error (RMSE)**: It is the square root of the MSE but has
    the same units as the quantity plotted on the vertical axis.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均方根误差 (RMSE)**: 它是 MSE 的平方根，但具有与垂直轴上绘制的数量相同的单位。'
- en: '**R-squared**: It is the coefficient of determination for assessing how close
    the data is to the fitted regression line ranges between 0 and 1\. The higher
    the R-squared, the better the model fits your data.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**R²**: 它是确定系数，用于评估数据与拟合回归线之间的接近程度，范围在 0 到 1 之间。R² 越高，模型与数据的拟合度越好。'
- en: '**Mean absolute error (MAE)**: It is a measure of *accuracy* for continuous
    variables without considering their direction. The smaller the MAE, the better
    the model fits your data.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均绝对误差 (MAE)**: 它是连续变量精度的度量，不考虑其方向。MAE 越小，模型与数据的拟合度越好。'
- en: Now that we know how a regression algorithm works and how to evaluate the performance
    using several metrics, the next important task is to apply this knowledge to solve
    a real-life problem.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了回归算法的工作原理以及如何使用几个指标来评估性能，下一个重要的任务是应用这些知识来解决现实生活中的问题。
- en: Learning regression analysis through examples
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过示例学习回归分析
- en: In the previous section, we discussed a simple real-life problem (that is, **Age**
    versus **Savings**). However, in practice, there are several real-life problems
    where more factors and parameters (that is, data properties) are involved, where
    regression can be applied too. Let's first introduce a real-life problem. Imagine
    that you live in Sao Paulo, a city in Brazil, where every day several hours of
    your valuable time are wasted because of unavoidable reasons such as an immobilized
    bus, broken truck, vehicle excess, accident victim, overtaking, fire vehicles,
    incident involving dangerous freight, lack of electricity, fire, and flooding.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了一个简单的现实生活中的问题（即**年龄**与**储蓄**）。然而，在实践中，存在许多涉及更多因素和参数（即数据属性）的现实生活问题，在这些问题中也可以应用回归。让我们首先介绍一个现实生活中的问题。想象一下，你住在巴西的圣保罗市，每天由于不可避免的诸如公交车停滞、损坏的卡车、车辆过多、事故受害者、超车、消防车辆、涉及危险货物的意外、电力短缺、火灾和洪水等原因，你宝贵的时间有几小时被浪费了。
- en: Now, to measure how many man hours get wasted, we can we develop an automated
    technique, which will predict the slowness of traffic such that you can avoid
    certain routes or at least get some rough estimation of how long it'll take you
    to reach some point in the city. A predictive analytics application using machine
    learning is probably one of the preferred solutions for predicting such slowness.
    Yes, for that we'll use the behavior of the urban traffic of the city of Sao Paulo
    in Brazil dataset in the next section.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了衡量浪费了多少人工小时，我们可以开发一种自动化的技术，该技术可以预测交通的缓慢程度，这样你就可以避免某些路线，或者至少得到一些粗略的估计，了解你到达城市某个地点需要多长时间。使用机器学习的预测分析应用程序可能是预测这种缓慢程度的首选解决方案。是的，为此我们将使用巴西圣保罗市城市交通行为数据集。在下一节中，我们将使用这个数据集。
- en: Description of the dataset
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集描述
- en: 'The dataset is downloaded from [https://archive.ics.uci.edu/ml/datasets/Behavior+of+the+urban+traffic+of+the+city+of+Sao+Paulo+in+Brazil](https://archive.ics.uci.edu/ml/datasets/Behavior+of+the+urban+traffic+of+the+city+of+Sao+Paulo+in+Brazil).
    It contains the records of behavior of the urban traffic of the city of Sao Paulo
    in Brazil between December 14, 2009 and December 18, 2009\. The dataset has the
    following features:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集从[https://archive.ics.uci.edu/ml/datasets/Behavior+of+the+urban+traffic+of+the+city+of+Sao+Paulo+in+Brazil](https://archive.ics.uci.edu/ml/datasets/Behavior+of+the+urban+traffic+of+the+city+of+Sao+Paulo+in+Brazil)下载。它包含2009年12月14日至2009年12月18日之间巴西圣保罗市城市交通行为记录。该数据集具有以下特征：
- en: '**Hour**: Total hours spent on the road'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小时**：在道路上花费的总小时数'
- en: '**Immobilized bus**: Number of immobilized buses'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**停滞的公交车**：停滞的公交车数量'
- en: '**Broken truck**: Number of broken trucks'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**损坏的卡车**：损坏的卡车数量'
- en: '**Vehicle excess**: Number of redundant vehicles'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**车辆过多**：多余的车辆数量'
- en: '**Accident victim**: Number of accident victims on the road or road side'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事故受害者**：道路或道路旁的事故受害者数量'
- en: '**Running over**: Number of running over or taking over cases'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**碾压**：碾压或超车案例的数量'
- en: '**Fire vehicles**: Number of fire trucks and vehicles'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消防车辆**：消防车和其他车辆的数量'
- en: '**Occurrence involving freight**: Number of goods transported in bulk by trucks'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**货运事故**：卡车大量运输的货物数量'
- en: '**Incident involving dangerous freight**: Number of transporter bulk trucks
    involved in accident'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**涉及危险货物的意外**：发生事故的运输散装卡车数量'
- en: '**Lack of electricity**: Number of hours without electricity in the affected
    areas'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电力短缺**：受影响地区无电的小时数'
- en: '**Fire**: Number of fire incidents'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**火灾**：火灾事件的数量'
- en: '**Point of flooding**: Number of points of flooding areas'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**洪水点**：洪水区域的点数量'
- en: '**Manifestations**: Number of places showing construction work ongoing or dangerous
    signs'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**施工或危险标志的表现**：显示施工正在进行或存在危险标志的地方数量'
- en: '**Defect in the network of trolleybuses**: Number of defects in the network
    of trolley buses'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有轨电车网络故障**：有轨电车网络中的故障数量'
- en: '**Tree on the road**: Number of trees on the road or road side that create
    obstacles'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**道路上的树木**：道路上或道路旁的树木数量，它们造成障碍'
- en: '**Semaphore off**: Number of mechanical gadgets with arms, lights, or flags
    that are used as a signal'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信号灯关闭**：用作信号的机械装置，带有臂、灯光或旗帜的数量'
- en: '**Intermittent semaphore**: Number of mechanical gadgets with arms, lights,
    or flags that are used as a signal for a specific period of time'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**间歇性信号灯**：在一定时间内用作信号的机械装置，带有臂、灯光或旗帜'
- en: '**Slowness in traffic**: Number of average hours people got stuck in traffic
    because of the preceding reasons'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交通缓慢**：由于上述原因，人们因交通堵塞而花费的平均小时数'
- en: 'The last feature is the target column, which we want to predict. Since I used
    this dataset, I would like to acknowledge the following publication:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个特征是目标列，这是我们想要预测的。由于我使用了这个数据集，我想感谢以下出版物：
- en: Ferreira, R. P., Affonso, C., & Sassi, R. J. (2011, November). Combination of
    Artificial Intelligence Techniques for Prediction the Behavior of Urban Vehicular
    Traffic in the City of Sao Paulo. In 10th Brazilian Congress on Computational
    Intelligence (CBIC) - Fortaleza, Brazil. (pp.1-7), 2011.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Ferreira, R. P., Affonso, C., & Sassi, R. J. (2011, November). Combination of
    Artificial Intelligence Techniques for Prediction the Behavior of Urban Vehicular
    Traffic in the City of Sao Paulo. In 10th Brazilian Congress on Computational
    Intelligence (CBIC) - Fortaleza, Brazil. (pp.1-7), 2011.
- en: Exploratory analysis of the dataset
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集的探索性分析
- en: 'First, we read the training set for the **exploratory data analysis** (**EDA**).
    Readers can refer to the `EDA.scala` file for this. Once extracted, there will
    be a CSV file named `Behavior of the urban traffic of the city of Sao Paulo in
    Brazil.csv`. Let''s rename the file as `UrbanTraffic.csv`. Also, `Slowness in
    traffic (%)`, which is the last column, represents the percentage of slowness
    in an unusual format: it represents the real number with a comma (`,`), for example,
    `4,1` instead of `4.1`. So I replaced all instances of a comma (`,`) in that column
    with a period (`.`). Otherwise, the Spark CSV reader will treat the column as
    a `String` type:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们读取用于**探索性数据分析**（**EDA**）的训练集。读者可以参考`EDA.scala`文件。一旦提取出来，将会有一个名为`Behavior
    of the urban traffic of the city of Sao Paulo in Brazil.csv`的CSV文件。让我们将文件重命名为`UrbanTraffic.csv`。此外，`Slowness
    in traffic (%)`，即最后一列，以一个不寻常的格式表示缓慢的百分比：它使用逗号（`,`）表示实数，例如`4,1`而不是`4.1`。因此，我将该列中所有逗号（`,`）替换为句号（`.`）。否则，Spark
    CSV读取器将把该列视为`String`类型：
- en: '[PRE0]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'First, let''s load, parse, and create a DataFrame using the `read.csv()` method
    but with the Databricks CSV format (also known as `com.databricks.spark.csv`)
    by setting it to read the header of the CSV file, which is directly applied to
    the columns'' names of the DataFrame created; and the `inferSchema` property is
    set to `true`, because if you don''t specify the `inferSchema` configuration explicitly,
    the float values would be treated as strings*.* This might cause `VectorAssembler`
    to raise an exception such as `java.lang.IllegalArgumentException: Data type StringType
    is not supported`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，让我们使用`read.csv()`方法加载、解析并创建一个DataFrame，但使用Databricks CSV格式（也称为`com.databricks.spark.csv`），通过将其设置为读取CSV文件的标题，这直接应用于创建的DataFrame的列名；并且将`inferSchema`属性设置为`true`，因为如果你没有明确指定`inferSchema`配置，浮点值将被视为字符串*.*
    这可能会导致`VectorAssembler`抛出异常，例如`java.lang.IllegalArgumentException: Data type StringType
    is not supported`：'
- en: '[PRE1]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now let''s print the schema of the DataFrame we just created to check to make
    sure the structure is preserved:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们打印我们刚刚创建的DataFrame的模式，以确保结构得到保留：
- en: '[PRE2]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As seen from the following screenshot, the schema of the Spark DataFrame has
    been correctly identified. Also, as expected, all the features of my ML algorithms
    are numeric (in other words, in integer or double format):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下截图所示，Spark DataFrame的模式已被正确识别。此外，正如预期的那样，我的机器学习算法的所有特征都是数值的（换句话说，以整数或双精度格式）。
- en: '![](img/4d2ffd9c-b6b3-41e5-a06e-ef7868fed189.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4d2ffd9c-b6b3-41e5-a06e-ef7868fed189.png)'
- en: 'You can see that none of the columns are categorical features. So, we don''t
    need any numeric transformation. Now let''s see how many rows there are in the
    dataset using the `count()` method:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，没有任何一列是分类特征。因此，我们不需要任何数值转换。现在让我们使用`count()`方法看看数据集中有多少行：
- en: '[PRE3]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This gives a 135 sample count**.** Now let''s see a snapshot of the dataset
    using the `show()` method, but with only some selected columns so that it can
    make more sense rather than showing all of them. But feel free to use `rawTrafficDF.show()`
    to see all columns:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了135个样本计数**。**现在让我们使用`show()`方法查看数据集的快照，但只选择一些列，以便它更有意义，而不是显示所有列。但请随意使用`rawTrafficDF.show()`来查看所有列：
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As the `Slowness in traffic (%)` column contains continuous values, we have
    to deal with a regression task. Now that we have seen a snapshot of the dataset,
    it would be worth seeing some other statistics such as average claim or loss,
    minimum, and maximum loss of Spark SQL using the `sql()` interface:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`Slowness in traffic (%)`列包含连续值，我们必须处理回归任务。现在我们已经看到了数据集的快照，查看一些其他统计数据可能也很有价值，例如平均索赔或损失、最小和最大损失，使用Spark
    SQL的`sql()`接口：
- en: '![](img/a076e247-3e92-4e9f-9f63-9848530ada55.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a076e247-3e92-4e9f-9f63-9848530ada55.png)'
- en: 'However, before that, let''s rename the last column from `Slowness in traffic
    (%)` to `label`, since the ML model will complain about it. Even after using `setLabelCol`
    on the regression model, it still looks for a column called `label`. This introduces
    a disgusting error saying `org.apache.spark.sql.AnalysisException: cannot resolve
    ''label'' given input columns`:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，在那之前，让我们将最后一列从`交通中的速度（%）`重命名为`label`，因为ML模型会对此提出异议。即使在回归模型上使用了`setLabelCol`之后，它仍然在寻找名为`label`的列。这引入了一个令人讨厌的错误，表示`org.apache.spark.sql.AnalysisException:
    cannot resolve ''label'' given input columns`：'
- en: '[PRE5]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Since we want to execute some SQL query, we need to create a temporary view
    so that the operation can be performed in-memory:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们想要执行一些SQL查询，我们需要创建一个临时视图，以便在内存中执行操作：
- en: '[PRE6]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now let''s average the slowness in the form of a percentage (the deviation
    with standard hours):'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们以百分比的形式平均速度（与标准小时数的偏差）：
- en: '[PRE7]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding line of code should show a 10% delay on average every day across
    routes and based on other factors:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行代码应该在每天的平均情况下在路线和基于其他因素上显示10%的延迟：
- en: '[PRE8]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Also, we can see the number of flood points in the city. However, for that
    we might need some extra effort by changing the column name into a single string
    since it''s a multi-string containing spaces, so SQL won''t be able to resolve
    it:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还可以看到城市中的洪水点数量。然而，为了做到这一点，我们可能需要一些额外的努力，将列名更改为单个字符串，因为它是一个包含空格的多字符串，所以SQL无法解析它：
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This should show as many as seven flood points that could be very dangerous:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该显示多达七个可能非常危险的洪水点：
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'However, the `describe()` method will give these types of statistics more flexibly.
    Let''s do it for the selected columns:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，`describe()`方法将更灵活地提供这些类型的统计信息。让我们为所选列执行此操作：
- en: '[PRE11]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'So, we can see that the slowness varies between `3.4` and `23.4`, which is
    quite high. This is why we need efficient data processing steps so that such a
    relation can be preserved. Now let''s focus on the data preprocessing instead:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到速度在`3.4`和`23.4`之间变化，这相当高。这就是为什么我们需要高效的数据处理步骤，以便保留这种关系。现在让我们专注于数据预处理：
- en: '![](img/1f6af703-9e8a-4f0c-a96b-09601ef91887.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1f6af703-9e8a-4f0c-a96b-09601ef91887.png)'
- en: Feature engineering and data preparation
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程和数据准备
- en: Now that we have seen some properties of the dataset and since there're no null
    values or categorical features, we don't need any other preprocessing or intermediate
    transformations. We just need to do some feature engineering before we can have
    our training and test sets.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了数据集的一些属性，并且由于没有空值或分类特征，我们不需要任何其他预处理或中间转换。我们只需要在我们获得训练和测试集之前做一些特征工程。
- en: The first step before getting these sets is to prepare training data that is
    consumable by the Spark regression model. For this, Spark classification and regression
    algorithms expect two components called `features` and `label`. Fortunately, we
    already have the `label` column. Next, the `features` column has to contain the
    data from all the columns except the `label` column, which can be achieved using
    the `VectorAssembler()` transformer.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在获取这些集合之前的第一步是准备Spark回归模型可消费的训练数据。为此，Spark分类和回归算法期望有两个组件，称为`features`和`label`。幸运的是，我们已经有`label`列。接下来，`features`列必须包含除`label`列之外的所有列的数据，这可以通过使用`VectorAssembler()`转换器来实现。
- en: 'Since all the columns are numeric, we can use `VectorAssembler()` directly
    from the Spark ML library to transform a given list of columns into a single vector
    column. So, let''s collect the list of desirable columns. As you may have guessed,
    we''ll have to exclude the `label` column, which can be done using the `dropRight()`
    method of standard Scala:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有列都是数值型的，我们可以直接从Spark ML库中使用`VectorAssembler()`将给定的列列表转换为一个单一的向量列。因此，让我们收集所需的列列表。正如你可能已经猜到的，我们将不得不排除`label`列，这可以通过使用标准Scala的`dropRight()`方法来完成：
- en: '[PRE12]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now that we have the `VectorAssembler()` estimator, we now call the `transform()`
    method, which will embed selected columns into a single vector column:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了`VectorAssembler()`估计器，我们现在调用`transform()`方法，该方法将所选列嵌入到单个向量列中：
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'As expected, the last line of the preceding code segment shows the assembled
    DataFrame having `label` and `features`, which are needed to train an ML algorithm:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，上一代码段中的最后一行显示了包含`label`和`features`的组装DataFrame，这些是训练ML算法所需的：
- en: '![](img/a0b68aa4-2797-4b5e-9a8f-644d1d4edf84.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a0b68aa4-2797-4b5e-9a8f-644d1d4edf84.png)'
- en: 'We can now proceed to generate separate training and test sets. Additionally,
    we can cache both the sets for faster in-memory access. We use 60% of the data
    to train the model and the other 40% will be used to evaluate the model:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以继续生成单独的训练集和测试集。此外，我们可以缓存这两个集合以实现更快的内存访问。我们使用60%的数据来训练模型，其余的40%将用于评估模型：
- en: '[PRE14]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: That is all we need before we start training the regression models. At first,
    we start training the LR model and evaluate the performance.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练回归模型之前，我们需要做的一切都准备好了。首先，我们开始训练LR模型并评估其性能。
- en: Linear regression
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归
- en: 'In this section, we will develop a predictive analytics model for predicting
    slowness in traffic for each row of the data using an LR algorithm. First, we
    create an LR estimator as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将开发一个预测分析模型，使用LR算法预测数据每一行的交通缓慢情况。首先，我们创建一个LR估计器，如下所示：
- en: '[PRE15]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then we invoke the `fit()` method to perform the training on the training set
    as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们调用`fit()`方法在训练集上执行训练，如下所示：
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now we have the fitted model, which means it is now capable of making predictions.
    So, let''s start evaluating the model on the training and validation sets and
    calculating the RMSE, MSE, MAE, R squared, and so on:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了拟合好的模型，这意味着它现在能够进行预测。所以，让我们开始在训练集和验证集上评估模型，并计算RMSE、MSE、MAE、R平方等：
- en: '[PRE17]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Great! We have managed to compute the raw prediction on the training and the
    test sets. Now that we have both the performance metrics on both training and
    validation sets, let''s observe the results of the training and the validation
    sets:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！我们已经成功计算了训练集和测试集的原始预测结果。现在我们有了训练集和验证集上的性能指标，让我们观察训练集和验证集的结果：
- en: '[PRE18]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The preceding code segment should show something similar. Although, because
    of the randomness, you might experience slightly different output:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码段应该显示类似的内容。尽管如此，由于随机性，你可能会得到略微不同的输出：
- en: '[PRE19]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now that we have the prediction on the test set as well, however, we can't directly
    say if it's a good or optimal regression model. To improve the result further
    with lower MAE, Spark also provides the generalized version of linear regression
    implementation called GLR.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现在我们有了测试集上的预测结果，但我们不能直接说它是一个好或最优的回归模型。为了进一步降低MAE，Spark还提供了线性回归实现的广义版本，称为GLR。
- en: Generalized linear regression (GLR)
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广义线性回归（GLR）
- en: 'In an LR, the output is assumed to follow a Gaussian distribution. In contrast,
    in **generalized linear models** (**GLMs**), the response variable *Y[i]* follows
    some random distribution from a parametric set of probability distributions of
    a certain form. As we have seen in the previous example, following and creating
    a GLR estimator will not be difficult:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归（LR）中，输出被假定为遵循高斯分布。相比之下，在**广义线性模型**（**GLMs**）中，响应变量*Y[i]*遵循来自参数化概率分布集的某种随机分布，这些概率分布具有某种形式。正如我们在前面的例子中所看到的，跟随和创建GLR估计器不会很困难：
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'For the GLR-based prediction, the following response and identity link functions
    are supported based on data types (source: [https://spark.apache.org/docs/latest/ml-classification-regression.html#generalized-linear-regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#generalized-linear-regression)):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于GLR的预测，根据数据类型支持以下响应和身份链接函数（来源：[https://spark.apache.org/docs/latest/ml-classification-regression.html#generalized-linear-regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#generalized-linear-regression)）：
- en: '![](img/fbc3b29b-50ad-4c25-9c92-8a25f3fdd716.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fbc3b29b-50ad-4c25-9c92-8a25f3fdd716.png)'
- en: 'Then we invoke the `fit()` method to perform the training on the training set
    as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们调用`fit()`方法在训练集上执行训练，如下所示：
- en: '[PRE21]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The current implementation through the `GeneralizedLinearRegression` interface
    in Spark supports up to 4,096 features only. Now that we have the fitted model
    (which means it is now capable of making predictions), let''s start evaluating
    the model on training and validation sets and calculating the RMSE, MSE, MAE,
    R squared, and so on:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当前通过Spark中的`GeneralizedLinearRegression`接口的实现仅支持最多4,096个特征。现在我们有了拟合好的模型（这意味着它现在能够进行预测），让我们开始在训练集和验证集上评估模型，并计算RMSE、MSE、MAE、R平方等：
- en: '[PRE22]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Great! We have managed to compute the raw prediction on the training and the
    test sets. Now that we have both the performance metrics on both training and
    test sets, let''s observe the result on the train and the validation sets:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！我们已经成功计算了训练集和测试集的原始预测结果。现在我们有了训练集和测试集上的性能指标，让我们观察训练集和验证集的结果：
- en: '[PRE23]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The preceding code segment should show similar results. Although, because of
    the randomness, you might experience slightly different output:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码段应该显示类似的结果。尽管如此，由于随机性，你可能会遇到略微不同的输出：
- en: '[PRE24]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Using GLR, we can see a slightly worse MAE value and also the RMSE is higher.
    If you see these two examples, we have not got to tune the hyperparameters but
    simply let the models train and evaluate a single value of each parameter. We
    could even use a regularization parameter for reducing overfitting. However, the
    performance of an ML pipeline often improves with the hyperparameter tuning, which
    is usually done with grid search and cross-validation. In the next section, we
    will discuss how we can get even better performance with the cross-validated models.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GLR，我们可以看到略差的MAE值，同时RMSE也更高。如果你看到这两个例子，我们还没有调整超参数，而是简单地让模型训练并评估每个参数的单个值。我们甚至可以使用正则化参数来减少过拟合。然而，ML管道的性能通常随着超参数调整而提高，这通常是通过网格搜索和交叉验证来完成的。在下一节中，我们将讨论如何通过交叉验证模型获得更好的性能。
- en: Hyperparameter tuning and cross-validation
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数调整和交叉验证
- en: In machine learning, the term hyperparameter refers to those parameters that
    cannot be learned from the regular training process directly. These are the various
    knobs that you can tweak on your machine learning algorithms. Hyperparameters
    are usually decided by training the model with different combinations of the parameters
    and deciding which ones work best by testing them. Ultimately, the combination
    that provides the best model would be our final hyperparameters. Setting hyperparameters
    can have a significant influence on the performance of the trained models.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，超参数一词指的是那些不能从常规训练过程中直接学习的参数。这些是你可以在机器学习算法上调整的各种旋钮。超参数通常通过用不同参数组合训练模型，并通过测试决定哪些参数效果最好来决定。最终，提供最佳模型组合的参数将是我们最终的超参数。设置超参数可以对训练模型的性能产生重大影响。
- en: On the other hand, cross-validation is often used in conjunction with hyperparameter
    tuning. Cross-validation (also know asrotation estimation) is a model validation
    technique for assessing the quality of the statistical analysis and results. Cross-validation
    helps to describe a dataset to test the model in the training phase using the
    validation set.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，交叉验证通常与超参数调整一起使用。交叉验证（也称为旋转估计）是一种模型验证技术，用于评估统计分析的质量和结果。交叉验证有助于描述数据集，在训练阶段使用验证集来测试模型。
- en: Hyperparameter tuning
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数调整
- en: 'Unfortunately, there is no shortcut or straightforward way of choosing the
    right combination of hyperparameters based on a clear recipe—of course, experience
    helps. For example, while training a random forest, Matrix factorization, k-means,
    or a logistic/LR algorithm might be appropriate. Here are some typical examples
    of such hyperparameters:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，没有快捷或直接的方法可以根据明确的配方选择正确的超参数组合——当然，经验有所帮助。例如，在训练随机森林、矩阵分解、k-means或逻辑/LR算法时，可能需要适当的超参数。以下是一些此类超参数的典型示例：
- en: Number of leaves, bins, or depth of a tree in tree-based algorithms
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于树的算法中树的数量、bins或深度
- en: Number of iterations
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代次数
- en: Regularization values
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则化值
- en: Number of latent factors in a matrix factorization
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵分解中的潜在因子数量
- en: Number of clusters in a k-means clustering and so on
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k-means聚类中的聚类数量等等
- en: Technically, hyperparameters form an *n*-dimensional space called a param-grid,
    where *n* is the number of hyperparameters. Every point in this space is one particular
    hyperparameter configuration, which is a hyperparameter vector.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，超参数形成一个称为参数网格的*n*-维空间，其中*n*是超参数的数量。这个空间中的每一个点代表一种特定的超参数配置，即超参数向量。
- en: As discussed in [Chapter 1](33fe7442-ce44-4a18-bac6-0e08e9b1ae1e.xhtml), *Introduction
    to Machine Learning with Scala*, overfitting and underfitting are two problematic
    phenomena in machine learning. Therefore, sometimes full convergence to a best
    model parameter set is often not necessary and can be even preferred, because
    an almost-best-fitting model tends to perform better on new data or settings.
    In other words, if you care for a best fitting model, you really don't need the
    best parameter set.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第1章](33fe7442-ce44-4a18-bac6-0e08e9b1ae1e.xhtml)“使用Scala的机器学习入门”中所述，过拟合和欠拟合是机器学习中的两种问题现象。因此，有时不需要完全收敛到最佳模型参数集，甚至可能更倾向于这样做，因为几乎最佳拟合的模型往往在新数据或设置上表现更好。换句话说，如果你关心最佳拟合模型，你实际上并不需要最佳参数集。
- en: 'In practice, we cannot explore every point in this space, so the grid search
    over a subset in that space is commonly used. The following diagram shows some
    high-level idea:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们无法探索这个空间中的每一个点，因此通常使用网格搜索来搜索该空间的一个子集。以下图表展示了某些高级概念：
- en: '![](img/01205c83-200d-47ce-aa8a-d7c03f2909ea.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/01205c83-200d-47ce-aa8a-d7c03f2909ea.png)'
- en: 'Figure 5: Hyperparameter tuning of ML models'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：机器学习模型的超参数调整
- en: 'Although there are several approaches for such a scheme, random search or grid
    search are probably the most well-known techniques used:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有几种这样的方案，但随机搜索或网格搜索可能是最著名的两种技术：
- en: '**Grid search**: Using this approach, different hyperparameters are defined
    in a dictionary that you want to test. Then a param-grid is constructed before
    feeding them into the ML model such that the training can be performed with the
    different combinations. Finally, the algorithm tells you for which combination
    of the hyperparameters you have the highest accuracy.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网格搜索**：使用这种方法，在字典中定义了你想测试的不同超参数。然后在将它们输入ML模型之前构建一个参数网格，以便可以使用不同的组合进行训练。最后，算法会告诉你哪个超参数组合的准确率最高。'
- en: '**Random search**: As you can understand, training an ML model with all possible
    combinations of hyperparameters is a very expensive and time consuming operation.
    However, often we don''t have that much flexibility but still we want to tune
    those parameters. In such a situation, random search could be a workaround. Random
    search is performed through evaluating *n* uniformly random points in the hyperparameter
    space, and selecting the right combination for which the model gives the best
    performance.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机搜索**：正如你可以理解的，使用所有可能的超参数组合来训练一个机器学习模型是一个既昂贵又耗时的操作。然而，我们通常没有那么多灵活性，但我们仍然想调整这些参数。在这种情况下，随机搜索可能是一个解决方案。随机搜索通过评估超参数空间中的*n*个均匀随机点来执行，并选择模型性能最佳的组合。'
- en: Cross-validation
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证
- en: There are two types of cross-validation, called exhaustive cross-validation,
    which includes leave-p-out cross-validation and leave-one-out cross-validation,
    and non-exhaustive cross-validation, which is based on K-fold cross-validation
    and repeated random sub-sampling cross-validation, for example, 5-fold or 10-fold
    cross-validation, is very common.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种交叉验证类型，称为穷举交叉验证，包括留出-p 个样本交叉验证和留出一个样本交叉验证，以及非穷举交叉验证，它基于K折交叉验证和重复随机子采样交叉验证，例如，5折或10折交叉验证，非常常见。
- en: In most of the cases, 10-fold cross-validation is used instead of testing on
    a validation set. Also, the training set should be as large as possible (because
    more data with quality features are good to train the model) not only to train
    the model but because about 5 to 10% of the training set can be used for the cross-validation.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，使用10折交叉验证而不是在验证集上进行测试。此外，训练集应该尽可能大（因为具有高质量特征的数据对训练模型有利），不仅是为了训练模型，而且因为大约5%到10%的训练集可以用于交叉验证。
- en: Using the K-fold cross-validation technique, the complete training data is split
    into K subsets. The model is trained on K-1 subsets; hold the last one for the
    validation. This process is repeated K times so that each time, one of the K subsets
    is used as the validation set and the other K-1 subsets are used to form the training
    set. This way, each of the subsets (fold) is used at least once for both training
    and validation.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 使用K折交叉验证技术，将完整训练数据分成K个子集。模型在K-1个子集上训练；保留最后一个用于验证。这个过程重复K次，这样每次都使用K个子集中的一个作为验证集，其他K-1个子集用于形成训练集。这样，每个子集（折）至少被用于训练和验证一次。
- en: 'Finally, different machine learning models that have been obtained are joined
    by a bagging (or boosting) scheme for classifiers or by averaging (that is, regression).
    The following diagram explains the 10-fold cross-validation technique:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过袋装（或提升）方案将获得的不同的机器学习模型结合在一起，用于分类器或通过平均（即回归）。以下图表解释了10折交叉验证技术：
- en: '![](img/460bc239-46e0-4317-8bfa-48b326d6ae45.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/460bc239-46e0-4317-8bfa-48b326d6ae45.png)'
- en: Figure 6: 10-fold cross-validation technique
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：10折交叉验证技术
- en: Tuning and cross-validation in Spark ML
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark ML中的调整和交叉验证
- en: In Spark ML, before performing the cross-validation, we need to have a `paramGrid`
    (that is a grid of parameters). The `ParamGridBuilder` interface is used in order
    to define the hyperparameter space where `CrossValidator` has to search and finally, `CrossValidator()`
    takes our pipeline, the hyperparameter space of our LR regressor, and the number
    of folds for the cross-validation as parameters.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark ML中，在进行交叉验证之前，我们需要有一个`paramGrid`（即参数网格）。`ParamGridBuilder`接口用于定义`CrossValidator`必须搜索的超参数空间，最后，`CrossValidator()`函数接受我们的流水线、LR回归器的超参数空间以及交叉验证的折数作为参数。
- en: 'So, let''s start creating `paramGrid` by specifying the number of maximum iterations,
    the value of regularization parameter, the value of tolerance, and the elastic
    network parameters, as follows for the LR model (since we observed lower MAE for
    this):'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们通过指定最大迭代次数、正则化参数的值、容忍度的值以及弹性网络参数来开始创建`paramGrid`，如下所示（因为我们观察到对于这个模型MAE较低）：
- en: '[PRE25]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The regularization parameter reduces overfitting by reducing the variance of
    your estimated regression parameters. Now, for a better and more stable performance,
    we can perform 10-fold cross-validation. Since our task is predicting continuous
    values, we need to define `RegressionEvaluator`, that is, the evaluator for regression,
    which expects two input columns—`prediction` and `label`—and evaluates the training
    based on MSE, RMSE, R-squared, and MAE:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化参数通过减少估计回归参数的方差来减少过拟合。现在，为了获得更好的更稳定的性能，我们可以进行10折交叉验证。由于我们的任务是预测连续值，我们需要定义`RegressionEvaluator`，即回归评估器，它期望两个输入列——`prediction`和`label`——并根据MSE、RMSE、R-squared和MAE评估训练：
- en: '[PRE26]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Fantastic, we have created the cross-validation estimator. Now it''s time to
    train the LR model:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了，我们已经创建了交叉验证估计器。现在是时候训练LR模型了：
- en: '[PRE27]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'By the way, Spark provides a way to save a trained ML model using the `save()`
    method:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，Spark提供了一个使用`save()`方法保存训练好的ML模型的方法：
- en: '[PRE28]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Then the same model can be restored from the disk using the `load()` method:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以使用`load()`方法从磁盘恢复相同的模型：
- en: '[PRE29]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then we compute the model''s metrics on the test set similar to the LR and
    GLR models:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们像LR和GLR模型一样在测试集上计算模型的指标：
- en: '[PRE30]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Finally, we gather the metrics and print to get some insights:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们收集指标并打印以获得一些见解：
- en: '[PRE31]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The preceding code segment should show something similar. Although, because
    of the randomness, you might experience slightly different output:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码段应该显示类似的内容。尽管如此，由于随机性的存在，你可能会得到略微不同的输出：
- en: '[PRE32]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: As we can see, both the RMSE and MAE are slightly lower than the non-cross validated
    LR model. Ideally, we should have experienced even lower values for these metrics.
    However, due to the small size of the training as well as test sets, probably
    both the LR and GLR models overfitted. Still, we will try to use robust regression
    analysis algorithms in [Chapter 4](6730e23e-eabb-4628-934a-7ac609049563.xhtml),
    *Scala for Tree-Based Ensemble Techniques*. More specifically, we will try to
    solve the same problem with decision trees, random forest, and GBTRs.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，RMSE和MAE都略低于未进行交叉验证的LR模型。理想情况下，我们应该体验到这些指标甚至更低的值。然而，由于训练集和测试集的规模较小，LR和GLR模型可能都出现了过拟合。尽管如此，我们将在[第4章](6730e23e-eabb-4628-934a-7ac609049563.xhtml)，“基于树的集成技术Scala”，尝试使用稳健的回归分析算法。更具体地说，我们将尝试使用决策树、随机森林和GBTRs来解决相同的问题。
- en: Summary
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have seen how to develop a regression model for analyzing
    insurance severity claims using LR and GLR algorithms. We have also seen how to
    boost the performance of the GLR model using cross-validation and grid search
    techniques, which give the best combination of hyperparameters. Finally, we have
    seen some frequently asked questions so that the similar regression techniques
    can be applied for solving other real-life problems.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了如何使用LR和GLR算法开发用于分析保险严重索赔的回归模型。我们还看到了如何使用交叉验证和网格搜索技术来提高GLR模型的表现，这些技术提供了最佳的超参数组合。最后，我们看到了一些常见问题，以便可以将类似的回归技术应用于解决其他现实生活中的问题。
- en: In the next chapter, we will see another supervised learning technique called
    classification through a real-life problem called analyzing outgoing customers
    through churn prediction. Several classification algorithms will be used for making
    the prediction in Scala. Churn prediction is essential for businesses as it helps
    you detect customers who are likely to cancel a subscription, product, or service,
    which also minimizes customer defection by predicting which customers are likely
    to cancel a subscription to a service.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将通过一个名为通过客户流失预测分析流失客户的真实问题来了解另一种监督学习技术，即分类。在Scala中，我们将使用几种分类算法来进行预测。客户流失预测对商业至关重要，因为它可以帮助你检测可能取消订阅、产品或服务的客户，通过预测哪些客户可能取消对服务的订阅，还可以最小化客户流失。
