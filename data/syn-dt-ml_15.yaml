- en: '15'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '15'
- en: Diversity Issues in Synthetic Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据中的多样性问题
- en: This chapter introduces you to a well-known issue in the field of synthetic
    data, which is generating diverse synthetic datasets. It discusses different approaches
    to ensure high diversity in large-scale datasets. Then, it highlights some issues
    and challenges in achieving diversity for synthetic data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向您介绍合成数据领域的一个众所周知的问题，即生成多样化的合成数据集。它讨论了确保大规模数据集中高度多样性的不同方法。然后，它突出了实现合成数据多样性的问题和挑战。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: The need for diverse data in ML
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习中多样化数据的需求
- en: Generating diverse synthetic datasets
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成多样化的合成数据集
- en: Diversity issues in the synthetic data realm
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合成数据领域中的多样性问题
- en: The need for diverse data in ML
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中多样化数据的需求
- en: As we have discussed and seen in previous chapters, diverse training data improves
    the generalizability of ML models to new domains and contexts. In fact, diversity
    helps your ML-based solution to be more accurate and better applicable to real-world
    scenarios. Additionally, it makes it more robust to noise and anomalies, which
    are usually unavoidable in practice. For more information, please refer to *Diversity
    in Machine Learning* ([https://arxiv.org/abs/1807.01477](https://arxiv.org/abs/1807.01477))
    and *Performance of Machine Learning Algorithms and Diversity in* *Data* ([https://doi.org/10.1051/MATECCONF%2F201821004019](https://doi.org/10.1051/MATECCONF%2F201821004019)).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的章节中讨论和看到的，多样化的训练数据提高了机器学习模型对新领域和上下文的泛化能力。实际上，多样性有助于你的基于机器学习的解决方案更准确，更好地适用于现实世界场景。此外，它使模型对噪声和异常更加鲁棒，这在实践中通常是不可避免的。有关更多信息，请参阅
    *Diversity in Machine Learning* ([https://arxiv.org/abs/1807.01477](https://arxiv.org/abs/1807.01477))
    和 *Performance of Machine Learning Algorithms and Diversity in* *Data* ([https://doi.org/10.1051/MATECCONF%2F201821004019](https://doi.org/10.1051/MATECCONF%2F201821004019))。
- en: 'Next, let’s highlight some of the main advantages of using diverse training
    data in ML. In general, training and validating your ML model on diverse datasets
    improve the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们强调使用多样化训练数据在机器学习中的主要优势。总的来说，在多样化的数据集上训练和验证你的机器学习模型可以提高以下方面：
- en: Transferability
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可迁移性
- en: Problem modeling
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题建模
- en: Security
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全性
- en: The process of debugging
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试过程
- en: Robustness to anomalies
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对异常的鲁棒性
- en: Creativity
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创造力
- en: Customer satisfaction
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户满意度
- en: Now, let’s delve into each of these elements in more detail.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们更详细地探讨这些要素中的每一个。
- en: Transferability
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可迁移性
- en: When you train your ML model on diverse data covering a variety of scenarios,
    contexts, and environments, you boost the transferability of your ML solution
    to other applications and domains. The reason for this is that when the model
    learns how to deal with more diverse situations in the training stage, it becomes
    more capable of adapting to new, unseen contexts. For more information, please
    refer to *Can Data Diversity Enhance Learning* *Generalization?* ([https://aclanthology.org/2022.coling-1.437](https://aclanthology.org/2022.coling-1.437)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在涵盖各种场景、环境和上下文的多样化数据上训练你的机器学习模型时，你提高了你的机器学习解决方案在其他应用和领域中的可迁移性。其原因是，当模型在训练阶段学习如何处理更多样化的情况时，它就更能适应新的、未见过的上下文。有关更多信息，请参阅
    *Can Data Diversity Enhance Learning* *Generalization?* ([https://aclanthology.org/2022.coling-1.437](https://aclanthology.org/2022.coling-1.437))。
- en: Better problem modeling
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更好的问题建模
- en: Diverse training data enables the ML model to look at the problem from different
    perspectives. For example, let’s consider that our ML model is learning a semantic
    segmentation task. Training the model under adverse weather conditions and with
    objects of various colors, textures, and shapes will help the model to better
    learn the mapping from the RGB images to the semantic segmentation ones. Thus,
    it will significantly enhance the performance as the model has already learned
    how to capture a wider range of patterns under various variations. These patterns
    and associations between input features and output labels may not be easily identified
    given a less diverse training dataset.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 多样化的训练数据使机器学习模型能够从不同的角度看待问题。例如，让我们考虑我们的机器学习模型正在学习一个语义分割任务。在恶劣天气条件下以及具有各种颜色、纹理和形状的物体下训练模型，将有助于模型更好地学习从RGB图像到语义分割图像的映射。因此，它将显著提高性能，因为模型已经学会了如何捕捉各种变化下的更广泛范围的模式。这些模式和输入特征与输出标签之间的关联，在训练数据集较少多样化的情况下可能不容易识别。
- en: Security
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安全性
- en: 'Research has recently shown that training your ML model on diverse training
    data can improve the robustness of your model to adversarial attacks. Thus, your
    model becomes even more reliable and secure with diverse training data. For example,
    training your ML model on a diverse set of adversarial training samples significantly
    boosts your ML model’s robustness to adversarial attacks. These attacks primarily
    involve manipulating images with noise to fool the ML model while still making
    them recognizable to the human eye. For instance, a slight change in some pixels’
    intensity such as the color of a traffic sign may cause ML models to wrongly classify
    it under a different class with a high confidence. For more information, please
    refer to *Diversity Adversarial Training against Adversarial Attack on Deep Neural
    Networks* ([http://www.mdpi.com/2073-8994/13/3/428](http://www.mdpi.com/2073-8994/13/3/428))
    and *Adversarial Attacks on Traffic Sign Recognition: A* *Survey* ([https://arxiv.org/pdf/2307.08278.pdf](https://arxiv.org/pdf/2307.08278.pdf)).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究表明，在多样化的训练数据上训练您的机器学习模型可以提高模型对对抗攻击的鲁棒性。因此，多样化的训练数据使您的模型更加可靠和安全。例如，在多样化的对抗训练样本集上训练您的机器学习模型可以显著提高模型对对抗攻击的鲁棒性。这些攻击主要涉及通过添加噪声来操纵图像，以欺骗机器学习模型，同时仍然使它们对人类眼睛来说是可识别的。例如，某些像素强度的轻微变化，如交通标志的颜色，可能会导致机器学习模型以高置信度错误地将它归类为不同的类别。更多信息，请参阅
    *针对深度神经网络对抗攻击的多样性对抗训练* ([http://www.mdpi.com/2073-8994/13/3/428](http://www.mdpi.com/2073-8994/13/3/428))
    和 *对抗攻击在交通标志识别中的应用：一项* *调查* ([https://arxiv.org/pdf/2307.08278.pdf](https://arxiv.org/pdf/2307.08278.pdf))。
- en: Process of debugging
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调试过程
- en: Leveraging diverse data in the validation and evaluation stages helps ML practitioners
    identify the weaknesses and limitations of their ML models and algorithms. Thus,
    they can avoid costly failures under challenging scenarios. Furthermore, they
    can iterate on their solutions and mitigate any potential issues and problems.
    For instance, suppose we are proposing a new person identification ML model. To
    clearly understand the limitations of our model, we need to evaluate the model
    on diverse datasets that cover various illumination conditions, camera viewpoints,
    indoor and outdoor scenes, and other relevant attributes. This will help us to
    spot the weaknesses of our approach. By returning to our example, we may see that
    our model is struggling to identify people at nighttime or when the camera is
    very close to the person. This sort of observation is essential for improving
    the model and preventing costly failures, which cannot be achieved without using
    appropriate diverse validation or evaluation datasets.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 利用多样化的数据在验证和评估阶段有助于机器学习从业者识别其机器学习模型和算法的弱点和局限性。因此，他们可以在具有挑战性的场景下避免代价高昂的失败。此外，他们可以迭代他们的解决方案并减轻任何潜在的问题和问题。例如，假设我们正在提出一个新的个人识别机器学习模型。为了清楚地了解我们模型的局限性，我们需要在涵盖各种照明条件、摄像机视角、室内和室外场景以及其他相关属性的不同数据集上评估该模型。这将帮助我们找出我们方法中的弱点。通过回到我们的例子，我们可能会看到我们的模型在夜间或摄像机非常靠近人的时候难以识别人。这种观察对于改进模型和防止代价高昂的失败至关重要，而这不能在没有使用适当的多样化验证或评估数据集的情况下实现。
- en: Robustness to anomalies
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对异常的鲁棒性
- en: Training your ML model on diverse training data that includes anomalies helps
    the model learn how to deal with similar situations. Thus, it makes your ML-based
    solution more robust against outliers and unexpected situations. For instance,
    let’s suppose you trained your ML model for depth estimation on standard data
    collected by an industry-standard sensor under normal conditions. Your model may
    fail if the camera sensor was partially damaged, or some dust or raindrops accumulated
    on the camera lens. Therefore, training your ML model on similar scenarios improves
    the robustness and reliability of your ML system. Please refer to *A Novel Cross-Perturbation
    for Single Domain Generalization* ([https://arxiv.org/pdf/2308.00918.pdf](https://arxiv.org/pdf/2308.00918.pdf))
    for more in-depth details.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在包含异常的多样化训练数据上训练您的机器学习模型有助于模型学习如何处理类似的情况。因此，它使您的基于机器学习的解决方案对异常值和意外情况更加鲁棒。例如，假设您为深度估计训练了机器学习模型，该模型是在正常条件下由行业标准传感器收集的标准数据上进行的。如果相机传感器部分损坏，或者一些灰尘或雨滴积累在相机镜头上，您的模型可能会失败。因此，在类似的场景下训练您的机器学习模型可以提高您机器学习系统的鲁棒性和可靠性。更多信息，请参阅
    *一种新的跨扰动用于单域泛化* ([https://arxiv.org/pdf/2308.00918.pdf](https://arxiv.org/pdf/2308.00918.pdf))。
- en: Creativity
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创造力
- en: In problems where creativity is a key requirement, training generative models
    on diverse training data is necessary to fuel this need. For instance, an LLM
    or image generator will significantly benefit from being trained on textual or
    visual data collected from different sources. This will help these generative
    models to be exposed to various topics, styles, ideas, and opinions, which will
    provide sufficient knowledge and urge the model to be more creative at various
    tasks and applications. For some interesting examples, please refer to *Deep Dream
    Generator* ([https://deepdreamgenerator.com](https://deepdreamgenerator.com)),
    *AutoDraw* ([https://www.autodraw.com](https://www.autodraw.com)), *Stablecog*
    ([https://stablecog.com](https://stablecog.com)), and *DALL-E* *2* ([https://openai.com/dall-e-2](https://openai.com/dall-e-2)).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在创意是关键要求的领域中，在多样化的训练数据上训练生成模型是满足这一需求所必需的。例如，一个大型语言模型或图像生成器将显著受益于从不同来源收集的文本或视觉数据的训练。这将帮助这些生成模型接触到各种主题、风格、想法和观点，这将提供充足的知识并促使模型在各个任务和应用中更加具有创造力。对于一些有趣的例子，请参阅
    *Deep Dream Generator* ([https://deepdreamgenerator.com](https://deepdreamgenerator.com))、*AutoDraw*
    ([https://www.autodraw.com](https://www.autodraw.com))、*Stablecog* ([https://stablecog.com](https://stablecog.com))
    和 *DALL-E* *2* ([https://openai.com/dall-e-2](https://openai.com/dall-e-2))。
- en: Inclusivity
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 包容性
- en: Deploying diverse training data that appropriately represents the real world
    helps customers to feel that your ML-based solution is inclusive and does not
    discriminate against any characteristics of the population worldwide. Therefore,
    it is essential to ensure that your ML model works as intended for all customers
    regardless of their age, race, gender, geography, language, and religion. If customers
    feel that they are disadvantaged because of any of the previous factors, they
    will develop a negative impression of your business, not just the application
    itself. Additionally, it may cause legal issues and unwanted consequences to organizations.
    On the other hand, it helps decision-makers to make more appropriate decisions
    that take into careful consideration the unique needs of each demographic group
    of the target audience.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 部署适当代表现实世界的多样化训练数据有助于让客户感觉到你的基于机器学习的解决方案是包容性的，不会歧视全球人口的任何特征。因此，确保你的机器学习模型对所有客户都能按预期工作，无论他们的年龄、种族、性别、地理位置、语言和宗教，这一点至关重要。如果客户因为上述任何因素而感到处于不利地位，他们将对你的业务产生负面印象，而不仅仅是应用程序本身。此外，这还可能导致组织面临法律问题和不良后果。另一方面，这有助于决策者做出更合适的决策，这些决策会仔细考虑目标受众中每个人口群体的独特需求。
- en: Now that we understand the importance of training our ML models on diverse training
    data, let’s examine how to generate diverse synthetic data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了在多样化的训练数据上训练我们的机器学习模型的重要性，让我们来探讨如何生成多样化的合成数据。
- en: Generating diverse synthetic datasets
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成多样化的合成数据集
- en: 'In this section, you will learn different methods of generating diverse synthetic
    datasets. We will discuss the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习到生成多样化合成数据集的不同方法。我们将讨论以下内容：
- en: Latent space variations
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 潜在空间变化
- en: Ensemble synthetic data generation
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成合成数据生成
- en: Diversity regularization
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多样性正则化
- en: Incorporating external knowledge
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合外部知识
- en: Progressive training
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步训练
- en: Procedural content generation with game engines
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用游戏引擎进行程序化内容生成
- en: Latent space variations
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 潜在空间变化
- en: Latent space usually refers to a high-dimensional space where the training data
    is represented in a more abstract or compact way. Deep learning with many layers
    is designed to make the features in the latent space capture more semantic and
    conceptual information. For more details, please refer to [*Chapter 1*](B18494_01.xhtml#_idTextAnchor014).
    Thus, these features, in that space, convey encoded information about the problem
    through the ML model during the training stage. We may not be able to directly
    link the changes in the latent space to the changes that will happen on the generated
    images in models such as GANs. However, it was shown in *Interpreting the Latent
    Space of GANs for Semantic Face Editing* ([https://arxiv.org/abs/1907.10786](https://arxiv.org/abs/1907.10786))
    and *Closed-Form Factorization of Latent Semantics in GANs* ([https://arxiv.org/abs/2007.06600](https://arxiv.org/abs/2007.06600))
    that changing certain attributes in the latent space can generate unique and diverse
    synthetic samples. For instance, if you carefully change certain features in the
    latent space, you may generate new samples with different poses, backgrounds,
    lighting, and weather conditions.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在空间通常指的是一个高维空间，其中训练数据以更抽象或紧凑的方式表示。具有许多层的深度学习旨在使潜在空间中的特征捕获更多语义和概念信息。更多详情，请参阅[*第一章*](B18494_01.xhtml#_idTextAnchor014)。因此，这些特征在该空间中通过机器学习模型在训练阶段传达关于问题的编码信息。我们可能无法直接将潜在空间中的变化与在如GANs等模型中生成的图像上的变化联系起来。然而，在*《解释GANs的潜在空间以进行语义人脸编辑》*([https://arxiv.org/abs/1907.10786](https://arxiv.org/abs/1907.10786))和*《GANs中潜在语义的闭式分解》*([https://arxiv.org/abs/2007.06600](https://arxiv.org/abs/2007.06600))中表明，改变潜在空间中的某些属性可以生成独特且多样化的合成样本。例如，如果你仔细改变潜在空间中的某些特征，你可能会生成具有不同姿势、背景、光照和天气条件的新样本。
- en: Ensemble synthetic data generation
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集合合成数据生成
- en: One of the approaches that is usually deployed to improve the diversity of the
    generated synthetic data is using multiple generative models to ensure that they
    capture the intended data distribution. This is especially applicable if the distribution
    is complex and cannot be modeled using a single generative model. For more information,
    please refer to *Ensembles of GANs for Synthetic Training Data Generation* ([https://arxiv.org/pdf/2104.11797.pdf](https://arxiv.org/pdf/2104.11797.pdf)).
    In this work, multiple GANs were used to improve the generated synthetic data
    diversity. The researchers focused specifically on the effectiveness of this approach
    for synthesizing digital pathology patches. GANs were trained independently and
    in isolation from each other on the training dataset. This work shows that the
    stochasticity of the optimization process is fundamental to better represent the
    training data distribution and enrich the generated data diversity for GANs.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通常部署以提高生成合成数据多样性的一种方法是使用多个生成模型以确保它们能够捕获预期的数据分布。这在分布复杂且无法使用单个生成模型进行建模的情况下尤其适用。更多信息，请参阅*《用于合成训练数据生成的GANs集合》*([https://arxiv.org/pdf/2104.11797.pdf](https://arxiv.org/pdf/2104.11797.pdf))。在这项工作中，使用了多个GANs来提高生成的合成数据多样性。研究人员特别关注了这种方法在合成数字病理切片方面的有效性。GANs在训练数据集上是独立且相互隔离地训练的。这项工作表明，优化过程的随机性对于更好地表示训练数据分布和丰富GANs生成的数据多样性是基本的。
- en: Diversity regularization
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多样性正则化
- en: Another approach to encourage generative models to generate diverse synthetic
    samples is to utilize a regularization term in the training objective or loss.
    In other words, you can penalize the generative model for generating similar synthetic
    samples. Thus, your model will tend to generate more diverse samples to minimize
    the training loss. For example, this approach was utilized in *Mode Seeking Generative
    Adversarial Networks for Diverse Image Synthesis* ([https://arxiv.org/pdf/1903.05628.pdf](https://arxiv.org/pdf/1903.05628.pdf))
    to address the mode collapse issue in GANs and improve the diversity of the generated
    synthetic images. For more details about the mode collapse issue in GANs, please
    refer to [*Chapter 7*](B18494_07.xhtml#_idTextAnchor120). This approach does not
    require any modification to the architecture of the GAN. It simply changes the
    loss to encourage the generator to generate dissimilar images. Thus, the generator
    is urged to better cover the training data distribution and consequently generate
    more diverse synthetic images. For a survey of the regularization approaches in
    GANs, please refer to *A Systematic Survey of Regularization and Normalization
    in* *GANs* ([https://arxiv.org/abs/2008.08930](https://arxiv.org/abs/2008.08930)).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励生成模型生成多样化的合成样本的另一种方法是利用训练目标或损失中的正则化项。换句话说，你可以对生成模型生成相似的合成样本进行惩罚。因此，你的模型将倾向于生成更多样化的样本以最小化训练损失。例如，这种方法在*用于多样化图像合成的模式寻找生成对抗网络*（[https://arxiv.org/pdf/1903.05628.pdf](https://arxiv.org/pdf/1903.05628.pdf)）中被采用，以解决GAN中的模式坍塌问题并提高生成合成图像的多样性。有关GAN中模式坍塌问题的更多详细信息，请参阅[*第7章*](B18494_07.xhtml#_idTextAnchor120)。这种方法不需要对GAN的架构进行任何修改。它只是将损失函数改为鼓励生成器生成不同的图像。因此，生成器被鼓励更好地覆盖训练数据分布，从而生成更多样化的合成图像。关于GAN中正则化方法的综述，请参阅*GAN中的正则化和归一化系统调查*（[https://arxiv.org/abs/2008.08930](https://arxiv.org/abs/2008.08930)）。
- en: Incorporating external knowledge
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结合外部知识
- en: 'You can also condition the generation process to encourage the generative models
    to generate synthetic data with certain attributes and under specific scenarios.
    For example, if your data has fewer training samples taken in rainy conditions,
    you can explicitly condition the GAN model to generate more examples under this
    weather condition. Additionally, you may prevent generative models from generating
    examples that are not relevant to your problem. For example, if you are generating
    cat images in an indoor environment, you may prevent your GAN from generating
    examples under adverse weather conditions as they are not valid in this particular
    environment. This can be achieved through various means, such as modifying the
    loss function to impose penalties on these irrelevant or unwanted predictions.
    In this scenario, the discriminator would need to make at least two distinct predictions:
    one for assessing whether the sample is real or fake and another for determining
    its relevance.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以对生成过程进行条件化，以鼓励生成模型生成具有特定属性和特定场景下的合成数据。例如，如果你的数据在雨天采集的训练样本较少，你可以明确地条件化GAN模型以生成更多这种天气条件下的示例。此外，你可能防止生成模型生成与你的问题不相关的示例。例如，如果你在室内环境中生成猫的图像，你可能防止你的GAN在恶劣天气条件下生成示例，因为这些条件在这个特定环境中是不适用的。这可以通过各种方式实现，例如修改损失函数对这些无关或不希望的预测施加惩罚。在这种情况下，判别器至少需要做出两个不同的预测：一个用于评估样本是真实还是虚假，另一个用于确定其相关性。
- en: Progressive training
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进阶训练
- en: Another interesting approach to increase the diversity of the generated synthetic
    samples is to gradually introduce more complex patterns, add more layers to the
    generator and discriminator throughout the training process, and penalize for
    less diverse examples during the training stage. This encourages the synthetic
    data generation model to generate more diverse and variant data. For example,
    researchers in *Progressive Growing of GANs for Improved Quality, Stability, and
    Variation* ([https://arxiv.org/pdf/1710.10196.pdf](https://arxiv.org/pdf/1710.10196.pdf))
    showed that growing the generator and discriminator by adding new layers and training
    on more detailed and higher-resolution images as the training progresses significantly
    improves the stability of the training process of the GAN and the diversity of
    the generated synthetic images.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 增加生成的合成样本多样性的另一种有趣的方法是在训练过程中逐渐引入更复杂的模式，在整个训练过程中增加生成器和判别器的层数，并在训练阶段对多样性较低的示例进行惩罚。这鼓励合成数据生成模型生成更多样化和变体化的数据。例如，在*《用于提高质量、稳定性和变化的渐进式增长
    GAN》*（[https://arxiv.org/pdf/1710.10196.pdf](https://arxiv.org/pdf/1710.10196.pdf)）的研究中，研究人员通过添加新层并在训练过程中使用更详细和更高分辨率的图像来增长生成器和判别器，显著提高了
    GAN 训练过程的稳定性和生成合成图像的多样性。
- en: Procedural content generation with game engines
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用游戏引擎进行程序性内容生成
- en: '**Procedural Content Generation** (**PCG**) is a widely used approach in video
    games to make the virtual world diverse and rich, resulting in a better player
    experience. The same concept can be utilized in game engines and simulators to
    create diverse 3D virtual worlds and thus generate diverse synthetic data. PCG
    can be utilized to generate textures, objects, maps, animations, and other scene
    elements. For a specific example, please refer to *ProcSy: Procedural Synthetic
    Dataset Generation Towards Influence Factor Studies Of Semantic Segmentation*
    *Networks* ([https://uwaterloo.ca/waterloo-intelligent-systems-engineering-lab/procsy](https://uwaterloo.ca/waterloo-intelligent-systems-engineering-lab/procsy)).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**程序性内容生成**（**PCG**）是视频游戏中广泛使用的一种方法，用于使虚拟世界多样化且丰富，从而提高玩家的体验。同样的概念可以用于游戏引擎和模拟器中，以创建多样化的
    3D 虚拟世界，从而生成多样化的合成数据。PCG 可以用于生成纹理、对象、地图、动画和其他场景元素。具体示例，请参阅*《ProcSy：程序化合成数据集生成，用于语义分割影响因子研究网络》*（[https://uwaterloo.ca/waterloo-intelligent-systems-engineering-lab/procsy](https://uwaterloo.ca/waterloo-intelligent-systems-engineering-lab/procsy)）。'
- en: So far, we have learned the main approaches usually utilized to improve the
    diversity of the generated synthetic data. Next, let’s learn the main issues and
    limitations of these approaches.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了通常用于提高生成合成数据多样性的主要方法。接下来，让我们了解这些方法的主要问题和局限性。
- en: Diversity issues in the synthetic data realm
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据领域的多样性问题
- en: 'As we have seen, diversity helps us to build robust, accurate, and general-purpose
    ML models. Additionally, we learned many approaches to improve synthetic data
    diversity in practice. In this section, we will examine three main issues we usually
    encounter when we try to generate diverse synthetic data:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，多样性有助于我们构建健壮、准确和通用的机器学习模型。此外，我们还学习了在实践中提高合成数据多样性的许多方法。在本节中，我们将探讨我们在尝试生成多样化合成数据时通常遇到的三种主要问题：
- en: Balancing diversity and realism
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平衡多样性与现实性
- en: Privacy and confidentiality concerns
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐私和保密问题
- en: Validation and evaluation challenges
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证和评估挑战
- en: Balancing diversity and realism
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平衡多样性与现实性
- en: There is usually a trade-off between diversity and realism. Generating diverse
    synthetic examples without considering the realism of these generated samples
    may introduce or increase the domain gap between synthetic and real domains. For
    more details, please refer to *Chapters 13* and *14*. For example, let’s suppose
    that we want to generate images with sports cars for a particular computer vision
    task or application. While it is crucial to generate diverse sports cars that
    cover most of the available real sports car samples in the real world, we do not
    want to generate sports cars that are unlikely to be observed in our problem context.
    Thus, our aim should always be to generate synthetic data that accurately represents
    the distribution in the real world. It should be diverse but also realistic to
    be useful for training and testing ML models in practice.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 通常在多样性和逼真度之间存在权衡。在不考虑这些生成的样本逼真度的前提下生成多样化的合成示例可能会引入或增加合成域和真实域之间的领域差距。更多细节，请参阅*第13章*和*第14章*。例如，假设我们想要为特定的计算机视觉任务或应用生成带有运动汽车的图像。虽然生成覆盖现实世界中大多数可用真实运动汽车样本的多样化运动汽车至关重要，但我们不希望生成在问题上下文中不太可能观察到的运动汽车。因此，我们的目标始终应该是生成能够准确反映现实世界分布的合成数据。它应该是多样化的，同时也应该是逼真的，以便在实际中用于训练和测试机器学习模型。
- en: Privacy and confidentiality concerns
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隐私和保密问题
- en: When generating synthetic data for applications that have restrictions on the
    real data because of privacy or confidentiality concerns, it becomes rather hard
    to generate diverse synthetic data. The reason behind this is the limited understanding
    of the attributes, patterns, and correlations of the real data, which cannot be
    learned by generative models given a small-scale training dataset. Thus, it becomes
    extremely hard for generative models to generate diverse synthetic data for such
    applications. Please refer to [*Chapter 3*](B18494_03.xhtml#_idTextAnchor049)
    for an in-depth discussion about privacy issues with large-scale real datasets.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当生成受隐私或保密问题限制的具有真实数据的合成数据时，生成多样化的合成数据变得相当困难。其背后的原因是对于真实数据属性、模式和关联的理解有限，这些关联无法通过给定小规模训练数据集的生成模型来学习。因此，对于这类应用，生成模型生成多样化的合成数据变得极其困难。请参阅[*第3章*](B18494_03.xhtml#_idTextAnchor049)以深入了解大规模真实数据集的隐私问题。
- en: Validation and evaluation challenges
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证和评估挑战
- en: One of the main issues in this area is assessing the diversity of the generated
    synthetic data, and thus the usability of this data in practice. Developing a
    robust, reliable, and universal diversity evaluation metric would be highly beneficial
    in practice. State-of-the-art metrics are usually problem dependent and experimental
    and lack the appropriate theoretical framework. For more information, please refer
    to *Reliable Fidelity and Diversity Metrics for Generative* *Models* ([https://arxiv.org/abs/2002.09797](https://arxiv.org/abs/2002.09797)).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 该领域的主要问题之一是评估生成的合成数据的多样性，以及因此在实际应用中该数据的可用性。开发一个稳健、可靠和通用的多样性评估指标在实践中将非常有用。最先进的指标通常是问题相关的，实验性的，并且缺乏适当的理论框架。更多信息，请参阅*生成模型的可靠保真度和多样性指标*
    ([https://arxiv.org/abs/2002.09797](https://arxiv.org/abs/2002.09797))。
- en: Summary
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have discussed the main reasons why the diversity of data
    is crucial for ML-based solutions. We also examined the key approaches to generating
    diverse synthetic data. Then, we highlighted the main issues and challenges. In
    the next chapter, we will focus on another relevant and interesting issue in synthetic
    data, which is photorealism.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了为什么数据多样性对于基于机器学习的解决方案至关重要。我们还考察了生成多样化合成数据的关键方法。然后，我们强调了主要问题和挑战。在下一章中，我们将关注合成数据中的另一个相关且有趣的问题，即逼真度。
