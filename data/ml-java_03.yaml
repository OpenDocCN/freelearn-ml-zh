- en: Basic Algorithms - Classification, Regression, and Clustering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本算法 - 分类、回归和聚类
- en: In the previous chapter, we reviewed the key Java libraries that are used for
    machine learning and what they bring to the table. In this chapter, we will finally
    get our hands dirty. We will take a closer look at the basic machine learning
    tasks, such as classification, regression, and clustering. Each of the topics
    will introduce basic algorithms for classification, regression, and clustering.
    The example datasets will be small, simple, and easy to understand.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们回顾了用于机器学习的关键Java库以及它们带来的好处。在本章中，我们将最终动手实践。我们将更深入地了解基本的机器学习任务，如分类、回归和聚类。每个主题将介绍分类、回归和聚类的算法。示例数据集将小、简单且易于理解。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Loading data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载数据
- en: Filtering attributes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤属性
- en: Building classification, regression, and clustering models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建分类、回归和聚类模型
- en: Evaluating models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估模型
- en: Before you start
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在开始之前
- en: Before you start, download the latest stable version of Weka (Weka 3.8 at the
    time of writing) from [http://www.cs.waikato.ac.nz/ml/weka/downloading.html](http://www.cs.waikato.ac.nz/ml/weka/downloading.html).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，从[http://www.cs.waikato.ac.nz/ml/weka/downloading.html](http://www.cs.waikato.ac.nz/ml/weka/downloading.html)下载Weka的最新稳定版本（写作时为Weka
    3.8）。
- en: 'There are multiple download options available. You''ll want to use Weka as
    a library in your source code, so make sure that you skip the self-extracting
    executables and download the ZIP archive, as shown in the following screenshot.
    Unzip the archive and locate `weka.jar` within the extracted archive:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个下载选项可用。您希望将Weka作为库添加到源代码中，因此请确保跳过自解压可执行文件，并下载以下截图所示的ZIP存档。解压存档，并在解压的存档中找到`weka.jar`：
- en: '![](img/7db1f2c9-1619-4251-9a3b-ef6a59eb9538.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7db1f2c9-1619-4251-9a3b-ef6a59eb9538.png)'
- en: 'We''ll use the Eclipse IDE to show examples; follow these steps:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Eclipse IDE来展示示例；请按照以下步骤操作：
- en: Start a new Java project.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始一个新的Java项目。
- en: Right-click on the project properties, select Java Build Path, click on the
    Libraries tab, and select Add External JARs.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键点击项目属性，选择Java Build Path，点击库标签，然后选择添加外部JAR文件。
- en: Navigate to extract the Weka archive and select the `weka.jar` file.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到解压Weka存档，并选择`weka.jar`文件。
- en: That's it; we are ready to implement the basic machine learning techniques!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样；我们已经准备好实现基本的机器学习技术了！
- en: Classification
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类
- en: 'We will start with the most commonly used machine learning technique: classification.
    As we reviewed in the first chapter, the main idea is to automatically build a
    mapping between the input variables and the outcome. In the following sections,
    we will look at how to load the data, select features, implement a basic classifier
    in Weka, and evaluate its performance.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从最常用的机器学习技术开始：分类。正如我们在第一章中回顾的那样，主要思想是自动在输入变量和结果之间建立映射。在接下来的几节中，我们将探讨如何加载数据、选择特征、在Weka中实现基本分类器以及评估其性能。
- en: Data
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: 'For this task, we will take a look at the `ZOO` database. The database contains
    101 data entries of animals described with 18 attributes, as shown in the following
    table:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个任务，我们将查看`ZOO`数据库。该数据库包含101个动物数据条目，每个动物用18个属性描述，如下表所示：
- en: '| animal | aquatic | fins |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| animal | aquatic | fins |'
- en: '| hair | predator | legs |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| hair | predator | legs |'
- en: '| feathers | toothed | tail |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| feathers | toothed | tail |'
- en: '| eggs | backbone | domestic |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| eggs | backbone | domestic |'
- en: '| milk | breathes | cat size |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| milk | breathes | cat size |'
- en: '| airborne | venomous | type |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| airborne | venomous | type |'
- en: 'An example entry in the dataset is a lion, with the following attributes:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的示例条目是一只狮子，具有以下属性：
- en: '`animal`: lion'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`animal`: 狮子'
- en: '`hair`: true'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hair`: true'
- en: '`feathers`: false'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feathers`: false'
- en: '`eggs`: false'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eggs`: false'
- en: '`milk`: true'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`milk`: true'
- en: '`airborne`: false'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`airborne`: false'
- en: '`aquatic`: false'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aquatic`: false'
- en: '`predator`: true'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predator`: true'
- en: '`toothed`: true'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`toothed`: true'
- en: '`backbone`: true'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backbone`: true'
- en: '`breathes`: true'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`breathes`: true'
- en: '`venomous`: false'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`venomous`: false'
- en: '`fins`: false'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fins`: false'
- en: '`legs`: 4'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`legs`: 4'
- en: '`tail`: true'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tail`: true'
- en: '`domestic`: false'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`domestic`: false'
- en: '`catsize`: true'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`catsize`: true'
- en: '`type`: mammal'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type`: 哺乳动物'
- en: Our task will be to build a model to predict the outcome variable, `animal`,
    given all of the other attributes as input.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的任务将是构建一个模型来预测结果变量`animal`，给定所有其他属性作为输入。
- en: Loading data
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据
- en: Before we start the analysis, we will load the data in Weka's **Attribute-Relation
    File Format** (**ARFF**) and print the total number of loaded instances. Each
    data sample is held within a `DataSource` object, while the complete dataset,
    accompanied by meta-information, is handled by the `Instances` object.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始分析之前，我们将加载数据到Weka的**属性-关系文件格式**（**ARFF**）并打印加载的实例总数。每个数据样本都包含在一个`DataSource`对象中，而完整的数据集，包括元信息，由`Instances`对象处理。
- en: 'To load the input data, we will use the `DataSource` object that accepts a
    variety of file formats and converts them into `Instances`:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加载数据，我们将使用接受多种文件格式并将其转换为`Instances`的`DataSource`对象：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will provide the number of loaded instances as output, as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这将提供以下输出，显示加载的实例数量：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We can also print the complete dataset by calling the `data.toString()` method.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以通过调用`data.toString()`方法来打印完整的数据集。
- en: Our task is to learn a model that is able to predict the `animal` attribute
    in the future examples for which we know the other attributes, but do not know
    the `animal` label. Hence, we will remove the `animal` attribute from the training
    set. We will accomplish this by filtering out the animal attribute, using the
    `Remove()` filter.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的任务是学习一个模型，能够预测未来示例中的`animal`属性，对于这些示例我们知道其他属性，但不知道`animal`标签。因此，我们将从训练集中删除`animal`属性。我们将通过使用`Remove()`过滤器过滤掉动物属性来完成此操作。
- en: 'First, we set a string table of parameters, specifying that the first attribute
    must be removed. The remaining attributes are used as our dataset for training
    a classifier:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们设置一个参数字符串表，指定必须删除第一个属性。剩余的属性将用作我们的数据集以训练分类器：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, we call the `Filter.useFilter(Instances, Filter)` static method to
    apply the filter on the selected dataset:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们调用`Filter.useFilter(Instances, Filter)`静态方法来对所选数据集应用过滤器：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Feature selection
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征选择
- en: As introduced in [Chapter 1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml), *Applied
    Machine Learning Quick Start*, one of the preprocessing steps is focused on feature
    selection, also known as **attribute selection**. The goal is to select a subset
    of relevant attributes that will be used in a learned model. Why is feature selection
    important? A smaller set of attributes simplifies the models and makes them easier
    for users to interpret. This usually requires shorter training and reduces overfitting.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如在[第1章](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml)《应用机器学习快速入门》中所述，预处理步骤之一是关注特征选择，也称为**属性选择**。目标是选择一个相关属性的子集，该子集将用于学习模型。为什么特征选择很重要？属性集越小，模型越简单，用户也越容易理解。这通常需要更短的训练时间并减少过拟合。
- en: Attribute selection can take the class value into account or it cannot. In the
    first case, an attribute selection algorithm evaluates the different subsets of
    features and calculates a score that indicates the quality of selected attributes.
    We can use different searching algorithms, such as exhaustive search and best-first
    search, and different quality scores, such as information gain, the Gini index,
    and so on.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 属性选择可以考虑到类别值，也可以不考虑。在前一种情况下，属性选择算法评估不同的特征子集，并计算一个表示所选属性质量的分数。我们可以使用不同的搜索算法，如穷举搜索和最佳优先搜索，以及不同的质量分数，如信息增益、基尼指数等。
- en: 'Weka supports this process with an `AttributeSelection` object, which requires
    two additional parameters: an evaluator, which computes how informative an attribute
    is, and a ranker, which sorts the attributes according to the score assigned by
    the evaluator.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Weka通过一个`AttributeSelection`对象支持此过程，该对象需要两个额外的参数：一个计算属性信息量的评估器，以及一个根据评估器分配的分数对属性进行排序的排序器。
- en: 'We will use the following steps to perform selection:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下步骤进行选择：
- en: 'In this example, we will use information gain as an evaluator, and we will
    rank the features by their information gain score:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本例中，我们将使用信息增益作为评估者，并根据它们的信息增益分数对特征进行排序：
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We will initialize an `AttributeSelection` object and set the evaluator, ranker,
    and data:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将初始化一个`AttributeSelection`对象并设置评估器、排序器和数据：
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will print an order list of attribute `indices`, as follows:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将打印属性`indices`的顺序列表，如下所示：
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This process will provide the following result as output:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此过程将提供以下结果作为输出：
- en: '[PRE7]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The most informative attributes are `12` (fins), `3` (eggs), `7` (aquatic),
    `2` (hair), and so on. Based on this list, we can remove additional, non-informative
    features in order to help the learning algorithms achieve more accurate and faster
    learning models.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最具信息量的属性是`12`（鳍）、`3`（蛋）、`7`（水生）、`2`（毛发）等等。基于这个列表，我们可以移除额外的、非信息量的特征，以便帮助学习算法实现更准确和更快的模型。
- en: What would make the final decision about the number of attributes to keep? There's
    no rule of thumb related to an exact number; the number of attributes depends
    on the data and the problem. The purpose of attribute selection is to choose attributes
    that serve your model better, so it is best to focus on whether the attributes
    are improving the model.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 什么会决定保留属性的数量？没有关于确切数字的经验法则；属性的数量取决于数据和问题。属性选择的目的在于选择对模型更有益的属性，因此最好关注属性是否在改进模型。
- en: Learning algorithms
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习算法
- en: We have loaded our data and selected the best features, and we are ready to
    learn some classification models. Let's begin with basic decision trees.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经加载了数据并选择了最佳特征，我们现在准备学习一些分类模型。让我们从基本的决策树开始。
- en: In Weka, a decision tree is implemented within the `J48` class, which is a reimplementation
    of Quinlan's famous C4.5 decision tree learner (Quinlan, 1993).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在Weka中，决策树是通过`J48`类实现的，它是Quinlan著名的C4.5决策树学习器（Quinlan，1993）的重新实现。
- en: 'We will make a decision tree by using the following steps:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下步骤构建决策树：
- en: 'We initialize a new `J48` decision tree learner. We can pass additional parameters
    with a string table—for instance, the tree pruning that controls the model complexity
    (refer to [Chapter 1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml), *Applied Machine
    Learning Quick Start*). In our case, we will build an un-pruned tree; hence, we
    will pass a single `-U` parameter, as follows:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们初始化一个新的`J48`决策树学习器。我们可以通过字符串表传递额外的参数——例如，控制模型复杂性的树剪枝（参考[第1章](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml)，*应用机器学习快速入门*）。在我们的情况下，我们将构建一个未剪枝的树；因此，我们将传递单个`-U`参数，如下所示：
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will call the `buildClassifier(Instances)` method to initialize the learning
    process:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将调用`buildClassifier(Instances)`方法来初始化学习过程：
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The built model is now stored in a `tree` object. We can provide the entire
    `J48` unpruned tree by calling the `toString()` method:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建好的模型现在存储在`tree`对象中。我们可以通过调用`toString()`方法提供整个`J48`未剪枝树：
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output will be as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The tree in the output has `17` nodes in total and `9` of them are terminal
    (`Leaves`).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的树总共有`17`个节点，其中`9`个是终端节点（叶子）。
- en: 'Another way to present the tree is to leverage the built-in `TreeVisualizer`
    tree viewer, as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种表示树的方法是利用内置的`TreeVisualizer`树查看器，如下所示：
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding code results in the following output frame:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将产生以下输出框架：
- en: '![](img/10ddbded-4f22-4f20-a2d5-eefd3158464e.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/10ddbded-4f22-4f20-a2d5-eefd3158464e.png)'
- en: The decision process starts at the top node, also known as the root node. The
    node label specifies the attribute value that will be checked. In our example,
    first, we check the value of the `feathers` attribute. If the feather is present,
    we follow the right-hand branch, which leads us to the leaf labeled `bird`, indicating
    that there are `20` examples supporting this outcome. If the feather is not present,
    we follow the left-hand branch, which leads us to the `milk` attribute. We check
    the value of the attribute again, and we follow the branch that matches the attribute
    value. We repeat the process until we reach a leaf node.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 决策过程从顶部节点开始，也称为根节点。节点标签指定将要检查的属性值。在我们的例子中，首先，我们检查`feathers`属性的值。如果羽毛存在，我们跟随右侧分支，这会引导我们到标记为`bird`的叶子，表示有`20`个示例支持这个结果。如果羽毛不存在，我们跟随左侧分支，这会引导我们到`milk`属性。我们再次检查属性的值，并跟随与属性值匹配的分支。我们重复这个过程，直到达到叶子节点。
- en: 'We can build other classifiers by following the same steps: initialize a classifier,
    pass the parameters controlling the model complexity, and call the `buildClassifier(Instances)`
    method.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过遵循相同的步骤构建其他分类器：初始化分类器，传递控制模型复杂性的参数，并调用`buildClassifier(Instances)`方法。
- en: In the next section, you will learn how to use a trained model to assign a class
    label to a new example whose label is unknown.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习如何使用训练好的模型为标签未知的新示例分配类标签。
- en: Classifying new data
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对新数据进行分类
- en: 'Suppose that we record attributes for an animal whose label we do not know;
    we can predict its label from the learned classification model. We will use the
    following animal for this process:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们记录了一个我们不知道标签的动物的属性；我们可以从学习到的分类模型中预测其标签。我们将使用以下动物来完成这个过程：
- en: '![](img/7f4f4365-22d9-44d1-9cfc-942e707c67cd.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7f4f4365-22d9-44d1-9cfc-942e707c67cd.png)'
- en: 'First, we construct a feature vector describing the new specimen, as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们构建一个描述新样本的特征向量，如下所示：
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, we call the `classify(Instance)` method on the model, in order to obtain
    the class value. The method returns the label index, as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们在模型上调用`classify(Instance)`方法，以获取类值。该方法返回标签索引，如下所示：
- en: '[PRE14]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This will provide the `mammal` class label as output.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出`mammal`类标签。
- en: Evaluation and prediction error metrics
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估和预测误差指标
- en: We built a model, but we do not know if it can be trusted. To estimate its performance,
    we can apply a cross-validation technique that was explained in [Chapter 1](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml),
    *Applied Machine Learning Quick Start*.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了一个模型，但我们不知道它是否值得信赖。为了估计其性能，我们可以应用在[第1章](11a9489b-c4dd-4544-ace8-f84533d8fd7c.xhtml)，《应用机器学习快速入门》中解释的交叉验证技术。
- en: 'Weka offers an `Evaluation` class for implementing cross-validation. We pass
    the model, data, number of folds, and an initial random seed, as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Weka提供了一个`Evaluation`类来实现交叉验证。我们传递模型、数据、折数和初始随机种子，如下所示：
- en: '[PRE15]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The evaluation results are stored in the `Evaluation` object.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 评估结果存储在`Evaluation`对象中。
- en: 'A mix of the most common metrics can be invoked by calling the `toString()`
    method. Note that the output does not differentiate between regression and classification,
    so make sure to pay attention to the metrics that make sense, as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用`toString()`方法，可以调用最常用的一组指标。请注意，输出不会区分回归和分类，因此请确保注意有意义的指标，如下所示：
- en: '[PRE16]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: In the classification, we are interested in the number of correctly/incorrectly
    classified instances.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类中，我们关注的是正确/错误分类的实例数量。
- en: The confusion matrix
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'Furthermore, we can inspect where a particular misclassification has been made
    by examining the confusion matrix. The confusion matrix shows how a specific class
    value was predicted:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以通过检查混淆矩阵来检查特定错误分类发生在哪里。混淆矩阵显示了特定类值是如何被预测的：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The resulting confusion matrix is as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最终得到的混淆矩阵如下：
- en: '[PRE18]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The column names in the first row correspond to the labels assigned by the classification
    node. Each additional row then corresponds to an actual true class value. For
    instance, the second row corresponds to instances with the `mammal` true class
    label. In the column line, we read that all mammals were correctly classified
    as mammals. In the fourth row, `reptiles`, we notice that three were correctly
    classified as `reptiles`, while one was classified as `fish` and one as `insect`.
    The confusion matrix gives us insight into the kinds of errors that our classification
    model can make.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行的列名对应于分类节点分配的标签。然后，每一行额外的对应于一个实际的真实类值。例如，第二行对应于具有`mammal`真实类标签的实例。在列行中，我们读到所有哺乳动物都被正确分类为哺乳动物。在第四行，`reptiles`，我们注意到有三个被正确分类为`reptiles`，而一个被分类为`fish`，另一个被分类为`insect`。混淆矩阵让我们了解我们的分类模型可能犯的错误类型。
- en: Choosing a classification algorithm
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择分类算法
- en: Naive Bayes is one of the most simple, efficient, and effective inductive algorithms
    in machine learning. When features are independent, which is rarely true in the
    real world, it is theoretically optimal and, even with dependent features, its
    performance is amazingly competitive (Zhang, 2004). The main disadvantage is that
    it cannot learn how features interact with each other; for example, despite the
    fact that you like your tea with lemon or milk, you hate a tea that has both of
    them at the same time.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯是机器学习中最为简单、高效和有效的归纳算法之一。当特征相互独立时，这在现实世界中很少见，但从理论上讲是最佳的，即使有依赖特征，其性能也令人惊讶地具有竞争力（张，2004）。主要缺点是它无法学习特征如何相互作用；例如，尽管你喜欢加柠檬或牛奶的茶，但你讨厌同时加这两种东西的茶。
- en: The main advantage of the decision tree is that it is a model that is easy to
    interpret and explain, as we studied in our example. It can handle both nominal
    and numeric features, and you don't have to worry about whether the data is linearly
    separable.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树的主要优点是它是一个易于解释和说明的模型，正如我们在示例中所研究的。它可以处理名义和数值特征，你不必担心数据是否线性可分。
- en: 'Some other examples of classification algorithms are as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些其他分类算法的示例：
- en: '`weka.classifiers.rules.ZeroR`: This predicts the majority class and is considered
    a baseline; that is, if your classifier''s performance is worse than the average
    value predictor, it is not worth considering it.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.rules.ZeroR`: 这预测多数类，并被认为是一个基线；也就是说，如果你的分类器的性能比平均值预测器差，那么它不值得考虑。'
- en: '`weka.classifiers.trees.RandomTree`: This constructs a tree that considers
    *K* randomly chosen attributes at each node.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.trees.RandomTree`: 这构建了一个在每个节点考虑 *K* 个随机选择的属性的树。'
- en: '`weka.classifiers.trees.RandomForest`: This constructs a set (forest) of random
    trees and uses majority voting to classify a new instance.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.trees.RandomForest`: 这构建了一组（森林）随机树，并使用多数投票对新实例进行分类。'
- en: '`weka.classifiers.lazy.IBk`: This is the k-nearest neighbors classifier that
    is able to select an appropriate value of neighbors, based on cross-validation.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.lazy.IBk`: 这是一个能够根据交叉验证选择适当邻居值的 k-最近邻分类器。'
- en: '`weka.classifiers.functions.MultilayerPerceptron`: This is a classifier based
    on neural networks that uses backpropagation to classify instances. The network
    can be built by hand, or created by an algorithm, or both.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.functions.MultilayerPerceptron`: 这是一个基于神经网络的分类器，它使用反向传播对实例进行分类。网络可以手动构建，或由算法创建，或两者兼而有之。'
- en: '`weka.classifiers.bayes.NaiveBayes`: This is a Naive Bayes classifier that
    uses estimator classes, where numeric estimator precision values are chosen based
    on the analysis of the training data.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.bayes.NaiveBayes`: 这是一个使用估计类（其中数值估计精度值基于训练数据的分析选择）的朴素贝叶斯分类器。'
- en: '`weka.classifiers.meta.AdaBoostM1`: This is the class for boosting a nominal
    class classifier by using the `AdaBoost M1` method. Only nominal class problems
    can be tackled. This often dramatically improves the performance, but sometimes,
    it overfits.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.meta.AdaBoostM1`: 这是一个通过使用 `AdaBoost M1` 方法来提升名义类分类器的类。只能解决名义类问题。这通常可以显著提高性能，但有时会过拟合。'
- en: '`weka.classifiers.meta.Bagging`: This is the class for bagging a classifier
    to reduce the variance. This can perform classification and regression, depending
    on the base learner.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weka.classifiers.meta.Bagging`: 这是一个用于通过袋装法减少方差分类器的类。这可以执行分类和回归，具体取决于基学习器。'
- en: Classification using Encog
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Encog 进行分类
- en: In the previous section, you saw how to use a Weka library for classification.
    In this section, we will quickly look at how the same can be achieved by using
    the Encog library. Encog requires us to build a model to do the classification.
    Download the Encog library from [https://github.com/encog/encog-java-core/releases](https://github.com/encog/encog-java-core/releases).
    Once downloaded, add the `.jar` file in the Eclipse project, as explained at the
    beginning of the chapter.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你看到了如何使用 Weka 库进行分类。在本节中，我们将快速查看如何通过使用 Encog 库实现相同的功能。Encog 要求我们构建一个模型来进行分类。从
    [https://github.com/encog/encog-java-core/releases](https://github.com/encog/encog-java-core/releases)
    下载 Encog 库。下载后，将 `.jar` 文件添加到 Eclipse 项目中，如本章开头所述。
- en: For this example, we will use the `iris` dataset, which is available in `.csv`
    format; it can be downloaded from [https://archive.ics.uci.edu/ml/datasets/Iris](https://archive.ics.uci.edu/ml/datasets/Iris).
    From the download path, copy the `iris.data.csv` file into your data directory.
    This file contains the data of 150 different flowers. It contains four different
    measurements about the flowers, and the last column is a label.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我们将使用 `.csv` 格式的 `iris` 数据集；它可以从 [https://archive.ics.uci.edu/ml/datasets/Iris](https://archive.ics.uci.edu/ml/datasets/Iris)
    下载。从下载路径中，将 `iris.data.csv` 文件复制到你的数据目录。此文件包含150种不同花朵的数据。它包含关于花朵的四个不同测量值，最后一列是标签。
- en: 'We will now perform the classification, using the following steps:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将执行分类，按照以下步骤进行：
- en: 'We will use the `VersatileMLDataSet` method to load the file and define all
    four columns. The next step is to call the `analyze` method that will read the
    entire file and find the statistical parameters, such as the mean, the standard
    deviation, and many more:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用 `VersatileMLDataSet` 方法来加载文件并定义所有四个列。下一步是调用 `analyze` 方法，它将读取整个文件并找到统计参数，如均值、标准差等：
- en: '[PRE19]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The next step is to define the output column. Then, it''s time to normalize
    the data; but before that, we need to decide on the model type according to which
    the data will be normalized, as follows:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是定义输出列。然后，是时候对数据进行归一化；但在那之前，我们需要根据以下模型类型来决定数据将如何归一化：
- en: '[PRE20]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The next step is to fit the model on a training set, leaving a test set aside.
    We will hold 30% of the data, as specified by the first argument, `0.3`; the next
    argument specifies that we want to shuffle the data in randomly. `1001` says that
    there is a seed value of 1001, so we use a `holdBackValidation` model:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是在训练集上拟合模型，留出测试集。我们将保留30%的数据，如第一个参数`0.3`所指定；下一个参数指定我们想要随机打乱数据。`1001`表示有一个1001的种子值，因此我们使用`holdBackValidation`模型：
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, it''s time to train the model and classify the data, according to the
    measurements and labels. The cross-validation breaks the training dataset into
    five different combinations:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，是时候根据测量值和标签来训练模型并分类数据了。交叉验证将训练数据集分成五个不同的组合：
- en: '[PRE22]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The next step is to display the results of each fold and the errors:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是显示每个折叠的结果和错误：
- en: '[PRE23]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, we will start to use the model to predict the values, using the following
    code block:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将开始使用以下代码块来使用模型预测值：
- en: '[PRE24]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This will yield an output similar to the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生类似于以下输出的结果：
- en: '![](img/7c6cad63-e1ef-499b-8b39-74d333a78d85.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7c6cad63-e1ef-499b-8b39-74d333a78d85.png)'
- en: Encog supports many other options in `MLMethodFactory`, such as SVM, PNN, and
    so on.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Encog在`MLMethodFactory`中支持许多其他选项，如SVM、PNN等。
- en: Classification using massive online analysis
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用大规模在线分析进行分类
- en: '**Massive Online Analysis** (**MOA**), as discussed in [Chapter 2](6fd557d7-2807-4a6d-8f93-d7c4ca094b7e.xhtml), *Java
    Libraries and Platforms for Machine Learning,* is another library that can be
    used to achieve classification. It is mainly designed to work with the stream.
    If it is working with the stream, a lot of data will be there; so, how do we evaluate
    the model? In the traditional batch learning mode, we usually divide the data
    into training and test sets and cross-validation is preferred if the data is limited.
    In stream processing, where the data seems to be unlimited, cross-validation proves
    to be expensive. Two approaches that we can use are as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**大规模在线分析**（**MOA**），如第2章[Java Libraries and Platforms for Machine Learning](6fd557d7-2807-4a6d-8f93-d7c4ca094b7e.xhtml)中所述，是另一个可以用于分类的库。它主要设计用于与流一起工作。如果它与流一起工作，将会有大量的数据；那么，我们如何评估模型呢？在传统的批量学习模式下，我们通常将数据分为训练集和测试集，如果数据有限，则首选交叉验证。在流处理中，数据似乎无限，交叉验证证明是昂贵的。我们可以使用以下两种方法：'
- en: '**Holdout**: This is useful when the data is already divided into two parts,
    which are predefined. It gives the estimation of the current classifier, if it
    is similar to the current data. This similarity is hard to guarantee between the
    holdout set and the current data.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**保留**：当数据已经分为两个预定义的部分时，这很有用。它给出了当前分类器的估计，如果它与当前数据相似。这种相似性在保留集和当前数据之间很难保证。'
- en: '**Interleaved test-then-train, or prequential**: In this method, the model
    is tested on the example before it is used for training. So, the model is always
    tested for the data that it has never seen. In this, no holdout scheme is needed.
    It uses the available data. Over time, this approach will improve the accuracy
    of classification.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交错测试-然后训练，或预quential**：在这个方法中，模型在用于训练之前先被测试。因此，模型总是对其从未见过的数据进行测试。在这种情况下，不需要保留方案。它使用可用的数据。随着时间的推移，这种方法将提高分类的准确性。'
- en: 'MOA provides various ways to generate the stream of data. First, download the
    MOA library from [https://moa.cms.waikato.ac.nz/downloads/](https://moa.cms.waikato.ac.nz/downloads/).
    Add the downloaded `.jar` files to Eclipse, like we did for Weka at the beginning
    of this chapter. We will be using the GUI tool provided by MOA to see how to use
    MOA for streams. To launch the GUI, make sure `moa.jar` and `sizeofag.jar` are
    in the current path; then, run the following command in Command Prompt:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: MOA提供了多种生成数据流的方法。首先，从[https://moa.cms.waikato.ac.nz/downloads/](https://moa.cms.waikato.ac.nz/downloads/)下载MOA库。将下载的`.jar`文件添加到Eclipse中，就像我们在本章开头为Weka所做的那样。我们将使用MOA提供的GUI工具来了解如何使用MOA进行流处理。要启动GUI，请确保`moa.jar`和`sizeofag.jar`在当前路径中；然后在命令提示符中运行以下命令：
- en: '[PRE25]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'It will display the following output:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 它将显示以下输出：
- en: '![](img/3ba39b4e-10ac-424d-b2a1-187bdee96629.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3ba39b4e-10ac-424d-b2a1-187bdee96629.png)'
- en: 'We can see that it has options for classification, regression, clustering,
    outliers, and more. Clicking on the Configure button will display the screen used
    to make your classifier. It provides various learners and streams to work with,
    as shown in the following screenshot:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到它有分类、回归、聚类、异常值等选项。点击“配置”按钮将显示用于创建分类器的屏幕。它提供了各种学习者和流来工作，如下面的截图所示：
- en: '![](img/16dcc58d-a17e-42bf-a59e-fa4a28af752c.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/16dcc58d-a17e-42bf-a59e-fa4a28af752c.png)'
- en: 'The following is an example of running `RandomTreeGenerator` with `NaiveBayes`
    and `HoeffdingTree`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个使用`RandomTreeGenerator`、`NaiveBayes`和`HoeffdingTree`运行的示例：
- en: '![](img/f0662400-373d-4b18-9d2d-ac392275f3e6.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f0662400-373d-4b18-9d2d-ac392275f3e6.png)'
- en: Evaluation
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估
- en: 'Evaluation is the next important task, after the model has been developed.
    It lets you decide whether the model is performing on the given dataset well and
    ensures that it will be able to handle data that it has never seen. The evaluation
    framework mostly uses the following features:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 评估是模型开发后的下一个重要任务。它让您决定模型在给定数据集上的表现是否良好，并确保它能够处理它从未见过的数据。评估框架主要使用以下功能：
- en: '**Error estimation**: This uses holdout or interleaved test-and-train methods
    to estimate the errors. K-fold cross-validation is also used.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误估计**：这使用保留或交错测试和训练方法来估计错误。K折交叉验证也被使用。'
- en: '**Performance measures**: The Kappa statistics are used, which are more sensitive
    towards streaming classifiers.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能指标**：使用Kappa统计量，它对流分类器更敏感。'
- en: '**Statistical validation**: When comparing evaluating classifiers, we must
    look at the differences in random and non-random experiments. The McNemar''s test
    is the most popular test in streaming, used to access the statistical significance
    of differences in two classifiers. If we are working with one classifier, the
    confidence intervals of parameter estimates indicate the reliability.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统计验证**：在比较评估分类器时，我们必须考虑随机和非随机实验之间的差异。McNemar测试是流中最受欢迎的测试，用于评估两个分类器之间差异的统计显著性。如果我们只使用一个分类器，参数估计的置信区间表明其可靠性。'
- en: '**The cost measure of the process**: As we are dealing with streaming data,
    which may require access to third-party or cloud-based solutions to get and process
    the data, the cost per hour of usage and memory is considered for evaluation purposes.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过程的成本度量**：由于我们处理的是流数据，可能需要访问第三方或基于云的解决方案来获取和处理数据，因此考虑了每小时使用成本和内存成本用于评估目的。'
- en: Baseline classifiers
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基线分类器
- en: Batch learning has led to the development of many classifiers in different paradigms,
    such as divide and conquer, lazy learners, kernel methods, graphics models, and
    so on. Now, if we move to a stream for the same, we need to understand how to
    make them incremental and fast for the large datasets in the streams. We have
    to think in terms of the complexity of the model versus the speed of the model
    update, and this is the main trade-off that needs to be taken care of.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 批量学习导致了在不同范式下许多分类器的开发，例如分而治之、懒惰学习器、核方法、图形模型等。现在，如果我们转向相同的流，我们需要了解如何使它们对流中的大数据集进行增量化和快速处理。我们必须从模型复杂性与模型更新速度的角度来思考，这是需要关注的主要权衡。
- en: The **majority class algorithm** is one of the simplest classifiers, and it
    is used as a baseline. It is also used as a default classifier for decision tree
    leaves. Another is the **no**-**change classifier**, which predicts the labels
    for new instances. The Naive Bayes algorithm is known for its low cost in terms
    of computational power and simplicity. It's an incremental algorithm and is best
    suited for streams.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**多数类算法**是最简单的分类器之一，它被用作基线。它也被用作决策树叶子的默认分类器。另一个是**无变化分类器**，它预测新实例的标签。朴素贝叶斯算法以其计算能力和简单性成本低而闻名。它是一个增量算法，非常适合流。'
- en: Decision tree
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树
- en: The decision tree is a very popular classifier technique, making it easy to
    interpret and visualize the models. It is based on trees. It divides or splits
    the nodes on the basis of the attribute value and the leaves of the tree usually
    fall to the majority class classifier. In streaming data, the Hoeffding tree is
    a very fast algorithm for decision trees; it waits for new instances, instead
    of reusing instances. It builds a tree for large data. The **Concept-adapting
    Very Fast Decision Tree** (**CVFDT**) deals with the concept of drift, which maintains
    a model consistency with the instances in a sliding window. The other trees are
    the **Ultra Fast Forest of Trees** (**UFFT**), the Hoeffding adaptive tree, the
    exhaustive binary tree, and so on.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是一种非常流行的分类技术，使得模型易于解释和可视化。它基于树结构。它根据属性值来划分或分割节点，而树的叶子通常落在多数类分类器上。在流数据中，Hoeffding树是决策树的一个非常快速的算法；它等待新实例的到来，而不是重用实例。它为大量数据构建树。**概念自适应快速决策树**（**CVFDT**）处理漂移的概念，它通过滑动窗口保持模型与实例的一致性。其他树包括**超快速树森林**（**UFFT**）、Hoeffding自适应树、穷举二叉树等等。
- en: Lazy learning
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 惰性学习
- en: In the streaming context, **k-nearest neighbor** (**KNN**) is the most convenient
    batch method. A sliding window is used to determine the KNN for a new instance
    that is not yet classified. It normally uses the 1,000 most recent instances for
    the sliding window. As the sliding window slides, it handles the concept drift,
    too.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在流处理上下文中，**k最近邻**（**KNN**）是最方便的批量方法。使用滑动窗口来确定尚未分类的新实例的KNN。它通常使用最近1,000个实例作为滑动窗口。当滑动窗口滑动时，它也处理概念漂移。
- en: Active learning
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主动学习
- en: We all know that classifiers work well with labeled data, but that is not always
    the case with stream data. For example, the data from a stream may come unlabeled.
    Labeling data is costly, because it requires human intervention to label the unlabeled
    data. We understand that the streams generate large amounts of data. Active learning
    algorithms only do the labeling for selective data. The data to be labeled is
    decided on from historical data suited for pool-based settings. Regular retraining
    is required to decide whether a label is required for incoming instances. A simple
    strategy for labeling data is to use a random strategy. It is also called a baseline
    strategy, and it asks for a label for each incoming instance with probability
    of a budget for labelling. Another strategy is to ask for a label for the instance
    for which the current classifier is least confident. This may work fine, but soon,
    the classifier will exhaust its budget or reach its threshold.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都知道分类器在标记数据上表现良好，但流数据并不总是如此。例如，流数据可能未标记。标记数据成本高昂，因为它需要人工干预来标记未标记的数据。我们理解流数据生成大量数据。主动学习算法只为选择性数据执行标记。要标记的数据是从适合池设置的历
    史数据中决定的。需要定期重新训练以决定是否需要为传入的实例标记标签。标记数据的一个简单策略是使用随机策略。这也被称为基线策略，它要求为每个传入的实例请求一个标签，概率为标记预算。另一种策略是为当前分类器最不自信的实例请求一个标签。这可能效果不错，但很快，分类器就会耗尽其预算或达到其阈值。
- en: Regression
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归
- en: We will explore basic regression algorithms through an analysis of an energy
    efficiency dataset (Tsanas and Xifara, 2012). We will investigate the heating
    and cooling load requirements of the buildings based on their construction characteristics,
    such as surface, wall, and roof area; height; glazing area; and compactness. The
    researchers have used a simulator to design 12 different house configurations,
    while varying 18 building characteristics. In total, 768 different buildings were
    simulated.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过分析一个能源效率数据集（Tsanas和Xifara，2012）来探讨基本的回归算法。我们将根据建筑物的构造特征，如表面、墙体和屋顶面积；高度；玻璃面积；和紧凑性，研究建筑物的供暖和冷却负荷需求。研究人员使用模拟器设计了12种不同的房屋配置，同时改变18个建筑特征。总共模拟了768个不同的建筑物。
- en: Our first goal is to systematically analyze the impact that each building characteristic
    has on the target variable, that is, the heating or cooling load. The second goal
    is to compare the performance of a classical linear regression model against other
    methods, such as SVM regression, random forests, and neural networks. For this
    task, we will use the Weka library.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的首要目标是系统地分析每个建筑特征对目标变量（即供暖或冷却负荷）的影响。第二个目标是比较经典线性回归模型与其他方法的性能，例如SVM回归、随机森林和神经网络。为此任务，我们将使用Weka库。
- en: Loading the data
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据
- en: Download the energy efficiency dataset from [https://archive.ics.uci.edu/ml/datasets/Energy+efficiency](https://archive.ics.uci.edu/ml/datasets/Energy+efficiency).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 从[https://archive.ics.uci.edu/ml/datasets/Energy+efficiency](https://archive.ics.uci.edu/ml/datasets/Energy+efficiency)下载能源效率数据集。
- en: 'The dataset is in Excel''s XLSX format, which cannot be read by Weka. We can
    convert it into a **comma-separated value** (**CSV**) format by clicking on File
    | Save As and picking `.csv` in the saving dialog, as shown in the following screenshot.
    Confirm to save only the active sheet (since all of the others are empty), and
    confirm to continue, to lose some formatting features. Now, the file is ready
    to be loaded by Weka:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集以Excel的XLSX格式存储，无法被Weka读取。我们可以通过点击文件 | 另存为，在保存对话框中选择`.csv`格式将其转换为**逗号分隔值**（**CSV**），如下所示截图。确认只保存活动工作表（因为其他所有工作表都是空的），并确认继续，以丢失一些格式化功能。现在，文件已准备好由Weka加载：
- en: '![](img/c14075de-336e-4f70-a82a-bc3405293095.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c14075de-336e-4f70-a82a-bc3405293095.png)'
- en: 'Open the file in a text editor and inspect whether the file was correctly transformed.
    There might be some minor issues that could cause problems. For instance, in my
    export, each line ended with a double semicolon, as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本编辑器中打开文件，检查文件是否正确转换。可能会有一些可能导致问题的细微问题。例如，在我的导出中，每一行都以双分号结尾，如下所示：
- en: '[PRE26]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To remove the doubled semicolon, you can use the Find and Replace function:
    find `;;` and replace it with `;`.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除重复的分号，可以使用查找和替换功能：查找`;;`并将其替换为`;`。
- en: 'The second problem was that my file had a long list of empty lines at the end
    of the document, which can be deleted, as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个问题是我的文件在文档末尾有一个长长的空行列表，可以删除，如下所示：
- en: '[PRE27]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now, we are ready to load the data. Let''s open a new file and write a simple
    data import function by using Weka''s converter for reading files in a CSV format,
    as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好加载数据。让我们打开一个新文件，并使用Weka的转换器编写一个简单的数据导入函数，用于读取CSV格式的文件，如下所示：
- en: '[PRE28]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The data is loaded! Let's move on.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 数据已加载！让我们继续。
- en: Analyzing attributes
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析属性
- en: 'Before we analyze the attributes, let''s try to understand what we are dealing
    with. In total, there are eight attributes describing building characteristics,
    and there are also two target variables, the heating and cooling load, as shown
    in the following table:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析属性之前，让我们先尝试理解我们正在处理的内容。总共有八个属性描述建筑特征，还有两个目标变量，即供暖和冷却负荷，如下表所示：
- en: '| **Attribute** | **Attribute name** |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| **属性** | **属性名称** |'
- en: '| `X1` | Relative compactness |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| `X1` | 相对紧凑度 |'
- en: '| `X2` | Surface area |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| `X2` | 表面积 |'
- en: '| `X3` | Wall area |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| `X3` | 墙面积 |'
- en: '| `X4` | Roof area |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| `X4` | 屋顶面积 |'
- en: '| `X5` | Overall height |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| `X5` | 总高度 |'
- en: '| `X6` | Orientation |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| `X6` | 方向 |'
- en: '| `X7` | Glazing area |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| `X7` | 玻璃面积 |'
- en: '| `X8` | Glazing area distribution |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| `X8` | 玻璃面积分布 |'
- en: '| `Y1` | Heating load |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| `Y1` | 供暖负荷 |'
- en: '| `Y2` | Cooling load |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| `Y2` | 冷却负荷 |'
- en: Building and evaluating the regression model
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立和评估回归模型
- en: 'We will start by learning a model for the heating load by setting the class
    attribute at the feature position:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过设置类属性在特征位置来学习供暖负荷的模型：
- en: '[PRE29]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The second target variable, the cooling load, can now be removed:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个目标变量，冷却负荷，现在可以删除：
- en: '[PRE30]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Linear regression
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归
- en: 'We will start with a basic linear regression model, implemented with the `LinearRegression`
    class. Similar to the classification example, we will initialize a new model instance,
    pass the parameters and data, and invoke the `buildClassifier(Instances)` method,
    as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个基本的线性回归模型开始，使用`LinearRegression`类实现。类似于分类示例，我们将初始化一个新的模型实例，传递参数和数据，并调用`buildClassifier(Instances)`方法，如下所示：
- en: '[PRE31]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The learned model, which is stored in the object, can be provided by calling
    the `toString()` method, as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 存储在对象中的学习模型可以通过调用`toString()`方法提供，如下所示：
- en: '[PRE32]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The linear regression model constructs a function that linearly combines the
    input variables to estimate the heating load. The number in front of the feature
    explains the feature''s impact on the target variable: the sign corresponds to
    the positive/negative impact, while the magnitude corresponds to its significance.
    For instance, the relative compactness of the feature `X1` is negatively correlated
    with heating load, while the glazing area is positively correlated. These two
    features also significantly impact the final heating load estimate. The model''s
    performance can similarly be evaluated with the cross-validation technique.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型构建了一个函数，该函数线性组合输入变量以估计加热负荷。特征前的数字解释了特征对目标变量的影响：符号对应于正/负影响，而幅度对应于其重要性。例如，特征
    `X1` 的相对紧凑性与加热负荷呈负相关，而玻璃面积呈正相关。这两个特征也对最终的加热负荷估计有显著影响。模型的性能可以通过交叉验证技术进行评估。
- en: 'The ten-fold cross-validation is as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 十折交叉验证如下：
- en: '[PRE33]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We can provide the common evaluation metrics, including the correlation, the
    mean absolute error, the relative absolute error, and so on, as output, as follows:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以提供常见的评估指标，包括相关系数、平均绝对误差、相对绝对误差等，作为输出，如下所示：
- en: '[PRE34]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Linear regression using Encog
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Encog 进行线性回归
- en: 'Now, we will quickly look at how Encog can be used to make a regression model.
    We will be using the dataset that we used in a previous section, *Loading the
    data*. The following steps show how to make the model:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将快速查看如何使用 Encog 创建回归模型。我们将使用之前章节中使用的数据集，即“加载数据”。以下步骤展示了如何创建模型：
- en: 'To load the data, we will use the `VersatileMLDataSet` function, as follows:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了加载数据，我们将使用 `VersatileMLDataSet` 函数，如下所示：
- en: '[PRE35]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'As we have two pieces of output, `Y1` and `Y2`, they can be added by using
    the `defineMultipleOutputsOthersInput` function, as follows:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们有两个输出，`Y1` 和 `Y2`，它们可以通过使用 `defineMultipleOutputsOthersInput` 函数添加，如下所示：
- en: '[PRE36]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The next step is to develop a simple regression model by using the `FEEDFORWARD` instance:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是使用 `FEEDFORWARD` 实例开发一个简单的回归模型：
- en: '[PRE37]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, our regression model is ready. The last few lines of the output are given
    in the following screenshot:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的回归模型已经准备好了。输出中的最后几行如下截图所示：
- en: '![](img/7a260d2b-211b-40d0-884b-21b04ec6ac34.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7a260d2b-211b-40d0-884b-21b04ec6ac34.png)'
- en: Regression using MOA
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MOA 进行回归
- en: Using MOA for regression requires us to use the GUI. You can download the dataset
    from [http://www.cs.waikato.ac.nz/~bernhard/halifax17/census.arff.gz](http://www.cs.waikato.ac.nz/~bernhard/halifax17/census.arff.gz).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 MOA 进行回归需要我们使用图形用户界面。您可以从 [http://www.cs.waikato.ac.nz/~bernhard/halifax17/census.arff.gz](http://www.cs.waikato.ac.nz/~bernhard/halifax17/census.arff.gz)
    下载数据集。
- en: 'The following steps show how to perform regression:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤展示了如何执行回归：
- en: 'Launch the MOA GUI by using the following command:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令启动 MOA 图形用户界面：
- en: '[PRE38]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Select the Regression tab and click on Configure, as shown in the following
    screenshot:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“回归”选项卡并点击“配置”，如下截图所示：
- en: '![](img/afc20bde-fc01-44f6-864f-07b531de5c92.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](img/afc20bde-fc01-44f6-864f-07b531de5c92.png)'
- en: 'We will use the downloaded `.arff` file for regression. When we click on Configure
    in the preceding step, it will display the Configure task window, as shown in
    the following screenshot:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用下载的 `.arff` 文件进行回归。当我们点击前一步中的“配置”时，将显示“配置任务”窗口，如下截图所示：
- en: '![](img/62d0e7ee-fbcd-41bc-aa15-5632716435ed.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![](img/62d0e7ee-fbcd-41bc-aa15-5632716435ed.png)'
- en: 'In the stream option, click on Edit and select the ArffFileStream; select the
    `.arff` file that we downloaded, as shown in the following screenshot:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“流”选项中点击“编辑”并选择 ArffFileStream；选择我们下载的 `.arff` 文件，如下截图所示：
- en: '![](img/c679a3fd-fadd-410d-9635-c3bf2fd7c871.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c679a3fd-fadd-410d-9635-c3bf2fd7c871.png)'
- en: 'In classIndex, specify `-1`, which sets the first attribute as the target.
    Click on OK in all pop-up windows and click on Run. It will take some time, as
    the census file has a large amount of data to process, as shown in the following
    screenshot:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 classIndex 中指定 `-1`，这将第一个属性设置为目标。在所有弹出窗口中点击“确定”，然后点击“运行”。由于人口普查文件包含大量数据需要处理，这将花费一些时间，如下截图所示：
- en: '![](img/82fc5070-7875-4ad8-a5e7-3860ed59c498.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](img/82fc5070-7875-4ad8-a5e7-3860ed59c498.png)'
- en: Regression trees
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归树
- en: 'Another approach is to construct a set of regression models, each on its own
    part of the data. The following diagram shows the main difference between a regression
    model and a regression tree. A regression model constructs a single model that
    best fits all of the data. A regression tree, on the other hand, constructs a
    set of regression models, each modeling a part of the data, as shown on the right-hand
    side. Compared to the regression model, the regression tree can better fit the
    data, but the function is a piece-wise linear plot, with jumps between modeled
    regions, as seen in the following diagram:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是构建一组回归模型，每个模型对应数据的一部分。以下图显示了回归模型和回归树之间的主要区别。回归模型构建一个最适合所有数据的单一模型。另一方面，回归树构建一组回归模型，每个模型模拟数据的一部分，如图右侧所示。与回归模型相比，回归树可以更好地拟合数据，但函数是分段线性图，在建模区域之间有跳跃，如下面的图所示：
- en: '![](img/05ac04c7-3b94-4b84-ad85-107afa117db8.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/05ac04c7-3b94-4b84-ad85-107afa117db8.png)'
- en: 'A regression tree in Weka is implemented within the `M5` class. The model construction
    follows the same paradigm: initialize the model, pass the parameters and data,
    and invoke the `buildClassifier(Instances)` method, as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在Weka中，回归树是在`M5`类中实现的。模型构建遵循相同的范例：初始化模型，传递参数和数据，然后调用`buildClassifier(Instances)`方法，如下所示：
- en: '[PRE39]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The induced model is a tree with equations in the leaf nodes, as follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 诱导模型是一个叶子节点中有方程的树，如下所示：
- en: '[PRE40]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The tree has `13` leaves, each corresponding to a linear equation. The preceding
    output is visualized in the following diagram:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 该树有`13`个叶子节点，每个对应一个线性方程。前面的输出在以下图中可视化：
- en: '![](img/afb3b685-9ce9-4bcc-b3eb-9ba448748986.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/afb3b685-9ce9-4bcc-b3eb-9ba448748986.png)'
- en: The tree can be read similarly to a classification tree. The most important
    features are at the top of the tree. The terminal node, the leaf, contains a linear
    regression model explaining the data that reaches this part of the tree.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 该树可以像分类树一样阅读。最重要的特征位于树的顶部。终端节点，即叶子节点，包含一个线性回归模型，解释了到达该树部分的数据。
- en: 'An evaluation will provide the following results as output:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 评估将提供以下结果作为输出：
- en: '[PRE41]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Tips to avoid common regression problems
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免常见回归问题的技巧
- en: First, we have to use prior studies and domain knowledge to figure out which
    features to include in regression. Check literature, reports, and previous studies
    on what kinds of features work and some reasonable variables for modeling your
    problem. Suppose that you have a large set of features with random data; it is
    highly likely that several features will be correlated to the target variable
    (even though the data is random).
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须使用先前的研究和领域知识来确定哪些特征应包含在回归中。检查文献、报告和以前的研究，了解哪些类型的特征有效，以及一些合理的变量来建模你的问题。假设你有一组带有随机数据的特征；高度可能存在几个特征与目标变量相关（即使数据是随机的）。
- en: We have to keep the model simple, in order to avoid overfitting. The Occam's
    razor principle states that you should select a model that best explains your
    data, with the least assumptions. In practice, the model can be as simple as having
    two to four predictor features.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须保持模型简单，以避免过拟合。奥卡姆剃刀原则指出，你应该选择一个最能解释你的数据且假设最少的模型。在实践中，模型可以简单到只有两个到四个预测特征。
- en: Clustering
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: Compared to a supervised classifier, the goal of clustering is to identify intrinsic
    groups in a set of unlabeled data. It can be applied to identifying representative
    examples of homogeneous groups, finding useful and suitable groupings, or finding
    unusual examples, such as outliers.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 与监督分类器相比，聚类的目标是识别未标记数据集中的内在群体。它可以应用于识别同质群体的代表性示例，找到有用和合适的分组，或找到不寻常的示例，例如异常值。
- en: We'll demonstrate how to implement clustering by analyzing a bank dataset. The
    dataset consists of 11 attributes, describing 600 instances, with age, sex, region,
    income, marital status, children, car ownership status, saving activity, current
    activity, mortgage status, and PEP. In our analysis, we will try to identify the
    common groups of clients by applying the **expectation maximization** (**EM**)
    clustering.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过分析一个银行数据集来演示如何实现聚类。该数据集包含11个属性，描述了600个实例，包括年龄、性别、地区、收入、婚姻状况、子女、汽车拥有状态、储蓄活动、当前活动、抵押状态和PEP。在我们的分析中，我们将通过应用**期望最大化（EM**）聚类来尝试识别客户的常见群体。
- en: 'EM works as follows: given a set of clusters, EM first assigns each instance
    with a probability distribution of belonging to a particular cluster. For example,
    if we start with three clusters—namely, A, B, and C—an instance might get the
    probability distribution of 0.70, 0.10, and 0.20, belonging to the A, B, and C
    clusters, respectively. In the second step, EM re-estimates the parameter vector
    of the probability distribution of each class. The algorithm iterates these two
    steps until the parameters converge or the maximum number of iterations is reached.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: EM算法的工作原理如下：给定一组聚类，EM首先为每个实例分配一个属于特定聚类的概率分布。例如，如果我们从三个聚类——即A、B和C——开始，一个实例可能会得到0.70、0.10和0.20的概率分布，分别属于A、B和C聚类。在第二步中，EM重新估计每个类别的概率分布的参数向量。算法重复这两个步骤，直到参数收敛或达到最大迭代次数。
- en: The number of clusters to be used in EM can be set either manually or automatically
    by cross-validation. Another approach to determining the number of clusters in
    a dataset includes the elbow method. This method looks at the percentage of variance
    that is explained with a specific number of clusters. The method suggests increasing
    the number of clusters until the additional cluster does not add much information,
    that is, it explains little additional variance.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在EM中使用的聚类数量可以手动设置或通过交叉验证自动设置。确定数据集中聚类数量的另一种方法包括肘部方法。此方法查看特定数量聚类解释的方差百分比。该方法建议增加聚类数量，直到额外的聚类不会添加太多信息，即它解释的额外方差很少。
- en: Clustering algorithms
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类算法
- en: 'The process of building a cluster model is quite similar to the process of
    building a classification model, that is, loading the data and building a model.
    Clustering algorithms are implemented in the `weka.clusterers` package, as follows:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 构建聚类模型的过程与构建分类模型的过程非常相似，即加载数据并构建模型。聚类算法在`weka.clusterers`包中实现，如下所示：
- en: '[PRE42]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The model identified the following six clusters:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 模型识别了以下六个聚类：
- en: '[PRE43]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The table can be read as follows: the first line indicates six clusters, while
    the first column shows the attributes and their ranges. For example, the attribute
    `age` is split into three ranges: `0-34`, `35-51`, and `52-max`. The columns on
    the left indicate how many instances fall into the specific range in each cluster;
    for example, clients in the `0-34` years age group are mostly in cluster 2 (122
    instances).'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 表格可以按以下方式读取：第一行表示六个聚类，而第一列显示了属性及其范围。例如，属性`age`被分为三个范围：`0-34`、`35-51`和`52-max`。左侧的列表示每个聚类中特定范围中实例的数量；例如，`0-34`年龄组的客户主要在聚类2中（122个实例）。
- en: Evaluation
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估
- en: 'A clustering algorithm''s quality can be estimated by using the `logLikelihood`
    measure, which measures how consistent the identified clusters are. The dataset
    is split into multiple folds, and clustering is run with each fold. The motivation
    is that, if the clustering algorithm assigns a high probability to similar data
    that wasn''t used to fit parameters, then it has probably done a good job of capturing
    the data structure. Weka offers the `CluterEvaluation` class to estimate it, as
    follows:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用`logLikelihood`度量来估计聚类算法的质量，该度量衡量识别出的聚类的一致性。数据集被分成多个折叠，并且每个折叠都进行聚类。动机是，如果聚类算法将高概率分配给未用于拟合参数的相似数据，那么它可能已经很好地捕捉到了数据结构。Weka提供了`CluterEvaluation`类来估计它，如下所示：
- en: '[PRE44]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'It provides the following output:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 它提供了以下输出：
- en: '[PRE45]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Clustering using Encog
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Encog进行聚类
- en: 'Encog supports k-means clustering. Let''s consider a very simple example, with
    the data shown in the following code block:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: Encog支持k-means聚类。让我们考虑一个非常简单的例子，数据如下所示：
- en: '[PRE46]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'To make `BasicMLDataSet` from this data, a simple `for` loop is used, which
    will add data to the dataset:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 要从这些数据创建`BasicMLDataSet`，使用一个简单的`for`循环，它将数据添加到数据集中：
- en: '[PRE47]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Using the `KMeansClustering` function, let''s clusters the dataset into two
    clusters, as follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`KMeansClustering`函数，将数据集聚为两个聚类，如下所示：
- en: '[PRE48]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This will generate the following output:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '[PRE49]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Clustering using ELKI
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ELKI进行聚类
- en: 'ELKI supports many clustering algorithms. A few are listed as follows:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ELKI支持许多聚类算法。以下列出了一些：
- en: '**Affinity propagation clustering algorithm**: This is a cluster analysis that
    uses affinity propagation.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**亲和传播聚类算法**：这是一种使用亲和传播的聚类分析。'
- en: '**DBSCAN**: This is density based clustering especially for the applications
    with noise; it finds the sets in the database on the basis of density.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DBSCAN**: 这是一种基于密度的聚类算法，特别适用于有噪声的应用；它根据密度在数据库中找到集合。'
- en: '**EM**: This algorithm creates clusters based on the expectation maximization
    algorithm.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**EM**: 该算法基于期望最大化算法创建聚类。'
- en: '**AGNES**: **Hierarchical agglomerative clustering (HAC),** or **agglomerative
    nesting (AGNES),** is a classic hierarchical clustering algorithm.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AGNES**: **层次聚类（HAC），** 或 **聚集嵌套（AGNES），** 是一种经典的层次聚类算法。'
- en: '**SLINK**: This is the single link algorithm.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SLINK**: 这是一种单链接算法。'
- en: '**CLINK**: This is used for complete linkage.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CLINK**: 这用于完全链接。'
- en: '**HDBSCAN**: This is an extracting cluster hierarchy.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HDBSCAN**: 这是一种提取聚类层次的方法。'
- en: Also, KMeansSort, KMeansCompare, KMedianLloyd, KMediodsEM, KMeansBisecting,
    and so on, are some examples from the family of KMean.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，KMeansSort、KMeansCompare、KMedianLloyd、KMediodsEM、KMeansBisecting 等也是 KMean
    家族的一些例子。
- en: A detailed list of clustering algorithms, with all of the algorithms supported
    by ELKI, can be found at [https://elki-project.github.io/algorithms/](https://elki-project.github.io/algorithms/).
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在 [https://elki-project.github.io/algorithms/](https://elki-project.github.io/algorithms/)
    找到详细列表的聚类算法，包括 ELKI 支持的所有算法。
- en: We need to get the required `.jar` file from [https://elki-project.github.io/releases/](https://elki-project.github.io/releases/).
    Download the executable archive, and download the mouse dataset from [https://elki-project.github.io/datasets/](https://elki-project.github.io/datasets/).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要从 [https://elki-project.github.io/releases/](https://elki-project.github.io/releases/)
    获取所需的 `.jar` 文件。下载可执行存档，并从 [https://elki-project.github.io/datasets/](https://elki-project.github.io/datasets/)
    下载鼠标数据集。
- en: 'From the Terminal or Command Prompt, run the following command:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 从终端或命令提示符运行以下命令：
- en: '[PRE50]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The preceding command generates the following output:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令生成以下输出：
- en: '![](img/ad7aa6a0-9316-4d68-ac6c-3fd4ad9f7bba.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ad7aa6a0-9316-4d68-ac6c-3fd4ad9f7bba.png)'
- en: 'We can see two options, in an orange color: `dbc.in` and `algorithm`. We need
    to specify the value. In `dbc.in`, click on the dots (`...`) to select the `mouse.csv`
    file that we downloaded. In `algorithm`, select `k-Mean Clustering algorithm`
    by clicking on the plus sign (`+`), find `kmean.k`, and fill it with the value
    `3`. Click on the Run Task button, which is now enabled. It will generate the
    following output:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到两个选项，以橙色显示：`dbc.in` 和 `algorithm`。我们需要指定值。在 `dbc.in` 中，点击点（`...`）选择我们下载的
    `mouse.csv` 文件。在 `algorithm` 中，通过点击加号（`+`）选择 `k-Mean Clustering algorithm`，找到
    `kmean.k` 并将其值填为 `3`。点击现在已启用的“运行任务”按钮，它将生成以下输出：
- en: '![](img/ff63ada1-1a48-4ca8-bbfd-e32a2e6e34f6.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ff63ada1-1a48-4ca8-bbfd-e32a2e6e34f6.png)'
- en: Summary
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, you learned how to implement basic machine learning tasks
    with Weka: classification, regression, and clustering. We briefly discussed the
    attribute selection process and trained models and evaluated their performance.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何使用 Weka 实现基本机器学习任务：分类、回归和聚类。我们简要讨论了属性选择过程，并训练了模型以评估其性能。
- en: The next chapter will focus on how to apply these techniques to solving real-life
    problems, such as customer retention.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将重点介绍如何将这些技术应用于解决现实生活中的问题，例如客户保留。
