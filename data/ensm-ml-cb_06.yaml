- en: When in Doubt, Use Random Forests
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当有疑问时，使用随机森林
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下食谱：
- en: Introduction to random forests
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林简介
- en: Implementing a random forest for predicting credit card defaults using scikit-learn
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 实现随机森林以预测信用卡违约
- en: Implementing a random forest for predicting credit card defaults using H2O
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 H2O 实现预测信用卡违约的随机森林
- en: Introduction to random forests
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林简介
- en: A random forest is a supervised machine learning algorithm based on ensemble
    learning. It is used for both regression and classification problems. The general
    idea behind random forests is to build multiple decision trees and aggregate them
    to get an accurate result. A decision tree is a deterministic algorithm, which
    means if the same data is given to it, the same tree will be produced each time.
    They have a tendency to overfit, because they build the best tree possible with
    the given data, but may fail to generalize when unseen data is provided. All the
    decision trees that make up a random forest are different because we build each
    tree on a different random subset of our data. A random forest tends to be more
    accurate than a single decision tree because it minimizes overfitting.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是一种基于集成学习的监督机器学习算法，用于回归和分类问题。随机森林背后的基本思想是构建多个决策树并将它们聚合以获得准确的结果。决策树是一种确定性算法，这意味着如果给定的相同数据，每次都会产生相同的树。它们有过度拟合的倾向，因为它们使用给定数据构建最佳树，但在提供未见数据时可能无法泛化。构成随机森林的所有决策树都是不同的，因为我们使用不同的随机子集构建每棵树。随机森林通常比单个决策树更准确，因为它最小化了过度拟合。
- en: 'The following diagram demonstrates bootstrap sampling being done from the source
    sample. Models are built on each of the samples and then the predictions are combined
    to arrive at a final result:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了从源样本中进行的引导采样。在每个样本上构建模型，然后将预测组合起来以得出最终结果：
- en: '![](img/b7a368ae-ce16-47db-96c7-5ab98ab0b289.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b7a368ae-ce16-47db-96c7-5ab98ab0b289.png)'
- en: 'Each tree in a random forest is built using the following steps where A represents
    the entire forest, a represents a single tree, for *a = 1* to *A*:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林中的每棵树都是按照以下步骤构建的，其中 A 代表整个森林，a 代表单个树，对于 *a = 1* 到 *A*：
- en: Create a bootstrap sample with replacement, *D* training from *x*, *y* label
    these *X[a]*[, ]*Y[a]*
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用替换方法创建一个从 *x*，*y* 标签的 *X[a]*[, ]*Y[a]* 训练的引导样本，*D* 训练
- en: Train the tree *f[a]* on *X[a]*, *Y[a]*
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 *X[a]*，*Y[a]* 上训练树 *f[a]*
- en: Average the predictions or take the majority vote to arrive at a final prediction
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 取平均值或进行多数投票以得出最终预测
- en: 'In a regression problem, predictions for the test instances are made by taking
    the mean of the predictions made by all trees. This can be represented as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归问题中，通过取所有树做出的预测的平均值来对测试实例进行预测。这可以表示如下：
- en: '![](img/b058aa6d-f242-48e0-ab2c-e20bca7feca3.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b058aa6d-f242-48e0-ab2c-e20bca7feca3.png)'
- en: Here, *N* is the total number of trees in the random forest. *a=1* represents
    the first tree in a forest, while the last tree in the forest is *A*. ![](img/b6820836-5f23-4996-b72c-86e17bcfbed3.png)(![](img/d7f322ac-15d3-4190-bea7-6b3f7250eba4.png))
    represents the prediction from a single tree.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*N* 是随机森林中树的总数。*a=1* 代表森林中的第一棵树，而森林中的最后一棵树是 *A*。(![图片](img/b6820836-5f23-4996-b72c-86e17bcfbed3.png)(![图片](img/d7f322ac-15d3-4190-bea7-6b3f7250eba4.png)))
    代表单个树的预测。
- en: If we have a classification problem, majority voting or the most common answer
    is used.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个分类问题，则使用多数投票或最常见的答案。
- en: Implementing a random forest for predicting credit card defaults using scikit-learn
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 实现预测信用卡违约的随机森林
- en: 'The scikit-learn library implements random forests by providing two estimators:
    `RandomForestClassifier`and `RandomForestRegressor`. They take various parameters,
    some of which are explained as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 库通过提供两个估计器实现随机森林：`RandomForestClassifier` 和 `RandomForestRegressor`。它们接受各种参数，其中一些如下所述：
- en: '` n_estimators`:This parameter is the number of trees the algorithm builds
    before taking a maximum vote or the average prediction. In general, the higher
    the number of trees the better the performance and the accuracy of the predictions,
    but it also costs more in terms of computation.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '` n_estimators`：此参数是算法在采取最大投票或平均预测之前构建的树的数量。一般来说，树的数量越多，性能和预测的准确性越好，但这也意味着计算成本更高。'
- en: '`max_features`: This parameter is the maximum number of features that the random
    forest is allowed to try in an individual tree.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_features`: 此参数是随机森林允许在单个树中尝试的最大特征数。'
- en: '`min_sample_leaf`:This parameter determines the minimum number of leaves that
    are required to split an internal node.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_sample_leaf`: 此参数决定了分割内部节点所需的最小叶子数。'
- en: '`n_jobs`: This hyperparameter tells the engine how many jobs to run in parallel
    for both fitting the model and predicting new instances. If it has a value of
    `None` or `1`, it runs only one job. A value of `-1` means it will use all the
    processors.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_jobs`: 此超参数告诉引擎在拟合模型和预测新实例时并行运行多少个作业。如果它的值为 `None` 或 `1`，则只运行一个作业。`-1` 的值意味着它将使用所有处理器。'
- en: '`random_state`:This parameter will always produce the same results when it
    has a definite value of `random_state` and if it has been given the same hyperparameters
    and the same training data.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`random_state`: 此参数将在 `random_state` 有确定的值时始终产生相同的结果，并且如果它已经给出了相同的超参数和相同的训练数据。'
- en: '`oob_score`: This parameter is also known as **out-of-the-bag ****sampling**,
    and is a random forest cross-validation method. In this sampling method, about
    one-third of the data is not used to train the model and can be used to evaluate
    its performance. These samples are called the **out-of-the-bag** **samples**.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`oob_score`: 此参数也称为 **袋外抽样**，是一种随机森林交叉验证方法。在此抽样方法中，大约三分之一的 数据未用于训练模型，可用于评估其性能。这些样本称为
    **袋外样本**。'
- en: Getting ready
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In this example, we use a dataset from the UCI ML repository on credit card
    defaults. This dataset contains the following information:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用了来自 UCI ML 存储库的信用卡违约数据集。此数据集包含以下信息：
- en: Default payments
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 违约支付
- en: Demographic factors
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口统计因素
- en: Credit data
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用数据
- en: History of payments
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 付款历史
- en: Bill statements of credit card clients
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用卡客户的账单
- en: 'The data and the data descriptions are provided in the GitHub folder:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数据和数据描述提供在 GitHub 文件夹中：
- en: 'We will start by loading the required libraries and reading our dataset:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先加载所需的库并读取我们的数据集：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We set our working folder as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将工作文件夹设置为以下内容：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s now read our data. We will prefix the DataFrame name with `df_` so that
    we can understand it easily:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在读取我们的数据。我们将 `DataFrame` 名称前缀为 `df_`，这样我们就可以轻松理解它：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We check the shape of the dataset:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查数据集的形状：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We check the datatypes:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查数据类型：
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We drop the `ID` column, as this is not required:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们删除了 `ID` 列，因为这不是必需的：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can explore our data in various ways. Let''s take a look at a couple of
    different methods:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用各种方式探索我们的数据。让我们看看几种不同的方法：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note that we have used a semicolon in the last line in the preceding code block.
    The semicolon helps to hide the verbose information produced by Matplotlib. `xlabelsize`
    and `ylabelsize` are used to adjust the font size in the x-axis and the y-axis.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在前面的代码块中，我们使用了分号。分号有助于隐藏 Matplotlib 生成的冗长信息。`xlabelsize` 和 `ylabelsize` 用于调整
    x 轴和 y 轴的字体大小。
- en: 'The following plot shows the distribution of the numeric variables:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了数值变量的分布：
- en: '![](img/9ea0dcfd-9bd1-47c3-9207-8d476ce78ee0.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9ea0dcfd-9bd1-47c3-9207-8d476ce78ee0.png)'
- en: 'We will now explore the payment defaults by age group. We bucket the `age`
    variable and store the binned values in a new variable, `age_group`, in `df_creditcarddata`:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将按年龄组探索支付违约情况。我们将 `age` 变量分桶，并将分桶的值存储在 `df_creditcarddata` 中的新变量 `age_group`
    中：
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We then use our new `age_group` variable to plot the number of defaults per
    age group:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用新的 `age_group` 变量来绘制每个年龄组的违约数量：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following screenshot shows the amount of defaults per age:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了每个年龄的违约金额：
- en: '![](img/a01f25a0-5db7-469d-b4b7-e1638ac2ed03.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a01f25a0-5db7-469d-b4b7-e1638ac2ed03.png)'
- en: 'We can drop the `age_group` variable from `df_creditcarddata` since we do not
    need it anymore:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不再需要它，我们可以从 `df_creditcarddata` 中删除 `age_group` 变量：
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We will now look at the payment defaults according to the credit limits of
    the account holders:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将根据账户持有者的信用额度查看支付违约情况：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding code gives us the following plot:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码给出了以下图表：
- en: '![](img/8ca04a04-c2dc-4bac-bbf1-55319d9dee18.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/8ca04a04-c2dc-4bac-bbf1-55319d9dee18.png)'
- en: We can also assign labels to some of our variables to make the interpretations
    better. We assign labels for the `Gender`, `Marriage`, and `Education` variables.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以为一些变量分配标签以使解释更好。我们为 `Gender`、`Marriage` 和 `Education` 变量分配标签。
- en: 'We also change the datatype of the `pay` variables to the string:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将`pay`变量的数据类型更改为字符串：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: There are more explorations available in the code bundle provided with this
    book. We now move on to training our random forest model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书提供的代码包中还有更多的探索。我们现在继续训练我们的随机森林模型。
- en: How to do it...
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'We will now look at how to use a random forest to train our model:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将探讨如何使用随机森林来训练我们的模型：
- en: 'We start by splitting our target and feature variables:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先将目标和特征变量分开：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We separate the numerical and non-numerical variables in our feature set:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在我们的特征集中将数值变量和非数值变量分开：
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We dummy code the categorical variables:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对分类变量进行虚拟编码：
- en: '[PRE14]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We concatenate the dummy code variables to our DataFrame:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将虚拟编码变量连接到我们的DataFrame：
- en: '[PRE15]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We split our dataset into training and testing subsets:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将数据集分为训练集和测试集：
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We scale the features with `StandardScaler()`:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`StandardScaler()`对特征进行缩放：
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We might notice that the column names have been changed to numbers. We assign
    the columns names and index values back to the scaled DataFrame:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可能会注意到列名已被更改为数字。我们将列名和索引值赋回缩放后的DataFrame：
- en: '[PRE18]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We import `RandomForestClassifier()` from `sklearn.ensemble`. We will then
    build our random forest classifier model:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从`sklearn.ensemble`导入`RandomForestClassifier()`。然后我们将构建我们的随机森林分类器模型：
- en: '[PRE19]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After that, we calculate the accuracy of our training model:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们计算训练模型的准确率：
- en: '[PRE20]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We get the **f****alse positive rate** (**FPR**) and **t****rue positive rate** (**TPR**)
    by passing `y_test` and `y_pred_proba` to `roc_curve()`. We also get the `auc `value
    using `roc_auc_score()`. Using the FPR, TPR, and the AUC value, we plot the ROC
    curve with the AUC value annotated on the plot:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将`y_test`和`y_pred_proba`传递给`roc_curve()`，我们得到**假阳性率**（**FPR**）和**真阳性率**（**TPR**）。我们还可以使用`roc_auc_score()`得到`auc`值。使用FPR、TPR和AUC值，我们在图表上绘制ROC曲线，并在图表上标注AUC值：
- en: '[PRE21]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following graph shows the ROC curve with the AUC value annotated on it:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了带有标注AUC值的ROC曲线：
- en: '![](img/43c5f4c5-d916-4f76-a3b4-8bf301a6926f.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/43c5f4c5-d916-4f76-a3b4-8bf301a6926f.png)'
- en: 'We can also evaluate other scores, as shown here:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以评估其他分数，如下所示：
- en: '[PRE22]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The preceding code produces the following evaluation scores:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码产生了以下评估分数：
- en: '![](img/dac2941b-1804-4d74-977b-f9878a69d72a.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dac2941b-1804-4d74-977b-f9878a69d72a.png)'
- en: 'We can also evaluate a few statistics based on the class of the target variable,
    which in this case is `0` or `1`:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以根据目标变量的类别评估一些统计信息，在这种情况下是`0`或`1`：
- en: '[PRE23]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '`classification_report` from `sklearn.metrics` gives us the following scores
    based on each class of the target variable:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.metrics`中的`classification_report`根据目标变量的每个类别给出以下分数：'
- en: '![](img/eb489a75-2234-4f49-86ce-191e94fd501c.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb489a75-2234-4f49-86ce-191e94fd501c.png)'
- en: 'We can plot the top 10 variables by feature importance to see which variables
    are important for the model:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过特征重要性绘制前10个变量，以查看哪些变量对模型很重要：
- en: '[PRE24]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following screenshot shows the top 10 variables with their relative importance:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了前10个变量及其相对重要性：
- en: '![](img/152d22d8-51d0-4861-9e34-66ac936652a2.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/152d22d8-51d0-4861-9e34-66ac936652a2.png)'
- en: We can change the hyperparameters to see how the model can perform better. We
    can also perform a grid search over combinations of hyperparameter values to fine-tune
    our model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以更改超参数以查看模型如何表现更好。我们还可以对超参数值的组合进行网格搜索以微调我们的模型。
- en: How it works...
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In *Step 1*, we split our target and feature variables. In *Step 2*, in our
    feature set, we separated the numeric and non-numeric variables. In *Step 3* and
    *Step 4*, we converted the non-numeric variables to dummy coded variables and
    added them back to the DataFrame. In *Step 5*, we split our dataset into training
    and testing subsets, and in *Step 6*, we imported `StandardScaler()` from `sklearn.preprocessing`
    and applied the same scale to our features.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤1*中，我们将目标和特征变量分开。在*步骤2*中，在我们的特征集中，我们将数值变量和非数值变量分开。在*步骤3*和*步骤4*中，我们将非数值变量转换为虚拟编码变量，并将它们添加回DataFrame。在*步骤5*中，我们将数据集分为训练集和测试集，在*步骤6*中，我们从`sklearn.preprocessing`导入`StandardScaler()`并将相同的缩放应用于我们的特征。
- en: After executing the commands in *Step 6*, we noticed that the column names had
    changed to sequential numbers. For this reason, in *Step 7*, we assigned the column
    names and the index values back to the scaled DataFrame. In *Step 8*, we imported `RandomForestClassifier()`
    from `sklearn.ensemble` and built our first random forest classifier model. After
    that, in *Step 9* and *Step 10*, we used our model to calculate the accuracy of
    our training model and plotted the ROC curve respectively. We also annotated the
    ROC Curve with the AUC value.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 执行**步骤6**中的命令后，我们注意到列名已更改为顺序号。因此，在**步骤7**中，我们将列名和索引值重新分配给缩放后的DataFrame。在**步骤8**中，我们从`sklearn.ensemble`中导入`RandomForestClassifier()`并构建了我们第一个随机森林分类器模型。之后，在**步骤9**和**步骤10**中，我们使用我们的模型计算训练模型的准确度并绘制ROC曲线。我们还用AUC值标注了ROC曲线。
- en: In *Step 11*, we evaluated other scores, including the kappa value, the precision,
    the recall, and the accuracy.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤11**中，我们评估了其他分数，包括kappa值、精确度、召回率和准确度。
- en: In *Step 12*, we also evaluated these scores based on each class of the target
    variable, which in this case is `0` or `1`, using `classification_report` from
    `sklearn.metrics`. There, `classification_report()` provides us with metrics such
    as precision, recall, and f1-score by each class, as well as the average of each
    of the metrics.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤12**中，我们也根据目标变量的每个类别（在这种情况下是`0`或`1`）使用`sklearn.metrics`中的`classification_report`对这些分数进行了评估。在那里，`classification_report()`为我们提供了每个类别的精确度、召回率和f1分数等指标，以及每个指标的均值。
- en: '`classification_report()` reports averages, including averaging the total true
    positives, false negatives and false positives, averaging the unweighted mean
    per label, and averaging the support-weighted mean per label. It also reports
    sample averages for multi-label classification.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`classification_report()`报告平均值，包括平均总真实阳性、假阴性、假阳性，平均每个标签的无权均值，以及平均每个标签的支持加权均值。它还报告多标签分类的样本平均值。'
- en: Finally, in *Step 13*, we looked at the relative variable importance of the
    top 10 features. This can help in feature selection to build the models with the
    right features.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在**步骤13**中，我们研究了前10个特征的相对变量重要性。这有助于在特征选择中构建具有正确特征的模型。
- en: There are various feature selection methods available, such as averaged variable,
    importance, Boruta, recursive feature selection, and variable selection using
    RF.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种特征选择方法可用，例如平均变量重要性、Boruta、递归特征选择以及使用RF进行变量选择。
- en: There's more...
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Isolation forest is another algorithm that is built on the basis of decision
    trees, and it's used for anomaly and outlier detection. This algorithm is based
    on the assumption that the outlier data points are rare.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 隔离森林是另一种基于决策树的算法，用于异常值和异常检测。该算法基于异常数据点稀少的假设。
- en: The algorithm works a bit differently to the random forest. It creates a bunch
    of decision trees, then it calculates the path length necessary to isolate an
    observation in the tree. The idea is that isolated observations, or anomalies,
    are easier to separate because there are fewer conditions necessary to distinguish
    them from normal cases. Thus, the anomalies will have shorter paths than normal
    observations and will, therefore, reside closer to the root of the tree. When
    several decision trees are created, the scores are averaged, which gives us a
    good idea about which observations are truly anomalies. As a result, isolation
    forests are used for outliers and anomaly detection.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法的工作方式与随机森林略有不同。它创建了一组决策树，然后计算在树中隔离一个观察所需的路径长度。其想法是孤立观察值或异常值更容易分离，因为区分它们与正常情况所需的条件较少。因此，异常值将比正常观察值有更短的路径，并且因此将更靠近树的根部。当创建了多个决策树时，分数会被平均，这让我们对哪些观察值真正是异常值有一个很好的了解。因此，隔离森林被用于异常值和异常检测。
- en: Also, an isolation forest does not utilize any distance or density measures
    to detect an anomaly. This reduces the computational cost significantly compared
    to the distance-based and density-based methods.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，隔离森林不利用任何距离或密度度量来检测异常。与基于距离和密度的方法相比，这显著降低了计算成本。
- en: In scikit-learn, `sklearn.ensemble.IsolationForest` provides an implementation
    of the isolation forest algorithm.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在scikit-learn中，`sklearn.ensemble.IsolationForest`提供了隔离森林算法的实现。
- en: See also
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The scikit-learn implementation of the isolation forest algorithm can be found
    here: [https://bit.ly/2DCjGGF](https://bit.ly/2DCjGGF)
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隔离森林算法的scikit-learn实现可以在这里找到：[https://bit.ly/2DCjGGF](https://bit.ly/2DCjGGF)
- en: Implementing random forest for predicting credit card defaults using H2O
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 H2O 实现预测信用卡违约的随机森林
- en: H2O is an open source and distributed machine learning platform that allows
    you to build machine learning models on large datasets. H2O supports both supervised
    and unsupervised algorithms and is extremely fast, scalable, and easy to implement. H2O's
    REST API allows us to access all its functionalities from external programs such
    as R and Python. H2O in Python is designed to be very similar to scikit-learn. At
    the time of writing this book, the latest version of H2O is H2O v3.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 是一个开源的分布式机器学习平台，允许您在大型数据集上构建机器学习模型。H2O 支持监督和非监督算法，并且非常快速、可扩展且易于实现。H2O 的
    REST API 允许我们从外部程序（如 R 和 Python）访问其所有功能。在编写本书时，H2O 的最新版本是 H2O v3。
- en: 'The reason why H2O brought lightning-fast machine learning to enterprises is
    given by the following explanation:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 将闪电般的机器学习带给企业的原因如下所述：
- en: '"H2O''s core code is written in Java. Inside H2O, a distributed key/value store
    is used to access and reference data, models, objects, and so on, across all nodes
    and machines. The algorithms are implemented on top of H2O''s distributed Map/Reduce
    framework and utilize the Java fork/join framework for multi-threading. The data
    is read in parallel and is distributed across the cluster and stored in memory
    in a columnar format in a compressed way. H2O''s data parser has built-in intelligence
    to guess the schema of the incoming dataset and supports data ingest from multiple
    sources in various formats"'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '"H2O 的核心代码是用 Java 编写的。在 H2O 中，使用分布式键/值存储来访问和引用数据、模型、对象等，跨越所有节点和机器。算法是在 H2O
    的分布式 Map/Reduce 框架上实现的，并利用 Java fork/join 框架进行多线程处理。数据并行读取并分布在整个集群中，以压缩的列格式存储在内存中。H2O
    的数据解析器具有内置的智能来猜测传入数据集的模式，并支持从多种格式的多个来源进行数据摄取"'
- en: '- from h2o.ai'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '- 来自 h2o.ai'
- en: H2O provides us with distributed random forests, which are a powerful tool used
    for classification and regression tasks. This generates multiple trees, rather
    than single trees. In a distributed random forest, we use the average predictions
    of both the classification and regression models to reach a final result.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 为我们提供了分布式随机森林，这是一种用于分类和回归任务的有力工具。它生成多个树，而不是单个树。在分布式随机森林中，我们使用分类和回归模型的平均预测来得出最终结果。
- en: Getting ready
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Java is an absolute must for H2O to run. Make sure you have Java installed
    with the following command in Jupyter:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Java 对于 H2O 运行是绝对必要的。请确保您已安装 Java，并在 Jupyter 中使用以下命令：
- en: '[PRE25]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You will now need to install H2O. To install this from Jupyter, use the following
    command:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您需要安装 H2O。要从 Jupyter 安装，请使用以下命令：
- en: '[PRE26]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Import the required libraries:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '[PRE27]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To use H2O, we need to initialize an instance and connect to it. We can do
    that as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 H2O，我们需要初始化一个实例并将其连接。我们可以这样做：
- en: '[PRE28]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'By default, the preceding command tries to connect to an instance. If it fails
    to do so, it will attempt to start an instance and then connect to it. Once connected
    to an instance, we will see the details of that instance, as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，前面的命令会尝试连接到一个实例。如果它无法这样做，它将尝试启动一个实例然后连接到它。一旦连接到实例，我们将看到该实例的详细信息，如下所示：
- en: '![](img/845d5994-fe6f-4d56-abfe-db1c235d5142.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/845d5994-fe6f-4d56-abfe-db1c235d5142.png)'
- en: 'We read our data into a `pandas` DataFrame:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据读入一个 `pandas` DataFrame：
- en: '[PRE29]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We change our `pandas` DataFrame to an H2O DataFrame using `h2o.H2OFrame()`.
    We name the `df_creditcarddata` H2O DataFrame:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `h2o.H2OFrame()` 将我们的 `pandas` DataFrame 转换为 H2O DataFrame。我们将 `df_creditcarddata`
    H2O DataFrame 命名：
- en: '[PRE30]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Check whether the data in the H2O DataFrame is properly loaded as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 H2O DataFrame 中的数据是否已正确加载，如下所示：
- en: '[PRE31]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can see the summary statistics with the `describe()` method:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `describe()` 方法查看摘要统计信息：
- en: '[PRE32]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We drop the ID column, as this will not be required for our model building
    exercise:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们删除 ID 列，因为这对于我们的模型构建练习不是必需的：
- en: '[PRE33]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We will now move on to explore our data and build our model.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将进入探索数据和构建模型的过程。
- en: How to do it...
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'We have performed various explorations on our data in the previous section.
    There is no limit to the ways in which we can explore our data. In this section,
    we are going to look at a few more techniques:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们对数据进行了各种探索。我们可以探索数据的方式没有限制。在本节中，我们将探讨一些更多技术：
- en: 'We check the correlation of each of our feature variables with the target variable:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们检查每个特征变量与目标变量的相关性：
- en: '[PRE34]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The following plot shows how each of the features is correlated with the target
    variable:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图显示了每个特征与目标变量的相关性：
- en: '![](img/fac4a15a-c60d-4fca-9ae4-01edb2638f15.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fac4a15a-c60d-4fca-9ae4-01edb2638f15.png)'
- en: 'We check the datatypes in the H2O DataFrame. Note that for the `pandas` DataFrame, we
    used `dtypes`. For the H2O DataFrame, we use types:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们检查H2O DataFrame中的数据类型。注意，对于`pandas` DataFrame，我们使用了`dtypes`。对于H2O DataFrame，我们使用`types`：
- en: '[PRE35]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We notice that they are all of the integer datatype. We will convert them to
    factor type, which is categorical in nature:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们注意到它们都是整型数据类型。我们将它们转换为因子类型，这是分类性质的：
- en: '[PRE36]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We can check the datatypes with `hf_creditcarddata.types` to see that the datatype
    conversion has taken place.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`hf_creditcarddata.types`来检查数据类型，以查看数据类型转换是否已发生。
- en: 'We will encode the binary target variable as a factor type variable:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将二进制目标变量编码为因子类型变量：
- en: '[PRE37]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We select the features and the `target` variable:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们选择特征和`target`变量：
- en: '[PRE38]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We now split the H2O DataFrame into training and testing subsets. We use 70%
    of our data for training the model and the remaining 30% for validation:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将H2O DataFrame拆分为训练集和测试集。我们使用70%的数据来训练模型，剩余的30%用于验证：
- en: '[PRE39]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We build our random forest model with the default settings. You can check the
    model performance on the test data with the following commands:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用默认设置构建了随机森林模型。您可以使用以下命令检查测试数据上的模型性能：
- en: '[PRE40]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This gives us the following performance metrics:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下性能指标：
- en: '![](img/1b237e8e-a899-4125-8590-a66ef4baa7a0.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1b237e8e-a899-4125-8590-a66ef4baa7a0.png)'
- en: How it works...
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the *Getting ready* section, we installed JRE and H2O. We initialized and
    connected to an H2O instance with `h2o.init()`. We then read our data using `pandas`
    and converted it to an H2O DataFrame. We used the `head()` and `describe()` methods
    on the H2O DataFrame, just like we used them on a `pandas` DataFrame. We then
    dropped the `ID` column from the H2O DataFrame.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在**准备就绪**部分，我们安装了JRE和H2O。我们使用`h2o.init()`初始化并连接到一个H2O实例。然后我们使用`pandas`读取我们的数据并将其转换为H2O
    DataFrame。我们在H2O DataFrame上使用了`head()`和`describe()`方法，就像我们在`pandas` DataFrame上使用它们一样。然后我们从H2O
    DataFrame中删除了`ID`列。
- en: After we did these data explorations in the *Getting ready* section, we moved
    on to the next steps. In *Step 1,* we checked the correlation of each of the features
    with the `target` variable. In *Step 2*, we used the `h2o` DataFrame and checked
    the datatypes.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在**准备就绪**部分进行这些数据探索之后，我们继续下一步。在**步骤 1**中，我们检查了每个特征与`target`变量的相关性。在**步骤 2**中，我们使用了`h2o`
    DataFrame并检查了数据类型。
- en: Note that for the `pandas` DataFrame we used `dtypes`, whereas we used `types`
    with the `h2o `DataFrame.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于`pandas` DataFrame，我们使用了`dtypes`，而对于`h2o` DataFrame，我们使用了`types`。
- en: In *Step 3*, we used `asfactor()` to convert the numeric variables to the categorical
    type. We performed this on variables that were supposed to be of a categorical
    type but were appearing as numeric.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 3**中，我们使用了`asfactor()`函数将数值变量转换为分类类型。我们对那些本应为分类类型但显示为数值的变量执行了此操作。
- en: In previous examples, we used the `astype()` method on a `pandas` DataFrame.
    With an H2O DataFrame, we used the `asfactor()` method.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们在`pandas` DataFrame上使用了`astype()`方法。对于H2O DataFrame，我们使用了`asfactor()`方法。
- en: In *Step 4*, we used `asfactor()` on our `target` variable to convert it to
    a categorical variable.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 4**中，我们在`target`变量上使用了`asfactor()`将其转换为分类变量。
- en: In *Step 5*, we separated our features and the `target` variable. In *Step*
    6, we split the H2O DataFrame into training and testing subsets using `split_frame()`
    on our H2O DataFrame. We used the `ratios` parameter and set it to `ratios=[0.7]`
    for `split_frame()` to allocate 70% of the data to the training set and 30% of
    the data to the testing set.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 5**中，我们将特征和`target`变量分开。在**步骤 6**中，我们使用`split_frame()`在H2O DataFrame上拆分了H2O
    DataFrame，将数据集分为训练集和测试集。我们使用`ratios`参数，并将其设置为`ratios=[0.7]`，以便`split_frame()`将70%的数据分配给训练集，30%的数据分配给测试集。
- en: In *Step 7*, we imported `H2ORandomForestEstimator` from `h2o.estimators.random_forest`.
    We passed `model_id` and then referred to it to call the `train()` function and
    pass the predictor and the `target` variables. We then looked at the performance
    metrics by passing the test subset to `model_performance()`.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 7**中，我们从`h2o.estimators.random_forest`导入了`H2ORandomForestEstimator`。我们传递了`model_id`，然后引用它来调用`train()`函数并传递预测变量和`target`变量。然后我们通过传递测试子集到`model_performance()`来查看性能指标。
- en: There's more...
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'In our preceding example, we have an AUC of `0.76` and a log loss of `0.44`:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们前面的例子中，我们有AUC为`0.76`和log损失为`0.44`：
- en: 'We can apply cross-validation by passing `nfolds` as a parameter to `H2ORandomForestEstimator()`:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过将`nfolds`作为参数传递给`H2ORandomForestEstimator()`来应用交叉验证：
- en: '[PRE41]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We notice that the AUC has slightly improved to `0.77` and that the log loss
    has dropped to `0.43`:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到AUC略有提高至`0.77`，而log损失降至`0.43`：
- en: '![](img/ee005306-9054-40e0-b54f-eb0931b04b2d.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ee005306-9054-40e0-b54f-eb0931b04b2d.png)'
- en: 'We can also apply a grid search to extract the best model from the given options.
    We set our options as follows:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以应用网格搜索来从给定选项中提取最佳模型。我们设置选项如下：
- en: '[PRE42]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We build the model with the preceding search parameters:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用前面的搜索参数构建模型：
- en: '[PRE43]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We now sort all models by AUC in a descending manner and then pick the first
    model, which has the highest AUC:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在按AUC降序对所有模型进行排序，然后选择第一个具有最高AUC的模型：
- en: '[PRE44]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We apply the best model for our test data:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应用最佳模型来测试我们的数据：
- en: '[PRE45]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We can plot the variable importance from the best model that we have achieved
    so far:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以绘制到目前为止我们达到的最佳模型的变量重要性：
- en: '[PRE46]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This gives us the following plot:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下图表：
- en: '![](img/1014ef94-8e46-46df-af56-802e3ba9589f.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1014ef94-8e46-46df-af56-802e3ba9589f.png)'
- en: See also
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: You may want to look into extremely randomized trees, which have a slightly
    different implementation but can sometimes perform better than random forests.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想了解一下极随机树，它们的实现方式略有不同，但有时可能比随机森林表现得更好。
- en: In ensemble methods, each model learns differently in terms of the subset of
    the dataset and the subset of the feature vector used for training. These subsets
    are taken randomly. Extremely randomized trees possess a high randomness factor
    in the way they compute the splits and the subset of the features selected. Unlike
    random forests, in which the splitting threshold is chosen randomly, in extremely
    randomized trees, a discriminative threshold is used as the splitting rule. Due
    to this, the overall variance of the ensemble decreases and the overall performance
    may be better.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在集成方法中，每个模型在数据集的子集和用于训练的特征向量子集方面以不同的方式学习。这些子集是随机选取的。极随机树在计算分裂和选择特征子集的方式上具有很高的随机性因素。与随机森林不同，在随机森林中分裂阈值是随机选择的，而在极随机树中，使用判别阈值作为分裂规则。因此，集成整体的方差降低，整体性能可能更好。
- en: The scikit-learn implementation of extremely randomized trees can be found at
    the following link: [https://bit.ly/2zWsNNS](https://bit.ly/2zWsNNS)[. H2O also
    supports extremely randomized trees. ](https://bit.ly/2zWsNNS)
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下链接中可以找到scikit-learn对极随机树的实现：[https://bit.ly/2zWsNNS](https://bit.ly/2zWsNNS)[.
    H2O也支持极随机树。](https://bit.ly/2zWsNNS)
