- en: '*Chapter 9*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第9章*'
- en: Hotspot Analysis
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 热点分析
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，你将能够：
- en: Understand some of the applications of spatial modeling
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解空间建模的一些应用
- en: Deploy hotspot models in the appropriate context
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在适当的背景下部署热点模型
- en: Build kernel density estimation models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建核密度估计模型
- en: Perform hotspot analysis and visualize the results
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行热点分析并可视化结果
- en: In this chapter, we will learn about kernel density estimation and learn how
    to perform hotspot analysis.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习核密度估计，并学习如何进行热点分析。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: 'Let''s consider an imaginary scenario: a new disease has begun spreading through
    numerous communities in the country that you live in and the government is trying
    to figure out how to confront this health emergency. Critical to any plan to confront
    this health emergency is epidemiological knowledge, including where the patients
    are located and how the disease is moving. The ability to locate and quantify
    problem areas (which are classically referred to as hotspots) can help health
    professionals, policy makers, and emergency response teams craft the most effective
    and efficient strategies for combating the disease. This scenario highlights one
    of the many applications of hotspot modeling.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个假设的情景：一种新的疾病已开始在你所在的国家的多个社区传播，政府正在努力找出如何应对这一健康紧急情况。应对这一健康紧急情况的关键是流行病学知识，包括患者的位置和疾病的传播方式。能够定位和量化问题区域（通常称为热点）可以帮助卫生专业人员、政策制定者和应急响应团队制定最有效的应对策略。这个情景突出了热点建模的众多应用之一。
- en: 'Hotspot modeling is an approach that is used to identify how a population is
    distributed across a geographical area; for example, how the population of individuals
    infected with the previously mentioned disease is spread across the country. The
    creation of this distribution relies on the availability of representative sample
    data. Note that the population can be anything definable in geographical terms,
    which includes, but is not limited to, crime, disease-infected individuals, people
    with certain demographic characteristics, or hurricanes:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 热点建模是一种用于识别人口在地理区域分布的方式的方法；例如，前面提到的疾病感染者在全国范围内的分布。创建这种分布依赖于代表性样本数据的可用性。请注意，人口可以是任何在地理术语上可定义的事物，包括但不限于犯罪、感染疾病的个体、具有特定人口特征的人群或飓风：
- en: '![Figure 9.1: A fabricated example of fire location data showing some potential
    hotspots'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.1：一个虚构的火灾位置数据示例，展示了一些潜在的热点'
- en: '](img/C12626_09_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_01.jpg)'
- en: 'Figure 9.1: A fabricated example of fire location data showing some potential
    hotspots'
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.1：一个虚构的火灾位置数据示例，展示了一些潜在的热点
- en: Hotspot analysis is incredibly popular, and this is mainly because of how easy
    it is to visualize the results and to read and interpret the visualizations. Newspapers,
    websites, blogs, and TV shows all leverage hotspot analysis to support the arguments,
    chapters, and topics included in them or on them. While it might not be as well-known
    as the most popular machine learning models, the main hotspot analysis algorithm,
    known as **kernel density estimation**, is arguably one of the most widely used
    analytical techniques. Kernel density estimation is a hotspot analysis technique
    that is used to estimate the true population distribution of specific geographical
    events.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 热点分析非常流行，主要是因为它易于可视化结果，并且易于阅读和解释这些可视化图像。报纸、网站、博客和电视节目都利用热点分析来支持其中的论点、章节和话题。虽然它可能不像最流行的机器学习模型那样知名，但主要的热点分析算法——**核密度估计**，无疑是最广泛使用的分析技术之一。核密度估计是一种热点分析技术，用于估计特定地理事件的真实人口分布。
- en: Spatial Statistics
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 空间统计
- en: '**Spatial statistics** is a branch of statistics that focuses on the analysis
    of data that has spatial properties, including geographic or topological coordinates.
    It is similar to time series analysis in that the goal is to analyze data that
    changes across some dimension. In the case of time series analysis, the dimension
    across which the data changes is time, whereas in the spatial statistics case,
    the data changes across the spatial dimension. There are a number of techniques
    that are included under the spatial statistics umbrella, but the technique we
    are concerned with here is kernel density estimation.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**空间统计学**是统计学的一个分支，专注于分析具有空间特性的数据显示，包括地理或拓扑坐标。它与时间序列分析相似，目标是分析在某一维度上发生变化的数据。在时间序列分析中，数据变化的维度是时间，而在空间统计学中，数据则在空间维度上变化。空间统计学涵盖了多种技术，但我们这里关注的技术是核密度估计。'
- en: As is the goal of most statistical analyses, in spatial statistics, we are trying
    to take samples of geographic data and use them to generate insights and make
    predictions. The analysis of earthquakes is one arena in which spatial statistical
    analyses are commonly deployed. By collecting earthquake location data, maps that
    identify areas of high and low earthquake likelihood can be generated, which can
    help scientists determine both where future earthquakes are likely to occur and
    what to expect in terms of intensity.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如大多数统计分析的目标一样，在空间统计学中，我们试图通过采样地理数据并利用这些数据生成见解和做出预测。地震分析是空间统计分析常见的一个应用领域。通过收集地震位置数据，可以生成标识高低地震可能性的地图，这可以帮助科学家确定未来地震发生的可能位置及强度预期。
- en: Probability Density Functions
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 概率密度函数
- en: 'Kernel density estimation uses the idea of the **probability density function**
    (**PDF**), which is one of the foundational concepts in statistics. The probability
    density function is a function that describes the behavior of a continuous **random
    variable**. That is, it expresses the likelihood, or probability, that the random
    variable takes on some range of values. Consider the heights of males in the United
    States as an example. By using the probability density function of the heights
    of males in the United States, we can determine the probability that some United
    States-based male is between 1.9 and 1.95 meters tall:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 核密度估计使用**概率密度函数**（**PDF**）的概念，这是统计学中的一个基础概念。概率密度函数是一个描述连续**随机变量**行为的函数。也就是说，它表示随机变量取某一范围值的可能性或概率。以美国男性的身高为例，通过使用美国男性身高的概率密度函数，我们可以确定某位美国男性身高在
    1.9 米到 1.95 米之间的概率：
- en: '![Figure 9.2: The standard normal distribution'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.2：标准正态分布'
- en: '](img/C12626_09_02.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_02.jpg)'
- en: 'Figure 9.2: The standard normal distribution'
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.2：标准正态分布
- en: Possibly the most popular density function in statistics is the standard normal
    distribution, which is simply the normal distribution centered at zero with the
    standard deviation equal to one.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 可能是统计学中最流行的密度函数就是标准正态分布，它是以零为中心，标准差为一的正态分布。
- en: 'Instead of the density function, what is typically available to statisticians
    or data scientists are randomly collected sample values coming from a population
    distribution that is unknown. This is where kernel density estimation comes in;
    it is a technique that is used for estimating the unknown probability density
    function of a random variable using sample data:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 与密度函数不同，统计学家或数据科学家通常只能获得从一个未知的总体分布中随机采集的样本值。这正是核密度估计的应用场景，它是一种利用样本数据估计随机变量的未知概率密度函数的技术：
- en: '![Figure 9.3: A mixture of three normal distributions'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.3：三种正态分布的混合'
- en: '](img/C12626_09_03.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_03.jpg)'
- en: 'Figure 9.3: A mixture of three normal distributions'
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.3：三种正态分布的混合
- en: Using Hotspot Analysis in Business
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在商业中使用热点分析
- en: We have already mentioned some of the ways in which hotspot modeling can be
    leveraged to meaningfully impact industry. The following use cases are common
    applications of hotspot modeling.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提到了一些可以利用热点建模对行业产生重要影响的方式。以下是热点建模的常见应用案例。
- en: When reporting on infectious diseases, health organizations and media companies
    typically use hotspot analysis to communicate where the diseases are located and
    the likelihood of contracting the disease based on geographic location. Using
    hotspot analysis, this information could be reliably computed and disseminated.
    Hotspot analysis is great for dealing with health data because the visualizations
    are very straightforward. This means that the chances of data being misinterpreted
    either intentionally or unintentionally are relatively low.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在报告传染性疾病时，卫生组织和媒体公司通常使用热点分析来传达疾病的地理分布及其根据地理位置的传播可能性。通过使用热点分析，这些信息可以被可靠地计算并传播。热点分析非常适合处理健康数据，因为可视化图表非常直接。这意味着数据被故意或无意地误解的可能性相对较低。
- en: Hotspot analysis can also be used to predict where certain events are likely
    to occur geographically. One research area that is leveraging the predictive capabilities
    of hotspot analysis more and more is the environmental sciences, which includes
    the study of natural disasters and extreme weather events. Earthquakes, for example,
    are notorious for being difficult to predict, because the time between significant
    earthquakes can be large, and the machinery needed to track and measure earthquakes
    to the degree required to make these predictions is relatively new.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 热点分析还可以用于预测某些事件在地理上的发生概率。越来越多的研究领域正在利用热点分析的预测能力，其中一个例子就是环境科学领域，包括自然灾害和极端天气事件的研究。例如，地震就以难以预测而闻名，因为重大地震之间的时间间隔可能较长，而所需的用于追踪和测量地震的机械设备相对较新。
- en: In terms of public policy and resource deployment, hotspot analysis can be very
    impactful when dealing with the analysis of population demographics. Determining
    where resources, both monetary and personnel, should be deployed can be challenging;
    however, given that resources are often demographic-specific, hotspot analysis
    is a useful technique since it can be used to determine the distribution of certain
    demographic characteristics. By demographic characteristics we mean that we could
    find the geographic distribution of high school graduates, immigrants from a specific
    global region, or individuals making $100,000 or more annually.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在公共政策和资源部署方面，热点分析在分析人口统计数据时可以产生重大影响。确定应该部署哪些资源（无论是金钱还是人力）可能是具有挑战性的；然而，考虑到资源往往是特定于人口的，热点分析是一种有用的技术，因为它可以用于确定某些人口统计特征的分布。这里的人口统计特征指的是我们可以找到高中毕业生、来自特定全球区域的移民或年收入超过10万美元的个人的地理分布。
- en: Kernel Density Estimation
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核密度估计
- en: One of the main methodological approaches to hotspot analysis is kernel density
    estimation. Kernel density estimation builds an estimated density using sample
    data and two parameters known as the **kernel function** and the **bandwidth value**.
    The estimated density is, like any distribution, essentially a guideline for the
    behavior of a random variable. Here, we mean how frequently the random variable
    takes on any specific value, ![](img/C12626_09_Formula_01.png). When dealing with
    hotspot analysis where the data is typically geographic, the estimated density
    answers the question *How frequently do specific longitude and latitude pairs
    appear?*. If a specific longitude and latitude pair, ![](img/C12626_09_Formula_02.png),
    and other nearby pairs occur with high frequency, then the estimated density built
    using the sample data will be expected to show that the area around the longitude
    and latitude pair has a high likelihood.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 热点分析的主要方法之一是核密度估计。核密度估计通过样本数据和两个被称为**核函数**和**带宽值**的参数来构建估计密度。估计的密度与任何分布一样，本质上是对随机变量行为的一个指导。在这里，我们指的是随机变量取特定值的频率，![](img/C12626_09_Formula_01.png)。在处理通常为地理数据的热点分析时，估计的密度回答了这个问题：*特定的经纬度对出现的频率是多少？*。如果某个特定的经纬度对，![](img/C12626_09_Formula_02.png)，以及其他附近的经纬度对出现频率较高，那么使用样本数据构建的估计密度将预示着该经纬度对周围区域的可能性较高。
- en: Kernel density estimation is referred to as a smoothing algorithm, because the
    process of estimating a density is the process of estimating the underlying shape
    of the data by disregarding the eccentricities and anomalies in the sample data.
    Stated another way, kernel density estimation removes the noise from the data.
    The only assumption of the model is that the data truly belongs to some interpretable
    and meaningful density from which insights can be derived and acted upon. That
    is, there exists a true underlying distribution.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 核密度估计被称为一种平滑算法，因为估计密度的过程实际上是通过忽略样本数据中的异常和离群值来估计数据的潜在形状。换句话说，核密度估计去除了数据中的噪声。该模型的唯一假设是数据确实属于某个可解释且有意义的密度，能够从中提取洞察并付诸实践。也就是说，存在一个真实的潜在分布。
- en: Arguably, more than any other topic in this book, kernel density estimation
    embodies the basic idea of statistics, which is to use sample data of finite size
    to make inferences about the population. We assume that the sample data contains
    clusters of data points and that these clusters imply regions of high likelihood
    in the true population. A benefit of creating a quality estimate of the true population
    density is that the estimated density can then be used to sample more data from
    the population.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，比本书中的任何其他话题，核密度估计体现了统计学的基本思想，即利用有限大小的样本数据对总体做出推断。我们假设样本数据包含数据点的聚类，这些聚类意味着总体中高可能性的区域。创建高质量的真实总体密度估计的好处是，估计的密度可以用来从总体中抽取更多的数据。
- en: 'Following this brief introduction, you probably have the following two questions:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段简要介绍之后，你可能会有以下两个问题：
- en: What is the bandwidth value?
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是带宽值？
- en: What is the kernel function?
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是核函数？
- en: We answer both of these questions next.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来会回答这两个问题。
- en: The Bandwidth Value
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带宽值
- en: The most crucial parameter in kernel density estimation is called the **bandwidth
    value** and its impact on the quality of the estimate cannot be overestimated.
    A high-level definition of the bandwidth value is that it is a value that determines
    the degree of smoothing. If the bandwidth value is low, then the estimated density
    will feature limited smoothing, which means that the density will capture all
    the noise in the sample data. If the bandwidth value is high, then the estimated
    density will be very smooth. An overly smooth density will remove characteristics
    of the true density from the estimated density, which are legitimate and not simply
    noise.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 核密度估计中最关键的参数被称为**带宽值**，它对估计结果的影响不可过高估计。带宽值的高层次定义是，它决定了平滑的程度。如果带宽值低，那么估计的密度将具有有限的平滑度，这意味着密度会捕捉到样本数据中的所有噪声。如果带宽值高，那么估计的密度将非常平滑。过于平滑的密度会移除估计密度中那些真实的且不只是噪声的特征。
- en: In more statistical or machine learning languages, the bandwidth parameter controls
    the bias-variance trade-off. That is, high variance is the result of low bandwidth
    values because the density is sensitive to the variance of the sample data. Low
    bandwidth values limit any ability the model may have had to adapt to and work
    around gaps in the sample data that are not present in the population. Densities
    estimated using low bandwidth values tend to overfit the data (this is also known
    as under-smoothed densities). When high bandwidth values are used, then the resulting
    density is underfit and the estimated density has a high bias (this is also known
    as over-smoothed densities).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在更多的统计学或机器学习语言中，带宽参数控制着偏差-方差权衡。也就是说，低带宽值会导致高方差，因为密度对样本数据的方差非常敏感。低带宽值限制了模型适应样本数据中未在总体中出现的空缺的能力。使用低带宽值估计的密度往往会出现过拟合（这也被称为过度平滑的密度）。当使用高带宽值时，所得的密度会出现欠拟合，并且估计的密度会有较高的偏差（这也被称为过度平滑的密度）。
- en: 'Exercise 46: The Effect of the Bandwidth Value'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习46：带宽值的影响
- en: 'In this exercise, we will fit nine different models with nine different bandwidth
    values to sample data created in the exercise. The goal here is to solidify our
    understanding of the impact the bandwidth parameter can have and make clear that
    if an accurate estimated density is sought, then the bandwidth value needs to
    be selected with care. Note that finding an optimal bandwidth value will be the
    topic of the next section. All exercises will be done in a Jupyter notebook utilizing
    Python 3; ensure that all package installation is done using `pip`. The easiest
    way to install the `basemap` module from `mpl_toolkits` is by using *Anaconda*.
    Instructions for downloading and installing *Anaconda* can be found at the beginning
    of this book:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将拟合九种不同的模型，每个模型使用不同的带宽值，来处理练习中创建的样本数据。这里的目标是巩固我们对带宽参数影响的理解，并明确表示，如果需要准确的估计密度，则必须小心选择带宽值。请注意，找到最优带宽值将是下一部分的主题。所有练习将在Jupyter
    notebook中使用Python 3完成；确保所有包的安装通过`pip`进行。安装`mpl_toolkits`中的`basemap`模块的最简单方法是使用*Anaconda*。下载和安装*Anaconda*的说明可以在本书的开头找到：
- en: 'Load all of the libraries that are needed for the exercises in this chapter.
    Here, the `matplotlib` library is used to create basic graphics; the `basemap`
    library is used to create graphics involving location data; the `numpy` library
    is used for working with arrays and matrices; the `pandas` library is used for
    working with DataFrames; the `scipy` library is used for scientific computing
    in Python; the `seaborn` library is used for creating much more attractive and
    complicated graphics; and the `sklearn` library is used to access data, manipulate
    the data, and run models. Additionally, ensure that the graphics be run inline
    and set to `seaborn`, so that all graphics appear as `seaborn` graphics:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载本章练习所需的所有库。在这里，`matplotlib`库用于创建基本图形；`basemap`库用于创建涉及位置数据的图形；`numpy`库用于处理数组和矩阵；`pandas`库用于处理DataFrame；`scipy`库用于Python中的科学计算；`seaborn`库用于创建更具吸引力和复杂的图形；`sklearn`库用于访问数据、处理数据和运行模型。此外，确保图形以内联方式运行并设置为`seaborn`，以便所有图形以`seaborn`图形的形式呈现：
- en: '[PRE0]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create some sample data (`vals`) by mixing three normal distributions. In addition
    to the sample data, define the true density curve (`true_density`) and the range
    over which the data will be plotted (`x_vec`):'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一些样本数据（`vals`），通过混合三个正态分布。除了样本数据外，还定义真实的密度曲线（`true_density`）以及数据将被绘制的范围（`x_vec`）：
- en: '[PRE1]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Define a list of tuples that will guide the creation of the multiplot graphic.
    Each tuple contains the row and column indices of the specific subplot, and the
    bandwidth value used to create the estimated density in that particular subplot:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个元组列表，用于指导创建多图形。每个元组包含特定子图的行和列索引，以及用于在该特定子图中创建估计密度的带宽值：
- en: '[PRE2]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create nine plots each using a different bandwidth value. The first plot, with
    the index of (0, 0), will have the lowest bandwidth and the last plot, with the
    index of (2, 2), will have the highest bandwidth. These values are not the absolute
    lowest or absolute highest bandwidth values, rather they are only the minimum
    and maximum of the list defined in the previous step:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建九个图形，每个图形使用不同的带宽值。第一个图形（索引为(0, 0)）将具有最低带宽，最后一个图形（索引为(2, 2)）将具有最高带宽。这些值不是绝对最低或绝对最高的带宽值，而仅仅是前一步中定义的列表中的最小和最大值：
- en: '[PRE3]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output is as follows:'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.4: A 3 x 3 matrix of subplots; each of which features an estimated
    density created using one of nine bandwidth values'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.4：一个3 x 3的子图矩阵；每个子图都使用九个带宽值之一创建了一个估计的密度'
- en: '](img/C12626_09_04.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_04.jpg)'
- en: 'Figure 9.4: A 3 x 3 matrix of subplots; each of which features an estimated
    density created using one of nine bandwidth values'
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9.4：一个3 x 3的子图矩阵；每个子图都使用九个带宽值之一创建了一个估计的密度
- en: Notice that on the lower end, the density curves clearly overfit the data. As
    the bandwidth values increase, the estimated density becomes smoother until it
    noticeably underfits the data. Visually, it looks like the optimal bandwidth may
    be around 1.6.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在较低带宽值时，密度曲线明显过度拟合数据。随着带宽值的增加，估计的密度变得更加平滑，直到明显低估数据。视觉上看，最优带宽可能在1.6左右。
- en: The next step is to design an algorithm to identify the optimal bandwidth value,
    so that the estimated density is the most reasonable and, therefore, the most
    reliable and actionable.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是设计一个算法来识别最优带宽值，从而使得估计的密度最为合理，因此也是最可靠和可操作的。
- en: Selecting the Optimal Bandwidth
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择最优带宽
- en: As mentioned in the previous exercise, we can come quite close to selecting
    the optimal bandwidth by simply comparing several densities visually. However,
    this is neither the most efficient method of selecting parameter values nor the
    most reliable.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一个练习中提到的，我们可以通过仅仅比较几种密度来接近选择最优带宽。然而，这既不是选择参数值的最有效方法，也不是最可靠的方法。
- en: There are two standard approaches to optimizing the bandwidth value, and both
    of these will appear in future exercises and activities. The first approach is
    a plug-in method (or a formulaic approach) that is deterministic and not optimized
    on the sample data. Plug-in methods are generally much faster to implement, simpler
    to code, and easier to explain. However, these methods have one big downside,
    which is that their accuracy tends to suffer compared to approaches that are optimized
    on the sample data. These methods also have distributional assumptions. The most
    popular plug-in methods are Silverman's Rule and Scott's Rule. By default, the
    `seaborn` package (which will be used in future exercises) uses Scott's Rule as
    the method to determine the bandwidth value.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种标准方法可以优化带宽值，这两种方法将在未来的练习和活动中出现。第一种方法是插件法（或公式化方法），它是确定性的，并且没有在样本数据上进行优化。插件方法通常实现更快，代码更简单，解释起来也更容易。然而，这些方法有一个重大缺点，即与在样本数据上进行优化的方法相比，其准确性往往较差。这些方法还具有分布假设。最流行的插件方法是Silverman规则和Scott规则。默认情况下，`seaborn`包（将在未来的练习中使用）使用Scott规则作为确定带宽值的方法。
- en: The second, and arguably the more robust, approach to finding an optimal bandwidth
    value is by searching a predefined grid of bandwidth values. Grid search is an
    empirical approach that is used frequently in machine learning and predictive
    modeling to optimize model hyperparameters. The process starts by defining the
    bandwidth grid, which is simply the collection of bandwidth values to be evaluated.
    Use each bandwidth value in the grid to create an estimated density; then, score
    the estimated density using the pseudo-log-likelihood value. The optimal bandwidth
    value is that which has the maximum pseudo-log-likelihood value. Think of the
    pseudo-log-likelihood value as the result of the probability of getting data points
    where we did get data points and the probability of not getting points where we
    did not get any data points. Ideally, both of these probabilities would be large.
    Consider the case where the probability of getting data points where we did get
    points is low. In this situation, the implication would be that the data points
    in the sample were anomalous because, under the true distribution, getting points
    where we did would not be expected with a high likelihood value.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种，也是更强健的方法，是通过搜索预定义的带宽值网格来找到最优的带宽值。网格搜索是一种经验性的方法，常用于机器学习和预测建模中，以优化模型的超参数。这个过程从定义带宽网格开始，带宽网格只是待评估的带宽值的集合。使用网格中的每个带宽值来创建估计的密度；然后，使用伪对数似然值对估计的密度进行评分。最优带宽值是具有最大伪对数似然值的那个。可以把伪对数似然值看作是获取我们确实获得数据点的概率和未获取数据点的概率。理想情况下，这两个概率应该都很大。考虑一下获取我们确实获得数据点的概率较低的情况。在这种情况下，意味着样本中的数据点是异常的，因为在真实分布下，获取我们确实获得的点的概率应该不高。
- en: Let's now implement the grid search approach to optimize the bandwidth value.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们实现网格搜索方法来优化带宽值。
- en: 'Exercise 47: Selecting the Optimal Bandwidth Using Grid Search'
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 47：使用网格搜索选择最优带宽
- en: 'In this exercise, we will create an estimated density for the sample data created
    in *Exercise 46*, *The Effect of the Bandwidth Value* with an optimal bandwidth
    value identified using grid search and cross-validation. To run the grid search
    with cross-validation, we will leverage `sklearn`, which we have used throughout
    this book. This exercise is a continuation of Exercise 1 as we are using the same
    sample data and continuing our exploration of the bandwidth value:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将为*练习 46*中创建的样本数据生成估计密度，*带宽值的影响*，并使用网格搜索和交叉验证方法确定最优带宽值。为了进行带有交叉验证的网格搜索，我们将使用`sklearn`，这是本书中一直使用的工具。这个练习是练习
    1 的延续，因为我们使用的是相同的样本数据，并继续探索带宽值：
- en: 'Define a grid of bandwidth values and the grid search cross-validation model.
    Ideally, the leave-one-out approach to cross-validation should be used, but for
    the sake of having the model run in a reasonable amount of time, we will do a
    10-fold cross-validation. Fit the model on the sample data, as follows:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义带宽值的网格和网格搜索交叉验证模型。理想情况下，应该使用逐一剔除交叉验证方法，但为了使模型在合理的时间内运行，我们将采用 10 倍交叉验证。按如下方式拟合模型：
- en: '[PRE4]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Extract the optimal bandwidth value from the model, as follows:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从模型中提取最优带宽值，如下所示：
- en: '[PRE5]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The optimal bandwidth value should be approximately two. We can interpret the
    optimal bandwidth value as the bandwidth value producing the maximum pseudo-log-likelihood
    value. Note that depending on the values included in the grid, the optimal bandwidth
    value can change.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最优带宽值应该大约为 2。我们可以将最优带宽值解释为生成最大伪对数似然值的带宽值。请注意，根据网格中包含的值，最优带宽值可能会有所变化。
- en: 'Plot the histogram of the sample data overlaid by both the true and estimated
    densities. In this case, the estimated density will be the optimal estimated density:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制样本数据的直方图，叠加真实密度和估计密度。在这种情况下，估计密度将是最优估计密度：
- en: '[PRE6]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is as follows:'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.5: A histogram of the random sample with the true density and the
    optimal estimated density overlaid'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.5：随机样本的直方图，叠加了真实密度和最优估计密度'
- en: '](img/C12626_09_05.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_05.jpg)'
- en: 'Figure 9.5: A histogram of the random sample with the true density and the
    optimal estimated density overlaid'
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.5：随机样本的直方图，叠加了真实密度和最优估计密度
- en: The estimated density is neither overfit or underfit to any noticeable degree
    and it definitely captures the three clusters. Arguably, it could map to the true
    density better, but this is just an estimated density generated by a model that
    has limitations.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 估计密度没有明显的过拟合或欠拟合，且它确实捕捉到了三个聚类。可以说，它可能会更好地映射到真实密度，但这只是由有局限性的模型生成的估计密度。
- en: 'Let''s now move onto the second question: what is the kernel function and what
    role does it play?'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续第二个问题：什么是核函数，它在模型中扮演什么角色？
- en: Kernel Functions
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 核函数
- en: The other parameter to be set is the kernel function. The kernel is a non-negative
    function that controls the shape of the density. Like topic models, we are working
    in a non-negative environment because it does not make sense to have negative
    likelihoods or probabilities.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要设置的参数是核函数。核是一个非负函数，控制密度的形状。像主题模型一样，我们在一个非负环境中工作，因为负的可能性或概率是没有意义的。
- en: The kernel function controls the shape of the estimated density by weighting
    the points in a systematic way. This systematic methodology for weighting is fairly
    simple; data points that are in close proximity to many other data points are
    up-weighted, whereas data points that are alone or far away from any other data
    points are down-weighted. Up-weighted data points will correspond to points of
    higher likelihood in the final estimated density.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 核函数通过系统地加权点来控制估计密度的形状。这种加权的系统方法相当简单；与许多其他数据点接近的数据点会被加权，而孤立或远离其他数据点的数据点则会被减权。加权的数据点将对应于最终估计密度中较高可能性的点。
- en: 'Many functions can be used as kernels, but six frequent choices are Gaussian,
    Tophat, Epanechnikov, Exponential, Linear, and Cosine. Each of these functions
    represents a unique distributional shape. Note that in each of the formulas the
    parameter, *h*, represents the bandwidth value:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用多种函数作为核，但六种常见选择是高斯核、顶帽核、埃潘尼基诺夫核、指数核、线性核和余弦核。这些函数分别代表独特的分布形状。请注意，在每个公式中，参数*h*表示带宽值：
- en: 'Gaussian:'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高斯：
- en: '![Figure 9.6: The formula for the Gaussian kernel'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.6：高斯核的公式'
- en: '](img/C12626_09_06.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_06.jpg)'
- en: 'Figure 9.6: The formula for the Gaussian kernel'
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.6：高斯核函数的公式
- en: 'Tophat:'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tophat 核：
- en: '![Figure 9.7: The formula for the Tophat kernel'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.7：Tophat 核函数的公式'
- en: '](img/C12626_09_07.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_07.jpg)'
- en: 'Figure 9.7: The formula for the Tophat kernel'
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.7：Tophat 核函数的公式
- en: 'Epanechnikov:'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Epanechnikov 核：
- en: '![Figure 9.8: The formula for the Epanechnikov kernel'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.8：Epanechnikov 核函数的公式'
- en: '](img/C12626_09_08.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_08.jpg)'
- en: 'Figure 9.8: The formula for the Epanechnikov kernel'
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.8：Epanechnikov 核函数的公式
- en: 'Exponential:'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指数型：
- en: '![Figure 9.9: The formula for the Exponential kernel'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.9：指数核函数的公式'
- en: '](img/C12626_09_09.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_09.jpg)'
- en: 'Figure 9.9: The formula for the Exponential kernel'
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.9：指数核函数的公式
- en: 'Linear:'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性型：
- en: '![Figure 9.10: The formula for the Linear kernel'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.10：线性核函数的公式'
- en: '](img/C12626_09_10.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_10.jpg)'
- en: 'Figure 9.10: The formula for the Linear kernel'
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.10：线性核函数的公式
- en: 'Cosine:'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 余弦型：
- en: '![Figure 9.11: The formula for the Cosine kernel'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.11：余弦核函数的公式'
- en: '](img/C12626_09_11.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_11.jpg)'
- en: 'Figure 9.11: The formula for the Cosine kernel'
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.11：余弦核函数的公式
- en: 'Here are the distributional shapes of the six kernel functions:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是六种核函数的分布形状：
- en: '![Figure 9.12: The general shapes of the six kernel functions'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.12：六种核函数的整体形状'
- en: '](img/C12626_09_12.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_12.jpg)'
- en: 'Figure 9.12: The general shapes of the six kernel functions'
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.12：六种核函数的整体形状
- en: The choice of kernel function is not completely insignificant, but it is definitely
    not nearly as important as the choice of bandwidth value. A reasonable book of
    action would be to use the gaussian kernel for all density estimation problems,
    which is what we will do in the following exercises and activities.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 核函数的选择并非完全不重要，但它绝对没有带宽值的选择那么重要。一个合理的行动方案是，对于所有的密度估计问题使用高斯核函数，这也是我们在接下来的练习和活动中将要做的。
- en: 'Exercise 48: The Effect of the Kernel Function'
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 48：核函数的影响
- en: 'The goal of this exercise is to understand how the choice of kernel function
    affects the quality of the density estimation. Like we did when exploring the
    bandwidth value effect, we will hold all other parameters constant, use the same
    data generated in the first two exercises, and run six different kernel density
    estimation models using the six kernel functions previously specified. Clear differences
    should be noticeable between the six estimated densities, but these differences
    should be slightly less dramatic than the differences between the densities estimated
    using the different bandwidth values:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的目标是理解核函数的选择如何影响密度估计的质量。就像我们在探索带宽值的影响时一样，我们将保持其他所有参数不变，使用在前两个练习中生成的相同数据，并使用先前指定的六种核函数运行六个不同的核密度估计模型。六个估算的密度之间应该能看到明显的差异，但这些差异应该比使用不同带宽值时的密度差异稍微小一些：
- en: 'Define a list of tuples along the same lines as the one defined previously.
    Each tuple includes the row and column indices of the subplot, and the kernel
    function to be used to create the density estimation:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个与之前定义的类似的元组列表。每个元组包括子图的行列索引，以及用于创建密度估计的核函数：
- en: '[PRE7]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is as follows:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.13: A 3 x 2 matrix of subplots, each of which features an estimated
    density'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.13：一个 3 x 2 的子图矩阵，每个子图展示一个估算的密度'
- en: created using one of six kernel functions
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用六种核函数之一创建
- en: '](img/C12626_09_13.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_13.jpg)'
- en: 'Figure 9.13: A 3 x 2 matrix of subplots, each of which features an estimated
    density created using one of six kernel functions'
  id: totrans-122
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.13：一个 3 x 2 的子图矩阵，每个子图展示使用六种核函数之一估算的密度
- en: Out of the six kernel functions, the gaussian kernel produced the most reasonable
    estimated density. Beyond that, notice that the difference between the estimated
    densities with different kernels is less than the difference between the estimated
    densities with different bandwidth values. This goes to the previously made claim
    that the bandwidth value is the more important parameter and should be the focus
    during the model building process.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这六种核函数中，高斯核函数产生了最合理的估算密度。更进一步，注意到不同核函数下的估算密度之间的差异小于使用不同带宽值时的差异。这证明了之前的观点，即带宽值是更重要的参数，应该在模型构建过程中重点关注。
- en: With our understanding mostly formed, let's discuss the derivation of kernel
    density estimation in a high-level fashion.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们大致理解的基础上，接下来让我们以高层次的方式讨论核密度估计的推导过程。
- en: Kernel Density Estimation Derivation
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 核密度估计推导
- en: Let's skip the formal mathematical derivation in favor of the popular derivation
    by intuition. Kernel density estimation turns each data point in the sample into
    its own distribution whose width is controlled by the bandwidth value. The individual
    distributions are then summed to create the desired density estimate. This concept
    is fairly easy to demonstrate; however, before doing that in the next exercise,
    let's try to think through it in an abstract way. For geographic regions containing
    many sample data points, the individual densities will overlap and, through the
    process of summing those densities, will create points of high likelihood in the
    estimated density. Similarly, for geographic regions containing few to no sample
    data points, the individual densities will not overlap and, therefore, will correspond
    to points of low likelihood in the estimated density.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们跳过正式的数学推导，而采用直观的流行推导方法。核密度估计将样本中的每个数据点转化为其自身的分布，其宽度由带宽值控制。然后，将这些单独的分布相加，以创建所需的密度估计。这个概念相对容易演示；然而，在接下来的练习中之前，让我们尝试以抽象的方式思考它。对于包含许多样本数据点的地理区域，单独的密度将会重叠，并且通过加总这些密度，将在估计密度中创建高概率点。同样，对于包含少量甚至没有样本数据点的地理区域，单独的密度不会重叠，因此在估计密度中对应的将是低概率点。
- en: 'Exercise 49: Simulating the Derivation of Kernel Density Estimation'
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 49：模拟核密度估计的推导
- en: 'The goal here is to demonstrate the concept of summing individual distributions
    to create an overall estimated density for a random variable. We will establish
    the concept incrementally by starting with one sample data point and then work
    up to many sample data points. Additionally, different bandwidth values will be
    applied, so our understanding of the effect of the bandwidth value on these individual
    densities will solidify further:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目标是演示将单独分布相加，以创建随机变量的总体估计密度的概念。我们将通过从一个样本数据点开始，逐步建立这个概念，随后增加更多的样本数据点。此外，还将应用不同的带宽值，从而进一步巩固我们对带宽值对这些单独密度影响的理解：
- en: 'Define a function that will evaluate the normal distribution. The input values
    are the grid representing the range of the random variable, *X*, the sampled data
    point, *m*, and the bandwidth, *b*:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来评估正态分布。输入值包括代表随机变量范围的网格 *X*、采样数据点 *m* 和带宽 *b*：
- en: '[PRE8]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Plot a single sample data point as a histogram and as an individual density
    with varying bandwidth values:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将单个样本数据点绘制为直方图，并与不同带宽值下的单独密度进行比较：
- en: '[PRE9]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output is as follows:'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.14: Showing one data point and its individual density at various
    bandwidth values'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.14：展示一个数据点及其在不同带宽值下的单独密度'
- en: '](img/C12626_09_14.jpg)'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12626_09_14.jpg)'
- en: 'Figure 9.14: Showing one data point and its individual density at various bandwidth
    values'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.14：展示一个数据点及其在不同带宽值下的单独密度
- en: Here, we see what has already been established, which is that lower bandwidth
    values produce very narrow densities that tend to overfit the data.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们看到已经建立的结论，即较小的带宽值会产生非常狭窄的密度，容易导致数据过拟合。
- en: 'Reproduce the work done in *Step 2*, but now scale up to 16 data points:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新生成*步骤2*中的工作，但这次扩展到16个数据点：
- en: '[PRE10]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output is as follows:'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.15: Showing 16 data points, their individual densities at various  andwidth
    values, and the sum of their individual densities'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.15：展示16个数据点、它们在不同带宽值下的单独密度，以及它们单独密度的总和'
- en: '](img/C12626_09_15.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_15.jpg)'
- en: 'Figure 9.15: Showing 16 data points, their individual densities at various
    bandwidth values, and the sum of their individual densities'
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.15：展示16个数据点、它们在不同带宽值下的单独密度，以及它们单独密度的总和
- en: Again, unsurprisingly, the plot utilizing the smallest bandwidth value features
    a wildly overfitted estimated density. That is, the estimated density captures
    all the noise in the sample data. Of these three densities, the second one, where
    the bandwidth value was set to 0.35, is the most reasonable.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，使用最小带宽值的图形呈现出严重过拟合的估计密度。也就是说，估计密度捕捉到了样本数据中的所有噪声。在这三种密度中，第二种密度，即带宽值设置为0.35时的估计密度，最为合理。
- en: 'Activity 21: Estimating Density in One Dimension'
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 21：估计一维密度
- en: In this first activity, we will be generating some fake sample data and estimating
    the density function using kernel density estimation. The bandwidth value will
    be optimized using grid search cross-validation. The goal is to solidify our understanding
    of this useful methodology by running the model in a simple one-dimension case.
    We will once again leverage Jupyter notebooks to do our work.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在这第一个活动中，我们将生成一些虚拟示例数据，并使用核密度估计估计密度函数。带宽值将通过网格搜索交叉验证进行优化。目标是通过在一个简单的单维案例中运行模型，巩固我们对这一有用方法论的理解。我们将再次使用
    Jupyter notebooks 来完成这项工作。
- en: Imagine that the sample data we will be creating describes the price of homes
    in a state in the United States. Momentarily ignore the values in the following
    sample data. The question is, *What does the distribution of home prices look
    like, and can we extract the probability of a house having a price that falls
    in some specific range?* These questions and more are answerable using kernel
    density estimation.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们将要创建的示例数据描述的是美国某州的房价。暂时忽略以下示例数据中的数值。问题是，*房价的分布是什么样的，我们能否提取出房子价格落在某个特定范围内的概率？*这些问题以及更多的问题都可以通过核密度估计来回答。
- en: 'Here are the steps to complete the activity:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 完成该活动的步骤如下：
- en: Open a new notebook and install all the necessary libraries.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的笔记本，并安装所有必要的库。
- en: Sample 1,000 data points from the standard normal distribution. Add 3.5 to each
    of the last 625 values of the sample (that is, the indices between 375 and 1,000).
    Set a random state of 100\. To do this, set a random state of 100 using `numpy.random.RandomState`
    to guarantee the same sampled values, and then randomly generate the data points
    using the `randn(1000)` call.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从标准正态分布中采样1,000个数据点。将3.5加到样本的最后625个值上（即，375到1,000之间的索引）。设置随机状态为100。为此，使用`numpy.random.RandomState`设置一个随机状态为100，以保证相同的采样值，然后使用`randn(1000)`调用随机生成数据点。
- en: Plot the 1,000-point sample data as a histogram and add a scatterplot below
    it.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将1,000个样本数据绘制成直方图，并在其下方添加散点图。
- en: Define a grid of bandwidth values. Then, define and fit a grid search cross-validation
    algorithm.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个带宽值的网格。然后，定义并拟合一个网格搜索交叉验证算法。
- en: Extract the optimal bandwidth value.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取最佳带宽值。
- en: Replot the histogram from *Step 3* and overlay the estimated density.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新绘制*步骤 3*中的直方图，并叠加估计的密度。
- en: 'The output will be as follows:'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.16: A histogram of the random sample with the optimal estimated
    density overlaid'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.16：带有最佳估计密度叠加的随机样本直方图'
- en: '](img/C12626_09_16.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_16.jpg)'
- en: 'Figure 9.16: A histogram of the random sample with the optimal estimated density
    overlaid'
  id: totrans-158
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.16：带有最佳估计密度叠加的随机样本直方图
- en: Note
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 374.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以在第374页找到。
- en: Hotspot Analysis
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 热点分析
- en: To start, hotspots are areas of higher concentrations of data points, such as
    particular neighborhoods where the crime rate is abnormally high or swaths of
    the country that are impacted by an above-average number of tornadoes. Hotspot
    analysis is the process of finding these hotspots, should any exist, in a population
    using sampled data. This process is generally done by leveraging kernel density
    estimation.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，热点是数据点浓度较高的区域，例如犯罪率异常高的特定街区，或遭受异常多龙卷风影响的某些地区。热点分析是通过使用采样数据，在总体中寻找这些热点的过程。这个过程通常通过利用核密度估计来完成。
- en: 'Hotspot analysis can be described in four high-level steps:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 热点分析可以通过四个高层次步骤来描述：
- en: '**Collect the data**: The data should include the locations of the objects
    or events. As we have briefly mentioned, the amount of data needed to run and
    achieve actionable results is relatively flexible. The optimal state is to have
    a sample dataset that is representative of the population.'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**收集数据**：数据应包括对象或事件的位置。如我们简要提到的，进行分析并获得可操作结果所需的数据量相对灵活。理想状态是拥有一个能够代表总体的样本数据集。'
- en: '**Identify the base map**: The next step is to identify which base map would
    best suit the analytical and presentational needs of the project. On this base
    map, the results of the model will be overlaid, so that the locations of the hotspots
    can be easily articulated in much more digestible terms, such as city, neighborhood,
    or region.'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**确定基础地图**：下一步是确定哪种基础地图最适合项目的分析和展示需求。在这张基础地图上，将叠加模型的结果，以便更容易地以城市、街区或区域等更易理解的术语表达热点的位置。'
- en: '**Execute the model**: In this step, you select and execute one or multiple
    methodologies of extracting spatial patterns to identify hotspots. For us, this
    method will be – no surprise – kernel density estimation.'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**执行模型**：在此步骤中，您将选择并执行一种或多种提取空间模式以识别热点的方法。对于我们来说，这种方法将是——毫无悬念——核密度估计。'
- en: '**Create the visualization**: The hotspot maps are generated by overlaying
    the model results on the base map to support whatever business questions are outstanding.'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建可视化**：热点图是通过将模型结果叠加在基础地图上生成的，旨在支持解决任何悬而未决的业务问题。'
- en: One of the principal issues with hotspot analysis from a usability standpoint
    is that the statistical significance of a hotspot is not particularly easy to
    ascertain. Most questions about statistical significance revolve around the existence
    of the hotspots. That is, do the fluctuations in likelihood of occurrence actually
    amount to statistically significant fluctuations? It is important to note that
    statistical significance is not required to perform kernel density estimation
    and that we will not be dealing with significance at all going forward.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 从可用性角度来看，热点分析的一个主要问题是热点的统计显著性并不是特别容易确定。关于统计显著性的大部分问题围绕热点的存在展开。也就是说，发生可能性的波动是否真的构成统计学上的显著波动？需要注意的是，执行核密度估计并不要求统计显著性，且我们在后续过程中将完全不涉及显著性问题。
- en: While the term hotspot is traditionally reserved to describe a cluster of location
    data points, it is not limited to location data. Any data type can have hotspots
    regardless of whether or not they are referred to as hotspots. In one of the following
    exercises, we will model some non-location data to find hotspots, which will be
    regions of feature space having a high or low likelihood of occurrence.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管“热点”一词传统上用来描述一组地理位置数据点，但它不限于位置数据。任何类型的数据都可能有热点，无论这些数据是否被称为热点。在接下来的练习中，我们将对一些非位置数据进行建模，以找出热点，这些热点是特征空间中发生可能性较高或较低的区域。
- en: 'Exercise 50: Loading Data and Modeling with Seaborn'
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 50：加载数据并使用 Seaborn 进行建模
- en: 'In this exercise, we will work with the `seaborn` library to fit and visualize
    kernel density estimation models. This is done on both location and non-location
    data. Before getting into the modeling, we load the data, which is the California
    housing dataset that is automatically loaded with `sklearn`. Taken from the United
    States census in 1990, this dataset describes the housing situation in California
    during that time. One row of data describes one census block group. The definition
    of a census block group is irrelevant to this exercise, so we will bypass the
    definition here in favor of more hands-on coding and modeling. It is important
    to mention that all the variables are aggregated to the census block. For example,
    `MedInc` is the median income of households in each census block. Additional information
    on this dataset is available at [https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset](https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset):'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将使用 `seaborn` 库来拟合和可视化核密度估计模型。这将应用于位置数据和非位置数据。开始建模之前，我们加载数据，这些数据是与
    `sklearn` 一起自动加载的加利福尼亚住房数据集。该数据集来源于1990年美国人口普查，描述了当时加利福尼亚的住房情况。数据集中的每一行描述了一个人口普查块组。人口普查块组的定义与本次练习无关，因此我们将跳过对其的定义，专注于更多的实操编码与建模。需要提到的是，所有变量都是按人口普查块进行聚合的。例如，`MedInc`
    是每个人口普查块的家庭收入中位数。关于此数据集的更多信息，请访问 [https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset](https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset)：
- en: 'Load the California housing dataset using `fetch_california_housing()`. Convert
    the data to a DataFrame using `pandas` and print the first five rows of the DataFrame:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `fetch_california_housing()` 加载加利福尼亚住房数据集。使用 `pandas` 将数据转换为 DataFrame 并打印出
    DataFrame 的前五行：
- en: '[PRE11]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.17: The first five rows of the California housing dataset from sklearn'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.17：来自 sklearn 的加利福尼亚住房数据集的前五行'
- en: '](img/C12626_09_17.jpg)'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12626_09_17.jpg)'
- en: 'Figure 9.17: The first five rows of the California housing dataset from sklearn'
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.17：来自 sklearn 的加利福尼亚住房数据集的前五行
- en: 'Filter the DataFrame based on the `HouseAge` feature, which is the median home
    age of each census block. Keep only the rows with `HouseAge` less than or equal
    to 15 and name the DataFrame `dfLess15`. Print out the first five rows of the
    DataFrame; Then, reduce the DataFrame down to just the longitude and latitude
    features:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据`HouseAge`特征过滤数据框，该特征表示每个普查区块的房屋中位数年龄。仅保留`HouseAge`小于或等于15的行，并将数据框命名为`dfLess15`。打印数据框的前五行；然后，将数据框缩减为仅包含经度和纬度特征：
- en: '[PRE12]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output is as follows:'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.18: The first five rows of the dataset filtered down to those rows
    that have a value of 15 or less in the HouseAge column'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.18：过滤后的数据集前五行，仅包含`HouseAge`列值小于或等于15的行'
- en: '](img/C12626_09_18.jpg)'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12626_09_18.jpg)'
- en: 'Figure 9.18: The first five rows of the dataset filtered down to those rows
    that have a value of 15 or less in the HouseAge column'
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.18：过滤后的数据集前五行，仅包含`HouseAge`列值小于或等于15的行
- en: 'Use `seaborn` to fit and visualize the kernel density estimation model built
    on the longitude and latitude data points. The `seaborn` approach to fitting these
    models uses Scott''s Rule. There are four inputs to the model, which are the names
    of the two columns over which the estimated density is sought (that is, the longitude
    and latitude), the DataFrame to which those columns belong, and the method of
    density estimation (that is, the `kde` or kernel density estimation):'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`seaborn`拟合并可视化基于经度和纬度数据点构建的核密度估计模型。`seaborn`拟合这些模型的方法使用了Scott规则。该模型有四个输入，它们是求估计密度的两列的名称（即经度和纬度）、这些列所属的数据框，以及密度估计的方法（即`kde`或核密度估计）：
- en: '[PRE13]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is as follows:'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.19: A joint plot containing both the two-dimensional estimated density
    plus the marginal densities for the dfLess15 dataset'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.19：包含二维估计密度以及dfLess15数据集的边际密度的联合图'
- en: '](img/C12626_09_19.jpg)'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12626_09_19.jpg)'
- en: 'Figure 9.19: A joint plot containing both the two-dimensional estimated density
    plus the marginal densities for the dfLess15 dataset'
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.19：包含二维估计密度以及dfLess15数据集的边际密度的联合图
- en: If we overlay these results on a map of California, we will see that the hotspots
    are southern California, including Los Angeles and San Diego, the bay area, including
    San Francisco, and to a small degree the area known as the central valley. A benefit
    of this `seaborn` graphic is that we get the two-dimensional estimated density
    and the marginal densities for both longitude and latitude.
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们将这些结果叠加到加利福尼亚州的地图上，我们将看到热点位于南加州，包括洛杉矶和圣地亚哥，湾区，包括旧金山，以及在一定程度上被称为中央谷地的地区。这个`seaborn`图形的一个优点是，我们可以得到二维估计密度以及经度和纬度的边际密度。
- en: 'Create another filtered DataFrame based on the `HouseAge` feature; this time
    keep only the rows with `HouseAge` greater than 40 and name the DataFrame `dfMore40`.
    Additionally, remove all the columns except for longitude and latitude. Then,
    print the first five rows of the DataFrame:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于`HouseAge`特征创建另一个过滤后的数据框；这次仅保留`HouseAge`大于40的行，并将数据框命名为`dfMore40`。此外，移除所有列，保留经度和纬度。然后，打印数据框的前五行：
- en: '[PRE14]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output is as follows:'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.20: The top of the dataset filtered to the rows containing values
    greater than 40 in the HouseAge column'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.20：过滤后的数据集顶部，仅包含`HouseAge`列中大于40的行'
- en: '](img/C12626_09_20.jpg)'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12626_09_20.jpg)'
- en: 'Figure 9.20: The top of the dataset filtered to the rows containing values
    greater than 40 in the HouseAge column'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.20：过滤后的数据集顶部，仅包含`HouseAge`列中大于40的行
- en: 'Repeat the process from *Step 3*, but now using this new filtered DataFrame:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*步骤3*的过程，但这次使用新的过滤后的数据框：
- en: '[PRE15]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output is as follows:'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.21: A joint plot containing both the two-dimensional estimated density
    plus the marginal densities for the dfMore40 dataset'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.21：包含二维估计密度以及dfMore40数据集的边际密度的联合图'
- en: '](img/C12626_09_21.jpg)'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12626_09_21.jpg)'
- en: 'Figure 9.21: A joint plot containing both the two-dimensional estimated density
    plus the marginal densities for the dfMore40 dataset'
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.21：包含二维估计密度以及dfMore40数据集的边际密度的联合图
- en: This estimated density is much more compact in that the data is clustered almost
    entirely in two areas. Those areas are Los Angeles and the bay area. Comparing
    this to the plot in *Step 3*, we notice that housing development has spread out
    across the state. Additionally, newer housing developments occur with much higher
    frequencies in a larger number of census blocks.
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个估算密度要紧凑得多，因为数据几乎完全聚集在两个区域。这些区域是洛杉矶和湾区。将其与*步骤3*中的图形进行比较，我们注意到住房开发已经遍布全州。此外，新建住房开发在更多普查区块中出现的频率更高。
- en: 'Let''s again create another filtered DataFrame. This time only keeping rows
    where `HouseAge` is less than or equal to five and name the DataFrame `dfLess5`.
    Plot `Population` and `MedInc` as a scatterplot, as follows:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们再次创建一个新的过滤后的DataFrame。这次仅保留`HouseAge`小于或等于5的行，并将该DataFrame命名为`dfLess5`。绘制`Population`和`MedInc`的散点图，方法如下：
- en: '[PRE16]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output is as follows:'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.22: A scatterplot of the median income against population for values
    of five or less in the HouseAge column'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.22：中位收入与人口的散点图，HouseAge列中的值为5或以下'
- en: '](img/C12626_09_22.jpg)'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12626_09_22.jpg)'
- en: 'Figure 9.22: A scatterplot of the median income against population for values
    of five or less in the HouseAge column'
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9.22：中位收入与人口的散点图，HouseAge列中的值为5或以下
- en: 'Use yet another `seaborn` function to fit a kernel density estimation model.
    Again, the optimal bandwidth is found using Scott''s Rule. Replot the histogram
    and overlay the estimated density, as follows:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用另一个`seaborn`函数来拟合核密度估计模型。同样，使用Scott规则找到最优带宽。重新绘制直方图并叠加估算密度，如下所示：
- en: '[PRE17]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is as follows:'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.23: The same scatterplot as created in Step 6 with the estimated
    density overlaid'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.23：与步骤6中创建的散点图相同，叠加了估算密度'
- en: '](img/C12626_09_23.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_23.jpg)'
- en: 'Figure 9.23: The same scatterplot as created in Step 6 with the estimated density
    overlaid'
  id: totrans-215
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9.23：与步骤6中创建的散点图相同，叠加了估算密度
- en: Here, the estimated density shows that census blocks with smaller populations
    have lower median incomes at higher likelihoods than they have high median incomes.
    The point of this step is to showcase how kernel density estimation can be used
    on non-location data.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，估算密度显示，人口较少的普查区块比人口较多的普查区块更有可能拥有较低的中位收入，而不是较高的中位收入。本步骤的目的是展示如何在非位置数据上使用核密度估计。
- en: When presenting the results of hotspot analysis, some type of map should be
    involved since hotspot analysis is generally done on location data. Acquiring
    maps on which estimated densities can be overlaid is not an easy process. Due
    to copyright issues, we will use very basic maps, called basemaps, on which we
    can overlay our estimated densities. It will be left to you to extend the knowledge
    you acquire in this chapter to fancier and more detailed maps. Mapping environments
    can also be complicated and time-consuming to download and install.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在展示热点分析结果时，应当使用某种地图，因为热点分析通常是基于位置数据进行的。获取可以叠加估算密度的地图并不是一个简单的过程。由于版权问题，我们将使用非常基础的地图，称为底图，来叠加我们的估算密度。如何将本章获得的知识扩展到更复杂和详细的地图将留给你自己去做。地图环境的下载和安装可能也会很复杂且耗时。
- en: 'Exercise 51: Working with Basemaps'
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习51：与底图一起工作
- en: This exercise leverages the `basemap` module of `mpl_toolkits`. `basemap` is
    a mapping library, which can be used to create basic maps or outlines of geographic
    regions. These maps can have the results of kernel density estimation overlaid,
    so that we can clearly see where the hotspots are located.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习利用了`mpl_toolkits`中的`basemap`模块。`basemap`是一个地图绘制库，可以用来创建基础的地图或地理区域的轮廓。这些地图可以叠加核密度估计的结果，从而清晰地看到热点的位置。
- en: First, check whether `basemap` is installed by running `import mpl_toolkits.basemap`
    in a Jupyter notebook. If it loads without error, then you are ready and need
    to take no further action. If the call fails, then install `basemap` using `pip`
    by running `python3 -m pip install basemap`. You should be good to go after restarting
    any already-open notebooks. Note that the `pip` installation will only work if
    Anaconda is installed.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过在Jupyter Notebook中运行`import mpl_toolkits.basemap`来检查`basemap`是否已安装。如果加载没有错误，那么你已经准备好了，无需进一步操作。如果调用失败，则使用`pip`安装`basemap`，方法是运行`python3
    -m pip install basemap`。在重新启动任何已打开的Notebook之后，你应该就可以正常使用。请注意，`pip`安装只有在安装了Anaconda的情况下才有效。
- en: 'The goal of this exercise is to remodel and replot the location data from *Exercise
    50*, *Loading Data and Modeling with Seaborn*, using the kernel density estimation
    functions of `sklearn` and the mapping capabilities of `basemap`. Extract the
    longitude and latitude values from the filtered DataFrame called `dfLess15`, as
    follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的目标是重新建模并重新绘制*练习50*中位置数据的图表，使用`sklearn`的核密度估计功能和`basemap`的映射能力。从名为`dfLess15`的筛选后的DataFrame中提取经纬度值，如下所示：
- en: 'Form the grid of locations over which the estimated density will be laid. The
    grid of locations is the two-dimensional location equivalent of the one-dimensional
    vector defining the range of the random variable in Exercise 1:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 形成将要叠加估算密度的位置网格。位置网格是定义随机变量范围的一维向量的二维位置等价物，在练习1中已涉及。
- en: '[PRE18]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output is as follows:'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.24: The x and y components of the grid representing the dfLess15
    dataset'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.24：表示dfLess15数据集的网格的x和y分量'
- en: '](img/C12626_09_24.jpg)'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12626_09_24.jpg)'
- en: 'Figure 9.24: The x and y components of the grid representing the dfLess15 dataset'
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9.24：表示dfLess15数据集的网格的x和y分量
- en: 'Define and fit a kernel density estimation model. Set the bandwidth value to
    0.05 in order to save runtime; then, create likelihood values for each point on
    the location grid:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义并拟合一个核密度估计模型。设置带宽值为0.05，以节省运行时间；然后，为位置网格中的每个点创建似然值：
- en: '[PRE19]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Notice that if you print out the shape of the likelihood values, it is 3,287
    rows by 3,287 columns, which is 10,804,369 likelihood values. This is the same
    number of values in the preestablished longitude and latitude grid, called `xy15`.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，如果你打印出似然值的形状，它是3,287行和3,287列，总共有10,804,369个似然值。这与预设的经纬度网格（称为`xy15`）中的值数量相同。
- en: 'Create an outline of California and overlay the estimated density computed
    in *Step 2*:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建加利福尼亚州的轮廓，并叠加在*步骤2*中估算的密度值上：
- en: '[PRE20]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output is as follows:'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.25: The estimated density of dfLess15 overlaid onto an outline of
    California'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.25：将dfLess15的估算密度叠加到加利福尼亚州的轮廓上'
- en: '](img/C12626_09_25.jpg)'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12626_09_25.jpg)'
- en: 'Figure 9.25: The estimated density of dfLess15 overlaid onto an outline of
    California'
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9.25：将dfLess15的估算密度叠加到加利福尼亚州的轮廓上
- en: The 0.05 value was set to purposefully overfit the data slightly. You'll notice
    that instead of the larger clusters that make up the density in *Exercise 50,
    Loading Data and Modeling with Seaborn* the estimated density here is made up
    of much smaller clusters. This slightly overfit density might be a bit more helpful
    than the previous version of the density because it gives you a clearer view of
    where the high likelihood census blocks are truly located. One of the high-likelihood
    areas in the previous density was southern California, but southern California
    is a huge area with an enormous population and many municipalities. Bear in mind
    that when using the results for business decisions, certain levels of specificity
    might be required and should be provided if the sample data can support results
    with that level of specificity or granularity.
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 0.05的值是故意设置为稍微过拟合数据的。你会注意到，与在*练习50，使用Seaborn加载数据和建模*中组成密度的大型聚类不同，这里的估算密度由许多更小的聚类组成。这个稍微过拟合的密度可能比之前的版本更有帮助，因为它能更清楚地显示出高似然值的普查区块真正的位置。前一个密度中的一个高似然区域是南加州，但南加州是一个巨大的地区，拥有庞大的人口和许多市政区。请记住，在使用结果做出商业决策时，可能需要特定的精度级别，并且如果样本数据可以支持这样的结果，应该提供该精度或粒度。
- en: 'Repeat *Step 1*, but with the `dfMore40` DataFrame:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*步骤1*，但使用`dfMore40` DataFrame：
- en: '[PRE21]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is as follows:'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.26: The x and y components of the grid representing the dfMore40
    dataset'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.26：表示dfMore40数据集的网格的x和y分量'
- en: '](img/C12626_09_26.jpg)'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12626_09_26.jpg)'
- en: 'Figure 9.26: The x and y components of the grid representing the dfMore40 dataset'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9.26：表示dfMore40数据集的网格的x和y分量
- en: 'Repeat *Step 2* using the grid established in *Step 4*:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*步骤4*中建立的网格，重复*步骤2*：
- en: '[PRE22]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Repeat *Step 3* using the estimated density computed in *Step 5*:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*步骤3*中估算的密度值，重复操作：
- en: '[PRE23]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output is as follows:'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.27: The estimated density of dfMore40 overlaid onto an outline of
    California'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.27：将dfMore40的估算密度叠加到加利福尼亚州的轮廓上'
- en: '](img/C12626_09_27.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12626_09_27.jpg)'
- en: 'Figure 9.27: The estimated density of dfMore40 overlaid onto an outline of
    California'
  id: totrans-251
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9.27：将dfMore40的估算密度叠加到加利福尼亚州的轮廓上
- en: This estimated density is again a redo of the one that we did in *Exercise 50*,
    *Loading Data and Modeling with Seaborn*. While the density from *Step 3* will
    provide more detail for a person interested in real estate or the census, this
    density does not actually look that different from its corollary density in *Exercise
    50*, *Loading Data and Modeling with Seaborn*. The clusters are primarily around
    Los Angeles and San Francisco with almost no points anywhere else.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这个估计密度是我们在*练习50*中重新做的那个，*使用Seaborn加载数据和建模*。虽然*第3步*中的密度会为对房地产或人口普查感兴趣的人提供更多细节，但这个密度实际上与*练习50*中的对应密度差别不大。聚类主要集中在洛杉矶和旧金山，几乎没有在其他地方出现数据点。
- en: 'Activity 22: Analyzing Crime in London'
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动22：伦敦犯罪分析
- en: In this activity, we will perform hotspot analysis with kernel density estimation
    on London crime data from [https://data.police.uk/data/](https://data.police.uk/data/).
    Due to the difficulties of working with map data, we will visualize the results
    of the analysis using `seaborn`. However, if you feel brave and were able to run
    all the plots in *Exercise 51*, *Working with Basemaps* you are encouraged to
    try using maps.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在此活动中，我们将对来自[https://data.police.uk/data/](https://data.police.uk/data/)的伦敦犯罪数据进行核密度估计的热点分析。由于处理地图数据的困难，我们将使用`seaborn`来可视化分析结果。不过，如果你觉得有信心并且能够运行*练习51*中的所有图表，*与底图一起工作*，那么鼓励你尝试使用地图。
- en: The motivation for performing hotspot analysis on this crime data is two-fold.
    We are asked first to determine where certain types of crimes are occurring in
    high likelihood, so that police resources can be allocated for maximum impact.
    Then, as a follow up, we are asked to ascertain whether the hotspots for certain
    types of crime are changing over time. Both of these questions are answerable
    using kernel density estimation.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 对这个犯罪数据进行热点分析的动机有两个方面。我们首先需要确定某些类型的犯罪在高概率区域发生的位置，以便能够最大化地分配警察资源。然后，作为后续分析，我们需要确定某些类型犯罪的热点是否随时间变化。这两个问题都可以通过核密度估计来回答。
- en: Note
  id: totrans-256
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意事项
- en: This dataset is downloaded from [https://data.police.uk/data/](https://data.police.uk/data/).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集是从[https://data.police.uk/data/](https://data.police.uk/data/)下载的。
- en: You can download it from the Packt GitHub at [https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-Python/tree/master/Lesson09/Activity21-Activity22](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-Python/tree/master/Lesson09/Activity21-Activity22).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从Packt GitHub下载，网址是[https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-Python/tree/master/Lesson09/Activity21-Activity22](https://github.com/TrainingByPackt/Applied-Unsupervised-Learning-with-Python/tree/master/Lesson09/Activity21-Activity22)。
- en: Alternatively, to download the data directly from the source, go to the preceding
    police website, check the box for **Metropolitan Police Service**, and then set
    the date range to **July 2018** to **Dec 2018**. Next, click **Generate file**
    followed by **Download now** and name the downloaded file **metro-jul18-dec18**.
    Make sure that you know how or can retrieve the path to the downloaded directory.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，为了直接从源下载数据，前往前面的警察网站，勾选**大都市警察局**，然后设置日期范围为**2018年7月**至**2018年12月**。接下来，点击**生成文件**，然后点击**立即下载**并将下载的文件命名为**metro-jul18-dec18**。确保你知道如何获取或能够找到下载目录的路径。
- en: This dataset contains public sector information licensed under the Open Government
    License v3.0.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集包含根据开放政府许可证 v3.0 许可的公共部门信息。
- en: 'Here are the steps to complete the activity:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是完成活动的步骤：
- en: Load the crime data. Use the path where you saved the downloaded directory,
    create a list of the year-month tags, use the `read_csv` command to load the individual
    files iteratively, and then concatenate these files together.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载犯罪数据。使用你保存下载目录的路径，创建年份-月份标签的列表，使用`read_csv`命令逐个加载文件，然后将这些文件合并在一起。
- en: Print diagnostics of the complete (six months) and concatenated dataset.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印完整（六个月）和合并数据集的诊断信息。
- en: Subset the DataFrame down to four variables (`Longitude`, `Latitude`, `Month`,
    and `Crime type`).
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据框架（DataFrame）缩小到四个变量（`经度`、`纬度`、`月份`和`犯罪类型`）。
- en: Using the `jointplot` function from `seaborn`, fit and visualize three kernel
    density estimation models for bicycle theft in July, September, and December 2018.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`seaborn`中的`jointplot`函数，为2018年7月、9月和12月的自行车盗窃数据拟合并可视化三个核密度估计模型。
- en: Repeat *Step 4*; this time, use shoplifting crimes for the months of August,
    October, and November 2018.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*第4步*；这次，使用2018年8月、10月和11月的商店盗窃犯罪数据。
- en: Repeat *Step 5*; this time, use burglary crimes for the months of July, October,
    and December 2018.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*第5步*；这次，使用2018年7月、10月和12月的入室盗窃犯罪数据。
- en: 'The output from the last part of *Step 6* will be as follows:'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*第6步* 的最后输出如下：'
- en: '![Figure 9.28: The estimated joint and marginal densities for burglaries in
    December 20 ](img/C12626_09_28.jpg)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.28：2018年12月入室盗窃的联合和边缘密度估计](img/C12626_09_28.jpg)'
- en: 'Figure 9.28: The estimated joint and marginal densities for burglaries in December
    2018'
  id: totrans-270
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9.28：2018年12月入室盗窃的联合和边缘密度估计
- en: To clarify one more time, the densities found in this activity should have been
    overlaid on maps so that we could see exactly what areas these densities cover.
    Attempting to overlay the results on maps on your own would be encouraged if you
    have the appropriate mapping platforms at your disposal. If not, you could go
    to the mapping services available online and use the longitude and latitude pairs
    to gain insight into the specific locations.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，本活动中找到的密度应该在地图上叠加显示，以便我们能够看到这些密度覆盖的具体区域。如果您有合适的地图平台，请尝试自行叠加结果在地图上显示。如果没有，您可以访问在线地图服务，并使用经度和纬度对来获取关于具体位置的洞察。
- en: Note
  id: totrans-272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 377.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可在第377页找到。
- en: Summary
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'Kernel density estimation is a classic statistical technique that is in the
    same family of techniques as the histogram. It allows the user to extrapolate
    out from sample data to make insights and predictions about the population of
    particular objects or events. This extrapolation comes in the form of a probability
    density function, which is nice because the results read as likelihoods or probabilities.
    The quality of this model is dependent on two parameters: the bandwidth value
    and the kernel function. As discussed, the most crucial component of leveraging
    kernel density estimation successfully is the setting of an optimal bandwidth.
    Optimal bandwidths are most frequently identified using grid search cross-validation
    with pseudo-log-likelihood as the scoring metric. What makes kernel density estimation
    great is both its simplicity and its applicability to so many fields.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 核密度估计是一种经典的统计技术，与直方图技术属于同一类。它允许用户从样本数据中推断出对特定对象或事件的人群进行洞察和预测。这种推断以概率密度函数的形式呈现，这非常好，因为结果可以解读为概率或可能性。这个模型的质量取决于两个参数：带宽值和核函数。正如讨论的那样，成功利用核密度估计的关键组成部分是设置一个最佳的带宽值。最常用的方法是使用网格搜索交叉验证，以伪对数似然作为评分指标来确定最佳带宽。核密度估计的优点在于其简单性和适用性广泛。
- en: It is routine to find kernel density estimation models in criminology, epidemiology,
    meteorology, and real estate to only name a few. Regardless of your area of business,
    kernel density estimation should be applicable.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在犯罪学、流行病学、气象学和房地产等多个领域中，经常可以找到核密度估计模型。无论您从事哪个领域的业务，核密度估计都应该适用。
- en: In this book, we explored the best practices for using unsupervised learning
    techniques in tandem with Python libraries and extracting meaningful information
    from unstructured data. Now you can confidently build your own models using Python.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们探讨了如何在Python库的支持下，使用无监督学习技术的最佳实践，并从非结构化数据中提取有意义的信息。现在，您可以自信地使用Python构建自己的模型。
