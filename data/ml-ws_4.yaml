- en: '4\. Supervised Learning Algorithms: Predicting Annual Income'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 监督学习算法：预测年收入
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we will take a look at three different supervised learning
    algorithms used for classification. We will also solve a supervised learning classification
    problem using these algorithms and perform error analysis by comparing the results
    of the three different algorithms.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究三种不同的用于分类的监督学习算法。我们还将使用这些算法解决一个监督学习分类问题，并通过比较三种不同算法的结果进行误差分析。
- en: By the end of this chapter, you will be able to identify the algorithm with
    the best performance.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章末尾，您将能够确定具有最佳性能的算法。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: In the previous chapter, we covered the key steps involved in working with a
    supervised learning data problem. Those steps aim to create high-performing algorithms,
    as explained in the previous chapter.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了处理监督学习数据问题涉及的关键步骤。这些步骤旨在创建高性能算法，正如前一章所解释的那样。
- en: This chapter focuses on applying different algorithms to a real-life dataset,
    with the underlying objective of applying the steps that we learned previously
    to choose the best-performing algorithm for the case study. Considering this,
    you will pre-process and analyze a dataset, and then create three models using
    different algorithms. These models will be compared to one another in order to
    measure their performance.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点介绍将不同算法应用于真实数据集的过程，其底层目标是应用我们之前学到的步骤，选择适用于案例研究的表现最佳算法。因此，您将预处理和分析数据集，然后使用不同的算法创建三个模型。将比较这些模型以衡量它们的性能。
- en: The Census Income dataset that we'll be using contains demographical and financial
    information, which can be used to try and predict the level of income of an individual.
    By creating a model capable of predicting this outcome for new observations, it
    will be possible to determine whether a person can be pre-approved to receive
    a loan.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的Census Income数据集包含个人的人口统计和财务信息，可以用于预测个人收入水平。通过创建能够预测这一结果的模型，可以确定一个人是否可以预先批准接收贷款。
- en: Exploring the Dataset
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据集
- en: Real-life applications are crucial for cementing knowledge. Therefore, this
    chapter consists of a real-life case study involving a classification task, where
    the key steps that you learned about in the previous chapter will be applied in
    order to select the best performing model.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 真实应用对于巩固知识至关重要。因此，本章包括一个涉及分类任务的真实案例研究，其中将应用您在前一章学到的关键步骤，以选择表现最佳的模型。
- en: To accomplish this, the Census Income dataset will be used, which is available
    at the UC Irvine Machine Learning Repository.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成这个任务，将使用Census Income数据集，该数据集可以在UC Irvine机器学习库中找到。
- en: Note
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The dataset that will be used in the following section, as well as in this chapter's
    activities, can be found in this book's GitHub repository at [https://packt.live/2xUGShx](https://packt.live/2xUGShx).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 将在以下部分以及本章的活动中使用的数据集，可以在本书的GitHub存储库中找到[https://packt.live/2xUGShx](https://packt.live/2xUGShx)。
- en: 'Citation: Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)].
    Irvine, CA: University of California, School of Information and Computer Science.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 引用：Dua, D. 和 Graff, C. (2019). UCI Machine Learning Repository [[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)]。Irvine,
    CA：加利福尼亚大学，信息与计算机科学学院。
- en: 'You can download the dataset from this book''s GitHub repository. Alternatively,
    to download the dataset from the original source, follow these steps:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从本书的GitHub存储库下载数据集。或者，要从原始来源下载数据集，请按照以下步骤操作：
- en: 'Visit the following link: [http://archive.ics.uci.edu/ml/datasets/Census+Income](http://archive.ics.uci.edu/ml/datasets/Census+Income).'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问以下链接：[http://archive.ics.uci.edu/ml/datasets/Census+Income](http://archive.ics.uci.edu/ml/datasets/Census+Income)。
- en: First, click the `Data Folder` link.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，点击`Data Folder`链接。
- en: For this chapter, the data available under `adult.data` will be used. Once you
    click this link, the download will be triggered. Save it as a `.csv` file.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章中，将使用`adult.data`可用的数据。点击此链接后，将触发下载。将其保存为`.csv`文件。
- en: Note
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Open the file and add header names over each column to make pre-processing easier.
    For instance, the first column should have the header `Age`, as per the features
    available in the dataset. These can be seen in the preceding link, under `Attribute
    Information`.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 打开文件并在每一列上添加列名，以便于预处理。例如，第一列应该有`Age`的列名，按照数据集中提供的特征。这些可以在前面的链接中看到，在`属性信息`下。
- en: Understanding the Dataset
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解数据集
- en: To build a model that fits the data accurately, it is important to understand
    the different details of the dataset, as mentioned in previous chapters.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建一个准确拟合数据的模型，理解数据集的不同细节是非常重要的，如前几章所述。
- en: 'First, the data that''s available is revised to understand the size of the
    dataset and the type of supervised learning task to be developed: classification
    or regression. Next, the purpose of the study should be clearly defined, even
    if it is obvious. For supervised learning, the purpose is closely linked to the
    class labels. Finally, each feature is analyzed so that we can be aware of their
    types for pre-processing purposes.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，评审可用数据以了解数据集的大小和要开发的监督学习任务类型：分类或回归。接下来，应明确界定研究的目的，即使它显而易见。对于监督学习，目的与类标签密切相关。最后，分析每个特征，以便我们了解其类型，便于预处理。
- en: The Census Income dataset is a collection of demographical data on adults, which
    is an extract from the 1994 Census Database from the United States. For this chapter,
    only the data available under the `adult.data` link will be used. The dataset
    consists of 32,561 instances, 14 features, and 1 binary class label. Considering
    that the class label is discrete, our task is to achieve the classification of
    the different observations.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Census Income数据集是一个关于成人的群体统计数据集，来自美国1994年人口普查数据库的提取数据。本章仅使用在`adult.data`链接下可用的数据。该数据集包含32,561个实例，14个特征和1个二进制类标签。考虑到类标签是离散的，我们的任务是实现不同观察值的分类。
- en: Note
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The following exploration of the dataset does not require coding of any sort,
    but rather a simple evaluation by opening the dataset in Excel or a similar program.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下对数据集的探索不需要任何编码，只需要通过在Excel或类似程序中打开数据集进行简单评估。
- en: Through a quick evaluation of the data, it is possible to observe that some
    features present missing values in the form of a question mark. This is common
    when dealing with datasets that are available online and should be handled by
    replacing the symbol with an empty value (not a space). Other common forms of
    missing values are the `NULL` value and a dash.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对数据的快速评估，可以观察到某些特征存在缺失值，表现为问号。这在处理在线可用数据集时很常见，应该通过将符号替换为空值（而不是空格）来处理。其他常见的缺失值形式包括`NULL`值和短横线。
- en: 'To edit missing value symbols in Excel, use the **Replace** functionality,
    as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Excel中编辑缺失值符号，请使用**替换**功能，如下所示：
- en: '`?`).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`?`）。'
- en: '**Replace with**: Leave it blank (do not enter a space).'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**替换为**：保持空白（不要输入空格）。'
- en: This way, once we import the dataset into the code, NumPy will be able to find
    the missing values so that it can handle them.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，一旦我们将数据集导入代码中，NumPy将能够找到缺失值并处理它们。
- en: The prediction task for this dataset involves determining whether a person earns
    over 50K dollars a year. According to this, the two possible outcome labels are
    `>50K` (greater than 50K) or `<=50K` (less than, or equal to 50K).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集的预测任务是确定一个人年收入是否超过50K美元。根据这一点，两个可能的结果标签是`>50K`（大于50K）或`<=50K`（小于或等于50K）。
- en: 'A brief explanation of each of the features in the dataset is shown in the
    following table:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中每个特征的简要解释如下表所示：
- en: '![Figure 4.1: Dataset feature analysis'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.1：数据集特征分析'
- en: '](img/B15781_04_01.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_04_01.jpg)'
- en: 'Figure 4.1: Dataset feature analysis'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1：数据集特征分析
- en: Note
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '*Publisher''s Note: Gender and race would have impacted the earning potential
    of an individual at the date this study was conducted. However, for the purpose
    of this chapter, we have decided to exclude these categories from our exercises
    and activities.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*出版商说明：性别和种族在本研究进行时会影响个人的收入潜力。然而，为了本章的目的，我们决定在练习和活动中排除这些类别。'
- en: We recognize that due to biases and discriminatory practices, it is impossible
    to separate issues such as gender, race, and educational and vocational opportunities.
    The removal of certain features from our dataset in the pre-processing stage of
    these exercises is not intended to ignore the issues, nor the valuable work undertaken
    by organizations and individuals working in the civil rights sphere.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认识到，由于偏见和歧视性做法，无法将性别、种族、教育和职业机会等问题完全分开。在这些练习的预处理阶段从数据集中删除某些特征，并非忽视这些问题，也不是忽视民权领域中组织和个人所做的有价值的工作。
- en: We strongly recommend that you consider the sociopolitical impacts of data and
    the way it is used, and also consider how past prejudices can be perpetuated by
    using historical data to introduce bias into new algorithms.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强烈建议你考虑数据及其使用方式的社会政治影响，并思考如何通过使用历史数据将过去的偏见传递到新的算法中。
- en: 'From the preceding table, it is possible to conclude the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从上表中，可以得出以下结论：
- en: 'Five features are not relevant to the study: `fnlwgt`, `education`, `relationship`,
    `race`, and `sex`. These features must be deleted from the dataset before we proceed
    with pre-processing and training the model.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有五个特征与研究无关：`fnlwgt`、`education`、`relationship`、`race` 和 `sex`。在进行预处理和模型训练之前，必须从数据集中删除这些特征。
- en: Out of the remaining features, four are presented as qualitative values. Considering
    that many algorithms do not take qualitative features into account, the values
    should be represented in numerical form.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剩余的特征中，有四个是定性值。考虑到许多算法不考虑定性特征，这些值应当以数字形式表示。
- en: 'Using the concepts that we learned about in the previous chapters, the preceding
    statements, as well as the pre-processing process for handling outliers and missing
    values, can be taken care of. The following steps explain the logic of this process:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 利用我们在前几章学到的概念，可以处理上述语句以及异常值和缺失值的预处理过程。以下步骤解释了这个过程的逻辑：
- en: You need to import the dataset and drop the features that are irrelevant to
    the study.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要导入数据集，并删除与研究无关的特征。
- en: You should check for missing values. Considering the feature with the most missing
    values (`occupation`, with 1,843 missing values), there will be no need to delete
    or replace the missing values as they represent only 5% or less of the entire
    dataset.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你应该检查是否存在缺失值。考虑到缺失值最多的特征（`occupation`，有1,843个缺失值），由于这些缺失值仅占整个数据集的5%或更少，因此不需要删除或替换它们。
- en: You must convert the qualitative values into their numeric representations.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你必须将定性值转换为其数值表示。
- en: You should check for outliers. Upon using three standard deviations to detect
    outliers, the feature with the maximum number of outliers is `capital-loss`, which
    contains 1,470 outliers. Again, the outliers represent less than 5% of the entire
    dataset, meaning they can be left untouched without impacting the result of the
    model.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你应该检查是否存在异常值。在使用三倍标准差法检测异常值时，具有最多异常值的特征是`capital-loss`，包含1,470个异常值。由于这些异常值占整个数据集的比例不到5%，因此它们可以不做处理，不会影响模型的结果。
- en: 'The preceding process will convert the original dataset into a new dataset
    with 32,561 instances (since no instances were deleted), but with 9 features and
    a class label. All values should be in their numerical forms. Save the pre-processed
    dataset into a file using pandas'' `to_csv` function, as per the following code
    snippet:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 上述过程将原始数据集转换为一个新数据集，包含32,561个实例（因为没有删除任何实例），但只有9个特征和一个类别标签。所有的值应该是数字形式。按照以下代码片段，使用pandas的`to_csv`函数将预处理后的数据集保存为文件：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The preceding code snippet takes the pre-processed data stored in a Pandas DataFrame
    and saves it into a CSV file.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码片段将处理过的数据存储在Pandas DataFrame中，并将其保存为CSV文件。
- en: Note
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Make sure that you perform the preceding pre-processing steps, as this is the
    dataset that will be used for training the models in the different activities
    of this chapter.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你执行了前述的预处理步骤，因为这是本章中将用于训练模型的数据集。
- en: To review these steps, visit the GitHub repository of this book, under the folder
    named `Chapter04`, in the file named `Census income dataset preprocessing`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要回顾这些步骤，请访问本书的GitHub仓库，在名为`Chapter04`的文件夹下，查看名为`Census income dataset preprocessing`的文件。
- en: The Naïve Bayes Algorithm
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朴素贝叶斯算法
- en: '**Naïve Bayes** is a classification algorithm based on **Bayes'' theorem**
    that *naïvely* assumes independence between features and assigns the same weight
    (degree of importance) to all features. This means that the algorithm assumes
    that no single feature correlates to or affects another. For example, although
    weight and height are somehow correlated when predicting a person''s age, the
    algorithm assumes that each feature is independent. Additionally, the algorithm
    considers all features equally important. For instance, even though an education
    degree may influence the earnings of a person to a greater degree than the number
    of children the person has, the algorithm still considers both features equally
    important.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**朴素贝叶斯**是一种基于**贝叶斯定理**的分类算法，它*天真地*假设特征之间是独立的，并且对所有特征赋予相同的权重（重要性程度）。这意味着该算法假设没有任何特征彼此相关或影响对方。例如，尽管在预测一个人的年龄时，体重和身高在某种程度上是相关的，但该算法仍假设每个特征是独立的。此外，算法将所有特征视为同等重要。例如，尽管教育程度可能比一个人孩子的数量更能影响其收入，算法仍然认为这两个特征同样重要。'
- en: Note
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Bayes'' theorem is a mathematical formula that calculates conditional probabilities.
    To learn more about this theorem, visit the following URL: [https://plato.stanford.edu/entries/bayes-theorem/](https://plato.stanford.edu/entries/bayes-theorem/).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理是一种计算条件概率的数学公式。欲了解更多关于该定理的信息，请访问以下网址：[https://plato.stanford.edu/entries/bayes-theorem/](https://plato.stanford.edu/entries/bayes-theorem/)。
- en: Although real-life datasets contain features that are not equally important,
    nor independent, this algorithm is popular among scientists as it performs surprisingly
    well on large datasets. Also, due to the simplistic approach of the algorithm,
    it runs quickly, thus allowing it to be applied to problems that require predictions
    in real-time. Moreover, it is frequently used for text classification as it commonly
    outperforms more complex algorithms.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管现实生活中的数据集包含了不等重要且相互之间不独立的特征，朴素贝叶斯算法在科学家中依然广受欢迎，因为它在大型数据集上表现得出奇的好。而且，由于算法的简易性，它运行速度快，因此可以应用于需要实时预测的问题。此外，它在文本分类中也得到了广泛使用，因为它常常超越了更复杂的算法。
- en: How Does the Naïve Bayes Algorithm Work?
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 朴素贝叶斯算法是如何工作的？
- en: The algorithm converts the input data into a summary of occurrences of each
    class label against each feature, which is then used to calculate the likelihood
    of one event (a class label), given a combination of features. Finally, this likelihood
    is normalized against the likelihood of the other class labels. The result is
    the probability of an instance belonging to each class label. The sum of the probabilities
    must be one, and the class label with a higher probability is the one that the
    algorithm chooses as the prediction.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 算法将输入数据转化为每个类标签与每个特征的发生情况总结，然后利用这些信息计算在给定一组特征组合的情况下，某一事件（类标签）发生的可能性。最后，该可能性会与其他类标签的可能性进行归一化处理。结果是一个实例属于每个类标签的概率。所有概率的总和必须为1，具有较高概率的类标签是算法作为预测结果选择的标签。
- en: 'Let''s take, for example, the data presented in the following tables:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举个例子，来看一下下面表格中的数据：
- en: '![Figure 4.2: Table A - Input data and Table B - Occurrence count](img/B15781_04_02.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图4.2：表A - 输入数据，表B - 发生次数](img/B15781_04_02.jpg)'
- en: 'Figure 4.2: Table A - Input data and Table B - Occurrence count'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2：表A - 输入数据，表B - 发生次数
- en: Table A represents the data that is fed to the algorithm to build the model.
    Table B refer to the occurrence count that the algorithm uses implicitly to calculate
    the probabilities.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 表A表示输入到算法中的数据，用于构建模型。表B则指的是算法隐式使用的事件发生次数，用于计算概率。
- en: 'To calculate the likelihood of an event occurring when given a set of features,
    the algorithm multiplies the probability of the event occurring, given each individual
    feature, by the probability of the occurrence of the event, independent of the
    rest of the features, as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算在给定一组特征的情况下，事件发生的可能性，算法会将每个特征下事件发生的概率与该事件的总发生概率相乘，计算公式如下：
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, *A*1 refers to an event (one of the class labels) and *E* represents the
    set of features, where *E*1 is the first feature and *E*n is the last feature
    in the dataset.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*A*1代表一个事件（类标签之一），*E*表示特征集，其中 *E*1 是第一个特征，*E*n 是数据集中的最后一个特征。
- en: Note
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The multiplication of these probabilities can only be made by assuming independence
    between features.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这些概率的相乘只能通过假设特征之间是独立的来进行。
- en: 'The preceding equation is calculated for all possible outcomes (all class labels),
    and then the normalized probability of each outcome is calculated as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的公式是针对所有可能的结果（所有类别标签）进行计算的，然后标准化每个结果的概率，计算公式如下：
- en: '![Figure 4.3: Formula to calculate normalized probability'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.3：计算标准化概率的公式'
- en: '](img/B15781_04_03.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_04_03.jpg)'
- en: 'Figure 4.3: Formula to calculate normalized probability'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3：计算标准化概率的公式
- en: 'For the example in *Figure 4.2*, given a new instance with weather equal to
    *sunny* and temperature equal to *cool*, the calculation of probabilities is as
    follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*图4.2*中的例子，给定一个新的实例，其中天气为*晴朗*，温度为*凉爽*，概率的计算如下：
- en: '![Figure 4.4: Calculation of the likelihood and probabilities for the example
    dataset'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.4：示例数据集的似然性和概率计算'
- en: '](img/B15781_04_04.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_04_04.jpg)'
- en: 'Figure 4.4: Calculation of the likelihood and probabilities for the example
    dataset'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4：示例数据集的似然性和概率计算
- en: By looking at the preceding equations, it is possible to conclude that the prediction
    should be *yes*.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看前面的公式，可以得出结论，预测结果应该是*yes*。
- en: It is important to mention that for continuous features, the summary of occurrences
    is done by creating ranges. For instance, for a feature of price, the algorithm
    may count the number of instances with prices below 100K, as well as the instances
    with prices above 100K.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 需要提到的是，对于连续特征，发生情况的汇总是通过创建范围来进行的。例如，对于一个价格特征，算法可能会统计价格低于100K的实例数量，以及价格高于100K的实例数量。
- en: Moreover, the algorithm may encounter some issues if one value of a feature
    is never associated with one of the outcomes. This is an issue mainly because
    the probability of the outcome given that feature will be zero, which influences
    the entire calculation. In the preceding example, for predicting the outcome of
    an instance with weather equal to *mild* and temperature equal to *cool*, the
    probability of *no*, given the set of features will be equal to zero, considering
    that the probability of *no*, given *mild* weather, computes to zero, since there
    are no occurrences of *mild* weather when the outcome is *no*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果某个特征的某个值从未与某个结果相关联，算法可能会遇到一些问题。这是一个主要问题，因为给定该特征时，结果的概率将为零，这会影响整个计算。在前面的例子中，对于预测一个实例，其中天气为*温和*，温度为*凉爽*，给定特征集的*no*概率将等于零，因为给定*温和*天气时，*no*的概率为零，因为没有*温和*天气对应*no*结果。
- en: To avoid this, the **Laplace estimator** technique should be used. Here, the
    fractions representing the probability of the occurrence of an event given a feature,
    *P[A|E*1*]*, are modified by adding 1 to the numerator while also adding the number
    of possible values of that feature to the denominator.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种情况，应使用**拉普拉斯估计器**技术。在这里，表示给定特征下事件发生概率的分数，*P[A|E*1*]*，通过在分子上加1，同时在分母上加上该特征的可能值的数量来进行修改。
- en: 'For this example, to perform a prediction for a new instance with weather equal
    to *mild* and temperature equal to *cool* using the Laplace estimator, this would
    be done as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，使用拉普拉斯估计器来预测天气为*温和*、温度为*凉爽*的新实例的预测结果，可以按如下方式进行：
- en: '![Figure 4.5: Calculation of the likelihood and probability using the Laplace
    estimator for the example dataset'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.5：使用拉普拉斯估计器计算示例数据集的似然性和概率'
- en: '](img/B15781_04_05.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_04_05.jpg)'
- en: 'Figure 4.5: Calculation of the likelihood and probability using the Laplace
    estimator for the example dataset'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5：使用拉普拉斯估计器计算示例数据集的似然性和概率
- en: Here, the fraction that calculates the occurrences of *yes*, given *mild* weather,
    goes from 2/7 to 3/10, as a result of the addition of 1 to the numerator and 3
    (for *sunny*, *mild*, and *rainy*) to the denominator. The same goes for the other
    fractions that calculate the probability of the event, given a feature. Note that
    the fraction that calculates the probability of the event occurring independently
    of any feature is left unaltered.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，计算在*温和*天气下出现*yes*的分数，从2/7变为3/10，这是由于在分子上加了1，在分母上加了3（对应*晴朗*、*温和*和*雨天*）。其他计算事件发生概率的分数也有相同的变化，前提是给定某一特征。请注意，计算事件独立于任何特征发生的概率的分数没有改变。
- en: Nevertheless, as you have learned so far, the scikit-learn library allows you
    to train models and then use them for predictions, without needing to hardcode
    the math.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如你到目前为止所学到的，scikit-learn库允许你训练模型，然后使用它们进行预测，而无需手动编写数学公式。
- en: 'Exercise 4.01: Applying the Naïve Bayes Algorithm'
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习4.01：应用朴素贝叶斯算法
- en: 'Now, let''s apply the Naïve Bayes algorithm to a Fertility dataset, which aims
    to determine whether the fertility level of an individual has been affected by
    their demographics, their environmental conditions, and their previous medical
    conditions. Follow these steps to complete this exercise:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将朴素贝叶斯算法应用于Fertility数据集，该数据集旨在判断个体的生育能力是否受到其人口统计特征、环境条件和过去的医疗状况的影响。按照以下步骤完成此练习：
- en: Note
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For the exercises and activities within this chapter, you will need to have
    Python 3.7, NumPy, Jupyter, Pandas, and scikit-learn installed on your system.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章中的练习和活动，你需要在系统中安装Python 3.7、NumPy、Jupyter、Pandas和scikit-learn。
- en: Download the Fertility dataset from [http://archive.ics.uci.edu/ml/datasets/Fertility](http://archive.ics.uci.edu/ml/datasets/Fertility).
    Go to the link and click on `Data Folder`. Click on `fertility_Diagnosis.txt`,
    which will trigger the download. Save it as a `.csv` file.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[Fertility数据集](http://archive.ics.uci.edu/ml/datasets/Fertility)下载数据。进入链接并点击`Data
    Folder`。点击`fertility_Diagnosis.txt`，这将触发下载。将其保存为`.csv`文件。
- en: Note
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The dataset is also available in this book's GitHub repository at [https://packt.live/39SsSSN](https://packt.live/39SsSSN).
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该数据集也可以在本书的GitHub仓库中找到：[https://packt.live/39SsSSN](https://packt.live/39SsSSN)。
- en: 'It was downloaded from the UC Irvine Machine Learning Repository: David Gil,
    Jose Luis Girela, Joaquin De Juan, M. Jose Gomez-Torres, and Magnus Johnsson.
    *Predicting seminal quality with artificial intelligence methods*. Expert Systems
    with Applications.'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集来自UC Irvine机器学习库：David Gil, Jose Luis Girela, Joaquin De Juan, M. Jose Gomez-Torres和Magnus
    Johnsson。*使用人工智能方法预测精液质量*。《专家系统应用》期刊。
- en: 'Open a Jupyter Notebook to implement this exercise. Import pandas, as well
    as the `GaussianNB` class from scikit-learn''s `naive_bayes` module:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter Notebook来实现这个练习。导入pandas，并从scikit-learn的`naive_bayes`模块导入`GaussianNB`类：
- en: '[PRE2]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Read the `.csv` file that you downloaded in the first step. Make sure that
    you add the `header` argument equal to `None` to the `read_csv` function, considering
    that the dataset does not contain a header row:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阅读你在第一步下载的`.csv`文件。确保在`read_csv`函数中添加`header`参数，并将其设置为`None`，因为该数据集不包含标题行：
- en: '[PRE3]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Split the data into `X` and `Y`, considering that the class label is found
    under the column with an index equal to 9\. Use the following code to do so:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据拆分为`X`和`Y`，因为类标签位于索引为9的列下。使用以下代码来完成此操作：
- en: '[PRE4]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Instantiate the `GaussianNB` class that we imported previously. Next, use the
    `fit` method to train the model using `X` and `Y`:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化我们之前导入的`GaussianNB`类。接下来，使用`fit`方法，使用`X`和`Y`训练模型：
- en: '[PRE5]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output from running this script is as follows:'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行此脚本的输出如下：
- en: '[PRE6]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This states that the instantiation of the class was successful. The information
    inside the parentheses represents the values used for the arguments that the class
    accepts, which are the hyperparameters.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这表示类的实例化成功。括号内的信息代表用于参数的值，这些值是类接受的超参数。
- en: For instance, for the `GaussianNB` class, it is possible to set the prior probabilities
    to consider for each class label and a smoothing argument that stabilizes variance.
    Nonetheless, the model was initialized without setting any arguments, which means
    that it will use the default values for each argument, which is `None` for the
    case of `priors` and `1e-09` for the smoothing hyperparameter.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，对于`GaussianNB`类，可以设置每个类别标签的先验概率，并设置一个平滑参数来稳定方差。然而，该模型在初始化时没有设置任何参数，这意味着它将使用每个参数的默认值，对于`priors`是`None`，对于平滑超参数是`1e-09`。
- en: 'Finally, perform a prediction using the model that you trained before, for
    a new instance with the following values for each feature: `−0.33`, `0.69`, `0`,
    `1`, `1`, `0`, `0.8`, `0`, `0.88`. Use the following code to do so:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用你之前训练的模型对一个新的实例进行预测，给定每个特征的以下值：`−0.33`，`0.69`，`0`，`1`，`1`，`0`，`0.8`，`0`，`0.88`。使用以下代码来进行预测：
- en: '[PRE7]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that we feed the values inside of double square brackets, considering that
    the `predict` function takes in the values for prediction as an array of arrays,
    where the first set of arrays corresponds to the list of new instances to predict
    and the second array refers to the list of features for each instance.
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，我们将值放入双重方括号中，因为`predict`函数将预测值作为数组的数组输入，其中第一组数组对应于要预测的新实例列表，第二个数组表示每个实例的特征列表。
- en: 'The output from the preceding code snippet is as follows:'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码片段的输出如下：
- en: '[PRE8]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The predicted class for that subject is equal to `N`, which means that the fertility
    of the subject has not been affected.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对该对象的预测类别为 `N`，这意味着该对象的生育能力没有受到影响。
- en: Note
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Y2wW0c](https://packt.live/2Y2wW0c).
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 若要访问此特定部分的源代码，请参阅 [https://packt.live/2Y2wW0c](https://packt.live/2Y2wW0c)。
- en: You can also run this example online at [https://packt.live/3e40LTt](https://packt.live/3e40LTt).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在 [https://packt.live/3e40LTt](https://packt.live/3e40LTt) 上在线运行这个示例。你必须执行整个
    Notebook 才能获得期望的结果。
- en: You have successfully trained a Naïve Bayes model and performed prediction on
    a new observation.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功训练了一个 Naïve Bayes 模型，并对新观测值进行了预测。
- en: 'Activity 4.01: Training a Naïve Bayes Model for Our Census Income Dataset'
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 4.01：为我们的 Census Income 数据集训练 Naïve Bayes 模型
- en: 'To test different classification algorithms on a real-life dataset, consider
    the following scenario: you work for a bank, and they have decided to implement
    a model that is able to predict a person''s annual income and use that information
    to decide whether to approve a loan. You are given a dataset with 32,561 suitable
    observations, which you have already pre-processed. Your job is to train three
    different models on the dataset and determine which one best suits the case study.
    The first model to be built is a Gaussian Naïve Bayes model. Use the following
    steps to complete this activity:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在真实数据集上测试不同的分类算法，考虑以下场景：你为一家银行工作，他们决定实现一个能够预测个人年收入的模型，并根据此信息决定是否批准贷款。你得到一个包含
    32,561 个合适观测值的数据集，数据集已经过预处理。你的任务是训练三个不同的模型，并确定哪个最适合此案例研究。第一个模型是构建一个高斯 Naïve Bayes
    模型。使用以下步骤完成这个活动：
- en: In a Jupyter Notebook, import all the required elements to load and split the
    dataset, as well as to train a Naïve Bayes algorithm.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Jupyter Notebook 中，导入所有需要的元素来加载和拆分数据集，以及训练 Naïve Bayes 算法。
- en: Load the pre-processed Census Income dataset. Next, separate the features from
    the target by creating two variables, `X` and `Y`.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载预处理后的 Census Income 数据集。接下来，通过创建两个变量 `X` 和 `Y`，将特征与目标变量分开。
- en: Note
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The pre-processed Census Income dataset can be found in this book's GitHub repository
    at [https://packt.live/2JMhsFB](https://packt.live/2JMhsFB). It consists of the
    transformed Census Income dataset that was pre-processed at the beginning of this
    chapter.
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预处理后的 Census Income 数据集可以在本书的 GitHub 仓库中找到，地址是 [https://packt.live/2JMhsFB](https://packt.live/2JMhsFB)。它包含了本章开始时预处理过的
    Census Income 数据集。
- en: Divide the dataset into training, validation, and testing sets, using a split
    ratio of 10%.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集划分为训练集、验证集和测试集，使用 10% 的拆分比例。
- en: Note
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: When all three sets are created from the same dataset, it is not required to
    create an additional train/dev set to measure data mismatch. Moreover, note that
    it is OK to try a different split ratio, considering that the percentages explained
    in the previous chapter are not set in stone. Even though they tend to work well,
    it is important that you embrace experimentation at different levels when building
    machine learning models.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当所有三个数据集都是从同一个数据集中创建时，就不需要额外创建训练/验证集来测量数据不匹配的情况。此外，值得注意的是，可以尝试不同的拆分比例，因为前一章解释的百分比并不是固定不变的。尽管这些比例通常有效，但在构建机器学习模型时，重要的是要接受在不同层次上进行实验。
- en: Use the `fit` method to train a Naïve Bayes model on the training sets (`X_train`
    and `Y_train`).
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `fit` 方法在训练集（`X_train` 和 `Y_train`）上训练 Naïve Bayes 模型。
- en: 'Finally, perform a prediction using the model that you trained previously,
    for a new instance with the following values for each feature: `39`, `6`, `13`,
    `4`, `0`, `2174`, `0`, `40`, `38`.'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用你之前训练的模型对具有以下每个特征值的新实例进行预测：`39`，`6`，`13`，`4`，`0`，`2174`，`0`，`40`，`38`。
- en: The prediction for the individual should be equal to zero, meaning that the
    individual most likely has an income less than or equal to 50K.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于该个体的预测结果应该为零，意味着该个体的收入可能小于或等于 50K。
- en: Note
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Use the same Jupyter Notebook for all the activities within this chapter so
    that you can perform a comparison of different models on the same dataset.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在本章的所有活动中使用相同的 Jupyter Notebook，这样你就可以在相同的数据集上比较不同模型的表现。
- en: The solution for this activity can be found on page 236.
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以在第236页找到。
- en: The Decision Tree Algorithm
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树算法
- en: The **decision tree algorithm** performs classification based on a sequence
    that resembles a tree-like structure. It works by dividing the dataset into small
    subsets that serve as guides to develop the decision tree nodes. The nodes can
    be either decision nodes or leaf nodes, where the former represent a question
    or decision, and the latter represent the decisions made or the final outcome.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**决策树算法**通过一个类似树形结构的序列进行分类。它通过将数据集划分为小的子集来工作，这些子集作为指导来开发决策树节点。这些节点可以是决策节点或叶节点，其中前者代表一个问题或决策，后者代表做出的决策或最终结果。'
- en: How Does the Decision Tree Algorithm Work?
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 决策树算法如何工作？
- en: Considering what we just mentioned, decision trees continually split the dataset
    according to the parameters defined in the decision nodes. Decision nodes have
    branches coming out of them, where each decision node can have two or more branches.
    The branches represent the different possible answers that define the way in which
    the data is split.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到我们刚才提到的内容，决策树不断根据决策节点中定义的参数来划分数据集。决策节点有分支从其发出，每个决策节点可以有两个或更多的分支。这些分支代表不同的可能答案，定义了数据如何被划分。
- en: 'For instance, consider the following table, which shows whether a person has
    a pending student loan based on their age, highest education, and current income:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下表格，它展示了一个人是否有未结学生贷款，基于他们的年龄、最高教育水平和当前收入：
- en: '![Figure 4.6: Dataset for student loans'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.6：学生贷款数据集'
- en: '](img/B15781_04_06.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_04_06.jpg)'
- en: 'Figure 4.6: Dataset for student loans'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6：学生贷款数据集
- en: 'One possible configuration for a decision tree built based on the preceding
    data is shown in the following diagram, where the light boxes represent the decision
    nodes, the arrows are the branches representing each answer to the decision node,
    and the dark boxes refer to the outcome for instances that follow the sequence:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 基于前述数据构建的决策树的一种可能配置如下图所示，其中浅色框表示决策节点，箭头是代表每个决策节点答案的分支，深色框表示按照序列进行的实例的结果：
- en: '![Figure 4.7: Data represented in a decision tree'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.7：决策树中表示的数据'
- en: '](img/B15781_04_07.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_04_07.jpg)'
- en: 'Figure 4.7: Data represented in a decision tree'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7：决策树中表示的数据
- en: To perform the prediction, once the decision tree has been built, the model
    takes each instance and follows the sequence that matches the instance's features
    until it reaches a leaf, that is, the outcome. According to this, the classification
    process starts at the root node (the one on top) and continues along the branch
    that describes the instance. This process continues until a leaf node is reached,
    which represents the prediction for that instance.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行预测，在构建决策树之后，模型会逐个实例地跟随与该实例特征匹配的序列，直到到达一个叶节点，即结果。根据这一点，分类过程从根节点（最上面那个）开始，沿着描述该实例的分支进行。该过程一直持续，直到到达叶节点，表示该实例的预测结果。
- en: For instance, a person *over 40 years old* with an income *below $150,000* and
    an education level of *bachelor* is likely to not have a student loan; hence,
    the class label assigned to it would be *No*.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个*40岁以上*、收入*低于$150,000*、教育水平为*学士*的人可能没有学生贷款；因此，分配给该类的标签为*否*。
- en: Decision trees can handle both quantitative and qualitative features, considering
    that continuous features will be handled in ranges. Additionally, leaf nodes can
    handle categorical or continuous class labels; for categorical class labels, a
    classification is made, while for continuous class labels, the task to be handled
    is regression.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树可以处理定量和定性特征，考虑到连续特征会以区间的形式处理。此外，叶节点可以处理分类的或连续的类标签；对于分类类标签，进行分类；而对于连续类标签，要处理的任务是回归。
- en: 'Exercise 4.02: Applying the Decision Tree Algorithm'
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.02：应用决策树算法
- en: 'In this exercise, we will apply the decision tree algorithm to the Fertility
    Dataset, with the objective of determining whether the fertility level of an individual
    is affected by their demographics, their environmental conditions, and their previous
    medical conditions. Follow these steps to complete this exercise:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将应用决策树算法到生育数据集，目的是确定个体的生育水平是否受到其人口统计信息、环境条件和以往健康状况的影响。按照以下步骤完成此练习：
- en: 'Open a Jupyter Notebook to implement this exercise and import `pandas`, as
    well as the `DecisionTreeClassifier` class from scikit-learn''s `tree` module:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter Notebook来实现这个练习，并导入`pandas`，以及从scikit-learn的`tree`模块中导入`DecisionTreeClassifier`类：
- en: '[PRE9]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Load the `fertility_Diagnosis` dataset that you downloaded in *Exercise 4.01*,
    *Applying the Naïve Bayes Algorithm*. Make sure that you add the `header` argument
    equal to `None` to the `read_csv` function, considering that the dataset does
    not contain a header row:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载你在*练习 4.01*中下载的`fertility_Diagnosis`数据集，*应用朴素贝叶斯算法*。确保在`read_csv`函数中添加`header`参数并设置为`None`，因为数据集没有包含标题行：
- en: '[PRE10]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Split the data into `X` and `Y`, considering that the class label is found
    under the column with the index equal to `9`. Use the following code:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据拆分为`X`和`Y`，因为类别标签位于索引为`9`的列下。使用以下代码：
- en: '[PRE11]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Instantiate the `DecisionTreeClassifier` class. Next, use the `fit` function
    to train the model using `X` and `Y`:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化`DecisionTreeClassifier`类。接下来，使用`fit`函数训练模型，使用`X`和`Y`：
- en: '[PRE12]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Again, the output from running the preceding code snippet will appear. This
    output summarizes the conditions that define your model by printing the values
    that are used for every hyperparameter that the model uses, as follows:'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 再次运行前面的代码片段，输出结果将会显示。这个输出总结了定义模型的条件，通过打印出模型使用的每个超参数的值，如下所示：
- en: '[PRE13]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Since the model has been instantiated without setting any hyperparameters, the
    summary will show the default values that were used for each.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于模型在没有设置任何超参数的情况下被实例化，因此总结将显示每个超参数使用的默认值。
- en: 'Finally, perform a prediction by using the model that you trained before, for
    the same instances that we used in *Exercise 4.01*, *Applying the Naïve Bayes
    Algorithm*: `−0.33`, `0.69`, `0`, `1`, `1`, `0`, `0.8`, `0`, `0.88`.'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用你之前训练的模型对相同的实例进行预测，这些实例在*练习 4.01*中也使用过，*应用朴素贝叶斯算法*：`−0.33`，`0.69`，`0`，`1`，`1`，`0`，`0.8`，`0`，`0.88`。
- en: 'Use the following code to do so:'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用以下代码来实现：
- en: '[PRE14]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output from the prediction is as follows:'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预测的输出结果如下：
- en: '[PRE15]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Again, the model predicted that the fertility of the subject has not been affected.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 再次，模型预测显示受试者的生育能力没有受到影响。
- en: Note
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3hDlvns](https://packt.live/3hDlvns).
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/3hDlvns](https://packt.live/3hDlvns)。
- en: You can also run this example online at [https://packt.live/3fsVw07](https://packt.live/3fsVw07).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你还可以在线运行这个示例，网址为[https://packt.live/3fsVw07](https://packt.live/3fsVw07)。你必须执行整个Notebook才能获得预期的结果。
- en: You have successfully trained a decision tree model and performed a prediction
    on new data.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功训练了一个决策树模型，并对新数据进行了预测。
- en: 'Activity 4.02: Training a Decision Tree Model for Our Census Income Dataset'
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 4.02：为我们的普查收入数据集训练决策树模型
- en: 'You continue to work on building a model that''s able to predict a person''s
    annual income. Using the pre-processed Census Income dataset, you have chosen
    to build a decision tree model:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 你继续构建一个能够预测个人年收入的模型。使用预处理过的普查收入数据集，你选择了构建一个决策树模型：
- en: Open the Jupyter Notebook that you used for the previous activity and import
    the decision tree algorithm from scikit-learn.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开你在之前活动中使用的Jupyter Notebook，并从scikit-learn中导入决策树算法。
- en: Train the model using the `fit` method on the `DecisionTreeClassifier` class
    from scikit-learn. To train the model, use the training set data from the previous
    activity (`X_train` and `Y_train`).
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用来自scikit-learn的`DecisionTreeClassifier`类的`fit`方法训练模型。使用来自前一个活动的训练集数据（`X_train`和`Y_train`）来训练模型。
- en: 'Finally, perform a prediction by using the model that you trained for a new
    instance with the following values for each feature: `39`, `6`, `13`, `4`, `0`,
    `2174`, `0`, `40`, `38`.'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用你训练的模型对一个新的实例进行预测，该实例的每个特征值如下：`39`，`6`，`13`，`4`，`0`，`2174`，`0`，`40`，`38`。
- en: The prediction for the individual should be equal to zero, meaning that the
    individual most likely has an income less than or equal to 50K.
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于该个体的预测应该为零，意味着该个体的收入可能小于或等于50K。
- en: Note
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 237.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以在第237页找到。
- en: The Support Vector Machine Algorithm
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量机算法
- en: The **Support Vector Machine** (**SVM**) algorithm is a classifier that finds
    the hyperplane that effectively separates the observations into their class labels.
    It starts by positioning each instance into a data space with *n* dimensions,
    where *n* represents the number of features. Next, it traces an imaginary line
    that clearly separates the instances belonging to a class label from the instances
    belonging to others.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVM**）算法是一种分类器，它找到一个有效地将观察值分隔到各自类别标签的超平面。算法首先将每个实例放入具有*n*维度的数据空间，其中*n*表示特征的数量。接着，它会画出一条虚拟的直线，这条线清楚地将属于同一类别标签的实例与属于其他类别标签的实例分开。'
- en: A support vector refers to the coordinates of a given instance. According to
    this, the support vector machine is the boundary that effectively segregates the
    different support vectors in a data space.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量指的是给定实例的坐标。根据这一点，支持向量机是有效地在数据空间中将不同支持向量分开的边界。
- en: For a two-dimensional data space, the hyperplane is a line that splits the data
    space into two sections, each one representing a class label.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二维数据空间，超平面是将数据空间分为两个部分的直线，每部分代表一个类别标签。
- en: How Does the SVM Algorithm Work?
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SVM算法是如何工作的？
- en: The following diagram shows a simple example of an SVM model. Both the triangles
    and circular data points represent the instances from the input dataset, where
    the shapes define the class label that each instance belongs to. The dashed line
    signifies the hyperplane that clearly segregates the data points, which is defined
    based on the data points' location in the data space. This line is used to classify
    unseen data, as represented by the square. This way, new instances that are located
    to the left of the line will be classified as triangles, while the ones to the
    right will be circles.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了一个简单的SVM模型示例。三角形和圆形的数据点代表输入数据集中的实例，其中形状定义了每个实例所属的类别标签。虚线表示超平面，清晰地分隔了数据点，这个超平面是基于数据点在数据空间中的位置来定义的。此线用于分类未见过的数据，正如图中的方块所示。通过这种方式，位于该线左侧的新实例将被分类为三角形，而位于右侧的实例将被分类为圆形。
- en: 'The larger the number of features, the more dimensions the data space will
    have, which will make visually representing the model impossible:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 特征数量越多，数据空间的维度就越多，这将使得模型的可视化变得不可能：
- en: '![Figure 4.8: Graphical example of an SVM model'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.8: SVM模型的图示例'
- en: '](img/B15781_04_08.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_04_08.jpg)'
- en: 'Figure 4.8: Graphical example of an SVM model'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4.8: SVM模型的图示例'
- en: Although the algorithm seems to be quite simple, its complexity is evident in
    the algorithm's methodology for drawing the appropriate hyperplane. This is because
    the model generalizes to hundreds of observations with multiple features.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管该算法看似非常简单，但其复杂性体现在算法绘制适当超平面的方式上。这是因为该模型可以概括成数百个具有多个特征的观察数据。
- en: 'To choose the right hyperplane, the algorithm follows the following rules,
    wherein *Rule 1* is more important than *Rule 2*:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择正确的超平面，算法遵循以下规则，其中*规则 1*比*规则 2*更为重要：
- en: '**Rule 1**: The hyperplane must maximize the correct classification of instances.
    This basically means that the best line is the one that effectively separates
    data points belonging to different class labels while keeping those that belong
    to the same one together.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规则 1**：超平面必须最大化实例的正确分类。这基本上意味着，最佳的直线是那条能够有效地将不同类别标签的数据点分开，同时将属于同一类别的数据点保持在一起的直线。'
- en: 'For instance, in the following diagram, although both lines are able to separate
    most instances into their correct class labels, line A would be selected by the
    model as the one that segregates the classes better than line B, which fails to
    classify two data points:'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，在下图中，尽管两条直线都能够将大多数实例分入正确的类别标签，但线A会被模型选为比线B更好地分隔类别的超平面，后者未能正确分类两个数据点：
- en: '![Figure 4.9: Sample of hyperplanes that explain Rule 1'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.9: 解释规则 1 的超平面示例'
- en: '](img/B15781_04_09.jpg)'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_04_09.jpg)'
- en: 'Figure 4.9: Sample of hyperplanes that explain Rule 1'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4.9: 解释规则 1 的超平面示例'
- en: '**Rule 2**: The hyperplane must maximize its distance to the nearest data point
    of either of the class labels, which is also known as the **margin**. This rule
    helps the model become more robust, which means that the model is able to generalize
    the input data so that it works efficiently on unseen data. This rule is especially
    important in preventing new instances from being mislabeled.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规则 2**：超平面必须最大化其到任一类别标签最近数据点的距离，这也被称为**间隔**。该规则有助于使模型更加健壮，这意味着模型能够对输入数据进行泛化，从而能够高效处理未见过的数据。此规则在防止新实例被错误标记时尤为重要。'
- en: 'For example, by looking at the following diagram, it is possible to conclude
    that both hyperplanes comply with *Rule 1*. Nevertheless, line A is selected,
    since it maximizes its distance to the nearest data points for both classes in
    comparison to the distance of line B to its nearest data point:'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，通过查看下图，可以得出结论，两个超平面都符合*规则 1*。然而，选择了 A 线，因为它最大化了与两个类别最近数据点的距离，相比之下，B 线与其最近数据点的距离较小：
- en: '![Figure 4.10: Sample of hyperplanes that explain Rule 2'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.10：解释规则 2 的超平面示例'
- en: '](img/B15781_04_10.jpg)'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_04_10.jpg)'
- en: 'Figure 4.10: Sample of hyperplanes that explain Rule 2'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10：解释规则 2 的超平面示例
- en: 'By default, the SVM algorithm uses a linear function to split the data points
    of the input data. However, this configuration can be modified by changing the
    kernel type of the algorithm. For example, consider the following diagram:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，SVM 算法使用线性函数来分隔输入数据的点。然而，可以通过更改算法的核类型来修改此配置。例如，考虑以下图示：
- en: Note
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'For scikit-learn''s SVM algorithm, the kernel refers to the mathematical function
    to be used to split the data points, which can be linear, polynomial, or sigmoidal,
    among others. To learn more about the parameters for this algorithm, visit the
    following URL: [https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC).'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 scikit-learn 的 SVM 算法，核指的是用于分隔数据点的数学函数，可以是线性的、多项式的或 sigmoid 函数等。要了解更多关于该算法的参数，可以访问以下网址：[https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)。
- en: '![Figure 4.11: Sample observations'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.11：示例观测值'
- en: '](img/B15781_04_11.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_04_11.jpg)'
- en: 'Figure 4.11: Sample observations'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11：示例观测值
- en: To segregate these observations, the model would have to draw a circle or another
    similar shape. The algorithm handles this by using kernels (mathematical functions)
    that can introduce additional features to the dataset in order to modify the distribution
    of data points into a form that allows a line to segregate them. There are several
    kernels available for this, and the selection of one should be done by trial and
    error so that you can find the one that best classifies the data that's available.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将这些观测值分隔开，模型必须绘制一个圆或其他类似的形状。该算法通过使用核函数（数学函数）来处理这一问题，核函数可以向数据集引入额外的特征，从而修改数据点的分布，使其能够通过一条直线将其分隔开来。为此有几种不同的核可供选择，选择合适的核函数需要通过试验和错误来进行，以便找到最适合分类现有数据的核函数。
- en: However, the default kernel for the SVM algorithm in scikit-learn is the **Radial
    Basis Function** (**RBF**) kernel. This is mainly because, based on several studies,
    this kernel has proved to work great for most data problems.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，scikit-learn 中 SVM 算法的默认核函数是**径向基函数**（**RBF**）核。主要原因是，根据多项研究表明，这种核函数在大多数数据问题中表现良好。
- en: 'Exercise 4.03: Applying the SVM Algorithm'
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.03：应用 SVM 算法
- en: 'In this exercise, we will apply the SVM algorithm to the Fertility dataset.
    The idea, which is the same as in previous exercises, is to determine whether
    the fertility level of an individual is affected by their demographics, their
    environmental conditions, and their previous medical conditions. Follow these
    steps to complete this exercise:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将应用 SVM 算法处理“生育数据集”。这个想法与之前的练习相同，即确定个体的生育水平是否受其人口统计学、环境条件和既往病史的影响。按照以下步骤完成本次练习：
- en: 'Open a Jupyter Notebook to implement this exercise. Import pandas as well as
    the `SVC` class from scikit-learn''s `svm` module:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 Jupyter Notebook 来实现本次练习。导入 pandas 以及 scikit-learn 的 `svm` 模块中的 `SVC` 类：
- en: '[PRE16]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Load the `fertility_Diagnosis` dataset that you downloaded in *Exercise 4.01*,
    *Applying the Naïve Bayes Algorithm*. Make sure to add the `header = None` argument
    to the `read_csv` function, considering that the dataset does not contain a header
    row:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载你在*练习4.01*中下载的`fertility_Diagnosis`数据集，*应用朴素贝叶斯算法*。确保在`read_csv`函数中添加`header
    = None`参数，因为该数据集不包含标题行：
- en: '[PRE17]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Split the data into `X` and `Y`, considering that the class label is found
    under the column with the index equal to `9`. Use the following code to do so:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分成`X`和`Y`，考虑到类别标签位于索引为`9`的列下。使用以下代码进行操作：
- en: '[PRE18]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Instantiate scikit-learn''s `SVC` class and use the `fit` function to train
    the model using `X` and `Y`:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化scikit-learn的`SVC`类，并使用`fit`函数，利用`X`和`Y`数据来训练模型：
- en: '[PRE19]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Again, the output from running this code represents the summary of the model,
    along with its default hyperparameters, as follows:'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 再次运行这段代码时，输出结果为模型的总结，以及其默认超参数，如下所示：
- en: '[PRE20]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Finally, perform a prediction using the model that you trained previously,
    for the same instances that we used in *Exercise 4.01*, *Applying the Naïve Bayes
    Algorithm*: −`0.33`, `0.69`, `0`, `1`, `1`, `0`, `0.8`, `0`, `0.88`.'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用之前训练的模型进行预测，预测与我们在*练习4.01*中使用的相同实例：−`0.33`、`0.69`、`0`、`1`、`1`、`0`、`0.8`、`0`、`0.88`。
- en: 'Use the following code to do so:'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用以下代码进行操作：
- en: '[PRE21]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is as follows:'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE22]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Again, the model predicts the instance's class label as `N`, meaning that the
    fertility of the subject has not been affected.
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 再次，模型预测该实例的类别标签为`N`，意味着该对象的生育能力未受到影响。
- en: Note
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2YyEMNX](https://packt.live/2YyEMNX).
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问这一特定部分的源代码，请参考[https://packt.live/2YyEMNX](https://packt.live/2YyEMNX)。
- en: You can also run this example online at [https://packt.live/2Y3nIR2](https://packt.live/2Y3nIR2).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例，网址为[https://packt.live/2Y3nIR2](https://packt.live/2Y3nIR2)。你必须执行整个Notebook才能得到预期结果。
- en: You have successfully trained an SVM model and performed a prediction.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地训练了一个SVM模型并进行了预测。
- en: 'Activity 4.03: Training an SVM Model for Our Census Income Dataset'
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动4.03：为我们的普查收入数据集训练SVM模型
- en: 'Continuing with your task of building a model that is capable of predicting
    a person''s annual income, the final algorithm that you want to train is the Support
    Vector Machine. Follow these steps to implement this activity:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 继续你的任务，构建一个能够预测个人年收入的模型，最后你要训练的算法是支持向量机。按照以下步骤来实现此活动：
- en: Open the Jupyter Notebook that you used for the previous activity and import
    the SVM algorithm from scikit-learn.
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开你在前一活动中使用的Jupyter Notebook，并从scikit-learn中导入SVM算法。
- en: Train the model using the `fit` method on the `SVC` class from scikit-learn.
    To train the model, use the training set data from the previous activity (`X_train`
    and `Y_train`).
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用scikit-learn中的`SVC`类的`fit`方法来训练模型。要训练模型，使用前一活动中的训练集数据（`X_train`和`Y_train`）。
- en: Note
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The process of training the SVC class using the `fit` method may take a while.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用`fit`方法训练SVC类可能需要一些时间。
- en: 'Finally, perform a prediction using the model that you trained previously,
    for a new instance with the following values for each feature: `39`, `6`, `13`,
    `4`, `0`, `2174`, `0`, `40`, `38`.'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用之前训练的模型进行预测，预测一个新实例，假设该实例的每个特征值如下：`39`、`6`、`13`、`4`、`0`、`2174`、`0`、`40`、`38`。
- en: The prediction for the individual should be equal to zero, that is, the individual
    most likely has an income less than or equal to 50K.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对个体的预测应为零，即该个体的收入最有可能小于或等于50K。
- en: Note
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 238.
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以在第238页找到。
- en: Error Analysis
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 误差分析
- en: In the previous chapter, we explained the importance of error analysis. In this
    section, the different evaluation metrics will be calculated for all three models
    that were created in the previous activities so that we can compare them.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们解释了误差分析的重要性。在本节中，我们将计算前面活动中创建的三个模型的不同评估指标，以便进行比较。
- en: For learning purposes, we will compare the models using accuracy, precision,
    and recall metrics. This way, it will be possible to see that even though a model
    might be better in terms of one metric, it could be worse when measuring a different
    metric, which helps to emphasize the importance of choosing the right metric to
    measure your model according to the goal you wish to achieve.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 为了学习的目的，我们将使用准确率、精确度和召回率指标来比较模型。这样，就能看到即使某个模型在某个指标上表现较好，在另一个指标上却可能表现较差，这有助于强调选择适当指标的重要性，以便根据你希望实现的目标来衡量模型。
- en: Accuracy, Precision, and Recall
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准确率、精确度和召回率
- en: 'As a quick reminder, in order to measure performance and perform error analysis,
    it is required that you use the `predict` method for the different sets of data
    (training, validation, and testing). The following code snippets present a clean
    way of measuring all three metrics on our three sets at once:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 简要提醒一下，为了衡量性能并进行误差分析，你需要使用 `predict` 方法来处理不同的数据集（训练集、验证集和测试集）。以下代码片段展示了一种简洁的方式，可以同时在我们的三个数据集上衡量所有三个指标：
- en: Note
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The following steps are to be performed after solving the activities of this
    chapter. This is mainly because the steps in this section correspond to a continuation
    of this chapter's activities.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章活动后，需执行以下步骤。这主要是因为这一部分的步骤是本章活动的延续。
- en: 'First, the three metrics to be used are imported:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，导入将要使用的三个评估指标：
- en: '[PRE23]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, we create two lists containing the different sets of data that will be
    used inside a `for` loop to perform the performance calculation on all sets of
    data for all models:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们创建两个列表，包含将用于 `for` 循环中的不同数据集，用于对所有模型的所有数据集进行性能计算：
- en: '[PRE24]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'A dictionary will be created, which will hold the value of each evaluation
    metric for each set of data for each model:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个字典将被创建，用来存储每个模型对每组数据的每个评估指标的值：
- en: '[PRE25]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'A `for` loop is used to go through the different sets of data:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `for` 循环来遍历不同的数据集：
- en: '[PRE26]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Print the metrics, as follows:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印评估指标，结果如下：
- en: '[PRE27]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is as follows:'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.12: Printing the metrics'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.12：打印评估指标](img/B15781_04_13.jpg)'
- en: '](img/B15781_04_12.jpg)'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15781_04_12.jpg)'
- en: 'Figure 4.12: Printing the metrics'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12：打印评估指标
- en: Inside the `for` loop, there are three blocks of code, one for each model we
    created in the previous activities. Each block of code performs the following
    actions.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `for` 循环内，有三个代码块，每个代码块对应我们在之前活动中创建的一个模型。每个代码块执行以下操作：
- en: First, a prediction is made. The prediction is achieved by calling the `predict`
    method on the model and inputting a set of data. As this operation occurs inside
    a `for` loop, the prediction will occur for all sets of data.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，进行预测。预测是通过调用模型的 `predict` 方法，并输入一组数据来实现的。由于该操作发生在 `for` 循环中，预测将对所有数据集进行。
- en: Next, the calculation of all three metrics is done by comparing the ground truth
    data with the prediction that we calculated previously. The calculation is appended
    to the dictionary that was created previously.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，通过将实际数据与我们之前计算的预测结果进行比较，来计算所有三个指标。计算结果会附加到之前创建的字典中。
- en: 'From the preceding snippets, the following results are obtained:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码片段中，得到以下结果：
- en: '![Figure 4.13: Performance results of all three models'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.13：所有三个模型的性能结果](img/B15781_04_12.jpg)'
- en: '](img/B15781_04_13.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15781_04_13.jpg)'
- en: 'Figure 4.13: Performance results of all three models'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13：所有三个模型的性能结果
- en: Note
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Review the code to arrive at these results, which can be found in this book's
    GitHub repository, under the folder named `Chapter04`, by opening the file named
    `Error analysis`.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 请检查代码，以获得这些结果，相关代码可以在本书的 GitHub 仓库中找到，路径为 `Chapter04` 文件夹，文件名为 `Error analysis`。
- en: 'Initially, the following inferences, in relation to selecting the best-fitted
    model, as well as with regard to the conditions that each model suffers from,
    will be done while considering only the values from the accuracy metric, assuming
    a Bayes error of close to 0 (meaning that the model could reach a maximum success
    rate of close to 1):'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 初步推断，关于选择最适合的模型，并考虑每个模型面临的条件时，将仅考虑准确率指标的值，假设贝叶斯误差接近0（这意味着该模型可能达到接近1的最大成功率）：
- en: Upon comparing the three accuracy scores of the Naïve Bayes and the SVM models,
    it is possible to conclude that the models behave almost the same way for all
    three sets of data. This basically means that the models are generalizing the
    data from the training set, which allows them to perform well on unseen data.
    Nevertheless, the overall performance of the models is around 0.8, which is far
    from the maximum success rate. This means that the models may be suffering from
    high bias.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在比较了朴素贝叶斯和支持向量机（SVM）模型的三项准确率得分后，可以得出结论：这两种模型在三组数据上的表现几乎相同。这基本上意味着这些模型能够很好地泛化训练集数据，因此在未见过的数据上也能表现良好。然而，这些模型的整体表现约为0.8，远低于最大成功率。这意味着这些模型可能存在较高的偏差。
- en: Moreover, the performance of the decision tree model, in terms of the accuracy
    of the training set, is closer to the maximum success rate. However, the model
    is suffering from a case of overfitting, considering that the accuracy level of
    the model on the validation set is much lower than its performance on the training
    set. According to this, it would be possible to address the overfitting issue
    by adding more data to the training set or by fine-tuning the hyperparameters
    of the model, which would help to bring up the accuracy level of the validation
    and testing sets. Pruning the tree can help an overfitted model.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，决策树模型在训练集准确度方面的表现更接近最大成功率。然而，考虑到模型在验证集上的准确度远低于训练集表现，模型正面临过拟合问题。为了解决过拟合问题，可以通过增加训练集数据或微调模型的超参数来帮助提高验证集和测试集的准确度。对树进行剪枝也有助于缓解过拟合问题。
- en: Considering this, the researcher now has the required information to select
    a model and work on improving the results to achieve the maximum possible performance
    of the model.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于此，研究人员现在已经拥有了选择模型并致力于提高结果以实现模型最大可能性能所需的信息。
- en: Next, for learning purposes, let's compare the results of all the metrics for
    the decision tree model. Although the values for all three metrics prove the existence
    of overfitting, it is possible to observe that the degree of overfitting is much
    larger for the precision and recall metrics. Also, it is possible to conclude
    that the performance of the model on the training set measured by the recall metric
    is much lower, which means that the model is not as good at classifying positive
    labels. This means that if the purpose of the case study was to maximize the number
    of positive classifications, regardless of the classification of negative labels,
    the model would also need to improve its performance on the training set.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了学习的目的，让我们比较决策树模型的所有衡量标准的结果。尽管三项衡量标准的值都证明了过拟合的存在，但可以观察到精度和召回率标准下的过拟合程度明显更大。此外，可以得出结论，模型在训练集上以召回率衡量时的表现较差，这意味着模型在分类正标签时的能力较弱。这意味着，如果案例研究的目标是最大化正标签的分类数，而不考虑负标签的分类，那么模型还需要提高其在训练集上的表现。
- en: Note
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The preceding comparison is done to show that the performance of the same model
    can vary if measured with a different metric. According to this, it is crucial
    to choose the metric of relevance for the case study.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的对比是为了说明，同一模型的表现可能因采用不同的衡量标准而有所不同。因此，选择与案例研究相关的衡量标准至关重要。
- en: Using the knowledge that you have gained from previous chapters, feel free to
    keep exploring the results shown in the preceding table.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 利用从前几章获得的知识，随时可以继续探索前面表格中显示的结果。
- en: Summary
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Using the knowledge from previous chapters, we started this chapter by performing
    an analysis of the Census Income dataset, with the objective of understanding
    the data that's available and making decisions about the pre-processing process.
    Three supervised learning classification algorithms—the Naïve Bayes algorithm,
    the Decision Tree algorithm, and the SVM algorithm—were explained, and were applied
    to the previously pre-processed dataset to create models that generalized to the
    training data. Finally, we compared the performance of the three models on the
    Census Income dataset by calculating the accuracy, precision, and recall on the
    different sets of data (training, validation, and testing).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 运用前几章的知识，我们通过对人口普查收入数据集进行分析来开始本章，目的是了解可用数据并对预处理过程做出决策。解释了三种监督学习分类算法——朴素贝叶斯算法、决策树算法和支持向量机（SVM）算法，并将它们应用于之前预处理的数据集，以创建能够泛化到训练数据的模型。最后，我们通过计算不同数据集（训练、验证和测试）上的准确率、精确率和召回率来比较三种模型在人口普查收入数据集上的表现。
- en: In the next chapter, we will look at **Artificial Neural Networks** (**ANNs**),
    their different types, and their advantages and disadvantages. We will also use
    an ANN to solve the same data problem that was discussed in this chapter, as well
    as to compare its performance with that of the other supervised learning algorithms.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将研究**人工神经网络**（**ANNs**）、它们的不同类型以及它们的优缺点。我们还将使用ANN解决本章讨论的相同数据问题，并将其性能与其他监督学习算法进行比较。
