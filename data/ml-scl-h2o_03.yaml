- en: '*Chapter 2*: Platform Components and Key Concepts'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第二章*：平台组件和关键概念'
- en: In this chapter, we will gain a fundamental understanding of the components
    of H2O's machine learning at scale technology. We will view a simple code example
    of H2O machine learning, understand what it does, and identify any problems the
    example has with machine learning at an enterprise scale. This *Hello World* code
    example will serve as a simple representation in which to build our understanding
    further.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将对H2O大规模机器学习技术的组件有一个基本理解。我们将查看H2O机器学习的简单代码示例，了解它做什么，并确定示例在企业管理规模机器学习方面可能存在的问题。这个*Hello
    World*代码示例将作为一个简单的表示，以便进一步构建我们的理解。
- en: We will overview each H2O component of machine learning at scale, identify how
    each component achieves scale, and identify how each component relates to our
    simple code snippet. Then, we will tie these components together into a reference
    machine learning workflow using these components. Finally, we will focus on the
    underlying key concepts that arise from these components. The understanding obtained
    in this chapter will be foundational to the rest of the book, where we will be
    implementing H2O technology to build and deploy state-of-the-art machine learning
    models at scale in an enterprise setting.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将概述H2O机器学习大规模的每个组件，确定每个组件如何实现规模，以及每个组件如何与我们的简单代码片段相关联。然后，我们将使用这些组件将这些组件组合成一个参考机器学习工作流程。最后，我们将关注从这些组件中产生的底层关键概念。在本章中获得的理解将是本书其余部分的基础，其中我们将实现H2O技术，在企业环境中构建和部署大规模的先进机器学习模型。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Hello World – the H2O machine learning code
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hello World – H2O机器学习代码
- en: The components of H2O machine learning at scale
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H2O机器学习大规模的组成部分
- en: The machine learning workflow using these H2O components
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用这些H2O组件的机器学习工作流程
- en: H2O key concepts
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H2O关键概念
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you will need to install H2O-3 locally to run through a bare
    minimum *Hello World* workflow. To implement it, follow the instructions in the
    [*Appendix*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268). Note that
    we will use the Python API throughout the book, so follow the instructions to
    install it in Python.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，您需要在本地安装H2O-3以运行一个基本的*Hello World*工作流程。要实现它，请遵循[*附录*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268)中的说明。请注意，我们将全书使用Python
    API，因此请按照说明在Python中安装它。
- en: Hello World – the H2O machine learning code
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hello World – H2O机器学习代码
- en: H2O Core is designed for machine learning at scale; however, it can also be
    used on small datasets on a user's laptop. In the following section, we will use
    a minimal code example of H2O-3 to build a machine learning model and export it
    as a deployable artifact. We will use this example to serve as the most basic
    unit to understand H2O machine learning code, much like viewing a human stick
    figure to begin learning about human biology.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: H2O核心是为大规模机器学习设计的；然而，它也可以用于用户笔记本电脑上的小数据集。在下一节中，我们将使用H2O-3的最小代码示例构建一个机器学习模型，并将其导出为可部署的工件。我们将使用这个示例作为理解H2O机器学习代码的最基本单元，就像通过查看人类棍状图开始学习人类生物学一样。
- en: Code example
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码示例
- en: Take a look at the code examples that follow. Here, we are writing in Python,
    which could be from Jupyter, PyCharm, or another Python client. We will learn
    that R and Java/Scala are alternative languages in which to write H2O code.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 查看下面的代码示例。在这里，我们使用Python编写，这可能是来自Jupyter、PyCharm或其他Python客户端。我们将了解到R和Java/Scala是编写H2O代码的替代语言。
- en: 'Let''s start by importing the H2O library:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先导入H2O库：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Recall from the documentation that this has been downloaded from H2O and installed
    in the client or an IDE environment. This `h2o` package allows us to run H2O in-memory
    distributed machine learning from the IDE using the H2O API written in Python.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从文档中回忆，这已经从H2O下载并安装到客户端或IDE环境中。这个`h2o`包允许我们使用Python编写的H2O API在IDE中运行内存分布式机器学习。
- en: 'Next, we create an H2O cluster:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个H2O集群：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The preceding line of code creates what is called An **H2O cluster**. This is
    a key concept underlying H2O's model building technology. It is a distributed
    in-memory architecture. In the *Hello World* case, the H2O cluster will be created
    on the laptop as localhost and will not be distributed. We will learn more about
    the H2O cluster in the *H2O key concepts* section of this chapter.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行代码创建了一个所谓的 **H2O 集群**。这是 H2O 模型构建技术背后的一个关键概念。它是一个分布式内存架构。在 *Hello World*
    案例中，H2O 集群将在笔记本电脑上作为 localhost 创建，并且不会分布式。我们将在本章的 *H2O 关键概念* 部分学习更多关于 H2O 集群的内容。
- en: The `ip` and `port` configurations that are used to start the H2O cluster should
    provide sufficient clues that the H2O code will be sent via an API to the compute
    environment, which could be inside a data center or the cloud for an enterprise
    environment. However, here, it is on our localhost.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 用于启动 H2O 集群的 `ip` 和 `port` 配置应提供足够的线索，表明 H2O 代码将通过 API 发送到计算环境，这可能是在数据中心或企业环境中，也可能是云端。然而，在这里，它是在我们的本地主机上。
- en: 'Then, we import a dataset:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们导入一个数据集：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now we explore the dataset:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来探索数据集：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This is a minimal amount of data exploration. It simply returns the number of
    rows and columns.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最小限度的数据探索。它只是简单地返回行数和列数。
- en: 'Okay, now let''s prepare the data for our model:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在让我们为我们的模型准备数据：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We have split the data into training and validation sets, with a `0.75` proportion
    for training. We are going to predict whether a loan will be bad or not (that
    is, whether it will default or not) and have identified this column as the label.
    Finally, we define the columns used to predict bad loans by using all columns
    in the dataset except the bad loan column.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将数据分为训练集和验证集，其中训练集的比例为 `0.75`。我们将预测一笔贷款是否会坏账（即是否会违约）并已将该列标识为标签。最后，我们使用数据集中的所有列（除了坏账列）来定义用于预测坏账的列。
- en: 'Now, we build the model:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们构建模型：
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We have imported H2O's **XGBoost** module and configured two hyperparameters
    for it. Then, we started the model training by inputting references into the predictor
    column, label column, training data, and testing data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经导入了 H2O 的 **XGBoost** 模块，并为其配置了两个超参数。然后，我们通过输入参考到预测列、标签列、训练数据和测试数据中，开始模型训练。
- en: XGBoost is one of many widely recognized and extensively used machine learning
    algorithms packaged in the `h2o` module. The H2O API exposed by this module will
    run the XGBoost model in H2O's architecture on the enterprise infrastructure,
    as we will learn later. Regarding hyperparameters, we will discover that H2O offers
    an extensive set of hyperparameters to configure for each model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 是 `h2o` 模块中包装的许多广泛认可和广泛使用的机器学习算法之一。该模块暴露的 H2O API 将在 H2O 的架构上运行 XGBoost
    模型，在企业基础设施上，正如我们稍后将要学习的。关于超参数，我们将发现 H2O 为每个模型提供了一套广泛的可配置超参数。
- en: 'When the model finishes, we can export the model using one line of code:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型完成时，我们可以使用一行代码导出模型：
- en: '[PRE15]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The exported scoring artifact is now ready to pass to DevOps to deploy. The
    `get_genmodel_jar=True` parameter triggers the download to include `h2o-genmodel.jar`.
    This is a library used by the model for scoring outside of an H2O cluster, that
    is, in a production environment. We will learn more about productionizing H2O
    models in *Section 3 – Deploying Your Models to Production Environments*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 导出的评分工件现在可以传递给 DevOps 进行部署。`get_genmodel_jar=True` 参数触发下载以包括 `h2o-genmodel.jar`。这是一个模型在
    H2O 集群之外评分时使用的库，即在生产环境中。我们将在 *第 3 节 – 将您的模型部署到生产环境* 中学习更多关于生产化 H2O 模型的内容。
- en: 'We are done with model building, for now. So, we will shut down the cluster:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们已经完成了模型构建。因此，我们将关闭集群：
- en: '[PRE16]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This frees up the resources that the H2O cluster has been using.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这将释放 H2O 集群所使用的资源。
- en: 'Bear in mind that this is a simple *Hello World* H2O model building example.
    It is meant to do both of the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这是一个简单的 *Hello World* H2O 模型构建示例。它的目的是做以下两件事：
- en: Give a bare minimum introduction to H2O model building.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对 H2O 模型构建提供一个最基本介绍。
- en: Serve as a basis to discuss issues of scale in the enterprise, which we will
    do in the next section.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为讨论企业中规模问题的基础，我们将在下一节中进行讨论。
- en: In *Section 2 – Building State-of-the-Art Models on Large Data Volumes Using
    H2O*, we will explore extensive techniques to build highly predictive and explainable
    models at scale. Let's start our journey by discussing some issues of scale that
    our *Hello World* example exposes.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第 2 节 - 使用 H2O 在大量数据上构建最先进的模型* 中，我们将探讨构建高度预测性和可解释模型的多种技术。让我们从讨论 *Hello World*
    示例暴露的规模化问题开始我们的旅程。
- en: Some issues of scale
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规模化的一些问题
- en: This *Hello World* code will not scale well in an enterprise setting. Let's
    revisit the code to better understand these scaling constraints.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这段 *Hello World* 代码在企业环境中扩展性不佳。让我们重新审视代码，以更好地理解这些扩展限制。
- en: 'We import the library in our IDE code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在我们的 IDE 代码中导入库：
- en: '[PRE17]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Most enterprises want to have some control over the versions of libraries that
    are used. Additionally, they usually want to provide a central platform to host
    and authenticate all users of a piece of technology and to have administrators
    manage that platform. We will discover that Enterprise Steam plays a key role
    in centrally managing users and H2O environments.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数企业希望对所使用的库版本有所控制。此外，他们通常希望提供一个中央平台来托管和验证一项技术的所有用户，并让管理员管理该平台。我们将发现，企业 Steam
    在集中管理用户和 H2O 环境方面发挥着关键作用。
- en: 'We initialize the H2O cluster:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始化 H2O 集群：
- en: '[PRE18]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Machine learning at scale requires the distribution of compute resources across
    a server cluster to achieve horizontal scaling (that is, divide-and-conquer compute
    resources across many servers). Therefore, the IP address and port should point
    to a member of a server cluster and not to a single computer, as demonstrated
    in this example. We will see that H2O Core creates its own self-organized cluster
    that distributes and horizontally scales model building.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 规模化机器学习需要将计算资源分布在服务器集群中，以实现横向扩展（即在许多服务器之间划分和征服计算资源）。因此，IP 地址和端口应该指向服务器集群的成员，而不是单个计算机，如本例所示。我们将看到
    H2O Core 会创建自己的自组织集群，该集群负责分配和横向扩展模型构建。
- en: Since scaling is on the enterprise server cluster, which, typically, is used
    by many individuals and groups, enterprises want to control user access to this
    environment along with the number of resources consumed by users. But then what
    would prevent a user from launching multiple H2O clusters, using as many resources
    as possible on each, and thus, blocking resource availability from other users?
    Enterprise Steam manages H2O user and H2O resource consumption on the enterprise
    server cluster.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于扩展是在企业服务器集群上进行的，通常情况下，许多个人和团体都会使用这个集群，因此企业希望控制用户对这个环境的访问以及用户消耗的资源数量。但是，这又如何阻止用户启动多个
    H2O 集群，在每个集群上尽可能多地使用资源，从而阻止其他用户获取资源呢？企业 Steam 管理企业服务器集群上的 H2O 用户和 H2O 资源消耗。
- en: 'We import the dataset:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入数据集：
- en: '[PRE19]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Data at large volumes takes an exceedingly long time to move over the network,
    taking hours or days to complete a transfer, or it could time out beforehand.
    Computation during model building at scale should occur where the data resides
    to prevent this bottleneck in data movement. We will discover that H2O clusters
    that are launched on the enterprise system ingest data from the storage layer
    directly into server memory. Because data is partitioned across the servers that
    comprise an H2O cluster, data ingest occurs in parallel to those partitions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 大量数据在网络上的移动需要极长的时间，可能需要数小时或数天才能完成传输，或者可能在传输之前就超时了。在规模化的模型构建过程中，计算应该发生在数据所在的位置，以防止数据移动的瓶颈。我们将发现，在企业系统中启动的
    H2O 集群会直接从存储层将数据摄入到服务器内存中。因为数据分布在构成 H2O 集群的各个服务器上，数据摄入与这些分区并行进行。
- en: We will see how Enterprise Steam centralizes user authentication and how the
    user's identity is passed to the enterprise system where its native authorization
    mechanism is honored.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到企业 Steam 如何集中用户身份验证，以及用户的身份信息如何传递到企业系统，在那里其原生授权机制得到尊重。
- en: 'We train the model:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们训练模型：
- en: '[PRE20]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Of course, this is the heart of the model building process and, likewise, the
    focus of much of this book: how to build world-class machine learning models against
    large data volumes using H2O''s extensive machine learning algorithm and model
    building capabilities.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这是模型构建过程的核心，也是本书许多内容的焦点：如何使用 H2O 的广泛机器学习算法和模型构建能力，在大量数据上构建世界级的机器学习模型。
- en: 'We download the deployable model:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下载可部署的模型：
- en: '[PRE24]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Bear in mind that, from a business standpoint, value is not achieved until a
    model is exported and deployed into production. Doing so involves the complexities
    of multiple enterprise stakeholders. We will learn how the design and capabilities
    of the exported **MOJO** (**Model Object, Optimized**) facilitate the ease of
    deployment to diverse software systems involving these stakeholders.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，从商业角度来看，直到模型导出并部署到生产中，才能实现价值。这样做涉及到多个企业利益相关者的复杂性。我们将学习如何设计导出的**MOJO**（**模型对象，优化**）的功能，以简化涉及这些利益相关者的各种软件系统的部署。
- en: 'We shut down the H2O cluster:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关闭了H2O集群：
- en: '[PRE25]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: An H2O cluster uses resources and should be shut down when not in use. If this
    is not done, other users or jobs on the enterprise system could be competing for
    these resources and, consequently, become impacted. Additionally, fewer new users
    can be added to the system before the infrastructure must be expanded. We will
    see that Enterprise Steam governs how H2O users consume resources on the enterprise
    system. The resulting gain in resource efficiency allows H2O users and their work
    to scale more effectively on a given allocation of infrastructure.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: H2O集群使用资源，当不使用时应关闭。如果不这样做，其他用户或企业系统上的作业可能会竞争这些资源，从而受到影响。此外，在必须扩展基础设施之前，系统中可以添加的新用户数量会减少。我们将看到企业蒸汽如何管理H2O用户在企业系统上消耗资源。这种资源效率的提高使得H2O用户及其工作在给定的基础设施分配上能够更有效地扩展。
- en: Now that we have run our *Hello World* example and explored some of its issues
    regarding scale, let's move on to gain an understanding of H2O components for
    machine learning model building and deployment at scale.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经运行了我们的*Hello World*示例并探讨了其关于扩展的一些问题，让我们继续了解H2O组件，以便在大规模机器学习模型构建和部署中取得理解。
- en: The components of H2O machine learning at scale
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: H2O机器学习大规模组件
- en: As introduced in the previous chapter and emphasized throughout this book, H2O
    machine learning overcomes problems of scale. The following is a brief introduction
    of each component of H2O machine learning at scale and how each overcomes these
    challenges.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，并在整本书中强调，H2O机器学习克服了扩展问题。以下是对H2O大规模机器学习每个组件的简要介绍以及每个组件如何克服这些挑战。
- en: H2O Core – in-memory distributed model building
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: H2O Core – 内存分布式模型构建
- en: H2O Core allows a data scientist to write code to build models using well-known
    machine learning algorithms. The coding experience is through an H2O API expressed
    in Python, R, or Java/Scala language and written in their favorite client or IDE,
    for example Python in a Jupyter notebook. The actual computation of model building,
    however, takes place on an enterprise server cluster (not the IDE environment)
    and leverages the server cluster's vast pool of memory and CPUs needed to run
    machine learning algorithms against massive data volumes.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: H2O Core允许数据科学家编写代码，使用知名的机器学习算法构建模型。编码体验是通过Python、R或Java/Scala语言表达的H2O API实现的，并在他们喜欢的客户端或IDE中编写，例如在Jupyter笔记本中的Python。然而，模型构建的实际计算是在企业服务器集群（而不是IDE环境）上进行的，并利用服务器集群的大量内存和CPU资源来运行针对大量数据的机器学习算法。
- en: So, how does this work? First, data used for model building is partitioned and
    distributed in memory by H2O on the server cluster. The IDE sends H2O instructions
    to the server cluster. A server in the cluster receives these instructions and
    distributes them to the other servers in the cluster. The instructions are run
    in parallel on the partitioned in-memory data. The server that received the instructions
    gathers and combines the results and sends them back to the IDE. This is done
    repeatedly as code is sequenced through the IDE.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，它是如何工作的呢？首先，用于模型构建的数据由H2O在服务器集群上分区和内存中分布式。IDE将H2O指令发送到服务器集群。集群中的服务器接收这些指令并将它们分发到集群中的其他服务器。指令在分区内存数据上并行运行。接收指令的服务器收集和合并结果，并将它们发送回IDE。随着代码通过IDE的序列执行，这个过程会重复进行。
- en: This *divide and conquer* approach is fundamental to H2O model building at scale.
    A unit of H2O divide and conquer architecture is called an H2O cluster and is
    elaborated as a *key concept* later in the chapter. The result is rapid model
    building on large volumes of data.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这种*分而治之*的方法是H2O大规模模型构建的基础。H2O分而治之架构的一个单元被称为H2O集群，在章节的后面将详细阐述为*关键概念*。结果是快速在大数据量上构建模型。
- en: The key features of H2O Core
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: H2O Core的关键特性
- en: 'Some of the key features of H2O Core are as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: H2O Core的一些关键特性如下：
- en: '**Horizontal scaling**: Data operations and machine learning algorithms are
    distributed in parallel and in memory, with additional optimizations such as a
    distributed key/value store to rapidly access data and objects during model building.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**水平扩展**：数据操作和机器学习算法在并行和内存中分布，并具有额外的优化，如分布式键/值存储，以在模型构建期间快速访问数据和对象。'
- en: '**Familiar experience**: Data scientists use familiar languages and IDEs to
    write H2O API code, as we have just done.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**熟悉的经验**：数据科学家使用熟悉的语言和 IDE 编写 H2O API 代码，正如我们刚刚所做的那样。'
- en: '**Open source**: H2O Core is open source.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开源**：H2O Core 是开源的。'
- en: '**Wide range of file formats**: H2O supports a wide range of source data formats.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广泛的文件格式**：H2O 支持广泛的源数据格式。'
- en: '**Data manipulation**: The H2O API includes a wide range of tasks commonly
    performed to prepare data for machine learning. Sparkling Water (covered in the
    next section) extends data engineering techniques to Spark.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据处理**：H2O API 包含了广泛的数据处理任务，这些任务通常用于准备机器学习所需的数据。Sparkling Water（下一节将介绍）将数据工程技术扩展到
    Spark。'
- en: '**Well-recognized machine learning algorithms**: H2O uses a wide range of well-recognized
    supervised and unsupervised machine learning algorithms.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公认的机器学习算法**：H2O 使用了广泛公认的监督和无监督机器学习算法。'
- en: '**Training, testing, and evaluation**: Extensive techniques in cross-validation,
    grid search, variable importance, and performance metrics are used to train, test,
    and evaluate models; this also includes model checkpointing capabilities.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练、测试和评估**：使用交叉验证、网格搜索、变量重要性和性能指标等广泛的技术来训练、测试和评估模型；这还包括模型检查点功能。'
- en: '**Automatic Machine Learning (AutoML)**: The H2O Core AutoML API provides a
    simple wrapper function to concisely automate the training and tuning of multiple
    models, including stacked ensembling, and present results in a leaderboard.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动机器学习 (AutoML)**: H2O Core 自动机器学习 API 提供了一个简单的包装函数，可以简洁地自动化多个模型的训练和调优，包括堆叠集成，并以排行榜的形式展示结果。'
- en: '**Model explainability**: It offers extensive local and global explainability
    methods and visualizations for single models or those involved in AutoML, all
    from a single wrapper function.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型可解释性**：它提供了广泛的局部和全局可解释性方法和可视化，适用于单个模型或参与 AutoML 的模型，所有这些都可以通过单个包装函数实现。'
- en: '**AutoDoc**: It enables the automated generation of standardized Word documents,
    extensively describing model building and explainability in detail; note that
    AutoDoc is not available as a free open source platform.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AutoDoc**：它能够自动生成标准化的 Word 文档，详细描述模型构建和可解释性；请注意，AutoDoc 不是一个免费的开源平台。'
- en: '**Exportable scoring artifact (MOJO)**: It uses a single line of code to export
    the model as a deployable scoring artifact (model deployment will be discussed
    in greater detail in *Section 3 – Deploying Your Models to Production Environments*).'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可导出的评分工件 (MOJO)**：它使用一行代码将模型导出为可部署的评分工件（模型部署将在第 3 节“将您的模型部署到生产环境”中更详细地讨论）。'
- en: '**H2O Flow Web UI**: This is an optional web-based interactive UI to guide
    users through the model building workflow in an easy yet rich point-and-click
    experience, which is useful for the rapid experimentation and prototyping of H2O
    models.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H2O 流 Web UI**：这是一个可选的基于 Web 的交互式 UI，可以引导用户通过模型构建工作流程，提供简单而丰富的点选体验，这对于 H2O
    模型的快速实验和原型设计非常有用。'
- en: H2O-3 and H2O Sparkling Water
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: H2O-3 和 H2O Sparkling Water
- en: 'H2O Core comes in two flavors: **H2O-3** and **H2O Sparkling Water**.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: H2O Core 有两种版本：**H2O-3** 和 **H2O Sparkling Water**。
- en: 'H2O-3 is H2O Core, as described in the previous section. H2O Sparkling Water
    is H2O-3 wrapped by Spark integration. It is identical to H2O-3 along with the
    following additional capabilities:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: H2O-3 是 H2O Core，如前所述。H2O Sparkling Water 是 H2O-3 通过 Spark 集成包装的。它与 H2O-3 相同，并具有以下附加功能：
- en: '**Seamless integration of Spark and H2O API code**: The user writes both Spark
    and H2O code in the same IDE; for example, using SparkSQL code to engineer data
    and H2O code to build world-class models.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark 和 H2O API 代码的无缝集成**：用户在同一个 IDE 中编写 Spark 和 H2O 代码；例如，使用 SparkSQL 代码进行数据处理，使用
    H2O 代码构建世界级的模型。'
- en: '**Conversion between H2O and Spark DataFrames**: H2O and Spark DataFrames interconvert
    as part of the seamless integration; therefore, the results of SparkSQL data munging
    can be used as input to H2O model building.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H2O 和 Spark DataFrame 之间的转换**：H2O 和 Spark DataFrame 作为无缝集成的一部分进行相互转换；因此，SparkSQL
    数据处理的结果可以用作 H2O 模型构建的输入。'
- en: '**Spark engine**: Sparkling Water runs as a native Spark application on the
    Spark framework.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**火花引擎**：Sparkling Water作为原生Spark应用程序在Spark框架上运行。'
- en: H2O-3 and Sparkling Water are the model building alternatives of the more general
    H2O Core. The concept of the H2O cluster launched on the larger enterprise server
    cluster is similar for both H2O Core flavors, though some implementation details
    differ, which are essentially invisible to the data scientist. As mentioned, Sparkling
    Water is particularly useful for integrating Spark data engineering and H2O model
    building workflows.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: H2O-3和Sparkling Water是更通用的H2O Core的模型构建替代方案。在较大的企业服务器集群上启动的H2O集群的概念对两种H2O Core版本都是相似的，尽管一些实现细节不同，但这些对数据科学家来说是基本不可见的。如前所述，Sparkling
    Water特别适用于集成Spark数据工程和H2O模型构建工作流程。
- en: H2O Enterprise Steam – a managed, self-provisioning portal
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: H2O Enterprise Steam – 一个可管理的、自助配置的门户
- en: Enterprise Steam provides a centralized web UI and API for data scientists to
    initialize and terminate their H2O environments (called H2O clusters) and for
    administrators to manage H2O users and H2O integration with the enterprise server
    cluster.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 企业蒸汽为数据科学家提供了一个集中的Web UI和API，用于初始化和终止他们的H2O环境（称为H2O集群），以及管理员管理H2O用户和H2O与企业服务器集群的集成。
- en: The key features of Enterprise Steam
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 企业蒸汽的关键特性
- en: 'The key features of Enterprise steam are as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 企业蒸汽的关键特性如下：
- en: '**Data science self-provisioning**: This is an easy, UI-based way for data
    scientists to manage their H2O environments.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据科学自助配置**：这是一种简单、基于UI的方式，让数据科学家管理他们的H2O环境。'
- en: '**Central access point for all H2O users**: This creates the ease of H2O user
    management and a single entry point for H2O access to the enterprise server cluster.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**所有H2O用户的集中访问点**：这简化了H2O用户管理，并为H2O访问企业服务器集群提供了一个单一的入口点。'
- en: '**Govern user resource consumption**: Administrators build profiles of resource
    usage boundaries that are assigned to users or user groups. This places limits
    on the number of resources a user can allocate on the enterprise server cluster.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理用户资源消耗**：管理员为用户或用户组建立资源使用边界配置文件。这限制了用户在企业服务器集群上可以分配的资源数量。'
- en: '**Seamless security**: User authentication to Enterprise Steam flows through
    to the authorization of resources on the enterprise server cluster. Enterprise
    Steam authenticates against the same identity provider (for example, LDAP) that
    is used by the enterprise server cluster.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无缝安全**：用户对企业蒸汽的认证流程会传递到企业服务器集群上的资源授权。企业蒸汽使用与企业服务器集群相同的身份提供者（例如，LDAP）进行认证。'
- en: '**Configure integration**: The administrator configures the integration of
    H2O with the enterprise server cluster and identity provider.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**配置集成**：管理员配置H2O与企业服务器集群和身份提供者的集成。'
- en: '**Manage H2O Core versions**: The administrator manages one or more H2O Core
    versions that data scientists use to create H2O clusters for model building.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理H2O Core版本**：管理员管理一个或多个数据科学家用于创建模型构建H2O集群的H2O Core版本。'
- en: The H2O MOJO – a flexible, low-latency scoring artifact
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: H2O MOJO – 一种灵活、低延迟的评分工件
- en: The models built from H2O Core are exported as deployable scoring artifacts
    called H2O MOJOs. MOJOs can run in any JVM environment (except, perhaps, the very
    smallest edge devices).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从H2O Core构建的模型被导出为可部署的评分工件，称为H2O MOJOs。MOJOs可以在任何JVM环境中运行（可能，除了非常小的边缘设备之外）。
- en: In *Section 3 – Deploying Your Models to Production Environments*, we will learn
    that MOJOs are ready to deploy directly to H2O software as well as many third-party
    scoring solutions with no coding required. However, if you wish to directly embed
    MOJOs into your own software, there is a MOJO Java API to build Java helper classes
    to expose MOJO capabilities (for example, output reason codes in addition to a
    prediction) and to provide flexible integration with your scoring input and output.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第3节 – 将您的模型部署到生产环境*中，我们将了解到MOJOs可以直接部署到H2O软件以及许多第三方评分解决方案，无需编写代码。然而，如果您希望直接将MOJOs嵌入到自己的软件中，有一个MOJO
    Java API来构建Java辅助类以公开MOJO功能（例如，输出原因代码以及预测）并提供与评分输入和输出的灵活集成。
- en: MOJOs, out of all models, regardless of the machine learning algorithm used
    to build the model, are identical in construct. Therefore, deployment from a DevOps
    perspective is repeatable and automatable.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有模型相比，无论用于构建模型的机器学习算法如何，MOJOs的结构都是相同的。因此，从DevOps的角度来看，部署是可重复和可自动化的。
- en: The key features of MOJOs
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MOJOs的关键特性
- en: 'The key features of the MOJO are as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: MOJO 的关键特性如下：
- en: '**Low latency**: Typically, this is less than 100 milliseconds for each scoring.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低延迟**：通常，每个评分的延迟小于 100 毫秒。'
- en: '**Flexible data speeds**: Mojos can make predictions on batch, real time, and
    streaming data (for example on entire database tables, as REST endpoints and Kafka
    topics, respectively, to name a few examples).'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活的数据速度**：Mojos 可以对批量、实时和流数据（例如，对整个数据库表、作为 REST 端点和 Kafka 主题等）进行预测。'
- en: '**Flexible target systems**: This fits into JVM runtimes, including JDBC clients,
    **REST servers**, **AWS Lambda**, **AWS SageMaker**, **Kafka queues**, **Flink
    streams**, Spark pipelines including streaming, Hive UDF, Snowflake''s external
    functions, and more. Target systems can be specialized H2O scoring software, third-party
    scoring software, or your own software. A common pattern is to deploy the MOJO
    to a REST server and consume its predictions via REST calls from a client application
    (for example, an Excel spreadsheet).'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活的目标系统**：这适用于 JVM 运行时，包括 JDBC 客户端、**REST 服务器**、**AWS Lambda**、**AWS SageMaker**、**Kafka
    队列**、**Flink 流**、包括流处理的 Spark 管道、Hive UDF、Snowflake 的外部函数等。目标系统可以是专门的 H2O 评分软件、第三方评分软件或您自己的软件。一个常见的模式是将
    MOJO 部署到 REST 服务器，并通过客户端应用程序（例如 Excel 电子表格）的 REST 调用来消费其预测。'
- en: '**Explainability features**: In addition to predictions, you can receive K-Lime
    or Shapley reason codes from the MOJO during live scoring, and you can load the
    MOJO into H2O Core to score and inspect MOJO attributes.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性功能**：除了预测之外，您还可以在实时评分期间从 MOJO 接收 K-Lime 或 Shapley 原因代码，并且可以将 MOJO 加载到
    H2O Core 中进行评分和检查 MOJO 属性。'
- en: '**Repeatable deployments**: MOJOs are easy to integrate into existing deployment
    automation (CI/CD) pipelines used by the organization for software deployment.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可重复部署**：MOJO 很容易集成到组织用于软件部署的现有部署自动化（CI/CD）管道中。'
- en: Note that there is an alternative to the H2O MOJO, called **POJO**, which is
    used for infrequent edge cases. This will be explored further in [*Chapter 8*](B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137),
    *Putting It All Together*.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，H2O MOJO 有一个替代方案，称为 **POJO**，用于不常见的边缘情况。这将在 [*第 8 章*](B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137)，*整合一切*
    中进一步探讨。
- en: The workflow using H2O components
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 H2O 组件的工作流程
- en: 'Now that we understand the roles and key features of H2O''s machine learning
    at scale components, let''s tie them together into a high-level workflow, as represented
    in the following diagram:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 H2O 的机器学习大规模组件的角色和关键特性，让我们将它们整合成一个高级工作流程，如下面的图所示：
- en: '![Figure 2.1 – A high-level machine learning at scale workflow with H2O'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 2.1 – 使用 H2O 的高级机器学习大规模工作流程'
- en: '](img/B16721_Figure_2.1.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_Figure_2.1.jpg]'
- en: Figure 2.1 – A high-level machine learning at scale workflow with H2O
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – 使用 H2O 的高级机器学习大规模工作流程
- en: 'The workflow occurs in the following sequence:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程按以下顺序进行：
- en: The administrator configures **H2O Enterprise Steam**.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 管理员配置 **H2O Enterprise Steam**。
- en: The data scientist logs into **H2O Enterprise Steam** and launches the **H2O
    Core** cluster (choosing either **H2O-3** or **H2O Sparkling Water**).
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家登录到 **H2O Enterprise Steam** 并启动 **H2O Core** 集群（选择 **H2O-3** 或 **H2O Sparkling
    Water**）。
- en: The data scientist uses their favorite client to build models using the Python,
    R, or Java/Scala language flavor of the H2O model building API. The data scientist
    uses a UI or IDE to authenticate to **H2O Enterprise Steam** and connect to the
    **H2O cluster** that was started on H2O Enterprise Steam.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家使用他们喜欢的客户端，通过 H2O 模型构建 API 的 Python、R 或 Java/Scala 语言版本来构建模型。数据科学家使用 UI
    或 IDE 认证到 **H2O Enterprise Steam** 并连接到在 H2O Enterprise Steam 上启动的 **H2O 集群**。
- en: The data scientist uses the IDE to iterate through the model building steps
    with H2O.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家使用 IDE 通过 H2O 迭代模型构建步骤。
- en: After the data scientist decides on the model to be deployed, **H2O** **AutoDoc**
    is generated, and **H2O MOJO** is exported from the IDE.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家确定要部署的模型后，**H2O** **AutoDoc** 生成，并且 **H2O MOJO** 从 IDE 导出。
- en: The data scientist either terminates the **H2O cluster** or waits for **H2O
    Enterprise Steam** to do so after the idle or absolute uptime duration has been
    exceeded. These durations have been configured in a resource profile assigned
    to the user by the administrator. Note that the terminated cluster checkpoints
    do work, and a new **H2O cluster** can always be launched to continue working
    from the termination point.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家在空闲或绝对运行时间超过后，要么终止**H2O集群**，要么等待**H2O Enterprise Steam**这样做。这些持续时间已由管理员分配给用户的资源配置文件中配置。请注意，已终止的集群检查点仍然在工作，并且可以始终启动一个新的**H2O集群**，从终止点继续工作。
- en: The model is exported as **H2O MOJO** and is deployed to any of a diverse set
    of hosting targets. The model is consumed in a business context and achievement
    of the business value begins.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该模型以**H2O MOJO**格式导出，并部署到各种不同的托管目标。模型在业务环境中被使用，业务价值的实现由此开始。
- en: H2O key concepts
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: H2O关键概念
- en: In the following sections, we will identify and describe the key concepts of
    H2O that underlie the workflow steps of the previous section. These concepts are
    necessary to understand the rest of the book.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将识别和描述H2O的关键概念，这些概念是理解前述章节工作流程步骤所必需的。
- en: The data scientist's experience
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学家的经验
- en: 'The data scientist has a familiar experience in building H2O models at scale
    while being abstracted from the complexities of the infrastructure and architecture
    on the enterprise server cluster. This is further detailed in the following diagram:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家在构建H2O模型时具有熟悉的经验，同时抽象出企业服务器集群上基础设施和架构的复杂性。以下图表将进一步详细说明这一点：
- en: '![Figure 2.2 – Details of the data scientist''s experience with H2O Core'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.2 – 数据科学家使用H2O Core的经验细节'
- en: '](img/B16721_Figure_2.2.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_Figure_2.2.jpg)'
- en: Figure 2.2 – Details of the data scientist's experience with H2O Core
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – 数据科学家使用H2O Core的经验细节
- en: Data scientists use well-known unsupervised and supervised machine learning
    techniques that scale across the enterprise's distributed infrastructure and architecture.
    These techniques are written with the H2O model building API, which is written
    in familiar languages (such as Python, R, or Java) using familiar IDEs (for example,
    Jupyter or RStudio).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家使用在企业的分布式基础设施和架构中可扩展的知名无监督和监督机器学习技术。这些技术是用H2O模型构建API编写的，该API用熟悉的语言（如Python、R或Java）编写，并使用熟悉的IDE（例如Jupyter或RStudio）。
- en: H2O Flow – A Convenient, Optional UI
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: H2O Flow – 一个方便的、可选的UI
- en: H2O generates its own web UI called H2O Flow, which is optional to use during
    model building. H2O Flow's UI focus and richness of features can be used for a
    full model building workflow or to leverage for handy tricks, as we will demonstrate
    in [*Chapter 5*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082), *Advanced Model
    Building – Part 1*.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: H2O生成自己的Web UI，称为H2O Flow，在模型构建期间使用它是可选的。H2O Flow的UI焦点和功能丰富性可用于完整的模型构建工作流程，或者像我们在[*第5章*](B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082)中将要展示的，利用它进行一些实用的技巧，*高级模型构建
    – 第1部分*。
- en: Therefore, the data scientist works in a familiar world that connects to a complex
    architecture to scale model building to large or massive datasets. We will explore
    this architecture in the next section.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据科学家在一个熟悉的世界中工作，连接到一个复杂的架构，以扩展模型构建到大型或海量数据集。我们将在下一节中探讨这个架构。
- en: The H2O cluster
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: H2O集群
- en: 'The H2O cluster is perhaps the most central concept for all stakeholders to
    understand. It is how H2O creates its unit of architecture for building machine
    learning models on the enterprise server cluster. We can understand this concept
    using the following diagram:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: H2O集群可能是所有利益相关者需要理解的最核心概念。它是H2O在企业服务器集群上构建机器学习模型的架构单元。我们可以通过以下图表来理解这个概念：
- en: '![Figure 2.3 – The architecture of the H2O cluster'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.3 – H2O集群的架构'
- en: '](img/B16721_Figure_2.3.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16721_Figure_2.3.jpg)'
- en: Figure 2.3 – The architecture of the H2O cluster
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 – H2O集群的架构
- en: When a data scientist launches an H2O cluster, they specify the number of servers
    to distribute the work across (which is also known as the number of *nodes*),
    along with the amount of memory and CPUs to use for each node. We will learn that
    this can be done by configuring manually or by allowing Enterprise Steam to auto
    compute these specifications based on the volume of training data.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家启动一个H2O集群时，他们指定要分配工作到多少个服务器（这也就是所谓的节点数），以及每个节点要使用的内存和CPU数量。我们将了解到这可以通过手动配置或允许Enterprise
    Steam根据训练数据量自动计算这些规格来实现。
- en: When the H2O cluster is launched, the IDE pushes H2O software (a single JAR
    file) to each specified number of nodes in the enterprise server cluster, where
    each node allocates the specified memory and CPU. Then, the H2O software organizes
    into a self-communicating cluster with one node elected as the leader that communicates
    with the IDE and coordinates with the remainder of the H2O cluster.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 当H2O集群启动时，IDE会将H2O软件（一个单一的JAR文件）推送到企业服务器集群中指定的每个节点，每个节点分配指定的内存和CPU。然后，H2O软件组织成一个自我通信的集群，其中选出一个节点作为领导者，与IDE通信并协调H2O集群的其他部分。
- en: The data scientist connects to the launched H2O cluster from the IDE. Then,
    the data scientist writes the model building code. Each part of the code is translated
    by the H2O library in the IDE into instructions to the H2O cluster. Each instruction
    is sent, in sequence, to the leader node on the H2O cluster, which distributes
    it to other H2O cluster members where the instructions are executed in parallel.
    The leader node gathers and combines the results and sends them back to the IDE.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家从IDE连接到启动的H2O集群。然后，数据科学家编写模型构建代码。代码的每一部分都由IDE中的H2O库翻译成对H2O集群的指令。每个指令按顺序发送到H2O集群的领导者节点，该节点将其分配给其他H2O集群成员，在那里指令并行执行。领导者节点收集和合并结果，并将它们发送回IDE。
- en: 'Here are some important notes to bear in mind:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些重要的注意事项需要记住：
- en: Data is ingested directly from the data source to the memory of the H2O nodes.
    Source data is partitioned between the H2O nodes and not duplicated among them.
    Data ingested from the storage layer (for example, S3, HDFS, and more) is done
    in parallel and, therefore, is fast. Data from external sources (for example,
    the GitHub repository and the JDBC database tables) is not done in parallel. In
    all cases, data does not pass through the IDE or the client.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据直接从数据源摄入到H2O节点的内存中。源数据在H2O节点之间分区，并且不会在它们之间重复。从存储层（例如，S3、HDFS等）摄入的数据是并行进行的，因此速度快。来自外部源（例如，GitHub存储库和JDBC数据库表）的数据不是并行进行的。在所有情况下，数据都不会通过IDE或客户端。
- en: Each H2O cluster is independent and isolated from the others, including the
    data ingested into them. Thus, two users launching a cluster and using the same
    data source do not share data.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个H2O集群都是独立的，并且与其他集群隔离，包括它们所摄入的数据。因此，两个启动集群并使用相同数据源的用户不会共享数据。
- en: We will see that administrators of Enterprise Steam assign upper limits on the
    number of concurrent clusters that users can launch, along with the amount of
    memory, CPU, and other resources a user can specify when launching a cluster.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将看到，Enterprise Steam的管理员为用户可以启动的并发集群数量以及用户在启动集群时可以指定的内存、CPU和其他资源数量分配了上限。
- en: H2O clusters are static. Once launched, the number of nodes and the number of
    resources per node do not change until they are terminated, in which case the
    H2O cluster is torn down. If one of the nodes goes down, the H2O cluster must
    be restarted and model building steps from the IDE started from the beginning.
    For longer durations of work, H2O's checkpointing feature helps you to continue
    from a restore point.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H2O集群是静态的。一旦启动，节点数和每个节点的资源数量不会改变，直到它们被终止，在这种情况下，H2O集群将被拆解。如果一个节点宕机，H2O集群必须重新启动，并且从IDE开始模型构建步骤。对于更长时间的工作，H2O的检查点功能可以帮助您从恢复点继续。
- en: 'Let''s look at the life cycle of an H2O cluster, as shown in the following
    diagram:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下图中H2O集群的生命周期：
- en: '![Figure 2.4 – The life cycle of the H2O cluster'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 2.4 – H2O集群的生命周期'
- en: '](img/B16721_Figure_2.4.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_Figure_2.4.jpg](img/B16721_Figure_2.4.jpg)'
- en: Figure 2.4 – The life cycle of the H2O cluster
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 2.4 – H2O集群的生命周期
- en: 'Let''s look at each of the stages of the life cycle, one by one, to understand
    how they work:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一查看生命周期的各个阶段，以了解它们是如何工作的：
- en: '**Launch**: The data scientist launches an H2O cluster from the Enterprise
    Steam UI or API. H2O-3 or Sparkling Water is chosen. The H2O cluster size and
    resources (that is, the number of nodes, memory per node, and other configurations)
    are manually input, or they are automatically generated by Enterprise Steam based
    on the data volume input by the user. The H2O cluster is formed as described earlier.'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**启动**：数据科学家从企业蒸汽UI或API启动一个H2O集群。选择H2O-3或Sparkling Water。H2O集群的大小和资源（即节点数量、每个节点的内存以及其他配置）是手动输入的，或者由企业蒸汽根据用户输入的数据量自动生成。H2O集群的形成如前所述。'
- en: '**Connect to**: The data scientist switches to their IDE and connects to the
    H2O cluster by specifying its name.'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**连接到**：数据科学家切换到他们的IDE，并通过指定其名称来连接到H2O集群。'
- en: '**Build models on**: The data scientist builds models using H2O. The H2O library
    used in the IDE translates the H2O API code for each model building iteration
    into instructions. These are sent to the leader node and distributed across the
    H2O cluster.'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建模型于**：数据科学家使用H2O构建模型。在IDE中使用的H2O库将每个模型构建迭代的H2O API代码转换为指令。这些指令被发送到主节点并在H2O集群中分发。'
- en: '**Stop**: The H2O cluster is shut down. Resources are released, and the H2O
    software is removed from each node of the H2O cluster. This can be done by the
    user from the IDE or can occur automatically after a duration of idle time or
    when the absolute running time of the H2O cluster has been exceeded (these durations
    were specified in the H2O cluster launch during step 1 of the life cycle). Though
    not running, information regarding this cluster is still available to the user
    (for example, the name, the H2O version, and the size).'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**停止**：H2O集群被关闭。资源被释放，H2O软件从H2O集群的每个节点中移除。这可以通过用户从IDE完成，也可以在空闲时间超过一定时长或当H2O集群的绝对运行时间超过（这些时长在H2O集群启动时在步骤1中指定）后自动发生。尽管没有运行，但用户仍然可以访问有关此集群的信息（例如，名称、H2O版本和大小）。'
- en: '**Stop/Save Data & Restart**: This is an alternative to **Stop** and is possible
    when the Enterprise Steam administrator configures this option for a user or user
    group. In this case, when the H2O cluster is stopped, it saves data from the model
    building steps (that is, it saves the model building state) to the storage layer.
    When the cluster is restarted (using the same name as when it was launched), the
    cluster is launched and returned to its previous state.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**停止/保存数据 & 重新启动**：这是**停止**的替代方案，当企业蒸汽管理员为用户或用户组配置此选项时是可能的。在这种情况下，当H2O集群停止时，它会将模型构建步骤中的数据保存到存储层（即保存模型构建状态）。当集群重新启动（使用启动时的相同名称）时，集群启动并返回到其之前的状态。'
- en: '**Delete**: This stops the cluster (if running) and permanently deletes all
    references to the H2O cluster. If it has been stopped with the model building
    state saved, this data will be permanently deleted as well.'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**删除**：这停止了集群（如果正在运行）并永久删除了所有关于H2O集群的引用。如果它已经停止并保存了模型构建状态，这些数据也将被永久删除。'
- en: Enterprise Steam as an H2O gateway
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 企业蒸汽作为H2O网关
- en: 'All H2O administration activities occur on Enterprise Steam, and users must
    launch H2O clusters through Steam. This *all roads lead to Enterprise Steam* approach
    means that Steam governs users and their H2O clusters before they are launched
    on the enterprise system. This is detailed in the following diagram:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 所有H2O管理活动都在企业蒸汽上发生，用户必须通过Steam启动H2O集群。这种“条条大路通企业蒸汽”的方法意味着在用户在企业系统中启动之前，Steam管理用户及其H2O集群。这将在以下图中详细说明：
- en: '![Figure 2.5 – Enterprise Steam viewed as an H2O gateway to the enterprise
    cluster'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.5 – 将企业蒸汽视为企业集群的H2O网关'
- en: '](img/B16721_Figure_2.5.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16721_Figure_2.5.jpg)'
- en: Figure 2.5 – Enterprise Steam viewed as an H2O gateway to the enterprise cluster
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 – 将企业蒸汽视为企业集群的H2O网关
- en: Administrators configure settings to manage H2O users and integrate Enterprise
    Steam with the enterprise server cluster. Additionally, administrators store H2O
    software versions that will be pushed to the server cluster when H2O clusters
    are launched and removed when the cluster is stopped and the resources are released.
    Administrators also have access to user usage data. This is all done through an
    administration-only UI.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 管理员配置设置以管理H2O用户并集成企业蒸汽与企业服务器集群。此外，管理员存储将在启动H2O集群时推送到服务器集群的H2O软件版本，并在集群停止和资源释放时删除。管理员还可以访问用户使用数据。所有这些操作都通过仅管理员UI完成。
- en: Administrators configure users and how users launch H2O clusters in the enterprise
    environment. These configurations define limits on the number of concurrent clusters
    a user can launch simultaneously, the size (that is, the number of nodes), and
    the number of resources (for example, memory per node) allocated for each H2O
    cluster that is launched. Configurations also define when the cluster will stop
    or delete if the user does not do so manually from the H2O model building code
    in the IDE. A set of such configurations is defined as a profile, and one or more
    profiles are assigned to users or user groups. Therefore, administrators can assign
    some users as power users and others as light users.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 管理员配置用户和企业环境中用户如何启动 H2O 集群。这些配置定义了用户可以同时启动的并发集群数量、大小（即节点数）以及为每个启动的 H2O 集群分配的资源数量（例如，每个节点的内存）。配置还定义了如果用户没有从
    IDE 中的 H2O 模型构建代码手动停止或删除集群，集群将在何时停止或删除。一组此类配置被定义为配置文件，一个或多个配置文件被分配给用户或用户组。因此，管理员可以将一些用户指定为高级用户，而将其他用户指定为普通用户。
- en: Users authenticate to Enterprise Steam via the same identity provider (for example,
    LDAP) that was implemented to authorize access to resources on the enterprise
    server cluster environment (for example, S3 buckets). Enterprise Steam passes
    the user identity when the user launches a cluster, and this identity is used
    during authorization challenges on the enterprise system. Users in their IDEs
    must authenticate against the Enterprise Steam API to connect to the clusters
    they have launched.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 用户通过与企业服务器集群环境（例如，S3 存储桶）授权访问资源时实施的相同身份提供者（例如，LDAP）对企业蒸汽进行身份验证。当用户启动集群时，企业蒸汽传递用户身份，并在企业系统上的授权挑战期间使用此身份。在他们的
    IDE 中，用户必须对 Enterprise Steam API 进行身份验证，才能连接到他们启动的集群。
- en: Does H2O Core Require Enterprise Steam?
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 核心需要企业蒸汽吗？
- en: Note that H2O core does not require Enterprise Steam. Enterprise administrators
    can configure their enterprise server cluster infrastructure to allow H2O clusters
    to be launched on this infrastructure.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，H2O 核心不需要企业蒸汽。企业管理员可以配置他们的企业服务器集群基础设施，以允许在上述基础设施上启动 H2O 集群。
- en: However, this approach is not a sound enterprise practice. It introduces a loss
    of control and governance that Enterprise Steam provides as a centralized H2O
    gateway to secure, manage, and log users, as elaborated in this section. Additionally,
    Enterprise Steam provides benefits to users by freeing them from the technical
    steps involved with integrating H2O Core with the enterprise cluster when launching
    H2O clusters, for example, Kerberos security requirements. The enterprise benefits
    of Enterprise Steam are explored in greater detail in [*Chapter 11*](B16721_11_Final_SK_ePub.xhtml#_idTextAnchor207),
    *The Administrator and Operations Views*, and in [*Chapter 12*](B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226),
    *The Enterprise Architect and Security Views*.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法并不是一个可靠的企业实践。它引入了企业蒸汽作为集中式 H2O 网关所提供的控制和管理损失，如本节所述。此外，企业蒸汽通过在启动 H2O 集群时，使用户免于与
    H2O 核心与企业集群集成相关的技术步骤（例如，Kerberos 安全要求）来为用户提供便利。企业蒸汽的好处将在[*第 11 章*](B16721_11_Final_SK_ePub.xhtml#_idTextAnchor207)，“管理员和操作视图”，以及[*第
    12 章*](B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226)，“企业架构和安全视图”中更详细地探讨。
- en: Also, bear in mind that H2O Core is free and open source, whereas Enterprise
    Steam is not.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请记住，H2O 核心是免费和开源的，而企业蒸汽则不是。
- en: Enterprise Steam and the H2O Core high-level architecture
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 企业蒸汽和 H2O 核心高级架构
- en: 'Now that we know how H2O clusters are formed and the role Enterprise Steam
    plays in administering H2O users and launching H2O clusters, let''s understand
    Enterprise Steam and the H2O Core architecture from a high-level deployment perspective.
    The following diagram describes this deployment architecture:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了 H2O 集群是如何形成的，以及企业蒸汽在管理 H2O 用户和启动 H2O 集群中所起的作用，那么让我们从高级部署的角度来理解企业蒸汽和
    H2O 核心架构。以下图表描述了这种部署架构：
- en: '![Figure 2.6 – Enterprise Steam and the H2O Core high-level deployment architecture'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.6 – 企业蒸汽和 H2O 核心高级部署架构'
- en: '](img/B16721_Figure_2.6.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16721_Figure_2.6.jpg](img/B16721_Figure_2.6.jpg)'
- en: Figure 2.6 – Enterprise Steam and the H2O Core high-level deployment architecture
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – 企业蒸汽和 H2O 核心高级部署架构
- en: Enterprise Steam runs on its own dedicated server that communicates with the
    enterprise server cluster via HTTP(S). As mentioned earlier, Enterprise Steam
    stores the H2O Core (H2O-3 or Sparkling Water) JAR file that is pushed to the
    server cluster, which then self-organizes into a coordinated but distributed H2O
    cluster. This H2O cluster can be a native YARN or Kubernetes job, depending on
    which backend is implemented. Note that H2O-3 is run on a Map-Reduce framework,
    and Sparkling Water is run on the Spark framework.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Enterprise Steam 在其专用的服务器上运行，通过 HTTP(S) 与企业服务器集群通信。如前所述，Enterprise Steam 存储了推送到服务器集群的
    H2O Core (H2O-3 或 Sparkling Water) JAR 文件，然后该文件在服务器集群中自我组织成一个协调但分布式的 H2O 集群。这个
    H2O 集群可以是本地的 YARN 或 Kubernetes 作业，具体取决于实现了哪个后端。请注意，H2O-3 在 Map-Reduce 框架上运行，而
    Sparkling Water 在 Spark 框架上运行。
- en: An H2O-3 or Sparkling Water API library is installed to the data science IDE
    (for example, a `pip install` of the H2O-3 package in the Jupyter environment).
    It must match the version that is used to launch the cluster from Enterprise Steam.
    As mentioned previously, data scientists use the IDE to authenticate to Enterprise
    Steam, connect to the H2O cluster, and write H2O model building code. The H2O
    model building code is translated by the H2O client library into a REST message
    that is sent to the H2O cluster's leader node. Then, the work is distributed across
    the H2O cluster, and the results are returned to the IDE.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 安装了 H2O-3 或 Sparkling Water API 库到数据科学 IDE（例如，在 Jupyter 环境中执行 `pip install`
    H2O-3 包）。它必须与从 Enterprise Steam 启动集群所使用的版本相匹配。如前所述，数据科学家使用 IDE 认证到 Enterprise
    Steam，连接到 H2O 集群，并编写 H2O 模型构建代码。H2O 模型构建代码被 H2O 客户端库转换为发送到 H2O 集群首领节点的 REST 消息。然后，工作在
    H2O 集群中分发，并将结果返回到 IDE。
- en: Note that enterprise clusters can be on-premise, cloud infrastructure-as-a-service,
    or managed service implementations. They can be, for example, Kubernetes or Cloudera
    CDH on-premise or in the cloud, or Cloudera CDP or Amazon EMR in the cloud. The
    full deployment possibilities are discussed in more detail in [*Chapter 12*](B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226),
    *The Enterprise Architect and Security Views*.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，企业集群可以是本地、云基础设施即服务或托管服务实现。例如，可以是本地或云中的 Kubernetes 或 Cloudera CDH，或者云中的 Cloudera
    CDP 或 Amazon EMR。完整的部署可能性在 [*第 12 章*](B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226)，*企业架构师和安全视角*
    中有更详细的讨论。
- en: H2O Platform Choices
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 平台选择
- en: 'H2O At Scale technology in this book is referred to as comprising: H2O Enterprise
    Steam + H2O Core (H2O-3, H2O Sparkling Water) + H2O MOJO. H2O At Scale integrates
    with an enterprise server cluster for model building and an enterprise scoring
    environment for model deployment.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的 H2O At Scale 技术被称为包括：H2O Enterprise Steam + H2O Core (H2O-3, H2O Sparkling
    Water) + H2O MOJO。H2O At Scale 与企业服务器集群集成以进行模型构建，与企业评分环境集成以进行模型部署。
- en: H2O At Scale can be implemented with the just mentioned components alone. Alternatively,
    H2O At Scale can be implemented as a subset of the larger H2O machine learning
    platform and capability set called H2O AI Cloud. The H2O AI Cloud platform is
    described in greater detail in *Section 5 – Broadening the View – Data to AI Applications
    with the H2O AI Cloud Platform*.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: H2O At Scale 可以仅使用前面提到的组件实现。或者，H2O At Scale 可以作为更大的 H2O 机器学习平台和功能集 H2O AI Cloud
    的子集实现。H2O AI Cloud 平台在 *第 5 节 – 扩展视野 – 使用 H2O AI Cloud 平台将数据转换为 AI 应用程序* 中有更详细的描述。
- en: Sparkling Water allows users to code in H2O and Spark seamlessly
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sparkling Water 允许用户在 H2O 和 Spark 中无缝编码
- en: 'The following code shows a simple example of Spark and H2O integrated in the
    same H2O code using H2O Sparkling Water:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了使用 H2O Sparkling Water 在同一 H2O 代码中集成 Spark 的简单示例：
- en: '[PRE26]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The code shows Spark importing data, which is held as a **Spark DataFrame**.
    **Spark SQL** or the **Spark DataFrame** API is used to engineer this data into
    a new DataFrame and then this Spark DataFrame is converted into an **H2OFrame**
    from which H2O model building is performed. Therefore, the user is iterating seamlessly
    from Spark to H2O code in the same API language and IDE.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 代码展示了 Spark 导入数据，这些数据以 **Spark DataFrame** 的形式保存。使用 **Spark SQL** 或 **Spark
    DataFrame** API 将这些数据工程化为新的 DataFrame，然后将这个 Spark DataFrame 转换为 **H2OFrame**，从其中执行
    H2O 模型构建。因此，用户可以在相同的 API 语言和 IDE 中无缝地从 Spark 迭代到 H2O 代码。
- en: The idea of the H2O cluster is still fundamentally true for Sparkling Water.
    It now expresses the H2O cluster architecture within the Spark framework. Details
    of this architecture are elaborated in [*Chapter 12*](B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226),
    *The Enterprise Architect and Security Views*.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: H2O集群的概念在Sparkling Water中仍然根本正确。现在，它将在Spark框架内表达H2O集群架构。关于这个架构的详细信息在[*第12章*](B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226)，“企业架构和安全视图”中进行了阐述。
- en: MOJOs export as DevOps-friendly artifacts
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MOJOs导出为DevOps友好的工件
- en: Data scientists build models, but the end goal is to put models into a production
    environment where predictions are made in a business context. MOJOs make this
    last mile of deployment easy. MOJOs are exported by a single line of code. For
    example, whether the model was built using Python, R, or using a generalized linear
    model, an XGBoost model, or stacked ensemble, all MOJOs are identical from a DevOps
    perspective. This makes model deployment repeatable and, thus, capable of fitting
    into existing automated CI/CD pipelines that are used throughout the organization.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家构建模型，但最终目标是将这些模型部署到生产环境中，在商业环境中进行预测。MOJOs使得部署的最后一步变得简单。MOJOs可以通过一行代码导出。例如，无论模型是使用Python、R还是使用广义线性模型、XGBoost模型或堆叠集成构建的，从DevOps的角度来看，所有MOJOs都是相同的。这使得模型部署可重复，因此可以适应组织内部使用的现有自动化CI/CD管道。
- en: Summary
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we laid the foundation for understanding H2O machine learning
    at scale. We started by reviewing a bare minimum *Hello World* code example and
    discussed the problems of scale around it. Then, we introduced the H2O Core, Enterprise
    Steam, and MOJO technology components and how these can overcome problems of scale.
    Finally, we extracted a set of key concepts from these technologies to deepen
    our understanding.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们为理解H2O机器学习在规模上的应用奠定了基础。我们首先回顾了一个最基础的*Hello World*代码示例，并讨论了其周围的规模问题。然后，我们介绍了H2O
    Core、企业版Steam和MOJO技术组件，以及这些组件如何克服规模问题。最后，我们从这些技术中提取了一系列关键概念，以加深我们对这些技术的理解。
- en: In the next chapter, we will use this understanding to begin our journey of
    learning how to build and deploy world-class models at scale. Let the coding begin!
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将利用这些理解开始我们的学习之旅，学习如何以规模构建和部署世界级的模型。让我们开始编码吧！
