- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Identify Common Machine Learning Techniques
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别常见的机器学习技术
- en: So far, we’ve introduced you to AI technologies (such as computer vision or
    generative AI) as well as Microsoft’s principles for responsible AI. Now, it’s
    time to start talking about the substance of AI.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经向您介绍了人工智能技术（如计算机视觉或生成式AI）以及微软的负责任AI原则。现在，是时候开始讨论AI的实质了。
- en: One of the most important questions you might have about AI is how AI manages
    to know what it does. Just as humans learn, AI systems have been designed to be
    capable of learning. And, just like humans learn through a variety of mechanisms
    (such as memorization and practice or repetition), AI systems also learn through
    different techniques and scenarios.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能对AI的一个最重要的问题是AI如何知道它所做的事情。正如人类学习一样，AI系统被设计成具有学习能力。而且，就像人类通过各种机制（如记忆和实践或重复）学习一样，AI系统也通过不同的技术和场景学习。
- en: 'To be honest, though, the term **machine learning** is a bit of a misnomer.
    Since computers aren’t exactly sentient at this point, one might argue that they’re
    not capable of really learning. What they are capable of, however, is something
    quite useful: examining vast data sets to establish patterns and predict outcomes.
    Humans can sometimes be pretty good at recognizing patterns for small data sets.
    Once the data set includes tens of thousands or millions of data points, it becomes
    much more difficult for a human to keep up—and this is where machine learning
    excels.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 老实说，尽管“机器学习”这个术语有点名不副实。因为到目前为止，计算机并不完全具有意识，所以有人可能会认为它们实际上不具备真正的学习能力。然而，它们能够做到的却非常有用：检查大量数据集以建立模式和预测结果。人类有时在识别小数据集的模式方面可能相当出色。一旦数据集包含成千上万或数百万个数据点，人类就很难跟上——这正是机器学习擅长的领域。
- en: 'The core idea of machine learning is looking at these vast data sets and predicting
    outcomes or values of similar actions or scenarios. Examples of machine learning
    might include the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的核心思想是查看这些大量数据集，并预测类似行动或场景的结果或值。以下是一些机器学习示例：
- en: A power company combining historical weather patterns and historical energy
    usage to estimate the load on an electric grid
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一家电力公司结合历史天气模式和历史能源使用情况来估计电网的负载
- en: An insurance company using miles driven, whether driven hours are daylight or
    nighttime, and driver age to predict the likelihood of an accident
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一家保险公司使用行驶里程、驾驶时间是否为白天或夜间以及驾驶员年龄来预测事故发生的可能性
- en: A biologist researcher using visual data of animals to automate the identification
    of known species observed on cameras and highlight potentially unknown species
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一位生物学家研究人员使用动物的视频数据来自动识别相机上观察到的已知物种，并突出可能未知物种
- en: In each of these cases, an AI system is trained on known data sets and then
    either asked questions or exposed to new data and is instructed to apply its past
    observations on the new data or queries to come up with new outputs or results.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些案例中，AI系统在已知数据集上进行训练，然后要么被提问，要么接触到新数据，并被指示将过去的观察应用于新数据或查询，以产生新的输出或结果。
- en: 'In this chapter, we’ll cover some of the high-level concepts related to machine
    learning. The objectives and skills we’ll cover in this chapter include the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍一些与机器学习相关的高级概念。本章我们将涵盖以下目标和技能：
- en: Identify regression machine learning scenarios
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别回归机器学习场景
- en: Identify classification machine learning scenarios
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别分类机器学习场景
- en: Identify clustering machine learning scenarios
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别聚类机器学习场景
- en: Identify features of deep learning techniques
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别深度学习技术的特征
- en: By the end of this chapter, you should be able to identify and describe some
    of the common machine learning scenarios.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该能够识别并描述一些常见的机器学习场景。
- en: First, let’s establish a little background information on machine learning.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们对机器学习做一些背景介绍。
- en: Understanding machine learning terminology
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解机器学习术语
- en: As you’ve already learned, machine learning is another way to think about predicting
    outcomes based on observed data sets.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所知，机器学习是另一种基于观察数据集预测结果的方法。
- en: 'Machine learning models are essentially software applications that use mathematical
    functions to calculate output values based on input values. This process involves
    two main phases: **training** and **inferencing**.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型本质上是一种软件应用，它使用数学函数根据输入值计算输出值。这个过程涉及两个主要阶段：**训练**和**推理**。
- en: Training
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: During training, the model learns to predict output values based on input values
    by analyzing past observations. These past observations include both the **features**
    (input values) and **labels** (output values).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，模型通过分析过去的观察结果来学习预测输出值。这些过去的观察结果包括 **特征**（输入值）和 **标签**（输出值）。
- en: In a typical scenario, features are represented as variables denoted by *x*,
    while labels are denoted by *y*. Features can consist of multiple values, forming
    a **vector** represented by *[x1, x2, x3, ...],y*. For example, in predicting
    bottled water sales based on weather, weather measurements are features (*x*)
    and the number of bottles sold is the label (*y*).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在典型场景中，特征由表示为 *x* 的变量表示，而标签由表示为 *y* 的变量表示。特征可以由多个值组成，形成一个由 *[x1, x2, x3, ...],y*
    表示的 **向量**。例如，在根据天气预测瓶装水销售时，天气测量值是特征 (*x*)，而销售的瓶装水数量是标签 (*y*)。
- en: An **algorithm** is then applied to the data to establish a relationship between
    the features and labels, creating a calculation to predict the label based on
    the features. The choice of algorithm depends on the type of predictive problem
    being addressed. The outcome is a **model** represented by a function *f*, where
    *y =* *f(x)*.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将算法应用于数据，以建立特征和标签之间的关系，创建一个基于特征预测标签的计算。算法的选择取决于要解决的问题类型。结果是表示为函数 *f* 的 **模型**，其中
    *y =* *f(x)*。
- en: What are vectors and algorithms, anyway?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 向量和算法究竟是什么？
- en: Vectors, foundational units of algebra, are essentially **tuples** (or collections)
    of values. These groups of values can be thought of as being similar to an array,
    though tuples can contain mixed data types such as strings, floating point numbers,
    and integers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 向量，代数的基础单元，实际上是 **元组**（或值的集合）。这些值组可以被视为类似于数组，尽管元组可以包含混合数据类型，如字符串、浮点数和整数。
- en: At a high level, an algorithm is a set of functions, rules, formulas, or processes
    that an AI system uses to analyze data, discover insights, and predict outcomes.
    Algorithms represent the math that enables machine learning.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，算法是一组函数、规则、公式或过程，AI系统使用它们来分析数据、发现洞察力和预测结果。算法代表了使机器学习成为可能的数学。
- en: 'The learning part of machine learning can be divided into two types: **supervised**
    and **unsupervised**. Each of these types has a variety of algorithms and processes
    associated with them.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的“学习”部分可以分为两种类型：**监督**和**无监督**。每种类型都与各种算法和过程相关联。
- en: Supervised machine learning techniques
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督机器学习技术
- en: 'Supervised machine learning encompasses algorithms that learn from data containing
    both input features and corresponding target labels. The goal is to uncover patterns
    that link the input features to their outcomes, enabling the model to forecast
    outcomes for new, unseen data. Let’s look at types of supervised learning techniques:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习包括从包含输入特征和相应目标标签的数据中学习的算法。目标是揭示将输入特征与其结果相联系的模式，使模型能够预测新、未见过的数据的结果。让我们看看监督学习技术的类型：
- en: Regression
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 回归
- en: '**Regression**-based learning is designed to identify and understand the relationship
    between independent and dependent variables and is frequently used to make business
    projections. Regression is a type of supervised learning where the output is a
    continuous number. Examples include the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归**-基于的学习旨在识别和理解自变量与因变量之间的关系，并常用于进行商业预测。回归是一种监督学习，其输出是一个连续的数字。以下是一些例子：'
- en: Predicting bottled water sales based on weather conditions such as temperature
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据温度等天气条件预测瓶装水销售
- en: Estimating a dealership’s vehicle sales prices from amount of available inventory
    and previous sales prices
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据可用库存量和历史销售价格估算经销商的汽车销售价格
- en: Classification
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分类
- en: '**Classification** uses an algorithm to assign the training data to categories.
    Classification identifies or recognizes entities in the training data and attempts
    to draw conclusions about how the entities are defined or labeled. Classification
    involves categorizing data points into distinct classes:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类**使用算法将训练数据分配到类别中。分类识别或识别训练数据中的实体，并试图得出关于实体如何定义或标记的结论。分类涉及将数据点分类到不同的类别中：'
- en: '**Binary classification**: This predicts one of two possible outcomes. Examples
    include diagnosing diabetes from health metrics, assessing loan default risk from
    financial history, and predicting marketing response from consumer profiles.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二元分类**：这预测两种可能结果中的一种。例如，根据健康指标诊断糖尿病，根据财务历史评估贷款违约风险，或根据消费者档案预测营销响应。'
- en: '**Multiclass classification**: This predicts which one of several classes an
    observation belongs to. For instance, classifying an animal species based on physical
    features or a movie’s genre from its production details. Unlike binary classification,
    a single observation in multiclass classification is assigned to one exclusive
    category.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多类分类**：这预测一个观察值属于几个类别中的哪一个。例如，根据物理特征对动物物种进行分类，或根据制作细节对电影类型进行分类。与二元分类不同，多类分类中的单个观察值被分配到一个唯一的类别。'
- en: Algorithms
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 算法
- en: 'As you’ve already learned, algorithms are the mathematical formulas used to
    process data. From a supervised learning perspective, these algorithms are commonly
    used:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你已经学到的，算法是用于处理数据的数学公式。从监督学习的角度来看，这些算法通常被使用：
- en: '**AdaBoost** and **gradient boosting**: These methods enhance the accuracy
    of simple models by aggregating them into a more robust model. By sequentially
    correcting errors of a basic model using additional weak models, they collectively
    improve prediction accuracy. Boosting models can be applied to both classification
    and regression problems.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AdaBoost**和**梯度提升**：这些方法通过将简单模型聚合为更稳健的模型来提高其准确性。通过使用额外的弱模型按顺序纠正基本模型的错误，它们共同提高了预测准确性。提升模型可以应用于分类和回归问题。'
- en: '**Artificial Neural Networks** (**ANNs**): ANNs are inspired by the human brain’s
    neural networks and are foundational to deep learning. They process data through
    interconnected units called neurons, learning to recognize patterns and make decisions
    over time. ANNs are used in a variety of contexts, such as natural language processing,
    speech and image recognition, and game-playing (such as chess and Go).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工神经网络**（**ANNs**）：ANNs受到人脑神经网络灵感的启发，是深度学习的基础。它们通过称为神经元的相互连接的单元处理数据，随着时间的推移学习识别模式和做出决策。ANNs在各种环境中得到应用，例如自然语言处理、语音和图像识别以及游戏（如象棋和国际象棋）。'
- en: '**Decision trees**: These algorithms predict outcomes or classify data by breaking
    down decisions into a tree-like structure of choices. Decision trees are transparent,
    making them easier to understand and validate compared to more opaque models such
    as neural networks. You might picture a decision tree as a type of flow chart,
    as shown in *Figure 3**.1*:'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策树**：这些算法通过将决策分解成类似树状结构的选项来预测结果或对数据进行分类。决策树是透明的，与更不透明的模型（如神经网络）相比，它们更容易理解和验证。你可以将决策树想象成一种流程图，如图*图3.1*1*所示：'
- en: '![Figure 3.1 – Example of a simple decision tree](img/B22207_03_01.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1 – 简单决策树的示例](img/B22207_03_01.jpg)'
- en: Figure 3.1 – Example of a simple decision tree
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – 简单决策树的示例
- en: '**Dimensionality reduction**: This technique reduces the complexity of data
    by decreasing the number of input features, focusing on retaining only the most
    relevant information. Principal component analysis is a common method used for
    this purpose.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降维**：这种技术通过减少输入特征的数量来降低数据的复杂性，专注于仅保留最相关的信息。主成分分析是用于此目的的常用方法。'
- en: '**K-Nearest Neighbor** (**KNN**): KNN classifies data points based on the closest
    neighboring points in the data set. It calculates the distance (often Euclidean)
    between points and assigns a category based on the most common category among
    its nearest neighbors. KNN makes predictions based on the majority or average
    value of the nearest data points.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**K-最近邻**（**KNN**）：KNN根据数据集中最近的邻近点对数据点进行分类。它计算点之间的距离（通常是欧几里得距离），并根据其最近邻中最常见的类别分配一个类别。KNN根据最近数据点的多数或平均值做出预测。'
- en: '**Linear regression**: This approach models the relationship between a dependent
    variable and one or more independent variables to predict continuous outcomes.
    Simple linear regression involves just one independent and one dependent variable.
    An example of a linear regression might be predicting house prices based on its
    square footage.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性回归**：这种方法通过建立一个或多个自变量与因变量之间的关系来预测连续结果。简单线性回归只涉及一个自变量和一个因变量。线性回归的一个例子可能是根据房屋的面积预测房价。'
- en: '**Logistic regression**: Used for binary outcomes (e.g., yes/no, true/false),
    logistic regression models the probability of a categorical dependent variable
    based on one or more independent variables, ideal for binary classification tasks.
    Logistic regression can be used in spam email detection by building a model based
    on the features of messages such as keywords that indicate spam content, source
    IP address, length of the email, volume of misspelled words, or other characteristics.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逻辑回归**：用于二元结果（例如，是/否、真/假），逻辑回归模型基于一个或多个独立变量对分类因变量的概率进行建模，非常适合二元分类任务。逻辑回归可以通过构建基于消息特征的模型（如表示垃圾邮件内容的关键词、源IP地址、电子邮件长度、错别字数量或其他特征）用于垃圾邮件检测。'
- en: '**Naïve Bayes**: Based on Bayes’ theorem, this technique assumes independence
    among predictors and is effective for text classification, spam detection, and
    recommendation systems. Variants include multinomial, Bernoulli, and Gaussian
    Naïve Bayes. Bayes algorithms are frequently used in text classification tasks
    such as spam detection and sentiment analysis.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**朴素贝叶斯**：基于贝叶斯定理，该技术假设预测因子之间相互独立，对于文本分类、垃圾邮件检测和推荐系统非常有效。变体包括多项式、伯努利和高斯朴素贝叶斯。贝叶斯算法常用于文本分类任务，如垃圾邮件检测和情感分析。'
- en: '**Random forests**: This ensemble method uses multiple decision trees to make
    more reliable and accurate predictions by averaging their results, effectively
    reducing overfitting and variance in predictions. A common use case of a random
    forest algorithm might be detecting if a customer is likely to leave a subscription
    service (or churn) based on a number of features (number of calls made to support,
    length of calls, length of subscription service, telemetry data of how often the
    service used). Each of those features can be evaluated in a decision tree and
    then used together to predict a customer’s churn potential.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林**：这种集成方法通过平均多个决策树的结果，从而做出更可靠和准确的预测，有效地减少了过拟合和预测中的方差。随机森林算法的一个常见用例可能是根据多个特征（如支持部门电话次数、通话时长、订阅服务时长、服务使用频率的遥测数据）检测客户是否可能离开订阅服务（或流失）。每个这些特征都可以在决策树中进行评估，然后一起用来预测客户的流失潜力。'
- en: '**Support Vector Machines** (**SVM**): SVMs are used for classification and
    regression by finding the optimal boundary (hyperplane) that maximizes the margin
    or distance between different classes of data points, enhancing the model’s discriminative
    power. Imagine you have a collection of points on a graph that you need to divide
    into two groups. An SVM would determine how to draw a line that best separates
    them. The optimal line path would be one that divides the points on the plane,
    maximizing the gaps between the line and points. See *Figure 3**.2* for a very
    simple example:'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVM**）：SVM通过找到最大化不同类别数据点之间间隔（超平面）的最优边界来用于分类和回归，增强了模型的判别能力。想象一下，你有一组在图上的点，需要将它们分成两组。SVM将确定如何绘制一条最佳分离线。最优的线路径将是最大化线与点之间间隔的线。请参见*图3.2*中的一个非常简单的例子：'
- en: '![Figure 3.2 – Simple representation of a support vector machine model](img/B22207_03_02.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2 – 支持向量机模型简单表示](img/B22207_03_02.jpg)'
- en: Figure 3.2 – Simple representation of a support vector machine model
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – 支持向量机模型简单表示
- en: Further reading
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: While you won’t see all of these individual algorithms on the AI-900 exam, they’re
    neat to learn about. You can explore the basic mathematical concepts behind many
    of these algorithms at sites such as [https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/](https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)
    and [https://www.kdnuggets.com/a-beginner-guide-to-the-top-10-machine-learning-algorithms](https://www.kdnuggets.com/a-beginner-guide-to-the-top-10-machine-learning-algorithms).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在AI-900考试中你不会看到所有这些个别算法，但了解它们是很有趣的。你可以在诸如[https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/](https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)和[https://www.kdnuggets.com/a-beginner-guide-to-the-top-10-machine-learning-algorithms](https://www.kdnuggets.com/a-beginner-guide-to-the-top-10-machine-learning-algorithms)等网站探索这些算法背后的基本数学概念。
- en: Unsupervised machine learning techniques
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无监督机器学习技术
- en: Unsupervised learning models are trained on data without labels, aiming to find
    underlying patterns or groupings in the data based on similarities.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习模型在无标签的数据上进行训练，旨在根据数据中的相似性找到潜在的模式或分组。
- en: '**Clustering** is a primary technique in unsupervised learning that groups
    data points based on feature similarities. Examples include categorizing different
    types of flowers or segmenting customers by purchasing habits. Unlike classification,
    clustering does not require pre-defined categories; the algorithm identifies these
    groups autonomously. Clustering can also be a preliminary step to define classes
    for a subsequent classification model, such as segmenting customers into categories
    for targeted marketing strategies.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类**是无监督学习中的一个主要技术，它根据特征相似性将数据点分组。例如，将不同类型的花朵分类或根据购买习惯对客户进行细分。与分类不同，聚类不需要预定义的类别；算法自主识别这些组。聚类也可以是定义后续分类模型类别的初步步骤，例如将客户细分到针对营销策略的类别中。'
- en: Semi-supervised machine learning techniques
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 半监督机器学习技术
- en: Semi-supervised learning occupies a space between supervised and unsupervised
    learning. This technique combines both aspects of supervised learning (providing
    labeled input data) as well as unsupervised learning (training with unlabeled
    data).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习位于监督学习和无监督学习之间。这种技术结合了监督学习的两个方面（提供标记的输入数据）以及无监督学习（使用未标记的数据进行训练）。
- en: Inferencing
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理
- en: Once the training phase is complete, the model can be used for **inferencing**
    or making predictions. The model acts as a software program encapsulating the
    learned function, allowing users to input feature values and receive predictions
    of corresponding labels. The predicted label is represented by *ŷ* (pronounced
    “y-hat”) to distinguish it from observed values.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练阶段完成，模型就可以用于**推理**或做出预测。该模型作为一个封装了学习到的函数的软件程序，允许用户输入特征值并接收对应标签的预测。预测标签用*ŷ*（发音为“y-hat”）表示，以区别于观察值。
- en: Understanding machine learning involves grasping these fundamental concepts
    of training and inferencing, as well as recognizing the role of algorithms in
    establishing predictive relationships between features and labels. By applying
    mathematical functions to data, machine learning models can make predictions and
    facilitate decision-making in various domains, from weather forecasting to medical
    diagnosis.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 理解机器学习需要掌握训练和推理的基本概念，以及认识到算法在建立特征与标签之间预测关系中的作用。通过将数学函数应用于数据，机器学习模型可以做出预测，并促进从天气预报到医疗诊断等各个领域的决策制定。
- en: Identify regression machine learning scenarios
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别回归机器学习场景
- en: Regression models aim to forecast numerical outcomes using training data that
    encompasses input features along with their corresponding target values. The development
    of a regression model, as with any supervised learning approach, unfolds through
    several cycles. In each cycle, you select a suitable algorithm—often configurable
    with various parameters—to build the model. You then assess how well the model
    predicts outcomes and adjust it by experimenting with alternative algorithms and
    tuning the parameters. This iterative process continues until the model reaches
    a satisfactory level of prediction accuracy.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型旨在使用包含输入特征及其对应目标值的训练数据来预测数值结果。与任何监督学习方法一样，回归模型的发展通过几个周期展开。在每个周期中，你选择一个合适的算法——通常可以配置各种参数——来构建模型。然后，你评估模型预测结果的好坏，并通过尝试不同的算法和调整参数来调整它。这个过程会持续进行，直到模型达到令人满意的预测准确度水平。
- en: 'The overall process for regression training is as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 回归训练的整体过程如下：
- en: Divide the training data randomly to form a training set for model development,
    reserving a portion for model validation. For example, consider setting aside
    30-50% of the training data to test against later.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机划分训练数据以形成用于模型开发的训练集，并保留一部分用于模型验证。例如，可以考虑预留30-50%的训练数据以供后续测试。
- en: Employ a fitting algorithm, such as linear regression for regression models,
    to construct the model based on the training set.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用合适的算法，例如线性回归，根据训练集构建模型。
- en: Then, use the set aside validation data from *step 1* to evaluate the model’s
    effectiveness by making predictions and comparing these predicted values against
    the actual labels in the validation set.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用预留的验证数据从*步骤 1*开始评估模型的有效性，通过做出预测并将这些预测值与验证集中的实际标签进行比较。
- en: Summarize the discrepancies between predicted and actual values to derive a
    performance metric reflecting the model’s prediction accuracy.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总结预测值与实际值之间的差异，以得出反映模型预测准确度的性能指标。
- en: Iterate this train–validate–evaluate cycle, experimenting with various algorithms
    and settings, until the model’s performance matches your expectations.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迭代这个训练-验证-评估周期，尝试不同的算法和设置，直到模型的表现符合你的期望。
- en: Through these steps, you can build regression models to predict a number of
    real-world scenarios.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些步骤，你可以构建回归模型来预测许多现实世界的场景。
- en: Example
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: Earlier, we discussed an example of predicting bottled water sales based on
    how warm it is. To see how regression training works, let’s dive into the bottled
    water sales example.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们讨论了基于天气温暖程度预测瓶装水销售的例子。为了了解回归训练是如何工作的，让我们深入瓶装水销售的例子。
- en: Let’s say you want to predict, based on the outside temperature, how many bottles
    of water you anticipate selling. This would be important to you as a vendor since
    it helps you understand how much you need to stock to meet the demand.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想根据室外温度预测你预计会售出多少瓶水。这对作为供应商的你来说很重要，因为它有助于你了解你需要储备多少才能满足需求。
- en: 'First, you need to gather historical data that will be used to train the model
    (as well as validate the model later). Take the following sample data set in *Table
    3.1*—it captures two critical pieces of data: how many bottles of water sold (*y*)
    at a given temperature (*x*):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要收集用于训练模型（以及后来验证模型）的历史数据。请参考*表3.1*中的以下样本数据集——它捕捉了两个关键数据点：在给定温度下售出的瓶装水数量（*y*）：
- en: '| **Sample** | **Temperature (x)** | **Bottled water** **sales (y)** |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| **样本** | **温度 (x)** | **瓶装水销售 (y)** |'
- en: '| --- | --- | --- |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | 50 | 0 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 50 | 0 |'
- en: '| 2 | 53 | 1 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 53 | 1 |'
- en: '| 3 | 62 | 5 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 62 | 5 |'
- en: '| 4 | 63 | 7 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 63 | 7 |'
- en: '| 5 | 65 | 9 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 65 | 9 |'
- en: '| 6 | 68 | 12 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 68 | 12 |'
- en: '| 7 | 70 | 18 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 70 | 18 |'
- en: '| 8 | 74 | 22 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 74 | 22 |'
- en: '| 9 | 77 | 28 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 77 | 28 |'
- en: '| 10 | 84 | 36 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 84 | 36 |'
- en: '| 11 | 64 | 7 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 64 | 7 |'
- en: '| 12 | 78 | 33 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 78 | 33 |'
- en: '| 13 | 81 | 34 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 81 | 34 |'
- en: '| 14 | 79 | 31 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 79 | 31 |'
- en: '| 15 | 54 | 2 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 54 | 2 |'
- en: Table 3.1 – Bottled water sales
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.1 – 瓶装水销售
- en: The next step is to select the amount of data that we’ll use for training and
    the amount we’ll set aside for validation and testing. Let’s go ahead and take
    the first 10 rows for training our fictional model, leaving the last 5 rows for
    validation.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是选择我们将用于训练的数据量以及我们将留出的用于验证和测试的数据量。让我们先取前10行来训练我们的虚构模型，留下最后5行用于验证。
- en: In this case, an easy way to understand the relationship between temperature
    and bottles of water sold is to plot them on a simple graph, as shown in *Figure
    3**.3*.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，理解温度和售出瓶装水之间关系的一个简单方法是将它们绘制在简单的图表上，如图*图3**.3*所示。
- en: '![Figure 3.3 – Temperature and bottles of water sold plotted on a graph](img/B22207_03_03.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3 – 温度和售出瓶装水在图上绘制](img/B22207_03_03.jpg)'
- en: Figure 3.3 – Temperature and bottles of water sold plotted on a graph
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 – 温度和售出瓶装水在图上绘制
- en: 'Through the training process, an algorithm applies a formula or function to
    calculate the value of *y* from the value of *x*. In this case, the algorithm
    used would be one of linear regression—one that calculates a straight line through
    the points. See *Figure 3**.4*:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，算法将公式或函数应用于计算*y*的值，其中*y*是从*x*的值中得出的。在这种情况下，所使用的算法将是线性回归中的一种——它通过点计算一条直线。见图*图3**.4*：
- en: '![Figure 3.4 – Linear regression](img/B22207_03_04.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图3.4 – 线性回归](img/B22207_03_04.jpg)'
- en: Figure 3.4 – Linear regression
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 – 线性回归
- en: As you can see from the graph, for every degree of change, the historical data
    trends upward. The slope can be expressed using the equation *y* = 1.11*x* – 60.02,
    where *x* is the temperature and *y* is the number of water bottles sold. Put
    another way, starting at 60 degrees, for every 1 degree increase in temperature,
    the number of water bottles sold increases by 1.11.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中可以看出，对于每度的变化，历史数据趋势上升。斜率可以用方程*y* = 1.11*x* – 60.02表示，其中*x*是温度，*y*是售出的水瓶数量。换句话说，从60度开始，每增加1度温度，售出的水瓶数量增加1.11。
- en: 'Given this formula that’s been developed, the next step is to test the formula
    based on the remaining data in the training set. In this example, the additional
    data left in the training set has been plotted on the same graph and a linear
    regression run against them as well:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发出这个公式后，下一步是根据训练集中的剩余数据测试该公式。在这个例子中，训练集中剩余的数据已经绘制在同一图表上，并对它们进行了线性回归分析：
- en: '![Figure 3.5 – Validation data set composited on to original graph](img/B22207_03_05.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图3.5 – 验证数据集组合到原始图上](img/B22207_03_05.jpg)'
- en: Figure 3.5 – Validation data set composited on to original graph
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – 验证数据集复合到原始图上
- en: To test the formula, you could take a value from the held back training data
    (such as 81 degrees) and project the number of water bottles sold by calculating
    *y* = 1.11(81) – 60.02, which results in 30 water bottles (or 29.91 rounded up
    to the next whole number).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试公式，你可以从保留的训练数据中取一个值（例如81度）并通过计算 *y* = 1.11(81) – 60.02来预测卖出的水瓶数量，结果为30个水瓶（或四舍五入到下一个整数的29.91个）。
- en: 'You can repeat that process for every temperature value held back in the data
    set, using the function to calculate a prediction for the number of water bottles
    sold. See *Table 3.2* for an example:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以对数据集中保留的每个温度值重复这个过程，使用该函数计算卖出的水瓶数量的预测。见*表3.2*中的示例：
- en: '| **Sample** | **Temperature** | **Bottles of** **water sold** | **Prediction**
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| **样本** | **温度** | **卖出的水瓶** | **预测** |'
- en: '| 11 | 64 | 7 | 12 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 64 | 7 | 12 |'
- en: '| 12 | 78 | 33 | 27 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 78 | 33 | 27 |'
- en: '| 13 | 81 | 34 | 29 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 81 | 34 | 29 |'
- en: '| 14 | 79 | 31 | 28 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 79 | 31 | 28 |'
- en: '| 15 | 54 | 2 | 0 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 54 | 2 | 0 |'
- en: Table 3.2 – Predicting the water bottles sold with the training data
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.2 – 使用训练数据预测卖出的水瓶数量
- en: How do you express the accuracy of the model? If you’re not sure how accurate
    your model is, read on! There are a few metrics that can be used to help understand
    how accurate (or inaccurate) the model and its predictions are.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何表达模型的准确性？如果你不确定你的模型有多准确，请继续阅读！有一些指标可以帮助你理解模型及其预测的准确性（或不准确性）。
- en: Evaluation metrics
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估指标
- en: Evaluation metrics are statistical formulas used to evaluate the validity of
    predictions against a data set.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标是用于评估预测对数据集有效性的统计公式。
- en: Mean Absolute Error (MAE)
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 均绝对误差 (MAE)
- en: This **mean absolute error** (**MAE**) represents how many units of variance
    there are (either positive or negative) on average. For example, in sample *11*
    from *Table 3.2*, the prediction was to sell 12 bottles of water. The actual value
    sold (based on the training data) was seven, meaning that the prediction was five
    units higher than actual. This variance is known as the **absolute error**. In
    sample 12, the prediction was for 27 bottles to be sold, but the actual number
    sold was 33 (6 units higher, or an absolute error of 6).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这个**均绝对误差**（**MAE**）表示平均上有多少单位的方差（无论是正数还是负数）。例如，在表3.2中的样本11，预测卖出12瓶水。实际卖出的数量（基于训练数据）是7，这意味着预测比实际高出5个单位。这种方差被称为**绝对误差**。在样本12中，预测卖出27瓶水，但实际卖出的数量是33（高出6个单位，或绝对误差为6）。
- en: 'To calculate the MAE, add up all the absolute error values and divide by the
    number of samples in the validation set. In this case:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算MAE，将所有绝对误差值相加，然后除以验证集中的样本数量。在这种情况下：
- en: '| **Sample** | **Bottles of** **water sold** | **Prediction** **(ŷ)** | **Absolute
    error** |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| **样本** | **卖出的水瓶** | **预测** **(ŷ)** | **绝对误差** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 11 | 7 | 12 | 5 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 7 | 12 | 5 |'
- en: '| 12 | 33 | 27 | 6 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 33 | 27 | 6 |'
- en: '| 13 | 34 | 29 | 5 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 34 | 29 | 5 |'
- en: '| 14 | 31 | 28 | 4 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 31 | 28 | 4 |'
- en: '| 15 | 2 | 0 | 2 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 2 | 0 | 2 |'
- en: Table 3.3 – Absolute error table
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.3 – 绝对误差表
- en: The total of all of the absolute errors is 22, and the number of items in the
    validation set was 5, resulting in an MAE for the validation set of 4.4 (22 divided
    by 5).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 所有绝对误差的总和为22，验证集的项目数量为5，因此验证集的MAE为4.4（22除以5）。
- en: Mean squared error
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 均方误差
- en: One of the drawbacks of the mean absolute error is that it treats all discrepancies
    equally. While the overall average error rate may be acceptable, there are industries
    or scenarios where it’s more desirable to have more (but smaller) errors as opposed
    to fewer (but larger) errors. For example, with fresh produce, it’s very undesirable
    to overstock because you have a higher likelihood of having to throw away larger
    quantities of expired food.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 均绝对误差的一个缺点是它平等地对待所有差异。虽然整体平均误差率可能是可接受的，但在某些行业或场景中，更希望有更多（但更小）的误差，而不是更少（但更大）的误差。例如，对于新鲜农产品，过度库存是非常不希望的，因为你更有可能需要丢弃大量过期的食物。
- en: The **mean squared error** (**MSE**) functions as a measure of the quality of
    the model itself. This metric gives individual errors more weight—and larger error
    predictions in the training data result in a much higher MSE.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**均方误差**（**MSE**）作为衡量模型本身质量的一个指标。这个指标给个别误差更多的权重——训练数据中的较大误差预测会导致均方误差显著增加。'
- en: To calculate this, each absolute error value is squared, and then the sum of
    those values is averaged. Using the training data output in *Table 3.3*, the mean
    squared error value is 21.2, highlighting the fact that the model may need tweaking
    or more training data.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算这个值，每个绝对误差值被平方，然后这些值的总和被平均。使用 *表 3.3* 中的训练数据输出，均方误差值为 21.2，突显出模型可能需要调整或更多训练数据。
- en: Root Mean Squared Error (RMSE)
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 均方根误差 (RMSE)
- en: The next metric is **root mean squared error**, which is the square root of
    the MSE. While the MSE provides a measure of the quality of the predictor function,
    the RMSE is converted back to the original unit, making it a little easier to
    interpret and communicate the model’s performance. RMSE is sensitive to outliers
    and gives relatively high weight to large errors. Like MSE, a smaller RMSE indicates
    a better fit.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个指标是**均方根误差**，它是均方误差的平方根。虽然均方误差提供了预测函数质量的度量，但 RMSE 被转换回原始单位，这使得它更容易解释和传达模型的表现。RMSE
    对异常值敏感，并给予较大的误差相对较高的权重。像 MSE 一样，较小的 RMSE 指示更好的拟合。
- en: With our validation data set, the RMSE is 4.6.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的验证数据集，RMSE 为 4.6。
- en: Coefficient of determination
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 决定系数
- en: The **coefficient of determination**, known as *R*2, measures how well a statistical
    model predicts the actual outcome. It’s a score between 0 and 1 that tells us
    the percentage of the variation in our target variable (what we’re trying to predict)
    that can be explained by the model. A score of 1 means the model predicts perfectly,
    with no difference between predicted and actual values, while a score of 0 means
    the model doesn’t explain any of the variation.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**决定系数**，也称为 *R*2，衡量统计模型预测实际结果的好坏。它是一个介于 0 和 1 之间的分数，告诉我们模型可以解释的目标变量（我们试图预测的变量）的变化百分比。得分为
    1 表示模型完美预测，预测值和实际值之间没有差异，而得分为 0 表示模型无法解释任何变化。'
- en: An *R*2 closer to 1 indicates a model that fits our data well, suggesting a
    strong relationship between our input variables and the outcome. However, a high
    *R*2 alone doesn’t guarantee that the model is accurate or useful for making predictions,
    especially in complex models with many variables. It’s essential to look beyond
    *R*2 to ensure the model isn’t just fitting the noise in our data (overfitting),
    which could lead to misleading results. So, while *R*2 is a helpful indicator
    of model fit, it’s just one piece of the puzzle in evaluating a model’s performance.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*R*2 值越接近 1，表明模型很好地拟合了我们的数据，暗示我们的输入变量与结果之间存在强烈的关系。然而，仅凭高 *R*2 并不能保证模型是准确的或对预测有用，尤其是在具有许多变量的复杂模型中。确保模型不是仅仅拟合了数据中的噪声（过拟合），这可能导致误导性结果，这一点至关重要。因此，虽然
    *R*2 是模型拟合的有用指标，但它只是评估模型性能的谜题中的一块。'
- en: The coefficient of determination for our sample validation data set is 0.898—essentially
    89.8% accurate.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们样本验证数据集的决定系数为 0.898——基本上是 89.8% 准确。
- en: Based on that, it appears that our model may be pretty good (for bottled water).
    Since bottled water isn’t as perishable of a product as say, strawberries, stocking
    a little extra water likely won’t result in a product loss.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，我们的模型可能相当不错（对于瓶装水来说）。由于瓶装水不像草莓那样容易腐烂，所以多储备一些水不太可能导致产品损失。
- en: If, however, we were talking about more volatile products, you would probably
    perform some **iterative training** (that is repeated training sessions) by varying
    the input data sets, regression algorithms, and algorithm **hyperparameters**
    (parameters that control how the algorithm works, as opposed to the data supplied
    to the algorithm) to come up with a function that more accurately predicts the
    sales outcomes.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们讨论的是更易变的产品，你可能需要通过改变输入数据集、回归算法和算法**超参数**（控制算法工作方式的参数，而不是算法提供的数据）来进行一些**迭代训练**（即重复的训练会话），以得出一个更准确地预测销售结果的函数。
- en: Applications
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用
- en: So where is regression machine learning useful? As you can see from the bottled
    water example, it’s useful for making a number of predictions, especially when
    projecting sales, quotas, housing prices, stock prices, and other forecasting
    activities. It’s also useful in analyzing user trends for advertising or media
    services.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 那么回归机器学习在哪里有用呢？正如从瓶装水示例中可以看到，它在进行多种预测时很有用，尤其是在预测销售、配额、房价、股价和其他预测活动中。它也适用于分析广告或媒体服务的用户趋势。
- en: Identify classification machine learning scenarios
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别分类机器学习场景
- en: 'Classification is a supervised machine learning technique that essentially
    puts values into groups (classes) based on a criteria. There are two main types
    of classification techniques: binary and multiclass. Let’s look at both of them.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是一种监督机器学习技术，其基本原理是根据标准将值放入组（类别）中。主要有两种分类技术：二元和多类。让我们看看这两种。
- en: Binary classification
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二元分类
- en: You may have heard the terminology **binary** before and know that it’s the
    language of ones and zeroes that computers use to process information. Binary
    simply means that a data item can be set to one of two values. For example, 0
    or 1 and true or false are binary selections.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能之前听说过**二进制**这个术语，并且知道它是计算机用来处理信息的由一和零组成的语言。二进制简单来说就是数据项可以设置为两个值之一。例如，0或1以及真或假都是二进制选择。
- en: In the machine learning context, binary classification works similarly—using
    the value of a feature (*x*, just like in regression machine learning), the model
    predicts whether a label (*y*) is 0 or 1\. Binary classification categories data
    into mutually exclusive groups based on the feature data.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习环境中，二元分类与回归机器学习中的工作方式类似——使用特征值（*x*，就像在回归机器学习中一样），模型预测标签（*y*）是0还是1。二元分类根据特征数据将数据分类到互斥的组中。
- en: Example
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例
- en: 'Let’s look at a sample data set that might be used for training a binary classification
    model on whether a patient might be at risk of heart disease based on their LDL
    cholesterol level. Just like the regressive data set we looked at earlier, we’ll
    have a feature (*x*) column containing data measurements and a corresponding label
    (*y*):'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个可能用于训练二元分类模型的数据集，该模型基于患者的LDL胆固醇水平预测患者是否有患心脏病的风险。就像我们之前看到的回归数据集一样，我们将有一个包含数据测量的特征（*x*）列和相应的标签（*y*）：
- en: '| **Patient ID** | **LDL cholesterol level (x) (measured** **in mg/DL)** |
    **Heart** **disease (y)****0 = no, 1 =** **yes** |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| **患者ID** | **LDL胆固醇水平（x）（以mg/DL为单位测量**） | **心脏病（y）** | **0 = 无，1 = 是** |'
- en: '| --- | --- | --- |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | 100 | 0 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 100 | 0 |'
- en: '| 2 | 87 | 0 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 87 | 0 |'
- en: '| 3 | 132 | 0 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 132 | 0 |'
- en: '| 4 | 159 | 1 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 159 | 1 |'
- en: '| 5 | 152 | 1 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 152 | 1 |'
- en: '| 6 | 171 | 1 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 171 | 1 |'
- en: '| 7 | 188 | 1 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 188 | 1 |'
- en: '| 8 | 161 | 0 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 161 | 0 |'
- en: '| 9 | 118 | 0 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 118 | 0 |'
- en: '| 10 | 141 | 0 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 141 | 0 |'
- en: '| 11 | 102 | 1 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 102 | 1 |'
- en: '| 12 | 144 | 0 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 144 | 0 |'
- en: '| 13 | 155 | 1 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 155 | 1 |'
- en: '| 14 | 167 | 1 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 167 | 1 |'
- en: '| 15 | 142 | 1 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 142 | 1 |'
- en: Table 3.4 – Binary classification data for heart disease patients
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.4 – 心脏病患者二元分类数据
- en: 'Just as with the regression model techniques, there are many algorithms that
    can be used with binary classification. One popular algorithm is *logistic regression*
    (which, despite its name, is not an algorithm for regression-based models), which
    is typically identified by its sigmoid (S-shaped) function graph depicting values
    between 0 and 1\. See *Figure 3**.6*:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 就像回归模型技术一样，有许多算法可以用于二元分类。一个流行的算法是**逻辑回归**（尽管其名称如此，但它并不是基于回归模型的算法），它通常通过其表示0到1之间值的S形（S型）函数图来识别。见图3.6：
- en: '![Figure 3.6 – An example of a Sigmoid function graph](img/B22207_03_06.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图3.6 – Sigmoid函数图的示例](img/B22207_03_06.jpg)'
- en: Figure 3.6 – An example of a Sigmoid function graph
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 – Sigmoid函数图的示例
- en: 'Like a regression algorithm, the resultant function can be expressed mathematically.
    In the graph, the *y* axis represents the probability of a label being true (ranked
    0 to 1), using the following expression:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 与回归算法一样，结果函数可以用数学表达式表示。在图中，*y*轴表示标签为真的概率（从0到1排序），使用以下表达式：
- en: '*f(x) = P(y=1 |* *x)*'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*f(x) = P(y=1 | x)*'
- en: The training data set in *Table 3.4* shows seven patients that definitely do
    not have heart disease and eight patients that do. The graph depicted in *Figure
    3**.6* also shows an optional horizontal line that can indicate the **threshold**
    at which a prediction switches from false to true.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.4中的训练数据集显示了七个肯定没有心脏病的人和八个有心脏病的人。图3.6中描绘的图表也显示了一条可选的水平线，它可以指示预测从假变为真的**阈值**。
- en: 'As with the regression model training, you should divide the dataset into two
    selections: one piece to be used for training and the other for validation.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 与回归模型训练一样，你应该将数据集分为两个选择：一部分用于训练，另一部分用于验证。
- en: Plugging the data into a simple binary classification function, you may plot
    a graph similar to the one in *Figure 3**.7*.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据输入到简单的二元分类函数中，你可能绘制出类似于图3.7中的图表。
- en: '![Figure 3.7 – A sample binary classification graph](img/B22207_03_07.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 3.7 – 一个样本的二分类图](img/B22207_03_07.jpg)'
- en: Figure 3.7 – A sample binary classification graph
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 – 一个样本的二分类图
- en: In *Figure 3**.7*, the plotted points indicate the patient’s LDL cholesterol
    reading (plotted along the *x* axis)., and their location on the *y* axis indicates
    if the patient had heart disease or not, where 0 represents “no” and 1 represents
    “yes.”
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图3.7*中，绘制的点表示患者的LDL胆固醇读数（沿*x*轴绘制），它们在*y*轴上的位置表示患者是否有心脏病，其中0代表“无”，1代表“是”。
- en: 'Using the same method for validating the algorithm with the reserved training
    data as we did with regression training, you can do the same thing with binary
    classification. With the model created, predicting heart disease based on the
    features (LDL cholesterol levels) should be easy:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 使用与回归训练中验证算法相同的方法，使用保留的训练数据，可以对二分类做同样的事情。创建模型后，根据特征（LDL胆固醇水平）预测心脏病应该很容易：
- en: '| **Patient ID** | **LDL cholesterol level (x) (measured** **in mg/DL)** |
    **Prediction (ŷ)** | **Heart** **disease (y)****0 = no, 1 =** **yes** |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| **患者ID** | **LDL胆固醇水平（x）（测量** **在mg/DL中**） | **预测（ŷ）** | **心脏病（y）** **0 =
    无，1 = 是** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 11 | 102 | 0 | 1 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 102 | 0 | 1 |'
- en: '| 12 | 144 | 0 | 0 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 144 | 0 | 0 |'
- en: '| 13 | 155 | 1 | 1 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 155 | 1 | 1 |'
- en: '| 14 | 167 | 1 | 1 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 167 | 1 | 1 |'
- en: '| 15 | 142 | 0 | 1 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 142 | 0 | 1 |'
- en: Table 3.5 – Predictions for heart disease based on cholesterol
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.5 – 基于胆固醇的心脏病预测
- en: Next, let’s look at how to evaluate the data.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何评估数据。
- en: Evaluation metrics
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估指标
- en: 'When evaluating a model, it’s important to be able to determine not only *where*
    the predictions were right and wrong but to understand *how* they were right or
    wrong. These results can be expressed in a graph called a **confusion matrix**
    or **confusion diagram**, as shown in *Figure 3**.8*:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 当评估一个模型时，不仅要能够确定预测正确和错误的地方，还要理解它们正确或错误的原因。这些结果可以用一个称为**混淆矩阵**或**混淆图**的图表来表示，如图*图3.8*所示：
- en: '![Figure 3.8 – Confusion matrix](img/B22207_03_08.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 3.8 – 混淆矩阵](img/B22207_03_08.jpg)'
- en: Figure 3.8 – Confusion matrix
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8 – 混淆矩阵
- en: 'The data is broken into four categories:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 数据被分为四个类别：
- en: '**Actual Yes**: The training data said the patient had heart disease'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实际为是**：训练数据表明患者有心脏病'
- en: '**Actual No**: The training data said the patient did not have heart disease'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实际为否**：训练数据表明患者没有心脏病'
- en: '**Predicted Yes**: The model predicted based on the cholesterol level that
    the patient would have heart disease'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测为是**：模型根据胆固醇水平预测患者会有心脏病'
- en: '**Predicted No**: The model predicted based on the cholesterol level that the
    patient would not have heart disease'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测为否**：模型根据胆固醇水平预测患者不会患有心脏病'
- en: 'Those are then laid out on a quadrant, and the intersections are labelled accordingly:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将它们布局在四个象限中，并相应地标记交叉点：
- en: '|  | **Predicted No** | **Predicted Yes** |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '|  | **预测为否** | **预测为是** |'
- en: '| **Actual No** | True negative | False positive |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| **实际为否** | 真阴性 | 假阳性 |'
- en: '| **Actual Yes** | False negative | True positive |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| **实际为是** | 假阴性 | 真阳性 |'
- en: Table 3.6 – Confusion matrix table
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.6 – 混淆矩阵表
- en: 'Here’s how to interpret the values:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何解释这些值的说明：
- en: '**True Negatives** (**TN**): This is the number of instances where the model
    correctly predicted the absence of the condition (class 0). In our case, this
    would represent the number of patients correctly identified as not being at risk
    for heart disease.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阴性**（**TN**）：这是模型正确预测了条件不存在（类别0）的实例数量。在我们的案例中，这代表被正确地识别为没有心脏病风险的患者数量。'
- en: '**False Positives** (**FP**): This is the number of instances where the model
    incorrectly predicted the presence of the condition (class 1). In our case, this
    would represent the number of patients incorrectly identified as being at risk
    for heart disease when they are not.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性**（**FP**）：这是模型错误地预测了条件存在（类别1）的实例数量。在我们的案例中，这代表被错误地识别为有心脏病风险但实际上没有的患者数量。'
- en: '**False Negatives** (**FN**): This is the number of instances where the model
    incorrectly predicted the absence of the condition (class 0). In our case, this
    would represent the number of patients who are actually at risk for heart disease
    but were incorrectly identified as not being at risk.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性**（**FN**）：这是模型错误地预测了条件不存在（类别0）的实例数量。在我们的案例中，这代表实际上有心脏病风险但被错误地识别为没有风险的患者数量。'
- en: '**True Positives** (**TP**): This is the number of instances where the model
    correctly predicted the presence of the condition (class 1). In our case, this
    would represent the number of patients correctly identified as being at risk for
    heart disease.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阳性**（**TP**）：这是模型正确预测条件存在（类别1）的实例数量。在我们的案例中，这代表正确识别为患有心脏病风险的患者数量。'
- en: These data points (the true negatives, true positives, false positives, and
    false negatives) can then be used to further evaluate how accurate the model is
    using several metrics.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据点（真正的负数、真正的正数、错误的正数和错误的负数）可以进一步用于评估模型准确性的几个指标。
- en: Accuracy
  id: totrans-211
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**准确率**'
- en: '**Accuracy** is used to describe how often the model is correct in general.
    The formula or computing accuracy is *(TP + TN) / (total)*. In this case, the
    accuracy of the model is 60%.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '**准确率**用于描述模型总体上正确性的频率。计算准确率的公式是 *(TP + TN) / (total)*。在此情况下，模型的准确率为60%。'
- en: Recall
  id: totrans-213
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 回忆
- en: '**Recall** (sometimes called **sensitivity**) indicates how well the model
    identifies the positive class (1, or in this case, patients at risk of heart disease).
    The formula is *TP / (TP + FN)*. The recall for class 1 (with heart disease) is
    50%.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '**召回率**（有时称为**灵敏度**）表明模型识别正类（1，或在此情况下，患有心脏病风险的患者）的能力。公式是 *TP / (TP + FN)*。类别1（患有心脏病）的召回率为50%。'
- en: Precision
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**精确率**'
- en: '**Precision** is an indicator of how often the model is right for each class
    prediction. For the positive class, this formula is TP / (TP + FP). For class
    1 (heart disease), the model correctly predicts 100% of the time.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确率**是模型对每个类别预测正确频率的指标。对于正类，此公式是 TP / (TP + FP)。对于类别1（心脏病），模型正确预测的频率为100%。'
- en: Specificity
  id: totrans-217
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 特异性
- en: '**Specificity** measures how often a model is right for the negative class
    (0, or in this case, patients without heart disease). The formula is *TN / (TN
    + FP)*. This model’s specificity for the negative class is 33%, indicating that
    it is only correct 33% of the time when predicting that a patient will not have
    heart disease.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '**特异性**衡量模型对负类（0，或在此情况下，无心脏病患者）预测正确性的频率。公式是 *TN / (TN + FP)*。此模型对负类的特异性为33%，表明在预测患者不会患有心脏病时，只有33%的时间是正确的。'
- en: If there were discrepancies in prediction versus actual data, it could suggest
    areas where the model might need improvement, such as collecting more diverse
    data, using a different model, or tuning the existing model. Understanding where
    the model fails can help in reducing false positives (incorrectly predicting risk
    where there is none) and false negatives (missing out on identifying actual risk),
    which are particularly critical in medical diagnostics.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果预测与实际数据之间存在差异，这可能表明模型可能需要改进的领域，例如收集更多样化的数据、使用不同的模型或调整现有模型。了解模型失败的地方可以帮助减少假阳性（错误地预测没有风险的风险）和假阴性（错过识别实际风险），这在医学诊断中尤其重要。
- en: Applications
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用
- en: Binary classifications are most useful when there are a limited number of factors
    influencing a true or false outcome. It is common in fields such as medicine,
    biology, technology, and chemistry when you’re trying to determine a yes/no or
    true/false result based on a small set of variables.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 当影响真实或虚假结果的因素有限时，二元分类最有用。在医学、生物学、技术和化学等领域，当你试图根据一小组变量确定是/否或真/假结果时，这是常见的。
- en: 'Common real-world examples of binary classification include the following:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 二元分类的常见现实世界例子包括以下：
- en: '**Email spam detection**: Classifying emails as either spam or not spam. This
    is one of the most common applications of binary classification, used by email
    services to filter out unwanted messages.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电子邮件垃圾邮件检测**：将电子邮件分类为垃圾邮件或非垃圾邮件。这是二元分类最常见的一种应用，由电子邮件服务用于过滤掉不受欢迎的消息。'
- en: '**Medical diagnosis**: Diagnosing patients with a disease or condition as either
    positive (having the disease) or negative (not having the disease). For example,
    binary classification models can be used to detect the presence of a tumor as
    malignant or benign based on medical imaging.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医学诊断**：将患者疾病或状况诊断为阳性（患有疾病）或阴性（未患病）。例如，二元分类模型可以根据医学影像检测肿瘤是否为恶性或良性。'
- en: '**Credit approval**: Deciding whether to approve or decline a credit application.
    Financial institutions use binary classification algorithms to predict whether
    an applicant is likely to default on a loan.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信用批准**：决定是否批准或拒绝信用申请。金融机构使用二元分类算法来预测申请者是否可能违约。'
- en: '**Churn prediction**: Predicting whether a customer will churn (leave) or stay
    with a company or service. Companies use binary classification to identify at-risk
    customers and develop strategies to retain them.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户流失预测**：预测客户是否会流失（离开）或继续与公司或服务保持关系。公司使用二元分类来识别风险客户并制定保留策略。'
- en: '**Fraud detection**: Identifying transactions as fraudulent or legitimate.
    Banks and financial institutions use binary classification models to detect suspicious
    activities and prevent fraud.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欺诈检测**：识别交易为欺诈或合法。银行和金融机构使用二元分类模型来检测可疑活动并预防欺诈。'
- en: '**Sentiment analysis**: Determining whether a piece of text (such as a product
    review or social media post) expresses a positive or negative sentiment. This
    is widely used in marketing and customer service to gauge public opinion and customer
    satisfaction.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**情感分析**：确定一段文本（如产品评论或社交媒体帖子）是否表达积极或消极的情感。这在市场营销和客户服务中广泛用于衡量公众舆论和客户满意度。'
- en: '**Malware detection**: Classifying files or programs as malicious or safe,
    used by cybersecurity systems to protect computers and networks from viruses and
    other malicious software.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**恶意软件检测**：将文件或程序分类为恶意或安全，由网络安全系统用于保护计算机和网络免受病毒和其他恶意软件的侵害。'
- en: Multiclass classification
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多类分类
- en: Shifting gears a little bit, let’s look at multiclass classification. Like binary
    classification, it’s a probability method that assigns a classification based
    on a feature. However, instead of using a single feature or a binary label (true/false,
    0/1), it can use multiple features and multiple classifications. The underlying
    ideas are the same, but let’s just look at a quick example of how it works.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 稍微转换一下话题，让我们看看多类分类。像二元分类一样，它是一种基于特征的概率方法，根据特征分配分类。然而，它不仅可以使用多个特征和多个分类，而不是使用单个特征或二元标签（真/假，0/1）。基本思想是相同的，但让我们快速看一下它的工作原理的一个例子。
- en: Example
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例
- en: In this example, we’ll be evaluating peppers and their heat (or Scoville heat
    unit rating). Every pepper has a heat rating, ranked in Scoville units, that describes
    how spicy it is.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将评估辣椒及其辣度（或斯科维尔辣度单位评分）。每种辣椒都有一个辣度评分，按斯科维尔单位排名，描述了它的辣度。
- en: 'The data in *Table 3.7* depicts a variety of peppers and their average Scoville
    heat units:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '*表 3.7* 中的数据展示了各种辣椒及其平均斯科维尔辣度单位：'
- en: '| **Scoville** **heat units** | **Pepper** |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| **斯科维尔辣度单位** | **辣椒** |'
- en: '| --- | --- |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1,500,000 – 2,200,000 | Carolina Reaper |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 1,500,000 – 2,200,000 | 特立尼达毒蝎 |'
- en: '| 1,000,000 – 1,500,000 | Trinidad Scorpion |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 1,000,000 – 1,500,000 | 特立尼达毒蝎 |'
- en: '| 855,000 – 1,000,000 | Ghost pepper |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 855,000 – 1,000,000 | 幽灵辣椒 |'
- en: '| 350,000 – 577,000 | Red Savina Habanero |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 350,000 – 577,000 | 红色萨维纳哈瓦那辣椒 |'
- en: '| 100,000 – 350,000 | Habanero |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 100,000 – 350,000 | 哈瓦那辣椒 |'
- en: '| 70,000 – 100,000 | Charleston hot |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 70,000 – 100,000 | 查尔斯顿热辣椒 |'
- en: '| 30,000 – 50,000 | Cayenne pepper |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| 30,000 – 50,000 | 卡宴辣椒 |'
- en: '| 10,000 – 23,000 | Serrano pepper |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 10,000 – 23,000 | 塞拉诺辣椒 |'
- en: '| 8,000 – 10,000 | Hungarian pepper |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| 8,000 – 10,000 | 匈牙利辣椒 |'
- en: '| 2,000 – 7,000 | Jalapeno pepper |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 2,000 – 7,000 | 奇瓦潘辣椒 |'
- en: '| 0-100 | Bell pepper |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 0-100 | 青椒 |'
- en: Table 3.7 – Selected peppers and their Scoville heat unit ratings
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.7 – 选择辣椒及其斯科维尔辣度单位评分
- en: 'Now, just like the binary classification training, let’s generate a sample
    table of features (Scoville heat unit ratings) and labels (peppers):'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '现在，就像二元分类训练一样，让我们生成一个特征（斯科维尔辣度单位评分）和标签（辣椒）的样本表： '
- en: '| **ID** | **Scoville heat** **unit (x)** | **Pepper (y)** |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| **ID** | **斯科维尔辣度单位 (x)** | **辣椒 (y)** |'
- en: '| --- | --- | --- |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | 1,900,000 | Carolina reaper |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1,900,000 | 卡罗来纳死神辣椒 |'
- en: '| 2 | 10 | Bell |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 10 | 青椒 |'
- en: '| 3 | 2,850 | Jalapeno |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 2,850 | 奇瓦潘辣椒 |'
- en: '| 4 | 447,700 | Red Savina |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 447,700 | 红色萨维纳辣椒 |'
- en: '| 5 | 8,700 | Hungarian |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 8,700 | 匈牙利辣椒 |'
- en: '| 6 | 127,000 | Habanero |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 127,000 | 哈瓦那辣椒 |'
- en: '| 7 | 88,000 | Charleston hot |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 88,000 | 查尔斯顿热辣椒 |'
- en: '| 8 | 289,000 | Habanero |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 289,000 | 哈瓦那辣椒 |'
- en: '| 9 | 0 | Bell |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 0 | 青椒 |'
- en: '| 10 | 900,000 | Ghost |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 900,000 | 幽灵辣椒 |'
- en: '| 11 | 1,250,000 | Scorpion |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 1,250,000 | 毒蝎 |'
- en: '| 12 | 11,000 | Serrano |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 11,000 | 塞拉诺辣椒 |'
- en: '| 13 | 42,000 | Cayenne |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 42,000 | 卡宴辣椒 |'
- en: '| 14 | 7,000 | Jalapeno |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 7,000 | 奇瓦潘辣椒 |'
- en: '| 15 | 2,200,000 | Carolina Reaper |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 2,200,000 | 卡罗来纳死神辣椒 |'
- en: Table 3.8 – Scoville rating sample data
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.8 – 斯科维尔评分样本数据
- en: Once the training data is assembled, it’s time to use an algorithm to fit the
    training data to a function that will calculate the probability for our classes.
    There are 11 possible answers (classes) for our data set based on our training
    data. They’re zero-indexed, meaning they’re numbered from 0 to 10.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦收集了训练数据，就到了使用算法将训练数据拟合到计算我们类别概率的函数的时候了。根据我们的训练数据，我们的数据集有11个可能的答案（类别）。它们是零索引的，这意味着它们从0到10编号。
- en: The most common algorithms in multiclass classification models are **one-vs-rest**
    (**OvR**) and **multinominal** algorithms.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 多元分类模型中最常见的算法是**一对余**（**OvR**）和**多项式**算法。
- en: '**One-vs-Rest** (**OvR**) or **One-vs-All** (**OvA**): With this algorithm,
    you train a binary classification function for each class individually. Each function
    targets a specific class compared to any of the other classes in the set. In this
    case, since there are 11 pepper types represented, the algorithm would create
    11 binary classification functions. Like the binary classifications previously,
    the algorithm produces a sigmoid function. The outcome of this model predicts
    the class for the function that results in the highest probability output. OvR
    or OvA strategies could be applied, for example, in a Carolina Reaper vs. all
    classifier—essentially determining if an element is a Carolina Reaper or not.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一对余**（**OvR**）或**一对所有**（**OvA**）：使用此算法，你为每个类别单独训练一个二分类函数。每个函数针对集合中的特定类别与其他任何类别进行比较。在这种情况下，由于有11种辣椒类型，算法将创建11个二分类函数。像之前的二分类一样，该算法产生一个Sigmoid函数。该模型的输出预测了产生最高概率输出的函数的类别。OvR或OvA策略可以应用于例如卡罗来纳雷aper对所有分类器的场景——本质上确定一个元素是否是卡罗来纳雷aper。'
- en: '**Multinomial**: This algorithm approaches the problem differently, creating
    a single function with a multivalued (or vector) output. This vector can contain
    a probability distribution across all the potential classes, though it’s really
    designed for mutually exclusive data sets (for example, if a pepper’s Scoville
    rating can’t expand into another pepper’s range). With a vector containing multiple
    elements, each class element is scored individually between 0 and 1, with the
    total adding up to 1.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多项式**：此算法以不同的方式处理问题，创建一个具有多值（或向量）输出的单个函数。这个向量可以包含所有潜在类别的概率分布，尽管它实际上是为互斥数据集设计的（例如，如果一个辣椒的Scoville评分不能扩展到另一个辣椒的范围内）。具有多个元素的向量中，每个类别的元素都会在0到1之间单独评分，总和为1。'
- en: These types of models may need more information to reliably predict. For example,
    review the sample data in *Table 3.7* for the Scoville pepper ratings. As you
    can see, there are a few instances where a pepper might have a similar heat rating
    to another pepper (either milder or spicier). A larger training data set would
    help the model understand concepts of frequency to help more accurately predict
    and select an appropriate classification strategy (depending on the factors you
    want to identify) would help you be most successful in this classification methodology.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这类模型可能需要更多信息才能可靠地预测。例如，查看 *表 3.7* 中的Scoville辣椒评分样本数据。正如你所看到的，有几个实例中，一个辣椒可能与其他辣椒有相似的热度评分（要么较温和，要么较辣）。更大的训练数据集将有助于模型理解频率的概念，从而帮助更准确地预测和选择适当的分类策略（取决于你想要识别的因素），这将有助于你在这种分类方法中取得最大的成功。
- en: Evaluation metrics
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估指标
- en: Since multiclass classification can really be looked at as an extension of binary
    classification (in many cases), the same techniques and terminology apply.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 由于多元分类实际上可以看作是二分类的扩展（在许多情况下），因此相同的技术和术语适用。
- en: 'For example, with the training data, you could develop a confusion matrix.
    The layout is very similar to the confusion matrix for binary classification—it’s
    just got more labels to deal with, as shown in *Figure 3**.9*:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用训练数据，你可以开发一个混淆矩阵。布局与二分类的混淆矩阵非常相似——只是需要处理更多的标签，如图 *图 3.9* 所示：
- en: '![Figure 3.9 – Multiclass confusion matrix based on Scoville pepper data](img/B22207_03_09.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.9 – 基于Scoville辣椒数据的多元混淆矩阵](img/B22207_03_09.jpg)'
- en: Figure 3.9 – Multiclass confusion matrix based on Scoville pepper data
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.9 – 基于Scoville辣椒数据的多元混淆矩阵
- en: Applications
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用
- en: Multiclass classification refers to the scenarios where you need to classify
    items into more than two categories. Unlike binary classification, which differentiates
    between two classes (such as yes/no or true/false), multiclass classification
    deals with situations where there are three or more classes.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 多类分类指的是需要将项目分类到两个以上类别的场景。与区分两个类别（如是/否或真/假）的二分类不同，多类分类处理的是有三个或更多类别的情形。
- en: 'Potential use cases include the following:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在的应用场景包括以下内容：
- en: '**Predicting animal types**: Suppose you have a dataset containing images of
    animals and you want to classify each image as a dog, cat, bird, or fish. This
    is a multiclass classification problem with four classes.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测动物类型**：假设你有一个包含动物图像的数据集，你想要将每个图像分类为狗、猫、鸟或鱼。这是一个有四个类别的多类分类问题。'
- en: '**Weather forecasting**: If you’re predicting whether the weather will be sunny,
    cloudy, rainy, or snowy, you’re dealing with multiclass classification.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**天气预报**：如果你在预测天气将是晴朗、多云、下雨还是下雪，你就是在处理多类分类。'
- en: '**Handwritten numeral recognition**: A classic example is the MNIST dataset,
    where the task is to classify images of handwritten digits into 10 classes (0
    through 9).'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手写数字识别**：一个经典的例子是 MNIST 数据集，其中的任务是把手写数字图像分类到 10 个类别（0 到 9）。'
- en: '**Medical diagnosis**: Suppose a particular diagnostic test can indicate one
    of several different diseases. If you’re developing a model to predict which specific
    disease (out of a possible set) a patient might have based on their symptoms and
    test results, you’re engaging in multiclass classification.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医疗诊断**：假设某个特定的诊断测试可以指示几种不同的疾病。如果你正在开发一个模型，根据患者的症状和测试结果预测患者可能患有的特定疾病（从可能的集合中），你就是在进行多类分类。'
- en: In multiclass classification, techniques and metrics are slightly different
    from binary classification in that you have to consider how the model performs
    across all the different classes (not just two), but overall the process is very
    similar. Metrics such as precision and recall are calculated for each class and
    then averaged in some way (such as micro, macro, or weighted average) to understand
    the overall performance.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在多类分类中，技术和指标与二分类略有不同，因为你必须考虑模型在所有不同类别（而不仅仅是两个）上的表现，但总体过程非常相似。对于每个类别都会计算精确度和召回率等指标，然后以某种方式（如微平均、宏平均或加权平均）进行平均，以了解整体性能。
- en: A classification’s F1 score is a measure used to summarize the overall accuracy
    of a class. Previously, you learned about **precision** (ratio of correctly predicted
    positive observations to the total positives using the formula *P = TP / (TP+FP)*)
    and recall (ratio of correctly predicted positive observations to all the observations
    in the class, calculated using the formula *R = TP / (**TP +FN)*).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 一个分类的 F1 分数是用来总结该类整体准确性的一个度量。之前，你学习了**精确度**（正确预测的正观察值与总正值的比率，公式为 *P = TP / (TP+FP)*)
    和召回率（正确预测的正观察值与类别中所有观察值的比率，使用公式 *R = TP / (TP + FN)* 计算）。
- en: An F1 score is calculated using the formula *F1 = 2 * (P * R) / (P +* *R)*.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: F1 分数是使用以下公式计算的：*F1 = 2 * (P * R) / (P + R)*。
- en: Up to this point, you’ve been learning about **supervised learning** scenarios
    such as binary and multiclass classification. Next, we’ll be shifting to unsupervised
    scenarios.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你一直在学习关于**监督学习**场景，如二分类和多类分类。接下来，我们将转向无监督场景。
- en: Identify clustering machine learning scenarios
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别聚类机器学习场景
- en: Clustering is an unsupervised machine learning scenario where algorithms are
    employed to try to identify patterns in data. Unlike supervised learning, where
    training data has labels and features, unsupervised learning does not. The main
    goal of clustering is to be able to let the machine learning algorithms discover
    natural groupings within the data based on the similarities in the data points
    themselves.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是一种无监督机器学习场景，其中算法被用来尝试识别数据中的模式。与有监督学习不同，有监督学习中的训练数据有标签和特征，而无监督学习没有。聚类的主要目标是让机器学习算法能够根据数据点本身的相似性在数据中找到自然分组。
- en: 'Just as supervised learning had its algorithms, there are several popular algorithms
    available to use with clustering scenarios:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 正如监督学习有自己的算法一样，有几种流行的算法可用于聚类场景：
- en: '**K-means clustering**: This algorithm partitions the data into *K* distinct,
    non-overlapping subsets (or clusters) based on the mean distance from the centroid
    of each cluster. The value of *K* needs to be specified beforehand.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**K-means聚类**：该算法根据每个簇质心的平均距离将数据划分为*K*个互不重叠的子集（或簇）。*K*的值需要事先指定。'
- en: '**Hierarchical clustering**: Builds a hierarchy of clusters either with a bottom-up
    approach (agglomerative) or a top-down approach (divisive). It does not require
    pre-specification of the number of clusters.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**层次聚类**：通过自底向上（聚合）或自顶向下（划分）的方法构建簇的层次结构。它不需要预先指定簇的数量。'
- en: '**Density-Based Spatial Clustering of Applications with Noise** (**DBSCAN**):
    Forms clusters based on the density of data points, capable of discovering clusters
    of arbitrary shape and handling noise and outliers effectively.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于密度的空间聚类应用噪声**（**DBSCAN**）：基于数据点的密度形成簇，能够发现任意形状的簇并有效地处理噪声和异常值。'
- en: '**Example**'
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**示例**'
- en: 'Let’s say we have some sample data from grocery shoppers; 15 shoppers have
    put the items (or features, in this case) depicted in *Table 3.9* in their baskets:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一些来自杂货购物者的样本数据；15位购物者将*表3.9*中描述的项目（或特征）放入了他们的篮子里：
- en: '| **Basket Id** | **Bread (x1)** | **Milk (x2)** | **Eggs (x3)** | **Bananas
    (x4)** | **Chicken (x5)** | **Apples (x6)** | **Cheese (x7)** | **Tomatoes (x8)**
    | **Potatoes (x9)** | **Onions (x10)** | **Coffee (x11)** | **Lettuce (x12)**
    |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| **篮子ID** | **面包（x1）** | **牛奶（x2）** | **鸡蛋（x3）** | **香蕉（x4）** | **鸡肉（x5）**
    | **苹果（x6）** | **奶酪（x7）** | **番茄（x8）** | **土豆（x9）** | **洋葱（x10）** | **咖啡（x11）**
    | **生菜（x12）** |'
- en: '| 1 | 1 | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 1 | 1 | 1 | 0 |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 1 | 1 | 1 | 0 |'
- en: '| 2 | 1 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 1 | 0 |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 1 | 0 |'
- en: '| 3 | 1 | 1 | 1 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 1 | 1 |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1 | 1 | 1 | 0 | 1 | 1 | 1 | 0 | 1 | 1 | 1 | 1 |'
- en: '| 4 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |'
- en: '| 5 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |'
- en: '| 6 | 0 | 1 | 1 | 0 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 1 |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 0 | 1 | 1 | 0 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 1 |'
- en: '| 7 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 0 |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 0 |'
- en: '| 8 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 1 | 1 | 1 |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 | 1 | 1 | 1 | 1 |'
- en: '| 9 | 0 | 0 | 1 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 0 | 0 |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 0 | 0 | 1 | 1 | 1 | 0 | 0 | 1 | 1 | 1 | 0 | 0 |'
- en: '| 10 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 1 | 1 | 1 |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 1 | 1 | 1 |'
- en: '| 11 | 1 | 0 | 1 | 0 | 1 | 0 | 0 | 1 | 0 | 1 | 0 | 1 |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 1 | 0 | 1 | 0 | 1 | 0 | 0 | 1 | 0 | 1 | 0 | 1 |'
- en: '| 12 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 0 | 0 | 1 | 1 |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 1 | 1 | 0 | 1 | 1 | 0 | 1 | 1 | 0 | 0 | 1 | 1 |'
- en: '| 13 | 1 | 1 | 1 | 0 | 0 | 0 | 1 | 1 | 1 | 0 | 0 | 1 |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| 13 | 1 | 1 | 1 | 0 | 0 | 0 | 1 | 1 | 1 | 0 | 0 | 1 |'
- en: '| 14 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 1 | 1 | 0 | 1 |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 1 | 1 | 0 | 1 |'
- en: '| 15 | 0 | 1 | 1 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 0 | 1 | 1 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 |'
- en: Table 3.9 – Example shopping baskets of food
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.9 – 食物示例购物篮
- en: 'In this example, we can instruct a K-means algorithm to partition the data
    into three groups of shopping baskets. Based on the output, we end up with the
    following three clusters:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们可以指导K-means算法将数据划分为三个购物篮组。根据输出结果，我们最终得到以下三个簇：
- en: 'Cluster 0: Baskets 2, 5, 12, 15'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 簇0：篮子2、5、12、15
- en: 'Cluster 1: Baskets 5, 9, 11, 14'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 簇1：篮子5、9、11、14
- en: 'Cluster 2: Baskets 1, 3, 4, 6, 8, 10, 13'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 簇2：篮子1、3、4、6、8、10、13
- en: 'Here’s how the K-means algorithm was applied to the dataset of grocery items
    purchased by shoppers:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何将K-means算法应用于购物者购买的杂货数据集的示例：
- en: First, the grocery items (such as bread, milk, eggs, etc.) were represented
    in a format suitable for machine learning algorithms. This was done using a binary
    representation where each item was encoded as 0 (not purchased) or 1 (purchased),
    as shown in *Table 3.9*. This binary matrix forms the dataset where each row represents
    a shopping basket and each column represents a different grocery item.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，将杂货商品（如面包、牛奶、鸡蛋等）以适合机器学习算法的格式表示。这是通过二进制表示实现的，其中每个项目被编码为0（未购买）或1（购买），如*表3.9*所示。这个二进制矩阵形成了数据集，其中每一行代表一个购物篮，每一列代表不同的杂货商品。
- en: Next, we chose a number of clusters (or groups) that would be used for grouping
    the items. In this case, we set *K* to three, meaning we decided to group the
    shopping baskets into three distinct clusters based on the items they contained.
    The choice of *K* can be influenced by domain knowledge, experimentation, or other
    techniques and algorithms.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们选择了一些集群（或组）用于对项目进行分组。在这种情况下，我们将 *K* 设置为三个，这意味着我们决定根据包含的项目将购物篮分为三个不同的集群。*K*
    的选择可能受到领域知识、实验或其他技术和算法的影响。
- en: Once the prerequisites for the process are set, we then choose some random points
    on a graph. These points, called **centroids**, are the center points of the clusters
    being formed. In our case, three shopping baskets were randomly chosen as the
    initial centroids.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦设置了过程的先决条件，我们然后在图上选择一些随机点。这些点称为 **质心**，是正在形成的集群的中心点。在我们的例子中，随机选择了三个购物篮作为初始质心。
- en: Each shopping basket (or row of our dataset) was then assigned to the nearest
    centroid. The “nearest” is typically determined by calculating the distance between
    the basket and each centroid. Each basket is assigned to the cluster whose centroid
    is closest to it, forming three initial clusters based on the current centroids.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，每个购物篮（或我们的数据集的一行）被分配到最近的质心。通常，“最近”是通过计算篮子与每个质心之间的距离来确定的。每个篮子被分配到离它最近的质心的集群，从而根据当前的质心形成三个初始集群。
- en: Go the distance
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 去更远的地方
- en: There are many different methods for determining distance in clustering. The
    three most common types of distance calculations are **Euclidean**, **Hamming**,
    **Manhattan**, **Minkowski**, and **Jaccard**. Each type of distance is used for
    different types of data (for example, binary data versus linear or continuous
    numerical data). The good news is that none of these things appear on the exam,
    so you don’t need to learn them. However, if you want to explore different mathematical
    foundations for determining clustering distance, see [https://www.displayr.com/understanding-cluster-analysis-a-comprehensive-guide/](https://www.displayr.com/understanding-cluster-analysis-a-comprehensive-guide/).
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在聚类中确定距离有许多不同的方法。最常用的三种距离计算类型是 **欧几里得**、**汉明**、**曼哈顿**、**闵可夫斯基** 和 **杰卡德**。每种类型的距离用于不同类型的数据（例如，二进制数据与线性或连续数值数据）。好消息是，这些内容都不出现在考试中，所以你不需要学习它们。然而，如果你想探索确定聚类距离的不同数学基础，请参阅
    [https://www.displayr.com/understanding-cluster-analysis-a-comprehensive-guide/](https://www.displayr.com/understanding-cluster-analysis-a-comprehensive-guide/)。
- en: Once all baskets have been assigned to clusters, the centroids of these clusters
    are recalculated. This is done by taking the mean (or average) of all baskets
    in each cluster. Since our data is binary, this average may not be exactly 0 or
    1; it represents the proportion of baskets in the cluster that contain each item.
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦所有篮子都被分配到集群中，这些集群的质心将被重新计算。这是通过取每个集群中所有篮子的平均值（或平均数）来完成的。由于我们的数据是二进制的，这个平均值可能不是正好是
    0 或 1；它代表集群中包含每个项目的篮子比例。
- en: The steps of assigning baskets to the nearest centroid and then updating the
    centroids based on the current cluster memberships were repeated. With each iteration,
    baskets might shift from one cluster to another as the centroids change.
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将篮子分配到最近的质心并根据当前的集群成员资格更新质心的步骤被重复执行。随着质心的变化，每个迭代中篮子可能会从一个集群转移到另一个集群。
- en: This process was repeated until the centroids no longer changed significantly
    between iterations, meaning that the clusters had stabilized and the algorithm
    had converged. This is the stopping criterion for K-means.
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个过程一直重复，直到质心在迭代之间不再显著变化，这意味着集群已经稳定，算法已经收敛。这是 K-means 的停止标准。
- en: Once the algorithm converged, each shopping basket was assigned to one of the
    three clusters based on the items it contained. The final clusters represent groups
    of shopping baskets that are similar to each other based on the presence or absence
    of certain items.
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦算法收敛，每个购物篮根据其包含的项目被分配到三个集群中的一个。最终的集群代表基于某些项目的存在或不存在而彼此相似的购物篮组。
- en: In the context of our grocery item dataset, applying K-means allowed us to group
    shopping baskets into clusters that could potentially reflect different types
    of shopping patterns or preferences among customers. For example, one cluster
    might represent weekly staple shopping (including items such as bread, milk, and
    eggs), another might represent fresh produce shopping (including items such as
    fruits and vegetables), and another might represent specialty item shopping (such
    as coffee or cheese).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的购物项目数据集的背景下，应用K-means使我们能够将购物篮分组到簇中，这些簇可能反映了客户不同的购物模式或偏好。例如，一个簇可能代表每周的必需品购物（包括面包、牛奶和鸡蛋等物品），另一个簇可能代表新鲜农产品购物（包括水果和蔬菜等物品），另一个簇可能代表特殊商品购物（如咖啡或奶酪）。
- en: This type of information is frequently used by merchants to help understand
    buying habits and suggestive or upselling opportunities. If you’ve ever wondered
    how Amazon determines how items show up as suggested for you to buy or why you
    get certain coupons in the mail, clustering machine learning models were very
    likely involved at some point.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的信息通常被商家用来帮助理解购买习惯和推荐或升级销售的机会。如果你曾经好奇亚马逊是如何确定哪些商品会作为推荐给你购买，或者为什么你会收到某些优惠券，那么在某个阶段很可能涉及聚类机器学习模型。
- en: Evaluation metrics
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估指标
- en: Since there are no labels to compare against, evaluating the performance of
    clustering is less straightforward than supervised learning. However, metrics
    such as **silhouette score** (or **silhouette coefficient**), the **Davies-Bouldin
    index**, and the **Calinski-Harabasz index** can be used to assess the quality
    of clustering by measuring the distance between clusters and the density of the
    clusters themselves.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有标签进行比较，评估聚类的性能不如监督学习直接。然而，可以使用诸如**轮廓得分**（或**轮廓系数**）、**戴维斯-博尔丁指数**和**卡尔斯基-哈拉巴斯指数**等指标，通过测量簇之间的距离和簇本身的密度来评估聚类的质量。
- en: Silhouette score
  id: totrans-333
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 轮廓得分
- en: The silhouette score or silhouette coefficient measures how well each data point
    fits within its final assigned cluster. The score ranges from -1 to 1, where values
    closer to 1 indicate better-defined, less-overlapping clusters.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 轮廓得分或轮廓系数衡量每个数据点如何适合其最终分配的簇。分数范围从-1到1，其中接近1的值表示定义更清晰、重叠更少的簇。
- en: A score close to 1 indicates that the clusters are well apart from each other
    and clearly defined
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分数接近1表示簇彼此之间距离较远且定义清晰
- en: A score of 0 indicates that the clusters are overlapping
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分数为0表示簇之间存在重叠
- en: A score close to -1 indicates that the clusters are assigned inappropriately
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分数接近-1表示簇的分配不适当
- en: In this case, this model’s silhouette score is 0.128, which suggests that the
    clusters are overlapping or might not be distinctly separated. That can be expected
    with this type of data (a grocery shopping list), since shoppers use items at
    different rates and have different needs than each other, leading them to complex
    purchase decisions that might result in them buying the same things but for different
    reasons.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，该模型的轮廓得分是0.128，这表明簇之间存在重叠或可能没有明显分离。这种情况对于这种类型的数据（如购物清单）是可以预料的，因为购物者使用物品的频率不同，彼此有不同的需求，导致他们做出复杂的购买决策，可能结果是购买相同的东西但出于不同的原因。
- en: Davies-Bouldin index
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 戴维斯-博尔丁指数
- en: The **Davies-Bouldin index** is used to measure the quality of clustering, where
    lower scores indicate better clustering.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '**戴维斯-博尔丁指数**用于衡量聚类的质量，其中较低的分数表示聚类质量更好。'
- en: The Davies-Bouldin index score for our grocery basket K-means clustering model
    is approximately 1.65\. The score essentially evaluates the average similarity
    between each cluster and its most similar cluster, where similarity is a measure
    that combines the compactness (how close the points in a cluster are to each other)
    and the separation (how far apart different clusters are from each other) of the
    clusters.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 我们购物篮K-means聚类模型的戴维斯-博尔丁指数得分约为1.65。这个分数本质上评估了每个簇与其最相似簇之间的平均相似度，其中相似度是一个结合簇的紧凑性（簇内点彼此之间的接近程度）和分离度（不同簇彼此之间的距离）的度量。
- en: A lower Davies-Bouldin index indicates that the clusters are compact (i.e.,
    the points within each cluster are close to each other) and well-separated (i.e.,
    the clusters are far apart from each other). Conversely, a higher score suggests
    less distinct clusters.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 较低的戴维斯-博尔丁指数表示簇是紧凑的（即，每个簇内的点彼此靠近）且分离良好（即，簇彼此之间距离较远）。相反，较高的分数表明簇的区分度较低。
- en: Generally, scores closer to 0 are more desirable.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，分数接近0的更受欢迎。
- en: Calinski-Barabasz index
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Calinski-Barabasz指数
- en: The **Calinski-Harabasz index**, also known as the Variance Ratio Criterion,
    does not have a fixed range such as some other metrics (such as the silhouette
    score, which goes from -1 to 1). Instead, its value depends on the dataset’s characteristics,
    including the number of samples, dimensions, and the inherent cluster structure.
    The Calinski-Harabasz index score for this model is 3.10.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '**Calinski-Harabasz指数**，也称为方差比率准则，没有像某些其他指标（如轮廓分数，其范围从-1到1）那样的固定范围。相反，其值取决于数据集的特征，包括样本数量、维度和固有的簇结构。此模型的Calinski-Harabasz指数得分为3.10。'
- en: A higher Calinski-Harabasz index score indicates that the clusters are dense
    (meaning points within a cluster are close to each other) and well-separated (meaning
    clusters are far apart from each other). This is interpreted as a model with a
    better-defined cluster structure. Unlike metrics such as accuracy, which ranges
    from 0 to 1, or the silhouette score, which has a theoretical range from -1 to
    1, the Calinski-Harabasz index does not have a maximum value and is not bounded
    in a fixed range. Its absolute value is less informative without context.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 更高的Calinski-Harabasz指数得分表明簇是密集的（意味着簇内的点彼此靠近）并且分离良好（意味着簇彼此之间距离较远）。这被解释为具有更好定义的簇结构的模型。与准确度等指标的范围从0到1，或轮廓分数的理论范围从-1到1不同，Calinski-Harabasz指数没有最大值，并且不在固定范围内有界。没有上下文的情况下，其绝对值信息较少。
- en: The index is most useful when it’s being used to compare different clustering
    models or configurations on the same dataset. For example, comparing the scores
    obtained from clustering the same data with different numbers of clusters (*K*)
    can help in choosing the best *K* by selecting the one with the highest Calinski-Harabasz
    score. In this example, we told the model to group the grocery baskets into three
    clusters. To effectively use the Calinski-Harabasz score, it would be useful to
    re-run the model breaking the baskets into two, four, or five clusters.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 当用于比较同一数据集上不同的聚类模型或配置时，该指数最有用。例如，通过选择具有最高Calinski-Harabasz得分的簇数（*K*）来选择最佳*K*，可以帮助通过聚类相同数据并使用不同数量的簇来获得分数。在这个例子中，我们告诉模型将购物篮分为三个簇。为了有效地使用Calinski-Harabasz分数，重新运行模型将篮子分为两个、四个或五个簇将是有用的。
- en: 'For example, after rerunning the K-means algorithm with parameters for two,
    four, and five clusters, the following scores were achieved:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在重新运行K-means算法并使用两个、四个和五个簇的参数后，取得了以下分数：
- en: 'Two clusters: 2.997'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个簇：2.997
- en: 'Four clusters: 2.73'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 四个簇：2.73
- en: 'Five clusters: 2.504'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 五个簇：2.504
- en: In practice, because there is no fixed “good” threshold, the best approach is
    to use the Calinski-Harabasz index to compare the effectiveness of different clustering
    solutions on the same data and choose the one with the highest score. However,
    this score should be used alongside other metrics such as the silhouette score
    and the Davies-Bouldin index for a more comprehensive evaluation.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，因为没有固定的“良好”阈值，最佳方法是使用Calinski-Harabasz指数来比较同一数据集上不同聚类解决方案的有效性，并选择得分最高的一个。然而，这个分数应该与其他指标（如轮廓分数和Davies-Bouldin指数）一起使用，以进行更全面的评估。
- en: Applications
  id: totrans-353
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用
- en: 'Clustering has a lot of real-world applications, from social sciences to marketing
    and threat modeling. Example applications include the following:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类有许多实际应用，从社会科学到市场营销和威胁建模。以下是一些示例应用：
- en: '**Market segmentation**: Grouping customers based on purchasing behavior, interests,
    or demographic profiles.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**市场细分**：根据购买行为、兴趣或人口统计特征对客户进行分组。'
- en: '**Anomaly detection**: Identifying unusual data points by finding which ones
    do not fit into any cluster.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常检测**：通过找出哪些数据点不适合任何簇来识别异常数据点。'
- en: '**Data organization**: Organizing large volumes of data into manageable and
    meaningful groups.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据组织**：将大量数据组织成可管理和有意义的组。'
- en: '**Pattern discovery**: Finding hidden patterns or intrinsic structures in data,
    such as grouping genes with similar expression patterns in bioinformatics.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模式发现**：在数据中寻找隐藏的模式或内在结构，例如在生物信息学中根据相似的表达模式对基因进行分组。'
- en: '**Customer behavior analysis**: Understanding different customer groups and
    their purchasing patterns can help in optimizing product placements, store layouts,
    and inventory management.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户行为分析**：了解不同的客户群体及其购买模式可以帮助优化产品定位、商店布局和库存管理。'
- en: '**Recommendation systems**: Clustering can help identify groups of similar
    items or users, which can then be used to recommend items to users based on the
    preferences of others in their group.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推荐系统**：聚类可以帮助识别相似物品或用户群体，然后可以根据该群体中其他人的偏好向用户推荐物品。'
- en: '**Social network analysis**: Clustering can help identify communities or groups
    within large networks of individuals based on their interactions or shared interests.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社交网络分析**：聚类可以帮助根据个人的互动或共同兴趣，在大型个人网络中识别社区或群体。'
- en: These applications show how versatile and powerful clustering can be in extracting
    meaningful patterns from vast amounts of data across different fields.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 这些应用展示了聚类如何在不同领域从大量数据中提取有意义的模式，其灵活性和强大功能。
- en: Identify features of deep learning techniques
  id: totrans-363
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别深度学习技术的特征
- en: Deep learning is an advanced subset of machine learning that mimics the human
    brain’s way of learning through an artificial neural network structure. These
    networks consist of multiple layers of neurons that process data in a hierarchical
    manner, which is why the models are called **deep neural networks** (**DNNs**).
    Deep learning automates feature extraction from large volumes of unstructured
    data, such as images and text, significantly enhancing machine learning tasks’
    accuracy and efficiency.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个高级子集，它通过人工神经网络结构模拟人类大脑的学习方式。这些网络由多个层次神经元组成，以分层方式处理数据，这就是为什么这些模型被称为**深度神经网络**（**DNNs**）。深度学习自动从大量非结构化数据中提取特征，如图像和文本，显著提高了机器学习任务的准确性和效率。
- en: Unlike traditional machine learning, which relies on manual feature extraction,
    deep learning models learn to identify and differentiate data features automatically.
    This learning process requires significant computational power and data, utilizing
    backpropagation and optimization algorithms such as stochastic gradient descent
    to adjust neuron connections and minimize prediction errors.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的机器学习不同，后者依赖于手动特征提取，深度学习模型学会自动识别和区分数据特征。这个过程需要大量的计算能力和数据，利用反向传播和优化算法，如随机梯度下降，来调整神经元连接并最小化预测误差。
- en: Deep learning applications include regression, classification, natural language
    processing, and computer vision, revolutionizing fields such as autonomous driving,
    virtual assistants, facial recognition, and recommendation systems. The training
    process involves fitting data to predict outcomes based on features, iteratively
    adjusting the model to improve accuracy. This technology represents a significant
    advancement in machines’ abilities to perform complex tasks by learning from data.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习应用包括回归、分类、自然语言处理和计算机视觉，这些应用正在改变自动驾驶、虚拟助手、面部识别和推荐系统等领域。训练过程涉及拟合数据以预测基于特征的输出，迭代调整模型以提高准确性。这项技术代表了机器通过学习数据执行复杂任务能力的一个重大进步。
- en: Just like other machine learning techniques discussed in this chapter, deep
    learning involves fitting training data to a function that can predict a label
    (*y*) based on the value of one or more features (*x*). The function (*f*(*x*))
    is the outer layer of a nested function in which each layer of the neural network
    encapsulates functions that operate on *x* and the weight (*w*) values associated
    with them. The algorithm used to train the model involves iteratively feeding
    the feature values (*x*) in the training data forward through the layers to calculate
    output values for *ŷ*, validating the model to evaluate how far off the calculated
    *ŷ* values are from the known *y* values (which quantifies the level of error,
    or loss, in the model), and then modifying the weights (*w*) to reduce the loss.
    The trained model includes the final weight values that result in the most accurate
    predictions.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 就像本章讨论的其他机器学习技术一样，深度学习涉及将训练数据拟合到一个函数中，该函数可以根据一个或多个特征（*x*）的值预测标签（*y*）。函数（*f*(*x*））是嵌套函数的外层，其中每个神经网络层封装了操作于*x*及其相关联的权重（*w*）值的函数。训练模型所使用的算法涉及迭代地将训练数据中的特征值（*x*）向前传递通过层来计算输出值*ŷ*，验证模型以评估计算出的*ŷ*值与已知的*y*值（这量化了模型中的错误或损失水平）有多远，然后修改权重（*w*）以减少损失。训练好的模型包括导致最准确预测的最终权重值。
- en: So how does deep learning work? The foundation of deep learning is a structure
    called the **neural network**.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，深度学习是如何工作的呢？深度学习的基础是一个称为**神经网络**的结构。
- en: 'Neural networks refer to computational systems designed to mimic the human
    brain and nervous system’s structure and function. Similar to the brain’s neurons,
    artificial neural networks consist of units called neurons or nodes, interconnected
    with one another. These connections are characterized by weights and biases, activating
    subsequent nodes once input values surpass predefined thresholds. Visualize a
    neural network as a series of nodes organized in layers, where each node connects
    to several others in the neighboring layer, with the output of each node affecting
    the inputs of nodes in the next layer, kind of like a 3D flowchart where each
    condition and action can connect to other conditions and actions. *Figure 3**.10*
    depicts an example of a simple neural network design:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是指设计用来模拟人脑和神经系统结构和功能的计算系统。类似于大脑的神经元，人工神经网络由称为神经元或节点的单元组成，它们相互连接。这些连接由权重和偏差特征化，一旦输入值超过预定义的阈值，就会激活后续节点。将神经网络想象为一组按层组织的节点，其中每个节点连接到相邻层中的几个节点，每个节点的输出影响下一层节点的输入，有点像3D流程图，其中每个条件和动作都可以连接到其他条件和动作。*图3.10*展示了简单神经网络设计的一个示例：
- en: '![Figure 3.10 – Example of a simple neural network](img/B22207_03_10.jpg)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![图3.10 – 简单神经网络的示例](img/B22207_03_10.jpg)'
- en: Figure 3.10 – Example of a simple neural network
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10 – 简单神经网络的示例
- en: Each input layer node is connected to two nodes in the hidden layer and the
    resultant data is connected to the output layer. The input layer of a neural network
    processes raw data and passes it to the nodes of hidden layers, which classify
    the data points according to the target criteria. As data progresses through successive
    hidden layers, the target value’s focus becomes more refined, leading to more
    precise assumptions.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 每个输入层节点都与隐藏层中的两个节点相连，并且结果数据连接到输出层。神经网络的输入层处理原始数据并将其传递到隐藏层的节点，这些节点根据目标标准对数据点进行分类。随着数据通过连续的隐藏层，目标值的焦点变得更加精细，从而得出更精确的假设。
- en: A **loss function** is used to compare the predicted *ŷ* values against the
    known values. The function compiles those differences, resulting in the aggregate
    variance for multiple cases. This total variance is summarized as the **loss**.
    An optimization function may be employed to evaluate the weight of the various
    losses and determine how to adjust to minimize the loss. These changes are **backpropagated**
    throughout the neural network to replace the original values and the model re-learns
    based on the updated values. Each iteration of this process is known as an **epoch**;
    epochs are repeated until the loss and predictions fall within an acceptable threshold.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '**损失函数**用于比较预测的*ŷ*值与已知值。该函数汇总这些差异，得出多个案例的总方差。这个总方差被总结为**损失**。可能使用一个优化函数来评估各种损失的权重，并确定如何调整以最小化损失。这些变化会**反向传播**到整个神经网络中，以替换原始值，并且模型会根据更新的值重新学习。这个过程每次迭代被称为**一个epoch**；epochs会重复进行，直到损失和预测值在可接受的阈值范围内。'
- en: Finally, the output layer utilizes the information from the hidden layers to
    determine the most likely label.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，输出层利用隐藏层的信息来确定最可能的标签。
- en: When you hear people talk about **deep learning**, it’s really about expanding
    the concept of neural networks with more hidden layers (representing more dimensions
    of data classification), resulting in more precise predictions.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 当你听到人们谈论**深度学习**时，实际上是在扩展神经网络的观念，增加更多的隐藏层（代表更多数据分类维度），从而实现更精确的预测。
- en: Example
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: An example of deep learning in action is an image identification scenario where
    the goal is to predict animal types in images. In this case, a deep learning model,
    typically a **Convolutional Neural Network** (**CNN**), would be trained on a
    large dataset of animal images. Each image in the dataset is labeled with the
    type of animal it contains (e.g., dog, cat, tiger, etc.).
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的一个实际应用示例是图像识别场景，其目标是预测图像中的动物类型。在这种情况下，一个深度学习模型，通常是一个**卷积神经网络**（**CNN**），会在大量动物图像数据集上进行训练。数据集中的每张图像都会标注包含的动物类型（例如，狗、猫、老虎等）。
- en: During training, the CNN learns to recognize patterns and features in the images,
    such as shapes, textures, and colors, that distinguish one animal from another.
    The network consists of various layers, including input, hidden, and output layers.
    The input layer receives the raw image data, while the hidden layers process the
    data through a series of filters, identifying increasingly complex features at
    each layer. The output layer then uses the information extracted by the hidden
    layers to classify the image according to the type of animal it most likely represents.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，卷积神经网络（CNN）学习识别图像中的模式和特征，如形状、纹理和颜色，这些特征可以区分不同的动物。该网络由各种层组成，包括输入层、隐藏层和输出层。输入层接收原始图像数据，而隐藏层通过一系列过滤器处理数据，在每个层中识别越来越复杂的特征。输出层随后使用隐藏层提取的信息，根据最可能代表的动物类型对图像进行分类。
- en: Once the model is trained, it can be used to predict the type of animal in new,
    unseen images by processing the images through the same network and producing
    a prediction based on the features it has learned to recognize.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，它可以通过处理新图像并通过相同的网络产生预测，来预测新图像中动物的类型。该模型通过学习识别的特征，基于其识别到的特征来生成预测。
- en: Applications
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用
- en: This ability to automatically and accurately classify images makes deep learning
    a powerful tool for tasks such as wildlife monitoring, pet identification, and
    even medical image analysis.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 这种自动且准确地对图像进行分类的能力，使深度学习成为野生动物监测、宠物识别甚至医学图像分析等任务的有力工具。
- en: 'Deep learning has many of the same applications as clustering (as its goals
    are very similar—the identification and classification or grouping of previously
    unlabeled data). As such, real-world applications include everything that clustering
    can do, as well as many others:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习与聚类有许多相同的应用（因为其目标非常相似——识别和分类或分组先前未标记的数据）。因此，实际应用包括聚类可以做到的一切，以及许多其他应用：
- en: '**Image recognition and computer vision**: Deep learning models, especially
    CNNs, are widely used in image recognition tasks due to the way they are structured,
    mimicking human visual perception. They can identify faces, objects, scenes, and
    actions in images and videos. This technology underpins various applications,
    including security surveillance, medical imaging diagnosis, and autonomous vehicles.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像识别和计算机视觉**：由于深度学习模型的结构方式模仿人类视觉感知，因此它们在图像识别任务中得到了广泛应用，特别是卷积神经网络（CNN）。它们可以在图像和视频中识别面部、物体、场景和动作。这项技术支撑着各种应用，包括安全监控、医学影像诊断和自动驾驶汽车。'
- en: '**Natural Language Processing** (**NLP**): Deep learning has significantly
    advanced the capabilities of NLP, enabling applications such as language translation,
    sentiment analysis, and chatbots. Models such as transformers and **Recurrent
    Neural Networks** (**RNNs**) have been pivotal in these advancements.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言处理（NLP）**：深度学习显著提高了NLP的能力，使得语言翻译、情感分析和聊天机器人等应用成为可能。Transformer和**循环神经网络（RNNs**）等模型在这些进步中发挥了关键作用。'
- en: '**Speech recognition and generation**: Deep learning models are at the heart
    of voice-activated systems such as virtual assistants (e.g., Siri, Alexa), speech-to-text
    transcription services, and voice-enabled customer service systems.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音识别和生成**：深度学习模型是语音激活系统（如虚拟助手（例如，Siri、Alexa）、语音转文本转录服务和语音驱动的客户服务系统）的核心。'
- en: '**Recommendation systems**: Deep learning is used to power recommendation engines
    on platforms such as Netflix, YouTube, and Amazon, enhancing user experience by
    personalizing content, products, and services based on individual preferences
    and past behavior.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推荐系统**：深度学习被用于为Netflix、YouTube和Amazon等平台上的推荐引擎提供动力，通过根据个人偏好和以往行为个性化内容、产品和服务来提升用户体验。'
- en: '**Autonomous vehicles**: Deep learning models process and interpret the complex
    visual environment required for autonomous navigation, including recognizing traffic
    signs, signals, pedestrians, and other vehicles.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动驾驶汽车**：深度学习模型处理和解释自动驾驶所需的复杂视觉环境，包括识别交通标志、信号、行人和其他车辆。'
- en: '**Fraud detection**: Financial institutions use deep learning to detect unusual
    patterns and prevent fraudulent activities in real-time, significantly reducing
    the risk of financial losses for both financial institutions and consumers.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欺诈检测**：金融机构利用深度学习检测异常模式，实时预防欺诈活动，显著降低了金融机构和消费者遭受财务损失的风险。'
- en: '**Drug discovery and genomics**: In the field of biotechnology, deep learning
    aids in the discovery of new drugs and the understanding of genetic sequences,
    contributing to personalized medicine and the treatment of complex diseases.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**药物发现和基因组学**：在生物技术领域，深度学习有助于新药的开发和对基因序列的理解，为个性化医疗和复杂疾病的治疗做出贡献。'
- en: '**Content generation**: Deep learning techniques are used to create realistic
    images, videos, text, and voice, enabling applications such as virtual reality,
    game development, and the creation of art and music.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容生成**：深度学习技术用于创建逼真的图像、视频、文本和声音，使虚拟现实、游戏开发以及艺术和音乐的创作等应用成为可能。'
- en: '**Sentiment analysis**: Companies use deep learning to analyze customer feedback,
    social media comments, and reviews to gauge public sentiment, improve products,
    and tailor services.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**情感分析**：公司使用深度学习来分析客户反馈、社交媒体评论和评论，以衡量公众情绪，改进产品并定制服务。'
- en: These applications demonstrate the versatility and transformative potential
    of deep learning across different domains, driving innovation and improving efficiency,
    accuracy, and user experience.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 这些应用展示了深度学习在不同领域的多功能性和变革潜力，推动了创新，提高了效率、准确性和用户体验。
- en: Summary
  id: totrans-393
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about many different types of machine learning
    scenarios such as regression, classification, and deep learning. You learned about
    both supervised and unsupervised learning, and where each of those is appropriate.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了多种不同的机器学习场景，如回归、分类和深度学习。你学习了监督学习和无监督学习，以及它们各自适用的场合。
- en: Machine learning is helpful in a variety of real-world scenarios, from weather
    forecasting to medical imaging analysis. You learned about applications for each
    type of machine learning technology and even how to compute several metrics to
    determine how accurate trained models are.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习在众多现实场景中都有帮助，从天气预报到医学影像分析。你了解了每种机器学习技术的应用，甚至学习了如何计算几个指标来确定训练模型的准确性。
- en: In the next chapter, we’ll start talking about core machine learning concepts.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始讨论核心机器学习概念。
- en: Exam Readiness Drill – Chapter Review Questions
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考试准备练习 – 第 3 章复习问题
- en: Apart from a solid understanding of key concepts, being able to think quickly
    under time pressure is a skill that will help you ace your certification exam.
    That is why working on these skills early on in your learning journey is key.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对关键概念有扎实的理解外，能够在时间压力下快速思考是一项帮助你通过认证考试的关键技能。这就是为什么在学习的早期阶段就培养这些技能至关重要。
- en: Chapter review questions are designed to improve your test-taking skills progressively
    with each chapter you learn and review your understanding of key concepts in the
    chapter at the same time. You’ll find these at the end of each chapter.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 复习问题旨在通过学习并复习每一章的内容来逐步提高你的应试技巧，同时检查你对章节中关键概念的理解。你可以在每一章的末尾找到这些复习问题。
- en: Before You Proceed
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前
- en: If you don't have a Packt Library subscription or you haven't purchased this
    book from the Packt store, you will need to unlock the online resources to access
    the exam readiness drills. Unlocking is free and needs to be done only once. To
    learn how to do that, head over to the chapter titled [*Chapter 12*](B22207_12.xhtml#_idTextAnchor228)*,
    Accessing the* *Online Resources*.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有 Packt 图书馆订阅或没有从 Packt 商店购买这本书，你需要解锁在线资源以访问考试准备练习。解锁是免费的，只需进行一次。要了解如何操作，请参阅标题为
    [*第 12 章*](B22207_12.xhtml#_idTextAnchor228) 的章节，*访问在线资源*。
- en: 'To open the Chapter Review Questions for this chapter, perform the following
    steps:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 要打开本章的复习问题，请执行以下步骤：
- en: Click the link – [https://packt.link/AI-900_CH03](https://packt.link/AI-900_CH03).
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击链接 – [https://packt.link/AI-900_CH03](https://packt.link/AI-900_CH03)。
- en: 'Alternatively, you can scan the following QR code (*Figure 3**.11*):'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者，你可以扫描以下二维码 (*图 3.11*)：
- en: '![Figure 3.11– QR code that opens Chapter Review Questions for logged-in users](img/B22207_03_11.jpg)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.11– 为登录用户打开第 3 章复习问题的二维码](img/B22207_03_11.jpg)'
- en: Figure 3.11– QR code that opens Chapter Review Questions for logged-in users
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.11– 为登录用户打开第 3 章复习问题的二维码
- en: 'Once you log in, you’ll see a page similar to the one shown in *Figure 3**.12*:'
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你登录，你将看到一个类似于 *图 3.12* 所示的页面：
- en: '![Figure 3.12 – Chapter Review Questions for Chapter 3](img/B22207_03_12.jpg)'
  id: totrans-408
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.12 – 第 3 章的复习问题](img/B22207_03_12.jpg)'
- en: Figure 3.12 – Chapter Review Questions for Chapter 3
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.12 – 第 3 章的复习问题
- en: Once ready, start the following practice drills, re-attempting the quiz multiple
    times.
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备就绪后，开始以下练习，多次重新尝试测验。
- en: Exam Readiness Drill
  id: totrans-411
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 考试准备练习
- en: For the first three attempts, don’t worry about the time limit.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前三次尝试，不必担心时间限制。
- en: ATTEMPT 1
  id: totrans-413
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尝试1
- en: The first time, aim for at least **40%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix your learning gaps.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次，目标至少是**40%**。查看你答错的答案，并再次阅读章节中的相关部分，以填补学习上的差距。
- en: ATTEMPT 2
  id: totrans-415
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尝试2
- en: The second time, aim for at least **60%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix any remaining learning
    gaps.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次，目标至少是**60%**。查看你答错的答案，并再次阅读章节中的相关部分，以修复任何剩余的学习差距。
- en: ATTEMPT 3
  id: totrans-417
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尝试3
- en: The third time, aim for at least **75%**. Once you score 75% or more, you start
    working on your timing.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 第三次，目标至少是**75%**。一旦得分达到75%或更高，你就可以开始练习计时了。
- en: Tip
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: You may take more than **three** attempts to reach 75%. That’s okay. Just review
    the relevant sections in the chapter till you get there.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要超过**三次**尝试才能达到75%。这没关系。只需复习章节中的相关部分，直到你达到目标。
- en: Working On Timing
  id: totrans-421
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作在计时上
- en: 'Your aim is to keep the score the same while trying to answer these questions
    as quickly as possible. Here’s an example of how your next attempts should look
    like:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 你的目标是保持分数不变，同时尽可能快地回答这些问题。以下是你下一次尝试应该看起来像的例子：
- en: '| **Attempt** | **Score** | **Time Taken** |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| **尝试** | **分数** | **用时** |'
- en: '| --- | --- | --- |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Attempt 5 | 77% | 21 mins 30 seconds |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| 尝试5 | 77% | 21分钟30秒 |'
- en: '| Attempt 6 | 78% | 18 mins 34 seconds |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| 尝试6 | 78% | 18分钟34秒 |'
- en: '| Attempt 7 | 76% | 14 mins 44 seconds |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| 尝试7 | 76% | 14分钟44秒 |'
- en: Table 3.10 – Sample timing practice drills on the online platform
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.10 – 在线平台上的样本计时练习
- en: Note
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The time limits shown in the above table are just examples. Set your own time
    limits with each attempt based on the time limit of the quiz on the website.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 上表中显示的时间限制只是示例。根据网站上的测验时间限制，为每次尝试设定自己的时间限制。
- en: With each new attempt, your score should stay above **75%** while your “time
    taken” to complete should “decrease”. Repeat as many attempts as you want till
    you feel confident dealing with the time pressure.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 每次新的尝试，你的分数应保持在**75%**以上，而完成所需的时间“应减少”。直到你觉得自己能够应对时间压力，可以尝试尽可能多次。
