- en: 7\. Model Evaluation
  id: totrans-0
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7\. 模型评估
- en: Overview
  id: totrans-1
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter is an introduction to how you can improve a model's performance
    by using hyperparameters and model evaluation metrics. You will see how to evaluate
    regression and classification models using a number of metrics and learn how to
    choose a suitable metric for evaluating and tuning a model.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了如何通过使用超参数和模型评估指标来提升模型的性能。你将了解如何使用多种指标评估回归和分类模型，并学习如何选择合适的指标来评估和调优模型。
- en: By the end of this chapter, you will be able to implement various sampling techniques
    and perform hyperparameter tuning to find the best model. You will also be well
    equipped to calculate feature importance for model evaluation.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，你将能够实施各种采样技术并进行超参数调整，以找到最佳模型。你还将具备计算特征重要性以进行模型评估的能力。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 介绍
- en: 'In the previous chapters, we discussed the two types of supervised learning
    problems, regression and classification, followed by ensemble models, which are
    built from a combination of base models. We built several models and discussed
    how and why they work. However, that is not enough to take a model to production.
    Model development is an iterative process, and the model training step is followed
    by validation and updating steps, as shown in the following figure:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们讨论了两种监督学习问题：回归和分类，然后介绍了集成模型，这些模型是由多个基础模型组合而成。我们构建了多个模型并讨论了它们的工作原理和原因。然而，这些还不足以将模型投入生产。模型开发是一个迭代过程，模型训练步骤之后是验证和更新步骤，如下图所示：
- en: '![Figure 7.1: Machine learning model development process'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.1：机器学习模型开发过程'
- en: '](img/image-91L52I4W.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-91L52I4W.jpg)'
- en: 'Figure 7.1: Machine learning model development process'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1：机器学习模型开发过程
- en: 'This chapter will explain the peripheral steps in the process shown in the
    preceding flowchart; we will discuss how to select the appropriate hyperparameters
    and how to perform model validation using the appropriate error metrics. Improving
    a model''s performance happens by iteratively performing these two tasks. But
    why is it important to evaluate your model? Say you''ve trained your model and
    provided some hyperparameters, made predictions, and found its accuracy. That''s
    the gist of it, but how do you make sure that your model is performing to the
    best of its ability? We need to ensure that the performance measure that you''ve
    come up with is actually representative of the model and that it will indeed perform
    well on an unseen test dataset. The essential part of making sure that the model
    is the best version of itself comes after the initial training: the process of
    evaluating and improving the performance of the model. This chapter will take
    you through the essential techniques required when it comes to this.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将解释上图流程图中的外围步骤；我们将讨论如何选择合适的超参数，并如何使用合适的错误指标进行模型验证。提高模型性能是通过迭代执行这两个任务来完成的。那么，为什么评估模型如此重要呢？假设你已经训练好了模型，并提供了一些超参数，做出了预测，并得到了准确度。这就是模型的核心，但你如何确保你的模型能够发挥最佳性能呢？我们需要确保你制定的性能评估标准确实能够代表模型，并且它在未见过的测试数据集上也能表现良好。确保模型是最佳版本的关键步骤发生在初始训练之后：评估和提高模型性能的过程。本章将带你了解这一过程中所需的核心技术。
- en: 'In this chapter, we will first discuss why model evaluation is important, and
    introduce several evaluation metrics for both regression tasks and classification
    tasks that can be used to quantify the predictive performance of a model. This
    will be followed by a discussion on hold-out datasets and k-fold cross-validation
    and why it is imperative to have a test set that is independent of the validation
    set. After this, we''ll look at tactics we can use to boost the performance of
    the model. In the previous chapter, we talked about how having a model with a
    high bias or a high variance can result in suboptimal performance, and how building
    an ensemble of models can help us build a robust system that makes more accurate
    predictions without increasing the overall variance. We also mentioned the following
    as techniques to avoid overfitting our model to the training data:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先讨论为什么模型评估很重要，并介绍几种用于回归任务和分类任务的评估指标，这些指标可以用来量化模型的预测性能。接下来，我们将讨论保留数据集和k折交叉验证，并解释为什么必须有一个独立于验证集的测试集。之后，我们将探讨可以用来提高模型性能的策略。在上一章中，我们讨论了高偏差或高方差的模型如何导致次优的性能，以及如何通过构建模型集成来帮助我们建立一个稳健的系统，使预测更加准确，而不会增加整体方差。我们还提到了以下技术来避免将模型过度拟合到训练数据：
- en: 'To get more data: A highly complex model can easily overfit to a small dataset
    but may not be able to as easily on a larger dataset.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 获取更多数据：一个高度复杂的模型可能容易在小数据集上过拟合，但在较大数据集上可能不容易过拟合。
- en: 'Dimensionality reduction: Reducing the number of features can help make the
    model less complex.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 降维：减少特征数量可以帮助使模型更简单。
- en: 'Regularization: A new term is added to the cost function in order to adjust
    the coefficients (especially the high-degree coefficients in linear regression)
    toward a small value.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化：在代价函数中添加一个新的项，以便将系数（特别是线性回归中的高次项系数）调整到较小的值。
- en: In this chapter, we'll introduce learning curves and validation curves as a
    way to see how variations in training and validation errors allow us to see whether
    the model needs more data, and where the appropriate level of complexity is. This
    will be followed by a section on hyperparameter tuning in an effort to boost performance,
    and a brief introduction to feature importance.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍学习曲线和验证曲线，这些曲线可以帮助我们查看训练和验证误差的变化，了解模型是否需要更多数据，以及适当的复杂度级别在哪里。接下来我们将讨论超参数调优以提高性能，并简要介绍特征重要性。
- en: Note
  id: totrans-15
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'All the relevant code for this chapter can be found here: https://packt.live/2T1fCWM.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有相关代码可以在这里找到：https://packt.live/2T1fCWM。
- en: Importing the Modules and Preparing Our Dataset
  id: totrans-17
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 导入模块并准备数据集
- en: In the previous exercises and activities, we used terms such as Mean Absolute
    Error (MAE) and accuracy. In machine learning terms, these are called evaluation
    metrics and, in the next sections, we will discuss some useful evaluation metrics,
    what they are, and how and when to use them.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的练习和活动中，我们使用了诸如平均绝对误差（MAE）和准确率等术语。在机器学习中，这些被称为评估指标，在接下来的部分中，我们将讨论一些有用的评估指标，它们是什么，如何使用以及何时使用它们。
- en: Note
  id: totrans-19
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Although this section is not positioned as an exercise, we encourage you to
    follow through this section carefully by executing the presented code. We will
    be using the code presented here in the upcoming exercises.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这一部分没有被定位为练习，但我们鼓励你通过执行呈现的代码，仔细跟进这一部分。我们将在接下来的练习中使用这里展示的代码。
- en: We will now load the data and models that we trained as part of Chapter 6, Ensemble
    Modeling. We will use the stacked linear regression model from Activity 6.01,
    Stacking with Standalone and Ensemble Algorithms, and the random forest classification
    model to predict the survival of passengers from Exercise 6.06, Building the Ensemble
    Model Using Random Forest.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将加载在第6章《集成建模》中训练的数据和模型。我们将使用在活动6.01《使用独立和集成算法进行堆叠》中创建的堆叠线性回归模型，以及在练习6.06《使用随机森林构建集成模型》中创建的随机森林分类模型，来预测乘客的生存情况。
- en: 'First, we need to import the relevant libraries:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要导入相关的库：
- en: import pandas as pd
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: import pandas as pd
- en: import numpy as np
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: import pickle
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: import pickle
- en: '%matplotlib inline'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '%matplotlib inline'
- en: import matplotlib.pyplot as plt
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: import matplotlib.pyplot as plt
- en: 'Next, load the processed data files from Chapter 6, Ensemble Modeling. We will
    use pandas'' read_csv() method to read in our prepared datasets, which we will
    use in the exercises in this chapter. First, we''ll read the house price data:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，加载第六章集成建模中处理过的数据文件。我们将使用 pandas 的 `read_csv()` 方法读取我们准备好的数据集，这些数据集将在本章的练习中使用。首先，我们将读取房价数据：
- en: house_prices_reg = \
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: house_prices_reg = \
- en: pd.read_csv('../Datasets/boston_house_prices_regression.csv')
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: pd.read_csv('../Datasets/boston_house_prices_regression.csv')
- en: house_prices_reg.head()
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: house_prices_reg.head()
- en: 'We''ll see the following output:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下输出：
- en: '![Figure 7.2: First five rows of house_prices'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.2：房价数据集的前五行'
- en: '](img/image-RII8SDX9.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-RII8SDX9.jpg)'
- en: 'Figure 7.2: First five rows of house_prices'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2：房价数据集的前五行
- en: 'Next, we''ll read in the Titanic data:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将读取 Titanic 数据：
- en: titanic_clf = pd.read_csv('../Datasets/titanic_classification.csv')
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: titanic_clf = pd.read_csv('../Datasets/titanic_classification.csv')
- en: titanic_clf.head()
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: titanic_clf.head()
- en: 'We''ll see the following output:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下输出：
- en: '![Figure 7.3: First five rows of Titanic'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.3：Titanic 数据集的前五行'
- en: '](img/image-7X7RBYDH.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-7X7RBYDH.jpg)'
- en: 'Figure 7.3: First five rows of Titanic'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：Titanic 数据集的前五行
- en: 'Next, load the model files that we will use for the exercises in this chapter
    by using the pickle library to load them from a binary file:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用 pickle 库从二进制文件加载本章练习中将使用的模型文件：
- en: 'with open(''../../Saved_Models/titanic_regression.pkl'', ''rb'') as f:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`open('../../Saved_Models/titanic_regression.pkl', 'rb')`打开文件：
- en: reg = pickle.load(f)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: reg = pickle.load(f)
- en: 'with open(''../../Saved_Models/random_forest_clf.pkl'', ''rb'') as f:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`open('../../Saved_Models/random_forest_clf.pkl', 'rb')`打开文件：
- en: rf = pickle.load(f)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: rf = pickle.load(f)
- en: with open('../../Saved_Models/stacked_linear_regression.pkl',\
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`open('../../Saved_Models/stacked_linear_regression.pkl',\`
- en: '''rb'') as f:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '''rb'') as f:'
- en: reg = pickle.load(f)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: reg = pickle.load(f)
- en: So far, we have successfully loaded the necessary datasets as well as trained
    machine learning models from our previous exercises and activities in this section.
    Before starting to use these loaded datasets and models to explore the evaluation
    metrics, let's first acquire an understanding of different kinds of evaluation
    metrics.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经成功加载了必要的数据集以及从前面的练习和活动中训练好的机器学习模型。在开始使用这些加载的数据集和模型探索评估指标之前，让我们首先了解不同类型的评估指标。
- en: Note
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find the files for saved models at the following link: https://packt.live/2vjoSwf.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下链接找到保存的模型文件：https://packt.live/2vjoSwf。
- en: Evaluation Metrics
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估指标
- en: 'Evaluating a machine learning model is an essential part of any project: once
    we have allowed our model to learn from the training data, the next step is to
    measure the performance of the model. We need to find a metric that can not only
    tell us how accurate the predictions made by the model are, but also allow us
    to compare the performance of a number of models so that we can select the one
    best suited for our use case.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 评估机器学习模型是任何项目中的一个关键部分：一旦我们让模型从训练数据中学习，下一步就是衡量模型的性能。我们需要找到一种指标，不仅能够告诉我们模型预测的准确性，还能让我们比较多个模型的性能，从而选择最适合我们用例的模型。
- en: Defining a metric is usually one of the first things we should do when defining
    our problem statement and before we begin the exploratory data analysis, since
    it's a good idea to plan ahead and think about how we intend to evaluate the performance
    of any model we build and how to judge whether it is performing optimally. Eventually,
    calculating the performance evaluation metric will fit into the machine learning
    pipeline.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个指标通常是我们在定义问题陈述时要做的第一件事，而且是在开始进行探索性数据分析之前，因为提前规划并思考如何评估我们所构建的任何模型的表现，以及如何判断其是否达到最佳表现，都是一个好主意。最终，计算性能评估指标将成为机器学习管道的一部分。
- en: Needless to say, evaluation metrics will be different for regression tasks and
    classification tasks, since the output values in the former are continuous, while
    the outputs in the latter are categorical. In this section, we'll look at the
    different metrics we can use to quantify the predictive performance of a model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 不用多说，回归任务和分类任务的评估指标是不同的，因为前者的输出值是连续的，而后者的输出值是类别型的。在本节中，我们将探讨可以用来量化模型预测性能的不同指标。
- en: Regression Metrics
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 回归指标
- en: For an input variable, X, a regression model gives us a predicted value that
    can take on a range of values. The ideal scenario would be to have the model predict
    values that are as close as possible to the actual value of y. Therefore, the
    smaller the difference between the two, the better the model performs. Regression
    metrics mostly involve looking at the numerical difference between the predicted
    value and actual value (that is, the residual or error value) for each data point,
    and subsequently aggregating these differences in some way.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输入变量 X，回归模型给出了一个预测值，该值可以取一系列不同的值。理想的情况是模型预测的值尽可能接近实际值 y。因此，二者之间的差异越小，模型表现得越好。回归度量通常涉及查看每个数据点的预测值与实际值之间的数值差异（即残差或误差值），然后以某种方式聚合这些差异。
- en: 'Let''s look at the following plot, which plots the actual and predicted values
    for every point X:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下下面的图表，该图展示了每个 X 点的实际值与预测值：
- en: '![Figure 7.4: Residuals between actual and predicted outputs in a linear regression
    problem'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.4：线性回归问题中实际输出与预测输出之间的残差](img/image-HF45QXRY.jpg)'
- en: '](img/image-R47Y9F4G.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-R47Y9F4G.jpg)'
- en: 'Figure 7.4: Residuals between actual and predicted outputs in a linear regression
    problem'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4：线性回归问题中实际输出与预测输出之间的残差
- en: However, we can't just find the mean value of overall data points, since there
    could be data points that have a prediction error that is positive or negative,
    and the aggregate would ultimately end up canceling out a lot of the errors and
    severely overestimate the performance of the model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们不能仅仅对所有数据点求平均值，因为可能会有数据点的预测误差为正或负，最终聚合会取消掉许多误差，严重高估模型的性能。
- en: 'Instead, we can consider the absolute error for each data point and find the
    MAE, which is given by the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可以考虑每个数据点的绝对误差并计算 MAE，公式如下：
- en: '![Figure 7.5: MAE'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.5：平均绝对误差](img/image-HF45QXRY.jpg)'
- en: '](img/image-HF45QXRY.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-HF45QXRY.jpg)'
- en: 'Figure 7.5: MAE'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5：平均绝对误差
- en: Here, yi and ŷi are the actual and predicted values, respectively, for the ith
    data point.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，yi 和 ŷi 分别是第 i 个数据点的实际值和预测值。
- en: MAE is a linear scoring function, which means that it gives each residual an
    equal weight when it aggregates the errors. The MAE can take on any value from
    zero to infinity and is indifferent to the direction (positive or negative) of
    errors. Since these are error metrics, a lower value (as close to zero as possible)
    is usually desirable.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: MAE 是一个线性评分函数，这意味着在聚合误差时，它对每个残差赋予相等的权重。MAE 可以取从零到无穷大的任何值，且对误差的方向（正或负）不敏感。由于这些是误差指标，通常情况下，较低的值（尽可能接近零）是更可取的。
- en: 'In order to not let the direction of the error affect the performance estimate,
    we can also take the square of the error terms. Taking the mean of the squared
    errors gives us the Mean Squared Error (MSE):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免误差方向影响性能估计，我们还可以对误差项进行平方处理。对平方误差求平均得到均方误差（MSE）：
- en: '![Figure 7.6: MSE'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.6：均方误差](img/image-TZPF7OIL.jpg)'
- en: '](img/image-E2RVLXAK.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-E2RVLXAK.jpg)'
- en: 'Figure 7.6: MSE'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6：均方误差
- en: 'While the MAE has the same units as the target variable, y, the units for the
    MSE will be the squared unit of y, which may make the MSE slightly less interpretable
    while judging the model in real-world terms. However, if we take the square root
    of the MSE, we get the Root Mean Squared Error (RMSE):'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 MAE 与目标变量 y 具有相同的单位，但 MSE 的单位将是 y 的平方单位，这可能会使得在实际应用中评估模型时，MSE 的解释性稍差。不过，如果我们取
    MSE 的平方根，就得到了均方根误差（RMSE）：
- en: '![Figure 7.7: Root Mean Squared Error'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.7：均方根误差](img/image-R47Y9F4G.jpg)'
- en: '](img/image-TZPF7OIL.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-TZPF7OIL.jpg)'
- en: 'Figure 7.7: Root Mean Squared Error'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7：均方根误差
- en: Since the errors are squared before they are averaged, having even a few error
    values that are high can cause the RMSE value to significantly increase. This
    means that the RMSE is more useful than MAE for judging models in which we want
    to penalize large errors.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在求平均之前，误差被平方，甚至少数较高的误差值也可能导致 RMSE 值显著增加。这意味着 RMSE 在判断我们希望惩罚大误差的模型时，比 MAE 更有用。
- en: 'Since MAE and RMSE have the same units as the target variable, it can be hard
    to judge whether a particular value of the MAE or RMSE is good or bad, since there
    is no scale to refer to. A metric that is commonly used to overcome this problem
    is the R2 Score, or the R-Squared Score:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 MAE 和 RMSE 与目标变量具有相同的单位，因此很难判断某个特定的 MAE 或 RMSE 值是好还是坏，因为没有可参考的尺度。为了解决这个问题，通常使用一个度量标准，即
    R² 得分或 R-squared 得分：
- en: '![Figure 7.8: R-squared score'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.8：R-squared 得分](img/image-E2RVLXAK.jpg)'
- en: '](img/image-BTCJID5U.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-BTCJID5U.jpg)'
- en: 'Figure 7.8: R-squared score'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.8：R 平方分数
- en: 'The R2 score has a lower limit of -∞ and an upper limit of 1\. The base model
    predicts the target variable to be equal to the mean of the target values in the
    training dataset, μ, mathematically written as:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: R2 分数的下限为 -∞，上限为 1。基本模型将目标变量预测为训练数据集目标值的均值 μ，数学表示为：
- en: '![Figure 7.9: Expression for the mean of the target values in the training
    dataset'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.9：训练数据集目标值的均值表达式'
- en: '](img/image-KMJDX6RT.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-KMJDX6RT.jpg)'
- en: 'Figure 7.9: Expression for the mean of the target values in the training dataset'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9：训练数据集目标值的均值表达式
- en: 'And so, for the base model:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于基本模型：
- en: '![Figure 7.10: Expression for the base model target variable'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.10：基本模型目标变量的表达式'
- en: '](img/image-01N2DWDR.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-01N2DWDR.jpg)'
- en: 'Figure 7.10: Expression for the base model target variable'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10：基本模型目标变量的表达式
- en: Keeping this in mind, a negative value of R2 would be one where the trained
    model makes a prediction that is worse than simply predicting the mean value for
    all the data, and a value close to 1 would be achieved if the MSE of the model
    is close to 0.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这一点，如果 R2 的值为负，则表示训练模型的预测比简单预测所有数据的均值还差；如果 R2 值接近 1，则表示模型的 MSE 接近 0。
- en: 'Exercise 7.01: Calculating Regression Metrics'
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习 7.01：计算回归指标
- en: 'In this exercise, we will use the same model and processed dataset that we
    trained in Activity 6.01, Stacking with Standalone and Ensemble Algorithms, in
    Chapter 6, Ensemble Modeling, to calculate regression metrics. We will use scikit-learn''s
    implementation of MAE and MSE:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用与第 6 章“集成建模”中活动 6.01“单一算法与集成算法堆叠”中训练的相同模型和处理后的数据集来计算回归指标。我们将使用 scikit-learn
    实现的 MAE 和 MSE：
- en: Note
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Before beginning this exercise, make sure you have imported the relevant libraries
    and models as listed in the Importing the Modules and Preparing Our Dataset section.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始本练习之前，确保已按照“导入模块和准备数据集”部分列出的方式导入相关库和模型。
- en: 'The code for this exercise can be found here:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 此练习的代码可以在这里找到：
- en: 'Import the metric functions:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 导入指标函数：
- en: from sklearn.metrics import mean_absolute_error, \
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.metrics import mean_absolute_error, \
- en: mean_squared_error, r2_score
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: mean_squared_error, r2_score
- en: from math import sqrt
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: from math import sqrt
- en: 'Use the loaded model to predict the output on the given data. We will use the
    same features as we did in Activity 6.01, Stacking with Standalone and Ensemble
    Algorithms, in Chapter 6, Ensemble Modeling, and use the model to make a prediction
    on the loaded dataset. The column we saved as y is the target variable, and we
    will create X and y accordingly:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用已加载的模型对给定数据进行预测。我们将使用与活动 6.01“单一算法与集成算法堆叠”中相同的特征，在第 6 章“集成建模”中，并使用该模型对加载的数据集进行预测。我们保存的列
    y 是目标变量，我们将相应地创建 X 和 y：
- en: X = house_prices_reg.drop(columns=['y'])
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: X = house_prices_reg.drop(columns=['y'])
- en: y = house_prices_reg['y'].values
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: y = house_prices_reg['y'].values
- en: y_pred = reg.predict(X)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: y_pred = reg.predict(X)
- en: 'Calculate the MAE, RMSE, and R2 scores. Let''s print the values of the MAE
    and the RMSE from the predicted values. Also, print the R2 score for the model:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 计算 MAE、RMSE 和 R2 分数。让我们打印预测值中的 MAE 和 RMSE 的值。同时，打印模型的 R2 分数：
- en: print('Mean Absolute Error = {}'\
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: print('平均绝对误差 = {}'\
- en: .format(mean_absolute_error(y, y_pred)))
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: .format(mean_absolute_error(y, y_pred)))
- en: print('Root Mean Squared Error = {}'\
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: print('均方根误差 = {}'\
- en: .format(sqrt(mean_squared_error(y, y_pred))))
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: .format(sqrt(mean_squared_error(y, y_pred))))
- en: print('R Squared Score = {}'.format(r2_score(y, y_pred)))
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: print('R 平方分数 = {}'.format(r2_score(y, y_pred)))
- en: 'The output will be as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: Mean Absolute Error = 2.874084343939712
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 平均绝对误差 = 2.874084343939712
- en: Root Mean Squared Error = 4.50458397908091
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 均方根误差 = 4.50458397908091
- en: R Squared Score = 0.7634986504091822
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: R 平方分数 = 0.7634986504091822
- en: We can see that the RMSE is higher than the MAE. This shows that there are some
    data points where the residuals are particularly high, which is being highlighted
    by the larger RMSE value. But the R2 score is close to 1, indicating that the
    model actually has close to ideal performance compared to a base model, which
    would predict a mean value.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，RMSE 高于 MAE。这表明存在一些残差特别高的数据点，较大的 RMSE 值突出了这一点。但是 R2 分数接近 1，表明该模型与基本模型相比，实际上具有接近理想的性能，基本模型会预测目标变量为平均值。
- en: Note
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to https://packt.live/3epdfp3.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考 https://packt.live/3epdfp3。
- en: You can also run this example online at https://packt.live/3hMLBnY. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在网上运行这个示例，网址是 [https://packt.live/3hMLBnY](https://packt.live/3hMLBnY)。你必须执行整个笔记本才能获得期望的结果。
- en: Classification Metrics
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分类指标
- en: For an input variable, X, a classification task gives us a predicted value,
    which can take on a limited set of values (two in the case of binary classification
    problems). Since the ideal scenario would be to predict a class for each data
    point that is the same as the actual class, there is no measure of how close or
    far the predicted class is from the actual class. Therefore, to judge the model's
    performance, it would be as simple as determining whether the model predicted
    the class correctly.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个输入变量 X，分类任务会给出一个预测值，该值可以取有限的一组值（在二分类问题中为两个值）。由于理想情况下是预测每个数据点的类别与实际类别相同，因此没有衡量预测类别与实际类别之间距离的标准。因此，判断模型性能的标准就简单得多，基本上就是判断模型是否正确预测了类别。
- en: 'Judging a classification model''s performance can be done in two ways: using
    numerical metrics, or by plotting a curve and looking at the shape of the curve.
    Let''s explore both of these options in greater detail.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 判断分类模型的性能可以通过两种方式进行：使用数值指标，或通过绘制曲线并观察曲线的形状。我们将更详细地探讨这两种方法。
- en: Numerical Metrics
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数值指标
- en: 'The simplest and most basic way to judge the performance of the model is to
    calculate the proportion of the correct predictions to the total number of predictions,
    which gives us the accuracy, as shown in the following figure:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 判断模型性能最简单、最基本的方法是计算正确预测与总预测数之比，这给出了准确率，如下图所示：
- en: '![Figure 7.11: Accuracy'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.11：准确率](img/image-LTXKNB1V.jpg)'
- en: '](img/image-LTXKNB1V.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 7.11: Accuracy](img/image-LTXKNB1V.jpg)'
- en: 'Figure 7.11: Accuracy'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11：准确率
- en: Although the accuracy metric is the same irrespective of the number of classes,
    the next few metrics are discussed keeping in mind a binary classification problem.
    Additionally, accuracy may not be the best metric to judge the performance of
    a classification task in many cases.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管准确率指标无论类别数目如何都是相同的，接下来的几个指标将在二分类问题的背景下讨论。此外，在许多情况下，准确率可能不是判断分类任务性能的最佳指标。
- en: 'Let''s look at an example of fraud detection: say the problem statement is
    to detect whether a particular email is fraudulent. Our dataset, in this case,
    is highly skewed (or imbalanced, that is, there are many more data points belonging
    to one class compared to the other class), with 100 out of 10,000 emails (1% of
    the total) having been classified as fraudulent (having class 1). Say we build
    two models:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一个欺诈检测的示例：假设问题是检测某封邮件是否欺诈。我们的数据集在这种情况下是高度倾斜的（或不平衡的，也就是说，一个类别的数据点比另一个类别的数据点要多得多），其中10,000封邮件中有100封（占总数的1%）被标记为欺诈（属于类别1）。假设我们构建了两个模型：
- en: The first model simply predicts each email as not being fraud, that is, each
    of the 10,000 emails is classified with class 0\. In this case, 9,900 of the 10,000
    were classified correctly, which means the model has 99% accuracy.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个模型简单地将每封邮件预测为不是欺诈邮件，也就是说，10,000封邮件中每一封都被分类为类别0。在这种情况下，10,000封邮件中的9,900封被正确分类，这意味着模型的准确率为99%。
- en: The second model predicts the 100 fraud emails as being fraud, but also predicts
    another 100 emails incorrectly as fraud. In this case as well, 100 data points
    were misclassified out of 10,000, and the model has an accuracy level of 99%.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个模型预测了100封欺诈邮件为欺诈邮件，但也错误地将另外100封邮件预测为欺诈邮件。在这种情况下，100个数据点在10,000个数据中被错误分类，模型的准确率为99%。
- en: 'How do we compare these two models? The purpose of building a fraud detection
    model is to allow us to know how well the fraud was detected: it matters more
    that the fraudulent emails were correctly classified than if non-fraudulent emails
    were classified as fraudulent. Although both the models were equally high in accuracy,
    the second was actually more effective than the first.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何比较这两个模型呢？构建欺诈检测模型的目的是让我们了解欺诈邮件检测的效果：正确分类欺诈邮件比将非欺诈邮件错误分类为欺诈邮件更为重要。尽管这两个模型的准确率相同，第二个模型实际上比第一个更有效。
- en: 'Since this cannot be captured using accuracy, we need the confusion matrix,
    a table with n different combinations of predicted and actual values, where n
    is the number of classes. The confusion matrix essentially gives us a summary
    of the prediction results of a classification problem. Figure 7.12 shows an example
    confusion matrix for a binary classification problem:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 由于准确率无法捕捉到这一点，我们需要混淆矩阵，一个具有 n 种不同预测值和实际值组合的表格，其中 n 是类别数。混淆矩阵本质上给出了分类问题预测结果的总结。图
    7.12 显示了一个二分类问题的混淆矩阵示例：
- en: '![Figure 7.12: Confusion matrix'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.12：混淆矩阵'
- en: '](img/image-U9FWM5QS.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-U9FWM5QS.jpg)'
- en: 'Figure 7.12: Confusion matrix'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12：混淆矩阵
- en: 'Since it is a binary classification problem, the preceding confusion matrix
    can be viewed directly as a table of confusion, in other words, a matrix of true
    positives, true negatives, false positives, and false negatives, as shown in Figure
    7.13\. The table of confusion is always 2 x 2 in size, regardless of binary or
    multiclass classification. In the case of multiclass classification, if we use
    the one-versus-all classification approach, then there will be as many tables
    of confusion as the number of classes:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个二分类问题，前面的混淆矩阵可以直接视为一个混淆表，换句话说，它是一个包含真阳性、真阴性、假阳性和假阴性的矩阵，如图 7.13 所示。混淆表的大小始终是
    2 x 2，无论是二分类还是多分类。在多分类的情况下，如果我们使用一对多分类方法，那么会有与类数相同数量的混淆表：
- en: '![Figure 7.13: Table of confusion'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.13：混淆表'
- en: '](img/image-QJ73DZR8.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-QJ73DZR8.jpg)'
- en: 'Figure 7.13: Table of confusion'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13：混淆表
- en: 'Here is what the terms used in the table of confusion mean:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是混淆表中使用的术语的含义：
- en: 'True positives and true negatives: These are the counts of the correctly predicted
    data points in the positive and negative classes, respectively.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 真阳性和真阴性：这些是分别在正类和负类中正确预测的数据点数量。
- en: 'False positives: These are also known as Type 1 errors and refer to the count
    of the data points that actually belong to the negative class but were predicted
    to be positive. Continuing from the previous example, a false positive case would
    be if a normal email is classified as a fraudulent email.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 假阳性：这也被称为类型 1 错误，指的是实际上属于负类的数据点，但被预测为正类的数量。延续前面的例子，假阳性案例会是如果一封正常的邮件被分类为欺诈邮件。
- en: 'False negatives: These are also known as Type 2 errors and refer to the count
    of the data points that actually belong to the positive class but were predicted
    to be negative. An example of a false negative case would be if a fraudulent email
    was classified as not being one.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 假阴性：这也被称为类型 2 错误，指的是实际上属于正类的数据点，但被预测为负类的数量。一个假阴性案例的例子是，如果一封欺诈邮件被分类为不是欺诈邮件。
- en: 'Two extremely important metrics can be derived from a confusion matrix: precision
    and recall:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 从混淆矩阵中可以得出两个极其重要的指标：精确度和召回率：
- en: '![Figure 7.14: Precision'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.14：精确度'
- en: '](img/image-U4FYMQ8E.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-U4FYMQ8E.jpg)'
- en: 'Figure 7.14: Precision'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14：精确度
- en: '![Figure 7.15: Recall'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.15：召回率'
- en: '](img/image-3A2JB47P.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-3A2JB47P.jpg)'
- en: 'Figure 7.15: Recall'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.15：召回率
- en: While precision tells us how many of the predicted positives were actually positive
    (from the results the model says are relevant, how many are actually relevant?),
    recall tells us how many of the actual positives were correctly predicted to be
    positive (from the real relevant results, how many are included in the model's
    list of relevant results?). These two metrics are especially useful when there
    is an imbalance between the two classes.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度告诉我们预测为正类的有多少实际上是正类（从模型认为相关的结果中，有多少实际是相关的？），而召回率告诉我们有多少实际的正类被正确预测为正类（从实际相关的结果中，有多少被包括在模型的相关结果列表中？）。这两个指标在两类之间存在不平衡时尤其有用。
- en: 'There is usually a trade-off between the precision and recall of a model: if
    you have to recall all the relevant results, the model will generate more results
    that are not accurate, thereby lowering the precision. On the other hand, having
    a higher percentage of relevant results from the generated results would involve
    including as few results as possible. In most cases, you would give a higher priority
    to either the precision or the recall, and this entirely depends on the problem
    statement. For example, since it matters more that all the fraudulent emails are
    correctly classified, recall would be an important metric that would need to be
    maximized.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，模型的精度和召回率之间存在权衡：如果你必须召回所有相关结果，模型会生成更多不准确的结果，从而降低精度。另一方面，如果从生成的结果中获得更高比例的相关结果，则需要尽量减少包含的结果。在大多数情况下，你会优先考虑精度或召回率，这完全取决于问题的具体要求。例如，由于所有欺诈邮件是否被正确分类更为重要，因此召回率将是一个需要最大化的关键指标。
- en: 'The next question that arises is how we take both precision and recall, evaluating
    our model using a single number instead of balancing two separate metrics. The
    F1 score combines the two into a single number that can be used for a fair judgment
    of the model and is equal to the harmonic mean of precision and recall:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的问题是，我们如何通过一个单一的数字来评估模型，而不是平衡两个独立的指标，既考虑精度又考虑召回率。F1 分数将两者结合为一个单一的数字，能够公平地评判模型，它等于精度和召回率的调和平均数：
- en: '![Figure 7.16: F1 score'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.16: F1 分数'
- en: '](img/image-1WZ3SX0O.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-1WZ3SX0O.jpg)'
- en: 'Figure 7.16: F1 score'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7.16: F1 分数'
- en: 'The value of the F1 score will always lie between 0 (if either precision or
    recall is 0) and 1 (if both precision and recall are 1). The higher the score,
    the better the model''s performance is said to be. The F1 score allows equal weightage
    to both measures. It is a specific example of the Fβ metric, where β can be adjusted
    to give more weight to either of the two parameters (recall or precision score)
    using the following formula:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: F1 分数的值始终介于 0（如果精度或召回率为 0）和 1（如果精度和召回率都为 1）之间。分数越高，表示模型的性能越好。F1 分数对精度和召回率给予相等的权重。它是
    Fβ 指标的一个具体实例，其中 β 可以调整，以便对两个参数（召回率或精度分数）中的一个给予更多的权重，公式如下：
- en: '![Figure 7.17: F beta score'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.17: F β 分数'
- en: '](img/image-D8FPG7UG.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-D8FPG7UG.jpg)'
- en: 'Figure 7.17: F beta score'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7.17: F β 分数'
- en: A value of β < 1 focuses more on precision, while taking β > 1 focuses more
    on recall. The F1 score takes β = 1 to give both equal weight.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 当 β < 1 时，更加注重精度，而 β > 1 时，更加注重召回率。F1 分数取 β = 1，给这两个参数相等的权重。
- en: Curve Plots
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 曲线图
- en: Sometimes, instead of predicting the class, we have the class probabilities
    at our disposal. Say, in a binary classification task, the class probabilities
    of both the positive (class A) and negative (class B) classes will always add
    up to unity (or 1), which means that if we take the classification probability
    as equal to the probability of class A and apply a threshold, we can essentially
    use it as a cut-off value to either round up (to 1) or down (to 0), which will
    give the output class.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，我们不是预测类别，而是得到类别的概率。在二分类任务中，正类（A 类）和负类（B 类）的类别概率总和始终为 1（或 1），这意味着如果我们将分类概率等于
    A 类的概率并应用一个阈值，我们实际上可以将其作为一个临界值来进行四舍五入（取 1）或舍去（取 0），从而得出最终的输出类别。
- en: Usually, by varying the threshold, we can get data points that have classification
    probabilities closer to 0.5 from one class to another. For example, with a threshold
    of 0.5, a data point having a probability of 0.4 would be assigned class B and
    a data point having probability 0.6 would be assigned class A. But if we change
    the threshold to 0.35 or 0.65, both those data points would be classified as the
    other class.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，通过改变阈值，我们可以得到一些分类概率接近 0.5 的数据点，这些数据点会从一个类别转换到另一个类别。例如，当阈值为 0.5 时，概率为 0.4
    的数据点会被归为 B 类，而概率为 0.6 的数据点会被归为 A 类。但是，如果我们将阈值改为 0.35 或 0.65，这两个数据点就会被归为另一个类别。
- en: 'As it turns out, varying the probability threshold changes the precision and
    recall values and this can be captured by plotting the precision-recall curve.
    The plot has precision on the Y axis and recall on the X axis, and for a range
    of thresholds starting from 0 to 1 plot each (recall, precision) point. Connecting
    these points gives us the curve. The following graph provides an example:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，改变概率阈值会改变精确度和召回率的值，这可以通过绘制精确度-召回率曲线来捕捉。该图的 Y 轴表示精确度，X 轴表示召回率，对于从 0 到 1
    的一系列阈值，绘制每个（召回率，精确度）点。连接这些点得到曲线。以下图形提供了一个示例：
- en: '![Figure 7.18: Precision-recall curve'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.18：精确度-召回率曲线'
- en: '](img/image-D9L0M4OZ.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-D9L0M4OZ.jpg)'
- en: 'Figure 7.18: Precision-recall curve'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.18：精确度-召回率曲线
- en: We know that in an ideal case, the values of precision and recall will be unity.
    This means that upon increasing the threshold from 0 to 1, the precision would
    stay constant at 1, but the recall would increase from 0 to 1 as more and more
    (relevant) data points would be classified correctly. Thus, in an ideal case,
    the precision-recall curve would essentially just be a square and the Area Under
    the Curve (AUC) would be equal to one.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，在理想情况下，精确度和召回率的值将是 1。这意味着，当将阈值从 0 增加到 1 时，精确度将保持在 1，但召回率会随着越来越多（相关）数据点被正确分类而从
    0 增加到 1。因此，在理想情况下，精确度-召回率曲线本质上会是一个正方形，曲线下面积（AUC）将等于 1。
- en: Thus, we can see that, as with the F1 score, the AUC is another metric derived
    from the precision and recall behavior that uses a combination of their values
    to evaluate the performance of the model. We want the model to achieve an AUC
    as high and close to 1 as possible.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到，和 F1 分数一样，AUC 也是一个由精确度和召回率行为衍生的指标，它结合了这两者的值来评估模型的表现。我们希望模型能够实现尽可能高且接近
    1 的 AUC。
- en: 'The Receiver Operating Characteristic (ROC) curve is another technique used
    for visualizing the performance of a classification model. The ROC curve plots
    the relationship between the True Positive Rate (TPR) on the Y axis and the False
    Positive Rate (FPR) on the X axis across a varying classification probability
    threshold. TPR is exactly the same as the recall (and is also known as the sensitivity
    of the model), and FPR is an equal complement of the specificity (that is, 1 –
    FPR = Specificity); both can be derived from the confusion matrix using these
    formulas:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 接收者操作特征（ROC）曲线是另一种用于可视化分类模型性能的技术。ROC 曲线绘制了 Y 轴上的真正阳性率（TPR）和 X 轴上的假阳性率（FPR）之间的关系，跨越不同的分类概率阈值。TPR
    与召回率完全相同（也被称为模型的敏感性），而 FPR 是特异度的补数（即 1 – FPR = 特异度）；这两者都可以通过以下公式从混淆矩阵中得出：
- en: '![Figure 7.19: True positive rate'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.19：真正阳性率'
- en: '](img/image-RJ4GSRCG.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-RJ4GSRCG.jpg)'
- en: 'Figure 7.19: True positive rate'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.19：真正阳性率
- en: '![Figure 7.20: False positive rate'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.20：假阳性率'
- en: '](img/image-2SYKGQPB.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-2SYKGQPB.jpg)'
- en: 'Figure 7.20: False positive rate'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.20：假阳性率
- en: 'The following diagram shows an example of an ROC curve, plotted in the same
    way as the precision-recall curve, by varying the probability threshold such that
    each point on the curve represents a (TPR, FPR) data point corresponding to a
    specific probability threshold:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示显示了 ROC 曲线的示例，通过改变概率阈值，以使曲线上的每个点都代表一个（TPR，FPR）数据点，这些点对应于特定的概率阈值：
- en: '![Figure 7.21: ROC curve'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.21：ROC 曲线'
- en: '](img/image-5EWLE67F.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-5EWLE67F.jpg)'
- en: 'Figure 7.21: ROC curve'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.21：ROC 曲线
- en: ROC curves are more useful when the classes are fairly balanced, since they
    tend to represent a favorable output of the model on datasets with a class imbalance
    via their use of true negatives in the false positive rate in the ROC curve (which
    is not present in the precision-recall curve).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线在类平衡较好的情况下更为有用，因为它们通过在假阳性率中使用真阴性来表示模型在类别不平衡的数据集上的有利输出（而这一点在精确度-召回率曲线中没有体现）。
- en: 'Exercise 7.02: Calculating Classification Metrics'
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习 7.02：计算分类指标
- en: 'In this exercise, we will use the random forest model we trained in Chapter
    6, Ensemble Modeling, and use its predictions to generate the confusion matrix
    and calculate the precision, recall, and F1 scores as a way of rating our model.
    We will use scikit-learn''s implementations to calculate these metrics:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将使用第 6 章《集成建模》中训练的随机森林模型，并使用其预测结果生成混淆矩阵，计算精确度、召回率和 F1 分数，以此来评估我们的模型。我们将使用
    scikit-learn 的实现来计算这些指标：
- en: Note
  id: totrans-186
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Before beginning this exercise, make sure you have imported the relevant libraries
    and models as listed in the Importing the Modules and Preparing Our Dataset section.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始这个练习之前，请确保你已经导入了相关的库和模型，详见“导入模块和准备数据集”部分。
- en: 'Import the relevant libraries and functions:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 导入相关库和函数：
- en: from sklearn.metrics import (accuracy_score, confusion_matrix, \
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.metrics import (accuracy_score, confusion_matrix, \
- en: precision_score, recall_score, f1_score)
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: precision_score, recall_score, f1_score)
- en: 'Use the model to predict classes for all data points. We will use the same
    features as we did earlier and use the random forest classifier to make a prediction
    in relation to the loaded dataset. Every classifier in scikit-learn has a .predict_proba()
    function, which we will use here along with the standard .predict() function to
    give us the class probabilities and the classes, respectively:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模型对所有数据点进行类别预测。我们将使用与之前相同的特征，并使用随机森林分类器对加载的数据集进行预测。scikit-learn中的每个分类器都有一个.predict_proba()函数，我们将在这里与标准的.predict()函数一起使用，分别给出类别概率和类别：
- en: X = titanic_clf.iloc[:, :-1]
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: X = titanic_clf.iloc[:, :-1]
- en: y = titanic_clf.iloc[:, -1]
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: y = titanic_clf.iloc[:, -1]
- en: y_pred = rf.predict(X)
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: y_pred = rf.predict(X)
- en: y_pred_probs = rf.predict_proba(X)
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: y_pred_probs = rf.predict_proba(X)
- en: 'Calculate the accuracy:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 计算准确率：
- en: print('Accuracy Score = {}'.format(accuracy_score(y, y_pred)))
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: print('Accuracy Score = {}'.format(accuracy_score(y, y_pred)))
- en: 'The output will be as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: Accuracy Score = 0.6251402918069585
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: Accuracy Score = 0.6251402918069585
- en: An accuracy score of 62.5% is not that great, especially considering the fact
    that flipping a coin for guessing each output would result in an accuracy of 50%.
    However, the goal of the current exercise is to get an understanding of how metrics
    work. Hence, after noticing that our classifier doesn't really do well in terms
    of accuracy, we move on to some other metrics that will help us to analyze the
    model performance in more detail.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 62.5%的准确率并不是很高，特别是考虑到如果每次猜测输出都像掷硬币一样，那么准确率将是50%。然而，本次练习的目标是理解指标的作用。因此，在发现我们的分类器在准确率方面表现不佳后，我们将转向其他一些指标，帮助我们更详细地分析模型的表现。
- en: 'Print the confusion matrix:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 打印混淆矩阵：
- en: print(confusion_matrix(y_pred=y_pred, y_true=y))
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: print(confusion_matrix(y_pred=y_pred, y_true=y))
- en: 'The output will be as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 7.22: Confusion matrix'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.22：混淆矩阵](img/image-882W286D.jpg)'
- en: '](img/image-882W286D.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-882W286D.jpg)'
- en: 'Figure 7.22: Confusion matrix'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.22：混淆矩阵
- en: Here, we can see that the model seems to have a high number of false negatives,
    which means that we can expect the recall value for this model to be extremely
    low. Similarly, since the count of the false positives is just one, we can expect
    the model to have high precision.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到模型似乎有很多假阴性，这意味着我们可以预期该模型的召回率极低。同样，由于假阳性的数量只有一个，我们可以预期该模型具有较高的精度。
- en: 'Calculate the precision and recall:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 计算精度和召回率：
- en: print('Precision Score = {}'.format(precision_score(y, y_pred)))
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: print('Precision Score = {}'.format(precision_score(y, y_pred)))
- en: print('Recall Score = {}'.format(recall_score(y, y_pred)))
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: print('Recall Score = {}'.format(recall_score(y, y_pred)))
- en: 'The output will be as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: Precision Score = 0.9
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: Precision Score = 0.9
- en: Recall Score = 0.02631578947368421
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: Recall Score = 0.02631578947368421
- en: 'Calculate the F1 score:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 计算F1得分：
- en: print('F1 Score = {}'.format(f1_score(y, y_pred)))
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: print('F1 Score = {}'.format(f1_score(y, y_pred)))
- en: 'The output will be as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: F1 Score = 0.05113636363636364
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: F1 Score = 0.05113636363636364
- en: We can see that, since the recall is extremely low, this is affecting the F1
    score as well, making it close to zero.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，由于召回率极低，这也影响了F1得分，使得它接近零。
- en: Note
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注释
- en: To access the source code for this specific section, please refer to https://packt.live/2V6mbYQ.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 若要访问该特定部分的源代码，请参考 [https://packt.live/2V6mbYQ](https://packt.live/2V6mbYQ)。
- en: You can also run this example online at https://packt.live/37XirOr. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在线运行此示例，网址为 [https://packt.live/37XirOr](https://packt.live/37XirOr)。你必须执行整个Notebook才能得到预期结果。
- en: Now that we have talked about the metrics that we can use to measure the predictive
    performance of the model, let's talk about validation strategies, in which we
    will use a metric to evaluate the performance of the model in different cases
    and situations.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了可以用来衡量模型预测性能的指标，接下来我们将讨论验证策略，在这些策略中，我们将使用某个指标来评估模型在不同情况下的表现。
- en: Splitting a Dataset
  id: totrans-223
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据集拆分
- en: A common mistake made when determining how well a model is performing is to
    calculate the prediction error on the data that the model was trained on and conclude
    that a model performs really well on the basis of a high prediction accuracy on
    the training dataset.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定一个模型表现如何时，一个常见的错误是计算模型在其训练数据上的预测误差，并基于在训练数据集上高准确度的结果得出模型表现非常好的结论。
- en: This means that we are trying to test the model on data that the model has already
    seen, that is, the model has already learned the behavior of the training data
    because it was exposed to it—if asked to predict the behavior of the training
    data again, it would undoubtedly perform well. And the better the performance
    on the training data, the higher the chances that the model knows the data too
    well, so much so that it has even learned the noise and behavior of outliers in
    the data.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们正在尝试在模型已经见过的数据上进行测试，也就是说，模型已经学习了训练数据的行为，因为它已经接触过这些数据——如果要求模型再次预测训练数据的行为，它无疑会表现得很好。而且，在训练数据上的表现越好，模型对数据的了解程度可能越高，以至于它甚至学会了数据中的噪声和异常值的行为。
- en: Now, high training accuracy results in a model having high variance, as we saw
    in the previous chapter. In order to get an unbiased estimate of the model's performance,
    we need to find its prediction accuracy on data it has not already been exposed
    to during training. This is where the hold-out dataset comes into the picture.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，高训练准确度导致模型具有高方差，正如我们在上一章中看到的那样。为了获得模型表现的无偏估计，我们需要找到模型在它没有在训练过程中接触过的数据上的预测准确度。这就是持留数据集发挥作用的地方。
- en: Hold-Out Data
  id: totrans-227
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 持留数据
- en: The hold-out dataset refers to a sample of the dataset that has been held back
    from training the model on and is essentially unseen by the model. The hold-out
    data points will likely contain outliers and noisy data points that behave differently
    from those in the training dataset, given that noise is random. Thus, calculating
    the performance on the hold-out dataset would allow us to validate whether the
    model is overfitting or not, as well as give us an unbiased view of the model's
    performance.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 持留数据集是指从训练模型时被暂时保留的样本，它本质上对模型来说是“未见过”的。由于噪声是随机的，持留数据点很可能包含与训练数据集中的数据行为不同的异常值和噪声数据点。因此，计算持留数据集上的表现可以帮助我们验证模型是否过拟合，并且为我们提供模型表现的无偏见视角。
- en: 'We began our previous chapter by splitting the Titanic dataset into training
    and validation sets. What is this validation dataset, and how is it different
    from a test dataset? We often see the terms validation set and test set used interchangeably—although
    they both characterize a hold-out dataset, there are some differences in purpose:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一章开始时将泰坦尼克号数据集分为训练集和验证集。那么，这个验证数据集是什么？它与测试数据集有什么不同？我们经常看到验证集和测试集这两个术语被交替使用——尽管它们都表示一个持留数据集，但它们在目的上有所不同：
- en: 'Validation data: After the model learns from the training data, its performance
    is evaluated on the validation dataset. However, in order to get the model to
    perform the best it can, we need to fine-tune the model and iteratively evaluate
    the updated model''s performance repeatedly, and this is done on the validation
    dataset. The fine-tuned version of the model that performs best on the validation
    dataset is usually chosen to be the final model.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 验证数据：在模型从训练数据中学习后，它的表现会在验证数据集上进行评估。然而，为了使模型发挥最佳性能，我们需要对模型进行微调，并反复评估更新后的模型表现，这一过程是在验证数据集上完成的。通常，表现最好且通过验证数据集验证过的微调模型会被选为最终模型。
- en: The model is therefore exposed to the validation dataset multiple times, at
    each iteration of improvement, although it does not essentially learn from the
    data. It can be said that the validation set does affect the model, although indirectly.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管模型本质上没有从数据中学习，但它会在每次改进的迭代中多次接触到验证数据集。可以说，验证集虽然间接，但确实影响了模型。
- en: 'Test data: The final model that was chosen is now evaluated on the test dataset.
    The performance measured on this dataset will be an unbiased measure that is reported
    as the final performance metric of the model. This final evaluation is done once
    the model has been completely trained on the combined training and validation
    datasets. No training or updating of the model is performed after this metric
    has been calculated.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据：选择的最终模型现在将在测试数据集上进行评估。测量的性能将在此数据集上提供一个无偏的度量，这个度量将作为模型的最终性能指标。这个最终评估是在模型已经在合并的训练和验证数据集上完全训练之后进行的。在计算这个度量值后，不再对模型进行训练或更新。
- en: This means that the model is exposed to the test dataset only once, when calculating
    the final performance metric.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着模型只在计算最终性能度量时暴露于测试数据集一次。
- en: 'It should be kept in mind that the validation dataset should never be used
    to evaluate the final performance of the model: our estimate of the true performance
    of a model will be positively biased if the model has seen and been modified subsequently
    in an effort to specifically improve performance in relation to the validation
    set.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的是，验证数据集绝不能用于评估模型的最终性能：如果模型已经看到并且在后续的修改中专门为提高在验证集上的表现而进行过调整，那么我们对模型真实性能的估计将会有正向偏差。
- en: Having a single hold-out validation dataset does have some limitations, however
    since the model is only validated once in each iteration of improvement, it might
    be difficult to capture the uncertainty in prediction using this single evaluation.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，只有一个保留的验证数据集确实存在一些局限性，因为模型在每次改进迭代中只进行一次验证，因此使用这个单一的评估可能很难捕捉到预测的不确定性。
- en: Dividing the data into training and validation sets decreases the size of the
    data upon which the model is trained, and this can lead to the model having a
    high variance.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据划分为训练集和验证集会减少用于训练模型的数据量，这可能导致模型具有较高的方差。
- en: The final model may overfit to this validation set since it was tuned in order
    to maximize performance on this dataset.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 最终模型可能会过拟合于这个验证集，因为它是为了最大化在这个数据集上的表现而进行调优的。
- en: These challenges can be overcome if we use a validation technique called k-fold
    cross-validation instead of using a single validation dataset.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用称为k折交叉验证的验证技术，而不是使用单一的验证数据集，那么这些挑战是可以克服的。
- en: K-Fold Cross-Validation
  id: totrans-239
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: K折交叉验证
- en: 'K-fold cross-validation is a validation technique that helps us get an unbiased
    estimate of the model''s performance by essentially rotating the validation set
    in k folds. This is how it works:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: K折交叉验证是一种验证技术，它通过本质上将验证集轮换成k个折叠，从而帮助我们得到一个无偏的模型性能估计。它是如何工作的：
- en: First, we choose the value of k and divide the data into k subsets.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们选择k的值并将数据划分为k个子集。
- en: Then, we set aside the first subset as the validation set and use the remaining
    data to train the model.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将第一个子集作为验证集，其余数据用于训练模型。
- en: We measure the performance of the model on the validation subset.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在验证子集上测量模型的性能。
- en: Then, we set aside the second subset as the validation subset and repeat the process.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将第二个子集作为验证子集，重复这一过程。
- en: Once we have done this k times, we aggregate the performance metric values over
    all the folds and present the final metric.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们完成了k次迭代，我们将所有折叠的性能度量值进行汇总，并呈现最终的度量值。
- en: 'The following figure explains this visually:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 下图直观地解释了这一点：
- en: '![Figure 7.23: K-fold cross-validation'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.23：K折交叉验证'
- en: '](img/image-9PFF1KHD.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-9PFF1KHD.jpg)'
- en: 'Figure 7.23: K-fold cross-validation'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.23：K折交叉验证
- en: Although this method of validation is more computationally expensive, the benefits
    outweigh the costs. This approach makes sure that the model is validated on each
    example in the training dataset exactly once and that the performance estimate
    we achieve in the end is not biased in favor of a validation dataset, especially
    in the case of small datasets. A special case is leave-one-out cross-validation,
    where the value of k is equal to the number of data points.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种验证方法计算开销较大，但其好处超过了成本。这种方法确保模型在训练数据集中的每个样本上都被验证一次，并且最终获得的性能估计不会偏向于验证数据集，尤其是在小型数据集的情况下。一个特殊情况是留一交叉验证，其中k的值等于数据点的数量。
- en: Sampling
  id: totrans-251
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 抽样
- en: 'Now that we''ve looked at the strategies for splitting the dataset for training
    and validating the model, let''s discuss how to allocate data points to these
    splits. There are two ways we can sample the data in the splits, and these are
    as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了用于拆分数据集以进行模型训练和验证的策略，让我们来讨论如何将数据点分配到这些拆分中。我们可以在拆分中采样数据的方式有两种，分别如下：
- en: 'Random sampling: This is as simple as allocating random samples from the overall
    dataset into training, validation, and/or test datasets. Randomly splitting the
    data only works when all the data points are independent of each other. For example,
    random splitting would not be the way to go if the data was in the form of a time
    series, since the data points are ordered, and each depends on the previous one.
    Randomly splitting the data would destroy that order and not take into account
    this dependence. One common real-world example where random sampling could be
    used to split training and test datasets is for the handwritten digits classification
    task, because in this case, all data samples (images of handwritten digits) are
    independent of one another and data is roughly equally distributed among all 10
    classes (digits).'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 随机抽样：这就是从整体数据集中随机分配样本到训练集、验证集和/或测试集中。随机拆分数据仅在所有数据点彼此独立时有效。例如，如果数据以时间序列的形式呈现，随机拆分就不适用了，因为数据点是有序的，并且每个数据点都依赖于前一个数据点。随机拆分数据会破坏这种顺序，并且不会考虑这种依赖关系。一个常见的现实世界示例是手写数字分类任务，因为在这种情况下，所有数据样本（手写数字的图像）彼此独立，且数据在所有
    10 个类别（数字）之间大致均匀分布。
- en: 'Stratified sampling: This is a way to ensure that each subset has the same
    distribution of values of the target variable as the original dataset. For example,
    if the original dataset has two classes in the ratio 3:7, stratified sampling
    ensures that each subset will also contain the two classes in the ratio 3:7.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 分层抽样：这是一种确保每个子集的目标变量值分布与原始数据集相同的方法。例如，如果原始数据集中的两个类别的比例是 3:7，则分层抽样确保每个子集也包含按
    3:7 比例分布的两个类别。
- en: Stratified sampling is important since testing our model on a dataset with a
    different distribution of target values from the dataset on which the model was
    trained can give us a performance estimate that is not representative of the model's
    actual performance.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 分层抽样很重要，因为在一个与模型训练数据集目标值分布不同的数据集上测试模型，可能会给出一个不代表模型实际性能的性能估计。
- en: A real-life example where this sampling technique is used is fraud detection
    in financial transactions. Because frauds occur rarely, the imbalance between
    the FRAUD and NOT_FRAUD classes is huge. In order to split 1,000 financial transactions,
    of which 5 are fraudulent, into training and test sets for the fraud detection
    task, we must use stratified sampling. If we don't, then all 5 fraudulent samples
    might end up in the training set (or test set), which will prevent us from performing
    any useful validation.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这种抽样技术的实际应用示例是在金融交易中的欺诈检测。由于欺诈事件发生的频率较低，因此欺诈（FRAUD）和非欺诈（NOT_FRAUD）类别之间的不平衡非常大。例如，假设我们有
    1,000 笔金融交易，其中有 5 笔是欺诈性的，我们必须使用分层抽样来将这些交易分成训练集和测试集。如果不使用分层抽样，那么所有 5 笔欺诈交易可能都被分配到训练集（或测试集），这将导致我们无法进行有效的验证。
- en: The size of the train, validation, and test samples also plays an important
    role in the model evaluation process. Keeping aside a large dataset on which to
    test the final performance of the model will help us get an unbiased estimate
    of the model's performance and reduce the variance in prediction, but if the test
    set is so large that it compromises the model's ability to train due to a lack
    of training data, this will severely affect the model as well. This is a consideration
    that is especially relevant for smaller datasets.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集、验证集和测试集样本的大小在模型评估过程中也起着重要作用。保留一个大数据集用于测试模型的最终性能，将有助于我们获得一个无偏的模型性能估计，并减少预测的方差，但如果测试集太大，以至于由于缺乏训练数据而影响模型的训练能力，这将严重影响模型的效果。这一点在较小的数据集中特别重要。
- en: 'Exercise 7.03: Performing K-Fold Cross-Validation with Stratified Sampling'
  id: totrans-258
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习 7.03：使用分层抽样进行 K-折交叉验证
- en: 'In this exercise, we''ll implement K-fold cross-validation with stratified
    sampling on scikit-learn''s random forest classifier. The StratifiedKFold class
    in scikit-learn implements a combination of cross-validation and sampling together
    in one class, and we will use this in our exercise:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在此练习中，我们将实现基于 scikit-learn 的随机森林分类器的 K 折交叉验证与分层抽样。scikit-learn 中的 StratifiedKFold
    类实现了交叉验证和抽样的结合，我们将在本练习中使用它：
- en: Note
  id: totrans-260
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Before beginning this exercise, make sure you have imported the relevant libraries
    and models as listed in the Importing the Modules and Preparing Our Dataset section.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始此练习之前，请确保已导入《导入模块和准备数据集》部分中列出的相关库和模型。
- en: 'Import the relevant classes. We will import scikit-learn''s StratifiedKFold
    class, which is a variation of KFold that returns stratified folds, along with
    RandomForestClassifier:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 导入相关类。我们将导入 scikit-learn 的 StratifiedKFold 类，它是 KFold 的变体，返回分层折叠，并与 RandomForestClassifier
    一起使用：
- en: from sklearn.metrics import accuracy_score
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.metrics import accuracy_score
- en: from sklearn.model_selection import StratifiedKFold
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.model_selection import StratifiedKFold
- en: from sklearn.ensemble import RandomForestClassifier
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.ensemble import RandomForestClassifier
- en: 'Prepare data for training and initialize the k-fold object. Here, we will use
    five folds to evaluate the model, and hence will give the n_splits parameter a
    value of 5:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 为训练准备数据并初始化 k 折对象。在这里，我们将使用五折来评估模型，因此将 n_splits 参数设置为 5：
- en: X = titanic_clf.iloc[:, :-1].values
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: X = titanic_clf.iloc[:, :-1].values
- en: y = titanic_clf.iloc[:, -1].values
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: y = titanic_clf.iloc[:, -1].values
- en: skf = StratifiedKFold(n_splits=5)
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: skf = StratifiedKFold(n_splits=5)
- en: 'Train a classifier for each fold and record the score. The functioning of the
    StratifiedKFold class is similar to the KFold class that we used in the previous
    chapter, Chapter 6, Ensemble Modeling in Exercise 6.06, Building a Stacked Model.
    For each of the five folds, we will train on the other four folds and predict
    on the fifth fold, and find the accuracy score for predictions in relation to
    the fifth fold. As we saw in the previous chapter, the skf.split() function takes
    the dataset to split as input and returns an iterator comprising the index values
    used to subdivide the training data for training and validation for each row:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 为每个折叠训练一个分类器并记录得分。StratifiedKFold 类的功能类似于我们在上一章中使用的 KFold 类，上一章为第六章《集成建模》中第6.06节《构建堆叠模型》中的内容。对于每个五折交叉验证，我们将在其他四折上进行训练，并在第五折上进行预测，然后计算预测结果与第五折之间的准确率。如上一章所示，skf.split()
    函数接受要拆分的数据集作为输入，并返回一个迭代器，其中包含用于将训练数据细分为训练和验证的索引值：
- en: scores = []
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: scores = []
- en: 'for train_index, val_index in skf.split(X, y):'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 'for train_index, val_index in skf.split(X, y):'
- en: X_train, X_val = X[train_index], X[val_index]
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: X_train, X_val = X[train_index], X[val_index]
- en: y_train, y_val = y[train_index], y[val_index]
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: y_train, y_val = y[train_index], y[val_index]
- en: rf_skf = RandomForestClassifier(**rf.get_params())
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: rf_skf = RandomForestClassifier(**rf.get_params())
- en: rf_skf.fit(X_train, y_train)
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: rf_skf.fit(X_train, y_train)
- en: y_pred = rf_skf.predict(X_val)
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: y_pred = rf_skf.predict(X_val)
- en: scores.append(accuracy_score(y_val, y_pred))
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: scores.append(accuracy_score(y_val, y_pred))
- en: scores
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: scores
- en: 'The output will be as follows:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 7.24: Scores using the random forest classifier'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.24: 使用随机森林分类器的得分'
- en: '](img/image-G9XNLB0R.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-G9XNLB0R.jpg)'
- en: 'Figure 7.24: Scores using the random forest classifier'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7.24: 使用随机森林分类器的得分'
- en: 'Print the aggregated accuracy score:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 打印聚合的准确率得分：
- en: print('Mean Accuracy Score = {}'.format(np.mean(scores)))
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: print('平均准确率得分 = {}'.format(np.mean(scores)))
- en: 'The output will be as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: Mean Accuracy Score = 0.7105606912862568
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 平均准确率得分 = 0.7105606912862568
- en: Note
  id: totrans-288
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to https://packt.live/316TUF5.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看此特定部分的源代码，请参考 https://packt.live/316TUF5。
- en: You can also run this example online at https://packt.live/2V6JilY. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 https://packt.live/2V6JilY 在线运行此示例。你必须执行整个Notebook，才能获得预期结果。
- en: Thus, we have demonstrated how we can use k-fold cross-validation to have a
    robust assessment of model performance. And we use stratified sampling in the
    preceding approach that ensures that the training and validation sets have similar
    class distribution. Next, we will focus on how to improve model performance.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经演示了如何使用 k 折交叉验证来对模型性能进行稳健评估。我们在前述方法中使用了分层抽样，确保训练集和验证集具有相似的类别分布。接下来，我们将专注于如何提升模型性能。
- en: Performance Improvement Tactics
  id: totrans-292
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 性能提升策略
- en: 'Performance improvement for supervised machine learning models is an iterative
    process, and a continuous cycle of updating and evaluation is usually required
    to get the perfect model. While the previous sections in this chapter dealt with
    the evaluation strategies, this section will talk about model updating: we will
    discuss some ways we can determine what our model needs to give it that performance
    boost, and how to effect that change in our model.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 监督式机器学习模型的性能提升是一个迭代过程，通常需要不断的更新和评估循环才能得到完美的模型。尽管本章之前的部分讨论了评估策略，本节将讨论模型更新：我们将讨论一些方法，帮助我们确定模型需要什么来提升性能，以及如何对模型进行这些调整。
- en: Variation in Train and Test Errors
  id: totrans-294
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 训练和测试误差的变化
- en: In the previous chapter, we introduced the concepts of underfitting and overfitting,
    and mentioned a few ways to overcome them, later introducing ensemble models.
    But we didn't talk about how to identify whether our model was underfitting or
    overfitting to the training data.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们介绍了欠拟合和过拟合的概念，并提到了解决这些问题的一些方法，随后引入了集成模型。但我们没有讨论如何识别我们的模型是否在训练数据上出现了欠拟合或过拟合。
- en: It's usually useful to look at the learning and validation curves.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 通常查看学习曲线和验证曲线是很有帮助的。
- en: Learning Curve
  id: totrans-297
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 学习曲线
- en: The learning curve shows the variation in the training and validation errors
    with the training data increasing in size. By looking at the shape of the curves,
    we can get a good idea of whether more data will benefit the modeling and possibly
    improve the model's performance.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 学习曲线显示了随着训练数据量增加，训练误差和验证误差的变化。通过观察曲线的形状，我们可以大致判断增加更多数据是否会对建模产生积极影响，并可能提高模型的性能。
- en: 'Let''s look at the following figure: the dotted curve represents the validation
    error, and the solid curve represents the training error. The plot on the left
    shows the two curves converging to an error value that is quite high. This means
    that the model has a high bias and adding more data isn''t likely to affect the
    model''s performance. So instead of wasting time and money collecting more data,
    all we need to do is increase model complexity.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看以下图：虚线表示验证误差，实线表示训练误差。左侧的图显示这两条曲线都趋向于一个较高的误差值。这意味着模型具有较高的偏差，增加更多数据不太可能影响模型的表现。因此，我们不必浪费时间和金钱去收集更多数据，而需要做的只是增加模型的复杂性。
- en: 'On the other hand, the plot on the right shows a significant difference between
    the training and test errors, even with an increasing number of data points in
    the training set. The wide gap indicates a high variance in the system, which
    means the model is overfitting. In this case, adding more data points will probably
    help the model generalize better, as you can see in the following figure:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，右侧的图显示了即使训练集中的数据点数量不断增加，训练误差和测试误差之间仍然存在显著差异。这个较大的差距表明系统的方差较高，这意味着模型出现了过拟合。在这种情况下，增加更多的数据点可能有助于模型更好地泛化，正如下图所示：
- en: '![Figure 7.25: Learning curve for increasing data size'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.25：数据量增加的学习曲线'
- en: '](img/image-LBZS46E0.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-LBZS46E0.jpg)'
- en: 'Figure 7.25: Learning curve for increasing data size'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.25：数据量增加的学习曲线
- en: 'But how will we recognize the perfect learning curve? When we have a model
    with low bias and low variance, we will see a curve like the one shown in the
    following figure. It shows a low training error (low bias) as well as a low gap
    between the validation and training curves (low variance) as they converge. In
    practice, the best possible learning curves we can see are those that converge
    to the value of an irreducible error value (which exists due to noise and outliers
    in the dataset), as shown in the following figure:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何识别完美的学习曲线呢？当我们的模型具有低偏差和低方差时，我们会看到类似下图的曲线。它显示了低训练误差（低偏差）以及训练曲线和验证曲线之间的低差距（低方差），因为它们会趋于一致。在实践中，我们能看到的最好的学习曲线是那些趋向不可减少的误差值（由于数据集中的噪声和异常值存在），如以下图所示：
- en: '![Figure 7.26: Variation in training and validation error with an increasing
    training data size for a low bias and variance model'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.26：低偏差和低方差模型在训练数据量增加时，训练误差和验证误差的变化'
- en: '](img/image-5EK0XCQE.jpg)'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-5EK0XCQE.jpg)'
- en: 'Figure 7.26: Variation in training and validation error with an increasing
    training data size for a low bias and variance model'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.26：低偏差和低方差模型在训练数据量增加时，训练误差和验证误差的变化
- en: Validation Curve
  id: totrans-308
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 验证曲线
- en: 'As we have discussed previously, the goal of a machine learning model is to
    be able to generalize to unseen data. Validation curves allow us to find the ideal
    point between an underfitted and an overfitted model where the model would generalize
    well. In the previous chapter, we talked a bit about how model complexity affects
    prediction performance: we said that as we move from an overly simplistic to an
    overly complex model, we go from having an underfitted model with high bias and
    low variance to an overfitted model with low bias and high variance.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，机器学习模型的目标是能够对未见过的数据进行泛化。验证曲线帮助我们找到一个理想的点，这个点介于欠拟合和过拟合的模型之间，在这里模型能够很好地进行泛化。在前一章中，我们谈到了模型复杂度如何影响预测性能：我们说过，随着我们从一个过于简单的模型到一个过于复杂的模型，我们会从一个欠拟合的高偏差低方差模型，过渡到一个过拟合的低偏差高方差模型。
- en: 'A validation curve shows the variation in training and validation error with
    a varying value of a model parameter that has some degree of control over the
    model''s complexity—this could be the degree of the polynomial in linear regression,
    or the depth of a decision tree classifier:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 验证曲线展示了随着模型参数值变化，训练和验证误差的变化，其中该模型参数在某种程度上控制着模型的复杂度——这可以是线性回归中的多项式度数，或者是决策树分类器的深度：
- en: '![Figure 7.27: Variation in training and validation with increasing model complexity'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.27：随着模型复杂度增加，训练和验证的变化](img/image-2PLE7KLZ.jpg)'
- en: '](img/image-1MWNFP2X.jpg)'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-1MWNFP2X.jpg)'
- en: 'Figure 7.27: Variation in training and validation with increasing model complexity'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.27：随着模型复杂度增加，训练和验证的变化
- en: The preceding figure shows how the validation and training error will vary with
    model complexity (of which the model parameter is an indicator). We can also see
    how the point in between the shaded regions is where the total error would be
    at a minimum, at the sweet spot between underfitting and overfitting. Finding
    this point will help us find the ideal value of the model's parameters that will
    help build a model with low bias as well as low variance.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图示展示了随着模型复杂度（其模型参数是一个指标）变化，验证和训练误差是如何变化的。我们还可以看到，阴影区域之间的点就是总误差最小的地方，这正是欠拟合和过拟合之间的最佳点。找到这个点将帮助我们找到模型参数的理想值，从而构建一个低偏差和低方差的模型。
- en: Hyperparameter Tuning
  id: totrans-315
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 超参数调整
- en: 'We''ve talked about hyperparameter tuning several times previously. Now, let''s
    discuss why it''s so important. First, it should be noted that model parameters
    are different from model hyperparameters: while the former are internal to the
    model and are learned from the data, the latter define the architecture of the
    model itself.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已经多次讨论了超参数调整。现在，让我们讨论为什么它如此重要。首先，需要注意的是，模型参数与模型超参数是不同的：前者是模型内部的，并且是从数据中学习得来的，而后者则定义了模型本身的架构。
- en: 'Examples of hyperparameters include the following:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数的示例包括以下内容：
- en: The degree of polynomial features to be used for a linear regressor
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 用于线性回归的多项式特征的度数
- en: The maximum depth allowed for a decision tree classifier
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树分类器的最大深度
- en: The number of trees to be included in a random forest classifier
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林分类器中要包含的树的数量
- en: The learning rate used for the gradient descent algorithm
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降算法使用的学习率
- en: The design choices that define the architecture of the model can make a huge
    difference in how well the model performs. Usually, the default values for the
    hyperparameters work, but getting the perfect combination of values for the hyperparameters
    can really give the predictive power of the model a boost as the default values
    may be completely inappropriate for the problem we are trying to model.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 定义模型架构的设计选择可以对模型的表现产生巨大影响。通常，超参数的默认值是有效的，但找到超参数的完美组合可以大大提升模型的预测能力，因为默认值可能完全不适合我们正在尝试建模的问题。
- en: 'In the following diagram, we see how varying the values of two hyperparameters
    can cause such a difference in the model score:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图示中，我们可以看到改变两个超参数的值如何导致模型得分的巨大差异：
- en: '![Figure 7.28: Variation in model score (Z axis) across the values of two model
    parameters (the X and Y axes)'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.28：随着两个模型参数（X轴和Y轴）值的变化，模型得分（Z轴）的变化](img/image-1MWNFP2X.jpg)'
- en: '](img/image-2PLE7KLZ.jpg)'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-2PLE7KLZ.jpg)'
- en: 'Figure 7.28: Variation in model score (Z axis) across the values of two model
    parameters (the X and Y axes)'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.28：随着两个模型参数（X轴和Y轴）值的变化，模型得分（Z轴）的变化
- en: Finding that perfect combination by exploring a range of possible values is
    what is referred to as hyperparameter tuning. Since there is no loss function
    that we can use to maximize the model performance, tuning the hyperparameters
    generally just involves experimenting with different combinations and choosing
    the one that performs best during validation.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 通过探索一系列可能的值来找到完美的组合，这就是所谓的超参数调优。由于没有可用于最大化模型表现的损失函数，超参数调优通常只是通过实验不同的组合，并选择在验证过程中表现最好的组合。
- en: 'There are a few ways in which we can go about tuning our model''s hyperparameters:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有几种方法可以进行模型的超参数调优：
- en: 'Hand-tuning: When we manually choose the values of our hyperparameters, this
    is known as hand-tuning. It is usually inefficient, since solving a high-dimensional
    optimization problem by hand can not only be slow, but also would not allow the
    model to reach its peak performance as we probably wouldn''t try out every single
    combination of hyperparameter values.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 手动调优：当我们手动选择超参数的值时，这被称为手动调优。它通常效率低下，因为通过手工解决高维度优化问题不仅会很慢，而且也无法让模型达到最佳性能，因为我们可能不会尝试每一种超参数值的组合。
- en: 'Grid search: Grid search involves training and evaluating a model for each
    combination of the hyperparameter values provided and selecting the combination
    that produces the best performing model. Since this involves performing an exhaustive
    sampling of the hyperparameter space, it is quite computationally speaking and,
    hence, inefficient.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 网格搜索：网格搜索涉及对每一个超参数值的组合进行模型训练和评估，并选择表现最佳的组合。由于这需要对超参数空间进行详尽的采样，因此从计算角度来看，它是相当低效的。
- en: 'Random search: While the first method was deemed inefficient because too few
    combinations were tried, the second one was deemed so because too many combinations
    were tried. Random search aims to solve this problem by selecting a random subset
    of hyperparameter combinations from the grid (specified previously), and training
    and evaluating a model just for those. Alternatively, we can also provide a statistical
    distribution for each hyperparameter from which the values can be randomly sampled.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 随机搜索：虽然第一种方法因为尝试的组合太少被认为效率低下，但第二种方法因为尝试的组合太多也被认为低效。随机搜索通过从之前定义的网格中随机选择一个超参数组合的子集，然后只对这些组合进行训练和评估，从而解决了这一问题。或者，我们还可以为每个超参数提供一个统计分布，从中随机抽取值。
- en: The logic behind random search was proved by Bergstra and Bengio, which states
    that if at least 5% of the points on the grid yield a close-to-optimal solution,
    then random search with 60 trials will find that region with a probability of
    95%.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 随机搜索的逻辑由 Bergstra 和 Bengio 提出，指出如果网格中至少 5% 的点能提供接近最优的解，那么通过 60 次试验，随机搜索能够以 95%
    的概率找到这一区域。
- en: 'Note:'
  id: totrans-333
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意：
- en: You can read the paper by Bergstra and Bengio at http://www.jmlr.org/papers/v13/bergstra12a.html.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以阅读 Bergstra 和 Bengio 的论文，网址是 [http://www.jmlr.org/papers/v13/bergstra12a.html](http://www.jmlr.org/papers/v13/bergstra12a.html)。
- en: 'Bayesian optimization: The previous two methods involved independently experimenting
    with combinations of hyperparameter values and recording the model performance
    for each. However, Bayesian optimization iterates over experiments sequentially
    and allows us to use the results of a previous experiment to improve the sampling
    method for the next experiment.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯优化：前两种方法涉及独立地尝试超参数值的组合，并记录每个组合的模型表现。然而，贝叶斯优化通过顺序地进行实验并利用前一个实验的结果来改善下一个实验的采样方法。
- en: 'Exercise 7.04: Hyperparameter Tuning with Random Search'
  id: totrans-336
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习 7.04：使用随机搜索进行超参数调优
- en: 'In this exercise, we will perform hyperparameter tuning with the random search
    method. We will define a grid of hyperparameter ranges and randomly sample from
    the grid using the RandomizedSearchCV method. We will also be performing K-fold
    cross-validation with each combination of values. This exercise is a continuation
    of Exercise 7.03, Performing K-Fold Cross-Validation with Stratified Sampling:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用随机搜索方法进行超参数调优。我们将定义一个超参数范围的网格，并使用 RandomizedSearchCV 方法从该网格中随机采样。我们还将对每个组合的值进行
    K 折交叉验证。本练习是练习 7.03“使用分层抽样执行 K 折交叉验证”的延续：
- en: 'Import the class for random search:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 导入随机搜索的类：
- en: from sklearn.ensemble import RandomForestClassifier
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.ensemble import RandomForestClassifier
- en: from sklearn.model_selection import RandomizedSearchCV
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.model_selection import RandomizedSearchCV
- en: 'Prepare data for training and initialize the classifier. Here, we will initialize
    our random forest classifier without passing any arguments, since this is just
    a base object that will be instantiated for each grid point on which to perform
    the random search:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 准备训练数据并初始化分类器。这里，我们将初始化我们的随机森林分类器而不传递任何参数，因为这只是一个基础对象，将为每个网格点实例化进行随机搜索：
- en: X = titanic_clf.iloc[:, :-1].values
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: X = titanic_clf.iloc[:, :-1].values
- en: y = titanic_clf.iloc[:, -1].values
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: y = titanic_clf.iloc[:, -1].values
- en: rf_rand = RandomForestClassifier()
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: rf_rand = 随机森林分类器()
- en: 'def report(results, max_rank=3):'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 'def report(results, max_rank=3):'
- en: 'for rank in range(1, max_rank+1):'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 'for rank in range(1, max_rank+1):'
- en: results_at_rank = np.flatnonzero\
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: results_at_rank = np.flatnonzero\
- en: (results['rank_test_score'] == i)
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: (results['rank_test_score'] == i)
- en: 'def report(results, n_top=3):'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 'def report(results, n_top=3):'
- en: 'for i in range(1, n_top + 1):'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i in range(1, n_top + 1):'
- en: candidates = np.flatnonzero\
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: candidates = np.flatnonzero\
- en: (results['rank_test_score'] == i)
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: (results['rank_test_score'] == i)
- en: 'for candidate in candidates:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 'for candidate in candidates:'
- en: 'print("Model with rank: {0}".format(i))'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: print("排名模型：{0}".format(i))
- en: 'print("Mean validation score: {0:.3f} (std: {1:.3f})"\'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: print("平均验证得分：{0:.3f}（标准差：{1:.3f}）"\
- en: .format(results['mean_test_score'][candidate], \
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: .format(results['mean_test_score'][candidate], \
- en: results['std_test_score'][candidate]))
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: results['std_test_score'][candidate]))
- en: 'print("Parameters: {0}".format(results[''params'']\'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: print("参数：{0}".format(results['params']\
- en: '[candidate]))'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '[candidate]))'
- en: print("")
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: print("")
- en: 'Specify the parameters to sample from. Here, we will list the different values
    for each hyperparameter that we would like to have in the grid:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 指定要采样的参数。这里，我们将列出每个超参数在网格中需要的不同值：
- en: 'param_dist = {"n_estimators": list(range(10,210,10)), \'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 'param_dist = {"n_estimators": list(range(10,210,10)), \'
- en: '"max_depth": list(range(3,20)), \'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '"max_depth": list(range(3,20)), \'
- en: '"max_features": list(range(1, 10)), \'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '"max_features": list(range(1, 10)), \'
- en: '"min_samples_split": list(range(2, 11)), \'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '"min_samples_split": list(range(2, 11)), \'
- en: '"bootstrap": [True, False], \'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '"bootstrap": [True, False], \'
- en: '"criterion": ["gini", "entropy"]}'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '"criterion": ["gini", "entropy"]}'
- en: 'Run a randomized search. We initialize the random search object with the total
    number of trials we want to run, the parameter values dictionary, the scoring
    function, and the number of folds in the K-fold cross-validation. Then, we call
    the .fit() function to perform the search:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 执行随机搜索。我们初始化随机搜索对象，指定我们要运行的试验总数、参数值字典、评分函数以及 K 折交叉验证的折数。然后，我们调用 .fit() 函数执行搜索：
- en: n_iter_search = 60
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: n_iter_search = 60
- en: random_search = RandomizedSearchCV(rf_rand, \
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: random_search = RandomizedSearchCV(rf_rand, \
- en: param_distributions=param_dist, \
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: param_distributions=param_dist, \
- en: scoring='accuracy', \
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: scoring='accuracy', \
- en: n_iter=n_iter_search, cv=5)
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: n_iter=n_iter_search, cv=5)
- en: random_search.fit(X, y)
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: random_search.fit(X, y)
- en: 'The output will be as follows:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果将如下所示：
- en: '![Figure 7.29: Output for RandomizedSearchCV'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.29：随机搜索 CV 输出](img/image-AFPFRK4C.jpg)'
- en: '](img/image-VHCZRJC2.jpg)'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-VHCZRJC2.jpg)'
- en: 'Figure 7.29: Output for RandomizedSearchCV'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.29：随机搜索 CV 输出
- en: 'Print the scores and hyperparameters for the top five models. Convert the results
    dictionary into a pandas DataFrame and sort the values by rank_test_score. Then,
    for the first five rows, print the rank, mean validation score, and the hyperparameters:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 打印前五名模型的得分和超参数。将结果字典转换为 pandas DataFrame，并按 rank_test_score 排序。然后，对于前五行，打印排名、平均验证得分和超参数：
- en: results = pd.DataFrame(random_search.cv_results_)\
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: results = pd.DataFrame(random_search.cv_results_)\
- en: .sort_values('rank_test_score')
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: .sort_values('rank_test_score')
- en: 'for i, row in results.head().iterrows():'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 'for i, row in results.head().iterrows():'
- en: 'print("Model rank: {}".format(row.rank_test_score))'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: print("模型排名：{}".format(row.rank_test_score))
- en: 'print("Mean validation score: {:.3f} (std: {:.3f})"\'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: print("平均验证得分：{:.3f}（标准差：{:.3f}）"\
- en: .format(row.mean_test_score, row.std_test_score))
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: .format(row.mean_test_score, row.std_test_score))
- en: 'print("Model Hyperparameters: {}\n".format(row.params))'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: print("模型超参数：{}\n".format(row.params))
- en: 'The output will be as follows:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果将如下所示：
- en: '![Figure 7.30: Top five models’ scores and hyperparameters'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.30：前五名模型的得分和超参数](img/image-VHCZRJC2.jpg)'
- en: '](img/image-AFPFRK4C.jpg)'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-AFPFRK4C.jpg)'
- en: 'Figure 7.30: Top five models'' scores and hyperparameters'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.30：前五名模型的得分和超参数
- en: Generate the report for random search cv results
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 生成随机搜索 CV 结果的报告
- en: report(random_search.cv_results_)
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: report(random_search.cv_results_)
- en: 'The output will be as follows:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果将如下所示：
- en: '![Figure 7.31: Report for random search cv results'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.31：随机搜索 CV 结果报告](img/image-ZKVL6UYV.jpg)'
- en: '](img/image-ZKVL6UYV.jpg)'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-ZKVL6UYV.jpg)'
- en: 'Figure 7.31: Report for random search cv results'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.31：随机搜索 CV 结果报告
- en: Note
  id: totrans-397
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注：
- en: To access the source code for this specific section, please refer to https://packt.live/314tqUX.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该部分的源代码，请参阅 https://packt.live/314tqUX。
- en: You can also run this example online at https://packt.live/2V3YC2z. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 https://packt.live/2V3YC2z 在线运行这个示例。你必须执行整个 Notebook 才能获得预期的结果。
- en: We can see that the model that performs best has only 70 trees, compared to
    the 160+ trees in the models ranked 2 to 7\. Also, the model ranked 5 only has
    10 trees and still has a performance comparable to that of the more complex models.
    This demonstrates that the number of trees in a random forest model is not solely
    indicative of how well the model performs.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，表现最佳的模型只有 70 棵树，而排名第 2 到第 7 的模型有 160 多棵树。此外，排名第 5 的模型只有 10 棵树，仍然表现得与更复杂的模型相当。这表明，随机森林模型中的树木数量并不完全能反映模型的表现。
- en: 'A model''s performance is impacted by other factors, including the following:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 一个模型的表现会受到其他因素的影响，包括以下几点：
- en: How many maximum features are used for a tree (max_features)
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 每棵树使用的最大特征数（max_features）
- en: How descriptive are the features selected for each tree
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 每棵树选择的特征有多具描述性
- en: How distinct are those feature sets across trees
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特征集在树间的区别有多大
- en: How many data samples are used to train each tree
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练每棵树的数据样本数
- en: How many decisions a data instance goes through in a decision tree (max_depth)
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 数据实例在决策树中经过多少次决策（max_depth）
- en: How many minimum samples are allowed in a tree leaf (min_samples_split) and
    so on.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 树叶中允许的最小样本数（min_samples_split）等等。
- en: Feature Importance
  id: totrans-408
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 特征重要性
- en: 'While it is essential to focus on model performance, it is also important to
    understand how the features in our model contribute to the prediction:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管关注模型性能至关重要，但理解模型中各特征如何对预测结果产生影响也是很重要的：
- en: We need to be able to explain the model and how different variables affect the
    prediction to the relevant stakeholders who might demand insight into why our
    model is successful.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要能够向相关利益相关者解释模型及其不同变量如何影响预测，以便他们了解为什么我们的模型是成功的。
- en: The data might be biased and training a model on this data could hurt the model's
    performance and result in a biased model evaluation, in which case the ability
    to interpret the model by finding the important features and analyzing them will
    help debug the performance of the model.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可能存在偏差，在这些数据上训练模型可能会影响模型的表现，并导致模型评估结果偏颇，在这种情况下，通过找到重要特征并分析它们来解释模型的能力将有助于调试模型的性能。
- en: In addition to the previous point, it must be noted that some model biases might
    just be socially or legally unacceptable. For example, if a model works well because
    it implicitly places high importance on a feature based on ethnicity, this might
    cause issues.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 除了前一点之外，还必须注意到某些模型偏差可能是社会上或法律上不可接受的。例如，如果一个模型的表现良好，因为它隐式地对基于种族的特征赋予了很高的权重，这可能会引发问题。
- en: Besides these points, finding feature importance can also help in feature selection.
    If the data has high dimensionality and the trained model has high variance, removing
    features that have low importance is one way to achieve lowered variance through
    dimensionality reduction.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些点，寻找特征重要性还可以帮助进行特征选择。如果数据具有高维度并且训练后的模型具有较高的方差，去除那些重要性低的特征是一种通过降维来降低方差的方式。
- en: 'Exercise 7.05: Feature Importance Using Random Forest'
  id: totrans-414
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习 7.05：使用随机森林进行特征重要性分析
- en: In this exercise, we will find the feature importance from the random forest
    model we loaded earlier. This exercise is a continuation of Exercise 7.04, Hyperparameter
    Tuning with Random Search.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从之前加载的随机森林模型中找出特征的重要性。这个练习是练习 7.04 “使用随机搜索进行超参数调优”的延续。
- en: 'Find feature importance. Let''s find the feature importance and save it in
    a pandas DataFrame with an index equal to the column names, and sort this DataFrame
    in descending order:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 找到特征重要性。让我们找到特征的重要性并将其保存在一个 pandas DataFrame 中，索引设置为列名，并按降序对该 DataFrame 进行排序：
- en: 'feat_imps = pd.DataFrame({''importance'': rf.feature_importances_}, \'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 'feat_imps = pd.DataFrame({''importance'': rf.feature_importances_}, \'
- en: index=titanic_clf.columns[:-1])
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: index=titanic_clf.columns[:-1])
- en: feat_imps.sort_values(by='importance', ascending=False, \
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: feat_imps.sort_values(by='importance', ascending=False, \
- en: inplace=True)
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: inplace=True)
- en: 'Plot the feature importance as a bar plot:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制特征重要性柱状图：
- en: feat_imps.plot(kind='bar', figsize=(10,7))
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: feat_imps.plot(kind='bar', figsize=(10,7))
- en: plt.legend()
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: plt.legend()
- en: plt.show()
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: plt.show()
- en: 'The output will be as follows:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 7.32: Histogram of features'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.32：特征直方图'
- en: '](img/image-T0MUHCEU.jpg)'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-T0MUHCEU.jpg)'
- en: 'Figure 7.32: Histogram of features'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.32：特征直方图
- en: Here, we can see that the Gender, Fare, and Pclass features seem to have the
    highest importance; that is, they have the greatest impact on the target variable.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，性别、票价和舱位特征似乎具有最高的重要性；也就是说，它们对目标变量的影响最大。
- en: Note
  id: totrans-430
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to https://packt.live/2YYnxWz.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考 https://packt.live/2YYnxWz。
- en: You can also run this example online at https://packt.live/2Yo896Y. You must
    execute the entire Notebook in order to get the desired result.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 https://packt.live/2Yo896Y 在线运行这个示例。你必须执行整个 Notebook 才能获得所需的结果。
- en: 'Activity 7.01: Final Test Project'
  id: totrans-433
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 活动 7.01：最终测试项目
- en: In this activity, we'll use the Breast Cancer Diagnosis dataset that we used
    in Chapter 5, Classification Techniques (refer to Activity 5.04, Breast Cancer
    Diagnosis Classification Using Artificial Neural Networks for dataset details),
    to solve a binary classification problem wherein we have to predict whether the
    breast cell is benign or malignant given the features. In this problem, we want
    to maximize our recall; that is, we want to be able to identify all malignant
    cells, because if we miss any of those, we could detect no cancer, when there
    actually is cancer. And, we do not want to end up in that scenario.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，我们将使用在第五章《分类技术》中使用的乳腺癌诊断数据集（有关数据集的详细信息，请参见活动 5.04，使用人工神经网络进行乳腺癌诊断分类），来解决一个二分类问题，其中我们必须预测乳腺细胞是良性还是恶性，给定的特征。在这个问题中，我们希望最大化我们的召回率；也就是说，我们希望能够识别所有恶性细胞，因为如果错过其中任何一个，我们可能会误判没有癌症，而实际上有癌症。而且，我们不希望发生这种情况。
- en: We will use a gradient boosting classifier from scikit-learn to train the model.
    This activity is intended as a final project that will help consolidate the practical
    aspects of the concepts learned in this book, and particularly in this chapter.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 scikit-learn 中的梯度提升分类器来训练模型。本活动作为一个最终项目，旨在帮助巩固本书中学到的概念的实践方面，特别是在本章中。
- en: We will find the most optimal set of hyperparameters for the model by using
    random search with cross-validation. Then, we will build the final classifier
    using the gradient boosting algorithm on a portion of the dataset and evaluate
    its performance using the classification metrics we have learned about on the
    remaining portion of the dataset. We will use precision and recall as the evaluation
    metric for this activity.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用随机搜索与交叉验证来为模型找到最优的超参数组合。然后，我们将使用梯度提升算法在数据集的一部分上构建最终分类器，并使用我们在数据集的剩余部分上学到的分类度量来评估其性能。我们将使用精确度和召回率作为此活动的评估标准。
- en: 'The steps to be performed are as follows:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 执行的步骤如下：
- en: Import the relevant libraries.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 导入相关库。
- en: Read the breast-cancer-data.csv dataset.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 读取 breast-cancer-data.csv 数据集。
- en: Split the dataset into training and test sets.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集分成训练集和测试集。
- en: Choose a base model and define the range of hyperparameter values corresponding
    to the model to be searched for hyperparameter tuning.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个基础模型，并定义与该模型对应的超参数值范围，以进行超参数调优。
- en: Define the parameters with which to initialize the RandomizedSearchCV object
    and use K-fold cross-validation to find the best model hyperparameters.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 定义初始化 RandomizedSearchCV 对象的参数，并使用 K 折交叉验证找到最佳的模型超参数。
- en: Split the training dataset further into training and validation sets and train
    a new model using the final hyperparameters on the subdivided training dataset.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 将训练数据集进一步划分为训练集和验证集，并在划分后的训练数据集上使用最终超参数训练一个新模型。
- en: Calculate the accuracy, precision, and recall for predictions in relation to
    the validation set, and print the confusion matrix.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 计算与验证集相关的预测的准确性、精确度和召回率，并打印混淆矩阵。
- en: Experiment with varying thresholds to find the optimal point with high recall.
    Plot the precision-recall curve.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试不同的阈值，以找到具有高召回率的最优点。绘制精确度-召回率曲线。
- en: 'The output will be as follows:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 7.33: Precision recall curve'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.33：精确度召回率曲线'
- en: '](img/image-W7R7BD57.jpg)'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-W7R7BD57.jpg)'
- en: 'Figure 7.33: Precision recall curve'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.33：精确度召回率曲线
- en: Finalize a threshold that will be used for predictions in relation to the test dataset.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 确定一个阈值，用于与测试数据集相关的预测。
- en: 'The output will be as follows:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 7.34: Variation in precision and recall with increasing threshold
    values'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.34：精确度和召回率随着阈值增加的变化'
- en: '](img/image-7WEPT1JF.jpg)'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-7WEPT1JF.jpg)'
- en: 'Figure 7.34: Variation in precision and recall with increasing threshold values'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.34：随着阈值增加而变化的精确度和召回率
- en: Predict the final values on the test dataset.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 预测测试数据集的最终数值。
- en: 'The output will be as follows:'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 7.35: Predictions for the cancer dataset'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.35：癌症数据集的预测结果'
- en: '](img/image-8Q00N88H.jpg)'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image-8Q00N88H.jpg)'
- en: 'Figure 7.35: Predictions for the cancer dataset'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.35：癌症数据集的预测结果
- en: 'Note:'
  id: totrans-460
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意：
- en: The solution for this activity can be found via this link.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 可通过此链接找到此活动的解决方案。
- en: Summary
  id: totrans-462
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 概要
- en: This chapter discussed why model evaluation is important in supervised machine
    learning and looked at several important metrics that are used to evaluate regression
    and classification tasks. We saw that while regression models were fairly straightforward
    to evaluate, the performance of classification models could be measured in a number
    of ways, depending on what we want the model to prioritize. Besides numerical
    metrics, we also looked at how to plot precision-recall and ROC curves to better
    interpret and evaluate model performance. After this, we talked about why evaluating
    a model by calculating the prediction error in relation to the data that the model
    was trained on was a bad idea, and how testing a model on data that it has already
    seen would lead to the model having a high variance. With this, we introduced
    the concept of having a hold-out dataset and demonstrated why k-fold cross-validation
    is a useful strategy to have, along with sampling techniques that ensure that
    the model training and evaluation processes remain unbiased. The final section
    on performance improvement tactics started with a discussion on learning and validation
    curves, and how they can be interpreted to drive the model development process
    toward finding a better-performing model. This was followed by a section on hyperparameter
    tuning by way of an effort to boost performance, and a brief introduction to feature
    importance.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了为什么在监督学习中模型评估很重要，并查看了用于评估回归和分类任务的几个重要指标。我们看到，虽然回归模型评估相对直接，但分类模型的性能可以用多种方式衡量，具体取决于我们希望模型优先考虑的内容。除了数值指标外，我们还看了如何绘制精确率-召回率曲线和ROC曲线，以更好地解释和评估模型性能。在此之后，我们讨论了为什么通过计算模型在训练数据上的预测误差来评估模型是个坏主意，以及如何在模型已经看到的数据上测试模型会导致模型具有很高的方差。因此，我们引入了保留数据集的概念，并演示了为什么K折交叉验证是一种有用的策略，以及确保模型训练和评估过程保持无偏的抽样技术。性能改进策略的最后一部分从讨论学习曲线和验证曲线开始，以及如何解释它们以推动模型开发过程朝着找到性能更好的模型方向发展。接着是一节关于通过调整超参数来提升性能的讨论，并简要介绍了特征重要性的概念。
- en: Right from the fundamentals of supervised learning and regression and classification
    models to the concepts of ensembling and model performance evaluation, we have
    now added all the necessary tools to our supervised learning toolkit. This means
    that we are all set to start working on real-life supervised learning projects
    and apply all the knowledge and skills that we have gained with this Workshop.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 从监督学习和回归分类模型的基本原理到集成学习和模型性能评估的概念，我们现在已经为我们的监督学习工具包添加了所有必要的工具。这意味着我们已经准备好开始处理真实的监督学习项目，并应用我们通过这个研讨会获得的所有知识和技能。
