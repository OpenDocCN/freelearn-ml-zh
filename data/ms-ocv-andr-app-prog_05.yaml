- en: Chapter 5. Tracking Objects in Videos
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章：视频中的目标跟踪
- en: 'Object tracking is one of the most important applications of computer vision.
    It can be used for many applications, some of which are as follows:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 目标跟踪是计算机视觉最重要的应用之一。它可以用于许多应用，以下是一些例子：
- en: 'Human–computer interaction: We might want to track the position of a person''s
    finger and use its motion to control the cursor on our machines'
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人机交互：我们可能想要追踪人的手指位置，并使用其运动来控制我们机器上的光标
- en: 'Surveillance: Street cameras can capture pedestrians'' motions that can be
    tracked to detect suspicious activities'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控：街上的摄像头可以捕捉到行人的运动，这些运动可以被追踪以检测可疑活动
- en: Video stabilization and compression
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频稳定和压缩
- en: 'Statistics in sports: By tracking a player''s movement in a game of football,
    we can provide statistics such as distance travelled, heat maps, and so on'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 体育统计：通过追踪足球比赛中球员的运动，我们可以提供诸如行进距离、热图等统计数据
- en: 'In this chapter, you will learn the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习以下主题：
- en: Optical flow
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 光流
- en: Image Pyramids
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像金字塔
- en: Global Motion Estimation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全局运动估计
- en: The KLT tracker
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: KLT 追踪器
- en: Optical flow
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 光流
- en: Optical flow is an algorithm that detects the pattern of the motion of objects,
    or edges, between consecutive frames in a video. This motion may be caused by
    the motion of the object or the motion of the camera. Optical flow is a vector
    that depicts the motion of a point from the first frame to the second.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 光流是一种检测视频连续帧之间物体或边缘运动模式的算法。这种运动可能是由物体的运动或摄像机的运动引起的。光流是从第一帧到第二帧点的运动的向量。
- en: 'The optical flow algorithm works under two basic assumptions:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 光流算法基于两个基本假设：
- en: The pixel intensities are almost constant between consecutive frames
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像素强度在连续帧之间几乎保持恒定
- en: The neighboring pixels have the same motion as the anchor pixel
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相邻像素具有与锚点像素相同的运动
- en: 'We can represent the intensity of a pixel in any frame by *f(x,y,t)*. Here,
    the parameter *t* represents the frame in a video. Let''s assume that, in the
    next *dt* time, the pixel moves by *(dx,dy)*. Since we have assumed that the intensity
    doesn''t change in consecutive frames, we can say:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用 *f(x,y,t)* 来表示任何帧中像素的强度。在这里，参数 *t* 代表视频中的帧。让我们假设，在下一个 *dt* 时间内，像素移动了 *(dx,dy)*。由于我们假设强度在连续帧之间没有变化，因此我们可以说：
- en: '*f(x,y,t) = f(x + dx,y + dy,t + dt)*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*f(x,y,t) = f(x + dx,y + dy,t + dt)*'
- en: 'Now we take the Taylor series expansion of the RHS in the preceding equation:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对前面方程的右侧进行泰勒级数展开：
- en: '![Optical flow](img/B02052_05_10.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![光流](img/B02052_05_10.jpg)'
- en: 'Cancelling the common term, we get:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 消除公共项，我们得到：
- en: '![Optical flow](img/B02052_05_11.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![光流](img/B02052_05_11.jpg)'
- en: Where ![Optical flow](img/B02052_05_12.jpg).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![光流](img/B02052_05_12.jpg)。
- en: 'Dividing both sides of the equation by *dt* we get:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 将方程两边除以 *dt*，我们得到：
- en: '![Optical flow](img/B02052_05_13.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![光流](img/B02052_05_13.jpg)'
- en: 'This equation is called the optical flow equation. Rearranging the equation
    we get:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程被称为光流方程。重新排列方程，我们得到：
- en: '![Optical flow](img/B02052_05_14.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![光流](img/B02052_05_14.jpg)'
- en: We can see that this represents the equation of a line in the *(u,v)* plane.
    However, with only one equation available and two unknowns, this problem is under
    constraint at the moment. Two of the most widely used methods to calculate the
    optical flow are explained in the upcoming section.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，这代表了 *(u,v)* 平面上的直线方程。然而，只有一个方程可用，有两个未知数，因此目前这个问题处于约束状态。在下文中，我们将解释计算光流最广泛使用的两种方法。
- en: The Horn and Schunck method
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Horn 和 Schunck 方法
- en: 'By taking into account our assumptions, we get:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到我们的假设，我们得到：
- en: '![The Horn and Schunck method](img/B02052_05_15.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![Horn 和 Schunck 方法](img/B02052_05_15.jpg)'
- en: 'We can say that the first term will be small due to our assumption that the
    brightness is constant between consecutive frames. So, the square of this term
    will be even smaller. The second term corresponds to the assumption that the neighboring
    pixels have similar motion to the anchor pixel. We need to minimize the preceding
    equation. For this, we differentiate the preceding equation with respect to *u*
    and *v*. We get the following equations:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以说，由于我们的假设亮度在连续帧之间是恒定的，因此第一个项将很小。所以，这个项的平方将更小。第二个项对应于相邻像素与锚点像素具有相似运动的假设。我们需要最小化前面的方程。为此，我们对前面的方程关于
    *u* 和 *v* 求导。我们得到以下方程：
- en: '![The Horn and Schunck method](img/B02052_05_16.jpg)![The Horn and Schunck
    method](img/B02052_05_17.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![霍恩-舒恩克方法](img/B02052_05_16.jpg)![霍恩-舒恩克方法](img/B02052_05_17.jpg)'
- en: Here, ![The Horn and Schunck method](img/B02052_05_18.jpg) and ![The Horn and
    Schunck method](img/B02052_05_19.jpg) are the Laplacians of *u* and *v* respectively.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![霍恩-舒恩克方法](img/B02052_05_18.jpg)和![霍恩-舒恩克方法](img/B02052_05_19.jpg)分别是*u*和*v*的拉普拉斯算子。
- en: The Lucas and Kanade method
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卢卡斯-卡纳德方法
- en: 'We start off with the optical flow equation that we derived earlier and noticed
    that it is under constrained as it has one equation and two variables:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从之前推导出的光流方程开始，并注意到它是不受约束的，因为它有一个方程和两个变量：
- en: '![The Lucas and Kanade method](img/B02052_05_20.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_20.jpg)'
- en: 'To overcome this problem, we make use of the assumption that pixels in a 3x3
    neighborhood have the same optical flow:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这个问题，我们利用假设，即3x3邻域内的像素具有相同的光流：
- en: '![The Lucas and Kanade method](img/B02052_05_21.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_21.jpg)'
- en: 'We can rewrite these equations in the form of matrices, as shown here:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些方程重写为矩阵形式，如下所示：
- en: '![The Lucas and Kanade method](img/B02052_05_64.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_64.jpg)'
- en: 'This can be rewritten in the form:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以重写为以下形式：
- en: '![The Lucas and Kanade method](img/B02052_05_22.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_22.jpg)'
- en: 'Where:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '![The Lucas and Kanade method](img/B02052_05_23.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_23.jpg)'
- en: 'As we can see, *A* is a 9x2 matrix, *U* is a 2x1 matrix, and *b* is a 9x1 matrix.
    Ideally, to solve for *U*, we just need to multiply by ![The Lucas and Kanade
    method](img/B02052_05_24.jpg) on both sides of the equation. However, this is
    not possible, as we can only take the inverse of square matrices. Thus, we try
    to transform *A* into a square matrix by first multiplying the equation by ![The
    Lucas and Kanade method](img/B02052_05_25.jpg) on both sides of the equation:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，*A*是一个9x2的矩阵，*U*是一个2x1的矩阵，*b*是一个9x1的矩阵。理想情况下，为了求解*U*，我们只需要在方程的两边乘以![卢卡斯-卡纳德方法](img/B02052_05_24.jpg)。然而，这是不可能的，因为我们只能取方阵的逆。因此，我们尝试通过在方程的两边乘以![卢卡斯-卡纳德方法](img/B02052_05_25.jpg)来将*A*转换成一个方阵：
- en: '![The Lucas and Kanade method](img/B02052_05_26.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_26.jpg)'
- en: 'Now ![The Lucas and Kanade method](img/B02052_05_27.jpg) is a square matrix
    of dimension 2x2\. Hence, we can take its inverse:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在![卢卡斯-卡纳德方法](img/B02052_05_27.jpg)是一个2x2维度的方阵。因此，我们可以取其逆：
- en: '![The Lucas and Kanade method](img/B02052_05_28.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_28.jpg)'
- en: 'On solving this equation, we get:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 解这个方程，我们得到：
- en: '![The Lucas and Kanade method](img/B02052_05_29.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_29.jpg)'
- en: This method of multiplying the transpose and then taking an inverse is called
    **pseudo-inverse**.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这种先乘转置再取逆的方法称为**伪逆**。
- en: 'This equation can also be obtained by finding the minimum of the following
    equation:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程也可以通过找到以下方程的最小值来获得：
- en: '![The Lucas and Kanade method](img/B02052_05_30.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_30.jpg)'
- en: 'According to the optical flow equation and our assumptions, this value should
    be equal to zero. Since the neighborhood pixels do not have exactly the same values
    as the anchor pixel, this value is very small. This method is called **Least Square
    Error**. To solve for the minimum, we differentiate this equation with respect
    to *u* and *v*, and equate it to zero. We get the following equations:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 根据光流方程和我们的假设，这个值应该等于零。由于邻域像素的值并不完全与锚点像素相同，这个值非常小。这种方法称为**最小二乘误差**。为了求解最小值，我们对这个方程关于*u*和*v*求导，并将其等于零。我们得到以下方程：
- en: '![The Lucas and Kanade method](img/B02052_05_31.jpg)![The Lucas and Kanade
    method](img/B02052_05_32.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_31.jpg)![卢卡斯-卡纳德方法](img/B02052_05_32.jpg)'
- en: 'Now we have two equations and two variables, so this system of equations can
    be solved. We rewrite the preceding equations as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有两个方程和两个变量，因此这个方程组可以求解。我们将前面的方程重写如下：
- en: '![The Lucas and Kanade method](img/B02052_05_33.jpg)![The Lucas and Kanade
    method](img/B02052_05_34.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_33.jpg)![卢卡斯-卡纳德方法](img/B02052_05_34.jpg)'
- en: 'So, by arranging these equations in the form of a matrix, we get the same equation
    as obtained earlier:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，将这些方程排列成矩阵形式，我们得到与之前相同的方程：
- en: '![The Lucas and Kanade method](img/B02052_05_35.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![卢卡斯-卡纳德方法](img/B02052_05_35.jpg)'
- en: 'Since, the matrix *A* is now a 2x2 matrix, it is possible to take an inverse.
    On taking the inverse, the equation obtained is as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于矩阵 *A* 现在是一个 2x2 矩阵，因此可以取其逆。取逆后，得到的方程如下：
- en: '![The Lucas and Kanade method](img/B02052_05_36.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![Lucas 和 Kanade 方法](img/B02052_05_36.jpg)'
- en: 'This can be simplified as:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以简化为：
- en: '![The Lucas and Kanade method](img/B02052_05_37.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![Lucas 和 Kanade 方法](img/B02052_05_37.jpg)'
- en: 'Solving for *u* and *v*, we get:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 解算 *u* 和 *v*，我们得到：
- en: '![The Lucas and Kanade method](img/B02052_05_38.jpg)![The Lucas and Kanade
    method](img/B02052_05_39.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![Lucas 和 Kanade 方法](img/B02052_05_38.jpg)![Lucas 和 Kanade 方法](img/B02052_05_39.jpg)'
- en: Now we have the values for all the ![The Lucas and Kanade method](img/B02052_05_40.jpg),
    ![The Lucas and Kanade method](img/B02052_05_41.jpg), and ![The Lucas and Kanade
    method](img/B02052_05_42.jpg). Thus, we can find the values of *u* and *v* for
    each pixel.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了所有 ![Lucas 和 Kanade 方法](img/B02052_05_40.jpg)，![Lucas 和 Kanade 方法](img/B02052_05_41.jpg)，和
    ![Lucas 和 Kanade 方法](img/B02052_05_42.jpg) 的值。因此，我们可以找到每个像素的 *u* 和 *v* 的值。
- en: When we implement this algorithm, it is observed that the optical flow is not
    very smooth near the edges of the objects. This is due to the brightness constraint
    not being satisfied. To overcome this situation, we use **image pyramids** (explained
    in detail in the following sections).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们实现此算法时，观察到光流在物体边缘附近不是很平滑。这是由于亮度约束未得到满足。为了克服这种情况，我们使用 **图像金字塔**（在以下章节中详细解释）。
- en: Checking out the optical flow on Android
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查 Android 上的光流
- en: To see the optical flow in action on Android, we will create a grid of points
    over a video feed from the camera, and then the lines will be drawn for each point
    that will depict the motion of the point on the video, which is superimposed by
    the point on the grid.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Android 上查看光流的效果，我们将在来自摄像头的视频流上创建一个点阵，然后为每个点绘制线条，以描绘视频上该点的运动，该点叠加在网格点上。
- en: Before we begin, we will set up our project to use OpenCV and obtain the feed
    from the camera. We will process the frames to calculate the optical flow.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，我们将设置我们的项目以使用 OpenCV 并从摄像头获取视频流。我们将处理帧以计算光流。
- en: 'First, create a new project in Android Studio, in the same way as we did in
    the previous chapters. We will set the activity name to `MainActivity.java` and
    the XML resource file as `activity_main.xml`. Second, we will give the app the
    permissions to access the camera. In the `AndroidManifest.xml` file, add the following
    lines to the manifest tag:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在 Android Studio 中创建一个新的项目，就像我们在前面的章节中所做的那样。我们将活动名称设置为 `MainActivity.java`，并将
    XML 资源文件设置为 `activity_main.xml`。其次，我们将给应用授予访问摄像头的权限。在 `AndroidManifest.xml` 文件中，将以下行添加到
    manifest 标签中：
- en: '[PRE0]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Make sure that your activity tag for `MainActivity` contains the following
    line as an attribute:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您的 `MainActivity` 活动标签包含以下行作为属性：
- en: '[PRE1]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Our `activity_main.xml` file will contain a simple `JavaCameraView`. This is
    a custom OpenCV defined layout that enables us to access the camera frames and
    processes them as normal `Mat` objects. The XML code has been shown here:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `activity_main.xml` 文件将包含一个简单的 `JavaCameraView`。这是一个自定义的 OpenCV 定义布局，它使我们能够访问摄像头帧并将它们作为正常的
    `Mat` 对象处理。XML 代码如下所示：
- en: '[PRE2]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, let''s work on some Java code. First, we''ll define some global variables
    that we will use later in the code or for other sections in this chapter:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们编写一些 Java 代码。首先，我们将定义一些全局变量，我们将在代码的后续部分或其他章节中使用它们：
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We will need to create a callback function for OpenCV, like we did earlier.
    In addition to the code we used earlier, we will also enable `CameraView` to capture
    frames for processing:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要创建一个类似于之前的 OpenCV 回调函数。除了我们之前使用的代码之外，我们还将启用 `CameraView` 捕获用于处理的帧：
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We will now check whether the OpenCV manager is installed on the phone, which
    contains the required libraries. In the `onResume` function, add the following
    line of code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将检查手机上是否安装了 OpenCV 管理器，其中包含所需的库。在 `onResume` 函数中，添加以下代码行：
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the `onCreate()` function, add the following line before calling `setContentView`
    to prevent the screen from turning off, while using the app:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `onCreate()` 函数中，在调用 `setContentView` 之前添加以下行，以防止在使用应用时屏幕关闭：
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We will now initialize our `JavaCameraView` object. Add the following lines
    after `setContentView` has been called:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将初始化我们的 `JavaCameraView` 对象。在调用 `setContentView` 之后添加以下行：
- en: '[PRE7]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Notice that we called `setCvCameraViewListener` with the `this` parameter.
    For this, we need to make our activity implement the `CvCameraViewListener2` interface.
    So, your class definition for the `MainActivity` class should look like the following
    code:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用`this`参数调用了`setCvCameraViewListener`。为此，我们需要让我们的活动实现`CvCameraViewListener2`接口。所以，你的`MainActivity`类的类定义应该看起来像以下代码：
- en: '[PRE8]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will add a menu to this activity to toggle between different examples in
    this chapter. Add the following lines to the `onCreateOptionsMenu` function:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将向这个活动添加一个菜单来在章节中的不同示例之间切换。将以下行添加到`onCreateOptionsMenu`函数中：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We will now add some actions to the menu items. In the `onOptionsItemSelected`
    function, add the following lines:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将向菜单项添加一些操作。在`onOptionsItemSelected`函数中，添加以下行：
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We used a `resetVars` function to reset all the `Mat` objects. It has been
    defined as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了一个`resetVars`函数来重置所有的`Mat`对象。它已经被定义为以下内容：
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We will also add the code to make sure that the camera is released for use
    by other applications, whenever our application is suspended or killed. So, add
    the following snippet of code to the `onPause` and `onDestroy` functions:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将添加代码以确保，当我们的应用程序挂起或被杀死时，摄像头可以供其他应用程序使用。因此，将以下代码片段添加到`onPause`和`onDestroy`函数中：
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After the OpenCV camera has been started, the `onCameraViewStarted` function
    is called, which is where we will add all our object initializations:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV摄像头启动后，会调用`onCameraViewStarted`函数，这是我们添加所有对象初始化的地方：
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Similarly, the `onCameraViewStopped` function is called when we stop capturing
    frames. Here we will release all the objects we created when the view was started:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，当停止捕获帧时，会调用`onCameraViewStopped`函数。在这里，我们将释放在视图开始时创建的所有对象：
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now we will add the implementation to process each frame of the feed that we
    captured from the camera. OpenCV calls the `onCameraFrame` method for each frame,
    with the frame as a parameter. We will use this to process each frame. We will
    use the `viewMode` variable to distinguish between the optical flow and the KLT
    tracker, and have different case constructs for the two:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将添加处理从摄像头捕获的每一帧的实现。OpenCV为每一帧调用`onCameraFrame`方法，并将帧作为参数。我们将使用这个方法来处理每一帧。我们将使用`viewMode`变量来区分光流和KLT跟踪器，并为这两个提供不同的case结构：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We will use the `gray()`function to obtain the Mat object that contains the
    captured frame in a grayscale format. OpenCV also provides a similar function
    called `rgba()` to obtain a colored frame. Then we will check whether this is
    the first run. If this is the first run, we will create and fill up a `features`
    array that stores the position of all the points in a grid, where we will compute
    the optical flow:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`gray()`函数来获取包含捕获帧的灰度格式的Mat对象。OpenCV还提供了一个名为`rgba()`的类似函数来获取彩色帧。然后我们将检查这是否是第一次运行。如果是第一次运行，我们将创建并填充一个`features`数组，该数组存储网格中所有点的位置，我们将在这里计算光流：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `mPrevGray` object refers to the previous frame in a grayscale format.
    We copied the points to a `prevFeatures` object that we will use to calculate
    the optical flow and store the corresponding points in the next frame in `nextFeatures`.
    All of the computation is carried out in the `calcOpticalFlowPyrLK` OpenCV defined
    function. This function takes in the grayscale version of the previous frame,
    the current grayscale frame, an object that contains the feature points whose
    optical flow needs to be calculated, and an object that will store the position
    of the corresponding points in the current frame:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`mPrevGray`对象指的是灰度格式的上一帧。我们将点复制到一个`prevFeatures`对象中，我们将使用它来计算光流，并将相应的点存储在下一帧的`nextFeatures`中。所有的计算都是在OpenCV定义的`calcOpticalFlowPyrLK`函数中进行的。这个函数接受上一帧的灰度版本、当前灰度帧、一个包含需要计算光流的特征点的对象，以及一个将存储当前帧中相应点位置的对象：'
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we have the position of the grid of points and their position in the next
    frame as well. So, we will now draw a line that depicts the motion of each point
    on the grid:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了点的网格位置以及它们在下一帧中的位置。因此，我们现在将绘制一条线来描述网格上每个点的运动：
- en: '[PRE18]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Before the loop ends, we have to copy the current frame to `mPrevGray` so that
    we can calculate the optical flow in the subsequent frames:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在循环结束之前，我们必须将当前帧复制到`mPrevGray`，以便我们可以在后续帧中计算光流：
- en: '[PRE19]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After we end the switch case construct, we will return a Mat object. This is
    the image that will be displayed as an output to the user of the application.
    Here, since all our operations and processing were performed on the grayscale
    image, we will return this image:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束switch case结构后，我们将返回一个Mat对象。这是将作为应用程序用户输出的图像显示的图像。在这里，由于我们的所有操作和处理都是在灰度图像上进行的，我们将返回此图像：
- en: '[PRE20]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'So, this is all about optical flow. The result can be seen in the following
    image:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这就是关于光流的所有内容。结果可以在以下图像中看到：
- en: '![Checking out the optical flow on Android](img/B02052_05_01.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![检查Android上的光流](img/B02052_05_01.jpg)'
- en: Optical flow at various points in the camera feed
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 相机馈送中不同点的光流
- en: Image pyramids
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像金字塔
- en: 'Pyramids are multiple copies of the same images that differ in their sizes.
    They are represented as layers, as shown in the following figure. Each level in
    the pyramid is obtained by reducing the rows and columns by half. Thus, effectively,
    we make the image''s size one quarter of its original size:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 金字塔是相同图像的多个副本，它们的大小不同。它们以层的形式表示，如下所示。金字塔中的每一层都是通过将行和列减半获得的。因此，实际上，我们将图像的大小减少到原始大小的四分之一：
- en: '![Image pyramids](img/B02052_05_02.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图像金字塔](img/B02052_05_02.jpg)'
- en: Relative sizes of pyramids
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 金字塔的相对大小
- en: Pyramids intrinsically define **reduce** and **expand** as their two operations.
    Reduce refers to a reduction in the image's size, whereas expand refers to an
    increase in its size.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 金字塔本质上定义了**减少**和**扩展**为其两个操作。减少指的是图像大小的减少，而扩展指的是图像大小的增加。
- en: Note
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: We will use a convention that lower levels in a pyramid mean downsized images
    and higher levels mean upsized images.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个约定，即金字塔中的较低层表示缩小后的图像，而较高层表示放大后的图像。
- en: Gaussian pyramids
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高斯金字塔
- en: 'In the reduce operation, the equation that we use to successively find levels
    in pyramids, while using a 5x5 sliding window, has been written as follows. Notice
    that the size of the image reduces to a quarter of its original size:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在减少操作中，我们使用以下方程来连续找到金字塔中的层级，同时使用一个5x5的滑动窗口。请注意，图像的大小减少到原始大小的四分之一：
- en: '![Gaussian pyramids](img/B02052_05_43.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![高斯金字塔](img/B02052_05_43.jpg)'
- en: 'The elements of the weight kernel, *w*, should add up to 1\. We use a 5x5 Gaussian
    kernel for this task. This operation is similar to convolution with the exception
    that the resulting image doesn''t have the same size as the original image. The
    following image shows you the reduce operation:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 权重核的元素，*w*，应该加起来等于1。我们为此任务使用了一个5x5的高斯核。这个操作类似于卷积，但结果图像的大小与原始图像不同。以下图像展示了减少操作：
- en: '![Gaussian pyramids](img/B02052_05_03.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![高斯金字塔](img/B02052_05_03.jpg)'
- en: The reduce operation
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 减少操作
- en: 'The expand operation is the reverse process of reduce. We try to generate images
    of a higher size from images that belong to lower layers. Thus, the resulting
    image is blurred and is of a lower resolution. The equation we use to perform
    expansion is as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展操作是减少操作的逆过程。我们尝试从属于较低层的图像生成较大尺寸的图像。因此，结果图像是模糊的，并且分辨率较低。我们用于执行扩展的方程如下：
- en: '![Gaussian pyramids](img/B02052_05_44.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![高斯金字塔](img/B02052_05_44.jpg)'
- en: 'The weight kernel in this case, *w*, is the same as the one used to perform
    the reduce operation. The following image shows you the expand operation:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，权重核*w*与用于执行减少操作的权重核相同。以下图像展示了扩展操作：
- en: '![Gaussian pyramids](img/B02052_05_04.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![高斯金字塔](img/B02052_05_04.jpg)'
- en: The expand operation
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展操作
- en: The weights are calculated using the Gaussian function that we used in [Chapter
    1](ch01.html "Chapter 1. Applying Effects to Images"), *Applying Effects to Images*,
    to perform Gaussian blur.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 权重是使用我们在[第1章](ch01.html "第1章。对图像应用效果")中使用的，*对图像应用效果*，高斯函数来执行高斯模糊计算的。
- en: Laplacian pyramids
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拉普拉斯金字塔
- en: 'Laplacian pyramids are images that generally represent the edges. They are
    obtained from Gaussian pyramids. They are calculated using the following formula:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 拉普拉斯金字塔通常表示边缘。它们是从高斯金字塔获得的。它们使用以下公式计算：
- en: '![Laplacian pyramids](img/B02052_05_45.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![拉普拉斯金字塔](img/B02052_05_45.jpg)'
- en: '*g[i] and Expand* (*g*[*i*+1]) are not the same once we downsize an image;
    we lose information, which cannot be recovered.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*g[i]和扩展* (*g*[*i*+1])在我们缩小图像后不再相同；我们丢失了信息，这些信息无法恢复。'
- en: '![Laplacian pyramids](img/B02052_05_05.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![拉普拉斯金字塔](img/B02052_05_05.jpg)'
- en: Gaussian and Laplacian pyramids in OpenCV
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCV中的高斯和拉普拉斯金字塔
- en: 'To see how pyramids are created in OpenCV, we will create two new activities
    called `PyramidActivity` and `HomeActivity`. The `PyramidActivity` class will
    load an image from the gallery, and then, based on the user''s options, perform
    the required actions. `HomeActivity` is used to call either `PyramidActivity`
    or `MainActivity` based on options provided by the user. So first, we make the
    resource for the `HomeActivity` class and call it `activity_home.xml`:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解 OpenCV 中如何创建金字塔，我们将创建两个新的活动，分别称为 `PyramidActivity` 和 `HomeActivity`。`PyramidActivity`
    类将从图库中加载一张图片，然后根据用户的选项执行所需的操作。`HomeActivity` 用于根据用户提供的选项调用 `PyramidActivity` 或
    `MainActivity`。因此，首先，我们为 `HomeActivity` 类创建资源，并将其命名为 `activity_home.xml`：
- en: '[PRE21]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In our Java code, we will add listeners to these buttons to call the respective
    activities, as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 Java 代码中，我们将为这些按钮添加监听器以调用相应的活动，如下所示：
- en: '[PRE22]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now we move on to the implementation of `PyramidActivity`. First, we will take
    a look at `activity_pyramid.xml`. We will add buttons to perform various actions
    as per the user''s options. The possible options are Gaussian pyramid up, Gaussian
    pyramid down, and Laplacian pyramid calculation. The following code is inserted
    into `LinearLayout` inside `ScrollView`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们转向 `PyramidActivity` 的实现。首先，我们将查看 `activity_pyramid.xml`。我们将添加按钮以执行用户选项的各种操作。可能的选项是高斯金字塔向上、高斯金字塔向下和拉普拉斯金字塔计算。以下代码被插入到
    `ScrollView` 内部的 `LinearLayout`：
- en: '[PRE23]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We will also have a menu file for this activity that will be used to load images
    from the gallery. We will have a similar method to load images from the gallery
    that we did in the earlier chapters. We will have the following lines in `PyramidActivity.java`:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将为这个活动创建一个菜单文件，用于从图库中加载图片。我们将有一个类似于前面章节中加载图片的方法。在 `PyramidActivity.java`
    中，我们将有以下行：
- en: '[PRE24]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now we will define some global variables that we will need:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将定义一些全局变量，我们将需要它们：
- en: '[PRE25]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We also need to specify the OpenCV callback function and initialize it in `onResume`,
    as we did earlier.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要指定 OpenCV 回调函数并在 `onResume` 中初始化它，就像我们之前做的那样。
- en: 'In our `onCreate` function, after we initialize all our buttons, we will first
    disable them until an image has been loaded from the gallery. So, add the following
    lines after initializing all the buttons in this activity:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 `onCreate` 函数中，初始化所有按钮之后，我们将首先禁用它们，直到从图库中加载了一张图片。因此，在这个活动中初始化所有按钮之后，添加以下行：
- en: '[PRE26]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In our `onActivityResult`, we will check whether the image has been loaded
    successfully, and if it has been we activate the buttons. We also load the image
    to a Mat and store it for later use:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 `onActivityResult` 中，我们将检查图片是否已成功加载，如果是，我们将激活按钮。我们还将图片加载到 `Mat` 中并存储起来以供以后使用：
- en: '[PRE27]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now we will add the listeners for each of the buttons. In your `onCreate`,
    add the following lines:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将为每个按钮添加监听器。在你的 `onCreate` 中，添加以下行：
- en: '[PRE28]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now we will implement the `executeTask` function that will perform the required
    computations in `AsyncTask`, and after they are completed, they will be loaded
    into `ImageView` that we have in our layout:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将实现 `executeTask` 函数，该函数将在 `AsyncTask` 中执行所需的计算，并在完成后将它们加载到我们布局中的 `ImageView`：
- en: '[PRE29]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Here, we have called `pyrUp` and `pyrDown` with just two arguments; however,
    you can specify a custom size for the results by calling the function as `Imgproc.pyrUp(srcMat,
    dstMat, resultSize)`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只用了两个参数调用了 `pyrUp` 和 `pyrDown`；然而，你可以通过调用函数 `Imgproc.pyrUp(srcMat, dstMat,
    resultSize)` 来指定自定义的结果大小。
- en: OpenCV doesn't provide a separate function to calculate the Laplacian pyramid,
    but we can use the Gaussian pyramids to generate our Laplacian pyramids.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 不提供单独的函数来计算拉普拉斯金字塔，但我们可以使用高斯金字塔来生成我们的拉普拉斯金字塔。
- en: Basic 2D transformations
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本二维变换
- en: 'An object in 3D space can cast a projection in 2D space that is different from
    the original projection. Such transformations are called 2D transformations. They
    are shown in the following image. We will use some of these transformations to
    explain concepts discussed later in the chapter and also in other chapters:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 3D 空间中的对象可以在 2D 空间中投射出与原始投影不同的投影。这种变换称为二维变换。它们在以下图像中显示。我们将使用其中一些变换来解释本章后面以及在其他章节中讨论的概念：
- en: '![Basic 2D transformations](img/B02052_05_06.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![基本二维变换](img/B02052_05_06.jpg)'
- en: 'We write these transformations in the mathematical form, along with their matrix
    representations, as shown here:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些变换写成数学形式，以及它们的矩阵表示，如下所示：
- en: '**Translation**: The mathematical representation of a translation transformation
    is given by:![Basic 2D transformations](img/B02052_05_47.jpg)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平移**：平移变换的数学表示如下：![基本二维变换](img/B02052_05_47.jpg)'
- en: '**Affine**: The mathematical representation of an affine transformation is
    given by:![Basic 2D transformations](img/B02052_05_65.jpg)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仿射**：仿射变换的数学表示如下：![基本二维变换](img/B02052_05_65.jpg)'
- en: '**Rigid**: The mathematical representation of a rigid transformation is given
    by:![Basic 2D transformations](img/B02052_05_48.jpg)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**刚性**：刚性变换的数学表示如下：![基本二维变换](img/B02052_05_48.jpg)'
- en: '**Projective**: The mathematical representation of a projective transformation
    is given by:![Basic 2D transformations](img/B02052_05_49.jpg)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**投影**：投影变换的数学表示如下：![基本二维变换](img/B02052_05_49.jpg)'
- en: Global motion estimation
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全球运动估计
- en: 'Global motion estimation, as the name suggests, is the detection of motion
    using all pixels in a frame in its calculation. Some of the applications of global
    motion estimation include:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，全球运动估计是在计算中使用帧中所有像素来检测运动。全球运动估计的一些应用包括：
- en: Video stabilization
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频稳定化
- en: Video encoding/decoding
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频编码/解码
- en: Object segmentation
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物体分割
- en: 'This method was proposed by Bergen et.al. (1992). In this method, when the
    distance between the camera and the background scenes is large, we can approximate
    the motion of objects as affine transformations. The equations we saw earlier
    were as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法由Bergen等人（1992年）提出。在此方法中，当相机与背景场景之间的距离很大时，我们可以将对象的运动近似为仿射变换。我们之前看到的方程如下：
- en: '![Global motion estimation](img/B02052_05_50.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![全球运动估计](img/B02052_05_50.jpg)'
- en: 'We can rewrite these equations in the matrix form as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些方程重写为以下矩阵形式：
- en: '![Global motion estimation](img/B02052_05_51.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![全球运动估计](img/B02052_05_51.jpg)'
- en: This can be written as ![Global motion estimation](img/B02052_05_52.jpg).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以写成![全球运动估计](img/B02052_05_52.jpg)。
- en: 'According to the optical flow equation:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 根据光流方程：
- en: '![Global motion estimation](img/B02052_05_53.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![全球运动估计](img/B02052_05_53.jpg)'
- en: 'We try to estimate the motion in the image such that all the pixels satisfy
    it. Thus, we sum up the optical flow equation for all the pixels and try to generate
    an estimate:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们试图估计图像中的运动，使得所有像素都满足它。因此，我们求和所有像素的光流方程，并尝试生成一个估计：
- en: '![Global motion estimation](img/B02052_05_54.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![全球运动估计](img/B02052_05_54.jpg)'
- en: '![Global motion estimation](img/B02052_05_55.jpg) should ideally be zero but
    practically, it is a small value. Thus, the squared error will be small. Hence,
    we need to minimize it for the best results:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '![全球运动估计](img/B02052_05_55.jpg)理想情况下应为零，但实际上是一个小值。因此，平方误差将很小。因此，我们需要最小化它以获得最佳结果：'
- en: '![Global motion estimation](img/B02052_05_56.jpg)![Global motion estimation](img/B02052_05_57.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![全球运动估计](img/B02052_05_56.jpg)![全球运动估计](img/B02052_05_57.jpg)'
- en: 'This equation can be minimized with respect to ![Global motion estimation](img/B02052_05_61.jpg)
    to the following linear equation:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 该方程可以相对于![全球运动估计](img/B02052_05_61.jpg)最小化到以下线性方程：
- en: '![Global motion estimation](img/B02052_05_58.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![全球运动估计](img/B02052_05_58.jpg)'
- en: 'This linear equation can be written as:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这个线性方程可以写成：
- en: '![Global motion estimation](img/B02052_05_59.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![全球运动估计](img/B02052_05_59.jpg)'
- en: 'This algorithm is now divided into four subparts: pyramid construction, motion
    estimation, image warping, and coarse-to-fine refinement.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法现在分为四个子部分：金字塔构建、运动估计、图像扭曲和从粗到细的细化。
- en: For the pyramid construction, we first take a Gaussian pyramid of the images
    at time *t* and *t-1*, and compute the global flows iteratively, starting from
    the smallest layers going toward the bigger layers.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 对于金字塔构建，我们首先对时间 *t* 和 *t-1* 的图像进行高斯金字塔，然后从最底层开始迭代计算全局流，逐渐向更底层移动。
- en: Then, for each layer, to find the motion estimation, we use the linear equation
    derived earlier to compute A and B for the frames at time *t* and *t-1*, and use
    this information to compute an estimate for *a* ![Global motion estimation](img/B02052_05_60.jpg).
    We then warp the image at time *t-1* to an image, which tries to generate the
    object motion from the original image. This new image is compared to the image
    captured at time *t*. We then iteratively warp the image frame obtained at *t-1*
    to compute the value of ![Global motion estimation](img/B02052_05_61.jpg). With
    this value of ![Global motion estimation](img/B02052_05_61.jpg), we generate another
    warped image, which is then compared to the image at time *t*. We use this value
    of ![Global motion estimation](img/B02052_05_61.jpg) to update the value of *a*.
    This process is performed multiple times until we have a good enough estimate
    of the motion of the image.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于每一层，为了找到运动估计，我们使用之前推导出的线性方程来计算时间 *t* 和 *t-1* 的帧的 A 和 B，并使用这些信息来计算 *a* ![全局运动估计](img/B02052_05_60.jpg)
    的估计。然后我们将时间 *t-1* 的图像扭曲到另一个图像，该图像试图从原始图像生成对象运动。这个新图像与时间 *t* 捕获的图像进行比较。然后我们迭代扭曲在
    *t-1* 获得的图像帧以计算 ![全局运动估计](img/B02052_05_61.jpg) 的值。有了 ![全局运动估计](img/B02052_05_61.jpg)
    的这个值，我们生成另一个扭曲图像，然后将其与时间 *t* 的图像进行比较。我们使用 ![全局运动估计](img/B02052_05_61.jpg) 的这个值来更新
    *a* 的值。这个过程执行多次，直到我们得到图像运动的足够好的估计。
- en: 'Image warping is the process of performing any transformation on an image to
    produce another image. For this method, we perform affine transformations because
    of our earlier assumptions:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图像扭曲是将任何变换应用于图像以产生另一个图像的过程。对于这种方法，我们执行仿射变换，因为我们之前的假设：
- en: '![Global motion estimation](img/B02052_05_07.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![全局运动估计](img/B02052_05_07.jpg)'
- en: For the final step, coarse-to-fine refinement, we make use of image pyramids
    to extend our model to include dense images (for example, representing a depth
    map).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 对于最后一步，从粗到细的细化，我们利用图像金字塔将我们的模型扩展到包括密集图像（例如，表示深度图）。
- en: The Kanade-Lucas-Tomasi tracker
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kanade-Lucas-Tomasi跟踪器
- en: 'Having seen local and global motion estimation, we will now take a look at
    object tracking. Tracking objects is one of the most important applications of
    computer vision. The **Kanade-Lucas-Tomasi** (**KLT**) tracker implements an optical
    flow to track objects in videos. The steps to implement the algorithm are explained
    as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了局部和全局运动估计之后，我们现在将看看目标跟踪。跟踪目标是计算机视觉最重要的应用之一。**Kanade-Lucas-Tomasi**（**KLT**）跟踪器通过光流在视频中跟踪对象。实现该算法的步骤如下所述：
- en: Detect Harris corners in the first frame of the video.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在视频的第一帧中检测Harris角点。
- en: For each detected Harris corner, compute the motion between consecutive frames
    using the optical flow (translator) and local affine transformation (affine).
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个检测到的Harris角点，使用光流（translator）和局部仿射变换（affine）计算连续帧之间的运动。
- en: Now link these motion vectors from frame-to-frame to track the corners.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在将这些运动矢量从一帧链接到另一帧以跟踪角点。
- en: Generate new Harris corners after a specific number of frames (say, 10 to 20)
    to compensate for new points entering the scene or to discard the ones going out
    of the scene.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在特定数量的帧（例如，10到20帧）之后生成新的Harris角点，以补偿场景中进入的新点或丢弃场景外的点。
- en: Track the new and old Harris points.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟踪新的和旧的Harris点。
- en: Checking out the KLT tracker on OpenCV
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在OpenCV上检查KLT跟踪器
- en: 'As we have seen earlier, the KLT tracker is one of the best algorithms available
    to track objects in videos. For this example, we will take a feed from the camera,
    detect some good trackable features, and update these to the new locations, as
    obtained by the `calcOpticalFlowPyrLK` function. We will just add a new case construct
    to the code that we wrote for the optical flow:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所见，KLT跟踪器是可用的最佳算法之一，用于在视频中跟踪对象。对于这个例子，我们将从摄像头获取输入，检测一些可跟踪的特征，并将这些特征更新到新位置，如
    `calcOpticalFlowPyrLK` 函数获得的位置。我们只需将一个新的情况构造添加到我们为光流编写的代码中：
- en: '[PRE30]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The `goodFeaturesToTrack` function uses the Shi-Tomasi method to calculate good
    trackable features in an image. This could be replaced by any reliable feature
    calculation technique. It takes the frame in a grayscale format as the input and
    returns the list of features. It also takes the parameter of the maximum number
    of features, to track, the quality of features, and the minimum distance between
    features respectively. For the purpose of this sample, we will only calculate
    features in the first frame and track these features in the subsequent frames.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '`goodFeaturesToTrack` 函数使用 Shi-Tomasi 方法来计算图像中的良好可追踪特征。这可以被任何可靠的特征计算技术所替代。它以灰度格式作为输入帧，并返回特征列表。它还接受要追踪的最大特征数量、特征的质最以及特征之间的最小距离作为参数。在本示例中，我们只将在第一帧中计算特征，并在后续帧中追踪这些特征。'
- en: 'Now we will obtain the optical flow for the feature points obtained previously.
    Note that `nextFeatures` contains the locations of the corresponding points in
    the previous frame in `prevFeatures`. We will mark the location of the feature
    points with circles. Note that we are drawing the circles at the new locations
    of the features:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将获得之前获得的特征点的光流。请注意，`nextFeatures` 包含在 `prevFeatures` 中的前一个帧中相应点的位置。我们将用圆圈标记特征点的位置。请注意，我们是在特征的新位置上画圆圈：
- en: '[PRE31]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now we need to set the current frame as the previous frame, and the current
    feature point locations as the locations of the features in the previous frame
    so as to enable tracking:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要将当前帧设置为前一个帧，并将当前特征点的位置设置为前一个帧中特征的位置，以便启用追踪：
- en: '[PRE32]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The results of Shi-Tomasi tracker and the KLT tracker can be seen in the following
    image:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Shi-Tomasi 追踪器和 KLT 追踪器的结果可以在以下图像中看到：
- en: '![Checking out the KLT tracker on OpenCV](img/B02052_05_08.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![检查 OpenCV 中的 KLT 追踪器](img/B02052_05_08.jpg)'
- en: 'The white circles in the following image represent the features that we are
    tracking:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像中的白色圆圈代表我们正在追踪的特征：
- en: '![Checking out the KLT tracker on OpenCV](img/B02052_05_09.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![检查 OpenCV 中的 KLT 追踪器](img/B02052_05_09.jpg)'
- en: As it is visible, a small number of points are not tracked properly. For example,
    consider the feature point at the *L* key. As you can see, in one frame, it is
    at the *L* key, while in the other frame, it shifts to the key with the semicolon.
    If you consider the feature points at the *Y* and *J* keys, they remain in their
    positions. This is because at the keys *Y* and *J*, there are well-defined corners;
    hence, the feature points are better there.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如图中所示，有一些点没有正确追踪。例如，考虑 *L* 键上的特征点。如您所见，在一个帧中，它位于 *L* 键上，而在另一个帧中，它移动到了带有分号的键上。如果您考虑
    *Y* 和 *J* 键上的特征点，它们保持在它们的位置。这是因为 *Y* 和 *J* 键上有定义良好的角点；因此，特征点在那里更好。
- en: Summary
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have seen how to detect a local and global motion in a video,
    and how we can track objects. We have also learned about Gaussian and Laplacian
    pyramids, and how they can be used to improve the performance of some computer
    vision tasks.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何在视频中检测局部和全局运动，以及如何追踪对象。我们还了解了高斯和拉普拉斯金字塔，以及它们如何被用来提高某些计算机视觉任务的性能。
- en: In the next chapter, we will learn how to align multiple images and how to stitch
    them together to form a panoramic image.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何对多张图像进行对齐，以及如何将它们拼接在一起形成全景图像。
