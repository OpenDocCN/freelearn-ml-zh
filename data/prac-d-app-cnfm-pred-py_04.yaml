- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Validity and Efficiency of Conformal Prediction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 符合性预测的有效性和效率
- en: In this chapter, we will dive deeper into the concepts of validity and efficiency
    in the context of probabilistic prediction models, building upon the foundations
    laid in the previous chapters.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将更深入地探讨概率预测模型中的有效性和效率概念，在前面章节的基础上进行构建。
- en: Validity and efficiency are crucial aspects that ensure the practicality and
    robustness of prediction models across a wide range of industry applications.
    Understanding these concepts and their implications will enable you to develop
    unbiased and high-performing models that can reliably support decision-making
    and risk assessment processes.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 有效性和效率是确保预测模型在广泛行业应用中的实用性和鲁棒性的关键方面。理解这些概念及其影响将使你能够开发出无偏且高性能的模型，这些模型可以可靠地支持决策和风险评估过程。
- en: In this chapter, we will explore the definitions, metrics, and examples of valid
    and efficient models and discuss the automatic validity guarantees provided by
    **conformal prediction**, a cutting-edge approach to uncertainty quantification.
    By the end of this chapter, you will be equipped with the knowledge necessary
    to assess and improve the validity and efficiency of your predictive models, paving
    the way for more reliable and effective applications in your respective fields.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨有效和高效模型的定义、指标和示例，并讨论由**符合性预测**提供的自动有效性保证，这是一种前沿的不确定性量化方法。到本章结束时，你将具备评估和改进你预测模型有效性和效率所需的知识，为你在各自领域内更可靠和有效的应用铺平道路。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The validity of probabilistic predictors
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率预测器的有效性
- en: The efficiency of probabilistic predictors
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率预测器的效率
- en: The validity of probabilistic predictors
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概率预测器的有效性
- en: 'We start by summarizing the reasons why unbiased point prediction models are
    important across various domains and applications:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先总结一下为什么无偏点预测模型在各个领域和应用中都很重要：
- en: '**Accuracy and reliability**: An unbiased model ensures that the predictions
    it generates are accurate and reliable on average, meaning that the model is neither
    systematically overestimating nor underestimating the true values. This accuracy
    is crucial for making well-informed decisions, minimizing risks, and improving
    the overall performance of a system.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确性和可靠性**：无偏模型确保其生成的预测在平均上是准确和可靠的，这意味着模型既不会系统地高估也不会低估真实值。这种准确性对于做出明智的决策、最小化风险和提升系统的整体性能至关重要。'
- en: '**Trust and credibility**: Unbiased prediction models help build trust and
    credibility among stakeholders, as they provide a reliable basis for decision-making.
    Users can have more confidence in the outputs generated by an unbiased model,
    knowing that it is not skewed or favoring any specific outcome.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信任和可信度**：无偏预测模型有助于在利益相关者之间建立信任和可信度，因为它们为决策提供了可靠的基础。用户可以更有信心地依赖无偏模型生成的输出，知道它不会偏斜或偏向任何特定结果。'
- en: '**Fairness and equity**: In some applications, such as finance, healthcare,
    and human resources, unbiased models are essential to ensure fairness and equity
    among different groups or individuals. Biased models can inadvertently reinforce
    existing inequalities or create new ones, leading to unfair treatment or allocation
    of resources.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公平性和公正性**：在某些应用中，例如金融、医疗保健和人力资源，无偏模型对于确保不同群体或个人之间的公平性和公正性至关重要。有偏模型可能会无意中加剧现有的不平等或创造新的不平等，导致不公平的待遇或资源分配。'
- en: '**Generalizability**: Unbiased models are more likely to generalize well to
    new, unseen data because they accurately represent the underlying relationships
    in the data. In contrast, biased models may perform poorly when applied to new
    data or different conditions, leading to unexpected errors or suboptimal outcomes.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**泛化性**：无偏模型更有可能在新数据或未见数据上良好泛化，因为它们准确地代表了数据中的潜在关系。相比之下，有偏模型在应用于新数据或不同条件下可能会表现不佳，导致意外的错误或次优结果。'
- en: '**Regulatory compliance**: In certain industries, unbiased models are a requirement
    for regulatory compliance. For example, in finance, healthcare, and insurance,
    models must be free of bias to meet regulatory standards and ensure that customers
    are treated fairly and risks are managed effectively.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合规性**：在某些行业中，无偏模型是合规性的要求。例如，在金融、医疗保健和保险业，模型必须无偏见以满足监管标准，并确保客户得到公平对待，风险得到有效管理。'
- en: In the context of conformal prediction, validity refers to the ability of a
    prediction model to provide accurate, reliable, and unbiased estimates of the
    uncertainty associated with its predictions. More specifically, a valid conformal
    predictor generates prediction intervals that contain the true values of the target
    variable with a predefined coverage probability, ensuring that the model’s uncertainty
    quantification is reliable and well calibrated.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在一致预测的背景下，有效性指的是预测模型提供准确、可靠和无偏估计其预测相关不确定性的能力。更具体地说，一个有效的一致预测器会生成包含目标变量真实值的预测区间，并具有预定义的覆盖概率，确保模型的不确定性量化是可靠的且经过良好校准。
- en: 'The significance of validity in conformal prediction can be understood from
    various perspectives:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从不同角度可以理解一致预测中有效性的重要性：
- en: '**Confidence in** **predictions**: Valid conformal predictors allow users to
    have confidence in the prediction intervals they generate, as they know that these
    intervals truly reflect the uncertainty in the predictions. For instance, if a
    conformal predictor produces a 95% prediction interval for a certain data point,
    users can trust that there is a 95% probability that the true value lies within
    that interval. This confidence is crucial for decision-making and risk management
    in various applications.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对预测的信心**：有效的预测器允许用户对其生成的预测区间有信心，因为他们知道这些区间真正反映了预测的不确定性。例如，如果一个一致预测器为某个数据点生成一个95%的预测区间，用户可以相信有95%的概率真实值位于该区间内。这种信心对于各种应用中的决策和风险管理至关重要。'
- en: '**Robustness to model misspecification**: One of the key strengths of conformal
    prediction is its ability to provide valid uncertainty estimates even when the
    underlying prediction model is misspecified or imperfect. This robustness to model
    misspecification is particularly valuable in real-world settings, where the true
    data-generating process is often unknown or complex and the available models may
    only provide approximations of the underlying relationships.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对模型误设的鲁棒性**：一致预测的一个关键优势是即使在底层预测模型误设或不完美的情况下，它也能提供有效的确定性估计。这种对模型误设的鲁棒性在现实世界场景中特别有价值，因为在这些场景中，真实的数据生成过程往往是未知的或复杂的，而可用的模型可能只能提供底层关系的近似。'
- en: '**Non-parametric nature**: Conformal prediction is a non-parametric method,
    meaning that it does not rely on any specific assumptions about the data distribution
    or prediction errors. This non-parametric property further contributes to the
    validity of conformal predictors, as they can adapt to different data structures
    and provide accurate uncertainty estimates without requiring explicit knowledge
    of the underlying distributions.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非参数性质**：一致预测是一种非参数方法，这意味着它不依赖于关于数据分布或预测误差的任何特定假设。这种非参数特性进一步促进了一致预测器的有效性，因为它们可以适应不同的数据结构，并在不需要了解底层分布的显式知识的情况下提供准确的不确定性估计。'
- en: '**Applicability across domains**: The validity of conformal prediction is a
    universal property that holds across various domains and applications. This universality
    allows practitioners to leverage conformal prediction in diverse fields, such
    as finance, healthcare, energy, and transportation, knowing that the uncertainty
    estimates provided by conformal predictors will be valid and reliable regardless
    of the specific context.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跨领域的适用性**：一致预测的有效性是一个普遍的特性，适用于各种领域和应用。这种普遍性允许从业者利用一致预测在多个领域，如金融、医疗保健、能源和交通等领域，知道一致预测器提供的不确定性估计将有效且可靠，无论具体情境如何。'
- en: '**Automatic validity guarantees**: A key advantage of conformal prediction
    over traditional methods is its ability to provide automatic validity guarantees,
    meaning that the uncertainty estimates it produces are guaranteed to be valid
    under mild assumptions, such as the exchangeability of the data. This automatic
    validity ensures that conformal predictors maintain their reliability even as
    new data points are added or as the underlying relationships evolve over time.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动有效性保证**：与传统方法相比，一致预测的一个关键优势是它能够提供自动有效性保证，这意味着它产生的不确定性估计在轻微的假设下（如数据的可交换性）是有效的。这种自动有效性确保一致预测器即使在添加新数据点或底层关系随时间演变时也能保持其可靠性。'
- en: In conformal prediction, validity is mathematically defined in terms of the
    coverage probability of the prediction intervals or regions generated by the conformal
    predictor. A conformal predictor is valid if, for any desired confidence level
    *(1−α)*, the proportion of true target values contained within their corresponding
    prediction intervals is at least *(1−α)*, on average, across multiple instances.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在符合性预测中，有效性从数学上定义为预测区间或由符合性预测器生成的区域的覆盖概率。如果对于任何期望的置信水平 *(1−α)*，真实目标值在其相应预测区间内包含的比例平均而言至少为
    *(1−α)*，则符合性预测器是有效的，在多个实例中。
- en: 'Mathematically, let’s denote the target variable as *Y* and the prediction
    interval (in regression) or set (in classification) as *I(x, α)*, where *x* represents
    the features of the test data point and *α* is the significance level *(α* ∈ *[0,
    1])*. The conformal predictor is valid if the following condition holds:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，让我们将目标变量表示为 *Y*，预测区间（在回归中）或集合（在分类中）表示为 *I(x, α)*，其中 *x* 代表测试数据点的特征，*α*
    是显著性水平 *(α* ∈ *[0, 1])*。如果以下条件成立，则符合性预测器是有效的：
- en: P(Y ∈ I(x, α)) ≥ 1 – α
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: P(Y ∈ I(x, α)) ≥ 1 – α
- en: This condition states that the probability that the true target value *Y* is
    within the prediction interval *I(x, α)* is at least *(1−α)* for any given input
    data point *x*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此条件表明，对于任何给定的输入数据点 *x*，真实目标值 *Y* 在预测区间 *I(x, α)* 内的概率至少为 *(1−α)*。
- en: Validity in conformal prediction is closely related to the calibration concept
    in probabilistic prediction. A calibrated predictor generates prediction intervals
    with the correct coverage probability, ensuring that the uncertainty estimates
    it provides are well aligned with the true underlying uncertainty in the data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 符合性预测中的有效性与概率预测中的校准概念密切相关。校准预测器生成的预测区间具有正确的覆盖概率，确保它提供的不确定性估计与数据中的真实潜在不确定性良好对齐。
- en: It is important to note that validity in conformal prediction is guaranteed
    under the assumption of exchangeability, which requires that the observed data
    points are exchangeable with future, unseen data points. This assumption holds
    for **independent and identically distributed** (**IID**) data. In addition, successful
    modifications of conformal prediction have been developed to address non-exchangeable
    data, including many successful models for time series.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的一点是，在可交换性的假设下，符合性预测的有效性是有保证的，这要求观察到的数据点可以与未来的、未见过的数据点交换。对于 **独立同分布**（**IID**）数据，这个假设是成立的。此外，已经开发出成功的符合性预测修改方法来处理不可交换的数据，包括许多针对时间序列的成功模型。
- en: Classifier calibration
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类器校准
- en: Classifier calibration ensures that the predicted probabilities of an event
    match the true probabilities or frequencies of that event occurring. For example,
    in weather forecasting, calibration ensures that the forecasted probability of
    rain aligns with the actual occurrence of rain over a series of predictions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器校准确保预测事件的概率与该事件发生的真实概率或频率相匹配。例如，在天气预报中，校准确保预测的降雨概率与一系列预测中实际降雨的发生相一致。
- en: The concept of classifier calibration has been applied to weather forecasting
    since the 1950s, pioneered by Glen Brier. In the case of rain forecasting, a forecaster
    might declare an 80% chance of rain. If, on average, rain occurs 60% of the time
    following such statements, we consider the forecast well calibrated.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器校准的概念自20世纪50年代以来就被应用于天气预报，由Glen Brier开创。在降雨预测的情况下，预报员可能会宣布有80%的降雨概率。如果平均而言，在这样的话语之后，降雨发生60%的时间，我们认为这样的预测校准良好。
- en: Let’s consider a weather forecaster who makes a statement that there is an *x*%
    chance of rain for a particular day. To assess the calibration of the forecaster’s
    predictions, we would collect a series of similar predictions along with their
    corresponding outcomes (whether it rained or not). For example, suppose we gather
    100 instances in which the forecaster predicted a 60% chance of rain. If the forecaster’s
    predictions are well calibrated, it should rain on approximately 60 of those 100
    days, resulting in an observed frequency of rain that matches the predicted probability.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一位天气预报员，他声称某一天有 *x*% 的降雨概率。为了评估预报员预测的校准，我们会收集一系列类似的预测及其相应的结果（是否下雨）。例如，假设我们收集了100个实例，预报员预测了60%的降雨概率。如果预报员的预测校准良好，那么大约会有60天下雨，从而使得观察到的降雨频率与预测的概率相匹配。
- en: But what would this mean in practice? Let’s consider an example to understand
    this concept better.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 但这在实践中意味着什么呢？让我们通过一个例子来更好地理解这个概念。
- en: 'Suppose, over time, a weather forecaster made 10 predictions of an *x*% chance
    of rain. In the following table, we show these forecasts and the actual outcome:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 假设，随着时间的推移，一位天气预报员做出了10次关于有 *x*% 降雨概率的预测。在下表中，我们展示了这些预测和实际结果：
- en: '| **Day** | **Forecasted probability** **of rain** | **Actual** **outcome (rain)**
    |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| **日期** | **预测降雨** **概率** | **实际** **结果（降雨）** |'
- en: '| 1 | 80% | Yes |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 80% | 是 |'
- en: '| 2 | 60% | No |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 60% | 否 |'
- en: '| 3 | 90% | Yes |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 90% | 是 |'
- en: '| 4 | 30% | No |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 30% | 否 |'
- en: '| 5 | 70% | Yes |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 70% | 是 |'
- en: '| 6 | 50% | No |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 50% | 否 |'
- en: '| 7 | 80% | Yes |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 80% | 是 |'
- en: '| 8 | 20% | No |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 20% | 否 |'
- en: '| 9 | 40% | Yes |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 40% | 是 |'
- en: '| 10 | 60% | Yes |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 60% | 是 |'
- en: Table 4.1 – Forecasted probability of rain versus actual outcome
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.1 – 预测降雨概率与实际结果对比
- en: To determine whether this forecast is well calibrated, we need to compare the
    forecasted rain probabilities with the actual outcomes for each probability level.
    We can group the forecasts by their probability levels and calculate the observed
    frequency of rain for each group.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定这个预测是否校准良好，我们需要比较每个概率水平下的预测降雨概率与实际结果。我们可以按概率水平分组预测，并计算每个组的降雨观察频率。
- en: '| **Chance** **of rain** | 20% | 30% | 40% | 50% | 60% | 70% | 80% | 90% |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| **降雨** **概率** | 20% | 30% | 40% | 50% | 60% | 70% | 80% | 90% |'
- en: '| **Predicted** | 1 day | 1 day | 1 day | 1 day | 2 days | 1 day | 2 days |
    1 day |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| **预测** | 1 天 | 1 天 | 1 天 | 1 天 | 2 天 | 1 天 | 2 天 | 1 天 |'
- en: '| **Rained** | 0 days | 0 days | 1 day | 0 days | 1 day | 1 day | 2 days |
    1 day |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| **降雨** | 0 天 | 0 天 | 1 天 | 0 天 | 1 天 | 1 天 | 2 天 | 1 天 |'
- en: '| **Observed** **frequency** | 0% | 0% | 100% | 0% | 50% | 100% | 100% | 100%
    |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| **观察** **频率** | 0% | 0% | 100% | 0% | 50% | 100% | 100% | 100% |'
- en: Table 4.2 – Forecasted probability of rain versus observed frequency
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.2 – 预测降雨概率与观察频率对比
- en: Based on the observed frequencies, we can see that the forecast is not well
    calibrated. The observed frequencies do not align with the forecasted probabilities
    for most probability levels. For example, on the two days with a 60% chance of
    rain, it only rained once (50% of the predicted frequency), and on the day with
    a 50% chance of rain, it didn’t rain at all (0% the predicted frequency).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 根据观察频率，我们可以看到预测并未校准良好。观察频率与大多数概率水平的预测概率不一致。例如，在两个有 60% 降雨概率的日子里，只下了雨一次（预测频率的
    50%），而在有 50% 降雨概率的日子里，一点雨都没下（预测频率的 0%）。
- en: How can we aggregate these results into certain metrics? We could use the **Brier
    score**, which we encountered in previous chapters. The Brier score is a commonly
    used calibration metric for binary classification problems.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何将这些结果汇总成某些指标？我们可以使用**Brier 分数**，这是我们之前章节中遇到的。Brier 分数是二分类问题中常用的校准指标。
- en: 'Recall that the Brier score is calculated as the mean squared difference between
    the predicted probabilities and the true binary outcomes (0 or 1):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，Brier 分数是预测概率与真实二元结果（0 或 1）之间平均平方差的计算：
- en: Brier score = (1 / N) ∑ (prediction _ i − outcome _ i) ^ 2
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Brier 分数 = (1 / N) ∑ (prediction_i - outcome_i)^2
- en: where *N* is the number of predictions, *prediction_i* is the predicted probability
    for the *i*-th instance, and *outcome_i* is the true binary outcome for the *i*-th
    instance (1 for rain, 0 for no rain).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *N* 是预测次数，*prediction_i* 是第 *i* 次实例的预测概率，*outcome_i* 是第 *i* 次实例的真实二元结果（降雨为1，无降雨为0）。
- en: 'Now we can compute the Brier score:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以计算 Brier 分数：
- en: Brier score = (1 / 10) * (0.04 + 0.36 + 0.01 + 0.09 + 0.09 + 0.25 + 0.04 + 0.04
    + 0.36 + 0.16) = 0.144
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Brier 分数 = (1 / 10) * (0.04 + 0.36 + 0.01 + 0.09 + 0.09 + 0.25 + 0.04 + 0.04
    + 0.36 + 0.16) = 0.144
- en: A lower Brier score indicates better model performance and, consequently, better
    calibration. However, with a reference or comparison to other models, it is easier
    to determine whether a Brier score of 0.144 is good or not. Additionally, it is
    important to remember that this assessment is based on a limited sample size of
    only 10 days, which may not provide an accurate representation of the forecast’s
    calibration over a longer period.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 较低的 Brier 分数表示更好的模型性能和，因此，更好的校准。然而，与其他模型进行比较或参考，更容易确定 Brier 分数为 0.144 是否良好。此外，重要的是要记住，这种评估仅基于只有
    10 天的有限样本量，这可能无法准确代表预报在更长时期内的校准。
- en: We can also create a calibration diagram, also known as a reliability diagram,
    to assess the calibration of probabilistic prediction models. The diagram plots
    the predicted probabilities (grouped into bins) on the *x* axis against the observed
    frequencies of the event on the *y* axis. A well-calibrated model would have points
    along the diagonal (45-degree angle), indicating that the predicted probabilities
    match the observed frequencies.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以创建一个校准图，也称为可靠性图，以评估概率预测模型的校准。该图在 *x* 轴上绘制预测概率（分组到不同的区间），在 *y* 轴上绘制事件的观察频率。一个校准良好的模型将沿对角线（45度角）有多个点，这表明预测概率与观察到的频率相匹配。
- en: As we can see from *Table 4.2*, the forecast is not well calibrated. The observed
    frequencies do not match the forecasted probabilities for most probability levels.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们从 *表4.2* 中可以看到，预测并没有很好地校准。观察到的频率与大多数概率水平上的预测概率不匹配。
- en: 'There are two types of miscalibration: *underconfidence* and *overconfidence*.
    When a classifier exhibits underconfidence, it underestimates its ability to distinguish
    between classes, performing better in practice than its predictions suggest. In
    contrast, an overconfident classifier overestimates its capacity to separate classes,
    performing worse than its predicted probabilities imply.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 存在两种类型的校准错误：*信心不足*和*信心过强*。当一个分类器表现出信心不足时，它会低估其区分类别的能力，在实际表现上比其预测更好。相反，一个信心过强的分类器会高估其分离类别的能力，其表现比预测的概率更差。
- en: Another metric that can be used to evaluate calibration is log loss, also known
    as logarithmic loss or cross-entropy, which is a metric used to evaluate the performance
    of classification models that produce probability estimates for each class. It
    measures the divergence between the true and predicted probability distributions,
    penalizing incorrect and uncertain predictions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 可以用来评估校准的另一个指标是对数损失，也称为对数损失或交叉熵，它是一种用于评估产生每个类别概率估计的分类模型性能的指标。它衡量真实和预测概率分布之间的差异，对错误和不准确的预测进行惩罚。
- en: The concept of log loss is based on the idea that a classifier should not only
    predict the correct class but also be confident in its prediction. Log loss quantifies
    the uncertainty in the predicted probabilities by comparing them with the actual
    outcomes.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对数损失的概念基于这样一个想法，即分类器不仅应该预测正确的类别，而且对其预测应该有信心。对数损失通过对预测概率与实际结果进行比较来量化预测概率的不确定性。
- en: 'For binary classification, log loss is defined as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二元分类，对数损失定义为以下：
- en: Log loss = − (y * log(p) + (1 − y) * log(1 − p))
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对数损失 = − (y * log(p) + (1 − y) * log(1 − p))
- en: In this scenario, *y* stands for the true class label, which can be either 0
    or 1\. The symbol *p* signifies the predicted probability for the positive class
    (class 1). The term *log* indicates the natural logarithm. The log loss is calculated
    for each instance and then averaged across all instances to obtain the final log
    loss value.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，*y* 代表真实类别标签，可以是0或1。符号 *p* 表示对正类（类别1）的预测概率。术语 *log* 表示自然对数。对数损失是对每个实例进行计算，然后对所有实例进行平均，以获得最终的对数损失值。
- en: In a calibration context, log loss can be used to assess how well the predicted
    probabilities match the true outcomes. A well-calibrated model will have a lower
    log loss, as the predicted probabilities will be closer to the actual class labels.
    Conversely, a poorly calibrated model will have a higher log loss, indicating
    a discrepancy between the predicted probabilities and the true outcomes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在校准的上下文中，对数损失可以用来评估预测概率与真实结果匹配得有多好。一个校准良好的模型将具有较低的对数损失，因为预测概率将更接近实际的类别标签。相反，一个校准不良的模型将具有较高的对数损失，这表明预测概率与真实结果之间存在差异。
- en: It is important to note that log loss alone might not be sufficient to assess
    calibration, as it also depends on the classification accuracy. However, when
    used in conjunction with other metrics, such as calibration diagrams, log loss
    can provide valuable insights into the calibration of a classification model.
    In practice, log loss is often used alongside the Brier score to evaluate a model’s
    calibration. When both metrics agree on the relative calibration of two models,
    this provides stronger evidence than relying on a single calibration metric, such
    as log loss or Brier loss, alone. A more comprehensive assessment of a model’s
    calibration can be achieved by considering both metrics.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，仅对数损失本身可能不足以评估校准，因为它还取决于分类精度。然而，当与其他指标结合使用时，如校准图，对数损失可以提供关于分类模型校准的有价值见解。在实践中，对数损失通常与Brier分数一起使用来评估模型的校准。当这两个指标在两个模型的相对校准上达成一致时，这比仅依赖单个校准指标（如对数损失或Brier损失）提供了更强的证据。通过考虑这两个指标，可以更全面地评估模型的校准。
- en: Recall the rain prediction example from earlier.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下之前提到的降雨预测示例。
- en: 'To calculate the log loss for this example, we will use this formula:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算此例的对数损失，我们将使用这个公式：
- en: Log loss = − (y * log(p) + (1 − y) * log(1 − p))
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对数损失 = − (y * log(p) + (1 − y) * log(1 − p))
- en: Here, *y* is the true class label (0 or 1) and *p* is the predicted probability
    of the positive class (rain).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*y* 是真实的类别标签（0或1），而 *p* 是预测的正类概率（降雨）。
- en: 'Let’s compute the log loss for each day:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算每一天的对数损失：
- en: 'Day 1: (1 * log(0.8) + (1 - 1) * log(1 - 0.8)) = 0.223'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第1天：(1 * log(0.8) + (1 - 1) * log(1 - 0.8)) = 0.223
- en: 'Day 2: (0 * log(0.8) + (1 - 0) * log(1 - 0.8)) = 1.609'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第2天：(0 * log(0.8) + (1 - 0) * log(1 - 0.8)) = 1.609
- en: 'Day 3: (1 * log(0.6) + (1 - 1) * log(1 - 0.6)) = 0.511'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第3天：(1 * log(0.6) + (1 - 1) * log(1 - 0.6)) = 0.511
- en: 'Day 4: (1 * log(0.7) + (1 - 1) * log(1 - 0.7)) = 0.357'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第4天：(1 * log(0.7) + (1 - 1) * log(1 - 0.7)) = 0.357
- en: 'Day 5: (1 * log(0.9) + (1 - 1) * log(1 - 0.9)) = 0.105'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第5天：(1 * log(0.9) + (1 - 1) * log(1 - 0.9)) = 0.105
- en: 'Day 6: (0 * log(0.7) + (1 - 0) * log(1 - 0.7)) = 1.204'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第6天：(0 * log(0.7) + (1 - 0) * log(1 - 0.7)) = 1.204
- en: 'Day 7: (1 * log(0.6) + (1 - 1) * log(1 - 0.6)) = 0.511'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7天：(1 * log(0.6) + (1 - 1) * log(1 - 0.6)) = 0.511
- en: 'Day 8: (1 * log(0.5) + (1 - 1) * log(1 - 0.5)) = 0.693'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第8天：(1 * log(0.5) + (1 - 1) * log(1 - 0.5)) = 0.693
- en: 'Day 9: (0 * log(0.6) + (1 - 0) * log(1 - 0.6)) = 0.916'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9天：(0 * log(0.6) + (1 - 0) * log(1 - 0.6)) = 0.916
- en: 'Day 10: (0 * log(0.4) + (1 - 0) * log(1 - 0.4)) = 0.511'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10天：(0 * log(0.4) + (1 - 0) * log(1 - 0.4)) = 0.511
- en: 'Now, we can compute the average log loss across all 10 days:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以计算10天内的平均对数损失：
- en: Average log loss = (0.223 + 1.609 + 0.511 + 0.357 + 0.105 + 1.204 + 0.511 +
    0.693 + 0.916 + 0.511) / 10 ≈ 0.664
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 平均对数损失 = (0.223 + 1.609 + 0.511 + 0.357 + 0.105 + 1.204 + 0.511 + 0.693 + 0.916
    + 0.511) / 10 ≈ 0.664
- en: The average log loss for this rain prediction example is approximately 0.664.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此降雨预测示例的平均对数损失约为0.664。
- en: 'A question naturally arises: of statistical, machine, and deep learning, which
    are well calibrated and which are not?'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一个自然而然的问题：在统计学习、机器学习和深度学习中，哪些是校准良好的，哪些不是？
- en: As a general guideline, it is important to remember that most machine learning
    models are miscalibrated to some extent, with varying degrees of severity. However,
    logistic regression has its own limitations and may only be suitable for some
    applications due to its relatively simpler modeling capacity.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一般准则，重要的是要记住，大多数机器学习模型在某种程度上都存在校准不当，严重程度不同。然而，逻辑回归有其局限性，可能只适用于某些应用，因为其建模能力相对简单。
- en: A classical study of calibration is the paper *Predicting Good Probabilities
    With Supervised Learning (**2005):* [https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf](https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf)
    which examined the calibration properties of various supervised classification
    algorithms. The paper found that maximum margins, such as support vector machines
    and boosted trees, produced miscalibrated class scores and tended to push predictions
    close to 0 and 1, while other methods, such as naïve Bayes, pushed predictions
    in the other directions.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关于校准的经典研究是论文 *Predicting Good Probabilities With Supervised Learning (2005):*
    [https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf](https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf)，该论文研究了各种监督分类算法的校准特性。研究发现，最大边缘，如支持向量机和提升树，产生了校准不当的类别得分，并且倾向于将预测值推向0和1，而其他方法，如朴素贝叶斯，则将预测值推向相反方向。
- en: While it was initially thought that simple neural networks produced calibrated
    predictions, this conclusion has since been reevaluated. In a more recent paper
    titled *Are Traditional Neural Networks Well-Calibrated?* ([https://ieeexplore.ieee.org/document/8851962](https://ieeexplore.ieee.org/document/8851962)),
    the authors showed that individual multilayer perceptrons, as well as ensembles
    of multilayer perceptrons, frequently display poor calibration.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然最初认为简单的神经网络会产生校准预测，但这种结论后来被重新评估。在一篇题为《传统神经网络是否校准良好？》的更近期的论文中（[https://ieeexplore.ieee.org/document/8851962](https://ieeexplore.ieee.org/document/8851962)），作者们表明，单个多层感知器以及多层感知器的集成，经常显示出校准不良。
- en: The efficiency of probabilistic predictors
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概率预测器的效率
- en: Efficiency is a performance metric used to evaluate probabilistic predictors.
    It measures how precise or informative the prediction intervals or regions are.
    In other words, efficiency indicates how tight or narrow the predicted probability
    distributions are. Smaller intervals or regions are considered more efficient,
    as they convey more certainty about the predicted outcomes.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 效率是一个用于评估概率预测器的性能指标。它衡量预测区间或区域有多精确或信息量有多大。换句话说，效率表明预测的概率分布有多紧密或狭窄。更小的区间或区域被认为是更高效的，因为它们传达了关于预测结果的更多确定性。
- en: While validity focuses on ensuring that the error rate is controlled, efficiency
    assesses the usefulness and precision of the predictions. An efficient predictor
    provides more specific information about the possible outcomes, whereas a less
    efficient predictor generates wider intervals or regions, resulting in less precise
    information.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当有效性关注于确保错误率得到控制时，效率则评估预测的有用性和精确度。一个高效的预测器提供了关于可能结果的更具体信息，而一个效率较低的预测器则生成更宽的区间或区域，导致信息不够精确。
- en: There is an inherent trade-off between validity and efficiency. A conformal
    predictor can always achieve perfect validity by outputting very wide prediction
    sets that encompass all possible outcomes. However, this lacks efficiency, as
    the predictions are too conservative and imprecise.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在有效性和效率之间存在固有的权衡。一致性预测器可以通过输出包含所有可能结果的非常宽的预测集来始终实现完美的有效性。然而，这缺乏效率，因为预测过于保守且不精确。
- en: On the other hand, a model can output very narrow, precise predictions but may
    fail on the validity criteria by making erroneous predictions more than the allowed
    threshold. This results from overconfidence and unreliable probability estimates.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，一个模型可以输出非常狭窄、精确的预测，但可能会因为错误预测超过允许的阈值而未能满足有效性标准。这源于过度自信和不可靠的概率估计。
- en: Ideally, a conformal predictor finds an optimal balance; the predictions are
    as tight as possible while still meeting the validity guarantee. This ensures
    accuracy and precision without being overly conservative or exceeding the error
    rate threshold.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，一致性预测器会找到一个最佳平衡点；预测尽可能紧密，同时仍然满足有效性保证。这确保了准确性和精确性，而不会过于保守或超过错误率阈值。
- en: 'In conformal prediction, efficiency is typically measured by evaluating the
    size of the prediction intervals or regions generated by the conformal predictor.
    Smaller intervals or regions are considered more efficient, as they provide more
    precise information about the possible outcomes. Here are a few common ways to
    measure efficiency in conformal prediction:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在一致性预测中，效率通常通过评估一致性预测器生成的预测区间或区域的大小来衡量。更小的区间或区域被认为是更高效的，因为它们提供了关于可能结果的更精确信息。以下是一些在一致性预测中衡量效率的常见方法：
- en: '**Prediction** **interval length**: For regression problems, the average length
    of the prediction intervals can be calculated by finding the difference between
    the upper and lower bounds of each interval and then averaging these differences
    across all instances. Smaller average lengths indicate higher efficiency.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测区间长度**：对于回归问题，可以通过找到每个区间的上下限之间的差异，然后对所有实例的平均这些差异来计算预测区间的平均长度。更小的平均长度表明更高的效率。'
- en: '**Prediction set size**: For classification problems, the size of the prediction
    sets can be evaluated. A smaller prediction set contains fewer class labels and
    is considered more efficient. One way to measure this is by computing the average
    size of the prediction sets across all instances. A lower average set size indicates
    better efficiency.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测集大小**：对于分类问题，可以评估预测集的大小。较小的预测集包含较少的类别标签，被认为是更高效的。一种衡量方法是计算所有实例的预测集的平均大小。较低的平均集大小表明更好的效率。'
- en: '**Coverage probability**: Coverage probability measures the proportion of true
    outcomes that fall within the prediction intervals or regions. While it is mainly
    used to evaluate the validity of conformal predictors, it can also provide insights
    into efficiency. A predictor with tight intervals or regions will have a higher
    coverage probability, indicating better efficiency.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**覆盖率概率**：覆盖率概率衡量了真实结果落在预测区间或区域内的比例。虽然它主要用于评估一致性预测器的有效性，但它也可以提供关于效率的见解。具有紧密区间或区域的预测器将具有更高的覆盖率概率，这表明更好的效率。'
- en: '**P-value histograms**: In conformal prediction, p-values are calculated for
    each instance and class label. Examining the distribution of p-values can provide
    insights into efficiency. A uniform distribution of p-values suggests that the
    predictor is valid but not necessarily efficient, while a more concentrated distribution
    (e.g., with p-values close to 0 or 1) implies greater efficiency.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P值直方图**：在一致性预测中，为每个实例和类别标签计算p值。检查p值的分布可以提供关于效率的见解。p值的均匀分布表明预测器是有效的，但并不一定高效，而更集中的分布（例如，p值接近0或1）则意味着更高的效率。'
- en: We have already seen in the previous chapters how conformal prediction guarantees
    the automatic validity of prediction sets by constructing prediction intervals
    (for regression) or prediction sets (for classification) that come with a guaranteed
    error rate, which is determined by a user-defined confidence level. The key idea
    behind conformal prediction is to use past data and the observed behavior of a
    given machine learning model to estimate the uncertainty in its predictions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们已经看到一致性预测如何通过构建带有保证错误率的预测区间（用于回归）或预测集（用于分类）来保证预测集的自动有效性，该错误率由用户定义的置信水平确定。一致性预测背后的关键思想是利用过去数据和给定机器学习模型的观察行为来估计其预测的不确定性。
- en: 'Let’s recap the stages in **inductive conformal prediction,** which consists
    of two main phases: the calibration phase and the prediction phase. Here’s an
    outline of how it works:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下**归纳一致性预测**的阶段，它包括两个主要阶段：校准阶段和预测阶段。以下是其工作原理的概述：
- en: '**Calibration phase**: In this phase, a machine learning model is trained on
    a dataset, and a nonconformity measure is calculated for each instance in the
    dataset. The nonconformity measure quantifies the strangeness or atypicality of
    an instance with respect to the rest of the data.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**校准阶段**：在这个阶段，机器学习模型在数据集上训练，并为数据集中的每个实例计算非一致性度量。非一致性度量量化了实例相对于其余数据的不寻常性或异常性。'
- en: '**Prediction phase**: When a new instance needs to be predicted, the nonconformity
    measure, for instance, is calculated using the same nonconformity measure function
    used in the calibration phase. The instance’s nonconformity score is then compared
    to the nonconformity scores of the calibration instances. A p-value is computed
    for each possible outcome, reflecting the proportion of calibration instances
    with nonconformity scores higher than or equal to that of the new instance. The
    p-values can be interpreted as a measure of how likely it is for the instance
    to belong to each class (for classification) or to fall within a certain range
    (for regression).'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测阶段**：当需要预测新实例时，使用与校准阶段相同的非一致性度量函数计算非一致性度量。然后，将实例的非一致性得分与校准实例的非一致性得分进行比较。为每个可能的输出计算p值，反映具有高于或等于新实例非一致性得分的校准实例的比例。p值可以解释为实例属于每个类别（用于分类）或落在某个范围（用于回归）的可能性度量。'
- en: '**Prediction intervals or sets**: Based on the computed p-values and the user-defined
    confidence level, prediction intervals (for regression) or prediction sets (for
    classification) are constructed. These intervals or sets are guaranteed to contain
    the true outcome with a probability equal to the chosen confidence level. For
    instance, if the confidence level is set to 0.95, the true outcome will fall within
    the prediction interval or set 95% of the time.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测区间或集合**：基于计算出的p值和用户定义的置信水平，构建预测区间（用于回归）或预测集合（用于分类）。这些区间或集合保证以等于所选置信水平的概率包含真实结果。例如，如果置信水平设置为0.95，则真实结果将有95%的时间落在预测区间或集合内。'
- en: By ensuring that the prediction intervals or sets contain the true outcomes
    with the desired probability, conformal prediction provides automatic validity
    for predictions. It is worth noting that while conformal prediction guarantees
    validity, it does not necessarily guarantee efficiency, which depends on the precision
    of the prediction intervals or sets.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 通过确保预测区间或集合以所需的概率包含真实结果，一致性预测为预测提供了自动的有效性。值得注意的是，虽然一致性预测保证了有效性，但它并不一定保证效率，这取决于预测区间或集合的精度。
- en: In [*Chapter 4*](B19925_04.xhtml#_idTextAnchor040), we will look at and learn
    about different types of conformal prediction with practical examples.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第4章*](B19925_04.xhtml#_idTextAnchor040)中，我们将通过实际例子了解和学习不同类型的一致性预测。
- en: Summary
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have deep-dived into the concepts of validity and efficiency
    in the context of probabilistic prediction models, building upon the foundations
    laid in the previous chapters. We have looked at the definitions of validity and
    efficiency and learned about various metrics that can be used to evaluate and
    compare different models in terms of validity and efficiency.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入探讨了概率预测模型中的有效性和效率的概念，基于前几章奠定的基础。我们研究了有效性和效率的定义，并了解了可以用来评估和比较不同模型有效性和效率的各种指标。
- en: In the next chapter, we will learn about different families of conformal predictors
    and explore various approaches to quantifying uncertainty.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习不同类型的一致性预测，并探讨量化不确定性的各种方法。
