- en: Chapter 5. Transforming Images with Morphological Operations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章 使用形态学操作转换图像
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下配方：
- en: Eroding and dilating images using morphological filters
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用形态学过滤器腐蚀和膨胀图像
- en: Opening and closing images using morphological filters
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用形态学过滤器打开和关闭图像
- en: Detecting edges and corners using morphological filters
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用形态学过滤器检测边缘和角
- en: Segmenting images using watersheds
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分水岭分割图像
- en: Extracting distinctive regions using MSER
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MSER提取特征区域
- en: Extracting foreground objects with the GrabCut algorithm
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GrabCut算法提取前景对象
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: '**Mathematical morphology** is a theory that was developed in the 1960s for
    the analysis and processing of discrete images. It defines a series of operators
    that transform an image by probing it with a predefined shape element. The way
    this shape element intersects the neighborhood of a pixel determines the result
    of the operation. This chapter presents the most important morphological operators.
    It also explores the problems of image segmentation and feature detection using
    algorithms based on morphological operators.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**数学形态学**是20世纪60年代为分析和处理离散图像而开发的一种理论。它定义了一系列通过使用预定义的形状元素探测图像来转换图像的算子。这个形状元素与像素邻域的交集方式决定了操作的结果。本章介绍了最重要的形态学算子。它还探讨了使用基于形态学算子的算法进行图像分割和特征检测的问题。'
- en: Eroding and dilating images using morphological filters
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用形态学过滤器腐蚀和膨胀图像
- en: 'Erosion and dilation are the most fundamental morphological operators. Therefore,
    we will present these in the first recipe. The fundamental component in mathematical
    morphology is the **structuring element**. A structuring element can be simply
    defined as a configuration of pixels (the square shape in the following figure)
    on which an origin is defined (also called an **anchor point**). Applying a morphological
    filter consists of probing each pixel of the image using this structuring element.
    When the origin of the structuring element is aligned with a given pixel, its
    intersection with the image defines a set of pixels on which a particular morphological
    operation is applied (the nine shaded pixels in the following figure). In principle,
    the structuring element can be of any shape, but most often, a simple shape such
    as a square, circle, or diamond with the origin at the center is used (mainly
    for efficiency reasons), as shown in the following figure:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 腐蚀和膨胀是最基本的形态学算子。因此，我们将首先介绍这些算子。数学形态学的基本组成部分是**结构元素**。结构元素可以简单地定义为定义了原点（也称为**锚点**）的像素配置（以下图中的正方形形状）。应用形态学过滤器包括使用这个结构元素探测图像中的每个像素。当结构元素的原点与给定的像素对齐时，它与图像的交集定义了一个特定形态学操作应用的像素集（以下图中的九个阴影像素）。原则上，结构元素可以是任何形状，但最常见的是使用具有原点在中心的简单形状，如正方形、圆形或菱形（主要是为了效率原因），如下所示：
- en: '![Eroding and dilating images using morphological filters](img/00050.jpeg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![使用形态学过滤器腐蚀和膨胀图像](img/00050.jpeg)'
- en: Getting ready
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: As morphological filters often work on binary images, we will use the binary
    image that was created through thresholding in the first recipe of the previous
    chapter. However, since the convention is to have the foreground objects represented
    by high (white) pixel values and the background objects by low (black) pixel values
    in morphology, we have negated the image.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由于形态学过滤器通常在二值图像上工作，我们将使用上一章第一个配方中通过阈值创建的二值图像。然而，由于在形态学中，惯例是用高（白色）像素值表示前景对象，用低（黑色）像素值表示背景对象，因此我们已对图像进行了取反。
- en: 'In morphological terms, the following image is said to be the complement of
    the image that was created in the previous chapter:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在形态学术语中，以下图像被认为是上一章创建的图像的补集：
- en: '![Getting ready](img/00051.jpeg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](img/00051.jpeg)'
- en: How to do it...
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Erosion and dilation are implemented in OpenCV as simple functions, which are
    `cv::erode` and `cv::dilate`. Their usage is straightforward:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 腐蚀和膨胀在OpenCV中作为简单的函数实现，分别是`cv::erode`和`cv::dilate`。它们的用法简单直接：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The two images produced by these function calls are seen in the following screenshots.
    The first screenshot shows erosion:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了这些函数调用产生的两个图像。第一个屏幕截图显示了腐蚀：
- en: '![How to do it...](img/00052.jpeg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/00052.jpeg)'
- en: 'The second screenshot shows the dilation result:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个屏幕截图显示了膨胀的结果：
- en: '![How to do it...](img/00053.jpeg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/00053.jpeg)'
- en: How it works...
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何工作...
- en: As with all the other morphological filters, the two filters of this recipe
    operate on the set of pixels (or the neighborhood) around each pixel as defined
    by the structuring element. Recall that when applied to a given pixel, the anchor
    point of the structuring element is aligned with this pixel location, and all
    the pixels that intersect the structuring element are included in the current
    set. **Erosion** replaces the current pixel with the minimum pixel value found
    in the defined pixel set. **Dilation** is the complementary operator, and it replaces
    the current pixel with the maximum pixel value found in the defined pixel set.
    Since the input binary image contains only black (`0`) and white (`255`) pixels,
    each pixel is replaced by either a white or black pixel.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有其他形态学过滤器一样，这个菜谱中的两个过滤器都是根据结构元素定义的每个像素（或邻域）的像素集（或邻域）进行操作的。回想一下，当应用于某个像素时，结构元素的锚点与该像素位置对齐，并且所有与结构元素相交的像素都包含在当前集合中。**腐蚀**用在定义的像素集中找到的最小像素值替换当前像素。**膨胀**是互补操作，它用在定义的像素集中找到的最大像素值替换当前像素。由于输入的二值图像只包含黑色（`0`）和白色（`255`）像素，每个像素要么被替换为白色像素，要么被替换为黑色像素。
- en: 'A good way to picturize the effect of these two operators is to think in terms
    of background (black) and foreground (white) objects. With erosion, if the structuring
    element when placed at a given pixel location touches the background (that is,
    one of the pixels in the intersecting set is black), then this pixel will be sent
    to the background. In the case of dilation, if the structuring element on a background
    pixel touches a foreground object, then this pixel will be assigned a white value.
    This explains why the size of the objects has been reduced (the shape has been
    eroded) in the eroded image. Note how some of the small objects (which can be
    considered as "noisy" background pixels) have also been completely eliminated.
    Similarly, the dilated objects are now larger, and some of the "holes" inside
    them have been filled. By default, OpenCV uses a 3 x 3 square structuring element.
    This default structuring element is obtained when an empty matrix (that is, `cv::Mat()`)
    is specified as the third argument in the function call, as it was done in the
    preceding example. You can also specify a structuring element of the size (and
    shape) you want by providing a matrix in which the nonzero element defines the
    structuring element. In the following example, a 7 x 7 structuring element is
    applied:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 将这两个算子的效果形象化的一种好方法是考虑背景（黑色）和前景（白色）对象。在腐蚀过程中，如果结构元素放置在某个像素位置时接触到背景（即，交集中的一组像素是黑色），那么这个像素将被发送到背景。在膨胀的情况下，如果结构元素在背景像素上接触到前景对象，那么这个像素将被赋予白色值。这解释了为什么腐蚀图像中对象的大小已经减小（形状已经被腐蚀）。注意，一些小对象（可以被认为是“噪声”背景像素）也被完全消除了。同样，膨胀的对象现在更大，它们内部的一些“空洞”也被填充了。默认情况下，OpenCV使用3
    x 3的正方形结构元素。当在函数调用中将空矩阵（即`cv::Mat()`）指定为第三个参数时，就得到了这个默认的结构元素，就像在先前的例子中那样。您也可以通过提供一个矩阵来指定您想要的（大小和形状）结构元素，其中非零元素定义了结构元素。在下面的例子中，应用了一个7
    x 7的结构元素：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The effect is much more destructive in this case, as shown in the following
    screenshot:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，效果要破坏性得多，如下面的截图所示：
- en: '![How it works...](img/00054.jpeg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00054.jpeg)'
- en: 'Another way to obtain the same result is to repetitively apply the same structuring
    element on an image. The two functions have an optional parameter to specify the
    number of repetitions:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 获得相同结果的另一种方法是重复应用相同的结构元素到图像上。这两个函数有一个可选参数可以指定重复的次数：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The argument `cv::Point(-1,-1)` means that the origin is at the center of the
    matrix (default); it can be defined anywhere on the structuring element. The image
    that is obtained will be identical to the image we obtained with the 7 x 7 structuring
    element. Indeed, eroding an image twice is similar to eroding an image with a
    structuring element dilated with itself. This also applies to dilation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 参数`cv::Point(-1,-1)`表示原点位于矩阵的中心（默认）；它可以在结构元素的任何位置定义。得到的图像将与使用7 x 7结构元素得到的图像相同。实际上，腐蚀图像两次与腐蚀一个自身膨胀的结构元素相同。这也适用于膨胀。
- en: 'Finally, since the notion of background/foreground is arbitrary, we can make
    the following observation (which is a fundamental property of the erosion/dilation
    operators). Eroding the foreground objects with a structuring element can be seen
    as a dilation of the background part of the image. In other words, we can make
    the following observations:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于背景/前景的概念是任意的，我们可以做出以下观察（这是腐蚀/膨胀算子的基本属性）。使用结构元素腐蚀前景对象可以看作是图像背景部分的膨胀。换句话说，我们可以得出以下结论：
- en: The erosion of an image is equivalent to the complement of the dilation of the
    complement image
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像的腐蚀等同于补图像膨胀的补集
- en: The dilation of an image is equivalent to the complement of the erosion of the
    complement image
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像的膨胀等同于补图像腐蚀的补集
- en: There's more...
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多...
- en: Note that even though we applied our morphological filters on binary images
    here, these filters can be applied on gray-level or even color images with the
    same definitions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，尽管我们在这里对二值图像应用了形态学滤波器，但这些滤波器也可以用相同的定义应用于灰度图像甚至彩色图像。
- en: 'Also, note that the OpenCV morphological functions support in-place processing.
    This means that you can use the input image as the destination image, as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意，OpenCV的形态学函数支持就地处理。这意味着您可以使用输入图像作为目标图像，如下所示：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: OpenCV will create the required temporary image for you for this to work properly.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV会为您创建所需的临时图像，以确保其正常工作。
- en: See also
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Opening and closing images using morphological filters* recipe applies
    the erosion and dilation filters in cascade to produce new operators
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用形态学滤波器进行图像的开放和闭合*菜谱将腐蚀和膨胀滤波器级联应用以产生新的算子'
- en: The *Detecting edges and corners using morphological filters* recipe applies
    morphological filters on gray-level images
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用形态学滤波器检测边缘和角点*菜谱在灰度图像上应用形态学滤波器'
- en: Opening and closing images using morphological filters
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用形态学滤波器进行图像的开放和闭合
- en: 'The previous recipe introduced you to the two fundamental morphological operators:
    dilation and erosion. From these, other operators can be defined. The next two
    recipes will present some of them. The opening and closing operators are presented
    in this recipe.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 之前菜谱向您介绍了两个基本的形态学算子：膨胀和腐蚀。从这些算子中，可以定义其他算子。接下来的两个菜谱将介绍其中的一些。本菜谱中介绍了开放和闭合算子。
- en: How to do it...
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'In order to apply higher-level morphological filters, you need to use the `cv::morphologyEx`
    function with the appropriate function code. For example, the following call will
    apply the closing operator:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应用高级形态学滤波器，您需要使用带有适当功能代码的`cv::morphologyEx`函数。例如，以下调用将应用闭合算子：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Note that we used a 5 x 5 structuring element to make the effect of the filter
    more apparent. If we use the binary image of the preceding recipe as input, we
    will obtain an image similar to what''s shown in the following screenshot:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用了5 x 5的结构元素来使滤波器效果更加明显。如果我们使用前一道菜谱的二值图像作为输入，我们将获得类似于以下截图所示的图像：
- en: '![How to do it...](img/00055.jpeg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/00055.jpeg)'
- en: 'Similarly, applying the morphological opening operator will result in the following
    screenshot:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，应用形态学开放算子将产生以下截图：
- en: '![How to do it...](img/00056.jpeg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/00056.jpeg)'
- en: 'The preceding image is obtained from the following code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图像是通过以下代码获得的：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: How it works...
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The opening and closing filters are simply defined in terms of the basic erosion
    and dilation operations. **Closing** is defined as the erosion of the dilation
    of an image. **Opening** is defined as the dilation of the erosion of an image.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 开放和闭合滤波器只是用基本腐蚀和膨胀操作来定义的。**闭合**定义为图像膨胀的腐蚀。**开放**定义为图像腐蚀的膨胀。
- en: 'Consequently, one can compute the closing of an image using the following calls:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，可以使用以下调用计算图像的闭合：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The opening filter can be obtained by reverting these two function calls. While
    examining the result of the closing filter, it can be seen that the small holes
    of the white foreground objects have been filled. The filter also connects several
    adjacent objects together. Basically, any holes or gaps that are too small to
    completely contain the structuring element will be eliminated by the filter.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 开放滤波器可以通过反转这两个函数调用获得。在检查闭合滤波器的结果时，可以看到白色前景对象的小孔已被填充。该滤波器还连接了几个相邻的对象。基本上，任何太小而无法完全包含结构元素的孔洞或间隙都将被滤波器消除。
- en: Reciprocally, the opening filter eliminated several small objects from the scene.
    All the objects that were too small to contain the structuring element have been
    removed.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，开运算从场景中消除了几个小物体。所有太小以至于无法包含结构元素的物体都被移除了。
- en: These filters are often used in object detection. The closing filter connects
    the objects erroneously fragmented into smaller pieces together, while the opening
    filter removes the small blobs introduced by the image noise. Therefore, it is
    advantageous to use them in a sequence. If our test binary image is successively
    closed and opened, we obtain an image that shows only the main objects in the
    scene, as shown in the following screenshot. You can also apply the opening filter
    before the closing filter if you wish to prioritize noise filtering, but this
    will be at the price of eliminating some fragmented objects.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这些过滤器通常用于对象检测。闭运算将错误地分割成更小片段的物体连接起来，而开运算则移除由图像噪声引入的小块。因此，按顺序使用它们是有利的。如果我们连续地对测试二值图像进行闭运算和开运算，我们将获得一个只显示场景中主要物体的图像，如下面的截图所示。如果您希望优先进行噪声过滤，也可以在闭运算之前应用开运算，但这将以消除一些碎片化物体为代价。
- en: '![How it works...](img/00057.jpeg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![它如何工作...](img/00057.jpeg)'
- en: Note that applying the same opening (and similarly the closing) operator on
    an image several times has no effect. Indeed, as the holes have been filled by
    the first opening filter an additional application of the same filter will not
    produce any other changes to the image. In mathematical terms, these operators
    are said to be idempotent.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对图像多次应用相同的开运算（以及类似地，闭运算）没有任何效果。实际上，由于开运算已经通过填充孔洞，因此再次应用相同的过滤器不会对图像产生任何其他变化。从数学的角度来看，这些算子被称为幂等的。
- en: See also
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The opening and closing operators are often used to clean up an image before
    extracting its connected components as explained in the *Extracting the components'
    contours* recipe of [Chapter 7](part0052_split_000.html#page "Chapter 7. Extracting
    Lines, Contours, and Components"), *Extracting Lines, Contours, and Components*.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 开运算和闭运算算子通常用于在提取图像的连通组件之前清理图像，如第7章中“提取组件轮廓”菜谱所述，*提取线条、轮廓和组件*。
- en: Detecting edges and corners using morphological filters
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用形态学过滤器检测边缘和角
- en: Morphological filters can also be used to detect specific features in an image.
    In this recipe, we will learn how to detect contours and corners in a gray-level
    image.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 形态学过滤器也可以用于检测图像中的特定特征。在本菜谱中，我们将学习如何检测灰度图像中的轮廓和角。
- en: Getting ready
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'In this recipe, the following image will be used:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，将使用以下图像：
- en: '![Getting ready](img/00058.jpeg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](img/00058.jpeg)'
- en: How to do it...
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The edges of an image can be detected by using the appropriate filter of the
    `cv::morphologyEx` function. Refer to the following code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图像的边缘可以通过使用`cv::morphologyEx`函数的适当过滤器来检测。请参阅以下代码：
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following image is obtained as the result:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图像是结果：
- en: '![How to do it...](img/00059.jpeg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00059.jpeg)'
- en: 'In order to detect corners using morphology, we now define a class named `MorphoFeatures`
    as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用形态学检测角，我们现在定义一个名为`MorphoFeatures`的类，如下所示：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The detection of corners using morphological corners is a bit complex since
    it requires the successive application of several different morphological filters.
    This is a good example of the use of nonsquare structuring elements. Indeed, this
    requires four different structuring elements shaped as a square, diamond, cross,
    and X-shape to be defined in the constructor (all these structuring elements have
    a fixed 5 x 5 dimension for simplicity):'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用形态学角检测角检测稍微复杂一些，因为它需要连续应用几个不同的形态学过滤器。这是一个使用非正方形结构元素的很好例子。确实，这需要在构造函数中定义四个不同形状的结构元素，形状为正方形、菱形、十字形和X形（所有这些结构元素都具有固定的5
    x 5维以简化问题）：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the detection of corner features, all these structuring elements are applied
    in a cascade to obtain the resulting corner map:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测角特征时，所有这些结构元素都按级联方式应用，以获得最终的角图：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The corners are then detected on an image by using the following code:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用以下代码在图像上检测角：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the image, the detected corners are displayed as circles, as shown in the
    following screenshot:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像中，检测到的角以圆圈的形式显示，如下面的截图所示：
- en: '![How to do it...](img/00060.jpeg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00060.jpeg)'
- en: How it works...
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它如何工作...
- en: A good way to understand the effect of morphological operators on a gray-level
    image is to consider an image as a topological relief in which the gray levels
    correspond to elevation (or altitude). Under this perspective, the bright regions
    correspond to mountains, while the dark areas correspond to the valleys of the
    terrain. Also, since edges correspond to a rapid transition between the dark and
    bright pixels, these can be pictured as abrupt cliffs. If an erosion operator
    is applied on such a terrain, the net result will be to replace each pixel by
    the lowest value in a certain neighborhood, thus reducing its height. As a result,
    cliffs will be "eroded" as the valleys expand. Dilation has the exact opposite
    effect; that is, cliffs will gain terrain over the valleys. However, in both cases,
    the plateaux (that is, the area of constant intensity) will remain relatively
    unchanged.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解形态学算子对灰度图像的影响，可以将图像视为一个拓扑地形，其中灰度级别对应于高度（或海拔）。从这种角度来看，明亮区域对应于山脉，而暗区对应于地形的山谷。此外，由于边缘对应于暗亮像素之间的快速过渡，这些可以想象为陡峭的悬崖。如果在这种地面上应用腐蚀操作符，最终结果将是用一定邻域中的最低值替换每个像素，从而降低其高度。因此，随着山谷的扩张，悬崖将被“腐蚀”。相反，膨胀具有完全相反的效果；也就是说，悬崖将在山谷上方获得地形。然而，在这两种情况下，高原（即强度恒定的区域）将相对保持不变。
- en: These observations lead to a simple way to detect the edges (or cliffs) of an
    image. This can be done by computing the difference between the dilated and eroded
    images. Since these two transformed images differ mostly at the edge locations,
    the image edges will be emphasized by the subtraction. This is exactly what the
    `cv::morphologyEx` function does when the `cv::MORPH_GRADIENT` argument is inputted.
    Obviously, the larger the structuring element is, the thicker the detected edges
    will be. This edge detection operator is also called the **Beucher** gradient
    (the next chapter will discuss the concept of an image gradient in more detail).
    Note that similar results can also be obtained by simply subtracting the original
    image from the dilated one or the eroded image from the original. The resulting
    edges would be thinner.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这些观察结果导致了一种简单的方法来检测图像的边缘（或悬崖）。这可以通过计算膨胀图像和腐蚀图像之间的差异来实现。由于这两个转换图像主要在边缘位置不同，因此减法将强调图像边缘。这正是当输入`cv::MORPH_GRADIENT`参数时，`cv::morphologyEx`函数所做的事情。显然，结构元素越大，检测到的边缘就越粗。这个边缘检测操作符也被称为**Beucher**梯度（下一章将更详细地讨论图像梯度的概念）。请注意，通过简单地从原始图像减去膨胀图像或从原始图像减去腐蚀图像也可以获得类似的结果。得到的边缘会更细。
- en: 'Corner detection is a bit more complex since it uses four different structuring
    elements. This operator is not implemented in OpenCV, but we present it here to
    demonstrate how the structuring elements of various shapes can be defined and
    combined. The idea is to close the image by dilating and eroding it with two different
    structuring elements. These elements are chosen such that they leave straight
    edges unchanged, but because of their respective effects, the edges at corner
    points will be affected. Let''s use the simple following image made of a single
    white square to better understand the effect of this asymmetrical closing operation:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 角点检测稍微复杂一些，因为它使用了四个不同的结构元素。这个操作符在OpenCV中未实现，但我们在这里展示它是如何定义和组合各种形状的结构元素的。其思路是通过使用两个不同的结构元素对图像进行膨胀和腐蚀来封闭图像。这些元素被选择得使得它们不会改变直线边缘，但由于它们各自的效果，角点的边缘将会受到影响。让我们使用以下简单的由单个白色正方形组成的图像来更好地理解这种非对称封闭操作的效果：
- en: '![How it works...](img/00061.jpeg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00061.jpeg)'
- en: The first square is the original image. When dilated with a cross-shaped structuring
    element, the square edges expand, except at the corner points where the cross
    shape does not hit the square. This is the result illustrated by the square in
    the middle. This dilated image is then eroded by a structuring element that has
    a diamond shape. This erosion brings back most edges to their original position
    but pushes the corners even further since they were not dilated. The rightmost
    square is then obtained, which (as it can be seen) has lost its sharp corners.
    The same procedure is repeated with the X-shaped and square-shaped structuring
    elements. These two elements are the rotated versions of the previous elements
    and will consequently capture the corners at a 45-degree orientation. Finally,
    differencing the two results will extract the corner features.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个正方形是原始图像。当使用十字形结构元素膨胀时，正方形的边缘会扩展，除了在角点处，因为十字形没有接触到正方形。这是中间正方形所展示的结果。然后，使用具有菱形形状的结构元素对膨胀后的图像进行腐蚀。这种腐蚀将大多数边缘恢复到原始位置，但由于角点没有被膨胀，所以它们被推得更远。然后得到最右侧的正方形，它（如所见）已经失去了其锐利的角。使用X形和正方形结构元素重复相同的程序。这两个元素是先前元素的旋转版本，因此将捕捉到45度方向的角。最后，对这两个结果进行差分将提取角特征。
- en: See also
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: The *Applying directional filters to detect edges* recipe in [Chapter 6](part0047_split_000.html#page
    "Chapter 6. Filtering the Images"), *Filtering the Images* describes the other
    filters that perform edge detection
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第6章](part0047_split_000.html#page "第6章. 过滤图像")中的*应用方向滤波器以检测边缘*配方，*过滤图像*描述了执行边缘检测的其他滤波器。'
- en: '[Chapter 8](part0058_split_000.html#page "Chapter 8. Detecting Interest Points"),
    *Detecting Interest Points*, presents different operators that perform corner
    detection'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第8章](part0058_split_000.html#page "第8章. 检测兴趣点")，*检测兴趣点*，介绍了执行角点检测的不同算子。'
- en: The article, *The Morphological gradients*, *J.-F. Rivest, P. Soille, and S.
    Beucher, ISET's symposium on electronic imaging science and technology, SPIE,
    Feb. 1992*, discusses the concept of morphological gradients in more detail
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文章《形态梯度》，作者J.-F. Rivest, P. Soille, 和 S. Beucher，发表于1992年2月的ISET电子成像科学和技术研讨会，SPIE，详细讨论了形态梯度的概念。
- en: The article, *A modified regulated morphological corner detector*, *F.Y. Shih,
    C.-F. Chuang, and V. Gaddipati, Pattern Recognition Letters, volume 26, issue
    7, May 2005*, gives more information on morphological corner detection
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文章《改进的调节形态角点检测器》，作者F.Y. Shih, C.-F. Chuang, 和 V. Gaddipati，发表于2005年5月的《Pattern
    Recognition Letters》，第26卷第7期，提供了关于形态角点检测的更多信息。
- en: Segmenting images using watersheds
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用水印分割图像
- en: The watershed transformation is a popular image processing algorithm that is
    used to quickly segment an image into homogenous regions. It relies on the idea
    that when the image is seen as a topological relief, the homogeneous regions correspond
    to relatively flat basins delimited by steep edges. As a result of its simplicity,
    the original version of this algorithm tends to over-segment the image, which
    produces multiple small regions. This is why OpenCV proposes a variant of this
    algorithm that uses a set of predefined markers that guide the definition of the
    image segments.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 水印变换是一种流行的图像处理算法，用于快速将图像分割成同质区域。它基于这样的想法：当图像被视为拓扑起伏时，同质区域对应于相对平坦的盆地，这些盆地由陡峭的边缘所限定。由于其简单性，该算法的原始版本往往会过度分割图像，从而产生多个小区域。这就是为什么OpenCV提出了该算法的一个变体，该变体使用一组预定义的标记来引导图像段定义。
- en: How to do it...
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'The watershed segmentation is obtained through the use of the `cv::watershed`
    function. The input for this function is a 32-bit signed integer-marker image
    in which each nonzero pixel represents a label. The idea is to mark some pixels
    of the image that are known to belong to a given region. From this initial labeling,
    the watershed algorithm will determine the regions to which the other pixels belong.
    In this recipe, we will first create the marker image as a gray-level image and
    then convert it into an image of integers. We have conveniently encapsulated this
    step into a `WatershedSegmenter` class. Refer to the following code:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 水印分割是通过使用`cv::watershed`函数获得的。该函数的输入是一个32位有符号整数标记图像，其中每个非零像素代表一个标签。其想法是标记图像中已知属于某个区域的像素。从这个初始标记开始，水印算法将确定其他像素所属的区域。在这个配方中，我们首先创建标记图像作为灰度图像，然后将其转换为整数图像。我们方便地将这一步骤封装到`WatershedSegmenter`类中。请参考以下代码：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The way these markers are obtained depends on the application. For example,
    some preprocessing steps might have resulted in the identification of some pixels
    that belong to an object of interest. The watershed would then be used to delimitate
    the complete object from that initial detection. In this recipe, we will simply
    use the binary image used throughout this chapter in order to identify the animals
    of the corresponding original image (this is the image shown at the beginning
    of [Chapter 4](part0032_split_000.html#page "Chapter 4. Counting the Pixels with
    Histograms"), *Counting the Pixels with Histograms*). Therefore, from our binary
    image, we need to identify the pixels that belong to the foreground (the animals)
    and the pixels that belong to the background (mainly the grass). Here, we will
    mark the foreground pixels with the label `255` and the background pixels with
    the label `128` (this choice is totally arbitrary; any label number other than
    `255` will work). The other pixels, that is, the ones for which the labeling is
    unknown are assigned the value `0`.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这些标记的获取方式取决于应用。例如，一些预处理步骤可能导致了识别一些属于感兴趣对象的像素。然后使用水岭来从初始检测中界定整个对象。在本食谱中，我们将简单地使用本章中使用的二值图像来识别对应原始图像中的动物（这是在第
    [4章](part0032_split_000.html#page "第4章. 使用直方图计数像素")，*使用直方图计数像素*中显示的图像）。因此，从我们的二值图像中，我们需要识别属于前景（动物）的像素和属于背景（主要是草地）的像素。在这里，我们将前景像素标记为标签
    `255`，背景像素标记为标签 `128`（这种选择完全是任意的；除了 `255` 之外的其他标签数字也可以工作）。其他像素，即标签未知的那部分像素，被分配值为
    `0`。
- en: 'As of now, the binary image includes too many white pixels that belong to the
    various parts of the image. We will then severely erode this image in order to
    retain only the pixels that belong to the important objects:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，二值图像包含太多属于图像各个部分的白色像素。因此，我们将严重侵蚀此图像，仅保留属于重要对象的像素：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The result is the following image:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是以下图像：
- en: '![How to do it...](img/00062.jpeg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00062.jpeg)'
- en: 'Note that a few pixels that belong to the background (forest) are still present.
    Let''s keep them. Therefore, they will be considered to correspond to an object
    of interest. Similarly, we also select a few pixels of the background by a large
    dilation of the original binary image:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，仍然有一些属于背景（森林）的像素存在。让我们保留它们。因此，它们将被认为是对应于感兴趣对象的。同样，我们通过在原始二值图像上执行大膨胀来选择背景的几个像素：
- en: '[PRE14]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The resulting black pixels correspond to the background pixels. This is why
    the thresholding operation assigns the value `128` to these pixels immediately
    after the dilation. The following image is obtained:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的黑色像素对应于背景像素。这就是为什么阈值操作在膨胀之后立即将这些像素的值分配为 `128`。得到的图像如下：
- en: '![How to do it...](img/00063.jpeg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00063.jpeg)'
- en: 'These images are combined to form the marker image as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图像被组合成标记图像，如下所示：
- en: '[PRE15]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Note how we used the overloaded operator `+` here in order to combine the images.
    The following image will be used as the input to the watershed algorithm:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们在这里如何使用重载的运算符 `+` 来组合图像。以下图像将被用作水岭算法的输入：
- en: '![How to do it...](img/00064.jpeg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00064.jpeg)'
- en: 'In this input image, the white areas belong, for sure, to the foreground objects,
    the gray areas are a part of the background, and the black areas have an unknown
    label. The segmentation is then obtained as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个输入图像中，白色区域肯定属于前景对象，灰色区域是背景的一部分，黑色区域具有未知标签。然后通过以下方式获得分割：
- en: '[PRE16]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The marker image is then updated such that each zero pixel is assigned one
    of the input labels, while the pixels that belong to the found boundaries have
    a value `-1`. The resulting image of the labels is as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 标记图像随后被更新，使得每个零像素被分配给输入标签中的一个，而属于找到的边界的像素具有值 `-1`。标签的最终图像如下所示：
- en: '![How to do it...](img/00065.jpeg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00065.jpeg)'
- en: 'The boundary image will be similar to the following screenshot:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 边界图像将类似于以下截图：
- en: '![How to do it...](img/00066.jpeg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00066.jpeg)'
- en: How it works...
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: As we did in the preceding recipes, we will use the topological map analogy
    in the description of the watershed algorithm. In order to create a watershed
    segmentation, the idea is to progressively flood the image starting at level 0\.
    As the level of "water" progressively increases (to levels 1, 2, 3, and so on),
    catchment basins are formed. The size of these basins also gradually increases
    and, consequently, the water of two different basins will eventually merge. When
    this happens, a watershed is created in order to keep the two basins separate.
    Once the level of water has reached its maximal level, the sets of these created
    basins and watersheds form the watershed segmentation.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的菜谱中所做的那样，我们将在分水岭算法的描述中使用拓扑图类比。为了创建分水岭分割，想法是从级别 0 开始逐渐淹没图像。随着“水”的级别逐渐增加（到级别
    1、2、3 等等），会形成集水盆地。这些盆地的尺寸也逐步增加，因此，来自两个不同盆地的水最终会汇合。当这种情况发生时，为了保持两个盆地的分离，会创建一个分水岭。一旦水的级别达到最大值，这些创建的盆地和分水岭的集合就形成了分水岭分割。
- en: As expected, the flooding process initially creates many small individual basins.
    When all of these are merged, many watershed lines are created, which results
    in an over-segmented image. To overcome this problem, a modification to this algorithm
    has been proposed in which the flooding process starts from a predefined set of
    marked pixels. The basins created from these markers are labeled in accordance
    with the values assigned to the initial marks. When two basins having the same
    label merge, no watersheds are created, thus preventing over-segmentation. This
    is what happens when the `cv::watershed` function is called. The input marker
    image is updated to produce the final watershed segmentation. Users can input
    a marker image with any number of labels and pixels of unknown labeling left to
    value `0`. The marker image is chosen to be an image of a 32-bit signed integer
    in order to be able to define more than `255` labels. It also allows the special
    value, `-1`, to be assigned to the pixels associated with a watershed. This is
    returned by the `cv::watershed` function.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，淹没过程最初会创建许多小的独立盆地。当所有这些盆地都合并时，会创建许多分水岭线，这导致图像过度分割。为了克服这个问题，已经提出了一种修改后的算法，其中淹没过程从预定义的标记像素集开始。从这些标记创建的盆地按照分配给初始标记的值进行标记。当具有相同标签的两个盆地合并时，不会创建分水岭，从而防止过度分割。这就是调用
    `cv::watershed` 函数时发生的情况。输入标记图像被更新以产生最终的分水岭分割。用户可以输入带有任何数量标签的标记图像，未知标签的像素保留为值
    `0`。标记图像被选择为 32 位有符号整数图像，以便能够定义超过 `255` 个标签。它还允许将特殊值 `-1` 分配给与分水岭相关的像素。这是 `cv::watershed`
    函数返回的。
- en: 'To facilitate the display of the result, we have introduced two special methods.
    The first method returns an image of the labels (with watersheds at value `0`).
    This is easily done through thresholding, as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于显示结果，我们引入了两种特殊方法。第一种方法返回标签图像（分水岭值为 `0`）。这可以通过阈值化轻松完成，如下所示：
- en: '[PRE17]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Similarly, the second method returns an image in which the watershed lines
    are assigned the value `0`, and the rest of the image is at `255`. This time the
    `cv::convertTo` method is used to achieve this result, as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，第二种方法返回的图像中，分水岭线被赋予值 `0`，而图像的其余部分为 `255`。这次使用 `cv::convertTo` 方法来实现这一结果，如下所示：
- en: '[PRE18]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The linear transformation that is applied before the conversion allows the `-1`
    pixels to be converted into `0` (since *-1*255+255=0*).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在转换之前应用的线性变换允许 `-1` 像素转换为 `0`（因为 *-1*255+255=0*）。
- en: Pixels with a value greater than `255` are assigned the value `255`. This is
    due to the saturation operation that is applied when signed integers are converted
    into unsigned characters.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 值大于 `255` 的像素被赋予值 `255`。这是由于在将有符号整数转换为无符号字符时应用的饱和操作。
- en: There's more...
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Obviously, the marker image can be obtained in many different ways. For example,
    users can be interactively asked to paint areas on the objects and the background
    of a scene. Alternatively, in an attempt to identify an object located at the
    center of an image, one can also simply input an image with the central area marked
    with a certain label and the border of the image (where the background is assumed
    to be present) marked with another label. This marker image can be created as
    follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，标记图像可以通过许多不同的方式获得。例如，可以交互式地要求用户在场景的对象和背景上绘制区域。或者，为了识别图像中心位置的对象，也可以简单地输入一个带有中心区域标记的图像，该区域用某种标签标记，而图像的边缘（假设存在背景）用另一个标签标记。这个标记图像可以创建如下：
- en: '[PRE19]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'If we superimpose this marker image on a test image, we will obtain the following
    image:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这个标记图像叠加到测试图像上，我们将获得以下图像：
- en: '![There''s more...](img/00067.jpeg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![还有更多...](img/00067.jpeg)'
- en: 'The following is the resulting watershed image:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的结果是流域图像：
- en: '![There''s more...](img/00068.jpeg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![还有更多...](img/00068.jpeg)'
- en: See also
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The article, *The viscous watershed transform*, *C. Vachier and F. Meyer, Journal
    of Mathematical Imaging and Vision, volume 22, issue 2-3, May 2005*, gives more
    information on the watershed transform
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文章《粘性流域变换》，*C. Vachier 和 F. Meyer，数学图像与视觉杂志，第 22 卷，第 2-3 期，2005 年 5 月*，提供了关于流域变换的更多信息
- en: The last recipe of this chapter, *Extracting foreground objects with the GrabCut
    algorithm*, presents another image segmentation algorithm that can also segment
    an image into background and foreground objects
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的最后一个配方，*使用 GrabCut 算法提取前景对象*，介绍了另一种可以将图像分割为背景和前景对象的图像分割算法
- en: Extracting distinctive regions using MSER
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MSER 提取独特区域
- en: In the previous recipe, you learned how an image can be segmented into regions
    by gradually flooding it and creating watersheds. The **maximally stable extremal
    regions** (**MSER**) algorithm uses the same immersion analogy in order to extract
    meaningful regions in an image. These regions will also be created by flooding
    the image level by level, but this time, we will be interested in the basins that
    remain relatively stable for a period of time during the immersion process. It
    will be observed that these regions correspond to some distinctive parts of the
    scene objects pictured in the image.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的配方中，你学习了如何通过逐渐淹没图像并创建流域来将图像分割成区域。**最大稳定极值区域**（**MSER**）算法使用相同的沉浸类比来提取图像中的有意义区域。这些区域也将通过逐级淹没图像来创建，但这次，我们将对在沉浸过程中相对稳定的盆地感兴趣。将观察到这些区域对应于图像中场景对象的某些独特部分。
- en: How to do it...
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'The basic class to compute the MSER of an image is `cv::MSER`. An instance
    of this class can be created by using the default empty constructor. In our case,
    we chose to initialize it by specifying a minimum and maximum size for the detected
    regions in order to limit their number. Then, our call will be as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 计算图像 MSER 的基本类是 `cv::MSER`。可以通过使用默认的空构造函数创建此类的一个实例。在我们的情况下，我们选择通过指定检测到的区域的最小和最大尺寸来初始化它，以限制其数量。然后，我们的调用如下所示：
- en: '[PRE20]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, the MSER can be obtained by a call to a functor, specifying the input
    image and an appropriate output data structure, as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，可以通过调用一个函数对象来获得 MSER，指定输入图像和适当的数据结构，如下所示：
- en: '[PRE21]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The result is a vector of regions represented by the pixel points that compose
    each of them. In order to visualize the results, we create a blank image on which
    we will display the detected regions in different colors (which are randomly chosen).
    This is done as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个由组成每个区域的像素点表示的区域向量。为了可视化结果，我们在一个空白图像上显示检测到的区域，这些区域将以不同的颜色（随机选择）显示。这是通过以下方式完成的：
- en: '[PRE22]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Note that the MSER form a hierarchy of regions. Therefore, to make all of these
    visible, we have chosen to not overwrite the small regions when they are included
    in larger ones. If the MSER are detected on the following image:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，MSER 形成区域的一个层次结构。因此，为了使所有这些区域都可见，我们选择在它们包含在更大的区域中时不要覆盖小区域。如果我们在这个图像上检测到 MSER：
- en: '![How to do it...](img/00069.jpeg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![如何做到这一点...](img/00069.jpeg)'
- en: 'Then, the resulting image will be (refer to the book''s graphics PDF to view
    this image in color) as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，生成的图像将如下所示（请参考书籍的图形 PDF 以查看此图像的颜色）（参照以下内容）：
- en: '![How to do it...](img/00070.jpeg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![如何做到这一点...](img/00070.jpeg)'
- en: These are the raw results of the detection. Nevertheless, it can be observed
    how this operator has been able to extract some meaningful regions (for example,
    the building's windows) from this image.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是检测的原始结果。尽管如此，可以观察到这个操作员如何能够从这个图像中提取一些有意义的区域（例如，建筑物的窗户）。
- en: How it works...
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: MSER uses the same mechanism as the watershed algorithm; that is, it proceeds
    by gradually flooding the image from level `0` to level `255`. As the level of
    water increases, you can observe that the sharply delimitated darker areas form
    the basins that have a relatively stable shape for a period of time (recall that
    under the immersion analogy, the water levels correspond to the intensity levels).
    These stable basins are the MSER. These are detected by considering the connected
    regions at each level and measuring their stability. This is done by comparing
    the current area of a region with the area it previously had when the level was
    down by a value of delta. When this relative variation reaches a local minimum,
    the region is identified as a MSER. The delta value that is used to measure the
    relative stability is the first parameter in the constructor of the `cv::MSER`
    class; its default value is `5`. In addition, to be considered, the size of a
    region must be within a certain predefined range. The acceptable minimum and maximum
    region sizes are the next two parameters of the constructor. We must also ensure
    that the MSER is stable (the fourth parameter), that is, the relative variation
    of its shape is small enough. The stable regions can be included in the larger
    regions (called parent regions).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: MSER使用与水算法相同的机制；也就是说，它通过从级别`0`逐渐淹没图像到级别`255`来执行。随着水位的升高，你可以观察到那些尖锐界定较暗的区域形成了在一定时间内形状相对稳定的盆地（回忆一下，在沉浸类比中，水位对应于强度级别）。这些稳定的盆地就是MSER。这些是通过考虑每个级别的连通区域并测量它们的稳定性来检测的。这是通过比较区域的当前面积与当级别下降delta值时的先前面积来完成的。当这种相对变化达到局部最小值时，该区域被识别为MSER。用于测量相对稳定性的delta值是`cv::MSER`类构造函数的第一个参数；其默认值是`5`。此外，要考虑的区域大小必须在某个预定义的范围内。可接受的区域最小和最大大小是构造函数的下一个两个参数。我们还必须确保MSER是稳定的（第四个参数），也就是说，其形状的相对变化足够小。稳定的区域可以包含在更大的区域中（称为父区域）。
- en: To be valid, a parent MSER must be sufficiently different from its child; this
    is the diversity criterion, and it is specified by the fifth parameter of the
    `cv::MSER` constructor. In the example used in the previous section, the default
    value for these last two parameters were used. (The default values are `0.25`
    for the maximum allowable variation of a MSER and `0.2` for the minimum diversity
    of a parent MSER.)
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 要有效，父MSER必须与其子足够不同；这是多样性标准，它由`cv::MSER`构造函数的第五个参数指定。在上一节中使用的示例中，使用了这两个最后参数的默认值。（这些最后两个参数的默认值是MSER允许的最大变化为`0.25`，父MSER的最小多样性为`0.2`。）
- en: 'The output of the MSER detector is a vector of point sets. Since we are generally
    more interested in a region as a whole rather than its individual pixel locations,
    it is common to represent a MSER by a simple geometrical shape that describes
    the MSER location and size. A bounding ellipse is a commonly used representation.
    In order to obtain these ellipses, we will make use of two convenient OpenCV functions.
    The first is the `cv::minAreaRect` function that finds the rectangle of minimum
    area that binds all the points in a set. This rectangle is described by a `cv::RotatedRect`
    instance. Once this bounding rectangle is found, it is possible to draw the inscribed
    ellipse on the image by using the `cv::ellipse` function. Let''s encapsulate this
    complete process in one class. The constructor of this class basically repeats
    the one of the `cv::MSER` class. Refer to the following code:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: MSER检测器的输出是一个点集的向量。由于我们通常更关注整个区域而不是其单个像素位置，因此通常用描述MSER位置和大小的简单几何形状来表示MSER。边界椭圆是一种常用的表示方法。为了获得这些椭圆，我们将利用两个方便的OpenCV函数。第一个是`cv::minAreaRect`函数，它找到绑定集合中所有点的最小面积矩形。这个矩形由一个`cv::RotatedRect`实例描述。一旦找到这个边界矩形，就可以使用`cv::ellipse`函数在图像上绘制内切椭圆。让我们将这个完整的过程封装在一个类中。这个类的构造函数基本上重复了`cv::MSER`类的构造函数。参考以下代码：
- en: '[PRE23]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: One extra parameter (`minAreaRatio`) has been added to eliminate the MSER for
    which the bounding rectangle has an area that differs greatly from the one of
    the MSER it represents. This is to remove the less interesting elongated shapes.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 添加了一个额外的参数（`minAreaRatio`）来消除那些边界矩形面积与所代表MSER面积差异很大的MSER。这是为了去除那些不太有趣的细长形状。
- en: 'The list of representative bounding rectangles is computed by the following
    method:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 代表性边界矩形的列表是通过以下方法计算的：
- en: '[PRE24]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The corresponding ellipses are drawn on the image using the following method:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下方法在图像上绘制相应的椭圆：
- en: '[PRE25]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The detection of the MSER is then obtained as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: MSER的检测随后获得如下：
- en: '[PRE26]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'By applying this function to the previously used image, we will get the following
    image:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将此函数应用于之前使用的图像，我们将得到以下图像：
- en: '![How it works...](img/00071.jpeg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00071.jpeg)'
- en: Comparing this result with the previous result should convince you that this
    later representation is easier to interpret. Note how the child and parent MSER
    are often represented by very similar ellipses. In some cases, it would then be
    interesting to apply a minimum variation criterion on these ellipses in order
    to eliminate these repeated representations.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 将此结果与之前的结果进行比较应该会使您相信这种后来的表示更容易解释。注意，子MSER和父MSER通常由非常相似的椭圆表示。在某些情况下，然后可能会对这些椭圆应用最小变化标准，以消除这些重复的表示。
- en: See also
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Computing components' shape descriptors* recipe in [Chapter 7](part0052_split_000.html#page
    "Chapter 7. Extracting Lines, Contours, and Components"), *Extracting Lines, Contours,
    and Components* will show you how to compute other properties of connected point
    sets
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第7章](part0052_split_000.html#page "第7章。提取线条、轮廓和组件")中的*计算组件形状描述符*配方，*提取线条、轮廓和组件*将向您展示如何计算连接点集的其他属性'
- en: '[Chapter 8](part0058_split_000.html#page "Chapter 8. Detecting Interest Points"),
    *Detecting Interest Points*, will explain how to use MSER as an interest point
    detector'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第8章](part0058_split_000.html#page "第8章。检测兴趣点")，*检测兴趣点*将解释如何使用MSER作为兴趣点检测器'
- en: Extracting foreground objects with the GrabCut algorithm
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GrabCut算法提取前景对象
- en: 'OpenCV proposes the implementation of another popular algorithm for image segmentation:
    the **GrabCut** algorithm. This algorithm is not based on mathematical morphology,
    but we have presented it here since it shows some similarities in its use with
    the watershed segmentation algorithm presented earlier in this chapter. GrabCut
    is computationally more expensive than watershed, but it generally produces more
    accurate results. It is the best algorithm to use when you want to extract a foreground
    object in a still image (for example, to cut and paste an object from one picture
    to another).'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV提出了另一个流行的图像分割算法的实现：**GrabCut**算法。这个算法不是基于数学形态学，但我们在这里介绍它，因为它在用法上与本章 earlier
    提到的水系分割算法有一些相似之处。与水系相比，GrabCut的计算成本更高，但通常会产生更准确的结果。当您想要从静态图像中提取前景对象时（例如，从一个图片中剪切并粘贴对象到另一个图片中），这是最好的算法。
- en: How to do it...
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: The `cv::grabCut` function is easy to use. You just need to input an image,
    and label some of its pixels as belonging to the background or to the foreground.
    Based on this partial labeling, the algorithm will then determine a foreground/background
    segmentation for the complete image.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv::grabCut`函数易于使用。您只需要输入一个图像，并标记其中一些像素属于背景或前景。基于这种部分标记，算法将确定整个图像的前景/背景分割。'
- en: 'One way to specify a partial foreground/background labeling for an input image
    is by defining a rectangle inside which the foreground object is included:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一种指定输入图像的部分前景/背景标记的方法是在其中定义一个矩形，前景对象包含在这个矩形内：
- en: '[PRE27]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![How to do it...](img/00072.jpeg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/00072.jpeg)'
- en: 'All the pixels outside this rectangle will then be marked as the background.
    In addition to the input image and its segmentation image, calling the `cv::grabCut`
    function requires the definition of two matrices, which will contain the models
    built by the algorithm as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 然后所有在这个矩形之外的像素将被标记为背景。除了输入图像及其分割图像外，调用`cv::grabCut`函数还需要定义两个矩阵，这些矩阵将包含算法构建的模型，如下所示：
- en: '[PRE28]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Note how we specified that we are using the bounding rectangle mode using the
    `cv::GC_INIT_WITH_RECT` flag as the last argument of the function (the next section
    will discuss the other available mode). The input/output segmentation image can
    have one of the following four values:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们如何指定使用边界矩形模式，通过将 `cv::GC_INIT_WITH_RECT` 标志作为函数的最后一个参数（下一节将讨论其他可用模式）。输入/输出分割图像可以具有以下四个值之一：
- en: '`cv::GC_BGD`: This is the value for the pixels that certainly belong to the
    background (for example, pixels outside the rectangle in our example)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv::GC_BGD`：这是属于背景像素的值（例如，在我们的例子中矩形外的像素）'
- en: '`cv::GC_FGD`: This is the value for the pixels that certainly belong to the
    foreground (there are none in our example)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv::GC_FGD`：这是属于前景像素的值（在我们的例子中没有这样的像素）'
- en: '`cv::GC_PR_BGD`: This is the value for the pixels that probably belong to the
    background'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv::GC_PR_BGD`：这是可能属于背景的像素的值'
- en: '`cv::GC_PR_FGD`: This is the value for the pixels that probably belong to the
    foreground (that is, the initial value for the pixels inside the rectangle in
    our example)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv::GC_PR_FGD`：这是可能属于前景像素的值（即我们例子中矩形内部像素的初始值）'
- en: 'We get a binary image of the segmentation by extracting the pixels that have
    a value equal to `cv::GC_PR_FGD`. Refer to the following code:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过提取值为 `cv::GC_PR_FGD` 的像素来得到分割的二值图像。参考以下代码：
- en: '[PRE29]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To extract all the foreground pixels, that is, with values equal to `cv::GC_PR_FGD`
    or `cv::GC_FGD`, it is possible to check the value of the first bit, as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 要提取所有前景像素，即值为 `cv::GC_PR_FGD` 或 `cv::GC_FGD` 的像素，可以检查第一个位的值，如下所示：
- en: '[PRE30]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This is possible because these constants are defined as values 1 and 3, while
    the other two (`cv::GC_BGD` and `cv::GC_PR_BGD`) are defined as 0 and 2\. In our
    example, the same result is obtained because the segmentation image does not contain
    the `cv::GC_FGD` pixels (only the `cv::GC_BGD` pixels have been inputted).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这之所以可能，是因为这些常量被定义为值 1 和 3，而其他两个（`cv::GC_BGD` 和 `cv::GC_PR_BGD`）被定义为 0 和 2。在我们的例子中，得到相同的结果是因为分割图像不包含
    `cv::GC_FGD` 像素（只有 `cv::GC_BGD` 像素被输入）。
- en: 'Finally, we obtain an image of the foreground objects (over a white background)
    by the following copy operation with a mask:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过以下带有掩膜的复制操作，我们得到前景对象（在白色背景上）的图像：
- en: '[PRE31]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The following image is obtained as the result:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 下图是得到的结果：
- en: '![How to do it...](img/00073.jpeg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/00073.jpeg)'
- en: How it works...
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the preceding example, the GrabCut algorithm was able to extract the foreground
    objects by simply specifying a rectangle inside which these objects (the four
    animals) were contained. Alternatively, one could also assign the values `cv::GC_BGD`
    and `cv::GC_FGD` to some specific pixels of the segmentation image, which are
    provided as the second argument of the `cv::grabCut` function. You would then
    specify `GC_INIT_WITH_MASK` as the input mode flag. These input labels could be
    obtained, for example, by asking a user to interactively mark a few elements of
    the image. It is also possible to combine these two input modes.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，GrabCut 算法能够通过简单地指定一个包含这些对象（四只动物）的矩形来提取前景对象。或者，也可以将 `cv::GC_BGD` 和 `cv::GC_FGD`
    的值分配给分割图像中的某些特定像素，这些像素作为 `cv::grabCut` 函数的第二个参数提供。然后，指定 `GC_INIT_WITH_MASK` 作为输入模式标志。这些输入标签可以通过要求用户交互式标记图像的几个元素来获得。也可以将这两种输入模式结合起来。
- en: Using this input information, the GrabCut algorithm creates the background/foreground
    segmentation by proceeding as follows. Initially, a foreground label (`cv::GC_PR_FGD`)
    is tentatively assigned to all the unmarked pixels. Based on the current classification,
    the algorithm groups the pixels into clusters of similar colors (that is, `K`
    clusters for the background and `K` clusters for the foreground). The next step
    is to determine a background/foreground segmentation by introducing boundaries
    between the foreground and background pixels. This is done through an optimization
    process that tries to connect pixels with similar labels, and that imposes a penalty
    for placing a boundary in the regions of relatively uniform intensity. This optimization
    problem can be efficiently solved using the **Graph Cuts** algorithm, a method
    that can find the optimal solution of a problem by representing it as a connected
    graph on which cuts are applied in order to compose an optimal configuration.
    The obtained segmentation produces new labels for the pixels. The clustering process
    can then be repeated, and a new optimal segmentation is found again, and so on.
    Therefore, the GrabCut algorithm is an iterative procedure that gradually improves
    the segmentation result. Depending on the complexity of the scene, a good solution
    can be found in more or less number of iterations (in easy cases, one iteration
    would be enough).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此输入信息，GrabCut算法通过以下步骤创建背景/前景分割。最初，将前景标签(`cv::GC_PR_FGD`)暂时分配给所有未标记的像素。根据当前的分类，算法将像素分组为相似颜色的簇（即，背景和前景各有`K`个簇）。下一步是通过在前景和背景像素之间引入边界来确定背景/前景分割。这是通过一个优化过程来完成的，该过程试图连接具有相似标签的像素，并对在相对均匀强度区域放置边界施加惩罚。此优化问题可以使用**图割**算法有效地解决，这是一种通过将其表示为应用切割以组成最优配置的连通图来找到问题最优解的方法。获得的分割为像素产生新的标签。然后可以重复聚类过程，并再次找到新的最优分割，依此类推。因此，GrabCut算法是一个迭代过程，它逐渐改进分割结果。根据场景的复杂性，可以在更多或更少的迭代次数中找到良好的解决方案（在简单情况下，一次迭代就足够了）。
- en: This explains the argument of the function where the user can specify the number
    of iterations to be applied. The two internal models maintained by the algorithm
    are passed as an argument of the function (and returned). Therefore, it is possible
    to call the function with the models of the last run again if one wishes to improve
    the segmentation result by performing additional iterations.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这解释了函数的参数，用户可以指定要应用的迭代次数。算法维护的两个内部模型作为函数的参数传递（并返回）。因此，如果希望通过执行额外的迭代来改进分割结果，可以再次使用上次运行的模型调用该函数。
- en: See also
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'The article, *GrabCut: Interactive Foreground Extraction using Iterated Graph
    Cuts in ACM Transactions on Graphics (SIGGRAPH) volume 23, issue 3, August 2004,*
    *C. Rother, V. Kolmogorov, and A. Blake* describes the GrabCut algorithm in detail.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文章《GrabCut：在ACM Transactions on Graphics (SIGGRAPH) 第23卷第3期，2004年8月》中，*GrabCut：使用迭代图割进行交互式前景提取*，由C.
    Rother, V. Kolmogorov和A. Blake描述了GrabCut算法的详细信息。
