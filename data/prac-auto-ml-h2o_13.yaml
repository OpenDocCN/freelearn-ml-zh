- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Using H2O AutoML with Other Technologies
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 H2O AutoML 与其他技术
- en: In the last few chapters, we have been exploring how we can use H2O AutoML in
    production. We saw how we can use H2O models as POJOs and MOJOs as portable objects
    that can make predictions. However, in actual production environments, you will
    often be using multiple technologies to meet various technical requirements. The
    collaboration of such technologies plays a big role in the seamless functionality
    of your system.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们一直在探讨如何在生产环境中使用 H2O AutoML。我们看到了如何使用 H2O 模型作为 POJOs 和 MOJOs 作为可移植对象来进行预测。然而，在实际的生产环境中，您通常会使用多种技术来满足各种技术要求。这些技术的协作在您系统的无缝功能中起着重要作用。
- en: Thus, it is important to know how we can use H2O models in collaboration with
    other commonly used technologies in the ML domain. In this chapter, we shall explore
    and implement H2O with some of these technologies and see how we can build systems
    that can work together to provide a collaborative benefit.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，了解我们如何将 H2O 模型与其他在机器学习领域中常用的技术协作使用非常重要。在本章中，我们将探索和实现 H2O 与这些技术中的一些，并查看我们如何构建可以协同工作以提供协作优势的系统。
- en: First, we will investigate how we can host an H2O prediction service as a web
    service using the **Spring Boot** application. Then, we will explore how we can
    perform real-time prediction using H2O with **Apache Storm**.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将研究如何使用 **Spring Boot** 应用程序将 H2O 预测服务托管为网络服务。然后，我们将探讨如何使用 H2O 和 **Apache
    Storm** 进行实时预测。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Using H2O AutoML and Spring Boot
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 H2O AutoML 和 Spring Boot
- en: Using H2O AutoML and Apache Storm
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 H2O AutoML 和 Apache Storm
- en: By the end of this chapter, you should have a better understanding of how you
    can use models trained using H2O AutoML with different technologies to make predictions
    in different scenarios.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您应该对如何使用使用 H2O AutoML 训练的模型与不同技术结合，在不同场景中进行预测有更好的理解。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you will require the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，您需要以下内容：
- en: The latest version of your preferred web browser.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您首选的网页浏览器的最新版本。
- en: An **Integrated Development Environment** (**IDE**) of your choice.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您选择的 **集成开发环境**（**IDE**）。
- en: All the experiments conducted in this chapter have been performed using IntelliJ
    IDE on an Ubuntu Linux system. You are free to follow along using the same setup
    or perform the same experiments using IDEs and operating systems that you are
    comfortable with.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中进行的所有实验都是在 Ubuntu Linux 系统上的 IntelliJ IDE 中完成的。您可以使用相同的设置跟随操作，或者使用您熟悉的 IDE
    和操作系统执行相同的实验。
- en: All code examples for this chapter can be found on GitHub at [https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013](https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码示例都可以在 GitHub 上找到，网址为 [https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013](https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013)。
- en: Let’s jump right into the first section, where we’ll learn how to host models
    trained using H2O AutoML on a web application created using Spring Boot.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接进入第一部分，我们将学习如何将使用 H2O AutoML 训练的模型托管在 Spring Boot 创建的 Web 应用程序上。
- en: Using H2O AutoML and Spring Boot
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 H2O AutoML 和 Spring Boot
- en: In today’s times, most software services that are created are hosted on the
    internet, where they can be made accessible to all internet users. All of this
    is done using web applications hosted on web servers. Even prediction services
    that use ML can be made available to the public by hosting them on web applications.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今时代，大多数创建的软件服务都托管在互联网上，它们可以通过托管在 Web 服务器上的 Web 应用程序对所有互联网用户开放。所有这些都是在使用 Web
    应用程序完成的。即使是使用机器学习的预测服务也可以通过托管在 Web 应用程序上向公众提供。
- en: The **Spring Framework** is one of the most commonly used open source web application
    frameworks to create websites and web applications. It is based on the Java platform
    and, as such, can be run on any system with a JVM. **Spring Boot** is an extension
    of the Spring Framework that provides a preconfigured setup for your web application
    out of the box. This helps you quickly set up your web application without the
    need to implement the underlying pipelining needed to configure and host your
    web service.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**Spring 框架**是最常用的开源Web应用框架之一，用于创建网站和Web应用。它基于Java平台，因此可以在任何具有JVM的系统上运行。**Spring
    Boot**是Spring框架的扩展，它提供了预配置的Web应用设置。这有助于你快速设置Web应用，无需实现配置和托管Web服务所需的底层管道。'
- en: So, let’s dive into the implementation by understanding the problem statement.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们通过理解问题陈述来深入了解实现。
- en: Understanding the problem statement
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解问题陈述
- en: Let’s assume you are working for a wine manufacturing company. The officials
    have a requirement where they want to automate the process of calculating the
    quality of wine and its color. The service should be available as a web service
    where the quality assurance executive can provide some information about the wine’s
    attributes, and the service uses these details and an underlying ML model to predict
    the quality of the wine as well as its color.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在为一家葡萄酒制造公司工作。官员们有一个要求，他们希望自动化计算葡萄酒品质及其颜色的过程。该服务应作为一个Web服务提供，质量保证主管可以提供一些关于葡萄酒特性的信息，该服务使用这些细节和底层ML模型来预测葡萄酒的品质及其颜色。
- en: So, technically, we will need two models to make the full prediction. One will
    be a regression model that predicts the quality of the wine, while the other will
    be a classification model that predicts the color of the wine.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从技术上讲，我们需要两个模型来完成完整的预测。一个将是预测葡萄酒品质的回归模型，另一个将是预测葡萄酒颜色的分类模型。
- en: We can use a combination of the Red Wine Quality and White Wine Quality datasets
    and run H2O AutoML on it to train the models. You can find the datasets at https://archive.ics.uci.edu/ml/datasets/Wine+Quality.
    The combined dataset is already present at [https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_spring_boot/h2o_spring_boot](https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_spring_boot/h2o_spring_boot).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用红葡萄酒品质和白葡萄酒品质数据集的组合，并在其上运行H2O AutoML来训练模型。你可以在https://archive.ics.uci.edu/ml/datasets/Wine+Quality找到数据集。组合数据集已存在于[https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_spring_boot/h2o_spring_boot](https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_spring_boot/h2o_spring_boot)。
- en: 'The following screenshot shows a sample of the dataset:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的截图显示了数据集的一个样本：
- en: '![Figure 13.1 – Wine quality and color dataset ](img/B17298_13_001.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.1 – 葡萄酒品质和颜色数据集](img/B17298_13_001.jpg)'
- en: Figure 13.1 – Wine quality and color dataset
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.1 – 葡萄酒品质和颜色数据集
- en: 'This dataset consists of the following features:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集包含以下特征：
- en: '**fixed acidity**: This feature explains the amount of acidity that is non-volatile,
    meaning it does not evaporate over a certain period.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**固定酸度**：这个特征解释了非挥发性酸度的量，意味着它不会在特定时间内蒸发。'
- en: '**volatile acidity**: This feature explains the amount of acidity that is volatile,
    meaning it will evaporate over a certain period.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**挥发性酸度**：这个特征解释了挥发性酸度的量，意味着它会在特定时间内蒸发。'
- en: '**citric acid**: This feature explains the amount of citric acid present in
    the wine.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**柠檬酸**：这个特征解释了葡萄酒中柠檬酸的量。'
- en: '**residual sugar**: This feature explains the amount of residual sugar present
    in the wine.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**残留糖分**：这个特征解释了葡萄酒中残留糖分的量。'
- en: '**chlorides**: This feature explains the number of chlorides present in the
    wine.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**氯化物**：这个特征解释了葡萄酒中氯化物的数量。'
- en: '**free sulfur dioxide**: This feature explains the amount of free sulfur dioxide
    present in the wine.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**游离二氧化硫**：这个特征解释了葡萄酒中游离二氧化硫的量。'
- en: '**total sulfur dioxide**: This feature explains the amount of total sulfur
    dioxide present in the wine.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总二氧化硫**：这个特征解释了葡萄酒中总二氧化硫的量。'
- en: '**density**: This feature explains the density of the wine.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**密度**：这个特征解释了葡萄酒的密度。'
- en: '**pH**: This feature explains the pH value of the wine, with 0 being the most
    acidic and 14 being the most basic.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pH值**：这个特征解释了葡萄酒的pH值，其中0是最酸性的，14是最碱性的。'
- en: '**sulphates**: This feature explains the number of sulfates present in the
    wine.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硫酸盐**: 此功能解释了葡萄酒中存在的硫酸盐数量。'
- en: '**alcohol**: This feature explains the amount of alcohol present in the wine.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**酒精**: 此功能解释了葡萄酒中存在的酒精含量。'
- en: '**quality**: This is the response column, which notes the quality of the wine.
    0 indicates that the wine is very bad, while 10 indicates that the wine is excellent.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**质量**: 这是响应列，记录了葡萄酒的质量。0表示葡萄酒非常差，而10表示葡萄酒非常好。'
- en: '**color**: This feature represents the color of the wine.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**颜色**: 此功能代表葡萄酒的颜色。'
- en: Now that we understand the problem statement and the dataset that we will be
    working with, let’s design the architecture to show how this web service will
    work.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经理解了问题陈述和我们将要处理的数据集，让我们设计架构以展示这个网络服务的工作方式。
- en: Designing the architecture
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计架构
- en: 'Before we dive deep into the implementation of the service, let’s look at the
    overall architecture of how all of the technologies should work together. The
    following is the architecture diagram of the wine quality and color prediction
    web service:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入服务实施之前，让我们看看所有技术应该如何协同工作的整体架构。以下是我们葡萄酒质量和颜色预测网络服务的架构图：
- en: '![Figure 13.2 – Architecture of the wine quality and color prediction web service
    ](img/B17298_13_002.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图13.2 – 葡萄酒质量和颜色预测网络服务的架构](img/B17298_13_002.jpg)'
- en: Figure 13.2 – Architecture of the wine quality and color prediction web service
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2 – 葡萄酒质量和颜色预测网络服务的架构
- en: 'Let’s understand the various components of this architecture:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解这个架构的各个组成部分：
- en: '**Client**: This is the person – or in this case, the wine quality assurance
    executive – who will be using the application. The client communicates with the
    web application by making a POST request to it, passing the attributes of the
    wine, and getting the quality and color of the wine as a prediction response.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户端**: 这是指使用应用程序的人——在这种情况下，是葡萄酒质量保证执行者。客户端通过向其发送POST请求并与网络应用程序通信，传递葡萄酒的属性，并获取葡萄酒的质量和颜色作为预测响应。'
- en: '**Spring Boot Application**: This is the web application that runs on a web
    server and is responsible for performing the computation processes. In our scenario,
    this is the application that will be accepting the POST request from the client,
    feeding the data to the model, getting the prediction results, and sending the
    results back to the client as a response.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spring Boot应用程序**: 这是运行在网络服务器上的网络应用程序，负责执行计算过程。在我们的场景中，这是将接受客户端POST请求的应用程序，将数据输入到模型中，获取预测结果，并将结果作为响应发送回客户端。'
- en: '**Tomcat Web server**: The web server is nothing but the software and hardware
    that handles the HTTP communication over the internet. For our scenario, we shall
    be using the Apache Tomcat web server. Apache Tomcat is a free and open source
    HTTP web server written in Java. The web server is responsible for forwarding
    client requests to the web application.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tomcat Web服务器**: 网络服务器仅仅是处理互联网上HTTP通信的软件和硬件。在我们的场景中，我们将使用Apache Tomcat网络服务器。Apache
    Tomcat是一个用Java编写的免费开源HTTP网络服务器。网络服务器负责将客户端请求转发到网络应用程序。'
- en: '`h2o-genmodel` library to make predictions.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`h2o-genmodel`库进行预测。
- en: '**H2O server**: Models will be trained using the H2O server. As we saw in [*Chapter
    1*](B17298_01.xhtml#_idTextAnchor017), *Understanding H2O AutoML Basics*, we can
    run H2O AutoML on an H2O server. We shall do the same for our scenario by starting
    an H2O server, training the models using H2O AutoML, and then downloading the
    trained models as POJOs so that we can load them into the Spring Boot application.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H2O服务器**: 将使用H2O服务器来训练模型。正如我们在[*第1章*](B17298_01.xhtml#_idTextAnchor017)中看到的，*理解H2O
    AutoML基础知识*，我们可以在H2O服务器上运行H2O AutoML。我们将通过启动H2O服务器，使用H2O AutoML训练模型，然后下载训练好的模型作为POJOs，以便我们可以将它们加载到Spring
    Boot应用程序中。'
- en: '**Dataset**: This is the wine quality dataset that we are using to train our
    models. As stated in the previous section, this dataset is a combination of the
    Red Wine Quality and White Wine Quality datasets.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集**: 这是用于训练我们的模型的葡萄酒质量数据集。如前所述，此数据集是红葡萄酒质量和白葡萄酒质量数据集的组合。'
- en: Now that we have a good understanding of how we are going to create our wine
    quality and color prediction web service, let’s move on to its implementation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经很好地理解了我们将如何创建我们的葡萄酒质量和颜色预测网络服务，让我们继续到其实施部分。
- en: Working on the implementation
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在实施工作中
- en: This service has already been built and is available on GitHub. The code base
    can be found at [https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_spring_boot](https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_spring_boot).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此服务已经构建完成，可在 GitHub 上找到。代码库可以在 [https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_spring_boot](https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_spring_boot)
    找到。
- en: 'Before we dive into the code, make sure your system meets the following minimum
    requirements:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入代码之前，请确保您的系统满足以下最低要求：
- en: Java version 8 and above
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java 版本 8 及以上
- en: The latest version of Maven, preferably version 3.8.6
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maven 的最新版本，最好是 3.8.6 版本
- en: Python version 3.7 and above
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 版本 3.7 及以上
- en: H2O Python library installed using pip3
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 pip3 安装的 H2O Python 库
- en: Git installed on your system
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统上已安装的 Git
- en: First, we will clone the GitHub repository, open it in our preferred IDE, and
    go through the files to understand the whole process. The following steps have
    been performed on *Ubuntu 22.04 LTS* and we are using **IntelliJ IDEA** *version
    2022.1.4* as the IDE. Feel free to use any IDE of your choice that supports Maven
    and the Spring Framework for better support.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将克隆 GitHub 仓库，在我们的首选 IDE 中打开它，并查看文件以了解整个过程。以下步骤已在 *Ubuntu 22.04 LTS* 上执行，我们使用
    **IntelliJ IDEA** *版本 2022.1.4* 作为 IDE。请随意使用任何支持 Maven 和 Spring 框架的 IDE 以获得更好的支持。
- en: 'So, clone the GitHub repository and navigate to `Chapter 13/h2o_spring_boot/`.
    Then, you start your IDE and open the project. Once you have opened the project,
    you should get a directory structure similar to the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，克隆 GitHub 仓库并导航到 `Chapter 13/h2o_spring_boot/`。然后，你启动你的 IDE 并打开项目。一旦你打开了项目，你应该得到一个类似于以下目录结构的结构：
- en: '![Figure 13.3 – Directory structure of h2o_wine_predictor ](img/B17298_13_003.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.3 – h2o_wine_predictor 的目录结构](img/B17298_13_003.jpg)'
- en: Figure 13.3 – Directory structure of h2o_wine_predictor
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.3 – h2o_wine_predictor 的目录结构
- en: 'The directory structure consists of the following important files:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 目录结构包括以下重要文件：
- en: '`pom.xml`: A **Project Object Model** (**POM**) is the fundamental unit of
    the Maven build automation tool. It is an XML file that contains all the information
    about all the dependencies needed, as well as the configurations needed to correctly
    build the application.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pom.xml`: **项目对象模型**（**POM**）是 Maven 构建自动化工具的基本单元。它是一个包含所有所需依赖项信息以及正确构建应用程序所需配置的
    XML 文件。'
- en: '`script.py`: This is the Python script that we will use to train our models
    on the wine quality dataset. The script starts an H2O server instance, imports
    the dataset, and then runs AutoML to train the models. We shall look at it in
    more detail later.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`script.py`: 这是我们将用于在葡萄酒质量数据集上训练模型的 Python 脚本。该脚本启动 H2O 服务器实例，导入数据集，然后运行 AutoML
    来训练模型。我们将在稍后更详细地查看它。'
- en: '`src/main/java/com.h2o_wine_predictor.demo/api/PredictionController.java`:
    This is the controller file that has the request mapping to direct the POST request
    to execute the mapped function. The function eventually calls the actual business
    logic where predictions are made using the ML models and the response is sent
    back.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`src/main/java/com.h2o_wine_predictor.demo/api/PredictionController.java`:
    这是一个控制器文件，它具有将 POST 请求映射到执行映射函数的请求映射。该函数最终调用实际的业务逻辑，在 ML 模型中进行预测，并将响应发送回去。'
- en: '`src/main/java/com.h2o_wine_predictor.demo/service/PredictionService.java`:
    This is the actual file where the business logic of making predictions resides.
    This function imports the POJO models and the h2o-genmodel library and uses them
    to predict the data received from the controller.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`src/main/java/com.h2o_wine_predictor.demo/service/PredictionService.java`:
    这是实际存放预测业务逻辑的文件。这个函数导入 POJO 模型和 h2o-genmodel 库，并使用它们来预测从控制器接收到的数据。'
- en: '`src/main/java/com.h2o_wine_predictor.demo/Demo`: This is the main function
    of the Spring Boot application. If you want to start the Spring Boot application,
    you must execute this main function, which starts the Apache Tomcat server that
    hosts the web application.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`src/main/java/com.h2o_wine_predictor.demo/Demo`: 这是 Spring Boot 应用程序的主函数。如果你想启动
    Spring Boot 应用程序，你必须执行这个主函数，它会启动 Apache Tomcat 服务器，该服务器承载着网络应用程序。'
- en: '`src/main/resources/winequality-combined.csv`: This is where the actual CSV
    dataset is stored. The Python script that trains the H2O models picks the dataset
    from this path and starts training the models.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`src/main/resources/winequality-combined.csv`: 这是实际 CSV 数据集存储的地方。训练 H2O 模型的
    Python 脚本从这个路径选择数据集并开始训练模型。'
- en: You may have noticed that we don’t have the model POJO files anywhere in the
    directory. So, let’s build those. Refer to the `script.py` Python file and let’s
    understand what is being done line by line.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，我们在这个目录中没有找到任何模型 POJO 文件。所以，让我们构建这些文件。参考 `script.py` Python 文件，让我们逐行了解正在做什么。
- en: 'The code for `script.py` is as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`script.py` 的代码如下：'
- en: 'The script starts by importing the dependencies:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 脚本首先导入依赖项：
- en: '[PRE0]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once importing is done, the script initializes the H2O server:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入完成后，脚本初始化 H2O 服务器：
- en: '[PRE1]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once the H2O server is up and running, the script imports the dataset from
    the `src/main/resources` directory:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦 H2O 服务器启动并运行，脚本将从 `src/main/resources` 目录导入数据集：
- en: '[PRE2]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Since the column color is categorical, the script sets it to `factor`:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于列颜色是分类的，脚本将其设置为 `factor`：
- en: '[PRE3]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Finally, you will need a training and validation DataFrame to train and validate
    your model during training. Therefore, the script also splits the DataFrame into
    a 70/30 ratio:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，你将需要一个用于训练和验证的 DataFrame，以便在训练过程中训练和验证你的模型。因此，脚本还将 DataFrame 分割成 70/30 的比例：
- en: '[PRE4]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now that the DataFrames are ready, we can begin the training process for training
    the first model, which is the classification model to classify the color of the
    wine. So, the script sets the label and features, as follows:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在数据框已经准备好了，我们可以开始训练第一个模型，这是一个用于分类葡萄酒颜色的分类模型。因此，脚本设置了标签和特征，如下所示：
- en: '[PRE5]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now that the training data is ready, we can create the H2O AutoML object and
    begin the model training. The following script does this:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在训练数据已经准备好了，我们可以创建 H2O AutoML 对象并开始模型训练。以下脚本执行此操作：
- en: '[PRE6]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When initializing the `H2OautoML` object, we set the `exclude_algos` parameter
    with the `StackedEnsemble` value. This is done as stacked ensemble models are
    not supported by POJOs, as we learned in [*Chapter 10*](B17298_10.xhtml#_idTextAnchor196),
    *Working with Plain Old Java Objects (POJOs)*.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当初始化 `H2OautoML` 对象时，我们使用 `StackedEnsemble` 值设置 `exclude_algos` 参数。这样做是因为堆叠集成模型不支持
    POJO，正如我们在 [*第 10 章*](B17298_10.xhtml#_idTextAnchor196)，*与普通旧 Java 对象 (POJOs)
    一起工作* 中所学到的。
- en: This starts the AutoML model training process. Some `print` statements will
    help you observe the progress and results of the model training process.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这启动了 AutoML 模型训练过程。一些 `print` 语句将帮助你观察模型训练过程的进度和结果。
- en: 'Once the model training process is done, the script will retrieve the leader
    model and download it as a POJO with the correct name – that is, `WineColorPredictor`
    – and place it in the `tmp` directory:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练过程完成后，脚本将检索主模型并将其作为具有正确名称的 POJO（即 `WineColorPredictor`）下载，并将其放置在 `tmp` 目录中：
- en: '[PRE7]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, the script will do the same for the next model – that is, the regression
    model – to predict the quality of the wine. It slightly tweaks the label and sets
    it to `quality`. The rest of the steps are the same:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，脚本将对下一个模型（即回归模型）做同样的事情，以预测葡萄酒的质量。它稍微调整了标签并将其设置为 `quality`。其余步骤相同：
- en: '[PRE8]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Once the training is finished, the script will extract the leader model, name
    it `WineQualityPredictor`, and download it as a POJO in the `tmp` directory:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练完成后，脚本将提取主模型，将其命名为 `WineQualityPredictor`，并将其作为 POJO 下载到 `tmp` 目录中：
- en: '[PRE9]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now that we have both model POJOs downloaded, we need to move them to the `src/main/java/com.h2o_wine_predictor.demo/model/`
    directory. But before we do that, we will also need to add the POJOs to the `com.h2o.wine_predictor.demo`
    package so that the `PredictionService.java` file can import the models. So, the
    script does this by creating a new file, adding the package inclusion instruction
    line to the file, appending the rest of the original POJO file, and saving the
    file in the `src/main/java/com.h2o_wine_predictor.demo/model/` directory:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经下载了两个模型 POJO，我们需要将它们移动到 `src/main/java/com.h2o_wine_predictor.demo/model/`
    目录。但在我们这样做之前，我们还需要将 POJO 添加到 `com.h2o.wine_predictor.demo` 包中，以便 `PredictionService.java`
    文件可以导入模型。因此，脚本通过创建一个新文件，将包包含指令行添加到文件中，附加原始 POJO 文件的其余部分，并将文件保存在 `src/main/java/com.h2o_wine_predictor.demo/model/`
    目录中来实现这一点：
- en: '[PRE10]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'It does the same for the `WineQualityPredictor` model:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它对 `WineQualityPredictor` 模型也做了同样的事情：
- en: '[PRE11]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, it deletes the `tmp` directory to clean everything up:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，它删除 `tmp` 目录以清理所有内容：
- en: '[PRE12]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'So, let’s run this script and generate our models. You can do so by executing
    the following command in your Terminal:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们运行这个脚本并生成我们的模型。你可以在你的终端中执行以下命令来做到这一点：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This should generate the respective model POJO files in the `src/main/java/com.h2o_wine_predictor.demo/model/`
    directory.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该在 `src/main/java/com.h2o_wine_predictor.demo/model/` 目录中生成相应的模型 POJO 文件。
- en: Now, let’s observe the `PredictionService` file in the `src/main/java/com.h2o_wine_predictor.demo/service`
    directory.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们观察位于 `src/main/java/com.h2o_wine_predictor.demo/service` 目录下的 `PredictionService`
    文件。
- en: 'The `PredictionService` class inside the `PredictionService` file has the following
    attributes:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`PredictionService` 文件中的 `PredictionService` 类具有以下属性：'
- en: '`wineColorPredictorModel`: This is an attribute of the `EasyPredictModelWrapper`
    type. It is a class from the h2o-genmodel library that is imported by the `PredictionService`
    file. We use this attribute to load the `WineColorPredictor` model that we just
    generated using `script.py`. We shall use this attribute to make predictions on
    the incoming request later.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wineColorPredictorModel`: 这是一个 `EasyPredictModelWrapper` 类型的属性。它是由 `PredictionService`
    文件导入的 h2o-genmodel 库中的类。我们使用此属性来加载我们刚刚使用 `script.py` 生成的 `WineColorPredictor`
    模型。我们将使用此属性来对后续的请求进行预测。'
- en: '`wineQualityPredictorModel`: Similar to `wineColorPredictorModel`, this is
    the wine quality equivalent attribute that uses the same `EasyPredictModelWrapper`.
    This attribute will be used to load the `WineQualityPredictor` model and use it
    to make predictions on the quality of the wine.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wineQualityPredictorModel`: 与 `wineColorPredictorModel` 类似，这是使用相同 `EasyPredictModelWrapper`
    的葡萄酒质量等效属性。此属性将用于加载 `WineQualityPredictor` 模型，并使用它来预测葡萄酒的质量。'
- en: 'Now that we understand the attributes of this file, let’s check out the methods,
    which are as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了这个文件的属性，让我们来看看方法，具体如下：
- en: '`createJsonResponse()`: This function is pretty straightforward in the sense
    that it takes the binomial classification prediction result from the `WineColorPredictor`
    model and the regression prediction result from the `WineQualityPredictor` model
    and combines them into a JSON response that the web application sends back to
    the client.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`createJsonResponse()`: 这个函数在意义上相当直接，它从 `WineColorPredictor` 模型的二项分类预测结果和 `WineQualityPredictor`
    模型的回归预测结果中获取，并将它们合并成一个 JSON 响应，该响应由网络应用程序发送回客户端。'
- en: '`predictColor()`: This function uses the `wineColorPredictorModel` attribute
    of the `PredictionService` class to make predictions on the data. It outputs the
    prediction result of the color of the wine as a `BinomialModelPrediction` object,
    which is a part of the h2o-genmodel library.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predictColor()`: 这个函数使用 `PredictionService` 类的 `wineColorPredictorModel` 属性对数据进行预测。它以
    `BinomialModelPrediction` 对象的形式输出葡萄酒颜色的预测结果，这是 h2o-genmodel 库的一部分。'
- en: '`predictQuality()`: This function uses the `wineQualityPredictorModel` attribute
    of the `PredictionService` class to make predictions on the data. It outputs the
    prediction result of the quality of the wine as a `RegressionModelPrediction`
    object, which is part of the h2o-genmodel library.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predictQuality()`: 这个函数使用 `PredictionService` 类的 `wineQualityPredictorModel`
    属性对数据进行预测。它以 `RegressionModelPrediction` 对象的形式输出葡萄酒质量的预测结果，这是 h2o-genmodel 库的一部分。'
- en: '`fillRowDataFromHttpRequest()`: This function is responsible for converting
    the feature values received from the POST request into a `RowData` object that
    will be passed to `wineQualityPredictorModel` and `wineColorPredictorModel` to
    make predictions. `RowData` is an object from the h2o-genmodel library.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fillRowDataFromHttpRequest()`: 这个函数负责将来自 POST 请求的特征值转换为 `RowData` 对象，该对象将被传递给
    `wineQualityPredictorModel` 和 `wineColorPredictorModel` 以进行预测。`RowData` 是 h2o-genmodel
    库中的一个对象。'
- en: '`getPrediction()`: This is called by `PredictionController`, which passes the
    feature values as a map to make predictions on. This function internally calls
    all the previously mentioned functions and orchestrates the entire prediction
    process:'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getPrediction()`: 这个函数由 `PredictionController` 调用，它将特征值作为映射传递以进行预测。此函数内部调用所有之前提到的函数，并协调整个预测过程：'
- en: It gets the feature values from the POST request as input. It passes these values,
    which are in the form of `Map` objects, to `fillRowDataFromHttpRequest()`, which
    converts them into the `RowData` type.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它从 POST 请求中获取特征值作为输入。它将这些值（以 `Map` 对象的形式）传递给 `fillRowDataFromHttpRequest()`，该函数将它们转换为
    `RowData` 类型。
- en: Then, it passes this `RowData` to the `predictColor()` and `predictQuality()`
    functions to get the prediction values.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它将此 `RowData` 传递给 `predictColor()` 和 `predictQuality()` 函数以获取预测值。
- en: Afterward, it passes these results to the `createJsonResponse()` function to
    create an appropriate JSON response with the prediction values and returns the
    JSON to `PredictionController`, where the controller returns it to the client.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它将这些结果传递给 `createJsonResponse()` 函数，以创建包含预测值的适当 JSON 响应，并将 JSON 返回给 `PredictionController`，控制器将其返回给客户端。
- en: Now that we have had a chance to go through the important parts of the whole
    project, let’s go ahead and run the application so that we can have the web service
    running locally on our machines. Then, we will run a simple `cURL` command with
    the wine quality feature values and see if we get the predictions as a response.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有机会了解整个项目的重要部分，让我们继续运行应用程序，以便我们可以在本地机器上运行 Web 服务。然后，我们将使用葡萄酒质量特征值运行一个简单的
    `cURL` 命令，看看我们是否得到响应。
- en: 'To start the application, you can do the following:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动应用程序，你可以执行以下操作：
- en: If you are using IntelliJ IDE, then you can directly click on the green play
    button in the top-right corner of the IDE.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你使用 IntelliJ IDE，则可以直接点击 IDE 右上角的绿色播放按钮。
- en: 'Alternatively, you can directly run it from your command line by executing
    the following command inside the project directory where the `pom.xml` file is:'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 或者，你可以在项目目录中直接运行它，该目录包含 `pom.xml` 文件，并执行以下命令：
- en: '[PRE14]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If everything is working fine, then you should get an output similar to the
    following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正常，你应该得到以下类似的输出：
- en: '![Figure 13.4 – Successful Spring Boot application run output ](img/B17298_13_004.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.4 – 成功的 Spring Boot 应用程序运行输出](img/B17298_13_004.jpg)'
- en: Figure 13.4 – Successful Spring Boot application run output
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.4 – 成功的 Spring Boot 应用程序运行输出
- en: Now that the Spring Boot application is running, the only thing remaining is
    to test this out by making a POST request call to the web service running on `localhost:8082`.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Spring Boot 应用程序正在运行，剩下的事情就是通过向运行在 `localhost:8082` 的 Web 服务发出 POST 请求调用来测试它。
- en: 'Open another Terminal and execute the following `curl` command to make a prediction
    request:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 打开另一个终端，并执行以下 `curl` 命令以发出预测请求：
- en: '[PRE15]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The request should go to the web application, where the application will extract
    the feature values, convert them into the `RowData` object type, pass `RowData`
    to the prediction function, get the prediction results, convert the prediction
    results into an appropriate `JSON`, and get the `JSON` back as a response. This
    should look as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 请求应发送到 Web 应用程序，应用程序将提取特征值，将它们转换为 `RowData` 对象类型，将 `RowData` 传递给预测函数，获取预测结果，将预测结果转换为适当的
    `JSON`，并将 `JSON` 作为响应返回。这应该看起来如下所示：
- en: '![Figure 13.5 – Prediction result from the Spring Boot web application ](img/B17298_13_005.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.5 – Spring Boot 网络应用程序的预测结果](img/B17298_13_005.jpg)'
- en: Figure 13.5 – Prediction result from the Spring Boot web application
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.5 – Spring Boot 网络应用程序的预测结果
- en: From the JSON response, you can see that the predicted color of the wine is
    `white` and that its quality is `5.32`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 从 JSON 响应中，你可以看到预测的葡萄酒颜色是 `white`，其质量是 `5.32`。
- en: Congratulations! You have just implemented an ML prediction service on a Spring
    Boot web application. You can further expand this service by adding a frontend
    that takes the feature values as input and a button that, upon being clicked,
    creates a POST body of all those values and sends the API request to the backend.
    Feel free to experiment with this project as there is plenty of scope for how
    you can use H2O model POJOs on a web service.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经在 Spring Boot 网络应用程序上实现了一个机器学习预测服务。你可以通过添加一个前端来进一步扩展此服务，该前端接受特征值作为输入，并添加一个按钮，点击该按钮将创建所有这些值的
    POST 主体，并将 API 请求发送到后端。请随意实验这个项目，因为你可以有很多方法在 Web 服务中使用 H2O 模型 POJO。
- en: In the next section, we’ll learn how to make real-time predictions using H2O
    AutoML, along with another interesting technology called Apache Storm.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习如何使用 H2O AutoML 和另一个有趣的技术 Apache Storm 进行实时预测。
- en: Using H2O AutoML and Apache Storm
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 H2O AutoML 和 Apache Storm
- en: '**Apache Storm** is an open source data analysis and computation tool for processing
    large amounts of stream data in real time. In the real world, you will often have
    plenty of systems that continuously generate large amounts of data. You may need
    to make some computations or run some processes on this data to extract useful
    information as it is generated in real time.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**Apache Storm** 是一个开源的数据分析和计算工具，用于实时处理大量流数据。在现实世界中，你经常会遇到许多系统持续生成大量数据。你可能需要对这些数据进行一些计算或运行一些过程，以便在实时生成时提取有用信息。'
- en: What is Apache Storm?
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apache Storm 是什么？
- en: Let’s take the example of a **log system** in a very heavily used web service.
    Assuming that this web service receives millions of requests per second, it is
    going to generate tons of logs. And you already have a system in place that stores
    these logs in your database. Now, this log data will eventually pile up and you
    will have petabytes of log data stored in your database. Querying all this historical
    data to process it in one go is going to be very slow and time-consuming.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个在非常繁忙的 Web 服务中使用的 **日志系统** 为例。假设这个 Web 服务每秒接收数百万个请求，它将生成大量的日志。您已经有一个系统来存储这些日志到您的数据库中。现在，这些日志数据最终会堆积起来，您将在数据库中存储数以PB计的日志数据。一次性查询所有这些历史数据来处理它将非常慢且耗时。
- en: What you can do is process the data as it is generated. This is where Apache
    Storm comes into play. You can configure your Apache Storm application to perform
    the needed processing and direct your log data to flow through it and then store
    it in your database. This will streamline the processing, making it real-time.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以做到的是在数据生成时处理数据。这正是 Apache Storm 发挥作用的地方。您可以将您的 Apache Storm 应用程序配置为执行所需的处理，并将您的日志数据引导通过它，然后存储到您的数据库中。这将简化处理过程，使其成为实时处理。
- en: Apache Storm can be used for multiple use cases, such as real-time analytics,
    **Extract-Transform-Load** (**ETL**) data in data pipelines, and even ML. What
    makes Apache Storm the go-to solution for real-time processing is because of how
    fast it is. A benchmarking test performed by the Apache Foundation found Apache
    Storm to process around a million tuples per second per node. Apache Storm is
    also very scalable and fault-tolerant, which guarantees that it will process all
    the incoming real-time data.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Storm 可用于多种用例，例如实时分析、数据管道中的 **提取-转换-加载**（**ETL**）数据，甚至机器学习（ML）。使 Apache
    Storm 成为实时处理首选解决方案的原因在于它的速度之快。Apache 基金会进行的一项基准测试发现，Apache Storm 每个节点每秒可以处理大约一百万个元组。Apache
    Storm 还非常可扩展和容错，这保证了它将处理所有传入的实时数据。
- en: So, let’s dive deep into the architecture of Apache Storm to understand how
    it works.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们深入探讨 Apache Storm 的架构，以了解它是如何工作的。
- en: Understanding the architecture of Apache Storm
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解 Apache Storm 的架构
- en: 'Apache Storm uses cluster computing, similar to how **Hadoop** and even H2O
    work. Consider the following architectural diagram of Apache Storm:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Storm 使用集群计算，类似于 **Hadoop** 和 H2O 的工作方式。考虑以下 Apache Storm 的架构图：
- en: '![Figure 13.6 – Architecture of Apache Storm ](img/B17298_13_006.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.6 – Apache Storm 架构](img/B17298_13_006.jpg)'
- en: Figure 13.6 – Architecture of Apache Storm
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6 – Apache Storm 架构
- en: 'Apache Storm distinguishes the nodes in its cluster into two categories – a
    master node and a worker node. The features of these nodes are as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Storm 将其集群中的节点分为两类 – 主节点和工节点。这些节点的特性如下：
- en: '**Master Node**: The master node runs a special daemon called **Nimbus**. The
    Nimbus daemon is responsible for distributing the data among all the worker nodes
    in the cluster. It also monitors failures and will resend the data to other nodes
    once a failure is detected, ensuring that no data is left out of processing.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主节点**：主节点运行一个名为 **Nimbus** 的特殊守护进程。Nimbus 守护进程负责在集群中的所有工节点之间分配数据。它还监控故障，并在检测到故障后重新发送数据到其他节点，确保没有数据被遗漏处理。'
- en: '**Worker Node**: The worker nodes run a daemon called the **Supervisor**. The
    Supervisor daemon is the service that is constantly listening for work and starts
    or stops the underlying processes as necessary for the computation.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工节点**：工节点运行一个名为 **Supervisor** 的守护进程。Supervisor 守护进程是始终监听工作并根据计算需要启动或停止底层进程的服务。'
- en: The communication between the master node and the worker nodes using their respective
    daemons is done using the **Zookeeper cluster**. In short, the Zookeeper cluster
    is a centralized service that maintains configuration and synchronization services
    for stateless groups. In this scenario, the master node and the worker nodes are
    stateless and fast-failing services. All the state details are stored in the Zookeeper
    cluster. This is beneficial as keeping the nodes stateless helps with fault tolerance
    as the nodes can be brought back to life and they will start working as if nothing
    had happened.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点和工节点之间使用各自的守护进程进行通信，这是通过 **Zookeeper 集群** 实现的。简而言之，Zookeeper 集群是一个集中式服务，为无状态组维护配置和同步服务。在这种情况下，主节点和工节点是无状态且快速失败的服务。所有状态细节都存储在
    Zookeeper 集群中。这很有益，因为保持节点无状态有助于容错，因为节点可以被恢复并开始工作，就像什么都没发生过一样。
- en: Tip
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: If you are interested in understanding the various concepts and technicalities
    of Zookeeper, then feel free to explore it in detail at [https://zookeeper.apache.org/](https://zookeeper.apache.org/).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣，想了解Zookeeper的各种概念和技术细节，那么请自由地在其官网[https://zookeeper.apache.org/](https://zookeeper.apache.org/)上详细探索。
- en: 'Before we move on to the implementation part of Apache Storm, we need to be
    aware of certain concepts that are important to understand how Apache Storm works.
    The different concepts are as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续Apache Storm的实现部分之前，我们需要了解某些重要概念，这些概念对于理解Apache Storm的工作方式至关重要。不同的概念如下：
- en: '**Tuples**: Apache Storm uses a data model called Tuple as its primary unit
    of data that is to be processed. It is a named list of values and can be an object
    of any type. Apache Storm supports all primitive data types out of the box. But
    it can also support custom objects, which can be deserialized into primitive types.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元组（Tuples）**：Apache Storm使用一个称为元组的数据模型作为其要处理的主要数据单元。它是一个命名值列表，可以是任何类型的对象。Apache
    Storm支持所有原始数据类型。但它也可以支持自定义对象，这些对象可以被反序列化为原始类型。'
- en: '**Streams**: Streams are unbounded sequences of tuples. A stream represents
    the path from where your data flows from one transformation to the next. The basic
    primitives that Apache Storm provides for doing these transformations are spouts
    and bolts:'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流（Streams）**：流是无界元组的序列。流表示你的数据从一处流向下一处转换的路径。Apache Storm提供的基本原语用于执行这些转换是喷泉和螺栓：'
- en: '**Spouts**: A spout is a source for a stream. It is at the start of the stream
    from where it reads the data from the outside world. It takes this data from the
    outside world and sends it to a bolt.'
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**喷泉（Spouts）**：喷泉是流的来源。它是流的起点，从这里读取来自外部世界的数据。它从外部世界获取这些数据并将其发送到螺栓。'
- en: '**Bolt**: A bolt is a process that consumes data from single or multiple streams,
    transforms or processes it, and then outputs the result. You can link multiple
    bolts one after the other while feeding the output of one bolt as input to the
    next to perform complex processing. Bolts can run functions, filter data, perform
    aggregation, and even store data in databases. You can perform any kind of functionality
    you want on a bolt.'
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**螺栓（Bolt）**：螺栓是一个从单个或多个流中消耗数据、对其进行转换或处理，然后输出结果的过程。你可以在连续的流中链接多个螺栓，将一个螺栓的输出作为下一个螺栓的输入，以执行复杂的处理。螺栓可以运行函数、过滤数据、执行聚合，甚至可以将数据存储在数据库中。你可以在螺栓上执行任何你想要的功能。'
- en: '**Topologies**: The entire orchestration of how data will be processed in real
    time using streams, spouts, and bolts in the form of a **Directed Acyclic Graph**
    (**DAG**) is called a **topology**. You need to submit this topology to the Nimbus
    daemon using the main function of Apache Storm. The topology graph contains nodes
    and edges, just like a regular graph structure. Each node contains processing
    logic and each edge shows how data is to be transferred between two nodes. Both
    the Nimbus and the topology are **Apache Thrift** structures, which are special
    type systems that allow programmers to use native types in any programming language.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拓扑（Topologies）**：使用流、喷泉和螺栓以**有向无环图（DAG**）的形式实时处理数据的整个编排过程称为**拓扑**。你需要使用Apache
    Storm的主函数将此拓扑提交给Nimbus守护进程。拓扑图包含节点和边，就像常规的图结构一样。每个节点包含处理逻辑，每条边显示数据如何在两个节点之间传输。Nimbus和拓扑都是**Apache
    Thrift**结构，这是一种特殊的类型系统，允许程序员在任何编程语言中使用本地类型。'
- en: Tip
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示**'
- en: You can learn more about Apache Thrift by going to [https://thrift.apache.org/docs/types](https://thrift.apache.org/docs/types).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过访问[https://thrift.apache.org/docs/types](https://thrift.apache.org/docs/types)来了解更多关于Apache
    Thrift的信息。
- en: Now that you have a better understanding of what Apache Storm is and the various
    concepts involved in its implementation, we can move on to the implementation
    part of this section, starting with installing Apache Storm.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经更好地理解了Apache Storm是什么以及其实施中涉及的各种概念，我们可以继续本节的实现部分，从安装Apache Storm开始。
- en: Tip
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示**'
- en: Apache Storm is a very powerful and sophisticated system. It has plenty of applicability
    outside of just machine learning and also has plenty of features and support.
    If you want to learn more about Apache Storm, go to [https://storm.apache.org/](https://storm.apache.org/).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Storm是一个非常强大且复杂的系统。它不仅在机器学习之外有广泛的应用，而且还有许多特性和支持。如果你想了解更多关于Apache Storm的信息，请访问[https://storm.apache.org/](https://storm.apache.org/)。
- en: Installing Apache Storm
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装Apache Storm
- en: 'Let’s start by noting down the basic requirements for installing Apache Storm.
    They are as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先记下安装 Apache Storm 的基本要求。它们如下：
- en: Java version greater than Java 8
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java 版本大于 Java 8
- en: The latest version of Maven, preferably version 3.8.6
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最新的 Maven 版本，最好是 3.8.6 版
- en: So, make sure these basic requirements are already installed on your system.
    Now, let’s start by downloading the Apache Storm repo. You can find the repo at
    [https://github.com/apache/storm](https://github.com/apache/storm).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，请确保这些基本要求已经安装到您的系统上。现在，让我们先下载 Apache Storm 仓库。您可以在 [https://github.com/apache/storm](https://github.com/apache/storm)
    找到该仓库。
- en: 'So, execute the following command to clone the repository to your system:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，执行以下命令以将存储库克隆到您的系统：
- en: '[PRE16]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Once the download is finished, you can open the `storm` folder to get a glimpse
    of its contents. You will notice that there are tons of files, so it can be overwhelming
    when you’re trying to figure out where to start. Don’t worry – we’ll work on very
    simple examples that should be enough to give you a basic idea of how Apache Storm
    works. Then, you can branch out from there to get a better understanding of what
    Apache Storm has to offer.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 下载完成后，您可以打开 `storm` 文件夹，一窥其内容。您会注意到有很多文件，所以在试图弄清楚从哪里开始时可能会感到不知所措。别担心——我们将通过非常简单的示例来工作，这些示例应该足以让您对
    Apache Storm 的工作方式有一个基本的了解。然后，您可以从那里分支出去，以更好地了解 Apache Storm 提供的内容。
- en: Now, open your Terminal and navigate to the cloned repo. You will need to locally
    build Apache Storm itself before you can go about implementing any of the Apache
    Storm features. You need to do this as locally building Apache Storm generates
    important JAR files that get installed in your `$HOME/.m2/repository` folder.
    This is the folder where Maven will pick up the JAR dependencies when you build
    your Apache Storm application.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，打开您的终端并导航到克隆的仓库。在您开始实现任何 Apache Storm 功能之前，您需要本地构建 Apache Storm 本身。您需要这样做，因为本地构建
    Apache Storm 会生成重要的 JAR 文件，这些文件将被安装到您的 `$HOME/.m2/repository` 文件夹中。这是 Maven 在构建您的
    Apache Storm 应用程序时将检索 JAR 依赖项的文件夹。
- en: 'So, locally build Apache Storm by executing the following command at the root
    of the repository:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在仓库根目录下执行以下命令以本地构建 Apache Storm：
- en: '[PRE17]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The build might take some time, considering that Maven will be building several
    JAR files that are important dependencies to your application. So, while that
    is happening, let’s understand the problem statement that we will be working on.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 构建可能需要一些时间，因为 Maven 将构建几个对您的应用程序重要的 JAR 文件。所以，当这个过程中发生时，让我们了解我们将要工作的问题描述。
- en: Understanding the problem statement
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解问题描述
- en: Let’s assume you are working for a medical company. The medical officials have
    a requirement, where they want to create a system that predicts whether the person
    is likely to suffer from any complications after surviving a heart failure or
    whether they are safe to be discharged. The catch is that this prediction service
    will be used by all the hospitals in the country, and they need immediate prediction
    results so that the doctors can decide whether to keep the patient admitted for
    a few days to monitor their health or decide to discharge them.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您在一家医疗公司工作。医疗官员有一个要求，他们希望创建一个系统，预测一个人在心脏病发作后是否可能遭受任何并发症，或者他们是否可以安全出院。难点在于这个预测服务将用于全国的所有医院，他们需要立即的预测结果，以便医生可以决定是否将患者留院观察几天以监测他们的健康状况，或者决定让他们出院。
- en: So, the machine learning problem is that there will be streams of data that
    our system will need to make immediate predictions. We can set up a Apache Storm
    application that streams all the data into the prediction service and deploys
    model POJOs trained using H2O AutoML to make the predictions.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，机器学习问题在于将会有数据流进入我们的系统，系统需要立即做出预测。我们可以设置一个 Apache Storm 应用程序，将所有数据流输入到预测服务中，并部署使用
    H2O AutoML 训练的模型 POJO 来进行预测。
- en: We can train the models on the Heart Failure Clinical dataset, which can be
    found at [https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records](https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在心脏衰竭临床数据集上训练模型，该数据集可在 [https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records](https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records)
    找到。
- en: 'The following screenshot shows some sample content from the dataset:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了数据集的一些示例内容：
- en: '![Figure 13.7 – Heart Failure Clinical dataset ](img/B17298_13_007.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.7 – 心脏衰竭临床数据集](img/B17298_13_007.jpg)'
- en: Figure 13.7 – Heart Failure Clinical dataset
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7 – 心脏衰竭临床数据集
- en: 'This dataset consists of the following features:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集包含以下特征：
- en: '**age**: This feature indicates the age of the patient in years'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**年龄**：此功能表示患者的年龄，单位为年'
- en: '`1` indicates yes and `0` indicates no'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1` 表示是，`0` 表示否'
- en: '`1` indicates yes and `0` indicates no'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1` 表示是，`0` 表示否'
- en: '**creatinine phosphokinase**: This feature indicates the level of the CPK enzyme
    in the blood in **micrograms per liter** (**mcg/L**)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**肌酸激酶**：此功能表示血液中 CPK 酶的水平，单位为每升**微克**（**mcg/L**）'
- en: '`1` indicates yes and `0` indicates no'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1` 表示是，`0` 表示否'
- en: '**ejection fraction**: This feature indicates the percentage of blood leaving
    the heart at each contraction'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**射血分数**：此功能表示每次收缩时心脏排出的血液百分比'
- en: '**platelets**: This feature indicates the platelets in the blood in kilo platelets
    per **milliliter** (**ml**)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**血小板**：此功能表示血液中的血小板，单位为每毫升**千血小板**（**ml**）'
- en: '`1` indicates the patient is a woman and `0` indicates the patient is a man'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1` 表示患者为女性，`0` 表示患者为男性'
- en: '**serum creatinine**: This feature indicates the level of serum creatinine
    in the blood in **milligrams per deciliter** (**mg/dL**)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**血清肌酐**：此功能表示血液中血清肌酐的水平，单位为每毫升**毫克**（**mg/dL**）'
- en: '**serum sodium**: This feature indicates the level of serum sodium in the blood
    **milliequivalent per liter** (**mEq/L**)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**血清钠**：此功能表示血液中血清钠的水平，单位为每升**毫当量**（**mEq/L**）'
- en: '`1` indicates yes and `0` indicates no'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1` 表示是，`0` 表示否'
- en: '**time**: This feature indicates the number of follow-ups in days'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间**：此功能表示随访天数'
- en: '`1` indicates yes and `0` indicates no'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1` 表示是，`0` 表示否'
- en: Now that we understand the problem statement and the dataset that we will be
    working with, let’s design the architecture of how we can use Apache Storm and
    H2O AutoML to solve this problem.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了问题陈述以及我们将要处理的数据集，让我们设计如何使用 Apache Storm 和 H2O AutoML 解决这个问题的架构。
- en: Designing the architecture
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计架构
- en: 'Let’s look at the overall architecture of how all the technologies should work
    together. Refer to the following architecture diagram of the heart failure complication
    prediction service:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看所有技术如何协同工作的整体架构。参考以下心脏衰竭并发症预测服务架构图：
- en: '![Figure 13.8 – Architecture diagram of using H2O AutoML with Apache Storm
    ](img/B17298_13_008.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.8 – 使用 H2O AutoML 与 Apache Storm 的架构图](img/B17298_13_008.jpg)'
- en: Figure 13.8 – Architecture diagram of using H2O AutoML with Apache Storm
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.8 – 使用 H2O AutoML 与 Apache Storm 的架构图
- en: 'Let’s understand the various components of the architecture:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解架构的各个组成部分：
- en: '`script.py`: From an architectural point of view, the solution is pretty simple.
    First, we train the models using H2O AutoML, which can be easily done by using
    this script, which imports the dataset, sets the label and features, and runs
    AutoML. The leader model can then be extracted as a POJO, which we can later use
    in Apache Storm to make predictions.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`script.py`：从架构角度来看，解决方案相当简单。首先，我们使用 H2O AutoML 训练模型，这可以通过使用此脚本轻松完成，该脚本导入数据集，设置标签和特征，并运行
    AutoML。然后可以提取领先模型作为 POJO，我们可以在 Apache Storm 中使用它进行预测。'
- en: '**Data Spout**: We will have a spout in Apache Storm that constantly reads
    data and passes it to the **Prediction Bolt** in real time.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据喷泉**：在 Apache Storm 中，我们将有一个喷泉，它将不断读取数据并将其实时传递给**预测螺栓**。'
- en: '**Prediction Bolt**: This bolt contains the prediction service that imports
    the trained model POJO and uses it to make predictions.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测螺栓**：此螺栓包含预测服务，它导入训练好的模型 POJO 并使用它进行预测。'
- en: '**Classification Bolt**: The results from the Prediction Bolt are passed to
    this bolt. This bolt classifies the results as potential complications and no
    complications based on the binary classification result from the Prediction Bolt.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类螺栓**：预测螺栓的结果传递给此螺栓。此螺栓根据预测螺栓的二分类结果将结果分类为潜在并发症和无并发症。'
- en: Now that we have designed a simple and good solution, let’s move on to its implementation.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设计了一个简单且良好的解决方案，让我们继续其实现。
- en: Working on the implementation
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在实现上工作
- en: This service is already available on GitHub. The code base can be found at [https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_apache_storm/h2o_storm](https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_apache_storm/h2o_storm).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 此服务已在GitHub上提供。代码库可以在[https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_apache_storm/h2o_storm](https://github.com/PacktPublishing/Practical-Automated-Machine-Learning-on-H2O/tree/main/Chapter%2013/h2o_apache_storm/h2o_storm)找到。
- en: So, download the repo and navigate to `/Chapter 13/h2o_apache_storm/h2o_storm/`.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，下载仓库并导航到`/Chapter 13/h2o_apache_storm/h2o_storm/`。
- en: 'You will see that we have two folders. One is the `storm-starter` directory,
    while the other is the `storm-streaming` directory. Let’s focus on the `storm-streaming`
    directory first. Start your IDE and open the `storm-streaming` project. Once you
    open the project, you should see a directory structure similar to the following:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到我们有两个文件夹。一个是`storm-starter`目录，另一个是`storm-streaming`目录。让我们首先关注`storm-streaming`目录。启动你的IDE并打开`storm-streaming`项目。一旦打开项目，你应该会看到一个类似于以下目录结构：
- en: '![Figure 13.9 – storm_streaming directory structure ](img/B17298_13_009.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图13.9 – storm_streaming目录结构](img/B17298_13_009.jpg)'
- en: Figure 13.9 – storm_streaming directory structure
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.9 – storm_streaming目录结构
- en: 'This directory structure consists of the following important files:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 此目录结构包含以下重要文件：
- en: '`scripty.py`: This is the Python script that we will use to train our models
    on the heart failure complication dataset. The script starts an H2O server instance,
    imports the dataset, and then runs AutoML to train the models. We shall look at
    this in more detail later.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scripty.py`：这是我们将在心脏衰竭并发症数据集上训练模型的Python脚本。脚本启动H2O服务器实例，导入数据集，然后运行AutoML来训练模型。我们将在稍后详细探讨这一点。'
- en: '`H2ODataSpout.java`: This is the Java file that contains the Apache Storm spout
    and its functionality. It reads the data from the `live_data.csv` file and forwards
    individual observations one at a time to the bolts, simulating the real-time flow
    of data.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`H2ODataSpout.java`：这是一个Java文件，其中包含Apache Storm spout及其功能。它从`live_data.csv`文件中读取数据，并将单个观测值逐个转发到bolt，模拟数据的实时流动。'
- en: '`H2OStormStarter.java`: This is a Java file that contains the Apache Storm
    topology with the two bolts – the Prediction Bolt and Classification Bolt classes.
    We shall start our Apache Storm service using this file.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`H2OStormStarter.java`：这是一个Java文件，其中包含Apache Storm拓扑以及两个bolt类 – 预测bolt和分类bolt。我们将使用此文件启动我们的Apache
    Storm服务。'
- en: '`training_data.csv`: This is the dataset that contains a part of the heart
    failure complication data that we will be using to train our models.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`training_data.csv`：这是我们用来训练模型的包含部分心脏衰竭并发症数据的数据集。'
- en: '`live_data.csv`: This is the dataset that contains the heart failure complication
    data that we will be using to simulate the real-time inflow of data into our Apache
    Storm application.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`live_data.csv`：这是我们用来模拟Apache Storm应用程序实时数据流入的心脏衰竭并发症数据集。'
- en: Unlike the previous experiments, where we made changes in a separate application
    repository, for this experiment, we shall make changes in Apache Storm’s repository.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前在单独的应用程序仓库中做更改的实验不同，对于这次实验，我们将在Apache Storm的仓库中做更改。
- en: The following steps have been performed on *Ubuntu 22.04 LTS*; *IntelliJ IDEA
    version 2022.1.4* has been used as the IDE. Feel free to use any IDE of your choice
    that supports the Maven framework for better support.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤已在*Ubuntu 22.04 LTS*上执行；*IntelliJ IDEA版本2022.1.4*已被用作IDE。请随意使用任何支持Maven框架的IDE，以获得更好的支持。
- en: 'Let’s start by understanding the model training script, `script.py`. The code
    for `script.py` is as follows:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先了解模型训练脚本`script.py`。`script.py`的代码如下：
- en: 'First, the script imports the dependencies:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，脚本导入依赖项：
- en: '[PRE18]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Once importing is done, the H2O server is initialized:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入完成后，H2O服务器被初始化：
- en: '[PRE19]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Once the H2O server is up and running, the script imports the `training_data.csv`
    file:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦H2O服务器启动并运行，脚本将导入`training_data.csv`文件：
- en: '[PRE20]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now that the DataFrame has been imported, we can begin the training process
    for training the models using AutoML. So, the script sets the label and features,
    as follows:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在DataFrame已经导入，我们可以开始使用AutoML对模型进行训练过程。因此，脚本设置了标签和特征，如下所示：
- en: '[PRE21]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we can create the H2O AutoML object and begin the model training:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以创建H2O AutoML对象并开始模型训练：
- en: '[PRE22]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Since POJOs are not supported for stacked ensemble models, we set the `exclude_algos`
    parameter with the `StackedEnsemble` value.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 由于POJO不支持堆叠集成模型，我们使用`StackedEnsemble`值设置`exclude_algos`参数。
- en: This starts the AutoML model training process. Some `print` statements are in
    here that will help you observe the progress and results of the model training
    process.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这启动了AutoML模型训练过程。这里有一些`print`语句，它们将帮助您观察模型训练过程的进度和结果。
- en: 'Once the model training process is done, the script retrieves the leader model
    and downloads it as a POJO with the correct name – that is, `HeartFailureComplications`
    – and places it in the `tmp` directory:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型训练过程完成，脚本检索主模型，并以正确的名称（即`HeartFailureComplications`）将其作为POJO下载，并将其放置在`tmp`目录中：
- en: '[PRE23]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'So, let’s run this script and generate our model. Executing the following command
    in your Terminal:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们运行这个脚本并生成我们的模型。在您的终端中执行以下命令：
- en: '[PRE24]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This should generate the respective model POJO files in the `tmp` directory.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该在`tmp`目录中生成相应的模型POJO文件。
- en: 'Now, let’s investigate the next file in the repository: `H2ODataSpout.java`.
    The `H2ODataSpout` class in the Java file has a few attributes and functions that
    are important for building the Apache Storm applications. We won’t focus on them
    much, but let’s have a look at the functions that do play a bigger role in the
    business logic of the applications. They are as follows:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们调查仓库中的下一个文件：`H2ODataSpout.java`。Java文件中的`H2ODataSpout`类有几个属性和函数，对于构建Apache
    Storm应用程序非常重要。我们不会过多关注它们，但让我们看看在应用程序的业务逻辑中扮演更大角色的函数。它们如下：
- en: '`nextTuple()`: This function contains the logic of reading the data from the
    `live_data.csv` file and emits the data row by row to the Prediction Bolt. Let’s
    have a quick look at the code:'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nextTuple()`: 这个函数包含从`live_data.csv`文件读取数据的逻辑，并将数据行行地发送到Prediction Bolt。让我们快速看一下代码：'
- en: 'First, you have the sleep timer. Apache Storm, as we know, is a super-fast
    real-time data processing system. Observing our live data flowing through the
    system will be difficult for us, so the `sleep` function ensures that there is
    a delay of 1,000 milliseconds so that we can easily observe the flow of data and
    see the results:'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，你有睡眠计时器。众所周知，Apache Storm是一个超级快速的现实数据处理系统。观察我们的实时数据通过系统对我们来说将是困难的，所以`sleep`函数确保有1,000毫秒的延迟，这样我们就可以轻松观察数据的流动并看到结果：
- en: '[PRE25]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The function then instantiates the `live_data.csv` file into the program:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后该函数将`live_data.csv`文件实例化到程序中：
- en: '[PRE26]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The code then declares the `observation` variable. This is nothing but the
    individual row data that will be read and stored in this variable by the spout:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后代码声明了`observation`变量。这仅仅是将被读取并存储在这个变量中的单个行数据，由spout读取：
- en: '[PRE27]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Then, we have the logic where the spout program reads the row in the data.
    Which row to read is decided by the `_cnt` atomic integer, which gets incremented
    as the spout reads and emits the row to the Prediction Bolt in an infinite loop.
    This infinite loop simulates the continuous flow of data, despite `live_data.csv`
    containing only limited data:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们有逻辑，其中spout程序读取数据中的行。读取哪一行是由`_cnt`原子整数决定的，它在spout读取并将行发送到Prediction Bolt的无限循环中时递增。这个无限循环模拟了数据的连续流动，尽管`live_data.csv`只包含有限的数据：
- en: '[PRE28]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Then, we have the atomic number increment so that the next iteration picks
    up the next row in the data:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们有原子数递增，以便下一次迭代可以获取数据中的下一行：
- en: '[PRE29]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Finally, we have the `_collector.emit()` function, which emits the row data
    so that it’s stored in `_collector`, which, in turn, is consumed by the Prediction
    Bolt:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们有`_collector.emit()`函数，它发出行数据，以便将其存储在`_collector`中，然后`_collector`被Prediction
    Bolt消费：
- en: '[PRE30]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '`declareOutputFields()`: In this method, we declare the headers of our data.
    We can extract and use the headers from our trained AutoML model POJO using its
    `NAMES` attribute:'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`declareOutputFields()`: 在这个方法中，我们声明了我们的数据头。我们可以使用训练好的AutoML模型POJO的`NAMES`属性来提取和使用这些头：'
- en: '[PRE31]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '*Other miscellaneous functions*: The remaining `open()`, `close()`, `ack()`,
    `fail()`, and `getComponentConfiguration()` functions are supportive functions
    for error handling and preprocessing or postprocessing activities that you might
    want to do in the spout. To keep this experiment simple, we won’t dwell on them
    too much.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*其他杂项函数*：剩余的`open()`、`close()`、`ack()`、`fail()`和`getComponentConfiguration()`函数是用于错误处理和预处理或后处理活动的辅助函数。为了使这个实验简单，我们不会过多地探讨它们。'
- en: 'Moving on, let’s investigate the `H2OStormStarter.java` file. This file contains
    both bolts that are needed for performing the predictions and classification,
    as well as the `h2o_storm()` function, which builds the Apache Storm topology
    and passes it onto the Apache Storm cluster. Let’s dive deep into the individual
    attributes:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们调查`H2OStormStarter.java`文件。此文件包含执行预测和分类所需的两个bolt，以及构建Apache Storm拓扑并将其传递给Apache
    Storm集群的`h2o_storm()`函数。让我们深入了解各个属性：
- en: '`class PredictionBolt`: This is the `Bolt` class and is responsible for obtaining
    the class probabilities of the heart failure complication dataset. It imports
    the H2O model POJO and uses it to calculate the class probabilities of the incoming
    row data. It has three functions – `prepare()`, `execute()` and `declareOutputFields()`.
    We shall only focus on the `execute` function since it contains the execution
    logic of the bolt; the rest are supportive functions. The `execute` function contains
    the following code:'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class PredictionBolt`：这是一个`Bolt`类，负责获取心脏衰竭并发症数据集的类别概率。它导入H2O模型POJO并使用它来计算传入行数据的类别概率。它有三个函数
    – `prepare()`、`execute()`和`declareOutputFields()`。我们只关注`execute`函数，因为它包含bolt的执行逻辑；其余的都是辅助函数。`execute`函数包含以下代码：'
- en: 'The very first thing this function does is import the H2O model POJO:'
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此函数首先执行的操作是导入H2O模型POJO：
- en: '[PRE32]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Then, it extracts the input tuple values from its parameter variables and stores
    them in the `raw_data` variable:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它从其参数变量中提取输入元组值并将它们存储在`raw_data`变量中：
- en: '[PRE33]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Next, the code categorically maps all the categorical data in the row:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，代码将行中的所有分类数据分类映射：
- en: '[PRE34]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Then, the code gets the prediction and emits the results:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，代码获取预测并发出结果：
- en: '[PRE35]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Finally, the code acknowledges the tuple so that the spout is informed about
    its consumption and won’t resend the tuple for retry:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，代码确认了元组，以便spout知道其消费情况，不会为重试重新发送元组：
- en: '[PRE36]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '`Bolt` class also has some supportive functions, along with the main `execute()`
    function. Let’s dive deep into this to understand what is going on in the function:'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Bolt`类也有一些辅助函数，以及主要的`execute()`函数。让我们深入了解这个函数，以了解函数中发生了什么：'
- en: 'The function simply computes if there is a possibility of *Possible Complication*
    or *No Complications* based on the `_threshold` value and emits the result back:'
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数简单地根据`_threshold`值计算是否存在*可能的并发症*或*无并发症*的可能性，并将结果发送回去：
- en: '[PRE37]'
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '`h2o_storm()`: This is the main function of the application and builds the
    topology using `H2ODataSpout` and the two bolts – Prediction Bolt and Classifier
    Bolt. Let’s have a deeper look into its functionality.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`h2o_storm()`：这是应用程序的主要函数，使用`H2ODataSpout`和两个bolt（预测bolt和分类bolt）构建拓扑。让我们深入了解其功能。'
- en: 'First, the function instantiates `TopologyBuilder()`:'
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，函数实例化`TopologyBuilder()`：
- en: '[PRE38]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Using this object, it builds the topology by setting the spout and the bolts,
    as follows:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用此对象，它通过设置spout和bolt来构建拓扑，如下所示：
- en: '[PRE39]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Apache Storm also needs some configuration data to set up its cluster. Since
    we are creating a simple example, we can just use the default configurations,
    as follows:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Apache Storm也需要一些配置数据来设置其集群。由于我们正在创建一个简单的示例，我们可以直接使用默认配置，如下所示：
- en: '[PRE40]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Finally, it creates a cluster and submits the topology it created, along with
    the configuration:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，它创建一个集群并提交它创建的拓扑以及配置：
- en: '[PRE41]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'After that, there are some functions to wrap the whole experiment together.
    The `Util.sleep()` function is used to pause for an hour so that Apache Storm
    can loop over the functionality indefinitely while simulating a continuous flow
    of real-time data. The `cluster.killTopology()` function kills the `HeartComplicationPredictor`
    topology, which stops the simulation in the cluster. Finally, the `cluster.shutdown()`
    function brings down the Apache Storm cluster, freeing up the resources:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，有一些函数将整个实验封装在一起。`Util.sleep()`函数用于暂停一小时，以便Apache Storm可以无限循环功能，同时模拟实时数据的连续流动。`cluster.killTopology()`函数终止`HeartComplicationPredictor`拓扑，停止集群中的模拟。最后，`cluster.shutdown()`函数关闭Apache
    Storm集群，释放资源：
- en: '[PRE42]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now that we have a better understanding of the contents of the files and how
    we are going to be running our service, let’s proceed and look at the contents
    of the `storm-starter` project. The directory structure will be as follows:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经更好地理解了文件的内容以及我们将如何运行我们的服务，让我们继续并查看`storm-starter`项目的目录结构。结构如下：
- en: '![Figure 13.10 – storm-starter directory structure ](img/B17298_13_010.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.10 – storm-starter 目录结构](img/B17298_13_010.jpg)'
- en: Figure 13.10 – storm-starter directory structure
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.10 – storm-starter 目录结构
- en: The `src` directory contains several different types of Apache Storm topology
    samples that you can choose to experiment with. I highly recommend that you do
    so as that will help you get a better understanding of how versatile Apache Storm
    is when it comes to configuring your streaming service for different needs.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '`src` 目录包含几种不同类型的 Apache Storm 拓扑示例，你可以选择进行实验。我强烈建议你这样做，因为这将帮助你更好地理解 Apache
    Storm 在配置不同需求的流服务时的多功能性。'
- en: However, we shall perform this experiment in the `test` directory to keep our
    files isolated from the ones in the `src` directory. So, let’s see how we can
    run this experiment.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们将在这个 `test` 目录中执行这个实验，以保持我们的文件与 `src` 目录中的文件隔离。那么，让我们看看我们如何运行这个实验。
- en: 'Follow these steps to build and run the experiment:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤构建和运行实验：
- en: 'In the `storm-streaming` directory, run the `script.py` file to generate the
    H2O model POJO. The script should run H2O AutoML and generate a leaderboard. The
    leader model will be extracted, renamed `HeartFailureComplications`, and downloaded
    as a POJO. Run the following command in your Terminal:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `storm-streaming` 目录中，运行 `script.py` 文件以生成 H2O 模型 POJO。脚本应该运行 H2O AutoML 并生成一个排行榜。领先模型将被提取，重命名为
    `HeartFailureComplications`，并作为 POJO 下载。在你的终端中运行以下命令：
- en: '[PRE43]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The `HeartFailureComplications` POJO will be imported by the other files in
    the `storm-starter` project, so to ensure that it can be correctly imported by
    files in the same package, we need to add this POJO to that same package. So,
    modify the POJO file to add the `storm.starter` package as the first line.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`HeartFailureComplications` POJO 将被 `storm-starter` 项目的其他文件导入，因此为了确保它可以被同一包中的文件正确导入，我们需要将这个
    POJO 添加到同一个包中。因此，修改 POJO 文件，将 `storm.starter` 包作为第一行添加。'
- en: Now, move the `HeartFailureComplications` POJO file, the `H2ODataSpout.java`
    file, and the `H2OStormStarted.java` file inside the `storm-starter` repository
    inside its `storm-starter/test/jvm/org.apache.storm.starter` directory.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，将 `HeartFailureComplications` POJO 文件、`H2ODataSpout.java` 文件和 `H2OStormStarted.java`
    文件移动到 `storm-starter` 仓库内的 `storm-starter/test/jvm/org.apache.storm.starter` 目录中。
- en: 'Next, we need to import the `h2o-model.jar` file into the `storm-starter` project.
    We can do so by adding the following dependency to the `pom.xml` file of the experiment,
    as follows:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要将 `h2o-model.jar` 文件导入到 `storm-starter` 项目中。我们可以通过在实验的 `pom.xml` 文件中添加以下依赖项来实现，如下所示：
- en: '[PRE44]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Your directory should now look as follows:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 你的目录现在应该看起来如下所示：
- en: '![Figure 13.11 – storm-starter directory structure after file transfers ](img/B17298_13_011.jpg)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.11 – 文件传输后的 storm-starter 目录结构](img/B17298_13_011.jpg)'
- en: Figure 13.11 – storm-starter directory structure after file transfers
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.11 – 文件传输后的 storm-starter 目录结构
- en: 'Finally, we will run this project by right-clicking on the `H2OStormStarter.java`
    file and running it. You should get a stream of constant output that demonstrates
    your spout and bolt in action. This can be seen in the following screenshot:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将通过右键单击 `H2OStormStarter.java` 文件并运行它来运行此项目。你应该会得到一个显示你的 spout 和 bolt 作用的恒定输出流。这可以在以下屏幕截图中看到：
- en: '![Figure 13.12 – Heart complication prediction output in Apache Storm ](img/B17298_13_012.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.12 – Apache Storm 中的心脏并发症预测输出](img/B17298_13_012.jpg)'
- en: Figure 13.12 – Heart complication prediction output in Apache Storm
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.12 – Apache Storm 中的心脏并发症预测输出
- en: 'If you observe the results closely, you should see that there are executors
    in the logs; all the Apache Storm spouts and bolts are internal executor processes
    that run on the cluster. You will also see the prediction probabilities besides
    each tuple. This should look as follows:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细观察结果，你应该会看到日志中有执行者；所有的 Apache Storm spouts 和 bolts 都是运行在集群内部的内部执行进程。你还会看到每个元组旁边的预测概率。这应该看起来如下所示：
- en: '![Figure 13.13 – Heart complication prediction result ](img/B17298_13_013.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.13 – 心脏并发症预测结果](img/B17298_13_013.jpg)'
- en: Figure 13.13 – Heart complication prediction result
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.13 – 心脏并发症预测结果
- en: Congratulations – we have just covered another design pattern that shows us
    how we can use models trained using H2O AutoML to make real-time predictions on
    streaming data using Apache Storm. This concludes the last experiment of this
    chapter.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜 – 我们刚刚覆盖了另一个设计模式，它展示了我们如何使用 H2O AutoML 训练的模型，通过 Apache Storm 对流数据进行实时预测。这标志着本章最后一个实验的结束。
- en: Summary
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we focused on how we can implement models that have been trained
    using H2O AutoML in different scenarios using different technologies to make predictions
    on different kinds of data.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们关注了如何使用不同的技术在不同场景下实现使用H2O AutoML训练的模型，以便对各种数据进行预测。
- en: We started by implementing an AutoML leader model in a scenario where we tried
    to make predictions on data over a web service. We created a simple web service
    that was hosted on localhost using Spring Boot and the Apache Tomcat web server.
    We trained the model on data using AutoML, extracted the leader model as a POJO,
    and loaded that POJO as a class in the web application. By doing this, the application
    was able to use the model to make predictions on the data that it received as
    a POST request, responding with the prediction results.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个场景开始，在这个场景中，我们尝试在Web服务上对数据进行预测，并实现了AutoML领导者模型。我们创建了一个简单的Web服务，该服务使用Spring
    Boot和Apache Tomcat Web服务器在本地主机上托管。我们使用AutoML在数据上训练模型，提取领导者模型作为POJO，并将该POJO作为类加载到Web应用程序中。通过这样做，应用程序能够使用模型对作为POST请求接收到的数据进行预测，并返回预测结果。
- en: Then, we looked into another design pattern where we aimed to make predictions
    on real-time data. We had to implement a system that can simulate the real-time
    flow of data. We did this with Apache Storm. First, we dived deep into understanding
    what Apache Storm is, its architecture, and how it works by using spouts and bolts.
    Using this knowledge, we built a real-time data streaming application. We deployed
    our AutoML trained model in a Prediction Bolt where the Apache Storm application
    was able to use the model to make predictions on the real-time streaming data.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们探讨了另一种设计模式，我们的目标是预测实时数据。我们必须实现一个能够模拟实时数据流的系统。我们使用Apache Storm做到了这一点。首先，我们深入了解了Apache
    Storm是什么，它的架构以及它是如何通过使用spouts和bolts来工作的。利用这些知识，我们构建了一个实时数据流应用程序。我们将AutoML训练的模型部署在预测Bolt中，Apache
    Storm应用程序能够使用该模型对实时流数据进行预测。
- en: This concludes the final chapter of this book. There are still innumerable features,
    concepts, and design patterns that we can work with while using H2O AutoML. The
    more you experiment with this technology, the better you will get at implementing
    it. Thus, it is highly recommended that you keep experimenting with this technology
    and discover new ways of solving ML problems while automating your ML workflows.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的最后一章到此结束。在使用H2O AutoML的过程中，我们还可以利用无数的特征、概念和设计模式。你越是对这项技术进行实验，你将越擅长实现它。因此，强烈建议你继续实验这项技术，并在自动化你的机器学习工作流程的同时，发现解决机器学习问题的新方法。
