- en: <st c="0">4</st>
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="0">4</st>
- en: <st c="2">Performing Variable Discretization</st>
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="2">执行变量离散化</st>
- en: <st c="36">Discretization is the</st> <st c="59">process of transforming continuous
    variables into discrete features by creating a set of contiguous intervals, also</st>
    <st c="175">called</st> **<st c="182">bins</st>**<st c="186">, which span the
    range of the variable values.</st> <st c="233">Subsequently, these intervals are
    treated as</st> <st c="278">categorical data.</st>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="36">离散化是将</st> <st c="59">通过创建一系列连续的区间将连续变量转换为离散特征的过程，也</st> <st c="175">称为</st>
    **<st c="182">bins</st>**<st c="186">，这些区间跨越了变量值的范围。</st> <st c="233">随后，这些区间被视为</st>
    <st c="278">分类数据。</st>
- en: <st c="295">Many machine learning models, such as decision trees and Naïve Bayes,
    work better with discrete attributes.</st> <st c="404">In fact, decision tree-based
    models make decisions based on discrete partitions over the attributes.</st> <st
    c="505">During induction, a decision tree evaluates all possible feature values
    to find the best cut-point.</st> <st c="605">Therefore, the more values the feature
    has, the longer the induction time of the tree is.</st> <st c="695">In this sense,
    discretization can reduce the time it takes to train</st> <st c="763">the models.</st>
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="295">许多机器学习模型，例如决策树和朴素贝叶斯，与离散属性配合工作效果更好。</st> <st c="404">实际上，基于决策树的模型是根据属性上的离散划分来做出决策的。</st>
    <st c="505">在归纳过程中，决策树评估所有可能的特征值以找到最佳的切割点。</st> <st c="605">因此，特征值越多，树的归纳时间就越长。</st>
    <st c="695">从这个意义上说，离散化可以减少模型训练所需的时间。</st> <st c="763">模型。</st>
- en: <st c="774">Discretization has additional advantages.</st> <st c="817">Data
    is reduced and simplified; discrete features can be easier to understand by domain
    experts.</st> <st c="914">Discretization can change the distribution of skewed
    variables; when sorting observations across bins with equal-frequency, the values
    are spread more homogeneously across the range.</st> <st c="1097">Additionally,
    discretization can minimize the influence of outliers by placing them at lower
    or higher intervals, together with the remaining</st> **<st c="1239">inlier</st>**
    <st c="1245">values of the distribution.</st> <st c="1274">Overall, discretization
    reduces and simplifies data, making the learning process faster and potentially
    yielding more</st> <st c="1392">accurate results.</st>
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="774">离散化还有额外的优势。</st> <st c="817">数据被减少和简化；离散特征更容易被领域专家理解。</st> <st c="914">离散化可以改变偏斜变量的分布；当按等频对区间内的观测值进行排序时，值在范围内分布得更均匀。</st>
    <st c="1097">此外，离散化可以通过将异常值放置在较低或较高的区间中，与分布的剩余**<st c="1239">内点</st>** <st c="1245">值一起，最小化它们的影响。</st>
    <st c="1274">总的来说，离散化减少了数据并简化了数据，使学习过程更快，并可能产生更</st> <st c="1392">准确的结果。</st>
- en: <st c="1409">Discretization can also lead to a loss of information, for example,
    by combining values that are strongly associated with different classes or target
    values into the same bin.</st> <st c="1586">Therefore, the aim of a discretization
    algorithm is to find the minimal number of intervals without incurring a significant
    loss of information.</st> <st c="1731">In practice, many discretization procedures
    require the user to input the number of intervals into which the values will be
    sorted.</st> <st c="1863">Then, the job of the algorithm is to find the cut points
    for those intervals.</st> <st c="1941">Among these procedures, we find the most
    widely used equal-width and equal-frequency discretization methods.</st> <st c="2050">Discretization
    methods based on decision trees are, otherwise, able to find the optimal number
    of partitions, as well as the</st> <st c="2175">cut points.</st>
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="1409">离散化也可能导致信息丢失，例如，通过将强烈关联不同类别或目标值的值组合到同一个区间中。</st> <st c="1586">因此，离散化算法的目标是找到最小数量的区间，同时不造成显著的信息丢失。</st>
    <st c="1731">在实践中，许多离散化过程需要用户输入将值排序到的区间数量。</st> <st c="1863">然后，算法的任务是找到这些区间的切割点。</st>
    <st c="1941">在这些过程中，我们发现最广泛使用的等宽和等频离散化方法。</st> <st c="2050">基于决策树的离散化方法，否则，能够找到最优的分区数量，以及</st>
    <st c="2175">切割点。</st>
- en: <st c="2186">Discretization procedures can be classified as</st> **<st c="2234">supervised</st>**
    <st c="2244">and</st> **<st c="2249">unsupervised</st>**<st c="2261">. Unsupervised
    discretization methods only use the variable’s distribution to determine the limits
    of the contiguous bins.</st> <st c="2384">On the other hand, supervised methods
    use target information to create</st> <st c="2455">the intervals.</st>
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 离散化过程可以分为**监督****的**和**非监督**的**。非监督离散化方法仅使用变量的分布来确定连续箱的界限。</st> <st c="2261">另一方面，监督方法使用目标信息来创建**区间**。</st>
- en: <st c="2469">In this chapter, we will discuss widely used supervised and unsupervised
    discretization procedures that are available in established open source libraries.</st>
    <st c="2626">Among these, we will cover equal-width, equal-frequency, arbitrary,
    k-means, and decision tree-based discretization.</st> <st c="2743">More elaborate
    methods, such as ChiMerge and CAIM, are out of the scope of this chapter, as their
    implementation is not yet open</st> <st c="2872">source available.</st>
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论在成熟的开源库中广泛使用的监督和非监督离散化过程。</st> <st c="2626">在这些过程中，我们将涵盖等宽、等频率、任意、k-means和基于决策树的离散化。</st>
    <st c="2743">更详细的方法，如ChiMerge和CAIM，超出了本章的范围，因为它们的实现尚未开源。</st>
- en: <st c="2889">This chapter contains the</st> <st c="2916">following recipes:</st>
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含以下**食谱**：
- en: <st c="2934">Performing</st> <st c="2946">equal-width discretization</st>
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行**等宽离散化**
- en: <st c="2972">Implementing</st> <st c="2986">equal-frequency discretization</st>
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现等**频率**离散化
- en: <st c="3016">Discretizing the variable into</st> <st c="3048">arbitrary intervals</st>
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将变量**离散化**到**任意区间**
- en: <st c="3067">Performing discretization with</st> <st c="3099">k-means clustering</st>
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**k-means聚类**进行离散化
- en: <st c="3117">Implementing</st> <st c="3131">feature binarization</st>
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现特征**二值化**
- en: <st c="3151">Using decision trees</st> <st c="3173">for discretization</st>
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用决策树进行**离散化**
- en: <st c="3191">Technical requirements</st>
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**技术要求**'
- en: <st c="3214">In this chapter, we will use the numerical computing libraries</st>
    `<st c="3278">pandas</st>`<st c="3284">,</st> `<st c="3286">numpy</st>`<st c="3291">,</st>
    `<st c="3293">matplotlib</st>`<st c="3303">,</st> `<st c="3305">scikit-learn</st>`<st
    c="3317">, and</st> `<st c="3322">feature-engine</st>`<st c="3337">. We will also
    use the</st> `<st c="3360">yellowbrick</st>` <st c="3371">Python open source library,
    which you can install</st> <st c="3422">with</st> `<st c="3427">pip</st>`<st c="3430">:</st>
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用数值计算库**`pandas`**、**`numpy`**、**`matplotlib`**、**`scikit-learn`**和**`feature-engine`**。我们还将使用**`yellowbrick`**
    Python开源库，您可以使用**`pip`**安装它：</st>
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: <st c="3456">For more details about</st> `<st c="3480">yellowbrick</st>`<st
    c="3491">, visit the</st> <st c="3503">documentation here:</st>
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于**`yellowbrick`**的详细信息，请访问以下**文档**：
- en: <st c="3522">https://www.scikit-yb.org/en/latest/index.html</st>
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.scikit-yb.org/en/latest/index.html](https://www.scikit-yb.org/en/latest/index.html)'
- en: <st c="3569">Performing equal-width discretization</st>
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行**等宽离散化**
- en: <st c="3607">Equal-width</st> <st c="3619">discretization</st> <st c="3634">consists
    of dividing the range of</st> <st c="3668">observed values for a variable into</st>
    *<st c="3705">k</st>* <st c="3706">equally sized intervals, where</st> *<st c="3738">k</st>*
    <st c="3739">is supplied by the user.</st> <st c="3765">The interval width for
    the</st> *<st c="3792">X</st>* <st c="3793">variable is given by</st> <st c="3815">the
    followin</st><st c="3827">g:</st>
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**等宽**离散化**包括将变量的观察值范围划分为**k****等宽的区间，其中**k****由用户提供。</st> <st c="3738">变量X的区间宽度由以下公式给出：</st>
    <st c="3815">以下公式：</st><st c="3827">g:</st>'
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi
    mathvariant="bold-italic">W</mi><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">d</mi><mi
    mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">h</mi><mo>=</mo><mfrac><mrow><mi
    mathvariant="bold-italic">M</mi><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">x</mi><mfenced
    open="(" close=")"><mi mathvariant="bold-italic">X</mi></mfenced><mo>−</mo><mi
    mathvariant="bold-italic">M</mi><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">n</mi><mo>(</mo><mi
    mathvariant="bold-italic">X</mi><mo>)</mo></mrow><mi mathvariant="bold-italic">k</mi></mfrac></mrow></mrow></math>](img/20.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi
    mathvariant="bold-italic">W</mi><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">d</mi><mi
    mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">h</mi><mo>=</mo><mfrac><mrow><mi
    mathvariant="bold-italic">M</mi><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">x</mi><mfenced
    open="(" close=")"><mi mathvariant="bold-italic">X</mi></mfenced><mo>−</mo><mi
    mathvariant="bold-italic">M</mi><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">n</mi><mo>(</mo><mi
    mathvariant="bold-italic">X</mi><mo>)</mo></mrow><mi mathvariant="bold-italic">k</mi></mfrac></mrow></mrow></math>](img/20.png)'
- en: <st c="3860">Then, if the</st> <st c="3873">values of the variable vary between
    0 and 100, we can create five bins like this:</st> *<st c="3955">width = (100-0)
    / 5 = 20</st>*<st c="3979">. The bins will be 0–20, 20–40, 40–60, and 80–100\.</st>
    <st c="4030">The first and final bins (0–20 and 80–100) can be expanded to accommodate
    values smaller than 0 or greater than 100 by extending the limits to minus and</st>
    <st c="4183">plus infinity.</st>
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="3860">然后，如果变量的值在0到100之间变化，我们可以创建五个箱子，如下所示：</st> *<st c="3955">宽度 = (100-0)
    / 5 = 20</st>*<st c="3979">。箱子将是0-20，20-40，40-60和80-100。</st> <st c="4030">第一个和最后一个箱子（0-20和80-100）可以通过将限制扩展到负无穷和正无穷来扩展，以容纳小于0或大于100的值。</st>
- en: <st c="4197">In this recipe, we will carry out equal-width discretization using</st>
    `<st c="4265">pandas</st>`<st c="4271">,</st> `<st c="4273">scikit-learn</st>`<st
    c="4285">,</st> <st c="4287">and</st> `<st c="4291">feature-engi</st><st c="4303">ne</st>`<st
    c="4306">.</st>
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="4197">在这个配方中，我们将使用</st> `<st c="4265">pandas</st>`<st c="4271">，`<st
    c="4273">scikit-learn</st>`<st c="4285">，`<st c="4287">和`<st c="4291">特征工程</st>`<st
    c="4303">来执行等宽离散化。</st>
- en: <st c="4307">How to do it...</st>
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="4307">如何操作...</st>
- en: <st c="4323">First, le</st><st c="4333">t’s import the necessary Python libraries
    and get the</st> <st c="4388">dataset ready:</st>
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="4323">首先，让我们导入必要的Python库并准备好</st> <st c="4388">数据集：</st>
- en: <st c="4402">Let’s import the libraries</st> <st c="4430">and functions:</st>
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="4402">让我们导入所需的库和函数：</st>
- en: '[PRE1]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: <st c="4622">Let’s load the predictor and target variables of the California</st>
    <st c="4687">housing dataset:</st>
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="4622">让我们加载加利福尼亚住房数据集的预测变量和目标变量：</st>
- en: '[PRE2]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: <st c="4768">Note</st>
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="4768">注意</st>
- en: <st c="4773">To avoid data leakage, we will find the intervals’ limits by using
    the variables in the train set.</st> <st c="4873">Then, we will use these limits
    to discretize the variables in train and</st> <st c="4945">test sets.</st>
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="4773">为了避免数据泄露，我们将使用训练集中的变量来找到区间的限制。</st> <st c="4873">然后，我们将使用这些限制来离散化训练集和</st>
    <st c="4945">测试集中的变量。</st>
- en: <st c="4955">Let’s divide the data into train and</st> <st c="4993">test sets:</st>
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="4955">让我们将数据分为训练集和</st> <st c="4993">测试集：</st>
- en: '[PRE3]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: <st c="5093">Next, we will divide the continuous</st> `<st c="5130">HouseAge</st>`
    <st c="5138">variable into 10 intervals using</st> `<st c="5172">pandas</st>`
    <st c="5178">and the formula described at the beginning of</st> <st c="5225">the
    recipe.</st>
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="5093">接下来，我们将使用</st> `<st c="5172">pandas</st>` <st c="5178">和配方开头描述的公式，将连续的</st>
    `<st c="5130">HouseAge</st>` <st c="5138">变量分为10个区间：</st>
- en: <st c="5236">Let’s capture the minimum and maximum values</st> <st c="5282">of</st>
    `<st c="5285">HouseAge</st>`<st c="5293">:</st>
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="5236">让我们捕获</st> <st c="5285">HouseAge</st> <st c="5293">的最小值和最大值：</st>
- en: '[PRE4]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: <st c="5381">Let’s</st> <st c="5388">determine the interval width, which is
    the variable’s value range divided by the number</st> <st c="5476">of bins:</st>
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="5381">让我们</st> <st c="5388">确定区间宽度，即变量的值范围除以箱子的数量：</st>
- en: '[PRE5]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: <st c="5526">If we execute</st> `<st c="5541">print(width)</st>`<st c="5553">,
    we will obtain</st> `<st c="5570">5</st>`<st c="5571">, which is the size of</st>
    <st c="5594">the intervals.</st>
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="4687">如果我们执行</st> `<st c="5541">print(width)</st>`<st c="5553">，我们将获得</st>
    `<st c="5570">5</st>`<st c="5571">，这是区间的</st> <st c="5594">大小。</st>
- en: <st c="5608">No</st><st c="5611">w we need to define the interval limits and
    store them in</st> <st c="5670">a list:</st>
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="5608">现在</st><st c="5611">我们需要定义区间限制并将它们存储在一个列表中：</st>
- en: '[PRE6]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: <st c="5744">If we now execute</st> `<st c="5763">print(interval_limits)</st>`<st
    c="5785">, we will see the</st> <st c="5803">interval limits:</st>
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="5744">如果我们现在执行</st> `<st c="5763">print(interval_limits)</st>`<st c="5785">，我们将看到</st>
    <st c="5803">区间限制：</st>
- en: '[PRE7]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: <st c="5862">Let’s expand the limits of the first and last intervals to accommodate
    smaller or greater values that we could find in the test set or in future</st>
    <st c="6008">data sources:</st>
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="5862">让我们将第一个和最后一个区间的限制范围扩展，以容纳测试集或未来数据源中可能找到的较小或较大的值：</st>
- en: '[PRE8]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: <st c="6079">Let’s make a copy of the DataFrames so we don’t overwrite the original
    ones, which we will need for later steps in</st> <st c="6195">the recipe:</st>
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="6079">让我们复制一下DataFrame，这样我们就不会覆盖原始的DataFrame，我们将在食谱的后续步骤中需要它们：</st> <st
    c="6195">：</st>
- en: '[PRE9]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: <st c="6254">Let’s sort</st> <st c="6266">the</st> `<st c="6270">HouseAge</st>`
    <st c="6278">variable into the intervals that we defined in</st> *<st c="6326">step
    6</st>*<st c="6332">:</st>
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="6254">让我们将</st> <st c="6266">HouseAge</st> <st c="6278">变量排序到我们在</st>
    *<st c="6326">步骤6</st>*<st c="6332">中定义的区间中：</st>
- en: '[PRE10]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: <st c="6534">Note</st>
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="6534">注意</st>
- en: <st c="6539">We have set</st> `<st c="6552">include_lowest=True</st>` <st c="6571">to
    include the lowest value in the first interval.</st> <st c="6623">Note that we
    used the train set to find the intervals and then used those limits to sort the
    variable in</st> <st c="6728">both datasets.</st>
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="6539">我们已将</st> `<st c="6552">include_lowest=True</st>` <st c="6571">设置为包含第一个区间的最低值。</st>
    <st c="6623">请注意，我们使用训练集来找到区间，然后使用这些限制在两个数据集中对变量进行排序。</st>
- en: <st c="6742">Let’s print the top</st> `<st c="6763">5</st>` <st c="6764">observations
    of the discretized and</st> <st c="6801">original variables:</st>
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="6742">让我们打印离散化和原始变量的前</st> `<st c="6763">5</st>` <st c="6764">个观测值：</st>
- en: '[PRE11]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: <st c="6874">In the foll</st><st c="6886">owing output, we can see that the</st>
    `<st c="6921">52</st>` <st c="6923">value was allocated to the 46–infinite interval,
    the</st> `<st c="6977">43</st>` <st c="6979">value was allocated to the 41–46
    interval, and</st> <st c="7027">so on:</st>
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="6874">在以下输出中，我们可以看到</st> `<st c="6921">52</st>` <st c="6923">值被分配到46-无穷区间，</st>
    `<st c="6977">43</st>` <st c="6979">值被分配到41-46区间，以此类推：</st>
- en: '[PRE12]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: <st c="7168">Note</st>
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7168">注意</st>
- en: <st c="7173">The parentheses and brackets in the intervals indicate whether
    a value is included in the interval or not.</st> <st c="7281">For example, the
    (41, 46] interval contains all values greater than 41 and smaller than or equal</st>
    <st c="7378">to 46.</st>
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7173">区间中的括号和方括号表示一个值是否包含在该区间内。</st> <st c="7281">例如，(41, 46] 区间包含所有大于41且小于或等于46的值。</st>
    <st c="7378">。</st>
- en: <st c="7384">Equal-width discretization</st> <st c="7411">allocates a different
    number of observations to</st> <st c="7460">each i</st><st c="7466">nterval.</st>
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="7384">等宽离散化将不同数量的观测值分配给每个</st> <st c="7460">区间。</st>
- en: <st c="7475">Let’s make a bar plot with the proportion of observations across
    the intervals of</st> `<st c="7558">HouseAge</st>` <st c="7566">in the train and</st>
    <st c="7584">test sets:</st>
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="7475">让我们绘制一个条形图，显示训练集和测试集中</st> `<st c="7558">HouseAge</st>` <st c="7566">区间的观测比例：</st>
- en: '[PRE13]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: <st c="7969">In the following output, we can see that the proportion of observations
    per interval is approximately the same in the train and test sets, but different</st>
    <st c="8123">across inter</st><st c="8135">vals:</st>
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="7969">在以下输出中，我们可以看到训练集和测试集中每个区间的观测比例大致相同，但不同</st> <st c="8123">区间之间不同：</st>
- en: '![Figure 4.1 – The proportion of observations per interval after the discretization](img/B22396_04_1.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图4.1 – 离散化后每个区间的观测比例](img/B22396_04_1.jpg)'
- en: <st c="8299">Figure 4.1 – The proportion of observations per interval after
    the discretization</st>
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="8299">图4.1 – 离散化后每个区间的观测比例</st>
- en: <st c="8380">With</st> `<st c="8386">feature-engine</st>`<st c="8400">, we</st>
    <st c="8405">can perform equal-width discretization in fewer lines of code and
    for many variables at</st> <st c="8493">a time.</st>
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="8380">使用</st> `<st c="8386">feature-engine</st>`<st c="8400">，我们可以用更少的代码行和更多变量同时进行等宽离散化。</st>
- en: <st c="8500">First, let’s import</st> <st c="8521">the discretizer:</st>
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="8500">首先，让我们导入</st> <st c="8521">离散化器：</st>
- en: '[PRE14]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: <st c="8601">Let’s set up the discretizer to sort three continuous variables
    into</st> <st c="8671">eight intervals:</st>
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="8601">让我们设置离散化器，将三个连续变量排序到八个区间中：</st>
- en: '[PRE15]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: <st c="8793">Note</st>
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="8793">注意</st>
- en: '`<st c="8798">EqualWidthDiscretiser()</st>` <st c="8822">returns an integer
    indicating w</st><st c="8854">hether the value was sorted into the first, second,
    or eighth bin by default.</st> <st c="8933">That is the equivalent of ordinal
    encoding, which we described in the</st> *<st c="9003">Replacing categories with
    ordinal numbers</st>* <st c="9044">recipe of</st> [*<st c="9055">Chapter 2</st>*](B22396_02.xhtml#_idTextAnchor182)<st
    c="9064">,</st> *<st c="9066">Encoding Categorical Variables</st>*<st c="9096">.
    To carry out a different encoding with the</st> `<st c="9141">feature-engine</st>`
    <st c="9155">or</st> `<st c="9159">category</st>` `<st c="9167">encoders</st>`
    <st c="9177">Python libraries, cast the returned variables as objects by setting</st>
    `<st c="9245">return_object</st>` <st c="9258">to</st> `<st c="9262">True</st>`<st
    c="9266">. Alternatively, make the transformer return the interval limits by setting</st>
    `<st c="9342">return_boundaries</st>` <st c="9359">to</st> `<st c="9363">True</st>`<st
    c="9367">.</st>'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="8798">EqualWidthDiscretiser()</st>` <st c="8822">返回一个整数，表示默认情况下值是否被排序到第一个、第二个或第八个箱中。</st>
    <st c="8854">这相当于顺序编码，我们在</st> *<st c="9003">用顺序数字替换类别</st>* <st c="9044">的</st>
    [*<st c="9055">第2章</st>*](B22396_02.xhtml#_idTextAnchor182)<st c="9064">，</st>
    *<st c="9066">编码分类变量</st>*<st c="9096">中进行了描述。要使用</st> `<st c="9141">feature-engine</st>`
    <st c="9155">或</st> `<st c="9159">category</st>` `<st c="9167">encoders</st>`
    <st c="9177">Python库执行不同的编码，通过将</st> `<st c="9245">return_object</st>` <st c="9258">设置为</st>
    `<st c="9262">True</st>`<st c="9266">将返回的变量转换为对象。或者，通过将</st> `<st c="9342">return_boundaries</st>`
    <st c="9359">设置为</st> `<st c="9363">True</st>`<st c="9367">，使转换器返回区间限制。</st>'
- en: <st c="9368">Let’s fit the</st> <st c="9383">discretizer to the train set so
    that it learns the cut points for</st> <st c="9449">each variable:</st>
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="9368">让我们将离散化器拟合到训练集，以便它为每个变量学习切分点：</st>
- en: '[PRE16]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: <st c="9481">After fitting, we can inspect the cut points in the</st> `<st c="9534">binner_dict_</st>`
    <st c="9546">attribute by</st> <st c="9560">executing</st> `<st c="9570">print(disc.binner_dict_)</st>`<st
    c="9594">.</st>
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="9481">拟合后，我们可以通过执行</st> `<st c="9534">binner_dict_</st>` <st c="9546">属性中的</st>
    `<st c="9560">print(disc.binner_dict_)</st>`<st c="9594">来检查切分点。</st>
- en: <st c="9595">Note</st>
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="9595">注意</st>
- en: '`<st c="9600">feature-engine</st>` <st c="9615">will automatically extend the
    limits of the lower and upper intervals to infinite to accommodate potential outliers
    in</st> <st c="9735">future data.</st>'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="9600">feature-engine</st>` <st c="9615">将自动将下限和上限区间的范围扩展到无限大，以适应未来数据中的潜在异常值。</st>
    <st c="9735">。</st>'
- en: <st c="9747">Let’s discretize the variables in the train and</st> <st c="9796">test
    sets:</st>
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="9747">让我们对训练集和测试集中的变量进行离散化：</st>
- en: '[PRE17]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`<st c="9872">EqualWidthDiscretiser()</st>` <st c="9896">returns a DataFrame
    where the selected variables are discretized.</st> <st c="9963">If we run</st>
    `<st c="9973">test_t.head()</st>`<st c="9986">,</st> <st c="9988">we will see
    the following output where the original values of</st> `<st c="10050">MedInc</st>`<st
    c="10056">,</st> `<st c="10058">HouseAge</st>`<st c="10066">, and</st> `<st c="10072">AveRooms</st>`
    <st c="10080">are replaced by the</st> <st c="10101">interval nu</st><st c="10112">mbers:</st>'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`<st c="9872">EqualWidthDiscretiser()</st>` <st c="9896">返回一个DataFrame，其中选定的变量被离散化。</st>
    <st c="9963">如果我们运行</st> `<st c="9973">test_t.head()</st>`<st c="9986">，</st>
    <st c="9988">我们将看到以下输出，其中原始值</st> `<st c="10050">MedInc</st>`<st c="10056">，</st>
    `<st c="10058">HouseAge</st>`<st c="10066">，和</st> `<st c="10072">AveRooms</st>`
    <st c="10080">被替换为</st> <st c="10101">区间数值：</st>'
- en: '![Figure 4.2 – A DataFrame with three discretized variables: HouseAge, MedInc,
    and AveRooms](img/B22396_04_2.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图4.2 – 包含三个离散化变量：HouseAge，MedInc和AveRooms的DataFrame](img/B22396_04_2.jpg)'
- en: '<st c="10446">Figure 4.2 – A DataFrame with three discretized variables: HouseAge,
    MedInc, and AveRooms</st>'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="10446">图4.2 – 包含三个离散化变量：HouseAge，MedInc和AveRooms的DataFrame</st>
- en: <st c="10535">Now, let’s</st> <st c="10546">make bar plots with the proportion
    of observations per interval to better understand the effect of</st> <st c="10646">equal-width
    discretization:</st>
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="10535">现在，让我们</st> <st c="10546">用每个区间的观测值比例制作条形图，以更好地理解等宽离散化的影响：</st>
- en: '[PRE18]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: <st c="11271">The in</st><st c="11278">tervals contain</st> <st c="11294">a
    different number of observations, as shown in the</st> <st c="11347">following
    plots:</st>
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="11271">区间包含不同数量的观测值，如下面的图表所示：</st>
- en: '![Figure 4.3 – Bar plots with the proportion of observations per interval after
    the discretization](img/B22396_04_3.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图4.3 – 切分后每个区间的观测比例的条形图](img/B22396_04_3.jpg)'
- en: <st c="11674">Figure 4.3 – Bar plots with the proportion of observations per
    interval after the discretization</st>
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – 切分后每个区间的观测比例的条形图
- en: <st c="11770">Now, let’s</st> <st c="11782">implement equal-width discretization</st>
    <st c="11819">with scikit-learn.</st>
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用scikit-learn实现等宽切分。
- en: <st c="11837">Let’s import the classes</st> <st c="11863">from scikit-learn:</st>
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入来自scikit-learn的类。
- en: '[PRE19]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: <st c="11979">Let’s set up an equal-width discretizer by setting its</st> `<st
    c="12035">strategy</st>` <st c="12043">to</st> `<st c="12047">uniform</st>`<st
    c="12054">:</st>
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过将其`<st c="12035">strategy</st>`设置为`<st c="12047">uniform</st>`来设置等宽切分器。
- en: '[PRE20]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: <st c="12129">Note</st>
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`<st c="12134">KBinsDiscretiser()</st>` <st c="12153">can return the bins as
    integers by setting</st> `<st c="12197">encoding</st>` <st c="12205">to</st> `<st
    c="12209">''ordinal''</st>` <st c="12218">or one-hot encoded by setting</st> `<st
    c="12249">encoding</st>` <st c="12257">to</st> `<st c="12261">''onehot-dense''</st>`<st
    c="12275">.</st>'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="12134">KBinsDiscretiser()</st>`可以通过设置`<st c="12197">encoding</st>`为`<st
    c="12209">''ordinal''</st>`或通过设置`<st c="12249">encoding</st>`为`<st c="12261">''onehot-dense''</st>`来返回整数形式的区间。'
- en: <st c="12276">Let’s use</st> `<st c="12287">ColumnTransformer()</st>` <st c="12306">to
    restrict the discretization to the selected variables from</st> *<st c="12369">step
    13</st>*<st c="12376">:</st>
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用`<st c="12287">ColumnTransformer()</st>`将切分限制为从*<st c="12369">步骤13</st>*选定的变量。
- en: '[PRE21]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: <st c="12495">Note</st>
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: <st c="12500">With</st> `<st c="12506">remainder</st>` <st c="12515">set to</st>
    `<st c="12523">passthrough</st>`<st c="12534">,</st> `<st c="12536">ColumnTransformer()</st>`
    <st c="12555">returns all the variables in the input DataFrame after the transformation.</st>
    <st c="12631">To return only the transformed variables, set</st> `<st c="12677">remainder</st>`
    <st c="12686">to</st> `<st c="12690">drop</st>`<st c="12694">.</st>
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当`<st c="12506">remainder</st>`设置为`<st c="12523">passthrough</st>`时，`<st c="12536">ColumnTransformer()</st>`在转换后返回输入DataFrame中的所有变量。要仅返回转换后的变量，将`<st
    c="12677">remainder</st>`设置为`<st c="12690">drop</st>`。
- en: <st c="12695">Let’s fit the discretizer to the train set so that it learns the</st>
    <st c="12761">interval limits:</st>
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将切分器拟合到训练集，以便它学习区间限制。
- en: '[PRE22]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: <st c="12793">Finall</st><st c="12800">y, let’s</st> <st c="12810">discretize
    the selected variables in the train and</st> <st c="12861">test sets:</st>
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们在训练集和测试集中对选定的变量进行切分。
- en: '[PRE23]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: <st c="12933">We can inspect the cut points learned by the transformer by</st>
    <st c="12994">executing</st> `<st c="13004">ct.named_transformers_["discretizer"].bin_edges_</st>`<st
    c="13052">.</st>
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以通过执行`ct.named_transformers_["discretizer"].bin_edges_`来检查transformer学习到的切分点。
- en: <st c="13053">Note</st>
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`<st c="13058">ColumnTransformer()</st>` <st c="13078">will append</st> `<st
    c="13091">discretize</st>` <st c="13101">to the variables that were discretized
    and</st> `<st c="13145">remainder</st>` <st c="13154">to those that were</st>
    <st c="13174">not modified.</st>'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="13058">ColumnTransformer()</st>`将`<st c="13091">discretize</st>`附加到已切分的变量上，并将`<st
    c="13145">remainder</st>`附加到未修改的变量上。'
- en: <st c="13187">We can check the output by</st> <st c="13215">executing</st> `<st
    c="13225">test_</st><st c="13230">t.head()</st>`<st c="13239">.</st>
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过执行`<st c="13225">test_</st><st c="13230">t.head()</st>`来检查输出。
- en: <st c="13240">How it works…</st>
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: <st c="13254">In this recipe, we sorted the variable values into equidistant
    intervals.</st> <st c="13329">To perform discretization with</st> `<st c="13360">pandas</st>`<st
    c="13366">, we first found the maximum and minimum values of the</st> `<st c="13421">HouseAge</st>`
    <st c="13429">variable using the</st> `<st c="13449">max()</st>` <st c="13454">and</st>
    `<st c="13459">min()</st>` <st c="13464">methods.</st> <st c="13474">Then, we
    estimated the interval width by dividing the value range by the number of arbitrary
    bins.</st> <st c="13573">With the width and the minimum and maximum values, we
    determined the interval limits and stored them in a list.</st> <st c="13685">We</st>
    <st c="13687">used this list with pandas</st> `<st c="13715">cut()</st>` <st c="13720">to
    sort the variable values into</st> <st c="13754">the intervals.</st>
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方法中，我们将变量值排序到等距的区间中。<st c="13329">为了使用</st> `<st c="13360">pandas</st>`<st
    c="13366">进行离散化，我们首先使用</st> `<st c="13449">max()</st>` <st c="13454">和</st c="13459">min()</st>`
    <st c="13464">方法找到了</st> `<st c="13421">HouseAge</st>` <st c="13429">变量的最大值和最小值。</st>
    <st c="13474">然后，我们将值范围除以任意分箱的数量来估计区间宽度。</st> <st c="13573">有了宽度和最小值、最大值，我们确定了区间界限并将它们存储在一个列表中。</st>
    <st c="13685">我们使用这个列表和pandas的</st> `<st c="13715">cut()</st>` <st c="13720">函数将变量值排序到</st>
    `<st c="13754">区间</st>`中。
- en: <st c="13768">Note</st>
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13768">注意</st>
- en: <st c="13773">Pandas</st> `<st c="13781">cut()</st>` <st c="13786">sorts the
    variable into intervals of equal size by default.</st> <st c="13847">It will extend
    the variable range by .1% on each side to include the minimum and maximum values.</st>
    <st c="13944">The reason why we generated the intervals manually is to accommodate
    potentially smaller or larger values than those seen in the dataset in future
    data sources when we deploy</st> <st c="14119">our model.</st>
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="13773">Pandas的</st> `<st c="13781">cut()</st>` <st c="13786">函数默认按等大小区间对变量进行排序。</st>
    <st c="13847">它会在每侧扩展变量范围0.1%，以包含最小值和最大值。</st> <st c="13944">我们手动生成区间的理由是为了在部署</st>
    `<st c="14119">我们的模型</st>`时，适应未来数据源中可能出现的比数据集中看到的更小或更大的值。
- en: <st c="14129">After discretization, we normally treat the intervals as categorical
    values.</st> <st c="14207">By default, pandas</st> `<st c="14226">cut()</st>`
    <st c="14231">returns the interval values as ordered integers, which is the equivalent
    of ordinal encoding.</st> <st c="14326">Alternatively, we can return the interval
    limits by setting the</st> `<st c="14390">labels</st>` <st c="14396">parameter</st>
    <st c="14407">to</st> `<st c="14410">None</st>`<st c="14414">.</st>
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="14129">离散化后，我们通常将区间视为分类值。</st> <st c="14207">默认情况下，pandas的</st> `<st
    c="14226">cut()</st>` <st c="14231">函数返回有序整数作为区间值，这相当于顺序编码。</st> <st c="14326">或者，我们可以通过设置</st>
    `<st c="14390">labels</st>` <st c="14396">参数为</st> `<st c="14410">None</st>`<st
    c="14414">来返回区间界限。</st>
- en: <st c="14415">To display the</st> <st c="14431">number of observations per interval,
    we created a bar plot.</st> <st c="14491">We used the pandas</st> `<st c="14510">value_counts()</st>`
    <st c="14524">function to obtain the fraction of observations per interval, which
    returns the result in pandas Series, where the index is the interval and the counts
    are the values.</st> <st c="14693">To plot these proportions, first, we concatenated
    the train and test set series using the pandas</st> `<st c="14790">concat()</st>`<st
    c="14798">function in a DataFrame, and then we assigned the</st> `<st c="14849">train</st>`
    <st c="14854">and</st> `<st c="14859">test</st>` <st c="14863">column names to
    it.</st> <st c="14884">Finally, we used</st> `<st c="14901">plot.bar()</st>` <st
    c="14911">to display a bar plot.</st> <st c="14935">We rotated the labels with
    Matplotlib’s</st> `<st c="14975">xticks()</st>`<st c="14983">function, and added
    the</st> *<st c="15008">x</st>* <st c="15009">and</st> *<st c="15014">y</st>*
    <st c="15015">legend with</st> `<st c="15028">xlabels()</st>` <st c="15037">and</st>
    `<st c="15042">ylabel()</st>`<st c="15050">, as well as the title</st> <st c="15073">with</st>
    `<st c="15078">title()</st>`<st c="15085">.</st>
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="14415">为了显示每个区间的观测数，我们创建了一个条形图。</st> <st c="14431">我们使用 pandas 的 `<st
    c="14510">value_counts()</st>` <st c="14524">函数来获取每个区间的观测数比例，该函数返回 pandas Series，其中索引是区间，计数是值。</st>
    <st c="14693">为了绘制这些比例，首先，我们使用 pandas 的 `<st c="14790">concat()</st>`<st c="14798">函数在一个
    DataFrame 中连接了训练集和测试集的 Series，然后我们将 `<st c="14849">train</st>` <st c="14854">和
    `<st c="14859">test</st>` <st c="14863">列名分配给它。</st> <st c="14884">最后，我们使用 `<st
    c="14901">plot.bar()</st>` <st c="14911">来显示条形图。</st> <st c="14935">我们使用 Matplotlib
    的 `<st c="14975">xticks()</st>`<st c="14983">函数旋转了标签，并使用 `<st c="15028">xlabels()</st>`
    <st c="15037">和 `<st c="15042">ylabel()</st>`<st c="15050">添加了 *<st c="15008">x</st>*
    <st c="15009">和 *<st c="15014">y</st>* <st c="15015">图例，以及使用 `<st c="15073">title()</st>`<st
    c="15078">添加了标题。</st>
- en: <st c="15086">To perform equal-width discretization with</st> `<st c="15130">feature-engine</st>`<st
    c="15144">, we</st> <st c="15149">used</st> `<st c="15154">EqualWidth</st>` **<st
    c="15164">Discretiser()</st>**<st c="15178">, which takes the number of bins and
    the variables to discretize as arguments.</st> <st c="15257">With</st> `<st c="15262">fit()</st>`<st
    c="15267">, the discretizer learned the interval limits for each variable.</st>
    <st c="15332">With</st> `<st c="15337">transform()</st>`<st c="15348">, it sorted
    the values into</st> <st c="15376">each bin.</st>
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="15086">要使用 `<st c="15130">feature-engine</st>`<st c="15144">执行等宽离散化，我们使用了
    `<st c="15154">EqualWidth</st>` **<st c="15164">Discretiser()</st>**<st c="15178">，它接受
    bin 数和要离散化的变量作为参数。</st> <st c="15257">使用 `<st c="15262">fit()</st>`<st c="15267">，离散化器学习每个变量的区间限制。</st>
    <st c="15332">使用 `<st c="15337">transform()</st>`<st c="15348">，它将值排序到每个 bin 中。</st>
- en: '`<st c="15385">EqualWidthDiscretiser()</st>` <st c="15409">returns the bins
    as sorted integers by default, which is the equivalent of ordinal encoding.</st>
    <st c="15503">To follow up the discretization with any other encoding procedure
    available in the</st> `<st c="15586">feature-engine</st>` <st c="15600">or</st>
    `<st c="15604">category encoders</st>` <st c="15621">libraries, we need to return
    the bins cast as objects by setting</st> `<st c="15687">return_object</st>` <st
    c="15700">to</st> `<st c="15704">True</st>` <st c="15708">when we set up</st>
    <st c="15724">the transformer.</st>'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="15385">EqualWidthDiscretiser()</st>` <st c="15409">默认情况下返回排序后的整数 bins，这相当于顺序编码。</st>
    <st c="15503">为了在 `<st c="15586">feature-engine</st>` <st c="15600">或 `<st c="15604">category
    encoders</st>` <st c="15621">库中跟随任何其他编码过程，我们需要通过将 `<st c="15687">return_object</st>`
    <st c="15700">设置为 `<st c="15704">True</st>` <st c="15708">来设置转换器时，将 bins 转换为对象。</st>'
- en: <st c="15740">Note</st>
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="15740">注意</st>
- en: '`<st c="15745">EqualWidthDiscretiser()</st>` <st c="15769">extends the values
    of the first and last interval to minus and plus infinity by default to automatically
    accommodate smaller and greater values than those seen in the</st> <st c="15937">training
    set.</st>'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="15745">EqualWidthDiscretiser()</st>` <st c="15769">默认情况下将第一个和最后一个区间的值扩展到负无穷和正无穷，以自动适应训练集中看到的较小和较大的值。</st>'
- en: <st c="15950">We followed the discretization with bar plots to display the fraction
    of observations per interval for each of the transformed variables.</st> <st c="16089">We
    could see that if the original variable was skewed, the bar plot was also skewed.</st>
    <st c="16174">Note how some of the intervals of the</st> `<st c="16212">MedInc</st>`
    <st c="16218">and</st> `<st c="16223">AveRooms</st>` <st c="16231">variables,
    which had skewed distributions, contained very few observations.</st> <st c="16308">In
    particular, even though we wanted to create eight bins for</st> `<st c="16370">AveRooms</st>`<st
    c="16378">, there were only enough values to create five, and most values of the
    variables were allocated to the</st> <st c="16481">first interval.</st>
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在离散化后使用条形图来显示每个转换变量的每个区间的观测值比例。</st> 我们可以看到，如果原始变量是偏斜的，那么条形图也是偏斜的。</st> 注意到
    `<st c="16212">MedInc</st>` `<st c="16218">和</st>` `<st c="16223">AveRooms</st>`
    `<st c="16231">变量</st>` 的某些区间，这些变量具有偏斜分布，包含非常少的观测值。</st> 特别是，尽管我们想要为 `<st c="16370">AveRooms</st>`
    `<st c="16378">》 创建八个桶，但只有足够的数据创建五个，并且大多数变量的值都被分配到</st>` `<st c="16481">第一个区间</st>`。
- en: <st c="16496">Finally, we</st> <st c="16509">discretized</st> <st c="16520">three
    continuous variables into equal-width bins with</st> `<st c="16575">KBinsDiscretizer()</st>`
    <st c="16593">from scikit-learn.</st> <st c="16613">To create equal-width bins,
    we set the</st> `<st c="16652">strategy</st>` <st c="16660">argument to</st> `<st
    c="16673">uniform</st>`<st c="16680">. With</st> `<st c="16687">fit()</st>`<st
    c="16692">, the transformer learned the limits of the intervals, and with</st>
    `<st c="16756">transform()</st>`<st c="16767">, it sorted the values into</st>
    <st c="16795">each interval.</st>
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用 `<st c="16575">KBinsDiscretizer()</st>` 从 scikit-learn 中将三个连续变量离散化成等宽桶。</st>
    `<st c="16593">为了创建等宽桶，我们将</st>` `<st c="16652">strategy</st>` `<st c="16660">参数</st>`
    `<st c="16673">设置为</st>` `<st c="16680">uniform</st>`<st c="16687">。使用</st>` `<st
    c="16687">fit()</st>`<st c="16692">，转换器学习了区间的极限，并使用</st>` `<st c="16756">transform()</st>`<st
    c="16767">，将值排序到</st>` `<st c="16795">每个区间</st>`。
- en: <st c="16809">We used the</st> `<st c="16822">ColumnTransformer()</st>` <st
    c="16841">to restrict the discretization to the selected variables, setting the
    transform output to pandas to obtain a DataFrame after the transformation.</st>
    `<st c="16987">KBinsDiscretizer()</st>` <st c="17005">can return the intervals
    as ordinal numbers, as we had it do in the recipe, or as one-hot-encoded variables.</st>
    <st c="17115">The behavior can be modified through the</st> `<st c="17156">encod</st><st
    c="17161">e</st>` <st c="17163">parameter.</st>
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 `<st c="16809">ColumnTransformer()</st>` 来限制离散化只应用于选定的变量，并将转换输出设置为 pandas，以便在转换后获得一个
    DataFrame。</st> `<st c="16987">KBinsDiscretizer()</st>` 可以返回作为序数的区间，正如我们在配方中所做的那样，或者作为
    one-hot 编码的变量。</st> `<st c="17115">通过</st>` `<st c="17156">encod</st><st c="17161">e</st>`
    `<st c="17163">参数</st>` 可以修改这种行为。
- en: <st c="17174">See also</st>
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见也
- en: '<st c="17183">For a comparison of equal-width discretization with more sophisticated
    methods, see Dougherty J, Kohavi R, Sahami M.</st> *<st c="17301">Supervised and
    unsupervised discretization of continuous features</st>*<st c="17366">. In: Proceedings
    of the 12th international conference on machine learning.</st> <st c="17442">San
    Francisco: Morgan Kaufma</st><st c="17470">nn; 1995.</st> <st c="17480">p.</st>
    <st c="17484">194–202.</st>'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较等宽离散化与更复杂的方法，请参阅 Dougherty J, Kohavi R, Sahami M. *<st c="17301">监督和非监督连续特征的离散化</st>*<st
    c="17366">。在：第 12 届国际机器学习会议论文集。</st> <st c="17442">旧金山：Morgan Kaufma</st><st c="17470">nn;
    1995。</st> <st c="17480">p。</st> <st c="17484">194–202。</st>
- en: <st c="17492">Implementing equal-frequency discretization</st>
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现等频离散化
- en: <st c="17536">Equal-width discretization</st> <st c="17563">is intuitive and
    easy to compute.</st> <st c="17598">However, if the variables are skewe</st><st
    c="17633">d, then there will be many empty bins or bins with only a few values,
    while most observations will be allocated to a few intervals.</st> <st c="17766">This
    could result in a loss of information.</st> <st c="17810">This problem can be
    solved by adaptively finding the interval cut-points so that each interval contains
    a similar fraction</st> <st c="17933">of observations.</st>
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 等宽离散化 `<st c="17536">是直观且易于计算的。</st>` 然而，如果变量是偏斜的，那么将会有许多空桶或只有少数值的桶，而大多数观测值将被分配到少数几个区间。</st>
    这可能会导致信息丢失。</st> 通过自适应地找到区间切点，可以解决这个问题，使得每个区间包含相似比例的观测值。</st>
- en: <st c="17949">Equal-frequency discretization</st> <st c="17980">divides the
    values of the variable into intervals that carry the same proportion of observations.</st>
    <st c="18079">The interval width is</st> <st c="18100">determined by</st> **<st
    c="18115">quantiles</st>**<st c="18124">. Quantiles are values that divide data
    into equal portions.</st> <st c="18185">For example, the median is a quantile
    that divides the data into two halves.</st> <st c="18262">Quartiles divide the
    data into four equal portions, and percentiles divide the data into 100 equal-sized
    portions.</st> <st c="18377">As a result, the intervals will most likely have
    different widths, but a similar number of observations.</st> <st c="18482">The
    number of intervals is defined by</st> <st c="18520">the user.</st>
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="17949">等频率离散化</st> <st c="17980">将变量的值划分为具有相同观测值比例的区间。</st> <st c="17980">区间宽度由</st>
    <st c="18100">**<st c="18115">分位数</st>**<st c="18124">确定。分位数是分割数据为相等部分的值。</st>
    <st c="18185">例如，中位数是一个将数据分为两半的分位数。</st> <st c="18262">四分位数将数据分为四个相等的部分，而百分位数将数据分为100个相等大小的部分。</st>
    <st c="18377">因此，区间可能具有不同的宽度，但观测值数量相似。</st> <st c="18482">区间的数量由</st> <st c="18520">用户定义。</st>
- en: <st c="18529">In this recipe, we will perform equal-frequency discretization
    using</st> `<st c="18599">pandas</st>`<st c="18605">,</st> `<st c="18607">scikit-learn</st>`<st
    c="18619">,</st> <st c="18621">and</st> `<st c="18625">feature-engine</st>`<st
    c="18639">.</st>
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="18529">在这个菜谱中，我们将使用</st> `<st c="18599">pandas</st>`<st c="18605">,</st>
    `<st c="18607">scikit-learn</st>`<st c="18619">,</st> <st c="18621">和</st> `<st
    c="18625">feature-engine</st>`<st c="18639">。</st>进行等频率离散化。
- en: <st c="18640">How to do it...</st>
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="18640">如何做到这一点...</st>
- en: <st c="18656">First, let’s</st> <st c="18669">import the necessary Python libraries
    and get the</st> <st c="18720">dataset ready:</st>
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="18656">首先，让我们</st> <st c="18669">导入必要的Python库并准备好</st> <st c="18720">数据集：</st>
- en: <st c="18734">Let’s import the required Python libraries</st> <st c="18778">and
    functions:</st>
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="18734">让我们导入所需的Python库</st> <st c="18778">和函数：</st>
- en: '[PRE24]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: <st c="18951">Let’s load the California housing dataset into</st> <st c="18999">a
    DataFrame:</st>
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="18951">让我们将加利福尼亚住房数据集加载到</st> <st c="18999">DataFrame中：</st>
- en: '[PRE25]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: <st c="19076">Note</st>
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="19076">注意</st>
- en: <st c="19081">To avoid data leakage, we will determine the interval boundaries
    or quantiles from the</st> <st c="19169">train set.</st>
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免数据泄露，我们将从训练集中确定区间边界或分位数<st c="19081">。</st> <st c="19169">。</st>
- en: <st c="19179">Let’s divide the data into train and</st> <st c="19217">test sets:</st>
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="19179">让我们将数据分为训练集和</st> <st c="19217">测试集：</st>
- en: '[PRE26]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: <st c="19317">Let’s make a copy of</st> <st c="19339">the DataFrames:</st>
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="19317">让我们复制</st> <st c="19339">DataFrame：</st>
- en: '[PRE27]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: <st c="19402">We’ll use pandas</st> `<st c="19420">qcut()</st>`<st c="19426">to
    obtain a discretized copy of the</st> `<st c="19463">HouseAge</st>` <st c="19471">variable,
    which we will store as a new column in the training set, and the limits of eight</st>
    <st c="19563">equal-frequency intervals:</st>
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="19402">我们将使用pandas</st> `<st c="19420">qcut()</st>`<st c="19426">来获取</st>
    `<st c="19463">HouseAge</st>` <st c="19471">变量的离散化副本，并将其存储为训练集中的新列，以及八个</st> <st
    c="19563">等频率区间的边界：</st>
- en: '[PRE28]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: <st c="19696">If you execute</st> `<st c="19712">print(interval_limits)</st>`<st
    c="19734">, you’ll see the following interval limits:</st> `<st c="19778">array([
    1., 14., 18., 24., 29., 34., 37.,</st>` `<st c="19820">44., 52.])</st>`<st c="19830">.</st>
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="19696">如果你执行</st> `<st c="19712">print(interval_limits)</st>`<st c="19734">，你会看到以下区间限制：</st>
    `<st c="19778">array([ 1., 14., 18., 24., 29., 34., 37.,</st>` `<st c="19820">44.,
    52.])</st>`<st c="19830">。</st>
- en: <st c="19831">Let’s</st> <st c="19838">print the top five observations of the
    discretized and</st> <st c="19893">original variables:</st>
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="19831">让我们</st> <st c="19838">打印离散化和</st> <st c="19893">原始变量的前五个观测值：</st>
- en: '[PRE29]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: <st c="19963">In the following output, we see that the</st> `<st c="20005">52</st>`
    <st c="20007">value was allocated to the 44–52 interval, the</st> `<st c="20055">43</st>`
    <st c="20057">value was allocated to the 37–44 interval, and</st> <st c="20105">so
    on:</st>
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="19963">在以下输出中，我们看到</st> `<st c="20005">52</st>` <st c="20007">值被分配到44-52区间，</st>
    `<st c="20055">43</st>` <st c="20057">值被分配到37-44区间，以此类推：</st>
- en: '[PRE30]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: test_t["House_disc"] = pd.cut(
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: test_t["House_disc"] = pd.cut(
- en: x=X_test["HouseAge"],
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: x=X_test["HouseAge"],
- en: bins=interval_limits,
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: bins=interval_limits,
- en: include_lowest=True)
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: include_lowest=True)
- en: '[PRE31]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: <st c="20456">Let’s</st> <st c="20463">make a bar plot with the proportion of
    observations per interval in the train and</st> <st c="20545">test sets:</st>
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="20456">让我们</st> <st c="20463">制作一个条形图，展示训练集和</st> <st c="20545">测试集中每个区间的观测值比例：</st>
- en: '[PRE32]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: <st c="20959">In the following plot, we can see that the bins contain a similar
    fraction</st> <st c="21034">of observations:</st>
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`<st c="20959">在下面的图表中，我们可以看到每个区间包含相似比例的观测值：</st>` `<st c="21034">。</st>'
- en: '![Figure 4.4 – The proportion of observations per interval of HouseAge after
    equal-frequency discretization](img/B22396_04_4.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4 – 在等频率离散化后 HouseAge 每个区间的观测比例](img/B22396_04_4.jpg)'
- en: <st c="21186">Figure 4.4 – The proportion of observations per interval of HouseAge
    after equal-frequency discretization</st>
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="21186">图 4.4 – 在等频率离散化后 HouseAge 每个区间的观测比例。</st>`'
- en: <st c="21291">With</st> `<st c="21297">feature-engine</st>`<st c="21311">, we
    can apply equal-frequency discretization to</st> <st c="21360">multiple</st> <st
    c="21369">variables.</st>
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="21291">使用</st>` `<st c="21297">feature-engine</st>` `<st c="21311">，我们可以将等频率离散化应用于</st>`
    `<st c="21360">多个</st>` `<st c="21369">变量。</st>`'
- en: <st c="21379">Let’s</st> <st c="21386">import</st> <st c="21393">the discretizer:</st>
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`<st c="21379">让我们</st>` <st c="21386">导入</st> <st c="21393">离散化器：</st>'
- en: '[PRE33]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: <st c="21477">Let’s set up the transformer to discretize three continuous variables
    into</st> <st c="21553">eight bins:</st>
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`<st c="21477">让我们设置转换器将三个连续变量离散化成</st>` <st c="21553">八个区间：</st>'
- en: '[PRE34]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: <st c="21695">Note</st>
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="21695">注意</st>`'
- en: <st c="21700">With</st> `<st c="21706">return_boundaries=True</st>`<st c="21728">,
    the transformer will return the interval boundaries after the discretization.</st>
    <st c="21808">To return the interval number, set it</st> <st c="21846">to</st>
    `<st c="21849">False</st>`<st c="21854">.</st>
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="21700">使用</st>` `<st c="21706">return_boundaries=True</st>` `<st c="21728">，转换器将在离散化后返回区间边界。</st>`
    `<st c="21808">要返回区间编号，将其</st>` `<st c="21846">设置为</st>` `<st c="21849">False</st>`
    `<st c="21854">。</st>`'
- en: <st c="21855">Let’s fit the</st> <st c="21870">discretizer to the train set
    so that it learns the</st> <st c="21921">interval limits:</st>
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`<st c="21855">让我们将</st>` `<st c="21870">离散化器拟合到训练集中，以便它学习区间限制：</st>` `<st
    c="21921">。</st>'
- en: '[PRE35]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: <st c="22076">Note</st>
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="22076">注意</st>`'
- en: '`<st c="22081">feature-engine</st>` <st c="22096">will automatically extend
    the limits of the lower and upper intervals to infinite to accommodate potential
    outliers in</st> <st c="22216">future data.</st>'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="22081">feature-engine</st>` <st c="22096">将自动将下限和上限区间的范围扩展到无限大，以适应未来数据中的潜在异常值。</st>
    <st c="22216">。</st>'
- en: <st c="22228">Let’s transform the variables in the train and</st> <st c="22276">test
    sets:</st>
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`<st c="22228">让我们将训练集和</st>` <st c="22276">测试集中的变量</st> <st c="22276">进行转换：</st>'
- en: '[PRE36]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: <st c="22353">Let’s make bar plots with the fraction of observations per interval
    to better understand the effect of</st> <st c="22457">equal-frequency discretization:</st>
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`<st c="22353">让我们绘制条形图，以观察每个区间的观测值比例，更好地理解等频率离散化的影响：</st>` `<st c="22457">。</st>`'
- en: '[PRE37]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: <st c="23092">In the following</st> <st c="23110">figure, we can se</st><st
    c="23127">e that the intervals have a similar fracti</st><st c="23170">on</st>
    <st c="23174">of observations:</st>
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`<st c="23092">在下面的</st>` `<st c="23110">图表中，我们可以看到区间具有相似比例的观测值：</st>` `<st
    c="23127">。</st>` `<st c="23170">。</st>` `<st c="23174">。</st>'
- en: "![Figure 4.5 – The proportion of observations per interval after  equal-frequency\
    \ discretization of three va\uFEFFriables.](img/B22396_04_5.jpg)"
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.5 – 在三个变量的等频率离散化后每个区间的观测比例](img/B22396_04_5.jpg)'
- en: <st c="23721">Figure 4.5 – The proportion of observations per interval after
    equal-frequency discretization of three va</st><st c="23826">riables.</st>
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="23721">图 4.5 – 在三个变量的等频率离散化后每个区间的观测比例。</st><st c="23826">。</st>'
- en: <st c="23835">Now, let’s carry</st> <st c="23853">out equal-frequency discretization</st>
    <st c="23888">with scikit-learn:</st>
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="23835">现在，让我们使用 scikit-learn</st>` `<st c="23853">执行等频率离散化：</st>` `<st
    c="23888">。</st>'
- en: <st c="23906">Let’s import</st> <st c="23920">the transformer:</st>
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`<st c="23906">让我们导入</st>` `<st c="23920">转换器：</st>`'
- en: '[PRE38]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: <st c="23987">Let’s set up the discretizer to sort variables into eight</st>
    <st c="24046">equal-frequency bins:</st>
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`<st c="23987">让我们设置离散化器将变量排序成八个</st>` <st c="24046">等频率区间：</st>'
- en: '[PRE39]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: <st c="24141">Let’s fit the</st> <st c="24156">discretizer to a slice of the
    train set containing the variables from</st> *<st c="24226">step 10</st>* <st
    c="24233">so that it learns the</st> <st c="24256">interval limits:</st>
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`<st c="24141">让我们将</st>` `<st c="24156">离散化器拟合到包含来自</st>` `<st c="24226">步骤
    10</st>` `<st c="24233">的变量的训练集切片中，以便它学习区间限制：</st>` `<st c="24256">。</st>'
- en: '[PRE40]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: <st c="24301">Note</st>
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="24301">注意</st>`'
- en: <st c="24306">scikit-learn’s</st> `<st c="24322">KBinsDiscretiser()</st>` <st
    c="24340">will discretize all the variables in the dataset.</st> <st c="24391">To
    discretize only a subset, we apply the transformer to the slice of the DataFrame
    that contains the variables of interest.</st> <st c="24516">Alternatively, we
    can restrict the discretization to a subset of variables by using the</st> `<st
    c="24604">ColumnTransformer()</st>`<st c="24623">, as we did in the</st> *<st
    c="24642">Performing equal-width</st>* *<st c="24665">discretization</st>* <st
    c="24679">recipe.</st>
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24306">scikit-learn的</st> `<st c="24322">KBinsDiscretiser()</st>` <st
    c="24340">将离散化数据集中的所有变量。</st> <st c="24391">要仅离散化子集，我们将转换器应用于包含感兴趣变量的DataFrame切片。</st>
    <st c="24516">或者，我们可以通过使用</st> `<st c="24604">ColumnTransformer()</st>`<st c="24623">来限制离散化到变量的子集，就像我们在</st>
    *<st c="24642">执行等宽</st>* *<st c="24665">离散化</st>* <st c="24679">食谱中做的那样。</st>
- en: <st c="24687">Let’s make a copy of the DataFrames where we’ll store the</st>
    <st c="24746">discretized variables:</st>
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="24687">让我们复制一个DataFrame，我们将存储</st> <st c="24746">离散化变量：</st>
- en: '[PRE41]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: <st c="24816">Finally, let’s transform the variables in both the train and</st>
    <st c="24878">test sets:</st>
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="24816">最后，让我们转换训练集和</st> <st c="24878">测试集中的变量：</st>
- en: '[PRE42]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: <st c="24999">We can inspect the cut points by</st> <st c="25033">execu</st><st
    c="25038">ting</st> `<st c="25044">disc.bin_edges_</st>`<st c="25059">.</st>
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="24999">我们可以通过执行</st> <st c="25033">disc.bin_edges_</st>`<st c="25059">来检查切点。</st>
- en: <st c="25060">How it works…</st>
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="25060">它是如何工作的…</st>
- en: <st c="25074">In this recipe, we sorted the variable values into intervals with
    a similar proportion</st> <st c="25162">of observations.</st>
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25074">在这个食谱中，我们将变量值排序到具有相似观测比例的区间。</st>
- en: <st c="25178">We used pandas</st> `<st c="25194">qcut()</st>` <st c="25200">to
    identify the interval limits from the train set and sort the values of the</st>
    `<st c="25279">HouseAge</st>` <st c="25287">variable into those intervals.</st>
    <st c="25319">Next, we passed those interval limits to pandas</st> `<st c="25367">cut()</st>`
    <st c="25372">to discretize</st> `<st c="25387">HouseAge</st>` <st c="25395">in
    the test set.</st> <st c="25413">Note that pandas</st> `<st c="25430">qcut()</st>`<st
    c="25436">, like pandas</st> `<st c="25450">cut()</st>`<st c="25455">, returned
    the interval values as ordered integers, which is the equivalent of</st> <st c="25534">ordinal
    encoding,</st>
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25178">我们使用了pandas</st> `<st c="25194">qcut()</st>` <st c="25200">从训练集中识别区间限制，并将</st>
    `<st c="25279">HouseAge</st>` <st c="25287">变量的值排序到这些区间。</st> <st c="25319">接下来，我们将这些区间限制传递给pandas</st>
    `<st c="25367">cut()</st>` <st c="25372">以在测试集中离散化</st> `<st c="25387">HouseAge</st>`
    <st c="25395">。</st> <st c="25413">请注意，pandas</st> `<st c="25430">qcut()</st>`<st
    c="25436">，就像pandas</st> `<st c="25450">cut()</st>`<st c="25455">一样，返回了有序整数作为区间值，这相当于</st>
    <st c="25534">序数编码</st>，
- en: <st c="25551">Note</st>
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25551">注意</st>
- en: <st c="25556">With equal-frequency discretization, many occurrences of values
    within a small continuous range could cause observations with very similar values,
    resulting in different intervals.</st> <st c="25738">The problem with this is
    that it can introduce artificial distinctions between data points that are actually
    quite similar in nature, biasing models or subsequent</st> <st c="25901">data
    analysis.</st>
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25556">使用等频率离散化，小连续范围内的许多值的出现可能会导致具有非常相似值的观测结果，从而产生不同的区间。</st> <st c="25738">这个问题在于，它可能会在实际上性质相当相似的数据点之间引入人为的区别，从而偏置模型或后续</st>
    <st c="25901">数据分析。</st>
- en: <st c="25915">With Feature-engine’s</st> `<st c="25938">EqualFrequencyDiscretiser()</st>`<st
    c="25965">, we discretized three variables into eight bins.</st> <st c="26015">With</st>
    `<st c="26020">fit()</st>`<st c="26025">, the discretizer learned the interval
    limits and stored them in the</st> `<st c="26094">binner_dict_</st>` <st c="26106">attribute.</st>
    <st c="26118">With</st> `<st c="26123">transform()</st>`<st c="26134">, the observations
    were allocated to</st> <st c="26171">the bins.</st>
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="25915">使用Feature-engine的</st> `<st c="25938">EqualFrequencyDiscretiser()</st>`<st
    c="25965">，我们将三个变量离散化到八个箱子。</st> <st c="26015">使用</st> `<st c="26020">fit()</st>`<st
    c="26025">，离散化器学习了区间限制并将它们存储在</st> `<st c="26094">binner_dict_</st>` <st c="26106">属性中。</st>
    <st c="26118">使用</st> `<st c="26123">transform()</st>`<st c="26134">，观测值被分配到</st>
    `<st c="26171">箱子中。</st>
- en: <st c="26180">Note</st>
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26180">注意</st>
- en: '`<st c="26185">EqualFrequencyDiscretiser()</st>` <st c="26213">returns an integer
    indicating whether the value was sorted into the first, second, or eighth bin
    by default.</st> <st c="26323">That is the equivalent of ordinal encoding, which
    we described in the</st> *<st c="26393">Replacing categories with ordinal numbers</st>*
    <st c="26434">recipe in</st> [*<st c="26445">Chapter 2</st>*](B22396_02.xhtml#_idTextAnchor182)<st
    c="26454">,</st> *<st c="26456">Encoding</st>* *<st c="26465">Categorical Variables</st>*<st
    c="26486">.</st>'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="26185">EqualFrequencyDiscretiser()</st>` <st c="26213">默认返回一个整数，表示值是否被排序到第一个、第二个或第八个区间。</st>
    <st c="26323">这相当于顺序编码，我们在</st> *<st c="26393">用顺序数字替换类别</st>* <st c="26434">食谱中进行了描述，该食谱位于</st>
    [*<st c="26445">第2章</st>*](B22396_02.xhtml#_idTextAnchor182)<st c="26454">，*<st
    c="26456">编码</st>* *<st c="26465">分类变量</st>*<st c="26486">。</st>'
- en: <st c="26487">To follow up the discretization with a different type of encoding,
    we can return the variables cast as objects by setting</st> `<st c="26610">return_object</st>`
    <st c="26623">to</st> `<st c="26627">True</st>` <st c="26631">and then use any
    of the</st> `<st c="26656">feature-engine</st>` <st c="26670">or</st> `<st c="26674">category
    encoders</st>` <st c="26691">transformers</st> <st c="26704">. Alternatively,
    we can return the interval limits, as we did in</st> <st c="26769">this recipe.</st>
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26487">为了在离散化之后使用不同类型的编码，我们可以通过将</st> `<st c="26610">return_object</st>`
    <st c="26623">设置为</st> `<st c="26627">True</st>` <st c="26631">来返回作为对象转换的变量，然后使用任何</st>
    `<st c="26656">feature-engine</st>` <st c="26670">或</st> `<st c="26674">category
    encoders</st>` <st c="26691">转换器</st> <st c="26704">。或者，我们可以返回区间限制，就像我们在</st>
    <st c="26769">这个食谱中所做的那样。</st>
- en: <st c="26781">Finally, we discretized variables into eight equal-frequency bins
    using</st> `<st c="26854">scikit-learn</st>`<st c="26866">’s</st> `<st c="26870">KBinsDiscretizer()</st>`<st
    c="26888">. With</st> `<st c="26895">fit()</st>`<st c="26900">, the transformer
    learned the cut points and stored them in its</st> `<st c="26964">bin_edges_</st>`
    <st c="26974">attribute.</st> <st c="26986">With</st> `<st c="26991">transform()</st>`<st
    c="27002">, it sorted the values into each interval.</st> <st c="27045">Note that,
    differently from</st> `<st c="27073">EqualFrequencyDiscretiser()</st>`<st c="27100">,</st>
    `<st c="27102">KBinsDiscretizer()</st>` <st c="27120">will transform all of the
    variables in the dataset.</st> <st c="27173">To avoid this, we only applied the
    discretizer on a slice of the data with the variables</st> <st c="27262">to modify.</st>
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="26781">最后，我们使用</st> `<st c="26854">scikit-learn</st>`<st c="26866">的</st>
    `<st c="26870">KBinsDiscretizer()</st>`<st c="26888">将变量离散化为八个等频率的区间。通过</st> `<st
    c="26895">fit()</st>`<st c="26900">，转换器学习到了分割点并将它们存储在其</st> `<st c="26964">bin_edges_</st>`
    <st c="26974">属性中。</st> <st c="26986">通过</st> `<st c="26991">transform()</st>`<st
    c="27002">，它将值排序到每个区间。</st> <st c="27045">请注意，与</st> `<st c="27073">EqualFrequencyDiscretiser()</st>`<st
    c="27100">不同，</st> `<st c="27102">KBinsDiscretizer()</st>` <st c="27120">将转换数据集中的所有变量。</st>
    <st c="27173">为了避免这种情况，我们只对包含要修改的变量的数据子集应用了离散化器。</st>
- en: <st c="27272">Note</st>
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27272">注意</st>
- en: <st c="27277">scikit-learn’s</st> `<st c="27293">KbinsDiscretizer</st>` <st
    c="27309">has the option to return the intervals as ordinal numbers or one-hot
    encoded.</st> <st c="27388">The behavior can be modified through</st> <st c="27424">the</st>
    `<st c="27429">encode</st>` <st c="27435">parameter.</st>
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27277">scikit-learn的</st> `<st c="27293">KbinsDiscretizer</st>` <st c="27309">有选项返回区间作为顺序数字或独热编码。</st>
    <st c="27388">可以通过</st> <st c="27424">的</st> `<st c="27429">encode</st>` <st c="27435">参数来修改行为。</st>
- en: <st c="27446">Discretizing the va</st><st c="27466">riable into arbitrar</st><st
    c="27487">y intervals</st>
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="27446">将变量离散化到任意区间</st><st c="27466">中</st><st c="27487">的</st>
- en: <st c="27499">In various</st> <st c="27510">industries</st><st c="27521">, it
    is common to group variable values into segments that make sense for the business.</st>
    <st c="27609">For example, we might want to group the variable age in intervals
    representing children, young adults, middle-aged people, and retirees.</st> <st
    c="27746">Alternatively, we might group ratings into bad, good, and excellent.</st>
    <st c="27815">On occasion, if we know that the variable is in a certain scale
    (for example, logarithmic), we might want to define the interval cut points within</st>
    <st c="27962">that scale.</st>
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="27499">在各个</st> <st c="27510">行业</st><st c="27521">中，将变量值分组到对业务有意义的段是常见的。</st>
    <st c="27609">例如，我们可能希望将变量年龄分组到代表儿童、年轻人、中年人和退休人员的区间。</st> <st c="27746">或者，我们可能将评分分组为差、好和优秀。</st>
    <st c="27815">有时，如果我们知道变量处于某个尺度（例如，对数尺度），我们可能希望在</st> <st c="27962">该尺度内定义区间分割点。</st>
- en: <st c="27973">In this recipe, we will discretize a variable into pre-defined
    user intervals using</st> `<st c="28058">pan</st><st c="28061">das</st>` <st c="28065">and</st>
    `<st c="28070">feature-engine</st>`<st c="28084">.</st>
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用 `<st c="27973">pan</st><st c="28058">das</st>` `<st c="28065">和</st>`
    `<st c="28070">feature-engine</st>`<st c="28084">.</st>` 将一个变量离散化到预定义的用户区间。
- en: <st c="28085">How t</st><st c="28091">o do it...</st>
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="28085">如何</st><st c="28091">做到这一点...</st>
- en: <st c="28102">First, let’s</st> <st c="28116">imp</st><st c="28119">ort the
    necessary Python libraries and get the</st> <st c="28167">dataset ready:</st>
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28102">首先，让我们</st> <st c="28116">导入必要的Python库并</st> <st c="28167">准备好数据集：</st>
- en: <st c="28181">Import Python libraries</st> <st c="28206">and classes:</st>
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="28181">导入Python库和类：</st>
- en: '[PRE43]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: <st c="28343">Let’s load the California housing dataset into a</st> `<st c="28393">pandas</st>`
    <st c="28399">DataFrame:</st>
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="28343">让我们</st> <st c="28393">将加利福尼亚住房数据集</st> <st c="28399">加载到一个</st>
    `<st c="28393">pandas</st>` <st c="28399">DataFrame：</st>
- en: '[PRE44]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: <st c="28475">Let’s plot a</st> <st c="28488">histogram of the</st> `<st c="28506">Population</st>`
    <st c="28516">variable to find out its</st> <st c="28542">value range:</st>
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="28475">让我们</st> <st c="28488">绘制</st> `<st c="28506">人口</st>` <st c="28516">变量的直方图，以找出其</st>
    <st c="28542">值范围：</st>
- en: '[PRE45]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: <st c="28656">Population</st> <st c="28668">values vary between 0</st> <st c="28690">and</st>
    <st c="28694">approximately 40,000:</st>
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="28656">人口</st> <st c="28668">值在 0</st> <st c="28690">和</st> <st c="28694">大约
    40,000</st> 之间变化：</st>
- en: "![Figure 4.6 – Histogram of the \uFEFFPopulation variable](img/B22396_04_6.jpg)"
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – 人口变量的直方图](img/B22396_04_6.jpg)'
- en: <st c="28831">Figure 4.6 – Histogram of the</st> <st c="28861">Population variable</st>
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="28831">图 4.6 – 人口变量的直方图</st>
- en: <st c="28880">Let’s cre</st><st c="28890">ate a list with arbitrary interval
    limits, setting the upper limit to infinity to accommodate</st> <st c="28985">bigger
    values:</st>
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="28880">让我们</st> <st c="28890">创建一个包含任意区间极限的列表，将上限设置为无穷大以适应</st> <st c="28985">更大的值：</st>
- en: '[PRE46]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: <st c="29045">Let’s create a list with the interval limits</st> <st c="29091">as
    strings:</st>
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="29045">让我们</st> <st c="29091">创建一个包含区间极限的字符串列表：</st>
- en: '[PRE47]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: <st c="29166">Let’s make</st> <st c="29177">a copy of the dataset and discretize
    the</st> `<st c="29219">Population</st>` <st c="29229">variable into the pre-defined
    limits from</st> *<st c="29272">step 4</st>*<st c="29278">:</st>
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="29166">让我们</st> <st c="29177">复制数据集并</st> <st c="29219">将</st> `<st c="29229">人口</st>`
    <st c="29229">变量离散化到从</st> *<st c="29272">步骤 4</st>*<st c="29278">预定义的极限：</st>
- en: '[PRE48]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: <st c="29397">Now, let’s</st> <st c="29409">discretize</st> `<st c="29420">Population</st>`
    <st c="29430">into pre-defined intervals and name the intervals with the labels
    that we defined in</st> *<st c="29516">step 5</st>* <st c="29522">for comparison:</st>
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="29397">现在，让我们</st> <st c="29409">将</st> `<st c="29420">人口</st>` <st c="29430">变量离散化到预定义的区间，并使用我们在</st>
    *<st c="29516">步骤 5</st>* <st c="29522">中定义的标签来命名区间，以便进行比较：</st>
- en: '[PRE49]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: <st c="29641">Let’s</st> <st c="29648">inspect the first five rows of the original
    and</st> <st c="29696">discretized variables:</st>
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="29641">让我们</st> <st c="29648">检查原始和</st> <st c="29696">离散化变量的前五行：</st>
- en: '[PRE50]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '<st c="29786">In the last two columns of the DataFrame, we can see the discretized
    variables: the first one with the strings that we created in</st> *<st c="29917">step
    5</st>* <st c="29923">as values, and the second one with the</st> <st c="29963">interval
    limits:</st>'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="29786">在DataFrame的最后两列中，我们可以看到离散化变量：第一个以我们在</st> *<st c="29917">步骤 5</st>*
    <st c="29923">中创建的字符串作为值，第二个以</st> `<st c="29963">区间极限</st>`：</st>
- en: '[PRE51]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: <st c="30182">Note</st>
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="30182">注意</st>
- en: <st c="30187">We only need one of the variable versions, either the one with
    the value range or the one with the interval limits.</st> <st c="30304">In this
    recipe, I created both to highlight the different options offered</st> <st c="30378">by</st>
    `<st c="30381">pandas</st>`<st c="30387">.</st>
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="30187">我们只需要变量的一个版本，无论是值范围还是区间极限。</st> <st c="30304">在这个菜谱中，我创建了两个，以突出</st>
    `<st c="30381">pandas</st>`<st c="30387">.</st>` 提供的不同选项。
- en: <st c="30388">Finally, we</st> <st c="30401">can count and plot the</st> <st
    c="30424">number of observations within</st> <st c="30454">each interval:</st>
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="30388">最后，我们可以</st> <st c="30401">计算并绘制每个区间内的</st> <st c="30424">观察次数：</st>
- en: '[PRE52]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: <st c="30627">In the foll</st><st c="30639">owing figure, we can see that t</st><st
    c="30671">he number of obser</st><st c="30690">vations per</st> <st c="30703">interval
    varies:</st>
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="30627">在下面的图中，我们可以看到每个区间的观察次数</st><st c="30639">有所变化：</st>
- en: '![Figure 4.7 – The proportion of observations per interval after the discretization.](img/B22396_04_7.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – 离散化后每个区间的观测比例](img/B22396_04_7.jpg)'
- en: <st c="30824">Figure 4.7 – The proportion of observations per interval after
    the discretization.</st>
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="30824">图 4.7 – 离散化后每个区间的观测比例。</st>
- en: <st c="30906">To wrap up</st> <st c="30917">the recipe, let’s discretize multiple
    variables</st> <st c="30966">ut</st><st c="30968">ilizing</st> `<st c="30977">feature-engine</st>`<st
    c="30991">:</st>
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="30906">为了总结</st> <st c="30917">这个方法，让我们使用 `<st c="30977">feature-engine</st>`<st
    c="30991">`<st c="30966">来离散化多个变量</st> <st c="30968">utilizing</st>：
- en: <st c="30993">Let’s</st> <st c="30998">import</st> <st c="31006">the transformer:</st>
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="30993">让我们</st> <st c="30998">导入</st> <st c="31006">转换器：</st>
- en: '[PRE53]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: <st c="31085">Let’s create a dictionary with the variables as keys and the interval
    limits</st> <st c="31163">as values:</st>
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="31085">让我们创建一个字典，将变量作为键，将区间极限作为值：</st>
- en: '[PRE54]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: <st c="31269">Let’s set up the discretizer with the limits from</st> *<st c="31320">step
    11</st>*<st c="31327">:</st>
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="31269">让我们使用从</st> *<st c="31320">步骤 11</st>*<st c="31327">的极限来设置离散化器：</st>
- en: '[PRE55]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: <st c="31413">Now, we can go ahead and discretize</st> <st c="31450">the variables:</st>
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="31413">现在，我们可以继续对变量进行离散化</st> <st c="31450">处理：</st>
- en: '[PRE56]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: <st c="31499">If we execute</st> `<st c="31514">X_t.head()</st>`<st c="31524">,
    we will see the following output, where the</st> `<st c="31570">Population</st>`
    <st c="31580">and</st> `<st c="31585">MedInc</st>` <st c="31591">var</st><st c="31595">iables
    have</st> <st c="31608">been discretized:</st>
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="31499">如果我们执行</st> `<st c="31514">X_t.head()</st>`<st c="31524">`，我们将看到以下输出，其中</st>
    `<st c="31570">人口</st>` <st c="31580">和</st> `<st c="31585">中位收入</st>` <st c="31591">变量已经被离散化：</st>
- en: '![Figure 4.8 – A DataFrame containing the discretized variables](img/B22396_04_8.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8 – 包含离散化变量的 DataFrame](img/B22396_04_8.jpg)'
- en: <st c="32062">Figure 4.8 – A DataFrame containing the discretized variables</st>
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32062">图 4.8 – 包含离散化变量的 DataFrame</st>
- en: <st c="32123">The advantage</st> <st c="32137">of using</st> `<st c="32147">feature-engine</st>`
    <st c="32161">is that we</st> <st c="32173">can discretize multiple variables
    at the same time and apply arbitrary discretization as p</st><st c="32263">art
    of a</st> <st c="32273">scikit-learn</st> `<st c="32286">Pipeline</st>`<st c="32294">.</st>
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="32123">使用 `<st c="32147">feature-engine</st>` <st c="32161">的优势在于我们可以同时离散化多个变量，并将任意离散化作为
    scikit-learn `<st c="32286">Pipeline</st>`<st c="32294">的一部分。</st>
- en: <st c="32295">How it works...</st>
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="32295">它是如何工作的...</st>
- en: '<st c="32311">In this recipe, we sorted the values of a variable into user-defin</st><st
    c="32378">ed intervals.</st> <st c="32393">First, we plotted a histogram of the</st>
    `<st c="32430">Population</st>` <st c="32440">variable to get an idea of its va</st><st
    c="32474">lue range.</st> <st c="32486">Next, we arbitrarily determined the limits
    of the intervals and captured them in a list.</st> <st c="32575">We created intervals
    that included 0–200, 200–500, 500–1000, 1000–2000, and more than 2,000 by setting
    the upper limit to infinite with</st> `<st c="32711">np.inf</st>`<st c="32717">.
    Next, we created a list with the interval names as strings.</st> <st c="32779">Using
    pandas</st> `<st c="32792">cut()</st>` <st c="32797">and passing the list with
    the interval limits, we sorted the variable values into the pre-defined bins.</st>
    <st c="32902">We executed the command twice; in the first run, we set the</st>
    `<st c="32962">labels</st>` <st c="32968">argument to</st> `<st c="32981">None</st>`<st
    c="32985">, returning the interval limits as a result.</st> <st c="33030">In the
    second run, we set the</st> `<st c="33060">labels</st>` <st c="33066">argument
    to the list of strings.</st> <st c="33100">We captured the returned output in
    two variables: the first one displays the interval limits as values and the second
    one has strings as values.</st> <st c="33245">Finally, we counted the number of
    observations per variable using</st> <st c="33311">pandas</st> `<st c="33318">value_counts()</st>`<st
    c="33332">.</st>'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方法中，我们将一个变量的值排序到用户定义的区间中。首先，我们绘制了`<st c="32430">Population</st>`变量的直方图，以了解其值范围。接下来，我们任意确定了区间的限制，并将它们捕获在一个列表中。我们创建了包含0-200、200-500、500-1000、1000-2000以及超过2,000的区间，通过将上限设置为`<st
    c="32711">np.inf</st>`来设置。接下来，我们创建了一个包含区间名称的字符串列表。使用pandas的`<st c="32792">cut()</st>`，并传递包含区间限制的列表，我们将变量值排序到预定义的箱中。我们执行了两次命令；在第一次运行中，我们将`<st
    c="32962">labels</st>`参数设置为`<st c="32981">None</st>`，返回结果为区间限制。在第二次运行中，我们将`<st
    c="33060">labels</st>`参数设置为字符串列表。我们将返回的输出捕获在两个变量中：第一个变量显示区间限制作为值，第二个变量具有字符串作为值。最后，我们使用pandas的`<st
    c="33311">value_counts()</st>`对每个变量进行了观测次数的计数。
- en: <st c="33333">Finally, we automated the procedure with</st> `<st c="33375">feature-engine</st>`<st
    c="33389">’s</st> `<st c="33393">ArbitraryDiscretiser()</st>`<st c="33415">. This
    transformer takes a dictionary with the variables to discretize as keys and the
    interval limits in a list as values, and then uses pandas</st> `<st c="33560">cut()</st>`
    <st c="33565">under the hood to discretize the variables.</st> <st c="33610">With</st>
    `<st c="33615">fit()</st>`<st c="33620">, the transformer does not learn any parameters
    but checks that the variables are numerical.</st> <st c="33713">With</st> `<st
    c="33718">transform()</st>`<st c="33729">, it discretizes</st> <st c="33746">the
    variables.</st>
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用`<st c="33375">feature-engine</st>`的`<st c="33393">ArbitraryDiscretiser()</st>`函数自动化了该过程。这个转换器接受一个字典作为键，其中包含要离散化的变量，以及作为值的列表，其中包含区间限制，然后使用pandas的`<st
    c="33560">cut()</st>`在底层对变量进行离散化。使用`<st c="33615">fit()</st>`，转换器不会学习任何参数，而是检查变量是否为数值型。使用`<st
    c="33718">transform()</st>`，它将变量进行离散化。
- en: <st c="33760">Performing discretization</st> <st c="33787">with k-means clustering</st>
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用k-means聚类进行离散化
- en: <st c="33810">The aim o</st><st c="33820">f a discretization</st> <st c="33840">procedure
    is to find a set of cut points that</st> <st c="33885">partition a variable into
    a small number of intervals that have good class coherence.</st> <st c="33972">To
    create partitions that group similar observations, we can use clustering algorithms
    such</st> <st c="34064">as k-means.</st>
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 离散化过程的目标是找到一组切割点，将变量划分为几个具有良好类别一致性的小区间。为了创建将相似观测值分组在一起的分区，我们可以使用k-means等聚类算法。
- en: <st c="34075">In</st> <st c="34078">discretization using k-means clustering,
    the partitions are the clusters identified by the k-means algorithm.</st> <st
    c="34189">The k-means clustering algorithm has two main steps.</st> <st c="34242">In
    the initialization step,</st> *<st c="34270">k</st>* <st c="34271">observations
    are chosen randomly as the initial centers of the</st> *<st c="34335">k</st>*
    <st c="34336">clusters, and the remaining data points are assigned to the closest
    cluster.</st> <st c="34414">The proximity to the cluster is measured by a distance
    measure, such as the Euclidean distance.</st> <st c="34510">In the iteration step,
    the centers of the clusters are re-computed as the average of all of the observations
    within the cluster, and the observations are reassigned to the newly created closest
    cluster.</st> <st c="34713">The iteration step continues until the optimal</st>
    *<st c="34760">k</st>* <st c="34761">centers</st> <st c="34770">are found.</st>
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 k-means 聚类进行离散化时，分区是由 k-means 算法识别的聚类。<st c="34075">聚类算法有两个主要步骤。</st> <st
    c="34189">在初始化步骤中，<st c="34242">k</st> <st c="34270">个观测值被随机选择作为 <st c="34271">k</st>
    <st c="34335">个聚类的初始中心，其余数据点被分配到最近的聚类。</st> <st c="34414">聚类之间的接近程度是通过距离度量来衡量的，例如欧几里得距离。</st>
    <st c="34510">在迭代步骤中，聚类的中心被重新计算为聚类内所有观测值的平均值，观测值被重新分配到新创建的最近聚类。</st> <st c="34713">迭代步骤会继续进行，直到找到最佳
    <st c="34760">k</st> <st c="34761">中心</st> <st c="34770">。</st>
- en: <st c="34780">Discretization with k-means requires one parameter, which is</st>
    *<st c="34842">k</st>*<st c="34843">, the number of clusters.</st> <st c="34869">There
    are a few methods to determine the optimal number of clusters.</st> <st c="34938">One
    of them is the elbow method, which we will use in this recipe.</st> <st c="35005">This
    m</st><st c="35011">ethod consists of training s</st><st c="35040">everal k-means
    algorithms over the data using different values of</st> *<st c="35107">k</st>*<st
    c="35108">, and then determining the explained variation returned by the clustering.</st>
    <st c="35183">In the next step, we plot the explained variation as a function
    of the number of clusters,</st> *<st c="35274">k</st>*<st c="35275">, and pick
    the</st> *<st c="35290">elbow</st>* <st c="35295">of the curve as the number of
    clusters to use.</st> <st c="35343">The elbow is the inflection point that indicates
    that increasing the number of</st> *<st c="35422">k</st>* <st c="35423">further
    does not significantly increase the variance explained by the model.</st> <st
    c="35501">There are different metrics to quantify the explained variation.</st>
    <st c="35566">We will use the sum of the square distances from each point to its</st>
    <st c="35633">assigned center.</st>
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 k-means 进行离散化需要一个参数，即 <st c="34842">k</st> <st c="34843">，聚类的数量。<st c="34869">有一些方法可以确定最佳聚类数量。</st>
    <st c="34938">其中之一是肘部方法，我们将在本菜谱中使用。</st> <st c="35005">这种方法包括使用不同的 <st c="35107">k</st>
    <st c="35108">值在数据上训练多个 k-means 算法，然后确定聚类返回的解释变异。</st> <st c="35183">在下一步中，我们将解释变异作为聚类数量
    <st c="35274">k</st> <st c="35275">的函数进行绘图，并选择曲线的 <st c="35290">肘部</st> <st c="35295">作为要使用的聚类数量。</st>
    <st c="35343">肘部是拐点，表明增加 <st c="35422">k</st> <st c="35423">的数量不会显著增加模型解释的方差。</st>
    <st c="35501">有几种不同的指标可以量化解释变异。</st> <st c="35566">我们将使用每个点到其分配中心的平方距离之和。</st>
- en: <st c="35649">In this recipe, we will use the Python library</st> `<st c="35697">yellowbrick</st>`
    <st c="35708">to determine the optimal number of clusters and then carry out k-means</st>
    <st c="35779">discretization</st> <st c="35795">with scikit-learn.</st>
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用 Python 库 `<st c="35649">yellowbrick</st>` `<st c="35697">来决定最佳聚类数量，然后使用
    scikit-learn 执行 k-means `<st c="35779">离散化</st>` `<st c="35795">。</st>`
- en: <st c="35813">How to do it...</st>
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="35813">如何操作...</st>
- en: <st c="35829">Let’s start by importing the necessary Python libraries and get
    the</st> <st c="35898">dataset ready:</st>
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="35829">让我们首先导入必要的 Python 库，并准备好数据集：</st>
- en: <st c="35912">Import</st> <st c="35920">the required Python libraries</st> <st
    c="35950">and classes:</st>
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="35912">导入所需的 Python 库</st> <st c="35920">和类：</st>
- en: '[PRE57]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: <st c="36224">Let’s</st> <st c="36231">load the California housing dataset into
    a</st> `<st c="36274">pandas</st>` <st c="36280">DataFrame:</st>
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="36224">让我们将加利福尼亚住房数据集加载到一个 <st c="36274">pandas</st> <st c="36280">DataFrame</st>：</st>
- en: '[PRE58]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: <st c="36358">The k-means optimal clusters should be determined using the train
    set, so let’s divide the data into train and</st> <st c="36470">test sets:</st>
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="36358">k-means最佳簇应该使用训练集来确定，因此让我们将数据分为训练集和</st> <st c="36470">测试集：</st>
- en: '[PRE59]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: <st c="36570">Let’s make a list with the variables</st> <st c="36608">to transform:</st>
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="36570">让我们创建一个包含要转换的变量的列表：</st> <st c="36608">：</st>
- en: '[PRE60]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: <st c="36668">Let’s set up a k-means</st> <st c="36692">clustering algorithm:</st>
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="36668">让我们设置一个k-means</st> <st c="36692">聚类算法：</st>
- en: '[PRE61]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: <st c="36747">Now, using Yellowbrick’s visualizer and the elbow method, let’s
    find the optimal number of clusters for</st> <st c="36852">each variable:</st>
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="36747">现在，使用Yellowbrick的可视化器和肘部方法，让我们找到每个变量的最佳簇数量：</st> <st c="36852">：</st>
- en: '[PRE62]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: <st c="37066">In the</st> <st c="37074">following</st> <st c="37084">plots,
    we see that the optimal number of clusters is six for the first t</st><st c="37156">wo
    variables and seven for</st> <st c="37184">the third:</st>
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="37066">在</st> <st c="37074">以下</st> <st c="37084">图表中，我们看到前两个变量的最佳簇数量是六个，第三个是七个：</st>
- en: '![Figure 4.9 – The number of clusters versus the explained variation for the
    MedInc, HouseAge, and AveRooms variables, from top to bottom](img/B22396_04_9.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9 – MedInc、HouseAge和AveRooms变量中簇的数量与解释变异的关系，从上到下](img/B22396_04_9.jpg)'
- en: <st c="37557">Figure 4.9 – The number of clusters versus the explained variation
    for the MedInc, HouseAge, and AveRooms variables, from top to bottom</st>
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="37557">图4.9 – MedInc、HouseAge和AveRooms变量中簇的数量与解释变异的关系，从上到下</st>
- en: <st c="37692">Let’s set</st> <st c="37703">up a discretizer that</st> <st c="37724">uses
    k-means clustering to create six partitions and returns the clusters as</st> <st
    c="37802">one-hot-encoded variables:</st>
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="37692">让我们设置一个使用k-means聚类创建六个分区并将簇作为</st> <st c="37724">one-hot编码变量返回的离散化器：</st>
    <st c="37802">：</st>
- en: '[PRE63]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: <st c="37954">Let’s fit</st> <st c="37965">the discretizer to the slice of the</st>
    <st c="38000">DataFrame that contains the variables to discretize so that it finds
    the clusters for</st> <st c="38087">each variable:</st>
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="37954">让我们将离散化器拟合到包含要离散化变量的DataFrame切片中，以便它为每个变量找到簇：</st> <st c="38087">：</st>
- en: '[PRE64]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: <st c="38130">Note</st>
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38130">注意</st>
- en: <st c="38135">In this recipe, we sort the values of all three of the variables
    into six clusters.</st> <st c="38220">To discretize</st> `<st c="38234">MedInc</st>`
    <st c="38240">and</st> `<st c="38245">HouseAge</st>` <st c="38253">into six partitions
    and</st> `<st c="38278">AveRooms</st>` <st c="38286">into seven, we would set
    up one instance of the discretizer for each variable group and use the</st> `<st
    c="38383">ColumnTransformer()</st>` <st c="38402">to restrict the discretization
    to</st> <st c="38437">each group.</st>
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="38135">在这个菜谱中，我们将所有三个变量的值排序到六个簇中。</st> <st c="38220">要将</st> `<st c="38234">MedInc</st>`
    <st c="38240">和</st> `<st c="38245">HouseAge</st>` <st c="38253">离散化到六个分区，并将</st>
    `<st c="38278">AveRooms</st>` <st c="38286">离散化到七个，我们需要为每个变量组设置一个离散化器实例，并使用</st>
    `<st c="38383">ColumnTransformer()</st>` <st c="38402">将离散化限制在每个组中：</st>
- en: <st c="38448">Let’s inspect the</st> <st c="38467">cut points:</st>
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="38448">让我们检查</st> <st c="38467">切割点：</st>
- en: '[PRE65]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: <st c="38494">Each array contains the cut points for the six clusters for</st>
    `<st c="38555">MedInc</st>`<st c="38561">,</st> `<st c="38563">HouseAge</st>`<st
    c="38571">,</st> <st c="38573">and</st> `<st c="38577">AveRooms</st>`<st c="38585">:</st>
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="38494">每个数组包含</st> `<st c="38555">MedInc</st>`<st c="38561">、</st> `<st
    c="38563">HouseAge</st>`<st c="38571">、</st> <st c="38573">和</st> `<st c="38577">AveRooms</st>`<st
    c="38585">的六个簇的切割点：</st>
- en: '[PRE66]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: <st c="38873">Let’s obtain the discretized form of the variables in the train</st>
    <st c="38938">test sets:</st>
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="38873">让我们获取训练集测试集中变量的离散化形式：</st> <st c="38938">：</st>
- en: '[PRE67]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: <st c="39050">With</st> `<st c="39056">print(test_features)</st>`<st c="39076">,
    we can</st> <st c="39085">inspect the DataFrame that is returned by the discretizer.</st>
    <st c="39144">It contains 18 binary variables correspond</st><st c="39186">ing
    to the one-hot-encoded</st> <st c="39214">transformation</st> <st c="39229">of
    the six clusters returned for each of the three</st> <st c="39280">numerical variables:</st>
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="39050">使用</st> `<st c="39056">print(test_features)</st>`<st c="39076">，我们可以</st>
    <st c="39085">检查离散化器返回的DataFrame。</st> <st c="39144">它包含18个二元变量，对应于每个三个数值变量返回的六个簇的one-hot编码转换：</st>
    <st c="39186">：</st> <st c="39214">转换</st> <st c="39229">：</st> <st c="39280">：</st>
- en: '[PRE68]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: <st c="40004">You</st> <st c="40008">can</st> <st c="40013">concatenate the
    result to the original DataFrame using</st> `<st c="40068">pandas</st>` <st c="40074">and
    then drop the original numerical variables.</st> <st c="40123">Alternatively,
    use the</st> `<st c="40146">ColumnTransformer()</st>` <st c="40165">class to restrict
    the discretization to the selected variables and add the result to th</st><st
    c="40253">e data by setting</st> `<st c="40272">remainder</st>` <st c="40281">to</st>
    `<st c="40285">"passthrough"</st>`<st c="40298">.</st>
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40004">您</st> <st c="40008">可以使用</st> `<st c="40013">pandas</st>` <st
    c="40074">将结果连接到原始 DataFrame，然后删除原始数值变量。</st> <st c="40123">或者，使用</st> `<st c="40146">ColumnTransformer()</st>`
    <st c="40165">类将离散化限制在所选变量上，并通过将</st><st c="40253">`remainder`</st> <st c="40272">设置为</st>
    `<st c="40285">"passthrough"</st>`<st c="40298">将结果添加到数据中。</st>
- en: <st c="40299">How it works...</st>
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="40299">它是如何工作的...</st>
- en: <st c="40315">In this recipe, we performed discretization</st> <st c="40359">with
    k-means clustering.</st> <st c="40385">First</st><st c="40390">, we identified
    the optimal number of clusters utilizing the elbow method by using</st> <st c="40473">Yellowbrick’s</st>
    `<st c="40487">KElbowVisualizer()</st>`<st c="40505">.</st>
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40315">在这个配方中，我们使用 k-means 聚类进行了离散化。</st> <st c="40359">首先</st><st c="40385">，我们使用
    Yellowbrick 的</st> `<st c="40473">KElbowVisualizer()</st>`<st c="40505">通过肘部方法确定了最佳聚类数量。</st>
- en: <st c="40506">To perform k-means</st> <st c="40525">discretization, we used
    scikit-learn’s</st> `<st c="40565">KBinsDiscretizer()</st>`<st c="40583">, setting</st>
    `<st c="40593">strategy</st>` <st c="40601">to</st> `<st c="40605">kmeans</st>`
    <st c="40611">and the number of clusters to six in the</st> `<st c="40653">n_bins</st>`
    <st c="40659">argument.</st> <st c="40670">With</st> `<st c="40675">fit()</st>`<st
    c="40680">, the transformer learned the cluster boundaries using the k-means algorithm.</st>
    <st c="40758">With</st> `<st c="40763">transform()</st>`<st c="40774">, it sorted
    the variable values to their corresponding cluster.</st> <st c="40838">We set</st>
    `<st c="40845">encode</st>` <st c="40851">to</st> `<st c="40855">"onehot-dense"</st>`<st
    c="40869">; hence, after the discretization, the transformer applied one-hot encoding
    to the clusters.</st> <st c="40963">We also set the output of the discretizer
    to</st> `<st c="41008">pandas</st>`<st c="41014">, and with that, the transformer
    returned the one-hot encoded ver</st><st c="41079">sion of the clustered variables
    as</st> <st c="41115">a DataFrame.</st>
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="40506">为了执行 k-means</st> <st c="40525">离散化，我们使用了 scikit-learn 的</st>
    `<st c="40565">KBinsDiscretizer()</st>`<st c="40583">，将</st> `<st c="40593">strategy</st>`
    <st c="40601">设置为</st> `<st c="40605">kmeans</st>` <st c="40611">，并在</st> `<st
    c="40653">n_bins</st>` <st c="40659">参数中将聚类数量设置为六个。</st> <st c="40670">使用</st>
    `<st c="40675">fit()</st>`<st c="40680">，转换器通过 k-means 算法学习了聚类边界。</st> <st c="40758">使用</st>
    `<st c="40763">transform()</st>`<st c="40774">，它将变量值排序到相应的聚类。</st> <st c="40838">我们将</st>
    `<st c="40845">encode</st>` <st c="40851">设置为</st> `<st c="40855">"onehot-dense"</st>`<st
    c="40869">；因此，在离散化之后，转换器对聚类应用了独热编码。</st> <st c="40963">我们还设置了离散化器的输出为</st> `<st
    c="41008">pandas</st>`<st c="41014">，因此，转换器返回了作为 DataFrame 的聚类变量的独热编码版本。</st>
- en: <st c="41127">See also</st>
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="41127">另请参阅</st>
- en: <st c="41136">Discretization with k-means is described in the article found
    in</st> *<st c="41202">Palaniappan and Hong, Discretization of Continuous Valued
    Dimensions in OLAP Data Cube</st>*<st c="41288">s.</st> <st c="41292">International
    Journal of Computer Science and Network Security, VOL.8 No.11, November</st> <st
    c="41378">2008\.</st> [<st c="41384">http://paper.i</st><st c="41398">jcsns.org/07_book/200811/20081117.pdf</st>](http://paper.ijcsns.org/07_book/200811/20081117.pdf)<st
    c="41436">.</st>
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="41136">k-means 离散化在</st> *<st c="41202">Palaniappan 和 Hong，OLAP 数据立方体中连续值维度的离散化</st>*<st
    c="41288">文章中有描述。</st> <st c="41292">国际计算机科学和网络安全杂志，第 8 卷第 11 期，2008 年 11 月。</st>
    [<st c="41384">http://paper.i</st><st c="41398">jcsns.org/07_book/200811/20081117.pdf</st>](http://paper.ijcsns.org/07_book/200811/20081117.pdf)<st
    c="41436">。</st>
- en: <st c="41437">To learn more about the elbow method, visit Yellowbrick’s documentation
    and references</st> <st c="41525">at</st> [<st c="41528">https://www.scikit-yb.org/en/latest/api/cluster/elbow.html</st>](https://www.scikit-yb.org/en/latest/api/cluster/elbow.html)<st
    c="41586">.</st>
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="41437">要了解更多关于肘部方法的信息，请访问 Yellowbrick 的文档和参考资料</st> <st c="41525">在</st>
    [<st c="41528">https://www.scikit-yb.org/en/latest/api/cluster/elbow.html</st>](https://www.scikit-yb.org/en/latest/api/cluster/elbow.html)<st
    c="41586">。</st>
- en: <st c="41587">For other ways of determining the fit of k-means clustering, check
    out the additional visualizers in Yellowbrick</st> <st c="41701">at</st> [<st
    c="41704">https://www.</st><st c="41716">scikit-yb.org/en/latest/api/cluster/index.html</st>](https://www.scikit-yb.org/en/latest/api/cluster/index.html)<st
    c="41763">.</st>
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="41587">要确定 k-means 聚类分析的拟合度，请查看 Yellowbrick 的其他可视化工具</st> <st c="41701">在</st>
    [<st c="41704">https://www.</st><st c="41716">scikit-yb.org/en/latest/api/cluster/index.html</st>](https://www.scikit-yb.org/en/latest/api/cluster/index.html)<st
    c="41763">。</st>
- en: <st c="41764">Implementing feature binarization</st>
  id: totrans-291
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="41764">实现特征二值化</st>
- en: <st c="41798">Some datasets</st> <st c="41812">contain sparse variables.</st>
    <st c="41839">Sparse variables are those where the majority of the values are
    0\.</st> <st c="41906">The classical example of sparse va</st><st c="41940">riables
    are those derived from text data through the bag-of-words model, where each variable
    is a word and each value represents the number of times the word appears in a
    certain document.</st> <st c="42130">Given that a document contains a limited
    number of words, whereas the feature space contains the words that appear across
    all documents, most documents, that is, most rows, will show a value of 0 for
    most columns.</st> <st c="42344">However, words are not the</st> <st c="42371">sole
    example.</st> <st c="42385">If we think about house details data, the</st> *<st
    c="42427">number of saunas</st>* <st c="42443">variable will also be 0 for most
    houses.</st> <st c="42485">In summary, some variables have very skewed distributions,
    where most observations show the same value, usually 0, and only a few observations
    show different, usually</st> <st c="42652">higher, values.</st>
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="41798">一些数据集</st> <st c="41812">包含稀疏变量。</st> <st c="41839">稀疏变量是指大多数值都是
    0 的变量。</st> <st c="41906">稀疏变量的一个经典例子是通过词袋模型从文本数据中得到的，其中每个变量是一个单词，每个值代表该单词在某个文档中出现的次数。</st>
    <st c="42130">由于一个文档包含有限数量的单词，而特征空间包含所有文档中出现的单词，因此大多数文档，即大多数行，对于大多数列将显示值为 0。</st>
    <st c="42344">然而，单词并不是</st> <st c="42371">唯一的例子。</st> <st c="42385">如果我们考虑房屋细节数据，*<st
    c="42427">桑拿数量</st>* <st c="42443">变量对于大多数房屋也将是 0。</st> <st c="42485">总之，一些变量具有非常偏斜的分布，其中大多数观测值显示相同的值，通常是
    0，而只有少数观测值显示不同的值，通常是</st> <st c="42652">更高的值。</st>
- en: <st c="42667">For a simpler representation of these sparse or highly skewed
    variables, we can binarize them by clipping all values greater than 1 to 1\.</st>
    <st c="42806">In fact, binarization is commonly performed on text count data,
    where we consider the presence or absence of a feature rather than a quantified
    number of occurrences of</st> <st c="42975">a word.</st>
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更简单地表示这些稀疏或高度偏斜的变量，我们可以通过将所有大于 1 的值裁剪为 1 来对它们进行二值化。<st c="42806">实际上，二值化通常在文本计数数据上执行，我们考虑的是特征的呈现或缺失，而不是单词出现的量化次数。</st>
    <st c="42975">一个单词。</st>
- en: <st c="42982">In this recipe,</st> <st c="42998">we will perform binarizat</st><st
    c="43024">ion</st> <st c="43029">using</st> `<st c="43035">scikit-learn</st>`<st
    c="43047">.</st>
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="42982">在这个菜谱中，</st> <st c="42998">我们将使用</st> `<st c="43035">scikit-learn</st>`<st
    c="43047">.</st> 进行二值化。
- en: <st c="43048">Getting ready</st>
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="43048">准备工作</st>
- en: <st c="43062">We will use a dataset consisting of a bag of words, which is available
    in the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Bag+of+Words).</st>
    <st c="43229">It is licensed under CC BY</st> <st c="43256">4.0 (</st>[<st c="43261">https://creativecommons.org/licenses/by/4.0/legalcode</st>](https://creativecommons.org/licenses/by/4.0/legalcode)<st
    c="43315">).</st>
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个包含词袋的语料库，它可在 UCI 机器学习仓库（https://archive.ics.uci.edu/ml/datasets/Bag+of+Words）找到。<st
    c="43229">该数据集遵循 CC BY</st> <st c="43256">4.0</st> <st c="43261">（</st>[<st c="43261">https://creativecommons.org/licenses/by/4.0/legalcode</st>](https://creativecommons.org/licenses/by/4.0/legalcode)<st
    c="43315">）许可协议。</st>
- en: <st c="43318">I downloaded and prepared a small bag of words representing a
    simplified version of one of those datasets.</st> <st c="43426">You will find
    this dataset in the accompanying</st> <st c="43473">GitHub repository:</st>
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我下载并准备了一个小词袋，它代表了一个数据集的简化版本。<st c="43318">您可以在附带的</st> <st c="43426">GitHub
    仓库中找到这个数据集：</st>
- en: <st c="43491">https://github.com/PacktPublishing/Python-Feature-Engineering-Coo</st><st
    c="43557">kbook-Third-Edition/tr</st><st c="43580">ee/main/ch04-discretization</st>
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="43491">https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/tr</st><st
    c="43557">ee/main/ch04-discretization</st>
- en: <st c="43608">How to do it...</st>
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="43608">如何实现...</st>
- en: <st c="43624">Let’s begin by importing the libraries and loading</st> <st c="43676">the
    data:</st>
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="43624">让我们首先导入库并加载数据：</st> <st c="43676">：</st>
- en: <st c="43685">Let’s import the required Python libraries, classes,</st> <st
    c="43739">and datasets:</st>
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="43685">让我们导入所需的Python库、类和</st> <st c="43739">数据集：</st>
- en: '[PRE69]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: <st c="43901">Let’s load the bag of words dataset, which contains words as columns
    and different texts</st> <st c="43991">as rows:</st>
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="43901">让我们加载包含单词作为列和不同文本作为行的词袋数据集：</st> <st c="43991">：</st>
- en: '[PRE70]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: <st c="44038">Let’s</st> <st c="44044">display histograms to visualize the sparsity
    of</st> <st c="44093">the variables:</st>
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="44038">让我们</st> <st c="44044">显示直方图以可视化变量的稀疏性：</st>
- en: '[PRE71]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: <st c="44169">In the following histograms, we can see that the dif</st><st c="44222">ferent
    words appear zero times in</st> <st c="44257">most documents:</st>
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="44169">在以下直方图中，我们可以看到不同的单词在</st><st c="44222">大多数文档中</st> <st c="44257">没有出现：</st>
- en: "![Figure 4.10 – Histograms representing th\uFEFFe number of times each word\
    \ appears in a document](img/B22396_04_10.jpg)"
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![图4.10 – 表示每个单词在文档中出现的次数的直方图](img/B22396_04_10.jpg)'
- en: <st c="44633">Figure 4.10 – Histograms representing th</st><st c="44673">e number
    of times each word appears in a document</st>
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="44633">图4.10 – 表示每个单词在文档中出现的次数的直方图</st>
- en: <st c="44723">Let’s</st> <st c="44730">set up</st> `<st c="44737">binarizer</st>`
    <st c="44746">to clip all values greater than 1 to 1 and return DataFrames as</st>
    <st c="44811">a result:</st>
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="44723">让我们</st> <st c="44730">设置</st> `<st c="44737">binarizer</st>`
    <st c="44746">将所有大于1的值裁剪为1，并返回结果为</st> <st c="44811">DataFrame：</st>
- en: '[PRE72]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: <st c="44890">Let’s binarize</st> <st c="44906">the variables:</st>
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="44890">让我们二进制化</st> <st c="44906">变量：</st>
- en: '[PRE73]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: <st c="44959">Now we can explore the distribution of the binarized variables
    by displaying the histograms as</st> <st c="45055">in</st> *<st c="45058">step
    3</st>*<st c="45064">, or better, by creating</st> <st c="45089">bar plots.</st>
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="44959">现在我们可以通过显示直方图，如</st> <st c="45055">第3步</st><st c="45064">中所示，或者更好的方法，通过创建</st>
    <st c="45089">条形图来探索二进制变量的分布。</st>
- en: <st c="45099">Let’s</st> <st c="45105">create a bar plot with the number of
    observations per bin</st> <st c="45164">per variable:</st>
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="45099">让我们</st> <st c="45105">创建一个条形图，显示每个变量中每个箱的观测数</st> <st c="45164">：</st>
- en: '[PRE74]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: <st c="45487">In the following plot, we can see the binarized v</st><st c="45537">ariables,
    where most occurrences show the</st> `<st c="45580">0</st>` <st c="45581">value:</st>
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="45487">在下面的图中，我们可以看到二进制变量，其中大多数出现显示的是</st> `<st c="45580">0</st>` <st
    c="45581">值：</st>
- en: "![Figure 4.11 – Bar plots containing the number of documents that eithe\uFEFF\
    r show each one of the words or not](img/B22396_04_11.jpg)"
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![图4.11 – 包含显示或未显示每个单词的文档数量的条形图](img/B22396_04_11.jpg)'
- en: <st c="46228">Figure 4.11 – Bar plots containing the number of documents that
    eithe</st><st c="46297">r show each one of the words or not</st>
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="46228">图4.11 – 包含显示或未显示每个单词的文档数量的条形图</st><st c="46297">（部分显示）</st>
- en: <st c="46333">That’s it;</st> <st c="46344">now</st> <st c="46348">we have a
    simpler representation of</st> <st c="46385">the data.</st>
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="46333">这就完成了；</st> <st c="46344">现在</st> <st c="46348">我们有了数据的更简单表示。</st>
- en: <st c="46394">How it works…</st>
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="46394">它是如何工作的…</st>
- en: <st c="46408">In this recipe, we changed the representation of sparse variables
    to consider the presence or absence of an occurrence, which, in our case, is a
    word.</st> <st c="46560">The data consisted of a bag of words, where each variable
    (column) is a wor</st><st c="46635">d, each row is a document, and the values
    represent the number of times the word appears in a document.</st> <st c="46740">Most
    words do not appear in</st> <st c="46767">most documents; therefore, most values
    in the data are 0\.</st> <st c="46826">We corroborated the sparsity of our data</st>
    <st c="46867">with histograms.</st>
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="46408">在这个配方中，我们将稀疏变量的表示方式改为考虑出现与否，在我们的案例中，是一个单词。</st> <st c="46560">数据由一个词袋组成，其中每个变量（列）是一个单词，每行是一个文档，值表示单词在文档中出现的次数。</st>
    <st c="46740">大多数单词没有出现在</st> <st c="46767">大多数文档中；因此，数据中的大多数值是0。</st> <st c="46826">我们通过直方图证实了数据的稀疏性。</st>
- en: <st c="46883">scikit-learn’s</st> `<st c="46899">Binarizer()</st>` <st c="46910">mapped
    values greater than the threshold, which, in our case, was 0, to the</st> `<st
    c="46987">1</st>` <st c="46988">value, while values less than or equal to the
    threshold were mapped to 0\.</st> `<st c="47063">Binarizer()</st>` <st c="47074">has
    the</st> `<st c="47083">fit()</st>` <st c="47088">and</st> `<st c="47093">transform()</st>`
    <st c="47104">methods, where</st> `<st c="47120">fit()</st>` <st c="47125">does
    not do anything and</st> `<st c="47151">transform()</st>` <st c="47162">binarizes</st>
    <st c="47173">the variables.</st>
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="46883">scikit-learn 的</st> `<st c="46899">Binarizer()</st>` <st c="46910">将大于阈值的值映射到</st>
    `<st c="46987">1</st>` <st c="46988">值，而小于或等于阈值的值被映射到 0。</st> `<st c="47063">Binarizer()</st>`
    <st c="47074">具有</st> `<st c="47083">fit()</st>` <st c="47088">和</st> `<st c="47093">transform()</st>`
    <st c="47104">方法，其中</st> `<st c="47120">fit()</st>` <st c="47125">不执行任何操作，而</st>
    `<st c="47151">transform()</st>` <st c="47162">将变量二值化。</st>
- en: '`<st c="47187">Binarizer()</st>` <st c="47199">modifies all variables in a
    dataset returning NumPy arrays by default.</st> <st c="47271">To return</st> `<st
    c="47281">pandas</st>` <st c="47287">DataFr</st><st c="47294">ames instead, we
    set the transform output</st> <st c="47337">to</st> `<st c="47340">pandas</st>`<st
    c="47346">.</st>'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '`<st c="47187">Binarizer()</st>` <st c="47199">通过默认返回 NumPy 数组来修改数据集中的所有变量。</st>
    <st c="47271">要返回</st> `<st c="47281">pandas</st>` <st c="47287">DataFrame</st><st
    c="47294">，我们将转换输出设置为</st> `<st c="47337">pandas</st>`<st c="47346">。</st>'
- en: <st c="47347">Using decision trees for discretization</st>
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: <st c="47347">使用决策树进行离散化</st>
- en: <st c="47387">In all previous</st> <st c="47403">recipes in this chapter, we
    determined the number of intervals arbitrarily, and then the discretization algorithm
    would find the interval limits one way or another.</st> <st c="47569">Decision
    trees can find the interval limits and th</st><st c="47619">e optimal number of</st>
    <st c="47640">bins autom</st><st c="47650">atically.</st>
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="47387">在本章的所有先前</st> <st c="47403">食谱中，我们任意确定区间的数量，然后离散化算法会以某种方式找到区间限制。</st>
    <st c="47569">决策树可以自动找到区间限制和最优的箱数。</st>
- en: <st c="47660">Decision</st> <st c="47669">tree methods discretize continuous
    attributes during the learning process.</st> <st c="47745">At each node, a decision
    tree evaluates all possible values of a feature and selects the cut point that
    maximizes the class separation, or sample coherence, by utilizing a performance
    metric such as entropy or Gini impurity for classification, or the squared or
    absolute error for regression.</st> <st c="48038">As a result, the observations
    end up in certain leaves based on whether their feature values are greater or
    smaller than certain</st> <st c="48167">cut points.</st>
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="47660">决策树方法在学习过程中将连续属性离散化。</st> <st c="47745">在每个节点，决策树评估一个特征的所有可能值，并选择最大化类别分离或样本一致性的切割点，这通过使用性能指标如熵或基尼不纯度进行分类，或平方误差或绝对误差进行回归来实现。</st>
    <st c="48038">因此，观察结果根据其特征值是否大于或小于某些</st> <st c="48167">切割点而最终落在某些叶子节点。</st>
- en: <st c="48178">In the following figure, we can see the diagram of a decision
    tree that is trained to predict house prices based on the property’s average number</st>
    <st c="48325">of rooms:</st>
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="48178">在下面的图中，我们可以看到训练用于根据房产平均房间数预测房价的决策树图：</st> <st c="48325">:</st>
- en: '![Figure 4.12 – A diagram of a decision tree trained to predict house price
    based on the property’s average number of rooms](img/B22396_04_12.jpg)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.12 – 基于房产平均房间数的房价预测决策树图](img/B22396_04_12.jpg)'
- en: <st c="48749">Figure 4.12 – A diagram of a decision tree trained to predict
    house price based on the property’s average number of rooms</st>
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="48749">图 4.12 – 基于房产平均房间数的房价预测决策树图</st>
- en: <st c="48870">Based on this decision tree, houses with a smaller mean number
    of rooms than 5.5 will go to the first leaf, houses with a mean number of rooms
    between 5.5 and 6.37 will fall into the second leaf, houses with mean values between
    6.37 and 10.77 will end up in the third leaf, and</st> <st c="49149">houses with
    mean values greater than 10.77 will land in the</st> <st c="49209">fourth leaf.</st>
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="48870">根据这个决策树，平均房间数小于 5.5 的房屋将进入第一个叶子节点，平均房间数在 5.5 到 6.37 之间的房屋将进入第二个叶子节点，平均房间数在
    6.37 到 10.77 之间的房屋将进入第三个叶子节点，而</st> <st c="49149">平均房间数大于 10.77 的房屋将落在</st> <st
    c="49209">第四个叶子节点。</st>
- en: <st c="49221">As you see, by design, decision trees</st> <st c="49259">can find
    the set of cut points that partition a variable into intervals with good</st>
    <st c="49342">class coherence.</st>
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49221">如您所见，按照设计，决策树可以找到一组分割变量的切点，将变量分割成具有良好</st> <st c="49259">类别一致性</st>的区间。</st>
- en: <st c="49358">In this recipe,</st> <st c="49375">we will perform d</st><st c="49392">ecision
    tree-based discretization</st> <st c="49427">using Feature-engine.</st>
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49358">在这个菜谱中，</st> <st c="49375">我们将使用 Feature-engine 执行基于决策树的离散化：</st>
- en: <st c="49448">How to do it...</st>
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: <st c="49448">如何做到这一点...</st>
- en: <st c="49464">Let’s begin by importing some libraries and loading</st> <st c="49517">the
    data:</st>
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="49464">让我们首先导入一些库并加载数据：</st> <st c="49517">数据：</st>
- en: <st c="49526">Let’s import the required Python libraries, classes,</st> <st
    c="49580">and datasets:</st>
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="49526">让我们导入所需的 Python 库、类和数据集：</st>
- en: '[PRE75]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: <st c="49853">Let’s load the California housing dataset into a</st> `<st c="49903">pandas</st>`
    <st c="49909">DataFrame and then split it into train and</st> <st c="49953">test
    sets:</st>
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="49853">让我们将加利福尼亚住房数据集加载到一个</st> `<st c="49903">pandas</st>` <st c="49909">DataFrame中，并将其分为训练集和</st>
    <st c="49953">测试集：</st>
- en: '[PRE76]'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: <st c="50117">Let’s make a list with the names of the variables</st> <st c="50168">to
    discretize:</st>
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="50117">让我们创建一个包含要离散化变量名称的列表：</st>
- en: '[PRE77]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: <st c="50215">If we execute</st> `<st c="50230">print(variables)</st>`<st c="50246">,
    we’ll see the following variable names:</st> `<st c="50288">['MedInc'</st>`<st
    c="50297">,</st> `<st c="50299">'HouseAge'</st>`<st c="50309">,</st> `<st c="50311">'AveRooms'</st>`<st
    c="50321">,</st> `<st c="50323">'AveBedrms'</st>`<st c="50334">,</st> `<st c="50336">'</st>``<st
    c="50337">Population'</st>`<st c="50348">,</st> `<st c="50350">'AveOccup']</st>`<st
    c="50361">.</st>
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="50215">如果我们执行</st> `<st c="50230">print(variables)</st>`<st c="50246">，我们将看到以下变量名称：</st>
    `<st c="50288">['MedInc'</st>`<st c="50297">,</st> `<st c="50299">'HouseAge'</st>`<st
    c="50309">,</st> `<st c="50311">'AveRooms'</st>`<st c="50321">,</st> `<st c="50323">'AveBedrms'</st>`<st
    c="50334">,</st> `<st c="50336">'</st>``<st c="50337">Population'</st>`<st c="50348">,</st>
    `<st c="50350">'AveOccup']</st>`<st c="50361">.</st>
- en: <st c="50362">Let’s set</st> <st c="50373">up the transformer to discretize</st>
    <st c="50405">the variables from</st> *<st c="50425">step 3</st>*<st c="50431">.
    We want the transformer to optimize the hyperparameter’s maximum depth and minimum
    samples per leaf of each tree based on the negative mean square error metric using
    three-fold cross-validation.</st> <st c="50628">As the output of the discretization,
    we want the limits of</st> <st c="50687">the intervals:</st>
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="50362">让我们设置</st> <st c="50373">转换器以离散化</st> <st c="50405">从</st> *<st
    c="50425">步骤 3</st>*<st c="50431">中的变量。我们希望转换器根据三折交叉验证的负均方误差指标优化每个树的超参数的最大深度和每个叶子的最小样本数。我们希望离散化的输出是区间的范围：</st>
    <st c="50628">作为离散化的输出，我们希望得到区间的范围：</st>
- en: '[PRE78]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: <st c="50923">Let’s fit the discretizer using the train set so that it finds
    the best decision trees for each of</st> <st c="51023">the variables:</st>
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="50923">让我们使用训练集来拟合离散化器，以便它为每个变量找到最佳的决策树：</st>
- en: '[PRE79]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: <st c="51064">Note</st>
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="51064">注意</st>
- en: <st c="51069">You can inspect the limits of the found intervals for each variable
    in the</st> `<st c="51145">binner_dict_</st>` <st c="51157">attribute by executing</st>
    `<st c="51181">disc.binner_dict_</st>`<st c="51198">. Note how the discretizer
    appended minus and plus infinity to the limits to accommodate smaller and greater
    values than those observed in the</st> <st c="51341">training set.</st>
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="51069">您可以通过执行</st> `<st c="51181">disc.binner_dict_</st>`<st c="51198">来检查每个变量在</st>
    `<st c="51145">binner_dict_</st>` <st c="51157">属性中找到的区间的范围。注意离散化器如何将负无穷和正无穷添加到极限中，以适应训练集中观察到的较小和较大的值：</st>
    <st c="51341">训练集：</st>
- en: <st c="51354">Let’s discretize the variables and then display the first five
    rows of the transformed</st> <st c="51442">training set:</st>
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="51354">让我们对变量进行离散化，然后显示转换后训练集的前五行：</st>
- en: '[PRE80]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: <st c="51547">In the following</st> <st c="51564">output, we can see the limits
    of the</st> <st c="51601">intervals to which each observation</st> <st c="51638">was
    allocated:</st>
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="51547">在以下</st> <st c="51564">输出中，我们可以看到每个观测值被分配到的区间的范围：</st>
- en: '![Figure 4.13 – The first five rows of the transformed training set containing
    the discretized variables](img/B22396_04_13.jpg)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.13 – 包含离散化变量的转换后训练集的前五行](img/B22396_04_13.jpg)'
- en: <st c="52162">Figure 4.13 – The first five rows of the transformed training
    set containing the discretized variables</st>
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="52162">图 4.13 – 包含离散化变量的转换后训练集的前五行</st>
- en: <st c="52264">Note</st>
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="52264">注意</st>
- en: <st c="52269">If you choose to return the interval limits and want to use these
    datasets to train machine learning models, you will need to follow up the discretization
    with one-hot encoding or ordinal encoding.</st> <st c="52468">Check the recipes
    in</st> [*<st c="52489">Chapter 2</st>*](B22396_02.xhtml#_idTextAnchor182)<st
    c="52498">,</st> *<st c="52500">Encoding Categorical Variables</st>*<st c="52530">,
    for</st> <st c="52536">more details.</st>
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="52269">如果你选择返回区间限制并希望使用这些数据集来训练机器学习模型，你需要对离散化进行后续的一热编码或顺序编码。</st> <st
    c="52468">有关更多详细信息，请参阅</st> [*<st c="52489">第2章</st>*](B22396_02.xhtml#_idTextAnchor182)<st
    c="52498">，</st> *<st c="52500">编码分类变量</st>*<st c="52530">。</st>
- en: <st c="52549">Instead of returning the interval limits, we can return the interval
    number to which</st> <st c="52634">each observation is allocated by setting</st>
    <st c="52675">up the transformer</st> <st c="52695">like this:</st>
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="52549">我们不是返回区间限制，而是可以通过设置</st> <st c="52634">将每个观测值分配到相应区间的转换器</st>
    <st c="52675">来返回区间编号：</st>
- en: '[PRE81]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: <st c="52912">We can now fit and then transform the training and</st> <st c="52964">testing
    sets:</st>
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="52912">我们现在可以拟合并转换训练集和</st> <st c="52964">测试集：</st>
- en: '[PRE82]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: <st c="53056">If you now execute</st> `<st c="53076">train_t[variables].head()</st>`<st
    c="53101">, you will see integers as a result instead of the</st> <st c="53152">interval
    limits:</st>
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="53056">如果你现在执行</st> `<st c="53076">train_t[variables].head()</st>`<st
    c="53101">，你将看到整数结果而不是区间限制：</st>
- en: '![Figure 4.14 – The first five rows of the transformed training set containing
    the discretized variables](img/B22396_04_14.jpg)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![图4.14 – 包含离散化变量的转换训练集的前五行](img/B22396_04_14.jpg)'
- en: <st c="53292">Figure 4.14 – The first five rows of the transformed training
    set containing the discretized variables</st>
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="53292">图4.14 – 包含离散化变量的转换训练集的前五行</st>
- en: <st c="53394">To wrap up the recipe, we will make the discretizer return the
    predictions of the trees as replacement values for the</st> <st c="53513">discretized
    variables:</st>
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="53394">为了总结这个配方，我们将使离散化器返回树的预测值作为离散化变量的替换值：</st>
- en: <st c="53535">Let’s set up</st> <st c="53548">the transformer to return the</st>
    <st c="53579">predictions, then fit it to the training set, and finally transform</st>
    <st c="53647">both datasets:</st>
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="53535">让我们设置</st> <st c="53548">转换器以返回</st> <st c="53579">预测值，然后将其拟合到训练集，最后转换</st>
    <st c="53647">这两个数据集：</st>
- en: '[PRE83]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: <st c="53962">Let’s explore the number of unique values of the</st> `<st c="54012">AveRooms</st>`
    <st c="54020">variable before and after</st> <st c="54047">the discretization:</st>
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="53962">让我们探索在离散化前后</st> `<st c="54012">AveRooms</st>` <st c="54020">变量的唯一值数量：</st>
- en: '[PRE84]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: <st c="54125">In the following output, we can see that the predictions of the
    decision trees are also discrete or finite because the trees contain a finite
    number of end leaves;</st> `<st c="54290">7</st>`<st c="54291">, while the original</st>
    <st c="54311">variable</st> <st c="54321">contained more than 6000</st> <st c="54346">different
    values:</st>
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <st c="54125">在以下输出中，我们可以看到决策树的预测值也是离散的或有限的，因为树包含有限数量的末端叶子节点；</st> `<st c="54290">7</st>`<st
    c="54291">，而原始</st> <st c="54311">变量</st> <st c="54321">包含超过6000</st> <st c="54346">个不同的值：</st>
- en: '[PRE85]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: <st c="54373">To better understand the structure of the tree, we can capture
    it into</st> <st c="54445">a variable:</st>
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="54373">为了更好地理解树的结构，我们可以将其捕获到一个</st> <st c="54445">变量</st>中：</st>
- en: '[PRE86]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: <st c="54509">Note</st>
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="54509">注意</st>
- en: <st c="54514">When we set the transformer to return integers or bin limits,
    we will obtain the bin limits in the</st> `<st c="54614">binner_dict_</st>` <st
    c="54626">attribute.</st> <st c="54638">If we set the transformer to return the
    tree predictions,</st> `<st c="54696">binner_dict_</st>` <st c="54708">will contain
    the trained tree for</st> <st c="54743">each variable.</st>
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: <st c="54514">当我们设置转换器返回整数或箱限值时，我们将在</st> `<st c="54614">binner_dict_</st>`
    <st c="54626">属性中获得箱限值。</st> <st c="54638">如果我们设置转换器返回树预测值，</st> `<st c="54696">binner_dict_</st>`
    <st c="54708">将包含每个变量的训练树。</st>
- en: <st c="54757">Now, we can display the</st> <st c="54782">tree structure:</st>
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="54757">现在，我们可以显示</st> <st c="54782">树结构：</st>
- en: '[PRE87]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: <st c="54888">In the following figure, we can see the values used by the tree
    to allocate samples to the different end leaves based on the mean number</st>
    <st c="55026">of rooms:</st>
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: <st c="54888">在下面的图中，我们可以看到树根据房间数量的平均值将样本分配到不同的末端叶子节点所使用的值：</st>
- en: '![Figure 4.15 – The structure of the decision tree trained to discretize AveRooms](img/B22396_04_15.jpg)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![图4.15 – 训练用于离散化AveRooms的决策树结构](img/B22396_04_15.jpg)'
- en: <st c="55862">Figure 4.15 – The structure of the decision tree trained to discretize
    AveRooms</st>
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.15 – 训练用于离散化AveRooms的决策树结构
- en: <st c="55941">To wrap up the recipe, we can plot the number of observations
    per bin for three of</st> <st c="56025">the</st> <st c="56029">variables:</st>
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了总结这个方法，我们可以绘制三个变量每个区间的观测数：
- en: '[PRE88]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: <st c="56457">We can s</st><st c="56466">ee the</st> <st c="56474">number of
    observations per bin in the</st> <st c="56512">following output:</st>
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以在以下输出中看到每个区间的观测数：
- en: "![Figure 4.16 – The proportion of observations \uFEFFper bin after discretizing\
    \ the variables with decision trees](img/B22396_04_16.jpg)"
  id: totrans-382
  prefs: []
  type: TYPE_IMG
  zh: '![图4.16 – 使用决策树对变量进行离散化后的观测比例](img/B22396_04_16.jpg)'
- en: <st c="56827">Figure 4.16 – The proportion of observations</st> <st c="56872">per
    bin after discretizing the variables with decision trees</st>
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.16 – 使用决策树对变量进行离散化后的观测比例
- en: <st c="56932">As</st> <st c="56936">evidenced in</st> <st c="56949">the plots,
    discretization with decision tree</st><st c="56993">s</st> <st c="56996">returns
    a different fraction of observations at each node</st> <st c="57054">or bin.</st>
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 如图中所示，使用决策树进行离散化在每个节点或区间返回不同比例的观测值。
- en: <st c="57061">How it works...</st>
  id: totrans-385
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: <st c="57077">To perform discretization with decision trees, we used</st> <st
    c="57133">f</st>`<st c="57134">eature-engine</st>`<st c="57147">’s</st> `<st c="57151">Decision</st>`
    **<st c="57159">TreeDiscretiser()</st>**<st c="57177">. This transformer fitted
    a decision tree using each variable to discretize as input and optimized the hyperparameters
    of the model to find the best</st> <st c="57326">partitions</st> <st c="57337">based
    on a performance metric.</st> <st c="57368">It automatically found the optimal
    number of intervals, as well as their limits, returning</st> <st c="57458">either
    the limits, the bin number, or the predictions as</st> <st c="57516">a result.</st>
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行使用决策树的离散化，我们使用了`feature-engine`的`DecisionTreeDiscretiser()`。这个转换器使用每个变量作为输入来拟合决策树，并优化模型的超参数以找到基于性能指标的最佳分区。它自动找到最佳区间数量及其限制，返回结果可以是限制、区间编号或预测。
- en: <st c="57525">There’s more...</st>
  id: totrans-387
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: <st c="57541">The implementation of</st> `<st c="57564">feat</st><st c="57568">ure-engine</st>`
    <st c="57579">is inspired by the winning solution of the KDD 2009 data science
    competition.</st> <st c="57658">The winners created new features by obtaining
    predictions of decision trees based on continuous features.</st> <st c="57764">You
    can find more details in the</st> *<st c="57797">Winning the KDD Cup Orange Challenge
    with Ensemble Selection</st>* <st c="57857">article on</st> *<st c="57869">page
    27</st>* <st c="57876">of the article series</st> <st c="57899">at</st> [<st c="57902">http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf</st>](http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf)<st
    c="57957">.</st>
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '`<feature-engine>`的实现灵感来源于KDD 2009数据科学竞赛的获胜方案。获胜者通过基于连续特征的决策树预测创建了新特征。你可以在文章系列的第27页找到更多细节，文章标题为《用集成选择赢得KDD
    Cup Orange挑战》[*Winning the KDD Cup Orange Challenge with Ensemble Selection*](http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf)。'
- en: <st c="57958">For a review of discretization techniques, you might find the
    following</st> <st c="58031">articles useful:</st>
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 对于离散化技术的回顾，你可能觉得以下文章有用：
- en: '<st c="58047">Dougherty et al,</st> *<st c="58065">Supervised and Unsupervised
    Discretization of Continuous Features, Machine Learning: Proceedings of the 12th
    International Conference</st>*<st c="58198">,</st> <st c="58200">1995, (</st>[<st
    c="58207">https://ai.stanford.edu/~ronnyk/disc.pdf</st>](https://ai.stanford.edu/~ronnyk/disc.pdf)<st
    c="58248">).</st>'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dougherty等人，*《监督和非监督连续特征离散化，机器学习：第12届国际会议论文集》，1995年，(*[https://ai.stanford.edu/~ronnyk/disc.pdf](https://ai.stanford.edu/~ronnyk/disc.pdf)*)。*
- en: '<st c="58251">Lu et al,</st> *<st c="58262">Discretization: An Enabling Technique,
    Data Mining, and Knowledge Discovery</st>*<st c="58337">, 6, 393–423,</st> <st
    c="58351">2002, (</st>[<st c="58358">https://www.researchgate.net/publication/220451974_Discretization_An_Enabling_Technique</st>](https://www.researchgate.net/publication/220451974_Discretization_An_Enabling_Technique)<st
    c="58446">).</st>'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="58251">卢等人</st> *<st c="58262">《离散化：一种使能技术，数据挖掘与知识发现》</st>*<st c="58337">，第6卷，第393–423页，</st>
    <st c="58351">2002年，(</st>[<st c="58358">https://www.researchgate.net/publication/220451974_Discretization_An_Enabling_Technique</st>](https://www.researchgate.net/publication/220451974_Discretization_An_Enabling_Technique)<st
    c="58446">).</st>
- en: '<st c="58449">Garcia et al,</st> *<st c="58464">A Survey of Discretization
    Techniques: Taxonomy and Empirical Analysis in Supervised Learning, IEEE Transactions
    on Knowledge in Data</st> <st c="58597">Engineering 25 (4)</st>*<st c="58616">,</st>
    <st c="58618">2013, (</st>[<st c="58625">https://ieeexplore.ieee.org/document/6152258</st>](https://ieeexplore.ieee.org/document/6152258)<st
    c="58670">).</st>'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: <st c="58449">加西亚等人</st> *<st c="58464">《离散化技术综述：监督学习中的分类和实证分析，IEEE知识数据工程杂志》</st>
    <st c="58597">第25卷第4期</st>*<st c="58616">,</st> <st c="58618">2013年，(</st>[<st
    c="58625">https://ieeexplore.ieee.org/document/6152258</st>](https://ieeexplore.ieee.org/document/6152258)<st
    c="58670">).</st>
