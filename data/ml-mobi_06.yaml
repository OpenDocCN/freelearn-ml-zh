- en: The ML Kit SDK
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML Kit SDK
- en: In this chapter, we will discuss ML Kit, which was announced by Firebase at
    the Google I/O 2018\. This SDK packages Google's mobile machine learning offerings
    under a single umbrella.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论由Firebase在2018年Google I/O大会上宣布的ML Kit。此SDK将Google的移动机器学习产品打包在一个统一的框架下。
- en: Mobile application developers may want to implement features in their mobile
    apps that require machine learning capabilities. However, they may not have knowledge
    of machine learning concepts and which algorithms to use for which scenarios,
    how to build the model, train the model, and so on.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 移动应用开发者可能希望在他们的移动应用中实现需要机器学习功能的功能。然而，他们可能没有机器学习概念和算法的知识，不知道在哪种场景下使用哪种算法，如何构建模型，训练模型等等。
- en: ML Kit tries to address this problem by identifying all the potential use cases
    for machine learning in the context of mobile devices, and providing ready-made
    APIs. If the correct inputs are passed to these, the required output is received,
    with no further coding required.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit通过识别移动设备上下文中所有潜在的机器学习用例，并提供现成的API来解决这个问题。如果将这些正确的输入传递给它们，就会接收到所需输出，无需进一步编码。
- en: Additionally, this kit enables the inputs to be passed either to on-device APIs
    that work offline, or to online APIs that are hosted in the cloud.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，此套件还允许将输入传递到离线工作的设备端API，或者传递到托管在云端的在线API。
- en: To top it all, ML Kit also provides options for developers with expertise in
    machine learning, allowing them to build their own models using TensorFlow/TensorFlow
    Lite, and them import them into the application and invoke them using ML Kit APIs.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，ML Kit还为具有机器学习专业知识的开发者提供了选项，允许他们使用TensorFlow/TensorFlow Lite构建自己的模型，并将它们导入应用程序中，然后使用ML
    Kit API调用它们。
- en: ML Kit also offers further useful features, such as model upgrade and monitoring
    capabilities (if hosted with Firebase).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit还提供了其他有用的功能，例如模型升级和监控能力（如果与Firebase托管）。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中将涵盖以下主题：
- en: ML Kit and its features
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ML Kit及其功能
- en: Creating an image-labeling sample using ML Kit on-device APIs
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ML Kit设备端API创建图像标注示例
- en: Creating the same sample using ML Kit cloud APIs
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ML Kit云API创建相同的示例
- en: Creating Face Detection application
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建人脸检测应用
- en: Understanding ML Kit
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解ML Kit
- en: 'ML Kit encompasses all the existing Google offerings for machine learning on
    mobile. It bundles the Google Cloud Vision API, TensorFlow Lite, and the Android
    Neural Networks API together in a single SDK, as shown:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit包含了Google在移动设备上提供的所有现有机器学习产品。它将Google Cloud Vision API、TensorFlow Lite和Android
    Neural Networks API捆绑在一个SDK中，如下所示：
- en: '![](img/e34862b1-59df-45ab-acca-1aebfdb354b5.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e34862b1-59df-45ab-acca-1aebfdb354b5.png)'
- en: ML Kit enables developers to utilize machine learning in their mobile applications
    for both Android and iOS apps, in a very easy way. Inference can be carried out
    by invoking APIs that are either on-device or on-cloud.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit使开发者能够以非常简单的方式在Android和iOS应用中利用机器学习。推理可以通过调用设备端或云端的API来完成。
- en: The advantages of on-device APIs are that they work completely offline, and
    are more secure as no data is sent to the cloud. By contrast, on-cloud APIs do
    require network connectivity, and do send data off-device, but allow for greater
    accuracy.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 设备端API的优势在于它们完全离线工作，并且更安全，因为没有数据被发送到云端。相比之下，云API确实需要网络连接，并将数据发送到设备外，但允许更高的精度。
- en: 'ML Kit offers APIs covering the following machine learning scenarios that may
    be required by mobile application developers:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit提供了覆盖以下机器学习场景的API，这些场景可能被移动应用开发者所需要：
- en: Image labeling
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像标注
- en: Text recognition
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本识别
- en: Landmark detection
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 地标检测
- en: Face detection
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸检测
- en: Barcode scanning
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 条形码扫描
- en: All these APIs are implemented using complex machine learning algorithms. However,
    those details are wrapped. The mobile developer need not get into the details
    of which algorithms are used for implementing these APIs; all that needs to be
    done is to pass the desired data to the SDK, and in return the correct output
    will be received back, depending on which part of ML Kit is being used.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些API都是使用复杂的机器学习算法实现的。然而，这些细节都被封装了。移动开发者不需要深入了解用于实现这些API的算法细节；他们需要做的只是将所需数据传递给SDK，然后根据使用的ML
    Kit部分，将接收到正确的输出。
- en: If the provided APIs don't cover a specific use case, you can build your own
    TensorFlow Lite model. ML Kit will help to host that model, and serve it to your
    mobile application.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提供的API没有涵盖特定的用例，你可以构建自己的TensorFlow Lite模型。ML Kit将帮助托管该模型，并将其服务于你的移动应用程序。
- en: Since Firebase ML Kit provides both on-device and on-cloud capabilities, developers
    can come up with innovative solutions to leverage either or both, based on the
    specific problem at hand. All they need to know is that on-device APIs are fast
    and work offline, while Cloud APIs utilize the Google Cloud platform to provide
    predictions with increased levels of accuracy.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Firebase ML Kit提供设备上和云上的功能，开发者可以根据具体问题提出创新的解决方案，利用其中之一或两者。他们需要知道的是，设备上的API速度快，可以离线工作，而云API利用Google
    Cloud平台提供更高准确度的预测。
- en: 'The following diagram describes the issues to consider when deciding between
    on-device or on-cloud APIs:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表描述了在决定使用设备上或云上的API时需要考虑的问题：
- en: '![](img/7ad6b4d2-8c3b-420a-96ae-4d80d493b816.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7ad6b4d2-8c3b-420a-96ae-4d80d493b816.png)'
- en: ML Kit APIs
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML Kit API
- en: 'Not all APIs provided by ML Kit are supported in both on-device and on-cloud
    modes. The following table shows which APIs are supported in each mode:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 并非ML Kit提供的所有API都支持设备上和云上模式。以下表格显示了每种模式下支持哪些API：
- en: '![](img/d35b8fc6-71dc-4e0d-ae3c-e28c568a0796.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d35b8fc6-71dc-4e0d-ae3c-e28c568a0796.png)'
- en: Let's look at the details of each API.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看每个API的详细信息。
- en: Text recognition
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本识别
- en: ML Kit's text recognition APIs help with the recognition of text in any Latin-based
    language, using the mobile device camera. They are available both on-device and
    on-cloud.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit的文本识别API通过使用移动设备摄像头帮助识别任何基于拉丁字母的语言中的文本。它们既可以在设备上使用，也可以在云上使用。
- en: The on-device API allows for recognition of sparse text, or text present in
    images. The cloud API does the same, but also allows for recognition of bulk text,
    such as in documents. The cloud API also supports recognition of more languages
    than device APIs are capable of.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 设备上的API允许识别稀疏文本或图像中存在的文本。云API执行相同的操作，但还允许识别大量文本，如文档中的文本。云API还支持比设备API能够识别的更多语言。
- en: Possible use cases for these APIs would be to recognize text in images, to scan
    for characters that may be embedded in images, or to automate tedious data entry.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些API的可能用例包括在图像中识别文本、扫描可能嵌入在图像中的字符，或自动化繁琐的数据输入。
- en: Face detection
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸检测
- en: 'The ML Kit''s face detection API allows for the detection of faces in an image
    or video. Once the face is detected, we can apply the following refinements:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit的人脸检测API允许在图像或视频中检测人脸。一旦检测到人脸，我们可以应用以下改进：
- en: '**Landmark detection**: Determining specific points of interest (landmarks)
    within the face, such as the eyes'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地标检测**：确定人脸内的特定兴趣点（地标），如眼睛'
- en: '**Classification**: Classifying the face based on certain characteristics,
    such as whether the eyes are open or closed'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：根据某些特征（如眼睛是睁开还是闭合）对脸部进行分类'
- en: '**Face tracking**: Recognizing and tracking the same face (in various positions)
    across different frames of video'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人脸追踪**：识别和追踪视频不同帧中的同一人脸（在不同位置）'
- en: Face detection can be done only on-device and in real time. There may be many
    use cases for mobile device applications, in which the camera captures an image
    and manipulates it based on landmarks or classifications, to produce selfies,
    avatars, and so on.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸检测只能在设备上实时进行。在移动设备应用程序中可能有多种用例，其中摄像头捕捉图像并根据地标或分类进行操作，以生成自拍、头像等。
- en: Barcode scanning
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条形码扫描
- en: ML Kit's barcode-scanning API helps read data encoded using most standard barcode
    formats. It supports linear formats such as Codabar, Code 39, Code 93, Code 128,
    EAN-8, EAN-13, ITF, UPC-A, or UPC-E, as well as 2-D formats such as Aztec, Data
    Matrix, PDF417, or QR codes.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit的条形码扫描API有助于读取使用大多数标准条形码格式编码的数据。它支持线性格式，如Codabar、Code 39、Code 93、Code
    128、EAN-8、EAN-13、ITF、UPC-A或UPC-E，以及二维格式，如Aztec、Data Matrix、PDF417或QR码。
- en: The API can recognize and scan barcodes regardless of their orientation. Any
    structured data that is stored as a barcode can be recognized.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 该API可以识别和扫描无论其方向如何的条形码。任何存储为条形码的有序数据都可以被识别。
- en: Image labeling
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像标签
- en: ML Kit's image-labeling APIs help recognize entities in an image. There is no
    need for any other metadata information to be provided for this entity recognition.
    Image labeling gives insight into the content of images. The ML Kit API provides
    the entities in the images, along with a confidence score for each one.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit 的图像标注 API 帮助识别图像中的实体。对于此实体识别，无需提供任何其他元数据信息。图像标注可以深入了解图像内容。ML Kit API
    提供了图像中的实体，并为每个实体提供置信度分数。
- en: Image labeling is available both on-device and on-cloud, with the difference
    being the number of labels supported. The on-device API supports around 400 labels,
    while the cloud-based API supports up to 10,000.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图像标注既可在设备上使用，也可在云端使用，区别在于支持的标签数量。设备端 API 支持大约 400 个标签，而基于云的 API 支持多达 10,000
    个。
- en: Landmark recognition
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 地标识别
- en: The ML Kit's landmark recognition API helps recognize well-known landmarks in
    an image.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ML Kit 的地标识别 API 帮助识别图像中的知名地标。
- en: This API, when given an image as input, will provide the landmarks found in
    the image along with geographical coordinates and region information. The knowledge
    graph entity ID is also returned for the landmark. This ID is a string that uniquely
    identifies the landmark that was recognized.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当此 API 以图像作为输入时，将提供图像中找到的地标，包括地理坐标和区域信息。同时还会返回地标的知识图谱实体 ID。此 ID 是一个字符串，唯一标识已识别的地标。
- en: Custom model inference
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义模型推理
- en: If the APIs provided out-of-the-box are not sufficient for your use case, ML
    Kit also provides the option to create your own custom model and deploy it through
    ML Kit.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提供的现成 API 不足以满足您的用例，ML Kit 还提供了创建您自己的自定义模型并通过 ML Kit 部署它的选项。
- en: Creating a text recognition app using Firebase on-device APIs
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Firebase 在设备上创建文本识别应用
- en: 'To get started in ML Kit, you need to sign in to your Google account, activate
    your Firebase account, and create a Firebase project. Follow these steps:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 ML Kit，您需要登录您的 Google 账户，激活您的 Firebase 账户，并创建一个 Firebase 项目。按照以下步骤操作：
- en: Go to [https://firebase.google.com/.](https://firebase.google.com/)
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前往 [https://firebase.google.com/](https://firebase.google.com/)
- en: Sign in to your Google account, if you are not already signed in.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 登录您的 Google 账户，如果您尚未登录。
- en: Click Go to console in the menu bar.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在菜单栏中点击“转到控制台”。
- en: Click Add project to create a project and open it.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击“添加项目”以创建项目并打开它。
- en: Now open Android Studio, and create a project with an empty activity. Note down
    the app package name that you have given while creating the project—for example,  `com.packt.mlkit.textrecognizationondevice`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在打开 Android Studio，创建一个带有空活动的项目。记下您在创建项目时给出的应用包名——例如，`com.packt.mlkit.textrecognizationondevice`。
- en: 'Next, go to the Firebase console. In the Project overview menu, click Add app
    and give the required information. It will give you a JSON file to download. Add
    to the app folder of your project in project view in Android Studio, as shown
    in the following screenshot:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，转到 Firebase 控制台。在项目概览菜单中，点击“添加应用”并输入所需信息。它将提供一个 JSON 文件供您下载。将此文件添加到 Android
    Studio 项目视图中的项目应用文件夹中，如图所示：
- en: '![](img/7e38470b-fdb7-42a7-a5ff-2880d1e01259.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7e38470b-fdb7-42a7-a5ff-2880d1e01259.png)'
- en: 'Next, add the following lines of code to the manifest file:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将以下代码行添加到清单文件中：
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We need these permissions for our app to work. The next line tells the Firebase
    dependencies to download the **text recognition** (**OCR**) model from the Google
    server, and keep it in the device for inference:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要这些权限使我们的应用能够运行。下一行告诉 Firebase 依赖项从 Google 服务器下载**文本识别**（**OCR**）模型，并将其保存在设备上进行推理：
- en: '[PRE1]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The whole manifest file will look as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 整个清单文件将如下所示：
- en: '[PRE2]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, we need to add the Firebase dependencies to the project. To do so, we
    need to add the following lines to the project `build.gradle` file:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要将 Firebase 依赖项添加到项目中。为此，我们需要在项目的 `build.gradle` 文件中添加以下行：
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then open the module app `build.gradle` file, and add the following dependencies:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然后打开模块应用 `build.gradle` 文件，并添加以下依赖项：
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Also add the following line to the bottom of that file:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要在文件的底部添加以下行：
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, in your layout file, write the following `.xml` code to define the elements:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在您的布局文件中，编写以下 `.xml` 代码以定义元素：
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, it's time to code your application's main activity class.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候编写您应用程序的主活动类了。
- en: Please download the application code from Packt Github repository at [https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/mlkit](https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/mlkit).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 请从Packt Github仓库下载应用程序代码：[https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/mlkit](https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/mlkit)。
- en: 'We are assuming you are already familiar with Android—so, we are discussing
    the code using Firebase functionalities:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设你已经熟悉Android——因此，我们将使用Firebase功能讨论代码：
- en: '[PRE7]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The preceding code will import the firebase libraries.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行代码将导入firebase库。
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The preceding line will declare the firebase text recognizer.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行将声明firebase文本识别器。
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The preceding line will initialize the Firebase application context.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行将初始化Firebase应用程序上下文。
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The preceding line will get the on-device text recognizer.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行将获取设备上的文本识别器。
- en: '[PRE11]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The preceding code snippet registers the on-click-event listener for the take-picture
    button.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码片段为拍照按钮注册了点击事件监听器。
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Creating a bitmap from the byte array.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 从字节数组创建位图。
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The preceding line creates a firebase image object to pass through the recognizer.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行创建了一个firebase图像对象以传递给识别器。
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The preceding line passes the created image object to the recognizer for processing.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行将创建的图像对象传递给识别器进行处理。
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The preceding code block will add the on-success listener. It will receive a
    firebase vision text object, which it in turn displays to the user in the form
    of a `Toast` message.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码块将添加on-success监听器。它将接收一个firebase视觉文本对象，然后将其以`Toast`消息的形式显示给用户。
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The preceding code block will add the `on-failure` listener. It will receive
    an exception object, which is in turn a display error message to the user in the
    form of a `Toast` message.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码块将添加`on-failure`监听器。它将接收一个异常对象，然后将其转换为以`Toast`消息形式显示给用户的错误信息。
- en: 'When you run the preceding code, you will have the following output in your
    device:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行上一行代码时，你将在设备上得到以下输出：
- en: '![](img/70a9a836-c149-4fc8-88af-fc888459126f.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/70a9a836-c149-4fc8-88af-fc888459126f.png)'
- en: Note that you must be connected to the internet while installing this app, as
    Firebase needs to download the model to your device.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在安装此应用时，你必须连接到互联网，因为Firebase需要将模型下载到你的设备上。
- en: Creating a text recognition app using Firebase on-cloud APIs
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Firebase云端API创建文本识别应用
- en: In this section, we are going to convert the on-device app to a cloud app. The
    difference is that on-device apps download the model and store it on the device.
    This allows for a lower inference time, allowing the app to make quick predictions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将把设备上的应用转换为云端应用。区别在于设备上的应用会下载模型并存储在设备上。这允许有更低的推理时间，使得应用能够快速做出预测。
- en: By contrast, cloud-based apps upload the image to the Google server, meaning
    inference will happen there. It won't work if you are not connected to the internet.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，基于云的应用会将图像上传到Google服务器，这意味着推理将在那里进行。如果你没有连接到互联网，则不会工作。
- en: In this case, why use a cloud-based model? Because on-device, the model has
    limited space and processing hardware, whereas Google's servers are scalable.
    The Google on-cloud text recognizer model is also able to decode multiple languages.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，为什么使用基于云的模型？因为设备上的模型空间和处理硬件有限，而Google的服务器是可扩展的。Google的云端文本识别模型也能够解码多种语言。
- en: 'To get started, you need a Google Cloud subscription. Follow these steps:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，你需要一个Google Cloud订阅。按照以下步骤操作：
- en: Go to your Firebase project console
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前往你的Firebase项目控制台。
- en: In the menu on the left, you will see that you are currently on the Spark Plan
    (the free tier)
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在左侧菜单中，你会看到你目前处于Spark计划（免费层）。
- en: Click Upgrade, and follow the instructions to upgrade to the Blaze Plan, which
    is pay-as-you-go
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击“升级”，并按照说明升级到Blaze计划，这是按需付费。
- en: You need to provide credit card or payment details for verification purposes—these
    will not be charged automatically
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要提供信用卡或支付详情以供验证——这些将不会自动收费。
- en: Once you subscribe, you will receive 1,000 Cloud Vision API requests free each
    month
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦你订阅，你将每月免费获得1,000次Cloud Vision API请求
- en: This program can be tried only if you have a upgraded Blaze Plan and not a free
    tier account. The steps are given to create a upgraded account and please follow
    steps to get the account to try the program given.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当你拥有升级的Blaze计划而不是免费层账户时，才能尝试此程序。以下是创建升级账户的步骤，请按照步骤操作以尝试提供的程序。
- en: By default, Cloud Vision is not enabled for your project. To do so, you need
    to go to the following link: [https://console.cloud.google.com/apis/library/vision.googleapis.com/?authuser=0](https://console.cloud.google.com/apis/library/vision.googleapis.com/?authuser=0).
    In the top menu dropdown, select the Firebase project containing the Android app
    you added in the previous section.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Cloud Vision未为您的项目启用。要启用它，您需要访问以下链接：[https://console.cloud.google.com/apis/library/vision.googleapis.com/?authuser=0](https://console.cloud.google.com/apis/library/vision.googleapis.com/?authuser=0)。在顶部菜单下拉菜单中，选择包含您在上一节中添加的Android应用的Firebase项目。
- en: 'Click Enable to enable this feature for your app. The page will look like the
    following screenshot:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 点击启用以启用此功能。页面将看起来像以下截图：
- en: '![](img/aa14a5d0-5a6b-4135-bb4a-bd85d8a04f02.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/aa14a5d0-5a6b-4135-bb4a-bd85d8a04f02.png)'
- en: Now return to your code, and make the following changes.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在回到您的代码，并做出以下更改。
- en: You can find the application code in our Packt Github repository at:[ https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/Testrecognizationoncloud](https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/Testrecognizationoncloud).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在我们的Packt Github仓库中找到应用程序代码：[https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/Testrecognizationoncloud](https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/Testrecognizationoncloud)。
- en: All the other files, except the main activity, have no changes.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 除了主活动之外的所有其他文件都没有变化。
- en: 'The changes are as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 变更如下：
- en: '[PRE17]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now, we need to import the preceding packages as dependencies.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要将前面的包作为依赖项导入。
- en: '[PRE18]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The preceding code will declare the document text recognizer.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码将声明文档文本识别器。
- en: '[PRE19]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The preceding code instantiates and assigns the cloud text recognizer.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码实例化并分配了云文本识别器。
- en: '[PRE20]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The preceding code registers the on-click-event listener for the take-picture
    button.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码为拍照按钮注册了on-click-event监听器。
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The preceding line creates a bitmap from the byte array.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行从字节数组创建了一个位图。
- en: '[PRE22]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The preceding line creates a firebase image object to pass through the recognizer.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行创建了一个firebase图像对象以传递给识别器。
- en: '[PRE23]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The preceding line passes the created image object to the recognizer for processing.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行将创建的图像对象传递给识别器进行处理。
- en: '[PRE24]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The preceding code block will add the on-success listener. It will receive a
    FirebaseVision document text object, which is in turn displayed to the user in
    the form of a `Toast` message.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码块将添加on-success监听器。它将接收一个FirebaseVision文档文本对象，该对象随后以`Toast`消息的形式显示给用户。
- en: '[PRE25]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The preceding code block will add the on-failure listener. It will receive an
    exception object, which is in turn a display error message to the user in the
    form of a `Toast` message.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码块将添加on-failure监听器。它将接收一个异常对象，随后以`Toast`消息的形式向用户显示错误信息。
- en: '[PRE26]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Face detection using ML Kit
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ML Kit进行人脸检测
- en: Now we will try to understand how face detection works with ML Kit. Face detection,
    which was previously part of the Mobile Vision API, has now been moved to ML Kit.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将尝试了解如何使用ML Kit进行人脸检测。之前作为Mobile Vision API一部分的人脸检测现在已移动到ML Kit。
- en: Face detection concepts
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸检测概念
- en: The Google Developers page defines face detection as the process of automatically
    locating and detecting human faces in visual media (digital images or video).
    The detected face is reported at a position with an associated size and orientation.
    After the face is detected, we can search for landmarks present in the face such
    as the eyes and nose.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Google开发者页面将人脸检测定义为在视觉媒体（数字图像或视频）中自动定位和检测人类面部的过程。检测到的面部以关联的位置、大小和方向报告。面部被检测到后，我们可以搜索面部中存在的地标，如眼睛和鼻子。
- en: 'Here are some important terms to understand before we can move on to programming
    face detection with ML Kit:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续使用ML Kit进行编程人脸检测之前，以下是一些重要术语，我们需要理解：
- en: '**Face Orientation**: Detects faces at a range of different angles.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人脸朝向**：检测不同角度的人脸。'
- en: '**Face Recognition**: Determines whether two faces can belong to the same person.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人脸识别**：确定两个面部是否属于同一个人。'
- en: '**Face Tracking**: Refers to detecting faces in videos.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人脸追踪**：指在视频中检测人脸。'
- en: '**Landmark**: Refers to a point of interest within a face. This corresponds
    to the notable features on a face, such as the right eye, left eye, and nose base.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地标**：指人脸内的一个兴趣点。这对应于人脸上的显著特征，如右眼、左眼和鼻基底。'
- en: '**Classification**: Determines the presence of facial characteristics, such
    as open or closed eye or a smiling or serious face.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：确定面部特征的存在，例如眼睛是睁开还是闭合，或者面部是微笑还是严肃。'
- en: Sample solution for face detection using ML Kit
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ML Kit进行面部检测的示例解决方案
- en: Now open Android Studio, and create a project with an empty activity. Note down
    the app package name that you have given while creating the project—for example,
    `com.packt.mlkit.facerecognization`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在打开Android Studio，创建一个带有空活动的项目。记下您在创建项目时给出的应用程序包名——例如，`com.packt.mlkit.facerecognization`。
- en: 'Here we are going to modify the text recognization code to predict faces. So,
    we are not changing the package names and other things. Just the code changes.
    The project structure is the same as shown previously:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将修改文本识别代码以预测面部信息。因此，我们不会更改包名和其他内容。只是代码更改。项目结构与之前显示的相同：
- en: '![](img/bfd38de1-3b33-45d5-b438-bc647837d680.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/bfd38de1-3b33-45d5-b438-bc647837d680.png)'
- en: It's time to code our application's main activity class. First we need to download
    the application code from the Packt GitHub repository at [https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/facerecognization](https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/facerecognization).
    and open the project in Android Studio.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候编写我们应用程序的主活动类了。首先，我们需要从Packt GitHub仓库下载应用程序代码，网址为[https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/facerecognization](https://github.com/PacktPublishing/Machine-Learning-for-Mobile/tree/master/facerecognization)，然后在Android
    Studio中打开项目。
- en: 'Then we will add the following lines of code to the Gradle dependencies. Open
    the `build.gradle` file of the module app and add the following dependencies:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将添加以下代码行到Gradle依赖项中。打开模块app的`build.gradle`文件，并添加以下依赖项：
- en: '[PRE27]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now we will  add the import statements to work with face detection:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将添加导入语句以使用面部检测：
- en: '[PRE28]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The following statement will declare the `FaceDetector` object:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 以下语句将声明`FaceDetector`对象：
- en: '[PRE29]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now we will create an object and assign it to the declared detector:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将创建一个对象并将其分配给声明的检测器：
- en: '[PRE30]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We declared a string object to save the prediction messages to the user:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声明了一个字符串对象，用于将预测消息保存给用户：
- en: '[PRE31]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Here we will check whether the detector is operational; we also have a bitmap
    object that was obtained from the camera:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将检查检测器是否可操作；我们还有一个从相机获取的bitmap对象：
- en: '[PRE32]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Then we create a frame object, which `FaceDetector` class detect method needs
    to predict the face information:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建一个frame对象，这是`FaceDetector`类检测方法需要预测面部信息：
- en: '[PRE33]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Once it successfully detects, it will return the face object array. The following
    code appends the information that each `nface` object has to our results string:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦成功检测到，它将返回面部对象数组。以下代码将每个`nface`对象的信息附加到我们的结果字符串中：
- en: '[PRE34]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'If no faces are returned, then the following error message will be shown:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有返回面部，则将显示以下错误信息：
- en: '[PRE35]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'If the face size is not `0`, that means it already went through the `for` loop,
    which appended the faces information to our results text. Now we will add the
    total number of faces and end the result string:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果面部大小不是`0`，这意味着它已经通过了`for`循环，将面部信息附加到我们的结果文本中。现在我们将添加面部总数并结束结果字符串：
- en: '[PRE36]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If the detector is not operational then the error message will be shown to
    the user as follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果检测器不可操作，则错误信息将以以下方式显示给用户：
- en: '[PRE37]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Finally, the following code will show the results to the reader:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，以下代码将向读者展示结果：
- en: '[PRE38]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Running the app
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行应用程序
- en: 'Now it''s time to run the app. For that, you will have to connect your mobile
    to your desktop through the USB debugging option in your mobile and install the
    app:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候运行应用程序了。为此，您需要通过手机中的USB调试选项将您的手机连接到桌面，并安装应用程序：
- en: '![](img/024b29f4-2d08-4cb6-9efd-7533311a3949.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/024b29f4-2d08-4cb6-9efd-7533311a3949.png)'
- en: 'On running the app, you will have the following as the output:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 运行应用程序后，您将得到以下输出：
- en: '![](img/766c66a2-276a-4889-8b0d-b89b66259545.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/766c66a2-276a-4889-8b0d-b89b66259545.jpg)'
- en: Summary
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed ML Kit SDK, which was announced by Firebase at
    Google I/O 2018\. We covered different APIs provided by ML Kit, such as image
    labeling, text recognition, landmark detection, and more. We then created a text
    recognition app using on-device APIs, and then using on-cloud APIs. We also create
    an Face detection application by making minor changes in text recognition application.  In
    the next chapter, we will learn about a spam messages classifier and build a sample
    implementation of such a classifier for iOS.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了 Firebase 在 Google I/O 2018 上宣布的 ML Kit SDK。我们涵盖了 ML Kit 提供的不同 API，例如图像标签、文本识别、地标检测等。然后我们使用设备端
    API 创建了一个文本识别应用，接着又使用云端 API。我们还通过对文本识别应用进行微小修改创建了一个面部检测应用。在下一章中，我们将学习垃圾邮件分类器，并构建一个
    iOS 上的此类分类器的示例实现。
