- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: AWS is constantly driving new innovations that empower data scientists to explore
    a variety of machine learning cloud services. This book is your comprehensive
    reference for learning about and implementing advanced machine learning algorithms
    in AWS.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 不断推动新的创新，使数据科学家能够探索各种机器学习云服务。这本书是您了解和实施 AWS 上的高级机器学习算法的全面参考。
- en: As you go through this book, you'll gain insights into how these algorithms
    can be trained, tuned, and deployed in AWS using Apache Spark on Elastic MapReduce,
    SageMaker, and TensorFlow. While you focus on algorithms such as XGBoost, linear
    models, Factorization Machines, and deep networks, the book will also provide
    you with an overview of AWS, as well as detailed practical applications that will
    help you solve real-world problems. Every practical application includes a series
    of companion notebooks with all the necessary code to run on AWS. In the next
    few chapters, you will learn how to use SageMaker and EMR notebooks to perform
    a range of tasks, from smart analytics and predictive modeling through to sentiment
    analysis.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你阅读这本书，你将深入了解这些算法如何在 AWS 上使用 Apache Spark 在 Elastic MapReduce、SageMaker 和
    TensorFlow 上进行训练、调整和部署。当你专注于 XGBoost、线性模型、因子分解机以及深度网络等算法时，本书还将为你提供 AWS 的概述，以及帮助你解决现实世界问题的详细实际应用。每个实际应用都包括一系列配套笔记本，其中包含在
    AWS 上运行所需的所有代码。在接下来的几章中，你将学习如何使用 SageMaker 和 EMR 笔记本来执行一系列任务，从智能分析和预测建模到情感分析。
- en: By the end of this book, you will be equipped with the skills you need to effectively
    handle machine learning projects and implement and evaluate algorithms on AWS.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到这本书的结尾，你将掌握处理机器学习项目所需的技能，并在 AWS 上实现和评估算法。
- en: Who this book is for
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书面向的对象
- en: This book is for data scientists, machine learning developers, deep learning
    enthusiasts and AWS users who want to build advanced models and smart applications
    on the cloud using AWS and its integration services. Some understanding of machine
    learning concepts, Python programming and AWS will be beneficial.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书是为数据科学家、机器学习开发者、深度学习爱好者以及希望使用 AWS 和其集成服务在云上构建高级模型和智能应用的 AWS 用户而编写的。对机器学习概念、Python
    编程和 AWS 的了解将有所帮助。
- en: What this book covers
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖的内容
- en: '[Chapter 1](c8f24db7-b015-4025-b9fb-19e5a4007700.xhtml), *Getting Started with
    Machine Learning for AWS*, introduces machine learning to the readers. It explains
    why it is necessary for data scientists to learn about machine learning and how
    AWS can help them to solve various real-world problems. We also discuss the AWS
    services and tools that we will be covered in the book.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[第一章](c8f24db7-b015-4025-b9fb-19e5a4007700.xhtml)，*AWS 机器学习入门*，向读者介绍了机器学习。它解释了为什么数据科学家有必要学习机器学习，以及
    AWS 如何帮助他们解决各种现实世界的问题。我们还讨论了本书中将涵盖的 AWS 服务和工具。'
- en: '[Chapter 2](9163133d-07bc-43a6-88e6-c79b2187e257.xhtml), *Classifying Twitter
    Feeds with Naive Bayes*, introduces the basics of the Naive Bayes algorithm and
    presents a text classification problem that will be addressed by the use of this
    algorithm and language models. We''ll provide examples explaining how to apply
    Naive Bayes using scikit-learn and Apache Spark on SageMaker''s BlazingText. Additionally,
    we''ll explore how to use the ideas behind Bayesian reasoning in more complex
    scenarios. We will use the Twitter API to stream tweets from two different political
    candidates and predict who wrote them. We will use scikit-learn, Apache Spark,
    SageMaker, and BlazingText.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[第二章](9163133d-07bc-43a6-88e6-c79b2187e257.xhtml)，*使用朴素贝叶斯分类 Twitter 流*，介绍了朴素贝叶斯算法的基础，并展示了一个将通过使用此算法和语言模型解决的问题。我们将提供示例，解释如何使用
    scikit-learn 和 Apache Spark 在 SageMaker 的 BlazingText 上应用朴素贝叶斯。此外，我们还将探讨如何在更复杂的情况下使用贝叶斯推理背后的思想。我们将使用
    Twitter API 从两位不同的政治候选人那里实时获取推文，并预测是谁写的。我们将使用 scikit-learn、Apache Spark、SageMaker
    和 BlazingText。'
- en: '[Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml), *Predicting House
    Value with Regression Algorithms*, introduces the basics of regression algorithms
    and applies them to predict the price of houses given a number of features. We''ll
    also introduce how to use logistic regression for classification problems. Examples
    in SageMaker for scikit-learn and Apache Spark will be provided. We''ll be using
    the Boston Housing Price dataset [https://www.kaggle.com/c/boston-housing/](https://www.kaggle.com/c/boston-housing/),
    along with scikit-learn, Apache Spark, and SageMaker.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[第3章](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml)，*使用回归算法预测房价*，介绍了回归算法的基础知识，并将其应用于根据多个特征预测房价。我们还将介绍如何使用逻辑回归进行分类问题。将提供SageMaker中scikit-learn和Apache
    Spark的示例。我们将使用波士顿房价数据集[https://www.kaggle.com/c/boston-housing/](https://www.kaggle.com/c/boston-housing/)，以及scikit-learn、Apache
    Spark和SageMaker。'
- en: '[Chapter 4](af506fc8-f482-453e-8162-93a676b2e737.xhtml), *Predicting User Behavior
    with Tree-Based Methods*, introduces decision trees, random forests, and gradient
    boosted trees. We will explore how to use these algorithms to predict when users
    will click on ads. Additionally, we will explain how to use AWS EMR and Apache
    Spark to engineer models at a large scale. We will use the Adform click prediction
    dataset ([https://doi.org/10.7910/DVN/TADBY7](https://doi.org/10.7910/DVN/TADBY7),
    Harvard Dataverse, V2). We will use the xgboost, Apache Spark, SageMaker, and
    EMR libraries.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[第4章](af506fc8-f482-453e-8162-93a676b2e737.xhtml)，*使用基于树的算法预测用户行为*，介绍了决策树、随机森林和梯度提升树。我们将探讨如何使用这些算法来预测用户何时会点击广告。此外，我们还将解释如何使用AWS
    EMR和Apache Spark在大规模上构建模型。我们将使用Adform点击预测数据集([https://doi.org/10.7910/DVN/TADBY7](https://doi.org/10.7910/DVN/TADBY7)，哈佛数据集，V2)。我们将使用xgboost、Apache
    Spark、SageMaker和EMR库。'
- en: '[Chapter 5](ccd8e969-f651-4fb9-8ef2-026286577e70.xhtml), *Customer Segmentation
    Using Clustering Algorithms*, introduces the main clustering algorithms by exploring
    how to apply them for customer segmentation based on consumer patterns. Through
    AWS SageMaker, we will show how to run these algorithms in skicit-learn and Apache
    Spark. We will use the e-commerce data from Fabien Daniel ([https://www.kaggle.com/fabiendaniel/customer-segmentation/data](https://www.kaggle.com/fabiendaniel/customer-segmentation/data))
    and scikit-learn, Apache Spark, and SageMaker.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[第5章](ccd8e969-f651-4fb9-8ef2-026286577e70.xhtml)，*使用聚类算法进行客户细分*，通过探索如何根据消费者模式应用这些算法进行客户细分，介绍了主要的聚类算法。通过AWS
    SageMaker，我们将展示如何在skicit-learn和Apache Spark中运行这些算法。我们将使用来自Fabien Daniel的电子商务数据([https://www.kaggle.com/fabiendaniel/customer-segmentation/data](https://www.kaggle.com/fabiendaniel/customer-segmentation/data))以及scikit-learn、Apache
    Spark和SageMaker。'
- en: '[Chapter 6](c940bfe6-b849-4179-b8f8-65e5d44652d6.xhtml), *Analyzing Visitor
    Patterns to Make Recommendations*, presents the problem of finding similar users
    based on their navigation patterns in order to recommend custom marketing strategies.
    Collaborative filtering and distance-based methods will be introduced with examples
    in scikit-learn and Apache Spark on AWS SageMaker. We will use Kwan Hui Lim''s Theme
    Park Attraction Visits Dataset ([https://sites.google.com/site/limkwanhui/datacode](https://sites.google.com/site/limkwanhui/datacode)), Apache
    Spark, and SageMaker.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](c940bfe6-b849-4179-b8f8-65e5d44652d6.xhtml)，*分析访问模式以制定推荐策略*，提出了基于用户导航模式寻找相似用户的问题，以便推荐定制营销策略。我们将介绍协同过滤和基于距离的方法，并在AWS
    SageMaker上的scikit-learn和Apache Spark中提供示例。我们将使用Kwan Hui Lim的游乐场景点访问数据集([https://sites.google.com/site/limkwanhui/datacode](https://sites.google.com/site/limkwanhui/datacode))、Apache
    Spark和SageMaker。'
- en: '[Chapter 7](c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml), *Implementing Deep
    Learning Algorithms*, introduces the reader to the main concepts behind deep learning
    and explains why it has become so relevant in today''s AI-powered products. The
    aim of this chapter is to not discuss the theoretical details of deep learning,
    but to explain the algorithms with examples and provide a high-level conceptual
    understanding of deep learning algorithms. This will give the readers a platform
    to understand what they are implementing in the next chapters.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml)，*实现深度学习算法*，向读者介绍了深度学习背后的主要概念，并解释了为什么它在今天的AI产品中变得如此重要。本章的目的是不讨论深度学习的理论细节，而是通过示例解释算法，并提供对深度学习算法的高级概念理解。这将给读者提供一个平台，以了解他们在下一章中将要实现的内容。'
- en: '[Chapter 8](a05fc52e-bb4c-4200-b0c5-154dccaad739.xhtml), *Implementing Deep
    Learning with TensorFlow on AWS*, goes through a series of practical image-recognition
    problems and explains how to address them with TensorFlow on AWS. TensorFlow is
    a very popular deep learning framework that can be used to train deep neural networks.
    This chapter will explain how TensorFlow can be installed by readers and used
    to train deep learning models using toy datasets. In this chapter, we''ll use
    the MNIST handwritten digits dataset ([http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)),
    along with TensorFlow and SageMaker.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[第8章](a05fc52e-bb4c-4200-b0c5-154dccaad739.xhtml), 《在AWS上使用TensorFlow实现深度学习*》*，通过一系列实用的图像识别问题，并解释如何使用AWS上的TensorFlow来解决这些问题。TensorFlow是一个非常流行的深度学习框架，可以用来训练深度神经网络。本章将解释读者如何安装TensorFlow，并使用玩具数据集来训练深度学习模型。在本章中，我们将使用MNIST手写数字数据集
    ([http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/))，以及TensorFlow和SageMaker。'
- en: '[Chapter 9](37b99b21-96c2-4857-b8e0-686179d109cf.xhtml), *Image Classification
    and Detection with SageMaker*, revisits the image classification problem we dealt
    with in the previous chapters, but using SageMaker''s image classification algorithm
    and object detection algorithm. We''ll use the following datasets:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9章](37b99b21-96c2-4857-b8e0-686179d109cf.xhtml), 《使用SageMaker进行图像分类和检测*》*，回顾了我们在前几章中处理过的图像分类问题，但这次使用SageMaker的图像分类算法和目标检测算法。我们将使用以下数据集：'
- en: Caltech256 ([http://www.vision.caltech.edu/Image_Datasets/Caltech256/](http://www.vision.caltech.edu/Image_Datasets/Caltech256/))
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Caltech256 ([http://www.vision.caltech.edu/Image_Datasets/Caltech256/](http://www.vision.caltech.edu/Image_Datasets/Caltech256/))
- en: We'll also use AWS Sagemaker.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用AWS Sagemaker。
- en: '[Chapter 10](b83ce0ca-e2d7-43f5-9e82-21edb54250c9.xhtml), *Working with AWS
    Comprehend*, explains the functionality of an AWS tool called Comprehend, which
    is an NLP tool that performs various useful tasks.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[第10章](b83ce0ca-e2d7-43f5-9e82-21edb54250c9.xhtml), 《与AWS Comprehend协作*》*，解释了AWS工具Comprehend的功能，这是一个执行各种有用任务的NLP工具。'
- en: '[Chapter 11](b6601397-10a0-4a94-ba9f-32b5bfcdbb06.xhtml), *Using AWS Rekognition*,
    explains how to use Rekognition, which is an image recognition tool that uses
    deep learning. The readers will learn an easy way of applying image recognition
    in their applications.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[第11章](b6601397-10a0-4a94-ba9f-32b5bfcdbb06.xhtml), 《使用AWS Rekognition*》*，解释了如何使用Rekognition，这是一个使用深度学习的图像识别工具。读者将学习一种简单的方法，将图像识别应用于他们的应用程序中。'
- en: '[Chapter 12](f9e097f0-ee26-456d-9360-7d0d3743e3a6.xhtml), *Building Conversational
    Interfaces Using AWS Lex*, explains that AWS Lex is a tool that allows programmers
    to build conversational interfaces. This chapter introduces the readers to topics
    such as natural language understanding using deep learning.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[第12章](f9e097f0-ee26-456d-9360-7d0d3743e3a6.xhtml), 《使用AWS Lex构建对话界面*》*，解释了AWS
    Lex是一个允许程序员构建对话界面的工具。本章向读者介绍了诸如使用深度学习进行自然语言理解等主题。'
- en: '[Chapter 13](06270fa5-1364-4ad2-b4a0-3522c1ef7bcd.xhtml), *Creating Clusters
    on AWS*, discusses that one of the key problems in deep learning is understanding
    how to scale and parallelize learning on multiple machines. In this chapter, we''ll
    examine different ways to create clusters of learners. In particular, we''ll focus
    on how to parallelize deep learning pipelines through distributed TensorFlow and
    Apache Spark.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[第13章](06270fa5-1364-4ad2-b4a0-3522c1ef7bcd.xhtml), 《在AWS上创建集群*》*，讨论了深度学习中的一个关键问题，即理解如何在多台机器上扩展和并行化学习。在本章中，我们将探讨创建学习者集群的不同方法。特别是，我们将关注如何通过分布式TensorFlow和Apache
    Spark并行化深度学习管道。'
- en: '[Chapter 14](7de65295-dd1f-4eb3-af00-3868ed7e2df9.xhtml), *Optimizing Models
    in Spark and SageMaker*, explains that the models that are trained on AWS can
    be further optimized to run smoothly in production environments. In this section,
    we will discuss various tricks that our readers can use to improve the performance
    of their algorithms.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[第14章](7de65295-dd1f-4eb3-af00-3868ed7e2df9.xhtml), 《在Spark和SageMaker中优化模型*》*，解释了在AWS上训练的模型可以进一步优化，以便在生产环境中平稳运行。在本节中，我们将讨论读者可以使用的一些技巧，以改善他们算法的性能。'
- en: '[Chapter 15](691fc3d8-e4b8-4e3f-a8d9-e13f53f058c4.xhtml), *Tuning Clusters
    for Machine Learning*, explains that many data scientists and machine learning
    practitioners face the problem of scale when attempting to run machine learning
    data pipelines at scale. In this chapter, we focus primarily on EMR, which is
    a very powerful tool for running very large machine learning jobs. There are many
    ways to configure EMR, and not every setup works for every scenario. We will go
    through the main configurations of EMR and explain how each configuration works
    for different objectives. Additionally, we''ll present other ways to run big data
    pipelines through AWS.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[第15章](691fc3d8-e4b8-4e3f-a8d9-e13f53f058c4.xhtml)，*调整集群以适应机器学习*，解释了许多数据科学家和机器学习实践者在尝试大规模运行机器学习数据管道时面临规模问题。在本章中，我们主要关注EMR，这是一个运行非常大的机器学习作业的非常强大的工具。配置EMR有许多方法，并不是每一种设置都适用于每一种场景。我们将介绍EMR的主要配置，并解释每种配置如何适用于不同的目标。此外，我们还将介绍其他通过AWS运行大数据管道的方法。'
- en: '[Chapter 16](6bc1a319-1195-4c30-8de8-09c795076f10.xhtml), *Deploying Models
    Built on AWS*, discusses deployment. At this point, readers will have their models
    built on AWS and would like to ship them to production. We understand that there
    are a variety of different contexts in which models should be deployed. In some
    cases, it''s as easy as generating a CSV of actions that would be fed to some
    system. Often, we just need to deploy a web service that''s capable of making
    predictions. However, there are many times in which we need to deploy these models
    to complex, low-latency, or edge systems. We will go through the different ways
    you can deploy machine learning models to production.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[第16章](6bc1a319-1195-4c30-8de8-09c795076f10.xhtml)，*在AWS上构建的模型部署*，讨论了部署问题。到这时，读者将已经在AWS上构建了模型，并希望将它们部署到生产环境中。我们理解模型应该部署的上下文有很多种。在某些情况下，这就像生成一个将输入到某些系统的动作的CSV文件一样简单。通常，我们只需要部署一个能够进行预测的Web服务。然而，有许多时候我们需要将这些模型部署到复杂、低延迟或边缘系统中。我们将介绍您可以将机器学习模型部署到生产环境的不同方法。'
- en: To get the most out of this book
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 要充分利用本书
- en: This book covers a number of different frameworks, such as Spark and Tensorflow.
    However it is not meant to be a comprehensive guide for each. Instead we focus
    on the way AWS empowers practical machine learning through the use of the different
    frameworks. We encourage the readers to refer to other books with framework-specific
    content when necessary.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本书涵盖了多个不同的框架，例如Spark和Tensorflow。但它并不是针对每个框架的全面指南。相反，我们关注AWS如何通过使用不同的框架来赋予实际机器学习能力。我们鼓励读者在需要时参考其他具有特定框架内容的书籍。
- en: Download the example code files
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from your account at [www.packt.com](http://www.packt.com).
    If you purchased this book elsewhere, you can visit [www.packt.com/support](http://www.packt.com/support)
    and register to have the files emailed directly to you.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[www.packt.com](http://www.packt.com)的账户下载本书的示例代码文件。如果您在其他地方购买了本书，您可以访问[www.packt.com/support](http://www.packt.com/support)并注册，以便将文件直接通过电子邮件发送给您。
- en: 'You can download the code files by following these steps:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下步骤下载代码文件：
- en: Log in or register at [www.packt.com](http://www.packt.com).
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[www.packt.com](http://www.packt.com)登录或注册。
- en: Select the SUPPORT tab.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“支持”标签。
- en: Click on Code Downloads & Errata.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“代码下载与勘误”。
- en: Enter the name of the book in the Search box and follow the onscreen instructions.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索框中输入书名，并遵循屏幕上的说明。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦文件下载完成，请确保您使用最新版本的软件解压或提取文件夹：
- en: WinRAR/7-Zip for Windows
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WinRAR/7-Zip for Windows
- en: Zipeg/iZip/UnRarX for Mac
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipeg/iZip/UnRarX for Mac
- en: 7-Zip/PeaZip for Linux
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7-Zip/PeaZip for Linux
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Mastering-Machine-Learning-on-AWS](https://github.com/PacktPublishing/Mastering-Machine-Learning-on-AWS). In
    case there's an update to the code, it will be updated on the existing GitHub
    repository.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 该书的代码包也托管在GitHub上，网址为[https://github.com/PacktPublishing/Mastering-Machine-Learning-on-AWS](https://github.com/PacktPublishing/Mastering-Machine-Learning-on-AWS)。如果代码有更新，它将在现有的GitHub仓库中更新。
- en: We also have other code bundles from our rich catalog of books and videos available
    at **[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)**.
    Check them out!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有其他来自我们丰富的图书和视频目录的代码包，可在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)找到。查看它们吧！
- en: Download the color images
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载彩色图像
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [http://www.packtpub.com/sites/default/files/downloads/9781789349795_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/9781789349795_ColorImages.pdf).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一份包含本书中使用的截图/图表彩色图像的PDF文件。您可以从这里下载：[http://www.packtpub.com/sites/default/files/downloads/9781789349795_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/9781789349795_ColorImages.pdf)。
- en: Conventions used
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用了多种文本约定。
- en: '`CodeInText`: Indicates code words in text, database table names, folder names,
    filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.
    Here is an example: "The following screenshot shows the first few lines of our
    `df` dataframe."'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`CodeInText`：表示文本中的代码单词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter昵称。以下是一个示例：“以下截图显示了我们的`df`数据框的前几行。”'
- en: 'A block of code is set as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出都按以下方式编写：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: "You can also train a custom NER algorithm in AWS Comprehend using the Customization | Custom
    entity recognition option in the left menu."'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示新术语、重要单词或屏幕上看到的单词。例如，菜单或对话框中的单词在文本中显示如下。以下是一个示例：“您还可以在AWS Comprehend中使用自定义NER算法进行训练，方法是在左侧菜单中选择自定义
    | 自定义实体识别选项。”'
- en: Warnings or important notes appear like this.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要注意事项显示如下。
- en: Tips and tricks appear like this.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 技巧和窍门显示如下。
- en: Get in touch
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们欢迎读者的反馈。
- en: '**General feedback**: If you have questions about any aspect of this book,
    mention the book title in the subject of your message and email us at `customercare@packtpub.com`.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：如果您对本书的任何方面有疑问，请在邮件主题中提及书名，并给我们发送邮件至`customercare@packtpub.com`。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packt.com/submit-errata](http://www.packt.com/submit-errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误表**：尽管我们已经尽最大努力确保内容的准确性，但错误仍然可能发生。如果您在这本书中发现了错误，我们将不胜感激，如果您能向我们报告这个错误。请访问[www.packt.com/submit-errata](http://www.packt.com/submit-errata)，选择您的书籍，点击勘误提交表单链接，并输入详细信息。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the Internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packt.com` with a link
    to the material.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果您在互联网上发现我们作品的任何非法副本，我们将不胜感激，如果您能提供位置地址或网站名称。请通过`copyright@packt.com`与我们联系，并提供材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com/).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个领域有专业知识，并且您有兴趣撰写或为书籍做出贡献，请访问[authors.packtpub.com](http://authors.packtpub.com/)。'
- en: Reviews
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评论
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 请留下评论。一旦您阅读并使用过这本书，为何不在您购买它的网站上留下评论呢？潜在读者可以查看并使用您的客观意见来做出购买决定，Packt公司可以了解您对我们产品的看法，我们的作者也可以看到他们对书籍的反馈。谢谢！
- en: For more information about Packt, please visit [packt.com](http://www.packt.com/).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解更多关于Packt的信息，请访问[packt.com](http://www.packt.com/)。
