- en: '*Chapter 8*: DevOps and MLOps for the Edge'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第8章*：边缘的DevOps和MLOps'
- en: The 21st century's flurry of connected devices has transformed the way we live.
    It can be hard to remember the days without the convenience of smartphones, smartwatches,
    personal digital assistants (such as Amazon Alexa), connected cars, smart thermostats,
    or other devices.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 21世纪的连接设备激增改变了我们的生活方式。很难回忆起没有智能手机、智能手表、个人数字助理（如亚马逊Alexa）、联网汽车、智能恒温器或其他设备的便利日子。
- en: This adoption is not going to slow down anytime soon as the industry forecasts
    that there will be over 25 billion IoT devices globally in the next few years.
    With the increased adoption of connected technologies, the new normal is to have
    *always-on* devices. In other words, the *devices should work all the time*. Not
    only that, but we also expect these devices to continuously get smarter and stay
    secure throughout their life cycles with new features, enhancements, or bug fixes.
    But how do you make that happen reliably and at scale? Werner Vogels, Amazon's
    chief technology officer and vice president, often says that "*Everything**fails
    all the time.*" It's challenging to keep any technological solution up and running
    all the time.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这种采用趋势不会很快放缓，因为行业预测，在未来几年内，全球将有超过250亿个物联网设备。随着连接技术的普及，新的常态是设备始终处于开启状态。换句话说，*设备应该始终工作*。不仅如此，我们还期望这些设备在其生命周期内持续变得更智能，并通过新功能、增强或错误修复保持安全。但如何可靠且大规模地实现这一点呢？亚马逊首席技术官和副总裁Werner
    Vogels经常说，“*一切都会时常出问题*。”保持任何技术解决方案始终运行是一个挑战。
- en: With **IoT**, these challenges are elevated and more complicated as the **edge**
    devices are deployed in diverse operating conditions, exposed to environmental
    interferences, and have multiple layers of connectivity, communication, and latency.
    Thus, it's critical to build an edge-to-cloud continuum mechanism to collect feedback
    from the deployed fleet of edge devices and act on them quickly. This is where
    DevOps for IoT helps. **DevOps** is short for **development and operations**.
    It facilitates an agile approach to performing **continuous integration and continuous
    deployment** (**CI/CD**) from the cloud to the edge.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在**物联网**领域，由于边缘设备部署在多样的操作条件下，易受环境干扰，并且具有多层连接性、通信和延迟，这些挑战变得更加严重和复杂。因此，构建边缘到云的连续机制，以收集已部署的边缘设备队伍的反馈并迅速采取行动，至关重要。这正是DevOps在物联网中发挥作用的地方。**DevOps**是**开发和运营**的缩写。它促进了一种敏捷的方法，从云到边缘执行**持续集成和持续部署**（**CI/CD**）。
- en: In this chapter, we will focus on how DevOps capabilities can be leveraged for
    IoT workloads. We will also expand our discussion to **MLOps** at the edge, which
    implies implementing agile practices for **machine learning** (**ML**) workloads.
    You learned about some of these concepts in the previous chapter when you built
    an ML pipeline. The focus of this chapter will be on deploying and operating those
    models efficiently.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点关注如何利用DevOps能力来处理物联网工作负载。我们还将扩展我们的讨论范围至边缘的**MLOps**，这意味着为**机器学习**（**ML**）工作负载实施敏捷实践。在您构建ML管道时，您已经在上一章中学习了这些概念的一些内容。本章的重点将是高效地部署和运行这些模型。
- en: You are already familiar with developing local processes on the edge or deploying
    components from the cloud in a decoupled way. In this chapter, we will explain
    how to stitch those pieces together using DevOps principles that will help automate
    the development, integration, and deployment workflow for a fleet of edge devices.
    This will allow you to efficiently operate an intelligent distributed architecture
    on the edge (that is, a Greengrass-enabled device) and help your organization
    achieve a faster time to market for rolling out different products and features.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经熟悉在边缘开发本地流程或以解耦方式从云中部署组件。在本章中，我们将解释如何使用DevOps原则将这些部分拼接在一起，这将有助于自动化一队边缘设备的开发、集成和部署工作流程。这将使您能够高效地运营边缘的智能分布式架构（即Greengrass启用的设备），并帮助您的组织更快地将不同产品和服务推向市场。
- en: 'In this chapter, we will be covering the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Defining DevOps for IoT workloads
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义物联网工作负载的DevOps
- en: Performing MLOps at the edge
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在边缘执行MLOps
- en: Hands-on with deploying containers at the edge
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在边缘部署容器的实践操作
- en: Checking your knowledge
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查您的知识
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The technical requirements for this chapter are the same as those outlined in
    [*Chapter 2*](B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032), *Foundations of
    Edge Workloads*. See the full requirements in that chapter.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的技术要求与在[*第二章*](B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032)中概述的要求相同，即*边缘工作负载基础*。完整的详细要求请参阅该章节。
- en: Now, let's dive into this chapter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入本章内容。
- en: Defining DevOps for IoT workloads
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义针对物联网工作负载的DevOps
- en: DevOps has transformed the way companies do business in today's world. Companies
    such as Amazon, Netflix, Google, and Facebook conduct hundreds or more deployments
    every week to push different features, enhancements, or bug fixes. The deployments
    themselves are typically transparent to the end customers in that they don't experience
    any downtime from these constant deployments.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps改变了当今世界公司开展业务的方式。例如，亚马逊、Netflix、谷歌和Facebook每周进行数百次或更多部署，以推送不同的功能、增强或错误修复。对于最终用户来说，这些部署通常是透明的，因为他们不会因为这些持续的部署而经历任何停机时间。
- en: 'DevOps is a methodology that brings *developers and operations* closer to infer
    quantifiable technical and business benefits with faster time to market through
    shorter development cycles and increased release frequency. A common misunderstanding
    is that DevOps is only a set of new technologies to build and deliver software
    faster. DevOps also represents a cultural shift to promote ownership, collaboration,
    and cohesiveness across different teams to foster innovation across the organization.
    DevOps has been adopted by organizations and companies of all sizes for distributed
    workloads to deliver innovation, enhancements, and operational efficiency faster.
    The following diagram shows the virtuous cycle of software delivery:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps是一种方法，它通过缩短开发周期和增加发布频率，使开发者和运维人员更接近，从而在更短的时间内实现可量化的技术和商业效益。一个常见的误解是，DevOps只是一套用于更快构建和交付软件的新技术。DevOps还代表了一种文化转变，旨在促进不同团队之间的所有权、协作和凝聚力，以促进组织内的创新。DevOps已被各种规模的组织和企业采用，以针对分布式工作负载更快地提供创新、增强和运营效率。以下图表显示了软件交付的良性循环：
- en: '![Figure 8.1 – The virtuous cycle of software delivery'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.1 – 软件交付的良性循环'
- en: '](img/B17595_08_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_01.jpg)'
- en: Figure 8.1 – The virtuous cycle of software delivery
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 软件交付的良性循环
- en: For the sake of brevity, we are not going to dive deeper into the concepts of
    DevOps or **Agile** practices here. Instead, we will focus on introducing the
    high-level concepts surrounding DevOps and discuss its relevance for IoT workloads.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁起见，我们在此不会深入探讨DevOps或**敏捷**实践的概念。相反，我们将专注于介绍围绕DevOps的高级概念，并讨论其对物联网工作负载的相关性。
- en: Fundamentals of DevOps
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DevOps基础
- en: 'DevOps brings together different tools and best practices, as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps将不同的工具和最佳实践结合在一起，如下所示：
- en: '**Shared code repository**: Using a version control system is a prerequisite
    and a best practice in the field of code development. All artifacts that are required
    in the deployment package need to be stored here. Examples include **Bitbucket**,
    **Gitlab**, and **AWS CodeCommit**.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**共享代码库**：在代码开发领域，使用版本控制系统是前提和最佳实践。部署包中所需的所有工件都需要存储在这里。例如，包括**Bitbucket**、**Gitlab**和**AWS
    CodeCommit**。'
- en: '**Continuous integration** (**CI**): In this step, developers commit their
    code changes regularly in the code repository. Every revision that is committed
    will trigger an automated build process that performs code scanning, code reviews,
    compilation, and automated unit testing. This allows developers to identify and
    fix bugs quickly, allowing them to adhere to the best practices and deliver features
    faster. The output of this process includes build artifacts (such as binaries
    or executable programs) that comply with the organization''s enforced practices.
    Examples of toolchains include **Jenkins**, **Bamboo**, **GitLab CI**, and **AWS
    CodePipeline**. For IoT workloads, similar toolchains can be used.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续集成**（**CI**）：在这一步中，开发者会定期在代码库中提交代码更改。每次提交都会触发一个自动构建过程，该过程执行代码扫描、代码审查、编译和自动单元测试。这允许开发者快速识别和修复错误，使他们能够遵守最佳实践并更快地交付功能。此过程的结果包括符合组织强制执行的实践的构建工件（如二进制文件或可执行程序）。工具链的例子包括**Jenkins**、**Bamboo**、**GitLab
    CI**和**AWS CodePipeline**。对于物联网工作负载，可以使用类似的工具链。'
- en: '**Continuous delivery** (**CD**): This step expands on the previous step of
    CI and deploys all the compiled binaries to the staging or test environment. Once
    deployed, automated tests related to integration, functional, or non-functional
    requirements are executed as part of the workflow. Examples of toolchains for
    testing include **JMeter**, **Selenium**, **Jenkins**, and **Cucumber**. This
    allows developers to thoroughly test changes and pre-emptively discover issues
    in the context of the overall application. The final step is deploying the validated
    code artifacts to the production environment (with or without manual approval).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续交付**（**CD**）：这一步在CI的先前步骤上进行了扩展，将所有编译的二进制文件部署到预发布或测试环境。一旦部署，与集成、功能或非功能性要求相关的自动化测试作为工作流程的一部分执行。测试工具链的例子包括**JMeter**、**Selenium**、**Jenkins**和**Cucumber**。这允许开发者彻底测试更改，并在整体应用程序的上下文中预先发现问题。最后一步是将验证过的代码工件部署到生产环境（无论是否有手动批准）。'
- en: '**Continuous monitoring** (**CM**): The core objective for DevOps is to remove
    silos between the development and operations teams. Thus, CM is a critical step
    if you wish to have a continuous feedback loop for observing, alerting, and mitigating
    issues related to infrastructure or hosted applications, as shown in the following
    diagram:'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续监控**（**CM**）：DevOps的核心目标是消除开发和运维团队之间的隔阂。因此，如果您希望有一个持续的反馈循环来观察、警报和缓解与基础设施或托管应用程序相关的问题，CM是一个关键步骤，如下面的图所示：'
- en: '![Figure 8.2 – DevOps life cycle'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.2 – DevOps生命周期'
- en: '](img/B17595_08_02.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_02.jpg)'
- en: Figure 8.2 – DevOps life cycle
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – DevOps生命周期
- en: Common toolchains for monitoring include **Amazon CloudWatch**, **Amazon X-Ray**,
    **Splunk**, and **New Relic**.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的监控工具链包括**Amazon CloudWatch**、**Amazon X-Ray**、**Splunk**和**New Relic**。
- en: '**Infrastructure as Code** (**IaC**): Adhering to the software development
    practices of CI/CD to expedite shipping code is a great first step, but it''s
    not enough. Teams can develop and test their code using agile processes, but the
    final delivery to production still follows waterfall methods. This is often due
    to a lack of control regarding provisioning or scaling the infrastructure dynamically.
    Traditionally, organizations will have system admins to provision the required
    infrastructure resources manually, which can take days, weeks, or months. This
    is where IaC helps as it allows you to provision and manage the infrastructure,
    configurations, and policies using code (or APIs) in an automated fashion without
    requiring any manual interventions that might be error-prone or time-consuming.
    Common toolchains include **Amazon CloudFormation**, **HashiCorp Terraform**,
    and **Ansible**.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施即代码**（**IaC**）：遵循CI/CD的软件开发实践以加快代码的发布是一个很好的第一步，但这还不够。团队可以使用敏捷流程开发和测试他们的代码，但最终交付到生产环境仍然遵循瀑布方法。这通常是由于缺乏对动态配置或扩展基础设施的控制。传统上，组织将会有系统管理员手动配置所需的基础设施资源，这可能需要几天、几周或几个月。这就是IaC发挥作用的地方，因为它允许您使用代码（或API）以自动化的方式配置和管理基础设施、配置和策略，而不需要任何可能存在错误或耗时的手动干预。常见的工具链包括**Amazon
    CloudFormation**、**HashiCorp Terraform**和**Ansible**。'
- en: Now that we have covered the the basics of DevOps, let's understand its relevance
    to IoT and the edge.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了DevOps的基础知识，让我们了解其与物联网和边缘的相关性。
- en: Relevance of DevOps for IoT and the edge
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DevOps对物联网和边缘的相关性
- en: 'The evolution of edge computing from simple radio frequency identification
    systems to the microcontrollers and microprocessors of today has opened up different
    use cases across industry segments that require building a distributed architecture
    on the edge. For example, the connected HBS hub has a diverse set of functionalities,
    such as the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从简单的射频识别系统到今天的微控制器和微处理器的边缘计算演变，为需要在边缘构建分布式架构的行业细分市场打开了不同的用例。例如，连接的HBS中心具有以下多样化的功能：
- en: A gateway for backend sensors/actuators
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后端传感器/执行器的网关
- en: Runtime for local components
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地组件的运行时间
- en: Interface to the cloud
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接到云的接口
- en: Message broker
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消息代理
- en: Datastream processor
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据流处理器
- en: ML inferencing engine
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习推理引擎
- en: Container orchestrator
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器编排器
- en: 'That''s a lot of work on the edge! Thus, the traditional ways of developing
    and delivering embedded software are not sustainable anymore. So, let''s discuss
    the core activities in the life cycle of an IoT device, as depicted in the following
    table, to understand the relevance of DevOps:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘的工作量很大！因此，传统的开发和交付嵌入式软件的方式已经不再可持续。那么，让我们讨论物联网设备生命周期中的核心活动，如图表所示，以了解 DevOps
    的相关性：
- en: '![Figure 8.3 – Relevance of DevOps in IoT workloads'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.3 – DevOps 在物联网工作负载中的相关性'
- en: '](img/B17595_08_Table1.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_Table1.jpg)'
- en: Figure 8.3 – Relevance of DevOps in IoT workloads
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – DevOps 在物联网工作负载中的相关性
- en: The key components of DevOps such as CI/CD/CM are equally relevant for IoT workloads.
    This set of activities is often referred to as **EdgeOps** and, as we observed
    earlier, they are applied differently between the edge and the cloud. For example,
    CI is different for the edge because we need to test device software on the same
    hardware that is deployed in the world. However, because of the higher costs and
    risks associated with edge deployments, it is common to reduce the frequency of
    updating devices at the edge. It is also common for organizations to have different
    sets of hardware for prototyping versus production runtimes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps 的关键组件，如 CI/CD/CM，对于物联网工作负载同样相关。这组活动通常被称为 **EdgeOps**，正如我们之前观察到的，它们在边缘和云之间应用方式不同。例如，由于我们需要在部署在世界的相同硬件上测试设备软件，因此边缘的
    CI 是不同的。然而，由于边缘部署相关的成本和风险较高，降低边缘设备更新的频率是常见的。组织通常拥有不同的硬件集，用于原型设计和生产运行时。
- en: DevOps challenges with IoT workloads
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DevOps 在物联网工作负载中的挑战
- en: 'Now that you understand how to map DevOps phases to different IoT activities,
    let''s expand on those a bit more. The following diagram shows the workflow that''s
    typically involved in the life cycle of a device, from its creation to being decommissioned:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了如何将 DevOps 阶段映射到不同的物联网活动，让我们更深入地探讨一下。以下图表展示了设备生命周期中通常涉及的工作流程，从其创建到退役：
- en: '![Figure 8.4 – DevOps workflow for IoT'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.4 – 物联网的 DevOps 工作流程'
- en: '](img/B17595_08_04.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_04.jpg)'
- en: Figure 8.4 – DevOps workflow for IoT
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 物联网的 DevOps 工作流程
- en: Here, you can see some key differences between an IoT workload and other cloud-hosted
    workloads. Let's take a look.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到物联网工作负载与其他云托管工作负载之间的关键差异。让我们看看。
- en: '*The manufacturing process is involved*:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*制造过程涉及*：'
- en: 'Distributed workloads such as web apps, databases, and APIs use the underlying
    infrastructure provided by the cloud platform. Software developers can use IaC
    practices and integrate them with other CI/CD mechanisms to provision the cloud
    resources that are automatically required to host their workload. For edge workloads,
    the product lives beyond the boundaries of any data center. Although it''s possible
    to run edge applications on virtual infrastructure provided by the cloud platform
    during the testing or prototyping phases, the real product is always hosted on
    hardware (such as a **Raspberry Pi** for this book''s project). There is always
    a dependency on the contract manufacturer (or other vendors) in the supply chain
    for manufacturing the hardware, as per the required specifications that are followed
    for programming it with the device firmware. Although the firmware can be developed
    on the cloud using DevOps practices, flashing the firmware image is done at manufacturing
    time only. This hinders the end-to-end automation common in traditional DevOps
    workflows, where the infrastructure (such as an AWS EC2 instance) is readily imaged
    and available for application deployments. The following diagram shows the typical
    life cycle of device manufacturing and distribution:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式工作负载，如 Web 应用程序、数据库和 API，使用云平台提供的底层基础设施。软件开发者可以使用 IaC 实践，并将它们与其他 CI/CD 机制集成，以提供自动所需的云资源来托管他们的工作负载。对于边缘工作负载，产品超越了任何数据中心边界。虽然在测试或原型阶段可以在云平台提供的虚拟基础设施上运行边缘应用程序，但实际产品始终托管在硬件上（例如，本书项目中的
    **Raspberry Pi**）。在供应链中，始终依赖于合同制造商（或其他供应商）根据编程设备固件所需的规格进行硬件制造。尽管可以使用 DevOps 实践在云上开发固件，但固件映像的烧录仅在制造时间进行。这阻碍了在传统
    DevOps 工作流程中常见的端到端自动化，其中基础设施（如 AWS EC2 实例）可以轻松镜像并可用于应用程序部署。以下图表展示了设备制造和分发的典型生命周期：
- en: '![Figure 8.5 – IoT device manufacturing process'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.5 – 物联网设备制造过程'
- en: '](img/B17595_08_05.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_05.jpg)'
- en: Figure 8.5 – IoT device manufacturing process
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – 物联网设备制造过程
- en: '*Securing the hardware is quintessential*:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*确保硬件安全至关重要*：'
- en: 'Some of the key vulnerabilities for edge workloads that are listed by **The
    Open Web Application Security Project** (**OWASP**) are as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**开放网络应用安全项目**（**OWASP**）列出的边缘工作负载的一些关键漏洞如下：'
- en: Weak, guessable, or hardcoded passwords
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弱、可猜测或硬编码的密码
- en: Lack of physical hardening
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏物理加固
- en: Insecure data transfer and storage
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不安全的数据传输和存储
- en: Insecure default settings
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不安全默认设置
- en: Insecure ecosystem interfaces
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不安全生态系统接口
- en: Although distributed workloads may have similar challenges, mitigating them
    using cloud-native controls makes them easier to automate than IoT workloads.
    Using AWS as an example, all communications within AWS infrastructure (such as
    across data centers) are encrypted in transit by default and require no action.
    Data at rest can be encrypted with a one-click option (or automation) using the
    key management infrastructure provided by AWS (or customers can bring their own).
    Every service (or hosted workloads) needs to enable access controls for authentication
    and authorization through cloud-native **Identity & Access Management** services,
    which can be automated as well through IaC implementation. Every service (or hosted
    workload) can take advantage of observability and traceability through cloud-native
    monitoring services (such as **Amazon CloudTrail** or **Amazon CloudWatch**).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管分布式工作负载可能面临相似的挑战，但使用云原生控制措施来缓解这些挑战，使得它们比物联网工作负载更容易自动化。以 AWS 为例，AWS 基础设施内部的所有通信（例如跨数据中心）默认都是加密传输的，无需采取任何行动。静态数据可以通过一键选项（或自动化）使用
    AWS 提供的密钥管理基础设施进行加密（或客户可以自行提供）。每个服务（或托管工作负载）都需要通过云原生**身份与访问管理**服务启用访问控制以进行身份验证和授权，这些也可以通过
    IaC 实施自动化。每个服务（或托管工作负载）都可以利用云原生监控服务（如**Amazon CloudTrail**或**Amazon CloudWatch**）提供的可观察性和可追溯性。
- en: On the contrary, for edge workloads, all of the preceding requirements are required
    to be fulfilled during manufacturing, assembling, and registering the device,
    thus putting more onus on the supply chain to manually implement these over one-click
    or automated workflows. For example, as a best practice, edge devices should perform
    mutual authentication over TLS1.2 with the cloud using credentials such as X.509
    certificates compared to using usernames and passwords or symmetric credentials.
    In addition, the credentials should have least-privileged access implemented using
    the right set of permissions (through policies). This can help ensure that the
    devices are implementing the required access controls to protect the device's
    identity and that the data in transit is fully encrypted. In addition, device
    credentials (such as X.509 certificates) on the edge must reside inside a secure
    element or **trusted platform module** (**TPM**) to reduce the risk of unauthorized
    access and identity compromise. Additionally, secure mechanisms are required to
    separate the filesystems on the device and encrypt the data at rest using different
    cryptographic utilities such as **dm-crypt**, **GPG**, and **Bitlocker**. Observability
    and traceability implementations for different edge components are left to the
    respective owners.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，对于边缘工作负载，所有上述要求都必须在制造、组装和注册设备时得到满足，从而给供应链带来更大的压力，手动执行这些操作，而不是一键或自动化工作流程。例如，作为最佳实践，边缘设备应使用
    X.509 证书等凭证通过 TLS1.2 与云进行相互认证，而不是使用用户名和密码或对称凭证。此外，凭证应通过正确的权限集（通过策略）实现最小权限访问，这有助于确保设备正在实施所需的访问控制以保护设备身份，并且传输中的数据得到完全加密。此外，边缘上的设备凭证（如
    X.509 证书）必须位于安全元素或**可信平台模块**（**TPM**）内部，以降低未经授权访问和身份泄露的风险。此外，还需要安全的机制来分离设备上的文件系统，并使用不同的加密工具（如**dm-crypt**、**GPG**和**Bitlocker**）加密静态数据。不同边缘组件的可观察性和可追溯性实现留给各自的拥有者。
- en: '*Lack of standardized frameworks for the edge*:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*缺乏边缘标准化的框架*：'
- en: 'Edge components are no longer limited to routers, switches, miniature servers,
    or workstations. Instead, the industry is moving toward building distributed architectures
    on the edge in different ways, as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘组件不再局限于路由器、交换机、微型服务器或工作站。相反，行业正在以不同的方式向边缘构建分布式架构，如下所示：
- en: '**Fog computing**, which lets us shift more intelligence to the edge using
    a decentralized computing infrastructure of heterogeneous nodes'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**雾计算**，它允许我们使用异构节点的分布式计算基础设施将更多智能转移到边缘'
- en: '**Mobile/Multi-Access Computing (MEC)**, which incorporates next-generation
    radio spectrums (such as 5G) to enable a new generation of workloads possible
    for the edge'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**移动/多接入计算（MEC**），通过整合下一代无线电频谱（如5G）来使边缘可能的新一代工作负载成为可能'
- en: '**Data center-in-a-box**, which enables resource-intensive computing capabilities
    at the edge with integrations to the cloud'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据中心即盒子**，通过云集成在边缘实现资源密集型计算能力'
- en: 'The following diagram shows an edge-to-cloud workflow that includes various
    technology capabilities that are common in distributed architectures:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示显示了包含分布式架构中常见各种技术能力的边缘到云工作流程：
- en: '![Figure 8.6 – Edge-to-cloud architecture'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.6 – 边缘到云架构'
- en: '](img/B17595_08_06.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_06.jpg)'
- en: Figure 8.6 – Edge-to-cloud architecture
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6 – 边缘到云架构
- en: The edge architecture's standards are still evolving. Considering there are
    different connectivity interfaces, communication protocols, and topologies, there
    are heterogeneous ways of solving different use cases. For example, connectivity
    interfaces may include different short-range (such as *BLE*, *Wi-Fi*, and *Ethernet*)
    or long-range radio networks (such as *cellular*, *NB-IoT*, and *LoRa*). The connectivity
    interface that's used needs to be determined during the hardware designing phase
    and is implemented as a one-time process. Communication protocols may include
    different transport layer protocols over TCP (connection-oriented such as *MQTT*
    and *HTTPS*) or UDP (connectionless such as *CoAP*). Recall the layers of the
    **Open System Interconnection** (**OSI**) model, which we reviewed in [*Chapter
    2*](B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032), *Foundations of Edge Workloads*.
    The choice of communication interfaces can be flexible, so long as the underlying
    Layer 4 protocols are supported on the hardware. For example, if the hardware
    supports UDP, it can be activated with configuration changes, along with installing
    additional Layer 7 software (such as a COAP client) as required. Thus, this step
    can be performed through a cloud-to-edge DevOps workflow (that is, an OTA update).
    Bringing more intelligence to the edge requires dealing with the challenges of
    running distributed topologies on a computing infrastructure with low horsepower.
    Thus, it's necessary to define standards and design principles to design, deploy,
    and operate optimized software workloads on the edge (such as brokers, microservices,
    containers, caches, and lightweight databases).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘架构的标准仍在不断发展。考虑到存在不同的连接接口、通信协议和拓扑结构，解决不同用例的方式也各不相同。例如，连接接口可能包括不同的短距离（如*BLE*、*Wi-Fi*和*Ethernet*）或长距离无线网络（如*蜂窝*、*NB-IoT*和*LoRa*）。所使用的连接接口需要在硬件设计阶段确定，并作为一个一次性过程实现。通信协议可能包括TCP（面向连接，如*MQTT*和*HTTPS*）或UDP（无连接，如*CoAP*）。回想一下我们在[*第2章*](B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032)“边缘工作负载的基础”中回顾的**开放系统互联**（**OSI**）模型的层级，通信接口的选择可以灵活，只要底层第4层协议在硬件上得到支持。例如，如果硬件支持UDP，可以通过配置更改激活它，并根据需要安装额外的第7层软件（如COAP客户端）。因此，这一步可以通过云到边缘的DevOps工作流程（即OTA更新）来完成。将更多智能带到边缘需要处理在低功耗计算基础设施上运行分布式拓扑结构所带来的挑战。因此，有必要定义标准和设计原则，以设计、部署和运营边缘优化的软件工作负载（如代理、微服务、容器、缓存和轻量级数据库）。
- en: Hopefully, this has helped you understand the unique challenges for edge workloads
    from a DevOps perspective. In the next section, you will understand how AWS IoT
    Greengrass can help you build and operate distributed workloads on the edge.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这能帮助你从DevOps的角度理解边缘工作负载的独特挑战。在下一节中，你将了解AWS IoT Greengrass如何帮助你构建和运营边缘的分布式工作负载。
- en: Understanding the DevOps toolchain for the edge
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解边缘的DevOps工具链
- en: 'In the previous chapters, you learned how to develop and deploy native processes,
    data streams, and ML models on the edge locally and then deployed them at scale
    using **Greengrass''s** built-in OTA mechanism. We will explain the reverse approach
    here; that is, building distributed applications on the cloud using DevOps practices
    and deploying them to the edge. The following diagram shows the approach to continuously
    build, test, integrate, and deploy workloads using the **OTA** update mechanism:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，你学习了如何在边缘本地开发和部署原生进程、数据流和机器学习模型，然后使用**Greengrass的**内置OTA机制进行大规模部署。在这里，我们将解释相反的方法；即在云中使用DevOps实践构建分布式应用程序，并将它们部署到边缘。以下图表显示了使用**OTA**更新机制持续构建、测试、集成和部署工作负载的方法：
- en: '![Figure 8.7 – A CI/CD view for Edge applications](img/B17595_08_07.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图8.7 – 边缘应用的CI/CD视图](img/B17595_08_07.jpg)'
- en: Figure 8.7 – A CI/CD view for Edge applications
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 – 边缘应用的CI/CD视图
- en: The two most common ways to build a distributed architecture on the edge using
    AWS IoT Greengrass is by using AWS Lambda services or Docker containers.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS IoT Greengrass上构建边缘分布式架构的两种最常见方式是通过使用AWS Lambda服务或Docker容器。
- en: AWS Lambda at the edge
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS IoT Greengrass上的AWS Lambda
- en: I want to make it clear, to avoid any confusion, that the concept of Lambda
    design, which was introduced in [*Chapter 5*](B17595_05_Final_SS_ePub.xhtml#_idTextAnchor090),
    *Ingesting and Streaming Data from the Edge*, is an architectural pattern that's
    used to operate streaming and batch workflows on the edge. **AWS Lambda**, on
    the contrary, is a serverless compute service that offers a runtime for executing
    any type of application with no administration. It allows developers to focus
    on the business logic, write code in different programming languages (such as
    *C*, *C++*, *Java*, *Node.js*, and *Go*), and upload it as a ZIP file. The service
    takes it from there in provisioning the underlying infrastructure's resources
    and scales based on incoming requests or events.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我要明确指出，为了避免任何混淆，[*第5章*](B17595_05_Final_SS_ePub.xhtml#_idTextAnchor090)中引入的Lambda设计概念，*从边缘摄取和流式传输数据*，是一种用于在边缘操作流式和批处理工作流程的架构模式。**AWS
    Lambda**则相反，是一种无服务器计算服务，提供执行任何类型应用程序的运行时，无需管理。它允许开发者专注于业务逻辑，用不同的编程语言（如*C*、*C++*、*Java*、*Node.js*和*Go*）编写代码，并将其作为ZIP文件上传。服务从那里开始配置底层基础设施的资源，并根据传入的请求或事件进行扩展。
- en: AWS Lambda has been a popular compute choice in designing event-based architectures
    for real-time processing, batch, and API-driven workloads. Due to this, AWS has
    decided to extend the Lambda runtime support for edge processing through **Amazon
    IoT Greengrass**.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda在设计基于事件的架构以进行实时处理、批处理和API驱动的工作负载时，一直是一种流行的计算选择。因此，AWS决定通过**Amazon
    IoT Greengrass**扩展Lambda运行时对边缘处理的支持。
- en: So, are you wondering what the value of implementing AWS Lambda at the edge
    is?
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你在想AWS Lambda在边缘实施的价值是什么吗？
- en: You are not alone! Considering automated hardware provisioning is not an option
    for the edge, as explained earlier in this chapter, the value here is around interoperability,
    consistency, and continuity from the cloud to the edge. It's very common for IoT
    workloads to have different code bases for the cloud (**distributed stack**) and
    the edge (**embedded stack**), which leads to additional complexity around code
    integration, testing, and deployment. This results in additional operational overhead
    and a delayed time to market.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你并不孤单！考虑到在边缘进行自动硬件配置不是一种选择，正如本章前面所解释的，这里的价值在于从云到边缘的互操作性、一致性和连续性。对于物联网工作负载来说，云（**分布式栈**）和边缘（**嵌入式栈**）有不同的代码库是很常见的，这导致了代码集成、测试和部署方面的额外复杂性。这导致了额外的运营开销和市场延迟时间。
- en: AWS Lambda aimed to bridge this gap so that the cloud and embedded developers
    can use similar technology stacks for software development and have interoperable
    solutions. Therefore, building a DevOps pipeline from the cloud to the edge using
    a common toolchain becomes feasible.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda旨在弥合这一差距，以便云和嵌入式开发者可以使用类似的技术栈进行软件开发，并拥有互操作性解决方案。因此，使用通用工具链从云到边缘构建DevOps管道变得可行。
- en: Benefits of AWS Lambda on AWS IoT Greengrass
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AWS IoT Greengrass上AWS Lambda的优势
- en: 'There are several benefits of running Lambda functions on the edge, as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在边缘运行Lambda函数有几个好处，如下所述：
- en: Lambda functions that are deployed locally on the edge devices can *connect
    to different physical interfaces* such as CANBus, Modbus, or Ethernet to access
    different serial ports or GPIO on the hardware similar to embedded applications.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署在边缘设备本地的 Lambda 函数可以连接到不同的物理接口，如 CANBus、Modbus 或以太网，以访问硬件上的不同串行端口或 GPIO，类似于嵌入式应用程序。
- en: Lambda functions can *act as the glue between different edge components* (such
    as Stream Manager) within AWS IoT Greengrass and the cloud resources.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda 函数可以在 AWS IoT Greengrass 和云资源之间充当不同边缘组件（如流管理器）之间的粘合剂。
- en: AWS IoT Greengrass also *makes it easier to deploy different versions of Lambda
    functions* by using an alias or a specific version for the edge. This helps in
    continuous delivery and is useful for scenarios such as blue/green deployments.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS IoT Greengrass 通过使用别名或特定版本为边缘提供 Lambda 函数，使部署不同版本的 Lambda 函数变得更加容易。这有助于持续交付，并在蓝/绿部署等场景中很有用。
- en: '*Granular access control*, including specifying configurations (run as root)
    or permissions (read/write) for different local resources (such as disk volumes,
    serial ports, or GPIOs), can be managed for Lambda functions.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*细粒度访问控制*，包括为不同的本地资源（如磁盘卷、串行端口或 GPIO）指定配置（以 root 运行）或权限（读取/写入），可以用于管理 Lambda
    函数。'
- en: Lambda functions can be run in both **containerized** and **non-containerized**
    modes. Non-containerized mode removes the abstraction layer and allows Lambda
    to run as a regular process on the OS. This is useful for latency-sensitive applications
    such as ML inferencing.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda 函数可以在**容器化**和**非容器化**模式下运行。非容器化模式移除了抽象层，允许 Lambda 作为常规进程在操作系统上运行。这对于对延迟敏感的应用程序（如机器学习推理）很有用。
- en: Finally, AWS IoT Greengrass *allows you to manage the hardware resources* (RAM)
    that can be used by the Lambda function on the edge.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，AWS IoT Greengrass 允许你管理边缘上 Lambda 函数可以使用的硬件资源（RAM）。
- en: 'The following diagram shows how an AWS Lambda function that''s been deployed
    on the edge can interact with different components on the physical (such as the
    filesystem) or abstracted layer (such as stream manager on AWS IoT Greengrass):'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了已部署在边缘的 AWS Lambda 函数如何与物理层（如文件系统）或抽象层（如 AWS IoT Greengrass 上的流管理器）的不同组件进行交互：
- en: '![Figure 8.8 – Lambda interactions on the edge'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 8.8 – Lambda interactions on the edge]'
- en: '](img/B17595_08_08.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_08_08.jpg]'
- en: Figure 8.8 – Lambda interactions on the edge
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 – Lambda 在边缘的交互
- en: Here, you can see that Lambda provides some distinct value propositions out
    of the box that you have to build yourself with native processes.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到 Lambda 提供了一些独特的价值主张，这些价值主张你需要通过本地进程自行构建。
- en: Challenges with Lambda on the edge
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Lambda 在边缘的挑战
- en: 'As you have understood by now, every solution or architecture has a trade-off.
    AWS Lambda is not an exception either and can have the following challenges:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如你现在所理解的，每个解决方案或架构都有其权衡之处。AWS Lambda 也不例外，可能面临以下挑战：
- en: '*Lambda functions can be resource-intensive* compared to native processes.
    This is because they require additional libraries.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*与本地进程相比，Lambda 函数可能更占用资源*。这是因为它们需要额外的库。'
- en: '*Lambda functions are AWS only*. Thus, if you are looking to develop a cloud-agnostic     edge solution (to mitigate vendor lock-in concerns), you may need to stick to
    native processes or Docker containers. Although Greengrass v2, as an edge software,
    is open source, AWS Lambda functions are not.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Lambda 函数仅适用于 AWS*。因此，如果你正在寻找一个云无关的边缘解决方案（以减轻供应商锁定问题），你可能需要坚持使用本地进程或 Docker
    容器。尽管 Greengrass v2 作为边缘软件是开源的，但 AWS Lambda 函数不是。'
- en: Now, let's understand containers for the edge.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们了解边缘的容器。
- en: Containers for the edge
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 边缘容器
- en: A **container** is a unit of software that packages the necessary code with
    the required dependencies for the application to run reliably across different
    computing environments. Essentially, a container provides an abstraction layer
    to its hosted applications from the underlying *OS* (such as Ubuntu, Linux, or
    Windows) or *architecture* (such as x86 or ARM). In addition, since containers
    are lightweight, a single server or a virtual machine can run multiple containers.
    For example, you can run a *3-tier architecture* (web, app, and a database) on
    the same server (or VM) using their respective container images. The two most
    popular open source frameworks for container management are **Docker** and **Kubernetes**.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**容器**是一个软件单元，它将应用程序运行所需的所有代码及其依赖项打包在一起，以便在不同的计算环境中可靠地运行。本质上，容器为其托管应用程序提供了一个抽象层，从底层的
    *OS*（例如 Ubuntu、Linux 或 Windows）或 *架构*（例如 x86 或 ARM）中分离出来。此外，由于容器轻量级，单个服务器或虚拟机可以运行多个容器。例如，您可以使用各自的容器镜像在同一服务器（或
    VM）上运行一个 *3 层架构*（Web、应用和数据库）。最流行的两个开源容器管理框架是 **Docker** 和 **Kubernetes**。'
- en: 'In this section, we will primarily discuss Docker as it''s the only option
    that''s supported natively by AWS IoT Greengrass at the time of writing. Similar
    to Lambda, Docker supports an exhaustive set of programming languages and toolchains
    for the developers to develop, operate, and deploy their applications in an agile
    fashion. The following diagram shows the reference architecture for a Docker-based
    workload deployed on AWS IoT Greengrass:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将主要讨论 Docker，因为它是 AWS IoT Greengrass 在编写时唯一原生支持的选项。与 Lambda 类似，Docker
    支持一系列编程语言和工具链，以便开发者以敏捷的方式开发、操作和部署他们的应用程序。以下图示展示了基于 Docker 的工作负载在 AWS IoT Greengrass
    上的参考架构：
- en: '![Figure 8.9 – Docker abstraction layers'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.9 – Docker 抽象层'
- en: '](img/B17595_08_09.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_09.jpg)'
- en: Figure 8.9 – Docker abstraction layers
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9 – Docker 抽象层
- en: So, why run containers over Lambda on the edge?
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么在边缘使用 Lambda 运行容器呢？
- en: Containers can bring all of the benefits that Lambda does (and more), along
    with being heterogeneous (different platforms), open source, and better optimized
    for edge resources. Containers have a broader developer community as well. Since
    containers have an orchestration and abstraction layer, it's not dependent on
    other runtimes such as AWS IoT Greengrass. So, if your organization decides to
    move away to another edge solution, containers are more portable than Lambda functions.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 容器可以带来 Lambda 所有的好处（以及更多），同时具有异构性（不同的平台）、开源和针对边缘资源进行了更好的优化。容器还有一个更广泛的开发者社区。由于容器具有编排和抽象层，它不依赖于其他运行时，如
    AWS IoT Greengrass。因此，如果您的组织决定迁移到另一个边缘解决方案，容器比 Lambda 函数更易于移植。
- en: Benefits of Docker containers on AWS IoT Greengrass
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWS IoT Greengrass 上 Docker 容器的优势
- en: 'Running containers at the edge using Greengrass has the following benefits:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Greengrass 在边缘运行容器有以下优势：
- en: Developers can continue to use their existing CI/CD pipelines and store artifacts
    (that is, **Docker images**) in different code repositories such as **Amazon Elastic
    Container Registry** (**ECR**), the public Docker Hub, the public Docker Trusted
    Registry, or an S3 bucket.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发者可以继续使用他们现有的 CI/CD 管道，并将工件（即 **Docker 镜像**）存储在不同的代码仓库中，例如 **Amazon Elastic
    Container Registry** （**ECR**），公共 Docker Hub，公共 Docker Trusted Registry 或 S3 桶。
- en: Greengrass simplifies deploying to the edge, with the only dependency being
    having the `aws.greengrass.DockerApplicationManager`) that enables Greengrass
    to manage credentials and download images from the supported repositories.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Greengrass 简化了向边缘部署的过程，唯一的依赖是拥有 `aws.greengrass.DockerApplicationManager`，它使
    Greengrass 能够管理凭证并从支持的仓库下载镜像。
- en: Greengrass offers first-class support for Docker utilities such as `docker-compose`,
    `docker run`, and `docker load`, all of which can be included as dependencies
    in the recipe file for the component or can be used separately for testing or
    monitoring purposes.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Greengrass 为 Docker 工具提供了第一级支持，例如 `docker-compose`、`docker run` 和 `docker load`，所有这些都可以作为组件配方文件中的依赖项包含，也可以单独用于测试或监控目的。
- en: Finally, Greengrass also supports inter-process communication between Docker-based
    applications and other components.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，Greengrass 还支持基于 Docker 的应用程序和其他组件之间的进程间通信。
- en: 'The following diagram shows how containerized applications can be developed
    using a CI/CD approach and be deployed on the edge while running AWS IoT Greengrass:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了如何使用 CI/CD 方法开发容器化应用程序，并在运行 AWS IoT Greengrass 的同时部署到边缘：
- en: '![Figure 8.10 – CI/CD approach for Docker workloads'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.10 – Docker工作负载的CI/CD方法'
- en: '](img/B17595_08_10.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_10.jpg)'
- en: Figure 8.10 – CI/CD approach for Docker workloads
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.10 – Docker工作负载的CI/CD方法
- en: Next, let's learn about the challenges with Docker on the edge.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们了解边缘Docker的挑战。
- en: Challenges with Docker on the edge
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 边缘Docker的挑战
- en: 'Running containers on the edge has some tradeoffs that need to be considered,
    as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在边缘运行容器有一些权衡需要考虑，如下所示：
- en: Managing containers at scale on the edge brings more operational overhead as
    it can become complex. Thus, it requires careful designing, planning, and monitoring.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在边缘大规模管理容器会带来更多的运营开销，因为它可能会变得复杂。因此，它需要仔细的设计、规划和监控。
- en: As you build sophisticated edge applications with private and public Docker
    images, you are increasing the surface area for attacks as well. Thus, adhering
    to various operational and security best practices at all times is quintessential.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您使用私有和公共Docker镜像构建复杂的边缘应用程序时，您也在增加攻击面。因此，始终遵守各种运营和安全最佳实践至关重要。
- en: In addition to AWS IoT Greengrass-specific updates, you need to have a patching
    and maintenance routine for Docker-specific utilities as well, which, in turn,
    increases the operational overhead and network charges.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了AWS IoT Greengrass特定的更新外，您还需要为Docker特定的实用程序制定补丁和维护程序，这反过来又增加了运营开销和网络费用。
- en: An additional layer of abstraction with containers may not be a fit for latency-sensitive
    use cases. For example, performing ML inferencing on GPUs for time-sensitive actions
    such as detecting an intrusion in your home through computer vision may run better
    as a native process over a container.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于对延迟敏感的使用案例，可能不适合使用容器增加抽象层。例如，在GPU上执行时间敏感的机器学习推理，如通过计算机视觉检测家庭入侵，可能作为容器上的原生进程运行得更好。
- en: In the lab section of this chapter, you will get your hands dirty by deploying
    a Docker-based application to the edge using AWS IoT Greengrass.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的实验室部分，您将通过使用AWS IoT Greengrass将基于Docker的应用程序部署到边缘来亲自动手。
- en: Additional toolsets for Greengrass deployments
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Greengrass部署的附加工具集
- en: Similar to other AWS services, AWS IoT Greengrass also supports integration
    with various IaC solutions such as **CloudFormation**, **CDK**, and **Terraform**.
    All these tools can help you create cloud-based resources and integrate with different
    CI/CD pipelines for supporting cloud-to-edge deployments.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他AWS服务类似，AWS IoT Greengrass也支持与各种IaC解决方案集成，例如**CloudFormation**、**CDK**和**Terraform**。所有这些工具都可以帮助您创建基于云的资源，并集成到不同的CI/CD管道中，以支持云到边缘的部署。
- en: Now that you are familiar with the benefits and tradeoffs of the DevOps toolchain,
    let's learn how that extends to machine learning.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经熟悉了DevOps工具链的益处和权衡，让我们学习它是如何扩展到机器学习的。
- en: MLOps at the edge
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘MLOps
- en: '**Machine Learning Operations** (**MLOps**) aims to integrate agile methodologies
    into the end-to-end process of running machine learning workloads. MLOps brings
    together best practices from data science, data engineering, and DevOps to streamline
    model design, development, and delivery across the **machine learning development
    life cycle** (**MLDLC**).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习运营**（**MLOps**）旨在将敏捷方法集成到运行机器学习工作负载的端到端流程中。MLOps将数据科学、数据工程和DevOps的最佳实践结合在一起，以简化模型设计、开发和交付，贯穿**机器学习开发生命周期**（**MLDLC**）。'
- en: As per MLOps **special interest group** (**SIG**), MLOps is defined as "*The
    extension of the DevOps methodology to include machine learning and data science
    assets as first-class citizens within the DevOps ecology.*" MLOps has gained rapid
    momentum in the last few years from ML practitioners and is a language-, framework-,
    platform-, and infrastructure-agnostic practice.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 根据MLOps**特别兴趣小组**（**SIG**）的定义，MLOps被定义为“*将DevOps方法扩展到包括机器学习和数据科学资产作为DevOps生态系统中的一等公民。*”MLOps在过去几年中从机器学习从业者那里获得了快速发展，并且是一种语言、框架、平台和基础设施无关的实践。
- en: 'The following diagram shows the virtuous cycle of the MLDLC:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了MLDLC的良性循环：
- en: '![Figure 8.11 – MLOps workflow'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.11 – MLOps工作流程'
- en: '](img/B17595_08_11.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_11.jpg)'
- en: Figure 8.11 – MLOps workflow
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11 – MLOps工作流程
- en: The preceding diagram shows how **Operations** is a fundamental block of the
    ML workflow. We introduced some of the concepts of ML design and development in
    [*Chapter 7*](B17595_07_Final_SS_ePub.xhtml#_idTextAnchor138), *Machine Learning
    Workloads at the Edge*, so in this section, we will primarily focus on the **Operations**
    layer.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 上一张图显示了**操作**是ML工作流程的基本模块。我们在[*第7章*](B17595_07_Final_SS_ePub.xhtml#_idTextAnchor138)，*边缘的机器学习工作负载*中介绍了一些ML设计和开发的概念，因此在本节中，我们将主要关注**操作**层。
- en: 'There are several benefits of MLOps, as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps有以下几个好处：
- en: '**Productive**: Data, ML engineers, and data scientists can use self-service
    environments to iterate faster with curated datasets and integrated ML tools.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效性**：数据、ML工程师和数据科学家可以使用自助环境，通过精选数据集和集成ML工具更快地迭代。'
- en: '**Repeatable**: Similar to DevOps, bringing automation to all aspects of the
    ML development life cycle (that is, MLDC) reduces human error and improves efficiency.
    MLOps helps ensure a repeatable process to help version, build, train, deploy,
    and operate ML models.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可重复性**：类似于DevOps，将自动化引入ML开发生命周期的各个方面（即MLDC）可以减少人为错误并提高效率。MLOps有助于确保可重复的过程，以帮助版本控制、构建、训练、部署和操作ML模型。'
- en: '**Reliable**: Incorporating CI/CD practices into the MLDC adds to the quality
    and consistency of the deployments.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可靠性**：将CI/CD实践纳入MLDC增加了部署的质量和一致性。'
- en: '**Auditable**: Enabling capabilities such as versioning of all inputs and outputs,
    ranging from source data to trained models, allows for end-to-end traceability
    and observability of the ML workload.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可审计性**：启用所有输入和输出的版本控制功能，从源数据到训练好的模型，允许对ML工作负载进行端到端的可追溯性和可观察性。'
- en: '**Governance**: Implementing governance practices to enforce policies helps
    to guard against model bias and track changes to data lineage and model quality
    over time.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**治理**：实施治理实践以强制执行政策有助于防止模型偏差并跟踪数据血缘和模型质量随时间的变化。'
- en: So, now that you understand what MLOps is, are you curious to know how it's
    related to IoT and the edge? Let's take a look.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经了解了MLOps是什么，您是否好奇它如何与物联网和边缘计算相关？让我们来看看。
- en: Relevance of MLOps for IoT and the edge
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps在物联网和边缘计算中的相关性
- en: As an IoT/edge SME, you will *NOT* be owning the MLOps process. Rather, you
    need to ensure that the dependencies are met on the edge (at the hardware and
    software layer) for the ML engineers to perform their due diligence in setting
    up and maintaining this workflow. Thus, don't be surprised by the brevity of this
    section, as our goal is to only introduce you to the fundamental concepts and
    the associated services available today on AWS for this subject area. We hope
    to give you a quick ramp-up so that you are adept at having better conversations
    with ML practitioners in your organization.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 作为物联网/边缘领域的专家，您将*不会*拥有MLOps流程。相反，您需要确保边缘（在硬件和软件层）满足依赖关系，以便ML工程师能够履行其设置和维护此工作流程的职责。因此，不要对这一章节的简短感到惊讶，因为我们的目标只是向您介绍基本概念和今天在AWS上为此主题领域提供的关联服务。我们希望让您快速入门，以便您能够与组织中的ML实践者进行更好的对话。
- en: So, with that background, let's consider the scenario where the sensors from
    the connected HBS hub are reporting various anomalies from different customer
    installations. This is leading to multiple technician calls and thereby impacting
    the customer experience and bottom line. Thus, your CTO has decided to build a
    *predictive maintenance solution* using ML models to rapidly identify and fix
    faults through remote operations. The models should be able to identify data drift
    dynamically and collect additional information around the reported anomalies.
    Thus, the goal for ML practitioners here is to build an MLOps workflow so that
    models can be frequently and automatically trained on the collected data, followed
    by deploying it to the connected HBS hub.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有了这个背景，让我们考虑这样一个场景：连接的HBS中心传感器正在报告来自不同客户安装的各种异常。这导致了多次技术员呼叫，从而影响了客户体验和底线。因此，您的首席技术官决定使用ML模型构建一个*预测性维护解决方案*，通过远程操作快速识别和修复故障。这些模型应能够动态地识别数据漂移并收集有关报告异常的附加信息。因此，这里ML实践者的目标是构建一个MLOps工作流程，以便模型可以频繁且自动地在收集到的数据上训练，然后部署到连接的HBS中心。
- en: 'In addition, it''s essential to monitor the performance of the ML models that
    are deployed on the edge to understand their efficiency; for example, to see how
    many false positives are being generated. Similar to the DevOps workflow, the
    ML workflow includes different components such as source control for versioning,
    a training pipeline for CI/CD, testing for model validation, packaging for deployment,
    and monitoring for assessing efficiency. If this project is a success, it will
    help the company add more ML intelligence to the edge and mitigate issues predictively
    to improve customer experience and reduce costs. The following reference architecture
    depicts a workflow we can use to implement the predictive maintenance of ML models
    on AWS IoT Greengrass v2:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，监控部署在边缘的机器学习模型的表现对于理解其效率至关重要；例如，查看产生了多少假阳性。类似于DevOps工作流程，机器学习工作流程包括不同的组件，如版本控制的源代码管理、用于CI/CD的训练管道、用于模型验证的测试、用于部署的打包以及用于评估效率的监控。如果这个项目成功，它将帮助公司向边缘添加更多机器学习智能，并预测性地减轻问题以改善客户体验并降低成本。以下参考架构展示了一个我们可以用于在AWS
    IoT Greengrass v2上实现机器学习模型预测性维护的工作流程：
- en: '![Figure 8.12 – Predictive maintenance of HBS sensors'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.12 – HBS传感器的预测性维护'
- en: '](img/B17595_08_12.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17595_08_12.jpg](img/B17595_08_12.jpg)'
- en: Figure 8.12 – Predictive maintenance of HBS sensors
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.12 – HBS传感器的预测性维护
- en: If we want to implement the preceding architecture, we must try to foresee some
    common challenges.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要实现前面的架构，我们必须尝试预见一些常见的挑战。
- en: MLOps challenges for the edge
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 边缘的MLOps挑战
- en: 'Quite often, the most common questions that are asked by edge and ML practitioners
    related to MLOps are as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 很常见，边缘和机器学习从业者关于MLOps最常问的问题如下：
- en: How do I prepare and deploy ML models to edge devices at scale?
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我该如何大规模准备和部署机器学习模型到边缘设备？
- en: How do I secure the models (being intellectual property) once they've been deployed
    at the edge?
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦模型在边缘部署，我该如何确保模型（作为知识产权）的安全？
- en: How do I monitor the ML models operating at the edge and retrain them when needed?
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我该如何监控边缘运行的机器学习模型，并在需要时重新训练它们？
- en: How do I eliminate the need for installing resource-intensive runtimes such
    as TensorFlow and PyTorch?
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我该如何消除安装资源密集型运行时（如TensorFlow和PyTorch）的需求？
- en: How do I interface one or more models with my edge applications using a standard
    interface?
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我该如何使用标准接口将一个或多个模型与我的边缘应用程序接口？
- en: How do I automate all these tasks so that there is a repeatable, efficient mechanism
    in place?
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我该如何自动化所有这些任务，以便有一个可重复、高效的机制？
- en: 'This is not an exhaustive list as it continues to expand with ML being adopted
    more and more on the edge. The answers to some of those questions are a mix of
    cultural and technical shifts within an organization. Let''s look at some examples:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一个详尽的列表，因为它随着机器学习在边缘的采用而不断扩展。对一些问题的答案是一个组织内部文化和技术转变的混合。让我们看看一些例子：
- en: '**Communication is key**: For MLOps to generate the desired outcomes, communication
    and collaboration across different stakeholders are key. Considering ML projects
    involve a different dimension of technology related to algorithms and mathematical
    models, the ML practitioners often speak a different technical language than traditional
    IT (or IoT) folks.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**沟通是关键**：为了使MLOps产生预期的结果，跨不同利益相关者的沟通和协作是关键。考虑到机器学习项目涉及与算法和数学模型相关的技术不同维度，机器学习从业者通常说的技术语言与传统的IT（或物联网）人员不同。'
- en: Thus, becoming an ML organization requires time, training, and co-development
    exercises to be completed across different teams to produce fruitful results.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，成为一个机器学习组织需要时间、培训和跨不同团队的合作练习，以产生有成效的结果。
- en: '**Decoupling and recoupling**: Machine learning models have life cycles that
    are generally independent of other distributed systems. This decoupling allows
    ML practitioners to focus on building their applications without being distracted
    by the rest.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解耦和重新耦合**：机器学习模型的生命周期通常独立于其他分布式系统。这种解耦使得机器学习从业者可以专注于构建他们的应用程序，而不会被其他事情分散注意力。'
- en: At the same time, though, ML workflows have certain dependencies, such as on
    big data workflows or applications required for inferencing. This means that MLOps
    is a combination of a traditional CI/CD workflow and another workflow engine.
    This can often become tricky without a robust pipeline and the required toolsets.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 同时，尽管如此，机器学习工作流程有一定的依赖性，例如对大数据工作流程或推理所需的应用的依赖。这意味着MLOps是传统CI/CD工作流程和另一个工作流程引擎的组合。如果没有健壮的管道和所需的工具集，这往往变得很棘手。
- en: '**Deployment can be tricky**: According to Algorithmia''s report, *2020 State
    of Enterprise Machine Learning*, "*Bridging the gap between ML model building
    and practical deployments is a challenging task*." There is a fundamental difference
    between building an ML model in a Jupyter notebook on a laptop or a cloud environment
    versus deploying that model into a production system that generates value.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署可能很棘手**：根据Algorithmia的报告，《2020年企业机器学习现状》，"*弥合机器学习模型构建与实际部署之间的差距是一项具有挑战性的任务*"。在笔记本电脑或云环境中在Jupyter笔记本上构建ML模型与将该模型部署到生成价值的生产系统之间存在根本性的区别。'
- en: With IoT, this problem acts as the force multiplier, as it's required to consider
    various optimization strategies for different hardware and runtimes before deploying
    the ML models. For example, in [*Chapter 7*](B17595_07_Final_SS_ePub.xhtml#_idTextAnchor138),
    *Machine Learning Workloads at the Edge*, you learned how to optimize ML models
    using **Amazon SageMaker Neo** so that they can run efficiently in your working
    environment.
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在物联网中，这个问题充当了乘数效应，因为部署ML模型之前，需要考虑针对不同硬件和运行时的各种优化策略。例如，在[*第7章*](B17595_07_Final_SS_ePub.xhtml#_idTextAnchor138)，“边缘机器学习工作负载”，你学习了如何使用**Amazon
    SageMaker Neo**优化ML模型，以便在您的环境中高效运行。
- en: '**The environment matters**: The ML models may need to run in offline conditions
    and thus are more susceptible to data drift due to the high rate of data from
    changing environments. For example, think of a scenario where your home has a
    power or water outage due to a natural disaster. Thus, your devices, such as the
    HVAC or water pumps, act in an anomalous way, leading to data drift for the locally
    deployed models. Thus, your locally deployed ML models need to be intelligent
    enough to handle different false positives in unexpected scenarios.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**环境很重要**：ML模型可能需要在离线条件下运行，因此更容易受到不断变化的环境中的数据漂移的影响。例如，想象一下由于自然灾害导致你的家庭停电或断水的情况。因此，你的设备，如HVAC或水泵，会以异常的方式运行，导致本地部署的模型数据漂移。因此，你的本地部署的ML模型需要足够智能，能够处理意外场景中的不同误报。'
- en: We have gone through the MLOps challenges for the edge in this section. In the
    next section, we will understand the MLOps toolchain for the edge.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了边缘的MLOps挑战。在下一节中，我们将了解边缘的MLOps工具链。
- en: Understanding the MLOps toolchain for the edge
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解边缘的MLOps工具链
- en: 'In [*Chapter 7*](B17595_07_Final_SS_ePub.xhtml#_idTextAnchor138), *Machine
    Learning Workloads at the Edge*, you learned how to develop ML models using Amazon
    SageMaker, optimize them through SageMaker Neo, and deploy them on the edge using
    AWS IoT Greengrass v2\. In this chapter, I would like to introduce you to another
    service in the SageMaker family called **Edge Manager**, which can help address
    some of the preceding MLOps challenges and which provides the following capabilities
    out of the box:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第7章*](B17595_07_Final_SS_ePub.xhtml#_idTextAnchor138)，“边缘机器学习工作负载”中，你学习了如何使用Amazon
    SageMaker开发ML模型，通过SageMaker Neo进行优化，并使用AWS IoT Greengrass v2在边缘部署它们。在本章中，我想向你介绍SageMaker家族中的另一个服务，称为**Edge
    Manager**，它可以帮助解决一些先前的MLOps挑战，并提供以下即插即用的功能：
- en: The ability to automate the build-train-deploy workflow from cloud to edge devices
    and trace the life cycle of each model.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够从云端到边缘设备自动化构建-训练-部署工作流程，并跟踪每个模型的整个生命周期。
- en: Automatically optimize ML models for deployment on a wide variety of edge devices
    that are powered by CPUs, GPUs, and embedded ML accelerators.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动优化ML模型，以便在由CPU、GPU和嵌入式ML加速器供电的广泛边缘设备上部署。
- en: Supports model compilation from different frameworks such as **DarkNet**, **Keras**,
    **MXNet**, **PyTorch**, **TensorFlow**, **TensorFlow-Lite**, **ONNX**, and **XGBoost**.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持从不同的框架（如**DarkNet**、**Keras**、**MXNet**、**PyTorch**、**TensorFlow**、**TensorFlow-Lite**、**ONNX**和**XGBoost**）进行模型编译。
- en: Supports multi-modal hosting of ML models, along with simple API interfaces,
    for performing common queries such as loading, unloading, and running inferences
    on the models on a device.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持多模态托管ML模型，以及简单的API接口，以执行常见的查询，例如在设备上加载、卸载和运行模型推理。
- en: Supports open source remote procedure protocols (using **gRPC**), which allow
    you to integrate with existing edge applications through APIs in common programming
    languages, such as **Android Java**, **C#**/**.NET**, **Go**, **Java**, **Python**,
    and **C**.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持开源远程过程调用协议（使用**gRPC**），允许您通过常用编程语言的API（如**Android Java**、**C#**/**.NET**、**Go**、**Java**、**Python**和**C**）与现有的边缘应用程序集成。
- en: Offers a dashboard to monitor the performance of models running on different
    devices across the fleet. So, in the scenario explained earlier with a connected
    HBS hub, if issues related to model drift, model quality, or predictions are identified,
    these issues can be quickly visualized in a dashboard or reported through configured
    alerts.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供仪表板以监控整个车队中不同设备上运行的模型性能。因此，在前面解释的具有连接 HBS 中心的场景中，如果发现与模型漂移、模型质量或预测相关的问题，这些问题可以快速在仪表板中可视化或通过配置的警报报告。
- en: 'As you can see, Edge Manager brings robust capabilities to manage required
    capabilities for MLOps out of the box and brings native integrations with different
    AWS services, such as AWS IoT Greengrass. The following is a reference architecture
    for Edge Manager integrating with various other services that you were exposed
    to earlier in this book, such as SageMaker and S3:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，Edge Manager 带来了强大的功能，可以开箱即用地管理 MLOps 所需的功能，并带来了与不同 AWS 服务（如 AWS IoT Greengrass）的本地集成。以下是与本书前面介绍的其他服务（如
    SageMaker 和 S3）集成的 Edge Manager 的参考架构：
- en: '![Figure 8.13 – Edge Manager reference architecture'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.13 – 边缘管理器参考架构'
- en: '](img/B17595_08_13.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_13.jpg)'
- en: Figure 8.13 – Edge Manager reference architecture
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.13 – 边缘管理器参考架构
- en: Note
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: MLOps is still emerging and can be complicated to implement without the involvement
    of ML practitioners. If you would like to learn more about this subject, please
    refer to other books that have been published on this subject.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps 仍在不断发展，如果没有 ML 实践者的参与，实施起来可能会很复杂。如果您想了解更多关于这个主题的信息，请参阅已经出版的其他关于这个主题的书籍。
- en: Now that you have learned the fundamentals of DevOps and MLOps, let's get our
    hands dirty so that we can apply some of these practices and operate edge workloads
    in an agile fashion.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学习了 DevOps 和 MLOps 的基础知识，让我们动手实践，以便我们可以应用一些这些实践，并以敏捷的方式操作边缘工作负载。
- en: Hands-on with the DevOps architecture
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实战 DevOps 架构
- en: 'In this section, you will learn how to deploy multiple Docker applications
    to the edge that have already been developed using CI/CD best practices in the
    cloud. These container images are available in a **Docker repository** called
    **Docker Hub**. The following diagram shows the architecture for this hands-on
    exercise, where you will complete *Steps 1* and *2* to integrate the HBS hub with
    an existing CI/CD pipeline (managed by your DevOps org), configure the Docker
    containers, and then deploy and validate them so that they can operate at the
    edge:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何将已经使用云中的 CI/CD 最佳实践开发的多个 Docker 应用程序部署到边缘。这些容器镜像可在名为 **Docker Hub**
    的 **Docker 仓库** 中找到。以下图表显示了本实战练习的架构，其中你将完成 *步骤 1* 和 *步骤 2* 以将 HBS 中心与现有的 CI/CD
    管道（由你的 DevOps 组织管理）集成，配置 Docker 容器，然后部署和验证它们，以便它们可以在边缘运行：
- en: '![Figure 8.14 – Hands-on DevOps architecture'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.14 – 实战 DevOps 架构'
- en: '](img/B17595_08_14.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_14.jpg)'
- en: Figure 8.14 – Hands-on DevOps architecture
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.14 – 实战 DevOps 架构
- en: 'The following are the services you will use in this exercise:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是你将在本练习中使用的服务：
- en: '![Figure 8.15 – Services for this exercise'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.15 – 本练习的服务'
- en: '](img/B17595_08_Table2.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_08_Table2.jpg)'
- en: Figure 8.15 – Services for this exercise
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.15 – 本练习的服务
- en: 'Your objectives for this hands-on section are as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 本实战部分的你的目标是以下内容：
- en: Deploy container images from Docker Hub to AWS IoT Greengrass.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 Docker Hub 将容器镜像部署到 AWS IoT Greengrass。
- en: Confirm that the containers are running.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确认容器正在运行。
- en: Let's get started.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Deploying the container from the cloud to the edge
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从云部署容器到边缘
- en: 'In this section, you will learn how to deploy a pre-built container from the
    cloud to the edge:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何将预构建的容器从云部署到边缘：
- en: 'Navigate to your device''s terminal and confirm that Docker is installed:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到您的设备终端并确认 Docker 已安装：
- en: '[PRE0]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, let's review the `docker-compose` file. If you have not used `docker-compose`
    before, then note that it is a utility that's used for defining and running multi-container
    applications. This tool requires a file called `docker-compose.yaml` that lists
    the configuration details for application services to be installed and their dependencies.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们回顾一下 `docker-compose` 文件。如果您之前没有使用过 `docker-compose`，请注意，这是一个用于定义和运行多容器应用的实用工具。此工具需要一个名为
    `docker-compose.yaml` 的文件，该文件列出了要安装的应用程序服务的配置细节及其依赖项。
- en: 'Please review the `docker-compose.yaml` file in the `artifacts` folder of this
    chapter. It includes three container images from Docker Hub corresponding to the
    web, application, and database tiers:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请查阅本章`artifacts`文件夹中的`docker-compose.yaml`文件。它包括来自Docker Hub的三个容器镜像，分别对应于Web、应用程序和数据库层：
- en: '[PRE1]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Navigate to the following working directory to review the Greengrass recipe
    file:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到以下工作目录以审查Greengrass配方文件：
- en: '[PRE2]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that there is a dependency on the Greengrass-managed Docker application
    manager component. This component helps with retrieving container images from
    the respective repositories and executes Docker-related commands for installing
    and managing the life cycle of containers on the edge:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，这里依赖于Greengrass管理的Docker应用程序管理器组件。这个组件有助于从相应的仓库检索容器镜像，并执行与安装和管理边缘上容器生命周期相关的Docker命令：
- en: '[PRE3]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now that we have the updated `docker-compose` file and the Greengrass component
    recipe, let''s create a local deployment:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了更新的`docker-compose`文件和Greengrass组件配方，让我们创建一个本地部署：
- en: '[PRE4]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Verify that the component has been successfully deployed (and is running) using
    the following command:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令验证组件是否已成功部署（并且正在运行）：
- en: '[PRE5]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To test which containers are currently running, run the following command:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要测试哪些容器目前正在运行，请运行以下命令：
- en: '[PRE6]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You should see the following output:'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该看到以下输出：
- en: '![Figure 8.16 – Running container processes'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.16 – 运行中的容器进程'
- en: '](img/B17595_08_16.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.16 – 运行中的容器进程](img/B17595_08_16.jpg)'
- en: Figure 8.16 – Running container processes
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.16 – 运行中的容器进程
- en: 'In our example here, the app (`hello-world`) is a one-time process, so it has
    already been completed. But the remaining two containers are still up and running.
    If you want to check all the container processes that have run so far, use the
    following command:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们这里的例子中，这个应用（`hello-world`）是一个一次性进程，所以它已经完成了。但剩下的两个容器仍在运行。如果你想检查到目前为止已经运行的所有容器进程，请使用以下命令：
- en: '[PRE7]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You should see the following output:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下输出：
- en: '![Figure 8.17 – All container processes'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.17 – 所有容器进程'
- en: '](img/B17595_08_17.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.17 – 所有容器进程](img/B17595_08_17.jpg)'
- en: Figure 8.17 – All container processes
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.17 – 所有容器进程
- en: Congratulations – you now have multiple containers successfully deployed on
    the edge from a Docker repository (Docker Hub). In the real world, if you want
    to run a local web application on the HBS hub, this pattern can be useful.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你——你现在已经在边缘从Docker仓库（Docker Hub）成功部署了多个容器。在现实世界中，如果你想在一个HBS中心运行本地Web应用程序，这种模式可能很有用。
- en: Challenge zone (Optional)
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战区域（可选）
- en: Can you figure out how to deploy a Docker image from Amazon ECR or Amazon S3?
    Although Docker Hub is useful for storing public container images, enterprises
    will often use a private repository for their home-grown applications.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 你能想出如何从Amazon ECR或Amazon S3部署Docker镜像吗？虽然Docker Hub对于存储公共容器镜像很有用，但企业通常会使用私有仓库来存储他们自家的应用程序。
- en: 'Hint: You need to make changes to `docker-compose` with the appropriate URI
    for the container images and provide the required permissions to the Greengrass
    role.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：你需要对`docker-compose`进行更改，使用适当的URI来指定容器镜像，并为Greengrass角色提供所需的权限。
- en: With that, you've learned how to deploy any number of containers on the edge
    (so long as the hardware resource permits it) from heterogeneous sources to develop
    a multi-faceted architecture on the edge. Let's wrap up this chapter with a quick
    summary and a set of knowledge check questions.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，你已经学会了如何从异构源部署任意数量的容器到边缘（只要硬件资源允许），以在边缘开发一个多方面的架构。让我们通过一个快速总结和一些知识检查问题来结束这一章。
- en: Summary
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you were introduced to the DevOps and MLOps concepts that are
    required to bring operational efficiency and agility to IoT and ML workloads at
    the edge. You also learned how to deploy containerized applications from the cloud
    to the edge. This functionality allowed you to build an intelligent, distributed,
    and heterogeneous architecture on the Greengrass-enabled HBS hub. With this foundation,
    your organization can continue to innovate with different kinds of workloads,
    as well as deliver features and functionalities to the end consumers throughout
    the life cycle of the product. In the next chapter, you will learn about the best
    practices of scaling IoT operations as your customer base grows from thousands
    to millions of devices globally. Specifically, you will learn about the different
    techniques surrounding fleet provisioning and fleet management that are supported
    by AWS IoT Greengrass.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了DevOps和MLOps的概念，这些概念对于在边缘提高物联网和机器学习工作负载的操作效率和敏捷性是必需的。你还学习了如何从云部署容器化应用程序到边缘。这一功能使你能够在Greengrass启用的HBS中心构建一个智能、分布式和异构的架构。有了这个基础，你的组织可以继续用不同类型的工作负载进行创新，并在产品的整个生命周期中向最终消费者提供功能和功能。在下一章中，你将了解随着你的客户群从数千台设备增长到全球数百万台设备时，扩展物联网操作的最佳实践。具体来说，你将了解AWS
    IoT Greengrass支持的围绕车队配置和车队管理的不同技术。
- en: Knowledge check
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 知识检查
- en: 'Before moving on to the next chapter, test your knowledge by answering these
    questions. The answers can be found at the end of the book:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入下一章之前，通过回答以下问题来测试你的知识。答案可以在书的末尾找到：
- en: What strategy would you implement to bring agility in developing IoT workloads
    faster?
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将实施什么策略来加快开发物联网工作负载的敏捷性？
- en: 'True or false: DevOps is a set of tools to help developers and operations collaborate
    faster.'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对或错：DevOps是一套工具，有助于开发者和运维更快地协作。
- en: Can you recall at least two challenges of implementing DevOps with IoT workloads?
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能回忆起实施DevOps与物联网工作负载至少两个挑战吗？
- en: What services should you consider when designing a DevOps workflow from the
    cloud to the edge?
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设计从云到边缘的DevOps工作流程时，你应该考虑哪些服务？
- en: 'True or false: Running native containers and AWS Lambda functions on the edge
    both offer similar benefits.'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对或错：在边缘运行原生容器和AWS Lambda函数都提供了类似的好处。
- en: Can you think of at least three benefits of using MLOps with IoT workloads?
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能想到使用MLOps与物联网工作负载至少三个好处吗？
- en: What are the different phases of an MLOps workflow?
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MLOps工作流程的不同阶段是什么？
- en: 'True or false: The MLOps toolchain for the edge is limited to a few frameworks
    and programming languages.'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对或错：边缘的MLOps工具链仅限于几个框架和编程语言。
- en: What service is available from AWS for performing MLOps on the edge?
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AWS为在边缘执行MLOps提供了哪些服务？
- en: References
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'For more information regarding the topics that were covered in this chapter,
    take a look at the following resources:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 有关本章涵盖的主题的更多信息，请参阅以下资源：
- en: 'DevOps and AWS: [https://aws.amazon.com/devops/](https://aws.amazon.com/devops/%0D)'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DevOps和AWS：[https://aws.amazon.com/devops/](https://aws.amazon.com/devops/%0D)
- en: 'Infrastructure as Code with AWS CloudFormation: [https://aws.amazon.com/cloudformation/](https://aws.amazon.com/cloudformation/%0D)'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用AWS CloudFormation的基础设施即代码：[https://aws.amazon.com/cloudformation/](https://aws.amazon.com/cloudformation/%0D)
- en: 'Developing an IoT-MLOps workflow on AWS Using Edge Manager: [https://docs.aws.amazon.com/sagemaker/latest/dg/edge-greengrass.html](https://docs.aws.amazon.com/sagemaker/latest/dg/edge-greengrass.html%0D)'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在AWS使用Edge Manager开发物联网-MLOps工作流程：[https://docs.aws.amazon.com/sagemaker/latest/dg/edge-greengrass.html](https://docs.aws.amazon.com/sagemaker/latest/dg/edge-greengrass.html%0D)
- en: 'CRISP-ML Methodology with Quality Assurance: [https://arxiv.org/pdf/2003.05155.pdf](https://arxiv.org/pdf/2003.05155.pdf%0D)'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有质量保证的CRISP-ML方法论：[https://arxiv.org/pdf/2003.05155.pdf](https://arxiv.org/pdf/2003.05155.pdf%0D)
- en: 'Machine Learning Operations: [https://ml-ops.org/](https://ml-ops.org/%0D)'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习操作：[https://ml-ops.org/](https://ml-ops.org/%0D)
- en: 'Overview of Docker: [https://docs.docker.com/get-started/overview/](https://docs.docker.com/get-started/overview/%0D)'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker概述：[https://docs.docker.com/get-started/overview/](https://docs.docker.com/get-started/overview/%0D)
- en: 'Different Ways of Running Dockerized Applications on AWS IoT Greengrass: [https://docs.aws.amazon.com/greengrass/v2/developerguide/run-docker-container.html](https://docs.aws.amazon.com/greengrass/v2/developerguide/run-docker-container.html)'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在AWS IoT Greengrass上运行Docker化应用程序的不同方式：[https://docs.aws.amazon.com/greengrass/v2/developerguide/run-docker-container.html](https://docs.aws.amazon.com/greengrass/v2/developerguide/run-docker-container.html)
- en: 'Special interest group: [https://github.com/cdfoundation/sig-mlops](https://github.com/cdfoundation/sig-mlops)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特殊兴趣小组：[https://github.com/cdfoundation/sig-mlops](https://github.com/cdfoundation/sig-mlops)
