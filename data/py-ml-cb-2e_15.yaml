- en: Automated Machine Learning and Transfer Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化机器学习和迁移学习
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下配方：
- en: Working with Auto-WEKA
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Auto-WEKA
- en: Using AutoML to generate machine learning pipelines with TPOT
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AutoML 和 TPOT 生成机器学习管道
- en: Working with Auto-Keras
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Auto-Keras
- en: Working with auto-sklearn
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 auto-sklearn
- en: Using MLBox for selection and leak detection
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 MLBox 进行选择和泄漏检测
- en: Convolutional neural networks with transfer learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有迁移学习的卷积神经网络
- en: Transfer learning – pretrained image classifiers with ResNet-50
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移学习 – 使用 ResNet-50 预训练图像分类器
- en: Transfer learning – feature extraction with the VGG16 model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移学习 – 使用 VGG16 模型进行特征提取
- en: Transfer learning with retrained GloVe embedding
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用重新训练的 GloVe 嵌入进行迁移学习
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To address the recipes in this chapter, you will need the following files (available
    on GitHub):'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理本章中的配方，您需要以下文件（可在 GitHub 上找到）：
- en: '`TPOTIrisClassifier.py`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TPOTIrisClassifier.py`'
- en: '`AKClassifier.py`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AKClassifier.py`'
- en: '`MLBoxRegressor.py`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLBoxRegressor.py`'
- en: '`ASKLClassifier.py`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ASKLClassifier.py`'
- en: '`ImageTransferLearning.py`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ImageTransferLearning.py`'
- en: '`PretrainedImageClassifier.py`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PretrainedImageClassifier.py`'
- en: '`ExtractFeatures.py`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ExtractFeatures.py`'
- en: '`PTGloveEMB.py`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PTGloveEMB.py`'
- en: Introduction
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: '**Automated machine learning** (**AutoML**) refers to those applications that
    are able to automate the end-to-end process of applying machine learning to real-world
    problems. Generally, scientific analysts must process data through a series of
    preliminary procedures before submitting it to machine learning algorithms. In
    the previous chapters, you saw the necessary steps for performing a proper analysis
    of data through these algorithms. You saw how simple it is to build a model based
    on deep neural networks by using several libraries. In some cases, these skills
    are beyond those possessed by analysts, who must seek support from industry experts
    to solve the problem.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**自动化机器学习**（**AutoML**）指的是那些能够自动化将机器学习应用于现实世界问题端到端过程的应用。通常，科学分析师必须在将数据提交给机器学习算法之前，通过一系列的初步程序来处理数据。在前几章中，您看到了通过这些算法进行适当数据分析的必要步骤。您看到了如何通过使用几个库来构建基于深度神经网络的模型是多么简单。在某些情况下，这些技能超出了分析师所拥有的，他们必须寻求行业专家的支持来解决该问题。'
- en: 'AutoML was born from a need to create an application that automated the whole
    machine learning process so that the user could take advantage of these services.
    Generally, machine learning experts must perform the following tasks:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML 的诞生源于创建一个能够自动化整个机器学习过程的应用的需求，以便用户可以利用这些服务。通常，机器学习专家必须执行以下任务：
- en: Data preparation
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据准备
- en: Selecting features
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择特征
- en: Selecting an appropriate model class
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择合适的模型类别
- en: Choosing and optimizing model hyperparameters
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择和优化模型超参数
- en: Post-processing machine learning models
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后处理机器学习模型
- en: Analyzing the results obtained
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析获得的结果
- en: AutoML automates all of these operations. It offers the advantages of producing
    simpler and faster-to-create solutions that often outperform hand-designed models.
    There are a number of AutoML frameworks; in the following sections, we will look
    at some of them.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML 自动化所有这些操作。它提供了产生更简单、创建更快且通常优于手工设计的解决方案的优势。存在许多 AutoML 框架；在接下来的几节中，我们将探讨其中的一些。
- en: Working with Auto-WEKA
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Auto-WEKA
- en: Weka is a software environment that's entirely written in Java. **Weka**, an
    acronym for **Waikato Environment for Knowledge Analysis**, is a machine learning
    software that was developed at the University of Waikato in New Zealand. It is
    open source and is distributed under the GNU General Public License. It is possible
    to build many models based on machine learning by using it.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Weka 是一个完全用 Java 编写的软件环境。**Weka**，即**Waikato 知识分析环境**的缩写，是在新西兰的 Waikato 大学开发的机器学习软件。它是开源的，并按照
    GNU 通用公共许可证进行分发。使用它，可以基于机器学习构建许多模型。
- en: However, each of the algorithms has its own hyperparameters, which can drastically
    change their performance. The task of the researcher is to find the right combination
    of these parameters that will maximize the performance of the model. Auto-WEKA
    automatically solves the problem of the selection of a learning algorithm and
    the setting of its hyperparameters.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，每个算法都有自己的超参数，这些参数可能会极大地改变它们的性能。研究人员的任务是找到这些参数的正确组合，以最大化模型的性能。Auto-WEKA 自动解决了选择学习算法及其超参数设置的问题。
- en: Getting ready
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: In this recipe, you will learn how to use Auto-WEKA in only three main steps. To
    use this library, it is necessary to install it beforehand. For information on
    the system requirements and the installation procedure, refer to [https://www.cs.ubc.ca/labs/beta/Projects/autoweka/manual.pdf](https://www.cs.ubc.ca/labs/beta/Projects/autoweka/manual.pdf).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，你将学习如何在三个主要步骤中使用Auto-WEKA。要使用这个库，必须先安装它。有关系统要求和安装程序的详细信息，请参阅[https://www.cs.ubc.ca/labs/beta/Projects/autoweka/manual.pdf](https://www.cs.ubc.ca/labs/beta/Projects/autoweka/manual.pdf)。
- en: How to do it...
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s look at how to work with Auto-WEKA, as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用Auto-WEKA，如下所示：
- en: '**Building the experiment definition and instantiating it**: In this step,
    you specify which dataset to use and which type of hyperparameter search will
    be performed. Then, the experiment is completely instantiated so that Auto-WEKA
    can identify the classifier to be used. In this phase, Auto-WEKA transforms all
    of the paths into absolute paths.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建实验定义并实例化**：在这个步骤中，你指定要使用哪个数据集以及要执行哪种类型的超参数搜索。然后，实验被完全实例化，以便Auto-WEKA可以识别要使用的分类器。在这个阶段，Auto-WEKA将所有路径转换为绝对路径。'
- en: '**Experiment execution**: Auto-WEKA uses multiple cores by running the same
    experiment with several random seeds; the only requirement is that all of the
    experiments have a similar filesystem.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实验执行**：Auto-WEKA通过使用多个随机种子运行相同的实验来利用多个核心；唯一的要求是所有实验都有一个相似的文件系统。'
- en: '**Analysis phase**: When Auto-WEKA uses a model-based optimization method,
    it produces a trajectory of hyperparameters that have identified by the optimization
    method as the best at a given time. The simplest form of analysis examines the
    best hyperparameters that have been found in all seeds and uses the trained model
    to make predictions about a new dataset.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分析阶段**：当Auto-WEKA使用基于模型的优化方法时，它会生成一个超参数轨迹，这些超参数是由优化方法在特定时间识别为最佳的超参数。分析的最简单形式是检查在所有种子中找到的最佳超参数，并使用训练好的模型对新数据集进行预测。'
- en: How it works...
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: To select a learning algorithm and set its hyperparameters, Auto-WEKA uses a
    completely automated approach, taking advantage of recent innovations in Bayesian
    optimization.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择学习算法并设置其超参数，Auto-WEKA使用一种完全自动化的方法，利用贝叶斯优化方面的最新创新。
- en: There's more…
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: Auto-WEKA was the first library to use Bayesian optimization to automatically
    instantiate a highly parametric machine learning framework. Later, AutoML was
    also applied by other libraries.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-WEKA是第一个使用贝叶斯优化来自动实例化高度参数化机器学习框架的库。后来，AutoML也被其他库所应用。
- en: See also
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: 'Refer to the official Auto-WEKA website: [https://www.cs.ubc.ca/labs/beta/Projects/autoweka/](https://www.cs.ubc.ca/labs/beta/Projects/autoweka/)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考官方Auto-WEKA网站：[https://www.cs.ubc.ca/labs/beta/Projects/autoweka/](https://www.cs.ubc.ca/labs/beta/Projects/autoweka/)
- en: 'Refer to *Auto-WEKA 2.0: Automatic model selection and hyperparameter optimization
    in WEKA*: [https://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/16-599.pdf](https://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/16-599.pdf)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考以下文档：*Auto-WEKA 2.0：在WEKA中进行自动模型选择和超参数优化*：[https://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/16-599.pdf](https://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/16-599.pdf)
- en: 'Refer to *Auto-WEKA: Combined Selection and Hyperparameter Optimization of
    Classification Algorithms*: [https://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/autoweka.pdf](https://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/autoweka.pdf)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考以下文档：*Auto-WEKA：分类算法的联合选择和超参数优化*：[https://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/autoweka.pdf](https://www.cs.ubc.ca/labs/beta/Projects/autoweka/papers/autoweka.pdf)
- en: Using AutoML to generate machine learning pipelines with TPOT
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AutoML和TPOT生成机器学习管道
- en: '**TPOT** is a Python automated machine learning tool that optimizes machine
    learning pipelines by using genetic programming. In artificial intelligence, genetic
    algorithms are part of the class of evolutionary algorithms. A characteristic
    of the latter is finding solutions to problems by using techniques that are borrowed
    from natural evolution. The search for a solution to a problem is entrusted to
    an iterative process that selects and recombines more and more refined solutions
    until a criterion of optimality is reached. In a genetic algorithm, the population
    of solutions is pushed toward a given objective by evolutionary pressure.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**TPOT**是一个Python自动化机器学习工具，通过使用遗传编程优化机器学习管道。在人工智能中，遗传算法是进化算法类的一部分。进化算法的一个特点是使用从自然进化中借鉴的技术来寻找问题的解决方案。寻找问题解决方案的过程被委托给一个迭代过程，该过程通过选择和重组越来越精细的解决方案，直到达到最优性标准。在遗传算法中，通过进化压力将解决方案种群推向一个既定目标。'
- en: Getting ready
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, you will learn how to build the best performing model to classify
    the iris species (setosa, virginica, and versicolor) from the `iris` dataset,
    using TPOT. To use this library, it is necessary to install it. For information
    on the system requirements and for the installation procedure, refer to [https://epistasislab.github.io/tpot/installing/](https://epistasislab.github.io/tpot/installing/).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你将学习如何使用TPOT构建最佳性能模型，从`iris`数据集对鸢尾花物种（setosa、virginica和versicolor）进行分类。要使用此库，必须安装它。有关系统要求和安装过程的信息，请参阅[https://epistasislab.github.io/tpot/installing/](https://epistasislab.github.io/tpot/installing/)。
- en: How to do it...
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s look at how to use AutoML to generate machine learning pipelines with
    TPOT:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用AutoML通过TPOT生成机器学习管道：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `TPOTIrisClassifier.py` file that''s already been provided for you):'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整代码已在提供的`TPOTIrisClassifier.py`文件中给出）：
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s import the iris dataset, as follows:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们按照以下方式导入鸢尾花数据集：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s split the dataset, as follows:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们按照以下方式分割数据集：
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, we can build the classifier:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以构建分类器：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, we can train the model:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以训练模型：
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, we will use the model with unseen data (`XTest`) to evaluate the performance:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将使用未见过的数据(`XTest`)来评估模型性能：
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, we will export the model pipeline:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将导出模型管道：
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you run this code, a pipeline that achieves about 97% test accuracy will
    be returned.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行此代码，将返回一个大约97%测试准确率的管道。
- en: How it works...
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: TPOT automates machine learning pipeline construction by combining a flexible
    representation of the pipeline expression tree with stochastic search algorithms,
    such as genetic programming. In this recipe, you learned how to use TPOT to search
    for the best pipeline to classify the iris species from the iris dataset.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: TPOT通过结合灵活的管道表达式树表示和随机搜索算法（如遗传编程）来自动化机器学习管道的构建。在本教程中，你学习了如何使用TPOT搜索最佳管道来从鸢尾花数据集对鸢尾花物种进行分类。
- en: There's more…
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: TPOT is built on the basis of `scikit-learn`, so all of the code that is generated
    will seem very familiar to us, given the extensive use of the `scikit-learn` libraries
    in the previous chapters. TPOT is a platform that's under active development,
    and it is therefore subject to continuous updates.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: TPOT是在`scikit-learn`的基础上构建的，因此，鉴于前几章广泛使用了`scikit-learn`库，生成的所有代码对我们来说都非常熟悉。TPOT是一个处于积极开发中的平台，因此它将不断更新。
- en: See also
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The official documentation of the TPOT tool: [https://epistasislab.github.io/tpot/](https://epistasislab.github.io/tpot/)
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TPOT工具的官方文档：[https://epistasislab.github.io/tpot/](https://epistasislab.github.io/tpot/)
- en: '*Automating biomedical data science through tree-based pipeline optimization*,
    by Randal S. Olson, Ryan J. Urbanowicz, Peter C. Andrews, Nicole A. Lavender,
    La Creis Kidd, and Jason H. Moore (2016)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过基于树的管道优化自动化生物医学数据科学*，作者：Randal S. Olson, Ryan J. Urbanowicz, Peter C. Andrews,
    Nicole A. Lavender, La Creis Kidd, 和 Jason H. Moore (2016)'
- en: Working with Auto-Keras
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Auto-Keras
- en: Auto-Keras is an open source software library for AutoML that aims at providing
    easy access to deep learning models. Auto-Keras has a number of features that
    allow you to automatically set up the architecture and parameters of deep learning
    models. Its ease of use, simple installation, and numerous examples make it a
    very popular framework. Auto-Keras was developed by the DATA Lab at Texas A and
    M University and community contributors.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-Keras是一个开源的AutoML软件库，旨在提供轻松访问深度学习模型。Auto-Keras具有许多功能，允许您自动设置深度学习模型的架构和参数。其易用性、简单安装和大量示例使其成为一个非常受欢迎的框架。Auto-Keras由德克萨斯A&M大学的DATA实验室和社区贡献者开发。
- en: Getting ready
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In this recipe, you will learn how to use the Auto-Keras library to classify
    handwritten digits. To install the Auto-Keras package, we can use the `pip` command,
    as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，您将学习如何使用Auto-Keras库来分类手写数字。要安装Auto-Keras包，我们可以使用以下`pip`命令：
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: At the time of writing this book, Auto-Keras was only compatible with Python
    3.6\. For the installation procedure, refer to the official website at [https://autokeras.com/](https://autokeras.com/).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，Auto-Keras仅兼容Python 3.6。对于安装过程，请参考官方网站[https://autokeras.com/](https://autokeras.com/)。
- en: How to do it...
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s look at how to work with Auto-Keras:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用Auto-Keras：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `AKClassifier.py` file that''s already been provided for you):'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码已包含在您已提供的`AKClassifier.py`文件中）：
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s import the `mnist` dataset, as follows:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们按照以下方式导入`mnist`数据集：
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Before defining a classifier, we must give a new form to the arrays containing
    the input data without changing its contents:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在定义分类器之前，我们必须给包含输入数据的数组赋予新的形式，而不改变其内容：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, we can build the classifier:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以构建分类器：
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Then, we can train the model:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以训练模型：
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, we will use the model with unseen data (`XTest`):'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将使用未见过的数据（`XTest`）来使用模型：
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: How it works...
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, with a few lines of code, we have managed to construct a classifier
    which, by providing a series of images of handwritten digits, can correctly classify
    the digits.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们仅用几行代码就构建了一个分类器，通过提供一系列手写数字的图像，可以正确地分类数字。
- en: There's more…
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容…
- en: This is a package that allows us to automatically create an algorithm based
    on machine learning without worrying about the setting of the training parameters
    that, as you saw in previous chapters, are fundamental to the success of the model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个允许我们自动创建基于机器学习的算法的包，无需担心训练参数的设置，正如您在前几章中看到的，这些参数对于模型的成功至关重要。
- en: See also
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考信息
- en: Refer to the official documentation of the Auto-Keras library: [https://autokeras.com/](https://autokeras.com/)
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考Auto-Keras库的官方文档：[https://autokeras.com/](https://autokeras.com/)
- en: 'Refer to *Auto-Keras: Efficient Neural Architecture Search with Network Morphism*,
    by Haifeng Jin, Qingquan Song, and Xia Hu (arXiv:1806.10282).'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '参考Haifeng Jin、Qingquan Song和Xia Hu合著的《*Auto-Keras: Efficient Neural Architecture
    Search with Network Morphism*》（arXiv:1806.10282）。'
- en: Working with auto-sklearn
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用auto-sklearn
- en: Auto-sklearn works on the `scikit-learn` machine learning library. It represents
    a platform based on supervised machine learning that's ready for use. It automatically
    searches for the correct machine learning algorithm for a new dataset and optimizes
    its hyperparameters.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-sklearn在`scikit-learn`机器学习库上工作。它代表了一个基于监督机器学习的平台，可直接使用。它自动为新数据集搜索正确的机器学习算法并优化其超参数。
- en: Getting ready
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, you will learn how to use auto-sklearn to build a classifier.
    To import the data, the `sklearn.datasets.load_digits` function will be used.
    This function loads and returns the digits dataset for classification problems.
    Each datapoint is an 8x8 image of a digit.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，您将学习如何使用auto-sklearn构建分类器。为了导入数据，将使用`sklearn.datasets.load_digits`函数。此函数加载并返回用于分类问题的数字数据集。每个数据点是数字的8x8图像。
- en: How to do it...
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s look at how to work with auto-sklearn:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用auto-sklearn：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `ASKLClassifier.py` file that''s already been provided for you):'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码已包含在您已提供的`ASKLClassifier.py`文件中）：
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s import the `digits` dataset, as follows:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们按照以下方式导入`digits`数据集：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s split the dataset, as follows:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们按照以下方式分割数据集：
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we can build the classifier:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以构建分类器：
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Then, we can train the model:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以训练模型：
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Finally, we will use the model with unseen data (`XTest`):'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将使用未见过的数据（`XTest`）来使用模型：
- en: '[PRE19]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: How it works...
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Auto-sklearn uses Bayesian optimization for hyperparameter tuning for traditional
    machine learning algorithms that are implemented within `scikit-learn`. The best
    machine learning algorithm and the parameters that are optimized are searched
    automatically.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-sklearn使用贝叶斯优化来调整`scikit-learn`中实现的传统机器学习算法的超参数。自动搜索最佳的机器学习算法和优化的参数。
- en: There's more…
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Auto-sklearn is a good choice to automate the process of selecting and optimizing
    an automatic learning model because it creates extremely precise machine learning
    models, avoiding the tedious tasks of selecting, training, and testing different
    models.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-sklearn是一个很好的选择来自动化选择和优化自动学习模型的过程，因为它创建了极其精确的机器学习模型，避免了选择、训练和测试不同模型的繁琐任务。
- en: See also
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'The official documentation of the `auto-sklearn` package: [https://automl.github.io/auto-sklearn/stable/](https://automl.github.io/auto-sklearn/stable/)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auto-sklearn`包的官方文档：[https://automl.github.io/auto-sklearn/stable/](https://automl.github.io/auto-sklearn/stable/)'
- en: '*Efficient and Robust Automated Machine Learning*, by Feurer, et al., in Advances
    in Neural Information Processing Systems'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由Feurer等人撰写的《高效且鲁棒的自动化机器学习》，发表于《神经信息处理系统进展》
- en: Using MLBox for selection and leak detection
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MLBox进行选择和泄漏检测
- en: MLBox is an automated library for machine learning. It supports distributed
    data processing, cleaning, formatting, and numerous algorithms for classification
    and regression. It allows for the extremely robust selection of functions and
    leak detection. It also provides stacking models, which means combining a set
    of model information to generate a new model that aims to perform better than
    the individual models.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: MLBox是一个机器学习的自动化库。它支持分布式数据处理、清理、格式化以及分类和回归的多种算法。它允许进行极其鲁棒的功能选择和泄漏检测。它还提供了堆叠模型，这意味着结合一组模型信息以生成一个旨在比单个模型表现更好的新模型。
- en: Getting ready
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: To use this library, it is necessary to install it beforehand. For information
    on the system requirements and the installation procedure, refer to [https://mlbox.readthedocs.io/en/latest/installation.html](https://mlbox.readthedocs.io/en/latest/installation.html).[ ](https://mlbox.readthedocs.io/en/latest/installation.html)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用这个库，必须先安装它。有关系统要求和安装过程的信息，请参阅[https://mlbox.readthedocs.io/en/latest/installation.html](https://mlbox.readthedocs.io/en/latest/installation.html)。
- en: In this recipe, you will learn what's strictly necessary to set up a pipeline
    using MLBox. A regression problem will be addressed via the use of the Boston
    dataset that was already used in [Chapter 1](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml), *The
    Realm of Supervised Learning*.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，你将学习设置使用MLBox管道的严格必要条件。通过使用已经在[第1章](f552bbc7-5e56-41b8-8e8d-915cc1bd53ab.xhtml)，“监督学习领域”中使用的波士顿数据集，我们将解决回归问题。
- en: How to do it...
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s look at how to use MLBox for selection and leak detection:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用MLBox进行选择和泄漏检测：
- en: 'Import the following packages (the full code is in the `MLBoxRegressor.py` file
    that''s already been provided for you):'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下包（完整代码在已经为你提供的`MLBoxRegressor.py`文件中）：
- en: '[PRE20]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s import the data, as follows:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入数据，如下所示：
- en: '[PRE21]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: With this code, we have set up the list of paths to our datasets and the name
    of the target that we are trying to predict.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此代码，我们已经设置了数据集的路径列表以及我们试图预测的目标名称。
- en: 'Now, we will read and preprocess these files:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将读取和预处理这些文件：
- en: '[PRE22]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To evaluate the model, the following code will be used:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了评估模型，将使用以下代码：
- en: '[PRE23]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: In this case, the default configuration was used.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，使用了默认配置。
- en: 'Finally, to predict on the test set, use the following code:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，为了在测试集上进行预测，使用以下代码：
- en: '[PRE24]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: If you want configure the pipeline (steps, parameters, and values), the following
    optional step must be used.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要配置管道（步骤、参数和值），必须使用以下可选步骤。
- en: 'To test and optimize the whole pipeline, we will use the following code:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了测试和优化整个管道，我们将使用以下代码：
- en: '[PRE25]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Finally, to predict on the test set, we will use the following code:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，为了在测试集上进行预测，我们将使用以下代码：
- en: '[PRE26]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: How it works...
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'MLBox builds the whole pipeline with the following three steps:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: MLBox通过以下三个步骤构建整个管道：
- en: '**Preprocessing**: All of the operations related to this phase make use of
    the `mlbox.preprocessing` sub-package. In this phase, we proceed to the reading
    and cleaning of the input file and then to the removal of the drift variables.'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预处理**：与这一阶段相关的所有操作都使用了`mlbox.preprocessing`子包。在这一阶段，我们进行输入文件的读取和清理，然后移除漂移变量。'
- en: '**Optimization**: All of the operations related to this phase make use of the
    sub-package `mlbox.mlbox.optimisation`. In this phase, the whole pipeline is optimized.
    The hyperparametric optimization method that''s adopted uses the `hyperopt` library.
    This library creates a highly-dimensional space for the parameters to be optimized
    and chooses the best combination of parameters that lowers the validation score.'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**优化**：与这一阶段相关的所有操作都使用了`mlbox.mlbox.optimisation`子包。在这一阶段，整个流程被优化。采用的超参数优化方法使用了`hyperopt`库。这个库为要优化的参数创建了一个高维空间，并选择最佳参数组合以降低验证分数。'
- en: '**Prediction**: All of the operations related to this phase make use of the
    `mlbox.prediction` sub-package. In this phase, we proceed to prediction by using
    the test dataset and the best hyperparameters that were identified in the previous
    phase.'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测**：与这一阶段相关的所有操作都使用了`mlbox.prediction`子包。在这一阶段，我们使用测试数据和前一个阶段中确定的最佳超参数进行预测。'
- en: There's more…
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: MLBox provides advanced algorithms and techniques, such as hyperparameter optimization,
    stacking, deep learning, leak detection, entity embedding, parallel processing,
    and more. The use of MLBox is currently limited to Linux only. MLBox was first
    developed using Python 2, and then it was extended to Python 3.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: MLBox提供了高级算法和技术，如超参数优化、堆叠、深度学习、泄漏检测、实体嵌入、并行处理等。目前，MLBox的使用仅限于Linux。MLBox最初是用Python
    2开发的，后来扩展到了Python 3。
- en: See also
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考阅读
- en: 'MLBox''s official documentation: [https://mlbox.readthedocs.io/en/latest/](https://mlbox.readthedocs.io/en/latest/)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLBox的官方文档：[https://mlbox.readthedocs.io/en/latest/](https://mlbox.readthedocs.io/en/latest/)
- en: 'Installation guide: [https://mlbox.readthedocs.io/en/latest/installation.html](https://mlbox.readthedocs.io/en/latest/installation.html)'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装指南：[https://mlbox.readthedocs.io/en/latest/installation.html](https://mlbox.readthedocs.io/en/latest/installation.html)
- en: Convolutional neural networks with transfer learning
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于迁移学习的卷积神经网络
- en: '**Transfer learning** is a methodology based on machine learning that exploits
    the memorization of the knowledge that''s acquired during the resolution of a
    problem and the application of the same to different (but related) problems. The
    need to use transfer learning takes place when there is a limited supply of training
    data. This could be due to the fact that data is rare or expensive to collect
    or label, or inaccessible. With the growing presence of large amounts of data,
    the transfer learning option has become more frequently used.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**迁移学习**是一种基于机器学习的方法，它利用在解决问题的过程中获得的知识记忆，并将其应用于不同（但相关）的问题。当训练数据供应有限时，就需要使用迁移学习。这可能是因为数据稀缺或收集、标记成本高昂，或者难以获取。随着大量数据的日益增多，迁移学习选项的使用频率越来越高。'
- en: '**Convolutional neural networks** (**CNNs**) are essentially **artificial neural
    networks** (**ANNs**). In fact, just like the latter, CNNs are made up of neurons
    that are connected to one another by weighted branches (weight); the training
    parameters of the networks are once again the weight and the bias. In CNNs, the
    connection pattern between neurons is inspired by the structure of the visual
    cortex in the animal world. The individual neurons that are present in this part
    of the brain (the visual cortex) respond to certain stimuli in a narrow region
    of the observation, called the **receptive field**. The receptive fields of different
    neurons are partially overlapped to cover the entire field of vision. The response
    of a single neuron to stimuli taking place in its receptive field can be mathematically
    approximated by a convolution operation.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNNs**）本质上是一种**人工神经网络**（**ANNs**）。实际上，就像后者一样，CNNs由通过加权分支（权重）相互连接的神经元组成；网络的训练参数再次是权重和偏差。在CNNs中，神经元之间的连接模式受到了动物世界中视觉皮层结构的启发。大脑的这一部分（视觉皮层）中的单个神经元对观察到的某个狭窄区域的特定刺激做出反应，这个区域被称为**感受野**。不同神经元的感受野部分重叠，以覆盖整个视野。单个神经元对其感受野内发生的刺激的反应可以通过卷积运算进行数学近似。'
- en: Getting ready
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, you will learn how to build an image recognition model by using
    transfer learning in Keras. To do this, the MobileNet model and Keras high-level
    neural networks API will be used to train the model images extracted from the
    `Caltech256` dataset that we already used in [Chapter 10](8c346bea-36ab-4087-918f-b5d8712977cc.xhtml), *Image
    Content Analysis*. `Caltech256` is very popular in this field! It contains 256
    classes of images, where each class contains thousands of samples.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，你将学习如何使用Keras中的迁移学习来构建图像识别模型。为此，我们将使用MobileNet模型和Keras高级神经网络API来训练从`Caltech256`数据集中提取的模型图像，我们在第10章[图像内容分析](8c346bea-36ab-4087-918f-b5d8712977cc.xhtml)中已经使用过这个数据集。`Caltech256`在这个领域非常受欢迎！它包含256个类别的图像，每个类别包含数千个样本。
- en: How to do it...
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'Let''s build an image recognition model by using transfer learning in Keras;
    in this section, we will explain the code step by step:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Keras中的迁移学习来构建一个图像识别模型；在本节中，我们将逐步解释代码：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `ImageTransferLearning.py` file that''s already been provided for you):'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在已经为你提供的`ImageTransferLearning.py`文件中）：
- en: '[PRE27]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let''s import the `MobileNet` model and discard the last 1,000 neuron layers:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入`MobileNet`模型并丢弃最后的1,000个神经元层：
- en: '[PRE28]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let''s define the Keras model architecture:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义Keras模型架构：
- en: '[PRE29]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, we can build a model based on the architecture that was previously defined:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以基于之前定义的架构构建一个模型：
- en: '[PRE30]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, we can move on to the training phase. Having adopted an approach based
    on transfer learning, it is not necessary to proceed with the training of the
    whole model. This is because MobileNet is already trained. Let''s define the last
    dense levels as the trainable layer:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以进入训练阶段。由于采用了基于迁移学习的方法，因此没有必要对整个模型进行训练。这是因为MobileNet已经训练好了。让我们定义最后的密集层为可训练层：
- en: '[PRE31]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let''s load the training data into `ImageDataGenerator`:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将训练数据加载到`ImageDataGenerator`中：
- en: '[PRE32]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '`ImageDataGenerator` is a built-in Keras class that creates groups of tensor
    image data with real-time data augmentation. The data will be wound over in groups.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '`ImageDataGenerator`是一个内置的Keras类，它创建具有实时数据增强的tensor图像数据组。数据将以组的形式被卷绕。'
- en: 'Let''s define some dependencies and a path for the training data:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一些依赖项和训练数据的路径：
- en: '[PRE33]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let''s compile the Keras model:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们编译Keras模型：
- en: '[PRE34]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The following three arguments are passed:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 以下三个参数被传递：
- en: '`optimizer=''adam''`: An algorithm for first-order, gradient-based optimization
    of stochastic objective functions, based on adaptive estimates of lower-order
    moments.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizer=''adam''`：这是一个基于自适应低阶矩估计的一阶、基于梯度的随机目标函数优化算法。'
- en: '`loss=''categorical_crossentropy''`: We have used the `categorical_crossentropy`
    argument here. When using'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss=''categorical_crossentropy''`：我们在这里使用了`categorical_crossentropy`参数。当使用'
- en: '`categorical_crossentropy`, your targets should be in a categorical format
    (we have 10 classes; the target for each sample must be a 10-dimensional vector
    that is all-zeros, except for a one at the index corresponding to the class of
    the sample).'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`categorical_crossentropy`，你的目标应该以分类格式（我们有10个类别；每个样本的目标必须是一个10维向量，除了对应于样本类别的索引处有一个1之外，其余都是0）。'
- en: '`metrics=[''accuracy'']`: A metric is a function that is used to evaluate the
    performance of your model during training and testing.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metrics=[''accuracy'']`：一个指标是一个在训练和测试期间用于评估模型性能的函数。'
- en: 'Finally, we will define the step size for training and fit the model, as follows:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将定义训练的步长并拟合模型，如下所示：
- en: '[PRE35]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The following results are printed:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 打印以下结果：
- en: '[PRE36]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: How it works...
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, you learned how to use transfer learning in an image recognition
    problem. Through transfer learning, a pretrained model can be used on a large
    and accessible dataset to find layers whose output have reusable features, which
    is done by using this output as input to train a smaller network that requires
    fewer parameters. This network will only need to know the relationships between
    the patterns that are obtained from the pretrained models and the specific problem
    to be solved. As a pretrained model, the MobileNet model was used.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，你学习了如何在图像识别问题中使用迁移学习。通过迁移学习，可以在大型且可访问的数据集上使用预训练模型，以找到具有可重用特征的输出层，这是通过使用这些输出作为输入来训练一个需要较少参数的较小网络来完成的。这个网络只需要知道从预训练模型获得的模式之间的关系以及要解决的特定问题。作为一个预训练模型，我们使用了MobileNet模型。
- en: '`MobileNet` is an architecture that was proposed by Google and that is particularly
    suitable for vision-based applications. MobileNet uses deep separable convolutions
    that significantly reduce the number of parameters, compared to a network with
    normal convolutions with the same depth in the networks. Neural networks based
    on the MobileNet model are thus lighter. The normal convolution is replaced by
    a in-depth convolution, followed by a punctual convolution that is called **convolution
    separable in depth**.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`MobileNet` 是由谷歌提出的一种架构，特别适合于基于视觉的应用。与具有相同深度网络的普通卷积相比，MobileNet使用深度可分离卷积，显著减少了参数数量。因此，基于MobileNet模型的神经网络更轻。普通卷积被深度卷积替换，随后是一个称为**深度可分离卷积**的局部卷积。'
- en: 'The transfer learning procedure was then performed in two phases:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习过程随后分为两个阶段：
- en: First, almost all levels of the neural network were trained on a very large
    and generic dataset to allow for the acquisition of global notions
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，几乎所有的神经网络层都在一个非常大且通用的数据集上进行了训练，以便获取全局概念
- en: Later, we used the specific dataset for the training of the remaining layers,
    deciding whether to propagate the errors through fine-tuning
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后来，我们使用了特定的数据集来训练剩余的层，并决定是否通过微调传播错误
- en: There's more…
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: In this recipe, we used fine-tuning; in fact, we didn't simply replace the final
    level, but we also trained some of the previous levels. In the network that we
    used, the initial levels were used to acquire generic functionalities (exploiting
    the potential of the MobileNet trained network), while the subsequent ones were
    used to finalize the experience that was acquired on the specific activity in
    question. Using this procedure, we froze the first 20 layers while we traced the
    following layers to meet our needs. This methodology helps to achieve better performance
    with less training time.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们使用了微调；实际上，我们并没有简单地替换最终层，我们还训练了一些之前的层。在我们使用的网络中，初始层被用来获取通用功能（利用MobileNet训练网络的潜力），而后续层被用来最终确定特定活动获得的经验。使用这个程序，我们冻结了前20层，同时追踪后续层以满足我们的需求。这种方法有助于在更少的训练时间内实现更好的性能。
- en: 'Fine-tuning can be achieved through the following steps:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 微调可以通过以下步骤实现：
- en: We start with a pretrained network trained on a similar problem and replace
    the output level with a new level of output by adjusting the number of classes.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从一个在类似问题上预训练的网络开始，通过调整类别数量来替换输出层。
- en: The initial values ​​of the weights are those of the pretrained net, except
    for the connections between successive layers whose weights are initialized randomly.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 权重的初始值是预训练网络的值，除了连续层之间的连接，其权重是随机初始化的。
- en: We perform new training iterations (SGD) for optimized weights with respect
    to the peculiarities of the new dataset (it does not need to be large).
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们针对新数据集的独特性（不需要很大）进行新的训练迭代（SGD），以优化权重。
- en: In the fine-tuning process, the model parameters will be adjusted precisely
    to fit with certain observations.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调过程中，模型参数将被精确调整以适应某些观察结果。
- en: See also
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: 'Refer to Keras application models: [https://keras.io/applications/](https://keras.io/applications/)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考Keras应用模型：[https://keras.io/applications/](https://keras.io/applications/)
- en: 'Refer to *MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
    Applications*: [https://arxiv.org/pdf/1704.04861.pdf](https://arxiv.org/pdf/1704.04861.pdf)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考以下内容：《MobileNets：适用于移动视觉应用的效率卷积神经网络》：[https://arxiv.org/pdf/1704.04861.pdf](https://arxiv.org/pdf/1704.04861.pdf)
- en: 'Refer to *Transfer Learning and Computer Vision* (from Yale University): [http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/lecture18.pdf](http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/lecture18.pdf)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考以下内容：《迁移学习与计算机视觉》（耶鲁大学）：[http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/lecture18.pdf](http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/lecture18.pdf)
- en: Refer to *A Survey on Transfer Learning*, S. J. Pan and Q. Yang, in IEEE Transactions
    on Knowledge and Data Engineering: [https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf](https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf)
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考以下内容：《迁移学习综述》，S. J. Pan 和 Q. Yang，发表在《IEEE知识数据工程杂志》：[https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf](https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf)
- en: Transfer learning with pretrained image classifiers using ResNet-50
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ResNet-50预训练图像分类器进行迁移学习
- en: The **residual network** (**ResNet**) represents an architecture that, through
    the use of new and innovative types of blocks (known as **residual blocks**) and
    the concept of residual learning, has allowed researchers to reach depths that
    were unthinkable with the classic feedforward model, due to the problem of the
    degradation of the gradient.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '**残差网络**（**ResNet**）代表了一种架构，通过使用新的创新类型的块（称为**残差块**）和残差学习的概念，使得研究人员能够达到经典前馈模型因梯度退化问题而无法达到的深度。'
- en: Pretrained models are trained on a large set of data, and so they allow us to
    obtain excellent performance. We can therefore adopt pretrained models for a problem
    similar to the one that we want to solve, to avoid the problem of a lack of data.
    Because of the computational costs of the formation of such models, they are available
    in ready-to-use formats. For example, the Keras library offers several models
    such as Xception, VGG16, VGG19, ResNet, ResNetV2, ResNeXt, InceptionV3, InceptionResNetV2,
    MobileNet, MobileNetV2, DenseNet, and NASNet.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型是在大量数据上训练的，因此它们允许我们获得优异的性能。因此，我们可以采用与我们要解决的问题相似的预训练模型，以避免数据不足的问题。由于形成此类模型的计算成本，它们以可用的格式提供。例如，Keras库提供了Xception、VGG16、VGG19、ResNet、ResNetV2、ResNeXt、InceptionV3、InceptionResNetV2、MobileNet、MobileNetV2、DenseNet和NASNet等模型。
- en: Getting ready
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, you will learn how to use a pretrained model to predict the
    class of a single image. To do this, a ResNet-50 model will be used. This model
    is available from the `keras.applications` library.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，你将学习如何使用预训练模型来预测单个图像的类别。为此，将使用ResNet-50模型。此模型来自`keras.applications`库。
- en: How to do it...
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Now, we will use a pretrained model to classify a single image; in this section,
    we will explain the code step by step:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用一个预训练模型来对单个图像进行分类；在本节中，我们将逐步解释代码：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `PretrainedImageClassifier.py` file that''s already been provided for you):'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在已经为你提供的`PretrainedImageClassifier.py`文件中）：
- en: '[PRE37]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let''s define the pretrained model:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义预训练模型：
- en: '[PRE38]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let''s define the image to classify:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义要分类的图像：
- en: '[PRE39]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Here, we will take an image instance and turn it into a `numpy` array with
    `dtype` `float32`:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们将一个图像实例转换为一个`numpy`数组，数据类型为`float32`：
- en: '[PRE40]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, we will expand the `numpy` array that''s obtained in the shape that''s
    required by the pretrained model:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将获得的`numpy`数组扩展到预训练模型所需的形状：
- en: '[PRE41]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Then, we will preprocess the data:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将预处理数据：
- en: '[PRE42]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Finally, we will use the pretrained model to classify the input image:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将使用预训练模型对输入图像进行分类：
- en: '[PRE43]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'To evaluate the model''s performance, we will use the `decode_predictions`
    function, as follows:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了评估模型性能，我们将使用`decode_predictions`函数，如下所示：
- en: '[PRE44]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The `keras.applications.resnet50.decode_predictions` function decodes the results
    into a list of tuples (class, description, and probability). The following results
    are printed:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '`keras.applications.resnet50.decode_predictions`函数将结果解码为一个包含元组的列表（类别、描述和概率）。以下结果被打印出来：'
- en: '[PRE45]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The higher probability (`0.80847234`) tells us that it is an airliner; in fact,
    the following is the image that was provided as input:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 较高的概率（`0.80847234`）告诉我们它是一架飞机；事实上，以下就是作为输入提供的图像：
- en: '![](img/999001d5-8a86-43b0-8bc7-fc359f12e3b6.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/999001d5-8a86-43b0-8bc7-fc359f12e3b6.png)'
- en: How it works...
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Instead of trying to estimate a function `G` that, given an `x`, returns `G
    (x)`, ResNet learns the difference between the two values—a value called the **residual**. In
    the residual layer of the network, a classical convolution takes place and the
    input is added to the result. If the input and output are of different sizes,
    the input is transformed with another 1×1 filter convolution before being added
    to the output so that it has the same feature map number. The size of a feature
    map is preserved by padding. A benefit of this technique is that the L2 regularization,
    which tends the weights toward zero, does not make us forget what was learned
    previously, but simply preserves it.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是试图估计一个函数`G`，该函数给定一个`x`，返回`G(x)`，ResNet学习这两个值之间的差异——一个称为**残差**的值。在网络中的残差层，发生了一个经典的卷积，并将输入加到结果上。如果输入和输出的大小不同，输入在添加到输出之前会通过另一个1×1滤波器卷积进行转换，以确保它具有相同的特征图数量。通过填充来保留特征图的大小。这种技术的优点是，L2正则化，它倾向于将权重推向零，不会让我们忘记之前学到的内容，而只是简单地保留它。
- en: There's more…
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: There are ResNet implementations with different depths; the deepest counts as
    many as 152 levels. There is also a prototype with 1,202 levels, but it achieved
    worse results due to overfitting. This architecture won ILSVRC 2015, with an error
    of 3.6%. To understand the value of this result, just consider that the error
    that's generally achieved by a human being is around 5-10%, based on their skills
    and knowledge. Thanks to these results, the ResNet model is currently state of
    the art in the field of computer vision.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同深度的ResNet实现；最深的达到152层。还有一个1,202层的原型，但由于过拟合，它实现了更差的结果。这个架构赢得了2015年ILSVRC，错误率为3.6%。为了理解这个结果的价值，只需考虑人类通常能达到的错误率大约在5-10%，这取决于他们的技能和知识。多亏了这些结果，ResNet模型目前在计算机视觉领域是当前最先进的。
- en: See also
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关内容
- en: 'The official documentation of the `keras.applications` models: [https://keras.io/applications/ ](https://keras.io/applications/)'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keras.applications`模型的官方文档：[https://keras.io/applications/](https://keras.io/applications/)'
- en: '*Deep Residual Learning for Image Recognition* (by Kaiming He, Xiangyu Zhang,
    Shaoqing Ren, and Jian Sun): [https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《深度残差学习用于图像识别》*（由Kaiming He、Xiangyu Zhang、Shaoqing Ren和Jian Sun著）：[https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)'
- en: '*Pretrained Models* (from Toronto University): [https://www.cs.toronto.edu/~frossard/tags/pre-trained-models/](https://www.cs.toronto.edu/~frossard/tags/pre-trained-models/)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预训练模型*（来自多伦多大学）：[https://www.cs.toronto.edu/~frossard/tags/pre-trained-models/](https://www.cs.toronto.edu/~frossard/tags/pre-trained-models/)'
- en: Transfer learning using feature extraction with the VGG16 model
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用VGG16模型进行特征提取的迁移学习
- en: As we stated in the *Visualizing the MNIST dataset using PCA and t-SNE* recipe
    of [Chapter 14](bfa120ec-7b32-4af2-85c3-f16bbaf84998.xhtml)*, Unsupervised Representation
    Learning*, in the case of datasets of important dimensions, the data was transformed
    into a reduced series of representation functions. This process of transforming
    the input data into a set of functionalities is named **feature extraction**.
    This is because the extraction of the characteristics proceeds from an initial
    series of measured data and produces derived values that can keep the information
    contained in the original dataset, but excluded from the redundant data. In the
    case of images, feature extraction is aimed at obtaining information that can
    be identified by a computer.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[第14章](bfa120ec-7b32-4af2-85c3-f16bbaf84998.xhtml)的*使用PCA和t-SNE可视化MNIST数据集*食谱中所述，在重要维度的数据集中，数据被转换成一系列的表示函数。这个过程将输入数据转换成一系列功能，被称为**特征提取**。这是因为特征的提取是从一系列初始测量数据开始的，并产生导出的值，这些值可以保留原始数据集中的信息，但排除冗余数据。在图像的情况下，特征提取的目标是获取计算机可以识别的信息。
- en: Getting ready
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, you will learn how to extract features from a series of images.
    Then, we will use these features to classify the images by using the k-means algorithm.
    In this recipe, we will use the VGG16 pretrained model and the `klearn.cluster.KMeans`
    function.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，你将学习如何从一系列图像中提取特征。然后，我们将使用这些特征通过k-means算法对图像进行分类。在这个食谱中，我们将使用VGG16预训练模型和`klearn.cluster.KMeans`函数。
- en: How to do it...
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s perform a feature extraction procedure by using the VGG16 model:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用VGG16模型执行特征提取过程：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `ExtractFeatures.py` file that''s already been provided for you):'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在已经为你提供的`ExtractFeatures.py`文件中）：
- en: '[PRE46]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Let''s define the pretrained model:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义预训练模型：
- en: '[PRE47]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Let''s initialize the list of features that will be extracted:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们初始化将要提取的特征列表：
- en: '[PRE48]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'For each image in the dataset, we have to proceed with the extraction of features:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于数据集中的每个图像，我们必须进行特征提取：
- en: '[PRE49]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: In this way, we have recovered the path of each image contained in the folder.
    The images that are used are contained in the `training_images` folder, which
    we already used in the *Convolutional neural networks with transfer learning *recipe.
    It is a series of images that was extracted from the `Caltech256` dataset.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们已经恢复了文件夹中每个图像的路径。所使用的图像包含在`training_images`文件夹中，我们在*使用迁移学习的卷积神经网络*食谱中已经使用过它。这是一系列从`Caltech256`数据集中提取的图像。
- en: 'Let''s import the image, as follows:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们按照以下方式导入图像：
- en: '[PRE50]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We will take an image instance and turn it into a NumPy array, with datatype
    as `float32`:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将取一个图像实例并将其转换为`float32`类型的NumPy数组：
- en: '[PRE51]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Now, we will expand the NumPy array that''s obtained in the shape that''s required
    by the pretrained model:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将根据预训练模型所需形状扩展获得的NumPy数组：
- en: '[PRE52]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Then, we will preprocess the data:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将预处理数据：
- en: '[PRE53]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We will use the pretrained model to extract features from the input image:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用预训练模型从输入图像中提取特征：
- en: '[PRE54]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'At this point, we will create an array with the obtained features:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一点上，我们将创建一个包含获取到的特征的数组：
- en: '[PRE55]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Now, we will add the array that was obtained, to the list of features that
    we are building (one element for each image):'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将获得的数组添加到我们正在构建的特征列表中（每个图像一个元素）：
- en: '[PRE56]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'We will transform the final list into an array:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将最终列表转换为数组：
- en: '[PRE57]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Now, we can use the features that was obtained from the images to group them
    by type. Remember that these are images from three categories: airplanes, cars,
    and motorbikes. So, we expect the images to be labeled with three different labels.
    To do this, we use the `KMeans` algorithm, as follows:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用从图像中获得的特征按类型对它们进行分组。记住，这些图像来自三个类别：飞机、汽车和摩托车。因此，我们预计图像将被标记为三个不同的标签。为此，我们使用以下`KMeans`算法：
- en: '[PRE58]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'After defining the model, we move on to training it:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在定义模型后，我们继续训练它：
- en: '[PRE59]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Finally, we print the labels of the images that are used:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们打印出所使用图像的标签：
- en: '[PRE60]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The following results are printed:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 以下结果被打印出来：
- en: '[PRE61]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: As you can see, the 60 images have been correctly labeled in the three available
    categories.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，60张图像已经正确地标记在三个可用的类别中。
- en: How it works...
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: In this recipe, you learned how to extract features from a series of images.
    As we have a limited number of images available, we used a pretrained model (VGG16)
    to correctly extract the information that was needed for subsequent identification.
    This procedure is useful to understand how to proceed to perform automatic recognition
    of the images through an unsupervised model. After extracting the features, we
    used them to classify the images, using the KMeans algorithm.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，你学习了如何从一系列图像中提取特征。由于我们可用的图像数量有限，我们使用了预训练模型（VGG16）来正确提取后续识别所需的信息。这个程序有助于理解如何通过无监督模型自动识别图像。在提取特征后，我们使用它们通过KMeans算法对图像进行分类。
- en: There's more…
  id: totrans-291
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多……
- en: VGG16 is a convolutional neural network model that was presented by K. Simonyan
    and A. Zisserman, from the University of Oxford, in the paper *Very Deep Convolutional
    Networks for Large-Scale Image Recognition*. This model has achieved excellent
    results in image recognition (with 92.7% accuracy). The test was performed on
    the ImageNet dataset, with over 14 million images belonging to 1,000 classes.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: VGG16是由牛津大学的K. Simonyan和A. Zisserman提出的一种卷积神经网络模型，在论文*非常深的卷积神经网络在大规模图像识别中的应用*中进行了介绍。该模型在图像识别（准确率达到92.7%）方面取得了优异的成绩。测试是在ImageNet数据集上进行的，该数据集包含超过1400万张属于1000个类别的图像。
- en: See also
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Refer to the *Visualizing Mnist dataset using PCA and t-SNE* recipe in [Chapter
    14](bfa120ec-7b32-4af2-85c3-f16bbaf84998.xhtml)*, Unsupervised Representation
    Learning*
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考第14章中*使用PCA和t-SNE可视化Mnist数据集*的菜谱[第14章](bfa120ec-7b32-4af2-85c3-f16bbaf84998.xhtml)*，无监督表示学习*
- en: 'Refer to *Very Deep Convolutional Networks for Large-Scale Image Recognition*:
    [https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考论文*非常深的卷积神经网络在大规模图像识别中的应用*：[https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)
- en: Transfer learning with pretrained GloVe embedding
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用预训练GloVe嵌入的迁移学习
- en: '**GloVe** is an unsupervised learning algorithm for obtaining vector representations
    of words. The training is performed on the aggregate global statistics on the
    co-occurrence of words that has been extracted from a body of text present in
    the code files. The resulting representations show interesting linear substructures
    in the vector space of words. In this recipe, you will learn how to use a pretrained
    GloVe embedding model to classify adjectives to describe a person in a positive
    or negative fashion.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '**GloVe**是一种用于获取单词向量表示的无监督学习算法。训练是在从代码文件中的文本中提取的单词共现的全球统计聚合上进行的。这些表示在单词的向量空间中显示出有趣的线性子结构。在这个菜谱中，你将学习如何使用预训练的GloVe嵌入模型来对形容词进行分类，以描述一个人的正面或负面特征。'
- en: Getting ready
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'To follow this recipe, you will need to download the `glove.6B.100d.txt` file.
    This file is available at [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/).
    There are several versions of the pretrained word vectors:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 要遵循此食谱，您需要下载 `glove.6B.100d.txt` 文件。此文件可在 [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)
    获取。预训练的词向量有多个版本：
- en: '**glove.6B**: 6B tokens, 400K vocab, uncased, 50d, 100d, 200d, and 300d vectors—822
    MB'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**glove.6B**: 6B 令牌，400K 词汇量，不区分大小写，50d、100d、200d 和 300d 向量——822 MB'
- en: '**glove.42B.300d**: 42B tokens, 1.9M vocab, uncased, 300d vectors—1.75 GB'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**glove.42B.300d**: 42B 令牌，1.9M 词汇量，不区分大小写，300d 向量——1.75 GB'
- en: '**glove.840B.300d**: 840B tokens, 2.2M vocab, cased, 300d vectors—2.03 GB'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**glove.840B.300d**: 840B 令牌，2.2M 词汇量，区分大小写，300d 向量——2.03 GB'
- en: '**Twitter**: 27B tokens, 1.2M vocab, uncased, 25d, 50d, 100d, and 200d vectors—1.42
    GB'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Twitter**: 27B 令牌，1.2M 词汇量，不区分大小写，25d、50d、100d 和 200d 向量——1.42 GB'
- en: How to do it...
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s classify the adjectives that are used to describe a person in a positive
    and negative fashion:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分类用于描述人的积极和消极态度的形容词：
- en: 'Create a new Python file and import the following packages (the full code is
    in the `PTGloveEMB.py` file that''s already been provided for you):'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的 Python 文件并导入以下包（完整的代码已包含在您已提供的 `PTGloveEMB.py` 文件中）：
- en: '[PRE62]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Let''s define the 10 positive and 10 negative adjectives that are used to describe
    a person:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义用于描述人的 10 个积极和 10 个消极形容词：
- en: '[PRE63]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Let''s define the labels of the adjectives that were defined previously (`1` =
    positive, `0` = negative):'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义之前定义的形容词的标签（`1` = 积极，`0` = 消极）：
- en: '[PRE64]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Let''s tokenize the adjectives and prepare the vocabulary:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们分词形容词并准备词汇表：
- en: '[PRE65]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Let''s encode the adjectives into an integer sequence and transform a list
    of sequences into a two-dimensional NumPy array:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将形容词编码为整数序列并将序列列表转换为二维 NumPy 数组：
- en: '[PRE66]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Let''s load the pretrained model:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载预训练模型：
- en: '[PRE67]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'We will create a weight matrix for words in tokenized adjectives:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将为分词形容词创建一个权重矩阵：
- en: '[PRE68]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Now, we are ready to define the `keras` sequential model:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们准备好定义 `keras` 顺序模型：
- en: '[PRE69]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The following summary is printed:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 以下摘要将被打印：
- en: '[PRE70]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: As you can see, only part of the parameters have been trained.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，只有部分参数已被训练。
- en: 'Let''s compile and fit the model:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们编译和拟合模型：
- en: '[PRE71]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Finally, we will evaluate the model''s performance:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将评估模型的表现：
- en: '[PRE72]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The following result is returned:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 以下结果将被返回：
- en: '[PRE73]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: How it works...
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: To quantitatively capture the nuances that are necessary to distinguish a positive
    adjective from a negative adjective, a model has to associate more than a single
    number with word combinations. A simple method for a set of words is the vector
    difference between two vectors of words. GloVe is designed so that these vector
    differences capture the meanings specified by the juxtaposition of several words
    as closely as possible.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定量捕捉区分积极形容词和消极形容词所必需的细微差别，模型必须将多个数字与词组合相关联。一组词的简单方法就是两个词向量之间的向量差。GloVe 被设计成尽可能紧密地捕捉由几个词并置所指定的意义。
- en: There's more…
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'In transfer learning, the weights of the network are adapted and transferred
    so that we can use this knowledge to pursue multiple different objectives. To
    obtain good performance from transfer learning, certain conditions must be met:
    the initial and final datasets must not be too different from each other, and
    they must share the same preprocessing operations.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在迁移学习中，网络的权重被调整和转移，以便我们可以使用这些知识来追求多个不同的目标。为了从迁移学习中获得良好的性能，必须满足某些条件：初始数据和最终数据集之间不应相差太大，并且它们必须共享相同的预处理操作。
- en: 'So far, you have seen several examples of how the concepts of transfer learning
    can be applied to real cases. Actually, in practice, transfer learning takes on
    different types: `Inductive Transfer learning`, `Unsupervised Transfer Learning`,
    `Transductive Transfer Learning`, and `Instance Transfer`. We are trying to deepen
    those concepts.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经看到了如何将迁移学习的概念应用于实际案例的几个示例。实际上，在实践中，迁移学习有多种类型：`归纳迁移学习`、`无监督迁移学习`、`归纳推理迁移学习`
    和 `实例迁移学习`。我们正在努力深化这些概念。
- en: To understand the differences between these methodologies, we will look at the
    terms—domains and tasks. By the term **domain**, we mean the type of data that's
    used by the network, while by the term **task**, we mean what the network intends
    to do. We will also use the terms **source** and **destination** to distinguish
    the network that's already trained on a large amount of data from the network
    that we intend to build.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解这些方法之间的差异，我们将查看术语——领域和任务。通过术语**领域**，我们指的是网络使用的类型的数据，而通过术语**任务**，我们指的是网络打算做什么。我们还将使用术语**源**和**目标**来区分已经在大量数据上训练过的网络和我们打算构建的网络。
- en: Inductive transfer learning
  id: totrans-337
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 归纳迁移学习
- en: 'One of the simplest forms of supervised machine learning is `inductive learning`.
    It is based solely on observation. Given an initial set of input-output examples,
    the agent elaborates on hypotheses to reconstruct the transfer function. The agent
    is designed to observe interactions with the outside world. In particular, the
    agent analyzes the feedback of its decisions. The perceptions of the artificial
    agent can be used as follows:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习中最简单的一种形式是`归纳学习`。它完全基于观察。给定一组初始的输入输出示例，智能体通过提出假设来重建迁移函数。智能体被设计用来观察与外部世界的交互。特别是，智能体会分析其决策的反馈。人工智能体的感知可以如下使用：
- en: To make decisions (reactive agent)
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 做出决策（反应性智能体）
- en: To improve the agent's decision-making capacity (machine learning)
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高智能体的决策能力（机器学习）
- en: In `Inductive Transfer Learning` methods, the information that's processed by
    the two networks (the source and destination) is of the same type (images, sounds,
    and so on), while the tasks performed by the networks are different. In this case,
    the purpose of transfer learning is to use the `inductive-bias` that was recovered
    in the training of the source network to improve the performance of the destination
    network. By the term **inductive-bias**, we mean a series of hypotheses concerning
    the distribution of the data that the algorithm recovers in the training phase.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在`归纳迁移学习`方法中，两个网络（源网络和目标网络）处理的信息类型相同（图像、声音等），而网络执行的任务不同。在这种情况下，迁移学习的目的是利用在源网络的训练中恢复的`归纳偏差`来提高目标网络的表现。通过术语**归纳偏差**，我们指的是算法在训练阶段恢复的一系列关于数据分布的假设。
- en: Unsupervised transfer learning
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督迁移学习
- en: In unsupervised transfer learning, the information that's processed by the two
    networks (the source and destination) is of the same type (images, sounds, and
    so on), while the tasks that are performed by the networks are different, like
    in inductive transfer learning. The substantial difference between the two methods
    lies in the fact that no labeled data is available in unsupervised transfer learning.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督迁移学习中，两个网络（源网络和目标网络）处理的信息类型相同（图像、声音等），而网络执行的任务不同，就像归纳迁移学习一样。这两种方法实质性的区别在于无监督迁移学习中没有可用的标记数据。
- en: Transductive transfer learning
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 归纳迁移学习
- en: In transductive transfer learning, the information that's processed by the two
    networks (the source and destination) is different, while the tasks that are performed
    by the networks are similar. This methodology is based on the concept of transductive
    inference, which brings the reasoning from specific (training) cases to specific
    cases (tests). Unlike induction, which requires the solution to a more general
    problem before solving a more specific problem, in transduction, we try to get
    the answer that we really need, but not a more general one.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在归纳迁移学习中，两个网络（源网络和目标网络）处理的信息不同，而网络执行的任务相似。这种方法基于归纳推理的概念，它将推理从特定的（训练）案例带到特定的案例（测试）。与需要先解决更一般的问题再解决更具体问题的归纳不同，在归纳中，我们试图得到我们真正需要的答案，而不是更一般的答案。
- en: Instance transfer learning
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实例迁移学习
- en: A scenario in which the domains of the origin and destination are perfectly
    similar is difficult to find. It is more possible to identify a part of data that
    is better approximating to those of destination but lies in the domain of origin
    which is of a much larger size than the destination one. In instance transfer
    learning, we look for the training samples in the origin domain that have a strong
    correlation with the destination domain. Once they are identified, they are reused
    in the learning phase of the target activity; in this way, the accuracy of the
    classification is improved.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在源域和目标域完全相似的场景中很难找到。更可能的是，找到一部分数据，这部分数据与目标域的数据更接近，但位于源域，而源域的大小远大于目标域。在实例迁移学习中，我们寻找源域中与目标域有强相关性的训练样本。一旦找到，它们将在目标活动的学习阶段被重新使用；这样，分类的准确性就得到了提高。
- en: See also
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: 'Refer to *Global Vectors for Word Representation* (by Jeffrey Pennington, Richard
    Socher, and Christopher D. Manning): [https://www.aclweb.org/anthology/D14-1162](https://www.aclweb.org/anthology/D14-1162)'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考以下文献：《*全局词向量表示*》（作者：Jeffrey Pennington, Richard Socher, 和 Christopher D. Manning）：[https://www.aclweb.org/anthology/D14-1162](https://www.aclweb.org/anthology/D14-1162)
- en: 'Refer to *A Review of Transfer Learning Algorithms* (by Mohsen Kaboli): [https://hal.archives-ouvertes.fr/hal-01575126/document](https://hal.archives-ouvertes.fr/hal-01575126/document)'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考以下文献：《*迁移学习算法综述*》（作者：Mohsen Kaboli）：[https://hal.archives-ouvertes.fr/hal-01575126/document](https://hal.archives-ouvertes.fr/hal-01575126/document)
