- en: Heterogeneous Ensemble Classifiers Using H2O
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用H2O的异构集成分类器
- en: 'In this chapter, we will cover the following recipe:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下食谱：
- en: Predicting credit card defaulters using heterogeneous ensemble classifiers
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用异构集成分类器预测信用卡违约者
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: In this chapter, we'll showcase how to build heterogeneous ensemble classifier
    using H2O, which is an open source, distributed, in-memory, machine learning platform. There
    are a host of supervised and unsupervised algorithms available in H2O.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将展示如何使用H2O构建异构集成分类器，H2O是一个开源的、分布式的、内存中的机器学习平台。H2O中提供了大量的监督和无监督算法。
- en: Among the supervised algorithms, H2O provides us with neural networks, random
    forest (RF), generalized linear models, a Gradient-Boosting Machine, a naive Bayes
    classifier, and XGBoost.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督算法中，H2O为我们提供了神经网络、随机森林（RF）、广义线性模型、梯度提升机、朴素贝叶斯分类器和XGBoost。
- en: H2O also provides us with a stacked ensemble method that aims to find the optimal
    combination of a collection of predictive algorithms using the stacking process.
    H2O's stacked ensemble supports both regression and classification.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: H2O还为我们提供了一个旨在通过堆叠过程找到一组预测算法最佳组合的堆叠集成方法。H2O的堆叠集成支持回归和分类。
- en: Predicting credit card defaulters using heterogeneous ensemble classifiers
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用异构集成分类器预测信用卡违约者
- en: We will use Taiwan's credit card payment defaulters data as an example. This
    is the same dataset we used earlier, in [Chapter 3](6a5a73fc-dba9-4903-a54a-6c79a8ee57b4.xhtml),
    *Resampling Methods*, to build a logistic regression model. In this recipe, we'll
    build multiple models using different algorithms, and finally, build a stacked
    ensemble model.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以台湾的信用卡支付违约者数据为例。这是我们之前在[第3章](6a5a73fc-dba9-4903-a54a-6c79a8ee57b4.xhtml)，“重采样方法”中使用的相同数据集，用于构建逻辑回归模型。在本食谱中，我们将使用不同的算法构建多个模型，并最终构建一个堆叠集成模型。
- en: This dataset contains information about credit card clients in Taiwan. This
    includes information to do with payment defaulters, customers' demographic factors,
    their credit data, and their payment history. The dataset is provided in GitHub.
    It is also available from its main source, the UCI ML Repository:[ https://bit.ly/2EZX6IC](https://bit.ly/2EZX6IC).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集包含有关台湾信用卡客户的信息。这包括有关支付违约者、客户的人口统计因素、他们的信用数据和他们的支付历史信息。数据集可在GitHub上找到。它也可以从其主要来源UCI
    ML存储库获得：[https://bit.ly/2EZX6IC](https://bit.ly/2EZX6IC)。
- en: 'In our example, we''ll use the following supervised algorithms from H2O to
    build our models:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们将使用以下来自H2O的监督算法来构建我们的模型：
- en: Generalized linear model
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广义线性模型
- en: Distributed random forest
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式随机森林
- en: Gradient-boosting machine
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度提升机
- en: Stacked ensemble
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆叠集成
- en: We'll see how to use these algorithms in Python and learn how to set some of
    the hyperparameters for each of the algorithms.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将了解如何在Python中使用这些算法，并学习如何为每个算法设置一些超参数。
- en: Getting ready
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We'll use Google Colab to build our model. In [Chapter 10](0d0517ac-d372-478f-ba6a-4ad4828b81a0.xhtml),
    *Heterogeneous Ensemble Classifiers Using H2O**,* we explained how to use Google
    Colaboratory in the *There's more* section.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Google Colab来构建我们的模型。在[第10章](0d0517ac-d372-478f-ba6a-4ad4828b81a0.xhtml)，“使用H2O的异构集成分类器”，我们在“更多内容”部分解释了如何使用Google
    Colaboratory。
- en: 'We''ll start by installing H2O in Google Colab as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先按照以下步骤在Google Colab中安装H2O：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Executing the preceding command will show you a few instructions, with the
    final line showing the following message (the version number of H2O will be different
    depending on the latest version available):'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 执行前面的命令将显示一些指令，最后一行将显示以下消息（H2O的版本号将根据最新版本而有所不同）：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We import all the required libraries, as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照以下方式导入所有必需的库：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We''ll then initialize H2O:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将初始化H2O：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Upon successful initialization, we''ll see the information shown in the following screenshot.
    This information might be different, depending on the environment:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功初始化后，我们将看到以下截图所示的信息。这些信息可能因环境而异：
- en: '![](img/882ed571-c8ba-4490-a404-f16e26aabade.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/882ed571-c8ba-4490-a404-f16e26aabade.png)'
- en: 'We''ll read our dataset from Google Drive. In order to do this, we first need
    to mount the drive:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从Google Drive读取我们的数据集。为了做到这一点，我们首先需要挂载驱动器：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'It will instruct you to go to a URL to get the authorization code. You''ll
    need to click on the URL, copy the authorization code, and paste it. Upon successful
    mounting, you can read your file from the respective folder in Google Drive:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 它将指导你访问一个 URL 以获取授权代码。你需要点击该 URL，复制授权代码，并将其粘贴。在成功挂载后，你可以从 Google Drive 的相应文件夹中读取你的文件：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note that with `h2o.import_file`, we create `h2o.frame.H2OFrame`. This is similar
    to a `pandas` DataFrame. However, in the case of a `pandas` DataFrame, the data
    is held in the memory, while in this case, the data is located on an H2O cluster.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，使用 `h2o.import_file`，我们创建 `h2o.frame.H2OFrame`。这与 `pandas` DataFrame 类似。然而，在
    `pandas` DataFrame 的情况下，数据存储在内存中，而在这个案例中，数据位于 H2O 集群上。
- en: 'You can run similar methods on an H2O DataFrame as you can on pandas. For example,
    in order to see the first 10 observations in the DataFrame, you can use the following
    command:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 H2O DataFrame 上运行与在 pandas 上类似的方法。例如，为了查看 DataFrame 中的前 10 个观测值，你可以使用以下命令：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To check the dimensions of the DataFrame, we use the following command:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查 DataFrame 的维度，我们使用以下命令：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In order to see all the column names, we run the following syntax:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了查看所有列名，我们运行以下语法：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the `pandas` DataFrame, we used `dtypes` to see the datatypes of each column.
    In the H2o DataFrame, we would use the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `pandas` DataFrame 中，我们使用 `dtypes` 来查看每列的数据类型。在 H2o DataFrame 中，我们会使用以下：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This gives us the following output. Note that the categorical variables appear
    as `''enum''`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下输出。请注意，分类变量以 `'enum'` 的形式出现：
- en: '![](img/937331c5-ec80-4367-add7-ab7fd1c2be27.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/937331c5-ec80-4367-add7-ab7fd1c2be27.png)'
- en: 'We have our target variable, `default.payment.next.month`, in the dataset.
    This tells us which customers have and have not defaulted on their payments. We
    want to see the distribution of the defaulters and non-defaulters:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在数据集中有目标变量 `default.payment.next.month`。这告诉我们哪些客户已经违约或未违约。我们想看到违约者和非违约者的分布：
- en: '[PRE10]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This gives us the count of each class in the `default.payment.next.month` variable:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了 `default.payment.next.month` 变量中每个类别的计数：
- en: '![](img/4a2cdc5f-076e-4b13-bf8e-c0ef7bc4b80d.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4a2cdc5f-076e-4b13-bf8e-c0ef7bc4b80d.png)'
- en: 'We don''t need the `ID` column for predictive modeling, so we remove it from
    our DataFrame:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要 `ID` 列进行预测建模，所以我们将其从 DataFrame 中删除：
- en: '[PRE11]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can see the distribution of the numeric variables using the `hist()` method:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `hist()` 方法查看数值变量的分布：
- en: '[PRE12]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following screenshot shows us the plotted variables . This can help us
    in our analysis of each of the variables:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的屏幕截图显示了绘制的变量。这可以帮助我们分析每个变量：
- en: '![](img/23b6773e-bf76-460b-9529-95a123315127.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/23b6773e-bf76-460b-9529-95a123315127.png)'
- en: 'To extend our analysis, we can see the distribution of defaulters and non-defaulters
    by gender, education, and marital status:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了扩展我们的分析，我们可以通过性别、教育和婚姻状况查看违约者和非违约者的分布：
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In the following screenshot, we get to see the distribution of defaulters by
    different categories:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图中，我们可以看到不同类别的违约者分布：
- en: '![](img/6bae3882-f108-4d74-8219-38c232dbe93f.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6bae3882-f108-4d74-8219-38c232dbe93f.png)'
- en: 'We''ll now convert the categorical variables into factors:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将分类变量转换为因子：
- en: '[PRE14]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We also encode the dichotomous target variable, `default.payment.next.month`,
    as a factor variable. After the conversion, we check the classes of the target
    variable with the `levels()` method:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将二元目标变量 `default.payment.next.month` 编码为因子变量。转换后，我们使用 `levels()` 方法检查目标变量的类别：
- en: '[PRE15]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We''ll then define our predictor and target variables:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将定义我们的预测变量和目标变量：
- en: '[PRE16]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We then split our DataFrame using the `split_frame()` method:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用 `split_frame()` 方法分割我们的 DataFrame：
- en: '[PRE17]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following code gives us two split output:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码给出了两个分割输出：
- en: '[PRE18]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'In the following screenshot, we get to see the following two splits:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图中，我们可以看到以下两个分割：
- en: '![](img/0c3138ad-28b8-46f5-b7d6-9d1ef46803f4.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0c3138ad-28b8-46f5-b7d6-9d1ef46803f4.png)'
- en: 'We separate the splits into train and test subsets:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分割分为训练和测试子集：
- en: '[PRE19]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: How to do it...
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s move on to training our models using the algorithms we mentioned earlier
    in this chapter. We''ll start by training our **generalized linear model** (**GLM**)
    models. We''ll build three GLM models:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用本章前面提到的算法来训练我们的模型。我们将首先训练我们的 **广义线性模型**（**GLM**）模型。我们将构建三个 GLM 模型：
- en: A GLM model with default values for the parameters
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有默认参数值的 GLM 模型
- en: A GLM model with Lambda search (regularization)
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有 Lambda 搜索（正则化）的 GLM 模型
- en: A GLM model with grid search
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有网格搜索的 GLM 模型
- en: Now we will start with training our models in the following section.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将在下一节开始训练我们的模型。
- en: 'Let''s train our first model:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们训练我们的第一个模型：
- en: '[PRE20]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '`H2OGeneralizedLinearEstimator` fits a generalized linear model. It takes in
    a response variable and a set of predictor variables.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`H2OGeneralizedLinearEstimator`拟合一个广义线性模型。它接受一个响应变量和一组预测变量。'
- en: '`H2OGeneralizedLinearEstimator` can handle both regression and classification
    tasks. In the case of a regression problem, it returns an `H2ORegressionModel` subclass,
    while for classification, it returns an `H2OBinomialModel` subclass.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`H2OGeneralizedLinearEstimator`可以处理回归和分类任务。在回归问题的情况下，它返回一个`H2ORegressionModel`子类，而对于分类，它返回一个`H2OBinomialModel`子类。'
- en: 'We created predictor and target variables in the *Getting ready* section. Pass
    the predictor and target variables to the model:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在“准备就绪”部分创建了预测变量和目标变量。将预测变量和目标变量传递给模型：
- en: '[PRE21]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Train the GLM model using the `lambda_search` parameter:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`lambda_search`参数训练GLM模型：
- en: '[PRE22]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '`lambda_search` helps the GLM to find an optimal regularization parameter,
    λ. The `lambda_search` parameter takes in a Boolean value. When set to `True`,
    the GLM will first fit a model with the highest lambda value, which is known as
    **maximum regularization**. It then decreases this at each step until it reaches
    the minimum lambda. The resulting optimum model is based on the best lambda value.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`lambda_search`帮助GLM找到最优的正则化参数λ。`lambda_search`参数接受一个布尔值。当设置为`True`时，GLM将首先拟合一个具有最高λ值的模型，这被称为**最大正则化**。然后它将逐步降低λ值，直到达到最小λ值。得到的最佳模型基于最佳的λ值。'
- en: 'Train the model using the GLM with a grid search:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用GLM和网格搜索训练模型：
- en: '[PRE23]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We get the grid result sorted by the `auc` value with the `get_grid()` method:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`get_grid()`方法按`auc`值排序网格结果：
- en: '[PRE24]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In the following screenshot, we can see the `auc` score for each model, which
    consists of different combinations of the `alpha` and `lambda` parameters:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下屏幕截图中，我们可以看到每个模型的`auc`分数，它由不同的`alpha`和`lambda`参数组合而成：
- en: '![](img/f4209530-ce0e-440d-ab7a-85f54f11e2e6.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f4209530-ce0e-440d-ab7a-85f54f11e2e6.png)'
- en: 'We can see the model metrics on our train data and our cross-validation data:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到我们的训练数据和交叉验证数据上的模型指标：
- en: '[PRE25]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: From the preceding code block, you can evaluate the model metrics, which include
    `MSE`, `RMSE`, `Null` and `Residual Deviance`, `AUC`, and `Gini`, along with the
    `Confusion Matrix`. At a later stage, we will use the best model from the grid
    search for our stacked ensemble.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码块中，您可以评估模型指标，包括`MSE`、`RMSE`、`Null`和`Residual Deviance`、`AUC`、`Gini`以及`Confusion
    Matrix`。在稍后的阶段，我们将使用网格搜索中的最佳模型进行我们的堆叠集成。
- en: 'Let us look at the following image and evaluate the model metrics:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下以下图像并评估模型指标：
- en: '![](img/f2e1b50c-c083-4d8c-a17b-37ff57893a35.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f2e1b50c-c083-4d8c-a17b-37ff57893a35.png)'
- en: 'Train the model using random forest. The code for random forest using default
    settings looks as follows:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用随机森林训练模型。使用默认设置的随机森林代码如下：
- en: '[PRE26]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To get the summary output of the model, use the following code:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要获取模型的摘要输出，请使用以下代码：
- en: '[PRE27]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Train the random forest model using a grid search. Set the hyperparameters
    as shown in the following code block:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网格搜索训练随机森林模型。将超参数设置如下所示：
- en: '[PRE28]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Use the hyperparameters on `H2OGridSearch()` to train the `RF` model using
    `gridsearch`:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`H2OGridSearch()`上的超参数使用`gridsearch`训练`RF`模型：
- en: '[PRE29]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Sort the results by AUC score to see which model performs best:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按AUC分数排序结果以查看哪个模型表现最佳：
- en: '[PRE30]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Extract the best model from the grid search result:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从网格搜索结果中提取最佳模型：
- en: '[PRE31]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'In the following screenshot, we see the model metrics for the grid model on
    the train data and the cross-validation data:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下屏幕截图中，我们可以看到网格模型在训练数据和交叉验证数据上的模型指标：
- en: '![](img/960c92f8-db18-427d-a08a-ee1a3750b8d7.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/960c92f8-db18-427d-a08a-ee1a3750b8d7.png)'
- en: 'Train the model using GBM. Here''s how to train a GBM with the default settings:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用GBM训练模型。以下是使用默认设置训练GBM的方法：
- en: '[PRE32]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Use a grid search on the GBM. To perform a grid search, set the hyperparameters
    as follows:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在GBM上使用网格搜索。要执行网格搜索，请设置以下超参数：
- en: '[PRE33]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Use the hyperparameters on `H2OGridSearch()` to train the GBM model using grid
    search:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`H2OGridSearch()`上的超参数使用网格搜索训练GBM模型：
- en: '[PRE34]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'As with the earlier models, we can view the results sorted by AUC:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与早期模型一样，我们可以按AUC排序查看结果：
- en: '[PRE35]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Extract the best model from the grid search:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从网格搜索中提取最佳模型：
- en: '[PRE36]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We can use `H2OStackedEnsembleEstimator` to build a stacked ensemble ML model
    that can use the models we have built using H2O algorithms to improve the predictive
    performance. `H2OStackedEnsembleEstimator` helps us find the optimal combination
    of a collection of predictive algorithms.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`H2OStackedEnsembleEstimator`构建一个堆叠集成ML模型，该模型可以使用我们使用H2O算法构建的模型来提高预测性能。`H2OStackedEnsembleEstimator`帮助我们找到一组预测算法的最佳组合。
- en: 'Create a list of the best models from the earlier models that we built using
    grid search:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个列表，包含我们使用网格搜索构建的早期模型的最佳模型：
- en: '[PRE37]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Set up a stacked ensemble model using `H2OStackedEnsembleEstimator`:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`H2OStackedEnsembleEstimator`设置堆叠集成模型：
- en: '[PRE38]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Evaluate the ensemble performance on the test data:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试数据上评估集成性能：
- en: '[PRE39]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Compare the performance of the base learners on the `test` data. The following
    code tests the model performance of all the GLM models we''ve built:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`test`数据上比较基学习器的性能。以下代码测试了我们构建的所有GLM模型的表现：
- en: '[PRE40]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The following code tests the model performance of all the random forest models
    we''ve built:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码测试了我们构建的所有随机森林模型的表现：
- en: '[PRE41]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The following code tests the model performance of all the GBM models we''ve
    built:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码测试了我们构建的所有GBM模型的表现：
- en: '[PRE42]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'To get the best AUC from the base learners, execute the following commands:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从基学习器中获得最佳的AUC，请执行以下命令：
- en: '[PRE43]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The following commands show the AUC from the stacked ensemble model:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下命令显示了堆叠集成模型的AUC：
- en: '[PRE44]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: How it works...
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: We used Google Colab to train our models. After we installed H2O in Google Colab,
    we initialized the H2O instance. We also imported the required libraries.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Google Colab来训练我们的模型。在我们在Google Colab中安装H2O之后，我们初始化了H2O实例。我们还导入了所需的库。
- en: In order to use the H2O libraries, we imported `H2OGeneralizedLinearEstimator`,
    `H2ORandomForestEstimator`, and `H2OGradientBoostingEstimator` from `h2o.estimators`.
    We also imported `H2OStackedEnsembleEstimator` to train our model using a stacked
    ensemble.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用H2O库，我们从`h2o.estimators`中导入了`H2OGeneralizedLinearEstimator`、`H2ORandomForestEstimator`和`H2OGradientBoostingEstimator`。我们还导入了`H2OStackedEnsembleEstimator`，以使用堆叠集成训练我们的模型。
- en: We mounted Google Drive and read our dataset using `h2o.import_file()`. This
    created an H2O DataFrame, which is very similar to a `pandas` DataFrame. Instead
    of holding it in the memory, however, the data is located in one of the remote
    H2O clusters.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们挂载了Google Drive并使用`h2o.import_file()`读取我们的数据集。这创建了一个H2O DataFrame，它与`pandas`
    DataFrame非常相似。然而，数据不是存储在内存中，而是在远程H2O集群中的一个位置。
- en: We then performed basic operations on the H2O DataFrame to analyze our data.
    We took a look at the dimensions, the top few rows, and the data types of each
    column. The `shape` attribute returned a tuple with the number of rows and columns.
    The `head()` method returned the top 10 observations. The `types` attribute returned
    the data types of each column.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们对H2O DataFrame进行了基本操作以分析我们的数据。我们查看维度、前几行以及每列的数据类型。`shape`属性返回一个包含行数和列数的元组。`head()`方法返回前10个观测值。`types`属性返回每列的数据类型。
- en: Note that a categorical variable in an H2O DataFrame is marked as an `enum`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，H2O DataFrame中的分类变量被标记为`enum`。
- en: Our target variable was `default.payment.next.month`. With the `table()` method,
    we saw the distribution of both classes of our target variable. The `table()`
    method returned the count for classes `1` and `0` in this case.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标变量是`default.payment.next.month`。使用`table()`方法，我们看到了目标变量两个类的分布。在这种情况下，`table()`方法返回了类`1`和`0`的计数。
- en: We didn't need the `ID` column, so we removed it using the `drop()` method with `axis=1` as
    a parameter. With `axis=1`, it dropped the columns. Otherwise, the default value
    of `axis=0` would have dropped the labels from the index.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要`ID`列，因此使用带有`axis=1`参数的`drop()`方法将其删除。使用`axis=1`，它删除了列。否则，`axis=0`的默认值将删除索引中的标签。
- en: We analyzed the distribution of the numeric variables. There's no limit to how
    far you can explore your data. We also saw the distribution of both of the classes
    of our target variable by various categories, such as gender, education, and marriage.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分析了数值变量的分布。你可以探索数据到任何程度。我们还通过性别、教育、婚姻等各种类别看到了目标变量两个类的分布。
- en: We then converted the categorical variables to factor type with the `asfactor()`
    method. This was done for the target variable as well.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`asfactor()`方法将分类变量转换为因子类型。这也适用于目标变量。
- en: We created a list of predictor variables and target variables. We split our
    DataFrame into the train and test subsets with the `split_frame()` method.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个预测变量列表和目标变量列表。我们使用`split_frame()`方法将我们的DataFrame拆分为训练集和测试集。
- en: We passed ratios to the `split_frame()` method. In our case, we split the dataset
    into 70% and 30%. However, note that this didn't give an exact split of 70%-30%.
    H2O uses a probabilistic splitting method instead of using the exact ratios to
    split the dataset. This is to make the split more efficient on big data.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将比率传递给`split_frame()`方法。在我们的例子中，我们将数据集拆分为70%和30%。然而，请注意，这并没有给出精确的70%-30%拆分。H2O使用概率拆分方法而不是使用精确比率来拆分数据集。这是为了使在大数据上的拆分更加高效。
- en: After we split our datasets into train and test subsets, we moved onto training
    our models. We used GLM, random forest, a **gradient-boosting machine** (**GBM**),
    and stacked ensembles to train the stacking model.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将数据集拆分为训练集和测试集之后，我们开始训练我们的模型。我们使用了GLM、随机森林、**梯度提升机**（**GBM**）和堆叠集成来训练堆叠模型。
- en: In the *How to do it...* section, in *Step 1* and *Step 2*, we showcased the
    code to train a GLM model with the default settings. We used cross-validation
    to train our model.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在*如何做...*部分，在*步骤 1*和*步骤 2*中，我们展示了使用默认设置训练GLM模型的代码。我们使用交叉验证来训练我们的模型。
- en: In *Step 3*, we trained a GLM model with `lambda_search`, which helps to find
    the optimal regularization parameter.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 3*中，我们使用`lambda_search`训练了一个GLM模型，这有助于找到最佳的正则化参数。
- en: In *Step 4*, we used grid-search parameters to train our GLM model. We set our
    hyper-parameters and provided these to the `H2OGridSearch()` method. This helps
    us search for the optimum parameters across models. In the `H2OGridSearch()` method,
    we used the `RandomDiscrete` search-criteria strategy.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 4*中，我们使用网格搜索参数来训练我们的GLM模型。我们设置了超参数并将它们提供给`H2OGridSearch()`方法。这有助于我们在模型之间搜索最佳参数。在`H2OGridSearch()`方法中，我们使用了`RandomDiscrete`搜索标准策略。
- en: The default search-criteria strategy is Cartesian, which covers the entire space
    of hyperparameter combinations. The random discrete strategy carries out a random
    search of all the combinations of the hyperparameters provided.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的搜索标准策略是笛卡尔，它涵盖了超参数组合的全部空间。随机离散策略执行所有提供的超参数组合的随机搜索。
- en: In *Step 5*, with the `get_grid()` method, we looked at the AUC score of each
    model built with different combinations of the parameters provided. In *Step 6*,
    we extracted the `best` model from the random grid search. We can also use the
    `print()` method on the best model to see the model performance metrics on both
    the train data and the cross-validation data.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 5*中，通过`get_grid()`方法，我们查看使用提供的参数的不同组合构建的每个模型的AUC分数。在*步骤 6*中，我们从随机网格搜索中提取了`最佳`模型。我们还可以在最佳模型上使用`print()`方法来查看模型在训练数据和交叉验证数据上的性能指标。
- en: In *Step 7*, we trained a random forest model with default settings and looked
    at the summary of the resulting model in step 8\. In *Step 9* and *Step 10*, we
    showcased the code to train a random forest model using grid-search. We set multiple
    values for various acceptable hyper-parameters, such as `sample_rate`, `col_sample_rate_per_tree`,
    `max_depth`, and `ntrees`. `sample_rate` refers to row sampling without replacement.
    It takes a value between `0` and `1`, indicating the sampling percentage of the
    data. `col_sample_rate_per_tree` is the column sampling for each tree without
    replacement. `max_depth` is set to specify the maximum depth to which each tree
    should be built. Deeper trees may perform better on the training data but will
    take more computing time and may overfit and fail to generalize on unseen data. The
    `ntrees` parameter is used for tree-based algorithms to specify the number of
    trees to build on the model.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 7*中，我们使用默认设置训练了一个随机森林模型，并在步骤 8 中查看结果的模型摘要。在*步骤 9*和*步骤 10*中，我们展示了使用网格搜索训练随机森林模型的代码。我们为各种可接受的超参数设置了多个值，例如`sample_rate`、`col_sample_rate_per_tree`、`max_depth`和`ntrees`。`sample_rate`指的是不重复的行采样。它的值在`0`和`1`之间，表示数据的采样百分比。`col_sample_rate_per_tree`是每个树的不重复列采样。`max_depth`用于指定每个树应构建的最大深度。更深的树可能在训练数据上表现更好，但将花费更多计算时间，并且可能过拟合，无法泛化到未见过的数据。`ntrees`参数用于基于树的算法，用于指定在模型上构建的树的数量。
- en: In *Step 11* and *Step 12*, we printed the AUC score of each model generated
    by the grid-search and extracted the best model from it.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 11*和*步骤 12*中，我们打印了由网格搜索生成的每个模型的AUC分数，并从中提取了最佳模型。
- en: We also trained GBM models to fit our data. In *Step 13*, we built the GBM using
    the default settings. In *Step 14*, we set the hyperparameter space for the grid
    search. We used this in *Step 15*, where we trained our GBM. In the GBM, we set
    values for hyperparameters, such as `learn_rate`, `sample_rate`, `col_sample_rate`,
    `max_depth`, and `ntrees`. The `learn_rate` parameter is used to specify the rate
    at which the GBM algorithm trains the model. A lower value for the `learn_rate`
    parameter is better and can help in avoiding overfitting, but can be costly in
    terms of computing time.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还训练了GBM模型来拟合我们的数据。在第13步中，我们使用默认设置构建了GBM。在第14步中，我们为网格搜索设置了超参数空间。我们在第15步中使用了它，在那里我们训练了我们的GBM。在GBM中，我们为超参数设置了值，例如`learn_rate`、`sample_rate`、`col_sample_rate`、`max_depth`和`ntrees`。`learn_rate`参数用于指定GBM算法训练模型的速度。较低的`learn_rate`参数值更好，可以帮助避免过拟合，但可能会在计算时间上付出代价。
- en: In H2O, `learn_rate` is available in GBM and XGBoost.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在H2O中，`learn_rate`在GBM和XGBoost中可用。
- en: '*Step 16* showed us the AUC score of each resulting model from the grid search.
    We extracted the best grid-searched GBM in *Step 17*.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 第16步显示了网格搜索产生的每个模型的AUC分数。我们在第17步中提取了最佳的网格搜索GBM。
- en: In *Step 18* through to *Step 20*, we trained our stacked ensemble model using `H2OStackedEnsembleEstimator`
    from H2O. We evaluated the performance of the resulting model on the test data.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在第18步到第20步中，我们使用H2O的`H2OStackedEnsembleEstimator`训练了我们的堆叠集成模型。我们在测试数据上评估了所得模型的性能。
- en: In S*tep 21*, we evaluated all the GLM models we built on our test data. We
    did the same with all the models we trained using RF and GBM. *Step 22* gave us
    the model with the maximum AUC score. In *Step 23*, we evaluated the AUC score
    of the stacked ensemble model on the test data in order to compare the performance
    of the stacked ensemble model with the individual base learners.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在第21步中，我们评估了我们构建的所有GLM模型在测试数据上的表现。我们用RF和GBM训练的所有模型也做了同样的事情。在第22步中，我们得到了AUC分数最高的模型。在第23步中，我们评估了堆叠集成模型在测试数据上的AUC分数，以便比较堆叠集成模型与单个基础学习器的性能。
- en: There's more...
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Note that we used cross-validation to train all our models. We used the `nfolds`
    option to set the number of folds to use for cross-validation. In our example,
    we used `nfolds=5`, but we can also set it to higher numbers.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用了交叉验证来训练所有模型。我们使用`nfolds`选项来设置用于交叉验证的折数。在我们的例子中，我们使用了`nfolds=5`，但我们也可以将其设置为更高的数字。
- en: The number of folds needs to be the same across every models you build.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 每个构建的模型中折数需要相同。
- en: With a value for `nfolds` specified, we can also provide a value for the `fold_assignment`
    parameters. `fold_assignment` takes values such as `auto`, `random`, `modulo`,
    and `stratified`. If we set it to `Auto`, the algorithm automatically chooses
    an option; currently, it chooses `Random`. With `fold_assignment` set to `Random`,
    it will enable a random split of the data into `nfolds` sets. When `fold_assignment` is
    set to `Modulo`, it uses a deterministic method to evenly split the data into
    `nfolds` that don't depend on the `seed` parameter.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 指定了`nfolds`的值后，我们还可以为`fold_assignment`参数提供一个值。`fold_assignment`可以取`auto`、`random`、`modulo`和`stratified`等值。如果我们将其设置为`Auto`，算法将自动选择一个选项；目前，它选择`Random`。将`fold_assignment`设置为`Random`将启用将数据随机分割成`nfolds`个集合。当`fold_assignment`设置为`Modulo`时，它使用确定性方法将数据均匀分割成`nfolds`，这些`nfolds`不依赖于`seed`参数。
- en: When we use cross-validation method to build models, ensure that you specify
    a `seed` value for all models or use `fold_assignment="Modulo"`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用交叉验证方法构建模型时，确保您为所有模型指定一个`seed`值或使用`fold_assignment="Modulo"`。
- en: 'In grid search, we used two parameters: `stopping_metric` and `stopping_rounds`.
    These parameters are available for GBM and random forest algorithms, but they
    aren''t available for GLM. `stopping_metric` specifies the metric to consider
    when early stopping is specified, which can be done by setting `stopping_rounds`
    to a value greater than zero.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在网格搜索中，我们使用了两个参数：`stopping_metric`和`stopping_rounds`。这些参数适用于GBM和随机森林算法，但不适用于GLM。`stopping_metric`指定了在指定提前停止时考虑的指标，这可以通过将`stopping_rounds`设置为一个大于零的值来实现。
- en: In our examples, we set `stopping_metric` to AUC and `stopping_rounds` to five.
    This means that the algorithm will measure the AUC before it stops training any
    further if the AUC doesn't improve in the specified number of rounds, which is
    five in our case.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们将`stopping_metric`设置为AUC，将`stopping_rounds`设置为五。这意味着如果AUC在指定的轮次（在我们的例子中是五轮）内没有改善，算法将测量AUC并在进一步训练之前停止。
- en: If `stopping_metric` is specified, `stopping_rounds` must be set as well. When `stopping_tolerance` is
    also set, the model will stop training after reaching the number of rounds mentioned
    in `stopping_rounds` if the model's `stopping_metric` doesn't improve by the `stopping_tolerance`
    value.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如果指定了`stopping_metric`，则必须设置`stopping_rounds`。当也设置了`stopping_tolerance`时，如果模型的`stopping_metric`没有通过`stopping_tolerance`值改善，模型将在达到`stopping_rounds`中提到的轮数后停止训练。
- en: See also
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The H2O documentation is available at [http://docs.h2o.ai/](http://docs.h2o.ai/).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: H2O文档可在[http://docs.h2o.ai/](http://docs.h2o.ai/)找到。
