- en: '16'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '16'
- en: Photorealism in Computer Vision
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉中的逼真度
- en: In this chapter, you will learn why we need photorealistic synthetic data in
    computer vision. Then, you will explore the main approaches to generating photorealistic
    synthetic data. After that, you will comprehend the main challenges and limitations.
    Although this chapter focuses on computer vision, the discussion can be generalized
    to other domains and applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解为什么在计算机视觉中需要逼真合成数据。然后，您将探索生成逼真合成数据的主要方法。之后，您将理解主要挑战和限制。尽管本章侧重于计算机视觉，但讨论可以推广到其他领域和应用。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Synthetic data photorealism for computer vision
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机视觉中的合成数据逼真度
- en: Photorealism approaches
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逼真度方法
- en: Photorealism evaluation metrics
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逼真度评估指标
- en: Challenges and limitations of photorealistic synthetic data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逼真合成数据面临的挑战和限制
- en: Synthetic data photorealism for computer vision
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉中的合成数据逼真度
- en: 'In this section, you will learn why photorealism is essential in computer vision.
    Photorealism of synthetic data is one of the main factors that mitigates the domain
    gap between real and synthetic data. Thus, training computer vision models on
    photorealistic synthetic data improves the performance of these models on real
    data. For more details, please refer to *Hypersim: A Photorealistic Synthetic
    Dataset for Holistic Indoor Scene Understanding* ([https://arxiv.org/abs/2011.02523](https://arxiv.org/abs/2011.02523))
    and *A Review of Synthetic Image Data and Its Use in Computer Vision* ([https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9698631](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9698631)).
    Additionally, synthetic data can be used to evaluate computer vision algorithms.
    However, evaluating these models on non-photorealistic synthetic data may cause
    these models to show poor performance not because of the challenging nature of
    the test scenarios but because of the domain gap itself. Thus, photorealistic
    synthetic data is essential to effectively train and accurately evaluate ML models.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，您将了解为什么逼真度在计算机视觉中至关重要。合成数据的逼真度是缓解真实和合成数据之间领域差距的主要因素之一。因此，在逼真合成数据上训练计算机视觉模型可以提高这些模型在真实数据上的性能。更多详情请参阅
    *Hypersim: A Photorealistic Synthetic Dataset for Holistic Indoor Scene Understanding*
    ([https://arxiv.org/abs/2011.02523](https://arxiv.org/abs/2011.02523)) 和 *A Review
    of Synthetic Image Data and Its Use in Computer Vision* ([https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9698631](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9698631))。此外，合成数据可以用来评估计算机视觉算法。然而，在非逼真合成数据上评估这些模型可能会导致这些模型表现出较差的性能，这并非因为测试场景的挑战性质，而是因为领域差距本身。因此，逼真合成数据对于有效地训练和准确评估机器学习模型至关重要。'
- en: Now, let us discuss the main benefits of utilizing photorealistic synthetic
    data. First, let us delve into feature extraction.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论利用逼真合成数据的主要好处。首先，让我们深入了解特征提取。
- en: Feature extraction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征提取
- en: Computer vision algorithms usually rely on automatic feature extraction, which
    is learned in the training stage. ML models learn how to identify the most reliable
    and discriminative features and patterns, which subsequent submodules leverage
    to learn the actual task, such as semantic segmentation, depth estimation, and
    visual object tracking. Training your computer vision model on non-photorealistic
    synthetic data that oversimplifies the real world will lead to inappropriate feature
    extraction. Conversely, photorealistic synthetic data helps the ML model to learn
    how to extract discriminative features. Thus, the ML model will perform well in
    the real world. This is because realistic data helps ML models to better understand
    the relationship between scene elements, how they affect each other, and how they
    contribute to the task being learned.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉算法通常依赖于在训练阶段学习的自动特征提取。机器学习模型学习如何识别最可靠和具有判别性的特征和模式，后续子模块利用这些特征和模式来学习实际任务，例如语义分割、深度估计和视觉目标跟踪。在非逼真合成数据上训练您的计算机视觉模型，这些数据过度简化了现实世界，会导致不适当的特征提取。相反，逼真合成数据帮助机器学习模型学习如何提取判别性特征。因此，机器学习模型将在现实世界中表现良好。这是因为真实数据帮助机器学习模型更好地理解场景元素之间的关系，它们如何相互影响，以及它们如何有助于正在学习的任务。
- en: Domain gap
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 领域差距
- en: Photorealistic synthetic data mitigates the domain gap between synthetic and
    real domains. The main reason is that realistic data partially resamples the real
    data, which helps computer vision models to be trained on data that is closer
    to the environment where the model will be deployed in practice. Thus, the model
    can still generalize well from the synthetic data learned in the training stage.
    On the other hand, large-scale, diverse, but non-realistic synthetic data may
    enlarge the domain gap and significantly hinder the performance.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 真实感合成数据缓解了合成域和真实域之间的领域差距。主要原因在于真实数据部分重采样了真实数据，这有助于计算机视觉模型在更接近模型实际部署环境的训练数据上训练。因此，模型可以从训练阶段学习的合成数据中很好地泛化。另一方面，大规模、多样但非真实感的合成数据可能会扩大领域差距并显著阻碍性能。
- en: Robustness
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 坚韧性
- en: Creating simulators that simulate realistic lighting, textures, shaders, animations,
    and camera movements enables researchers to generate large-scale and diverse synthetic
    training datasets that properly reflect the challenges and varieties in the real
    world. Thus, computer vision algorithms can be trained on more real scenarios
    to learn how to adapt to the actual complexities of the real world. This is important
    to make computer vision algorithms more robust in the real world where collecting
    real data is extremely expensive or not applicable.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 创建能够模拟真实光照、纹理、着色器、动画和摄像机运动的模拟器，使研究人员能够生成大规模、多样化的合成训练数据集，这些数据集能够恰当地反映现实世界中的挑战和多样性。因此，计算机视觉算法可以在更多真实场景中训练，以学习如何适应现实世界的实际复杂性。这对于使计算机视觉算法在现实世界中更加健壮至关重要，因为在现实世界中收集真实数据可能极其昂贵或不可行。
- en: Benchmarking performance
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能基准测试
- en: Synthetic data provides a more accurate and efficient way to generate the ground
    truth (refer to [*Chapter 5*](B18494_05.xhtml#_idTextAnchor083)). The ground truth
    is essential for assessing ML models’ performance. Photorealistic synthetic data
    enables us to ensure that the performance of synthetic data appropriately reflects
    that expected in the real world. Conversely, non-realistic synthetic data is less
    suitable for accurate evaluation and benchmarking.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据提供了一种更准确、更高效的方式来生成地面真实数据（参考[*第5章*](B18494_05.xhtml#_idTextAnchor083)）。地面真实数据对于评估机器学习模型性能至关重要。真实感合成数据使我们能够确保合成数据的性能适当反映了真实世界中的预期。相反，非真实感合成数据不太适合进行准确评估和基准测试。
- en: Photorealism approaches
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 真实感方法
- en: 'In this section, you will learn about and explore the main approaches usually
    deployed to generate photorealistic synthetic data. We will learn about the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将了解并探索通常用于生成真实感合成数据的主要方法。我们将了解以下内容：
- en: Physically based rendering
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于物理的渲染
- en: Neural style transfer
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经风格迁移
- en: Physically Based Rendering (PBR)
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于物理的渲染（PBR）
- en: The **Physically Based Rendering** (**PBR**) approach is widely used in game
    engines such as *Unity* and *Unreal* to accurately simulate how materials in the
    3D virtual world interact with light. In the real world, this is a complex process,
    thus it requires a significant understanding of optics and many simplifications
    to make these processes applicable to game engines. **Physically based materials**
    are essential to this approach. They resemble how similar materials in the real
    world interact with light. These materials usually have properties and parameters
    that are calculated based on real measurements from real-world materials. The
    properties may include absorption, scattering, and refraction coefficients and
    parameters. It should be noted that the main principle behind PBR is **energy
    conservation**, which means that light energy reflected and scattered by a material
    should not exceed the total incoming or received light energy by this material.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于物理的渲染**（**PBR**）方法在游戏引擎如*Unity*和*Unreal*中得到了广泛应用，用于准确模拟3D虚拟世界中的材料如何与光线相互作用。在现实世界中，这是一个复杂的过程，因此它需要深入了解光学并简化这些过程以适用于游戏引擎。**基于物理的材料**对于这种方法至关重要。它们类似于现实世界中类似材料如何与光线相互作用。这些材料通常具有基于现实世界材料真实测量的属性和参数。这些属性可能包括吸收、散射和折射系数和参数。需要注意的是，PBR背后的主要原则是**能量守恒**，这意味着材料反射和散射的光能不应超过该材料接收到的总入射或接收光能。'
- en: As expected, deploying a photorealistic rendering pipeline will help us to simulate
    and render more accurate and realistic light behaviors and materials. Thus, we
    can generate more photorealistic synthetic data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，部署一个照片真实感渲染管线将帮助我们模拟和渲染更准确和真实的光照和材质行为。因此，我们可以生成更具照片真实感的合成数据。
- en: Neural style transfer
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经风格迁移
- en: '**Neural style transfer** is a well-known technique that transfers an artistic
    style from one image to another while preserving the content of the latter. This
    method can be applied to synthetic datasets to improve their photorealism and
    thus mitigate the domain gap between synthetic and real data. For example, the
    **Sim2Real**-style transfer model can be deployed to bridge the gap between synthetic
    and real data for the task of pose estimation. For more information, please refer
    to *Sim2Real Instance-Level Style Transfer for 6D Pose Estimation* ([https://arxiv.org/abs/2203.02069](https://arxiv.org/abs/2203.02069)).
    Additionally, there are many interesting works that explore how to adapt the *GTA5*
    synthetic dataset (https://www.v7labs.com/open-datasets/gta5), which was generated
    from the *Grand Theft Auto* *V* video game, to the real *Cityscapes* dataset ([https://www.cityscapes-dataset.com](https://www.cityscapes-dataset.com)).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**神经风格迁移**是一种著名的技巧，它可以将一种艺术风格从一个图像转移到另一个图像，同时保留后者的内容。这种方法可以应用于合成数据集，以提高其照片真实感，从而缓解合成数据和真实数据之间的领域差距。例如，**Sim2Real**风格迁移模型可以部署以弥合合成数据和真实数据在姿态估计任务之间的差距。更多信息，请参阅*Sim2Real
    Instance-Level Style Transfer for 6D Pose Estimation* ([https://arxiv.org/abs/2203.02069](https://arxiv.org/abs/2203.02069))。此外，还有许多有趣的研究探讨了如何将来自*Grand
    Theft Auto* *V*电子游戏的合成数据集*GTA5*（https://www.v7labs.com/open-datasets/gta5）适配到真实的*Cityscapes*数据集（[https://www.cityscapes-dataset.com](https://www.cityscapes-dataset.com)）。'
- en: Photorealism evaluation metrics
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 照片真实度评估指标
- en: 'One of the main issues within this subject matter is quantitatively assessing
    the photorealism of the generated synthetic images. In this section, we will explore
    the main metrics usually used. We will explore the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个主题领域中的一个主要问题是定量评估生成的合成图像的照片真实感。在本节中，我们将探讨通常使用的指标。我们将探讨以下内容：
- en: '**Structural Similarity Index** **Measure** (**SSIM**)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构相似性指数** **度量**（**SSIM**）'
- en: '**Learned Perceptual Image Patch** **Similarity** (**LPIPS**)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习感知图像块** **相似度**（**LPIPS**）'
- en: Expert evaluation
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专家评估
- en: Structural Similarity Index Measure (SSIM)
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结构相似性指数度量（SSIM）
- en: 'SSIM is one of the most widely used metrics to measure the structural similarity
    between two images. It was first introduced in the paper titled *Image quality
    assessment: from error visibility to structural similarity* ([https://ieeexplore.ieee.org/document/1284395](https://ieeexplore.ieee.org/document/1284395)).
    The SSIM metric does not compare individual pixels of the two images. However,
    it considers a group of pixels assuming that spatially close pixels have inter-dependencies.
    These dependencies can be linked to the actual structure of objects that were
    captured and presented by the given images. SSIM specifically focuses on the spatial
    relationships among pixels, such as edges and textures, to assess how close an
    image is to a reference one.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 'SSIM是衡量两张图像之间结构相似度最广泛使用的指标之一。它首次在题为*Image quality assessment: from error visibility
    to structural similarity*的论文中提出（[https://ieeexplore.ieee.org/document/1284395](https://ieeexplore.ieee.org/document/1284395)）。SSIM指标并不比较两张图像的个别像素。然而，它考虑了一组像素，假设空间上接近的像素具有相互依赖性。这些依赖性可以与由给定图像捕获和呈现的实际物体结构联系起来。SSIM特别关注像素之间的空间关系，如边缘和纹理，以评估图像与参考图像的接近程度。'
- en: Recently, it was shown that SSIM may lead to incorrect or unexpected results
    when utilized to compare images or when included in the training loss of ML models.
    For more information, please refer to *Understanding* *SSIM* ([https://arxiv.org/pdf/2006.13846.pdf](https://arxiv.org/pdf/2006.13846.pdf)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，研究表明，当SSIM用于比较图像或包含在机器学习模型的训练损失中时，可能会导致不正确或意外的结果。更多信息，请参阅*Understanding SSIM*
    ([https://arxiv.org/pdf/2006.13846.pdf](https://arxiv.org/pdf/2006.13846.pdf))。
- en: Learned Perceptual Image Patch Similarity (LPIPS)
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习感知图像块相似度（LPIPS）
- en: '**LPIPS** measures the distance between images in the feature space by leveraging
    networks trained for computer vision tasks on large-scale datasets, for example,
    *VGG* trained on the *ImageNet* dataset. It was found that LPIPS gives more similar
    results to how humans perceive similarity between images. For more information,
    please refer to *The Unreasonable Effectiveness of Deep Features as a Perceptual
    Metric* ([https://arxiv.org/abs/1801.03924](https://arxiv.org/abs/1801.03924)).
    In this paper, it was found that ML models trained on complex visual tasks learn
    a rich, general-purpose, and useful visual representation of the world. This knowledge
    can be leveraged to assess the visual similarity between images in a similar manner
    to how humans may perceive this similarity.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**LPIPS**通过利用在大规模数据集上训练用于计算机视觉任务的神经网络来衡量特征空间中图像之间的距离，例如在*ImageNet*数据集上训练的*VGG*。研究发现，LPIPS给出了与人类感知图像之间相似性的更相似结果。更多信息，请参阅*深度特征作为感知度量不可理喻的有效性*([https://arxiv.org/abs/1801.03924](https://arxiv.org/abs/1801.03924))。在这篇论文中，研究发现，在复杂视觉任务上训练的机器学习模型学习到了丰富、通用和有用的世界视觉表示。这种知识可以用来以类似于人类可能感知这种相似性的方式来评估图像之间的视觉相似性。'
- en: Expert evaluation
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 专家评估
- en: In certain applications, we may need to request a domain expert evaluation of
    the generated synthetic images. For example, assume your generative model is generating
    synthetic images of **Computerized Tomography** (**CT**) scans that will be used
    later to train a cancer prediction ML model. We can still leverage qualitative
    metrics, such as SSIM to assess structural similarity with a real data counterpart,
    **Peak Signal to Noise Ratio** (**PSNR**) to measure the quality of the generated
    images, **Fréchet Inception Distance** (**FID**) to give us an idea about the
    realism and diversity of the generated samples, and LPIPS to assess the perceptual
    similarity to real data. However, expert evaluation is still essential for these
    critical problems. Expert evaluation of the synthetically generated data is essential
    to verify its validity, quality, and diversity. Most importantly, this evaluation
    is essential to confirm that synthetic data adheres to ethical standards.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些应用中，我们可能需要请求领域专家对生成的合成图像进行评估。例如，假设你的生成模型正在生成用于后续训练癌症预测机器学习模型的计算机断层扫描（**CT**）合成图像。我们仍然可以利用定性指标，如结构相似性指数（SSIM）来评估与真实数据对应的结构相似性，峰值信噪比（**PSNR**）来衡量生成图像的质量，弗雷歇起始距离（**FID**）来了解生成样本的现实性和多样性，以及LPIPS来评估与真实数据的感知相似性。然而，对于这些关键问题，专家评估仍然是必不可少的。对合成生成数据的专家评估对于验证其有效性、质量和多样性至关重要。最重要的是，这种评估对于确认合成数据符合伦理标准是必不可少的。
- en: Next, let us discuss some of the main challenges in generating photorealistic
    synthetic data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论生成光真实合成数据的一些主要挑战。
- en: Challenges and limitations of photorealistic synthetic data
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 光真实合成数据面临的挑战和限制
- en: In this section, you will explore the main challenges that hinder generating
    photorealistic synthetic data in practice. We will highlight the following limitations.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将探索阻碍在实际中生成光真实合成数据的主要挑战。我们将强调以下限制。
- en: Creating hyper-realistic scenes
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建超逼真场景
- en: The real world is complex, diverse, and intricate with details. Scene elements
    in reality have various shapes, sophisticated dynamics, and highly non-linear
    interactions. Additionally, our vision and perception of the world are limited
    and subject to many factors, such as cognitive biases and color perception. Additionally,
    we may judge photorealism differently based on the context and evaluator. For
    example, what is more photorealistic, realistic foreground objects and a non-realistic
    background or the opposite? All these aspects together make generating highly
    realistic scenes rather hard in practice.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界是复杂、多样和错综复杂的，细节丰富。现实场景中的元素具有各种形状、复杂的动态和高度非线性的相互作用。此外，我们对世界的视觉和感知是有限的，并受许多因素的影响，例如认知偏差和颜色感知。此外，我们可能根据上下文和评估者的不同对光真实性有不同的判断。例如，更真实的是前景物体真实而背景不真实，还是相反？所有这些因素共同使得在实际中生成高度逼真的场景相当困难。
- en: Resources versus photorealism trade-off
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源与光真实性的权衡
- en: Budget, time, skills, and other factors limit the photorealism of the generated
    synthetic data. As expected, simulating realistic worlds populated with high-poly
    3D models and diverse, realistic animations necessitates substantial computational
    resources. Additionally, employing advanced and complex light- rendering mechanisms,
    such as ray tracing and PBR, further increases the demand for more processing
    capabilities and resources. **Ray tracing** is a rendering technique that can
    simulate the realistic behavior of light and its complex interactions with scene
    elements. Thus, there is always a trade-off observed between resources and photorealism.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 预算、时间、技能和其他因素限制了生成的合成数据的照片级真实感。正如预期的那样，模拟由高多边形3D模型和多样化、逼真的动画组成的世界需要大量的计算资源。此外，采用高级和复杂的光渲染机制，如光线追踪和PBR，进一步增加了对更多处理能力和资源的需求。“光线追踪”是一种渲染技术，可以模拟光的真实行为及其与场景元素的复杂交互。因此，在资源和照片级真实感之间始终存在权衡。
- en: Therefore, it is very important to identify what you mean by photorealism for
    your particular problem. Additionally, you need to carefully consider which metrics
    you will deploy to assess the quality and photorealism of the generated synthetic
    data, taking into account the available resources.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于您特定的实际问题，确定您所说的“照片级真实感”是什么非常重要。此外，您还需要仔细考虑您将部署哪些指标来评估生成的合成数据的质量和照片级真实感，同时考虑到可用的资源。
- en: Summary
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned the main reasons that motivate researchers to strive
    to achieve high photorealism in generated synthetic data for computer vision problems.
    You learned about two main approaches usually utilized for that aim. Then, you
    explored well-known quantitative and qualitative measures deployed to assess the
    photorealism of the generated synthetic data. Finally, you examined some issues
    that hinder generating ideal photorealistic synthetic data in practice. In the
    next and final chapter, we will wrap up and conclude the book.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了促使研究人员努力在计算机视觉问题中生成的合成数据中实现高照片级真实感的主要原因。您了解了通常用于此目的的两个主要方法。然后，您探讨了用于评估生成的合成数据照片级真实感的知名定量和定性指标。最后，您检查了一些在实践中阻碍生成理想照片级真实感合成数据的问题。在下一章和最后一章中，我们将总结并结束本书。
