- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Recommender Systems
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统
- en: 'Recommender systems are algorithms, programs, and services that are designed
    to use data to predict which objects (goods or services) are of interest to a
    user. There are two main types of recommender systems: *content-based* and *collaborative
    filtering*. **Content-based recommender systems** are based on data that’s been
    collected from specific products. They recommend objects to a user that are similar
    to ones the user has previously acquired or shown interest in. **Collaborative
    filtering recommender systems** filter out objects that a user might like based
    on the reaction history of other, similar users of these systems. They also usually
    consider the user’s previous reactions.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统是设计用来使用数据预测用户可能感兴趣的对象（商品或服务）的算法、程序和服务。主要有两种类型的推荐系统：*基于内容的*和*协同过滤*。**基于内容的推荐系统**基于从特定产品收集的数据。它们向用户推荐与用户之前获取或表现出兴趣的对象相似的对象。**协同过滤推荐系统**根据其他类似用户的反应历史过滤掉用户可能喜欢的对象。它们通常还会考虑用户的先前反应。
- en: 'In this chapter, we’ll learn how to implement recommender system algorithms
    based on both content and collaborative filtering. We’re going to discuss different
    approaches for implementing collaborative filtering algorithms, implement systems
    using only the linear algebra library, and learn how to use the `mlpack` library
    to solve collaborative filtering problems. We’ll be using the MovieLens dataset
    provided by GroupLens from a research lab in the Department of Computer Science
    and Engineering at the University of Minnesota: [https://grouplens.org/datasets/movielens/](B19849_08.xhtml#_idTextAnchor473).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何根据内容和协同过滤实现推荐系统算法。我们将讨论实现协同过滤算法的不同方法，使用仅包含线性代数库的系统实现系统，并学习如何使用`mlpack`库解决协同过滤问题。我们将使用明尼苏达大学计算机科学与工程学院一个研究实验室提供的MovieLens数据集：[https://grouplens.org/datasets/movielens/](B19849_08.xhtml#_idTextAnchor473)。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: An overview of recommender system algorithms
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统算法概述
- en: Understanding the collaborative filtering method
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解协同过滤方法
- en: Examples of item-based collaborative filtering with C++
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于C++的基于物品的协同过滤示例
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To complete this chapter, you’ll need the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成本章，你需要以下内容：
- en: The `Eigen` library
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Eigen`库'
- en: The `Armadillo` library
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Armadillo`库'
- en: The `mlpack` library
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlpack`库'
- en: A modern C++ compiler with C++20 support
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 C++20 的现代C++编译器
- en: CMake build system version >= 3.10
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CMake构建系统版本 >= 3.10
- en: 'The code files for this chapter can be found in this book’s GitHub repository:
    [https://github.com/PacktPublishing/Hands-On-Machine-Learning-with-C-Second-Edition/tree/main/Chapter08](B19849_08.xhtml#_idTextAnchor470).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在本书的GitHub仓库中找到：[https://github.com/PacktPublishing/Hands-On-Machine-Learning-with-C-Second-Edition/tree/main/Chapter08](B19849_08.xhtml#_idTextAnchor470)。
- en: An overview of recommender system algorithms
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统算法概述
- en: A recommender system’s task is to inform a user about an object that could be
    the most interesting to them at a given time. Often, such an object is a product
    or service, but it may be information—for example, in the form of a recommended
    news article.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统的任务是通知用户在特定时间可能对他们最有兴趣的对象。通常，这样的对象是产品或服务，但它也可能是信息——例如，以推荐新闻文章的形式。
- en: 'Before we dive into the technicalities of the recommender system, let’s look
    at some real-world scenarios where recommender systems are used to improve user
    experience and increase sales. The following are the most common applications:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨推荐系统的技术细节之前，让我们看看一些实际场景，在这些场景中，推荐系统被用来改善用户体验并增加销售额。以下是最常见的应用：
- en: Recommender systems help online retailers suggest products that might interest
    a customer based on their past purchases, browsing history, and other data. This
    helps customers find relevant products more easily and increases the likelihood
    of conversion.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统帮助在线零售商根据客户的过去购买、浏览历史和其他数据建议可能感兴趣的产品。这有助于客户更容易地找到相关产品，并增加转换的可能性。
- en: Music and video streaming services use recommender systems to suggest music
    or videos based on a user’s listening or viewing history. The goal is to provide
    personalized content recommendations that keep users engaged with the platform.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音乐和视频流媒体服务使用推荐系统根据用户的收听或观看历史推荐音乐或视频。目标是提供个性化的内容推荐，以保持用户对平台的参与度。
- en: Social media platforms such as Meta and Instagram use recommender systems to
    show users content from friends and pages they might be interested in. This keeps
    users engaged and spending time on the platform.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社交媒体平台如Meta和Instagram使用推荐系统向用户展示他们可能感兴趣的朋友和页面内容。这有助于保持用户活跃并花费更多时间在平台上。
- en: Advertisers use recommender systems to target adverts at specific audiences
    based on their interests, demographics, and behavior. This improves the effectiveness
    of advertising campaigns.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广告商利用推荐系统，根据他们的兴趣、人口统计和行为，针对特定受众投放广告。这提高了广告活动的有效性。
- en: News websites, blogs, and search engines use recommender systems to recommend
    articles, stories, or search results based on user preferences and search history.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新闻网站、博客和搜索引擎利用推荐系统，根据用户偏好和搜索历史推荐文章、故事或搜索结果。
- en: Recommender systems can be used to suggest treatments, medications, or medical
    procedures based on patient data and medical research.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统可以根据患者数据和医学研究，建议治疗方案、药物或医疗程序。
- en: Travel websites and hotel booking platforms use recommender systems to suggest
    travel destinations, accommodations, and activities based on a traveler’s preferences,
    budget, and travel history.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旅行网站和酒店预订平台利用推荐系统，根据旅行者的偏好、预算和旅行历史，推荐旅行目的地、住宿和活动。
- en: Educational platforms and online courses use recommender systems to personalize
    learning experiences by suggesting courses, materials, and learning paths based
    on student performance, interests, and goals.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教育平台和在线课程利用推荐系统，根据学生的表现、兴趣和目标，推荐课程、材料和学习路径，以实现个性化学习体验。
- en: Video game platforms use recommender systems to suggest games based on player
    preferences, play style, and gaming history.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频游戏平台利用推荐系统，根据玩家的偏好、游戏风格和游戏历史推荐游戏。
- en: These are just a few examples of how recommender systems are applied in real-life
    scenarios. They’ve become an essential tool for businesses looking to improve
    customer engagement, increase sales, and provide personalized experiences.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是推荐系统在实际场景中应用的一些例子。它们已成为企业寻求提高客户参与度、增加销售额和提供个性化体验的必备工具。
- en: 'Despite the many existing algorithms, we can divide recommender systems into
    several basic approaches. The most common are as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在许多现有算法，我们仍然可以将推荐系统分为几种基本方法。最常见的方法如下：
- en: '**Summary-based**: Non-personal models based on the average product rating'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于总结**：基于平均产品评分的非个性化模型'
- en: '**Content-based**: Models based on the intersection of product descriptions
    and user interests'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于内容**：基于产品描述与用户兴趣交集的模型'
- en: '**Collaborative filtering**: Models based on interests of similar user groups'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协同过滤**：基于相似用户群体兴趣的模型'
- en: '**Matrix factorization**: Methods based on the preferences matrix’s decomposition'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**矩阵分解**：基于偏好矩阵分解的方法'
- en: 'The basis of any recommender system is the preferences matrix. It has all users
    of the service laid on one of the axes and recommendation objects on the other.
    The recommendation objects are usually called **items**. At the intersection of
    rows and columns (user, item), this matrix is filled with ratings that indicate
    user interest in a product, expressed on a given scale (for example, from 1 to
    5), as illustrated in the following table:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 任何推荐系统的基础是偏好矩阵。它将服务的所有用户放在一个轴上，推荐对象放在另一个轴上。推荐对象通常被称为**项目**。在行和列（用户、项目）的交叉处，这个矩阵填充了表示用户对产品的兴趣的评分，这些评分是在给定的尺度上表达的（例如，从1到5），如下表所示：
- en: '|  | **item1** | **item 2** | **item3** |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|  | **item1** | **item 2** | **item3** |'
- en: '| user1 | 1 |  |  |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| user1 | 1 |  |  |'
- en: '| user2 |  | 2 | 4 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| user2 |  | 2 | 4 |'
- en: '| user3 | 1 | 1 | 1 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| user3 | 1 | 1 | 1 |'
- en: '| user4 |  |  | 5 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| user4 |  |  | 5 |'
- en: '| user5 | 3 | 1 |  |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| user5 | 3 | 1 |  |'
- en: '| user6 |  | 4 |  |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| user6 |  | 4 |  |'
- en: Table 8.1 – User interest count
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.1 – 用户兴趣计数
- en: Users usually evaluate only a small number of the items in the catalog; the
    task of the recommender system is to summarize this information and predict the
    attitude the user might have toward other items. In other words, you need to fill
    in all the blank cells in the preceding table.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 用户通常只评估目录中少量项目；推荐系统的任务是总结这些信息并预测用户可能对其他项目的态度。换句话说，你需要填写前面表格中的所有空白单元格。
- en: 'People’s consumption patterns are different, and new products don’t have to
    be recommended all the time. You can show repeated items—for example, when a user
    has bought something they’ll need again. According to this principle, there are
    two groups of items:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 人们的消费模式各不相同，不必总是推荐新产品。您可以在用户需要再次购买某物时展示重复的物品——例如，当用户购买了一些他们将来还会需要的东西时。根据这一原则，存在两类物品：
- en: '**Repeatable**: For example, shampoos or razors, which are always needed'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可重复的**：例如，洗发水或剃须刀，总是需要使用的'
- en: '**Unrepeatable**: For example, books or films, which are rarely purchased repeatedly'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不可重复的**：例如，书籍或电影，很少会重复购买'
- en: If the product can’t be attributed to one of these groups, it makes sense to
    determine the group type of repetitive purchases individually (someone usually
    buys only a specific brand, but someone else might try everything in the catalog).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果产品不能归入这些类别之一，那么确定重复购买的产品类型就很有意义（有人通常只购买特定品牌的产品，但其他人可能会尝试目录中的所有产品）。
- en: Determining what product *interests* a user is also subjective. Some users need
    things only from their favorite category (conservative recommendations), while
    others respond more to non-standard goods (risky recommendations). For example,
    a video-hosting service may only recommend new series from their favorite TV series
    (conservative) but may periodically recommend new shows or new genres. Ideally,
    you should choose a strategy for displaying recommendations for each client separately
    by using generalized information about the client’s preferences.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 确定什么产品会吸引用户也是主观的。一些用户只需要他们最喜欢的类别的物品（保守型推荐），而其他人则对非标准商品（风险型推荐）反应更强烈。例如，一个视频托管服务可能只会推荐他们最喜欢的电视剧的新系列（保守型），但可能会定期推荐新的节目或新的类型。理想情况下，您应该使用客户偏好的泛化信息，为每个客户分别选择显示推荐策略。
- en: 'The essential part of datasets that are used to build recommendation models
    is user reactions to different objects or items. These reactions are typically
    called user ratings of objects. We can obtain user ratings in the following ways:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 用于构建推荐模型的必要数据集部分是用户对不同对象或物品的反应。这些反应通常被称为对象的用户评分。我们可以通过以下方式获取用户评分：
- en: '**Explicit ratings**: The user gives their rating for the product, leaves a
    review, or *likes* the page.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**显式评分**：用户对产品进行评分，留下评论，或*点赞*页面。'
- en: '**Implicit ratings**: The user doesn’t express their attitude, but an indirect
    conclusion can be made from their actions. For example, if they bought a product,
    it means they like it; if they read the description for a long time, it means
    they have serious interest.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐式评分**：用户没有表达他们的态度，但可以从他们的行为中得出间接结论。例如，如果他们购买了一个产品，这意味着他们喜欢它；如果他们长时间阅读描述，这意味着他们有浓厚的兴趣。'
- en: Of course, explicit preferences are better. However, in practice, not all services
    allow users to express their interests clearly, and not all users have the desire
    to do so. Both types of assessments are often used in tandem and complement each
    other well.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，显式偏好更好。然而，在实践中，并非所有服务都允许用户清楚地表达他们的兴趣，并非所有用户都有此愿望。这两种评估类型通常同时使用，并且很好地相互补充。
- en: It’s also essential to distinguish between the terms *prediction* (the prediction
    of the degree of interest) and the *recommendation* itself (showing the recommendation).
    How to show something is a separate task from the task of *what to show*. *How
    to show* is a task that uses the estimates obtained in the prediction step, and
    can be implemented in different ways.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 区分术语*预测*（预测兴趣程度）和*推荐*本身（展示推荐）也是非常重要的。如何展示是一个独立于*展示什么*的任务。*如何展示*是一个使用预测步骤中获得的估计的任务，并且可以以不同的方式实现。
- en: In this section, we discussed the basics of recommender systems. In the following
    sections, we’ll look at the essential building blocks of recommender systems.
    Let’s begin by looking at the main principles of content-based filtering, user
    and item-based collaborative filtering, and collaborative filtering based on matrix
    factorization.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了推荐系统的基础知识。在接下来的章节中，我们将探讨推荐系统的基本构建块。让我们首先看看基于内容的过滤、基于用户和物品的协同过滤以及基于矩阵分解的协同过滤的主要原则。
- en: Non-personalized recommendations
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非个性化推荐
- en: 'For non-personalized recommendations, the potential interest of the user is
    determined by the average rating of the product: *if everyone likes it, you’ll
    like it too*. According to this principle, most services work when the user isn’t
    authorized on the system.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非个性化推荐，用户的潜在兴趣由产品的平均评分决定：*如果每个人都喜欢它，你也会喜欢它*。根据这个原则，大多数服务在用户未在系统上授权时工作。
- en: Content-based recommendations
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于内容的推荐
- en: Personal recommendations use the maximum information available about the user—primarily,
    information about their previous purchases. Content-based filtering was one of
    the first approaches to be developed for personalized recommendations. In this
    approach, the product’s description (content) is compared with the interests of
    the user, which are obtained from their previous assessments. The more the product
    meets these interests, the higher the potential interest of the user. The obvious
    requirement here is that all products in the catalog should have a description.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 个人推荐使用关于用户可用的最大信息——主要是他们之前购买的信息。基于内容的过滤是用于个性化推荐最早开发的方法之一。在这种方法中，产品的描述（内容）与用户的兴趣进行比较，这些兴趣是从他们之前的评估中获得的。产品越能满足这些兴趣，用户的潜在兴趣就越高。这里的一个明显要求是，目录中的所有产品都应该有描述。
- en: 'Historically, the subject of content-based recommendations was products with
    unstructured descriptions: films, books, or articles. Their features may be, for
    example, text descriptions, reviews, or casts. However, nothing prevents the use
    of usual numerical or categorical features.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，基于内容的推荐的主题是具有无结构描述的产品：电影、书籍或文章。它们的特征可能是，例如，文本描述、评论或演员阵容。然而，没有任何东西阻止使用常规的数值或分类特征。
- en: Unstructured features are described in a text-typical way—vectors in the space
    of words (vector-space model). Each element of a vector is a feature that potentially
    characterizes the interest of the user. Similarly, an item (product) is a vector
    in the same space.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 无结构特征以文本典型的方式进行描述——词空间中的向量（向量空间模型）。向量的每个元素都是一个特征，它可能表征了用户的兴趣。同样，一个项目（产品）是这个空间中的向量。
- en: As users interact with the system (say, they buy films), the vector descriptions
    of the goods they’ve purchased merge (sum up and normalize) into a single vector
    and, thus, form the vector of a user’s interests. Using this vector of interests,
    we can find the product and the description of which is closest to it—that is,
    we can solve the problem of finding the nearest neighbors.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户与系统互动时（例如，他们购买电影），他们购买的商品的向量描述会合并（求和并归一化）成一个单一的向量，从而形成用户兴趣的向量。使用这个兴趣向量，我们可以找到与它最接近的产品和描述——即，我们可以解决寻找最近邻的问题。
- en: When forming the vector space of a product presentation, instead of individual
    words, you can use shingles or n-grams (successive pairs of words, triples of
    words, or other numbers of words). This approach makes the model more detailed,
    but more data is required for training.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在形成产品展示的向量空间时，你不仅可以使用单个单词，还可以使用shingles或n-grams（连续的单词对、三词组或其他数量的单词）。这种方法使模型更加详细，但需要更多的数据进行训练。
- en: In different places of the description of the product, the weight of keywords
    may differ (for example, the description of the film may consist of a title, a
    brief description, and a detailed description). Product descriptions from different
    users can be weighed differently. For example, we can give more weight to active
    users who have many ratings. Similarly, you can weigh them by item. The higher
    the average rating of an object, the greater its weight (similar to PageRank).
    If the product description allows links to external sources, then you can also
    analyze all third-party information related to the product.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在产品描述的不同位置，关键词的权重可能不同（例如，电影的描述可能包括标题、简短描述和详细描述）。来自不同用户的商品描述可以有不同的权重。例如，我们可以给评分多的活跃用户更多的权重。同样，你也可以按项目来权衡。一个对象的平均评分越高，其权重就越大（类似于PageRank）。如果产品描述允许链接到外部来源，那么你还可以分析与产品相关的所有第三方信息。
- en: The cosine distance is often used to compare product representation vectors.
    This distance measures the value of proximity between two vectors.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦距离常用于比较产品表示向量。这个距离衡量了两个向量之间接近度的值。
- en: When adding a new assessment, the vector of interests is updated incrementally
    (only for those elements that have changed). During the update, it makes sense
    to give a bit more weight to new estimates since the user’s preferences may change.
    You’ll notice that content-based filtering almost wholly repeats the query-document
    matching mechanism used in search engines such as Google. The only difference
    lies in the form of a search query—content filtering systems use a vector that
    describes the interests of the user, whereas search engines use keywords of the
    requested document. When search engines began to add personalization, this distinction
    was erased even more.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在添加新的评估时，兴趣向量会增量更新（仅针对那些发生变化的元素）。在更新过程中，由于用户的偏好可能会改变，因此给予新的估计更多权重是有意义的。你会注意到基于内容的过滤几乎完全重复了搜索引擎如Google所使用的查询-文档匹配机制。唯一的区别在于搜索查询的形式——内容过滤系统使用描述用户兴趣的向量，而搜索引擎使用请求文档的关键词。当搜索引擎开始添加个性化时，这种区别被进一步抹去。
- en: User-based collaborative filtering
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于用户的协同过滤
- en: This class of system began to develop in the 90s. Under this approach, recommendations
    are generated based on the interests of other, similar users. Such recommendations
    are the result of the **collaboration** of many users, hence the name of the method.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这类系统在90年代开始发展。在这种方法下，推荐是基于其他相似用户的兴趣生成的。这种推荐是许多用户**协作**的结果，因此得名该方法。
- en: The classical implementation of the algorithm is based on the principle of **k-nearest
    neighbors** (**kNN**). For every user, we look for the **k** most similar to them
    (in terms of preferences). Then, we supplement the information about the user
    with known data from their neighbors. So, for example, if it’s known that your
    neighbors are delighted with a movie, and you haven’t watched it for some reason,
    this is a great reason to recommend this movie.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的经典实现基于**k最近邻**（**kNN**）的原则。对于每个用户，我们寻找与他们最相似的前**k**个（就偏好而言）。然后，我们使用已知的数据补充用户的信息。例如，如果已知你的邻居对一部电影感到非常满意，而你由于某种原因没有看过，这是一个很好的推荐这部电影的理由。
- en: The similarity is, in this case, a synonym for a *correlation* of interests
    and can be considered in many ways—Pearson’s correlation, cosine distance, Jaccard
    distance, Hamming distance, and other types of distances.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，相似性是兴趣**相关性**的同义词，可以从许多方面考虑——皮尔逊相关系数、余弦距离、Jaccard距离、汉明距离以及其他类型的距离。
- en: The classical implementation of the algorithm has one distinct disadvantage—it’s
    poorly applicable in practice due to the quadratic complexity of the calculations.
    As with any nearest neighbor method, it requires all pairwise distances between
    users to be calculated (and there may be millions of users). It’s easy to calculate
    that the complexity of calculating the distance matrix is ![](img/B19849_08_01.png),
    where ![](img/B19849_Formula_001.png) is the number of users, and ![](img/B19849_08_03.png)
    is the number of items (goods).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的经典实现有一个明显的缺点——由于计算的二次复杂性，它在实践中应用得不好。与任何最近邻方法一样，它需要计算用户之间的所有成对距离（可能有数百万用户）。很容易计算出计算距离矩阵的复杂度是
    ![](img/B19849_08_01.png)，其中 ![](img/B19849_Formula_001.png) 是用户的数量，而 ![](img/B19849_08_03.png)
    是物品（商品）的数量。
- en: 'This problem can be partly mitigated by purchasing high-performance hardware.
    But if you approach it wisely, then it’s better to introduce some corrections
    to the algorithm in the following way:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通过购买高性能硬件可以部分缓解这个问题。但如果你明智地处理，那么最好是以下这种方式对算法进行一些修正：
- en: Update distances not with every purchase but with batches (for example, once
    a day)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要在每次购买时更新距离，而是以批量（例如，每天一次）更新
- en: Don’t recalculate the distance matrix completely, but update it incrementally
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要完全重新计算距离矩阵，而是增量更新
- en: Choose some iterative and approximate algorithms (for example, **Alternating
    Least** **Squares** (**ALS**))
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择一些迭代和近似算法（例如，**交替最小二乘法**（**ALS**））
- en: 'Fulfill the following assumptions to make the algorithm more practical:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 满足以下假设可以使算法更加实用：
- en: The tastes of people don’t change over time (or they do change, but they’re
    the same for everyone)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人们的品味不会随时间改变（或者它们会改变，但每个人都是相同的）
- en: If people’s tastes are the same, then they’re the same in everything
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果人们的品味相同，那么他们在所有事情上都是相同的
- en: For example, if two clients prefer the same films, then they also like the same
    book. This assumption is often the case when the recommended products are homogeneous
    (for example, films only). If this isn’t the case, then a couple of clients may
    well have the same eating habits but their political views might be the opposite;
    here, the algorithm is less efficient.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果两个客户喜欢相同的电影，那么他们也会喜欢相同的书籍。当推荐的产品是同质化的（例如，仅限电影）时，这种假设通常是成立的。如果情况不是这样，那么一对客户可能有相同的饮食习惯，但他们的政治观点可能正好相反；在这种情况下，算法的效率较低。
- en: The neighborhood of the user in the space of preferences (the user’s neighbors),
    which we analyze to generate new recommendations, can be chosen in different ways.
    We can work with all users of the system; we can set a certain proximity threshold;
    we can choose several neighbors at random; or we can take the **k** most similar
    neighbors (this is the most popular approach). If we take too many neighbors,
    we get a higher chance of random noise, and vice versa. If we take too little,
    we get more accurate recommendations, but fewer goods can be recommended.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分析以生成新推荐的偏好空间中的用户邻域（用户的邻居），可以选择不同的方式。我们可以与系统中的所有用户一起工作；我们可以设置一个特定的接近度阈值；我们可以随机选择几个邻居；或者我们可以选择**k**个最相似的邻居（这是最流行的方法）。如果我们选择太多的邻居，我们得到更高的随机噪声机会，反之亦然。如果我们选择太少的邻居，我们得到更准确的推荐，但可以推荐的商品更少。
- en: An interesting development in the collaborative approach is trust-based recommendations,
    which take into account not only the proximity of people according to their interests
    but also their *social* proximity and the degree of trust between them. If, for
    example, we see that on Facebook, a girl occasionally visits a page that has her
    friend’s audio recordings, then she trusts her musical taste. Therefore, when
    making recommendations to the girl, you can add new songs from her friend’s playlist.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤方法中的一个有趣的发展是基于信任的推荐，它不仅考虑了人们根据兴趣的接近程度，还考虑了他们之间的社会接近程度以及他们之间的信任程度。例如，如果我们看到在Facebook上，一个女孩偶尔访问一个有她朋友音频录音的页面，那么她信任她的音乐品味。因此，在向这个女孩推荐时，你可以添加她朋友播放列表中的新歌曲。
- en: Item-based collaborative filtering
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于项目的协同过滤
- en: The item-based approach is a natural alternative to the classic user-based approach
    described previously and almost repeats it, except for one thing—it applies to
    the transposed preference matrix, which looks for similar products instead of
    users.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 基于项目的这种方法是之前描述的经典基于用户方法的自然替代品，几乎重复了它，除了一个方面——它适用于转置的偏好矩阵，寻找类似的产品而不是用户。
- en: For each client, a user-based collaborative filtering system searches a group
    of customers who are similar to this user in terms of previous purchases, and
    then the system averages their preferences. These average preferences serve as
    recommendations for the user. In the case of item-based collaborative filtering,
    the nearest neighbors are searched for on a variety of products (items) using
    the columns of a preference matrix, and the averaging occurs precisely according
    to them.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个客户，基于用户的协同过滤系统会搜索一组与该用户在以往购买方面相似的客户，然后系统平均他们的偏好。这些平均偏好作为对用户的推荐。在基于项目的协同过滤的情况下，使用偏好矩阵的列在各种产品（项目）上搜索最近邻，平均也正好根据这些最近邻进行。
- en: If some products are meaningfully similar to each other, then users’ reactions
    to these products will be the same. Therefore, when we see that some products
    have a strong correlation between their estimates, this may indicate that these
    products are equivalent to each other.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果某些产品之间在意义上相似，那么用户对这些产品的反应也将相同。因此，当我们看到某些产品在其估计之间存在强烈的关联时，这可能表明这些产品彼此之间是等效的。
- en: The main advantage of the item-based approach over the user-based approach is
    lower computation complexity. When there are many users (almost always), the task
    of finding the nearest neighbor becomes poorly computable. For example, for 1
    million users, you need to calculate and store ~500 billion distances. If the
    distance is encoded in 8 bytes, this results in 4 **terabytes** (**TB**) for the
    distance matrix alone. If we take an item-based approach, then the computational
    complexity decreases from ![](img/B19849_08_04.png) to ![](img/B19849_08_05.png),
    and the distance matrix has a dimension no longer than 1 million per 1 million
    but 100 by 100, as per the number of items (goods).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于用户的方案相比，基于物品的方法的主要优势是计算复杂度更低。当用户数量很多（几乎总是如此）时，找到最近邻的任务变得难以计算。例如，对于100万用户，你需要计算和存储大约5000亿个距离。如果距离用8个字节编码，这仅距离矩阵就需要4
    **太字节**（**TB**）。如果我们采用基于物品的方法，那么计算复杂度将从 ![](img/B19849_08_04.png) 降低到 ![](img/B19849_08_05.png)，并且距离矩阵的维度不再是每100万用户就有100万，而是根据商品（物品）的数量，是100乘以100。
- en: Estimating the proximity of products is much more accurate than assessing the
    proximity of users. This assumption is a direct consequence of the fact that there
    are usually many more users than items, and therefore the standard error in calculating
    the correlation of items is significantly less because we have more information
    to work from.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 估计产品的邻近度比评估用户的邻近度要准确得多。这个假设是这样一个事实的直接后果：通常用户比物品多得多，因此计算物品相关性的标准误差显著较小，因为我们有更多的工作信息。
- en: In the user-based version, the description of users usually has a very sparse
    distribution (there are many goods, but only a few evaluations). On the one hand,
    this helps to optimize the calculation—we multiply only those elements where an
    intersection exists. But, on the other hand, the list of items that a system can
    recommend to a user is minimal due to the limited number of user neighbors (users
    who have similar preferences). Also, user preferences may change over time, but
    the descriptions of the goods are much more stable.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于用户的版本中，用户的描述通常具有非常稀疏的分布（有很多商品，但只有少数评价）。一方面，这有助于优化计算——我们只乘那些存在交集的元素。但另一方面，由于用户邻居（具有相似偏好的用户）的数量有限，系统可以向用户推荐的商品列表非常有限。此外，用户偏好可能会随时间变化，但商品的描述则要稳定得多。
- en: 'The rest of the algorithm almost wholly repeats the user-based version: it
    uses the same cosine distance as the primary measure of proximity and has the
    same need for data normalization. Since the correlation of items is considered
    on a higher number of observations, it isn’t as critical to recalculate it after
    each new assessment, and this can be done periodically in a batch mode.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的其余部分几乎完全重复了基于用户的版本：它使用相同的余弦距离作为距离的主要度量，并且需要相同的数据归一化。由于在更多的观察上考虑了物品的相关性，因此不需要在每次新的评估后重新计算它，这可以通过批量模式定期完成。
- en: Now, let’s look at another approach to generalizing user interests based on
    matrix factorization methods.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看另一种基于矩阵分解方法来泛化用户兴趣的方法。
- en: Factorization algorithms
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分解算法
- en: It would be nice to describe the interests of the user with more extensive features—not
    in the format of *they love movies X, Y, and Z*, but in the format of *they love
    romantic comedies*. Besides the fact that it increases the generalizability of
    the model, it also solves the problem of having a large data dimension—after all,
    the interests are described not by the items vector, but by a significantly smaller
    preference vector.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，如果能用更广泛的特征来描述用户的兴趣那就更好了——不是用*他们喜欢电影X、Y和Z*这样的格式，而是用*他们喜欢浪漫喜剧*这样的格式。除了增加模型的可泛化性之外，这还能解决数据维度大的问题——毕竟，兴趣不是由物品向量来描述的，而是由一个显著更小的偏好向量来描述的。
- en: Such approaches are also called **spectral decomposition** or **high-frequency
    filtering** (since we remove the noise and leave the useful signal). There are
    many different types of matrix decomposition in algebra, and one of the most commonly
    used is called **singular value** **decomposition** (**SVD**).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法也被称为**谱分解**或**高频滤波**（因为我们去除了噪声，留下了有用的信号）。代数中有许多不同的矩阵分解类型，其中最常用的一种被称为**奇异值分解**（**SVD**）。
- en: Initially, the SVD method was used to select pages that are similar in meaning
    but not in content. More recently, it has started being used in recommendations.
    The method is based on decomposing the original *R* rating matrix into a product
    of three matrices, ![](img/B19849_08_06.png), where the sizes of the matrices
    are ![](img/B19849_08_07.png) and *r* is the rank of the decomposition, which
    is the parameter characterizing the degree of detail decomposition.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，奇异值分解（SVD）方法用于选择在意义上相似但在内容上不同的页面。最近，它开始被用于推荐。该方法基于将原始的 *R* 评分矩阵分解为三个矩阵的乘积，![](img/B19849_08_06.png)，其中矩阵的大小是
    ![](img/B19849_08_07.png)，*r* 是分解的秩，它是描述分解详细程度的参数。
- en: 'Applying this decomposition to our matrix of preferences, we can get the following
    two matrices of factors (abbreviated descriptions):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 将这种分解应用于我们的偏好矩阵，我们可以得到以下两个因素矩阵（简称为描述）：
- en: '**U**: A compact description of user preferences'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**U**：对用户偏好的紧凑描述'
- en: '**S**: A compact description of the characteristics of the product'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**S**：对产品特性的紧凑描述'
- en: When using this approach, we can’t know which particular characteristics correspond
    to the factors in the reduced descriptions; for us, they’re encoded with some
    numbers. Therefore, SVD is an uninterpreted model. It’s sufficient to multiply
    the matrix of factors to obtain an approximation of the matrix of preferences.
    By doing this, we get a rating for all customer-product pairs.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用这种方法时，我们无法知道哪些特定的特性对应于简化描述中的因素；对我们来说，它们被编码为一些数字。因此，奇异值分解（SVD）是一个未解释的模型。通过乘以因素矩阵，我们可以获得偏好矩阵的近似值。通过这样做，我们得到了所有客户-产品对的评分。
- en: 'A typical family of such algorithms is called **non-negative matrix factorization**
    (**NMF**). As a rule, the calculation of such expansions is very computationally
    expensive. Therefore, in practice, they often resort to their approximate iterative
    variants. ALS is a popular iterative algorithm for decomposing a matrix of preferences
    into a product of two matrices: **user factors** (**U**) and **product factors**
    (**I**). It works on the principle of minimizing the **root mean square error**
    (**RMSE**) on the affixed ratings. Optimization takes place alternately—first
    by user factors, then by product factors. Also, to avoid retraining, the regularization
    coefficients are added to the RMSE.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的算法族通常被称为**非负矩阵分解**（**NMF**）。通常，这种展开的计算非常耗时。因此，在实践中，他们经常求助于它们的近似迭代变体。交替最小二乘法（ALS）是一种流行的迭代算法，用于将偏好矩阵分解为两个矩阵的乘积：**用户因素**（**U**）和**产品因素**（**I**）。它基于最小化固定评分的**均方根误差**（**RMSE**）。优化是交替进行的——首先通过用户因素，然后通过产品因素。此外，为了避免重新训练，正则化系数被添加到RMSE中。
- en: If we supplement the matrix of preferences with a new dimension containing information
    about the user or product, then we can work not with the matrix of preferences,
    but with the tensor. Thus, we use more available information and possibly get
    a more accurate model.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在偏好矩阵中补充一个包含有关用户或产品信息的新维度，那么我们就可以不与偏好矩阵，而与张量一起工作。因此，我们使用更多可用的信息，并可能得到一个更精确的模型。
- en: In this section, we considered different approaches to solving recommender systems’
    tasks. Now, we’re going to discuss methods for estimating the similarity of user
    preferences.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们考虑了解决推荐系统任务的不同方法。现在，我们将讨论估计用户偏好相似性的方法。
- en: Similarity or preferences correlation
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相似性或偏好相关性
- en: We can consider the similarity or correlation of two user preferences in different
    ways, but in general, we need to compare two vectors. Let’s look at some of the
    most popular vector comparison measures.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从不同的角度考虑两个用户偏好的相似性或相关性，但通常我们需要比较两个向量。让我们看看一些最流行的向量比较度量。
- en: Pearson’s correlation coefficient
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 皮尔逊相关系数
- en: 'This measure is a classic coefficient that can be applied when comparing vectors.
    Its primary disadvantage is that when the intersection is estimated as low, then
    the correlation can be high by accident. To combat accidental high correlation,
    you can multiply by a factor of 50/min (50, rating intersection) or any other
    damping factor, the effect of which decreases with an increasing number of estimates.
    An example is shown here:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这个度量是一个经典的系数，可以在比较向量时应用。它的主要缺点是，当交集被估计为低时，相关性可能会意外地很高。为了对抗意外的过高相关性，你可以乘以50/min（50，评分交集）或任何其他阻尼因子，其效果随着估计数量的增加而降低。这里有一个例子：
- en: '![](img/B19849_08_08.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19849_08_08.jpg)'
- en: Spearman’s correlation
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 斯皮尔曼相关系数
- en: 'The main difference compared to Pearson’s correlation is the rank factor—that
    is, it doesn’t work with absolute values of ratings, but with their sequence numbers.
    In general, the result is very close to Pearson’s correlation. An example is shown
    here:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 与皮尔逊相关系数相比，主要区别在于排名因素——也就是说，它不与评分的绝对值一起工作，而是与它们的序列号一起工作。一般来说，结果非常接近皮尔逊相关系数。这里有一个例子：
- en: '![](img/B19849_08_09.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_09.jpg)'
- en: Cosine distance
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 余弦距离
- en: 'Cosine distance is another classic measuring factor. If you look closely, the
    cosine of the angle between the standardized vectors is Pearson’s correlation,
    the same formula. This distance uses cosine properties: if the two vectors are
    co-directed (that is, the angle between them is 0), then the cosine of the angle
    between them is 1\. Conversely, the cosine of the angle between perpendicular
    vectors is 0\. An example is shown here:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦距离是另一个经典的测量因素。如果你仔细观察，标准化向量之间的余弦值就是皮尔逊相关系数，相同的公式。这个距离使用余弦性质：如果两个向量是同向的（也就是说，它们之间的角度是0），那么它们之间角度的余弦值是1。相反，垂直向量之间角度的余弦值是0。这里有一个例子：
- en: '![](img/B19849_08_10.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_10.jpg)'
- en: With that, we’ve discussed methods we can use to estimate the similarity of
    user preferences. The next important issue we’ll discuss is preparing data so
    that it can be used in recommender system algorithms.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些，我们已经讨论了我们可以用来估计用户偏好相似性的方法。接下来我们将讨论的一个重要问题是准备数据，以便它可以在推荐系统算法中使用。
- en: Data scaling and standardization
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据缩放和标准化
- en: All users evaluate (rate) items differently. If someone puts 5s in a row, instead
    of waiting for 4s from someone else, it’s better to normalize the data before
    calculating it—that is, convert the data into a single scale so that the algorithm
    can compare the results correctly. After, the predicted estimate needs to be converted
    into the original scale via inverse transformation (and, if necessary, rounded
    to the nearest whole number).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 所有用户对物品的评估（评分）都不同。如果有人连续给出5分，而不是等待别人给出4分，那么在计算之前对数据进行归一化会更好——也就是说，将数据转换成单一尺度，以便算法可以正确比较结果。之后，预测估计需要通过逆变换转换回原始尺度（如果需要，四舍五入到最接近的整数）。
- en: 'There are several ways to normalize data:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以归一化数据：
- en: '**Centering (mean-centering)**: From the user’s ratings, subtract their average
    rating. This type of normalization is only relevant for non-binary matrices.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中心化（均值中心化）**：从用户的评分中减去他们的平均评分。这种归一化类型仅适用于非二元矩阵。'
- en: '**Standardization (z-score)**: In addition to centering, this divides the user’s
    rating by the standard deviation of the user. But in this case, after the inverse
    transformation, the rating can go beyond the scale (for example, six on a five-point
    scale), but such situations are quite rare and can be solved by rounding to the
    nearest acceptable estimate.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化（z分数）**：除了中心化之外，这个方法还将用户的评分除以用户的标准差。但在这种情况下，在逆变换之后，评分可能会超出尺度（例如，在五点尺度上为六），但这种情况相当罕见，可以通过四舍五入到最近的可接受估计来解决。'
- en: '**Double standardization**: The first time data is normalized by user ratings;
    the second time, by item ratings.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**双重标准化**：第一次通过用户评分进行数据归一化；第二次，通过项目评分。'
- en: The details of these normalization techniques were provided in [*Chapter 2*](B19849_02.xhtml#_idTextAnchor075),
    *Data Processing*. The following section will describe a problem with recommender
    systems known as the **cold start problem**, which appears in the early stages
    of system work when the system doesn’t have enough data to make predictions.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这些归一化技术的细节在[*第二章*](B19849_02.xhtml#_idTextAnchor075)，*数据处理*中提供。下一节将描述推荐系统中已知的问题，称为**冷启动问题**，它出现在系统工作的早期阶段，当系统没有足够的数据来做出预测时。
- en: Cold start problem
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 冷启动问题
- en: A cold start is a typical situation when a sufficient amount of data hasn’t
    been accumulated for the correct operation of the recommender system yet (for
    example, when a product is new or is just rarely bought). If the ratings of only
    three users estimate the average rating, such an assessment isn’t reliable, and
    users understand this. In such situations, ratings are often artificially adjusted.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 冷启动是在推荐系统还没有积累足够数据以正确运行时的典型情况（例如，当产品是新的或很少被购买时）。如果只有三个用户的评分来估计平均评分，这样的评估并不可靠，用户也明白这一点。在这种情况下，评分通常会人为调整。
- en: The first way to do this is to show not the average value, but the smoothed
    average (damped mean). With a small number of ratings, the displayed rating leans
    more toward a specific safe *average* indicator, and as soon as a sufficient number
    of new ratings are typed, the *averaging* adjustment stops operating.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这一点的第一种方法是不显示平均值，而是显示平滑平均值（阻尼均值）。在评分数量较少时，显示的评分更倾向于一个特定的安全*平均值*指标，一旦输入足够数量的新评分，*平均*调整就会停止。
- en: Another approach is to calculate confidence intervals for each rating. Mathematically,
    the more estimates we have, the smaller the variation of the average will be and,
    therefore, the more confidence we have in its accuracy.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是计算每个评分的置信区间。从数学上讲，我们拥有的估计值越多，平均值的变异就越小，因此我们对它的准确性就越有信心。
- en: For example, we can display the lower limit of the interval (low **confidence
    interval** (**CI**) bound) as a rating. At the same time, it’s clear that such
    a system is quite conservative, with a tendency to underestimate ratings for new
    items.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以将区间的下限（低**置信区间**（**CI**）界限）显示为评分。同时，很明显，这样一个系统相当保守，倾向于低估新项目的评分。
- en: Since the estimates are limited to a specific scale (for example, from 0 to
    1), the usual methods for calculating the confidence interval are poorly applicable
    here due to the distribution tails that go to infinity, and the symmetry of the
    interval itself. There’s a more accurate way to calculate it—the Wilson CI.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 由于估计值限制在特定的范围内（例如，从0到1），由于分布尾端延伸到无穷大以及区间的对称性，因此通常用于计算置信区间的常规方法在这里适用性较差。有一种更准确的方法来计算它——威尔逊置信区间（Wilson
    CI）。
- en: The cold start problem is also relevant for non-personalized recommendations.
    The general approach here is to replace what currently can’t be calculated by
    different heuristics—for example, replace it with an average rating, use a simpler
    algorithm, or not use the product at all until the data has been collected.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 冷启动问题也适用于非个性化推荐。这里的一般方法是使用不同的启发式方法来替换当前无法计算的内容——例如，用平均评分替换，使用更简单的算法，或者直到收集到数据之前根本不使用该产品。
- en: Another issue that should be considered when we develop a recommender system
    is the relevance of recommendations, which considers factors other than the user’s
    interests—for example, it can be the freshness of a publication or a user’s rating.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开发推荐系统时，还应考虑的一个问题是推荐的相关性，这考虑了除了用户兴趣之外的因素——例如，可以是出版物的时效性或用户的评分。
- en: Relevance of recommendations
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐的相关性
- en: In some cases, it’s also essential to consider the *freshness* of the recommendation.
    This consideration is especially important for articles or posts on forums. Fresh
    entries should often get to the top. The correction factors (damping factors)
    are usually used to make such updates. The following formulas are used for calculating
    the rating of articles on media sites.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，考虑推荐的*时效性*也是至关重要的。这种考虑对于论坛上的文章或帖子尤为重要。新条目应经常出现在顶部。通常使用校正因子（阻尼因子）来执行此类更新。以下公式用于计算媒体网站上文章的评分。
- en: 'Here’s an example of a rating calculation in the *Hacker* news magazine:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在*Hacker*新闻杂志中评分计算的示例：
- en: '![](img/B19849_08_11.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19849_08_11.jpg)'
- en: Here, *U* denotes upvotes, *D* denotes downvotes, *P* denotes penalty (additional
    adjustment for the implementation of other business rules), and *T* denotes recording
    time.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*U*表示点赞，*D*表示踩，*P*表示惩罚（对其他业务规则实施的额外调整），*T*表示记录时间。
- en: 'The following equation shows a *Reddit* rating calculation:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 以下方程展示了*Reddit*评分的计算方法：
- en: '![](img/B19849_08_12.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19849_08_12.jpg)'
- en: Here, *U* denotes the number of upvotes, *D* denotes the number of downvotes,
    and *T* denotes the recording time. The first term evaluates the *quality of the
    record*, and the second corrects for the time.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*U*表示点赞数，*D*表示踩数，*T*表示记录时间。第一个项评估记录的*质量*，第二个项对时间进行校正。
- en: There’s no universal formula, and each service invents the formula that best
    solves its problem; it can only be tested empirically.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 没有通用的公式，每个服务都会发明一个最佳解决其问题的公式；它只能通过经验来测试。
- en: The following section will discuss the existing approaches to testing recommender
    systems. This isn’t a straightforward task because it’s usually hard to estimate
    the quality of a recommendation without having exact target values in a training
    dataset.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分将讨论测试推荐系统的现有方法。这不是一项简单的工作，因为通常在没有训练数据集中确切的目标值的情况下很难估计推荐的质量。
- en: Assessing system quality
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估系统质量
- en: Testing a recommender system is a complicated process that always poses many
    questions, mainly due to the ambiguity of the concept of *quality*.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 测试推荐系统是一个复杂的过程，总是提出许多问题，这主要是因为“质量”概念的不确定性。
- en: 'In general, in machine learning problems, there are two main approaches to
    testing:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在机器学习问题中，有两种主要的测试方法：
- en: Offline model testing on historical data using retro tests
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用回溯测试在历史数据上进行的离线模型测试
- en: Testing the model using A/B testing (we run several options and see which one
    gives the best result)
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用A/B测试（我们运行几个选项，看看哪个给出最好的结果）来测试模型
- en: Both of these approaches are actively used in developing recommender systems.
    The main limitation that we have to face is that we can only evaluate the accuracy
    of the forecast on those products that the user has already evaluated or rated.
    The standard approach is to use cross-validation alongside the **leave-one-out**
    and **leave-p-out** methods. Repeating the test and averaging the results provides
    a more stable assessment of quality.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法都在开发推荐系统中被积极使用。我们必须面对的主要限制是我们只能评估用户已经评估或评分的产品上的预测准确性。标准的方法是使用交叉验证与**留一法**和**留出法**相结合。重复测试并平均结果提供了一个更稳定的对质量的评估。
- en: The *leave-one-out* approach uses the model that’s been trained on all items
    except one and is evaluated by the user. This excluded item is used for model
    testing. This procedure is done for all *n* items, and an average is calculated
    among the obtained *n* quality estimates.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*留一法*使用除了一个项目之外所有项目训练的模型，并由用户进行评估。这个被排除的项目用于模型测试。这个程序对所有的*n*个项目都进行，并在获得的*n*个质量估计中计算平均值。'
- en: The *leave-p-out* approach is the same, but at each step, ![](img/B19849_Formula_119.png)
    points are excluded.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*留出法*的方法相同，但在每一步，会排除![](img/B19849_Formula_119.png)个点。'
- en: 'We can divide all quality metrics into the following three categories:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将所有质量指标分为以下三个类别：
- en: '**Prediction accuracy**: Estimates the accuracy of the predicted rating'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测准确度**：估计预测评分的准确性'
- en: '**Decision support**: Evaluates the relevance of the recommendations'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策支持**：评估推荐的相关性'
- en: '**Rank accuracy metrics**: Evaluates the quality of the ranking of recommendations
    issued'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**排名准确度指标**：评估发布的推荐排名的质量'
- en: Unfortunately, there’s no single recommended metric for all occasions, and everyone
    who’s involved in testing a recommender system selects it to fit their goals.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，没有适用于所有场合的单一推荐指标，并且所有参与测试推荐系统的人都会选择一个适合他们目标的指标。
- en: In the following section, we’ll formalize the collaborative filtering method
    and show the math behind it.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下部分，我们将形式化协同过滤方法，并展示其背后的数学。
- en: Understanding the collaborative filtering method
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解协同过滤方法
- en: In this section, we’ll formalize the recommender system problem. We have a set
    of users, ![](img/B19849_08_14.png), a set of items, ![](img/B19849_08_15.png)
    (movies, tracks, products, and so on), and a set of estimates, ![](img/B19849_08_16.png).
    Each estimate is given by a user ![](img/B19849_08_17.png), an object ![](img/B19849_Formula_0721.png),
    its result ![](img/B19849_08_19.png), and, possibly, some other characteristics.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将形式化推荐系统问题。我们有一组用户，![](img/B19849_08_14.png)，一组项目，![](img/B19849_08_15.png)（电影、曲目、产品等），以及一组估计，![](img/B19849_08_16.png)。每个估计由用户![](img/B19849_08_17.png)，一个对象![](img/B19849_Formula_0721.png)，其结果![](img/B19849_08_19.png)，以及可能的其他特征给出。
- en: 'We’re required to predict preference as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要按照以下方式预测偏好：
- en: '![](img/B19849_08_20.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_20.jpg)'
- en: 'We’re required to predict personal recommendations as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要按照以下方式预测个人推荐：
- en: '![](img/B19849_08_21.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_21.jpg)'
- en: 'We’re required to predict similar objects as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要按照以下方式预测相似对象：
- en: '![](img/B19849_08_22.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_22.jpg)'
- en: 'Remember that the main idea behind collaborative filtering is that similar
    users usually like similar objects. Let’s start with the simplest method:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，协同过滤背后的主要思想是相似的用户通常喜欢相似的对象。让我们从最简单的方法开始：
- en: Select some conditional measures of similarity of users according to their history
    of ![](img/B19849_08_23.png) ratings.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据用户对 ![](img/B19849_08_23.png) 评分的历史，选择一些条件相似度度量。
- en: 'Unite users into groups (clusters) so that similar users will end up in the
    same cluster: ![](img/B19849_08_24.png).'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将用户分组（聚类）以便相似用户最终会落在同一个簇中：![](img/B19849_08_24.png)。
- en: 'Predict the item’s user rating as the cluster’s average rating for this object:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测物品的用户评分为此对象簇的平均评分：
- en: '![](img/B19849_08_25.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19849_08_25.jpg)'
- en: 'This algorithm has several problems:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法有几个问题：
- en: There’s nothing to recommend to new or atypical users. For such users, there’s
    no suitable cluster with similar users.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于新用户或非典型用户，没有推荐的内容。对于这样的用户，没有合适的类似用户簇。
- en: It ignores the specificity of each user. In a sense, we divide all users into
    classes (templates).
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它忽略了每个用户的特殊性。在某种程度上，我们将所有用户划分为类别（模板）。
- en: If no one in the cluster has rated the item, the prediction won’t work.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果簇中没有人为该物品评分，则预测将不起作用。
- en: 'We can improve this method and replace hard clustering with the following formula:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以改进这种方法，用以下公式替换硬聚类：
- en: '![](img/B19849_08_26.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19849_08_26.jpg)'
- en: 'For an item-based version, the formula will be symmetrical, as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于物品的版本，公式将是对称的，如下所示：
- en: '![](img/B19849_08_27.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19849_08_27.jpg)'
- en: 'These approaches have the following disadvantages:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法有以下缺点：
- en: Cold start problem
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冷启动问题
- en: Bad predictions for new and atypical users or items
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对新用户或非典型用户或物品的糟糕预测
- en: Trivial recommendations
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单推荐
- en: Resource intensity calculations
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源密集型计算
- en: To overcome these problems, you can use SVD. The preference (ratings) matrix
    can be decomposed into the product of three matrices, ![](img/B19849_08_28.png).
    Let’s denote the product of the first two matrices for one matrix, ![](img/B19849_08_29.png),
    where *R* is the matrix of preferences, *U* is the matrix of parameters of users,
    and *V* is the matrix of parameters of items.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些问题，你可以使用奇异值分解（SVD）。偏好（评分）矩阵可以被分解为三个矩阵的乘积，![](img/B19849_08_28.png)。让我们用
    ![](img/B19849_08_29.png) 表示前两个矩阵的乘积，其中 *R* 是偏好矩阵，*U* 是用户参数矩阵，*V* 是物品参数矩阵。
- en: 'To predict the user rating, *U*, for an item, ![](img/B19849_08_30.png), we
    take a vector, ![](img/B19849_08_31.png) (parameter set), for a given user and
    a vector for a given item, ![](img/B19849_08_32.png). Their scalar product is
    the prediction we need: ![](img/B19849_08_33.png). Using this approach, we can
    identify the hidden features of items and user interests by user history. For
    example, it may happen that at the first coordinate of the vector, each user has
    a number indicating whether the user is more likely to be a boy or a girl, and
    the second coordinate is a number reflecting the approximate age of the user.
    In the item, the first coordinate shows whether it’s more interesting to boys
    or girls, and the second one shows the age group of users this item appeals to.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测一个物品的用户评分 *U*，对于物品 ![](img/B19849_08_30.png)，我们取一个向量 ![](img/B19849_08_31.png)（参数集），对于一个给定的用户和一个给定物品的向量
    ![](img/B19849_08_32.png)。它们的标量积是我们需要的预测：![](img/B19849_08_33.png)。使用这种方法，我们可以通过用户历史来识别物品和用户兴趣的隐藏特征。例如，向量的一阶坐标可能表示每个用户是男孩还是女孩的可能性数值，而第二坐标是一个反映用户大约年龄的数值。在物品中，第一坐标表示对男孩或女孩更有趣，第二坐标表示该物品吸引的用户年龄组。
- en: However, there are also several problems. The first one is the preferences matrix,
    *R*, which isn’t entirely known to us, so we can’t merely take its SVD decomposition.
    Secondly, the SVD decomposition isn’t the only one we have, so even if we find
    at least some decomposition, it’s unlikely that it’s optimal for our task.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，也存在一些问题。第一个问题是偏好矩阵 *R* 并不完全为我们所知，所以我们不能仅仅取其奇异值分解。其次，奇异值分解不是我们拥有的唯一分解，所以即使我们找到了至少一些分解，它也不太可能是我们任务的最优解。
- en: 'Here, we need machine learning. We can’t find the SVD decomposition of the
    matrix since we don’t know the matrix itself. However, we can take advantage of
    this idea and come up with a prediction model that works like SVD. Our model depends
    on many parameters—vectors of users and items. For the given parameters, to predict
    the estimate, we must take the user vector, the vector of the item, and get their
    scalar product, ![](img/B19849_08_34.png). However, since we don’t know vectors,
    they still need to be obtained. The idea is that we have user ratings with which
    we can find optimal parameters so that our model can predict these estimates as
    accurately as possible using the following equation: ![](img/B19849_08_35.png).
    We want to find such parameters’ *θ* values so that the square error is as small
    as possible. We also want to make fewer mistakes in the future, but we don’t know
    what estimates we need. Accordingly, we can’t optimize parameters’ *θ* values.
    We already know the ratings given by users, so we can try to choose parameters
    based on the estimates we already have to minimize the error. We can also add
    another term, the *regularizer*, as shown here:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们需要机器学习。由于我们不知道矩阵本身，所以我们无法找到矩阵的奇异值分解。然而，我们可以利用这个想法，提出一个类似于奇异值分解的预测模型。我们的模型依赖于许多参数——用户和物品的向量。对于给定的参数，为了预测估计值，我们必须取用户向量、物品向量，并得到它们的标量积，![图片](img/B19849_08_34.png)。然而，由于我们不知道向量，它们仍然需要被获得。想法是我们有用户评分，我们可以通过这些评分找到最优参数，使得我们的模型可以尽可能准确地使用以下方程预测这些估计值：![图片](img/B19849_08_35.png)。我们希望找到这样的参数*θ*值，使得平方误差尽可能小。我们还想在未来犯更少的错误，但我们不知道我们需要什么估计值。因此，我们无法优化参数的*θ*值。我们已经知道用户给出的评分，因此我们可以尝试根据我们已有的估计值来选择参数，以最小化误差。我们还可以添加另一个项，即*正则化器*，如下所示：
- en: '![](img/B19849_08_36.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_36.jpg)'
- en: 'Regularization is needed to combat overfitting. To find the optimal parameters,
    you need to optimize the following function:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对抗过拟合，需要正则化。为了找到最优参数，你需要优化以下函数：
- en: '![](img/B19849_08_37.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_37.jpg)'
- en: 'There are many parameters: for each user and item, we have the vector that
    we want to optimize. The most well-known method for optimizing functions is **gradient
    descent** (**GD**). Suppose we have a function of many variables, and we want
    to optimize it. We take an initial value, and then we look at where we can move
    to minimize this value. The GD method is an iterative algorithm—it takes the parameters
    of a certain point repeatedly, looks at the gradient, and steps against its direction,
    as shown here:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多参数：对于每个用户和物品，我们都有一个想要优化的向量。优化函数最著名的方法是**梯度下降**（**GD**）。假设我们有一个许多变量的函数，我们想要优化它。我们取一个初始值，然后我们看看我们可以移动到哪个位置以最小化这个值。GD方法是一个迭代算法——它反复取某个点的参数，查看梯度，并朝着其方向移动，如图所示：
- en: '![](img/B19849_08_38.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_38.jpg)'
- en: 'There are various problems with this method: it works very slowly and it finds
    local, rather than global, minima. The second problem isn’t so bad for us because
    in our case, the value of the function in local minima is close to the global
    optimum.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法存在各种问题：它运行得非常慢，并且找到的是局部而不是全局最小值。第二个问题对我们来说不是那么糟糕，因为在我们这个案例中，局部最小值处的函数值接近全局最优值。
- en: 'However, the GD method isn’t always necessary. For example, if we need to calculate
    the minimum for a parabola, there’s no need to act by this method as we know precisely
    where its minimum is. It turns out that the functionality that we’re trying to
    optimize—the sum of the squares of errors plus the sum of the squares of all the
    parameters—is also a quadratic function, which is very similar to a parabola.
    For each specific parameter, if we fix all the others, it’s just a parabola. For
    those, we can accurately determine at least one coordinate. The ALS method is
    based on this assumption. We alternate between accurately finding minima in one
    coordinate or another, as shown here:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，GD方法并不总是必要的。例如，如果我们需要计算抛物线的最小值，就没有必要采取这种方法，因为我们确切地知道它的最小值在哪里。结果证明，我们试图优化的功能——误差平方和加上所有参数平方和——也是一个二次函数，这与抛物线非常相似。对于每个特定的参数，如果我们固定所有其他参数，它就是一个抛物线。对于这些，我们可以准确地确定至少一个坐标。ALS方法基于这个假设。我们交替在某个坐标或另一个坐标上准确找到最小值，如图所示：
- en: '![](img/B19849_08_39.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_39.jpg)'
- en: 'We fix all the parameters of the items, optimize the parameters of users, fix
    the parameters of users, and then optimize the parameters of items. We act iteratively,
    as shown here:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们固定所有物品的参数，优化用户的参数，然后固定用户的参数，并优化物品的参数。我们按此方式迭代操作，如下所示：
- en: '![](img/B19849_08_40.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_40.jpg)'
- en: 'This method works reasonably quickly, and you can parallelize each step. However,
    there’s still a problem with implicit data because we have neither full user data
    nor full item data. So, we can penalize the items that don’t have ratings in the
    update rule. By doing so, we depend only on the items that have ratings from the
    users and don’t make any assumptions about the items that aren’t rated. So, let’s
    define a weight matrix, ![](img/B19849_08_41.png), as follows:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法运行得相当快，并且可以并行化每个步骤。然而，由于我们没有完整的用户数据或物品数据，隐式数据仍然存在问题。因此，我们可以在更新规则中对没有评分的物品进行惩罚。通过这样做，我们只依赖于有评分的用户物品，不对未评分的物品做出任何假设。因此，让我们定义一个权重矩阵，![](img/B19849_08_41.png)，如下所示：
- en: '![](img/B19849_08_42.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_42.jpg)'
- en: 'The cost functions that we’re trying to minimize look like this:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们试图最小化的成本函数看起来如下：
- en: '![](img/B19849_08_43.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_43.jpg)'
- en: 'Note that we need regularization terms to avoid overfitting the data. We can
    use the following solutions for factor vectors:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们需要正则化项来避免数据过拟合。我们可以为因子向量使用以下解决方案：
- en: '![](img/B19849_08_44.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_44.jpg)'
- en: Here, ![](img/B19849_08_45.png) and ![](img/B19849_08_46.png)are diagonal matrices.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/B19849_08_45.png) 和 ![](img/B19849_08_46.png) 是对角矩阵。
- en: 'Another approach for dealing with implicit data is to introduce confidence
    levels. Let’s define a set of binary observation variables:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种处理隐式数据的方法是引入置信水平。让我们定义一组二元观测变量：
- en: '![](img/B19849_08_47.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_47.jpg)'
- en: 'Now, we can define confidence levels for each ![](img/B19849_08_48.png) value.
    When ![](img/B19849_08_49.png), we have low confidence. This can be because the
    user has never been exposed to that item or it may be unavailable at the time.
    For example, it could be explained by the user buying a gift for someone else.
    Hence, we would have *low confidence*. When ![](img/B19849_08_50.png) is larger,
    we should have much more confidence. For example, we can define confidence as
    follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以为每个 ![](img/B19849_08_48.png) 值定义置信水平。当 ![](img/B19849_08_49.png) 时，我们具有低置信度。这可能是由于用户从未接触过该物品，或者它可能在当时不可用。例如，这可能是由用户为他人购买礼物来解释的。因此，我们将有
    *低置信度*。当 ![](img/B19849_08_50.png) 更大时，我们应该有更大的置信度。例如，我们可以定义置信度如下：
- en: '![](img/B19849_08_51.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_51.jpg)'
- en: 'Here, ![](img/B19849_08_52.png) is a hyperparameter that should be tuned for
    a given dataset. The updated optimization function is as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/B19849_08_52.png) 是一个超参数，应该针对给定的数据集进行调整。更新的优化函数如下：
- en: '![](img/B19849_08_53.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_53.jpg)'
- en: 'Here, ![](img/B19849_08_54.png) is a diagonal matrix with ![](img/B19849_08_55.png)
    values. The following solutions are for user and item ratings:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/B19849_08_54.png) 是一个具有 ![](img/B19849_08_55.png) 值的对角矩阵。以下解决方案用于用户和物品评分：
- en: '![](img/B19849_08_56.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_56.jpg)'
- en: 'However, it’s an expensive computational problem to calculate the ![](img/B19849_08_57.png)
    expression. However, it can be optimized in the following way:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，计算 ![](img/B19849_08_57.png) 表达式是一个昂贵的计算问题。然而，它可以以下方式进行优化：
- en: '![](img/B19849_08_58.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19849_08_58.jpg)'
- en: This means that ![](img/B19849_08_59.png) can be precomputed at each of the
    steps, and ![](img/B19849_08_60.png) only contains the non-zero entries where
    ![](img/B19849_08_61.png) was non-zero. Now that we’ve learned about collaborative
    filtering in detail, let’s understand it further practically by considering a
    few examples of how to implement a collaborative filtering recommender system.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着 ![](img/B19849_08_59.png) 可以在每个步骤中预先计算，而 ![](img/B19849_08_60.png) 只包含
    ![](img/B19849_08_61.png) 非零时的非零条目。现在我们已经详细了解了协同过滤，让我们通过考虑一些实现协同过滤推荐系统的示例来进一步了解它。
- en: In the following sections, we’ll learn how to use different C++ libraries for
    developing recommender systems.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，我们将学习如何使用不同的 C++ 库来开发推荐系统。
- en: Examples of item-based collaborative filtering with C++
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于物品的 C++ 协同过滤示例
- en: 'Let’s look at how we can implement a collaborative filtering recommender system.
    We’ll be using the MovieLens dataset provided by GroupLens from the research lab
    in the Department of Computer Science and Engineering at the University of Minnesota:
    [https://grouplens.org/datasets/movielens/](B19849_08.xhtml#_idTextAnchor473).
    They’ve provided a full dataset containing 20 million movie ratings and a smaller
    one for education that contains 100,000 ratings. We recommend starting with the
    smaller one because it allows us to see results earlier and detect implementation
    errors faster.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何实现协同过滤推荐系统。我们将使用由明尼苏达大学计算机科学与工程学院的研究实验室提供的MovieLens数据集：[https://grouplens.org/datasets/movielens/](B19849_08.xhtml#_idTextAnchor473)。他们提供了一个包含2000万条电影评分的完整数据集，以及一个包含10万条评分的教育用较小数据集。我们建议从较小的数据集开始，因为它允许我们更早地看到结果，并更快地检测实现错误。
- en: 'This dataset consists of several files, but we’re only interested in two of
    them: `ratings.csv` and `movies.csv`. The rating file contains lines with the
    following format: the user ID, the movie ID, the rating, and the timestamp. In
    this dataset, users made ratings on a 5-star scale, with half-star increments
    (0.5 stars to 5.0 stars). The movie’s file contains lines with the following format:
    the movie ID, the title, and the genre. The movie ID is the same in both files
    so that we can see which movies users are rating.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集包含多个文件，但我们只对其中两个感兴趣：`ratings.csv`和`movies.csv`。评分文件包含以下格式的行：用户ID、电影ID、评分和时间戳。在此数据集中，用户在5星评分尺度上进行了评分，以半星递增（0.5星到5.0星）。电影文件包含以下格式的行：电影ID、标题和类型。电影ID在这两个文件中是相同的，这样我们就可以看到用户在评分哪些电影。
- en: Using the Eigen library
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Eigen库
- en: 'First, let’s learn how to implement a collaborative filtering recommender system
    based on matrix factorization with ALS and with a pure linear algebra library
    as a backend. In the following sample, we’re using the `Eigen` library. The steps
    to implement a collaborative filtering recommender system are as follows:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们学习如何实现基于矩阵分解的协同过滤推荐系统，使用ALS和纯线性代数库作为后端。在以下示例中，我们使用`Eigen`库。实现协同过滤推荐系统的步骤如下：
- en: 'First, we must make base type definitions, as follows:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须进行基本类型定义，如下所示：
- en: '[PRE0]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'These definitions allow us to write less source code for matrices’ types and
    to quickly change floating-point precision. Next, we must define and initialize
    the ratings (preferences) matrix, list of movie titles, and binary rating flags
    matrix, as follows:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些定义使我们能够为矩阵类型编写更少的源代码，并快速更改浮点精度。接下来，我们必须定义和初始化评分（偏好）矩阵、电影标题列表和二进制评分标志矩阵，如下所示：
- en: '[PRE1]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We have a particular helper function, `LoadMovies`, which loads files into
    the map container, as shown in the following code snippet:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们有一个特定的辅助函数`LoadMovies`，它将文件加载到地图容器中，如下面的代码片段所示：
- en: '[PRE2]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once the data has been loaded, we can initialize matrix objects so that they’re
    the right size:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦数据被加载，我们可以初始化矩阵对象，使它们具有正确的大小：
- en: '[PRE3]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: However, because we’ve loaded data into the map, we need to move the required
    rating values to the matrix object.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然而，因为我们已经将数据加载到地图中，所以我们需要将所需的评分值移动到矩阵对象中。
- en: 'Now, we must initialize the movie titles list, convert user IDs into our zero-based
    sequential order, and initialize the binary rating matrix (this is used in the
    algorithm to deal with implicit data), as follows:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们必须初始化电影标题列表，将用户ID转换为我们的零基顺序，并初始化二进制评分矩阵（在算法中用于处理隐式数据），如下所示：
- en: '[PRE4]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once the rating matrix has been initialized, we must define and initialize
    our training variables:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦初始化了评分矩阵，我们必须定义和初始化我们的训练变量：
- en: '[PRE5]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, we must define and initialize the regularization matrix and identity
    matrices, which are constant during all learning cycles:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们必须定义和初始化正则化矩阵和单位矩阵，这些矩阵在整个学习周期中是恒定的：
- en: '[PRE7]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Additionally, because we’re implementing an algorithm version that can handle
    implicit data, we need to convert our rating matrix into another format to decrease
    computational complexity. Our version of the algorithm needs user ratings in the
    form of ![](img/B19849_08_62.png) and diagonal matrices for every user and item
    so that we can make two containers with corresponding matrix objects. The code
    for this can be seen in the following block:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，因为我们正在实现一个可以处理隐式数据的算法版本，所以我们需要将我们的评分矩阵转换为另一种格式以降低计算复杂度。我们的算法版本需要以以下形式提供用户评分！[](img/B19849_08_62.png)和每个用户和项目的对角矩阵。相应的矩阵对象的两个容器可以通过以下代码块查看：
- en: '[PRE8]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now, we’re ready to implement the main learning loop. As discussed previously,
    the ALS algorithm can be easily parallelized, so we use the `OpenMP` compiler
    extension to calculate user and item parameters in parallel.
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好实现主要的学习循环。如前所述，ALS 算法可以很容易地并行化，所以我们使用 `OpenMP` 编译器扩展来并行计算用户和项目参数。
- en: 'Let’s define the main learning cycle, which runs for a specified number of
    iterations:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义主要的学习周期，它运行指定次数的迭代：
- en: '[PRE9]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following code shows how to update item parameters:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码显示了如何更新项目参数：
- en: '[PRE10]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following code shows how to update users’ preferences:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码显示了如何更新用户的偏好：
- en: '[PRE11]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here, we have two parts of the loop body that are pretty much the same. First,
    we updated item parameters with frizzed user options, and then we updated user
    preferences with frizzed item parameters. Notice that all matrix objects were
    moved outside of the internal loop body to reduce memory allocations and significantly
    improve program performance. Also, notice that we parallelized the user and item
    parameters’ calculations separately because one of them should always be frizzed
    when the other is being calculated. To calculate exact values for user preferences
    and item parameters, we must use the following formula:'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，循环体中有两个部分几乎是相同的。首先，我们使用冻结的用户选项更新了项目参数，然后我们使用冻结的项目参数更新了用户偏好。请注意，所有矩阵对象都被移到了内部循环体外部，以减少内存分配并显著提高程序性能。另外，请注意，我们分别并行化了用户和项目参数的计算，因为当其中一个被计算时，另一个应该始终被冻结。为了计算用户偏好和项目参数的确切值，我们必须使用以下公式：
- en: '![](img/B19849_08_63.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19849_08_63.jpg)'
- en: '*X T X* and *Y T Y* are precomputed at each step. Also, notice that these formulas
    are expressed in the form of the linear equation system, *X = AB*. We use the
    `colPivHouseholderQr` function from the `Eigen` library to solve it and get exact
    values for the user and item parameters. This linear equation system can also
    be solved with other methods. The `colPivHouseholderQr` function was chosen because
    it shows a better ratio between computational speed and accuracy in the `Eigen`
    library implementation.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '*X T X* 和 *Y T Y* 在每一步都是预先计算的。另外，请注意，这些公式是以线性方程系统的形式表达的，*X = AB*。我们使用来自 `Eigen`
    库的 `colPivHouseholderQr` 函数来求解它，并得到用户和项目参数的确切值。这个线性方程系统也可以用其他方法求解。选择 `colPivHouseholderQr`
    函数是因为它在 `Eigen` 库实现中显示了更好的计算速度和准确性的比率。'
- en: 'To estimate the progress of the learning process of our system, we can calculate
    the **mean squared error** (**MSE**) between the original rating matrix and a
    predicted one. To calculate the predicted rating matrix, we must define another
    function:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了估计我们系统学习过程的进度，我们可以计算原始评分矩阵与预测矩阵之间的**均方误差**（**MSE**）。为了计算预测评分矩阵，我们必须定义另一个函数：
- en: '[PRE12]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'To calculate the MSE, we can use the ![](img/B19849_08_64.png) expression from
    our optimization function:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了计算 MSE，我们可以使用我们的优化函数中的 ![](img/B19849_08_64.png) 表达式：
- en: '[PRE13]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Please note that we have to use weights and binary ratings to get a meaningful
    value for the error because a similar approach was used during the learning process.
    Direct error calculation gives the wrong result because the predicted matrix has
    non-zero predictions, whereas the original rating matrix has zeros. It’s essential
    to understand that this algorithm doesn’t learn the original scale of ratings
    (from 0 to 5); instead, it learns prediction values in a range from 0 to 1\. It
    follows on from the function we optimize, as shown here:'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，我们必须使用权重和二进制评分来获得一个有意义的误差值，因为在学习过程中使用了类似的方法。直接计算误差会得到错误的结果，因为预测矩阵有非零预测，而原始评分矩阵有零。理解这一点很重要，这个算法并不学习原始评分的尺度（从
    0 到 5）；相反，它学习预测值在 0 到 1 的范围内。它从我们优化的函数开始，如下所示：
- en: '![](img/B19849_08_65.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19849_08_65.jpg)'
- en: 'We can use the previously defined movies list to show movie recommendations.
    The following function shows user preferences and system recommendations. To identify
    what a user likes, we’ll show movie titles that the user has rated with a rating
    value of more than 3\. We’ll also show movies that the system rates as equal to
    or higher than a 0.8 rating coefficient to identify which movie the system recommends
    to the user by running the following code:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用之前定义的电影列表来显示电影推荐。以下函数显示了用户偏好和系统推荐。为了确定用户喜欢什么，我们将显示用户评分超过 3 的电影标题。我们还将显示系统评分等于或高于
    0.8 评分系数的电影，以确定系统通过以下代码向用户推荐的电影：
- en: '[PRE14]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This function can be used as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数可以这样使用：
- en: '[PRE15]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Using the mlpack library
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用mlpack库
- en: The `mlpack` library is a general-purpose machine learning library that provides
    a lot of different algorithms and command-line tools to process the data and learn
    these algorithms without explicit programming. As a basis, this library uses the
    `Armadillo` linear algebra library for math calculations. Other libraries we’ve
    used in previous chapters don’t have collaborative filtering algorithm implementations.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`mlpack`库是一个通用机器学习库，它提供了许多不同的算法和命令行工具来处理数据并学习这些算法，而无需显式编程。作为基础，这个库使用`Armadillo`线性代数库进行数学计算。我们在前面的章节中使用的一些其他库没有协同过滤算法的实现。'
- en: 'To load the `MovieLens` dataset, use the same loading helper function that
    you did in the previous section. Once the data has been loaded, convert it into
    a format suitable for an object of the `mlpack::cf::CFType` type. This type implements
    a collaborative filtering algorithm and can be configured with different types
    of matrix factorization approaches. An object of this type can use dense as well
    as sparse rating matrices. In the case of a dense matrix, it should have three
    rows. The first row corresponds to users, the second row corresponds to items,
    and the third row corresponds to the rating. This structure is called a `arma::SpMat<DataType>`
    type from the `Armadillo` library, as illustrated in the following code block:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载`MovieLens`数据集，使用与上一节中相同的加载辅助函数。一旦数据被加载，将其转换为适合`mlpack::cf::CFType`类型对象的格式。这种类型实现了一个协同过滤算法，并且可以使用不同类型的矩阵分解方法进行配置。这种类型的对象可以使用密集和稀疏的评分矩阵。在密集矩阵的情况下，它应该有三行。第一行对应于用户，第二行对应于项目，第三行对应于评分。这种结构被称为来自`Armadillo`库的`arma::SpMat<DataType>`类型，如下面的代码块所示：
- en: '[PRE16]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we can initialize the `mlpack::cf::CFType` class object. It takes the
    next parameters in the constructor: the rating matrix, the matrix decomposition
    policy, the number of neighbors, the number of target factors, the number of iterations,
    and the minimum value of learning error, after which the algorithm can stop.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以初始化`mlpack::cf::CFType`类对象。它在构造函数中接受以下参数：评分矩阵、矩阵分解策略、邻居数量、目标因子数量、迭代次数和学习误差的最小值，之后算法可以停止。
- en: 'For this object, only perform the nearest neighbor search on the **H** matrix.
    This means you avoid calculating the full rating matrix, using the observation
    that if the rating matrix is **X = W H**, then the following applies:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个对象，只需在**H**矩阵上执行最近邻搜索。这意味着你避免了计算完整的评分矩阵，利用观察到的如果评分矩阵是**X = W H**，则以下适用：
- en: '[PRE17]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This expression can be seen as the nearest neighbor search on the **H** matrix
    with the Mahalanobis distance, as illustrated in the following code block:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表达式可以看作是使用马氏距离在**H**矩阵上的最近邻搜索，如下面的代码块所示：
- en: '[PRE18]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Notice that as a decomposition policy, the object of the `mlpack::NMFPolicy`
    type was used. This shows how to implement the non-negative matrix factorization
    algorithm with the ALS approach. There are several decomposition algorithms in
    the `mlpack` library. For example, batch SVD decomposition is implemented in the
    `mlpack::BatchSVDPolicy` type. The constructor of this object also does the complete
    training, so after its call has finished, we can use this object to get recommendations.
    Recommendations can be retrieved with the `GetRecommendations` method. This method
    gets the number of recommendations you want to get, the output matrix for recommendations,
    and the list of user IDs for users you want to get recommendations from, as shown
    in the following code block:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，作为一个分解策略，使用了`mlpack::NMFPolicy`类型的对象。这展示了如何使用ALS方法实现非负矩阵分解算法。`mlpack`库中有几个分解算法。例如，批处理SVD分解在`mlpack::BatchSVDPolicy`类型中实现。这个对象的构造函数也执行了完整的训练，因此在其调用完成后，我们可以使用这个对象来获取推荐。推荐可以通过`GetRecommendations`方法检索。此方法获取你想要获取的推荐数量、推荐输出矩阵以及你想要获取推荐的用户的用户ID列表，如下面的代码块所示：
- en: '[PRE19]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Notice that the `GetRecommendations` method returns the item IDs as its output.
    So, we can see that using this library for implementing a recommender system is
    much easier than writing it from scratch. Also, there are many more configuration
    options in the `mlpack` library for building such systems—for example, we can
    configure the neighbor detection policy and which distance measure to use. These
    configurations can significantly improve the quality of the system you build because
    you can make them according to your particular task.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`GetRecommendations`方法返回项目ID作为其输出。因此，我们可以看到，使用这个库来实现推荐系统比从头开始编写要容易得多。此外，`mlpack`库中还有许多更多配置选项来构建此类系统——例如，我们可以配置邻居检测策略和要使用的距离度量。这些配置可以显著提高你构建的系统质量，因为你可以根据你的特定任务来设置它们。
- en: Summary
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we discussed what recommender systems are and the types that
    exist today. We studied two main approaches to building recommender systems: content-based
    recommendations and collaborative filtering. We identified two types of collaborative
    filtering: user-based and item-based. Then, we looked at how to implement these
    approaches, as well as their pros and cons. We found out that an important issue
    we must rectify when implementing recommender systems is the amount of data and
    the associated large computational complexity of algorithms. We considered approaches
    to overcome computational complexity problems, such as partial data updates and
    approximate iterative algorithms such as ALS. We found out how matrix factorization
    can help to solve the problem with incomplete data, improve the generalizability
    of the model, and speed up the calculations. We also implemented a system of collaborative
    filtering based on the linear algebra library and used the `mlpack` general-purpose
    machine learning library.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了推荐系统是什么以及目前存在的类型。我们研究了构建推荐系统的两种主要方法：基于内容的推荐和协同过滤。我们确定了两种协同过滤类型：基于用户和基于物品。然后，我们探讨了如何实现这些方法，以及它们的优缺点。我们发现，在实现推荐系统时，我们必须纠正的一个重要问题是数据量以及算法相关的大规模计算复杂性。我们考虑了克服计算复杂性问题的方法，例如部分数据更新和近似迭代算法如ALS。我们发现矩阵分解可以帮助解决不完整数据的问题，提高模型的泛化能力，并加快计算速度。我们还实现了一个基于线性代数库的协同过滤系统，并使用了`mlpack`通用机器学习库。
- en: It makes sense to look at new methods that can be applied to recommender system
    tasks, such as autoencoders, variational autoencoders, or deep collaborative approaches.
    In recent research papers, these approaches show more impressive results than
    classical methods such as ALS. All these new methods are non-linear models, so
    they can potentially beat the limited modeling capacity of linear factor models.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 有必要研究可以应用于推荐系统任务的新方法，例如自动编码器、变分自动编码器或深度协同方法。在最近的研究论文中，这些方法比传统的如ALS等经典方法显示出更令人印象深刻的结果。所有这些新方法都是非线性模型，因此它们有可能超越线性因子模型的有限建模能力。
- en: In the next chapter, we’ll discuss ensemble learning techniques. The main idea
    of these techniques is to combine either different types of machine learning algorithms
    or use a set of the same kind of algorithms to obtain better predictive performance.
    Combining several algorithms into one ensemble allows us to get the best characteristics
    of each so that we can cover the disadvantages in a single algorithm.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论集成学习技术。这些技术的主要思想是将不同类型的机器学习算法结合在一起，或者使用同一类算法的集合以获得更好的预测性能。将几个算法组合成一个集成，使我们能够获得每个算法的最佳特性，从而覆盖单个算法中的缺点。
- en: Further reading
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Collaborative Filtering for Implicit Feedback* *Datasets*: [http://yifanhu.net/PUB/cf.pdf](B19849_08.xhtml#_idTextAnchor476)'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*隐式反馈* *数据集的协同过滤*：[http://yifanhu.net/PUB/cf.pdf](B19849_08.xhtml#_idTextAnchor476)'
- en: '*ALS Implicit Collaborative* *Filtering*: [https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe](B19849_08.xhtml#_idTextAnchor482)'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ALS隐式协同* *过滤*：[https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe](B19849_08.xhtml#_idTextAnchor482)'
- en: '*Collaborative* *Filtering*: [https://datasciencemadesimpler.wordpress.com/tag/alternating-least-squares/](B19849_08.xhtml#_idTextAnchor485)'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*协同* *过滤*：[https://datasciencemadesimpler.wordpress.com/tag/alternating-least-squares/](B19849_08.xhtml#_idTextAnchor485)'
- en: 'The `mlpack` library’s official site: [https://www.mlpack.org/](B19849_08.xhtml#_idTextAnchor488)'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlpack`库的官方网站：[https://www.mlpack.org/](B19849_08.xhtml#_idTextAnchor488)'
- en: 'The `Armadillo` library’s official site: [http://arma.sourceforge.net/](B19849_08.xhtml#_idTextAnchor489)'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Armadillo` 库的官方网站：[http://arma.sourceforge.net/](B19849_08.xhtml#_idTextAnchor489)'
- en: '*Variational Autoencoders for Collaborative Filtering,* by Dawen Liang, Rahul
    G. Krishnan, Matthew D. Hoffman, and Tony Jebara: [https://arxiv.org/abs/1802.05814](B19849_08.xhtml#_idTextAnchor492)'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于变分自编码器的协同过滤*，作者：Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, 和 Tony
    Jebara: [https://arxiv.org/abs/1802.05814](B19849_08.xhtml#_idTextAnchor492)'
- en: '*Deep Learning-Based Recommender System: A Survey and New Perspectives*, by
    Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay: [https://arxiv.org/abs/1707.07435](B19849_08.xhtml#_idTextAnchor495)'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于深度学习的推荐系统：综述与新视角*，作者：Shuai Zhang, Lina Yao, Aixin Sun 和 Yi Tay: [https://arxiv.org/abs/1707.07435](B19849_08.xhtml#_idTextAnchor495)'
- en: '*Training Deep AutoEncoders for Collaborative Filtering*, by Oleksii Kuchaiev,
    and Boris Ginsburg: [https://arxiv.org/abs/1708.01715](B19849_08.xhtml#_idTextAnchor438)'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于深度自编码器的协同过滤训练*，作者：Oleksii Kuchaiev 和 Boris Ginsburg: [https://arxiv.org/abs/1708.01715](B19849_08.xhtml#_idTextAnchor438)'
