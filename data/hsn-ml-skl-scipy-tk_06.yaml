- en: Image Processing with Nearest Neighbors
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 使用最近邻进行图像处理
- en: 'In this chapter and the following one, we are going to take a different approach.
    The nearest neighbors algorithm will take a supporting role here, while image
    processing will be the main protagonist of the chapter. We will start by loading
    images and we will use Python to represent them in a suitable format for the machine
    learning algorithms to work with. We will be using the nearest neighbors algorithm
    for classification and regression. We will also learn how to compress information
    in images into a smaller space. Many of the concepts explained here are transferable
    and can be used with other algorithms with slight tweaks. Later, in [Chapter 7](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=33&action=edit),
    *Neural**Networks - Here Comes the Deep Learning*, we will build on the knowledge
    acquired here and continue with image processing by using neural networks. In
    this chapter, we are going to cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章及随后的章节中，我们将采取不同的方法。最近邻算法将在这里担任辅助角色，而图像处理将是本章的主要内容。我们将从加载图像开始，并使用Python将它们表示为适合机器学习算法处理的格式。我们将使用最近邻算法进行分类和回归。我们还将学习如何将图像中的信息压缩到更小的空间中。这里解释的许多概念是可转移的，并且可以通过稍微调整后用于其他算法。稍后，在[第7章](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=33&action=edit)，*神经网络——深度学习的到来*中，我们将基于在这里获得的知识，继续使用神经网络进行图像处理。在本章中，我们将涵盖以下主题：
- en: Nearest neighbors
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近邻
- en: Loading and displaying images
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载和显示图像
- en: Image classification
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像分类
- en: Using custom distances
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自定义距离
- en: Using nearest neighbors for regression
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最近邻进行回归
- en: Reducing the dimensions of our image data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降维我们的图像数据
- en: Nearest neighbors
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最近邻
- en: '"We learn by example and by direct experience because there are real limits
    to the adequacy of verbal instruction."'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: “我们通过示例和直接经验来学习，因为口头指导的充分性是有限的。”
- en: – Malcolm Gladwell
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: – 马尔科姆·格拉德威尔
- en: It feels as if Malcolm Gladwell is explaining the K-nearest neighbors algorithm
    in the preceding quote; we only need to replace "*verbal instruction*" with "*mathematical
    equation*." In cases such as linear models, training data is used to learn a mathematical
    equation that models the data. Once a model is learned, we can easily put the
    training data aside. Here, in the nearest neighbors algorithm, the data itself
    is the model. Whenever we encounter a new data sample, we compare it to the training
    dataset. We locate the K-nearest samples in the training set to the newly encountered
    sample, and then we use the class labels of the K samples in the training set
    to assign a label to the new sample.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 好像马尔科姆·格拉德威尔在前述引用中解释K近邻算法；我们只需要将“*口头指导*”替换为“*数学方程*”。像线性模型这样的情况中，训练数据用于学习一个数学方程来模拟数据。一旦模型被学习，我们可以轻松地将训练数据搁置一旁。在最近邻算法中，数据本身就是模型。每当遇到一个新的数据样本时，我们将其与训练数据集进行比较。我们定位到训练集中与新样本最近的K个样本，然后使用这些K个样本的类别标签为新样本分配标签。
- en: 'A few things should be noted here:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几点需要注意：
- en: The concept of training doesn't really exist here. Unlike other algorithms,
    where the training time is dependent on the amount of training data, the computational
    cost is mostly spent in the nearest neighbors algorithm at prediction time.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练的概念在这里并不存在。与其他算法不同，在其他算法中，训练时间取决于训练数据的数量，而在最近邻算法中，计算成本大部分花费在预测时的最近邻计算上。
- en: Most of the recent research done on the nearest neighbors algorithm is focused
    on finding the optimum ways to quickly search through the training data during
    prediction time.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近关于最近邻算法的大部分研究都集中在寻找在预测时快速搜索训练数据的最佳方法。
- en: What does *nearest* mean? In this chapter, we will learn about the different
    distance measures used to compare different data points to each other. Two data
    points are deemed near to each other depending on the distance metric used.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*最近*意味着什么？在本章中，我们将学习用于比较不同数据点之间距离的不同度量方法。两个数据点是否接近彼此，取决于使用的距离度量标准。'
- en: What is *K*? We can compare a new data point to 1, 2, 3, or 50 other samples
    in the training set. The number of samples we decide to compare to is *K*, and
    we are going to see how different values of *K* affect the behavior of the algorithms.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*K*是什么？我们可以将一个新数据点与训练集中的1、2、3或50个样本进行比较。我们决定比较的样本数量就是*K*，我们将看到不同的*K*值如何影响算法的行为。'
- en: Before using the nearest neighbors algorithm for image classification, we need
    to firstlearn how to deal with images. In the next section, we will load and display
    one of the most commonly used image datasets in the field of machine learning
    and image processing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用最近邻算法进行图像分类之前，我们需要先学习如何处理图像。在接下来的章节中，我们将加载并展示机器学习和图像处理领域中最常用的图像数据集之一。
- en: When finding the nearest neighbors of a sample, you can compare it to all the
    other training samples. This is a naive brute-force approach that doesn't scale
    well with the size of the training data. A more efficient approach for larger
    datasets requires the training samples to be stored in a specific data structure
    that is optimized for search. K-D tree and ball tree are two available data structures.
    These two data structures are parameterized by `leaf_size`. As its value approaches
    the size of the training set, the K-D tree and ball tree turn into a brute-force
    search. Conversely, setting the leaf size to `1` introduces lots of overhead when
    traversing the trees. A default leaf size of `30` is good middle ground for many
    sample sizes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在查找一个样本的最近邻时，可以将其与所有其他训练样本进行比较。这是一种简单的暴力方法，当训练数据集规模增大时，效果并不好。对于更大的数据集，一种更高效的方法是将训练样本存储在一个特定的数据结构中，该数据结构经过优化以便于搜索。K-D树和球树是两种可用的数据结构。这两种数据结构通过`leaf_size`参数进行调整。当其值接近训练集的大小时，K-D树和球树就变成了暴力搜索。相反，将叶子大小设置为`1`会在遍历树时引入大量开销。默认的叶子大小为`30`，对于许多样本大小来说，这是一个不错的折中值。
- en: Loading and displaying images
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载并显示图像
- en: '"Photographs are two-dimensional. I work in four dimensions."'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: “照片是二维的。我在四维空间中工作。”
- en: – Tino Sehgal
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: – Tino Sehgal
- en: When asked about the number of dimensions that an image has, photographers,
    painters, illustrators, and almost everyone else on this planet will agree that
    images are two-dimensional objects. Only machine learning practitioners see images
    differently. For us, every pixel in a black and white image is a separate dimension.
    Dimensions expand even more with colored images, but that's something for later.
    We see each pixel as a separate dimension so that we can deal with each pixel
    and its value as a unique feature that defines the image, along with the other
    pixels (features). So, unlike*Tino Sehgal, we can sometimes end up working with
    4,000 dimensions.*
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当被问到图像的维度时，摄影师、画家、插画家以及几乎地球上所有人都会认为图像是二维的物体。只有机器学习从业者会从不同的角度看待图像。对我们来说，黑白图像中的每个像素都是一个单独的维度。随着彩色图像的出现，维度会进一步增加，但那是后话。我们将每个像素视为一个单独的维度，以便我们能够将每个像素及其值当作定义图像的独特特征，与其他像素（特征）一起处理。所以，和*Tino
    Sehgal*不同，我们有时会处理4000维。
- en: '*The **ModifiedNational Institute****of** **Standards****and** **Technology**(**MNIST**)
    dataset is a collection of handwritten digits that is commonly used inimage processing.
    Due to its popularity, it is included in `scikit-learn`, and we can load it as
    we usually do with other datasets:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**修改后的国家标准与技术研究院**（**MNIST**）数据集是一个手写数字的集合，通常用于图像处理。由于其受欢迎程度，它被包含在`scikit-learn`中，我们可以像通常加载其他数据集一样加载它：'
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The dataset has digits from `0` to `9`. We can access their targets (labels)
    as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集包含从`0`到`9`的数字。我们可以通过以下方式访问它们的目标（标签）：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Similarly, we can load the pixel values, as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以加载像素值，如下所示：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Each line is a picture and each integer is a pixel value. In this dataset, the
    pixels take values between `0` and `16`. The shape of the dataset (`digits['data'].shape`)
    is *1,797 x 64*. In other words, we have 1,797 square-shaped pictures, and each
    of them has 64 pixels (width = height = 8).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 每一行是一个图像，每一个整数是一个像素值。在这个数据集中，像素值的范围在`0`到`16`之间。数据集的形状（`digits['data'].shape`）是*1,797
    x 64*。换句话说，我们有1,797张方形的图片，每张图片有64个像素（宽度 = 高度 = 8）。
- en: 'Knowing this information, we can create the following function to display an
    image. It takes an array of 64 values and reshapes it into a two-dimensional array
    with 8 rows and 8 columns. It also uses the corresponding target of the image
    to show on top of the digit. The `matplotlib` axis (`ax`) is given so that we
    can display the image on it:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 知道了这些信息后，我们可以创建以下函数来显示图像。它接受一个64个值的数组，并将其重塑成一个8行8列的二维数组。它还使用图像的对应目标值，在数字上方显示。`matplotlib`的坐标轴（`ax`）被传入，这样我们就可以在其上显示图像：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can now use the function we just created to display the first eight digits
    of our dataset:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用刚才创建的函数来显示数据集中的前八个数字：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The digits look as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 数字显示如下：
- en: '![](img/a162711f-176a-4239-bc38-b37cc6ecee3f.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a162711f-176a-4239-bc38-b37cc6ecee3f.png)'
- en: 'Being able to display the digits is a good first step. Next, we need to convert
    them into our usual training and test formats. This time, we want to keep each
    image as one row, so there is no need to reshape it into *8 x 8* matrices:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 能够显示数字是一个很好的第一步。接下来，我们需要将它们转换为我们通常的训练和测试格式。这次，我们希望将每张图片保留为一行，因此不需要将其重塑为*8 x
    8*矩阵：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: At this point, the data is ready to be used with an image classification algorithm.
    By learning to predict the targets when given a bunch of pixels, we are already
    one step closer to making our computer understand the handwritten text.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，数据已经准备好用于图像分类算法。通过学习在给定一堆像素时预测目标，我们已经离让计算机理解手写文本更近了一步。
- en: Image classification
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像分类
- en: 'Now that we have our data ready, we can predict the digits using the nearest
    neighbors classifier, as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了数据，可以使用最近邻分类器来预测数字，如下所示：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For this example, I set `n_neighbors` to `11` and `metric` to `manhattan`, meaning
    at prediction time, we compare each new sample to the 11 nearest training samples,
    using the Manhattan distance to evaluate how near they are. More on these parameters
    in a bit. This model made predictions with an accuracy of 96.4% on the test set.
    This might sound reasonable, but I'm sorry to break it to you; this isn't a fantastic
    score for this particular dataset. Anyway, let's keep on dissecting the model's
    performance further.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我将`n_neighbors`设置为`11`，`metric`设置为`manhattan`，意味着在预测时，我们将每个新样本与11个最接近的训练样本进行比较，使用曼哈顿距离来评估它们的接近程度。稍后会详细讲解这些参数。该模型在测试集上的预测准确率为96.4%。这听起来可能很合理，但很抱歉告诉你，这对于这个特定的数据集来说并不是一个很棒的得分。无论如何，我们继续深入分析模型的表现。
- en: Using a confusion matrix to understand the model's mistakes
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用混淆矩阵理解模型的错误
- en: 'When dealing with a dataset with 10 class labels, a single accuracy score can
    only tell us so much. To better understand what digits were harder to guess than
    others, we can print the model''s confusion matrix. This is a square matrix where
    the actual labels are shown as rows and the predicted labels are shown as columns.
    Then, the numbers in each cell show the testing instances that fell into it. Let
    me create it now, and it will become clearer in a moment. The `plot_confusion_matrix`
    function needs the classifier''s instance, along with the test''s `x` and `y`
    values, to display the matrix:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理具有10个类别标签的数据集时，单一的准确率得分只能告诉我们一些信息。为了更好地理解哪些数字比其他数字更难猜测，我们可以打印出模型的混淆矩阵。这是一个方阵，其中实际标签作为行显示，预测标签作为列显示。然后，每个单元格中的数字表示落入该单元格的测试实例。让我现在创建它，很快你就能看得更清楚。`plot_confusion_matrix`函数需要分类器实例，以及测试的`x`和`y`值，才能显示矩阵：
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Once called, the function runs the model internally on the test data and displays
    the following matrix:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦调用，该函数会在内部对测试数据运行模型，并显示以下矩阵：
- en: '![](img/3cfef06e-3d56-4368-941f-b71cbb4f47a1.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3cfef06e-3d56-4368-941f-b71cbb4f47a1.png)'
- en: Ideally, all the cells should have zeros, except for the diagonal cells. Falling
    into a diagonal cell means that a sample is correctly labeled. However, there
    are only a few non-zero cells here. The four samples at the intersection of row
    8 and column 1 signify that our model has classified four samples as `1`, while
    their actual label was `8`. Most likely, those were too-skinny eights that looked
    like ones to the algorithm. The same conclusions can be made for the remaining
    non-diagonal non-zero cells.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，所有单元格应为零，除了对角线上的单元格。落入对角线单元格意味着样本被正确标记。然而，这里只有少数几个非零单元格。位于第8行和第1列交点的四个样本表明，我们的模型将四个样本分类为`1`，而它们的实际标签是`8`。很可能，它们是看起来像1的过于瘦弱的8。对于其余的非对角线非零单元格，也可以得出相同的结论。
- en: Picking a suitable metric
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择合适的度量标准
- en: 'The images we are using are just lists of numbers (vectors). The distance metric
    decides whether one image is close to another. This also applies to non-image
    data, where distance metrics are used to decide whether one sample is close to
    another. Two commonly used metrics are the **M****anhattan** and**Euclidean**
    distances:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的图像只是数字列表（向量）。距离度量决定了一个图像是否接近另一个图像。这同样适用于非图像数据，其中距离度量用于决定一个样本是否接近另一个样本。两种常用的度量标准是**曼哈顿**距离和**欧几里得**距离：
- en: '| **Name** | **Manhattan (L1 norm)** | **Euclidean (L2 norm)** |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **曼哈顿（L1范数）** | **欧几里得（L2范数）** |'
- en: '| Formula | **![](img/e2930e27-c687-4f0f-b3bc-18888a658497.png)**  | **![](img/d4b9a9b8-1441-4eb6-8865-032cdb4295a5.png)**  |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 公式 | **![](img/e2930e27-c687-4f0f-b3bc-18888a658497.png)**  | **![](img/d4b9a9b8-1441-4eb6-8865-032cdb4295a5.png)**  |'
- en: 'Most likely, the equation for the Manhattan distance will remind you of the
    mean absolute error and L1 regularization, while the Euclidean distance resembles
    the mean squared error and L2 regularization. This resemblance is a nice reminder
    of how many concepts stem from common ideas:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，曼哈顿距离的公式会让你想起平均绝对误差和L1正则化，而欧几里得距离则类似于均方误差和L2正则化。这种相似性很好地提醒我们，许多概念都来源于共同的思想：
- en: '![](img/0a526191-f4f1-42b4-acbb-be335c7273f7.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0a526191-f4f1-42b4-acbb-be335c7273f7.png)'
- en: 'For the **M****anhattan** distance, the distance between A and C is calculated
    by going from A to D, and then from D to C. It gets its name from Manhattan Island
    in New York, where its landscape is divided into blocks. For the **Euclidean**
    distance, the distance between A and C is calculated via the diagonal line between
    the two points. There is a generalized form for the two metrics, called the **Minkowski**
    distance, and here is its formula:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**曼哈顿**距离，A和C之间的距离是通过从A到D，再从D到C来计算的。它得名于纽约的曼哈顿岛，因为那里有着分块的景观。对于**欧几里得**距离，A和C之间的距离是通过两点之间的对角线来计算的。这两种度量有一个广义的形式，叫做**闵可夫斯基**距离，其公式如下：
- en: '![](img/848895b2-14e8-47d2-97fb-6996b9c61839.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/848895b2-14e8-47d2-97fb-6996b9c61839.png)'
- en: 'Setting `p` to `1` gives us the Manhattan distance, and we can get the Euclidean
    distance by setting it to `2`. I am sure you can tell now where `1` and `2` in
    the L1 and L2 norms come from. To be able to compare the different values of `p`,
    we can run the following code. Here, we calculate the Minkowski distance for the
    two points—`(1, 2)` and `(4, 6)`—for different values of `p`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 设置`p`为`1`时，我们得到曼哈顿距离，设置为`2`时可以得到欧几里得距离。我相信你现在可以看出，L1和L2范数中的`1`和`2`来自哪里。为了能够比较不同`p`值的结果，我们可以运行以下代码。在这里，我们计算了两点之间的闵可夫斯基距离——`(1,
    2)`和`(4, 6)`——对于不同`p`值的情况：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Plotting the results shows us how the Minkowski distance changes with `p`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制结果可以显示出闵可夫斯基距离如何随`p`变化：
- en: '![](img/969974fd-d414-48a7-b0af-3afff2ebe68f.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/969974fd-d414-48a7-b0af-3afff2ebe68f.png)'
- en: Clearly, the Minkowski distance decreases with an increase in `p`. For `p =
    1`, the distance is `7`, `(4 - 1) + (6 - 2)`, and for `p = 2`, the distance is
    `5`, the square root of `(9 + 16)`. For higher values of `p`, the distance calculated
    approaches `4`, which is `(6 - 2)` only. In other words, as `p` approaches infinity,
    the distance is just the maximum of all the spans between the points on all the
    axes, which is known as the Chebyshev distance.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，闵可夫斯基距离随着`p`的增加而减小。对于`p = 1`，距离为`7`，即`(4 - 1) + (6 - 2)`，而对于`p = 2`，距离为`5`，即`(9
    + 16)`的平方根。对于更大的`p`值，计算出的距离接近`4`，也就是`(6 - 2)`。换句话说，随着`p`趋近于无穷大，距离就是所有坐标轴上点间跨度的最大值，这就是所谓的切比雪夫距离。
- en: 'The term *metric* is used to describe a distance measure that follows the following
    criteria:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*度量*一词用来描述符合以下标准的距离度量：'
- en: 'It cannot be negative: ![](img/e1e821f0-1c45-4c76-9137-9850474e9a52.png), and
    it is symmetric: ![](img/b98b8d27-e50e-4273-a005-ca7dbb7b1e35.png).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 它不能是负值：![](img/e1e821f0-1c45-4c76-9137-9850474e9a52.png)，并且它是对称的：![](img/b98b8d27-e50e-4273-a005-ca7dbb7b1e35.png)。
- en: 'The distance from one point to itself is 0\. It follows the following triangle
    inequality criterion: ![](img/73493af6-edf4-40b2-ad39-bf4f833fc034.png).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从一个点到它自身的距离是0。它遵循以下三角不等式准则：![](img/73493af6-edf4-40b2-ad39-bf4f833fc034.png)。
- en: 'Another common metric is the **cosine** distance, and its formula is as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见的度量是**余弦**距离，其公式如下：
- en: '![](img/d1e22299-fe13-4583-b408-d19e09b01940.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d1e22299-fe13-4583-b408-d19e09b01940.png)'
- en: Unlike the Euclidean distance, the cosine distance is scale-insensitive. I think
    it would be better to show the difference between the two metrics with the following
    example.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 与欧几里得距离不同，余弦距离对尺度不敏感。我认为通过以下示例展示两者的区别会更好。
- en: 'Here, we take one digit and multiply each pixel value by `2`:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们取一个数字并将每个像素值乘以`2`：
- en: '![](img/d95898c9-60d8-4961-bc9a-db69578ee328.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d95898c9-60d8-4961-bc9a-db69578ee328.png)'
- en: 'Now, let''s calculate the distances between the original image and the intensified
    one:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来计算原始图像和强化图像之间的距离：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Running the preceding code gives us the values for each distance—Manhattan =
    `294`, Euclidean = `55.41`, and cosine = `0`. As expected, the cosine distance
    does not care about the constant we used to multiply the pixels with, and it considers
    the two versions of the same images as one. The other two metrics, on the other
    hand, saw the two versions as further apart.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码给我们每个距离的值——曼哈顿距离 = `294`，欧氏距离 = `55.41`，余弦距离 = `0`。如预期，余弦距离不关心我们用来乘以像素的常数，并且它将两个相同图像的版本视为一样。另外两个度量标准则认为这两个版本之间有更大的距离。
- en: Setting the correct K
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置正确的K
- en: 'Equally important to metric selection is knowing how many neighbors to listen
    to when making a decision. You don''t want to ask too few neighbors as maybe they
    don''t know enough. You also don''t want to ask everyone as the very distant neighbors
    probably don''t know much about the sample at hand. To put it formally, a decision
    made based on too few neighbors introduces variance since any slight changes in
    the data will result in different neighborhoods and different results. Conversely,
    a decision made based on too many neighbors is a biased decision as it is less
    sensitive to the differences between the neighborhoods. Keep this in mind. Here,
    I used the model with different settings for *K* and plotted the resulting accuracy:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择度量标准同样重要的是知道在做决定时要听取多少个邻居的意见。你不希望询问太少的邻居，因为他们可能了解不足。你也不希望问每个人，因为远距离的邻居可能对手头的样本了解不多。正式地说，基于过少邻居做出的决定会引入方差，因为数据的轻微变化会导致不同的邻域和不同的结果。相反，基于过多邻居做出的决定是有偏的，因为它对邻域之间的差异不太敏感。请记住这一点。在这里，我使用了不同*K*设置的模型，并绘制了结果准确度：
- en: '![](img/532bfe59-376d-4d7e-a533-4eb75efc66df.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/532bfe59-376d-4d7e-a533-4eb75efc66df.png)'
- en: The concept of bias-variance trade-off will follow us throughout this book.
    When it comes to picking sides, we usually opt to use a biased model when we have
    smaller training sets. A high-variance model will overfit if there isn't enough
    data to learn from. The most biased model is one where *K* is set to the number
    of training samples. Then, all the new data points will get the same prediction
    and will be assigned to the same label as the majority class. Conversely, when
    we have a good amount of data, the few closest neighbors within a smaller radius
    are a better choice to consult, as it's more likely that they will belong to the
    same class as our new sample.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差-方差权衡的概念将贯穿本书始终。在选择方向时，通常在训练集较小时选择使用有偏模型。如果没有足够的数据进行学习，高方差模型会过拟合。最偏差的模型是当*K*设置为训练样本数时。然后，所有新数据点将得到相同的预测，并被分配给与多数类相同的标签。相反，当我们有足够的数据时，较小半径内的少数最近邻是更好的选择，因为它们更有可能属于与我们新样本相同的类。
- en: 'Now, we have two hyperparameters to set: the number of neighbors and the distance
    metrics. In the next section, we are going to use a grid search to find the optimum
    values for these parameters.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有两个超参数需要设置：邻居数量和距离度量。在接下来的部分，我们将使用网格搜索来找到这些参数的最佳值。
- en: Hyperparameter tuning using GridSearchCV
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用GridSearchCV进行超参数调整
- en: '`GridSearchCV` is a method for looping over all the possible hyperparameter
    combinations and employing cross-validation to pick the optimum hyperparameters.
    For each hyperparameter combination, we do not want to limit ourselves to just
    one accuracy score. So, to get a better understanding of the estimator''s accuracy
    of each combination, we make use of K-fold cross-validation. Then, the data is
    split into a number of folds, and for each iteration, all folds but one are used
    for training, and the remaining one is used for testing. This method for hyperparameter
    tuning performs an exhaustive search over all possible parameter combinations,
    hence the `Grid` prefix. In the following code, we give `GridSearchCV` a Python
    dictionary with all the parameter values we want to loop over, as well as the
    estimator we want to tune. We also specify the number of folds to split the data
    into, and then we call the grid search''s `fit` method with the training data.
    Remember, it is bad practice to learn anything from the test dataset, which should
    be kept aside for now. Here is the code to do this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`GridSearchCV`是一种遍历所有可能的超参数组合并使用交叉验证来选择最佳超参数的方法。对于每个超参数组合，我们并不想仅限于一个准确度得分。为了更好地理解每个组合的估算器准确性，我们使用K折交叉验证。然后，数据会被分割成若干折，在每次迭代中，除了一个折用于训练外，剩下的折用于测试。这个超参数调优方法对所有可能的参数组合进行穷举搜索，因此使用了`Grid`前缀。在下面的代码中，我们给`GridSearchCV`传入一个包含所有需要遍历的参数值的Python字典，以及我们想要调优的估算器。我们还指定了将数据划分成的折数，然后调用网格搜索的`fit`方法并传入训练数据。请记住，从测试数据集中学习任何内容是一个不好的做法，测试集应该暂时被保留。以下是实现这一过程的代码：'
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Once done, we can show the best parameters found via `gscv.best_params_`. We
    can also show the accuracy achieved when using the chosen parameter via `gscv.best_score_`.
    Here, the `euclidean` distance was chosen as `metric` and `n_neighbors` was set
    to `3`. I also got an accuracy score of 98.7% when using the chosen hyperparameters.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们可以通过`gscv.best_params_`显示通过`GridSearchCV`找到的最佳参数。我们还可以通过`gscv.best_score_`显示使用所选参数时得到的准确度。在这里，选择了`euclidean`距离作为`metric`，并将`n_neighbors`设置为`3`。在使用所选超参数时，我还得到了98.7%的准确度得分。
- en: 'We can now use the resulting classifier to make predictions for the test set:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用得到的分类器对测试集进行预测：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This gave me an accuracy of 98.0% on the test set. Luckily, the grid search
    helped us improve the accuracy of our estimator by picking the optimum hyperparameters.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我在测试集上的准确度达到了98.0%。幸运的是，网格搜索帮助我们通过选择最佳超参数来提高了估算器的准确度。
- en: '`GridSearchCV` can become computationally expensive if we have too many hyperparameters
    to search through and too many values for each one. When facing a problem like
    this,`RandomizedSearchCV` may be an alternative solution since it randomly picks
    hyperparameter values while searching. Both hyperparameter tuning algorithms use
    the `accuracy` score by default for classifiers and `R`^(`2`)for regressors. We
    can override this and specify different metrics to pick the best configuration.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`GridSearchCV`在我们需要搜索过多的超参数并且每个超参数有太多值时，会变得计算上非常昂贵。面对这种问题时，`RandomizedSearchCV`可能是一个替代的解决方案，因为它在搜索过程中会随机选择超参数值。两种超参数调优算法默认都使用分类器的`accuracy`得分和回归器的`R`^(`2`)得分。我们可以覆盖默认设置，指定不同的度量标准来选择最佳配置。'
- en: Using custom distances
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自定义距离
- en: 'The digits here are written in white pixels over a black background. I don''t
    think anyone would have a problem with identifying a digit if it was written in
    black pixels over a white background instead. As for a computer algorithm, things
    are a little different. Let''s train our classifier as usual and see whether it
    will have any issues if the colors are inverted. We will start by training the
    algorithm on the original images:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的数字是以白色像素写在黑色背景上的。如果数字是用黑色像素写在白色背景上，我想没有人会有问题识别这个数字。对于计算机算法来说，情况则有些不同。让我们像往常一样训练分类器，看看当颜色反转时，它是否会遇到任何问题。我们将从训练原始图像开始：
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We then create an inverted version of the data we have just used for training:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建了刚刚用于训练的反转数据版本：
- en: '[PRE13]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The nearest neighbors implementation has a method called `kneighbors`. When
    given a sample, it returns a list of the K-nearest samples to it from the training
    set, as well as their distances from the given sample. We are going to give this
    method one of the inverted samples and see which samples it will consider as its
    neighbors:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻实现有一个叫做`kneighbors`的方法。给定一个样本，它会返回训练集中与该样本最接近的K个样本及其与给定样本的距离。我们将给这个方法传递一个反转的样本，并观察它会将哪些样本视为邻居：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Just to make things clearer, I ran the code twice—once with the original sample
    and its seven neighbors, and once with the inverted sample and its neighbors.
    The output of the two runs is displayed here. As you can see, unlike us humans,
    the algorithm got totally confused by the adversarial example where the colors
    were inverted:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让事情更清晰，我运行了代码两次——一次使用原始样本及其七个邻居，另一次使用反转样本及其邻居。两次运行的输出结果如下所示。正如你所看到的，与我们人类不同，算法在处理颜色反转的对抗样本时完全混淆了：
- en: '![](img/2d65bf56-335e-41e9-b2c0-7d5f06cdca14.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2d65bf56-335e-41e9-b2c0-7d5f06cdca14.png)'
- en: If you think about it, according to the distance we use, a sample and its inverted
    version cannot be too much further from each other. Although we visually see the
    two as one, the model sees them as different as day and night. Having that said,
    it is clear that we need to come up with a different way to evaluate distances.
    Since pixels take values between `0` and `16`, in an inverted sample, all of the
    16s are turned into 0s, the 15s are turned into 1s, and so on. Therefore, a distance
    that compares samples in relation to how far their pixels are from the midpoint
    between `0` and `16` (`8`) can help us solve our problem here. Here is how to
    create this custom distance. Let's call our new distance `contrast_distance`***:***
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想一想，根据我们使用的距离度量，一个样本及其反转版本之间不应该相差太远。虽然我们从视觉上将它们视为同一个样本，但模型却将它们视为天壤之别。话虽如此，很显然我们需要找到一种不同的方式来评估距离。由于像素的值在`0`和`16`之间变化，在反转样本中，所有的16都变成了0，15变成了1，以此类推。因此，一种比较样本之间像素与`0`和`16`之间中点（即`8`）距离的度量可以帮助我们解决这里的问题。下面是如何创建这种自定义距离的方法。我们将这种新距离称为`contrast_distance`***：***
- en: '[PRE15]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Once defined, we can use the custom metric in our classifier, as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义完毕，我们可以在分类器中使用自定义度量，如下所示：
- en: '[PRE16]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'After this tweak, the inversion doesn''t bother the model anymore. For the
    original and the inverted sets, we get the exact same accuracy of 89.3%. We can
    also print the seven nearest neighbors according to the new metric to validate
    the fact that the new model is alreadysmarter and no longer discriminates against
    the black digits:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 经过这个调整后，反转对模型不再造成困扰。对于原始样本和反转样本，我们得到了相同的89.3%准确率。我们还可以根据新的度量标准打印出七个最近邻，验证新模型已经更聪明，并且不再歧视黑色数字：
- en: '![](img/0182aaa3-96f7-4660-8d3a-813ef9a4b70a.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0182aaa3-96f7-4660-8d3a-813ef9a4b70a.png)'
- en: One thing to keep in mind when writing your own custom distances is that they
    are not as optimized as the built-in ones, and running the algorithm will be more
    computationally expensive at prediction time.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 编写自定义距离时需要记住的一件事是，它们不像内置的度量那样优化，因此在预测时运行算法将会更耗费计算资源。
- en: Using nearest neighbors for regression
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用最近邻回归
- en: 'At the end of the day, the targets we predict in the MNIST dataset are just
    numbers between 0 and 9\. So, we can alternatively use a regressor algorithm for
    the same problem. In this case, our predictions will not be integers anymore,
    but rather floats. Training the regressor isn''t much different from training
    the classifier:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 到头来，我们在MNIST数据集中预测的目标只是0到9之间的数字。所以，我们可以改用回归算法来解决同样的问题。在这种情况下，我们的预测不再是整数，而是浮动值。训练回归器与训练分类器没有太大区别：
- en: '[PRE17]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here are some of the incorrectly made predictions:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些错误的预测结果：
- en: '![](img/0d85cc59-f732-415d-8c35-6edd0eb53706.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0d85cc59-f732-415d-8c35-6edd0eb53706.png)'
- en: The first item's three nearest neighbors are `3`, `3`, and `5`. So, the regressor
    used their mean (`3.67`) as the prediction. The second and third items' neighbors
    are `8, 9, 8` and `7, 9, 7`, respectively. Remember to round these predictions
    and convert them into integers if you want to use a classifier's evaluation metric
    to evaluate this model.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 第一项的三个最近邻分别是`3`、`3`和`5`。因此，回归器使用它们的平均值（`3.67`）作为预测结果。第二项和第三项的邻居分别是`8, 9, 8`和`7,
    9, 7`。记得如果你想用分类器的评估指标来评估这个模型，应该将这些预测四舍五入并转换成整数。
- en: More neighborhood algorithms
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多的邻域算法
- en: There are other variations of K-nearest neighbors that I'd like to quickly go
    through before moving on to the next section. These algorithms are less commonly
    used, although they have their merits as well as certain disadvantages.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我想在进入下一部分之前，快速介绍一些K近邻算法的其他变种。这些算法虽然不太常用，但它们也有自己的优点和某些缺点。
- en: Radius neighbors
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 半径邻居
- en: Contrary to the K-nearest neighbors algorithm, where a certain number of neighbors
    are allowed to vote, in radius neighbors, all the neighbors within a certain radius
    participate in the voting process. By setting a predefined radius, the decisions
    in sparser neighborhoods are based on fewer neighbors than the ones made in denser
    neighborhoods. This can be useful when dealing with imbalanced classes. Furthermore,
    by using the haversine formula as our metric, we can use this algorithm to recommend
    nearby venues or gas stations on a map to the users. Both radius neighbors and
    K-nearest neighbors can give closer data points more voting power than distant
    ones by specifying the algorithm's `weights` parameter.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 与K近邻算法不同，后者允许一定数量的邻居进行投票，而在半径邻居算法中，所有在一定半径内的邻居都会参与投票过程。通过设置预定义的半径，稀疏区域的决策将基于比密集区域更少的邻居进行。这在处理不平衡类别时可能非常有用。此外，通过使用哈弗辛公式作为我们的度量标准，我们可以使用此算法向用户推荐附近的场所或加油站。通过指定算法的`weights`参数，半径邻居和K近邻都可以给予距离较近的数据点比远离的数据点更多的投票权。
- en: Nearest centroid classifier
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最近质心分类器
- en: As we have seen, the K-nearest neighbors algorithm compares the test samples
    to all of the samples in the training set. This exhaustive search causes the model
    to become slower at prediction time. To deal with this, the nearest centroid classifier
    summarizes all the training samples from each class into a pseudo-sample that
    represents this class. This pseudo-sample is called the centroid as it is typically
    created by calculating the mean value for each of the features in a class. At
    prediction time, a test sample is compared to all the centroids and is classified
    based on the class whose centroid is closest to it.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，K近邻算法将测试样本与训练集中的所有样本进行比较。这种全面搜索导致模型在预测时变得更慢。为了解决这个问题，最近中心分类器将每个类别的所有训练样本总结为一个伪样本，这个伪样本代表了该类别。这个伪样本被称为质心，因为它通常通过计算该类别中每个特征的平均值来创建。在预测时，测试样本会与所有质心进行比较，并根据与其最接近的质心所属的类别进行分类。
- en: 'In the next section, we are going to use the centroid algorithm for training
    and prediction, but for now, we are going to use it to generate new digits just
    for fun. The algorithm is trained as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将使用质心算法进行训练和预测，但现在，我们将用它来生成新的数字，仅仅是为了好玩。算法的训练过程如下：
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The learned centroids are stored in `centroids_`. The following code displays
    these centroids, along with the class labels:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 学到的质心存储在`centroids_`中。以下代码显示这些质心以及类别标签：
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The generated digits are shown here:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的数字如下所示：
- en: '![](img/d40db71c-3169-4c18-8545-9756abdc83a6.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d40db71c-3169-4c18-8545-9756abdc83a6.png)'
- en: These digits do not exist in our dataset. They are just combinations of all
    the samples in each class.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数字在我们的数据集中并不存在。它们只是每个类别中所有样本的组合。
- en: The nearest centroid classifier is fairly simple, and I am sure you can implement
    it from scratch using a few lines of code. Its accuracy is not as good as nearest
    neighbors for the MNIST dataset, though. The centroid algorithm is more commonly
    used in natural language processing, where it's better known as Rocchio (pronounced
    like "we will rock you").
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最近质心分类器相当简单，我相信你可以通过几行代码从头实现它。不过，它的准确度在MNIST数据集上不如最近邻算法。质心算法在自然语言处理领域中更为常见，在那里它更为人知的是Rocchio（发音类似于“we
    will rock you”）。
- en: Finally, the centroid algorithm also has a hyperparameter called `shrink_threshold`.
    When set, this can help to remove the irrelevant features.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，质心算法还有一个超参数，叫做`shrink_threshold`。当设置时，这可以帮助去除无关特征。
- en: Reducing the dimensions of our image data
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 降低我们图像数据的维度
- en: Earlier, we realized that the dimensionality of an image is equal to the number
    of pixels in it. So, there is no way to visualize our 43-dimensional MNIST dataset.
    It is true that we can display each digit separately, yet we cannot see where
    each image falls in our feature space. This is important to understand the classifier's
    decision boundaries. Furthermore, an estimator's memory requirements grow in proportion
    to the number of features in the training data. As a result, we need a way to
    reduce the number of features in our data to deal with the aforementioned issues.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们意识到图像的维度等于图像中的像素数量。因此，我们无法将我们的43维MNIST数据集可视化。确实，我们可以单独展示每个数字，但无法看到每个图像在特征空间中的位置。这对于理解分类器的决策边界非常重要。此外，估计器的内存需求随着训练数据中特征数量的增加而增长。因此，我们需要一种方法来减少数据中特征的数量，以解决上述问题。
- en: 'In this section, we are going to discover two dimensionality-reduction algorithms:
    **Principal Component Analysis** (**PCA**) and **Neighborhood Component Analysis**
    (**NCA**). After explaining them, we will use them to visualize the MNIST dataset
    and generate additional samples to add to our training set. Finally, we will also
    use **feature selection** algorithms to remove non-informative pixels from our
    images.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将介绍两种降维算法：**主成分分析**（**PCA**）和**邻域成分分析**（**NCA**）。在解释这些方法后，我们将使用它们来可视化MNIST数据集，并生成额外的样本以加入我们的训练集。最后，我们还将使用**特征选择**算法，从图像中去除无信息的像素。
- en: Principal component analysis
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主成分分析
- en: '"A good photograph is knowing where to stand."'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '"一张好照片是知道站在哪里。"'
- en: –Ansel Adams
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: – 安塞尔·亚当斯
- en: 'Imagine having the following set of data with two features—`x1` and `x2`:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有以下两个特征的数据集——`x1`和`x2`：
- en: '![](img/f7abe53f-e78e-4b77-a1e6-36a96a374ec7.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f7abe53f-e78e-4b77-a1e6-36a96a374ec7.png)'
- en: 'You can generate a previous data frame by using the following code snippet,
    keeping in mind that the numbers may vary on your machine, given their randomness:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下代码片段生成一个之前的数据框，记住，由于其随机性，数字在你的机器上可能会有所不同：
- en: '[PRE20]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'When we plot the data, we realize that `x1` and `x2` take the following form:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们绘制数据时，我们会发现`x1`和`x2`呈现出如下的形式：
- en: '![](img/c3c020b0-d3cd-4f75-b10b-9f3e2fefdb78.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c3c020b0-d3cd-4f75-b10b-9f3e2fefdb78.png)'
- en: If you want, you can tilt your head to the left. Now, imagine we did not have
    the `x1` and `x2` axes, but instead had one diagonal axis that goes through the
    data. Wouldn't that axis be enough to represent our data? Then, we would have
    reduced it from a two-dimensional dataset into a one-dimensional dataset. That's
    exactly what PCA tries to achieve.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你愿意，可以把头偏向左边。现在，想象一下我们没有`x1`和`x2`轴，而是有一个通过数据的对角线轴。那条轴是否足以表示我们的数据呢？这样，我们就将其从一个二维数据集降维到一个一维数据集。这正是PCA试图实现的目标。
- en: This new axis has one main characteristic—the distances between the points on
    it are more than their distances on the `x1` or `x2` axes. Remember, the hypotenuse
    of a triangle is always bigger than any of the two other sides. In conclusion,
    PCA tries to find a set of new axes (principal components) where the data variance
    is maximized.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新轴有一个主要特点——轴上点与点之间的距离大于它们在`x1`或`x2`轴上的距离。记住，三角形的斜边总是大于其他两边中的任何一边。总之，PCA试图找到一组新的轴（主成分），使得数据的方差最大化。
- en: 'Just like in the case of the correlation coefficient equation discussed in
    [Chapter 4](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=27&action=edit),
    *Preparing Your Data*, PCA also needs the data to be centered. For each column,
    we subtract the mean of the column from each value in it. We can use the`with_std
    =False` standard scaler to achieve this. Here is how to calculate the PCA and
    convert our data into the new dimensions:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在[第4章](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=27&action=edit)中讨论的相关系数方程一样，*准备数据*，PCA也需要数据进行中心化。对于每一列，我们将该列的均值从每个值中减去。我们可以使用`with_std=False`的标准化缩放器来实现这一点。以下是如何计算PCA并将我们的数据转换为新维度的过程：
- en: '[PRE21]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The resulting `x_new` value is a single column data frame instead of two. We
    can also access the newly created component via `pca.components_`. Here, I plotted
    the new component over the original data:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的`x_new`值是一个单列数据框，而不是两个。我们也可以通过`pca.components_`访问新创建的组件。在这里，我将新组件与原始数据一起绘制出来：
- en: '![](img/fc219789-a691-4219-8947-664a480ba334.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fc219789-a691-4219-8947-664a480ba334.png)'
- en: As you can see, we were able to use the PCA algorithm to reduce the number of
    features here from two to one. Since the dots don't fall exactly on the line,
    some information is lost by only using one component. This information is stored
    in the second component that we did not retrieve. You can transform your data
    into any number of components from one up to the original number of features.
    The components are ordered descendingly according to the amount of information
    they carry. Therefore, ignoring the latter components may help to remove any noisy
    and less-useful information. Aftertransforming the data, it can also be transformed
    back (inverse transformation). The resulting data after the two operations only
    matches the original data if all the components are retained; otherwise, we can
    limit ourselves to the first few (principal) components to denoise the data.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们能够使用PCA算法将特征的数量从两个减少到一个。由于点并没有完全落在直线上，仅使用一个成分会丢失一些信息。这些信息存储在我们没有提取的第二个成分中。你可以将数据转换为从一个到原始特征数目的任何数量的成分。成分根据它们所包含的信息量降序排列。因此，忽略后续成分可能有助于去除任何噪声和不太有用的信息。数据经过转换后，也可以进行反向转换（逆变换）。只有在保留所有成分的情况下，经过这两步操作得到的数据才与原始数据匹配；否则，我们可以仅限于前几个（主要）成分来去噪数据。
- en: In the PCA assumption, the directions in the feature space with the highest
    variance are expected to carry more information than the directions with lower
    variance. This assumption may hold in some cases, but it is not guaranteed to
    always be true. Remember that in PCA, the target is not used, only the features.
    This makes it more suitable for unlabeled data.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在PCA假设中，特征空间中方差最大的方向预计携带比方差较小的方向更多的信息。这个假设在某些情况下可能成立，但并不总是成立。请记住，在PCA中，目标变量不被使用，只有特征变量。这使得它更适合无标签数据。
- en: Neighborhood component analysis
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 邻域成分分析
- en: In the nearest neighbors algorithms, the choice of the distance measure is paramount,
    yet it is only set empirically. We used K-fold cross-validation earlier in this
    chapter to decide which distance metric is better for our problem. This can be
    time-consuming, which triggers many researchers to look for better solutions.
    The main aim of NCA is to learn the distance metric from the data using gradient
    descend. The distances it tries to learn are usually represented by a square matrix.
    For *N* samples, we have ![](img/73d8334b-b8ad-4011-9da8-370f39c173c7.png) sample
    pairs to compare, hence the square matrix. Nevertheless, this matrix can be restricted
    to become a rectangular one, ![](img/64dcd70b-19c0-4a61-bf66-5ed6bc1db006.png),
    where the small *n* is a lower number than *N* and represents the reduced components.
    These reduced components are the building blocks of NCA.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近邻算法中，距离度量的选择至关重要，但通常是通过经验设定的。我们在本章前面使用了K折交叉验证来决定哪种距离度量更适合我们的任务。这个过程可能比较耗时，这也促使许多研究人员寻找更好的解决方案。NCA的主要目标是通过梯度下降从数据中学习距离度量。它尝试学习的距离通常用一个方阵表示。对于*N*个样本，我们有
    ![](img/73d8334b-b8ad-4011-9da8-370f39c173c7.png) 个样本对需要比较，因此是方阵。然而，这个矩阵可以被限制为一个矩形矩阵，![](img/64dcd70b-19c0-4a61-bf66-5ed6bc1db006.png)，其中小*n*是比*N*小的数字，表示降维后的成分。这些降维后的成分是NCA的基础构建块。
- en: The nearest neighbors algorithms belong to a class of learners called instance-based
    learners. We use instances of the training set to make decisions. So, the matrix
    that carries the distances between the instances is an essential part of it. This
    matrix inspired many researchers to do research on it. For example, learning the
    distances from data is what NCA and large-margin nearest neighbors do; other researchers
    converted this matrix into a higher dimensional space—for example, with the kernel
    trick—and others tried to embed feature selection into the instance-based learners
    via regularization.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻算法属于一种称为基于实例的学习器的学习类别。我们使用训练集的实例来做出决策。因此，承载实例之间距离的矩阵是其中的重要部分。这个矩阵激发了许多研究人员对此进行研究。例如，从数据中学习距离是NCA和大边际最近邻的研究内容；其他研究人员将这个矩阵转换到更高维空间——例如，使用核技巧——还有一些研究人员尝试通过正则化将特征选择嵌入到基于实例的学习器中。
- en: In the next section, we will visually compare the two dimensionality-reduction
    methods by using them to plot the MNIST dataset onto a two-dimensional graph.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将通过使用PCA和NCA算法将MNIST数据集绘制到二维图形中，来直观地比较这两种降维方法。
- en: Comparing PCA to NCA
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将PCA与NCA进行比较
- en: 'We will reduce the dimensionality of the data by projecting it into a smaller
    space. We will use **PCA** and **NCA** in addition to random projection. We will
    start by importing the required models and putting the three algorithms into a
    Python dictionary to loop over them later on:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过将数据投影到更小的空间中来减少数据的维度。除了随机投影，我们还将使用 **PCA** 和 **NCA**。我们将首先导入所需的模型，并将这三种算法放入一个
    Python 字典中，以便后续循环使用：
- en: '[PRE22]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then, we will create three plots side by side for the three algorithms, as
    follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将并排绘制三种算法的三个图表，如下所示：
- en: '[PRE23]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'It is important to center your data before applying PCA. We used `StandardScaler`
    to do this. Other algorithms shouldn''t mind the centering, anyway. Running the
    code gives us the following graphs:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用 PCA 之前，数据必须进行中心化。这时我们使用了 `StandardScaler` 来实现。其他算法本身应该不在乎是否进行中心化。运行代码后，我们得到以下图表：
- en: '![](img/9930f6ed-2feb-47eb-87a5-b66b9d94f28d.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9930f6ed-2feb-47eb-87a5-b66b9d94f28d.png)'
- en: 'PCA and NCA do a better job than random projection in clustering the same digits
    together. In addition to the visual analysis, we can run the nearest neighbors
    algorithm on the reduced data to judge which transformation represents the data
    better. We can use similar code to the preceding one and replace the part inside
    the `for` loop with the following two chunks of code:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 和 NCA 在将相同的数字聚集在一起方面比随机投影表现得更好。除了视觉分析，我们还可以在降维后的数据上运行最近邻算法，判断哪种变换更能代表数据。我们可以使用与之前类似的代码，并将
    `for` 循环中的内容替换为以下两段代码：
- en: 'First, we need to scale and transform our data:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要对数据进行缩放和转换：
- en: '[PRE24]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Then, we use cross-validation to set the optimum hyperparameters:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用交叉验证来设置最佳超参数：
- en: '[PRE25]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Since we do not need to visualize the data this time, we can set the number
    of components to `6`. This gives us the following accuracy scores. Keep in mind
    that your results may vary due to the random split of the data and the estimator''s
    initial values:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这次我们不需要可视化数据，可以将主成分数设置为 `6`。这样我们得到以下的准确率。请记住，由于数据的随机拆分和估计器的初始值不同，你的结果可能会有所不同：
- en: '| **Projection** | **Accuracy** |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| **投影** | **准确率** |'
- en: '| Sparse random projection | 73% |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 稀疏随机投影 | 73% |'
- en: '| PCA | 93% |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| PCA | 93% |'
- en: '| NCA | 95% |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| NCA | 95% |'
- en: In PCA, the class labels are not needed. I just passed them in the preceding
    code for consistency, but they were simply ignored by the algorithm. In comparison,
    in NCA, the class labels are used by the algorithm.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PCA 中，不需要类标签。我只是为了保持一致性，在之前的代码中传递了它们，但算法实际上是忽略了这些标签。相比之下，在 NCA 中，算法是会使用类标签的。
- en: Picking the most informative components
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择最具信息量的主成分
- en: 'After fitting PCA, `explained_variance_ratio_` contains the percentage of variance
    explained by each of the selected components. According to the principal components
    hypothesis, higher ratios should reflect more information. We can put this information
    into a data frame, as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在拟合 PCA 后，`explained_variance_ratio_` 包含了每个选择的主成分所解释的方差比例。根据主成分假设，较高的比例应反映更多的信息。我们可以将这些信息放入数据框中，如下所示：
- en: '[PRE26]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Then, plot it to get the following graph. I am sure plotting data via bar charts
    is becoming second nature to you by now:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，绘制图表以得到如下图表。我相信你现在应该已经习惯了通过条形图绘制数据了：
- en: '![](img/3abc98a2-6cd8-41d0-bc5a-c531ff4e8599.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3abc98a2-6cd8-41d0-bc5a-c531ff4e8599.png)'
- en: From the graph, we can tell that starting from the eighth component, the remaining
    components carry less than 5% of the information.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中可以看出，从第八个主成分开始，剩下的主成分携带的信息量不足 5%。
- en: 'We can also loop through different values for `n_components`, and then train
    a model on the reduced data and see how the accuracy changes with the number of
    components used. I''d trust this approach more than relying on the explained variance
    since it is independent of the principal components assumption and evaluates the
    feature reduction algorithm and the classifier as a single black box. This time,
    I am going to use a different algorithm: nearest centroid.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以循环不同的 `n_components` 值，然后在降维后的数据上训练模型，观察随着主成分数量的变化，准确率如何变化。我更信任这种方法，而不是依赖解释方差，因为它不依赖于主成分假设，并且将特征降维算法和分类器作为一个整体来评估。这一次，我将使用一个不同的算法：最近质心。
- en: Using the centroid classifier with PCA
  id: totrans-172
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用 PCA 的质心分类器
- en: 'In the following code, we will try the centroid algorithm with a different
    number of principal components each time. Please don''t forget to scale and transform
    your features with each iteration, and remember to store the resulting `x` values
    in `x_train_embed` and `x_test_embed`. I used `StandardScaler` here, as well as
    the PCA''s `transform` method, to transform the scaled data:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们将尝试使用不同数量的主成分每次使用质心算法。请不要忘记在每次迭代中对特征进行缩放和转换，并记住将生成的 `x` 值存储在 `x_train_embed`
    和 `x_test_embed` 中。我在这里使用了 `StandardScaler`，以及 PCA 的 `transform` 方法来转换缩放后的数据：
- en: '[PRE27]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Plotting the scores gives us the following graph:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制分数图表如下所示：
- en: '![](img/16bc1d1b-3393-4ec8-ae8d-cdd7be36711b.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/16bc1d1b-3393-4ec8-ae8d-cdd7be36711b.png)'
- en: When we use the centroid algorithm with this dataset, we can roughly see that
    anything above 15 components doesn't add much value. With the help of cross-validation,
    we can pick the exact number of components that gives the best results.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在这个数据集上使用质心算法时，我们大致可以看出超过 15 个成分不会增加太多价值。通过交叉验证的帮助，我们可以选择能够提供最佳结果的确切成分数量。
- en: Restoring the original image from its components
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从其成分恢复原始图像
- en: Once an image is reduced to its principal components, it can also be restored
    back, as follows.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦图像被降至其主成分，也可以将其恢复回来，如下所示。
- en: 'First, you have to scale your data before using PCA:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，在使用 PCA 前，您必须对数据进行缩放：
- en: '[PRE28]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Once scaled, you can transform your data using 32 principal components, as follows.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放后，您可以使用 32 个主成分来转换您的数据，如下所示。
- en: 'Then, you can restore the original data after transformation by using the `inverse_transform`
    method:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您可以使用 `inverse_transform` 方法在转换后恢复原始数据：
- en: '[PRE29]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To keep the original images and the restored ones on the same scale, we can
    use `MinMaxScaler`, as follows:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了保持原始图像和恢复图像在同一比例上，我们可以使用 `MinMaxScaler`，如下所示：
- en: '[PRE30]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Here, you can see a comparison between some digits and themselves, with the
    less important components removed. These restored versions of the original data
    can be useful to the classifier, either by using them in place of the training
    and test sets, or by adding them as additional samples to the training set:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，您可以看到一些数字与它们自身之间的比较，删除了不重要的成分。这些恢复的原始数据版本对分类器可能很有用，可以用它们替代训练和测试集，或者将它们作为训练集的附加样本：
- en: '![](img/2958362f-bb66-49ec-ba17-739dedb8d2be.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2958362f-bb66-49ec-ba17-739dedb8d2be.png)'
- en: 'Finally, I used `x_train_embed` and `x_test_embed` in place of the original
    features in our nearest neighbors classifier. I tried a different number of PCA
    components each time. The darker bars in the following graph show the number of
    PCA components that resulted in the highest accuracy scores:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我在最近邻分类器中使用了 `x_train_embed` 和 `x_test_embed` 替代了原始特征。我每次尝试了不同数量的 PCA 成分。以下图表中较暗的条形显示了能够产生最高准确度得分的
    PCA 成分数量：
- en: '![](img/b886c5c5-427e-4681-8a9d-50433541bb53.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b886c5c5-427e-4681-8a9d-50433541bb53.png)'
- en: Not only did PCA help us reduce the number of features and the prediction time
    consequently, but it also helped us achieve a score of 98.9%.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 不仅帮助我们减少了特征数量和预测时间，同时还帮助我们获得了 98.9% 的得分。
- en: Finding the most informative pixels
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查找最具信息量的像素
- en: 'Since almost all of the digits are centered in the images, we can intuitively
    deduce that the pixels on the right and left edges of the images do not carry
    valuable information. To validate our intuition, we will let the feature selection
    algorithms from [Chapter 4](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=27&action=edit),
    *Preparing Your Data*, decide for us which pixels are most important. Here, we
    can use the mutual information algorithm to return a list of pixels and their
    corresponding importance:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 由于几乎所有数字都位于图像的中心，我们可以直觉地推断图像右侧和左侧的像素不包含有价值的信息。为了验证我们的直觉，我们将使用[第 4 章](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=27&action=edit)中的特征选择算法，*数据准备*，来决定哪些像素最重要。在这里，我们可以使用互信息算法返回一个像素列表及其对应的重要性：
- en: '[PRE31]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We then use the preceding information to remove 75% of the pixels:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用前述信息去除了 75% 的像素：
- en: '[PRE32]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In the following diagram, the pixels marked in black are the most informative
    ones, and the rest are the 75% of the pixels that are deemed less important by
    the mutual information algorithm:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，标记为黑色的像素是最具信息量的，其余的像素则是互信息算法认为不太重要的 75% 像素：
- en: '![](img/5e056b18-96ab-4f33-b93b-ef6891058f42.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5e056b18-96ab-4f33-b93b-ef6891058f42.png)'
- en: 'As expected, the pixels on the edges are less informative. Now that we have
    identified the less informative pixels, we can reduce the number of features in
    our data by removing the less informative pixels, as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，边缘处的像素信息量较少。既然我们已经识别出这些信息量较少的像素，我们可以通过移除这些像素来减少数据中的特征数量，具体如下：
- en: '[PRE33]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Training a classifier on the reduced features gives us an accuracy score of
    94%. Knowing that the complexity of the nearest neighbors algorithm and its prediction
    time grows with the number of features, we can understand the value of a slightly
    less accurate algorithm that only uses **25%** of the data.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在减少特征后的数据上训练分类器，我们得到了94%的准确率。考虑到最近邻算法的复杂度以及其预测时间随着特征数量的增加而增长，我们可以理解一个略微不那么精确，但仅使用**25%**数据的算法的价值。
- en: Summary
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Images are in abundance in our day-to-day life. Robots need computer vision
    to understand their surroundings. The majority of the posts on social media include
    pictures. Handwritten documents require image processing to make them consumable
    by machines. These and many more uses cases are the reason why image processing
    is an essential competency for machine learning practitioners to master. In this
    chapter, we learned how to load images and make sense of their pixels. We also
    learned how to classify images and reduce their dimensions for better visualization
    and further manipulation.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图像在我们日常生活中无处不在。机器人需要计算机视觉来理解其周围环境。社交媒体上的大多数帖子都包含图片。手写文件需要图像处理才能被机器处理。这些以及更多的应用案例正是为什么图像处理成为机器学习从业者必须掌握的一项基本技能。在本章中，我们学习了如何加载图像并理解其像素。我们还学习了如何对图像进行分类，并通过降维来改善可视化效果和进一步的处理。
- en: We used the nearest neighbor algorithm for image classification and regression.
    This algorithm allowed us to plug our own metrics when needed. We also learned
    about other algorithms, such as radius neighbors and nearest centroid. The concepts
    behind these algorithms and their differences are omnipresent in the field of
    machine learning. Later on, we will see how the clustering and anomaly detection
    algorithms borrow ideas from the concepts discussed here. In addition to the main
    algorithms discussed here, concepts such as distance metrics and dimensionality
    reduction are also ubiquitous.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了最近邻算法进行图像分类和回归。这个算法允许我们在需要时插入自己的度量标准。我们还了解了其他算法，如半径邻居和最近质心。理解这些算法背后的概念及其差异在机器学习领域无处不在。稍后，我们将看到聚类和异常检测算法是如何借鉴这里讨论的概念的。除了这里讨论的主要算法，像距离度量和降维等概念也广泛存在。
- en: Due to the importance of image processing, we will not stop here, as we are
    going to build on the knowledge acquired here in [Chapter 7](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=33&action=edit),
    *Neural Networks – Here Comes the Deep Learning*, where we will use artificial
    neural networks for image classification.*
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像处理的重要性，我们不会就此止步，因为我们将在[第7章](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=33&action=edit)中进一步扩展这里获得的知识，*神经网络——深度学习的到来*，在那里我们将使用人工神经网络进行图像分类。
