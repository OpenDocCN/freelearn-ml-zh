- en: Predicting Categories with Logistic Regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用逻辑回归进行分类预测
- en: The logistic regression algorithm is one of the most interpretable algorithms
    in the world of machine learning, and although the word "regression" implies predicting
    a numerical outcome, the logistic regression algorithm is, used to predict categories
    and solve classification machine learning problems.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归算法是机器学习领域中最具可解释性的算法之一，尽管“回归”一词通常用于预测数值结果，但逻辑回归算法用于预测类别并解决分类机器学习问题。
- en: 'In this chapter, you will learn about the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习以下内容：
- en: How the logistic regression algorithm works mathematically
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归算法在数学上的工作原理
- en: Implementing and evaluating your first logistic regression algorithm with scikit-learn
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用scikit-learn实现并评估你的第一个逻辑回归算法
- en: Fine-tuning the hyperparameters using `GridSearchCV`
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`GridSearchCV`微调超参数
- en: Scaling your data for a potential improvement in accuracy
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了潜在提高准确性，对数据进行缩放
- en: Interpreting the results of the model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解读模型的结果
- en: Logistic regression has a wide range of applications, especially in the field
    of finance, where building interpretable machine learning models is key in convincing
    both investors and regulators alike that your model makes intuitive and logical
    sense.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归有广泛的应用，尤其在金融领域，在那里构建可解释的机器学习模型是说服投资者和监管者你的模型在直观和逻辑上都合理的关键。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will be required to have Python 3.6 or greater, Pandas ≥ 0.23.4, Scikit-learn
    ≥ 0.20.0, and Matplotlib ≥ 3.0.0 installed on your system.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要在系统上安装Python 3.6或更高版本、Pandas ≥ 0.23.4、Scikit-learn ≥ 0.20.0和Matplotlib ≥
    3.0.0。
- en: 'The code files of this chapter can be found on GitHub:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在GitHub上找到：
- en: '[https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_03.ipynb](https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_03.ipynb)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_03.ipynb](https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_03.ipynb)'
- en: 'Check out the following video to see the code in action:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，看看代码的实际操作：
- en: '[http://bit.ly/2DaTNgQ](http://bit.ly/2DaTNgQ)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2DaTNgQ](http://bit.ly/2DaTNgQ)'
- en: Understanding logistic regression mathematically
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数学角度理解逻辑回归
- en: 'As the name implies, logistic regression is fundamentally derived from the
    linear regression algorithm. The linear regression algorithm will be discussed
    in depth in the upcoming chapters. For now, let''s consider a hypothetical case
    in which we want to predict the probability that a particular loan will default
    based on the loan''s interest rate. Using linear regression, the following equation
    can be constructed:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，逻辑回归本质上源自线性回归算法。线性回归算法将在后续章节中深入讨论。现在，让我们考虑一个假设情况：我们希望根据贷款的利率预测某一贷款是否会违约。使用线性回归，可以构建以下方程：
- en: '`Default = (Interest Rate × x) + c`'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`违约 = (利率 × x) + c`'
- en: 'In the preceding equation, *c* is the intercept and *x* is a coefficient that
    will be the output from the logistic regression model. The intercept and the coefficient
    will have numeric values. For the purpose of this example, let''s assume *c* is
    5 and *x* is -0.2\. The equation now becomes this:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述方程中，*c* 是截距，*x* 是系数，将作为逻辑回归模型的输出。截距和系数将具有数值。为了此示例，我们假设 *c* 为5，*x* 为 -0.2。方程现在变为：
- en: '`Default = (Interest Rate × -0.2) + 5`'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`违约 = (利率 × -0.2) + 5`'
- en: 'The equation can be represented in a two-dimensional plot using the following
    diagram:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 该方程可以通过以下图示表示为二维图：
- en: '![](img/62295c65-377b-4206-a2a8-cc7052c49232.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/62295c65-377b-4206-a2a8-cc7052c49232.png)'
- en: 'Assuming that the interest rate is 10%, the value of default produced by the
    equation is as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 假设利率为10%，该方程产生的违约值如下：
- en: '*Default = (10 × -0.2) + 5*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*违约 = (10 × -0.2) + 5*'
- en: '*Default = 3*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*违约 = 3*'
- en: 'The logistic regression model now uses the `logit` function to transform this
    value of 3 into a probability between 0 and 1:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，逻辑回归模型使用`logit`函数将这个值3转换为一个介于0和1之间的概率：
- en: '![](img/8355ffed-7009-4f68-b1c7-896eba1d6313.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8355ffed-7009-4f68-b1c7-896eba1d6313.png)'
- en: After evaluating the preceding equation, we get an answer of 0.95\. In other
    words, using the logistic regression model that we just built mathematically,
    we obtained a probability of 95% that the loan would default if the interest rate
    was 10%.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 评估前面的方程式后，我们得到答案 0.95。换句话说，使用我们刚刚构建的逻辑回归模型，我们获得了 95% 的概率，表示在利率为 10% 时，贷款违约的可能性。
- en: 'After applying the `logit` function to the linear equation, the two-dimensional
    plot shown previously changes to the following diagram:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在对线性方程应用 `logit` 函数后，之前的二维图表变为下图所示：
- en: 'In the preceding diagram, the following is happening:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图表中，发生了以下情况：
- en: The function approaches 1 as the interest rate nears infinity along the *x*-axis.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当利率沿着 *x* 轴接近无穷大时，函数趋近于 1。
- en: The function approaches 0 as the interest rate nears 0 along the *x*-axis.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当利率沿 *x* 轴接近 0 时，函数趋近于 0。
- en: Implementing logistic regression using scikit-learn
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 实现逻辑回归
- en: 'In this section, you will learn how you can implement and quickly evaluate
    a logistic regression model for your dataset. We will be using the same dataset
    that we have already cleaned and prepared for the purpose of predicting whether
    a particular transaction was fraudulent. In the previous chapter, we saved this
    dataset as `fraud_detection.csv`. The first step is to load this dataset into
    your Jupyter Notebook. This can be done by using the following code:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习如何为您的数据集实现并快速评估逻辑回归模型。我们将使用之前已经清理和准备好的数据集，目的是预测某笔交易是否为欺诈。在上一章中，我们将此数据集保存为
    `fraud_detection.csv`。第一步是将该数据集加载到 Jupyter Notebook 中。这可以通过以下代码完成：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Splitting the data into training and test sets
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据分为训练集和测试集
- en: 'The first step to building any machine learning model with scikit-learn is
    to split the data into training and test sets. This can be done by using the following
    code:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 构建任何机器学习模型的第一步是将数据分为训练集和测试集。这可以通过以下代码完成：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The next step is to implement a base logistic regression classifier and evaluate
    its accuracy score. This can be done by using the following code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是实现一个基本的逻辑回归分类器并评估其准确率。这可以通过以下代码完成：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the preceding code, the `linear_model`package is imported from `sklearn`
    and is used to initialize the logistic regression algorithm by calling the `LogisticRegression()`method.
    This logistic regression algorithm is then fit into the training data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`linear_model` 包从 `sklearn` 导入，并通过调用 `LogisticRegression()` 方法来初始化逻辑回归算法。然后将该逻辑回归算法拟合到训练数据中。
- en: 'In order to extract the accuracy score, we use the following code on the test
    data:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提取准确率评分，我们对测试数据使用以下代码：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This model has produced an accuracy of 58.9% on the test data. This means that
    the base logistic regression model only performs slightly better than an algorithm
    that randomly guesses the output.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在测试数据上的准确率为 58.9%。这意味着基本的逻辑回归模型的表现仅略优于一个随机猜测输出的算法。
- en: Fine-tuning the hyperparameters
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调超参数
- en: From the output of the logistic regression model implemented in the preceding
    section, it is clear that the model performs slightly better than random guessing.
    Such a model fails to provide value to us. In order to optimize the model, we
    are going to optimize the hyperparameters of the logistic regression model by
    using the `GridSearchCV` algorithm that we used in the previous chapter.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 从前一部分中实现的逻辑回归模型的输出可以看出，该模型的表现略优于随机猜测。这样的模型无法为我们提供价值。为了优化模型，我们将使用上一章中介绍的 `GridSearchCV`
    算法来优化逻辑回归模型的超参数。
- en: The hyperparameter that is used by the logistic regression model is known as
    the inverse regularization strength. This is because we are implementing a type
    of linear regression known as **l1** regression. This type of linear regression
    will explained in detail in [Chapter 5](589b9373-c8dd-4243-aec8-9d6c4851f987.xhtml),
    *Predicting Numeric Outcomes with Linear Regression*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型使用的超参数被称为反向正则化强度。这是因为我们正在实现一种被称为 **l1** 回归的线性回归。关于这种线性回归的详细解释，请参考 [第 5
    章](589b9373-c8dd-4243-aec8-9d6c4851f987.xhtml)，*使用线性回归预测数值结果*。
- en: 'In order to optimize the inverse regularization strength, or **C** as it is
    called in short, we use the following code:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化反向正则化强度，简称 **C**，我们使用以下代码：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This produces an output as illustrated in the following screenshot:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成如下所示的输出：
- en: '![](img/2c9f6a51-729a-4cab-99c4-ba716af3bc17.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2c9f6a51-729a-4cab-99c4-ba716af3bc17.png)'
- en: In the preceding code, we first initialize a logistic regression model with
    the penalty argument set to **l1**, indicating that we are using **l1** regression.
    We then initialize a grid with the possible values of inverse regularization strengths
    that go from 0.0001 to 10\.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们首先初始化了一个逻辑回归模型，并将惩罚参数设置为**l1**，这表示我们使用的是**l1**回归。然后我们初始化了一个网格，其中包含从0.0001到10\的逆正则化强度的可能值。
- en: The number of values that you initialize in a grid object for the hyperparameter
    of a model is arbitrary. However, the more values, the longer it takes for `GridSearchCV`
    to give you the optimal value of the hyperparameter, therby making the process
    computationally expensive.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在网格对象中初始化模型的超参数的值的个数是任意的。然而，值越多，`GridSearchCV`找到最佳超参数值的时间就越长，从而使得这一过程在计算上变得更加昂贵。
- en: 'The grid object with the possible values of the inverse regularization strengths
    are then fit into the training data and the optimal value is printed out, which
    in this case is 10\. We can now build a new logistic regression model with this
    newly obtained optimal hyperparameter value by using the following code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将包含逆正则化强度可能值的网格对象拟合到训练数据中，并打印出最佳值，在本例中是10\。我们现在可以通过以下代码构建一个新的逻辑回归模型，使用这个新获得的最佳超参数值：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Evaluating the model on the test data by using the following code, we obtain
    an accuracy score of 99.6%! That's quite the improvement.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码评估测试数据上的模型时，我们得到了99.6%的准确率！这可算是一个相当大的提升。
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'One way to check whether `GridSearchCV` is giving us accurate results is to
    plot the accuracy scores along the *y*-axis for different values of the inverse
    regularization strengths along the x-axis. This can be done by using the following
    code:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 检查`GridSearchCV`是否给出准确结果的一种方法是绘制逆正则化强度不同值在x轴上的变化，并将准确率得分绘制在*y*轴上。这可以通过以下代码完成：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This results in a plot as illustrated in the following diagram:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下面所示的图：
- en: '![](img/822b690d-6fec-4165-9de9-1df7f8a6939b.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/822b690d-6fec-4165-9de9-1df7f8a6939b.png)'
- en: From the preceding plot, it is clear that an inverse regularization strength
    of 10 provides a high value of accuracy for both the training and testing sets.
    Such plots are also used to determine whether a particular value of the hyperparameter
    is overfitting the data by giving us a high accuracy score on the training set,
    but low accuracy scores on the test set. Conversely, they can also be used to
    check whether a model is undercutting the data by giving us low values of accuracy
    on the training set itself.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图中可以清楚地看到，逆正则化强度为10时，训练集和测试集的准确率都很高。此类图表还用于判断某个超参数值是否出现过拟合情况，即在训练集上得到较高的准确率，但在测试集上得到较低的准确率。相反，它们也可以用来检查模型是否低估了数据，通过在训练集上获得较低的准确率。
- en: Scaling the data
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据缩放
- en: 'Although the model has performed extremely well, scaling the data is still
    a useful step in building machine learning models with logistic regression, as
    it standardizes your data across the same range of values. In order to scale your
    data, we will use the same `StandardScaler()`function that we used in the previous
    chapter. This is done by using the following code:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管模型表现极为出色，缩放数据仍然是构建逻辑回归机器学习模型中的一个有用步骤，因为它标准化了数据，使其在相同范围的值内。在缩放数据时，我们将使用上一章中用过的`StandardScaler()`函数。具体代码如下：
- en: '[PRE8]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The preceding code resulted in the improvement in the accuracy score of the
    model by 0.1%, which is good considering how the model had a very high accuracy
    score in the first place. The code is similar to the pipeline for scaling we built
    in the previous chapter for the k-NN algorithm, and there are no changes except
    for the fact that we have used a logistic regression model instead of the k-NN
    model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码使得模型的准确率得分提高了0.1%，考虑到模型原本已经有非常高的准确率，这已经是一个不错的提升。该代码与上一章为k-NN算法构建的缩放管道类似，唯一的区别是我们使用了逻辑回归模型，而不是k-NN模型。
- en: Interpreting the logistic regression model
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释逻辑回归模型
- en: One of the key benefits of the logistic regression algorithm is that it is highly
    interpretable. This means that the outcome of the model can be interpreted as
    a function of the input variables. This allows us to understand how each variable
    contributes to the eventual outcome of the model.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归算法的一个关键优势是其高度可解释性。这意味着模型的结果可以解释为输入变量的函数。这使我们能够理解每个变量如何影响模型最终结果。
- en: 'In the first section, we understood that the logistic regression model consists
    of coefficients for each variable and an intercept that can be used to explain
    how the model works. In order to extract the coefficients for each variable in
    the model, we use the following code:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一部分中，我们了解到逻辑回归模型由每个变量的系数和一个截距组成，可以用来解释模型的工作原理。为了提取模型中每个变量的系数，我们使用以下代码：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This results in an output as illustrated by the following screenshot:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了如下截图所示的输出：
- en: '![](img/7076338c-7f04-40e8-bb96-4965b1ce2713.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7076338c-7f04-40e8-bb96-4965b1ce2713.png)'
- en: 'The coefficients are in the order in which the variables were in the dataset
    that was input into the model. In order to extract the intercept from the model,
    we use the following code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 系数的顺序与输入模型的数据集中变量的顺序相同。为了从模型中提取截距，我们使用以下代码：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This results in an output as shown in the following screenshot:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了如下截图所示的输出：
- en: '![](img/b59cf245-50ce-4030-9eb7-92a0fc145adc.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b59cf245-50ce-4030-9eb7-92a0fc145adc.png)'
- en: 'Now that we have the coefficients for each variable along with the intercept,
    we can construct an equation in the following form:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经获得了每个变量的系数以及截距，我们可以构建以下形式的方程：
- en: '![](img/eab80713-884d-44a2-b5ab-9908a296763f.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eab80713-884d-44a2-b5ab-9908a296763f.png)'
- en: Summary
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you have learned how the logistic regression model works on
    a mathematical level. Although simplistic, the model proves to be formidable in
    terms of interpretability, which is highly beneficial in the financial industry.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您已经了解了逻辑回归模型在数学层面上的工作原理。尽管简单，但该模型在可解释性方面表现出色，这在金融行业中非常有益。
- en: You have also learned how to build and evaluate logistic regression algorithms
    using scikit-learn, and looked at hyperparameter optimization using the `GridSearchCV`
    algorithm. Additionally, you have learned to verify whether the results provided
    to you by the `GridSearchCV` algorithm are accurate by plotting the accuracy scores
    for different values of the hyperparameter.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 您还学会了如何使用scikit-learn构建和评估逻辑回归算法，并使用`GridSearchCV`算法进行超参数优化。此外，您还学会了通过绘制不同超参数数值的准确度得分来验证`GridSearchCV`算法提供给您的结果是否准确。
- en: Finally, you have scaled your data in order make it standardized and learned
    how to interpret your model on a mathematical level.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您对数据进行了缩放以使其标准化，并学会了如何在数学层面解释您的模型。
- en: In the next chapter, you will learn how to implement tree-based algorithms,
    such as decision trees, random forests, and gradient-boosted trees, using scikit-learn.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将学习如何使用scikit-learn实现基于树的算法，如决策树、随机森林和梯度提升树。
