- en: '*Appendix*: Anomaly Detection Tips'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*附录*：异常检测技巧'
- en: As we wind down the content for this book, it occurred to us that there's still
    a plethora of good, bite-sized explanations, examples, and pieces of advice that
    didn't quite fit into sections of the other chapters. It therefore made sense
    to give them a home all to themselves here in the [*Appendix*](B17040_14_Epub_AM.xhtml#_idTextAnchor248).
    Enjoy this potpourri of tips, tricks, and advice!
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们结束本书的内容时，我们突然想到，还有很多很好的、适合小部分的内容、示例和建议，它们并没有很好地融入其他章节的章节中。因此，在这里为它们提供一个单独的家是有意义的，就在[*附录*](B17040_14_Epub_AM.xhtml#_idTextAnchor248)中。享受这个技巧、窍门和建议的大杂烩！
- en: 'The following topics will be covered here in the [*Appendix*](B17040_14_Epub_AM.xhtml#_idTextAnchor248):'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*附录*](B17040_14_Epub_AM.xhtml#_idTextAnchor248)中，以下主题将被涵盖：
- en: Understanding influencers in split versus non-split jobs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解分拆与非分拆工作中的影响者
- en: Using one-sided functions to your advantage
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用单侧函数
- en: Ignoring time periods
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 忽略时间段
- en: Using custom rules and filters to your advantage
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用自定义规则和过滤器
- en: Anomaly detection job throughput considerations
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常检测工作吞吐量考虑
- en: Avoiding the over-engineering of a use case
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免过度设计用例
- en: Using anomaly detection on runtime fields
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在运行时字段上使用异常检测
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The information in this chapter will use the Elastic Stack as it exists in v7.12\.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的信息将使用存在于v7.12的Elastic Stack。
- en: Understanding influencers in split versus non-split jobs
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解分拆与非分拆工作中的影响者
- en: You might question whether or not it is necessary to split the analysis by a
    field, or merely hope that the use of influencers will give the desired effect
    of identifying the offending entity.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会质疑是否有必要按字段分拆分析，或者仅仅希望使用影响者能够产生识别违规实体的预期效果。
- en: Let's remind ourselves of the difference between the purpose of influencers
    and the purpose of splitting a job. An entity is identified by an anomaly detection
    job as an influencer if it has contributed significantly to the existence of the
    anomaly. This notion of deciding influential entities is completely independent
    of whether or not the job is split. An entity can be deemed influential on an
    anomaly only if an anomaly happens in the first place. If there is no anomaly
    detected, there is no need to figure out whether there is an influencer. However,
    the job may or may not find that something is anomalous, depending on whether
    or not the job is split into multiple time series. When splitting the job, you
    are modeling (creating a separate analysis) for each entity of the field chosen
    for the split.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次提醒自己，影响者与分拆工作目的之间的区别。如果一个实体被异常检测工作识别为影响者，那么它对异常的存在做出了显著贡献。这种决定影响实体的概念与工作是否分拆完全独立。只有当首先发生异常时，一个实体才能被认为对异常有影响。如果没有检测到异常，就没有必要确定是否存在影响者。然而，工作可能或可能不会发现某些异常，这取决于工作是否被分拆成多个时间序列。当分拆工作的时候，你正在为所选分拆字段中的每个实体建模（创建一个单独的分析）。
- en: 'Let''s look at one of the Elastic ML development team''s favorite demo datasets,
    called `farequote` (available in the GitHub repository for this book as a file
    entitled `farequote-2021.csv` and easily uploaded via Elastic ML''s file upload
    in the **Data Visualizer**). This dataset originated from a real customer, who
    ran a travel portal application. The application''s access log recorded the number
    of times a piece of middleware was called when it reached out to a third-party
    airline for a quote of airline fares. The JSON documents look like the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看Elastic ML开发团队最喜欢的一个演示数据集，称为`farequote`（可在本书的GitHub存储库中找到，文件名为`farequote-2021.csv`，并通过Elastic
    ML的文件上传功能轻松上传到**数据可视化器**）。这个数据集来自一个真实客户，该客户运行了一个旅游门户应用程序。应用程序的访问日志记录了当它向第三方航空公司请求航班报价时，中间件被调用的次数。JSON文档看起来如下：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The number of events per unit of time corresponds to the number of requests
    being made, and the `responsetime` field is the response time of that individual
    request to the fare quoting web service of that airline.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 每单位时间的事件数对应于正在进行的请求数量，而`responsetime`字段是针对该航空公司的航班报价Web服务的单个请求的响应时间。
- en: 'Let''s take a look at the following cases:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下案例：
- en: '**Case 1**: An analysis of count over time, not split on airline, but using
    airline as an influencer. You could accomplish this using the Multi-metric wizard
    configured as follows:'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例 1**：对随时间变化的计数进行分析，没有按航空公司分割，但使用航空公司作为影响因素。你可以使用如下配置的多度量向导来完成此操作：'
- en: '![Figure A.1 – A job with no split, but an influencer'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.1 – 没有分割但有一个影响因素的工作'
- en: '](img/B17040_14_1.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_14_1.jpg]'
- en: Figure A.1 – A job with no split, but an influencer
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.1 – 没有分割但有一个影响因素的工作
- en: 'After the analysis runs, the spike seen in the middle of the data (as shown
    in the job configuration preview screen in *Figure A.1*) is indeed flagged as
    anomalous with a modest score of 27, and the airline of AAL was flagged as an
    influencer:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 分析运行后，数据中间出现的峰值（如图 A.1*中的工作配置预览屏幕所示）确实被标记为异常，得分为27分，AAL航空公司被标记为影响因素：
- en: '![Figure A.2 – Result of count job with no split, but an influencer found'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.2 – 没有分割但发现影响因素的计数工作结果'
- en: '](img/B17040_14_2.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_14_2.jpg]'
- en: Figure A.2 – Result of count job with no split, but an influencer found
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.2 – 没有分割但发现影响因素的计数工作结果
- en: Let's compare this result to what we see in the next case.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个结果与下一个案例中我们看到的结果进行比较。
- en: '`airline`, and using `airline` as an influencer.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`airline`，并使用`airline`作为影响因素。'
- en: 'If we repeat the configuration in *Figure A.1*, but this time choose to split
    on `airline` (thereby setting `partition_field_name:airline`), we will certainly
    see that airline AAL is still the most unusual, and that the anomaly score for
    it is much higher than in Case 1:'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们重复图 A.1*中的配置，但这次选择在`airline`上分割（从而设置`partition_field_name:airline`），我们肯定会看到航空公司AAL仍然是异常最不寻常的，并且其异常分数比案例
    1 高得多：
- en: '![Figure A.3 – Result of count job with a split, and an influencer found'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.3 – 使用分割和发现的影响者`airline`的结果'
- en: '](img/B17040_14_3.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_14_3.jpg]'
- en: Figure A.3 – Result of count job with a split, and an influencer found
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.3 – 使用分割和发现的影响者`airline`的计数工作结果
- en: In other words, the anomalous behavior of AAL is much more prominent when the
    job was split to model each airline separately. Otherwise, AAL's anomalous behavior
    was being masked somewhat when all the document counts were mixed. This is even
    more prominent when we show the difference of splitting versus not splitting when
    we look at an analysis of the `responsetime` field in the next two cases.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，当工作分割以单独建模每个航空公司时，AAL的异常行为更加突出。否则，当所有文档计数混合在一起时，AAL的异常行为被某种程度上掩盖了。当我们查看下一个两个案例中`responsetime`字段的`分割`与`不分割`的差异时，这一点更加明显。
- en: '`responsetime` field, split on `airline`.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`airline`上分割的`responsetime`字段。
- en: 'Here, we see that AAL is also the most unusual airline with respect to an analysis
    of the `responsetime` field:'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们看到AAL也是关于`responsetime`字段分析的异常最不寻常的航空公司：
- en: '![Figure A.4 – Result of response time job with a split, and an influencer
    found'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.4 – 使用分割和发现的影响者`airline`的响应时间工作结果'
- en: '](img/B17040_14_4.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_14_4.jpg]'
- en: Figure A.4 – Result of response time job with a split, and an influencer found
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.4 – 使用分割和发现的影响者`airline`的响应时间工作结果
- en: Let's now compare this result to the next case, where we won't split the job.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将这个结果与下一个案例进行比较，在这个案例中，我们不会分割工作。
- en: '`responsetime` field, no split, but still using `airline` as an influencer.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`responsetime`字段，没有分割，但仍然使用`airline`作为影响因素。'
- en: 'In this case, the results are as follows:'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这种情况下，结果如下：
- en: '![Figure A.5 – Result of response time job without a split, and an influencer
    found'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.5 – 没有分割但发现影响者的响应时间工作结果'
- en: '](img/B17040_14_5.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_14_5.jpg]'
- en: Figure A.5 – Result of response time job without a split, and an influencer
    found
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.5 – 没有分割但发现影响者的响应时间工作结果
- en: 'You can see that the airline that we know is the most unusual (AAL) is no longer
    found. In this case, all of the airline''s response times are getting averaged
    together each bucket span, because the job is not split. Now, the most prominent
    anomaly (even though it is a relatively minor variation above normal) is shown
    and is deemed to be influenced by `airline=NKS`. However, this may be misleading.
    You see, `airline=NKS` has a very stable response time during this period, but
    note that its normal operating range is much higher than the rest of the group:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我们知道的异常最不寻常的航空公司（AAL）不再被发现。在这种情况下，所有航空公司的响应时间在每个桶跨度内都被平均在一起，因为工作没有分割。现在，最突出的异常（尽管它是在正常水平之上的相对较小的变化）被显示出来，被认为是受`airline=NKS`的影响。然而，这可能是误导性的。你看，`airline=NKS`在此期间有非常稳定的响应时间，但请注意，其正常操作范围比其他组高得多：
- en: '![Figure A.6 – Average response times of each airline'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.6 – 每家航空公司的平均响应时间'
- en: '](img/B17040_14_6.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_14_6.jpg](img/B17040_14_6.jpg)'
- en: Figure A.6 – Average response times of each airline
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.6 – 每家航空公司的平均响应时间
- en: As such, the contribution of NKS to the total aggregate response times of all
    airlines is more significant than the others. So, of course, ML identifies NKS
    as the most prominent influencer.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，NKS对所有航空公司总聚合响应时间的贡献比其他因素更为显著。所以，当然，机器学习将NKS识别为最突出的影响因素。
- en: 'And there you have it: the moral here is that you should be thoughtful if you
    are simply relying on influencers to find unusual entities within a dataset of
    multiple entities. It might be more sensible to individually model each entity
    independently!'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由此可见：这里的教训是，如果你只是简单地依赖影响因素在多个实体的数据集中寻找异常实体，那么你应该深思熟虑。可能更有意义的是独立地对每个实体进行建模！
- en: Using one-sided functions to your advantage
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用单侧函数的优势
- en: Many people realize the usefulness of one-sided functions in ML, such as `low_count`
    and `high_mean`, to allow for the detection of anomalies only on the high side
    or on the low side. This is useful when you only care about a drop in revenue
    or a spike in response time.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人意识到单侧函数在机器学习中的有用性，例如`low_count`和`high_mean`，这允许仅在高侧或低侧检测异常。当你只关心收入下降或响应时间峰值时，这很有用。
- en: However, when you care about deviations in both directions, you are often inclined
    to use just the regular function (such as `count` or `mean`). However, on some
    datasets, it is more optimal to use both the high and low versions of the function
    as two separate detectors. Why is this the case and under what conditions, you
    might ask?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当你关心两个方向的偏差时，你通常会倾向于只使用常规函数（如`count`或`mean`）。然而，在某些数据集中，使用函数的高版本和低版本作为两个独立的检测器更为优化。你可能会问，为什么这种情况会发生，以及什么条件下会发生？
- en: 'The condition where this makes sense is when the dynamic range of the possible
    deviations is asymmetrical. In other words, the magnitude of potential spikes
    in the data is far, far bigger than the magnitude of the potential drops, possibly
    because the count or sum of something cannot be less than zero. Let''s look at
    the following screenshot:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况有意义的条件是可能的偏差动态范围不对称。换句话说，数据中潜在峰值的大小远大于潜在下降的大小，这可能是由于某个计数或总和不能小于零。让我们看看下面的截图：
- en: '![Figure A.7 – An analysis using the two-sided "sum" function'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.7 – 使用双向“求和”函数的分析'
- en: '](img/B17040_14_7.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_14_7.jpg](img/B17040_14_7.jpg)'
- en: Figure A.7 – An analysis using the two-sided "sum" function
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.7 – 使用双向“sum”函数的分析
- en: Here, the two-sided `sum` function properly identifies the large spike with
    a critical anomaly on the left, but the lack of expected double bumps in the middle
    is identified with only warning anomalies. Again, this is because, with a double-sided
    function, the normalization process ranks all anomalies together. The magnitude
    (and therefore the unlikeliness) of the spike is far bigger than the lack of data
    around 18:00, so the anomaly scores are assigned relatively.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，双向“求和”函数正确地识别了左侧的临界异常的大峰值，但中间缺少预期的双峰被仅以警告异常识别。再次强调，这是因为，使用双向函数，归一化过程将所有异常一起排序。峰值（因此是不太可能发生的）的幅度远大于18:00左右的数据缺失，因此异常评分被相对分配。
- en: 'However, if the dataset was analyzed with two separate detectors, using an
    advanced job, that is, `low_sum(num_trx)` and `high_sum(num_trx)`, then the results
    would look very different. Here''s the result of the high side:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果数据集是用两个独立的检测器分析的，即使用高级作业，即`low_sum(num_trx)`和`high_sum(num_trx)`，那么结果将非常不同。这里是高侧的结果：
- en: '![Figure A.8 – An analysis using the one-sided "high_sum" function'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.8 – 使用单侧“high_sum”函数的分析'
- en: '](img/B17040_14_8.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_14_8.jpg](img/B17040_14_8.jpg)'
- en: Figure A.8 – An analysis using the one-sided "high_sum" function
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.8 – 使用单侧“high_sum”函数的分析
- en: 'And here''s the result of the low side:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是低侧的结果：
- en: '![Figure A.9 – An analysis using the one-sided "low_sum" function'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.9 – 使用单侧“low_sum”函数的分析'
- en: '](img/B17040_14_9.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_14_9.jpg](img/B17040_14_9.jpg)'
- en: Figure A.9 – An analysis using the one-sided "low_sum" function
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.9 – 使用单侧“low_sum”函数的分析
- en: Notice that the anomalies in the middle are now scored much higher (in this
    case, with a maximum score of 47 yellow).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到中间的异常现在被评分得更高（在这个例子中，最高评分为47个黄色）。
- en: So now, when the two one-sided detectors are run together in the same job, you've
    optimized the dynamic range of each detector (since they have their own normalization
    table)!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当两个单边探测器在同一作业中一起运行时，你已经优化了每个探测器的动态范围（因为它们有自己的归一化表）！
- en: Ignoring time periods
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 忽略时间段
- en: 'Often, people ask how they can get ML to ignore the fact that a certain event
    has occurred. Perhaps it was an expected maintenance window, or perhaps something
    was broken within the data ingest pipeline and data was lost for a few moments.
    There are a few ways that you can get ML to ignore time periods, and for distinction,
    we''ll separate them into two groups:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 经常有人问如何让机器学习（ML）忽略某些事件已经发生的事实。可能是因为预期的维护窗口，或者可能是数据摄取管道中出现了故障，导致数据丢失了几分钟。有几种方法可以让机器学习忽略特定的时间段，为了区分，我们将它们分为两组：
- en: A known, upcoming window of time
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已知即将到来的时间段
- en: An unexpected window of time that is discovered only after the fact
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在事后才发现的不寻常的时间窗口
- en: 'To illustrate things, we''ll use a single-metric count job (from *Figure A.1*)
    on the `farequote` dataset that has an anomaly on the date of February 9th:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明问题，我们将使用一个单一指标计数作业（来自*图A.1*）在`farequote`数据集上，该作业在2月9日的日期上存在异常：
- en: '![Figure A.10 – An analysis on the farequote dataset with an anomaly we''d
    like to ignore'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![图A.10 – 对farequote数据集的分析，其中包含我们希望忽略的异常情况'
- en: '](img/B17040_14_10.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_14_10.jpg)'
- en: Figure A.10 – An analysis on the farequote dataset with an anomaly we'd like
    to ignore
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图A.10 – 对farequote数据集的分析，其中包含我们希望忽略的异常情况
- en: Now, let's explore the ways we can ignore the anomaly on February 9th using
    different situations.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探讨我们可以使用不同情况忽略2月9日异常的方法。
- en: Ignoring an upcoming (known) window of time
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 忽略即将到来的（已知）时间段
- en: Two methods can be used to ignore an upcoming window of time, as shown in the
    following subsections. One involves creating a special calendar event, and the
    other manipulates the time that the data feed runs for.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用两种方法来忽略即将到来的时间窗口，如下面的子节所示。一种涉及创建一个特殊的日历事件，另一种则是操纵数据源运行的时间。
- en: Creating a calendar event
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建日历事件
- en: 'You can easily create an event by clicking on **Settings** and then **Create**
    under the **Calendar** section. Here, I''ve created a calendar entry for February
    9th:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过点击**设置**，然后在**日历**部分下的**创建**来轻松创建一个事件。在这里，我为2月9日创建了一个日历条目：
- en: '![Figure A.11 – Creating a calendar event to ignore a specific time period'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图A.11 – 创建日历事件以忽略特定的时间段'
- en: '](img/B17040_14_11.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_14_11.jpg)'
- en: Figure A.11 – Creating a calendar event to ignore a specific time period
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图A.11 – 创建日历事件以忽略特定的时间段
- en: 'If a new job was created (and in this case, belonged to the **farequote_jobs**
    group so that it obeyed this calendar), then if the job were to be run over the
    data, the entire day of February 9th would be completely ignored:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果创建了一个新的作业（在这个案例中，属于**farequote_jobs**组，以便遵守这个日历），那么如果作业在数据上运行，2月9日整个一天将被完全忽略：
- en: '![Figure A.12 – A time period being ignored via a calendar event'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图A.12 – 通过日历事件来忽略一个时间段'
- en: '](img/B17040_14_12.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_14_12.jpg)'
- en: Figure A.12 – A time period being ignored via a calendar event
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图A.12 – 通过日历事件来忽略一个时间段
- en: As you can see, the entire day was masked, including the time of the anomalous
    spike.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，整个一天都被屏蔽了，包括异常峰值的时间。
- en: Stopping and starting the data feed to ignore the desired timeframe
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 停止和启动数据源以忽略所需的时间段
- en: 'By simply stopping and restarting the data feed of the anomaly detection job
    at the appropriate times, you can create a gap in the analysis. Here, the data
    feed was stopped at midnight on February 9th and restarted at midnight on February
    10th:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在适当的时间停止和重新启动异常检测作业的数据源，你可以在分析中创建一个间隙。在这里，数据源在2月9日凌晨停止，并在2月10日凌晨重新启动：
- en: '![Figure A.13 – A time period being ignored via manipulation of the data feed'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图A.13 – 通过操纵数据源来忽略一个时间段'
- en: '](img/B17040_14_13.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_14_13.jpg)'
- en: Figure A.13 – A time period being ignored via manipulation of the data feed
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图A.13 – 通过操纵数据源来忽略一个时间段
- en: It was like February 9th never happened! Now, let's discuss what you can do
    to ignore a window of time after the fact.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 就像2月9日从未发生过一样！现在，让我们讨论一下你可以在事后忽略时间窗口的方法。
- en: Ignoring an unexpected window of time, after the fact
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事后忽略一个意外的时间窗口
- en: To go *back in time* and *forget* that a window of time happened, we can use
    two methods. The first involves the simple cloning and re-running of historical
    data, and the second involves the use of model snapshots.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要*回到过去*并*忘记*一个时间窗口发生了，我们可以使用两种方法。第一种涉及简单的克隆和重新运行历史数据，第二种涉及使用模型快照。
- en: Cloning the job and re-running the historical data
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 克隆作业并重新运行历史数据
- en: Similar to the previous section as we saw, resulting in *Figure A.13*, we could
    create a new cloned job and just have the data feed avoid the window of time you
    wish to ignore. Stop it at the beginning of the window and resume it at the end
    of the window. This method works just fine if rebuilding the model from existing
    (still available) historical data isn't that burdensome. However, if you have
    really mature models that encapsulate data behaviors gleaned from data that you
    no longer have access to (because it aged out and was dropped from your cluster),
    then you will instead need to use the model snapshot technique discussed next.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前看到的类似，导致*图A.13*，我们可以创建一个新的克隆作业，并仅让数据馈送避免你希望忽略的时间窗口。在窗口开始时停止它，并在窗口结束时恢复它。如果从现有（仍然可用）的历史数据重建模型不是那么繁重，这种方法效果很好。然而，如果你有真正成熟的模型，这些模型封装了从你不再能访问的数据（因为数据已过时并被从你的集群中删除）中获取的数据行为，那么你将需要使用下一节讨论的模型快照技术。
- en: Reverting a job to a prior model snapshot
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将作业还原到先前的模型快照
- en: When cloning and retraining the job on existing historical data isn't desired
    or practical, you can effectively remove a window of time by using the fact that
    a model snapshot is taken periodically by the running job. By default, snapshots
    are captured approximately every 3 to 4 hours. You can change this interval (`background_persist_interval`)
    when you create or update a job.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当不希望或实际上无法在现有历史数据上克隆和重新训练作业时，你可以通过利用运行作业定期获取模型快照的事实来有效地移除一段时间窗口。默认情况下，快照大约每3到4小时捕获一次。当你创建或更新作业时，你可以更改此间隔（`background_persist_interval`）。
- en: Note
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Retention of these snapshots is controlled by a few other parameters (such as
    `daily_model_snapshot_retention_after_days` and `model_snapshot_retention_days`).
    Consult the Anomaly Detection API documentation at [https://www.elastic.co/guide/en/machine-learning/current/ml-api-quickref.html](https://www.elastic.co/guide/en/machine-learning/current/ml-api-quickref.html).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这些快照的保留由几个其他参数（如`daily_model_snapshot_retention_after_days`和`model_snapshot_retention_days`）控制。请参阅Anomaly
    Detection API文档[https://www.elastic.co/guide/en/machine-learning/current/ml-api-quickref.html](https://www.elastic.co/guide/en/machine-learning/current/ml-api-quickref.html)。
- en: 'The basic procedure for reverting an anomaly detection job to a prior snapshot
    is as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 将异常检测作业还原到先前快照的基本步骤如下：
- en: Stop the job's data feed if it is running.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果作业正在运行，请停止作业的数据馈送。
- en: Find the most recent model snapshot that was taken just before the window of
    time you wish to erase by using the `get` `snapshots` API call as documented at
    [https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-get-snapshot.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-get-snapshot.html).
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用[https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-get-snapshot.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-get-snapshot.html)中记录的`get
    snapshots` API调用，找到你希望擦除的时间窗口之前最近拍摄的模型快照。
- en: Revert the job to that snapshot by clicking the revert icon (![](img/B17040_14_15.png))
    or, if using the API, use the `_revert` command. In the Kibana UI, you will see
    options on how to delete the data and replay an analysis of the historical data
    after the snapshot time, including the ability to mask out the problematic time
    period using a **Calendar** event:![Figure A.15 – Reverting to a prior model snapshot
    with the ability to mask a period of time
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击还原图标 (![](img/B17040_14_15.png)) 将作业还原到该快照，或者如果使用API，则使用`_revert`命令。在Kibana
    UI中，你将看到如何删除数据以及如何在快照时间之后重新分析历史数据的选项，包括使用**日历**事件屏蔽问题时间段的能力：![图A.15 – 使用屏蔽时间段的能力还原到先前的模型快照
- en: '](img/B17040_14_16.jpg)'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_14_16.jpg)'
- en: Figure A.15 – Reverting to a prior model snapshot with the ability to mask a
    period of time
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图A.15 – 使用屏蔽时间段的能力还原到先前的模型快照
- en: Continue running the data feed in real time following the ignored time period,
    if desired.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果需要，在忽略的时间段之后继续实时运行数据馈送。
- en: With all of these helpful options, you can easily determine the right approach
    to ignoring a time interval and keeping your anomaly detection jobs from being
    polluted by problematic operational issues or undesired events.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些有用的选项中，您可以轻松地确定忽略时间间隔的正确方法，并防止异常检测作业受到问题操作问题或不受欢迎事件的影响。
- en: Using custom rules and filters to your advantage
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用自定义规则和过滤器
- en: While the anomaly detection jobs are incredibly useful, they are also agnostic
    to the domain and to the relevance of the raw data. In other words, the unsupervised
    machine learning algorithms do not know that a tenfold increase in CPU utilization
    (from 1% to 10%, for example) may not be that interesting to the proper operation
    of an application even though it may be statistically anomalous/unlikely in the
    scenario. Likewise, the anomaly detection jobs treat every entity analyzed equally,
    but the user might want to disavow results for a certain IP address or user ID,
    since the user knows that anomalies found for these entities are not desired or
    useful. The usage of custom rules and filters allows the user to inject domain
    knowledge into the anomaly detection job configuration, thereby having a fair
    amount of control as to what gets deemed or marked anomalous – or even if entities
    get considered part of the modeling process in the first place.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然异常检测作业非常有用，但它们对领域和原始数据的相关性却是无知的。换句话说，无监督的机器学习算法不知道 CPU 利用率增加十倍（例如，从 1% 增加到
    10%）可能对应用程序的正常运行并不那么有趣，尽管在统计上可能是异常的/不太可能。同样，异常检测作业对每个分析实体都同等对待，但用户可能希望拒绝某些 IP
    地址或用户 ID 的结果，因为用户知道这些实体发现的异常是不希望或不实用的。使用自定义规则和过滤器允许用户将领域知识注入异常检测作业配置中，从而对被认为或标记为异常的内容有相当的控制权——甚至是否将实体首先考虑为建模过程的一部分。
- en: Creating custom rules
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建自定义规则
- en: 'To define a custom rule, you can either accomplish it at job creation time
    (but only if using the Create job API) or after the job has revealed some anomalies
    by using the **Configure rules** menu option from the **actions** menu in the
    Anomaly Explorer UI:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 要定义自定义规则，您可以在作业创建时完成（但仅当使用创建作业 API 时）或使用异常探索器用户界面中的“操作”菜单中的“配置规则”菜单选项在作业揭示了一些异常后进行：
- en: '![Figure A.16 – The Configure rules menu item in the Anomaly Explorer UI'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.16 – 异常探索器用户界面中的“配置规则”菜单项'
- en: '](img/B17040_14_17.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_14_17.jpg)'
- en: Figure A.16 – The Configure rules menu item in the Anomaly Explorer UI
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.16 – 异常探索器用户界面中的“配置规则”菜单项
- en: 'When defining a rule, it is mostly self-explanatory. Here, we may decide that
    despite our response time anomaly of 282.025 ms (shown in *Figure A.16*), this
    is not that interesting and that we wish to ignore anomalies if the response time
    is still below 1 second (1,000 ms). We can define the rule as shown here:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义规则时，大多数情况下是自我解释的。在这里，我们可能决定，尽管我们的响应时间异常为 282.025 毫秒（如 *图 A.16* 所示），但这并不那么有趣，我们希望忽略响应时间仍然低于
    1 秒（1,000 毫秒）的异常。我们可以定义如下规则：
- en: '![Figure A.17 – The Create rule UI'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.17 – 创建规则的用户界面'
- en: '](img/B17040_14_18.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_14_18.jpg)'
- en: Figure A.17 – The Create rule UI
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.17 – 创建规则的用户界面
- en: There are additional options to exclude the value from the modeling and also
    to limit the scope of the rule to a certain filter list to have the rule only
    apply to particular entities (for example, only servers that are in a certain
    location). Filter lists can be defined under **Settings** and then **Filter lists**
    in the UI.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 有额外的选项可以排除值用于建模，也可以将规则的适用范围限制在特定的过滤器列表中，以便规则仅适用于特定的实体（例如，仅限于位于特定位置的服务器）。过滤器列表可以在用户界面中的“设置”和“过滤器列表”下定义。
- en: Note that the rule definition applies to future analysis (from the point of
    rule definition, forward in time) and does not apply to past anomalies. To have
    the rule apply to past anomalies, you would have to clone the existing job (once
    the rule was defined) and then re-run the analysis on the historical raw data.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，规则定义适用于未来的分析（从规则定义点开始，时间向前推进）且不适用于过去异常。若要让规则适用于过去的异常，您需要克隆现有的作业（一旦定义了规则）然后对历史原始数据重新运行分析。
- en: So, with rules and filters, the user has a lot of control as to what ultimately
    gets reported (and alerted) upon as anomalous. This allows a pretty major paradigm
    shift over the traditional approach of a bottom-up alert creation philosophy that
    has existed in IT operations for decades. An alternative approach is described
    in the next subsection.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过规则和过滤器，用户对最终报告（并警报）为异常的内容有相当大的控制权。这允许在IT运营中存在了几十年的传统自下而上的警报创建哲学发生相当大的范式转变。在下一小节中描述了另一种方法。
- en: Benefiting from custom rules for a "top-down" alerting philosophy
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从“自上而下”的警报哲学中受益于自定义规则
- en: If we asked, "what percentage of the data that you collect is being paid attention
    to?", often, a realistic answer is likely <10%, and maybe even <1%. The reason
    why this is the case is that the traditional approach to making data proactive
    is to start from scratch and then build up thresholds or rules-based alerts over
    time. This can be a daunting and/or tedious task that requires upfront knowledge
    (or at least a guess) as to what the expected behavior of each time series should
    be. Then, once the alerts have been configured, there can be an extended tuning
    process that balances alert sensitivity with annoying false positives. Additionally,
    there could also be metrics whose unusual behaviors could never be caught with
    a static threshold.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们问，“你收集的数据中有多少比例是被关注的？”通常，一个现实的答案可能是小于10%，甚至可能小于1%。这种情况的原因是，传统的将数据变得主动的方法是从头开始，然后随着时间的推移建立阈值或基于规则的警报。这可能是一项令人畏惧且/或繁琐的任务，需要事先了解（或至少猜测）每个时间序列的预期行为。然后，一旦配置了警报，可能会有一个长期的调整过程，以平衡警报的敏感性与令人烦恼的误报。此外，也可能存在一些指标，其异常行为无法通过静态阈值捕捉到。
- en: Combine this challenge with scale; if I have 10 metrics per server and 100 servers,
    there are 1,000 individual metrics. Creating individual alerts for each of these
    is impractical.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个挑战与规模结合起来；如果我每个服务器有10个指标，而我有100台服务器，那么就有1,000个单独的指标。为这些中的每一个创建单独的警报是不切实际的。
- en: However, a single anomaly detection job could be created against this data in
    less than 1 minute. Elastic ML's self-learning on historical data, which also
    takes very little time, will minimize false positives by adapting to the natural
    characteristics of each time series independently. However, if anomaly detection
    reveals things we don't care to know about, we can simply exclude them with custom
    rules.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，针对这些数据创建单个异常检测任务可能不到1分钟。弹性机器学习在历史数据上的自学习，这也花费很少的时间，将通过独立适应每个时间序列的自然特征来最小化误报。然而，如果异常检测揭示了我们不关心的事情，我们可以简单地通过自定义规则排除它们。
- en: This top-down approach (coverage for everything and then begin to exclude what
    you don't want) is faster and provides broader proactive coverage of the data
    than the bottom-up approach (creating threshold alerts from scratch).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这种自上而下的方法（覆盖所有内容，然后开始排除不需要的内容）比自下而上的方法（从头开始创建阈值警报）更快，并且为数据提供了更广泛的前瞻性覆盖。
- en: Anomaly detection job throughput considerations
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异常检测任务吞吐量的考虑
- en: 'Elastic ML is awesome and is no doubt very fast and scalable, but there will
    still be a practical upper bound of events/second processed to any anomaly detection
    job, depending on a couple of different factors:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 弹性机器学习（Elastic ML）非常出色，毫无疑问非常快且可扩展，但任何异常检测任务每秒处理的事件数量仍将有一个实际的上限，这取决于几个不同的因素：
- en: The speed at which data can be delivered to the algorithms (that is, query performance)
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可以传递给算法的速度（即查询性能）
- en: The speed at which the algorithms can chew through the data, given the desired
    analysis
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在给定所需分析的情况下，算法处理数据的速度
- en: 'For the latter, much of the performance is based upon the following:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于后者，大部分性能基于以下因素：
- en: The function(s) chosen for the analysis, that is, `count` is faster than `lat_long`
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为分析选择的功能，即 `count` 比较快于 `lat_long`
- en: The `bucket_span` value chosen (longer bucket spans are faster than smaller
    bucket spans because more buckets analyzed per unit of time compound the per-bucket
    processing overhead, which is writing results and so on)
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择的 `bucket_span` 值（较长的桶跨度比较小的桶跨度更快，因为每单位时间内分析的桶更多，这会累积每桶的处理开销，例如写入结果等）
- en: 'However, if you have a defined analysis set up and can''t change it for other
    reasons, then there''s not that much you can do unless you get creative and split
    the data up into multiple jobs. This is because the ML jobs (at least for now)
    are currently tied to a single CPU for the analysis bit (running the C++ process
    called autodetect). So, splitting the data into a few separate ML jobs to at least
    take advantage of multiple CPUs might be an option. But, before that, let''s focus
    on the former, the query''s performance, as there are a variety of possibilities
    here:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你已经定义了分析集并且由于其他原因无法更改，那么除非你富有创意地将数据分割成多个作业，否则你几乎无能为力。这是因为ML作业（至少目前）目前与单个CPU的分析部分（运行名为autodetect的C++进程）绑定。因此，将数据分割成几个单独的ML作业，至少可以充分利用多个CPU，可能是一个选择。但在那之前，让我们专注于前者，即查询的性能，因为这里有各种各样的可能性：
- en: Avoid doing a cross-cluster search to limit data transmission across the network.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免进行跨集群搜索以限制网络上的数据传输。
- en: Tweak data feed parameters to optimize performance.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整数据馈送参数以优化性能。
- en: Use Elasticsearch query aggregations to distribute the task of distilling the
    data to a smaller set of ML algorithms.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Elasticsearch查询聚合将提取数据的任务分配给更小的ML算法集。
- en: The first one is sort of obvious. You're only going to improve performance if
    you move the analysis closer to the raw data.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个似乎是显而易见的。只有当你将分析移得更接近原始数据时，你才能提高性能。
- en: The second one may take some experimentation. There are parameters, such as
    `scroll_size`, which control the size of each scroll. The default is 1,000, and
    for decent-sized clusters, this could be safely increased to 10,000\. Run some
    tests at different scroll sizes and see how it affects query and cluster performance.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个可能需要进行一些实验。有一些参数，例如`scroll_size`，控制每个滚动的大小。默认值为1,000，对于中等大小的集群，这个值可以安全地增加到10,000。在不同的滚动大小下进行一些测试，看看它如何影响查询和集群性能。
- en: The last one should make the biggest impact on performance, in my opinion, but
    obviously, it is a little tricky and error-prone to get the ES aggregation correct
    for it to work properly with ML, but it's not so bad. Refer to the documentation
    at [https://www.elastic.co/guide/en/machine-learning/current/ml-configuring-aggregation.html](https://www.elastic.co/guide/en/machine-learning/current/ml-configuring-aggregation.html)
    for more information. The downside of using aggregations with ML, in general,
    is that you lose access to the other fields in the data that might be good as
    influencers.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为最后一个对性能的影响最大，但显然，要正确配置ES聚合以使其与ML正常工作，这有点棘手且容易出错，但还不算太糟糕。有关更多信息，请参阅[https://www.elastic.co/guide/en/machine-learning/current/ml-configuring-aggregation.html](https://www.elastic.co/guide/en/machine-learning/current/ml-configuring-aggregation.html)。使用ML聚合的一般缺点是，你将失去访问数据中其他可能作为影响因素的字段。
- en: All in all, these are a few things to consider when optimizing the ML job's
    performance.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，这些都是优化ML作业性能时需要考虑的几个方面。
- en: Avoiding the over-engineering of a use case
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免过度设计用例
- en: I once worked with a user where we discussed different use cases for anomaly
    detection. In particular, this customer was building a hosted security operations
    center as part of their **managed security service provider** (**MSSP**) business,
    so they were keen to think about use cases in which ML could help.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾经与一个用户合作，我们讨论了异常检测的不同用例。特别是，这位客户正在构建一个托管安全运营中心，作为他们**托管安全服务提供商**（**MSSP**）业务的一部分，因此他们热衷于考虑ML可以帮助的用例。
- en: A high-level theme to their use cases was to look at a user's behavior and find
    unexpected behavior. One example that was discussed was login activity from unusual/rare
    locations such as *Bob just logged in from Ukraine, but he doesn't normally log
    in from there*.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的用例的一个高级主题是查看用户的行为并找到意外行为。讨论的一个例子是来自不寻常/罕见位置的登录活动，例如*鲍勃刚刚从乌克兰登录，但他通常不会从那里登录*。
- en: In the process of thinking the implementation through, there was talk of them
    having multiple clients, each of which had multiple users. Therefore, they were
    thinking of ways to split/partition the data so that they could execute `rare
    by country` for each and every user of every client.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在思考实现过程时，讨论了他们拥有多个客户，每个客户都有多个用户的情况。因此，他们正在考虑如何分割/划分数据，以便为每个客户的每个用户执行`按国家划分的稀有情况`。
- en: I asked them to take a step back and said, "Is it worthy of an anomaly if anyone
    logs in from Ukraine, not just Bob?" to which the answer was "Yes."
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我让他们退一步思考，问道：“如果任何人从乌克兰登录，不仅仅是鲍勃，这算不算一个异常？”得到的回答是“是的。”
- en: So, in this case, there is no point in splitting the analysis out per user;
    perhaps just keep the partitioning at the client level and simply lump all of
    the user's locations from each client into a single pool of observed countries.
    This is actually a better scenario; there's more overall data, and as we know,
    the `rare` function works best when there is lots of routine data to contrast
    a novel observation against.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这种情况下，没有必要按用户分割分析；也许只需在客户端级别保持分区，并将每个客户端的用户位置汇总到一个观察国家的单一池中。这实际上是一个更好的场景；整体数据更多，而且正如我们所知，`rare`函数在有大量常规数据可供对比新观察时工作得最好。
- en: Using anomaly detection on runtime fields
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用运行时字段进行异常检测
- en: In some cases, it might be necessary to analyze the value of a field that doesn't
    exist in the index mappings but can be calculated dynamically from other field
    values. This capability to dynamically define field values has existed for quite
    some time in Elasticsearch as **script fields**, but starting in v7.11, script
    fields are replaced by an updated concept known as **runtime fields**. In short,
    runtime fields are treated like first-class citizens in the Elasticsearch mapping
    (if defined there) and will eventually allow the user to promote a runtime field
    into an indexed field.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，可能有必要分析索引映射中不存在的字段的值，但这些值可以从其他字段的值动态计算得出。这种动态定义字段值的能力已经在Elasticsearch中存在了一段时间，被称为**脚本字段**，但从v7.11版本开始，脚本字段被一个更新的概念所取代，称为**运行时字段**。简而言之，运行时字段在Elasticsearch映射（如果在那里定义）中被视为一等公民，并最终允许用户将运行时字段提升为索引字段。
- en: Users can define runtime fields in the mapping or only in the search request.
    It is good to note that at the time of writing, there is no support for definitions
    of runtime fields in the data feed of an anomaly detection job. However, if the
    runtime fields are defined in the mappings, then the anomaly detection job can
    leverage them seamlessly.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以在映射中定义运行时字段，也可以只在搜索请求中定义。值得注意的是，在撰写本文时，异常检测作业的数据馈送中对运行时字段的定义没有支持。然而，如果运行时字段在映射中定义，那么异常检测作业可以无缝地利用它们。
- en: Note
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For more information on runtime fields, please consult the Elastic documentation
    at [https://www.elastic.co/guide/en/elasticsearch/reference/current/runtime.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/runtime.html).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于运行时字段的信息，请参阅Elastic文档[https://www.elastic.co/guide/en/elasticsearch/reference/current/runtime.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/runtime.html)。
- en: While the full details of runtime fields are beyond the scope of this book,
    it is important to know that anomaly detection jobs can leverage these dynamic
    fields just as if they were normal fields. Let's look at an interesting, albeit
    contrived, example.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然运行时字段的全部细节超出了本书的范围，但重要的是要知道，异常检测作业可以利用这些动态字段，就像它们是正常字段一样。让我们看看一个有趣但人为构造的例子。
- en: 'Suppose that we return to the `farequote` example shown in *Figure A.1*, where,
    for the sake of this argument, we declare that February 9th is a special day of
    some type for `airline:AAL` – perhaps the rough equivalent of Black Friday or
    Cyber Monday, or even just a day where we know things will be slightly off from
    normal by a known amount. We will contrive a scenario in which we know that AAL
    will experience predictably higher response times that could be 20% slower than
    normal (meaning measurements of `responsetime` should be 20% higher, in milliseconds).
    We don''t want to make February 9th a calendar event for Elastic ML to avoid completely,
    and we don''t want to stop looking at the data for AAL. Rather, we just want to
    temper the response time measures down by 20% so as not to upset our normal modeling
    and/or alerting. We can accomplish this via runtime fields:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们回到*图A.1*中所示的`farequote`示例，在这个论点中，我们宣布2月9日对`airline:AAL`来说是一个特殊的日子——可能是黑色星期五或网络星期一的大致等同，或者甚至只是我们知道事情会比正常情况稍微偏离已知量的那一天。我们将构造一个场景，其中我们知道AAL将经历可预测的更高响应时间，这可能会比正常情况慢20%（意味着`responsetime`的测量应该比正常情况高20%，以毫秒为单位）。我们不想让2月9日成为Elastic
    ML完全避免的日历事件，我们也不想停止查看AAL的数据。我们只是想将响应时间测量值降低20%，以免影响我们的正常建模和/或警报。我们可以通过运行时字段来实现这一点：
- en: 'The first thing to do is to define a new runtime field in the mapping for the
    index, called `responsetime_adjusted`:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先要做的是在索引的映射中定义一个新的运行时字段，称为`responsetime_adjusted`：
- en: '[PRE1]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This field (for now) will be exactly the same as the `responsetime` field for
    all airlines, simply accomplished by multiplying the field value by the constant
    of `1.0`.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个字段（目前）将与其他航空公司的`responsetime`字段完全相同，只需通过将字段值乘以常数`1.0`即可实现。
- en: Next, we will configure a job to use a `high_mean` detector on this new `responsetime_adjusted`
    field, where we will also split the analysis on the `airline` field:![Figure A.18
    – Configuring a job to analyze a runtime field
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将配置一个作业，使用新的`responsetime_adjusted`字段上的`high_mean`检测器，我们还将对`airline`字段进行拆分分析：![图
    A.18 – 配置作业以分析运行时字段
- en: '](img/B17040_14_19.jpg)'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_14_19.jpg](img/B17040_14_19.jpg)'
- en: Figure A.18 – Configuring a job to analyze a runtime field
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.18 – 配置作业以分析运行时字段
- en: 'We will run the data feed up until midnight on February 9th but stop the analysis
    there. To then temper the response time for AAL''s data by 20% (but leave other
    airlines'' data alone), we will execute the following command:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将运行数据馈送到2月9日的午夜，但在这里停止分析。为了将AAL数据的响应时间降低20%（但不对其他航空公司的数据进行调整），我们将执行以下命令：
- en: '[PRE2]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Next, we will continue the job's data feed to analyze the special day (February
    9th, but stop at midnight at the beginning of February 10th).
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将继续作业的数据馈送以分析特殊日子（2月9日，但停止在2月10日开始前的午夜）。
- en: Once February 9th's data has been analyzed, we will return the response time
    for AAL's data back to normal by re-invoking the command in *Step 1*.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦2月9日的数据被分析，我们将通过重新调用*步骤1*中的命令，将AAL的数据的响应时间恢复到正常状态。
- en: We'll allow the job to continue analyzing the rest of the data, as normal.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将允许作业继续分析剩余的数据，就像平常一样。
- en: 'The end result is that we were able to successfully suppress the values of
    AAL''s response times by 20% (as evidenced by the depressed values between the
    two annotations), but we were still able to pick up a significant anomaly despite
    our special treatment for AAL:'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最终结果是，我们能够成功地将AAL的响应时间值降低了20%（如两个注释之间的低值所示），尽管我们对AAL进行了特殊处理，但我们仍然能够捕捉到显著的异常：
- en: '![Figure A.19 – Results of the job that analyzed a dynamically changed runtime
    field'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 A.19 – 分析动态更改的运行时字段的作业结果'
- en: '](img/B17040_14_20.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_14_20.jpg](img/B17040_14_20.jpg)'
- en: Figure A.19 – Results of the job that analyzed a dynamically changed runtime
    field
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.19 – 分析动态更改的运行时字段的作业结果
- en: This technique could be useful in bringing any number of dynamic modifications
    to the data on the fly for enhanced analysis or to support the analysis in aspects
    of the data that may not be available in the default field mappings of the index.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术可以在分析过程中动态地对数据进行任何数量的修改，以增强分析或支持对索引默认字段映射中可能不可用的数据方面的分析。
- en: Summary
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Elastic ML is a powerful, flexible, yet easy-to-use feature that gives the power
    of data science to non-data scientists so that they can gain insight into massive
    amounts of data. Throughout this entire book, there are many different ways in
    which users can take advantage of technology to solve real-world challenges in
    IT. We hope that you will take the knowledge that you have gained in this book
    and implement some great use cases of your own. Don't worry about solving all
    possible problems on day 1 – start small, get some tangible wins, and grow your
    usage as you gain more confidence. Success will breed success!
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic ML是一个强大、灵活且易于使用的功能，它将数据科学的权力赋予了非数据科学家，使他们能够深入了解大量数据。在整个这本书中，用户可以利用技术以多种方式解决IT领域的现实世界挑战。我们希望您能将在这本书中学到的知识应用于一些您自己的优秀用例。不要担心第一天就解决所有可能的问题——从小处着手，获得一些实际的胜利，随着您获得更多信心，逐渐增加您的使用量。成功会孕育成功！
