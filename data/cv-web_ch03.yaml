- en: Chapter 3. Easy Object Detection for Everyone
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章：面向所有人的简单物体检测
- en: In the last chapter, We discussed fundamental topics such as matrix operations
    and matrix convolutions. Moreover, we saw how to apply various image filters and
    how to use them in our applications. But those topics are mostly about image processing,
    not about Computer Vision! What do Computer Vision methods do by themselves? They
    provide the ability to understand an image by analyzing it in such a manner that
    the computer can provide the information about objects of an image scene. Libraries,
    which we discussed previously, provide various functionalities to find different
    objects in an image. In this chapter, we will mainly discuss methods that are
    included in the tracking.js ([http://trackingjs.com](http://trackingjs.com)) and
    JSFeat ([http://inspirit.github.io/jsfeat/](http://inspirit.github.io/jsfeat/))
    libraries to get objects from an image. We will see how to find a colored object,
    and how to find an object using a template. Further, we will create our own object
    detector. These techniques can be implemented not only for an image, but for a
    video too! Finally, we will move on to the object tracking topic.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了诸如矩阵运算和矩阵卷积等基本主题。此外，我们看到了如何应用各种图像滤波器以及如何在我们的应用程序中使用它们。但那些主题主要关于图像处理，而不是计算机视觉！计算机视觉方法本身能做什么？它们通过分析图像提供了一种能力，使计算机能够提供有关图像场景中物体信息。我们之前讨论的库提供了各种功能，以在图像中找到不同的物体。在本章中，我们将主要讨论包含在tracking.js
    ([http://trackingjs.com](http://trackingjs.com)) 和 JSFeat ([http://inspirit.github.io/jsfeat/](http://inspirit.github.io/jsfeat/))
    库中的方法，以从图像中获取物体。我们将看到如何找到彩色物体，以及如何使用模板找到物体。进一步地，我们将创建自己的物体检测器。这些技术不仅可以应用于图像，还可以应用于视频！最后，我们将转向物体跟踪主题。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Color object detection
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 颜色物体检测
- en: Digging into the tracking.js API
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入研究tracking.js API
- en: Image features
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像特征
- en: Descriptors and object matching
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述符和物体匹配
- en: Detecting color objects
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测颜色物体
- en: In the previous chapters, we worked mainly with grayscale images. Of course,
    the shape and intensity parts of objects are important, but what about the color
    information? Why don't we use that too? For example, a red apple on a table can
    be easily detected with just the color information. Actually, that is why color
    object detection sometimes performs much better than other detector methods. In
    addition, it is much faster to implement these algorithms, and a computer usually
    consumes less resources for these types of operation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们主要处理的是灰度图像。当然，物体的形状和强度部分很重要，但颜色信息呢？我们为什么不使用它呢？例如，一张桌子上的红色苹果仅通过颜色信息就可以轻松检测到。实际上，这也是为什么颜色物体检测有时比其他检测方法表现得更好。此外，实现这些算法的速度更快，计算机在执行这类操作时通常消耗的资源也更少。
- en: The tracking.js library provides an outstanding functionality to create a color
    detection application. We will start from a basic color tracking example. It is
    relatively simple, but you need to keep in mind that it performs best only when
    a colored object can be easily separated from the background.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: tracking.js库提供了一个出色的功能，用于创建颜色检测应用程序。我们将从一个基本的颜色跟踪示例开始。它相对简单，但你需要记住，它只有在彩色物体可以轻松从背景中分离出来时才表现最佳。
- en: Using predefined colors with the tracking.js library
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用tracking.js库中的预定义颜色
- en: Color detection is one of the methods provided by tracking.js. To use it properly,
    we need to learn some background first.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色检测是tracking.js提供的方法之一。为了正确使用它，我们首先需要了解一些背景知识。
- en: 'We will start with the intuitive steps:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从直观的步骤开始：
- en: First, we find all connected regions with the specified color. This is the most
    computation consuming part of the algorithm. The smaller the color regions present
    on an image, the faster the algorithm works.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们找到所有具有指定颜色的连通区域。这是算法中最消耗计算的部分。图像上存在的颜色区域越小，算法运行得越快。
- en: Next, we define bounding boxes or rectangles around each of those regions. Finally,
    we merge overlapping boxes to find the main object. Merging is done by just one
    pass. So, if an image has overlapping boxes that are produced after the first
    merge, then they will still overlap each other.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义围绕每个区域的边界框或矩形。最后，我们合并重叠的框以找到主要物体。合并操作只需一次遍历。因此，如果一个图像在第一次合并后产生了重叠的框，那么它们仍然会相互重叠。
- en: 'We will run the algorithm using three colors: yellow, magenta, and cyan. Here
    is an example of the color detection algorithm:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用三种颜色：黄色、品红色和青色来运行该算法。以下是一个颜色检测算法的示例：
- en: '![Using predefined colors with the tracking.js library](img/image00112.jpeg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![使用tracking.js库中的预定义颜色](img/image00112.jpeg)'
- en: As you can see, it is really hard to get color objects from the first image.
    It is a bit easier to do so for the second, but it can be easily done only for
    the center of the flower, since it can be separated from the leaves and flower
    petals.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，从第一张图片中获取颜色对象非常困难。对于第二张来说，这样做稍微容易一些，但只有对于花朵的中心来说很容易做到，因为它可以与叶子分开，并且与花瓣分开。
- en: How can we do that with the tracking.js library? In this example, we will use
    the canvas, as we did in the previous chapters. It can be done for other tags
    too, which we will see a bit in the following.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何使用tracking.js库来实现这一点？在这个例子中，我们将使用画布，就像我们在前面的章节中所做的那样。这也可以用于其他标签，我们将在下面的内容中稍作展示。
- en: 'First, we define a `ColorTracker` object and add prebuilt colors to it. For
    now, there are only three colors available: `magenta`, `cyan`, and `yellow`.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义一个`ColorTracker`对象并将其预构建的颜色添加到其中。目前，只有三种颜色可用：`magenta`、`cyan`和`yellow`。
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The tracker variable is just a holder for various parameters, based on which
    we will track an object.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`tracker`变量只是一个用于存储各种参数的容器，基于这些参数我们将跟踪一个对象。'
- en: 'Then, we need to define a function which will be called after the `track` event.
    In the example, we just want to show all our bounding boxes over the canvas and
    we execute the `draw` function for each rectangle here. Since the algorithm returns
    a color for a box, it will be easier to see the difference between results:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要定义一个函数，该函数将在`track`事件之后被调用。在示例中，我们只想在画布上显示所有我们的边界框，并为每个矩形执行`draw`函数。由于算法为框返回一个颜色，这将更容易看到结果之间的差异：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As we did in the first chapter, we create a `<div>` element for our canvas:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第一章中所做的那样，我们为我们的画布创建一个`<div>`元素：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'There are many ways of printing a result, for now, we take an example of the
    draw function from the tracking.js examples section. It will create a `<div>`
    element for each bounding box and append it to the `<div>` tag around the canvas:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多种打印结果的方法，现在我们以tracking.js示例部分中的`draw`函数为例。它将为每个边界框创建一个`<div>`元素，并将其附加到画布周围的`<div>`标签中：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Finally, we only need to start the tracker by calling the `track` function.
    The first parameter defines the element that contains graphical information about
    where we need to detect a color. The second parameter holds the `tracker` variable:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们只需要通过调用`track`函数来启动跟踪器。第一个参数定义了包含我们需要检测颜色位置图形信息的元素。第二个参数持有`tracker`变量：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: It was simple, wasn't it? We saw how the tracker works with not-so-easy examples.
    It can be applied for those cases, but it will not be smart to do that. Let's
    see examples where the color detection works really well.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这很简单，不是吗？我们看到了跟踪器在不那么容易的例子中的工作方式。它可以应用于这些情况，但这样做并不聪明。让我们看看颜色检测真正奏效的例子。
- en: Using your own colors
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用你自己的颜色
- en: 'Only three colors?! Is that it? Of course not. If you want, you can register
    your own colors for object detection. It is not much harder than setting predefined
    colors. We first need to register a new color for the `ColorTracker` function.
    You create a mapping between a string and a function, where the function should
    return a Boolean condition based on three channels: R, G, and B. The `true` is
    returned when the color matches our condition and `false` if not. Here, we want
    to get all colors where the red channel prevails. Since we start from really dark
    pixels, we will call it the `darkRed` color:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 只有三种颜色？！这就结束了？当然不是。如果你想，你可以为对象检测注册自己的颜色。这并不比设置预定义颜色更难。我们首先需要为`ColorTracker`函数注册一个新的颜色。你创建一个字符串和函数之间的映射，其中函数应该基于三个通道：R、G和B返回一个布尔条件。当颜色匹配我们的条件时返回`true`，如果不匹配则返回`false`。在这里，我们希望获取所有红色通道占主导地位的颜色。由于我们从非常暗的像素开始，我们将它称为`darkRed`颜色：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'By doing that, we register the darkRed color for all color trackers which we
    create. Now, we need to define a new color tracker with the newly registered color:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样做，我们为所有创建的颜色跟踪器注册了深红色颜色。现在，我们需要定义一个新的颜色跟踪器，使用新注册的颜色：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'All other parts of the code are the same as they were in the previous example.
    The good thing is that the tracking.js library itself finds the color for a bounding
    box, we do not need to specify it. For example, we have picked a new image—two
    beautiful apples and the result looks something like the following screenshot:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的其他部分与之前的示例相同。好事是 tracking.js 库本身会为边界框找到颜色，我们不需要指定它。例如，我们选择了一张新的图片——两个美丽的苹果，结果看起来就像以下截图：
- en: '![Using your own colors](img/image00113.jpeg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![使用自己的颜色](img/image00113.jpeg)'
- en: Do you see how the apples stand out from the cloth? That is an example of an
    image where color tracker shows its best performance. Use the color detection
    when an object can be easily separated from the background and you will not be
    disappointed. Furthermore, the basic advantages are that color detection is fast
    in terms of computation, and it is very easy to implement.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到苹果从布料中突显出来了吗？这是一个颜色跟踪器表现出最佳性能的图像示例。当对象可以轻松地从背景中分离出来时，使用颜色检测，你不会失望。此外，基本优势在于颜色检测在计算方面速度快，而且实现起来非常简单。
- en: Digging into the tracking.js API
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入了解 tracking.js API
- en: We saw a color tracker and added our own color matcher. The tracking.js library
    provides an excellent functionality to add a new object detector. It has a clear
    API and good documentation to follow ([http://trackingjs.com/docs.html](http://trackingjs.com/docs.html)).
    But first, we will see how to use a tracker with different HTML tags and dig a
    bit into the tracker API.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了一个颜色跟踪器并添加了我们自己的颜色匹配器。tracking.js 库提供了一个非常出色的功能来添加一个新的对象检测器。它有一个清晰的 API
    和良好的文档可供参考([http://trackingjs.com/docs.html](http://trackingjs.com/docs.html))。但首先，我们将看看如何使用跟踪器与不同的
    HTML 标签一起使用，并深入了解一下跟踪器 API。
- en: Using the <img> and <video> tags
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 `<img>` 和 `<video>` 标签
- en: The library uses a `<canvas>` tag to operate with images. If you run a tracker
    on a different tag, then the library will convert the information from it to the
    canvas automatically.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 该库使用 `<canvas>` 标签来处理图像。如果你在另一个标签上运行跟踪器，那么库会自动将信息从它转换到画布上。
- en: 'First of all, tracking can be applied to an `<img>` tag:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，跟踪功能可以应用于 `<img>` 标签：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In that case, we can specify the image path not in a JavaScript code, but in
    the tag itself. To run a tracker, we just need to set the tag `id` as a first
    parameter:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以在标签本身中指定图像路径，而不是在 JavaScript 代码中。要运行跟踪器，我们只需将标签 `id` 设置为第一个参数：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next comes the `<video>` tag. In our `<div>` element, which wraps the canvas,
    we need to add a `<video>` tag with the path to a video file:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是 `<video>` 标签。在我们的 `<div>` 元素中，它包裹着画布，我们需要添加一个带有视频文件路径的 `<video>` 标签：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The library will take each frame and process it separately. If we want to print
    the result on a canvas, we need to clear the canvas of the previous tracking results.
    We can do that using the `context.clearRect` function and add it to the postprocessing
    part of the tracker functionality:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 该库将逐帧处理每个帧。如果我们想在画布上打印结果，我们需要清除之前跟踪结果所在的画布。我们可以使用 `context.clearRect` 函数并添加到跟踪功能的后期处理部分：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can draw new elements not only with the `<div>` tags, but also using the
    context itself. It is easier to use and the speed will be a bit faster. Here,
    in addition to just displaying a bounding box, we place a rectangle parameter
    around it:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不仅可以使用 `<div>` 标签来绘制新元素，还可以使用上下文本身。这样使用起来更简单，速度也会更快。在这里，除了仅仅显示一个边界框之外，我们还在它周围放置了一个矩形参数：
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To run the tracker with a video file, we place the `id` parameters of a `<video>`
    tag, as we did previously with other content tags:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用视频文件运行跟踪器，我们放置一个 `<video>` 标签的 `id` 参数，就像我们之前在其他内容标签上做的那样：
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'If you want to work with a camera instead of a video file, you need to remove
    the source from a `<video>` tag and add a new, third, parameter to the `track`
    call:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要使用摄像头而不是视频文件，你需要从 `<video>` 标签中移除源，并在 `track` 调用中添加一个新的、第三个参数：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'What if you have a long-running video? In that case, you probably need to have
    full control over your application, as you may want to stop and rerun the tracker.
    First, you need to get a reference to it:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个长时间运行的视频呢？在这种情况下，你可能需要完全控制你的应用程序，因为你可能想要停止并重新运行跟踪器。首先，你需要获取它的引用：
- en: '[PRE14]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You can stop or run a tracking task any time with those functions:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用这些函数随时停止或运行跟踪任务：
- en: '[PRE15]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'If you are still not satisfied with your control over the tracking methods,
    there are various functions that can help you while you do the tracking:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仍然对自己的跟踪方法控制不满意，有各种函数可以在跟踪过程中帮助你：
- en: '`setMinDimension`: This sets a bounding box of an object with minimum width
    and height; by default, it is 20 pixels. It helps to avoid noisy objects and focuses
    on objects that hold a larger space.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setMinDimension`：这个函数设置对象边界框的最小宽度和高度；默认为20像素。它有助于避免噪声对象并专注于占据更大空间的物体。'
- en: '`setMaxDimension`: This sets the maximum dimensions of a bounding box, it is
    infinity by default. In some cases, it helps to remove an image background which
    is of the same color as the object.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setMaxDimension`：这个函数设置边界框的最大尺寸，默认为无穷大。在某些情况下，它有助于移除与对象颜色相同的图像背景。'
- en: '`setMinGroupSize`: This sets the minimum number of pixels for a colored object
    to be classified as a rectangle; the default is 30\. This also helps to reduce
    the noise significantly.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setMinGroupSize`：这个函数设置一个彩色对象被分类为矩形的像素最小数量；默认为30。这也显著减少了噪声。'
- en: Building a custom tracker
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建自定义追踪器
- en: It is time to build your own tracker! The tracking.js library provides an abstract
    interface for that, but you need to write the core of the tracker—its brains.
    We will create a tracker that will determine edge pixels using the knowledge that
    you gained from the previous chapter.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候构建你自己的追踪器了！tracking.js库提供了一个抽象接口，但你需要编写追踪器的核心——它的“大脑”。我们将创建一个追踪器，它将使用你在上一章中获得的知识来确定边缘像素。
- en: 'As a first step, we will create a constructor of our new `CornerTracker` variable.
    We will use the Sobel filter for our example, so we only need one threshold parameter
    for it, which we define here as a field of our object:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们将创建我们的新`CornerTracker`变量的构造函数。在我们的示例中，我们将使用Sobel滤波器，所以我们只需要一个阈值参数，我们在这里将其定义为对象的一个字段：
- en: '[PRE16]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Our tracker must inherit from the basic tracker of the tracking.js library,
    which can be done using the following function:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的追踪器必须继承自tracking.js库的基本追踪器，这可以通过以下函数实现：
- en: '[PRE17]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The most important part of our tracker is a `track` function. It contains the
    tracker logic. As parameters, it takes an array of pixels from an image and the
    dimensions of that image. On the inside, we run the Sobel filter, and if you remember,
    it returns a 4-channel array for a grayscale image, but we need only one. We check
    whether the value exceeds the threshold and if so, we add a new edge pixel there.
    After all, we need to emit the computed data using the `emit` function. It sends
    the output data through the `track` event. The output for our example is the coordinates
    of pixels that passed the condition:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们追踪器最重要的部分是一个`track`函数。它包含追踪逻辑。作为参数，它接受来自图像的像素数组以及该图像的尺寸。在内部，我们运行Sobel滤波器，如果你还记得，它为灰度图像返回一个4通道数组，但我们只需要一个。我们检查值是否超过阈值，如果是，我们在那里添加一个新的边缘像素。最后，我们需要使用`emit`函数发出计算出的数据。它通过`track`事件发送输出数据。我们示例的输出是满足条件的像素坐标：
- en: '[PRE18]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To create a new tracker, we call the constructor with a threshold parameter
    and set the threshold to 400:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个新的追踪器，我们需要使用构造函数并设置阈值为400：
- en: '[PRE19]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'At the end of tracking process, we plot the result. The plot function simply
    puts the pixels on a canvas:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在追踪过程结束时，我们绘制结果。绘图函数简单地将像素放在画布上：
- en: '[PRE20]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To start our tracker, we need to initiate the tracking function as we did previously:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动我们的追踪器，我们需要像之前一样初始化追踪函数：
- en: '[PRE21]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s match the result from the previous chapter with our tracker:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将上一章的结果与我们的追踪器进行匹配：
- en: '![Building a custom tracker](img/image00114.jpeg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![构建自定义追踪器](img/image00114.jpeg)'
- en: 'From left to right: an image after the Sobel filter, Sobel filter thresholding
    and the result after our tracker.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从左到右：Sobel滤波器后的图像，Sobel滤波器阈值化和我们追踪器后的结果。
- en: As we see, the results match together, so we have done everything right. Good
    job!
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，结果是一致的，所以我们已经做对了所有的事情。干得好！
- en: The tracking.js API provides a very good abstraction level for creating your
    own object tracker. There are not many trackers there yet, but you can always
    extend the functionality. The main advantage of this abstraction is that you can
    focus on the implementation of algorithms without wasting your time thinking about
    how to apply your algorithm to an image.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: tracking.js API为创建自己的对象追踪器提供了一个非常好的抽象级别。目前那里还没有很多追踪器，但你总是可以扩展其功能。这个抽象的主要优势是你可以专注于算法的实现，而无需浪费时间思考如何将你的算法应用于图像。
- en: Image features
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像特征
- en: 'Color object detection and detection of changes in intensity of an image, is
    a simple Computer Vision method. It is a fundamental thing which every Computer
    Vision enthusiast should know. To get a better picture of Computer Vision capabilities,
    we will see how to find an object on a scene using a template. This topic includes
    several parts: feature extraction and descriptor matching. In this part, we will
    discuss feature detection and its application in Computer Vision.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色物体检测和图像强度变化的检测是一种简单的计算机视觉方法。这是每个计算机视觉爱好者都应该了解的基本知识。为了更好地了解计算机视觉的能力，我们将看到如何使用模板在场景中找到物体。这个主题包括几个部分：特征提取和描述符匹配。在本部分中，我们将讨论特征检测及其在计算机视觉中的应用。
- en: Detecting key points
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测关键点
- en: What information do we get when we see an object on an image? An object usually
    consists of some regular parts or unique points, which represent the particular
    object. Of course, we can compare each pixel of an image, but it is not a good
    idea in terms of computational speed. We can probably take unique points randomly,
    thus reducing the computation cost significantly. However, we will still not get
    much information from random points. Using the whole information, we can get too
    much noise and lose the important parts of an object representation. Eventually,
    we need to consider that both ideas—getting all pixels and selecting random pixels—are
    really bad. So, what can we do instead?
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在图像上看到一个物体时，我们得到了哪些信息？一个物体通常由一些规则的部分或独特的点组成，它们代表了特定的物体。当然，我们可以比较图像中的每个像素，但从计算速度的角度来看，这并不是一个好主意。我们可能随机选择独特的点，从而显著降低计算成本。然而，我们仍然不会从随机点中得到很多信息。使用全部信息，我们可能会得到太多的噪声，并丢失物体表示的重要部分。最终，我们需要考虑这两种想法——获取所有像素和选择随机像素——实际上都是不好的。那么，我们还能做什么呢？
- en: Since we are working with a grayscale image and we need to get a unique point,
    we need to focus on intensity information, for example, getting object edges like
    we did with the Canny edge detector or Sobel filter. We are closer to the solution!
    But still, not close enough. What if we have a long edge? Don't you think that
    it is a bit bad that we have too many unique pixels which lay on this edge? An
    edge of an object has end points or corners. If we reduce our edge to those corners,
    we will get enough unique pixels and remove unnecessary information.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在处理一个灰度图像，并且我们需要获取一个独特的点，因此我们需要关注强度信息，例如，获取与Canny边缘检测器或Sobel滤波器类似的对象边缘。我们离解决方案更近了！但仍然不够近。如果我们有一个长边缘呢？你不认为我们在这个边缘上有太多独特的像素有点不好吗？物体的边缘有端点或角落。如果我们把我们的边缘减少到那些角落，我们将得到足够的独特像素并去除不必要的信息。
- en: There are various methods of getting keypoints from an image, many of them extract
    corners as keypoints. To get them, we will use the **Features from Accelerated
    Segment Test** (**FAST**) algorithm. It is really simple and you can easily implement
    it by yourself if you want. But you do not need to. The algorithm implementation
    is provided both by the tracking.js and JSFeat libraries.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 从图像中获取关键点的方法有很多，其中许多方法将角落作为关键点提取。为了获取它们，我们将使用**加速分割测试（FAST**）算法。它非常简单，如果你愿意，你可以很容易地自己实现它。但你不一定需要。算法实现由tracking.js和JSFeat库提供。
- en: 'The idea of the FAST algorithm can be captured from the following image:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 从以下图像中可以捕捉到FAST算法的想法：
- en: '![Detecting key points](img/image00115.jpeg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![检测关键点](img/image00115.jpeg)'
- en: Suppose we want to check whether the pixel **P** is a corner, we will check
    16 pixels around it. And if at least 9 pixels in an arc around **P** are much
    darker or brighter than the **P** value, then we say that **P** is a corner. How
    much darker or brighter the **P** pixels be? The decision is made by applying
    a threshold for the difference between the value of **P** and the value of pixels
    around **P**.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要检查像素**P**是否是角落，我们将检查它周围的16个像素。如果围绕**P**的至少9个像素在一个弧形区域内比**P**的值暗得多或亮得多，那么我们就说**P**是一个角落。**P**像素可以暗得多或亮得多到什么程度？这个决定是通过应用**P**的值与其周围像素值之间的阈值来做出的。
- en: A practical example
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个实际例子
- en: 'First, we will start with an example of FAST corner detection for the tracking.js
    library. Before we do something, we can set the detector threshold. The threshold
    defines the minimum difference between a tested corner and points around it:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将从tracking.js库的FAST角落检测示例开始。在我们做任何事情之前，我们可以设置检测器的阈值。阈值定义了测试角落与其周围点之间的最小差异：
- en: '[PRE22]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'It is usually good practice to apply a Gaussian blur to an image before we
    start the method. It significantly reduces the noise of an image:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在开始方法之前对图像应用高斯模糊是一个好习惯。这可以显著减少图像的噪声：
- en: '[PRE23]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Remember, that the blur function returns a 4 channel array—RGBA. In that case,
    we need to convert it to a 1-channel array. Since we can easily skip other channels,
    it should not be a problem:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，模糊函数返回一个4通道数组——RGBA。在这种情况下，我们需要将其转换为1通道数组。由于我们可以轻松跳过其他通道，所以这应该不是问题：
- en: '[PRE24]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, we run a corner detection function on our image array:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在我们的图像数组上运行一个角落检测函数：
- en: '[PRE25]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The result returns an array where length is twice that of the corners number.
    The array is returned in a format: `[x0,y0,x1,y1,...]`, where `[xn, yn]` are coordinates
    of a detected corner. To print the result on a canvas, we will use the `fillRect`
    function. Since the number of points is usually around several hundreds, we cannot
    efficiently use `<div>` tag for that:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 结果返回一个长度是角落数量的两倍的数组。数组以以下格式返回：`[x0,y0,x1,y1,...]`，其中`[xn, yn]`是检测到的角落的坐标。为了在画布上打印结果，我们将使用`fillRect`函数。由于点的数量通常在几百个左右，我们不能有效地使用`<div>`标签来处理：
- en: '[PRE26]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now we will see an example with the JSFeat library, the steps for which are
    very similar to what we saw with tracking.js. First, we set the global threshold
    with a function:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用JSFeat库看到一个示例，其步骤与我们在tracking.js中看到的过程非常相似。首先，我们使用一个函数设置全局阈值：
- en: '[PRE27]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Then, we apply a Gaussian blur to the image matrix and run corner detection:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们对图像矩阵应用高斯模糊并运行角落检测：
- en: '[PRE28]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We need to preallocate keypoints for a corner''s result. The `keypoint_t` function
    is just a new type, which is useful for key points of an image. The first two
    parameters represent coordinates of a point, and the other parameters represent
    point score (is that point good enough to be a key point?) point level (which
    you can use in an image pyramid, for example), and point angle (which is usually
    used for the gradient orientation):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为角落的结果预先分配关键点。`keypoint_t`函数只是一个新类型，它对图像的关键点很有用。前两个参数表示一个点的坐标，其他参数表示点分数（这个点是否足够好以成为一个关键点？）点级别（例如，你可以在图像金字塔中使用它），以及点角度（这通常用于梯度方向）：
- en: '[PRE29]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'After all this, we execute the FAST corner detection method. As a last parameter
    of the detection function, we define a border size. The border is used to constrain
    circles around each possible corner. For example, you cannot precisely say if
    the point is a corner for the `[0,0]` pixel. There is no `[0, -3]` pixel in our
    matrix:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些之后，我们执行FAST角落检测方法。作为检测函数的最后一个参数，我们定义一个边界大小。边界用于约束每个可能的角落周围的圆。例如，你不能精确地说一个点是否是`[0,0]`像素的角落。在我们的矩阵中没有`[0,
    -3]`像素：
- en: '[PRE30]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Since we preallocated the corners, the function returns the number of calculated
    corners for us. The result returns an array of structures with the `x` and `y`
    fields, so we can print it using those fields:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们预先分配了角落，函数会返回为我们计算出的角落数量。结果返回一个包含`x`和`y`字段的结构的数组，因此我们可以使用这些字段来打印它：
- en: '[PRE31]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The result is nearly the same for both algorithms. The difference is in some
    parts of realization. Let''s look at the following examples:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 两种算法的结果几乎相同。区别在于实现的一些部分。让我们看看以下示例：
- en: '![A practical example](img/image00116.jpeg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![一个实际例子](img/image00116.jpeg)'
- en: 'From left to right: tracking.js without blur, JSFeat without blur, tracking.js
    and JSFeat with blur.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从左到右：没有模糊的tracking.js，没有模糊的JSFeat，有模糊的tracking.js和JSFeat。
- en: If you look closely, you can see the difference between tracking.js and JSFeat
    results, but it is not easy to spot. Look at how much noise was reduced by applying
    just a small 3 x 3 Gaussian filter! A lot of noisy points were removed from the
    background. And now the algorithm can focus on points that represent flowers and
    the pattern of the vase.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细看，你可以看到tracking.js和JSFeat结果之间的差异，但并不容易发现。看看仅应用一个小的3 x 3高斯滤波器就减少了多少噪声！许多噪声点被从背景中移除。现在算法可以专注于代表花朵和花瓶图案的点。
- en: We extracted key points from our image, and we successfully reached the goal
    of reducing the number of keypoints and focusing on the unique points of an image.
    Now we need to compare or match those points somehow. How we can do that? We will
    cover this in the next chapter.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从我们的图像中提取了关键点，并成功达到了减少关键点数量并关注图像独特点的目标。现在我们需要以某种方式比较或匹配这些点。我们如何做到这一点？我们将在下一章中介绍。
- en: Descriptors and object matching
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 描述符和对象匹配
- en: Image features by themselves are a bit useless. Yes, we have found unique points
    on an image. But what did we get? Only pixels values and that's it. If we try
    to compare those values it will not give us much information. Moreover, if we
    change the overall image brightness, we will not find the same keypoints on the
    same image! Taking into account all of this, we need the information which surrounds
    our key points. Moreover, we need a method to efficiently compare this information.
    First, we need to describe the image features, which comes from image descriptors.
    In this part, we will see how those descriptors can be extracted and matched.
    The tracking.js and JSFeat libraries provide different methods for image descriptors.
    We will discuss both.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图像特征本身有点无用。是的，我们在图像上找到了独特的点。但我们得到了什么？只有像素值，仅此而已。如果我们尝试比较这些值，它不会给我们太多信息。此外，如果我们改变整体图像的亮度，我们将在同一图像上找不到相同的关键点！考虑到所有这些，我们需要围绕我们的关键点的信息。此外，我们需要一种方法来有效地比较这些信息。首先，我们需要描述图像特征，这来自图像描述符。在本部分中，我们将看到这些描述符如何被提取和匹配。tracking.js
    和 JSFeat 库提供了不同的图像描述符方法。我们将讨论两者。
- en: The BRIEF and ORB descriptors
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BRIEF 和 ORB 描述符
- en: The descriptors theory is focused on changes in an image pixels' intensities.
    The tracking.js library provides the **Binary Robust Independent Elementary Features**
    (**BRIEF**) descriptors and the its JSFeat extension **Oriented FAST and Rotated
    BRIEF** (**ORB**). As we can see from the ORB naming, it is rotation invariant.
    This means that even if you rotate an object, the algorithm can still detect it.
    Moreover, the authors of the JSFeat library provide an example using the image
    pyramid, which is scale invariant too.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 描述符理论关注图像像素强度的变化。tracking.js 库提供了 **二进制鲁棒独立基本特征**（**BRIEF**）描述符及其 JSFeat 扩展
    **方向性快速和旋转 BRIEF**（**ORB**）。从 ORB 的命名中我们可以看出，它是旋转不变的。这意味着即使你旋转一个对象，算法仍然可以检测到它。此外，JSFeat
    库的作者提供了一个使用图像金字塔的示例，它也是尺度不变的。
- en: Let's start by explaining BRIEF, since it is the source for ORB descriptors.
    As a first step, the algorithm takes computed image features, and it takes the
    unique pairs of elements around each feature. Based on these pairs' intensities,
    it forms a binary string. For example, if we have a positions pair `i` and `j`,
    and if `I(i) < I(j)` (where `I(pos)` indicates the value of the image at the position
    `pos`), then the result is 1, otherwise 0\. We add this result to the binary string.
    We do this for `N` pairs, where `N` is taken as a power of 2 `(128, 256, 512)`.
    Since descriptors are just binary strings, we can compare them in an efficient
    manner. To match these strings, the Hamming distance is usually used. It shows
    the minimum number of substitutions required to change one string to another.
    For example, if we have two binary strings—`10011` and `11001`, the Hamming distance
    between them is `2`, since we need to change two bits of information to change
    the first string to the second.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先解释一下 BRIEF，因为它是 ORB 描述符的来源。作为第一步，算法取计算出的图像特征，并取每个特征周围的唯一元素对。基于这些对的强度，它形成一个二进制字符串。例如，如果我们有一个位置对
    `i` 和 `j`，如果 `I(i) < I(j)`（其中 `I(pos)` 表示图像在位置 `pos` 的值），则结果为 1，否则为 0。我们将这个结果添加到二进制字符串中。我们为
    `N` 对做这件事，其中 `N` 被取为 2 的幂次方（128、256、512）。由于描述符只是二进制字符串，我们可以以有效的方式比较它们。为了匹配这些字符串，通常使用汉明距离。它显示了将一个字符串更改为另一个字符串所需的最小替换次数。例如，如果我们有两个二进制字符串——`10011`
    和 `11001`，它们之间的汉明距离是 `2`，因为我们需要更改两个位的信息才能将第一个字符串更改为第二个。
- en: 'The JSFeat library provides the functionality to apply the ORB descriptors.
    The core idea is very similar to that of BRIEF. There are two major differences:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: JSFeat 库提供了应用 ORB 描述符的功能。核心思想与 BRIEF 非常相似。有两个主要区别：
- en: The implementation is scale invariant, since the descriptors are computed for
    an image pyramid.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现是尺度不变的，因为描述符是在图像金字塔上计算的。
- en: The descriptors are rotation invariant; the direction is computed using intensity
    of the patch around a feature. Using this orientation, ORB manages to compute
    a BRIEF descriptor in a rotation invariant manner.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述符是旋转不变的；方向是通过计算特征周围区域的强度来确定的。使用这种方向，ORB 能够以旋转不变的方式计算 BRIEF 描述符。
- en: Descriptors implementation and their matching
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 描述符实现及其匹配
- en: Our goal is to find an object from a template on a scene image. We can do that
    by finding features and descriptors on both images and by matching descriptors
    from a template to an image.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是从场景图像上的模板中找到一个物体。我们可以通过在两个图像上找到特征和描述符，并将模板中的描述符与图像进行匹配来实现这一点。
- en: 'We start from the tracking.js library and BRIEF descriptors. The first thing
    that you can do is set the number of location pairs:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从tracking.js库和BRIEF描述符开始。你可以做的第一件事是设置位置对的数量：
- en: '[PRE32]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: By default, it is `256`, but you can choose a higher value. The larger the value
    the more information you will get and the more memory and computational cost it
    requires.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，它是`256`，但你可以选择更高的值。值越大，你将得到更多信息，但需要更多的内存和计算成本。
- en: 'Before starting the computation, do not forget to apply the Gaussian blur.
    Next, we find the FAST corners and compute descriptors on both images. In the
    following code, we use the suffix `Object` for a template image and `Scene` for
    a scene image:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始计算之前，别忘了应用高斯模糊。接下来，我们找到FAST角点，并在两个图像上计算描述符。在下面的代码中，我们使用后缀`Object`表示模板图像，`Scene`表示场景图像：
- en: '[PRE33]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Then, we do the matching:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们进行匹配：
- en: '[PRE34]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We need to pass both the corners and descriptors information to the function,
    since it returns coordinate information as a result.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将角点和描述符信息传递给函数，因为它返回坐标信息作为结果。
- en: 'Next, we print both images on one canvas. To draw the matches using this trick,
    we need to shift our scene keypoints for the width of a template image. As a `keypoint1`
    the matching function returns points on a template image and `keypoint2` matched
    points from a scene image. The keypoint1/2 are arrays with `x` and `y` coordinates
    at `0` and `1` indexes, respectively:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在一个画布上打印出两个图像。为了使用这个技巧绘制匹配，我们需要将场景关键点沿模板图像的宽度进行平移。作为`keypoint1`，匹配函数返回模板图像上的点，而`keypoint2`是场景图像上的匹配点。keypoint1/2是包含`x`和`y`坐标的数组，分别在`0`和`1`索引处：
- en: '[PRE35]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The JSFeat library provides most of the code for pyramids and scale invariant
    features not in the library, but in the examples, which are available on [https://github.com/inspirit/jsfeat/blob/gh-pages/](https://github.com/inspirit/jsfeat/blob/gh-pages/)
    [sample_orb.html](http://sample_orb.html). We will not provide the full code here,
    because it requires too much space. But do not worry; we will highlight the main
    topics.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: JSFeat库提供了大多数代码，用于不在库中但在示例中的金字塔和尺度不变特征，这些示例可以在[https://github.com/inspirit/jsfeat/blob/gh-pages/](https://github.com/inspirit/jsfeat/blob/gh-pages/)
    [sample_orb.html](http://sample_orb.html)找到。我们不会在这里提供完整的代码，因为它需要太多的空间。但不用担心；我们将突出主要话题。
- en: 'Let''s start from functions that are included in the library. First, we need
    to preallocate the descriptors matrix, where 32 is the length of a descriptor
    and 500 is the maximum number of descriptors. Again 32 is a power of two:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从库中包含的函数开始。首先，我们需要预分配描述符矩阵，其中32是描述符的长度，500是描述符的最大数量。再次，32是2的幂：
- en: '[PRE36]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Then, we compute the ORB descriptors for each corner, we need to do this for
    both template and scene images:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们为每个角点计算ORB描述符，我们需要对模板和场景图像都这样做：
- en: '[PRE37]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'JSFeat does not provide a matching function in the library but it does in the
    examples section. The function uses global variables, which mainly define input
    descriptors and output matching:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: JSFeat库中不提供匹配函数，但在示例部分提供了。该函数使用全局变量，主要定义输入描述符和输出匹配：
- en: '[PRE38]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The resulting `match_t` function contains the following fields:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的`match_t`函数包含以下字段：
- en: '`screen_idx`: This is the index of a scene descriptor'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`screen_idx`：这是场景描述符的索引'
- en: '`pattern_lev`: This is the index of a pyramid level'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pattern_lev`：这是金字塔层的索引'
- en: '`pattern_idx`: This is the index of a template descriptor'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pattern_idx`：这是模板描述符的索引'
- en: 'Since ORB works with the image pyramid, it returns corners and matches for
    each level the pyramid:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 由于ORB与图像金字塔一起工作，它为金字塔的每个级别返回角点和匹配：
- en: '[PRE39]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can print each matching as follows. Again, we use *Shift*, since we computed
    descriptors on separate images, but print the result on one canvas:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按以下方式打印每个匹配。同样，我们使用*Shift*，因为我们是在单独的图像上计算描述符，但将结果打印在一个画布上：
- en: '[PRE40]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Finding an object location
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寻找物体位置
- en: We found a match. That is great. But what we did not do is find the object location.
    There is no function for that in the tracking.js library but JSFeat provides such
    a functionality in the examples section.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们找到了匹配。那太好了。但我们没有做的是找到物体位置。在tracking.js库中没有这样的函数，但JSFeat在示例部分提供了这样的功能。
- en: First, we need to compute a perspective transform matrix. Remember the first
    chapter? We have points from two images, but we do not have a transformation for
    the whole image.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要计算一个透视变换矩阵。还记得第一章吗？我们有两个图像的点，但我们没有整个图像的变换。
- en: 'First, we define a transform matrix:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义一个变换矩阵：
- en: '[PRE41]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: To compute the homography, we need only four points. But after the matching,
    we get too many. In addition, there can be noisy points, which we want to skip
    somehow. For this, we use a **Random sample consensus** (**RANSAC**) algorithm.
    It is an iterative method for estimating a mathematical model from a dataset that
    contains outliers (noise). It estimates outliers and generates a model that is
    computed without the noisy data.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算单应性，我们只需要四个点。但在匹配后，我们得到了太多的点。此外，还可能有噪声点，我们希望以某种方式跳过它们。为此，我们使用**随机样本一致性**（**RANSAC**）算法。它是一种迭代方法，用于从包含异常值（噪声）的数据集中估计数学模型。它估计异常值并生成一个没有噪声数据计算的模型。
- en: Before we start, we need to define the algorithm parameters. The first parameter
    is a match mask, where all matches will be marked as good (`1`) or bad (`0`).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，我们需要定义算法参数。第一个参数是匹配掩码，其中所有匹配都将标记为良好（`1`）或不良（`0`）。
- en: '[PRE42]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Next parameter is a mathematical model which we want to obtain using the RANSAC
    algorithm:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个参数是我们想使用RANSAC算法获得的一个数学模型：
- en: '[PRE43]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Third, we need minimum number of points to estimate a model (4 points to get
    a homography), this can be defined as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，我们需要最小数量的点来估计一个模型（4个点来获取单应性），这可以定义如下：
- en: '[PRE44]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Then, it is useful to have a maximum threshold to classify a data point as
    an inlier or a good match:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，有一个最大阈值来分类数据点为内点或良好匹配是有用的：
- en: '[PRE45]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Finally, the variable which holds the main parameters, that is, the last two
    arguments define the maximum ratio of outliers and probability of success. The
    algorithm stops when the number of inliers is 99 percent:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，保存主要参数的变量，即最后两个参数定义了异常值和成功概率的最大比率。当内点数量达到99%时，算法停止：
- en: '[PRE46]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Then we run the RANSAC algorithm. The last parameter represents the number of
    maximum iterations for the algorithm.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们运行RANSAC算法。最后一个参数代表算法的最大迭代次数。
- en: '[PRE47]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The shape finding can be applied for both tracking.js and JSFeat libraries,
    you just need to set matches as `object_xy` and `screen_xy`, where those arguments
    must hold an array of objects with the `x` and `y` fields. After we find the transformation
    matrix, we compute the projected shape of an object to a new image:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 形状查找可以应用于tracking.js和JSFeat库，你只需将匹配设置为`object_xy`和`screen_xy`，其中这些参数必须包含一个具有`x`和`y`字段的物体数组。找到变换矩阵后，我们计算物体在新图像上的投影形状：
- en: '[PRE48]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'After the computation is done, we draw the computed shapes on our images:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 计算完成后，我们在图像上绘制计算出的形状：
- en: '![Finding an object location](img/image00117.jpeg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![找到物体位置](img/image00117.jpeg)'
- en: As we see, our program successfully found an object in both cases. Actually,
    both methods can show different performance, it is mainly based on the thresholds
    you set.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们的程序在两种情况下都成功地找到了一个物体。实际上，这两种方法可以表现出不同的性能，这主要取决于你设置的阈值。
- en: Summary
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We completed one of the hardest chapters in this book. Congratulations! We saw
    how to find and track a basic colored object and plunged into the depths of library
    APIs. Oh, and don't forget, we have completed our own object detector! The applications
    of Computer Vision methods vary. What we cannot accomplish with the simple color
    detection, we achieve with powerful feature detection and descriptor matching
    algorithms. Both libraries provide different functionalities to match the objects
    and some functions are not included in the libraries. But it should not stop you
    from using those excellent methods. To know how and, probably the more important
    part, when to use those algorithms are the most crucial things you need to know.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们完成了这本书中最难的一章。恭喜！我们看到了如何找到和跟踪一个基本彩色物体，并深入研究了库API。哦，别忘了，我们已经完成了我们自己的物体检测器！计算机视觉方法的应用范围很广。我们无法通过简单的颜色检测完成的事情，我们通过强大的特征检测和描述符匹配算法来完成。这两个库提供了不同的功能来匹配物体，但有些功能不包括在库中。但这不应阻止你使用这些优秀的方法。了解如何使用这些算法，以及可能更重要的是，何时使用这些算法，是你最需要知道的关键信息。
- en: One of the most commonly seen objects in our world is a person's face. We interact
    with people everywhere. However, we did not see how to detect such objects in
    an application. The algorithms we covered in this chapter are not so useful for
    face detection, which is why we need to introduce new methods for that. This is
    our topic of the next chapter. See you there!
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们世界中最常见的物体之一就是人的面孔。我们无处不在与人互动。然而，我们并未看到如何在应用中检测此类物体。本章中我们讨论的算法对于人脸检测并不那么有用，这就是为什么我们需要为这个目的引入新的方法。这就是下一章的主题。那里见！
