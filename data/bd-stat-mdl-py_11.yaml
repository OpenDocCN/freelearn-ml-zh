- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: ARIMA Models
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ARIMAæ¨¡å‹
- en: In this chapter, we will discuss univariate time series models. These are models
    that only consider a single variable and create forecasts based only on the previous
    samples in the time series. We will start by looking at models for stationary
    time series data and then progress to models for non-stationary time series data.
    We will also discuss how to identify appropriate models based on the characteristics
    of time series. This will provide a powerful set of models for forecasting time
    series.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå•å˜é‡æ—¶é—´åºåˆ—æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹åªè€ƒè™‘ä¸€ä¸ªå˜é‡ï¼Œå¹¶ä»…åŸºäºæ—¶é—´åºåˆ—ä¸­çš„å…ˆå‰æ ·æœ¬åˆ›å»ºé¢„æµ‹ã€‚æˆ‘ä»¬å°†é¦–å…ˆæŸ¥çœ‹å¹³ç¨³æ—¶é—´åºåˆ—æ•°æ®çš„æ¨¡å‹ï¼Œç„¶åè¿‡æ¸¡åˆ°éå¹³ç¨³æ—¶é—´åºåˆ—æ•°æ®çš„æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å°†è®¨è®ºå¦‚ä½•æ ¹æ®æ—¶é—´åºåˆ—çš„ç‰¹å¾è¯†åˆ«é€‚å½“çš„æ¨¡å‹ã€‚è¿™å°†æä¾›ä¸€ç»„å¼ºå¤§çš„æ¨¡å‹ï¼Œç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹ã€‚
- en: 'In this chapter, weâ€™re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¶µç›–ä»¥ä¸‹ä¸»è¦ä¸»é¢˜ï¼š
- en: Models for stationary time series
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¨³å®šæ—¶é—´åºåˆ—æ¨¡å‹
- en: Models for non-stationary time series
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éå¹³ç¨³æ—¶é—´åºåˆ—æ¨¡å‹
- en: More on model evaluation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹è¯„ä¼°çš„æ›´å¤šå†…å®¹
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æŠ€æœ¯è¦æ±‚
- en: 'In this chapter, we use two additional Python libraries for time series analysis:
    `sktime` and `pmdarima`. Please install the following versions of these libraries
    to run the provided code. Instructions for installing libraries can be found in
    [*Chapter 1*](B18945_01.xhtml#_idTextAnchor015), *Sampling* *and Generalization*.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸¤ä¸ªé¢å¤–çš„Pythonåº“è¿›è¡Œæ—¶é—´åºåˆ—åˆ†æï¼š`sktime`å’Œ`pmdarima`ã€‚è¯·å®‰è£…ä»¥ä¸‹ç‰ˆæœ¬çš„è¿™äº›åº“ä»¥è¿è¡Œæä¾›çš„ä»£ç ã€‚æœ‰å…³å®‰è£…åº“çš„è¯´æ˜ï¼Œè¯·å‚é˜…[*ç¬¬1ç« *](B18945_01.xhtml#_idTextAnchor015)ï¼Œ*é‡‡æ ·*
    *å’Œæ³›åŒ–*ã€‚
- en: '`sktime==0.15.0`'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sktime==0.15.0`'
- en: '`pmdarima==2.02`'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pmdarima==2.02`'
- en: 'More information about `sktime` can be found at this link: [https://www.sktime.org/en/stable/get_started.xhtml](https://www.sktime.org/en/stable/get_started.xhtml)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äº`sktime`çš„æ›´å¤šä¿¡æ¯å¯ä»¥åœ¨ä»¥ä¸‹é“¾æ¥ä¸­æ‰¾åˆ°ï¼š[https://www.sktime.org/en/stable/get_started.xhtml](https://www.sktime.org/en/stable/get_started.xhtml)
- en: 'More information about `pmdarima` can be found at this link: [http://alkaline-ml.com/pmdarima/](http://alkaline-ml.com/pmdarima/)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äº`pmdarima`çš„æ›´å¤šä¿¡æ¯å¯ä»¥åœ¨ä»¥ä¸‹é“¾æ¥ä¸­æ‰¾åˆ°ï¼š[http://alkaline-ml.com/pmdarima/](http://alkaline-ml.com/pmdarima/)
- en: Models for stationary time series
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¨³å®šæ—¶é—´åºåˆ—æ¨¡å‹
- en: In this section, we will discuss **Autoregressive** (**AR**), **Moving Average**
    (**MA**), and **Autoregressive Moving Average** (**ARMA**) models that are useful
    for stationary data. These models are useful when modeling patterns and variance
    around process means that output over time. *When we have data that does not exhibit
    autocorrelation, we can use statistical and machine learning models that do not
    make assumptions about time, such as Logistic Regression or NaÃ¯ve Bayes, so long
    as the data supports such* *use cases*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¯¹å¹³ç¨³æ•°æ®æœ‰ç”¨çš„**è‡ªå›å½’**ï¼ˆ**AR**ï¼‰ã€**ç§»åŠ¨å¹³å‡**ï¼ˆ**MA**ï¼‰å’Œ**è‡ªå›å½’ç§»åŠ¨å¹³å‡**ï¼ˆ**ARMA**ï¼‰æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹åœ¨å»ºæ¨¡è¿‡ç¨‹å‡å€¼å‘¨å›´çš„æ¨¡å¼å’Œæ–¹å·®æ—¶å¾ˆæœ‰ç”¨ã€‚*å½“æˆ‘ä»¬æœ‰ä¸å…·æœ‰è‡ªç›¸å…³æ€§çš„æ•°æ®æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸å‡è®¾æ—¶é—´çš„ç»Ÿè®¡å’Œæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä¾‹å¦‚é€»è¾‘å›å½’æˆ–æœ´ç´ è´å¶æ–¯ï¼Œåªè¦æ•°æ®æ”¯æŒæ­¤ç±»*
    *ç”¨ä¾‹*ã€‚
- en: Autoregressive (AR) models
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªå›å½’ï¼ˆARï¼‰æ¨¡å‹
- en: The AR(p) model
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AR(p)æ¨¡å‹
- en: 'In [*Chapter 10*](B18945_10.xhtml#_idTextAnchor160), *Introduction to Time
    Series* we considered how the **Partial Auto-Correlation Function** (**PACF**)
    correlates one data point to another lag, controlling for those lags between.
    We also discussed how inspection of the PACF plot is a frequently used method
    for assessing the ordering of an autoregressive model. Thereto, the autoregressive
    model is one that considers specific points in the past to be directly correlated
    to the value of a given point at lag zero. Suppose we have a process yÂ t with
    random, normally distributed white noise, ÏµÂ t, where t = Â± 1, Â± 2, â€¦. If â€“ using
    real constants of Ï•Â 1, Ï•Â 2, â€¦ , Ï•Â p where Ï•Â p â‰  0 â€“ we can formulate the process
    in the following way:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[*ç¬¬10ç« *](B18945_10.xhtml#_idTextAnchor160)ï¼Œ*æ—¶é—´åºåˆ—ç®€ä»‹*ä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘äº†**åè‡ªç›¸å…³å‡½æ•°**ï¼ˆ**PACF**ï¼‰å¦‚ä½•å°†ä¸€ä¸ªæ•°æ®ç‚¹ä¸å¦ä¸€ä¸ªæ»åç‚¹ç›¸å…³è”ï¼ŒåŒæ—¶æ§åˆ¶è¿™äº›æ»åç‚¹ä¹‹é—´çš„å·®å¼‚ã€‚æˆ‘ä»¬è¿˜è®¨è®ºäº†æ£€æŸ¥PACFå›¾æ˜¯è¯„ä¼°è‡ªå›å½’æ¨¡å‹é¡ºåºçš„å¸¸ç”¨æ–¹æ³•ã€‚å› æ­¤ï¼Œè‡ªå›å½’æ¨¡å‹æ˜¯ä¸€ç§è€ƒè™‘è¿‡å»ç‰¹å®šç‚¹ä¸é›¶æ»åç»™å®šç‚¹çš„å€¼ç›´æ¥ç›¸å…³çš„æ¨¡å‹ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå…·æœ‰éšæœºã€æ­£æ€åˆ†å¸ƒçš„ç™½è‰²å™ªå£°çš„è¿‡ç¨‹yÂ tï¼ŒÏµÂ tï¼Œå…¶ä¸­t
    = Â± 1ï¼ŒÂ± 2ï¼Œâ€¦â€¦ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨å®å¸¸æ•°Ï•Â 1ï¼ŒÏ•Â 2ï¼Œâ€¦â€¦ï¼ŒÏ•Â pï¼ˆå…¶ä¸­Ï•Â p â‰  0ï¼‰æ¥åˆ¶å®šè¿‡ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥ä¸‹è¿°æ–¹å¼åˆ¶å®šè¿‡ç¨‹ï¼š
- en: yÂ t âˆ’ Î¼ âˆ’ Ï•Â 1(yÂ tâˆ’1 âˆ’ Î¼) âˆ’ Ï•Â 2(yÂ tâˆ’2 âˆ’ Î¼) âˆ’ â€¦ âˆ’ Ï•Â p(yÂ p âˆ’ Î¼) = ÏµÂ t
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: yÂ t âˆ’ Î¼ âˆ’ Ï•Â 1(yÂ tâˆ’1 âˆ’ Î¼) âˆ’ Ï•Â 2(yÂ tâˆ’2 âˆ’ Î¼) âˆ’ â€¦ âˆ’ Ï•Â p(yÂ p âˆ’ Î¼) = ÏµÂ t
- en: 'Letting Î¼ represent the overall process sample mean (in our examples, we will
    consider **zero-mean** processes), we can consider this to be an autoregressive
    process of order *p*, or AR(p) [*1*]. We can define the autocorrelation for the
    AR(p) model as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è®©Î¼ä»£è¡¨æ•´ä½“è¿‡ç¨‹æ ·æœ¬å‡å€¼ï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†è€ƒè™‘**é›¶å‡å€¼**è¿‡ç¨‹ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶è§†ä¸ºä¸€ä¸ª*p*é˜¶è‡ªå›å½’è¿‡ç¨‹ï¼Œæˆ–AR(p) [*1*]ã€‚æˆ‘ä»¬å¯ä»¥å®šä¹‰AR(p)æ¨¡å‹çš„è‡ªç›¸å…³å¦‚ä¸‹ï¼š
- en: ÏÂ k = Ï•Â 1Â |k|
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ÏÂ k = Ï•Â 1Â |k|
- en: 'There is also this example:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰è¿™ä¸ªä¾‹å­ï¼š
- en: ÏÂ k = Ï•Â 1 ÏÂ kâˆ’1 + â€¦ + Ï•Â p ÏÂ kâˆ’p
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ÏÂ k = Ï•Â 1 ÏÂ kâˆ’1 + â€¦ + Ï•Â p ÏÂ kâˆ’p
- en: In the preceding example, where ÏÂ k is the lag *k* autocorrelation. Ï•Â 1 is both
    the slope and autocorrelation for an AR(1) process.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‰é¢çš„ä¾‹å­ä¸­ï¼Œå…¶ä¸­ÏÂ kæ˜¯æ»å*k*è‡ªç›¸å…³ã€‚Ï•Â 1æ˜¯AR(1)è¿‡ç¨‹çš„æ–œç‡å’Œè‡ªç›¸å…³ã€‚
- en: AR(p) model structure and components
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: AR(p)æ¨¡å‹ç»“æ„å’Œç»„ä»¶
- en: To prevent confusion, note that with the equation yÂ t âˆ’ Î¼ âˆ’ Ï•Â 1(yÂ tâˆ’1 âˆ’ Î¼) âˆ’
    Ï•Â 2(yÂ tâˆ’2 âˆ’ Î¼) âˆ’ â€¦ âˆ’ Ï•Â p(yÂ p âˆ’ Î¼) = ÏµÂ t we are attempting to build a mathematical
    model that represents the process such that if perfectly modeled, all that remains
    is the random, normally distributed white noise, ÏµÂ t. This effectively means the
    model leaves zero residual error (in other words, a perfect fit). Each yÂ tâˆ’k term
    â€“ where *k* is a lag in time â€“ represents the value at that point in time and
    each corresponding value of Ï• is the coefficient value required for the yÂ tâˆ’k
    such that when taken in combination with all other values of *y*, the model statistically
    approximates zero error.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†é¿å…æ··æ·†ï¼Œè¯·æ³¨æ„ï¼Œåœ¨æ–¹ç¨‹yÂ t âˆ’ Î¼ âˆ’ Ï•Â 1(yÂ tâˆ’1 âˆ’ Î¼) âˆ’ Ï•Â 2(yÂ tâˆ’2 âˆ’ Î¼) âˆ’ â€¦ âˆ’ Ï•Â p(yÂ p âˆ’ Î¼) =
    ÏµÂ tä¸­ï¼Œæˆ‘ä»¬è¯•å›¾æ„å»ºä¸€ä¸ªæ•°å­¦æ¨¡å‹æ¥è¡¨ç¤ºè¿‡ç¨‹ï¼Œå¦‚æœå®Œç¾å»ºæ¨¡ï¼Œåˆ™å‰©ä¸‹çš„åªæ˜¯éšæœºã€æ­£æ€åˆ†å¸ƒçš„ç™½å™ªå£°ï¼ŒÏµÂ tã€‚è¿™å®é™…ä¸Šæ„å‘³ç€æ¨¡å‹ç•™ä¸‹é›¶æ®‹å·®è¯¯å·®ï¼ˆæ¢å¥è¯è¯´ï¼Œæ˜¯ä¸€ä¸ªå®Œç¾çš„æ‹Ÿåˆï¼‰ã€‚æ¯ä¸ªyÂ tâˆ’ké¡¹ï¼ˆå…¶ä¸­*k*æ˜¯æ—¶é—´æ»åï¼‰ä»£è¡¨è¯¥æ—¶é—´ç‚¹çš„å€¼ï¼Œæ¯ä¸ªç›¸åº”çš„Ï†å€¼æ˜¯yÂ tâˆ’kæ‰€éœ€çš„ç³»æ•°å€¼ï¼Œå½“ä¸å…¶ä»–æ‰€æœ‰*y*å€¼ç»“åˆæ—¶ï¼Œæ¨¡å‹ç»Ÿè®¡ä¸Šè¿‘ä¼¼é›¶è¯¯å·®ã€‚
- en: The AR(1) model
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AR(1)æ¨¡å‹
- en: 'The **backshift operator notation**, or simply **operator notation**, is a
    simplified, shorthand method of formulating models. It is called â€œbackshiftâ€ because
    it shifts time back one lag from *t* to *t-1*. The purpose is to avoid the necessitation
    of writing the subscript (yÂ tâˆ’k) following every Ï† coefficient and instead writing
    BÂ kâˆ’1 while including only yÂ t once, which is handy when writing AR(p) models
    with high orders of *p*. In the following equation, the zero-mean form of an AR(1)
    follows the following structure:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**åç§»ç®—å­ç¬¦å·**ï¼Œæˆ–ç®€ç§°**ç®—å­ç¬¦å·**ï¼Œæ˜¯ä¸€ç§ç®€åŒ–çš„ã€ç®€å†™çš„æ–¹æ³•æ¥åˆ¶å®šæ¨¡å‹ã€‚å®ƒè¢«ç§°ä¸ºâ€œåç§»â€ï¼Œå› ä¸ºå®ƒå°†æ—¶é—´å‘åç§»åŠ¨ä¸€ä¸ªæ»åï¼Œä»*t*åˆ°*t-1*ã€‚å…¶ç›®çš„æ˜¯é¿å…åœ¨æ¯ä¸€ä¸ªÏ†ç³»æ•°åé¢éƒ½å†™ä¸Šä¸‹æ ‡(yÂ tâˆ’k)ï¼Œè€Œæ˜¯å†™ä¸ŠBÂ kâˆ’1ï¼ŒåŒæ—¶åªåŒ…æ‹¬ä¸€æ¬¡yÂ tï¼Œè¿™åœ¨ç¼–å†™é«˜é˜¶*p*çš„AR(p)æ¨¡å‹æ—¶å¾ˆæ–¹ä¾¿ã€‚åœ¨ä»¥ä¸‹æ–¹ç¨‹ä¸­ï¼ŒAR(1)çš„é›¶å‡å€¼å½¢å¼éµå¾ªä»¥ä¸‹ç»“æ„ï¼š'
- en: yÂ t âˆ’ Î¼ âˆ’ Ï•Â 1(yÂ tâˆ’1 âˆ’ Î¼) = ÏµÂ t
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: yÂ t âˆ’ Î¼ âˆ’ Ï•Â 1(yÂ tâˆ’1 âˆ’ Î¼) = ÏµÂ t
- en: 'The equation reduces to the following example:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ç®€åŒ–ä¸ºä»¥ä¸‹ç¤ºä¾‹ï¼š
- en: yÂ t âˆ’ Ï•Â 1(yÂ tâˆ’1) = ÏµÂ t
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: yÂ t âˆ’ Ï•Â 1(yÂ tâˆ’1) = ÏµÂ t
- en: 'In backshift operator notation, we can say this:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åç§»ç®—å­ç¬¦å·ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·è¯´ï¼š
- en: ( 1 âˆ’ Ï•Â 1 B)yÂ t = ğÂ t
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ( 1 âˆ’ Ï•Â 1 B)yÂ t = ğÂ t
- en: Note on |ğ“Â 1| in an AR(1)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºAR(1)ä¸­çš„|ğ“Â 1|çš„æ³¨é‡Š
- en: Itâ€™s worth noting at this point that an AR(1) process is stationary if |Ï•Â 1|
    < 1\. That is, when the absolute value of the lag-one autocorrelation is < 1,
    the AR(1) process is stationary. When |Ï•Â 1| = 1, an ARIMA model may still be useful,
    but when |Ï•Â 1| > 1, the process is considered to be explosive and should not be
    modeled. This is because a value |Ï•Â 1| < 1 means the root is outside of, and not
    bounded by, the unit circle. A value of |Ï•Â 1| = 1 is on the unit circle but can
    be differenced to remove the unit root. The root for the case of an AR(1) can
    be calculated as z = 1/Ï•Â 1\. A set of data producing |Ï•Â 1| > 1 cannot be filtered
    in a way that puts its root outside the unit circle.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€ç‚¹ä¸Šå€¼å¾—æ³¨æ„ï¼Œå¦‚æœ|Ï•Â 1| < 1ï¼Œåˆ™AR(1)è¿‡ç¨‹æ˜¯å¹³ç¨³çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå½“æ»åä¸€é˜¶è‡ªç›¸å…³ç³»æ•°çš„ç»å¯¹å€¼å°äº1æ—¶ï¼ŒAR(1)è¿‡ç¨‹æ˜¯å¹³ç¨³çš„ã€‚å½“|Ï•Â 1|
    = 1æ—¶ï¼ŒARIMAæ¨¡å‹å¯èƒ½ä»ç„¶æœ‰ç”¨ï¼Œä½†å½“|Ï•Â 1| > 1æ—¶ï¼Œè¯¥è¿‡ç¨‹è¢«è®¤ä¸ºæ˜¯çˆ†ç‚¸æ€§çš„ï¼Œä¸åº”è¿›è¡Œå»ºæ¨¡ã€‚è¿™æ˜¯å› ä¸º|Ï•Â 1| < 1çš„å€¼æ„å‘³ç€æ ¹ä½äºå•ä½åœ†ä¹‹å¤–ï¼Œè€Œä¸æ˜¯è¢«å•ä½åœ†æ‰€é™åˆ¶ã€‚|Ï•Â 1|
    = 1çš„å€¼ä½äºå•ä½åœ†ä¸Šï¼Œä½†å¯ä»¥é€šè¿‡å·®åˆ†æ¥æ¶ˆé™¤å•ä½æ ¹ã€‚AR(1)æƒ…å†µçš„æ ¹å¯ä»¥è®¡ç®—ä¸ºz = 1/Ï•Â 1ã€‚äº§ç”Ÿ|Ï•Â 1| > 1çš„æ•°æ®é›†ä¸èƒ½ä»¥ä½¿å…¶æ ¹ä½äºå•ä½åœ†ä¹‹å¤–çš„æ–¹å¼è¿›è¡Œè¿‡æ»¤ã€‚
- en: When all roots of an AR(p) are outside the unit circle, the given realization
    (one time series sampled from a stochastic process) will converge to the mean,
    have constant variance, and be independent of time. This is an ideal scenario
    for time series data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å½“AR(p)çš„æ‰€æœ‰æ ¹éƒ½ä½äºå•ä½åœ†ä¹‹å¤–æ—¶ï¼Œç»™å®šçš„å®ç°ï¼ˆä»éšæœºè¿‡ç¨‹ä¸­æŠ½å–çš„ä¸€ä¸ªæ—¶é—´åºåˆ—æ ·æœ¬ï¼‰å°†æ”¶æ•›åˆ°å‡å€¼ï¼Œå…·æœ‰æ’å®šçš„æ–¹å·®ï¼Œå¹¶ä¸”ä¸æ—¶é—´æ— å…³ã€‚è¿™æ˜¯æ—¶é—´åºåˆ—æ•°æ®çš„ä¸€ä¸ªç†æƒ³åœºæ™¯ã€‚
- en: 'Letâ€™s walk through an example of an AR(1) process with |Ï•Â 1| < 1 and therefore
    a stationary root. Assume we have identified the following first-order autoregressive
    process:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªAR(1)è¿‡ç¨‹çš„ä¾‹å­æ¥æ¢è®¨ï¼Œå…¶ä¸­|Ï•_1| < 1ï¼Œå› æ­¤æœ‰ä¸€ä¸ªå¹³ç¨³æ ¹ã€‚å‡è®¾æˆ‘ä»¬å·²ç»è¯†åˆ«äº†ä»¥ä¸‹ä¸€é˜¶è‡ªå›å½’è¿‡ç¨‹ï¼š
- en: yÂ t âˆ’ 0.5 yÂ tâˆ’1 = ÏµÂ t
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: y_t âˆ’ 0.5 y_{tâˆ’1} = Ïµ_t
- en: 'This is converted to operator notation:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¢«è½¬æ¢ä¸ºç®—å­ç¬¦å·ï¼š
- en: (1 âˆ’ 0.5B) yÂ t = ÏµÂ t
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: (1 âˆ’ 0.5B) y_t = Ïµ_t
- en: 'When looking for roots, we can use the following notation:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å¯»æ‰¾æ ¹æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ç¬¦å·ï¼š
- en: (1 âˆ’ 0.5z) = 0
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: (1 âˆ’ 0.5z) = 0
- en: 'This gives us a root of *z*:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»™å‡ºäº†*z*çš„æ ¹ï¼š
- en: z = Â 1Â _Â Ï•Â 1Â  = Â 1Â _Â 0.5Â  = 2
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: z = 1 / Ï•_1 = 1 / 0.5 = 2
- en: 'Therefore, since the root is greater than 1 and thus outside the unit circle,
    the AR(1) representation of the process is stationary. In Python, we can build
    this process using the upcoming code. First, we build the AR(1) parameters, which
    we want to have a 0.5\. Because we substitute 0.5 into the model XÂ t âˆ’ Ï•Â 1(yÂ tâˆ’1)
    = ÏµÂ t, we insert *0.5* and not *-0.5* for `arparams`. Also, note based on ÏÂ k
    = Ï•Â 1Â |k| that *0.5* is the lag-1 autocorrelation. The process we build will have
    an arbitrary sample size of `nsample=200`. We build the (1 âˆ’ 0.5B) component of
    (1 âˆ’ 0.5B) yÂ t = ÏµÂ t using the `np.r_[1, -``arparams]` step:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œç”±äºæ ¹å¤§äº1å¹¶ä¸”å› æ­¤ä½äºå•ä½åœ†å¤–ï¼Œè¯¥è¿‡ç¨‹çš„AR(1)è¡¨ç¤ºæ˜¯å¹³ç¨³çš„ã€‚åœ¨Pythonä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å³å°†åˆ°æ¥çš„ä»£ç æ„å»ºæ­¤è¿‡ç¨‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ„å»ºAR(1)å‚æ•°ï¼Œæˆ‘ä»¬å¸Œæœ›å®ƒä¸º0.5ã€‚å› ä¸ºæˆ‘ä»¬æŠŠ0.5ä»£å…¥æ¨¡å‹X_t
    âˆ’ Ï•_1(y_{tâˆ’1}) = Ïµ_tï¼Œæ‰€ä»¥æˆ‘ä»¬æ’å…¥*0.5*è€Œä¸æ˜¯*-0.5*ä½œä¸º`arparams`ã€‚å¦å¤–ï¼Œæ ¹æ®Ï_k = Ï•_1|k|ï¼Œ*0.5*æ˜¯æ»å1çš„è‡ªç›¸å…³ã€‚æˆ‘ä»¬æ„å»ºçš„è¿‡ç¨‹å°†å…·æœ‰ä»»æ„çš„æ ·æœ¬å¤§å°`nsample=200`ã€‚æˆ‘ä»¬ä½¿ç”¨`np.r_[1,
    -arparams]`æ­¥éª¤æ„å»º(1 âˆ’ 0.5B)çš„(1 âˆ’ 0.5B) y_t = Ïµ_téƒ¨åˆ†ï¼š
- en: '[PRE0]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now that we have the code to create the AR(1) we looked at the equation for,
    letâ€™s see the roots and compare it to our manually calculated *z*:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†åˆ›å»ºæˆ‘ä»¬æŸ¥çœ‹çš„AR(1)æ–¹ç¨‹çš„ä»£ç ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹æ ¹å¹¶ä¸æˆ‘ä»¬æ‰‹åŠ¨è®¡ç®—çš„*z*è¿›è¡Œæ¯”è¾ƒï¼š
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`array([2.])`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`array([2.])`'
- en: 'We can see the Python output, `2.` is the same as the calculation we performed.
    We know that since the absolute value of the root is greater than 1, the AR(1)
    process is stationary, but letâ€™s confirm with Python:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°Pythonè¾“å‡º`2.`ä¸æˆ‘ä»¬è¿›è¡Œçš„è®¡ç®—ç›¸åŒã€‚æˆ‘ä»¬çŸ¥é“ï¼Œç”±äºæ ¹çš„ç»å¯¹å€¼å¤§äº1ï¼ŒAR(1)è¿‡ç¨‹æ˜¯å¹³ç¨³çš„ï¼Œä½†è®©æˆ‘ä»¬ç”¨Pythonæ¥ç¡®è®¤ï¼š
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`True`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`True`'
- en: 'We can observe by looking at the PACF that this is an autoregressive of order
    p = 5\. We can also observe by looking at the ACF that the value of Ï•Â 1 is approximately
    0.5\. For an autoregressive model, the PACF is used to identify the number of
    significant lags to include as the order of the AR, and the ACF is used to determine
    the values of the coefficients, Ï•Â k, included in that order. It is simple to observe
    the values for an AR(1) using the ACF, but less obvious when p > 1 since ACF does
    not control for individual lags when compared to the most recent point (lag zero)
    as the PACF does. Letâ€™s generate the plots with Python:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è§‚å¯ŸPACFï¼Œæˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°è¿™æ˜¯ä¸€ä¸ªp = 5çš„è‡ªå›å½’ã€‚æˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡è§‚å¯ŸACFè§‚å¯Ÿåˆ°Ï•_1çš„å€¼å¤§çº¦ä¸º0.5ã€‚å¯¹äºè‡ªå›å½’æ¨¡å‹ï¼ŒPACFç”¨äºç¡®å®šä½œä¸ºARé˜¶æ•°çš„æ˜¾è‘—æ»åæ•°é‡ï¼ŒACFç”¨äºç¡®å®šåŒ…å«åœ¨è¯¥é˜¶æ•°ä¸­çš„ç³»æ•°ï¼ŒÏ•_kçš„å€¼ã€‚ä½¿ç”¨ACFè§‚å¯ŸAR(1)çš„å€¼å¾ˆç®€å•ï¼Œä½†å½“p
    > 1æ—¶ä¸å¤ªæ˜æ˜¾ï¼Œå› ä¸ºACFä¸æœ€æ¥è¿‘çš„ç‚¹ï¼ˆæ»å0ï¼‰ç›¸æ¯”ï¼Œä¸æ§åˆ¶å•ä¸ªæ»åï¼Œè€ŒPACFåˆ™æ§åˆ¶ã€‚è®©æˆ‘ä»¬ç”¨Pythonç”Ÿæˆè¿™äº›å›¾ï¼š
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Figure 11.1 â€“ The AR(1) process](img/B18945_11_001.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.1 â€“ AR(1)è¿‡ç¨‹](img/B18945_11_001.jpg)'
- en: Figure 11.1 â€“ The AR(1) process
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.1 â€“ AR(1)è¿‡ç¨‹
- en: Common for AR(1) processes, we see in *Figure 11**.1* a single significant partial
    autocorrelation in the PACF plot, excluding lag zero. Note there is some significance
    as we near lag 45, but because of the insignificance between lag 1 and those points,
    including those lags and constructing something such as an AR(50) would result
    in extreme overfitting; the coefficients from lag 2 through roughly lag 45 would
    fall between roughly 0 and Â± 0.15\. As referenced in [*Chapter 4*](B18945_04.xhtml#_idTextAnchor070),
    *Parametric Tests*, the correlation between about Â± 0.1 and Â± 0.3 is generally
    considered a weak correlation.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºAR(1)è¿‡ç¨‹ï¼Œæˆ‘ä»¬åœ¨*å›¾11.1*ä¸­çœ‹åˆ°ï¼Œé™¤äº†æ»å0ä¹‹å¤–ï¼ŒPACFå›¾ä¸Šåªæœ‰ä¸€ä¸ªæ˜¾è‘—çš„åè‡ªç›¸å…³ã€‚æ³¨æ„ï¼Œå½“æˆ‘ä»¬æ¥è¿‘æ»å45æ—¶ï¼Œæœ‰ä¸€äº›æ˜¾è‘—æ€§ï¼Œä½†ç”±äºæ»å1å’Œè¿™äº›ç‚¹ä¹‹é—´çš„ä¸æ˜¾è‘—æ€§ï¼ŒåŒ…æ‹¬è¿™äº›æ»åå¹¶æ„å»ºå¦‚AR(50)ä¹‹ç±»çš„æ¨¡å‹ä¼šå¯¼è‡´æç«¯è¿‡æ‹Ÿåˆï¼›ä»æ»å2åˆ°å¤§çº¦æ»å45çš„ç³»æ•°å°†ä»‹äºå¤§çº¦0å’ŒÂ±0.15ä¹‹é—´ã€‚å¦‚[*ç¬¬4ç« *](B18945_04.xhtml#_idTextAnchor070)ä¸­æ‰€è¿°ï¼Œ*å‚æ•°æ£€éªŒ*ï¼Œå¤§çº¦Â±0.1å’ŒÂ±0.3ä¹‹é—´çš„ç›¸å…³æ€§é€šå¸¸è¢«è®¤ä¸ºæ˜¯ä¸€ç§å¼±ç›¸å…³æ€§ã€‚
- en: The AR(2) model
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AR(2)æ¨¡å‹
- en: 'Letâ€™s look at the following stationary AR(2) process:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹ä»¥ä¸‹å¹³ç¨³AR(2)è¿‡ç¨‹ï¼š
- en: yÂ t âˆ’ 0.8 yÂ tâˆ’1 âˆ’ 0.48 yÂ tâˆ’2 = ÏµÂ t
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: y_t âˆ’ 0.8 y_{tâˆ’1} âˆ’ 0.48 y_{tâˆ’2} = Ïµ_t
- en: 'Converted to backshift operator notation, we have the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è½¬æ¢ä¸ºåç§»ç®—å­ç¬¦å·ï¼Œæˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹å†…å®¹ï¼š
- en: (1 âˆ’ 0.8B âˆ’ 0.48 BÂ 2) yÂ t = ÏµÂ t
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: (1 âˆ’ 0.8B âˆ’ 0.48 BÂ²) y_t = Ïµ_t
- en: 'We also have this:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜æœ‰ä»¥ä¸‹å†…å®¹ï¼š
- en: (1 âˆ’ 0.8z âˆ’ 0.48 zÂ 2) = 0
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: (1 âˆ’ 0.8z âˆ’ 0.48 zÂ²) = 0
- en: 'Since weâ€™re focusing on Python in this book, we wonâ€™t walk through the steps,
    but it may be useful to know second-order polynomials â€“ such as AR(2) â€“ follow
    the quadratic equation, a xÂ 2 + bx + c (âˆ’ 0.48 zÂ 2 âˆ’ 0.8z + 1 for our process).
    Therefore, we can use the quadratic formula:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬åœ¨è¿™æœ¬ä¹¦ä¸­ä¸“æ³¨äº Pythonï¼Œæˆ‘ä»¬ä¸ä¼šè¯¦ç»†ä»‹ç»æ­¥éª¤ï¼Œä½†äº†è§£äºŒæ¬¡å¤šé¡¹å¼ï¼ˆå¦‚ AR(2)ï¼‰éµå¾ªäºŒæ¬¡æ–¹ç¨‹ a xÂ² + bx + cï¼ˆå¯¹äºæˆ‘ä»¬çš„è¿‡ç¨‹æ˜¯
    -0.48 zÂ² âˆ’ 0.8z + 1ï¼‰å¯èƒ½æ˜¯æœ‰ç”¨çš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨äºŒæ¬¡å…¬å¼ï¼š
- en: âˆ’ b Â± âˆšÂ _Â bÂ 2 âˆ’ 4acÂ Â Â ___________Â 2a
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ’ b Â± âˆšÂ bÂ² âˆ’ 4acÂ Â Â ___________Â 2a
- en: 'This is what weâ€™ll use to find the roots. In Python, we can find the roots
    of this model using the following:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬ç”¨æ¥æ‰¾åˆ°æ ¹çš„ä¾æ®ã€‚åœ¨ Python ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•æ‰¾åˆ°è¯¥æ¨¡å‹çš„æ ¹ï¼š
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here we can see the unit roots identified using the `statmodels` ArmaProcess
    function:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä½¿ç”¨ `statmodels` ArmaProcess å‡½æ•°è¯†åˆ«çš„å•ä½æ ¹ï¼š
- en: '`AR(2) Roots: [-``0.83333333-1.1785113j -0.83333333+1.1785113j]`'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`AR(2) æ ¹ï¼š[-0.83333333-1.1785113j -0.83333333+1.1785113j]`'
- en: '`AR(2) Stationarity:` `True`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`AR(2) ç«™ç«‹æ€§:` `True`'
- en: 'We can observe the roots are in complex conjugate form a Â± bi. When a process
    has roots in complex conjugate form, it is expected the autocorrelations will
    exhibit an oscillatory pattern, which we can see in the ACF plot in *Figure 11**.2*.
    We can also observe the two significant lags in the PACF, which support the case
    of order p=2:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°æ ¹ä»¥å¤å…±è½­å½¢å¼ a Â± bi å­˜åœ¨ã€‚å½“ä¸€ä¸ªè¿‡ç¨‹å…·æœ‰å¤å…±è½­å½¢å¼çš„æ ¹æ—¶ï¼Œæˆ‘ä»¬é¢„æœŸè‡ªç›¸å…³å°†è¡¨ç°å‡ºæŒ¯è¡æ¨¡å¼ï¼Œè¿™åœ¨ *å›¾ 11.2* ä¸­çš„ ACF
    å›¾ä¸­å¯ä»¥çœ‹åˆ°ã€‚æˆ‘ä»¬è¿˜å¯ä»¥è§‚å¯Ÿåˆ° PACF ä¸­çš„ä¸¤ä¸ªæ˜¾è‘—æ»åï¼Œè¿™æ”¯æŒäº† p=2 çš„é˜¶æ•°ï¼š
- en: '![Figure 11.2 â€“ AR(2) with complex conjugate roots](img/B18945_11_002.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 11.2 â€“ å…·æœ‰å¤å…±è½­æ ¹çš„ AR(2)](img/B18945_11_002.jpg)'
- en: Figure 11.2 â€“ AR(2) with complex conjugate roots
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.2 â€“ å…·æœ‰å¤å…±è½­æ ¹çš„ AR(2)
- en: 'To mathematically test that complex conjugate roots are stationary (outside
    the unit circle), we take the magnitude of the vector of each rootâ€™s real and
    imaginary parts and check if it is greater than 1\. The magnitude for complex
    conjugate roots, *z*, following form a Â± bi is the following equation:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä»æ•°å­¦ä¸Šæµ‹è¯•å¤å…±è½­æ ¹æ˜¯å¦ç¨³å®šï¼ˆä½äºå•ä½åœ†å¤–ï¼‰ï¼Œæˆ‘ä»¬å–æ¯ä¸ªæ ¹çš„å®éƒ¨å’Œè™šéƒ¨çš„å‘é‡çš„å¤§å°ï¼Œå¹¶æ£€æŸ¥å®ƒæ˜¯å¦å¤§äº1ã€‚å¤å…±è½­æ ¹ï¼Œ*z*ï¼ŒæŒ‰ç…§å½¢å¼ a Â± bi çš„æ¨¡é‡å¦‚ä¸‹æ–¹ç¨‹ï¼š
- en: â€–zâ€– = âˆšÂ _Â aÂ 2 + bÂ 2
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: â€–zâ€– = âˆšÂ aÂ² + bÂ²
- en: 'The magnitude of our roots is this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ ¹çš„æ¨¡é‡å¦‚ä¸‹ï¼š
- en: âˆšÂ _________________Â Â âˆ’ 0.8333Â 2Â± 1.1785Â 2Â  = 1.4433
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: âˆšÂ _________________Â Â âˆ’ 0.8333Â²Â± 1.1785Â²Â  = 1.4433
- en: Since 1.4433 > 1, we know our AR(2) model is stationary.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº 1.4433 > 1ï¼Œæˆ‘ä»¬çŸ¥é“æˆ‘ä»¬çš„ AR(2) æ¨¡å‹æ˜¯ç¨³å®šçš„ã€‚
- en: Identifying order p for AR models using the PACF
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ PACF è¯†åˆ« AR æ¨¡å‹çš„é˜¶æ•° p
- en: When identifying a lag order p for an autoregressive process, AR(p), based on
    the PACF plot, we take the maximum lag where significant partial autocorrelation
    exists as the order for p. In observing *Figure 11**.3*, because the PACF dampens
    after lag 4 and through about lag 30, we will cut off order consideration after
    lag 4 because using more lags (consider them as features for a time series model)
    will likely result in overfitting. The order selected using PACF is based on the
    last significant lag before the partial autocorrelations dampen. While lags 2
    and 3 seem to be small and may not be significant, lag 4 is. Therefore, we may
    get the best model using an AR of order 4\. Typically, we test our assumptions
    using errors with information criteria, such as AIC or BIC.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ ¹æ® PACF å›¾è¯†åˆ«è‡ªå›å½’è¿‡ç¨‹ AR(p) çš„æ»åé˜¶æ•° p æ—¶ï¼Œæˆ‘ä»¬å–å­˜åœ¨æ˜¾è‘—åè‡ªç›¸å…³çš„æœ€å¤§æ»åä½œä¸º p çš„é˜¶æ•°ã€‚åœ¨è§‚å¯Ÿ *å›¾ 11.3* æ—¶ï¼Œå› ä¸º
    PACF åœ¨æ»å 4 åå‡å¼±ï¼Œå¹¶é€šè¿‡å¤§çº¦æ»å 30ï¼Œæˆ‘ä»¬å°†åœ¨æ»å 4 ååœæ­¢é˜¶æ•°è€ƒè™‘ï¼Œå› ä¸ºä½¿ç”¨æ›´å¤šçš„æ»åï¼ˆå°†å®ƒä»¬è§†ä¸ºæ—¶é—´åºåˆ—æ¨¡å‹çš„ç‰¹å¾ï¼‰å¯èƒ½ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆã€‚ä½¿ç”¨
    PACF é€‰æ‹©çš„é˜¶æ•°æ˜¯åŸºäºåè‡ªç›¸å…³å‡å¼±å‰çš„æœ€åä¸€ä¸ªæ˜¾è‘—æ»åã€‚è™½ç„¶æ»å 2 å’Œ 3 çœ‹èµ·æ¥å¾ˆå°ï¼Œå¯èƒ½ä¸æ˜¾è‘—ï¼Œä½†æ»å 4 æ˜¯æ˜¾è‘—çš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯èƒ½ä½¿ç”¨é˜¶æ•°ä¸º 4
    çš„ AR æ¨¡å‹è·å¾—æœ€ä½³æ¨¡å‹ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¿¡æ¯å‡†åˆ™ï¼ˆå¦‚ AIC æˆ– BICï¼‰çš„é”™è¯¯æ¥æµ‹è¯•æˆ‘ä»¬çš„å‡è®¾ã€‚
- en: '![Figure 11.3 â€“ AR(p) order identification](img/B18945_11_003.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 11.3 â€“ AR(p) é˜¶æ•°è¯†åˆ«](img/B18945_11_003.jpg)'
- en: Figure 11.3 â€“ AR(p) order identification
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.3 â€“ AR(p) é˜¶æ•°è¯†åˆ«
- en: AR(p) end-to-end example
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AR(p) ç«¯åˆ°ç«¯ç¤ºä¾‹
- en: 'Let us walk through an end-to-end example of AR(p) modeling in Python. First,
    we need to generate a dataset produced by an AR(4) process. We will use this data
    as the process we will attempt to model:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ª Python ä¸­ AR(p) æ¨¡å‹ç«¯åˆ°ç«¯ç¤ºä¾‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç”Ÿæˆä¸€ä¸ªç”± AR(4) è¿‡ç¨‹äº§ç”Ÿçš„æ•°æ®é›†ã€‚æˆ‘ä»¬å°†ä½¿ç”¨è¿™äº›æ•°æ®ä½œä¸ºæˆ‘ä»¬å°†å°è¯•å»ºæ¨¡çš„è¿‡ç¨‹ï¼š
- en: '[PRE5]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For the following steps, let us assume data `y` is the output of a machine about
    which we know nothing.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä»¥ä¸‹æ­¥éª¤ï¼Œè®©æˆ‘ä»¬å‡è®¾æ•°æ® `y` æ˜¯ä¸€ä¸ªæœºå™¨çš„è¾“å‡ºï¼Œæˆ‘ä»¬å¯¹å®ƒä¸€æ— æ‰€çŸ¥ã€‚
- en: Step 1 - visual inspection
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬ 1 æ­¥ - è§†è§‰æ£€æŸ¥
- en: 'We first visualize the original data and its ACF and PACF plots using the code
    we provided earlier in the chapter:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆä½¿ç”¨æœ¬ç« å‰é¢æä¾›çš„ä»£ç å¯è§†åŒ–åŸå§‹æ•°æ®åŠå…¶ ACF å’Œ PACF å›¾ï¼š
- en: '![Figure 11.4 â€“ Step 1 in model development: visual inspection](img/B18945_11_004.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 11.4 â€“ æ¨¡å‹å¼€å‘æ­¥éª¤ 1ï¼šè§†è§‰æ£€æŸ¥](img/B18945_11_004.jpg)'
- en: 'Figure 11.4 â€“ Step 1 in model development: visual inspection'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.4 â€“ æ¨¡å‹å¼€å‘æ­¥éª¤ 1ï¼šè§†è§‰æ£€æŸ¥
- en: We can see based on the PACF plot we have what appears to be an AR(2), but possibly
    an AR(4). After lag 4, the partial autocorrelations lose statistical significance
    at the 5% level of significance. We can see, however, when considering the statistical
    significance of lag 4 in the PACF, however slight, lag 4 in the ACF is significant.
    While the value at lag 4 is not the value of the coefficient, its significance
    is useful in helping determine order p. Nonetheless, an AR(4) may overfit and
    fail to generalize as well as an AR(2). Next, we will use **Aikake Information
    Criterion** (**AIC**) and **Bayesian Information Criterion** (**BIC**) to help
    make our determination.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ® PACF å›¾ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¼¼ä¹æ˜¯ä¸€ä¸ª AR(2)ï¼Œä½†å¯èƒ½æ˜¯ AR(4)ã€‚åœ¨æ»å 4 ä¹‹åï¼Œåè‡ªç›¸å…³ç³»æ•°åœ¨ 5% çš„æ˜¾è‘—æ€§æ°´å¹³ä¸Šå¤±å»äº†ç»Ÿè®¡æ˜¾è‘—æ€§ã€‚ç„¶è€Œï¼Œå½“æˆ‘ä»¬è€ƒè™‘
    PACF ä¸­æ»å 4 çš„ç»Ÿè®¡æ˜¾è‘—æ€§æ—¶ï¼Œå°½ç®¡å¾ˆå¾®å°ï¼ŒACF ä¸­æ»å 4 æ˜¯æ˜¾è‘—çš„ã€‚è™½ç„¶æ»å 4 çš„å€¼ä¸æ˜¯ç³»æ•°çš„å€¼ï¼Œä½†å…¶æ˜¾è‘—æ€§æœ‰åŠ©äºç¡®å®šé˜¶æ•° pã€‚å°½ç®¡å¦‚æ­¤ï¼ŒAR(4)
    å¯èƒ½ä¼šè¿‡æ‹Ÿåˆï¼Œå¹¶ä¸”ä¸å¦‚ AR(2) ä¸€æ ·å¾ˆå¥½åœ°æ³›åŒ–ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ **èµ¤æ± ä¿¡æ¯é‡å‡†åˆ™**ï¼ˆ**AIC**ï¼‰å’Œ **è´å¶æ–¯ä¿¡æ¯é‡å‡†åˆ™**ï¼ˆ**BIC**ï¼‰æ¥å¸®åŠ©æˆ‘ä»¬åšå‡ºå†³å®šã€‚
- en: Based on the constant mean and the fact we do not have an exponentially dampening
    (which would also need to be significant) ACF, there does not appear to be a trend.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®å¸¸æ•°å‡å€¼å’Œæˆ‘ä»¬æ²¡æœ‰æŒ‡æ•°è¡°å‡ï¼ˆè¿™ä¹Ÿéœ€è¦æ˜¯æ˜¾è‘—çš„ï¼‰ACF çš„äº‹å®ï¼Œä¼¼ä¹æ²¡æœ‰è¶‹åŠ¿ã€‚
- en: Step 2 - selecting the order of AR(p)
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 2 - é€‰æ‹© AR(p) çš„é˜¶æ•°
- en: 'Since we are uncertain based on the visual inspection of the order we should
    use for the AR(p) model, we will use AIC and BIC to help our decision. The AIC
    and BIC process will fit models using order zero up to the `max_ar` value provided
    in the upcoming code. The models will fit the entire dataset. The order with the
    lowest error is generally the best. Their error calculations are as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬æ ¹æ®å¯¹ AR(p) æ¨¡å‹åº”ä½¿ç”¨é˜¶æ•°çš„è§†è§‰æ£€æŸ¥ä¸ç¡®å®šï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ AIC å’Œ BIC æ¥å¸®åŠ©æˆ‘ä»¬åšå‡ºå†³å®šã€‚AIC å’Œ BIC è¿‡ç¨‹å°†ä½¿ç”¨ä»é›¶é˜¶åˆ°å³å°†åœ¨ä»£ç ä¸­æä¾›çš„
    `max_ar` å€¼çš„æ‰€æœ‰é˜¶æ•°æ¥æ‹Ÿåˆæ¨¡å‹ã€‚è¿™äº›æ¨¡å‹å°†æ‹Ÿåˆæ•´ä¸ªæ•°æ®é›†ã€‚è¯¯å·®æœ€ä½çš„é˜¶æ•°é€šå¸¸æ˜¯æœ€å¥½çš„ã€‚å®ƒä»¬çš„è¯¯å·®è®¡ç®—å¦‚ä¸‹ï¼š
- en: AIC = 2k âˆ’ 2ln(Â Ë†Â LÂ )
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: AIC = 2k âˆ’ 2ln(Ë†L)
- en: BIC = kln(n) âˆ’ 2ln(Â Ë†Â LÂ )
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: BIC = kln(n) âˆ’ 2ln(Ë†L)
- en: This is where *k* is the number of lags â€“ up to the maximum order tested â€“ for
    the data, Â Ë†Â LÂ  is the maximum likelihood estimate, and *n* is the sample size
    (or length of the dataset being tested). For both tests, the lower error is better.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„ *k* æ˜¯æ•°æ®çš„æ»åæ•° - æœ€å¤šåˆ°æµ‹è¯•çš„æœ€å¤§é˜¶æ•°ï¼ŒË†L æ˜¯æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œ*n* æ˜¯æ ·æœ¬å¤§å°ï¼ˆæˆ–æ­£åœ¨æµ‹è¯•çš„æ•°æ®é›†çš„é•¿åº¦ï¼‰ã€‚å¯¹äºè¿™ä¸¤ä¸ªæµ‹è¯•ï¼Œè¯¯å·®è¶Šä½è¶Šå¥½ã€‚
- en: We will import `arma_order_select_ic` from `Statsmodels` and test it using up
    to a maximum of 4 lags based on our observation in the PACF plot in *Figure 11**.4*.
    As noted, based on our visual inspection, we do not appear to have a trend. However,
    we can verify this statistically with an OLS-based unit root test called the **Dickey-Fuller
    test**. The **null hypothesis** of the Dickey-Fuller test is that a unit root
    (and therefore, trend) is present at some point in the maximum number of lags
    tested (maxlag). The alternative hypothesis is that there is no unit root (no
    trend) in the data. For reference, the alternative hypothesis states that the
    data is an order zero - **I(0)** - integrated process while the null hypothesis
    states that the data is an order one - **I(1)** - integrated process. If the absolute
    value of the test statistic is greater than the critical value or the p-value
    is significant, we can conclude there is no trend present (no unit root).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä» `Statsmodels` å¯¼å…¥ `arma_order_select_ic` å¹¶æ ¹æ®æˆ‘ä»¬åœ¨ *å›¾ 11**.4* ä¸­çš„ PACF å›¾ä¸­çš„è§‚å¯Ÿç»“æœï¼Œä½¿ç”¨æœ€å¤š
    4 ä¸ªæ»åé¡¹è¿›è¡Œæµ‹è¯•ã€‚æ­£å¦‚æ‰€æ³¨ï¼Œæ ¹æ®æˆ‘ä»¬çš„è§†è§‰æ£€æŸ¥ï¼Œæˆ‘ä»¬ä¼¼ä¹æ²¡æœ‰è¶‹åŠ¿ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ä¸ªåŸºäº OLS çš„å•ä½æ ¹æµ‹è¯•ï¼Œç§°ä¸º **Dickey-Fuller
    æµ‹è¯•** æ¥è¿›è¡Œç»Ÿè®¡éªŒè¯ã€‚Dickey-Fuller æµ‹è¯•çš„ **é›¶å‡è®¾** æ˜¯åœ¨æµ‹è¯•çš„æœ€å¤§æ»åæ•°ï¼ˆmaxlagï¼‰ä¸­çš„æŸä¸ªç‚¹å­˜åœ¨å•ä½æ ¹ï¼ˆå› æ­¤ï¼Œè¶‹åŠ¿ï¼‰ã€‚å¤‡æ‹©å‡è®¾æ˜¯æ•°æ®ä¸­æ²¡æœ‰å•ä½æ ¹ï¼ˆæ²¡æœ‰è¶‹åŠ¿ï¼‰ã€‚ä¸ºäº†å‚è€ƒï¼Œå¤‡æ‹©å‡è®¾è¡¨æ˜æ•°æ®æ˜¯ä¸€ä¸ªé›¶é˜¶
    - **I(0)** - é›†æˆè¿‡ç¨‹ï¼Œè€Œé›¶å‡è®¾è¡¨æ˜æ•°æ®æ˜¯ä¸€ä¸ªä¸€é˜¶ - **I(1)** - é›†æˆè¿‡ç¨‹ã€‚å¦‚æœæµ‹è¯•ç»Ÿè®¡é‡çš„ç»å¯¹å€¼å¤§äºä¸´ç•Œå€¼æˆ– p å€¼æ˜¾è‘—ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºæ²¡æœ‰è¶‹åŠ¿ï¼ˆæ²¡æœ‰å•ä½æ ¹ï¼‰çš„ç»“è®ºã€‚
- en: The Dickey-Fuller test considers each data point out to the number of lags included
    in the regression test. We will need to analyze the ACF plot for this; because
    we want to consider as far out as a trend could be possible, we must choose the
    longest lag that has significance. The idea is that if we have a strong trend
    in our data, such as growth, for the most part, each sequential value will lead
    to another increasing subsequent value for as long as the trend exists. In our
    case, the maximum significant lag in the ACF plot is approximately 25\. The Dickey-Fuller
    test has relatively low statistical power (prone to Type II error or failing to
    reject the null when the null should be rejected) so a high order of lags is not
    concerning so long as it is practical; the risk is failing to include enough lags.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Dickey-Fuller æµ‹è¯•è€ƒè™‘å›å½’æµ‹è¯•ä¸­åŒ…å«çš„æ»åæ•°ç›®çš„æ¯ä¸ªæ•°æ®ç‚¹ã€‚æˆ‘ä»¬éœ€è¦åˆ†æ ACF å›¾æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼›å› ä¸ºæˆ‘ä»¬å¸Œæœ›è€ƒè™‘è¶‹åŠ¿å¯èƒ½å­˜åœ¨çš„æœ€è¿œèŒƒå›´ï¼Œæˆ‘ä»¬å¿…é¡»é€‰æ‹©å…·æœ‰æ˜¾è‘—æ€§çš„æœ€é•¿æ»åã€‚æƒ³æ³•æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬æ•°æ®ä¸­æœ‰ä¸€ä¸ªå¼ºçƒˆçš„è¶‹åŠ¿ï¼Œæ¯”å¦‚å¢é•¿ï¼Œé‚£ä¹ˆåœ¨è¶‹åŠ¿å­˜åœ¨æœŸé—´ï¼Œæ¯ä¸ªè¿ç»­çš„å€¼éƒ½å°†å¯¼è‡´å¦ä¸€ä¸ªåç»­å€¼çš„å¢åŠ ã€‚åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼ŒACF
    å›¾ä¸­çš„æœ€å¤§æ˜¾è‘—æ»åå¤§çº¦æ˜¯ 25ã€‚ç”±äº Dickey-Fuller æµ‹è¯•çš„ç»Ÿè®¡åŠŸæ•ˆç›¸å¯¹è¾ƒä½ï¼ˆå®¹æ˜“çŠ¯ç¬¬äºŒç±»é”™è¯¯æˆ–å½“åº”è¯¥æ‹’ç»é›¶å‡è®¾æ—¶æœªèƒ½æ‹’ç»ï¼‰ï¼Œå› æ­¤åªè¦å®ƒæ˜¯å®ç”¨çš„ï¼Œé«˜é˜¶æ»åå¹¶ä¸ä»¤äººæ‹…å¿§ï¼›é£é™©æ˜¯æœªèƒ½åŒ…å«è¶³å¤Ÿçš„æ»åã€‚
- en: Dickey-Fuller unit roots
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Dickey-Fuller å•ä½æ ¹
- en: The Dickey-Fuller tests only if there is a trend unit root, but not if there
    is a seasonal unit root. We discuss the difference between trend and seasonal
    unit roots in the ARIMA section of this chapter.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Dickey-Fuller æµ‹è¯•ä»…å½“å­˜åœ¨è¶‹åŠ¿å•ä½æ ¹æ—¶æ‰è¿›è¡Œï¼Œä½†å¦‚æœæœ‰å­£èŠ‚æ€§å•ä½æ ¹åˆ™ä¸è¿›è¡Œã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« çš„ ARIMA éƒ¨åˆ†è®¨è®ºè¶‹åŠ¿å’Œå­£èŠ‚æ€§å•ä½æ ¹ä¹‹é—´çš„åŒºåˆ«ã€‚
- en: 'In the upcoming code block, we add `maxlag=25` for our 25 lags from the ACF
    plot in *Figure 11**.4*. We will also include `regression=''c''`, which adds a
    constant (or intercept) into the OLS it performs; we will not need to manually
    add the constant in that case:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¥ä¸‹æ¥çš„ä»£ç å—ä¸­ï¼Œæˆ‘ä»¬åœ¨ *å›¾11**.4* ä¸­çš„è‡ªç›¸å…³å›¾ï¼ˆACFï¼‰ä¸­æ·»åŠ äº† `maxlag=25`ï¼Œå¯¹åº”äºæˆ‘ä»¬çš„25ä¸ªæ»åé¡¹ã€‚æˆ‘ä»¬è¿˜å°†åŒ…æ‹¬ `regression='c'`ï¼Œè¿™å°†åœ¨è¿›è¡Œçš„
    OLS å›å½’ä¸­æ·»åŠ ä¸€ä¸ªå¸¸æ•°ï¼ˆæˆ–æˆªè·ï¼‰ï¼›åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¸éœ€è¦æ‰‹åŠ¨æ·»åŠ å¸¸æ•°ï¼š
- en: '[PRE6]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can see based on the Dickey-Fuller test that we should reject the null hypothesis
    and conclude the process is order-zero integrated and therefore does not have
    trend:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ® Dickey-Fuller æµ‹è¯•ï¼Œæˆ‘ä»¬åº”è¯¥æ‹’ç»é›¶å‡è®¾ï¼Œå¹¶å¾—å‡ºç»“è®ºè¯¥è¿‡ç¨‹æ˜¯é›¶é˜¶ç§¯åˆ†çš„ï¼Œå› æ­¤æ²¡æœ‰è¶‹åŠ¿ï¼š
- en: '`Dickey-Fuller p-value:` `1.6668842047161513e-06`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dickey-Fuller på€¼:` `1.6668842047161513e-06`'
- en: '`Dickey-Fuller test statistic: -``5.545206445371327`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dickey-Fuller æµ‹è¯•ç»Ÿè®¡é‡: -5.545206445371327`'
- en: '`Dickey-Fuller critical value: -``2.8765564361715534`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dickey-Fuller ä¸´ç•Œå€¼: -2.8765564361715534`'
- en: 'We can therefore insert into our `arma_order_select_ic` function that `trend=''n''`
    (otherwise, we may want to difference the data, which we will show in the ARIMA
    section of the chapter):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°† `trend='n'` æ’å…¥åˆ°æˆ‘ä»¬çš„ `arma_order_select_ic` å‡½æ•°ä¸­ï¼ˆå¦åˆ™ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦å¯¹æ•°æ®è¿›è¡Œå·®åˆ†ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬ç« çš„
    ARIMA éƒ¨åˆ†å±•ç¤ºï¼‰ï¼š
- en: '[PRE7]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here we can see the AR and MA orders identified to produce a fit with the lowest
    overall error according to our AIC and BIC tests:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ ¹æ®æˆ‘ä»¬çš„ AIC å’Œ BIC æµ‹è¯•ï¼Œè¯†åˆ«å‡ºçš„ AR å’Œ MA é˜¶æ•°ï¼Œä»¥äº§ç”Ÿæœ€ä½çš„æ•´ä½“è¯¯å·®ï¼š
- en: '`AIC Order Selection: (``4, 0)`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`AIC é˜¶æ•°é€‰æ‹©: (4, 0)`'
- en: '`AIC Error:` `586.341`'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`AIC é”™è¯¯:` `586.341`'
- en: '`BIC Order Selection: (``2, 0)`'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`BIC é˜¶æ•°é€‰æ‹©: (2, 0)`'
- en: '`BIC Error:` `597.642`'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`BIC é”™è¯¯:` `597.642`'
- en: We can see AIC selected an AR(4) and BIC selected an AR(2). It is preferable
    that both tests select the same term orders. However, as we noted already, the
    AR(2) may be less likely to overfit. Since the best order isnâ€™t completely clear,
    we will proceed to test both models (using AR(2) and AR(4)) by comparing their
    errors and log-likelihood estimates.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ° AIC é€‰æ‹©äº†ä¸€ä¸ª AR(4)ï¼Œè€Œ BIC é€‰æ‹©äº†ä¸€ä¸ª AR(2)ã€‚æœ€å¥½æ˜¯ä¸¤ä¸ªæµ‹è¯•éƒ½é€‰æ‹©ç›¸åŒçš„é¡¹é˜¶æ•°ã€‚ç„¶è€Œï¼Œæ­£å¦‚æˆ‘ä»¬ä¹‹å‰æåˆ°çš„ï¼ŒAR(2)
    å¯èƒ½ä¸å¤ªå¯èƒ½è¿‡åº¦æ‹Ÿåˆã€‚ç”±äºæœ€ä½³é˜¶æ•°å¹¶ä¸å®Œå…¨æ¸…æ¥šï¼Œæˆ‘ä»¬å°†é€šè¿‡æ¯”è¾ƒå®ƒä»¬çš„è¯¯å·®å’Œå¯¹æ•°ä¼¼ç„¶ä¼°è®¡æ¥æµ‹è¯•è¿™ä¸¤ä¸ªæ¨¡å‹ï¼ˆä½¿ç”¨ AR(2) å’Œ AR(4)ï¼‰ã€‚
- en: Step 3 - building the AR(p) model
  id: totrans-116
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬ 3 æ­¥ - æ„å»ºAR(p)æ¨¡å‹
- en: 'In this step, we can add our arguments to the `statsmodelsâ€™` ARIMA function
    and fit it to the data with our prescribed AR(4). To be clear, an AR(4) is the
    same as an ARIMA(4,0,0). We want to include `enforce_stationarity=True` to ensure
    our model will produce useful results. If not, we will receive a warning and need
    to address the issue by either differencing, using a different model â€“ such as
    SARIMA, changing our sampling method, changing our time binning (from days to
    weeks, for example), or abandoning time series modeling for the data altogether:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥å°†æˆ‘ä»¬çš„å‚æ•°æ·»åŠ åˆ°`statsmodels`çš„ARIMAå‡½æ•°ä¸­ï¼Œå¹¶ä½¿ç”¨æˆ‘ä»¬æŒ‡å®šçš„AR(4)æ‹Ÿåˆæ•°æ®ã€‚ä¸ºäº†æ˜ç¡®ï¼ŒAR(4)ç­‰åŒäºARIMA(4,0,0)ã€‚æˆ‘ä»¬å¸Œæœ›åŒ…å«`enforce_stationarity=True`ä»¥ç¡®ä¿æˆ‘ä»¬çš„æ¨¡å‹å°†äº§ç”Ÿæœ‰ç”¨çš„ç»“æœã€‚å¦‚æœä¸æ˜¯ï¼Œæˆ‘ä»¬å°†æ”¶åˆ°è­¦å‘Šï¼Œå¹¶éœ€è¦é€šè¿‡å·®åˆ†ã€ä½¿ç”¨ä¸åŒçš„æ¨¡å‹ï¼ˆå¦‚SARIMAï¼‰ã€æ”¹å˜æˆ‘ä»¬çš„é‡‡æ ·æ–¹æ³•ã€æ”¹å˜æˆ‘ä»¬çš„æ—¶é—´åˆ†ç®±ï¼ˆä¾‹å¦‚ä»å¤©åˆ°å‘¨ï¼‰æˆ–å®Œå…¨æ”¾å¼ƒæ—¶é—´åºåˆ—å»ºæ¨¡æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š
- en: '[PRE8]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In our model output, we can see the *SARIMAX Results* title and *Model: ARIMA(4,0,0)*.
    This can be disregarded. A SARIMAX with no seasonal component and no exogenous
    variables (in our case) is simply an ARIMA. Further, an ARIMA of order (4,0,0)
    is an *AR(4)*:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„æ¨¡å‹è¾“å‡ºä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°*SARIMAXç»“æœ*æ ‡é¢˜å’Œ*æ¨¡å‹ï¼šARIMA(4,0,0)*ã€‚è¿™å¯ä»¥å¿½ç•¥ã€‚æ²¡æœ‰å­£èŠ‚æˆåˆ†å’Œæ²¡æœ‰å¤–ç”Ÿå˜é‡ï¼ˆåœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼‰çš„SARIMAXåªæ˜¯ä¸€ä¸ªARIMAã€‚æ­¤å¤–ï¼Œé˜¶æ•°ä¸º(4,0,0)çš„ARIMAæ˜¯ä¸€ä¸ª*AR(4)*ï¼š
- en: '![Figure 11.5 â€“ AR(4) model results](img/B18945_11_005.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.5 â€“ AR(4)æ¨¡å‹ç»“æœ](img/B18945_11_005.jpg)'
- en: Figure 11.5 â€“ AR(4) model results
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.5 â€“ AR(4)æ¨¡å‹ç»“æœ
- en: The AR(4) process we modeled (the simulated process we built prior to step 1
    is
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å»ºæ¨¡çš„AR(4)è¿‡ç¨‹ï¼ˆåœ¨æ­¥éª¤1ä¹‹å‰æ„å»ºçš„æ¨¡æ‹Ÿè¿‡ç¨‹ï¼‰æ˜¯ï¼š
- en: yÂ t âˆ’ 1.59 yÂ tâˆ’1 + 0.544 yÂ tâˆ’2 + 0.511 yÂ tâˆ’3 âˆ’ 0.222 yÂ tâˆ’4 = ÏµÂ t
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: y_{t-1} - 1.59 y_{t-1} + 0.544 y_{t-2} + 0.511 y_{t-3} - 0.222 y_{t-4} = Ïµ_{t}
- en: 'and the AR(4) model we produced using the data from the input process is the
    following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨è¾“å…¥è¿‡ç¨‹çš„æ•°æ®ç”Ÿæˆçš„AR(4)æ¨¡å‹å¦‚ä¸‹ï¼š
- en: yÂ t âˆ’ 1.6217 yÂ tâˆ’1 + 0.6877 yÂ tâˆ’2 + 0.3066 yÂ tâˆ’3 âˆ’ 0.1158 yÂ tâˆ’4 = ÏµÂ t
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: y_{t-1} - 1.6217 y_{t-1} + 0.6877 y_{t-2} + 0.3066 y_{t-3} - 0.1158 y_{t-4}
    = Ïµ_{t}
- en: 'In backshift operator notation, we have the following equation:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åç§»ç®—å­ç¬¦å·è¡¨ç¤ºæ³•ä¸­ï¼Œæˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹æ–¹ç¨‹ï¼š
- en: (1 âˆ’ 1.6217B + 0.6877 BÂ 2 + 0.3066 BÂ 3 âˆ’ 0.1158 BÂ 4) yÂ t = ÏµÂ t
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: (1 - 1.6217B + 0.6877 B^2 + 0.3066 B^3 - 0.1158 B^4) y_{t} = Ïµ_{t}
- en: Notably, the term for lag 4 is not significant and the confidence interval contains
    0\. Therefore, including this term is a known risk for overfitting and something
    worth weighing if considering alternative models. It would be prudent to compare
    an AR(2) and even an AR(3) to our AR(4) based on AIC and BIC and choose a different
    model if the results are much improved, but we will skip this process for the
    sake of time.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ»å4çš„é¡¹å¹¶ä¸æ˜¾è‘—ï¼Œç½®ä¿¡åŒºé—´åŒ…å«0ã€‚å› æ­¤ï¼ŒåŒ…æ‹¬è¿™ä¸ªé¡¹æ˜¯è¿‡åº¦æ‹Ÿåˆçš„å·²çŸ¥é£é™©ï¼Œå¦‚æœè€ƒè™‘æ›¿ä»£æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ªå€¼å¾—æƒè¡¡çš„å› ç´ ã€‚å¦‚æœåŸºäºAICå’ŒBICæ¯”è¾ƒAR(2)ç”šè‡³AR(3)ä¸æˆ‘ä»¬çš„AR(4)çš„ç»“æœæœ‰æ˜¾è‘—æ”¹å–„ï¼Œé‚£ä¹ˆé€‰æ‹©ä¸åŒçš„æ¨¡å‹å°†æ˜¯è°¨æ…çš„ï¼Œä½†ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œæˆ‘ä»¬å°†è·³è¿‡è¿™ä¸ªè¿‡ç¨‹ã€‚
- en: Regarding the model summary metrics, we discussed the **Ljung-Box test** in
    the last chapter so will not cover the details here, but the high p-value *(Prob(Q)*)
    for that test indicates there is not correlated error at lag 1\. Typically, if
    there is serial correlation in the residuals of a model fit, the residuals will
    have lag 1 autocorrelation. The **Jarque-Bera test** assumes the errors are normally
    distributed under the null hypothesis and not normally distributed under the alternative
    hypothesis. The high p-value *(Prob(JB)*) for that test suggests the error is
    normally distributed. The test for **heteroskedasticity** tests the null that
    the residuals are constant (homoscedastic) with the alternative hypothesis being
    that they are non-constant, which is an issue for a time series regression fit.
    Here, our Heteroskedasticity p-value *(Prob(H)*) is high so we can assume our
    modelâ€™s residuals have constant variance. A **skew** score between [-0.5, 0.5]
    is considered not skewed, whereas between [-1, -0.5] or [0.5, 1] is moderately
    skewed and > Â±2 is high. A perfect score for **kurtosis** is 3\. Kurtosis > Â±7
    is high. Because our skew is 0.04 and our kurtosis score is 2.58, we can assume
    our residuals are normally distributed.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºæ¨¡å‹æ‘˜è¦æŒ‡æ ‡ï¼Œæˆ‘ä»¬åœ¨ä¸Šä¸€ç« è®¨è®ºäº†**Ljung-Box æ£€éªŒ**ï¼Œæ‰€ä»¥è¿™é‡Œä¸å†è¯¦ç»†è¯´æ˜ï¼Œä½†è¯¥æ£€éªŒçš„é«˜ p å€¼ï¼ˆProb(Q)ï¼‰è¡¨æ˜åœ¨æ»å 1 å¤„æ²¡æœ‰ç›¸å…³è¯¯å·®ã€‚é€šå¸¸ï¼Œå¦‚æœæ¨¡å‹æ‹Ÿåˆçš„æ®‹å·®ä¸­å­˜åœ¨åºåˆ—ç›¸å…³æ€§ï¼Œæ®‹å·®å°†å…·æœ‰æ»å
    1 çš„è‡ªç›¸å…³æ€§ã€‚**Jarque-Bera æ£€éªŒ**å‡è®¾åœ¨é›¶å‡è®¾ä¸‹è¯¯å·®æ˜¯æ­£æ€åˆ†å¸ƒçš„ï¼Œè€Œåœ¨å¤‡æ‹©å‡è®¾ä¸‹ä¸æ˜¯æ­£æ€åˆ†å¸ƒçš„ã€‚è¯¥æ£€éªŒçš„é«˜ p å€¼ï¼ˆProb(JB)ï¼‰è¡¨æ˜è¯¯å·®æ˜¯æ­£æ€åˆ†å¸ƒçš„ã€‚**å¼‚æ–¹å·®æ€§æ£€éªŒ**æ£€éªŒçš„æ˜¯æ®‹å·®æ˜¯å¦æ’å®šï¼ˆåŒæ–¹å·®ï¼‰ï¼Œå¤‡æ‹©å‡è®¾æ˜¯å®ƒä»¬ä¸æ˜¯æ’å®šçš„ï¼Œè¿™æ˜¯æ—¶é—´åºåˆ—å›å½’æ‹Ÿåˆçš„é—®é¢˜ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬çš„å¼‚æ–¹å·®æ€§
    p å€¼ï¼ˆProb(H)ï¼‰è¾ƒé«˜ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å‡è®¾æˆ‘ä»¬çš„æ¨¡å‹æ®‹å·®å…·æœ‰æ’å®šçš„æ–¹å·®ã€‚**ååº¦**åˆ†æ•°åœ¨ [-0.5, 0.5] ä¹‹é—´è¢«è®¤ä¸ºæ˜¯æœªåæ–œçš„ï¼Œè€Œåœ¨ [-1,
    -0.5] æˆ– [0.5, 1] ä¹‹é—´æ˜¯ä¸­åº¦åæ–œçš„ï¼Œè€Œ > Â±2 æ˜¯é«˜åº¦åæ–œçš„ã€‚**å³°åº¦**çš„å®Œç¾åˆ†æ•°æ˜¯ 3ã€‚å³°åº¦ > Â±7 æ˜¯é«˜åº¦åæ–œçš„ã€‚å› ä¸ºæˆ‘ä»¬çš„ååº¦ä¸º
    0.04ï¼Œæˆ‘ä»¬çš„å³°åº¦åˆ†æ•°ä¸º 2.58ï¼Œæˆ‘ä»¬å¯ä»¥å‡è®¾æˆ‘ä»¬çš„æ®‹å·®æ˜¯æ­£æ€åˆ†å¸ƒçš„ã€‚
- en: Step 4 - test forecasting
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 4 - æµ‹è¯•é¢„æµ‹
- en: 'Another method for validating a model is to forecast existing points using
    data leading up to those points. Here, we use the model to forecast the last 5
    points using the full dataset excluding those last 5 points. We then compare to
    get an idea of model performance. Note that we generated 200 samples and the index
    for those samples starts at 0\. Therefore, our 200th sample is at positional index
    199:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: éªŒè¯æ¨¡å‹çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨é‚£äº›ç‚¹ä¹‹å‰çš„æ•°æ®æ¥é¢„æµ‹ç°æœ‰ç‚¹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡å‹æ¥é¢„æµ‹æœ€å 5 ä¸ªç‚¹ï¼Œä½¿ç”¨çš„æ˜¯é™¤äº†æœ€å 5 ä¸ªç‚¹ä¹‹å¤–çš„å…¨æ•°æ®é›†ã€‚ç„¶åæˆ‘ä»¬è¿›è¡Œæ¯”è¾ƒï¼Œä»¥äº†è§£æ¨¡å‹æ€§èƒ½ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ç”Ÿæˆäº†
    200 ä¸ªæ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬çš„ç´¢å¼•ä» 0 å¼€å§‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„ç¬¬ 200 ä¸ªæ ·æœ¬ä½äºä½ç½®ç´¢å¼• 199ï¼š
- en: '[PRE9]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In the following table, the *mean* column is the forecast. We manually appended
    the *actuals* column with the last 5 values in our data to compare to the forecast.
    *mean_se* is our mean squared error for our estimates compared to actuals. *y*
    is our index and the *ci* columns are for our 95% forecast confidence interval
    since we used `alpha=0.05` in the previous code.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä»¥ä¸‹è¡¨æ ¼ä¸­ï¼Œ*mean* åˆ—æ˜¯é¢„æµ‹å€¼ã€‚æˆ‘ä»¬æ‰‹åŠ¨å°† *actuals* åˆ—æ·»åŠ åˆ°æˆ‘ä»¬æ•°æ®çš„æœ€å 5 ä¸ªå€¼ä¸­ï¼Œä»¥ä¸é¢„æµ‹å€¼è¿›è¡Œæ¯”è¾ƒã€‚*mean_se* æ˜¯æˆ‘ä»¬ä¼°è®¡å€¼ä¸å®é™…å€¼ç›¸æ¯”çš„å‡æ–¹è¯¯å·®ã€‚*y*
    æ˜¯æˆ‘ä»¬çš„ç´¢å¼•ï¼Œ*ci* åˆ—æ˜¯æˆ‘ä»¬ 95% é¢„æµ‹ç½®ä¿¡åŒºé—´ï¼Œå› ä¸ºæˆ‘ä»¬ä¹‹å‰åœ¨ä»£ç ä¸­ä½¿ç”¨ `alpha=0.05`ã€‚
- en: '| **y** | **mean** | **mean_se** | **mean_ci_lower** | **mean_ci_upper** |
    **actuals** |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| **y** | **mean** | **mean_se** | **mean_ci_lower** | **mean_ci_upper** |
    **actuals** |'
- en: '| 195 | 24.70391 | 0.99906 | 22.74579 | 26.662035 | 25.5264 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 195 | 24.70391 | 0.99906 | 22.74579 | 26.662035 | 25.5264 |'
- en: '| 196 | 19.36453 | 0.99906 | 17.4064 | 21.322652 | 18.8797 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 196 | 19.36453 | 0.99906 | 17.4064 | 21.322652 | 18.8797 |'
- en: '| 197 | 7.525904 | 0.99906 | 5.567779 | 9.484028 | 7.4586 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 197 | 7.525904 | 0.99906 | 5.567779 | 9.484028 | 7.4586 |'
- en: '| 198 | -5.8744 | 0.99906 | -7.83252 | -3.916274 | -7.1316 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 198 | -5.8744 | 0.99906 | -7.83252 | -3.916274 | -7.1316 |'
- en: '| 199 | -19.5785 | 0.99906 | -21.5366 | -17.620356 | -17.9268 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 199 | -19.5785 | 0.99906 | -21.5366 | -17.620356 | -17.9268 |'
- en: Figure 11.6 â€“ AR(4) model outputs versus actuals
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.6 â€“ AR(4) æ¨¡å‹è¾“å‡ºä¸å®é™…å€¼å¯¹æ¯”
- en: 'We can see based on our mean squared error (0.999062) that our model provides
    a reasonable fit across a forecast horizon of 5 points on test data. Using the
    following code, we plot our test forecast against the corresponding actuals:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æˆ‘ä»¬çš„å‡æ–¹è¯¯å·®ï¼ˆ0.999062ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ¨¡å‹åœ¨æµ‹è¯•æ•°æ®ä¸Šå¯¹ 5 ä¸ªç‚¹çš„é¢„æµ‹èŒƒå›´å†…æä¾›äº†åˆç†çš„æ‹Ÿåˆã€‚ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼Œæˆ‘ä»¬ç»˜åˆ¶äº†æˆ‘ä»¬çš„æµ‹è¯•é¢„æµ‹ä¸ç›¸åº”çš„å®é™…å€¼ï¼š
- en: '[PRE10]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Figure 11.7 â€“ The AR(4) test forecast](img/B18945_11_007.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 11.7 â€“ AR(4) æµ‹è¯•é¢„æµ‹](img/B18945_11_007.jpg)'
- en: Figure 11.7 â€“ The AR(4) test forecast
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.7 â€“ AR(4) æµ‹è¯•é¢„æµ‹
- en: Step 5 - building a forecast
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 5 - æ„å»ºé¢„æµ‹
- en: 'Determining a reasonable forecast horizon is highly dependent on at least the
    data and the process it represents, and the lag used for modeling, in addition
    to model error. The time series practitioner should weigh all factors of model
    performance and business needs versus risks before providing forecasting to stakeholders.
    Adding the following code, we re-run the plot to see our true forecast with a
    5-point horizon:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®å®šåˆç†çš„é¢„æµ‹èŒƒå›´é«˜åº¦ä¾èµ–äºè‡³å°‘æ•°æ®åŠå…¶æ‰€ä»£è¡¨çš„è¿‡ç¨‹ï¼Œä»¥åŠç”¨äºå»ºæ¨¡çš„æ»åï¼Œä»¥åŠæ¨¡å‹è¯¯å·®ã€‚åœ¨å‘åˆ©ç›Šç›¸å…³è€…æä¾›é¢„æµ‹ä¹‹å‰ï¼Œæ—¶é—´åºåˆ—ä»ä¸šè€…åº”æƒè¡¡æ¨¡å‹æ€§èƒ½å’Œä¸šåŠ¡éœ€æ±‚ä¸é£é™©çš„æ‰€æœ‰å› ç´ ã€‚æ·»åŠ ä»¥ä¸‹ä»£ç ï¼Œæˆ‘ä»¬é‡æ–°è¿è¡Œå›¾è¡¨ä»¥æŸ¥çœ‹å…·æœ‰5ç‚¹é¢„æµ‹èŒƒå›´çš„çœŸæ­£é¢„æµ‹ï¼š
- en: '[PRE11]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Figure 11.8 â€“ The AR(4) forecast horizon = 5](img/B18945_11_008.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.8 â€“ AR(4)é¢„æµ‹èŒƒå›´=5](img/B18945_11_008.jpg)'
- en: Figure 11.8 â€“ The AR(4) forecast horizon = 5
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.8 â€“ AR(4)é¢„æµ‹èŒƒå›´=5
- en: We will cover additional steps in the model evaluation section of this chapter.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨æœ¬ç« çš„æ¨¡å‹è¯„ä¼°éƒ¨åˆ†ä»‹ç»é¢å¤–çš„æ­¥éª¤ã€‚
- en: Moving average (MA) models
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç§»åŠ¨å¹³å‡ï¼ˆMAï¼‰æ¨¡å‹
- en: The MA(q) model
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MA(q)æ¨¡å‹
- en: Whereas the AR(p) model is a direct function of the correlation between lag
    zero and specific individual lags of order *p* over time, the moving average model
    of order *q*, MA(q), is a function of autocorrelation between lag zero and all
    previous lags included in order *q*. It acts as a low-pass filter that models
    errors to provide a useful fit to data.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: è€ŒAR(p)æ¨¡å‹æ˜¯æ—¶é—´ä¸Šæ»åé›¶ä¸ç‰¹å®šä¸ªä½“é˜¶æ•°*p*çš„æ»åä¹‹é—´çš„ç›¸å…³æ€§çš„ç›´æ¥å‡½æ•°ï¼Œé˜¶æ•°*p*çš„ç§»åŠ¨å¹³å‡æ¨¡å‹ï¼ŒMA(q)ï¼Œæ˜¯æ»åé›¶ä¸åŒ…æ‹¬åœ¨é˜¶æ•°*p*ä¸­çš„æ‰€æœ‰å…ˆå‰æ»åä¹‹é—´çš„è‡ªç›¸å…³å‡½æ•°ã€‚å®ƒä½œä¸ºä¸€ä¸ªä½é€šæ»¤æ³¢å™¨ï¼Œé€šè¿‡å»ºæ¨¡è¯¯å·®æ¥æä¾›å¯¹æ•°æ®çš„æœ‰æ•ˆæ‹Ÿåˆã€‚
- en: Let us take a process, yÂ t, that has a mean of zero and a random, normally distributed
    white noise component, ÏµÂ t, where t = Â± 1, Â± 2, â€¦. If we can write this process
    as
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªè¿‡ç¨‹ï¼ŒyÂ tï¼Œå®ƒå…·æœ‰é›¶å‡å€¼å’Œä¸€ä¸ªéšæœºã€æ­£æ€åˆ†å¸ƒçš„ç™½å™ªå£°æˆåˆ†ï¼ŒÏµÂ tï¼Œå…¶ä¸­t = Â± 1, Â± 2, â€¦ã€‚å¦‚æœæˆ‘ä»¬èƒ½å°†æ­¤è¿‡ç¨‹å†™æˆ
- en: yÂ t âˆ’ Î¼ = ÏµÂ t âˆ’ Ï´Â 1 ÏµÂ tâˆ’1 âˆ’ â€¦ âˆ’ Ï´Â q ÏµÂ tâˆ’q
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: yÂ t âˆ’ Î¼ = ÏµÂ t âˆ’ Ï´Â 1 ÏµÂ tâˆ’1 âˆ’ â€¦ âˆ’ Ï´Â q ÏµÂ tâˆ’q
- en: 'and Ï´Â 1, Ï´Â 2, â€¦ , Ï´Â q are real constants and Ï´Â q â‰  0, then we can call this
    a moving average process having order *q*, or MA(q). In backshift operator notation,
    we have the following:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä¸” Ï´Â 1, Ï´Â 2, â€¦ , Ï´Â q æ˜¯å®å¸¸æ•°ä¸” Ï´Â q â‰  0ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ç§°è¿™æ˜¯ä¸€ä¸ªå…·æœ‰é˜¶æ•°*q*çš„ç§»åŠ¨å¹³å‡è¿‡ç¨‹ï¼Œæˆ–MA(q)ã€‚åœ¨å‘åç§»ä½ç®—å­è®°æ³•ä¸­ï¼Œæˆ‘ä»¬æœ‰ä»¥ä¸‹ï¼š
- en: yÂ t âˆ’ Î¼ = (1 âˆ’ Ï´Â 1 B âˆ’ â€¦ âˆ’ Ï´Â q BÂ q) ÏµÂ t
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: yÂ t âˆ’ Î¼ = (1 âˆ’ Ï´Â 1 B âˆ’ â€¦ âˆ’ Ï´Â q BÂ q) ÏµÂ t
- en: 'We can define the autocorrelations (ÏÂ k) for the MA(q) model thusly:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è¿™æ ·å®šä¹‰MA(q)æ¨¡å‹çš„è‡ªç›¸å…³ï¼ˆÏÂ kï¼‰ï¼š
- en: ÏÂ k = Â âˆ’ Ï´Â k + âˆ‘Â j=1Â qâˆ’kÂ Ï´Â j Ï´Â j+kÂ Â _____________Â Â 1 + âˆ‘Â j=1Â qÂ Â Ï´Â jÂ 2
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ÏÂ k = Â âˆ’ Ï´Â k + âˆ‘Â j=1Â qâˆ’kÂ Ï´Â j Ï´Â j+kÂ Â _____________Â Â 1 + âˆ‘Â j=1Â qÂ Â Ï´Â jÂ 2
- en: For all lags *k* in 1,2, â€¦ , q. Where k > q, we have ÏÂ k = 0.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ‰€æœ‰æ»å*k*åœ¨1,2, â€¦ , qä¸­ã€‚å½“k > qæ—¶ï¼Œæˆ‘ä»¬æœ‰ÏÂ k = 0ã€‚
- en: When discussing the AR(p) models, we explained how the roots of the AR model
    must be outside the unit circle. When considering MA(q) models, we have the concept
    of invertibility. **Invertibility** essentially ensures a *logical and stable
    correlation with the past*. Typically, this means the current point in time is
    more closely related to nearby points in the past than those more distant. The
    inability to model a process using invertible roots means we cannot ensure our
    model provides a unique solution for the set of model autocorrelations. If points
    in the distant past are more relevant to the current point than those nearby,
    we have a randomness in the process that cannot be reliably modeled or forecasted.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: å½“è®¨è®ºAR(p)æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬è§£é‡Šäº†ARæ¨¡å‹çš„æ ¹å¿…é¡»ä½äºå•ä½åœ†å¤–éƒ¨ã€‚å½“è€ƒè™‘MA(q)æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬æœ‰å¯é€†æ€§çš„æ¦‚å¿µã€‚**å¯é€†æ€§**æœ¬è´¨ä¸Šç¡®ä¿äº†ä¸è¿‡å»çš„*é€»è¾‘å’Œç¨³å®šçš„å…³è”*ã€‚é€šå¸¸ï¼Œè¿™æ„å‘³ç€å½“å‰æ—¶é—´ç‚¹ä¸è¿‡å»é™„è¿‘çš„æ—¶é—´ç‚¹æ¯”é‚£äº›æ›´è¿œçš„æ—¶é—´ç‚¹æ›´ç´§å¯†ç›¸å…³ã€‚æ— æ³•ä½¿ç”¨å¯é€†æ ¹æ¥å»ºæ¨¡è¿‡ç¨‹æ„å‘³ç€æˆ‘ä»¬æ— æ³•ç¡®ä¿æˆ‘ä»¬çš„æ¨¡å‹ä¸ºæ¨¡å‹è‡ªç›¸å…³é›†æä¾›å”¯ä¸€è§£ã€‚å¦‚æœè¿‡å»è¾ƒè¿œçš„æ—¶é—´ç‚¹æ¯”é™„è¿‘çš„æ—¶é—´ç‚¹å¯¹å½“å‰ç‚¹æ›´ç›¸å…³ï¼Œé‚£ä¹ˆè¿‡ç¨‹ä¸­å­˜åœ¨æ— æ³•å¯é å»ºæ¨¡æˆ–é¢„æµ‹çš„éšæœºæ€§ã€‚
- en: Identifying MA(q) model invertibility
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: è¯†åˆ«MA(q)æ¨¡å‹çš„å¯é€†æ€§
- en: For a moving average model to be invertible, all roots must be outside the unit
    circle and non-imaginary; *all* roots must be greater than 1\. For an MA(1) process,
    it is invertible when |Ï´Â 1| < 1\. An invertible MA(q) process is equivalent to
    an infinite-order, converging AR(p). An AR(p) model converges if its coefficients
    converge to zero as lags k approach p. If an MA(q) is invertible, we can say yÂ t
    = Ï´(B) ÏµÂ t and Ï´Â âˆ’1(B) yÂ t = ÏµÂ t [*1*].
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿ç§»åŠ¨å¹³å‡æ¨¡å‹å¯é€†ï¼Œæ‰€æœ‰æ ¹å¿…é¡»ä½äºå•ä½åœ†å¤–éƒ¨ä¸”éè™šæ•°ï¼›*æ‰€æœ‰*æ ¹å¿…é¡»å¤§äº1ã€‚å¯¹äºMA(1)è¿‡ç¨‹ï¼Œå½“|Ï´Â 1| < 1æ—¶ï¼Œå®ƒæ˜¯å¯é€†çš„ã€‚ä¸€ä¸ªå¯é€†çš„MA(q)è¿‡ç¨‹ç­‰ä»·äºä¸€ä¸ªæ— é™é˜¶ã€æ”¶æ•›çš„AR(p)è¿‡ç¨‹ã€‚å¦‚æœAR(p)æ¨¡å‹çš„ç³»æ•°éšç€æ»åkæ¥è¿‘pè€Œæ”¶æ•›åˆ°é›¶ï¼Œåˆ™è¯¥æ¨¡å‹æ”¶æ•›ã€‚å¦‚æœä¸€ä¸ªMA(q)æ˜¯å¯é€†çš„ï¼Œæˆ‘ä»¬å¯ä»¥è¯´yÂ t
    = Ï´(B) ÏµÂ t å’Œ Ï´Â âˆ’1(B) yÂ t = ÏµÂ t [*1*]ã€‚
- en: The MA(1) model
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MA(1)æ¨¡å‹
- en: 'For an MA(q) model of order 1, we have the following process:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸€é˜¶MA(q)æ¨¡å‹ï¼Œæˆ‘ä»¬æœ‰ä»¥ä¸‹è¿‡ç¨‹ï¼š
- en: ÏÂ 0 = 1
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ÏÂ 0 = 1
- en: ÏÂ 1 = Â Ï´Â 1Â _Â 1 + Ï´Â 1Â 2
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ÏÂ 1 = Â Ï´Â 1Â _Â 1 + Ï´Â 1Â 2
- en: ÏÂ k>1 = 0
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ÏÂ k>1 = 0
- en: For a MA(q) model with zero autocorrelation, the pattern of whose process we
    are attempting to model is random, normally distributed white noise variance,
    which can â€“ at best â€“ only be modeled by its mean. It is important to note that
    as Ï´Â 1 â†’ 0, ÏÂ 1 â†’ 0 and for an MA(1) process, this means the process can be approximated
    by white noise.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå…·æœ‰é›¶è‡ªç›¸å…³å‡½æ•°çš„MA(q)æ¨¡å‹ï¼Œæˆ‘ä»¬è¯•å›¾å»ºæ¨¡çš„è¿‡ç¨‹æ¨¡å¼æ˜¯éšæœºçš„ï¼Œæœä»æ­£æ€åˆ†å¸ƒçš„ç™½å™ªå£°æ–¹å·®ï¼Œè¿™æœ€å¤šåªèƒ½é€šè¿‡å…¶å‡å€¼æ¥å»ºæ¨¡ã€‚é‡è¦çš„æ˜¯è¦æ³¨æ„ï¼Œå½“ Ï´â‚ â†’
    0 æ—¶ï¼ŒÏâ‚ â†’ 0ï¼Œå¯¹äºMA(1)è¿‡ç¨‹ï¼Œè¿™æ„å‘³ç€è¿‡ç¨‹å¯ä»¥è¿‘ä¼¼ä¸ºç™½å™ªå£°ã€‚
- en: 'Let us consider the following MA(1) zero-mean model following the form yÂ t
    âˆ’ Î¼ = ÏµÂ t âˆ’ Ï´Â 1 ÏµÂ tâˆ’1:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è€ƒè™‘ä»¥ä¸‹MA(1)é›¶å‡å€¼æ¨¡å‹ï¼Œå…¶å½¢å¼ä¸ºy_t - Î¼ = Ïµ_t - Ï´â‚ Ïµ_{t-1}ï¼š
- en: yÂ t âˆ’ 0 = aÂ t âˆ’ 0.8 ÏµÂ tâˆ’1
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: y_t - 0 = a_t - 0.8 Ïµ_{t-1}
- en: 'In backshift notation we have the following:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åç§»è®°å·æ³•ä¸­ï¼Œæˆ‘ä»¬æœ‰ä»¥ä¸‹å†…å®¹ï¼š
- en: yÂ t = (1 âˆ’ 0.8B) ÏµÂ t
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: y_t = (1 - 0.8B) Ïµ_t
- en: 'We know this process is invertible because |Ï´Â 1| < 1\. Let us confirm this
    with Python using the `ArmaProcess` function from the `statsmodels` `tsa` module:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çŸ¥é“è¿™ä¸ªè¿‡ç¨‹æ˜¯å¯é€†çš„ï¼Œå› ä¸º |Ï´â‚| < 1ã€‚è®©æˆ‘ä»¬ä½¿ç”¨Pythonä¸­çš„`statsmodels.tsa`æ¨¡å—çš„`ArmaProcess`å‡½æ•°æ¥ç¡®è®¤è¿™ä¸€ç‚¹ï¼š
- en: '[PRE12]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`MA(1) Roots: [``1.25]`'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`MA(1) Roots: [1.25]`'
- en: '`MA(1) Invertibility:` `True`'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '`MA(1) å¯é€†æ€§:` `True`'
- en: 'Contrary to the AR(p) model, the MA(q) modelâ€™s order is identified using the
    ACF plot. Because the ACF does not control for lags and is a composite autocorrelation
    measure across all lags up to the lag whose autocorrelation measure is considered,
    the function is used to identify the relevant lag order for the moving average
    component. In *Figure 11**.9*, we can see the significant correlation at lag 1
    for our MA(1) process. There are two additional significant correlations at lags
    6 and 7, but using lags this far out typically results in overfitting, especially
    when taken alongside the fact that lags 2 through 5 are not significant at the
    5% level of significance:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸AR(p)æ¨¡å‹ç›¸åï¼ŒMA(q)æ¨¡å‹çš„é˜¶æ•°æ˜¯é€šè¿‡ACFå›¾æ¥ç¡®å®šçš„ã€‚å› ä¸ºACFæ²¡æœ‰æ§åˆ¶æ»åï¼Œå¹¶ä¸”æ˜¯è€ƒè™‘åˆ°çš„æ»åé˜¶æ•°åŠå…¶è‡ªç›¸å…³æµ‹åº¦çš„ä¸€ä¸ªç»¼åˆè‡ªç›¸å…³åº¦é‡ï¼Œæ‰€ä»¥è¯¥å‡½æ•°ç”¨äºç¡®å®šç§»åŠ¨å¹³å‡æˆåˆ†çš„ç›¸å…³æ»åé˜¶æ•°ã€‚åœ¨*å›¾11*.*9*ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„MA(1)è¿‡ç¨‹åœ¨æ»å1å¤„çš„æ˜¾è‘—ç›¸å…³æ€§ã€‚åœ¨æ»å6å’Œ7å¤„è¿˜æœ‰ä¸¤ä¸ªé¢å¤–çš„æ˜¾è‘—ç›¸å…³æ€§ï¼Œä½†ä½¿ç”¨å¦‚æ­¤è¿œçš„æ»åé€šå¸¸ä¼šå¯¼è‡´è¿‡åº¦æ‹Ÿåˆï¼Œå°¤å…¶æ˜¯å½“è€ƒè™‘åˆ°æ»å2è‡³5åœ¨5%çš„æ˜¾è‘—æ€§æ°´å¹³ä¸Šå¹¶ä¸æ˜¾è‘—ï¼š
- en: '![Figure 11.9 â€“ MA(1) plots](img/B18945_11_009.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.9 â€“ MA(1)å›¾](img/B18945_11_009.jpg)'
- en: Figure 11.9 â€“ MA(1) plots
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.9 â€“ MA(1)å›¾
- en: Dampening ACFs and PACFs
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶ˆå‡ACFå’ŒPACF
- en: For an invertible moving average model, we can observe that the ACF will cut
    off at the order of significance, but the PACF will typically continue and dampen
    *overall* to statistical zero over time. It is not necessarily expected to happen
    smoothly and all at once as all data sets are different, but it is expected that
    over time, more and more lags will dampen to zero. We explain the reason for this
    behavior from the ACFs and PACFs in the ARMA section of this chapter, but it is
    worth noting this is to be expected for invertible processes. Conversely, stationary
    autoregressive processes are expected to cut off at the order of significance
    in the PACF plots while the ACFs dampen to zero over time.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¯é€†ç§»åŠ¨å¹³å‡æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°è‡ªç›¸å…³å‡½æ•°ï¼ˆACFï¼‰å°†åœ¨æ˜¾è‘—æ€§é˜¶æ•°å¤„æˆªæ–­ï¼Œä½†åè‡ªç›¸å…³å‡½æ•°ï¼ˆPACFï¼‰é€šå¸¸ä¼šç»§ç»­å¹¶éšæ—¶é—´é€æ¸è¡°å‡è‡³ç»Ÿè®¡ä¸Šçš„é›¶ã€‚è¿™å¹¶ä¸ä¸€å®šæœŸæœ›ä¼šå¹³æ»‘ä¸”ä¸€æ¬¡æ€§å‘ç”Ÿï¼Œå› ä¸ºæ‰€æœ‰æ•°æ®é›†éƒ½æ˜¯ä¸åŒçš„ï¼Œä½†é¢„è®¡éšç€æ—¶é—´çš„æ¨ç§»ï¼Œè¶Šæ¥è¶Šå¤šçš„æ»åé¡¹å°†è¡°å‡è‡³é›¶ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« çš„ARMAéƒ¨åˆ†è§£é‡Šè¿™ç§è¡Œä¸ºçš„ç†ç”±ï¼Œä½†å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¯¹äºå¯é€†è¿‡ç¨‹ï¼Œè¿™æ˜¯å¯ä»¥é¢„æœŸçš„ã€‚ç›¸åï¼Œå¹³ç¨³è‡ªå›å½’è¿‡ç¨‹åœ¨PACFå›¾ä¸­é¢„è®¡ä¼šåœ¨æ˜¾è‘—æ€§é˜¶æ•°å¤„æˆªæ–­ï¼Œè€ŒACFéšæ—¶é—´è¡°å‡è‡³é›¶ã€‚
- en: The MA(2) model
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MA(2)æ¨¡å‹
- en: 'For an MA(q) model of order 2, we have this:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºäºŒé˜¶çš„MA(q)æ¨¡å‹ï¼Œæˆ‘ä»¬æœ‰ä»¥ä¸‹å…¬å¼ï¼š
- en: ÏÂ 0 = 1
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Ïâ‚€ = 1
- en: ÏÂ 1 = Â âˆ’ Ï´Â 1 + Ï´Â 1 Ï´Â 2Â Â _Â 1 + Ï´Â 1Â 2 + Ï´Â 2Â 2
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Ïâ‚ = - Ï´â‚ + Ï´â‚ Ï´â‚‚_1 + Ï´â‚Â² + Ï´â‚‚Â²
- en: ÏÂ 2 = Â âˆ’ Ï´Â 2Â _Â 1 + Ï´Â 1Â 2 + Ï´Â 2Â 2
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ÏÂ² = - Ï´Â²_1 + Ï´â‚Â² + Ï´Â²_2
- en: ÏÂ k>2 = 0
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Ï_k>2 = 0
- en: 'The following is an MA(2) example we will look at:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯ä¸€ä¸ªæˆ‘ä»¬å°†è¦ç ”ç©¶çš„MA(2)ç¤ºä¾‹ï¼š
- en: yÂ t = (1 âˆ’ 1.6B + 0.9 BÂ 2) ÏµÂ t
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: y_t = (1 - 1.6B + 0.9BÂ²) Ïµ_t
- en: 'Using the modelâ€™s polynomial in the quadratic equation form, we can find the
    approximate roots using the quadratic formula:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨äºŒæ¬¡æ–¹ç¨‹çš„æ¨¡å‹å¤šé¡¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨äºŒæ¬¡å…¬å¼æ‰¾åˆ°è¿‘ä¼¼æ ¹ï¼š
- en: 0.888 Â± 0.567i
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 0.888 Â± 0.567i
- en: 'Because we have two complex conjugate roots, we can take the same LÂ 2 norm
    we did for the AR(p) process, using the form of a Â± bi:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬æœ‰ä¸¤ä¸ªå…±è½­å¤æ ¹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸AR(p)è¿‡ç¨‹ç›¸åŒçš„LÂ²èŒƒæ•°ï¼Œä½¿ç”¨å½¢å¼ä¸ºa Â± biï¼š
- en: âˆšÂ _____________Â Â 0.888Â 2 + 0.567Â 2Â  â‰ˆ 1.054
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: âˆš(0.888Â² + 0.567Â²) â‰ˆ 1.054
- en: 'Because 1.054 is greater than 1, we can confirm the MA(2) has invertible roots
    and is thus capable of producing a unique solution and a model whose values are
    logically serially correlated to past values. Let us perform the same analysis
    in Python:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸º 1.054 å¤§äº 1ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®è®¤ MA(2) æœ‰å¯é€†æ ¹ï¼Œå› æ­¤èƒ½å¤Ÿäº§ç”Ÿä¸€ä¸ªå”¯ä¸€è§£å’Œä¸€ä¸ªæ¨¡å‹ï¼Œå…¶å€¼åœ¨é€»è¾‘ä¸Šæ˜¯ä¸è¿‡å»å€¼åºåˆ—ç›¸å…³çš„ã€‚è®©æˆ‘ä»¬åœ¨ Python
    ä¸­è¿›è¡ŒåŒæ ·çš„åˆ†æï¼š
- en: '[PRE13]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output we see highlighted in green confirms our calculated findings and
    the fact that since the magnitude of the complex conjugate roots is greater than
    0, we have an invertible MA(2) process:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç”¨ç»¿è‰²çªå‡ºæ˜¾ç¤ºçš„è¾“å‡ºç¡®è®¤äº†æˆ‘ä»¬çš„è®¡ç®—ç»“æœå’Œäº‹å®ï¼Œå³ç”±äºå¤å…±è½­æ ¹çš„å¹…åº¦å¤§äº 0ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªå¯é€†çš„ MA(2) è¿‡ç¨‹ï¼š
- en: '`MA(2) Roots: [``0.88888889-0.56655772j 0.88888889+0.56655772j]`'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`MA(2) æ ¹: [0.88888889-0.56655772j 0.88888889+0.56655772j]`'
- en: '`MA(2) Invertibility:` `True`'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`MA(2) å¯é€†æ€§:` `True`'
- en: 'We can see in the ACF in *Figure 11**.10* that this is a second-order moving
    average process:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨å›¾ 11**.10** çš„è‡ªç›¸å…³å›¾ä¸­çœ‹åˆ°ï¼Œè¿™æ˜¯ä¸€ä¸ªäºŒé˜¶ç§»åŠ¨å¹³å‡è¿‡ç¨‹ï¼š
- en: '![Figure 11.10 â€“ MA(2) plots](img/B18945_11_010.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 11.10 â€“ MA(2) å›¾](img/B18945_11_010.jpg)'
- en: Figure 11.10 â€“ MA(2) plots
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.10 â€“ MA(2) å›¾
- en: The process and code for identifying model ordering, building the model, and
    generating a forecast are the same for the MA(q) model as it is for the AR(p)
    model. We have discussed that the order selection based on visual inspection for
    the MA(q) is performed using the ACF, whereas for the AR(p) this is done using
    the PACF, and that it is the only major difference in the process between the
    two models. Aside from that, `enforce_invertibility` should be set to equal `True`
    for MA(q) models in place of `enforce_stationarity=True`. Providing a `max_ar`
    or `max_ma` order higher or lower than useful in the `arma_order_select_ic` function
    may result in a *convergence warning or an invertibility warning*. One reason
    for these warnings is there was a higher order provided than possible to fit (such
    as when there is no order possible). Another reason is the presence of a **unit
    root**. If there is an apparent trend in the data, it *must be removed* before
    modeling. If there is no trend, it is possible to receive this error due to seasonality
    in the data, which presents a different order of unit root. We will discuss modeling
    in the case of unit roots associated with trend and seasonality in the ARIMA and
    seasonal ARIMA section of this chapter. It is also worth specifying that the Dickey-Fuller
    test can be used for moving average data since moving average processes can be
    influenced by trends.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº MA(q) æ¨¡å‹ï¼Œè¯†åˆ«æ¨¡å‹é˜¶æ•°ã€æ„å»ºæ¨¡å‹å’Œç”Ÿæˆé¢„æµ‹çš„è¿‡ç¨‹ä¸ AR(p) æ¨¡å‹ç›¸åŒã€‚æˆ‘ä»¬è®¨è®ºè¿‡ï¼Œå¯¹äº MA(q)ï¼ŒåŸºäºè§†è§‰æ£€æŸ¥çš„é˜¶æ•°é€‰æ‹©æ˜¯é€šè¿‡ ACF
    è¿›è¡Œçš„ï¼Œè€Œå¯¹äº AR(p)ï¼Œè¿™æ˜¯é€šè¿‡ PACF è¿›è¡Œçš„ï¼Œè¿™æ˜¯ä¸¤ä¸ªæ¨¡å‹ä¹‹é—´è¿‡ç¨‹çš„ä¸»è¦åŒºåˆ«ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œå¯¹äº MA(q) æ¨¡å‹ï¼Œåº”å°† `enforce_invertibility`
    è®¾ç½®ä¸º `True` è€Œä¸æ˜¯ `enforce_stationarity=True`ã€‚åœ¨ `arma_order_select_ic` å‡½æ•°ä¸­æä¾›æ¯”æœ‰ç”¨é˜¶æ•°æ›´é«˜æˆ–æ›´ä½çš„
    `max_ar` æˆ– `max_ma` é˜¶æ•°å¯èƒ½ä¼šå¯¼è‡´æ”¶æ•›è­¦å‘Šæˆ–å¯é€†æ€§è­¦å‘Šã€‚è¿™äº›è­¦å‘Šçš„ä¸€ä¸ªåŸå› æ˜¯æä¾›äº†æ¯”å¯èƒ½æ‹Ÿåˆçš„æ›´é«˜é˜¶æ•°ï¼ˆä¾‹å¦‚ï¼Œå½“æ²¡æœ‰å¯èƒ½çš„é˜¶æ•°æ—¶ï¼‰ã€‚å¦ä¸€ä¸ªåŸå› æ˜¯å­˜åœ¨ä¸€ä¸ª**å•ä½æ ¹**ã€‚å¦‚æœæ•°æ®ä¸­å­˜åœ¨æ˜æ˜¾çš„è¶‹åŠ¿ï¼Œåˆ™åœ¨å»ºæ¨¡ä¹‹å‰å¿…é¡»å°†å…¶**å»é™¤**ã€‚å¦‚æœæ²¡æœ‰è¶‹åŠ¿ï¼Œç”±äºæ•°æ®ä¸­çš„å­£èŠ‚æ€§ï¼Œå¯èƒ½ä¼šæ”¶åˆ°æ­¤é”™è¯¯ï¼Œè¿™è¡¨ç°ä¸ºä¸åŒçš„å•ä½æ ¹é˜¶æ•°ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ç« çš„
    ARIMA å’Œå­£èŠ‚æ€§ ARIMA éƒ¨åˆ†è®¨è®ºä¸è¶‹åŠ¿å’Œå­£èŠ‚æ€§ç›¸å…³çš„å•ä½æ ¹çš„å»ºæ¨¡ã€‚è¿˜å€¼å¾—æŒ‡å‡ºçš„æ˜¯ï¼Œç”±äºç§»åŠ¨å¹³å‡è¿‡ç¨‹å¯èƒ½å—åˆ°è¶‹åŠ¿çš„å½±å“ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨ Dickey-Fuller
    æµ‹è¯•æ¥ç§»åŠ¨å¹³å‡æ•°æ®ã€‚
- en: Autoregressive moving average (ARMA) models
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªå›å½’ç§»åŠ¨å¹³å‡ (ARMA) æ¨¡å‹
- en: In the autoregressive model section, we discussed how an AR(p) model is used
    to model process output values using autocorrelation controlling for individual
    lags. The goal of the AR(p) model is to estimate exact values for points corresponding
    to lags in the future using the values for the same specific lags in the context
    of a past horizon. For example, the value at two points in the future is strongly
    correlated with the value at two points in the past. In the moving average model
    section, we discussed how MA(q) models act as low-pass filters that help a model
    explain noise in a process. Rather than seeking to model exact points, we use
    the MA(q) to model variance around the process.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è‡ªå›å½’æ¨¡å‹éƒ¨åˆ†ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•ä½¿ç”¨ AR(p) æ¨¡å‹é€šè¿‡è‡ªç›¸å…³æ§åˆ¶ä¸ªä½“æ»åæ¥å»ºæ¨¡è¿‡ç¨‹è¾“å‡ºå€¼ã€‚AR(p) æ¨¡å‹çš„ç›®æ ‡æ˜¯ä½¿ç”¨è¿‡å»æŸä¸ªç‰¹å®šæ»åä¸‹çš„å€¼æ¥ä¼°è®¡æœªæ¥å¯¹åº”æ»åç‚¹çš„ç¡®åˆ‡å€¼ã€‚ä¾‹å¦‚ï¼Œæœªæ¥ä¸¤ä¸ªç‚¹çš„å€¼ä¸è¿‡å»ä¸¤ä¸ªç‚¹çš„å€¼é«˜åº¦ç›¸å…³ã€‚åœ¨ç§»åŠ¨å¹³å‡æ¨¡å‹éƒ¨åˆ†ï¼Œæˆ‘ä»¬è®¨è®ºäº†
    MA(q) æ¨¡å‹å¦‚ä½•ä½œä¸ºä½é€šæ»¤æ³¢å™¨ï¼Œå¸®åŠ©æ¨¡å‹è§£é‡Šè¿‡ç¨‹ä¸­çš„å™ªå£°ã€‚æˆ‘ä»¬ä¸æ˜¯å¯»æ±‚å»ºæ¨¡ç¡®åˆ‡ç‚¹ï¼Œè€Œæ˜¯ä½¿ç”¨ MA(q) æ¥å»ºæ¨¡è¿‡ç¨‹å‘¨å›´çš„æ–¹å·®ã€‚
- en: Consider an example of a four-cylinder car engine that produces constant output.
    Let us assume we have a worn-down motor mount near the fourth cylinder. We can
    expect consistent output vibration related to each cylinder firing, but the vibration
    will increase slightly for each stroke that is closer to the worn motor mount.
    Using an AR-only model would assume each cylinder vibrates a certain amount and
    be able to account for that, but we would be missing information. Adding a MA
    component would be able to model the fact that starting at cylinder one, each
    subsequent stroke up through cylinder four will have additional vibration related
    to the worn motor mount and thus explain much more of the overall process. This
    would reasonably be an ARMA(4,4) model. Suppose we replace the worn-down motor
    mount with a mount of equal wear compared to the other mounts; we would then have
    an ARMA(4,0) (or AR(4)) process.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘ä¸€ä¸ªå››ç¼¸æ±½è½¦å‘åŠ¨æœºçš„ä¾‹å­ï¼Œè¯¥å‘åŠ¨æœºäº§ç”Ÿæ’å®šçš„è¾“å‡ºã€‚è®©æˆ‘ä»¬å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç£¨æŸçš„å‘åŠ¨æœºæ”¯æ¶é è¿‘ç¬¬å››ç¼¸ã€‚æˆ‘ä»¬å¯ä»¥é¢„æœŸä¸æ¯ä¸ªæ°”ç¼¸ç‚¹ç«ç›¸å…³çš„è¿ç»­è¾“å‡ºæŒ¯åŠ¨ï¼Œä½†æŒ¯åŠ¨ä¼šéšç€æ¥è¿‘ç£¨æŸçš„å‘åŠ¨æœºæ”¯æ¶çš„æ¯ä¸€ä¸‹å†²è€Œç•¥æœ‰å¢åŠ ã€‚ä½¿ç”¨ä»…ARæ¨¡å‹ä¼šå‡è®¾æ¯ä¸ªæ°”ç¼¸æŒ¯åŠ¨ä¸€å®šé‡å¹¶èƒ½è§£é‡Šè¿™ä¸€ç‚¹ï¼Œä½†æˆ‘ä»¬ä¼šä¸¢å¤±ä¿¡æ¯ã€‚æ·»åŠ ä¸€ä¸ªMAæˆåˆ†å°†èƒ½å¤Ÿæ¨¡æ‹Ÿä»ç¬¬ä¸€ç¼¸å¼€å§‹ï¼Œæ¯ä¸ªåç»­å†²ç¨‹ç›´åˆ°ç¬¬å››ç¼¸éƒ½ä¼šæœ‰ä¸ç£¨æŸçš„å‘åŠ¨æœºæ”¯æ¶ç›¸å…³çš„é¢å¤–æŒ¯åŠ¨ï¼Œä»è€Œè§£é‡Šæ›´å¤šçš„æ•´ä½“è¿‡ç¨‹ã€‚è¿™åˆç†åœ°æ˜¯ä¸€ä¸ªARMA(4,4)æ¨¡å‹ã€‚å‡è®¾æˆ‘ä»¬ç”¨ç£¨æŸç¨‹åº¦ä¸å…¶ä»–æ”¯æ¶ç›¸åŒçš„æ”¯æ¶æ›¿æ¢ç£¨æŸçš„å‘åŠ¨æœºæ”¯æ¶ï¼›é‚£ä¹ˆæˆ‘ä»¬å°±ä¼šæœ‰ARMA(4,0)ï¼ˆæˆ–AR(4)ï¼‰è¿‡ç¨‹ã€‚
- en: 'In many cases, we find we have significant peaks in both autocorrelation and
    partial autocorrelation. Rather than using only MA(q) or AR(p) modeling, respectively,
    we can combine the two. This combination, represented as an ARMA(p,q), enables
    us to model the process as well as any noise component around the process that
    may correlate to specific lags. Because an ARMA(p,q) typically has fewer parameters
    (lower order) for each AR and MA component than AR or MA models do, the ARMA is
    considered a **parsimonious model**, which is a model that uses as few explanatory
    variables (in this case, time lags) as possible to achieve the desired level of
    performance. When yÂ t is an invertible and stationary process, we can define it
    as an ARMA(p,q):'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å‘ç°è‡ªç›¸å…³å’Œåè‡ªç›¸å…³éƒ½æœ‰æ˜¾è‘—çš„å³°å€¼ã€‚è€Œä¸æ˜¯åªä½¿ç”¨MA(q)æˆ–AR(p)æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¸¤è€…ç»“åˆèµ·æ¥ã€‚è¿™ç§ç»„åˆï¼Œè¡¨ç¤ºä¸ºARMA(p,q)ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿæ¨¡æ‹Ÿè¿‡ç¨‹ä»¥åŠå¯èƒ½ä¸ç‰¹å®šæ»åç›¸å…³çš„è¿‡ç¨‹å‘¨å›´çš„ä»»ä½•å™ªå£°æˆåˆ†ã€‚å› ä¸ºARMA(p,q)é€šå¸¸æ¯”ARæˆ–MAæ¨¡å‹å…·æœ‰æ›´å°‘çš„å‚æ•°ï¼ˆæ›´ä½é˜¶ï¼‰ï¼ŒARMAè¢«è®¤ä¸ºæ˜¯ä¸€ä¸ª**ç®€çº¦æ¨¡å‹**ï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨å°½å¯èƒ½å°‘çš„è§£é‡Šå˜é‡ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ—¶é—´æ»åï¼‰æ¥å®ç°æ‰€éœ€æ€§èƒ½æ°´å¹³çš„æ¨¡å‹ã€‚å½“yÂ tæ˜¯ä¸€ä¸ªå¯é€†å’Œå¹³ç¨³çš„è¿‡ç¨‹æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶å®šä¹‰ä¸ºARMA(p,q)ï¼š
- en: yÂ t âˆ’ Î¼ = Î¦Â 1(yÂ tâˆ’1 âˆ’ Î¼) âˆ’ â€¦ âˆ’ Î¦Â p(yÂ tâˆ’p âˆ’ Î¼) = ÏµÂ t âˆ’ Ï´Â 1 ÏµÂ tâˆ’1 âˆ’ â€¦ âˆ’ Ï´Â q ÏµÂ tâˆ’q
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: yÂ t âˆ’ Î¼ = Î¦Â 1(yÂ tâˆ’1 âˆ’ Î¼) âˆ’ â€¦ âˆ’ Î¦Â p(yÂ tâˆ’p âˆ’ Î¼) = ÏµÂ t âˆ’ Ï´Â 1 ÏµÂ tâˆ’1 âˆ’ â€¦ âˆ’ Ï´Â q ÏµÂ tâˆ’q
- en: 'Where Î¦Â p â‰  0 and Ï´Â q â‰  0, we can re-write the equation for ARMA(p,q) in backshift
    operator notation:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: å½“Î¦Â p â‰  0å’ŒÏ´Â q â‰  0æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨åç§»ç®—å­ç¬¦å·é‡æ–°å†™å‡ºARMA(p,q)çš„æ–¹ç¨‹ï¼š
- en: Î¦B(yÂ t âˆ’ Î¼) = Ï´(B) ÏµÂ t
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Î¦B(yÂ t âˆ’ Î¼) = Ï´(B) ÏµÂ t
- en: 'Practically speaking, we can expect that for an invertible moving average process,
    we see significant lags in the ACF up to the magnitude of the order *q*, but then
    the PACF will taper off thereafter, typically in lags beyond the order of the
    moving average process identified in the ACF. This is because a finite moving
    average process can be represented as an infinite-order autoregressive process.
    Conversely, because the moving average process that has this behavior is invertible,
    the inverse must also be true; that a finite autoregressive process can be represented
    as an infinite-order moving average process. Therefore, the PACF will dampen to
    zero for an invertible moving average process, and for a stationary autoregressive
    process, the ACF will dampen to zero. Because invertibility is a requirement of
    an ARMA process, it allows us to re-write the equation as an infinite-order MA
    process in general linear form:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å®é™…è§’åº¦æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥é¢„æœŸå¯¹äºä¸€ä¸ªå¯é€†çš„ç§»åŠ¨å¹³å‡è¿‡ç¨‹ï¼Œåœ¨è‡ªç›¸å…³å‡½æ•°ï¼ˆACFï¼‰ä¸­æˆ‘ä»¬ä¼šçœ‹åˆ°æ˜¾è‘—çš„æ»åï¼Œç›´åˆ°é˜¶æ•° *q* çš„é‡çº§ï¼Œä½†éšååè‡ªç›¸å…³å‡½æ•°ï¼ˆPACFï¼‰å°†é€æ¸å‡å°ï¼Œé€šå¸¸åœ¨ACFä¸­è¯†åˆ«å‡ºçš„ç§»åŠ¨å¹³å‡è¿‡ç¨‹é˜¶æ•°ä¹‹å¤–ã€‚è¿™æ˜¯å› ä¸ºæœ‰é™é˜¶çš„ç§»åŠ¨å¹³å‡è¿‡ç¨‹å¯ä»¥è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªæ— é™é˜¶çš„è‡ªå›å½’è¿‡ç¨‹ã€‚ç›¸åï¼Œç”±äºå…·æœ‰è¿™ç§è¡Œä¸ºçš„ç§»åŠ¨å¹³å‡è¿‡ç¨‹æ˜¯å¯é€†çš„ï¼Œå…¶é€†è¿‡ç¨‹ä¹Ÿå¿…é¡»æˆç«‹ï¼›å³æœ‰é™é˜¶çš„è‡ªå›å½’è¿‡ç¨‹å¯ä»¥è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªæ— é™é˜¶çš„ç§»åŠ¨å¹³å‡è¿‡ç¨‹ã€‚å› æ­¤ï¼Œå¯¹äºå¯é€†çš„ç§»åŠ¨å¹³å‡è¿‡ç¨‹ï¼Œåè‡ªç›¸å…³å‡½æ•°å°†è¡°å‡åˆ°é›¶ï¼Œè€Œå¯¹äºå¹³ç¨³çš„è‡ªå›å½’è¿‡ç¨‹ï¼Œè‡ªç›¸å…³å‡½æ•°ä¹Ÿå°†è¡°å‡åˆ°é›¶ã€‚å› ä¸ºå¯é€†æ€§æ˜¯ARMAè¿‡ç¨‹çš„è¦æ±‚ï¼Œå®ƒå…è®¸æˆ‘ä»¬å°†æ–¹ç¨‹é‡å†™ä¸ºä¸€èˆ¬çº¿æ€§å½¢å¼ä¸‹çš„æ— é™é˜¶MAè¿‡ç¨‹ï¼š
- en: yÂ t = Î¦Â âˆ’1(B)Ï´(B) ÏµÂ t
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: yÂ t = Î¦Â âˆ’1(B)Ï´(B) ÏµÂ t
- en: 'It also allows us to do so as an infinite-order AR process:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè¿˜å…è®¸æˆ‘ä»¬å°†å®ƒä½œä¸ºä¸€ä¸ªæ— é™é˜¶çš„è‡ªå›å½’è¿‡ç¨‹ï¼š
- en: Ï´Â âˆ’1(B)Î¦(B) yÂ t = ÏµÂ t
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: Ï´Â âˆ’1(B)Î¦(B) yÂ t = ÏµÂ t
- en: 'Let us walk through an example in Python. First, using the same imports we
    did before in this chapter, let us generate an invertible and stationary ARMA(2,1)
    process dummy dataset that satisfies the following equation:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ª Python ä¸­çš„ä¾‹å­æ¥æ¼”ç¤ºã€‚é¦–å…ˆï¼Œä½¿ç”¨æœ¬ç« å‰é¢ç›¸åŒçš„å¯¼å…¥ï¼Œè®©æˆ‘ä»¬ç”Ÿæˆä¸€ä¸ªå¯é€†ä¸”å¹³ç¨³çš„ ARMA(2,1) è¿‡ç¨‹çš„è™šæ‹Ÿæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ»¡è¶³ä»¥ä¸‹æ–¹ç¨‹ï¼š
- en: (1 âˆ’ 1.28B + 0.682 BÂ 2) yÂ t = (1 âˆ’ 0.58B) ÏµÂ t
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: (1 âˆ’ 1.28B + 0.682 BÂ²) y_t = (1 âˆ’ 0.58B) Îµ_t
- en: '[PRE14]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let us confirm stationary and invertibility:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç¡®è®¤å¹³ç¨³æ€§å’Œå¯é€†æ€§ï¼š
- en: '[PRE15]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can use the quadratic formula to test, but we can trust the code to confirm:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨äºŒæ¬¡å…¬å¼æ¥æµ‹è¯•ï¼Œä½†æˆ‘ä»¬å¯ä»¥ç›¸ä¿¡ä»£ç æ¥ç¡®è®¤ï¼š
- en: '`AR(2) Roots: [``1.-0.81649658j 1.+0.81649658j]`'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '`AR(2) æ ¹ï¼š` `[1.-0.81649658j 1.+0.81649658j]`'
- en: '`AR(2) Stationarity:` `True`'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`AR(2) å¹³ç¨³æ€§ï¼š` `True`'
- en: '`MA(1) Roots: [``2.]`'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`MA(1) æ ¹ï¼š` `[2.]`'
- en: '`MA(1) Invertibility:` `True`'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`MA(1) å¯é€†æ€§ï¼š` `True`'
- en: 'Now that we have a stationary and invertible process, let us generate 200 samples
    from it:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¢ç„¶æˆ‘ä»¬å·²ç»æœ‰ä¸€ä¸ªå¹³ç¨³ä¸”å¯é€†çš„è¿‡ç¨‹ï¼Œè®©æˆ‘ä»¬ä»ä¸­ç”Ÿæˆ 200 ä¸ªæ ·æœ¬ï¼š
- en: '[PRE16]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Step 1 â€“ Visual inspection
  id: totrans-227
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬ 1 æ­¥ â€“ è§†è§‰æ£€æŸ¥
- en: 'Let us take a look at the plots we have been using to build intuition about
    the process that generated the data:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬ä¸€ç›´åœ¨ä½¿ç”¨çš„å›¾è¡¨ï¼Œä»¥æ„å»ºå…³äºç”Ÿæˆæ•°æ®çš„è¿‡ç¨‹çš„ç›´è§‰ï¼š
- en: '![Figure 11.11 â€“ ARMA(p,q) process sample data](img/B18945_11_011.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 11.11 â€“ ARMA(p,q) è¿‡ç¨‹æ ·æœ¬æ•°æ®](img/B18945_11_011.jpg)'
- en: Figure 11.11 â€“ ARMA(p,q) process sample data
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.11 â€“ ARMA(p,q) è¿‡ç¨‹æ ·æœ¬æ•°æ®
- en: We can see using the ACF that we have what appears to be an MA(1) component.
    Based on the PACF, it looks as if we could have either an AR(2) or an AR(4). The
    realization appears to be a process that satisfies stationarity.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡ ACF çœ‹å‡ºï¼Œä¼¼ä¹æœ‰ä¸€ä¸ª MA(1) çš„æˆåˆ†ã€‚æ ¹æ® PACFï¼Œçœ‹èµ·æ¥æˆ‘ä»¬å¯èƒ½æœ‰ä¸€ä¸ª AR(2) æˆ– AR(4)ã€‚å®ç°çœ‹èµ·æ¥æ˜¯ä¸€ä¸ªæ»¡è¶³å¹³ç¨³æ€§çš„è¿‡ç¨‹ã€‚
- en: Step 2 â€“ Select order of ARMA(p,q)
  id: totrans-232
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬ 2 æ­¥ â€“ é€‰æ‹© ARMA(p,q) çš„é˜¶æ•°
- en: 'Before we decide on an order for our ARMA model, let us use the Dickey-Fuller
    test to check if our data has any trend:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬å†³å®š ARMA æ¨¡å‹çš„é˜¶æ•°ä¹‹å‰ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ Dickey-Fuller æµ‹è¯•æ¥æ£€æŸ¥æˆ‘ä»¬çš„æ•°æ®æ˜¯å¦å­˜åœ¨è¶‹åŠ¿ï¼š
- en: '[PRE17]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can see the statistical significance that confirms we do not have a unit
    root in the lags provided with `maxlag` (remember, HÂ o : *the data has a unit
    root* and HÂ a : *the data does not have a unit root*). Therefore, we can use the
    ARMA model without any first-order differencing, which would require at least
    an ARIMA:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œè¿™è¯å®äº†æˆ‘ä»¬æä¾›çš„æ»åé¡¹ä¸­æ²¡æœ‰å•ä½æ ¹ï¼ˆè®°ä½ï¼ŒH_0ï¼š*æ•°æ®æœ‰ä¸€ä¸ªå•ä½æ ¹* å’Œ H_1ï¼š*æ•°æ®æ²¡æœ‰å•ä½æ ¹*ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨
    ARMA æ¨¡å‹è€Œä¸éœ€è¦ä»»ä½•ä¸€é˜¶å·®åˆ†ï¼Œè¿™è‡³å°‘éœ€è¦ä¸€ä¸ª ARIMAï¼š
- en: '`Dickey-Fuller p-value:` `6.090665062133195e-16`'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dickey-Fuller p å€¼ï¼š` `6.090665062133195e-16`'
- en: '`Dickey-Fuller test statistic: -``9.40370671340928`'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dickey-Fuller æµ‹è¯•ç»Ÿè®¡é‡ï¼š` `-9.40370671340928`'
- en: '`Dickey-Fuller critical value: -``2.876401960790147`'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dickey-Fuller ä¸´ç•Œå€¼ï¼š` `-2.876401960790147`'
- en: 'Now let us use `statmodels` `arma_order_select_ic` to see what AIC and BIC
    select for the ARMA(p,q) order. We know the maximum order for an MA(q) is one,
    but since we are not sure if this is an AR(2) or an AR(4), we can use `max_ar=4`:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ `statmodels` çš„ `arma_order_select_ic` æ¥æŸ¥çœ‹ AIC å’Œ BIC å¯¹ ARMA(p,q) é˜¶æ•°çš„é€‰æ‹©ã€‚æˆ‘ä»¬çŸ¥é“
    MA(q) çš„æœ€å¤§é˜¶æ•°æ˜¯ 1ï¼Œä½†ç”±äºæˆ‘ä»¬ä¸ç¡®å®šè¿™æ˜¯ AR(2) è¿˜æ˜¯ AR(4)ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `max_ar=4`ï¼š
- en: '[PRE18]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can see that AIC selected an ARMA(4,1) and BIC selected an ARMA(2,1):'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ° AIC é€‰æ‹©äº†ä¸€ä¸ª ARMA(4,1)ï¼Œè€Œ BIC é€‰æ‹©äº†ä¸€ä¸ª ARMA(2,1)ï¼š
- en: '`AIC Order Selection: (``4, 1)`'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`AIC é˜¶æ•°é€‰æ‹©ï¼š` `(4, 1)`'
- en: '`AIC Error:` `548.527`'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '`AIC é”™è¯¯ï¼š` `548.527`'
- en: '`BIC Order Selection: (``2, 1)`'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`BIC é˜¶æ•°é€‰æ‹©ï¼š` `(2, 1)`'
- en: '`BIC Error:` `565.019`'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '`BIC é”™è¯¯ï¼š` `565.019`'
- en: The ARMA(4,1) has a lower error, but we know from this and previous chapters
    in the book that models with lower error on training data may be more likely to
    have more variance and thus be more likely to overfit. However, let us use ARMA(4,1).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ARMA(4,1) å…·æœ‰è¾ƒä½çš„è¯¯å·®ï¼Œä½†æˆ‘ä»¬çŸ¥é“ä»è¿™æœ¬ä¹¦çš„æ­¤ç« èŠ‚å’Œå‰é¢çš„ç« èŠ‚ä¸­ï¼Œå…·æœ‰è¾ƒä½è®­ç»ƒæ•°æ®è¯¯å·®çš„æ¨¡å‹å¯èƒ½æ›´æœ‰å¯èƒ½å…·æœ‰æ›´å¤§çš„æ–¹å·®ï¼Œå› æ­¤æ›´æœ‰å¯èƒ½è¿‡æ‹Ÿåˆã€‚ä½†æ˜¯ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨
    ARMA(4,1)ã€‚
- en: Step 3 â€“ Building the AR(p) model
  id: totrans-247
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬ 3 æ­¥ â€“ æ„å»º AR(p) æ¨¡å‹
- en: 'Now let us build our ARMA(4,1) model. Note the 0 is for the integrated first-order
    difference for an ARIMA(p,d,q) model. Since we do not have a trend-based unit
    root, we do not need to difference to remove any trend. Thus, d=0:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ„å»ºæˆ‘ä»¬çš„ ARMA(4,1) æ¨¡å‹ã€‚æ³¨æ„ï¼Œ0 æ˜¯ ARIMA(p,d,q) æ¨¡å‹ä¸­ä¸€é˜¶å·®åˆ†çš„ç§¯åˆ†ã€‚ç”±äºæˆ‘ä»¬æ²¡æœ‰åŸºäºè¶‹åŠ¿çš„å•ä½æ ¹ï¼Œæˆ‘ä»¬ä¸éœ€è¦å·®åˆ†æ¥å»é™¤ä»»ä½•è¶‹åŠ¿ã€‚å› æ­¤ï¼Œd=0ï¼š
- en: '[PRE19]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here, we can see the model provides a reasonable fit based on the model metrics.
    However, there is one issue; our first three AR coefficients have no statistical
    significance (high p-values and confidence intervals containing zero). This is
    a big problem and confirms our model is overfitted. Our model includes terms it
    is not getting benefit from. Therefore, our model would most certainly fail to
    generalize well on unseen data and should be reconstructed:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹åŸºäºæ¨¡å‹æŒ‡æ ‡æä¾›äº†ä¸€ä¸ªåˆç†çš„æ‹Ÿåˆã€‚ç„¶è€Œï¼Œæœ‰ä¸€ä¸ªé—®é¢˜ï¼›æˆ‘ä»¬å‰ä¸‰ä¸ª AR ç³»æ•°æ²¡æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ï¼ˆé«˜ p å€¼å’ŒåŒ…å«é›¶çš„ç½®ä¿¡åŒºé—´ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªå¤§é—®é¢˜ï¼Œè¯å®äº†æˆ‘ä»¬çš„æ¨¡å‹è¿‡åº¦æ‹Ÿåˆã€‚æˆ‘ä»¬çš„æ¨¡å‹åŒ…å«äº†å®ƒæ²¡æœ‰ä»ä¸­è·å¾—ç›Šå¤„çš„é¡¹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šå¾ˆå¯èƒ½æ— æ³•å¾ˆå¥½åœ°æ³›åŒ–ï¼Œåº”è¯¥é‡å»ºï¼š
- en: '![Figure 11.12 â€“ ARIMA(4,0,1) model results](img/B18945_11_012.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 11.12 â€“ ARIMA(4,0,1) æ¨¡å‹ç»“æœ](img/B18945_11_012.jpg)'
- en: Figure 11.12 â€“ ARIMA(4,0,1) model results
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.12 â€“ ARIMA(4,0,1) æ¨¡å‹ç»“æœ
- en: 'Let us re-run this as an ARMA(2,1), which is the same as an ARIMA(2,0,1) since
    there is no differencing to be integrated. This is what we visually identified,
    and BIC selected the following code:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é‡æ–°è¿è¡Œè¿™ä¸ª ARMA(2,1)ï¼Œå®ƒä¸ ARIMA(2,0,1) ç›¸åŒï¼Œå› ä¸ºæ²¡æœ‰å·®åˆ†éœ€è¦ç§¯åˆ†ã€‚è¿™æ˜¯æˆ‘ä»¬é€šè¿‡è§†è§‰è¯†åˆ«çš„ï¼ŒBIC é€‰æ‹©ä»¥ä¸‹ä»£ç ï¼š
- en: '[PRE20]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We can see now a much better fit for our variables. All coefficients are significant,
    and the model metrics remain sufficient. The model we have identified corresponds
    to the following equation:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„å˜é‡æœ‰äº†æ›´å¥½çš„æ‹Ÿåˆã€‚æ‰€æœ‰ç³»æ•°éƒ½æ˜¯æ˜¾è‘—çš„ï¼Œæ¨¡å‹æŒ‡æ ‡ä»ç„¶è¶³å¤Ÿã€‚æˆ‘ä»¬è¯†åˆ«å‡ºçš„æ¨¡å‹å¯¹åº”ä»¥ä¸‹æ–¹ç¨‹ï¼š
- en: (1 âˆ’ 1.2765B + 0.6526 BÂ 2) yÂ t = (1 + 0.58B) ÏµÂ t
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: (1 âˆ’ 1.2765B + 0.6526 BÂ 2) yÂ t = (1 + 0.58B) ÏµÂ t
- en: 'We can compare that to our dummy process:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†è¿™äº›ä¸æˆ‘ä»¬çš„è™šæ‹Ÿè¿‡ç¨‹è¿›è¡Œæ¯”è¾ƒï¼š
- en: (1 âˆ’ 1.28B + 0.682 BÂ 2) yÂ t = (1 âˆ’ 0.58B) ÏµÂ t
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: (1 âˆ’ 1.28B + 0.682 BÂ 2) yÂ t = (1 âˆ’ 0.58B) ÏµÂ t
- en: '![Figure 11.13 â€“ ARIMA(2,0,1) model results](img/B18945_11_013.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 11.13 â€“ ARIMA(2,0,1) æ¨¡å‹ç»“æœ](img/B18945_11_013.jpg)'
- en: Figure 11.13 â€“ ARIMA(2,0,1) model results
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.13 â€“ ARIMA(2,0,1) æ¨¡å‹ç»“æœ
- en: Step 4 â€“ Test forecasting
  id: totrans-261
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬ 4 æ­¥ â€“ æµ‹è¯•é¢„æµ‹
- en: 'Now, let us cross-validate our model by training the model on data up through
    the last five points, then forecasting the last five points so that we can compare
    them to the actuals. Recall that our indexing starts at 0 so our dataset ends
    at index 199:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬é€šè¿‡åœ¨æœ€åäº”ä¸ªæ•°æ®ç‚¹ä¸Šè®­ç»ƒæ¨¡å‹æ¥äº¤å‰éªŒè¯æˆ‘ä»¬çš„æ¨¡å‹ï¼Œç„¶åé¢„æµ‹æœ€åäº”ä¸ªç‚¹ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥å°†å®ƒä»¬ä¸å®é™…å€¼è¿›è¡Œæ¯”è¾ƒã€‚è®°ä½ï¼Œæˆ‘ä»¬çš„ç´¢å¼•ä» 0 å¼€å§‹ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„æ•°æ®é›†åœ¨ç´¢å¼•
    199 ç»“æŸï¼š
- en: '[PRE21]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We can see our predicted values in the *mean* column in the following table:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨ä»¥ä¸‹è¡¨æ ¼çš„ *å‡å€¼* åˆ—ä¸­çœ‹åˆ°æˆ‘ä»¬çš„é¢„æµ‹å€¼ï¼š
- en: '| **y** | **mean** | **mean_se** | **mean_ci_lower** | **mean_ci_upper** |
    **actuals** |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| **y** | **mean** | **mean_se** | **mean_ci_lower** | **mean_ci_upper** |
    **actuals** |'
- en: '| 195 | -0.01911 | 0.932933 | -1.84762 | 1.80940631 | 0.559875 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 195 | -0.01911 | 0.932933 | -1.84762 | 1.80940631 | 0.559875 |'
- en: '| 196 | 0.58446 | 0.932933 | -1.24406 | 2.412975242 | 0.778127 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 196 | 0.58446 | 0.932933 | -1.24406 | 2.412975242 | 0.778127 |'
- en: '| 197 | 0.479364 | 0.932933 | -1.34915 | 2.307879057 | 1.695218 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 197 | 0.479364 | 0.932933 | -1.34915 | 2.307879057 | 1.695218 |'
- en: '| 198 | 0.914009 | 0.932933 | -0.91451 | 2.74252465 | 2.041826 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 198 | 0.914009 | 0.932933 | -0.91451 | 2.74252465 | 2.041826 |'
- en: '| 199 | 0.80913 | 0.932933 | -1.01939 | 2.637645206 | 0.578695 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 199 | 0.80913 | 0.932933 | -1.01939 | 2.637645206 | 0.578695 |'
- en: Figure 11.14 â€“ AR(4) model outputs versus actuals
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.14 â€“ AR(4) æ¨¡å‹è¾“å‡ºä¸å®é™…å€¼å¯¹æ¯”
- en: 'Letâ€™s print out our modelâ€™s **Average Squared** **Error** (**ASE**):'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ‰“å°å‡ºæˆ‘ä»¬æ¨¡å‹çš„ **å¹³å‡å¹³æ–¹** **è¯¯å·®** (**ASE**)ï¼š
- en: '[PRE22]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here we see the ASE:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæˆ‘ä»¬çœ‹åˆ° ASEï¼š
- en: '`Average Squared Error:` `0.6352208223437921`'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '`å¹³å‡å¹³æ–¹è¯¯å·®:` `0.6352208223437921`'
- en: 'Our test forecast plot is shown in *Figure 11**.15*. Note that our estimate
    appears conservative. Using ARMA(4,1) may have produced a closer, but less generalizable
    fit. One method for improving forecasting would be to build the model using only
    recent points (relative to subject matter knowledge of the process). Including
    a larger set of data will produce a fit that generalizes more to the overall process
    rather than to a possibly more relevant timeframe:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æµ‹è¯•é¢„æµ‹å›¾æ˜¾ç¤ºåœ¨ *å›¾ 11**.15* ä¸­ã€‚æ³¨æ„ï¼Œæˆ‘ä»¬çš„ä¼°è®¡çœ‹èµ·æ¥æ¯”è¾ƒä¿å®ˆã€‚ä½¿ç”¨ ARMA(4,1) å¯èƒ½ä¼šäº§ç”Ÿæ›´æ¥è¿‘çš„æ‹Ÿåˆï¼Œä½†æ³›åŒ–æ€§è¾ƒå·®ã€‚æ”¹è¿›é¢„æµ‹çš„ä¸€ä¸ªæ–¹æ³•æ˜¯é€šè¿‡ä»…ä½¿ç”¨æœ€è¿‘çš„æ•°æ®ç‚¹ï¼ˆç›¸å¯¹äºè¿‡ç¨‹çš„ä¸»é¢˜çŸ¥è¯†ï¼‰æ¥æ„å»ºæ¨¡å‹ã€‚åŒ…æ‹¬æ›´å¤§çš„æ•°æ®é›†å°†äº§ç”Ÿä¸€ä¸ªæ›´é€‚åˆæ•´ä½“è¿‡ç¨‹çš„æ‹Ÿåˆï¼Œè€Œä¸æ˜¯å¯èƒ½æ›´ç›¸å…³çš„æ—¶æ®µï¼š
- en: '![Figure 11.15 â€“ ARMA(2,1) test forecast](img/B18945_11_015.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 11.15 â€“ ARMA(2,1) æµ‹è¯•é¢„æµ‹](img/B18945_11_015.jpg)'
- en: Figure 11.15 â€“ ARMA(2,1) test forecast
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.15 â€“ ARMA(2,1) æµ‹è¯•é¢„æµ‹
- en: Step 5 â€“ Building a forecast
  id: totrans-279
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬ 5 æ­¥ â€“ æ„å»ºé¢„æµ‹
- en: 'Now, let us forecast five ahead:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬é¢„æµ‹äº”ä¸ªç‚¹ï¼š
- en: '[PRE23]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![Figure 11.16 â€“ ARMA(2,1) forecast horizon = 5](img/B18945_11_016.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 11.16 â€“ ARMA(2,1) é¢„æµ‹èŒƒå›´ = 5](img/B18945_11_016.jpg)'
- en: Figure 11.16 â€“ ARMA(2,1) forecast horizon = 5
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11.16 â€“ ARMA(2,1) é¢„æµ‹èŒƒå›´ = 5
- en: On a final note, regarding ARMA models, *we always assume process stationarity*.
    If stationarity cannot be assumed, neither autoregressive nor moving average models
    can be used. In the next section of this chapter, we will discuss integrating
    into ARMA models first-order differencing as a method for conditionally stationarizing
    a process to overcome limitations of non-stationarity.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åå…³äºARMAæ¨¡å‹çš„ä¸€ç‚¹ï¼Œæˆ‘ä»¬**æ€»æ˜¯å‡è®¾è¿‡ç¨‹å¹³ç¨³æ€§**ã€‚å¦‚æœæ— æ³•å‡è®¾å¹³ç¨³æ€§ï¼Œåˆ™æ—¢ä¸èƒ½ä½¿ç”¨è‡ªå›å½’æ¨¡å‹ä¹Ÿä¸èƒ½ä½¿ç”¨ç§»åŠ¨å¹³å‡æ¨¡å‹ã€‚åœ¨æœ¬ç« çš„ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå°†ä¸€é˜¶å·®åˆ†æ•´åˆåˆ°ARMAæ¨¡å‹ä¸­ï¼Œä½œä¸ºæ¡ä»¶å¹³ç¨³åŒ–è¿‡ç¨‹ä»¥å…‹æœéå¹³ç¨³æ€§å±€é™æ€§çš„æ–¹æ³•ã€‚
- en: Models for non-stationary time series
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: éå¹³ç¨³æ—¶é—´åºåˆ—çš„æ¨¡å‹
- en: 'In the previous section, we discussed ARMA models for stationary time series
    data. In this section, we will look at non-stationary time series data and extend
    our model to work with non-stationary data. Let us start by taking a look at some
    sample data (shown in *Figure 11**.17*). There are two series: US GDP (left) and
    airline passenger volume (right).'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†é€‚ç”¨äºå¹³ç¨³æ—¶é—´åºåˆ—æ•°æ®çš„ARMAæ¨¡å‹ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨éå¹³ç¨³æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¹¶å°†æˆ‘ä»¬çš„æ¨¡å‹æ‰©å±•åˆ°å¯ä»¥å¤„ç†éå¹³ç¨³æ•°æ®ã€‚è®©æˆ‘ä»¬é¦–å…ˆæŸ¥çœ‹ä¸€äº›æ ·æœ¬æ•°æ®ï¼ˆå¦‚å›¾*11.17*æ‰€ç¤ºï¼‰ã€‚æœ‰ä¸¤ä¸ªåºåˆ—ï¼šç¾å›½GDPï¼ˆå·¦ï¼‰å’Œèˆªç©ºæ—…å®¢é‡ï¼ˆå³ï¼‰ã€‚
- en: '![Figure 11.17 â€“ US GDP (left) and airline passenger (right) time series](img/B18945_11_017.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.17 â€“ ç¾å›½GDPï¼ˆå·¦ï¼‰å’Œèˆªç©ºæ—…å®¢ï¼ˆå³ï¼‰æ—¶é—´åºåˆ—](img/B18945_11_017.jpg)'
- en: Figure 11.17 â€“ US GDP (left) and airline passenger (right) time series
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.17 â€“ ç¾å›½GDPï¼ˆå·¦ï¼‰å’Œèˆªç©ºæ—…å®¢ï¼ˆå³ï¼‰æ—¶é—´åºåˆ—
- en: The US GDP series appears to exhibit an upward trend with some variations in
    the series. The airline passenger volume series also exhibits an upward trend,
    but there also appears to be a repeated pattern in the series. The repeated pattern
    in the airline series is called **seasonality**. Both series are non-stationary
    because of the apparent trend. Additionally, the airline passenger volume series
    appears to exhibit non-constant variance. We will model the GDP series with ARIMA,
    and we will model the seasonal ARIMA. Letâ€™s take a look at these models.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: ç¾å›½GDPåºåˆ—ä¼¼ä¹è¡¨ç°å‡ºä¸Šå‡è¶‹åŠ¿ï¼Œåºåˆ—ä¸­ä¹Ÿæœ‰ä¸€äº›å˜åŒ–ã€‚èˆªç©ºæ—…å®¢é‡åºåˆ—ä¹Ÿè¡¨ç°å‡ºä¸Šå‡è¶‹åŠ¿ï¼Œä½†åºåˆ—ä¸­ä¼¼ä¹ä¹Ÿå­˜åœ¨é‡å¤çš„æ¨¡å¼ã€‚èˆªç©ºåºåˆ—ä¸­çš„é‡å¤æ¨¡å¼ç§°ä¸º**å­£èŠ‚æ€§**ã€‚ç”±äºæ˜æ˜¾çš„è¶‹åŠ¿ï¼Œè¿™ä¸¤ä¸ªåºåˆ—éƒ½æ˜¯éå¹³ç¨³çš„ã€‚æ­¤å¤–ï¼Œèˆªç©ºæ—…å®¢é‡åºåˆ—ä¼¼ä¹è¡¨ç°å‡ºéæ’å®šçš„æ–¹å·®ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ARIMAæ¨¡å‹æ¥æ¨¡æ‹ŸGDPåºåˆ—ï¼Œå¹¶å°†æ¨¡æ‹Ÿå­£èŠ‚æ€§ARIMAã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹è¿™äº›æ¨¡å‹ã€‚
- en: ARIMA models
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ARIMAæ¨¡å‹
- en: '**ARIMA** is an acronym for **AutoRegressive Integrated Moving Average**. This
    model is a generalization of the ARMA model that can be applied to non-stationary
    time series data. The new part added to this model is â€œintegrated,â€ which is a
    **differencing** operation applied to the time series to **stationarize** (to
    make stationary) the time series. After the time series is stationarized, we can
    fit an ARMA model to the differenced data. Letâ€™s take a look at the mathematics
    of this model. We will start with understanding how differencing works, and then
    put the whole model ARIMA model together.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '**ARIMA**æ˜¯**è‡ªå›å½’ç§¯åˆ†ç§»åŠ¨å¹³å‡**çš„ç¼©å†™ã€‚è¿™ä¸ªæ¨¡å‹æ˜¯ARMAæ¨¡å‹çš„ä¸€ç§æ¨å¹¿ï¼Œå¯ä»¥åº”ç”¨äºéå¹³ç¨³æ—¶é—´åºåˆ—æ•°æ®ã€‚è¿™ä¸ªæ¨¡å‹æ–°å¢çš„éƒ¨åˆ†æ˜¯â€œç§¯åˆ†â€ï¼Œå®ƒæ˜¯å¯¹æ—¶é—´åºåˆ—è¿›è¡Œ**å·®åˆ†**æ“ä½œä»¥**å¹³ç¨³åŒ–**ï¼ˆä½¿æ—¶é—´åºåˆ—å¹³ç¨³ï¼‰ã€‚æ—¶é—´åºåˆ—å¹³ç¨³åŒ–åï¼Œæˆ‘ä»¬å¯ä»¥å¯¹å·®åˆ†æ•°æ®è¿›è¡ŒARMAæ¨¡å‹çš„æ‹Ÿåˆã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹è¿™ä¸ªæ¨¡å‹çš„æ•°å­¦åŸç†ã€‚æˆ‘ä»¬å°†ä»ç†è§£å·®åˆ†æ˜¯å¦‚ä½•å·¥ä½œçš„å¼€å§‹ï¼Œç„¶åæ„å»ºæ•´ä¸ªARIMAæ¨¡å‹ã€‚'
- en: Differencing
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å·®åˆ†
- en: 'Differencing data is computing the difference between consecutive data points.
    The resulting data from differencing represents the *change* between each data
    point. We can write the difference as such:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: å·®åˆ†æ•°æ®æ˜¯è®¡ç®—è¿ç»­æ•°æ®ç‚¹ä¹‹é—´çš„å·®å¼‚ã€‚å·®åˆ†åçš„æ•°æ®ä»£è¡¨æ¯ä¸ªæ•°æ®ç‚¹ä¹‹é—´çš„**å˜åŒ–**ã€‚æˆ‘ä»¬å¯ä»¥å°†å·®åˆ†å†™æˆå¦‚ä¸‹å½¢å¼ï¼š
- en: y â€²Â t = yÂ t âˆ’ yÂ tâˆ’1
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: yâ€²t = yt âˆ’ ytâˆ’1
- en: 'This equation is the first-order difference, meaning it is the first difference
    between the data points. It may be necessary to make additional differences between
    the data points to stationarize the series. The second difference represents the
    *change of changes* between the data points. The second-order difference can be
    written thusly:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ–¹ç¨‹æ˜¯ä¸€é˜¶å·®åˆ†ï¼Œæ„å‘³ç€å®ƒæ˜¯æ•°æ®ç‚¹ä¹‹é—´çš„ç¬¬ä¸€ä¸ªå·®åˆ†ã€‚å¯èƒ½éœ€è¦åœ¨å¯¹æ•°æ®ç‚¹è¿›è¡Œé¢å¤–çš„å·®åˆ†ä»¥ä½¿åºåˆ—å¹³ç¨³åŒ–ã€‚äºŒé˜¶å·®åˆ†ä»£è¡¨æ•°æ®ç‚¹ä¹‹é—´çš„**å˜åŒ–çš„æ”¹å˜**ã€‚äºŒé˜¶å·®åˆ†å¯ä»¥å†™æˆå¦‚ä¸‹å½¢å¼ï¼š
- en: y â€³Â t = yÂ â€²Â Â t âˆ’ yÂ â€²Â Â tâˆ’1 = (yÂ t âˆ’ yÂ tâˆ’1) âˆ’ (yÂ tâˆ’1 âˆ’ yÂ tâˆ’2)
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: yâ€³t = yâ€²t âˆ’ yâ€²tâˆ’1 = (yt âˆ’ ytâˆ’1) âˆ’ (ytâˆ’1 âˆ’ ytâˆ’2)
- en: The â€œorderâ€ is simply the number of times a difference operation is applied.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: â€œé˜¶æ•°â€ç®€å•åœ°æŒ‡å·®åˆ†æ“ä½œåº”ç”¨çš„æ¬¡æ•°ã€‚
- en: The ARIMA model
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ARIMAæ¨¡å‹
- en: 'As mentioned earlier, the ARIMA model is ARMA with the addition of differencing
    to make the time series stationary (stationarize the time series). Then we can
    express an ARIMA model mathematically as follows, where yâ€²Â t is the differenced
    series, differenced d times until it is stationary:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰æ‰€è¿°ï¼ŒARIMAæ¨¡å‹æ˜¯ARMAæ¨¡å‹ï¼Œé€šè¿‡æ·»åŠ å·®åˆ†ä½¿æ—¶é—´åºåˆ—å¹³ç¨³ï¼ˆä½¿æ—¶é—´åºåˆ—å¹³ç¨³åŒ–ï¼‰ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥å°†ARIMAæ¨¡å‹æ•°å­¦ä¸Šè¡¨ç¤ºå¦‚ä¸‹ï¼Œå…¶ä¸­yâ€²Â tæ˜¯å·®åˆ†åºåˆ—ï¼Œå·®åˆ†dæ¬¡ç›´åˆ°å®ƒå¹³ç¨³ï¼š
- en: yâ€²Â t = c + Ï•Â 1 yâ€²Â tâˆ’1 + â€¦ + Ï•Â p yÂ â€²Â Â tâˆ’p + ÏµÂ t + Î¸Â 1 ÏµÂ tâˆ’1 + â€¦ + Ï•Â q ÏµÂ tâˆ’q
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: yâ€²Â t = c + Ï•Â 1 yâ€²Â tâˆ’1 + â€¦ + Ï•Â p yÂ â€²Â Â tâˆ’p + ÏµÂ t + Î¸Â 1 ÏµÂ tâˆ’1 + â€¦ + Ï•Â q ÏµÂ tâˆ’q
- en: 'The ARIMA model has three orders, which are denoted ARIMA(p,d,q):'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: ARIMAæ¨¡å‹æœ‰ä¸‰ä¸ªé˜¶æ•°ï¼Œåˆ†åˆ«è¡¨ç¤ºä¸ºARIMA(p,d,q)ï¼š
- en: p â€“ the autoregressive order
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: p â€“ è‡ªå›å½’é˜¶æ•°
- en: d â€“ the differencing order
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: d â€“ å·®åˆ†é˜¶æ•°
- en: q â€“ the moving average order
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: q â€“ ç§»åŠ¨å¹³å‡é˜¶æ•°
- en: 'With more complicated models such as ARIMA, we will tend to describe them with
    backshift notation since it is easier to express these models with backshift notation.
    An ARIMA model will take the following form using backshift notation:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåƒARIMAè¿™æ ·çš„æ›´å¤æ‚æ¨¡å‹ï¼Œæˆ‘ä»¬å€¾å‘äºç”¨åç§»ç¬¦å·æ¥æè¿°å®ƒä»¬ï¼Œå› ä¸ºç”¨åç§»ç¬¦å·è¡¨è¾¾è¿™äº›æ¨¡å‹æ›´å®¹æ˜“ã€‚ä½¿ç”¨åç§»ç¬¦å·ï¼ŒARIMAæ¨¡å‹å°†é‡‡å–ä»¥ä¸‹å½¢å¼ï¼š
- en: (1 âˆ’ Ï•Â 1 B âˆ’ â€¦ âˆ’ Ï•Â p BÂ p) (1 âˆ’ B)Â d yÂ t = c + (1 + Î¸Â 1 B + â€¦ + Î¸Â q BÂ q) ğÂ t
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: (1 âˆ’ Ï•Â 1 B âˆ’ â€¦ âˆ’ Ï•Â p BÂ p) (1 âˆ’ B)Â d yÂ t = c + (1 + Î¸Â 1 B + â€¦ + Î¸Â q BÂ q) ğÂ t
- en: â†‘Â Â Â Â Â Â  Â Â Â â†‘Â Â  Â Â Â  Â  â†‘
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: â†‘Â Â Â Â Â Â  Â Â Â â†‘Â Â  Â Â Â  Â  â†‘
- en: AR(p) d differences Â Â Â Â Â Â Â Â Â Â Â Â Â Â MA(q)
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: AR(p) då·®åˆ†Â Â Â Â Â Â Â Â Â Â Â Â Â MA(q)
- en: 'Notice the term for the differences in the equation: (1 âˆ’ B)Â d. In the previous
    section, we discussed roots as related to stationary models. In that context,
    the roots were always outside of the unit circle. With an ARIMA model, we add
    unit roots to the model. To understand the impact of a unit root, letâ€™s simulate
    an AR(1) model and see what happens as the root of the model is moved toward one.
    These simulations are shown in *Figure 11**.18*.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„æ–¹ç¨‹ä¸­å·®å¼‚é¡¹çš„è¡¨ç¤ºï¼š(1 âˆ’ B)Â dã€‚åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä¸å¹³ç¨³æ¨¡å‹ç›¸å…³çš„æ ¹ã€‚åœ¨é‚£ä¸ªèƒŒæ™¯ä¸‹ï¼Œæ ¹å§‹ç»ˆä½äºå•ä½åœ†ä¹‹å¤–ã€‚åœ¨ARIMAæ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬å‘æ¨¡å‹ä¸­æ·»åŠ å•ä½æ ¹ã€‚ä¸ºäº†ç†è§£å•ä½æ ¹çš„å½±å“ï¼Œè®©æˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸ªAR(1)æ¨¡å‹ï¼Œå¹¶è§‚å¯Ÿå½“æ¨¡å‹æ ¹å€¼æ¥è¿‘1æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚è¿™äº›æ¨¡æ‹Ÿæ˜¾ç¤ºåœ¨å›¾11.18ä¸­ã€‚
- en: '![Figure 11.18 â€“ AR(1) simulations with root approaching 1](img/B18945_11_018.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.18 â€“ æ ¹å€¼æ¥è¿‘1çš„AR(1)æ¨¡æ‹Ÿ](img/B18945_11_018.jpg)'
- en: Figure 11.18 â€“ AR(1) simulations with root approaching 1
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.18 â€“ æ ¹å€¼æ¥è¿‘1çš„AR(1)æ¨¡æ‹Ÿ
- en: We can make two observations from the simulations shown in *Figure 11**.18*.
    The first observation is that the time series appear to exhibit more wandering
    behavior as the root increases toward one. For instance, the middle-time series
    shows more wandering from the mean than the top-time series. The bottom time series
    (with a root of one), does not appear to regress toward a mean such as the other
    two simulations. The second observation is about the autocorrelations. As the
    root of the AR(1) approaches 1, the autocorrelations get stronger and decrease
    slower over the lags. These two observations are characteristic of a series with
    a root near or at one. Additionally, the presence of unit roots will dominate
    the time series behavior, making it easy to recognize from the autocorrelation
    plot.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å›¾11.18æ‰€ç¤ºçš„æ¨¡æ‹Ÿä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºä¸¤ä¸ªè§‚å¯Ÿç»“æœã€‚ç¬¬ä¸€ä¸ªè§‚å¯Ÿç»“æœæ˜¯ï¼Œéšç€æ ¹å€¼é€æ¸æ¥è¿‘1ï¼Œæ—¶é—´åºåˆ—ä¼¼ä¹è¡¨ç°å‡ºæ›´å¤šçš„æ¸¸èµ°è¡Œä¸ºã€‚ä¾‹å¦‚ï¼Œä¸­é—´æ—¶é—´åºåˆ—ç›¸å¯¹äºé¡¶éƒ¨æ—¶é—´åºåˆ—ï¼Œä»å¹³å‡å€¼å‡ºå‘çš„æ¸¸èµ°è¡Œä¸ºæ›´å¤šã€‚åº•éƒ¨æ—¶é—´åºåˆ—ï¼ˆæ ¹å€¼ä¸º1ï¼‰ä¼¼ä¹ä¸åƒå…¶ä»–ä¸¤ä¸ªæ¨¡æ‹Ÿé‚£æ ·å›å½’åˆ°å¹³å‡å€¼ã€‚ç¬¬äºŒä¸ªè§‚å¯Ÿç»“æœæ˜¯å…³äºè‡ªç›¸å…³æ€§çš„ã€‚éšç€AR(1)çš„æ ¹å€¼æ¥è¿‘1ï¼Œè‡ªç›¸å…³æ€§å˜å¾—æ›´å¼ºï¼Œå¹¶ä¸”éšç€æ»åæ—¶é—´çš„å¢åŠ è€Œå‡æ…¢ã€‚è¿™ä¸¤ä¸ªè§‚å¯Ÿç»“æœæ˜¯æ ¹å€¼æ¥è¿‘æˆ–ç­‰äº1çš„åºåˆ—çš„ç‰¹å¾ã€‚æ­¤å¤–ï¼Œå•ä½æ ¹çš„å­˜åœ¨å°†ä¸»å¯¼æ—¶é—´åºåˆ—çš„è¡Œä¸ºï¼Œä½¿å¾—ä»è‡ªç›¸å…³å›¾ä¸Šå®¹æ˜“è¯†åˆ«ã€‚
- en: Fitting an ARIMA model
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: é€‚é…ARIMAæ¨¡å‹
- en: 'There are two steps to fit an ARIMA model: (1) stationarize the series from
    differencing to determine the difference order and (2) fit an ARMA model to the
    resulting series. In the previous section, we discussed how to fit an ARMA model
    so in this section, we will focus on the first step.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: é€‚é…ARIMAæ¨¡å‹æœ‰ä¸¤ä¸ªæ­¥éª¤ï¼š(1)é€šè¿‡å·®åˆ†ä½¿åºåˆ—å¹³ç¨³ä»¥ç¡®å®šå·®åˆ†é˜¶æ•°ï¼Œ(2)å°†ARMAæ¨¡å‹æ‹Ÿåˆåˆ°å¾—åˆ°çš„åºåˆ—ã€‚åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•æ‹ŸåˆARMAæ¨¡å‹ï¼Œå› æ­¤åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨ç¬¬ä¸€æ­¥ã€‚
- en: At the beginning of this section, we showed a time series of US GDP values.
    We will use that time series as a case study for fitting an ARIMA model. First,
    letâ€™s take a look at the series and its autocorrelations again. The series and
    autocorrelations are shown in *Figure 11**.19*.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚çš„å¼€å§‹ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªç¾å›½GDPçš„æ—¶é—´åºåˆ—ã€‚æˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ªæ—¶é—´åºåˆ—ä½œä¸ºæ‹ŸåˆARIMAæ¨¡å‹çš„æ¡ˆä¾‹ç ”ç©¶ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬å†æ¬¡æŸ¥çœ‹è¯¥åºåˆ—åŠå…¶è‡ªç›¸å…³æ€§ã€‚åºåˆ—å’Œè‡ªç›¸å…³æ€§æ˜¾ç¤ºåœ¨å›¾11.19ä¸­ã€‚
- en: '![Figure 11.19 â€“ US GDP time series and autocorrelations](img/B18945_11_019.jpg)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.19 â€“ ç¾å›½GDPæ—¶é—´åºåˆ—å’Œè‡ªç›¸å…³æ€§](img/B18945_11_019.jpg)'
- en: Figure 11.19 â€“ US GDP time series and autocorrelations
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.19 â€“ ç¾å›½GDPæ—¶é—´åºåˆ—å’Œè‡ªç›¸å…³å›¾
- en: 'From the plots shown in *Figure 11**.19*, it appears that the time series of
    US GPD data is non-stationary time series. The time series exhibits wandering
    behavior, and the autocorrelations are strong and decrease slowly. As we discussed,
    this is characteristic behavior of unit roots. For secondary evidence, we can
    use the Dickey-Fuller test for unit root. The null hypothesis of the Dickey-Fuller
    test is that a unit root is present in the time series. The following code shows
    how to use the Dickey-Fuller test from `pmdarima`. The test returns a p-value
    of 0.74 indicating we cannot reject the null hypothesis, meaning that the time
    series should be differenced:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å›¾11**.19**æ‰€ç¤ºçš„å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œç¾å›½GDPæ•°æ®çš„æ—¶é—´åºåˆ—æ˜¯éå¹³ç¨³æ—¶é—´åºåˆ—ã€‚æ—¶é—´åºåˆ—è¡¨ç°å‡ºæ¸¸èµ°è¡Œä¸ºï¼Œè‡ªç›¸å…³æ€§å¼ºä¸”ç¼“æ…¢ä¸‹é™ã€‚æ­£å¦‚æˆ‘ä»¬è®¨è®ºçš„é‚£æ ·ï¼Œè¿™æ˜¯å•ä½æ ¹çš„ç‰¹å¾è¡Œä¸ºã€‚ä½œä¸ºæ¬¡è¦è¯æ®ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨Dickey-Fulleræµ‹è¯•æ¥æ£€éªŒå•ä½æ ¹ã€‚Dickey-Fulleræµ‹è¯•çš„é›¶å‡è®¾æ˜¯æ—¶é—´åºåˆ—ä¸­å­˜åœ¨å•ä½æ ¹ã€‚ä»¥ä¸‹ä»£ç æ˜¾ç¤ºäº†å¦‚ä½•ä½¿ç”¨`pmdarima`ä¸­çš„Dickey-Fulleræµ‹è¯•ã€‚æµ‹è¯•è¿”å›çš„på€¼ä¸º0.74ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬ä¸èƒ½æ‹’ç»é›¶å‡è®¾ï¼Œè¿™æ„å‘³ç€æ—¶é—´åºåˆ—åº”è¯¥è¿›è¡Œå·®åˆ†ï¼š
- en: '[PRE24]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We can take the first difference of time series using the `diff` function from
    `numpy`:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`numpy`ä¸­çš„`diff`å‡½æ•°å¯¹æ—¶é—´åºåˆ—è¿›è¡Œç¬¬ä¸€æ¬¡å·®åˆ†ï¼š
- en: '[PRE25]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Taking the first difference, we arrive at a new time series as shown in *Figure
    11**.20*:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: è¿›è¡Œç¬¬ä¸€æ¬¡å·®åˆ†åï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªæ–°çš„æ—¶é—´åºåˆ—ï¼Œå¦‚å›¾11**.20**æ‰€ç¤ºï¼š
- en: '![Figure 11.20 â€“ The first difference of US GDP time series](img/B18945_11_020.jpg)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.20 â€“ ç¾å›½GDPæ—¶é—´åºåˆ—çš„ç¬¬ä¸€å·®åˆ†](img/B18945_11_020.jpg)'
- en: Figure 11.20 â€“ The first difference of US GDP time series
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.20 â€“ ç¾å›½GDPæ—¶é—´åºåˆ—çš„ç¬¬ä¸€å·®åˆ†
- en: 'The first difference of the US GDP time series shown in *Figure 11**.20* appears
    to be stationary. In fact, it appears to be consistent with an AR(2) model. We
    double-check whether we need to take an additional difference using the Dickey-Fuller
    test on the first differenced data:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: ç¾å›½GDPæ—¶é—´åºåˆ—å›¾11**.20**ä¸­æ˜¾ç¤ºçš„ç¬¬ä¸€ä¸ªå·®å¼‚ä¼¼ä¹å…·æœ‰å¹³ç¨³æ€§ã€‚å®é™…ä¸Šï¼Œå®ƒä¼¼ä¹ä¸AR(2)æ¨¡å‹ä¸€è‡´ã€‚æˆ‘ä»¬é€šè¿‡åœ¨ç¬¬ä¸€å·®åˆ†æ•°æ®ä¸Šä½¿ç”¨Dickey-Fulleræµ‹è¯•æ¥åŒé‡æ£€æŸ¥æ˜¯å¦éœ€è¦é¢å¤–çš„å·®åˆ†ï¼š
- en: '[PRE26]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The Dickey-Fuller test returns a p-value of 0.01 for the first differenced data,
    which means we can reject the null hypothesis and we can stop differencing the
    data. That means that our ARIMA model for this data will have a difference order
    of 1 (d = 1).
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: Dickey-Fulleræµ‹è¯•å¯¹ç¬¬ä¸€å·®åˆ†æ•°æ®è¿”å›çš„på€¼ä¸º0.01ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥æ‹’ç»é›¶å‡è®¾ï¼Œæˆ‘ä»¬å¯ä»¥åœæ­¢å¯¹æ•°æ®è¿›è¡Œå·®åˆ†ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬çš„ARIMAæ¨¡å‹å¯¹äºè¿™äº›æ•°æ®å°†æœ‰ä¸€ä¸ªå·®åˆ†é˜¶æ•°ä¸º1ï¼ˆd
    = 1ï¼‰ã€‚
- en: 'After finding the difference order, we can fit an ARMA model to the differenced
    data. Since we have already discussed fitting ARMA models, we will use an automated
    fitting method provided by `pmdarima`. `pm.auto_arima` is a function for automatically
    fitting an ARIMA model to data, however, in this case, we will use it to fit the
    ARMA portion from the differenced series. The output of `pm.auto_arima` for the
    first difference data is shown in the following code block:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‰¾åˆ°å·®åˆ†é˜¶æ•°åï¼Œæˆ‘ä»¬å¯ä»¥å°†ARMAæ¨¡å‹æ‹Ÿåˆåˆ°å·®åˆ†æ•°æ®ä¸Šã€‚ç”±äºæˆ‘ä»¬å·²ç»è®¨è®ºäº†ARMAæ¨¡å‹çš„æ‹Ÿåˆï¼Œæˆ‘ä»¬å°†ä½¿ç”¨`pmdarima`æä¾›çš„è‡ªåŠ¨æ‹Ÿåˆæ–¹æ³•ã€‚`pm.auto_arima`æ˜¯ä¸€ä¸ªç”¨äºè‡ªåŠ¨å°†ARIMAæ¨¡å‹æ‹Ÿåˆåˆ°æ•°æ®çš„å‡½æ•°ï¼Œç„¶è€Œï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å®ƒæ¥æ‹Ÿåˆå·®åˆ†åºåˆ—çš„ARMAéƒ¨åˆ†ã€‚ä»¥ä¸‹ä»£ç å—æ˜¾ç¤ºäº†`pm.auto_arima`å¯¹ç¬¬ä¸€å·®åˆ†æ•°æ®çš„è¾“å‡ºï¼š
- en: '[PRE27]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Since the ARMA fit for the differenced data is ARMA(2,0), the ARIMA orders for
    the original time series would be ARIMA(2,1,0). Next, we will look at forecasting
    from an ARIMA model.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå·®åˆ†æ•°æ®çš„ARMAæ‹Ÿåˆæ˜¯ARMA(2,0)ï¼ŒåŸå§‹æ—¶é—´åºåˆ—çš„ARIMAé˜¶æ•°å°†æ˜¯ARIMA(2,1,0)ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹ä»ARIMAæ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚
- en: Forecasting with ARIMA
  id: totrans-331
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ARIMAè¿›è¡Œé¢„æµ‹
- en: 'Once we have a fit model, we can forecast with that model. As mentioned in
    previous chapters, when making predictions we should create a train-test split,
    so we have data to compare with the predictions. The model should only fit the
    training data to avoid data leakage. We can use the `train_test_split` function
    from `pmdarima` to split the data. Then we proceed with the usual steps: split,
    train, and predict. The code for this is shown in the following code block:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬æœ‰ä¸€ä¸ªæ‹Ÿåˆçš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”¨è¯¥æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚å¦‚å‰å‡ ç« æ‰€è¿°ï¼Œåœ¨åšå‡ºé¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥åˆ›å»ºä¸€ä¸ªè®­ç»ƒ-æµ‹è¯•åˆ†å‰²ï¼Œä»¥ä¾¿æˆ‘ä»¬æœ‰æ•°æ®å¯ä»¥ä¸é¢„æµ‹è¿›è¡Œæ¯”è¾ƒã€‚æ¨¡å‹åº”è¯¥åªæ‹Ÿåˆè®­ç»ƒæ•°æ®ä»¥é¿å…æ•°æ®æ³„éœ²ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`pmdarima`ä¸­çš„`train_test_split`å‡½æ•°æ¥åˆ†å‰²æ•°æ®ã€‚ç„¶åæˆ‘ä»¬è¿›è¡Œå¸¸è§„æ­¥éª¤ï¼šåˆ†å‰²ã€è®­ç»ƒå’Œé¢„æµ‹ã€‚ä»¥ä¸‹ä»£ç å—æ˜¾ç¤ºäº†è¿™ä¸€è¿‡ç¨‹ï¼š
- en: '[PRE28]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The preceding code fits an ARIMA model with `auto_arima` and then forecasts
    the size of the test set using the `predict` method of the ARIMA object. The forecasts
    for the series generated by the code are shown in *Figure 11**.21*:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ä»£ç ä½¿ç”¨`auto_arima`æ‹ŸåˆARIMAæ¨¡å‹ï¼Œç„¶åä½¿ç”¨ARIMAå¯¹è±¡çš„`predict`æ–¹æ³•é¢„æµ‹æµ‹è¯•é›†çš„å¤§å°ã€‚ç”±ä»£ç ç”Ÿæˆçš„åºåˆ—é¢„æµ‹ç»“æœå¦‚å›¾11**.21**æ‰€ç¤ºï¼š
- en: '![Figure 11.21 â€“ US GDP ARIMA forecast over test split](img/B18945_11_021.jpg)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.21 â€“ æµ‹è¯•åˆ†å‰²ä¸Šçš„ç¾å›½GDP ARIMAé¢„æµ‹](img/B18945_11_021.jpg)'
- en: Figure 11.21 â€“ US GDP ARIMA forecast over test split
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.21 â€“ æµ‹è¯•åˆ†å‰²ä¸Šçš„ç¾å›½GDP ARIMAé¢„æµ‹
- en: The forecast of the US GDP in *Figure 11**.21* appears to follow the trend of
    the data but does not capture the small variations in the series. However, the
    variation is captured in the prediction interval (labeled as â€œintervalâ€). This
    model appears to provide a reasonably good prediction of the test data. Note that
    the interval increases over time. This is because predictions become more uncertain
    farther in the future. Generally, shorter forecasts are more likely to be accurate.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*å›¾11.21*ä¸­ï¼Œç¾å›½GDPçš„é¢„æµ‹ä¼¼ä¹éµå¾ªæ•°æ®çš„è¶‹åŠ¿ï¼Œä½†æ²¡æœ‰æ•æ‰åˆ°åºåˆ—ä¸­çš„å°å˜åŒ–ã€‚ç„¶è€Œï¼Œè¿™ç§å˜åŒ–åœ¨é¢„æµ‹åŒºé—´ï¼ˆæ ‡è®°ä¸ºâ€œåŒºé—´â€ï¼‰ä¸­è¢«æ•æ‰åˆ°ã€‚è¿™ä¸ªæ¨¡å‹ä¼¼ä¹ä¸ºæµ‹è¯•æ•°æ®æä¾›äº†ç›¸å½“å¥½çš„é¢„æµ‹ã€‚è¯·æ³¨æ„ï¼ŒåŒºé—´éšæ—¶é—´å¢åŠ ã€‚è¿™æ˜¯å› ä¸ºé¢„æµ‹åœ¨æœªæ¥çš„ä¸ç¡®å®šæ€§å¢åŠ ã€‚ä¸€èˆ¬æ¥è¯´ï¼ŒçŸ­æœŸé¢„æµ‹æ›´å¯èƒ½å‡†ç¡®ã€‚
- en: In this section, we built on the ARMA model and extended it to non-stationary
    data using differencing, which formed the ARIMA model. In the next section, we
    will look at non-stationary time series that include seasonal effects and make
    a further extension to the ARIMA model.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬åŸºäºARMAæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨å·®åˆ†å°†å…¶æ‰©å±•åˆ°éå¹³ç¨³æ•°æ®ï¼Œä»è€Œå½¢æˆäº†ARIMAæ¨¡å‹ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹åŒ…å«å­£èŠ‚æ€§å½±å“çš„ä¸å¹³ç¨³æ—¶é—´åºåˆ—ï¼Œå¹¶å°†è¿›ä¸€æ­¥æ‰©å±•ARIMAæ¨¡å‹ã€‚
- en: Seasonal ARIMA models
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å­£èŠ‚æ€§ARIMAæ¨¡å‹
- en: Letâ€™s look at another characteristic of time series called **seasonality**.
    Seasonality is the presence of a pattern in a time series that repeats at regular
    intervals. Seasonal time series are common in nature. For example, yearly weather
    patterns and daily sunshine patterns are seasonal patterns. Back at the start
    of the non-stationary section, we showed an example of a non-stationary time series
    with seasonality. This time series is shown again in *Figure 11**.22* along with
    its ACF plot.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹æ—¶é—´åºåˆ—çš„å¦ä¸€ä¸ªç‰¹å¾ï¼Œç§°ä¸º**å­£èŠ‚æ€§**ã€‚å­£èŠ‚æ€§æ˜¯æŒ‡æ—¶é—´åºåˆ—ä¸­å­˜åœ¨ä¸€ä¸ªåœ¨å›ºå®šé—´éš”é‡å¤çš„æ¨¡å¼ã€‚å­£èŠ‚æ€§æ—¶é—´åºåˆ—åœ¨è‡ªç„¶ç•Œä¸­å¾ˆå¸¸è§ã€‚ä¾‹å¦‚ï¼Œå¹´å¤©æ°”æ¨¡å¼å’Œæ—¥é˜³å…‰æ¨¡å¼éƒ½æ˜¯å­£èŠ‚æ€§æ¨¡å¼ã€‚å›åˆ°éå¹³ç¨³æ€§éƒ¨åˆ†çš„å¼€å§‹ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªå…·æœ‰å­£èŠ‚æ€§çš„éå¹³ç¨³æ—¶é—´åºåˆ—çš„ä¾‹å­ã€‚è¿™ä¸ªæ—¶é—´åºåˆ—å†æ¬¡åœ¨*å›¾11.22*ä¸­å±•ç¤ºï¼Œå¹¶é™„æœ‰å®ƒçš„ACFå›¾ã€‚
- en: '![Figure 11.22 â€“ Airline volume data and ACF plot](img/B18945_11_022.jpg)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.22 â€“ èˆªç©ºå®¢æµé‡æ•°æ®å’ŒACFå›¾](img/B18945_11_022.jpg)'
- en: Figure 11.22 â€“ Airline volume data and ACF plot
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.22 â€“ èˆªç©ºå®¢æµé‡æ•°æ®å’ŒACFå›¾
- en: The time series shown in *Figure 11**.22* is the monthly total of international
    airline passengers from 1949 to 1960 [*3*]. There is a definite repeated pattern
    in this time series. To model this type of data, we will need to an additional
    term to the ARIMA model to account for seasonality.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾11.22*ä¸­æ˜¾ç¤ºçš„æ—¶é—´åºåˆ—æ˜¯1949å¹´è‡³1960å¹´å›½é™…èˆªç©ºæ—…å®¢çš„æœˆåº¦æ€»è®¡[*3*]ã€‚åœ¨è¿™ä¸ªæ—¶é—´åºåˆ—ä¸­æœ‰ä¸€ä¸ªæ˜æ˜¾çš„é‡å¤æ¨¡å¼ã€‚ä¸ºäº†æ¨¡æ‹Ÿè¿™ç±»æ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ARIMAæ¨¡å‹ä¸­æ·»åŠ ä¸€ä¸ªé¢å¤–çš„é¡¹æ¥è§£é‡Šå­£èŠ‚æ€§ã€‚'
- en: Seasonal differencing
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å­£èŠ‚æ€§å·®åˆ†
- en: 'We will use a similar approach for modeling this type of time series as we
    did with ARIMA. We will start by using differencing to stationarize the data,
    then fit an ARMA model to the differenced data. With seasonal time series, we
    will need to use seasonal differencing to remove the seasonal effects, which we
    can show mathematically:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨ä¸ARIMAç›¸åŒçš„æ–¹æ³•æ¥å»ºæ¨¡è¿™ç§ç±»å‹çš„æ—¶é—´åºåˆ—ã€‚æˆ‘ä»¬é¦–å…ˆå°†ä½¿ç”¨å·®åˆ†æ¥ä½¿æ•°æ®å¹³ç¨³ï¼Œç„¶åå¯¹å·®åˆ†æ•°æ®è¿›è¡ŒARMAæ¨¡å‹æ‹Ÿåˆã€‚å¯¹äºå­£èŠ‚æ€§æ—¶é—´åºåˆ—ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨å­£èŠ‚æ€§å·®åˆ†æ¥æ¶ˆé™¤å­£èŠ‚æ€§å½±å“ï¼Œè¿™å¯ä»¥é€šè¿‡æ•°å­¦å…¬å¼è¡¨ç¤ºï¼š
- en: y â€²Â t = yÂ t âˆ’ yÂ tâˆ’T
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: yâ€²t = yt âˆ’ ytâˆ’T
- en: 'Where T is the period of the season. For example, the time series in *Figure
    11**.22* exhibits monthly seasonality and each data point represents one month;
    therefore, the T = 12 for the airline volume data. Then, for the airline data,
    we would use the following difference equation to remove seasonality:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­Tæ˜¯å­£èŠ‚çš„å‘¨æœŸã€‚ä¾‹å¦‚ï¼Œ*å›¾11.22*ä¸­çš„æ—¶é—´åºåˆ—è¡¨ç°å‡ºæœˆåº¦å­£èŠ‚æ€§ï¼Œæ¯ä¸ªæ•°æ®ç‚¹ä»£è¡¨ä¸€ä¸ªæœˆï¼›å› æ­¤ï¼Œèˆªç©ºå®¢æµé‡æ•°æ®çš„T = 12ã€‚ç„¶åï¼Œå¯¹äºèˆªç©ºæ•°æ®ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹å·®åˆ†æ–¹ç¨‹æ¥æ¶ˆé™¤å­£èŠ‚æ€§ï¼š
- en: y â€²Â t = yÂ t âˆ’ yÂ tâˆ’12
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: yâ€²t = yt âˆ’ ytâˆ’12
- en: We can also identify the seasonality by observing where peaks occur in the ACF
    plot. The ACF plot in *Figure 11**.22* shows a peak at 12, indicating a seasonal
    period of 12, which is consistent with our knowledge of the time series.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡è§‚å¯ŸACFå›¾ä¸­å³°å€¼å‡ºç°çš„ä½ç½®æ¥è¯†åˆ«å­£èŠ‚æ€§ã€‚*å›¾11.22*ä¸­çš„ACFå›¾æ˜¾ç¤ºåœ¨12å¤„æœ‰ä¸€ä¸ªå³°å€¼ï¼Œè¡¨æ˜å­£èŠ‚å‘¨æœŸä¸º12ï¼Œè¿™ä¸æˆ‘ä»¬å¯¹æ—¶é—´åºåˆ—çš„äº†è§£ä¸€è‡´ã€‚
- en: We will see how to apply seasonal differences later in this section using `pmdarima`.
    Letâ€™s take a look at how seasonality is included in the model.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ç¨åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨`pmdarima`å±•ç¤ºå¦‚ä½•åº”ç”¨å­£èŠ‚å·®åˆ†ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å­£èŠ‚æ€§æ˜¯å¦‚ä½•åŒ…å«åœ¨æ¨¡å‹ä¸­çš„ã€‚
- en: Seasonal ARIMA
  id: totrans-351
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å­£èŠ‚æ€§ARIMA
- en: 'As mentioned in the ARIMA section, we will be differencing the original series,
    then fitting a stationary model to the differenced data. Then our time series
    would be described by the following equation where yâ€²Â t is the differenced series
    (including seasonal and sequential differences):'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚åœ¨ARIMAéƒ¨åˆ†æ‰€è¿°ï¼Œæˆ‘ä»¬å°†å¯¹åŸå§‹åºåˆ—è¿›è¡Œå·®åˆ†ï¼Œç„¶åå¯¹å·®åˆ†æ•°æ®è¿›è¡Œå¹³ç¨³æ¨¡å‹æ‹Ÿåˆã€‚ç„¶åæˆ‘ä»¬çš„æ—¶é—´åºåˆ—å°†ç”±ä»¥ä¸‹æ–¹ç¨‹æè¿°ï¼Œå…¶ä¸­yâ€²tæ˜¯å·®åˆ†åºåˆ—ï¼ˆåŒ…æ‹¬å­£èŠ‚æ€§å’Œé¡ºåºå·®åˆ†ï¼‰ï¼š
- en: yâ€²Â t = c + Ï•Â 1 yâ€²Â tâˆ’1 + â€¦ + Ï•Â p yÂ â€²Â Â tâˆ’p + ÏµÂ t + Î¸Â 1 ÏµÂ tâˆ’1 + â€¦ + Ï•Â q ÏµÂ tâˆ’q
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: yâ€²t = c + Ï•1 yâ€²tâˆ’1 + â€¦ + Ï•p yâ€²tâˆ’p + Ïµt + Î¸1 Ïµtâˆ’1 + â€¦ + Ï•q Ïµtâˆ’q
- en: 'We can express the whole model with backshift notation:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åç§»ç¬¦å·è¡¨ç¤ºæ•´ä¸ªæ¨¡å‹ï¼š
- en: (1 âˆ’ Ï•Â 1 B âˆ’ â€¦ âˆ’ Ï•Â p BÂ p) (1 âˆ’ B)Â d (1 âˆ’ BÂ s)yÂ t = c + (1 + Î¸Â 1 B + â€¦ + Î¸Â q
    BÂ q) ğÂ t
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: (1 âˆ’ Ï•1 B âˆ’ â€¦ âˆ’ Ï•p Bp) (1 âˆ’ B) d (1 âˆ’ Bs)y t = c + (1 + Î¸1 B + â€¦ + Î¸q Bq) ğt
- en: â†‘Â Â  Â  â†‘ Â Â Â â†‘Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  â†‘
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: â†‘Â Â  Â  â†‘ Â Â Â â†‘Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  â†‘
- en: AR(p)Â Â Â Â Â Â Â Â Â d diff Â Â seasonal diffÂ Â Â  Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  MA(q)
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: AR(p)Â Â Â Â Â Â Â Â Â d å·®åˆ†Â Â Â Â Â Â  å­£èŠ‚å·®åˆ†Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  MA(q)
- en: 'We have a new term in the equation that accounts for seasonality: (1 âˆ’ BÂ s).
    We are adding a new order parameter to the model: s. This model is typically denoted
    ARUMA(p,d,q,s).'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨æ–¹ç¨‹ä¸­æ·»åŠ äº†ä¸€ä¸ªè€ƒè™‘å­£èŠ‚æ€§çš„æ–°é¡¹ï¼š(1 âˆ’ Bs)ã€‚æˆ‘ä»¬å‘æ¨¡å‹æ·»åŠ äº†ä¸€ä¸ªæ–°çš„é˜¶æ•°å‚æ•°ï¼šsã€‚æ­¤æ¨¡å‹é€šå¸¸è¡¨ç¤ºä¸ºARUMA(p,d,q,s)ã€‚
- en: SARIMA models
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: SARIMAæ¨¡å‹
- en: In this section, we are only covering seasonal differencing. There are more
    complex models that allow for moving average seasonality and autoregressive seasonality
    called SARIMA and denoted SARIMA(p,d,q)(P,D,Q)[m]. These models are beyond the
    scope of this chapter. However, we would encourage the reader to explore these
    models further after mastering the topics found in this chapter and the next chapter.
    The ARIMA model covered in this chapter is a subset of the SARIMA model, which
    accounts for seasonal differencing, which is the â€œDâ€ order of SARIMA(p,d,q)(P,D,Q)[m].
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»…æ¶µç›–å­£èŠ‚å·®åˆ†ã€‚å­˜åœ¨æ›´å¤æ‚çš„æ¨¡å‹ï¼Œå…è®¸ç§»åŠ¨å¹³å‡å­£èŠ‚æ€§å’Œè‡ªå›å½’å­£èŠ‚æ€§ï¼Œç§°ä¸ºSARIMAï¼Œè¡¨ç¤ºä¸ºSARIMA(p,d,q)(P,D,Q)[m]ã€‚è¿™äº›æ¨¡å‹è¶…å‡ºäº†æœ¬ç« çš„èŒƒå›´ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬é¼“åŠ±è¯»è€…åœ¨æŒæ¡æœ¬ç« å’Œä¸‹ä¸€ç« çš„ä¸»é¢˜åè¿›ä¸€æ­¥æ¢ç´¢è¿™äº›æ¨¡å‹ã€‚æœ¬ç« ä¸­æ¶µç›–çš„ARIMAæ¨¡å‹æ˜¯SARIMAæ¨¡å‹çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒè€ƒè™‘äº†å­£èŠ‚å·®åˆ†ï¼Œå³SARIMA(p,d,q)(P,D,Q)[m]ä¸­çš„â€œDâ€é˜¶æ•°ã€‚
- en: Just as the (1 âˆ’ B)Â d term we added for ARIMA, the (1 âˆ’ BÂ s) term adds roots
    to the unit circle. However, unlike the roots from (1 âˆ’ B)Â d, the roots from (1
    âˆ’ BÂ s) are distributed uniformly around the unit circle. These roots can be calculated
    and plotted programmatically with `numpy` and `matplotlib` or automatically with
    computational intelligence tools such as Wolfram Alpha ([https://www.wolframalpha.com/](https://www.wolframalpha.com/)).
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬ä¸ºARIMAæ·»åŠ çš„(1 âˆ’ B)dé¡¹ä¸€æ ·ï¼Œ(1 âˆ’ Bs)é¡¹å‘å•ä½åœ†æ·»åŠ äº†æ ¹ã€‚ç„¶è€Œï¼Œä¸(1 âˆ’ B)dçš„æ ¹ä¸åŒï¼Œ(1 âˆ’ Bs)çš„æ ¹å‡åŒ€åˆ†å¸ƒåœ¨å•ä½åœ†å‘¨å›´ã€‚è¿™äº›æ ¹å¯ä»¥ä½¿ç”¨`numpy`å’Œ`matplotlib`æˆ–ä½¿ç”¨è®¡ç®—æ™ºèƒ½å·¥å…·ï¼ˆå¦‚Wolfram
    Alpha [https://www.wolframalpha.com/](https://www.wolframalpha.com/)ï¼‰è¿›è¡Œè®¡ç®—å’Œç»˜åˆ¶ã€‚
- en: Fitting an ARIMA model with seasonality
  id: totrans-362
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ‹Ÿåˆå…·æœ‰å­£èŠ‚æ€§çš„ARIMAæ¨¡å‹
- en: 'We will take the following steps to fit an ARIMA model with seasonality:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é‡‡å–ä»¥ä¸‹æ­¥éª¤æ¥æ‹Ÿåˆå…·æœ‰å­£èŠ‚æ€§çš„ARIMAæ¨¡å‹ï¼š
- en: Remove seasonality with differencing.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å·®åˆ†å»é™¤å­£èŠ‚æ€§ã€‚
- en: Remove additional non-stationarity with differencing.
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å·®åˆ†å»é™¤é¢å¤–çš„éå¹³ç¨³æ€§ã€‚
- en: Fit a stationary model to the resulting series.
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†å¹³ç¨³æ¨¡å‹æ‹Ÿåˆåˆ°ç»“æœåºåˆ—ã€‚
- en: This is essentially the same process we used to fit an ARIMA model, but there
    is an additional step to handle the seasonal component. Let us walk through an
    example with the airline data.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ¬è´¨ä¸Šæ˜¯æˆ‘ä»¬ç”¨æ¥æ‹ŸåˆARIMAæ¨¡å‹çš„è¿‡ç¨‹ï¼Œä½†æœ‰ä¸€ä¸ªé¢å¤–çš„æ­¥éª¤æ¥å¤„ç†å­£èŠ‚æ€§æˆåˆ†ã€‚è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªä½¿ç”¨èˆªç©ºå…¬å¸æ•°æ®çš„ä¾‹å­æ¥è®²è§£ã€‚
- en: 'We will start with using differencing to remove the seasonal component of the
    time series. Recall that the seasonal period of the airline time series is 12,
    meaning that we need to perform differencing at lag 12 as shown with this equation:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é¦–å…ˆä½¿ç”¨å·®åˆ†æ¥å»é™¤æ—¶é—´åºåˆ—çš„å­£èŠ‚æ€§æˆåˆ†ã€‚å›æƒ³ä¸€ä¸‹ï¼Œèˆªç©ºå…¬å¸æ—¶é—´åºåˆ—çš„å­£èŠ‚å‘¨æœŸæ˜¯12ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦åœ¨æ»å12å¤„è¿›è¡Œå·®åˆ†ï¼Œå¦‚ä¸‹æ–¹ç¨‹æ‰€ç¤ºï¼š
- en: y â€²Â t = yÂ t âˆ’ yÂ tâˆ’12
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: yâ€²t = yt âˆ’ ytâˆ’12
- en: 'We can perform this difference using the `diff` function from `pmdarima`. The
    following code shows how to perform the 12th lagged difference on the airline
    data:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`pmdarima`ä¸­çš„`diff`å‡½æ•°æ‰§è¡Œæ­¤å·®åˆ†ã€‚ä»¥ä¸‹ä»£ç æ˜¾ç¤ºäº†å¦‚ä½•åœ¨èˆªç©ºå…¬å¸æ•°æ®ä¸Šæ‰§è¡Œç¬¬12æ»åå·®åˆ†ï¼š
- en: '[PRE29]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'After performing the seasonal difference, we get the differenced series shown
    in *Figure 11**.23* along with the ACF plot. The seasonal portion of the time
    series appears to be completely removed. The differenced series does not appear
    to exhibit any repeating patterns. Additionally, the ACF plot does not show the
    seasonal peak that was present in the ACF plot of the original data:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿›è¡Œå­£èŠ‚å·®åˆ†åï¼Œæˆ‘ä»¬å¾—åˆ°*å›¾11.23*ä¸­æ˜¾ç¤ºçš„å·®åˆ†åºåˆ—ä»¥åŠACFå›¾ã€‚æ—¶é—´åºåˆ—çš„å­£èŠ‚éƒ¨åˆ†ä¼¼ä¹å·²ç»å®Œå…¨å»é™¤ã€‚å·®åˆ†åºåˆ—ä¼¼ä¹æ²¡æœ‰æ˜¾ç¤ºå‡ºä»»ä½•é‡å¤çš„æ¨¡å¼ã€‚æ­¤å¤–ï¼ŒACFå›¾æ²¡æœ‰æ˜¾ç¤ºåŸå§‹æ•°æ®ACFå›¾ä¸­å­˜åœ¨çš„å­£èŠ‚æ€§å³°å€¼ï¼š
- en: '![Figure 11.23 â€“ Airline data after seasonal difference](img/B18945_11_023.jpg)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.23 â€“ å­£èŠ‚å·®åˆ†åçš„èˆªç©ºå…¬å¸æ•°æ®](img/B18945_11_023.jpg)'
- en: Figure 11.23 â€“ Airline data after seasonal difference
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.23 â€“ å­£èŠ‚å·®åˆ†åçš„èˆªç©ºå…¬å¸æ•°æ®
- en: 'With the seasonal portion of the time series removed, we need to determine
    whether we need to take any additional differences to stationarize the new time
    series. The differenced series in *Figure 11**.23* appears to exhibit a trend.
    The original data also exhibited a trend. As before, we can use the Dickey-Fuller
    test to get additional evidence on whether we should apply additional differences.
    Running the Dickey-Fuller test on this series will result in a p-value of 0.099,
    which suggests that we should take a difference in the series to account for a
    unit root:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å»é™¤æ—¶é—´åºåˆ—çš„å­£èŠ‚éƒ¨åˆ†åï¼Œæˆ‘ä»¬éœ€è¦ç¡®å®šæ˜¯å¦éœ€è¦å–ä»»ä½•é¢å¤–çš„å·®åˆ†æ¥ä½¿æ–°çš„æ—¶é—´åºåˆ—å¹³ç¨³åŒ–ã€‚*å›¾11.23*ä¸­çš„å·®åˆ†åºåˆ—ä¼¼ä¹æ˜¾ç¤ºå‡ºè¶‹åŠ¿ã€‚åŸå§‹æ•°æ®ä¹Ÿæ˜¾ç¤ºå‡ºè¶‹åŠ¿ã€‚ä¸ä¹‹å‰ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨Dickey-Fulleræµ‹è¯•æ¥è·å–æ›´å¤šè¯æ®ï¼Œä»¥ç¡®å®šæˆ‘ä»¬æ˜¯å¦åº”è¯¥åº”ç”¨é¢å¤–çš„å·®åˆ†ã€‚å¯¹è¿™ä¸ªåºåˆ—è¿è¡ŒDickey-Fulleræµ‹è¯•å°†å¾—åˆ°ä¸€ä¸ªpå€¼ä¸º0.099ï¼Œè¿™è¡¨æ˜æˆ‘ä»¬åº”è¯¥å¯¹åºåˆ—å–å·®åˆ†ä»¥è§£é‡Šå•ä½æ ¹ï¼š
- en: '[PRE30]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Taking the first difference of the series will result in the series shown in
    *Figure 11**.24*. After taking these two differences the series appears to be
    sufficiently stationarized.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹åºåˆ—å–ä¸€é˜¶å·®åˆ†å°†å¯¼è‡´*å›¾11.24*ä¸­æ˜¾ç¤ºçš„åºåˆ—ã€‚åœ¨å–è¿™ä¸¤ä¸ªå·®åˆ†ä¹‹åï¼Œåºåˆ—ä¼¼ä¹å·²ç»è¶³å¤Ÿå¹³ç¨³åŒ–ã€‚
- en: '![Figure 11.24 â€“ Airline data after seasonal and first difference](img/B18945_11_024.jpg)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.24 â€“ å­£èŠ‚å·®åˆ†å’Œä¸€é˜¶å·®åˆ†åçš„èˆªç©ºå…¬å¸æ•°æ®](img/B18945_11_024.jpg)'
- en: Figure 11.24 â€“ Airline data after seasonal and first difference
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.24 â€“ å­£èŠ‚å·®åˆ†å’Œä¸€é˜¶å·®åˆ†åçš„èˆªç©ºå…¬å¸æ•°æ®
- en: 'The series in *Figure 11**.24* shows the stationarized version of the airline
    data. Based on the ACF plot, we should be able to fit a relatively simple ARMA
    model to the stationarized series. We will use `auto_arima` function to make an
    automatic fit as we did in the ARIMA section:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾11.24*ä¸­çš„åºåˆ—æ˜¾ç¤ºäº†èˆªç©ºå…¬å¸æ•°æ®çš„å¹³ç¨³åŒ–ç‰ˆæœ¬ã€‚æ ¹æ®ACFå›¾ï¼Œæˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿå¯¹å¹³ç¨³åŒ–åºåˆ—æ‹Ÿåˆä¸€ä¸ªç›¸å¯¹ç®€å•çš„ARMAæ¨¡å‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨`auto_arima`å‡½æ•°è¿›è¡Œè‡ªåŠ¨æ‹Ÿåˆï¼Œå°±åƒæˆ‘ä»¬åœ¨ARIMAéƒ¨åˆ†æ‰€åšçš„é‚£æ ·ï¼š'
- en: '[PRE31]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Fitting the differenced data with `auto_arima` returns an AR(1) model. A simple
    model as we expected.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`auto_arima`å¯¹å·®åˆ†æ•°æ®è¿›è¡Œæ‹Ÿåˆè¿”å›ä¸€ä¸ªAR(1)æ¨¡å‹ã€‚æ­£å¦‚æˆ‘ä»¬æ‰€æœŸæœ›çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•çš„æ¨¡å‹ã€‚
- en: 'Putting this all together our resulting model is an ARUMA(1,1,0,12). As with
    the previous ARIMA example, we could have fit this model with `auto_arima`, but
    we walked through the differencing steps here to help build intuition for what
    each difference element does to the series. Letâ€™s take a look at the direct fit
    from `auto_arima` now:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ‰€æœ‰è¿™äº›æ”¾åœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬å¾—åˆ°çš„æ¨¡å‹æ˜¯ARUMA(1,1,0,12)ã€‚ä¸ä¹‹å‰çš„ARIMAç¤ºä¾‹ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`auto_arima`æ¥æ‹Ÿåˆè¿™ä¸ªæ¨¡å‹ï¼Œä½†æˆ‘ä»¬åœ¨æœ¬ä¾‹ä¸­è¯¦ç»†è¯´æ˜äº†å·®åˆ†æ­¥éª¤ï¼Œä»¥å¸®åŠ©å»ºç«‹å¯¹æ¯ä¸ªå·®åˆ†å…ƒç´ å¯¹åºåˆ—å½±å“çš„ç†è§£ã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹`auto_arima`çš„ç›´æ¥æ‹Ÿåˆç»“æœï¼š
- en: '[PRE32]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We see that `auto_arima` found the same model that we did using manual differencing.
    Note the model is denoted in SARIMA format (see earlier callout about SARIMA).
    The (0,1,0)[12] means seasonality of 12 when one difference for the seasonality.
    Now that we have a fit model, letâ€™s look at forecasting for our seasonal model.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°`auto_arima`æ‰¾åˆ°äº†ä¸æˆ‘ä»¬ä½¿ç”¨æ‰‹åŠ¨å·®åˆ†å¾—åˆ°ç›¸åŒçš„æ¨¡å‹ã€‚æ³¨æ„æ¨¡å‹ä»¥SARIMAæ ¼å¼è¡¨ç¤ºï¼ˆå‚è§å…³äºSARIMAçš„æ—©æœŸè¯´æ˜ï¼‰ã€‚(0,1,0)[12]è¡¨ç¤ºå½“å­£èŠ‚æ€§æœ‰ä¸€ä¸ªå·®åˆ†æ—¶ï¼Œå­£èŠ‚æ€§ä¸º12ã€‚ç°åœ¨æˆ‘ä»¬æœ‰äº†æ‹Ÿåˆæ¨¡å‹ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬å¯¹å­£èŠ‚æ€§æ¨¡å‹çš„é¢„æµ‹ã€‚
- en: Forecasting ARIMA with seasonality
  id: totrans-386
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å…·æœ‰å­£èŠ‚æ€§çš„ARIMAé¢„æµ‹
- en: 'Once we have a fit model, we can forecast with that model. As mentioned in
    the section on forecasting with ARIMA, when should we make a train-test split
    so we have data to compare with the predictions? We will use the same procedure:
    split the data, train the model, and forecast over the test set size:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬æœ‰äº†æ‹Ÿåˆæ¨¡å‹ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”¨è¿™ä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚å¦‚ARIMAé¢„æµ‹éƒ¨åˆ†æ‰€è¿°ï¼Œæˆ‘ä»¬åº”è¯¥ä½•æ—¶è¿›è¡Œè®­ç»ƒ-æµ‹è¯•é›†åˆ’åˆ†ä»¥ä¾¿æˆ‘ä»¬æœ‰æ•°æ®æ¥æ¯”è¾ƒé¢„æµ‹ç»“æœï¼Ÿæˆ‘ä»¬å°†ä½¿ç”¨ç›¸åŒçš„ç¨‹åºï¼šåˆ†å‰²æ•°æ®ï¼Œè®­ç»ƒæ¨¡å‹ï¼Œå¹¶åœ¨æµ‹è¯•é›†å¤§å°ä¸Šè¿›è¡Œé¢„æµ‹ï¼š
- en: '[PRE33]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The preceding code fits a full SARIMA model with `auto_arima` and then forecasts
    the size of the test set using the `predict` method. The forecasts for the series
    generated by the code are shown in *Figure 11**.25*.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: å‰é¢çš„ä»£ç ä½¿ç”¨`auto_arima`æ‹Ÿåˆäº†ä¸€ä¸ªå®Œæ•´çš„SARIMAæ¨¡å‹ï¼Œç„¶åä½¿ç”¨`predict`æ–¹æ³•é¢„æµ‹æµ‹è¯•é›†çš„å¤§å°ã€‚ç”±ä»£ç ç”Ÿæˆçš„åºåˆ—é¢„æµ‹æ˜¾ç¤ºåœ¨*å›¾11.25*ä¸­ã€‚
- en: '![Figure 11.25 â€“ SARIMA forecast of the airline data](img/B18945_11_025.jpg)'
  id: totrans-390
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.25 â€“ èˆªç©ºå…¬å¸æ•°æ®çš„SARIMAé¢„æµ‹](img/B18945_11_025.jpg)'
- en: Figure 11.25 â€“ SARIMA forecast of the airline data
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.25 â€“ èˆªç©ºå…¬å¸æ•°æ®çš„SARIMAé¢„æµ‹
- en: The forecast of the airline data in *Figure 11**.25* appears to capture the
    variation of the data very well. This is likely due to the strength of the seasonality
    component in the time series. Note that the prediction intervals increase over
    time just as with the ARIMA prediction intervals, but the intervals follow the
    general pattern of the series. This is an impact of the additional knowledge of
    seasonality in the series.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾11.25*ä¸­çš„èˆªç©ºå…¬å¸æ•°æ®é¢„æµ‹ä¼¼ä¹å¾ˆå¥½åœ°æ•æ‰äº†æ•°æ®çš„å˜åŠ¨ã€‚è¿™å¯èƒ½æ˜¯ç”±äºæ—¶é—´åºåˆ—ä¸­å­£èŠ‚æ€§æˆåˆ†çš„å¼ºåº¦ã€‚è¯·æ³¨æ„ï¼Œé¢„æµ‹åŒºé—´éšç€æ—¶é—´çš„æ¨ç§»è€Œå¢åŠ ï¼Œå°±åƒARIMAé¢„æµ‹åŒºé—´ä¸€æ ·ï¼Œä½†åŒºé—´éµå¾ªåºåˆ—çš„ä¸€èˆ¬æ¨¡å¼ã€‚è¿™æ˜¯ç”±äºå¯¹åºåˆ—ä¸­å­£èŠ‚æ€§çš„é¢å¤–çŸ¥è¯†çš„å½±å“ã€‚'
- en: In this section, we discussed ARIMA models with seasonality and showed how to
    remove seasonal components. We also looked at forecasting a model with seasonality.
    In the next section, we will take a closer look at validating time series models.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†å…·æœ‰å­£èŠ‚æ€§çš„ARIMAæ¨¡å‹ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•å»é™¤å­£èŠ‚æ€§æˆåˆ†ã€‚æˆ‘ä»¬è¿˜ç ”ç©¶äº†å…·æœ‰å­£èŠ‚æ€§çš„æ¨¡å‹é¢„æµ‹ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ›´è¯¦ç»†åœ°æ¢è®¨éªŒè¯æ—¶é—´åºåˆ—æ¨¡å‹ã€‚
- en: More on model evaluation
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ›´å¤šå…³äºæ¨¡å‹è¯„ä¼°
- en: 'In the previous sections, we discussed other methods to prepare data, test
    and validate models. In this section, we will discuss how to validate time series
    models and introduce several methods for validating time series models. We will
    cover the following methods for model evaluation: **resampling**, **shifting**,
    **optimized persistence forecasting,** and **rolling** **window forecasting**.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†å…¶ä»–å‡†å¤‡æ•°æ®ã€æµ‹è¯•å’ŒéªŒè¯æ¨¡å‹çš„æ–¹æ³•ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¦‚ä½•éªŒè¯æ—¶é—´åºåˆ—æ¨¡å‹ï¼Œå¹¶ä»‹ç»å‡ ç§éªŒè¯æ—¶é—´åºåˆ—æ¨¡å‹çš„æ–¹æ³•ã€‚æˆ‘ä»¬å°†æ¶µç›–ä»¥ä¸‹æ¨¡å‹è¯„ä¼°æ–¹æ³•ï¼š**é‡é‡‡æ ·**ã€**ç§»åŠ¨**ã€**ä¼˜åŒ–æŒä¹…é¢„æµ‹**å’Œ**æ»šåŠ¨çª—å£é¢„æµ‹**ã€‚
- en: 'The real-world dataset considered in this section is Coca Cola stock data collected
    from Yahoo Finance databases from 01/19/1962 to 12/19/2021 for stock price prediction.
    This is a time series analysis to forecast the future stock value of a given stock.
    The reader can download the dataset from the Kaggle platform for this analysis.
    To motivate the study, we first go to explore the Coco Cola stock dataset:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬èŠ‚è€ƒè™‘çš„å®é™…æ•°æ®é›†æ˜¯ä»Yahoo Financeæ•°æ®åº“ä¸­æ”¶é›†çš„1962å¹´1æœˆ19æ—¥è‡³2021å¹´12æœˆ19æ—¥çš„å¯å£å¯ä¹è‚¡ç¥¨æ•°æ®ï¼Œç”¨äºè‚¡ç¥¨ä»·æ ¼é¢„æµ‹ã€‚è¿™æ˜¯ä¸€é¡¹æ—¶é—´åºåˆ—åˆ†æï¼Œç”¨äºé¢„æµ‹ç»™å®šè‚¡ç¥¨çš„æœªæ¥è‚¡ç¥¨ä»·å€¼ã€‚è¯»è€…å¯ä»¥ä»Kaggleå¹³å°ä¸‹è½½è¯¥æ•°æ®é›†è¿›è¡Œåˆ†æã€‚ä¸ºäº†æ¿€å‘ç ”ç©¶å…´è¶£ï¼Œæˆ‘ä»¬é¦–å…ˆå»æ¢ç´¢å¯å£å¯ä¹è‚¡ç¥¨æ•°æ®é›†ï¼š
- en: '[PRE34]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![Figure 11.26 â€“ Coco Cola dataset](img/B18945_11_026.jpg)'
  id: totrans-398
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.26 â€“ å¯å£å¯ä¹æ•°æ®é›†](img/B18945_11_026.jpg)'
- en: Figure 11.26 â€“ Coco Cola dataset
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.26 â€“ å¯å£å¯ä¹æ•°æ®é›†
- en: 'The Date index is related to 15096 trading days from 01/19/1962 to 12/19/2021\.
    The `High` and `Low` columns here refer to the maximum and minimum prices on each
    trading day. `Open` and `Close` refer to the stock prices when the market was
    open and closed on the same trading day. The total amount of trading stocks in
    each day refers to the `Volume` column and the last column (`Adj Close`) refers
    to adjusted values (combining with stock splits, dividends, etc.). To illustrate
    how resampling, shifting, rolling windows, and expanding windows perform, we narrow
    down to use only the `Open` column from the year 2016:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¥æœŸç´¢å¼•ä¸ä»1962å¹´1æœˆ19æ—¥åˆ°2021å¹´12æœˆ19æ—¥çš„15096ä¸ªäº¤æ˜“æ—¥ç›¸å…³ã€‚è¿™é‡Œçš„`High`å’Œ`Low`åˆ—åˆ†åˆ«æŒ‡æ¯ä¸ªäº¤æ˜“æ—¥çš„æœ€é«˜å’Œæœ€ä½ä»·æ ¼ã€‚`Open`å’Œ`Close`åˆ†åˆ«æŒ‡åœ¨åŒä¸€ä¸ªäº¤æ˜“æ—¥çš„å¸‚åœºå¼€ç›˜å’Œæ”¶ç›˜æ—¶çš„è‚¡ä»·ã€‚æ¯å¤©äº¤æ˜“çš„è‚¡ç¥¨æ€»é‡æŒ‡çš„æ˜¯`Volume`åˆ—ï¼Œè€Œæœ€åä¸€åˆ—ï¼ˆ`Adj
    Close`ï¼‰æŒ‡çš„æ˜¯è°ƒæ•´åçš„å€¼ï¼ˆç»“åˆè‚¡ç¥¨åˆ†å‰²ã€è‚¡æ¯ç­‰ï¼‰ã€‚ä¸ºäº†è¯´æ˜é‡é‡‡æ ·ã€ç§»åŠ¨ã€æ»šåŠ¨çª—å£å’Œæ‰©å±•çª—å£çš„æ€§èƒ½ï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨2016å¹´çš„`Open`åˆ—ï¼š
- en: '[PRE35]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The data was collected by trading dates. However, we will perform the study
    monthly. The **resampling** technique is used to aggregate data from days to months.
    This idea motivates us to introduce this technique.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®æ˜¯æ ¹æ®äº¤æ˜“æ—¥æœŸæ”¶é›†çš„ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å°†æŒ‰æœˆè¿›è¡Œè¿™é¡¹ç ”ç©¶ã€‚ä½¿ç”¨**é‡é‡‡æ ·**æŠ€æœ¯å°†æ•°æ®ä»æ—¥èšåˆåˆ°æœˆã€‚è¿™ä¸ªæƒ³æ³•æ¿€åŠ±æˆ‘ä»¬å¼•å…¥è¿™é¡¹æŠ€æœ¯ã€‚
- en: Resampling
  id: totrans-403
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: é‡é‡‡æ ·
- en: '`resample()` function to change time frequencies. The following code illustrates
    the resampling technique in Python:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '`resample()`å‡½æ•°ç”¨äºæ›´æ”¹æ—¶é—´é¢‘ç‡ã€‚ä»¥ä¸‹ä»£ç å±•ç¤ºäº†Pythonä¸­çš„é‡é‡‡æ ·æŠ€æœ¯ï¼š'
- en: '[PRE36]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Here is the output of the previous code:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å‰ä¸€æ®µä»£ç çš„è¾“å‡ºï¼š
- en: '![Figure 11.27 â€“ Resampling for Coco Cola dataset](img/B18945_11_027.jpg)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.27 â€“ Coco Colaæ•°æ®é›†çš„é‡é‡‡æ ·](img/B18945_11_027.jpg)'
- en: Figure 11.27 â€“ Resampling for Coco Cola dataset
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.27 â€“ Coco Colaæ•°æ®é›†çš„é‡é‡‡æ ·
- en: We observe that the plots become smoother when time frequencies decrease. Next,
    we discuss the shifting method used in time series.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è§‚å¯Ÿåˆ°å½“æ—¶é—´é¢‘ç‡é™ä½æ—¶ï¼Œå›¾è¡¨å˜å¾—æ›´åŠ å¹³æ»‘ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è®¨è®ºæ—¶é—´åºåˆ—ä¸­ä½¿ç”¨çš„å¹³ç§»æ–¹æ³•ã€‚
- en: Shifting
  id: totrans-410
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: å¹³ç§»
- en: 'In time series analysis, it is not uncommon to `shift()` function to create
    new features:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ—¶é—´åºåˆ—åˆ†æä¸­ï¼Œä½¿ç”¨`shift()`å‡½æ•°åˆ›å»ºæ–°ç‰¹å¾å¹¶ä¸ç½•è§ï¼š
- en: '[PRE37]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![Figure 11.28 â€“ First five rows of Coco Cola stock data with price shifted
    once](img/B18945_11_028.jpg)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.28 â€“ Coco Colaè‚¡ç¥¨æ•°æ®çš„å‰äº”è¡Œï¼Œä»·æ ¼å·²è°ƒæ•´ä¸€æ¬¡](img/B18945_11_028.jpg)'
- en: Figure 11.28 â€“ First five rows of Coco Cola stock data with price shifted once
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.28 â€“ Coco Colaè‚¡ç¥¨æ•°æ®çš„å‰äº”è¡Œï¼Œä»·æ ¼å·²è°ƒæ•´ä¸€æ¬¡
- en: 'Observe that the first row of the `price_lag_1` column is filled with a NaN
    value. We can replace the missing value with the `fill_value` parameter:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿåˆ°`price_lag_1`åˆ—çš„ç¬¬ä¸€è¡Œå¡«å……äº†ä¸€ä¸ªNaNå€¼ã€‚æˆ‘ä»¬å¯ä»¥ç”¨`fill_value`å‚æ•°æ›¿æ¢ç¼ºå¤±å€¼ï¼š
- en: '[PRE38]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Finally, we discuss the forecasting methods such as **optimized persistence**
    and **rolling window forecasting**. Another resource related to these methods
    can be found in [*3*].
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬è®¨è®ºé¢„æµ‹æ–¹æ³•ï¼Œå¦‚**ä¼˜åŒ–æŒä¹…æ€§**å’Œ**æ»šåŠ¨çª—å£é¢„æµ‹**ã€‚æœ‰å…³è¿™äº›æ–¹æ³•çš„å¦ä¸€ä¸ªèµ„æºå¯ä»¥åœ¨[*3*]ä¸­æ‰¾åˆ°ã€‚
- en: Optimized persistence forecasting
  id: totrans-418
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ä¼˜åŒ–æŒä¹…æ€§é¢„æµ‹
- en: 'We will convert the Coco Cola stock price time frequency to monthly frequency
    from 2016 using resampling and then we apply an optimized persistence forecasting
    technique to predict the future value using the previous observation. RMSE scores
    are considered to evaluate persistence models:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨é‡é‡‡æ ·å°†Coco Colaè‚¡ç¥¨ä»·æ ¼çš„æ—¶é—´é¢‘ç‡ä»2016å¹´å¼€å§‹è½¬æ¢ä¸ºæœˆåº¦é¢‘ç‡ï¼Œç„¶åæˆ‘ä»¬åº”ç”¨ä¼˜åŒ–æŒä¹…æ€§é¢„æµ‹æŠ€æœ¯ï¼Œä½¿ç”¨ä¹‹å‰çš„è§‚æµ‹å€¼æ¥é¢„æµ‹æœªæ¥çš„å€¼ã€‚RMSEå¾—åˆ†ç”¨äºè¯„ä¼°æŒä¹…æ€§æ¨¡å‹ï¼š
- en: '[PRE39]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output is as follows:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡ºå¦‚ä¸‹ï¼š
- en: '![Figure 11.29 â€“ RMSE scores for Optimized persistence forecasting](img/B18945_11_029.jpg)'
  id: totrans-422
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.29 â€“ ä¼˜åŒ–æŒä¹…æ€§é¢„æµ‹çš„RMSEå¾—åˆ†](img/B18945_11_029.jpg)'
- en: Figure 11.29 â€“ RMSE scores for Optimized persistence forecasting
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.29 â€“ ä¼˜åŒ–æŒä¹…æ€§é¢„æµ‹çš„RMSEå¾—åˆ†
- en: 'We observe that when p=6, the RMSE score is the smallest:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è§‚å¯Ÿåˆ°å½“p=6æ—¶ï¼ŒRMSEå¾—åˆ†æ˜¯æœ€å°çš„ï¼š
- en: '![Figure 11.30 â€“ Optimized Persistence Forecasting, test versus prediction](img/B18945_11_030.jpg)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.30 â€“ ä¼˜åŒ–æŒä¹…æ€§é¢„æµ‹ï¼Œæµ‹è¯•ä¸é¢„æµ‹å¯¹æ¯”](img/B18945_11_030.jpg)'
- en: Figure 11.30 â€“ Optimized Persistence Forecasting, test versus prediction
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.30 â€“ ä¼˜åŒ–æŒä¹…æ€§é¢„æµ‹ï¼Œæµ‹è¯•ä¸é¢„æµ‹å¯¹æ¯”
- en: 'Running the persistence test again with p=6, we can see the following:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡è¿è¡ŒæŒä¹…æ€§æµ‹è¯•ï¼Œä½¿ç”¨p=6ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä»¥ä¸‹ç»“æœï¼š
- en: '[PRE40]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Then, we can produce a visualization:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ç”Ÿæˆä¸€ä¸ªå¯è§†åŒ–ï¼š
- en: '![Figure 11.31 â€“ Optimized Persistence Forecasting](img/B18945_11_031.jpg)'
  id: totrans-430
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.31 â€“ ä¼˜åŒ–æŒä¹…æ€§é¢„æµ‹](img/B18945_11_031.jpg)'
- en: Figure 11.31 â€“ Optimized Persistence Forecasting
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.31 â€“ ä¼˜åŒ–æŒä¹…æ€§é¢„æµ‹
- en: The blue curve is the test value, and the orange curve is for the prediction.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: è“è‰²æ›²çº¿æ˜¯æµ‹è¯•å€¼ï¼Œæ©™è‰²æ›²çº¿æ˜¯é¢„æµ‹å€¼ã€‚
- en: Rolling window forecast
  id: totrans-433
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ»šåŠ¨çª—å£é¢„æµ‹
- en: 'This technique creates a **rolling window** with a specified window size and
    then performs a statistic calculation in this window, using it for forecasting
    which rolls through the data used in a study. We conduct a similar study as in
    the last part on the Coco Cola stock price dataset from 2016 using a monthly resampling
    dataset:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æŠ€æœ¯åˆ›å»ºäº†ä¸€ä¸ªå…·æœ‰æŒ‡å®šçª—å£å¤§å°çš„**æ»šåŠ¨çª—å£**ï¼Œç„¶ååœ¨è¿™ä¸ªçª—å£å†…è¿›è¡Œç»Ÿè®¡è®¡ç®—ï¼Œç”¨äºé¢„æµ‹ï¼Œè¯¥é¢„æµ‹ä¼šæ»šåŠ¨é€šè¿‡ç ”ç©¶ä¸­ä½¿ç”¨çš„æ•°æ®ã€‚æˆ‘ä»¬ä½¿ç”¨2016å¹´çš„Coco
    Colaè‚¡ç¥¨ä»·æ ¼æ•°æ®é›†ï¼Œé‡‡ç”¨æœˆåº¦é‡é‡‡æ ·æ•°æ®é›†è¿›è¡Œç±»ä¼¼çš„ç ”ç©¶ï¼š
- en: '[PRE41]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![Figure 11.32 â€“ Rolling window forecasting](img/B18945_11_032.jpg)'
  id: totrans-436
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾11.32 â€“ æ»šåŠ¨çª—å£é¢„æµ‹](img/B18945_11_032.jpg)'
- en: Figure 11.32 â€“ Rolling window forecasting
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11.32 â€“ æ»šåŠ¨çª—å£é¢„æµ‹
- en: With window size = 9, the RMSE of 3.808 is the smallest. Run the Python code
    again with window size = 9 we produce a similar visualization as with the Optimized
    Persistence Forecast.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: å½“çª—å£å¤§å°ä¸º9æ—¶ï¼ŒRMSEä¸º3.808æ˜¯æœ€å°çš„ã€‚å†æ¬¡è¿è¡ŒPythonä»£ç ï¼Œä½¿ç”¨çª—å£å¤§å°=9ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸ä¼˜åŒ–æŒä¹…æ€§é¢„æµ‹ç›¸ä¼¼çš„å¯è§†åŒ–æ•ˆæœã€‚
- en: Summary
  id: totrans-439
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: In this chapter, we discussed various methods for modeling univariate time series
    data from stationary time series models such as ARMA to non-stationary models
    such as ARIMA. We started with stationary models and discussed how to identify
    modeling approaches based on the characteristics of time series. Then we built
    on the stationary models by adding a term in the model to stationarize time series.
    Finally, we talked about seasonality and how to account for seasonality in an
    ARIMA model. While these methods are powerful for forecasting, they do not incorporate
    potential information from other external variables. As in the previous chapter,
    we will see that external variables can help improve forecasts. In the next chapter,
    we will look at multivariate methods for time series data to take advantage of
    other explanatory variables.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä»å¹³ç¨³æ—¶é—´åºåˆ—æ¨¡å‹ï¼ˆå¦‚ARMAï¼‰åˆ°éå¹³ç¨³æ¨¡å‹ï¼ˆå¦‚ARIMAï¼‰çš„å„ç§å»ºæ¨¡æ–¹æ³•æ¥å»ºæ¨¡ä¸€å…ƒæ—¶é—´åºåˆ—æ•°æ®ã€‚æˆ‘ä»¬ä»å¹³ç¨³æ¨¡å‹å¼€å§‹ï¼Œè®¨è®ºäº†å¦‚ä½•æ ¹æ®æ—¶é—´åºåˆ—çš„ç‰¹å¾æ¥è¯†åˆ«å»ºæ¨¡æ–¹æ³•ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨å¹³ç¨³æ¨¡å‹çš„åŸºç¡€ä¸Šé€šè¿‡åœ¨æ¨¡å‹ä¸­æ·»åŠ ä¸€ä¸ªé¡¹æ¥ä½¿æ—¶é—´åºåˆ—å¹³ç¨³åŒ–ã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†å­£èŠ‚æ€§å’Œå¦‚ä½•åœ¨ARIMAæ¨¡å‹ä¸­è€ƒè™‘å­£èŠ‚æ€§ã€‚è™½ç„¶è¿™äº›æ–¹æ³•åœ¨é¢„æµ‹æ–¹é¢éå¸¸å¼ºå¤§ï¼Œä½†å®ƒä»¬å¹¶æ²¡æœ‰ç»“åˆæ¥è‡ªå…¶ä»–å¤–éƒ¨å˜é‡çš„æ½œåœ¨ä¿¡æ¯ã€‚æ­£å¦‚å‰ä¸€ç« æ‰€è¿°ï¼Œå¤–éƒ¨å˜é‡å¯ä»¥å¸®åŠ©æé«˜é¢„æµ‹ã€‚åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨æ—¶é—´åºåˆ—æ•°æ®çš„å¤šå…ƒæ–¹æ³•ï¼Œä»¥åˆ©ç”¨å…¶ä»–è§£é‡Šå˜é‡ã€‚
- en: References
  id: totrans-441
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: Please refer to the final word file for how the references should look.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·å‚è€ƒæœ€ç»ˆæ–‡æ¡£ï¼Œäº†è§£å‚è€ƒæ–‡çŒ®çš„æ ¼å¼ã€‚
- en: '*APPLIED TIME SERIES ANALYSIS WITH R*, W. Woodward, H. Gray, A. Elliott. Taylor
    & Francis Group, LLC. 2017.'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä½¿ç”¨Rè¿›è¡Œåº”ç”¨æ—¶é—´åºåˆ—åˆ†æ*ï¼ŒW. Woodward, H. Gray, A. Elliott. Taylor & Francis Group, LLC.
    2017.'
- en: Box, G. E. P., Jenkins, G. M. and Reinsel, G. C. (1976) *Time Series Analysis,
    Forecasting and Control*. Third Edition. Holden-Day. Series G.
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Box, G. E. P., Jenkins, G. M. å’Œ Reinsel, G. C. (1976) *æ—¶é—´åºåˆ—åˆ†æã€é¢„æµ‹ä¸æ§åˆ¶*ã€‚ç¬¬ä¸‰ç‰ˆã€‚Holden-Day.
    ç³»åˆ— G.
- en: Brownlee, J, (2017) *Simple Time Series Forecasting Models to Test So That You
    Donâ€™t Fool* *Yourself* ([https://machinelearningmastery.com/simple-time-series-forecasting-models/](https://machinelearningmastery.com/simple-time-series-forecasting-models/)).
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Brownlee, J, (2017) *ç®€å•æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ä»¥æµ‹è¯•æ‚¨ä¸è¦æ¬ºéª—è‡ªå·±* ([https://machinelearningmastery.com/simple-time-series-forecasting-models/](https://machinelearningmastery.com/simple-time-series-forecasting-models/)).
