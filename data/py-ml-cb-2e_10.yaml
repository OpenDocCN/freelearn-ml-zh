- en: Analyzing Image Content
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析图像内容
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下食谱：
- en: Operating on images using OpenCV-Python
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用OpenCV-Python操作图像
- en: Detecting edges
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测边缘
- en: Histogram equalization
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直方图均衡化
- en: Detecting corners
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测角点
- en: Detecting SIFT feature points
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测SIFT特征点
- en: Building a Star feature detector
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建星特征检测器
- en: Creating features using Visual Codebook and vector quantization
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用视觉代码簿和向量量化创建特征
- en: Training an image classifier using Extremely Random Forests
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用超随机森林训练图像分类器
- en: Building an object recognizer
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建物体识别器
- en: Using LightGBM for image classification
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LightGBM进行图像分类
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To go through the recipes in this chapter, you need the following files (available
    on GitHub):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要浏览本章的食谱，你需要以下文件（可在GitHub上找到）：
- en: '`operating_on_images.py`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`operating_on_images.py`'
- en: '`capri.jpg`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`capri.jpg`'
- en: '`edge_detector.py`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`edge_detector.py`'
- en: '`chair.jpg`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chair.jpg`'
- en: '`histogram_equalizer.py`'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`histogram_equalizer.py`'
- en: '`sunrise.jpg`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sunrise.jpg`'
- en: '`corner_detector.py`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`corner_detector.py`'
- en: '`box.png`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`box.png`'
- en: '`feature_detector.py`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature_detector.py`'
- en: '`table.jpg`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`table.jpg`'
- en: '`star_detector.py`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`star_detector.py`'
- en: '`trainer.py`'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainer.py`'
- en: '`object_recognizer.py`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`object_recognizer.py`'
- en: '`LightgbmClassifier.py`'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LightgbmClassifier.py`'
- en: Introducing computer vision
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍计算机视觉
- en: '**Computer vision** is a field that studies how to process, analyze, and understand
    the contents of visual data. In image content analysis, we use a lot of computer
    vision algorithms to build our understanding of the objects in the image. Computer
    vision covers various aspects of image analysis, such as object recognition, shape
    analysis, pose estimation, 3D modeling, visual search, and so on. Humans are really
    good at identifying and recognizing things around them! The ultimate goal of computer
    vision is to accurately model the human vision system using computers.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算机视觉**是一个研究如何处理、分析和理解视觉数据内容的领域。在图像内容分析中，我们使用大量的计算机视觉算法来构建我们对图像中对象的了解。计算机视觉涵盖了图像分析的各个方面，如物体识别、形状分析、姿态估计、3D建模、视觉搜索等。人类在识别和识别周围事物方面非常出色！计算机视觉的最终目标是使用计算机准确模拟人类的视觉系统。'
- en: Computer vision consists of various levels of analysis. In low-level vision,
    we deal with pixel-processing tasks, such as **edge detection**, **morphological
    processing**, and **optical flow**. In middle-level and high-level vision, we
    deal with things such as **object recognition**, **3D modeling**, **motion analysis**,
    and various other aspects of visual data. As we go higher, we tend to delve deeper
    into the conceptual aspects of our visual system and try to extract a description
    of visual data, based on activities and intentions. One thing to note is that
    higher levels tend to rely on the outputs of the lower levels for analysis.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉包括多个分析层次。在低级视觉中，我们处理像素处理任务，例如**边缘检测**、**形态处理**和**光流**。在中级和高级视觉中，我们处理诸如**物体识别**、**3D建模**、**运动分析**以及视觉数据的各个方面。随着层次的提高，我们倾向于深入探讨视觉系统的概念性方面，并尝试根据活动和意图提取视觉数据的描述。需要注意的是，高级层次往往依赖于低级层次的输出进行分析。
- en: 'One of the most common questions here is this: how is computer vision different
    than image processing? **Image processing** studies image transformations at the
    pixel level. Both the input and output of an image processing system are images.
    Some common examples are edge detection, **histogram equalization**, and **image
    compression**. Computer vision algorithms heavily rely on image processing algorithms
    to perform their duties. In computer vision, we deal with more complex things
    that include understanding the visual data at a conceptual level. The reason for
    this is that we want to construct meaningful descriptions of the objects in the
    images. The output of a computer vision system is an interpretation of the 3D
    scene in the given image. This interpretation can come in various forms, depending
    on the task at hand.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这里最常见的问题之一是：计算机视觉与图像处理有何不同？**图像处理**研究像素级别的图像变换。图像处理系统的输入和输出都是图像。一些常见的例子包括边缘检测、**直方图均衡化**和**图像压缩**。计算机视觉算法在很大程度上依赖于图像处理算法来执行其任务。在计算机视觉中，我们处理更复杂的事情，包括在概念层面上理解视觉数据。这样做的原因是我们想要构建图像中对象的具有意义的描述。计算机视觉系统的输出是对给定图像中3D场景的解释。这种解释可以以各种形式出现，具体取决于任务。
- en: Operating on images using OpenCV-Python
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用OpenCV-Python操作图像
- en: In this chapter, we will use a library called **Open Source Computer Vision
    Library** (**OpenCV**), to analyze images. OpenCV is the world's most popular
    library for computer vision. As it has been highly optimized for many different
    platforms, it has become the de facto standard in the industry. Before you proceed,
    make sure that you install the library with Python support. You can download and
    install OpenCV at [http://opencv.org](http://opencv.org). For detailed installation
    instructions on various operating systems, you can refer to the documentation
    section on the website.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用一个名为**开源计算机视觉库**（**OpenCV**）的库来分析图像。OpenCV是世界上最受欢迎的计算机视觉库。由于它针对许多不同的平台进行了高度优化，因此已成为行业中的事实标准。在继续之前，请确保您已安装具有Python支持的库。您可以从[http://opencv.org](http://opencv.org)下载并安装OpenCV。有关各种操作系统的详细安装说明，您可以参考网站上的文档部分。
- en: Getting ready
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will take a look at how to operate on images using OpenCV-Python.
    In this recipe, we will look at how to load and display an image. We will also
    look at how to crop, resize, and save an image to an output file.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将探讨如何使用OpenCV-Python操作图像。在本食谱中，我们将查看如何加载和显示图像。我们还将查看如何裁剪、调整大小并将图像保存到输出文件中。
- en: How to do it...
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s see how we can operate on images using OpenCV-Python:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用OpenCV-Python操作图像：
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `operating_on_images.py` file that is provided for you):'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件，并导入以下包（完整的代码在提供的`operating_on_images.py`文件中给出）：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Specify the input image as the first argument to the file, and read it using
    the image read function. We will use the `forest.jpg` file that is provided to
    you, as follows:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入图像指定为文件的第一个参数，并使用图像读取函数读取它。我们将使用您提供的`forest.jpg`文件，如下所示：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Display the input image, as follows:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下方式显示输入图像：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will now crop this image. Extract the height and width of the input image,
    and then specify the boundaries:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将裁剪此图像。提取输入图像的高度和宽度，然后指定边界：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Crop the image using NumPy-style slicing and display it:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用NumPy风格的切片裁剪图像并显示：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Resize the image to `1.3` times its original size and display it:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像调整到原始大小的`1.3`倍并显示：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The previous method will uniformly scale the image on both dimensions. Let''s
    assume that we want to skew the image based on specific output dimensions. We
    will use the following code:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之前的方法将在两个维度上均匀缩放图像。假设我们想要根据特定的输出维度扭曲图像。我们将使用以下代码：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Save the image to an output file:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像保存到输出文件中：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `waitKey()` function displays the images until you hit a key on the keyboard.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`waitKey()`函数将显示图像，直到你在键盘上按下一个键。'
- en: 'We will run the code in a Terminal window:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在终端窗口中运行此代码：
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You will see the following four images on the screen (*Capri''s Faraglioni
    (Italy)*):'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在屏幕上看到以下四幅图像（*意大利卡普里岛的法拉乔尼*）：
- en: '![](img/7512e226-cd6e-4f44-8a58-f924d96d324e.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7512e226-cd6e-4f44-8a58-f924d96d324e.png)'
- en: How it works...
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In this recipe, we learned how to operate on images using the OpenCV-Python
    library. The following tasks were performed:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们学习了如何使用OpenCV-Python库操作图像。以下任务被执行：
- en: Loading and displaying an image
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载和显示图像
- en: Cropping an image
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 裁剪图像
- en: Resizing an image
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整图像大小
- en: Saving an image
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存图像
- en: There's more…
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: OpenCV is a free software library that was originally developed by Intel and
    the Nizhny Novgorod research center in Russia. Later, it was maintained by Willow
    Garage and is now maintained by Itseez. The programming language that's mainly
    used to develop with this library is C ++, but it is also possible to interface
    through C, Python, and Java.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV是一个由英特尔和俄罗斯下诺夫哥罗德研究中心最初开发的免费软件库。后来，它由Willow Garage维护，现在由Itseez维护。主要用于与该库一起开发的编程语言是C++，但也可以通过C、Python和Java进行接口。
- en: See also
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Refer to the official documentation of the OpenCV library at [http://opencv.org](http://opencv.org)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参阅OpenCV库的官方文档[http://opencv.org](http://opencv.org)
- en: Refer to the OpenCV tutorials at [https://docs.opencv.org/2.4/opencv_tutorials.pdf](https://docs.opencv.org/2.4/opencv_tutorials.pdf)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请参阅OpenCV教程[https://docs.opencv.org/2.4/opencv_tutorials.pdf](https://docs.opencv.org/2.4/opencv_tutorials.pdf)
- en: Detecting edges
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测边缘
- en: '**Edge detection** is one of the most popular techniques in computer vision.
    It is used as a preprocessing step in many applications. With edge detection,
    you can mark points in a digital image where light intensity suddenly changes.
    The sudden changes in the properties of an image want to highlight important events
    or changes in the physical world of which the images are representations. These
    changes identify, for example, surface orientation discontinuities, depth discontinuities,
    and so on.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**边缘检测**是计算机视觉中最受欢迎的技术之一。它被用作许多应用的前处理步骤。通过边缘检测，你可以在数字图像中标记光强度突然变化的位置。图像属性的突然变化旨在突出重要的物理世界事件或变化，这些图像是这些事件或变化的表示。这些变化确定了，例如，表面方向不连续性、深度不连续性等。'
- en: Getting ready
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备中
- en: In this recipe, we will learn how to use different edge detectors to detect
    edges in the input image.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将学习如何使用不同的边缘检测器来检测输入图像中的边缘。
- en: How to do it...
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s see how we can detect edges:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何检测边缘：
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `edge_detector.py` file that is provided for you):'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件，并导入以下包（完整的代码在提供的`edge_detector.py`文件中给出）：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Load the input image. We will use `chair.jpg`:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载输入图像。我们将使用`chair.jpg`：
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Extract the height and width of the image:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取图像的高度和宽度：
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The **Sobel filter** is a type of edge detector that uses a 3 x 3 kernel to
    detect horizontal and vertical edges separately:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**索贝尔滤波器**是一种边缘检测器，它使用一个3 x 3核分别检测水平和垂直边缘：'
- en: '[PRE12]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Run the vertical Sobel detector:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行垂直索贝尔检测器：
- en: '[PRE13]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The **Laplacian edge detector** detects edges in both directions. We use it
    as follows:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**拉普拉斯边缘检测器**可以在两个方向上检测边缘。我们使用它如下：'
- en: '[PRE14]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Even though Laplacian addresses the shortcomings of Sobel, the output is still
    very noisy. The **Canny edge detector** outperforms all of them because of the
    way it treats the problem. It is a multistage process, and it uses hysteresis
    to come up with clean edges:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽管拉普拉斯解决了索贝尔的不足，但输出仍然非常嘈杂。**Canny边缘检测器**由于处理问题的方法而优于所有这些，它是一个多阶段过程，并使用滞后性来得到干净的边缘：
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Display all the output images:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示所有输出图像：
- en: '[PRE16]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We will run the code in the terminal window using the following command:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在终端窗口中使用以下命令运行代码：
- en: '[PRE17]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You will see the following five images on the screen (*The ancient theatre
    of Siracusa (Italy)*):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在屏幕上看到以下五张图像（*意大利西西里岛的古代剧院*）：
- en: '![](img/308073ff-013c-4bb3-a8a5-cb2b1cac353e.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/308073ff-013c-4bb3-a8a5-cb2b1cac353e.png)'
- en: At the top of the screenshot is the original image, the horizontal Sobel edge
    detector output, and the vertical Sobel edge detector output. Note how the detected
    lines tend to be vertical. This is due to the fact that it's a horizontal edge
    detector, and it tends to detect changes in this direction. At the bottom of the
    screenshot is the Laplacian edge detector output and the Canny edge detector,
    which detects all the edges nicely.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 截图顶部是原始图像、水平索贝尔边缘检测器输出和垂直索贝尔边缘检测器输出。注意检测到的线条倾向于垂直。这是因为它是一个水平边缘检测器，并且倾向于检测这个方向的变化。截图底部是拉普拉斯边缘检测器输出和Canny边缘检测器，它很好地检测到了所有边缘。
- en: How it works...
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The Sobel operator is a differential operator, which calculates an approximate
    value of the gradient of a function that represents the brightness of the image.
    At each point in the image, the Sobel operator can correspond to the gradient
    vector or to the norm of that vector. The algorithm that's used by the Sobel operator
    is based on the convolution of the image with a filter, separated and of integer
    value, applied both in the vertical and horizontal direction, and is therefore
    economical in terms of the calculation power required.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 索贝尔算子是一个微分算子，它计算表示图像亮度的函数梯度的近似值。在图像的每个点上，索贝尔算子可以对应于梯度向量或该向量的范数。索贝尔算子使用的算法是基于图像与一个分离的、整数值的滤波器的卷积，这个滤波器在垂直和水平方向上应用，因此在计算能力方面是经济的。
- en: The Laplacian edge detector is part of the zero-crossing methods that look for
    points where the second-order derivative goes through zero, which is usually the
    Laplacian function or a differential expression of a non-linear function.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 拉普拉斯边缘检测器是零交叉方法的一部分，它寻找二阶导数穿过零的点，这通常是拉普拉斯函数或非线性函数的微分表达式。
- en: There's more…
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多...
- en: The Canny algorithm uses a multi-stage calculation method to find outlines of
    many of the types that are normally present in real images. To do this, the algorithm
    must identify and mark as many contours as possible in the image good location.
    Furthermore, the marked contours must be as close as possible to the real contours
    of the image. Finally, a given image contour must be marked only once, and if
    possible, the noise that's present in the image must not cause the detection of
    false contours.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Canny算法使用多阶段计算方法来寻找真实图像中通常存在的许多类型的轮廓。为此，算法必须尽可能多地识别和标记图像中的良好位置。此外，标记的轮廓必须尽可能接近图像的真实轮廓。最后，给定的图像轮廓只能标记一次，并且如果可能的话，图像中存在的噪声不应导致检测到错误的轮廓。
- en: See also
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Sobel Operator*: [http://www.tutorialspoint.com/dip/sobel_operator.htm](http://www.tutorialspoint.com/dip/sobel_operator.htm)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Sobel算子*：[http://www.tutorialspoint.com/dip/sobel_operator.htm](http://www.tutorialspoint.com/dip/sobel_operator.htm)'
- en: '*Laplacian edge detector*: [http://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm](http://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*拉普拉斯边缘检测器*：[http://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm](http://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm)'
- en: '*Canny edge detector*: [http://homepages.inf.ed.ac.uk/rbf/HIPR2/canny.htm](http://homepages.inf.ed.ac.uk/rbf/HIPR2/canny.htm)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Canny边缘检测器*：[http://homepages.inf.ed.ac.uk/rbf/HIPR2/canny.htm](http://homepages.inf.ed.ac.uk/rbf/HIPR2/canny.htm)'
- en: '*Most Common Edge Detectors* (from the University of Minnesota): [http://me.umn.edu/courses/me5286/vision/Notes/2015/ME5286-Lecture7.pdf](http://me.umn.edu/courses/me5286/vision/Notes/2015/ME5286-Lecture7.pdf)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*最常见的边缘检测器*（来自明尼苏达大学）：[http://me.umn.edu/courses/me5286/vision/Notes/2015/ME5286-Lecture7.pdf](http://me.umn.edu/courses/me5286/vision/Notes/2015/ME5286-Lecture7.pdf)'
- en: Histogram equalization
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 直方图均衡化
- en: '**Histogram equalization** is the process of modifying the intensities of the
    image pixels to enhance the image''s contrast. The human eye likes contrast! This
    is the reason why almost all camera systems use histogram equalization to make
    images look nice.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**直方图均衡化**是修改图像像素强度以增强图像对比度的过程。人眼喜欢对比度！这就是为什么几乎所有的相机系统都使用直方图均衡化来使图像看起来很棒。'
- en: Getting ready
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The interesting thing is that the histogram equalization process is different
    for grayscale and color images. There's a catch when dealing with color images,
    and we'll see it in this recipe. Let's see how to do it.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，直方图均衡化过程对于灰度图像和彩色图像是不同的。处理彩色图像时有一个陷阱，我们将在本食谱中看到它。让我们看看如何做到这一点。
- en: How to do it...
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s see how we can perform histogram equalization:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何执行直方图均衡化：
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `histogram_equalizer.py` file that is provided for you):'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在提供的`histogram_equalizer.py`文件中给出）：
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Load the input image. We will use the `sunrise.jpg` image:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载输入图像。我们将使用`sunrise.jpg`图像：
- en: '[PRE19]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Convert the image into `grayscale` and display it:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像转换为`灰度`并显示：
- en: '[PRE20]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Equalize the histogram of the `grayscale` image and display it:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 均衡`灰度`图像的直方图并显示：
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'OpenCV loads images in the `BGR` format by default, so let''s convert it from
    `BGR` into `YUV` first:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenCV默认以`BGR`格式加载图像，所以让我们首先将其从`BGR`转换为`YUV`：
- en: '[PRE22]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Equalize the Y channel, as follows:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式均衡Y通道：
- en: '[PRE23]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Convert it back into `BGR`:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其转换回`BGR`：
- en: '[PRE24]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Display the input and output images:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示输入和输出图像：
- en: '[PRE25]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We will run the code in a terminal window:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在终端窗口中运行代码：
- en: '[PRE26]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You will see the following four images on the screen (*the medieval city of
    Gubbio (Italy)*):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在屏幕上看到以下四幅图像（*意大利古比奥的中世纪城市*）：
- en: '![](img/e409691b-5e34-4d71-92a1-08eaa439ba53.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e409691b-5e34-4d71-92a1-08eaa439ba53.png)'
- en: How it works...
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Histogram equalization is a digital image processing method with which you can
    calibrate the contrast using the image histogram. Histogram equalization increases
    the general contrast of many images, particularly when the usable image data is
    represented by very close intensity values. With this adaptation, intensities
    can be better distributed on the histogram. In this way, the areas with low local
    contrast obtain a greater contrast. The equalization of the histogram is achieved
    by spreading most of the values of frequent intensity.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图均衡化是一种数字图像处理方法，您可以使用图像直方图来校准对比度。直方图均衡化增加了许多图像的总体对比度，尤其是在可用图像数据由非常接近的强度值表示时。通过这种适应，强度可以在直方图上更好地分布。这样，局部对比度低的区域可以获得更大的对比度。直方图均衡是通过扩展频繁强度的大多数值来实现的。
- en: There's more…
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: To equalize the histogram of the color images, we need to follow a different
    procedure. Histogram equalization only applies to the intensity channel. An RGB
    image consists of three color channels, and we cannot apply the histogram equalization
    process on these channels separately. We need to separate the intensity information
    from the color information before we do anything. So, we convert it into a YUV
    colorspace first, equalize the Y channel, and then convert it back into RGB to
    get the output.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了均衡彩色图像的直方图，我们需要遵循不同的步骤。直方图均衡化仅适用于强度通道。RGB图像由三个颜色通道组成，我们不能单独对这些通道应用直方图均衡化过程。在我们做任何事情之前，我们需要将强度信息从颜色信息中分离出来。因此，我们首先将其转换为YUV颜色空间，然后均衡Y通道，最后将其转换回RGB以获得输出。
- en: See also
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Contrast Enhancement* (from the Polytechnic University, Brooklyn): [http://eeweb.poly.edu/~yao/EL5123/lecture3_contrast_enhancement.pdf](http://eeweb.poly.edu/~yao/EL5123/lecture3_contrast_enhancement.pdf)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*对比度增强*（来自布鲁克林理工学院）：[http://eeweb.poly.edu/~yao/EL5123/lecture3_contrast_enhancement.pdf](http://eeweb.poly.edu/~yao/EL5123/lecture3_contrast_enhancement.pdf)'
- en: '*YUV Colorspace*: [http://softpixel.com/~cwright/programming/colorspace/yuv/](http://softpixel.com/~cwright/programming/colorspace/yuv/)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*YUV颜色空间*：[http://softpixel.com/~cwright/programming/colorspace/yuv/](http://softpixel.com/~cwright/programming/colorspace/yuv/)'
- en: Detecting corners
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测角点
- en: '**Corner detection** is an important process in computer vision. It helps us
    identify the salient points in the image. This was one of the earliest feature
    extraction techniques that was used to develop image analysis systems.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**角点检测**是计算机视觉中的一个重要过程。它帮助我们识别图像中的显著点。这是最早用于开发图像分析系统的特征提取技术之一。'
- en: Getting ready
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will learn how to detect the corner of a box by placing markers
    at the points that are identified.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将学习如何通过在识别的点放置标记来检测盒子的角点。
- en: How to do it...
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s see how we can detect corners:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何检测角点：
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `corner_detector.py` file that is provided for you):'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在提供的`corner_detector.py`文件中给出）：
- en: '[PRE27]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Load the input image. We will use `box.png`:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载输入图像。我们将使用`box.png`：
- en: '[PRE28]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Convert the image into `grayscale` and cast it to floating-point values. We
    need the floating-point values for the corner detector to work:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像转换为`灰度`并转换为浮点值。我们需要浮点值以便角点检测器工作：
- en: '[PRE29]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Run the `Harris corner detector` function on the `grayscale` image:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`灰度`图像上运行`Harris角点检测器`函数：
- en: '[PRE30]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'To mark the corners, we need to dilate the image, as follows:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了标记角点，我们需要膨胀图像，如下所示：
- en: '[PRE31]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let''s threshold the image to display the important points:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们阈值化图像以显示重要点：
- en: '[PRE32]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Display the output image:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示输出图像：
- en: '[PRE33]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We will run the code in a terminal window:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在终端窗口中运行代码：
- en: '[PRE34]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You will see the following two images on the screen:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在屏幕上看到以下两个图像：
- en: '![](img/fb0530af-e029-465d-b6a7-900e99e5a7b3.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fb0530af-e029-465d-b6a7-900e99e5a7b3.png)'
- en: How it works...
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Corner detection is an approach that's used in computer vision to extract types
    of features and infer the contents of the image. It is often used in motion detection,
    image recording, video tracking, image mosaicization, image panoramas creation,
    3D modeling, and object recognition. It is a topic similar to the detection of
    points of interest.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 角点检测是计算机视觉中用于提取特征类型并推断图像内容的方法。它常用于运动检测、图像记录、视频跟踪、图像拼接、图像全景创建、3D建模和物体识别。它是一个与兴趣点检测类似的话题。
- en: There's more…
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: 'Corner detection methods can be subdivided into two groups:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 角点检测方法可以分为两组：
- en: Techniques based on the extraction of the contours and the subsequent identification
    of the points corresponding to the maximum curvature, or where the edge segments
    intersect
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于提取轮廓和随后识别对应于最大曲率或边缘段相交点的技术的技巧
- en: Algorithms that search for corners directly from the intensity of the gray levels
    of the image pixels
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接从图像像素的灰度强度中搜索角点的算法
- en: See also
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Harris Corner Detector* (from Penn State University): [http://www.cse.psu.edu/~rtc12/CSE486/lecture06.pdf](http://www.cse.psu.edu/~rtc12/CSE486/lecture06.pdf)'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Harris角点检测器*（来自宾夕法尼亚州立大学）：[http://www.cse.psu.edu/~rtc12/CSE486/lecture06.pdf](http://www.cse.psu.edu/~rtc12/CSE486/lecture06.pdf)'
- en: 'The official documentation of the Harris corner detector: [https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html)'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Harris角检测器的官方文档：[https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html)
- en: Detecting SIFT feature points
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测SIFT特征点
- en: '**Scale invariant feature transform** (**SIFT**) is one of the most popular
    features in the field of computer vision. David Lowe first proposed this in his
    seminal paper. It has since become one of the most effective features to use for
    image recognition and content analysis. It is robust against scale, orientation,
    intensity, and so on. This forms the basis of our object recognition system.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**尺度不变特征变换**（**SIFT**）是计算机视觉领域最受欢迎的特征之一。David Lowe在他的开创性论文中首次提出了这一概念。它已经成为用于图像识别和内容分析的最有效的特征之一。它对尺度、方向、强度等因素具有鲁棒性。这构成了我们物体识别系统的基础。'
- en: Getting ready
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will learn how to detect SIFT feature points.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将学习如何检测SIFT特征点。
- en: How to do it...
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how we can detect SIFT feature points:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何检测SIFT特征点：
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `feature_detector.py` file that is provided for you):'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在提供的`feature_detector.py`文件中给出）：
- en: '[PRE35]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Load the input image. We will use `table.jpg`:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载输入图像。我们将使用`table.jpg`：
- en: '[PRE36]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Convert this image into grayscale:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此图像转换为灰度：
- en: '[PRE37]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Initialize the SIFT detector object and extract the keypoints:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化SIFT检测器对象并提取关键点：
- en: '[PRE38]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The keypoints are the salient points, but they are not the features. This basically
    gives us the location of the salient points. SIFT also functions as a very effective
    feature extractor.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关键点是显著点，但它们不是特征。这基本上给出了显著点的位置。SIFT还充当一个非常有效的特征提取器。
- en: 'Draw the keypoints on top of the input image, as follows:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式在输入图像上绘制关键点：
- en: '[PRE39]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Display the input and output images:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示输入和输出图像：
- en: '[PRE40]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We will run this in a terminal window:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在终端窗口中运行此代码：
- en: '[PRE41]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'You will see the following two images on the screen:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在屏幕上看到以下两个图像：
- en: '![](img/d879a540-7db8-4d25-bdfb-e9fcd02cef02.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d879a540-7db8-4d25-bdfb-e9fcd02cef02.png)'
- en: How it works...
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: For each object in an image, some interesting points are extracted to provide
    a description of the characteristics of the object. This feature, obtained from
    an image selected for training, is used to identify the object when trying to
    locate it in a test image that contains many other objects. To obtain a reliable
    recognition, the features that are extracted from the training image must be detectable,
    even with scale variations, noise, and lighting. These points are usually placed
    in high-contrast regions of the image, such as object contours.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像中的每个对象，都会提取一些有趣的点来描述对象的特点。这个从训练图像中获得的特征，用于在包含许多其他对象的测试图像中定位对象时识别对象。为了获得可靠的识别，从训练图像中提取的特征必须可检测，即使存在尺度变化、噪声和光照。这些点通常放置在图像的高对比度区域，如对象轮廓。
- en: There's more…
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In Lowe's method, the key points of the SIFT objects are extracted from a set
    of reference images in the first phase and then they are stored in a database.
    The recognition of the object in a new image takes place by individually comparing
    each characteristic of the new image with the database that was obtained previously
    and looking for features based on the Euclidean distance of their feature vectors.
    From the complete set of matches in the new image, subsets of key points are identified that
    agree with the object and its position, scale, and orientation to filter the best
    matches.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在Lowe的方法中，SIFT对象的特征点在第一阶段从一组参考图像中提取出来，然后它们被存储在数据库中。在新的图像中识别对象是通过将新图像的每个特征与之前获得的数据库中的特征逐一比较，并基于特征向量的欧几里得距离寻找特征来实现的。从新图像中的完整匹配集中，识别出与对象及其位置、尺度、方向一致的关键点子集，以过滤出最佳匹配。
- en: See also
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Introduction to SIFT (Scale-Invariant Feature Transform)*: [https://docs.opencv.org/3.4/d5/d3c/classcv_1_1xfeatures2d_1_1SIFT.html](https://docs.opencv.org/3.4/d5/d3c/classcv_1_1xfeatures2d_1_1SIFT.html)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SIFT（尺度不变特征变换）简介*：[https://docs.opencv.org/3.4/d5/d3c/classcv_1_1xfeatures2d_1_1SIFT.html](https://docs.opencv.org/3.4/d5/d3c/classcv_1_1xfeatures2d_1_1SIFT.html)'
- en: 'The official documentation of the `OpenCV.xfeatures2d.SIFT` function: [https://docs.opencv.org/3.4/d5/d3c/classcv_1_1xfeatures2d_1_1SIFT.html](https://docs.opencv.org/3.4/d5/d3c/classcv_1_1xfeatures2d_1_1SIFT.html)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OpenCV.xfeatures2d.SIFT` 函数的官方文档：[https://docs.opencv.org/3.4/d5/d3c/classcv_1_1xfeatures2d_1_1SIFT.html](https://docs.opencv.org/3.4/d5/d3c/classcv_1_1xfeatures2d_1_1SIFT.html)'
- en: '*Distinctive Image Features from Scale-Invariant Keypoints* (by David G Lowe
    from the University of British Columbia): [https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*从尺度不变关键点中提取的显著图像特征*（由不列颠哥伦比亚大学的David G Lowe撰写）：[https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)'
- en: Building a Star feature detector
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建星形特征检测器
- en: The SIFT feature detector is good in many cases. However, when we build object
    recognition systems, we may want to use a different feature detector before we
    extract features using SIFT. This will give us the flexibility to cascade different
    blocks to get the best possible performance.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: SIFT特征检测器在许多情况下都很好。然而，当我们构建对象识别系统时，我们可能在提取SIFT特征之前想要使用不同的特征检测器。这将给我们提供灵活性，以级联不同的块以获得最佳性能。
- en: Getting ready
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use the** S****tar** **feature detector** to detect
    features from an image.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用**S****tar** **特征检测器**从图像中检测特征。
- en: How to do it...
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how we can build a Star feature detector:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何构建一个星形特征检测器：
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `star_detector.py` file that is provided for you):'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在提供的`star_detector.py`文件中给出）：
- en: '[PRE42]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Define a class to handle all the functions that are related to Star feature
    detection:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个类来处理与星形特征检测相关的所有函数：
- en: '[PRE43]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Define a function to run the detector on the input image:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来在输入图像上运行检测器：
- en: '[PRE44]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Load the input image in the `main` function. We will use `table.jpg`:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`main`函数中加载输入图像。我们将使用`table.jpg`：
- en: '[PRE45]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Convert the image into grayscale:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像转换为灰度：
- en: '[PRE46]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Detect features using the Star feature detector:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用星形特征检测器检测特征：
- en: '[PRE47]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Draw keypoints on top of the input image:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在输入图像上绘制关键点：
- en: '[PRE48]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Display the output image:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示输出图像：
- en: '[PRE49]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We will run the code in a terminal window:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在终端窗口中运行代码：
- en: '[PRE50]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'You will see the following image on the screen:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在屏幕上看到以下图像：
- en: '![](img/f32de3b7-9417-4bc7-808e-ed23ada7d6d2.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f32de3b7-9417-4bc7-808e-ed23ada7d6d2.png)'
- en: How it works...
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In this recipe, we learned how to use the OpenCV-Python library to build a
    Star feature detector. The following tasks were performed:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们学习了如何使用OpenCV-Python库构建星形特征检测器。以下任务被执行了：
- en: Loading an image
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载图像
- en: Converting to grayscale
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换为灰度
- en: Detecting features using the Star feature detector
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用星形特征检测器检测特征
- en: Drawing keypoints and displaying the image
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绘制关键点和显示图像
- en: There's more…
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: 'The **Star function detector** is based on **CenSurE** (**Center Surrounded
    Extrema**). The differences between the two detectors lie in the choice of polygons:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '**Star函数检测器**基于**CenSurE**（**中心周围极值**）。两个检测器之间的区别在于多边形的选取：'
- en: CenSurE uses square, hexagons, and octagons as an alternative to the circle
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CenSurE使用正方形、六边形和八边形作为圆形的替代品
- en: 'Star approximates the circle with two superimposed squares: one vertical and
    one rotated 45 degrees'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星形通过两个叠加的正方形来近似圆形：一个垂直和一个旋转45度
- en: See also
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考内容
- en: 'The official documentation of OpenCV: [https://docs.opencv.org/2.4/modules/features2d/doc/common_interfaces_of_feature_detectors.html?highlight=fast%20feature#StarFeatureDetector%20:%20public%20FeatureDetector](https://docs.opencv.org/2.4/modules/features2d/doc/common_interfaces_of_feature_detectors.html?highlight=fast%20feature#StarFeatureDetector%20:%20public%20FeatureDetector)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV的官方文档：[https://docs.opencv.org/2.4/modules/features2d/doc/common_interfaces_of_feature_detectors.html?highlight=fast%20feature#StarFeatureDetector%20:%20public%20FeatureDetector](https://docs.opencv.org/2.4/modules/features2d/doc/common_interfaces_of_feature_detectors.html?highlight=fast%20feature#StarFeatureDetector%20:%20public%20FeatureDetector)
- en: '*CenSurE: Center Surround Extremas for Realtime Feature Detection and Matching*,
    in Computer Vision–ECCV 2008 (pp. 102-115). Springer Berlin Heidelberg: [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.465.1117&rep=rep1&type=pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.465.1117&rep=rep1&type=pdf)'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*CenSurE：用于实时特征检测和匹配的中心周围极值*，在计算机视觉–ECCV 2008（第102-115页）。Springer Berlin Heidelberg：[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.465.1117&rep=rep1&type=pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.465.1117&rep=rep1&type=pdf)'
- en: Creating features using Visual Codebook and vector quantization
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用视觉代码簿和向量量化创建特征
- en: To build an object recognition system, we need to extract feature vectors from
    each image. Each image needs to have a signature that can be used for matching.
    We use a concept called **V****isual Codebook** to build image signatures. This
    codebook is basically the dictionary that we will use to come up with a representation
    for the images in our training data image signatures set. We use **vector quantization**
    to cluster many feature points and come up with **centroids**. These centroids
    will serve as the elements of our Visual Codebook.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建一个目标识别系统，我们需要从每张图片中提取特征向量。每张图片都需要一个可以用于匹配的签名。我们使用一个叫做**V**isual Codebook的概念来构建图像签名。这个codebook基本上是我们用来为训练数据集中的图像签名提供表示的字典。我们使用**向量量化**来聚类许多特征点并得出**质心**。这些质心将作为我们Visual
    Codebook的元素。
- en: Getting ready
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will create features using Visual Codebook and vector quantization. To
    build a robust object recognition system, you need tens of thousands of images.
    There is a dataset called `Caltech256` that's very popular in this field! It contains
    256 classes of images, where each class contains thousands of samples.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用Visual Codebook和向量量化来创建特征。为了构建一个健壮的目标识别系统，你需要成千上万张图片。有一个叫做`Caltech256`的数据集在这个领域非常受欢迎！它包含256类图片，每类包含数千个样本。
- en: How to do it...
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Let''s see how we can create features using Visual Codebook and vector quantization:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用Visual Codebook和向量量化来创建特征：
- en: 'This is a lengthy recipe, so we will only look at the important functions.
    The full code is given in the `build_features.py` file that is already provided
    for you. Let''s look at the class that''s defined to extract features:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一个篇幅较长的菜谱，所以我们只看重要的函数。完整的代码在提供的`build_features.py`文件中给出。让我们看看定义用于提取特征的类：
- en: '[PRE51]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Define a method to extract features from the input image. We will use the Star
    detector to get the keypoints and then use SIFT to extract descriptors from these
    locations:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个从输入图像中提取特征的方法。我们将使用Star检测器来获取关键点，然后使用SIFT从这些位置提取描述符：
- en: '[PRE52]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We need to extract centroids from all the descriptors:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要从所有描述符中提取质心：
- en: '[PRE53]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Each image will give rise to a large number of descriptors. We will just use
    a small number of images because the centroids won''t change much after this:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每张图片都会产生大量的描述符。我们只需使用少量图片，因为质心在此之后不会变化太多：
- en: '[PRE54]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The print progress is as follows:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印进度如下：
- en: '[PRE55]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Extract the current label:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取当前标签：
- en: '[PRE56]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Read the image and resize it:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取图片并调整大小：
- en: '[PRE57]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Extract the features:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取特征：
- en: '[PRE58]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Use vector quantization to quantize the feature points. Vector quantizationis
    the *N*-dimensional version of rounding off:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用向量量化对特征点进行量化。向量量化是**N**维度的舍入：
- en: '[PRE59]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Define the class to handle the bag-of-words model and vector quantization:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个处理词袋模型和向量量化的类：
- en: '[PRE60]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Define a method to quantize the datapoints. We will use **k-means clustering**
    to achieve this:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个量化数据点的函数。我们将使用**k-means聚类**来实现这一点：
- en: '[PRE61]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Extract the centroids, as follows:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取质心，如下所示：
- en: '[PRE62]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Define a method to normalize the data:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个数据归一化的方法：
- en: '[PRE63]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Define a method to get the feature vector:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个获取特征向量的方法：
- en: '[PRE64]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Build a histogram and normalize it:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建直方图并对其进行归一化：
- en: '[PRE65]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Define a method, and then extract the SIFT features:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个方法，然后提取SIFT特征：
- en: '[PRE66]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'As we mentioned earlier, please refer to `build_features.py` for the complete
    code. You should run the code in the following way:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，请参考`build_features.py`以获取完整的代码。你应该按照以下方式运行代码：
- en: '[PRE67]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: This will generate two files called `codebook.pkl` and `feature_map.pkl`. We
    will use these files in the next recipe.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成两个文件，分别叫做`codebook.pkl`和`feature_map.pkl`。我们将在下一个菜谱中使用这些文件。
- en: How it works...
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we used a visual textbook as a dictionary, which we then used
    to create a representation for images in our image signatures, which are contained
    in the training set. So, we used vector quantization to group many characteristic
    points and create centroids. These centroids are served as elements of our visual
    textbook.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用了一个视觉教科书作为字典，然后我们使用它来为图像签名创建表示，这些图像签名包含在训练集中。因此，我们使用向量量化来分组许多特征点并创建质心。这些质心作为我们视觉教科书的元素。
- en: There's more…
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: We extract the features from various points in the image, counting the frequency
    of the values of the extracted features and classifying the image based on the
    frequency found, which is a technique that's similar to the representation of
    a document in a vector space. It is a vector quantization process with which I
    create a dictionary to discretize the possible values of the feature space.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从图像的各个点提取特征，计算提取特征的值频率，并根据找到的频率对图像进行分类，这是一种类似于在向量空间中表示文档的技术。这是一个向量量化过程，我用它创建一个字典来离散化特征空间的可能值。
- en: See also
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Visual Codebook* (by Tae-Kyun Kim, from Sidney Sussex College): [http://mi.eng.cam.ac.uk/~cipolla/lectures/PartIB/old/IB-visualcodebook.pdf](http://mi.eng.cam.ac.uk/~cipolla/lectures/PartIB/old/IB-visualcodebook.pdf)'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*视觉代码簿*（由Tae-Kyun Kim，来自西德尼·萨塞克斯学院）：[http://mi.eng.cam.ac.uk/~cipolla/lectures/PartIB/old/IB-visualcodebook.pdf](http://mi.eng.cam.ac.uk/~cipolla/lectures/PartIB/old/IB-visualcodebook.pdf)'
- en: '*Caltech-256 images repository* (from the California Institute of Technology):
    [http://www.vision.caltech.edu/Image_Datasets/Caltech256/](http://www.vision.caltech.edu/Image_Datasets/Caltech256/)'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*加州理工学院Caltech-256图像库*（来自加州理工学院）：[http://www.vision.caltech.edu/Image_Datasets/Caltech256/](http://www.vision.caltech.edu/Image_Datasets/Caltech256/)'
- en: '*Vector Quantization Overview* (from Binghamton University): [http://www.ws.binghamton.edu/fowler/fowler%20personal%20page/EE523_files/Ch_10_1%20VQ%20Description%20(PPT).pdf](http://www.ws.binghamton.edu/fowler/fowler%20personal%20page/EE523_files/Ch_10_1%20VQ%20Description%20(PPT).pdf)'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*向量量化概述*（来自宾汉顿大学）: [http://www.ws.binghamton.edu/fowler/fowler%20personal%20page/EE523_files/Ch_10_1%20VQ%20Description%20(PPT).pdf](http://www.ws.binghamton.edu/fowler/fowler%20personal%20page/EE523_files/Ch_10_1%20VQ%20Description%20(PPT).pdf)'
- en: Training an image classifier using Extremely Random Forests
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用极端随机森林训练图像分类器
- en: An object recognition system uses an image classifier to classify the images
    into known categories. **Extremely Random Forests** (**ERFs**) are very popular
    in the field of machine learning because of their speed and accuracy. This algorithm
    is based on decision trees. Their differences compared to classical decision trees
    are in the choice of the points of division of the tree. The best division to
    separate the samples of a node into two groups is done by creating random subdivisions
    for each of the randomly selected features and choosing the best division between
    those.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 一个物体识别系统使用图像分类器将图像分类到已知类别。**极端随机森林**（**ERFs**）在机器学习领域非常受欢迎，因为它们的速度和准确性。该算法基于决策树。与经典决策树相比，它们的区别在于树分割点的选择。通过为随机选择的每个特征创建随机子划分，并选择这些子划分之间的最佳分割，来完成将节点样本分割成两组的最佳分割。
- en: Getting ready
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use ERFs to train our image classifier. We basically
    construct decision trees based on our image signatures, and then train the forest
    to make the right decision.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用ERFs来训练我们的图像分类器。我们基本上基于我们的图像特征构建决策树，然后训练森林以做出正确的决策。
- en: How to do it...
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how we can train an image classifier using ERFs:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用ERFs训练图像分类器：
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `trainer.py` file that is provided for you):'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在提供的`trainer.py`文件中给出）：
- en: '[PRE68]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Define an argument parser:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个参数解析器：
- en: '[PRE69]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Define a class to handle ERF training. We will use a label encoder to encode
    our training labels:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个类来处理ERF训练。我们将使用标签编码器来编码我们的训练标签：
- en: '[PRE70]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Encode the labels and train the classifier:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对标签进行编码并训练分类器：
- en: '[PRE71]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Define a function to encode the labels:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来编码标签：
- en: '[PRE72]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Define a function to classify an unknown datapoint:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来分类未知数据点：
- en: '[PRE73]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Define the `main` function and parse the input arguments:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`main`函数并解析输入参数：
- en: '[PRE74]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Load the feature map that we created in the previous recipe:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载我们在上一个菜谱中创建的特征图：
- en: '[PRE75]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Extract the feature vectors:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取特征向量：
- en: '[PRE76]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Train the ERF, which is based on the training data:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于训练数据训练ERF：
- en: '[PRE77]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Save the trained ERF model, as follows:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式保存训练好的ERF模型：
- en: '[PRE78]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Now, you should run the code in the Terminal:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你应该在终端中运行代码：
- en: '[PRE79]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: This will generate a file called `erf.pkl`. We will use this file in the next
    recipe.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个名为`erf.pkl`的文件。我们将在下一个菜谱中使用此文件。
- en: How it works...
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we used ERFs to train our image classifier. First, we defined
    an argument parser function and a class to handle ERF training. We used a label
    encoder to encode our training labels. Then, we loaded the feature map we obtained
    in the *Creating features using Visual Codebook and vector quantization* recipe.
    So, we extracted feature vectors and the labels, and finally we trained the ERF
    classifier.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用了ERFs来训练我们的图像分类器。首先，我们定义了一个参数解析器函数和一个处理ERF训练的类。我们使用标签编码器来编码我们的训练标签。然后，我们加载了在*使用视觉代码簿和矢量量化创建特征*菜谱中获得的特征图。因此，我们提取了特征向量和标签，最后我们训练了ERF分类器。
- en: There's more…
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容…
- en: To train the image classifier, the `sklearn.ensemble.ExtraTreesClassifier` function
    was used. This function builds an extremely randomized tree classifier.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练图像分类器，使用了`sklearn.ensemble.ExtraTreesClassifier`函数。此函数构建了一个超随机树分类器。
- en: See also
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关内容
- en: 'The official documentation of the `sklearn.ensemble.ExtraTreesClassifier` function:
    [https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html#sklearn.tree.ExtraTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html#sklearn.tree.ExtraTreeClassifier)'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn.ensemble.ExtraTreesClassifier`函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html#sklearn.tree.ExtraTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html#sklearn.tree.ExtraTreeClassifier)'
- en: '*Random Forests* (by Leo Breiman and Adele Cutler, from the University of California,
    Berkeley): [https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm)'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*随机森林*（由Leo Breiman和Adele Cutler撰写，来自加州大学伯克利分校)：[https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm)'
- en: '*Extremely randomized trees* (by Pierre Geurts, Damien Ernst, and Louis Wehenkel,
    form *Machine learning Journal - Springer)*: [https://link.springer.com/content/pdf/10.1007/s10994-006-6226-1.pdf](https://link.springer.com/content/pdf/10.1007/s10994-006-6226-1.pdf)'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*超随机树*（由Pierre Geurts、Damien Ernst和Louis Wehenkel撰写，来自*机器学习杂志 - 斯普林格)*：[https://link.springer.com/content/pdf/10.1007/s10994-006-6226-1.pdf](https://link.springer.com/content/pdf/10.1007/s10994-006-6226-1.pdf)'
- en: Building an object recognizer
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建对象识别器
- en: In the previous recipe, *Training an image classifier using Extremely Random
    Forests*, we used ERFs to train our image classifier. Now that we have trained
    an ERF model, let's go ahead and build an object recognizer that can recognize
    the content of unknown images.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的菜谱*使用超随机森林训练图像分类器*中，我们使用了ERFs来训练我们的图像分类器。现在我们已经训练了一个ERF模型，让我们继续构建一个能够识别未知图像内容的对象识别器。
- en: Getting ready
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will learn how to use a trained ERF model to recognize the
    content of unknown images.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将学习如何使用训练好的ERF模型来识别未知图像的内容。
- en: How to do it...
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s see how we can build an object recognizer:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建对象识别器：
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `object_recognizer.py` file that is provided for you):'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '创建一个新的Python文件并导入以下包（完整的代码在提供的`object_recognizer.py`文件中）： '
- en: '[PRE80]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Define the argument parser:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义参数解析器：
- en: '[PRE81]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Define a class to handle the image tag extraction functions:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个类来处理图像标签提取函数：
- en: '[PRE82]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Define a function to predict the output using the trained ERF model:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，使用训练好的ERF模型来预测输出：
- en: '[PRE83]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Define the `main` function and load the input image:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`main`函数并加载输入图像：
- en: '[PRE84]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Scale the image appropriately, as follows:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 适当缩放图像，如下所示：
- en: '[PRE85]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Print the output on the terminal:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端上打印输出：
- en: '[PRE86]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Now, you should run the code in the following way:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你应该按照以下方式运行代码：
- en: '[PRE87]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: How it works...
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, we used a trained ERF model to recognize the content of unknown
    images. To do this, the algorithms discussed in the two previous recipes were
    used, namely, *Creating features using Visual Codebook and vector quantization* and *Training
    an image classifier using Extremely Random Forests.*
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用了一个训练好的ERF模型来识别未知图像的内容。为此，我们使用了前两个菜谱中讨论的算法，即*使用视觉代码簿和矢量量化创建特征*和*使用超随机森林训练图像分类器*。
- en: There's more…
  id: totrans-355
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容…
- en: A **random forest** is an aggregate classifier that is made up of many decision
    trees and outputs the class that corresponds to the output of the individual tree
    classes. The algorithm for inducing a random forest was developed by Leo Breiman
    and Adele Cutler. It is based on the creation of a broad set of classifying trees,
    each of which is proposed to classify a single plant whose characteristics of
    any nature have been evaluated. Comparing the classification proposals provided
    by each tree in the forest shows the class to attribute the plant to it is the
    one that received the most indications or votes.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机森林**是一个由许多决策树组成的聚合分类器，输出与单个树类输出相对应的类别。随机森林的诱导算法由Leo Breiman和Adele Cutler开发。它基于创建一组广泛的分类树，每棵树都旨在对单个植物进行分类，该植物任何性质的特征都已被评估。比较森林中每棵树提供的分类建议，将植物归类的类别是获得最多指示或投票的类别。'
- en: See also
  id: totrans-357
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: '*Intro to random forest* (by Anthony Anh Quoc Doan, from California State University,
    Long Beach): [https://web.csulb.edu/~tebert/teaching/lectures/551/random_forest.pdf](https://web.csulb.edu/~tebert/teaching/lectures/551/random_forest.pdf)'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*随机森林简介*（由加州州立大学长滩分校的Anthony Anh Quoc Doan编写）：[https://web.csulb.edu/~tebert/teaching/lectures/551/random_forest.pdf](https://web.csulb.edu/~tebert/teaching/lectures/551/random_forest.pdf)'
- en: Using Light GBM for image classification
  id: totrans-359
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Light GBM进行图像分类
- en: Gradient boosting is used in regression and classification problems to produce
    a predictive model in the form of a set of weak predictive models, typically decision
    trees. This methodology is similar to the boosting methods and generalizes them,
    allowing for the optimization of an arbitrary differentiable `loss` function.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度提升在回归和分类问题中用于生成一系列弱预测模型的预测模型，通常是决策树。这种方法类似于提升方法，并对其进行了推广，允许优化任意可微分的`loss`函数。
- en: The **Light Gradient Boosting Machine** (**LightGBM**) is a particular variation
    of gradient boosting, with some modifications that make it particularly advantageous.
    It is based on classification trees, but the choice of splitting the leaf at each
    step is done more effectively.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '**轻量梯度提升机**（**LightGBM**）是梯度提升的一种特定变体，经过一些修改使其特别有利。它基于分类树，但在每一步选择分割叶子节点的方式更为有效。'
- en: Getting ready
  id: totrans-362
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will learn how to use LightGBM to classify handwritten digits.
    To do this, the **Modified National Institute of Standards and Technology** (**MNIST**)
    dataset will be used. This is a large database of handwritten digits. It has a
    set of 70,000 examples of data. It is a subset of NIST's larger dataset. The digits
    are of a 28 x 28 pixel resolution and are stored in a matrix of 70,000 rows and
    785 columns; 784 columns form each pixel value from the 28 x 28 matrix, and one
    value is the actual digit. The digits have been size-normalized and centered in
    a fixed-size image.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将学习如何使用LightGBM对手写数字进行分类。为此，我们将使用**修改后的国家标准与技术研究院**（**MNIST**）数据集。这是一个包含大量手写数字的大型数据库。它包含70,000个数据示例。它是NIST更大数据集的一个子集。这些数字具有28
    x 28像素的分辨率，并存储在一个70,000行和785列的矩阵中；784列形成28 x 28矩阵中每个像素的值，一个值是实际的数字。这些数字已被尺寸归一化并居中在固定大小的图像中。
- en: How to do it...
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s see how we can use LightGBM for image classification:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用LightGBM进行图像分类：
- en: 'Create a new Python file and import the following packages (the full code is
    given in the `LightgbmClassifier.py` file that is provided for you):'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Python文件并导入以下包（完整的代码在提供的`LightgbmClassifier.py`文件中给出）：
- en: '[PRE88]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'To import the `mnist` dataset, the following code must be used:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要导入`mnist`数据集，必须使用以下代码：
- en: '[PRE89]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'The following tuples are returned:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下元组：
- en: '`XTrain`, `XTest`: A `uint8` array of grayscale image data with the (`num_samples,`
    `28, 28`) shape'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`XTrain`，`XTest`：一个形状为（`num_samples`，`28`，`28`）的灰度图像数据的`uint8`数组'
- en: '`YTrain`, `YTest`: A `uint8` array of digit labels (integers in the range 0-9)
    with the (`num_samples`) shape'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`YTrain`，`YTest`：一个形状为（`num_samples`）的数字标签（0-9范围内的整数）的`uint8`数组'
- en: 'So, each sample image consists of a 28 x 28 matrix. To reduce the dimensionality,
    we will flatten the 28 x 28 images into vectors of size 784:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，每个样本图像由一个28 x 28的矩阵组成。为了降低维度，我们将28 x 28的图像展平成大小为784的向量：
- en: '[PRE90]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'Now, we will extract from the dataset that contains the digits from 0 to 9,
    but only the first two (0 and 1) because we want to build a binary classifier.
    To do this, we will use the `numpy.where` function:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将从包含0到9数字的数据集中提取，但只提取前两个（0和1），因为我们想构建一个二元分类器。为此，我们将使用`numpy.where`函数：
- en: '[PRE91]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'We create a dataset for `lightgbm`:'
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为`lightgbm`创建了一个数据集：
- en: '[PRE92]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Now, we have to specify the model parameters as a dictionary:'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们必须将模型参数指定为字典：
- en: '[PRE93]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Let''s train the model:'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们训练模型：
- en: '[PRE94]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'Our model is now ready, so we can use it to classify the handwritten digits
    automatically. To do this, we will use the `predict()` method:'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的模式现在准备好了，我们可以用它来自动分类手写数字。为此，我们将使用`predict()`方法：
- en: '[PRE95]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Now, we can evaluate the model:'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以评估模型：
- en: '[PRE96]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'The following result is returned:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE97]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'To analyze the errors that were made in the binary classification in more detail,
    we need to compute the confusion matrix:'
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要更详细地分析二分类中犯的错误，我们需要计算混淆矩阵：
- en: '[PRE98]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The following results are returned:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE99]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Finally, we will calculate the model''s accuracy:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将计算模型的准确率：
- en: '[PRE100]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'The following result is returned:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下结果：
- en: '[PRE101]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: The model is therefore able to classify images of handwritten digits with a
    high accuracy.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，该模型能够以高精度对手写数字的图像进行分类。
- en: How it works...
  id: totrans-398
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we used LightGBM to classify handwritten digits. LightGBM is
    a particular variation of gradient boosting, with some modifications that make
    it particularly advantageous. It is based on classification trees, but the choice
    of splitting the leaf at each step is done more effectively.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们使用了LightGBM来分类手写数字。LightGBM是梯度提升的一种特定变体，经过一些修改使其特别有利。它基于分类树，但在每一步选择分裂叶子节点的方式更为有效。
- en: 'While boosting operates a tree growth in depth, LightGBM makes this choice
    by combining two criteria:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 当提升操作在深度上生长树时，LightGBM通过结合两个标准来做出这个选择：
- en: Optimization based on gradient descent
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于梯度下降的优化
- en: To avoid overfitting problems, a limit for the maximum depth is set
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了避免过拟合问题，设置了最大深度的限制
- en: This type of growth is called **leaf-wise**.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 这种增长方式被称为**叶式**。
- en: There's more…
  id: totrans-404
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Light GBM has many advantages:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: Light GBM有许多优点：
- en: The procedure that's presented is, on average, an order of magnitude faster
    than similar algorithms. This is because it does not completely grow trees, and
    it also makes use of the binning of variables (a procedure that divides these
    into sub-groups, both to speed up the calculations and as a regularization method).
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所展示的过程平均比类似算法快一个数量级。这是因为它没有完全生长树，而且还利用了变量的分箱（将变量分成子组的过程，既为了加快计算速度，也是一种正则化方法）。
- en: 'More economical use of memory: the binning procedure involves less intensive
    use of memory.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更经济的内存使用：分箱过程涉及较少的内存使用。
- en: 'Better accuracy compared to the usual boosting algorithms: since it uses a
    leaf-wise procedure, the obtained trees are more complex. At the same time, to
    avoid overfitting, a limit is placed on the maximum depth.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与常规提升算法相比，准确率更高：因为它使用叶式过程，得到的树更复杂。同时，为了避免过拟合，对最大深度进行了限制。
- en: The algorithm is easily parallelizable.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该算法易于并行化。
- en: See also
  id: totrans-410
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The official documentation of the `LightGBM` library: [https://lightgbm.readthedocs.io/en/latest/](https://lightgbm.readthedocs.io/en/latest/)
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LightGBM`库的官方文档：[https://lightgbm.readthedocs.io/en/latest/](https://lightgbm.readthedocs.io/en/latest/)'
- en: '*A Gentle Introduction to Gradient Boosting* (from Northeastern University):
    [http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf](http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf)'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《梯度提升的温和介绍》*（来自东北大学）：[http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf](http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf)'
- en: '*LightGBM: A Highly Efficient Gradient Boosting Decision Tree* (by Guolin Ke
    and others): [https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf](https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf)'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《LightGBM：高效的梯度提升决策树》*（由Guolin Ke等人撰写）：[https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf](https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf)'
