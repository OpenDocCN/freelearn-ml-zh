- en: Chapter 10. Estimating Projective Relations in Images
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章. 图像中的投影关系估计
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下食谱：
- en: Computing the fundamental matrix of an image pair
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算图像对的基本矩阵
- en: Matching images using random sample consensus
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用随机样本一致性匹配图像
- en: Computing a homography between two images
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算两张图像之间的单应性
- en: Detecting a planar target in images
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在图像中检测平面目标
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Images are generally produced using a digital camera, which captures a scene
    by projecting light going through its lens onto an image sensor. The fact that
    an image is formed by the projection of a 3D scene onto a 2D plane implies the
    existence of important relationships both between a scene and its image and between
    different images of the same scene. Projective geometry is the tool that is used
    to describe and characterize, in mathematical terms, the process of image formation.
    In this chapter, we will introduce you to some of the fundamental projective relations
    that exist in multi-view imagery and explain how these can be used in computer
    vision programming. But, before we start the recipes, let's explore the basic
    concepts related to scene projection and image formation.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图像通常是通过使用数字相机生成的，该相机通过将穿过其镜头的光线投射到图像传感器上来捕捉场景。一个图像是通过将3D场景投影到2D平面上形成的这一事实，意味着场景与其图像之间以及同一场景的不同图像之间存在重要的关系。投影几何是用于用数学术语描述和表征图像形成过程的工具。在本章中，我们将向您介绍多视图图像中存在的一些基本投影关系，并解释这些关系如何在计算机视觉编程中使用。但是，在我们开始介绍食谱之前，让我们探索与场景投影和图像形成相关的基本概念。
- en: Image formation
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像形成
- en: 'Fundamentally, the process used to produce images has not changed since the
    beginning of photography. The light coming from an observed scene is captured
    by a camera through a frontal aperture, and the captured light rays hit an image
    plane (or an image sensor) located at the back of the camera. Additionally, a
    lens is used to concentrate the rays coming from the different scene elements.
    This process is illustrated by the following figure:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，自摄影术开始以来，用于生成图像的过程并没有改变。从观察场景发出的光线通过相机的前置孔径被捕捉，捕捉到的光线射向位于相机后部的图像平面（或图像传感器）。此外，还使用一个镜头来集中来自不同场景元素的光线。这个过程如下图所示：
- en: '![Image formation](img/image_10_001.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图像形成](img/image_10_001.jpg)'
- en: 'Here, `do` is the distance from the lens to the observed object, `di` is the
    distance from the lens to the image plane, and `f` is the focal length of the
    lens. These quantities are related by the so-called **thin lens equation**:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`do` 是镜头到观察对象的距离，`di` 是镜头到图像平面的距离，`f` 是镜头的焦距。这些量通过所谓的**薄透镜方程**相关联：
- en: '![Image formation](img/B05388_10_15-2.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图像形成](img/B05388_10_15-2.jpg)'
- en: 'In computer vision, this camera model can be simplified in a number of ways.
    Firstly, we can neglect the effect of the lens by considering that we have a camera
    with an infinitesimal aperture since, in theory, this does not change the image
    appearance. (However, by doing so, we ignore the focusing effect by creating an
    image with an infinite depth of field.) In this case, therefore, only the central
    ray is considered. Secondly, since most of the time we have `do>>di`, we can assume
    that the image plane is located at the focal distance. Finally, we can note from
    the geometry of the system that the image on the plane is inverted. We can obtain
    an identical but upright image by simply positioning the image plane in front
    of the lens. Obviously, this is not physically feasible, but from a mathematical
    point of view, this is completely equivalent. This simplified model is often referred
    to as the **pinhole camera ** **model**, and it is represented as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉中，这个相机模型可以通过多种方式简化。首先，我们可以通过考虑我们有一个具有无穷小孔径的相机来忽略镜头的影响，因为从理论上讲，这不会改变图像的外观。（然而，这样做会通过创建具有无限景深图像的方式忽略聚焦效果。）在这种情况下，因此，只考虑中心光线。其次，由于大多数时候我们有
    `do>>di`，我们可以假设图像平面位于焦距处。最后，我们可以从系统的几何关系中注意到，平面上的图像是倒置的。我们可以通过简单地将图像平面放置在镜头前方来获得一个相同但正立的图像。显然，这在物理上是不切实际的，但从数学角度来看，这是完全等价的。这个简化的模型通常被称为**针孔相机模型**，如下所示：
- en: '![Image formation](img/image_10_003.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图像形成](img/image_10_003.jpg)'
- en: 'From this model, and using the law of similar triangles, we can easily derive
    the basic projective equation that relates a photographed object with its image:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个模型出发，并使用相似三角形定律，我们可以很容易地推导出将摄影物体与其图像相关联的基本投影方程：
- en: '![Image formation](img/B05388_10_16-2.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图像形成](img/B05388_10_16-2.jpg)'
- en: 'The size (`hi`) of the image of an object (of physical height `ho`) is therefore
    inversely proportional to its distance (`do`) from the camera, which is naturally
    true. In general, this relation describes where a 3D scene point will be projected
    on the image plane given the geometry of the camera. More specifically, if we
    assume that the reference frame is positioned at the focal point, then a 3D scene
    point located at position `(X,Y,Z)` will be projected onto the image plane at
    `(x,y)=(fX/Z,fY/Z)`. Here, the `Z` coordinate corresponds with the depth of the
    point (or distance to camera, denoted by `do` in the previous equation). This
    relation can be rewritten in a simple matrix form through the introduction of
    homogeneous coordinates, in which 2D points are represented by 3-vectors, and
    3D points are represented by 4-vectors (the extra coordinate is simply an arbitrary
    scale factor `s` that needs to be removed when a 2D coordinate needs to be extracted
    from a homogeneous 3-vector):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一个物体（物理高度为`ho`）的图像大小（`hi`）与其与相机距离（`do`）成反比，这是自然而然的事情。一般来说，这种关系描述了在给定相机几何形状的情况下，一个3D场景点将在图像平面上投影的位置。更具体地说，如果我们假设参考框架位于焦点处，那么位于位置`(X,Y,Z)`的3D场景点将被投影到图像平面上，即`(x,y)=(fX/Z,fY/Z)`。在这里，`Z`坐标对应于点的深度（或到相机的距离，在前面方程中用`do`表示）。通过引入齐次坐标，可以将这种关系重写为简单的矩阵形式，其中二维点由3向量表示，三维点由4向量表示（额外的坐标只是一个需要从齐次3向量中提取二维坐标时去除的任意比例因子`s`）：
- en: '![Image formation](img/B05388_10_17-1.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图像形成](img/B05388_10_17-1.jpg)'
- en: 'This `3x4` matrix is called the projection matrix. In cases where the reference
    frame is not aligned with the focal point, then rotation `r` and translation `t` matrices
    must be introduced. The role of these ones is simply to express the projected
    3D point into a camera-centric reference frame, which is as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`3x4`矩阵被称为投影矩阵。在参考框架未与焦点对齐的情况下，必须引入旋转`r`和平移`t`矩阵。这些矩阵的作用仅仅是将投影的3D点表达为以相机为中心的参考框架，如下所示：
- en: '![Image formation](img/B05388_10_18-1.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图像形成](img/B05388_10_18-1.jpg)'
- en: The first matrix of this equation is said to contain the intrinsic parameters
    of the camera (here, only the focal length, but the next chapter will introduce
    a few more intrinsic parameters). The second matrix contains the extrinsic parameters
    that are the parameters that relate the camera to the exterior world. It should
    be noted that, in practice, image coordinates are expressed in pixels while 3D
    coordinates are expressed in world measurements (for example, meters). This aspect
    will be explored in [Chapter 11](ch11.html "Chapter 11. Reconstructing 3D Scenes")
    , *Reconstructing 3D Scenes*.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 该方程的第一个矩阵据说包含相机的内在参数（在这里，只有焦距，但下一章将介绍一些更多的内在参数）。第二个矩阵包含外参数，这些参数与相机与外部世界相关。应注意的是，在实践中，图像坐标用像素表示，而3D坐标用世界测量表示（例如，米）。这一点将在[第11章](ch11.html
    "第11章。重建3D场景") *重建3D场景*中探讨。
- en: Computing the fundamental matrix of an image pair
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算图像对的基本矩阵
- en: The introductory section of this chapter presented the projective equation,
    describing how a scene point projects onto the image plane of a single camera.
    In this recipe, we will explore the projective relationship that exists between
    two images that display the same scene. These two images could have been obtained
    by moving a camera to two different locations to take pictures from two viewpoints,
    or by using two cameras, each of them taking a different picture of the scene.
    When those two cameras are separated by a rigid baseline, we use the term **stereovision**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的引言部分介绍了投影方程，描述了场景点如何投影到单台相机的图像平面上。在本食谱中，我们将探讨显示相同场景的两个图像之间存在的投影关系。这两个图像可能是通过将相机移动到两个不同的位置从两个视点拍照获得的，或者是通过使用两个相机，每个相机拍摄场景的不同图像。当这两个相机通过一个刚体基线分开时，我们使用术语**立体视觉**。
- en: Getting ready
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备中
- en: 'Let''s now consider two pinhole cameras observing a given scene point, as shown
    in the following figure:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们考虑两个小孔相机观察一个给定的场景点，如图所示：
- en: '![Getting ready](img/image_10_007.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![准备中](img/image_10_007.jpg)'
- en: We learned that we can find the image `x` of a 3D point `X` by tracing a line
    joining this 3D point with the camera's center. Conversely, the scene point that
    has its image at position **x** on the image plane can be located anywhere on
    this line in the 3D space. This implies that, if we want to find the corresponding
    point of a given image point in another image, we need to search along the projection
    of this line onto the second image plane. This imaginary line is called the **epipolar
    line** of point `x`. It defines a fundamental constraint that must satisfy two
    corresponding points; that is, the match of a given point must lie on the epipolar
    line of this point in the other view, and the exact orientation of this epipolar
    line depends on the respective position of the two cameras. In fact, the configuration
    of the set of possible epipolar lines characterizes the geometry of a two-view
    system.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们了解到，我们可以通过追踪连接3D点 `X` 和相机中心的直线来找到3D点 `X` 的图像 `x`。相反，在图像平面上具有图像位置 **x** 的场景点可以在3D空间中的这条直线上任何位置。这意味着，如果我们想在另一幅图像中找到给定图像点的对应点，我们需要沿着这条直线在第二幅图像平面上的投影进行搜索。这条想象中的直线称为点
    `x` 的**极线**。它定义了一个必须满足两个对应点的基本约束；也就是说，给定点的匹配必须位于另一视图中的该点的极线上，并且这条极线的确切方向取决于两个相机的相对位置。实际上，可能极线集的配置表征了双视图系统的几何形状。
- en: Another observation that can be made from the geometry of this two-view system
    is that all the epipolar lines pass through the same point. This point corresponds
    to the projection of one camera's center onto the other camera (points `e` and
    `e'` in the above figure). This special point is called an **epipole**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个双视图系统的几何形状中可以得出的另一个观察结果是，所有的极线都通过同一点。这一点对应于一个相机中心在另一个相机上的投影（上图中的点 `e` 和 `e'`）。这个特殊点称为**极点**。
- en: 'Mathematically, the relationship between an image point and its corresponding
    epipolar line can be expressed using a `3x3` matrix, as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，图像点与其对应极线之间的关系可以使用一个 `3x3` 矩阵来表示，如下所示：
- en: '![Getting ready](img/B05388_10_19-1.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![准备中](img/B05388_10_19-1.jpg)'
- en: In projective geometry, a 2D line is also represented by a 3-vector. It corresponds
    to the set of 2D points `(x',y')`, that satisfy the equation `l1'x'+ l2'y'+ l3'=
    0` (the prime superscript denotes that this line belongs to the second image).
    Consequently, the matrix `F`, called the fundamental matrix, maps a 2D image point
    in one view to an epipolar line in the other view.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在射影几何中，二维直线也由一个3向量表示。它对应于满足方程 `l1'x'+ l2'y'+ l3'= 0`（上标撇表示这条直线属于第二幅图像）的二维点集
    `(x',y')`。因此，称为基本矩阵的矩阵 `F` 将一个视图中的二维图像点映射到另一个视图中的极线。
- en: How to do it...
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: The fundamental matrix of an image pair can be estimated by solving a set of
    equations that involve a certain number of known matched points between the two
    images. The minimum number of such matches is seven. In order to illustrate the
    fundamental matrix estimation process, we selected seven good matches from the
    matching results of SIFT features, as presented in the previous chapter.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图像对的基本矩阵可以通过解一组方程来估计，这组方程涉及两个图像之间的一定数量的已知匹配点。这种匹配的最小数量是七个。为了说明基本矩阵估计过程，我们从上一章中展示的SIFT特征匹配结果中选择了七个良好的匹配点。
- en: 'These matches will be used to compute the fundamental matrix using the `cv::findFundamentalMat`
    OpenCV function. The image pair with its selected matches is shown here:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这些匹配将用于使用 `cv::findFundamentalMat` OpenCV 函数计算基本矩阵。显示的是具有其选定匹配的图像对：
- en: '![How to do it...](img/image_10_009.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/image_10_009.jpg)'
- en: 'These matches are stored in a `cv::DMatch` vector pointing to indexes of `cv::keypoint`
    instances. These keypoints first need to be converted into `cv::Point2f` in order
    to be used with `cv::findFundamentalMat`. An OpenCV function can be used to this
    end:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些匹配存储在一个指向 `cv::keypoint` 实例索引的 `cv::DMatch` 向量中。这些关键点首先需要转换为 `cv::Point2f`，以便与
    `cv::findFundamentalMat` 一起使用。可以使用OpenCV函数来完成此操作：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The two resulting vectors `selPoints1` and `selPoints2` contain the corresponding
    point coordinates in the two images. The `pointIndexes1` and `pointIndexes2` vectors
    contain the indexes of the keypoints to be converted. The call to the `cv::findFundamentalMat`
    function is then as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的两个向量 `selPoints1` 和 `selPoints2` 包含两个图像中对应点的坐标。`pointIndexes1` 和 `pointIndexes2`
    向量包含要转换的关键点的索引。然后对 `cv::findFundamentalMat` 函数的调用如下：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'One way to visually verify the validity of the fundamental matrix is to draw
    the epipolar lines of some selected points. Another OpenCV function allows the
    epipolar lines of a given set of points to be computed. Once these have been computed,
    they can be drawn using the `cv::line` function. The following lines of code accomplish
    these two steps (that is, computing and drawing epipolar lines on the image on
    the right from the points in the image on the left):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 验证基本矩阵有效性的一个方法是绘制一些选定点的极线。另一个OpenCV函数允许计算给定点的极线。一旦这些极线被计算出来，就可以使用`cv::line`函数来绘制。以下代码行完成了这两个步骤（即从左图中的点计算并绘制右图上的极线）：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The epipolar lines of the left image are obtained in a similar way. The following
    image shows these lines:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 左图的极线以类似的方式获得。以下图像显示了这些线：
- en: '![How to do it...](img/image_10_010.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/image_10_010.jpg)'
- en: Remember that the epipole of one image is at the intersection of all its epipolar
    lines. This one is the projection of the other camera's center. Note that the
    epipolar lines can intersect (and often do) outside of the image boundaries. In
    the case of our example, the epipole of the second image is at the location where
    the first camera would be visible if the two images were taken at the same instant.
    Note also that the results can be quite unstable when the fundamental matrix is
    computed from only seven matches. Indeed, substituting one match for another could
    lead to a significantly different set of epipolar lines.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，一个图像的极点位于所有极线的交点处。这个点是另一个相机的中心的投影。请注意，极线可以在图像边界之外相交（并且通常确实如此）。在我们的例子中，第二图像的极点位于如果两个图像在同一瞬间拍摄，第一个相机应该可见的位置。还请注意，当仅从七个匹配中计算基本矩阵时，结果可能非常不稳定。确实，用一个匹配替换另一个匹配可能会导致极线集合显著不同。
- en: How it works...
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'We previously explained that, for a point in one image, the fundamental matrix
    gives the equation of the line on which its corresponding point in the other view
    should be found. If the corresponding point of a point `(x,y)` is `(x'',y'')`,
    suppose we have `F`, the fundamental matrix, between the two views. Since `(x'',y'')`
    lies on the epipolar line given by multiplying `F` by `(x,y)` expressed in homogenous
    coordinates, we must then have the following equation:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前解释过，对于一幅图中的一个点，基本矩阵给出了另一个视图中其对应点所在线的方程。如果点`(x,y)`的对应点是`(x',y')`，假设我们有两个视图之间的基本矩阵`F`。由于`(x',y')`位于通过将`F`乘以表示为齐次坐标的`(x,y)`得到的极线上，因此我们必须有以下的方程：
- en: '![How it works...](img/B05388_10_20-1.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/B05388_10_20-1.jpg)'
- en: This equation expresses the relationship between two corresponding points and
    is known as the **epipolar constraint**. Using this equation, it becomes possible
    to estimate the entries of the matrix using known matches. Since the entries of
    the `F` matrix are given up to a scale factor, there are only eight entries to
    be estimated (the ninth one can be arbitrarily set to `1`). Each match contributes
    to one equation. Therefore, with eight known matches, the matrix can be fully
    estimated by solving the resulting set of linear equations. This is what is done
    when you use the `cv::FM_8POINT` flag with the `cv::findFundamentalMat` function.
    Note that, in this case, it is possible (and preferable) to input more than eight
    matches. The obtained over-determined system of linear equations can then be solved
    in a mean-square sense.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程表达了两个对应点之间的关系，被称为**极线约束**。使用这个方程，就可以使用已知的匹配来估计矩阵的项。由于`F`矩阵的项只给出一个比例因子，因此只有八个项需要估计（第九项可以任意设置为`1`）。每个匹配都对一个方程有贡献。因此，使用八个已知的匹配，可以通过求解得到的线性方程组来完全估计矩阵。这就是当你使用`cv::findFundamentalMat`函数的`cv::FM_8POINT`标志时所做的事情。请注意，在这种情况下，输入超过八个匹配是可能的（并且是首选的）。然后，可以在均方意义上求解得到的超定线性方程组。
- en: To estimate the fundamental matrix, an additional constraint can also be exploited.
    Mathematically, the `F` matrix maps a 2D point to a 1D pencil of lines (that is,
    lines that intersect at a common point). The fact that all these epipolar lines
    pass through this unique point (that is, the epipole) imposes a constraint on
    the matrix. This constraint reduces the number of matches required to estimate
    the fundamental matrix to seven. In mathematical terms, we say that the fundamental
    matrix has 7 degrees of freedom and is therefore of rank-2\. Unfortunately, in
    this case, the set of equations becomes nonlinear, with up to three possible solutions
    (in this case, `cv::findFundamentalMat` will return a fundamental matrix of the
    size `9x3`, that is, three `3x3` matrices stacked up). The seven-match solution
    of the `F` matrix estimation can be invoked in OpenCV by using the `cv::FM_7POINT`
    flag. This is what we did in the example in the preceding section.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了估计基础矩阵，还可以利用一个额外的约束条件。从数学上讲，`F` 矩阵将一个二维点映射到一条一维直线束（即相交于一个公共点的直线）。所有这些极线都通过这个唯一点（即极点）的事实对矩阵施加了一个约束。这个约束将估计基础矩阵所需的匹配数量减少到七个。用数学术语来说，我们说基础矩阵有7个自由度，因此是秩为2的。不幸的是，在这种情况下，方程组变得非线性，最多有三个可能的解（在这种情况下，`cv::findFundamentalMat`
    将返回一个大小为 `9x3` 的基础矩阵，即三个 `3x3` 矩阵堆叠）。可以通过在 OpenCV 中使用 `cv::FM_7POINT` 标志来调用 `F`
    矩阵估计的七个匹配解。这正是我们在上一节示例中所做的。
- en: Lastly, it should be mentioned that the choice of an appropriate set of matches
    in the image is important to obtain an accurate estimation of the fundamental
    matrix. In general, the matches should be well distributed across the images and
    include points at different depths in the scene. Otherwise, the solution will
    become unstable. In particular, the selected scene points should not be coplanar,
    as the fundamental matrix (in this case) becomes degenerated.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，应该提到的是，在图像中选择一个合适的匹配集对于获得基础矩阵的准确估计很重要。一般来说，匹配应该在图像中均匀分布，并包括场景中不同深度的点。否则，解将变得不稳定。特别是，所选的场景点不应共面，因为在这种情况下，基础矩阵（在这种情况下）将变得退化。
- en: See also
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '*Multiple View Geometry in Computer Vision*, Cambridge University Press, 2004,
    *R. Hartley* and *A. Zisserma*n, is the most complete reference on projective
    geometry in computer vision'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《计算机视觉中的多视图几何》，剑桥大学出版社，2004年，*R. Hartley* 和 *A. Zisserman*，是计算机视觉中投影几何最完整的参考书
- en: The *Matching images using random sample **consensus* recipe explains how a
    fundamental matrix can be robustly estimated from a larger match set
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《使用随机样本一致性匹配图像》菜谱解释了如何从更大的匹配集中稳健地估计基础矩阵
- en: The *Computing a homography between two images* recipe explains why a fundamental
    matrix cannot be computed when the matched points are coplanar, or are the result
    of a pure rotation
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《在两幅图像之间计算单应性》菜谱解释了为什么当匹配点共面或是由纯旋转产生的结果时，无法计算基础矩阵
- en: Matching images using random sample consensus
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用随机样本一致性匹配图像
- en: When two cameras observe the same scene, they see the same elements but under
    different viewpoints. We have already studied the feature point matching problem
    in the previous chapter. In this recipe, we come back to this problem, and we
    will learn how to exploit the epipolar constraint introduced in the previous recipe
    to match image features more reliably.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个相机观察同一个场景时，它们看到相同的元素，但处于不同的视点。我们已经在上一章研究了特征点匹配问题。在这个菜谱中，我们回到这个问题，我们将学习如何利用上一菜谱中引入的极线约束来更可靠地匹配图像特征。
- en: 'The principle that we will follow is simple: when we match feature points between
    two images, we only accept those matches that fall on corresponding epipolar lines.
    However, to be able to check this condition, the fundamental matrix must be known,
    but we need good matches to estimate this matrix. This seems to be a chicken-and-egg
    problem. However, in this recipe, we propose a solution in which the fundamental
    matrix and a set of good matches will be jointly computed.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将遵循的原则很简单：当我们在两幅图像之间匹配特征点时，我们只接受落在对应极线上的匹配。然而，为了能够检查这个条件，必须知道基础矩阵，但我们需要好的匹配来估计这个矩阵。这似乎是一个鸡生蛋的问题。然而，在这个菜谱中，我们提出了一种解决方案，其中基础矩阵和一组好的匹配将共同计算。
- en: How to do it...
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'The objective is to be able to compute a fundamental matrix and a set of good
    matches between two views. To do so, all the found feature point correspondences
    will be validated using the epipolar constraint introduced in the previous recipe.
    To this end, we have created a class that encapsulates the different steps of
    the proposed robust matching process:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是能够计算两个视图之间的基本矩阵和一组好的匹配项。为此，我们将使用在前面食谱中引入的极线约束来验证找到的所有特征点对应关系。为此，我们创建了一个封装所提议的鲁棒匹配过程不同步骤的类：
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Users of this class simply supply the feature detector and descriptor instances
    of their choice. These ones can also be specified using the defined `setFeatureDetector`
    and `setDescriptorExtractor` setter methods.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 该类的用户只需提供他们选择的特征检测器和描述符实例。这些也可以使用定义的`setFeatureDetector`和`setDescriptorExtractor`设置方法来指定。
- en: 'The main method is the match method, which returns matches, detected keypoints,
    and the estimated fundamental matrix. The method proceeds in four distinct steps
    (explicitly identified in the comments of the following code), which we will now
    explore:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 主要方法是匹配方法，它返回匹配项、检测到的关键点和估计的基本矩阵。该方法分为四个不同的步骤（在以下代码的注释中明确标识），我们现在将探讨这些步骤：
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The first two steps simply detect the feature points and compute their descriptors.
    Next, we proceed to feature matching using the `cv::BFMatcher` class, as we did
    in the previous chapter. We use the crosscheck flag to obtain matches of better
    quality.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个步骤仅仅是检测特征点并计算它们的描述符。接下来，我们使用`cv::BFMatcher`类进行特征匹配，就像我们在上一章中所做的那样。我们使用交叉检查标志来获得更好的匹配项。
- en: The fourth step is the new concept introduced in this recipe. It consists of
    an additional filtering test that will this time use the fundamental matrix in
    order to reject matches that do not obey the epipolar constraint. This test is
    based on the `RANSAC` method that can compute the fundamental matrix even when
    outliers are present in the match set (this method will be explained in the next
    section).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 第四步是本食谱中引入的新概念。它包括一个额外的过滤测试，这次将使用基本矩阵来拒绝不遵守极线约束的匹配项。这个测试基于`RANSAC`方法，即使匹配集中存在异常值也能计算基本矩阵（这种方法将在下一节中解释）。
- en: 'Using our `RobustMatcher` class, the robust matching of an image pair is then
    easily accomplished by the following calls:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的`RobustMatcher`类，通过以下调用就可以轻松完成图像对的鲁棒匹配：
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This results in `54` matches that are shown in the following screenshot:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了`54`个匹配项，如下面的截图所示：
- en: '![How to do it...](img/image_10_012.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![如何做到这一点...](img/image_10_012.jpg)'
- en: Most of the time, the resulting matches will be good matches. However, a few
    false matches might remain; these are ones that accidently fell on the corresponding
    epipolar lines of the computed fundamental matrix.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，得到的匹配项将是好的匹配项。然而，可能还有一些错误的匹配项残留；这些是那些意外落在计算出的基本矩阵的对应极线上的。
- en: How it works...
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the preceding recipe, we learned that it is possible to estimate the fundamental
    matrix associated with an image pair from a number of feature point matches. Obviously,
    to be exact, this match set must be made up of only good matches. However, in
    a real context, it is not possible to guarantee that a match set obtained by comparing
    the descriptors of the detected feature points will be completely exact. This
    is why a fundamental matrix estimation method based on the **RANSAC** (**RANdom
    SAmpling Consensus**) strategy has been introduced.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的食谱中，我们了解到可以从多个特征点匹配中估计与图像对相关联的基本矩阵。显然，为了精确，这个匹配集必须只由好的匹配项组成。然而，在实际情况下，无法保证通过比较检测到的特征点的描述符获得的匹配集是完全精确的。这就是为什么引入了一种基于**RANSAC**（**RANdom
    SAmpling Consensus**）策略的基本矩阵估计方法。
- en: The RANSAC algorithm aims to estimate a given mathematical entity from a data
    set that may contain a number of outliers. The idea is to randomly select some
    data points from the set and perform the estimation with only those. The number
    of selected points should be the minimum number of points required to estimate
    the mathematical entity. In the case of the fundamental matrix, eight matched
    pairs is the minimum number (in fact, the real minimum is seven matches, but the
    8-point linear algorithm is faster to compute). Once the fundamental matrix is
    estimated from these eight random matches, all the other matches in the match
    set are tested against the epipolar constraint that derives from this matrix.
    All the matches that fulfill this constraint (that is, matches for which the corresponding
    feature is at a short distance from its epipolar line) are identified. These matches
    form the support set of the computed fundamental matrix.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: RANSAC算法旨在从一个可能包含多个异常值的数据集中估计一个给定的数学实体。其思路是从集合中随机选择一些数据点，并仅使用这些点进行估计。所选点的数量应该是估计数学实体所需的最小点数。在基本矩阵的情况下，八个匹配对是最小数量（实际上，真正的最小值是七个匹配，但8点线性算法计算更快）。一旦从这八个随机匹配中估计出基本矩阵，所有其他匹配集的匹配都将与由此矩阵导出的共线约束进行测试。所有满足此约束的匹配（即对应特征与其共线线距离较短的匹配）都将被识别。这些匹配构成了计算出的基本矩阵的支持集。
- en: The central idea behind the RANSAC algorithm is that, the larger the support
    set, the higher the probability that the computed matrix is the right one. Conversely,
    if one (or more) of the randomly selected matches is an incorrect match, then
    the computed fundamental matrix will also be incorrect, and its support set will
    be expected to be small. This process is repeated a number of times and, in the
    end, the matrix with the largest support will be retained as the most probable
    one.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: RANSAC算法背后的核心思想是，支持集越大，计算出的矩阵是正确的概率就越高。相反，如果随机选择的匹配中有一个（或多个）是错误的匹配，那么计算出的基本矩阵也将是错误的，其支持集预计会很小。这个过程会重复多次，最后，支持集最大的矩阵将被保留为最可能的矩阵。
- en: Therefore, our objective is to pick eight random matches several times so that
    eventually we select eight good ones, which should give us a large support set.
    Depending on the proportion of incorrect matches in the entire data set, the probability
    of selecting a set of eight correct matches will differ. However, we know that,
    the more selections we make, the higher our confidence will be that we have at
    least one good match set among those selections. More precisely, if we assume
    that the match set is made of `w%` inliers (good matches), then the probability
    that we select eight good matches is `w⁸.` Consequently, the probability that
    a selection contains at least one incorrect match is `(1-w⁸)`. If we make `k`
    selections, the probability of having one random set that contains good matches
    only is `1-(1-w⁸)^k`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的目标是多次随机选择八个匹配，以便最终选择出八个好的匹配，这将给我们一个大的支持集。根据整个数据集中错误匹配的比例，选择八个正确匹配集的概率将不同。然而，我们知道，我们选择的次数越多，我们对在这些选择中至少有一个好的匹配集的信心就越高。更精确地说，如果我们假设匹配集由`w%`的内部点（好的匹配）组成，那么我们选择八个好匹配的概率是`w⁸`。因此，选择包含至少一个错误匹配的概率是`(1-w⁸)`。如果我们进行`k`次选择，只有一个随机集只包含好匹配的概率是`1-(1-w⁸)^k`。
- en: This is the confidence probability `c`, and we want this probability to be as
    high as possible, since we need at least one good set of matches in order to obtain
    the correct fundamental matrix. Therefore, when running the RANSAC algorithm,
    one needs to determine the number of `k` selections that need to be made in order
    to obtain a given confidence level.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是置信概率`c`，我们希望这个概率尽可能高，因为我们至少需要一个好的匹配集才能获得正确的基本矩阵。因此，在运行RANSAC算法时，需要确定需要进行多少次`k`次选择才能获得给定的置信水平。
- en: 'The use of the RANSAC method to estimate the fundamental matrix is done inside
    the `ransacTest` method of our `RobustMatcher` class:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RANSAC方法估计基本矩阵是在我们的`RobustMatcher`类的`ransacTest`方法中完成的：
- en: '[PRE6]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This code is a bit long because the keypoints need to be converted into `cv::Point2f`
    before the F matrix computation. When using the `cv::findFundamentalMat` function
    with the `cv::FM_RANSAC` method, two extra parameters are provided. One of these
    extra parameters is the confidence level, which determines the number of iterations
    to be made (by default, it is `0.99`). The other parameter is the maximum distance
    to the epipolar line for a point to be considered as an inlier. All of the matched
    pairs in which a point is at a greater distance from its epipolar line than the
    distance specified will be reported as an outlier. The function also returns `std::vector`
    of the character value, indicating that the corresponding match in the input set
    has been identified either as an outlier (`0`) or as an inlier (`1`). This explains
    the last loop of our method that extracts the good matches from the original match
    set.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码有点长，因为在使用F矩阵计算之前，需要将关键点转换为`cv::Point2f`。当使用`cv::findFundamentalMat`函数并选择`cv::FM_RANSAC`方法时，提供了两个额外的参数。其中一个额外参数是置信水平，它决定了要进行的迭代次数（默认为`0.99`）。另一个参数是点被认为是内点（inlier）的最大距离到极线的距离。所有点与其极线距离大于指定距离的匹配对将被报告为异常点。该函数还返回一个`std::vector`字符值，表示输入集中的相应匹配已被识别为异常点（`0`）或内点（`1`）。这解释了我们方法中提取良好匹配的最后循环。
- en: The more good matches you have in your initial match set, the higher the probability
    that RANSAC will give you the correct fundamental matrix. This is why we applied
    the crosscheck filter when matching the feature points. You could have also used
    the ratio test presented in the previous recipe in order to further improve the
    quality of the final match set. It is just a question of balancing the computational
    complexity, the final number of matches, and the required level of confidence
    that the obtained match set will contain only exact matches.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的初始匹配集中，良好的匹配点越多，RANSAC给出正确基本矩阵的概率就越高。这就是为什么我们在匹配特征点时应用了交叉检查过滤器。你也可以使用之前菜谱中提到的比率测试来进一步提高最终匹配集的质量。这只是平衡计算复杂度、最终匹配点的数量以及所需置信水平的问题，即获得的匹配集将只包含精确匹配。
- en: There's more...
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The result of the robust matching process presented in this recipe is: 1) an
    estimate of the fundamental matrix computed using the eight selected matches that
    have the largest support and 2) the match set included in this support set. Using
    this information, it is possible to refine these results in two ways.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本菜谱中提出的鲁棒匹配过程的结果是：1）使用具有最大支持的八个选定匹配点计算的基本矩阵的估计值；2）包含在这个支持集中的匹配集。使用这些信息，可以通过两种方式来优化这些结果。
- en: Refining the fundamental matrix
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化基本矩阵
- en: 'Since we now have a match set of good quality, as a last step, it might be
    a good idea to use all of them to re-estimate the fundamental matrix. We already
    mentioned that a linear 8-point algorithm to estimate this matrix exists. We can,
    therefore, obtain an over-determined system of equations that will solve the fundamental
    matrix in a least-squares sense. This step can be added the end of our `ransacTest`
    function:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们现在有一组高质量的匹配点，作为最后一步，使用所有这些点来重新估计基本矩阵可能是个好主意。我们之前提到，存在一个线性8点算法来估计这个矩阵。因此，我们可以获得一个超定方程组，以最小二乘法求解基本矩阵。这一步可以添加到我们的`ransacTest`函数的末尾：
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `cv::findFundamentalMat` function does indeed accept more than `8` matches
    by solving the linear system of equations using singular value decomposition.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv::findFundamentalMat`函数确实可以通过使用奇异值分解求解线性方程组来接受超过`8`个匹配点。'
- en: Refining the matches
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化匹配
- en: 'We learned that in a two-view system, every point must lie on the epipolar
    line of its corresponding point. This is the epipolar constraint expressed by
    the fundamental matrix. Consequently, if you have a good estimate of a fundamental
    matrix, you can use this epipolar constraint to correct the obtained matches by
    forcing them to lie on their epipolar lines. This can be easily done by using
    the `cv::correctMatches` OpenCV function:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们了解到，在双视场系统中，每个点都必须位于其对应点的极线（epipolar line）上。这是由基本矩阵表达的基本约束。因此，如果你有一个基本矩阵的良好估计，你可以使用这个极线约束来通过强制它们位于其极线上来纠正获得的匹配点。这可以通过使用`cv::correctMatches`
    OpenCV函数轻松完成：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This function proceeds by modifying the position of each corresponding point
    so that it satisfies the epipolar constraint while minimizing the cumulative (squared)
    displacement.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数通过修改每个对应点的位置，使其满足极线约束，同时最小化累积（平方）位移来执行。
- en: Computing a homography between two images
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算两张图像之间的单应性
- en: The first recipe of this chapter showed you how to compute the fundamental matrix
    of an image pair from a set of matches. In projective geometry, another very useful
    mathematical entity also exists. This one can be computed from multi-view imagery
    and, as we will see, is a matrix with special properties.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第一个食谱向您展示了如何从一组匹配中计算图像对的基本矩阵。在射影几何中，还存在另一个非常有用的数学实体。这个实体可以从多视图图像中计算出来，正如我们将要看到的，它是一个具有特殊性质的矩阵。
- en: Getting ready
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备中
- en: 'Again, let''s consider the projective relation between a 3D point and its image
    on a camera, which we presented in the introduction section of this chapter. Basically,
    we learned that this equation relates a 3D point to its image using the intrinsic
    properties of the camera and the position of that camera (specified with a rotation
    and a translation component). If we now carefully examine this equation, we realize
    that there are two special situations of particular interest. The first situation
    is when two views of a scene are separated by a pure rotation. We can then observe
    that the fourth column of the extrinsic matrix will be made up of `0`s (that is,
    the translation is null):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，让我们考虑一个3D点与其在相机上的图像之间的射影关系，这是我们在本章引言部分介绍的。基本上，我们了解到这个方程通过相机的内在属性和该相机的位置（用旋转和平移分量指定）将3D点与其图像联系起来。如果我们现在仔细检查这个方程，我们会意识到有两个特别有趣的特殊情况。第一种情况是当场景的两个视图之间仅由纯旋转分离时。我们可以观察到外矩阵的第四列将全部由`0`s组成（即平移为零）：
- en: '![Getting ready](img/B05388_10_21-1.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![准备中](img/B05388_10_21-1.jpg)'
- en: 'As a result, the projective relation in this special case becomes a `3x3` matrix.
    A similarly interesting situation also occurs when the object we observe is a
    plane. In this specific case, we can assume without loss of generality that the
    points on this plane will be located at `Z=0`. As a result, we obtain the following
    equation:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这种特殊情况下，射影关系变成了一个`3x3`矩阵。当我们观察到的物体是一个平面时，也会出现一个同样有趣的情况。在这种情况下，我们可以假设（不失一般性）该平面上的点将位于`Z=0`。因此，我们得到以下方程：
- en: '![Getting ready](img/B05388_10_22-1.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![准备中](img/B05388_10_22-1.jpg)'
- en: 'This zero coordinate of the scene points will then cancel the third column
    of the projective matrix, which will then again become a `3x3` matrix. This special
    matrix is called a **homography**, and it implies that, under special circumstances
    (here, a pure rotation or a planar object), a world point can be related to its
    image by a linear relation. In addition, because this matrix is invertible, you
    can also relate an image point on one view directly to its corresponding point
    on the other view, given that these two views are separated by a pure rotation,
    or are imaging a planar object. The homographic relation is then of the following
    form:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 场景点的这个零坐标将取消掉射影矩阵的第三列，从而使它再次成为一个`3x3`矩阵。这个特殊的矩阵被称为**单应性矩阵**，它意味着在特殊情况下（在这里，是纯旋转或平面物体），一个世界点可以通过线性关系与其图像相关联。此外，因为这个矩阵是可逆的，所以如果你知道这两个视图之间是纯旋转，或者它们正在成像一个平面物体，你也可以直接将一个视图上的图像点与其在另一个视图上的对应点联系起来。单应性关系的形式如下：
- en: '![Getting ready](img/B05388_10_23-1.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![准备中](img/B05388_10_23-1.jpg)'
- en: Here, `H` is a `3x3` matrix. This relation holds up to a scale factor represented
    here by the `s` scalar value. Once this matrix is estimated, all the points in
    one view can be transferred to a second view using this relation. This is the
    property that will be exploited in this recipe and the next one. Note that, as
    a side effect of the homography relation, the fundamental matrix becomes undefined
    in these cases.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`H`是一个`3x3`矩阵。这个关系在由`s`标量值表示的尺度因子下成立。一旦估计出这个矩阵，就可以使用这个关系将一个视图中的所有点转移到第二个视图。这就是本食谱和下一个食谱将要利用的性质。请注意，作为单应性关系的副作用，在这些情况下基本矩阵变得未定义。
- en: How to do it...
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Suppose that we have two images separated by a pure rotation. This happens,
    for example, when you take pictures of a building or a landscape by rotating yourself;
    as you are sufficiently far away from your subject, the translational component
    is, in this case, negligible. These two images can be matched using the features
    of your choice and the `cv::BFMatcher` function.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两个由纯旋转分隔的图像。例如，当你通过旋转自己来拍摄建筑物或风景时，这种情况就会发生；由于你离你的主题足够远，在这种情况下，平移分量是可忽略的。可以使用你选择的特征和`cv::BFMatcher`函数将这两个图像匹配起来。
- en: 'The result is something like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![How to do it...](img/image_10_016.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/image_10_016.jpg)'
- en: 'Then, as we did in the previous recipe, we will apply a RANSAC step that will
    this time involve the estimation of a homography based on a match set (which obviously
    contains a good number of outliers). This is done by using the `cv::findHomography`
    function, which is very similar to the `cv::findFundamentalMat` function:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，就像我们在之前的菜谱中做的那样，我们将应用一个RANSAC步骤，这次将涉及基于匹配集（显然包含大量异常值）的透视变换估计。这是通过使用`cv::findHomography`函数来完成的，该函数与`cv::findFundamentalMat`函数非常相似：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Recall that a homography exists (instead of a fundamental matrix) because our
    two images are separated by a pure rotation. We display here the inlier keypoints
    as identified by the `inliers` argument of the function:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，存在透视变换（而不是基本矩阵），因为我们的两个图像是通过纯旋转分隔的。我们在这里显示由函数的`inliers`参数识别的内点关键点：
- en: '![How to do it...](img/image_10_017.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/image_10_017.jpg)'
- en: 'The homography is a `3x3` invertible matrix. Therefore, once it has been computed,
    you can transfer image points from one image to the other. In fact, you can do
    this for every pixel of an image. Consequently, you can transfer a complete image
    to the point of view of a second image. This process is called image **mosaicing**
    or image **stitching** and is often used to build a large panorama from multiple
    images. An OpenCV function that does exactly this is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 透视变换是一个`3x3`可逆矩阵。因此，一旦计算出来，就可以将一个图像中的图像点转移到另一个图像中。实际上，你可以对图像的每个像素都这样做。因此，你可以将整个图像转移到第二个图像的视角中。这个过程被称为图像**拼接**或图像**缝合**，通常用于从多张图像构建大型全景图。执行此操作的确切OpenCV函数如下：
- en: '[PRE10]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Once this new image is obtained, it can be appended to the other image in order
    to expand the view (since the two images are now from the same point of view):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获得这张新图像，就可以将其附加到其他图像上以扩展视图（因为这两张图像现在是从相同视角拍摄的）：
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following image is the result:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图像是结果：
- en: '![How to do it...](img/image_10_018.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/image_10_018.jpg)'
- en: How it works...
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: When two views are related by a homography, it becomes possible to determine
    where a given scene point on one image is found on the other image. This property
    becomes particularly interesting for the points in one image that fall outside
    the image boundaries of the other. Indeed, since the second view shows a portion
    of the scene that is not visible in the first image, you can use the homography
    in order to expand the image by reading the color value of the additional pixels
    in the other image. That's how we were able to create a new image that is an expansion
    of our second image in which extra columns were added to the right-hand side.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个视角通过透视变换相关联时，就可以确定一个图像上的给定场景点在另一图像上的位置。这个特性对于落在另一图像边界外的图像中的点尤其有趣。确实，由于第二个视角显示了第一个图像中不可见的场景的一部分，你可以使用透视变换来通过读取另一图像中额外像素的颜色值来扩展图像。这就是我们能够创建一个新图像的原因，它是第二个图像的扩展，在右侧添加了额外的列。
- en: The homography computed by `cv::findHomography` is the one that maps the points
    in the first image to the points in the second image. This homography can be computed
    from a minimum of four matches and the RANSAC algorithm is again used here. Once
    the homography with the best support is found, the `cv::findHomography` method
    refines it using all the identified inliers.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 由`cv::findHomography`计算的透视变换是将第一图像中的点映射到第二图像中的点。这个透视变换可以从至少四个匹配中计算出来，并且在这里再次使用RANSAC算法。一旦找到具有最佳支持的透视变换，`cv::findHomography`方法就会使用所有识别出的内点来细化它。
- en: Now, in order to transfer the points of image `1` to image `2`, what we need
    is, in fact, the inverse homography. This is exactly what the `cv::warpPerspective`
    function is doing by default; that is, it uses the inverse of the homography provided
    as the input to get the color value of each point of the output image (this is
    what we called backward mapping in [Chapter 2](ch02.html "Chapter 2. Manipulating
    Pixels") , *Manipulating Pixels*). When an output pixel is transferred to a point
    outside the input image, a black value (`0`) is simply assigned to this pixel.
    Note that a `cv::WARP_INVERSE_MAP` flag can be specified as the optional fifth
    argument in `cv::warpPerspective` if you want to use direct homography instead
    of the inverted one during the pixel transfer process.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了将图像`1`的点转移到图像`2`上，我们实际上需要的是逆单应性。这正是`cv::warpPerspective`函数默认执行的操作；也就是说，它使用作为输入提供的单应性的逆来获取输出图像中每个点的颜色值（这就是我们在[第2章](ch02.html
    "第2章. 操作像素")，*操作像素*中提到的反向映射）。当一个输出像素被转移到输入图像之外的一个点时，这个像素将被简单地分配一个黑色值（`0`）。请注意，如果想在像素传输过程中使用直接单应性而不是逆单应性，可以在`cv::warpPerspective`中将`cv::WARP_INVERSE_MAP`标志指定为可选的第五个参数。
- en: There's more...
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The `contrib` package of OpenCV offers a complete stitching solution that can
    produce high-quality panoramas from multiple images.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV的`contrib`包提供了一个完整的拼接解决方案，可以从多张图像生成高质量的全景图。
- en: Generating image panoramas with the cv::Stitcher module
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用cv::Stitcher模块生成图像全景
- en: 'The mosaic we obtained in this recipe is good but still contains some defects.
    The alignment of the images is not perfect and we can clearly see the cut between
    the two images because the brightness and contrast in the two images are not the
    same. Fortunately, there is now a stitching solution in OpenCV that looks at all
    these aspects and tries to produce a panorama of optimal quality. This solution
    is quite complex and elaborated but, at its core, it relies on the principles
    learned in this recipe. That is, matching feature points in images and robustly
    estimating a homography. In addition, the solution estimates the intrinsic and
    extrinsic camera parameters to ensure a better alignment. It also nicely blends
    the images together by compensating for the difference in exposure conditions.
    The high-level call of this function is as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中我们获得的风暴图虽然不错，但仍然存在一些缺陷。图像的对齐并不完美，我们可以清楚地看到两张图像之间的切割，因为两张图像的亮度和对比度并不相同。幸运的是，现在OpenCV中有一个拼接解决方案，它考虑了所有这些方面，并试图生成一个质量最优的全景图。这个解决方案相当复杂且详尽，但其核心依赖于在这个配方中学到的原则。也就是说，匹配图像中的特征点并稳健地估计单应性。此外，该解决方案通过补偿曝光条件差异来很好地将图像融合在一起。此函数的高级调用如下：
- en: '[PRE12]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Numerous parameters in the instance can be adjusted to obtain high-quality
    results. Interested readers should explore this package in more depth in order
    to learn more about it. In our case, the result obtained is as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 实例中的许多参数都可以调整以获得高质量的结果。感兴趣的读者应更深入地探索这个包，以了解更多信息。在我们的案例中，得到的结果如下：
- en: '![Generating image panoramas with the cv::Stitcher module](img/image_10_019.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![使用cv::Stitcher模块生成图像全景](img/image_10_019.jpg)'
- en: Obviously, in general, an arbitrary number of input images can be used to compose
    a large panorama.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，在一般情况下，可以使用任意数量的输入图像来组成一个大全景。
- en: See also
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Remapping an image* recipe in [Chapter 2](ch02.html "Chapter 2. Manipulating
    Pixels") , *Manipulating Pixels*, discusses the concept of backward mapping
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第2章](ch02.html "第2章. 操作像素")，*操作像素*中的*重映射图像*配方讨论了反向映射的概念'
- en: The *Automatic panoramic image stitching using invariant* features article by
    *M. Brown* and *D. Lowe* in *International Journal of Computer Vision,*74, 1,
    2007, describes a complete method for building panoramas from multiple images
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由*M. Brown*和*D. Lowe*在*《国际计算机视觉杂志》*，第74卷，第1期，2007年发表的《使用不变特征的自动全景图像拼接》文章，描述了一种从多张图像构建全景的完整方法
- en: Detecting a planar target in images
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在图像中检测平面目标
- en: In the previous recipe, we explained how homographies can be used to stitch
    together images separated by a pure rotation to create a panorama. In this recipe,
    we also learned that different images of a plane also generate homographies between
    views. We will now see how we can make use of this fact to recognize a planar
    object in an image.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的菜谱中，我们解释了如何使用单应性将纯旋转分离的图像拼接在一起以创建全景图。在本菜谱中，我们还了解到不同视角的平面图像也会生成视图之间的单应性。现在我们将看到如何利用这一事实来识别图像中的平面物体。
- en: How to do it...
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: Suppose you want to detect the occurrence of a planar object in an image. This
    object could be a poster, painting, logo, signage, and so on. Based on what we
    have learned in this chapter, the strategy would consist of detecting feature
    points on this planar object and to try to match them with the feature points
    in the image. These matches would then be validated using a robust matching scheme
    similar to the one we used previously, but this time based on a homography. If
    the number of valid matches is high, then this must mean that our planar object
    is visible in the current image.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想要检测图像中平面物体的出现。这个物体可能是一张海报、画作、标志、标牌等等。根据我们在本章中学到的知识，策略将包括检测这个平面物体上的特征点，并尝试将它们与图像中的特征点进行匹配。然后，使用与之前类似但这次基于单应性的鲁棒匹配方案对这些匹配进行验证。如果有效匹配的数量很高，那么这必须意味着我们的平面物体在当前图像中是可见的。
- en: 'In this recipe, our mission is to detect the occurrence of the first edition
    of our book in an image, more specifically, the following image:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们的任务是检测我们书籍第一版在图像中的出现，更具体地说，是以下图像：
- en: '![How to do it...](img/image_10_020-1.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/image_10_020-1.jpg)'
- en: 'Let''s define a `TargetMatcher` class that is very similar to our `RobustMatcher`
    class:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个与我们的`RobustMatcher`类非常相似的`TargetMatcher`类：
- en: '[PRE13]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The reference image of the planar object to be matched is held by the `target`
    attribute. As it will be explained in the next section, feature points will be
    detected in a pyramid of images of the target successively down-sampled. The matching
    methods are similar to the ones of the `RobustMatcher` class, except that they
    include `cv::findHomography` instead of `cv::findFundamentalMat` in the `ransacTest`
    method.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 要匹配的平面物体的参考图像由`target`属性持有。正如将在下一节中解释的那样，特征点将在目标图像的金字塔中逐级下采样检测。匹配方法与`RobustMatcher`类的方法类似，只是在`ransacTest`方法中使用`cv::findHomography`而不是`cv::findFundamentalMat`。
- en: 'To use the `TargetMatcher` class, a specific feature point detector and descriptor
    must be instantiated and passed to the constructor:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`TargetMatcher`类，必须实例化一个特定的特征点检测器和描述符，并将其传递给构造函数：
- en: '[PRE14]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here, we selected the FAST detector in conjunction with the BRISK descriptor
    because they are quick to compute. Then, you must specify the target to be detected:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们选择了FAST检测器与BRISK描述符一起使用，因为它们计算速度快。然后，你必须指定要检测的目标：
- en: '[PRE15]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In our case, this is the following image:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，这是以下图像：
- en: '![How to do it...](img/image_10_021.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/image_10_021.jpg)'
- en: 'You can detect this target in an image by calling the `detectTarget` method:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过调用`detectTarget`方法来检测图像中的这个目标：
- en: '[PRE16]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This method returns the position of the four corners of the target in the image
    (if found). Lines can then be drawn to visually validate the detection:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法返回目标在图像中的四个角的位置（如果找到的话）。然后可以绘制线条来直观地验证检测：
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The result is as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![How to do it...](img/image_10_022.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/image_10_022.jpg)'
- en: How it works...
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'Since we do not know what the size of the target in the image is, we have decided
    to build a pyramid made of the target image in different sizes. Another option
    would have been to use scale-invariant features. At each level of our pyramid,
    the size of the target image is reduced by a certain factor (attribute `scaleFactor`,
    `0.9` by default) and the pyramid is made of a number of levels (attribute `numberOfLevels`,
    `8` by default). Feature points are detected for each level of the pyramid:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不知道图像中目标的大小，我们决定构建一个由不同尺寸的目标图像组成的金字塔。另一种选择是使用尺度不变特征。在金字塔的每个级别上，目标图像的大小会按一定比例（属性`scaleFactor`，默认为`0.9`）减小，金字塔由一定数量的级别（属性`numberOfLevels`，默认为`8`）组成。为金字塔的每个级别检测特征点：
- en: '[PRE18]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `detectTarget` method then proceeds onto three steps. Firstly, interest
    points are detected in the input image. Secondly, this image is robustly matched
    with each image of the target pyramid. The level with the highest number of inliers
    is retained. If this one has a sufficiently high number of surviving matches,
    then we have found the target. The third step consists of reprojecting the four
    corners of the target to the correct scale onto the input image using the found
    homography and the `cv::getPerspectiveTransform` function:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`detectTarget` 方法随后进入三个步骤。首先，在输入图像中检测兴趣点。其次，将此图像与目标金字塔中的每一幅图像进行鲁棒匹配。保留具有最高内点数的级别。如果这个级别有足够多的存活匹配，那么我们就找到了目标。第三步包括使用找到的透视变换和
    `cv::getPerspectiveTransform` 函数，将目标的四个角重新投影到输入图像的正确比例上：'
- en: '[PRE19]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following image shows the matching results obtained in the case of our
    example:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像显示了在我们示例中获得的匹配结果：
- en: '![How it works...](img/image_10_023.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/image_10_023.jpg)'
- en: See also
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Fast and robust homography scheme for real-time planar target detection*
    article by *H. Bazargani*, *O. Bilaniuk* and *R. Laganière* in *Journal of Real-Time
    Image Processing*, May 2015, describes a method to detecting a planar target in
    real-time. It also describes the `cv::RHO` method for the `cv::findHomography`
    function.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《*实时平面目标检测的快速鲁棒透视变换方案*》这篇文章由 *H. Bazargani*、*O. Bilaniuk* 和 *R. Laganière* 撰写，发表在
    *Journal of Real-Time Image Processing* 2015年5月，描述了一种实时检测平面目标的方法。它还描述了 `cv::findHomography`
    函数的 `cv::RHO` 方法。
