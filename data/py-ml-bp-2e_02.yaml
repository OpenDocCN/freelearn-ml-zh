- en: Build an App to Find Underpriced Apartments
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个应用程序来找到低价公寓
- en: 'In [Chapter 1](32e9f384-e739-4a1c-833e-11ee40051ac8.xhtml), *The Python Machine
    Learning Ecosystem*, we learned the essentials for working with data. We''ll now
    apply that knowledge to build out our first machine learning application. We''ll
    begin with a minimal, but highly-practical example: building an application to
    identify underpriced apartments.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](32e9f384-e739-4a1c-833e-11ee40051ac8.xhtml)，*Python机器学习生态系统*中，我们学习了处理数据的基本知识。接下来，我们将应用这些知识，构建我们的第一个机器学习应用程序。我们将从一个简明但高度实用的例子开始：构建一个识别低价公寓的应用程序。
- en: If you've ever searched for an apartment, you will appreciate just how frustrating
    the process can be. Not only is it time-consuming, but even when you do find an
    apartment you like, how do you know whether it's the right one?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经搜索过公寓，你一定能体会到这个过程有多么令人沮丧。它不仅耗时，而且即便你找到了一个你喜欢的公寓，你如何确定它就是合适的呢？
- en: Most likely, you have a target budget and a target location. But, if you are
    anything like me, you are also willing to make a few trade-offs. For example,
    I live in New York City, and being near an amenity like the subway is a big plus.
    But how much is that worth? Should I trade being in a building with an elevator
    for being closer to the train? How many minutes of walking to the train is worth
    walking up a flight of stairs? When renting, there are dozens of questions like
    this to consider. So how can we use machine learning to help us make these types
    of decisions?
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，你有一个预算目标和一个地点目标。但是，如果你像我一样，你也愿意做出一些妥协。例如，我住在纽约市，靠近地铁这种设施是一个很大的优势。但这值得多少？我是否应该为了靠近地铁而放弃住在有电梯的楼里？步行到地铁站的几分钟，是否值得爬上一层楼梯？租房时，像这样的疑问有很多。那么，我们怎样才能利用机器学习帮助我们做出这些决策呢？
- en: We'll spend the remainder of this chapter exploring just that. We won't be able
    to get answers to all the questions we have (for reasons that will become clear
    later), but by the end of the chapter, we'll have created an application that
    will make finding the right apartment just a little bit easier.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章剩下的内容将围绕这一主题展开。我们不能解答所有问题（有些原因稍后会变得清楚），但在本章结束时，我们将创建一个应用程序，让找到合适的公寓变得稍微容易一些。
- en: 'Here''s what we''ll cover in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下内容：
- en: Sourcing apartment listing data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取公寓列表数据
- en: Inspecting and preparing the data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查和准备数据
- en: Visualizing the data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化数据
- en: Regression modeling
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归建模
- en: Forecasting
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测
- en: Sourcing apartment listing data
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取公寓列表数据
- en: In the early 1970s, if you wanted to purchase a stock, you would need to engage
    a broker, who would charge you a fixed commission of nearly 1%. If you wanted
    to purchase an airline ticket, you would need to contact a travel agent, who would
    earn a commission of around 7%. And if you wanted to sell a home, you would contact
    a real estate agent, who would earn a commission of 6%. In 2018, you can do the
    first two essentially for free. The last one remains as it was in the 1970s.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在1970年代初期，如果你想购买股票，你需要聘请一个经纪人，他会收取近1%的固定佣金。如果你想购买机票，你需要联系旅行代理商，他们会赚取大约7%的佣金。如果你想卖房，你需要联系房地产代理商，他们会赚取6%的佣金。而到了2018年，你几乎可以免费完成前两项。而最后一项依然保持着1970年代的样子。
- en: Why is this the case and, more importantly, what does any of this have to do
    with machine learning? The reality is, it all comes down to data, and who has
    access to that data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么会这样？更重要的是，这一切与机器学习有什么关系呢？现实情况是，这一切归根结底是关于数据的，关于谁能访问这些数据。
- en: You might assume that you could easily access troves of real estate listing
    data quite easily through APIs or by **web scraping** real estate websites. You
    would be wrong. Well, wrong if you intend to follow the terms and conditions of
    those sites. Real estate data is tightly controlled by the **National Association
    of Realtors** (**NAR**), who run the **Multiple Listing Service** (**MLS**). This
    is a service that aggregates listing data, and is only available to brokers and
    agents at great expense. So, as you can imagine, they aren't too keen on letting
    just anyone download it *en masse*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能认为可以通过API或**网络爬虫**轻松获取大量房地产列表数据。你错了。如果你打算遵循这些网站的条款和条件的话，那就错了。房地产数据由**美国房地产经纪人协会**（**NAR**）严格控制，他们运营着**多重房源服务**（**MLS**）。这是一个汇总房源数据的服务，只提供给经纪人和代理商，且费用昂贵。所以，你可以想象，他们并不热衷于让任何人轻松下载这些数据*大规模地*。
- en: This is unfortunate, since opening up this data would undoubtedly lead to useful
    consumer applications. This seems especially important for a purchase decision
    that represents the largest portion of a family's budget.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这是不幸的，因为开放这些数据无疑将会带来有用的消费者应用程序。这对于家庭预算中最大的一部分购买决策尤为重要。
- en: With that said, not all hope is lost, as not every site explicitly bans scraping.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，并不是所有希望都失去，因为并非每个网站都明确禁止抓取数据。
- en: Pulling down listing data
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取公寓列表数据
- en: 'We''ll be using the RentHop site, [http://www.renthop.com](https://www.renthop.com/),
    to source our listing data. The following screenshot of the site shows the layout
    of the listings we''ll be retrieving:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 RentHop 网站， [http://www.renthop.com](https://www.renthop.com/)，来获取我们的公寓列表数据。以下是该网站的截图，展示了我们将要提取的列表布局：
- en: '![](img/3ed2e732-72cd-481f-ac8d-1c37a4355b7b.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3ed2e732-72cd-481f-ac8d-1c37a4355b7b.png)'
- en: What we can see is that the listings have the address, the price, the number
    of bedrooms, and the number of bathrooms. We'll start by retrieving this information
    for each listing.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从中我们可以看到，公寓列表中包括地址、价格、卧室数量和浴室数量。我们将从每个列表中获取这些信息。
- en: 'We are going to be using the Python Requests library for this task. Requests
    is dubbed *HTTP for humans*, and it makes it super easy to retrieve websites.
    If you want an overview on how to use Requests, the quick start guide is available
    at [http://docs.python-requests.org/en/master/user/quickstart/](http://docs.python-requests.org/en/master/user/quickstart/).
    Follow these steps:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Python 的 Requests 库来完成此任务。Requests 被称为 *人性化的 HTTP*，它使得获取网站变得非常容易。如果你想了解如何使用
    Requests，快速入门指南可以在 [http://docs.python-requests.org/en/master/user/quickstart/](http://docs.python-requests.org/en/master/user/quickstart/)
    上找到。请按以下步骤操作：
- en: 'So, the first step is to prepare our Jupyter Notebook with the imports we''ll
    be using for this task. We do that in the following code snippet:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所以，第一步是准备好我们的 Jupyter Notebook，并导入我们在这个任务中将使用的库。我们在以下代码片段中完成这项操作：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We'll likely need to import more libraries later on, but for now this should
    get us started.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能需要在稍后导入更多的库，但现在这应该足以让我们开始了。
- en: 'We are going to use NYC apartment data in our model. The URL for that data
    is [https://www.renthop.com/nyc/apartments-for-rent](https://www.renthop.com/nyc/apartments-for-rent).
    Let''s run a quick test and make sure we can retrieve that page. We do that in
    the following code:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在模型中使用纽约公寓数据。该数据的网址是 [https://www.renthop.com/nyc/apartments-for-rent](https://www.renthop.com/nyc/apartments-for-rent)。让我们进行一个快速测试，确保我们能成功获取该页面。我们在以下代码中完成这个操作：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This code makes a call to the site, and retrieves the information, storing
    it in the `r` object. There are a number of attributes we could retrieve from
    that `r` object, but for now, we just want the page content. We can see the output
    of that in the following screenshot:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这段代码调用了该网站，并获取了信息，将其存储在 `r` 对象中。我们可以从 `r` 对象中获取许多属性，但现在我们只关心页面内容。我们可以在以下截图中看到这个输出：
- en: '![](img/f91672bd-b5d9-4562-840b-65431127b904.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f91672bd-b5d9-4562-840b-65431127b904.png)'
- en: Upon inspection, it looks like everything we want is contained in this. To verify
    that, let's copy all of the HTML and paste it into a text editor, and then open
    it in a browser. I'm going to do that using **Sublime Text**, a popular text editor
    available at [https://www.sublimetext.com/](https://www.sublimetext.com/).
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 经检查，看来我们需要的数据都包含在其中。为了验证这一点，让我们将所有 HTML 复制并粘贴到文本编辑器中，然后在浏览器中打开。我将使用 **Sublime
    Text**，这是一款流行的文本编辑器，可以在 [https://www.sublimetext.com/](https://www.sublimetext.com/)
    上找到。
- en: 'In the following screenshot, you can see that I have pasted the copied HTML
    from the Jupyter output into Sublime Text and saved it as `test.html`:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下面的截图中，您可以看到我已将从 Jupyter 输出中复制的 HTML 粘贴到 Sublime Text 中，并保存为 `test.html`：
- en: '![](img/1e5be5b0-f835-42f5-8f9a-527637540495.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1e5be5b0-f835-42f5-8f9a-527637540495.png)'
- en: HTML text
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: HTML 文本
- en: 'Next, we click on Open in Browser, and we can see output that resembles the
    following image:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们点击“在浏览器中打开”，可以看到类似以下图片的输出：
- en: '![](img/85ddd01e-3d57-4e79-b922-2a0fa4d63082.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/85ddd01e-3d57-4e79-b922-2a0fa4d63082.png)'
- en: Notice that although the text doesn't render cleanly (due to the lack of CSS),
    all the data we are targeting is there. Fortunately for us, that means the RentHop
    site doesn't use any advanced JavaScript rendering, so that should make our job
    much easier. If it did, we'd have to use a different tool like Selenium.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，尽管文本没有正确渲染（因为缺少 CSS），但我们目标的所有数据都在那里。幸运的是，这意味着 RentHop 网站没有使用任何高级的 JavaScript
    渲染技术，这样就使得我们的工作更轻松。如果使用了高级技术，我们就不得不使用像 Selenium 这样的工具了。
- en: 'Let''s now examine the page elements to see how we can parse the page data:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们检查页面元素，看看如何解析页面数据：
- en: Open the RentHop site in Chrome and right-click anywhere on the page.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Chrome中打开RentHop网站，并右键点击页面的任意位置。
- en: 'At the bottom of the context menu, you should see Inspect. Click on that. The
    page should now resemble the following image:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在上下文菜单的底部，你应该能看到“检查”（Inspect）选项。点击它。页面现在应该看起来像下图：
- en: '![](img/9e9a1c0e-8312-4e60-87b5-8dc1cd532333.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9e9a1c0e-8312-4e60-87b5-8dc1cd532333.png)'
- en: 'In the tool that just opened, in the upper left-hand corner, there is a square
    with an arrow in the corner. Click that, and then click on the data on the page.
    It should look like the following:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在刚刚打开的工具中，左上角有一个带箭头的方框。点击它，然后点击页面上的数据。它应该像下图一样：
- en: '![](img/d971858e-a691-4eae-94aa-b47f60d21317.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d971858e-a691-4eae-94aa-b47f60d21317.png)'
- en: We can see from this that each listing's data is in a table, and that the first
    `td` tag contains the price, the second contains the number of bedrooms, and the
    third contains the number of bathrooms. We will also want the address of the apartment
    that can be found in an anchor, or a tag.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里我们可以看到，每个房源的数据都在一个表格中，第一个`td`标签包含价格，第二个包含卧室数量，第三个包含浴室数量。我们还需要公寓的地址，它可以在一个锚点标签或`<a>`标签中找到。
- en: 'Let''s now begin building out our code to test our parsing of the data. To
    do our HTML parsing, we are going to use a library call **BeautifulSoup**. The
    documentation for it can be found at [https://www.crummy.com/software/BeautifulSoup/](https://www.crummy.com/software/BeautifulSoup/).
    BeautifulSoup is a popular, easy-to-use Python HTML parsing library. It can be
    pip installed if you don''t already have it. We are going to use it to pull out
    all of the individual specs for our apartment listings:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们开始编写代码，测试我们的数据解析。为了进行HTML解析，我们将使用一个叫做**BeautifulSoup**的库。它的文档可以在[https://www.crummy.com/software/BeautifulSoup/](https://www.crummy.com/software/BeautifulSoup/)找到。BeautifulSoup是一个流行、易于使用的Python
    HTML解析库。如果你还没有安装，可以通过pip安装。我们将使用它来提取我们公寓列表的所有单独规格：
- en: 'To get started, we simply need to pass our page content into the `BeautifulSoup`
    class. This can be seen in the following code:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要开始，我们只需要将页面内容传递给`BeautifulSoup`类。这可以在下面的代码中看到：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We now can use this `soup` object that we''ve created to begin parsing out
    our apartment data. The first thing we want to do is retrieve that `div` tag that
    contains our listing data on the page. We see that in the following code:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以使用我们创建的`soup`对象开始解析公寓数据。我们要做的第一件事是获取包含我们房源数据的`div`标签。我们可以在下面的代码中看到：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: What we've done in the preceding code is to select all `divs` that contain `search-info`.
    These are exactly the `divs` that have our data.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们做的是选择所有包含`search-info`的`div`元素。这些正是包含我们数据的`div`元素。
- en: 'Next, we look at the output from this in the following screenshot:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们来看一下下面截图中的输出：
- en: '![](img/354d6474-7e80-4967-8f21-1fa657ceb267.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/354d6474-7e80-4967-8f21-1fa657ceb267.png)'
- en: 'Notice that we have a Python list of all the `div` tags we were seeking. We
    know from looking at the page that there should be twenty of these. Let''s confirm
    that:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，我们有一个包含所有目标`div`标签的Python列表。根据页面显示，我们知道应该有二十个这些元素。我们来确认一下：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We then see the following output, which confirms that we have captured them
    all as we wanted:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们会看到以下输出，这确认我们已经成功获取到所有需要的数据：
- en: '![](img/d65d3be9-fa3b-462d-84ad-ad353cb1087c.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d65d3be9-fa3b-462d-84ad-ad353cb1087c.png)'
- en: Pulling out the individual data points
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取单独的数据点
- en: Now that we have all the `divs` with our listing data for each apartment, we
    need to pull out the individual data points for each apartments.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了所有包含房源数据的`div`元素，接下来需要提取每个公寓的单独数据点。
- en: 'These are the points in each that we want to target:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们要在每个房源中提取的点：
- en: URL of the listing
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 房源的URL
- en: Address of the apartment
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公寓的地址
- en: Neighborhood
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邻里
- en: Number of bedrooms
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卧室数量
- en: Number of bathrooms
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 浴室数量
- en: Obviously, we love to have way more info—things such as square footage, for
    example, but we'll have to make do with what we have.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们希望获得更多的信息——例如，公寓的面积，但我们只能利用现有的数据。
- en: 'Let''s begin by looking at the first listing:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从查看第一个房源开始：
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding code results in the following output:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码将输出以下结果：
- en: '![](img/d622f786-908e-4e9f-9578-cfc63d1c150d.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d622f786-908e-4e9f-9578-cfc63d1c150d.png)'
- en: Notice that this first `div` contains all of the data points we were looking
    for. We just now need to begin our parse to target them each individually. Let's
    look at the first one we want to retrieve, the URL.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这第一个`div`包含了我们寻找的所有数据点。现在我们只需开始解析它们，逐个提取。让我们先看看第一个我们想要获取的内容，URL。
- en: 'We can see that the URL for the page is with an anchor, or a tag. Let''s parse
    that out now. We can do that with another `select` statement, as can be seen in
    the following code snippet:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到页面的URL带有一个锚点或标签。现在让我们解析这个URL。我们可以使用另一个`select`语句来完成这个操作，以下是相关代码片段：
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We see the output in the following screenshot:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下截图中看到输出结果：
- en: '![](img/783a7653-3757-4149-bd8c-a5fdcb4a2a1e.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/783a7653-3757-4149-bd8c-a5fdcb4a2a1e.png)'
- en: 'This is exactly what we were hoping for. We can now continue to retrieve the
    other data points for the listing. We do that in the following code:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们所期望的结果。现在我们可以继续提取列表中的其他数据点。我们在下面的代码中执行了这一操作：
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let''s now verify this by printing out what we''ve captured. We do that in
    the following code:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过打印出我们已经捕获到的数据来验证这一点。我们通过以下代码来实现：
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The preceding code results in the following output:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/fc936587-2ea0-4ff4-983d-cf957338dd68.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fc936587-2ea0-4ff4-983d-cf957338dd68.png)'
- en: Based on this output, we are getting the data we need. Let's continue on with
    the last few items we need—the bedrooms, bathrooms, and the price.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 根据此输出，我们得到了所需的数据。接下来，让我们继续获取最后几个数据项——卧室数、浴室数和价格。
- en: 'Since these items have a slightly different presentation in that they are in
    a `table` tag in our `div` and then inside a table row, or `tr`, we will need
    to iterate over each point to capture our data. We do that in the following code:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些项目的呈现方式略有不同，它们在我们的`div`标签中的`table`标签内，并且在表格行`tr`中，我们需要遍历每个数据点以捕获数据。我们在下面的代码中进行了这个操作：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding code results in the following output:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/c9d91942-f5cd-48f0-b7ea-187affdea492.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9d91942-f5cd-48f0-b7ea-187affdea492.png)'
- en: Again, this is exactly what we were looking for. We now have all the data that
    we were seeking. Let's now pull it all together in a loop so that we can pull
    the data from each listing and save it into a list.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 再次检查，这正是我们要找的结果。我们现在已经收集了所有我们需要的数据。接下来，让我们将这些数据整合到一个循环中，以便从每个列表中提取数据并保存到一个列表里。
- en: 'In the following code, we will pull out all the data points for each listing:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的代码中，我们将提取每个公寓列表中的所有数据点：
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s unpack a bit what we did in the preceding code. We know we have 20 divs
    that contain the apartment listing on the page, so we create a `for` loop that
    goes through each one and pulls out the data and adds it to `indv_listing`. When
    that is complete, all the data for the individual listing is then added to the
    `listing_list`, which contains all the final info for the 20 apartment listings.
    We verify that with the following code:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微分析一下前面的代码。我们知道页面上有20个`div`元素，其中包含公寓的列表，所以我们创建了一个`for`循环，遍历每个元素，提取数据并将其添加到`indv_listing`中。完成后，所有单独公寓的数据会被添加到`listing_list`中，该列表包含了所有20个公寓的最终信息。我们可以通过以下代码来验证这一点：
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The preceding code results in the following output:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/829b00c3-db15-4c34-a87c-84e7244a8865.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/829b00c3-db15-4c34-a87c-84e7244a8865.png)'
- en: Again, we appear to be getting the results we expect, so we will continue on.
    A check of the number of items in `listing_list` also confirms we have all 20
    apartments on the page.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 再次检查，我们似乎得到了预期的结果，所以我们将继续进行。`listing_list`中的项数也确认我们已经获得了页面上的所有20个公寓。
- en: So far, we have successfully retrieved one page of data. While that is great,
    we are going to need far more apartments if we want to build any kind of meaningful
    model. To do this, we will need to iterate over a number of pages. To that end,
    we'll need to use the appropriate URLs. We can see that at the bottom of the listings,
    there is a button that says Next. If you right-click on that button, and click
    Copy Link Address, you see it looks like the following URL: [https://www.renthop.com/search/nyc?max_price=50000&min_price=0&page=2&sort=hopscore&q=&search=0](https://www.renthop.com/search/nyc?max_price=50000&min_price=0&page=2&sort=hopscore&q=&search=0).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经成功获取了第一页的数据。虽然这很好，但如果我们想构建一个有意义的模型，我们将需要更多的公寓数据。为此，我们需要遍历多个页面。为此，我们需要使用适当的URLs。我们可以看到在公寓列表的底部，有一个写着“下一页”的按钮。如果你右键点击该按钮并选择“复制链接地址”，你会看到以下的URL：[https://www.renthop.com/search/nyc?max_price=50000&min_price=0&page=2&sort=hopscore&q=&search=0](https://www.renthop.com/search/nyc?max_price=50000&min_price=0&page=2&sort=hopscore&q=&search=0)。
- en: Parsing data
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解析数据
- en: A basic analysis of the URL tells us that we are passing in parameters that
    include min price and max price, but most importantly, the page number. We can
    use this in our code, and just dynamically change that page number to pull additional
    pages using a loop.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对URL进行基本分析，我们可以看到传入的参数包括最小价格和最大价格，但最重要的是，页码。我们可以在代码中使用这个参数，并动态地改变页码，以便通过循环拉取更多的页面。
- en: 'Let''s try this with some sample code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试一些示例代码：
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding code results in the following output:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下输出：
- en: '![](img/439f0f72-5676-4282-85e4-1996bcd9e60d.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/439f0f72-5676-4282-85e4-1996bcd9e60d.png)'
- en: 'This looks like a success. Now we need to just put it all together. We''ll
    start by turning our parsing loop into a proper function that we can call for
    each of the pages. We do that in the following code:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来像是成功了。现在我们只需要把它们合并到一起。我们将通过将我们的解析循环转化为一个适当的函数来开始，这样我们就可以在每个页面上调用它。我们通过以下代码来实现：
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This function will take in a page full of `listing_divs` and return the data
    payload for each. We can then keep adding the data to our master list of apartment
    data. Notice that there is some additional code in there to validate and remove
    some erroneous `'_'` values that get added in the `listing_spec` loop. This was
    to avoid some bad parsing that added an additional column when there shouldn't
    have been one.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数会接收一整页的`listing_divs`，并返回每个条目的数据载荷。然后我们可以将数据继续添加到我们的主公寓数据列表中。注意，在这段代码中有额外的代码来验证并移除一些错误的`'_'`值，这些值是在`listing_spec`循环中被加进去的。这样做是为了避免一些错误的解析，这些解析本不应该添加额外的列。
- en: 'Next, we will build the main loop that will retrieve each page, get the `listing_divs`,
    parse out the data points, and finally add all of the info to our final Python
    list of all data points for each listing. We do that in the following code:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将构建主循环，该循环将检索每个页面，获取`listing_divs`，解析数据点，最后将所有信息添加到我们最终的Python列表中，包含每个条目的所有数据点。我们通过以下代码来实现：
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Before trying this on 100 pages, you should confirm that it works on a much
    smaller number, like 3.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试100个页面之前，你应该确认它在更小的数量上能正常工作，比如3个页面。
- en: You should have noticed the page being printed out as the code ran. If you used
    30 pages, you should see that there are 2,000 listings in your `all_pages_parsed`
    list.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该注意到页面在代码运行时已经被打印出来。如果你使用了30页，你应该会看到`all_pages_parsed`列表中有2,000个条目。
- en: 'Let''s now move our data into a `pandas` DataFrame, so that we can work with
    it more easily. We do that in the following code:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将数据移入一个`pandas` DataFrame，这样我们可以更方便地处理它。我们通过以下代码来实现：
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The preceding code results in the following output:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下输出：
- en: '![](img/c5103f6c-211e-4b4a-a991-255f8cfd26f7.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c5103f6c-211e-4b4a-a991-255f8cfd26f7.png)'
- en: Now that we have all our data pulled down, parsed, and incorporated in a DataFrame,
    let's move on to cleansing and verifying our data.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经把所有数据拉取、解析并整合进了一个DataFrame，接下来我们将进行数据的清理和验证。
- en: Inspecting and preparing the data
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查并准备数据
- en: 'Let''s begin by inspecting the data points for each of our columns. We want
    to look for odd and outlier values in our data. We will start by looking at the
    bedroom and bathroom columns:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先检查每一列的数据点。我们希望查找数据中的异常值和离群值。我们将从查看卧室和卫生间列开始：
- en: 'In the following code, we look at the unique values for bedrooms:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下代码中，我们查看卧室的唯一值：
- en: '[PRE16]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The preceding code results in the following output:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下输出：
- en: '![](img/10ec2364-5b9f-4e4c-b291-4b1e4a52813a.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10ec2364-5b9f-4e4c-b291-4b1e4a52813a.png)'
- en: 'Now, let''s look at bathrooms. We do that in the following code:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下卫生间。我们通过以下代码来实现：
- en: '[PRE17]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The preceding code results in the following output:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下输出：
- en: '![](img/6502f7a8-337c-47ad-8a37-379e3fc9a140.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6502f7a8-337c-47ad-8a37-379e3fc9a140.png)'
- en: 'Based on the output from the two preceding queries, we see that we need to
    correct some items that have a leading underscore. Let''s do that now:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据前面两个查询的输出，我们看到需要修正一些前面带有下划线的项。现在我们来做这个修改：
- en: '[PRE18]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'In the preceding code, we ran a pandas `map` function with a `lambda` function
    that essentially checks whether the element begins with an underscore and, if
    so, removes it. A quick check of the unique values for beds and baths should reveal
    that our erroneous starting underscores have been removed:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用了pandas的`map`函数和一个`lambda`函数，基本上检查元素是否以下划线开始，如果是，则移除它。快速检查一下床和浴室的唯一值，应该可以发现我们错误的下划线已被移除：
- en: '[PRE19]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The preceding code results in the following output:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下输出：
- en: '![](img/b020bf80-3365-4261-b9fe-501c97c84d0f.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b020bf80-3365-4261-b9fe-501c97c84d0f.png)'
- en: 'Let''s execute the following line of code and look at the results:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下代码行并查看结果：
- en: '[PRE20]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The preceding code results in the following output:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/05be5f71-4fb5-49d7-932f-50ce674e00e3.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/05be5f71-4fb5-49d7-932f-50ce674e00e3.png)'
- en: 'Next, we want to look at some descriptive statistics to better understand our
    data. One way to do that is with the `describe` method. Let''s try that in the
    following code:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们希望查看一些描述性统计数据，以更好地理解我们的数据。一种方法是使用`describe`方法。让我们在下面的代码中尝试一下：
- en: '[PRE21]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The preceding code results in the following output:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/b1e30c62-34f6-4ea3-bb92-c3870e31c936.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1e30c62-34f6-4ea3-bb92-c3870e31c936.png)'
- en: 'While we were hoping to get metrics such as the average number of beds and
    baths, and things like the max rent, what we instead received was much less than
    that. The problem is that the data is not the correct data type for these operations.
    Pandas can''t perform those types of operation on what are string objects. We
    will need to clean up our data further and set it to the correct data types. We
    will do that in the following code:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们希望得到诸如平均卧室和浴室数量、最大租金等指标，但我们实际上得到的结果远少于预期。问题是数据的类型不适合这些操作。Pandas无法对字符串对象执行这些类型的操作。我们需要进一步清理数据，并将其设置为正确的数据类型。我们将在下面的代码中进行操作：
- en: '[PRE22]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: What we have done in the preceding code is to remove anything that is non-numeric
    from each of the values. You can see that we removed `_Bed` and `_Bath` to leave
    just the number, and that we replaced words such as `Studio` and `Loft` with the
    actual number of bedrooms, which is zero.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们做了一个操作，将每个值中非数字的部分移除。你可以看到，我们去除了`_Bed`和`_Bath`，只留下了数字，并且我们将诸如`Studio`和`Loft`之类的词替换为实际的卧室数量，替换成了零。
- en: Sneak-peek at the data types
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据类型预览
- en: 'Let''s now look at our data types:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下我们的数据类型：
- en: '[PRE23]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The preceding code results in the following output:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/004c3498-365f-4413-a374-cc313910ac25.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/004c3498-365f-4413-a374-cc313910ac25.png)'
- en: This is what we want to see. Notice that since we can have a half bath, we needed
    a float there rather than an integer.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们想要看到的结果。请注意，由于我们可以有半个浴室，因此我们需要使用浮动类型而不是整数。
- en: 'Next, let''s carry out an inspection. Let''s get a count of the number of units
    in each neighborhood:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们进行一次检查。我们来统计每个社区单元的数量：
- en: '[PRE24]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The preceding code generates the following output:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/0b82a455-5b59-4ba6-8f11-7783d31ab819.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0b82a455-5b59-4ba6-8f11-7783d31ab819.png)'
- en: 'It looks like most of the units are in Manhattan, which is what we might expect.
    Let''s make sure that our neighborhood strings are clean. We can do that by doing
    a number of `groupby` operations:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来大多数单元都位于曼哈顿，这也是我们所预期的。让我们确保我们的社区字符串是干净的。我们可以通过执行多个`groupby`操作来做到这一点：
- en: '[PRE25]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The preceding code generates the following output:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/088f78f1-58b4-452b-8bef-d64b0bc2074a.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/088f78f1-58b4-452b-8bef-d64b0bc2074a.png)'
- en: 'It looks like we have some issues with leading and possibly trailing spaces.
    Let''s clean that up. We do so in the following code:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们在数据中有一些前导空格，可能还存在尾随空格的问题。让我们清理一下这些问题。我们将在以下代码中进行处理：
- en: '[PRE26]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'That should clear it up. Let''s validate that:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这样应该就清楚了。我们来验证一下：
- en: '[PRE27]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The preceding code results in the following output:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/cd7f984d-69f4-4fcf-8d77-68be60114fe3.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cd7f984d-69f4-4fcf-8d77-68be60114fe3.png)'
- en: 'Perfect. Exactly what we want to see. At this point, we can do a few more inspections.
    Let''s just take a look at the mean rent by neighborhood:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 完美！正是我们想要看到的结果。到此为止，我们可以再做一些检查。我们来看看每个社区的平均租金：
- en: '[PRE28]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The preceding code results in the following output:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/7abacf8e-6a05-46a9-a20b-1a8f0672482b.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7abacf8e-6a05-46a9-a20b-1a8f0672482b.png)'
- en: We see that the Lincoln Square area appears to have the highest rent on average.
    At this point, we could continue on querying the data for interesting patterns,
    but let's move on to visualizing the data.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到林肯广场区域的租金平均值似乎是最高的。到此为止，我们可以继续查询数据以寻找有趣的模式，但现在我们将继续进行数据的可视化。
- en: Visualizing our data
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化我们的数据
- en: When dealing with geographic data, as we are here, it is immensely valuable
    to be able to plot that information. One way of doing that is with something called
    a **choropleth** map. A choropleth is essentially a geographic heat map. We are
    going to build a choropleth to create a heat map of average rental price by ZIP
    code.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理地理数据时，就像我们现在做的那样，能够绘制这些信息是非常有价值的。一种实现方法是使用被称为 **染色图** 的地图。染色图本质上是一个地理热力图。我们将创建一个染色图，生成按
    ZIP 码分布的平均租金价格热力图。
- en: The first thing we will need to do this is the ZIP code. Unfortunately for us,
    our dataset does not contain ZIP code information. We do, however, have the address
    for the properties. With a little help from the Google Maps API, we can retrieve
    this information.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是 ZIP 码。不幸的是，我们的数据集中没有 ZIP 码信息。然而，我们有物业的地址。借助 Google Maps API，我们可以获取这些信息。
- en: 'Currently, the Google Maps API is a paid API. The rates are reasonable, 1,000
    calls for $5, but they also give you a credit of $200 each month (at the time
    of writing). They also allow you to sign up for a free trial before they will
    start billing you, and they won''t bill unless you explicitly give them the okay
    to do so. Since there really is no free alternative out there, we''ll go ahead
    and sign up for an account. I''ll walk you through the steps in the following:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Google Maps API 是一个收费 API。收费标准合理，1,000 次调用 $5，但每月还提供 $200 的信用额度（截至写作时）。他们还允许你在开始计费之前先注册免费试用，并且只有在你明确同意的情况下才会开始收费。由于市面上没有真正免费的替代品，我们将继续注册一个账户。接下来我将为你讲解步骤：
- en: 'The first step is to go to the Google Maps API page at [https://developers.google.com/maps/documentation/geocoding/intro](https://developers.google.com/maps/documentation/geocoding/intro):'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是访问 Google Maps API 页面：[https://developers.google.com/maps/documentation/geocoding/intro](https://developers.google.com/maps/documentation/geocoding/intro)：
- en: '![](img/26646108-bf3e-4860-94b6-6cf5bcabdcb9.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/26646108-bf3e-4860-94b6-6cf5bcabdcb9.png)'
- en: 'Click on GET STARTED in the upper right-hand corner. You''ll next be prompted
    to create a project. Give it any name you like:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击右上角的 GET STARTED。接下来，你将被提示创建一个项目。给它取一个你喜欢的名字：
- en: '![](img/eb95ec16-8435-4b33-a113-4c8196564d63.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb95ec16-8435-4b33-a113-4c8196564d63.png)'
- en: Creating a project
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个项目
- en: 'Then you will enable billing:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后你将启用计费：
- en: '![](img/38605d33-524b-4534-abb2-751e12451633.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38605d33-524b-4534-abb2-751e12451633.png)'
- en: 'Next, you will enable your API keys:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你将启用 API 密钥：
- en: '![](img/78f3f58e-76f5-451c-9d65-ac02b116f6fd.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](img/78f3f58e-76f5-451c-9d65-ac02b116f6fd.png)'
- en: 'Once this is completed and you have your API keys, head back to the front page
    to enable the Geolocation API. Click on APIs in the left-hand side pane:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后并获得 API 密钥后，返回首页启用地理定位 API。点击左侧面板中的 APIs：
- en: '![](img/50eb78d9-6e3d-45c3-829e-4e842689f153.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](img/50eb78d9-6e3d-45c3-829e-4e842689f153.png)'
- en: 'And then, under Unused APIs, click Geolocation API:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在未使用的 API 下，点击地理定位 API：
- en: '![](img/f998f931-657d-4ff6-a8e8-86e78e4848b6.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f998f931-657d-4ff6-a8e8-86e78e4848b6.png)'
- en: Once all of this is complete, and you have your API keys, pip install Google
    Maps. That can be done from your command line with `pip install -U googlemaps`.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些步骤并获得 API 密钥后，使用 `pip install -U googlemaps` 安装 Google Maps。你可以在命令行中执行此操作：
- en: 'Let''s continue on now with this API in our Jupyter Notebook. We''ll import
    our new mapping API and test it out:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续在 Jupyter Notebook 中使用这个 API。我们将导入新的地图 API 并进行测试：
- en: '[PRE29]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The preceding code results in the following output:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码会输出以下结果：
- en: '![](img/5f6b021c-588f-4b4c-b09e-a3f4d93e74a2.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f6b021c-588f-4b4c-b09e-a3f4d93e74a2.png)'
- en: 'Okay, so essentially, all we did in the final bit of code was to import and
    initialize our `googlemaps` client, as well as use piece together from one of
    our apartments as usable address. Let''s now pass in that address to the Google
    Maps API:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，实际上我们在代码的最后部分所做的就是导入并初始化 `googlemaps` 客户端，并使用我们某个公寓的地址作为可用地址。现在让我们将该地址传递给
    Google Maps API：
- en: '[PRE30]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The preceding code generates the following output:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![](img/ab9e809c-61bc-42ad-a4af-86d262f6030e.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ab9e809c-61bc-42ad-a4af-86d262f6030e.png)'
- en: 'Remember, we are looking to extract just the ZIP code here. The ZIP code is
    embedded in the JSON, but it will take a bit of work to extract due to the formatting
    of this response JSON object. Let''s do that now:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们这里的目标是提取 ZIP 码。ZIP 码嵌入在 JSON 中，但由于响应 JSON 对象的格式，这需要一些工作来提取。我们现在来做这个：
- en: '[PRE31]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The preceding code results in the following output:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码会输出以下结果：
- en: '![](img/aee66726-b6b6-4501-ae33-4c65987eb78a.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aee66726-b6b6-4501-ae33-4c65987eb78a.png)'
- en: 'It looks like we''re getting the information we want. There is one caveat,
    however. Looking deeper into the address column, we can see that occasionally,
    a full address is not given. This will result in no ZIP code coming back. We''ll
    just have to deal with that later. For now, let''s build a function to retrieve
    the ZIP codes that we can do as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们正在获得我们想要的信息。然而，有一个注意事项。深入查看地址栏时，我们可以看到偶尔并没有提供完整的地址。这将导致没有邮政编码返回。我们只需稍后处理这个问题。现在，让我们构建一个函数来检索邮政编码，代码如下：
- en: '[PRE32]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: There's a fair bit of code in the preceding snippet, so let's talk about what's
    going on here.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码片段有不少内容，让我们来讨论一下这里的过程：
- en: First, at the bottom, you see that we are running an `apply` method on our DataFrame.
    Because we have set `axis=1`, each row of the `df` DataFrame will be passed into
    our function. Within the function, we are piecing together an address to call
    with the Google Maps Geolocation API. We are using regex to limit our calls to
    only those that start with a street number. We then iterate over the JSON response
    to parse out the ZIP code. If we find a ZIP code, we return it, otherwise we return
    a `np.nan`, or null value. Note that this function will take some time to run
    as we have to make many hundreds of calls and then parse out the response.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在底部，你会看到我们在DataFrame上运行了`apply`方法。因为我们设置了`axis=1`，所以`df` DataFrame的每一行都会传递到我们的函数中。在函数内部，我们正在拼接一个地址来调用Google
    Maps地理定位API。我们使用正则表达式限制我们的调用仅限于那些以街道编号开头的地址。然后，我们遍历JSON响应来解析出邮政编码。如果找到了邮政编码，我们就返回它，否则返回`np.nan`，即空值。请注意，这个函数运行时需要一些时间，因为我们需要进行数百次调用并解析响应。
- en: 'Once that completes, we will have a DataFrame that now has the ZIP code for
    those properties that had a proper address provided. Let''s take a look and see
    how many that actually is:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成，我们将得到一个新的DataFrame，其中包含了那些提供了完整地址的物业的邮政编码。让我们来看一下，看看有多少条数据实际上是有邮政编码的：
- en: '[PRE33]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The preceding code generated the following output:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![](img/c182f5b9-f892-46cf-8c3e-2730e41403fc.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c182f5b9-f892-46cf-8c3e-2730e41403fc.png)'
- en: So, we lost quite a bit of our data, but nevertheless, what we have now is more
    useful in many ways, so we will continue on.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们失去了相当一部分数据，但无论如何，现在我们拥有的数据在许多方面都更有用，因此我们将继续进行。
- en: 'First, since it takes so long to retrieve all the ZIP code data, let''s now
    store what we have so that we can always retrieve it later if necessary, and not
    have to make all those API calls again. We do that with the following code:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，由于获取所有邮政编码数据需要较长时间，让我们现在存储我们已经获得的数据，以便以后需要时可以随时检索，而不必再次进行所有的API调用。我们可以通过以下代码来实现：
- en: '[PRE34]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Let''s also store just the data with the ZIP code information in a new DataFrame.
    We will call that one `zdf`:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将把仅包含邮政编码信息的数据存储在一个新的DataFrame中。我们将其命名为`zdf`：
- en: '[PRE35]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Finally, let''s do an aggregation by ZIP code to see what the average rental
    price is by ZIP:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们按邮政编码进行聚合，看看每个邮政编码的平均租金是多少：
- en: '[PRE36]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The preceding code generates the following output:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![](img/bc5c1458-e3e6-4320-adaf-0179894ec839.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bc5c1458-e3e6-4320-adaf-0179894ec839.png)'
- en: We can see this jibes with our earlier finding that the Lincoln Center area
    had the highest mean rental prices, since 10069 is in the Lincoln Center region.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，这与我们之前发现的林肯中心区域的租金均价最高一致，因为10069就在林肯中心区域。
- en: Let's now move on to visualizing this information.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们继续进行数据可视化：
- en: Visualizing the data
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化数据
- en: Since this data is based on ZIP codes, the best way to visualize it is with
    a choropleth. If you're unfamiliar with a choropleth, it's simply a visualization
    that represents the data according to a color spectrum. Let's create one now using
    a Python mapping library called `folium` at [https://github.com/python-visualization/folium](https://github.com/python-visualization/folium)**.**
    If you don't have folium installed, again, it can be done with pip install on
    the command line.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些数据是基于邮政编码的，最好的可视化方式是使用色块图。如果你不熟悉色块图，它只是根据颜色谱表示数据的可视化方式。现在让我们使用一个名为`folium`的Python映射库来创建一个色块图，[https://github.com/python-visualization/folium](https://github.com/python-visualization/folium)**。**
    如果你没有安装folium，可以通过命令行使用`pip install`来安装。
- en: 'Now we''ll go ahead and create our visualization:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们继续创建我们的可视化：
- en: '[PRE37]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'There''s a lot going on here, so let''s take it step by step:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多内容，我们来一步步看：
- en: After importing `folium`, we create a `.Map()` object. We need to pass in coordinates
    and a zoom level to center the map. A Google search for the coordinates of the
    Empire State Building will give us the proper lat and long (flip the sign on the
    longitude to render it properly). Finally, adjust the zoom to get it centered
    appropriately for our data.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在导入`folium`后，我们创建一个`.Map()`对象。我们需要传入坐标和缩放级别来居中地图。通过Google搜索帝国大厦的坐标，可以获得正确的纬度和经度（将经度符号翻转以正确显示）。最后，调整缩放级别，使其适合我们的数据并正确居中。
- en: The next line requires something called a GeoJSON file. This is an open format
    for representing geographic attributes. This can be found by searching for NYC
    GeoJSON files—specifically, ones with ZIP code mappings. Once that is done, we
    reference the GeoJSON file by inputting its path.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一行代码需要使用GeoJSON文件。这是一种表示地理属性的开放格式。您可以通过搜索纽约市的GeoJSON文件来找到它们——特别是那些包含邮政编码映射的文件。完成后，我们通过输入文件路径来引用GeoJSON文件。
- en: Next, we reference our DataFrame in the `data` parameter. Here, we are using
    the mean rent by ZIP code we created previously. The `columns` parameter references
    those. The `key_on` parameter references the part of our JSON file that we are
    targeting, in this instance, the `postalCode`.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们在`data`参数中引用我们的DataFrame。在这里，我们使用的是之前创建的按邮政编码划分的平均租金。`columns`参数引用了这些列。`key_on`参数引用了我们目标JSON文件中的部分内容，在这个例子中是`postalCode`。
- en: Finally, the other options determine the color palette and certain other parameters
    to adjust the legend and coloring.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，其他选项确定了色板和一些其他参数，用于调整图例和颜色。
- en: 'When the cell is run, the map should render inline in your Jupyter Notebook,
    as can be seen in the following diagram:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 当该单元格运行时，地图应该会在您的Jupyter Notebook中呈现，如下图所示：
- en: '![](img/9d831ef3-59ab-4d65-9bf7-d06ff1c1f525.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9d831ef3-59ab-4d65-9bf7-d06ff1c1f525.png)'
- en: With the heat map completed, you can begin to get a sense of which areas have
    higher or lower rents. This could help when targeting a particular area, but let's
    take our analysis deeper by using regression modeling.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 完成热力图后，您可以开始了解哪些区域的租金较高或较低。这可以帮助我们在针对特定区域时做出决策，但让我们通过使用回归建模来进一步深入分析。
- en: Modeling the data
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据建模
- en: 'Let''s begin modeling by using our dataset. We''re going to examine the effect
    that the ZIP code and the number of bedrooms have on the rental price. We''ll
    use two packages here: the first, `statsmodels`, we introduced in [Chapter 1](32e9f384-e739-4a1c-833e-11ee40051ac8.xhtml), *The
    Python Machine Learning Ecosystem*,  but the second, `patsy`, [https://patsy.readthedocs.org/en/latest/index.html](https://patsy.readthedocs.org/en/latest/index.html),
    is a package that makes working with `statsmodels` easier. Patsy allows you to
    use R-style formulas when running a regression. Let''s do that now:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始使用我们的数据集进行建模。我们将分析邮政编码和卧室数量对租金价格的影响。这里我们将使用两个包：第一个是`statsmodels`，我们在[第1章](32e9f384-e739-4a1c-833e-11ee40051ac8.xhtml)《Python机器学习生态系统》中介绍过，而第二个是`patsy`，[https://patsy.readthedocs.org/en/latest/index.html](https://patsy.readthedocs.org/en/latest/index.html)，这个包使得使用`statsmodels`更加简便。Patsy允许您在运行回归时使用类似R语言的公式。我们现在来实现一下：
- en: '[PRE38]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The preceding code generates the following output:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![](img/f3b6bd1e-72ff-467c-b633-784f63ec3eef.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3b6bd1e-72ff-467c-b633-784f63ec3eef.png)'
- en: Note that the preceding output is truncated.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面的输出被截断了。
- en: With those few lines of code, we have just run our first machine learning algorithm.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 只需要几行代码，我们就运行了第一个机器学习算法。
- en: While most people don't tend to think of linear regression as machine learning,
    that's exactly what it is. Linear regression is a type of supervised machine learning.
    Supervised, in this context, simply means we provide the output values for our
    training set.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然大多数人不认为线性回归是机器学习的一部分，但它实际上正是机器学习的一种。线性回归是一种有监督的机器学习方法。在此上下文中，“有监督”意味着我们为训练集提供了输出值。
- en: Let's now unpack what happened there. After our imports, we have two lines that
    relate to the `patsy` module. The first line is the formula we will be using.
    On the left-hand side (before the tilde) is our response, or dependent, variable,
    `rent`. On the right-hand side, we have our independent, or predictor, variables,
    `zip` and `beds`. This formula simply means we want to know how the ZIP code and
    the number of bedrooms will affect the rental price.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来拆解一下发生了什么。在导入包之后，我们有两行与`patsy`模块相关。第一行是我们将使用的公式。在波浪号（~）左侧是我们的响应变量或因变量`rent`。在右侧是我们的自变量或预测变量`zip`和`beds`。这个公式的意思就是我们想知道邮政编码和卧室数量如何影响租金价格。
- en: Our formula is then passed into `patsy.dmatrices()` along with our DataFrame
    containing corresponding column names. Patsy is then set to return a DataFrame
    with our `X` matrix of predictor variables and a *y* vector with our response
    variable. These are then passed into `sm.OLS()`, on which we also call `.fit()` to
    run our model. Finally, we print out the results of the model.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的公式接着与包含相应列名的 DataFrame 一起传递给 `patsy.dmatrices()`。Patsy 会返回一个包含预测变量 `X` 矩阵和响应变量
    *y* 向量的 DataFrame。这些数据随后被传递给 `sm.OLS()`，并通过 `.fit()` 来运行我们的模型。最后，我们输出模型的结果。
- en: As you can see, there is a lot of information provided in the resulting output.
    Let's begin by looking at the topmost section. We see that the model included
    `555` observations, that it has an adjusted R² of `.367`, and that it is significant
    with an `F-statistic` probability of `3.50e-31`. What is the significance of this?
    It means that we have created a model that is able to explain about a third of
    the variance in price using just bedrooms and ZIP code. Is this a good result?
    In order to better answer that, let's now look at the center section of the output.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，输出结果中提供了大量的信息。让我们从最上面的部分开始看。我们看到模型包含了 `555` 个观察值，调整后的 R² 值为 `.367`，并且具有显著性，其
    `F-统计量` 的概率为 `3.50e-31`。这意味着什么呢？这意味着我们建立的模型能够利用卧室数和邮政编码解释大约三分之一的价格方差。这是一个好的结果吗？为了更好地回答这个问题，我们现在来看输出的中间部分。
- en: 'The center section provides us with information on each of the independent
    variables in our model. From left to right, we see the following: the variable,
    the variable''s coefficient in the model, the standard error, the *t*-statistic,
    the *p*-value for the *t*-statistic, and a 95% confidence interval.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 中间部分为我们提供了关于模型中每个自变量的信息。从左到右，我们看到以下内容：变量、模型中的变量系数、标准误差、*t*-统计量、*t*-统计量的 *p*-值，以及
    95% 的置信区间。
- en: What does all of this tell us? If we look at the *p*-value column, we can determine
    whether our individual variables are statistically significant. Statistically
    significant in a regression model means that the relationship between an independent
    variable and a response variable is unlikely to have occurred by chance. Typically,
    statisticians use a *p*-value of `.05` when determining this. A `.05` *p*-value
    means that the results we see would occur by chance only 5% of the time. In terms
    of our output here, the number of bedrooms is clearly significant. What about
    the ZIP codes?
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息告诉我们什么？如果我们查看 *p*-值列，就可以判断各个变量是否在统计上显著。在回归模型中，统计显著性意味着自变量与响应变量之间的关系不太可能是偶然发生的。通常，统计学家使用
    *p*-值为 `.05` 来确定这一点。`.05` 的 *p*-值意味着我们看到的结果只有 5% 的概率是偶然发生的。在这里的输出中，卧室数量显然是显著的。那么邮政编码呢？
- en: 'The first thing to notice here is that our intercept represents the 07302 ZIP
    code. When modeling a linear regression, an intercept is needed. The intercept
    is simply where the regression line meets the *y* axis. Statsmodels will automatically
    select one of the predictor variables to use as the intercept. Here it decided
    on Jersey City, 07302, since it organized the ZIP codes in ascending order. We
    can confirm this by examining the data as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的第一点是，我们的截距表示的是 07302 邮政编码。在进行线性回归建模时，需要一个截距。截距就是回归线与 *y* 轴相交的点。Statsmodels
    会自动选择一个预测变量作为截距。在此，它选择了泽西市（07302），因为它将邮政编码按升序排列。我们可以通过以下方式确认这一点：
- en: '[PRE39]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The preceding code generates the following output:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/6fa694ea-2579-4909-b200-2075c06a0d6e.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6fa694ea-2579-4909-b200-2075c06a0d6e.png)'
- en: Notice that they are in ascending order, and if we look at the sorted ZIP code
    values in our DataFrame, we see the same with the exception of the missing ZIP
    07302, which is now our baseline against which all the others will be compared.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，它们是按升序排列的，如果我们查看 DataFrame 中排序后的邮政编码值，我们会发现除了缺失的邮政编码 07302 外，其他都符合排序规则，07302
    现在成为了我们的基准，所有其他邮政编码将与之进行比较。
- en: Looking at our results output again, we notice that some ZIP codes are highly
    significant and others are not. Let's look at our old friend, the Lincoln Center
    neighborhood, or 10069\. If you remember, it was the area with the highest rents
    in our sample. We would expect that it would be significant and have a large positive
    coefficient when compared to the baseline of Jersey City, and, in fact, it does.
    The *p*-value is 0.000, and the coefficient is 4116\. This means that you can
    expect the rent to be significantly higher near Lincoln Center, compared to an
    equivalent apartment in Jersey City—no surprise there.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 再次查看我们的结果输出，我们注意到一些邮政编码非常显著，而其他的则不显著。让我们来看一下我们的老朋友，林肯中心附近的10069区。如果你记得的话，这个地区是我们样本中租金最高的地方。我们可以预期，与泽西市作为基准相比，它应该是显著的并且有一个较大的正系数，实际上它确实是如此。*p*-值为0.000，系数为4116。这意味着，与你在泽西市的同等公寓相比，你可以预期林肯中心附近的租金会显著更高——这并不令人意外。
- en: Let's now use our model to make a number of forecasts.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用我们的模型进行一系列预测。
- en: Forecasting
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测
- en: 'Let''s say we''ve decided from our prior analysis that we are interested in
    three particular ZIP codes: `10002`, `10003`, and `10009`. How can we use our
    model to determine what we should pay for a given apartment? Let''s now take a
    look.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们从之前的分析中决定，我们对三个特定的邮政编码感兴趣：`10002`，`10003`和`10009`。我们如何使用模型来确定我们应该为某个公寓支付多少钱呢？现在让我们来看一下。
- en: 'First, we need to know what the inputs into the model looked like so that we
    know how to enter a new set of values. Let''s take a look at our `X` matrix:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要了解模型的输入是怎样的，这样我们才能知道如何输入新的数据。让我们来看一下我们的`X`矩阵：
- en: '[PRE40]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The preceding code generates the following output:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![](img/6ecddbd6-bd84-4377-a099-b82414cb21e8.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6ecddbd6-bd84-4377-a099-b82414cb21e8.png)'
- en: 'What we see is that our input is coded with what are called **dummy variables.**
    To represent a ZIP code feature, since it is not numerical, dummy coding is used.
    If the apartment is in 10003, then that column will be coded as `1`, while all
    other ZIP codes are coded as `0`. Beds will be coded according to the actual number
    since they are numerical. So let''s now create our own input row to predict:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到的是，输入数据使用了所谓的**虚拟变量（dummy variables）**编码。由于邮政编码不是数值型特征，所以采用虚拟编码来表示它。如果公寓位于10003区域，那么该列将被编码为`1`，而所有其他邮政编码则编码为`0`。卧室数将根据实际数值进行编码，因为它是数值型特征。所以让我们现在创建自己的输入行进行预测：
- en: '[PRE41]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The preceding code generates the following output:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![](img/7bdb87fb-ee6f-4d97-b81c-e70471996391.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7bdb87fb-ee6f-4d97-b81c-e70471996391.png)'
- en: 'We have just used the index from the `X` matrix and filled in the data with
    all zeros. Let''s now fill in our values. We are going to price a one-bedroom
    apartment in the `10009` area code:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚使用了`X`矩阵中的索引，并用全零填充了数据。现在让我们填入我们的值。我们将定价位于`10009`区号的单卧公寓：
- en: '[PRE42]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The intercept value for a linear regression must always be set to `1` for the
    model in order to return accurate statistical values.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性回归，截距值必须始终设置为`1`，这样模型才能返回准确的统计值。
- en: 'The preceding code generates the following output:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![](img/a3a0c802-ddb2-4516-acd2-a2227ade41e8.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a3a0c802-ddb2-4516-acd2-a2227ade41e8.png)'
- en: 'We have set our features to the appropriate values, so let''s now use our model
    to return a prediction. We''ll need to convert it to a DataFrame and transpose
    it in order to get the correct format. We do this as follows:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将特征设置为合适的值，现在让我们使用模型返回预测结果。我们需要将其转换为DataFrame并进行转置，以获得正确的格式。我们可以按以下方式操作：
- en: '[PRE43]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The preceding code generates the following output:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![](img/0d362192-3996-4c4d-9e57-e5395eb12744.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0d362192-3996-4c4d-9e57-e5395eb12744.png)'
- en: You will recall that `results` was the variable name we saved our model to.
    That model object has a `.predict()` method, which we call with our input values.
    And, as you can see, the model returns a predicted value.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 你会记得`results`是我们保存模型时的变量名。该模型对象有一个`.predict()`方法，我们用输入值调用它。正如你所看到的，模型返回了一个预测值。
- en: 'What if we want to add another bedroom? We can do it as follows:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想添加另一个卧室呢？我们可以按照以下方式操作：
- en: 'Let''s change our inputs and see:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们改变输入并查看结果：
- en: '[PRE44]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Then we''ll run the prediction again:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们再次运行预测：
- en: '[PRE45]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The preceding code generates the following output:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![](img/ebd4fa95-44eb-44f5-9924-a0e47df69849.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ebd4fa95-44eb-44f5-9924-a0e47df69849.png)'
- en: 'It looks like that extra bedroom will cost us about $800 more a month. But
    what if we choose `10069` instead? Lets change our input and see:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 看起来额外的卧室每月大约需要多花$800。但如果我们选择`10069`呢？让我们修改输入并看看：
- en: '[PRE46]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The preceding code generates the following output:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了如下输出：
- en: '![](img/6bf9e978-fcc7-4f1f-ae05-b3fb976d051e.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6bf9e978-fcc7-4f1f-ae05-b3fb976d051e.png)'
- en: According to our model, two bedrooms in the Lincoln Center area is going to
    cost a pretty penny compared to the East Village.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的模型，在林肯中心地区，两间卧室的租金将比东村高出不少。
- en: Extending the model
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展模型
- en: At this point, we have only examined the relationship between the ZIP code,
    bedrooms, and rental price. And while our model had some explanatory benefit,
    we had a minimal dataset and far too few features to adequately examine the complex
    world of real estate valuation.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们仅仅考察了邮政编码、卧室数量与租金价格之间的关系。尽管我们的模型有一些解释性作用，但数据集非常小，特征也太少，无法充分考察房地产估值这个复杂的领域。
- en: Fortunately, however, if we were to add more data and features to the model,
    we could use the exact same framework to expand our analysis.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 然而幸运的是，如果我们向模型中添加更多数据和特征，我们可以使用完全相同的框架来扩展我们的分析。
- en: Some possible future extensions to explore would be utilizing data for restaurants
    and bars available from APIs such as Foursquare or Yelp, or walkability and transportation-proximity
    measures from providers such as Walk Score.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 一些可能的未来扩展可以探索利用来自Foursquare或Yelp等API的餐厅和酒吧数据，或者利用Walk Score等提供商的数据来评估步行便利性和交通便捷性。
- en: There are a number of ways to extend the model, and I suggest if you do pursue
    working on a project such as this that you explore a variety of measures. More
    data is released every day and, with it, models can only improve.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展模型有很多种方式，我建议如果你确实打算做这样的项目，可以探索多种方法。每天都有更多的数据发布，借助这些数据，模型只能越来越好。
- en: Summary
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小结
- en: In this chapter, we learned how to acquire data on real estate listings, how
    to utilize the functionality of pandas to manipulate and sanitize that data, how
    to inspect the data visually with choropleths, and finally, how to build and use
    regression modeling to price out an apartment.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们学习了如何获取房地产列表数据，如何利用pandas的功能对数据进行处理和清洗，如何通过地理热力图对数据进行可视化检查，最后，如何构建和使用回归模型来估算公寓价格。
- en: At this point, we have just touched the surface of machine learning. In the
    chapters that follow, we'll go further into how to evaluate the quality of our
    model, and we'll also learn how to turn them into full-scale solutions.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，我们仅仅触及了机器学习的表面。在接下来的章节中，我们将深入学习如何评估模型的质量，同时也将了解如何将这些模型转化为完整的解决方案。
