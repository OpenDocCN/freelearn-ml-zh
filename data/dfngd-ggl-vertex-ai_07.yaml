- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Training Fully Custom ML Models with Vertex AI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Vertex AI训练完全自定义的ML模型
- en: In the previous chapters, we learned about training no-code (Auto-ML) as well
    as low-code (BQML) **Machine Learning** (**ML**) models with minimum technical
    expertise required. These solutions are really handy when it comes to solving
    common ML problems. However, sometimes the problem or data itself is so complex
    that it requires the development of custom **Artificial Intelligence** (**AI**)
    models, in most cases large deep learning-based models. Working on custom models
    requires a significant level of technical expertise in the fields of ML, deep
    learning, and AI. Sometimes, even with this expertise, it becomes really difficult
    to manage training and experiments of large-scale custom deep learning models
    due to a lack of resources, compute, and proper metadata tracking mechanisms.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们学习了如何使用最小技术专长训练无代码（Auto-ML）以及低代码（BQML）**机器学习**（**ML**）模型。当解决常见的机器学习问题时，这些解决方案非常实用。然而，有时问题或数据本身非常复杂，需要开发自定义的**人工智能**（**AI**）模型，在大多数情况下是大型基于深度学习的模型。在自定义模型上工作需要机器学习、深度学习和人工智能领域的显著技术专长。有时，即使拥有这种专长，由于资源、计算能力和适当的元数据跟踪机制不足，管理大规模自定义深度学习模型的训练和实验也变得非常困难。
- en: 'To make the lives of ML developers easier, Vertex AI provides a managed environment
    for launching large-scale custom training jobs. Vertex AI-managed jobs let us
    track useful metadata, monitor jobs through the Google Cloud console UI, and launch
    large-scale batch inference jobs without the need to actively monitor them. In
    this chapter, we will learn how to work with custom deep learning-based models
    on Google Vertex AI. Specifically, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使机器学习开发者的生活更轻松，Vertex AI提供了一个托管环境，用于启动大规模的自定义训练作业。Vertex AI管理的作业让我们能够跟踪有用的元数据，通过Google
    Cloud控制台UI监控作业，并且无需主动监控即可启动大规模批量推理作业。在本章中，我们将学习如何在Google Vertex AI上使用自定义深度学习模型。具体来说，我们将涵盖以下主题：
- en: Building a basic deep learning model with TensorFlow
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorFlow构建基本的深度学习模型
- en: Packaging a model to submit to Vertex AI as a training job
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型打包以提交给Vertex AI进行训练作业
- en: Monitoring model training progress
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控模型训练进度
- en: Evaluating trained models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估训练后的模型
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires basic-level knowledge of the deep learning framework TensorFlow
    and neural networks. Code artifacts can be found in the following GitHub repo
    – [https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/tree/main/Chapter07](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/tree/main/Chapter07)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要具备深度学习框架TensorFlow和神经网络的入门级知识。代码工件可以在以下GitHub仓库中找到 - [https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/tree/main/Chapter07](https://github.com/PacktPublishing/The-Definitive-Guide-to-Google-Vertex-AI/tree/main/Chapter07)
- en: Building a basic deep learning model with TensorFlow
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow构建基本的深度学习模型
- en: '**TensorFlow**, or **TF** for short, is an end-to-end platform for building
    ML models. The main focus of the TensorFlow framework is to simplify the development,
    training, evaluation, and deployment of deep neural networks. When it comes to
    working with unstructured data (such as images, videos, audio, etc.), neural network-based
    solutions have achieved significantly better results than traditional ML approaches
    that mostly rely on handcrafted features. Deep neural networks are good at understanding
    complex patterns from high-dimensional data points (for example, an image with
    millions of pixels). In this section, we will develop a basic neural network-based
    model using TensorFlow. In the next few sections, we will see how Vertex AI can
    help with setting up scalable and systemic training/tuning of such custom models.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow**，简称**TF**，是一个用于构建机器学习模型的端到端平台。TensorFlow框架的主要重点是简化深度神经网络的开发、训练、评估和部署。当涉及到处理非结构化数据（例如图像、视频、音频等）时，基于神经网络的解决方案比主要依赖于手工特征的传统的机器学习方法取得了显著更好的结果。深度神经网络擅长从高维数据点中理解复杂模式（例如，包含数百万像素的图像）。在本节中，我们将使用TensorFlow开发一个基本的基于神经网络的模型。在接下来的几节中，我们将看到Vertex
    AI如何帮助设置可扩展和系统化的自定义模型训练/调优。'
- en: Important Note
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: It is important to note that TensorFlow is not the only ML framework that Vertex
    AI supports. Vertex AI supports many different ML frameworks and open-source projects
    including Pytorch, Spark and XGBoost. Pytorch is one of the fastest growing ML
    frameworks and with Vertex AI’s Pytorch integrations, we can easily train, deploy
    and orchestrate PyTorch models in production. Vertex AI provides prebuilt training
    and serving containers and also supports optimized distributed training of PyTorch
    models. Similarly, Vertex AI provides prebuilt training, serving and explainability
    features for multiple ML frameworks including XGBoost, TensorFlow, Pytorch and
    Scikit-learn.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，TensorFlow并不是Vertex AI支持的唯一机器学习框架。Vertex AI支持许多不同的机器学习框架和开源项目，包括Pytorch、Spark和XGBoost。Pytorch是增长最快的机器学习框架之一，借助Vertex
    AI的Pytorch集成，我们可以轻松地在生产环境中训练、部署和编排PyTorch模型。Vertex AI提供了预构建的训练和托管容器，并支持PyTorch模型的优化分布式训练。同样，Vertex
    AI为包括XGBoost、TensorFlow、Pytorch和Scikit-learn在内的多个机器学习框架提供了预构建的训练、托管和可解释性功能。
- en: Experiment – converting black-and-white images into color images
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验 – 将黑白图像转换为彩色图像
- en: In this experiment, we will develop a TensorFlow-based deep learning model that
    takes black-and-white images as input and converts them into color images. As
    this exercise, requires developing a custom model, we will start our initial development
    work on a Jupyter Notebook. The first step is to create a user-managed Jupyter
    Notebook inside Vertex AI Workbench using a preconfigured TensorFlow image. More
    details on how to successfully create a Vertex AI Workbench notebook instance
    can be found in [*Chapter 4*](B17792_04.xhtml#_idTextAnchor056), *Vertex AI Workbench*.
    Next, let’s launch one Jupyter Notebook from the JupyterLab application. We are
    now all set to start working on our experiment.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们将开发一个基于TensorFlow的深度学习模型，该模型以黑白图像为输入，并将它们转换为彩色图像。由于这个练习需要开发一个自定义模型，我们将从Jupyter
    Notebook中的初始开发工作开始。第一步是在Vertex AI Workbench中使用预配置的TensorFlow图像创建一个用户管理的Jupyter
    Notebook。有关如何成功创建Vertex AI Workbench笔记本实例的更多详细信息，请参阅[*第4章*](B17792_04.xhtml#_idTextAnchor056)，*Vertex
    AI Workbench*。接下来，让我们从JupyterLab应用程序启动一个Jupyter Notebook。我们现在已经准备好开始我们的实验了。
- en: 'We will start with importing useful libraries (prebuilt Python packages) in
    the first cell of our notebook. In this experiment, we will be using the following
    Python libraries – `numpy` for multi-dimensional array manipulation, TensorFlow
    for developing a deep learning model, OpenCV (or `cv2`) for image manipulation,
    and `matplotlib` for plotting images or graphs:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在笔记本的第一个单元格中开始导入有用的库（预构建的Python包）。在这个实验中，我们将使用以下Python库 – `numpy`用于多维数组操作，TensorFlow用于开发深度学习模型，OpenCV（或`cv2`）用于图像处理，以及`matplotlib`用于绘制图像或图表：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We will need an image dataset with at least a few thousand images to train
    and test our model. In this experiment, we will work with the **Oxford-IIIT Pet**
    dataset, which is a public and free-to-use dataset. This dataset consists of around
    7k pet images from more than 30 different annotated categories. The dataset can
    be downloaded from the following website: [https://www.robots.ox.ac.uk/~vgg/data/pets/](https://www.robots.ox.ac.uk/~vgg/data/pets/).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个包含至少几千张图像的图像数据集来训练和测试我们的模型。在这个实验中，我们将使用**Oxford-IIIT Pet**数据集，这是一个公开且免费使用的数据集。该数据集包含来自30多个不同标注类别的约7k张宠物图像。数据集可以从以下网站下载：[https://www.robots.ox.ac.uk/~vgg/data/pets/](https://www.robots.ox.ac.uk/~vgg/data/pets/)。
- en: 'We can also download this dataset using the following commands in our terminal:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用以下终端命令下载这个数据集：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once the downloads are complete, put the zipped files in the same directory
    as our notebook. Now, let’s create a `!` sign in a notebook cell lets us run terminal
    commands from within Jupyter Notebook):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下载完成后，将压缩文件放在与我们的笔记本相同的目录中。现在，让我们在笔记本单元格中创建一个`!`符号，这样我们就可以在Jupyter Notebook中运行终端命令了）：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As our current experiment is concerned with converting black-and-white images
    into colored versions, we will not be using annotations. Now, let’s quickly verify
    in a new cell whether we have all the images successfully copied into the **data**
    folder:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们当前的实验是关于将黑白图像转换为彩色版本，我们将不会使用标注。现在，让我们快速在一个新单元格中验证是否已成功将所有图像复制到**data**文件夹中：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here, the `glob` module helps us by listing all the `.jpg` image paths inside
    the data directory. The length of this list will be equal to the number of images.
    The preceding code should print the following output:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`glob`模块通过列出数据目录内所有的`.jpg`图像路径来帮助我们。这个列表的长度将与图像数量相等。前面的代码应该打印出以下输出：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now that we have successfully downloaded and extracted data, let’s check a
    few images to be sure everything is fine. The following code block will plot a
    few random images with their annotations:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功下载并提取了数据，让我们检查一些图像以确保一切正常。下面的代码块将绘制一些带有注释的随机图像：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, we are extracting the image class (or annotation) from the image path
    name itself as all images have the pet category in their filenames. The output
    of the preceding code should look something like shown in *Figure 7**.1*.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们通过从图像路径名称本身提取图像类别（或注释），因为所有图像的文件名中都有宠物类别。前面代码的输出应该类似于*图7.1*中所示。
- en: '![Figure 7.1 – A few samples from the pet dataset](img/B17792_07_1.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图7.1 – 宠物数据集的一些样本](img/B17792_07_1.jpg)'
- en: Figure 7.1 – A few samples from the pet dataset
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1 – 宠物数据集的一些样本
- en: 'Now that we have verified our dataset, let’s split these images into three
    sets – train, validation, and test – as we usually do for training/validating
    and testing ML models. We will keep 60% of the images for training, 20% for validation,
    and the remaining 20% for testing. One simple way to do these splits is as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经验证了我们的数据集，让我们将这些图像分成三个集合——训练集、验证集和测试集——就像我们通常为训练/验证和测试机器学习模型所做的那样。我们将保留60%的图像用于训练，20%用于验证，剩下的20%用于测试。完成这些分割的一个简单方法如下：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The main focus of this experiment is to develop a deep learning model that converts
    black-and-white images into color images. To learn this mapping, the model will
    require pairs of black-and-white and corresponding color versions in order to
    learn this mapping. Our dataset already has color images. We will utilize the
    OpenCV library to convert them into grayscale (black-and-white) images and use
    them as input in our model. We will compare the output with their color versions.
    Another important thing to keep in mind is that our deep learning model will take
    fixed-size images as inputs, so we also need to bring all input images into a
    common resolution. In our experiment, we will change all of our images to have
    an 80x80 resolution. We already have training, validation, and test splits of
    the image paths. We can now read those files and prepare data for training, validation,
    and testing purposes. The following code blocks can be used to prepare the dataset
    as described previously.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本实验的主要重点是开发一个深度学习模型，该模型可以将黑白图像转换为彩色图像。为了学习这种映射，模型将需要黑白图像及其对应的彩色版本对来学习这种映射。我们的数据集已经包含了彩色图像。我们将利用OpenCV库将它们转换为灰度（黑白）图像，并将它们作为模型输入。我们将比较输出与它们的彩色版本。需要注意的是，我们的深度学习模型将接受固定大小的图像作为输入，因此我们还需要将所有输入图像调整到相同的分辨率。在我们的实验中，我们将所有图像的分辨率更改为80x80。我们已经有图像路径的训练、验证和测试分割。我们现在可以读取这些文件，为训练、验证和测试准备数据。下面的代码块可以用来准备之前描述的数据集。
- en: 'Let’s first define empty lists for storing training, validation, and test data,
    respectively:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先定义空列表来分别存储训练、验证和测试数据：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here, we read training images, resize them to the required size, create a black-and-white
    version of each of them, and store them as target images:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们读取训练图像，将它们调整到所需的大小，为每个图像创建一个黑白版本，并将它们存储为目标图像：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Similarly, we repeat the same process for validation files:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们对验证文件重复相同的流程：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, prepare test files as well in a similar way:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，以类似的方式准备测试文件：
- en: '[PRE10]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note that images are represented with pixel values ranging from 0 to 255\. We
    are normalizing pixel values and bringing them into the range [-1, 1] by subtracting
    and dividing by 127.5\. Data normalization makes the optimization of deep learning
    models smoother and more stable.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，图像是用0到255之间的像素值表示的。我们通过减去并除以127.5来归一化像素值，并将它们带入[-1, 1]的范围内。数据归一化使得深度学习模型的优化更加平滑和稳定。
- en: Now that we have successfully prepared our dataset with train, validation, and
    test set splits, let’s check a few samples to confirm that the data has been prepared
    correctly. The following code block chooses some random training set images and
    plots them.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功地将数据集准备好，包括训练集、验证集和测试集的分割，让我们检查一些样本以确认数据已经被正确准备。下面的代码块选择了一些随机的训练集图像并将它们绘制出来。
- en: 'Let’s plot some input images to get a sense of the data:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制一些输入图像，以了解数据：
- en: '[PRE11]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We will also be plotting the output versions (colored versions) of these randomly
    chosen images:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将绘制这些随机选择的图像的输出版本（彩色版本）：
- en: '[PRE12]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: If everything is correct, we should see input-output pair images very similar
    to as in *Figure 7**.2*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正确，我们应该看到输入-输出对图像与*图7**.2*中的非常相似。
- en: '![](img/B17792_07_2.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17792_07_2.jpg)'
- en: Figure 7.2 – Sample input-output pairs for data verification
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 – 数据验证的样本输入-输出对
- en: 'As we are dealing with image data here, we will be working with a **Convolutional
    Neural Network** (**CNN**)-based model so that we can extract useful features
    from image data. The current research shows that CNNs can be very useful in extracting
    features and other useful information from image data. As we will be working with
    CNNs here, we need to convert our image dataset into NumPy arrays, and also add
    one channel dimension to each black-and-white input image (CNNs accept image input
    as a three-dimensional array, one dimension each for width, height, and channels).
    A colored image will already have three channels, one for each color value – R,
    G, and B. The following code block prepares our final dataset as per the steps
    described previously:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在这里处理图像数据，我们将使用基于**卷积神经网络**（**CNN**）的模型，以便我们可以从图像数据中提取有用的特征。当前的研究表明，CNN在从图像数据中提取特征和其他有用信息方面非常有用。由于我们将在这里使用CNN，我们需要将我们的图像数据集转换为NumPy数组，并且还需要为每个黑白输入图像添加一个通道维度（CNN接受图像输入为一个三维数组，每个维度分别对应宽度、高度和通道）。彩色图像已经具有三个通道，每个通道对应一个颜色值
    – R、G和B。以下代码块根据之前描述的步骤准备我们的最终数据集：
- en: '[PRE13]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now, once again, let’s check the dimensions of our dataset splits:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，再次检查我们数据集分割的维度：
- en: '[PRE14]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'It should print something like this:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 应该打印出类似以下内容：
- en: '[PRE15]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Everything looks great from a data perspective. Let’s jump into defining our
    neural network architecture.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据角度来看，一切看起来都很不错。让我们跳转到定义我们的神经网络架构。
- en: In this experiment, we will define a TensorFlow-based CNN that takes black-and-white
    images as input and predicts their colored variants as output. The model architecture
    can be broadly divided into two parts – **encoder** and **decoder**. The encoder
    part of the model takes a black-and-white image as input and extracts useful features
    from it by passing it through four down-sampling convolutional layers. Each convolutional
    layer is followed by layers of **LeakyReLU** activation and **batch normalization**
    except for the last layer, which has a **dropout** layer in place of batch normalization.
    After passing through the encoder model, an input image with the dimensions (80,
    80, 1) changes into a feature vector with the dimensions (5, 5, 256).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们将定义一个基于TensorFlow的CNN，它以黑白图像为输入，并预测它们的彩色变体作为输出。模型架构可以大致分为两部分 – **编码器**和**解码器**。模型的编码器部分以黑白图像为输入，并通过四个下采样卷积层从中提取有用的特征。每个卷积层后面跟着LeakyReLU激活层和批归一化层，除了最后一层，它用**dropout**层代替了批归一化层。通过编码器模型后，一个尺寸为（80,
    80, 1）的输入图像变成了一个尺寸为（5, 5, 256）的特征向量。
- en: The second part of the model is called the decoder. The decoder part takes the
    feature vector from the encoder output and converts it back into a colored version
    of the corresponding input image. The decoder is made up of four transpose-convolutional
    or up-sampling layers. Each decoder layer is followed by layers of ReLU activation
    and batch normalization except for the last layer, which has tanh activation and
    does not have a normalization layer. tanh activation restricts final output vector
    values into the range [-1,1], which is desired for our output image.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的第二部分被称为解码器。解码器部分从编码器的输出中获取特征向量，并将其转换回对应输入图像的彩色版本。解码器由四个转置卷积或上采样层组成。每个解码器层后面跟着ReLU激活层和批归一化层，除了最后一层，它有tanh激活而没有归一化层。tanh激活将最终输出向量的值限制在[-1,1]的范围内，这是我们输出图像所期望的。
- en: 'The following code blocks define the TensorFlow model:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块定义了TensorFlow模型：
- en: '[PRE16]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The encoder part starts from here, within the same function:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器部分从这里开始，在同一个函数内：
- en: '[PRE17]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The decoder part starts from here, within the same function:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器部分从这里开始，在同一个函数内：
- en: '[PRE18]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Finally, add tanh activation to get the required output image in colored format:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，添加tanh激活函数以获得所需输出的彩色图像：
- en: '[PRE19]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, let’s create a TensorFlow model object and print the summary of our model:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个TensorFlow模型对象并打印我们模型的摘要：
- en: '[PRE20]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This should print the model summary as shown in *Figure 7**.3*.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会打印出如图*图7.3*所示的模型摘要。
- en: '![Figure 7.3 – TensorFlow model summary (see full summary on Github)](img/B17792_07_3.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图7.3 – TensorFlow模型摘要（在GitHub上查看完整摘要）](img/B17792_07_3.jpg)'
- en: Figure 7.3 – TensorFlow model summary (see full summary on GitHub)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 – TensorFlow模型摘要（在GitHub上查看完整摘要）
- en: 'As we can see from the summary, our model has roughly 1.1 million trainable
    parameters. The next step is to compile the TensorFlow model:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从摘要中我们可以看出，我们的模型大约有110万个可训练参数。下一步是编译TensorFlow模型：
- en: '[PRE21]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We are using the Adam optimizer with a learning rate of 0.0002 and the `beta_1`
    parameter with a value of 0.5\. Here, `beta_1` represents the value for the exponential
    decay rate for the first-moment estimates and the learning rate tells the optimizer
    the rate of updating the model parameter values during training. The rest of the
    parameter values are kept as the default. The idea is to pass a black-and-white
    image and reconstruct its colored version, so we will be using the **Mean Squared
    Error** (**MSE**) loss function as a reconstruction loss on the pixel level.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用学习率为0.0002的Adam优化器以及值为0.5的`beta_1`参数。在这里，`beta_1`代表第一矩估计的指数衰减率，学习率告诉优化器在训练期间更新模型参数值的速率。其余的参数值保持默认。我们的想法是传递一个黑白图像并重建其彩色版本，因此我们将使用**均方误差**（**MSE**）作为像素级别的重建损失函数。
- en: 'We are all set to start the training now. We will train our model for about
    100 epochs, with a batch size of 128 for this experiment, and check the results.
    The following code snippet starts the training:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好开始训练了。我们将在这个实验中使用128个批次的尺寸，训练模型大约100个周期，并检查结果。以下代码片段开始训练：
- en: '[PRE22]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output logs should look something like the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 输出日志应类似于以下内容：
- en: '[PRE23]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To check whether our training went smoothly, we can have a look at the loss
    charts from the `history` variable:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查我们的训练是否顺利，我们可以查看`history`变量中的损失图表：
- en: '[PRE24]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The preceding snippet will plot the training and validation loss as a line chart
    for all the training epochs. The output graphs should look something like *Figure
    7**.4*. As we can see, training and validation loss are consistently decreasing
    as training progresses. It is reassuring that our training is going in the right
    direction.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段将绘制所有训练周期的训练和验证损失作为折线图。输出图表应类似于*图7.4*。正如我们所见，随着训练的进行，训练和验证损失持续下降。我们的训练朝着正确的方向进行，这让人感到放心。
- en: '![Figure 7.4 – Training and validation loss](img/B17792_07_4.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图7.4 – 训练和验证损失](img/B17792_07_4.jpg)'
- en: Figure 7.4 – Training and validation loss
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 – 训练和验证损失
- en: 'The final step is now to check the results on an unseen test dataset. The following
    code chooses some random samples from `test_set` and generates model outputs for
    them. We’ve also plotted input images, model-generated colored images, and actual
    colored images for understanding purposes:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是检查一个未见过的测试数据集上的结果。以下代码从`test_set`中选择一些随机样本并为它们生成模型输出。我们还绘制了输入图像、模型生成的彩色图像和实际彩色图像，以便理解。
- en: '[PRE25]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Plot a few test images to verify the model outputs:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制几个测试图像以验证模型输出：
- en: '[PRE26]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Here, the model generates a colored version:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，模型生成一个彩色版本：
- en: '[PRE27]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Also, plot the real colored version for reference:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还可以绘制一个参考的彩色版本：
- en: '[PRE28]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: When plotting model outputs or input images, we add 1.0 to the image array and
    divide by 2.0\. We are doing this because during data preprocessing, we normalized
    image pixel values into the range [-1,1]. But ideally, image pixel values can’t
    be negative, so we need to inverse our transformation for image plotting purposes.
    So, adding 1.0 and dividing by 2.0 brings pixel values into the range [0,1], which
    is supported by Matplotlib for plotting. See *Figure 7**.5*.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当绘制模型输出或输入图像时，我们将1.0加到图像数组上，然后除以2.0。我们这样做是因为在数据预处理过程中，我们将图像像素值归一化到[-1,1]的范围内。但理想情况下，图像像素值不能为负，因此我们需要对图像绘制目的进行逆变换。所以，加1.0并除以2.0将像素值带入[0,1]的范围内，这是Matplotlib绘图所支持的。参见*图7.5*。
- en: '![Figure 7.5 – Black-and-white to color model output](img/B17792_07_5.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图7.5 – 黑白到彩色模型输出](img/B17792_07_5.jpg)'
- en: Figure 7.5 – Black-and-white to color model output
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 – 黑白到彩色模型输出
- en: As we can see from the preceding outputs, our model is learning some kind of
    colorization, which is, of course, not ideal but still looks pretty good. An interesting
    thing to notice is that it is not filling the color gradient randomly; we can
    clearly spot the main objects as they have a different contrast from the background.
    Given that we had a very small model and small training dataset, this performance
    is quite promising.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述的输出所示，我们的模型正在学习某种着色，这当然不是理想的，但看起来仍然相当不错。一个有趣的现象是它不是随机填充颜色渐变；我们可以清楚地看到主要对象，因为它们与背景有不同的对比度。鉴于我们有一个非常小的模型和小的训练数据集，这种性能相当有希望。
- en: However, this is not the best model architecture for solving the image colorization
    problem. Nowadays, generative models such as **Generative Adversarial Networks**
    (**GANs**) provide the best results for such problems. We will study GANs later
    in this book, but for now, let’s stick to this simple experiment. Next, we will
    work with other Vertex AI tools that will make our lives easier when it comes
    to experimentation.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不是解决图像着色问题的最佳模型架构。如今，生成模型如 **生成对抗网络**（GANs）为这类问题提供了最佳结果。我们将在本书的后面部分研究 GANs，但现在，让我们继续这个简单的实验。接下来，我们将使用其他
    Vertex AI 工具，这些工具将使我们的实验更容易进行。
- en: Packaging a model to submit it to Vertex AI as a training job
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将模型打包以提交给 Vertex AI 作为训练作业
- en: The previous section demonstrated a small image colorization experiment on a
    Vertex AI Workbench notebook. Notebooks are great for small-scale and quick experiments,
    but when it comes to large-scale experiments (with more compute and/or memory
    requirements), it is advised to launch them as a Vertex AI job and specify desired
    machine specifications (accelerators such as GPU or TPU if needed) for optimal
    experimentation. Vertex AI jobs also let us execute tons of experiments in parallel
    without waiting for the results of a single experiment. Experiment tracking is
    also quite easy with Vertex AI jobs, so it becomes easier to compare your latest
    experiments with past experiments with the help of saved metadata and the Vertex
    AI UI. Now, let’s use our model experimentation setup from the previous section
    and launch it as a Vertex AI training job.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节演示了在 Vertex AI Workbench 笔记本上进行的小型图像着色实验。笔记本非常适合小规模和快速实验，但当涉及到大规模实验（具有更多的计算和/或内存需求）时，建议将其作为
    Vertex AI 作业启动，并指定所需的机器规格（如果需要，指定加速器如 GPU 或 TPU）以实现最佳实验。Vertex AI 作业还允许我们并行执行大量实验，而无需等待单个实验的结果。使用
    Vertex AI 作业进行实验跟踪也非常简单，因此，借助保存的元数据和 Vertex AI UI，比较您最新的实验与过去的实验变得更加容易。现在，让我们使用上一节中的模型实验设置，并将其作为
    Vertex AI 训练作业启动。
- en: Important note
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 重要注意事项
- en: Vertex AI jobs run in a containerized environment, so in order to launch an
    experiment, we must package our entire code (including reading data, preprocessing,
    model building, training, and evaluation) into a single script to be launched
    within the container. Google Cloud provides tons of prebuilt container images
    for training and evaluation (with dependencies pre-installed for desired frameworks
    such as TensorFlow, PyTorch, etc.). Plus, we also have the flexibility of defining
    our own custom container with any kind of dependencies that we may need.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI 作业在容器化环境中运行，因此为了启动一个实验，我们必须将我们的整个代码（包括读取数据、预处理、模型构建、训练和评估）打包成一个在容器内运行的单一脚本。Google
    Cloud 提供了大量的预构建容器镜像用于训练和评估（预先安装了所需的框架依赖，如 TensorFlow、PyTorch 等）。此外，我们还可以灵活地定义我们自己的自定义容器，包含我们可能需要的任何类型的依赖。
- en: 'For the experiment from the previous section, as we downloaded open source
    data into our Jupyter environment, this data is not yet present in **Google Cloud
    Storage** (**GCS**) (i.e., a GCS bucket or BigQuery). So, first, we need to store
    this data somewhere such that our Vertex AI training job can read it from within
    the training container. To make things easier for us, we will upload our pre-processed
    data into a storage bucket. This will save us the effort of preparing data again
    within the job container. We can use the following script to save our prepared
    data into a GCS bucket:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上一节中的实验，由于我们将开源数据下载到我们的 Jupyter 环境中，这些数据尚未存在于 **Google Cloud Storage**（GCS）（即
    GCS 存储桶或 BigQuery）。因此，首先，我们需要将这些数据存储在某个地方，以便我们的 Vertex AI 训练作业可以在训练容器内读取它。为了让我们更容易操作，我们将我们的预处理数据上传到存储桶中。这将节省我们在作业容器内再次准备数据的精力。我们可以使用以下脚本将我们的准备数据保存到
    GCS 存储桶中：
- en: '[PRE29]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Note that before executing this code, we must create a bucket where we want
    to store these NumPy arrays. In this case, we have already created one bucket
    with the name `data-bucket-417812395597`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在执行此代码之前，我们必须创建一个存储桶，用于存储这些 NumPy 数组。在这种情况下，我们已创建了一个名为 `data-bucket-417812395597`
    的存储桶。
- en: 'We can read these NumPy arrays in any number of training jobs/experiments using
    the following script:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下脚本在任意数量的训练作业/实验中读取这些 NumPy 数组：
- en: '[PRE30]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Our data requirements are now all set. Next, let’s work on setting up our Vertex
    AI training job.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据需求现在已经全部设置好了。接下来，让我们着手设置我们的 Vertex AI 训练作业。
- en: 'First, we will install some useful packages required to define and launch Vertex
    AI jobs:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将安装一些必要的包，这些包用于定义和启动 Vertex AI 作业：
- en: '[PRE31]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Once package installation is done, we will move to a new notebook and import
    useful libraries:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成包安装，我们将转到一个新的笔记本并导入有用的库：
- en: '[PRE32]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, we will define our project configurations:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义我们的项目配置：
- en: '[PRE33]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Note that we have created a bucket with the name `my-training-artifacts` to
    store all the intermediate metadata and artifacts as a result of our Vertex AI
    job.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们已经创建了一个名为 `my-training-artifacts` 的存储桶，用于存储 Vertex AI 作业产生的所有中间元数据和工件。
- en: 'Next, let’s initialize the Vertex AI SDK with our project configurations:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们使用我们的项目配置初始化 Vertex AI SDK：
- en: '[PRE34]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'For our experimentations, we will be using prebuilt TensorFlow images as our
    model is also based on TensorFlow. Let’s define the images to be used:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的实验，我们将使用预构建的 TensorFlow 图像作为我们的模型也是基于 TensorFlow。让我们定义要使用的图像：
- en: '[PRE35]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: In this section, we will just launch a simple training job. In the next sections,
    we will also deploy and test our trained models.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们只是启动一个简单的训练作业。在下一节中，我们还将部署和测试我们的训练好的模型。
- en: 'Next, let’s define some command-line arguments for our training (these can
    be modified on a per-need basis):'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们为训练定义一些命令行参数（这些可以根据需要修改）：
- en: '[PRE36]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We should also provide a meaningful job name; it will help us distinguish our
    experiment from other experiments running in parallel.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该提供一个有意义的作业名称；这将帮助我们区分我们的实验与其他并行运行的实验。
- en: 'The next step is to write down our entire training script – starting from reading
    data, defining the model, training, and saving the model into a single file. We
    will write down our entire code from the previous section into a file with the
    name `task.py`. The following are the contents of our `task.py` file:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是写下我们的整个训练脚本——从读取数据、定义模型、训练到将模型保存到一个文件中。我们将把上一节中的整个代码写入一个名为 `task.py` 的文件。以下是我们
    `task.py` 文件的内容：
- en: '[PRE37]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The following part of the file parses command-line arguments:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 文件的下述部分解析命令行参数：
- en: '[PRE38]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Here, we print some version and environment configurations to keep track of
    current settings:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们打印一些版本和环境配置以跟踪当前设置：
- en: '[PRE39]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Here, we define a training strategy:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们定义了一个训练策略：
- en: '[PRE40]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, we prepare the dataset for training, validation, and testing:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备用于训练、验证和测试的数据集：
- en: '[PRE41]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, we define our TensorFlow model as discussed before:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们像之前讨论的那样定义我们的 TensorFlow 模型：
- en: '[PRE42]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Here is the definition of Encoder part of the TF model:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是 TF 模型编码器部分的定义：
- en: '[PRE43]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The Encoder part is now done. Next we define the decoder part of the model
    within the same function:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器部分现在已经完成。接下来，我们在同一个函数中定义模型的解码器部分：
- en: '[PRE44]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now, we are ready to build and compile our TensorFlow model:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好构建和编译我们的 TensorFlow 模型：
- en: '[PRE45]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The following block launches training with the defined settings and saves the
    trained model:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码块使用定义的设置启动训练，并将训练好的模型保存下来：
- en: '[PRE46]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Now that we have all the configurations set up and our training script, `task.py`,
    is ready, we are all set to define and launch our custom training job on Vertex
    AI.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置了所有配置，并且我们的训练脚本 `task.py` 已经准备好了，我们就可以定义并启动我们的自定义训练作业在 Vertex AI 上。
- en: 'Let’s define our custom Vertex AI training job:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义我们的自定义 Vertex AI 训练作业：
- en: '[PRE47]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The final step is to launch the job:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是启动作业：
- en: '[PRE48]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: This setup launches a Vertex AI custom training job on an `n1-standard-16` machine
    as defined as a parameter in the preceding `job.run` method. When we launch the
    job in a notebook cell, it gives us a URL to the Google Cloud console UI. By clicking
    on it, we can monitor our job logs within the Vertex AI UI.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 此设置在 `n1-standard-16` 机器上启动一个 Vertex AI 自定义训练作业，正如前面 `job.run` 方法中定义的参数。当我们在一个笔记本单元中启动作业时，它给我们一个
    Google Cloud 控制台 UI 的 URL。通过点击它，我们可以在 Vertex AI UI 中监控我们的作业日志。
- en: 'A Vertex AI training job looks something like *Figure 7**.6* in the Google
    Cloud console UI. Here, we can re-verify the configurations and parameters of
    our job that we had defined at the time of launch:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI 训练作业在 Google Cloud 控制台 UI 中看起来类似于 *图 7**.6*。在这里，我们可以重新验证我们在启动时定义的作业配置和参数：
- en: '![Figure 7.6 – Vertex AI training job](img/B17792_07_6.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.6 – Vertex AI 训练作业](img/B17792_07_6.jpg)'
- en: Figure 7.6 – Vertex AI training job
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6 – Vertex AI 训练作业
- en: 'The Vertex AI UI lets us monitor near real-time logs of all the training/custom
    jobs. We can monitor our training within the UI, and it looks something like *Figure
    7**.7*:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI UI 允许我们监控所有训练/定制作业的近乎实时日志。我们可以在 UI 中监控我们的训练，看起来类似于 *图 7**.7*：
- en: '![Figure 7.7 – Real-time logs for Vertex AI training job on Google Cloud console](img/B17792_07_7.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.7 – Google Cloud 控制台上的 Vertex AI 训练作业实时日志](img/B17792_07_7.jpg)'
- en: Figure 7.7 – Real-time logs for Vertex AI training job on Google Cloud console
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7 – Google Cloud 控制台上的 Vertex AI 训练作业实时日志
- en: Going through the logs may not be the best way to monitor training progress
    as we may want to track a few parameters, such as loss and accuracy. In the next
    section, we will learn about how to set up TensorBoard-based live monitoring of
    training progress. However, these logs can be really handy for debugging purposes;
    if our pipeline fails in between before completing the execution successfully,
    we can always check these logs to identify the root cause.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通过日志来监控训练进度可能不是最佳方式，因为我们可能想要跟踪一些参数，例如损失和准确度。在下一节中，我们将学习如何设置基于 TensorBoard 的实时监控训练进度。然而，这些日志对于调试目的来说确实非常有用；如果我们的管道在执行成功完成之前失败，我们总是可以检查这些日志来识别根本原因。
- en: Monitoring model training progress
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控模型训练进度
- en: In the previous section, we saw how easy it is to launch a Vertex AI custom
    training job with desired configurations and machine types. These Vertex AI training
    jobs are really useful for running large-scale experiments where training uses
    high compute (multiple GPUs or TPUs) and also may run for a few days. Such long-running
    experiments are not very feasible to run in a Jupyter Notebook-based environment.
    Another great thing about launching Vertex AI jobs is that all the metadata and
    lineage are tracked in a systematic way so that we can come back later and look
    into our past experiments and compare them with the latest ones in an easy and
    accurate way.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到了如何轻松地使用所需的配置和机器类型启动 Vertex AI 定制训练作业。这些 Vertex AI 训练作业对于运行需要高计算能力（多个
    GPU 或 TPUs）的大型实验非常有用，这些实验可能需要运行几天。在基于 Jupyter Notebook 的环境中运行这种长时间运行的实验并不可行。启动
    Vertex AI 作业的另一个优点是，所有元数据和血缘关系都以系统化的方式跟踪，这样我们就可以稍后回来查看过去的实验，并以简单准确的方式与最新的实验进行比较。
- en: Another important aspect is monitoring the live progress of training jobs (including
    metrics such as loss and accuracy). For this purpose, we can easily set up Vertex
    AI TensorBoard within our Vertex AI job and track the progress in a near real-time
    fashion. In this section, we will set up a TensorBoard instance for our previous
    experiment.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要方面是监控训练作业的实时进度（包括损失和准确度等指标）。为此，我们可以在 Vertex AI 作业中轻松设置 Vertex AI TensorBoard，并以近乎实时的方式跟踪进度。在本节中，我们将为之前的实验设置一个
    TensorBoard 实例。
- en: Most of the code/scripts will be similar to the previous section. Here, we will
    just examine the modifications needed to set up TensorBoard monitoring.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数代码/脚本将与上一节相似。在这里，我们只需检查设置 TensorBoard 监控所需的修改。
- en: 'Firstly, we need to make small changes in the `task.py` file to account for
    TensorFlow callbacks as we want to monitor training loss. To keep things clean,
    we will modify a copy of the `task.py` file that we have renamed to `task2.py`.
    The following are the changes in the `model.fit` function:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要在 `task.py` 文件中进行一些小的修改，以考虑 TensorFlow 回调，因为我们想监控训练损失。为了保持整洁，我们将修改一个重命名为
    `task2.py` 的 `task.py` 文件副本。以下是在 `model.fit` 函数中的更改：
- en: '[PRE49]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: In the preceding script, we have just defined a TensorFlow callback object and
    also passed it into the `model.fit` function.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的脚本中，我们只定义了一个 TensorFlow 回调对象，并将其传递到 `model.fit` 函数中。
- en: 'Working with TensorBoard requires a service account to be in place (instead
    of individual user accounts). If we already don’t have a service account set up,
    we can use the following script to quickly set up a service account. A service
    account is used to grant permissions to services, VMs, and other tooling on Google
    Cloud:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorBoard需要一个服务账户（而不是个人用户账户）。如果我们还没有设置服务账户，我们可以使用以下脚本快速设置一个服务账户。服务账户用于在Google
    Cloud上授予服务、虚拟机和其他工具的权限：
- en: '[PRE50]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'If we are working with colab, the following code snippet will create a service
    account accordingly:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在使用colab，以下代码片段将相应地创建一个服务账户：
- en: '[PRE51]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The next step is to create a Vertex AI TensorBoard instance that we will use
    for monitoring our training.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建一个我们将用于监控训练的Vertex AI TensorBoard实例。
- en: 'Set up the TensorBoard instance:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 设置TensorBoard实例：
- en: '[PRE52]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We need a staging bucket for our Vertex AI job so that it can write event logs
    into that location:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个用于我们的Vertex AI作业的临时存储桶，以便它可以将事件日志写入该位置：
- en: '[PRE53]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We are now all set to define our custom training job:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经准备好定义我们的自定义训练作业：
- en: '[PRE54]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We can now launch the Vertex AI job using the following script. Here, we can
    choose the machine type and also specify the `replica_count` parameter, which
    controls the number of replicas to run for the current job:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用以下脚本启动Vertex AI作业。在这里，我们可以选择机器类型，还可以指定`replica_count`参数，该参数控制当前作业要运行的副本数量：
- en: '[PRE55]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Once we launch the job, it will give us the URL for locating the Vertex AI job
    in the Google Cloud console UI like in the previous section; but this time, it
    will also give us a URL to the Vertex TensorBoard UI. Using this URL, we will
    be able to monitor our training in a near real-time fashion.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们启动作业，它将给我们一个URL，用于在Google Cloud控制台UI中定位Vertex AI作业，就像上一节中那样；但这次，它还会给我们一个指向Vertex
    TensorBoard UI的URL。使用这个URL，我们将能够以近乎实时的方式监控我们的训练。
- en: 'This is how it looks for our little experiment (see *Figure 7**.8*):'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们的小实验看起来像什么（见*图7.8*）：
- en: '![Figure 7.8 – Vertex TensorBoard for real-time monitoring of experiments](img/B17792_07_8.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图7.8 – 用于实时监控实验的Vertex TensorBoard](img/B17792_07_8.jpg)'
- en: Figure 7.8 – Vertex TensorBoard for real-time monitoring of experiments
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 – 用于实时监控实验的Vertex TensorBoard
- en: We can configure it to show more desired metrics for our experiments. Now that
    we are able to launch Vertex AI training, monitor it, and also save our TensorFlow-trained
    model, let’s move on to the model evaluation part.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以配置它以显示更多我们实验中所需的指标。现在我们能够启动Vertex AI训练、监控它，并且还能保存我们的TensorFlow训练模型，让我们继续到模型评估部分。
- en: Evaluating trained models
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估训练模型
- en: 'In this section, we will take the already trained model from the previous section
    and launch a batch inference job on the test data. The first step here will be
    to load our test data into a Jupyter Notebook:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将从上一节中提取已经训练好的模型，并在测试数据上启动一个批量推理作业。这里的第一个步骤将是将我们的测试数据加载到Jupyter Notebook中：
- en: '[PRE56]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The next step is to create a JSON payload of instances from our test data and
    save it in a cloud storage location. The batch inference module will be able to
    read these instances and perform inference:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是从我们的测试数据中创建实例的JSON有效负载并将其保存到云存储位置。批推理模块将能够读取这些实例并执行推理：
- en: '[PRE57]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Here we convert the input images to a serializable format so that the prediction
    service can accept input as a JSON file:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将输入图像转换为可序列化的格式，以便预测服务可以接受JSON文件作为输入：
- en: '[PRE58]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Now our test dataset instances are ready in a cloud storage bucket. We can
    launch batch prediction over them, and the batch inference module will save the
    output results into a new folder inside the same bucket:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的测试数据集实例已准备好在云存储桶中。我们可以对它们启动批量预测，批推理模块将输出结果保存到同一存储桶中的新文件夹中：
- en: '[PRE59]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Here, we call the batch prediction service using the SDK:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用SDK调用批预测服务：
- en: '[PRE60]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: We can also monitor the progress of the batch prediction job within the Google
    Cloud console UI if needed. Once this job finishes, we can check the outputs inside
    the defined destination folder.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，我们还可以在Google Cloud控制台UI中监控批量预测作业的进度。一旦这个作业完成，我们可以在定义的目标文件夹中检查输出。
- en: Summary
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In the chapter, we learned how to work with a Vertex AI-based managed training
    environment and launch custom training jobs. Launching custom training jobs on
    Vertex AI comes with a number of advantages, such as managed metadata tracking,
    no need to actively monitor jobs, and the ability to launch any number of experiments
    in parallel, choose your desired machine specifications to run your experiments,
    monitor training progress and results in near-real time fashion using the Cloud
    console UI, and run managed batch inference jobs on a saved model. It is also
    tighly integrated with other GCP products.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用基于Vertex AI的托管训练环境以及启动自定义训练任务。在Vertex AI上启动自定义训练任务具有许多优势，例如托管元数据跟踪、无需主动监控任务，以及能够并行启动任意数量的实验，选择你想要的机器规格来运行你的实验，使用云控制台UI以近乎实时的方式监控训练进度和结果，并在保存的模型上运行托管批量推理任务。它还与其他GCP产品紧密集成。
- en: After reading this chapter, you should be able to develop and run custom deep
    learning models (using frameworks such as TensorFlow) on Vertex AI Workbench notebooks.
    Secondly, you should be able to launch long-running Vertex AI custom training
    jobs and also understand the advantages of the managed Vertex AI training framework.
    The managed Google Cloud console interface and TensorBoard make it easy to monitor
    and evaluate various Vertex AI training jobs.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读本章后，你应该能够开发并在Vertex AI Workbench笔记本上运行自定义深度学习模型（使用如TensorFlow等框架）。其次，你应该能够启动长时间运行的Vertex
    AI自定义训练任务，并理解托管Vertex AI训练框架的优势。托管的Google Cloud控制台界面和TensorBoard使得监控和评估各种Vertex
    AI训练任务变得容易。
- en: Now that we have a good understanding of training models using Vertex AI on
    GCP, we will learn about model explainability in the next chapter.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对在GCP上使用Vertex AI进行模型训练有了很好的理解，接下来我们将学习下一章中的模型可解释性。
