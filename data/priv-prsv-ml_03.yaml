- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Machine Learning Phases and Privacy Threats/Attacks in Each Phase
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习阶段和每个阶段的隐私威胁/攻击概述
- en: 'In this chapter, we will provide a quick refresher on the different types of
    **machine learning** (**ML**): supervised, unsupervised, and reinforcement learning.
    We will also review the essential phases or pipelines of ML. You may already be
    familiar with these; if not, this chapter will serve as a foundational introduction.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将快速回顾不同类型的**机器学习**（**ML**）：监督学习、无监督学习和强化学习。我们还将回顾ML的基本阶段或流程。你可能已经熟悉这些内容；如果不熟悉，本章将作为一个基础性的介绍。
- en: Subsequently, we will delve into the crucial topic of privacy preservation within
    each phase of the ML process. Specifically, we will explore the importance of
    maintaining privacy in training data, input data, model storage, and inference/output
    data. Additionally, we will examine various privacy attacks that can occur in
    each phase, such as training data extraction attacks, model inversion attacks,
    and model inference attacks. Through detailed examples, we will gain an understanding
    of how these attacks function and discuss strategies to safeguard against them.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，我们将深入研究ML过程中的每个阶段隐私保护的关键主题。具体来说，我们将探讨在训练数据、输入数据、模型存储和推理/输出数据中保持隐私的重要性。此外，我们还将检查每个阶段可能发生的各种隐私攻击，例如训练数据提取攻击、模型反演攻击和模型推理攻击。通过详细的示例，我们将了解这些攻击是如何工作的，并讨论防范策略。
- en: 'We will cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主要主题：
- en: ML types
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习类型
- en: Overview of ML phases
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ML阶段概述
- en: Privacy threats/attacks in the ML phases
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习阶段中的隐私威胁/攻击
- en: ML types
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习类型
- en: Some of you may already be familiar with the different types of ML, namely supervised
    ML, unsupervised ML, and reinforcement learning. In the next sections, we will
    provide a quick refresher on these ML types, summarizing what you may have already
    learned.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一些人对不同的ML类型可能已经熟悉，即监督学习、无监督学习和强化学习。在接下来的章节中，我们将快速回顾这些ML类型，总结你可能已经学到的内容。
- en: Supervised ML
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习
- en: Supervised ML models involve the development of a mathematical model using a
    set of input data and corresponding actual output. The input data is known as
    the training data, while the output is referred to as the predicted output. These
    models employ mathematical functions to learn from the training data and aim to
    minimize the errors between the predicted output and the expected output using
    an optimal function. The training data, which consists of input examples, is typically
    represented in formats such as arrays, vectors, matrices, or tensors. This data
    is often referred to as feature data or feature vectors, where each attribute
    within the data is considered a feature.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习模型涉及使用一组输入数据和相应的实际输出开发一个数学模型。输入数据被称为训练数据，而输出被称为预测输出。这些模型使用数学函数从训练数据中学习，并旨在使用最优函数最小化预测输出和预期输出之间的误差。由输入示例组成的数据通常以数组、向量、矩阵或张量等格式表示。这种数据通常被称为特征数据或特征向量，其中数据中的每个属性都被视为一个特征。
- en: '| **Type** | **Example** | **Details** |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| **类型** | **示例** | **细节** |'
- en: '| Scalar | 1 | A scalar is a single number. |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 标量 | 1 | 标量是一个单独的数字。 |'
- en: '| Vector | [ 1 2 3 4 ] | A vector is an array of numbers or objects with different
    data types. |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 向量 | [ 1 2 3 4 ] | 向量是由不同数据类型的数字或对象组成的数组。 |'
- en: '| Matrix | [1 2 3 4 5 6 7 8 9] | A matrix is an array of numbers arranged in
    rows and columns. In order to access the matrix, we need two indexes: column number
    and row number. |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 矩阵 | [1 2 3 4 5 6 7 8 9] | 矩阵是按行和列排列的数字数组。为了访问矩阵，我们需要两个索引：列号和行号。 |'
- en: '| Tensor | [[ 1 2] [ 3 4] [ 5 6][ 7 8 ] [9 0] [ 0 1]] | A tensor is an *n*-dimensional
    array with *n>2*. |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 张量 | [[ 1 2] [ 3 4] [ 5 6][ 7 8 ] [9 0] [ 0 1]] | 张量是一个*n*-维数组，其中*n>2*。 |'
- en: Table 2.1 – Examples of scalar, vector, matrix, and tensor
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.1 – 标量、向量、矩阵和张量的示例
- en: In mathematical terms, supervised learning in ML can be represented by a model,
    with parameters, *𝜃*. This model acts as a mapping function between input *x*
    and output *y*, denoted as *y =* 𝑓 *(x,* 𝜃*).* In this context, *x* represents
    a vector of attributes or features with a dimensionality of *𝑛*. The output or
    label *y* can vary in dimension depending on the specific learning task.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学术语中，ML中的监督学习可以用一个带有参数*𝜃*的模型来表示。该模型充当输入*x*和输出*y*之间的映射函数，表示为*y =* 𝑓 *(x,* 𝜃*).*
    在这个上下文中，*x*代表一个具有*𝑛*维度的属性或特征向量。输出或标签*y*的维度可以根据特定的学习任务而变化。
- en: To train the model, a training set T, is utilized, which consists of data points
    in the form of T = {(x , y𝑖)}, where *𝑖* ranges from 1 to n, representing the
    number of input–output pairs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练模型，使用了一个训练集T，它由形式为T = {(x, y𝑖)}的数据点组成，其中*𝑖*的范围从1到n，代表输入-输出对的数目。
- en: 'Supervised ML algorithms typically fall into two categories: regression and
    classification. These algorithms aim to learn patterns and relationships within
    the training data to make predictions or assign labels to new, unseen data.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习算法通常分为两类：回归和分类。这些算法旨在学习训练数据中的模式和关系，以便对新、未见过的数据进行预测或分配标签。
- en: Regression
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回归
- en: A target variable in ML is the variable that we aim to predict or forecast.
    It is also often termed as the dependent variable. It is what the ML model is
    trained to predict using independent or feature variables. For example, in a house
    price prediction model, the house price would be the target variable.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，目标变量是我们旨在预测或预测的变量。它也常被称为因变量。它是机器学习模型训练用来使用独立或特征变量预测的变量。例如，在房价预测模型中，房价将是目标变量。
- en: Regression is a fundamental concept in ML that focuses on predicting continuous
    numerical values based on input variables. It is a supervised learning technique
    that involves analyzing the relationship between the input features and the target
    variable. The goal of regression is to build a mathematical model that can accurately
    estimate or approximate the value of the target variable when provided with new
    input data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是机器学习中的一个基本概念，它侧重于根据输入变量预测连续数值。它是一种监督学习技术，涉及分析输入特征与目标变量之间的关系。回归的目标是构建一个数学模型，当提供新的输入数据时，可以准确地估计或近似目标变量的值。
- en: In regression, the target variable, also known as the dependent variable, is
    a continuous value. The input variables, also called independent variables or
    features, can be numerical or categorical. The regression model seeks to understand
    the relationship between these input variables and the target variable, enabling
    predictions to be made for unseen data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归中，目标变量，也称为因变量，是一个连续值。输入变量，也称为独立变量或特征，可以是数值或分类的。回归模型旨在理解这些输入变量与目标变量之间的关系，从而能够对未见数据做出预测。
- en: The performance of a regression model is typically measured by evaluating the
    closeness of its predictions to the actual target values. Various regression algorithms
    exist, such as linear regression, polynomial regression, and more complex techniques
    such as support vector regression and random forest regression. These algorithms
    use mathematical optimization methods to fit a regression function that minimizes
    the difference between predicted values and the true values of the target variable.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型的性能通常通过评估其预测值与实际目标值之间的接近程度来衡量。存在各种回归算法，如线性回归、多项式回归，以及更复杂的支持向量回归和随机森林回归等技术。这些算法使用数学优化方法来拟合回归函数，以最小化预测值与目标变量的真实值之间的差异。
- en: Regression analysis finds applications in numerous fields, including finance,
    economics, healthcare, and social sciences, where it is used for tasks such as
    price prediction, demand forecasting, risk assessment, and trend analysis. By
    leveraging regression algorithms, valuable insights can be gained from data, allowing
    for informed decision-making and accurate predictions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析在众多领域都有应用，包括金融、经济学、医疗保健和社会科学，其中它被用于诸如价格预测、需求预测、风险评估和趋势分析等任务。通过利用回归算法，可以从数据中获得有价值的见解，从而实现明智的决策和准确的预测。
- en: Regression model example
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 回归模型示例
- en: Here’s a straightforward example of predicting a target variable using two input
    features. In this scenario, a model is trained on a set of historical data, typically
    representing the data from the last X days.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个使用两个输入特征预测目标变量的简单示例。在这种情况下，模型是在一组历史数据上训练的，通常代表过去X天的数据。
- en: The purpose is to forecast or predict the target variable based on the provided
    input data. By analyzing patterns and relationships in the historical dataset,
    the trained model can make predictions about the target variable when presented
    with new input data. This process allows for forecasting future values or understanding
    potential outcomes based on the given inputs. The model’s accuracy and performance
    are evaluated based on how well it can predict the target variable compared to
    the actual values. By leveraging historical data and utilizing ML algorithms,
    valuable insights can be gained, enabling accurate predictions and informed decision-making.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 目的是根据提供的输入数据预测或预测目标变量。通过分析历史数据集中的模式和关系，训练好的模型可以在呈现新的输入数据时对目标变量进行预测。这个过程允许根据给定的输入预测未来的值或理解潜在的结果。模型的准确性和性能是根据其预测目标变量的能力与实际值相比来评估的。通过利用历史数据和利用机器学习算法，可以获得有价值的见解，从而实现准确的预测和明智的决策。
- en: '| Feature 1 value | Feature 2 value | Target variable value |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 特征1值 | 特征2值 | 目标变量值 |'
- en: '| 10 | 10 | 130 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 10 | 130 |'
- en: '| 10 | 20 | 180 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 20 | 180 |'
- en: '| 20 | 20 | 210 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 20 | 210 |'
- en: '| 20 | 30 | 260 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 30 | 260 |'
- en: '| 30 | 50 | ?? |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 50 | ?? |'
- en: Table 2.2 – regression model example
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.2 – 回归模型示例
- en: This example was implemented using the scikit-learn library. I have used Python
    version 3.8 and scikit-learn version 1.2.1.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例使用scikit-learn库实现。我使用了Python 3.8和scikit-learn 1.2.1版本。
- en: 'These are the steps followed in this example:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是在本例中遵循的步骤：
- en: Install Jupyter Notebook (**pip** **install notebook**).
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装Jupyter Notebook（**pip** **install notebook**）。
- en: Open a Python Jupyter notebook (**jupyter notebook**).
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Python Jupyter笔记本（**jupyter notebook**）。
- en: Install sci-kit learn libraries (**pip install -****U scikit-learn**).
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装sci-kit learn库（**pip install -****U scikit-learn**）。
- en: Type the following code and run the model code.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下代码并运行模型代码。
- en: 'You can directly execute the code using the Jupyter notebook provided in the
    GitHub location of this book—`LinearRegression.ipynb`—located at [https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%202/LinearRegression.ipynb](https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%202/LinearRegression.ipynb):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以直接使用本书GitHub位置提供的Jupyter笔记本执行代码—`LinearRegression.ipynb`—位于[https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%202/LinearRegression.ipynb](https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter%202/LinearRegression.ipynb)：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this example, target variable y is linearly dependent on input variables
    X0 and X1 with the linear equation y= 3X0+ 5X1+50 (50 is the intercept of the
    line).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，目标变量y与输入变量X0和X1呈线性相关，线性方程为y= 3X0+ 5X1+50（50是直线的截距）。
- en: The model uses the root mean square value as an optimal function and predicts
    the target variable. In this case, it predicts 100% accuracy because of the strong
    linear relationship between the features and the target variable.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 模型使用均方根值作为最优函数，并预测目标变量。在这种情况下，由于特征和目标变量之间强烈的线性关系，它预测了100%的准确率。
- en: Model persistence and retrieving the persisted model for inference
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型持久化和检索持久化模型以进行推理
- en: After developing and testing the model using training data and validating it
    with test data, the next step is to persist the model. This allows for easy sharing
    with other developers or engineers without revealing the training data and intricate
    model details. Additionally, if the model demonstrates sufficient accuracy during
    training, it can be deployed in production environments.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用训练数据开发和测试模型以及使用测试数据进行验证之后，下一步是持久化模型。这允许与其他开发人员或工程师轻松共享，而无需透露训练数据和复杂的模型细节。此外，如果模型在训练期间表现出足够的准确度，它可以在生产环境中部署。
- en: To persist the model, various formats are supported to store it in the disk
    or file system. The specific format utilized depends on the framework used to
    develop the ML or **deep learning** (**DL**) model. By employing these formats,
    the model can be stored and accessed efficiently, facilitating seamless integration
    into production systems or collaborations with other team members.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了持久化模型，支持多种格式以将其存储在磁盘或文件系统中。具体使用的格式取决于开发机器学习或**深度学习**（**DL**）模型所使用的框架。通过使用这些格式，模型可以高效地存储和访问，便于无缝集成到生产系统或与其他团队成员的合作中。
- en: Persisting the model enables reproducibility and scalability, as it can be shared,
    reused, and deployed in different environments without the need to retrain it
    from scratch. It also helps protect proprietary information and intellectual property
    associated with the model, allowing organizations to safeguard their valuable
    research and development efforts.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 持久化模型可以实现可重复性和可扩展性，因为它可以在不同的环境中共享、重用和部署，而无需从头开始重新训练。它还有助于保护与模型相关的专有信息和知识产权，使组织能够保护其宝贵的研究和开发工作。
- en: '![Figure 2.1 – Model persistence and retrieval](img/B16573_02_01.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1 – 模型持久化和检索](img/B16573_02_01.jpg)'
- en: Figure 2.1 – Model persistence and retrieval
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – 模型持久化和检索
- en: 'The following table shows some formats that are widely used and accepted in
    the community:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了社区中广泛使用和接受的格式：
- en: '| Framework | Model persistence format | Details |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 框架 | 模型持久化格式 | 详情 |'
- en: '| scikit-learn[https://scikit-learn.org/](https://scikit-learn.org/) | JoblibPickle
    | The Joblib and pickle formats don’t require any code changes.The pickle format
    has security issues, so most frameworks don’t advise using the pickle format for
    model persistence because arbitrary code can be executed during unpickling. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| scikit-learn[https://scikit-learn.org/](https://scikit-learn.org/) | JoblibPickle
    | Joblib 和 pickle 格式不需要任何代码更改。pickle 格式存在安全问题，因此大多数框架不建议使用 pickle 格式进行模型持久化，因为在反序列化过程中可以执行任意代码。|'
- en: '| TensorFlow/Keras[https://www.tensorflow.org/](https://www.tensorflow.org/)
    | JSONYAMLHDF5 | This is model data stored in JSON format or YAML format, and
    these formats are text-based formats, so they are language-agnostic.Weights are
    saved in HDF5 format. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow/Keras[https://www.tensorflow.org/](https://www.tensorflow.org/)
    | JSONYAMLHDF5 | 这是以 JSON 或 YAML 格式存储的模型数据，这些格式是基于文本的格式，因此它们是语言无关的。权重以 HDF5 格式保存。|'
- en: '| PyTorch[https://pytorch.org/](https://pytorch.org/) | state_dictPickle |
    For neural network models to store weights and biases. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch[https://pytorch.org/](https://pytorch.org/) | state_dictPickle |
    用于神经网络模型存储权重和偏差。|'
- en: '| ONNX | Onnx | Models need to be converted to ONNX format and exported and
    loaded/executed using ONNX Runtime so that they can be run either on CPU- or GPU-based
    servers. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| ONNX | Onnx | 模型需要转换为 ONNX 格式，并使用 ONNX Runtime 导出和加载/执行，以便它们可以在基于 CPU 或 GPU
    的服务器上运行。|'
- en: Table 2.3 – Examples of scalar, vector, matrix, and tensor
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.3 – 标量、向量、矩阵和张量的示例
- en: 'The following code shows how to store and retrieve a model in the Joblib format
    using Python:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何使用 Python 存储和检索 Joblib 格式的模型：
- en: What is Joblib?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是 Joblib？
- en: Joblib ([https://joblib.readthedocs.io/en/latest/](https://joblib.readthedocs.io/en/latest/))
    is a set of tools to provide lightweight pipelining in Python to persist (or serialize)
    the Python objects. Joblib version 1.2.0 is used in this code.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Joblib ([https://joblib.readthedocs.io/en/latest/](https://joblib.readthedocs.io/en/latest/))
    是一组工具，用于在 Python 中提供轻量级管道，以持久化（或序列化）Python 对象。本代码中使用 Joblib 版本 1.2.0。
- en: 'The Jupyter notebook for this example is `LinearRegression_SaveModel.ipynb`:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 本例的 Jupyter 笔记本为 `LinearRegression_SaveModel.ipynb`：
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once the model is persisted in a file system or a file, then the file can be
    shared with other developers or engineers without sharing any of the training
    data or model details used in the code. Other developers/engineers can then load
    this file and use it for further predictions or deploy it in production for production
    usage. This is explained in *Figure 2**.1*. This model is saved in the current
    directory and has the name `sample_model.sav`; you can make use of any extension
    as it doesn’t matter which extension is used. The source code is in `Linear_Regression_Load_Model.ipynb`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型在文件系统或文件中持久化，则可以与其他开发人员或工程师共享该文件，而无需共享代码中使用的任何训练数据或模型细节。其他开发人员/工程师然后可以加载此文件并用于进一步的预测或将其部署到生产环境中进行生产使用。这已在
    *图 2**.1 中解释。该模型保存在当前目录中，名称为 `sample_model.sav`；您可以使用任何扩展名，因为它并不重要使用哪个扩展名。源代码在
    `Linear_Regression_Load_Model.ipynb` 中：
- en: '[PRE2]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Classification
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类
- en: A classification model employs different algorithms to predict an output or
    dependent variable based on the relationship between the input variables. Classification
    algorithms are specifically designed to predict discrete values, such as spam/not
    spam, male/female, yes/no, and so on. Each of these predicted values is referred
    to as a label or class.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型使用不同的算法根据输入变量之间的关系预测输出或因变量。分类算法专门设计用于预测离散值，例如垃圾邮件/非垃圾邮件、男性/女性、是/否等。这些预测值中的每一个都被称为标签或类别。
- en: In binary classification scenarios, there are only two possible class labels,
    e.g., determining whether an email is spam or not spam. On the other hand, multi-label
    classification involves predicting multiple class labels simultaneously. An example
    could be classifying images into various categories such as cat, dog, and bird.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在二元分类场景中，只有两个可能的类别标签，例如，确定一封电子邮件是否为垃圾邮件。另一方面，多标签分类涉及同时预测多个类别标签。一个例子是将图像分类到各种类别，如猫、狗和鸟。
- en: Classification models are trained using historical data that contains both the
    input variables and their corresponding class labels. The algorithms learn from
    this labeled data and establish patterns and relationships to make accurate predictions
    on new, unseen data. The performance of a classification model is evaluated based
    on metrics such as accuracy, precision, recall, and F1 score. These metrics assess
    how well the model can correctly assign the appropriate class labels to new instances
    based on their input features.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型使用包含输入变量及其对应类别标签的历史数据进行训练。算法从这些有标签的数据中学习，并建立模式和关系，以便在新、未见过的数据上做出准确的预测。分类模型的性能基于准确率、精确率、召回率和F1分数等指标进行评估。这些指标评估模型根据其输入特征正确分配适当的类别标签到新实例的能力。
- en: Classification models find extensive applications in various domains, including
    spam filtering, sentiment analysis, customer churn prediction, fraud detection,
    and medical diagnosis. By leveraging different classification algorithms, valuable
    insights can be gained from data, enabling informed decision-making and efficient
    problem-solving.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型在各个领域都有广泛的应用，包括垃圾邮件过滤、情感分析、客户流失预测、欺诈检测和医疗诊断。通过利用不同的分类算法，可以从数据中获得有价值的见解，从而实现明智的决策和高效的问题解决。
- en: '| **Classification type** | **Details** | **Examples** | **Algorithms** |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| **分类类型** | **详细信息** | **示例** | **算法** |'
- en: '| Binary | Predicts one of two classes based on the training data | Yes/noSpam/not
    spamPass/failCancer/no cancer | Logistic regressionK-nearest neighborsDecision
    treesSupport vector machineNaive Bayes |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 二元 | 基于训练数据预测两个类别中的一个 | 是/否垃圾邮件/非垃圾邮件通过/失败癌症/无癌症 | 逻辑回归K最近邻决策树支持向量机朴素贝叶斯
    |'
- en: '| Multi-class | Predicts one of more than two classes | Based on symptoms,
    e.g., cold, flu, or COVID-19 | K-nearest neighborsDecision treesNaive BayesRandom
    forestGradient boosting |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 多分类 | 预测两个以上类别中的一个 | 基于症状，例如，感冒、流感或COVID-19 | K最近邻决策树朴素贝叶斯随机森林梯度提升 |'
- en: '| Multi-label | Has two or more class labels | Prediction of the topic based
    on the content: finance, politics, science, language, or all of them | Multi-label
    decision treesMulti-label random forestsMulti-label gradient boosting |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 多标签 | 有两个或更多类别标签 | 根据内容预测主题：金融、政治、科学、语言或所有这些 | 多标签决策树多标签随机森林多标签梯度提升 |'
- en: '| Extreme | Classification task in which the number of candidate labels is
    huge | Amazon 3M dataset, where the number of labels is 2,812,281 | DL algorithmsMore
    algorithms: [http://manikvarma.org/downloads/XC/XMLRepository.html](http://manikvarma.org/downloads/XC/XMLRepository.html)
    |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 极端 | 候选标签数量巨大的分类任务 | 亚马逊3M数据集，其中标签数量为2,812,281 | 深度学习算法更多算法：[http://manikvarma.org/downloads/XC/XMLRepository.html](http://manikvarma.org/downloads/XC/XMLRepository.html)
    |'
- en: Table 2.4 – Classification types and associated algorithms
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.4 – 分类类型和相关算法
- en: Classification example
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分类示例
- en: 'In this example, we will utilize the decision tree classification algorithm
    to determine the likelihood of a patient’s survival based on two features: age
    and whether they have a pre-existing cancer condition.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将利用决策树分类算法，根据两个特征：年龄和是否有既往癌症状况，来确定患者生存的可能性。
- en: The decision tree classification algorithm is a widely used technique in ML
    that constructs a tree-like model of decisions. It analyzes the provided data
    to create a structure that represents the decision-making process.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树分类算法是机器学习中广泛使用的技术，它构建了一个决策的树状模型。它分析提供的数据以创建一个表示决策过程的结构。
- en: In our scenario, the age of the patient and their cancer status will be used
    as input features for classification. By examining a labeled dataset consisting
    of patient information, including age, cancer status, and survival outcome, the
    algorithm learns patterns and establishes decision rules.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的场景中，患者的年龄和他们的癌症状态将被用作分类的输入特征。通过检查包含患者信息的有标签数据集，包括年龄、癌症状态和生存结果，算法学习模式并建立决策规则。
- en: 'Once the model is trained, it becomes capable of predicting the survival outcome
    for new patients who have not been previously encountered. By considering the
    age and cancer status of these patients, the model traverses the decision tree
    until reaching a leaf node that signifies the predicted outcome: whether the patient
    is expected to survive or not.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型经过训练，它就能够预测之前未曾遇到的新患者的存活结果。通过考虑这些患者的年龄和癌症状况，模型遍历决策树，直到达到表示预测结果的叶节点：患者是否预期会存活。
- en: By employing the decision tree classification algorithm in this example, we
    aim to classify patients’ survival probabilities based on their age and cancer
    status. This valuable insight can aid medical professionals in assessing patient
    prognosis and informing treatment decisions.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在这个例子中使用决策树分类算法，我们的目标是根据患者的年龄和癌症状况来分类患者的存活概率。这一宝贵的见解可以帮助医疗专业人员评估患者预后并告知治疗决策。
- en: '| **Age (years)** | **Has/had cancer (1 = yes, 0 =** **no)** | **Survived (1
    = yes,** **0 =no)** |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| **年龄（年）** | **是否有/曾经有癌症（1 = 是，0 = 否）** | **存活（1 = 是，0 = 否）** |'
- en: '| 10 | 1 | 1 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | 1 |'
- en: '| 20 | 1 | 1 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 1 | 1 |'
- en: '| 30 | 1 | 1 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 1 |'
- en: '| 80 | 1 | 0 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 1 | 0 |'
- en: '| 75 | 0 | 0 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 0 | 0 |'
- en: '| 78 | 0 | 0 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 78 | 0 | 0 |'
- en: '| 35 | 1 | ?? (predict) |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 35 | 1 | ?? (预测) |'
- en: '| 78 | 1 | ?? (predict) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 78 | 1 | ?? (预测) |'
- en: Table 2.5 – Toy dataset for classification example
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.5 – 分类示例的玩具数据集
- en: In this toy dataset, the model needs to predict whether the last two patients
    survive or not (classification with two labels) based on the trained historical
    data of the model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个玩具数据集中，模型需要根据模型训练的历史数据预测最后两位患者的存活情况（具有两个标签的分类）。
- en: The source code is in `Classification_Example.ipynb`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码位于`Classification_Example.ipynb`。
- en: 'Scikit-learn provides various Python classes for classification algorithms.
    Since we have chosen the decision tree algorithm for this example, import the
    necessary classes and prepare the data in a format that the model accepts:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn为分类算法提供了各种Python类。由于我们在这个例子中选择了决策树算法，因此导入必要的类并准备模型接受的格式化的数据：
- en: '[PRE3]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this case, the model predicted that the 35-year-old patient would survive
    but the 78-year-old patient would not survive based on the training data provided.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，模型根据提供的训练数据预测，35岁的患者会存活，而78岁的患者不会存活。
- en: 'To understand more about decision trees and how the trees are split, let’s
    look at the following line of code:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解决策树及其分裂方式，让我们看看以下代码行：
- en: '[PRE4]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will plot the tree based on the input features and how the tree is split.
    This is useful when more features are in the training data and we need to know
    which feature has more importance:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这将基于输入特征和树的分裂方式绘制树。当训练数据中有更多特征，我们需要知道哪个特征更重要时，这很有用：
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Figure 2.2 - Visualizing tree splitting](img/B16573_02_02.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2 - 树分裂的可视化](img/B16573_02_02.jpg)'
- en: Figure 2.2 - Visualizing tree splitting
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 - 树分裂的可视化
- en: Once the model is trained and tested, it can be persisted in a file system or
    directly used for production.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型经过训练和测试，它就可以在文件系统中持久化或直接用于生产。
- en: In the last example, we persisted the model in the Joblib format.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个例子中，我们使用Joblib格式持久化了模型。
- en: Let’s now try to persist the model with the ONNX format to learn more about
    it.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们尝试使用ONNX格式持久化模型，以了解更多信息。
- en: Model persistence using the ONNX format and executing the model
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用ONNX格式持久化模型和执行模型
- en: '**ONNX**, short for **Open Neural Network Exchange**, is an open source format
    designed for ML and DL models. Its purpose is to facilitate the interoperability
    of models across different frameworks. It accomplishes this by providing an extensible
    computation graph model and defining a set of built-in operators and standard
    data types.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**ONNX**，即**开放神经网络交换**，是一个为机器学习和深度学习模型设计的开源格式。其目的是促进不同框架之间模型的互操作性。它通过提供一个可扩展的计算图模型并定义一组内置运算符和标准数据类型来实现这一点。'
- en: With ONNX, ML/DL models can be easily converted to the ONNX format, allowing
    for seamless deployment, export, loading, and execution using ONNX Runtime. ONNX
    Runtime is a powerful tool that enables high-performance execution of ML models
    on either CPU or GPU. Importantly, it does not rely on dependencies on the specific
    training framework used to develop the models. By leveraging ONNX and ONNX Runtime,
    developers can ensure that their models are portable across various frameworks
    and can be efficiently executed. More details about ONNX can be found at [https://github.com/onnx/onnx](https://github.com/onnx/onnx).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 使用ONNX，ML/DL模型可以轻松转换为ONNX格式，允许使用ONNX Runtime无缝部署、导出、加载和执行。ONNX Runtime是一个强大的工具，它可以在CPU或GPU上实现高性能的ML模型执行。重要的是，它不依赖于用于开发模型的特定训练框架的依赖项。通过利用ONNX和ONNX
    Runtime，开发者可以确保他们的模型可以在各种框架之间移植，并且可以高效地执行。有关ONNX的更多详细信息，请参阅[https://github.com/onnx/onnx](https://github.com/onnx/onnx)。
- en: Converting the sklearn sample model to the ONNX format
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将sklearn样本模型转换为ONNX格式
- en: 'Converting the model to ONNX format requires the frameworks `onnx`, `onnxruntime`,
    and `skl2onnx` for scikit-learn. Install the frameworks in the following maner:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型转换为ONNX格式需要`onnx`、`onnxruntime`和`skl2onnx`框架。以下是如何安装这些框架的方法：
- en: '[PRE6]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once the frameworks are installed, execute the following code to convert the
    model to ONNX format (the source code is in `Model_Persistence_Load_ONNX_Format.ipynb`):'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 框架安装完成后，执行以下代码将模型转换为ONNX格式（源代码位于`Model_Persistence_Load_ONNX_Format.ipynb`）：
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In this case, to convert the ML model that was developed using `sklearn` to
    ONNX format, first, the data types used in the training need to be provided:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在此情况下，要将使用`sklearn`开发的ML模型转换为ONNX格式，首先需要提供训练中使用的数据类型：
- en: '[PRE8]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Later, use the methods provided to convert the model to ONNX format and specify
    the classifier that is used in `sklearn`. In our examples, we have used decision
    trees and named the model `clf`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用提供的方法将模型转换为ONNX格式，并指定在`sklearn`中使用的分类器。在我们的示例中，我们使用了决策树，并将模型命名为`clf`：
- en: '[PRE9]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once the model is converted to ONNX format, store it in the disk and name the
    model file (in our example, `survive.onnx`):'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型转换为ONNX格式，将其存储在磁盘上，并命名模型文件（在我们的例子中，为`survive.onnx`）：
- en: '[PRE10]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now the model is stored in ONNX format and it can be loaded and executed on
    any framework that supports ONNX Runtime.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已存储为ONNX格式，并且可以在支持ONNX Runtime的任何框架上加载和执行。
- en: Loading the ML model using ONNX format and executing the model
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用ONNX格式加载ML模型并执行模型
- en: 'The following lines of code show how to load the model stored in ONNX format
    and how to use the model for inference. ONNX version 1.14.1 is used in this code
    (the source code is in `Model_Persistence_Load_ONNX_Format.ipynb`):'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码行展示了如何加载存储在ONNX格式的模型以及如何使用该模型进行推理。本代码使用ONNX版本1.14.1（源代码位于`Model_Persistence_Load_ONNX_Format.ipynb`）：
- en: '[PRE11]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Unsupervised ML
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督机器学习
- en: In unsupervised ML, the model is trained using unlabeled training data, which
    means there are no target labels or classes provided. Instead, unsupervised ML
    models focus on understanding the inherent patterns and structures within the
    data. Unlike supervised learning, where the model learns from labeled examples,
    unsupervised machine learning models uncover hidden patterns and relationships
    within the data without any predefined class labels. This allows for the discovery
    of previously unknown insights and patterns that may not be readily apparent.
    By leveraging unsupervised ML techniques, analysts and data scientists can gain
    valuable insights from unlabeled data, uncover hidden structures, and make data-driven
    decisions based on the inherent patterns discovered in the dataset.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督机器学习中，模型使用未标记的训练数据进行训练，这意味着没有提供目标标签或类别。相反，无监督机器学习模型专注于理解数据中的内在模式和结构。与监督学习不同，监督学习中的模型从标记的示例中学习，无监督机器学习模型在没有任何预定义的类别标签的情况下揭示数据中的隐藏模式和关系。这允许发现以前未知的见解和模式，这些模式可能并不明显。通过利用无监督机器学习技术，分析师和数据科学家可以从未标记的数据中获得有价值的见解，揭示隐藏的结构，并根据数据集中发现的内在模式做出数据驱动的决策。
- en: Clustering
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 聚类
- en: Clustering is a primary technique used in unsupervised ML. It involves grouping
    similar data points together based on their intrinsic characteristics. By examining
    the data and identifying similarities, unsupervised models create clusters, which
    represent distinct groups or patterns within the dataset.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是用于无监督机器学习的主要技术。它涉及根据数据点的内在特征将相似的数据点分组在一起。通过检查数据和识别相似性，无监督模型创建聚类，这些聚类代表了数据集中的不同组或模式。
- en: Clustering algorithms, such as k-means clustering, hierarchical clustering,
    or density-based clustering, are commonly employed in unsupervised ML to organize
    data into meaningful groups. These clusters can help in data exploration, anomaly
    detection, customer segmentation, and other data-driven tasks.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类算法，如 k-means 聚类、层次聚类或基于密度的聚类，在无监督机器学习中常用于将数据组织成有意义的组。这些簇有助于数据探索、异常检测、客户细分和其他数据驱动任务。
- en: Clustering example
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 聚类示例
- en: Let’s consider a scenario where a company aims to offer transportation services
    to its employees and wants to cluster them based on their residential locations.
    To achieve this, the company can utilize a clustering model that takes the longitude
    and latitude coordinates of each employee’s residence as input data. The ML model
    will cluster the employees based on the specified cluster size, which can be equal
    to the number of vehicles available for transportation. By analyzing the spatial
    data of employees’ locations, the clustering model will group individuals who
    live in close proximity to one another. This grouping enables the company to efficiently
    allocate vehicles to each cluster.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个公司旨在为其员工提供运输服务，并希望根据他们的居住地对他们进行聚类的场景。为了实现这一点，公司可以利用一个聚类模型，该模型以每个员工居住地的经纬度坐标作为输入数据。机器学习模型将根据指定的簇大小对员工进行聚类，簇大小可以等于可用于运输的车辆数量。通过分析员工的地理位置空间数据，聚类模型将把居住地相近的个人分组。这种分组使公司能够有效地将车辆分配到每个簇。
- en: Once the clustering model is trained and established, it can predict the appropriate
    cluster for new employees based on their residential coordinates. This allows
    the company to easily determine which cluster the new employee should join, facilitating
    seamless transportation arrangements.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦聚类模型训练并建立，它可以根据新员工的居住坐标预测他们适当的簇。这使得公司可以轻松地确定新员工应加入哪个簇，从而便于无缝的运输安排。
- en: By utilizing ML clustering techniques in this scenario, the company can effectively
    organize its transportation services and optimize resource allocation based on
    employees’ residential locations.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在这个场景中利用机器学习聚类技术，公司可以有效地组织其运输服务，并根据员工的居住地优化资源配置。
- en: '| **Employee number** | **Latitude (****o N)** | **Longitude (****o E)** |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| **员工编号** | **纬度（****北纬）** | **经度（****东经）** |'
- en: '| --- | --- | --- |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | 12.93 | 77.4472 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 12.93 | 77.4472 |'
- en: '| 2 | 12.32 | 77.4472 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 12.32 | 77.4472 |'
- en: '| 3 | 12.51 | 77.4472 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 12.51 | 77.4472 |'
- en: '| 4 | 12.62 | 77.4472 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 12.62 | 77.4472 |'
- en: '| 5 | 12.73 | 77.4472 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 12.73 | 77.4472 |'
- en: '| 6 | 12.84 | 76.4158 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 12.84 | 76.4158 |'
- en: '| 7 | 12.91 | 76.4158 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 12.91 | 76.4158 |'
- en: '| 8 | 12.41 | 76.4158 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 12.41 | 76.4158 |'
- en: '| 9 | 12.92 | 76.4158 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 12.92 | 76.4158 |'
- en: '| 10 | 12.55 | 76.4158 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 12.55 | 76.4158 |'
- en: Table 2.6 – Toy dataset for clustering example
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.6 – 聚类示例的玩具数据集
- en: The `sklearn` framework supports various clustering algorithms, and we will
    use the K-means clustering algorithm in this example to cluster the given data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn` 框架支持各种聚类算法，在本例中我们将使用 K-means 聚类算法对给定数据进行聚类。'
- en: The K-means algorithm is a centroid-based algorithm, where each cluster is associated
    with a centroid. The main aim of this algorithm is to minimize the sum of distances
    between the input data point and their corresponding cluster.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 算法是一种基于质心的算法，其中每个簇都与一个质心相关联。该算法的主要目的是最小化输入数据点与其对应簇之间的距离之和。
- en: The source code is in `Clustering_Example.ipynb`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码位于 `Clustering_Example.ipynb`。
- en: 'Import the `sklearn` K-means clustering classes and prepare the training data
    as a `numpy` array format:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 `sklearn` K-means 聚类类，并将训练数据准备为 `numpy` 数组格式：
- en: '[PRE12]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In this case, the first five employees are assigned to cluster `1` and the
    remaining are assigned to cluster `0`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，前五个员工被分配到簇 `1`，其余的分配到簇 `0`：
- en: '| Employee number | Latitude (o N) | Longitude (o E) | Assigned cluster |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 员工编号 | 纬度（北纬） | 经度（东经） | 分配的簇 |'
- en: '| 1 | 12.93 | 77.4472 | 1 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 12.93 | 77.4472 | 1 |'
- en: '| 2 | 12.32 | 77.4472 | 1 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 12.32 | 77.4472 | 1 |'
- en: '| 3 | 12.51 | 77.4472 | 1 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 12.51 | 77.4472 | 1 |'
- en: '| 4 | 12.62 | 77.4472 | 1 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 12.62 | 77.4472 | 1 |'
- en: '| 5 | 12.73 | 77.4472 | 1 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 12.73 | 77.4472 | 1 |'
- en: '| 6 | 12.84 | 76.4158 | 0 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 12.84 | 76.4158 | 0 |'
- en: '| 7 | 12.91 | 76.4158 | 0 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 12.91 | 76.4158 | 0 |'
- en: '| 8 | 12.41 | 76.4158 | 0 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 12.41 | 76.4158 | 0 |'
- en: '| 9 | 12.92 | 76.4158 | 0 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 12.92 | 76.4158 | 0 |'
- en: '| 10 | 12.55 | 76.4158 | 0 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 12.55 | 76.4158 | 0 |'
- en: Table 2.7 - Assigned cluster
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.7 - 分配的簇
- en: The cluster model learned based on the input and formed two clusters. K-means
    is a clustering algorithm that finds the center of the cluster, divides the data
    into clusters, and predicts the new data based on the nearest cluster.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 基于输入学习并形成的聚类模型分为两个簇。K-means是一种聚类算法，它找到簇的中心，将数据划分为簇，并根据最近的簇预测新数据。
- en: 'The following is the list of clustering algorithms supported by the `sklearn`
    framework:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是由`sklearn`框架支持的聚类算法列表：
- en: Affinity propagation
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相似性传播
- en: Agglomerative clustering
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类
- en: BIRCH
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BIRCH
- en: DBSCAN
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DBSCAN
- en: K-means
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K-means
- en: Mini-batch K-means
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mini-batch K-means
- en: Mean shift
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均值漂移
- en: OPTICS
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OPTICS
- en: Spectral clustering
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谱聚类
- en: Mixture of Gaussians
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高斯混合模型
- en: Reinforced ML
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强化机器学习
- en: '**Reinforcement learning** (**RL**) is a type of ML technique that enables
    an agent to learn in an interactive environment by trial and error using feedback
    from its own actions and experiences. The agent learns a series of actions that
    lead to the final goal, maximizing its total rewards. RL differs from supervised
    learning in that the model learns from taking actions and observing the results,
    not from explicit teaching.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**强化学习**（**RL**）是一种机器学习技术，它使智能体能够通过尝试错误，利用自身行动和经验中的反馈在交互式环境中学习。智能体学习一系列导致最终目标的行动，最大化其总奖励。RL与监督学习不同，因为模型是从采取行动和观察结果中学习，而不是从明确的教学中学习。'
- en: One classic use case of RL is in gaming, such as teaching a model to play and
    excel at chess. The model starts with no knowledge of the game but learns by making
    moves and seeing the outcome of the game it plays, with the aim of maximizing
    the reward (i.e., winning the game).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习的一个经典用例是在游戏领域，例如教模型下棋并取得优异成绩。模型开始时对游戏一无所知，但通过移动和观察所玩游戏的结果来学习，目标是最大化奖励（即赢得游戏）。
- en: 'In the context of RL, exploration and exploitation are two strategies that
    an agent can use to navigate through the environment:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习的背景下，探索和利用是智能体可以用来在环境中导航的两个策略：
- en: '**Exploration**: This is when the agent seeks to learn more about its environment.
    It means trying out different actions and gathering more information to learn
    about each possible action’s reward. The agent aims to balance out the reward
    it gets from known information with the possibility of receiving an even higher
    reward from unknown areas. However, exploration might involve the risk of the
    agent making non-optimal choices.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**探索**：这是智能体试图了解更多关于其环境的时候。这意味着尝试不同的行动并收集更多信息，以了解每个可能行动的奖励。智能体的目标是平衡从已知信息中获得的奖励与从未知区域获得更高奖励的可能性。然而，探索可能涉及智能体做出非最优选择的风险。'
- en: '**Exploitation**: Here, the agent uses the information it has already learned
    to make the best action that will maximize its reward. It means using known information
    to maximize success instead of further exploring. The benefit of exploitation
    is that it allows for more assured, immediate rewards, but excessive exploitation
    can lead to suboptimal results as it may neglect even better options. The challenge
    lies in finding the right balance, as focusing too much on exploration might mean
    the agent will lose out on immediate rewards while focusing extensively on exploitation
    might prevent the agent from exploring options that could lead to larger rewards
    in the future. This trade-off is often referred to as the exploration–exploitation
    dilemma.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**利用**：在这里，智能体使用它已经学习到的信息来采取最佳行动，以最大化其奖励。这意味着使用已知信息来最大化成功，而不是进一步探索。利用的好处是它允许获得更确定、即时的奖励，但过度利用可能导致次优结果，因为它可能忽略了更好的选项。挑战在于找到正确的平衡，因为过分关注探索可能意味着智能体会失去即时奖励，而过分关注利用可能阻止智能体探索可能导致未来更大奖励的选项。这种权衡通常被称为探索-利用困境。'
- en: Example problem using RL—the multi-armed bandit problem
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用RL的示例问题——多臂老虎机问题
- en: The multi-armed bandit problem is a classic problem in the field of RL that
    captures the fundamental trade-off between exploration and exploitation. The name
    is derived from a hypothetical experiment in which you face several slot machines
    (also known as “one-armed bandits”) with different fixed payouts. Because of these
    differing payouts, your goal is to maximize your total payout over a certain number
    of attempts by figuring out which machines to play, how many times to play each
    machine, and in what sequence—hence, the “multi-armed bandit problem.”
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 多臂老虎机问题是强化学习领域的一个经典问题，它捕捉了探索与利用之间的基本权衡。这个名字来源于一个假设的实验，在这个实验中，你面对几个具有不同固定收益的老虎机（也称为“单臂老虎机”）。由于这些不同的收益，你的目标是通过对哪些机器进行游戏、每次玩多少次以及以何种顺序进行游戏来最大化在一定次数尝试中的总收益——因此，这就是“多臂老虎机问题”。
- en: The primary challenge in the multi-armed bandit problem is balancing the immediate
    rewards from exploitative actions (playing the machine that you believe currently
    has the highest expected payout) with the possible benefits from exploration (trying
    out others that might have higher expected payouts but you’re less certain about).
    This tension between exploration and exploitation is at the core of many reinforcement
    learning problems.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 多臂老虎机问题的主要挑战在于平衡来自利用性动作（玩你认为当前具有最高预期收益率的机器）的即时奖励与来自探索（尝试其他可能具有更高预期收益但不太确定的机器）的潜在收益。这种探索与利用之间的紧张关系是许多强化学习问题的核心。
- en: 'The following is example code for reinforcement learning—the source code is
    in `BandIt_RL_Example.ipynb`:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为强化学习的示例代码——源代码位于`BandIt_RL_Example.ipynb`中：
- en: '[PRE13]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this example, the epsilon-greedy strategy is used, where epsilon is `1`.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，使用了ε-贪婪策略，其中ε为`1`。
- en: This is a very simplistic example and real-world RL problems require much more
    sophisticated algorithms (e.g., Q-learning, policy gradient, etc.) and are therefore
    implemented using specialized libraries.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常简单的例子，而现实世界的强化学习问题需要更复杂的算法（例如Q学习、策略梯度等），因此使用专门的库来实现。
- en: In this section, we have covered the different types of ML and provided examples
    of how to save and load models for inference and prediction. Moving forward, the
    next section will delve into the various phases of ML, providing a detailed exploration.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了不同类型的机器学习，并提供了如何保存和加载模型以进行推理和预测的示例。接下来，下一节将深入探讨机器学习的各个阶段，提供详细的探索。
- en: Overview of ML phases
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习阶段概述
- en: ML encompasses a variety of techniques and approaches, and it involves several
    distinct phases or stages in the process of developing and deploying ML models.
    These phases help guide engineers through the iterative and cyclical nature of
    ML projects, allowing them to build effective and accurate models.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习包含各种技术和方法，它涉及在开发和部署机器学习模型过程中的几个不同的阶段或阶段。这些阶段有助于指导工程师通过机器学习项目的迭代和循环性质，使他们能够构建有效且准确的模型。
- en: The ML process typically consists of several key phases, each serving a specific
    purpose and contributing to the overall success of the project. These phases are
    not always strictly linear, and iterations may occur between them to refine and
    improve the models. The specific steps and terminology used may vary depending
    on the ML methodology employed, but the core phases remain consistent.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习过程通常包括几个关键阶段，每个阶段都服务于特定目的，并有助于项目的整体成功。这些阶段并不总是严格线性，它们之间可能发生迭代，以精炼和改进模型。具体步骤和术语的使用可能因采用的机器学习方法而异，但核心阶段保持一致。
- en: The ML phases provide a systematic framework for developing and deploying ML
    models, guiding practitioners through the complexities and challenges inherent
    in building effective solutions. By following these phases, practitioners can
    maximize their chances of success and create ML models that deliver valuable insights
    and predictions in a wide range of applications.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习阶段提供了一个系统框架，用于开发和部署机器学习模型，指导实践者通过构建有效解决方案固有的复杂性和挑战。通过遵循这些阶段，实践者可以最大化成功的机会，并创建能够在广泛应用中提供有价值和预测的机器学习模型。
- en: The main phases of ML
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习的主要阶段
- en: 'The following are the main phases of ML:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为机器学习的主要阶段：
- en: '**Data collection**: This phase involves gathering relevant data from various
    sources, such as databases, APIs, or manual collection. The data should be representative
    of the problem domain and cover a wide range of scenarios.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集**：这个阶段涉及从各种来源收集相关数据，例如数据库、API或手动收集。数据应代表问题域，并涵盖广泛的场景。'
- en: '**Data preparation**: In this phase, the collected data is preprocessed and
    transformed into a suitable format for analysis. This may include tasks such as
    cleaning the data, handling missing values, removing outliers, and normalizing
    or scaling the features.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据准备**：在这个阶段，收集到的数据被预处理并转换为适合分析的形式。这可能包括诸如清理数据、处理缺失值、去除异常值以及归一化或缩放特征等任务。'
- en: '**Feature engineering**: Feature engineering involves selecting and creating
    relevant features from the available data that will enhance the model’s predictive
    power. This phase requires domain knowledge and creativity to extract meaningful
    insights from the data.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程**：特征工程涉及从可用数据中选择和创建相关特征，这些特征将增强模型的预测能力。这个阶段需要领域知识和创造力，以从数据中提取有意义的见解。'
- en: '**Model development**: In this phase, a suitable ML algorithm or model is selected
    based on the problem at hand. The model is trained on the prepared data to learn
    patterns and relationships within the data.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型开发**：在这个阶段，根据手头的问题选择合适的机器学习算法或模型。模型在准备好的数据上训练，以学习数据中的模式和关系。'
- en: '**Model evaluation**: The trained model is evaluated using appropriate evaluation
    metrics to assess its performance. This helps in understanding how well the model
    generalizes to unseen data and whether it meets the desired criteria for accuracy
    and reliability.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型评估**：使用适当的评估指标对训练好的模型进行评估，以评估其性能。这有助于了解模型在未见过的数据上的泛化能力以及它是否满足准确性和可靠性方面的预期标准。'
- en: '**Model optimization**: If the model’s performance is not satisfactory, this
    phase involves fine-tuning the model by adjusting hyperparameters or trying different
    algorithms to improve its performance. The optimization process aims to achieve
    the best possible results.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型优化**：如果模型的性能不满意，这个阶段涉及通过调整超参数或尝试不同的算法来微调模型，以提高其性能。优化过程旨在实现最佳可能的结果。'
- en: '**Model Deployment**: Once the model is trained and optimized, it is deployed
    in a production environment where it can make predictions on new, unseen data.
    This phase involves integrating the model into existing systems or creating an
    interface for users to interact with the model.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署**：一旦模型经过训练和优化，它就被部署到生产环境中，可以在新的、未见过的数据上进行预测。这个阶段涉及将模型集成到现有系统中或为用户创建与模型交互的界面。'
- en: '**Model monitoring and maintenance**: After deployment, the model needs to
    be monitored to ensure it continues to perform well over time. Monitoring involves
    tracking performance metrics, identifying drift in data distribution, and updating
    the model if necessary. Regular maintenance is essential to keeping the model
    up to date and accurate.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型监控和维护**：部署后，需要监控模型以确保其随着时间的推移继续表现良好。监控涉及跟踪性能指标、识别数据分布的漂移，并在必要时更新模型。定期维护对于保持模型最新和准确至关重要。'
- en: These phases provide a systematic approach to building and deploying ML models,
    enabling organizations to leverage the power of data and make informed decisions.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这些阶段提供了一个系统的方法来构建和部署机器学习模型，使组织能够利用数据的力量并做出明智的决策。
- en: Sub-phases in the ML process
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习过程中的子阶段
- en: 'The following diagram shows the phases of the ML process:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图显示了机器学习过程的阶段：
- en: '![Figure 2.3 – ML phases](img/B16573_02_03.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图2.3 – 机器学习阶段](img/B16573_02_03.jpg)'
- en: Figure 2.3 – ML phases
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 – 机器学习阶段
- en: 'These are the main phases:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是主要阶段：
- en: Data preparation phase
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据准备阶段
- en: ML model phase (design and development)
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型阶段（设计和开发）
- en: ML operations phase
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习操作阶段
- en: Let’s look at these in more detail.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这些。
- en: Data preparation phase
  id: totrans-216
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据准备阶段
- en: The data preparation phase deals with data collection, extraction, and manipulation.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备阶段处理数据收集、提取和操作。
- en: '| **Phase** | **Sub-phases** | **Details** |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| **阶段** | **子阶段** | **细节** |'
- en: '| Data preparation | Data collection | Identify the data that needs to be analyzed
    |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 数据准备 | 数据收集 | 确定需要分析的数据 |'
- en: '| Data extraction | Extract the data from the data source |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 数据提取 | 从数据源中提取数据 |'
- en: '| Data manipulation | Data transformation, missing data, duplicate data, noise,
    and data preprocessing |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 数据操作 | 数据转换、缺失数据、重复数据、噪声和数据预处理 |'
- en: '| **Exploratory data** **analysis** (**EDA**) | EDA and handling data |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| **探索性数据分析**（EDA） | EDA 和数据处理 |'
- en: Table 2.8 - Data preparation phase
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.8 - 数据准备阶段
- en: 'The following figure shows the data preparation sub-phases:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了数据准备子阶段：
- en: Data Preparation Phase
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据准备阶段
- en: '![Figure 2.4 – ML data preparation sub-phases](img/B16573_02_04.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.4 – 机器学习数据准备子阶段](img/B16573_02_04.jpg)'
- en: Figure 2.4 – ML data preparation sub-phases
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – 机器学习数据准备子阶段
- en: ML model phase
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 机器学习模型阶段
- en: This phase is subdivided into several phases to deal with feature engineering,
    actual model identification, the training and testing of models, and so on.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 此阶段被细分为几个阶段，以处理特征工程、实际模型识别、模型的训练和测试等。
- en: '| **Phase** | **Sub-phases** | **Details** |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| **阶段** | **子阶段** | **详细信息** |'
- en: '| ML model | Model identification | This involves classification, clustering,
    re-enforcement, time series analysis, and so on. |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习模型 | 模型识别 | 这涉及到分类、聚类、强化学习、时间序列分析等。|'
- en: '| Feature engineering | In this phase, features are selected from the data.
    |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 特征工程 | 在此阶段，从数据中选择特征。|'
- en: '| Input data preparation for the model | This involves data processed and data
    prepared in the format the model expects. |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 为模型准备输入数据 | 这涉及到以模型期望的格式处理和准备的数据。|'
- en: '| Split the data (train, test, and validate) | Split the entire data into three
    parts—training data, test data, and validation data—to train, test, and validate
    the models. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 分割数据（训练、测试和验证） | 将整个数据分割成三个部分——训练数据、测试数据和验证数据，以训练、测试和验证模型。|'
- en: '| Train the model with the training dataset | In this phase, the model is trained
    with the training data. |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 使用训练数据集训练模型 | 在此阶段，模型使用训练数据进行训练。|'
- en: '| Test the model with the testing dataset | The ML model is tested with the
    test data to find out the accuracy of predictions. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 使用测试数据集测试模型 | 使用测试数据测试机器学习模型，以找出预测的准确性。|'
- en: '| Version of data, model, model parameters, and results | Version control is
    applied to datasets used, as well as to the model and its parameters, along with
    the results of each experiment. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 数据、模型、模型参数和结果版本 | 对使用的数据集、模型及其参数以及每个实验的结果应用版本控制。|'
- en: '| Validate the dataset with the trained model | This is similar to test data
    but the samples are from the validation dataset. |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 使用训练模型验证数据集 | 这类似于测试数据，但样本来自验证数据集。|'
- en: '| Predict results with new data (inference) | For inference, use the new data
    and find out the results. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 使用新数据预测结果（推理） | 对于推理，使用新数据并找出结果。|'
- en: Table 2.9 - ML model phase
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.9 - 机器学习模型阶段
- en: 'The following figure shows the ML model sub-phases:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了机器学习模型子阶段：
- en: '![Figure 2.5 – ML model sub-phases](img/B16573_02_05.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.5 – 机器学习模型子阶段](img/B16573_02_05.jpg)'
- en: Figure 2.5 – ML model sub-phases
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5 – 机器学习模型子阶段
- en: ML operations phase
  id: totrans-244
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 机器学习操作阶段
- en: This phase is mainly focused on the operations of the models in production.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 此阶段主要关注生产中模型的操作。
- en: '| Phase | Sub-phases | Details |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 阶段 | 子阶段 | 详细信息 |'
- en: '| ML operations(MLOps) | Package model artifacts | Persist the model (store
    the weights and biases) in ONNX format or other formats. |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习操作（MLOps） | 打包模型工件 | 将模型（存储权重和偏差）持久化存储为 ONNX 格式或其他格式。|'
- en: '| Deploy model | This involves the production deployment of the model.(A/B
    testing, canary deployment, shadow models, etc.) |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 部署模型 | 这涉及到模型的实际生产部署。（A/B 测试、金丝雀部署、影子模型等）|'
- en: '| Validate the inference results |  |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 验证推理结果 |  |'
- en: '| Monitor model performance | Monitor the performance model, i.e, whether the
    accuracy stays constant or degrades over a period. |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 监控模型性能 | 监控模型性能，即准确性是否在一段时间内保持不变或下降。|'
- en: '| Retrain the model and repeat the ML model life cycle | Retrain the model
    if the model performance degrades and handle model drift and data drift accordingly.
    |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 重新训练模型并重复机器学习模型生命周期 | 如果模型性能下降，则重新训练模型，并相应地处理模型漂移和数据漂移。|'
- en: Table 2.10 - ML operations
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.10 - 机器学习操作
- en: 'The following figure shows the ML operations sub-phases:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了机器学习操作子阶段：
- en: '![Figure 2.6 – ML operations sub-phases](img/B16573_02_06.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.6 – 机器学习操作子阶段](img/B16573_02_06.jpg)'
- en: Figure 2.6 – ML operations sub-phases
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – 机器学习操作子阶段
- en: We have thoroughly covered the development of ML models and the various phases
    involved in the process. In the upcoming section, our focus will shift to exploring
    the privacy threats and attacks that can occur in each phase of ML. We will delve
    into understanding these threats and discuss effective mitigation strategies to
    safeguard the privacy of the data and models involved. By addressing these privacy
    concerns at each stage, we can ensure the responsible and secure implementation
    of ML techniques.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经详细介绍了机器学习模型的发展以及该过程中涉及的各种阶段。在接下来的部分，我们的重点将转向探索机器学习每个阶段可能发生的隐私威胁和攻击。我们将深入了解这些威胁，并讨论有效的缓解策略，以保护数据和模型涉及的隐私。通过在每个阶段解决这些隐私问题，我们可以确保机器学习技术的负责任和安全实施。
- en: Privacy threats/attacks in ML phases
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习阶段中的隐私威胁/攻击
- en: ML projects are developed in collaboration with data engineers, ML engineers,
    and software engineers, and each one plays a different role in order to develop
    end-to-end systems to predict and provide insights.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习项目是由数据工程师、机器学习工程师和软件工程师协作开发的，每个角色都在开发端到端系统以预测和提供见解中扮演不同的角色。
- en: Collaborative roles in ML projects
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习项目中的协作角色
- en: 'ML projects are collaborative efforts involving various roles such as data
    engineers, ML engineers, and software engineers. Each role contributes in different
    ways to develop end-to-end systems that can predict outcomes and provide valuable
    insights. Let’s explore the roles and their responsibilities in the ML project
    life cycle:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习项目是涉及各种角色如数据工程师、机器学习工程师和软件工程师的协作努力。每个角色以不同的方式为开发端到端系统做出贡献，这些系统能够预测结果并提供有价值的见解。让我们来探讨在机器学习项目生命周期中各个角色的职责：
- en: '**Data engineer**: The data engineer primarily focuses on the data preparation
    phase. They are responsible for extracting data from one or multiple sources and
    ensuring its quality and suitability for the ML project. Data engineers work on
    tasks such as data cleaning, transformation, and feature selection to prepare
    the data for ML modeling.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据工程师**：数据工程师主要关注数据准备阶段。他们负责从一个或多个来源提取数据，并确保其质量适合机器学习项目。数据工程师从事数据清洗、转换和特征选择等任务，以准备数据用于机器学习建模。'
- en: '**ML engineer**: ML engineers play a crucial role in designing and developing
    ML models. They leverage the data provided by the data engineer to train and test
    the models. ML engineers are responsible for selecting appropriate algorithms
    or model architectures, tuning hyperparameters, and optimizing the models for
    accuracy and efficiency. They validate the model against validation test data
    and provide APIs for inference or export/deployment of the model into production.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习工程师**：机器学习工程师在设计和开发机器学习模型中扮演着至关重要的角色。他们利用数据工程师提供的数据来训练和测试模型。机器学习工程师负责选择合适的算法或模型架构，调整超参数，并优化模型以提高准确性和效率。他们使用验证测试数据验证模型，并提供推理或模型导出/部署到生产环境的API。'
- en: '**Model consumer**: The model consumer can be an individual or another application
    that interacts with the ML model. They make API calls and provide input to the
    model for prediction or inference. Model consumers utilize the insights generated
    by the ML model to make informed decisions or take appropriate actions.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型消费者**：模型消费者可以是个人或另一个与机器学习模型交互的应用程序。他们通过API调用向模型提供输入以进行预测或推理。模型消费者利用机器学习模型生成的见解做出明智的决策或采取适当的行动。'
- en: Privacy threats/attacks in ML
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习中的隐私威胁/攻击
- en: In the context of ML, an adversary refers to an entity or system that actively
    tries to undermine or exploit the machine learning model or system. The goal of
    an adversary is typically to manipulate the model’s behavior, gain unauthorized
    access to sensitive information, or deceive the system by exploiting vulnerabilities.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的背景下，对手指的是一个试图积极破坏或利用机器学习模型或系统的实体或系统。对手的目标通常是操纵模型的行为，未经授权访问敏感信息，或者通过利用漏洞欺骗系统。
- en: Adversaries can take various forms and have different motives.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 对手可以采取各种形式，具有不同的动机。
- en: 'Here are a few examples:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些例子：
- en: '**Adversarial examples**: In this case, the adversary aims to create input
    samples (e.g., images or text) that are intentionally crafted to mislead or deceive
    the ML model. Adversarial examples are designed to exploit vulnerabilities in
    the model’s decision-making process, leading to incorrect predictions or misclassifications.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对抗样本**：在这种情况下，攻击者的目标是创建旨在误导或欺骗ML模型的输入样本（例如，图像或文本）。对抗样本旨在利用模型决策过程中的漏洞，导致错误预测或误分类。'
- en: '**Data poisoning**: An adversary may try to inject malicious or misleading
    data into the training dataset. By inserting carefully crafted samples, the adversary
    aims to manipulate the model’s training process, leading to biased or compromised
    results. This can be particularly problematic in scenarios where the training
    data is collected from untrusted or unreliable sources.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据中毒**：攻击者可能会尝试将恶意或误导性数据注入训练数据集中。通过插入精心制作的样本，攻击者旨在操纵模型的训练过程，导致结果偏差或受损。这在从不可信或不可靠来源收集训练数据的情况下尤其成问题。'
- en: '**Model inversion**: An adversary might attempt to extract sensitive information
    from a trained model. By providing specific input and observing the model’s output,
    the adversary aims to infer confidential or private data that was used to train
    the model, such as **personally identifiable information** (**PII**) or proprietary
    knowledge.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型反演**：攻击者可能会尝试从训练好的模型中提取敏感信息。通过提供特定输入并观察模型的输出，攻击者旨在推断用于训练模型的机密或私人数据，例如**个人身份信息**（**PII**）或专有知识。'
- en: '**Evasion attacks**: Adversaries can also launch evasion attacks, also known
    as adversarial attacks, during the deployment phase. In these attacks, the adversary
    tries to bypass or manipulate the model’s defenses by carefully modifying input
    samples. For example, in the case of a spam email classifier, an adversary may
    add specific patterns or keywords to trick the model into classifying a malicious
    email as legitimate.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逃避攻击**：攻击者也可以在部署阶段发起逃避攻击，也称为对抗攻击。在这些攻击中，攻击者通过仔细修改输入样本来尝试绕过或操纵模型的防御机制。例如，在垃圾邮件分类器的情况下，攻击者可能会添加特定的模式或关键词来欺骗模型，将其分类为合法的恶意邮件。'
- en: To mitigate the impact of adversaries, researchers and practitioners develop
    robust ML models and techniques, such as adversarial training, defensive distillation,
    and input sanitization. These approaches aim to enhance the resilience of ML systems
    against adversarial attacks and maintain their performance and reliability in
    the presence of potential threats.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻攻击者的影响，研究人员和从业者开发了鲁棒的ML模型和技术，例如对抗训练、防御蒸馏和输入净化。这些方法旨在增强ML系统对对抗攻击的弹性，并在潜在威胁存在的情况下保持其性能和可靠性。
- en: Throughout the ML life cycle, privacy threats or attacks can occur, posing risks
    to the confidentiality of sensitive information. In the context of ML, adversaries
    attempt to gain unauthorized access to confidential data used in ML, the core
    ML model, or specific features of the data.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个ML生命周期中，隐私威胁或攻击都可能发生，对敏感信息的机密性构成风险。在ML的背景下，攻击者试图未经授权访问用于ML的机密数据、核心ML模型或数据的特定特征。
- en: 'There are two primary types of attacks, white-box and black-box:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种主要的攻击类型，白盒和黑盒：
- en: '**White-box attack**: A white-box attack assumes that the adversary has full
    knowledge and access to the ML model, including its architecture, input, output,
    and weights. The attacker exploits this information to extract confidential details.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**白盒攻击**：白盒攻击假设攻击者对ML模型有全面的知识和访问权限，包括其架构、输入、输出和权重。攻击者利用这些信息来提取机密细节。'
- en: '**Black-box attack**: In contrast, a black-box attack assumes that the attacker
    only has access to the input and output of the ML model. They have no knowledge
    of the underlying architecture or weights used in the ML/DL model. Despite the
    limited information, they aim to infer sensitive information from the model.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黑盒攻击**：相比之下，黑盒攻击假设攻击者只能访问ML模型的输入和输出。他们对底层架构或ML/DL模型中使用的权重一无所知。尽管信息有限，但他们旨在从模型中推断敏感信息。'
- en: 'Privacy threats/attacks classification:'
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 隐私威胁/攻击分类：
- en: The following are the privacy attacks on the ML models for classification
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对分类机器学习模型的隐私攻击
- en: '**Membership inference attack**: This attack aims to determine whether a particular
    data point was part of the training dataset used to train the ML model. The adversary
    tries to infer membership information by exploiting the model’s responses.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成员推理攻击**：这种攻击旨在确定特定数据点是否是用于训练机器学习模型的训练数据集的一部分。攻击者试图通过利用模型的响应来推断成员信息。'
- en: '**Model extraction attack**: In this attack, the adversary attempts to extract
    the entire or partial ML model architecture, weights, or parameters. This attack
    allows the attacker to replicate the ML model for their own purposes, potentially
    leading to intellectual property theft.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型提取攻击**：在这种攻击中，攻击者试图提取整个或部分机器学习模型架构、权重或参数。这种攻击允许攻击者复制机器学习模型以供自己使用，可能导致知识产权盗窃。'
- en: '**Reconstruction attack**: This attack focuses on reconstructing sensitive
    information from the ML model’s outputs. The attacker aims to infer private data
    or specific features that were used to generate the model’s predictions. By understanding
    and addressing these privacy threats, ML practitioners can take appropriate measures
    to safeguard sensitive data and ensure the security of ML models throughout their
    life cycle.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重建攻击**：这种攻击专注于从机器学习模型的输出中重建敏感信息。攻击者的目标是推断出用于生成模型预测的私有数据或特定特征。通过理解和应对这些隐私威胁，机器学习从业者可以采取适当的措施来保护敏感数据，并确保机器学习模型在其整个生命周期中的安全性。'
- en: We’ll look at these in more detail in the following sections.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中更详细地探讨这些问题。
- en: Membership inference attack
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成员推理攻击
- en: Assume a classification model is developed with certain input training data,
    X { x1, x2, x3, …. Xn} to predict certain labels, y, using a function, F.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 假设开发了一个分类模型，使用某些输入训练数据X {x1, x2, x3, …. Xn}，通过函数F预测某些标签y。
- en: A membership inference attack tries to determine whether an input sample, x,
    was used as part of the training dataset, X, or not. Basically, an adversary (attacker)
    needs to find out whether the data point at hand belongs to the original dataset
    that is used for training the ML model or not.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 成员推理攻击试图确定输入样本x是否是训练数据集X的一部分。基本上，攻击者（攻击者）需要找出当前数据点是否属于用于训练机器学习模型的原始数据集。
- en: '![Figure 2.7 – Membership inference attack - Example](img/B16573_02_07.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![图2.7 – 成员推理攻击 - 示例](img/B16573_02_07.jpg)'
- en: Figure 2.7 – Membership inference attack - Example
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7 – 成员推理攻击 - 示例
- en: '(Image source: Suha Hussain, PrivacyRaven, [https://blog.openmined.org/privacyraven-comprehensive-privacy-testing-for-deep-learning/](https://blog.openmined.org/privacyraven-comprehensive-privacy-testing-for-deep-learning/))'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: （图片来源：Suha Hussain，PrivacyRaven，[https://blog.openmined.org/privacyraven-comprehensive-privacy-testing-for-deep-learning/](https://blog.openmined.org/privacyraven-comprehensive-privacy-testing-for-deep-learning/))
- en: Let’s look at an example. Suppose an adversary wants to determine whether a
    particular person’s data was used in the training data or not without the knowledge
    of that person. Later, this data is used to derive insights on whether to approve
    that person’s insurance policy or not.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子。假设一个攻击者想要确定某个特定人的数据是否被用于训练数据中，而不需要知道这个人。后来，这些数据被用来推断是否批准该人的保险政策。
- en: This is the most popular category of attacks and was first introduced by Shokri
    et al.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 这是攻击中最受欢迎的类别，最初由Shokri等人提出。
- en: 'Here is the reference to the full paper: *Reza Shokri, Marco Stronati, Congzheng
    Song, and Vitaly Shmatikov. 2017\. Membership inference attacks against machine
    learning models. In 2017 IEEE Symposium on Security and Privacy (SP). IEEE, San
    Francisco, CA,* *USA, 3–18.*'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是完整论文的引用：*Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov.
    2017\. Membership inference attacks against machine learning models. In 2017 IEEE
    Symposium on Security and Privacy (SP). IEEE, San Francisco, CA,* *USA, 3–18.*
- en: This is a kind of black-box testing attack because the adversary doesn’t have
    the details of the actual ML model; all they have is the set of input data and
    inference results from the model.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种黑盒测试攻击，因为攻击者没有实际机器学习模型的详细信息；他们所拥有的只是输入数据集和模型推断结果。
- en: 'This is what the paper says about this approach:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 论文关于这种方法是这样说的：
- en: “The attacker queries the target model with a data record and obtains the model’s
    prediction on that record. The prediction is a vector of probabilities, one per
    class, that the record belongs to a certain class. This prediction vector, along
    with the label of the target record, is passed to the attack model, which determines
    whether the record was in or out of the target model’s training dataset.”
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: “攻击者用一个数据记录查询目标模型，并获取该模型对该记录的预测。预测是一个向量，每个类别一个概率，表示记录属于某个类别的概率。这个预测向量，连同目标记录的标签一起，被传递给攻击模型，该模型确定记录是否在目标模型的训练数据集中。”
- en: 'The following figure also comes from the aforementioned paper ([https://arxiv.org/pdf/1610.05820.pdf](https://arxiv.org/pdf/1610.05820.pdf)):'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图也来自上述论文（[https://arxiv.org/pdf/1610.05820.pdf](https://arxiv.org/pdf/1610.05820.pdf)）：
- en: '![Figure 2.8 – Membership inference attack - Example](img/B16573_02_08.jpg)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![图2.8 – 成员推理攻击 - 示例](img/B16573_02_08.jpg)'
- en: Figure 2.8 – Membership inference attack - Example
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 – 成员推理攻击 - 示例
- en: Membership inference attack—basic example
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 成员推理攻击—基本示例
- en: In a membership inference attack, an adversary attempts to determine whether
    a specific data point was used in the training set of an ML model, as stated earlier.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在成员推理攻击中，攻击者试图确定特定数据点是否被用于机器学习模型的训练集中，如前所述。
- en: 'Here’s an example using a simple decision tree classifier (the source code
    can be found in `Membership_Inference_basic_example.ipynb`):'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个使用简单的决策树分类器的例子（源代码可以在`Membership_Inference_basic_example.ipynb`中找到）：
- en: '[PRE14]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this example, we load the `Iris` dataset from scikit-learn and split it into
    a training set and a test set. We then train a decision tree classifier on the
    training set. Next, we select a data point (or set of points) from the test set
    and attempt to determine whether it was present in the training set by predicting
    its class. If the predicted class matches the actual class from the test set,
    we infer that the target data point was in the training set, indicating a successful
    attack. Remember, conducting membership inference attacks without proper authorization
    is unethical and often illegal.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们从scikit-learn中加载了`Iris`数据集，并将其分为训练集和测试集。然后我们在训练集上训练一个决策树分类器。接下来，我们从测试集中选择一个数据点（或一组数据点），并通过预测其类别来尝试确定它是否存在于训练集中。如果预测的类别与测试集中的实际类别相匹配，我们推断目标数据点在训练集中，这表明攻击成功。记住，未经适当授权进行成员推理攻击是不道德的，通常是非法的。
- en: Membership inference attack—advanced example
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 成员推理攻击—高级示例
- en: Let’s consider a scenario where an adversary seeks to determine whether a specific
    individual’s data is present in the training data without any prior knowledge
    of that person. This scenario involves discovering whether a person’s name exists
    within a hospital’s sensitive clinical data. The adversary intends to exploit
    this information to make decisions, such as granting or denying an insurance policy,
    based on the insights gained.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个场景，其中攻击者试图确定特定个人的数据是否存在于训练数据中，而对该个人没有任何先前的了解。这个场景涉及发现一个人的名字是否存在于医院的敏感临床数据中。攻击者打算利用这些信息来做出决策，例如根据从训练数据中获得的认识来授予或拒绝保险政策。
- en: To illustrate this scenario, let’s use a sample dataset (for illustrative purposes
    only) similar to the classification example we previously discussed. The dataset
    focuses on predicting whether a patient will live for the next 5 to 10 years or
    not based on factors such as age and existing diseases.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这种情况，让我们使用一个类似我们之前讨论的分类示例的样本数据集（仅用于说明目的）。该数据集侧重于根据年龄和现有疾病等因素预测患者是否能在未来5到10年内生存。
- en: In this context, the adversary’s goal is to identify whether the data related
    to a specific person, whose identity they are unaware of, is present in the training
    data. By discovering this information, the adversary can potentially manipulate
    decisions related to insurance policies based on the insights gained from the
    training data.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，攻击者的目标是确定与特定人员相关的数据（他们不知道该人员的身份）是否存在于训练数据中。通过发现这些信息，攻击者可以基于从训练数据中获得的认识来操纵与保险政策相关的决策。
- en: It is important to note that this example serves to highlight a potential privacy
    threat and does not aim to validate its accuracy or real-world applicability.
    The objective is to raise awareness about the importance of safeguarding sensitive
    data and implementing robust privacy measures to prevent unauthorized access and
    misuse.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，此示例旨在突出潜在的隐私威胁，并不旨在验证其准确性或实际应用性。目标是提高人们对保护敏感数据以及实施强大的隐私措施以防止未经授权的访问和滥用的认识。
- en: '| Age (years) | Has/had cancer (1 = yes, 0 = no) | Survived ( 1 = yes, 0 =
    no) |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| 年龄（年） | 是否患有癌症（1 = 是，0 = 否） | 是否存活（1 = 是，0 = 否） |'
- en: '| 10 | 1 | 1 |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | 1 |'
- en: '| 20 | 1 | 1 |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 1 | 1 |'
- en: '| 30 | 1 | 1 |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 1 |'
- en: '| 80 | 1 | 0 |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 1 | 0 |'
- en: '| 75 | 0 | 0 |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 0 | 0 |'
- en: '| 78 | 0 | 0 |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| 78 | 0 | 0 |'
- en: Table 2.11 - Training data
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.11 - 训练数据
- en: 'The source code for this ML model can be found in `Membership_Inference_advanced_example.ipynb`:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 该机器学习模型的源代码可在 `Membership_Inference_advanced_example.ipynb` 中找到：
- en: '[PRE15]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Inference results with sample test data
  id: totrans-318
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 样本测试数据的推理结果
- en: 'The adversary creates synthetic test data with diverse inputs to evaluate the
    model’s performance. Their objective is to determine whether the given patient
    data exists in the training dataset or not using the model’s predictions:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者创建具有不同输入的合成测试数据以评估模型性能。他们的目标是确定给定的患者数据是否存在于训练数据集中，使用模型预测：
- en: '[PRE16]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The results are in the table format; 1 means the person has cancer and the
    predicted probability column shows the percentage of predicted probability:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 结果以表格形式呈现；1 表示该人患有癌症，预测概率列显示预测概率的百分比：
- en: '| Age | Cancer | Class predicted | Predicted probability |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 年龄 | 癌症 | 预测类别 | 预测概率 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 25 | 1 | 1 | 100 |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 1 | 1 | 100 |'
- en: '| 25 | 0 | 1 | 100 |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 0 | 1 | 100 |'
- en: '| 30 | 1 | 1 | 100 |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 1 | 100 |'
- en: '| 30 | 0 | 1 | 100 |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 0 | 1 | 100 |'
- en: '| 45 | 1 | 1 | 100 |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| 45 | 1 | 1 | 100 |'
- en: '| 45 | 0 | 1 | 100 |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 45 | 0 | 1 | 100 |'
- en: '| 50 | 1 | 1 | 100 |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 1 | 1 | 100 |'
- en: '| 50 | 0 | 1 | 100 |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 0 | 1 | 100 |'
- en: '| 60 | 1 | 0 | 0 |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 60 | 1 | 0 | 0 |'
- en: '| 60 | 0 | 0 | 0 |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| 60 | 0 | 0 | 0 |'
- en: '| 75 | 1 | 0 | 0 |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 1 | 0 | 0 |'
- en: '| 75 | 0 | 0 | 0 |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 0 | 0 | 0 |'
- en: '| 80 | 1 | 0 | 0 |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 1 | 0 | 0 |'
- en: '| 80 | 0 | 0 | 0 |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 0 | 0 | 0 |'
- en: '| 90 | 1 | 0 | 0 |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| 90 | 1 | 0 | 0 |'
- en: '| 90 | 0 | 0 | 0 |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| 90 | 0 | 0 | 0 |'
- en: '| 100 | 1 | 0 | 0 |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| 100 | 1 | 0 | 0 |'
- en: '| 100 | 0 | 0 | 0 |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| 100 | 0 | 0 | 0 |'
- en: '| 10 | 1 | 0 | 100 |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | 0 | 100 |'
- en: '| 20 | 1 | 0 | 100 |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 1 | 0 | 100 |'
- en: '| 30 | 1 | 0 | 100 |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 0 | 100 |'
- en: '| 78 | 0 | 1 | 0 |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| 78 | 0 | 1 | 0 |'
- en: Table 2.12 - Predicted probability
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.12 - 预测概率
- en: Next, the adversary proceeds to develop shadow models and a final attack model.
    These models are designed to predict whether a given data record was used in the
    training dataset. By utilizing each record and its predicted class, along with
    the corresponding predicted probabilities, the adversary infers whether the data
    record was part of the training set or not.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，攻击者开始开发影子模型和最终的攻击模型。这些模型旨在预测给定的数据记录是否用于训练数据集。通过利用每个记录及其预测类别，以及相应的预测概率，攻击者推断该数据记录是否是训练集的一部分。
- en: '![Figure 2.9 – Shadow models](img/B16573_02_09.jpg)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.9 – 影子模型](img/B16573_02_09.jpg)'
- en: Figure 2.9 – Shadow models
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9 – 影子模型
- en: The preceding figure was sourced from the paper at [https://arxiv.org/pdf/1610.05820.pdf](https://arxiv.org/pdf/1610.05820.pdf).
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表来源于论文[https://arxiv.org/pdf/1610.05820.pdf](https://arxiv.org/pdf/1610.05820.pdf)。
- en: The attacker model makes use of the class label 'In' for the given input record
    used in the training, while 'out' means it is not used.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击模型使用类别标签 'In' 表示用于训练的给定输入记录，而 'out' 表示它没有被使用。
- en: 'This is the training data for the final attack model:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最终攻击模型的训练数据：
- en: '| Age | Cancer | Class predicted | Predicted probability | Record used in the
    training set (in = 1, out = 0) |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 年龄 | 癌症 | 预测类别 | 预测概率 | 训练集中使用的记录（in = 1，out = 0） |'
- en: '| 25 | 1 | 1 | 100 | 1 |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 1 | 1 | 100 | 1 |'
- en: '| 25 | 0 | 1 | 100 | 1 |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| 25 | 0 | 1 | 100 | 1 |'
- en: '| 30 | 1 | 1 | 100 | 1 |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 1 | 100 | 1 |'
- en: '| 30 | 0 | 1 | 100 | 1 |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 0 | 1 | 100 | 1 |'
- en: '| 45 | 1 | 1 | 100 | 1 |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 45 | 1 | 1 | 100 | 1 |'
- en: '| 45 | 0 | 1 | 100 | 1 |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 45 | 0 | 1 | 100 | 1 |'
- en: '| 50 | 1 | 1 | 100 | 1 |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 1 | 1 | 100 | 1 |'
- en: '| 50 | 0 | 1 | 100 | 1 |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 50 | 0 | 1 | 100 | 1 |'
- en: '| 10 | 1 | 0 | 100 | 1 |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | 0 | 100 | 1 |'
- en: '| 20 | 1 | 0 | 100 | 1 |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 1 | 0 | 100 | 1 |'
- en: '| 30 | 1 | 0 | 100 | 1 |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 1 | 0 | 100 | 1 |'
- en: '| 60 | 1 | 0 | 0 | 0 |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 60 | 1 | 0 | 0 | 0 |'
- en: '| 60 | 0 | 0 | 0 | 0 |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| 60 | 0 | 0 | 0 | 0 |'
- en: '| 75 | 1 | 0 | 0 | 0 |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 1 | 0 | 0 | 0 |'
- en: '| 75 | 0 | 0 | 0 | 0 |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| 75 | 0 | 0 | 0 | 0 |'
- en: '| 80 | 1 | 0 | 0 | 0 |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 1 | 0 | 0 | 0 |'
- en: '| 80 | 0 | 0 | 0 | 0 |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| 80 | 0 | 0 | 0 | 0 |'
- en: '| 90 | 1 | 0 | 0 | 0 |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| 90 | 1 | 0 | 0 | 0 |'
- en: '| 90 | 0 | 0 | 0 | 0 |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 90 | 0 | 0 | 0 | 0 |'
- en: '| 100 | 1 | 0 | 0 | 0 |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 100 | 1 | 0 | 0 | 0 |'
- en: '| 100 | 0 | 0 | 0 | 0 |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 100 | 0 | 0 | 0 | 0 |'
- en: '| 78 | 0 | 1 | 0 | 0 |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| 78 | 0 | 1 | 0 | 0 |'
- en: Table 2.13 - Training data for final attack model
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.13 - 最终攻击模型的训练数据
- en: Membership inference attacks can be easily executed with remarkable accuracy
    in simple linear models, as shown in the preceding example. ML models hosted in
    the cloud are susceptible to such inference attacks, as researchers have successfully
    demonstrated membership attack models with accuracies exceeding 90%.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 成员推理攻击可以在简单的线性模型中轻松执行，并且准确性非常高，如前例所示。托管在云中的机器学习模型容易受到此类推理攻击，因为研究人员已经成功演示了准确率超过90%的成员攻击模型。
- en: Techniques to mitigate membership inference attacks
  id: totrans-378
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 减轻成员推理攻击的技术
- en: Membership inference attacks can be a concern in ML models that involve sensitive
    data.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在涉及敏感数据的机器学习模型中，成员推理攻击可能是一个问题。
- en: 'Some techniques to mitigate membership inference attacks are as follows:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些减轻成员推理攻击的技术：
- en: '**Limit access to sensitive information**: One of the simplest ways to mitigate
    membership inference attacks is to limit access to sensitive information. By minimizing
    the amount of sensitive data that is exposed, you reduce the potential for attackers
    to perform membership inference.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**限制对敏感信息的访问**：减轻成员推理攻击的一种简单方法就是限制对敏感信息的访问。通过最小化暴露的敏感数据量，可以减少攻击者执行成员推理的可能性。'
- en: '**Differential privacy**: Differential privacy is a technique that adds noise
    to the training data or the model’s output, making it harder for an attacker to
    determine whether a specific record was part of the training set. Applying differential
    privacy mechanisms can help protect against membership inference attacks. We will
    learn about differential privacy in the next chapter.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**差分隐私**：差分隐私是一种向训练数据或模型输出添加噪声的技术，使得攻击者更难确定特定记录是否是训练集的一部分。应用差分隐私机制可以帮助抵御成员推理攻击。我们将在下一章学习差分隐私。'
- en: '**Training set augmentation**: By augmenting the training set with additional
    synthetic or generated data, you can make it more difficult for attackers to distinguish
    between genuine training instances and potential members. Augmentation techniques
    such as data generation, perturbation, or adding noise can help to increase the
    privacy of the training set.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练集增强**：通过向训练集添加额外的合成或生成数据，可以使得攻击者更难区分真实训练实例和潜在成员。数据生成、扰动或添加噪声等增强技术可以帮助提高训练集的隐私性。'
- en: '**Regularization and dropout**: Applying regularization techniques such as
    L1 or L2 regularization and incorporating dropout layers in neural networks can
    improve model robustness and reduce overfitting. Regularization can help in reducing
    the memorization of training instances, making it harder for attackers to infer
    membership.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正则化和dropout**：应用L1或L2正则化技术，并在神经网络中引入dropout层可以提高模型的鲁棒性并减少过拟合。正则化有助于减少训练实例的记忆，使得攻击者更难推断成员身份。'
- en: '**Model compression**: When sharing models or making predictions, consider
    using model compression techniques to reduce the amount of information leaked
    about the training data. Techniques such as quantization, pruning, or knowledge
    distillation can help reduce the model’s sensitivity to the training set.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型压缩**：在共享模型或进行预测时，考虑使用模型压缩技术以减少关于训练数据的泄露信息量。例如，量化、剪枝或知识蒸馏等技术可以帮助降低模型对训练集的敏感性。'
- en: '**Ensemble methods**: Training an ensemble of multiple models with different
    architectures or using different algorithms can make it more difficult for attackers
    to perform accurate membership inference. Ensemble methods make it harder for
    an attacker to learn the specific patterns in the training data.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成方法**：通过训练具有不同架构或使用不同算法的多个模型，可以使得攻击者更难执行准确的成员推理。集成方法使得攻击者更难学习训练数据中的特定模式。'
- en: '**Secure aggregation**: If the model is trained using a distributed setting,
    secure aggregation protocols can be employed to ensure that individual contributions
    from different parties are protected and the membership information is not exposed.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全聚合**：如果模型是在分布式环境中训练的，可以使用安全聚合协议来确保不同各方贡献的个体信息得到保护，并且成员信息不会被泄露。'
- en: '**Randomized response**: Randomized response techniques can be used to introduce
    noise into the model’s outputs during inference, making it harder for an attacker
    to determine membership status. Randomized response mechanisms ensure plausible
    deniability for individual records.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机响应**：在推理过程中，可以使用随机响应技术向模型输出引入噪声，使攻击者更难确定成员资格状态。随机响应机制确保了个人记录的可信否认性。'
- en: '**Access control and authorization**: Implementing access control measures
    and strong authorization mechanisms can help restrict access to sensitive models
    and data, limiting the exposure to potential attackers.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**访问控制和授权**：实施访问控制措施和强大的授权机制可以帮助限制对敏感模型和数据的访问，减少潜在攻击者的暴露。'
- en: '**Model monitoring**: Continuously monitoring the model’s behavior for any
    unusual patterns or unexpected outputs can help detect potential membership inference
    attacks. Monitoring can involve techniques such as outlier detection, adversarial
    robustness checks, or statistical analysis of model outputs.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型监控**：持续监控模型的行为，以检测任何异常模式或意外的输出，有助于检测潜在的成员推断攻击。监控可能涉及异常检测、对抗鲁棒性检查或模型输出的统计分析等技术。'
- en: It’s important to note that no single technique can provide complete protection
    against membership inference attacks. A combination of multiple techniques and
    a comprehensive approach to privacy and security is usually required to effectively
    mitigate these attacks.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，没有单一的技术可以提供对成员推断攻击的完全保护。通常需要结合多种技术和对隐私和安全的全面方法来有效地减轻这些攻击。
- en: Model extraction attack
  id: totrans-392
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型提取攻击
- en: A model extraction attack is a type of black-box attack in which the adversary
    aims to extract information, and possibly recreate a model, by creating a substitute
    model (denoted as *𝑓*’) that closely emulates the behavior of the original model
    being targeted (denoted as *𝑓*).
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 模型提取攻击是一种黑盒攻击，其中攻击者通过创建一个替代模型（表示为 *𝑓*’），该模型紧密模拟被针对的原始模型（表示为 *𝑓*）的行为，旨在提取信息，并可能重新创建模型。
- en: Let’s consider a scenario where we have developed an ML model specifically designed
    to predict whether a given post/tweet pertains to a disaster or not. We provide
    APIs to consumers, enabling them to access these prediction capabilities, and
    charge a fee for each API request made.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个场景，即我们开发了一个专门用于预测给定帖子/推文是否与灾难相关的机器学习模型。我们向消费者提供API，使他们能够访问这些预测功能，并对每个API请求收费。
- en: '![Figure 2.10 - Securing ML Model Integrity](img/B16573_02_10.jpg)'
  id: totrans-395
  prefs: []
  type: TYPE_IMG
  zh: '![图2.10 - 保护机器学习模型完整性](img/B16573_02_10.jpg)'
- en: Figure 2.10 - Securing ML Model Integrity
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10 - 保护机器学习模型完整性
- en: The adversary takes advantage of the API provided and systematically submits
    thousands of input tweets in order to obtain their respective predictions. Subsequently,
    the adversary proceeds to construct a new ML model using these tweets, which were
    obtained by querying the API exposed by the original author. The predicted results
    obtained from the API serve as the class labels for this new model, indicating
    whether the tweets are classified as disaster-related or not.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 对手利用提供的API，系统地提交数千条输入推文以获取相应的预测。随后，对手继续构建一个新的机器学习模型，这些推文是通过查询原始作者暴露的API获得的。从API获得的预测结果作为新模型的类别标签，指示推文是否被分类为与灾难相关。
- en: '![Figure 2.11 – Model extraction attack—adversary ML model](img/B16573_02_11.jpg)'
  id: totrans-398
  prefs: []
  type: TYPE_IMG
  zh: '![图2.11 – 模型提取攻击—对手的机器学习模型](img/B16573_02_11.jpg)'
- en: Figure 2.11 – Model extraction attack—adversary ML model
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.11 – 模型提取攻击—对手的机器学习模型
- en: In certain instances, the ML model developed by the adversary may exhibit superior
    accuracy compared to the original author’s ML model. As a consequence, this can
    significantly affect the revenue of the original author’s company. The adversary
    may exploit this advantage by exposing similar inference APIs, charging substantially
    lower fees than the original author, and potentially engaging in the theft of
    intellectual property. Furthermore, the model extraction attack enables the adversary
    to gain access to private information associated with the ML model, further exacerbating
    the potential damages caused.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，对手开发的机器学习模型可能比原始作者的机器学习模型具有更高的准确性。因此，这可能会严重影响原始作者公司的收入。对手可能通过公开类似的推理API，收取比原始作者低得多的费用，并可能涉及知识产权的盗窃。此外，模型提取攻击使对手能够访问与机器学习模型相关的私人信息，进一步加剧了可能造成的损害。
- en: Example of a model extraction attack
  id: totrans-401
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型提取攻击的示例
- en: The source code for this example can be found in `Model` `Extraction_Attack
    Example.ipynb`.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 本例的源代码可以在`Model` `Extraction_Attack Example.ipynb`中找到。
- en: In this example, we start by creating a sample dataset that consists of two
    features (*X*) and their corresponding labels (*y*). Subsequently, we train a
    logistic regression model on this dataset using the `LogisticRegression` class
    from scikit-learn.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们首先创建一个包含两个特征(*X*)及其对应标签(*y*)的样本数据集。随后，我们使用scikit-learn的`LogisticRegression`类在这个数据集上训练逻辑回归模型。
- en: The attacker’s code aims to execute a model extraction attack by training a
    new `LogisticRegression` model (`extracted_model`) on the same dataset. The attacker’s
    objective is to replicate the original model’s behavior without having direct
    access to its internal workings.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者的代码旨在通过在相同的数据集上训练一个新的`LogisticRegression`模型(`extracted_model`)来执行模型提取攻击。攻击者的目标是复制原始模型的行为，而不直接访问其内部工作原理。
- en: Once the extracted model is successfully generated, it can be utilized for unauthorized
    purposes, such as making predictions on new data (`new_data`) without requiring
    access to the original model. This unauthorized usage raises concerns regarding
    the security and integrity of the original model’s functionality.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提取的模型成功生成，它可以被用于未经授权的目的，例如在新数据(`new_data`)上做出预测，而无需访问原始模型。这种未经授权的使用引发了关于原始模型功能安全和完整性的担忧。
- en: 'The following is the source code for the model extraction attack (`Model` `Extraction_Attack
    Example.ipynb`):'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为模型提取攻击编写的源代码(`Model` `Extraction_Attack Example.ipynb`)：
- en: '[PRE17]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Techniques to mitigate model extraction attacks
  id: totrans-408
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 减缓模型提取攻击的技术
- en: Mitigating model extraction attacks, where an adversary tries to extract the
    underlying model’s architecture, parameters, or functionality, is crucial for
    protecting intellectual property and maintaining the security of sensitive models.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解模型提取攻击，即对手试图提取底层模型的架构、参数或功能，对于保护知识产权和维护敏感模型的安全至关重要。
- en: 'Some of the techniques to mitigate model extraction attacks are as follows:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 减缓模型提取攻击的一些技术如下：
- en: '**Model watermarking**: Embedding a unique watermark into the model’s parameters
    or architecture can help identify the origin of the model and deter unauthorized
    extraction. Watermarking techniques can be designed to be resilient against removal
    attempts or modifications while remaining imperceptible to normal model operations.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型水印**: 将一个独特的水印嵌入模型的参数或架构中，可以帮助识别模型的来源并阻止未经授权的提取。水印技术可以设计成对移除尝试或修改具有抵抗力，同时在正常模型操作中保持不可察觉。'
- en: '**Model obfuscation**: Applying obfuscation techniques to the model’s code
    or architecture can make it harder for attackers to understand the internal workings
    of the model. Obfuscation can involve techniques such as code obfuscation, function
    renaming, control flow diversification, or encryption to protect the model’s implementation
    details.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型混淆**: 对模型的代码或架构应用混淆技术可以使攻击者更难理解模型的内部工作原理。混淆可能涉及代码混淆、函数重命名、控制流多样化或加密等技术，以保护模型的实现细节。'
- en: '**Secure model sharing**: When sharing models with authorized users or collaborators,
    it’s important to employ secure sharing mechanisms. This can involve encryption
    during transit and at rest, strong access control measures, and secure authentication
    and authorization protocols to prevent unauthorized access to the model.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全模型共享**: 当与授权用户或合作者共享模型时，重要的是要采用安全的共享机制。这可能包括在传输和静止状态下的加密、强大的访问控制措施以及安全的身份验证和授权协议，以防止对模型的未经授权访问。'
- en: '**Model compression**: Using model compression techniques such as quantization,
    pruning, or knowledge distillation can make the model more compact and reduce
    the amount of information that can be extracted. Compressed models often have
    fewer parameters and structural details, making them more resistant to model extraction
    attacks.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型压缩**: 使用量化、剪枝或知识蒸馏等模型压缩技术可以使模型更加紧凑，并减少可以提取的信息量。压缩模型通常具有更少的参数和结构细节，这使得它们对模型提取攻击更具抵抗力。'
- en: '**Fine-grained access control**: Implementing fine-grained access control mechanisms
    can limit the exposure of sensitive models. This can involve providing access
    to only the necessary components or functionalities of the model based on user
    roles and permissions.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**细粒度访问控制**：实施细粒度访问控制机制可以限制敏感模型的暴露。这可能包括根据用户角色和权限仅提供对模型必要组件或功能的访问。'
- en: '**Secure execution environment**: Running the model in a secure execution environment
    can help protect against extraction attacks. Techniques such as secure enclaves
    (e.g., Intel SGX or AMD SEV), **trusted execution environments** (**TEEs**), and
    **secure multiparty computation** (**MPC**) can provide isolation and integrity
    guarantees for executing models, preventing unauthorized access to the model’s
    internals. We will learn more about TEE in [*Chapter 9*](B16573_09.xhtml#_idTextAnchor204).'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全执行环境**：在安全的执行环境中运行模型可以帮助防止提取攻击。例如，安全区域（如英特尔SGX或AMD SEV）、**可信执行环境**（**TEEs**）和**安全多方计算**（**MPC**）等技术可以为执行模型提供隔离和完整性保证，防止未经授权访问模型的内部信息。我们将在[*第9章*](B16573_09.xhtml#_idTextAnchor204)中了解更多关于TEE的内容。'
- en: '**Model metadata protection**: Protecting the metadata associated with the
    model, such as the training data, hyperparameters, or training process details,
    can make it harder for attackers to extract meaningful information about the model.
    Techniques such as differential privacy or data perturbation can help preserve
    privacy in model metadata.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型元数据保护**：保护与模型相关的元数据，如训练数据、超参数或训练过程细节，可以使攻击者更难提取有关模型的有意义信息。例如，差分隐私或数据扰动等技术可以帮助在模型元数据中保持隐私。'
- en: '**Monitoring for abnormal model usage**: Implementing model monitoring and
    anomaly detection mechanisms can help identify suspicious activities, such as
    repeated queries or excessive model interactions, which could indicate unauthorized
    extraction attempts. Monitoring can trigger alerts or initiate defensive actions
    when potential attacks are detected.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控异常模型使用**：实施模型监控和异常检测机制可以帮助识别可疑活动，如重复查询或过度模型交互，这可能表明未经授权的提取尝试。当检测到潜在攻击时，监控可以触发警报或启动防御行动。'
- en: '**Legal and licensing measures**: Implementing legal protections, such as copyright,
    patent, or licensing agreements, can provide additional legal recourse and deter
    unauthorized model extraction and usage.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**法律和许可措施**：实施法律保护，如版权、专利或许可协议，可以提供额外的法律救济并阻止未经授权的模型提取和使用。'
- en: As we discussed with the membership inference attack, it’s important to note
    that no single technique can provide complete protection against model extraction
    attacks; a combination of multiple techniques is usually required. The choice
    of mitigation techniques depends on the specific threat model, the sensitivity
    of the model, and the desired level of protection.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论的成员推理攻击，需要注意的是，没有单一的技术可以提供对模型提取攻击的完全保护；通常需要多种技术的组合。缓解技术的选择取决于具体的威胁模型、模型敏感性以及所需的保护水平。
- en: 'We have learned about membership inference attacks and model extraction attacks
    on ML models. Let’s now explore the third type of privacy attack on ML models:
    the reconstruction attack.'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了针对机器学习模型的成员推理攻击和模型提取攻击。现在让我们探索机器学习模型的第三种隐私攻击：重建攻击。
- en: Reconstruction attacks—model inversion attacks
  id: totrans-422
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重建攻击——模型反转攻击
- en: Reconstruction attacks try to recreate one or more instances of training data
    and/or their respective class labels. The reconstruction may be partial or full,
    depending on the strength of the original model. A fully successful attack can
    generate more realistic training data and various samples to match exact class
    label predictions.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 重建攻击试图重建一个或多个训练数据实例及其相应的类标签。重建可能是部分或完整的，这取决于原始模型的力量。一次完全成功的攻击可以生成更真实的训练数据和各种样本，以匹配精确的类标签预测。
- en: Model inversion or attribute inference are kinds of reconstruction attacks.
    They come under the black-box attack category because the attacker doesn’t need
    to know the details of the model’s structure or internal workings. They only need
    access to the model’s output based on some input data. Using that, they can infer
    details about the data used to train the model.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 模型反转或属性推理都是重建攻击的一种。它们属于黑盒攻击类别，因为攻击者不需要了解模型结构的细节或内部工作原理。他们只需要根据一些输入数据访问模型的输出。利用这一点，他们可以推断出用于训练模型的数据的详细信息。
- en: A step-by-step example of creating a model inversion attack
  id: totrans-425
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建模型反转攻击的逐步示例
- en: In this example, we first create a simple dataset with two input features (`X`)
    and binary labels (`y`). We train a logistic regression model using this dataset.
    The `model_inversion_attack` function attempts to invert the model by finding
    an input that produces the desired output probability.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们首先创建一个包含两个输入特征（`X`）和二进制标签（`y`）的简单数据集。我们使用此数据集训练一个逻辑回归模型。`model_inversion_attack`
    函数试图通过找到产生所需输出概率的输入来反转模型。
- en: Please note that this is a basic example to illustrate the concept of model
    inversion attacks. In real-world scenarios, model inversion attacks can be more
    complex and require sophisticated techniques to handle larger and more complex
    models.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这是一个基本示例，用于说明模型反转攻击的概念。在实际场景中，模型反转攻击可能更加复杂，需要更高级的技术来处理更大和更复杂的模型。
- en: 'The full source code can be found in `Model_Inversion_LR_Sample.ipynb`:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的源代码可以在 `Model_Inversion_LR_Sample.ipynb` 中找到：
- en: '[PRE18]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Let’s explore a more complex example to understand model inversion attacks.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一个更复杂的例子来理解模型反转攻击。
- en: Model inversion attacks in neural networks
  id: totrans-431
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络中的模型反转攻击
- en: Neural networks are a class of ML models inspired by the structure and functioning
    of the human brain. They are designed to recognize complex patterns and relationships
    in data. Neural networks consist of interconnected layers of artificial neurons,
    known as nodes or units, which collectively form a network.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是一类受人类大脑结构和功能启发的机器学习模型。它们被设计用来识别数据中的复杂模式和关系。神经网络由相互连接的人工神经元层组成，称为节点或单元，共同形成一个网络。
- en: Each neuron receives input signals, applies a mathematical operation to them,
    and produces an output signal. These signals are passed through the network, with
    weights assigned to the connections between neurons determining the strength of
    the signal. Neural networks are trained using a process called backpropagation,
    which adjusts the weights based on the errors between predicted and actual outputs.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 每个神经元接收输入信号，对它们应用数学运算，并产生输出信号。这些信号通过网络传递，神经元之间的连接权重决定了信号的强度。神经网络通过称为反向传播的过程进行训练，该过程根据预测输出和实际输出之间的误差调整权重。
- en: The hidden layers of a neural network enable it to learn and represent intricate
    nonlinear relationships in the data, making it capable of solving highly complex
    tasks such as image and speech recognition, natural language processing, and even
    playing games. Popular neural network architectures include feedforward neural
    networks, **convolutional neural networks** (**CNNs**), and **recurrent neural**
    **networks** (**RNNs**).
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的隐藏层使其能够学习并表示数据中的复杂非线性关系，使其能够解决高度复杂的问题，如图像和语音识别、自然语言处理，甚至玩游戏。流行的神经网络架构包括前馈神经网络、**卷积神经网络**（**CNNs**）和**循环神经网络**（**RNNs**）。
- en: Neural networks have achieved remarkable success in various fields, demonstrating
    state-of-the-art performance in many domains. They have become a fundamental tool
    in machine learning and continue to advance the boundaries of artificial intelligence
    by enabling sophisticated decision-making and pattern recognition capabilities.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络在各个领域取得了显著的成功，在许多领域展示了最先进的性能。它们已成为机器学习的一个基本工具，并通过实现复杂的决策和模式识别能力，继续推动人工智能的边界。
- en: We will not delve into the intricacies of neural networks, as this exceeds the
    scope of this book.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入探讨神经网络的复杂性，因为这超出了本书的范围。
- en: In this example, we will demonstrate how an adversary can generate input data
    using the output of a neural network model. The adversary’s goal is to reconstruct
    the original input that led to a specific output prediction by leveraging the
    characteristics of the model’s behavior. By reverse-engineering the relationship
    between the model’s output and the corresponding input data, the adversary can
    gain insights into the original data points used for training the model.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们将演示攻击者如何利用神经网络模型的输出生成输入数据。攻击者的目标是利用模型行为的特征，重建导致特定输出预测的原始输入。通过逆向工程模型输出与相应输入数据之间的关系，攻击者可以深入了解用于训练模型的原始数据点。
- en: '![Figure 2.12 – Neural network models of the original author and the adversary](img/B16573_02_12.jpg)'
  id: totrans-438
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.12 – 原作者和攻击者的神经网络模型](img/B16573_02_12.jpg)'
- en: Figure 2.12 – Neural network models of the original author and the adversary
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12 – 原作者和对手的神经网络模型
- en: Input data
  id: totrans-440
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 输入数据
- en: In this example, we utilize the **Modified National Institute of Standards and
    Technology** (**MNIST**) dataset to train a neural network model. The MNIST dataset
    comprises 60,000 grayscale images of handwritten single digits between 0 and 9\.
    Each image is a small square with dimensions of 28 x 28 pixels.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用 **Modified National Institute of Standards and Technology** （**MNIST**）数据集来训练一个神经网络模型。MNIST
    数据集包含 60,000 张 0 到 9 之间的手写单数字的灰度图像。每张图像都是一个 28 x 28 像素的小正方形。
- en: Original authors model
  id: totrans-442
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 原作者模型
- en: '[PRE19]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Download the dataset from Github ([https://github.com/pytorch/tutorials/blob/main/_static/mnist.pkl.gz](https://github.com/pytorch/tutorials/blob/main/_static/mnist.pkl.gz))
    and keep it in the **data/mnist** directory.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Github ([https://github.com/pytorch/tutorials/blob/main/_static/mnist.pkl.gz](https://github.com/pytorch/tutorials/blob/main/_static/mnist.pkl.gz))
    下载数据集并将其保存在 **data/mnist** 目录中。
- en: 'The full source code can be found in `Model_Inversion_Attack_Example.ipynb`.
    We are using PyTorch version 1.13.1 here:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的源代码可以在 `Model_Inversion_Attack_Example.ipynb` 中找到。这里我们使用 PyTorch 版本 1.13.1：
- en: '[PRE20]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After loading the data, you can visualize one sample image using the Matplotlib
    library and obtain its shape. Here’s the code snippet:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据后，您可以使用 Matplotlib 库可视化一个样本图像并获取其形状。以下是代码片段：
- en: '[PRE21]'
  id: totrans-449
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This results in the following output:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/B16573_02_13.jpg)'
  id: totrans-451
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16573_02_13.jpg)'
- en: '`(50000, 784) 5`'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '`(50000, 784) 5`'
- en: 'Now, convert the training samples into the tensor format in order to use the
    same in the neural network model as input:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将训练样本转换为张量格式，以便在神经网络模型中作为输入使用：
- en: '[PRE22]'
  id: totrans-454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let’s build a simple sequential neural network model with linear layers using
    **rectified linear unit** (**ReLU**) as an activation function:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用作为激活函数的 **rectified linear unit** （**ReLU**）构建一个简单的顺序神经网络模型：
- en: '[PRE23]'
  id: totrans-456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '`AuthorsNN` class extends the `nn.Module` class from PyTorch. This class represents
    a neural network model designed for a classification task. Here’s a breakdown
    of the preceding code and its functionality:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: '`AuthorsNN` 类扩展了 PyTorch 的 `nn.Module` 类。此类代表一个用于分类任务的神经网络模型。以下是前面代码及其功能的分解：'
- en: '**The AuthorsNN class**: This class represents the neural network model designed
    by the author(s). It inherits from the **nn.Module** class, which is the base
    class for all neural network modules in PyTorch.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**The AuthorsNN 类**：此类代表作者（们）设计的神经网络模型。它继承自 PyTorch 中所有神经网络模块的基类 **nn.Module**。'
- en: '**The __init__ method**: This method is the constructor of the **AuthorsNN**
    class and is called when an instance of the class is created. Inside this method,
    the architecture of the model is defined:'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**__init__ 方法**：此方法是 **AuthorsNN** 类的构造函数，在创建类的实例时被调用。在此方法内部，定义了模型的架构：'
- en: '**self.first_sec** is a sequential module consisting of two layers:'
  id: totrans-460
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**self.first_sec** 是一个由两个层组成的顺序模块：'
- en: '**nn.Linear(784, 450)** represents a linear layer with 784 input features and
    450 output features.'
  id: totrans-461
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.Linear(784, 450)** 代表一个具有 784 个输入特征和 450 个输出特征的线性层。'
- en: '**nn.ReLU()** applies the ReLU activation function to introduce non-linearity.'
  id: totrans-462
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.ReLU()** 应用 ReLU 激活函数以引入非线性。'
- en: '**self.second_sec** is another sequential module consisting of three layers:'
  id: totrans-463
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**self.second_sec** 是另一个由三个层组成的顺序模块：'
- en: '**nn.Linear(450, 450)** represents a linear layer with 450 input features and
    450 output features.'
  id: totrans-464
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.Linear(450, 450)** 代表一个具有 450 个输入特征和 450 个输出特征的线性层。'
- en: '**nn.ReLU()** applies the ReLU activation function.'
  id: totrans-465
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.ReLU()** 应用 ReLU 激活函数。'
- en: '**nn.Linear(450, 10)** represents a linear layer with 450 input features and
    10 output features, corresponding to the number of classes.'
  id: totrans-466
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.Linear(450, 10)** 代表一个具有 450 个输入特征和 10 个输出特征的线性层，对应于类别的数量。'
- en: '**nn.Softmax(dim=-1)** applies the softmax activation function to convert the
    raw output scores into probabilities, ensuring they sum to **1** across classes.'
  id: totrans-467
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nn.Softmax(dim=-1)** 将原始输出分数应用 softmax 激活函数转换为概率，确保它们在各个类别中总和为 **1**。'
- en: '**The forward method**: This method defines the forward pass of the model,
    specifying how input data flows through the network. The input, **x**, is passed
    through **self.first_sec**, followed by **self.second_sec**, and the resulting
    output is returned.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前向方法**：此方法定义了模型的前向传递，指定输入数据如何通过网络。输入 **x** 通过 **self.first_sec**，然后是 **self.second_sec**，最终返回输出结果。'
- en: 'The following code creates an instance of the `AuthorsNN` class named `auth_nn`.
    This instance represents the initialized neural network model:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码创建了一个名为`auth_nn`的`AuthorsNN`类实例。此实例代表初始化的神经网络模型：
- en: '[PRE24]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Printing `auth_nn` will display information about the model, such as its architecture
    and the number of trainable parameters:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 打印`auth_nn`将显示有关模型的信息，例如其架构和可训练参数的数量：
- en: '[PRE25]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, we define a loss function in order to measure the error between the actual
    data versus the predicted data:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个损失函数来衡量实际数据与预测数据之间的误差：
- en: '[PRE26]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: To enhance the network, let’s add the Adam optimizer function. This is an optimization
    algorithm that replaces **stochastic gradient descent** (**SGD**) for training
    DL models.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增强网络，让我们添加Adam优化器函数。这是一个优化算法，用于替换训练深度学习模型时使用的**随机梯度下降**（**SGD**）。
- en: 'It combines the desirable aspects of the `AdaGrad` and `RMSProp` algorithms,
    making it suitable for handling sparse gradients in noisy problem scenarios:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 它结合了`AdaGrad`和`RMSProp`算法的优点，使其适合处理噪声问题场景中的稀疏梯度：
- en: '[PRE27]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Here, we import the `optim` module from PyTorch. After instantiating the `AuthorsNN`
    class, we define the Adam optimizer using the `optim.Adam()` function. The optimizer
    is initialized with the model’s parameters (`auth_nn.parameters()`), enabling
    it to optimize the model during training.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们从PyTorch中导入`optim`模块。在实例化`AuthorsNN`类之后，我们使用`optim.Adam()`函数定义Adam优化器。优化器使用模型的参数（`auth_nn.parameters()`）初始化，使其能够在训练过程中优化模型。
- en: 'Next, print `optimizer` to provide details about the model’s optimizer’s configuration:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，打印`optimizer`以提供有关模型优化器配置的详细信息：
- en: '[PRE28]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This results in the following output:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE29]'
  id: totrans-482
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, train the neural network model with the MNIST training dataset that we
    loaded earlier and wrap it in a Python function:'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用我们之前加载的MNIST训练数据集来训练神经网络模型，并将其封装在一个Python函数中：
- en: '[PRE30]'
  id: totrans-484
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Let’s break this code down:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解这段代码：
- en: '**The** **train** **function**: This function trains the neural network model
    (**ann**) for a specified number of epochs (**num_epochs**). The function assumes
    the presence of input data (**x_train**) and corresponding target labels (**y_train**)
    used for training the model. Here, **ann.train()** is called to set the model
    in training mode, enabling functionalities such as dropout and batch normalization.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**train函数**：此函数使用指定的epoch数量（**num_epochs**）训练神经网络模型（**ann**）。该函数假定存在用于训练模型的数据（**x_train**）和相应的目标标签（**y_train**）。在此，调用**ann.train()**将模型设置为训练模式，启用诸如dropout和批量归一化等功能。'
- en: '**The training loop**: For each epoch in the range of **num_epochs**, the following
    steps are executed:'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练循环**：在**num_epochs**的范围内，对每个epoch执行以下步骤：'
- en: '**output = ann(x_train)**: Forward passes through the model, obtaining the
    output predictions.'
  id: totrans-488
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**output = ann(x_train)**：通过模型进行前向传递，获得输出预测。'
- en: '**loss = loss_func(output, y_train)**: Computes the loss between the predicted
    output and the ground truth labels.'
  id: totrans-489
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**loss = loss_func(output, y_train)**：计算预测输出与真实标签之间的损失。'
- en: '**optimizer.zero_grad()**: Clears the gradients accumulated from the previous
    iteration.'
  id: totrans-490
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**optimizer.zero_grad()**：清除之前迭代累积的梯度。'
- en: '**loss.backward()**: Performs backpropagation to compute the gradients of the
    model’s parameters with respect to the loss.'
  id: totrans-491
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**loss.backward()**：执行反向传播以计算模型参数相对于损失的梯度。'
- en: '**optimizer.step()**: Updates the model’s parameters by applying the computed
    gradients using the chosen optimizer.'
  id: totrans-492
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**optimizer.step()**：通过应用计算出的梯度并使用选择的优化器来更新模型的参数。'
- en: '**print(epoch, loss.item()**): Prints the current epoch number and the **loss**
    value.'
  id: totrans-493
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**print(epoch, loss.item()**): 打印当前epoch编号和**loss**值。'
- en: 'The **pass** statement: A placeholder that does nothing in this context and
    can be removed if not needed.'
  id: totrans-494
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pass语句**：在此上下文中什么都不做的占位符，如果不需要可以删除。'
- en: 'Now, train the neural network model with the MNIST training dataset that we
    loaded earlier with the author’s neural network model, which was built in the
    previous step with `100` epochs:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用我们之前加载的MNIST训练数据集以及作者在之前步骤中构建的神经网络模型（使用`100`个epoch）来训练神经网络模型：
- en: '[PRE31]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Once the model is trained, it can be used for further predictions. Now, we will
    construct the adversary attacker model with the objective of recreating the training
    data.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，就可以用于进一步的预测。现在，我们将构建一个对抗攻击者模型，其目标是重新创建训练数据。
- en: Adversary model to get the trained input data
  id: totrans-498
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对抗模型以获取训练输入数据
- en: 'Considering that the author’s model has been trained on the MNIST dataset and
    we have access to the size `450` vector output from the model’s first section
    (`first_sec`), we can utilize this information for our attack. Next, we will develop
    our adversary model. This model takes a size `450` vector as input, which corresponds
    to the output of the target’s first section. The adversary model’s objective is
    to generate a size `784` vector, matching the size of the original input data:'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到作者的模型是在MNIST数据集上训练的，并且我们有访问模型第一部分（`first_sec`）输出的`450`向量大小，我们可以利用这些信息进行攻击。接下来，我们将开发我们的对抗模型。这个模型以一个大小为`450`的向量作为输入，这对应于目标的第一部分的输出。对抗模型的目标是生成一个大小为`784`的向量，与原始输入数据的大小相匹配：
- en: '[PRE32]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Based on the information available, the authors’ original model was trained
    on a dataset consisting of handwritten images. This knowledge provides us with
    an understanding of the model’s training data source.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 根据现有信息，作者的原模型是在包含手写图像的数据集上训练的。这一知识使我们能够理解模型的训练数据来源。
- en: To train our adversary model, we can utilize the MNIST test data. Specifically,
    we will use the first 1,000 rows of the MNIST test data to train our adversary
    model. After training, we can evaluate the accuracy of the adversary model using
    the MNIST test data ranging from the 1,000th row to the 2,000th row.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练我们的对抗模型，我们可以利用MNIST测试数据。具体来说，我们将使用MNIST测试数据的前1000行来训练我们的对抗模型。训练完成后，我们可以使用从第1000行到第2000行的MNIST测试数据来评估对抗模型的准确性。
- en: 'Let’s train the adversary model:'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们训练对抗模型：
- en: '[PRE33]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'To assess the similarity between the recreated data and the original trained
    images from the training dataset, we can utilize the Matplotlib library to visualize
    the images. By plotting the recreated image, we can determine the level of resemblance
    it holds with the original trained images:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估重建数据与训练数据集中原始训练图像之间的相似性，我们可以利用Matplotlib库来可视化图像。通过绘制重建图像，我们可以确定它与原始训练图像的相似程度：
- en: '[PRE34]'
  id: totrans-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This results in the following output:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了以下输出：
- en: '![](img/B16573_02_14.jpg)'
  id: totrans-508
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16573_02_14.jpg)'
- en: It is evident that the images generated using model inversion attacks closely
    resemble the training data. This example demonstrates the successful recreation
    of training data without requiring complete knowledge of the model details, thereby
    achieving a model inversion attack.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，使用模型反演攻击生成的图像与训练数据非常相似。这个例子展示了成功重建训练数据而不需要完全了解模型细节，从而实现了模型反演攻击。
- en: Techniques to mitigate model inversion attacks
  id: totrans-510
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 减轻模型反演攻击的技术
- en: Mitigating model inversion attacks, where an adversary tries to infer sensitive
    training data from a trained model’s outputs, is crucial for preserving privacy
    and protecting sensitive information.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 减轻模型反演攻击，即攻击者试图从训练模型的输出中推断敏感训练数据，对于保护隐私和敏感信息至关重要。
- en: 'Some techniques to mitigate model inversion attacks include the following:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 减轻模型反演攻击的一些技术包括以下内容：
- en: '**Differential privacy**: Applying differential privacy mechanisms during the
    training process can help protect against model inversion attacks. Differential
    privacy adds controlled noise to the training data or model’s outputs, making
    it harder for an attacker to extract specific sensitive information from the model’s
    predictions. We will learn more about differential privacy in the next two chapters.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**差分隐私**：在训练过程中应用差分隐私机制可以帮助抵御模型反演攻击。差分隐私通过向训练数据或模型的输出添加受控噪声，使得攻击者从模型的预测中提取特定敏感信息变得更加困难。我们将在接下来的两章中学习更多关于差分隐私的知识。'
- en: '**Limit access to sensitive output**: Restricting access to sensitive model
    output or predictions can help mitigate model inversion attacks. By carefully
    controlling who has access to the output and under what circumstances, you can
    reduce the risk of an adversary inferring sensitive training data.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**限制对敏感输出的访问**：限制对敏感模型输出或预测的访问可以帮助减轻模型反演攻击。通过仔细控制谁可以访问输出以及在什么情况下访问，可以降低攻击者推断敏感训练数据的风险。'
- en: '**Preprocessing and postprocessing**: Applying preprocessing and postprocessing
    techniques to the data and model’s output can help protect against model inversion
    attacks. For example, data anonymization, aggregation, or transformation techniques
    can be applied to remove or obfuscate sensitive information from the input or
    output. We will learn more about data anonymization and aggregation in the subsequent
    chapters.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预处理和后处理**：对数据和模型输出应用预处理和后处理技术可以帮助抵御模型反演攻击。例如，可以应用数据匿名化、聚合或转换技术来从输入或输出中移除或模糊敏感信息。我们将在后续章节中了解更多关于数据匿名化和聚合的内容。'
- en: '**Regularization**: Incorporating regularization techniques such as L1 or L2
    regularization during the model training process can help improve privacy by reducing
    the model’s reliance on specific sensitive features. Regularization can help prevent
    overfitting and limit the leakage of sensitive information through the model’s
    predictions.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正则化**：在模型训练过程中结合正则化技术，如L1或L2正则化，可以帮助通过减少模型对特定敏感特征的依赖来提高隐私性。正则化可以帮助防止过拟合并限制通过模型预测泄露的敏感信息。'
- en: '**Generative adversarial networks** (**GANs**): Using generative models such
    as GANs can help protect against model inversion attacks. By generating synthetic
    data that preserves the statistical properties of the original data, GANs can
    provide alternative output for the attacker without revealing specific sensitive
    training instances.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成对抗网络**（**GANs**）：使用生成模型，如GANs，可以帮助抵御模型反演攻击。通过生成保留原始数据统计特性的合成数据，GANs可以为攻击者提供替代输出，而不会泄露特定的敏感训练实例。'
- en: '**Secure multi-party computation** (**MPC**): Leveraging secure MPC protocols
    can enable multiple parties to collaboratively train a model while keeping their
    individual training data private. Secure MPC ensures that no party can access
    the sensitive data of others, thereby mitigating model inversion attacks.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全多方计算**（**MPC**）：利用安全MPC协议可以使多个方能够协作训练模型，同时保持各自的训练数据私密。安全MPC确保没有任何一方可以访问其他方的敏感数据，从而减轻模型反演攻击。'
- en: '**Secure aggregation**: In scenarios where models are trained using a distributed
    setting, secure aggregation protocols can be employed to prevent sensitive information
    leakage during the aggregation of model updates. This protects against model inversion
    attacks during the training process.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全聚合**：在模型使用分布式设置进行训练的情境中，可以采用安全聚合协议来防止在模型更新聚合过程中敏感信息泄露。这可以在训练过程中保护免受模型反演攻击。'
- en: '**Access control and authorization**: Implementing access control measures
    and strong authorization mechanisms can help restrict access to sensitive model
    output, limiting the exposure to potential attackers. Only authorized entities
    should have access to sensitive predictions or output.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**访问控制和授权**：实施访问控制措施和强大的授权机制可以帮助限制对敏感模型输出的访问，减少潜在攻击者的暴露。只有授权实体应有权访问敏感预测或输出。'
- en: '**Synthetic data generation**: Instead of training models directly on sensitive
    data, using synthetic data generated from the original data can help mitigate
    model inversion attacks. Synthetic data retains the statistical characteristics
    of the original data but does not expose sensitive information.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合成数据生成**：不是直接在敏感数据上训练模型，而是使用从原始数据生成的合成数据可以帮助缓解模型反演攻击。合成数据保留了原始数据的统计特性，但不会暴露敏感信息。'
- en: '**Model monitoring**: Continuously monitoring the model’s behavior for any
    unusual patterns or unexpected output can help detect potential model inversion
    attacks. Monitoring can involve techniques such as outlier detection, adversarial
    robustness checks, or statistical analysis of model predictions.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型监控**：持续监控模型的行为，寻找任何异常模式或意外输出，可以帮助检测潜在的模型反演攻击。监控可能涉及异常检测、对抗鲁棒性检查或模型预测的统计分析等技术。'
- en: Like the previous two attacks, It’s important to note that choosing mitigation
    techniques depends on the specific context, the sensitivity of the data, and the
    desired level of privacy protection. Multiple techniques can be combined to achieve
    stronger privacy guarantees against model inversion attacks.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 与前两次攻击一样，需要注意的是，选择缓解技术取决于具体情境、数据的敏感性和所需的隐私保护水平。可以将多种技术结合起来，以实现更强的隐私保障，抵御模型反演攻击。
- en: Summary
  id: totrans-524
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: To summarize, we have covered different types of ML (supervised and unsupervised)
    and explored how to save and execute models in various formats. Additionally,
    we delved into the different phases of ML (data extraction, data preparation,
    model development, model deployment, and inferencing) and discussed the privacy
    threats and attacks associated with each phase in detail.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们已经涵盖了不同类型的机器学习（监督学习和无监督学习），并探讨了如何以各种格式保存和执行模型。此外，我们还深入探讨了机器学习的不同阶段（数据提取、数据准备、模型开发、模型部署和推理），并详细讨论了与每个阶段相关的隐私威胁和攻击。
- en: In the next chapter, we will dive deeper into privacy-preserving data analysis
    and focus on understanding the concept of differential privacy. This will allow
    us to explore techniques and methodologies that ensure privacy while conducting
    data analysis tasks. By gaining a thorough understanding of differential privacy,
    we can better safeguard sensitive information and mitigate privacy risks in the
    context of ML.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更深入地探讨隐私保护数据分析，并专注于理解差分隐私的概念。这将使我们能够探索确保在执行数据分析任务时保持隐私的技术和方法。通过全面理解差分隐私，我们可以更好地保护敏感信息并减轻机器学习环境中的隐私风险。
