- en: Blend It with Stacking
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与堆叠结合
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下食谱：
- en: Understanding stacked generalization
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解堆叠泛化
- en: Implementing stacked generalization by combining the predictions
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过结合预测实现堆叠泛化
- en: Implementing stacked generalization for marketing campaign outcome prediction
    using H2O
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用H2O实现营销活动结果预测的堆叠泛化
- en: Technical requirements
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The technical requirements for this chapter remain the same as those we detailed
    in earlier chapters.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的技术要求与我们在早期章节中详细说明的要求相同。
- en: Visit the GitHub repository to find the dataset and the code. The datasets and
    code files are arranged according to chapter numbers, and by the name of the topic.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 访问GitHub仓库以查找数据集和代码。数据集和代码文件按章节编号和主题名称排列。
- en: Understanding stacked generalization
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解堆叠泛化
- en: 'Stacked generalization is an ensemble of a diverse group of models that introduces
    the concept of a meta-learner. A meta-learner is a second-level machine learning
    algorithm that learns from an optimal combination of base learners:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠泛化是一组多样化的模型的集成，引入了元学习器的概念。元学习器是一个第二级机器学习算法，它从基础学习器的最优组合中学习：
- en: '"Stacked generalization is a means of non-linearly combining generalizers to
    make a new generalizer, to try to optimally integrate what each of the original
    generalizers has to say about the learning set. The more each generalizer has
    to say (which isn''t duplicated in what the other generalizers have to say), the
    better the resultant stacked generalization."'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '"堆叠泛化是一种非线性组合泛化器以创建一个新的泛化器的方法，试图最优地整合每个原始泛化器对学习集的看法。每个泛化器有更多的话要说（这不会在其他泛化器的话中重复），结果堆叠泛化就越好。"'
- en: - Wolpert (1992)*,* Stacked Generalization
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: - Wolpert (1992)*,* 堆叠泛化
- en: 'The steps for stacking are as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠的步骤如下：
- en: Split your dataset into a training set and a testing set.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的数据集分为训练集和测试集。
- en: Train several base learners on the training set.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上训练几个基础学习器。
- en: Apply the base learners on the testing set to make predictions.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将基础学习器应用于测试集进行预测。
- en: Use the predictions as inputs and the actual responses as outputs to train a
    higher-level learner.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用预测作为输入，实际响应作为输出来训练一个高级学习器。
- en: Because the predictions from the base learners are blended together, stacking
    is also referred to as blending.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于基础学习器的预测被混合在一起，堆叠也被称为混合。
- en: 'The following diagram gives us a conceptual representation of stacking:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表为我们提供了堆叠的概念表示：
- en: '![](img/addebcb4-b1e7-44d6-ad30-af0d0ddefebf.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/addebcb4-b1e7-44d6-ad30-af0d0ddefebf.png)'
- en: It's of significance for stack generalization that the predictions from the
    base learners are not correlated with each other. In order to get uncorrelated
    predictions from the base learners, algorithms that use different approaches internally
    may be used to train the base learners. Stacked generalization is used mainly
    for minimizing the generalization error of the base learners, and can be seen
    as a refined version of cross-validation. It uses a strategy that's more sophisticated
    than cross-validation's **winner-takes-all** approach for combining the predictions
    from the base learners.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于堆叠泛化来说，基础学习器的预测之间不相关是很重要的。为了从基础学习器中获得不相关的预测，可以使用内部采用不同方法的算法来训练基础学习器。堆叠泛化主要用于最小化基础学习器的泛化误差，可以看作是交叉验证的改进版本。它使用比交叉验证的**赢家通吃**方法更复杂的策略来结合基础学习器的预测。
- en: Implementing stacked generalization by combining predictions
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过结合预测实现堆叠泛化
- en: In this section, we'll look at how to implement stacked generalization from
    scratch.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨如何从头实现堆叠泛化。
- en: 'We will carry out the following steps to get started:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将执行以下步骤以开始：
- en: Build three base learners for stacking.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为堆叠构建三个基础学习器。
- en: Combine the predictions from each of the base learners.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结合每个基础学习器的预测。
- en: Build the meta-learner using another algorithm.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用另一种算法构建元学习器。
- en: Getting ready...
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备中...
- en: In this example, we use a dataset from the UCI ML Repository on credit card
    defaults. This dataset contains information on default payments, demographic factors,
    credit data, history of payments, and bill statements of credit card clients.
    The data and the data descriptions are provided in the GitHub.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用UCI ML存储库中的信用卡违约数据集。该数据集包含关于违约支付、人口统计因素、信用数据、支付历史和信用卡客户的账单陈述的信息。数据和数据描述在GitHub上提供。
- en: 'We will start by loading the required libraries and reading our dataset:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先加载所需的库并读取我们的数据集：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We set our working folder as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将工作文件夹设置为以下内容：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s now read our data. We will prefix the DataFrame name with `df_` so that
    we can understand it easily:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们读取我们的数据。我们将以`df_`作为DataFrame名称的前缀，这样我们就可以轻松理解它：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We drop the `ID` column, as this isn''t required:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们删除了`ID`列，因为这个列不是必需的：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We check the shape of the dataset:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查数据集的形状：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We notice that the dataset now has 30,000 observations and 24 columns. Let's
    now move on to training our models.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到数据集现在有30,000个观测值和24列。现在让我们继续训练我们的模型。
- en: How to do it...
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'We split our target and feature variables:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们分割目标和特征变量：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Split the data into training, validation, and testing subsets:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分割为训练、验证和测试子集：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Check the dimensions of each subset to ensure that our splits are correct:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查每个子集的维度以确保我们的分割是正确的：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Import the required libraries for the base learners and the meta-learner:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入基础学习器和元学习器所需的库：
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Create instances of the base learners and fit the model on our training data:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建基础学习器的实例并在我们的训练数据上拟合模型：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Use the base learners on our validation subset to make predictions:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们的验证子集上的基础学习器进行预测：
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We have three sets of prediction results from three base learners. We use them
    to create a stacked array:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从三个基础学习器获得了三组预测结果。我们使用它们来创建堆叠数组：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We convert the `final_train_stack` stacked array to a DataFrame and add column
    names to each of the columns. Verify the dimensions and take a look at the first
    few rows:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将`final_train_stack`堆叠数组转换为DataFrame并为每个列添加列名。验证维度并查看前几行：
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In the following image, we see that the stacked array now has 5,400 observations
    and 4 columns:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图像中，我们看到堆叠数组现在有5,400个观测值和4列：
- en: '![](img/56917bad-d1a0-46f2-9aef-12025ce62841.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/56917bad-d1a0-46f2-9aef-12025ce62841.png)'
- en: 'Train the meta-learner using the stacked array that we created in *Step 8*:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们在*步骤 8*中创建的堆叠数组来训练元学习器：
- en: '[PRE13]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create the stacked test set with the testing subset:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用测试子集创建堆叠测试集：
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Convert the `final_test_stack` stacked array to a DataFrame and add column
    names to each of the columns. Verify the dimensions and take a look at the first
    few rows:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`final_test_stack`堆叠数组转换为DataFrame并为每个列添加列名。验证维度并查看前几行：
- en: '[PRE15]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We see that the stacked array now has 3,000 observations and 3 columns in `stacked_test_dataframe`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到`stacked_test_dataframe`中的堆叠数组现在有3,000个观测值和3列：
- en: '![](img/26e39687-b793-40a5-85a8-4b9d6989a2a0.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/26e39687-b793-40a5-85a8-4b9d6989a2a0.png)'
- en: 'Check the accuracy of `base_learner` on our original test data:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查`base_learner`在我们原始测试数据上的准确率：
- en: '[PRE16]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We notice that the accuracy is as follows. Note that based on the sampling
    strategy and hyperparameters, the results may vary:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到准确率如下。请注意，根据采样策略和超参数，结果可能会有所不同：
- en: '![](img/587145bc-00ad-429b-a493-115eb20bacc3.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/587145bc-00ad-429b-a493-115eb20bacc3.png)'
- en: 'Use the meta-learner on the stacked test data and check the accuracy:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在堆叠测试数据上使用元学习器并检查准确率：
- en: '[PRE17]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We see the following output returned by the meta-learner applied on the stacked
    test data. This accuracy is higher than the individual base learners:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到元学习器在堆叠测试数据上应用后返回的以下输出。这个准确率高于单个基础学习器：
- en: '![](img/23f76ead-80a5-407b-a4cd-ccf09120bfc5.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/23f76ead-80a5-407b-a4cd-ccf09120bfc5.png)'
- en: How it works...
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In *Step 1*, we split our dataset into target and feature sets. In *Step 2*,
    we created our training, validation, and testing subsets. We took a look at the
    dimensions of each of the subset in *Step 3* to verify that the splits were done
    correctly.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 1*中，我们将数据集分为目标和特征集。在*步骤 2*中，我们创建了我们的训练、验证和测试子集。在*步骤 3*中，我们检查了每个子集的维度，以验证分割是否正确。
- en: We then moved on to building our base learners and the meta-learner. In *Step
    4*, we imported the required libraries for the base learners and the meta-learner.
    For the base learners, we used Gaussian Naive Bayes, KNN, and a decision tree,
    while for the meta-learner we used logistic regression.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们继续构建基础学习器和元学习器。在*步骤 4*中，我们导入了用于基础学习器和元学习器的必需库。对于基础学习器，我们使用了高斯朴素贝叶斯、KNN和决策树，而对于元学习器，我们使用了逻辑回归。
- en: In *Step 5*, we fitted the base learners to our train dataset. Single models,
    including Gaussian Naive Bayes, KNN, and a decision tree, are established in the
    level 0 space. We then had three base models.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 5*中，我们将基础学习器拟合到我们的训练数据集。包括高斯朴素贝叶斯、KNN和决策树在内的单一模型在0层空间中建立。然后我们有了三个基础模型。
- en: In *Step 6*, we used these three base models on our validation subset to predict
    the target variable. We then had three sets of predictions given by the respective
    base learners.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 6*中，我们使用这三个基础模型在我们的验证子集中预测目标变量。然后我们得到了基础学习器给出的三组预测。
- en: 'Now the base learners will be integrated by logistic regression in the level
    1 space via stacked generalization. In *Step 7*, we stacked the three sets of
    predicted values to create an array. We also stacked the actual target variable
    of our training dataset to the array. We then had four columns in our array: three
    columns from the three sets of predicted values of the base learners and a fourth
    column from the target variable of our training dataset. We called it `final_train_stack` known
    as `stacked_train_dataframe`, and we named the columns according to the algorithm
    used for the base learners. In our case, we used the names `NB_VAL`, `KNN_VAL`,
    and `DT_VAL` since we used Gaussian Naive Bayes, KNN, and a decision tree classifier,
    respectively. Because the base learners are fitted to our validation subset, we
    suffixed the column names with `_VAL` to make them easier to understand.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将通过堆叠泛化在第一层空间中将基础学习器通过逻辑回归进行集成。在*步骤 7*中，我们将三组预测值堆叠起来创建了一个数组。我们还把训练数据集的实际目标变量也堆叠到数组中。然后我们的数组中有四列：三列来自基础学习器的三组预测值，以及一列来自训练数据集的目标变量。我们称之为`final_train_stack`，也称为`stacked_train_dataframe`，并且根据用于基础学习器的算法命名列。在我们的例子中，我们使用了`NB_VAL`、`KNN_VAL`和`DT_VAL`这些名称，因为我们分别使用了高斯朴素贝叶斯、KNN和决策树分类器。因为基础学习器被拟合到我们的验证子集中，所以我们给列名加上`_VAL`后缀，以便更容易理解。
- en: In *Step 9*, we built the meta-learner with logistic regression and fitted it
    to our stacked dataset, `stacked_train_dataframe`. Notice that we moved away from
    our original dataset to a stacked dataset, which contains the predicted values
    from our base learners.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 9*中，我们使用逻辑回归构建了元学习器并将其拟合到我们的堆叠数据集`stacked_train_dataframe`。请注意，我们离开了原始数据集，转向了一个包含基础学习器预测值的堆叠数据集。
- en: In *Step 10*, we used the base models on our test subset to get the predicted
    results. We called it `final_test_stack`. In *Step 11*, we converted the `final_test_stack`
    array to a DataFrame called `stacked_test_dataframe`. Note that in our `stacked_test_dataframe`,
    we only had three columns, which held the predicted values returned by the base
    learners applied on our test subset. The three columns were named after the algorithm
    used, suffixed with `_TEST`, so we have `NB_TEST`, `KNN_TEST`, and `DT_TEST` as
    the three columns in `stacked_test_dataframe`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 10*中，我们使用基础模型在我们的测试子集中获取预测结果。我们称之为`final_test_stack`。在*步骤 11*中，我们将`final_test_stack`数组转换为名为`stacked_test_dataframe`的DataFrame。请注意，在我们的`stacked_test_dataframe`中，我们只有三列，这些列包含了在测试子集上应用基础学习器返回的预测值。这三列以使用的算法命名，后缀为`_TEST`，因此`stacked_test_dataframe`中的三列是`NB_TEST`、`KNN_TEST`和`DT_TEST`。
- en: In *Step 12*, we checked the accuracy of the base models on our original test
    subset. The Gaussian Naive Bayes, KNN, and decision tree classifier models gave
    us accuracy ratings of 0.39, 0.69, and 0.73, respectively.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 12*中，我们检查了基础模型在我们原始测试子集中的准确性。高斯朴素贝叶斯、KNN和决策树分类器模型分别给出了0.39、0.69和0.73的准确性评分。
- en: In *Step 13*, we checked the accuracy that we get by applying the meta-learner
    model on our stacked test data. This gave us an accuracy of 0.77, which we can
    see is higher than the individual base learners. However, bear in mind that simply
    adding more base learners to your stacking algorithm doesn't guarantee that you'll
    get better accuracy.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 13*中，我们检查了通过在堆叠测试数据上应用元学习器模型所获得的准确性。这给出了0.77的准确性，我们可以看到这比单个基础学习器的准确性要高。然而，请记住，仅仅在堆叠算法中添加更多基础学习器并不能保证你会得到更好的准确性。
- en: There's more...
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Creating a stacking model can be tedious. The `mlxtend` library provides tools
    that simplify building the stacking model. It provides StackingClassifier, which
    is the ensemble-learning meta-classifier for stacking, and it also provides StackingCVClassifier,
    which uses cross-validation to prepare the input for the second level meta-learner
    to prevent overfitting.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 创建堆叠模型可能很繁琐。`mlxtend`库提供了简化堆叠模型构建的工具。它提供了`StackingClassifier`，这是堆叠的集成学习元分类器，并且它还提供了`StackingCVClassifier`，它使用交叉验证为第二级元学习器准备输入，以防止过拟合。
- en: You can download the library from [https://pypi.org/project/mlxtend/](https://pypi.org/project/mlxtend/)
    or use the `pip install mlxtend` command to install it. You can find some great
    examples of simple stacked classification and stacked classification with grid
    search at [http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/](http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[https://pypi.org/project/mlxtend/](https://pypi.org/project/mlxtend/)下载库，或者使用`pip
    install mlxtend`命令进行安装。您可以在[http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/](http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/)找到一些简单的堆叠分类和带有网格搜索的堆叠分类的优秀示例。
- en: See also
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关内容
- en: You can also take a look at the `ML-Ensemble` library. To find out more about `ML-Ensemble`,
    visit [http://ml-ensemble.com/](http://ml-ensemble.com/). A guide to using `ML-Ensemble`
    is available at [https://bit.ly/2GFsxJN](https://bit.ly/2GFsxJN).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以查看`ML-Ensemble`库。要了解更多关于`ML-Ensemble`的信息，请访问[http://ml-ensemble.com/](http://ml-ensemble.com/)。`ML-Ensemble`的使用指南可在[https://bit.ly/2GFsxJN](https://bit.ly/2GFsxJN)找到。
- en: Implementing stacked generalization for campaign outcome prediction using H2O
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用H2O实现针对活动结果预测的堆叠泛化
- en: H2O is an open source platform for building machine learning and predictive
    analytics models. The algorithms are written on H2O's distributed map-reduce framework.
    With H2O, the data is distributed across nodes, read in parallel, and stored in
    the memory in a compressed manner. This makes H2O extremely fast.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: H2O是一个开源平台，用于构建机器学习和预测分析模型。算法是写在H2O的分布式map-reduce框架上的。使用H2O，数据在节点间分布式，并行读取，并以压缩方式存储在内存中。这使得H2O非常快。
- en: H2O's stacked ensemble method is an ensemble machine learning algorithm for
    supervised problems that finds the optimal combination of a collection of predictive
    algorithms using stacking. H2O's stacked ensemble supports regression, binary
    classification, and multiclass classification.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: H2O的堆叠集成方法是一个用于监督问题的集成机器学习算法，它通过堆叠找到一组预测算法的最佳组合。H2O的堆叠集成支持回归、二分类和多分类。
- en: In this example, we'll take a look at how to use H2O's stacked ensemble to build
    a stacking model. We'll use the bank marketing dataset which is available in the
    Github.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们将探讨如何使用H2O的堆叠集成构建堆叠模型。我们将使用可在GitHub上找到的银行营销数据集。
- en: Getting ready...
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备中...
- en: 'First, import the `h2o` library and other modules from H2O:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入`h2o`库和其他H2O模块：
- en: '[PRE18]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Initialize the `h2o` instance using the `init()` function:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`init()`函数初始化`h2o`实例：
- en: '[PRE19]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Once we run the preceding code, the `h2o` instance gets initialized and we
    will see the following output:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦运行前面的代码，`h2o`实例将被初始化，我们将看到以下输出：
- en: '![](img/ecafcf23-ff57-404b-8924-0eb395f3964f.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ecafcf23-ff57-404b-8924-0eb395f3964f.png)'
- en: Now that we have instantiated an `H2O` instance, we move onto reading our dataset
    and building stacking models.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经实例化了`H2O`实例，我们将继续读取我们的数据集并构建堆叠模型。
- en: How to do it...
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We read our data using the `h2o.import_file()` function. We pass the filename
    to the function as the parameter:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`h2o.import_file()`函数读取数据。我们将文件名作为参数传递给函数：
- en: '[PRE20]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We split our data into training and testing subsets:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将数据分为训练集和测试集：
- en: '[PRE21]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We check the dimensions of the training and testing subsets to verify that
    the splits are OK:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们检查训练集和测试集的维度，以验证分割是否正确：
- en: '[PRE22]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We take a look at the first few rows to ensure that data is loaded correctly:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们查看前几行以确保数据正确加载：
- en: '[PRE23]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We separate the target and predictor column names, which are the `response`
    and `predictors`, respectively:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将目标列和预测列的名称分别命名为`response`和`predictors`：
- en: '[PRE24]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We convert the `response` variable to a categorical type with the `asfactor()`
    function:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`asfactor()`函数将`response`变量转换为分类类型：
- en: '[PRE25]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We will train our base learners using cross-validation. We set the `nfolds` value
    to `5`.We also set a variable 'encoding' to 'OneHotExplicit'. We will use this
    variable to encode our categorical variables.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用交叉验证来训练我们的基本学习器。我们将`nfolds`值设置为`5`。我们还设置了一个变量`encoding`为`OneHotExplicit`。我们将使用此变量来对分类变量进行编码。
- en: '[PRE26]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We start training our base learners. We choose the Gradient Boosting Machine
    algorithm to build our first base learner:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们开始训练我们的基本学习器。我们选择梯度提升机算法来构建我们的第一个基本学习器：
- en: '[PRE27]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'For our second base learner, we use a Random Forest:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们的第二个基本学习器，我们使用随机森林：
- en: '[PRE28]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'For our third base learner, we implement a **Generalized Linear Model** (**GLM**):'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们的第三个基本学习器，我们实现了一个**广义线性模型**（**GLM**）：
- en: '[PRE29]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Get the best-performing base learner on the test set in terms of the `test
    AUC`. Compare this with the `test AUC` of the stacked ensemble model:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上，根据`test AUC`获取最佳性能的基本学习器。将其与堆叠集成模型的`test AUC`进行比较：
- en: '[PRE30]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We train a stacked ensemble using the base learners we built in the preceding
    steps:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用前面步骤中构建的基本学习器训练一个堆叠集成：
- en: '[PRE31]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: How it works...
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In *Step 1*, we used the `h2o.import_file()` function to read our dataset.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤1*中，我们使用了`h2o.import_file()`函数来读取我们的数据集。
- en: The `h2o.import_file()` function returns an `H2OFrame` instance.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`h2o.import_file()`函数返回一个`H2OFrame`实例。'
- en: In *Step 2*, we split our `H2OFrame` into training and testing subsets. In *Step
    3*, we checked the dimensions of these subsets to verify that our split is adequate
    for our requirements.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤2*中，我们将`H2OFrame`拆分为训练集和测试集。在*步骤3*中，我们检查了这些子集的维度，以验证我们的拆分是否满足我们的要求。
- en: In *Step 4*, we took a look at the first few rows to check if the data is correctly
    loaded. In *Step* *5*, we separated out the column names of our response and predictor
    variables, and in *Step 6*, we converted the response variables into a categorical
    type with the `asfactor()` function.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤4*中，我们查看了一些前几行数据，以检查数据是否正确加载。在*步骤5*中，我们分离出响应变量和预测变量的列名，并在*步骤6*中，我们使用`asfactor()`函数将响应变量转换为分类类型。
- en: We defined a variable called `nfolds` in *Step 7*, which we used for cross-validation.
    We have also defined a variable `encoding` which we used in the next steps to
    instruct H2O to use one-hot encoding for categorical variables. In *Step 8* to
    *Step 10*, we built our base learners.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤7*中，我们定义了一个名为`nfolds`的变量，我们使用它进行交叉验证。我们还定义了一个名为`encoding`的变量，我们在后续步骤中使用它来指示H2O对分类变量使用独热编码。在*步骤8*到*步骤10*中，我们构建了我们的基本学习器。
- en: 'In *Step 11*, we trained a Gradient Boosting Machine model. We passed some
    values to a few hyperparameters as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤11*中，我们训练了一个梯度提升机模型。我们向一些超参数传递了一些值，如下所示：
- en: '`nfolds`: Number of folds for K-fold cross-validation.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nfolds`：K折交叉验证的折数。'
- en: '`fold_assignment`: This option specifies the scheme to use for cross-validation
    fold assignment. This option is only applicable if a value for `nfolds` is specified
    and a `fold_column` isn''t specified.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fold_assignment`：此选项指定用于交叉验证折分配的方案。此选项仅在指定了`nfolds`值且未指定`fold_column`时适用。'
- en: '`distribution`: Specifies the distribution. In our case, since the response
    variable has two classes, we set `distribution` to `"bernoulli"`.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distribution`：指定分布。在我们的情况下，由于响应变量有两个类别，我们将`distribution`设置为`"bernoulli"`。'
- en: '`ntrees`: Number of trees.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ntrees`：树的数量。'
- en: '`max_depth`: Denotes the maximum tree depth.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_depth`：表示最大树深度。'
- en: '`min_rows`: Fewest allowed observations in a leaf.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_rows`：叶子节点中允许的最少观测值。'
- en: '`learn_rate`: Learning rate takes value from `0.0` to `1.0`.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learn_rate`：学习率取值范围从`0.0`到`1.0`。'
- en: Note that for all base learners, cross-validation folds must be the same and
    `keep_cross_validation_predictions` must be set to `True`.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于所有基本学习器，交叉验证折数必须相同，并且`keep_cross_validation_predictions`必须设置为`True`。
- en: 'In *Step 9*, we trained a random forest base learner using the following hyperparameters:
    `ntrees`, `nfolds`, `fold_assignment`.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤9*中，我们使用以下超参数训练了一个随机森林基本学习器：`ntrees`、`nfolds`、`fold_assignment`。
- en: In *Step 10*, we trained our algorithm with a GLM. Note that we have not encoded
    the categorical variables in GLM.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤10*中，我们使用GLM训练了我们的算法。请注意，我们尚未对GLM中的分类变量进行编码。
- en: H2O recommends users to allow GLM handle categorical columns, as it can take
    advantage of the categorical column for better performance and efficient memory
    utilization.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: H2O建议用户允许GLM处理分类列，因为它可以利用分类列以获得更好的性能和高效的内存利用。
- en: 'From H2o.ai: "We strongly recommend avoiding one-hot encoding categorical columns
    with any levels into many binary columns, as this is very inefficient. This is
    especially true for Python users who are used to expanding their categorical variables
    manually for other frameworks".'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 来自H2o.ai的建议："我们强烈建议避免将具有任何级别的分类列进行one-hot编码成多个二进制列，因为这非常低效。这对于习惯手动扩展其分类变量以适应其他框架的Python用户来说尤其如此"。
- en: In *Step 11*, we generated the test AUC values for each of the base learners
    and printed the best AUC.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤11*中，我们为每个基础学习者生成了测试AUC值，并打印了最佳的AUC。
- en: In *Step 12*, we trained a stacked ensemble model by combining the output of
    the base learners using `H2OStackedEnsembleEstimator`. We used the trained ensemble
    model on our test subset. Note that by default GLM is used as the meta-learner
    for `H2OStackedEnsembleEstimator`. However, we have used deep learning as the
    meta-learner in our example.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤12*中，我们通过使用`H2OStackedEnsembleEstimator`结合基础学习者的输出，训练了一个堆叠集成模型。我们在测试子集上使用了训练好的集成模型。请注意，默认情况下，GLM被用作`H2OStackedEnsembleEstimator`的元学习器。然而，在我们的示例中，我们使用了深度学习作为元学习器。
- en: Note that we have used default hyperparameters values for our meta-learner.
    We can specify the hyperparameter values with `metalearner_params`. The `metalearner_params` option
    allows you to pass in a dictionary/list of hyperparameters to use for the algorithm
    that is used as meta-learner.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们已经为我们的元学习器使用了默认的超参数值。我们可以使用`metalearner_params`指定超参数值。`metalearner_params`选项允许您传递一个字典/超参数列表，用于作为元学习器的算法。
- en: Fine-tuning the hyperparameters can deliver better results.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 微调超参数可以带来更好的结果。
- en: There's more...
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'You may also assemble a list of models to stack together in different ways.
    In the preceding example, we trained individual models and put them in a list
    to ensemble them. We can also train a grid of models:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以以不同的方式组装一个模型列表以堆叠。在前面的示例中，我们训练了单个模型并将它们放入列表中进行集成。我们也可以训练一个模型网格：
- en: 'We specify the random forest hyperparameters for the grid:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们指定网格的随机森林超参数：
- en: '[PRE32]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We train the grid using the hyperparameters defined in the preceding code:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用前面代码中定义的超参数进行网格训练：
- en: '[PRE33]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We train the ensemble using the random forest grid:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用随机森林网格进行集成训练：
- en: '[PRE34]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The preceding code will give the best base-learner test AUC and test the AUC
    from the ensemble model. If the response variable is highly imbalanced, consider
    fine-tuning the following hyperparameters to control oversampling and under-sampling:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将给出最佳基础学习器测试AUC，并测试集成模型的AUC。如果响应变量高度不平衡，考虑微调以下超参数以控制过采样和欠采样：
- en: '`balance_classes`: This option can be used to balance the class distribution. When
    enabled, H2O will either under-sample the majority classes or oversample the minority
    classes. If this option is enabled, you can also specify a value for the `class_sampling_factors` and `max_after_balance_size`
    options.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`balance_classes`：此选项可用于平衡类分布。当启用时，H2O将减少多数类的样本量或增加少数类的样本量。如果此选项被启用，您还可以指定`class_sampling_factors`和`max_after_balance_size`选项的值。'
- en: '`class_sampling_factors`: By default, sampling factors will be automatically
    computed to obtain class balance during training. This behavior may be changed
    using the `class_sampling_factors` parameter. This option sets an over- or under-sampling
    ratio for each class and requires `balance_classes=true`.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_sampling_factors`：默认情况下，采样因子将在训练期间自动计算以获得类平衡。此行为可以通过`class_sampling_factors`参数进行更改。此选项为每个类设置过采样或欠采样比率，并需要`balance_classes=true`。'
- en: '`max_after_balance_size`: In most cases, setting `balance_classes` to true will
    increase the size of the DataFrame. To reduce the DataFrame size, you can use
    the `max_after_balance_size` parameter. This specifies the maximum relative size
    of the training data after balancing the class counts and defaults to `5.0`.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_after_balance_size`：在大多数情况下，将`balance_classes`设置为true会增加DataFrame的大小。为了减少DataFrame的大小，您可以使用`max_after_balance_size`参数。此参数指定平衡类计数后的训练数据的最大相对大小，默认为`5.0`。'
- en: See also
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: Take a look at `StackNet`, which was developed by Marios Michailidis as part
    of his PhD. `StackNet` is available under the MIT licence. It's a scalable and
    analytical framework that resembles a feed-forward neural network, and uses Wolpert's
    stacked-generalization concept to improve accuracy in machine learning predictive
    tasks. It uses the notion of meta-learners, in that it uses the predictions of
    some algorithms as features for other algorithms. StackNet can also generalize
    stacking on multiple levels. It is, however, computationally intensive. It was originally
    developed in Java, but a lighter Python version of `StackNet`, named `pystacknet`,
    is now available as well.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 看一看由Marios Michailidis在其博士论文中开发的`StackNet`。`StackNet`在MIT许可下可用。它是一个可扩展的分析框架，类似于前馈神经网络，并使用Wolpert的堆叠泛化概念来提高机器学习预测任务的准确性。它使用元学习者的概念，即它使用某些算法的预测作为其他算法的特征。StackNet还可以在多个级别上进行泛化堆叠。然而，它计算密集。最初是用Java开发的，但现在也提供了一种较轻的Python版本，名为`pystacknet`。
- en: Let's think about how StackNet works. In the case of a neural network, the output
    of one layer is inserted as an input to the next layer and an activation function,
    such as sigmoid, tanh, or relu, is applied. Similarly, in the case of StackNet,
    the activation functions can be replaced with any supervised machine learning
    algorithm.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们思考一下StackNet是如何工作的。在神经网络的情况下，某一层的输出被插入到下一层作为输入，并应用激活函数，如sigmoid、tanh或relu。同样，在StackNet的情况下，激活函数可以被任何监督机器学习算法所替代。
- en: 'The stacking element can be run on two modes: a normal stacking mode and a
    re-stacking mode. In the case of a normal stacking mode, each layer uses the predictions
    of the previous one. In the case of re-stacking mode, each layer uses the neurons
    and activations of the previous layers.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠元素可以在两种模式下运行：正常堆叠模式和重新堆叠模式。在正常堆叠模式下，每一层使用前一层的结果进行预测。在重新堆叠模式下，每一层使用前几层的神经元和激活。
- en: 'Sample code that uses StackNet would consist of the following steps:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 使用StackNet的示例代码将包括以下步骤：
- en: 'Import the required libraries (note that we have imported `StackNetClassifier`
    and `StackNetRegressor` from the `pystacknet` library):'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库（请注意，我们已经从`pystacknet`库中导入了`StackNetClassifier`和`StackNetRegressor`）：
- en: '[PRE35]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We read the data, drop the `ID` column, and check the dimensions of the dataset:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们读取数据，删除`ID`列，并检查数据集的维度：
- en: '[PRE36]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We separate our target and predictor variables. We also split the data into
    training and testing subsets:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将目标变量和预测变量分开。同时，我们将数据分为训练集和测试集：
- en: '[PRE37]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We define the models for the base learners and the meta-learner:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了基学习器和元学习器的模型：
- en: '[PRE38]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We now use `StackNetClassifier` to build the stacking ensemble. However, note
    that we use `restacking=False`, which means that it uses the normal stacking mode:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们使用`StackNetClassifier`构建堆叠集成。但是请注意，我们使用`restacking=False`，这意味着它使用正常堆叠模式：
- en: '[PRE39]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: With `restacking=True`, `StackNetClassifier` would use the re-stacking mode
    to build the models.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`restacking=True`时，`StackNetClassifier`将使用重新堆叠模式来构建模型。
- en: There are various case studies of StackNet being used in winning competitions
    in Kaggle. An example of how `StackNet` can be used is available at [https://bit.ly/2T7339y](https://bit.ly/2T7339y).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kaggle竞赛中，StackNet被用于赢得各种案例研究。关于如何使用`StackNet`的示例可以在[https://bit.ly/2T7339y](https://bit.ly/2T7339y)找到。
