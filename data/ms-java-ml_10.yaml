- en: Appendix A. Linear Algebra
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录A. 线性代数
- en: Linear algebra is of primary importance in machine learning and it gives us
    an array of tools that are especially handy for the purpose of manipulating data
    and extracting patterns from it. Moreover, when data must be processed in batches
    as in much machine learning, great runtime efficiencies are gained from using
    the "vectorized" form as an alternative to traditional looping constructs when
    implementing software solutions in optimization or data pre-processing or any
    number of operations in analytics.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数在机器学习中至关重要，它为我们提供了一系列特别适用于数据操作和从数据中提取模式的有用工具。此外，当数据必须像在许多机器学习中那样批量处理时，使用“向量形式”作为传统循环结构的替代，在实现优化、数据预处理或分析中的任何操作时，可以获得巨大的运行时效率。
- en: We will consider only the domain of real numbers in what follows. Thus, a vector
    ![Linear Algebra](img/B05137_10_image001.jpg) represents an array of *n* real-valued
    numbers. A matrix ![Linear Algebra](img/B05137_10_image004.jpg) is a two-dimensional
    array of *m* rows and *n* columns of real-valued numbers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下内容中，我们只考虑实数域。因此，向量![线性代数](img/B05137_10_image001.jpg)代表一个*n*个实数值的数组。矩阵![线性代数](img/B05137_10_image004.jpg)是一个具有*m*行和*n*列实数值的二维数组。
- en: Some key concepts from the foundation of linear algebra are presented here.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这里介绍了线性代数基础的一些关键概念。
- en: Vector
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量
- en: The vector **x** (lowercase, bold, by convention; equivalently, ![Vector](img/B05137_10_image131.jpg))
    can be thought of as a point in *n*-dimensional space. Conventionally, we mean
    column-vector when we say vector. The *transpose* of a column vector is a *row*
    vector with the same number of elements, arranged in a single row.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 向量**x**（小写，粗体，按惯例；等价于![向量](img/B05137_10_image131.jpg)）可以被视为*n*-维空间中的一个点。按惯例，当我们说向量时，我们指的是列向量。列向量的*转置*是一个具有相同元素数量的行向量，排列在单行中。
- en: '![Vector](img/B05137_10_image005.jpg)![Vector](img/B05137_10_image006.jpg)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![向量](img/B05137_10_image005.jpg)![向量](img/B05137_10_image006.jpg)'
- en: Scalar product of vectors
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量标量积
- en: 'Also known as the dot product, the scalar product is defined for two vectors
    of equal length. The result of the operation is a scalar value and is obtained
    by summing over the products of the corresponding elements of the vectors. Thus,
    given vectors **x** and **y**:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 也称为点积，标量积定义为等长向量的乘积。该操作的结果是一个标量值，通过求向量对应元素的乘积之和得到。因此，给定向量**x**和**y**：
- en: '![Scalar product of vectors](img/B05137_10_image132.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![向量标量积](img/B05137_10_image132.jpg)'
- en: 'The dot product **x**T**y** is given as:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 点积**x**T**y**表示为：
- en: '![Scalar product of vectors](img/B05137_10_image133.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![向量标量积](img/B05137_10_image133.jpg)'
- en: Matrix
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 矩阵
- en: 'A matrix is a two-dimensional array of numbers. Each element can be indexed
    by its row and column position. Thus, a 3 x 2 matrix:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵是一个二维数字数组。每个元素可以通过其行和列位置进行索引。因此，一个3 x 2矩阵：
- en: '![Matrix](img/B05137_10_image008.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵](img/B05137_10_image008.jpg)'
- en: Transpose of a matrix
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵转置
- en: 'Swapping columns for rows in a matrix produces the transpose. Thus, the transpose
    of **A** is a 2 x 3 matrix:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 交换矩阵中的列和行产生转置。因此，**A**的转置是一个2 x 3矩阵：
- en: '![Transpose of a matrix](img/B05137_10_image010.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵转置](img/B05137_10_image010.jpg)'
- en: Matrix addition
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 矩阵加法
- en: 'Matrix addition is defined as element-wise summation of two matrices with the
    same shape. Let **A** and **B** be two *m* x *n* matrices. Their sum **C** can
    be written as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵加法定义为具有相同形状的两个矩阵的逐元素相加。设**A**和**B**为两个*m* x *n*矩阵。它们的和**C**可以表示如下：
- en: '**C**i,j = **A**i,j + **B**i,j'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**C**i,j = **A**i,j + **B**i,j'
- en: Scalar multiplication
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标量乘法
- en: 'Multiplication with a scalar produces a matrix where each element is scaled
    by the scalar value. Here **A** is multiplied by the scalar value *d*:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 与标量相乘产生一个矩阵，其中每个元素都按标量值缩放。这里**A**乘以标量值*d*：
- en: '![Scalar multiplication](img/B05137_10_image015.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![标量乘法](img/B05137_10_image015.jpg)'
- en: Matrix multiplication
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 矩阵乘法
- en: 'Two matrices **A** and **B** can be multiplied if the number of columns of
    **A** equals the number of rows of **B**. If **A** has dimensions *m* x *n* and
    **B** has dimensions *n* x *p*, then the product **AB** has dimensions *m* x *p*:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果矩阵**A**的列数等于矩阵**B**的行数，则两个矩阵**A**和**B**可以相乘。如果**A**的维度为*m* x *n*，**B**的维度为*n*
    x *p*，则乘积**AB**的维度为*m* x *p*：
- en: '![Matrix multiplication](img/B05137_10_image019.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵乘法](img/B05137_10_image019.jpg)'
- en: Properties of matrix product
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 矩阵乘积的性质
- en: 'Distributivity over addition: A(B + C) = AB + AC'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对加法的分配律：A(B + C) = AB + AC
- en: 'Associativity: A(BC) = (AB)C'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 结合律：A(BC) = (AB)C
- en: 'Non-commutativity: AB ≠ BA'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 非交换性：AB ≠ BA
- en: 'Vector dot-product is commutative: **x**T**y** = **y**T**x**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 向量点积是交换的：**x**T**y** = **y**T**x**
- en: 'Transpose of product is product of transposes: (**AB**)T = **A**T**B**T'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 乘积的转置是转置的乘积：(**AB**)T = **A**T**B**T
- en: Linear transformation
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 线性变换
- en: 'There is a special importance to the product of a matrix and a vector in linear
    algebra. Consider the product of a 3 x 2 matrix **A** and a 2 x 1 vector **x**
    producing a 3 x 1 vector *y*:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性代数中，矩阵与向量的乘积具有特殊的重要性。考虑一个 3 x 2 矩阵 **A** 与一个 2 x 1 向量 **x** 的乘积，产生一个 3 x
    1 向量 *y*：
- en: '![Linear transformation](img/B05137_10_image025.jpg)![Linear transformation](img/B05137_10_image026.jpg)![Linear
    transformation](img/B05137_10_image027.jpg)![Linear transformation](img/B05137_10_image028.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![线性变换](img/B05137_10_image025.jpg)![线性变换](img/B05137_10_image026.jpg)![线性变换](img/B05137_10_image027.jpg)![线性变换](img/B05137_10_image028.jpg)'
- en: (C)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: (C)
- en: '![Linear transformation](img/B05137_10_image029.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![线性变换](img/B05137_10_image029.jpg)'
- en: (R)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: (R)
- en: It is useful to consider two views of the preceding matrix-vector product, namely,
    the column picture (**C**) and the row picture (**R**). In the column picture,
    the product can be seen as a linear combination of the column vectors of the matrix,
    whereas the row picture can be thought of as the dot products of the rows of the
    matrix with the vector ![Linear transformation](img/B05137_10_image030.jpg)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑前面矩阵-向量乘积的两种观点是有用的，即列图（**C**）和行图（**R**）。在列图中，乘积可以看作是矩阵列向量的线性组合，而行图可以看作是矩阵行与向量
    ![线性变换](img/B05137_10_image030.jpg) 的点积。
- en: Matrix inverse
  id: totrans-40
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 矩阵逆
- en: 'The product of a matrix with its inverse is the Identity matrix. Thus:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵与其逆的乘积是单位矩阵。因此：
- en: '![Matrix inverse](img/B05137_10_image031.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵逆](img/B05137_10_image031.jpg)'
- en: 'The matrix inverse, if it exists, can be used to solve a system of simultaneous
    equations represented by the preceding vector-matrix product equation. Consider
    a system of equations:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存在矩阵逆，则可以用来解由前面的向量-矩阵乘积方程表示的联立方程组。考虑一个方程组：
- en: '*x*1 + 2*x*2 = 3'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*x*1 + 2*x*2 = 3'
- en: 3*x*1 + 9*x*2 = 21
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 3*x*1 + 9*x*2 = 21
- en: 'This can be expressed as an equation involving the matrix-vector product:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以表示为一个涉及矩阵-向量乘积的方程：
- en: '![Matrix inverse](img/B05137_10_image034.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵逆](img/B05137_10_image034.jpg)'
- en: 'We can solve for the variables *x*1 and *x*2 by multiplying both sides by the
    matrix inverse:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将两边乘以矩阵逆来求解变量 *x*1 和 *x*2。
- en: '![Matrix inverse](img/B05137_10_image035.jpg)![Matrix inverse](img/B05137_10_image036.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵逆](img/B05137_10_image035.jpg)![矩阵逆](img/B05137_10_image036.jpg)'
- en: 'The matrix inverse can be calculated by different methods. The reader is advised
    to view Prof. Strang''s MIT lecture: [bit.ly/10vmKcL](http://bit.ly/10vmKcL).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵逆可以通过不同的方法计算。读者建议观看斯特兰格教授的麻省理工学院讲座：[bit.ly/10vmKcL](http://bit.ly/10vmKcL)。
- en: Eigendecomposition
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 特征分解
- en: 'Matrices can be decomposed to factors that can give us valuable insight into
    the transformation that the matrix represents. Eigenvalues and eigenvectors are
    obtained as the result of eigendecomposition. For a given square matrix **A**,
    an eigenvector is a non-zero vector that is transformed into a scaled version
    of itself when multiplied by the matrix. The scalar multiplier is the eigenvalue.
    All scalar multiples of an eigenvector are also eigenvectors:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵可以被分解为因子，这些因子可以给我们提供关于矩阵表示的变换的宝贵见解。特征值和特征向量是特征分解的结果。对于给定的方阵 **A**，一个特征向量是一个非零向量，当乘以矩阵时，它被转换为其自身的缩放版本。标量乘数是特征值。一个特征向量的所有标量倍数也是特征向量：
- en: '**A** **v** = *λ* **v**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**A** **v** = *λ* **v**'
- en: In the preceding example, **v** is an eigenvector and λ is the eigenvalue.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，**v** 是一个特征向量，λ 是特征值。
- en: 'The eigenvalue equation of matrix **A** is given by:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 **A** 的特征值方程由以下给出：
- en: (**A** — *λ* **I**)**v** = 0
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: (**A** — *λ* **I**)**v** = 0
- en: 'The non-zero solution for the eigenvalues is given by the roots of the characteristic
    polynomial equation of degree *n* represented by the determinant:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值的非零解由特征多项式方程的根给出，该方程的阶数为 *n*，由行列式表示：
- en: '![Eigendecomposition](img/B05137_10_image041.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![特征分解](img/B05137_10_image041.jpg)'
- en: The eigenvectors can then be found by solving for *v* in **Av** = *λ* **v**.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以通过解 **Av** = λ **v** 来找到特征向量 *v*。
- en: 'Some matrices, called diagonalizable matrices, can be built entirely from their
    eigenvectors and eigenvalues. If **Λ** is the diagonal matrix with the eigenvalues
    of matrix A on its principal diagonal, and **Q** is the matrix whose columns are
    the eigenvectors of **A**:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一些矩阵，称为可对角化矩阵，可以完全由它们的特征向量和特征值构建。如果 **Λ** 是具有矩阵 A 的特征值的主对角线的对角矩阵，而 **Q** 是其列是
    **A** 的特征向量的矩阵：
- en: '![Eigendecomposition](img/B05137_10_image043.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![特征分解](img/B05137_10_image043.jpg)'
- en: Then **A = Q Λ Q**-1.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 那么 **A = Q Λ Q**-1。
- en: Positive definite matrix
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 正定矩阵
- en: 'If a matrix has only positive eigenvalues, it is called a **positive definite
    matrix**. If the eigenvalues are positive or zero, the matrix is called a **positive
    semi-definite matrix**. With positive definite matrices, it is true that:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个矩阵只有正特征值，则称为 **正定矩阵**。如果特征值为正或零，则称为 **正半定矩阵**。对于正定矩阵，以下说法是正确的：
- en: '**x**T**Ax** *≥* 0'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**x**T**Ax** *≥* 0'
- en: Singular value decomposition (SVD)
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 奇异值分解 (SVD)
- en: 'SVD is a decomposition of any rectangular matrix **A** of dimensions *n* x
    *p* and is written as the product of three matrices:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: SVD 是任何尺寸为 *n* x *p* 的矩形矩阵 **A** 的分解，表示为三个矩阵的乘积：
- en: '![Singular value decomposition (SVD)](img/B05137_10_image140.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![奇异值分解 (SVD)](img/B05137_10_image140.jpg)'
- en: '**U** is defined to be *n* x *n*, **S** is a diagonal *n* x *p* matrix, and
    **V** is *p* x *p*. **U** and **V** are orthogonal matrices; that is:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**U** 被定义为 *n* x *n*，**S** 是一个对角 *n* x *p* 矩阵，**V** 是 *p* x *p*。**U** 和 **V**
    是正交矩阵；即：'
- en: '![Singular value decomposition (SVD)](img/B05137_10_image141.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![奇异值分解 (SVD)](img/B05137_10_image141.jpg)'
- en: The diagonal values of **S** are called the singular values of **A**. Columns
    of **U** are called left singular vectors of **A** and those of **V** are called
    right singular vectors of **A**. The left singular vectors are orthonormal eigenvectors
    of **A**T**A** and the right singular vectors are orthonormal eigenvectors of
    **AA**T.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**S** 的对角值称为 **A** 的奇异值。**U** 的列称为 **A** 的左奇异向量，而 **V** 的列称为 **A** 的右奇异向量。左奇异向量是
    **A**T**A** 的正交归一特征向量，右奇异向量是 **AA**T 的正交归一特征向量。'
- en: The SVD representation expands the original data into a coordinate system such
    that the covariance matrix is a diagonal matrix.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: SVD 表示将原始数据扩展到一个坐标系中，使得协方差矩阵是一个对角矩阵。
