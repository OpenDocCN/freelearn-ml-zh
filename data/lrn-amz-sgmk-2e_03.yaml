- en: 'Chapter 2: Handling Data Preparation Techniques'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章：处理数据准备技术
- en: Data is the starting point of any machine learning project, and it takes lots
    of work to turn data into a dataset that can be used to train a model. That work
    typically involves annotating datasets, running bespoke scripts to preprocess
    them, and saving processed versions for later use. As you can guess, doing all
    this work manually, or building tools to automate it, is not an exciting prospect
    for machine learning teams.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是任何机器学习项目的起点，将数据转化为可以用于训练模型的数据集需要大量工作。这项工作通常涉及标注数据集、运行定制的脚本进行预处理，并保存处理后的版本以备后用。如你所料，手动完成所有这些工作，或构建工具来自动化这些过程，对机器学习团队来说并不是一项令人兴奋的任务。
- en: 'In this chapter, you will learn about AWS services that help you build and
    process data. We''ll first cover **Amazon SageMaker Ground Truth**, a capability
    of Amazon SageMaker that helps you quickly build accurate training datasets. Then,
    we''ll introduce **Amazon SageMaker Data Wrangler**, a new way to transform your
    data interactively. Next, we''ll talk about **Amazon SageMaker Processing**, another
    capability that helps you run your data processing workloads, such as feature
    engineering, data validation, model evaluation, and model interpretation. Finally,
    we''ll quickly discuss other AWS services that may help with data analytics: **Amazon
    Elastic Map Reduce**, **AWS Glue**, and **Amazon Athena**.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍帮助你构建和处理数据的 AWS 服务。我们首先会讲解 **Amazon SageMaker Ground Truth**，这是 Amazon
    SageMaker 的一项功能，帮助你快速构建准确的训练数据集。接着，我们会介绍 **Amazon SageMaker Data Wrangler**，一种交互式转换数据的新方法。然后，我们会讨论
    **Amazon SageMaker Processing**，另一项功能，帮助你运行数据处理工作负载，例如特征工程、数据验证、模型评估和模型解释。最后，我们会简要介绍其他可能有助于数据分析的
    AWS 服务：**Amazon Elastic Map Reduce**、**AWS Glue** 和 **Amazon Athena**。
- en: 'This chapter consists of the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包括以下主题：
- en: Labeling data with Amazon SageMaker Ground Truth
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker Ground Truth 标注数据
- en: Transforming data with Amazon SageMaker Data Wrangler
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker Data Wrangler 转换数据
- en: Running batch jobs with Amazon SageMaker Processing
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker Processing 运行批处理作业
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need an AWS account to run the examples included in this chapter. If
    you haven't got one already, please point your browser at [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    to create one. You should also familiarize yourself with the AWS Free Tier , which
    lets you use many AWS services for free within certain usage limits.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要一个 AWS 账户来运行本章中包含的示例。如果你还没有账户，请访问 [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    创建一个。你还应该熟悉 AWS 免费套餐，它允许你在特定的使用限制内免费使用许多 AWS 服务。
- en: You will need to install and to configure the AWS **Command Line Interface**
    (**CLI**) for your account ([https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要为你的账户安装并配置 AWS **命令行界面**（**CLI**）（[https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)）。
- en: You will need a working Python 3.x environment. Installing the Anaconda distribution
    ([https://www.anaconda.com/](https://www.anaconda.com/)) is not mandatory, but
    strongly encouraged as it includes many projects that we will need (Jupyter, `pandas`,
    `numpy`, and more).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要一个正常工作的 Python 3.x 环境。安装 Anaconda 发行版（[https://www.anaconda.com/](https://www.anaconda.com/)）不是强制要求，但强烈推荐，因为它包含我们需要的许多项目（Jupyter、`pandas`、`numpy`
    等）。
- en: Code examples included in the book are available on GitHub at [https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition](https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition).
    You will need to install a Git client to access them ([https://git-scm.com/](https://git-scm.com/)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的代码示例可以在 GitHub 上找到，地址是 [https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition](https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition)。你需要安装
    Git 客户端才能访问这些示例（[https://git-scm.com/](https://git-scm.com/)）。
- en: Labeling data with Amazon SageMaker Ground Truth
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker Ground Truth 标注数据
- en: Added to Amazon SageMaker in late 2018, Amazon SageMaker Ground Truth helps
    you quickly build accurate training datasets. Machine learning practitioners can
    distribute labeling work to public and private workforces of human labelers. Labelers
    can be productive immediately, thanks to built-in workflows and graphical interfaces
    for common image, video, and text tasks. In addition, Ground Truth can enable
    automatic labeling, a technique that trains a machine learning model able to label
    data without additional human intervention.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker于2018年底增加的Amazon SageMaker Ground Truth帮助你快速构建准确的训练数据集。机器学习从业者可以将标注工作分发给公共和私人劳动力的人工标注员。得益于内置工作流程和图形界面，标注员可以立即开始高效工作，处理常见的图像、视频和文本任务。此外，Ground
    Truth还支持自动标注技术，这是一种训练机器学习模型使其能够在没有额外人工干预的情况下进行数据标注的技术。
- en: In this section, you'll learn how to use Ground Truth to label images and text.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何使用Ground Truth标注图像和文本。
- en: Using workforces
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用劳动力
- en: The first step in using Ground Truth is to create a workforce, a group of workers
    in charge of labeling data samples.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Ground Truth的第一步是创建一个劳动力，这是负责标注数据样本的工作组。
- en: 'Let''s head out to the SageMaker console: in the left-hand vertical menu, we
    click on **Ground Truth**, then on **Labeling workforces**. Three types of workforces
    are available: **Amazon Mechanical Turk**, **Vendor**, and **Private**. Let''s
    discuss what they are, and when you should use them.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入SageMaker控制台：在左侧的垂直菜单中，点击**Ground Truth**，然后点击**标注劳动力**。有三种类型的劳动力可供选择：**Amazon
    Mechanical Turk**、**供应商**和**私人**。我们来讨论一下它们是什么，以及何时使用它们。
- en: Amazon Mechanical Turk
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon Mechanical Turk
- en: '**Amazon Mechanical Turk** ([https://www.mturk.com/](https://www.mturk.com/))
    makes it easy to break down large batch jobs into small work units that can be
    processed by a distributed workforce.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon Mechanical Turk**（[https://www.mturk.com/](https://www.mturk.com/)）使得将大型批处理任务拆分为小的工作单元变得更加容易，这些单元可以由分布式劳动力处理。'
- en: 'With Mechanical Turk, you can enroll tens or even hundreds of thousands of
    workers located across the globe. This is a great option when you need to label
    extremely large datasets. For example, think about a dataset for autonomous driving,
    made up of 1,000 hours of video: each frame would need to be processed in order
    to identify other vehicles, pedestrians, road signs, and more. If you wanted to
    annotate every single frame, you''d be looking at 1,000 hours x 3,600 seconds
    x 24 frames per second = **86.4 million images**! Clearly, you would have to scale
    out your labeling workforce to get the job done, and Mechanical Turk lets you
    do that.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Mechanical Turk，你可以招募来自全球的成千上万的工人。这是当你需要标注极大数据集时的一个很好的选择。例如，想象一个自动驾驶数据集，由1,000小时的视频组成：每一帧都需要处理，以识别其他车辆、行人、交通标志等。如果你想对每一帧进行标注，你将需要处理1,000小时
    x 3,600秒 x 每秒24帧 = **8640万张图片**！显然，你需要扩展你的标注劳动力才能完成这项工作，而Mechanical Turk可以让你做到这一点。
- en: Vendor workforce
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 供应商劳动力
- en: As scalable as Mechanical Turk is, sometimes you need more control on who data
    is shared with, and on the quality of annotations, particularly if additional
    domain knowledge is required.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Mechanical Turk具有良好的可扩展性，但有时你需要更多控制，特别是当数据共享对象和标注质量需要更多关注时，尤其是在需要额外领域知识的情况下。
- en: For this purpose, AWS has vetted a number of data labeling companies, which
    have integrated Ground Truth in their workflows. You can find the list of companies
    on **AWS Marketplace** ([https://aws.amazon.com/marketplace/](https://aws.amazon.com/marketplace/)),
    under **Machine Learning** | **Data Labeling Services** | **Amazon SageMaker Ground
    Truth Services**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，AWS已经审核了一些数据标注公司，这些公司已经将Ground Truth集成到他们的工作流程中。你可以在**AWS Marketplace**（[https://aws.amazon.com/marketplace/](https://aws.amazon.com/marketplace/)）中找到这些公司的列表，路径为**机器学习**
    | **数据标注服务** | **Amazon SageMaker Ground Truth服务**。
- en: Private workforce
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 私人劳动力
- en: Sometimes, data can't be processed by third parties. Maybe it's just too sensitive,
    or maybe it requires expert knowledge that only your company's employees have.
    In this case, you can create a private workforce made up of well-identified individuals
    that will access and label your data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，数据不能由第三方处理。也许它过于敏感，或者可能需要只有你公司员工才拥有的专业知识。在这种情况下，你可以创建一个由明确身份的个人组成的私人劳动力来访问并标注数据。
- en: Creating a private workforce
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建私人劳动力
- en: 'Creating a private workforce is the quickest and simplest option. Let''s see
    how it''s done:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 创建私人劳动力是最快且最简单的选项。让我们来看看如何操作：
- en: Starting from the **Labeling workforces** entry in the SageMaker console, we
    select the **Private** tab, as seen in the following screenshot. Then, we click
    on **Create private team**:![Figure 2.1 – Creating a private workforce
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从SageMaker控制台中的**Labeling workforces**入口开始，我们选择**Private**标签，如下图所示。然后，点击**Create
    private team**：![图 2.1 – 创建私有工作团队
- en: '](img/B17705_02_001.jpg)'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_001.jpg)'
- en: Figure 2.1 – Creating a private workforce
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.1 – 创建私有工作团队
- en: We give the team a name, then we have to decide whether we're going to invite
    workers by email, or whether we're going to import users that belong to an existing
    **Amazon Cognito** group.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为团队命名，然后需要决定是通过电子邮件邀请工作人员，还是导入属于现有**Amazon Cognito**组的用户。
- en: Amazon Cognito ([https://aws.amazon.com/cognito/](https://aws.amazon.com/cognito/))
    is a managed service that lets you build and manage user directories at any scale.
    Cognito supports both social identity providers (Google, Facebook, and Amazon),
    and enterprise identity providers (Microsoft Active Directory, SAML).
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Amazon Cognito ([https://aws.amazon.com/cognito/](https://aws.amazon.com/cognito/))
    是一种托管服务，可以让您在任何规模下构建和管理用户目录。Cognito支持社交身份提供者（Google、Facebook 和 Amazon），以及企业身份提供者（Microsoft
    Active Directory、SAML）。
- en: 'This makes a lot of sense in an enterprise context, but let''s keep things
    simple and use email instead. Here, I will use some sample email addresses: please
    make sure to use your own, otherwise you won''t be able to join the team!'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在企业环境中，这非常有意义，但为了简化流程，我们可以改用电子邮件。在这里，我将使用一些示例电子邮件地址：请确保使用您自己的电子邮件地址，否则您将无法加入团队！
- en: Then, we need to enter an organization name, and more importantly a contact
    email that workers can use for questions and feedback on the labeling job. These
    conversations are extremely important in order to fine-tune labeling instructions,
    pinpoint problematic data samples, and more.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们需要输入组织名称，更重要的是提供一个工作人员可以用来提问和反馈标注工作的联系方式电子邮件。这些交流非常重要，以便微调标注说明，找出有问题的数据样本等。
- en: Optionally, we can set up notifications with **Amazon Simple Notification Service**
    ([https://aws.amazon.com/sns/](https://aws.amazon.com/sns/)) to let workers know
    that they have work to do.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，我们可以使用**Amazon Simple Notification Service** ([https://aws.amazon.com/sns/](https://aws.amazon.com/sns/))
    设置通知，以告知工作人员他们有任务需要完成。
- en: The screen should look like in the following screenshot. Then, we click on **Create
    private team**:![Figure 2.2 – Setting up a private workforce
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 屏幕应该像下图所示。然后，我们点击**Create private team**：![图 2.2 – 设置私有工作团队
- en: '](img/B17705_02_002.jpg)'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_002.jpg)'
- en: Figure 2.2 – Setting up a private workforce
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.2 – 设置私有工作团队
- en: A few seconds later, the team has been set up. Invitations have been sent to
    workers, requesting that they join the workforce by logging in to a specific URL.
    The invitation email looks like that shown in the following screenshot:![Figure
    2.3 – Email invitation
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 几秒钟后，团队已建立。邀请已发送给工作人员，要求他们通过登录特定的URL加入工作团队。邀请邮件如下图所示：![图 2.3 – 邮件邀请
- en: '](img/B17705_02_003.jpg)'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_003.jpg)'
- en: Figure 2.3 – Email invitation
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.3 – 邮件邀请
- en: 'Clicking on the link opens a login window. Once we''ve logged in and defined
    a new password, we''re taken to a new screen showing available jobs, as in the
    following screenshot. As we haven''t defined one yet, it''s obviously empty:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击链接会打开一个登录窗口。一旦我们登录并定义了新密码，就会进入一个新页面，显示可用的工作，如下图所示。由于我们尚未定义任何工作，因此它显然是空的：
- en: '![Figure 2.4 – Worker console'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.4 – 工作控制台'
- en: '](img/B17705_02_004.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17705_02_004.jpg)'
- en: Figure 2.4 – Worker console
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – 工作控制台
- en: Let's keep our workers busy and create an image labeling job.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们让工作人员忙起来，创建一个图像标注工作。
- en: Uploading data for labeling
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上传数据进行标注
- en: 'As you would expect, Amazon SageMaker Ground Truth uses Amazon S3 to store
    datasets:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所期望的，Amazon SageMaker Ground Truth 使用Amazon S3来存储数据集：
- en: 'Using the AWS CLI, we create an S3 bucket hosted in the same region we''re
    running SageMaker in. Bucket names are globally unique, so please make sure to
    pick your own unique name when you create the bucket. Use the following code (feel
    free to use another AWS Region):'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用AWS CLI，我们创建一个托管在与我们运行SageMaker相同区域的S3桶。桶名称是全球唯一的，所以请确保在创建桶时选择一个独特的名称。使用以下代码（也可以选择其他AWS区域）：
- en: '[PRE0]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we copy the cat images located in the `chapter2` folder of our GitHub
    repository as follows:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将位于`chapter2`文件夹中的猫咪图片从我们的GitHub仓库复制过来，如下所示：
- en: '[PRE1]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now that we have some data waiting to be labeled, let's create a labeling job.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一些等待标注的数据，让我们创建一个标注工作。
- en: Creating a labeling job
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建标签工作
- en: 'As you would expect, we need to define the location of the data, what type
    of task we want to label it for, and what our instructions are:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所预期的，我们需要定义数据的位置、标注任务的类型，以及我们的标注指令：
- en: In the left-hand vertical menu of the SageMaker console, we click on **Ground
    Truth**, then on **Labeling jobs**, then on the **Create labeling job** button.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 SageMaker 控制台的左侧垂直菜单中，我们点击**Ground Truth**，然后点击**标注工作**，接着点击**创建标注工作**按钮。
- en: 'First, we give the job a name, say ''`my-cat-job`''. Then, we define the location
    of the data in S3\. Ground Truth expects a **manifest file**: a manifest file
    is a **JSON** file that lets you filter which objects need to be labeled, and
    which ones should be left out. Once the job is complete, a new file, called the
    augmented manifest, will contain labeling information, and we''ll be able to use
    this to feed data to training jobs.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们给工作命名，比如'`my-cat-job`'。然后，我们定义数据在 S3 中的位置。Ground Truth 需要一个**清单文件**：清单文件是一个**JSON**
    文件，用于过滤哪些对象需要标注，哪些不需要。工作完成后，一个名为增强清单的新文件将包含标注信息，我们将能够使用这个文件来为训练工作提供数据。
- en: Then, we define the location and the type of our input data, just like in the
    following screenshot:![Figure 2.5 – Configuring input data
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义输入数据的位置和类型，正如下面的截图所示：![图 2.5 – 配置输入数据
- en: '](img/B17705_02_005.jpg)'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_005.jpg)'
- en: Figure 2.5 – Configuring input data
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.5 – 配置输入数据
- en: As is visible in the next screenshot, we select the IAM role that we created
    for SageMaker in the first chapter (your name will be different), and we then
    click on the **Complete data setup** button to validate this section:![Figure
    2.6 – Validating input data
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如下图所示，我们选择了第一章中为 SageMaker 创建的 IAM 角色（你的名字会有所不同），然后点击**完成数据设置**按钮以验证这一部分：![图
    2.6 – 验证输入数据
- en: '](img/B17705_02_006.jpg)'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_006.jpg)'
- en: Figure 2.6 – Validating input data
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.6 – 验证输入数据
- en: Clicking on **View more details**, you can learn about what is happening under
    the hood. SageMaker Ground Truth crawls your data in S3 and creates a JSON file
    called the **manifest file**. You can go and download it from S3 if you're curious.
    This file points at your objects in S3 (images, text files, and so on).
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 点击**查看更多详情**，你可以了解后台发生了什么。SageMaker Ground Truth 会抓取你在 S3 中的数据，并创建一个名为**清单文件**的
    JSON 文件。如果你感兴趣，可以从 S3 下载它。这个文件指向你在 S3 中的对象（图片、文本文件等）。
- en: Optionally, we could decide to work either with the full manifest, a random
    sample, or a filtered subset based on a **SQL** query. We could also provide an
    **Amazon KMS** key to encrypt the output of the job. Let's stick to the defaults
    here.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，我们可以选择使用完整的清单、随机样本或基于**SQL**查询的过滤子集。我们还可以提供一个**Amazon KMS** 密钥来加密作业输出。这里我们保持默认设置。
- en: The **Task type** section asks us what kind of job we'd like to run. Please
    take a minute to explore the different task categories that are available (text,
    image, video, point cloud, and custom). As shown in the next screenshot, let's
    select the **Image** task category and the **Semantic segmentation** task, and
    then click **Next**:![Figure 2.7 – Selecting a task type
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**任务类型**部分会询问我们希望执行什么类型的任务。请花一分钟时间浏览可用的不同任务类别（文本、图像、视频、点云和自定义）。如下一张截图所示，让我们选择**图像**任务类别和**语义分割**任务，然后点击**下一步**：![图
    2.7 – 选择任务类型'
- en: '](img/B17705_02_007.jpg)'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_007.jpg)'
- en: Figure 2.7 – Selecting a task type
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.7 – 选择任务类型
- en: On the next screen, visible in the following screenshot, we first select our
    private team of workers:![Figure 2.8 – Selecting a team type
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个屏幕中，如下图所示，我们首先选择我们的私人工作人员团队：![图 2.8 – 选择团队类型
- en: '](img/B17705_02_008.jpg)'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_008.jpg)'
- en: Figure 2.8 – Selecting a team type
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.8 – 选择团队类型
- en: If we had a lot of samples (say, tens of thousands or more), we should consider
    enabling **automated data labeling**, as this feature would reduce both the duration
    and the cost of the labeling job. Indeed, as workers would start labeling data
    samples, SageMaker Ground Truth would train a machine learning model on these
    samples. It would use them as a dataset for a supervised learning problem. With
    enough worker-labeled data, this model would pretty quickly be able to match and
    exceed human accuracy, at which point it would replace workers and label the rest
    of the dataset. If you'd like to know more about this feature, please read the
    documentation at [https://docs.aws.amazon.com/sagemaker/latest/dg/sms-automated-labeling.html](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-automated-labeling.html).
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们有很多样本（比如说，数万个或更多），我们应该考虑启用**自动化数据标注**，因为此功能能够减少标注任务的持续时间和成本。事实上，当工作者开始标注数据样本时，SageMaker
    Ground Truth 会使用这些样本训练一个机器学习模型。它会将这些样本用作监督学习问题的数据集。在足够多的工作者标注数据的支持下，这个模型很快就能与人类的准确性匹敌，甚至超过人类的标注准确性，届时它将取代工作者并标注剩余的数据集。如果你想了解更多关于此功能的信息，请阅读文档
    [https://docs.aws.amazon.com/sagemaker/latest/dg/sms-automated-labeling.html](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-automated-labeling.html)。
- en: The last step in configuring our training job is to enter instructions for the
    workers. This is an important step, especially if your job is distributed to third-party
    workers. The better our instructions, the higher the quality of the annotations.
    Here, let's explain what the job is about, and enter a "cat" label for workers
    to apply. In a real-life scenario, you should add detailed instructions, provide
    sample images for good and bad examples, explain what your expectations are, and
    so on. The following screenshot shows what our instructions look like:![Figure
    2.9 – Setting up instructions
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置训练任务的最后一步是输入工作者的指示。这是一个重要步骤，特别是当你的任务分配给第三方工作者时。我们的指示越清晰，标注的质量就越高。在这里，我们将解释任务的内容，并为工作者输入一个“猫”标签。现实情况下，你应该添加详细的说明，提供良好和不良示例的样本图像，解释你的期望等等。以下截图展示了我们的指示内容：![图
    2.9 – 设置指示](img/B17705_02_010.jpg)
- en: '](img/B17705_02_009.jpg)'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_009.jpg)'
- en: Figure 2.9 – Setting up instructions
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.9 – 设置指示
- en: Once we're done with instructions, we click on **Create** to launch the labeling
    job. After a few minutes, the job is ready to be distributed to workers.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成指示后，我们点击**创建**来启动标注任务。几分钟后，任务准备好分配给工作者了。
- en: Labeling images
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标注图像
- en: 'Logging in to the worker URL, we can see from the screen shown in the following
    screenshot that we have work to do:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 登录到工作者 URL，我们可以从以下截图显示的屏幕看到，我们还有任务要做：
- en: '![Figure 2.10 – Worker console'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.10 – 工作者控制台](img/B17705_02_009.jpg)'
- en: '](img/B17705_02_010.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17705_02_010.jpg)'
- en: Figure 2.10 – Worker console
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10 – 工作者控制台
- en: 'We will use the following steps:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下步骤：
- en: Clicking on **Start working** opens a new window, visible in the next picture.
    It displays instructions as well as a first image to work on:![Figure 2.11 – Labeling
    images
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**开始工作**会打开一个新窗口，接下来图中所示。它显示了说明以及第一个需要处理的图像：![图 2.11 – 标注图像](img/B17705_02_010.jpg)
- en: '](img/B17705_02_011.jpg)'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_011.jpg)'
- en: Figure 2.11 – Labeling images
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.11 – 标注图像
- en: Using the graphical tools in the toolbar, and especially the auto-segment tool,
    we can very quickly produce high-quality annotations. Please take a few minutes
    to practice, and you'll be able to do the same in no time.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用工具栏中的图形工具，尤其是自动分割工具，我们可以非常快速地制作高质量的标注。请花几分钟时间进行练习，很快你就能做到同样的事情。
- en: 'Once we''re done with the three images, the job is complete, and we can visualize
    the labeled images under **Labeling jobs** in the SageMaker console. Your screen
    should look like the following screenshot:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们完成了三个图像的标注，任务就完成了，我们可以在 SageMaker 控制台的**标注任务**下查看标注的图像。你的屏幕应该像下面的截图一样：
- en: '![Figure 2.12 – Labeled images'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.12 – 标注图像](img/B17705_02_011.jpg)'
- en: '](img/B17705_02_012.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17705_02_012.jpg)'
- en: Figure 2.12 – Labeled images
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12 – 标注图像
- en: More importantly, we can find labeling information in the S3 output location.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，我们可以在 S3 输出位置找到标注信息。
- en: In particular, the `output/my-cat-job/manifests/output/output.manifest`) contains
    annotation information on each data sample, such as the classes present in the
    image, and a link to the segmentation mask.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，`output/my-cat-job/manifests/output/output.manifest` 包含每个数据样本的标注信息，例如图像中存在的类别，以及分割掩码的链接。
- en: In [*Chapter 5*](B17705_05_Final_JM_ePub.xhtml#_idTextAnchor091)*, Training
    Computer Vision Models*, we'll see how we can feed this information directly to
    the built-in computer vision algorithms implemented in Amazon SageMaker. Of course,
    we could also parse this information, and convert it for whatever framework we
    use to train our computer vision model.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 5 章*](B17705_05_Final_JM_ePub.xhtml#_idTextAnchor091)*，训练计算机视觉模型*中，我们将看到如何将这些信息直接输入到
    Amazon SageMaker 中内置的计算机视觉算法。当然，我们也可以解析这些信息，并根据我们用于训练计算机视觉模型的框架进行转换。
- en: As you can see, SageMaker Ground Truth makes it easy to label image datasets.
    You just need to upload your data to S3 and create a workforce. Ground Truth will
    then distribute the work automatically, and store the results in S3.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，SageMaker Ground Truth 使得标注图像数据集变得非常简单。您只需要将数据上传到 S3 并创建一个工作团队。Ground Truth
    将自动分配任务，并将结果存储在 S3 中。
- en: We just saw how to label images, but what about text tasks? Well, they're equally
    easy to set up and run. Let's go through an example.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚看到如何标注图像，那么文本任务呢？嗯，它们同样容易设置和运行。让我们通过一个示例来了解。
- en: Labeling text
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标注文本
- en: This is a quick example of labeling text for named entity recognition. The dataset
    is made up of text fragments from one of my blog posts, where we'd like to label
    all AWS service names. These are available in our GitHub repository.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个标注命名实体识别文本的快速示例。数据集由我博客文章中的一些文本片段组成，我们希望标注所有 AWS 服务名称。这些内容可以在我们的 GitHub
    仓库中找到。
- en: 'We will start labeling text using the following steps:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下步骤开始标注文本：
- en: 'First, let''s upload text fragments to S3 with the following line of code:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们使用以下代码将文本片段上传到 S3：
- en: '[PRE2]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Just like in the previous example, we configure a text labeling job, set up
    input data, and select an IAM role, as shown in the following screenshot:![Figure
    2.13 – Creating a text labeling job
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就像在前面的示例中，我们配置了一个文本标注任务，设置了输入数据并选择了一个 IAM 角色，截图如下所示：![图 2.13 – 创建文本标注任务
- en: '](img/B17705_02_013.jpg)'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_013.jpg)'
- en: Figure 2.13 – Creating a text labeling job
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.13 – 创建文本标注任务
- en: Then, we select **Text** as the category, and **Named entity recognition** as
    the task.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们选择**文本**作为类别，选择**命名实体识别**作为任务。
- en: On the next screen, shown in the following screenshot, we simply select our
    private team again, add a label, and enter instructions:![Figure 2.14 – Setting
    up instructions
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个屏幕上，截图如下所示，我们只需再次选择我们的私有团队，添加标签并输入指令：![图 2.14 – 设置指令
- en: '](img/B17705_02_014.jpg)'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_014.jpg)'
- en: Figure 2.14 – Setting up instructions
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.14 – 设置指令
- en: Once the job is ready, we log in to the worker console and start labeling. You
    can see a labeled example in the following screenshot:![Figure 2.15 – Labeling
    text
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦任务准备好，我们登录到工作控制台并开始标注。您可以在以下截图中看到一个标注示例：![图 2.15 – 标注文本
- en: '](img/B17705_02_015.jpg)'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_015.jpg)'
- en: Figure 2.15 – Labeling text
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.15 – 标注文本
- en: We're done quickly, and we can find the labeling information in our S3 bucket.
    For each sample, we see a start offset, an end offset, and a label for each labeled
    entity.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们很快就完成了任务，并且可以在我们的 S3 存储桶中找到标注信息。对于每个样本，我们可以看到起始偏移量、结束偏移量以及每个标注实体的标签。
- en: Amazon SageMaker Ground Truth really makes it easy to label datasets at scale.
    It has many nice features including job chaining and custom workflows, which I
    encourage you to explore at [https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html](https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker Ground Truth 使得大规模标注数据集变得非常简单。它有许多不错的功能，包括任务链和自定义工作流，强烈建议您访问
    [https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html](https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html)
    进一步了解。
- en: Now that we know how to label datasets, let's see how we can easily transform
    data interactively with Amazon SageMaker Data Wrangler.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何标注数据集了，接下来让我们看看如何使用 Amazon SageMaker Data Wrangler 轻松地交互式转换数据。
- en: Transforming data with Amazon SageMaker Data Wrangler
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker Data Wrangler 转换数据
- en: 'Collecting and labeling data samples is only the first step in preparing a
    dataset. Indeed, it''s very likely that you''ll have to pre-process your dataset
    in order to do the following, for example:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 收集和标注数据样本只是准备数据集的第一步。实际上，您很可能需要预处理数据集，以便进行如下操作：
- en: Convert it to the input format expected by the machine learning algorithm you're
    using.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将其转换为您所使用的机器学习算法所期望的输入格式。
- en: Rescale or normalize numerical features.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数值特征进行缩放或标准化。
- en: Engineer higher-level features, for example, one-hot encoding.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工程更高级的特征，例如，一热编码（One-Hot Encoding）。
- en: Clean and tokenize text for natural language processing applications
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清理并标记文本，以用于自然语言处理应用程序
- en: In the early stage of a machine learning project, it's not always obvious which
    transformations are required, or which ones are most efficient. Thus, practioners
    often need to experiment with lots of different combinations, transforming data
    in many different ways, training models, and evaluating results.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习项目的早期阶段，通常不容易明确需要哪些数据转换，或者哪些转换最为高效。因此，实践者通常需要尝试不同的组合，采用多种方式转换数据，训练模型，并评估结果。
- en: In this section, we're going to learn about **Amazon SageMaker Data Wrangler**,
    a graphical interface integrated in SageMaker Studio that makes it very easy to
    transform data, and to export results to a variety of Jupyter notebooks.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习**Amazon SageMaker Data Wrangler**，这是一个集成在SageMaker Studio中的图形界面，使得数据转换变得非常简单，并且能够将结果导出到多种Jupyter笔记本中。
- en: Loading a dataset in SageMaker Data Wrangler
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在SageMaker Data Wrangler中加载数据集
- en: First, we need a dataset. We'll use the direct marketing dataset published by
    S. Moro, P. Cortez, and P. Rita in "A Data-Driven Approach to Predict the Success
    of Bank Telemarketing", *Decision Support Systems*, Elsevier, 62:22-31, June 2014.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一个数据集。我们将使用由S. Moro、P. Cortez和P. Rita在《A Data-Driven Approach to Predict
    the Success of Bank Telemarketing》中发布的直接营销数据集，*Decision Support Systems*，Elsevier，62:22-31，2014年6月。
- en: 'This dataset describes a binary classification problem: will a customer accept
    a marketing offer, yes or no? It contains a little more than 41,000 customer samples,
    and labels are stored in the **y** column.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集描述了一个二分类问题：客户是否会接受营销优惠，接受或不接受？它包含了超过41,000个客户样本，标签存储在**y**列中。
- en: 'We will get started using the following steps:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照以下步骤开始使用：
- en: 'Using the AWS command line, let''s download the dataset, extract it, and copy
    it to the default SageMaker bucket for the region we''re running in (it should
    have been created automatically). You can run this on your local machine or in
    a Jupyter terminal:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用AWS命令行，我们将下载数据集，解压并将其复制到我们所在区域的默认SageMaker桶中（它应该已自动创建）。你可以在本地机器或Jupyter终端中运行此操作：
- en: '[PRE3]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In SageMaker Studio, we create a new Data Wrangler flow with **File** | **New**
    | **Data Wrangler Flow** to create. The following screenshot shows the Data Wrangler
    image being loaded:![Figure 2.16 – Loading Data Wrangler
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在SageMaker Studio中，我们通过**文件** | **新建** | **Data Wrangler流**来创建新的Data Wrangler流。以下截图展示了Data
    Wrangler图像正在加载：![图2.16 – 加载Data Wrangler
- en: '](img/B17705_02_016.jpg)'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_016.jpg)'
- en: Figure 2.16 – Loading Data Wrangler
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.16 – 加载Data Wrangler
- en: Once Data Wrangler is ready, the **Import** screen opens. We also see the Data
    Wrangler image in the left-hand pane, as shown in the next screenshot:![Figure
    2.17 – Opening Data Wrangler
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦Data Wrangler准备就绪，**导入**屏幕将打开。我们还可以在左侧窗格中看到Data Wrangler图像，如下一个截图所示：![图2.17
    – 打开Data Wrangler
- en: '](img/B17705_02_017.jpg)'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_017.jpg)'
- en: Figure 2.17 – Opening Data Wrangler
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.17 – 打开Data Wrangler
- en: We can import data from S3, Athena or Redshift (by clicking on **Add data source**).
    Here, we click on S3.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以从S3、Athena或Redshift导入数据（点击**添加数据源**）。在这里，我们点击S3。
- en: As shown in the following screenshot, we can easily locate the dataset that
    we just uploaded. Let's click on it.![Figure 2.18 – Locating a dataset
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如下截图所示，我们可以轻松定位到我们刚刚上传的数据集。点击它即可：![图2.18 – 定位数据集
- en: '](img/B17705_02_018.jpg)'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_018.jpg)'
- en: Figure 2.18 – Locating a dataset
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.18 – 定位数据集
- en: This opens a preview of the dataset, as shown in the next screenshot:![Figure
    2.19 – Previewing a dataset
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将打开数据集的预览，如下一个截图所示：![图2.19 – 预览数据集
- en: '](img/B17705_02_019.jpg)'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_019.jpg)'
- en: Figure 2.19 – Previewing a dataset
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.19 – 预览数据集
- en: Let's just click on **Import**, which opens the **Prepare** view, as shown in
    the next screenshot:![Figure 2.20 – Previewing a dataset
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们点击**导入**，这将打开**准备**视图，如下一个截图所示：![图2.20 – 预览数据集
- en: '](img/B17705_02_020.jpg)'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_020.jpg)'
- en: Figure 2.20 – Previewing a dataset
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.20 – 预览数据集
- en: Clicking on the **+** icon, we could add more data sources, joining them or
    concatenating them to our dataset. We could also edit data types for all columns,
    should Data Wrangler have detected them incorrectly. Instead, let's select **Add
    analysis** to visualize properties of our dataset. This opens the **Analyze view**,
    visible in the next screenshot:![Figure 2.21 – Visualizing a dataset
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**+**图标，我们可以添加更多的数据源，将它们与我们的数据集连接或拼接。如果Data Wrangler错误地检测了数据类型，我们也可以编辑所有列的数据类型。否则，我们可以选择**添加分析**，以可视化我们数据集的属性。这将打开**分析视图**，如下图所示：![图2.21
    – 可视化数据集
- en: '](img/B17705_02_021.jpg)'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_021.jpg)'
- en: Figure 2.21 – Visualizing a dataset
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.21 – 可视化数据集
- en: The next screenshot shows a scatter plot on duration vs. age. See how easy this
    is? You can experiment by selecting different columns, click on **Preview** to
    see results, and click on **Save** to create the analysis and save it for further
    use.![Figure 2.22 – Building a scatter plot
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一张截图显示了一个关于持续时间与年龄的散点图。看起来是不是很简单？你可以通过选择不同的列进行实验，点击**预览**查看结果，然后点击**保存**来创建分析并保存以供后续使用。![图
    2.22 – 构建散点图
- en: '](img/B17705_02_022.jpg)'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_022.jpg)'
- en: Figure 2.22 – Building a scatter plot
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.22 – 构建散点图
- en: On top of histograms and scatter plots, we can also build **Table Summary**,
    **Bias Analysis**, and **Target Leakage** reports. Let's build the latter to find
    out if certain columns are either leaking into the prediction, or not helpful
    at all. You can see the report in the next screenshot:![Figure 2.23 – Building
    a target leakage report
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了直方图和散点图，我们还可以构建**表格摘要**、**偏差分析**和**目标泄漏**报告。我们来构建后者，查看是否某些列泄漏到预测中，或者根本没有任何帮助。你可以在下图中看到该报告：![图
    2.23 – 构建目标泄漏报告
- en: '](img/B17705_02_023.jpg)'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_023.jpg)'
- en: Figure 2.23 – Building a target leakage report
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.23 – 构建目标泄漏报告
- en: 'This report tells us that no column is leaking (all scores are lower than 1).
    Several columns are also not useful in predicting the target (some scores are
    0.5 or lower): we should probably drop these columns during data processing.'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该报告告诉我们没有列发生泄漏（所有分数都低于 1）。一些列在预测目标时也没有什么用（某些分数为 0.5 或更低）：我们可能需要在数据处理过程中丢弃这些列。
- en: We could also try the **Quick Model** report, which trains a model using a **Random
    Forest** algorithm implemented with Spark, right in SageMaker Studio. Unfortunately,
    an error message pops up, complaining about column names. Indeed, some column
    names include a dot, which is not allowed by Spark. No problem, we can easily
    fix this during data processing, and build the report later.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以尝试**快速模型**报告，该报告使用在 SageMaker Studio 中实现的**随机森林**算法训练模型。不幸的是，弹出一个错误消息，抱怨列名不符合要求。确实，一些列名中包含点号，而
    Spark 不允许这种格式。没问题，我们可以在数据处理过程中轻松修复这个问题，然后稍后再构建报告。
- en: In fact, let's move on to transforming data with Data Wrangler.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，让我们继续使用数据处理工具 Data Wrangler 来转换数据。
- en: Transforming a dataset in SageMaker Data Wrangler
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 SageMaker Data Wrangler 中转换数据集
- en: Data Wrangler includes hundreds of built-in transforms, and we can also add
    our own.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Data Wrangler 包含数百种内置转换，我们也可以添加自己的转换。
- en: Starting from the **Prepare** view visible in the next screenshot, we click
    on the **+** icon to add transforms.![Figure 2.24 – Adding a transform
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从下图所示的**准备**视图开始，我们点击**+**图标以添加转换。![图 2.24 – 添加转换
- en: '](img/B17705_02_024.jpg)'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_024.jpg)'
- en: Figure 2.24 – Adding a transform
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.24 – 添加转换
- en: This opens the list of transforms, shown in the next screenshot. Take a minute
    to explore them.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将打开转换列表，如下图所示。花点时间来浏览它们。
- en: Let's start by dropping the columns flagged as useless in the `marital`, `day
    of week`, `month`, `housing`, `cons.conf.idx`, `nr.employed`, `cons.price.idx`.
    We click on `marital` column. Your screen should look like the following screenshot:![Figure
    2.25 – Dropping a column
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从删除标记为无用的列开始，这些列包括`marital`、`day of week`、`month`、`housing`、`cons.conf.idx`、`nr.employed`、`cons.price.idx`。我们点击`marital`列。你的屏幕应该如下所示：![图
    2.25 – 删除列
- en: '](img/B17705_02_025.jpg)'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_025.jpg)'
- en: Figure 2.25 – Dropping a column
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.25 – 删除列
- en: We can preview results and add the transform to our pipeline. We'll repeat the
    same operations for the other columns we want to drop.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以预览结果并将转换添加到管道中。我们将对其他需要删除的列重复相同的操作。
- en: Now, let's remove these annoying dots in column names, replacing them with underscores.
    The easiest way to do this is to use a `df`.![Figure 2.26 – Applying a custom
    transform
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们删除列名中的这些恼人的点号，用下划线替换它们。最简单的做法是使用`df`。![图 2.26 – 应用自定义转换
- en: '](img/B17705_02_026.jpg)'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_026.jpg)'
- en: Figure 2.26 – Applying a custom transform
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.26 – 应用自定义转换
- en: Jumping back to the **Analyze** view, and clicking on **Steps**, we can see
    the list of transforms that we've already applied, as shown in the next screenshot.
    We could also delete each transform by clicking on the icon to the right of it.![Figure
    2.27 – Viewing a pipeline
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回到**分析**视图，点击**步骤**，我们可以看到已经应用的转换列表，如下图所示。我们也可以通过点击每个转换右侧的图标来删除它。![图 2.27 –
    查看管道
- en: '](img/B17705_02_027.jpg)'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_027.jpg)'
- en: Figure 2.27 – Viewing a pipeline
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.27 – 查看管道
- en: Clicking on the `y` label, as shown in the next screenshot. The F1 score for
    this classification model is 0.881, and the most important features are `duration`,
    `euribor3m`, and `pdays`. By applying more transforms and building a quick model
    again, we can iteratively measure the positive impact (or the lack thereof) of
    our feature engineering steps.![Figure 2.28 – Building a quick model
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `y` 标签，如下一个截图所示。该分类模型的 F1 分数为 0.881，最重要的特征是 `duration`、`euribor3m` 和 `pdays`。通过应用更多的转换并再次构建快速模型，我们可以迭代地衡量我们的特征工程步骤的积极影响（或缺乏影响）。![图
    2.28 – 构建快速模型
- en: '](img/B17705_02_028.jpg)'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_028.jpg)'
- en: Figure 2.28 – Building a quick model
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.28 – 构建快速模型
- en: Coming back to the `job` and `education`. We decide to encode them to help algorithms
    understand that the different values are different dimensions to the problem.
    Starting with `job`, we apply the `job` column is automatically dropped.![Figure
    2.29 – One-hot encoding a column
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回到 `job` 和 `education`。我们决定对它们进行编码，以帮助算法理解不同的值是问题的不同维度。从 `job` 开始，我们应用 `job`
    列，然后该列会自动删除。![图 2.29 – 对某列进行独热编码
- en: '](img/B17705_02_029.jpg)'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_029.jpg)'
- en: Figure 2.29 – One-hot encoding a column
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.29 – 对某列进行独热编码
- en: The `job_admin.` column name contains a dot! We can remove it with the `education`
    column… and remove the dots in column names. We could apply **Process numeric**
    transforms to scale and normalize numerical columns, but let's stop there for
    now. Feel free to explore and experiment!
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`job_admin.` 列名中包含一个点！我们可以通过 `education` 列来移除它…并移除列名中的点。我们本可以应用**处理数字**转换来缩放和标准化数值列，但现在先停在这里。随时可以继续探索和实验！'
- en: 'One last thing: Data Wrangler workflows are stored in `.flow` files, visible
    in the Jupyter file view. These are JSON files that you can (and should) store
    in your Git repositories, in order to reuse them later and share them with other
    team members.'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一点：Data Wrangler 工作流存储在 `.flow` 文件中，可以在 Jupyter 文件视图中查看。这些是 JSON 文件，您可以（并且应该）将其存储在
    Git 仓库中，以便以后重用并与其他团队成员共享。
- en: Now that our pipeline is ready, let's see how we can export it to Python code.
    All it takes is a single click, and we won't have to write a single line of code.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的管道已准备好，让我们看看如何将其导出为 Python 代码。只需要单击一次，我们就不需要写任何代码。
- en: Exporting a SageMaker Data Wrangler pipeline
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导出 SageMaker Data Wrangler 管道
- en: 'Data Wrangler makes it easy to export a pipeline in four ways:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Data Wrangler 使导出管道变得容易，提供四种方式：
- en: Plain Python code that you can readily include in your machine learning project.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纯 Python 代码，您可以直接将其包含到您的机器学习项目中。
- en: A Jupyter notebook running a SageMaker Processing job, which will apply the
    pipeline to your dataset and save results in S3\. The notebook also includes optional
    code to train a model.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行 SageMaker 处理任务的 Jupyter notebook，它将把管道应用于您的数据集并将结果保存到 S3 中。该 notebook 还包括用于训练模型的可选代码。
- en: A Jupyter notebook storing the processed dataset in SageMaker Feature Store.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个将处理后数据集存储在 SageMaker Feature Store 中的 Jupyter notebook。
- en: A Jupyter notebook creating a SageMaker Pipelines workflow, with steps to process
    your dataset and train a model on it.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个创建 SageMaker Pipelines 工作流的 Jupyter notebook，包含处理数据集和在其上训练模型的步骤。
- en: 'OK, let''s go for it:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们开始吧：
- en: Starting from the **Export** view, we click on Steps and select the steps we'd
    like to export. Here, I selected them all, as shown in the next screenshot:![Figure
    2.30 – Selecting steps to export
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从**导出**视图开始，我们点击“步骤”并选择我们想要导出的步骤。在这里，我选择了所有步骤，如下一个截图所示：![图 2.30 – 选择要导出的步骤
- en: '](img/B17705_02_030.jpg)'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_030.jpg)'
- en: Figure 2.30 – Selecting steps to export
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.30 – 选择要导出的步骤
- en: Then, we simply click on **Export step** and select one of the four options.
    Here, I go for **Save to S3** in order to run a SageMaker Processing job.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们只需点击**导出步骤**并选择四个选项中的一个。在这里，我选择了**保存到 S3**，以便运行 SageMaker 处理任务。
- en: This opens a new notebook. We'll discuss SageMaker Processing in the next section,
    but let's go ahead and run the job. Once the Job Status & S3 Output Location cell
    is complete, our dataset is available in S3, as visible in the next screenshot:![Figure
    2.31 – Locating the processed dataset in S3
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将打开一个新的 notebook。我们将在下一节讨论 SageMaker Processing，但现在让我们继续运行任务。一旦“任务状态与 S3 输出位置”单元格完成，我们的数据集就可以在
    S3 中使用，如下一个截图所示：![图 2.31 – 在 S3 中定位处理后的数据集
- en: '](img/B17705_02_031.jpg)'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_031.jpg)'
- en: Figure 2.31 – Locating the processed dataset in S3
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.31 – 在 S3 中定位处理后的数据集
- en: Downloading and opening the CSV file stored at this location, we see that it
    contains the processed dataset, as shown in the next screenshot. In a typical
    machine learning workflow, we would then use this data directly to train a model.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并打开存储在此位置的CSV文件，我们看到它包含了处理过的数据集，如下一张截图所示。在典型的机器学习工作流中，我们随后将直接使用这些数据来训练模型。
- en: '![Figure 2.32 – Viewing the processed dataset'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 2.32 – Viewing the processed dataset'
- en: '](img/B17705_02_032.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17705_02_032.jpg)'
- en: Figure 2.32 – Viewing the processed dataset
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 2.32 – Viewing the processed dataset
- en: As you can see, SageMaker Data Wrangler makes it very easy (and even fun) to
    apply transforms to your datasets. Once you're done, you can immediately export
    them to Python code, without having to write a single line of code.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，SageMaker数据处理非常简单（甚至有趣），可以轻松应用转换到您的数据集。完成后，您可以立即将它们导出为Python代码，无需编写任何代码。
- en: In the next section, we're going to learn about Amazon SageMaker Processing,
    a great way run batch jobs for data processing and other machine learning tasks.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将学习关于Amazon SageMaker处理（Processing）的内容，这是一个执行批处理数据处理和其他机器学习任务的绝佳方式。
- en: Running batch jobs with Amazon SageMaker Processing
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Amazon SageMaker处理运行批处理作业
- en: As discussed in the previous section, datasets usually need quite a bit of work
    to be ready for training. Once training is complete, you may also want to run
    additional jobs to post-process the predicted data and to evaluate your model
    on different datasets.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如前节所述，数据集通常需要大量工作才能准备好进行训练。一旦训练完成，您可能还希望运行额外的作业来后处理预测数据并评估您的模型在不同数据集上的表现。
- en: Once the experimentation phase is complete, it's good practice to start automating
    all these jobs, so that you can run them on demand with little effort.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦实验阶段完成，最好开始自动化所有这些作业，这样您就可以随需求轻松运行它们。
- en: Discovering the Amazon SageMaker Processing API
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索Amazon SageMaker处理API
- en: The Amazon SageMaker Processing API is part of the SageMaker SDK, which we installed
    in [*Chapter 1*](B17705_01_Final_JM_ePub.xhtml#_idTextAnchor013)*, Introducing
    Amazon SageMaker*.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker处理API是SageMaker SDK的一部分，我们在[*Chapter 1*](B17705_01_Final_JM_ePub.xhtml#_idTextAnchor013)*，Introducing
    Amazon SageMaker*中安装了该SDK。
- en: 'SageMaker Processing jobs run inside Docker containers:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker处理作业运行在Docker容器内部：
- en: A built-in container for **scikit-learn** ([https://scikit-learn.org](https://scikit-learn.org))
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个内置的**scikit-learn**容器（[https://scikit-learn.org](https://scikit-learn.org)）
- en: A built-in container for **PySpark** ([https://spark.apache.org/docs/latest/api/python/](https://spark.apache.org/docs/latest/api/python/)),
    which supports distributed training
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个内置的**PySpark**容器（[https://spark.apache.org/docs/latest/api/python/](https://spark.apache.org/docs/latest/api/python/)），支持分布式训练
- en: Your own custom container
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您自己的自定义容器
- en: Logs are available in `/aws/sagemaker/ProcessingJobs` log group.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 日志可在`/aws/sagemaker/ProcessingJobs`日志组中找到。
- en: Let's first see how we can use scikit-learn and SageMaker Processing to prepare
    a dataset for training.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看看如何使用scikit-learn和SageMaker处理准备数据集进行训练。
- en: Processing a dataset with scikit-learn
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用scikit-learn处理数据集
- en: 'Here''s the high-level process:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是高级流程：
- en: Upload your unprocessed dataset to Amazon S3.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将您的未加工数据集上传到Amazon S3。
- en: Write a script with scikit-learn in order to load the dataset, process it, and
    save the processed features and labels.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用scikit-learn编写脚本以加载数据集，处理它，并保存处理过的特征和标签。
- en: Run this script with SageMaker Processing on managed infrastructure.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SageMaker处理在托管基础设施上运行此脚本。
- en: Uploading the dataset to Amazon S3
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将数据集上传到Amazon S3
- en: We're going to reuse the direct marketing dataset introduced in the previous
    section, and apply our own transforms.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重用前一节介绍的直接营销数据集，并应用我们自己的转换。
- en: 'Creating a new Jupyter notebook, let''s first download and extract the dataset:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Jupyter笔记本，让我们首先下载并提取数据集：
- en: '[PRE4]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, we load it with `pandas`:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们用`pandas`加载它：
- en: '[PRE5]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, let''s display the first five lines:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们显示前五行：
- en: '[PRE6]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This prints out the table visible in the following figure:'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'This prints out the table visible in the following figure:'
- en: '![Figure 2.33 – Viewing the dataset'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![Figure 2.33 – Viewing the dataset'
- en: '](img/B17705_02_033.jpg)'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_033.jpg)'
- en: Figure 2.33 – Viewing the dataset
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Figure 2.33 – Viewing the dataset
- en: Scrolling to the right, we can see a column named **y**, storing the labels.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 向右滚动，我们可以看到一个名为**y**的列，存储了标签。
- en: 'Now, let''s upload the dataset to Amazon S3\. We''ll use a default bucket automatically
    created by SageMaker in the region we''re running in. We''ll just add a prefix
    to keep things nice and tidy:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将数据集上传到Amazon S3\. 我们将使用SageMaker在我们运行的区域自动创建的默认存储桶。我们只需添加前缀以保持事务井然有序：
- en: '[PRE7]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Writing a processing script with scikit-learn
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 编写处理脚本
- en: As SageMaker Processing takes care of all infrastructure concerns, we can focus
    on the script itself. SageMaker Processing will also automatically copy the input
    dataset from S3 into the container, and the processed datasets from the container
    to S3\.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 SageMaker Processing 负责所有基础设施工作，我们可以专注于脚本本身。SageMaker Processing 还会自动将输入数据集从
    S3 复制到容器内，并将处理后的数据集从容器复制到 S3：
- en: 'Container paths are provided when we configure the job itself. Here''s what
    we''ll use:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 配置作业时，我们会提供容器路径。以下是我们将使用的路径：
- en: 'The input dataset: `/opt/ml/processing/input`'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入数据集：`/opt/ml/processing/input`
- en: 'The processed training set: `/opt/ml/processing/train`'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理后的训练集：`/opt/ml/processing/train`
- en: 'The processed test set: `/opt/ml/processing/test`'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理后的测试集：`/opt/ml/processing/test`
- en: 'In our Jupyter environment, let''s start writing a new Python file named `preprocessing.py`.
    As you would expect, this script will load the dataset, perform basic feature
    engineering, and save the processed dataset:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 Jupyter 环境中，让我们开始编写一个新的 Python 文件，名为`preprocessing.py`。正如你所期待的，这个脚本将加载数据集，执行基本的特征工程，并保存处理后的数据集：
- en: 'First, we read our single command-line parameter with the `argparse` library
    ([https://docs.python.org/3/library/argparse.html](https://docs.python.org/3/library/argparse.html)):
    the ratio for the training and test datasets. The actual value will be passed
    to the script by the SageMaker Processing SDK:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们使用`argparse`库（[https://docs.python.org/3/library/argparse.html](https://docs.python.org/3/library/argparse.html)）读取我们的单个命令行参数：训练集和测试集的比例。实际值将通过
    SageMaker Processing SDK 传递给脚本：
- en: '[PRE8]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We load the input dataset using `pandas`. At startup, SageMaker Processing
    automatically copied it from S3 to a user-defined location inside the container,
    `/opt/ml/processing/input`:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`pandas`加载输入数据集。在启动时，SageMaker Processing 会自动将其从 S3 复制到容器内的用户定义位置`/opt/ml/processing/input`：
- en: '[PRE9]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then, we remove any line with missing values, as well as duplicate lines:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们删除任何缺失值的行，以及重复的行：
- en: '[PRE10]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, we count negative and positive samples, and display the class ratio.
    This will tell us how unbalanced the dataset is:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们统计负样本和正样本，并显示类别比例。这将告诉我们数据集的不平衡程度：
- en: '[PRE11]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Looking at the dataset, we can see a column named `pdays`, telling us how long
    ago a customer has been contacted. Some lines have a 999 value, and that looks
    pretty suspicious: indeed, this is a placeholder value meaning that a customer
    has never been contacted. To help the model understand this assumption, let''s
    add a new column stating it explicitly:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看数据集，我们可以看到有一列名为`pdays`，表示客户最后一次联系的时间。有些行的值为999，这看起来相当可疑：实际上，这个值是一个占位符，表示该客户从未被联系过。为了帮助模型理解这一假设，我们将添加一个新列，明确指出这一点：
- en: '[PRE12]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In the job column, we can see three categories (`student`, `retired`, and `unemployed`)
    that should probably be grouped to indicate that these customers don''t have a
    full-time job. Let''s add another column:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在职位列中，我们可以看到三种类别（`student`、`retired` 和 `unemployed`），它们可能应该合并在一起，表示这些客户没有全职工作。我们来添加另一列：
- en: '[PRE13]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now, let''s split the dataset into training and test sets. Scikit-learn has
    a convenient API for this, and we set the split ratio according to a command-line
    argument passed to the script:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将数据集拆分为训练集和测试集。Scikit-learn 提供了一个方便的 API，我们根据传递给脚本的命令行参数来设置拆分比例：
- en: '[PRE14]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The next step is to scale numerical features and to one-hot encode the categorical
    features. We''ll use `StandardScaler` for the former, and `OneHotEncoder` for
    the latter:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是对数值特征进行缩放，并对分类特征进行独热编码。我们将使用`StandardScaler`来处理数值特征，使用`OneHotEncoder`来处理分类特征：
- en: '[PRE15]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then, we process the training and test datasets:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们处理训练集和测试集：
- en: '[PRE16]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Finally, we save the processed datasets, separating the features and labels.
    They''re saved to user-defined locations in the container, and SageMaker Processing
    will automatically copy the files to S3 before terminating the job:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们保存处理后的数据集，将特征和标签分开。它们被保存到容器内用户定义的位置，SageMaker Processing 会在作业结束前自动将文件复制到
    S3：
- en: '[PRE17]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: That's it. As you can see, this code is vanilla scikit-learn, so it shouldn't
    be difficult to adapt your own scripts for SageMaker Processing. Now let's see
    how we can actually run this.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。如你所见，这段代码是标准的 scikit-learn，因此将自己的脚本适配到 SageMaker Processing 并不困难。现在，让我们看看如何实际运行这个过程。
- en: Running a processing script
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行处理脚本
- en: 'Coming back to our Jupyter notebook, we use the `SKLearnProcessor` object from
    the SageMaker SDK to configure the processing job:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的 Jupyter 笔记本，我们使用 SageMaker SDK 中的`SKLearnProcessor`对象来配置处理作业：
- en: 'First, we define which version of scikit-learn we want to use, and what our
    infrastructure requirements are. Here, we go for an `ml.m5.xlarge` instance, an
    all-round good choice:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们定义要使用的 scikit-learn 版本和我们的基础设施需求。在这里，我们选择一个 `ml.m5.xlarge` 实例，这是一个多功能的良好选择：
- en: '[PRE18]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, we simply launch the job, passing the name of the script, the dataset
    input path in S3, the user-defined dataset paths inside the SageMaker Processing
    environment, and the command-line arguments:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们只需启动作业，传递脚本的名称、S3 中数据集的输入路径、SageMaker Processing 环境中用户定义的数据集路径以及命令行参数：
- en: '[PRE19]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As the job starts, SageMaker automatically provisions a managed `ml.m5.xlarge`
    instance, pulls the appropriate container to it, and runs our script inside the
    container. Once the job is complete, the instance is terminated, and we only pay
    for the amount of time we used it. There is zero infrastructure management, and
    we'll never leave idle instances running for no reason.
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当作业开始时，SageMaker 会自动配置一个托管的 `ml.m5.xlarge` 实例，将适当的容器拉取到该实例，并在容器内运行我们的脚本。一旦作业完成，实例会被终止，我们只需为实际使用的时间付费。完全无需管理基础设施，也不会因为没有理由而让空闲实例长时间运行。
- en: 'After a few minutes, the job is complete, and we can see the output of the
    script as follows:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 几分钟后，作业完成，我们可以看到脚本的输出如下：
- en: '[PRE20]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The following screenshot shows the same log in **CloudWatch**:'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图显示了 **CloudWatch** 中的相同日志：
- en: '![Figure 2.34 – Viewing the log in CloudWatch Logs'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.34 – 在 CloudWatch Logs 中查看日志'
- en: '](img/B17705_02_034.jpg)'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_02_034.jpg)'
- en: Figure 2.34 – Viewing the log in CloudWatch Logs
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.34 – 在 CloudWatch Logs 中查看日志
- en: 'Finally, we can describe the job and see the location of the processed datasets:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以描述作业并查看处理后的数据集位置：
- en: '[PRE21]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This results in the following output:'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE22]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In a terminal, we can use the AWS CLI to fetch the processed training set located
    at the preceding path, and take a look at the first sample and label:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在终端中，我们可以使用 AWS CLI 获取位于前述路径的处理过的训练集，并查看第一个样本和标签：
- en: '[PRE23]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now that the dataset has been processed with our own code, we could use it to
    train a machine learning model. In real life, we would also automate these steps
    instead of running them manually inside a notebook.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据集已经用我们的代码处理完成，我们可以用它来训练一个机器学习模型。在实际应用中，我们还会自动化这些步骤，而不是手动在笔记本中运行。
- en: Important Note
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'One last thing: here, our job writes output data to S3\. SageMaker Processing
    also supports writing directly to an existing Feature Group in **SageMaker Feature
    Store** (which we''ll introduce later in the book). API details are available
    at [https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ProcessingOutput](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ProcessingOutput).'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个要点：在这里，我们的作业将输出数据写入 S3。SageMaker Processing 还支持直接写入现有的 **SageMaker Feature
    Store** 中的 Feature Group（我们将在本书后面介绍）。API 详细信息可以在 [https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ProcessingOutput](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ProcessingOutput)
    中查看。
- en: Processing a dataset with your own code
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用你自己的代码处理数据集
- en: In the previous example, we used a built-in container to run our scikit-learn
    code. SageMaker Processing also makes it possible to use your own container. You
    can find an example at [https://docs.aws.amazon.com/sagemaker/latest/dg/build-your-own-processing-container.html](https://docs.aws.amazon.com/sagemaker/latest/dg/build-your-own-processing-container.html).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们使用了一个内置容器来运行我们的 scikit-learn 代码。SageMaker Processing 还支持使用自定义容器。你可以在
    [https://docs.aws.amazon.com/sagemaker/latest/dg/build-your-own-processing-container.html](https://docs.aws.amazon.com/sagemaker/latest/dg/build-your-own-processing-container.html)
    找到一个示例。
- en: As you can see, SageMaker Processing makes it really easy to run data processing
    jobs. You can focus on writing and running your script, without having to worry
    about provisioning and managing infrastructure.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，SageMaker Processing 使得运行数据处理作业变得非常简单。你可以专注于编写和运行脚本，而无需担心基础设施的配置和管理。
- en: Summary
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned how Amazon SageMaker Ground Truth helps you build
    highly accurate training datasets using image and text labeling workflows. We'll
    see in [*Chapter 5*](B17705_05_Final_JM_ePub.xhtml#_idTextAnchor091)*,* *Training
    Computer Vision Models*, how to use image datasets labeled with Ground Truth.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了 Amazon SageMaker Ground Truth 如何帮助你通过图像和文本标注工作流构建高度准确的训练数据集。我们将在 [*第
    5 章*](B17705_05_Final_JM_ePub.xhtml#_idTextAnchor091) 中看到如何使用通过 Ground Truth 标注的图像数据集来训练计算机视觉模型。
- en: 'Then, you learned about Amazon SageMaker Processing, a capability that helps
    you run your own data processing workloads on managed infrastructure: feature
    engineering, data validation, model evaluation, and so on.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你了解了 Amazon SageMaker 处理功能，这是一个帮助你在托管基础设施上运行自定义数据处理工作负载的能力：特征工程、数据验证、模型评估等等。
- en: Finally, we discussed three other AWS services (Amazon EMR, AWS Glue, and Amazon
    Athena), and how they could fit into your analytics and machine learning workflows.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们讨论了另外三个 AWS 服务（Amazon EMR、AWS Glue 和 Amazon Athena），以及它们如何融入到你的分析和机器学习工作流中。
- en: In the next chapter, we'll start training models using the built-in machine
    learning models of Amazon SageMaker.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将开始使用 Amazon SageMaker 内置的机器学习模型来训练模型。
