- en: Homogenous Ensemble for Multiclass Classification Using Keras
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Keras进行多类分类的同质集成
- en: 'In this chapter, we''ll cover the following recipe:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下配方：
- en: An ensemble of homogeneous models to classify fashion products
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用于分类时尚产品的同质模型集成
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: Many studies have been done in classification problems to find out how to obtain
    better classification accuracy. This problem tends to be more complex when there's
    a large number of classes on which to make a prediction. In the case of multiclass
    classification, it's assumed that each class in the target variable are independent
    of each other. A multiclass classification technique involves training one or
    more models to classify a target variable that can take more than two classes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类问题中，许多研究已经进行了，以找出如何获得更好的分类准确率。当有大量类别需要预测时，这个问题往往更加复杂。在多类分类的情况下，假设目标变量中的每个类别都是相互独立的。多类分类技术涉及训练一个或多个模型来分类目标变量，该变量可以超过两个类别。
- en: An ensemble of homogeneous models to classify fashion products
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个用于分类时尚产品的同质模型集成
- en: 'In this example, we''ll use the Fashion-MNIST dataset. This dataset has 60,000
    images of fashion products from ten categories. The target variable can be classified
    into ten classes:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用Fashion-MNIST数据集。这个数据集包含来自十个类别的60,000个时尚产品图像。目标变量可以被分类为十个类别：
- en: T-shirt/top
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: T恤/上衣
- en: Trouser
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 裤子
- en: Pullover
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开衫
- en: Dress
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服装
- en: Coat
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外套
- en: Sandal
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 凉鞋
- en: Shirt
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 衬衫
- en: Sneakers
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运动鞋
- en: Bag
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 袋
- en: Ankle boot
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 靴子
- en: Each image is a 28 x 28 grayscale image. We will proceed by reading the data
    to build a few homogeneous models over a few iterations to see whether the ensemble
    can deliver a higher accuracy.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 每个图像都是一个28 x 28的灰度图像。我们将通过读取数据，在几次迭代中构建几个同质模型，以查看集成是否可以提供更高的准确率。
- en: Getting ready
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We'll use Google Colab to train our models. Google Colab comes with TensorFlow
    installed, so we don't have to install it separately in our system.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Google Colab来训练我们的模型。Google Colab自带TensorFlow，所以我们不需要在我们的系统中单独安装它。
- en: 'We import the required libraries as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下方式导入所需的库：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We load our data from the datasets that come with `tf.keras`:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`tf.keras`附带的数据集中加载数据：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We check the dimensions of the train and test subsets:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查训练集和测试集的维度：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This gives us the following output:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下输出：
- en: '![](img/c7c78596-8409-45b0-9b07-88787f16e63b.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c7c78596-8409-45b0-9b07-88787f16e63b.png)'
- en: 'We take note of the unique values in the target variable:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们记录目标变量中的唯一值：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can see that there are 10 classes labelled from 0 to 9:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到有10个类别被标记为0到9：
- en: '![](img/adb643ea-43b7-4070-967a-1a60c4a811c5.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/adb643ea-43b7-4070-967a-1a60c4a811c5.png)'
- en: 'We can take a quick glimpse at the first few observations as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以快速查看前几个观察结果如下：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'With the preceding code, we plot the first 15 images, along with the associated
    labels:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面的代码，我们绘制了前15个图像及其相关标签：
- en: '![](img/3a825ef7-c292-420e-8539-a852303b3206.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3a825ef7-c292-420e-8539-a852303b3206.png)'
- en: How to do it...
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We''ll now move on to training our models:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将进入训练模型阶段：
- en: 'In the following code block, we''ll create multiple homogeneous models over
    a few iterations using `tf.keras`:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下面的代码块中，我们将使用`tf.keras`在几个迭代中创建多个同质模型：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We mention seven iterations and 10 epochs in each iteration. In the following
    screenshot, we can see the progress as the model gets trained:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在每个迭代中提到七个迭代和十个时期。在下面的屏幕截图中，我们可以看到随着模型训练的进展：
- en: '![](img/facfdce9-3e8f-43c7-91ba-7b757885f4c1.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/facfdce9-3e8f-43c7-91ba-7b757885f4c1.png)'
- en: 'With the code in *Step 1*, we collate the accuracy, precision, and recall for
    every iteration on the test data:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*步骤1*的代码中，我们收集了每个迭代在测试数据上的准确率、精确率和召回率：
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the following screenshot, we can see how the preceding three metrics change
    in each iteration:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图中，我们可以看到前三个指标在每个迭代中的变化：
- en: '![](img/66b6e227-2ba8-4c36-bc2b-8232068e5a6e.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/66b6e227-2ba8-4c36-bc2b-8232068e5a6e.png)'
- en: 'We''ll form a DataFrame with the predictions that are returned by all of the
    models in each iteration:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将创建一个包含每个迭代中所有模型返回的预测的DataFrame：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We convert the type into an integer:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将类型转换为整数：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We perform max-voting to identify the most predicted class for each observation.
    We simply use `mode` to find out which class was predicted the most times for
    an observation:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们执行最大投票来识别每个观察值预测的最可能类别。我们简单地使用`mode`来找出对于每个观察值预测次数最多的类别：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We calculate the accuracy of the test data:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们计算测试数据的准确率：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We generate the confusion matrix with the required labels:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用所需的标签生成混淆矩阵：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We plot the confusion matrix:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们绘制了混淆矩阵：
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The confusion matrix plot appears as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵的图表如下所示：
- en: '![](img/1e7a1a0d-f59b-4d09-b8fd-ccb1c8cf2eae.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1e7a1a0d-f59b-4d09-b8fd-ccb1c8cf2eae.png)'
- en: 'We create a DataFrame with all of the iteration numbers:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一个包含所有迭代编号的DataFrame：
- en: '[PRE13]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We then combine the accuracy, precision, and recall in one single table:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将准确率、精确率和召回率合并到一个单独的表中：
- en: '[PRE14]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In the following screenshot, we can see the structure that holds the metrics
    from each of the models and the ensemble model:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图中，我们可以看到包含每个模型和集成模型指标的结构的截图：
- en: '![](img/033e6f18-7e95-4b79-95c9-c433448cce9a.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/033e6f18-7e95-4b79-95c9-c433448cce9a.png)'
- en: 'We plot the accuracy returned by each iteration and the accuracy from max-voting:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们绘制了每个迭代的准确率和最大投票的准确率：
- en: '[PRE15]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This gives us the following plot. We notice that the accuracy returned by the
    max-voting method is the highest compared to individual models:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下图表。我们注意到与单个模型相比，最大投票方法返回的准确率是最高的：
- en: '![](img/de750f3d-1583-4900-aa77-1e788d9ac40d.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/de750f3d-1583-4900-aa77-1e788d9ac40d.png)'
- en: 'We also plot the precision and recall for each model and the ensemble:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还绘制了每个模型和集成模型的精确率和召回率：
- en: '[PRE16]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This is shown in the following screenshot:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这在下面的屏幕截图中显示：
- en: '![](img/2bb4181e-f699-495d-9bf5-d5aab4558174.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2bb4181e-f699-495d-9bf5-d5aab4558174.png)'
- en: From the preceding screenshot, we notice that the precision and recall improve
    for an ensemble model.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的屏幕截图中，我们注意到集成模型的精确率和召回率有所提高。
- en: How it works...
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In the *Getting ready* section, we imported our required libraries. Note that
    we''ve imported the `TensorFlow` library. We can directly access the datasets
    by importing the `tf.keras.datasets` module. This module comes with various built-in
    datasets, including the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在*准备就绪*部分，我们导入了所需的库。请注意，我们已经导入了`TensorFlow`库。我们可以通过导入`tf.keras.datasets`模块直接访问数据集。此模块包含各种内置数据集，包括以下内容：
- en: '`boston_housing`: Boston housing price regression dataset'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`boston_housing`：波士顿房价回归数据集'
- en: '`cifar10`: CIFAR10 small images classification dataset'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cifar10`：CIFAR10小型图像分类数据集'
- en: '`fashion_mnist`: Fashion-MNIST dataset'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fashion_mnist`：Fashion-MNIST数据集'
- en: '`imdb`: IMDB sentiment classification dataset'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imdb`：IMDB情感分类数据集'
- en: '`mnist`: MNIST handwritten digits dataset'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mnist`：MNIST手写数字数据集'
- en: '`reuters`: Reuters topic classification dataset'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reuters`：路透社主题分类数据集'
- en: We used the `fashion_mnist` dataset from this module. We loaded the pre-shuffled
    train and test data and checked the shape of the train and test subsets.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了此模块中的`fashion_mnist`数据集。我们加载了预洗牌的培训和测试数据，并检查了培训和测试子集的形状。
- en: We noticed, in the G*etting* *ready* section, that the shape of the training
    subset is (60000, 28, 28), which means that we have 60,000 images that are of
    28 X 28 pixel in size.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在*准备就绪*部分，我们注意到训练子集的形状是（60000，28，28），这意味着我们有60000个大小为28 X 28像素的图像。
- en: We checked the distinct levels in the target variable with the `unique()` method.
    We saw that there were 10 classes from 0 to 9.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`unique()`方法检查目标变量的不同级别。我们看到从0到9共有10个类别。
- en: We also took a quick look at some of the images. We defined the number of columns
    and rows that we required. Running an iteration, we plotted the images with `matplotlib.pyplot.imshow()`
    in grayscale. We also printed the actual class labels against each of the images using `matplotlib.pyplot.title()`.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还快速浏览了一些图像。我们定义了我们所需的列数和行数。运行迭代后，我们使用`matplotlib.pyplot.imshow()`以灰度形式绘制了图像。我们还使用`matplotlib.pyplot.title()`打印了每个图像的实际类别标签。
- en: In the *How to do it...* section, in *Step 1*, we created multiple homogeneous
    models using the `tf.keras` module. In each iteration, we used the `resample()`
    method to create bootstrap samples. We passed `replace=True` to the `resample()`
    method to ensure that we have samples with replacement.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在*如何做...*部分的*步骤1*中，我们使用`tf.keras`模块创建了多个同质模型。在每个迭代中，我们使用`resample()`方法创建自助样本。我们将`replace=True`传递给`resample()`方法，以确保我们有带替换的样本。
- en: In this step, we also defined the model architecture. We added layers to the
    model using `tf.keras.layers`. In each layer, we defined the number of units.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，我们还定义了模型架构。我们使用`tf.keras.layers`向模型中添加层。在每个层中，我们定义了单元数。
- en: '"Model architecture" refers to the overall neural network structure, which
    includes groups of units called layers. These layers are arranged in a chain-like
    structure. Each layer is a function of its previous layer. Determining the model
    architecture is key to neural networks.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: “模型架构”指的是整个神经网络结构，它包括称为层的单元组。这些层以链状结构排列。每一层是其前一层的函数。确定模型架构是神经网络的关键。
- en: 'We ran through a few iterations in our example. We set the number of iterations.
    In each iteration, we compiled the model and fit it to our training data. We made
    predictions on our test data and captured the following metrics in a DataFrame:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们进行了一些迭代。我们设置了迭代次数。在每次迭代中，我们编译模型并将其拟合到我们的训练数据上。我们在测试数据上进行了预测，并在DataFrame中捕获以下指标：
- en: Accuracy
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确度
- en: Precision
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度
- en: Recall
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率
- en: We've used `Rectified Linear Units (RELU)` as the activation function for the
    hidden layers. ReLU is represented by the `f(x) = max{0, x}`. In neural networks,
    ReLU is recommended as the default activation function.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`Rectified Linear Units (RELU)`作为隐藏层的激活函数。ReLU表示为`f(x) = max{0, x}`。在神经网络中，ReLU被推荐为默认的激活函数。
- en: Note that, in the last layer of the model architecture, we've used softmax as
    the activation function. The softmax function can be considered a generalization
    of the sigmoid function. While the sigmoid function is used to represent a probability
    distribution of a dichotomous variable, the softmax function is used to represent
    a probability distribution of a target variable with more than two classes. When
    the softmax function is used for multi-class classification, it returns a probability
    value between 0 and 1 for each class. The sum of all probabilities will be equal
    to one.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在模型架构的最后一层，我们使用了softmax作为激活函数。softmax函数可以看作是sigmoid函数的推广。虽然sigmoid函数用于表示二元变量的概率分布，但softmax函数用于表示具有两个以上类别的目标变量的概率分布。当softmax函数用于多类分类时，它为每个类别返回一个介于0和1之间的概率值。所有概率值的总和将等于1。
- en: In *Step 2*, we checked the structure of the accuracy DataFrame that we created
    in *Step 1*. We noticed that we had three columns for accuracy, precision, and
    recall and the metrics for each iteration were captured. In *Step 3*, we converted
    the datatypes in the DataFrame into an integer.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 2**中，我们检查了我们在**步骤 1**中创建的准确度DataFrame的结构。我们注意到我们有三个列用于准确度、精确度和召回率，以及每个迭代的指标都被捕获。在**步骤
    3**中，我们将DataFrame中的数据类型转换为整数。
- en: In *Step 4*, we performed max-voting using `stats.mode()` for each observation.
    Since we ran seven iterations, we had seven predictions for each observation.
    `stats.mode()` returned the prediction with the maximum occurrence.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 4**中，我们使用`stats.mode()`对每个观测值进行了最大投票。由于我们进行了七次迭代，因此每个观测值都有七个预测。`stats.mode()`返回了出现次数最多的预测。
- en: In *Step 5*, we checked the accuracy of the model with the max-voted predictions.
    In *Step 6* and *Step 7*, we generated the confusion matrix to visualize the correct
    predictions. The diagonal elements in the plot were the correct predictions, while
    the off-diagonal elements were the misclassifications. We saw that there was a
    higher number of correct classifications compared to misclassifications.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 5**中，我们检查了使用最大投票预测的模型的准确度。在**步骤 6**和**步骤 7**中，我们生成了混淆矩阵来可视化正确的预测。图表中的对角线元素是正确的预测，而离对角线元素是误分类。我们发现正确的分类数量比误分类的数量要多。
- en: In *Step 8* and *Step 9*, we proceeded to create a structure to hold the performance
    metrics (accuracy, precision, and recall), along with the labels for each iteration
    and the ensemble. We used this structure to plot our charts for the performance
    metrics.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 8**和**步骤 9**中，我们继续创建一个结构来保存性能指标（准确度、精确度和召回率），以及每个迭代和集成标签。我们使用这个结构来绘制性能指标的图表。
- en: In *Step 10*, we plotted the accuracy for each iteration and the max-voted predictions.
    Similarly, in *Step 11*, we plotted the precision and recall for each iteration
    and the max-voted predictions.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 10**中，我们绘制了每个迭代和最大投票预测的准确度。同样，在**步骤 11**中，我们绘制了每个迭代和最大投票预测的精确度和召回率。
- en: From the plots we generated in *Step 10* and *Step 11*, we noticed how the accuracy,
    precision, and recall improved for the max-voted predictions.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们在**步骤 10**和**步骤 11**中生成的图表中，我们注意到最大投票预测的准确度、精确度和召回率都有所提高。
- en: See also
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: The `tf.keras` module provides us with TensorFlow-specific functionality, such
    as eager-execution, data pipelines, and estimators. You can take a look at the
    various options the `tf.keras` module provides us.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.keras` 模块为我们提供了TensorFlow特定的功能，例如即时执行、数据管道和估计器。您可以查看`tf.keras`模块为我们提供的各种选项。'
- en: In our example, we used the built-in optimizer classes provided by the `tf.keras.optimizer`
    module. We used the **Adam** **optimizer** in our example, but there are other
    optimizers you can use, such as Adadelta, Adagrad, Adamax, RMSprop, or SGD.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们使用了`tf.keras.optimizer`模块提供的内置优化器类。在我们的示例中，我们使用了**Adam** **优化器**，但您还可以使用其他优化器，例如Adadelta、Adagrad、Adamax、RMSprop或SGD。
- en: In the present day, the Adam optimizer is one of the best optimizers. It's an
    extension of **Stochastic Gradient Descent** (**SGD**). SGD considers a single
    learning rate for all weight updates and the learning rate remains unchanged during
    the model training process. The Adam algorithm considers adaptive learning rates
    methods to compute individual learning rates for each parameter.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今时代，Adam优化器是最佳优化器之一。它是**随机梯度下降**（**SGD**）的扩展。SGD考虑所有权重更新使用单个学习率，并且在模型训练过程中学习率保持不变。Adam算法考虑自适应学习率方法来计算每个参数的单独学习率。
- en: The `tf.keras.losses` module provides us with various options so that we can choose
    our loss function. We used `sparse_categorical_crossentropy`. Depending on your
    task, you might opt for other options, such as `binary_crossentropy`, `categorical_crossentropy`, `mean_squared_error`,
    and so on.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.keras.losses` 模块为我们提供了各种选项，以便我们可以选择我们的损失函数。我们使用了`sparse_categorical_crossentropy`。根据您的任务，您可能需要选择其他选项，例如`binary_crossentropy`、`categorical_crossentropy`、`mean_squared_error`等等。'
- en: In the case of multiclass classification, if the target variable is one-hot
    encoded, use `categorical_crossentropy`. If the classes in the target variable
    are represented as integers, use `sparse_categorical_crossentropy`.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在多类分类的情况下，如果目标变量是独热编码的，请使用`categorical_crossentropy`。如果目标变量中的类别表示为整数，请使用`sparse_categorical_crossentropy`。
- en: You can get more detailed information about the other hyperparameters that can
    be used with `tf.keras` at [https://www.tensorflow.org/api_docs/python/tf/keras](https://www.tensorflow.org/api_docs/python/tf/keras).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://www.tensorflow.org/api_docs/python/tf/keras](https://www.tensorflow.org/api_docs/python/tf/keras)上获取有关可用于`tf.keras`的其他超参数的更详细信息。
