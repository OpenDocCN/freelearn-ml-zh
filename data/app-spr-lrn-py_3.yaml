- en: '*Chapter 3*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第三章*'
- en: Regression Analysis
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归分析
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将能够：
- en: Describe regression models and explain the difference between regression and
    classification problems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述回归模型，并解释回归与分类问题的区别
- en: Explain the concept of gradient descent, how it is used in linear regression
    problems, and how it can be applied to other model architectures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释梯度下降的概念，它在线性回归问题中的应用，以及如何应用到其他模型架构中
- en: Use linear regression to construct a linear model for data in an *x-y* plane
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线性回归为*x-y*平面上的数据构建线性模型
- en: Evaluate the performance of linear models and use the evaluation to choose the
    best model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估线性模型的性能，并利用评估结果选择最佳模型
- en: Use feature engineering to create dummy variables for constructing more complicated
    linear models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用特征工程为构建更复杂的线性模型创建虚拟变量
- en: Construct time series regression models using autoregression
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建时间序列回归模型，使用自回归方法
- en: This chapter covers regression problems and analysis, introducing us to linear
    regression as well as multiple linear regression, gradient descent, and autoregression.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了回归问题和分析，向我们介绍了线性回归以及多元线性回归、梯度下降和自回归。
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: In the first two chapters, we were introduced to the concept of supervised machine
    learning in Python and the essential techniques required for loading, cleaning,
    exploring, and visualizing raw data sources. We discussed the criticality of the
    correlations between the specified inputs and desired output for the given problem,
    as well as how the initial data preparation process can sometimes take a lot of
    the time spent on the entire project.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两章中，我们介绍了Python中监督机器学习的概念，以及加载、清理、探索和可视化原始数据源所需的基本技术。我们讨论了指定输入和所需输出之间相关性的关键性，以及初始数据准备过程有时可能占据整个项目所花费时间的大部分。
- en: In this chapter, we will delve into the model building process and will construct
    our first supervised machine learning solution using linear regression. So, let's
    get started.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨模型构建过程，并使用线性回归构建我们的第一个监督机器学习解决方案。所以，让我们开始吧。
- en: Regression and Classification Problems
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归与分类问题
- en: We discussed two distinct methods, supervised learning and unsupervised learning,
    in *Chapter 1*, *Python Machine Learning Toolkit*. Supervised learning problems
    aim to map input information to a known output value or label, but there are two
    further subcategories to consider. Both supervised and unsupervised learning problems
    can be further divided into regression or classification problems. Regression
    problems, which are the subject of this chapter, aim to predict or model continuous
    values, for example, predicting the temperature tomorrow in degrees Celsius or
    determining the location of a face within an image. In contrast, classification
    problems, rather than returning a continuous value, predict membership of one
    of a specified number of classes or categories. The example supervised learning
    problem in *Chapter 1*, *Python Machine Learning Toolkit*, where we wanted to
    determine or predict whether a wig was from the 1960s or 1980s, is a good example
    of a supervised classification problem. There, we attempted to predict whether
    a wig was from one of two distinct groups or classes; class 1 being the 1960s
    and class 2 being the 1980s. Other classification problems include predicting
    whether a passenger of the Titanic survived or perished or the classic MNIST problem
    ([http://yann.lecun.com/exdb/mnist/](B13323_03_ePub_Final_NT.xhtml#_idTextAnchor116)).
    MNIST is a database of 70,000 labeled images of handwritten digits 0 through 9\.
    The task in classifying examples from MNIST is to take one of the 70,000 input
    images and predict or classify which digit 0-9 is written in the image; so, the
    model must predict the membership of the image in one of 10 different classes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第一章*、*Python机器学习工具包*中讨论了两种不同的方法：监督学习和无监督学习。监督学习问题旨在将输入信息映射到已知的输出值或标签，但在此基础上，还有两个进一步的子类别需要考虑。监督学习和无监督学习问题都可以进一步细分为回归问题或分类问题。本章的主题是回归问题，它们旨在预测或建模连续值，例如预测明天的气温（摄氏度）或确定图像中人脸的位置。相反，分类问题则不同，它们预测的是某个输入属于预定类别中的某一个，而不是返回一个连续值。*第一章*、*Python机器学习工具包*中的示例监督学习问题，即我们想要预测一个假发是来自1960年代还是1980年代，就是一个很好的监督分类问题的例子。在这个例子中，我们试图预测一个假发是否来自两个不同的类别：类别1为1960年代，类别2为1980年代。其他分类问题包括预测泰坦尼克号的乘客是否幸存或死亡，或者经典的MNIST问题（[http://yann.lecun.com/exdb/mnist/](B13323_03_ePub_Final_NT.xhtml#_idTextAnchor116)）。MNIST是一个包含70,000个标注过的手写数字图像的数据库，数字范围为0到9。MNIST分类任务的目标是，从70,000张输入图像中挑选一张，预测或分类图像中的数字0-9。因此，模型必须预测该图像属于10个类别中的哪一个。
- en: Data, Models, Training, and Evaluation
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据、模型、训练和评估
- en: 'Before we begin our deep dive into regression problems, we will first look
    at the four major stages involved in creating any machine learning model, supervised
    regression or otherwise. These stages are as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨回归问题之前，我们将首先审视创建任何机器学习模型所涉及的四个主要阶段，无论是监督回归还是其他类型的模型。这些阶段如下：
- en: Data preparation
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据准备
- en: Model architecture specification
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型架构的规范
- en: The design and execution of the training process
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练过程的设计与执行
- en: The evaluation of the trained model
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型的评估
- en: It is advised that you ensure you are completely confident in your understanding
    of this pipeline and of what is described within this section, as each of these
    stages is critical in achieving high or even reasonable system performance. We
    will consider each of these stages in the context of the wig classification problem
    from *Chapter 1*, *Python Machine Learning Toolkit*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 建议确保你完全理解这个流程以及本节中描述的内容，因为每个阶段对实现高效或合理的系统性能都至关重要。我们将在*第一章*、*Python机器学习工具包*的背景下，考虑这些阶段如何应用于假发分类问题。
- en: '**Data Preparation**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据准备**'
- en: The first stage of the pipeline, data preparation, was the focus of a significant
    component of *Chapter 1*, *Python Machine Learning Toolkit*, and thus will not
    be the subject of further analysis in this section. It is important, however,
    that the criticality of the data specification, collection, and cleaning/tidying
    process is well understood. We cannot expect to produce a high-performing system
    if the input data is sub-optimal. One common phrase that you should always remember
    with regard to data quality is *junk in, junk out*. If you put junk data in, you
    are going to get a junk result out. In our wig example, we are looking for a sample
    size at least in the order of hundreds, ideally thousands, that have been correctly
    labeled as either from the 1960s or 1980s. We do not want samples that have been
    incorrectly labeled or aren't even from either era.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 管道的第一阶段是数据准备，这是*第1章*、*《Python机器学习工具包》*的一个重要组成部分，因此在本节中不再进一步分析。然而，重要的是要理解数据规范、收集和清理/整理过程的关键性。如果输入数据是次优的，我们不能期望能够产生一个高性能的系统。关于数据质量，有一句常见的格言是*垃圾进，垃圾出*。如果你输入的是垃圾数据，那么你得到的结果也将是垃圾。在我们的假发示例中，我们希望样本量至少在几百个，理想情况下是几千个，并且这些样本已正确标记为1960年代或1980年代的样本。我们不希望样本被错误标记，或者根本不属于这两个时代。
- en: '**Model Architecture**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型架构**'
- en: The second stage, model architecture specification, will be described in more
    detail in this chapter. This stage defines the type of model that is to be used,
    as well as the types and values of the parameters that comprise the model itself.
    The model is essentially a mathematical equation that is used to define the relationship
    between the input data and the desired result. As with any equation, the model
    is composed of variables and constants combined by a set of processes, for example,
    addition, subtraction, or convolution. The nature and values of the model parameters
    will vary depending upon the type of model selected and the level of complexity
    at which the model is able to describe the relationship being observed. Simpler
    models will contain fewer parameters with greater constraints on their values,
    while more complex models have a greater number of possibly varying parameters.
    In this chapter, we will be employing a linear model, which is one of the simpler
    models available, compared with some others, such as convolutional neural network
    models, which may have more than one million parameters that need to be optimized
    for a good result. This simplicity should not be mistaken for a lack of power,
    or a lack of ability to describe relationships within data, but simply that fewer
    parameters are available for tuning (that is, changing the values to optimize
    performance).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 第二阶段是模型架构规范，在本章中将进行更详细的描述。该阶段定义了将要使用的模型类型，以及组成模型本身的参数的类型和值。模型本质上是一个数学方程，用于定义输入数据与期望结果之间的关系。与任何方程一样，模型由变量和常量组成，并通过一组过程进行组合，例如加法、减法或卷积。模型参数的性质和值会根据选择的模型类型以及模型能够描述所观察关系的复杂性水平而有所不同。较简单的模型将包含较少的参数，并对其值有更大的约束，而更复杂的模型则可能包含更多的参数，并且这些参数可能会发生变化。在本章中，我们将使用一个线性模型，与一些其他模型（如卷积神经网络模型，它可能包含超过一百万个需要优化的参数）相比，线性模型是较简单的。这种简单性不应被误认为是缺乏能力，或者无法描述数据中的关系，而仅仅是意味着可调参数较少（即调整这些参数的值以优化性能）。
- en: '**Model Training**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型训练**'
- en: The third stage of the system pipeline is the design and execution of the training
    process, that is, the mechanism by which the values for the parameters of the
    model are determined. In a supervised learning problem, we can think about the
    training process as being analogous to being a student within a classroom. In
    a typical classroom environment, the teacher already has the answers to a given
    problem and is attempting to show the students how to solve the problem given
    some set of inputs. In such a scenario, the student is the model, and the parameters
    are all within the student's brain and are the means by which the student correctly
    answers the problem.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 系统管道的第三个阶段是训练过程的设计与执行，即通过这种机制来确定模型参数的值。在监督学习问题中，我们可以将训练过程类比为一个学生在课堂中的学习过程。在典型的课堂环境中，老师已经知道给定问题的答案，并尝试向学生展示如何根据一组输入来解决问题。在这种情况下，学生就是模型，参数就像学生大脑中的知识，是学生正确解答问题的手段。
- en: The training process is the method the teacher uses to train the student to
    correctly answer the problem; this method can be tweaked and changed in response
    to the student's ability to learn and understand the content. Once a model architecture
    has been defined (that is, the student in the class), it is the training process
    that is used to provide the guidance and constraints required to approach an optimal
    solution. Just as some students perform better in different learning environments,
    so do models. Thus, there is an additional set of parameters known as **hyperparameters**,
    which, while not being used within the model itself to make predictions given
    some set of input data, are defined, used, and tuned in an attempt to optimize
    the performance of the model against a specified cost (or error) function (for
    example, root mean squared error). We will also discuss hyperparameters in more
    detail in this chapter, but for the time being, it is simplest to think about
    hyperparameters as the environment in which the actual parameters of the model
    are determined.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程是教师用来训练学生正确回答问题的方法；该方法可以根据学生的学习能力和理解能力进行调整和变化。一旦模型架构被定义（即班级中的学生），训练过程就会提供所需的指导和约束，以接近最优解。就像一些学生在不同的学习环境中表现更好一样，模型也如此。因此，还存在一组额外的参数，称为**超参数**，它们虽然不在模型内部用于根据某些输入数据集进行预测，但它们被定义、使用并调优，旨在通过指定的成本（或误差）函数（例如，均方根误差）优化模型的性能。我们将在本章中更详细地讨论超参数，但目前，最简单的理解方式是将超参数视为决定模型实际参数的环境。
- en: '**Model Evaluation**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型评估**'
- en: The final stage of the pipeline is the evaluation of the model, which yields
    the final performance metric. This is the mechanism through which we know whether
    the model is worth publishing, better than a previous version, or has been effectively
    translated across programming languages or development environments. We will cover
    some of these metrics in more detail in *Chapter 6*, *Model Evaluation*, and as
    such this will not be discussed in detail at this stage. Just keep in mind that
    whichever validation technique is selected, it needs to be capable of consistently
    reporting and independently measuring the performance of the model against the
    dataset. Again, using our wig dataset as the example, the evaluation stage would
    look at how many correct predictions the model achieved, given wig images and
    the known eras as the labels.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 管道的最终阶段是模型评估，它产生最终的性能指标。这是我们知道模型是否值得发布、是否优于先前版本，或是否在不同的编程语言或开发环境中有效迁移的机制。我们将在*第6章*，*模型评估*中更详细地介绍这些指标，因此在此阶段不会详细讨论。只需记住，无论选择哪种验证技术，它都需要能够持续报告并独立地衡量模型在数据集上的性能表现。再次以我们的假发数据集为例，评估阶段将查看模型在给定假发图像和已知年代标签的情况下，达成多少个正确预测。
- en: Linear Regression
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性回归
- en: 'We will start our investigation into regression problems with the selection
    of a linear model. Linear models, while being a great first choice due to their
    intuitive nature, are also very powerful in their predictive power, assuming datasets
    contain some degree of linear or polynomial relationship between the input features
    and values. The intuitive nature of linear models often arises from the ability
    to view data as plotted on a graph and observe a trending pattern in the data
    with, say, the output (the *y* axis value for the data) trending positively or
    negatively with the input (*x* axis value). While often not presented as such,
    the fundamental components of linear regression models are also often learned
    during high school mathematics classes. You may recall that the equation of a
    straight line, or linear model, is defined as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从选择线性模型开始研究回归问题。线性模型因其直观性而成为一个很好的首选，同时也具有强大的预测能力，前提是数据集在输入特征和数值之间存在某种线性或多项式关系。线性模型的直观性通常来源于能够将数据绘制成图表，并观察数据中的趋势模式，例如输出（数据的*y*轴值）随着输入（*x*轴值）的变化呈正向或负向趋势。虽然通常不会以这种方式呈现，线性回归模型的基本组成部分也常常是在高中数学课程中学习的。你可能还记得，直线或线性模型的方程式定义如下：
- en: '![Figure 3.1: Equation of a straight line](img/C12622_03_01.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.1：直线方程](img/C12622_03_01.jpg)'
- en: 'Figure 3.1: Equation of a straight line'
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.1：直线方程
- en: 'Here, *x* is the input value and *y* is the corresponding output or predicted
    value. The parameters of the model are the gradient or slope of the line (change
    in *y* values divided by change in *x*) defined by *m* as well as the *y*-intercept
    value *b*, which indicates where the line crosses the *y* axis. With such a model,
    we can provide values for the *m* and *b* parameters to construct a linear model.
    For example, *y = 2x + 1*, has a slope of 2, indicating the changes in *y* values
    are at a rate of twice that of *x*; the line crosses the *y* intercept at 1:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*x* 是输入值，*y* 是对应的输出或预测值。模型的参数是由 *m* 定义的线的梯度或斜率（*y* 值的变化除以 *x* 值的变化），以及 *y*
    截距值 *b*，它表示线与 *y* 轴的交点。通过这样的模型，我们可以提供 *m* 和 *b* 参数的值来构建线性模型。例如，*y = 2x + 1*，其斜率为
    2，表示 *y* 值的变化速度是 *x* 的两倍；这条线与 *y* 截距相交于 1：
- en: '![Figure 3.2: Parameters of a straight line](img/C12622_03_02.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.2：直线的参数](img/C12622_03_02.jpg)'
- en: 'Figure 3.2: Parameters of a straight line'
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.2：直线的参数
- en: So, we have an understanding of the parameters that are required to define a
    straight line, but this isn't really doing anything particularly interesting.
    We just dictated the parameters of the model to construct a line. What we want
    to do is take a dataset and construct a model that best describes a dataset. As
    mentioned before, this dataset needs to have something that approximates a linear
    relationship between the input features and output values. For this purpose, we
    have created a synthetic dataset of recorded air temperatures from the years 1841
    to 2010, which is available in the accompanying code bundle of this book or on
    GitHub at [https://github.com/TrainingByPackt/Supervised-Learning-with-Python](B13323_03_ePub_Final_NT.xhtml#_idTextAnchor115).
    This dataset is composed of values designed to demonstrate the subject matter
    of this chapter and should not be mistaken for data collected from a scientific
    study.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们了解了定义直线所需的参数，但这实际上并没有做什么特别有趣的事情。我们只是规定了模型的参数来构建一条线。我们真正想做的是，拿一个数据集并构建一个最好描述数据集的模型。正如之前提到的，这个数据集需要在输入特征和输出值之间有某种线性关系的近似。为此，我们创建了一个合成数据集，记录了从
    1841 年到 2010 年的空气温度数据，这些数据可以在本书附带的代码包中找到，或者在 GitHub 上查看 [https://github.com/TrainingByPackt/Supervised-Learning-with-Python](B13323_03_ePub_Final_NT.xhtml#_idTextAnchor115)。这个数据集包含的值旨在演示本章的主题，不应与来自科学研究的实际数据混淆。
- en: 'Exercise 28: Plotting Data with a Moving Average'
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 28：使用移动平均绘制数据
- en: 'As we discussed in *Chapter 1*, *Python Machine Learning Toolkit*, a thorough
    understanding of the dataset being used is critical if a high-performing model
    is to be built. So, with this in mind, let''s use this exercise to load, plot,
    and interrogate the data source:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在*第一章*中讨论的，*Python 机器学习工具包*，如果要构建一个高性能的模型，彻底理解所使用的数据集是至关重要的。所以，考虑到这一点，让我们利用这个练习加载、绘制并查询数据源：
- en: 'Import the `numpy`, `pandas`, and `matplotlib` packages with alternative handles:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `numpy`、`pandas` 和 `matplotlib` 包，并使用替代名称：
- en: '[PRE0]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Use the pandas `read_csv` function to load the CSV file containing the `synth_temp.csv`
    dataset, and then display the first five lines of data:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 的 `read_csv` 函数加载包含 `synth_temp.csv` 数据集的 CSV 文件，然后显示前五行数据：
- en: '[PRE1]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output will be as follows:'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.3: The first five rows](img/C12622_03_03.jpg)'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.3：前五行数据](img/C12622_03_03.jpg)'
- en: 'Figure 3.3: The first five rows'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.3：前五行数据
- en: 'Since we are only interested in the data from 1901 to 2010, remove all rows
    prior to 1901:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们只对 1901 年至 2010 年的数据感兴趣，因此需要删除 1901 年之前的所有行：
- en: '[PRE2]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output will be:'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将是：
- en: '![Figure 3.4: The first five rows after removing all rows prior to 1901](img/C12622_03_04.jpg)'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.4：删除所有 1901 年之前的行后的前五行数据](img/C12622_03_04.jpg)'
- en: 'Figure 3.4: The first five rows after removing all rows prior to 1901'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.4：删除所有 1901 年之前的行后的前五行数据
- en: 'The original dataset contains multiple temperature measurements per year, with
    more measurements for the later years (12 for 2010) and less for the earlier years
    (6 for 1841); however, we are interested in a list of yearly average temperatures.
    Group the data by year and use the `agg` method of the DataFrame to create the
    yearly averages:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 原始数据集包含每年多个温度测量值，较晚年份的测量值更多（2010 年有 12 个），较早年份的测量值较少（1841 年有 6 个）；然而，我们感兴趣的是每年的平均温度列表。按年份对数据进行分组，并使用
    DataFrame 的 `agg` 方法来计算每年的平均值：
- en: '[PRE3]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output will be:'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将是：
- en: '![Figure 3.5: Yearly average data](img/C12622_03_05.jpg)'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.5：每年平均数据](img/C12622_03_05.jpg)'
- en: 'Figure 3.5: Yearly average data'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.5：每年平均数据
- en: 'Given that the data is quite noisy, a moving average filter would provide a
    useful indicator of the overall trend. A moving average filter simply computes
    the average over the last *N* values and assigns this average to the *(N+1)**th*
    sample. Compute the values for a moving average signal for the temperature measurements
    using a window of 10 years:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 鉴于数据相当嘈杂，移动平均滤波器将提供总体趋势的有用指标。移动平均滤波器仅计算最后 *N* 个值的平均值，并将此平均值分配给 *(N+1)* 个样本。使用
    10 年的窗口计算温度测量的移动平均信号的值：
- en: '[PRE4]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We will get the following output:'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将获得以下输出：
- en: '![Figure 3.6: Values for a moving average signal](img/C12622_03_06.jpg)'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.6: 移动平均信号的值](img/C12622_03_06.jpg)'
- en: 'Figure 3.6: Values for a moving average signal'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.6：移动平均信号的值
- en: Notice that the first 9 samples are `NaN`, which is because of the size of the
    moving average filter window. The window size is 10, thus 9 (10-1) samples are
    required to generate the first average, and thus the first 9 samples are `NaN`.
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，前 9 个样本是 `NaN`，这是由于移动平均滤波器窗口的大小。窗口大小为 10，因此需要 9（10-1）个样本来生成第一个平均值，因此前 9 个样本为
    `NaN`。
- en: 'Finally, plot the measurements by year along with the moving average signal:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，绘制每年的测量值以及移动平均信号：
- en: '[PRE5]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output will be as follows:'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 3.7: Mean annual air temperature](img/C12622_03_07.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.7: 年均空气温度](img/C12622_03_07.jpg)'
- en: 'Figure 3.7: Mean annual air temperature'
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.7：年均空气温度
- en: '*Figure 3.7* is the expected output of this exercise and is a plot of the mean
    land temperature measurements for each year with a 10-year moving average trending.
    By simply looking at this plot, we can immediately make a couple of interesting
    observations. The first observation that we can make is that the temperature remained
    relatively consistent from the year 1901 to about 1960, after which there is an
    increasing trend until the data ends in 2010\. Secondly, there is a reasonable
    amount of scatter or noise in the measurements.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3.7* 是此练习的预期输出，是每年平均陆地温度测量的图表，并显示了 10 年移动平均趋势。通过查看此图，我们可以立即得出几个有趣的观察结果。第一个观察结果是，从
    1901 年到大约 1960 年间温度保持相对稳定，之后呈增加趋势，直到数据截至于 2010 年。其次，测量中存在相当多的散点或噪声。'
- en: 'Activity 5: Plotting Data with a Moving Average'
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 5：绘制带有移动平均线的数据
- en: For this activity, we have acquired a dataset of weather information from Austin,
    Texas (`austin_weather.csv`), available in the accompanying source code, and will
    be looking at the changes in average daily temperature. We will plot a moving
    average filter for this dataset.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此活动，我们获取了奥斯汀，德克萨斯州的天气信息数据集（`austin_weather.csv`），该数据集可在附带的源代码中找到，并将查看平均日温度的变化。我们将为此数据集绘制移动平均滤波器。
- en: 'Before we begin, we will need to import a few libraries, which can be done
    as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，我们需要导入一些库，可以按如下方式完成：
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The steps to be performed are as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 需要执行的步骤如下：
- en: Load the dataset into a pandas DataFrame from the CSV file.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 CSV 文件中将数据集加载到 pandas DataFrame 中。
- en: We only need the `Date` and `TempAvgF` columns; remove all others from the dataset.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只需要 `Date` 和 `TempAvgF` 列；将数据集中的所有其他列删除。
- en: Initially, we will only be interested in the first year's data, so we need to
    extract that information only. Create a column in the DataFrame for the year value
    and extract the year value as an integer from the strings in the `Date` column
    and assign these values to the `Year` column.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最初，我们只对第一年的数据感兴趣，因此需要仅提取该信息。在 DataFrame 中为年份值创建一列，并从 `Date` 列中的字符串中提取年份值作为整数，并将这些值分配给
    `Year` 列。
- en: Note that temperatures are recorded daily.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，温度是每天记录的。
- en: Repeat this process to extract the month values and store the values as integers
    in a `Month` column.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复此过程以提取月份值，并将这些值存储为 `Month` 列中的整数。
- en: Copy the first year's worth of data to a DataFrame.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将第一年的数据复制到一个 DataFrame 中。
- en: Compute a 20-day moving average filter.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算 20 天的移动平均滤波器。
- en: Plot the raw data and moving average signal, with the *x* axis being the day
    number in the year.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制原始数据和移动平均信号，其中 *x* 轴是年中的日期编号。
- en: Note
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 325.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此活动的解决方案可在第 325 页找到。
- en: Least Squares Method
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最小二乘法
- en: The field of machine learning and artificial intelligence evolved essentially
    as a specialized branch of statistics, and as such it is important to reflect
    on these origins from time to time to have a thorough understanding of how models
    are able to be used as predictive tools. It is also interesting to see the points
    where machine learning grew out of statistics and compare the more modern methods
    available today. Linear regression models are a great example of this as they
    can be used to demonstrate more classical solving techniques such as the least
    squares method, as well as more modern methods, such as gradient descent, which
    we will also cover in this chapter. Linear models also have the additional advantage
    of containing mathematical concepts commonly learned in high school, such as the
    equation of a straight line, providing a useful platform for describing the methods
    used to fit data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习和人工智能领域本质上是统计学的一个专业分支，因此，时不时地反思这些起源是很重要的，这有助于我们深入理解模型如何作为预测工具被应用。通过回顾机器学习如何从统计学中发展而来，并对比今天更现代的方法，亦是很有趣的。线性回归模型就是一个很好的例子，它既可以用来展示一些经典的求解方法，如最小二乘法，也可以展示一些更现代的方法，如梯度下降法，这些我们将在本章中讨论。线性模型还具有额外的优势，它包含了高中数学中常见的概念，例如直线方程，为描述拟合数据的方法提供了一个有用的平台。
- en: 'The traditional method of solving linear models, which is executed by toolkits
    such as scikit-learn, SciPy, Minitab, and Excel, is the **least squares method**,
    and this is the first method we will cover. Referring to our standard equation
    for a straight line (*Figure 3.1*), *m* is the slope or gradient of the line and
    *c* is the *y* axis offset. These values can be directly calculated in the least
    squares method by first determining the average *x* and *y* values, which will
    be denoted as ![](img/C12622_Formula_03_01.png) and ![](img/C12622_Formula_03_02.png)
    respectively. With the mean values calculated, we can then calculate the gradient,
    *m*, by multiplying the differences in *x* values from the mean with the differences
    in *y* values from the mean and dividing by the squared differences in *x* from
    the mean. The offset can then be calculated by solving for *b* using the newly
    calculated *m* and ![](img/C12622_Formula_03_01.png) and ![](img/C12622_Formula_03_02.png).
    This is represented mathematically as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 求解线性模型的传统方法是通过诸如 scikit-learn、SciPy、Minitab 和 Excel 等工具包执行的**最小二乘法**，这也是我们将要讨论的第一个方法。参考我们的标准直线方程（*图
    3.1*），*m* 是直线的斜率或梯度，*c* 是 *y* 轴偏移。通过首先确定平均的 *x* 和 *y* 值（分别表示为 ![](img/C12622_Formula_03_01.png)
    和 ![](img/C12622_Formula_03_02.png)），在最小二乘法中这些值可以直接计算出来。计算出平均值后，我们可以通过将 *x* 值的差与平均值的差以及
    *y* 值的差与平均值的差相乘，再除以 *x* 与平均值的差的平方，来计算梯度 *m*。然后，可以通过使用新计算的 *m* 和 ![](img/C12622_Formula_03_01.png)
    和 ![](img/C12622_Formula_03_02.png) 来解出偏移 *b*。数学上可以表示如下：
- en: '![](img/C12622_03_08.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12622_03_08.jpg)'
- en: 'Figure 3.8: Least squares method'
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.8：最小二乘法
- en: We can consider this in more practical terms, recalling that the gradient is
    simply the change in the vertical (or *y*) values divided by the horizontal (or
    *x*) values. In the context of mean annual air temperature over time, we can see
    that we are taking the sum of the differences in the individual temperature values
    from the mean value multiplied by the individual differences in the time values
    from the mean. By dividing the result by the sum of the squared differences in
    time from the mean, the trending gradient is completed, providing part of the
    temperature over time model.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从更实际的角度来理解这一点，回顾一下梯度实际上就是纵向（或 *y*）值的变化除以横向（或 *x*）值的变化。在年均气温随时间变化的背景下，我们可以看到我们在计算的是每个温度值与平均值的差的总和，乘以每个时间值与平均值的差。通过将结果除以时间差的平方和，得出的趋势梯度即为完成，从而为温度随时间的模型提供部分数据。
- en: Now, we don't need to worry about computing these values by hand, though it
    wouldn't be that hard to do. But specialized libraries such as SciPy and scikit-learn
    can be used do to the work for us as well as worrying about some of the details
    such as computational efficiency. For the purposes of this section, we will use
    scikit-learn as our library of choice as it provides a great introduction to the
    scikit-learn interface.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们不需要手动计算这些值，虽然这并不困难。但像 SciPy 和 scikit-learn 这样的专业库可以帮助我们完成这项工作，并且关注一些细节，例如计算效率。对于本节内容，我们将使用
    scikit-learn 作为我们的首选库，因为它提供了很好的 scikit-learn 接口入门。
- en: 'One implementation detail to note is that the scikit-learn linear regression
    model is actually a wrapper around the SciPy ordinary least squares function and
    provides some additional convenience methods:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一个实现细节是，scikit-learn 的线性回归模型实际上是 SciPy 普通最小二乘法函数的封装，并提供了一些附加的便捷方法：
- en: '![Figure 3.9: scikit-learn’s implementation of linear regression](img/C12622_03_09.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.9：scikit-learn 的线性回归实现](img/C12622_03_09.jpg)'
- en: 'Figure 3.9: scikit-learn''s implementation of linear regression'
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.9：scikit-learn 的线性回归实现
- en: The scikit-learn Model API
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: scikit-learn 模型 API
- en: The scikit-learn API uses a reasonably simple code pattern irrespective of the
    type of model being constructed. Put simply, the model must first be defined with
    all appropriate hyperparameters that are relevant to the training or fitting process.
    In defining the model, a model object is returned, which is then used during the
    second stage of model construction, which is training or fitting. Calling the
    `fit` method on the model object with the appropriate training data will then
    train the model with the defined hyperparameters. We will now use this pattern
    to construct our first linear regression model.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn API 使用一个相对简单的代码模式，无论构建的是何种类型的模型。简单来说，模型必须首先定义所有与训练或拟合过程相关的超参数。在定义模型时，会返回一个模型对象，然后在模型构建的第二阶段——训练或拟合时使用该对象。调用模型对象的`fit`方法并提供适当的训练数据，即可使用定义的超参数训练模型。我们现在将使用这个模式来构建我们的第一个线性回归模型。
- en: 'Exercise 29: Fitting a Linear Model Using the Least Squares Method'
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 29：使用最小二乘法拟合线性模型
- en: In this exercise, we will construct our first linear regression model using
    the least squares method.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用最小二乘法构建我们的第一个线性回归模型。
- en: 'We will use the scikit-learn `LinearRegression` model for this exercise, so
    import the class from the `linear_regression` module of scikit-learn:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在这个练习中使用 scikit-learn 的 `LinearRegression` 模型，因此从 scikit-learn 的 `linear_regression`
    模块中导入该类：
- en: '[PRE7]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Construct a linear regression model using the default values; that is, compute
    a value for the *y* intercept and do not normalize the input data:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用默认值构建线性回归模型；即，计算 *y* 截距的值并且不对输入数据进行归一化：
- en: '[PRE8]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Figure 3.10: Linear regression model](img/C12622_03_10.jpg)'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.10：线性回归模型](img/C12622_03_10.jpg)'
- en: 'Figure 3.10: Linear regression model'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.10：线性回归模型
- en: 'Now we are ready to fit or train the model to the data. We will provide the
    year values as the input and the mean yearly temperature as the output. Note that
    the `fit` method of scikit-learn models expects 2D arrays to be provided as the
    `X` and `Y` value. As such, the year or index values need to be reshaped to suit
    the method. Get the values of the index as a NumPy array using the `.values` method
    and reshape the values to `((-1, 1))` which is an *N x 1* array. The value `-1`
    in a NumPy shape definition represents that its value is inferred from the current
    shape of the array and the target shape:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们准备好将模型拟合或训练到数据上了。我们将提供年份作为输入，年均温度作为输出。请注意，scikit-learn 模型的`fit`方法期望提供二维数组作为
    `X` 和 `Y` 的值。因此，年份或索引值需要调整为适合该方法的形状。使用 `.values` 方法获取索引值，并将其调整为 `((-1, 1))` 的形状，这样就变成了一个
    *N x 1* 数组。NumPy 形状定义中的值 `-1` 表示该值由数组的当前形状和目标形状推断得出：
- en: '[PRE9]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output will be as follows:'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.11: Output of the fit method](img/C12622_03_11.jpg)'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.11：fit 方法的输出](img/C12622_03_11.jpg)'
- en: 'Figure 3.11: Output of the fit method'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.11：fit 方法的输出
- en: 'Get the parameters for the model by printing the values for `model.coef_` (which
    is the value for *m*) and `model.intercept_` (which is the value for the *y* intercept):'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过打印 `model.coef_`（即 *m* 的值）和 `model.intercept_`（即 *y* 截距的值），获取模型的参数：
- en: '[PRE10]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output will be:'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将是：
- en: '![Figure 3.12: Output of model co-efficient and model intercept](img/C12622_03_12.jpg)'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.12：模型系数和模型截距的输出](img/C12622_03_12.jpg)'
- en: 'Figure 3.12: Output of model co-efficient and model intercept'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.12：模型系数和模型截距的输出
- en: 'Now that we have our generated model, we can predict some values to construct
    our trendline. So, let''s use the first, last, and average year value as the input
    to predict the local temperature. Construct a NumPy array with these values and
    call the array `trend_x`. Once you are done, pass the values for `trend_x` to
    the `predict` method of the model to get the predicted values:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经生成了模型，可以预测一些值来构建趋势线。那么，让我们使用第一个、最后一个和平均年份的值作为输入来预测当地温度。用这些值构建一个 NumPy
    数组并将其命名为`trend_x`。完成后，将`trend_x`的值传递给模型的`predict`方法来获取预测值：
- en: '[PRE11]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output will be as follows:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.13: Array showing min, mean, and max](img/C12622_03_13.jpg)'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.13：数组显示最小值、均值和最大值](img/C12622_03_13.jpg)'
- en: 'Figure 3.13: Array showing min, mean, and max'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.13：数组显示最小值、均值和最大值
- en: 'Now plot the trendline produced by the model, with the model parameters over
    the previous plot with the raw data:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在绘制由模型生成的趋势线，并将模型参数叠加到之前的图表上，包含原始数据：
- en: '[PRE12]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output will be as follows:'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.14: Linear regression – a first simple linear model](img/C12622_03_14.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.14：线性回归 – 第一个简单的线性模型](img/C12622_03_14.jpg)'
- en: 'Figure 3.14: Linear regression – a first simple linear model'
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.14：线性回归 – 第一个简单的线性模型
- en: Now that we have the model, we need to evaluate its performance to see how well
    it fits the data and to compare against other models we may like to generate.
    We will cover this topic in much more detail in *Chapter 6*, *Model Evaluation*,
    where we'll look at validation and cross validation, but for the moment we will
    compute the **R-squared** value for the model against the dataset. R-squared,
    which is commonly reported in statistical-based modeling, is a ratio of the sum
    of squares between the predicted and actual values and the actual value from its
    own mean. A perfect fit will have an r2 of 1, and the score decreases to 0 as
    the performance degrades.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了模型，需要评估其性能，以了解它与数据的拟合程度，并与其他可能生成的模型进行比较。我们将在*第六章*《模型评估》中详细讨论这个主题，我们将探讨验证和交叉验证的方法，但目前我们将计算模型与数据集之间的**R-squared**值。R-squared，通常在统计建模中报告，是预测值与实际值之间的平方和与实际值与其均值之间的平方和之比。完美的拟合将有一个
    R² 值为1，而随着性能的下降，分数会降低至0。
- en: '![Figure 3.15: R-squared score](img/C12622_03_15.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.15：R-squared 分数](img/C12622_03_15.jpg)'
- en: 'Figure 3.15: R-squared score'
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.15：R-squared 分数
- en: 'We can compute the R2 value using the `score` method:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`score`方法计算 R² 值：
- en: '[PRE13]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We''ll get an output like this:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到如下输出：
- en: '![](img/C12622_03_16.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12622_03_16.jpg)'
- en: 'Figure 3.16: R-squared score for the model against the dataset'
  id: totrans-133
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.16：模型与数据集的 R-squared 分数
- en: So, looking at the trendline in *Figure 3.14*, we can see that the linear model
    is OK. It definitely performs better in the linear region of the moving average
    post 1960, but could use some improvement for the data earlier than 1970\. Is
    there something we can do to manage this? It seems something that two separate
    linear models could perform better than one. The data prior to 1960 could form
    one model and the post-1960 data another? We could do that and just split the
    data and create two separate models, evaluate them separately, and put them together
    in a piece-wise fashion. But we could also include similar features in our existing
    model through the use of dummy variables.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，观察*图 3.14*中的趋势线，我们可以看到线性模型表现良好。在1960年后的移动平均线性区域，它的表现明显更好，但对于1970年之前的数据仍有改进的空间。我们能做些什么来处理这个问题吗？似乎两个单独的线性模型可能比一个模型表现得更好。1960年前的数据可以作为一个模型，1960年后的数据作为另一个模型？我们可以这样做，直接将数据分开，创建两个独立的模型，分别评估它们，然后将它们以分段的方式合并起来。但我们也可以通过使用虚拟变量，在现有模型中加入类似的特征。
- en: Note
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Before continuing, it is important to note that when reporting the performance
    of machine learning models, the data used to train the model is *not* to be used
    to evaluate the model, as it will give an optimistic view of the model's performance.
    We will cover the concept of validation, which includes evaluating and reporting
    model performance, in *Chapter 6*, *Model Evaluation*. For the purpose of this
    chapter, however, we will use the training data to check the model's performance;
    just remember that once you have completed *Chapter 6*, *Model Evaluation*, you
    will know better.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，需要注意的是，在报告机器学习模型的表现时，*不得*使用用于训练模型的数据来评估模型表现，因为这会给出模型表现的乐观看法。我们将在*第 6 章*《模型评估》中讨论验证的概念，包括评估和报告模型表现。然而，为了本章的目的，我们将使用训练数据来检查模型的表现；只需记住，一旦你完成了*第
    6 章*《模型评估》，你将能更好地理解这一点。
- en: 'Activity 6: Linear Regression Using the Least Squares Method'
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 6：使用最小二乘法进行线性回归
- en: For this activity, we will use the Austin, Texas weather dataset that we used
    in the previous activity. We will plot a linear regression model using the least
    squares method for the dataset.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本活动，我们将使用前一个活动中使用的德克萨斯州奥斯丁的天气数据集。我们将使用最小二乘法为该数据集绘制线性回归模型。
- en: 'Before we begin, we will need to import a few libraries and load data from
    a previous activity, which can be done as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，我们需要导入一些库并加载来自前一个活动的数据，方法如下：
- en: '[PRE14]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The steps to be performed are as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 需要执行的步骤如下：
- en: Visualize the measurements.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化测量值。
- en: Visualize the rolling average values.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化滚动平均值。
- en: Create a linear regression model using the default parameters, that is, calculate
    a *y* intercept for the model and do not normalize the data.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用默认参数创建线性回归模型，也就是说，为模型计算 *y* 截距，并且不对数据进行归一化处理。
- en: Now fit the model, where the input data is the day number for the year (1 to
    365) and the output is the average temperature. To make later calculations easier,
    insert a column (`DayOfYear`) that corresponds with the day of the year for that
    measurement.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在拟合模型，其中输入数据为年份中的天数（1 到 365），输出为平均温度。为了便于后续计算，插入一列（`DayOfYear`），对应于该测量的年份中的天数。
- en: Fit the model with the `DayOfYear` values as the input and `df_first_year.TempAvgF`
    as the output.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `DayOfYear` 值作为输入，`df_first_year.TempAvgF` 作为输出，来拟合模型。
- en: Print the parameters of the model.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印模型的参数。
- en: Let's check the trendline provided by the model. Plot this simply using the
    first, middle, and last values (days in years) in the linear equation.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查模型提供的趋势线。只需使用线性方程中的第一个、中间和最后的值（年份中的天数）来绘制即可。
- en: Plot the values with the trendline.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制带有趋势线的值。
- en: Evaluate the performance of the model.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型的表现。
- en: Let's check how well the model fits the data. Calculate the r2 score to find
    out.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查模型拟合数据的情况。计算 r2 得分来了解。
- en: Note
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 329.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解答可以在第 329 页找到。
- en: Linear Regression with Dummy Variables
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带虚拟变量的线性回归
- en: Dummy variables are categorical variables that we can introduce into a model,
    using information provided within the existing dataset. The design and selection
    of these variables is considered a component of feature engineering, and depending
    upon the choice of variables, the results may vary. We made the observation earlier
    that the moving average begins to continually increase from approximately 1960
    and that the initial plateau ends at approximately 1945\. We will introduce two
    dummy variables, `Gt_1960` and `Gt_1945`; these variables will indicate whether
    the time period for the measurements is greater than the year 1960 and greater
    than the year 1945\. Dummy variables are typically assigned the values 0 or 1
    to indicate the lack of or presence of the assigned category for each row. In
    our example, given the magnitude of the `Year` values, we will need to increase
    the positive value of the dummy variables as, with a value of 1, they will have
    little to no effect given that the values for `Year` are in the thousands. Throughout
    the following exercise, we will demonstrate that regression models can be composed
    of both discrete and continuous values and that, depending on an appropriate choice
    of dummy variables, performance can be improved.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟变量是我们可以通过现有数据集提供的信息引入模型中的分类变量。这些变量的设计和选择被视为特征工程的一部分，具体结果会根据变量的选择而有所不同。我们之前观察到，移动平均值从大约1960年开始持续上升，初始的平稳期大约在1945年结束。我们将引入两个虚拟变量，`Gt_1960`和`Gt_1945`；这两个变量将表示测量时间是否大于1960年和1945年。虚拟变量通常被赋值为0或1，以表示每行数据是否具有指定类别。在我们的例子中，由于`Year`的值较大，我们需要增加虚拟变量的正值，因为在`Year`的值达到千位数时，1的值几乎没有影响。在接下来的练习中，我们将展示回归模型可以由离散值和连续值组成，并且根据适当选择虚拟变量，模型的性能可以得到改善。
- en: 'Exercise 30: Introducing Dummy Variables'
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '练习 30: 引入虚拟变量'
- en: 'In this exercise, we will introduce two dummy variables into our linear regression
    model:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将向线性回归模型中引入两个虚拟变量：
- en: 'For convenience, assign the index values of the `df_group_year` DataFrame to
    the `Year` column:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了方便起见，将 `df_group_year` 数据框的索引值分配给 `Year` 列：
- en: '[PRE15]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create a dummy variable with a column labeled `Gt_1960`, where the value is
    `0` if the year is less than 1960 and `10` if greater:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个虚拟变量，并为其添加一个名为 `Gt_1960` 的列，其中，如果年份小于1960，则值为 `0`，如果大于1960，则值为 `10`：
- en: '[PRE16]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output will be as follows:'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.17: Added column Gt_1960](img/C12622_03_17.jpg)'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.17: 添加的列 Gt_1960](img/C12622_03_17.jpg)'
- en: 'Figure 3.17: Added column Gt_1960'
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 3.17: 添加的列 Gt_1960'
- en: 'Create a dummy variable with a column labeled `Gt_1945`, where the value is
    `0` if the year is less than 1945 and `10` if greater:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个虚拟变量，并为其添加一个名为 `Gt_1945` 的列，其中，如果年份小于1945，则值为 `0`，如果大于1945，则值为 `10`：
- en: '[PRE17]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output will be:'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果将是：
- en: '![Figure 3.18: Added column Gt_1945](img/C12622_03_18.jpg)'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.18: 添加的列 Gt_1945](img/C12622_03_18.jpg)'
- en: 'Figure 3.18: Added column Gt_1945'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 3.18: 添加的列 Gt_1945'
- en: 'Call the `tail()` method to look at the last two rows of the `df_group_year`
    DataFrame to confirm that the post 1960 and 1945 labels have been correctly assigned:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用 `tail()` 方法查看 `df_group_year` 数据框的最后两行，以确认1960年后和1945年后的标签是否已正确分配：
- en: '[PRE18]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output will be:'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果将是：
- en: '![Figure 3.19: Last two values](img/C12622_03_19.jpg)'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.19: 最后两行值](img/C12622_03_19.jpg)'
- en: 'Figure 3.19: Last two values'
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 3.19: 最后两行值'
- en: 'Fit the linear model with the additional dummy variables by passing the `Year`,
    `Gt_1960`, and `Gt_1945` columns as inputs to the model, with `AverageTemperature`
    again as the output:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将 `Year`、`Gt_1960` 和 `Gt_1945` 列作为输入，`AverageTemperature` 列作为输出，来拟合带有附加虚拟变量的线性模型：
- en: '[PRE19]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output will be:'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果将是：
- en: '![Figure 3.20: Linear model fitted on data](img/C12622_03_20.jpg)'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.20: 基于数据拟合的线性模型](img/C12622_03_20.jpg)'
- en: 'Figure 3.20: Linear model fitted on data'
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 3.20: 基于数据拟合的线性模型'
- en: 'Check the R-squared score for the new model against the training data to see
    whether we made an improvement:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查新模型的 R-squared 得分，并与训练数据进行比较，看看是否有所改进：
- en: '[PRE20]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output will be as follows:'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.21: R-squared score for the model](img/C12622_03_21.jpg)'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.21: 模型的 R-squared 得分](img/C12622_03_21.jpg)'
- en: 'Figure 3.21: R-squared score for the model'
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 3.21: 模型的 R-squared 得分'
- en: 'We have made an improvement! This is a reasonable step in accuracy given that
    the first model''s performance was 0.8618\. We will plot another trendline, but
    we will need more values than before to accommodate the additional complexity
    of the dummy variables. Use `linspace` to create 20 linearly spaced values between
    1902 and 2013:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经取得了进展！考虑到第一个模型的性能为0.8618，这在准确度上是一个合理的步骤。我们将绘制另一条趋势线，但由于虚拟变量增加了额外的复杂性，我们需要更多的值。使用`linspace`创建20个在1902到2013年之间均匀分布的值：
- en: '[PRE21]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We''ll get this output:'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将得到以下输出：
- en: '![Figure 3.22: Array of 20 years created using linspace](img/C12622_03_22.jpg)'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.22：使用 linspace 创建的20年数组](img/C12622_03_22.jpg)'
- en: 'Figure 3.22: Array of 20 years created using linspace'
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.22：使用 linspace 创建的20年数组
- en: 'Create an array of zeros in the shape *20 x 3* and fill the first column of
    values with `x`, the second column with the dummy variable value for greater than
    1960, and the third column with the dummy variable value for greater than 1945:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个形状为*20 x 3*的零数组，并将第一列的值填充为`x`，第二列填充为大于1960的虚拟变量值，第三列填充为大于1945的虚拟变量值：
- en: '[PRE22]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output will be:'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果将是：
- en: '![Figure 3.23: Finding trend_x](img/C12622_03_23.jpg)'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.23：寻找 trend_x](img/C12622_03_23.jpg)'
- en: 'Figure 3.23: Finding trend_x'
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.23：寻找 trend_x
- en: 'Now get the *y* values for the trendline by making predictions for `trend_x`:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在通过对 `trend_x` 进行预测，获取趋势线的 *y* 值：
- en: '[PRE23]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output will be as follows:'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.24: Finding trend_y](img/C12622_03_24.jpg)'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.24：寻找 trend_y](img/C12622_03_24.jpg)'
- en: 'Figure 3.24: Finding trend_y'
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.24：寻找 trend_y
- en: 'Plot the trendline:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制趋势线：
- en: '[PRE24]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output will be as follows:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.25: Predictions using dummy variables](img/C12622_03_25.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.25：使用虚拟变量的预测](img/C12622_03_25.jpg)'
- en: 'Figure 3.25: Predictions using dummy variables'
  id: totrans-204
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.25：使用虚拟变量的预测
- en: Incorporating dummy variables made quite an improvement to the model, but looking
    at the trendline, it doesn't seem like a reasonable path for natural phenomena
    such as temperature to take and could be suffering from overfitting. We will cover
    overfitting in more detail in *Chapter 5*, *Ensemble Modeling*; however, let's
    use linear regression to fit a model with a smoother prediction curve, such as
    a parabola.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 引入虚拟变量对模型进行了相当大的改进，但从趋势线来看，这似乎不是一个自然现象（如温度）应遵循的合理路径，可能存在过拟合的问题。我们将在*第5章*，*集成建模*中详细讲解过拟合；不过，我们可以先使用线性回归来拟合一个更平滑的预测曲线模型，比如抛物线。
- en: 'Activity 7: Dummy Variables'
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 7：虚拟变量
- en: For this activity, we will use the Austin, Texas weather dataset that we used
    in the previous activity. In this activity, we will use dummy variables to enhance
    our linear regression model for this dataset.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本活动，我们将使用在之前活动中使用的德克萨斯州奥斯汀的天气数据集。在本活动中，我们将使用虚拟变量来增强该数据集的线性回归模型。
- en: 'Before we begin, we will need to import a few libraries and load data from
    a previous activity, which can be done as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，我们需要导入一些库，并从之前的活动中加载数据，具体操作如下：
- en: '[PRE25]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The steps to be performed are as follows:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 需要执行的步骤如下：
- en: Plot the raw data (`df`) and moving average (`rolling`).
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制原始数据（`df`）和移动平均（`rolling`）。
- en: Looking at the result of the previous step, there seems to be an inflection
    point around day 250\. Create a dummy variable to introduce this feature into
    the linear model.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从上一步的结果来看，似乎在第250天左右有一个拐点。创建一个虚拟变量，将此特征引入线性模型中。
- en: Check the first and last samples to confirm that the dummy variable is correct.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查首尾样本，以确认虚拟变量是否正确。
- en: Use a least squares linear regression model and fit the model to the `DayOfYear`
    values and the dummy variable to predict `TempAvgF`.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用最小二乘法线性回归模型，将模型拟合到 `DayOfYear` 的值和虚拟变量，预测 `TempAvgF`。
- en: Compute the R2 score.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算 R2 分数。
- en: Using the `DayOfYear` values, create a set of predictions using the model to
    construct a trendline.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `DayOfYear` 的值，利用该模型构造趋势线进行预测。
- en: Plot the trendline against the data and moving average.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将趋势线与数据和移动平均进行对比绘制。
- en: Note
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 334.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解答请见第334页。
- en: Parabolic Model with Linear Regression
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线性回归的抛物线模型
- en: 'Linear regression models are not simply constrained to straight-line linear
    models. We can fit some more complicated models using the exact same techniques.
    We have mentioned that there seems to be some parabolic characteristics to the
    data, so let''s try fitting a parabolic model. As a reminder, the equation for
    a parabola is:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型不仅仅局限于直线模型。我们可以使用完全相同的技术拟合一些更复杂的模型。我们提到过数据似乎具有一些抛物线特征，所以我们来尝试拟合一个抛物线模型。提醒一下，抛物线的方程是：
- en: '![](img/C12622_03_26.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12622_03_26.jpg)'
- en: 'Figure 3.26: Equation for a parabola'
  id: totrans-223
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.26：抛物线的方程
- en: The addition of this squared term transforms the model from a straight line
    to one that has a parabolic (or arc like) trajectory.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 添加这个平方项将把模型从一条直线转换为具有抛物线（或弧线）轨迹的模型。
- en: '![Figure 3.27: Parabolic curve](img/C12622_03_27.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.27：抛物线曲线](img/C12622_03_27.jpg)'
- en: 'Figure 3.27: Parabolic curve'
  id: totrans-226
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.27：抛物线曲线
- en: 'Exercise 31: Parabolic Models with Linear Regression'
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 31：使用线性回归拟合抛物线模型
- en: 'In order to fit a parabolic model using linear regression, we just need to
    manipulate our inputs a little. In this exercise, we''ll see how to do it:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用线性回归拟合一个抛物线模型，我们只需要稍微调整一下输入。在这个练习中，我们将看到如何做到这一点：
- en: 'The first thing we need to do is provide a squared term for year values. For
    convenience, create a copy of the index and store it in a `Year` column. Now square
    the `Year` column to provide parabolic features and assign the result to the `Year2`
    column:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是为年份值提供平方项。为了方便，创建一个索引的副本并将其存储在 `Year` 列中。现在对 `Year` 列进行平方，提供抛物线特征，并将结果分配给
    `Year2` 列：
- en: '[PRE26]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We''ll get this:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将得到这个：
- en: '![Figure 3.28: First five rows](img/C12622_03_28.jpg)'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.28：前五行数据](img/C12622_03_28.jpg)'
- en: 'Figure 3.28: First five rows'
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.28：前五行数据
- en: 'Fit the data to the model. This time, we will need to provide two sets of values
    as the inputs to the model, `Year` and `Year2`, which is equivalent to passing
    *x* and *x**2* to the parabolic equation. As we are providing two columns of data,
    we do not need to reshape the input data as it will be provided as an *N x 2*
    array by default. The target *y* value remains the same:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据拟合到模型中。这一次，我们需要提供两组值作为模型的输入，`Year` 和 `Year2`，这相当于将 *x* 和 *x**2* 传递给抛物线方程。由于我们提供了两列数据，因此不需要重新调整输入数据，它将默认作为
    *N x 2* 数组提供。目标 *y* 值保持不变：
- en: '[PRE27]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output will be as follows:'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.29: Model fitted](img/C12622_03_29.jpg)'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.29：模型拟合](img/C12622_03_29.jpg)'
- en: 'Figure 3.29: Model fitted'
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.29：模型拟合
- en: 'Print the parameters of the model by looking at the coefficients and the intercept;
    there will now be two coefficients to print:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印模型的参数，通过查看系数和截距；现在将有两个系数需要打印：
- en: '[PRE28]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output will be:'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将会是：
- en: '![Figure 3.30: Model coefficients and intercept](img/C12622_03_30.jpg)'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.30：模型系数和截距](img/C12622_03_30.jpg)'
- en: 'Figure 3.30: Model coefficients and intercept'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.30：模型系数和截距
- en: Evaluate the performance of the model using the `score` method. Has the performance
    improved?
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `score` 方法评估模型的表现。性能有所提高吗？
- en: '[PRE29]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We''ll get the following output:'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将获得以下输出：
- en: '![Figure 3.31: R-squared score](img/C12622_03_31.jpg)'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.31：R 平方得分](img/C12622_03_31.jpg)'
- en: 'Figure 3.31: R-squared score'
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.31：R 平方得分
- en: 'Yes, the model has improved slightly on the dummy variable method, but let''s
    look at the trendline to see whether it is a more reasonable fit. Plot the trendline
    as we did before. Again, to effectively plot the parabolic arc of the trendline,
    we will need more predicted values. Use `linspace` to create 20 linearly spaced
    values between 1902 and 2013:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是的，模型在虚拟变量方法上略有改进，但让我们看看趋势线，看看它是否更合理地拟合。像之前那样绘制趋势线。为了有效地绘制趋势线的抛物线弧线，我们需要更多的预测值。使用
    `linspace` 创建 1902 和 2013 之间 20 个线性间隔的值：
- en: '[PRE30]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We''ll get this:'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将得到这个：
- en: '![Figure 3.32: Finding 20 increments using linspace](img/C12622_03_32.jpg)'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.32：使用 linspace 查找 20 个增量](img/C12622_03_32.jpg)'
- en: 'Figure 3.32: Finding 20 increments using linspace'
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.32：使用 linspace 查找 20 个增量
- en: 'Now the model we trained takes two columns of year data as an input: the first
    column containing squared yearly values and the second just the year value itself.
    To provide the data to the model, create a NumPy array (`trend_x`) of zeros with
    20 rows and 2 columns. Square the values for `x` and assign to the first column
    of `trend_x`, and simply assign `x` to the second column of `trend_x`:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们训练的模型需要两列年份数据作为输入：第一列包含平方的年份值，第二列仅包含年份值本身。为了向模型提供数据，创建一个20行2列的零数组（`trend_x`）。将`x`的平方值赋值给`trend_x`的第一列，直接将`x`赋值给`trend_x`的第二列：
- en: '[PRE31]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The output will be:'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果为：
- en: '![Figure 3.33: Trends for the x variable](img/C12622_03_33.jpg)'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.33：x变量的趋势](img/C12622_03_33.jpg)'
- en: 'Figure 3.33: Trends for the x variable'
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.33：x变量的趋势
- en: 'Now get the *y* values for the trendline by making predictions for `trend_x`:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在通过对`trend_x`进行预测，获取趋势线的*y*值：
- en: '[PRE32]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We''ll get this:'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将得到如下结果：
- en: '![Figure 3.34: Trends for the y variable](img/C12622_03_34.jpg)'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.34：y变量的趋势](img/C12622_03_34.jpg)'
- en: 'Figure 3.34: Trends for the y variable'
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.34：y变量的趋势
- en: 'Plot the trendline as per the straight-line model. Remember that the *x* axis
    values for `trend_y` are the years; that is, the second column of `trend_x`, and
    not the years squared:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照直线模型绘制趋势线。记住，`trend_y`的*x*轴值是年份，也就是`trend_x`的第二列，而不是年份的平方：
- en: '[PRE33]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output will be as follows:'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.35: Linear regression with a parabolic model](img/C12622_03_35.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.35：带有抛物线模型的线性回归](img/C12622_03_35.jpg)'
- en: 'Figure 3.35: Linear regression with a parabolic model'
  id: totrans-268
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.35：带有抛物线模型的线性回归
- en: Referring to *Figure 3.35*, we can see the performance benefit in using the
    parabolic model, with the trendline almost following the 10-year moving average.
    This is a reasonably good fit given the amount of noise in the yearly average
    raw data. In such a case, it should not be expected that the model will fit the
    data perfectly. If our model was to perfectly fit the observed examples, there
    would be a very strong case for overfitting the data, leading to poor predictive
    power with unseen examples.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 参考*图 3.35*，我们可以看到使用抛物线模型的性能优势，趋势线几乎与10年移动平均线相吻合。考虑到年度平均原始数据中的噪声量，这个拟合效果相当不错。在这种情况下，不应该期望模型能够完美地拟合数据。如果我们的模型能够完美拟合观察到的示例，那么就可能存在严重的过拟合问题，导致模型在面对未见数据时的预测能力较差。
- en: 'Activity 8: Other Model Types with Linear Regression'
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 8：其他线性回归模型类型
- en: We have tried a standard linear model as well as a dummy variable. In this activity,
    we will experiment with a few different functions to try and get a better fit
    for the data. For each different function, try to make sure you print the function
    parameters, R2 value, and plot the trendline against the original and moving average
    data.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试了标准的线性模型以及虚拟变量。在这个活动中，我们将尝试几个不同的函数，看看如何更好地拟合数据。对于每个不同的函数，确保打印函数参数、R2值，并将趋势线与原始数据及移动平均数据进行比较。
- en: Try a few different functions, experiment with the data, and see how good your
    predictions can get. In this activity, we will use the sine function.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试几个不同的函数，实验数据，看看你的预测能力能达到什么程度。在这个活动中，我们将使用正弦函数。
- en: 'Before we begin, we will need to import a few libraries and load data from
    a previous activity, which can be done as follows:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，我们需要导入一些库并加载来自先前活动的数据，操作步骤如下：
- en: '[PRE34]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The steps to be performed are as follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 执行的步骤如下：
- en: Use a sine curve function as the basis of the model.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用正弦曲线函数作为模型的基础。
- en: Print the parameters of the model.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印模型的参数。
- en: Compute the r2 value to measure the performance.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算r2值以衡量模型性能。
- en: Construct the trendline values.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建趋势线值。
- en: Plot the trendline with the raw data and the moving average.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制带有原始数据和移动平均线的趋势线。
- en: Note
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 338.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该活动的解答可以在第338页找到。
- en: Generic Model Training
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通用模型训练
- en: The least squares method of constructing a linear regression model is a useful
    and accurate method of training, assuming that the dimensionality of the dataset
    is low and that the system memory is sufficiently large to be able to manage the
    dataset and, in the case of the scikit-learn implementation, the matrix division
    operation. In recent times, large datasets have become more readily available,
    with universities, governments, and even some companies releasing large datasets
    for free online; as such, it may be relatively easy to exceed system memory when
    using the least squares method of regression modeling. In this situation, we will
    need to employ a different method of training the algorithm, such as gradient
    descent, which is not *as* susceptible to high dimensionality, allows large datasets
    to be trained, and avoids the use of memory intensive matrix operations. Before
    we look at gradient descent in a little more detail, we will revisit the process
    of training a model in a more general form, as most training methods, including
    gradient descent, adhere to this generic process (*Figure 3.36*). The training
    process involves the repeated exposure of the model and its parameters to a set
    of example training data and passing the predicted values issued by the model
    to a specified cost or error function.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法构建线性回归模型是一种有用且准确的训练方法，前提是数据集的维度较低，并且系统内存足够大，能够管理数据集以及在 scikit-learn 实现中进行矩阵除法操作。近年来，大型数据集变得更加容易获取，许多大学、政府甚至一些公司都在线免费发布了大型数据集；因此，在使用最小二乘法回归建模时，可能相对容易超出系统内存。在这种情况下，我们需要采用不同的训练方法，比如梯度下降，它*不那么*容易受到高维度的影响，能够训练大规模数据集，并避免使用内存密集型的矩阵运算。在我们进一步探讨梯度下降之前，我们将重新审视训练模型的一般过程，因为大多数训练方法，包括梯度下降，都遵循这一通用过程（*图
    3.36*）。训练过程涉及将模型及其参数反复暴露给一组示例训练数据，并将模型输出的预测值传递给指定的成本或误差函数。
- en: 'The cost function is used to determine how close the model is to its target
    values and a measure of progress throughout the training process. The final piece
    of the process is the definition of the training hyperparameters, which, as discussed
    at the start of this chapter, are the means by which the process of updating the
    model is regulated:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 成本函数用于确定模型与目标值的接近程度，并衡量训练过程中进展的程度。过程的最后一步是定义训练超参数，如本章开头所讨论的那样，这些超参数是调节模型更新过程的手段：
- en: '![Figure 3.36: Generic training process](img/C12622_03_36.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.36：通用训练过程](img/C12622_03_36.jpg)'
- en: 'Figure 3.36: Generic training process'
  id: totrans-287
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.36：通用训练过程
- en: Gradient Descent
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 梯度下降
- en: 'The process of gradient descent can be summarized as a means of updating the
    parameters of the model proportionally and in response to an error within the
    system, as defined by the cost function. There are a number of cost functions
    that can be selected, depending on the type of model being fitted or the problem
    being solved. We will select the simple but effective mean squared error cost
    function, but first we will rewrite our model equation in notation consistent
    with that generally used within machine learning literature. Using the equation
    of a straight line as our model:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降过程可以总结为根据成本函数定义的误差，逐步更新模型参数，并响应系统中的错误。有多种成本函数可以选择，具体取决于拟合的模型类型或解决的问题。我们将选择简单但有效的均方误差成本函数，但首先，我们将以与机器学习文献中普遍使用的符号一致的方式重写我们的模型方程。以直线方程为我们的模型：
- en: '![Figure 3.37: Equation of a straight line](img/C12622_03_37.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.37：直线方程](img/C12622_03_37.jpg)'
- en: 'Figure 3.37: Equation of a straight line'
  id: totrans-291
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.37：直线方程
- en: 'It can be rewritten as:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以重写为：
- en: '![Figure 3.38: Shortened linear model](img/C12622_03_38.jpg)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.38：简化线性模型](img/C12622_03_38.jpg)'
- en: 'Figure 3.38: Shortened linear model'
  id: totrans-294
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.38：简化线性模型
- en: 'Where ![](img/C12622_Formula_03_03.png) is the prediction made by the model
    and, by convention, ![](img/C12622_Formula_03_04.png) is used to represent the
    intercept term. With the new model notation, we can define the mean squared error
    function as follows:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![](img/C12622_Formula_03_03.png) 是模型做出的预测，按照惯例，![](img/C12622_Formula_03_04.png)
    用来表示截距项。使用新的模型符号，我们可以定义均方误差函数如下：
- en: '![Figure 3.39: Mean squared error](img/C12622_03_39.jpg)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.39：均方误差](img/C12622_03_39.jpg)'
- en: 'Figure 3.39: Mean squared error'
  id: totrans-297
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.39：均方误差
- en: Where *y**t* is the corresponding ground truth value and *N* is the number of
    training samples.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *y**t* 是对应的真实值，*N* 是训练样本的数量。
- en: 'With these two functions defined, we can now look at the gradient descent algorithm
    in greater detail:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了这两个函数后，我们现在可以更详细地看一下梯度下降算法：
- en: Gradient descent starts by taking an initial, random guess at the values for
    all ![](img/C12622_Formula_03_05.png).
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 梯度下降法从对所有![](img/C12622_Formula_03_05.png)的初始随机猜测开始。
- en: A prediction for each of the samples in the training set is made using the random
    values for ![](img/C12622_Formula_03_05.png).
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对训练集中的每个样本，使用随机值为![](img/C12622_Formula_03_05.png)进行预测。
- en: The error for those parameters ![](img/C12622_Formula_03_06.png) is then computed.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后计算这些参数![](img/C12622_Formula_03_06.png)的误差。
- en: The values for ![](img/C12622_Formula_03_05.png) are then modified, making a
    small adjustment proportional to the error, in an attempt to minimize the error.
    More formally, the update process takes the current value for ![](img/C12622_Formula_03_07.png)
    and subtracts the component of ![](img/C12622_Formula_03_06.png) attributed to
    ![](img/C12622_Formula_03_07.png) times the small adjustment ![](img/C12622_Formula_03_08.png),
    otherwise known as the learning rate.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后修改![](img/C12622_Formula_03_05.png)的值，做出与误差成比例的小调整，试图最小化误差。更正式地说，更新过程使用![](img/C12622_Formula_03_07.png)的当前值，并减去![](img/C12622_Formula_03_06.png)中与![](img/C12622_Formula_03_07.png)相关的部分，该部分等于![](img/C12622_Formula_03_07.png)乘以小调整量![](img/C12622_Formula_03_08.png)，也称为学习率。
- en: 'Without delving too deeply into the mathematical details, the equation to update
    the parameters or weights (![](img/C12622_Formula_03_09.png)) can be written as
    follows:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 不深入探讨数学细节，更新参数或权重(![](img/C12622_Formula_03_09.png))的方程可以写成如下：
- en: '![Figure 3.40: Gradient descent update step](img/C12622_03_40.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.40：梯度下降更新步骤](img/C12622_03_40.jpg)'
- en: 'Figure 3.40: Gradient descent update step'
  id: totrans-306
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.40：梯度下降更新步骤
- en: 'Let''s discuss this equation:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来讨论这个方程：
- en: The`:=` operator denotes variable reassignment or update as a computer programming
    concept.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:=`操作符表示计算机编程概念中的变量重新赋值或更新。'
- en: This training process will continue until convergence; that is, until the changes
    to the weights are so small that there is essentially no change to the parameters,
    or until we intervene and stop the process, as is the case in cross-validation.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个训练过程将持续到收敛；也就是说，直到权重的变化非常小，以至于参数几乎没有变化，或者直到我们介入并停止该过程，就像在交叉验证中的情况一样。
- en: The value assigned to the learning rate is critical for the training process
    as it defines how large the changes to the weights are and subsequently how big
    the steps to take down the error curve are. If the value is too small, the training
    process may take far too long or may get stuck in areas of local minima of the
    error curve and not find an optimal global value. Alternatively, if the steps
    are too large, the training process can become unstable, as they pass over the
    local and global minima.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为学习率分配的值对训练过程至关重要，因为它定义了权重变化的大小，从而决定了沿误差曲线下降的步伐大小。如果值过小，训练过程可能会耗费过长时间，或可能会陷入误差曲线的局部最小值，无法找到最优的全局值。相反，如果步伐过大，训练过程可能会变得不稳定，因为它们会越过局部和全局最小值。
- en: 'This process is visualized in the following graph:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程在下图中进行了可视化：
- en: '![Figure 3.41: Gradient descent process](img/C12622_03_41.jpg)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.41：梯度下降过程](img/C12622_03_41.jpg)'
- en: 'Figure 3.41: Gradient descent process'
  id: totrans-313
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.41：梯度下降过程
- en: Note
  id: totrans-314
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: As a general hint for setting the learning rate, start larger, say around 0.1,
    and if a solution cannot be found, that is, the error is a `NaN` (not a number),
    reduce by a factor of 10\. Keep going until the training is continuing and the
    error is continually reducing. Once you are happy with the model and are almost
    done, reduce the learning rate by a small amount and let the training run for
    longer.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 关于设置学习率的一般建议是，从较大的值开始，比如0.1，如果找不到解决方案，即误差为`NaN`（不是一个数字），则将其减少一个数量级。继续这样做，直到训练过程持续进行并且误差不断减少。一旦你对模型满意并且几乎完成时，将学习率稍微减小，并让训练继续更长时间。
- en: 'While this process may sound complicated, it isn''t anywhere near as scary
    as it looks. Gradient descent can be summarized by making a one-time only guess
    at the values for the weights, calculating the error in the guess, making small
    adjustments to the weights, and continually repeating the process until the error
    converges at a minimum value. To reinforce our understanding, let''s look at a
    more concrete example. We will use gradient descent to train the original linear
    regression model we constructed in *Exercise 29: Fitting a Linear Model Using
    the Least Squares Method*, replacing the least squares method with gradient descent.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个过程听起来可能很复杂，但它远没有看起来那么可怕。梯度下降可以总结为：第一次猜测权重的值，计算猜测的误差，对权重进行微小调整，并不断重复这一过程，直到误差收敛到最小值。为了加深我们的理解，让我们看一个更具体的例子。我们将使用梯度下降法来训练我们在*练习29：使用最小二乘法拟合线性模型*中构建的原始线性回归模型，使用梯度下降法替代最小二乘法。
- en: 'Exercise 32: Linear Regression with Gradient Descent'
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 32：使用梯度下降法的线性回归
- en: 'Before we can start the gradient descent process, we need to spend a little
    bit of time setting up the model. In our Jupyter notebook, perform these steps:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始梯度下降过程之前，我们需要花一点时间来设置模型。在我们的Jupyter笔记本中，执行以下步骤：
- en: 'Write a function to define our linear model. This is where the advantage of
    using the shortened form of the linear model (*Figure 3.38*) comes in handy. We
    can use linear algebra multiplication between the weights (theta) and the input
    values, *x*, which is the equivalent of ![](img/C12622_Formula_03_10.png):'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个函数来定义我们的线性模型。这时，使用线性模型的简化形式（*图3.38*）的优势就显现出来了。我们可以利用线性代数乘法，将权重（theta）与输入值，*x*，进行相乘，这等价于
    ![](img/C12622_Formula_03_10.png)：
- en: '[PRE35]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: In order to use this linear algebra multiplication technique, we must modify
    the input data by inserting a row of ones to represent the bias term. Create an
    array of ones with a shape of two columns (one for the gradient term of the weights
    and one for the bias term). Insert the normalized `Year` values into the first
    row of the newly created array.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使用这种线性代数乘法技巧，我们必须通过插入一行全为1的值来修改输入数据，以表示偏置项。创建一个具有两列形状的全1数组（一个用于权重的梯度项，另一个用于偏置项）。将标准化后的`Year`值插入到新创建数组的第一行。
- en: 'To use the input data in a gradient descent process, we must also normalize
    all of the values to be between 0 and 1\. This is a critical aspect of the process,
    as if one variable has values in the order of, say 1,000, and the second in the
    order of 10, then the first variable will be 100 times more influential in the
    training process and could lead to the inability to train the model. By ensuring
    that all variables are scaled between 0 and 1, they will have equal influence
    during training. Scale the input by dividing the values for `Year` by the maximum
    value:'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要在梯度下降过程中使用输入数据，我们还必须将所有值标准化到0到1之间。这是过程中的一个关键步骤，因为如果一个变量的值是1,000级别，而第二个变量是10级别，那么第一个变量在训练过程中将比第二个变量影响大100倍，这可能会导致模型无法训练。通过确保所有变量都在0到1之间缩放，它们将在训练过程中有相同的影响。通过将`Year`的值除以最大值来对输入数据进行缩放：
- en: '[PRE36]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'You''ll get this output:'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将得到如下输出：
- en: '![Figure 3.42: Modified data](img/C12622_03_42.jpg)'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图3.42：修改后的数据](img/C12622_03_42.jpg)'
- en: 'Figure 3.42: Modified data'
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.42：修改后的数据
- en: 'As we have learned, we need to take an initial guess at the values for the
    weights. We need to define two weight values, one for the gradient and one for
    the *y* intercept. To ensure that the same first random number is initialized
    each time, seed the NumPy random number generator. Seeding the random number generator
    ensures that each time the script is run, the same set of random numbers are produced.
    This ensures the consistency of the same model in multiple runs and provides the
    opportunity to check the performance of the model against possible changes:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如我们所学，我们需要对权重的值进行初始猜测。我们需要定义两个权重值，一个用于梯度，另一个用于*y*截距。为了确保每次初始化时使用相同的第一个随机数，需要对NumPy的随机数生成器进行初始化。初始化随机数生成器确保每次运行脚本时，生成的随机数集是相同的。这保证了多次运行中模型的一致性，并提供了检查模型表现是否受变化影响的机会：
- en: '[PRE37]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Initialize the weights with a normally distributed random number with a mean
    of 0 and standard deviation of 0.1\. We want the initialized weights to be random,
    but still close to zero to give them a chance to find a good solution. In order
    to execute the matrix multiplication operation in `h_x`, reshape the random numbers
    to one row and two columns (one for the gradient and one for the *y* intercept):'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用均值为0、标准差为0.1的正态分布随机数初始化权重。我们希望初始化的权重是随机的，但仍然接近零，以便给它们找到良好解的机会。为了执行`h_x`中的矩阵乘法操作，将随机数重塑为一行两列（一个用于梯度，一个用于*y*截距）：
- en: '[PRE38]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We''ll get the following output:'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将得到如下输出：
- en: '![Figure 3.43: Theta value](img/C12622_03_43.jpg)'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图3.43：Theta值](img/C12622_03_43.jpg)'
- en: 'Figure 3.43: Theta value'
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.43：Theta值
- en: 'Define the ground truth values as the average yearly temperatures:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义真实值为平均年气温：
- en: '[PRE39]'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Define the cost function (mean squared error) as a Python function:'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将代价函数（均方误差）定义为Python函数：
- en: '[PRE40]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Define the learning rate as discussed earlier. This is a very important parameter
    and it must be set appropriately. As mentioned earlier, set it too small and the
    model may take a very long time to find a minimum; set it too large and it may
    not reach it at all. Define the learning rate as `1e-6`:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义如前所述的学习率。这是一个非常重要的参数，必须适当设置。如前所述，设置得太小，模型可能需要很长时间才能找到最小值；设置得太大，可能根本找不到最小值。将学习率定义为`1e-6`：
- en: '[PRE41]'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Define a function that implements a step of gradient descent (*Figure 3.40*).
    The function will take the predicted and true values as well as the values for
    *x* and *gamma*, and return the value to be added to the weights (theta):'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来实现梯度下降的一步（*图3.40*）。该函数将接收预测值和真实值，以及*x*和*gamma*的值，并返回需要添加到权重（theta）的值：
- en: '[PRE42]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Define the maximum number of epochs (or iterations) we want the training process
    to run for. Each epoch predicts the values of *y* (the normalized annual mean
    land temperature) given *x* and updates the weights in accordance with the error
    in the predictions:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义我们希望训练过程运行的最大epoch数（或迭代次数）。每个epoch根据给定的*x*预测*y*值（标准化的年均气温），并根据预测误差更新权重：
- en: '[PRE43]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Make an initial prediction and calculate the error or cost in that prediction
    using the defined `h_x` and `J_theta` functions:'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 做一个初步预测，并使用定义的`h_x`和`J_theta`函数计算该预测的误差或代价：
- en: '[PRE44]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The output will be as follows:'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.44: Initial cost of J theta](img/C12622_03_44.jpg)'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图3.44：J theta的初始代价](img/C12622_03_44.jpg)'
- en: 'Figure 3.44: Initial cost of J theta'
  id: totrans-348
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.44：J theta的初始代价
- en: 'Complete the first update step by hand. Use the newly predicted values to call
    the `update` function, make another call to `h_x` to get the predicted values,
    and get the new error:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 手动完成第一次更新步骤。使用新预测的值来调用`update`函数，再次调用`h_x`获取预测值，并得到新的误差：
- en: '[PRE45]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We''ll get the following output:'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将得到如下输出：
- en: '![Figure 3.45: Updated cost of J theta](img/C12622_03_45.jpg)'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图3.45：更新后的J theta代价](img/C12622_03_45.jpg)'
- en: 'Figure 3.45: Updated cost of J theta'
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.45：更新后的J theta代价
- en: 'Notice the small reduction in the error; as such, many epochs of training will
    be required. Put the `predict` and `update` function calls in a `for` loop for
    `max_epochs` and print the corresponding error at each tenth epoch:'
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意到误差的微小减少；因此，需要很多epoch的训练。将`predict`和`update`函数调用放入`for`循环中，循环次数为`max_epochs`，并在每第十个epoch打印相应的误差：
- en: '[PRE46]'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The output will be as follows:'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.46: Ten epochs](img/C12622_03_46.jpg)'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图3.46：十个epoch](img/C12622_03_46.jpg)'
- en: 'Figure 3.46: Ten epochs'
  id: totrans-358
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.46：十个epoch
- en: 'Visualize the training history by plotting `epoch_hist` versus `error_hist`:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过绘制`epoch_hist`与`error_hist`来可视化训练历史：
- en: '[PRE47]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output will be:'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将是：
- en: '![Figure 3.47: Training history curve: a very important tool](img/C12622_03_47.jpg)'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图3.47：训练历史曲线：一个非常重要的工具](img/C12622_03_47.jpg)'
- en: 'Figure 3.47: Training history curve: a very important tool'
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.47：训练历史曲线：一个非常重要的工具
- en: Notice that the error reaches an asymptote at 30,000 epochs, and thus `max_epochs`
    could be reduced.
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意到误差在30,000个epoch时达到了一个渐近值，因此`max_epochs`可以减少。
- en: 'Use the `r2_score` function from `sklearn.metrics` to compute the R-squared
    score for the model trained using gradient descent:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`sklearn.metrics`中的`r2_score`函数来计算通过梯度下降训练的模型的R平方值：
- en: '[PRE48]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We''ll get the following output:'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将得到如下输出：
- en: '![Figure 3.48: R-squared score](img/C12622_03_48.jpg)'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图3.48：R平方值](img/C12622_03_48.jpg)'
- en: 'Figure 3.48: R-squared score'
  id: totrans-369
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.48：R平方值
- en: 'To plot the trendline for the new model, again create 20 linearly spaced year
    values between 1901 and 2013:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了绘制新模型的趋势线，再次创建 1901 到 2013 年之间线性间隔的 20 个年份值：
- en: '[PRE49]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output will be as follows:'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.49: Values using linspace](img/C12622_03_49.jpg)'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.49：使用 linspace 的值](img/C12622_03_49.jpg)'
- en: 'Figure 3.49: Values using linspace'
  id: totrans-374
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.49：使用 linspace 的值
- en: In order to use this data with our model, we must first normalize the maximum
    value to scale between 0 and 1 and insert a row of ones. Execute this step in
    a similar way to when the data was prepared for training in *Step 2*.
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了将这些数据与我们的模型一起使用，我们必须首先将最大值标准化到 0 到 1 之间，并插入一行 1。执行此步骤的方式与为训练准备数据时的 *步骤 2*
    类似。
- en: '[PRE50]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The output will be as follows:'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.50: Trends in x](img/C12622_03_50.jpg)'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.50：x 的趋势](img/C12622_03_50.jpg)'
- en: 'Figure 3.50: Trends in x'
  id: totrans-379
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.50：x 的趋势
- en: 'Call the `h_x` model function with the weights saved from the training process
    to get predicted *y* values for the trendline:'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练过程中保存的权重，调用`h_x`模型函数，得到趋势线的预测 *y* 值：
- en: '[PRE51]'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '![Figure 3.51: Trends in y](img/C12622_03_51.jpg)'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.51：y 的趋势](img/C12622_03_51.jpg)'
- en: 'Figure 3.51: Trends in y'
  id: totrans-383
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.51：y 的趋势
- en: 'Plot the trendline with the data:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用数据绘制趋势线：
- en: '[PRE52]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The output will be as follows:'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.52: Mean air temperature measurements using gradient descent](img/C12622_03_52.jpg)'
  id: totrans-387
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.52：使用梯度下降的平均气温测量值](img/C12622_03_52.jpg)'
- en: 'Figure 3.52: Mean air temperature measurements using gradient descent'
  id: totrans-388
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.52：使用梯度下降的平均气温测量值
- en: 'Congratulations! You have just trained your first model with gradient descent.
    This is an important step as this simple tool can be used to construct more complicated
    models such as logistic regression and neural network models. We must first, however,
    note one important observation: the r-squared value produced by the gradient descent
    model is not as high as the least squares model.'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你刚刚用梯度下降训练了第一个模型。这是一个重要的步骤，因为这个简单的工具可以用来构建更复杂的模型，如逻辑回归和神经网络模型。然而，我们首先需要注意一个重要的观察结果：梯度下降模型产生的
    r 方值不如最小二乘法模型高。
- en: 'In the first step of gradient descent, we guess some plausible values for the
    weights, and then make small adjustments to the weights in an attempt to reduce
    the error and stop training only when the error stops reducing. Gradient descent
    finds its power in two specific applications:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在梯度下降的第一步，我们猜测一些合理的权重值，然后对权重进行小幅调整，试图减少误差，并在误差停止减少时停止训练。梯度下降的优势体现在两个特定的应用中：
- en: Solving more complicated models for which a mathematically optimal solution
    has yet to be or cannot be found
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决更复杂的模型，这些模型的数学最优解尚未找到或无法找到
- en: Providing a means of training with datasets or parameters that are so large
    that physical hardware restrictions, such as available memory, prevent the use
    of other methods such as least squares
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供一种训练方法，适用于数据集或参数非常庞大，以至于物理硬件的限制（例如可用内存）阻止了使用其他方法，如最小二乘法
- en: So, if the dataset is not excessively large and can be solved optimally, we
    should definitely use the more precise method. That being said, there are many
    more options available to modify the gradient descent process, including different
    types of gradient descent algorithms and more advanced uses of learning rate and
    the way the data is supplied during training. These modifications fall outside
    the scope of this book, as an entire book could be written on the gradient descent
    process and methods for improving performance.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果数据集不是特别庞大并且可以通过优化解决，我们应该毫不犹豫地使用更精确的方法。话虽如此，还有很多方法可以修改梯度下降过程，包括不同类型的梯度下降算法、更高级的学习率使用方式以及训练过程中数据的供给方式。这些修改超出了本书的范围，因为关于梯度下降过程和改进性能方法的整本书都有写作空间。
- en: 'Exercise 33: Optimizing Gradient Descent'
  id: totrans-394
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 33：优化梯度下降
- en: 'In the previous exercise, we implemented gradient descent directly; however,
    we would not typically use this implementation. The scikit-learn method of gradient
    descent contains a number of optimizations and can be used in only a few lines
    of code:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个练习中，我们直接实现了梯度下降；然而，我们通常不会使用这种实现。scikit-learn 的梯度下降方法包含了许多优化，并且只需要几行代码即可使用：
- en: 'Import the `SGDRegressor` class and construct a model using the same parameters
    as used in the previous exercise:'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`SGDRegressor`类，并使用与前一个练习中相同的参数构建模型：
- en: '[PRE53]'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Use the year values, divided by the maximum year value, as an input and fit
    with the `AverageTemperature` values as the ground truth:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用年份值，除以最大年份值，作为输入，并与 `AverageTemperature` 值作为真实值进行拟合：
- en: '[PRE54]'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Predict the values using the trained model and determine the r-squared value:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练好的模型预测值，并确定 r-squared 值：
- en: '[PRE55]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Plot the trendline as determined by the model in addition to the raw data and
    the moving average:'
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制由模型确定的趋势线，除了原始数据和移动平均值之外：
- en: '[PRE56]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The output will be as follows:'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.53: Optimized gradient descent predicted trendline](img/C12622_03_53.jpg)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.53：优化后的梯度下降预测趋势线](img/C12622_03_53.jpg)'
- en: 'Figure 3.53: Optimized gradient descent predicted trendline'
  id: totrans-406
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.53：优化后的梯度下降预测趋势线
- en: 'Compare this graph to the one constructed using the manual implementation of
    gradient descent. Notice the similarities: this provides us with confidence that
    both implementations of gradient descent are correct.'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 将此图与使用梯度下降手动实现构建的图形进行比较。注意它们的相似性：这使我们有信心，梯度下降的两种实现都是正确的。
- en: 'Activity 9: Gradient Descent'
  id: totrans-408
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 9：梯度下降
- en: In this activity, we will implement the same model as *Activity 6*, *Linear
    Regression Using the Least Squares Method*; however, we will use the gradient
    descent process.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，我们将实现与 *活动 6*，*使用最小二乘法进行线性回归* 相同的模型；但是，我们将使用梯度下降过程。
- en: 'Before we begin, we will need to import a few libraries and load data from
    a previous activity, which can be done as follows:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，我们需要导入一些库并加载来自先前活动的数据，可以按照以下方式进行：
- en: '[PRE57]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The steps to be performed are as follows:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 执行的步骤如下：
- en: Create a generic gradient descent model and normalize the day of year values
    to be between 0 and 1.
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个通用的梯度下降模型，并将年份值标准化到0到1之间。
- en: Fit the model.
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合模型。
- en: Print the details of the model.
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印模型的详细信息。
- en: Prepare the *x* `(trend_x`) trendline values by dividing by the maximum. Predict
    `y_trend_values` using the gradient descent model.
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备 *x* `(trend_x)` 趋势线的值，通过除以最大值。使用梯度下降模型预测 `y_trend_values`。
- en: Plot the data and the moving average with the trendline.
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制数据、移动平均值和趋势线。
- en: Note
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 341.
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以在第341页找到。
- en: Multiple Linear Regression
  id: totrans-420
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多元线性回归
- en: 'We have already covered regular linear regression, as well as linear regression
    with polynomial terms, and considered training them with both the least squares
    method and gradient descent. This section of the chapter will consider an additional
    type of linear regression: multiple linear regression, where more than one type
    of variable (or feature) is used to construct the model. To examine multiple linear
    regression, we will use a modified version of the Boston Housing Dataset, available
    from [https://archive.ics.uci.edu/ml/index.php](B13323_03_ePub_Final_NT.xhtml#_idTextAnchor114).
    The modified dataset can be found in the accompanying source code or on GitHub
    at [https://github.com/TrainingByPackt/Supervised-Learning-with-Python](B13323_03_ePub_Final_NT.xhtml#_idTextAnchor115)
    and has been reformatted for simplified use. This dataset contains a list of different
    attributes for property in the Boston area, including the crime rate per capita
    by town, the percentage of the population with a lower socio-economic status,
    as well as the average number of rooms per dwelling, and the median value of owner-occupied
    homes in the area.'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经涵盖了常规线性回归，以及带有多项式项的线性回归，并考虑了使用最小二乘法和梯度下降法训练它们。本章的这一部分将考虑另一种类型的线性回归：多元线性回归，其中使用多个变量（或特征）来构建模型。为了研究多元线性回归，我们将使用波士顿住房数据集的修改版，该数据集可从
    [https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)
    获取。修改后的数据集可以在随附的源代码中找到，或者在 GitHub 上找到：[https://github.com/TrainingByPackt/Supervised-Learning-with-Python](https://github.com/TrainingByPackt/Supervised-Learning-with-Python)，并且已被重新格式化以简化使用。该数据集包含波士顿地区不同属性的列表，包括按城镇计算的人均犯罪率、低社会经济状态人口的百分比、每个住宅的平均房间数，以及该地区业主自住房屋的中位数价值。
- en: 'Exercise 34: Multiple Linear Regression'
  id: totrans-422
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 34：多元线性回归
- en: 'We will use the Boston Housing Dataset to construct a multiple linear model
    that predicts the median value of owner-occupied homes given the percentage of
    the population with a lower socio-economic status and the average number of rooms
    per dwelling:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用波士顿住房数据集来构建一个多元线性模型，该模型预测在给定低社会经济状态人口百分比和每个住宅的平均房间数的情况下，业主自住房屋的中位数价值：
- en: 'Import the required dependencies:'
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的依赖项：
- en: '[PRE58]'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Read in the housing database:'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取住房数据库：
- en: '[PRE59]'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The `head()` function will return the following output:'
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`head()` 函数将返回以下输出：'
- en: '![Figure 3.54: First five rows](img/C12622_03_54.jpg)'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.54：前五行](img/C12622_03_54.jpg)'
- en: 'Figure 3.54: First five rows'
  id: totrans-430
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.54：前五行
- en: 'Plot both columns: average number of rooms (`RM`) and the percentage of the
    population of a lower socio-economic status (`PTRATIO`):'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制两个列：平均房间数量（`RM`）和低社会经济状态人口的百分比（`PTRATIO`）：
- en: '[PRE60]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The output will be as follows:'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.55: Parameters versus the median value](img/C12622_03_55.jpg)'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.55：参数与中位数值的关系](img/C12622_03_55.jpg)'
- en: 'Figure 3.55: Parameters versus the median value'
  id: totrans-435
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.55：参数与中位数值的关系
- en: 'Construct a linear regression model for the percentage of lower socio-economic
    status (`LSTAT`) versus the median property value (`MEDV`), and compute the performance
    of the model in terms of the R-squared value:'
  id: totrans-436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个线性回归模型，用于预测低社会经济状态的百分比（`LSTAT`）与中位数房产价值（`MEDV`）之间的关系，并计算模型的性能，使用 R 平方值来衡量：
- en: '[PRE61]'
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'We''ll get the following output:'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将获得以下输出：
- en: '![Figure 3.56: Model score using LSTAT](img/C12622_03_56.jpg)'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.56：使用 LSTAT 的模型评分](img/C12622_03_56.jpg)'
- en: 'Figure 3.56: Model score using LSTAT'
  id: totrans-440
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.56：使用 LSTAT 的模型评分
- en: 'Compute the prediction performance of the linear model trained using the average
    number of rooms to predict the property value:'
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算使用平均房间数量训练的线性模型的预测性能，以预测房产价值：
- en: '[PRE62]'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The output will be as follows:'
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.57: Model score using RM](img/C12622_03_57.jpg)'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.57：使用 RM 的模型评分](img/C12622_03_57.jpg)'
- en: 'Figure 3.57: Model score using RM'
  id: totrans-445
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.57：使用 RM 的模型评分
- en: 'Create a multiple linear regression model using both the `LSTAT` and `RM` values
    as input to predict the median property value:'
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个多元线性回归模型，使用 `LSTAT` 和 `RM` 值作为输入，预测中位数房产价值：
- en: '[PRE63]'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The output will be:'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 3.58: Model score using LSTAT and RM](img/C12622_03_58.jpg)'
  id: totrans-449
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.58：使用 LSTAT 和 RM 的模型评分](img/C12622_03_58.jpg)'
- en: 'Figure 3.58: Model score using LSTAT and RM'
  id: totrans-450
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.58：使用 LSTAT 和 RM 的模型评分
- en: Autoregression Models
  id: totrans-451
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自回归模型
- en: Autoregression models are part of a more classical statistical modeling technique
    that is used on time series data (that is, any dataset that changes with time)
    and extends upon the linear regression techniques covered in this chapter. Autoregression
    models are commonly used in the economics and finance industry as they are particularly
    powerful in time series datasets with a sizeable number of measurements. To reflect
    this, we will change our dataset to the S&P daily closing prices from 1986 to
    2018, which is available in the accompanying source code.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 自回归模型是经典统计建模技术的一部分，通常用于时间序列数据（即任何随时间变化的数据集），并在本章中涉及的线性回归技术基础上进行扩展。自回归模型在经济学和金融行业中广泛应用，因为它们在拥有大量测量数据的时间序列数据集中尤其有效。为了反映这一点，我们将数据集更改为
    1986 年到 2018 年的标准普尔每日收盘价格，该数据可在随附的源代码中找到。
- en: '![Figure 3.59: S&P 500 Daily Closing Price](img/C12622_03_59.jpg)'
  id: totrans-453
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.59：标准普尔 500 指数每日收盘价](img/C12622_03_59.jpg)'
- en: 'Figure 3.59: S&P 500 Daily Closing Price'
  id: totrans-454
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.59：标准普尔 500 指数每日收盘价
- en: 'The main principle behind autoregression models is that, given enough previous
    observations, a reasonable prediction for the future can be made; that is, we
    are essentially constructing a model using the dataset as a regression against
    itself, hence **autoregression**. This relationship can be modeled mathematically
    as a linear equation:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 自回归模型背后的主要原理是，给定足够的先前观察数据，就可以对未来做出合理的预测；换句话说，我们实际上是在使用数据集将其自身作为回归来构建模型，因此称为
    **自回归**。这种关系可以用线性方程在数学上建模：
- en: '![](img/C12622_03_60.jpg)'
  id: totrans-456
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12622_03_60.jpg)'
- en: 'Figure 3.60: First-order autoregression model'
  id: totrans-457
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.60：一阶自回归模型
- en: Where ![](img/C12622_Formula_03_11.png) is the predicted value for time, *t*,
    ![](img/C12622_Formula_03_12.png) is the first weight of the model, ![](img/C12622_Formula_03_13.png)
    is the second weight with ![](img/C12622_Formula_03_14.png) as the previous value
    in the dataset, and ![](img/C12622_Formula_03_15.png) is an error term.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![](img/C12622_Formula_03_11.png) 是时间 *t* 的预测值，![](img/C12622_Formula_03_12.png)
    是模型的第一个权重，![](img/C12622_Formula_03_13.png) 是第二个权重，且 ![](img/C12622_Formula_03_14.png)
    是数据集中前一个值，![](img/C12622_Formula_03_15.png) 是误差项。
- en: The equation in *Figure 3.60* represents a model using only the previous value
    in the dataset to make a prediction. This is a first-order autoregression model
    and can be extended to include more previous samples.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的方程 *图 3.60* 表示使用数据集中的前一个值进行预测的模型。这是一个一阶自回归模型，可以扩展为包括更多的前置样本。
- en: The equation in *Figure 3.61* provides an example of a second-order model, including
    the previous two values.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3.61* 中的方程提供了一个二阶模型的示例，包括之前的两个值。'
- en: Similarly, a *k**th* order autoregression model contains values with corresponding
    parameters between ![](img/C12622_Formula_03_16.png), adding more context about
    the previous observations about the model. Again, referring to the equation in
    *Figure 3.61* and the *k**th* order autoregression, the recursive properties of
    the autoregression model can also be observed. Each prediction uses the previous
    value(s) in its summation, and thus, if we take the previously predicted values,
    they themselves use the predictions of the previous value, hence the recursion.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，*k**阶*自回归模型包含与 ![](img/C12622_Formula_03_16.png) 相应的参数值，增加了关于模型前期观测的更多上下文。同样，参考
    *图 3.61* 中的方程和 *k**阶*自回归模型，可以观察到自回归模型的递归特性。每个预测都会使用前一个值（或多个值）进行求和，因此，如果我们取之前预测的值，它们本身也会使用前一个值的预测，因此产生了递归。
- en: '![Figure 3.61: Second and kth order autoregression model](img/C12622_03_61.jpg)'
  id: totrans-462
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.61：二阶和k阶自回归模型](img/C12622_03_61.jpg)'
- en: 'Figure 3.61: Second and kth order autoregression model'
  id: totrans-463
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.61：二阶和k阶自回归模型
- en: 'Exercise 35: Creating an Autoregression Model'
  id: totrans-464
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 35：创建自回归模型
- en: 'We will use the S&P 500 model to create an autoregression model:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用标准普尔500指数模型来创建一个自回归模型：
- en: 'Load the S&P 500 dataset, extract the year represented as two digits in the
    column date, and create a new column, `Year`, with the year represented in the
    four-digit format (for example, 02-Jan-86 will become 1986 and 31-Dec-04 will
    become 2004):'
  id: totrans-466
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载标准普尔500指数数据集，从日期列中提取表示年份的两位数字，并创建一个新的列 `Year`，将年份转换为四位数格式（例如，02-Jan-86 会变为
    1986，31-Dec-04 会变为 2004）：
- en: '[PRE64]'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'We''ll get the following output:'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将获得以下输出：
- en: '![Figure 3.62: First five rows](img/C12622_03_62.jpg)'
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.62：前五行](img/C12622_03_62.jpg)'
- en: 'Figure 3.62: First five rows'
  id: totrans-470
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.62：前五行
- en: 'Plot the raw dataset with years along the *x* axis in multiples of five:'
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制原始数据集，x 轴按五年为单位：
- en: '[PRE65]'
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The output will be as follows:'
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.63: Plot of closing price through the years](img/C12622_03_63.jpg)'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.63：历年收盘价图](img/C12622_03_63.jpg)'
- en: 'Figure 3.63: Plot of closing price through the years'
  id: totrans-475
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.63：历年收盘价图
- en: 'Before we can construct an autoregression model, we must first check to see
    whether the model is able to be used as a regression against itself. To do that,
    we can once again use the pandas library to check for correlations between the
    dataset and a copy of the dataset that is shifted by a defined number of samples,
    known as `shift` method, introduce a sample lag of `3` into the first 10 values
    of the closing price and look at the result:'
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们构建自回归模型之前，必须首先检查该模型是否能够作为一个回归模型使用。为此，我们可以再次使用 pandas 库检查数据集与其平移了定义数量样本的副本之间的相关性，这种方法称为
    `shift` 方法，引入一个 `3` 的样本滞后并查看前 10 个收盘价的结果：
- en: '[PRE66]'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We''ll get this output:'
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将得到这个输出：
- en: '![Figure 3.64: Values with a lag of three](img/C12622_03_64.jpg)'
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.64：滞后三期的值](img/C12622_03_64.jpg)'
- en: 'Figure 3.64: Values with a lag of three'
  id: totrans-480
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.64：滞后三期的值
- en: Notice the introduction of three NaN values into the array and that the last
    three values have dropped off the array. This is the effect of shifting, essentially
    sliding the dataset forward in time by the period defined by the lag.
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意数组中引入了三个 NaN 值，并且最后三个值已从数组中删除。这是平移的效果，实质上是将数据集根据滞后期定义的时间段向前滑动。
- en: 'Shift the dataset by a lag of 100 and plot the result:'
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集按 100 的滞后平移并绘制结果：
- en: '[PRE67]'
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The output will be as follows:'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.65: Plot of closing price over the year](img/C12622_03_65.jpg)'
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.65：全年收盘价图](img/C12622_03_65.jpg)'
- en: 'Figure 3.65: Plot of closing price over the year'
  id: totrans-486
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.65：全年收盘价图
- en: 'Now that we have an understanding of the time shift, we will confirm that the
    data can be correlated against itself. To do this, use the pandas `autocorrelation_plot`
    method to check for randomness within the data:'
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经理解了时间平移，我们将确认数据是否能够与其自身相关。为此，使用 pandas 的 `autocorrelation_plot` 方法来检查数据中的随机性：
- en: '[PRE68]'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The output will be as follows:'
  id: totrans-489
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.66: Relation of autocorrelation versus the lag](img/C12622_03_66.jpg)'
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.66：自相关与滞后的关系](img/C12622_03_66.jpg)'
- en: 'Figure 3.66: Relation of autocorrelation versus the lag'
  id: totrans-491
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.66：自相关与滞后的关系
- en: All of the information required to determine whether autoregression is possible
    is defined within this plot. We can see on the *x* axis, the values for **Lag**
    range from 0 to 8,000 samples, and the values for **Autocorrelation** vary from
    approximately -0.4 to 1\. There are five other additional lines of interest; however,
    at this scale on the *y* axis, it is difficult to see them.
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确定是否可以进行自动回归的所有信息都定义在这个图中。我们可以在*x*轴上看到，**Lag**的值从0到8,000个样本变化，而**Autocorrelation**的值大约在-0.4到1之间。还有五条其他的附加线比较重要；不过，在这个*y*轴的刻度下，很难看到它们。
- en: 'Set the *y* axis limits to be between -0.1 and 0.1:'
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将*y*轴的限制设置为-0.1到0.1之间：
- en: '[PRE69]'
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The output will be as follows:'
  id: totrans-495
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 3.67: Plot of autocorrelation versus lag](img/C12622_03_67.jpg)'
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.67：自相关与滞后图](img/C12622_03_67.jpg)'
- en: 'Figure 3.67: Plot of autocorrelation versus lag'
  id: totrans-497
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.67：自相关与滞后图
- en: We can see in the enhanced view that there are two gray dashed lines, which
    represent the 99% confidence band that the series is non-random. The solid gray
    line represents the 95% confidence band. Once the autocorrelation plot approaches
    zero within these bands, the time series with the specified lag becomes sufficiently
    random that autoregression models would not be appropriate.
  id: totrans-498
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在增强视图中，我们可以看到有两条灰色虚线，表示99%置信带，表明该序列是非随机的。实线灰色线表示95%置信带。一旦自相关图在这些带内接近零，带有指定滞后的时间序列就变得足够随机，自动回归模型将不再适用。
- en: To further solidify our understanding, create a plot of the closing prices versus
    the closing prices with a lag of 100 samples. According to our autocorrelation
    plot, there is a high correlation between these sets. What does that look like?
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了进一步巩固我们的理解，绘制收盘价与滞后100个样本的收盘价的图。根据我们的自相关图，这两组数据之间存在高度的相关性。那是什么样子的呢？
- en: '[PRE70]'
  id: totrans-500
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The output will be:'
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将是：
- en: '![Figure 3.68: Autocorrelation plot](img/C12622_03_68.jpg)'
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.68：自相关图](img/C12622_03_68.jpg)'
- en: 'Figure 3.68: Autocorrelation plot'
  id: totrans-503
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.68：自相关图
- en: 'Create a plot of closing prices versus closing prices with a lag of 4,000 samples.
    Again, looking at the autocorrelation plot at a lag of 4,000, the autocorrelation
    value is approximately 0, indicating that there is no real correlation between
    the two and it is mostly random:'
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建收盘价与滞后4,000个样本的收盘价图。同样，根据自相关图，在滞后4,000时，自相关值大约为0，表示两者之间没有真正的相关性，它们大多是随机的：
- en: '[PRE71]'
  id: totrans-505
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The output will be:'
  id: totrans-506
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将是：
- en: '![Figure 3.69: Plot of closing prices versus closing prices with a lag of 4,000
    samples](img/C12622_03_69.jpg)'
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.69：收盘价与滞后4,000个样本的收盘价图](img/C12622_03_69.jpg)'
- en: 'Figure 3.69: Plot of closing prices versus closing prices with a lag of 4,000
    samples'
  id: totrans-508
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.69：收盘价与滞后4,000个样本的收盘价图
- en: 'Now we are ready to create our model. To do this, however, we will need another
    Python package, the `statsmodel` package ([http://www.statsmodels.org](B13323_03_ePub_Final_NT.xhtml#_idTextAnchor113)),
    which is similar to scikit-learn but is dedicated to creating models and executing
    tests using the more classical statistical techniques. Install the `statsmodel`
    package. You can do this either using `conda install` or `pip`. For the Anaconda
    installation, the `conda install` method is preferred:'
  id: totrans-509
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们准备创建模型了。然而，为了做到这一点，我们还需要一个Python包——`statsmodel`包（[http://www.statsmodels.org](B13323_03_ePub_Final_NT.xhtml#_idTextAnchor113)），它类似于scikit-learn，但专门用于创建模型并执行使用更经典统计技术的测试。安装`statsmodel`包。你可以使用`conda
    install`或`pip`来安装。对于Anaconda安装，推荐使用`conda install`方法：
- en: '[PRE72]'
  id: totrans-510
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Import the autoregression class (`AR`) from `statsmodel` and construct the
    model using the closing price data:'
  id: totrans-511
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`statsmodel`导入自回归类（`AR`），并使用收盘价数据构建模型：
- en: '[PRE73]'
  id: totrans-512
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Fit the model using the `fit` method and print out the lag that was selected
    for use and the coefficients of the model:'
  id: totrans-513
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`fit`方法拟合模型，并打印出选择使用的滞后值以及模型的系数：
- en: '[PRE74]'
  id: totrans-514
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The output will be:'
  id: totrans-515
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将是：
- en: '![Figure 3.70: Lag co-efficients](img/C12622_03_70.jpg)'
  id: totrans-516
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.70：滞后系数](img/C12622_03_70.jpg)'
- en: 'Figure 3.70: Lag coefficients'
  id: totrans-517
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.70：滞后系数
- en: Note that there are 36 coefficients for each of the weights and one constant;
    only an extract is shown for simplicity. All coefficients can be found in the
    `Ex7-AutoRegressors.ipynb` Jupyter notebook in the accompanying source code.
  id: totrans-518
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，每个权重都有36个系数，还有一个常数；为了简便起见，这里仅显示了一部分。所有系数可以在随附源代码中的`Ex7-AutoRegressors.ipynb`
    Jupyter笔记本中找到。
- en: 'Use the model to create a set of predictions starting at sample 36 (the lag)
    and finishing at 500 samples after the dataset has ended:'
  id: totrans-519
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用该模型从第36个样本（滞后）开始创建一组预测，直到数据集结束后的500个样本为止：
- en: '[PRE75]'
  id: totrans-520
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'We''ll get the following output:'
  id: totrans-521
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将得到以下输出：
- en: '![](img/C12622_03_71.jpg)'
  id: totrans-522
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C12622_03_71.jpg)'
- en: 'Figure 3.71: Prediction values'
  id: totrans-523
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.71：预测值
- en: 'Plot the predictions'' values over the top of the original dataset:'
  id: totrans-524
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测值覆盖在原始数据集上进行绘制：
- en: '[PRE76]'
  id: totrans-525
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'This will give the following output:'
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 3.72: Plot of price through the year](img/C12622_03_72.jpg)'
  id: totrans-527
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图3.72：全年价格变化图](img/C12622_03_72.jpg)'
- en: 'Figure 3.72: Plot of price through the year'
  id: totrans-528
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.72：全年价格变化图
- en: Note that the predictions do an excellent job of following the dataset, and
    that after the dataset has ended, the predictions are relatively linear. Given
    that the model is constructed from the previous samples, it makes sense that it
    becomes less certain once the dataset has finished, particularly as there are
    no repetitive patterns in the data.
  id: totrans-529
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，预测值很好地跟踪了数据集，并且在数据集结束后，预测值相对线性。由于模型是基于之前的样本构建的，因此一旦数据集结束，它变得不那么确定，尤其是数据中没有重复模式时，这一点尤为明显。
- en: 'The fit seems really close – what does the difference between the predictions
    and original dataset look like? Enhance the model to observe the differences:'
  id: totrans-530
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合看起来非常接近——预测值与原始数据集之间的差异是什么样的？增强模型以观察差异：
- en: '[PRE77]'
  id: totrans-531
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'This provides the following plot:'
  id: totrans-532
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将提供以下图形：
- en: '![Figure 3.73: Predictions on the original dataset values](img/C12622_03_73.jpg)'
  id: totrans-533
  prefs: []
  type: TYPE_IMG
  zh: '![图3.73：原始数据集值的预测](img/C12622_03_73.jpg)'
- en: 'Figure 3.73: Predictions on the original dataset values'
  id: totrans-534
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.73：原始数据集值的预测
- en: From this exercise using an autoregressor, we can see that there is significant
    predictive power in using these models when there is missing data from the set
    or when we are attempting to predict between measurement intervals. The autoregressor
    model shown for the S&P 500 dataset was able to effectively provide predictions
    within the range of observed samples. However, outside of this range, when predicting
    future values for which no measurements have been taken, the predictive power
    may be somewhat limited.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用自回归模型的这个练习，我们可以看到，在数据集缺失数据时，或当我们尝试在测量间隔之间进行预测时，使用这些模型具有显著的预测能力。对于S&P 500数据集显示的自回归模型，它能够有效地提供观测样本范围内的预测。然而，超出该范围，当预测未来值且没有测量数据时，预测能力可能会有所限制。
- en: 'Activity 10: Autoregressors'
  id: totrans-536
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动10：自回归模型
- en: 'In this activity, we will now use autoregressors to model the Austin weather
    dataset and predict future values:'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，我们将使用自回归模型来建模奥斯汀的天气数据集，并预测未来的值：
- en: 'Before we begin, we will need to import a few libraries and load data from
    a previous activity, which can be done as follows:'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，我们需要导入一些库，并从之前的活动中加载数据，操作如下：
- en: '[PRE78]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The steps to be performed are as follows:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 需要执行的步骤如下：
- en: Plot the complete set of average temperature values (`df.TempAvgF`) with years
    on the *x* axis.
  id: totrans-541
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制完整的平均温度值（`df.TempAvgF`）图，年份作为*X*轴。
- en: Create a 20-day lag and plot the lagged data on the original dataset.
  id: totrans-542
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个20天的滞后，并将滞后的数据绘制在原始数据集上。
- en: Construct an autocorrelation plot to see whether the average temperature can
    be used with an autoregressor.
  id: totrans-543
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建自相关图，查看平均温度是否可以与自回归模型一起使用。
- en: Choose an acceptable lag and an unacceptable lag and construct lag plots using
    these values.
  id: totrans-544
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个可接受的滞后和一个不可接受的滞后，并使用这些值构建滞后图。
- en: Create an autoregressor model, note the selected lag, calculate the r2 value,
    and plot the autoregressor model with the original plot. The model is to project
    past the available data by 1,000 samples.
  id: totrans-545
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个自回归模型，注意所选的滞后，计算r2值，并将自回归模型与原始图形一起绘制。该模型将预测超出可用数据的1,000个样本。
- en: Fit the model to the data.
  id: totrans-546
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到数据中。
- en: Create a set of predictions for 1,000 days after the last sample.
  id: totrans-547
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为数据集结束后的1,000天创建一组预测。
- en: Plot the predictions, as well as the original dataset.
  id: totrans-548
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制预测值以及原始数据集。
- en: Enhance the view to look for differences by showing the 100th to 200th sample.
  id: totrans-549
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过显示第100个到第200个样本，增强视图以查找差异。
- en: Note
  id: totrans-550
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 344.
  id: totrans-551
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第344页找到。
- en: Summary
  id: totrans-552
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we took our first big leap into constructing machine learning
    models and making predictions with labeled datasets. We began our analysis by
    looking at a variety of different ways to construct linear models, starting with
    the precise least squares method, which is very good when modeling small amounts
    of data that can be processed using the available computer memory. The performance
    of our vanilla linear model was improved using dummy variables, which we created
    from categorical variables, adding additional features and context to the model.
    We then used linear regression analysis with a parabolic model to further improve
    performance, fitting a more natural curve to the dataset. We also implemented
    the gradient descent algorithm, which we noticed, while not as precise as the
    least squares method was for our limited dataset, was most powerful when the dataset
    cannot be processed on the resources available on the system.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们迈出了构建机器学习模型和使用带标签数据进行预测的第一大步。我们首先分析了多种构建线性模型的方式，从精确的最小二乘法开始，当对少量数据建模时，这种方法非常有效，可以使用可用的计算机内存进行处理。我们通过使用从分类变量中创建的虚拟变量来改进我们的基础线性模型，为模型增加了额外的特征和上下文。接着，我们使用了带抛物线模型的线性回归分析来进一步改进性能，使得模型更贴近数据集的自然曲线。我们还实施了梯度下降算法，虽然我们注意到，对于我们的有限数据集来说，它并不像最小二乘法那样精确，但在系统资源无法处理数据集时表现最为强大。
- en: Finally, we investigated the use of autoregression models, which predict future
    values based on the experience of previous data in the set. Using autoregressors,
    we were able to accurately model the closing price of the S&P 500 over the years
    1986 – 2018.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们研究了自回归模型的应用，这些模型基于先前数据的经验预测未来值。通过使用自回归模型，我们能够准确地对1986年至2018年间标准普尔500指数的收盘价进行建模。
- en: Now that we have experience with supervised regression problems, we will turn
    our attention to classification problems in the next chapter.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了监督回归问题的经验，我们将在下一章节关注分类问题。
