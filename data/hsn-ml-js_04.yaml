- en: Grouping with Clustering Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用聚类算法进行分组
- en: 'A common and introductory unsupervised learning problem is that of *clustering.*
    Often, you have large datasets that you wish to organize into smaller groups,
    or wish to break up into logically similar groups. For instance, you can try to
    divide census data of household incomes into three groups: low, high, and super
    rich. If you feed the household income data into a clustering algorithm, you would
    expect to see three data points as a result, with each corresponding to the average
    value of your three categories. Even this one-dimensional problem of clustering
    household incomes may be difficult to do by hand, because you might not know where
    one group should end and the other should begin. You could use governmental definitions
    of income brackets, but there''s no guarantee that those brackets are geometrically
    balanced; they were invented by policymakers and may not accurately represent
    the data.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见且入门级的无监督学习问题是 *聚类*。通常，你拥有大量数据集，希望将其组织成更小的组，或者希望将其分解成逻辑上相似的组。例如，你可以尝试将家庭收入普查数据分为三个组：低收入、高收入和超级富豪。如果你将家庭收入数据输入到聚类算法中，你预计会看到三个数据点作为结果，每个数据点对应于你三个类别的平均值。即使这个一维的聚类家庭收入问题也可能很难手工完成，因为你可能不知道一个组应该在哪里结束，另一个组应该在哪里开始。你可以使用政府关于收入分组的定义，但没有保证这些分组在几何上是平衡的；它们是由政策制定者发明的，可能无法准确代表数据。
- en: A *cluster* is a group of logically similar data points. They can be users with
    similar behavior, citizens with similar income ranges, pixels with similar colors,
    and so on. The k-means algorithm is numerical and geometric, so the clusters it
    identifies will all be numerically similar, with data points that are geometrically
    close to one another. Fortunately, most data can be represented numerically, so
    the k-means algorithm is useful for many different problem domains.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*簇* 是一组逻辑上相似的数据点。它们可以是具有相似行为的用户、具有相似收入范围的公民、具有相似颜色的像素等等。k-means 算法是数值和几何的，因此它所识别的簇都将具有数值上的相似性，并且数据点在几何上彼此接近。幸运的是，大多数数据都可以用数值表示，因此
    k-means 算法适用于许多不同的问题领域。'
- en: 'The k-means algorithm is a powerful, fast, and popular clustering algorithm
    for numerical data. The name k-means is comprised of two parts: ***k***, which
    represents the number of clusters that we want the algorithm to find, and ***means,***
    which is the method of determining where those cluster centers are (you could,
    for instance, also use k-medians or k-modes). Translated into plain English, we
    might ask the algorithm to find us three cluster centers that are the mean values
    of the points they represent. In that case, *k = 3* and we can tell our bosses
    that we did a k-means analysis with *k = 3* when filing our report.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: k-means 算法是一种强大、快速且流行的数值数据聚类算法。名称 k-means 由两部分组成：***k***，它代表我们希望算法找到的簇的数量，和***means***，这是确定那些簇中心位置的方法（例如，你也可以使用
    k-medians 或 k-modes）。用简单的英语来说，我们可能会要求算法为我们找到三个簇中心，这些中心是它们所代表点的平均值。在这种情况下，*k =
    3*，我们可以在提交报告时告诉我们的老板我们进行了 *k = 3* 的 k-means 分析。
- en: 'The k-means algorithm is an iterative algorithm, which means it runs a loop
    and continually updates its model until the model reaches steady state, at which
    point it will return its results. Put into narrative form, the k-means algorithm
    works like this: plot the data that you wish to analyze, and pick a value for
    *k*. You must know the value of *k* beforehand, or at least have an idea of what
    it should be (though we''ll also explore a way around this later in the chapter).
    Randomly create *k* points (if *k = 5*, create five points) and add them to your
    plot; these points are called the **centroids**, as they will ultimately represent
    the geometric centers of the clusters. For each data point in the plot, find the
    centroid closest to that point and connect or assign it to the point. Once all
    the assignments have been made, look at each centroid in turn and update its position
    to the mean position of all the points assigned to it. Repeat the assign-then-update
    procedure until the centroids stop moving; these final positions of the centroids
    are the output of the algorithm, and can be considered your cluster centers. If
    the narrative is hard to follow, don''t worry, we''ll dig into it more deeply
    as we build this algorithm from scratch.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: K-means算法是一个迭代算法，这意味着它会运行一个循环，并不断更新其模型，直到模型达到稳定状态，此时它将返回其结果。用叙述形式来说，k-means算法的工作方式是这样的：绘制你想要分析的数据，并选择一个*k*的值。你事先必须知道*k*的值，或者至少有一个大概的估计（尽管我们也会在后面的章节中探讨一种绕过这个问题的方法）。随机创建*k*个点（如果*k*等于5，就创建五个点），并将它们添加到你的图表中；这些点被称为**质心**，因为它们最终将代表簇的几何中心。对于图表中的每个数据点，找到离该点最近的质心，并将其连接或分配给该点。一旦所有分配都已完成，依次查看每个质心，并将其位置更新为分配给它的所有点的平均值。重复分配然后更新的过程，直到质心停止移动；这些质心的最终位置是算法的输出，可以被认为是你的簇中心。如果叙述难以理解，不要担心，随着我们从零开始构建这个算法，我们会更深入地探讨它。
- en: 'In this chapter, we''ll first discuss the concepts of average and distance
    and how they apply to the k-means algorithm. Then we''ll describe the algorithm
    itself and build a JavaScript class from scratch to implement the k-means algorithm.
    We''ll test our k-means solver with a couple of simple datasets, and then discuss
    what to do when you don''t know the value of *k* beforehand. We''ll build another
    tool that automates the discovery of the value *k*. We''ll also discuss what the
    concept of *error* means for k-means applications, and how to design an error
    algorithm that helps us achieve our goals. The following are the topics that will
    be covered in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先将讨论平均值和距离的概念以及它们如何应用于k-means算法。然后我们将描述算法本身，并从头开始构建一个JavaScript类来实现k-means算法。我们将用几个简单的数据集测试我们的k-means求解器，然后讨论在事先不知道*k*的值时应该做什么。我们将构建另一个工具来自动发现*k*的值。我们还将讨论对于k-means应用来说，*错误*的概念意味着什么，以及如何设计一个帮助实现我们目标的错误算法。以下是在本章中将要涉及的主题：
- en: Average and distance
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均值和距离
- en: Writing the k-means algorithm
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写k-means算法
- en: Example 1—k-means on simple 2D data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例1—简单2D数据上的k-means
- en: Example 2—3D data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例2—3D数据
- en: K-means where *k* is unknown
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当*k*未知时的K-means
- en: Average and distance
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平均值和距离
- en: 'The k-means algorithm relies on two concepts in order to operate: average and
    distance. In order to tell you where the center of a cluster is, the algorithm
    will calculate an average value for these points. In this case, we will use the
    arithmetic mean, or the sum of values divided by the number of values, to represent
    our average. In ES5/classic JavaScript (I''m also being purposefully explicit
    in this example, for any readers who are not familiar with calculating the mean),
    we might write a function like this:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法依赖于两个概念来运行：平均值和距离。为了告诉你簇的中心在哪里，算法将计算这些点的平均值。在这种情况下，我们将使用算术平均值，即值的总和除以值的数量，来表示我们的平均值。在ES5/经典JavaScript（我还在这个例子中有意地明确指出，对于不熟悉计算平均值的读者），我们可能会编写一个像这样的函数：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In ES6, we can abuse our shorthand privileges and write the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在ES6中，我们可以滥用我们的简写特权，并编写以下代码：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This is a handy ES6 one-liner to keep in your back pocket, however, it assumes
    all values are already numeric and defined, and it will return NaN if you give
    it an empty array. If the shorthand is confusing, we can break it up like so:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可以随时放在口袋里的ES6单行代码，然而，它假设所有值都已经数字化和定义好了，如果你给它一个空数组，它将返回NaN。如果这个简写让人困惑，我们可以这样拆分它：
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Keep in mind we can use any type of average, including the median and mode.
    In fact, it's sometimes preferable to use k-medians over k-means. The median does
    a better job of muting outliers than the mean does. You should therefore always
    ask yourself which average you actually need. If you want a representation of
    total resources consumed, for instance, you might use the arithmetic mean. If
    you suspect outliers are caused by faulty measurements and should be ignored,
    k-medians could suit you better.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们可以使用任何类型的平均值，包括中位数和众数。事实上，有时使用k-medians而不是k-means更可取。中位数在抑制异常值方面比平均值做得更好。因此，你应该始终问自己你实际上需要哪种平均值。例如，如果你想表示总资源消耗，你可能使用算术平均值。如果你怀疑异常值是由错误的测量引起的并且应该被忽略，k-medians可能更适合你。
- en: 'We will also need a concept of distance in this algorithm. It can be any distance
    measure, however, for numeric data you will mostly use the typical Euclidean distance—the
    standard distance measure you''d learn in high school—which in ES5 JavaScript
    looks like this for two dimensions:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在此算法中，我们还需要一个距离的概念。它可以采用任何距离度量，然而，对于数值数据，你将主要使用典型的欧几里得距离——你在高中学习过的标准距离度量，在ES5
    JavaScript中，对于二维数据如下所示：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We must support many more than two dimensions, however, so we can generalize
    to the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们必须支持超过两个维度的更多维度，因此可以推广如下：
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can write an ES6 one-liner for this, but it won''t be as readable as the
    lengthier, explicit example:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以为此编写一个ES6单行代码，但它不会像较长的、明确的示例那样易于阅读：
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Armed with these tools, we can start writing the k-means algorithm itself.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 带着这些工具，我们可以开始编写k-means算法本身。
- en: Writing the k-means algorithm
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写k-means算法
- en: 'The k-means algorithm is relatively simple to implement, so in this chapter
    we''ll write it from scratch. The algorithm requires only two pieces of information:
    the *k* in k-means (the number of clusters we wish to identify), and the data
    points to evaluate. There are additional parameters the algorithm can use, for
    example, the maximum number of iterations to allow, but they are not required.
    The only required output of the algorithm is *k* centroids, or a list of points
    that represent the centers of the clusters of data. If *k = 3*, then the algorithm
    must return three centroids as its output. The algorithm may also return other
    metrics, such as the total error, the total number of iterations required to reach
    steady state, and so on, but again these are optional.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: K-means算法相对简单易实现，因此在本章中我们将从头开始编写它。该算法只需要两条信息：k-means中的*k*（我们希望识别的聚类数量），以及要评估的数据点。算法还可以使用一些额外的参数，例如允许的最大迭代次数，但这些不是必需的。算法的唯一必需输出是*k*个质心，或者表示数据点聚类中心的点列表。如果*k*等于3，则算法必须返回三个质心作为其输出。算法还可以返回其他指标，例如总误差、达到稳态所需的总迭代次数等，但这些是可选的。
- en: 'A high-level description of the k-means algorithm is as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: K-means算法的高级描述如下：
- en: Given the parameter *k* and the data to process, initialize *k* candidate centroids
    randomly
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定参数*k*和要处理的数据，随机初始化*k*个候选质心
- en: For each data point, determine which candidate centroid is closest to that point
    and *assign* the point to that centroid
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个数据点，确定哪个候选质心与该点最近，并将该点*分配*给该质心
- en: For each centroid, update its position to be the mean position of all the points
    assigned to it
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个质心，将其位置更新为其分配给的所有点的平均位置
- en: Repeat *Step 2* and *Step 3* until the centroids' positions reach steady state
    (that is, the centroids stop moving)
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*步骤2*和*步骤3*，直到质心的位置达到稳态（即，质心停止移动）
- en: At the end of this process, you may return the positions of the centroids as
    the algorithm's output.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程结束时，你可以返回质心的位置作为算法的输出。
- en: Setting up the environment
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置环境
- en: Let's take a moment to set up our development environment for this algorithm.
    The environment will be as described in [Chapter 1](370a39e1-e618-475d-9722-9b4315a9a6ee.xhtml), *Exploring
    the Potential of JavaScript,* however, we'll run through the entire process here.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花点时间来设置这个算法的开发环境。环境将如[第1章](370a39e1-e618-475d-9722-9b4315a9a6ee.xhtml)中所述，*探索JavaScript的潜力*，然而，我们将在这里完整地走一遍整个过程。
- en: First, create a new folder for this project. I've named the folder `Ch4-kmeans`.
    Create a subfolder called `src` inside `Ch4-kmeans`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，为该项目创建一个新的文件夹。我已将该文件夹命名为`Ch4-kmeans`。在`Ch4-kmeans`内部创建一个名为`src`的子文件夹。
- en: 'Next, add a file called `package.json` to the `Ch4-kmeans` folder. Add the
    following content to the file:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将一个名为`package.json`的文件添加到`Ch4-kmeans`文件夹中。将该文件的内容添加如下：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: After creating the `package.json` file, switch to your terminal program and
    (from the `Ch4-kmeans` folder) run the `yarn install` command.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建`package.json`文件后，切换到您的终端程序，并在`Ch4-kmeans`文件夹中运行`yarn install`命令。
- en: 'Next, create three new files inside the `Ch4-kmeans/src` folder: `index.js`,
    `data.js`, and `kmeans.js`. We will write the actual k-means algorithm inside
    `kmeans.js`, we will load some example data into `data.js`, and we''ll use `index.js`
    as our bootstrapping point to set up and run a number of examples.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在`Ch4-kmeans/src`文件夹内创建三个新文件：`index.js`、`data.js`和`kmeans.js`。我们将在`kmeans.js`中编写实际的k-means算法，将一些示例数据加载到`data.js`中，并使用`index.js`作为我们的启动点来设置和运行多个示例。
- en: At this point, you may want to stop and test that everything is working. Add
    a simple `console.log("Hello");` to `index.js` and then run the command `yarn
    start` from the command line. You should see the file compile and run, printing
    `Hello` to the screen before exiting. If you get errors or do not see the `Hello`,
    you may want to take a step back and double-check your environment. If everything
    is working, you can delete the `console.log("Hello");` from `index.js`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，您可能想要停下来测试一切是否正常工作。在`index.js`中添加一个简单的`console.log("Hello");`，然后从命令行运行`yarn
    start`命令。您应该看到文件编译并运行，在退出前将`Hello`打印到屏幕上。如果您遇到错误或看不到`Hello`，您可能需要退一步并仔细检查您的环境。如果一切正常，您可以删除`index.js`中的`console.log("Hello");`。
- en: Initializing the algorithm
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始化算法
- en: 'In this section, we''ll be working in the `kmeans.js` file. The first thing
    to do is to add our functions for mean and distance to the top of the file. Since
    these are generic functions that can be called **statistically**, we will not
    define them inside a class. Add the following to the top of the file:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将工作在`kmeans.js`文件中。首先要做的事情是将我们的均值和距离函数添加到文件顶部。由于这些是通用的函数，可以**统计地**调用，我们不会在类内部定义它们。将以下内容添加到文件顶部：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, create and export a `KMeans` class. We will fill this in with many more
    methods throughout this chapter, but let''s start with the following. Add this
    to the `kmeans.js` file beneath the code you just added:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在`kmeans.js`文件中添加并导出`KMeans`类。我们将在本章的其余部分添加更多方法，但让我们从以下内容开始。将以下内容添加到您刚刚添加的代码下方：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We've created a class called `KMeans` and are exporting it as the default export
    for this file. The preceding code also initializes some of the instance variables
    that the class will need, which we will describe shortly.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个名为`KMeans`的类，并将其作为此文件的默认导出。前面的代码还初始化了类将需要的某些实例变量，我们将在稍后描述。
- en: The constructor for the class takes two parameters, `k` and `data`, and stores
    both as instance variables. The `k` parameter represents the `k` in k-means, or
    the desired number of clusters as the algorithm's output. The `data` parameter
    is an array of data points that the algorithm will process.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 类的构造函数接受两个参数，`k`和`data`，并将它们都存储为实例变量。`k`参数代表k-means中的`k`，或者算法输出中期望的簇数量。`data`参数是算法将处理的数据点的数组。
- en: 'At the end of the constructor, we call the `reset()` method, which is used
    to initialize (or reset) the solver''s state. Specifically, the instance variables
    we initialize in the `reset` method are:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在构造函数的末尾，我们调用`reset()`方法，该方法用于初始化（或重置）求解器的状态。具体来说，我们在`reset`方法中初始化的实例变量包括：
- en: '`iterations`, which is a simple counter of how many iterations the solver has
    run, starting from 0'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iterations`，它是一个简单的计数器，记录求解器已运行的迭代次数，从0开始'
- en: '`error`, which records the **root mean square error** (**RMSE**) of the points''
    distance to their centroids for the current iteration'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`error`，它记录了当前迭代中点到其质心的**均方根误差**（**RMSE**）'
- en: '`centroidAssignments`, which is an array of data point index numbers that map
    to a centroid index number'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`centroidAssignments`，它是一个数据点索引数组，映射到一个质心索引'
- en: '`centroids`, which will store the solver''s candidates for the *k* centroids
    at the current iteration'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`centroids`，它将存储求解器在当前迭代中候选的`k`个质心'
- en: Notice that in the `reset` method, we're making a call to `this.initRandomCentroids()`,
    which we have not yet defined. The k-means algorithm must start with a set of
    candidate centroids, so the purpose of that method is to generate the correct
    number of centroids randomly. Because the algorithm starts with a random state,
    it can be expected that multiple runs of the algorithm will return different results
    based on the initial conditions. This is actually a desired property of the k-means
    algorithm, because it is susceptible to finding local optima, and running the
    algorithm multiple times with different initial conditions may help you find the
    global optimum.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在 `reset` 方法中，我们调用了 `this.initRandomCentroids()`，这是我们尚未定义的。k-means 算法必须从一个候选质心集合开始，所以那个方法的目的就是随机生成正确数量的质心。因为算法从一个随机状态开始，可以预期多次运行算法将基于初始条件返回不同的结果。这实际上是
    k-means 算法的一个期望属性，因为它容易陷入局部最优，多次运行算法使用不同的初始条件可能有助于找到全局最优。
- en: 'We have some prerequisites to satisfy before we can generate our random centroids.
    First, we must know the dimensionality of the data. Are we working with 2D data,
    3D data, 10D data, or 1324D data? The random centroids we generate must have the
    same number of dimensions as the rest of the data points. This is an easy problem
    to solve; we assume that all the data points have the same number of dimensions,
    so we can just inspect the first data point we encounter. Add the following method
    to the `KMeans` class:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们生成随机质心之前，我们必须满足一些先决条件。首先，我们必须知道数据的维度。我们是在处理 2D 数据、3D 数据、10D 数据还是 1324D 数据？我们生成的随机质心必须与数据点的其他维度数量相同。这是一个容易解决的问题；我们假设所有数据点都有相同的维度，所以我们只需检查我们遇到的第一个数据点。将以下方法添加到
    `KMeans` 类中：
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The other consideration we must make when generating random initial centroids
    is that the centroids should be close to the data that we're working with. For
    instance, if all your data points are points between (0, 0) and (10, 10), you
    would not want to generate a random centroid such as (1200, 740). Similarly, if
    your data points are all negative, you would not want to generate positive centroids,
    and so on.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成随机初始质心时，我们必须考虑的其他因素是质心应该接近我们正在处理的数据。例如，如果你的所有数据点都在 (0, 0) 和 (10, 10) 之间，你不会希望生成一个像
    (1200, 740) 这样的随机质心。同样，如果你的数据点都是负数，你不会希望生成正的质心，等等。
- en: Why should we care where the random centroids start? In this algorithm, points
    will be assigned to the centroid closest to it and gradually *pull* the centroid
    towards the cluster center. If the centroids are all to the right of the data
    points, then the centroids themselves will follow similar paths towards the data
    and may get all clumped together in one single cluster, converging to a local
    optimum. By making sure that the centroids are randomly distributed within the
    range of the data, we have a better chance of avoiding this type of local optimum.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为什么要关心随机质心的起始位置呢？在这个算法中，点会被分配到最近的质心，并逐渐 *拉* 质心向簇中心移动。如果所有质心都在数据点的右侧，那么质心本身也会遵循类似的路径向数据移动，并可能全部聚集在一个单独的簇中，收敛到局部最优。通过确保质心在数据范围内部随机分布，我们更有可能避免这种类型的局部最优。
- en: 'Our approach to generating our centroid starting positions will be to determine
    the range of each dimension of the data, and then choose random values for our
    centroid''s position within those ranges. For instance, imagine three two-dimensional
    data points in an *x, **y* plane: (1, 3), (5, 8), and (3, 0). The range of the
    *x *dimension lies between 1 and 5, while the range of the *y* dimension lies
    between 0 and 8\. Therefore, when creating a randomly initialized centroid, we
    will choose a random number between 1 and 5 for its *x* position, and a random
    number between 0 and 8 for its *y* position.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生成质心起始位置的方法将是确定数据的每个维度的范围，然后在那些范围内为质心的位置选择随机值。例如，想象在 *x, **y* 平面上的三个二维数据点：(1,
    3)，(5, 8) 和 (3, 0)。*x* 维度的范围在 1 和 5 之间，而 *y* 维度的范围在 0 和 8 之间。因此，当创建随机初始化的质心时，我们将为其
    *x* 位置选择一个介于 1 和 5 之间的随机数，为其 *y* 位置选择一个介于 0 和 8 之间的随机数。
- en: 'We can use JavaScript''s `Math.min` and `Math.max` to determine the data ranges
    for each dimension. Add the following method to the `KMeans` class:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 JavaScript 的 `Math.min` 和 `Math.max` 来确定每个维度的数据范围。将以下方法添加到 `KMeans` 类中：
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This method first collects all the values of the given dimension from the data
    points as an array and then returns an object containing that range''s `min` and
    `max`. Returning to our preceding example of three data points ((1, 3), (5, 8),
    and (3, 0)), calling `getRangeForDimension(0)` would return `{min: 1, max: 5}`,
    and calling `getRangeForDimension(1)` would return `{min: 0, max: 8}`.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '此方法首先收集数据点中给定维度的所有值作为数组，然后返回一个包含该范围 `min` 和 `max` 的对象。回到我们前面三个数据点（（1，3），（5，8）和（3，0））的示例，调用
    `getRangeForDimension(0)` 将返回 `{min: 1, max: 5}`，而调用 `getRangeForDimension(1)`
    将返回 `{min: 0, max: 8}`。'
- en: 'It will be useful for us to have an object of all dimensions and their ranges
    that we can cache while initializing centroids, so add the following method to
    the `KMeans` class as well:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们来说，有一个包含所有维度及其范围的缓存对象将很有用，我们可以在初始化质心时使用它，所以也将以下方法添加到 `KMeans` 类中：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This method simply looks at all dimensions and returns the `min` and `max` ranges
    for each, structured as objects in an array indexed by the dimension. This method
    is primarily a convenience, but we will use it shortly.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法简单地查看所有维度，并为每个维度返回 `min` 和 `max` 范围，结构为一个按维度索引的数组中的对象。此方法主要是为了方便，但我们很快就会使用它。
- en: 'We can finally generate our randomly initialized centroids. We will need to
    create *k* centroids, and work dimension by dimension to choose a random point
    inside the range of each dimension. Add the following method to the `KMeans` class:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终可以生成随机初始化的质心。我们需要创建 *k* 个质心，并且逐个维度地选择每个维度范围内的随机点。将以下方法添加到 `KMeans` 类中：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The preceding algorithm contains two loops; the outer loop creates `k` candidate
    centroids. Because the number of dimensions in the dataset is arbitrary, and because
    each dimension itself has an arbitrary range, we must then work dimension by dimension
    for each centroid in order to generate a random position. If your data is three-dimensional,
    the inner loop will consider dimensions 0, 1, and 2 separately, determining the
    `min` and `max` values for each dimension, choosing a random value in that range,
    and assigning that value to that specific dimension of the centroid point.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的算法包含两个循环；外循环创建 `k` 个候选质心。由于数据集的维度数量是任意的，并且每个维度本身也有一个任意的范围，因此我们必须逐个维度地工作，为每个质心生成随机位置。如果你的数据是三维的，内循环将分别考虑维度
    0、1 和 2，确定每个维度的 `min` 和 `max` 值，在该范围内选择一个随机值，并将该值分配给质心点的特定维度。
- en: Testing random centroid generation
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试随机质心生成
- en: We've already written a significant amount of code, so now would be a good time
    to stop and test our work. We should also start setting up our `data.js` file
    that we'll use to hold some example data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经编写了大量的代码，所以现在是停止并测试我们工作的好时机。我们还应该开始设置我们的 `data.js` 文件，我们将使用它来存储一些示例数据。
- en: 'Open up the `data.js` file and add the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 `data.js` 文件并添加以下内容：
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The values used are the same ones from our simple data point example written
    in the preceding block.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的值与前面块中编写的简单数据点示例中的值相同。
- en: 'Now, switch to `index.js` and add the following code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，切换到 `index.js` 并添加以下代码：
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: First, we import the `KMeans` class and the `example_data` object from their
    respective files. We print some helpful output to the screen, and then initialize
    a `KMeans` solver instance for our simple data. We can check the randomly initialized
    centroids by inspecting the value of `ex_randomCentroids_solver.centroids`.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从各自的文件中导入 `KMeans` 类和 `example_data` 对象。我们在屏幕上打印一些有用的输出，然后为我们的简单数据初始化一个
    `KMeans` 求解器实例。我们可以通过检查 `ex_randomCentroids_solver.centroids` 的值来检查随机初始化的质心。
- en: 'Once you''ve added this code, run `yarn start` from the command line, and you
    should see something similar to the following output. Note that because the centroid
    initialization is random, you will not see the same values that I see; however,
    what we''re looking for is to make sure that the random centroids lie within the
    correct ranges. Specifically, we want our centroids to have *x* positions between
    1 and 5, and *y* positions between 0 and 8\. Run the code a number of times to
    make sure that the centroids have the correct position:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 添加此代码后，从命令行运行 `yarn start`，你应该会看到以下类似输出。请注意，由于质心初始化是随机的，你将不会看到与我相同的值；然而，我们想要确保随机质心位于正确的范围内。具体来说，我们希望我们的质心在
    1 和 5 之间有 *x* 位置，在 0 和 8 之间有 *y* 位置。多次运行代码以确保质心有正确的位置：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If you see something similar to the preceding block, that means everything is
    working well so far and we're ready to continue implementing the algorithm.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看到与前面块类似的内容，这意味着到目前为止一切正常，我们可以继续实现算法。
- en: Assigning points to centroids
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将点分配到质心
- en: 'The iteration loop that the k-means algorithm performs has two steps: assigning
    each point to the centroid closest to it, and then updating the location of the
    centroids to be the mean value of all the points assigned to that centroid. In
    this section, we''ll implement the first part of the algorithm: assigning points
    to centroids.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法执行的迭代循环包含两个步骤：将每个点分配到最近的质心，然后更新质心的位置，使其成为分配给该质心的所有点的平均值。在本节中，我们将实现算法的第一部分：将点分配到质心。
- en: At a high level, our task is to consider each point in the dataset and determine
    which centroid is closest to it. We also need to record the results of this assignment
    so that we can later update the centroid's location based on the points assigned
    to it.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，我们的任务是考虑数据集中的每个点，并确定哪个质心离它最近。我们还需要记录此分配的结果，以便我们可以稍后根据分配给它的点更新质心的位置。
- en: 'Add the following method to the body of the `KMeans` class:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下方法添加到`KMeans`类的主体中：
- en: '[PRE16]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This method considers a single data point, given by its index, and considers
    each centroid in the system in turn. We also keep track of the last centroid this
    point has been assigned to in order to determine if the assignment has changed.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法考虑单个数据点，由其索引给出，并依次考虑系统中的每个质心。我们还跟踪此点最后分配到的质心，以确定分配是否已更改。
- en: In the preceding code, we loop over all centroids and use our `distance` function
    to determine the distance between the point and the centroid. If the distance
    is less than the lowest distance we've seen so far, or if this is the first centroid
    we're considering for this point (`minDistance` will be null in that case), we
    record the distance and the index position of the centroid. After looping over
    all centroids, we will now know which centroid is closest to the point under consideration.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们遍历所有质心并使用我们的`distance`函数来确定点与质心之间的距离。如果距离小于迄今为止看到的最低距离，或者这是我们为该点考虑的第一个质心（在这种情况下`minDistance`将为null），我们将记录距离和质心的索引位置。遍历所有质心后，我们现在将知道哪个质心是考虑中的点最近的。
- en: Finally, we record the assignment of the centroid to the point by setting it
    to the `this.centroidAssignments` array—in this array, the index is the index
    of the point, and the value is the index of the centroid. We return a Boolean
    from this method by comparing the last known centroid assignment to the new centroid
    assignment—it will return `true` if the assignment has changed, or `false` if
    not. We'll use this information to figure out when the algorithm has reached steady
    state.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过将质心分配给点的索引设置到`this.centroidAssignments`数组中来记录质心分配——在这个数组中，索引是点的索引，值是质心的索引。我们通过比较最后已知的质心分配和新质心分配来从这个方法返回一个布尔值——如果分配已更改，则返回`true`，如果没有更改，则返回`false`。我们将使用这个信息来确定算法何时达到稳态。
- en: 'The previous method considers only a single point, so we should also write
    a method to process the centroid assignments of all points. Additionally, the
    method we write should determine if *any* point has updated its centroid assignment.
    Add the following to the `KMeans` class:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的方法只考虑单个点，因此我们还应该编写一个方法来处理所有点的质心分配。此外，我们编写的方法还应确定是否有任何点更新了其质心分配。将以下内容添加到`KMeans`类中：
- en: '[PRE17]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This method defines a variable called `didAnyPointsGetReassigned`, initialized
    to `false`, and then loops over all points in the dataset to update their centroid
    assignments. If any point is assigned to a new centroid, the method will return
    `true`. If no assignments were changed, the method returns `false`. The return
    value from this method will become one of our termination conditions; if no points
    update after an iteration, we can consider the algorithm to have reached steady
    state and can terminate it.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法定义了一个名为`didAnyPointsGetReassigned`的变量，并将其初始化为`false`，然后遍历数据集中的所有点以更新它们的质心分配。如果有任何点被分配到新的质心，该方法将返回`true`。如果没有分配更改，该方法返回`false`。此方法的返回值将成为我们的终止条件之一；如果在迭代后没有点更新，我们可以认为算法已达到稳态，可以终止它。
- en: 'Let''s now address the second part of the k-means algorithm: updating centroid
    locations.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来讨论k-means算法的第二部分：更新质心位置。
- en: Updating centroid locations
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新质心位置
- en: 'In the previous section, we implemented the first part of the k-means algorithm:
    looking at all points in the dataset and assigning them to the centroid that''s
    geographically closest. The next step in the algorithm is to look at all centroids
    and update their locations to the mean value of all the points assigned to them.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们实现了 k-means 算法的第一部分：查看数据集中的所有点并将它们分配到地理位置上最近的质心。算法的下一步是查看所有质心并更新它们的地理位置到分配给它们的所有点的平均值。
- en: To make an analogy, you can imagine each point reaching out and grabbing the
    centroid closest to it. The points give the centroid a tug, trying to pull it
    closer to them. We've already implemented the *reach out and grab portion* of
    the algorithm, and now we'll implement the *pull the centroid closer* portion.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做一个类比，你可以想象每个点伸出手去抓住离它最近的质心。点给质心一个拉力，试图将其拉得更近。我们已经实现了算法的“伸出手去抓住”部分，现在我们将实现“拉质心更近”的部分。
- en: At a high level, our task is to loop over all the centroids, and for each, determine
    the mean position of all the points assigned to it. We'll then update the centroid's
    position to that mean value. Breaking this down further, we must first collect
    all the points assigned to a centroid, and then we have to calculate the average
    value of these points, always keeping in mind that points can have any number
    of dimensions.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，我们的任务是遍历所有质心，对于每个质心，确定分配给它的所有点的平均位置。然后我们将更新质心的位置到这个平均值。进一步分解，我们必须首先收集分配给质心的所有点，然后我们必须计算这些点的平均值，始终记住点可以有任意数量的维度。
- en: 'Let''s start with the easy task of collecting all the points assigned to a
    centroid. We already have a mapping of point indexes to centroid indexes in our
    `this.centroidAssignments` instance variable. Add the following code to the body
    of the `KMeans` class:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从收集分配给质心的所有点这个简单的任务开始。我们已经在 `this.centroidAssignments` 实例变量中有一个点索引到质心索引的映射。将以下代码添加到
    `KMeans` 类的主体中：
- en: '[PRE18]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The preceding method is quite standard: looping over all data points, we look
    up that point''s centroid assignment, and if it is assigned to the centroid in
    question, we add the point to an output array.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方法是相当标准的：遍历所有数据点，查找该点的质心分配，如果它被分配到所讨论的质心，我们就将该点添加到输出数组中。
- en: We can now use this list of points to update the centroid's location. Our goal
    is to update the centroid's location to be the mean value of all the points we
    found previously. Because the data may be multi-dimensional, we must also consider
    each dimension independently.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用这个点列表来更新质心的位置。我们的目标是更新质心的位置，使其成为我们之前找到的所有点的平均值。因为数据可能是多维的，我们必须独立考虑每个维度。
- en: Using our simple example of points (1, 3), (5, 8), and (3, 0), we would find
    a mean location of (3, 3.6667). To get this value, we first calculate the mean
    value of the *x* dimension ( (1 + 5 + 3) / 3 = 3 ), and then calculate the mean
    value of the *y* dimension ( (3 + 8 + 0) / 3 = 11/3 = 3.6666... ). If we're working
    in more than two dimensions, we simply repeat the procedure for each dimension.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们简单的点示例（1, 3）、（5, 8）和（3, 0），我们会找到一个平均位置为（3, 3.6667）。为了得到这个值，我们首先计算 x 维度的平均值（（1
    + 5 + 3）/ 3 = 3），然后计算 y 维度的平均值（（3 + 8 + 0）/ 3 = 11/3 = 3.6666...）。如果我们工作在超过两个维度的情况下，我们只需对每个维度重复此过程。
- en: 'We can write this algorithm in JavaScript. Add the following to the body of
    the `KMeans` class:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用 JavaScript 编写这个算法。将以下代码添加到 `KMeans` 类的主体中：
- en: '[PRE19]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The preceding method considers only one centroid at a time, specified by its
    index. We use the `getPointsForCentroid` method that we just added to get an array
    of points assigned to this centroid. We initialize a variable called `newCentroid`
    as an empty array; this will ultimately replace the current centroid.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方法只考虑一个质心，由其索引指定。我们使用刚刚添加的 `getPointsForCentroid` 方法来获取分配给该质心的点数组。我们初始化一个名为
    `newCentroid` 的变量为空数组；这最终将替换当前的质心。
- en: Considering one dimension at a time, we collect the positions of the points
    *in that dimension only,* and then calculate the mean. We use JavaScript's `Array.map`
    to extract the positions for the correct dimension only, and then we use our `mean`
    function to calculate the average position in that dimension.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一次一个维度，我们只收集该维度的点位置，然后计算平均值。我们使用 JavaScript 的 `Array.map` 方法来提取正确维度的位置，然后使用我们的
    `mean` 函数来计算该维度的平均位置。
- en: If we work this example by hand with the data points (1, 3), (5, 8), and (3,
    0), we start by examining dimension 0, or the *x* dimension. The result of `thisCentroidPoints.map(point
    => point[dimension])` is the array `[1, 5, 3]` for dimension 0, and for dimension
    1, the result is `[3, 8, 0]`. Each of these arrays is passed to the `mean` function,
    and the mean value is used in `newCentroid` for that dimension.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们手动使用数据点（1, 3）、（5, 8）和（3, 0）来工作，我们首先检查维度0，即*x*维度。`thisCentroidPoints.map(point
    => point[dimension])`的结果是维度0的数组`[1, 5, 3]`，对于维度1，结果是`[3, 8, 0]`。这些数组中的每一个都传递给`mean`函数，并且该维度的`newCentroid`使用平均值。
- en: At the end of this method, we update our array of `this.centroids` with the
    newly calculated centroid position.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在此方法结束时，我们使用新计算出的质心位置更新我们的`this.centroids`数组。
- en: 'We will also write a convenience method to loop over all centroids and update
    their positions. Add the following to the body of the `KMeans` class:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将编写一个便利方法来遍历所有质心并更新它们的位置。将以下代码添加到`KMeans`类的主体中：
- en: '[PRE20]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Before finishing the algorithm and tying together all the pieces, we have one
    final prerequisite to satisfy. We're going to introduce the concept of *error*
    into the algorithm. Calculating the error is not required for the k-means algorithm
    to function, but you'll see later that this can be advantageous in certain situations.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成算法并将所有部分连接起来之前，我们还有一个最终的前提条件需要满足。我们将把*误差*的概念引入算法中。计算误差对于k-means算法的功能不是必需的，但你会看到，在某些情况下这可能会带来优势。
- en: Because this is an unsupervised learning algorithm, our concept of error does
    not relate to semantic error. Instead, we will use an error metric that represents
    the average distance of all points from their assigned centroids. We'll use the
    RMSE for this, which penalizes bigger distances more harshly, so our error metric
    will be a good indication of how tight the clustering is.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这是一个无监督学习算法，我们的误差概念与语义错误无关。相反，我们将使用一个误差度量，它表示所有点与其分配的质心之间的平均距离。我们将使用RMSE来做到这一点，它对更大的距离进行更严厉的惩罚，因此我们的误差度量将很好地指示聚类的紧密程度。
- en: To perform this error calculation, we loop over all points and determine the
    distance of that point from its centroid. We square each distance before adding
    it to a running total (the *squared* in root-mean-squared), then divide the running
    total by the number of points (the *mean* in root-mean-squared), and finally take
    the square root of the whole thing (the *root* in root-mean-squared).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行这个误差计算，我们遍历所有点并确定该点与其质心的距离。在将每个距离加到运行总和中之前，我们将其平方（在均方根中称为*平方*），然后除以点的数量（在均方根中称为*平均*），最后取整个数的平方根（在均方根中称为*根*）。
- en: 'Add the following code to the body of the `KMeans` class:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下代码添加到`KMeans`类的主体中：
- en: '[PRE21]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We're now ready to tie everything together and implement the main loop of the
    algorithm.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好将所有东西连接起来并实现算法的主循环。
- en: The main loop
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主循环
- en: All the supporting and foundational logic for the k-means algorithm is now implemented.
    The last thing to do is to tie it all together and implement the main loop of
    the algorithm. To run the algorithm, we should repeat the procedure of assigning
    points to centroids and then updating centroid locations until the centroids stop
    moving. We can also perform optional steps such as calculating the error and making
    sure that the algorithm does not exceed some maximum allowable number of iterations.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法的所有支持和基础逻辑现在都已实现。最后要做的就是将它们全部连接起来并实现算法的主循环。要运行算法，我们应该重复将点分配给质心和更新质心位置的过程，直到质心停止移动。我们还可以执行可选步骤，例如计算误差并确保算法不超过某些最大允许的迭代次数。
- en: 'Add the following code to the body of the `KMeans` class:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下代码添加到`KMeans`类的主体中：
- en: '[PRE22]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We've written a `solve` method that also accepts a limit on the maximum number
    of iterations allowed, which we've defaulted to `1000`. We run the algorithm in
    a `while` loop, and for each iteration in the loop, we call `assignPointsToCentroids`
    (recording its output value, `didAssignmentsChange`), call `updateCentroidLocations`,
    and call `calculateError`.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编写了一个`solve`方法，它还接受允许的最大迭代次数的限制，我们将其默认设置为`1000`。我们在`while`循环中运行算法，并在循环的每次迭代中调用`assignPointsToCentroids`（记录其输出值，`didAssignmentsChange`），调用`updateCentroidLocations`，并调用`calculateError`。
- en: In order to help debugging and maintain a history of what the algorithm has
    accomplished, we maintain an array of `this.iterationLogs`, and for each iteration
    we'll record the centroid locations, the iteration number, the calculated error,
    and whether or not the algorithm has reached steady state (which is the opposite
    of `didAssignmentsChange`). We use ES6's array spread operator on `this.centroids`
    when recording logs to avoid passing this array as a reference, otherwise the
    iteration logs would show the last state of centroids instead of its progress
    over time.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助调试并维护算法所完成工作的历史记录，我们维护一个`this.iterationLogs`数组，并在每次迭代中记录质心位置、迭代次数、计算误差以及算法是否达到稳态（这是`didAssignmentsChange`的反面）。我们在记录日志时使用ES6的数组扩展运算符对`this.centroids`进行操作，以避免将此数组作为引用传递，否则迭代日志将显示质心的最后状态而不是其随时间的变化过程。
- en: If the point/centroid assignments don't change from one iteration to the next,
    we consider the algorithm to have reached steady state and can return results.
    We accomplish this by using the `break` keyword to break from the `while` loop
    early. If the algorithm never reaches steady state, the `while` loop will continue
    until it has performed the maximum number of iterations allowed, and return the
    latest available result. The output for the `solve` method is simply the most
    recent iteration log, which contains all the information a user of this class
    would need to know.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果点/质心分配在连续的迭代中不发生变化，我们认为算法已经达到稳态，可以返回结果。我们通过使用`break`关键字提前退出`while`循环来实现这一点。如果算法从未达到稳态，`while`循环将继续执行，直到达到允许的最大迭代次数，并返回最新的可用结果。`solve`方法的输出仅仅是最近的迭代日志，其中包含了此类用户需要了解的所有信息。
- en: Example 1 – k-means on simple 2D data
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例1 - 对简单2D数据的k-means算法
- en: We've got our implementation of the k-means algorithm written and coded, so
    now it's time to see how it works. In our first example, we'll run our algorithm
    against a simple dataset of two-dimensional data. The data itself will be contrived
    so that the algorithm can easily find three distinct clusters.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经编写并编码了k-means算法的实现，所以现在是时候看看它是如何工作的了。在我们的第一个例子中，我们将运行我们的算法针对一个简单的二维数据集。数据本身将被设计得算法可以轻松找到三个不同的簇。
- en: 'First, modify the `data.js` file to add the following data, anywhere preceding
    the `export default` line:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，修改`data.js`文件，在`export default`行之前添加以下数据：
- en: '[PRE23]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, update the final export line to look like this:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，更新最终的导出行，使其看起来像这样：
- en: '[PRE24]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'If we were to graph the preceding data points, we would see the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要绘制前面的数据点，我们会看到以下内容：
- en: '![](img/29251362-e458-4369-b23a-b53b12378019.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/29251362-e458-4369-b23a-b53b12378019.png)'
- en: Visually, we can see that there are three neatly clustered groups of data points.
    When we run the algorithm, we will use *k = 3* and expect that the centroids neatly
    position themselves to the centers of those three clusters. Let's try it out.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 从视觉上看，我们可以看到有三个整齐聚集的数据点组。当我们运行算法时，我们将使用*k = 3*，并期望质心能够整齐地定位到这三个簇的中心。让我们试试看。
- en: 'Open up `index.js` and add the following. You can either replace the code you
    added earlier (preserving the `import` statements), or simply add this at the
    bottom:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 打开`index.js`并添加以下内容。你可以替换你之前添加的代码（保留`import`语句），或者简单地添加到下面：
- en: '[PRE25]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: After outputting some headers, we create a new `KMeans` instance called `ex_1_solver`
    and initialize it with k = 3 and the `example_data.example_2d3k` that we just
    added. We call the `solve` method, with no parameters (that is, the max allowed
    iterations will be 1,000), and capture the output in the variable `ex_1_centroids`.
    Finally, we print the results to the screen and add a newline—we'll add a few
    more tests and examples following this point.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在输出一些标题后，我们创建了一个新的名为`ex_1_solver`的`KMeans`实例，并用k = 3和刚刚添加的`example_data.example_2d3k`初始化它。我们调用`solve`方法，不带任何参数（即，最大允许的迭代次数将是1,000），并将输出捕获在变量`ex_1_centroids`中。最后，我们将结果打印到屏幕上并添加换行符——我们将在这一点之后添加更多的测试和示例。
- en: Note that the order of your centroids may be different to mine, since random
    initial conditions will differ.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你的质心顺序可能与我不同，因为随机初始条件会有所不同。
- en: 'You can now run `yarn start` and should see output that looks similar to this. Additionally,
    because of the random initialization, it''s possible that some runs of the solver
    will get caught in local optima and you''ll see different centroids. Run the program
    a few times in a row and see what happens. Here''s what my output looks like:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以运行`yarn start`，应该会看到类似的输出。此外，由于随机初始化，解算器的某些运行可能会陷入局部最优，你将看到不同的质心。连续运行程序几次，看看会发生什么。以下是我的输出：
- en: '[PRE26]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The output of the program tells us that the algorithm reached steady state after
    only two iterations (iteration 1 is the 2nd iteration, because we start counting
    from zero), and that our centroids are located at (2.8, 3.9), (13.4, 2.4), and
    (7.6, 7.5).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的输出告诉我们，算法在仅经过两次迭代后（迭代1是第二次迭代，因为我们从零开始计数），并且我们的质心位于（2.8，3.9），（13.4，2.4），和（7.6，7.5）。
- en: 'Let''s graph these centroids along with the original data and see what it looks
    like:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制这些质心与原始数据，看看它看起来像什么：
- en: '![](img/b5d4cbd5-39f2-4a08-8b02-9aa82f98d24c.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b5d4cbd5-39f2-4a08-8b02-9aa82f98d24c.png)'
- en: As you can see, k-means has done its job splendidly, reporting centroids exactly
    where we would expect them to be.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，k-means已经出色地完成了其工作，报告的质心正好在我们预期的位置。
- en: 'Let''s take a deeper look into what this algorithm is doing, by printing the
    `iterationLogs` after the solution. Add the following code to the bottom of `index.js`:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解一下这个算法在解决方案之后做了什么，通过打印`iterationLogs`。将以下代码添加到`index.js`的底部：
- en: '[PRE27]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Run `yarn start` again, and you should see output like the following. As always,
    based on initial conditions, your version may have required more or fewer iterations
    than mine so your output will differ, but you should see something like this:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 再次运行`yarn start`，你应该会看到以下输出。像往常一样，根据初始条件，你的版本可能需要比我的更多或更少的迭代，所以你的输出会有所不同，但你应该会看到类似的东西：
- en: '[PRE28]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: As you can see, the algorithm took five iterations to reach steady state, as
    opposed to only two iterations like it did earlier. This is normal and expected
    due to the differing random initial conditions between the two runs. Looking through
    the logs, you can see that the error reported by the algorithm goes down with
    time. Also, notice that the first centroid, (2.8, 3.9), reaches its final destination
    after the first iteration, while the other centroids take more time to catch up.
    This is because the first centroid was randomly initialized to a location very
    close to its final destination, starting at (2.7, 3.7) and finishing at (2.8,
    3.9).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，算法经过五次迭代才达到稳定状态，而之前只有两次。这是正常的，也是预期的，因为两次运行之间的随机初始条件不同。查看日志，您可以看到算法报告的错误随着时间的推移而下降。注意，第一个质心（2.8，3.9）在第一次迭代后到达其最终位置，而其他质心则需要更多时间才能赶上。这是因为第一个质心被随机初始化到一个非常接近其最终位置的位置，从（2.7，3.7）开始，到（2.8，3.9）结束。
- en: 'It is possible, though somewhat rare, to catch the algorithm caught in a local
    optimum on this dataset. Let''s add the following code to the bottom of `index.js`
    to run the solver multiple times and see if it''ll find a local optimum instead
    of a global optimum:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可能性不大，但在该数据集上捕捉到算法陷入局部最优是有可能的。让我们将以下代码添加到`index.js`的底部，以多次运行解算器，看看它是否会找到局部最优而不是全局最优：
- en: '[PRE29]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Run this with `yarn start` a few times until you see an unexpected result.
    In my case, I found the following solution (I''m omitting the other output of
    the preceding program):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 用`yarn start`运行几次，直到你看到意外结果。在我的情况下，我找到了以下解决方案（我省略了前面程序的其他输出）：
- en: '[PRE30]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The fourth run of the solver found a different answer from the other runs:
    it discovered (11.3, 2.3), (5.1, 5.6), (14.5, 2.5) as a solution. Because the
    other solution is much more common than this one, we can assume the algorithm
    has been trapped in a local optimum. Let''s chart these values against the rest
    of the data and see what it looks like:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 解算器的第四次运行得到了与其他运行不同的答案：它发现了（11.3，2.3），（5.1，5.6），（14.5，2.5）作为解决方案。因为其他解决方案比这个更常见，我们可以假设算法已经陷入了局部最优。让我们将这些值与剩余的数据进行比较，看看它看起来像什么：
- en: '![](img/98271672-cb1c-4ee0-8c0a-7d5bb65e18b4.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/98271672-cb1c-4ee0-8c0a-7d5bb65e18b4.png)'
- en: 'In the preceding chart, our data points are represented by circles, the centroids
    we''d expect are represented by triangles, and the odd result we got is represented
    by **X** marks. Looking at the chart, you can understand how the algorithm may
    have come to this conclusion. One centroid, the **X** mark at (5.1, 5.6), has
    captured two different clusters and is sitting between them. The other two centroids
    have divided the third cluster into two. This is a perfect example of a local
    optimum: it''s a solution that makes sense, it logically clusters the data points,
    but it is not the best available solution (the global optimum) for the data. Most
    likely, the two centroids on the right were both randomly initialized inside that
    cluster and got trapped there.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图表中，我们的数据点用圆圈表示，我们预期的质心用三角形表示，而我们得到的不寻常的结果用**X**标记表示。查看图表，你可以理解算法是如何得出这个结论的。一个质心，位于（5.1，5.6）的**X**标记，捕捉了两个不同的簇，并且位于它们之间。其他两个质心将第三个簇分成了两部分。这是一个完美的局部最优解的例子：这是一个有意义的解决方案，它逻辑上聚类了数据点，但它并不是数据最佳可用的解决方案（全局最优解）。很可能是右边的两个质心都在该簇内部随机初始化，并且被困在那里。
- en: This is always a potential outcome for the k-means algorithm, and indeed all
    ML algorithms. Based on initial conditions and the quirks of the dataset, the
    algorithm may occasionally (or even frequently) discover local optima. Fortunately,
    if you compare the errors of the two solutions from the preceding output, the
    global solution has an error of 1.9 and the locally optimum solution reports an
    error of 3.0\. In this case, our error calculation has done its job well, and
    correctly represented the tightness of the clustering.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这总是k-means算法以及所有机器学习算法的一个潜在结果。基于初始条件和数据集的怪癖，算法可能会偶尔（甚至经常）发现局部最优解。幸运的是，如果你比较前面输出中的两个解决方案的误差，全局解决方案的误差为1.9，局部最优解报告的误差为3.0。在这种情况下，我们的误差计算已经很好地完成了工作，并正确地表示了聚类的紧密程度。
- en: To combat this issue with the k-means algorithm, you should generally run it
    more than one time, and look for either consensus (for example, four of five runs
    all agree), or the minimum error, and use that as your result.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决k-means算法的这个问题，你应该通常运行它多次，并寻找一致性（例如，五次运行中有四次同意），或者最小误差，并使用那个作为你的结果。
- en: Example 2 – 3D data
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例2 – 3D数据
- en: Because we've written the k-means algorithm to handle any arbitrary number of
    dimensions, we can also test it with 3D data (or 10D, or 100D or any number of
    dimensions that you require). While this algorithm will work for more than three
    dimensions, we have no way of visually plotting the higher dimensions and therefore
    can't visually check the results—so we'll test with 3D data and move on.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们已经编写了k-means算法来处理任意数量的维度，我们也可以用3D数据（或10D，或100D或任何你需要的维度）来测试它。虽然这个算法可以处理超过三个维度，但我们无法可视地绘制高维，因此无法直观地检查结果——所以我们将用3D数据进行测试，然后继续。
- en: 'Open up `data.js` and add the following to the middle of the file—anywhere
    preceding the `export default` line is OK:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 打开`data.js`并在文件的中间添加以下内容——在任何`export default`行之前都可以：
- en: '[PRE31]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'And then modify the export line to look like this (add the `example_3d3k` variable
    to the export):'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将导出行修改为如下所示（将`example_3d3k`变量添加到导出中）：
- en: '[PRE32]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The preceding data, when plotted in 3D, looks like this:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的数据，当在三维中绘制时，看起来是这样的：
- en: '![](img/22e12169-6eea-4d16-ac25-6a0ce167876d.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/22e12169-6eea-4d16-ac25-6a0ce167876d.png)'
- en: 'As you can see, there are three clear clusters, and we''d expect k-means to
    handle this easily. Now, switch to `index.js` and add the following. We are simply
    creating a new solver for this example, loading the 3D data, and printing the
    results:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，有三个清晰的簇，我们预计k-means可以轻松处理这个问题。现在，切换到`index.js`并添加以下内容。我们只是为这个例子创建了一个新的求解器，加载3D数据，并打印结果：
- en: '[PRE33]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Run the program with `yarn start` and you should see something like the following.
    I''ve omitted the output from the earlier 2D example:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`yarn start`运行程序，你应该看到以下内容。我已经省略了早期2D示例的输出：
- en: '[PRE34]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Thankfully, our solver has given us 3D data points, so we know that, at the
    very least, the algorithm can differentiate between 2D and 3D problems. We see
    that it still only took a handful of iterations, and that the error is a reasonable
    number (meaning it's defined, not negative, and not too large).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们的求解器给了我们3D数据点，因此我们知道，至少，算法可以区分二维和三维问题。我们看到它仍然只进行了少量迭代，并且误差是一个合理的数字（意味着它是定义的，不是负数，也不是太大）。
- en: 'If we plot these centroids against our original data we will see the following:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这些质心与原始数据相对应，我们会看到以下情况：
- en: '![](img/a9fd84dc-522b-4517-8b61-816538a9edc9.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a9fd84dc-522b-4517-8b61-816538a9edc9.png)'
- en: The circles represent the data points, as before, and now we can see our black
    diamond centroids have found their homes in the middle of their clusters. Our
    algorithm has proven that it can work for three-dimensional data, and it will
    work just as well for any number of dimensions you can give it.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 圆圈代表数据点，就像之前一样，现在我们可以看到我们的黑色菱形质心已经找到了它们簇的中间位置。我们的算法已经证明它可以用于三维数据，并且对于您给出的任何维度的数据，它都会同样有效。
- en: k-means where k is unknown
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当 k 未知时的 k-means
- en: So far, we've been able to define, in advance, how many clusters the algorithm
    should find. In each example, we've started the project knowing that our data
    has three clusters, so we've manually programmed a value of 3 for *k*. This is
    still a very useful algorithm, but you may not always know how many clusters are
    represented in your data. To solve this problem we need to extend the k-means
    algorithm.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们能够提前定义算法应该找到多少个簇。在每个示例中，我们开始项目时都知道我们的数据有三个簇，因此我们手动编程了 *k* 的值为 3。这仍然是一个非常有用的算法，但您可能并不总是知道您的数据中有多少个簇。为了解决这个问题，我们需要扩展
    k-means 算法。
- en: A major reason I included the optional error calculation in our k-means implementation
    was to help solve this problem. Using an error metric—in any ML algorithm—doesn't
    only allow us to search for a solution, it also allows us to search for the best
    *parameters* that yield the best solution.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我在 k-means 实现中包含可选的错误计算的主要原因是为了帮助解决这个问题。在任何机器学习算法中使用错误度量——不仅允许我们寻找解决方案，还允许我们寻找产生最佳解决方案的最佳
    *参数*。
- en: 'In a way, we need to build a meta-ML algorithm, or an algorithm that modifies
    our algorithm and its parameters. Our approach will be straightforward but effective:
    we''ll build a new class called `KMeansAutoSolver`, and instead of specifying
    a value of *k*, we''ll specify a range of *k* values to test. The new solver will
    run our k-means code for each value of *k* in the range and determine which value
    of *k* yields the lowest error. Additionally, we''ll also run multiple trials
    of each *k* value so that we avoid getting caught in local optima.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 从某种意义上说，我们需要构建一个元机器学习算法，或者是一个修改我们算法及其参数的算法。我们的方法将简单但有效：我们将构建一个新的类，称为 `KMeansAutoSolver`，而不是指定一个
    *k* 的值，我们将指定一个要测试的 *k* 值的范围。新的求解器将为范围内的每个 *k* 值运行我们的 k-means 代码，并确定哪个 *k* 值产生最低的错误。此外，我们还将对每个
    *k* 值运行多次试验，以避免陷入局部最优解。
- en: 'Add a file to the `src/` folder called `kmeans-autosolver.js`. Add the following
    code to the file:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个名为 `kmeans-autosolver.js` 的文件添加到 `src/` 文件夹中。将以下代码添加到该文件中：
- en: '[PRE35]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The `KMeansAutoSolver` class contains a constructor which accepts `kMin`, `kMax`,
    `maxTrials`, and `data`. The `data` parameter is the same data you would give
    to the `KMeans` class. Instead of providing the class with a value for *k,* you
    provide a range of *k *values to test, as specified by `kMin` and `kMax`. Additionally,
    we'll also program this solver to run the k-means algorithm a number of times
    for each value of *k,* in order to avoid finding local optima, as we demonstrated
    earlier.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '`KMeansAutoSolver` 类包含一个构造函数，该函数接受 `kMin`、`kMax`、`maxTrials` 和 `data` 参数。`data`
    参数与您提供给 `KMeans` 类的数据相同。您不是为类提供一个 *k* 的值，而是提供一个要测试的 *k* 值的范围，该范围由 `kMin` 和 `kMax`
    指定。此外，我们还将编程这个求解器为每个 *k* 值运行 k-means 算法多次，以避免找到局部最优解，正如我们之前所展示的。'
- en: The main part of the class is the `solve` method, which, like the `KMeans` class,
    also accepts a `maxIterations` argument. The `solve` method also returns the same
    thing the `KMeans` class returns, except that we've also added the value of *k*
    to the output and also the `currentTrial` number. Adding the value of *k* to the
    output is a bit redundant, as you could just count the number of centroids returned,
    but it's nice to see in the output.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 类的主要部分是 `solve` 方法，与 `KMeans` 类一样，它也接受一个 `maxIterations` 参数。`solve` 方法返回与 `KMeans`
    类相同的内容，除了我们还在输出中添加了 *k* 的值和 `currentTrial` 数量。将 *k* 的值添加到输出中有点冗余，因为您可以直接计算返回的质心的数量，但看到输出中的这个值还是不错的。
- en: The body of the `solve` method is straightforward. For each value of *k* in
    the range between `kMin` and `kMax`*,* we run the `KMeans` solver `maxTrials`
    times*.* If the solution beats the current best solution in terms of error, we
    record this solution as the best. At the end of the method, we return the solution
    with the best (lowest) error.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`solve`方法的主体很简单。对于`kMin`和`kMax`之间的每个*k*值*，*我们运行`KMeans`求解器`maxTrials`次*.* 如果解决方案在误差方面优于当前最佳解决方案，我们就将其记录为最佳解决方案。方法结束时，我们返回具有最佳（最低）误差的解决方案。'
- en: 'Let''s try it out. Open up `data.js` and add the following:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试看。打开`data.js`并添加以下内容：
- en: '[PRE36]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'And update the export line as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 并更新导出行如下：
- en: '[PRE37]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Graphing this data, we see four neat clusters:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制这些数据，我们看到四个整齐的聚类：
- en: '![](img/77724ab4-a38e-4f3a-8895-592e857470bd.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77724ab4-a38e-4f3a-8895-592e857470bd.png)'
- en: However, for the purposes of this example, we do not know how many clusters
    to expect, only that it's likely between one and five.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于这个示例的目的，我们不知道预期有多少个聚类，只知道它可能在1到5之间。
- en: 'Next, open up `index.js` and import the `KMeansAutoSolver` at the top of the
    file:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，打开`index.js`并在文件顶部导入`KMeansAutoSolver`：
- en: '[PRE38]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Then, at the bottom of the file, add the following:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在文件底部添加以下内容：
- en: '[PRE39]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Run `yarn start` and you should see output similar to the following (previous
    output omitted):'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`yarn start`，你应该看到类似以下输出（省略了之前的输出）：
- en: '[PRE40]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Right away, you can see that the solver found an answer with `k: 4`, which
    is what we expected, and that the algorithm reached steady state in only three
    iterations with a low error value—all good signs.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '立即可以看到，求解器找到了`k: 4`的答案，这正是我们预期的，并且算法在仅三次迭代中就达到了稳态，误差值很低——这些都是好兆头。'
- en: 'Plotting these centroids against our data, we see that the algorithm has determined
    both the correct value for *k* and the centroid positions:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些质点与我们的数据作图，我们看到算法已经确定了*k*的正确值和质心位置：
- en: '![](img/0be74388-4e0e-4154-b914-8649691d2d86.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0be74388-4e0e-4154-b914-8649691d2d86.png)'
- en: Note that our k-means auto-solver is also susceptible to local optima, and will
    not always guess the correct value for *k*. The reason? Increasing the value of
    *k* means that we can distribute more centroids amongst the data and reduce the
    error value. If we have 25 data points and set the range of *k* to anywhere from
    1 to 30, the solver may end up finding a solution where k = 25, and each centroid
    sits on top of each individual data point for a total error of 0! This can be
    considered *overfitting*, where the algorithm finds a correct answer but hasn't
    sufficiently generalized the problem to give us the results we want. Even when
    using the auto-solver, you must be careful of the range of *k* values you give
    it, and keep the range as small as possible.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们的k-means自动求解器也容易受到局部最优的影响，并且不一定总能猜出*k*的正确值。原因？增加*k*的值意味着我们可以将更多的质心分配到数据中，并减少误差值。如果我们有25个数据点，并将*k*的范围设置为1到30之间，求解器最终可能会找到一个k
    = 25的解决方案，每个质心都位于每个单独的数据点上，总误差为0！这可以被认为是*过拟合*，其中算法找到了正确的答案，但没有充分泛化问题以给出我们想要的结果。即使使用自动求解器，你也必须小心你给出的*k*值范围，并尽可能保持范围小。
- en: 'For example, if we increase `kMax` from 5 to 10 in the preceding example, we
    find that it gives a result for *k = 7* as the best. As always, the local optimum
    makes sense, but it is not quite what we were looking for:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们把前面的例子中的`kMax`从5增加到10，我们会发现它给出了*k = 7*作为最佳结果。像往常一样，局部最优是有意义的，但它并不是我们真正想要的：
- en: '![](img/dd2f5145-2c4f-4057-8e60-0eb0a213423f.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dd2f5145-2c4f-4057-8e60-0eb0a213423f.png)'
- en: Because the auto-solver uses the error value calculation as its only guidance,
    you may be able to tune the error calculation to also consider the value of *k*
    and penalize solutions with too many clusters*.* The previous error calculation
    was a purely geometric calculation, representing the average distance each point
    is from its centroid. We may want to upgrade our error calculation so that it
    also prefers solutions with fewer centroids. Let's see what that would look like.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 因为自动求解器只使用误差值计算作为其唯一指导，你可能能够调整误差计算，使其也考虑*k*的值，并惩罚具有过多聚类的解决方案*.* 之前的误差计算是一个纯粹几何计算，表示每个点与其质心的平均距离。我们可能希望升级我们的误差计算，使其也偏好具有较少质心的解决方案。让我们看看这将是什么样子。
- en: 'Return to the `kmeans.js` file and modify the `calculateError` method. Find
    the following line:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 返回`kmeans.js`文件并修改`calculateError`方法。找到以下行：
- en: '[PRE41]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'And modify it to add the value of `k` to the distance:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 并修改它以将`k`的值添加到距离中：
- en: '[PRE42]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: When running the `KMeans` class by itself, this modification will do no harm
    because the value of `k` will be constant for that solver. The only time this
    modification may be undesirable is if you're actually interpreting and using the
    error value as a representation of *distance specifically*, as opposed to just
    looking for lower error values. Meaning, if you *need* the error to be a representation
    of distance, then you should not make this change. In all other cases, however,
    it can be advantageous, as this modification will prefer solutions with fewer
    clusters.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 当单独运行 `KMeans` 类时，这种修改不会造成伤害，因为那个求解器的 `k` 值将是恒定的。唯一可能不希望这种修改的情况是，如果你实际上是在解释和使用误差值作为
    *距离* 的表示，而不是仅仅寻找更低的误差值。这意味着，如果你 *需要* 误差成为距离的表示，那么你不应该进行这种修改。然而，在所有其他情况下，这可能是有益的，因为这种修改将倾向于具有更少簇的解。
- en: Now, return to `index.js` and modify the `ex_3_solver` to search the range of
    `k` values from 1 through 30\. Run the program again with `yarn start` and you
    will see that the auto-solver once again correctly returns results for *k = 4*!
    While the previous, locally optimal solution with *k = 7* has a low error rate,
    adding the value of `k` to the error penalized the *k = 7* solution enough that
    the solver now prefers the *k = 4* solution. Because of this modification to the
    error calculation, we can be a little less careful when choosing our `kMin` and
    `kMax`, which is very helpful when we have no idea what *k* will be.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，回到 `index.js` 并修改 `ex_3_solver` 以搜索从 1 到 30 的 `k` 值范围。再次使用 `yarn start` 运行程序，你会看到自动求解器再次正确地返回了
    *k = 4* 的结果！虽然之前具有低误差率的局部最优解是 *k = 7*，但将 `k` 的值添加到误差中，使得求解器现在更倾向于 *k = 4* 的解。由于对误差计算的这种修改，我们在选择
    `kMin` 和 `kMax` 时可以稍微不那么小心，这在当我们不知道 *k* 会是多少时非常有帮助。
- en: While our error calculation is no longer a geometrical representation of the
    cluster tightness, you can see that being thoughtful about the error calculation
    can give you a lot of leeway when trying to optimize for certain system properties.
    In our case, we wanted to find not just the tightest geometrical clusters, but
    the tightest geometrical clusters *with the fewest amount of clusters possible*,
    so updating the error calculation to consider *k* was a very helpful step.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们的误差计算不再是簇紧度的几何表示，但你可以看到，在尝试优化某些系统属性时，对误差计算的深思熟虑可以给你很大的灵活性。在我们的例子中，我们不仅想要找到最紧密的几何簇，还想要找到尽可能少的簇数量的最紧密几何簇，因此将误差计算更新为考虑
    *k* 是一个非常有益的步骤。
- en: Summary
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the problem of clustering, or grouping data points
    into logically similar groups. Specifically, we introduced the k-means algorithm,
    which is the most popular numerical clustering algorithm in ML. We then implemented
    the k-means algorithm in the form of a `KMeans` JavaScript class and tested it
    with both two and three-dimensional data. We also discussed how to approach the
    clustering problem when the number of clusters you desire is unknown beforehand,
    and built a new JavaScript class called `KMeansAutoSolver` to solve this problem.
    Along the way, we also discussed the impact of error calculations, and made a
    modification to our error calculation that helps generalize our solution to avoid
    overfitting.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了聚类问题，即将数据点分组到逻辑上相似的组中。具体来说，我们介绍了 k-means 算法，这是机器学习中最流行的数值聚类算法。然后我们以
    `KMeans` JavaScript 类的形式实现了 k-means 算法，并用二维和三维数据进行了测试。我们还讨论了在事先不知道所需簇的数量时如何处理聚类问题，并构建了一个新的
    JavaScript 类 `KMeansAutoSolver` 来解决这个问题。在这个过程中，我们还讨论了误差计算的影响，并对我们的误差计算进行了修改，以帮助我们的解决方案泛化并避免过拟合。
- en: In the next chapter we'll take a look at classification algorithms. Classification
    algorithms are supervised learning algorithms that can be seen as a more sophisticated
    extension of clustering algorithms. Rather than simply grouping data points by
    their similarity or proximity, classification algorithms can be trained to learn
    specific labels that should be applied to data.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨分类算法。分类算法是监督学习算法，可以看作是聚类算法的更复杂扩展。与仅仅根据相似性或接近性对数据点进行分组不同，分类算法可以被训练来学习应该应用于数据的特定标签。
