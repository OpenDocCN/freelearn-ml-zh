- en: '*Chapter 1*: Evaluating Machine Learning Models'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第一章*：评估机器学习模型'
- en: '**Machine Learning** (**ML**) models need to be thoroughly evaluated to ensure
    they will work in production. We have to ensure the model is not *memorizing*
    the training data and also ensure it learns enough from the given training data.
    Choosing the appropriate evaluation method is also critical when we want to perform
    hyperparameter tuning at a later stage.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）模型需要彻底评估以确保它们在生产环境中能够工作。我们必须确保模型不是在**记忆**训练数据，同时也确保模型从给定的训练数据中学习到足够的信息。当我们希望在以后阶段进行超参数调整时，选择合适的评估方法也是至关重要的。'
- en: In this chapter, we'll learn about all the important things we need to know
    when it comes to evaluating ML models. First, we need to understand the concept
    of overfitting. Then, we will look at the idea of splitting data into train, validation,
    and test sets. Additionally, we'll learn about the difference between random and
    stratified splits and when to use each of them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将了解评估机器学习模型时需要了解的所有重要事项。首先，我们需要理解过拟合的概念。然后，我们将探讨将数据拆分为训练集、验证集和测试集的想法。此外，我们还将了解随机拆分和分层拆分的区别以及何时使用每种拆分方法。
- en: 'We''ll discuss the concept of cross-validation and its numerous variations
    of strategy: k-fold repeated k-fold, **Leave One Out** (**LOO**), **Leave P Out**
    (**LPO**), and a specific strategy when dealing with time-series data, called
    time-series cross-validation. We''ll also learn how to implement each of the evaluation
    strategies using the Scikit-Learn package.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论交叉验证的概念及其多种策略变体：k折重复k折、**留一法**（**LOO**）、**留P法**（**LPO**），以及处理时间序列数据时的特定策略，称为时间序列交叉验证。我们还将学习如何使用Scikit-Learn包实现每种评估策略。
- en: By the end of this chapter, you will have a good understanding of why choosing
    a proper evaluation strategy is critical in the ML model development life cycle.
    Also, you will be aware of numerous evaluation strategies and will be able to
    choose the most appropriate one for your situation. Furthermore, you will also
    be able to implement each of the evaluation strategies using the Scikit-Learn
    package.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将很好地理解为什么选择合适的评估策略在机器学习模型开发生命周期中至关重要。此外，你将了解多种评估策略，并能够根据你的情况选择最合适的一种。此外，你还将能够使用Scikit-Learn包实现每种评估策略。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主要内容：
- en: Understanding the concept of overfitting
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解过拟合的概念
- en: Creating training, validation, and test sets
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建训练集、验证集和测试集
- en: Exploring random and stratified split
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索随机和分层拆分
- en: Discovering k-fold cross-validation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现k折交叉验证
- en: Discovering repeated k-fold cross-validation
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现重复k折交叉验证
- en: Discovering LOO cross-validation
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现LOO交叉验证
- en: Discovering LPO cross-validation
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现LPO交叉验证
- en: Discovering time-series cross-validation
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现时间序列交叉验证
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will learn how to implement each of the evaluation strategies using the
    Scikit-Learn package. To ensure that you can reproduce the code examples in this
    chapter, you will need the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习如何使用Scikit-Learn包实现每种评估策略。为了确保你能重现本章中的代码示例，你需要以下内容：
- en: Python 3 (version 3.7 or above)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3（版本3.7或以上）
- en: The pandas package installed (version 1.3.4 or above)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装pandas包（版本1.3.4或以上）
- en: The Scikit-Learn package installed (version 1.0.1 or above)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Scikit-Learn包（版本1.0.1或以上）
- en: All of the code examples for this chapter can be found on GitHub at [https://github.com/PacktPublishing/Hyperparameter-Tuning-with-Python/blob/main/01_Evaluating-Machine-Learning-Models.ipynb](https://github.com/PacktPublishing/Hyperparameter-Tuning-with-Python/blob/main/01_Evaluating-Machine-Learning-Models.ipynb).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码示例都可以在GitHub上找到，链接为[https://github.com/PacktPublishing/Hyperparameter-Tuning-with-Python/blob/main/01_Evaluating-Machine-Learning-Models.ipynb](https://github.com/PacktPublishing/Hyperparameter-Tuning-with-Python/blob/main/01_Evaluating-Machine-Learning-Models.ipynb)。
- en: Understanding the concept of overfitting
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解过拟合的概念
- en: '**Overfitting** occurs when the trained ML model learns too much from the given
    training data. In this situation, the trained model successfully gets a high evaluation
    score on the training data but a far lower score on new, unseen data. In other
    words, the trained ML model fails to generalize the knowledge learned from the
    training data to the unseen data.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**过拟合**发生在训练的机器学习模型从给定的训练数据中学习过多时。在这种情况下，训练模型在训练数据上成功获得高评估分数，但在新的、未见过的数据上分数远低。换句话说，训练的机器学习模型未能将训练数据中学习到的知识泛化到未见过的数据。'
- en: So, how exactly does the trained ML model get decent performance on the training
    data but fail to give a reasonable performance on unseen data? Well, that happens
    when the model *tries too hard* to achieve high performance on the training data
    and has picked up knowledge that is only applicable to that specific training
    data. Of course, this will negatively impact the model's ability to generalize,
    which results in bad performance when the model is evaluated on unseen data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，训练的机器学习模型如何在训练数据上获得良好的性能，但在未见数据上却无法给出合理的性能呢？嗯，这发生在模型*过于努力*地试图在训练数据上获得高绩效，并吸收了仅适用于特定训练数据的知识。当然，这会负面影响模型的泛化能力，导致模型在未见数据上的评估表现不佳。
- en: 'To detect whether our trained ML model faces an overfitting issue, we can monitor
    the performance of our model on the training data versus unseen data. Performance
    can be defined as the loss value of our model or metrics that we care about, for
    example, accuracy, precision, and the mean absolute error. If the performance
    of the training data keeps getting better, while the performance on the unseen
    data starts to become stagnant or even gets worse, then this is a sign of an overfitting
    issue (see *Figure 1.1*):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检测我们的训练机器学习模型是否面临过拟合问题，我们可以监控模型在训练数据与未见数据上的性能。性能可以定义为我们的模型损失值或我们关心的指标，例如准确率、精确度和平均绝对误差。如果训练数据的性能持续改善，而未见数据的性能开始变得停滞甚至变差，那么这就是过拟合问题的迹象（参见*图1.1*）：
- en: '![Figure 1.1 – The model''s performance on training data versus unseen data
    (overfitting)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.1 – 模型在训练数据与未见数据（过拟合）上的性能'
- en: '](img/B18753_01_001.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18753_01_001.jpg)'
- en: Figure 1.1 – The model's performance on training data versus unseen data (overfitting)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – 模型在训练数据与未见数据（过拟合）上的性能
- en: Note
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The preceding diagram image has been reproduced according to the license specified:
    [https://commons.wikimedia.org/wiki/File:Overfitting_svg.svg](https://commons.wikimedia.org/wiki/File:Overfitting_svg.svg).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表图像是根据指定的许可证复制的：[https://commons.wikimedia.org/wiki/File:Overfitting_svg.svg](https://commons.wikimedia.org/wiki/File:Overfitting_svg.svg).
- en: Now that you are aware of the overfitting problem, we need to learn how to prevent
    this from happening in our ML development life cycle. We will discuss this in
    the following sections.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了过拟合问题，我们需要学习如何在我们的机器学习开发生命周期中防止这种情况发生。我们将在接下来的章节中讨论这个问题。
- en: Creating training, validation, and test sets
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建训练、验证和测试集
- en: We understand that overfitting can be detected by monitoring the model's performance
    on the training data versus the unseen data, but what exactly is unseen data?
    Is it just random data that has not yet been seen by the model during the training
    phase?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道可以通过监控模型在训练数据与未见数据上的性能来检测过拟合，但未见数据究竟是什么？它仅仅是模型在训练阶段尚未见过的随机数据吗？
- en: Unseen data is a portion of our original complete data that was not seen by
    the model during the training phase. We usually refer to this unseen data as the
    **test set**. Let's imagine you have 100,000 samples of data, to begin with; you
    can take out a portion of the data, let's say 10% of it, to become the test set.
    So, now we have 90,000 samples as the training set and 10,000 samples as the testing
    set.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 未见数据是我们原始完整数据的一部分，在训练阶段模型没有看到这部分数据。我们通常将这部分未见数据称为**测试集**。让我们假设你一开始有100,000个数据样本；你可以取出其中的一部分，比如说10%，作为测试集。因此，现在我们有90,000个样本作为训练集，10,000个样本作为测试集。
- en: However, it is better to not just split our original data into train and test
    sets but also into a **validation set**, *especially when we want to perform hyperparameter
    tuning* on our model. Let's say that out of 100,000 original samples, we held
    out 10% of it to become the validation set and another 10% to become the test
    set. Therefore, we will have 80,000 samples as the train set, 10,000 samples as
    the validation set, and 10,000 samples as the test set.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅仅将我们的原始数据拆分为训练集和测试集还不够，还需要拆分为一个**验证集**，尤其是当我们想要对模型进行超参数调整时。假设我们有100,000个原始样本，我们将其中的10%保留为验证集，另外10%作为测试集。因此，我们将有80,000个样本作为训练集，10,000个样本作为验证集，10,000个样本作为测试集。
- en: You might be wondering why do we need a validation set apart from the test set.
    Actually, we do not need it if we do not want to perform hyperparameter tuning
    or any other *model-centric* approaches. This is because the purpose of having
    a validation set is to have an unbiased evaluation of the test set using the final
    version of the trained model.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道为什么我们除了测试集之外还需要验证集。实际上，如果我们不想进行超参数调整或其他**以模型为中心**的方法，我们不需要它。这是因为拥有验证集的目的是使用训练模型的最终版本对测试集进行无偏评估。
- en: A validation set can help us to get an unbiased evaluation of the test set because
    we only incorporate the validation set during the hyperparameter tuning phase.
    Once we finish the hyperparameter tuning phase and get the final model configuration,
    we can then evaluate our model on the purely unseen data, which is called the
    test set.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 验证集可以帮助我们获得对测试集的无偏评估，因为我们只在超参数调整阶段包含验证集。一旦我们完成超参数调整阶段并得到最终的模型配置，我们就可以在纯未见过的新数据上评估我们的模型，这被称为测试集。
- en: Important Note
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If you are going to perform any data preprocessing steps (for example, missing
    value imputation, feature engineering, standardization, label encoding, and more),
    you have to build the function based on the train set and then apply it to the
    validation and test set. Do *not* perform those data preprocessing steps on the
    full original data (before data splitting). That's because it might lead to a
    **data leakage** problem.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打算执行任何数据预处理步骤（例如，缺失值填充、特征工程、标准化、标签编码等），你必须基于训练集构建函数，然后将其应用于验证集和测试集。**不要**在数据拆分之前对完整原始数据进行数据预处理（即，在数据拆分之前）。这是因为这可能会导致**数据泄露**问题。
- en: There is no specific rule when it comes to choosing the proportions for each
    of the train, validation, and test sets. You have to choose the split proportion
    by yourself based on the condition you are faced with. However, the common splitting
    proportion used by the data science community is 8:2 or 9:1 for the train set
    and the validation and test set, respectively. Usually, the validation and test
    set will have a proportion of 1:1\. Therefore, the common splitting proportion
    is 8:1:1 or 9:0.5:0.5 for the train, validation, and test sets, respectively.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择训练集、验证集和测试集的比例时，并没有特定的规则。你必须根据你所面临的情况自行选择拆分比例。然而，数据科学社区常用的拆分比例是训练集8:2或9:1，验证集和测试集分别为8:2或9:1。通常，验证集和测试集的比例为1:1。因此，常用的拆分比例是训练集8:1:1或9:0.5:0.5，分别对应训练集、验证集和测试集。
- en: Now that we are aware of the train, validation, and test set concept, we need
    to learn how to build those sets. Do we just randomly split our original data
    into three sets? Or can we also apply some predefined rules? In the next section,
    we will explore this topic in more detail.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了训练集、验证集和测试集的概念，我们需要学习如何构建这些集合。我们只是随机地将原始数据拆分为三个集合吗？或者我们也可以应用一些预定义的规则？在下一节中，我们将更详细地探讨这个话题。
- en: Exploring random and stratified splits
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索随机和分层拆分
- en: The most straightforward way (but *not entirely a correct way*) to split our
    original full data into train, validation, and test sets is by choosing the proportions
    for each set and then directly splitting them into three sets based on the order
    of the index.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们的原始完整数据直接拆分为训练集、验证集和测试集的最直接方法（但并非完全正确的方法）是选择每个集合的比例，然后根据索引的顺序直接将它们拆分为三个集合。
- en: For instance, the original full data has 100,000 samples, and we want to split
    this into train, validation, and test sets with a proportion of 8:1:1\. Then,
    the training set will be the samples from index 1 until 80,000\. The validation
    and test set will be the index from 81,000 until 90,000 and 91,000 until 100,000,
    respectively.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，原始完整数据有100,000个样本，我们希望将其按8:1:1的比例分割成训练集、验证集和测试集。那么，训练集将是索引从1到80,000的样本。验证集和测试集将分别是索引从81,000到90,000和91,000到100,000。
- en: So, what's wrong with that approach? There is nothing wrong with that approach
    *as long as the original full data is shuffled*. It might cause a problem when
    there is some kind of pattern between the indices of the samples.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这种方法有什么问题吗？只要原始完整数据被随机打乱，这种方法就没有问题。如果样本索引之间存在某种模式，可能会引起问题。
- en: For instance, we have data consisting of 10,000 samples and 3 columns. The first
    and second columns contain weight and height information, respectively. The third
    column contains the "weight status" class (for example, underweight, normal weight,
    overweight, and obesity). Our task is to build an ML classifier model to predict
    what the "weight status" class of a person is, given their weight and height.
    It is not impossible for the data to be given to us in the condition that it was
    ordered based on the third column. So, the first 80,000 rows only consist of the
    underweight and normal weight classes. In comparison, the overweight and obesity
    classes are only located in the last 20,000 rows. If this is the case, and we
    apply the data splitting logic from earlier, then there is no way our classifier
    can predict a new person has the overweight or obesity "weight status" classes.
    Why? Because our classifier has never seen those classes before during the training
    phase!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们拥有包含10,000个样本和3列的数据。第一列和第二列分别包含体重和身高信息。第三列包含“体重状态”类别（例如，体重不足、正常体重、超重和肥胖）。我们的任务是构建一个机器学习分类器模型，根据一个人的体重和身高预测其“体重状态”类别。如果数据是按照第三列排序给出的，这种情况并非不可能。因此，前80,000行只包含体重不足和正常体重类别。相比之下，超重和肥胖类别仅位于最后20,000行。如果这种情况发生，并且我们应用之前的数据分割逻辑，那么我们的分类器将无法预测一个新的人具有超重或肥胖的“体重状态”类别。为什么？因为我们的分类器在训练阶段从未见过这些类别！
- en: Therefore, it is very important to ensure the original full data is shuffled
    in the first place, and essentially, this is what we mean by the random split.
    **Random split** works by first shuffling the original full data and then splitting
    it into the train, validation, and test sets based on the order of the index.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，确保原始完整数据首先被随机打乱是非常重要的，本质上，这就是我们所说的随机分割。**随机分割**的工作原理是首先打乱原始完整数据，然后根据索引顺序将其分割成训练集、验证集和测试集。
- en: There is also another splitting logic called the **stratified split**. This
    logic ensures that the train, validation, and test set will get *a similar proportion
    number of samples for each target class* found in the original full data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种称为**分层分割**的分割逻辑。这种逻辑确保训练集、验证集和测试集将获得与原始完整数据中每个目标类别相似的样本比例。
- en: Using the same "weight status" class prediction case example, let's say that
    we found that the proportion of each class in the full original data is 3:5:1.5:0.5
    for underweight, normal weight, overweight, and obese, respectively. The stratified
    split logic will ensure that we can find a similar proportion of those classes
    in the train, validation, and test sets. So, out of 80,000 samples of the train
    set, around 24,000 samples are in the underweight class, around 40,000 samples
    are in the normal weight class, around 12,000 samples are overweight, and around
    4,000 samples are in the obesity class. This will also be applied to the validation
    and test set.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以相同的“体重状态”类别预测案例为例，假设我们发现全原始数据中每个类别的比例分别是体重不足3:5:1.5:0.5、正常体重、超重和肥胖。分层分割逻辑将确保我们可以在训练集、验证集和测试集中找到这些类别的相似比例。因此，在80,000个训练样本中，大约有24,000个样本属于体重不足类别，大约有40,000个样本属于正常体重类别，大约有12,000个样本属于超重，大约有4,000个样本属于肥胖类别。这也会应用到验证集和测试集。
- en: The remaining question is understanding *when it is the right time* to use the
    random split/stratified split logic. Often, the stratified split logic is used
    when we are faced with an imbalanced class problem. However, it is also often
    used when we want to make sure that we have a similar proportion of samples based
    on a specific variable (not necessarily the target class). If you are not faced
    with this kind of situation, then the random split is the go-to logic that you
    can always choose.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的问题是理解 *何时是使用随机分割/分层分割逻辑的正确时机*。通常，当面临不平衡类别问题时，我们会使用分层分割逻辑。然而，当我们要确保基于特定变量（不一定必须是目标类别）具有相似样本比例时，分层分割也经常被使用。如果你没有遇到这种情况，那么随机分割就是你可以始终选择的逻辑。
- en: 'To implement both of the data splitting logics, you can write the code by yourself
    from scratch or utilize the well-known package called **Scikit-Learn**. The following
    is an example to perform a random split with a proportion of 8:1:1:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这两种数据分割逻辑，你可以从头开始编写代码，或者利用名为 **Scikit-Learn** 的知名包。以下是一个以 8:1:1 的比例执行随机分割的示例：
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `df` variable is our complete original data that was stored in the Pandas
    DataFrame object. The `train_test_split` function splits the Pandas DataFrame,
    array, or matrix into shuffled train and test sets. In lines 2–3, first, we split
    the original full data into `df_train` and `df_unseen` with a proportion of 8:2,
    as specified by the `test_size` argument. Then, we split `df_unseen` into `df_val`
    and `df_test` with a proportion of 1:1.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`df` 变量是我们存储在 Pandas DataFrame 对象中的完整原始数据。`train_test_split` 函数将 Pandas DataFrame、数组或矩阵分割成打乱的训练集和测试集。在第
    2-3 行中，首先，我们根据 `test_size` 参数指定的比例 8:2 将原始完整数据分割成 `df_train` 和 `df_unseen`。然后，我们将
    `df_unseen` 按比例 1:1 分割成 `df_val` 和 `df_test`。'
- en: 'To perform the *stratify split* logic, you can just add the `stratify` argument
    to the `train_test_split` function and fill it with the target array:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行 *分层分割* 逻辑，你只需将 `stratify` 参数添加到 `train_test_split` 函数中，并用目标数组填充它：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `stratify` argument will ensure the data is split in the stratified fashion
    based on the given target array.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`stratify` 参数将确保数据根据给定的目标数组以分层的方式进行分割。'
- en: In this section, we have learned the importance of shuffling the original full
    data before performing data splitting and also understand the difference between
    the random and stratified split, as well as when to use each of them. In the next
    section, we will start learning variations of the data splitting strategies and
    how to implement each of them using the Scikit-learn package.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了在执行数据分割之前对原始完整数据进行洗牌的重要性，也理解了随机分割和分层分割之间的区别，以及何时使用每种分割。在下一节中，我们将开始学习数据分割策略的变体，以及如何使用
    Scikit-learn 包实现每种策略。
- en: Discovering k-fold cross-validation
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 探索 k 折交叉验证
- en: '**Cross-validation** is a way to evaluate our ML model by performing *multiple
    evaluations* on our original full data via a resampling procedure. This is a variation
    from the vanilla train-validation-test split that we learned about in previous
    sections. Additionally, the concept of random and stratified splits can be applied
    in cross-validation.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**交叉验证**是一种通过在原始完整数据上执行多次评估来评估我们的机器学习模型的方法。这与我们在前几节中学到的标准训练-验证-测试分割有所不同。此外，随机分割和分层分割的概念也可以应用于交叉验证。'
- en: In cross-validation, we perform multiple splits for the *train and validation*
    sets, where each split is usually referred to **Fold**. What about the test set?
    Well, it still acts as the purely unseen data where we can test the final model
    configuration on it. Therefore, in the beginning, it is only separated once from
    the train and validation set.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在交叉验证中，我们对训练集和验证集执行多次分割，其中每个分割通常被称为 **折**。那么测试集呢？嗯，它仍然作为纯未见过数据存在，我们可以用它来测试最终的模型配置。因此，在开始时，它只从训练集和验证集中分离一次。
- en: 'There are several variations of the cross-validation strategy. The first one
    is called **k-fold cross-validation**. It works by performing k times of training
    and evaluation with a proportion of (k-1):1 for the train and validation set,
    respectively, in each fold. To have a clearer understanding of k-fold cross-validation,
    please refer to *Figure 1.2*:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证策略有几种变体。第一种被称为 **k 折交叉验证**。它通过在每个折中执行 k 次训练和评估，分别以 (k-1):1 的比例对训练集和验证集进行训练和评估来实现。为了更清楚地理解
    k 折交叉验证，请参考 *图 1.2*：
- en: '![Figure 1.2 – K-fold cross-validation'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.2 – K 折交叉验证'
- en: '](img/B18753_01_002.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18753_01_002.jpg)'
- en: Figure 1.2 – K-fold cross-validation
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2 – K 折交叉验证
- en: Note
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The preceding diagram has been reproduced according to the license specified:
    [https://commons.wikimedia.org/wiki/File:K-fold_cross_validation.jpg](https://commons.wikimedia.org/wiki/File:K-fold_cross_validation.jpg).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表是根据指定的许可证复制的：[https://commons.wikimedia.org/wiki/File:K-fold_cross_validation.jpg](https://commons.wikimedia.org/wiki/File:K-fold_cross_validation.jpg)。
- en: For instance, let's choose k = 4 to match the illustration in *Figure 1.2*.
    The green and red balls correspond to the target class, where, in this case, we
    only have two target classes. The data is shuffled beforehand, which can be seen
    from the absence of a pattern of green and red balls. It is also worth mentioning
    that the *shuffling was previously only done once*. That's why the order of green
    and red balls is always the same for each iteration (fold). The black box in each
    fold corresponds to the validation set (the test data is in the illustration).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们选择 k = 4 来匹配 *图 1.2* 中的插图。绿色和红色球对应于目标类别，在这种情况下，我们只有两个目标类别。数据在之前已经被打乱，这可以从绿色和红色球没有模式中看出。也值得提到的是，*打乱之前只进行了一次*。这就是为什么绿色和红色球的顺序在每次迭代（折）中总是相同的。每个折中的黑色框对应于验证集（测试数据在插图上）。
- en: As you can see in *Figure 1.2*, the proportion of the training set versus the
    validation set is (k-1):1, or in this case, 3:1\. During each fold, the model
    will be trained on the train set and evaluated on the validation set. Notice that
    the training and validation sets are *different across each fold*. The final evaluation
    score can be calculated by taking the average score of all of the folds.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在 *图 1.2* 中所见，训练集与验证集的比例是 (k-1):1，或者在这个例子中，3:1。在每一折中，模型将在训练集上训练并在验证集上评估。请注意，训练集和验证集在每个折中都是
    *不同的*。最终评估分数可以通过取所有折的平均分数来计算。
- en: 'In summary, k-fold cross-validation works as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，k 折交叉验证的工作原理如下：
- en: Shuffling the original full data
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打乱原始完整数据。
- en: Holding out the test data
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保留测试数据
- en: Performing the k-fold multiple evaluation strategy on the rest of the original
    full data
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在原始完整数据集的其余部分执行 k 折多次评估策略。
- en: Calculating the final evaluation score by taking the average score of all of
    the folds
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过取所有折的平均分数来计算最终评估分数。
- en: Evaluating the test data using the final model configuration
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用最终模型配置评估测试数据。
- en: 'You might ask why do we need to perform cross-validation in the first place?
    Why is the vanilla train-validation-test splitting strategy not enough? There
    are several reasons why we need to apply the cross-validation strategy:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会问，为什么我们最初需要进行交叉验证？为什么传统的训练-验证-测试分割策略不够用？我们需要应用交叉验证策略有几个原因：
- en: Having only a small amount of training data.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有少量训练数据。
- en: To get a more confident conclusion from the evaluation performance.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了从评估性能中获得更自信的结论。
- en: To get a clearer picture of our model's learning ability and/or the complexity
    of the given data.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了更清晰地了解我们模型的学习能力以及/或给定数据的复杂性。
- en: 'The first and second reasons are quite straightforward. The third reason is
    more interesting and should be discussed. How can cross-validation help us to
    get a better idea about our model''s learning ability and/or the data complexity?
    Well, this happens when the variation of evaluation scores from each fold is quite
    big. For instance, out of 4 folds, we get accuracy scores of 45%, 82%, 64%, and
    98%. This scenario should trigger our curiosity: what is wrong with our model
    and/or data? It could be that the data is too hard to learn and/or our model can''t
    learn properly.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个原因是相当直接的。第三个原因更有趣，应该进行讨论。交叉验证如何帮助我们更好地了解模型的学习能力以及/或数据复杂性？好吧，这发生在每个折的评估分数变化相当大的时候。例如，在
    4 个折中，我们得到了准确率分数 45%、82%、64% 和 98%。这种情况应该激发我们的好奇心：我们的模型和数据有什么问题？可能是数据太难学习，或者我们的模型不能正确学习。
- en: 'The following is the syntax to perform k-fold cross-validation via the Scikit-Learn
    package:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过 Scikit-Learn 包执行 k 折交叉验证的语法：
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Notice that, first, we hold out the test set and only work with `df_cv` when
    performing the k-fold cross-validation. By default, the `Kfold` function will
    disable the shuffling procedure. However, this is not a problem for us since the
    data has already shuffled beforehand when we called the `train_test_split` function.
    If you want to run the shuffling procedure again, you can pass `shuffle=True`
    in the `Kfold` function.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，首先，我们在进行k折交叉验证时保留测试集，并且只使用`df_cv`。默认情况下，`Kfold`函数将禁用洗牌过程。然而，这对我们来说不是问题，因为我们调用`train_test_split`函数时数据已经预先洗牌了。如果你想再次运行洗牌过程，可以在`Kfold`函数中传递`shuffle=True`。
- en: 'Here is another example if you are interested in learning how to apply the
    concept of stratifying splits in k-fold cross-validation:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣学习如何在k折交叉验证中应用分层分割的概念，这里有一个例子：
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The only difference is to import `StratifiedKFold` instead of the `Kfold` function
    and add the array of target variables, which will be used to split the data in
    a stratified fashion.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的区别是导入`StratifiedKFold`而不是`Kfold`函数，并添加目标变量的数组，这将用于以分层的方式分割数据。
- en: In this section, you have learned what cross-validation is, when the right time
    is to perform cross-validation, and the first (and the *most widely used*) cross-validation
    strategy variation, which is called k-fold cross-validation. In the subsequent
    sections, we will also learn other variations of cross-validation and how to implement
    them using the Scikit-Learn package.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你学习了什么是交叉验证，何时是进行交叉验证的正确时机，以及第一个（也是*最广泛使用*）的交叉验证策略变体，即k折交叉验证。在随后的章节中，我们还将学习其他交叉验证的变体以及如何使用Scikit-Learn包实现它们。
- en: Discovering repeated k-fold cross-validation
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发现重复k折交叉验证
- en: '**Repeated k-fold cross-validation** involves simply performing the k-fold
    cross-validation repeatedly, *N* times, with different randomizations in each
    repetition. The final evaluation score is the average of all scores from all folds
    of each repetition. This strategy will increase our confidence in our model.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**重复k折交叉验证**涉及简单地重复执行k折交叉验证，*N*次，每次重复都有不同的随机化。最终的评估分数是所有重复中所有折的分数的平均值。这种策略将增加我们对模型自信。'
- en: So, why repeat the k-fold cross-validation? Why don't we just increase the value
    of k in k-fold? Surely, increasing the value of k will reduce the bias of our
    model's estimated performance. However, increasing the value of k will increase
    the variation, especially when we have a small number of samples. Therefore, usually,
    repeating the k-folds is a better way to gain higher confidence in our model's
    estimated performance. Of course, this comes with a drawback, which is the increase
    in computation time.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么重复k折交叉验证呢？为什么我们不直接增加k的值呢？当然，增加k的值将减少模型估计性能的偏差。然而，增加k的值会增加变异，尤其是在样本数量较少的情况下。因此，通常重复k折是获得对模型估计性能更高自信的更好方法。当然，这也伴随着一个缺点，那就是计算时间的增加。
- en: 'To implement this strategy, we can simply perform a manual for-loop, where
    we apply the k-fold cross-validation strategy to each loop. Fortunately, the Scikit-Learn
    package provide us with a specific function in which to implement this strategy:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这一策略，我们可以简单地执行一个手动循环，在每次循环中应用k折交叉验证策略。幸运的是，Scikit-Learn包为我们提供了一个特定的函数来实现这一策略：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Choosing `n_splits=4` and `n_repeats=3` means that we will have 12 different
    train and validation sets. The final evaluation score is then just the average
    of all 12 scores. As you might expect, there is also a dedicated function to implement
    the repeated k-fold in a stratified fashion:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 选择`n_splits=4`和`n_repeats=3`意味着我们将有12个不同的训练和验证集。最终的评估分数就是这12个分数的平均值。正如你所预期的，也有一个专门的功能来实现分层重复k折：
- en: '[PRE23]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `RepeatedStratifiedKFold` function will perform stratified k-fold cross-validation
    repeatedly, `n_repeats` times.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`RepeatedStratifiedKFold`函数将重复执行分层k折交叉验证，`n_repeats`次。'
- en: Now that you have learned another variation of the cross-validation strategy,
    called repeated k-fold cross-validation, let's learn about the other variations
    next.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学习了另一种交叉验证策略的变体，称为重复k折交叉验证，接下来让我们了解其他变体。
- en: Discovering Leave-One-Out cross-validation
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发现留一法交叉验证
- en: 'Essentially, **Leave One Out (LOO) cross-validation** is just k-fold cross-validation
    where k = n, where n is the number of samples. This means there are n-1 samples
    for the training set and 1 sample for the validation set in each fold (see *Figure
    1.3*). Undoubtedly, this is a very *computationally expensive* strategy and will
    result in a *very high variance* evaluation score estimator:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，**Leave One Out (LOO)交叉验证**只是k-fold交叉验证，其中k = n，n是样本数量。这意味着每个折叠中有n-1个样本用于训练集，1个样本用于验证集（见*图1.3*）。毫无疑问，这是一个非常*计算密集型*的策略，并将导致*非常高的方差*评估分数估计器：
- en: '![Figure 1.3 – LOO cross-validation'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.3 – LOO交叉验证'
- en: '](img/B18753_01_003.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18753_01_003.jpg)'
- en: Figure 1.3 – LOO cross-validation
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – LOO交叉验证
- en: So, when is LOO preferred over k-fold cross-validation? Well, LOO works best
    when you have a very small dataset. It is also good to choose LOO over k-fold
    if you prefer the high confidence of the model's performance estimation over the
    computational cost limitation.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，何时选择LOO而不是k-fold交叉验证？嗯，当数据集非常小的时候，LOO效果最好。如果你更倾向于模型性能估计的高置信度而不是计算成本的限制，那么选择LOO比k-fold更好。
- en: 'Implementing this strategy from scratch is actually very simple. We just need
    to loop through each of the indexes of data and do some data manipulation. However,
    the Scikit-Learn package also provides the implementation for LOO, which we can
    use:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 从头开始实现这种策略实际上非常简单。我们只需要遍历数据的每个索引并进行一些数据处理。然而，Scikit-Learn包也提供了LOO的实现，我们可以使用它：
- en: '[PRE29]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Notice that there is no argument provided in the `LeaveOneOut` function since
    this strategy is very straightforward and involves no stochastic procedure. There
    is also no stratified version of the LOO since the validation set will always
    contain one sample.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在`LeaveOneOut`函数中没有提供任何参数，因为这种策略非常直接，不涉及任何随机过程。也没有LPO的分层版本，因为验证集将始终包含一个样本。
- en: Now that you are aware of the concept of LOO, in the next section, we will learn
    about a slight variation of LOO.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你已经了解了LOO的概念，在下一节中，我们将学习LOO的轻微变化。
- en: Discovering LPO cross-validation
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发现LPO交叉验证
- en: '**LPO cross-validation** is a variation of the LOO cross-validation strategy,
    where the validation set in each fold contains *p* samples instead of only 1 sample.
    Similar to LOO, this strategy will ensure that we get all possible combinations
    of train-validation pairs. To be more precise, there will be ![](img/Formula_B18753_01_001.png)
    number of folds assuming there are *n* samples on our data. For example, there
    will be ![](img/Formula_B18753_01_002.png) or 142,506 folds if we want to perform
    Leave-5-Out cross-validation on data that has 50 samples.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**LPO交叉验证**是LOO交叉验证策略的一种变体，其中每个折叠的验证集包含*p*个样本，而不是仅包含1个样本。类似于LOO，这种策略将确保我们得到所有可能的训练-验证对组合。更精确地说，如果有*n*个样本在我们的数据中，将会有![](img/Formula_B18753_01_001.png)个折叠。例如，如果我们想在有50个样本的数据上执行Leave-5-Out交叉验证，将会有![](img/Formula_B18753_01_002.png)或142,506个折叠。'
- en: LPO is suitable when you have a small number of samples and want to get even
    higher confidence in the model's estimated performance compared to the LOO method.
    LPO will result in an exploding number of folds when you have a large number of
    samples.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 当样本数量较少且希望比LOO方法获得更高的模型估计性能置信度时，LPO是合适的。当样本数量较多时，LPO将导致折叠数量激增。
- en: 'This strategy is a bit different from k-fold or LOO in terms of the overlapping
    between the validation sets. For P > 1, LPO will result in overlapping validation
    sets, while k-fold and LOO will always result in non-overlapping validation sets.
    Also, note that LPO is different from k-fold with K = N // P since k-fold will
    always create non-overlapping validation sets, but not with the LPO strategy:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这种策略在验证集之间的重叠方面与k-fold或LOO略有不同。对于P > 1，LPO将导致重叠的验证集，而k-fold和LOO将始终导致非重叠的验证集。此外，请注意，LPO与k-fold不同，因为当K
    = N // P时，k-fold将始终创建非重叠的验证集，但LPO策略则不是这样：
- en: '[PRE35]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Unlike LOO, we have to provide the `p` argument to LPO, which refers to the
    p values in LPO.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 与LOO不同，我们必须为LPO提供`p`参数，它指的是LPO中的p值。
- en: In this section, we have learned about the variations of the LOO cross-validation
    strategy. In the next section, we will learn how to perform cross-validation on
    time-series data.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了LOO交叉验证策略的变体。在下一节中，我们将学习如何在时间序列数据上执行交叉验证。
- en: Discovering time-series cross-validation
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发现时间序列交叉验证
- en: '**Time-series** data has a unique characteristic in nature. Unlike "normal"
    data, which is assumed to be **independent and identically distributed** (**IID**),
    time-series data does not follow that assumption. In fact, each sample is dependent
    on previous samples, meaning changing the order of the samples will result in
    different data interpretations.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间序列**数据在本质上具有独特的特征。与假设为**独立同分布**（**IID**）的“正常”数据不同，时间序列数据不遵循这一假设。实际上，每个样本都依赖于前面的样本，这意味着改变样本的顺序会导致不同的数据解释。'
- en: 'Several examples of time-series data are listed as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列出了几个时间序列数据的示例：
- en: Daily stock market price
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每日股市价格
- en: Hourly temperature data
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每小时温度数据
- en: Minute-by-minute web page clicks count
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每分钟网页点击次数
- en: There will be a **look-ahead bias** if we apply previous cross-validation strategies
    (for example, k-fold or random or stratified splits) to time-series data. Look-ahead
    bias happens when we use the future value of the data that is supposedly not available
    for the current time of the simulation.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将之前的交叉验证策略（例如，k-fold、随机或分层拆分）应用于时间序列数据，将会出现**前瞻偏差**。前瞻偏差发生在我们使用数据当前模拟时间点后未来的值时。
- en: For instance, we are working with hourly temperature data. We want to predict
    what the temperature will be in 2 hours, but we use the temperature value of the
    next hour or the next 3 hours, which is supposedly not available yet. This kind
    of bias will happen easily if we apply the previous cross-validation strategies
    since those strategies are designed to work well only on IID distribution.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们正在处理每小时温度数据。我们想要预测2小时后的温度，但我们使用的是下一小时或下一3小时的温度值，这本来应该是不可用的。如果我们应用之前的交叉验证策略，这种偏差很容易发生，因为那些策略仅设计在IID分布上良好工作。
- en: '**Time-series cross-validation** is the cross-validation strategy that is specifically
    designed to handle time-series data. It works similarly to k-fold in terms of
    accepting the predefined values of folds, which then generates k test sets. The
    difference is that the *data* *is not shuffled in the first place*, and the training
    set in the next iteration is the *superset* of the one in the previous iteration,
    meaning the training set keeps getting bigger over the number of iterations. Once
    we finish with the cross-validation and get the final model configuration, we
    can then test our final model on the test data (see *Figure 1.4*):'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间序列交叉验证**是一种专门为处理时间序列数据而设计的交叉验证策略。它在接受折叠的预定义值方面与k-fold类似，然后生成k个测试集。不同之处在于，*数据*在最初*并未打乱*，下一个迭代的训练集是前一个迭代的*超集*，这意味着训练集在迭代次数增加的过程中会不断变大。一旦我们完成了交叉验证并获得了最终的模型配置，我们就可以在测试数据上测试我们的最终模型（见*图1.4*）：'
- en: '![Figure 1.4 – Time-series cross-validation'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.4 – 时间序列交叉验证'
- en: '](img/B18753_01_004.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18753_01_004.jpg)'
- en: Figure 1.4 – Time-series cross-validation
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – 时间序列交叉验证
- en: 'Also, the Scikit-Learn package provides us with a nice implementation of this
    strategy:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Scikit-Learn包为我们提供了一个很好的策略实现：
- en: '[PRE41]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Providing n_splits=5 will ensure that there are five test sets generated. It
    is worth noting that, by default, the train set will have the size of ![](img/Formula_B18753_01_003.png)
    for the ith fold, while the test set will have the size of ![](img/Formula_B18753_01_004.png).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 提供n_splits=5将确保生成五个测试集。值得注意的是，默认情况下，训练集将为第i个折叠的大小为![](img/Formula_B18753_01_003.png)，而测试集将为![](img/Formula_B18753_01_004.png)的大小。
- en: However, you can change the train and test set size via the `max_train_size`
    and `test_size` arguments of the `TimeSeriesSplit` function. Additionally, there
    is also a `gap` argument that can be utilized to exclude G samples from the end
    of each train set, where G is the value needed to be specified by the developer.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您可以通过`TimeSeriesSplit`函数的`max_train_size`和`test_size`参数来更改训练集和测试集的大小。此外，还有一个`gap`参数可以被利用来排除每个训练集末尾的G个样本，其中G是开发者需要指定的值。
- en: You need to be aware that the Scikit-Learn implementation will always make sure
    that *there is no overlap between test sets*, which is actually not necessary.
    Currently, there is no way to enable the overlap between the test sets using the
    Scikit-Learn implementation. You need to *write the code from scratch* to perform
    that kind of strategy.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要意识到，Scikit-Learn的实现将始终确保*测试集之间没有重叠*，这实际上并不是必要的。目前，使用Scikit-Learn实现无法启用测试集之间的重叠。您需要*从头编写代码*来执行这种策略。
- en: In this section, we learned about the unique characteristic of time-series data
    and how to perform a cross-validation strategy on it. There are other variations
    of the cross-validation strategy that haven't been covered in this book. If you
    are interested, you might find some pointers in the *Further reading* section.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了时间序列数据的独特特征以及如何对其执行交叉验证策略。本书中未涵盖交叉验证策略的其他变体。如果您感兴趣，您可能会在*进一步阅读*部分找到一些线索。
- en: Summary
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned a lot of important things that we need to know regarding
    how to evaluate ML models properly. Starting from the concept of overfitting,
    numerous data splitting strategies, how to choose the best data splitting strategy
    based on the given situation, and how to implement each of them using the Scikit-Learn
    package. Understanding these concepts is important since you can't perform a good
    hyperparameter tuning process without applying the appropriate data splitting
    strategy.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了许多关于如何正确评估机器学习模型的重要知识。从过拟合的概念出发，探讨了多种数据拆分策略，以及如何根据具体情况选择最佳的数据拆分策略，以及如何使用Scikit-Learn包实现这些策略。理解这些概念非常重要，因为如果不应用适当的数据拆分策略，您无法进行良好的超参数调整过程。
- en: In the next chapter, we will discuss hyperparameter tuning. We will not only
    discuss the definition but also several misconceptions and types of hyperparameter
    distributions.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论超参数调整。我们将不仅讨论定义，还会讨论一些误解和超参数分布的类型。
- en: Further reading
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: In this chapter, we have covered a lot of topics. However, there are still many
    uncovered interesting algorithms related to cross-validation due to the scope
    of this book. If you want to learn more about those algorithms and the implementation
    details of each of them, you can refer to this awesome page created by the Scikit-Learn
    authors at [https://scikit-learn.org/stable/modules/cross_validation.html](https://scikit-learn.org/stable/modules/cross_validation.html).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖了众多主题。然而，由于本书的范畴限制，仍有许多与交叉验证相关的有趣算法未被涉及。如果您想了解更多关于这些算法以及每个算法的实现细节，可以参考Scikit-Learn作者创建的这篇精彩的页面：[https://scikit-learn.org/stable/modules/cross_validation.html](https://scikit-learn.org/stable/modules/cross_validation.html)。
