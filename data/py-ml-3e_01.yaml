- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Giving Computers the Ability to Learn from Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 赋予计算机从数据中学习的能力
- en: In my opinion, **machine learning**, the application and science of algorithms
    that make sense of data, is the most exciting field of all the computer sciences!
    We are living in an age where data comes in abundance; using self-learning algorithms
    from the field of machine learning, we can turn this data into knowledge. Thanks
    to the many powerful open source libraries that have been developed in recent
    years, there has probably never been a better time to break into the machine learning
    field and learn how to utilize powerful algorithms to spot patterns in data and
    make predictions about future events.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，**机器学习**，作为一种理解数据的算法应用与科学，是所有计算机科学领域中最令人兴奋的！我们正生活在一个数据充盈的时代；利用机器学习领域中的自我学习算法，我们可以将这些数据转化为知识。得益于近年来开发的许多强大的开源库，可能没有比现在更好的时机来进入机器学习领域，并学习如何利用强大的算法从数据中识别模式，并预测未来事件。
- en: In this chapter, you will learn about the main concepts and different types
    of machine learning. Together with a basic introduction to the relevant terminology,
    we will lay the groundwork for successfully using machine learning techniques
    for practical problem solving.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习机器学习的主要概念和不同类型的机器学习。结合对相关术语的基本介绍，我们将为成功使用机器学习技术解决实际问题奠定基础。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The general concepts of machine learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的通用概念
- en: The three types of learning and basic terminology
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三种学习类型及基本术语
- en: The building blocks for successfully designing machine learning systems
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成功设计机器学习系统的构建模块
- en: Installing and setting up Python for data analysis and machine learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装和设置Python用于数据分析和机器学习
- en: Building intelligent machines to transform data into knowledge
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建智能机器，将数据转化为知识
- en: 'In this age of modern technology, there is one resource that we have in abundance:
    a large amount of structured and unstructured data. In the second half of the
    20th century, machine learning evolved as a subfield of **artificial intelligence**
    (**AI**) involving self-learning algorithms that derive knowledge from data in
    order to make predictions.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个现代技术的时代，我们拥有一种丰富的资源：大量的结构化和非结构化数据。在20世纪下半叶，机器学习作为**人工智能**（**AI**）的一个子领域发展起来，涉及自我学习的算法，这些算法从数据中提取知识并进行预测。
- en: Instead of requiring humans to manually derive rules and build models from analyzing
    large amounts of data, machine learning offers a more efficient alternative for
    capturing the knowledge in data to gradually improve the performance of predictive
    models and make data-driven decisions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习提供了一种比要求人类手动从大量数据中推导规则和建立模型更高效的替代方案，通过捕获数据中的知识，逐步提高预测模型的性能，并做出基于数据的决策。
- en: Not only is machine learning becoming increasingly important in computer science
    research, but it is also playing an ever-greater role in our everyday lives. Thanks
    to machine learning, we enjoy robust email spam filters, convenient text and voice
    recognition software, reliable web search engines, and challenging chess-playing
    programs. Hopefully soon, we will add safe and efficient self-driving cars to
    this list. Also, notable progress has been made in medical applications; for example,
    researchers demonstrated that deep learning models can detect skin cancer with
    near-human accuracy ([https://www.nature.com/articles/nature21056](https://www.nature.com/articles/nature21056)).
    Another milestone was recently achieved by researchers at DeepMind, who used deep
    learning to predict 3D protein structures, outperforming physics-based approaches
    for the first time ([https://deepmind.com/blog/alphafold/](https://deepmind.com/blog/alphafold/)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习不仅在计算机科学研究中变得越来越重要，而且在我们日常生活中也扮演着越来越大的角色。得益于机器学习，我们享受着强大的电子邮件垃圾邮件过滤器、便捷的文本和语音识别软件、可靠的网页搜索引擎和具有挑战性的国际象棋程序。希望不久后，我们能将安全高效的自动驾驶汽车加入这个列表。此外，在医学应用方面也取得了显著进展；例如，研究人员证明深度学习模型能够以接近人类的准确性检测皮肤癌（[https://www.nature.com/articles/nature21056](https://www.nature.com/articles/nature21056)）。最近，DeepMind的研究人员通过深度学习预测3D蛋白质结构，首次超越了基于物理的传统方法（[https://deepmind.com/blog/alphafold/](https://deepmind.com/blog/alphafold/)）。
- en: The three different types of machine learning
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的三种不同类型
- en: 'In this section, we will take a look at the three types of machine learning:
    **supervised learning**, **unsupervised learning**, and **reinforcement learning**.
    We will learn about the fundamental differences between the three different learning
    types and, using conceptual examples, we will develop an understanding of the
    practical problem domains where they can be applied:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍三种类型的机器学习：**监督学习**、**无监督学习**和**强化学习**。我们将了解这三种不同学习类型之间的基本区别，并通过概念性示例，我们将理解它们可以应用于的实际问题领域：
- en: '![](img/B13208_01_01.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_01.png)'
- en: Making predictions about the future with supervised learning
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用监督学习对未来进行预测
- en: 'The main goal in supervised learning is to learn a model from labeled training
    data that allows us to make predictions about unseen or future data. Here, the
    term "supervised" refers to a set of training examples (data inputs) where the
    desired output signals (labels) are already known. The following figure summarizes
    a typical supervised learning workflow, where the labeled training data is passed
    to a machine learning algorithm for fitting a predictive model that can make predictions
    on new, unlabeled data inputs:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的主要目标是从标注好的训练数据中学习一个模型，使我们能够对未见过或未来的数据进行预测。在这里，“监督”一词指的是一组训练样本（数据输入），这些训练样本的目标输出信号（标签）已经知道。下图总结了一个典型的监督学习工作流程，其中标注好的训练数据被传递给机器学习算法，用于拟合一个预测模型，从而可以对新的、未标记的数据输入进行预测：
- en: '![](img/B13208_01_02.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_02.png)'
- en: Considering the example of email spam filtering, we can train a model using
    a supervised machine learning algorithm on a corpus of labeled emails, which are
    correctly marked as spam or non-spam, to predict whether a new email belongs to
    either of the two categories. A supervised learning task with discrete class labels,
    such as in the previous email spam filtering example, is also called a **classification
    task**. Another subcategory of supervised learning is **regression**, where the
    outcome signal is a continuous value.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以电子邮件垃圾邮件过滤为例，我们可以使用监督学习算法在标注好的电子邮件语料库上训练一个模型，这些电子邮件已经正确地标记为垃圾邮件或非垃圾邮件，从而预测一封新邮件是否属于这两个类别之一。具有离散类别标签的监督学习任务，如之前的电子邮件垃圾邮件过滤示例，也被称为**分类任务**。监督学习的另一个子类别是**回归**，其中输出信号是一个连续值。
- en: Classification for predicting class labels
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用于预测类别标签的分类
- en: 'Classification is a subcategory of supervised learning where the goal is to
    predict the categorical class labels of new instances, based on past observations.
    Those class labels are discrete, unordered values that can be understood as the
    group memberships of the instances. The previously mentioned example of email
    spam detection represents a typical example of a binary classification task, where
    the machine learning algorithm learns a set of rules in order to distinguish between
    two possible classes: spam and non-spam emails.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是监督学习的一个子类别，其目标是根据过去的观察来预测新实例的类别标签。这些类别标签是离散的、无序的值，可以理解为实例的组成员身份。之前提到的电子邮件垃圾邮件检测示例代表了一个典型的二分类任务，在这个任务中，机器学习算法学习一组规则，以区分两种可能的类别：垃圾邮件和非垃圾邮件。
- en: 'The following figure illustrates the concept of a binary classification task
    given 30 training examples; 15 training examples are labeled as the negative class
    (minus signs) and 15 training examples are labeled as the positive class (plus
    signs). In this scenario, our dataset is two-dimensional, which means that each
    example has two values associated with it: *x[1]* and *x[2]*. Now, we can use
    a supervised machine learning algorithm to learn a rule—the decision boundary
    represented as a dashed line—that can separate those two classes and classify
    new data into each of those two categories given its *x[1]* and *x[2]* values:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示说明了二分类任务的概念，给定30个训练样本；其中15个训练样本被标记为负类（减号），另外15个训练样本被标记为正类（加号）。在这种情况下，我们的数据集是二维的，这意味着每个样本有两个值与之相关：*x[1]*
    和 *x[2]*。现在，我们可以使用监督学习算法来学习一个规则——决策边界，表示为虚线——它能够将这两个类别分开，并根据样本的 *x[1]* 和 *x[2]*
    值将新数据分类到这两个类别中：
- en: '![](img/B13208_01_03.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_03.png)'
- en: However, the set of class labels does not have to be of a binary nature. The
    predictive model learned by a supervised learning algorithm can assign any class
    label that was presented in the training dataset to a new, unlabeled instance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，类别标签集不必是二元的。监督学习算法学习到的预测模型可以将训练数据集中呈现的任何类别标签分配给新的、未标记的实例。
- en: A typical example of a **multiclass classification** task is handwritten character
    recognition. We can collect a training dataset that consists of multiple handwritten
    examples of each letter in the alphabet. The letters ("A," "B," "C," and so on)
    will represent the different unordered categories or class labels that we want
    to predict. Now, if a user provides a new handwritten character via an input device,
    our predictive model will be able to predict the correct letter in the alphabet
    with certain accuracy. However, our machine learning system will be unable to
    correctly recognize any of the digits between 0 and 9, for example, if they were
    not part of the training dataset.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**多类分类**任务的一个典型例子是手写字符识别。我们可以收集一个训练数据集，其中包含每个字母的多个手写示例。字母（“A”，“B”，“C”等）将代表我们想要预测的不同无序类别或标签。现在，如果用户通过输入设备提供一个新的手写字符，我们的预测模型将能够以一定的准确度预测字母表中的正确字母。然而，如果这些数字（例如0到9之间的数字）没有出现在训练数据集中，我们的机器学习系统将无法正确识别它们。'
- en: Regression for predicting continuous outcomes
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用于预测连续结果的回归
- en: We learned in the previous section that the task of classification is to assign
    categorical, unordered labels to instances. A second type of supervised learning
    is the prediction of continuous outcomes, which is also called **regression analysis**.
    In regression analysis, we are given a number of predictor (**explanatory**) variables
    and a continuous response variable (**outcome**), and we try to find a relationship
    between those variables that allows us to predict an outcome.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节中学到，分类任务是将类别化、无序的标签分配给实例。第二种类型的监督学习是预测连续的结果，也叫做**回归分析**。在回归分析中，我们给定若干个预测变量（**解释性变量**）和一个连续的响应变量（**结果**），然后尝试找到这些变量之间的关系，从而预测结果。
- en: Note that in the field of machine learning, the predictor variables are commonly
    called "features," and the response variables are usually referred to as "target
    variables." We will adopt these conventions throughout this book.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在机器学习领域，预测变量通常称为“特征”，响应变量通常被称为“目标变量”。本书中我们将采用这些约定。
- en: For example, let's assume that we are interested in predicting the math SAT
    scores of students. If there is a relationship between the time spent studying
    for the test and the final scores, we could use it as training data to learn a
    model that uses the study time to predict the test scores of future students who
    are planning to take this test.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有兴趣预测学生的数学SAT成绩。如果学习考试的时间与最终成绩之间存在某种关系，我们可以利用这段时间作为训练数据，学习一个模型，该模型使用学习时间来预测未来计划参加此考试的学生的成绩。
- en: '**Regression toward the mean**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归向均值**'
- en: The term "regression" was devised by Francis Galton in his article *Regression
    towards Mediocrity in Hereditary Stature* in 1886\. Galton described the biological
    phenomenon that the variance of height in a population does not increase over
    time.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: “回归”这个术语是由弗朗西斯·高尔顿在他1886年的文章《*回归到平庸的遗传身高*》中提出的。高尔顿描述了这样一个生物现象：一个种群的身高方差随着时间的推移不会增加。
- en: He observed that the height of parents is not passed on to their children, but
    instead, their children's height regresses toward the population mean.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 他观察到，父母的身高并没有遗传给孩子，而是孩子的身高会回归到种群的平均身高。
- en: 'The following figure illustrates the concept of linear regression. Given a
    feature variable, *x*, and a target variable, *y*, we fit a straight line to this
    data that minimizes the distance—most commonly the average squared distance—between
    the data points and the fitted line. We can now use the intercept and slope learned
    from this data to predict the target variable of new data:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 下图说明了线性回归的概念。给定一个特征变量 *x* 和目标变量 *y*，我们对这些数据拟合一条直线，使得数据点和拟合直线之间的距离——通常是平均平方距离——最小化。现在，我们可以利用从这些数据中学习到的截距和斜率来预测新数据的目标变量：
- en: '![](img/B13208_01_04.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_04.png)'
- en: Solving interactive problems with reinforcement learning
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用强化学习解决互动问题
- en: Another type of machine learning is **reinforcement learning**. In reinforcement
    learning, the goal is to develop a system (**agent**) that improves its performance
    based on interactions with the environment. Since the information about the current
    state of the environment typically also includes a so-called **reward signal**,
    we can think of reinforcement learning as a field related to supervised learning.
    However, in reinforcement learning, this feedback is not the correct ground truth
    label or value, but a measure of how well the action was measured by a reward
    function. Through its interaction with the environment, an agent can then use
    reinforcement learning to learn a series of actions that maximizes this reward
    via an exploratory trial-and-error approach or deliberative planning.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种机器学习类型是**强化学习**。在强化学习中，目标是开发一个系统（**智能体**），该系统基于与环境的互动不断提升其表现。由于关于环境当前状态的信息通常也包括所谓的**奖励信号**，我们可以将强化学习视为与监督学习相关的领域。然而，在强化学习中，这种反馈不是正确的真实标签或值，而是通过奖励函数衡量行动效果的指标。通过与环境的互动，智能体可以使用强化学习来学习一系列行动，这些行动通过探索性的试错法或深思熟虑的规划来最大化奖励。
- en: 'A popular example of reinforcement learning is a chess engine. Here, the agent
    decides upon a series of moves depending on the state of the board (the environment),
    and the reward can be defined as **win** or **lose** at the end of the game:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习的一个常见例子是国际象棋引擎。在这个例子中，智能体根据棋盘的状态（即环境）决定一系列的棋步，而奖励可以定义为游戏结束时的**胜利**或**失败**：
- en: '![](img/B13208_01_05.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_05.png)'
- en: There are many different subtypes of reinforcement learning. However, a general
    scheme is that the agent in reinforcement learning tries to maximize the reward
    through a series of interactions with the environment. Each state can be associated
    with a positive or negative reward, and a reward can be defined as accomplishing
    an overall goal, such as winning or losing a game of chess. For instance, in chess,
    the outcome of each move can be thought of as a different state of the environment.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习有许多不同的子类型。然而，一般的框架是，强化学习中的智能体试图通过与环境的一系列互动来最大化奖励。每个状态都可以与正向或负向奖励相关联，奖励可以定义为实现一个整体目标，比如赢得或输掉一局国际象棋比赛。例如，在国际象棋中，每一步的结果可以看作是环境的一个不同状态。
- en: To explore the chess example further, let's think of visiting certain configurations
    on the chess board as being associated with states that will more likely lead
    to winning—for instance, removing an opponent's chess piece from the board or
    threatening the queen. Other positions, however, are associated with states that
    will more likely result in losing the game, such as losing a chess piece to the
    opponent in the following turn. Now, in the game of chess, the reward (either
    positive for winning or negative for losing the game) will not be given until
    the end of the game. In addition, the final reward will also depend on how the
    opponent plays. For example, the opponent may sacrifice the queen but eventually
    win the game.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步探讨国际象棋的例子，我们可以将访问棋盘上某些配置视为与更可能导致胜利的状态相关联——例如，移除对方的棋子或威胁对方的皇后。然而，其他位置则与更可能导致失败的状态相关联，比如在接下来的回合中失去棋子。现在，在国际象棋中，奖励（无论是赢得比赛的正奖励还是输掉比赛的负奖励）直到游戏结束时才会给出。此外，最终的奖励还将取决于对手的表现。例如，对手可能会牺牲皇后，但最终赢得比赛。
- en: Reinforcement learning is concerned with learning to choose a series of actions
    that maximizes the total reward, which could be earned either immediately after
    taking an action or via *delayed* feedback.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习关注的是学习选择一系列能够最大化总奖励的行动，这些奖励可能在采取行动后立即获得，或通过*延迟*反馈获得。
- en: Discovering hidden structures with unsupervised learning
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用无监督学习发现隐藏的结构
- en: In supervised learning, we know the right answer beforehand when we train a
    model, and in reinforcement learning, we define a measure of reward for particular
    actions carried out by the agent. In unsupervised learning, however, we are dealing
    with unlabeled data or data of unknown structure. Using unsupervised learning
    techniques, we are able to explore the structure of our data to extract meaningful
    information without the guidance of a known outcome variable or reward function.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，我们在训练模型时已经知道正确的答案；在强化学习中，我们为代理执行的特定动作定义了奖励度量。然而，在无监督学习中，我们处理的是无标签数据或结构未知的数据。通过使用无监督学习技术，我们能够探索数据的结构，从中提取有意义的信息，而不依赖于已知的结果变量或奖励函数。
- en: Finding subgroups with clustering
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用聚类找到子组
- en: '**Clustering** is an exploratory data analysis technique that allows us to
    organize a pile of information into meaningful subgroups (**clusters**) without
    having any prior knowledge of their group memberships. Each cluster that arises
    during the analysis defines a group of objects that share a certain degree of
    similarity but are more dissimilar to objects in other clusters, which is why
    clustering is also sometimes called **unsupervised classification**. Clustering
    is a great technique for structuring information and deriving meaningful relationships
    from data. For example, it allows marketers to discover customer groups based
    on their interests, in order to develop distinct marketing programs.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类**是一种探索性数据分析技术，它允许我们将一堆信息组织成有意义的子组（**簇**），而不需要事先了解它们的组别。分析过程中产生的每个簇都定义了一组共享某种程度相似性的对象，但与其他簇中的对象更为不同，这也是为什么聚类有时被称为**无监督分类**的原因。聚类是一种很好的结构化信息的技术，可以从数据中推导出有意义的关系。例如，它可以帮助市场营销人员根据客户的兴趣发现客户群体，从而制定不同的营销方案。'
- en: 'The following figure illustrates how clustering can be applied to organizing
    unlabeled data into three distinct groups based on the similarity of their features,
    *x[1]* and *x[2]*:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了如何将聚类应用于将无标签数据根据其特征的相似性（*x[1]* 和 *x[2]*）组织成三个不同的组：
- en: '![](img/B13208_01_06.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_06.png)'
- en: Dimensionality reduction for data compression
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据压缩的降维
- en: Another subfield of unsupervised learning is **dimensionality reduction**. Often,
    we are working with data of high dimensionality—each observation comes with a
    high number of measurements—that can present a challenge for limited storage space
    and the computational performance of machine learning algorithms. Unsupervised
    dimensionality reduction is a commonly used approach in feature preprocessing
    to remove noise from data, which can also degrade the predictive performance of
    certain algorithms, and compress the data onto a smaller dimensional subspace
    while retaining most of the relevant information.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习的另一个子领域是**降维**。我们常常处理的是高维数据——每个观察值都包含大量的测量值——这可能对有限的存储空间和机器学习算法的计算性能带来挑战。无监督降维是特征预处理中常用的一种方法，可以去除数据中的噪音，这些噪音可能会降低某些算法的预测性能，同时将数据压缩到一个较小的维度子空间，同时保留大部分相关信息。
- en: 'Sometimes, dimensionality reduction can also be useful for visualizing data;
    for example, a high-dimensional feature set can be projected onto one-, two-,
    or three-dimensional feature spaces in order to visualize it via 2D or 3D scatterplots
    or histograms. The following figure shows an example where nonlinear dimensionality
    reduction was applied to compress a 3D Swiss Roll onto a new 2D feature subspace:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，降维也可以用于数据可视化；例如，某些高维特征集可以被投影到一维、二维或三维特征空间中，以便通过二维或三维散点图或直方图进行可视化。下图展示了一个例子，其中应用了非线性降维技术，将一个三维的瑞士卷数据压缩到新的二维特征子空间：
- en: '![](img/B13208_01_07.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_07.png)'
- en: Introduction to the basic terminology and notations
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本术语和符号介绍
- en: Now that we have discussed the three broad categories of machine learning—supervised,
    unsupervised, and reinforcement learning—let's have a look at the basic terminology
    that we will be using throughout this book. The following subsection covers the
    common terms we will be using when referring to different aspects of a dataset,
    as well as the mathematical notation to communicate more precisely and efficiently.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了机器学习的三大类别——监督学习、无监督学习和强化学习——接下来让我们看一下本书中将使用的基本术语。以下小节介绍了我们在谈到数据集的不同方面时常用的术语，以及用于更精确和高效沟通的数学符号。
- en: As machine learning is a vast field and very interdisciplinary, you are guaranteed
    to encounter many different terms that refer to the same concepts sooner rather
    than later. The second subsection collects many of the most commonly used terms
    that are found in machine learning literature, which may be useful to you as a
    reference section when reading more diverse machine learning literature.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器学习是一个广泛且跨学科的领域，您很快就会遇到许多不同的术语，它们实际上指的是相同的概念。第二小节收集了机器学习文献中最常用的术语，这些术语在您阅读更多不同的机器学习文献时可能会作为参考部分对您有所帮助。
- en: Notation and conventions used in this book
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本书中使用的符号和约定
- en: 'The following table depicts an excerpt of the Iris dataset, which is a classic
    example in the field of machine learning. The Iris dataset contains the measurements
    of 150 Iris flowers from three different species—Setosa, Versicolor, and Virginica.
    Here, each flower example represents one row in our dataset, and the flower measurements
    in centimeters are stored as columns, which we also call the **features** of the
    dataset:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格展示了Iris数据集的一个摘录，这是机器学习领域的经典例子。Iris数据集包含了来自三种不同物种——Setosa、Versicolor和Virginica的150朵鸢尾花的测量数据。在这里，每个花卉示例代表数据集中的一行，花卉的测量值（以厘米为单位）存储为列，我们也称这些为数据集的**特征**：
- en: '![](img/B13208_01_08.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_08.png)'
- en: To keep the notation and implementation simple yet efficient, we will make use
    of some of the basics of linear algebra. In the following chapters, we will use
    a matrix and vector notation to refer to our data. We will follow the common convention
    to represent each example as a separate row in a feature matrix, **X**, where
    each feature is stored as a separate column.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持符号简洁而高效，我们将利用一些线性代数的基础知识。在接下来的章节中，我们将使用矩阵和向量的符号表示我们的数据。我们将遵循常用的约定，将每个示例表示为特征矩阵**X**中的一行，其中每个特征存储为一个单独的列。
- en: 'The Iris dataset, consisting of 150 examples and four features, can then be
    written as a ![](img/B13208_01_001.png) matrix, ![](img/B13208_01_002.png):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 由150个示例和四个特征组成的Iris数据集可以写成一个！[](img/B13208_01_001.png)矩阵，![](img/B13208_01_002.png)：
- en: '![](img/B13208_01_003.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_003.png)'
- en: '**Notational conventions**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**符号约定**'
- en: For the rest of this book, unless noted otherwise, we will use the superscript
    *i* to refer to the *i*th training example, and the subscript *j* to refer to
    the *j*th dimension of the training dataset.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的其余部分，除非另有说明，我们将使用上标*i*来表示第*i*个训练示例，使用下标*j*来表示训练数据集的第*j*维度。
- en: We will use lowercase, bold-face letters to refer to vectors ![](img/B13208_01_004.png)
    and uppercase, bold-face letters to refer to matrices ![](img/B13208_01_005.png).
    To refer to single elements in a vector or matrix, we will write the letters in
    italics (![](img/B13208_01_006.png) or ![](img/B13208_01_007.png) , respectively).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用小写粗体字母来表示向量！[](img/B13208_01_004.png)，大写粗体字母来表示矩阵！[](img/B13208_01_005.png)。若要表示向量或矩阵中的单个元素，我们将使用斜体字母（![](img/B13208_01_006.png)或![](img/B13208_01_007.png)，分别表示）。
- en: 'For example, ![](img/B13208_01_008.png) refers to the first dimension of flower
    example 150, the *sepal length*. Thus, each row in this feature matrix represents
    one flower instance and can be written as a four-dimensional row vector, ![](img/B13208_01_009.png):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，![](img/B13208_01_008.png)指的是花卉示例150的第一个维度，即*萼片长度*。因此，该特征矩阵中的每一行代表一个花卉实例，可以写成一个四维行向量，![](img/B13208_01_009.png)：
- en: '![](img/B13208_01_010.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_010.png)'
- en: 'And each feature dimension is a 150-dimensional column vector, ![](img/B13208_01_011.png).
    For example:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 每个特征维度是一个150维的列向量，![](img/B13208_01_011.png)。例如：
- en: '![](img/B13208_01_012.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_012.png)'
- en: 'Similarly, we will store the target variables (here, class labels) as a 150-dimensional
    column vector:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们将目标变量（在这里是类标签）存储为一个150维的列向量：
- en: '![](img/B13208_01_013.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_01_013.png)'
- en: Machine learning terminology
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习术语
- en: 'Machine learning is a vast field and also very interdisciplinary as it brings
    together many scientists from other areas of research. As it happens, many terms
    and concepts have been rediscovered or redefined and may already be familiar to
    you but appear under different names. For your convenience, in the following list,
    you can find a selection of commonly used terms and their synonyms that you may
    find useful when reading this book and machine learning literature in general:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个广阔的领域，也非常跨学科，因为它将许多来自其他研究领域的科学家聚集在一起。事实上，许多术语和概念已经被重新发现或重新定义，可能对你来说已经很熟悉，但以不同的名称出现。为了方便你，在以下列表中，你可以找到一些常见术语及其同义词，在阅读本书和一般机器学习文献时可能会派上用场：
- en: 'Training example: A row in a table representing the dataset and synonymous
    with an observation, record, instance, or sample (in most contexts, sample refers
    to a collection of training examples).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练示例：表示数据集的表中的一行，与观察值、记录、实例或样本同义（在大多数情况下，样本指的是一组训练示例）。
- en: 'Training: Model fitting, for parametric models similar to parameter estimation.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练：模型拟合，对于类似于参数估计的参数化模型。
- en: 'Feature, abbrev. *x*: A column in a data table or data (design) matrix. Synonymous
    with predictor, variable, input, attribute, or covariate.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征，缩写为 *x*：数据表或数据（设计）矩阵中的一列。与预测变量、输入、属性或协变量同义。
- en: 'Target, abbrev. *y*: Synonymous with outcome, output, response variable, dependent
    variable, (class) label, and ground truth.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标，缩写为 *y*：与结果、输出、响应变量、因变量、（类别）标签和真实标签同义。
- en: 'Loss function: Often used synonymously with a *cost* function. Sometimes the
    loss function is also called an *error* function. In some literature, the term
    "loss" refers to the loss measured for a single data point, and the cost is a
    measurement that computes the loss (average or summed) over the entire dataset.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失函数：通常与 *成本* 函数同义。有时损失函数也称为 *错误* 函数。在某些文献中，“损失”一词指的是对单个数据点的损失，而成本是一个度量，它计算整个数据集上的损失（平均值或总和）。
- en: A roadmap for building machine learning systems
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建机器学习系统的路线图
- en: In previous sections, we discussed the basic concepts of machine learning and
    the three different types of learning. In this section, we will discuss the other
    important parts of a machine learning system accompanying the learning algorithm.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，我们讨论了机器学习的基本概念和三种不同的学习类型。在这一部分，我们将讨论机器学习系统中伴随学习算法的其他重要部分。
- en: 'The following diagram shows a typical workflow for using machine learning in
    predictive modeling, which we will discuss in the following subsections:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了在预测建模中使用机器学习的典型工作流程，我们将在接下来的子章节中讨论：
- en: '![B07030_01_09](img/B13208_01_09.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![B07030_01_09](img/B13208_01_09.png)'
- en: Preprocessing – getting data into shape
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理 – 使数据适配
- en: Let's begin with discussing the roadmap for building machine learning systems.
    Raw data rarely comes in the form and shape that is necessary for the optimal
    performance of a learning algorithm. Thus, the preprocessing of the data is one
    of the most crucial steps in any machine learning application.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从讨论构建机器学习系统的路线图开始。原始数据很少以适合学习算法最佳性能的形式和结构出现。因此，数据预处理是任何机器学习应用中最关键的步骤之一。
- en: If we take the Iris flower dataset from the previous section as an example,
    we can think of the raw data as a series of flower images from which we want to
    extract meaningful features. Useful features could be the color, hue, and intensity
    of the flowers, or the height, length, and width of the flowers.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以前面部分的鸢尾花数据集为例，我们可以将原始数据看作是一系列花卉图像，从中我们想要提取有意义的特征。有效的特征可能是花朵的颜色、色调和强度，或者花朵的高度、长度和宽度。
- en: Many machine learning algorithms also require that the selected features are
    on the same scale for optimal performance, which is often achieved by transforming
    the features in the range [0, 1] or a standard normal distribution with zero mean
    and unit variance, as we will see in later chapters.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习算法还要求所选特征在同一尺度上以实现最佳性能，这通常通过将特征转换到[0, 1]范围内或标准正态分布（均值为零，方差为单位）的方式来实现，正如我们将在后续章节中看到的那样。
- en: Some of the selected features may be highly correlated and therefore redundant
    to a certain degree. In those cases, dimensionality reduction techniques are useful
    for compressing the features onto a lower dimensional subspace. Reducing the dimensionality
    of our feature space has the advantage that less storage space is required, and
    the learning algorithm can run much faster. In certain cases, dimensionality reduction
    can also improve the predictive performance of a model if the dataset contains
    a large number of irrelevant features (or noise); that is, if the dataset has
    a low signal-to-noise ratio.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一些选择的特征可能高度相关，因此在某种程度上是冗余的。在这种情况下，降维技术对于将特征压缩到较低维度的子空间是有用的。减少特征空间的维度具有以下优点：所需的存储空间较少，且学习算法可以运行得更快。在某些情况下，如果数据集包含大量无关特征（或噪声），降维还可以改善模型的预测性能；也就是说，如果数据集的信噪比低。
- en: To determine whether our machine learning algorithm not only performs well on
    the training dataset but also generalizes well to new data, we also want to randomly
    divide the dataset into a separate training and test dataset. We use the training
    dataset to train and optimize our machine learning model, while we keep the test
    dataset until the very end to evaluate the final model.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定我们的机器学习算法不仅在训练数据集上表现良好，而且能够很好地泛化到新数据，我们还需要随机地将数据集划分为单独的训练集和测试集。我们使用训练集来训练和优化我们的机器学习模型，而在最后，我们保留测试集以评估最终的模型。
- en: Training and selecting a predictive model
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练和选择预测模型
- en: As you will see in later chapters, many different machine learning algorithms
    have been developed to solve different problem tasks. An important point that
    can be summarized from David Wolpert's famous *No free lunch theorems* is that
    we can't get learning "for free" (*The Lack of A Priori Distinctions Between Learning
    Algorithms*, D.H. Wolpert, 1996; *No free lunch theorems for optimization*, D.H.
    Wolpert and W.G. Macready, 1997). We can relate this concept to the popular saying,
    "*I suppose it is tempting, if the only tool you have is a hammer, to treat everything
    as if it were a nail"* (Abraham Maslow, 1966). For example, each classification
    algorithm has its inherent biases, and no single classification model enjoys superiority
    if we don't make any assumptions about the task. In practice, it is therefore
    essential to compare at least a handful of different algorithms in order to train
    and select the best performing model. But before we can compare different models,
    we first have to decide upon a metric to measure performance. One commonly used
    metric is classification accuracy, which is defined as the proportion of correctly
    classified instances.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你将在后续章节中看到的那样，已经开发了许多不同的机器学习算法来解决不同的问题任务。从David Wolpert著名的*无免费午餐定理*中可以总结出一个重要的观点，那就是我们不能“免费”地进行学习（*学习算法之间缺乏先验区别*，D.H.
    Wolpert，1996；*优化的无免费午餐定理*，D.H. Wolpert和W.G. Macready，1997）。我们可以将这个概念与流行的说法相联系，"我想，如果你只有一把锤子，所有的东西都会看起来像钉子"（Abraham
    Maslow，1966）。例如，每个分类算法都有其固有的偏见，如果我们不对任务做任何假设，则没有一个单一的分类模型能在所有情况下占据优势。因此，在实践中，比较至少几个不同的算法以训练并选择表现最佳的模型是至关重要的。但在我们能够比较不同模型之前，首先必须决定一个衡量性能的标准。一种常用的衡量标准是分类准确率，它被定义为正确分类实例的比例。
- en: 'One legitimate question to ask is this: *how do we know which model performs
    well on the final test dataset and real-world data if we don''t use this test
    dataset for the model selection, but keep it for the final model evaluation?*
    In order to address the issue embedded in this question, different techniques
    summarized as "cross-validation" can be used. In cross-validation, we further
    divide a dataset into training and validation subsets in order to estimate the
    generalization performance of the model. Finally, we also cannot expect that the
    default parameters of the different learning algorithms provided by software libraries
    are optimal for our specific problem task. Therefore, we will make frequent use
    of hyperparameter optimization techniques that help us to fine-tune the performance
    of our model in later chapters.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一个合理的问题是：*如果我们不使用测试数据集来选择模型，而是将其保留用于最终的模型评估，那么我们如何知道哪个模型在最终测试数据集和真实世界数据上表现良好？*
    为了解决这个问题，可以使用被总结为“交叉验证”的不同技术。在交叉验证中，我们将数据集进一步划分为训练集和验证集，以便估计模型的泛化性能。最后，我们也不能期望软件库提供的不同学习算法的默认参数对我们的特定问题任务是最优的。因此，我们将在后续章节中频繁使用超参数优化技术，以帮助我们微调模型的性能。
- en: We can think of those hyperparameters as parameters that are not learned from
    the data but represent the knobs of a model that we can turn to improve its performance.
    This will become much clearer in later chapters when we see actual examples.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以把这些超参数看作是模型的参数，它们不是从数据中学习到的，而是代表模型的控制按钮，我们可以调节它们来提高模型的性能。在后面的章节中，我们会通过实际的例子使这一点变得更加清晰。
- en: Evaluating models and predicting unseen data instances
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估模型并预测未见过的数据实例
- en: After we have selected a model that has been fitted on the training dataset,
    we can use the test dataset to estimate how well it performs on this unseen data
    to estimate the so-called generalization error. If we are satisfied with its performance,
    we can now use this model to predict new, future data. It is important to note
    that the parameters for the previously mentioned procedures, such as feature scaling
    and dimensionality reduction, are solely obtained from the training dataset, and
    the same parameters are later reapplied to transform the test dataset, as well
    as any new data instances—the performance measured on the test data may be overly
    optimistic otherwise.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们选择了一个已经在训练数据集上拟合的模型后，可以使用测试数据集来估计它在这些未见过的数据上的表现，从而估算所谓的泛化误差。如果我们对它的表现感到满意，我们就可以使用这个模型来预测新的未来数据。需要注意的是，之前提到的程序步骤中的参数（如特征缩放和降维）完全来源于训练数据集，并且这些相同的参数稍后会被重新应用于转换测试数据集以及任何新的数据实例——否则，在测试数据上的表现可能会过于乐观。
- en: Using Python for machine learning
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 进行机器学习
- en: Python is one of the most popular programming languages for data science and
    thanks to its very active developer and open source community, a large number
    of useful libraries for scientific computing and machine learning have been developed.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Python 是数据科学中最受欢迎的编程语言之一，得益于其非常活跃的开发者和开源社区，已经开发出大量用于科学计算和机器学习的有用库。
- en: Although the performance of interpreted languages, such as Python, for computation-intensive
    tasks is inferior to lower-level programming languages, extension libraries such
    as NumPy and SciPy have been developed that build upon lower-layer Fortran and
    C implementations for fast vectorized operations on multidimensional arrays.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管解释型语言（如 Python）在计算密集型任务中的性能不如低级编程语言，但已经开发出如 NumPy 和 SciPy 等扩展库，这些库建立在低层次的
    Fortran 和 C 实现之上，以便在多维数组上进行快速的向量化操作。
- en: For machine learning programming tasks, we will mostly refer to the scikit-learn
    library, which is currently one of the most popular and accessible open source
    machine learning libraries. In the later chapters, when we focus on a subfield
    of machine learning called deep learning, we will use the latest version of the
    TensorFlow library, which specializes in training so-called deep neural network
    models very efficiently by utilizing graphics cards.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习编程任务，我们主要会参考 scikit-learn 库，这是目前最流行和易于访问的开源机器学习库之一。在后面的章节中，当我们专注于机器学习的一个子领域——深度学习时，我们将使用最新版本的
    TensorFlow 库，它通过利用图形处理单元（GPU）非常高效地训练所谓的深度神经网络模型。
- en: Installing Python and packages from the Python Package Index
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 Python 包索引安装 Python 和软件包
- en: 'Python is available for all three major operating systems—Microsoft Windows,
    macOS, and Linux—and the installer, as well as the documentation, can be downloaded
    from the official Python website: [https://www.python.org](https://www.python.org).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Python 可用于所有三大主流操作系统——Microsoft Windows、macOS 和 Linux——安装程序及文档可以从官方 Python 网站下载：[https://www.python.org](https://www.python.org)。
- en: This book is written for Python version 3.7 or higher, and it is recommended
    that you use the most recent version of Python 3 that is currently available.
    Some of the code may also be compatible with Python 2.7, but as the official support
    for Python 2.7 ends in 2019, and the majority of open source libraries have already
    stopped supporting Python 2.7 ([https://python3statement.org](https://python3statement.org)),
    we strongly advise that you use Python 3.7 or newer.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 本书适用于 Python 3.7 或更高版本，建议使用当前可用的最新 Python 3 版本。部分代码也可能与 Python 2.7 兼容，但由于 Python
    2.7 的官方支持已于 2019 年结束，并且大多数开源库已停止对 Python 2.7 的支持（[https://python3statement.org](https://python3statement.org)），我们强烈建议使用
    Python 3.7 或更新版本。
- en: The additional packages that we will be using throughout this book can be installed
    via the `pip` installer program, which has been part of the Python Standard Library
    since Python 3.3\. More information about `pip` can be found at [https://docs.python.org/3/installing/index.html](https://docs.python.org/3/installing/index.html).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用的额外包可以通过 `pip` 安装程序进行安装，`pip` 自 Python 3.3 起成为 Python 标准库的一部分。更多关于 `pip`
    的信息可以在 [https://docs.python.org/3/installing/index.html](https://docs.python.org/3/installing/index.html)
    找到。
- en: 'After we have successfully installed Python, we can execute pip from the terminal
    to install additional Python packages:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 成功安装 Python 后，我们可以从终端执行 pip 来安装额外的 Python 包：
- en: '[PRE0]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Already installed packages can be updated via the `--upgrade` flag:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 已安装的包可以通过 `--upgrade` 标志进行更新：
- en: '[PRE1]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using the Anaconda Python distribution and package manager
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Anaconda Python 发行版和包管理器
- en: A highly recommended alternative Python distribution for scientific computing
    is Anaconda by Continuum Analytics. Anaconda is a free—including commercial use—enterprise-ready
    Python distribution that bundles all the essential Python packages for data science,
    math, and engineering into one user-friendly, cross-platform distribution. The
    Anaconda installer can be downloaded at [https://docs.anaconda.com/anaconda/install/](https://docs.anaconda.com/anaconda/install/),
    and an Anaconda quick start guide is available at [https://docs.anaconda.com/anaconda/user-guide/getting-started/](https://docs.anaconda.com/anaconda/user-guide/getting-started/).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐的科学计算 Python 发行版是 Continuum Analytics 提供的 Anaconda。Anaconda 是一个免费（包括商业用途）且企业级的
    Python 发行版，集合了数据科学、数学和工程所需的所有核心 Python 包，且跨平台用户友好。Anaconda 安装程序可以从 [https://docs.anaconda.com/anaconda/install/](https://docs.anaconda.com/anaconda/install/)
    下载，快速入门指南可以在 [https://docs.anaconda.com/anaconda/user-guide/getting-started/](https://docs.anaconda.com/anaconda/user-guide/getting-started/)
    获取。
- en: 'After successfully installing Anaconda, we can install new Python packages
    using the following command:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 成功安装 Anaconda 后，我们可以使用以下命令安装新的 Python 包：
- en: '[PRE2]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Existing packages can be updated using the following command:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令更新现有的包：
- en: '[PRE3]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Packages for scientific computing, data science, and machine learning
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 科学计算、数据科学和机器学习的相关包
- en: Throughout this book, we will mainly use NumPy's multidimensional arrays to
    store and manipulate data. Occasionally, we will make use of pandas, which is
    a library built on top of NumPy that provides additional higher-level data manipulation
    tools that make working with tabular data even more convenient. To augment your
    learning experience and visualize quantitative data, which is often extremely
    useful to make sense of it, we will use the very customizable Matplotlib library.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们主要使用 NumPy 的多维数组来存储和处理数据。偶尔，我们会使用 pandas，这是一个基于 NumPy 构建的库，提供了更多高级的数据处理工具，使得处理表格数据变得更加方便。为了增强学习体验并可视化定量数据，我们将使用高度可定制的
    Matplotlib 库，这对于理解数据非常有帮助。
- en: 'The version numbers of the major Python packages that were used to write this
    book are mentioned in the following list. Please make sure that the version numbers
    of your installed packages are equal to, or greater than, these version numbers
    to ensure that the code examples run correctly:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用的主要 Python 包的版本号列在下方。请确保安装的包的版本号与这些版本号相等或更高，以确保代码示例能够正确运行：
- en: NumPy 1.17.4
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy 1.17.4
- en: SciPy 1.3.1
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SciPy 1.3.1
- en: scikit-learn 0.22.0
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn 0.22.0
- en: Matplotlib 3.1.0
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib 3.1.0
- en: pandas 0.25.3
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas 0.25.3
- en: Summary
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we explored machine learning at a very high level and familiarized
    ourselves with the big picture and major concepts that we are going to explore
    in the following chapters in more detail. We learned that supervised learning
    is composed of two important subfields: classification and regression. While classification
    models allow us to categorize objects into known classes, we can use regression
    analysis to predict the continuous outcomes of target variables. Unsupervised
    learning not only offers useful techniques for discovering structures in unlabeled
    data, but it can also be useful for data compression in feature preprocessing
    steps.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们以非常高的层次探讨了机器学习，并熟悉了我们将在接下来的章节中更详细探索的大致框架和主要概念。我们了解到，监督学习由两个重要的子领域组成：分类和回归。分类模型使我们能够将对象分类到已知类别中，而回归分析则帮助我们预测目标变量的连续结果。无监督学习不仅提供了有助于发现无标签数据结构的技术，还可以在特征预处理步骤中用于数据压缩。
- en: We briefly went over the typical roadmap for applying machine learning to problem
    tasks, which we will use as a foundation for deeper discussions and hands-on examples
    in the following chapters. Finally, we set up our Python environment and installed
    and updated the required packages to get ready to see machine learning in action.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简要地回顾了将机器学习应用于问题任务的典型路线图，接下来我们将以此为基础，在后续章节中进行更深入的讨论和实践示例。最后，我们设置了Python环境，并安装和更新了所需的包，为实际操作机器学习做好准备。
- en: Later in this book, in addition to machine learning itself, we will introduce
    different techniques to preprocess a dataset, which will help you to get the best
    performance out of different machine learning algorithms. While we will cover
    classification algorithms quite extensively throughout the book, we will also
    explore different techniques for regression analysis and clustering.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的后续内容中，除了机器学习本身，我们还将介绍不同的数据集预处理技术，这将帮助你从不同的机器学习算法中获得最佳性能。尽管我们将贯穿全书详细讲解分类算法，我们也会探讨回归分析和聚类的不同技术。
- en: We have an exciting journey ahead, covering many powerful techniques in the
    vast field of machine learning. However, we will approach machine learning one
    step at a time, building upon our knowledge gradually throughout the chapters
    of this book. In the following chapter, we will start this journey by implementing
    one of the earliest machine learning algorithms for classification, which will
    prepare us for *Chapter 3*, *A Tour of Machine Learning Classifiers Using scikit-learn*,
    where we will cover more advanced machine learning algorithms using the scikit-learn
    open source machine learning library.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将开始一段令人兴奋的旅程，涵盖机器学习广阔领域中的许多强大技术。然而，我们将一步步地接触机器学习，在本书的各个章节中逐步构建我们的知识。在接下来的章节中，我们将通过实现最早的分类机器学习算法之一，开启这段旅程，为*第3章*，*使用scikit-learn探索机器学习分类器*做准备，届时我们将使用scikit-learn开源机器学习库，介绍更多高级的机器学习算法。
