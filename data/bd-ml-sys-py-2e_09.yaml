- en: Chapter 9. Classification – Music Genre Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章 分类 – 音乐流派分类
- en: So far, we have had the luxury that every training data instance could easily
    be described by a vector of feature values. In the Iris dataset, for example,
    the flowers are represented by vectors containing values for length and width
    of certain aspects of a flower. In the text-based examples, we could transform
    the text into a bag of word representations and manually craft our own features
    that captured certain aspects of the texts.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的训练数据实例每个都可以通过一组特征值向量轻松描述。例如，在Iris数据集中，花卉是通过包含花的某些部分长度和宽度值的向量表示的。在基于文本的示例中，我们可以将文本转化为词袋表示，并手动创建自己的特征来捕捉文本中的某些方面。
- en: It will be different in this chapter, when we try to classify songs by their
    genre. Or, how would we, for instance, represent a three-minute-long song? Should
    we take the individual bits of its MP3 representation? Probably not, since treating
    it like a text and creating something like a "bag of sound bites" would certainly
    be way too complex. Somehow, we will, nevertheless, have to convert a song into
    a series of values that describe it sufficiently.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，当我们尝试根据流派对歌曲进行分类时，情况将有所不同。例如，我们应该如何表示一首三分钟的歌曲呢？我们是否应该取MP3表示中的每个单独的比特？可能不是，因为将其视为文本并创建类似于“声音片段袋”的东西肯定会太复杂。然而，我们仍然必须将一首歌曲转换为一系列足够描述它的值。
- en: Sketching our roadmap
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制我们的路线图
- en: This chapter will show how we can come up with a decent classifier in a domain
    that is outside our comfort zone. For one, we will have to use sound-based features,
    which are much more complex than the text-based ones we have used before. And
    then we will learn how to deal with multiple classes, whereas we have only encountered
    binary classification problems up to now. In addition, we will get to know new
    ways of measuring classification performance.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将展示如何在一个超出我们舒适区的领域中构建一个合理的分类器。首先，我们将不得不使用基于声音的特征，这比我们之前使用的基于文本的特征复杂得多。接着，我们将学习如何处理多分类问题，而目前为止我们只遇到过二分类问题。此外，我们还将了解一些新的分类性能衡量方法。
- en: Let us assume a scenario in which, for some reason, we find a bunch of randomly
    named MP3 files on our hard disk, which are assumed to contain music. Our task
    is to sort them according to the music genre into different folders such as jazz,
    classical, country, pop, rock, and metal.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们遇到一个场景，在某种原因下，我们的硬盘中出现了一堆随机命名的MP3文件，假设这些文件包含音乐。我们的任务是根据音乐流派将它们分类到不同的文件夹中，比如爵士、古典、乡村、流行、摇滚和金属。
- en: Fetching the music data
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取音乐数据
- en: 'We will use the GTZAN dataset, which is frequently used to benchmark music
    genre classification tasks. It is organized into 10 distinct genres, of which
    we will use only 6 for the sake of simplicity: Classical, Jazz, Country, Pop,
    Rock, and Metal. The dataset contains the first 30 seconds of 100 songs per genre.
    We can download the dataset from [http://opihi.cs.uvic.ca/sound/genres.tar.gz](http://opihi.cs.uvic.ca/sound/genres.tar.gz).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用GTZAN数据集，该数据集常用于基准测试音乐流派分类任务。它包含10个不同的流派，我们为了简单起见，只使用其中的6个：古典音乐、爵士乐、乡村音乐、流行音乐、摇滚乐和金属乐。该数据集包含每个流派100首歌曲的前30秒。我们可以从[http://opihi.cs.uvic.ca/sound/genres.tar.gz](http://opihi.cs.uvic.ca/sound/genres.tar.gz)下载数据集。
- en: Tip
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: The tracks are recorded at 22,050 Hz (22,050 readings per second) mono in the
    WAV format.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这些音轨以22,050赫兹（每秒22,050次采样）单声道的WAV格式录制。
- en: Converting into a WAV format
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换为WAV格式
- en: Sure enough, if we would want to test our classifier later on our private MP3
    collection, we would not be able to extract much meaning. This is because MP3
    is a lossy music compression format that cuts out parts that the human ear cannot
    perceive. This is nice for storing because with MP3 you can fit 10 times as many
    songs on your device. For our endeavor, however, it is not so nice. For classification,
    we will have an easier game with WAV files, because they can be directly read
    by the `scipy.io.wavfile` package. We would, therefore, have to convert our MP3
    files in case we want to use them with our classifier.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，如果我们以后想要在私人MP3收藏中测试我们的分类器，我们可能无法提取太多有意义的信息。这是因为MP3是一种有损的音乐压缩格式，它会去除人耳无法感知的部分。这种格式对存储非常友好，因为使用MP3，你可以在设备上存储更多的歌曲。但对于我们的任务来说，这就不太合适了。为了分类，我们使用WAV文件会更简单一些，因为它们可以被`scipy.io.wavfile`包直接读取。因此，如果我们希望使用分类器处理MP3文件，我们就必须将它们转换成WAV格式。
- en: Tip
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: In case you don't have a conversion tool nearby, you might want to check out
    SoX at [http://sox.sourceforge.net](http://sox.sourceforge.net). It claims to
    be the Swiss Army Knife of sound processing, and we agree with this bold claim.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你附近没有转换工具，你可以查看 [http://sox.sourceforge.net](http://sox.sourceforge.net)上的
    SoX。它号称是声音处理的瑞士军刀，我们也同意这个**大胆的**说法。
- en: 'One advantage of having all our music files in the WAV format is that it is
    directly readable by the SciPy toolkit:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有音乐文件保存为WAV格式的一个优点是，SciPy工具包可以直接读取它：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`X` now contains the samples and `sample_rate` is the rate at which they were
    taken. Let us use that information to peek into some music files to get a first
    impression of what the data looks like.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`X`现在包含了样本，而`sample_rate`是它们被采样的速率。让我们利用这些信息，快速查看一些音乐文件，初步了解数据的样子。'
- en: Looking at music
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看音乐
- en: A very convenient way to get a quick impression of what the songs of the diverse
    genres "look" like is to draw a spectrogram for a set of songs of a genre. A spectrogram
    is a visual representation of the frequencies that occur in a song. It shows the
    intensity for the frequencies at the *y* axis in the specified time intervals
    at the *x* axis. That is, the darker the color, the stronger the frequency is
    in the particular time window of the song.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 获取不同风格歌曲“外观”的一种非常方便的方法是为一个风格的歌曲集绘制频谱图。频谱图是歌曲中频率的可视化表示。它在*y*轴上显示频率的强度，在*x*轴上显示特定时间间隔的强度。也就是说，颜色越深，某一时间窗口内该频率的强度越大。
- en: 'Matplotlib provides the convenient function `specgram()` that performs most
    of the under-the-hood calculation and plotting for us:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Matplotlib 提供了一个方便的函数`specgram()`，它为我们执行了大部分底层计算和绘图工作：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The WAV file we just read in was sampled at a rate of 22,050 Hz and contains
    661,794 samples.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚读取的WAV文件的采样率为22,050 Hz，包含661,794个样本。
- en: 'If we now plot the spectrogram for these first 30 seconds for diverse WAV files,
    we can see that there are commonalities between songs of the same genre, as shown
    in the following image:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在为这些前30秒的不同WAV文件绘制频谱图，我们可以看到同一类型歌曲之间的共性，如下图所示：
- en: '![Looking at music](img/2772OS_09_01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![Looking at music](img/2772OS_09_01.jpg)'
- en: Just glancing at the image, we immediately see the difference in the spectrum
    between, for example, metal and classical songs. While metal songs have high intensity
    over most of the frequency spectrum all the time (they're energetic!), classical
    songs show a more diverse pattern over time.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 仅从图像中，我们立刻能看出金属和古典歌曲在频谱上的差异。例如，金属歌曲在大部分频率范围内始终具有较高的强度（它们很有活力！），而古典歌曲则在时间上展示出更为多样化的模式。
- en: It should be possible to train a classifier that discriminates at least between
    Metal and Classical songs with high enough accuracy. Other genre pairs like Country
    and Rock could pose a bigger challenge, though. This looks like a real challenge
    to us, since we need to discriminate not only between two classes, but between
    six. We need to be able to discriminate between all of them reasonably well.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 应该可以训练一个分类器，以足够高的准确率区分至少金属与古典歌曲。然而，像乡村与摇滚这种其他音乐风格对比可能会更具挑战性。这对我们来说看起来像是一个真正的挑战，因为我们不仅需要区分两类，还要区分六类。我们需要能够合理地区分所有这些类别。
- en: Decomposing music into sine wave components
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将音乐分解成正弦波分量
- en: Our plan is to extract individual frequency intensities from the raw sample
    readings (stored in `X` earlier) and feed them into a classifier. These frequency
    intensities can be extracted by applying the so-called **fast Fourier transform**
    (**FFT**). As the theory behind FFT is outside the scope of this chapter, let
    us just look at an example to get an intuition of what it accomplishes. Later
    on, we will treat it as a black box feature extractor.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的计划是从原始样本数据（之前存储在`X`中的）中提取各个频率强度，并将它们输入分类器。这些频率强度可以通过应用所谓的**快速傅里叶变换**（**FFT**）来提取。由于傅里叶变换的理论超出了本章的范围，我们只看一个例子，直观地理解它的作用。稍后，我们将把它作为一个黑箱特征提取器。
- en: 'For example, let us generate two WAV files, `sine_a.wav` and `sine_b.wav`,
    that contain the sound of 400 Hz and 3,000 Hz sine waves respectively. The aforementioned
    "Swiss Army Knife", SoX, is one way to achieve this:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以生成两个WAV文件，`sine_a.wav`和`sine_b.wav`，它们分别包含400 Hz和3,000 Hz的正弦波声音。前面提到的“瑞士军刀”SoX，就是实现这一目标的一种方法：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the following charts, we have plotted their first 0.008 seconds. Below we
    can see the FFT of the sine waves. Not surprisingly, we see a spike at 400 Hz
    and 3,000 Hz below the corresponding sine waves.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的图表中，我们绘制了它们的前0.008秒。下面我们可以看到正弦波的FFT。毫不奇怪，我们在对应的正弦波下看到400 Hz和3,000 Hz的尖峰。
- en: 'Now, let us mix them both, giving the 400 Hz sound half the volume of the 3,000
    Hz one:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将两者混合，将400 Hz的声音音量设置为3,000 Hz的音量的一半：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We see two spikes in the FFT plot of the combined sound, of which the 3,000
    Hz spike is almost double the size of the 400 Hz.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在合成声音的FFT图中看到两个尖峰，其中3,000 Hz的尖峰几乎是400 Hz的两倍大小。
- en: '![Decomposing music into sine wave components](img/2772OS_09_02.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![将音乐分解为正弦波组件](img/2772OS_09_02.jpg)'
- en: 'For real music, we quickly see that the FFT doesn''t look as beautiful as in
    the preceding toy example:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于真实的音乐，我们很快发现FFT不像前面的玩具示例那样漂亮：
- en: '![Decomposing music into sine wave components](img/2772OS_09_03.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![将音乐分解为正弦波组件](img/2772OS_09_03.jpg)'
- en: Using FFT to build our first classifier
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用FFT构建我们的第一个分类器
- en: Nevertheless, we can now create some kind of musical fingerprint of a song using
    FFT. If we do that for a couple of songs and manually assign their corresponding
    genres as labels, we have the training data that we can feed into our first classifier.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们现在可以使用FFT创建歌曲的某种音乐指纹。如果我们对几首歌曲这样做，并手动分配相应的音乐类型标签，我们就得到了可以输入到我们第一个分类器的训练数据。
- en: Increasing experimentation agility
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提高实验灵活性
- en: Before we dive into the classifier training, let us first spend some thoughts
    on experimentation agility. Although we have the word "fast" in FFT, it is much
    slower than the creation of the features in our text-based chapters. And because
    we are still in an experimentation phase, we might want to think about how we
    could speed up the whole feature creation process.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入分类器训练之前，让我们先思考一下实验的灵活性。尽管FFT中有“快”这个词，但它比我们在基于文本的章节中创建特征的速度要慢得多。而且由于我们仍处于实验阶段，我们可能想考虑如何加速整个特征创建过程。
- en: Of course, the creation of the FFT per file will be the same each time we are
    running the classifier. We could, therefore, cache it and read the cached FFT
    representation instead of the complete WAV file. We do this with the `create_fft()`
    function, which, in turn, uses `scipy.fft()` to create the FFT. For the sake of
    simplicity (and speed!), let us fix the number of FFT components to the first
    1,000 in this example. With our current knowledge, we do not know whether these
    are the most important ones with regard to music genre classification—only that
    they show the highest intensities in the preceding FFT example. If we would later
    want to use more or fewer FFT components, we would of course have to recreate
    the FFT representations for each sound file.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，每次运行分类器时，创建每个文件的FFT都会是相同的。因此，我们可以缓存它，并读取缓存的FFT表示，而不是完整的WAV文件。我们通过`create_fft()`函数来实现这一点，后者又使用`scipy.fft()`来创建FFT。为了简单起见（以及提高速度！），我们在这个示例中将FFT组件的数量固定为前1,000个。根据我们当前的知识，我们不知道这些是否是与音乐类型分类最相关的组件——只知道它们在前面的FFT示例中显示了最高的强度。如果以后我们想使用更多或更少的FFT组件，当然需要为每个音频文件重新创建FFT表示。
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We save the data using NumPy's `save()` function, which always appends `.npy`
    to the filename. We only have to do this once for every WAV file needed for training
    or predicting.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用NumPy的`save()`函数保存数据，该函数总是将`.npy`附加到文件名。每个WAV文件只需为训练或预测做一次此操作。
- en: 'The corresponding FFT reading function is `read_fft()`:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对应的FFT读取函数是`read_fft()`：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In our scrambled music directory, we expect the following music genres:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的音乐目录中，我们预期以下音乐类型：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Training the classifier
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练分类器
- en: Let us use the logistic regression classifier, which has already served us well
    in the [Chapter 6](ch06.html "Chapter 6. Classification II – Sentiment Analysis"),
    *Classification II - Sentiment Analysis*. The added difficulty is that we are
    now faced with a multiclass classification problem, whereas up to now we had to
    discriminate only between two classes.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用逻辑回归分类器，它已经在[第六章](ch06.html "第六章 分类 II - 情感分析")中为我们提供了很好的效果，*分类 II - 情感分析*。增加的难度是，我们现在面临的是一个多类分类问题，而之前我们只需要区分两类。
- en: Just to mention one aspect that is surprising is the evaluation of accuracy
    rates when first switching from binary to multiclass classification. In binary
    classification problems, we have learned that an accuracy of 50 percent is the
    worst case, as it could have been achieved by mere random guessing. In multiclass
    settings, 50 percent can already be very good. With our six genres, for instance,
    random guessing would result in only 16.7 percent (equal class sizes assumed).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 需要提到的一个令人惊讶的方面是，从二分类问题切换到多分类问题时准确率的评估。在二分类问题中，我们已经了解到50%的准确率是最差的情况，因为这个结果仅仅是通过随机猜测就能达到的。而在多分类设置下，50%的准确率可能已经很不错了。例如，在我们的六个类别中，随机猜测的结果大约只有16.7%的准确率（假设类别大小相同）。
- en: Using a confusion matrix to measure accuracy in multiclass problems
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用混淆矩阵来衡量多类问题中的准确性
- en: 'With multiclass problems, we should not only be interested in how well we manage
    to correctly classify the genres. In addition, we should also look into which
    genres we actually confuse with each other. This can be done with the so-called
    confusion matrix, as shown in the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在多类问题中，我们不仅要关注我们能多好地正确分类不同的类型。此外，我们还应该注意哪些类别之间我们存在混淆。这可以通过所谓的混淆矩阵来实现，如下所示：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This prints the distribution of labels that the classifier predicted for the
    test set for every genre. The diagonal represents the correct classifications.
    Since we have six genres, we have a six-by-six matrix. The first row in the matrix
    says that for 31 Classical songs (sum of first row), it predicted 26 to belong
    to the genre Classical, 1 to be a Jazz song, 2 to belong to the Country genre,
    and 2 to be Metal songs. The diagonal shows the correct classifications. In the
    first row, we see that out of (26+1+2+2)=31 songs, 26 have been correctly classified
    as classical and 5 were misclassifications. This is actually not that bad. The
    second row is more sobering: only 7 out of 24 Jazz songs have been correctly classified—that
    is, only 29 percent.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 该图展示了分类器对每个类别的测试集标签分布。对角线代表正确分类的结果。由于我们有六个类别，因此矩阵是六行六列。矩阵的第一行表示，对于31个古典音乐（第一行的总和），分类器预测了26个属于古典音乐，1个属于爵士音乐，2个属于乡村音乐，2个属于金属音乐。对角线显示了正确分类的结果。在第一行中，我们看到，在（26+1+2+2）=31首歌曲中，26首被正确分类为古典音乐，5首被误分类。实际上，这并不算太差。第二行则更为令人失望：在24首爵士歌曲中，只有7首被正确分类——也就是说，准确率只有29%。
- en: Of course, we follow the train/test split setup from the previous chapters,
    so that we actually have to record the confusion matrices per cross-validation
    fold. We have to average and normalize later on, so that we have a range between
    0 (total failure) and 1 (everything classified correctly).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们遵循前几章中的训练/测试集拆分设置，因此我们实际上需要记录每个交叉验证折中的混淆矩阵。之后，我们需要对其进行平均和归一化处理，以便将结果的范围控制在0（完全失败）和1（全部分类正确）之间。
- en: 'A graphical visualization is often much easier to read than NumPy arrays. The
    `matshow()` function of matplotlib is our friend:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图形化的可视化通常比NumPy数组更易于阅读。matplotlib的`matshow()`函数是我们的好朋友：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Tip
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: When you create a confusion matrix, be sure to choose a color map (the `cmap`
    parameter of `matshow()`) with an appropriate color ordering so that it is immediately
    visible what a lighter or darker color means. Especially discouraged for these
    kinds of graphs are rainbow color maps, such as matplotlib's default `jet` or
    even the `Paired` color map.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 创建混淆矩阵时，请确保选择一个适当的颜色映射（`matshow()`的`cmap`参数），使得颜色的深浅变化能够立即显现其含义。尤其不推荐使用这些类型的图表的彩虹色图，比如matplotlib的默认`jet`色图，甚至`Paired`色图。
- en: 'The final graph looks like the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的图表看起来如下所示：
- en: '![Using a confusion matrix to measure accuracy in multiclass problems](img/2772OS_09_04.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![使用混淆矩阵来衡量多类问题中的准确性](img/2772OS_09_04.jpg)'
- en: For a perfect classifier, we would have expected a diagonal of dark squares
    from the left-upper corner to the right lower one, and light colors for the remaining
    area. In the preceding graph, we immediately see that our FFT-based classifier
    is far away from being perfect. It only predicts Classical songs correctly (dark
    square). For Rock, for instance, it preferred the label Metal most of the time.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个完美的分类器，我们期望从左上角到右下角呈现一条深色的对角线，其他区域则为浅色。在之前的图表中，我们可以立即看到我们的基于FFT的分类器离完美还有很大距离。它只正确预测了古典音乐（深色方块）。例如，对于摇滚音乐，它大多数时间都将标签预测为金属音乐。
- en: Obviously, using FFT points in the right direction (the Classical genre was
    not that bad), but is not enough to get a decent classifier. Surely, we can play
    with the number of FFT components (fixed to 1,000). But before we dive into parameter
    tuning, we should do our research. There we find that FFT is indeed not a bad
    feature for genre classification—it is just not refined enough. Shortly, we will
    see how we can boost our classification performance by using a processed version
    of it.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，使用FFT点指向了正确的方向（古典音乐类别并不那么糟糕），但这还不足以得到一个不错的分类器。当然，我们可以调整FFT组件的数量（固定为1,000）。但是在深入调整参数之前，我们应该先进行一些研究。结果表明，FFT确实是一个不错的特征用于类别分类——只是它的精度还不够高。很快，我们将看到如何通过使用经过处理的FFT版本来提高分类性能。
- en: Before we do that, however, we will learn another method of measuring classification
    performance.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们进行这个分析之前，我们将学习另一种衡量分类性能的方法。
- en: An alternative way to measure classifier performance using receiver-operator
    characteristics
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用接收器操作特征（ROC）来衡量分类器性能的另一种方式
- en: We already learned that measuring accuracy is not enough to truly evaluate a
    classifier. Instead, we relied on **precision-recall** (**P/R**) curves to get
    a deeper understanding of how our classifiers perform.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解到，仅仅通过衡量准确率不足以真正评估一个分类器。相反，我们依赖于**精准率-召回率**（**P/R**）曲线来深入理解分类器的性能。
- en: There is a sister of P/R curves, called **receiver-operator-characteristics**
    (**ROC**), which measures similar aspects of the classifier's performance, but
    provides another view of the classification performance. The key difference is
    that P/R curves are more suitable for tasks where the positive class is much more
    interesting than the negative one, or where the number of positive examples is
    much less than the number of negative ones. Information retrieval and fraud detection
    are typical application areas. On the other hand, ROC curves provide a better
    picture on how well the classifier behaves in general.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: P/R曲线有一个姐妹曲线，叫做**接收器操作特征**（**ROC**），它衡量分类器性能的相似方面，但提供了另一种分类性能的视角。两者的关键区别在于，P/R曲线更适合于正类比负类更为重要，或者正类样本远少于负类样本的任务。信息检索和欺诈检测是典型的应用领域。另一方面，ROC曲线则更好地展示了分类器整体表现。
- en: 'To better understand the differences, let us consider the performance of the
    previously trained classifier in classifying country songs correctly, as shown
    in the following graph:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这些差异，假设我们来看一下先前训练的分类器在正确分类乡村歌曲方面的表现，如下图所示：
- en: '![An alternative way to measure classifier performance using receiver-operator
    characteristics](img/2772OS_09_05.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![使用接收器操作特征来衡量分类器性能的另一种方式](img/2772OS_09_05.jpg)'
- en: On the left, we see the P/R curve. For an ideal classifier, we would have the
    curve going from the top left directly to the top right and then to the bottom
    right, resulting in an area under curve (AUC) of 1.0.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧，我们可以看到P/R曲线。对于一个理想的分类器，我们希望看到的曲线是从左上角直接到右上角，再到右下角，从而形成一个面积（AUC）为1.0的曲线。
- en: The right graph depicts the corresponding ROC curve. It plots the True Positive
    Rate over the False Positive Rate. There, an ideal classifier would have a curve
    going from the lower left to the top left, and then to the top right. A random
    classifier would be a straight line from the lower left to the upper right, as
    shown by the dashed line, having an AUC of 0.5\. Therefore, we cannot compare
    an AUC of a P/R curve with that of an ROC curve.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 右侧的图展示了相应的ROC曲线。它绘制了真正例率与假正例率之间的关系。在这里，一个理想的分类器曲线应该从左下角走到左上角，然后到达右上角。而一个随机分类器则表现为从左下角到右上角的直线，如虚线所示，AUC为0.5。因此，我们不能将P/R曲线的AUC与ROC曲线的AUC进行比较。
- en: Independent of the curve, when comparing two different classifiers on the same
    dataset, we are always safe to assume that a higher AUC of a P/R curve for one
    classifier also means a higher AUC of the corresponding ROC curve and vice versa.
    Thus, we never bother to generate both. More on this can be found in the very
    insightful paper *The Relationship Between Precision-Recall and ROC Curves* by
    Davis and Goadrich (ICML, 2006).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 独立于曲线，在比较同一数据集上两个不同分类器时，我们总是可以安全地假设，一个分类器的P/R曲线的AUC较高，也意味着其对应的ROC曲线的AUC较高，反之亦然。因此，我们通常不会生成两者。关于这一点的更多信息可以在Davis和Goadrich（ICML，2006）撰写的非常有见地的论文《**精准率-召回率与ROC曲线的关系**》中找到。
- en: 'The following table summarizes the differences between P/R and ROC curves:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格总结了P/R曲线与ROC曲线之间的差异：
- en: '|   | x axis | y axis |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '|   | x 轴 | y 轴 |'
- en: '| P/R | ![An alternative way to measure classifier performance using receiver-operator
    characteristics](img/2772OS_05_18.jpg) | ![An alternative way to measure classifier
    performance using receiver-operator characteristics](img/2772OS_09_07.jpg) |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| P/R | ![使用接收者操作特征衡量分类器性能的另一种方法](img/2772OS_05_18.jpg) | ![使用接收者操作特征衡量分类器性能的另一种方法](img/2772OS_09_07.jpg)
    |'
- en: '| ROC | ![An alternative way to measure classifier performance using receiver-operator
    characteristics](img/2772OS_09_08.jpg) | ![An alternative way to measure classifier
    performance using receiver-operator characteristics](img/2772OS_09_09.jpg) |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| ROC | ![使用接收者操作特征衡量分类器性能的另一种方法](img/2772OS_09_08.jpg) | ![使用接收者操作特征衡量分类器性能的另一种方法](img/2772OS_09_09.jpg)
    |'
- en: Looking at the definitions of both curves' *x* and *y* axis, we see that the
    True Positive Rate in the ROC curve's *y* axis is the same as Recall of the P/R
    graph's *x* axis.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 看着这两条曲线的* x *轴和* y *轴的定义，我们可以看到，ROC曲线的* y *轴上的真正阳性率与P/R图的* x *轴上的召回率是相同的。
- en: The False Positive Rate measures the fraction of true negative examples that
    were falsely identified as positive ones, giving a 0 in a perfect case (no false
    positives) and 1 otherwise. Contrast this to the precision, where we track exactly
    the opposite, namely the fraction of true positive examples that we correctly
    classified as such.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 假阳性率衡量被错误识别为阳性的真正负例的比例，在完美的情况下为0（没有假阳性），否则为1。与此对比，精准度则关注完全相反的内容，即我们正确分类为阳性的真正例的比例。
- en: 'Going forward, let us use ROC curves to measure our classifiers'' performance
    to get a better feeling for it. The only challenge for our multiclass problem
    is that both ROC and P/R curves assume a binary classification problem. For our
    purpose, let us, therefore, create one chart per genre that shows how the classifier
    performed a one versus rest classification:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以后，让我们使用ROC曲线来衡量分类器的性能，以便更好地感知其效果。我们多类问题的唯一挑战是，ROC和P/R曲线假设的是二分类问题。因此，为了我们的目的，我们将为每个音乐类型创建一张图表，展示分类器在一对其余类别分类中的表现：
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The outcomes are the following six ROC plots. As we have already found out,
    our first version of a classifier only performs well on Classical songs. Looking
    at the individual ROC curves, however, tells us that we are really underperforming
    for most of the other genres. Only Jazz and Country provide some hope. The remaining
    genres are clearly not usable.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是以下六个ROC图。如我们已经发现的，我们的第一个版本的分类器只对古典歌曲表现良好。然而，查看个别的ROC曲线告诉我们，大部分其他类型的表现确实不佳。只有爵士乐和乡村音乐带来了一些希望。其余的类型显然无法使用。
- en: '![An alternative way to measure classifier performance using receiver-operator
    characteristics](img/2772OS_09_10.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![使用接收者操作特征衡量分类器性能的另一种方法](img/2772OS_09_10.jpg)'
- en: Improving classification performance with Mel Frequency Cepstral Coefficients
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用梅尔频率倒谱系数提高分类性能
- en: We already learned that FFT is pointing in the right direction, but in itself
    it will not be enough to finally arrive at a classifier that successfully manages
    to organize our scrambled directory of songs of diverse music genres into individual
    genre directories. We need a somewhat more advanced version of it.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解到，FFT指向了正确的方向，但它本身不足以最终得到一个成功的分类器，能够将我们乱序的、包含多种音乐类型的歌曲目录整理到各个单独的类型目录中。我们需要一个稍微更高级的版本。
- en: At this point, it is always wise to acknowledge that we have to do more research.
    Other people might have had similar challenges in the past and already have found
    out new ways that might also help us. And, indeed, there is even a yearly conference
    dedicated to only music genre classification, organized by the **International
    Society for Music Information Retrieval** (**ISMIR**). Apparently, **Automatic
    Music Genre Classification** (**AMGC**) is an established subfield of Music Information
    Retrieval. Glancing over some of the AMGC papers, we see that there is a bunch
    of work targeting automatic genre classification that might help us.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，承认我们需要做更多的研究总是明智的。其他人可能曾面临类似的挑战，并且已经找到了新的方法，可能也能帮助我们。事实上，甚至每年都有一场专注于音乐类型分类的会议，由**国际音乐信息检索学会**（**ISMIR**）组织。显然，**自动音乐类型分类**（**AMGC**）已经成为音乐信息检索的一个成熟子领域。快速浏览一些AMGC的论文，我们看到有很多针对自动类型分类的工作，可能会帮助我们。
- en: One technique that seems to be successfully applied in many of those works is
    called Mel Frequency Cepstral Coefficients. The **Mel Frequency Cepstrum** (**MFC**)
    encodes the power spectrum of a sound, which is the power of each frequency the
    sound contains. It is calculated as the Fourier transform of the logarithm of
    the signal's spectrum. If that sounds too complicated, simply remember that the
    name "cepstrum" originates from "spectrum" having the first four characters reversed.
    MFC has been successfully used in speech and speaker recognition. Let's see whether
    it also works in our case.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多研究中似乎成功应用的一个技术叫做梅尔频率倒谱系数（Mel Frequency Cepstral Coefficients）。**梅尔频率倒谱**（**MFC**）编码了声音的功率谱，即声音包含的每个频率的功率。它是通过对信号谱的对数进行傅里叶变换来计算的。如果这听起来太复杂，简单记住，“倒谱”这个名字源于“谱”（spectrum）一词的前四个字母倒过来。MFC已被成功应用于语音和说话人识别。我们来看看它是否也能在我们的案例中发挥作用。
- en: 'We are in a lucky situation in that someone else already needed exactly this
    and published an implementation of it as the Talkbox SciKit. We can install it
    from [https://pypi.python.org/pypi/scikits.talkbox](https://pypi.python.org/pypi/scikits.talkbox).
    Afterward, we can call the `mfcc()` function, which calculates the MFC coefficients,
    as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正处于一个幸运的情况，因为别人已经恰好需要这个并且发布了一个实现，叫做Talkbox SciKit。我们可以从[https://pypi.python.org/pypi/scikits.talkbox](https://pypi.python.org/pypi/scikits.talkbox)安装它。之后，我们可以调用`mfcc()`函数来计算MFC系数，方法如下：
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The data we would want to feed into our classifier is stored in `ceps`, which
    contains 13 coefficients (default value for the `nceps` parameter of `mfcc()`)
    for each of the 4,135 frames for the song with the filename `fn`. Taking all of
    the data would overwhelm our classifier. What we could do, instead, is to do an
    averaging per coefficient over all the frames. Assuming that the start and end
    of each song are possibly less genre specific than the middle part of it, we also
    ignore the first and last 10 percent:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望输入到分类器中的数据存储在`ceps`中，它包含了每个歌名为`fn`的歌曲的4,135帧的13个系数（`mfcc()`函数的`nceps`参数的默认值）。如果直接使用所有数据，会使分类器过载。相反，我们可以对每个系数在所有帧上进行平均。假设每首歌的开始和结束部分可能不如中间部分具有明显的音乐类型特征，我们也忽略了前后各10%的数据。
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Sure enough, the benchmark dataset we will be using contains only the first
    30 seconds of each song, so that we would not need to cut off the last 10 percent.
    We do it, nevertheless, so that our code works on other datasets as well, which
    are most likely not truncated.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，我们将使用的基准数据集只包含每首歌的前30秒，因此我们不需要剪掉最后10%。不过我们还是这么做了，以确保我们的代码可以在其他可能没有截断的数据集上运行。
- en: Similar to our work with FFT, we certainly would also want to cache the once
    generated MFCC features and read them instead of recreating them each time we
    train our classifier.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我们使用FFT的工作，我们当然也希望缓存一次生成的MFCC特征，并在每次训练分类器时读取它们，而不是每次都重新生成。
- en: 'This leads to the following code:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了以下代码：
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We get the following promising results with a classifier that uses only 13
    features per song:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过一个每首歌只使用13个特征的分类器得到了以下有希望的结果：
- en: '![Improving classification performance with Mel Frequency Cepstral Coefficients](img/2772OS_09_11.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![通过梅尔频率倒谱系数提高分类性能](img/2772OS_09_11.jpg)'
- en: The classification performances for all genres have improved. Classical and
    Metal are even at almost 1.0 AUC. And indeed, also the confusion matrix in the
    following plot looks much better now. We can clearly see the diagonal showing
    that the classifier manages to classify the genres correctly in most of the cases.
    This classifier is actually quite usable to solve our initial task.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 所有音乐类型的分类表现都有所提升。古典音乐和金属音乐的AUC几乎达到了1.0。实际上，下面的混淆矩阵现在看起来好多了。我们可以清楚地看到对角线，显示出分类器在大多数情况下能够正确地分类各个音乐类型。这个分类器实际上相当适用于解决我们的初始任务。
- en: '![Improving classification performance with Mel Frequency Cepstral Coefficients](img/2772OS_09_12.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![通过梅尔频率倒谱系数提高分类性能](img/2772OS_09_12.jpg)'
- en: 'If we would want to improve on this, this confusion matrix tells us quickly
    what to focus on: the non-white spots on the non-diagonal places. For instance,
    we have a darker spot where we mislabel Rock songs as being Jazz with considerable
    probability. To fix this, we would probably need to dive deeper into the songs
    and extract things such as drum patterns and similar genre specific characteristics.
    And then—while glancing over the ISMIR papers—we also have read about the so-called
    **Auditory Filterbank Temporal Envelope** (**AFTE**) features, which seem to outperform
    MFCC features in certain situations. Maybe we should have a look at them as well?'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想在这方面有所改进，这个混淆矩阵会迅速告诉我们需要关注的地方：非对角线位置的非白色区域。例如，我们在一个较暗的区域中错误地将摇滚歌曲标记为爵士乐，且这种错误有相当大的概率。要解决这个问题，我们可能需要更深入地研究这些歌曲，提取诸如鼓点模式和类似的音乐风格特征。然后——在浏览ISMIR论文时——我们还读到了一种名为**听觉滤波器带时域包络**（**AFTE**）的特征，似乎在某些情况下优于MFCC特征。或许我们也该看看它们？
- en: The nice thing is that, only equipped with ROC curves and confusion matrices,
    we are free to pull in other experts' knowledge in terms of feature extractors
    without requiring ourselves to fully understand their inner workings. Our measurement
    tools will always tell us, when the direction is right and when to change it.
    Of course, being a machine learner who is eager to learn, we will always have
    the dim feeling that there is an exciting algorithm buried somewhere in a black
    box of our feature extractors, which is just waiting for us to be understood.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，只要配备了ROC曲线和混淆矩阵，我们可以随时借用其他专家在特征提取器方面的知识，而无需完全理解它们的内部工作原理。我们的测量工具总是会告诉我们，何时方向正确，何时需要改变。当然，作为一个渴望学习的机器学习者，我们总会有一种模糊的感觉，觉得在特征提取器的黑箱中埋藏着一个激动人心的算法，正等着我们去理解。
- en: Summary
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we totally stepped out of our comfort zone when we built a
    music genre classifier. Not having a deep understanding of music theory, at first
    we failed to train a classifier that predicts the music genre of songs with reasonable
    accuracy using FFT. But, then, we created a classifier that showed really usable
    performance using MFC features.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们在构建音乐类型分类器时完全走出了舒适区。由于对音乐理论没有深入理解，最初我们未能训练出一个合理准确地预测歌曲音乐类型的分类器。通过快速傅里叶变换（FFT）进行尝试失败。但随后，我们使用MFC特征创建了一个表现出真正可用性能的分类器。
- en: In both the cases, we used features that we understood only enough to know how
    and where to put them into our classifier setup. The one failed, the other succeeded.
    The difference between them is that in the second case we relied on features that
    were created by experts in the field.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，我们使用的特征我们只是了解得足够多，知道如何以及在哪里将它们放入分类器设置中。一个失败了，另一个成功了。它们之间的区别在于，在第二种情况下，我们依赖的是领域专家创建的特征。
- en: And that is totally OK. If we are mainly interested in the result, we sometimes
    simply have to take shortcuts—we just have to make sure to take these shortcuts
    from experts in the specific domains. And because we had learned how to correctly
    measure the performance in this new multiclass classification problem, we took
    these shortcuts with confidence.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这完全没问题。如果我们主要关心结果，有时候我们只是需要走捷径——我们只需要确保这些捷径来自于特定领域的专家。而且，因为我们学会了如何在这个新的多类别分类问题中正确地衡量性能，所以我们能够充满信心地走这些捷径。
- en: In the next chapter, we will look at how to apply techniques you have learned
    in the rest of this book to this specific type of data. We will learn how to use
    the mahotas computer vision package to preprocess images using traditional image
    processing functions.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将探讨如何将你在本书其余部分学到的技术应用到这种特定类型的数据中。我们将学习如何使用mahotas计算机视觉包，通过传统的图像处理功能来预处理图像。
