- en: What's Next?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下一步是什么？
- en: So far, we've used **machine learning** (**ML**) to implement various tasks.
    There are many advancements in the field of ML, and with each passing day, the
    areas in which it is applied are increasing too.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经使用**机器学习**（**ML**）实现了各种任务。机器学习领域有许多进展，随着时间的推移，其应用领域也在不断增加。
- en: In this chapter, we'll summarize the projects that we executed in the previous
    chapters.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将总结在前几章中执行的项目。
- en: Summary of the projects
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目总结
- en: Let's start with [Chapter 1](32e9f384-e739-4a1c-833e-11ee40051ac8.xhtml), *The
    Python Machine Learning Ecosystem*.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从[第1章](32e9f384-e739-4a1c-833e-11ee40051ac8.xhtml)，*Python机器学习生态系统*开始。
- en: In the first chapter, we began with an overview of ML with Python. We started
    with the ML workflow, which included acquisition, inspection, preparation, modeling
    evaluation, and deployment. Then we studied the various Python libraries and functions
    that are needed for each step of the workflow. Lastly, we set up our ML environment
    to execute the projects.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章，我们开始了Python机器学习的概述。我们从机器学习的工作流程入手，包括数据获取、检查、准备、建模评估和部署。然后我们学习了每个工作流程步骤所需的各种Python库和函数。最后，我们设置了机器学习环境来执行这些项目。
- en: '[Chapter 2](75c4451a-b290-4625-955d-8418bfaf852b.xhtml), *Building an App to
    Find Underpriced Apartments*, as the name says, was based on building an app to
    find underpriced apartments. Initially, we listed our data to find the source
    of the apartments in the required location. Then, we inspected the data, and after
    preparing and visualizing the data, we performed regression modeling. Linear regression
    is a type of supervised ML. Supervised, in this context, simply means we provide
    the output values for our training set.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[第2章](75c4451a-b290-4625-955d-8418bfaf852b.xhtml)，*构建一个寻找低价公寓的应用程序*，顾名思义，基于构建一个应用程序来寻找低价公寓。最初，我们列出了数据来寻找所需位置的公寓来源。然后，我们检查了数据，并在准备和可视化数据后，进行了回归建模。线性回归是一种监督式机器学习（ML）。在这个上下文中，监督式意味着我们为训练集提供输出值。'
- en: Then, we spent the remainder of our time exploring the options as per our choice.
    We created an application that made finding the right apartment just a little
    bit easier.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们花剩余的时间按照我们的选择探索其他选项。我们创建了一个应用程序，使寻找合适的公寓变得更加轻松。
- en: In [Chapter 3](73ff80b5-e844-4791-bf95-b678215c00a8.xhtml), *Building an App
    to Find Cheap Airfare*, we built a similar app as in [Chapter 2](75c4451a-b290-4625-955d-8418bfaf852b.xhtml),
    *Building an App to Find Underpriced Apartments*, but to find cheap airfare. We
    started by sourcing airfare prices on the web. We used one of the trending techniques,
    web scraping, to retrieve the data of the airplane fares. To parse the DOM for
    our Google page, we used the `Beautifulsoup` library. Then, we used anomaly detection
    techniques to identify outlier fares. In doing this, cheaper airfare can be found,
    and we'll receive real-time text alerts using IFTTT.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](73ff80b5-e844-4791-bf95-b678215c00a8.xhtml)，*构建一个寻找便宜机票的应用程序*，我们构建了一个类似于[第2章](75c4451a-b290-4625-955d-8418bfaf852b.xhtml)，*构建一个寻找低价公寓的应用程序*，但目的是寻找便宜的机票。我们首先在网上获取了机票价格。我们使用了当下流行的技术之一——网页抓取，来获取机票价格数据。为了解析我们的Google页面的DOM，我们使用了`Beautifulsoup`库。接着，我们使用异常检测技术来识别离群的机票价格。通过这样做，我们可以找到更便宜的机票，并且通过IFTTT收到实时文本提醒。
- en: In [Chapter 4](62de7683-c87e-4ddd-b27a-55be8ce501a9.xhtml), *Forecasting the
    IPO Market Using Logistic Regression*, we looked at how the IPO market works.
    First, we discussed what an **Initial Public Offering** (**IPO**) is, and what
    the research tells us about this market. After that, we discussed a number of
    strategies that we can apply to predict the IPO market. It involved data cleansing
    and feature-engineering. Then, we implemented binary classification of the data
    using logistic regression to analyze the data. Then, we evaluated the final model,
    which was obtained as the output.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](62de7683-c87e-4ddd-b27a-55be8ce501a9.xhtml)，*使用逻辑回归预测IPO市场*，我们探讨了IPO市场的运作方式。首先，我们讨论了什么是**首次公开募股**（**IPO**），以及研究告诉我们关于这个市场的情况。接着，我们讨论了多种策略，这些策略可以用来预测IPO市场。这包括数据清洗和特征工程。然后，我们使用逻辑回归对数据进行了二分类分析。最后，我们评估了获得的最终模型。
- en: We also understood that the features that have an impact on our model include
    the feature importance that comes out of a random forest classifier. This more
    accurately reflects the true impact of a given feature.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还了解到，影响我们模型的特征包括来自随机森林分类器的特征重要性。这能更准确地反映某个特征的实际影响。
- en: '[Chapter 5](0f9be478-251c-40ea-9aa7-2e7a6941199f.xhtml), *Create a Custom Newsfeed*,
    was mostly for avid news readers who are interested in knowing what''s going on
    around the globe. By creating a custom newsfeed, you can decide what news updates
    you get on your devices. In this chapter, you learned how to build a system that
    understands your taste in news, and will send you a tailored newsletter each day.
    We started by creating a supervised training set with the Pocket app, and then
    leveraged the Pocket API to retrieve the stories. We used the Embedly API to extract
    story bodies.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[第5章](0f9be478-251c-40ea-9aa7-2e7a6941199f.xhtml)，*创建自定义新闻推送*，主要面向那些对全球新闻充满兴趣的新闻爱好者。通过创建一个自定义新闻推送，你可以决定哪些新闻更新会出现在你的设备上。在本章中，你学习了如何构建一个能够理解你新闻偏好的系统，并每天向你发送量身定制的新闻简报。我们从使用Pocket应用创建一个监督训练集开始，然后利用Pocket
    API来获取故事内容。我们使用Embedly API来提取故事正文。'
- en: Then, we studied the basics of **natural language processing** (**NLP**) and **Support
    Vector Machines** (**SVMs**). We integrated **If This Then That** (**IFTTT**)
    with RSS feeds and Google sheets so that we could stay up to date with notifications,
    emails, and more. Lastly, we set up a daily personal newsletter. We used the Webhooks
    channel to send a `POST` request.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们学习了**自然语言处理**（**NLP**）和**支持向量机**（**SVMs**）的基础知识。我们将**If This Then That**（**IFTTT**）与RSS源和Google
    Sheets结合使用，以便我们能够通过通知、电子邮件等方式保持最新。最后，我们设置了一个每日个人新闻简报。我们使用Webhooks通道发送`POST`请求。
- en: The script runs every four hours, pulls down the news stories from Google Sheets,
    runs the stories through the model, generates an email by sending a `POST` request
    to IFTTT for the stories that are predicted to be of interest, and then, finally,
    it will clear out the stories in the spreadsheet so only new stories get sent
    in the next email. And that's how we get our very own personalized newsfeed.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本每四小时运行一次，从Google Sheets中提取新闻故事，通过模型处理这些故事，生成电子邮件，发送`POST`请求到IFTTT，通知我们预测可能感兴趣的故事，最后，它会清空电子表格中的旧故事，以确保下次邮件只发送新的故事。这就是我们如何获取个性化新闻推送的方式。
- en: In [Chapter 6, ](5c87cb71-18aa-401c-bcf0-f6142bdd4250.xhtml)*Predicate Whether
    Your Content Will Go Viral*, we examined some of the most-shared content and attempted
    to find the common elements that differentiate this content from the content people
    were less inclined to share. The chapter started by providing an understanding
    of what exactly virality means. We also looked at what research tells us about
    virality.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](5c87cb71-18aa-401c-bcf0-f6142bdd4250.xhtml)，*判断你的内容是否会病毒式传播*，我们考察了一些最受分享的内容，并试图找出这些内容与人们不太愿意分享的内容之间的共同元素。本章开始时提供了关于病毒式传播的定义。我们还研究了关于病毒式传播的研究结果。
- en: Then, as we did it in the rest of the chapters we will be sourcing the shared
    counts and content. We used a dataset that was collected from a now-defunct website
    called `ruzzit.com`. This site, when it was active, tracked the most-shared content
    over time, which was exactly what we needed for this project. Then we explored
    the features of shareability, which included exploring image data, clustering,
    exploring the headlines, and exploring the story's content.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，正如我们在其他章节中所做的那样，我们将会获取共享的计数和内容。我们使用了一个来自现已关闭的名为`ruzzit.com`的网站收集的数据集。该网站在运营时，追踪了最受分享的内容，这正是我们这个项目所需要的。接着，我们探索了可分享性的特征，其中包括探索图片数据、聚类、探索标题以及分析故事的内容。
- en: The last, but most important, part was building the predictive content-scoring
    model. We used an algorithm called **random forest regression**. We built the
    model with zero errors in it. Then, we evaluated the model and added some features
    to enhance it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，也是最重要的一部分，是构建预测内容评分模型。我们使用了一种名为**随机森林回归**的算法。我们构建的模型没有任何错误。然后，我们评估了这个模型，并添加了一些特性来增强它。
- en: In [Chapter 7](030a0c35-a14e-48a0-984b-af0c01f9377b.xhtml), *Use Machine Learning
    to Forecast the Stock Market*, we learned how to build and test a trading strategy.
    We also learned how *not* to do it. There are countless pitfalls to avoid when
    trying to devise your own system, and it's nearly an impossible task, but it can
    be a lot of fun, and sometimes it can even be profitable. That said, don't do
    dumb things, such as risking money you can't afford to lose.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](030a0c35-a14e-48a0-984b-af0c01f9377b.xhtml)，*使用机器学习预测股市*，我们学会了如何建立和测试一个交易策略。我们还学到了如何*不*去做这件事。在尝试设计自己的系统时，有无数的陷阱需要避免，这几乎是一个不可能完成的任务，但它也可以非常有趣，有时甚至能带来利润。话虽如此，不要做愚蠢的事情，比如冒着自己负担不起的风险去投资。
- en: When you're ready to risk you money, you might as well learn some tricks and
    tips to avoid losing much of it. Who likes to lose in life—be it for money or
    a game?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当你准备好冒险投资时，不妨学习一些技巧和窍门，以避免损失太多。谁喜欢在生活中失败——无论是钱财还是游戏？
- en: We mostly concentrated our attention on stocks and the stock market. Initially,
    we analyzed types of markets and then the researched on the stock market. It's
    always better to have some prior knowledge before risking anything. We began developing
    our strategy by focusing on the technical aspects. We went through the S&P 500
    over the last few years and used pandas to import our data. That gave us access
    to several sources of stock data, including Yahoo! and Google.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们主要集中精力在股票和股市上。最初，我们分析了市场类型，然后研究了股市。在冒险之前，有一些先验知识总是更好的。我们通过关注技术方面开始制定策略。我们回顾了过去几年中的标准普尔500指数，并使用pandas导入我们的数据。这使我们能够访问多个股票数据来源，包括Yahoo!和Google。
- en: Then we built the regression model. We started with a very basic model using
    only the stock's prior closing values to predict the next day's close, and built
    it using a support vector regression. Lastly, we evaluated the performance of
    our model and the trades that were carried out.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们建立了回归模型。我们从一个非常基础的模型开始，只使用股票的前一天收盘值来预测第二天的收盘价，并使用支持向量回归来构建它。最后，我们评估了模型的表现以及所执行的交易。
- en: Long before Siri was released with the iPhone 4S, we had chatbots that were
    used widely across multiple applications. In [Chapter 9](f84d1bd3-b045-4747-abd7-66ae24d1db66.xhtml),
    *Building a Chatbot*, we learned about the Turing Test and its origins. Then we
    looked at a program called ELIZA. If ELIZA was an early example of chatbots, what
    have we seen since then? In recent years, there has been an explosion of new chatbots—the
    most notable of these is Cleverbot.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在Siri随iPhone 4S发布之前，我们就有了广泛应用于多种场景的聊天机器人。在[第9章](f84d1bd3-b045-4747-abd7-66ae24d1db66.xhtml)，*构建聊天机器人*中，我们学习了图灵测试及其起源。然后我们看了一个叫做ELIZA的程序。如果ELIZA是聊天机器人的早期示例，那么我们从那时以来又见到了什么？近年来，新的聊天机器人层出不穷，其中最著名的就是Cleverbot。
- en: 'Then, we looked at the interesting part: designing these chatbots.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们看到了有趣的部分：设计这些聊天机器人。
- en: But what about more advanced bots? How are they built?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 那么更先进的机器人呢？它们是如何构建的？
- en: Surprisingly, most chatbots you're likely to encounter don't use ML; they're
    what's know as retrieval-based models. This means responses are predefined according
    to the question and the context. The most common architecture for these bots is
    something called **Artificial Intelligence Markup Language** (**AIML**). AIML
    is an XML-based schema for representing how the bot should interact given the
    user's input. It's really just a more advanced version of how ELIZA works.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，大多数你可能遇到的聊天机器人并没有使用机器学习；它们是所谓的基于检索的模型。这意味着响应是根据问题和上下文预定义的。这些机器人最常见的架构是被称为**人工智能标记语言**（**AIML**）的东西。AIML是一种基于XML的架构，用于表示机器人在用户输入的情况下应该如何互动。它实际上只是ELIZA工作方式的一个更高级版本。
- en: Lastly, we did sequence-to-sequence modeling for chatbots. This is frequently
    used in machine translation and question-answering applications as it allows us
    to map an input sequence of any length to an output sequence of any length.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们进行了聊天机器人中的序列到序列建模。这种方法在机器翻译和问答应用中经常使用，因为它允许我们将任意长度的输入序列映射到任意长度的输出序列。
- en: In [Chapter 8](5df6fae8-a5c0-4fab-8508-baef0085b4f5.xhtml), *Classifying Images
    with Convolutional Neural Networks*, we looked at building a **Convolutional Neural
    Network** (**CNN**) to classify images in the Zalando Research dataset using Keras.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第8章](5df6fae8-a5c0-4fab-8508-baef0085b4f5.xhtml)，*使用卷积神经网络进行图像分类*中，我们学习了使用Keras构建**卷积神经网络**（**CNN**）来分类Zalando研究数据集中的图像。
- en: We started by extracting the image's features. Then, using CNNs, we understood
    the network topology, the various convolutional layers and filters, and what max
    pooling layers are.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从提取图像的特征开始。然后，使用卷积神经网络（CNN），我们理解了网络拓扑结构、各种卷积层和滤波器，以及最大池化层的原理。
- en: Try building deeper models or grid searching over the many hyperparameters we
    used in our models. Assess your classifier's performance as you would with any
    other model—try building a confusion matrix to understand what classes we predicted
    well and what classes we weren't as strong in!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试构建更深层次的模型，或者对我们在模型中使用的许多超参数进行网格搜索。像评估其他模型一样评估你的分类器的表现——尝试构建混淆矩阵，了解我们预测得好的类别以及我们不太擅长的类别！
- en: In [Chapter 10](b23a1432-191f-42f7-b5d5-f2cbaea4d041.xhtml), *Build a Recommendation
    Engine*, we explored different varieties of recommendation systems. We saw how
    they're implemented commercially and how they work. Then we implemented our own
    recommendation engine for finding GitHub repositories.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第10章](b23a1432-191f-42f7-b5d5-f2cbaea4d041.xhtml)，*构建推荐引擎*，我们探索了不同种类的推荐系统。我们了解了它们是如何在商业中实现的，以及它们是如何工作的。然后，我们为寻找GitHub仓库实现了自己的推荐引擎。
- en: We started with collaborative filtering. Collaborative filtering is based on
    the idea that, somewhere out there in the world, you have a taste doppelganger—someone
    who has the same feelings about how good *Star Wars* is and how awful *Love Actually* is.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从协同过滤开始。协同过滤基于这样一个观点：在这个世界的某个地方，你有一个品味的“替身”——某个人对*星球大战*的评价和对*真爱至上*的看法与你完全相同。
- en: Then we also studied what content-based filtering and hybrid systems are.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们还学习了基于内容的过滤和混合系统是什么。
- en: Lastly, we used the GitHub API to create a recommendation engine based on collaborative
    filtering. The plan was to get all of the repositories that I'd starred over time
    and to then get all of the creators of those repositories to find out what repositories they'd
    starred. This enabled us to find out which users starred repositories were most
    similar to mine.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用GitHub API创建了一个基于协同过滤的推荐引擎。计划是获取我在一段时间内所有的星标仓库，并通过这些仓库的创建者，找出他们星标的仓库。这样，我们就能找出哪些用户的星标仓库与我最相似。
- en: Summary
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter was just a small recap to take you back through all the projects
    we implemented.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本章只是一个小小的回顾，带你回顾我们实施过的所有项目。
- en: I hope you enjoyed reading this book, and that the executions will help you
    to create your own projects in a similar manner!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢阅读这本书，并且这些实践能帮助你以类似的方式创建自己的项目！
