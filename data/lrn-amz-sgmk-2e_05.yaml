- en: 'Chapter 3: AutoML with Amazon SageMaker Autopilot'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章：使用亚马逊SageMaker Autopilot进行AutoML
- en: In the previous chapter, you learned how Amazon SageMaker helps you build and
    prepare datasets. In a typical machine learning project, the next step would be
    to start experimenting with algorithms in order to find an early fit and get a
    sense of the predictive power you could expect from the model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您已经了解了亚马逊SageMaker如何帮助您构建和准备数据集。在典型的机器学习项目中，下一步将是开始尝试不同的算法，以找到初步适合的模型，并了解您可以从模型中预期的预测能力。
- en: 'Whether you work with traditional machine learning or deep learning, three
    options are available when it comes to selecting an algorithm:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是使用传统机器学习还是深度学习，在选择算法时有三个选项：
- en: Write your own, or customize an existing one. This only makes sense if you have
    strong skills in statistics and computer science, if you're quite sure that you
    can do better than well-tuned, off-the-shelf algorithms, and if you're given enough
    time to work on the project. Let's face it, these conditions are rarely met.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 写自己的代码，或者自定义现有代码。只有在你具备强大的统计和计算机科学技能，并且相当确定你能比调优后的现成算法做得更好，而且有足够的时间来完成项目时，这才有意义。让我们面对现实吧，这些条件很少能够满足。
- en: Use a built-in algorithm implemented in one of your favorite libraries, such
    as **linear regression** or **XGBoost**. For deep learning problems, this includes
    pre-trained models available in **TensorFlow**, **PyTorch**, and so on. This option
    saves you the trouble of writing machine learning code. Instead, it lets you focus
    on feature engineering and model optimization.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内置算法实现您喜欢的库中的一个，如**线性回归**或**XGBoost**。对于深度学习问题，这包括在**TensorFlow**、**PyTorch**等中可用的预训练模型。此选项省去了编写机器学习代码的麻烦，而是让您专注于特征工程和模型优化。
- en: Use **AutoML**, a rising technique that lets you automatically build, train,
    and optimize machine learning models.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**AutoML**，这是一种新兴技术，可以自动构建、训练和优化机器学习模型。
- en: 'In this chapter, you will learn about **Amazon SageMaker Autopilot**, an AutoML
    capability part of Amazon SageMaker with built-in model explainability. We''ll
    see how to use it in Amazon SageMaker Studio without writing a single line of
    code, and also how to use it with the Amazon SageMaker SDK:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解**亚马逊SageMaker Autopilot**，这是亚马逊SageMaker的AutoML功能之一，具有内置的模型可解释性。我们将看到如何在亚马逊SageMaker
    Studio中使用它，而无需编写一行代码，并且如何使用亚马逊SageMaker SDK：
- en: Discovering Amazon SageMaker Autopilot
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现亚马逊SageMaker Autopilot
- en: Using Amazon SageMaker Autopilot in SageMaker Studio
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在SageMaker Studio中使用亚马逊SageMaker Autopilot
- en: Using Amazon SageMaker Autopilot with the SageMaker SDK
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用亚马逊SageMaker Autopilot和SageMaker SDK
- en: Diving deep on Amazon SageMaker Autopilot
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入探讨亚马逊SageMaker Autopilot
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need an AWS account to run the examples included in this chapter. If
    you haven't got one already, please point your browser at [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    to create it. You should also familiarize yourself with the AWS Free Tier ([https://aws.amazon.com/free/](https://aws.amazon.com/free/)),
    which lets you use many AWS services for free within certain usage limits.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要一个AWS帐户来运行本章中包含的示例。如果您尚未拥有，请访问[https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)创建一个。您还应该熟悉AWS
    Free Tier（[https://aws.amazon.com/free/](https://aws.amazon.com/free/)），它允许您在一定使用限制内免费使用许多AWS服务。
- en: You will need to install and configure the AWS **Command-Line Interface** (**CLI**)
    for your account ([https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您将需要为您的帐户安装和配置AWS **命令行界面**（**CLI**）（[https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)）。
- en: You will need a working Python 3.x environment. Installing the Anaconda distribution
    ([https://www.anaconda.com/](https://www.anaconda.com/)) is not mandatory, but
    is strongly encouraged as it includes many projects that we will need (Jupyter,
    `pandas`, `numpy`, and more).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您将需要一个运行Python 3.x的环境。虽然安装Anaconda发行版（[https://www.anaconda.com/](https://www.anaconda.com/)）不是强制的，但强烈建议这样做，因为它包含了我们需要的许多项目（Jupyter、`pandas`、`numpy`等）。
- en: Code examples included in the book are available on GitHub at [https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition](https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition).
    You will need to install a Git client to access them ([https://git-scm.com/](https://git-scm.com/)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中包含的代码示例可在GitHub上访问（[https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition](https://github.com/PacktPublishing/Learn-Amazon-SageMaker-second-edition)）。您需要安装Git客户端才能访问这些示例（[https://git-scm.com/](https://git-scm.com/)）。
- en: Discovering Amazon SageMaker Autopilot
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发现 Amazon SageMaker Autopilot
- en: Added to Amazon SageMaker in late 2019, **Amazon SageMaker Autopilot** is an
    AutoML capability that takes care of all the machine learning steps for you. You
    only need to upload a columnar dataset to an Amazon S3 bucket and define the column
    you want the model to learn (the **target attribute**). Then, you simply launch
    an Autopilot job, with either a few clicks in the SageMaker Studio GUI or a couple
    of lines of code with the SageMaker SDK.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon SageMaker Autopilot** 于2019年末加入 Amazon SageMaker，是一个 AutoML 功能，能够为你处理所有机器学习步骤。你只需要将列数据集上传到
    Amazon S3 存储桶，并定义你希望模型学习的列（**目标属性**）。然后，你只需启动一个 Autopilot 作业，无论是通过在 SageMaker
    Studio GUI 中点击几下，还是使用 SageMaker SDK 编写几行代码。'
- en: The simplicity of SageMaker Autopilot doesn't come at the expense of transparency
    and control. You can see how your models are built, and you can keep experimenting
    to refine results. In that respect, SageMaker Autopilot should appeal to new and
    seasoned practitioners alike.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Autopilot 的简便性并不意味着缺乏透明度和控制权。你可以看到模型是如何构建的，并且可以不断实验以优化结果。从这个角度来看，SageMaker
    Autopilot 应该能吸引新手和经验丰富的从业者。
- en: 'In this section, you''ll learn about the different steps of a SageMaker Autopilot
    job and how they contribute to delivering high-quality models:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，你将了解 SageMaker Autopilot 作业的不同步骤，以及它们如何帮助提供高质量的模型：
- en: Analyzing data
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分析
- en: Feature engineering
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程
- en: Model tuning
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型调优
- en: Let's start by seeing how SageMaker Autopilot analyzes data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从了解 SageMaker Autopilot 如何分析数据开始。
- en: Analyzing data
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据分析
- en: This step is responsible for understanding what type of machine learning problem
    we're trying to solve. SageMaker Autopilot currently supports **linear regression**,
    **binary classification**, and **multi-class classification**.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步骤负责理解我们要解决的机器学习问题类型。SageMaker Autopilot 当前支持 **线性回归**、**二元分类** 和 **多类别分类**。
- en: Note
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: A frequent question is ”how much data is needed to build such models?” This
    is a surprisingly difficult question. The answer—if there is one—depends on many
    factors, such as the number of features and their quality. As a basic rule of
    thumb, some practitioners recommend having 10-100 times more samples than features.
    In any case, I'd advise you to collect no fewer than hundreds of samples (for
    each class, if you're building a classification model). Thousands or tens of thousands
    are better, especially if you have more features. For statistical machine learning,
    there is rarely a need for millions of samples, so start with what you have, analyze
    the results, and iterate before going on a data collection rampage!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的问题是：“构建这样的模型需要多少数据？”这是一个出人意料的难题。答案—如果有的话—取决于许多因素，比如特征的数量和质量。作为一个基本的经验法则，一些从业者建议样本数量是特征数量的10到100倍。无论如何，我建议你至少收集几百个样本（如果你在构建分类模型的话，应该按类别收集样本）。如果有更多特征，收集上千或上万个样本会更好。对于统计机器学习来说，通常不需要几百万个样本，因此从现有数据开始，分析结果，进行迭代，再决定是否需要收集更多数据！
- en: By analyzing the distribution of the target attribute, SageMaker Autopilot can
    easily figure out which one is the right one. For instance, if the target attribute
    has only two values (say, "yes" and "no"), you're likely trying to build a binary
    classification model.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析目标属性的分布，SageMaker Autopilot 可以轻松判断哪一种是正确的。例如，如果目标属性只有两个值（比如“是”和“否”），那么你很可能是在构建一个二元分类模型。
- en: 'Then, SageMaker Autopilot computes statistics on the dataset and individual
    columns: the number of unique values, the mean, median, and so on. Machine learning
    practitioners very often do this in order to get an initial feel for the data,
    and it''s nice to see it automated. In addition, SageMaker Autopilot generates
    a Jupyter notebook, the **data exploration notebook**, to present these statistics
    in a user-friendly way.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，SageMaker Autopilot 会计算数据集和各个列的统计信息：唯一值的数量、均值、中位数等等。机器学习从业者通常会这样做，以便初步了解数据，看到这一过程自动化也是很好的。此外，SageMaker
    Autopilot 还会生成一个 Jupyter 笔记本，**数据探索笔记本**，以用户友好的方式呈现这些统计信息。
- en: 'Once SageMaker Autopilot has analyzed the dataset, it builds **candidate pipelines**
    that will be used to train candidate models. A pipeline is a combination of the
    following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 SageMaker Autopilot 分析了数据集，它会构建 **候选管道**，用于训练候选模型。管道是以下内容的组合：
- en: A data processing job, in charge of feature engineering. As you can guess, this
    job runs on **Amazon SageMaker Processing**, which we studied in [*Chapter 2*](B17705_02_Final_JM_ePub.xhtml#_idTextAnchor030)*,*
    *Handling Data Preparation Techniques*.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个数据处理任务，负责特征工程。正如你所猜测的，这个任务运行在**Amazon SageMaker Processing**上，正如我们在[*第2章*](B17705_02_Final_JM_ePub.xhtml#_idTextAnchor030)《数据准备技巧》中所研究的那样。
- en: A training job, running on the processed dataset. Algorithms include the built-in
    Linear Learner in SageMaker, XGBoost, and multi-layer perceptrons.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个训练任务，运行在处理过的数据集上。算法包括 SageMaker 中内置的 Linear Learner、XGBoost 和多层感知机。
- en: Next, let's see how Autopilot can be used in feature engineering.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看 Autopilot 如何在特征工程中发挥作用。
- en: Feature engineering
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程
- en: This step is responsible for pre-processing the input dataset according to the
    pipelines defined during data analysis.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步负责根据数据分析过程中定义的管道来预处理输入数据集。
- en: 'Candidate pipelines are fully documented in another autogenerated notebook
    – the **candidate generation notebook**. This notebook isn''t just descriptive:
    you can actually run its cells, and manually reproduce the steps performed by
    SageMaker Autopilot. This level of transparency and control is extremely important
    as it lets you understand exactly how the model was built. Thus, you''re able
    to verify that it performs the way it should, and you''re able to explain it to
    your stakeholders. Also, you can use the notebook as a starting point for additional
    optimization and tweaking if you''re so inclined.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 候选管道在另一个自动生成的笔记本中进行了完整文档记录——**候选生成笔记本**。这个笔记本不仅仅是描述性的：你实际上可以运行它的单元格，手动重现 SageMaker
    Autopilot 执行的步骤。这种透明度和控制级别非常重要，因为它可以让你准确理解模型是如何构建的。因此，你可以验证它是否按预期执行，并且能够向你的利益相关者解释它。此外，如果你有兴趣，你还可以使用这个笔记本作为进一步优化和调整的起点。
- en: Lastly, let's take a look at model tuning in Autopilot.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看 Autopilot 中的模型调优。
- en: Model tuning
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型调优
- en: This step is responsible for training and tuning models according to the pipelines
    defined during data analysis. For each pipeline, SageMaker Autopilot will launch
    an **automatic model tuning** job (we'll cover this topic in detail in a later
    chapter). In a nutshell, each tuning job will use **hyperparameter optimization**
    to train a large number of increasingly accurate models on the processed dataset.
    As usual, all of this happens on managed infrastructure.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步负责根据数据分析过程中定义的管道来训练和调优模型。对于每个管道，SageMaker Autopilot 将启动一个**自动模型调优**任务（我们将在后续章节中详细介绍这个主题）。简而言之，每个调优任务将使用**超参数优化**在处理过的数据集上训练大量逐渐提高精度的模型。像往常一样，所有这些都发生在受管的基础设施上。
- en: Once the model tuning is complete, you can view the model information and metrics
    in Amazon SageMaker Studio, build visualizations, and so on. You can do the same
    programmatically with the **Amazon SageMaker Experiments** SDK.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型调优完成，您可以在 Amazon SageMaker Studio 中查看模型信息和指标，构建可视化图表等。您也可以使用**Amazon SageMaker
    Experiments** SDK 以编程方式执行相同的操作。
- en: Finally, you can deploy your model of choice just like any other SageMaker model
    using either the SageMaker Studio GUI or the SageMaker SDK.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以像使用任何其他 SageMaker 模型一样部署所选模型，使用 SageMaker Studio GUI 或 SageMaker SDK。
- en: Now that we understand the different steps of an Autopilot job, let's run a
    job in SageMaker Studio.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了 Autopilot 任务的不同步骤，让我们在 SageMaker Studio 中运行一个任务。
- en: Using Amazon SageMaker Autopilot in SageMaker Studio
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 SageMaker Studio 中使用 Amazon SageMaker Autopilot
- en: We will build a model using only SageMaker Studio. We won't write a line of
    machine learning code, so get ready for zero-code AI.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将仅使用 SageMaker Studio 构建一个模型。我们不会写一行机器学习代码，所以准备好进行零代码 AI。
- en: 'In this section, you''ll learn how to do the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习如何完成以下操作：
- en: Launch a SageMaker Autopilot job in SageMaker Studio.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 SageMaker Studio 中启动一个 SageMaker Autopilot 任务。
- en: Monitor the different steps of the job.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控任务的不同步骤。
- en: Visualize models and compare their properties.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化模型并比较它们的属性。
- en: Launching a job
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动任务
- en: 'First, we need a dataset. We''ll reuse the direct marketing dataset used in
    [*Chapter 2*](B17705_02_Final_JM_ePub.xhtml#_idTextAnchor030), *Handling Data
    Preparation Techniques*. This dataset describes a binary classification problem:
    will a customer accept a marketing offer, yes or no? It contains a little more
    than 41,000 labeled customer samples. Let''s dive in:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一个数据集。我们将重新使用在[*第2章*](B17705_02_Final_JM_ePub.xhtml#_idTextAnchor030)《数据准备技巧》中使用的直接营销数据集。这个数据集描述了一个二分类问题：客户是否会接受营销优惠，是或不是？它包含了超过41,000个标记的客户样本。让我们深入了解：
- en: Let's open SageMaker Studio. Create a new Python 3 notebook using the **Data
    Science** kernel, as shown in the following screenshot:![Figure 3.1 – Creating
    a notebook
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们打开 SageMaker Studio。使用**数据科学**内核创建一个新的 Python 3 笔记本，如下图所示：![图 3.1 – 创建一个笔记本
- en: '](img/B17705_03_001.jpg)'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_001.jpg)'
- en: Figure 3.1 – Creating a notebook
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.1 – 创建一个笔记本
- en: 'Now, let''s download and extract the dataset as follows:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们按以下步骤下载并提取数据集：
- en: '[PRE0]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In [*Chapter 2*](B17705_02_Final_JM_ePub.xhtml#_idTextAnchor030), *Handling
    Data Preparation Techniques*, we ran a feature engineering script with Amazon
    SageMaker Processing. We will do no such thing here: we simply upload the dataset
    as is to S3, into the **default bucket** created by SageMaker:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[*第 2 章*](B17705_02_Final_JM_ePub.xhtml#_idTextAnchor030)《数据处理技巧》中，我们通过 Amazon
    SageMaker Processing 运行了一个特征工程脚本。但在这里，我们不做这样的操作：我们只是将数据集原封不动地上传到 S3，上传到 SageMaker
    创建的**默认桶**中：
- en: '[PRE1]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The dataset will be available in S3 at the following location:'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集将可在 S3 中的以下位置获取：
- en: '[PRE2]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now, we click on the **Components and registries** icon in the left-hand vertical
    icon bar, as can be seen in the following screenshot. This opens the **Experiments**
    tab, and we click on the **Create Autopilot Experiment** button to create a new
    Autopilot job.![Figure 3.2 – Viewing experiments
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们点击左侧垂直图标栏中的**组件与注册表**图标，正如下图所示。这将打开**实验**标签页，我们点击**创建自动驾驶实验**按钮以创建一个新的自动驾驶任务。![图
    3.2 – 查看实验
- en: '](img/B17705_03_002.jpg)'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_002.jpg)'
- en: Figure 3.2 – Viewing experiments
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.2 – 查看实验
- en: The next screen is where we configure the job. Let's enter `my-first-autopilot-job`
    as the experiment name.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个屏幕是我们配置任务的地方。让我们输入`my-first-autopilot-job`作为实验名称。
- en: We set the location of the input dataset using the path returned in *step 3*.
    As can be seen in the following screenshot, we can either browse S3 buckets or
    enter the S3 location directly:![Figure 3.3 – Defining the input location
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用*第 3 步*返回的路径设置输入数据集的位置。如下图所示，我们可以浏览 S3 桶，或者直接输入 S3 位置：![图 3.3 – 定义输入位置
- en: '](img/B17705_03_003.jpg)'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_003.jpg)'
- en: Figure 3.3 – Defining the input location
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.3 – 定义输入位置
- en: The next step is to define the name of the **target attribute**, as shown in
    the following screenshot. The column storing the "yes" or "no" label is called
    "y".![Figure 3.4 – Defining the target attribute
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是定义**目标属性**的名称，如下图所示。存储“是”或“否”标签的列称为“y”。![图 3.4 – 定义目标属性
- en: '](img/B17705_03_004.jpg)'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_004.jpg)'
- en: Figure 3.4 – Defining the target attribute
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.4 – 定义目标属性
- en: As shown in the following screenshot, we set the S3 output location where job
    artifacts will be copied to. I use `s3://sagemaker-us-east-2-123456789012/sagemaker/DEMO-autopilot/output/`
    here, and you should, of course, update it with your own region and account number.![Figure
    3.5 – Defining the output location
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如下图所示，我们设置任务输出文件的位置，任务生成的工件将被复制到该位置。我在此使用 `s3://sagemaker-us-east-2-123456789012/sagemaker/DEMO-autopilot/output/`，当然，你应该用你自己的区域和账户编号来更新此位置。![图
    3.5 – 定义输出位置
- en: '](img/B17705_03_005.jpg)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_005.jpg)'
- en: Figure 3.5 – Defining the output location
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.5 – 定义输出位置
- en: 'We set the type of job we want to train, as shown in the following screenshot.
    Here, we select **Auto** in order to let SageMaker Autopilot figure out the problem
    type. Alternatively, we could select **Binary classification**, and pick our metric:
    **Accuracy**, **AUC**, or **F1** (the default setting).![Figure 3.6 – Setting
    the problem type'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们设置所需的任务类型，如下图所示。在这里，我们选择**自动**，让 SageMaker Autopilot 自动确定问题类型。或者，我们可以选择**二元分类**，并选择我们的指标：**准确率**、**AUC**
    或 **F1**（默认设置）。![图 3.6 – 设置问题类型
- en: '](img/B17705_03_006.jpg)'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_006.jpg)'
- en: Figure 3.6 – Setting the problem type
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.6 – 设置问题类型
- en: Finally, we decide whether we want to run a full job, or simply generate notebooks.
    We'll go with the former, as shown in the following screenshot. The latter would
    be a good option if we wanted to train and tweak the parameters manually. We also
    decide not to deploy the best model automatically for now.![Figure 3.7 – Running
    a complete experiment
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们决定是运行完整任务，还是仅生成笔记本。如果选择前者，则如下一图所示。如果选择后者，那么当我们希望手动训练并调整参数时，它将是一个不错的选择。我们还决定暂时不自动部署最佳模型。![图
    3.7 – 运行完整实验
- en: '](img/B17705_03_007.jpg)'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_007.jpg)'
- en: Figure 3.7 – Running a complete experiment
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.7 – 运行完整实验
- en: Optionally, in the **Advanced Settings** section, we would change the IAM role,
    set an encryption key for job artifacts, define the VPC where we'd like to launch
    job instances, and so on. Let's keep default values here.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，在**高级设置**部分，我们可以更改IAM角色，设置作业工件的加密密钥，定义我们希望启动作业实例的VPC等。这里我们保持默认值。
- en: 'The job setup is complete: all it took was this one screen. Then, we click
    on **Create Experiment**, and off it goes!'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 任务设置已完成：这一切只需要一个屏幕。然后，我们点击**创建实验**，任务就开始了！
- en: Monitoring a job
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控任务
- en: 'Once the job is launched, it goes through the three steps that we already discussed,
    which should take around 5 hours to complete. The new experiment is listed in
    the **Experiments** tab, and we can right-click **Describe AutoML Job** to describe
    its current status. This opens the following screen, where we can see the progress
    of the job:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦任务启动，它将经过我们已经讨论过的三个步骤，预计大约需要5小时完成。新实验会列在**实验**标签中，我们可以右键点击**描述AutoML任务**以查看其当前状态。这会打开如下屏幕，我们可以看到任务的进度：
- en: As expected, the job starts by analyzing data, as highlighted in the following
    screenshot:![Figure 3.8 – Viewing job progress
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如预期的那样，任务开始时会分析数据，如下面的截图所示：![图3.8 – 查看任务进度
- en: '](img/B17705_03_008.jpg)'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_008.jpg)'
- en: Figure 3.8 – Viewing job progress
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.8 – 查看任务进度
- en: 'About 10 minutes later, data analysis is complete, and the job moves on to
    feature engineering, where the input dataset will be transformed according to
    the steps defined in the candidate pipelines. As shown in the following screenshot,
    we can also see new two buttons in the top-right corner, pointing at the **candidate
    generation** and **data exploration** notebooks: don''t worry, we''ll take a deeper
    look at both later in the chapter.![Figure 3.9 – Viewing job progress'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大约10分钟后，数据分析完成，任务进入特征工程阶段，此时输入数据集将按照候选管道中定义的步骤进行转换。如下面的截图所示，我们还可以看到右上角新增了两个按钮，分别指向**候选生成**和**数据探索**笔记本：别担心，我们将在本章后面详细讲解这两者。![图3.9
    – 查看任务进度
- en: '](img/B17705_03_009.jpg)'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_009.jpg)'
- en: Figure 3.9 – Viewing job progress
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.9 – 查看任务进度
- en: Once feature engineering is complete, the job then moves on to model tuning,
    where candidate models are trained and tuned. As can be seen in the following
    screenshot, the first training jobs quickly show up in the **Trials** tab. A "trial"
    is the name SageMaker uses for a collection of related jobs, such as processing
    jobs, batch transform jobs, and training jobs. We can see the **Objective**, that
    is to say, the metric that the job tried to optimize (in this case, it's the F1
    score). We can sort jobs based on this metric, and the best tuning job so far
    is highlighted with a star.![Figure 3.10 – Viewing tuning jobs
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦特征工程完成，接下来的工作就是模型调优，在这一阶段，候选模型会被训练和调整。如下面的截图所示，第一个训练任务很快出现在**试验**标签中。 "试验"是SageMaker用来表示一组相关任务的名称，例如处理任务、批量转换任务和训练任务。我们可以看到**目标**，也就是任务试图优化的指标（在本例中是F1得分）。我们可以根据该指标对任务进行排序，当前最好的调优任务会被高亮显示并标注星标。![图3.10
    – 查看调优任务
- en: '](img/B17705_03_010.jpg)'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_010.jpg)'
- en: Figure 3.10 – Viewing tuning jobs
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.10 – 查看调优任务
- en: Once the AutoPilot job is complete, your screen should look similar to the following
    screenshot. Here, the top model has reached an F1 score of 0.8031.![Figure 3.11
    – Viewing results
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦AutoPilot任务完成，你的屏幕应该会类似于以下截图。在这里，顶部模型达到了0.8031的F1得分。![图3.11 – 查看结果
- en: '](img/B17705_03_011.jpg)'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_011.jpg)'
- en: Figure 3.11 – Viewing results
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.11 – 查看结果
- en: If we select the best job and right-click **Open in model details**, we can
    see a model explainability graph showing us the most important features, as can
    be seen in the following screenshot. This graph is based on global **SHapley Additive
    exPlanations** (**SHAP**) ([https://github.com/slundberg/shap](https://github.com/slundberg/shap))
    values computed automatically by AutoPilot.![Figure 3.12 – Viewing the most important
    features
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们选择最佳任务并右键点击**打开模型详细信息**，我们可以看到一个模型可解释性图，显示了最重要的特征，如下截图所示。该图基于由AutoPilot自动计算的全局**SHapley加法解释**（**SHAP**）值
    ([https://github.com/slundberg/shap](https://github.com/slundberg/shap))。![图3.12
    – 查看最重要特征
- en: '](img/B17705_03_012.jpg)'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_012.jpg)'
- en: Figure 3.12 – Viewing the most important features
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.12 – 查看最重要特征
- en: 'In the **Artifacts** tab, we can also see a list of training artifacts and
    parameters involved in building the model: input data, training and validation
    splits, transformed datasets, feature engineering code, the algorithm (XGBoost
    in my case), and more.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **Artifacts**（工件）标签中，我们还可以看到构建模型时涉及的训练工件和参数的列表：输入数据、训练和验证分割、转换后的数据集、特征工程代码、算法（在我的案例中是
    XGBoost）等。
- en: At this point, we could simply deploy the best job, but instead, let's compare
    the top 10 ones using the visualization tools built into SageMaker Studio.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们可以直接部署最佳作业，但我们将使用 SageMaker Studio 内置的可视化工具来比较前 10 个作业。
- en: Comparing jobs
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较作业
- en: 'A single SageMaker Autopilot job trains 250 jobs by default. Over time, you
    may end up with tens of thousands of jobs, and you may wish to compare their properties.
    Let''s see how:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，单个 SageMaker Autopilot 作业会训练 250 个作业。随着时间的推移，你可能会有成千上万个作业，并且你可能希望比较它们的属性。让我们看看如何操作：
- en: Going to the **Experiments** tab on the left, we locate our job and right-click
    **Open in trial component list**, as can be seen in the following screenshot:![Figure
    3.13 – Opening the list of trials
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧的 **Experiments** 标签页中，我们定位到我们的作业，右键点击**在试验组件列表中打开**，如下图所示：![图 3.13 – 打开试验列表
- en: '](img/B17705_03_013.jpg)'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_013.jpg)'
- en: Figure 3.13 – Opening the list of trials
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.13 – 打开试验列表
- en: This opens **Trial Component List**, as shown in the following screenshot.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将打开**试验组件列表**，如下图所示。
- en: 'We open the **Table Properties** panel on the right by clicking on the icon
    representing a cog, and we untick everything except **Experiment name**, **Trial
    component name**, and **ObjectiveMetric**. In the main panel, we sort jobs by
    descending objective metrics by clicking on the arrow. We hold down the *Shift*
    key and click the top 10 jobs to select them, as shown in the following screenshot:'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们点击右侧的齿轮图标打开 **表格属性** 面板，然后取消勾选除 **Experiment name**（实验名称）、**Trial component
    name**（试验组件名称）和 **ObjectiveMetric**（目标指标）以外的所有选项。在主面板中，我们通过点击箭头将作业按目标指标降序排序。按住*Shift*键并点击前
    10 个作业进行选择，如下图所示：
- en: '![Figure 3.14 – Comparing jobs'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.14 – 比较作业'
- en: '](img/B17705_03_014.jpg)'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_014.jpg)'
- en: Figure 3.14 – Comparing jobs
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.14 – 比较作业
- en: Then, we click on the **Add chart** button. This opens a new view that can be
    seen in the following screenshot. Click inside the chart box at the bottom to
    open the **Chart properties** panel on the right.![Figure 3.15 – Building a chart
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们点击**添加图表**按钮。这将打开一个新的视图，见下图所示。点击图表框底部以打开右侧的**图表属性**面板。![图 3.15 – 创建图表
- en: '](img/B17705_03_015.jpg)'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_015.jpg)'
- en: Figure 3.15 – Building a chart
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.15 – 创建图表
- en: As our training jobs are very short (about a minute), there won't be enough
    data for **Time series** charts, so let's select **Summary statistics** instead.
    We're going to build a **scatter plot**, putting the eta and lambda hyperparameters
    in perspective, as shown in the following screenshot. We also color data points
    with our trial names.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于我们的训练作业非常短（大约一分钟），因此没有足够的数据生成**时间序列**图表，所以我们选择**汇总统计**。我们将构建一个**散点图**，将 eta
    和 lambda 超参数进行对比，如下图所示。我们还将数据点按我们的试验名称进行着色。
- en: '![Figure 3.16 – Creating a chart'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.16 – 创建图表'
- en: '](img/B17705_03_016.jpg)'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_016.jpg)'
- en: Figure 3.16 – Creating a chart
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.16 – 创建图表
- en: Zooming in on the following chart, we can quickly visualize our jobs and their
    respective parameters. We could build additional charts showing the impact of
    certain hyperparameters on accuracy. This would help us shortlist a few models
    for further testing. Maybe we would end up considering several of them for ensemble
    prediction.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 放大下图，我们可以快速地可视化我们的作业及其相应的参数。我们还可以构建其他图表，展示某些超参数对准确率的影响。这将帮助我们筛选出一些模型进行进一步的测试。也许我们最终会考虑将多个模型用于集成预测。
- en: '![Figure 3.17 – Plotting hyperparameters'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.17 – 绘制超参数图'
- en: '](img/B17705_03_017.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17705_03_017.jpg)'
- en: Figure 3.17 – Plotting hyperparameters
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.17 – 绘制超参数图
- en: The next step is to deploy a model and start testing it.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是部署模型并开始测试。
- en: Deploying and invoking a model
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署和调用模型
- en: 'SageMaker Studio makes it extremely easy to deploy a model. Let''s see how:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Studio 使得部署模型变得非常简单。让我们看看如何操作：
- en: Going back to the **Experiments** tab, we right-click the name of our experiment
    and select **Describe AutoML Job**. This opens the list of training jobs. Making
    sure that they're sorted by descending objective, we select the best one (it's
    highlighted with a star), as shown in the screenshot that follows, and then we
    click on the **Deploy model** button:![Figure 3.18 – Deploying a model
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回到**实验**标签页，我们右键点击实验名称并选择**描述AutoML作业**。这会打开训练作业列表。确保它们按目标值降序排列，我们选择最好的那个（它会用星标高亮显示），如下图所示，然后点击**部署模型**按钮：![图
    3.18 – 部署模型
- en: '](img/B17705_03_018.jpg)'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_018.jpg)'
- en: Figure 3.18 – Deploying a model
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.18 – 部署模型
- en: Under `my-first-autopilot-endpoint`), leave all other settings as is, and click
    on `ml.m5.xlarge` instance:![Figure 3.19 – Deploying a model
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`my-first-autopilot-endpoint`下，保持其他设置不变，点击`ml.m5.xlarge`实例：![图 3.19 – 部署模型
- en: '](img/B17705_03_019.jpg)'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_019.jpg)'
- en: Figure 3.19 – Deploying a model
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.19 – 部署模型
- en: Heading to the **Endpoints** section in the left-hand vertical panel, we can
    see the endpoint being created. As shown in the following screenshot, it will
    initially be in the **Creating** state. After a few minutes, it's **In service**:![Figure
    3.20 – Creating an endpoint
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入左侧垂直面板中的**端点**部分，我们可以看到正在创建的端点。如下面的截图所示，最初它会处于**创建中**状态。几分钟后，它会变为**在服务中**：![图
    3.20 – 创建端点
- en: '](img/B17705_03_020.jpg)'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17705_03_020.jpg)'
- en: Figure 3.20 – Creating an endpoint
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.20 – 创建端点
- en: 'Moving to a Jupyter notebook (we can reuse the one we wrote to download the
    dataset), we define the name of the endpoint, and a sample to predict. Here, I''m
    using the first line of the dataset:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到Jupyter笔记本（我们可以重复使用写来下载数据集的那个），我们定义端点的名称和要预测的样本。这里，我使用的是数据集的第一行：
- en: '[PRE3]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We create a `boto3` client for the SageMaker runtime. This runtime contains
    a single API, `invoke_endpoint` ([https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime.html](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime.html)).
    This makes it efficient to embed in client applications that just need to invoke
    models:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为SageMaker运行时创建一个`boto3`客户端。这个运行时包含一个API，`invoke_endpoint` ([https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime.html](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime.html))。这使得它非常高效，适合嵌入到只需要调用模型的客户端应用程序中：
- en: '[PRE4]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We send the sample to the endpoint, also passing the input and output content
    types:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将样本发送到端点，同时传递输入和输出内容类型：
- en: '[PRE5]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We decode the prediction and print it – this customer is not likely to accept
    the offer:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们解码预测结果并打印出来——该客户不太可能接受该提议：
- en: '[PRE6]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This sample is predicted as a "no":'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个样本被预测为“否”：
- en: '[PRE7]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'When we''re done testing the endpoint, we should delete it to avoid unnecessary
    charges. We can do this with the `delete_endpoint` API in `boto3` ([https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.delete_endpoint](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.delete_endpoint)):'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们完成测试端点时，我们应该删除它以避免不必要的费用。我们可以通过`boto3`中的`delete_endpoint` API来实现这一点([https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.delete_endpoint](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.delete_endpoint))：
- en: '[PRE8]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Congratulations! You've successfully built, trained, and deployed your first
    machine learning model on Amazon SageMaker. That was pretty simple, wasn't it?
    The only code we wrote was to download the dataset and to predict with our model.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经成功地在Amazon SageMaker上构建、训练并部署了你的第一个机器学习模型。是不是很简单？我们写的唯一代码是下载数据集并用模型进行预测。
- en: Using **SageMaker Studio** is a great way to quickly experiment with a new dataset,
    and also to let fewer technical users build models on their own. Advanced users
    can also add their own custom images to SageMaker Studio, and they'll find more
    details at [https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi.html](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi.html).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**SageMaker Studio**是快速尝试新数据集的好方法，也让技术要求较低的用户可以独立构建模型。高级用户还可以将自己的自定义镜像添加到SageMaker
    Studio，更多详细信息请参考[https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi.html](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-byoi.html)。
- en: Now, let's see how we can use SageMaker Autopilot programmatically with the
    **SageMaker SDK**.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何通过**SageMaker SDK**以编程方式使用SageMaker Autopilot。
- en: Using the SageMaker Autopilot SDK
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SageMaker Autopilot SDK
- en: The Amazon SageMaker SDK includes a simple API for SageMaker Autopilot. You
    can find its documentation at [https://sagemaker.readthedocs.io/en/stable/automl.html](https://sagemaker.readthedocs.io/en/stable/automl.html).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker SDK 包括一个简单的 API 用于 SageMaker Autopilot。你可以在 [https://sagemaker.readthedocs.io/en/stable/automl.html](https://sagemaker.readthedocs.io/en/stable/automl.html)
    查阅文档。
- en: In this section, you'll learn how to use this API to train a model on the same
    dataset as in the previous section.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何使用此 API 在与上一节相同的数据集上训练模型。
- en: Launching a job
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动任务
- en: 'The SageMaker SDK makes it extremely easy to launch an Autopilot job – just
    upload your data in S3, and call a single API! Let''s see how:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker SDK 使启动 Autopilot 任务变得异常简单——只需将数据上传到 S3，然后调用一个 API！让我们来看看如何操作：
- en: 'First, we import the SageMaker SDK:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入 SageMaker SDK：
- en: '[PRE9]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then, we download the dataset:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，我们下载数据集：
- en: '[PRE10]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, we upload the dataset to S3:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将数据集上传到 S3：
- en: '[PRE11]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We then configure the AutoML job, which only takes one line of code. We define
    the **target attribute** (remember, that column is named "y"), and where to store
    training artifacts. Optionally, we can also set a maximum runtime for the job,
    a maximum runtime per job, or reduce the number of candidate models that will
    be tuned. Please note that restricting the job''s duration too much is likely
    to impact its accuracy. For development purposes, this isn''t a problem, so let''s
    cap our job at one hour, or 250 tuning jobs (whichever limit it hits first):'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，我们配置 AutoML 任务，这只需要一行代码。我们定义了**目标属性**（记住，这一列的名称是“y”），以及训练产物的存储位置。可选地，我们还可以设置任务的最大运行时间、每个任务的最大运行时间，或者减少将要调优的候选模型数量。请注意，限制任务持续时间过多可能会影响其准确性。对于开发目的而言，这不是问题，因此我们将任务时长限制为一小时，或者
    250 个调优任务（以先到为准）：
- en: '[PRE12]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next, we launch the Autopilot job, passing it the location of the training
    set. We turn logs off (who wants to read hundreds of tuning logs?), and we set
    the call to non-blocking, as we''d like to query the job status in the next cells:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们启动 Autopilot 任务，传递给它训练集的位置。我们关闭日志（谁想阅读数百个调优日志呢？），并将调用设置为非阻塞，因为我们希望在接下来的单元格中查询任务状态：
- en: '[PRE13]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The job starts right away. Now let's see how we can monitor its status.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 任务会立刻开始。现在让我们看看如何监控它的状态。
- en: Monitoring a job
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控任务
- en: 'While the job is running, we can use the `describe_auto_ml_job()` API to monitor
    its progress:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在任务运行时，我们可以使用`describe_auto_ml_job()` API 来监控其进度：
- en: 'For example, the following code will check the job''s status every 60 seconds
    until the data analysis step completes:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 例如，以下代码将每 60 秒检查一次任务的状态，直到数据分析步骤完成：
- en: '[PRE14]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once the data analysis is complete, the two autogenerated notebooks are available.
    We can find their location using the same API:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦数据分析完成，两个自动生成的 notebook 就会可用。我们可以使用相同的 API 查找它们的位置：
- en: '[PRE15]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This prints out the S3 paths for the two notebooks:'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这会打印出两个 notebook 的 S3 路径：
- en: '[PRE16]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Using the AWS CLI, we can copy the two notebooks locally. We''ll take a look
    at them later in this chapter:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 AWS CLI，我们可以将两个 notebook 下载到本地。我们稍后将在本章中查看它们：
- en: '[PRE17]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: While the feature engineering runs, we can wait for completion using the same
    code snippet as the preceding, looping while `job_sec_status` is equal to `FeatureEngineering`.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当特征工程运行时，我们可以使用与之前相同的代码片段等待完成，循环判断 `job_sec_status` 是否等于 `FeatureEngineering`。
- en: 'Once model tuning is complete, we can very easily find the best candidate:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型调优完成，我们可以非常轻松地找到最佳候选模型：
- en: '[PRE18]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This prints out the name of the best tuning job, along with its validation
    accuracy:'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这会输出最佳调优任务的名称及其验证准确度：
- en: '[PRE19]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Then, we can deploy and test the model using the SageMaker SDK. We've covered
    a lot of ground already, so let's save that for future chapters, where we'll revisit
    this example.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用 SageMaker SDK 部署并测试模型。我们已经涵盖了很多内容，所以将这部分留到后续章节，我们会重新回顾这个例子。
- en: Cleaning up
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清理
- en: 'SageMaker Autopilot creates many underlying artifacts, such as dataset splits,
    pre-processing scripts, pre-processed datasets, and models. If you''d like to
    clean up completely, the following code snippet will do that. Of course, you could
    also use the AWS CLI:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Autopilot 创建了许多底层产物，例如数据集拆分、预处理脚本、预处理数据集和模型。如果你想完全清理，下面的代码片段可以做到这一点。当然，你也可以使用
    AWS CLI：
- en: '[PRE20]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now that we know how to train models using both the SageMaker Studio GUI and
    the SageMaker SDK, let's take a look under the hood. Engineers like to understand
    how things really work, right?
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经知道如何使用 SageMaker Studio GUI 和 SageMaker SDK 训练模型，让我们深入了解其背后的原理。工程师们喜欢理解事物是如何真正工作的，对吧？
- en: Diving deep on SageMaker Autopilot
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入了解 SageMaker Autopilot
- en: In this section, we're going to learn in detail how SageMaker Autopilot processes
    data and trains models. If this feels too advanced for now, you're welcome to
    skip this material. You can always revisit it later once you've gained more experience
    with the service.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将详细了解 SageMaker Autopilot 如何处理数据并训练模型。如果现在感觉太高级，可以跳过这些内容。等你对该服务有了更多经验后，可以随时回头再看。
- en: First, let's look at the artifacts that SageMaker Autopilot produces.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们来看一下 SageMaker Autopilot 生成的工件。
- en: The job artifacts
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作业工件
- en: 'Listing our S3 bucket confirms the existence of many different artifacts:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 列出我们的 S3 存储桶可以确认存在许多不同的工件：
- en: '[PRE21]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We can see many new prefixes. Let''s figure out what''s what:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到许多新的前缀。让我们来弄明白它们分别代表什么：
- en: '[PRE22]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The `preprocessed-data/tuning_data` prefix contains the training and validation
    splits generated from the input dataset. Each split is broken down further into
    small CSV chunks.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`preprocessed-data/tuning_data` 前缀包含从输入数据集生成的训练和验证拆分。每个拆分进一步被分解成小的 CSV 块。'
- en: The `sagemaker-automl-candidates` prefix contains 10 data pre-processing scripts
    (`dpp[0-9].py`), one for each pipeline. It also contains the code to train them
    (`trainer.py`) on the input dataset, and the code to process the input dataset
    with each one of the 10 resulting models (`sagemaker_serve.py`). Last but not
    least, it contains the autogenerated notebooks.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sagemaker-automl-candidates` 前缀包含 10 个数据预处理脚本（`dpp[0-9].py`），每个管道一个。它还包含训练它们的代码（`trainer.py`），以及使用这
    10 个生成模型中的每一个处理输入数据集的代码（`sagemaker_serve.py`）。最后但同样重要的是，它包含自动生成的笔记本。'
- en: The `data-processor-models` prefix contains the 10 data processing models trained
    by the `dpp` scripts.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data-processor-models` 前缀包含通过 `dpp` 脚本训练的 10 个数据处理模型。'
- en: The `transformed-data` prefix contains the 10 processed versions of the training
    and validation splits.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformed-data` 前缀包含训练和验证拆分的 10 个处理版本。'
- en: The `tuning` prefix contains the actual models trained during the **Model Tuning**
    step.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tuning` 前缀包含在**模型调优**步骤中训练的实际模型。'
- en: The `documentation` prefix contains the explainability report.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`documentation` 前缀包含可解释性报告。'
- en: 'The following diagram summarizes the relationship between these artifacts:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表总结了这些工件之间的关系：
- en: '![Figure 3.21 – Summing up the Autopilot process'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.21 – 总结 Autopilot 过程'
- en: '](img/B17705_03_021.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17705_03_021.jpg)'
- en: Figure 3.21 – Summing up the Autopilot process
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.21 – 总结 Autopilot 过程
- en: In the next sections, we'll take a look at the two **autogenerated notebooks**,
    which are one of the most important features in SageMaker Autopilot.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将看一下两个**自动生成的笔记本**，它们是 SageMaker Autopilot 中最重要的功能之一。
- en: The data exploration notebook
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据探索笔记本
- en: This notebook is available in Amazon S3 once the data analysis step is complete.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据分析步骤完成，此笔记本可以在 Amazon S3 上使用。
- en: 'The first section, seen in the following screenshot, simply displays a sample
    of the dataset:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 第一部分，如下图所示，简单地显示了数据集的一个样本：
- en: '![Figure 3.22 – Viewing dataset statistics'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.22 – 查看数据集统计信息'
- en: '](img/B17705_03_022.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17705_03_022.jpg)'
- en: Figure 3.22 – Viewing dataset statistics
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.22 – 查看数据集统计信息
- en: 'Shown in the following screenshot, the second section focuses on column analysis:
    percentages of missing values, counts of unique values, and descriptive statistics.
    For instance, it appears that the `pdays` field has both a maximum value and a
    median of 999, which looks suspicious. As explained in the previous chapter, 999
    is indeed a placeholder value, meaning that a customer has never been contacted
    before.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如下截图所示，第二部分重点分析列：缺失值的百分比、唯一值的计数和描述性统计数据。例如，`pdays` 字段的最大值和中位数均为 999，这看起来很可疑。如上一章所述，999
    确实是一个占位符值，意味着客户之前从未被联系过。
- en: '![Figure 3.23 – Viewing dataset statistics'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.23 – 查看数据集统计信息'
- en: '](img/B17705_03_023.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17705_03_023.jpg)'
- en: Figure 3.23 – Viewing dataset statistics
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.23 – 查看数据集统计信息
- en: As you can see, this notebook saves us the trouble of computing these statistics
    ourselves, and we can use them to quickly check that the dataset is what we expect.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个笔记本为我们省去了计算这些统计数据的麻烦，我们可以利用它们快速检查数据集是否符合预期。
- en: Now, let's look at the second notebook. As you will see, it's extremely insightful!
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下第二个笔记本。正如你将看到的，它非常具有洞察力！
- en: The candidate generation notebook
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 候选生成笔记本
- en: This notebook contains the definition of the 10 candidate pipelines, and how
    they're trained. This is a **runnable notebook**, and advanced practitioners can
    use it to replay the AutoML process, and keep refining their experiment. Please
    note that this is totally optional! It's perfectly OK to deploy the top model
    directly and start testing it.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 本笔记本包含了10个候选管道的定义，以及它们的训练方式。这是一个**可运行的笔记本**，高级实践者可以利用它重现AutoML过程，并不断优化实验。请注意，这完全是可选的！直接部署最佳模型并开始测试也是完全可以的。
- en: 'Having said that, let''s run one of the pipelines manually:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，让我们手动运行其中一个管道：
- en: We open the notebook and save a read-write copy by clicking on the **Import
    notebook** link in the top-right corner.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们打开笔记本并通过点击右上角的**导入笔记本**链接保存一个可读写的副本。
- en: Then, we run the cells in the **SageMaker Setup** section to import all the
    required artifacts and parameters.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在**SageMaker设置**部分运行单元格，以导入所有所需的工件和参数。
- en: 'Moving to the **Candidate Pipelines** section, we create a runner object that
    will launch jobs for selected candidate pipelines:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移动到**候选管道**部分，我们创建一个运行器对象，它将为选定的候选管道启动作业：
- en: '[PRE23]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, we add the first pipeline (`dpp0`). The notebook tells us: "*This data
    transformation strategy first transforms ''numeric'' features using* `RobustImputer`
    *(converts missing values to nan) and ''categorical'' features using* `ThresholdOneHotEncoder`*.
    It merges all the generated features and applies* `RobustStandardScaler`*. The
    transformed data will be used to tune an XGBoost model*". We just need to run
    the following cell to add it:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，我们添加第一个管道（`dpp0`）。笔记本告诉我们：“*此数据转换策略首先使用`RobustImputer`转换'数值'特征（将缺失值转换为nan），然后使用`ThresholdOneHotEncoder`转换'类别'特征。它将所有生成的特征合并并应用`RobustStandardScaler`。转换后的数据将用于调整XGBoost模型*。”我们只需运行以下单元格来添加它：
- en: '[PRE24]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: If you're curious about the implementation of `RobustImputer` or `ThresholdOneHotEncoder`,
    hyperlinks take you to the appropriate source file in the `sagemaker_sklearn_extension`
    module (https://github.com/aws/sagemaker-scikit-learn-extension/).
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你对`RobustImputer`或`ThresholdOneHotEncoder`的实现感到好奇，超链接将引导你到`sagemaker_sklearn_extension`模块中的相关源文件（https://github.com/aws/sagemaker-scikit-learn-extension/）。
- en: This way, you can understand exactly how data has been processed. As these objects
    are based on scikit-learn objects, they should quickly look very familiar. For
    instance, we can see that `RobustImputer` is built on top of `sklearn.impute.SimpleImputer`,
    with added functionality. Likewise, `ThresholdOneHotEncoder` is an extension of
    `sklearn.preprocessing.OneHotEncoder`.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这样，你可以准确理解数据是如何处理的。由于这些对象是基于scikit-learn对象构建的，它们应该会很快变得非常熟悉。例如，我们可以看到`RobustImputer`是建立在`sklearn.impute.SimpleImputer`之上的，并增加了额外的功能。同样，`ThresholdOneHotEncoder`是`sklearn.preprocessing.OneHotEncoder`的扩展。
- en: Taking a quick look at other pipelines, we see different processing strategies
    and algorithms. You should see the **Linear Learner** algorithm used in some pipelines.
    It's one of the **built-in algorithms** in SageMaker, and we'll cover it in the
    next chapter. You should also see the **mlp** algorithm, which is based on neural
    networks.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 浏览其他管道时，我们可以看到不同的处理策略和算法。你应该能看到在一些管道中使用的**线性学习者**算法。它是SageMaker中的**内置算法**之一，我们将在下一章进行讲解。你还应该能看到基于神经网络的**mlp**算法。
- en: Scrolling down, we get to the `dpp0.py` script and that the model will be trained
    using the XGBoost algorithm.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动，我们进入了`dpp0.py`脚本，并看到该模型将使用XGBoost算法进行训练。
- en: 'Clicking on the **dpp0** hyperlink opens the script. As expected, we see that
    it builds a scikit-learn transformer pipeline (not to be confused with the SageMaker
    pipeline composed of pre-processing and training jobs). Missing values are imputed
    in the numerical features, and the categorical features are one-hot encoded. Then,
    all features are scaled and the labels are encoded:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**dpp0**超链接会打开脚本。正如预期的那样，我们看到它构建了一个scikit-learn变换器管道（不要与由预处理和训练作业组成的SageMaker管道混淆）。数值特征的缺失值被填补，而类别特征则被进行独热编码。接下来，所有特征都被缩放，标签也被编码：
- en: '[PRE25]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Back in the notebook, we launch this script in the **Run Data Transformation
    Steps** section:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回到笔记本中，我们在**运行数据转换步骤**部分启动此脚本：
- en: '[PRE26]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This creates two sequential SageMaker jobs and their artifacts are stored in
    a new prefix created for the notebook run:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将创建两个顺序执行的SageMaker作业，其工件将存储在为笔记本运行创建的新前缀中：
- en: '[PRE27]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Going back to SageMaker Studio, let's find out more about these two jobs. Starting
    from the `my-first-a-notebook-run-24-13-17-22-dpp0-train-24-13-38-38-aws-training-job`
    and `my-first-a-notebook-run-24-13-17-22-dpp0-transform-24-13-38-38-aws-transform-job`.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回到 SageMaker Studio，让我们进一步了解这两个作业。从`my-first-a-notebook-run-24-13-17-22-dpp0-train-24-13-38-38-aws-training-job`和`my-first-a-notebook-run-24-13-17-22-dpp0-transform-24-13-38-38-aws-transform-job`开始。
- en: 'Double-clicking a job name opens the **Open in trial details** window, as shown
    in the following screenshot. It tells us everything there is to know about the
    job: the parameters, location of artifacts, and more:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 双击作业名称会打开**试验详情**窗口，如下截图所示。它告诉我们关于作业的所有信息：参数、工件的位置等等：
- en: '![Figure 3.25 – Describing a trial'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.25 – 描述一个试验'
- en: '](img/B17705_03_025.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17705_03_025.jpg)'
- en: Figure 3.25 – Describing a trial
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.25 – 描述一个试验
- en: Once data processing is complete, the notebook proceeds with **automatic model
    tuning** and **model deployment**. We haven't yet discussed these topics, so let's
    stop there for now. I encourage you to go through the rest of the notebook once
    you're comfortable with them.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据处理完成，笔记本将继续进行**自动模型调优**和**模型部署**。我们还没有讨论这些主题，所以现在先停在这里。等你对这些内容熟悉后，建议你继续阅读笔记本的其余部分。
- en: Summary
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: As you can see, Amazon SageMaker Autopilot makes it easy to build, train, and
    optimize machine learning models for beginners and advanced users alike.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，Amazon SageMaker Autopilot 使得初学者和高级用户都能轻松构建、训练和优化机器学习模型。
- en: In this chapter, you learned about the different steps of an Autopilot job,
    and what they mean from a machine learning perspective. You also learned how to
    use both the SageMaker Studio GUI and the SageMaker SDK to build a classification
    model with minimal coding. Then, we dived deep into the autogenerated notebooks,
    which give you full control and transparency over the modeling processing. In
    particular, you learned how to run the candidate generation notebook manually
    to replay all the steps involved.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了 Autopilot 作业的不同步骤，以及它们从机器学习角度的含义。你还学会了如何使用 SageMaker Studio 图形用户界面和
    SageMaker SDK 构建一个分类模型，几乎不需要编写代码。然后，我们深入探讨了自动生成的笔记本，这些笔记本让你对建模过程拥有完全的控制权和透明度。特别是，你学会了如何手动运行候选生成笔记本，以重播所有涉及的步骤。
- en: In the next chapter, you will learn how to use the built-in algorithms in Amazon
    SageMaker to train models for a variety of machine learning problems.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何使用 Amazon SageMaker 中的内置算法，训练模型以解决各种机器学习问题。
