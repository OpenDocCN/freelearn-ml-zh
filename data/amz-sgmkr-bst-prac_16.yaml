- en: 'Chapter 12: Machine Learning Automated Workflows'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章：机器学习自动化工作流程
- en: For **machine learning** (**ML**) models that are deployed to production environments,
    it's important to establish a consistent and repeatable process to retrain, deploy,
    and operate these models. This becomes increasingly important as you scale the
    number of ML models running in production. The **machine learning development
    lifecycle** (**ML Lifecycle)** brings with it some unique challenges in operationalizing
    ML workflows. This will be discussed in this chapter. We will also discuss common
    patterns to not only automate your ML workflows, but also implement **continuous
    integration** (**CI**) and **continuous delivery**/**deployment** (**CD**) practices
    for your ML pipelines.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 对于部署到生产环境中的**机器学习**（**ML**）模型，建立一致且可重复的过程来重新训练、部署和操作这些模型非常重要。随着在生产环境中运行的ML模型数量的增加，这一点变得越来越重要。**机器学习开发生命周期**（**ML生命周期**）在实施ML工作流程时带来了一些独特的挑战。这一点将在本章中讨论。我们还将讨论常见的模式，不仅自动化ML工作流程，而且为ML管道实施**持续集成**（**CI**）和**持续交付**/**部署**（**CD**）实践。
- en: Although we will cover various options for automating your ML workflows and
    building CI/CD pipelines for ML in this chapter, we will focus particularly on
    detailed implementation patterns using Amazon SageMaker Pipelines and Amazon SageMaker
    projects. SageMaker Pipelines is purpose-built for activities that include the
    automation of the steps needed to build a model, such as **data preparation**,
    **model training**, and **model evaluation** tasks. SageMaker projects build on
    SageMaker Pipelines by incorporating CI/CD practices into your ML pipelines. SageMaker
    projects utilize SageMaker Pipelines in combination with the SageMaker model registry
    to build out end-to-end ML pipelines that also incorporate CI/CD practices such
    as source control, version management, and automated deployments.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们将在本章中涵盖自动化ML工作流程和构建ML的CI/CD管道的各种选项，但我们特别关注使用Amazon SageMaker Pipelines和Amazon
    SageMaker项目进行详细实现模式。SageMaker Pipelines专为包括自动化构建模型所需的步骤的活动而设计，例如**数据准备**、**模型训练**和**模型评估**任务。SageMaker项目通过将CI/CD实践纳入您的ML管道来构建在SageMaker
    Pipelines的基础上。SageMaker项目利用SageMaker Pipelines结合SageMaker模型注册表构建端到端ML管道，这些管道还纳入了CI/CD实践，如源代码控制、版本管理和自动化部署。
- en: 'In this chapter, we''ll cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Considerations for automating your SageMaker ML workflows
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化SageMaker ML工作流程的考虑因素
- en: Building ML workflows with Amazon SageMaker Pipelines
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Amazon SageMaker Pipelines构建ML工作流程
- en: Creating CI/CD ML pipelines using Amazon SageMaker projects
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Amazon SageMaker项目创建CI/CD ML管道
- en: Considerations for automating your SageMaker ML workflows
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化SageMaker ML工作流程的考虑因素
- en: In this section, we'll review a typical ML workflow that includes the basic
    steps for model building and deploy activities. Understanding the key SageMaker
    inputs and artifacts for each step is important in building automated workflows,
    regardless of the automation or workflow tooling you choose to employ.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾一个典型的ML工作流程，包括模型构建和部署活动的基本步骤。理解每个步骤的关键SageMaker输入和工件对于构建自动化工作流程非常重要，无论您选择使用哪种自动化或工作流程工具。
- en: This information was covered in [*Chapter 8*](B17249_08_Final_JM_ePub.xhtml#_idTextAnchor151),
    *Manage Models at Scale Using a Model Registry*. Therefore, if you have not yet
    read that chapter it's recommended to do so prior to continuing with this chapter.
    We'll build on that information and cover high-level considerations and guidance
    for building out automated workflows and CI/CD pipelines for SageMaker workflows.
    We'll also briefly cover the common AWS native service options when building automated
    workflows and CI/CD ML pipelines.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 此信息已在[*第8章*](B17249_08_Final_JM_ePub.xhtml#_idTextAnchor151)中介绍，*使用模型注册表按比例管理模型*。因此，如果您尚未阅读该章节，建议在继续阅读本章之前先阅读。我们将在此基础上构建信息，并涵盖构建SageMaker工作流程的自动化工作流程和CI/CD管道的高级考虑因素和指导。我们还将简要介绍在构建自动化工作流程和CI/CD
    ML管道时常用的AWS原生服务选项。
- en: Typical ML workflows
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 典型的ML工作流程
- en: An ML workflow contains all the steps required to build an ML model for an ML
    use case, followed by the steps needed to deploy and operate the model in production.
    *Figure 12.1* shows a typical ML workflow that includes model build and model
    deploy steps. Each step within the workflow often has a number of associated tasks.
    As an example, data preparation can include multiple tasks needed to transform
    data into a format that is consistent with your ML algorithm.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一个机器学习工作流程包含构建机器学习模型所需的全部步骤，随后是部署和在生产环境中运行该模型所需的步骤。*图12.1*展示了包含模型构建和模型部署步骤的典型机器学习工作流程。工作流程中的每一步通常都有多个相关任务。例如，数据准备可能包括将数据转换成与你的机器学习算法一致格式的多个任务。
- en: When we look at automating the end-to-end ML workflow, we look to automate the
    tasks included within a step, as well as how to orchestrate the sequence and timing
    of steps into an end-to-end pipeline. As a result, knowing the key inputs for
    each step, as well as the expected output or artifact of a step, is key in building
    end-to-end pipelines.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑自动化端到端的机器学习工作流程时，我们寻求自动化步骤中包含的任务，以及如何编排步骤的顺序和时机到一个端到端的管道中。因此，了解每一步的关键输入以及步骤的预期输出或工件对于构建端到端管道至关重要。
- en: Additionally, model development is an iterative process. It may therefore take
    many experiments until you're able to find a candidate model that meets your model
    performance criteria. As a result, it's common to continue to experiment in a
    data science sandbox environment until you find a candidate model to register
    into a model registry. This would indicate that the model is ready to deploy to
    one or more target environments for additional testing, followed by deployment
    to a production environment.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，模型开发是一个迭代的过程。因此，可能需要多次实验才能找到一个满足模型性能标准的候选模型。因此，在找到可以注册到模型注册表的候选模型之前，通常会在数据科学沙盒环境中继续进行实验。这表明模型已准备好部署到一个或多个目标环境进行进一步测试，然后部署到生产环境。
- en: 'Refer to the following figure for an example of a typical workflow:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 参考以下图例，了解典型工作流程的示例：
- en: '![Figure 12.1 – Typical ML workflow'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图12.1 – 典型机器学习工作流程'
- en: '](img/B17249_12_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![图B17249_12_01.jpg](img/B17249_12_01.jpg)'
- en: Figure 12.1 – Typical ML workflow
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 – 典型机器学习工作流程
- en: 'After the model is deployed, there may also be additional tasks required to
    integrate the model with existing client applications. There may also be tasks
    required to create a more complex inference workflow that includes multiple models
    and tasks required for inference. Finally, there would still be tasks required
    to operate that model. Although the *Operate* step comes at the end, the activities
    that need to be performed for the ongoing operation of that model need to be considered
    early on in the process. This is in order to include all necessary tasks within
    your automated workflow, as well as ensure key metrics are captured, and available
    for key personas. In addition, this allows you to set up alerts as needed. This
    includes activities such as the following:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部署后，还可能需要额外的任务来将模型与现有的客户端应用程序集成。还可能需要创建一个更复杂的推理工作流程，该工作流程包括多个模型和推理所需的任务。最后，仍需要执行操作该模型的任务。尽管*操作*步骤位于最后，但需要考虑在早期过程中执行该模型持续运行所需的活动。这是为了确保在自动化工作流程中包含所有必要的任务，以及确保关键指标被捕获并可供关键角色使用。此外，这还允许你根据需要设置警报。这包括以下活动：
- en: '**Model monitoring**: This includes the tasks required to ensure your model
    performance does not degrade over time. This topic is covered in detail in [*Chapter
    11*](B17249_11_Final_JM_ePub.xhtml#_idTextAnchor210), *Monitoring Production Models
    with Amazon SageMaker Model Monitor and Clarify.* However, when building your
    automated deployment workflows, it''s important to consider the additional tasks
    that may need to be included and automated within your pipeline. As an example,
    SageMaker Model Monitor for data drift requires tasks such as baselining of your
    training data, enabling data capture on your endpoints, and scheduling a SageMaker
    monitoring job. All of these tasks should be automated and included in your automated
    workflow. You can also utilize *Human in the Loop* reviews with **Amazon Augmented
    AI** (**Amazon A2I**) to check low-confidence predictions that can be implemented
    along with, or complementary to, SageMaker Model Monitor.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型监控**：这包括确保您的模型性能随时间不退化的任务。此主题在[*第11章*](B17249_11_Final_JM_ePub.xhtml#_idTextAnchor210)，*使用Amazon
    SageMaker模型监控和Clarify监控生产模型*中详细说明。然而，在构建您的自动化部署工作流时，考虑可能需要在管道中包含和自动化的额外任务是很重要的。例如，SageMaker模型监控对于数据漂移需要诸如基准测试您的训练数据、在您的端点上启用数据捕获以及安排SageMaker监控作业等任务。所有这些任务都应自动化并包含在您的自动化工作流中。您还可以利用带有**Amazon增强AI**（**Amazon
    A2I**）的**人工审核**来检查低置信度预测，这些预测可以与SageMaker模型监控一起实施，或作为其补充。'
- en: '**System monitoring**: System monitoring includes capturing and alerting on
    metrics that are key to the resources hosting your model, as well as the other
    resources supporting the deployed ML solution. As an example, Amazon SageMaker
    will automatically capture key metrics about an endpoint, such as CPU/GPU utilization
    or the number of invocations. Setting thresholds and creating alerts in Amazon
    CloudWatch helps ensure the overall health of resources hosting models, as well
    as other solution components.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统监控**：系统监控包括捕获和警报对托管您的模型以及支持已部署机器学习解决方案的其他资源至关重要的指标。例如，Amazon SageMaker将自动捕获端点的关键指标，例如CPU/GPU利用率或调用次数。在Amazon
    CloudWatch中设置阈值和创建警报有助于确保托管模型的资源以及其他解决方案组件的整体健康。'
- en: '**Model retraining**: To set up automatic model retraining, the tasks that
    are performed across your model build steps should be captured as code that can
    be executed as part of a model build pipeline. This pipeline would include automation
    of all of the tasks within each step, as well as orchestration of those steps.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型重新训练**：为了设置自动模型重新训练，应在模型构建步骤中执行的任务被捕获为可以作为模型构建管道一部分执行的代码。此管道将包括每个步骤内所有任务的自动化，以及这些步骤的编排。'
- en: '**Pipeline monitoring**: If you have automated pipelines set up for your model
    build and model deploy activities, it''s key to also have monitoring in place
    on your pipeline to ensure you are notified in the event of a step failure in
    your pipeline.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道监控**：如果您为模型构建和模型部署活动设置了自动化管道，那么在您的管道上实施监控也很关键，以确保在管道中的步骤失败时您会收到通知。'
- en: We have covered the general steps in an ML workflow. However, each automated
    workflow and CI/CD pipeline can vary due to a number of factors. In the next section,
    we'll cover some of the considerations that are common across ML use cases.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经覆盖了机器学习工作流中的通用步骤。然而，由于许多因素，每个自动化工作流和CI/CD管道都可能有所不同。在下一节中，我们将讨论一些在机器学习用例中常见的考虑因素。
- en: Considerations and guidance for building SageMaker workflows and CI/CD pipelines
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建SageMaker工作流和CI/CD管道的考虑和指导
- en: 'The steps and tasks performed as part of an ML workflow can vary depending
    on the use case; however, the following high-level practices are recommended when
    building an automated workflow for your ML use case:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习工作流中执行的任务可能因用例而异；然而，当为您的机器学习用例构建自动化工作流时，以下高级实践是推荐的：
- en: '**Implement a model registry**: A **model registry** helps bridge the steps
    between the phases of model building experimentation and deploying your models
    to higher-level environments. A model registry captures key metadata, such as
    **model metrics**. It also ensures you''re able to track key inputs and artifacts
    for traceability, as well as manage multiple model versions across environments.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实施模型注册表**：**模型注册表**有助于连接模型构建实验阶段和将模型部署到更高级环境之间的步骤。模型注册表捕获关键元数据，如**模型指标**。它还确保您能够跟踪关键输入和工件以实现可追溯性，以及管理跨环境的多个模型版本。'
- en: '**Version inputs and artifacts**: The ability to roll back or recreate a specific
    model version or deployable artifact is dependent on knowing the specific versions
    of inputs and artifacts used to create that resource. As an example, to recreate
    a SageMaker endpoint, you need to know key version information, such as the model
    artifact and the inference container image. These inputs and artifacts should
    be protected from inadvertent deletion. They should also be tracked through an
    end-to-end pipeline to be able to confidently recreate resources as part of an
    automated workflow.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版本输入和工件**：能够回滚或重新创建特定模型版本或可部署工件的能力取决于知道创建该资源所使用的输入和工件的具体版本。例如，要重新创建 SageMaker
    端点，你需要知道关键版本信息，例如模型工件和推理容器镜像。这些输入和工件应免受意外删除的保护。它们还应通过端到端管道进行跟踪，以便能够自信地作为自动化工作流程的一部分重新创建资源。'
- en: AWS-native options for automated workflow and CI/CD pipelines
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动化工作流程和 CI/CD 管道中的 AWS 原生选项
- en: In this chapter, we focus primarily on the SageMaker-native options for creating
    automated workflows, as well as layering on CI/CD practices in end-to-end pipelines.
    However, there are other options that can also be used for creating automated
    workflows that contain SageMaker tasks for model building and model deployment.
    There are also third-party options that contain operators or integrations with
    SageMaker. However, they are not covered in this book.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们主要关注 SageMaker 原生选项用于创建自动化工作流程，以及在端到端管道中叠加 CI/CD 实践。然而，还有其他选项也可以用于创建包含
    SageMaker 任务的自动化工作流程，这些任务用于模型构建和模型部署。还有第三方选项包含与 SageMaker 的操作符或集成。然而，这些内容在本书中并未涉及。
- en: 'First, we''ll cover a few of the AWS services and features that can be used
    to build automated workflows that include SageMaker tasks:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将介绍一些可以用于构建包含 SageMaker 任务的自动化工作流程的 AWS 服务和功能：
- en: '**AWS Step Functions**: AWS Step Functions ([https://aws.amazon.com/step-functions/?step-functions.sort-by=item.additionalFields.postDateTime&step-functions.sort-order=desc](https://aws.amazon.com/step-functions/?step-functions.sort-by=item.additionalFields.postDateTime&step-functions.sort-order=desc))
    allows you to create automated serverless workflows that include integration with
    a number of AWS services, as well as giving you the capability to integrate third-party
    tasks into your workflows. AWS Step Functions also has native support for SageMaker
    tasks, such as SageMaker processing jobs, SageMaker training jobs, and SageMaker
    hosting options.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS Step Functions**：AWS Step Functions ([https://aws.amazon.com/step-functions/?step-functions.sort-by=item.additionalFields.postDateTime&step-functions.sort-order=desc](https://aws.amazon.com/step-functions/?step-functions.sort-by=item.additionalFields.postDateTime&step-functions.sort-order=desc))
    允许你创建包含与多个 AWS 服务集成的自动化无服务器工作流程，同时赋予你将第三方任务集成到工作流程中的能力。AWS Step Functions 还具有对
    SageMaker 任务的本地支持，例如 SageMaker 处理作业、SageMaker 训练作业和 SageMaker 托管选项。'
- en: In addition, ML builders can choose to take advantage of the AWS Step Functions
    Data Science SDK ([https://docs.aws.amazon.com/step-functions/latest/dg/concepts-python-sdk.html](https://docs.aws.amazon.com/step-functions/latest/dg/concepts-python-sdk.html))
    to create ML workflows using Python instead of through Amazon States Language.
    Amazon States Language is the native pipeline syntax for AWS Step Functions. AWS
    Step Functions offers extensibility across AWS services with native integrations
    for the AWS services most commonly used in ML workflows, such as AWS Lambda, Amazon
    EMR, or AWS Glue.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，ML 构建者可以选择利用 AWS Step Functions 数据科学 SDK ([https://docs.aws.amazon.com/step-functions/latest/dg/concepts-python-sdk.html](https://docs.aws.amazon.com/step-functions/latest/dg/concepts-python-sdk.html))，使用
    Python 而不是通过 Amazon States 语言来创建 ML 工作流程。Amazon States 语言是 AWS Step Functions
    的原生管道语法。AWS Step Functions 提供了跨 AWS 服务的可扩展性，具有与在 ML 工作流程中最常使用的 AWS 服务（如 AWS Lambda、Amazon
    EMR 或 AWS Glue）的本地集成。
- en: '**Amazon Managed Workflows for Apache Airflow**: Amazon Managed Workflows for
    Apache Airflow ([https://aws.amazon.com/managed-workflows-for-apache-airflow/](https://aws.amazon.com/managed-workflows-for-apache-airflow/))
    allows you to create automated ML workflows by using native integration with SageMaker
    among other AWS services that are commonly used. Many organizations and teams
    already use or have invested in Airflow, so this service provides a way to take
    advantage of those existing investments using a managed service that includes
    native integrations with SageMaker for model building and deployment steps.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon Managed Workflows for Apache Airflow**：Amazon Managed Workflows for
    Apache Airflow ([https://aws.amazon.com/managed-workflows-for-apache-airflow/](https://aws.amazon.com/managed-workflows-for-apache-airflow/))
    允许您通过与其他常用 AWS 服务（如 SageMaker）的本地集成来创建自动化的机器学习工作流程。许多组织和团队已经使用或投资了 Airflow，因此这项服务提供了一种方式，通过使用包括与
    SageMaker 的本地集成在内的托管服务来利用这些现有投资。'
- en: '**Amazon SageMaker Operators for Kubernetes**: SageMaker Operators for Kubernetes
    ([https://docs.aws.amazon.com/sagemaker/latest/dg/amazon-sagemaker-operators-for-kubernetes.html](https://docs.aws.amazon.com/sagemaker/latest/dg/amazon-sagemaker-operators-for-kubernetes.html))
    allows teams to create SageMaker tasks natively using the Kubernetes API and command-line
    Kubernetes tools, such as **kubectl**.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon SageMaker Operators for Kubernetes**：SageMaker Operators for Kubernetes
    ([https://docs.aws.amazon.com/sagemaker/latest/dg/amazon-sagemaker-operators-for-kubernetes.html](https://docs.aws.amazon.com/sagemaker/latest/dg/amazon-sagemaker-operators-for-kubernetes.html))
    允许团队使用 Kubernetes API 和命令行 Kubernetes 工具（如 **kubectl**）原生地创建 SageMaker 任务。'
- en: '**Amazon SageMaker Components for Kubeflow Pipelines**: SageMaker Components
    for Kubeflow Pipelines allows teams to still utilize Kubeflow for workflow orchestration,
    while providing integrations with SageMaker so that you can create and run SageMaker
    jobs in managed environments without running them directly on your Kubernetes
    clusters. This is useful for taking advantage of end-to-end managed SageMaker
    features, but also for cases where you do not want to perform those tasks directly
    on your cluster.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon SageMaker Components for Kubeflow Pipelines**：SageMaker Components
    for Kubeflow Pipelines 允许团队继续利用 Kubeflow 进行工作流程编排，同时提供与 SageMaker 的集成，以便您可以在托管环境中创建和运行
    SageMaker 作业，而无需直接在您的 Kubernetes 集群上运行。这对于利用端到端托管的 SageMaker 功能很有用，同时也适用于您不希望在集群上直接执行这些任务的情况。'
- en: 'Next, we''ll cover a few of the AWS services and features that can be used
    to incorporate CI/CD practices into your ML pipelines. These services are not
    unique to ML and can also be substituted for third-party tools offering similar
    capabilities:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍一些 AWS 服务和功能，这些服务可以用于将 CI/CD 实践集成到您的机器学习管道中。这些服务不仅限于机器学习，还可以替代提供类似功能的第三方工具：
- en: '**AWS CodeCommit**: AWS CodeCommit ([https://aws.amazon.com/codecommit/](https://aws.amazon.com/codecommit/))
    is a private Git-based source code repository. For ML pipelines, AWS CodeCommit
    can store any related source code, such as **infrastructure as code** (**IaC**)/**configuration
    as code** (**CaC**), data processing code, training code, model evaluation code,
    pipeline code, and model deployment code. The structure of your repositories may
    vary, but in general, it''s recommended to at least separate your model build
    and model deploy code.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS CodeCommit**：AWS CodeCommit ([https://aws.amazon.com/codecommit/](https://aws.amazon.com/codecommit/))
    是一个基于 Git 的私有源代码仓库。对于机器学习管道，AWS CodeCommit 可以存储任何相关的源代码，例如 **基础设施即代码**（**IaC**）和**配置即代码**（**CaC**），数据处理代码，训练代码，模型评估代码，管道代码和模型部署代码。您的存储库结构可能有所不同，但通常建议至少将模型构建和模型部署代码分开。'
- en: '**AWS CodeBuild**: AWS CodeBuild ([https://aws.amazon.com/codebuild/](https://aws.amazon.com/codebuild/))
    is a fully managed build service that can be used for multiple purposes. These
    include compiling source code, running tests, and running custom scripts as part
    of a pipeline. For ML pipelines, AWS CodeBuild can be used for tasks such as testing
    through custom scripts and packaging AWS CloudFormation templates.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS CodeBuild**：AWS CodeBuild ([https://aws.amazon.com/codebuild/](https://aws.amazon.com/codebuild/))
    是一个完全托管的构建服务，可用于多种用途。这包括编译源代码，运行测试，以及作为管道的一部分运行自定义脚本。对于机器学习管道，AWS CodeBuild 可以用于测试通过自定义脚本和打包
    AWS CloudFormation 模板等任务。'
- en: '**AWS CodePipeline**: AWS CodePipeline ([https://aws.amazon.com/codepipeline/](https://aws.amazon.com/codepipeline/))
    is a fully managed CD service that can be used to orchestrate the steps of your
    ML pipeline. AWS CodePipeline can be used to orchestrate the steps for model build
    tasks, as well as model deploy tasks.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS CodePipeline**：AWS CodePipeline ([https://aws.amazon.com/codepipeline/](https://aws.amazon.com/codepipeline/))
    是一个完全托管的 CD 服务，可用于编排您的 ML 管道步骤。AWS CodePipeline 可用于编排模型构建任务和模型部署任务的步骤。'
- en: The preceding list of AWS services can be used to incorporate CI/CD practices
    for your ML pipelines. You can also optionally substitute the services above for
    third-party options, such as GitHub, BitBucket, or Jenkins.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的 AWS 服务列表可用于为您的 ML 管道融入 CI/CD 实践。您还可以选择用 GitHub、BitBucket 或 Jenkins 等第三方选项替换上述服务。
- en: In this section, we covered a high-level ML workflow in the context of automating
    the tasks within key steps, as well as providing overall orchestration to automate
    those steps. We also discussed some of the key considerations when building your
    ML workflows. We reviewed the AWS-native options for creating automated ML workflows.
    We then looked at the AWS services that can be used to incorporate CI/CD practices.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了在自动化关键步骤的任务以及提供整体编排以自动化这些步骤的背景下，一个高级 ML 工作流程。我们还讨论了构建您的 ML 工作流程时的一些关键考虑因素。我们回顾了创建自动化
    ML 工作流程的 AWS 原生选项。然后我们查看可用于融入 CI/CD 实践的 AWS 服务。
- en: All of these, as well as many third-party options, are valid options when selecting
    the right tooling for automating your SageMaker workflows. The decision to custom
    build workflows using the services mentioned in the preceding list, or the decision
    to substitute the services above with third-party options, typically comes from
    either personal preference or having organizational standards or requirements
    to utilize existing tooling.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些，以及许多第三方选项，都是选择自动化 SageMaker 工作流程的正确工具时的有效选项。决定使用前面提到的服务自定义构建工作流程，或者决定用第三方选项替换上述服务，通常来自个人偏好或组织标准或要求利用现有工具。
- en: For the remainder of this chapter, we'll focus on the SageMaker-native capabilities
    for automating your ML workflows and incorporating CI/CD practices.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章剩余部分，我们将重点关注 SageMaker 原生能力，用于自动化您的 ML 工作流程并融入 CI/CD 实践。
- en: Building ML workflows with Amazon SageMaker Pipelines
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker Pipelines 构建 ML 工作流程
- en: Model build workflows cover all of the steps performed when developing your
    model, including data preparation, model training, model tuning, and model deployment.
    In this case, model deployment can include the tasks necessary to evaluate your
    model, as well as batch use cases that do not need to be deployed to higher environments.
    SageMaker Pipelines is a fully managed service that allows you to create automated
    model build workflows using the SageMaker Python SDK.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 模型构建工作流程涵盖了开发模型时执行的所有步骤，包括数据准备、模型训练、模型调优和模型部署。在这种情况下，模型部署可以包括评估您的模型所需的任务，以及不需要部署到更高环境的批量用例。SageMaker
    Pipelines 是一个完全托管的托管服务，允许您使用 SageMaker Python SDK 创建自动化的模型构建工作流程。
- en: SageMaker Pipelines includes built-in step types ([https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html))
    for executing SageMaker tasks, such as SageMaker Processing for data pre-processing,
    and SageMaker Training for model training. Pipelines also include steps for controlling
    how your pipeline works. For example, the pipeline could include conditional steps
    that could be used to evaluate the output of a previous step to determine whether
    to proceed to the next step in the pipeline.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Pipelines 包含用于执行 SageMaker 任务（如 SageMaker Processing 用于数据预处理和 SageMaker
    Training 用于模型训练）的内置步骤类型 ([https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html))。Pipelines
    还包括控制您的管道如何工作的步骤。例如，管道可以包括条件步骤，用于评估前一个步骤的输出，以确定是否继续到管道中的下一个步骤。
- en: 'To include steps that perform tasks using other AWS services or non-AWS tasks,
    you must use the **callback step**. This is useful if you are using another AWS
    service for a task in your pipeline. One example could be if you are using AWS
    Glue for data preprocessing. *Figure 12.2* builds on the previous workflow illustration
    to indicate where SageMaker Pipelines fits into the end-to-end workflow, as well
    as providing examples of the supported SageMaker features for each model build
    workflow step:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要包括执行其他 AWS 服务或非 AWS 任务的步骤，您必须使用 **回调步骤**。如果您在管道中使用另一个 AWS 服务执行任务，这将非常有用。一个例子是如果您正在使用
    AWS Glue 进行数据预处理。*图 12.2* 在先前的流程图的基础上，表明 SageMaker Pipelines 在端到端工作流程中的位置，以及为每个模型构建工作流程步骤提供支持的
    SageMaker 功能示例：
- en: '![Figure 12.2 – SageMaker Pipelines model building workflows'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 12.2 – SageMaker 管道模型构建工作流程'
- en: '](img/B17249_12_02.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17249_12_02.jpg](img/B17249_12_02.jpg)'
- en: Figure 12.2 – SageMaker Pipelines model building workflows
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.2 – SageMaker 管道模型构建工作流程
- en: 'In this section, you''ll build out a SageMaker pipeline for your ML use case.
    The pipeline will include all of the steps necessary for data preparation, model
    training, and model evaluation. Because we don''t need every SageMaker feature
    to build our pipeline, you''ll only be using the features noted in the following
    diagram:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将为您的机器学习用例构建一个 SageMaker 管道。该管道将包括数据准备、模型训练和模型评估所需的全部步骤。由于我们不需要 SageMaker
    的每个功能来构建我们的管道，您将只使用以下图中注明的功能：
- en: '![Figure 12.3 – SageMaker Pipelines example pipeline'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 12.3 – SageMaker 管道示例管道'
- en: '](img/B17249_12_03.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17249_12_03.jpg](img/B17249_12_03.jpg)'
- en: Figure 12.3 – SageMaker Pipelines example pipeline
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.3 – SageMaker 管道示例管道
- en: For each step in your SageMaker pipeline, you first need to configure the task
    that you will execute (for example, a training job) and then configure the SageMaker
    Pipelines step for that task. After all, steps have been configured, you chain
    the steps together and then execute the pipeline. The following sections will
    walk you through the steps in building your SageMaker pipeline for your example
    use case.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于您 SageMaker 管道中的每个步骤，您首先需要配置您将执行的任务（例如，训练作业），然后配置该任务的 SageMaker Pipelines
    步骤。配置完所有步骤后，将步骤链接在一起，然后执行管道。以下各节将指导您构建用于示例用例的 SageMaker 管道。
- en: Building your SageMaker pipeline
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建您的 SageMaker 管道
- en: 'In this section, we''ll walk through the steps needed to configure each step
    in your SageMaker pipeline, as well as how to chain those steps together and finally
    execute your model build pipeline. For each step in your pipeline, there are two
    steps to follow:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍配置您 SageMaker 管道中每个步骤所需的步骤，以及如何将这些步骤链接在一起，并最终执行您的模型构建管道。对于您管道中的每个步骤，您需要遵循以下两个步骤：
- en: Configure the SageMaker job.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置 SageMaker 作业。
- en: Configure the SageMaker Pipelines step.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置 SageMaker Pipelines 步骤。
- en: '*Figure 12.4* illustrates the steps that we will use to build the pipeline:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12.4* 展示了我们构建管道将使用的步骤：'
- en: '![Figure 12.4 – Pipeline use case with SageMaker steps'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 12.4 – 使用 SageMaker 步骤的管道用例'
- en: '](img/B17249_12_04.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17249_12_04.jpg](img/B17249_12_04.jpg)'
- en: Figure 12.4 – Pipeline use case with SageMaker steps
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.4 – 使用 SageMaker 步骤的管道用例
- en: We'll start with the data preparation step, where we'll use SageMaker Processing
    to transform our raw data into the format expected by the algorithm.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从数据准备步骤开始，在此步骤中，我们将使用 SageMaker Processing 将我们的原始数据转换为算法期望的格式。
- en: Data preparation step
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备步骤
- en: 'In this step, you''ll configure the SageMaker processing job that will be used
    to transform your data into a format expected by the algorithm. For this, we''ll
    use the same configuration from [*Chapter 4*](B17249_04_Final_JM_ePub.xhtml#_idTextAnchor072),
    *Data Preparation at Scale Using Amazon SageMaker Data Wrangler and Processing*:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，您将配置用于将您的数据转换为算法期望格式的 SageMaker 处理作业。为此，我们将使用来自 [*第 4 章*](B17249_04_Final_JM_ePub.xhtml#_idTextAnchor072)，*使用
    Amazon SageMaker Data Wrangler 和 Processing 进行大规模数据准备* 的相同配置：
- en: 'First, we''ll configure the SageMaker processing job, as follows:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将配置 SageMaker 处理作业，如下所示：
- en: '[PRE0]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we''ll configure the SageMaker Pipelines step that will be used to execute
    your data preparation tasks. For this, we''ll use the built-in processing step
    ([https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing))
    that tells Pipelines this step will be a SageMaker processing job. *Figure 12.5*
    shows the high-level inputs and outputs/artifacts that `ProcessingStep` used for
    data preprocessing will expect:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将配置用于执行你的数据准备任务的 SageMaker Pipelines 步骤。为此，我们将使用内置的处理步骤（[https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing)），它告诉管道这个步骤将是一个
    SageMaker 处理作业。*图 12.5* 展示了 `ProcessingStep` 用于数据预处理所期望的高级输入和输出/工件：
- en: '![Figure 12.5 – Data preparation pipeline step'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 12.5 – 数据准备管道步骤'
- en: '](img/B17249_12_05.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17249_12_05.jpg)'
- en: Figure 12.5 – Data preparation pipeline step
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.5 – 数据准备管道步骤
- en: 'We previously configured the processor, so we will now use that processor (combined
    with the other inputs shown in *Figure 12.4*) to set up our Pipelines step, as
    follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已经配置了处理器，因此现在我们将使用该处理器（结合 *图 12.4* 中显示的其他输入）来设置我们的管道步骤，如下所示：
- en: 'First, we''ll enable **step caching**. Step caching tells SageMaker to check
    for a previous execution of a step that was called with the same arguments. This
    is so that it can use the previous step values of a successful run instead of
    re-executing a step with the exact same arguments. You should consider using step
    caching to avoid unnecessary tasks and costs. As an example, if the second step
    (model training) in your pipeline fails, you can start the pipeline again without
    re-executing the data preparation step if that step has not changed, as follows:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将启用**步骤缓存**。步骤缓存会告诉 SageMaker 检查是否有之前使用相同参数调用过的步骤的执行。这样，它就可以使用成功运行的先前步骤值，而不是重新执行具有完全相同参数的步骤。你应该考虑使用步骤缓存来避免不必要的任务和成本。例如，如果你的管道中的第二个步骤（模型训练）失败，你可以在该步骤没有变化的情况下重新启动管道，而不需要重新执行数据准备步骤，如下所示：
- en: '[PRE1]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we''ll define the runtime arguments using the `get_run_args` method.
    In this case, we are passing the Spark processor that was previously configured,
    in combination with the parameters identifying the inputs (raw weather data),
    the outputs (train, test, and validation datasets), and additional arguments the
    data processing script accepts as input. The data processing script, `preprocess.py`,
    is a slightly modified version of the processing script used in [*Chapter 4*](B17249_04_Final_JM_ePub.xhtml#_idTextAnchor072),
    *Data Preparation at Scale Using Amazon SageMaker Data Wrangler and Processing*.
    Refer to the following script:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 `get_run_args` 方法定义运行时参数。在这种情况下，我们正在传递之前配置的 Spark 处理器，结合标识输入（原始天气数据）、输出（训练、测试和验证数据集）以及数据预处理脚本作为输入接受的其他参数。数据预处理脚本
    `preprocess.py` 是用于 [*第 4 章*](B17249_04_Final_JM_ePub.xhtml#_idTextAnchor072)，*使用
    Amazon SageMaker Data Wrangler 和 Processing 进行大规模数据准备* 中使用的处理脚本的略微修改版本。请参考以下脚本：
- en: '[PRE2]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, we''ll use the runtime parameters to configure the actual SageMaker Pipelines
    step for our data preprocessing tasks. You''ll notice we''re using all of the
    parameters we configured previously to build the step that will execute as part
    of the pipeline:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用运行时参数来配置实际的数据预处理任务所用的 SageMaker Pipelines 步骤。你会注意到我们正在使用之前配置的所有参数来构建作为管道一部分执行的步骤：
- en: '[PRE3]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Model build step
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型构建步骤
- en: In this step, you'll configure the SageMaker training job that will be used
    to train your model. You'll use the training data produced from the data preparation
    step, in combination with your training code and configuration parameters.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个步骤中，你将配置用于训练你的模型的 SageMaker 训练作业。你将使用数据准备步骤生成的训练数据，结合你的训练代码和配置参数。
- en: Important note
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Although we do not cover it in this chapter specifically, it is important to
    note that SageMaker Pipelines now integrates with SageMaker Experiments, allowing
    you to capture extra metrics, as well as view corresponding plots in SageMaker
    Pipelines.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们在这个章节中没有具体介绍，但需要注意的是，SageMaker Pipelines 现在已与 SageMaker Experiments 集成，允许你捕获额外的指标，并在
    SageMaker Pipelines 中查看相应的图表。
- en: 'For this, we''ll use the same configuration from [*Chapter 6*](B17249_06_Final_JM_ePub.xhtml#_idTextAnchor117),
    *Training and Tuning at Scale*. Refer to the following steps:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此，我们将使用来自 [*第 6 章*](B17249_06_Final_JM_ePub.xhtml#_idTextAnchor117)，*大规模训练和调优*
    的相同配置。请参考以下步骤：
- en: 'First, we''ll configure the SageMaker training job, as follows:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将配置 SageMaker 训练作业，如下所示：
- en: '[PRE4]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, we''ll configure the SageMaker Pipelines step that will be used to execute
    your model training task. For this, we''ll use the built-in `training step` ([https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training)).
    This tells Pipelines this step will be a SageMaker training job. *Figure 12.6*
    shows the high-level inputs and outputs/artifacts that a **Training step** will
    expect:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将配置用于执行您的模型训练任务的 SageMaker Pipelines 步骤。为此，我们将使用内置的 `training step` ([https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training))。这告诉
    Pipelines 此步骤将是一个 SageMaker 训练作业。*图 12.6* 展示了 **Training step** 预期的高级别输入和输出/工件：
- en: '![Figure 12.6 – Model build pipeline step'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 12.6 – Model build pipeline step]'
- en: '](img/B17249_12_06.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17249_12_06.jpg]'
- en: Figure 12.6 – Model build pipeline step
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.6 – 模型构建管道步骤
- en: 'We previously configured the estimator, so we will now use that estimator combined
    with the other inputs shown in *Figure 12.6* to set up our Pipelines step:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已配置了估算器，因此现在我们将使用该估算器结合 *图 12.6* 中显示的其他输入来设置我们的 Pipelines 步骤：
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Model evaluation step
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估步骤
- en: 'In this step, you''ll configure a SageMaker processing job that will be used
    to evaluate your trained model using the model artifact produced from the training
    step in combination with your processing code and configuration:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，您将配置一个用于评估您训练的模型（使用从训练步骤生成的模型工件以及您的处理代码和配置）的 SageMaker 处理作业：
- en: 'First, we''ll configure the SageMaker processing job starting with `ScriptProcessor`.
    We will use this to execute a simple evaluation script, as follows:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将从 `ScriptProcessor` 开始配置 SageMaker 处理作业。我们将使用它来执行一个简单的评估脚本，如下所示：
- en: '[PRE6]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we''ll configure the SageMaker Pipelines step that will be used to execute
    your model evaluation tasks. For this, we''ll use the built-in Processing step
    ([https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing)).
    This tells Pipelines this step will be a SageMaker processing job. *Figure 12.7*
    shows the high-level inputs and outputs/artifacts that a Processing step used
    for model evaluation will expect:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将配置用于执行您的模型评估任务的 SageMaker Pipelines 步骤。为此，我们将使用内置的 Processing step ([https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing))。这告诉
    Pipelines 此步骤将是一个 SageMaker 处理作业。*图 12.7* 展示了用于模型评估的 Processing step 预期的高级别输入和输出/工件：
- en: '![Figure 12.7 – Model evaluation pipeline step'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 12.7 – Model evaluation pipeline step]'
- en: '](img/B17249_12_07.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17249_12_07.jpg]'
- en: Figure 12.7 – Model evaluation pipeline step
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.7 – 模型评估管道步骤
- en: 'We previously configured the processor, so we will now use that processor combined
    with the other inputs shown in *Figure 12.7* to set up our Pipelines step. To
    do this, we''ll first set up the property file that will be used to store the
    output, in this case, model evaluation metrics, of our processing job. Then, we''ll
    configure the `ProcessingStep` definition as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已配置了处理器，因此现在我们将使用该处理器结合 *图 12.7* 中显示的其他输入来设置我们的 Pipelines 步骤。为此，我们首先将设置用于存储处理作业输出（在这种情况下，模型评估指标）的属性文件。然后，我们将配置
    `ProcessingStep` 定义，如下所示：
- en: '[PRE7]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Conditional step
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 条件步骤
- en: 'In this step, you''ll configure a built-in conditional step that will determine
    whether to proceed to the next step in the pipeline based on the results of your
    previous model evaluation step. Setting up a conditional step requires a list
    of conditions or items that must be true. This is in combination with instructions
    on the list of steps to execute based on that condition. *Figure 12.8* illustrates
    the inputs and outputs required for a conditional step:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，您将配置一个内置的条件步骤，该步骤将根据您之前模型评估步骤的结果确定是否继续执行管道中的下一个步骤。设置条件步骤需要一系列条件或必须为真的项目。这结合了根据该条件执行步骤的指令列表。*图
    12.8* 阐述了条件步骤所需的输入和输出：
- en: '![Figure 12.8 – Conditional pipeline step'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 12.8 – Conditional pipeline step]'
- en: '](img/B17249_12_08.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17249_12_08.jpg]'
- en: Figure 12.8 – Conditional pipeline step
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.8 – Conditional pipeline 步骤
- en: 'In this case, we''re going to set up a condition using the `if_steps` parameter.
    In this case, the next steps if the condition were true would be to register the
    model and then create the model that packages your model for deployment. You can
    optionally specify `else_steps` to indicate the next steps to perform if the condition
    is not true. In this case, we will simply terminate the pipeline if the condition
    is not true:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将使用`if_steps`参数设置一个条件。在这种情况下，如果条件为真，则下一步将是注册模型然后创建打包模型的模型。您可以可选地指定`else_steps`以指示条件不为真时要执行的下一步。在这种情况下，如果条件不为真，我们将简单地终止管道：
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Register model step(s)
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注册模型步骤
- en: 'In this final step, you''ll package the model and configure a built-in register
    model ([https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-register-model](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-register-model))
    step that will register your model to a model package group in SageMaker model
    registry. As seen in *Figure 12.9*, the inputs we''ll use to register the model
    contain information about the packaged model, such as the model version, estimator,
    and S3 location of the model artifact. This information, when combined with additional
    information such as model metrics and inference specifications, is used to register
    the model version:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个最后一步，您将打包模型并配置一个内置的注册模型步骤（[https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-register-model](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-register-model)），该步骤将您的模型注册到SageMaker模型注册库中的模型包组。如图12.9所示，我们将用于注册模型的输入包含有关打包模型的信息，例如模型版本、估计器和模型工件在S3上的位置。这些信息与模型指标和推理规范等附加信息结合使用，用于注册模型版本：
- en: '![Figure 12.9 – Conditional pipeline step'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图12.9 – 条件管道步骤'
- en: '](img/B17249_12_09.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17249_12_09.jpg)'
- en: Figure 12.9 – Conditional pipeline step
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 – 条件管道步骤
- en: 'This step will use data from the prior steps in the pipeline to register the
    model and centrally store key metadata about this specific model version. In addition,
    you''ll see an `approval_status parameter`. This parameter can be used to trigger
    downstream deployment processes (these will be discussed in more detail under
    SageMaker Projects):'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤将使用管道中先前步骤的数据来注册模型并集中存储有关此特定模型版本的键信息。此外，您将看到`approval_status`参数。此参数可用于触发下游部署过程（这些将在SageMaker项目中更详细地讨论）：
- en: '[PRE9]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Creating the pipeline
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建管道
- en: In the preceding steps, we configured the tasks and steps that will be used
    as part of the model build pipeline. We now need to chain those steps together
    to create the SageMaker Pipeline.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的步骤中，我们配置了作为模型构建管道一部分的任务和步骤。我们现在需要将这些步骤链接起来以创建SageMaker管道。
- en: When configuring pipeline steps and creating a SageMaker pipeline, it is important
    to identify the parameters that could vary per pipeline execution and may be more
    dynamic. For example, the instance type for processing or training may be something
    you want to be able to change with each execution of your pipeline without directly
    modifying your pipeline code. This is where parameters become important in being
    able to dynamically pass in parameters at execution time. This allows you to change
    configurations (such as changing the instance type parameters) with each execution
    of your pipeline, based on different environments or as your data grows.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置管道步骤和创建SageMaker管道时，识别可能随管道执行而变化的参数以及可能更动态的参数非常重要。例如，处理或训练的实例类型可能是您希望在每次执行管道时都能更改的内容，而不直接修改您的管道代码。这就是参数在执行时动态传递参数变得重要的地方。这允许您根据不同的环境或随着数据增长来更改配置（例如更改实例类型参数）。
- en: 'The following code shows the chaining together of our previously configured
    pipeline steps, as well as identifying the parameters we want to be able to pass
    in on each execution:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了将先前配置的管道步骤链接起来，以及确定我们希望在每次执行中能够传递的参数：
- en: '[PRE10]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Executing the pipeline
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行管道
- en: 'Now that we''ve defined and configured our steps and the pipeline itself, we
    want to be able to execute the pipeline. To do this, you''ll need to perform a
    few steps. These steps need to be performed for each pipeline execution. A pipeline
    can be started in multiple ways:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义和配置了步骤和管道本身，我们希望能够执行管道。为此，您需要执行几个步骤。这些步骤需要在每次管道执行时执行。管道可以通过多种方式启动：
- en: Programmatically within a notebook (as shown in the example notebook for this
    chapter)
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在笔记本中编程（如本章示例笔记本所示）
- en: Under Pipelines in the SageMaker Studio UI
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 SageMaker Studio UI 中的“Pipelines”下
- en: Programmatically via another resource
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过其他资源编程方式
- en: Through an EventBridge source triggered by an event or schedule
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过由事件或计划触发的 EventBridge 源
- en: In this section, we'll focus on the steps required to execute your pipeline
    from your example notebook. First, you need to submit the pipeline definition
    to the SageMaker Pipelines service. This is done through an `upsert` that passes
    in the IAM role as an argument. Keep in mind that an `upsert` will create a pipeline
    definition if it doesn't exist or update the pipeline if it does. Also, the role
    that is passed is used by SageMaker Pipelines to create and launch all of the
    tasks defined in the steps. Therefore, you need to ensure that the role is scoped
    to the API permissions you need for your pipeline. It's a best practice to only
    include the API permissions that are actually needed so as to avoid overly permissive
    roles.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将关注从你的示例笔记本执行你的 pipeline 所需的步骤。首先，你需要将 pipeline 定义提交给 SageMaker Pipelines
    服务。这是通过一个 `upsert` 完成的，该 `upsert` 将 IAM 角色作为参数传递。请注意，如果不存在，`upsert` 将创建 pipeline
    定义，如果存在，则更新 pipeline。此外，传递的角色由 SageMaker Pipelines 用于创建和启动步骤中定义的所有任务。因此，你需要确保该角色具有你
    pipeline 所需的 API 权限。最佳实践是只包括实际需要的 API 权限，以避免过度授权的角色。
- en: 'In the following code, you need to load the pipeline definition and then submit
    that definition through `upsert`:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，你需要加载 pipeline 定义，然后通过 `upsert` 提交该定义：
- en: '[PRE11]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Once your pipeline definition is submitted, you''re ready to start the pipeline
    using the following code:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提交了 pipeline 定义，你就可以使用以下代码开始 pipeline：
- en: '[PRE12]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: There are multiple ways to check the status and progress of your pipeline steps.
    You can view your pipeline in the Studio console and click on each step to get
    metadata about each step, including the step logs. In addition, you can programmatically
    check the status of your pipeline execution. To do this, you can run `execution.describe()`
    to view the pipeline execution status, or `execution.list_steps()` to view the
    execution status and each step.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以检查你的 pipeline 步骤的状态和进度。你可以在 Studio 控制台中查看你的 pipeline，并点击每个步骤以获取每个步骤的元数据，包括步骤日志。此外，你可以通过编程方式检查
    pipeline 执行的状态。为此，你可以运行 `execution.describe()` 来查看 pipeline 执行状态，或运行 `execution.list_steps()`
    来查看执行状态和每个步骤。
- en: Running your pipelines ad hoc from a notebook is often acceptable during your
    model-building activities. However, when you're ready to move your models to production,
    it's common at that stage to find the most consistent and repeatable ways to trigger
    or schedule your model-building pipelines for model retraining.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型构建活动中，从笔记本中临时运行你的 pipeline 通常是可以接受的。然而，当你准备将模型部署到生产环境时，在那个阶段找到最一致和可重复的触发或安排模型构建
    pipeline 以进行模型重新训练的方式是很常见的。
- en: To do this, you can utilize the integration between SageMaker Pipelines and
    Amazon EventBridge ([https://docs.aws.amazon.com/sagemaker/latest/dg/pipeline-eventbridge.html](https://docs.aws.amazon.com/sagemaker/latest/dg/pipeline-eventbridge.html)).
    This integration allows you to trigger the execution of your SageMaker pipeline
    through event rules. These rules can be based on an event, such as the completion
    of an AWS Glue job, or they can be scheduled.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，你可以利用 SageMaker Pipelines 和 Amazon EventBridge 之间的集成（[https://docs.aws.amazon.com/sagemaker/latest/dg/pipeline-eventbridge.html](https://docs.aws.amazon.com/sagemaker/latest/dg/pipeline-eventbridge.html)）。这种集成允许你通过事件规则触发你的
    SageMaker pipeline 的执行。这些规则可以基于事件，例如 AWS Glue 作业的完成，或者它们可以是计划好的。
- en: Pipeline recommended practices
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pipeline 推荐实践
- en: 'In this section, we covered how to set up a SageMaker pipeline using your example
    weather use case. As you build your own pipelines, they will likely vary in terms
    of the configuration required and the steps that should be included. However,
    the following general recommendations apply across use cases (unique considerations
    are highlighted where applicable):'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了如何使用你的示例天气用例设置 SageMaker pipeline。随着你构建自己的 pipeline，它们在所需配置和应包含的步骤方面可能会有所不同。然而，以下一般性建议适用于所有用例（适用时突出显示独特考虑因素）：
- en: SageMaker Pipelines has built-in steps supporting a variety of SageMaker jobs
    and the ability to utilize callback for custom steps. The built-in integrations
    with SageMaker steps simplify building and managing the pipeline. It is therefore
    recommended to **utilize SageMaker-native steps for the tasks in your pipeline**
    when possible.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SageMaker Pipelines 内置了支持各种 SageMaker 作业的步骤，并能够利用回调进行自定义步骤。与 SageMaker 步骤的内置集成简化了管道的构建和管理。因此，建议在可能的情况下，**使用
    SageMaker 原生步骤来处理您的管道中的任务**。
- en: '**Utilize runtime parameters** for job arguments that are more likely to change
    between executions or environments, such as the size or number of ML instances
    running your training or processing jobs. This allows you to pass values in when
    you start the execution of the pipeline, as opposed to modifying your pipeline
    code every time.'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用运行时参数**对于在执行或环境中更可能变化的作业参数，例如运行训练或处理作业的 ML 实例的大小或数量。这允许你在启动管道执行时传递值，而不是每次都修改你的管道代码。'
- en: '**Enable step caching** to take advantage of eliminating unnecessary execution
    of steps in your pipeline. This will reduce costs, as well as reducing pipeline
    time when a previous pipeline step has already been successfully executed with
    the same parameters.'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**启用步骤缓存**以利用消除管道中不必要的步骤执行的优势。这将降低成本，并在前一个管道步骤已成功执行且参数相同的情况下减少管道时间。'
- en: In this section, we covered automating your model build ML workflows using SageMaker
    Pipelines. In the next section, we'll cover creating an end-to-end ML pipeline
    that goes beyond automation and incorporates CI/CD practices.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了使用 SageMaker Pipelines 自动化模型构建 ML 工作流程。在下一节中，我们将介绍创建一个超越自动化并包含 CI/CD
    实践的端到端 ML 管道。
- en: Creating CI/CD pipelines using Amazon SageMaker Projects
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker Projects 创建 CI/CD 管道
- en: "In this section, we'll discuss using Amazon SageMaker Projects to incorporate\
    \ CI/CD practices into your ML pipelines. SageMaker Projects is a service that\
    \ uses SageMaker Pipelines and the SageMaker model registry, in combination with\
    \ CI/CD tools, to automatically provision and configure CI/CD pipelines for ML.\
    \ *Figure 12.10* illustrates \Lthe core components of SageMaker Projects. With\
    \ Projects, you have the advantage of a CD pipeline, source code versioning, and\
    \ automatic triggers for pipeline execution:"
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论使用 Amazon SageMaker Projects 将 CI/CD 实践纳入您的 ML 管道。SageMaker Projects
    是一种服务，它结合使用 SageMaker Pipelines 和 SageMaker 模型注册，以及 CI/CD 工具，来自动提供和配置 CI/CD 管道。*图
    12.10* 说明了 SageMaker Projects 的核心组件。使用 Projects，您具有 CD 管道的优势、源代码版本控制和管道执行的自动触发：
- en: '![ Figure 12.10 – SageMaker Projects'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 12.10 – SageMaker 项目'
- en: '](img/B17249_12_10.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17249_12_10.jpg)'
- en: Figure 12.10 – SageMaker Projects
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.10 – SageMaker 项目
- en: Projects are made available through built-in SageMaker MLOps project templates
    or by creating your own organization's MLOps templates. The underlying templates
    are offered through AWS Service Catalog, via SageMaker Studio, and contain CloudFormation
    templates that preconfigure CI/CD pipelines for the selected template. Because
    projects rely on CloudFormation to provision pipelines, this ensures the practice
    of IaC/CaC to be able to consistently and reliably create CI/CD ML pipelines.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 项目通过内置的 SageMaker MLOps 项目模板或通过创建您自己组织的 MLOps 模板提供。底层模板通过 AWS 服务目录、SageMaker
    Studio 提供，并包含预配置 CI/CD 管道的 CloudFormation 模板。由于项目依赖于 CloudFormation 来提供管道，这确保了
    IaC/CaC 实践的实践，能够一致且可靠地创建 CI/CD ML 管道。
- en: 'There are three core types of built-in SageMaker MLOps project templates. *Figure
    12.11* shows the three primary types: 1\. **Build and Train Pipeline**, 2\. **Deploy
    Pipeline**, 3\. **Build, Train, and Deploy Pipeline**.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 内置了三种核心类型的 MLOps 项目模板。*图 12.11* 展示了这三种主要类型：1\. **构建和训练管道**，2\. **部署管道**，3\.
    **构建、训练和部署管道**。
- en: 'Refer to the following figure:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 参考以下图示：
- en: '![Figure 12.11 – SageMaker Projects'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 12.11 – SageMaker 项目'
- en: '](img/B17249_12_11_new.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17249_12_11_new.jpg)'
- en: Figure 12.11 – SageMaker Projects
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.11 – SageMaker 项目
- en: First, there is a build and train template. This covers the tasks required in
    data preparation, feature engineering, model training, and evaluation. This template
    is useful when you are performing model build activities on SageMaker but deploying
    your model somewhere else. It is also useful if you have batch-only use cases.
    In this case, Projects will automatically provision and seed a source code repository
    for a model build pipeline, set up pipeline triggers for changes to that code
    repository, and create a model group in the model registry. You are then responsible
    for going in and modifying that pipeline code to match your use case.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，有一个构建和训练模板。这个模板涵盖了数据准备、特征工程、模型训练和评估所需的任务。当您在 SageMaker 上执行模型构建活动但将模型部署到其他地方时，此模板非常有用。如果您只有批量用例，此模板也很有用。在这种情况下，项目将自动提供和初始化一个模型构建管道的源代码存储库，设置对该代码存储库更改的管道触发器，并在模型注册表中创建一个模型组。然后，您需要负责进入并修改该管道代码以匹配您的用例。
- en: Second, there is a model deployment template. This template is useful when you
    are looking to standardize SageMaker for hosting. In this case, Projects will
    automatically provision and seed a source code repository for a model deploy pipeline
    that deploys to a SageMaker endpoint based on triggers and information pulled
    from the model registry.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，有一个模型部署模板。当您希望标准化 SageMaker 以进行托管时，此模板非常有用。在这种情况下，项目将自动提供和初始化一个模型部署管道的源代码存储库，该存储库基于从模型注册表中拉取的触发器和信息部署到
    SageMaker 端点。
- en: Finally, there are end-to-end templates that cover all phases, including build,
    train, and deploy. These templates cover AWS Developer Services (AWS CodePipeline,
    AWS CodeCommit, AWS CodeBuild), or allow the option to utilize third-party source
    code repositories (GitHub, GitHub Enterprise, BitBucket, or Jenkins) for orchestration.
    In this case, Projects will automatically provision and seed source code for both
    model build and model deploy activities. Projects will also set up the triggers
    for both model build, and model deploy activities. Again, you are then responsible
    for going in and modifying seed code to meet your use case.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，有一些端到端的模板涵盖了所有阶段，包括构建、训练和部署。这些模板涵盖了 AWS 开发者服务（AWS CodePipeline、AWS CodeCommit、AWS
    CodeBuild），或者允许选择利用第三方源代码存储库（GitHub、GitHub Enterprise、BitBucket 或 Jenkins）进行编排。在这种情况下，项目将自动提供和初始化模型构建和模型部署活动的源代码。项目还将设置模型构建和模型部署活动的触发器。再次强调，您需要负责进入并修改初始代码以满足您的用例。
- en: In this section, we examined SageMaker projects. We concluded that it is a service
    that can be used to incorporate CI/CD practices into your ML pipelines. We'll
    now cover some of the recommended practices when using SageMaker projects.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们研究了 SageMaker 项目。我们得出结论，这是一个可以将 CI/CD 实践纳入您的 ML 管道的服务。现在，我们将介绍使用 SageMaker
    项目时的一些推荐实践。
- en: SageMaker projects recommended practices
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SageMaker 项目推荐实践
- en: In the preceding section, we covered SageMaker projects as a way to incorporate
    CI/CD practices into your ML pipelines by using a managed AWS service that will
    automatically provision and configure the integrations that are required. We'll
    now cover some of the general recommended practices when using SageMaker projects.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们介绍了 SageMaker 项目，作为通过使用自动提供和配置所需集成的一站式 AWS 服务来将 CI/CD 实践纳入您的 ML 管道的方法。现在，我们将介绍使用
    SageMaker 项目时的一些一般推荐实践。
- en: 'As you use SageMaker projects, the customizations for your use case can vary
    between customizing the code within the built-in MLOps project templates or creating
    your own fully custom MLOps project templates. As a result, there can be a lot
    of variance between pipelines in order to meet the requirements of your organization
    and use case. However, there are some general recommendations that apply across
    use cases, as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用 SageMaker 项目时，针对您的用例的定制可能因在内置 MLOps 项目模板中定制代码或创建您自己的完全定制的 MLOps 项目模板而异。因此，为了满足您组织和用例的要求，管道之间可能会有很多差异。然而，有一些通用的建议适用于所有用例，如下所述：
- en: Utilize built-in MLOps project templates when they meet your requirements.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在满足您的要求时，请使用内置的 MLOps 项目模板。
- en: When you have unique requirements, such as additional deployment quality gates,
    create custom MLOps project templates.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您有独特的要求，例如额外的部署质量门时，请创建定制的 MLOps 项目模板。
- en: When creating custom MLOps project templates, it is often easier to use the
    AWS CloudFormation templates used for the built-in MLOps project templates as
    a starting point and then modify accordingly. All of the built-in MLOps project
    templates are available and visible in AWS Service Catalog.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在创建自定义 MLOps 项目模板时，通常更容易以用于内置 MLOps 项目模板的 AWS CloudFormation 模板作为起点，然后相应地进行修改。所有内置的
    MLOps 项目模板都在 AWS 服务目录中可用且可见。
- en: In this section, we covered adding CI/CD practices to your automated workflows
    using SageMaker projects. We also discussed the MLOps project template options
    that are available. Finally, we discussed additional considerations and best practices
    when using SageMaker projects.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了如何使用 SageMaker 项目将 CI/CD 实践添加到您的自动化工作流程中。我们还讨论了可用的 MLOps 项目模板选项。最后，我们讨论了使用
    SageMaker 项目时的额外考虑因素和最佳实践。
- en: Summary
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we first covered general considerations for automating your
    SageMaker workflows. We then discussed automating your SageMaker model build workflows,
    specifically through using SageMaker Pipelines. The steps required to build out
    a pipeline for your weather use case were highlighted in order to illustrate SageMaker
    Pipeline usage. Finally, we discussed how you can enhance that automated model
    build workflow by using SageMaker projects to incorporate CI/CD practices, in
    addition to the automation offered by SageMaker Pipelines.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先介绍了自动化 SageMaker 工作流程的一般性考虑因素。然后，我们讨论了如何通过使用 SageMaker Pipelines 自动化
    SageMaker 模型构建工作流程，特别是通过使用 SageMaker Pipelines。为了说明 SageMaker Pipeline 的使用，我们强调了构建针对天气用例的管道所需的步骤。最后，我们讨论了如何通过使用
    SageMaker 项目来整合 CI/CD 实践，从而增强自动化模型构建工作流程，除了 SageMaker Pipelines 提供的自动化功能之外。
- en: In the next chapter, we'll discuss the AWS Well-Architected Framework, specifically
    looking at how best practices across each Well-Architected pillar map to SageMaker
    workloads.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论 AWS Well-Architected 架构，特别是探讨每个 Well-Architected 柱石的最佳实践如何映射到 SageMaker
    工作负载。
