- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Building an Intelligent MSA Enterprise System
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建智能MSA企业系统
- en: In previous chapters, we gradually built the ABC-MSA to demonstrate some of
    an MSA system’s features, techniques, and traffic patterns.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们逐步构建ABC-MSA来展示MSA系统的一些功能、技术和流量模式。
- en: In this chapter, we will combine both MSA concepts and AI concepts to build
    an ABC-Intelligent-MSA system, which is an enhanced version of our ABC-MSA. The
    intelligent version of the ABC-MSA will use various AI algorithms to enhance the
    performance and general operations of the original ABC-MSA system.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将结合MSA概念和AI概念来构建ABC-Intelligent-MSA系统，这是ABC-MSA的增强版本。ABC-MSA的智能版本将使用各种AI算法来增强原始ABC-MSA系统的性能和一般操作。
- en: ABC-Intelligent-MSA will be able to examine different traffic patterns and detect
    potential problems and then **self-rectify** or self-adjust to try to prevent
    the problem from taking place before it actually happens.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ABC-Intelligent-MSA将能够检查不同的流量模式，并检测潜在的问题，然后**自我纠正**或自我调整，以尝试在问题实际发生之前防止其发生。
- en: The ABC-Intelligent-MSA will be able to **self-learn** the traffic behavior,
    API calls, and response patterns, and try to **self-heal** if a traffic anomaly
    or problematic pattern is detected for whatever reason.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ABC-Intelligent-MSA将能够**自我学习**流量行为、API调用和响应模式，并在检测到任何原因的流量异常或问题模式时尝试**自我修复**。
- en: 'The following topics are covered in this chapter:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了以下主题：
- en: The machine learning advantage
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的优势
- en: Building your first AI microservice
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建你的第一个AI微服务
- en: The intelligent MSA system in action
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 智能MSA系统在实际中的应用
- en: Analyzing AI service operations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析AI服务操作
- en: The machine learning advantage
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的优势
- en: There are many areas in our MSA where we can leverage AI to enhance the system’s
    reliability and operability. We will focus our system on two main potential areas
    of enhancement. One is to enhance the system response in case of a microservice
    failure or performance degradation. The second area of enhancement is to add a
    proactive circuit breaker role.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的MSA中，有许多领域可以利用AI来增强系统的可靠性和可操作性。我们将重点关注两个主要的潜在增强领域。一个是增强系统对微服务故障或性能下降的响应。第二个增强领域是添加一个主动断路器角色。
- en: As we discussed in [*Chapter 3*](B18934_03.xhtml#_idTextAnchor039), the circuit
    breaker pattern is used to prevent a system cascading failure when one of the
    system’s microservices fails to respond to API consumer requests promptly. Should
    a microservice fail or perform poorly, our AI will try to take proactive action
    to fix the problem rather than waiting for the problem to be manually fixed for
    the system to return to normal operation.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[*第3章*](B18934_03.xhtml#_idTextAnchor039)中讨论的，断路器模式用于防止系统在其中一个系统微服务未能及时响应API消费者请求时发生级联故障。如果一个微服务失败或表现不佳，我们的AI将尝试采取主动行动来解决问题，而不是等待手动修复问题以使系统恢复正常运行。
- en: In [*Chapter 7*](B18934_07.xhtml#_idTextAnchor079), we discussed the advantages
    of using **Machine Learning** (**ML**) and DL in MSA in detail. This chapter will
    focus on building two AI microservices to enhance our MSA system.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第7章*](B18934_07.xhtml#_idTextAnchor079)中，我们详细讨论了在MSA中使用**机器学习**（**ML**）和深度学习（**DL**）的优势。本章将专注于构建两个AI微服务来增强我们的MSA系统。
- en: The first AI microservice is called a **Performance Baseline Watchdog** (**PBW**)
    service. The PBW is an ML microservice that creates a baseline for the expected
    performance of each microservice in the MSA system under a certain system load.
    Should the operational performance of the measured microservice fall under the
    performance baseline by the configurable value of *x*, the system should send
    a warning message to the **Operation Support System** (**OSS**) or the **Network
    Management System** (**NMS**) and should performance fall by *y* (which is also
    configurable), the system then should take predefined action(s) to try to self-rectify
    and self-heal the MSA system.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个AI微服务被称为**性能基线看门狗**（**PBW**）服务。PBW是一个机器学习微服务，它为MSA系统在特定系统负载下每个微服务的预期性能创建基线。如果测量的微服务的运行性能低于性能基线，并且低于可配置值*x*，系统应向**运营支持系统**（**OSS**）或**网络管理系统**（**NMS**）发送警告消息；如果性能下降*y*（这也是可配置的），系统应采取预定义的行动来尝试自我纠正和自我修复MSA系统。
- en: The second AI microservice we will build in this chapter is the **Performance
    Anomaly Detector** (**PAD**) service. The PAD is an ML microservice that takes
    a holistic view of the entire MSA system. The PAD learns the MSA performance patterns
    and tries to detect any anomalous behavior. It identifies “problematic patterns,”
    tries to automatically detect a problem before it happens, and accordingly takes
    proactive action to fix the faulty area of the system.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将构建的第二个AI微服务是**性能异常检测器**（**PAD**）服务。PAD是一个ML微服务，它对整个MSA系统有一个全面的视角。PAD学习MSA的性能模式，并试图检测任何异常行为。它识别“问题模式”，试图在问题发生之前自动检测到问题，并相应地采取主动措施来修复系统的故障区域。
- en: Building your first AI microservice
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建你的第一个AI微服务
- en: Before we start building our two AI microservices, we need to think about our
    training and test data first – how we will collect our training data, build the
    model accordingly, test the model and measure its reliability, and enhance the
    algorithm’s reliability if needed.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始构建我们的两个AI微服务之前，我们需要首先考虑我们的训练和测试数据——我们将如何收集训练数据，相应地构建模型，测试模型并衡量其可靠性，以及在需要时增强算法的可靠性。
- en: Important Note
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The AI services we are building in our MSA system are only a proof of concept
    to demonstrate the value of implementing AI in MSA systems. Rather, businesses
    should consider an AI service or model that matches their unique needs, business
    process, and their deployed MSA system.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在MSA系统中构建的AI服务只是为了证明概念，以展示在MSA系统中实施AI的价值。相反，企业应考虑一个与他们的独特需求、业务流程以及部署的MSA系统相匹配的AI服务或模型。
- en: We will also need to simulate the use cases themselves. Simulate a system’s
    microservice failure or performance degradation, simulate a cascading failure,
    and we should also be able to simulate some system’s outlier patterns to see how
    the algorithm would detect and react to pattern anomalies.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要模拟使用案例本身。模拟系统微服务的故障或性能下降，模拟级联故障，我们还应该能够模拟一些系统的异常模式，以查看算法如何检测和响应模式异常。
- en: To do all this, let’s first understand how the PBW and PAD microservices fit
    with the overall system’s operation and how they would normally interact with
    the different system’s components.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成所有这些，让我们首先了解PBW和PAD微服务如何与整体系统操作相匹配，以及它们通常如何与不同的系统组件交互。
- en: The anatomy of AI enhancements
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI增强的解剖结构
- en: The main role of both the PBW and PAD is to enhance the stability and reliability
    of our MSA system. It is therefore imperative for both services to constantly
    watch individual microservices and the overall system performance and then take
    the necessary action when performance issues are detected.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: PBW和PAD的主要作用是增强我们MSA系统的稳定性和可靠性。因此，对于这两个服务来说，持续监控单个微服务和整体系统性能，并在检测到性能问题时采取必要的行动是至关重要的。
- en: The training data is first collected in a controlled environment for a specific
    training period, where normal, stable system operations and the average user load
    are simulated and applied. This can be achieved using some of the simulation tools
    we built, which will be discussed later in this section.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据首先在一个受控环境中收集，用于特定的训练期间，其中模拟了正常、稳定的系统操作和平均用户负载。这可以通过我们构建的一些模拟工具实现，这些工具将在本节稍后讨论。
- en: This training period creates an ideal first baseline that will be the main reference
    for the AI services to use during actual production time. The collected training
    data will then be used to build the algorithm. To achieve better and more accurate
    results, the training data and algorithm can be regularly tuned later when more
    information about real-time production traffic is collected.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个训练期间创建了一个理想的第一基线，这将成为AI服务在实际生产时间使用时的主要参考。收集到的训练数据将被用于构建算法。为了获得更好、更准确的结果，可以在收集到更多关于实时生产流量的信息后，定期调整训练数据和算法。
- en: 'The simulated load and system operations are tweaked through multiple simulation
    parameters. These parameters are tweaked regularly to mimic the actual acceptable
    operational performance. The algorithm tweaks would eventually stop (or become
    very minor) as the AI algorithms mature. The cycle of onboarding the AI services
    to the ABC-MSA system is demonstrated in *Figure 10**.1*:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟负载和系统操作通过多个模拟参数进行调整。这些参数会定期调整，以模拟实际可接受的运行性能。随着AI算法的成熟，算法调整最终会停止（或变得非常微小）。将AI服务纳入ABC-MSA系统的周期在*图10.1*中展示：
- en: '![Figure 10.1: AI microservices implementation in ABC-Intelligent-MSA](img/B18934_10_1.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图10.1：ABC-Intelligent-MSA中的AI微服务实现](img/B18934_10_1.jpg)'
- en: 'Figure 10.1: AI microservices implementation in ABC-Intelligent-MSA'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：ABC-Intelligent-MSA中的AI微服务实现
- en: More information on the simulation tools and parameters is coming up in the
    next section.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模拟工具和参数的更多信息将在下一节中提供。
- en: Once the AI services are operational, they will start collecting performance
    stats from each of the system’s microservices through periodic API calls and then
    compare these performance stats with the expected performance or behavior.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦AI服务运行，它们将通过周期性API调用从系统中的每个微服务收集性能统计数据，然后比较这些性能统计数据与预期的性能或行为。
- en: 'Should an individual microservice or the overall system performance deviate
    from what the AI expects to see, a system action will be triggered to either warn
    the system administrators or self-heal whenever possible. *Figure 10**.2* shows
    the high-level architecture of the PBW and PAD services:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果单个微服务或整体系统性能偏离AI期望看到的结果，系统将触发操作，要么警告系统管理员，要么尽可能进行自我修复。*图10.2*显示了PBW和PAD服务的高级架构：
- en: '![Figure 10.2: PBW and PAD services in ABC-Intelligent-MSA](img/B18934_10_2.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图10.2：ABC-Intelligent-MSA中的PBW和PAD服务](img/B18934_10_2.jpg)'
- en: 'Figure 10.2: PBW and PAD services in ABC-Intelligent-MSA'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：ABC-Intelligent-MSA中的PBW和PAD服务
- en: The PBW’s algorithm calculates the expected performance metrics based on the
    performance stats collected. Collected performance stats include API call response
    time stats, the failures or failure rate of individual microservices, the API
    response code, and the load applied on the microservice itself.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: PBW的算法根据收集的性能统计数据计算预期的性能指标。收集的性能统计数据包括API调用响应时间统计、单个微服务的失败或失败率、API响应代码以及施加在微服务本身的负载。
- en: Pre-defined actions are triggered based on how far the microservice deviates
    from the calculated performance metric. Based on the configuration of the PBW,
    the higher the deviation, the more likely a proactive action is to be triggered
    to try to self-heal. In the case of a slight deviation, however, no healing action
    is supposed to be trigged; a system warning informing the system administrator
    is sufficient.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 根据微服务偏离计算性能指标的程度，将触发预定义的操作。根据PBW的配置，偏差越大，主动触发尝试自我修复的可能性就越大。然而，在轻微偏差的情况下，不应触发任何修复操作；系统警告通知系统管理员就足够了。
- en: The following table shows some of the possible system issues that could be encountered
    during the operations of an ABC-Intelligent-MSA system, and the actions the PBW
    service would take to try to rectify the problem.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了在ABC-Intelligent-MSA系统操作过程中可能遇到的一些系统问题，以及PBW服务将采取哪些操作来尝试解决问题。
- en: 'The list shown in the table is only a sample of potential issues and can, of
    course, grow as more use cases are considered:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 表格中显示的列表仅是潜在问题的样本，当然，随着更多用例的考虑，它也可以增长：
- en: '| **Microservice Issue** | **Triggered Action** |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| **微服务问题** | **触发操作** |'
- en: '| Slow responsiveness | Scale the microservice vertically/horizontally or restart
    the microservice |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 响应缓慢 | 垂直/水平扩展微服务或重启微服务 |'
- en: '| Intermittent timeouts | Scale vertically/horizontally or restart |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 间歇性超时 | 垂直/水平扩展或重启 |'
- en: '| API call HTTP response errors | Check Apache, Flask, the JVM, the Docker
    volume, SQL service, etc. Restart the service if neededRestart the microservice’s
    container |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| API调用HTTP响应错误 | 检查Apache、Flask、JVM、Docker卷、SQL服务等。如有需要，重启服务重启微服务的容器 |'
- en: '| Service is unresponsive (down) | Restart the microservice’s container |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 服务无响应（关闭） | 重启微服务的容器 |'
- en: Table 10.1 – Potential ABC-Intelligent-MSA operational issues and the PBW’s
    self-healing actions
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.1 – ABC-Intelligent-MSA操作中可能遇到的问题和PBW的自我修复操作
- en: The healing mechanism can be applied to the MSA system using multiple AI services,
    not necessarily only using the PBW and PAD that we are implementing in our ABC-Intelligent-MSA.
    This is just an example.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 恢复机制可以通过使用多个AI服务应用于MSA系统，而不仅仅是使用我们在ABC-Intelligent-MSA中实施的PBW和PAD。这只是一个例子。
- en: The self-healing process
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自我修复过程
- en: All of the PBW’s healing actions listed in *Table 10.1* should not be taken
    in isolation from the PAD’s operations, but rather should be carefully coordinated
    with the PAD’s healing actions. A single issue in a microservice could (although
    not necessarily) trigger actions from both the PBW and PAD services at the same
    time and could consequently create an operational conflict.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在*表10.1*中列出的所有PBW的修复操作不应孤立于PAD的操作，而应与PAD的修复操作仔细协调。一个微服务中的单个问题可能会（尽管不一定）同时触发PBW和PAD服务的操作，从而可能造成操作冲突。
- en: In terms of the self-healing process, and to avoid conflict between the system’s
    AI services when triggering self-healing actions, whenever an action is determined
    and before it is triggered, the AI service sends an API call to the other AI services
    first (either directly or through the API gateway), declaring a **Self-Healing
    Lock State** in the troubled microservice. Accordingly, all the other AI services
    in the MSA system will hold off any actions that may have been planned related
    to that troubled microservice.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在自我修复过程中，为了避免在触发自我修复操作时系统AI服务之间发生冲突，每当确定一个操作并在触发之前，AI服务首先向其他AI服务发送API调用（无论是直接还是通过API网关），在受影响的微服务中声明**自我修复锁定状态**。因此，MSA系统中的所有其他AI服务将推迟任何与该受影响微服务相关的计划中的操作。
- en: During the self-healing lock state, the only AI service allowed to work on the
    troubled microservice is the **Healer AI Service**, which is the AI service that
    locked it.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在自我修复锁定状态下，唯一允许在受影响的微服务上工作的AI服务是**修复AI服务**，正是这个AI服务将其锁定。
- en: Once the healer has fixed the problem and detects a normal operation in the
    affected microservice, the healer then sends another API call to the other AI
    services in the MSA system declaring that the lock state is over.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦修复者修复了问题并检测到受影响的微服务中的正常操作，修复者随后向MSA系统中的其他AI服务发送另一个API调用，声明锁定状态结束。
- en: If the healer is unable to self-heal and gives up on resolving the issue, it
    sends an alarm to the NMS/OSS and marks that microservice as **unhealable** for
    a specific configurable period of time, known as the **Unhealable Wait Period**
    (by default, 15 minutes).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果修复者无法自我修复并放弃解决问题，它将向NMS/OSS发送警报，并将该微服务标记为**无法修复**，持续特定可配置的时间，称为**无法修复的等待期**（默认为15分钟）。
- en: The unhealable wait period allows other AI services to try to heal that microservice
    and gives the healer a breather to pace out its operation across all other microservices
    in the MSA system.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 无法修复的等待期允许其他AI服务尝试修复该微服务，并给修复者一个喘息的机会，以调整其在MSA系统中的所有其他微服务上的操作。
- en: To prevent healers from consuming system resources by slipping into indefinite
    healing attempts, healers will try to heal the troubled microservices for a specific
    number of healing attempts, configured through the **Maximum Healing Attempts**
    value (four attempts, by default), and will then completely give up trying. If
    the maximum healing attempts are exhausted, a manual system intervention will
    be needed to fix the troubled microservice.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止修复者通过无限期的修复尝试消耗系统资源，修复者将尝试修复受影响的微服务特定数量的修复尝试，通过**最大修复尝试次数**值（默认为四次）进行配置，然后完全放弃尝试。如果最大修复尝试次数耗尽，则需要手动系统干预来修复受影响的微服务。
- en: System administrators can still configure indefinite healing attempts if needed,
    but this can consume system resources and may not be effective depending on the
    nature of the problem the MSA system or a specific microservice is experiencing.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，系统管理员仍然可以配置无限期的修复尝试，但这可能会消耗系统资源，并且根据MSA系统或特定微服务遇到的问题的性质，可能不会有效。
- en: If another AI service can fix the troubled microservice or the microservice
    is manually fixed, the original healer will automatically clear the unhealable
    flag of the microservice after the unhealable wait period is over.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果另一个AI服务可以修复受影响的微服务或微服务被手动修复，在无法修复的等待期结束后，原始修复者将自动清除微服务的无法修复标志。
- en: If on the other hand, no other AI service can fix the problem and no manual
    intervention is taken to fix the microservice, the original healer – and any other
    healer that may have tried to fix the microservice – will try to heal the microservice
    again once the unhealable wait period expires if and only if the troubled microservice
    is not in a self-healing lock state.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果另一方面，没有其他AI服务可以修复问题，并且没有手动干预来修复微服务，那么当无法修复的等待期结束后，原始的治愈者——以及任何可能尝试修复微服务的其他治愈者——将再次尝试修复微服务，前提是有问题的微服务不在自愈锁定状态。
- en: The following visual chart summarizes the self-healing process and may help
    better explain the entire process.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下视觉图表总结了自愈过程，可能有助于更好地解释整个过程。
- en: '![Figure 10.3: The self-healing process in MSA](img/B18934_10_3.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图10.3：MSA中的自愈过程](img/B18934_10_3.jpg)'
- en: 'Figure 10.3: The self-healing process in MSA'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：MSA中的自愈过程
- en: 'It is important to also understand the main terminology used to explain the
    self-healing process. The following table shows a summary of the terminology of
    the main components of our self-healing process:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 理解用于解释自愈过程的主要术语也很重要。以下表格展示了我们自愈过程主要组件术语的总结：
- en: '| **Term** | **Description** |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| **术语** | **描述** |'
- en: '| Healer | An AI service that attempts to heal a troubled microservice. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 治愈者 | 一种尝试修复有问题的微服务的AI服务。|'
- en: '| Healing Action | An action taken by the healer to try to fix an ongoing system
    operational issue. |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 治愈动作 | 治愈者采取的行动，以尝试修复正在进行的系统操作问题。|'
- en: '| Self-Healing Lock State | A microservice state in which an attempt is made
    by the healer to fix the microservice.In this state, only one healer (the one
    that initiated the lock state) is allowed to work on the troubled microservice.A
    microservice self-healing lock state is a state visible by the entire MSA system
    and not a healer-specific state. |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 自愈锁定状态 | 当治愈者尝试修复微服务时的微服务状态。在此状态下，只有一位治愈者（启动锁定状态的治愈者）被允许对有问题的微服务进行操作。微服务自愈锁定状态是整个MSA系统可见的状态，而不是特定于治愈者的状态。|'
- en: '| Retry Wait Period | The time the healer for which has to wait when a healing
    action fails before it retries. The Retry Wait Period is 2 min by default. |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 重试等待期 | 治愈者在治愈动作失败后必须等待的时间，然后它才会重试。默认情况下，重试等待期为2分钟。|'
- en: '| Unhealable State | The state in which the troubled microservice is marked
    unfixable by a healer after a healer’s failed attempt to fix the troubled microservice.A
    microservice unhealable state is a healer-specific state and only visible to the
    healer that gave up on fixing that troubled microservice. Other healers can still
    try to fix the troubled microservice. |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 无法修复的状态 | 治愈者在其尝试修复有问题的微服务失败后，将该微服务标记为无法修复的状态。微服务的无法修复状态是特定于治愈者的状态，并且只有放弃修复该有问题的微服务的治愈者可见。其他治愈者仍然可以尝试修复有问题的微服务。|'
- en: '| Unhealable Wait Period | The time for which the healer has to wait before
    it starts to make another attempt to fix the troubled microservice. The Unhealable
    Wait Period is 15 min by default. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 无法修复的等待期 | 治愈者必须等待的时间，然后它才会开始尝试修复有问题的微服务。默认情况下，无法修复的等待期为15分钟。|'
- en: '| Maximum Healing Attempts | The maximum number of attempts the healer will
    try after each unhealable wait period, and before the healer totally gives up
    on the troubled microservice and no longer attempt to fix it. By default, PBW
    tries 4 healing attempts. |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 最大治愈尝试次数 | 治愈者在完全放弃有问题的微服务并停止尝试修复它之前，在每个无法修复的等待期后将会尝试的最大次数。默认情况下，PBW尝试4次治愈尝试。|'
- en: 'Table 10.2: ABC-Intelligent-MSA operational issues with the self-rectifying
    actions of the PBW'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.2：ABC-Intelligent-MSA的操作问题与PBW的自纠正动作
- en: So far, we have explained the value of deploying AI services in the MSA system
    and shown some practical application examples to demonstrate the value of AI in
    MSA.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经解释了在MSA系统中部署AI服务的价值，并展示了几个实际应用示例来证明AI在MSA中的价值。
- en: In order to build, run, and tweak AI services in MSA, we need to build certain
    tools to gather and log system statuses, operational dynamics, and operational
    statistics. In the following section, we will dive into what these tools are and
    how to use them.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在MSA中构建、运行和调整AI服务，我们需要构建某些工具来收集和记录系统状态、操作动态和操作统计。在下一节中，我们将深入了解这些工具是什么以及如何使用它们。
- en: Building the necessary tools
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建必要的工具
- en: The purpose of creating project tools is to first be able to build the AI models,
    then simulate the entire ABC-Intelligent-MSA system, and then collect stats and
    analyze the system’s operations.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 创建项目工具的目的是首先能够构建 AI 模型，然后模拟整个 ABC-Intelligent-MSA 系统，然后收集统计数据并分析系统的操作。
- en: Although there may be tools available online that would help us achieve our
    purpose, instead, we will build simple tools customized specifically for our use
    cases.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可能有一些在线工具可以帮助我们实现我们的目的，但我们将构建针对我们特定用例定制的简单工具。
- en: We created multiple tools to help us collect training and test data, simulate
    the system and microservices load, and measure the performance of the microservices.
    All the tools are available in the `tools` directory in our GitHub repository.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了多个工具来帮助我们收集训练和测试数据，模拟系统和微服务负载，以及衡量微服务的性能。所有工具都可在我们的 GitHub 仓库中的 `tools`
    目录中找到。
- en: The tools also help us scrub some of the generated logs and data for analysis
    and potential future enhancements.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 工具还帮助我们清理一些生成的日志和数据，以便进行分析和潜在的将来改进。
- en: The following are the main tools we need in our ABC-Intelligent-MSA setup.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们 ABC-Intelligent-MSA 设置中需要的主要工具。
- en: An API traffic simulator
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: API 流量模拟器
- en: The API traffic generator/simulator, `simulate_api_rqsts.py`, helps simulate
    the API request load for one or more of the system’s microservices.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: API 流量生成器/模拟器 `simulate_api_rqsts.py` 帮助模拟系统的一个或多个微服务的 API 请求负载。
- en: '`simulate_api_rqsts` creates multi-threaded API requests across multiple target
    microservices. API HTTP requests are then sent to each microservice in parallel.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`simulate_api_rqsts` 在多个目标微服务之间创建多线程 API 请求。然后并行将 API HTTP 请求发送到每个微服务。'
- en: The API load is measured by requests per minute and API requests can either
    be uniformly or randomly paced.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: API 负载是通过每分钟的请求数来衡量的，API 请求可以是均匀的或随机的。
- en: The uniformly paced requests are paced out so that the time between each API
    call is always the same, so if we are configuring a uniformly paced load of 600
    API requests/min, `simulate_api_rqsts` will send 1 API call every T = 100 ms.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 均匀速率的请求被安排得使得每个 API 调用之间的时间总是相同的，因此如果我们配置了 600 API 请求/分钟的均匀速率负载，`simulate_api_rqsts`
    将每 T = 100 毫秒发送 1 个 API 调用。
- en: In the randomly-paced case, each API call is sent after a random period, TR,
    from the time where the previous call was sent, but so that TR can never be larger
    or smaller than 95% of T. So if we are configuring a randomly-paced load of 600
    API requests/min, TR, in that case, will be equal to a value greater than 5 ms
    and smaller than 195 ms.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在随机速率的情况下，每个 API 调用都是在从上一个调用发送的时间开始的随机时间段 TR 后发送的，但 TR 不能大于或小于 T 的 95%。因此，如果我们配置了
    600 API 请求/分钟的随机速率负载，在这种情况下，TR 将等于一个大于 5 毫秒且小于 195 毫秒的值。
- en: '`simulate_api_rqsts` will send 1 API call every:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`simulate_api_rqsts` 将每：'
- en: '*(1-95%)T <= T*R *<= (1+95%)T* (i.e., for 600 requests/min: *5 ms <= TR <=*
    *195 ms*)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*(1-95%)T <= T*R *<= (1+95%)T*（即对于 600 请求/分钟：*5 毫秒 <= TR <=* *195 毫秒*）'
- en: The sum of all TRs, however, will still be approximately equal to the configured
    requests/min. In our example here, the load is 600 API requests/min.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，所有 TR 的总和仍然大约等于配置的请求/分钟。在我们的例子中，负载是 600 API 请求/分钟。
- en: Uniformly paced requests are better when you are manually analyzing how a particular
    microservice responds to the API load, while randomly paced requests are a better
    representation of a real-time production API request load.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当你手动分析特定微服务如何响应 API 负载时，均匀速率的请求更好，而随机速率的请求则更好地代表了实时生产 API 请求负载。
- en: The microservices performance monitor
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微服务性能监控器
- en: The microservices performance monitor, `ms_perfmon.py`, is another multithreading
    tool and is initially used for collecting and building the AI training data during
    the simulation period of ideal conditions.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务性能监控器 `ms_perfmon.py` 是另一个多线程工具，最初用于在理想条件下的模拟期间收集和构建 AI 训练数据。
- en: '`ms_perfmon` sends parallel API calls to each microservice in the system and
    then logs the API call hyperlink, the date and time at which it was sent, the
    receiving microservice response time, and the HTTP response code. The following
    is an example log entry of the collected data in a comma-separated format:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`ms_perfmon` 向系统中的每个微服务发送并行 API 调用，然后记录 API 调用超链接、发送的日期和时间、接收微服务的响应时间和 HTTP
    响应代码。以下是一个以逗号分隔的格式收集数据的示例日志条目：'
- en: '[PRE0]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Each microservice stat is collected in its own `perfmon_stats` directory in
    the `ms_perfmon` working path.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 每个微服务的统计数据都收集在其 `ms_perfmon` 工作路径下的 `perfmon_stats` 目录中。
- en: In real-time operation, both the PBW and PAD perform a similar job to `ms_perfmon`.
    They collect their own stats and measure the target microservice’s real-time performance
    against the baseline and the expected normal behavior.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在实时操作中，PBW和PAD都执行与`ms_perfmon`类似的工作。它们收集自己的统计数据，并将目标微服务的实时性能与基线和预期正常行为进行比较。
- en: Should we extend the MSA system’s AI capabilities by including more AI services
    for different purposes and use cases, which will likely require each AI service
    to conduct its own performance statistics collection?
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否应该通过包括更多用于不同目的和用例的AI服务来扩展MSA系统的AI能力，这可能会要求每个AI服务进行自己的性能统计收集？
- en: Depending on the collection frequency and the type of data collected, as the
    number of collectors increases, scalability could become an issue. The `ms_perfmon`
    function, in that case, can be extended to become the main AI collector for all
    AI or non-AI services in the MSA system. This setup can help offload the system’s
    microservices and allow the MSA system to scale better.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 根据收集频率和数据收集类型，随着收集器的数量增加，可扩展性可能成为一个问题。在这种情况下，`ms_perfmon`函数可以扩展成为MSA系统中所有AI或非AI服务的主要AI收集器。这种设置可以帮助减轻系统的微服务负担，并允许MSA系统更好地扩展。
- en: '![Figure 10.4: A collect-once performance stats setup in ABC-Intelligent-MSA](img/B18934_10_4.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图10.4：ABC-Intelligent-MSA中的单次收集性能统计数据设置](img/B18934_10_4.jpg)'
- en: 'Figure 10.4: A collect-once performance stats setup in ABC-Intelligent-MSA'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4：ABC-Intelligent-MSA中的单次收集性能统计数据设置
- en: '*Figure 10**.4* shows how `ms_perfmon` can handle stats collection on behalf
    of all other services in the MSA system and then act as a proxy and respond to
    API calls requesting whatever stats are needed for each particular AI (or non-AI)
    service.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10.4*显示了`ms_perfmon`如何代表MSA系统中的所有其他服务处理统计数据收集，然后作为代理并对请求特定AI（或非AI）服务所需任何统计数据的API调用做出响应。'
- en: The response delay simulator
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 响应延迟模拟器
- en: To simulate a delayed response or a troubled microservice, and solely for simulation
    and testing purposes, we added a feature in key microservices to simulate a delayed
    API call response.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟延迟响应或故障微服务，并且仅限于模拟和测试目的，我们在关键微服务中添加了一个功能，以模拟延迟的API调用响应。
- en: The delay response feature, when enabled in the microservice, has two configurable
    values – the minimum delay and the maximum delay. When a microservice receives
    an API call, it will automatically assign a random delay value between the configured
    minimum delay and maximum delay, and then wait for that time before it responds
    to the consumer’s API calls.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当在微服务中启用延迟响应功能时，有两个可配置的值——最小延迟和最大延迟。当微服务接收到API调用时，它将自动分配一个介于配置的最小延迟和最大延迟之间的随机延迟值，然后等待这段时间后再对消费者的API调用做出响应。
- en: The feature is very helpful for simulating a cascading system failure. As will
    be shown later in this chapter, the response delay feature can also help demonstrate
    the value of using AI services to enhance the operations of the MSA system compared
    to using the short circuit traffic pattern previously explained in [*Chapter 3*](B18934_03.xhtml#_idTextAnchor039).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能对于模拟级联系统故障非常有帮助。正如本章后面将要展示的，响应延迟功能还可以帮助展示使用AI服务增强MSA系统操作的价值，与之前解释的短路流量模式相比。
- en: 'The response delay is enabled whenever the max delay is configured with a value
    greater than zero. When the value of max delay is higher than zero, a delay value
    is assigned to the microservice API’s call response, as shown in the following
    code snippet:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当最大延迟配置的值大于零时，响应延迟功能被启用。当最大延迟的值高于零时，会将一个延迟值分配给微服务API的调用响应，如下面的代码片段所示：
- en: '[PRE1]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The max and min delay values can be configured using an API call. The following
    is an example of using `curl` to send an API call to configure the maximum and
    minimum delay response in milliseconds:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用API调用配置最大和最小延迟值。以下是一个使用`curl`发送API调用以配置最大和最小延迟响应（以毫秒为单位）的示例：
- en: '[PRE2]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Again, this feature is only for demo and test purposes. A more secure way of
    simulating a delay is using secured configuration files or local parameters instead.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，此功能仅用于演示和测试目的。模拟延迟的更安全方式是使用受保护的配置文件或本地参数。
- en: The API response error simulator
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: API响应错误模拟器
- en: Similar to the response delay simulator, this feature is for demo purposes only.
    The API error simulator feature uses one configurable value – the average HTTP
    error per hour. When the feature is enabled in the microservice, the microservice
    will pick a randomly applicable server 500 error and respond to API requests with
    randomly paced responses that match the configured error rate.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 与响应延迟模拟器类似，此功能仅用于演示目的。API错误模拟器功能使用一个可配置的值——每小时的平均HTTP错误。当在微服务中启用此功能时，微服务将随机选择一个适用的服务器500错误，并以匹配配置错误率的随机速度响应API请求。
- en: 'The error rate can be configured using an API call. The following is an example
    of using `curl` to send an API call to configure an API error response rate of
    `5` HTTP errors per hour:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用API调用配置错误率。以下是一个使用`curl`发送API调用以配置每小时`5`个HTTP错误的API错误响应率的示例：
- en: '[PRE3]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now, we know the testing and simulation tools available for us to use for training,
    testing, and simulating production for our MSA system.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们知道了可用于我们进行训练、测试和模拟MSA系统生产的测试和模拟工具。
- en: In the next section, we will discuss our ABC-Intelligent-MSA operations – how
    to initialize the system, how to build and use training and testing data, and
    how to simulate the system’s production traffic.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论我们的ABC-Intelligent-MSA操作——如何初始化系统，如何构建和使用训练和测试数据，以及如何模拟系统的生产流量。
- en: The intelligent MSA system in action
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 智能MSA系统正在运行中
- en: In the previous sections of this chapter, we discussed how the different system
    components interact with each other and what tools we use to build the AI algorithms,
    test the system, and monitor the operations of different components.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的前几节中，我们讨论了不同的系统组件之间是如何相互作用的，以及我们使用哪些工具来构建AI算法、测试系统和监控不同组件的操作。
- en: In this section, we will put our ABC-Intelligent-MSA to the test. We will run
    all system microservices and tools, and see how the different system components
    actually interact with each other, what results we see, and how we can tweak the
    system to maintain smooth end-to-end operations.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将对ABC-Intelligent-MSA进行测试。我们将运行所有系统微服务和工具，看看不同的系统组件实际上是如何相互作用的，我们会看到什么结果，以及我们如何调整系统以保持端到端操作的流畅。
- en: The ABC-Intelligent-MSA will first run under an ideal simulation environment
    (no error simulation and no delays) to collect the training data necessary to
    build the AI models. Once enough data has been collected, we will then train the
    models and prepare the system for actual production traffic.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ABC-Intelligent-MSA将首先在一个理想的模拟环境中运行（没有错误模拟和延迟），以收集构建AI模型所需的训练数据。一旦收集到足够的数据，我们将训练模型并准备系统以应对实际生产流量。
- en: 'The system initialization steps, therefore, are as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，系统初始化步骤如下：
- en: Start the system with no AI services to collect the necessary training data
    under an ideal operational situation and create an operational baseline.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在理想操作情况下，不启动AI服务来收集必要的训练数据，并创建一个操作基线。
- en: Sanitize the collected data if needed and remove outliers.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如有必要，对收集到的数据进行清理并移除异常值。
- en: Train the AI algorithms using the training data collected.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用收集到的训练数据训练AI算法。
- en: Re-initialize the system with all of its AI services.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新初始化系统，包括所有AI服务。
- en: Start production operations. In our example here, we will simulate actual production
    operations by injecting errors, data delay responses, service failures, and so
    on.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始生产操作。在我们的例子中，我们将通过注入错误、数据延迟响应、服务故障等来模拟实际生产操作。
- en: Initializing the ABC-Intelligent-MSA system
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始化ABC-Intelligent-MSA系统
- en: We start by initializing our MSA system using the system’s Docker compose file,
    `abc_ msa.yaml`, and using the `docker-compose` command as follows,
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用系统的Docker compose文件`abc_ msa.yaml`和`docker-compose`命令初始化我们的MSA系统，如下所示，
- en: '[PRE4]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As discussed previously in [*Chapter 9*](B18934_09.xhtml#_idTextAnchor102),
    the preceding `docker-compose` command is much more convenient than using multiple
    `docker run` commands. `docker-compose` will read the system’s run parameters
    and configuration from the `abc _msa.yaml` file, and initialize all the system
    components accordingly.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在[*第9章*](B18934_09.xhtml#_idTextAnchor102)中，前面的`docker-compose`命令比使用多个`docker
    run`命令要方便得多。`docker-compose`将从`abc _msa.yaml`文件中读取系统的运行参数和配置，并据此初始化所有系统组件。
- en: In our example, this will start the analysis and monitoring tools, along with
    all the regular microservices in the system. Since we are still collecting training
    data, no AI services need to be initialized yet.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，这将启动分析和监控工具，以及系统中的所有常规微服务。由于我们仍在收集训练数据，因此目前尚不需要初始化任何AI服务。
- en: As shown in *Figure 10**.2* and *Figure 10**.4*, when we start the AI services
    (the PBW and PAD), they will need to be able to remotely control (start, stop,
    and restart) the system’s Docker containers. The PBW and PAD are designed to control
    the Docker containers using API calls. Therefore, we need to enable Docker Engine
    first to respond to API calls and for the PBW and PAD to be able to successfully
    communicate with Docker Engine.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图10**.2*和*图10**.4*所示，当我们启动AI服务（PBW和PAD）时，它们需要能够远程控制（启动、停止和重启）系统的Docker容器。PBW和PAD被设计为通过API调用控制Docker容器。因此，我们需要首先启用Docker引擎以响应API调用，并使PBW和PAD能够成功与Docker引擎通信。
- en: 'The following are the steps needed to enable Docker’s API remote management:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 启用Docker的API远程管理所需的步骤如下：
- en: On your Ubuntu system, use `vi`, `vim`, or any other similar tool to edit the
    `/``lib/systemd/system/docker.service` file.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的Ubuntu系统上，使用`vi`、`vim`或任何其他类似工具编辑`/lib/systemd/system/docker.service`文件。
- en: 'Look for the `ExecStart` entry and make the necessary modifications for it
    to be like the following:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找`ExecStart`条目，并对其进行必要的修改，使其如下所示：
- en: '[PRE5]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This will enable Docker Engine to listen to API calls. Make sure you save the
    file after the modifications.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将使Docker引擎能够监听API调用。确保在修改后保存文件。
- en: 'Reload Docker Engine using the following command:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令重新加载Docker引擎：
- en: '[PRE6]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To ensure Docker Engine is working properly and responding to API calls, use
    the following command:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了确保Docker引擎正常工作并响应API调用，请使用以下命令：
- en: '[PRE7]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, the system is running and collecting training data. The longer you run
    the system, the more training data will be collected, and the more accurate your
    AI models will be. In our example, we will leave the system running for approximately
    48 hours.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，系统正在运行并收集训练数据。系统运行的时间越长，收集到的训练数据就越多，您的AI模型就会越准确。在我们的示例中，我们将让系统运行大约48小时。
- en: In the next subsection, we will go over how to run the tools, build training
    data, collect some of the system performance logs, simulate real-time system operations,
    and analyze the collected performance data.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将介绍如何运行工具、构建训练数据、收集一些系统性能日志、模拟实时系统操作，以及分析收集到的性能数据。
- en: Building and using the training data
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建和使用训练数据
- en: The `ms_perfmon` tool will create a separate stat file for each microservice
    in the `<ms_perfmon's working path>/perfmon_stats` directory. It is important
    that we leave the tool running and monitor the system’s performance stats under
    minimal load conditions.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`ms_perfmon`工具将在`<ms_perfmon的工作路径>/perfmon_stats`目录为每个微服务创建一个单独的统计文件。保持工具运行并监控系统性能统计信息在最小负载条件下是非常重要的。'
- en: We recommend at least 48 hours of training data collection. Ideally, however,
    data should be collected with seasonality load whenever applicable. In some environments,
    for example, the system load may increase on weekends over weekdays, during the
    shopping season, and so on. These situations should be considered in the training
    data to be able to build a more accurate AI model.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议至少收集48小时的训练数据。理想情况下，数据应在适用的情况下收集季节性负载。例如，在某些环境中，系统负载可能在周末比工作日高，在购物季节等。这些情况应在训练数据中考虑，以便能够构建更准确的AI模型。
- en: Performance data is pulled every 10 seconds, and accordingly, with 48h of active
    monitoring, `ms_perfmon` produces 17,280 entries for each microservice.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 性能数据每10秒拉取一次，因此，在48小时的活跃监控下，`ms_perfmon`为每个微服务生成17,280条记录。
- en: Regardless of the length of the system’s training period, whenever enough performance
    data has been collected, the `training_data_cleanup.py` tool should be run to
    detect any outliers and sanitize the performance data before using it in our AI
    services.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 无论系统的训练期有多长，只要收集到足够的性能数据，就应该运行`training_data_cleanup.py`工具来检测任何异常值并在将其用于我们的AI服务之前清理性能数据。
- en: The `training_data_cleanup` tool scrubs all the performance data files in the
    `<ms_perfmon's working path>/perfmon_stats` directory, and automatically creates
    a `scrubbed_stats` directory with all the scrubbed data for each microservice.
    These scrubbed files are the files that we will later use for training the AI
    services.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`training_data_cleanup` 工具会清理 `<ms_perfmon''s working path>/perfmon_stats`
    目录下所有的性能数据文件，并自动创建一个包含所有清理数据的 `scrubbed_stats` 目录，每个微服务对应一个目录。这些清理后的文件是我们稍后用于训练
    AI 服务的文件。'
- en: 'We are now ready to write our Python code for training the PBW:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好编写用于训练 PBW 的 Python 代码：
- en: 'We will use the `numpy` library for array and scientific data processing, `pandas`
    for reading our CSV training data files and testing data, and `sklearn` to build
    our AI model:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用 `numpy` 库进行数组和科学数据处理，使用 `pandas` 读取我们的 CSV 训练数据文件和测试数据，以及使用 `sklearn`
    构建我们的 AI 模型：
- en: '[PRE8]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'After importing the required libraries, we now need to copy all performance
    data into a DataFrame object. The following is a code example of this:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库后，我们现在需要将所有性能数据复制到一个 DataFrame 对象中。以下是一个代码示例：
- en: '[PRE9]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The PBW’s AI model includes the microservice response time, the calculated request
    failure rate, and the calculated microservice load. The model should calculate
    the expected response time based on all the preceding parameters.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: PBW 的 AI 模型包括微服务响应时间、计算出的请求失败率和计算出的微服务负载。该模型应根据所有前面的参数计算预期的响应时间。
- en: 'In our Python code, we need to point to the data column that needs to be predicted.
    In our example, that would be the response time. The following is a code snippet
    for the Payment microservice:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的 Python 代码中，我们需要指向需要预测的数据列。在我们的示例中，那将是响应时间。以下是对 Payment 微服务的代码片段：
- en: '[PRE10]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We need now to build our model, but before doing so, we need to load the rest
    of the performance data column into an array for training and testing processing.
    We do that by removing the “response time” column (an axis of `1`) from the created
    DataFrame and then loading that DataFrame into an array to be used in our `sklearn`
    object, as follows:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在需要构建我们的模型，但在这样做之前，我们需要将剩余的性能数据列加载到一个数组中，以便进行训练和测试处理。我们通过从创建的 DataFrame 中移除“响应时间”列（一个轴为
    `1`）来实现这一点，然后将该 DataFrame 加载到数组中，用于我们的 `sklearn` 对象，如下所示：
- en: '[PRE11]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The model data need to be split into training data and test data. We split
    the model data into 80% training and 20% test data as follows:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要将模型数据分为训练数据和测试数据。我们将模型数据分为 80% 的训练数据和 20% 的测试数据，如下所示：
- en: '[PRE12]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, we build the model from the training data:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们从训练数据构建模型：
- en: '[PRE13]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Save the data to a CSV file for future use:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据保存到 CSV 文件以备将来使用：
- en: '[PRE14]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now, we have the training data and the trained model. It is time to use the
    model for production traffic.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了训练数据和训练好的模型。是时候使用该模型进行生产流量了。
- en: In the next subsection, we will simulate production operations and describe
    how that can be applied to our trained MSA system, the ABC-Intelligent-MSA.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将模拟生产操作并描述如何将其应用于我们训练的 MSA 系统，即 ABC-Intelligent-MSA。
- en: Simulating the ABC-Intelligent-MSA’s operation
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模拟 ABC-Intelligent-MSA 的操作
- en: We need to reinitialize the system now with the trained model and production
    traffic. Since no actual production traffic is applied in our example, we need
    to simulate the production operation with its potential operational challenges,
    including high traffic loads, service failures, and potential network hiccups.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要使用训练好的模型和生产流量重新初始化系统。由于我们的示例中没有应用实际的生产流量，我们需要模拟生产操作及其潜在的操作挑战，包括高流量负载、服务故障和潜在的网络安全问题。
- en: 'We start by reinitializing the ABC-Intelligent-MSA system using `docker-compose`,
    as described earlier, but using the `abc_intelligent_msa.yaml` file:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用 `docker-compose` 重新初始化 ABC-Intelligent-MSA 系统，如前所述，但使用 `abc_intelligent_msa.yaml`
    文件：
- en: '[PRE15]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The main difference between `abc_intelligent_msa.yaml` and `abc _msa.yaml` is
    that the first file includes the initialization of the AI services.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`abc_intelligent_msa.yaml` 和 `abc_msa.yaml` 之间的主要区别在于第一个文件包含了 AI 服务的初始化。'
- en: Once the system is running, the AI tools will start monitoring and collecting
    the microservice’s performance and trigger healing actions whenever a system problem
    is detected and metrics exceed the configured performance thresholds.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦系统运行，AI 工具将开始监控和收集微服务的性能，并在检测到系统问题且指标超过配置的性能阈值时触发修复操作。
- en: The production traffic is ready to be simulated now using the `simulate_api_rqsts`
    API traffic simulator and the response delay simulator function discussed earlier.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可以使用`simulate_api_rqsts` API流量模拟器和之前讨论的响应延迟模拟功能来模拟生产流量。
- en: Using the API response error simulator, occasional HTTP errors can also be simulated
    if needed. A more sophisticated simulation would involve injecting HTTP 500 error
    codes as well, but we will stick to response time performance delays for simplicity.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 使用API响应错误模拟器，如果需要，也可以模拟偶尔的HTTP错误。更复杂的模拟将涉及注入HTTP 500错误代码，但我们为了简单起见，将坚持使用响应时间性能延迟。
- en: The `ms_perfmon` tool will still be running to collect data for our offline
    analysis whenever needed.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '`ms_perfmon`工具将始终运行，以便在需要时收集我们的离线分析数据。'
- en: We now need to simulate specific production use cases and see how the AI tools
    will respond and self-heal the entire system. In the next section, we will discuss
    the operations of the PBW and PAD and look into how both AI services interact
    with system performance readings and errors.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要模拟特定的生产用例，并查看AI工具将如何响应并自愈整个系统。在下一节中，我们将讨论PBW和PAD的操作，并探讨这两个AI服务如何与系统性能读数和错误交互。
- en: Analyzing AI service operations
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析AI服务操作
- en: In the preceding sections, we started by building our first AI service and covered
    how to use AI to enhance the MSA system’s operations and resilience, the self-healing
    process, and the tools we built to generate training data and simulate the ABC-Intelligent-MSA
    system’s operation.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们首先构建了我们的第一个AI服务，并介绍了如何使用AI来增强MSA系统的操作和弹性、自愈过程以及我们构建的用于生成训练数据和模拟ABC-Intelligent-MSA系统操作的工具体。
- en: In this section, we will examine the system logs and check how the PBW and PAD
    interact with the system and actually enhance its operations. We will then simulate
    a cascading system failure and examine how the self-healing process is triggered
    and handled to bring the MSA system back to normal operation.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将检查系统日志，并检查PBW和PAD如何与系统交互以及实际上如何增强其操作。然后，我们将模拟级联系统故障，并检查自愈过程是如何被触发和处理，以将MSA系统恢复到正常操作。
- en: The PBW in action
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PBW正在行动
- en: 'During the training period, the PBW was able to build an AI model and calculate
    the expected response time of each microservice in the ABC-Intelligent-MSA system.
    As you can see from the following log sample, under a normal system load, the
    average response time of the Inventory microservice is about 20 ms:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练期间，PBW能够构建AI模型并计算ABC-Intelligent-MSA系统中每个微服务的预期响应时间。从下面的日志样本中可以看出，在正常系统负载下，库存微服务的平均响应时间约为20毫秒：
- en: '[PRE16]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We configured the warning threshold for the PBW as 250 ms, and the action threshold
    as 750 ms. We will now start introducing an API call load to the Inventory microservice
    using `simulate_api_rqsts` and delays using the response delay simulator feature.
    Then, we will see how the PBW reacts from the PBW action logs.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将PBW的警告阈值配置为250毫秒，操作阈值配置为750毫秒。现在，我们将开始通过使用`simulate_api_rqsts`向库存微服务引入API调用负载，并使用响应延迟模拟器功能引入延迟。然后，我们将从PBW操作日志中看到PBW的反应。
- en: 'The following are the PBW’s performance readings for about 1.5 minutes. As
    you can see from the readings, the response time is consistently above the 250
    ms alarm threshold, but (with the exception of one reading) still below the 750
    ms action threshold:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是大约1.5分钟的PBW性能读数。从读数中可以看出，响应时间始终高于250毫秒的警报阈值，但（除了一项读数外）仍然低于750毫秒的操作阈值：
- en: '[PRE17]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The readings will have to be consistently above the 750 ms action threshold
    for the PBW to trigger a healing action. One reading above 750 ms is not enough
    for an action to be triggered. However, since the readings are constantly above
    the 250 ms alarm threshold, the PBW is expected to trigger an alarm to the NMS/OSS
    system.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 为了触发PBW的自愈操作，读数必须持续高于750毫秒的操作阈值。一个超过750毫秒的读数不足以触发操作。然而，由于读数始终高于250毫秒的警报阈值，预计PBW将向NMS/OSS系统触发警报。
- en: 'We need to verify the PBW’s behavior from the NMS/OSS system or the PBW’s action
    log. The following is a snippet of the PBW’s action log during the same period
    from the previous example:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要验证PBW在NMS/OSS系统或PBW操作日志中的行为。以下是从上一个示例中同一时期PBW操作日志的片段：
- en: '[PRE18]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see from the preceding snippet’s last 4 log entries, after a consistent
    delay of more than 250 ms, an alarm was triggered and sent to the NMS/OSS system.
    We need to increase the inventory microservice’s load and response time to see
    how the PBW will react.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从前面的片段的最后四条日志记录中看到，在超过250毫秒的一致延迟后，触发了警报并发送到NMS/OSS系统。我们需要增加库存微服务的负载和响应时间，以查看PBW将如何反应。
- en: 'The following is another snippet of the PBW’s performance log. Only the last
    4 log entries in a series of 10 consistent response delay readings are above 750
    ms:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是PBW性能日志的另一段。在一系列10次一致的响应延迟读数中，只有最后四条记录的响应时间超过750毫秒：
- en: '[PRE19]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Normally, we would have configured all healing actions shown in *Table 10.1*.
    In our demo system, however, we have configured only one healing action to demo
    the system self-healing operations in general. We only configured a microservice
    container to restart if a problem is experienced in the microservice. The response
    delay simulator feature is therefore a more relevant simulation tool than the
    other tools we have mentioned earlier.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们会配置*表10.1*中显示的所有修复操作。然而，在我们的演示系统中，我们只配置了一个修复操作来演示系统自我修复操作的一般情况。我们只配置了微服务容器，如果微服务出现问题，则重启。因此，响应延迟模拟功能比我们之前提到的其他工具更相关的模拟工具。
- en: In case of slow performance due to high API call requests volume, the most appropriate
    healing action would be to try to scale the microservice first and allocate more
    resources to respond to the high volume of API requests.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果由于API调用请求量高而导致性能缓慢，最合适的修复操作是首先尝试扩展微服务，并分配更多资源来响应高量的API请求。
- en: We assume in our simulation that the problem in the Inventory microservice is
    not necessarily due to the API request load, but rather some unforeseen problem
    causing the Inventory service to become unstable and unable to handle API calls
    promptly, so restarting the Inventory microservice could therefore fix the problem.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的模拟中，我们假设库存微服务的问题不一定是由API请求负载引起的，而是由于一些不可预见的问题导致库存服务变得不稳定，无法及时处理API调用，因此重启库存微服务可以修复问题。
- en: 'Now, here is a look at the PBW’s action log during the same period. Please
    note that prior to the actionably high response time, an alarmingly high response
    time below 750 ms was previously detected. The response time was higher than 250
    ms and below 750 ms:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看PBW在同一时期内的操作日志。请注意，在响应时间达到可操作的高水平之前，已经检测到低于750毫秒的令人担忧的高响应时间。响应时间高于250毫秒且低于750毫秒：
- en: '[PRE20]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As you see from the last 4 entries in the action log, the PBW detected a consistent
    response time (above 750 ms) and accordingly sent a red alarm to the NMS/OSS system,
    indicating a critical delay in the Inventory service and the need for a self-healing
    action to be taken. The PBW then locked the Inventory microservice to avoid clashing
    with healing actions from other AI services. The PBW then restarted the Inventory
    microservice by sending a restart API call to Docker Engine, verified that the
    Inventory microservice was back online, and finally unlocked the Inventory microservice.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从操作日志的最后四条记录中看到，PBW检测到一致的响应时间（超过750毫秒），因此向NMS/OSS系统发送了红色警报，表明库存服务存在关键延迟，需要采取自我修复操作。然后PBW锁定库存微服务以避免与其他AI服务的修复操作冲突。然后PBW通过向Docker引擎发送重启API调用重启库存微服务，验证库存微服务已恢复在线，并最终解锁库存微服务。
- en: 'To restart a Docker container through API, you will need to send a `POST` request
    as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过API重启Docker容器，您需要发送如下`POST`请求：
- en: '[PRE21]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You can also specify the number of seconds to wait before restarting the container
    using a `t` parameter. The following is a container restart `POST` example to
    restart the Inventory service container after a 10-second wait time:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用`t`参数指定在重启容器之前等待的秒数。以下是一个容器重启`POST`示例，在等待10秒后重启库存服务容器：
- en: '[PRE22]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: For more information on how to control Docker Engine using API calls, check
    the Docker Engine API documentation at [https://docs.docker.com/engine/api/version-history/](https://docs.docker.com/engine/api/version-history/).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何使用API调用控制Docker引擎的更多信息，请查看Docker引擎API文档[https://docs.docker.com/engine/api/version-history/](https://docs.docker.com/engine/api/version-history/)。
- en: However, was the PBW able to fix the Inventory microservice problem?
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，PBW能否修复库存微服务问题？
- en: 'Let’s go back now to the PBW’s performance log and see how this self-healing
    action impacted the Inventory service performance. The following are the log entries
    just before the healing action was triggered:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回到PBW的性能日志，看看这个自我修复操作如何影响了库存服务的性能。以下是在修复操作触发之前的日志条目：
- en: '[PRE23]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Sure enough, the response time dropped from above 1 s to a maximum of 170 ms.
    Not as low as it was before the problem appeared, but the Inventory microservice
    for sure has some breathing room now. The performance issues may very well return
    if the underlying problem is not attended to and properly fixed.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，响应时间从超过1秒降低到了最大170毫秒。虽然没有问题出现之前那么低，但库存微服务现在确实有了一些喘息的空间。如果不对根本问题进行关注并妥善修复，性能问题可能会再次出现。
- en: In a more advanced AI model, we can train and configure the system to take more
    sophisticated actions to fully resolve the problem whenever needed, but in this
    book, we are limited to a specific scope to be able to demonstrate the idea in
    principle and pave the way for you to develop your own AI models and algorithms
    for your specific use cases.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个更高级的AI模型中，我们可以训练和配置系统，使其能够采取更复杂的操作，在需要时完全解决问题，但在这本书中，我们限于特定的范围，以便在原则上展示这个想法，并为您开发针对特定用例的AI模型和算法铺平道路。
- en: We have demonstrated in this section how the PBW works and how an action is
    triggered when a microservice performance issue is detected. In the following
    section, we will go over the PAD AI service and how the PAD takes a rather more
    holistic view of the entire system.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们已经展示了PBW的工作原理以及当检测到微服务性能问题时如何触发操作。在下一节中，我们将介绍PAD AI服务以及PAD如何对整个系统采取更为全面的视角。
- en: The PAD in action
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 行动的PAD
- en: The best way to demonstrate the operations of the PAD is to simulate a cascading
    failure and see how the PAD can bring the MSA system back to normal operation.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 要展示PAD的操作，最好的方式是模拟级联故障，看看PAD如何将MSA系统恢复到正常操作。
- en: To simulate a cascading failure and ensure that the PAD responds to the failure
    and tries to auto-heal, we will first need to disable the PBW AI service. This
    will prevent the PBW from triggering a healing action and prevent it from trying
    to resolve the problem before the PAD’s healing action(s) kick in.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟级联故障并确保PAD能够响应故障并尝试自动修复，我们首先需要禁用PBW AI服务。这将防止PBW触发修复操作，并防止它在PAD的修复操作启动之前尝试解决问题。
- en: Let’s quickly revisit what we have previously discussed in [*Chapter 3*](B18934_03.xhtml#_idTextAnchor039),
    an example of how a cascading failure happens.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速回顾一下之前在[*第3章*](B18934_03.xhtml#_idTextAnchor039)中讨论的内容，这是一个级联故障发生的例子。
- en: 'As shown in *Figure 10**.5*, under heavy API traffic, a failure to the Inventory
    microservice could cause the **Payment** microservice to pile up too many API
    calls in the queue, waiting for a response from the Inventory service. Eventually,
    these API calls will consume and exhaust the available resources in the **Payment**
    microservice, causing it to fail. A failure in the Payment microservice will produce
    a similar situation in the **Order** microservice, and eventually, produce a failure
    for the **Order** microservice as well:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 如[*图10.5*]所示，在重压下的API流量中，库存微服务的故障可能导致**支付**微服务在队列中积压过多的API调用，等待从库存服务得到响应。最终，这些API调用将消耗并耗尽**支付**微服务中可用的资源，导致其失败。支付微服务的故障将在**订单**微服务中产生类似的情况，并最终导致**订单**微服务也出现故障：
- en: '![Figure 10.5: The Payment microservice is down](img/B18934_10_5.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图10.5：支付微服务已关闭](img/B18934_10_5.jpg)'
- en: 'Figure 10.5: The Payment microservice is down'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5：支付微服务已关闭
- en: For the PAD to respond with healing actions, each of the PAD’s detected anomaly
    types has to have healing actions defined for it.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使PAD能够响应修复操作，必须为PAD检测到的每种异常类型定义相应的修复操作。
- en: To successfully simulate the cascading failure, we only defined an action for
    a cascading failure situation. Otherwise, the PAD would automatically detect the
    failure in the Inventory service and self-heal it by restarting the Inventory
    microservice container, preventing a cascading failure from happening to begin
    with.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 为了成功模拟级联故障，我们只为级联故障情况定义了一个操作。否则，PAD会自动检测库存服务中的故障，并通过重启库存微服务容器来自我修复，从而从一开始就防止级联故障的发生。
- en: We will start by simulating a high volume of orders for the Order microservice
    and see how the system is going to respond to this situation in general, and specifically
    how the PAD will react under the situation.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先模拟大量订单请求给订单微服务，看看系统将如何应对这种情况，特别是PAD在这种情况下的反应。
- en: 'To simulate a high volume of order requests, use the following `simulate_api_rqsts`
    command to target the Order microservice with a fixed uniformly paced order requests
    of 100,000 per minute:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 要模拟高量的订单请求，请使用以下`simulate_api_rqsts`命令针对订单微服务进行固定均匀速率的每分钟100,000个订单请求：
- en: '[PRE24]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We will now shut down the Inventory microservice and examine the PAD action
    logs. The following is a snippet of the log about a minute after the PAD started
    to detect a failure in the Inventory microservice.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将关闭库存微服务并检查PAD操作日志。以下是在PAD开始检测库存微服务故障大约一分钟后的日志片段。
- en: 'Please note that we introduced sudden high-volume traffic into the system.
    This sudden traffic increase by itself is a traffic pattern anomaly that was picked
    up by the PAD, but the PAD did not respond to that specific anomaly because no
    healing action is specifically defined for that anomaly:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们已经将突发高流量引入了系统。这种突然的流量增加本身是一种由PAD检测到的流量模式异常，但PAD没有对这种特定的异常做出响应，因为没有为该异常定义特定的恢复操作：
- en: '[PRE25]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In the preceding snippet of the PAD log, the PAD automatically recognized the
    Inventory service failure since no response traffic was detected from the service.
    However, no action was taken by the PAD since no healing action was defined for
    that particular anomaly. Since the anomaly was consistent for more than 1 minute,
    the PAD sent an alarm to the NMS/OSS system to notify the system admins of the
    problem.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的PAD日志片段中，由于没有检测到来自该服务的响应流量，PAD自动识别了库存服务故障。然而，由于没有为该特定异常定义恢复操作，PAD没有采取任何行动。由于异常持续了超过1分钟，PAD向NMS/OSS系统发送了警报，通知系统管理员问题。
- en: Because of the Inventory microservice failure, the Payment microservice started
    to run out of resources, and the PAD picked up an unusually slow traffic flow
    from the Payment microservice given the API call request load applied. Accordingly,
    and as seen in the log, a little over 1 minute later, the PAD started to generate
    alarms to NMS/OSS.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 由于库存微服务故障，支付微服务开始耗尽资源，并且鉴于API调用请求负载，PAD检测到了支付微服务异常的异常缓慢流量。相应地，正如日志所示，大约1分钟后，PAD开始向NMS/OSS生成警报。
- en: 'As shown in the following PAD log, a few minutes after the Payment microservice
    anomaly, the Order microservice started acting up, and accordingly, the PAD was
    able to correlate all these anomalies and detect a potential cascading failure:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下PAD日志所示，在支付微服务异常几分钟之后，订单微服务开始出现问题，相应地，PAD能够关联所有这些异常并检测到潜在的级联故障：
- en: '[PRE26]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Please note that the only microservice failure we have so far is the one we
    manually shut down, the Inventory microservice. Both the Payment and Order microservices
    are still up and running but, as it seems from the log, may be suffering from
    resource exhaustion.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们迄今为止唯一的微服务故障是我们手动关闭的库存微服务。支付和订单微服务目前仍在运行，但从日志来看，可能正遭受资源耗尽的问题。
- en: The system is still running so far, and should the Inventory service return
    back online, the system will automatically recover. The user experience during
    the heavy load would only be slow performance during the ordering process, but
    no orders have been denied or failed yet.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，系统仍在运行，如果库存服务恢复在线，系统将自动恢复。在重负载期间的用户体验将是订单过程中的性能缓慢，但尚未有订单被拒绝或失败。
- en: By examining all these previously mentioned PAD action logs, and as the situation
    stands so far, we are still okay. However, if no action is taken to resolve the
    Inventory microservice problem, the system will eventually fail and user orders
    will start to be denied.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查所有之前提到的PAD操作日志，并且根据目前的情况，我们仍然处于正常状态。然而，如果不对库存微服务问题采取行动解决，系统最终会失败，用户订单将开始被拒绝。
- en: The short circuit traffic pattern discussed in [*Chapter 3*](B18934_03.xhtml#_idTextAnchor039)
    helps prevent a cascading failure from taking place, but it still cannot resolve
    the underlying problem. User orders in a traditional short circuit pattern implantation
    will still be rejected until manual intervention fixes the Inventory microservice.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第3章*](B18934_03.xhtml#_idTextAnchor039)中讨论的短路流量模式有助于防止级联故障的发生，但它仍然不能解决根本问题。在传统的短路模式实施中，用户订单仍然会被拒绝，直到手动干预修复库存微服务。
- en: That’s where the PAD comes in. Check the following PAD action log!
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是PAD的作用所在。查看以下PAD操作日志！
- en: '[PRE27]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The PAD was able to detect the cascading failure before it actually happened,
    and was able to identify the root cause of the problem. The PAD sent a red alarm
    to the NMS/OSS system, declared a self-healing lock state on the Inventory service
    to try to fix the problem’s root cause, was able to successfully restart the Inventory
    microservice container, and then cleared the self-healing lock on the Inventory
    service.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: PAD能够在实际发生之前检测到级联故障，并能够确定问题的根本原因。PAD向NMS/OSS系统发送了红色警报，在库存服务上声明了自愈锁定状态以尝试修复问题的根本原因，能够成功重启库存微服务容器，然后清除了库存服务上的自愈锁定。
- en: Let’s now check the microservices performance logs and ensure that the problem
    is fixed and that the ABC-Intelligent-MSA system and all of its microservices
    are running normally.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在检查微服务的性能日志，确保问题已解决，ABC-Intelligent-MSA系统和所有其微服务都在正常运行。
- en: 'Here’s the Inventory microservice’s performance log:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这是库存微服务的性能日志：
- en: '[PRE28]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Here’s the Payment microservice’s performance log:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这是支付微服务的性能日志：
- en: '[PRE29]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Here’s the Order microservice’s performance log:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这是订单微服务的性能日志：
- en: '[PRE30]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: As shown for the preceding Inventory, Payment, and Order microservices, all
    of those microservices are back online with normal performance readings. The system
    is now back to normal operation and should be able to handle the production load
    with no issues.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述的库存、支付和订单微服务，所有这些微服务都已恢复正常，性能读数正常。系统现在恢复正常运行，应该能够无问题地处理生产负载。
- en: Summary
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter walked us through how we can build AI models to build an intelligent
    MSA system step by step. We accordingly built two main AI services – the PBW and
    the PAD – and leveraged these AI services to enhance our MSA demo system, ABC-MSA,
    to build an intelligent MSA system that we named ABC-Intelligent-MSA.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 本章逐步向我们介绍了如何构建AI模型以构建智能MSA系统。因此，我们相应地构建了两个主要AI服务——PBW和PAD，并利用这些AI服务来增强我们的MSA演示系统ABC-MSA，构建了一个名为ABC-Intelligent-MSA的智能MSA系统。
- en: We explained the self-healing process design and dynamics in detail, as well
    as the tools we built to develop AI training data, how to simulate production
    operations, and how to measure the demo system’s performance. We then put the
    ABC-Intelligent-MSA to test, simulated a couple of use cases to demonstrate AI
    functions within the MSA system, and carefully examined the logs of our demo AI
    services to showcase the value of using AI in MSA.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们详细解释了自愈过程的设计和动态，以及我们构建的用于开发AI训练数据的工具，如何模拟生产操作，以及如何衡量演示系统的性能。然后我们对ABC-Intelligent-MSA进行了测试，模拟了几个用例以展示MSA系统中的AI功能，并仔细检查了我们的演示AI服务的日志，以展示在MSA中使用AI的价值。
- en: Everything explained in this chapter is just an example of using AI in an MSA
    system. Enterprises should consider using AI services that are specifically appropriate
    for their own MSA system and use cases. These AI tools may very well be available
    through third parties or built in-house whenever needed.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中解释的一切只是使用AI在MSA系统中的示例。企业应考虑使用适合其自身MSA系统和用例的特定AI服务。这些AI工具可能完全可以通过第三方提供或根据需要内部构建。
- en: In the next chapter, we will discuss the transformation process from a traditional
    MSA system to an intelligent MSA system – the things to consider in greenfield
    and brownfield implementations, and how to avoid integration challenges to make
    the corporate transformation as smooth as possible.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论从传统MSA系统到智能MSA系统的转型过程——在绿色和棕色场实施中需要考虑的事项，以及如何避免集成挑战，使企业转型尽可能顺利。
