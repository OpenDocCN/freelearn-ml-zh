- en: Tracking Visually Salient Objects
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪视觉显著性物体
- en: The goal of this chapter is to track multiple visually salient objects in a
    video sequence at once. Instead of labeling the objects of interest in the video
    ourselves, we will let the algorithm decide which regions of a video frame are
    worth tracking.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是在视频序列中同时跟踪多个视觉显著性物体。我们不会自己标记视频中的感兴趣物体，而是让算法决定视频帧中哪些区域值得跟踪。
- en: We have previously learned how to detect simple objects of interest (such as
    a human hand) in tightly controlled scenarios and how to infer geometrical features
    of a visual scene from camera motion. In this chapter, we ask what we can learn
    about a visual scene by looking at the *image statistics* of a large number of
    frames.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已经学习了如何在严格控制的情况下检测简单的感兴趣物体（如人手）以及如何从相机运动中推断视觉场景的几何特征。在本章中，我们将探讨通过观察大量帧的**图像统计信息**我们可以了解视觉场景的哪些内容。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Planning the app
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规划应用
- en: Setting up the app
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置应用
- en: Mapping visual saliency
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 映射视觉显著性
- en: Understanding mean-shift tracking
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解均值漂移跟踪
- en: Learning about the OpenCV Tracking API
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解OpenCV跟踪API
- en: Putting it all together
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整合所有内容
- en: By analyzing the **Fourier spectrum** of natural images, we will build a **saliency
    map**, which allows us to label certain statistically interesting patches of the
    image as (potential or actual) *proto-objects*. We will then feed the location
    of all the proto-objects to a **mean-shift tracker**, which will allow us to keep
    track of where the objects move from one frame to the next.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析自然图像的**傅里叶频谱**，我们将构建一个**显著性图**，它允许我们将图像中某些统计上有趣的区域标记为（潜在的或实际的）**原型物体**。然后我们将所有原型物体的位置输入到一个**均值漂移跟踪器**中，这将使我们能够跟踪物体从一个帧移动到下一个帧的位置。
- en: Getting started
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用
- en: This chapter uses **OpenCV 4.1.0**, as well as the additional packages **NumPy**
    ([http://www.numpy.org](http://www.numpy.org)), **wxPython 2.8** ([http://www.wxpython.org/download.php](http://www.wxpython.org/download.php)),
    and **matplotlib** ([http://www.matplotlib.org/downloads.html](http://www.matplotlib.org/downloads.html)).
    Although parts of the algorithms presented in this chapter have been added to
    an optional Saliency module of the **OpenCV 3.0.0** release, there is currently
    no Python API for it, so we will write our own code.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章使用**OpenCV 4.1.0**，以及额外的包**NumPy**([http://www.numpy.org](http://www.numpy.org))、**wxPython
    2.8**([http://www.wxpython.org/download.php](http://www.wxpython.org/download.php))和**matplotlib**([http://www.matplotlib.org/downloads.html](http://www.matplotlib.org/downloads.html))。尽管本章中提出的部分算法已被添加到**OpenCV
    3.0.0**版本的可选显著性模块中，但目前还没有Python API，因此我们将编写自己的代码。
- en: The code for this chapter can be found in the book's GitHub repository, available
    at [https://github.com/PacktPublishing/OpenCV-4-with-Python-Blueprints-Second-Edition/tree/master/chapter6](https://github.com/PacktPublishing/OpenCV-4-with-Python-Blueprints-Second-Edition/tree/master/chapter6).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在书的GitHub仓库中找到，仓库地址为[https://github.com/PacktPublishing/OpenCV-4-with-Python-Blueprints-Second-Edition/tree/master/chapter6](https://github.com/PacktPublishing/OpenCV-4-with-Python-Blueprints-Second-Edition/tree/master/chapter6)。
- en: Understanding visual saliency
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解视觉显著性
- en: '**Visual saliency** is a technical term from *cognitive psychology* that tries
    to describe the visual quality of certain objects or items that allows them to
    grab our immediate attention. Our brains constantly drive our gaze toward the *important* regions
    of the visual scene and keep track of them over time, allowing us to quickly scan
    our surroundings for interesting objects and events while neglecting the less
    important parts.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**视觉显著性**是来自**认知心理学**的一个术语，试图描述某些物体或项目的视觉质量，使其能够立即吸引我们的注意力。我们的大脑不断引导我们的目光向视觉场景中的**重要**区域，并在一段时间内跟踪它们，使我们能够快速扫描周围环境中的有趣物体和事件，同时忽略不那么重要的部分。'
- en: 'An example of a regular RGB image and its conversion to a **saliency map**,
    where the statistically interesting *pop-out* regions appear bright and the others
    dark, is shown in the following screenshot:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个常规RGB图像及其转换为**显著性图**的示例，其中统计上有趣的**突出**区域显得明亮，而其他区域则显得暗淡：
- en: '![](img/0f8d0894-fb45-4c57-8cb4-57c13bbc2256.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0f8d0894-fb45-4c57-8cb4-57c13bbc2256.png)'
- en: '**Fourier analysis** will enable us to get a general understanding of natural
    image statistics, which will help us build a model of what general image backgrounds
    look like. By comparing and contrasting the background model to a specific image
    frame, we can locate subregions of the image that *pop out* of their surroundings
    (as shown in the previous screenshot). Ideally, these subregions correspond to
    the image patches that tend to grab our immediate attention when looking at the
    image.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**傅里叶分析**将使我们能够对自然图像统计有一个一般性的了解，这将帮助我们构建一个关于一般图像背景外观的模型。通过将背景模型与特定图像帧进行比较和对比，我们可以定位图像中突出其周围环境的子区域（如图中所示的前一个屏幕截图）。理想情况下，这些子区域对应于当我们观察图像时，往往会立即吸引我们注意力的图像块。'
- en: Traditional models might try to associate particular features with each target
    (much like our feature-matching approach in [Chapter 3](905b17f6-8eea-4d33-9291-17ea93371f2d.xhtml), *Finding
    Objects via Feature Matching and Perspective Transforms*), which would convert
    the problem to the detection of specific categories of objects. However, these
    models require manual labeling and training. But what if the features or the number
    of the objects to track is not known?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 传统模型可能会尝试将特定的特征与每个目标关联起来（类似于我们在第3章中介绍的特征匹配方法，*通过特征匹配和透视变换查找对象*），这将把问题转化为检测特定类别对象的问题。然而，这些模型需要手动标记和训练。但如果要跟踪的特征或对象的数量是未知的呢？
- en: 'Instead, we will try to mimic what the brain does, that is, tune our algorithm
    to the statistics of the natural images, so that we can immediately locate the
    patterns or subregions that "*grab our attention*" in the visual scene (that is,
    patterns that deviate from these statistical regularities) and flag them for further
    inspection. The result is an algorithm that works for any number of proto-objects
    in the scene, such as tracking all the players on a soccer field. Refer to the
    following set of screenshots to see it in action:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们将尝试模仿大脑的工作方式，即调整我们的算法以适应自然图像的统计特性，这样我们就可以立即定位视觉场景中“吸引我们的注意力”的图案或子区域（即偏离这些统计规律的模式）并将它们标记出来进行进一步检查。结果是这样一个算法，它可以适用于场景中任何数量的原型对象，例如跟踪足球场上的所有球员。请参考以下一系列屏幕截图以查看其效果：
- en: '![](img/d7c88c8b-71f0-46b1-b61c-ee21b3c2e9d5.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d7c88c8b-71f0-46b1-b61c-ee21b3c2e9d5.png)'
- en: As we can see in these four screenshots, once all the potentially *interesting* patches
    of an image have been located, we can track their movement over many frames using
    a simple yet effective method called **object** **mean-shift tracking**. Because
    it is possible to have multiple proto-objects in the scene that might change appearance
    over time, we need to be able to distinguish between them and keep track of all
    of them.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在这四个屏幕截图中所看到的，一旦定位到图像中所有潜在的“有趣”的块，我们可以使用一种简单而有效的方法——**对象** **均值漂移跟踪**——来跟踪它们在多个帧中的运动。由于场景中可能存在多个可能随时间改变外观的原型对象，我们需要能够区分它们并跟踪所有这些对象。
- en: Planning the app
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规划应用程序
- en: 'To build the app, we need to combine the two main features discussed previously—a
    saliency map andobject tracking**. **The final app will convert each RGB frame
    of a video sequence into a saliency map, extract all the interesting proto-objects,
    and feed them to a mean-shift tracking algorithm. To do this, we need the following
    components:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建应用程序，我们需要结合之前讨论的两个主要功能——显著性图和对象跟踪**。**最终的应用程序将把视频序列的每个RGB帧转换为显著性图，提取所有有趣的原始对象，并将它们输入到均值漂移跟踪算法中。为此，我们需要以下组件：
- en: '`main`: This is the main function routine (in `chapter6.py`) to start the application.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`main`: 这是主函数例程（在`chapter6.py`中），用于启动应用程序。'
- en: '`saliency.py`: This is a module to generate a saliency map and proto-object
    map from an RGB color image. It includes the following functions:'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`saliency.py`: 这是一个模块，用于从RGB彩色图像生成显著性图和原型对象图。它包括以下功能：'
- en: '`get_saliency_map`: This is a function to convert an RGB color image to a saliency
    map.'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`get_saliency_map`: 这是一个函数，用于将RGB彩色图像转换为显著性图。'
- en: '`get_proto_objects_map`: This is a function to convert a saliency map into
    a binary mask containing all the proto-objects.'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`get_proto_objects_map`: 这是一个函数，用于将显著性图转换为包含所有原型对象的二值掩码。'
- en: '`plot_power_density`: This is a function to display the two-dimensional power
    density of an RGB color image, which is helpful to understand the Fourier transform.'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plot_power_density`: 这是一个函数，用于显示RGB彩色图像的二维功率密度，这有助于理解傅里叶变换。'
- en: '`plot_power_spectrum`: This is a function to display the radially averaged
    power spectrum of an RGB color image, which is helpful to understand natural image
    statistics.'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plot_power_spectrum`：这是一个用于显示RGB颜色图像的径向平均功率谱的函数，有助于理解自然图像统计信息。'
- en: '`MultiObjectTracker`: This is a class that tracks multiple objects in a video
    using mean-shift tracking. It includes the following public methods:'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultiObjectTracker`：这是一个使用均值漂移跟踪在视频中跟踪多个对象的类。它包括以下公共方法：'
- en: '`MultiObjectTracker.advance_frame`: This is a method to update the tracking
    information for a new frame, using the mean-shift algorithm on the saliency map
    of the current frame to update the positions of boxes from the previous frame
    to the current frame.'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultiObjectTracker.advance_frame`：这是一个用于更新新帧跟踪信息的方法，它使用当前帧的显著性图上的均值漂移算法来更新从前一帧到当前帧的框的位置。'
- en: '`MultiObjectTracker.draw_good_boxes`: This is a method to illustrate tracking
    results in the current frame.'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MultiObjectTracker.draw_good_boxes`：这是一个用于展示当前帧跟踪结果的方法。'
- en: In the following sections, we will discuss these steps in detail.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，我们将详细讨论这些步骤。
- en: Setting up the app
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置应用程序
- en: In order to run our app, we will need to execute the `main` function ,which
    reads a frame of a video stream, generates a saliency map, extracts the location
    of the proto-objects, and tracks these locations from one frame to the next.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行我们的应用程序，我们需要执行`main`函数，该函数读取视频流的一帧，生成显著性图，提取原对象的定位，并从一帧跟踪到下一帧。
- en: Let's learn about the `main` function routine in the next section.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在下一节学习`main`函数的常规操作。
- en: Implementing the main function
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现主函数
- en: 'The main process flow is handled by the `main` function in `chapter6.py`, which
    instantiates the tracker  (`MultipleObjectTracker`) and opens a video file showing
    the number of soccer players on the field:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 主要流程由`chapter6.py`中的`main`函数处理，该函数实例化跟踪器（`MultipleObjectTracker`）并打开显示场地上足球运动员数量的视频文件：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The function will then read the video frame by frame and extract some meaningful
    region of interest (for illustration purposes):'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 函数将逐帧读取视频并提取一些有意义的感兴趣区域（用于说明目的）：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After that, the region of interest will be passed to a function that will generate
    a saliency map of the region. Then, *interesting* proto-objects will be generated
    based on the saliency map, which finally will be fed into the tracker together
    with the region of interest. The output of the tracker is the input region annotated
    with bounding boxes as shown in the preceding set of screenshots:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，感兴趣区域将被传递到一个函数，该函数将生成该区域的显著性图。然后，基于显著性图生成*有趣的*原对象，最后将它们与感兴趣区域一起输入到跟踪器中。跟踪器的输出是带有边界框的标注输入区域，如前一组截图所示：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The app will run through all the frames of the video until the end of the file
    is reached or the user presses the `q` key:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序将运行到视频文件结束或用户按下`q`键为止：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the next section, we'll learn about the `MultiObjectTracker` class.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将了解`MultiObjectTracker`类。
- en: Understanding the MultiObjectTracker class
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解`MultiObjectTracker`类
- en: 'The constructor of the tracker class is straightforward. All it does is set
    up the termination criteria for mean-shift tracking and store the conditions for
    the minimum contour area (`min_area`) and the minimum average speed normalized
    by object size (`min_speed_per_pix`) to be considered in the subsequent computation
    steps:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪器类的构造函数很简单。它所做的只是设置均值漂移跟踪的终止条件，并存储后续计算步骤中要考虑的最小轮廓面积（`min_area`）和按对象大小归一化的最小平均速度（`min_speed_per_pix`）的条件：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: From then on, the user may call the `advance_frame` method to feed a new frame
    to the tracker.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从那时起，用户可以调用`advance_frame`方法向跟踪器提供新的帧。
- en: However, before we make use of all this functionality, we need to learn about
    image statistics and how to generate a saliency map.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们充分利用所有这些功能之前，我们需要了解图像统计信息以及如何生成显著性图。
- en: Mapping visual saliency
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 映射视觉显著性
- en: As already mentioned earlier in the chapter, visual saliency tries to describe
    the visual quality of certain objects or items that allows them to grab our immediate
    attention. Our brains constantly drive our gaze toward the important regions of
    the visual scene, as if it were shining a flashlight on different subregions of
    the visual world, allowing us to quickly scan our surroundings for interesting
    objects and events while neglecting the less important parts.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章前面所述，视觉显著性试图描述某些物体或项目的视觉质量，使它们能够吸引我们的即时注意力。我们的大脑不断引导我们的目光向视觉场景中的**重要**区域，就像在视觉世界的不同子区域上打闪光灯一样，使我们能够快速扫描周围环境中的有趣物体和事件，同时忽略不那么重要的部分。
- en: 'It is thought that this is an evolutionary strategy to deal with the constant **information
    overflow** that comes with living in a visually rich environment. For example,
    if you take a casual walk through a jungle, you want to be able to notice the
    attacking tiger in the bush to your left before admiring the intricate color pattern
    on the butterfly''s wings in front of you. As a result, the visually salient objects
    have the remarkable quality of *popping out* of their surroundings, much like
    the target bars in the following screenshot:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 人们认为，这是一种进化策略，用来应对在视觉丰富的环境中生活所带来的持续**信息过载**。例如，如果你在丛林中随意散步，你希望在欣赏你面前蝴蝶翅膀上复杂的颜色图案之前，就能注意到你左边灌木丛中的攻击性老虎。因此，视觉显著的物体具有从其周围**跳出**的显著特性，就像以下截图中的目标条形：
- en: '![](img/485b2aad-27a3-42e6-8d95-420cef08611a.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/485b2aad-27a3-42e6-8d95-420cef08611a.png)'
- en: Identifying the visual quality that makes these targets pop out may not always
    be trivial though. If you are viewing the image on the left in color, you may
    immediately notice the only red bar in the image. However, if you are looking
    at this image in grayscale, the target bar may be a little difficult to find (it
    is the fourth bar from the top, fifth bar from the left).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 识别使这些目标跳出的视觉质量可能并不总是微不足道的。如果你在彩色图像中查看左侧图像，你可能会立即注意到图像中唯一的红色条形。然而，如果你以灰度查看这张图像，目标条形可能有点难以找到（它是从上往下数的第四条，从左往右数的第五条）。
- en: 'Similar to color saliency, there is a visually salient bar in the image on
    the right. Although the target bar is of unique color in the left-hand image and
    of unique orientation in the right-hand image, we put the two characteristics
    together and suddenly the unique target bar does not pop out anymore:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 与颜色显著性类似，在右侧的图像中有一个视觉显著的条形。尽管左侧图像中的目标条形具有独特的颜色，而右侧图像中的目标条形具有独特的方向，但我们把这两个特征结合起来，突然独特的目标条形就不再那么突出：
- en: '![](img/809dd314-8c2a-4d16-a671-a35b1e6dce54.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/809dd314-8c2a-4d16-a671-a35b1e6dce54.png)'
- en: 'In the preceding display, there is again one bar that is unique and different
    from all the other ones. However, because of the way the distracting items were
    designed, there is little salience to guide you toward the target bar. Instead,
    you find yourself scanning the image, seemingly at random, looking for something
    interesting. (*Hint*: the target is the only red and almost vertical bar in the
    image, second row from the top, third column from the left.)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的显示中，又有一条独特的条形，与其他所有条形都不同。然而，由于干扰物品的设计方式，几乎没有显著性来引导你找到目标条形。相反，你发现自己似乎在随机扫描图像，寻找有趣的东西。（*提示*：目标是图像中唯一的红色且几乎垂直的条形，从上往下数的第二行，从左往右数的第三列。）
- en: '*What does this have to do with computer vision, you ask?* Quite a lot, actually.
    Artificial vision systems suffer from information overload much like you and me,
    except that they know even less about the world than we do. *What if we could
    extract some insights from biology and use them to teach our algorithms something
    about the world?*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*你可能会问，这与计算机视觉有什么关系？实际上，关系很大。人工视觉系统像我们一样，会遭受信息过载的问题，只不过它们对世界的了解甚至比我们还少。* 如果我们能从生物学中提取一些见解，并用它们来教我们的算法关于世界的一些知识呢？'
- en: Imagine a dashboard camera in your car that automatically focuses on the most
    relevant traffic sign. Imagine a surveillance camera that is part of a wildlife
    observation station that will automatically detect and track the sighting of the
    *notoriously shy platypus* but will ignore everything else. *How can we teach
    the algorithm what is important and what is not? How can we make that platypus
    "pop out"?*
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你车上的仪表盘摄像头，它会自动聚焦于最相关的交通标志。想象一下作为野生动物观察站一部分的监控摄像头，它会自动检测和跟踪**著名害羞的鸭嘴兽**的出现，但会忽略其他一切。*我们如何教会算法什么是重要的，什么不是？我们如何让那只鸭嘴兽“跳出”来？*
- en: Thus, we enter the Fourier analysis domain.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们进入了**傅里叶分析域**。
- en: Learning about Fourier analysis
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习傅里叶分析
- en: To find the visually salient subregions of an image, we need to look at its **frequency
    spectrum**. So far we have treated all our images and video frames in the **spatial
    domain**, that is, by analyzing the pixels or studying how the image intensity
    changes in different subregions of the image. However, the images can also be
    represented in the **frequency domain**, that is, by analyzing the pixel frequencies
    or studying how often and with what periodicity the pixels show up in the image.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到图像的视觉显著子区域，我们需要查看其**频谱**。到目前为止，我们一直在**空间域**处理我们的图像和视频帧，即通过分析像素或研究图像强度在不同图像子区域中的变化。然而，图像也可以在**频域**中表示，即通过分析像素频率或研究像素在图像中出现的频率和周期性。
- en: An image can be transformed from the space domain into the frequency domain
    by applying the **Fourier transform**. In the frequency domain, we no longer think
    in terms of image coordinates (*x*,*y*). Instead, we aim to find the spectrum
    of an image. Fourier's radical idea basically boils down to the following question—*what
    if any signal or image could be transformed into a series of circular paths (also
    called **harm****onics**)?*
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用**傅里叶变换**，可以将图像从空间域转换到频域。在频域中，我们不再以图像坐标（*x*，*y*）为思考单位。相反，我们的目标是找到图像的频谱。傅里叶的激进想法基本上可以归结为以下问题——*如果任何信号或图像可以被转换成一系列圆形路径（也称为**谐波**），会怎样？*
- en: For example, think of a rainbow. *Beautiful, isn't it?* In a rainbow, white
    sunlight (composed of many different colors or parts of the spectrum) is spread
    into its spectrum. Here, the color spectrum of the sunlight is exposed when the
    rays of light pass through raindrops (much like white light passing through a
    glass prism). The Fourier transform aims to do the same thing—to recover all the
    different parts of the spectrum that are contained in the sunlight.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想想彩虹。*美丽，不是吗？*在彩虹中，由许多不同颜色或光谱部分组成的白光被分散到其频谱中。在这里，当光线穿过雨滴（类似于白光穿过玻璃棱镜）时，太阳光的颜色频谱被暴露出来。傅里叶变换的目标就是要做到同样的事情——恢复阳光中包含的所有不同频谱部分。
- en: A similar thing can be achieved for arbitrary images. In contrast to rainbows,
    where frequency corresponds to electromagnetic frequency, with images we consider
    spatial frequency, that is, the spatial periodicity of the pixel values. In an
    image of a prison cell, you can think of spatial frequency as (the inverse of)
    the distance between two adjacent prison bars.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任意图像，也可以实现类似的效果。与彩虹不同，彩虹中的频率对应于电磁频率，而在图像中，我们考虑的是空间频率，即像素值的空间周期性。在一个监狱牢房的图像中，你可以将空间频率视为（两个相邻监狱栏杆之间的）距离的倒数。
- en: 'The insights that can be gained from this change of perspective are very powerful.
    Without going into too much detail, let''s just remark that a Fourier spectrum
    comes with both a magnitude and a phase. While the magnitude describes the number/amount
    of different frequencies in the image, the phase talks about the spatial location
    of these frequencies. The following screenshot shows a natural image on the left
    and the corresponding Fourier magnitude spectrum (of the grayscale version) on
    the right:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 从这种视角转变中获得的见解非常强大。不深入细节，我们只需指出，傅里叶频谱既包含幅度也包含相位。幅度描述了图像中不同频率的数量/数量，而相位则讨论这些频率的空间位置。下面的截图显示了左边的自然图像和右边的相应的傅里叶幅度频谱（灰度版本的频谱）：
- en: '![](img/279133b7-af17-4229-b8f7-84b8a1881114.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/279133b7-af17-4229-b8f7-84b8a1881114.png)'
- en: The magnitude spectrum on the right tells us which frequency components are
    the most prominent (bright) in the grayscale version of the image on the left.
    The spectrum is adjusted so that the center of the image corresponds to zero frequency
    in *x* and *y*. The further you move to the border of the image, the higher the
    frequency gets. This particular spectrum is telling us that there are a lot of
    low-frequency components in the image on the left (clustered around the center
    of the image).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 右侧的幅度频谱告诉我们，在左侧图像的灰度版本中，哪些频率成分是最突出的（明亮）的。频谱被调整，使得图像的中心对应于*x*和*y*方向上的零频率。你越靠近图像的边缘，频率就越高。这个特定的频谱告诉我们，左侧的图像中有许多低频成分（集中在图像的中心附近）。
- en: 'In OpenCV, this transformation can be achieved with the help of the **Discrete
    Fourier Transform** (**DFT**). Let''s construct a function that does the job.
    It consists of the following steps:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中，这个转换可以通过**离散傅里叶变换**（**DFT**）来实现。让我们构建一个执行这个任务的函数。它包括以下步骤：
- en: 'First, convert the image to grayscale if necessary. The function accepts both
    grayscale and RGB color images, so we need to make sure that we operate on a single-channel
    image:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，如果需要，将图像转换为灰度图。该函数接受灰度和RGB彩色图像，因此我们需要确保我们在单通道图像上操作：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**​**We resize the image to an optimal size. It turns out that the performance
    of a DFT depends on the image size. It tends to be fastest for the image sizes
    that are multiples of the number 2\. It is therefore generally a good idea to
    pad the image with 0:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '****我们调整图像到最佳尺寸。结果发现，DFT的性能取决于图像大小。对于是2的倍数的图像大小，它通常运行得最快。因此，通常一个好的做法是在图像周围填充0：'
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then we apply the DFT. This is a single function call in NumPy. The result
    is a two-dimensional matrix of complex numbers:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们应用DFT。这是一个NumPy中的单个函数调用。结果是复数的二维矩阵：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, transform the real and complex values to magnitude. A complex number
    has a real and complex (imaginary) part. To extract the magnitude, we take the
    absolute value:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，将实部和虚部值转换为幅度。一个复数有一个实部和虚部（虚数）部分。为了提取幅度，我们取绝对值：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Then we switch to a logarithmic scale. It turns out that the dynamic range of
    the Fourier coefficients is usually too large to be displayed on the screen. We
    have some low and some high changing values that we can't observe like this. Therefore,
    the high values will all turn out as white points, and the low ones as black points.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们切换到对数尺度。结果发现，傅里叶系数的动态范围通常太大，无法在屏幕上显示。我们有一些低值和高值的变化，我们无法这样观察。因此，高值将全部显示为白色点，低值则显示为黑色点。
- en: 'To use the grayscale values for visualization, we can transform our linear
    scale to a logarithmic one:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用灰度值进行可视化，我们可以将我们的线性尺度转换为对数尺度：
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We then shift quadrants, to center the spectrum on the image. This makes it
    easier to visually inspect the magnitude `spectrum`:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们进行象限平移，以便将频谱中心对准图像。这使得视觉检查幅度`频谱`更容易：
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We `return` the result for plotting:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们`返回`结果以进行绘图：
- en: '[PRE11]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The result can be plotted with `pyplot`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可以用`pyplot`绘制。
- en: Now that we understand what the Fourier spectrum of an image is and how to calculate
    it, let's analyze natural scene statistics in the next section.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了图像的傅里叶频谱以及如何计算它，让我们在下一节分析自然场景的统计信息。
- en: Understanding the natural scene statistics
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解自然场景的统计信息
- en: The human brain figured out how to focus on visually salient objects a long
    time ago. The natural world in which we live has some statistical regularities
    that make it uniquely *natural*, as opposed to a chessboard pattern or a random
    company logo. Probably, the most commonly known statistical regularity is the
    *1/f* law. It states that the amplitude of the ensemble of natural images obeys
    a *1/f* distribution (as shown in the following screenshot). This is sometimes
    also referred to as **scale invariance**.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 人类的大脑很久以前就找到了如何专注于视觉上显著对象的方法。我们生活的自然世界有一些统计规律性，这使得它独特地**自然**，而不是棋盘图案或随机的公司标志。最常见的一种统计规律性可能是**1/f**定律。它表明自然图像集合的幅度遵循**1/f**分布（如下面的截图所示）。这有时也被称为**尺度不变性**。
- en: 'A one-dimensional power spectrum (as a function of frequency) of a two-dimensional image
    can be visualized with the following `plot_power_spectrum` function. We can use
    a similar recipe as for the magnitude spectrum used previously, but we will have
    to make sure that we correctly collapse the two-dimensional spectrum onto a single
    axis:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一个二维图像的一维功率谱（作为频率的函数）可以用以下`plot_power_spectrum`函数进行可视化。我们可以使用与之前使用的幅度谱相似的配方，但我们必须确保我们正确地将二维频谱折叠到单个轴上：
- en: 'Define the function and convert the image to grayscale if necessary (this is
    the same as earlier):'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义函数并在必要时将图像转换为灰度图（这与之前相同）：
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Expand the image to its optimal size (this is the same as earlier):'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像扩展到其最佳尺寸（这与之前相同）：
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We then apply the DFT and get the log spectrum. Here we give the user an option
    (via the `use_numpy_fft` flag) to use either NumPy''s or OpenCV''s Fourier tools:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们应用DFT并得到对数频谱。这里我们给用户一个选项（通过`use_numpy_fft`标志）来选择使用NumPy的或OpenCV的傅里叶工具：
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We then perform radial averaging. This is the tricky part. It would be wrong
    to simply average the two-dimensional spectrum in the direction of *x* or *y*.
    What we are interested in is a spectrum as a function of frequency, independent
    of the exact orientation. This is sometimes also called the **Radially Averaged
    Power Spectrum** (**RAPS**).
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接下来进行径向平均。这是比较棘手的部分。简单地沿 *x* 或 *y* 方向平均二维频谱是错误的。我们感兴趣的是作为频率函数的频谱，与精确的取向无关。这有时也被称为**径向平均功率谱**（**RAPS**）。
- en: 'It can be achieved by summing up all the frequency magnitudes, starting at
    the center of the image, looking into all possible (radial) directions, from some
    frequency `r` to `r+dr`. We use the binning function of NumPy''s histogram to
    sum up the numbers, and accumulate them in the `histo` variable:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过从图像中心开始，向所有可能的（径向）方向求和所有频率的幅度来实现，从某个频率 `r` 到 `r+dr`。我们使用 NumPy 的直方图函数的
    binning 功能来求和数字，并将它们累积在 `histo` 变量中：
- en: '[PRE15]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We then plot the result and, finally, we can plot the accumulated numbers in
    `histo`, but must not forget to normalize these by the bin size (`dcount`):'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接下来绘制结果，最后，我们可以绘制 `histo` 中的累积数字，但不要忘记用 bin 大小（`dcount`）进行归一化：
- en: '[PRE16]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The result is a function that is inversely proportional to the frequency. If
    you want to be absolutely certain of the *1/f* property, you could take `np.log10` of
    all the *x* values and make sure the curve is decreasing in a roughly linear fashion.
    On a linear *x* axis and logarithmic *y* axis, the plot looks like the following
    screenshot:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个与频率成反比的函数。如果你想绝对确定 *1/f* 属性，你可以对所有的 *x* 值取 `np.log10`，并确保曲线以大致线性的方式下降。在线性
    *x* 轴和对数 *y* 轴上，图表看起来如下截图所示：
- en: '![](img/61fc8f5b-f196-4e26-8c1b-bec7ca65c16f.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/61fc8f5b-f196-4e26-8c1b-bec7ca65c16f.png)'
- en: This property is quite remarkable. It states that if we were to average all
    the spectra of all the images ever taken of natural scenes (neglecting all the
    ones taken with fancy image filters, of course), we would get a curve that would
    look remarkably like the one shown in the preceding image.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特性非常显著。它表明，如果我们平均所有自然场景的图像的频谱（当然忽略所有使用花哨图像滤镜拍摄的图像），我们会得到一个看起来非常像前面图像的曲线。
- en: 'But, going back to the image of a peaceful little boat on the **Limmat** river,
    *what about single images?* We have just looked at the power spectrum of this
    image and witnessed the *1/f* property. *How can we use our knowledge of natural
    image statistics to tell an algorithm not to stare at the tree on the left, but
    instead focus on the boat that is chugging in the water?* The following photo
    depicts a scene at the Limmat river:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，回到平静小船在 **Limmat** 河上的图像，*单张图像又如何呢？* 我们刚刚看了这张图像的功率谱，并见证了 *1/f* 属性。*我们如何利用我们对自然图像统计的了解来告诉算法不要盯着左边的树看，而是专注于在水中缓缓行驶的船呢？*
    以下照片描绘了 Limmat 河上的一个场景：
- en: '![](img/1ff3b240-c2b0-48ef-8e70-0e6b6cb0f53a.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1ff3b240-c2b0-48ef-8e70-0e6b6cb0f53a.png)'
- en: This is where we realize what saliency really means.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们真正意识到显著性真正含义的地方。
- en: Let's see how to generate a saliency map with the spectral residual approach
    in the next section.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在下一节中用频谱残差方法生成显著性图。
- en: Generating a saliency map with the spectral residual approach
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用频谱残差方法生成显著性图
- en: The things that deserve our attention in an image are not the image patches
    that follow the *1/f* law, but the patches that stick out of the smooth curves,
    in other words, statistical anomalies. These anomalies are termed the **spectral
    residual** of an image and correspond to the potentially *interesting* patches
    of an image (or proto-objects). A map that shows these statistical anomalies as
    bright spots is called a **saliency map**.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在图像中需要注意的事情不是遵循 *1/f* 法则的图像块，而是突出在平滑曲线之外的图像块，换句话说，是统计异常。这些异常被称为图像的**频谱残差**，对应于图像中可能*有趣*的块（或原对象）。显示这些统计异常为亮点的地图称为**显著性图**。
- en: 'The spectral residual approach described here is based on the original scientific
    publication article *Saliency Detection: A Spectral Residual Approach* by Xiaodi
    Hou and Liqing Zhang (2007), IEEE Transactions on Computer Vision and Pattern
    Recognition (CVPR), p.1-8, DOI: 10.1109/CVPR.2007.383267.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '这里描述的频谱残差方法基于 Xiaodi Hou 和 Liqing Zhang 于 2007 年发表的原科学出版物文章《显著性检测：频谱残差方法》（Saliency
    Detection: A Spectral Residual Approach），IEEE Transactions on Computer Vision
    and Pattern Recognition (CVPR)，第 1-8 页，DOI：10.1109/CVPR.2007.383267。'
- en: 'The saliency map of a single channel can be generated with the `_get_channel_sal_magn` function using
    the following process. In order to generate a saliency map based on the spectral
    residual approach, we need to process each channel of an input image separately
    (a single channel in the case of a grayscale input image, and three separate channels
    in the case of an RGB input image):'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 单个通道的显著性图可以通过`_get_channel_sal_magn`函数使用以下过程生成。为了基于频谱残差方法生成显著性图，我们需要分别处理输入图像的每个通道（对于灰度输入图像是单个通道，对于RGB输入图像是三个单独的通道）：
- en: 'Calculate the (`magnitude` and phase of the) Fourier spectrum of an image,
    by again using either the `fft` module of NumPy or the OpenCV functionality:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过再次使用NumPy的`fft`模块或OpenCV功能来计算图像的（幅度和相位）傅里叶频谱：
- en: '[PRE17]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Calculate the log amplitude of the Fourier spectrum. We will clip the lower
    bound of magnitudes to `1e-9` in order to prevent a division by 0 while calculating
    the log:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算傅里叶频谱的对数幅度。我们将幅度下限裁剪到`1e-9`，以防止在计算对数时除以0：
- en: '[PRE18]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Approximate the averaged spectrum of a typical natural image by convolving
    the image with a local averaging filter:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过与局部平均滤波器卷积来近似典型自然图像的平均光谱：
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Calculate the spectral `residual`. The spectral `residual` primarily contains
    the non-trivial (or unexpected) parts of a scene:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算频谱残差。频谱残差主要包含场景的非平凡（或意外）部分：
- en: '[PRE20]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Calculate the saliency map by using the inverse Fourier transform, again either
    via the `fft` module in NumPy or with OpenCV:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用逆傅里叶变换来计算显著性图，再次通过NumPy中的`fft`模块或OpenCV：
- en: '[PRE21]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'A single-channel saliency map (`magnitude`) is used by `get_saliency_map`,
    where the procedure is repeated for all channels of the input image. If the input
    image is grayscale, we are pretty much done:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 单通道显著性图（幅度）由`get_saliency_map`使用，对于输入图像的所有通道重复此过程。如果输入图像是灰度的，我们基本上就完成了：
- en: '[PRE22]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'However, if the input image has multiple channels, as is the case for an RGB
    color image, we need to consider each channel separately:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果输入图像具有多个通道，例如RGB彩色图像，我们需要分别考虑每个通道：
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The overall salience of a multichannel image is then determined by the average
    overall channels:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 多通道图像的整体显著性由平均整体通道确定：
- en: '[PRE24]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Finally, we need to apply some post-processing, such as an optional blurring
    stage to make the result appear smoother:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要应用一些后处理，例如可选的模糊阶段，以使结果看起来更平滑：
- en: '[PRE25]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Also, we need to square the values in `sal` in order to highlight the regions
    of high salience, as outlined by the authors of the original paper. In order to
    display the image, we scale it back up to its original resolution and normalize
    the values, so that the largest value is 1.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还需要将`sal`中的值平方，以突出显示作者在原始论文中概述的高显著性区域。为了显示图像，我们将它缩放回原始分辨率并归一化值，使得最大值为1。
- en: 'Next, normalize the values in `sal` so that the largest value is 1, then square
    them in order to highlight the regions of high salience as outlined by the authors
    of the original paper, and, lastly, scale back to its original resolution in order
    to display the image:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将`sal`中的值归一化，使得最大值为1，然后平方以突出显示作者在原始论文中概述的高显著性区域，最后将其缩放回原始分辨率以显示图像：
- en: '[PRE26]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The resulting saliency map then looks like the following:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的显著性图看起来如下：
- en: '![](img/27395e81-da35-4002-a05c-f4d7041789d1.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/27395e81-da35-4002-a05c-f4d7041789d1.png)'
- en: Now we can clearly spot the boat in the water (in the lower-left corner), which
    appears as one of the most salient subregions of the image. There are other salient
    regions, too, such as the **Grossmünster** on the right (*have you guessed the
    city yet?*).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以清楚地看到水中的船（在左下角），它看起来是图像中最显著的子区域之一。还有其他显著的区域，例如右边的**格罗斯穆斯特**（*你猜到这个城市了吗？*）。
- en: By the way, the fact that these two areas are the most salient ones in the image
    seems to be clear and indisputable evidence that the algorithm is aware of the
    ridiculous number of church towers in the city center of **Zurich**, effectively
    prohibiting any chance of them being labeled as "*salient*".
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，这两个区域是图像中最显著的，这似乎是明显的、无可争议的证据，表明算法意识到苏黎世市中心教堂塔楼的数量是荒谬的，有效地阻止了它们被标记为"*显著的*"。
- en: In the next section, we'll see how to detect proto-objects in a scene.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看到如何检测场景中的原型对象。
- en: Detecting proto-objects in a scene
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在场景中检测原型对象
- en: In a sense, the saliency map is already an explicit representation of proto-objects,
    as it contains only the *interesting* parts of an image. So now that we have done
    all the hard work, all that is left to do in order to obtain a proto-object map
    is to threshold the saliency map.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在某种意义上，显著度图已经是一个原型对象的显式表示，因为它只包含图像的**有趣**部分。因此，现在我们已经完成了所有艰苦的工作，剩下的工作就是将显著度图进行阈值处理，以获得原型对象图。
- en: The only open parameter to consider here is the threshold. Setting the threshold
    too low will result in labeling a lot of regions as proto-objects, including some
    that might not contain anything of interest (false alarm). On the other hand,
    setting the threshold too high will ignore most of the salient regions in the
    image and might leave us with no proto-objects at all.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这里唯一要考虑的开放参数是阈值。设置阈值过低会导致将许多区域标记为原型对象，包括可能不包含任何有趣内容的区域（误报）。另一方面，设置阈值过高会忽略图像中的大多数显著区域，并可能使我们没有任何原型对象。
- en: 'The authors of the original spectral residual paper chose to label only those
    regions of the image as proto-objects whose saliency was larger than three times
    the mean saliency of the image. We give the user the choice either to implement
    this threshold or to go with the **Otsu threshold** by setting the input flag `use_otsu` to `True`:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 原始光谱残差论文的作者选择仅将那些显著度大于图像平均显著度三倍的图像区域标记为原型对象。我们给用户提供了选择，要么实现这个阈值，要么通过将输入标志`use_otsu`设置为`True`来使用**Otsu阈值**：
- en: '[PRE27]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We then convert saliency to `uint8` precision so that it can be passed to `cv2.threshold`,
    set parameters for thresholding, and, finally, we apply thresholding and return
    the proto-objects:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将显著度转换为`uint8`精度，以便可以传递给`cv2.threshold`，设置阈值参数，最后应用阈值并返回原型对象：
- en: '[PRE28]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The resulting proto-objects mask looks as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 结果原型对象掩码看起来如下：
- en: '![](img/f3fabb1e-cfd2-493c-b3d2-33ab7c3e469f.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f3fabb1e-cfd2-493c-b3d2-33ab7c3e469f.png)'
- en: The proto-objects mask then serves as an input to the tracking algorithm, which
    we will see in the next section.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 原型对象掩码随后作为跟踪算法的输入，我们将在下一节中看到。
- en: Understanding mean-shift tracking
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解平均漂移跟踪
- en: So far we used the salience detector discussed previously to find bounding boxes
    of proto-objects. We could simply apply the algorithm to every frame of a video
    sequence and get a good idea of the location of the objects. However, what is
    getting lost is correspondence information.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用了之前讨论过的显著性检测器来找到原型对象的边界框。我们可以简单地将算法应用于视频序列的每一帧，并得到对象位置的不错概念。然而，丢失的是对应信息。
- en: Imagine a video sequence of a busy scene, such as from a city center or a sports
    stadium. Although a saliency map could highlight all the proto-objects in every
    frame of a recorded video, the algorithm would have no way to establish a correspondence
    between proto-objects from the previous frame and proto-objects in the current
    frame.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个繁忙场景的视频序列，比如城市中心或体育场的场景。尽管显著度图可以突出显示记录视频每一帧中的所有原型对象，但算法将无法在上一帧的原型对象和当前帧的原型对象之间建立对应关系。
- en: 'Also, the proto-objects map might contain some *false positives*, and we need
    an approach to select the most probable boxes that correspond to real-world objects.
    Such *false positives* can be noticed in the following example:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，原型对象映射可能包含一些**误报**，我们需要一种方法来选择最可能对应于真实世界对象的框。以下例子中可以注意到这些**误报**：
- en: '![](img/faf177a8-dc30-43e4-846f-ddaf5292e74d.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/faf177a8-dc30-43e4-846f-ddaf5292e74d.png)'
- en: Note that the bounding boxes extracted from the proto-objects map made (at least)
    three mistakes in the preceding example—it missed highlighting a player (upper-left),
    merged two players into the same bounding box, and highlighted some additional
    arguably non-interesting (although visually salient) objects. In order to improve
    these results and maintain correspondence, we want to take advantage of a tracking
    algorithm.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，从原型对象映射中提取的边界框在前面的例子中至少犯了三个错误——它没有突出显示一个球员（左上角），将两个球员合并到同一个边界框中，并突出显示了一些额外的可能不是有趣（尽管视觉上显著）的对象。为了改进这些结果并保持对应关系，我们想要利用跟踪算法。
- en: To solve the correspondence problem, we could use the methods we have learned
    about previously, such as feature matching and optical flow, but in this case,
    we will use the mean-shift algorithm for tracking.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决对应问题，我们可以使用之前学过的方法，例如特征匹配和光流，但在这个情况下，我们将使用平均漂移算法进行跟踪。
- en: Mean-shift is a simple yet very effective technique for tracking arbitrary objects.
    The intuition behind the mean-shift is to consider the pixels in a small region
    of interest (say, the bounding box of an object we want to track) as sampled from
    an underlying probability density function that best describes a target.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 均值漂移是一种简单但非常有效的追踪任意对象的技巧。均值漂移背后的直觉是将感兴趣区域（例如，我们想要追踪的对象的边界框）中的像素视为从描述目标的最佳概率密度函数中采样的。
- en: 'Consider, for example, the following image:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下图像：
- en: '![](img/152dad47-0db3-4d62-a1ff-dff96e83c526.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/152dad47-0db3-4d62-a1ff-dff96e83c526.png)'
- en: Here, the small gray dots represent samples from a probability distribution.
    Assume that the closer the dots, the more similar they are to each other. Intuitively
    speaking, what mean-shift is trying to do is to find the densest region in this
    landscape and draw a circle around it. The algorithm might start out centering
    a circle over a region of the landscape that is not dense at all (the dashed circle).
    Over time, it will slowly move toward the densest region (the solid circle) and
    anchor on it.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，小的灰色点代表概率分布的样本。假设点越近，它们彼此越相似。直观地说，均值漂移试图做的是找到这个景观中最密集的区域，并在其周围画一个圆。算法可能最初将圆的中心放在景观中完全不密集的区域（虚线圆）。随着时间的推移，它将逐渐移动到最密集的区域（实线圆）并锚定在那里。
- en: If we design the landscape to be more meaningful than dots, we can use mean-shift
    tracking to find the objects of interest in the scene. For example, if we assign
    to each dot some value for correspondence between the color histogram of an object
    and the color histogram of a neighborhood of an image of the same size as the
    object, we can use mean-shift on the resulting dots to track the object. It is
    the latter approach that is usually associated with mean-shift tracking. In our
    case, we will simply use the saliency map itself.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们设计景观使其比点更有意义，我们可以使用均值漂移追踪来找到场景中的感兴趣对象。例如，如果我们为每个点分配一个值，表示对象的颜色直方图与相同大小的图像邻域的颜色直方图之间的对应关系，我们就可以在生成的点上使用均值漂移来追踪对象。通常与均值漂移追踪相关的是后一种方法。在我们的情况下，我们将简单地使用显著性图本身。
- en: 'Mean-shift has many applications (such as clustering, or finding the mode of
    probability density functions), but it is also particularly well suited to target
    tracking. In OpenCV, the algorithm is implemented in `cv2.meanShift` and accepts
    a two-dimensional array (for example, a grayscale image such as a saliency map)
    and window (in our case, we use the bounding box of an object) as input. It returns
    new positions of the window in accordance with the mean-shift algorithm as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 均值漂移有许多应用（如聚类或寻找概率密度函数的模态），但它也非常适合目标追踪。在OpenCV中，该算法在`cv2.meanShift`中实现，接受一个二维数组（例如，一个灰度图像，如显著性图）和窗口（在我们的情况下，我们使用对象的边界框）作为输入。它根据均值漂移算法返回窗口的新位置，如下所示：
- en: It fixes a window position.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它固定窗口位置。
- en: It computes the mean of the data within the window.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它计算窗口内数据的平均值。
- en: It shifts the window to the mean and repeats until convergence. We can control
    the length and accuracy of the iterative method by specifying the termination
    criteria.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将窗口移动到平均值并重复，直到收敛。我们可以通过指定终止条件来控制迭代方法的长度和精度。
- en: Next, let's see how the algorithm tracks and visually maps (with bounding boxes)
    a player on the field.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看算法是如何追踪并在视觉上映射（使用边界框）场上的球员的。
- en: Automatically tracking all players on a soccer field
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动追踪足球场上的所有球员
- en: Our goal is to combine the saliency detector with mean-shift tracking to automatically
    track all the players on a soccer field. The proto-objects identified by the saliency
    detector will serve as input to the mean-shift tracker. Specifically, we will
    focus on a video sequence from the Alfheim dataset, which can be freely obtained
    from [http://home.ifi.uio.no/paalh/dataset/alfheim/](http://home.ifi.uio.no/paalh/dataset/alfheim/).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是将显著性检测器与均值漂移追踪相结合，以自动追踪足球场上的所有球员。显著性检测器识别出的原型对象将作为均值漂移追踪器的输入。具体来说，我们将关注来自Alfheim数据集的视频序列，该数据集可以从[http://home.ifi.uio.no/paalh/dataset/alfheim/](http://home.ifi.uio.no/paalh/dataset/alfheim/)免费获取。
- en: The reason for combining the two algorithms (saliency map and mean-shift tracking),
    is to maintain correspondence information between objects in different frames
    as well as to remove some false positives and improve the accuracy of detected
    objects.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 将两个算法（显著性图和均值漂移跟踪）结合的原因是为了在不同帧之间保持对象之间的对应信息，以及去除一些误报并提高检测对象的准确性。
- en: 'The hard work is done by the previously introduced `MultiObjectTracker` class
    and its `advance_frame` method. The `advance_frame` method is called whenever
    a new frame arrives, and accepts proto-objects and saliency as input:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 之前介绍过的`MultiObjectTracker`类及其`advance_frame`方法完成了这项艰苦的工作。每当有新帧到达时，就会调用`advance_frame`方法，并接受原型对象和显著性作为输入：
- en: '[PRE29]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The following steps are covered in this method:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤包含在本方法中：
- en: 'Create contours from `proto_objects_map` and find bounding rectangles for all
    contours that have an area greater than `min_object_area`. The latter is the candidate
    bounding boxes for tracking with the mean shift algorithm:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`proto_objects_map`创建轮廓，并找到面积大于`min_object_area`的所有轮廓的边界矩形。后者是使用均值漂移算法进行跟踪的候选边界框：
- en: '[PRE30]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The candidate boxes might be not the best ones for tracking them throughout
    the frames. For example, in this case, if two players are close to each other,
    they result in a single object box. We need some approach to select the best boxes.
    We could think about some algorithm that will analyze boxes tracked from previous
    frames in combination with boxes obtained from saliency, and deduce the most probable
    boxes.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 候选框可能不是在整个帧中跟踪的最佳选择。例如，在这种情况下，如果两个玩家彼此靠近，它们将导致一个单一的对象框。我们需要某种方法来选择最佳的框。我们可以考虑一些算法，该算法将分析从前一帧跟踪的框与从显著性获得的框结合起来，并推断出最可能的框。
- en: 'But we will do it in a simple manner here—if the number of boxes from the saliency
    map doesn''t increase, boxes from the previous frame to the current frame using
    the saliency map of the current frame are tracked, which are saved as `objcect_boxes`:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 但在这里我们将以简单的方式进行——如果显著性图中的框数量没有增加，则使用当前帧的显著性图跟踪从前一帧到当前帧的框，这些框被保存为`objcect_boxes`：
- en: '[PRE31]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'If it did increase, we reset the tracking information, which is the number
    of frames through which the objects were tracked and the initial centers of the
    objects were calculated:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果它确实增加了，我们将重置跟踪信息，即对象被跟踪的帧数以及对象初始中心的计算：
- en: '[PRE32]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Finally, save the boxes and make an illustration of the tracking information
    on the frame:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，保存框并将在帧上绘制跟踪信息：
- en: '[PRE33]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We are interested in boxes that move. For that purpose, we calculate the displacements
    of each box from their initial location at the start of tracking. We suppose that
    objects that appear larger on a frame should move faster, hence we normalize the
    displacements on box width:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对移动的框感兴趣。为此，我们计算每个框从跟踪开始时的初始位置的位移。我们假设在帧上出现更大的对象应该移动得更快，因此我们在框宽度上归一化位移：
- en: '[PRE34]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Next, we draw boxes and their number, which have average displacement per frame
    (or speed) greater than the value that we specified on the initialization of the
    tracker. A small number is added in order not to divide by 0 on the first frame
    of tracking:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们绘制框及其数量，这些框的平均每帧位移（或速度）大于我们在跟踪器初始化时指定的值。为了不在跟踪的第一帧上除以0，我们添加了一个小的数值：
- en: '[PRE35]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Now you understand how it is possible to implement tracking using the mean-shift
    algorithm. This is only one approach for tracking out of many others on offer.
    Mean-shift tracking might particularly fail when the objects rapidly change in
    size, as would be the case if an object of interest were to come straight at the
    camera.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经理解了如何使用均值漂移算法实现跟踪。这只是众多跟踪方法中的一种。当感兴趣的对象直接朝向相机快速改变大小时，均值漂移跟踪可能会特别失败。
- en: For such cases, OpenCV has a different algorithm, `cv2.CamShift`, which also
    takes into account rotations and changes in size, where **CAMShift** stands for
    **Continuously Adaptive Mean-Shift**. Moreover, OpenCV has a range of available
    trackers that can be used out of the box and are referred to as the **OpenCV Tracking
    API**. Let's learn about them in the next section.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此类情况，OpenCV有一个不同的算法，`cv2.CamShift`，它还考虑了旋转和尺寸的变化，其中**CAMShift**代表**连续自适应均值漂移**。此外，OpenCV提供了一系列可用的跟踪器，可以直接使用，被称为**OpenCV跟踪API**。让我们在下一节中了解它们。
- en: ​Learning about the OpenCV Tracking API
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解OpenCV跟踪API
- en: We have applied the mean-shift algorithm on the saliency map for tracking salient
    objects. Surely, not all the objects in the world are salient, so we can't use
    that approach for tracking any object. As mentioned previously, we could also
    use an HSV histogram in combination with the mean-shift algorithm to track objects.
    The latter does not require a saliency map—if a region is selected, that approach
    will try to track selected objects throughout the consequent frames.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将均值漂移算法应用于显著性图以跟踪显著对象。当然，世界上并非所有对象都是显著的，因此我们不能使用那种方法来跟踪任何对象。如前所述，我们还可以结合使用HSV直方图和均值漂移算法来跟踪对象。后者不需要显著性图——如果选择了区域，那种方法将尝试在后续帧中跟踪所选对象。
- en: In this section, we will create a script that is able to track an object throughout
    a video using the tracking algorithms available in OpenCV. All these algorithms
    have the same API and are referred to collectively as the OpenCV Tracking API.
    These algorithms track single objects—once the initial bounding box is provided
    to the algorithm, it will try to maintain the new positions of the box throughout
    the consequent frames. Surely, it's also possible to track multiple objects in
    the scene by creating a new tracker for each object.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将创建一个脚本，该脚本能够使用OpenCV中可用的跟踪算法在整个视频中跟踪一个对象。所有这些算法都有相同的API，并统称为OpenCV跟踪API。这些算法跟踪单个对象——一旦向算法提供了初始边界框，它将尝试在整个后续帧中维持该框的新位置。当然，也可以通过为每个对象创建一个新的跟踪器来跟踪场景中的多个对象。
- en: 'First of all, we import the libraries that we will use and define our constants:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入我们将使用的库并定义我们的常量：
- en: '[PRE36]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'OpenCV currently has eight built-in trackers. We define a map of the constructors
    of all trackers:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV目前有八个内置跟踪器。我们定义了一个所有跟踪器构造函数的映射：
- en: '[PRE37]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Our script will be able to accept the name of the tracker and a path to a video
    as arguments. In order to achieve this, we create arguments, set their default
    values, and parse them with the previously imported `argparse` module:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的脚本将能够接受跟踪器的名称和视频的路径作为参数。为了实现这一点，我们创建参数，设置它们的默认值，并使用之前导入的`argparse`模块解析它们：
- en: '[PRE38]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Then, we make sure that such a tracker exists and we try to read the first frame
    from the specified video.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们确保存在这样的跟踪器，并尝试从指定的视频中读取第一帧。
- en: 'Now that we have set up the script and can accept parameters, the next thing
    to do is to instantiate the tracker:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置了脚本并可以接受参数，下一步要做的是实例化跟踪器：
- en: 'First of all, it''s a good idea to make the script case-insensitive and check
    whether the passed tracker exists at all:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，使脚本不区分大小写并检查传递的跟踪器是否存在是一个好主意：
- en: '[PRE39]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Open the video and read the first `frame`. Then, break the script if the video
    cannot be read:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开视频并读取第一`帧`。然后，如果无法读取视频，则中断脚本：
- en: '[PRE40]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Select a region of interest (using a bounding box) for tracking throughout
    the video. OpenCV has a user-interface-based implementation for that:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个感兴趣的区域（使用边界框）以在整个视频中跟踪。OpenCV为此提供了一个基于用户界面的实现：
- en: '[PRE41]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Once this method is called, an interface will appear where you can select a
    box. Once the *Enter* key is pressed, the coordinates for the selected box are
    returned.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦调用此方法，将出现一个界面，您可以在其中选择一个框。一旦按下*Enter*键，就会返回所选框的坐标。
- en: 'Initiate the tracker with the first frame and the selected bounding box:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用第一帧和选定的边界框启动跟踪器：
- en: '[PRE42]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now we have an instance of the tracker that has been initiated with the first
    frame and selected a bounding box of interest. We update the tracker with the
    next frames to find the new location of the object in the bounding box. We also
    estimate the **frames per second** (**FPS**) of the selected tracking algorithm
    using the `time` module:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个跟踪器的实例，它已经使用第一帧和选定的感兴趣边界框启动。我们使用下一帧更新跟踪器以找到对象在边界框中的新位置。我们还使用`time`模块估计所选跟踪算法的**每秒帧数**（**FPS**）：
- en: '[PRE43]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'All the calculations are done by this point. Now we illustrate the results
    for each iteration:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 所有计算都在这一点上完成。现在我们展示每个迭代的计算结果：
- en: '[PRE44]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: If a bounding box was returned by the algorithm, we draw that box on the frame,
    otherwise, we illustrate that the tracking failed, which means that the selected
    algorithm failed to find the object in the current frame. Also, we type the name
    of the tracker and the current FPS on the frame.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如果算法返回了边界框，我们在帧上绘制该框，否则，我们说明跟踪失败，这意味着所选算法未能找到当前帧中的对象。此外，我们在帧上键入跟踪器的名称和当前FPS。
- en: You can run this script on different videos with different algorithms in order
    to see how the algorithms behave, especially how they handle occlusions, fast-moving
    objects, and objects that change a lot in appearance. After trying the algorithms,
    you might also be interested to read the original papers of the algorithms to
    find out implementation details.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用不同的算法在不同的视频上运行这个脚本，以查看算法的行为，特别是它们如何处理遮挡、快速移动的物体以及外观变化很大的物体。尝试了算法之后，你也可能对阅读算法的原始论文感兴趣，以了解实现细节。
- en: 'In order to track multiple objects using these algorithms, OpenCV has a convenient
    wrapper class that combines multiple instances of the tracker and updates them
    simultaneously. In order to use it, first, we create an instance of the class:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用这些算法跟踪多个物体，OpenCV有一个方便的包装类，它结合了多个跟踪器实例并同时更新它们。为了使用它，首先，我们创建该类的实例：
- en: '[PRE45]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Next, for each bounding box of interest, a new tracker is created (MIL tracker,
    in this case) and added to the `multiTracker` object:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，对于每个感兴趣的边界框，创建一个新的跟踪器（在本例中为MIL跟踪器）并将其添加到`multiTracker`对象中：
- en: '[PRE46]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Finally, the new positions of the bounding boxes are obtained by updating the `multiTracker` object
    with a new frame:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过用新帧更新`multiTracker`对象，我们获得了边界框的新位置：
- en: '[PRE47]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: As an exercise, you might want to replace the mean-shift tracking in the application
    for tracking salient objects with one of the trackers introduced in this chapter.
    In order to do it, you can use `multiTracker` with one of the trackers to update
    the positions of bounding boxes for proto-objects.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 作为练习，你可能想要用本章介绍的一种跟踪器替换应用程序中用于跟踪显著物体的mean-shift跟踪。为了做到这一点，你可以使用`multiTracker`与其中一个跟踪器一起更新原型物体的边界框位置。
- en: Putting it all together
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整合所有内容
- en: 'The result of our app can be seen in the following set of screenshots:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下一组屏幕截图中看到我们应用程序的结果：
- en: '![](img/1b1ed6e4-7749-467f-ac3b-0c8e47276039.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1b1ed6e4-7749-467f-ac3b-0c8e47276039.png)'
- en: Throughout the video sequence, the algorithm is able to pick up the location
    of the players and successfully track them frame by frame by using mean-shift
    tracking.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个视频序列中，算法能够通过使用mean-shift跟踪识别球员的位置，并逐帧成功跟踪他们。
- en: Summary
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored a way to label the potentially *interesting* objects
    in a visual scene, even if their shape and number are unknown. We explored natural
    image statistics using Fourier analysis and implemented a  method for extracting
    the visually salient regions in the natural scenes. Furthermore, we combined the
    output of the salience detector with a tracking algorithm to track multiple objects
    of unknown shape and number in a video sequence of a soccer game.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探索了一种标记视觉场景中可能*有趣*的物体方法，即使它们的形状和数量未知。我们使用傅里叶分析探索了自然图像统计，并实现了一种从自然场景中提取视觉显著区域的方法。此外，我们将显著性检测器的输出与跟踪算法相结合，以跟踪足球比赛视频序列中未知形状和数量的多个物体。
- en: We have introduced other, more complex tracking algorithms available in OpenCV,
    which you can use to replace mean-shift tracking in the application or even create
    your own application. Of course, it would also be possible to replace the mean-shift
    tracker with a previously studied technique such as feature matching or optic
    flow.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了OpenCV中可用的其他更复杂的跟踪算法，你可以用它们替换应用程序中的mean-shift跟踪，甚至创建自己的应用程序。当然，也可以用之前研究过的技术，如特征匹配或光流，来替换mean-shift跟踪器。
- en: In the next chapter, we will move on to the fascinating field of machine learning,
    which will allow us to build more powerful descriptors of objects. Specifically,
    we will focus on both detection (*the where*) and identification (*the what*)
    of street signs in images. This will allow us to train a classifier that could
    be used in a dashboard camera in your car and will familiarize us with the important
    concepts of machine learning and object recognition.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将进入迷人的机器学习领域，这将使我们能够构建更强大的物体描述符。具体来说，我们将专注于图像中街道标志的检测（*位置*）和识别（*内容*）。这将使我们能够训练一个分类器，它可以用于您汽车仪表盘上的摄像头，并使我们熟悉机器学习和物体识别的重要概念。
- en: Dataset attribution
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集归属
- en: '"*Soccer video and player position dataset*," *S. A. Pettersen, D. Johansen,
    H. Johansen, V. Berg-Johansen, V. R. Gaddam, A. Mortensen, R. Langseth, C. Griwodz,
    H. K. Stensland,* and *P. Halvorsen*, in Proceedings of the International Conference
    on Multimedia Systems (MMSys), Singapore, March 2014, pp. 18-23.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '"*足球视频和球员位置数据集*," *S. A. Pettersen, D. Johansen, H. Johansen, V. Berg-Johansen,
    V. R. Gaddam, A. Mortensen, R. Langseth, C. Griwodz, H. K. Stensland,* 和 *P. Halvorsen*，在2014年3月新加坡国际多媒体系统会议（MMSys）论文集中，第18-23页。'
