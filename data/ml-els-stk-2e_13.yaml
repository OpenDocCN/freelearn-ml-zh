- en: '*Chapter 10*: Outlier Detection'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第10章*：异常值检测'
- en: In the first section of this book, we discussed anomaly detection in depth,
    a feature that allows us to detect unusual behavior in time series data in an
    unsupervised fashion. This works well when we want to detect whether one of our
    applications is experiencing unusual latency at a particular time or whether a
    host on our corporate network is transmitting an unusual number of bytes.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第一部分，我们深入讨论了异常检测，这是一个允许我们以无监督方式检测时间序列数据中异常行为的特性。当我们想要检测我们的某个应用程序在特定时间是否经历了异常延迟，或者我们公司网络上的主机是否传输了异常数量的字节时，这种方法效果很好。
- en: 'In this chapter, we will learn about the second unsupervised learning feature
    in the Elastic Stack: outlier detection, which allows us to detect unusual entities
    in non-time series-based indices. Some interesting applications of outlier detection
    could involve, for example, detecting unusual cells in a tissue sample, investigating
    unusual houses, or areas in a local real estate market and catching unusual binaries
    installed on your computer.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将了解Elastic Stack中的第二个无监督学习特性：异常值检测，它允许我们在非时间序列索引中检测异常实体。异常值检测的一些有趣应用可能包括，例如，检测组织样本中的异常细胞，调查异常房屋或当地房地产市场中的区域，以及检测您计算机上安装的异常二进制文件。
- en: The outlier detection functionality in the Elastic Stack is based on an ensemble
    or a grouping of four different outlier detection techniques. Two of these techniques
    are density-based – that is, they try to determine which data points in your index
    are far away from the bulk of the data – and two are distance-based – that is,
    they try to determine which points are far away from all other points. While,
    individually, each of the four algorithms has its strengths and weaknesses, taken
    together as an ensemble (or a grouping), they perform robust outlier detection.
    We discuss what each of these algorithms does on a conceptual level later in the
    chapter.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic Stack中的异常值检测功能基于四种不同的异常值检测技术的集成或分组。其中两种技术基于密度——也就是说，它们试图确定在您的索引中哪些数据点远离数据的大多数——另外两种基于距离——也就是说，它们试图确定哪些点远离所有其他点。虽然，单独来看，这四个算法各有其优势和劣势，但作为一个整体（或分组），它们能够执行稳健的异常值检测。我们将在本章后面讨论每个算法在概念层面上的作用。
- en: 'In addition to exploring the technology that powers outlier detection, we will
    take a look at how outlier detection differs from anomaly detection, how to configure
    an outlier detection job in Elasticsearch, how to interpret the results of outlier
    detection, as well as how to understand which features were responsible for a
    given point being declared an outlier. We will explore the following topics in
    this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 除了探索驱动异常值检测的技术之外，我们还将探讨异常值检测与异常检测的区别，如何在Elasticsearch中配置异常值检测作业，如何解释异常值检测的结果，以及如何理解哪些特征导致了某个点被宣布为异常值。我们将在本章探讨以下主题：
- en: Discovering how outlier detection works under the hood
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索异常值检测的工作原理
- en: Applying outlier detection in practice
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实践中应用异常值检测
- en: Evaluating outlier detection with the Evaluate API
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Evaluate API评估异常值检测
- en: Hyperparameter tuning for outlier detection
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常值检测的超参数调整
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The material in this chapter relies on using Elasticsearch version 7.9 or above.
    The figures in this chapter have been generated using Elasticsearch 7.10\. Code
    snippets and code examples used in this chapter are under the `chapter10` folder
    in the book''s GitHub repository: [https://github.com/PacktPublishing/Machine-Learning-with-Elastic-Stack-Second-Edition](https://github.com/PacktPublishing/Machine-Learning-with-Elastic-Stack-Second-Edition).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的材料依赖于使用Elasticsearch版本7.9或更高版本。本章中的图表是使用Elasticsearch 7.10生成的。本章中使用的代码片段和代码示例位于书籍GitHub仓库的`chapter10`文件夹中：[https://github.com/PacktPublishing/Machine-Learning-with-Elastic-Stack-Second-Edition](https://github.com/PacktPublishing/Machine-Learning-with-Elastic-Stack-Second-Edition)。
- en: Discovering how outlier detection works
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 探索异常值检测的工作原理
- en: '**Outlier detection** can offer insights into datasets by discovering which
    points are different or unusual, but how does outlier detection in the Elastic
    Stack work? To understand how outlier detection functionality can be constructed,
    let''s start by thinking conceptually about how you would design the algorithm,
    and then see how our conceptual ideas can be formalized into the four separate
    algorithms that make up the outlier detection ensemble in Elasticsearch.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**异常值检测**可以通过发现哪些点是不同或异常的来对数据集提供洞察，但Elastic Stack中的异常值检测是如何工作的呢？为了理解如何构建异常值检测功能，让我们首先从概念上思考你将如何设计算法，然后看看我们的概念想法如何被形式化为构成Elasticsearch中异常值检测集合的四个独立算法。'
- en: 'Suppose for a second that we have a two-dimensional set of weight and circumference
    measurements of pumpkins and we wish to discover which pumpkins are outliers in
    this population (perhaps we want to use that information to find out *why* they
    are outliers). A good first step would be to plot the data to see whether there
    are any obvious data points that appear to be far from others:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一组关于南瓜重量和周长的二维数据集，并且我们希望发现哪些南瓜是这一群体中的异常值（也许我们想利用这些信息来找出它们为何是异常值）。一个很好的第一步是绘制数据，看看是否有任何明显的数据点看起来与其他数据点相距甚远：
- en: '![Figure 10.1 – Points A and B appear to be outliers in this dataset because
    they are located far from the general mass of data'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.1 – 点A和点B似乎是这个数据集中的异常值，因为它们位于数据总体分布之外'
- en: '](img/B17040_10_001.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_10_001.jpg)'
- en: Figure 10.1 – Points A and B appear to be outliers in this dataset because they
    are located far from the general mass of data
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – 点A和点B似乎是这个数据集中的异常值，因为它们位于数据总体分布之外
- en: Human eyes are exceptionally good at picking up patterns and a quick glance
    of the plot in *Figure 10.1* will tell you that points A and B appear to be outliers.
    What is the underlying intuitive reasoning that led us to this conclusion? Our
    visual system tells us that both points A and B appear to be, in some sense, far
    away from the two other distinct groups of points in the two-dimensional space.
    This observation and its formalization is the crux on which the outlier detection
    techniques used in the Elastic Stack are based.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 人类眼睛在捕捉模式方面非常出色，快速浏览一下*图10.1*就可以告诉你，点A和点B看起来像是异常值。是什么内在的直观推理让我们得出这个结论呢？我们的视觉系统告诉我们，从某种意义上说，点A和点B似乎远离二维空间中另外两个不同的点群。这一观察及其形式化是Elastic
    Stack中使用的异常值检测技术的基础。
- en: Discovering the four techniques used for outlier detection
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现用于异常值检测的四种技术
- en: 'As mentioned in the previous section, the outlier detection algorithm in the
    Elastic Stack is an ensemble, or grouping, of four distinct outlier detection
    techniques. These techniques can be further subdivided into two categories: **distance-based
    techniques** and **density-based techniques**. We will examine each in turn in
    the following sections.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如前节所述，Elastic Stack中的异常值检测算法是一个由四种不同的异常值检测技术组成的集合，或分组。这些技术可以进一步细分为两类：**基于距离的技术**和**基于密度的技术**。我们将在接下来的章节中逐一考察它们。
- en: Distance-based techniques
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于距离的技术
- en: As we saw in the previous section, the human visual system is incredibly adept
    at picking up outliers in two-dimensional images and the gist of how we are able
    to do this is by picking up the points that seem far away from the general mass
    of data. This observation is what the two distance-based techniques, **distance
    to kth-nearest neighbors** and **average distance to kth-nearest neighbors**,
    aim to capture.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如前节所述，人类的视觉系统在从二维图像中捕捉异常值方面非常擅长，而我们能够做到这一点的原因在于我们能够捕捉到那些似乎远离数据总体分布的点。这一观察结果正是两种基于距离的技术，即**到第k个最近邻的距离**和**到第k个最近邻的平均距离**，所试图捕捉的。
- en: 'Suppose we have a two-dimensional dataset that is spatially distributed, as
    in *Figure 10.2*, and suppose we pick the value of *k* to be 3\. At this point,
    we are just picking an arbitrarily low value of *k* for illustration purposes.
    This would mean that for point A in *Figure 10.2*, we find the third closest point
    and compute the distance of point A to it (marked with a thicker arrow in *Figure
    10.2*). This approach is great in its simplicity but is also prone to noise. To
    make this a bit more robust, we can also compute the **average distance to the
    kth-nearest neighbors** (illustrated in *Figure 10.2*):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个在空间上分布的两维数据集，如图*图10.2*所示，并且假设我们选择*k*的值为3。此时，我们只是为了说明目的而选择一个任意低的*k*值。这意味着对于*图10.2*中的点A，我们找到第三个最近点并计算点A到它的距离（在*图10.2*中以较粗的箭头标记）。这种方法在简单性方面很出色，但也容易受到噪声的影响。为了使这种方法更加稳健，我们还可以计算**到第k个最近邻的平均距离**（如图*图10.2*所示）：
- en: '![Figure 10.2 – Distance to kth-nearest neighbor from point A and average distance
    to kth-nearest neighbor for point A when k=3'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.2 – 点A到第k个最近邻的距离以及点A到第k个最近邻的平均距离，当k=3时'
- en: '](img/B17040_10_002.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_10_002.jpg)'
- en: Figure 10.2 – Distance to kth-nearest neighbor from point A and average distance
    to kth-nearest neighbor for point A when k=3
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 – 点A到第k个最近邻的距离以及点A到第k个最近邻的平均距离，当k=3时
- en: While distance-based methods are great in their simplicity and interpretability,
    they are unable to capture certain subtleties in the spatial distribution of the
    data, in particular, how sparse or dense the neighborhood of each data point is.
    To capture these properties, we have to look at density-based techniques.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然基于距离的方法在简单性和可解释性方面很出色，但它们无法捕捉数据空间分布中的某些细微差别，特别是每个数据点的邻域是稀疏还是密集。为了捕捉这些属性，我们必须查看基于密度的技术。
- en: Density-based techniques
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于密度的技术
- en: 'One factor that the distance-based methods fail to capture in full is the difference
    between the density of points in the neighborhood of our point of interest and
    the density of points around its neighbors. Computing the local outlier factor
    of a point captures exactly this: how different a given point''s neighborhood
    is from other points in the neighborhood.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 基于距离的方法未能充分捕捉的一个因素是，我们感兴趣点的邻域中点的密度与其邻居周围点的密度的差异。计算一个点的局部异常因子恰好捕捉了这一点：给定点的邻域与其他邻域中的点有多大的不同。
- en: '*Figure 10.3* illustrates the basic idea of this technique for k=3\. In this
    case, we compare the neighborhood of point A to the neighborhoods of its three
    nearest neighbors (illustrated by the dotted circles in the diagram in *Figure
    10.3*). A value of 1 for the local outlier factor measure means that the neighborhood
    of point A is comparable to that of its neighbors – it is neither more sparse
    nor more dense. A value greater than 1 means that the neighborhood of A is sparser
    than that of its neighbors and it could potentially be an outlier. Conversely,
    a value less than 1 means that the point is densely surrounded by its neighbors
    and thus unlikely to be an outlier:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10.3* 展示了当k=3时该技术的基本思想。在这种情况下，我们比较点A的邻域与其三个最近邻的邻域（如图*图10.3*中的虚线圆所示）。局部异常因子测量的值为1意味着点A的邻域与其邻居的邻域相当
    – 它既不更稀疏也不更密集。大于1的值意味着A的邻域比其邻居的邻域更稀疏，它可能是一个异常值。相反，小于1的值意味着该点被其邻居密集包围，因此不太可能是异常值：'
- en: '![Figure 10.3 – Local outlier factor compares the neighborhood of point A to
    the neighborhoods of its kth-nearest neighbors'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.3 – 局部异常因子比较点A的邻域与其第k个最近邻的邻域'
- en: '](img/B17040_10_003.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_10_003.jpg)'
- en: Figure 10.3 – Local outlier factor compares the neighborhood of point A to the
    neighborhoods of its kth-nearest neighbors
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 – 局部异常因子比较点A的邻域与其第k个最近邻的邻域
- en: The final method in our ensemble of four methods is the **local distance-based
    outlier factor** (**LDOF**). Similarly to the **local outlier factor** (**LOF**),
    the goal of **LDOF** is to compare the neighborhood of a given point, A, to the
    neighborhoods of its neighbors. In this case, we compute the average distance
    to the kth-nearest neighbors of A for some fixed value of *k*, *avg(A)*. Then,
    for each of the kth-nearest neighbors of A, we compute the pairwise distances
    and take the average value of them, *avgkk(A)*.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们四种方法组合中的最后一种方法是**基于局部距离的异常值因子**（**LDOF**）。与**局部异常因子**（**LOF**）类似，**LDOF**的目标是将给定点A的邻域与A的邻居的邻域进行比较。在这种情况下，我们计算A的第k个最近邻的平均距离，对于某个固定的*k*，计算*avg(A)*。然后，对于A的第k个最近邻中的每一个，我们计算成对距离并取它们的平均值，*avgkk(A)*。
- en: Finally, we inspect the ratio *avg(A)/avgkk(A)* to see how close it is to the
    value 1\. If the ratio approaches 1, it means that point A is surrounded by a
    local density of other points and is thus unlikely to be an outlier.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们检查*avg(A)/avgkk(A)*的比率，看看它接近1的程度。如果比率接近1，这意味着点A被其他点的局部密度所包围，因此不太可能是异常值。
- en: The final overall outlier score that is assigned to each data point is a combination
    of the values derived from the four methods above. The closer the value is to
    1, the more likely the point is to be an outlier.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 分配给每个数据点的最终整体异常值分数是上述四种方法得出的值的组合。该值越接近1，该点成为异常值的可能性就越大。
- en: While sometimes we simply want to figure out which of the points in our datasets
    are outliers, on other occasions, we also want to see why the outlier detection
    algorithm is suggesting that a particular point is an outlier. Is there a particular
    feature or field value or perhaps a group of values that is making the point unusual?
    This is the topic we will address in the next section.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们只是想找出数据集中哪些点是异常值，而在其他情况下，我们还想了解为什么异常值检测算法建议某个特定点是异常值。是否存在某个特定的特征或字段值，或者可能是一组值，使得该点变得不寻常？这就是我们将在下一节中讨论的主题。
- en: Understanding feature influence
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解特征影响力
- en: Let's return for a moment to our fictional pumpkin dataset from the beginning
    of this chapter. Suppose we are analyzing this dataset using outlier detection.
    After the analysis is complete, we have, for each pumpkin, a score from 0 to 1
    that measures the unusualness of the pumpkin. In addition to knowing the score,
    we might also be interested in understanding which feature – the weight of the
    pumpkin or the circumference of the pumpkin – contributed to its unusualness.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时回到本章开头提到的虚构南瓜数据集。假设我们正在使用异常值检测分析这个数据集。分析完成后，对于每个南瓜，我们都有一个从0到1的分数，衡量南瓜的异常性。除了知道分数外，我们还可能对了解哪些特征——南瓜的重量或南瓜的周长——对其异常性做出了贡献感兴趣。
- en: This is exactly the problem that **feature influence** aims to solve. In a nutshell,
    feature influence assigns to each feature (or **field** if we are thinking in
    terms of the vocabulary we usually use to describe Elasticsearch documents) a
    score from 0 to 1 that describes how significant the feature was in determining
    that the data point was an outlier. The total sum of feature influence scores
    across all features adds up to 1\.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是**特征影响力**旨在解决的问题。简而言之，特征影响力将0到1的分数分配给每个特征（如果我们从通常用来描述Elasticsearch文档的词汇来考虑，则是**字段**），该分数描述了该特征在确定数据点是异常值方面的重要性。所有特征的特征影响力分数总和为1。
- en: 'Let''s take a closer look at feature influence with the help of the fictional
    pumpkin dataset in *Figure 10.4*. Suppose that our outlier detection algorithm
    has identified points A and B as the outliers in this dataset. Now, let''s consider
    how the feature influence values of pumpkin weight and pumpkin circumference would
    be relative to one another in points A and B:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们借助图10.4中的虚构南瓜数据集来更仔细地看看特征影响力。假设我们的异常值检测算法已经确定A和B是该数据集中的异常值。现在，让我们考虑南瓜重量和南瓜周长在A和B点上的特征影响力值是如何相对的：
- en: '![Figure 10.4 – Feature influence scores measure how influential a given feature
    is in determining the unusualness of a data point'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.4 – 特征影响力分数衡量给定特征在确定数据点异常性方面的影响]'
- en: '](img/B17040_10_004.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_10_004.jpg]'
- en: Figure 10.4 – Feature influence scores measure how influential a given feature
    is in determining the unusualness of a data point
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.4 – 特征影响力分数衡量给定特征在确定数据点异常性方面的影响]'
- en: Pumpkin A has a weight that is far outside of the normal weight range of the
    pumpkins, but its circumference falls somewhere in the middle of the circumference
    values in the pumpkins of the left-hand cluster. Thus, we would expect the feature
    influence value for pumpkin weight to be high for point A, but the feature influence
    value for circumference to be low.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 南瓜A的重量远超出南瓜的正常重量范围，但其周长位于左侧簇南瓜周长值的中部。因此，我们预计南瓜重量的特征影响值对于点A会很高，但周长的特征影响值会很低。
- en: Now let's take a look at outlier pumpkin B, where the situation is reversed.
    While the weight of pumpkin B falls into the mid-range of the dataset, the circumference
    of pumpkin B is much higher than almost any other data point. Thus, for pumpkin
    B, the feature influence value of circumference would be higher than the value
    of weight.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看异常南瓜B，情况正好相反。虽然南瓜B的重量位于数据集的中段，但南瓜B的周长比几乎任何其他数据点都要高。因此，对于南瓜B，周长的特征影响值将高于重量的值。
- en: How is feature influence for each point calculated?
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每个点的特征影响是如何计算的？
- en: In the interpretation of these feature influence scores, it is often helpful
    to know exactly what goes into the calculation. Let's return for a moment to our
    two-dimensional pumpkin dataset to illustrate the steps that go into the calculation
    of feature influence. What we want to establish is how much of an effect a particular
    feature, *X*, say the weight of the pumpkin, has on the final outlier score. A
    natural way to try and quantify this effect is to imagine that we don't include
    this feature at all in our outlier calculation. *Figure 10.5* shows how this would
    look in practice for our pumpkin example. For each pumpkin data point, we project
    the value of the **Weight** feature to a fixed value 0 and see by how much each
    data point's unusualness has changed.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释这些特征影响分数时，了解计算中具体包含的内容通常很有帮助。让我们暂时回到我们的二维南瓜数据集，以说明计算特征影响所涉及的步骤。我们想要确定的是，特定特征，比如南瓜的重量*X*，对最终异常值分数的影响有多大。尝试量化这种影响的一种自然方式是想象我们根本不包括这个特征在我们的异常值计算中。*图10.5*展示了在我们的南瓜示例中这会是什么样子。对于每个南瓜数据点，我们将**权重**特征的值投影到一个固定的值0，并观察每个数据点的异常性变化了多少。
- en: 'We can see from *Figure 10.5* that for point A, removing or projecting the
    value of the weight to 0 will ultimately result in point A becoming an inlier.
    Hence, we can conclude that the `Weight` feature has a large influence on point
    A''s unusualness. On the other hand, if we look at point B on the right-hand side
    diagram in *Figure 10.5*, we can see that as a result of projecting its `Weight`
    feature to 0, the unusualness has not changed. Hence, we can conclude that the
    value of the `Weight` feature does not have much bearing on the unusualness of
    point B and thus its feature influence value will be low:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图10.5*中我们可以看出，对于点A，移除或投影权重值到0，最终会导致点A变成一个内点。因此，我们可以得出结论，`权重`特征对点A的不寻常性有重大影响。另一方面，如果我们观察*图10.5*右侧图中的点B，我们可以看到，由于将其`权重`特征投影到0，其不寻常性没有改变。因此，我们可以得出结论，`权重`特征值对点B的不寻常性影响不大，因此其特征影响值将较低：
- en: '![Figure 10.5 – Feature influence is calculated by asking how much a given
    data point''s unusualness will change if a given feature is projected to a fixed
    value or removed'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.5 – 通过询问如果将给定特征投影到固定值或移除，给定数据点的异常性将如何变化来计算特征影响'
- en: '](img/B17040_10_005.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_10_005.jpg](img/B17040_10_005.jpg)'
- en: Figure 10.5 – Feature influence is calculated by asking how much a given data
    point's unusualness will change if a given feature is projected to a fixed value
    or removed
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 – 通过询问如果将给定特征投影到固定值或移除，给定数据点的异常性将如何变化来计算特征影响
- en: How does outlier detection differ from anomaly detection?
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异常值检测与异常检测有何不同？
- en: 'While reading this chapter, you may have noticed that both outlier detection
    and anomaly detection are unsupervised learning methods that try to achieve a
    similar goal: to find unusual or outlying data points. A natural question would
    then be to ask, *how does anomaly detection differ from outlier detection?* In
    this section, we are going to outline and explain the main differences between
    the two. A summary of the main points is given in *Figure 10.6*, which we will
    see very soon.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本章时，你可能已经注意到异常检测和异常检测都是无监督学习方法，它们试图实现一个相似的目标：找到不寻常或异常的数据点。那么一个自然的问题就是询问，*异常检测与异常检测有何不同？*
    在本节中，我们将概述并解释这两种方法之间的主要区别。主要观点的总结见*图10.6*，我们很快就会看到。
- en: Probability model-based versus instance-based
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于概率模型与基于实例
- en: To make the distinction between anomaly detection and outlier detection clearer
    in our minds, let's first take a brief look at the available anomaly detection
    methods. The anomaly detection functionality allows us to detect unusual features
    in time series-based data. It does this by chunking up the time series into discrete
    time units called **buckets**, then applying a detector function such as mean
    or sum to the individual values in the bucket. Each bucket value is then used
    as an individual data point in a probability distribution that is continuously
    updated as the anomaly detector sees more and more data. The buckets that have
    a low probability of occurring under the probability distribution are flagged
    up as anomalies.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在我们心中更清晰地区分异常检测和异常检测，让我们首先简要地看一下可用的异常检测方法。异常检测功能使我们能够检测基于时间序列数据中的异常特征。它是通过将时间序列分割成离散的时间单元，称为**桶**，然后对桶中的单个值应用检测函数（如平均值或总和）来实现的。然后，每个桶的值被用作概率分布中的单个数据点，该概率分布随着异常检测器看到越来越多的数据而持续更新。在概率分布下发生概率低的桶被标记为异常。
- en: Instead of building a probabilistic model that tracks the evolution of our data
    across time, outlier detection uses an ensemble (or a group) of four techniques
    – two distance-based techniques and two density-based techniques, which were covered
    earlier in the chapter. The further away a data point is from the general mass
    of data in the dataset, the more likely it is to be an outlier. No probability
    model is constructed for the dataset.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 与构建一个追踪数据随时间演变的概率模型不同，异常检测使用一组四种技术——两种基于距离的技术和两种基于密度的技术，这些技术在前面的章节中已有介绍。数据点与数据集中一般数据质量越远，它成为异常值的可能性就越大。对于数据集没有构建概率模型。
- en: Scoring
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评分
- en: This major difference in the two techniques leads us, in turn, to a difference
    in scoring. In anomaly detection, the anomalousness of a bucket is determined
    by how unlikely it is to occur under the model that the anomaly detector has learned
    from the data. The lower the probability, the more anomalous the bucket is.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种技术之间的主要差异导致我们在评分上也有差异。在异常检测中，桶的异常性是通过异常检测器从数据中学到的模型下发生的不可能性来确定的。概率越低，桶的异常性就越大。
- en: In contrast, in outlier detection, we compute an outlier score, instead of a
    probability. The outlier score is a continuous measure ranging from 0 to 1 that
    captures a summary measure of how far the given data point is from the general
    mass of data in the whole dataset. As we saw earlier in the chapter, this measure
    is computed using four different techniques. The higher the outlier score, the
    more anomalous or unusual the data point is in the dataset.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，在异常检测中，我们计算异常分数，而不是概率。异常分数是一个从0到1的连续度量，它捕捉了给定数据点与整个数据集中一般数据质量距离的汇总度量。正如我们在本章前面所看到的，这个度量是通过四种不同的技术来计算的。异常分数越高，数据点在数据集中的异常或不寻常程度就越高。
- en: Data characteristics
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据特征
- en: In addition to scoring, another major difference between the two techniques
    is the type of data for which they are intended. Anomaly detection is suitable
    only for time series data, while outlier detection can be used on single or multidimensional
    datasets that may or may not contain a time-based component.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 除了评分之外，这两种技术之间的另一个主要区别是它们旨在处理的数据类型。异常检测仅适用于时间序列数据，而异常检测可以用于单维或多维数据集，这些数据集可能包含或不包含基于时间组件。
- en: Online versus batch
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在线与批量
- en: Finally, the last major difference between the two unsupervised learning techniques
    is how amenable they are for updates if new data is ingested into the index. Users
    familiar with anomaly detection will know that this technique is great for streaming
    data. As soon as a new bucket of data arrives in the cluster and is processed,
    the probability model can be updated to reflect the new data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这两种无监督学习技术之间最后一个主要区别是，当新数据被索引时，它们对更新的适应性。熟悉异常检测的用户会知道，这种技术非常适合流数据。一旦新数据桶到达集群并被处理，概率模型就可以更新以反映新数据。
- en: Outlier detection, on the other hand, is not amenable to online updates in the
    same fashion as anomaly detection. If a group of new data points is ingested into
    the source index, we have to rerun the outlier detection job on the source index
    once again. The reason for this is that outlier detection is an instance-based
    method that uses the spatial and density distribution of data points to determine
    which are normal and which are outliers. Any new points ingested into the source
    index could alter the spatial distribution of the data to such an extent that
    points previously classified as outliers would no longer be outliers and hence,
    a re-evaluation of new data requires the outlier score to be recomputed for the
    whole dataset in a batch add a lead-in sentence before the following table.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 与异常检测不同，离群点检测不能像异常检测那样进行在线更新。如果一组新数据点被摄入源索引，我们必须再次在源索引上重新运行离群点检测作业。原因在于，离群点检测是一种基于实例的方法，它使用数据点的空间和密度分布来确定哪些是正常的，哪些是离群点。任何被摄入源索引的新点都可能改变数据的空间分布，以至于之前被分类为离群点的点将不再是离群点，因此，对新数据的重新评估需要重新计算整个数据集的离群点分数。在以下表格之前添加一个引言句。
- en: '![Figure 10.6 – A summary of the main differences between anomaly detection
    and outlier detection ](img/B17040_10_006.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.6 – 异常检测与离群点检测的主要区别概述](img/B17040_10_006.jpg)'
- en: Figure 10.6 – A summary of the main differences between anomaly detection and
    outlier detection
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 – 异常检测与离群点检测的主要区别概述
- en: Applying outlier detection in practice
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实际应用离群点检测
- en: In this section, we will take a look at a practical example of outlier detection
    using a public dataset describing the physicochemical properties of wine. This
    dataset is available for download from the **University of California Irvine (UCI)**
    repository ([https://archive.ics.uci.edu/ml/datasets/wine+quality](https://archive.ics.uci.edu/ml/datasets/wine+quality)).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过一个使用描述葡萄酒物理化学性质的公共数据集的离群点检测的实际示例来探讨。此数据集可从加州大学欧文分校（UCI）的存储库下载（[https://archive.ics.uci.edu/ml/datasets/wine+quality](https://archive.ics.uci.edu/ml/datasets/wine+quality)）。
- en: 'The wine dataset is composed of two CSV files: one describing the physicochemical
    properties of white wine, the other those of red wine. In this walk-through, we
    will be focusing on the white wine dataset, but you are welcome to use the data
    for red wine as well since most of the steps described in this chapter should
    be applicable to both.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 葡萄酒数据集由两个 CSV 文件组成：一个描述白葡萄酒的物理化学性质，另一个描述红葡萄酒的性质。在本教程中，我们将重点关注白葡萄酒数据集，但您也可以使用红葡萄酒的数据，因为本章中描述的大多数步骤都适用于两者。
- en: 'First let''s import the dataset into our Elasticsearch cluster using the `winequality-white`:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们使用 `winequality-white` 将数据集导入我们的 Elasticsearch 集群：
- en: '![Figure 10.7 – The Data Visualizer tool can be found in the Machine Learning
    app in Kibana and is handy for importing small data files that can be used for
    experimentation'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.7 – 数据可视化工具可在 Kibana 的机器学习应用中找到，便于导入用于实验的小型数据文件]'
- en: '](img/B17040_10_007.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.7 – 数据可视化工具可在 Kibana 的机器学习应用中找到，便于导入用于实验的小型数据文件]'
- en: Figure 10.7 – The Data Visualizer tool can be found in the Machine Learning
    app in Kibana and is handy for importing small data files that can be used for
    experimentation
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7 – 数据可视化工具可在 Kibana 的机器学习应用中找到，便于导入用于实验的小型数据文件
- en: 'Taking a brief look at the data in the **Discover** tab will show us that each
    document represents a single wine and contains information about the alcohol content,
    the acidity, the pH, and the sugar content, among other chemical measurements,
    as well as a qualitative score for quality, which has been assigned by human tasters.
    The goal of our investigation will be to use outlier detection to detect which
    wines are outliers in terms of their chemical makeup and then see whether this
    correlates with the quality score they have received from human tasters. Our hypothesis
    is that wines that are unusual in terms of chemical makeup will also be outliers
    in terms of quality. Follow the steps outlined here to explore this hypothesis:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 简单查看 **发现** 选项卡中的数据将显示，每份文档代表一款单独的葡萄酒，并包含有关酒精含量、酸度、pH 值和糖含量等化学测量值的信息，以及由人类品酒师分配的定性评分。我们调查的目标将是使用异常检测来检测哪些葡萄酒在化学成分方面是异常的，然后看看这是否与人类品酒师给出的评分相关。我们的假设是，在化学成分方面不寻常的葡萄酒也将是质量评分方面的异常者。按照以下步骤进行操作以探索这个假设：
- en: Let's begin by creating an outlier detection job using the **Data Frame Analytics**
    wizard as seen in *Figure 10.8*:![Figure 10.8 – Use the Data Frame Analytics wizard
    to create an outlier detection job.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从使用如图 *图 10.8* 所示的 **数据帧分析** 向导创建异常检测作业开始：![图 10.8 – 使用数据帧分析向导创建异常检测作业。
- en: '](img/B17040_10_008.jpg)'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_10_008.jpg](img/B17040_10_008.jpg)'
- en: Figure 10.8 – Use the Data Frame Analytics wizard to create an outlier detection
    job.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.8 – 使用数据帧分析向导创建异常检测作业。
- en: Because we are interested in comparing wines that are outliers in chemical composition
    to the wines that are outliers in quality score, we will exclude the quality score
    from the outlier detection job as shown in *Figure 10.9*:![Figure 10.9 – Exclude
    the quality score from the outlier detection job by unticking the box next to
    the field name
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为我们对比较化学成分异常的葡萄酒和评分异常的葡萄酒感兴趣，所以我们将从异常检测作业中排除评分，如图 *图 10.9* 所示：![图 10.9 – 通过取消选中字段名称旁边的框来排除异常检测作业中的评分
- en: '](img/B17040_10_009.jpg)'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_10_009.jpg](img/B17040_10_009.jpg)'
- en: Figure 10.9 – Exclude the quality score from the outlier detection job by unticking
    the box next to the field name
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.9 – 通过取消选中字段名称旁边的框来排除异常检测作业中的评分
- en: We will use the default settings for the rest of the configuration options.
    Once the job has been completed, we can examine the results using the **Data Frame
    Analytics** results viewer:![Figure 10.10 – Use the Data frame analytics jobs
    management UI to see when the outlier detection job has been completed
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用默认设置配置其余的配置选项。一旦作业完成，我们可以使用 **数据帧分析** 结果查看器检查结果：![图 10.10 – 使用数据帧分析作业管理
    UI 查看异常检测作业何时完成
- en: '](img/B17040_10_010.jpg)'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_10_010.jpg](img/B17040_10_010.jpg)'
- en: Figure 10.10 – Use the Data frame analytics jobs management UI to see when the
    outlier detection job has been completed
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.10 – 使用数据帧分析作业管理 UI 查看异常检测作业何时完成
- en: A view of the `ml.outlier_score`. The outlier score is a floating value between
    0 and 1, which captures how outlying a given data point is with respect to the
    dataset. The closer a given point scores to 1, the more outlying it is and vice
    versa.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ml.outlier_score` 的视图。异常分数是一个介于 0 和 1 之间的浮点值，它捕捉了给定数据点相对于数据集的异常程度。一个给定点得分越接近
    1，它就越异常，反之亦然。'
- en: The rest of the columns in the table show us the values of a selection of other
    fields from the dataset. Each cell is shaded according to a gradient value from
    0 to 1, which captures the feature influence, in other words, how important the
    feature was in determining the unusualness of the data point. The darker shade
    of blue a given cell is, the more important that feature was for the unusualness
    of the point.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 表格中剩余的列显示了数据集中其他字段选择值的数值。每个单元格根据从 0 到 1 的渐变值着色，这捕捉了特征影响，换句话说，特征在确定数据点异常性方面的重要性。一个给定单元格的蓝色越深，该特征对点异常性的重要性就越大。
- en: 'For example, by looking at the values in the `ml.outlier_score` column in *Figure
    10.11*, we can see that the four most unusual wines in the dataset each scored
    an outlier score of 0.998:'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，通过查看 *图 10.11* 中的 `ml.outlier_score` 列的值，我们可以看到数据集中最不寻常的四款葡萄酒各自得分为 0.998：
- en: '![Figure 10.11 – The results UI for outlier detection displays a summary table
    that captures the outlier score of each data point as well as a selection of fields
    (in alphabetical order) color-coded with the feature influence score'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图10.11 – 异常检测的结果UI显示一个摘要表，捕获每个数据点的异常评分以及一些字段（按字母顺序排序）用特征影响评分着色'
- en: '](img/B17040_10_0011.jpg)'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_10_0011.jpg)'
- en: Figure 10.11 – The results UI for outlier detection displays a summary table
    that captures the outlier score of each data point as well as a selection of fields
    (in alphabetical order) color-coded with the feature influence score
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图10.11 – 异常检测的结果UI显示一个摘要表，捕获每个数据点的异常评分以及一些字段（按字母顺序排序）用特征影响评分着色
- en: Important note
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: An interesting question to ask at this point is *what is the threshold at which
    we declare a point as an outlier?* Do we say that all points that score above
    0.5 are outliers? Or do we set a more conservative threshold and say that only
    points above 0.9 are outliers? The process of setting a threshold for a continuous
    score to bin each data point as either normal or an outlier is known as binarization
    and is often determined by combining domain knowledge and goals that the user
    has. However, in the presence of a labeled dataset (for example, a dataset where
    each data point has already been labeled with the ground truth values of normal/outlier),
    it is possible to conduct a slightly more systematic process for choosing the
    threshold. We will return to this topic in the next section when we take a look
    at the Evaluate API.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个阶段提出的一个有趣的问题是*我们宣布一个点为异常的阈值是多少？*我们是说所有得分高于0.5的点都是异常点吗？或者我们设置一个更保守的阈值，只说得分高于0.9的点才是异常点？将连续得分设置为阈值的过程，将每个数据点分类为正常或异常，称为二值化，通常是通过结合领域知识和用户的目标来确定的。然而，在有标签的数据集（例如，每个数据点已经用正常/异常的地面真实值标记的数据集）的情况下，可以执行一个稍微更系统的过程来选择阈值。我们将在下一节中回到这个话题，当我们查看评估API时。
- en: Next, let's return to the results UI and take a look at the shading of the cells
    to see whether we can glean some interesting information about which factors make
    a certain wine unusual. We can toggle the hidden columns switch in the UI and
    add all of the remaining features so that we see a full picture of feature influence
    for the topmost outlying data points, as shown in *Figure 10.12*:![Figure 10.12
    – Feature influence displayed for all fields in the wine quality dataset
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们回到结果用户界面，看看单元格的阴影，看看我们是否能从中获取一些关于哪些因素使某种葡萄酒不寻常的有趣信息。我们可以在UI中切换隐藏列开关，添加所有剩余的特征，以便我们可以看到最顶层异常数据点的特征影响的全貌，如图*图10.12*所示：![图10.12
    – 在葡萄酒质量数据集的所有字段中显示的特征影响
- en: '](img/B17040_10_012.jpg)'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_10_012.jpg)'
- en: Figure 10.12 – Feature influence displayed for all fields in the wine quality
    dataset
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图10.12 – 在葡萄酒质量数据集的所有字段中显示的特征影响
- en: As we can see from the annotated areas, outlying wines are unusual for different
    reasons. For the first data point, the fields with the highest feature influence
    scores are chloride and citric acid content, while for the following three the
    most important features in determining unusualness seem to be density and the
    pH of the wine.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如我们从注释区域中可以看到的，异常葡萄酒因不同的原因而显得不寻常。对于第一个数据点，特征影响得分最高的字段是氯化物和柠檬酸含量，而对于接下来的三个点，似乎最重要的特征是密度和葡萄酒的pH值。
- en: 'Finally, we can return to the question we posed at the beginning of this section.
    *Does the unusualness of the wine correlate with the quantitative quality score
    assigned to it by human tasters?* To see whether we can glean any correlation
    with a quick glance, let''s add the quality score to the dataset alongside the
    outlier score (*Figure 10.13*):'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以回到本节开头提出的问题。*葡萄酒的不寻常性与人类品酒师分配给它的定量质量评分相关吗？*为了看看我们是否能快速地发现任何相关性，让我们将质量评分添加到数据集中，与异常评分并列（*图10.13*）：
- en: '![Figure 10.13 – The most unusual white wines sorted by descending outlier
    score along with the qualitative quality score assigned by human tasters'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.13 – 按异常评分降序排列的最不寻常的白葡萄酒，以及人类品酒师分配的定性质量评分'
- en: '](img/B17040_10_013.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_10_013.jpg)'
- en: Figure 10.13 – The most unusual white wines sorted by descending outlier score
    along with the qualitative quality score assigned by human tasters
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13 – 按异常评分降序排列的最不寻常的白葡萄酒，以及人类品酒师分配的定性质量评分
- en: As we can see, none of the top 10 most outlying white wines score in the best
    category (a quality score of 9). Instead, most of them score in the lower range
    of 3-6\. While this is not conclusive evidence, we have a hint that the most chemically
    unusual wines are usually not the best tasting!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，前10个最异常的白葡萄酒在最佳类别（质量分数为9）中的得分并不高。相反，它们大多数得分在3-6的较低范围内。虽然这并不是决定性的证据，但我们有理由相信，最化学异常的葡萄酒通常不是最好喝的！
- en: Evaluating outlier detection with the Evaluate API
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Evaluate API评估异常检测
- en: In the previous section, we touched on the fact it can be hard for a user to
    know how to set the threshold for outlier scores in order to group the data points
    in the dataset into normal and outlier categories. In this section, we will show
    how to approach this issue if you have a labeled dataset that contains, for each
    point, the ground truth values that record whether the point is an outlier. Before
    we dive into the practical demonstration, let's take a moment to understand some
    key performance metrics that are used in evaluating the performance of the outlier
    detection algorithm.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们提到了用户可能很难知道如何设置异常分数的阈值，以便将数据集中的数据点分组到正常和异常类别中。在本节中，我们将展示如果你有一个标记的数据集，其中每个点都包含记录该点是否为异常的地面真实值，如何处理这个问题。在我们深入实际演示之前，让我们花一点时间来了解一些在评估异常检测算法性能时使用的关键性能指标。
- en: 'One of the simplest ways we can measure the performance of the algorithm is
    to compute the number of data points that it correctly predicted as outliers;
    in other words, the number of **true positives** (**TPs**). In addition, we also
    want to know the number of **true negatives** (**TNs**): how many normal data
    points were correctly predicted as normal. By extension, we also want to record
    the number of times the outlier detection algorithm made one of two possible mistakes:
    either normal points were mislabeled as outliers (**false positives** (**FPs**))
    or vice versa (**false negatives** (**FNs**)).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以衡量算法性能的最简单方法之一是计算它正确预测为异常值的数据点的数量；换句话说，就是**真正例**（**TPs**）的数量。此外，我们还想了解**真正例**（**TNs**）的数量：有多少正常数据点被正确预测为正常。通过扩展，我们还想记录异常检测算法犯两种可能错误之一的次数：要么将正常点错误标记为异常（**假正例**（**FPs**）），要么相反（**假反例**（**FNs**））。
- en: 'These four measures can be conveniently summarized in a table known as a **confusion
    matrix**. An example confusion matrix is displayed in *Figure 10.14*:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个度量可以方便地总结在一个称为**混淆矩阵**的表中。一个示例混淆矩阵显示在*图10.14*中：
- en: '![Figure 10.14 – A confusion matrix displaying the true positive, true negative,
    false positive, and false negative rates'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.14 – 显示真正例、真正例、假正例和假反例率的混淆矩阵'
- en: '](img/B17040_10_014.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17040_10_014.jpg](img/B17040_10_014.jpg)'
- en: Figure 10.14 – A confusion matrix displaying the true positive, true negative,
    false positive, and false negative rates
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14 – 显示真正例、真正例、假正例和假反例率的混淆矩阵
- en: The following two measures, the **precision** and **recall**, can be built on
    top of the four metrics we just described.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下两个度量，**精确度**和**召回率**，可以建立在前面描述的四个度量之上。
- en: 'Precision is the proportion of true positives among all of the points that
    were predicted positive or outlying. Recall, on the other hand, is the proportion
    of true positives among all of the points that were actually positive. These quantities
    can be summarized as equations as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度是所有预测为正或异常的点中真正例的比例。另一方面，召回率是所有实际为正的点中真正例的比例。这些量可以用以下方程概括：
- en: '![](img/Formula_10_001.jpg)![](img/Formula_10_002.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![img/Formula_10_001.jpg](img/Formula_10_001.jpg)![img/Formula_10_002.jpg](img/Formula_10_002.jpg)'
- en: Based on the definitions given in the preceding paragraphs, it seems that in
    order to compute the number of true positives, true negatives, and so forth, we
    require each of the points in our destination index to be assigned a class label.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面段落中给出的定义，似乎为了计算真正例、真正例等数量，我们需要将我们的目标索引中的每个点分配一个类别标签。
- en: However, the result of the outlier detection job, as we described a few sections
    ago, is not a binary class label that assigns each point as an outlier or normal,
    but instead a numeric outlier score that ranges from 0 to 1.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，异常检测作业的结果，正如我们在几个段落之前所描述的，不是一个将每个点分配为异常或正常的二元类别标签，而是一个范围从0到1的数值异常分数。
- en: This presents a problem for us when it comes to computing our desired metrics
    because we have to make a decision and specify a cut-off point. Everything that
    scores higher than the cut-off point is assigned to the outlying class and everything
    that scores below the cut-off point is assigned to the normal class. We will call
    this the **binarization threshold**.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到计算我们所需的指标时，这给我们带来了一个问题，因为我们必须做出决定并指定一个截止点。所有得分高于截止点的都被分配到异常类别，而所有得分低于截止点的都被分配到正常类别。我们将此称为**二值化阈值**。
- en: It can be challenging to know exactly what value to set this threshold to, which
    brings us back to our original goal in this chapter – using the Evaluate API to
    understand the different performance metrics above at different thresholds so
    that we can make an informed choice.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 确定设置此阈值的准确值可能具有挑战性，这让我们回到了本章的原始目标——使用Evaluate API来理解不同阈值下的不同性能指标，以便我们可以做出明智的选择。
- en: 'Let''s now take a practical walk-through and see how we can apply this knowledge
    in practice:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来进行一次实际操作，看看我们如何将所学知识应用于实践：
- en: 'Let''s examine the public dataset that we are going to use for this section.
    The source of the original dataset is the UCI repository here : [https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29).
    To better fit the purpose of this exercise, we have modified the dataset slightly
    by creating an extra field called Outlier which records whether or not the given
    data point is an outlier or not. The modified dataset is in a file called `breast-cancer-wisconsin-outlier.csv`
    and is available for download in the book''s GitHub repository here [https://github.com/PacktPublishing/Machine-Learning-with-Elastic-Stack-Second-Edition/tree/main/Chapter%2010%20-%20Outlier%20Detection%20Analysis](https://github.com/PacktPublishing/Machine-Learning-with-Elastic-Stack-Second-Edition/tree/main/Chapter%2010%20-%20Outlier%20Detection%20Analysis).'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查我们将用于本节的公共数据集。原始数据集的来源是UCI仓库，请参阅此处：[https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)。为了更好地适应本练习的目的，我们略微修改了数据集，创建了一个名为Outlier的新字段，该字段记录了给定的数据点是否为异常值。修改后的数据集在一个名为`breast-cancer-wisconsin-outlier.csv`的文件中，可在本书的GitHub仓库中下载，请参阅此处
    [https://github.com/PacktPublishing/Machine-Learning-with-Elastic-Stack-Second-Edition/tree/main/Chapter%2010%20-%20Outlier%20Detection%20Analysis](https://github.com/PacktPublishing/Machine-Learning-with-Elastic-Stack-Second-Edition/tree/main/Chapter%2010%20-%20Outlier%20Detection%20Analysis)。
- en: Once you have downloaded this dataset, you can use the data import functionality
    in the Data Visualizer to import the dataset. For a refresher on the Data Visualizer
    and how to import data, please see the section Applying Outlier Detection in Practice
    .
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下载此数据集后，您可以使用数据可视化器中的数据导入功能导入数据集。有关数据可视化器和如何导入数据的复习，请参阅应用异常检测实践的章节。
- en: 'The dataset describes features measured from malignant and benign breast cancer
    tissue and includes a **Class** field, which can take either the value 2 (benign)
    or 4 (malignant). For the purpose of this section, we will treat the data points
    labeled as malignant as outliers:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该数据集描述了从恶性和良性乳腺癌组织中测量的特征，并包含一个**类别**字段，该字段可以取值为2（良性）或4（恶性）。在本节的目的上，我们将标记为恶性的数据点视为异常值：
- en: '![Figure 10.15 – Each data point in the dataset is labeled with a Class label.
    We have converted the Class label into a Boolean label and stored it in a new
    field called Outlier'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图10.15 – 数据集中的每个数据点都标记了类别标签。我们将类别标签转换为布尔标签，并存储在名为Outlier的新字段中。]'
- en: '](img/B17040_10_015.jpg)'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_10_015.jpg]'
- en: Figure 10.15 – Each data point in the dataset is labeled with a Class label.
    We have converted the Class label into a Boolean label and stored it in a new
    field called Outlier
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图10.15 – 数据集中的每个数据点都标记了类别标签。我们将类别标签转换为布尔标签，并存储在名为Outlier的新字段中。
- en: It is worth mentioning at this point that the Evaluate API ([https://www.elastic.co/guide/en/elasticsearch/reference/current/evaluate-dfanalytics.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/evaluate-dfanalytics.html)),
    which we will be using to understand how well the outlier detection algorithm
    performed against the ground truth labels, requires the ground truth label to
    be a Boolean 0 (for a normal data point) and 1 for an outlier data point. Therefore,
    we have slightly adjusted the original dataset by adding an extra field called
    **Outlier**, which converts the **Class** field into a suitable format for consumption
    by the Evaluate API. A sample document from the dataset is displayed in *Figure
    10.15*.
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这一点上值得提及的是，Evaluate API ([https://www.elastic.co/guide/en/elasticsearch/reference/current/evaluate-dfanalytics.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/evaluate-dfanalytics.html))，我们将使用它来了解异常检测算法与真实标签的匹配程度，要求真实标签为布尔值
    0（表示正常数据点）和 1（表示异常数据点）。因此，我们对原始数据集进行了轻微调整，增加了一个名为 **Outlier** 的额外字段，将 **Class**
    字段转换为 Evaluate API 可消费的合适格式。数据集的一个示例文档显示在 *图 10.15* 中。
- en: Let's use the **Data Frame Analytics** wizard to create an outlier detection
    job with this dataset. We will exclude the field that contains the **Class** label,
    the field that contains the ground truth label, as well as the sample code number,
    as shown in *Figure 10.16*:![Figure 10.16 – Excluding the Class, Outlier, and
    Sample_code_number fields from the outlier detection job
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用 **Data Frame Analytics** 向导使用此数据集创建一个异常检测作业。我们将排除包含 **Class** 标签的字段、包含真实标签的字段以及样本代码号，如图
    *图 10.16* 所示：![Figure 10.16 – 从异常检测作业中排除 Class、Outlier 和 Sample_code_number 字段
- en: '](img/B17040_10_016.jpg)'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17040_10_016.jpg]'
- en: Figure 10.16 – Excluding the Class, Outlier, and Sample_code_number fields from
    the outlier detection job
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.16 – 从异常检测作业中排除 Class、Outlier 和 Sample_code_number 字段
- en: Once the job has been completed, we can use the destination index that contains
    the results of the outlier detection job together with the Evaluate API to compute
    how well our outlier detection algorithm worked when compared to the ground truth
    labels.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦作业完成，我们可以使用包含异常检测作业结果的目标索引以及 Evaluate API 来计算我们的异常检测算法与真实标签相比的表现如何。
- en: We will interact with the Evaluate API through the `actual_field`. This is the
    field that contains the ground truth label for our data. In our case, this is
    the field called **Outlier**. Finally, we proceed to define the metrics that we
    would like the API to return for us as well as the thresholds at which these should
    be calculated.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将通过 `actual_field` 与 Evaluate API 进行交互。这是包含我们数据真实标签的字段。在我们的例子中，这是名为 **Outlier**
    的字段。最后，我们继续定义我们希望 API 为我们返回的指标以及这些指标应该计算的阈值。
- en: 'The parameters in the REST API call allow us to specify a wide variety of possible
    thresholds or cut-off points for which to compute the performance metrics. In
    the preceding example, we asked the Evaluate API to return the values of the performance
    metrics at three different binarization thresholds: 0.25, 0.5, and 0.75, but equally
    we could have picked another set of values.'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: REST API 调用中的参数允许我们指定各种可能的阈值或截止点，用于计算性能指标。在先前的例子中，我们要求 Evaluate API 在三个不同的二值化阈值（0.25、0.5
    和 0.75）处返回性能指标值，但同样，我们也可以选择另一组值。
- en: 'Next, we will examine the results returned by the Evaluate API. The response
    is shown here:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将检查 Evaluate API 返回的结果。响应如下：
- en: '[PRE0]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As we can see, the Evaluate API has returned a response where each of the metrics
    is computed three different times – once for each of the thresholds that were
    specified in the REST API call.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如我们所见，Evaluate API 返回了一个响应，其中每个指标都计算了三次——一次对应于 REST API 调用中指定的每个阈值。
- en: The different values of the confusion matrix indicate that the outlier detection
    algorithm has done quite poorly when it comes to this particular dataset. Not
    a single one of the thresholds yields any true positives, which means that we
    were not able to detect any outliers with the default settings. In the next section,
    we are going to see how **hyperparameter tuning** can help us achieve better results
    with outlier detection.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵的不同值表明，在特定数据集方面，异常检测算法表现相当差。没有任何一个阈值产生任何真阳性，这意味着我们无法使用默认设置检测到任何异常。在下一节中，我们将看到如何通过
    **超参数调整** 来帮助我们获得更好的异常检测结果。
- en: Hyperparameter tuning for outlier detection
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异常检测的超参数调整
- en: For the more advanced user, the **Data Frame Analytics** wizard offers an opportunity
    to configure and tune **hyperparameters** – various knobs and dials that fine-tune
    how the outlier detection algorithm works. The available hyperparameters are displayed
    in *Figure 10.17*. For example, we can direct the outlier detection job to use
    only a certain type of outlier detection method instead of the ensemble, to use
    a certain value for the number of nearest neighbors that are used in the computation
    in the ensemble, and to assume that a certain portion of the data is outlying.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更高级的用户，**数据帧分析**向导提供了一个配置和调整**超参数**的机会 – 这些是微调异常检测算法工作方式的各种旋钮和开关。可用的超参数在*图10.17*中显示。例如，我们可以指导异常检测作业仅使用某种类型的异常检测方法而不是集成方法，使用一定数量的最近邻值进行集成计算，并假设数据中有一部分是异常的。
- en: Please note that while it is good to play around with these settings to experiment
    and get a feel for how they affect the final results, if you want to customize
    any of these for a production usecase, you should carefully study the characteristics
    of your data and have an awareness of how these characteristics will interact
    with your chosen hyperparameter settings. More information on each of these hyperparameters
    is available in the documentation here [https://www.elastic.co/guide/en/elasticsearch/reference/current/put-dfanalytics.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/put-dfanalytics.html).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，虽然玩转这些设置以进行实验并了解它们如何影响最终结果是个好主意，但如果您想为生产用例定制这些设置，您应该仔细研究您数据的特点，并了解这些特点将如何与您选择的超参数设置相互作用。有关每个超参数的更多信息，请参阅此处文档[https://www.elastic.co/guide/en/elasticsearch/reference/current/put-dfanalytics.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/put-dfanalytics.html)。
- en: 'In our case, we know that the dataset contains about 30% malicious samples.
    Therefore, the number of outliers we expect is close to that as well. We can configure
    this as the value for **Outlier fraction** and rerun our job. This is shown in
    *Figure 10.17*:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们知道数据集包含大约30%的恶意样本。因此，我们预期的异常值数量也接近这个比例。我们可以将此配置为**异常比例**的值，并重新运行我们的作业。这如图*10.17*所示：
- en: '![Figure 10.17 – It is possible to fine-tune the behavior of the outlier detection
    job by tuning hyperparameters through the Data Frame Analytics wizard'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.17 – 通过数据帧分析向导调整超参数，可以微调异常检测作业的行为'
- en: '](img/B17040_10_017.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_10_017.jpg)'
- en: Figure 10.17 – It is possible to fine-tune the behavior of the outlier detection
    job by tuning hyperparameters through the Data Frame Analytics wizard
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.17 – 通过数据帧分析向导调整超参数，可以微调异常检测作业的行为
- en: 'Let''s recreate our outlier detection job with this new hyperparameter and
    compare the result to the one in *Figure 10.17*:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这个新的超参数重新创建我们的异常检测作业，并将结果与*图10.17*中的结果进行比较：
- en: Follow the steps outlined during the creation of our first outlier detection
    job in the *Evaluating outlier detection with the Evaluate API section*, but adjust
    the **Outlier fraction** setting under the **Hyperparameters** dialog as shown
    in *Figure 10.17*. Create and run the outlier detection job.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照在*评估异常检测与Evaluate API部分*中创建我们的第一个异常检测作业时概述的步骤进行操作，但在*超参数*对话框中调整**异常比例**设置，如图*10.17*所示。创建并运行异常检测作业。
- en: 'After the job has finished running, we can rerun the Evaluate API commands
    for this new results index. We have used the name `breast-cancer-wisconsin-outlier-fraction`
    as the name of the destination index that contains the results of the job with
    tuned hyperparameters. Hence our new Evaluate API call is as follows:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作业运行完成后，我们可以为这个新的结果索引重新运行Evaluate API命令。我们使用`breast-cancer-wisconsin-outlier-fraction`作为包含调整超参数作业结果的目标索引的名称。因此，我们新的Evaluate
    API调用如下：
- en: '[PRE1]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s see how much our confusion matrix has changed for the three different
    thresholds. The response we receive from the Evaluate API is displayed here:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看三个不同阈值下我们的混淆矩阵发生了多少变化。我们从Evaluate API收到的响应在这里显示：
- en: '[PRE2]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As we can see from the values of the confusion matrix, we are doing slightly
    better in terms of the detection of the true positives, the true outliers, but
    slightly worse in terms of detecting false negatives.
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从混淆矩阵的值中我们可以看出，我们在检测真正阳性、真正异常值方面做得稍微好一些，但在检测假阴性方面稍微差一些。
- en: Comparing the evaluation metrics from the preceding outlier detection job and
    the outlier detection job we created in the *Evaluating outlier detection with
    the Evaluate API* section illustrates that hyperparameter choice can have a significant
    bearing on the result of the outlier detection job. How should you, then, proceed
    in choosing sensible hyperparameters?
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 将先前异常值检测作业的评估指标与我们创建的“使用Evaluate API评估异常值检测”部分中的异常值检测作业进行比较，可以说明超参数选择对异常值检测作业的结果有重大影响。那么，在选择合理的超参数时，你应该如何进行？
- en: There are many subtleties and advanced topics that you can dive into when choosing
    hyperparameters, but a good guideline is to remember the iterative nature of the
    process. It is good to start with a labeled dataset and try the quality of results
    using the default settings (in other words, without adjusting anything under the
    **Hyperparameters** dialog in the Data Frame Analytics wizards).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择超参数时，有许多细微之处和高级主题可以深入研究，但一个好的指导原则是记住过程的迭代性质。从标记数据集开始并使用默认设置（换句话说，在数据帧分析向导的“超参数”对话框中不进行任何调整）尝试结果质量是一个好主意。
- en: The defaults have usually been sensibly chosen and tested on a variety of datasets.
    If the quality of results is not satisfactory, you can start coming up with a
    plan to adjust and fine-tune the various hyperparameter settings. A good first
    step is to fix known issues and examine how this affects the quality of the results.
    For example, we knew from prior experience that the breast cancer dataset contains
    outliers around 30% or 0.3 of the data, which allowed us to adjust this setting
    and achieve a slightly better true positive rate.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 默认值通常已经合理选择并测试过多种数据集。如果结果质量不满意，你可以开始制定一个计划来调整和微调各种超参数设置。一个好的第一步是修复已知问题并检查这如何影响结果质量。例如，我们根据以往的经验知道，乳腺癌数据集包含大约30%或0.3的异常值，这使我们能够调整此设置并实现略微更好的真正阳性率。
- en: Summary
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'To conclude the chapter, let''s remind ourselves of the main features of the
    second unsupervised learning feature in the Elastic Stack: outlier detection.
    Outlier detection can be used to detect unusual data points in single or multidimensional
    datasets.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 为了结束本章，让我们回顾一下Elastic Stack中第二个无监督学习特征的要点：异常值检测。异常值检测可以用来检测单维或多维数据集中的异常数据点。
- en: 'The algorithm is based on an ensemble of four separate measures: two distance-based
    measures based on kth-nearest neighbors and two density-based measures. The combination
    of these measures captures how far a given data point is from its neighbors and
    from the general mass of data in the dataset. This unusualness is captured in
    a numerical outlier score that ranges from 0 to 1\. The closer a given data point
    scores to 1, the more unusual it is in the dataset.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法基于四个独立的度量：两个基于k近邻的距离度量，以及两个基于密度的度量。这些度量的组合捕捉了给定数据点与其邻居以及数据集总体数据质量之间的距离。这种异常性通过一个介于0到1之间的数值异常值分数来捕捉。给定数据点的分数越接近1，它在数据集中的异常性就越大。
- en: In addition to the outlier score, for each feature or field of a point, we compute
    a quantity known as the feature influence. The higher the feature influence for
    a given field, the more that field is responsible for a given point being unusual.
    These feature influence scores can be used to understand why a particular point
    received a particular outlier score.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 除了异常值分数之外，对于每个点的每个特征或字段，我们计算一个称为特征影响力的量。对于给定字段的特征影响力越高，该字段对给定点异常性的贡献就越大。这些特征影响力分数可以用来理解为什么某个特定点得到了特定的异常值分数。
- en: In contrast with the other unsupervised learning functionality in the Elastic
    Stack, anomaly detection, outlier detection does not require the data to have
    a time component or be a time series of any kind. Moreover, outlier detection,
    in contrast with anomaly detection, does not learn a probabilistic model to understand
    which data points have a low probability of occurring. Instead, it uses distance
    and density-based measures to compute unusualness. Because of this difference
    in methodologies, it is not possible for outlier detection to function in an online
    manner, updating its computations of outlier-ness on the fly as new data is added
    to the source index. Instead, if we wish to predict the unusualness of new points
    as they are added to the index, we have to rerun the outlier detection calculation
    for the whole source index in batch mode.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 与Elastic Stack中其他无监督学习功能（异常检测）相比，离群值检测不需要数据具有时间组件或任何类型的时间序列。此外，与异常检测不同，离群值检测不是通过学习概率模型来理解哪些数据点发生的概率较低。相反，它使用基于距离和密度的度量来计算异常性。由于这种方法上的差异，离群值检测无法以在线方式运行，无法在将新数据添加到源索引时即时更新其离群值计算。相反，如果我们希望在将新点添加到索引时预测其异常性，我们必须以批量模式重新运行整个源索引的离群值检测计算。
- en: In the next chapter, we will leave unsupervised learning methods behind us and
    dive into the exciting world of supervised learning, starting with classification.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将放下无监督学习方法，深入探索令人兴奋的监督学习世界，从分类开始。
