- en: Chapter 5. Real-Time Stream Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。实时流机器学习
- en: In [Chapter 2](ch02.html "Chapter 2. Practical Approach to Real-World Supervised
    Learning"), *Practical Approach to Real-World Supervised Learning*, [Chapter 3](ch03.html
    "Chapter 3. Unsupervised Machine Learning Techniques"), *Unsupervised Machine
    Learning Techniques*, and [Chapter 4](ch04.html "Chapter 4. Semi-Supervised and
    Active Learning"), *Semi-Supervised and Active Learning*, we discussed various
    techniques of classification, clustering, outlier detection, semi-supervised,
    and active learning. The form of learning done from existing or historic data
    is traditionally known as batch learning.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](ch02.html "第2章。现实世界监督学习的实用方法")《现实世界监督学习的实用方法》、[第3章](ch03.html "第3章。无监督机器学习技术")《无监督机器学习技术》和[第4章](ch04.html
    "第4章。半监督和主动学习")《半监督和主动学习》中，我们讨论了分类、聚类、异常检测、半监督和主动学习的各种技术。从现有或历史数据中进行的学习的形式传统上被称为批量学习。
- en: 'All of these algorithms or techniques assume three things, namely:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些算法或技术都假设三个条件，即：
- en: Finite training data is available to build different models.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用有限训练数据来构建不同的模型。
- en: The learned model will be static; that is, patterns won't change.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习到的模型将是静态的；也就是说，模式不会改变。
- en: The data distribution also will remain the same.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分布也将保持不变。
- en: In many real-world data scenarios, there is either no training data available
    a priori or the data is dynamic in nature; that is, changes continuously with
    respect to time. Many real-world applications may also have data which has a transient
    nature to it and comes in high velocity or volume such as IoT sensor information,
    network monitoring, and Twitter feeds. The requirement here is to learn from the
    instance immediately and then update the learning.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多现实世界的数据场景中，要么事先没有可用的训练数据，要么数据本质上是动态的；也就是说，随着时间的推移而持续变化。许多现实世界应用也可能有具有短暂性质的数据，以高速或大量出现，例如物联网传感器信息、网络监控和Twitter动态。这里的要求是立即从实例中学习，然后更新学习。
- en: The nature of dynamic data and potentially changing distribution renders existing
    batch-based algorithms and techniques generally unsuitable for such tasks. This
    gave rise to adaptable or updatable or incremental learning algorithms in machine
    learning. These techniques can be applied to continuously learn from the data
    streams. In many cases, the disadvantage of learning from Big Data due to size
    and the need to fit the entire data into memory can also be overcome by converting
    the Big Data learning problem into an incremental learning problem and inspecting
    one example at a time.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 动态数据的性质和可能变化的分布使得现有的基于批量的算法和技术通常不适用于此类任务。这导致了机器学习中的自适应或可更新或增量学习算法的出现。这些技术可以应用于从数据流中持续学习。在许多情况下，由于大数据的规模和需要将整个数据拟合到内存中的需要，学习大数据的缺点也可以通过将大数据学习问题转化为增量学习问题并逐个检查示例来克服。
- en: In this chapter, we will discuss the assumptions and discuss different techniques
    in supervised and unsupervised learning that facilitate real-time or stream machine
    learning. We will use the open source library **Massive Online Analysis** (**MOA**)
    for performing a real-world case study.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论假设，并讨论监督学习和无监督学习中的不同技术，这些技术有助于实时或流机器学习。我们将使用开源库**大规模在线分析**（**MOA**）来进行现实世界案例研究。
- en: 'The major sections of this chapter are:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要部分包括：
- en: Assumptions and mathematical notation.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设和数学符号。
- en: Basic stream processing and computational techniques. A discussion of stream
    computations, sliding windows including the ADWIN algorithm, and sampling.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本流处理和计算技术。讨论流计算、滑动窗口包括ADWIN算法和采样。
- en: 'Concept drift and drift detection: Introduces learning evolving systems and
    data management, detection methods, and implicit and explicit adaptation.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概念漂移和漂移检测：介绍了学习演化的系统、数据管理、检测方法以及隐式和显式适应。
- en: 'Incremental supervised learning: A discussion of learning from labeled stream
    data, modeling techniques including linear, non-linear, and ensemble algorithms.
    This is followed by validation, evaluation, and model comparison methods.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增量监督学习：讨论从标记流数据中学习，包括线性、非线性以及集成算法的建模技术。随后是验证、评估和模型比较方法。
- en: 'Incremental unsupervised learning: Clustering techniques similar to those discussed
    in [Chapter 3](ch03.html "Chapter 3. Unsupervised Machine Learning Techniques"),
    *Unsupervised Machine Learning Techniques*, including validation and evaluation
    techniques.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增量无监督学习：与[第3章](ch03.html "第3章。无监督机器学习技术")中讨论的聚类技术类似，包括验证和评估技术。
- en: 'Unsupervised learning using outlier detection: Partition-based and distance-based,
    and the validation and evaluation techniques used.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用异常检测进行无监督学习：基于分区和基于距离的方法，以及所使用的验证和评估技术。
- en: 'Case study for stream-based learning: Introduces the MOA framework, presents
    the business problem, feature analysis, mapping to machine learning blueprint;
    describes the experiments, and concludes with the presentation and analysis of
    the results.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于流的案例研究：介绍了MOA框架，提出了业务问题，进行了特征分析，将其映射到机器学习蓝图；描述了实验，并以结果展示和分析结束。
- en: Assumptions and mathematical notations
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假设和数学符号
- en: 'There are some key assumptions made by many stream machine learning techniques
    and we will state them explicitly here:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 许多流机器学习技术都做出了某些关键假设，我们将在下面明确陈述：
- en: The number of features in the data is fixed.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中的特征数量是固定的。
- en: Data has small to medium dimensions, or number of features, typically in the
    hundreds.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据具有小到中等维度，或特征数量，通常在数百个左右。
- en: The number of examples or training data can be infinite or very large, typically
    in the millions or billions.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本数量或训练数据可以是无限的或非常庞大，通常在数百万或数十亿。
- en: The number of class labels in supervised learning or clusters are small and
    finite, typically less than 10.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在监督学习或聚类中，类标签的数量很小且有限，通常少于10。
- en: Normally, there is an upper bound on memory; that is, we cannot fit all the
    data in memory, so learning from data must take this into account, especially
    lazy learners such as K-Nearest-Neighbors.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常，内存有一个上限；也就是说，我们无法将所有数据放入内存，因此从数据中学习必须考虑这一点，特别是像K-Nearest-Neighbors这样的懒惰学习器。
- en: Normally, there is an upper bound on the time taken to process the event or
    the data, typically a few milliseconds.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常，处理事件或数据所需的时间有一个上限，通常是几毫秒。
- en: The patterns or the distributions in the data can be evolving over time.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中的模式或分布可能随时间演变。
- en: Learning algorithms must converge to a solution in finite time.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习算法必须在有限时间内收敛到解决方案。
- en: 'Let *D*[t] = {**x**[i], y[i] : *y = f(x)*} be the given data available at time
    *t* ∈ {1, 2, … *i*}.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '设 *D*[t] = {**x**[i], y[i] : *y = f(x)*} 为在时间 *t* ∈ {1, 2, … *i*} 可用的给定数据。'
- en: An incremental learning algorithm produces sequences of models/hypotheses {..,
    *G*[j-1], G[j], *G*[j+1]..} for the sequence of data {.., *D*[j-1], *D*[j], *D*[j+1]..}
    and model/hypothesis *G*[i] depends only on the previous hypothesis *G*[i-1] and
    current data *D*[i].
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 增量学习算法为数据序列 {.., *D*[j-1], *D*[j], *D*[j+1]..} 生成一系列模型/假设 {.., *G*[j-1], G[j],
    *G*[j+1]..}，其中模型/假设 *G*[i] 仅依赖于前一个假设 *G*[i-1] 和当前数据 *D*[i]。
- en: Basic stream processing and computational techniques
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本流处理和计算技术
- en: 'We will now describe some basic computations that can be performed on the stream
    of data. If we must run summary operations such as aggregations or histograms
    with limits on memory and speed, we can be sure that some kind of trade-off will
    be needed. Two well-known types of approximations in these situations are:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将描述一些可以在数据流上执行的基本计算。如果我们必须在内存和速度有限的情况下运行汇总操作，如聚合或直方图，我们可以确信需要某种形式的权衡。在这些情况下，两种众所周知的近似类型是：
- en: '*ϵ* Approximation: The computation is close to the exact value within the fraction
    *ϵ* of error.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ϵ* 近似：计算结果在误差的 *ϵ* 分数内接近精确值。'
- en: '(*ϵ**, δ*) Approximation: The computation is close to the exact value within
    1 ± *ϵ* with probability within 1 – *δ*.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (*ϵ**, δ*) 近似：计算结果在1 ± *ϵ* 范围内，以1 – *δ* 的概率接近精确值。
- en: Stream computations
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流计算
- en: 'We will illustrate some basic computations and aggregations to highlight the
    difference between batch and stream-based calculations when we must compute basic
    operations with constraints on memory and yet consider the entire data:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们必须在内存和整个数据上考虑基本操作时，我们将展示一些基本的计算和聚合，以突出批处理和基于流的计算之间的差异：
- en: '**Frequency count or point queries**: The generic technique of Count-Min Sketch
    has been successfully applied to perform various summarizations on the data streams.
    The primary technique is creating a window of size *w* x *d*. Then, given a desired
    probability (δ) and admissible error (*ϵ*), the size of data in memory can be
    created using *w* = 2/ *ϵ* and ![Stream computations](img/B05137_05_019.jpg).
    Associated with each row is a hash function: *h*(.). This uniformly transforms
    a value *x* to a value in the interval [1, 2 … *w*]. This method of lookup and
    updates can be used for performing point queries of values or dot products or
    frequency counts.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**频率计数或点查询**：Count-Min Sketch的通用技术已被成功应用于对数据流进行各种汇总。主要技术是创建一个大小为 *w* x *d*
    的窗口。然后，给定一个期望的概率（δ）和可接受的误差（*ϵ*），可以使用 *w* = 2/ *ϵ* 和 ![流计算](img/B05137_05_019.jpg)
    来创建内存中的数据大小。与每一行相关联的是一个哈希函数：*h*(.). 这个函数将值 *x* 均匀地转换到区间 [1, 2 … *w*] 内。这种方法可以用于执行值或点积或频率计数的点查询。'
- en: '**Distinct count**: The generic technique of Hash-Sketch can be used to perform
    "distinct values" queries or counts. Given the domain of incoming stream values
    x ∈ [0,1,2….N-1], the hash function *h*(*x*) maps the values uniformly across
    [0,1,….2L-1], where *L=O(log N)*.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不同计数**：Hash-Sketch的通用技术可用于执行“不同值”查询或计数。给定进入流值的域 x ∈ [0,1,2….N-1]，哈希函数 *h*(*x*)将值均匀映射到
    [0,1,….2L-1]，其中 *L=O(log N)*。'
- en: '**Mean**: Computing the mean without the need for storing all the values is
    very useful and is normally employed using a recursive method where only the number
    of observations *(n)* and sum of values seen so far (∑*x*[n]) is needed:![Stream
    computations](img/B05137_05_029.jpg)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均值**：在不存储所有值的情况下计算均值非常有用，通常使用递归方法实现，只需要观察数（*n*）和迄今为止看到的值的总和（∑*x*[n]）：![流计算](img/B05137_05_029.jpg)'
- en: '**Standard deviation**: Like the mean, standard deviation can be computed using
    the memoryless option with only the number of observations (*n*), sum of values
    seen so far (∑*x*[n]), and sum of squares of the values (∑*x*[n]²):![Stream computations](img/B05137_05_031.jpg)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准差**：与均值一样，标准差可以使用无记忆选项仅使用观察数（*n*）、迄今为止看到的值的总和（∑*x*[n]）和值的平方总和（∑*x*[n]²）来计算：![流计算](img/B05137_05_031.jpg)'
- en: '**Correlation coefficient**: Given a stream of two different values, many algorithms
    need to compute the correlation coefficient between the two which can be done
    by maintaining the running sum of each stream (∑*x*[n] and ∑*y*[n]), the sum of
    squared values (∑*x*[n]² and ∑*y*[n]²), and the cross-product (∑*x*[n]x *y*[n]).
    The correlation is given by:![Stream computations](img/B05137_05_036.jpg)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相关系数**：给定两个不同值的流，许多算法需要计算这两个值之间的相关系数，可以通过维护每个流的运行总和（∑*x*[n] 和 ∑*y*[n]）、值的平方总和（∑*x*[n]²
    和 ∑*y*[n]²）和交叉乘积（∑*x*[n]x *y*[n]）来实现。相关系数由以下公式给出：![流计算](img/B05137_05_036.jpg)'
- en: Sliding windows
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 滑动窗口
- en: Often, you don't need the entire data for computing statistics or summarizations
    but only the "recent past". In such cases, sliding window techniques are used
    to calculate summary statistics by keeping the window size either fixed or adaptable
    and moving it over the recent past.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在计算统计数据或汇总时，你不需要整个数据，只需要“最近过去”的数据。在这种情况下，使用滑动窗口技术通过保持窗口大小固定或可调整并移动它来计算汇总统计。
- en: '**ADaptable sliding WINdow** (**ADWIN**) is one well-known technique used to
    detect change as well as estimating values needed in the computation. The idea
    behind ADWIN is to keep a variable-length window of last seen values with the
    characteristic that the window has a maximum length statistically consistent with
    the fact that there has been no change in the average value within the window.
    In other words, the older values are dropped if and only if a new incoming value
    would change the average. This has the two-fold advantage of recording change
    and maintaining the dynamic value, such as aggregate, over the recent streams.
    The determination of the subjective notion "large enough" for dropping items can
    be determined using the well-known Hoeffding bound as:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**ADaptable sliding WINdow**（**ADWIN**）是一种用于检测变化以及估计计算所需值的知名技术。ADWIN背后的想法是保持一个具有可变长度的最近看到值的窗口，其特征是窗口的最大长度与窗口内平均值的平均值没有变化这一事实在统计上是一致的。换句话说，如果新的进入值会改变平均值，则仅当删除旧值时，才会删除旧值。这有两个优点：记录变化并维护最近流中的动态值，如聚合值。确定删除项的主观概念“足够大”可以使用已知的Hoeffding界来确定：'
- en: '![Sliding windows](img/B05137_05_037.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![滑动窗口](img/B05137_05_037.jpg)'
- en: Here ![Sliding windows](img/B05137_05_038.jpg) is the harmonic mean between
    two windows *W*[0] and *W*[1] of size |*W*[0]| and |*W*[1]| respectively, with
    *W*[1] containing the more recent elements. Further, let ![Sliding windows](img/B05137_05_043.jpg)
    and ![Sliding windows](img/B05137_05_044.jpg) be the respective calculated averages.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 ![滑动窗口](img/B05137_05_038.jpg) 是两个窗口 *W*[0] 和 *W*[1] 之间的调和平均值，其中 *W*[0] 和
    *W*[1] 的尺寸分别为 |*W*[0]| 和 |*W*[1]|，*W*[1] 包含更近期的元素。此外，![滑动窗口](img/B05137_05_043.jpg)
    和 ![滑动窗口](img/B05137_05_044.jpg) 分别是相应的计算平均值。
- en: 'The algorithm can be generalized as:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法可以概括为：
- en: 'ADWIN (*x: inputstream, δ: confidence*)'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'ADWIN (*x: 输入流, δ: 置信度*)'
- en: init (*W*) //Initialize Window *W*
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: init (*W*) //初始化窗口 *W*
- en: while (*x*){
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: while (*x*){
- en: W ← W ∪ {*x*[t]} //add new instance *x*[t] to the head of Window *W*
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: W ← W ∪ {*x*[t]} //将新实例 *x*[t] 添加到窗口 *W* 的头部
- en: repeat W ← W – *x*old //drop elements from tail of the window
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: repeat W ← W – *x*old //从窗口尾部删除元素
- en: '![Sliding windows](img/B05137_05_056.jpg) < ![Sliding windows](img/B05137_05_057.jpg)
    holds for every split of *W*'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![滑动窗口](img/B05137_05_056.jpg) < ![滑动窗口](img/B05137_05_057.jpg) 对 *W* 的每个分割都成立'
- en: output ![Sliding windows](img/B05137_05_058.jpg)
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: output ![滑动窗口](img/B05137_05_058.jpg)
- en: '}'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '}'
- en: ADWIN has also shown that it provides theoretical bounds on false positives
    and false negatives, which makes it a very promising technique to use.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ADWIN 还表明，它提供了对假阳性和假阴性的理论界限，这使得它成为一种非常有前途的技术。
- en: Sampling
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 采样
- en: In many stream-based algorithms, there is a need to reduce the data or select
    a subset of data for analysis. The normal methodology of sampling on the whole
    data must be augmented for stream-based data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多基于流的算法中，需要减少数据或选择数据的一个子集进行分析。对于基于流的算法，必须增强对整个数据集的采样方法。
- en: The key concerns in sampling that must be addressed are how unbiased the samples
    are and how representative they are of the population from which streams are being
    generated. In a non-streaming environment, this depends completely on the sample
    size and the sampling method. Uniform random sampling ([Chapter 2](ch02.html "Chapter 2. Practical
    Approach to Real-World Supervised Learning"), *Practical Approach to Real-World
    Supervised Learning*) is one of the most well-known techniques employed to reduce
    the data in the batch data world. The reservoir sampling technique is considered
    to be a very effective way of reducing the data given the memory constraints.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在采样中必须解决的关键问题是样本的无偏性和它们如何代表生成流的总体。在非流式环境中，这完全取决于样本大小和采样方法。均匀随机采样（[第2章](ch02.html
    "第2章. 实际应用中的监督学习"), *实际应用中的监督学习*）是在批量数据世界中用于减少数据的最知名技术之一。考虑到内存限制，水库采样技术被认为是一种非常有效的减少数据的方法。
- en: 'The basic idea of reservoir sampling is to keep a reservoir or sample of fixed
    size, say *k*, and every element that enters the stream has a probability *k/n*
    of replacing an older element in the reservoir. The detailed algorithm is shown
    here:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 水库采样的基本思想是保持一个固定大小的水库或样本，比如说 *k*，并且每个进入流量的元素都有 *k/n* 的概率替换水库中的较老元素。详细的算法如下所示：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: There are extensions to these such as the Min-wise Sampling and Load Shedding
    that overcome some issues associated with the base method.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法有扩展，如 Min-wise 采样和负载卸载，可以克服与基本方法相关的一些问题。
- en: Concept drift and drift detection
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概念漂移和漂移检测
- en: 'As discussed in the introduction of the chapter, the dynamic nature of infinite
    streams stands in direct opposition to the basic principles of stationary learning;
    that is, that the distribution of the data or patterns remain constant. Although
    there can be changes that are *swift* or *abrupt*, the discussion here is around
    slow, gradual changes. These slow, gradual changes are fairly hard to detect and
    separating the changes from the noise becomes tougher still:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章引言中所述，无限流量的动态性质与静态学习的基本原则直接对立；也就是说，数据的分布或模式保持不变。尽管可能会有快速或突然的变化，但这里的讨论是关于缓慢、渐进的变化。这些缓慢、渐进的变化相当难以检测，将变化与噪声分离变得更加困难：
- en: '![Concept drift and drift detection](img/B05137_05_071.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![概念漂移和漂移检测](img/B05137_05_071.jpg)'
- en: Figure 1 Concept drift illustrated by the gradual change in color from yellow
    to blue in the bottom panel. Sampled data reflects underlying change in data distribution,
    which must be detected and a new model learned.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图1 通过底部面板中颜色从黄色渐变到蓝色的方式展示了概念漂移。采样数据反映了数据分布的潜在变化，这必须被检测到，并学习一个新的模型。
- en: 'There have been several techniques described in various studies in the last
    two decades that can be categorized as shown in the following figure:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去二十年里，各种研究中描述了几种技术，可以按照以下图示进行分类：
- en: '![Concept drift and drift detection](img/B05137_05_072.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![概念漂移和漂移检测](img/B05137_05_072.jpg)'
- en: Figure 2 Categories of drift detection techniques
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图2 漂移检测技术分类
- en: Data management
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据管理
- en: The main idea is to manage a model in memory that is consistent with the dynamic
    nature of the data.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 主要思想是在内存中管理一个与数据的动态特性一致的模型。
- en: Partial memory
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部分内存
- en: 'These techniques use the most recently used data in a memory buffer to learn
    or derive summary information. The key question as discussed previously is: what
    is the right window size to be effective in detecting the change and learning
    effectively? In Fixed Window Size based techniques, we use the idea of a queue
    where a new instance with a recent timestamp comes in and the one with the oldest
    is evicted. The window thus contains all the recent enough examples and the size
    is generally chosen based on physical availability of memory and size of data
    elements in the queue. In Adaptive Window Size, the queue is used in conjunction
    with a detection algorithm. When the detection algorithm indicates signs of drifts
    based on performance evaluation, the window size can be reduced to effectively
    remove old examples which no longer help the model.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术使用内存缓冲区中最最近使用的数据来学习或推导摘要信息。正如之前讨论的那样，关键问题是：检测变化和学习有效性的正确窗口大小是什么？在基于固定窗口大小的技术中，我们使用队列的概念，其中带有最近时间戳的新实例进入，而最旧的实例被移除。因此，窗口包含所有足够近的示例，其大小通常基于内存的物理可用性和队列中数据元素的大小。在自适应窗口大小中，队列与检测算法结合使用。当检测算法根据性能评估表明存在漂移迹象时，窗口大小可以减小，以有效地移除不再帮助模型的旧示例。
- en: Full memory
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全内存
- en: 'The idea is to store sufficient statistics over all the examples or data seen.
    One way to do this is to put weights on the data and weights decay over time.
    Exponential weighting using the rate factor given by λ can be very effective:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 思想是在所有示例或数据上存储足够的统计信息。一种方法是对数据进行加权，权重随时间衰减。使用由 λ 给出的速率因子的指数加权可以非常有效：
- en: w[λ] (*x*) = *exp*(– λ * i)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: w[λ] (*x*) = *exp*(– λ * i)
- en: Detection methods
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检测方法
- en: 'Given the probability *P(X)* that the given data is observed, the probability
    of patterns/class *P(C)*, and the probability of data given class *P(X|C)*—which
    is the model—the detection method can be divided into two categories, at a high
    level:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 给定观察到的给定数据的概率 *P(X)*，模式/类 *P(C)* 的概率，以及给定类的数据概率 *P(X|C)*——即模型——检测方法可以大致分为两类：
- en: Monitoring evolution or performance of the model, classifier, or *P(C|X)*
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控模型、分类器或 *P(C|X)* 的演变或性能
- en: Monitoring distributions from the environment or observing *P(X)*, *P(C)*, and
    *P(X|C)*
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控环境中的分布或观察 *P(X)*，*P(C)* 和 *P(X|C)*
- en: Monitoring model evolution
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 监控模型演变
- en: Although this method is based on the assumption that all the learning of models
    is stationary and data is coming from **independent, identical distributions**
    (**i.i.d.**), which doesn't hold true in many applications, it has nevertheless
    been shown to be effective. Some of the well-known techniques are described next.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种方法基于所有模型的 学习都是平稳的，数据来自 **独立、同分布**（**i.i.d.**）的假设，这在许多应用中并不成立，但它已被证明是有效的。以下将描述一些知名技术。
- en: Widmer and Kubat
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 维德默和库巴特
- en: This is one of the earliest methods which observed the error rates or misclassification
    rates and the changes to the model such as tree structures due to new branches,
    for instance. Using these and known thresholds, the learning window size is increased
    or decreased.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最早的方法之一，它观察了错误率或误分类率以及由于新分支等原因对模型（如树结构）的变化。使用这些和已知的阈值，学习窗口的大小会增加或减少。
- en: Drift Detection Method or DDM
  id: totrans-83
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 漂移检测方法或DDM
- en: 'This method assumes that the parameter being observed, such as the classifier
    labeling things correctly or incorrectly, is a binary random variable which follows
    a binomial distribution. It assumes probability of misclassification at probability
    pi with standard deviation of ![Drift Detection Method or DDM](img/B05137_05_083.jpg)
    where the values are computed at the *i*^(th) point in the sequence. The method
    then uses two levels:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法假设正在观察的参数，例如分类器正确或错误地标记事物，是一个二元随机变量，遵循二项分布。它假设在概率 pi 处的误分类概率，标准差为 ![漂移检测方法或DDM](img/B05137_05_083.jpg)，其中值在序列的第
    *i*^(th) 点计算。然后，该方法使用两个水平：
- en: 'Warning level: When *p*[i] + *s*[i] ≥ *p*[min]+ 2 * *s*[min]'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 警告水平：当 *p*[i] + *s*[i] ≥ *p*[min]+ 2 * *s*[min]
- en: 'Detection level: When *p*[i] + *s*[i] ≥ *p*[min]+ 3 * *s*[min]'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测水平：当 *p*[i] + *s*[i] ≥ *p*[min]+ 3 * *s*[min]
- en: All the examples between the "warning" and "detection" levels are used to train
    a new classifier that will replace the "non-performing" classifier when the "detection"
    level is reached.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在“警告”和“检测”水平之间的所有示例都用于训练一个新的分类器，当达到“检测”水平时，将替换“表现不佳”的分类器。
- en: Early Drift Detection Method or EDDM
  id: totrans-88
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 早期漂移检测方法或EDDM
- en: EDDM uses the same technique as DDM but with a slight modification. It uses
    classification rate (that is, recall) rather than error rate (1 – accuracy) and
    uses the distance between the number of right predictions and two wrong predictions
    to change the levels.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: EDDM使用与DDM相同的技巧，但略有修改。它使用分类率（即召回率）而不是错误率（1 – 准确率），并使用正确预测数和两个错误预测数之间的距离来改变水平。
- en: 'EDDM computes the mean distance between the two errors *p*[i]*^''* and standard
    deviation between the two *s*[i]*''*. The levels are then:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: EDDM计算两个误差 *p*[i]*^'* 之间的平均距离和两个 *s*[i]*'*. 标准差之间的距离。水平如下：
- en: 'Warning level: (*p*[i]*^''* + 2 * *s*[i]*^''*) ⁄ (*p^''*[max] + 2 * *s^''*[max])
    < *α*'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 警告水平：(*p*[i]*^'* + 2 * *s*[i]*^'*) ⁄ (*p^'*[max] + 2 * *s^'*[max]) < *α*
- en: 'Detection level: (*p*[i]*^''* + 2 * *s*[i]*''*) ⁄ (*p^''*[max] + 2 * *s^''*[max])
    < *β*'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测水平：(*p*[i]*^'* + 2 * *s*[i]*'*) ⁄ (*p^'*[max] + 2 * *s^'*[max]) < *β*
- en: The parameters *α* and *β* are normally tuned by the user to something around
    90% and 95% respectively.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 参数 *α* 和 *β* 通常由用户调整到大约 90% 和 95%。
- en: Monitoring distribution changes
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 监控分布变化
- en: When there are no models or classifiers to detect changes, we apply techniques
    that use some form of statistical tests for monitoring distribution changes. These
    tests are used to identify the distribution changes. Owing to assumptions, whether
    parametric or non-parametric, and different biases, it is difficult to say concretely
    which works best. Here we provide some of the well-known statistical tests.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当没有模型或分类器来检测变化时，我们应用使用某种形式的统计检验来监控分布变化的技巧。这些检验用于识别分布变化。由于假设，无论是参数还是非参数，以及不同的偏差，很难具体地说哪个效果最好。在这里，我们提供一些著名的统计检验。
- en: Welch's t test
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 威尔奇t检验
- en: 'This is an adaptation of the Student *t* test with two samples. The test is
    adapted to take two windows of size *N*[1] and *N*[2] with means ![Welch''s t
    test](img/B05137_05_096.jpg)and ![Welch''s t test](img/B05137_05_097.jpg) and
    variances ![Welch''s t test](img/B05137_05_348.jpg) and ![Welch''s t test](img/B05137_05_349.jpg)
    to compute the *p* value and use that to reject or accept the null hypothesis:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Student *t* 检验的两个样本的改编。检验被改编为采用大小为 *N*[1] 和 *N*[2] 的两个窗口，均值 ![威尔奇t检验](img/B05137_05_096.jpg)和
    ![威尔奇t检验](img/B05137_05_097.jpg)，方差 ![威尔奇t检验](img/B05137_05_348.jpg)和 ![威尔奇t检验](img/B05137_05_349.jpg)来计算
    *p* 值，并使用该值来拒绝或接受零假设：
- en: '![Welch''s t test](img/B05137_05_100.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![威尔奇t检验](img/B05137_05_100.jpg)'
- en: Kolmogorov-Smirnov's test
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 科尔莫哥洛夫-斯米尔诺夫检验
- en: 'This statistical test is normally used to compare distances between two distributions
    and validate if they are below certain thresholds or not. This can be adapted
    for change detection by using windows of two different sample sizes, *N*[1] and
    *N*[2], with different cumulative distribution functions, *F*[1](*x*) and F[2](*x*),
    *KS* distance:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这种统计检验通常用于比较两个分布之间的距离，并验证它们是否低于某些阈值。这可以通过使用两个不同样本大小的窗口，*N*[1] 和 *N*[2]，具有不同的累积分布函数，*F*[1](*x*)
    和 F[2](*x*)，*KS* 距离来适应变化检测：
- en: '![Kolmogorov-Smirnov''s test](img/B05137_05_104.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![科尔莫哥洛夫-斯米尔诺夫检验](img/B05137_05_104.jpg)'
- en: The null hypothesis, which assumes the two distributions are similar, is rejected
    with confidence of *α* if and only if ![Kolmogorov-Smirnov's test](img/B05137_05_105.jpg),
    which is obtained by a lookup in the Kolmogorov-Smirnov's table.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当![Kolmogorov-Smirnov's test](img/B05137_05_105.jpg)（通过Kolmogorov-Smirnov表查找获得）的置信度为
    *α* 时，拒绝零假设，该假设认为两个分布是相似的。
- en: CUSUM and Page-Hinckley test
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: CUSUM 和 Page-Hinckley 测试
- en: 'The **cumulative sum** (**CUSUM**) is designed to indicate when the mean of
    the input is significantly different from zero:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**累积和**（**CUSUM**）旨在指示输入的平均值与零显著不同：'
- en: '*g*[0] = 0 , *g*[t] = *max*(0, *g*[t–1]) + *ϵ*[t] – *v*)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*g*[0] = 0 ， *g*[t] = *max*(0, *g*[t–1]) + *ϵ*[t] – *v*)'
- en: We raise change detection when *g*[t] > *h*, where (*h, v*) are user-defined
    parameters. Note that the CUSUM test is memoryless and is one-sided or asymmetric,
    detecting only the increase.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *g*[t] > *h* 时，我们提高变化检测，其中 (*h, v*) 是用户定义的参数。请注意，CUSUM 测试是无记忆的，是一侧或非对称的，仅检测增加。
- en: 'The Page Hinckley test is similar to CUSUM with a small variation as shown
    here:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Page Hinckley 测试与 CUSUM 类似，但有微小差异，如下所示：
- en: '*g*0 = 0 , *g*[t] = *g*[t–1] + *ϵ*[t] – *v*)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*g*0 = 0 ， *g*[t] = *g*[t–1] + *ϵ*[t] – *v*)'
- en: For increasing and decreasing the values, we use *G*[t] *= min(g*[t], *G*[t–1]*)
    or G*[t] *= max(g*[t], *G*[t–1]*)*, and *Gt – gt > h* for change detection.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于增加和减少值，我们使用 *G*[t] *= min(g*[t], *G*[t–1]*) 或 G*[t] *= max(g*[t], *G*[t–1]*)*，并且
    *Gt – gt > h* 用于变化检测。
- en: Adaptation methods
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 适应方法
- en: Explicit and implicit adaptation are the two well-known techniques for adapting
    to environment changes when a change is detected.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 显式和隐式适应是两种在检测到变化时适应环境变化的知名技术。
- en: Explicit adaptation
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 显式适应
- en: 'In explicit adaptation, an additional technique from among the following is
    used:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在显式适应中，使用以下技术之一：
- en: Retrain the model from scratch with new data so the previous model or data does
    not impact the new model
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用新数据从头开始重新训练模型，以确保以前的模型或数据不会影响新模型
- en: Update the model with the changes or new data such that the transition is smooth—assumes
    changes are gradual and not drastic
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用变化或新数据更新模型，以确保过渡平滑——假设变化是渐进的，而不是剧烈的
- en: Create a sequence or ensemble of models that are learned over time—when a collaborative
    approach is better than any single model
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个随时间学习的模型序列或集成——当协作方法比任何单个模型更好时
- en: Implicit adaptation
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 隐式适应
- en: In implicit adaptation, we generally use ensemble algorithms/models to adapt
    to the concept change. This can mean using different combinations ranging from
    a single classifier, to predicting in the ensemble, to using ADWIN for adaptive
    window-based with the classifier—all fall within the choices for implicit adaptation.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在隐式适应中，我们通常使用集成算法/模型来适应概念变化。这可能意味着使用从单个分类器到集成预测，再到使用 ADWIN 进行基于自适应窗口的适应的不同组合——所有这些都属于隐式适应的选择。
- en: Incremental supervised learning
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增量监督学习
- en: This section introduces several techniques used to learn from stream data when
    the true label for each instance is available. In particular, we present linear,
    non-linear, and ensemble-based algorithms adapted to incremental learning, as
    well as methods required in the evaluation and validation of these models, keeping
    in mind that learning is constrained by limits on memory and CPU time.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了在实例的真实标签可用时，从流数据中学习所使用的几种技术。特别是，我们展示了适用于增量学习的线性、非线性以及基于集成算法，以及这些模型评估和验证所需的方法，同时考虑到学习受限于内存和CPU时间的限制。
- en: Modeling techniques
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建模技术
- en: The modeling techniques are divided into linear algorithms, non-linear algorithms,
    and ensemble methods.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 建模技术分为线性算法、非线性算法和集成方法。
- en: Linear algorithms
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线性算法
- en: The linear methods described here require little to no adaptation to handle
    stream data.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这里描述的线性方法需要很少或不需要适应来处理流数据。
- en: Online linear models with loss functions
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 带损失函数的在线线性模型
- en: Different loss functions such as hinge, logistic, and squared error can be used
    in this algorithm.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用不同的损失函数，如铰链、逻辑和平方误差，在此算法中使用。
- en: Inputs and outputs
  id: totrans-127
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 输入和输出
- en: Only numeric features are used in these methods. The choice of loss function
    *l* and learning rate λ at which to apply the weight updates are taken as input
    parameters. The output is typically updatable models that give predictions accompanied
    by confidence values.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法仅使用数值特征。损失函数 *l* 和应用权重更新的学习率 λ 的选择被视为输入参数。输出通常是可更新的模型，这些模型提供带有置信值的预测。
- en: How does it work?
  id: totrans-129
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: 'The basic algorithm assumes linear weight combinations similar to linear/logistic
    regression explained in [Chapter 2](ch02.html "Chapter 2. Practical Approach to
    Real-World Supervised Learning"), *Practical Approach to Real-World Supervised
    Learning*. The stream or online learning algorithm can be summed up as:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 基本算法假设线性权重组合，类似于第2章中解释的线性/逻辑回归，*《面向现实世界监督学习的实用方法》*。流或在线学习算法可以总结如下：
- en: for(t=1,2,…T) do
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: for(t=1,2,…T) do
- en: '**x**[t] = *receive()*; // receive the data'
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**x**[t] = *receive()*; //接收数据'
- en: '![How does it work?](img/B05137_05_116.jpg) ; //predict the label'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![如何工作？](img/B05137_05_116.jpg) ; //预测标签'
- en: '*y*[t] = *obtainTrueLabel()*; // get the true label'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*y*[t] = *obtainTrueLabel()*; //获取真实标签'
- en: '*loss* = *l*(**w**[t], (**x**[t], **w**[t])); // calculate the loss'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*loss* = *l*(**w**[t], (**x**[t], **w**[t])); //计算损失'
- en: if(*l*(**w**t,(**x**t, **w**t )) > 0 then
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: if(*l*(**w**t,(**x**t, **w**t )) > 0 then
- en: '![How does it work?](img/B05137_05_120.jpg) ; //update the weights'
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![如何工作？](img/B05137_05_120.jpg) ; //更新权重'
- en: end
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: end
- en: end
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: end
- en: 'Different loss functions can be plugged in based on types of problems; some
    of the well-known types are shown here:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 可以根据问题类型插入不同的损失函数；这里展示了其中一些知名类型：
- en: 'Classification:'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类：
- en: 'Hinge loss: *l*(**w**[t], (**x**[t], **w**[t])) = max(0, 1 – *yf*(**x**[t],
    **w**[t]))'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 切比雪夫损失：*l*(**w**[t], (**x**[t], **w**[t])) = max(0, 1 – *yf*(**x**[t], **w**[t]))
- en: 'Logistic loss: ![How does it work?](img/B05137_05_123.jpg)'
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑损失：![如何工作？](img/B05137_05_123.jpg)
- en: 'Regression:'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归：
- en: 'Squared loss: ![How does it work?](img/B05137_05_124.jpg)'
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平方损失：![如何工作？](img/B05137_05_124.jpg)
- en: '**Stochastic Gradient Descent** (**SGD**) can be thought of as changing the
    weights to minimize the squared loss as in the preceding loss functions but going
    in the direction of the gradient with each example. The update of weights can
    be described as:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机梯度下降** (**SGD**)可以被视为改变权重以最小化平方损失，如前面的损失函数，但以每个示例的梯度方向前进。权重的更新可以描述为：'
- en: '![How does it work?](img/B05137_05_125.jpg)![How does it work?](img/B05137_05_126.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作？](img/B05137_05_125.jpg)![如何工作？](img/B05137_05_126.jpg)'
- en: Advantages and limitations
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'Online linear models have similar advantages and disadvantages as the linear
    models described in [Chapter 2](ch02.html "Chapter 2. Practical Approach to Real-World
    Supervised Learning"), *Practical Approach to Real-World Supervised Learning*:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在线线性模型与第2章中描述的线性模型具有类似的优缺点，*《面向现实世界监督学习的实用方法》*：
- en: Interpretable to some level as the weights of each features give insights on
    the impact of each feature
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一定程度上可解释，因为每个特征的权重可以提供对每个特征影响的见解
- en: Assumes linear relationship, additive and uncorrelated features, and hence doesn't
    model complex non-linear real-world data
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设线性关系，加性和不相关特征，因此不模拟复杂的非线性现实世界数据
- en: Very susceptible to outliers in the data
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常容易受到数据中异常值的影响
- en: Very fast and normally one of the first algorithms to try or baseline
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常快，通常也是尝试或基线算法之一
- en: Online Naïve Bayes
  id: totrans-154
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在线朴素贝叶斯
- en: 'Bayes theorem is applied to get predictions as the posterior probability, given
    for an *m* dimensional input:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理应用于获取预测值，即后验概率，给定一个*m*维输入：
- en: '![Online Naïve Bayes](img/B05137_05_128.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![在线朴素贝叶斯](img/B05137_05_128.jpg)'
- en: Inputs and outputs
  id: totrans-157
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 输入和输出
- en: Online Naïve Bayes can accept both categorical and continuous inputs. The categorical
    features are easier, as the algorithm must maintain counts for each class while
    computing the *P*(**X**[j]|*Y*) probability for each feature given the class.
    For continuous features, we must either assume a distribution, such as Gaussian,
    or to compute online Kernel Density estimates in an incremental way or discretize
    the numeric features incrementally. The outputs are updatable models and can predict
    the class accompanied by confidence value. Being probabilistic models, they have
    better confidence scores distributed between 0 and 1.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在线朴素贝叶斯可以接受分类和连续输入。对于分类特征来说更容易，因为算法必须维护每个类别的计数，同时计算给定类别的每个特征的*P*(**X**[j]|*Y*)概率。对于连续特征，我们必须假设一个分布，例如高斯分布，或者以增量方式计算在线核密度估计，或者以增量方式对数值特征进行离散化。输出是可更新的模型，可以预测类别并附带置信值。作为概率模型，它们具有更好的置信度分数，分布在0到1之间。
- en: How does it work?
  id: totrans-159
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 如何工作？
- en: for(t = 1,2,…T) do
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: for(t = 1,2,…T) do
- en: '**x**[t] = *receive()*; // receive the data'
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**x**[t] = *receive()*; //接收数据'
- en: incrementCounters(**x**[t]); //update the *P(***X**j*|Y)*
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: incrementCounters(**x**[t]); //更新*P(***X**j*|Y)*
- en: '![How does it work?](img/B05137_05_132.jpg) //posterior probability'
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![如何工作？](img/B05137_05_132.jpg) //后验概率'
- en: end
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: end
- en: Advantages and limitations
  id: totrans-165
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: This is the fastest algorithm and has a low memory footprint as well as computation
    cost. It is very popular among online or fast learners.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是最快的算法，同时具有低内存占用和计算成本。它在在线或快速学习者中非常受欢迎。
- en: Assumes distribution or some biases on the numeric features that can impact
    the predictive quality.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设分布或某些影响预测质量的数值特征的偏差。
- en: Non-linear algorithms
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 非线性算法
- en: One of the most popular non-linear stream learning classifiers in use is the
    Hoeffding Tree. In the following subsections, the notion of the Hoeffding bound
    is introduced, followed by the algorithm itself.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 目前使用最流行的非线性流学习分类器之一是Hoeffding树。在以下小节中，介绍了Hoeffding界限的概念，然后是算法本身。
- en: Hoeffding trees or very fast decision trees (VFDT)
  id: totrans-170
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Hoeffding树或非常快速决策树（VFDT）
- en: The key idea behind **Hoeffding Trees** (**HT**) is the concept of the Hoeffding
    bound. Given a real-valued random variable **x** whose range of values has size
    **R**, suppose we have **n** independent observations of **x** and compute the
    mean as ![Hoeffding trees or very fast decision trees (VFDT)](img/B05137_05_136.jpg).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Hoeffding树（**HT**）背后的关键思想是Hoeffding界限的概念。给定一个具有值范围大小**R**的实值随机变量**x**，假设我们有**n**个独立的**x**观察值，并计算其均值![Hoeffding
    trees or very fast decision trees (VFDT)](img/B05137_05_136.jpg)。
- en: The Hoeffding bound states that, with a probability of 1 – δ, the actual mean
    of the variable **x** is at least ![Hoeffding trees or very fast decision trees
    (VFDT)](img/B05137_05_138.jpg) where ![Hoeffding trees or very fast decision trees
    (VFDT)](img/B05137_05_139.jpg)
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Hoeffding界限表明，以1 – δ的概率，变量**x**的实际均值至少是![Hoeffding trees or very fast decision
    trees (VFDT)](img/B05137_05_138.jpg)其中![Hoeffding trees or very fast decision
    trees (VFDT)](img/B05137_05_139.jpg)
- en: The Hoeffding bound is independent of the probability distribution generating
    the samples and gives a good approximation with just **n** examples.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Hoeffding界限与生成样本的概率分布无关，并且仅使用**n**个示例就能给出良好的近似。
- en: 'The idea of the Hoeffding bound is used in the leaf expansion. If *x*[1] is
    the most informative feature and *x*[2] ranks second, then split using a user-defined
    split function *G*(.) in a way such that:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Hoeffding界限的思想在叶扩展中使用。如果*x*[1]是最具信息量的特征，而*x*[2]排名第二，那么使用用户定义的分割函数*G*(.)进行分割，以便：
- en: '![Hoeffding trees or very fast decision trees (VFDT)](img/B05137_05_144.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![Hoeffding trees or very fast decision trees (VFDT)](img/B05137_05_144.jpg)'
- en: Inputs and outputs
  id: totrans-176
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 输入和输出
- en: Both categorical and continuous data can be part of the data input. Continuous
    features are discretized in many implementations. The desired probability parameter
    1 – δ and the split function common to Decision Trees *G*(.) becomes part of the
    input. The output is the interpretable Decision Tree model and can predict/learn
    with class and confidence values.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 分类数据和连续数据都可以是数据输入的一部分。在许多实现中，连续特征被离散化。所需的概率参数1 – δ和与决策树共同的分割函数*G*(.)成为输入的一部分。输出是可解释的决策树模型，并且可以用类别和置信度值进行预测/学习。
- en: How does it work?
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: HoeffdingTree(x:inputstream,G(.):splitFunction,δ:probabilityBound)
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: HoeffdingTree(x:输入流,G(.):分割函数,δ:概率界限)
- en: Let HT be a tree with single leaf(root)
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让HT成为一个具有单个叶（根）的树
- en: InitCounts(*n*[ijk], *root*)
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化计数(*n*[ijk], *root*)
- en: for(t=1,2,…T) do //all data from stream
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: for(t=1,2,…T) do //来自流的全部数据
- en: '**x***[t] = receive();* //receive the data'
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**x***[t] = receive();* //接收数据'
- en: '*y[t] = obtainTrueLabel();* //get the true label'
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*y[t] = obtainTrueLabel();* //获取真实标签'
- en: HTGrow((**x**[t], *y*[t]), **HT**, δ)
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: HTGrow((**x**[t], *y*[t]), **HT**, δ)
- en: end
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: end
- en: '**HTGrow**((**x**[t], *y*[t]), **HT**, *G*(.), δ)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '**HTGrow**((**x**[t], *y*[t]), **HT**, *G*(.), δ)'
- en: '*l = sort((***x**[t], *y*[t]), **HT**); //sort the data to leaf l using HT'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*l = sort((***x**[t], *y*[t]), **HT**); //使用HT对数据进行排序到叶l'
- en: '*updateCounts(n*[ijk], *l);* // update the counts at leaf l'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*updateCounts(n*[ijk], *l);* //更新叶l的计数'
- en: '*if(examplesSoFarNotOfSameClass();*// check if there are multiple classes'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*if(examplesSoFarNotOfSameClass();*//检查是否存在多个类别'
- en: '*computeForEachFeature(,G(.))*'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*computeForEachFeature(,G(.))*'
- en: '![How does it work?](img/B05137_ch5.jpg)'
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_IMG
  zh: '![如何工作？](img/B05137_ch5.jpg)'
- en: 'Hoeffding Trees have interesting properties, such as:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Hoeffding树具有有趣的特性，例如：
- en: They are a robust low variance model
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们是一个稳健的低方差模型
- en: They exhibit lower overfitting
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们表现出较低的过拟合
- en: Theoretical guarantees with high probability on the error rate exist due to
    Hoeffding bounds
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于Hoeffding界限，存在高概率上的误差率的理论保证
- en: There are variations to Hoeffding Trees that can adapt concept drift, known
    as Concept-Adapting VFDT. They use the sliding window concept on the stream. Each
    node in the decision tree keeps sufficient statistics; based on the Hoeffding
    test, an alternate subtree is grown and swapped in when the accuracy is better.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Hoeffding Trees有适应概念漂移的变体，称为概念适应VFDT。它们在流上使用滑动窗口概念。决策树中的每个节点都保留足够的统计信息；基于Hoeffding测试，当准确性更好时，会生长一个替代子树并将其交换。
- en: Advantages and limitations
  id: totrans-198
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'The advantages and limitations are as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 优点和局限性如下：
- en: The basic HT has issues with attributes being close to the chosen *ϵ* and breaks
    the ties. Deciding the number of attributes at any node is again an issue. Some
    of it is resolved in VFDT.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本HT在属性接近所选*ϵ*时存在问题，并打破了平局。在任何节点上决定属性的数量又是一个问题。其中一些问题在VFDT中得到解决。
- en: Memory constraints on expansion of the trees as well as time spent on an instance
    becomes an issue as the tree changes.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着树的变化，树扩展的内存限制以及在一个实例上花费的时间成为问题。
- en: VFDT has issues with changes in patterns and CVFDT tries to overcome these as
    discussed previously. It is one of the most elegant, fast, interpretable algorithms
    for real-time and big data.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VFDT在模式变化方面存在问题，CVFDT试图克服这些问题，如前所述。它是实时和大数据中最优雅、快速、可解释的算法之一。
- en: Ensemble algorithms
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成算法
- en: The idea behind ensemble learning is similar to batch supervised learning where
    multiple algorithms are trained and combined in some form to predict unseen data.
    The same benefits accrue even in the online setting from different approaches
    to ensembles; for example, using multiple algorithms of different types, using
    models of similar type but with different parameters or sampled data, all so that
    different search spaces or patterns are found and the total error is reduced.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 集成学习的思想与批量监督学习类似，其中多个算法以某种形式训练和组合来预测未见数据。即使在在线设置中，不同的集成方法也能带来相同的益处；例如，使用不同类型的多个算法，使用具有不同参数或样本数据的类似类型的模型，所有这些都可以找到不同的搜索空间或模式，从而降低总误差。
- en: Weighted majority algorithm
  id: totrans-205
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 加权多数算法
- en: The **weighted majority algorithm** (**WMA**) trains a set of base classifiers
    and combines their votes, weighted in some way, and makes predictions based on
    the majority.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '**加权多数算法**（**WMA**）训练一组基础分类器，并按某种方式加权它们的投票，然后基于多数进行预测。'
- en: Inputs and outputs
  id: totrans-207
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 输入和输出
- en: The constraint on types of inputs (categorical only, continuous only, or mixed)
    depends on the chosen base classifiers. The interpretability of the model depends
    on the base model(s) selected but it is difficult to interpret the outputs of
    a combination of models. The weights for each model get updated by a factor (*β*)
    per example/instance when the prediction is incorrect. The combination of weights
    and models can give some idea of interpretability.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 输入类型的约束（仅分类，仅连续，或混合）取决于所选的基础分类器。模型的可解释性取决于所选的基础模型（s），但很难解释模型组合的输出。当预测不正确时，每个模型的权重通过每个示例/实例的因子（*β*）更新。权重和模型的组合可以给出一些可解释性的线索。
- en: How does it work?
  id: totrans-209
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: '*WeightedMajorityAlgorithm(x: inputstream, hm: m learner models)*'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*WeightedMajorityAlgorithm(x: inputstream, hm: m learner models)*'
- en: '*initializeWeights(w*[i]*)*'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*initializeWeights(w*[i]*)*'
- en: for(t=1, 2,…T) do
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: for(t=1, 2,…T) do
- en: '*x*[t] *= receive();*'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*x*[t] *= receive();*'
- en: '*foreach model hk* *∈* *h*'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*foreach model hk* *∈* *h*'
- en: '*y*[i] ← *h*[k](**x**[t]);'
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*y*[i] ← *h*[k](**x**[t]);'
- en: '![How does it work?](img/B05137_05_172.jpg)![How does it work?](img/B05137_05_173.jpg)'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![如何工作？](img/B05137_05_172.jpg)![如何工作？](img/B05137_05_173.jpg)'
- en: else ![How does it work?](img/B05137_05_173a.jpg)
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: else ![如何工作？](img/B05137_05_173a.jpg)
- en: if *y* is known then
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: if *y* is known then
- en: for *i* = 1 to m do
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: for *i* = 1 to m do
- en: if *y*i ≠ *y* then
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: if *y*i ≠ *y* then
- en: '*wi* ← *w*i ** β*'
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*wi* ← *w*i ** β*'
- en: end if
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: end if
- en: end for
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: end for
- en: end
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: end
- en: Advantages and limitations
  id: totrans-225
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'The advantages and limitations are as follows:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 优点和局限性如下：
- en: WMA has simple implementation and theoretic bounds on ensemble errors
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WMA具有简单的实现和理论上的集成误差界限
- en: The difficulty is to choose the right base algorithm as the model and the number
    of models in the pool
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 困难之处在于选择正确的基算法，因为模型和池中模型的数量。
- en: Online Bagging algorithm
  id: totrans-229
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在线Bagging算法
- en: As we saw in the chapter on supervised learning, the bagging algorithm, which
    creates different samples from the training sets and uses multiple algorithms
    to learn and predict, reduces the variance and is very effective in learning.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在监督学习章节中看到的，袋装算法从训练集中创建不同的样本，并使用多个算法进行学习和预测，减少了方差，在学习和预测中非常有效。
- en: Inputs and outputs
  id: totrans-231
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 输入和输出
- en: The constraint on the types of inputs (categorical only, continuous only, or
    mixed) depends on the chosen base classifiers. The base classifier algorithm with
    parameter choices corresponding to the algorithm are also the inputs. The output
    is the learned model that can predict the class/confidence based on the classifier
    chosen.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 对输入类型的限制（仅分类，仅连续，或混合）取决于所选的基本分类器。与算法对应的参数选择的基本分类器算法也是输入。输出是学习模型，可以根据所选分类器预测类别/置信度。
- en: How does it work?
  id: totrans-233
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: 'The basic batch bagging algorithm requires the entire data to be available
    to create different samples and provide these samples to different classifiers.
    Oza''s Online Bagging algorithm changes this constraint and makes it possible
    to learn from unbounded data streams. Based on sampling, each training instance
    in the original algorithm gets replicated many times and each base model is trained
    with *k* copies of the original instances where:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的批量袋装算法需要整个数据可用以创建不同的样本，并将这些样本提供给不同的分类器。Oza的在线袋装算法改变了这一限制，使得从无界数据流中学习成为可能。基于采样，原始算法中的每个训练实例被复制多次，每个基本模型使用原始实例的
    *k* 份副本进行训练，其中：
- en: '*P(k) = exp(–1)/k!*'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '*P(k) = exp(–1)/k!*'
- en: 'This is equivalent to taking one training example and choosing for each classifier
    *k~Poisson(1)* and updating the base classifier *k* times. Thus, the dependency
    on the number of examples is removed and the algorithm can run on an infinite
    stream:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这相当于取一个训练示例，并为每个分类器选择 *k~Poisson(1)*，然后更新基本分类器 *k* 次。因此，消除了对示例数量的依赖，算法可以在无限流上运行：
- en: '*OnlineBagging(x: inputstream, h*[m]*: m learner models)*'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '*OnlineBagging(x: inputstream, h*[m]*: m learner models)*'
- en: initialize base models *h*[m] for all *m* ∈ {1,2,..*M*}
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为所有 *m* ∈ {1,2,..*M*} 初始化基本模型 *h*[m]*
- en: for(t=1,2,…T) do
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: for(t=1,2,…T) do
- en: '*x*[t]*=receive();*'
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*x*[t]*=receive();*'
- en: foreach model *m* = {1,2,..*M*}
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: foreach model *m* = {1,2,..*M*}
- en: '*w = Poisson*(1)'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*w = Poisson*(1)'
- en: '*updateModel(h*[m]*, w, x*[t]*)*'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*updateModel(h*[m]*, w, x*[t]*)*'
- en: end
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: end
- en: return
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: return
- en: '![How does it work?](img/B05137_05_191.jpg)'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![它是如何工作的？](img/B05137_05_191.jpg)'
- en: Advantages and limitations
  id: totrans-247
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'The advantages and limitaions are as follows:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 优点和局限性如下：
- en: It has been empirically shown to be one of the most successful online or stream
    algorithms.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验表明，它是最成功的在线或流算法之一。
- en: The weight must be given to the data instance without looking at the other instances;
    this reduces the choices of different weighting schemes which are available in
    batch and are good in model performance.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 权重必须分配给数据实例，而不考虑其他实例；这减少了在批量中可用且对模型性能良好的不同加权方案的选择。
- en: The performance is entirely determined by the choice of the *M* learners—the
    type of learner used for the problem domain. We can only decide on this choice
    by adopting different validation techniques described in the section on model
    validation techniques.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 性能完全取决于 *M* 学习者的选择——用于问题域的学习者类型。我们只能通过采用模型验证技术部分中描述的不同验证技术来决定这个选择。
- en: Online Boosting algorithm
  id: totrans-252
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在线提升算法
- en: The supervised boosting algorithm takes many *weak learners* whose accuracy
    is slightly greater than random and combines them to produce a strong learner
    by iteratively sampling the misclassified examples. The concept is identical in
    Oza's Online Boosting algorithm with modification done for a continuous data stream.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 监督提升算法采用许多 *弱学习器*，其准确率略高于随机，通过迭代采样错误分类的示例来组合它们以产生强学习器。这个概念在Oza的在线提升算法中是相同的，但为了连续数据流进行了修改。
- en: Inputs and outputs
  id: totrans-254
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 输入和输出
- en: The constraint on types of inputs (categorical only, continuous only, or mixed)
    depends on the chosen base classifiers. The base classifier algorithms and their
    respective parameters are inputs. The output is the learned model that can predict
    the class/confidence based on the classifier chosen.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 对输入类型（仅分类，仅连续，或混合）的限制取决于所选的基本分类器。基本分类器算法及其相应的参数是输入。输出是学习模型，可以根据所选分类器预测类别/置信度。
- en: How does it work?
  id: totrans-256
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: 'The modification of batch boosting to online boosting is done as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 将批量提升修改为在线提升的方法如下：
- en: Keep two sets of weights for *M* base models, *λ*^c is a vector of dimension
    *M* which carries the sum of weights of correctly classified instances, and *λ*^w
    is a vector of dimension *M*, which carries the sum of weights of incorrectly
    classified instances.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 *M* 个基本模型保留两套权重，*λ*^c 是一个维度为 *M* 的向量，它携带正确分类实例的权重总和，而 *λ*^w 是一个维度为 *M* 的向量，它携带错误分类实例的权重总和。
- en: The weights are initialized to 1.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 权重初始化为1。
- en: Given a new instance (**x**[t], *y*[t]), the algorithm goes through the iterations
    of updating the base models.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定一个新的实例（**x**[t]，*y*[t]），算法通过更新基本模型的迭代过程。
- en: 'For each base model, the following steps are repeated:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个基本模型，重复以下步骤：
- en: 'For the first iteration, *k = Poisson(λ)* is set and the learning classifier
    updates the algorithm (denoted here by *h*[1]) *k* times using (**x**[t], *y*[t]):'
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于第一次迭代，*k = Poisson(λ)* 被设置，学习分类器使用（在此表示为 *h*[1]）*k* 次更新算法（使用（**x**[t]，*y*[t]))：
- en: If *h*[1] incorrectly classifies the instance, the *λ*^(w1) is incremented,
    *ϵ*[1], the weighted fraction, incorrectly classified by *h*[1], is computed and
    the weight of the example is multiplied by 1/2 *ϵ*[1].
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果 *h*[1] 错误地分类了实例，则 *λ*^(w1) 增加，*ϵ*[1]，由 *h*[1] 错误分类的加权分数，被计算，并且示例的权重乘以 1/2
    *ϵ*[1]。
- en: Advantages and limitations
  id: totrans-264
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'The advantages and limitations are as follows:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 优点和局限性如下：
- en: Again, the performance is determined by the choice of the multiple learners,
    their types and the particular domain of the problem. The different methods described
    in the section on model validation techniques help us in choosing the learners.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 再次，性能取决于多个学习者的选择、它们的类型以及特定问题的领域。在模型验证技术部分描述的不同方法帮助我们选择学习者。
- en: Oza's Online Boosting has been shown theoretically and empirically not to be
    "lossless"; that is, the model is different compared to its batch version. Thus,
    it suffers from performance issues and different extensions have been studied
    in recent years to improve performance.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oza的在线提升已被理论和实证证明不是“无损”；也就是说，与它的批量版本相比，模型是不同的。因此，它存在性能问题，近年来已经研究了不同的扩展来提高性能。
- en: Validation, evaluation, and comparisons in online setting
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在在线设置中的验证、评估和比较
- en: In contrast to the modes of machine learning we saw in the previous chapters,
    stream learning presents unique challenges to performing the core steps of validation
    and evaluation. The fact that we are no longer dealing with batch data means the
    standard techniques for validation evaluation and model comparison must be adapted
    for incremental learning.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在前几章中看到的机器学习模式不同，流学习在执行验证和评估的核心步骤时提出了独特的挑战。我们不再处理批量数据的事实意味着，用于验证评估和模型比较的标准技术必须适应增量学习。
- en: Model validation techniques
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型验证技术
- en: In the off-line or the batch setting, we discussed various methods of tuning
    the parameters of the algorithm or testing the generalization capability of the
    algorithms as a counter-measure against overfitting. Some of the techniques in
    the batch labeled data, such as cross-validation, are not directly applicable
    in the online or stream settings. The most common techniques used in online or
    stream settings are given next.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在离线或批量设置中，我们讨论了调整算法参数或测试算法泛化能力作为防止过拟合的对策的各种方法。批标签数据中的一些技术，如交叉验证，在在线或流设置中不直接适用。在线或流设置中最常用的技术将在下面给出。
- en: Prequential evaluation
  id: totrans-272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 预序评估
- en: 'The prequential evaluation method is a method where instances are provided
    to the algorithm and the output prediction of the algorithm is then measured in
    comparison with the actual label using a loss function. Thus, the algorithm is
    always tested on the unseen data and needs no "holdout" data to estimate the generalization.
    The prequential error is computed based on the sum of the accumulated loss function
    between actual values and predicted values, given by:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 预序评估方法是一种将实例提供给算法的方法，然后使用损失函数将算法的输出预测与实际标签进行比较。因此，算法始终在未见数据上测试，无需“保留”数据来估计泛化。预序误差是根据实际值和预测值之间累积损失函数的总和计算的，给出如下：
- en: '![Prequential evaluation](img/B05137_05_206.jpg)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![预序评估](img/B05137_05_206.jpg)'
- en: 'Three variations of basic prequential evaluation are done for better estimation
    on changing data, which are:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地估计变化数据，进行了三种基本预序评估的变体，它们是：
- en: Using Landmark Window (basic)
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用地标窗口（基本）
- en: Using Sliding Window
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用滑动窗口
- en: Using forgetting mechanism
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用遗忘机制
- en: The last two methods are extensions of previously described techniques where
    you put weights or fading factors on the predictions that reduce over time.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两种方法是之前描述的技术扩展，其中你在预测上放置权重或衰减因子，这些权重或因子会随着时间的推移而减少。
- en: Holdout evaluation
  id: totrans-280
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 保留集评估
- en: This is the extension of the holdout mechanism or "independent test set" methodology
    of the batch learning. Here the total labeled set or stream data is separated
    into training and testing sets, either based on some fixed intervals or the number
    of examples/instances the algorithm has seen. Imagine a continuous stream of data
    and we place well-known intervals at ![Holdout evaluation](img/B05137_05_207.jpg)
    and ![Holdout evaluation](img/B05137_05_208.jpg) to compare the evaluation metrics,
    as discussed in next section, for performance.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 这是保留机制或“独立测试集”方法在批量学习中的扩展。在这里，总标记集或流数据被分为训练集和测试集，要么基于某些固定间隔，要么基于算法看到的示例/实例数量。想象一下连续的数据流，我们在
    ![保留集评估](img/B05137_05_207.jpg) 和 ![保留集评估](img/B05137_05_208.jpg) 处放置已知的间隔，以比较评估指标，如下一节所述，以评估性能。
- en: Controlled permutations
  id: totrans-282
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 控制排列
- en: The issue with the aforementioned mechanisms is that they provide "average"
    behavior over time and can mask some basic issues such as the algorithm doing
    well at the start and very poorly at the end due to drift, for example. The advantage
    of the preceding methods is that they can be applied to real incoming streams
    to get estimates. One way to overcome the disadvantage is to create different
    random sets of the data where the order is shuffled a bit while maintaining the
    proximity in time and the evaluation is done over a number of these random sets.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 上述机制的问题在于，它们提供了随时间变化的“平均”行为，可能会掩盖一些基本问题，例如算法由于漂移而在开始时表现良好，而在结束时表现非常糟糕。前述方法的优点是，它们可以应用于实际的输入流以获得估计。克服这种缺点的一种方法是在数据的不同随机集中创建不同的随机集，同时保持时间上的邻近性，并在这些随机集上进行评估。
- en: Evaluation criteria
  id: totrans-284
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估标准
- en: 'Most of the evaluation criteria are the same as described in the chapter on
    supervised learning and should be chosen based on the business problem, the mapping
    of the business problem to the machine learning techniques, and on the benefits
    derived. In this section, the most commonly used online supervised learning evaluation
    criteria are summarized for the reader:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数评估标准与监督学习章节中描述的相同，应根据业务问题、业务问题到机器学习技术的映射以及从中获得的收益来选择。在本节中，总结了读者最常用的在线监督学习评估标准：
- en: '**Accuracy**: A measure of getting the true positives and true negatives correctly
    classified by the learning algorithm:![Evaluation criteria](img/B05137_05_209.jpg)'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确率**：衡量学习算法正确分类真实正例和真实负例的度量：![评估标准](img/B05137_05_209.jpg)'
- en: '**Balanced accuracy**: When the classes are imbalanced, balanced accuracy is
    often used as a measure. Balanced accuracy is an arithmetic mean of specificity
    and sensitivity. It can be also thought of as accuracy when positive and negative
    instances are drawn from the same probability in a binary classification problem.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平衡准确率**：当类别不平衡时，通常使用平衡准确率作为度量。平衡准确率是特异性和敏感性的算术平均值。也可以将其视为在二元分类问题中，从相同的概率中抽取正例和负例时的准确率。'
- en: '**Area under the ROC curve** (**AUC**): Area under the ROC curve gives a good
    measure of generalization of the algorithm. Closer to 1.0 means the algorithm
    has good generalization capability while close to 0.5 means it is closer to a
    random guess.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ROC 曲线下面积** (**AUC**): ROC 曲线下面积提供了算法泛化能力的良好度量。接近 1.0 表示算法具有良好的泛化能力，而接近 0.5
    则表示它更接近随机猜测。'
- en: '**Kappa statistic** (**K**): The Kappa statistic is used to measure the observed
    accuracy with the expected accuracy of random guessing in the classification.
    In online learning, the Kappa statistic is used by computing the prequential accuracy
    (*p*o) and the random classifier accuracy (*p*c) and is given by:![Evaluation
    criteria](img/B05137_05_213.jpg)'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kappa 统计量** (**K**): Kappa 统计量用于衡量分类中观察到的准确度与随机猜测的预期准确度。在在线学习中，Kappa 统计量通过计算先验准确度
    (*p*o) 和随机分类器准确度 (*p*c) 来使用，其表达式为：![评估标准](img/B05137_05_213.jpg)'
- en: '**Kappa Plus statistic**: The Kappa Plus statistic is a modification to the
    Kappa statistic obtained by replacing the random classifier by the persistent
    classifier. The persistent classifier is a classifier which predicts the next
    instance based on the label or outcome of the previous instance.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kappa Plus 统计量**: Kappa Plus 统计量是对 Kappa 统计量的一种修改，通过用持久分类器替换随机分类器来获得。持久分类器是一种基于先前实例的标签或结果预测下一个实例的分类器。'
- en: 'When considering "drift" or change in the concept as discussed earlier, in
    addition to these standard measures, some well-known measures given are used to
    give a quantitative measure:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 当考虑“漂移”或概念变化，如前所述，除了这些标准措施外，还使用一些已知的措施来给出定量度量：
- en: '**Probability of true change detection**: Usually, measured with synthetic
    data or data where the changes are known. It gives the ability of the learning
    algorithm to detect the change.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真实变化检测的概率**: 通常使用合成数据或已知变化的数据进行测量。它提供了学习算法检测变化的能力。'
- en: '**Probability of false alarm**: Instead of using the False Positive Rate in
    the off-line setting, the online setting uses the inverse of *time to detection
    or the average run* length which is computed using the expected time between false
    positive detections.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**误报概率**: 与离线设置中使用假阳性率不同，在线设置使用检测时间的倒数或平均运行长度，该长度使用预期假阳性检测时间来计算。'
- en: '**Delay of detection**: This is measured as the time required, terms of instances,
    to identify the drift.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检测延迟**: 这是指识别漂移所需的时间，以实例为单位的术语。'
- en: Comparing algorithms and metrics
  id: totrans-295
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 比较算法和指标
- en: 'When comparing two classifiers or learners in online settings, the usual mechanism
    is the method of taking a performance metric, such as the error rate, and using
    a statistical test adapted to online learning. Two widely used methods are described
    next:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 当在线设置中比较两个分类器或学习者时，通常的机制是采用性能指标，例如错误率，并使用适用于在线学习的统计检验。以下描述两种广泛使用的方法：
- en: '**McNemar test**: McNemar''s test is a non-parametric statistical test normally
    employed to compare two classifiers'' evaluation metrics, such as "error rate",
    by storing simple statistics about the two classifiers. By computing statistic
    *a*, the number of correctly classified points by one algorithm that are incorrectly
    classified by the other, and statistic *b*, which is the inverse, we obtain the
    McNemar''s Test as:![Comparing algorithms and metrics](img/B05137_05_217.jpg)'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**McNemar 检验**: McNemar 检验是一种非参数统计检验，通常用于比较两个分类器的评估指标，例如“错误率”，通过存储两个分类器的简单统计信息。通过计算统计量
    *a*，即一个算法正确分类的点数而另一个算法错误分类的数量，以及统计量 *b*，即其逆，我们得到 McNemar 检验如下：![比较算法和指标](img/B05137_05_217.jpg)'
- en: The test follows a χ2 distribution and the p-value can be used to check for
    statistical significance.
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该检验遵循 χ2 分布，p 值可用于检查统计显著性。
- en: '**Nemenyi test**: When there are multiple algorithms and multiple datasets,
    we use the Nemenyi test for statistical significance, which is based on average
    ranks across all. Two algorithms are considered to be performing differently in
    a statistically significant way if the ranks differ by a critical difference given
    by:![Comparing algorithms and metrics](img/B05137_05_218.jpg)'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Nemenyi 检验**: 当存在多个算法和多个数据集时，我们使用基于所有平均排名的 Nemenyi 检验进行统计显著性检验。如果排名差异超过由以下给出的关键差异，则认为两个算法在统计上以显著不同的方式表现：![比较算法和指标](img/B05137_05_218.jpg)'
- en: Here, K=number of algorithms, N=number of datasets.
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，K=算法数量，N=数据集数量。
- en: The critical difference values are assumed to follow a Student-T distribution.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 假设关键差异值遵循 Student-T 分布。
- en: Incremental unsupervised learning using clustering
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用聚类进行增量无监督学习
- en: The concept behind clustering in a data stream remains the same as in batch
    or offline modes; that is, finding interesting clusters or patterns which group
    together in the data while keeping the limits on finite memory and time required
    to process as constraints. Doing single-pass modifications to existing algorithms
    or keeping a small memory buffer to do mini-batch versions of existing algorithms,
    constitute the basic changes done in all the algorithms to make them suitable
    for stream or real-time unsupervised learning.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 数据流中聚类的概念与批量或离线模式中的概念相同；也就是说，在保持对有限内存和处理所需时间的限制作为约束的同时，寻找有趣的数据簇或模式，这些模式在数据中聚集在一起。对现有算法进行单次修改或保持一个小内存缓冲区以执行现有算法的迷你批处理版本，构成了所有算法的基本变化，使它们适合流或实时无监督学习。
- en: Modeling techniques
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建模技术
- en: The clustering modeling techniques for online learning are divided into partition-based,
    hierarchical-based, density-based, and grid-based, similar to the case of batch-based
    clustering.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在线学习的聚类建模技术分为基于分区、基于层次、基于密度和基于网格，类似于批量聚类的情况。
- en: Partition based
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于分区
- en: The concept of partition-based algorithms is similar to batch-based clustering
    where **k** clusters are formed to optimize certain objective functions such as
    minimizing the inter-cluster distance, maximizing the intra-cluster distance,
    and so on.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 基于分区算法的概念类似于批量聚类，其中形成**k**个聚类以优化某些目标函数，如最小化簇间距离，最大化簇内距离等。
- en: Online k-Means
  id: totrans-308
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在线k-Means
- en: k-Means is the most popular clustering algorithm, which partitions the data
    into user-specified *k* clusters, mostly to minimize the squared error or distance
    between centroids and cluster assigned points. We will illustrate a very basic
    online adaptation of k-Means, of which several variants exist.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: k-Means是最受欢迎的聚类算法，它将数据划分为用户指定的**k**个聚类，通常是为了最小化质心与分配给聚类的点之间的平方误差或距离。我们将说明k-Means的一个非常基本的在线自适应版本，其中存在几种变体。
- en: Inputs and outputs
  id: totrans-310
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 输入和输出
- en: Mainly, numeric features are considered as inputs; a few tools take categorical
    features and convert them into some form of numeric representation. The algorithm
    itself takes the parameters' number of clusters *k* and number of max iterations
    *n* as inputs.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 主要，数值特征被视为输入；一些工具将分类特征转换为某种形式的数值表示。算法本身将聚类数量参数**k**和最大迭代次数**n**作为输入。
- en: How does it work?
  id: totrans-312
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: The input data stream is considered to be infinite but of constant block size.
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入数据流被认为是无限的，但块大小是恒定的。
- en: A memory buffer of the block size is kept reserved to store the data or a compressed
    representation of the data.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保留一个块大小的内存缓冲区以存储数据或数据的压缩表示。
- en: Initially, the first stream of data of block size is used to find the *k* centroids
    of the clusters, the centroid information is stored and the buffer is cleared.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始时，使用块大小的第一个数据流来找到聚类的**k**个质心，质心信息被存储，缓冲区被清除。
- en: 'For the next data after it reaches the block size:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于达到块大小后的下一个数据：
- en: 'For either max number of iterations or until there is no change in the centroids:'
  id: totrans-317
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于最大迭代次数或直到质心没有变化：
- en: Execute k-Means with buffer data and the present centroids.
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用缓冲数据和当前质心执行k-Means。
- en: Minimize the squared sum error between centroids and data assigned to the cluster.
  id: totrans-319
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最小化质心与分配给聚类的数据之间的平方和误差。
- en: After the iterations, the buffer is cleared and new centroids are obtained.
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迭代后，缓冲区被清除，并获得了新的质心。
- en: Repeat step 4 until the data is no longer available.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤4，直到数据不再可用。
- en: Advantages and limitations
  id: totrans-322
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'The advantages and limitations are as follows:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 优点和局限性如下：
- en: Similar to batch-based, the shape of the detected cluster depends on the distance
    measure and is not appropriate in problem domains with irregular shapes.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与批量基础类似，检测到的聚类形状取决于距离度量，在形状不规则的领域问题中不合适。
- en: The choice of parameter **k**, as in batch-based, can limit the performance
    in datasets with many distinct patterns or clusters.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数**k**的选择，如在批量基础上，可能会限制在具有许多不同模式或聚类的数据集上的性能。
- en: Outliers and missing data can pose lots of irregularities in clustering behavior
    of online k-Means.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常值和缺失数据可能会在线k-Means的聚类行为中引起许多不规则性。
- en: If the selected buffer size or the block size of the stream on which iterative
    k-Means runs is small, it will not find the right clusters. If the chosen block
    size is large, it can result in slowdown or missed changes in the data. Extensions
    such as **Very Fast k-Means Algorithm** (**VFKM**), which uses the Hoeffding bound
    to determine the buffer size, overcome this limitation to a large extent.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果选择的缓冲区大小或迭代k-Means运行的流块大小较小，则无法找到正确的聚类。如果选择的块大小较大，可能会导致速度减慢或错过数据的变化。例如，**非常快速k-Means算法**（**VFKM**），它使用Hoeffding界限来确定缓冲区大小，在很大程度上克服了这一限制。
- en: Hierarchical based and micro clustering
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于层次和微聚类的
- en: Hierarchical methods are normally based on **Clustering Features** (**CF**)
    and **Clustering Trees** (**CT**). We will describe the basics and elements of
    hierarchical clustering and the BIRCH algorithm, the extension of which the CluStream
    algorithm is based on.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 层次方法通常基于**聚类特征**（**CF**）和**聚类树**（**CT**）。我们将描述层次聚类和**BIRCH**算法的基本内容和元素，CluStream算法就是基于这个扩展的。
- en: 'The Clustering Feature is a way to compute and preserve a summarization statistic
    about the cluster in a compressed way rather than holding on to the whole data
    belonging to the cluster. In a **d** dimensional dataset, with **N** points in
    the cluster, two aggregates in the form of total sum **LS** for each dimensions
    and total squared sum of data **SS** again for each dimension, are computed and
    the vector representing this triplet form the Clustering Feature:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类特征是一种以压缩方式计算和保存关于簇的汇总统计量，而不是保留簇所属的全部数据。在一个**d**维数据集中，有**N**个点的簇中，计算两个总和，即每个维度的总和**LS**和每个维度的数据总平方和**SS**，这个三元组的表示向量形成聚类特征：
- en: '*CF*[j] *= < N, LS*[j]*, SS*[j] *>*'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '*CF*[j]* = < N, LS*[j]*, SS*[j]* >*'
- en: 'These statistics are useful in summarizing the entire cluster information.
    The centroid of the cluster can be easily computed using:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 这些统计数据有助于总结整个簇信息。簇的重心可以通过以下方式轻松计算：
- en: '*centroid*[j] *= LS*[j]*/N*'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '*质心*[j]* = LS*[j]* / N*'
- en: 'The radius of the cluster can be estimated using:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下方法估计簇的半径：
- en: '![Hierarchical based and micro clustering](img/B05137_05_231.jpg)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![基于层次和微聚类的图](img/B05137_05_231.jpg)'
- en: 'The diameter of the cluster can be estimated using:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下方法估计簇的直径：
- en: '![Hierarchical based and micro clustering](img/B05137_05_232.jpg)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![基于层次和微聚类的图](img/B05137_05_232.jpg)'
- en: CF vectors have great incremental and additive properties which becomes useful
    in stream or incremental updates.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: CF向量具有很好的增量性和累加性，这在流或增量更新中非常有用。
- en: 'For an incremental update, when we must update the CF vector, the following
    holds true:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 对于增量更新，当我们必须更新CF向量时，以下条件成立：
- en: '![Hierarchical based and micro clustering](img/B05137_05_233.jpg)![Hierarchical
    based and micro clustering](img/B05137_05_234.jpg)![Hierarchical based and micro
    clustering](img/B05137_05_235.jpg)'
  id: totrans-340
  prefs: []
  type: TYPE_IMG
  zh: '![基于层次和微聚类的图](img/B05137_05_233.jpg)![基于层次和微聚类的图](img/B05137_05_234.jpg)![基于层次和微聚类的图](img/B05137_05_235.jpg)'
- en: 'When two CFs have to be merged, the following holds true:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个CF需要合并时，以下条件成立：
- en: '![Hierarchical based and micro clustering](img/B05137_05_236.jpg)![Hierarchical
    based and micro clustering](img/B05137_05_237.jpg)![Hierarchical based and micro
    clustering](img/B05137_05_238.jpg)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![基于层次和微聚类的图](img/B05137_05_236.jpg)![基于层次和微聚类的图](img/B05137_05_237.jpg)![基于层次和微聚类的图](img/B05137_05_238.jpg)'
- en: 'The **Clustering Feature Tree** (**CF Tree**) represents an hierarchical tree
    structure. The construction of the CF tree requires two user defined parameters:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类特征树**（**CF树**）表示一个层次树结构。CF树的构建需要两个用户定义的参数：'
- en: Branching factor **b** which is the maximum number of sub-clusters or non-leaf
    nodes any node can have
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分支因子**b**，即任何节点可以拥有的最大子簇或非叶节点数
- en: Maximum diameter (or radius) **T**, the number of examples that can be absorbed
    by the leaf node for a CF parent node
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大直径（或半径）**T**，CF父节点可以吸收的示例数量
- en: 'CF Tree operations such as insertion are done by recursively traversing the
    CF Tree and using the CF vector for finding the closest node based on distance
    metrics. If a leaf node has already absorbed the maximum elements given by parameter
    *T*, the node is split. At the end of the operation, the CF vector is appropriately
    updated for its statistic:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: CF树操作，如插入，是通过递归遍历CF树并使用CF向量根据距离度量找到最近节点来完成的。如果一个叶节点已经吸收了由参数*T*给出的最大元素，则节点被分割。操作结束时，CF向量会适当地更新其统计量：
- en: '![Hierarchical based and micro clustering](img/B05137_05_245.jpg)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![基于层次和微聚类的图](img/B05137_05_245.jpg)'
- en: Figure 3 An example Clustering Feature Tree illustrating hierarchical structure.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：一个展示层次结构的聚类特征树示例。
- en: We will discuss **BIRCH** (**Balanced Iterative Reducing and Clustering Hierarchies**)
    following this concept.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将根据这一概念讨论**BIRCH**（**平衡迭代减少和聚类层次结构**）。
- en: Inputs and outputs
  id: totrans-350
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 输入和输出
- en: BIRCH only accepts numeric features. CF and CF tree parameters, such as branching
    factor *b* and maximum diameter (or radius) *T* for leaf are user-defined inputs.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: BIRCH只接受数值特征。CF和CF树参数，如分支因子*b*和叶节点的最大直径（或半径）*T*是用户定义的输入。
- en: How does it work?
  id: totrans-352
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: 'BIRCH, designed for very large databases, was meant to be a *two-pass* algorithm;
    that is, scan the entire data once and re-scan it again, thus being an *O(N)*
    algorithm. It can be modified easily enough for online as a single pass algorithm
    preserving the same properties:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: BIRCH是为非常大的数据库设计的，原本是一个*两遍*算法；也就是说，扫描整个数据一次，然后再次扫描，因此是一个*O(N)*算法。它可以很容易地修改为单遍算法，以在线方式保留相同的属性：
- en: In the first phase or scan, it goes over the data and creates an in-memory CF
    Tree structure by sequentially visiting the points and carrying out CF Tree operations
    as discussed previously.
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一阶段或扫描中，它遍历数据，通过顺序访问点并执行之前讨论的CF树操作，创建一个内存中的CF树结构。
- en: In the second phase, an optional phase, we remove outliers and merge sub-clusters.
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二阶段，这是一个可选阶段，我们去除异常值并合并子簇。
- en: Phase three is to overcome the issue of order of data in phase one. We use agglomerative
    hierarchical clustering to refactor the CF Tree.
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三阶段是为了克服第一阶段数据顺序的问题。我们使用层次聚类对CF树进行重构。
- en: Phase four is the last phase which is an optional phase to compute statistics
    such as centroids, assign data to closest centroids, and so on, for more effectiveness.
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第四阶段是最后一个阶段，这是一个可选阶段，用于计算统计信息，如计算质心、将数据分配给最近的质心等，以提高效率。
- en: Advantages and limitations
  id: totrans-358
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'The advantages and limitations are as follows:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 优点和局限性如下：
- en: It is one of the most popular algorithms that scales linearly on a large database
    or stream of data.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是最受欢迎的线性扩展算法之一，在大数据库或数据流上具有线性扩展能力。
- en: It has compact memory representation in the form of the CF and CF Tree for statistics
    and operations on incoming data.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它以CF和CF树的形式具有紧凑的内存表示，用于对传入数据的统计和操作。
- en: It handles outliers better than most algorithms.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它比大多数算法更好地处理异常值。
- en: One of the major limitations is that it has been shown not to perform well when
    the shape of the clusters is not spherical.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个主要的局限性是，当簇的形状不是球形时，它已被证明表现不佳。
- en: The concepts of CF vector and clustering in BIRCH were extended for efficient
    stream mining requirements by Aggarwal *et al* and named *micro-cluster and CluStream*.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BIRCH中的CF向量聚类概念被Aggarwal等人扩展，以适应高效的流挖掘需求，并命名为*微簇和CluStream*。
- en: Inputs and outputs
  id: totrans-365
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 输入和输出
- en: CluStream only accepts numeric features. Among the user-defined parameters are
    the number of micro-clusters in memory (*q*) and the threshold (*δ*) in time after
    which they can be deleted. Additionally, included in the input are time-sensitive
    parameters for storing the micro-clusters information, given by *α* and *l*.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: CluStream只接受数值特征。用户定义的参数包括内存中微簇的数量（*q*）和阈值（*δ*），在时间之后它们可以被删除。此外，输入还包括时间敏感的参数，用于存储微簇信息，由*α*和*l*给出。
- en: How does it work?
  id: totrans-367
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: 'The micro-cluster extends the CF vector and keeps two additional measures.
    They are the sum of the timestamps and sum of the squares of timestamps:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 微簇扩展了CF向量，并保留了两个额外的度量。它们是时间戳的总和以及时间戳平方的总和：
- en: '*microCluster*[j] *= < N, LS*[j]*, SS*[j]*, ST, SST>*'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*微簇*[j] *= < N, LS*[j]*, SS*[j]*, ST, SST>*'
- en: The algorithm stores *q* micro-clusters in memory and each micro-cluster has
    a *maximum boundary* that can be computed based on means and standard deviations
    between centroid and cluster instance distances. The measures are multiplied by
    a factor which decreases exponentially with time.
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法在内存中存储*q*个微簇，每个微簇都有一个*最大边界*，可以根据质心和簇实例之间的距离的均值和标准差来计算。这些度量乘以一个随时间指数递减的因子。
- en: 'For each new instance, we select the closest micro-cluster based on Euclidean
    distance and decide whether it should be absorbed:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个新的实例，我们根据欧几里得距离选择最近的微簇，并决定它是否应该被吸收：
- en: If the distance between the new instance and the centroid of the closest micro-cluster
    falls within the maximum boundary, it is absorbed and the micro-cluster statistics
    are updated.
  id: totrans-372
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果新实例与最近微簇质心之间的距离在最大边界内，则它将被吸收，并且微簇统计信息将得到更新。
- en: If none of the micro-clusters can absorb, a new micro-cluster is created with
    the instance and based on the timestamp and threshold (*δ*), the oldest micro-cluster
    is deleted.
  id: totrans-373
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有微簇可以吸收，则创建一个新的微簇，包含实例，并根据时间戳和阈值（*δ*），删除最旧的微簇。
- en: Assuming normal distribution of timestamps, if the relevance time—the time of
    arrival of instance found by CluStream—is below the user-specified threshold,
    it is considered an outlier and removed. Otherwise, the two closest micro-clusters
    are merged.
  id: totrans-374
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设时间戳服从正态分布，如果 CluStream 找到的实例的相关时间——实例到达的时间——低于用户指定的阈值，则被视为异常并删除。否则，将合并两个最近的微簇。
- en: The micro-cluster information is stored in secondary storage from time to time
    by using a pyramidal time window concept. Each micro-cluster has time intervals
    decrease exponentially using *α*l to create snapshots. These help in efficient
    search in both time and space.
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 微簇信息通过使用金字塔时间窗口概念，时不时地存储在二级存储中。每个微簇使用 *α*l 指数递减的时间间隔来创建快照。这些快照有助于在时间和空间上高效搜索。
- en: Advantages and limitations
  id: totrans-376
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'The advantages and limitations are as follows:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 优点和局限性如下：
- en: CluStream has been shown to be very effective in finding clusters in real time
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CluStream 已被证明在实时寻找簇方面非常有效
- en: The CluStream algorithm, through effective storage using a pyramidal timestamp,
    has efficient time and space usage. CluStream, like BIRCH, can find only spherical
    shaped clusters
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CluStream 算法通过使用金字塔时间戳进行有效存储，具有高效的时间和空间使用。CluStream，就像 BIRCH 一样，只能找到球形形状的簇
- en: Density based
  id: totrans-380
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于密度
- en: Similar to batch clustering, density-based techniques overcome the "shape" issue
    faced by distance-based algorithms. Here we will present a well-known density-based
    algorithm, DenStream, which is based on the concepts of CF and CF Trees discussed
    previously.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 与批处理聚类类似，基于密度的技术克服了基于距离的算法面临的“形状”问题。在这里，我们将介绍一个著名的基于密度的算法，即 DenStream，它基于之前讨论的
    CF 和 CF Trees 概念。
- en: Inputs and outputs
  id: totrans-382
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 输入和输出
- en: The extent of the neighborhood of a core micro-cluster is the user-defined radius
    *ϵ*. A second input value is the minimum total weight *µ* of the micro-cluster
    which is the sum over the weighted function of the arrival time of each instance
    in the object, where the weight decays with a time constant proportional to another
    user-defined parameter, *λ*. Finally, an input factor *β* ∈ (0,1) is used to distinguish
    potential core micro-clusters from outlier micro-clusters.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 核心微簇的邻域范围是用户定义的半径 *ϵ*。第二个输入值是微簇的最小总权重 *µ*，它是每个实例到达时间加权函数的总和，其中权重随时间常数衰减，与另一个用户定义的参数
    *λ* 成正比。最后，使用输入因子 *β* ∈ (0,1) 来区分潜在的核微簇和异常微簇。
- en: How does it work?
  id: totrans-384
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: 'Based on the micro-cluster concepts of CluStream, DenStream holds two data
    structures: *p-micro-cluster* for potential clusters and *o-micro-clusters* for
    outlier detection.'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于 CluStream 的微簇概念，DenStream 包含两个数据结构：*p-微簇*用于潜在簇和*o-微簇*用于异常检测。
- en: 'Each *p-micro-cluster* structure has:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个 *p-微簇* 结构具有：
- en: 'A weight associated with it which decreases exponentially with the timestamps
    it has been updated with. If there are *j* objects in the micro-cluster: ![How
    does it work?](img/B05137_05_260.jpg) where *f(t) =* 2^(-λt)'
  id: totrans-387
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与它相关联的权重，该权重随时间戳的更新指数递减。如果微簇中有 *j* 个对象：![它是如何工作的？](img/B05137_05_260.jpg) 其中
    *f(t) =* 2^(-λt)
- en: '**Weighted linear sum** (**WLS**) and **weighted linear sum of squares** (**WSS**)
    are stored in micro-clusters similar to linear sum and sum of squares:![How does
    it work?](img/B05137_05_262.jpg)![How does it work?](img/B05137_05_263.jpg)'
  id: totrans-388
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**加权线性求和**（**WLS**）和**加权线性平方和**（**WSS**）与线性求和和平方和类似存储在微簇中：![它是如何工作的？](img/B05137_05_262.jpg)![它是如何工作的？](img/B05137_05_263.jpg)'
- en: 'The mean, radius, and diameter of the clusters are then computed using the
    weighted measures defined previously, exactly like in CF. For example, the radius
    can be given as:'
  id: totrans-389
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用之前定义的加权度量计算簇的均值、半径和直径，这与 CF 中的做法完全一样。例如，半径可以表示为：
- en: '![How does it work?](img/B05137_05_264.jpg)'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![它是如何工作的？](img/B05137_05_264.jpg)'
- en: Each *o-micro-cluster* has the same structure as *p-micro-cluster* and timestamps
    associated with it.
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个 *o-微簇* 与 *p-微簇* 具有相同的结构，并与其相关联时间戳。
- en: 'When a new instance arrives:'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当一个新的实例到达时：
- en: A closest *p-micro-cluster* is found and the instance is inserted if the new
    radius is within the user-defined boundary *ϵ*. If inserted, the *p-micro-cluster*
    statistics are updated accordingly.
  id: totrans-393
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果新半径在用户定义的边界 *ϵ* 内，则找到最近的 *p-微簇* 并将实例插入其中。如果插入，则相应更新 *p-微簇* 统计数据。
- en: Otherwise, an *o-micro-cluster* is found and the instance is inserted if the
    new radius is again within the boundary. The boundary is defined by *β* × *μ*,
    the product of the user-defined parameters, and if the radius grows beyond this
    value, the *o-micro-cluster* is moved to the *p-micro-cluster*.
  id: totrans-394
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 否则，如果新的半径再次在边界内，就会找到一个*o-微簇*，并将实例插入其中。边界由用户定义参数的乘积*β* × *μ*定义，如果半径超过这个值，*o-微簇*将被移动到*p-微簇*。
- en: If the instance cannot be absorbed by an *o-micro-cluster*, then a new micro-cluster
    is added to the *o-micro-clusters*.
  id: totrans-395
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果实例不能被一个*o-微簇*吸收，那么就会向*o-微簇*中添加一个新的微簇。
- en: At the time interval *t* based on weights, the *o-micro-cluster* can become
    the *p-micro-cluster* or vice versa. The time interval is defined in terms of
    *λ*, *β*, and *µ* as:![How does it work?](img/B05137_05_269.jpg)
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在基于权重的间隔时间*t*，*o-微簇*可以变成*p-微簇*，反之亦然。时间间隔以*λ*、*β*和*µ*来定义：![它是如何工作的？](img/B05137_05_269.jpg)
- en: Advantages and limitations
  id: totrans-397
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'The advantages and limitations are as follows:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 优点和局限性如下：
- en: Based on the parameters, DenStream can find effective clusters and outliers
    for real-time data.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于参数，DenStream可以找到实时数据的有效聚类和异常值。
- en: It has the advantage of finding clusters and outliers of any shape or size.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的优点是能够找到任何形状或大小的聚类和异常值。
- en: The house keeping job of updating the *o-micro-cluster* and *p-micro-cluster*
    can be computationally expensive if not selected properly.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有正确选择，更新*o-微簇*和*p-微簇*的维护工作可能会计算成本高昂。
- en: Grid based
  id: totrans-402
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于网格
- en: This technique is based on discretizing the multi-dimensional continuous space
    into a multi-dimensional discretized version with grids. The mapping of the incoming
    instance to grid online and maintaining the grid offline results in an efficient
    and effective way of finding clusters in real-time.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术基于将多维连续空间离散化为多维离散版本，并使用网格。将传入的实例映射到在线网格并维护离线网格的结果是一种高效且有效的方法，可以在实时中找到聚类。
- en: Here we present D-Stream, which is a grid-based online stream clustering algorithm.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们介绍了D-Stream，这是一个基于网格的在线流聚类算法。
- en: Inputs and outputs
  id: totrans-405
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 输入和输出
- en: 'As in density-based algorithms, the idea of decaying weight of instances is
    used in D-Stream. Additionally, as described next, cells in the grid formed from
    the input space may be deemed sparse, dense, or sporadic, distinctions that are
    central to the computational and space efficiency of the algorithm. The inputs
    to the grid-based algorithm, then, are:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于密度的算法一样，D-Stream使用了实例衰减权重的想法。此外，如以下所述，从输入空间形成的网格中的单元格可能被认为是稀疏的、密集的或偶然的，这些区别是算法的计算和空间效率的核心。因此，基于网格的算法的输入如下：
- en: '*λ*: The decay factor'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*λ*: 衰减因子'
- en: '0 < *C*[l] < 1 and *C*[m] > 1: Parameters that control the boundary between
    dense and sparse cells in the grid'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 < *C*[l] < 1 和 *C*[m] > 1：控制网格中密集和稀疏单元格之间边界的参数
- en: '*β* > 0: A constant that controls one of the conditions when a sparse cell
    is to be considered sporadic.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*β* > 0：一个常数，用于控制当稀疏单元格被视为偶然单元格时的一个条件。'
- en: How does it work?
  id: totrans-410
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: Each instance arriving at time *t* has a density coefficient that decreases
    exponentially over time:![How does it work?](img/B05137_05_273.jpg)
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在时间*t*到达的每个实例都有一个随时间指数衰减的密度系数：![它是如何工作的？](img/B05137_05_273.jpg)
- en: Density of the grid cell *g* at any given time *t* is given by *D(g, t)* and
    is the sum of the adjusted density of all instances given by *E(g, t)* that are
    mapped to grid cell *g*:![How does it work?](img/B05137_05_277.jpg)
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在任何给定时间*t*，网格单元格*g*的密度由*D(g, t)*给出，它是映射到网格单元格*g*的所有实例的调整密度的总和*E(g, t)*：![它是如何工作的？](img/B05137_05_277.jpg)
- en: 'Each cell in the grid captures the statistics as a characterization vector
    given by:'
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网格中的每个单元格都捕获了以下作为特征向量的统计数据：
- en: '*CV(g) =* <*t*[g], *t*>[m], *D*, *label*, *status*> where:'
  id: totrans-414
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*CV(g) =* <*t*[g], *t*>[m], *D*, *label*, *status*> 其中：'
- en: '*t*[g] = last time grid cell was updated'
  id: totrans-415
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*t*[g] = 网格单元格上次更新的时间'
- en: '*t*[m]= last time grid cell was removed due to sparseness'
  id: totrans-416
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*t*[m]= 网格单元格上次由于稀疏性而被移除的时间'
- en: '*D* = density of the grid cell when last updated'
  id: totrans-417
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*D* = 上次更新时网格单元格的密度'
- en: '*label* = class label of the grid cell'
  id: totrans-418
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*label* = 网格单元格的类别标签'
- en: '*status* = {NORMAL or SPORADIC}'
  id: totrans-419
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*status* = {正常或偶然}'
- en: When the new instance arrives, it gets mapped to a cell *g* and the characteristic
    vector is updated. If *g* is not available, it is created and the list of grids
    is updated.
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当新的实例到达时，它会被映射到一个单元格*g*，并且特征向量被更新。如果*g*不可用，它将被创建，并且网格列表被更新。
- en: Grid cells with empty instances are removed. Also, cells that have not been
    updated over a long time can become sparse, and conversely, when many instances
    are mapped, they become dense.
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 具有空实例的网格单元将被移除。此外，长时间未更新的单元可能会变得稀疏，相反，当映射许多实例时，它们会变得密集。
- en: At a regular time interval known as a gap, the grid cells are inspected for
    status and the cells with fewer instances than a number—determined by a density
    threshold function—are treated as outliers and removed.
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个称为间隔的常规时间间隔内，检查网格单元的状态，那些实例数量少于由密度阈值函数确定的数字的单元被视为异常值并被移除。
- en: Advantages and limitations
  id: totrans-423
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'The advantages and limitations are as follows:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 优点和局限性如下：
- en: D-Streams have theoretically and empirically been shown to find sporadic and
    normal clusters with very high efficiency in space and time.
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: D-Streams在理论和实证上已被证明能够在空间和时间上以非常高的效率找到偶然和正常的聚类。
- en: It can find clusters of any shape or size effectively.
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以有效地找到任何形状或大小的聚类。
- en: Validation and evaluation techniques
  id: totrans-427
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 验证和评估技术
- en: Many of the static clustering evaluation measures discussed in [Chapter 3](ch03.html
    "Chapter 3. Unsupervised Machine Learning Techniques"), *Unsupervised Machine
    Learning Techniques*, have an assumption of static and non-evolving patterns.
    Some of these internal and external measures are used even in streaming based
    cluster detection. Our goal in this section is to first highlight problems inherent
    to cluster evaluation in stream learning, then describe different internal and
    external measures that address these, and finally, present some existing measures—both
    internal and external—that are still valid.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 许多在第3章[无监督机器学习技术](ch03.html "Chapter 3. Unsupervised Machine Learning Techniques")中讨论的静态聚类评估度量都假设存在静态和非演化的模式。其中一些内部和外部度量甚至在基于流的聚类检测中使用。本节的目标是首先强调流学习聚类评估中固有的问题，然后描述解决这些问题的不同内部和外部度量，最后介绍一些现有的度量——包括内部和外部度量——它们仍然有效。
- en: Key issues in stream cluster evaluation
  id: totrans-429
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 流聚类评估的关键问题
- en: 'It is important to understand some of the important issues that are specific
    to streaming and clustering, as the measures need to address them:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 理解一些特定于流和聚类的关键问题很重要，因为这些度量需要解决这些问题：
- en: '**Aging**: The property of points being not relevant to the clustering measure
    after a given time.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**老化**: 点在给定时间后不再与聚类度量相关的属性。'
- en: '**Missed points**: The property of a point not only being missed as belonging
    to the cluster but the amount by which it was missed being in the cluster.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遗漏的点**: 点不仅被遗漏为属于聚类，而且遗漏的量在聚类中。'
- en: '**Misplaced points**: Changes in clusters caused by evolving new clusters.
    Merging existing or deleting clusters results in ever-misplaced points with time.
    The impact of these changes with respect to time must be taken into account.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**放置错误**: 由新聚类的演变引起的聚类变化。合并现有或删除聚类会导致随着时间的推移出现不断放置错误。必须考虑这些变化随时间的影响。'
- en: '**Cluster noise**: Choosing data that should not belong to the cluster or forming
    clusters around noise and its impact over time must be taken into account.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类噪声**: 选择不应属于聚类的数据或围绕噪声形成聚类及其随时间的影响必须被考虑。'
- en: Evaluation measures
  id: totrans-435
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估度量
- en: Evaluation measures for clustering in the context of streaming data must provide
    a useful index of the quality of clustering, taking into consideration the effect
    of evolving and noisy data streams, overlapping and merging clusters, and so on.
    Here we present some external measures used in stream clustering. Many internal
    measures encountered in [Chapter 3](ch03.html "Chapter 3. Unsupervised Machine
    Learning Techniques"), *Unsupervised Machine Learning Techniques*, such as the
    Silhouette coefficient, Dunn's Index, and R-Squared, are also used and are not
    repeated here.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 在流数据上下文中进行聚类的评估度量必须提供聚类质量的有用指标，同时考虑演化和噪声数据流的影响、重叠和合并的聚类等问题。在此，我们介绍了一些在流聚类中使用的外部度量。在第3章[无监督机器学习技术](ch03.html
    "Chapter 3. Unsupervised Machine Learning Techniques")中遇到的许多内部度量，如轮廓系数、Dunn指数和R平方，也被使用，此处不再重复。
- en: Cluster Mapping Measures (CMM)
  id: totrans-437
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 聚类映射度量（CMM）
- en: 'The idea behind CMM is to quantify the connectivity of the points to clusters
    given the ground truth. It works in three phases:'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: CMM背后的思想是在给定真实情况下量化点到聚类的连通性。它分为三个阶段：
- en: '**Mapping phase**: In this phase, clusters assigned by the stream learning
    algorithm are mapped to the ground truth clusters. Based on these, various statistics
    of distance and point connectivity are measured using the concepts of k-Nearest
    Neighbors.'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: '**映射阶段**：在这个阶段，流学习算法分配的聚类映射到真实聚类。基于这些，使用k-最近邻的概念测量距离和点连通性的各种统计量。'
- en: 'The average distance of point *p* to its closest *k* neighbors in a cluster
    *C*i is given by:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 点*p*在聚类*C*i中到其最近的*k*个邻居的平均距离由以下公式给出：
- en: '![Cluster Mapping Measures (CMM)](img/B05137_05_287.jpg)'
  id: totrans-441
  prefs: []
  type: TYPE_IMG
  zh: '![聚类映射度量（CMM）](img/B05137_05_287.jpg)'
- en: 'The average distance for a cluster *C*[i] is given by:'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类*C*[i]的平均距离由以下公式给出：
- en: '![Cluster Mapping Measures (CMM)](img/B05137_05_288.jpg)'
  id: totrans-443
  prefs: []
  type: TYPE_IMG
  zh: '![聚类映射度量（CMM）](img/B05137_05_288.jpg)'
- en: 'The point connectivity of a point *p* in a cluster *C*[i] is given by:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类*C*[i]中点*p*的点连通性由以下公式给出：
- en: '![Cluster Mapping Measures (CMM)](img/B05137_05_289.jpg)'
  id: totrans-445
  prefs: []
  type: TYPE_IMG
  zh: '![聚类映射度量（CMM）](img/B05137_05_289.jpg)'
- en: Class frequencies are counted for each cluster and the mapping of the cluster
    to the ground truth is performed by calculating the histograms and similarity
    in the clustering.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个聚类计算类别频率，并通过计算直方图和聚类中的相似性来执行聚类到真实聚类的映射。
- en: 'Specifically, a cluster *C*[i] is mapped to the ground truth class, and *Cl*[j]
    is mapped to a ground truth cluster ![Cluster Mapping Measures (CMM)](img/B05137_05_350.jpg),
    which covers the majority of class frequencies of *C*[i]. The surplus is defined
    as the number of instances from class *Cl*[i] not covered by the ground truth
    cluster ![Cluster Mapping Measures (CMM)](img/B05137_05_350.jpg) and total surplus
    for instances in classes *Cl*[1], *Cl*[2], *Cl*[3] … *Cl*[1] in cluster *C*[i]
    compared to ![Cluster Mapping Measures (CMM)](img/B05137_05_350.jpg) is given
    by:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，聚类*C*[i]映射到真实类别，而*Cl*[j]映射到覆盖*C*[i]中类别频率大多数的真实聚类![聚类映射度量（CMM）](img/B05137_05_350.jpg)。剩余定义为类*Cl*[i]中未被真实聚类![聚类映射度量（CMM）](img/B05137_05_350.jpg)覆盖的实例数量，以及与![聚类映射度量（CMM）](img/B05137_05_350.jpg)相比，在聚类*C*[i]中类*Cl*[1]，*Cl*[2]，*Cl*[3]
    … *Cl*[1]中的实例的总剩余量给出如下：
- en: '![Cluster Mapping Measures (CMM)](img/B05137_05_294.jpg)'
  id: totrans-448
  prefs: []
  type: TYPE_IMG
  zh: '![聚类映射度量（CMM）](img/B05137_05_294.jpg)'
- en: 'Cluster *C*[i] is mapped using:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下方法映射聚类*C*[i]：
- en: '![Cluster Mapping Measures (CMM)](img/B05137_05_295.jpg)'
  id: totrans-450
  prefs: []
  type: TYPE_IMG
  zh: '![聚类映射度量（CMM）](img/B05137_05_295.jpg)'
- en: '**Penalty phase**: The penalty for every instance that is mapped incorrectly
    is calculated in this step using computations of fault objects; that is, objects
    which are not noise and yet incorrectly placed, using:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: '**惩罚阶段**：在这个步骤中，使用错误对象的计算来计算映射错误的每个实例的惩罚；即不是噪声但放置错误的对象，使用以下方法：'
- en: '![Cluster Mapping Measures (CMM)](img/B05137_05_296.jpg)'
  id: totrans-452
  prefs: []
  type: TYPE_IMG
  zh: '![聚类映射度量（CMM）](img/B05137_05_296.jpg)'
- en: 'The overall penalty of point *o* with respect to all clusters found is given
    by:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 点*o*相对于所有找到的聚类的总体惩罚由以下公式给出：
- en: '![Cluster Mapping Measures (CMM)](img/B05137_05_297.jpg)'
  id: totrans-454
  prefs: []
  type: TYPE_IMG
  zh: '![聚类映射度量（CMM）](img/B05137_05_297.jpg)'
- en: '**CMM calculation**: Using all the penalties weighted over the lifespan is
    given by:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: '**CMM计算**：使用所有惩罚在生命周期内加权给出如下：'
- en: '![Cluster Mapping Measures (CMM)](img/B05137_05_298.jpg)'
  id: totrans-456
  prefs: []
  type: TYPE_IMG
  zh: '![聚类映射度量（CMM）](img/B05137_05_298.jpg)'
- en: Here, *C* is found clusters, *Cl* is ground truth clusters, *F* is the fault
    objects and *w(o)* is the weight of instance.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*C*是找到的聚类，*Cl*是真实聚类，*F*是错误对象，*w(o)*是实例的权重。
- en: V-Measure
  id: totrans-458
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: V度量
- en: Validity or V-Measure is an external measure which is computed based on two
    properties that are of interest in stream clustering, namely, **Homogeneity**
    and **Completeness**. If there are *n* classes as set *C* = {*c*[1], *c*[2] …,
    *c*[n]} and *k* clusters *K* = {*k*[1], *k*[2..]*k*[m]}, contingency tables are
    created such that *A* = {*a*[ij]} corresponds to the count of instances in class
    *c*[i] and cluster *k*[j].
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 验证度或V度量是一个外部度量，它是基于流聚类中两个感兴趣的属性计算的，即**同质性**和**完整性**。如果有*n*个类别，设*C* = {*c*[1],
    *c*[2] …, *c*[n]}，和*k*个聚类*K* = {*k*[1], *k*[2..]*k*[m]}，则创建列联表，其中*A* = {*a*[ij]}对应于类别*c*[i]和聚类*k*[j]中的实例数量。
- en: '**Homogeneity**: Homogeneity is defined as a property of a cluster that reflects
    the extent to which all the data in the cluster belongs to the same class.'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '**同质性**：同质性定义为聚类的一个属性，反映了聚类中所有数据属于同一类别的程度。'
- en: 'Conditional entropy and class entropy:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 条件熵和类别熵：
- en: '![V-Measure](img/B05137_05_309.jpg)![V-Measure](img/B05137_05_310.jpg)'
  id: totrans-462
  prefs: []
  type: TYPE_IMG
  zh: '![V-Measure](img/B05137_05_309.jpg)![V-Measure](img/B05137_05_310.jpg)'
- en: 'Homogeneity is defined as:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 同质性定义为：
- en: '![V-Measure](img/B05137_05_311.jpg)'
  id: totrans-464
  prefs: []
  type: TYPE_IMG
  zh: '![V-Measure](img/B05137_05_311.jpg)'
- en: A higher value of homogeneity is more desirable.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 同质性值越高越理想。
- en: '**Completeness**: Completeness is defined as the mirror property of Homogeneity,
    that is, having all instances of a single class belong to the same cluster.'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: '**完整性**：完整性定义为同质性的镜像属性，即所有单个类别的实例都属于同一个聚类。'
- en: 'Similar to Homogeneity, conditional entropies and cluster entropy are defined
    as:'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 与同质性类似，条件熵和聚类熵定义为：
- en: '![V-Measure](img/B05137_05_312.jpg)![V-Measure](img/B05137_05_313.jpg)'
  id: totrans-468
  prefs: []
  type: TYPE_IMG
  zh: '![V-Measure](img/B05137_05_312.jpg)![V-Measure](img/B05137_05_313.jpg)'
- en: 'Completeness is defined as:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 完整性定义为：
- en: '![V-Measure](img/B05137_05_314.jpg)'
  id: totrans-470
  prefs: []
  type: TYPE_IMG
  zh: '![V-Measure](img/B05137_05_314.jpg)'
- en: 'V-Measure is defined as the harmonic mean of homogeneity and completeness using
    a weight factor *β*:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: V-Measure定义为使用权重因子*β*的同质性和完整性的调和平均值：
- en: '![V-Measure](img/B05137_05_316.jpg)'
  id: totrans-472
  prefs: []
  type: TYPE_IMG
  zh: '![V-Measure](img/B05137_05_316.jpg)'
- en: A higher value of completeness or V-measure is better.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 完整性或V-measure的值越高越好。
- en: Other external measures
  id: totrans-474
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 其他外部度量
- en: 'Some external measures which are quite popular in comparing the clustering
    algorithms or measuring the effectiveness of clustering when the classes are known
    are given next:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来给出一些外部度量，这些度量在比较聚类算法或测量已知类别的聚类有效性时相当流行：
- en: '**Purity** and **Entropy**: They are similar to homogeneity and completeness
    defined previously.'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '**纯度**和**熵**：它们与之前定义的同质性和完整性相似。'
- en: 'Purity is defined as:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 纯度定义为：
- en: '![Other external measures](img/B05137_05_317.jpg)'
  id: totrans-478
  prefs: []
  type: TYPE_IMG
  zh: '![其他外部度量](img/B05137_05_317.jpg)'
- en: 'Entropy is defined as:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 熵定义为：
- en: '![Other external measures](img/B05137_05_318.jpg)'
  id: totrans-480
  prefs: []
  type: TYPE_IMG
  zh: '![其他外部度量](img/B05137_05_318.jpg)'
- en: Here, *q* = number of classes, *k* = number of clusters, *n*r = size of cluster
    *r* and ![Other external measures](img/B05137_05_320.jpg).
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*q* = 类别数量，*k* = 聚类数量，*n*r = 聚类*r*的大小，![其他外部度量](img/B05137_05_320.jpg)。
- en: '**Precision**, **Recall**, and **F-Measure**: Information retrieval measures
    modified for clustering algorithms are as follows:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '**精度**、**召回率**和**F-Measure**：针对聚类算法修改的信息检索度量如下：'
- en: Given, ![Other external measures](img/B05137_05_321.jpg) and ![Other external
    measures](img/B05137_05_322.jpg).
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 给定，![其他外部度量](img/B05137_05_321.jpg)和![其他外部度量](img/B05137_05_322.jpg)。
- en: 'Precision is defined as:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 精度定义为：
- en: '![Other external measures](img/B05137_05_323.jpg)'
  id: totrans-485
  prefs: []
  type: TYPE_IMG
  zh: '![其他外部度量](img/B05137_05_323.jpg)'
- en: 'Recall is defined as:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率定义为：
- en: '![Other external measures](img/B05137_05_324.jpg)'
  id: totrans-487
  prefs: []
  type: TYPE_IMG
  zh: '![其他外部度量](img/B05137_05_324.jpg)'
- en: 'F-measures is defined as:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: F-measures定义为：
- en: '![Other external measures](img/B05137_05_325.jpg)'
  id: totrans-489
  prefs: []
  type: TYPE_IMG
  zh: '![其他外部度量](img/B05137_05_325.jpg)'
- en: Unsupervised learning using outlier detection
  id: totrans-490
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用离群值检测进行无监督学习
- en: The subject of finding outliers or anomalies in the data streams is one of the
    emerging fields in machine learning. This area has not been explored by researchers
    as much as classification and clustering-based problems have. However, there have
    been some very interesting ideas extending the concepts of clustering to find
    outliers from data streams. We will provide some of the research that has been
    proved to be very effective in stream outlier detection.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据流中寻找离群值或异常值是机器学习中的一个新兴领域。这个领域的研究并没有像基于分类和聚类的问题那样受到研究者的广泛关注。然而，已经有一些非常有趣的想法将聚类的概念扩展到从数据流中寻找离群值。我们将提供一些在流离群值检测中已被证明非常有效的科研。
- en: Partition-based clustering for outlier detection
  id: totrans-492
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于分区聚类进行离群值检测
- en: The central idea here is to use an online partition-based clustering algorithm
    and based on either cluster size ranking or inter-cluster distance ranking, label
    the clusters as outliers.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的核心思想是使用基于在线分区聚类算法，并根据聚类大小排序或簇间距离排序，将簇标记为离群值。
- en: Here we present one such algorithm proposed by Koupaie *et al*., using incremental
    k-Means.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们介绍由Koupaie等人提出的一种算法，使用增量k-Means。
- en: Inputs and outputs
  id: totrans-495
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输入和输出
- en: Only numeric features are used, as in most k-Means algorithms. The number of
    clusters *k* and the number of windows of outliers *n*, on which offline clustering
    happens, are input parameters. The output is constant outliers (local and global)
    and an updatable model that detects these.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 仅使用数值特征，正如大多数k-Means算法一样。聚类数量*k*和离群值窗口数量*n*，在离线聚类中使用的输入参数。输出是恒定的离群值（局部和全局）以及一个可更新的模型，用于检测这些离群值。
- en: How does it work?
  id: totrans-497
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: This algorithm works by having the k-Means algorithm in two modes, an offline
    mode and an online mode, both working in parallel.
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该算法通过k-Means算法在两种模式下工作，离线模式和在线模式，两者并行运行。
- en: 'For the online mode:'
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于在线模式：
- en: Apply k-Means on the given window *w* and find clusters and partitions of the
    data with clusters.
  id: totrans-500
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在给定的窗口 *w* 上应用 k-Means，并找到具有簇的数据的簇和分区。
- en: Rank the clusters based on the cluster distances and cluster size. The clusters
    which are farthest apart and small in size are considered outliers.
  id: totrans-501
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据簇距离和簇大小对簇进行排序。距离最远且尺寸较小的簇被认为是异常值。
- en: Store the outliers in memory for the window as a set *O*[w] = {**x**[1], **x**[2..]**x**[n]}
    and regard them as local outliers.
  id: totrans-502
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将窗口作为集合 *O*[w] = {**x**[1], **x**[2..]**x**[n]} 存储异常值，并将它们视为局部异常值。
- en: The window is cleared and the process is repeated.
  id: totrans-503
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 窗口被清除，过程重复。
- en: 'For the offline mode:'
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于离线模式：
- en: 'Get outliers from *n*, previous windows, and create a set: ![How does it work?](img/B05137_05_328.jpg)'
  id: totrans-505
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 *n* 个先前窗口中获取异常值，并创建一个集合：![如何工作？](img/B05137_05_328.jpg)
- en: Cluster this window with set *S* using k-Means and find clusters which are farthest
    away and small in size.
  id: totrans-506
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 k-Means 对窗口 *S* 进行聚类，并找到距离最远且尺寸较小的簇。
- en: These clusters are global outliers.
  id: totrans-507
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些簇是全局异常值。
- en: The window is cleared and the process is repeated.
  id: totrans-508
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 窗口被清除，过程重复。
- en: Advantages and limitations
  id: totrans-509
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'The advantages and limitations are as follows:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 优点和局限性如下：
- en: It is very sensitive to the two parameters *k* and *n* and can generate lots
    of noise.
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它对参数 *k* 和 *n* 非常敏感，可以生成大量噪声。
- en: Only spherical clusters/outliers are found and outliers with different shapes
    get missed.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只找到了球形簇/异常值，而不同形状的异常值被遗漏了。
- en: Distance-based clustering for outlier detection
  id: totrans-513
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于距离的异常值检测聚类
- en: Distance-based outlier detection is the most studied, researched, and implemented
    method in the area of stream learning. There are many variants of the distance-based
    methods, based on sliding windows, the number of nearest neighbors, radius and
    thresholds, and other measures for considering outliers in the data. We will try
    to give a sampling of the most important algorithms in this section.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 基于距离的异常值检测是流学习领域中研究、实施最广泛的方法。基于滑动窗口、最近邻数量、半径和阈值以及其他考虑数据中异常值的措施，有许多基于距离的方法的变体。我们将尝试在本节中给出最重要的算法的抽样。
- en: Inputs and outputs
  id: totrans-515
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输入和输出
- en: 'Most algorithms take the following parameters as inputs:'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数算法将以下参数作为输入：
- en: Window size *w*, corresponding to the fixed size on which the algorithm looks
    for outlier patterns
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 窗口大小 *w*，对应算法查找异常值模式时的固定大小
- en: Sliding size *s*, corresponds to the number of new instances that will be added
    to the window, and old ones removed
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滑动大小 *s*，对应于将被添加到窗口中的新实例数量，以及将被移除的旧实例数量
- en: The count threshold *k* of instances when using nearest neighbor computation
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最近邻计算时实例的计数阈值 *k*
- en: The distance threshold *R* used to define the outlier threshold in distances
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于定义距离中异常值阈值的距离阈值 *R*
- en: Outliers as labels or scores (based on neighbors and distance) are outputs.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值作为标签或分数（基于邻居和距离）输出。
- en: How does it work?
  id: totrans-522
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何工作？
- en: We present different variants of distance-based stream outlier algorithms, giving
    insights into what they do differently or uniquely. The unique elements in each
    algorithm define what happens when the slide expires, how a new slide is processed,
    and how outliers are reported.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了基于距离的流异常值算法的不同变体，揭示了它们的不同之处或独特之处。每个算法的独特元素定义了滑动窗口过期时会发生什么，如何处理新的滑动窗口，以及如何报告异常值。
- en: Exact Storm
  id: totrans-524
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 精确风暴
- en: 'Exact Storm stores the data in the current window *w* in a well-known index
    structure, so that the range query search or query to find neighbors within the
    distance *R* for a given point is done efficiently. It also stores *k* preceding
    and succeeding neighbors of all data points:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 精确风暴将数据存储在当前窗口 *w* 中的已知索引结构中，以便对给定点的范围查询搜索或查询在距离 *R* 内的邻居进行高效处理。它还存储所有数据点的 *k*
    个前驱和后继邻居：
- en: '**Expired Slide**: Instances in expired slides are removed from the index structure
    that affects range queries but are preserved in the preceding list of neighbors.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过期滑动窗口**：过期滑动窗口中的实例从影响范围查询的索引结构中删除，但保留在邻居的前驱列表中。'
- en: '**New Slide**: For each data point in the new slide, range query *R* is executed,
    results are used to update the preceding and succeeding list for the instance,
    and the instance is stored in the index structure.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新滑动窗口**：对于新滑动窗口中的每个数据点，执行范围查询 *R*，使用结果更新实例的前驱和后继列表，并将实例存储在索引结构中。'
- en: '**Outlier Reporting**: In any window, after the processing of expired and new
    slide elements is complete, any instance with at least *k* elements from the succeeding
    list and non-expired preceding list is reported as an outlier.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值报告**：在任何窗口中，在处理过期和新幻灯片元素完成后，任何至少有 *k* 个元素来自后继列表和非过期前驱列表的实例都被报告为异常值。'
- en: Abstract-C
  id: totrans-529
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 抽象-C
- en: 'Abstract-C keeps the index structure similar to Exact Storm but instead of
    preceding and succeeding lists for every object it just maintains a list of counts
    of neighbors for the windows the instance is participating in:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: Abstract-C保持索引结构与Exact Storm相似，但不是为每个对象维护前驱和后继列表，而是仅维护实例参与窗口的邻居计数列表：
- en: '**Expired Slide**: Instances in expired slides are removed from the index structure
    that affects range queries and the first element from the list of counts is removed
    corresponding to the last window.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过期幻灯片**：在过期幻灯片中的实例将从影响范围查询的索引结构中移除，并且与最后一个窗口对应的计数列表中的第一个元素也被移除。'
- en: '**New Slide**: For each data point in the new slide, range query *R* is executed
    and results are used to update the list count. For existing instances, the count
    gets updated with new neighbors and instances are added to the index structure.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新幻灯片**：对于新幻灯片中的每个数据点，执行范围查询 *R*，并使用结果更新计数列表。对于现有实例，计数会根据新的邻居更新，并将实例添加到索引结构中。'
- en: '**Outlier Reporting**: In any window, after the processing of expired and new
    slide elements is complete, all instances with a neighbors count less than *k*
    in the current window are considered outliers.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值报告**：在任何窗口中，在处理过期和新幻灯片元素完成后，当前窗口中邻居计数少于 *k* 的所有实例都被视为异常值。'
- en: Direct Update of Events (DUE)
  id: totrans-534
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 直接更新事件（DUE）
- en: 'DUE keeps the index structure for efficient range queries exactly like the
    other algorithms but has a different assumption, that when an expired slide occurs,
    not every instance is affected in the same way. It maintains two priority queues:
    the unsafe inlier queue and the outlier list. The unsafe inlier queue has sorted
    instances based on the increasing order of smallest expiration time of their preceding
    neighbors. The outlier list has all the outliers in the current window:'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: DUE保持索引结构以进行高效的范围查询，与其它算法完全相同，但有一个不同的假设，即当发生过期幻灯片时，并非每个实例都会以相同的方式受到影响。它维护两个优先队列：不安全内点队列和异常值列表。不安全内点队列根据前驱邻居的最小过期时间的递增顺序排序实例。异常值列表包含当前窗口中的所有异常值：
- en: '**Expired Slide**: Instances in expired slides are removed from the index structure
    that affects range queries and the unsafe inlier queue is updated for expired
    neighbors. Those unsafe inliers which become outliers are removed from the priority
    queue and moved to the outlier list.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过期幻灯片**：过期幻灯片中的实例将从影响范围查询的索引结构中移除，并且不安全内点队列将更新过期邻居。那些成为异常值的不安全内点将从优先队列中移除，并移动到异常值列表中。'
- en: '**New Slide**: For each data point in the new slide, range query *R* is executed,
    results are used to update the succeeding neighbors of the point, and only the
    most recent preceding points are updated for the instance. Based on the updates,
    the point is added to the unsafe inlier priority queue or removed from the queue
    and added to the outlier list.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新幻灯片**：对于新幻灯片中的每个数据点，执行范围查询 *R*，使用结果更新点的后继邻居，并且仅更新实例的最近前驱点。基于这些更新，点被添加到不安全内点优先队列或从队列中移除并添加到异常值列表中。'
- en: '**Outlier Reporting**: In any window, after the processing of expired and new
    slide elements is complete, all instances in the outlier list are reported as
    outliers.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值报告**：在任何窗口中，在处理过期和新幻灯片元素完成后，所有异常值列表中的实例都被报告为异常值。'
- en: Micro Clustering based Algorithm (MCOD)
  id: totrans-539
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于微聚类的算法（MCOD）
- en: 'Micro-clustering based outlier detection overcomes the computational issues
    of performing range queries for every data point. The micro-cluster data structure
    is used instead of range queries in these algorithms. A micro-cluster is centered
    around an instance and has a radius of *R*. All the points belonging to the micro-clusters
    become inliers. The points that are outside can be outliers or inliers and stored
    in a separate list. It also has a data structure similar to DUE to keep a priority
    queue of unsafe inliers:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 基于微聚类的异常值检测克服了为每个数据点执行范围查询的计算问题。在这些算法中，使用微聚类数据结构而不是范围查询。微聚类以实例为中心，半径为 *R*。所有属于微聚类的点成为内点。位于微聚类之外的点可以是异常值或内点，并存储在单独的列表中。它还拥有与DUE类似的数据结构，以保持不安全内点的优先队列：
- en: '**Expired Slide**: Instances in expired slides are removed from both micro-clusters
    and the data structure with outliers and inliers. The unsafe inlier queue is updated
    for expired neighbors as in the DUE algorithm. Micro-clusters are also updated
    for non-expired data points.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过期的滑动窗口**：过期的滑动窗口中的实例从微簇和包含异常值和内点的数据结构中删除。与DUE算法一样，更新过期的邻居的不安全内点队列。微簇也针对非过期数据点进行更新。'
- en: '**New Slide**: For each data point in the new slide, the instance either becomes
    a center of a micro-cluster, or part of a micro-cluster or added to the event
    queue and the data structure of the outliers. If the point is within the distance
    *R*, it gets assigned to an existing micro-cluster; otherwise, if there are *k*
    points within *R*, it becomes the center of the new micro cluster; if not, it
    goes into the two structures of the event queue and possible outliers.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新滑动窗口**：对于新滑动窗口中的每个数据点，实例要么成为微簇的中心，要么成为微簇的一部分，或者被添加到事件队列和异常值的数据结构中。如果点在距离*R*内，它被分配给现有的微簇；否则，如果有*k*个点在*R*内，它成为新微簇的中心；如果没有，它进入事件队列和可能的异常值的两个结构中。'
- en: '**Outlier Reporting**: In any window, after the processing of expired and new
    slide elements is complete, any instance in the outlier structure with less than
    *k* neighboring instances is reported as an outlier.'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值报告**：在任何窗口中，在处理过期的和新滑动窗口元素完成后，任何在异常结构中具有少于*k*个邻近实例的实例被报告为异常值。'
- en: Approx Storm
  id: totrans-544
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Approx Storm
- en: 'Approx Storm, as the name suggests, is an approximation of Exact Storm. The
    two approximations are:'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，Approx Storm是Exact Storm的近似。这两种近似方法如下：
- en: Reducing the number of data points in the window by adding a factor *ρ* and
    changing the window to *ρW*.
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过添加一个因子*ρ*并将窗口更改为*ρW*来减少窗口中数据点的数量。
- en: Storing the number instead of the data structure of preceding neighbors by using
    the fraction of the number of neighbors which are safe inliers in the preceding
    list to the number in the current window.
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用前一个列表中安全的内点数与当前窗口中数字的比例来存储数字而不是前一个邻居的数据结构。
- en: 'The processing of expired and new slides and how outliers are determined based
    on these steps follows:'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 处理过期的和新滑动窗口以及如何根据这些步骤确定异常值如下：
- en: '**Expired Slide**: Same as Exact Storm—instances in expired slides are removed
    from the index structure that affects range queries but preserved in the preceding
    list of neighbors.'
  id: totrans-549
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**过期的滑动窗口**：与Exact Storm相同——过期的滑动窗口中的实例从影响范围查询的索引结构中删除，但保留在邻居的前一个列表中。'
- en: '**New Slide**: For each data point in the new slide, range query *R* is executed,
    results are used to compute the fraction discussed previously, and the index structure
    is updated. The number of safe inliers are constrained to *ρW* by removing random
    inliers if the size exceeds that value. The assumption is that most of the points
    in safe inliers are safe.'
  id: totrans-550
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**新滑动窗口**：对于新滑动窗口中的每个数据点，执行范围查询*R*，使用结果来计算之前讨论过的分数，并更新索引结构。如果大小超过该值，则通过移除随机内点来将安全内点的数量限制为*ρW*。假设大多数安全内点都是安全的。'
- en: '**Outlier Reporting**: In any window, after the processing of expired and new
    slide elements has been completed, when an approximation (see *References* [17])
    of the number of neighbors of an instance based on the fraction, window size,
    and preceding list is a value less than *k*, it is considered as an outlier.'
  id: totrans-551
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**异常值报告**：在任何窗口中，在处理过期的和新滑动窗口元素之后，当基于分数、窗口大小和前一个列表的实例的邻居数量的近似值小于*k*时，它被视为异常值。'
- en: Advantages and limitations
  id: totrans-552
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 优点和局限性
- en: 'The advantages and limitations are as follows:'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 优点和局限性如下：
- en: Exact Storm is demanding in storage and CPU for storing lists and retrieving
    neighbors. Also, it introduces delays; even though they are implemented in efficient
    data structures, range queries can be slow.
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Exact Storm在存储和CPU方面对存储列表和检索邻居有较高要求。尽管它们被实现为高效的数据结构，但范围查询可能会引入延迟。
- en: Abstract-C has a small advantage over Exact Storm, as no time is spent on finding
    active neighbors for each instance in the window. The storage and time spent is
    still very much dependent on the window and slide chosen.
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abstract-C相对于Exact Storm有轻微的优势，因为它不需要在每个窗口实例上花费时间来查找活跃的邻居。存储和时间消耗仍然很大程度上取决于窗口和滑动选择。
- en: DUE has some advantage over Exact Storm and Abstract-C as it can efficiently
    re-evaluate the "inlierness" of points (that is, whether unsafe inliers remain
    inliers or become outliers) but sorting the structure impacts both CPU and memory.
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DUE相对于Exact Storm和Abstract-C有一些优势，因为它可以有效地重新评估点的“内含性”（即，是否不安全的内点仍然保持内点或变为异常点），但排序结构会影响CPU和内存。
- en: MCOD has distinct advantages in memory and CPU owing to the use of the micro-cluster
    structure and removing the pair-wise distance computation. Storing the neighborhood
    information in micro-clusters helps memory too.
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MCOD由于使用了微簇结构并去除了成对距离计算，在内存和CPU方面具有独特的优势。在微簇中存储邻域信息也有助于节省内存。
- en: Approx Storm has an advantage of time over the others as it doesn't process
    the expired data points over the previous window.
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Approx Storm与其他方法相比，在时间上具有优势，因为它不会处理上一个窗口中的过期数据点。
- en: Validation and evaluation techniques
  id: totrans-559
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 验证和评估技术
- en: 'Validation and evaluation of stream-based outliers is still an open research
    area. In many research comparisons, we see various metrics being used, such as:'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 基于流的异常的验证和评估仍然是一个开放的研究领域。在许多研究比较中，我们看到使用了各种指标，例如：
- en: Time to evaluate in terms of CPU times per object
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以每个对象的CPU时间来衡量评估时间
- en: Number of outliers detected in the streams
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流中检测到的异常数量
- en: Number of outliers that correlate to existing labels, TP/Precision/Recall/Area
    under PRC curve, and so on
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与现有标签相关的异常数量，TP/精确率/召回率/PRC曲线下的面积等
- en: By varying parameters such as window-size, neighbors within radius, and so on,
    we determine the sensitivity to the performance metrics mentioned previously and
    determine the robustness.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 通过改变窗口大小、半径内的邻居等参数，我们确定了对之前提到的性能指标的敏感性，并确定其鲁棒性。
- en: Case study in stream learning
  id: totrans-565
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流学习案例研究
- en: The case study in this chapter consists of several experiments that illustrate
    different methods of stream-based machine learning. A well-studied dataset was
    chosen as the stream data source and supervised tree based methods such as Naïve
    Bayes, Hoeffding Tree, as well as ensemble methods, were used. Among unsupervised
    methods, clustering algorithms used include k-Means, DBSCAN, CluStream, and CluTree.
    Outlier detection techniques include MCOD and SimpleCOD, among others. We also
    show results from classification experiments that demonstrate handling concept
    drift. The ADWIN algorithm for calculating statistics in a sliding window, as
    described earlier in this chapter, is employed in several algorithms used in the
    classification experiments.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的案例研究包括几个实验，展示了基于流的机器学习的不同方法。选择了一个经过充分研究的数据集作为流数据源，并使用了基于监督的树方法，如朴素贝叶斯、Hoeffding树，以及集成方法。在无监督方法中，使用的聚类算法包括k-Means、DBSCAN、CluStream和CluTree。异常检测技术包括MCOD和SimpleCOD等。我们还展示了分类实验的结果，这些结果展示了处理概念漂移的能力。本章前面描述的用于在滑动窗口中计算统计的ADWIN算法被用于几个分类实验中。
- en: Tools and software
  id: totrans-567
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工具和软件
- en: One of the most popular and arguably the most comprehensive Java-based frameworks
    for data stream mining is the open source **Massive Online Analysis** (**MOA**)
    software created by the University of Waikato. The framework is a collection of
    stream classification, clustering, and outlier detection algorithms and has support
    for change detection and concept drift. It also includes data generators and several
    evaluation tools. The framework can be extended with new stream data generators,
    algorithms, and evaluators. In this case study, we employ several stream data
    learning methods using a file-based data stream.
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 最受欢迎且可能是最全面的基于Java的数据流挖掘框架之一是瓦卡托大学创建的开源**大规模在线分析**（**MOA**）软件。该框架是一系列流分类、聚类和异常检测算法的集合，并支持变化检测和概念漂移。它还包括数据生成器和几个评估工具。该框架可以通过新的流数据生成器、算法和评估器进行扩展。在本案例研究中，我们使用基于文件的数据流，采用了几种流数据学习方法。
- en: Note
  id: totrans-569
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Product homepage: [http://moa.cms.waikato.ac.nz/](http://moa.cms.waikato.ac.nz/)'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 产品主页：[http://moa.cms.waikato.ac.nz/](http://moa.cms.waikato.ac.nz/)
- en: 'GitHub: [https://github.com/Waikato/moa](https://github.com/Waikato/moa)'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub：[https://github.com/Waikato/moa](https://github.com/Waikato/moa)
- en: 'As shown in the series of screenshots from the MOA tool shown in *Figure 4*
    and *Figure 5*, the top-level menu lets you choose the type of learning to be
    done. For the classification experiments, for example, configuration of the tools
    consists of selecting the task to run (selected to be prequential evaluation here),
    and then configuring which learner and evaluator we want to use, and finally,
    the source of the data stream. A window width parameter shown in the **Configure
    Task** dialog can affect the accuracy of the model chosen, as we will see in the
    experiment results. Other than choosing different values for the window width,
    all base learner parameters were left as default values. Once the task is configured
    it is run by clicking the **Run** button:'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图4*和*图5*所示的MOA工具的一系列截图所示，顶层菜单允许你选择要执行的学习类型。例如，对于分类实验，工具的配置包括选择要运行的任务（此处选择为预quential评估），然后配置我们想要使用的学习器和评估器，最后是数据流的来源。**配置任务**对话框中显示的窗口宽度参数可以影响所选模型的准确性，正如我们将在实验结果中看到的那样。除了选择窗口宽度的不同值之外，所有基学习器参数都保留为默认值。一旦配置了任务，就可以通过点击**运行**按钮来运行：
- en: '![Tools and software](img/B05137_05_339.jpg)![Tools and software](img/B05137_05_340.jpg)'
  id: totrans-573
  prefs: []
  type: TYPE_IMG
  zh: '![工具和软件](img/B05137_05_339.jpg)![工具和软件](img/B05137_05_340.jpg)'
- en: Figure 4\. MOA graphical interface for configuring prequential evaluation for
    classification which includes setting the window width
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 图4. MOA配置预quential评估分类的图形界面，包括设置窗口宽度
- en: '![Tools and software](img/B05137_05_341.jpg)![Tools and software](img/B05137_05_342.jpg)'
  id: totrans-575
  prefs: []
  type: TYPE_IMG
  zh: '![工具和软件](img/B05137_05_341.jpg)![工具和软件](img/B05137_05_342.jpg)'
- en: Figure 5\. MOA graphical interface for prequential classification task. Within
    the Configure task, you must choose a learner, locate the data stream (details
    not shown), and select an evaluator
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 图5. MOA预quential分类任务的图形界面。在配置任务中，你必须选择一个学习器，定位数据流（细节未显示），并选择一个评估器
- en: After the task has completed running, model evaluation results can be exported
    to a CSV file.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 任务完成后，可以将模型评估结果导出为CSV文件。
- en: Business problem
  id: totrans-578
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 商业问题
- en: The problem for this case study is to continuously learn from a stream of electricity
    market data and predict the direction of movement of the market price. We compare
    the accuracy and average cost of different classification methods including concept
    drift as well as the performance of clustering and outlier detection.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 本案例研究的问题是从电力市场数据流中持续学习并预测市场价格变动方向。我们比较了包括概念漂移在内的不同分类方法的准确性和平均成本，以及聚类和异常检测的性能。
- en: Machine learning mapping
  id: totrans-580
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习映射
- en: The dataset used in this case study can be used to illustrate classical batch-based
    supervised and unsupervised learning techniques. However, here we treat it as
    a stream-based data source to show how we can employ the techniques described
    in this chapter to perform classification, clustering, and outlier detection tasks
    using the MOA framework. Within this context, we demonstrate how incremental learning
    can be achieved under assumptions of a stationary as well as an evolving data
    stream exhibiting concept drift.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 本案例研究中使用的数据集可以用来说明经典的基于批次的监督学习和无监督学习技术。然而，在这里我们将其视为基于流的 数据源，以展示我们如何使用本章中描述的技术在MOA框架下执行分类、聚类和异常检测任务。在此背景下，我们展示了在假设数据流是平稳的以及表现出概念漂移的演变数据流的情况下，如何实现增量学习。
- en: Data collection
  id: totrans-582
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据收集
- en: The dataset is known as the Electricity or ELEC dataset, which was collected
    by the New South Wales Electricity Market. The prices in this market are variable,
    and are adjusted every 5 minutes based on supply and demand. This dataset consists
    of 45,312 such data points obtained every half-hour between May 1996 and December
    1998\. The target is an indication of the movement of the price, whether up or
    down, relative to the 24-hour moving average.
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集被称为电力或ELEC数据集，由新南威尔士电力市场收集。该市场的价格是可变的，并且根据供需情况每5分钟调整一次。该数据集包括从1996年5月到1998年12月每半小时获得45,312个这样的数据点。目标是表示价格相对于24小时移动平均值的上升或下降趋势。
- en: Note
  id: totrans-584
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The data file is a publicly available file in the ARRF format at [http://downloads.sourceforge.net/project/moa-datastream/Datasets/Classification/elecNormNew.arff.zip?r=http%3A%2F%2Fmoa.cms.waikato.ac.nz%2Fdatasets%2F&ts=1483128450&use_mirror=cytranet](http://downloads.sourceforge.net/project/moa-datastream/Datasets/Classification/elecNormNew.arff.zip?r=http%3A%2F%2Fmoa.cms.waikato.ac.nz%2Fdatasets%2F&ts=1483128450&use_mirror=cytranet).
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 数据文件是位于[http://downloads.sourceforge.net/project/moa-datastream/Datasets/Classification/elecNormNew.arff.zip?r=http%3A%2F%2Fmoa.cms.waikato.ac.nz%2Fdatasets%2F&ts=1483128450&use_mirror=cytranet](http://downloads.sourceforge.net/project/moa-datastream/Datasets/Classification/elecNormNew.arff.zip?r=http%3A%2F%2Fmoa.cms.waikato.ac.nz%2Fdatasets%2F&ts=1483128450&use_mirror=cytranet)的ARFF格式的公开文件。
- en: Data sampling and transformation
  id: totrans-586
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据采样和转换
- en: In the experiments conducted here, no data sampling is done; each example in
    the dataset is processed individually and no example is excluded. All numeric
    data elements have been normalized to a value between 0 and 1.
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里进行的实验中，没有进行数据采样；数据集中的每个示例都是单独处理的，没有示例被排除。所有数值数据元素都已归一化到0到1之间。
- en: Feature analysis and dimensionality reduction
  id: totrans-588
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征分析和降维
- en: 'The ELEC dataset has 45,312 records with nine features, including the target
    class. The features class and day are nominal (categorical), all others are numeric
    (continuous). The features are listed in *Table 1* and *Table 2* and give descriptive
    statistics for the ELEC dataset:'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: ELEC数据集包含45,312条记录，有九个特征，包括目标类别。特征class和day是名义的（分类的），其余都是数值的（连续的）。特征列在*表1*和*表2*中，并给出了ELEC数据集的描述性统计：
- en: '| Name | Data Type | Description |'
  id: totrans-590
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 数据类型 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-591
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| class | nominal | UP, DOWN—direction of price movement relative to 24-hour
    moving average |'
  id: totrans-592
  prefs: []
  type: TYPE_TB
  zh: '| class | nominal | UP, DOWN—相对于24小时移动平均的价格变动方向 |'
- en: '| date | continuous | Date price recorded |'
  id: totrans-593
  prefs: []
  type: TYPE_TB
  zh: '| date | continuous | 记录价格日期 |'
- en: '| day | nominal | Day of the week (1-7) |'
  id: totrans-594
  prefs: []
  type: TYPE_TB
  zh: '| day | nominal | 星期几（1-7） |'
- en: '| period | continuous |   |'
  id: totrans-595
  prefs: []
  type: TYPE_TB
  zh: '| period | continuous |   |'
- en: '| nswprice | continuous | Electricity price in NSW |'
  id: totrans-596
  prefs: []
  type: TYPE_TB
  zh: '| nswprice | continuous | 新南威尔士州的电力价格 |'
- en: '| nswdemand | continuous | Electricity demand in NSW |'
  id: totrans-597
  prefs: []
  type: TYPE_TB
  zh: '| nswdemand | continuous | 新南威尔士州的电力需求 |'
- en: '| vicprice | continuous | Electricity price in Victoria |'
  id: totrans-598
  prefs: []
  type: TYPE_TB
  zh: '| vicprice | continuous | 维多利亚的电力价格 |'
- en: '| vicdemand | continuous | Electricity demand in Victoria |'
  id: totrans-599
  prefs: []
  type: TYPE_TB
  zh: '| vicdemand | continuous | 维多利亚的电力需求 |'
- en: '| transfer | integer |   |'
  id: totrans-600
  prefs: []
  type: TYPE_TB
  zh: '| transfer | integer |   |'
- en: '*Table 1\. ELEC dataset features*'
  id: totrans-601
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*表1. ELEC数据集特征*'
- en: '|   | count | mean | std | 25% | 50% | 75% |'
  id: totrans-602
  prefs: []
  type: TYPE_TB
  zh: '|   | count | mean | std | 25% | 50% | 75% |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-603
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| date | 45312 | 0.49908 | 0.340308 | 0.031934 | 0.456329 | 0.880547 |'
  id: totrans-604
  prefs: []
  type: TYPE_TB
  zh: '| date | 45312 | 0.49908 | 0.340308 | 0.031934 | 0.456329 | 0.880547 |'
- en: '| period | 45312 | 0.5 | 0.294756 | 0.25 | 0.5 | 0.75 |'
  id: totrans-605
  prefs: []
  type: TYPE_TB
  zh: '| period | 45312 | 0.5 | 0.294756 | 0.25 | 0.5 | 0.75 |'
- en: '| nswprice | 45312 | 0.057868 | 0.039991 | 0.035127 | 0.048652 | 0.074336 |'
  id: totrans-606
  prefs: []
  type: TYPE_TB
  zh: '| nswprice | 45312 | 0.057868 | 0.039991 | 0.035127 | 0.048652 | 0.074336 |'
- en: '| nswdemand | 45312 | 0.425418 | 0.163323 | 0.309134 | 0.443693 | 0.536001
    |'
  id: totrans-607
  prefs: []
  type: TYPE_TB
  zh: '| nswdemand | 45312 | 0.425418 | 0.163323 | 0.309134 | 0.443693 | 0.536001
    |'
- en: '| vicprice | 45312 | 0.003467 | 0.010213 | 0.002277 | 0.003467 | 0.003467 |'
  id: totrans-608
  prefs: []
  type: TYPE_TB
  zh: '| vicprice | 45312 | 0.003467 | 0.010213 | 0.002277 | 0.003467 | 0.003467 |'
- en: '| vicdemand | 45312 | 0.422915 | 0.120965 | 0.372346 | 0.422915 | 0.469252
    |'
  id: totrans-609
  prefs: []
  type: TYPE_TB
  zh: '| vicdemand | 45312 | 0.422915 | 0.120965 | 0.372346 | 0.422915 | 0.469252
    |'
- en: '| transfer | 45312 | 0.500526 | 0.153373 | 0.414912 | 0.414912 | 0.605702 |'
  id: totrans-610
  prefs: []
  type: TYPE_TB
  zh: '| transfer | 45312 | 0.500526 | 0.153373 | 0.414912 | 0.414912 | 0.605702 |'
- en: '*Table 2\. Descriptive statistics of ELEC dataset features*'
  id: totrans-611
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*表2. ELEC数据集特征的描述性统计*'
- en: The feature reduction step is omitted here as it is in most stream-based learning.
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 特征降维步骤在此省略，因为它在大多数基于流的机器学习中是常见的。
- en: Models, results, and evaluation
  id: totrans-613
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型、结果和评估
- en: The experiments are divided into classification, concept drift, clustering,
    and outlier detection. Details of the learning process for each set of experiments
    and the results of the experiments are given here.
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 实验被分为分类、概念漂移、聚类和异常检测。每个实验集的学习过程细节和实验结果在此给出。
- en: Supervised learning experiments
  id: totrans-615
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督学习实验
- en: For this set of experiments, a choice of linear, non-linear, and ensemble learners
    were chosen in order to illustrate the behavior of a variety of classifiers. **Stochastic
    Gradient Descent** (**SGD**), which uses a linear SVM, and Naïve Bayes are the
    linear classifiers, while Lazy k-NN is the non-linear classifier. For ensemble
    learning, we use two meta-learners, **Leveraging Bagging** (**LB**) and OxaBag,
    with different linear and non-linear base learners such as SGD, Naïve Bayes, and
    Hoeffding Trees. The algorithm used in OxaBag is described in the section on ensemble
    algorithms. In LB, the weight factor used for resampling is variable (the default
    value of 6 is used here) whereas the weight in OxaBag is fixed at 1.
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 在这组实验中，选择线性、非线性以及集成学习器，以展示各种分类器的行为。**随机梯度下降**（**SGD**），使用线性SVM，以及朴素贝叶斯是线性分类器，而懒惰k-NN是非线性分类器。对于集成学习，我们使用两个元学习器，**利用袋装**（**LB**）和OxaBag，以及不同的线性和非线性基学习器，如SGD、朴素贝叶斯和Hoeffding树。OxaBag中使用的算法在集成算法部分进行了描述。在LB中，用于重采样的权重因子是可变的（这里使用默认值6），而OxaBag中的权重是固定的，为1。
- en: 'Prequential evaluation is chosen for all the classification methods, so each
    example is first tested against the prediction with the existing model, and then
    used for training the model. This requires the selection of a window width, and
    the performance of the various models for different values of the window width
    are listed in *Table 3*. Widths of 100, 500, 1,000, and 5,000 elements were used:'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 预先评估被选用于所有分类方法，因此每个示例首先与现有模型的预测进行测试，然后用于训练模型。这需要选择窗口宽度，不同窗口宽度值下各种模型的性能列于*表3*。使用了100、500、1000和5000个元素的宽度：
- en: '| Algorithm | Window width | Evaluation time (CPU seconds) | Model cost (RAM-Hours)
    | Classifications correct (percent) | Kappa Statistic (percent) |'
  id: totrans-618
  prefs: []
  type: TYPE_TB
  zh: '| 算法 | 窗口宽度 | 评估时间（CPU秒） | 模型成本（RAM小时） | 分类正确率（百分比） | Kappa 统计量（百分比） |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-619
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| SGD | 100 | 0.5781 | 3.76E-10 | 67 | 0 |'
  id: totrans-620
  prefs: []
  type: TYPE_TB
  zh: '| SGD | 100 | 0.5781 | 3.76E-10 | 67 | 0 |'
- en: '| SGD | 500 | 0.5781 | 3.76E-10 | 55.6 | 0 |'
  id: totrans-621
  prefs: []
  type: TYPE_TB
  zh: '| SGD | 500 | 0.5781 | 3.76E-10 | 55.6 | 0 |'
- en: '| SGD | 1000 | 0.5469 | 3.55E-10 | 53.3 | 0 |'
  id: totrans-622
  prefs: []
  type: TYPE_TB
  zh: '| SGD | 1000 | 0.5469 | 3.55E-10 | 53.3 | 0 |'
- en: '| SGD | 5000 | 0.5469 | 3.55E-10 | 53.78 | 0 |'
  id: totrans-623
  prefs: []
  type: TYPE_TB
  zh: '| SGD | 5000 | 0.5469 | 3.55E-10 | 53.78 | 0 |'
- en: '| NaiveBayes | 100 | 0.7656 | 8.78E-10 | 86 | 65.7030 |'
  id: totrans-624
  prefs: []
  type: TYPE_TB
  zh: '| NaiveBayes | 100 | 0.7656 | 8.78E-10 | 86 | 65.7030 |'
- en: '| NaiveBayes | 500 | 0.6094 | 8.00E-10 | 82.2 | 62.6778 |'
  id: totrans-625
  prefs: []
  type: TYPE_TB
  zh: '| NaiveBayes | 500 | 0.6094 | 8.00E-10 | 82.2 | 62.6778 |'
- en: '| NaiveBayes | 1000 | 0.6719 | 7.77E-10 | 75.3 | 48.8583 |'
  id: totrans-626
  prefs: []
  type: TYPE_TB
  zh: '| NaiveBayes | 1000 | 0.6719 | 7.77E-10 | 75.3 | 48.8583 |'
- en: '| NaiveBayes | 5000 | 0.6406 | 7.35E-10 | 77.84 | 54.1966 |'
  id: totrans-627
  prefs: []
  type: TYPE_TB
  zh: '| NaiveBayes | 5000 | 0.6406 | 7.35E-10 | 77.84 | 54.1966 |'
- en: '| kNN | 100 | 34.6406 | 4.66E-06 | 74 | 36.3057 |'
  id: totrans-628
  prefs: []
  type: TYPE_TB
  zh: '| kNN | 100 | 34.6406 | 4.66E-06 | 74 | 36.3057 |'
- en: '| kNN | 500 | 34.5469 | 4.65E-06 | 79.8 | 59.1424 |'
  id: totrans-629
  prefs: []
  type: TYPE_TB
  zh: '| kNN | 500 | 34.5469 | 4.65E-06 | 79.8 | 59.1424 |'
- en: '| kNN | 1000 | 35.8750 | 4.83E-06 | 82.5 | 64.8049 |'
  id: totrans-630
  prefs: []
  type: TYPE_TB
  zh: '| kNN | 1000 | 35.8750 | 4.83E-06 | 82.5 | 64.8049 |'
- en: '| kNN | 5000 | 35.0312 | 4.71E-06 | 80.32 | 60.4594 |'
  id: totrans-631
  prefs: []
  type: TYPE_TB
  zh: '| kNN | 5000 | 35.0312 | 4.71E-06 | 80.32 | 60.4594 |'
- en: '| LB-kNN | 100 | 637.8125 | 2.88E-04 | 74 | 36.3057 |'
  id: totrans-632
  prefs: []
  type: TYPE_TB
  zh: '| LB-kNN | 100 | 637.8125 | 2.88E-04 | 74 | 36.3057 |'
- en: '| LB-kNN | 500 | 638.9687 | 2.89E-04 | 79.8 | 59.1424 |'
  id: totrans-633
  prefs: []
  type: TYPE_TB
  zh: '| LB-kNN | 500 | 638.9687 | 2.89E-04 | 79.8 | 59.1424 |'
- en: '| LB-kNN | 1000 | 655.8125 | 2.96E-04 | 82.4 | 64.5802 |'
  id: totrans-634
  prefs: []
  type: TYPE_TB
  zh: '| LB-kNN | 1000 | 655.8125 | 2.96E-04 | 82.4 | 64.5802 |'
- en: '| LB-kNN | 5000 | 667.6094 | 3.02E-04 | 80.66 | 61.0965 |'
  id: totrans-635
  prefs: []
  type: TYPE_TB
  zh: '| LB-kNN | 5000 | 667.6094 | 3.02E-04 | 80.66 | 61.0965 |'
- en: '| LB-HoeffdingTree | 100 | 13.6875 | 2.98E-06 | 91 | 79.1667 |'
  id: totrans-636
  prefs: []
  type: TYPE_TB
  zh: '| LB-HoeffdingTree | 100 | 13.6875 | 2.98E-06 | 91 | 79.1667 |'
- en: '| LB-HoeffdingTree | 500 | 13.5781 | 2.96E-06 | 93 | 85.8925 |'
  id: totrans-637
  prefs: []
  type: TYPE_TB
  zh: '| LB-HoeffdingTree | 500 | 13.5781 | 2.96E-06 | 93 | 85.8925 |'
- en: '| LB-HoeffdingTree | 1000 | 12.5625 | 2.74E-06 | 92.1 | 84.1665 |'
  id: totrans-638
  prefs: []
  type: TYPE_TB
  zh: '| LB-HoeffdingTree | 1000 | 12.5625 | 2.74E-06 | 92.1 | 84.1665 |'
- en: '| LB-HoeffdingTree | 5000 | 12.7656 | 2.78E-06 | 90.74 | 81.3184 |'
  id: totrans-639
  prefs: []
  type: TYPE_TB
  zh: '| LB-HoeffdingTree | 5000 | 12.7656 | 2.78E-06 | 90.74 | 81.3184 |'
- en: '*Table 3\. Classifier performance for different window sizes*'
  id: totrans-640
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*表3. 不同窗口大小的分类器性能*'
- en: 'For the algorithms in *Table 4*, the performance was the same for each value
    of the window width used:'
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: 对于表4中的算法，使用不同窗口宽度值时的性能相同：
- en: '| Algorithm | Evaluation time (CPU seconds) | Model cost (RAM-Hours) | Classifications
    correct (percent) | Kappa Statistic (percent) |'
  id: totrans-642
  prefs: []
  type: TYPE_TB
  zh: '| 算法 | 评估时间（CPU秒） | 模型成本（RAM小时） | 分类正确率（百分比） | Kappa 统计量（百分比） |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-643
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| HoeffdingTree | 1.1562 | 3.85E-08 | 79.1953 | 57.2266 |'
  id: totrans-644
  prefs: []
  type: TYPE_TB
  zh: '| HoeffdingTree | 1.1562 | 3.85E-08 | 79.1953 | 57.2266 |'
- en: '| HoeffdingAdaptiveTree | 2.0469 | 2.84E-09 | 83.3863 | 65.5569 |'
  id: totrans-645
  prefs: []
  type: TYPE_TB
  zh: '| HoeffdingAdaptiveTree | 2.0469 | 2.84E-09 | 83.3863 | 65.5569 |'
- en: '| OzaBag-NaiveBayes | 2.01562 | 1.57E-08 | 73.4794 | 42.7636 |'
  id: totrans-646
  prefs: []
  type: TYPE_TB
  zh: '| OzaBag-NaiveBayes | 2.01562 | 1.57E-08 | 73.4794 | 42.7636 |'
- en: '| OzaBagAdwin-HoeffdingTree | 5.7812 | 2.26E-07 | 84.3485 | 67.5221 |'
  id: totrans-647
  prefs: []
  type: TYPE_TB
  zh: '| OzaBagAdwin-HoeffdingTree | 5.7812 | 2.26E-07 | 84.3485 | 67.5221 |'
- en: '| LB-SGD | 2 | 1.67E-08 | 57.6977 | 3.0887 |'
  id: totrans-648
  prefs: []
  type: TYPE_TB
  zh: '| LB-SGD | 2 | 1.67E-08 | 57.6977 | 3.0887 |'
- en: '| LB-NaiveBayes | 3.5937 | 3.99E-08 | 78.8753 | 55.7639 |'
  id: totrans-649
  prefs: []
  type: TYPE_TB
  zh: '| LB-NaiveBayes | 3.5937 | 3.99E-08 | 78.8753 | 55.7639 |'
- en: '*Table 4\. Performance of classifiers (same for all window widths used)*'
  id: totrans-650
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*表 4\. 分类器性能（所有窗口宽度相同）*'
- en: Concept drift experiments
  id: totrans-651
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 概念漂移实验
- en: 'In this experiment, we continue using EvaluatePrequential when configuring
    the classification task. This time we select the `DriftDetectionMethodClassifier`
    as the learner and DDM as the drift detection method. This demonstrates adapting
    to an evolving data stream. Base learners used and the results obtained are shown
    in *Table 5*:'
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们继续使用 EvaluatePrequential 来配置分类任务。这次我们选择 `DriftDetectionMethodClassifier`
    作为学习器，DDM 作为漂移检测方法。这展示了适应不断变化的数据流。使用的基学习器和获得的结果显示在 *表 5* 中：
- en: '| Algorithm | Evaluation time (CPU seconds) | Model cost (RAM-Hours) | Classifications
    correct (percent) | Kappa Statistic (percent) | Change detected |'
  id: totrans-653
  prefs: []
  type: TYPE_TB
  zh: '| 算法 | 评估时间（CPU秒） | 模型成本（RAM小时） | 分类正确率（百分比） | Kappa 统计量（百分比） | 变化检测 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-654
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| SGD | 0.307368829 | 1.61E-09 | 53.3 | 0 | 132 |'
  id: totrans-655
  prefs: []
  type: TYPE_TB
  zh: '| SGD | 0.307368829 | 1.61E-09 | 53.3 | 0 | 132 |'
- en: '| Naïve-Bayes | 0.298290727 | 1.58E-09 | 86.6 | 73.03986 | 143 |'
  id: totrans-656
  prefs: []
  type: TYPE_TB
  zh: '| Naïve-Bayes | 0.298290727 | 1.58E-09 | 86.6 | 73.03986 | 143 |'
- en: '| Lazy-kNN | 10.34161893 | 1.74E-06 | 87.4 | 74.8498 | 12 |'
  id: totrans-657
  prefs: []
  type: TYPE_TB
  zh: '| Lazy-kNN | 10.34161893 | 1.74E-06 | 87.4 | 74.8498 | 12 |'
- en: '| HoeffdingTree | 0.472981754 | 5.49E-09 | 86.2 | 72.19816 | 169 |'
  id: totrans-658
  prefs: []
  type: TYPE_TB
  zh: '| HoeffdingTree | 0.472981754 | 5.49E-09 | 86.2 | 72.19816 | 169 |'
- en: '| HoeffdingAdaptiveTree | 0.598665043 | 7.19E-09 | 84 | 67.80878 | 155 |'
  id: totrans-659
  prefs: []
  type: TYPE_TB
  zh: '| HoeffdingAdaptiveTree | 0.598665043 | 7.19E-09 | 84 | 67.80878 | 155 |'
- en: '| LB-SGD | 0.912737325 | 2.33E-08 | 53.3 | 0 | 132 |'
  id: totrans-660
  prefs: []
  type: TYPE_TB
  zh: '| LB-SGD | 0.912737325 | 2.33E-08 | 53.3 | 0 | 132 |'
- en: '| LB-NaiveBayes | 1.990137758 | 3.61E-08 | 85.7 | 71.24056 | 205 |'
  id: totrans-661
  prefs: []
  type: TYPE_TB
  zh: '| LB-NaiveBayes | 1.990137758 | 3.61E-08 | 85.7 | 71.24056 | 205 |'
- en: '| OzaBag-NaiveBayes | 1.342189725 | 2.29E-08 | 77.4 | 54.017 | 211 |'
  id: totrans-662
  prefs: []
  type: TYPE_TB
  zh: '| OzaBag-NaiveBayes | 1.342189725 | 2.29E-08 | 77.4 | 54.017 | 211 |'
- en: '| LB-kNN | 173.3624715 | 1.14E-04 | 87.5 | 75.03296 | 4 |'
  id: totrans-663
  prefs: []
  type: TYPE_TB
  zh: '| LB-kNN | 173.3624715 | 1.14E-04 | 87.5 | 75.03296 | 4 |'
- en: '| LB-HoeffdingTree | 5.660440101 | 1.61E-06 | 91.3 | 82.56317 | 59 |'
  id: totrans-664
  prefs: []
  type: TYPE_TB
  zh: '| LB-HoeffdingTree | 5.660440101 | 1.61E-06 | 91.3 | 82.56317 | 59 |'
- en: '| OzaBag-HoeffdingTree | 4.306455545 | 3.48E-07 | 85.4 | 70.60209 | 125 |'
  id: totrans-665
  prefs: []
  type: TYPE_TB
  zh: '| OzaBag-HoeffdingTree | 4.306455545 | 3.48E-07 | 85.4 | 70.60209 | 125 |'
- en: '*Table 5\. Performance of classifiers with concept drift detection*'
  id: totrans-666
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*表 5\. 具有概念漂移检测的分类器性能*'
- en: Clustering experiments
  id: totrans-667
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚类实验
- en: 'Almost all of the clustering algorithms implemented in the MOA tool were used
    in this experiment. Both extrinsic and intrinsic evaluation results were collected
    and are tabulated in *Table 6*. CMM, homogeneity, and completeness were defined
    earlier in this chapter. We have encountered Purity and Silhouette coefficients
    before, from the discussion in [Chapter 3](ch03.html "Chapter 3. Unsupervised
    Machine Learning Techniques"), *Unsupervised Machine Learning Techniques*. SSQ
    is the sum of squared distances of instances from their respective cluster centers;
    the lower the value of SSQ, the better. The use of micro-clustering is indicated
    by *m = 1* in the table. How often the macro-clusters are calculated is determined
    by the selected time horizon *h*, in instances:'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有在 MOA 工具中实现的聚类算法都用于这次实验。收集了外部和内部评估结果，并已在 *表 6* 中列出。CMM、同质性和完整性在本章前面已定义。我们之前在
    [第 3 章](ch03.html "第 3 章。无监督机器学习技术") 的讨论中遇到过纯度和轮廓系数，*无监督机器学习技术*。SSQ 是实例与其各自簇中心距离平方和；SSQ
    的值越低，越好。表中 *m = 1* 表示使用微聚类。宏簇计算的频率由所选的时间跨度 *h* 决定，例如：
- en: '| Algorithm | CMM | Homogeneity | Completeness | Purity | SSQ | Silhouette
    Coefficient |'
  id: totrans-669
  prefs: []
  type: TYPE_TB
  zh: '| 算法 | CMM | 同质性 | 完整性 | 纯度 | SSQ | 轮廓系数 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-670
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| Clustream With k-Means (h = 5000; k = 2; m = 1) | 0.7168 | -1.0000 | 0.1737
    | 0.9504 | 9.1975 | 0.5687 |'
  id: totrans-671
  prefs: []
  type: TYPE_TB
  zh: '| Clustream With k-Means (h = 5000; k = 2; m = 1) | 0.7168 | -1.0000 | 0.1737
    | 0.9504 | 9.1975 | 0.5687 |'
- en: '| Clustream With k-Means(h = 1000; k = 5) | 0.5391 | -1.0000 | 0.8377 | 0.7238
    | 283.6543 | 0.8264 |'
  id: totrans-672
  prefs: []
  type: TYPE_TB
  zh: '| Clustream With k-Means(h = 1000; k = 5) | 0.5391 | -1.0000 | 0.8377 | 0.7238
    | 283.6543 | 0.8264 |'
- en: '| Clustream (h = 1000; m = 1) | 0.6241 | -1.0000 | 0.4363 | 0.9932 | 7.2734
    | 0.4936 |'
  id: totrans-673
  prefs: []
  type: TYPE_TB
  zh: '| Clustream (h = 1000; m = 1) | 0.6241 | -1.0000 | 0.4363 | 0.9932 | 7.2734
    | 0.4936 |'
- en: '| Denstream With DBSCAN (h = 1000) | 0.4455 | -1.0000 | 0.7586 | 0.9167 | 428.7604
    | 0.6682 |'
  id: totrans-674
  prefs: []
  type: TYPE_TB
  zh: '| Denstream With DBSCAN (h = 1000) | 0.4455 | -1.0000 | 0.7586 | 0.9167 | 428.7604
    | 0.6682 |'
- en: '| ClusTree (h = 5000; m = 1) | 0.7984 | 0.4874 | -0.4815 | 0.9489 | 11.7789
    | 0.6879 |'
  id: totrans-675
  prefs: []
  type: TYPE_TB
  zh: '| ClusTree (h = 5000; m = 1) | 0.7984 | 0.4874 | -0.4815 | 0.9489 | 11.7789
    | 0.6879 |'
- en: '| ClusTree (h = 1000; m = 1) | 0.7090 | -1.0000 | 0.3979 | 0.9072 | 13.4190
    | 0.5385 |'
  id: totrans-676
  prefs: []
  type: TYPE_TB
  zh: '| ClusTree (h = 1000; m = 1) | 0.7090 | -1.0000 | 0.3979 | 0.9072 | 13.4190
    | 0.5385 |'
- en: '| AbstractC | 1.0000 | 1.0000 | -8.1354 | 1.0000 | 0.0000 | 0.0000 |'
  id: totrans-677
  prefs: []
  type: TYPE_TB
  zh: '| AbstractC | 1.0000 | 1.0000 | -8.1354 | 1.0000 | 0.0000 | 0.0000 |'
- en: '| MCOD (w = 1000) | 1.0000 | 1.0000 | -8.1354 | 1.0000 | 0.0000 | 0.0000 |'
  id: totrans-678
  prefs: []
  type: TYPE_TB
  zh: '| MCOD (w = 1000) | 1.0000 | 1.0000 | -8.1354 | 1.0000 | 0.0000 | 0.0000 |'
- en: Outlier detection experiments
  id: totrans-679
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异常检测实验
- en: 'In the final set of experiments, five outlier detection algorithms were used
    to process the ELEC dataset. Results are given in *Table 7*:'
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: 在最终的实验集中，使用了五种异常检测算法来处理 ELEC 数据集。结果见 *表 7*：
- en: '| Algorithm | Nodes always inlier | Nodes always outlier | Nodes both inlier
    and outlier |'
  id: totrans-681
  prefs: []
  type: TYPE_TB
  zh: '| 算法 | 始终内节点的节点 | 始终异常节点的节点 | 同时内节点和异常节点的节点 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-682
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| MCOD | 42449 (93.7%) | 302 (0.7%) | 2561 (5.7%) |'
  id: totrans-683
  prefs: []
  type: TYPE_TB
  zh: '| MCOD | 42449 (93.7%) | 302 (0.7%) | 2561 (5.7%) |'
- en: '| ApproxSTORM | 41080 (90.7%) | 358 (0.8%) | 3874 (8.5%) |'
  id: totrans-684
  prefs: []
  type: TYPE_TB
  zh: '| ApproxSTORM | 41080 (90.7%) | 358 (0.8%) | 3874 (8.5%) |'
- en: '| SimpleCOD | 42449 (93.7%) | 302 (0.7%) | 2561 (5.7%) |'
  id: totrans-685
  prefs: []
  type: TYPE_TB
  zh: '| SimpleCOD | 42449 (93.7%) | 302 (0.7%) | 2561 (5.7%) |'
- en: '| AbstractC | 42449 (93.7%) | 302 (0.7%) | 2561 (5.7%) |'
  id: totrans-686
  prefs: []
  type: TYPE_TB
  zh: '| AbstractC | 42449 (93.7%) | 302 (0.7%) | 2561 (5.7%) |'
- en: '| ExactSTORM | 42449 (93.7%) | 302 (0.7%) | 2561 (5.7%) |'
  id: totrans-687
  prefs: []
  type: TYPE_TB
  zh: '| ExactSTORM | 42449 (93.7%) | 302 (0.7%) | 2561 (5.7%) |'
- en: '*Table 7\. Evaluation of outlier detection*'
  id: totrans-688
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*表 7\. 异常检测评估*'
- en: 'The following plots (*Figure 6*) show results for three pairs of features after
    running algorithm Abstract-C on the entire dataset. In each of the plots, it is
    easy to see the outliers identified by the circles surrounding the data points.
    Although it is difficult to visualize the outliers spatially in multiple dimensions
    simultaneously, the set bi-variate plots give some indication of the result of
    outlier detection methods applied in a stream-based setting:'
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表 (*图 6*) 展示了在运行算法 Abstract-C 对整个数据集进行处理后，三个特征对的实验结果。在每一个图表中，都很容易看到围绕数据点的圆圈所标识的异常值。尽管在多个维度上同时可视化异常值是困难的，但双变量散点图给出了一些在基于流的设置中应用异常检测方法的检测结果：
- en: '![Outlier detection experiments](img/B05137_05_343.jpg)![Outlier detection
    experiments](img/B05137_05_344.jpg)![Outlier detection experiments](img/B05137_05_345.jpg)'
  id: totrans-690
  prefs: []
  type: TYPE_IMG
  zh: '![异常检测实验](img/B05137_05_343.jpg)![异常检测实验](img/B05137_05_344.jpg)![异常检测实验](img/B05137_05_345.jpg)'
- en: Figure 6\. Outlier detection using Abstract-C, for three pairs of features,
    after processing all 45,300 instances
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6\. 使用 Abstract-C 对 45,300 个实例进行处理后，对三个特征对进行异常检测
- en: 'The image in *Figure 7* shows a screenshot from MOA when two algorithms, `Angiulli.ExactSTORM`
    and `Angiulli.ApproxSTORM`, were run simultaneously; a bivariate scatter-plot
    for each algorithm is shown side-by-side, accompanied by a comparison of the per-object
    processing time:'
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7* 中的图像显示了 MOA 的一个截图，其中同时运行了两个算法，`Angiulli.ExactSTORM` 和 `Angiulli.ApproxSTORM`；每个算法的双变量散点图并排显示，并附有每个对象的处理时间比较：'
- en: '![Outlier detection experiments](img/B05137_05_346.jpg)'
  id: totrans-693
  prefs: []
  type: TYPE_IMG
  zh: '![异常检测实验](img/B05137_05_346.jpg)'
- en: Figure 7\. Visualization of outlier detection in MOA
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7\. MOA 中异常检测的可视化
- en: Analysis of stream learning results
  id: totrans-695
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流学习结果分析
- en: Based on the evaluation of the learned models from the classification, clustering,
    and outlier detection experiments, analysis reveals several interesting observations.
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: 基于分类、聚类和异常检测实验中学习到的模型的评估，分析揭示了几个有趣的观察结果。
- en: 'Classification experiments:'
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: 分类实验：
- en: Performance improves from linear to non-linear algorithms in quite a significant
    way as shown in Table 3\. Linear SGD has the best performance using an accuracy
    metric of 67%, while KNN and Hoeffding Tree show 82.4 to 93%. This clearly shows
    that the problem is non-linear and using a non-linear algorithm will give better
    performance.
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如表 3 所示，性能从线性算法到非线性算法有相当显著的提升。线性 SGD 使用准确率指标达到 67% 的最佳性能，而 KNN 和 Hoeffding Tree
    显示 82.4 到 93%。这清楚地表明，问题是非线性的，使用非线性算法将提供更好的性能。
- en: K-NNs give good performance but come at the cost of evaluation time, as shown
    in Table 3\. Evaluation time as well as memory are significantly higher—about
    two orders of magnitude—than the linear methods. When the model has to perform
    in tighter evaluation cycles, extreme caution in choosing algorithms such as KNNs
    must be observed.
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K-NNs 提供了良好的性能，但代价是评估时间，如表 3 所示。评估时间和内存都显著更高——大约高两个数量级——比线性方法。当模型需要在更紧的评估周期中运行时，必须非常谨慎地选择算法，如
    KNNs。
- en: Hoeffding Trees gives the best classification rate and Kappa statistic. The
    evaluation time is also not as high as KNNs but is still in the order of seconds,
    which may or may not be acceptable in many real-time stream-based applications.
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 霍夫丁树提供了最佳的分类率和Kappa统计量。评估时间也不如KNNs高，但仍然在秒的量级，这在许多基于实时流的应用中可能或可能不是可接受的。
- en: The evaluation time of Naive Bayes is the lowest—though not much different from
    SGD—and with the right choice of window width can give performance second only
    to Hoeffding Trees. For example, at width 100, we have a classification rate of
    86 with Naïve Bayes, which is next best to 93 of Hoeffding Trees but compared
    to over 13 seconds, Naïve Bayes takes only 0.76 seconds, as shown in *Table 3*.
  id: totrans-701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朴素贝叶斯的评估时间最低——尽管与SGD没有太大区别——并且通过选择合适的窗口宽度，可以提供仅次于霍夫丁树的性能。例如，在宽度100时，朴素贝叶斯有86%的分类率，仅次于霍夫丁树的93%，但与超过13秒的评估时间相比，朴素贝叶斯只需0.76秒，如表3所示。
- en: Keeping the window width constant, there is a clear pattern of improvement from
    linear (SGD, Naïve Bayes) to non-linear (Hoeffding Trees) to ensemble based (OzaBag,
    Adwin, Hoeffding Tree) shown in Table 4\. This clearly shows that in theory, the
    choice of ensembles can help reduce the errors but comes at the cost of foregoing
    interpretability in the models.
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持窗口宽度不变，从线性（SGD，朴素贝叶斯）到非线性（霍夫丁树）再到基于集成（OzaBag，Adwin，霍夫丁树）的改进模式在表4中清晰展示。这清楚地表明，理论上，集成选择可以帮助减少错误，但代价是模型的可解释性降低。
- en: '*Table 5*, when compared to *Table 3* and *Table 4*, shows why having drift
    protection and learning with automated drift detection increases robustness. Ensemble-based
    learning of OzaBag-NaiveBayes, OzaBag-HoeffdingTrees, and OzaBag-HoeffdingAdaptiveTree
    all show improvements over the non- drift protected runs as an example.'
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与表3和表4相比，*表5*显示了为什么具有漂移保护和使用自动漂移检测进行学习可以增加鲁棒性。基于集成的OzaBag-NaiveBayes、OzaBag-HoeffdingTrees和OzaBag-HoeffdingAdaptiveTree的学习都显示出比非漂移保护运行更好的改进。
- en: 'Clustering experiments:'
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类实验：
- en: From the first two models in *Table 6*, we see that k-Means, with a horizon
    of 5,000 instances and *k* of 2, exhibits higher purity, higher CMM, and lower
    SSQ compared to the model with a smaller horizon and *k* of 5\. In the complete
    set of results (available on this book's website, see link below), one can see
    that the effect of the larger horizon is the predominant factor responsible for
    the differences.
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从表6的前两个模型中，我们可以看到，k-Means在5,000个实例的视域和k值为2的情况下，与视域较小且k值为5的模型相比，具有更高的纯度、更高的CMM和更低的SSQ。在完整的结果集中（可在本书网站上找到，见下文链接），可以看到较大视域的影响是导致差异的主要因素。
- en: In the clustering models using micro-clustering, the SSQ is typically significantly
    smaller than when no micro-clustering is used. This is understandable, as there
    are far more clusters and fewer instances per cluster, and SSQ is measured with
    respect to the cluster center.
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用微聚类的聚类模型中，SSQ通常比不使用微聚类时显著更小。这是可以理解的，因为存在更多的簇和每个簇的实例更少，SSQ是相对于簇中心来衡量的。
- en: DBSCAN was found to be insensitive to micro-clustering, and size of the horizon.
    Compared to all other models, it ranks high on both intrinsic (Silhouette coefficient)
    as well as extrinsic measures (Completeness, Purity).
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DBSCAN被发现对微聚类和视域大小不敏感。与其他所有模型相比，它在内在度量（轮廓系数）以及外在度量（完整性，纯度）方面都排名很高。
- en: The two ClusTree models have among the best CMM and Purity scores, with low
    SSQ due to micro-clusters.
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个ClusTree模型在CMM和纯度分数方面表现最佳，由于微聚类导致低SSQ。
- en: The final two outlier-based clustering algorithms have perfect CMM and Purity
    scores. The metrics are not significantly affected by the window size (although
    this impacts the evaluation time), or the value of k, the neighbor count threshold.
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后两个基于异常值聚类的算法具有完美的CMM和纯度分数。这些指标不受窗口大小（尽管这会影响评估时间）或k值（邻居计数阈值）的影响。
- en: 'Outlier detection experiments:'
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值检测实验：
- en: All the techniques in this set of experiments performed equally well, with the
    exception of ApproxSTORM, which is to be expected considering the reduced window
    used in this method compared to the exact version.
  id: totrans-711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本组实验中，所有技术表现相当，唯一的例外是ApproxSTORM，考虑到与精确版本相比，该方法使用的窗口减少，这是可以预料的。
- en: The ratio of instances, always inlier versus those always outlier, is close
    to 140 for the majority of the models. Whether this implies adequate discriminatory
    power for a given dataset depends on the goals of the real-time learning problem.
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实例之间的比例，总是内点与总是外点之间的比例，对于大多数模型来说接近140。这是否意味着对于给定的数据集具有足够的判别能力取决于实时学习问题的目标。
- en: Note
  id: totrans-713
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'All MOA configuration files and results from the experiments are available
    at: [https://github.com/mjmlbook/mastering-java-machine-learning/Chapter5](https://github.com/mjmlbook/mastering-java-machine-learning/Chapter5).'
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
  zh: 所有MOA配置文件和实验结果均可在以下网址获取：[https://github.com/mjmlbook/mastering-java-machine-learning/Chapter5](https://github.com/mjmlbook/mastering-java-machine-learning/Chapter5)。
- en: Summary
  id: totrans-715
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The assumptions in stream-based learning are different from batch-based learning,
    chief among them being upper bounds on operating memory and computation times.
    Running statistics using sliding windows or sampling must be computed in order
    to scale to a potentially infinite stream of data. We make the distinction between
    learning from stationary data, where it is assumed the generating data distribution
    is constant, and dynamic or evolving data, where concept drift must be accounted
    for. This is accomplished by techniques involving the monitoring of model performance
    changes or the monitoring of data distribution changes. Explicit and implicit
    adaptation methods are ways to adjust to the concept change.
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: 基于流的学习的假设与基于批次的学习的假设不同，其中最重要的是操作内存和计算时间上的上界。必须计算滑动窗口或采样的运行统计量，以便扩展到可能无限的数据流。我们区分了从静态数据学习的情况，其中假设生成数据分布是恒定的，以及动态或演变数据的情况，其中必须考虑概念漂移。这是通过涉及监控模型性能变化或监控数据分布变化的技巧来实现的。显式和隐式自适应方法是调整概念变化的方式。
- en: Several supervised and unsupervised learning methods have been adapted for incremental
    online learning. Supervised methods include linear, non-linear, and ensemble techniques,
    The HoeffdingTree is introduced which is particularly interesting due largely
    in part to its guarantees on upper bounds on error rates. Model validation techniques
    such as prequential evaluation are adaptations unique to incremental learning.
    For stationary supervised learning, evaluation measures are similar to those used
    in batch-based learning. Other measures are used in the case of evolving data
    streams.
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: 已经有几种监督学习和无监督学习方法被改编用于增量在线学习。监督方法包括线性、非线性以及集成技术，介绍了HoeffdingTree，它特别有趣，很大程度上是因为它对错误率上界提供了保证。模型验证技术，如预quential评估，是增量学习特有的改编。对于静态监督学习，评估指标与基于批次的学习方法中使用的相似。在演变数据流的情况下，使用其他指标。
- en: Clustering algorithms operating under fixed memory and time constraints typically
    use small memory buffers with standard techniques in a single pass. Issues specific
    to streaming must be considered during evaluations of clustering, such as aging,
    noise, and missed or misplaced points. Outlier detection in data streams is a
    relatively new and growing field. Extending ideas in clustering to anomaly detection
    has proved very effective.
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 在固定内存和时间约束下运行的聚类算法通常使用小内存缓冲区，并使用标准技术在单次遍历中使用。在评估聚类时必须考虑特定于流的问题，如老化、噪声、丢失或放置错误的数据点。数据流中的异常检测是一个相对较新且正在增长的领域。将聚类中的思想扩展到异常检测已被证明非常有效。
- en: The experiments in the case study in this chapter use the Java framework MOA,
    illustrating various stream-based learning techniques for supervised, clustering,
    and outlier detection.
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 本章案例研究中的实验使用Java框架MOA，展示了各种基于流的监督学习、聚类和异常检测技术。
- en: In the next chapter, we embark on a tour of the probabilistic graph modelling
    techniques that are useful in representing, eliciting knowledge, and learning
    in various domains.
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始探索在各个领域中用于表示、获取知识和学习的概率图建模技术。
- en: References
  id: totrans-721
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'G. Cormode and S. Muthukrishnan (2010). *An improved data stream summary: The
    Count-Min sketch and its applications*. Journal of Algorithms, 55(1):58–75, 2005.'
  id: totrans-722
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: G. Cormode和S. Muthukrishnan (2010). *改进的数据流摘要：Count-Min sketch及其应用*。算法杂志，55(1):58–75，2005。
- en: João Gama (2010). *Knowledge Discovery from Data Streams, Chapman and Hall /
    CRC Data Mining and Knowledge Discovery Series*, CRC Press 2010, ISBN 978-1-4398-2611-9,
    pp. I-XIX, 1-237.
  id: totrans-723
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: João Gama (2010). *从数据流中进行知识发现，Chapman and Hall / CRC数据挖掘与知识发现系列*，CRC Press
    2010，ISBN 978-1-4398-2611-9，第I-XIX页，1-237页。
- en: B. Babcock, M. Datar, R. Motwani (2002). *Sampling from a moving window over
    streaming data*, in Proceedings of the thirteenth annual ACM-SIAM symposium on
    Discrete algorithms, pp.633–634, 2002.
  id: totrans-724
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: B. Babcock，M. Datar，R. Motwani (2002)。*在流数据移动窗口上的抽样*，在第13届年度ACM-SIAM离散算法研讨会论文集，第633–634页，2002年。
- en: Bifet, A. and Gavalda, R. (2007). *Learning from time-changing data with adaptive
    windowing*. In Proceedings of SIAM int. conf. on Data Mining. SDM. 443–448.
  id: totrans-725
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bifet，A. 和 Gavalda，R. (2007). *使用自适应窗口从时间变化数据中学习*. 在SIAM国际数据挖掘会议论文集。SDM。443–448页。
- en: Vitter, J. (1985). *Random sampling with a reservoir. ACM Trans. Math. Softw*.
    11, 1, 37–57.
  id: totrans-726
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Vitter，J. (1985)。*带有水库的随机抽样. ACM数学软件交易*. 11，1，37–57页。
- en: Gama, J., Medas, P., Castillo, G., and Rodrigues, P. (2004). *Learning with
    drift detection*. In Proceedings of the 17th Brazilian symp. on Artif. Intell.
    SBIA. 286–295\.
  id: totrans-727
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gama，J.，Medas，P.，Castillo，G.，和 Rodrigues，P. (2004). *具有漂移检测的学习*. 在第17届巴西人工智能研讨会论文集，SBIA。286–295页。
- en: Gama, J., Sebastiao, R., and Rodrigues, P. 2013\. *On evaluating stream learning
    algorithms*. Machine Learning 90, 3, 317–346.
  id: totrans-728
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gama，J.，Sebastiao，R.，和 Rodrigues，P. (2013)。*评估流学习算法*. 机器学习90，3，317–346页。
- en: Domingos, P. and Hulten, G. (2000). *Mining high-speed data streams*. In Proceedings.
    of the 6th ACM SIGKDD int. conference on Knowledge discovery and data mining.
    KDD. 71–80.
  id: totrans-729
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Domingos，P. 和 Hulten，G. (2000). *挖掘高速数据流*. 在第6届ACM SIGKDD国际知识发现和数据挖掘会议论文集，KDD。71–80页。
- en: Oza, N. (2001). *Online ensemble learning*. Ph.D. thesis, University of California
    Berkeley.
  id: totrans-730
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Oza，N. (2001). *在线集成学习*. 博士学位论文，加州大学伯克利分校。
- en: Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M., Bouchachia, A. (2014).
    *A Survey on Concept Drift Adaptation.ACM Computing Surveys* 46(4), Article No.
    44.
  id: totrans-731
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gama，J.，Žliobaitė，I.，Bifet，A.，Pechenizkiy，M.，Bouchachia，A. (2014). *概念漂移适应综述*.
    ACM计算调查* 46(4)，文章编号44。
- en: Farnstrom, F., Lewis, J., and Elkan, C. (2000). *Scalability for clustering
    algorithms revisited*. SIGKDD Exploration, 51–57.
  id: totrans-732
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Farnstrom，F.，Lewis，J.，和 Elkan，C. (2000). *聚类算法的可扩展性回顾*. SIGKDD探索，51–57页。
- en: 'Zhang, T., Ramakrishnan, R., and Livny, M. (1996). *BIRCH: An Efficient Data
    Clustering Method for Very Large Databases*. In Proceedings of the ACM SIGMOD
    International Conference on Management of Data. ACM Press, 103–114.'
  id: totrans-733
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zhang，T.，Ramakrishnan，R.，和 Livny，M. (1996). *BIRCH：用于非常大数据库的高效数据聚类方法*. 在ACM
    SIGMOD国际数据管理会议论文集。ACM出版社，103–114页。
- en: Aggarwal, C. (2003). *A Framework for Diagnosing Changes in Evolving Data Streams*.
    In ACM SIGMOD Conference. 575–586.
  id: totrans-734
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Aggarwal，C. (2003). *诊断演变数据流中的变化框架*. 在ACM SIGMOD会议论文集。575–586页。
- en: 'Chen, Y. and Tu, L. (2007). *Density-based clustering for real-time stream
    data*. In KDD ''07: Proceedings of the 13th ACM SIGKDD international conference
    on knowledge discovery and data mining. ACM Press, 133–142.'
  id: totrans-735
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '陈，Y. 和 Tu，L. (2007). *基于密度的实时流数据聚类*. 在 KDD ''07: 第13届ACM SIGKDD国际知识发现和数据挖掘会议论文集。ACM出版社，133–142页。'
- en: Kremer, H., Kranen, P., Jansen, T., Seidl, T., Bifet, A., Holmes, G., and Pfahringer,
    B. (2011). *An effective evaluation measure for clustering on evolving data streams*.
    In proceedings of the 17th ACM SIGKDD international conference on knowledge discovery
    and data mining. KDD '11\. ACM, New York, NY, USA, 868–876.
  id: totrans-736
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kremer，H.，Kranen，P.，Jansen，T.，Seidl，T.，Bifet，A.，Holmes，G.，和 Pfahringer，B. (2011)。*用于演变数据流聚类的有效评估度量*.
    在第17届ACM SIGKDD国际知识发现和数据挖掘会议论文集，KDD '11。ACM，纽约，纽约，美国，868–876页。
- en: 'Mahdiraji, A. R. (2009). *Clustering data stream: A survey of algorithms*.
    International Journal of Knowledge-Based and Intelligent Engineering Systems,
    39–44.'
  id: totrans-737
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Mahdiraji，A. R. (2009). *数据流聚类：算法综述*. 国际基于知识和智能工程系统杂志，39–44页。
- en: F. Angiulli and F. Fassetti (2007). *Detecting distance-based outliers in streams
    of data*. In proceedings of the Sixteenth ACM Conference on Information and Knowledge
    Management, CIKM '07, pages 811–820, New York, NY, USA, 2007\. ACM.
  id: totrans-738
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: F. Angiulli 和 F. Fassetti (2007). *在数据流中检测基于距离的异常值*. 在第16届ACM信息与知识管理会议论文集，CIKM
    '07，第811–820页，纽约，纽约，美国，2007年。ACM。
- en: 'D. Yang, E. A. Rundensteiner, and M. O. Ward (2009). *Neighbor-based pattern
    detection for windows over streaming data*. In Proceedings of the 12th International
    Conference on Extending Database Technology: Advances in Database Technology,
    EDBT ''09, pages 529–540, New York, NY, USA, 2009\. ACM.'
  id: totrans-739
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: D. Yang，E. A. Rundensteiner，和 M. O. Ward (2009). *在流数据窗口上的基于邻居的模式检测*. 在第12届国际扩展数据库技术会议论文集，EDBT
    '09，第529–540页，纽约，纽约，美国，2009年。ACM。
- en: M. Kontaki, A. Gounaris, A. Papadopoulos, K. Tsichlas, and Y. Manolopoulos (2011).
    *Continuous monitoring of distance-based outliers over data streams*. In Data
    Engineering (ICDE), 2011 IEEE 27th International Conference on, pages 135–146,
    April 2011.
  id: totrans-740
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: M. Kontaki, A. Gounaris, A. Papadopoulos, K. Tsichlas, 和 Y. Manolopoulos (2011).
    *基于距离的异常值在数据流中的连续监控*. 在数据工程（ICDE），2011年第27届国际会议，第135–146页，2011年4月。
