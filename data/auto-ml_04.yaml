- en: '*Chapter 3*: Automated Machine Learning with Open Source Tools and Libraries'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第三章*：使用开源工具和库进行自动化机器学习'
- en: '"Empowerment of individuals is a key part of what makes open source work since,
    in the end, innovations tend to come from small groups, not from large, structured
    efforts."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “个人赋能是开源工作的重要组成部分，因为最终，创新往往来自小型团队，而不是来自大型、结构化的努力。”
- en: – Tim O'Reilly
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: – 蒂姆·奥莱利
- en: '"In open source, we feel strongly that to really do something well, you have
    to get a lot of people involved."'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: “在开源领域，我们坚信，要真正做好某件事，你必须让很多人参与进来。”
- en: – Linus Torvalds
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: – 林纳斯·托瓦兹
- en: In the previous chapter, you looked under the hood of automated **Machine Learning**
    (**ML**) technologies, techniques, and tools. You learned how AutoML actually
    works – that is, the algorithms and techniques of automated feature engineering,
    automated model and hyperparameter turning, and automated deep learning. You also
    explored Bayesian optimization, reinforcement learning, the evolutionary algorithm,
    and various gradient-based approaches by looking at their use in automated ML.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你了解了自动化**机器学习**（**ML**）技术、技术和工具的内部结构。你学习了AutoML是如何实际工作的——也就是说，自动化特征工程、自动化模型和超参数调整以及自动化深度学习的算法和技术。你还通过查看它们在自动化ML中的应用，探索了贝叶斯优化、强化学习、进化算法以及各种基于梯度的方法。
- en: However, as a hands-on engineer, you probably don't get the satisfaction of
    understanding something fully until you get your hands dirty by trying it out.
    This chapter will give you the very opportunity to do this. AutoML **open source
    software** (**OSS**) tools and libraries automate the entire life cycle of ideating,
    conceptualizing, developing, and deploying predictive models. From data preparation
    through model training to validation as well as deployment, these tools do everything
    with almost zero human intervention.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，作为一名动手的工程师，你可能直到通过实际尝试弄脏双手，才能真正理解某个东西，并从中获得满足感。本章将为你提供这样的机会。AutoML **开源软件**（**OSS**）工具和库自动化了从构思、概念化、开发到部署预测模型的全生命周期。从数据准备到模型训练、验证以及部署，这些工具几乎不需要人工干预就能完成所有工作。
- en: In this chapter, we will review the major OSS tools, including **TPOT**, **AutoKeras**,
    **auto-sklearn**, **Featuretools**, and **Microsoft NNI**, to help you understand
    the differential value propositions and approaches that are used in each of these
    libraries.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将回顾主要的开源工具，包括**TPOT**、**AutoKeras**、**auto-sklearn**、**Featuretools**和**Microsoft
    NNI**，以帮助你了解每个库中使用的差异化价值主张和方法。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The open source ecosystem for AutoML
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化机器学习的开源生态系统
- en: Introducing TPOT
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍TPOT
- en: Introducing Featuretools
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍Featuretools
- en: Introducing Microsoft NNI
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍Microsoft NNI
- en: Introducing auto-sklearn
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍auto-sklearn
- en: Introducing AutoKeras
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍AutoKeras
- en: Let's get started!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Technical requirements
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The technical requirements for this chapter are as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的技术要求如下：
- en: 'TPOT installation: [github.com/EpistasisLab/tpot](http://github.com/EpistasisLab/tpot'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TPOT安装：[github.com/EpistasisLab/tpot](http://github.com/EpistasisLab/tpot)
- en: )
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'Featuretools installation: [https://pypi.org/project/featuretools/](https://pypi.org/project/featuretools/)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Featuretools安装：[https://pypi.org/project/featuretools/](https://pypi.org/project/featuretools/)
- en: 'Microsoft NNI installation: [https://github.com/microsoft/nni](https://github.com/microsoft/nni)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Microsoft NNI安装：[https://github.com/microsoft/nni](https://github.com/microsoft/nni)
- en: 'auto-sklearn installation: [https://automl.github.io/auto-sklearn/master/installation.html](https://automl.github.io/auto-sklearn/master/installation.html)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: auto-sklearn安装：[https://automl.github.io/auto-sklearn/master/installation.html](https://automl.github.io/auto-sklearn/master/installation.html)
- en: 'AutoKeras installation: [https://autokeras.com/install/](https://autokeras.com/install/)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoKeras安装：[https://autokeras.com/install/](https://autokeras.com/install/)
- en: 'MNIST download: [https://www.kaggle.com/c/digit-recognizer](https://www.kaggle.com/c/digit-recognizer)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MNIST下载：[https://www.kaggle.com/c/digit-recognizer](https://www.kaggle.com/c/digit-recognizer)
- en: The open source ecosystem for AutoML
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化机器学习的开源生态系统
- en: 'By reviewing the history of automated ML, it is evident that, in the early
    days, the focus had always been on **hyperparameter** optimization. The earlier
    tools, such as **AutoWeka** and **HyperoptSkLearn**, and later **TPOT**, had an
    original focus on using Bayesian optimization techniques to find the most suitable
    **hyperparameters** for the model. However, this trend shifted left to include
    model selection, which eventually engulfed the entire pipeline by including feature
    selection, preprocessing, construction, and data cleaning. The following table
    shows some of the prominent automated ML tools that are available, including **TPOT**,
    **AutoKeras**, **auto-sklearn**, and **Featuretools**, along with their optimization
    techniques, ML tasks, and training frameworks:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通过回顾自动化机器学习的历史，可以明显看出，在早期，焦点始终集中在**超参数**优化上。早期的工具，如**AutoWeka**和**HyperoptSkLearn**，以及后来的**TPOT**，最初的重点是使用贝叶斯优化技术来找到模型的最合适的**超参数**。然而，这一趋势转向左侧，包括模型选择，最终通过包括特征选择、预处理、构建和数据清洗，将整个流程纳入其中。以下表格展示了一些可用的突出自动化机器学习工具，包括**TPOT**、**AutoKeras**、**auto-sklearn**和**Featuretools**，以及它们的优化技术、机器学习任务和训练框架：
- en: '![Figure 3.1 – Features of automated ML frameworks'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.1 – 自动化机器学习框架的特点'
- en: '](img/B16890_03_01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_01.jpg)'
- en: Figure 3.1 – Features of automated ML frameworks
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – 自动化机器学习框架的特点
- en: 'For several of the examples in this chapter, we will be using the `datasets`
    package since it has already taken care of data loading and preprocessing **MNIST**
    60,000 training examples and 10,000 test examples. Most data scientists are ML
    enthusiasts and are very familiar with the **MNIST** database, which makes it
    a great candidate for teaching you how to use this library:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的几个示例中，我们将使用 `datasets` 包，因为它已经处理了数据加载和预处理**MNIST** 60,000 个训练示例和 10,000
    个测试示例。大多数数据科学家都是机器学习爱好者，并且非常熟悉**MNIST**数据库，这使得它成为教授如何使用这个库的绝佳候选者：
- en: '![Figure 3.2 – MNIST database of handwritten digits – visualization'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.2 – 手写数字 MNIST 数据库 – 可视化'
- en: '](img/B16890_03_02.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_02.jpg)'
- en: Figure 3.2 – MNIST database of handwritten digits – visualization
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – 手写数字 MNIST 数据库 – 可视化
- en: The preceding image shows what the MNIST dataset looks like. The dataset is
    available as part of all major ML and deep learning libraries, and can be downloaded
    from [https://www.kaggle.com/c/digit-recognizer](https://www.kaggle.com/c/digit-recognizer).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图像显示了 MNIST 数据集的外观。该数据集作为所有主要机器学习和深度学习库的一部分提供，可以从 [https://www.kaggle.com/c/digit-recognizer](https://www.kaggle.com/c/digit-recognizer)
    下载。
- en: Introducing TPOT
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 TPOT
- en: The **Tree-based Pipeline Optimization Tool**, or **TPOT** for short, is a product
    of the University of Pennsylvania's, Computational Genetics Lab. TPOT is an automated
    ML tool written in Python. It helps build and optimize ML pipelines with genetic
    programming. Built on top of scikit-learn, TPOT helps automate the feature selection,
    preprocessing, construction, model selection, and parameter optimization processes
    by "*exploring thousands of possible pipelines to find the best one*". It is one
    of the only toolkits with a short learning curve.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于树的管道优化工具**，简称**TPOT**，是宾夕法尼亚大学计算遗传学实验室的产品。TPOT 是一个用 Python 编写的自动化机器学习工具。它通过遗传编程帮助构建和优化机器学习管道。建立在
    scikit-learn 之上，TPOT 通过“探索成千上万的可能管道以找到最佳方案”来自动化特征选择、预处理、构建、模型选择和参数优化过程。它是唯一具有较短学习曲线的工具包之一。'
- en: 'The toolkit is available on GitHub to be downloaded: [github.com/EpistasisLab/tpot](http://github.com/EpistasisLab/tpot).'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包可在 GitHub 上下载：[github.com/EpistasisLab/tpot](http://github.com/EpistasisLab/tpot)。
- en: 'To explain the framework, let''s start with a minimal working example. For
    this example, we will be using the **MNIST** database of handwritten digits:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释这个框架，让我们从一个最小的工作示例开始。对于这个示例，我们将使用**MNIST**手写数字数据库：
- en: Create a new `pip install TPOT`. TPOT can be directly used from the command
    line or via Python code:![Figure 3.3 – Installing TPOT on a Colab notebook
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的`pip install TPOT`。TPOT 可以直接从命令行或通过 Python 代码使用：![图 3.3 – 在 Colab 笔记本上安装
    TPOT
- en: '](img/B16890_03_03.jpg)'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16890_03_03.jpg)'
- en: Figure 3.3 – Installing TPOT on a Colab notebook
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.3 – 在 Colab 笔记本上安装 TPOT
- en: Import `TPOTClassifier`, the scikit-learn `datasets` package, and the model
    selection libraries. We will use these libraries to load the data that we will
    be using for classification within TPOT:![Figure 3.4 – AutoML TPOT example – import
    statement
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `TPOTClassifier`，scikit-learn 的 `datasets` 包和模型选择库。我们将使用这些库来加载我们将在 TPOT 中用于分类的数据：![图
    3.4 – AutoML TPOT 示例 – 导入语句
- en: '](img/B16890_03_04.jpg)'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16890_03_05.jpg)'
- en: Figure 3.4 – AutoML TPOT example – import statement
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.4 – AutoML TPOT 示例 – 导入语句
- en: Now, proceed by loading the `train_test_split` method returns a list containing
    a train-test split of given inputs. In this case, the inputs are digits data and
    digits target arrays. Here, you can see that the training size is **0.75** and
    that the test size is **0.25**, which signifies a standard 75-25 split in training
    and testing data:![Figure 3.5 – AutoML TPOT example – loading the digits dataset
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，通过加载 `train_test_split` 方法返回一个包含给定输入的 train-test 分割的列表。在这种情况下，输入是数字数据和数字目标数组。在这里，您可以看到训练大小是
    **0.75**，测试大小是 **0.25**，这表示标准 75-25 的训练和测试数据分割：![图 3.5 – AutoML TPOT 示例 – 加载数字数据集
- en: '](img/B16890_03_05.jpg)'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16890_03_05.jpg)'
- en: Figure 3.5 – AutoML TPOT example – loading the digits dataset
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.5 – AutoML TPOT 示例 – 加载数字数据集
- en: In a typical scenario, this is where we will choose a model, assign `TPOTClassifier`.
    This class is parametrically quite extensive, as shown in the following screenshot,
    but we will only be using three key parameters; that is, `verbosity`, `max_time_mins`,
    and `population_size`:![Figure 3.6 – AutoML TPOT example – instantiating the TPOTClassifier
    object
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在典型场景中，这就是我们选择模型、分配 `TPOTClassifier` 的地方。这个类在参数上相当广泛，如以下截图所示，但我们将只使用三个关键参数；即，`verbosity`、`max_time_mins`
    和 `population_size`：![图 3.6 – AutoML TPOT 示例 – 实例化 TPOTClassifier 对象
- en: '](img/B16890_03_06.jpg)'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16890_03_06.jpg)'
- en: Figure 3.6 – AutoML TPOT example – instantiating the TPOTClassifier object
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.6 – AutoML TPOT 示例 – 实例化 TPOTClassifier 对象
- en: A quick note about the arguments being passed to `Classifier` – setting `Verbosity`
    to `2` will make TPOT print information alongside a progress bar. The `max_time_mins`
    parameter sets the time allocation in minutes for TPOT to optimize the pipeline,
    while the `population_size` parameter is the number of individuals in the genetic
    programming population for every generation.
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于传递给 `Classifier` 的参数的简要说明 – 将 `Verbosity` 设置为 `2` 将使 TPOT 在进度条旁边打印信息。`max_time_mins`
    参数设置 TPOT 优化管道的分钟数分配，而 `population_size` 参数是每一代遗传编程种群中个体的数量。
- en: 'Upon starting the experiment, we will set the maximum time to only 1 minute:'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在开始实验时，我们将最大时间设置为仅 1 分钟：
- en: '![Figure 3.7 – AutoML TPOT example – optimization run of TPOTClassifier'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.7 – AutoML TPOT 示例 – TPOTClassifier 的优化运行](img/B16890_03_04.jpg)'
- en: '](img/B16890_03_07.jpg)'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16890_03_07.jpg)'
- en: Figure 3.7 – AutoML TPOT example – optimization run of TPOTClassifier
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.7 – AutoML TPOT 示例 – TPOTClassifier 的优化运行
- en: You will see that the optimization progress isn't quite as good; it's at 22%
    since only 9 out of the 40 individuals have been processed in this generation.
    In this case, the best recommended pipeline is based on `RandomForestClassifier`.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您将看到优化进度并不那么理想；它处于 22%，因为在这个世代中只有 40 个个体中的 9 个已被处理。在这种情况下，最佳推荐管道基于 `RandomForestClassifier`。
- en: Now, let's increase this to 5 minutes and check the resulting pipeline. At this
    point, it seems like the recommended classifier is the Gradient Boosting classifier.
    This is quite interesting:![Figure 3.8 – AutoML TPOT example – executing TPOTClassifier
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将其增加到 5 分钟并检查生成的管道。在这个阶段，看起来推荐的分类器是梯度提升分类器。这非常有趣：![图 3.8 – AutoML TPOT
    示例 – 执行 TPOTClassifier
- en: '](img/B16890_03_08.jpg)'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16890_03_08.jpg)'
- en: .
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: .
- en: Figure 3.8 – AutoML TPOT example – executing TPOTClassifier
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.8 – AutoML TPOT 示例 – 执行 TPOTClassifier
- en: This time, we will gradually increase the time to `15` minutes, in which case
    the best pipeline will turn out to be from the **k-nearest neighbours** (**KNN**)
    classifier:![Figure 3.9 – AutoML TPOT classifier – TPOTClassifier fit to get the
    predictions
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这次，我们将逐渐增加时间到 `15` 分钟，在这种情况下，最佳管道将来自 **k-最近邻**（**KNN**）分类器：![图 3.9 – AutoML
    TPOT 分类器 – 使用 TPOTClassifier 进行拟合以获取预测
- en: '](img/B16890_03_09.jpg)'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16890_03_09.jpg)'
- en: Figure 3.9 – AutoML TPOT classifier – TPOTClassifier fit to get the predictions
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.9 – AutoML TPOT 分类器 – 使用 TPOTClassifier 进行拟合以获取预测
- en: Increasing the time to `25` minutes does not change the algorithm, but other
    **hyperparameters** (number of neighbors) and their accuracy are increased:![Figure
    3.10 – AutoML TPOT example – running multiple generations and scores
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将时间增加到 `25` 分钟并不会改变算法，但其他 **超参数**（邻居数量）及其准确性有所提高：![图 3.10 – AutoML TPOT 示例 –
    运行多代和分数
- en: '](img/B16890_03_10.jpg)'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16890_03_10.jpg)'
- en: Figure 3.10 – AutoML TPOT example – running multiple generations and scores
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.10 – AutoML TPOT 示例 – 运行多代和分数
- en: Finally, let's run the experiment for an entire hour:![Figure 3.11 – AutoML
    TPOT example – TPOT generations and cross-validation scores
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们运行整个小时的实验：![图 3.11 – AutoML TPOT 示例 – TPOT 代数和交叉验证分数
- en: '](img/B16890_03_11.jpg)'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16890_03_11.jpg)'
- en: Figure 3.11 – AutoML TPOT example – TPOT generations and cross-validation scores
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.11 – AutoML TPOT 示例 – TPOT 代数和交叉验证分数
- en: 'The resulting best pipeline is `KNeighborsClassifier` using feature ranking
    with recursive feature elimination. Other hyperparameters include `max_features`
    and `n_estimators`, and the pipeline has an accuracy of `0.98666`:'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果最佳管道是使用特征排名和递归特征消除的 `KNeighborsClassifier`。其他超参数包括 `max_features` 和 `n_estimators`，该管道的准确率为
    `0.98666`：
- en: '![Figure 3.12 – AutoML TPOT example – the best pipeline'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.12 – AutoML TPOT 示例 – 最佳管道'
- en: '](img/B16890_03_12.jpg)'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16890_03_12.jpg)'
- en: Figure 3.12 – AutoML TPOT example – the best pipeline
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.12 – AutoML TPOT 示例 – 最佳管道
- en: This reminds me – if 666 is considered an evil number, then 25.8069758011 is
    the root of all evil.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这让我想起 – 如果 666 被认为是邪恶的数字，那么 25.8069758011 就是万恶之源。
- en: Also, as you have probably observed, the amount of time TPOT had to run its
    **cross-validation** (**CV**) for multiple generations, the pipeline changes,
    and not only the algorithm but the **hyperparameters** have evolved. There are
    also diminishing returns. The improvements in CV scores become smaller and smaller
    to where, at a certain point, these refinements doesn't make much difference.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，正如你可能观察到的，TPOT 需要运行其 **交叉验证**（**CV**）的时间，对于多代，管道发生变化，不仅仅是算法，**超参数**也发生了演变。还有递减的回报。CV
    分数的改进变得越来越小，到了某个点，这些改进几乎不起作用。
- en: 'Now, you can export the actual model from TPOT by calling the `export` method:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以通过调用 `export` 方法从 TPOT 导出实际模型：
- en: '![Figure 3.13 – AutoML TPOT example – exploring the digits pipeline'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.13 – AutoML TPOT 示例 – 探索数字管道'
- en: '](img/B16890_03_13.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16890_03_13.jpg)'
- en: Figure 3.13 – AutoML TPOT example – exploring the digits pipeline
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.13 – AutoML TPOT 示例 – 探索数字管道
- en: 'Once the model has been exported, you will be able to see the file in the left-hand
    pane of **Google Colab**, as shown in the following screenshot:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 模型导出后，你将能够在 **Google Colab** 的左侧面板中看到文件，如下面的截图所示：
- en: '![Figure 3.14 – AutoML TPOT example – visualizing the TPOT digits pipeline'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.14 – AutoML TPOT 示例 – 可视化 TPOT 数字管道'
- en: '](img/B16890_03_14.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16890_03_14.jpg)'
- en: Figure 3.14 – AutoML TPOT example – visualizing the TPOT digits pipeline
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.14 – AutoML TPOT 示例 – 可视化 TPOT 数字管道
- en: 'Now that we know that this pipeline works the best, let''s try this out. Notice
    how we don''t have any need for TPOT anymore since we already have the tea (or
    pipeline, in this case):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道这个管道效果最好，让我们试试看。注意我们不再需要 TPOT，因为我们已经有了“茶”（或在这个情况下是管道）：
- en: '![Figure 3.15 – AutoML TPOT example – exporting the pipeline with ExtraTreesClassifier'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.15 – AutoML TPOT 示例 – 使用 ExtraTreesClassifier 导出管道'
- en: '](img/B16890_03_15.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16890_03_15.jpg)'
- en: Figure 3.15 – AutoML TPOT example – exporting the pipeline with ExtraTreesClassifier
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.15 – AutoML TPOT 示例 – 使用 ExtraTreesClassifier 导出管道
- en: 'Now that we''ve created the exported pipeline, let''s load up the dataset.
    Instead of reading it from the CSV file, I can just use the `sklearn` datasets
    to expedite things. Also, I chose digit `target` `[10]`) in the array, and voila
    – the prediction was right:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了导出的管道，让我们加载数据集。我可以选择从 CSV 文件中读取它，但我可以直接使用 `sklearn` 数据集来加快速度。此外，我在数组中选择了数字
    `target` `[10]`)，哇 – 预测是正确的：
- en: '![Figure 3.16 – AutoML TPOT example – results from the exported pipeline'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.16 – AutoML TPOT 示例 – 导出管道的结果'
- en: '](img/B16890_03_16.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16890_03_16.jpg)'
- en: Figure 3.16 – AutoML TPOT example – results from the exported pipeline
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.16 – AutoML TPOT 示例 – 导出管道的结果
- en: How does TPOT do this?
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TPOT 是如何做到这一点的？
- en: 'This looks great, but you didn''t buy this book just to learn how to use an
    API – you want to understand a bit more about what is going on under the hood.
    Well, here is the scoop: TPOT has automated the key components of the pipeline
    using genetic programming; it tried different approaches, as you saw, and then
    eventually settled on using KNN as the best classifier:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这个看起来很棒，但你购买这本书的目的并不是仅仅为了学习如何使用API——你更想了解底层的运作原理。好的，现在我来告诉你：TPOT通过遗传编程自动化了管道的关键组件；它尝试了不同的方法，正如你所见，最终选择了使用KNN作为最佳分类器：
- en: '![Figure 3.17 – Overview of the TPOT pipeline search'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18 – TPOT – 用于自动化机器学习的基于树的管道优化工具
- en: '](img/B16890_03_17.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.17 – TPOT管道搜索概述'
- en: Figure 3.17 – Overview of the TPOT pipeline search
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Colab中启动Featuretools，你需要使用pip来安装该包。在这个例子中，我们将尝试为波士顿房价数据集创建特征：![图3.19 – 使用Featuretools的AutoML
    – 安装Featuretools
- en: 'Behind the scenes, TPOT uses genetic programming constructs (selection, crossover,
    and mutation) to optimize transformation, which helps maximize classification
    accuracy. The following is a list of operators provided by TPOT:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.18.jpg'
- en: '![Figure 3.18 – TPOT – a tree-based pipeline optimization tool for automating
    ML'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.19 – 使用Featuretools的AutoML – 安装Featuretools
- en: '](img/B16890_03_18.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.22 – 使用Featuretools的AutoML – 将数据集加载为pandas DataFrame
- en: Figure 3.18 – TPOT – a tree-based pipeline optimization tool for automating
    ML
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.21 – 使用Featuretools的AutoML – 安装Featuretools
- en: Introducing Featuretools
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '![图3.22.jpg'
- en: Featuretools is an excellent Python framework that helps with automated feature
    engineering by using DFS. Feature engineering is a tough problem due to its very
    nuanced nature. However, this open source toolkit, with its robust timestamp handling
    and reusable feature primitives, provides a proper framework for us to build and
    extract combinations of features and their impact.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Featuretools介绍
- en: 'The toolkit is available on GitHub to be downloaded: [https://github.com/FeatureLabs/featuretools/](https://github.com/FeatureLabs/featuretools/).
    The following steps will guide you through how to install Featuretools, as well
    as how to run an automated ML experiment using the library. Let''s get started:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具包可在GitHub上下载：[https://github.com/FeatureLabs/featuretools/](https://github.com/FeatureLabs/featuretools/).
    以下步骤将指导你如何安装Featuretools，以及如何使用该库运行自动机器学习实验。让我们开始吧：
- en: To start Featuretools in Colab, you will need to use pip to install the package.
    In this example, we will try to create features for the Boston Housing Prices
    dataset:![Figure 3.19 – AutoML with Featuretools – installing Featuretools
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在幕后，TPOT使用遗传编程结构（选择、交叉和变异）来优化转换，这有助于最大化分类精度。以下是TPOT提供的操作符列表：
- en: '](img/B16890_03_19.jpg)'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个实验中，我们将使用波士顿房价数据集，这是机器学习中一个知名且广泛使用的数据集。以下是数据集的简要描述和元数据：
- en: Figure 3.19 – AutoML with Featuretools – installing Featuretools
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.19 – 使用Featuretools的AutoML – 安装Featuretools'
- en: 'In this experiment, we will be using the Boston Housing Prices dataset, which
    is a well-known and widely used dataset in ML. The following is a brief description
    and the metadata of the dataset:'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Featuretools是一个优秀的Python框架，它通过使用DFS帮助自动化特征工程。由于特征工程的性质非常微妙，它是一个难题。然而，这个开源工具包，凭借其强大的时间戳处理和可重用的特征原语，为我们提供了一个合适的框架来构建和提取特征组合及其影响。
- en: '![Figure 3.20 – AutoML with Featuretools – Boston Housing Prices dataset'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.17 – TPOT管道搜索概述
- en: '](img/B16890_03_20.jpg)'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.20 – 使用Featuretools的AutoML – 波士顿房价数据集
- en: Figure 3.20 – AutoML with Featuretools – Boston Housing Prices dataset
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.19.jpg'
- en: The Boston Housing Prices dataset is part of the `scikit-learn` dataset, which
    makes it very easy to import, as shown here:![Figure 3.21 – AutoML with Featuretools
    – installing Featuretools
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 波士顿房价数据集是`scikit-learn`数据集的一部分，这使得它非常容易导入，如下所示：![图3.21 – 使用Featuretools的AutoML
    – 安装Featuretools
- en: '](img/B16890_03_21.jpg)'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.17 – TPOT管道搜索概述'
- en: Figure 3.21 – AutoML with Featuretools – installing Featuretools
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.18 – TPOT – 用于自动化机器学习的基于树的管道优化工具
- en: Now, we will use `boston`) using the `featuretools` **Deep Feature Synthesis**
    (**DFS**) API:![Figure 3.22 – AutoML with Featuretools – loading the dataset as
    a pandas DataFrame
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将使用`featuretools`的**深度特征合成（DFS**）API来处理`boston`数据集：![图3.22 – 使用Featuretools的AutoML
    – 将数据集加载为pandas DataFrame
- en: '](img/B16890_03_22.jpg)'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.20 – 使用Featuretools的AutoML – 波士顿房价数据集
- en: Figure 3.22 – AutoML with Featuretools – loading the dataset as a pandas DataFrame
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.20 – 使用Featuretools的AutoML – 波士顿房价数据集'
- en: Let's create a feature tools entity set for the Boston table, and then define
    the target entries. In this case, we will just create some new features; that
    is, the products and the sum of existing features. Once **Featuretools** has run
    the DFS, you will have all the summation and product features:![Figure 3.23 –
    AutoML with Featuretools – results of DFS
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为 Boston 表创建一个特征工具实体集，然后定义目标条目。在这种情况下，我们只需创建一些新特征；也就是说，现有特征的乘积和总和。一旦**Featuretools**运行了
    DFS，你将拥有所有求和和乘积特征：![图 3.23 – 使用 Featuretools 的 AutoML – DFS 的结果
- en: '](img/B16890_03_23.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16890_03_23.jpg)'
- en: Figure 3.23 – AutoML with Featuretools – results of DFS
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.23 – 使用 Featuretools 的 AutoML – DFS 的结果
- en: 'The list of features continues:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 特征列表继续：
- en: '![Figure 3.24 – AutoML with Featuretools – results of DFS – continued'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.24 – 使用 Featuretools 的 AutoML – DFS 的结果 – 继续显示'
- en: '](img/B16890_03_24.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_24.jpg)'
- en: Figure 3.24 – AutoML with Featuretools – results of DFS – continued
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.24 – 使用 Featuretools 的 AutoML – DFS 的结果 – 继续显示
- en: 'At this point, you might be wondering, what is the point of doing DFS if it
    just contains the sums and products of existing features? I''m glad you asked.
    Think of these derived features as highlighting the latent relationships between
    multiple data points – and it''s not related to sum and product. For example,
    you can link multiple tables with average order summation, and the algorithms
    will have additional pre-defined features to work with to find correlations. This
    is a very strong and significant quantitative value proposition that''s provided
    by DFS, and it is typically used in machine learning algorithmic competitions:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可能想知道，如果 DFS 只包含现有特征的求和和乘积，那么进行 DFS 的意义何在？我很高兴你提出了这个问题。将这些派生特征视为突出多个数据点之间的潜在关系——这与求和和乘积无关。例如，你可以通过平均订单求和将多个表链接起来，算法将具有额外的预定义特征来寻找相关性。这是
    DFS 提供的非常强大且具有显著性的量化价值主张，通常用于机器学习算法竞赛：
- en: '![Figure 3.25 – DFS – analyzing features from Entity'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.25 – DFS – 从实体分析特征'
- en: '](img/B16890_03_25.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_25.jpg)'
- en: Figure 3.25 – DFS – analyzing features from Entity
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.25 – DFS – 从实体分析特征
- en: 'The **Featuretools** website contains an excellent set of demos for predicting
    next purchases, remaining useful life, appointment no-shows, loan repayment likelihood,
    customer churn, household poverty, and malicious internet traffic, among many
    other use cases: [https://www.featuretools.com/demos/](https://www.featuretools.com/demos/).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**Featuretools**网站包含一套优秀的演示，用于预测下一次购买、剩余使用寿命、预约未出现、贷款偿还可能性、客户流失、家庭贫困和恶意互联网流量等众多用例：[https://www.featuretools.com/demos/](https://www.featuretools.com/demos/)。'
- en: Introducing Microsoft NNI
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Microsoft NNI
- en: '**Microsoft Neural Network Intelligence** (**NNI**) is an open source platform
    that addresses the three key areas of any automated ML life cycle – automated
    feature engineering, architectural search (also referred to as **neural architectural
    search** or **NAS**), and **hyperparameter tuning** (**HPI**). The toolkit also
    offers model compression features and operationalization. NNI comes with many
    hyperparameter tuning algorithms already built in.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**Microsoft 神经网络智能**（**NNI**）是一个开源平台，针对任何自动化机器学习生命周期的三个关键领域——自动化特征工程、架构搜索（也称为**神经架构搜索**或**NAS**）和**超参数调整**（**HPI**）。该工具包还提供模型压缩功能和部署。NNI
    内置了许多超参数调整算法。'
- en: 'A high-level architecture diagram of NNI is as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: NNI 的高级架构图如下：
- en: '![](img/B16890_03_26.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16890_03_26.jpg)'
- en: Figure 3.26 – Microsoft NNI high-level architecture
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.26 – Microsoft NNI 高级架构
- en: NNI has several state-of-the-art **hyperparameter** optimization algorithms
    built in, and they are called **tuners**. The list includes **TPE**, **Random
    Search**, **Anneal**, **Naive Evolution**, **SMAC**, **Metis Tuner**, **Batch
    Tuner**, **Grid Search**, **GP Tuner**, **Network Morphism**, **Hyperband**, **BOHB**,
    **PPO Tuner**, and **PBT Tuner**.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: NNI 内置了几个最先进的**超参数**优化算法，它们被称为**调优器**。列表包括**TPE**、**随机搜索**、**退火**、**朴素进化**、**SMAC**、**Metis
    Tuner**、**Batch Tuner**、**网格搜索**、**GP Tuner**、**网络形态**、**Hyperband**、**BOHB**、**PPO
    Tuner**和**PBT Tuner**。
- en: 'The toolkit is available on GitHub to be downloaded: [https://github.com/microsoft/nni](https://github.com/microsoft/nni).
    More information about its built-in tuners can be found here: [https://nni.readthedocs.io/en/latest/builtin_tuner.html](https://nni.readthedocs.io/en/latest/builtin_tuner.html).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包可在 GitHub 上下载：[https://github.com/microsoft/nni](https://github.com/microsoft/nni)。有关其内置调优器的更多信息，请在此处查看：[https://nni.readthedocs.io/en/latest/builtin_tuner.html](https://nni.readthedocs.io/en/latest/builtin_tuner.html)。
- en: Now, let's learn how to install Microsoft NNI and how to run an automated ML
    experiment using this library.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们学习如何安装 Microsoft NNI 以及如何使用此库运行自动机器学习实验。
- en: 'Let''s go ahead and install the NNI on our machine using `pip` :'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续在我们的机器上使用 `pip` 安装 NNI：
- en: '![Figure 3.27 – AutoML with Microsoft NNI – installation via Anaconda'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.27 – 使用 Microsoft NNI 的 AutoML – 通过 Anaconda 安装'
- en: '](img/B16890_03_27.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_27.jpg)'
- en: Figure 3.27 – AutoML with Microsoft NNI – installation via Anaconda
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.27 – 使用 Microsoft NNI 的 AutoML – 通过 Anaconda 安装
- en: 'One of the best features offered by NNI is that it has both a **command-line
    interface** (**CLI**) and a **web UI** so that we can view the trials and experiments.
    NNICtl is the command line that''s used to manage the NNI application. You can
    see the options for experiments in the following screenshot:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: NNI 提供的最好功能之一是它既有 **命令行界面**（**CLI**）又有 **Web UI**，这样我们就可以查看试验和实验。NNICtl 是用于管理
    NNI 应用程序的命令行。您可以在以下屏幕截图中看到实验的选项：
- en: '![Figure 3.28 – AutoML with Microsoft NNI – the nnictl command'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.28 – 使用 Microsoft NNI 的 AutoML – nnictl 命令'
- en: '](img/B16890_03_28.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_28.jpg)'
- en: Figure 3.28 – AutoML with Microsoft NNI – the nnictl command
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.28 – 使用 Microsoft NNI 的 AutoML – nnictl 命令
- en: 'NNI can have a learning curve if you do not understand how it works. You need
    to become familiar with the three primary NNI elements for it to work. First,
    you must define the search space, which you can find in the `search_space.json`
    file. You also need to update the model code (`main.py`) so that it incorporates
    `config.yml`) so that you can define the tuner and trial (execution model code)
    information:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不了解 NNI 的工作原理，它可能会有一个学习曲线。您需要熟悉 NNI 的三个主要元素才能使其正常工作。首先，您必须定义搜索空间，您可以在 `search_space.json`
    文件中找到它。您还需要更新模型代码（`main.py`），使其包含 `config.yml`），这样您就可以定义调优器和试验（执行模型代码）信息：
- en: '![Figure 3.29 – AutoML with Microsoft NNI – the configuration and execution
    files'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.29 – 使用 Microsoft NNI 的 AutoML – 配置和执行文件'
- en: '](img/B16890_03_29.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_29.jpg)'
- en: Figure 3.29 – AutoML with Microsoft NNI – the configuration and execution files
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.29 – 使用 Microsoft NNI 的 AutoML – 配置和执行文件
- en: As a reminder, the search space describes the value range of each hyperparameter
    and for each trial, various hyperparameter values from this space are picked.
    While creating a configuration for a hyperparamter tuning experiment, we can limit
    the maximum number of trials. Also, while creating a hyperparameter search space,
    we can list the values that we want to try out in the tuning experiment when using
    the **choice** type hyperparameter.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，搜索空间描述了每个超参数的值范围，并且对于每个试验，从这个空间中选取各种超参数值。在创建超参数调优实验的配置时，我们可以限制试验的最大数量。同时，在创建超参数搜索空间时，我们可以列出在
    **选择** 类型超参数的调优实验中想要尝试的值。
- en: 'In this case, we have taken a simple `nnictl` `create` command:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用了简单的 `nnictl` `create` 命令：
- en: '![Figure 3.30 – AutoML with Microsoft NNI – running the experiment'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.30 – 使用 Microsoft NNI 的 AutoML – 运行实验'
- en: '](img/B16890_03_30.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_30.jpg)'
- en: Figure 3.30 – AutoML with Microsoft NNI – running the experiment
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.30 – 使用 Microsoft NNI 的 AutoML – 运行实验
- en: 'You can use the following commands to find out more about the experiment:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令了解更多关于实验的信息：
- en: '![Figure 3.31 – AutoML with Microsoft NNI – the nnictrl parameters'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.31 – 使用 Microsoft NNI 的 AutoML – nnictrl 参数'
- en: '](img/B16890_03_31.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_31.jpg)'
- en: Figure 3.31 – AutoML with Microsoft NNI – the nnictrl parameters
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.31 – 使用 Microsoft NNI 的 AutoML – nnictrl 参数
- en: 'Now, let''s look at NNI''s secret weapon – its UI. The NNI UI can be accessed
    via the web UI URL shown in the output console shown in *Figure 3.29*. Here, you
    can see the experiment running, its parameters, and its details. For instance,
    in this case, we only ran 19 trials, so it ran through these quickly. However,
    there were no meaningful results, such as us finding out what the best metric
    is (`N/A`), as shown in the following screenshot:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看 NNI 的秘密武器——它的 UI。NNI UI 可以通过输出控制台显示的 Web UI URL 访问，如 *图 3.29* 所示。在这里，您可以查看正在运行的实验、其参数和详细信息。例如，在这种情况下，我们只运行了
    19 个试验，所以它们运行得很快。然而，没有有意义的结果，例如我们找到的最佳指标（`N/A`），如下面的截图所示：
- en: '![Figure 3.32 – AutoML with the Microsoft NNI UI'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.32 – 使用 Microsoft NNI UI 的 AutoML'
- en: '](img/B16890_03_32.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_32.jpg)'
- en: Figure 3.32 – AutoML with the Microsoft NNI UI
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.32 – 使用 Microsoft NNI UI 的 AutoML
- en: 'Increasing the number of trials to 30 takes longer, but it also gives you better
    accuracy in the results. Microsoft NNI helps you report intermediate results (results
    during a trial or training process before the training is complete). For instance,
    if the value of the metric being reported is stored in a variable, "x", you can
    do intermediate reporting using NNI like this:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 将试验次数增加到30需要更长的时间，但它也为你提供了更好的结果准确性。Microsoft NNI帮助你报告中间结果（在训练完成之前的试验或训练过程中的结果）。例如，如果报告的指标值存储在变量“x”中，你可以使用NNI进行中间报告，如下所示：
- en: '[PRE0]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following will be displayed on your screen:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 屏幕上将会显示以下内容：
- en: '![Figure 3.33 – AutoML with Microsoft NNI – the UI after completing an experiment'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.33 – 使用Microsoft NNI的AutoML – 实验完成后的用户界面'
- en: '](img/B16890_03_33.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16890_03_33.jpg](img/B16890_03_33.jpg)'
- en: Figure 3.33 – AutoML with Microsoft NNI – the UI after completing an experiment
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.33 – 使用Microsoft NNI的AutoML – 实验完成后的用户界面
- en: 'The NNI UI also provides you with views of the **default metrics**, **hyperparameters**,
    **duration**, and **intermediate results** of each trial. The **hyperparameter**
    view is especially amazing because you can visualize how each **hyperparameter**
    was selected. For example, in this case, it seems like RELU with a batch size
    of 1,024 provided significantly good results. This gives you an idea of what underlying
    algorithm can be used for model selection, as shown in the following screenshot:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: NNI的用户界面还提供了每个试验的**默认指标**、**超参数**、**持续时间**和**中间结果**的视图。特别是超参数视图非常令人惊叹，因为你可以可视化每个**超参数**是如何被选择的。例如，在这种情况下，似乎使用具有1,024个批次的ReLU提供了显著良好的结果。这给你一个关于可以用于模型选择的底层算法的想法，如下面的截图所示：
- en: '![Figure 3.34 – AutoML with Microsoft NNI – the hyperparameters in the experiment'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.34 – 使用Microsoft NNI的AutoML – 实验中的超参数'
- en: '](img/B16890_03_34.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16890_03_34.jpg](img/B16890_03_34.jpg)'
- en: Figure 3.34 – AutoML with Microsoft NNI – the hyperparameters in the experiment
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.34 – 使用Microsoft NNI的AutoML – 实验中的超参数
- en: 'As we learned earlier regarding diminishing returns, increasing the number
    of trials doesn''t increase the accuracy of the model significantly. In this case,
    the experiment spent 40 minutes completing 100 trials and provided a best metric
    of **0.981** compared to **0.980** from earlier, as seen in the following screenshot:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所学的关于收益递减，增加试验次数并不能显著提高模型的准确性。在这种情况下，实验花费了40分钟完成100次试验，并提供了最佳指标为**0.981**，与之前的**0.980**相比，如下截图所示：
- en: '![Figure 3.35 – AutoML with Microsoft NNI – the configuration parameters'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.35 – 使用Microsoft NNI的AutoML – 配置参数'
- en: '](img/B16890_03_35.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16890_03_35.jpg](img/B16890_03_35.jpg)'
- en: Figure 3.35 – AutoML with Microsoft NNI – the configuration parameters
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.35 – 使用Microsoft NNI的AutoML – 配置参数
- en: 'You can also select a different top percentage of results for the **hyperparameters**
    to see what **hyperparameters** we used to get the best performing results:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以选择不同的超参数结果百分比，以查看我们用于获得最佳性能结果的**超参数**：
- en: '![Figure 3.36 – AutoML with Microsoft NNI – the hyperparameters'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.36 – 使用Microsoft NNI的AutoML – 超参数'
- en: '](img/B16890_03_36.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16890_03_36.jpg](img/B16890_03_36.jpg)'
- en: Figure 3.36 – AutoML with Microsoft NNI – the hyperparameters
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.36 – 使用Microsoft NNI的AutoML – 超参数
- en: 'Alternatively, you can just look at the top 5% of the results by selecting
    `Top 5%` from the dropdown on the top right of the graph:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你只需从图形右上角的下拉菜单中选择“Top 5%”来查看结果的前5%：
- en: '![Figure 3.37 – AutoML with Microsoft NNI – the hyperparameters for the top
    5%'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.37 – 使用Microsoft NNI的AutoML – 前5%的超参数'
- en: '](img/B16890_03_37.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16890_03_37.jpg](img/B16890_03_37.jpg)'
- en: Figure 3.37 – AutoML with Microsoft NNI – the hyperparameters for the top 5%
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.37 – 使用Microsoft NNI的AutoML – 前5%的超参数
- en: 'NNI also allows you to drill down into each trial visually. You can see all
    the trial jobs in the following screenshot:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: NNI还允许你通过视觉方式深入到每个试验。你可以在以下截图中看到所有试验作业：
- en: '![Figure3.38 – AutoML with Microsoft NNI – the experiments list'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure3.38 – 使用Microsoft NNI的AutoML – 实验列表'
- en: '](img/B16890_03_38.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16890_03_38.jpg](img/B16890_03_38.jpg)'
- en: Figure3.38 – AutoML with Microsoft NNI – the experiments list
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.38 – 使用Microsoft NNI的AutoML – 实验列表
- en: 'Alternatively, you can drill down into individual jobs and view various hyperparameters,
    including `dropout_rate`, `num_units`, learning rate, `batch_size`, and `activation`
    function:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以深入到单个作业中，查看各种超参数，包括`dropout_rate`、`num_units`、学习率、`batch_size`和`activation`函数：
- en: '![Figure 3.39 – AutoML with Microsoft NNI – the path for the top 20% of hyperparameters'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 3.39 – 使用Microsoft NNI的AutoML – 前20%超参数的路径'
- en: '](img/B16890_03_39.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16890_03_39.jpg](img/B16890_03_39.jpg)'
- en: Figure 3.39 – AutoML with Microsoft NNI – the path for the top 20% of hyperparameters
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.39 – 使用Microsoft NNI的AutoML – 顶级20%超参数的路径
- en: Being able to see this level of detail about experiments and hyperparameters
    is phenomenal, and makes NNI one of our top open source tools for automated ML.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 能够看到关于实验和超参数的这种程度细节是非常惊人的，这使得NNI成为我们自动化ML的顶级开源工具之一。
- en: Before we move on, it is important to note that, like AutoGluon is part of AWS's
    automated ML offering, NNI is part of Microsoft Azure's automated ML toolset,
    which makes it much more powerful and verstaile when it comes to reusing it.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，重要的是要注意，类似于AutoGluon是AWS自动化ML服务的一部分，NNI是Microsoft Azure自动化ML工具集的一部分，这使得它在重用时更加强大和灵活。
- en: Introducing auto-sklearn
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍auto-sklearn
- en: '**scikit-learn** (also known as **sklearn**) is a very popular ML library for
    Python development – so popular that it has its own memes:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**scikit-learn**（也称为**sklearn**）是一个非常流行的Python开发ML库 – 非常受欢迎，以至于它有自己的梗：'
- en: '![Figure 3.40 – An ML meme'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.40 – 一个ML梗'
- en: '](img/B16890_03_40.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_40.jpg)'
- en: Figure 3.40 – An ML meme
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.40 – 一个ML梗
- en: As part of this ecosystem and based on *Efficient and Robust Automated Machine
    Learning* by *Feurer et al.*, **auto-sklearn** is an automated ML toolkit that
    performs algorithm selection and **hyperparameter tuning** using **Bayesian optimization**, **meta-learning**,
    and **ensemble construction**.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 作为这个生态系统的一部分，基于*Feurer等人*的*高效且鲁棒的自动化机器学习*，**auto-sklearn**是一个自动化ML工具包，它使用**贝叶斯优化**、**元学习**和**集成构建**来执行算法选择和**超参数调整**。
- en: 'The toolkit is available on GitHub to be downloaded: [github.com/automl/auto-sklearn](http://github.com/automl/auto-sklearn).'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包可在GitHub上下载：[github.com/automl/auto-sklearn](http://github.com/automl/auto-sklearn)。
- en: '`auto-sklearn` touts its ease of use for performing automated ML since it''s
    a four-line automated ML solution:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`auto-sklearn`宣称其自动化ML的易用性，因为它是一个四行自动化ML解决方案：'
- en: '![Figure 3.41 – AutoML with auto-sklearn – getting started'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.41 – 使用auto-sklearn的AutoML – 开始'
- en: '](img/B16890_03_41.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_41.jpg)'
- en: Figure 3.41 – AutoML with auto-sklearn – getting started
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.41 – 使用auto-sklearn的AutoML – 开始
- en: If the preceding syntax looks familiar, then it's because this is how `scikit-learn`
    does predictions and therefore makes `auto-sklearn` one of the easiest libraries
    to use. `auto-sklearn` uses `scikit-learn` as its backend framework and supports
    **Bayesian optimization** with automated **ensembled construction**.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如果前面的语法看起来很熟悉，那么这是因为这就是`scikit-learn`进行预测的方式，因此使`auto-sklearn`成为最容易使用的库之一。`auto-sklearn`使用`scikit-learn`作为其后端框架，并支持带有自动化**集成构建**的**贝叶斯优化**。
- en: 'Based on `auto-sklearn` addresses the problem of finding the best model and
    its hyperparameters at the same time. The following diagram shows how `auto-sklearn`
    describes its internal pipeline:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 基于`auto-sklearn`同时解决寻找最佳模型及其超参数的问题。以下图表显示了`auto-sklearn`如何描述其内部管道：
- en: '![Figure 3.42 – An auto-sklearn automated ML pipeline'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.42 – auto-sklearn自动化的ML管道'
- en: '](img/B16890_03_42.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_42.jpg)'
- en: Figure 3.42 – An auto-sklearn automated ML pipeline
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.42 – auto-sklearn自动化的ML管道
- en: 'The underlying automated ML "engine" uses **Information Retrieval** (**IR**)
    and statistical meta feature approaches to select a variety of configurations,
    all of which are used as part of Bayesian optimization input. This process is
    iterative, and auto-sklearn keeps the models to create an ensemble, thus iteratively
    building a model to maximize performance. Setting up auto-sklearn on Colab can
    be tricky as you will need to install the following packages to get started:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 基于自动ML的“引擎”使用**信息检索**（**IR**）和统计元特征方法来选择各种配置，所有这些配置都作为贝叶斯优化的输入部分。这个过程是迭代的，auto-sklearn保留模型以创建集成，从而迭代构建模型以最大化性能。在Colab上设置auto-sklearn可能很棘手，因为你需要安装以下包以开始：
- en: '![Figure 3.43 – AutoML with auto-sklearn – installing the necessary libraries'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.43 – 使用auto-sklearn的AutoML – 安装必要的库'
- en: '](img/B16890_03_43.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_43.jpg)'
- en: Figure 3.43 – AutoML with auto-sklearn – installing the necessary libraries
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.43 – 使用auto-sklearn的AutoML – 安装必要的库
- en: 'You may have to restart the runtime in Colab upon installation. You can also
    set up auto-sklearn on your local machine by following the instructions specified
    here: [https://automl.github.io/auto-sklearn/master/installation.html](https://automl.github.io/auto-sklearn/master/installation.html).'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要在Colab上安装后重新启动运行时。你也可以按照这里指定的说明在你的本地机器上设置auto-sklearn：[https://automl.github.io/auto-sklearn/master/installation.html](https://automl.github.io/auto-sklearn/master/installation.html)。
- en: 'Once you have completed the installation, you can run the **auto-sklearn classifier**
    and get great accuracy and **hyperparameters** via the magic of automated ML:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 完成安装后，你可以运行**auto-sklearn分类器**，并通过自动化机器学习的魔力获得高精度和**超参数**：
- en: '![Figure 3.44 – AutoML with AutoSkLearn – running a simple experiment for the
    auto-sklearn classifier'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.44 – 使用AutoSkLearn的AutoML – 运行auto-sklearn分类器的简单实验'
- en: '](img/B16890_03_44.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B16890_03_44.jpg)'
- en: Figure 3.44 – AutoML with AutoSkLearn – running a simple experiment for the
    auto-sklearn classifier
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.44 – 使用AutoSkLearn的AutoML – 运行auto-sklearn分类器的简单实验'
- en: 'We should point out that **auto-sklearn 2**, an experimental version of auto-sklearn,
    is also out and includes the latest work that''s been done on automatic configuration
    and performance improvements. You can import **auto-sklearn 2** like so:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该指出，**auto-sklearn 2**，auto-sklearn的一个实验版本，也已经发布，并包括了在自动配置和性能改进方面所做的工作。你可以这样导入**auto-sklearn
    2**：
- en: '[PRE1]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Examples of basic classification, regression, and multi-label classification
    datasets, as well as advanced examples of customizing auto-sklearn, are available
    here: [https://automl.github.io/auto-sklearn/master/examples/](https://automl.github.io/auto-sklearn/master/examples/).'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 基本分类、回归和多标签分类数据集的示例，以及自定义auto-sklearn的高级示例，都可以在这里找到：[https://automl.github.io/auto-sklearn/master/examples/](https://automl.github.io/auto-sklearn/master/examples/)。
- en: If you wish, you can try out the advanced use cases of changing the optimization
    metrics, the train-validation split, providing different feature types, using
    pandas DataFrames, and inspecting search procedures. These advanced examples also
    demonstrate how auto-sklearn can be used to **extend regression**, **classification**,
    and **preprocessor components**, as well as how a number of **hyperparameters**
    can be restricted.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你愿意，可以尝试改变优化指标、训练-验证分割、提供不同特征类型、使用pandas DataFrames以及检查搜索过程的高级用例。这些高级示例还展示了如何使用auto-sklearn来**扩展回归**、**分类**和**预处理组件**，以及如何限制多个**超参数**。
- en: AutoKeras
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AutoKeras
- en: '**Keras** is one of the most widely used deep learning frameworks and is an
    integral part of the TensorFlow 2.0 ecosystem. **Auto-Keras** is based on the
    paper by Jin et al., ([https://arxiv.org/abs/1806.10282](https://arxiv.org/abs/1806.10282))
    which proposed "*a novel method for efficient neural architecture search with
    network morphism, enabling Bayesian optimization*". **AutoKeras** is built on
    the concept that since existing neural architecture search algorithms such as
    **NASNet** and **PNAS** are computationally quite expensive, using **Bayesian
    optimization** to guide the network''s morphism is an efficient approach to explore
    the search space.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '**Keras**是使用最广泛的深度学习框架之一，也是TensorFlow 2.0生态系统的重要组成部分。**Auto-Keras**基于Jin等人撰写的论文([https://arxiv.org/abs/1806.10282](https://arxiv.org/abs/1806.10282))，该论文提出了"*一种使用网络形态学进行高效神经架构搜索的新方法，并实现了贝叶斯优化*"。**AutoKeras**基于这样一个概念，即由于现有的神经架构搜索算法如**NASNet**和**PNAS**在计算上相当昂贵，使用**贝叶斯优化**来指导网络的形态学是一种探索搜索空间的有效方法。'
- en: 'The toolkit is available on GitHub to be downloaded: [github.com/jhfjhfj1/autokeras](http://github.com/jhfjhfj1/autokeras).'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包可在GitHub上下载：[github.com/jhfjhfj1/autokeras](http://github.com/jhfjhfj1/autokeras)。
- en: 'The following steps will guide you through how to install AutoKeras and how
    to run an automated ML experiment using the library. Let''s get started:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将指导你如何安装AutoKeras以及如何使用库运行自动化机器学习实验。让我们开始吧：
- en: To get started with Auto-Keras, run the following `install` commands in Colab
    or in a Jupyter Notebook. Doing this will install `git uri`:![Figure 3.45 – AutoML
    with AutoKeras – installation
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要开始使用Auto-Keras，请在Colab或Jupyter Notebook中运行以下`install`命令。这样做将安装`git uri`：![图3.45
    – 使用AutoKeras的AutoML – 安装
- en: '](img/B16890_03_45.jpg)'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16890_03_45.jpg)'
- en: Figure 3.45 – AutoML with AutoKeras – installation
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.45 – 使用AutoKeras的AutoML – 安装
- en: Once you have met the dependencies, you can load the **MNIST dataset**:![Figure
    3.46 – AutoML with AutoKeras – loading the training data
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦满足依赖项，你可以加载**MNIST数据集**：![图3.46 – 使用AutoKeras的AutoML – 加载训练数据
- en: '](img/B16890_03_46.jpg)'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16890_03_46.jpg)'
- en: Figure 3.46 – AutoML with AutoKeras – loading the training data
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.46 – 使用AutoKeras的AutoML – 加载训练数据
- en: Now, you can get **AutoKeras** and go through the code for a classifier – in
    this case, an image classifier. **AutoKeras** shows the accuracy of data as it
    calculates the classification metrics:![Figure 3.47 – AutoML with AutoKeras –
    running the epochs
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您可以获取**AutoKeras**并查看分类器的代码——在这种情况下，是一个图像分类器。**AutoKeras**在计算分类度量时显示了数据的准确性：![图3.47
    – 使用AutoKeras的AutoML – 运行epoch
- en: '](img/B16890_03_47.jpg)'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16890_03_47.jpg)'
- en: Figure 3.47 – AutoML with AutoKeras – running the epochs
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.47 – 使用AutoKeras的AutoML – 运行epoch
- en: Fast forwarding through the fit procedure, now that you have discovered the
    `model.save` method and use it for `eval` at a later date. You can see the model
    stored in the `model_autokeras` folder on the left-hand pane of your Colab notebook,
    as shown in the following screenshot:![Figure 3.51 – AutoML with AutoKeras – exporting
    as a Keras model
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 快速跳过fit过程，现在您已经发现了`model.save`方法，并将在以后使用它进行`eval`。您可以在Colab笔记本的左侧面板中看到存储在`model_autokeras`文件夹中的模型，如下面的截图所示：![图3.51
    – 使用AutoKeras的AutoML – 导出为Keras模型
- en: '](img/B16890_03_51.jpg)'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16890_03_51.jpg)'
- en: Figure 3.51 – AutoML with AutoKeras – exporting as a Keras model
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.51 – 使用AutoKeras的AutoML – 导出为Keras模型
- en: 'Once the model has been saved, it can be used to retrieve data using `load_model`
    and make predictions against it, as shown in the following screenshot:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型被保存，就可以使用`load_model`来检索数据，并对它进行预测，如下面的截图所示：
- en: '![Figure 3.52 – AutoML with AutoKeras – predicting the values'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.52 – 使用AutoKeras的AutoML – 预测值'
- en: '](img/B16890_03_52.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16890_03_52.jpg)'
- en: Figure 3.52 – AutoML with AutoKeras – predicting the values
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.52 – 使用AutoKeras的AutoML – 预测值
- en: '**AutoKeras** uses **Efficient Neural Architecture Search** (**ENAS**), an
    approach similar to transfer learning. Like ensembles, the **hyperparameters**
    that are learned during the search are reused for other models, which helps us
    avoid having to retrain and provide improved performance.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '**AutoKeras**使用**高效神经网络架构搜索**（**ENAS**），这是一种类似于迁移学习的方法。像集成一样，在搜索过程中学习的**超参数**被用于其他模型，这有助于我们避免重新训练并提供改进的性能。'
- en: 'As we conclude our overview of open source libraries, some honorable mentions
    go to two excellent and easy-to-use AutoML frameworks: **Ludwig** and **AutoGluon**.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们概述开源库的总结中，有两款优秀且易于使用的AutoML框架值得特别提及：**Ludwig**和**AutoGluon**。
- en: Ludwig – a code-free AutoML toolbox
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ludwig – 无代码的AutoML工具箱
- en: Uber's automated ML tool, Ludwig, is an open source deep learning toolbox used
    for experimenting with, testing, and training ML models. Built on top of TensorFlow,
    Ludwig enables users to create model baselines and perform automated ML-style
    experimentation with different network architectures and models. In its latest
    release, Ludwig now integrates with CometML and supports BERT text encoders.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: Uber的自动化ML工具Ludwig是一个开源的深度学习工具箱，用于实验、测试和训练ML模型。建立在TensorFlow之上，Ludwig使用户能够创建模型基线和执行不同网络架构和模型的自动化ML风格实验。在其最新版本中，Ludwig现在与CometML集成并支持BERT文本编码器。
- en: 'The toolkit is available on GitHub to be downloaded: [https://github.com/uber/ludwig](https://github.com/uber/ludwig).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包可在GitHub上下载：[https://github.com/uber/ludwig](https://github.com/uber/ludwig)。
- en: 'There are tons of great examples with regard to this topic over here: [https://ludwig-ai.github.io/ludwig-docs/examples/#image-classification-mnist](https://ludwig-ai.github.io/ludwig-docs/examples/#image-classification-mnist).'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个主题，这里有很多很好的例子：[https://ludwig-ai.github.io/ludwig-docs/examples/#image-classification-mnist](https://ludwig-ai.github.io/ludwig-docs/examples/#image-classification-mnist)。
- en: AutoGluon – the AutoML toolkit for deep learning
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**AutoGluon** – 深度学习的AutoML工具包'
- en: From AWS Labs, with the goal of democratization of ML in mind, AutoGluon is
    described as being developed to enable "*easy-to-use and easy-to-extend AutoML
    with a focus on deep learning and real-world applications spanning image, text,
    or tabular data*". AutoGluon, an integral part of AWS's automated ML strategy,
    enables both junior and seasoned data scientists to build deep learning models
    and end-to-end solutions with ease. Like other automated ML toolkits, AutoGluon
    offers network architecture search, model selection, and the ability for you to
    improve custom models.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 从AWS实验室出发，考虑到ML民主化的目标，AutoGluon被描述为开发出来以实现“易于使用和易于扩展的AutoML，专注于深度学习和涵盖图像、文本或表格数据的实际应用*”。作为AWS自动化ML策略的一部分，AutoGluon使初级和经验丰富的数据科学家都能够轻松构建深度学习模型和端到端解决方案。像其他自动化ML工具包一样，AutoGluon提供网络架构搜索、模型选择以及改进自定义模型的能力。
- en: 'The toolkit is available on GitHub to be downloaded: [https://github.com/awslabs/autogluon](https://github.com/awslabs/autogluon).'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 工具包可在 GitHub 上下载：[https://github.com/awslabs/autogluon](https://github.com/awslabs/autogluon)。
- en: Summary
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you reviewed some major open source tools that are used for
    AutoML, including **TPOT**, **AutoKeras**, **auto-sklearn**, **Featuretools**,
    and **Microsoft NNI**. These tools have been provided to help you understand the
    concepts we discussed in [*Chapter 2*](B16890_02_Final_VK_ePub.xhtml#_idTextAnchor049),
    *Automated Machine Learning, Algorithms, and Techniques*, and the underlying approaches
    that are used in each of these libraries.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你回顾了一些用于 AutoML 的主要开源工具，包括 **TPOT**、**AutoKeras**、**auto-sklearn**、**Featuretools**
    和 **Microsoft NNI**。这些工具提供给你，以帮助你理解我们在 [*第 2 章*](B16890_02_Final_VK_ePub.xhtml#_idTextAnchor049)
    中讨论的概念，即 *自动化机器学习、算法和技术*，以及每个库中使用的底层方法。
- en: In the next chapter, we will do an in-depth review of commercial automated ML
    offerings, starting with the Microsoft Azure platform.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入探讨商业自动化机器学习产品，从微软 Azure 平台开始。
- en: Further reading
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information on the topics that were covered in this chapter, please
    refer to the resources and links:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 关于本章涵盖的主题的更多信息，请参阅资源和链接：
- en: TPOT for Automated ML in Python:[https://machinelearningmastery.com/tpot-for-automated-machine-learning-in-python/](https://machinelearningmastery.com/tpot-for-automated-machine-learning-in-python/)
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 中的 TPOT 自动机器学习：[https://machinelearningmastery.com/tpot-for-automated-machine-learning-in-python/](https://machinelearningmastery.com/tpot-for-automated-machine-learning-in-python/)
- en: Featuretools Demos:[https://www.featuretools.com/demos/](https://www.featuretools.com/demos/)
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Featuretools 示例：[https://www.featuretools.com/demos/](https://www.featuretools.com/demos/)
- en: Boston Dataset:[https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html)
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 波士顿数据集：[https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html)
- en: 'How to Automate ML: [https://www.knime.com/blog/how-to-automate-machine-learning](https://www.knime.com/blog/how-to-automate-machine-learning)'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何自动化机器学习：[https://www.knime.com/blog/how-to-automate-machine-learning](https://www.knime.com/blog/how-to-automate-machine-learning)
- en: '*Data-driven advice for applying ML to bioinformatics problems,* by Randal
    S. Olson:[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5890912/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5890912/)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由 Randal S. Olson 撰写的 *将机器学习应用于生物信息学问题的数据驱动建议*：[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5890912/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5890912/)
- en: 'TPOT Automated ML in Python: [https://towardsdatascience.com/tpot-automated-machine-learning-in-python-4c063b3e5de9](https://towardsdatascience.com/tpot-automated-machine-learning-in-python-4c063b3e5de9)'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 中的 TPOT 自动机器学习：[https://towardsdatascience.com/tpot-automated-machine-learning-in-python-4c063b3e5de9](https://towardsdatascience.com/tpot-automated-machine-learning-in-python-4c063b3e5de9)
- en: 'Microsoft NNI:     [https://github.com/microsoft/nni](https://github.com/microsoft/nni)'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软 NNI：[https://github.com/microsoft/nni](https://github.com/microsoft/nni)
- en: auto-sklearn:https://automl.github.io/auto-sklearn/master/examples/20_basic/example_regression.html#sphx-glr-examples-20-basic-example-regression-py
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: auto-sklearn：[https://automl.github.io/auto-sklearn/master/examples/20_basic/example_regression.html#sphx-glr-examples-20-basic-example-regression-py](https://automl.github.io/auto-sklearn/master/examples/20_basic/example_regression.html#sphx-glr-examples-20-basic-example-regression-py)
- en: TPOT Demos:https://github.com/EpistasisLab/tpot/blob/master/tutorials/Digits.ipynb
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TPOT 示例：[https://github.com/EpistasisLab/tpot/blob/master/tutorials/Digits.ipynb](https://github.com/EpistasisLab/tpot/blob/master/tutorials/Digits.ipynb)
