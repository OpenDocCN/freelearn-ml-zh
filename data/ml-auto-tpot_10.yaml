- en: '*Chapter 7*: Neural Network Classifier with TPOT'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第7章*：使用TPOT的神经网络分类器'
- en: 'In this chapter, you''ll learn how to build your deep learning classifier in
    an automated fashion – by using the TPOT library. It''s assumed that you know
    the basics of artificial neural networks, so terms such as *neurons*, *layers*,
    *activation functions*, and *learning rates* should sound familiar. If you don''t
    know how to explain these terms simply, please revisit [*Chapter 6*](B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073),
    *Getting Started with Deep Learning: Crash Course in Neural Networks*.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何以自动化的方式构建你的深度学习分类器——通过使用TPOT库。假设你已了解人工神经网络的基本知识，因此诸如*神经元*、*层*、*激活函数*和*学习率*等术语应该听起来很熟悉。如果你不知道如何简单地解释这些术语，请回顾[*第6章*](B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073)，*深度学习入门：神经网络快速入门*。
- en: Throughout this chapter, you'll learn how easy it is to build a simple classifier
    based on neural networks and how you can tweak the neural network so that it better
    suits your needs and the training data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的整个过程中，你将了解到构建基于神经网络的简单分类器是多么容易，以及你如何调整神经网络以更好地满足你的需求和训练数据。
- en: 'This chapter will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Exploring the dataset
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索数据集
- en: Exploring options for training neural network classifiers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索训练神经网络分类器的选项
- en: Training a neural network classifier
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练神经网络分类器
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You don''t need any prior hands-on experience with deep learning and neural
    networks. A knowledge of some basics concepts and terminology is a must, however.
    If you''re entirely new to the subject, please revisit [*Chapter 6*](B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073),
    *Getting Started with Deep Learning: Crash Course in Neural Networks*.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要有深度学习和神经网络的实际操作经验。然而，了解一些基本概念和术语是必须的。如果你对这个主题完全陌生，请回顾[*第6章*](B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073)，*深度学习入门：神经网络快速入门*。
- en: 'You can download the source code and dataset for this chapter here: [https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter07](https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter07).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在此处下载本章的源代码和数据集：[https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter07](https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter07)。
- en: Exploring the dataset
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据集
- en: There is no reason to go wild with the dataset. Just because we can train neural
    network models with TPOT doesn't mean we should spend 50+ pages exploring and
    transforming needlessly complex datasets.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 没有必要对数据集进行过度探索。仅仅因为我们可以用TPOT训练神经网络模型，并不意味着我们应该花费50多页来无谓地探索和转换复杂的数据集。
- en: 'For that reason, you''ll use a scikit-learn built-in dataset throughout the
    chapter – the Breast cancer dataset. This dataset doesn''t have to be downloaded
    from the web as it comes built-in with scikit-learn. Let''s start by loading and
    exploring it:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本章中，你将使用scikit-learn内置的数据集——乳腺癌数据集。这个数据集不需要从网络上下载，因为它已经内置在scikit-learn中。让我们先加载并探索它：
- en: 'To begin, you''ll need to load in a couple of libraries. We''re importing NumPy,
    pandas, Matplotlib, and Seaborn for easy data analysis and visualization. Also,
    we''re importing the `load_breast_cancer` function from the `sklearn.datasets`
    module. That''s the function that will load in the dataset. Finally, the `rcParams`
    module is imported from Matplotlib to make default styling a bit easier on the
    eyes:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，你需要加载几个库。我们导入NumPy、pandas、Matplotlib和Seaborn，以便于数据分析和可视化。此外，我们还从`sklearn.datasets`模块导入`load_breast_cancer`函数。这是将数据集加载进来的函数。最后，从Matplotlib导入`rcParams`模块，以便使默认样式更容易看清楚：
- en: '[PRE0]'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can now use the `load_breast_cancer` function to load in the dataset. The
    function returns a dictionary, so we can use the `keys()` method to print the
    keys:'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你现在可以使用`load_breast_cancer`函数来加载数据集。该函数返回一个字典，因此我们可以使用`keys()`方法来打印键：
- en: '[PRE1]'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The results are shown in the following diagram:'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.1 – Dictionary keys of the Breast cancer dataset'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.1 – 乳腺癌数据集的字典键'
- en: '](img/B16954_07_1.jpg)'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_07_1.jpg)'
- en: Figure 7.1 – Dictionary keys of the Breast cancer dataset
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.1 – 乳腺癌数据集的字典键
- en: You can now use this dictionary to extract attributes of interest. What is essential
    for now are the `data` and `target` keys. You can store their values to separate
    variables and then construct a data frame object from them. Working with raw values
    is possible, but a pandas data frame data structure will allow easier data manipulation,
    transformation, and exploration.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您现在可以使用这个字典来提取感兴趣的属性。目前最重要的是 `data` 和 `target` 键。您可以将它们的值存储到单独的变量中，然后从它们中构建一个数据框对象。使用原始值是可能的，但
    pandas 数据框数据结构将允许更轻松的数据操作、转换和探索。
- en: 'Here''s how you can transform these to a pandas data frame:'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里是如何将这些数据转换为 pandas 数据框的：
- en: '[PRE2]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The results are shown in the following table:'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下表所示：
- en: '![Figure 7.2 – Sample of eights rows from the Breast cancer dataset'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.2 – 乳腺癌数据集的八行样本'
- en: '](img/B16954_07_2.jpg)'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_07_2.jpg)'
- en: Figure 7.2 – Sample of eights rows from the Breast cancer dataset
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.2 – 乳腺癌数据集的八行样本
- en: 'The first thing you always want to do, analysis-wise, is to check for missing
    data. Pandas has an `isnull()` method built in, which returns Booleans for every
    value in the dataset. You can then call the `sum()` method on top of these results
    to get the count of missing values per column:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在分析方面，您首先想要做的是检查缺失数据。Pandas 内置了一个 `isnull()` 方法，它为数据集中的每个值返回布尔值。然后，您可以在这些结果上调用
    `sum()` 方法来获取每列的缺失值计数：
- en: '[PRE3]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The results are shown in the following diagram:'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.3 – Missing value count per column'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.3 – 每列的缺失值计数'
- en: '](img/B16954_07_3.jpg)'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_07_3.jpg)'
- en: Figure 7.3 – Missing value count per column
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.3 – 每列的缺失值计数
- en: As you can see, there are no missing values.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，没有缺失值。
- en: The next thing to do in the exploratory phase is to get familiar with your dataset.
    Data visualization techniques can provide an excellent way of doing so.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在探索阶段，下一步是熟悉您的数据集。数据可视化技术可以提供一种极好的方式来完成这项工作。
- en: 'For example, you can declare a function called `make_count_chart()` that takes
    any categorical attribute and visualizes its distribution. Here''s what the code
    for this function could look like:'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，您可以声明一个名为 `make_count_chart()` 的函数，它接受任何分类属性并可视化其分布。下面是这个函数的代码示例：
- en: '[PRE4]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You can now use the following code snippet to visualize the target variable
    to find out how many instances were benign and how many were malignant:'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您现在可以使用以下代码片段来可视化目标变量，以找出有多少实例是良性的，有多少是恶性的：
- en: '[PRE5]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The results are shown in the following diagram:'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.4 – Number of malignant and benign cases'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.4 – 恶性和良性病例数量'
- en: '](img/B16954_07_4.jpg)'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_07_4.jpg)'
- en: Figure 7.4 – Number of malignant and benign cases
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.4 – 恶性和良性病例数量
- en: As you can see, there's a decent amount more of malignant cases, so the classes
    aren't perfectly balanced. Class imbalance can lead to highly accurate but unusable
    models. Just imagine you are classifying a rare event. In every 10,000 transactions,
    only one is classified as an anomaly. Clearly, the machine learning model doesn't
    have much chance to learn what makes an anomaly so different from the rest.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，恶性病例的数量要多得多，所以类别并不完全平衡。类别不平衡可能导致高度准确但不可用的模型。想象一下，您正在对罕见事件进行分类。在每 10,000
    笔交易中，只有一笔被分类为异常。显然，机器学习模型没有多少机会学习使异常与其他事件不同的原因。
- en: Furthermore, always predicting that the transaction is normal leads to a 99.99%
    accurate model. State-of-the-art accuracy, for certain, but the model is unusable.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，总是预测交易是正常的会导致一个 99.99% 准确的模型。这是一个最先进的准确率，但模型不可用。
- en: There are numerous techniques for dealing with imbalanced datasets, but they
    are beyond the scope for this book.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 处理不平衡数据集有许多技术，但这些超出了本书的范围。
- en: Next stop – correlation analysis. The aim of this step is to take a glimpse
    at which feature(s) have the biggest effect on the target variables. In other
    words, we want to establish how correlated a change in direction in a feature
    is with the target class. Visualizing an entire correlation matrix on a dataset
    of 30+ columns isn't the best idea because it would require a figure too large
    to fit comfortably on a single page. Instead, we can calculate the correlation
    of the feature with the target variable.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个步骤是相关性分析。这一步的目标是看看哪些特征对目标变量影响最大。换句话说，我们想要确定特征方向变化与目标类之间的相关性。在 30+ 列的数据集上可视化整个相关性矩阵并不是最好的主意，因为这需要一个太大而无法舒适地放在单页上的图。相反，我们可以计算特征与目标变量之间的相关性。
- en: 'Here''s how you can do this for the `mean area` feature – by calling the `corrcoeff()`
    method from NumPy:'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里是如何为`平均面积`特征进行此操作的示例——通过从NumPy调用`corrcoeff()`方法：
- en: '[PRE6]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The results are shown in the following figure:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.5 – Correlation coefficient between a single feature and the target
    variable'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.5 – 单个特征与目标变量的相关系数'
- en: '](img/B16954_07_5.jpg)'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_07_5.jpg)'
- en: '[PRE7]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Please note the `[:-1]` at the beginning of the loop. Since the target variable
    is the last column, we can use the aforementioned slicing technique to exclude
    the target variable from the correlation calculation. The correlation coefficient
    between the target variable and the non-target variable would be 1, which is not
    particularly useful to us.
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意循环开始处的`[:-1]`。由于目标变量是最后一列，我们可以使用上述切片技术排除目标变量，从而不将其包含在相关性计算中。目标变量与非目标变量之间的相关系数将为1，这对我们来说并不特别有用。
- en: 'You can now use the following code to make a horizontal bar chart of the correlations
    with the target variable:'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您现在可以使用以下代码来绘制与目标变量的相关性水平条形图：
- en: '[PRE8]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The results are shown in the following diagram:'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.6 – Feature correlation with the target variable'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.6 – 特征与目标变量的相关性'
- en: '](img/B16954_07_6.jpg)'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_07_6.jpg)'
- en: Figure 7.6 – Feature correlation with the target variable
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.6 – 特征与目标变量的相关性
- en: As you can see, most of the features have a high negative correlation with the
    target variable. Negative correlation means that one variable increases as the
    other one decreases. In our case, a decrease in the number of features leads to
    an increase in the target variable.
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如您所见，大多数特征与目标变量具有高度负相关性。负相关性意味着当一个变量增加时，另一个变量会减少。在我们的例子中，特征数量的减少会导致目标变量的增加。
- en: You could also visualize the distribution of every numeric column with respect
    to the target variable value. To be more precise, this means two separate histograms
    are drawn on a single chart, and each histogram shows the distribution only for
    the respective target value's subset.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您还可以根据目标变量的值可视化每个数值列的分布。更准确地说，这意味着在单个图表上绘制两个单独的直方图，每个直方图只显示相应目标值子集的分布。
- en: For example, this means that one histogram will show the distribution of malignant
    and the other of benign instances, for each variable.
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，这意味着一个直方图将显示每个变量的恶性实例的分布，另一个直方图将显示良性实例的分布。
- en: The code snippet you're about to see declares a `draw_histogram()` function
    that goes over every column in a dataset, makes a histogram with respect to the
    distinct classes in the target variable, and appends this histogram to a figure.
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您即将看到的代码片段声明了一个`draw_histogram()`函数，该函数遍历数据集中的每一列，根据目标变量的不同类别绘制直方图，并将此直方图附加到图上。
- en: Once all of the histograms are appended, the figure is displayed to the user.
    The user also has to specify how many rows and columns they want, which gives
    a bit of extra freedom when designing visualizations.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦所有直方图都被附加，该图将显示给用户。用户还必须指定他们想要的行数和列数，这为设计可视化提供了一些额外的自由度。
- en: 'Here is the code snippet for drawing this histogram grid:'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是绘制此直方图网格的代码片段：
- en: '[PRE9]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This will be a pretty large data visualization, containing 9 rows and 4 columns.
    The last row will have only 2 histograms, as there are 30 continuous variables
    in total.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将是一个非常大的数据可视化，包含9行和4列。最后一行将只有2个直方图，因为总共有30个连续变量。
- en: 'The results are shown in the following diagram:'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.7 – Histogram for every continuous variable'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.7 – 每个连续变量的直方图'
- en: '](img/B16954_07_7.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16954_07_7.jpg)'
- en: Figure 7.7 – Histogram for every continuous variable
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 – 每个连续变量的直方图
- en: As you can see, there is a distinct separation most of the time, so our model
    shouldn't have too much trouble making decent separations between the classes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，大多数情况下存在明显的分离，因此我们的模型在类之间进行合理的分离时不应有太多困难。
- en: And that's all we'll do with regard to the exploratory data analysis. You can,
    and are encouraged to, do more, especially with custom and more complex datasets.
    The next section will introduce you to the options you have for training automated
    neural network classifiers.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 那就是我们在探索性数据分析方面要做的所有事情。您可以，并且被鼓励去做更多，特别是对于自定义和更复杂的数据集。下一节将向您介绍您用于训练自动神经网络分类器的选项。
- en: Exploring options for training neural network classifiers
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索训练神经网络分类器的选项
- en: You have a lot of options when training neural network models with TPOT. The
    whole neural network story is still new and experimental with TPOT, requiring
    a bit more manual work than regular scikit-learn estimators.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用TPOT训练神经网络模型时，你有许多选项。整个神经网络的故事在TPOT中仍然是新的和实验性的，需要比常规的scikit-learn估计器更多的手动工作。
- en: By default, TPOT won't use the neural network models unless you explicitly specify
    that it has to. This specification is done by selecting an adequate configuration
    dictionary that includes one or more neural network estimators (you can also write
    these manually).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，TPOT不会使用神经网络模型，除非你明确指定它必须使用。这种指定是通过选择一个包含一个或多个神经网络估计器的适当配置字典来完成的（你也可以手动编写这些字典）。
- en: 'The more convenient option is to import configuration dictionaries from the
    `tpot/config/classifier_nn.py` file. This file contains two PyTorch classifier
    configurations, as visible in the following diagram:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 更方便的选项是从`tpot/config/classifier_nn.py`文件中导入配置字典。该文件包含两个PyTorch分类器配置，如下面的图所示：
- en: '![Figure 7.8 – TPOT PyTorch classifier configurations'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.8 – TPOT PyTorch分类器配置'
- en: '](img/B16954_07_8.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16954_07_8.jpg)'
- en: Figure 7.8 – TPOT PyTorch classifier configurations
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 – TPOT PyTorch分类器配置
- en: 'From the preceding diagram, you can see that TPOT can currently handle two
    different types of classifiers based on deep learning libraries:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图中，你可以看到TPOT目前可以处理基于深度学习库的两种不同类型的分类器：
- en: 'Logistic regression: shown in `tpot.builtins.PytorchLRClassifier`'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归：在`tpot.builtins.PytorchLRClassifier`中展示
- en: 'Multi-layer perceptron: shown in `tpot.builtins.PytorchMLPClassifier`'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多层感知器：在`tpot.builtins.PytorchMLPClassifier`中展示
- en: 'You can either import this file or write the configurations manually. In addition,
    you can also specify your own configuration dictionaries, which somehow modify
    the existing ones. For example, you can use this code to use a PyTorch-based logistic
    regression estimator:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以选择导入此文件或手动编写配置。此外，你还可以指定自己的配置字典，这些字典以某种方式修改了现有的配置。例如，你可以使用以下代码来使用基于PyTorch的逻辑回归估计器：
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Custom configurations will be discussed later in the chapter when we start to
    implement neural network classifiers.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章后面，当我们开始实现神经网络分类器时，将讨论自定义配置。
- en: You should keep in mind that training neural network classifiers with TPOT is
    an expensive task and will typically take much more time to train than scikit-learn
    estimators. As a rule of thumb, you should expect the training time to be several
    orders of magnitude slower with neural networks. This is because neural network
    architectures can have millions of trainable and adjustable parameters, and finding
    the correct value for all of them takes time.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该记住，使用TPOT训练神经网络分类器是一个耗时的任务，通常比scikit-learn估计器训练时间要长得多。一般来说，你应该预计神经网络训练时间要慢几个数量级。这是因为神经网络架构可以有数百万个可训练和可调整的参数，找到所有这些参数的正确值需要时间。
- en: Having that in mind, you should always consider simpler options first, as TPOT
    is highly likely to give you an excellent-performing pipeline on the default scikit-learn
    estimators.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，你应该首先考虑更简单的选项，因为TPOT很可能在默认的scikit-learn估计器上为你提供一个性能优异的管道。
- en: The next section will continue with the training of neural network classifiers
    right where the previous section stopped and will show you how different training
    configurations can be used to train your models.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将继续从上一节停止的地方继续训练神经网络分类器，并展示如何使用不同的训练配置来训练你的模型。
- en: Training a neural network classifier
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练神经网络分类器
- en: 'Up to this point, we''ve loaded in the dataset and undertaken a basic exploratory
    data analysis. This section of the chapter will focus on training models through
    different configurations:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经加载了数据集并进行了基本的数据探索性分析。本章的这一部分将专注于通过不同的配置来训练模型：
- en: Before we can move on to model training, we need to split our dataset into training
    and testing subsets. Doing so will allow us to have a sample of the data never
    seen by the model, and which can later be used for evaluation.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们开始模型训练之前，我们需要将我们的数据集分成训练集和测试集。这样做将允许我们有一个模型从未见过的数据样本，并且可以稍后用于评估。
- en: 'The following code snippet will split the data in a 75:25 ratio:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段将以75:25的比例分割数据：
- en: '[PRE11]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can begin with training next.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以开始训练了。
- en: As always, let's start simply by training a baseline model. This will serve
    as a minimum viable performance that the neural network classifier has to outperform.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像往常一样，让我们从训练一个基线模型开始。这将作为神经网络分类器必须超越的最小可行性能。
- en: The simplest binary classification algorithm is logistic regression. The following
    code snippet imports it from scikit-learn, alongside some evaluation metrics,
    such as a confusion matrix and an accuracy score. Furthermore, the snippet instantiates
    the model, trains it, makes a prediction on the holdout set, and prints the confusion
    matrix and the accuracy score.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最简单的二元分类算法是逻辑回归。以下代码片段从scikit-learn中导入它，以及一些评估指标，如混淆矩阵和准确率。此外，该片段实例化了模型，进行了训练，在保留集上进行了预测，并打印了混淆矩阵和准确率。
- en: 'The code snippet is as follows:'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是一个代码片段：
- en: '[PRE12]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The results are shown in the following diagram:'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.9 – Confusion matrix and accuracy of the baseline model'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.9 – 基线模型的混淆矩阵和准确率]'
- en: '](img/B16954_07_9.jpg)'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_07_9.jpg)'
- en: Figure 7.9 – Confusion matrix and accuracy of the baseline model
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.9 – 基线模型的混淆矩阵和准确率
- en: We now know that the baseline model is 96.5% accurate, making 4 false positives
    and 1 false negative. Next, we'll train an automated neural network classifier
    with TPOT and see how the results compare.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们现在知道基线模型的准确率为96.5%，产生了4个假阳性和1个假阴性。接下来，我们将使用TPOT训练一个自动化的神经网络分类器，并看看结果如何比较。
- en: As mentioned before, training a neural network classifier with TPOT is a heavy
    task. For that reason, you might be better off switching to a free GPU Cloud environment,
    such as *Google Colab*.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，使用TPOT训练神经网络分类器是一项艰巨的任务。因此，你可能最好切换到一个免费的GPU云环境，例如*Google Colab*。
- en: 'This will ensure faster training time, but also you won''t melt your PC. Once
    there, you can use the following snippet to train the PyTorch-based logistic regression
    model:'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将确保更快的训练时间，同时你也不会让你的电脑过热。一旦进入该环境，你可以使用以下代码片段来训练基于PyTorch的逻辑回归模型：
- en: '[PRE13]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This will train the model for two generations. You''ll see various outputs
    during training, such as the following:'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将训练模型两代。你会在训练过程中看到各种输出，如下所示：
- en: '![Figure 7.10 – TPOT neural network training process'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.10 – TPOT神经网络训练过程]'
- en: '](img/B16954_07_10.jpg)'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_07_10.jpg)'
- en: '[PRE14]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The results are shown in the following diagram:'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.12 – TPOT PyTorch logistic regression best pipeline'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.12 – TPOT PyTorch逻辑回归最佳流程]'
- en: '](img/B16954_07_12.jpg)'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_07_12.jpg)'
- en: '[PRE15]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The results are shown in the following figure:'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.13 – Confusion matrix and accuracy score of a PyTorch logistic regression
    model'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.13 – PyTorch逻辑回归模型的混淆矩阵和准确率得分]'
- en: '](img/B16954_07_13.jpg)'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_07_13.jpg)'
- en: Figure 7.13 – Confusion matrix and accuracy score of a PyTorch logistic regression
    model
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.13 – PyTorch逻辑回归模型的混淆矩阵和准确率得分
- en: As you can see, two generations weren't enough to produce a better-than-baseline
    model. Let's see whether using a multi-layer perceptron model could help.
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，两代并不足以产生一个优于基线模型的结果。让我们看看使用多层感知器模型是否有所帮助。
- en: We're still in the Google Colab environment, as training on your own PC is significantly
    slower (depending on your configuration). The idea now is to use the multi-layer
    perceptron model instead of logistic regression and see how the change in the
    model could affect performance.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们仍然处于Google Colab环境中，因为在你自己的电脑上训练要慢得多（取决于你的配置）。现在的想法是使用多层感知器模型而不是逻辑回归，看看模型的变化如何影响性能。
- en: 'To begin, you''ll have to make a change to the `template` parameter of `TPOTClassifier`,
    as shown here:'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，你必须修改`TPOTClassifier`的`template`参数，如下所示：
- en: '[PRE16]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As you can see, we''re now using `PytorchMLPClassifier` instead of `PytorchLRClassifier`.
    To begin the optimization process, simply call the `fit()` method with the training
    data:'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，我们现在使用`PytorchMLPClassifier`而不是`PytorchLRClassifier`。要开始优化过程，只需用训练数据调用`fit()`方法：
- en: '[PRE17]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'As with the logistic regression algorithm, you''ll also see the progress bar
    during the optimization process:'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与逻辑回归算法一样，你也会在优化过程中看到进度条：
- en: '![Figure 7.14 – TPOT multi-layer perceptron training process'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.14 – TPOT多层感知器训练过程]'
- en: '](img/B16954_07_14.jpg)'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_07_14.jpg)'
- en: '[PRE18]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The results are shown in the following diagram:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.16 – TPOT PyTorch multi-layer perceptron best pipeline'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.16 – TPOT PyTorch多层感知器最佳流程]'
- en: '](img/B16954_07_16.jpg)'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B16954_07_16.jpg)'
- en: '[PRE19]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The results are shown in the following figure:'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.17 – Confusion matrix and accuracy score of a PyTorch multi-layer
    perceptron model'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.17 – PyTorch多层感知器模型的混淆矩阵和准确率得分'
- en: '](img/B16954_07_17.jpg)'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16954_07_17.jpg)'
- en: Figure 7.17 – Confusion matrix and accuracy score of a PyTorch multi-layer perceptron
    model
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.17 – PyTorch多层感知器模型的混淆矩阵和准确率得分
- en: As you can see, two generations still weren't enough to produce a better-than-baseline
    model, but the MLP model outperformed the logistic regression one. Let's now see
    whether using a custom training configuration could push the accuracy even higher.
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，两代仍然不足以产生优于基线模型的结果，但MLP模型的表现优于逻辑回归模型。现在让我们看看使用自定义训练配置是否可以将准确率进一步提高。
- en: Finally, let's see how you can specify possible hyperparameter values for either
    logistic regression or multi-layer perceptron models. All you have to do is specify
    a custom configuration dictionary, which holds the hyperparameters you want to
    test for (such as learning rate, batch size, and number of epochs), and assign
    values to those hyperparameters in the form of a list.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们看看如何为逻辑回归或多层感知器模型指定可能的超参数值。你所要做的就是指定一个自定义配置字典，其中包含你想要测试的超参数（如学习率、批量大小和迭代次数），并以列表的形式为这些超参数分配值。
- en: 'Here''s an example:'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里有一个例子：
- en: '[PRE20]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You can now use this `custom_config` dictionary when training models. Here
    is an example training snippet based on a multi-layer perceptron model:'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，你可以在训练模型时使用这个`custom_config`字典。以下是一个基于多层感知器模型的示例训练片段：
- en: '[PRE21]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As you can see, only the `config_dict` parameter has changed. Once the training
    process has started, you''ll see a progress bar similar to this one in the notebook:'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，只有`config_dict`参数发生了变化。一旦训练过程开始，你将在笔记本中看到类似这样的进度条：
- en: '![Figure 7.18 – TPOT custom tuning with neural networks'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.18 – 使用神经网络的TPOT自定义调整'
- en: '](img/B16954_07_18.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16954_07_18.jpg)'
- en: Figure 7.18 – TPOT custom tuning with neural networks
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.18 – 使用神经网络的TPOT自定义调整
- en: 'Once the training process is complete, you should see something along the following
    lines in the notebook:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练过程完成，你应在笔记本中看到以下类似的内容：
- en: '![Figure 7.19 – TPOT multi-layer perceptron classifier with custom hyperparameters'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.19 – 带有自定义超参数的TPOT多层感知器分类器'
- en: '](img/B16954_07_19.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16954_07_19.jpg)'
- en: Figure 7.19 – TPOT multi-layer perceptron classifier with custom hyperparameters
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.19 – 带有自定义超参数的TPOT多层感知器分类器
- en: 'And that''s all there is to it! Just to verify, you can examine the best-fitted
    pipeline by executing the following command:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 就这么简单！为了验证，你可以通过执行以下命令来检查最佳拟合管道：
- en: '[PRE22]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The results are shown in the following figure:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![Figure 7.20 – TPOT best-fitted pipeline for a model with custom hyperparameters'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.20 – 带有自定义超参数的模型的TPOT最佳拟合管道'
- en: '](img/B16954_07_20.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16954_07_20.jpg)'
- en: Figure 7.20 – TPOT best-fitted pipeline for a model with custom hyperparameters
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.20 – 带有自定义超参数的模型的TPOT最佳拟合管道
- en: As you can see, all of the hyperparameter values are within the specified range,
    which indicates that the custom model was trained successfully.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，所有超参数值都在指定的范围内，这表明自定义模型已成功训练。
- en: This concludes the model training portion of this section and this section in
    general. What follows is a brief summary of everything we have learned thus far,
    and a brief introduction to everything that will follow in the upcoming chapters.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了本节以及本节整体中的模型训练部分。接下来是一个对我们迄今为止所学内容的简要总结，以及对即将在后续章节中介绍内容的简要介绍。
- en: Summary
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter was quite intensive in terms of hands-on examples and demonstrations.
    You've hopefully managed to learn how to train automated classification pipelines
    with TPOT and what you can tweak during the process.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 本章在动手示例和演示方面相当密集。你或许已经学会了如何使用TPOT训练自动化分类管道，以及在整个过程中你可以调整什么。
- en: You should now be capable of training any kind of automated machine learning
    model with TPOT, whether we're talking about regression, classification, standard
    classifiers, or neural network classifiers. There is good news, as this was the
    last chapter with TPOT examples.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你应该能够使用TPOT训练任何类型的自动化机器学习模型，无论是回归、分类、标准分类器还是神经网络分类器。这是一个好消息，因为这是TPOT示例的最后一章。
- en: In the following chapter, [*Chapter 8*](B16954_08_Final_SK_ePub.xhtml#_idTextAnchor093),
    *TPOT Model Deployment*, you'll learn how to wrap the predictive functionality
    of your models inside a REST API, which will then be tested and deployed both
    locally and to the cloud. You'll also learn how to communicate with the API once
    it's deployed.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章[*第8章*](B16954_08_Final_SK_ePub.xhtml#_idTextAnchor093)，*TPOT模型部署*，你将学习如何将模型的预测功能封装在REST
    API中，然后将在本地和云中进行测试和部署。你还将学习部署后如何与API进行通信。
- en: Finally, in the previous chapter, [*Chapter 9*](B16954_09_Final_SK_ePub.xhtml#_idTextAnchor102),
    *Using the Deployed TPOT Model in Production*, you'll learn how to develop something
    useful with the deployed APIs. To be more precise, you'll learn how to make predictions
    in the Notebook environment by making REST calls to the deployed API, and you'll
    learn how to develop a simple GUI application that makes your model presentable
    to the end user.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在上一章[*第9章*](B16954_09_Final_SK_ePub.xhtml#_idTextAnchor102)，*在生产中使用部署的TPOT模型*，你将学习如何利用部署的API开发有用的东西。更准确地说，你将学习如何在笔记本环境中通过向部署的API发起REST调用来进行预测，以及如何开发一个简单的GUI应用程序，使你的模型对最终用户更具吸引力。
- en: As always, feel free to study TPOT in more depth, but by now, you're well ahead
    of the majority, and you're ready to make machine learning useful. See you there!
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，你可以更深入地研究TPOT，但到目前为止，你已经领先于大多数人，并且你准备好让机器学习变得有用。在那里见！
- en: Questions
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Which two algorithms are available in TPOT with regard to neural networks?
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TPOT中关于神经网络有哪些可用的算法？
- en: Approximately how many times are neural network classifiers slower to train
    than the default, scikit-learn ones?
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大约神经网络分类器训练速度比默认的scikit-learn分类器慢多少倍？
- en: List and briefly explain the different hyperparameters available when training
    models with TPOT and neural networks.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出并简要解释使用TPOT和神经网络训练模型时可用的一些超参数。
- en: Can you specify a custom range of hyperparameter values when training custom
    neural network models with TPOT? If so, how?
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用TPOT训练自定义神经网络模型时，能否指定自定义的超参数值范围？如果是的话，如何操作？
- en: How can you find the best-fitted pipeline after the model has finished training?
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练完成后，如何找到最佳拟合的流水线？
- en: What are the advantages of using a GPU runtime such as Google Colab when training
    neural network models with TPOT?
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用如Google Colab这样的GPU运行时在TPOT训练神经网络模型时有哪些优势？
- en: Describe why a single neuron in the multi-layer perceptron model can be thought
    of as logistic regression.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述为什么多层感知器模型中的单个神经元可以被视为逻辑回归。
