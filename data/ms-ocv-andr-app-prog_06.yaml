- en: Chapter 6. Working with Image Alignment and Stitching
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 使用图像对齐和拼接
- en: One limitation of cameras is the limited field of view, often shortened to FOV.
    Field-of-view is the parameter that defines how much information can be captured
    in one frame obtained by the camera. So, to capture an image that requires a larger
    field-of-view, we use image stitching. Image stitching is a method of joining
    multiple images to form a bigger image that represents the information that is
    consistent with the original images.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 相机的局限性之一是视野有限，通常简称为FOV。视野是定义通过相机获得的一帧中可以捕获多少信息的参数。因此，为了捕捉需要更大视野的图像，我们使用图像拼接。图像拼接是一种将多个图像连接起来形成更大图像的方法，该图像表示与原始图像一致的信息。
- en: 'In this chapter, we will take a look at the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨以下主题：
- en: Image stitching
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像拼接
- en: Image alignment
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像对齐
- en: Video stabilization
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频稳定
- en: Stereo vision
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 立体视觉
- en: Image stitching
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像拼接
- en: 'There has been a lot of work in image stitching over the years, but we will
    take a look at the algorithm OpenCV implements internally. Most of it was proposed
    by Michael Brown and David Lowe. Image stitching is done in the following steps:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，在图像拼接方面已经做了很多工作，但我们将探讨OpenCV内部实现的算法。其中大部分是由Michael Brown和David Lowe提出的。图像拼接按照以下步骤进行：
- en: Find suitable features and match them reliably across the set of images to obtain
    the relative positioning.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在图像集中找到合适的特征并可靠地匹配它们以获得相对位置。
- en: Develop the geometry to choose reliable features that are invariant to rotation,
    scale, and illumination.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开发几何学以选择对旋转、比例和光照不变的可靠特征。
- en: Match images using the RANSAC algorithm and a probabilistic model for verification.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用RANSAC算法和概率模型进行验证来匹配图像。
- en: Align the matched images.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对齐匹配的图像。
- en: Render the results to obtain a panoramic image. We use automatic straightening,
    gain compensation, and multi-band blending to achieve a seamlessly stitched panoramic
    image, as shown here:![Image stitching](img/B02052_06_01.jpg)
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 渲染结果以获得全景图像。我们使用自动校正、增益补偿和多波段混合来实现无缝拼接的全景图像，如图所示：![图像拼接](img/B02052_06_01.jpg)
- en: Feature detection and matching
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征检测与匹配
- en: First, we find and match SIFT features between all the images. By doing this,
    we get the scale and orientation associated with each feature point. With these
    details, we can form a similarity invariant matrix, where we can make appropriate
    measurements for calculations. We accumulate local gradients in the orientation
    histograms to obtain such a frame. By implementing such an algorithm, edges can
    shift slightly without modifying the descriptor values, thereby providing small
    levels of affine and shift invariances. The algorithm also proposes to achieve
    the illumination invariance using gradients to eliminate bias and normalizes the
    descriptor vector to eliminate the gain.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们在所有图像之间找到并匹配SIFT特征。通过这样做，我们得到与每个特征点相关的比例和方向。有了这些细节，我们可以形成一个相似性不变矩阵，在其中我们可以进行适当的测量以进行计算。我们在方向直方图中累积局部梯度以获得这样的帧。通过实现这样的算法，边缘可以略微移动而不会修改描述符值，从而提供小的仿射和位移不变性。该算法还建议使用梯度来实现光照不变性，以消除偏差并归一化描述符向量以消除增益。
- en: The algorithm also makes the assumption that a camera only rotates about its
    optical center. Due to this assumption, we can define rotations along the three
    primary axes, *x*, *y*, and *z*, as ![Feature detection and matching](img/B02052_06_11.jpg),
    and ![Feature detection and matching](img/B02052_06_12.jpg), respectively. We
    define a vector *θ*, as ![Feature detection and matching](img/B02052_06_13.jpg).
    We also use the focal length, *f* as a parameter. Thus, we get the pairwise homographies
    as ![Feature detection and matching](img/B02052_06_14.jpg).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法还假设相机仅围绕其光学中心旋转。由于这个假设，我们可以定义沿三个主轴的旋转，*x*，*y*，和*z*，分别如![特征检测与匹配](img/B02052_06_11.jpg)和![特征检测与匹配](img/B02052_06_12.jpg)所示。我们定义一个向量*θ*，如![特征检测与匹配](img/B02052_06_13.jpg)所示。我们还使用焦距，*f*作为一个参数。因此，我们得到成对的透视变换，如![特征检测与匹配](img/B02052_06_14.jpg)所示。
- en: '![Feature detection and matching](img/B02052_06_15.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![特征检测与匹配](img/B02052_06_15.jpg)'
- en: 'Here, ![Feature detection and matching](img/B02052_06_16.jpg) and ![Feature
    detection and matching](img/B02052_06_17.jpg) are the homographic image positions.
    ![Feature detection and matching](img/B02052_06_18.jpg) is the image position
    in a 2-dimensional space:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![特征检测与匹配](img/B02052_06_16.jpg)和![特征检测与匹配](img/B02052_06_17.jpg)是单应性图像位置。![特征检测与匹配](img/B02052_06_18.jpg)是二维空间中的图像位置：
- en: '![Feature detection and matching](img/B02052_06_19.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![特征检测与匹配](img/B02052_06_19.jpg)'
- en: 'The values of ![Feature detection and matching](img/B02052_06_20.jpg) and ![Feature
    detection and matching](img/B02052_06_21.jpg) are defined as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![特征检测与匹配](img/B02052_06_20.jpg)和![特征检测与匹配](img/B02052_06_21.jpg)的值定义如下：'
- en: '![Feature detection and matching](img/B02052_06_22.jpg)![Feature detection
    and matching](img/B02052_06_23.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![特征检测与匹配](img/B02052_06_22.jpg)![特征检测与匹配](img/B02052_06_23.jpg)'
- en: 'As you can see, this representation of R is consistent with the exponential
    form of depicting rotations. We have included provisions to allow small changes
    in positions. Hence, we have the following result:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这种R的表示与旋转的指数形式表示是一致的。我们已包括允许位置有微小变化的条款。因此，我们得到以下结果：
- en: '![Feature detection and matching](img/B02052_06_24.jpg)![Feature detection
    and matching](img/B02052_06_25.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![特征检测与匹配](img/B02052_06_24.jpg)![特征检测与匹配](img/B02052_06_25.jpg)'
- en: '![Feature detection and matching](img/B02052_06_26.jpg) represents the affine
    transformation of an image obtained by calculating linear homography of ![Feature
    detection and matching](img/B02052_06_27.jpg).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![特征检测与匹配](img/B02052_06_26.jpg)表示通过计算![特征检测与匹配](img/B02052_06_27.jpg)的线性单应性得到的图像的仿射变换。'
- en: After detecting features in all the images, we need to match them to find their
    relative arrangements. For this, we match the overlapping features using the k-nearest
    neighbors (with *k = 4*) in the feature space to obtain overlapping features.
    This method is employed to take into consideration the fact that each feature
    may overlap in more than one image.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有图像中检测到特征后，我们需要将它们匹配起来以找到它们的相对排列。为此，我们使用特征空间中的k最近邻（*k = 4*）来匹配重叠特征，以获得重叠特征。这种方法被采用以考虑每个特征可能在一个以上的图像中重叠的事实。
- en: Image matching
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像匹配
- en: By now, we have obtained the features and have the matches between features.
    Now we need to obtain the matching images to form the panorama. To form a panorama,
    we need a small number of images to match any image, so as to find adjacent images.
    The algorithm suggests the use of six matching images to the current image. This
    section is performed in two parts. First, we estimate the homography with which
    the two frames are compatible and we find a set of inliers for the same. For this,
    we use the RANSAC algorithm. Then we use a probabilistic model to verify the match
    between the images.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经获得了特征和特征之间的匹配。现在我们需要获得匹配图像以形成全景图。为了形成全景图，我们需要少量图像来匹配任何图像，以便找到相邻图像。算法建议使用六个匹配图像与当前图像匹配。本节分为两部分进行。首先，我们估计两个帧兼容的单应性，并为同一帧找到一组内点。为此，我们使用RANSAC算法。然后我们使用概率模型来验证图像之间的匹配。
- en: Homography estimation using RANSAC
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用RANSAC进行单应性估计
- en: The RANSAC algorithm, short for Random Sample Consensus, is an algorithm that
    uses a small set of randomly chosen matches in images to estimate the image transformation
    parameters. For image stitching, we use four feature matches to compute the homography
    between them. For this, the algorithm proposes the use of the direct linear transformation
    method described by R. Hartley and A. Zisserman. This is performed for 500 iterations
    and ultimately, the solution with the maximum number of *inliers* is chosen. Inliers
    are those features whose linear projections are consistent with the homography,
    H, up to a specified tolerance value for pixels. By performing probability calculations,
    it was found that the probability of finding a match is very high. For example,
    if inliers between images match with a probability of 0.5, the probability of
    not finding the homography is ![Homography estimation using RANSAC](img/B02052_06_28.jpg).
    Hence, RANSAC is quite successful at estimating H. This method is called the maximum
    likelihood estimation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: RANSAC算法，即随机样本一致性算法，是一种使用图像中随机选择的一小部分匹配来估计图像变换参数的算法。对于图像拼接，我们使用四个特征匹配来计算它们之间的单应性。为此，算法建议使用R.
    Hartley和A. Zisserman描述的直接线性变换方法。这个过程进行了500次迭代，最终选择具有最大数量*内点*的解。内点是指其线性投影与单应性H一致，直到达到指定的像素容差值。通过进行概率计算，发现找到匹配的概率非常高。例如，如果图像之间的内点匹配概率为0.5，则找不到单应性的概率为![使用RANSAC进行单应性估计](img/B02052_06_28.jpg)。因此，RANSAC在估计H方面非常成功。这种方法被称为最大似然估计。
- en: Verification of image matches using a probabilistic model
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用概率模型验证图像匹配
- en: 'By the model obtained till now, we have a set of feature matches within the
    overlap region (inliers), and some features within the area of overlap that do
    not match (outliers). Using a probabilistic model, we will verify that the obtained
    set of inliers and outliers produces a valid image match. The algorithm makes
    the assumption that the probability of the ![Verification of image matches using
    a probabilistic model](img/B02052_06_29.jpg) feature matching is an independent
    Bernoulli trial. The two equations that are obtained from this are shown as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过到目前为止获得的模型，我们有一组重叠区域（内点）内的特征匹配，以及重叠区域内不匹配的一些特征（异常值）。使用概率模型，我们将验证获得的内点和异常值集是否产生有效的图像匹配。算法假设![使用概率模型验证图像匹配](img/B02052_06_29.jpg)特征匹配的概率是一个独立的伯努利试验。从这个假设中得到的两个方程如下所示：
- en: '![Verification of image matches using a probabilistic model](img/B02052_06_30.jpg)![Verification
    of image matches using a probabilistic model](img/B02052_06_31.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![使用概率模型验证图像匹配](img/B02052_06_30.jpg)![使用概率模型验证图像匹配](img/B02052_06_31.jpg)'
- en: 'Here, ![Verification of image matches using a probabilistic model](img/B02052_06_32.jpg)
    represents the total number of features present in the overlap area. ![Verification
    of image matches using a probabilistic model](img/B02052_06_33.jpg) represents
    the total number of inliers. *m* specifies whether the two images have been matched
    correctly or not. ![Verification of image matches using a probabilistic model](img/B02052_06_35.jpg)
    is the probability of the feature being an inlier, given a correct image match.
    ![Verification of image matches using a probabilistic model](img/B02052_06_36.jpg)
    is the probability that the feature is not an inlier, given a correct image match.
    ![Verification of image matches using a probabilistic model](img/B02052_06_37.jpg)
    represents the set of feature matches ![Verification of image matches using a
    probabilistic model](img/B02052_06_38.jpg). *B* represents the binomial distribution,
    as shown here:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![使用概率模型验证图像匹配](img/B02052_06_32.jpg)代表重叠区域中存在的特征总数。![使用概率模型验证图像匹配](img/B02052_06_33.jpg)代表内点的总数。*m*指定两个图像是否正确匹配。![使用概率模型验证图像匹配](img/B02052_06_35.jpg)是在正确图像匹配的条件下，特征是内点的概率。![使用概率模型验证图像匹配](img/B02052_06_36.jpg)是在正确图像匹配的条件下，特征不是内点的概率。![使用概率模型验证图像匹配](img/B02052_06_37.jpg)代表特征匹配集![使用概率模型验证图像匹配](img/B02052_06_38.jpg)。*B*代表二项分布，如下所示：
- en: '![Verification of image matches using a probabilistic model](img/B02052_06_39.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![使用概率模型验证图像匹配](img/B02052_06_39.jpg)'
- en: 'For the purpose of this algorithm, the values of ![Verification of image matches
    using a probabilistic model](img/B02052_06_40.jpg) and ![Verification of image
    matches using a probabilistic model](img/B02052_06_41.jpg) are set to 0.6 and
    0.1, respectively. Using Bayes rule, we can calculate the probability of an image
    match being valid as:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本算法的目的，![使用概率模型验证图像匹配](img/B02052_06_40.jpg)和![使用概率模型验证图像匹配](img/B02052_06_41.jpg)的值分别设置为0.6和0.1。使用贝叶斯规则，我们可以计算出图像匹配有效的概率为：
- en: '![Verification of image matches using a probabilistic model](img/B02052_06_42.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![使用概率模型验证图像匹配](img/B02052_06_42.jpg)'
- en: 'An image match is considered to be valid if the value of the preceding expression
    is greater than a pre-chosen minimum probability. The algorithm suggests the use
    of ![Verification of image matches using a probabilistic model](img/B02052_06_43.jpg)
    and ![Verification of image matches using a probabilistic model](img/B02052_06_44.jpg).
    The match is accepted if the following equation is satisfied, and rejected otherwise:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果前述表达式的值大于预先选择的最低概率，则认为图像匹配是有效的。该算法建议使用![使用概率模型验证图像匹配](img/B02052_06_43.jpg)和![使用概率模型验证图像匹配](img/B02052_06_44.jpg)。如果满足以下方程，则匹配被接受，否则被拒绝：
- en: '![Verification of image matches using a probabilistic model](img/B02052_06_45.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![使用概率模型验证图像匹配](img/B02052_06_45.jpg)'
- en: 'A condition that arises from the assumption made earlier is that for a valid
    image match the following equation must be satisfied:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从早期假设中产生的一个条件是，对于有效的图像匹配，必须满足以下方程：
- en: '![Verification of image matches using a probabilistic model](img/B02052_06_46.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![使用概率模型验证图像匹配](img/B02052_06_46.jpg)'
- en: In the original paper, the authors also proposed a method by which the parameters
    can be learnt from the images rather than assigning fixed values to them.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始论文中，作者还提出了一种方法，通过这种方法可以从图像中学习参数，而不是为它们分配固定值。
- en: Bundle adjustment
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 捆绑调整
- en: Brown and Lowe's algorithm proposes the use of bundle adjustment to obtain all
    the camera parameters, jointly for a given set of matches between the images.
    For this, images are added to a bundle adjuster in decreasing order of the number
    of feature matches. Each time, the new image is initialized with the rotation
    and focal length of the image to which it matched. Then we use the Levenberg-Marquadt
    algorithm to update the camera parameters. The Levenberg-Marquadt algorithm is
    generally used to solve non-linear least squares problems in curve fitting problems.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 布朗和洛的算法提出了使用捆绑调整来获取所有相机参数，对于给定的一组图像匹配，是联合进行的。为此，图像按照特征匹配数量的降序添加到捆绑调整器中。每次，新图像都使用与其匹配的图像的旋转和焦距进行初始化。然后我们使用Levenberg-Marquadt算法来更新相机参数。Levenberg-Marquadt算法通常用于解决曲线拟合问题中的非线性最小二乘问题。
- en: 'This algorithm tries to minimize the sum of the squared projection errors.
    For this, each feature is projected on to every other image to which the original
    image matches, and then the sum of the squared distances is minimized with respect
    to the camera parameters. If the ![Bundle adjustment](img/B02052_06_47.jpg) feature
    in one image matches the ![Bundle adjustment](img/B02052_06_48.jpg) feature in
    another, we obtain the residual for the projection as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法试图最小化平方投影误差的总和。为此，每个特征都被投影到与原始图像匹配的每个其他图像上，然后相对于相机参数最小化平方距离的总和。如果一个图像的![捆绑调整](img/B02052_06_47.jpg)特征与另一个图像的![捆绑调整](img/B02052_06_48.jpg)特征匹配，我们得到以下投影残差：
- en: '![Bundle adjustment](img/B02052_06_49.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![捆绑调整](img/B02052_06_49.jpg)'
- en: Here, ![Bundle adjustment](img/B02052_06_50.jpg) represents the ![Bundle adjustment](img/B02052_06_51.jpg)
    feature in the ![Bundle adjustment](img/B02052_06_52.jpg) image, ![Bundle adjustment](img/B02052_06_53.jpg)
    is the residual after the projection of the ![Bundle adjustment](img/B02052_06_54.jpg)
    feature from ![Bundle adjustment](img/B02052_06_55.jpg) image on the ![Bundle
    adjustment](img/B02052_06_56.jpg) image, and ![Bundle adjustment](img/B02052_06_57.jpg)
    is the projection of ![Bundle adjustment](img/B02052_06_58.jpg) from the ![Bundle
    adjustment](img/B02052_06_59.jpg) image on the ![Bundle adjustment](img/B02052_06_60.jpg)
    image.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![捆绑调整](img/B02052_06_50.jpg)代表![捆绑调整](img/B02052_06_51.jpg)图像中的![捆绑调整](img/B02052_06_52.jpg)特征，![捆绑调整](img/B02052_06_53.jpg)是![捆绑调整](img/B02052_06_54.jpg)特征从![捆绑调整](img/B02052_06_55.jpg)图像投影到![捆绑调整](img/B02052_06_56.jpg)图像后的残差，而![捆绑调整](img/B02052_06_57.jpg)是![捆绑调整](img/B02052_06_58.jpg)从![捆绑调整](img/B02052_06_59.jpg)图像投影到![捆绑调整](img/B02052_06_60.jpg)图像上的投影。
- en: 'Then, the error function is calculated by summing up all the robustified residual
    field errors, over all the features, spanning all the images. For this robustification,
    the Huber robust error function is used:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过将所有特征的所有图像上的鲁棒化残差场误差相加来计算误差函数。为此鲁棒化，使用了Huber鲁棒误差函数：
- en: '![Bundle adjustment](img/B02052_06_61.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![捆绑调整](img/B02052_06_61.jpg)'
- en: On solving this, we get a non-linear equation, which is solved using the Levenberg-Marquadt
    algorithm, to estimate the values of the camera parameters.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题后，我们得到一个非线性方程，使用Levenberg-Marquardt算法求解，以估计相机参数的值。
- en: Automatic panoramic straightening
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动全景校正
- en: 'So far, the algorithm has been able to successfully find matches between images
    and able to stitch them together. However, there still exists an unknown 3D rotation
    component, which causes the panorama to be formed in a wave-like output, as shown
    in the following figure:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，该算法已经能够成功地在图像之间找到匹配，并将它们拼接在一起。然而，仍然存在一个未知的3D旋转分量，这导致全景图以波浪状输出，如下面的图所示：
- en: '![Automatic panoramic straightening](img/B02052_06_02.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![自动全景校正](img/B02052_06_02.jpg)'
- en: This arises mainly due to the fact that the camera would not have been perfectly
    level while clicking the multiple images.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这主要是因为在拍摄多张图像时，相机可能没有完全水平。
- en: This is solved by taking a heuristic into consideration regarding the way people
    click panoramic images. It is assumed that it is highly unlikely for a user to
    rotate the camera while clicking the image, so the camera vectors generally lie
    on the same plane. So, we try to find the null vector of the covariance matrix
    of the camera vectors and the vector normal to the plane of the center and horizon.
    This way, we can then apply the rotation on the images to effectively remove the
    wavy effect.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过考虑人们点击全景图像的方式的启发式方法来解决。假设用户在点击图像时旋转相机的可能性非常低，因此相机向量通常位于同一平面上。因此，我们尝试找到相机向量协方差矩阵的零向量和平面中心及地平线平面的法向量。这样，我们就可以对图像应用旋转，以有效地消除波浪效应。
- en: '![Automatic panoramic straightening](img/B02052_06_03.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![自动全景校正](img/B02052_06_03.jpg)'
- en: Gain compensation
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增益补偿
- en: 'Gain is the camera parameter that describes the sensitivity of the image to
    light. Different images could have been clicked at different levels of gain. To
    overcome this situation, we make use of gain compensation, as shown here:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 增益是描述图像对光敏感性的相机参数。不同的图像可能在不同的增益级别下被拍摄。为了克服这种情况，我们利用增益补偿，如下所示：
- en: '![Gain compensation](img/B02052_06_04.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![增益补偿](img/B02052_06_04.jpg)'
- en: 'Gain compensation refers to the normalization of the gain in images to facilitate
    a seamlessly stitched image. The method used is similar to the one used to compute
    the camera parameters. The error function used here is the sum of the errors in
    gain-normalized intensities for all the overlapping pixels:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 增益补偿是指对图像中的增益进行归一化，以方便无缝拼接图像。所使用的方法与计算相机参数的方法类似。这里使用的误差函数是所有重叠像素增益归一化强度的误差之和：
- en: '![Gain compensation](img/B02052_06_05.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![增益补偿](img/B02052_06_05.jpg)'
- en: Multi-band blending
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多波段混合
- en: Even after gain compensation, the stitching doesn't appear to be seamless. We
    need to apply a good blending algorithm to join the images without it being noticeable
    that the image has been stitched from multiple images.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在增益补偿之后，拼接似乎仍然不够无缝。我们需要应用一个好的混合算法来拼接图像，使其不明显地看出图像是由多张图像拼接而成的。
- en: For this, we apply a good blending strategy. We choose a blending algorithm
    in which we assign a weight function to each image. This weight function varies
    linearly with weight = 1 at the center and weight = 0 at the edges. This weight
    function is also extended to a spherical coordinate system. A simple weighted
    sum of the intensities along each ray can be calculated using these weight functions,
    but this would cause high frequency areas to be blurred out.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们采用了一种良好的混合策略。我们选择了一种混合算法，其中为每个图像分配一个权重函数。这个权重函数与权重成正比，权重中心为1，边缘为0。这个权重函数也被扩展到球坐标系。可以使用这些权重函数计算沿每条射线的强度加权总和，但这会导致高频区域被模糊掉。
- en: Due to this, we need to implement multi-band blending. The multi-band blending
    blends low frequency regions over a large area, where it blends high frequency
    regions over a relatively smaller area. We assign weights to each image, using
    ![Multi-band blending](img/B02052_06_62.jpg), such that the value of ![Multi-band
    blending](img/B02052_06_63.jpg) is 1 where there is maximum weight in the image
    and 0 where the maximum weight for the region is from some other image. We then
    successively blur out these weight graphs to ultimately get the blending weights
    for each band.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个原因，我们需要实现多波段混合。多波段混合在大区域内混合低频区域，在相对较小的区域内混合高频区域。我们使用![多波段混合](img/B02052_06_62.jpg)为每个图像分配权重，使得![多波段混合](img/B02052_06_63.jpg)的值在图像中权重最大时为1，在区域的权重最大值来自其他图像时为0。然后我们依次模糊掉这些权重图，最终得到每个波段的混合权重。
- en: 'Then we linearly combine the overlapping images for each band with respect
    to the blend weights. The amount of blurring depends on the frequency of the band.
    This results in the high frequency bands being blended over short regions, while
    the low frequency bands get blended over large regions:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们根据混合权重线性组合每个波段的重叠图像。模糊程度取决于波段的频率。这导致高频波段在短区域内混合，而低频波段在大区域内混合：
- en: '![Multi-band blending](img/B02052_06_06.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![多波段混合](img/B02052_06_06.jpg)'
- en: Image stitching using OpenCV
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用OpenCV进行图像拼接
- en: 'The following is the image stitching pipeline:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将图像拼接的流程：
- en: '![Image stitching using OpenCV](img/B02052_06_07.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![使用OpenCV进行图像拼接](img/B02052_06_07.jpg)'
- en: We will now see how to implement image stitching.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将看到如何实现图像拼接。
- en: First, we will set up our project in the same way as we did for all the previous
    chapters. We will use the package name `com.packtpub.masteringopencvandroid.chapter6`
    for this project. First, we will edit our manifest file.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将以与之前所有章节相同的方式设置我们的项目。对于这个项目，我们将使用包名`com.packtpub.masteringopencvandroid.chapter6`。首先，我们将编辑我们的清单文件。
- en: 'We will add all the required permissions to this project. We require the permissions
    to access the camera, and also to read and write to the external storage. So,
    add the following code to your manifest:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将向此项目添加所有必需的权限。我们需要访问摄像头的权限，以及读取和写入外部存储的权限。因此，将以下代码添加到您的清单文件中：
- en: '[PRE0]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then we will declare our activities. We only require one activity for this project.
    We will call it the `StitchingActivity`.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将声明我们的活动。对于这个项目，我们只需要一个活动。我们将称之为`StitchingActivity`。
- en: Setting up Android NDK
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置Android NDK
- en: 'We require NDK for this project as the stitching module is unavailable in OpenCV''s
    Java SDK. So, we will write the C++ code and compile it using Android NDK in order
    for it to be used as a part of our project. To do this, first download NDK from
    [http://developer.android.com/tools/sdk/ndk](http://developer.android.com/tools/sdk/ndk)
    and extract it to a location on your computer. Then go to your `local.properties`
    file and add the following line:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 由于拼接模块在OpenCV的Java SDK中不可用，因此我们需要NDK来完成这个项目。所以，我们将编写C++代码，并使用Android NDK进行编译，以便将其作为我们项目的一部分使用。为此，首先从[http://developer.android.com/tools/sdk/ndk](http://developer.android.com/tools/sdk/ndk)下载NDK，并将其解压缩到您的计算机上的某个位置。然后转到您的`local.properties`文件，并添加以下行：
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, go to your `build.gradle` file that is located in the main module of
    your project. In this file, inside the `defaultConfig` tag, add the following
    code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，转到您的项目主模块中的`build.gradle`文件。在这个文件中，在`defaultConfig`标签内，添加以下代码：
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This is the name of the module, which will contain our functions, where our
    computations will be performed. Now, under the `android` tag, after `defaultConfig`
    ends, add the following lines:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这是模块的名称，其中将包含我们的函数，我们的计算将在其中执行。现在，在`android`标签下，在`defaultConfig`结束之后，添加以下行：
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This defines where our compiled libraries will be located. After this, we need
    to set up the NDK part of our project. In the `src` folder, add a folder called
    `jni`. In this folder, we need to create two files. The first one is `Android.mk`.
    This contains information about the files in the project. Copy the following lines
    to this file. Remember to replace `OpenCV4AndroidSDK` with the location on your
    computer:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这定义了我们的编译库将被放置的位置。之后，我们需要设置我们项目的NDK部分。在`src`文件夹中，添加一个名为`jni`的文件夹。在这个文件夹中，我们需要创建两个文件。第一个是`Android.mk`。这个文件包含有关项目中文件的信息。将以下行复制到该文件中。请记住用你电脑上的位置替换`OpenCV4AndroidSDK`：
- en: '[PRE4]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, create another file named `Application.mk`. This defines the architectures
    for which the code has to be compiled. Copy the following lines to this file:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建另一个名为`Application.mk`的文件。这个文件定义了代码需要编译的架构。将以下行复制到该文件中：
- en: '[PRE5]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now we are all set to use NDK code in our project.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好在我们的项目中使用NDK代码了。
- en: The layout and Java code
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 布局和Java代码
- en: 'Next we will draw our layout. For this project, we only need one layout with
    one `ImageView` tag to display the stitched image and two `Buttons`. One of the
    buttons is used to click more images and one is used to signify that there are
    no more images to be clicked. We will also put all the items in a `ScrollView`
    tag to be able to see the full image if its size exceeds the screen size. Our
    `activity_stitching.xml` file is as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将绘制我们的布局。对于这个项目，我们只需要一个包含一个`ImageView`标签的布局来显示拼接的图像和两个`Button`。其中一个按钮用于点击更多图像，另一个用于表示没有更多图像可以点击。我们还将所有项目放入一个`ScrollView`标签中，以便能够看到超过屏幕大小的完整图像。我们的`activity_stitching.xml`文件如下：
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now we have to write our Java code. In the `StitchingActivity.java` file, in
    your OpenCV `BaseLoaderCallback` object, edit the `onManagerConnected` function
    by adding the following line in `case LoaderCallbackInterface.SUCCESS`:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须编写我们的Java代码。在`StitchingActivity.java`文件中，在你的OpenCV `BaseLoaderCallback`对象中，通过在`case
    LoaderCallbackInterface.SUCCESS`中添加以下行来编辑`onManagerConnected`函数：
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Notice that this is the same name that we gave our module in our `Android.mk`
    file. In our Java code, we will first declare and initialize all the variables
    that we will need. We have a button called `bClickImage`, which, on clicking,
    calls Android''s camera intent and requests the system''s camera app to click
    a picture and sends it to the app. We will convert this `Bitmap` image into an
    OpenCV `Mat` and store it in an `ArrayList`. We will stitch all the images together
    in the end, when the user clicks on the `bDone` button. The `onClickListener`
    for both the buttons is as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这与我们在`Android.mk`文件中给我们的模块起的名字相同。在我们的Java代码中，我们首先声明并初始化我们将需要的所有变量。我们有一个名为`bClickImage`的按钮，点击它将调用Android的相机意图并请求系统的相机应用拍照并发送给应用。我们将把这个`Bitmap`图像转换成OpenCV的`Mat`并存储在一个`ArrayList`中。当用户点击`bDone`按钮时，我们将最终拼接所有图像。两个按钮的`onClickListener`如下：
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `onActivityResult` function is called when the camera intent returns from
    the camera app. We need to check whether an image has been clicked and add it
    to the `ArrayList`, if required. We will use OpenCV''s `BitmapToMat` function
    to convert the image from an Android Bitmap to an OpenCV Mat. The code is as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当相机意图从相机应用返回时，将调用`onActivityResult`函数。我们需要检查是否已经点击了图像，并在必要时将其添加到`ArrayList`中。我们将使用OpenCV的`BitmapToMat`函数将图像从Android
    Bitmap转换为OpenCV Mat。代码如下：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In `onClickListener` for `bDone`, we called a `createPanorama` function. In
    this function, we will execute an `AsyncTask`, as this is a computationally intensive
    task. In `AsyncTask`, we will call upon our NDK to perform the actual computation.
    This is what our `doInBackground` looks like:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在`bDone`的`onClickListener`中，我们调用了`createPanorama`函数。在这个函数中，我们将执行一个`AsyncTask`，因为这个任务计算量很大。在`AsyncTask`中，我们将调用我们的NDK来执行实际计算。这就是我们的`doInBackground`看起来像：
- en: '[PRE10]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We also need to declare the `StitchPanorama` function as a native function
    so that Android knows where to look for it when executing:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要将`StitchPanorama`函数声明为原生函数，这样Android在执行时就知道在哪里查找它：
- en: '[PRE11]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: After this, in `onPostExecute`, we just need to set the returned `Bitmap` as
    the source for `ImageView`. This completes our Java code for this project, and
    all the major stitching is done using the C++ code.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，在`onPostExecute`中，我们只需将返回的`Bitmap`设置为`ImageView`的源。这完成了我们这个项目的Java代码，所有主要的拼接都是使用C++代码完成的。
- en: The C++ code
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C++代码
- en: 'In your `jni` folder, create the `stitcher.cpp` file. Notice that this is the
    same name as set in the `Android.mk` file. First, we need to include some libraries
    that we will require. We will also declare some namespaces that we will be using
    and some global variables as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的`jni`文件夹中，创建`stitcher.cpp`文件。请注意，这个名字与`Android.mk`文件中设置的名字相同。首先，我们需要包含我们将需要的库。我们还将声明我们将使用的一些命名空间和一些全局变量，如下所示：
- en: '[PRE12]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then we need to declare our function and write our code in it. To declare the
    function, write the following code:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要声明我们的函数并在其中编写代码。要声明函数，请编写以下代码：
- en: '[PRE13]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The ellipses are placeholders for where our code will go. Notice the variables
    and their orders compared to the variables declared in our Java code. First, we
    will initialize some variables and also convert the Mat object that we sent from
    Java to a C++ Mat:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 省略号是代码将放置的位置的占位符。注意变量及其顺序与Java代码中声明的变量相比。首先，我们将初始化一些变量，并将从Java发送的Mat对象转换为C++
    Mat：
- en: '[PRE14]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here, we have used the address of the Mat object and type-casted it to a C++
    Mat pointer. Next we need to convert the Mat array sent from Java to a C++ vector.
    We will use the following code:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了Mat对象的地址并将其转换为C++ Mat指针。接下来，我们需要将Java发送的Mat数组转换为C++ vector。我们将使用以下代码：
- en: '[PRE15]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We need to manually delete the local objects as the C++ code doesn't automatically
    call the garbage collector, and being on mobile, it is highly important to optimize
    the memory use.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于C++代码不会自动调用垃圾回收器，并且作为移动设备，优化内存使用非常重要，因此我们需要手动删除本地对象。
- en: 'Now we will use OpenCV''s stitcher module to stitch our images:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用OpenCV的拼接模块来拼接我们的图像：
- en: '[PRE16]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We have used the default setup for stitching the images; however, the stitcher
    module allows the modification of the pipeline by giving more control to the developer.
    Check out the available options at [http://docs.opencv.org/modules/stitching/doc/introduction.html](http://docs.opencv.org/modules/stitching/doc/introduction.html).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了默认的图像拼接设置；然而，拼接模块允许通过给予开发者更多控制来修改管道。查看可用的选项，请参阅[http://docs.opencv.org/modules/stitching/doc/introduction.html](http://docs.opencv.org/modules/stitching/doc/introduction.html)。
- en: 'Now we just need to build our C++ code file to generate the object files that
    our Java code will use to make function calls to C++ functions. For this, you
    will need to open the terminal/command prompt, and then use the `cd` command to
    change the active directory to `<project_dir>/app/src/main/jni`. Now we need to
    build our files. For this, you need to use the following command:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只需要构建我们的C++代码文件，生成Java代码将用于调用C++函数的对象文件。为此，您需要打开终端/命令提示符，然后使用`cd`命令将活动目录更改为`<project_dir>/app/src/main/jni`。现在我们需要构建我们的文件。为此，您需要使用以下命令：
- en: '[PRE17]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This will generate our object files and place them in the `obj` and `libs` folders.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成我们的对象文件并将它们放置在`obj`和`libs`文件夹中。
- en: This completes our project on image stitching using OpenCV on Android. You can
    see the stitched results in the following images.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了我们在Android上使用OpenCV进行图像拼接的项目。您可以在以下图像中看到拼接的结果。
- en: 'The following is the first sample image:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一张示例图像：
- en: '![The C++ code](img/B02052_06_08.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![C++代码](img/B02052_06_08.jpg)'
- en: 'The following is the second sample image:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一张第二张示例图像：
- en: '![The C++ code](img/B02052_06_09.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![C++代码](img/B02052_06_09.jpg)'
- en: 'The following is the result of applying image stitching over these two sample
    images:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将图像拼接应用于这两张示例图像的结果：
- en: '![The C++ code](img/B02052_06_10.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![C++代码](img/B02052_06_10.jpg)'
- en: There are chances that your code might crash due to the high memory requirements
    of the stitcher module. This is a limitation of the mobile ecosystem and can be
    overcome by including a server in the middle to perform the computations instead.
    You can modify the source of the app to send the images to the server, which in
    turn performs the stitching and returns the stitched result, which can be displayed
    in the app.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 由于拼接模块的高内存需求，您的代码可能会崩溃。这是移动生态系统的限制，可以通过在中间包含一个服务器来执行计算来克服。您可以修改应用程序的源代码，将图像发送到服务器，服务器随后执行拼接并返回拼接结果，该结果可以在应用程序中显示。
- en: Summary
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we saw how panoramic images are stitched. We took a look at
    image alignment by finding homography, using RANSAC, and image stitching as a
    whole. We also saw how it can be implemented in Android using OpenCV. These image
    alignment techniques can also be used for video stabilization. In the next chapter,
    we will take a look at how we can make use of machine learning algorithms to automate
    some of the complex tasks that generally require a human to be present.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了全景图像是如何拼接的。我们通过寻找单应性、使用RANSAC以及整体图像拼接来观察图像对齐。我们还看到了如何使用OpenCV在Android中实现它。这些图像对齐技术也可以用于视频稳定化。在下一章中，我们将探讨如何利用机器学习算法来自动化一些通常需要人类在场才能完成的复杂任务。
