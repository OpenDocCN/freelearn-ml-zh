- en: Introduction to Machine Learning
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习介绍
- en: Machine learning is everywhere. When you book a flight ticket, an algorithm
    decides the price you are going to pay for it. When you apply for a loan, machine
    learning may decide whether you are going to get it or not. When you scroll through
    your Facebook timeline, it picks which advertisements to show to you. Machine
    learning also plays a big role in your Google search results. It organizes your
    email's inbox and filters out spam, it goes through your resumé before recruiters
    when you apply for a job, and, more recently, it has also started to play the
    role of your personal assistant in the form of Siri and other virtual assistants.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习无处不在。当您预订航班机票时，算法决定您将支付的价格。当您申请贷款时，机器学习可能决定您是否能获得贷款。当您滚动查看Facebook的时间线时，它会选择向您展示哪些广告。机器学习还在您的Google搜索结果中起着重要作用。它整理您的电子邮件收件箱并过滤垃圾邮件，在您申请工作时，招聘人员查看您的简历之前，它也会进行审阅，而且最近它还开始在Siri等虚拟助手形式中扮演您的个人助理的角色。
- en: In this book, we will learn about the theory and practice of machine learning.
    We will understand when and how to apply it. To get started, we will look at a
    high-level introduction to how machine learning works. You will then be able to
    differentiate between the different machine learning paradigms and know when to
    use each of them. Then, you'll be taken through the model development life cycle
    and the different steps practitioners take to solve problems. Finally, we will
    introduce you to scikit-learn, and learn why it is the *de facto* tool for many
    practitioners.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将学习机器学习的理论和实践。我们将了解何时以及如何应用它。首先，我们将高层次介绍机器学习的工作原理。然后，您将能够区分不同的机器学习范式，并知道何时使用每种范式。接下来，您将了解模型开发生命周期以及从业者解决问题所采取的不同步骤。最后，我们将向您介绍scikit-learn，并了解为什么它是许多从业者的*事实标准*工具。
- en: 'Here is a list of the topics that will be covered in this first chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本书第一章将涵盖的主题列表：
- en: Understanding machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解机器学习
- en: The model development life cycle
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型开发生命周期
- en: Introduction to scikit-learn
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn简介
- en: Installing the packages you need
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装您需要的软件包
- en: Understanding machine learning
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解机器学习
- en: You may be wondering how machines actually learn. To get the answer to this
    query, let's take the following example of a fictional company. **Space Shuttle
    Corporation** has a few space vehicles to rent. They get applications every day
    from clients who want to travel to Mars. They are not sure whether those clients
    will ever return the vehicles—maybe they'll decide to continue living on Mars
    and never come back again. Even worse, some of the clients may be lousy pilots
    and crash their vehicles on the way. So, the company decides to hire shuttle rent-approval
    officers whose job is to go through the applications and decide who is worthy
    of a shuttle ride. Their business, however, grows so big that they need to formulate
    the shuttle-approval process.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能想知道机器是如何学习的。为了回答这个问题，让我们来看一个虚构公司的例子。**太空穿梭公司**有几辆太空车可供租赁。他们每天收到来自想要去火星旅行的客户的申请。他们不确定这些客户是否会归还车辆
    —— 也许他们会决定继续在火星上生活，永远不会回来。更糟糕的是，一些客户可能是糟糕的飞行员，在途中会坠毁他们的车辆。因此，公司决定聘请穿梭机租赁审批官员，他们的工作是审核申请并决定谁值得搭乘穿梭机。然而，随着业务的扩展，他们需要制定穿梭机审批流程。
- en: A traditional shuttle company would start by having business rules and hiring
    junior employees to execute those rules. For example, if you are an alien, then
    sorry, you cannot rent a shuttle from us. If you are a human and you have kids
    that are in school on Earth, then you are more than welcome to rent one of our
    shuttles. As you can see, those rules are too broad. What about aliens who love
    living on Earth and just want to go to Mars for a quick holiday? To come up with
    a better business policy, the company starts hiring analysts. Their job is to
    go through historical data and try to come up with detailed rules or business
    logic. These analysts can come up with very detailed rules. If you are an alien,
    one of your parents is from Neptune, your age is between 0.1 and 0.2 Neptunian
    years, and you have 3 to 4 kids and one of them is 80% or more human, then you
    are allowed to rent a shuttle. To be able to come up with suitable rules, the
    analysts also need a way to measure how good this business logic is. For example,
    what percentage of the shuttles return if certain rules are applied? They use
    historic data to evaluate these measures, and only then can wesay that these rules
    are actually learned from data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一家传统的班车公司会先制定业务规则，并雇佣初级员工执行这些规则。例如，如果你是外星人，那么抱歉，你不能从我们这里租借班车。如果你是人类，并且有孩子在地球上上学，那么你完全可以租借我们的班车。如你所见，这些规则过于宽泛。那么，喜欢住在地球并且只想去火星度假一小会儿的外星人呢？为了制定更好的业务政策，公司开始雇佣分析师。他们的工作是浏览历史数据，尝试制定详细的规则或业务逻辑。这些分析师能制定非常详细的规则。如果你是外星人，其中一位父母来自海王星，年龄在0.1到0.2海王星年之间，并且你有三到四个孩子，其中一个孩子的DNA至少80%是人类，那么你可以租借班车。为了能够制定合适的规则，分析师还需要一种方法来衡量这些业务逻辑的优劣。例如，如果应用某些规则，班车的回收率是多少？他们使用历史数据来评估这些指标，只有这样，我们才能说这些规则确实是从数据中学习出来的。
- en: Machine learning works in almost the same way. You want to use historic data
    to come up with some business logic (an algorithm) in order to optimize some measure
    of how good the logic is (an objective or loss function). Throughout this book,
    we will learn about numerous machine learning algorithms; they differ from each
    other in how they represent business logic, what objective functions they use,
    and what optimization techniques they utilize to reach a model that maximizes
    (or sometimes minimizes) the objective function. Like the analysts in the previous
    example, you should pick an objective function that is as close as possible to
    your business objective. Any time you hear people saying data scientists should
    have a good understanding of their business, a significant part of that is their
    choice of a good objective function and ways to evaluate the models they build.
    In my example, I quickly picked the percentage of shuttles returned as my objective.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习几乎以相同的方式工作。你想要利用历史数据来制定一些业务逻辑（一个算法），以优化某种衡量逻辑好坏的指标（目标函数或损失函数）。在本书中，我们将学习许多机器学习算法；它们在表示业务逻辑的方式、使用的目标函数以及利用的优化技术上各不相同，目标是达到一个最大化（或有时最小化）目标函数的模型。就像前面示例中的分析师一样，你应该选择一个尽可能接近你的业务目标的目标函数。每当你听到有人说数据科学家应该对他们的业务有很好的理解时，重要的一部分就是他们选择一个好的目标函数以及评估他们所建立模型的方法。在我的例子中，我迅速选择了“退还的班车百分比”作为我的目标。
- en: But if you think about it, is this really an accurate one-to-one mapping of
    the shuttle company's revenue? Is the revenue made by allowing a trip equal to
    the cost of losing a shuttle? Furthermore, rejecting a trip may also cost your
    company angry calls to the customer care center and negative word-of-mouth advertising.
    You have to understand all of this well enough before picking your objective function.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果你仔细想想，这真的是班车公司收入的准确一对一映射吗？通过允许一次旅行获得的收入是否等于失去一辆班车的成本？此外，拒绝一次旅行可能还会让公司接到愤怒的客户服务电话，并导致负面口碑传播。在选择目标函数之前，你必须对这些情况有足够的了解。
- en: Finally, a key benefit to using machine learning is that it can iterate over
    a vast amount of business logic cases until it reaches the optimum objective function,
    unlike the case of the analysts in our space shuttle company who can only go so
    far with their rules. The machine learning approach is also automated in the sense
    that it keeps updating the business logic whenever new data arrives. These two
    aspects make it scalable, more accurate, and adaptable to change.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用机器学习的一个关键好处是，它能够在大量的业务逻辑案例中进行迭代，直到达到最佳目标函数，而不像我们太空飞行器公司中的分析师那样，受限于规则的局限，无法深入。机器学习方法也是自动化的，意味着它在每次新数据到来时都会更新业务逻辑。这两个方面使得它具有可扩展性、更加精准，并且能够适应变化。
- en: Types of machine learning algorithms
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习算法的类型
- en: '"Society is changing, one learning algorithm at a time."'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: “社会在变化，每次都通过一个学习算法。”
- en: – Pedro Domingos
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: – Pedro Domingos
- en: 'In this book, we are going to cover the two main paradigms of machine learning—supervised
    learning and unsupervised learning. Each of these two paradigms has its own sub-branches
    that will be discussed in the next section. Although it is not covered in this
    book, reinforcement learning will also be introduced in the next section:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将介绍机器学习的两大主流范式——监督学习和无监督学习。这两种范式各自有一些子分支，我们将在下一节讨论。虽然本书中不涉及，但强化学习也将在下一节简单介绍：
- en: '![](img/1ca6ecc7-0e48-4729-9e46-188cf3242dfe.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1ca6ecc7-0e48-4729-9e46-188cf3242dfe.png)'
- en: Let's use our fictional Space Shuttle Corporation company once more to explain
    the differences between the different machine learning paradigms.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次使用我们的虚构太空飞行器公司来解释不同机器学习范式之间的差异。
- en: Supervised learning
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督学习
- en: Remember those old good days at school when you were given examples to practice
    on, along with the correct answers to them at the end to validate whether you
    are doing a good job? Then, at exam time, you were left on your own. That's basically
    what supervised learning is. Say our fictional space vehicle company wants to
    predict whether travelers will return their space vehicles. Luckily, the company
    has worked with many travelers in the past, and they already know which of them
    returned their vehicles and who did not. Think of this data as a spreadsheet,
    where each column has some information about the travelers—their financial statements,
    the number of kids they have, whether they are humans or aliens, and maybe their
    age (in Neptunian years, of course). Machine learners call these columns **features**.
    There is one extra column for previous travelers that states whether they returned
    or not; we call this column the **label** or **target** column. In the learning
    phase, we build a model using the features and targets. The aim of the algorithm
    while learning is to minimize the differences between its predictions and the
    actual targets. The difference is what we call the error. Once a model is constructed
    so that its error is minimal, we then use it to make predictions for newer data
    points. For new travelers, we only know their features, but we use the model we've
    just built to predict their corresponding targets. In a nutshell, the presence
    of the target in our historic data is what makes this process supervised.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得学校里那些美好的时光吗？老师给你提供了练习题，并在最后给出正确答案来验证你是否做得好？然后，在考试时，你就得独立完成。这基本上就是监督学习的原理。假设我们的虚构太空飞行器公司想要预测旅行者是否会归还他们的太空飞行器。幸运的是，公司以前与许多旅行者合作过，他们已经知道哪些旅行者归还了飞行器，哪些没有。可以把这些数据想象成一个电子表格，其中每一列都包含一些关于旅行者的信息——他们的财务状况、孩子的数量、是否是人类或外星人，甚至可能包括他们的年龄（当然是以海王星年为单位）。机器学习专家称这些列为**特征**。除此之外，还有一列用于记录旅行者是否归还了飞行器的历史数据，我们称这列为**标签**或**目标**列。在学习阶段，我们使用特征和目标来构建一个模型。算法在学习的目标是最小化其预测值与实际目标之间的差异，这种差异被称为误差。一旦模型构建完成并且误差最小化，我们就可以用它来对新的数据点进行预测。对于新旅行者，我们只知道他们的特征，但我们会使用刚构建的模型来预测他们对应的目标。简而言之，目标数据在我们历史数据中的存在，使得这个过程是监督学习。
- en: Classification versus regression
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分类与回归
- en: Supervised learning is furthersubdivided into classification and regression.
    For cases where we only have a few predefined labels to predict, we use a classifier—for
    example, *return*versus*no return* or*human* versus*Martian* versus*Venusian*.
    If what we want to predict is a wide-range number—say, how many years a traveler
    will take to come back—then it is a regression problem since these values can
    be anything from 1 or 2 years to 3 years, 5 months, and 7 days.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有监督学习进一步细分为分类和回归。在只有少数预定义标签需要预测的情况下，我们使用分类器——例如，*回报*与*不回报*，或者*人类*与*火星人*与*金星人*。如果我们要预测的是一个广泛范围的数值——比如说，一个旅行者返回需要多少年——那么这就是一个回归问题，因为这些数值可以是从1年或2年到3年、5个月、7天等任意值。
- en: Supervised learning evaluation
  id: totrans-24
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 有监督学习评估
- en: 'Due to their differences, the metrics we use to evaluate these classifiers
    are usually different from ones we use with regression:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们的差异，我们用来评估这些分类器的度量通常与我们在回归中使用的度量不同：
- en: '**Classifier evaluation metrics**: Suppose we are using a classifier to determine
    whether a traveler is going to return. Then, of those travelers that the classifier
    predicted to return, we want to measure what percentage of them actually did return.
    We call this measure **precision**. Also, of all travelers who did return, we
    want to measure what percentage of them the classifier correctly predicted to
    return. We call this **recall**. Precision and recall can be calculated for each
    class—that is, we can also calculate precision and recall for the travelers who
    did not return.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类器评估度量**：假设我们使用分类器来判断一个旅行者是否会返回。那么，对于那些分类器预测会返回的旅行者，我们希望衡量其中有多少实际返回。我们称这个度量为**精度**。另外，对于所有实际返回的旅行者，我们希望衡量其中有多少被分类器正确预测为返回。我们称这个度量为**召回率**。精度和召回率可以针对每个类别进行计算——也就是说，我们还可以计算未返回旅行者的精度和召回率。'
- en: '**Accuracy** is another commonly used, and sometimes abused, measure. For each
    case in our historic data, we know whether a traveler actually returned (**actuals**)
    and we can also generate **predictions** of whether they will return. The accuracy
    calculates what percentage of cases of the predictions and actuals match. As you
    can see, it is labeled **agnostic**, so it can sometimesbe misleading when the
    classes are highly imbalanced. In our example business, say 99% of our travelers
    actually return. We can build a dummy classifier that predicts whether every single
    traveler returns; it will be accurate 99% of the time. This 99% accuracy value
    doesn''t tell us much, especially if you know that in these cases, the recall
    value for non-returning travelers is 0%. As we are going to see later on in this
    book, each measure has its pros and cons, and a measure is only as good as how
    close it is to our business objectives. We are also going to learn about other
    metrics, such as **F[1] score**, **AUC**, and **log loss**.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**准确率**是另一个常用的、有时被滥用的度量标准。对于我们历史数据中的每一个案例，我们都知道旅行者是否实际返回（**实际值**），并且我们还可以生成**预测**他们是否会返回的结果。准确率计算预测与实际值匹配的百分比。正如你所看到的，它被称为**不考虑类别**，因此当类别高度不平衡时，它有时可能会产生误导。在我们的业务示例中，假设99%的旅行者实际返回。我们可以构建一个虚拟分类器，预测每个旅行者都会返回；它99%的时间是准确的。然而，这个99%的准确率并不能告诉我们太多，特别是当你知道在这些案例中，未返回旅行者的召回率是0%时。正如我们将在本书后面看到的，每个度量标准都有其优缺点，且一个度量标准的好坏取决于它与我们的业务目标的接近程度。我们还将学习其他度量标准，例如**F[1]
    分数**、**AUC**和**对数损失**。'
- en: '**Regressor evaluation metrics**: If we are using a regressor to tell how long
    a traveler will stay, then we need to determine how far the numbers that the regression
    evaluation is predicting are from reality. Let''s say for three users, the regressor
    expected them to stay for 6, 9, and 20 years, respectively, while they actually
    stayed for 5, 10, and 26 years, respectively. One solution is to calculate the
    average of the differences between the prediction and the reality—the average
    of 6–5, 9–10, and 20–25, so the average of 1, -1, and -6 is -2\. One problem with
    these calculations is that 1 and -1 cancel each other out. If you think about
    it, both 1 and -1 are mistakes that the model made, and the sign might not matter
    much here.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归模型评估度量**：如果我们使用回归模型来预测旅行者将停留多久，那么我们需要确定回归模型预测的数字与现实之间的差距。假设对于三个用户，回归模型预期他们分别停留6年、9年和20年，而他们实际分别停留了5年、10年和26年。一个解决方案是计算预测与现实之间差异的平均值——即6-5、9-10和20-25的平均值，所以1、-1和-6的平均值为-2。这个计算的一个问题是1和-1相互抵消。如果你仔细想想，1和-1都是模型所犯的错误，符号在这里可能并不重要。'
- en: So, we will need to use **Mean Absolute Error**(**MAE**) instead. This calculates
    the average of the absolute values of the differences—so, the average of 1, 1,
    and 6 is 2.67\. This makes more sense now, but what if we can tolerate a 1-year
    difference more than a 6-year difference? We can then use**Mean Squared Error**(**MSE**)
    to calculate the average of the differences squared—so, the average of 1, 1, and
    36 is 12.67\. Clearly, each measure has its pros and cons here as well. Additionally,
    we can also use different variations of these metrics, such as median absolute
    error or max error. Furthermore, sometimes your business objective can dictate
    other measures. Say we want to penalize the model if it predicts that a traveler
    will arrive 1 year later twice as often as when it predicts them to arrive 1 year
    earlier—what metric can you come up with then?
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们需要使用**平均绝对误差**（**MAE**）来代替。这计算的是差异的绝对值的平均数——例如，1、1 和 6 的平均值是 2.67。现在这更有意义了，但如果我们能容忍
    1 年的差异，而不是 6 年的差异呢？那么，我们可以使用**均方误差**（**MSE**）来计算差异平方的平均数——例如，1、1 和 36 的平均值是 12.67。显然，每个度量方法也有其优缺点。此外，我们还可以使用这些指标的不同变体，如中位数绝对误差或最大误差。此外，有时你的业务目标可能决定了其他的度量标准。比如，我们希望在模型预测一个旅行者会比预测他早
    1 年到达时，预测他晚 1 年到达的频率是前者的两倍——那么，你能想到什么度量标准来衡量这个呢？
- en: In practice, the lines between classification and regression problems can get
    blurred sometimes. For the case of how many years a traveler will take to return,
    you can still decide to bucket the range into 1–5 years, 5–10 years, and 10+ years.
    Then, you end up with a classification problem to solve instead. Conversely, classifiers
    return probabilities along with their predicted targets. For the case of whether
    a user will return, a predicted value of 60% and 95% means the same thing from
    a binary classifier's point of view, but the classifier is more confident that
    the traveler will return in the second case compared to the first case. Although
    this is still a classification problem, we can use the **Brier score** to evaluate
    our classifier here, which is actually **MSE** in disguise. More on the Brier
    score will be covered in [Chapter 9](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=31&action=edit),
    *The Y is as important as the X*. Most of the time, it is clear whether you are
    facing a classification or regression problem, but always keep your eyes open
    to the possibility of reformulating your problem if needed.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，分类问题和回归问题的界限有时会变得模糊。以旅行者返回的年数为例，你仍然可以选择将范围分成 1-5 年、5-10 年和 10 年以上。然后，你就变成了一个分类问题需要解决。相反，分类器会返回概率和它们预测的目标。在一个用户是否会返回的问题中，从二分类器的角度来看，预测值
    60% 和 95% 是一样的，但分类器对于第二种情况比第一种情况更有信心。虽然这依然是一个分类问题，但我们可以使用**Brier 分数**来评估我们的分类器，这实际上是**MSE**的伪装。关于
    Brier 分数的更多内容将在[第 9 章](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=31&action=edit)中讲解，*Y
    和 X 一样重要*。大多数时候，是否是分类问题或回归问题是明确的，但始终保持警觉，如果需要的话，随时可以重新定义你的问题。
- en: Unsupervised learning
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Life doesn't always provide us with correct answers as was the case when we
    were in school. We have been told that space travelers like it when they are traveling
    with like-minded passengers. We already know a lot about our travelers, but of
    course, no traveler will say *by the way, I am a type A, B, or C traveler*. So,
    to group our clients, we use a form of unsupervised learning called **clustering**.
    Clustering algorithms try to come up with groups and put our travelers into them
    without us telling them what groups may exist. Unsupervised learning lacks targets,
    but this doesn't mean that we cannot evaluate our clustering algorithms. We want
    the members of a cluster to be similar to each other, but we also want them to
    be dissimilar from the members of adjacent clusters. The **silhouette coefficient**
    basically measures that. We will come across other measures for clustering, such
    as the **Davies-Bouldin****index** and the **Calinski-Harabasz****index**, later
    in this book
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 生活并不总是像我们在学校时那样提供正确答案。我们曾被告知，太空旅行者喜欢和志同道合的乘客一起旅行。我们已经了解了很多关于旅行者的信息，但当然没有旅行者会说*顺便提一下，我是A型、B型或C型旅行者*。因此，为了对客户进行分组，我们使用了一种叫做**聚类**的无监督学习方法。聚类算法试图形成组，并将我们的旅行者分配到这些组中，而我们并未告诉它们可能存在哪些组。无监督学习没有明确的目标，但这并不意味着我们无法评估我们的聚类算法。我们希望同一聚类的成员相似，但也希望它们与相邻聚类的成员有所不同。**轮廓系数**基本上衡量的就是这一点。在本书后面，我们还会遇到其他用于聚类的评估指标，如**Davies-Bouldin指数**和**Calinski-Harabasz指数**。
- en: Reinforcement learning
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 强化学习
- en: Reinforcement learning is beyond the scope of this book and is not implemented
    in `scikit-learn`. Nevertheless, I will briefly talk about it here. In the supervised
    learning examples we have looked at, we treated each traveler separately. If we
    want to know which travelers are going to return their space vehicles the earliest,
    our aim then is to pick the best travelers for our business. But if you think
    about it, the behavior of one traveler affects the experience of the others as
    well. We only allow space vehicles to stay up to 20 years in space. However, we
    haven't explored the effect of allowing some travelers to stay longer or the effect
    of having a stricter rent period for other travelers. Reinforcement learning is
    the answer to that, where the key to it is exploration and exploitation.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习超出了本书的范围，并且在`scikit-learn`中并未实现。不过，我会在这里简要介绍一下它。在我们看过的监督学习示例中，我们将每个旅行者视为独立个体。如果我们想知道哪些旅行者最早归还他们的航天器，那么我们的目标就是挑选出最适合的旅行者。但如果仔细想想，一个旅行者的行为也会影响其他旅行者的体验。我们只允许航天器在太空中停留最长20年。然而，我们并未探索允许某些旅行者停留更久，或者对其他旅行者实施更严格租期的影响。强化学习就是解决这一问题的答案，其关键在于探索与利用。
- en: Rather than dealing with each action separately, we may want to explore sub-optimal
    actions in order to reach an overall optimumset of actions. Reinforcement learning
    is used in robotics, where a robot has a goal and it can only reach it through
    a sequence of steps—2 steps to the right, 5 steps forward, and so on. We can't
    tell whether a right versus left step is better on its own; the whole sequence
    must be found to reach the best outcome. Reinforcement learningis also used in
    gaming, as well as in recommendation engines. If Netflix only recommended to a
    user what matches their taste best, a user may end up with nothing but Star Wars
    movies on their home screen. Reinforcement learning is thenneeded to explore less-optimum
    matches to enrich the user's overall experience.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 与其单独处理每个动作，我们可能希望探索次优动作，以便达到整体最优的行动集合。强化学习被应用于机器人学，其中机器人有一个目标，且只能通过一系列步骤来实现——2步向右，5步向前，依此类推。我们不能单独判断右步或左步哪一个更好；必须找到完整的序列才能达到最佳结果。强化学习也被广泛应用于游戏和推荐引擎中。如果Netflix仅仅向用户推荐最符合他们口味的内容，用户的主页上可能只会显示《星际大战》系列电影。此时，强化学习需要探索次优匹配，以丰富用户的整体体验。
- en: The model development life cycle
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型开发生命周期
- en: When asked to solve a problem using machine learning, data scientists achieve
    this by following a sequence of steps. In this section, we are going to discuss
    those iterative steps.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当被要求用机器学习解决问题时，数据科学家通常通过一系列步骤来实现目标。在本节中，我们将讨论这些迭代步骤。
- en: Understanding a problem
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解问题
- en: '"All models are wrong, but some are useful."'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: “所有模型都是错误的，但有些模型是有用的。”
- en: – George Box
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ——乔治·博克斯
- en: The first thing to do when developing a model is to understand the problem you
    are trying to solve thoroughly. This not only involves understanding what problem
    you are solving, but also why you are solving it, what impact are you expecting
    to have, and what the currently available solution isthat you are comparing your
    new solution to. My understanding of what Box said when he stated that all models
    are wrong is that a model is just an approximation of reality by modeling one
    or more angles of it. By understanding the problem you are trying to solve, you
    can decide which angles of reality you need to model, and which ones you can tolerate
    ignoring.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 开发模型时，首先要做的是深入理解你要解决的问题。这不仅仅涉及理解你在解决什么问题，还包括为什么要解决它、你期望产生什么影响，以及你要与之比较的新解决方案目前已有的解决方案是什么。我理解Box所说的“所有模型都是错误的”这句话的意思是，模型只是通过建模现实的一个或多个角度来近似现实。通过理解你要解决的问题，你可以决定需要建模哪些现实角度，以及哪些角度可以忽略。
- en: You also need to understand the problem well to decide how to split your data
    for training and evaluation (more on that in the next section). You can then decide
    what kind of model to use. Is the problem suitable for supervised or unsupervised
    learning? Are we better off using classification or regression algorithms for
    this problem? What kind of classification algorithm will serve us best? Is a linear
    model good enough to approximate our reality? Do we need the most accurate model
    or one that we can easily explain to its users and to the business stakeholders?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要充分理解问题，以决定如何拆分数据进行训练和评估（关于这一点会在下一节中详细讨论）。然后，你可以决定使用什么样的模型。这个问题适合使用监督学习还是无监督学习？我们是否更适合使用分类算法还是回归算法？什么样的分类算法最适合我们？线性模型是否足以近似我们的现实？我们是需要最精确的模型，还是一个能够轻松向用户和业务相关者解释的模型？
- en: Minimal exploratory data analysis can be done here, where you can check whether
    you have labels and check the cardinality of the labels, if present, to decide
    whether you are dealing with a classification or a regression problem. I would
    still save any further data analysis until after the dataset is split into training
    and test sets. It is important to limit advanced data analysis to the training
    set only to ensure your model's generalizability.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这里可以进行最小化的探索性数据分析，检查是否有标签，并检查标签的基数（如果有的话），以决定你是否在处理分类问题或回归问题。任何进一步的数据分析最好等到数据集拆分为训练集和测试集后再进行。限制高级数据分析只在训练集上进行非常重要，以确保你的模型的泛化能力。
- en: Finally, we need to understand what we are comparing our model to. What is the
    current baseline that we need to improve on? If there are already business rules
    in place, then our model has to be better at solving the problem at hand than
    these rules. To be able to decide how much better it is at solving the problem,
    we need to use evaluation metrics—metrics that are suitable for our model and
    also as close as possible to our business requirements. If our aim is to increase
    revenue, then our metric should be good at estimating the increase in revenue
    when our model is used, compared to the current status quo. If our aim is to increase
    repeat purchases regardless of the revenue, then other metrics may be more suitable.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要理解我们将模型与什么进行比较。我们需要改进的当前基准是什么？如果已经有了业务规则，那么我们的模型在解决当前问题时必须优于这些规则。为了能够决定模型在解决问题上的优越性，我们需要使用评估指标——这些指标必须适合我们的模型，并且尽可能符合我们的业务需求。如果我们的目标是增加收入，那么我们的指标应该能有效估算模型使用后的收入增长，相对于当前的状况。如果我们的目标是增加重复购买，而不管收入如何，那么其他指标可能更合适。
- en: Splitting our data
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拆分我们的数据
- en: As we have seen in supervised learning, we train our model on a set of data
    where the correct answers (labels) are given. Learning, however, is only half
    of the problem. We also want to be able to tell whether the model we built is
    going to do a good job when used on future data. We cannot foresee the future,
    but we can use the data we already have to evaluate our model.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在监督学习中所看到的那样，我们在一组数据上训练模型，其中给出了正确的答案（标签）。然而，学习仅仅是问题的一半。我们还希望能够判断我们构建的模型在未来的数据上是否能做得很好。我们无法预测未来，但我们可以利用我们已有的数据来评估我们的模型。
- en: 'We do this by splitting our data into parts. We use one part of the data to
    train the model (the training set) and then use a separate part to evaluate the
    model (the test set). Since we want our test set to be as close as possible to
    the future data, there are two key points discussed in the following subsections
    to keep in mind when splitting our data:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过将数据分成不同部分来实现这一目标。我们使用其中一部分数据来训练模型（训练集），然后使用另一部分来评估模型（测试集）。由于我们希望测试集尽可能接近未来的数据，因此在划分数据时，需要注意以下两个关键点：
- en: Finding the best manner to split the data
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到最佳的数据划分方式
- en: Making sure the training and test datasets are separate
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保训练集和测试集是分开的
- en: Finding the best manner to split the data
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 找到最佳的数据划分方式
- en: Say your users' data is sorted according to their country in alphabetical order.
    If you just take the first *N* records for training and the rest for testing,
    you will end up training the model on users from certain countries and will never
    let it learn anything about users from, say, Zambia and Zimbabwe. So, one common
    solution is to randomize your data before splitting it. Random split is not always
    the best option, however. Say we want to build a model to predict the stock prices
    or climate change phenomena a few years ahead. To be confident that our system
    will capture temporal trends such as global warming, we need to split our data
    based on time. We can train on earlier data and see whether the model can do a
    good job in predicting more recent data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的用户数据是按国家字母顺序排序的。如果你仅选择前*N*条记录用于训练，剩下的用于测试，那么你最终将会训练一个只包含某些国家用户的数据模型，而无法让它学习来自其他国家（比如赞比亚和津巴布韦）的用户数据。因此，一个常见的解决方案是先对数据进行随机化再进行划分。然而，随机划分并不总是最佳选择。例如，假设我们想要建立一个模型，预测未来几年的股票价格或气候变化现象。为了确保我们的系统能够捕捉到诸如全球变暖等时间趋势，我们需要根据时间划分数据。我们可以在早期的数据上进行训练，看看模型是否能在预测更近期数据时表现良好。
- en: Sometimes, we just predict rare incidents. It can be that the number of fraud
    cases that occur in your payment system is 0.1%. If you randomly split your data,
    you may be unlucky and have the vast majority of the fraud cases in the training
    data and very few cases in the test data, or vice versa. So, it is advised that
    you use stratification when it comes to highly unbalanced data. Stratification
    makes sure that the distribution of your targets is more or less the same in both
    the training and test datasets.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们只是预测稀有事件。例如，支付系统中欺诈案件的发生率可能只有0.1%。如果你随机划分数据，可能会遇到运气不佳的情况，导致训练集中大部分欺诈案件，而测试集中几乎没有，反之亦然。因此，对于高度不平衡的数据，建议使用分层抽样。分层抽样确保你的目标变量在训练集和测试集中的分布大致相同。
- en: A stratified sampling strategy is used to make sure that the different subgroups
    in our population are represented in our samples. If my dataset is made up of
    99% males and 1% females, a random sample of the population may end up having
    only males in it. So, you should separate the male and female populations first,
    and then take a sample from each one of the two and combine them later to make
    sure they are both represented in the final sample. The same concept is applied
    here if we want to make sure all the class labels are present in our training
    and test sets. Later on in this book, we will be splitting our data using the
    `train_test_split()`function. This function uses the class labels to stratify
    its samples by default.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 分层抽样策略用于确保我们的人群中不同子群体在样本中都有体现。如果我的数据集由99%的男性和1%的女性组成，随机抽样可能会导致样本中全是男性。因此，你应该先将男性和女性人群分开，然后从每个群体中抽取样本，最后将它们合并，确保最终样本中男性和女性都有代表。为了确保训练集和测试集中的所有类别标签都能被代表，我们在这里也应用了相同的概念。在本书的后续章节中，我们将使用`train_test_split()`函数来划分数据。该函数默认使用类别标签对样本进行分层。
- en: Making sure the training and the test datasets are separate
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确保训练集和测试集是分开的
- en: One of the most common mistakes new data scientists may fall prey to is the
    look-ahead bias. We use the test dataset to simulate the data we will see in the
    future, but usually, the test dataset contains information that we can only know
    after time has passed. Take the case of our example space vehicles; we may have
    two columns—one saying whether the vehicle returns, and the other saying how long
    the vehicle will take to return. If we are to build a classifier to predict whether
    a vehicle will return, we will use the former column as our target, but we will
    never use the latter column as a feature. We can only know how long a vehicle
    stayed in outer space once it is actually back. This example looks trivial, but
    believe me, look-ahead bias is a very common mistake, especially when dealing
    with less obvious cases than this one.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 新的数据科学家常犯的一个常见错误是前瞻性偏差（look-ahead bias）。我们使用测试数据集来模拟我们未来将看到的数据，但通常，测试数据集包含的是我们只能在时间过去之后才知道的信息。以我们的太空飞行器例子为例；我们可能有两列数据——一列表示飞行器是否会返回，另一列表示飞行器将花多长时间返回。如果我们要构建一个分类器来预测飞行器是否会返回，我们将使用前一列作为目标，但绝不会将后一列用作特征。我们只能在飞行器实际返回后才知道它在太空中停留了多久。这个例子看起来很简单，但相信我，前瞻性偏差是一个非常常见的错误，尤其是在处理不如这个例子明显的情况时。
- en: Besides training, you also learn things from the data in order to preprocess
    it. Say, instead of users' heights in centimeters, you want to have a feature
    stating whether a user's height is above or below the median. To do that, you
    need to go through the data and calculate the median. Now, since anything that
    we learn has to come from the training set itself, we also need to learn this
    median from the training set and not from the entire dataset. Luckily, in all
    the data preprocessing functions of scikit-learn, there are separate methods for
    the `fit()`, `predict()`, and `transform()` functions. This makes sure that anything
    learned from the data (via the `fit()` method) is only learned from the training
    dataset, and then it can be applied to the test set (via the `predict()` and/or
    `transform()` methods).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 除了训练，你还需要从数据中学习以便对其进行预处理。例如，假设你希望不是以厘米为单位的用户身高，而是希望有一个特征来表示用户的身高是高于还是低于中位数。为了做到这一点，你需要遍历数据并计算中位数。现在，由于我们所学的任何东西必须来自于训练集本身，因此我们还需要从训练集中学习这个中位数，而不是从整个数据集中学习。幸运的是，在
    scikit-learn 的所有数据预处理函数中，`fit()`、`predict()` 和 `transform()` 函数都有单独的方法。这确保了从数据中学到的任何东西（通过
    `fit()` 方法）只会从训练数据集中学到，然后可以通过 `predict()` 和/或 `transform()` 方法应用到测试集上。
- en: Development set
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开发集
- en: When developing a model, we need to try multiple configurations of the model
    to decide which configuration gives the best results. To be able to do so, we
    usually split the training dataset further into training and development sets.
    Having two new subsets allows us to try different configurations when training
    on one of the two subsets and evaluating the effect of those configuration changes
    on the other. Once we find the best configuration, we evaluate our model with
    its final configuration on the test set. In [Chapter 2](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=25&action=edit),
    *Making Decisions with Trees*, we will do all this in practice. Note that I will
    be using the terms *model configuration* and *hyperparameters* interchangeably.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发模型时，我们需要尝试模型的多种配置，以决定哪种配置能够提供最佳结果。为了做到这一点，我们通常会进一步将训练数据集拆分成训练集和开发集。拥有这两个新的子集可以让我们在对其中一个子集进行训练时尝试不同的配置，并评估这些配置变化对另一个子集的影响。一旦我们找到最佳配置，我们就会在测试集上使用最终配置来评估模型。在[第
    2 章](https://cdp.packtpub.com/hands_on_machine_learning_with_scikit_learn/wp-admin/post.php?post=25&action=edit)《使用树做决策》中，我们将实际操作这一过程。请注意，我将交替使用
    *模型配置* 和 *超参数* 这两个术语。
- en: Evaluating our model
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估我们的模型
- en: Evaluating your model's performance is essential in picking the best algorithm
    for the job and to be able to estimate how your model will perform in real life.
    As Box said, a model that is wrong can still be useful. Take the example of a
    web start-up. They run an ad campaign where they are paid $1 for each view they
    get, and they know that for every 100 viewers, only one viewer signs up and buys
    stuff for $50\. In other words, they have to spend $100 to make $50\. Obviously,
    that's a bad **Return of Investment** (**ROI**) for their business. Now, what
    if you create a model for them that can pick users for them to target, but your
    new model is only correct 10% of the time? Is 10% precision good or bad, in this
    case? Well, of course, this model is wrong 90% of the time, which may sound like
    a very bad model, but if we calculate ROI now, then for every $100 they spend,
    they make $500\. Well, I would definitely pay you to build me this model that
    is quite wrong, yet quite useful!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型的性能对于选择最适合的算法以及估计模型在现实生活中的表现至关重要。正如 Box 所说，一个错误的模型仍然可以有用。以一个网络初创公司为例。它们进行了一次广告活动，每次展示广告获得
    1 美元的收入，而他们知道每 100 个观看者中，只有一个人注册并购买价值 50 美元的商品。换句话说，他们必须花费 100 美元才能赚取 50 美元。显然，这对他们的业务来说是一个糟糕的**投资回报率**
    (**ROI**) 。现在，假设你为他们创建了一个可以帮助他们挑选目标用户的模型，但你新建的模型只有 10% 的正确率。在这种情况下，10% 的准确率是好是坏呢？当然，这个模型
    90% 的时间都是错误的，听起来好像是一个很糟糕的模型，但如果我们现在计算 ROI，那么他们每花费 100 美元，就能赚取 500 美元。嗯，我一定会付钱给你，来为我构建这个虽然很错误，但却非常有用的模型！
- en: scikit-learn provides a large number of evaluation metrics that we will be using
    to evaluate the models we build in this book. But remember, a metric is only useful
    if you really understand the problem you are solving and its business impact.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 提供了大量评估指标，我们将在本书中使用这些指标来评估我们构建的模型。但请记住，只有在你真正理解你解决的问题及其商业影响的情况下，评估指标才有用。
- en: Deploying in production and monitoring
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在生产环境中部署并进行监控
- en: The main reason that many data scientists use Python for machine learning instead
    of R, for example, is that it makes it easier to productionize your code. Python
    has plenty of web frameworks to build APIs with and put the machine learning models
    behind. It is also supported by all cloud providers. I find it important that
    the team developing a model is also responsible for deploying it in production.
    Building your model in one language and then asking another team to port it into
    another language is error-prone. Of course, having one person or team building
    and deploying models may not be feasible in larger companies or due to other implementation
    constraints.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据科学家选择使用 Python 而不是 R 来进行机器学习的主要原因之一，是 Python 使得将代码投入生产变得更加容易。Python 有许多
    Web 框架可以用来构建 API，并将机器学习模型部署到后台。它也得到了所有云服务提供商的支持。我认为，开发模型的团队也应该负责将其部署到生产环境中。用一种语言构建模型，然后让另一个团队将其转换为另一种语言，这种做法容易出错。当然，在大型公司或由于其他实现限制的情况下，由一个人或团队负责构建和部署模型可能并不可行。
- en: However, keeping the two teams in close contact and making sure that the ones
    developing the model can still understand the production code is essential and
    helps to minimize errors on account of development and production code inconsistency.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，让两个团队保持紧密联系，并确保开发模型的团队仍然能够理解生产代码至关重要，这有助于最小化由于开发代码和生产代码不一致而导致的错误。
- en: We try our best not to have any look-ahead bias when training our models. We
    hope data doesn't change after our models are trained, and we want our code to
    be bug-free. However, we cannot guarantee any of this. We may overlook the fact
    that the user's credit score is only added to the database after they make their
    first purchase. We may not know that our developers decided to switch to the metric
    system to specify our inventory's weights while it was saved in pounds when the
    model was trained. Because of that, it is important to log all the predictions
    your model makes to be able to monitor its performance in real life and compare
    it to the test set's performance. You can also log the test set's performance
    every time you retrain the model or keep track of the target's distribution over
    time.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尽量避免在训练模型时出现前瞻性偏差。我们希望数据在模型训练完成后不会发生变化，并且我们希望代码是无错误的。然而，我们无法保证这一切。我们可能忽视了这样一个事实，即用户的信用评分是在他们进行首次购买后才添加到数据库中的。我们可能不知道，开发人员决定在保存时将库存重量从英镑改为使用公制系统，而在训练模型时，它是以英镑为单位的。因此，记录模型所做的所有预测非常重要，以便能够在实际环境中监控模型的表现，并将其与测试集的表现进行比较。你还可以每次重新训练模型时记录测试集的表现，或跟踪目标分布的变化。
- en: Iterating
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迭代
- en: Often, when you deploy a model, you end up with more data. Furthermore, the
    performance of your model is not guaranteed to be the same when deployed in production.
    This can be due to some implementation issues or mistakes that took place during
    the evaluation process. Those two points mean that the first version of your solution
    is always up for improvement. Starting with simple solutions (that can be improved
    via iterations) is an important concept for agile programming and is a paramount
    concept for machine learning.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当你部署一个模型时，你最终会得到更多的数据。此外，当你的模型部署到生产环境中时，其性能并不一定能够保持不变。这可能是由于某些实现问题或评估过程中的错误。这两点意味着你解决方案的第一个版本总是可以改进的。从简单的解决方案开始（可以通过迭代来改进）是敏捷编程的一个重要概念，也是机器学习中的核心概念。
- en: This whole process, from understanding theproblemto monitoring the ongoing improvements
    on the solution, requires tools that allow us to iterate quickly and efficiently.
    In the next section, we will introduce you to scikit-learn and explain why many
    machine learning practitioners consider it the right tool for the job.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这一整个过程，从理解问题到监控解决方案的持续改进，需要那些能够帮助我们快速、高效迭代的工具。在接下来的部分中，我们将介绍scikit-learn，并解释为什么许多机器学习从业者认为它是处理该任务的正确工具。
- en: When to use machine learning
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用机器学习
- en: '"Pretty much anything that a normal person can do in less than 1 second, we
    can now automate with AI."'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: “几乎任何正常人可以在不到1秒钟内完成的事情，我们现在都可以通过AI来自动化。”
- en: – Andrew Ng
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: – Andrew Ng
- en: One additional note before moving on to the next section is that when faced
    with a problem, you have to decide whether machine learning is apt for the task.
    Andrew Ng's 1-second rule is a good heuristic for you to estimate whether a machine
    learning-based solution will work. The main reason behind this is that computers
    are good with patterns. They are way better than humans at picking repeated patterns
    and acting on them.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入下一部分之前有一个额外的说明，当你面对一个问题时，必须决定是否适合使用机器学习。Andrew Ng的1秒规则是一个很好的启发式方法，帮助你评估基于机器学习的解决方案是否可行。背后的主要原因是计算机擅长发现模式。它们在识别重复模式并根据这些模式进行操作方面，远胜于人类。
- en: Once they identify the same pattern over and over again, it is easy to codify
    them to make the same decisions every time. In the same manner, computers are
    also good with tactics. In 1908, Richard Teichmann stated that a game of chess
    is 99% basedontactics. Maybe that's why computers have beat humans in chess since
    1997\. If we are to believe Teichmann's statement, then the remaining 1% is strategy.
    Unlike tactics, strategy is the arena where humans beat machines. If the problem
    you want to solve can be formulated as a set of tactics, then go for machine learning
    and leave the strategic decisions for humans to make. In the end, most of our
    day-to-day decisions are tactical. Furthermore, one man's strategy is often someone
    else's tactics.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦它们一次又一次地识别出相同的模式，就很容易将这些模式编码成每次都作出相同的决策。以同样的方式，计算机也擅长战术。1908年，Richard Teichmann曾指出，一局棋的99%是基于战术的。也许这就是为什么自1997年以来计算机一直战胜人类下棋的原因。如果我们相信Teichmann的说法，那么剩下的1%就是战略。与战术不同，战略是人类战胜机器的领域。如果你要解决的问题可以表述为一组战术，那就用机器学习，让人类来做战略决策。最终，我们大多数日常决策都是战术性的。此外，一个人的战略往往是另一个人的战术。
- en: Introduction to scikit-learn
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: scikit-learn简介
- en: Since you have already picked up this book, you probably don't need me to convince
    you why machine learning is important. However, you may still have doubts about
    why to use scikit-learn in particular. You may encounter names such as TensorFlow,
    PyTorch, and Spark more often during your daily news consumption than scikit-learn.
    So, let me convince you of my preference for the latter.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你已经拿起了这本书，你大概不需要我来说服你为什么机器学习很重要。然而，你可能仍然对为什么特别使用scikit-learn有所疑虑。你可能在日常新闻中更常遇到像TensorFlow、PyTorch和Spark这样的名字，而不是scikit-learn。那么，让我来说服你为什么我更偏爱后者。
- en: It plays well with the Python data ecosystem
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它与Python数据生态系统兼容性好
- en: scikit-learn is a Python toolkit built on top of NumPy, SciPy, and Matplotlib.
    These choices mean that it fits well into your daily data pipeline. As a data
    scientist, Python is most likely your language of choice since it is good for
    both offline analysis and real-time implementations. You will also be using tools
    such as `pandas` to load data from your database, which allows you to perform
    a vast amount of transformation to your data. Since both `pandas` and scikit-learn
    are built on top of NumPy, they play very well with each other. Matplotlib is
    the *de facto* data visualization tool for Python, which means you can use its
    sophisticated data visualization capabilities to explore your data and unravel
    your model's ins and outs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 是一个构建在 NumPy、SciPy 和 Matplotlib 之上的 Python 工具包。这些选择意味着它很好地融入了你日常的数据处理流程。作为一名数据科学家，Python
    很可能是你首选的编程语言，因为它既适合离线分析，也适合实时实现。你还会使用像 `pandas` 这样的工具从数据库中加载数据，它允许你对数据进行大量转换。由于
    `pandas` 和 scikit-learn 都是基于 NumPy 构建的，因此它们相互兼容得很好。Matplotlib 是 Python 的 *事实标准*
    数据可视化工具，这意味着你可以利用其强大的数据可视化功能来探索数据并揭示模型的细节。
- en: Since it is an open source tool that is heavily used in the community, it is
    very common to see other data tools use an almost identical interface to scikit-learn.
    Many of these tools are built on top of the same scientific Python libraries,
    and they are collectively known as **SciKits** (short for **SciPy****Toolkits**)—hence,
    the *scikit* prefix in scikit-learn. For example, `scikit-image` is a library
    for image processing, while `categorical-encoding` and `imbalanced-learn` are
    separate libraries for data preprocessing that are built as add-ons to scikit-learn.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它是一个开源工具，并且在社区中被广泛使用，许多其他数据工具采用了与 scikit-learn 几乎相同的接口。许多这样的工具建立在相同的科学 Python
    库之上，它们统称为 **SciKits**（即 **SciPy****Toolkits** 的缩写）——因此，scikit-learn 中的 *scikit*
    前缀就来源于此。例如，`scikit-image` 是一个用于图像处理的库，而 `categorical-encoding` 和 `imbalanced-learn`
    是两个单独的数据预处理库，它们作为 scikit-learn 的附加组件构建。
- en: We are going to use some of these tools in this book, and you will notice how
    easy it is to integrate these different tools into your workflow when using scikit-learn.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将使用这些工具，你会发现当使用 scikit-learn 时，将这些不同的工具集成到工作流程中是多么容易。
- en: Being a key player in the Python data ecosystem is what makes scikit-learn the
    *de facto* toolset for machine learning. This is the tool that you will most likely
    hand your job application assignment to, as well as use for Kaggle competitions
    and to solve most of your professional day-to-day machine learning problems for
    your job.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 成为 Python 数据生态系统中的关键角色，是 scikit-learn 成为 *事实标准* 机器学习工具集的原因。这就是你最有可能用来完成工作申请任务的工具，也是你参加
    Kaggle 竞赛并解决大多数专业日常机器学习问题时使用的工具。
- en: Practical level of abstraction
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实践级别的抽象
- en: scikit-learn implements a vast amount of machine learning, data processing,
    and model selection algorithms. These implementations are abstract enough, so
    you only need to apply minor changes when switching from one algorithm to another.
    This is a key feature since you will need to quickly iterate between different
    algorithms when developing a model to pick the best one for your problem. Having
    that said, this abstraction doesn't shield you from the algorithms' configurations.
    In other words, you are still in full control of your hyperparameters and settings.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 实现了大量的机器学习、数据处理和模型选择算法。这些实现足够抽象，因此你在切换算法时只需进行少量更改。这是一个关键特性，因为在开发模型时，你需要快速地在不同算法之间进行迭代，以选择最适合你问题的算法。话虽如此，这种抽象并不会使你对算法的配置失去控制。换句话说，你仍然完全掌握你的超参数和设置。
- en: When not to use scikit-learn
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时不使用 scikit-learn
- en: Most likely, the reasons to not use scikit-learn will include combinations of
    deep learning or scale. scikit-learn's implementation of neural networks is limited.
    Unlike scikit-learn, TensorFlow and PyTorch allow you to use a custom architecture,
    and they support GPUs for a massive training scale. All of scikit-learn's implementations
    run in memory on a single machine. I'd say that way more than 90% of businesses
    are at a scale where these constraints are fine. Data scientists can still fit
    their data in memory in large enough machines thanks to the cloud optionsavailable.
    They can cleverly engineer workarounds to deal with scaling issues, but if these
    limitations become something that they can no longer deal with, then they will
    need other tools to do the trick for them.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，不使用scikit-learn的原因将包括深度学习或规模的组合。scikit-learn对神经网络的实现有限。与scikit-learn不同，TensorFlow和PyTorch允许你使用自定义架构，并支持GPU以应对大规模训练。scikit-learn的所有实现都在内存中运行，并且仅限于单台机器。我认为超过90%的企业规模符合这些限制。数据科学家仍然能够在足够大的机器上将数据加载到内存中，这得益于云计算选项。他们可以巧妙地设计解决方法来应对扩展问题，但如果这些限制变得无法应对，他们将需要其他工具来解决问题。
- en: There are solutions being developed that allow scikit-learn to scale to multiple
    machines, such as Dask. Many scikit-learn algorithms allow parallel execution
    using `joblib`, which natively provides thread-based and process-based parallelism.
    Dask can scale these `joblib`-backed algorithms out to a cluster of machines by
    providing an alternative `joblib` backend.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 目前正在开发一些解决方案，使scikit-learn能够扩展到多台机器，如Dask。许多scikit-learn算法允许使用`joblib`进行并行执行，`joblib`本身提供了基于线程和进程的并行性。Dask通过提供一个替代的`joblib`后端，可以将这些基于`joblib`的算法扩展到集群中。
- en: Installing the packages you need
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装所需的包
- en: It's time to install the packages we will need in this book, but first of all,
    make sure you have Python installed on your computer. In this book, we will be
    using Python version 3.6\. If your computer comes with Python 2.x installed, then
    you should upgrade Python to version 3.6 or later. I will show you how to install
    the required packages using `pip`, Python's *de facto* package-management system.
    If you use other package-management systems, such as Anaconda, you can easily
    find the equivalent installation commands for each of the following packages online.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是安装我们在本书中需要的包的时候了，但首先，确保你的计算机上安装了Python。在本书中，我们将使用Python 3.6版本。如果你的计算机安装的是Python
    2.x版本，你应该将Python升级到3.6或更高版本。我将向你展示如何使用`pip`安装所需的包，`pip`是Python的*事实上的*包管理系统。如果你使用其他包管理系统，比如Anaconda，你可以在线轻松找到每个包的等效安装命令。
- en: 'To install `scikit-learn`, run the following command:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装`scikit-learn`，请运行以下命令：
- en: '[PRE0]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: I will be using version `0.22` of `scikit-learn` here. You can add the `--user`switch
    to the `pip` command to limit the installation to your own directories. This is
    important if you do not have root access to your machine or if you do not want
    to install the libraries globally. Furthermore, I prefer to create a virtual environment
    for each project I work on and install all the libraries I need for this project
    into that environment. You can check the documentation for Anaconda or Python's
    `venv` module to see how to create virtual environments.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在这里使用`0.22`版本的`scikit-learn`。你可以在`pip`命令中添加`--user`开关，将安装限制在自己的目录中。如果你没有管理员权限，或者不想全局安装这些库，这一点非常重要。此外，我更倾向于为每个项目创建一个虚拟环境，并将该项目所需的所有库安装到该环境中。你可以查看Anaconda的文档或Python的`venv`模块，了解如何创建虚拟环境。
- en: 'Along with scikit-learn, we will need to install `pandas`. I will briefly introduce
    `pandas` in the next section, but for now, you can use the following command to
    install it:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 除了scikit-learn，我们还需要安装`pandas`。我将在下一节中简要介绍`pandas`，但现在，你可以使用以下命令来安装它：
- en: '[PRE1]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Optionally, you may need to install **Jupyter**. Jupyter notebooks allow you
    to write code in your browser and run bits of it in whichever order you want.
    This makes it ideal for experimentation and trying different parameters without
    the need to rerun the entire code every time. You can also plot graphs in your
    notebooks with the help of Matplotlib. Use the following commands to install both
    Jupyter and Matplotlib:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 可选地，你可能需要安装**Jupyter**。Jupyter笔记本允许你在浏览器中编写代码，并按照你希望的顺序运行部分代码。这使得它非常适合实验和尝试不同的参数，而无需每次都重新运行整个代码。你还可以借助Matplotlib在笔记本中绘制图表。使用以下命令来安装Jupyter和Matplotlib：
- en: '[PRE2]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To start your Jupyter server, you can run `jupyter notebook`in your terminal,
    and then visit `http://localhost:8888/`in your browser.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动您的Jupyter服务器，可以在终端中运行`jupyter notebook`，然后在浏览器中访问`http://localhost:8888/`。
- en: We will make use of other libraries later on in the book. I'd rather introduce
    you to them when we need them and show you how to install each of them then.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书后面使用其他库。我宁愿在需要时向您介绍它们，并向您展示如何安装每一个。
- en: Introduction to pandas
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: pandas介绍
- en: '`pandas` is an open source library that provides data analysis tools for the
    Python programming language. If this definition doesn''t tell you much, then you
    may think of `pandas` as Python''s response to spreadsheets. I have decided to
    dedicate this section to `pandas` since you will be using it to create and load
    the data you are going to use in this book. You will also use `pandas` to analyze
    and visualize your data and alter the value of its columns before applying machine
    learning algorithms to it.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`是一个开源库，为Python编程语言提供数据分析工具。如果这个定义对您来说不是很清楚，那么您可以将`pandas`视为Python对电子表格的响应。我决定专门介绍`pandas`，因为您将使用它来创建和加载本书中要使用的数据。您还将使用`pandas`来分析和可视化数据，并在应用机器学习算法之前修改其列的值。'
- en: 'Tables in `pandas` are referred to as DataFrames. If you are an R programmer,
    then this name should be familiar to you. Now, let''s start by creating a DataFrame
    for some polygon names and the number of sides each has:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在`pandas`中，表被称为DataFrame。如果您是R程序员，那么这个名字对您来说应该很熟悉。现在，让我们从创建一些多边形名称和每个多边形边数的DataFrame开始：
- en: '[PRE3]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You can then use the `head` method to print the first *N* rows of your newly
    created DataFrame:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`head`方法打印您新创建的DataFrame的前*N*行：
- en: '[PRE4]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here, you can see the first three rows of the DataFrame. In addition to the
    columns we specified, `pandas` add a default index:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以看到DataFrame的前三行。除了我们指定的列之外，`pandas`还添加了一个默认索引：
- en: '![](img/36f71f93-9cce-4b4f-b03c-f4fc88b098f1.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36f71f93-9cce-4b4f-b03c-f4fc88b098f1.png)'
- en: 'Since we are programming in Python, we can also use the language''s built-in
    function or even use our custom-built functions when creating a DataFrame. Here,
    we will use the `range` generator, rather than typing in all the possible side
    counts ourselves:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在Python中编程，因此在创建DataFrame时，我们还可以使用语言的内置函数或甚至使用我们的自定义函数。在这里，我们将使用`range`生成器，而不是手动输入所有可能的边数：
- en: '[PRE5]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You can also sort your DataFrame by column. Here, we will sort it by polygon
    name in alphabetical order, and then print the first five polygons:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以按列对DataFrame进行排序。在这里，我们将按字母顺序按多边形名称对其进行排序，然后打印前五个多边形：
- en: '[PRE6]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This time, we can see the first five rows of the DataFrame after it has been
    ordered by the names of the polygons in alphabetical order:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，我们可以看到DataFrame按多边形名称按字母顺序排序后的前五行：
- en: '![](img/03cb45bc-2fdf-4b29-bfe4-10c1c1e15f76.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/03cb45bc-2fdf-4b29-bfe4-10c1c1e15f76.png)'
- en: 'Feature engineering is the art of deriving new features by manipulating existing
    data. This is something that `pandas` is good at. In the following example, we
    are creating a new column, `Length of Name`, and adding the character lengths
    of each polygon''s name:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程是通过操作现有数据来派生新特征的艺术。这是`pandas`擅长的事情。在下面的例子中，我们正在创建一个新列`Name长度`，并添加每个多边形名称的字符长度：
- en: '[PRE7]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We use `str` to be able to access the string functions to apply them to the
    values in the `Name` column. We then use the `len` method of a string. One other
    way to achieve the same result is to use the `apply()` function. If you call `apply()`
    on a column, you can get access to the values in the column. You can then apply
    any Python built-in or custom functions there. Here are two examples of how to
    use the `apply()` function.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`str`来访问字符串函数，以便将它们应用到`Name`列的值上。然后，我们使用字符串的`len`方法。实现相同结果的另一种方法是使用`apply()`函数。如果在列上调用`apply()`，您可以访问列中的值。然后，您可以在那里应用任何Python内置或自定义函数。以下是如何使用`apply()`函数的两个示例。
- en: 'Example 1 is as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 示例1如下所示：
- en: '[PRE8]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Example 2 is as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 示例2如下所示：
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The good thing about the `apply()` method is that it allows you to run your
    own custom code anywhere, which is something you will need to use a lot when performing
    complex feature engineering. Nevertheless, the code you run using the `apply()`
    method isn't as optimized as the code in the first example. This is a clear case
    of flexibility versus performance trade-off that you should be aware of.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '`apply()` 方法的好处在于它允许你在任何地方运行自定义代码，这是在进行复杂特征工程时经常需要使用的功能。尽管如此，使用 `apply()` 方法运行的代码并不像第一个示例中的代码那样经过优化。这是灵活性与性能之间明显的权衡案例，你应该注意到这一点。'
- en: 'Finally, we can use the plotting capabilities provided by `pandas` and Matplotlib
    to see whether there is any correlation between the number of sides a polygon
    has and the length of its name:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用 `pandas` 和 Matplotlib 提供的绘图功能来查看多边形边数与其名称长度之间是否存在任何相关性：
- en: '[PRE10]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Once we run the previous code, the following scatter plots will be displayed:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码后，将显示以下散点图：
- en: '![](img/7debbcb9-35d9-40a6-aa6d-d0d85e5146ef.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7debbcb9-35d9-40a6-aa6d-d0d85e5146ef.png)'
- en: Scatter plots are generally useful for seeing correlations between two features.
    In the following plot, there is no clear correlation to be seen.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图通常用于查看两个特征之间的相关性。在以下图中，没有明显的相关性可见。
- en: Python's scientific computing ecosystem conventions
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python的科学计算生态系统惯例
- en: 'Throughout this book, I will be using `pandas`, NumPy, SciPy, Matplotlib, and
    Seaborn. Any time you see the `np`, `sp`, `pd`, `sns`, and `plt`prefixes,you should
    assume that I have run the following import statements prior to the code:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我将使用 `pandas`、NumPy、SciPy、Matplotlib 和 Seaborn。每当你看到 `np`、`sp`、`pd`、`sns`
    和 `plt` 前缀时，你应该假设我在代码之前运行了以下导入语句：
- en: '[PRE11]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This is the *de facto* way of importing the scientific computing ecosystem
    into Python. If any of these libraries is missing on your computer, here is how
    to install them using `pip`:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这是将科学计算生态系统导入Python的*事实上*方式。如果你的电脑上缺少其中任何库，以下是如何使用 `pip` 安装它们的方法：
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Usually, you do not need to specify the versions for each library; running `pip
    install numpy` will just install the latest stable version of the library. Nevertheless,
    pinning the version is good practice for reproducibility. It ensures the same
    results from the same code when it runs on different machines.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，你不需要为每个库指定版本；运行 `pip install numpy` 将只安装库的最新稳定版本。尽管如此，锁定版本对于可复现性是个好习惯。当在不同机器上运行相同代码时，它确保相同的结果。
- en: 'The code used in this book is written in Jupyter notebooks. I advise you to
    do the same on your machine. In general, the code should run smoothly in any other
    environment with very few changes when it comes to printing and displaying the
    results. If the figures are not shown in your Jupyter notebook, you may need to
    run the following line at least once in any cell at the beginning of your notebook:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用的代码是在Jupyter笔记本中编写的。我建议你在你的机器上也这样做。总体而言，在任何其他环境中，代码应该在打印和显示结果时以很少的更改顺利运行。如果在你的Jupyter笔记本中未显示图形，你可能需要在任何一个单元格的开头运行以下行至少一次：
- en: '[PRE13]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Furthermore, randomness is quite common in many machine learning tasks. We may
    need to create random data to use with our algorithms. We may also randomly split
    this data into training and test sets. The algorithms themselves may use random
    values for initialization. There are tricks to make sure we all get the exact
    same results by using pseudo-random numbers. I will be using these tricks when
    needed sometimes, but other times, it would be better to make sure we get slightly
    different results to give you an idea of how things are not always deterministic
    and how to find ways to deal with underlying uncertainties. More on this later.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在许多机器学习任务中，随机性是非常常见的。我们可能需要创建随机数据来与我们的算法一起使用。我们还可能会随机将这些数据分割为训练集和测试集。算法本身可能会使用随机值进行初始化。有一些技巧可以通过使用伪随机数确保我们所有人都得到完全相同的结果。有时候需要使用这些技巧，但其他时候，确保我们得到稍有不同的结果会更好，以便让你了解事情并非总是确定性的，以及如何找到处理潜在不确定性的方法。稍后详述。
- en: Summary
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Mastering machine learning is a desirable skill nowadays given its vast application
    everywhere, from business to academia. Nevertheless, just understanding the theory
    of it will only take you so far since practitioners also need to understand their
    tools to be self-sufficient and capable.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握机器学习是一种现今广泛应用的理想技能，无论是在商业还是学术领域。然而，仅仅理解其理论只能带你走得那么远，因为从业者还需要理解他们的工具，以自给自足并有能力。
- en: In this chapter, we started with a high-level introduction to machine learning
    and learned when to use each of the machine learning types; from classification
    and regression to clustering and reinforcement learning. We then learned about
    scikit-learn and why practitioners recommend it when solving both supervised and
    unsupervised learning problems. To keep this book self-sufficient, we also covered
    the basics of data manipulation for those who haven't used libraries such as `pandas`
    and Matplotlib before. In the following chapters, we will continue to combine
    our understanding of the underlying theory of machine learning with more practical
    examples using scikit-learn.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们首先进行了机器学习的高层次介绍，并学习了何时使用每种类型的机器学习；从分类和回归到聚类和强化学习。然后，我们了解了 scikit-learn，以及为什么实践者在解决监督和无监督学习问题时推荐使用它。为了使本书自给自足，我们还涵盖了数据操作的基础知识，特别是为那些之前没有使用过
    `pandas` 和 Matplotlib 的读者准备的。在接下来的章节中，我们将继续将对机器学习基本理论的理解与使用 scikit-learn 的更多实际示例相结合。
- en: The first two parts of this book will cover supervised machine learning algorithms.
    The first part will cover basic algorithms, as well as some other machine learning
    basics, such as data splitting and preprocessing. Then, we will move on to more
    advanced topics in the second part. The third and final part will cover unsupervised
    learning and topics such as anomaly detection and recommendation engines.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的前两部分将涉及监督学习算法。第一部分将涵盖基础算法以及一些机器学习的基础知识，如数据拆分和预处理。然后，我们将进入第二部分，讨论更高级的话题。第三部分也是最后一部分，将涵盖无监督学习以及如异常检测和推荐引擎等主题。
- en: So that this book remains a practical guide, I have made sure to provide examples
    in each chapter. I also did not want to separate the data preparation from model
    creation. Although topics such as data splitting, feature selection, data scaling,
    and model evaluation are key concepts to know about, we usually deal with them
    as part of an overall whole solution. I also feel that those concepts are best
    understood in their correct context. That's why, within each chapter, I will be
    covering one main algorithm but will use some examples to shed light on some other
    concepts along the way.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保本书是一本实用的指南，我确保在每一章中都提供了示例。我也不想将数据准备与模型创建分开。虽然像数据拆分、特征选择、数据缩放和模型评估这样的主题是必须了解的关键概念，但我们通常将它们作为整体解决方案的一部分来处理。我还认为这些概念最好在正确的上下文中理解。这就是为什么在每一章中，我会覆盖一个主要的算法，并通过一些示例来阐明其他相关概念。
- en: This means that it is up to you whether you read this book from cover to cover
    or use it as a reference and jump straight to the algorithms you want to know
    about when you need them. Nevertheless, I advise that you skim through all the
    chapters, even if you already know about the algorithm covered there or don't
    need to know about it at the moment.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，你可以决定是从头到尾阅读本书，还是将其作为参考书，在需要时直接跳到你想了解的算法。然而，我建议你浏览所有章节，即使你已经了解其中涵盖的算法，或者目前不需要了解它们。
- en: I hope that you are now ready for the next chapter, where we will start by looking
    at decision trees and learn how to use them to solve different classification
    and regression problems.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你现在已经准备好进入下一章，我们将从决策树开始，学习如何使用它们解决不同的分类和回归问题。
- en: Further reading
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information on the relative topics of this chapter, please refer to
    the following links:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解本章相关的更多信息，请参考以下链接：
- en: '*Learn Python Programming – Second Edition*, by *Fabrizio Romano*: [https://www.packtpub.com/application-development/learn-python-programming-second-edition](https://www.packtpub.com/application-development/learn-python-programming-second-edition)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习 Python 编程 – 第二版*，作者 *法布里齐奥·罗马诺*：[https://www.packtpub.com/application-development/learn-python-programming-second-edition](https://www.packtpub.com/application-development/learn-python-programming-second-edition)'
- en: '*Hands-On Data Analysis with Pandas*, by *Stefanie Molin*: [https://www.packtpub.com/big-data-and-business-intelligence/hands-data-analysis-pandas](https://www.packtpub.com/big-data-and-business-intelligence/hands-data-analysis-pandas)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*动手实践 Pandas 数据分析*，作者 *斯特法妮·莫林*：[https://www.packtpub.com/big-data-and-business-intelligence/hands-data-analysis-pandas](https://www.packtpub.com/big-data-and-business-intelligence/hands-data-analysis-pandas)'
