- en: Chapter 6. Retrieving Images and Searching Using Image Descriptors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 使用图像描述符检索图像和搜索
- en: Similar to the human eyes and brain, OpenCV can detect the main features of
    an image and extract these into so-called image descriptors. These features can
    then be used as a database, enabling image-based searches. Moreover, we can use
    keypoints to stitch images together and compose a bigger image (think of putting
    together many pictures to form a 360 degree panorama).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 与人眼和大脑类似，OpenCV可以检测图像的主要特征，并将这些特征提取成所谓的图像描述符。这些特征可以用作数据库，实现基于图像的搜索。此外，我们可以使用关键点将图像拼接起来，组成更大的图像（例如，将多张图片拼成360度全景图）。
- en: This chapter shows you how to detect features of an image with OpenCV and make
    use of them to match and search images. Throughout the chapter, we will take sample
    images and detect their main features, and then try to find a sample image contained
    in another image using homography.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将向您展示如何使用OpenCV检测图像特征，并利用这些特征进行图像匹配和搜索。在整个章节中，我们将使用示例图像检测其主要特征，然后尝试使用单应性找到包含在另一图像中的示例图像。
- en: Feature detection algorithms
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征检测算法
- en: 'There are a number of algorithms that can be used to detect and extract features,
    and we will explore most of them. The most common algorithms used in OpenCV are
    as follows:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多算法可以用于检测和提取特征，我们将探索其中大部分。在OpenCV中最常用的算法如下：
- en: '**Harris**: This algorithm is useful to detect corners'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Harris**：此算法用于检测角点'
- en: '**SIFT**: This algorithm is useful to detect blobs'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SIFT**：此算法用于检测图像块'
- en: '**SURF**: This algorithm is useful to detect blobs'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SURF**：此算法用于检测图像块'
- en: '**FAST**: This algorithm is useful to detect corners'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FAST**：此算法用于检测角点'
- en: '**BRIEF**: This algorithm is useful to detect blobs'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BRIEF**：此算法用于检测图像块'
- en: '**ORB**: This algorithm stands for **Oriented FAST and Rotated BRIEF**'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ORB**：此算法代表**Oriented FAST and Rotated BRIEF**'
- en: 'Matching features can be performed with the following methods:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下方法进行特征匹配：
- en: Brute-Force matching
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 暴力匹配
- en: FLANN-based matching
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于FLANN的匹配
- en: Spatial verification can then be performed with homography.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用单应性进行空间验证。
- en: Defining features
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义特征
- en: What is a feature exactly? Why is a particular area of an image classifiable
    as a feature, while others are not? Broadly speaking, a feature is an area of
    interest in the image that is unique or easily recognizable. As you can imagine,
    corners and high-density areas are good features, while patterns that repeat themselves
    a lot or low-density areas (such as a blue sky) are not. Edges are good features
    as they tend to divide two regions of an image. A blob (an area of an image that
    greatly differs from its surrounding areas) is also an interesting feature.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 特征究竟是什么？为什么图像的某个特定区域可以被归类为特征，而其他区域则不是？广义上讲，特征是图像中一个独特或易于识别的兴趣区域。正如你可以想象的那样，角点和高密度区域是好的特征，而重复性很高的图案或低密度区域（如蓝天）则不是。边缘是好的特征，因为它们倾向于分割图像的两个区域。图像块（与周围区域差异很大的图像区域）也是一个有趣的特征。
- en: Most feature detection algorithms revolve around the identification of corners,
    edges, and blobs, with some also focusing on the concept of a **ridge**, which
    you can conceptualize as the symmetry axis of an elongated object (think, for
    example, about identifying a road in an image).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数特征检测算法都围绕角点、边缘和图像块的识别，其中一些也关注**脊**的概念，你可以将其视为长形物体的对称轴（例如，考虑在图像中识别道路）。
- en: Some algorithms are better at identifying and extracting features of a certain
    type, so it's important to know what your input image is so that you can utilize
    the best tool in your OpenCV belt.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有些算法在识别和提取特定类型的特征方面做得更好，因此了解你的输入图像很重要，这样你就可以利用OpenCV工具箱中的最佳工具。
- en: Detecting features – corners
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检测特征 – 角点
- en: Let's start by identifying corners by utilizing `CornerHarris`, and let's do
    this with an example. If you continue studying OpenCV beyond this book, you'll
    find that—for many a reason—chessboards are a common subject of analysis in computer
    vision, partly because a chequered pattern is suited to many types of feature
    detections, and maybe because chess is pretty popular among geeks.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先通过利用`CornerHarris`识别角点，以下是一个示例。如果你继续学习OpenCV，你会发现——出于许多原因——棋盘是计算机视觉中常见的分析对象，部分原因是因为棋盘图案适合许多类型的特征检测，也许是因为棋类游戏在极客中相当受欢迎。
- en: 'Here''s our sample image:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的示例图像：
- en: '![Detecting features – corners](img/image00216.jpeg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![检测特征 – 角点](img/image00216.jpeg)'
- en: 'OpenCV has a very handy utility function called `cornerHarris`, which detects
    corners in an image. The code to illustrate this is incredibly simple:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV有一个非常方便的实用函数叫做`cornerHarris`，它可以检测图像中的角落。说明这个功能的代码非常简单：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s analyze the code: after the usual imports, we load the chessboard image
    and turn it to grayscale so that `cornerHarris` can compute it. Then, we call
    the `cornerHarris` function:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下代码：在常规导入之后，我们加载棋盘图像并将其转换为灰度，这样`cornerHarris`就可以计算它了。然后，我们调用`cornerHarris`函数：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The most important parameter here is the third one, which defines the aperture
    of the Sobel operator. The Sobel operator performs the change detection in the
    rows and columns of an image to detect edges, and it does this using a kernel.
    The OpenCV `cornerHarris` function uses a Sobel operator whose aperture is defined
    by this parameter. In plain english, it defines how sensitive corner detection
    is. It must be between 3 and 31 and be an odd value. At value 3, all those diagonal
    lines in the black squares of the chessboard will register as corners when they
    touch the border of the square. At 23, only the corners of each square will be
    detected as corners.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这里最重要的参数是第三个参数，它定义了Sobel算子的孔径。Sobel算子通过在图像的行和列中进行变化检测来检测边缘，它使用一个核来实现这一点。OpenCV的`cornerHarris`函数使用一个Sobel算子，其孔径由这个参数定义。简单来说，它定义了角落检测的敏感性。它必须在3到31之间，并且必须是奇数。在值为3时，所有那些黑方块的对角线都会在接触到方块边界时被注册为角落。在值为23时，只有每个方块的角落会被检测为角落。
- en: 'Consider the following line:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下行：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, in places where a red mark in the corners is detected, tweaking the second
    parameter in `cornerHarris` will change this, that is, the smaller the value,
    the smaller the marks indicating corners.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，在检测到角落红色标记的地方，调整`cornerHarris`的第二个参数将改变这一点，也就是说，值越小，表示角落的标记就越小。
- en: 'Here''s the final result:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是最终的结果：
- en: '![Detecting features – corners](img/image00217.jpeg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![检测特征 – 角落](img/image00217.jpeg)'
- en: Great, we have corner points marked, and the result is meaningful at first glance;
    all the corners are marked in red.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了，我们已经标记了角落点，并且结果一目了然；所有的角落都用红色标记。
- en: Feature extraction and description using DoG and SIFT
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用DoG和SIFT进行特征提取和描述
- en: The preceding technique, which uses `cornerHarris`, is great to detect corners
    and has a distinct advantage because corners are corners; they are detected even
    if the image is rotated.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的技术，使用`cornerHarris`，非常适合检测角落，并且具有明显的优势，因为角落就是角落；即使图像被旋转，它们也能被检测到。
- en: However, if we reduce (or increase) the size of an image, some parts of the
    image may lose or even gain a corner quality.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们减小（或增加）图像的大小，图像的一些部分可能会失去或甚至获得角落的特性。
- en: 'For example, look at the following corner detections of the F1 Italian Grand
    Prix track:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，看看以下F1意大利大奖赛赛道角落的检测：
- en: '![Feature extraction and description using DoG and SIFT](img/image00218.jpeg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![使用DoG和SIFT进行特征提取和描述](img/image00218.jpeg)'
- en: 'Here''s a smaller version of the same screenshot:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是同一张截图的较小版本：
- en: '![Feature extraction and description using DoG and SIFT](img/image00219.jpeg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![使用DoG和SIFT进行特征提取和描述](img/image00219.jpeg)'
- en: You will notice how corners are a lot more condensed; however, we didn't only
    gain corners, we also lost some! In particular, look at the **Variante Ascari**
    chicane that squiggles at the end of the NW/SE straight part of the track. In
    the larger version of the image, both the entrance and the apex of the double
    bend were detected as corners. In the smaller image, the apex is not detected
    as such. The more we reduce the image, the more likely it is that we're going
    to lose the entrance to that chicane too.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到角落变得更加紧凑；然而，我们不仅获得了角落，还失去了一些！特别是，看看位于西北/东南直道末端的**Variante Ascari**弯道。在图像的大版本中，双弯道的入口和顶点都被检测为角落。在较小的图像中，顶点没有被检测为这样的角落。我们越减少图像的大小，就越有可能失去这个弯道的入口。
- en: 'This loss of features raises an issue; we need an algorithm that will work
    regardless of the scale of the image. Enter **SIFT**: while **Scale-Invariant
    Feature Transform** may sound a bit mysterious, now that we know what problem
    we''re trying to resolve, it actually makes sense. We need a function (a transform)
    that will detect features (a feature transform) and will not output different
    results depending on the scale of the image (a scale-invariant feature transform).
    Note that SIFT does not detect keypoints (which is done with Difference of Gaussians),
    but it describes the region surrounding them by means of a feature vector.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这种特征丢失引发了一个问题；我们需要一个无论图像尺度如何都能工作的算法。进入**SIFT**：虽然**尺度不变特征变换**可能听起来有点神秘，但既然我们知道我们正在尝试解决的问题，它实际上是有意义的。我们需要一个函数（一个变换），它将检测特征（一个特征变换）并且不会根据图像的尺度输出不同的结果（一个尺度不变特征变换）。请注意，SIFT不检测关键点（这是通过高斯差分完成的），而是通过特征向量描述它们周围区域。
- en: A quick introduction to **Difference of Gaussians** (**DoG**) is in order; we
    have already talked about low pass filters and blurring operations, specifically
    with the `cv2.GaussianBlur()` function. DoG is the result of different Gaussian
    filters applied to the same image. In [Chapter 3](part0023.xhtml#aid-LTSU1 "Chapter 3. Processing
    Images with OpenCV 3"), *Processing Images with OpenCV 3*, we applied this technique
    to compute a very efficient edge detection, and the idea is the same. The final
    result of a DoG operation contains areas of interest (keypoints), which are then
    going to be described through SIFT.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在对**高斯差分**（**DoG**）进行简要介绍；我们之前已经讨论了低通滤波器和模糊操作，特别是使用`cv2.GaussianBlur()`函数。DoG是将高斯滤波器应用于同一图像的结果。在[第3章](part0023.xhtml#aid-LTSU1
    "第3章。使用OpenCV 3处理图像")，*使用OpenCV 3处理图像*中，我们应用了这种技术来计算非常有效的边缘检测，其思想是相同的。DoG操作的最后结果包含感兴趣区域（关键点），然后通过SIFT对这些关键点进行描述。
- en: 'Let''s see how SIFT behaves in an image full of corners and features:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看SIFT在一个充满角和特征的图像中的表现：
- en: '![Feature extraction and description using DoG and SIFT](img/image00220.jpeg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![使用DoG和SIFT进行特征提取和描述](img/image00220.jpeg)'
- en: 'Now, the beautiful panorama of Varese (Lombardy, Italy) also gains a computer
    vision meaning. Here''s the code used to obtain this processed image:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，瓦雷泽（意大利伦巴第）美丽的全景也获得了计算机视觉的意义。以下是获取此处理图像所使用的代码：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'After the usual imports, we load the image that we want to process. To make
    this script generic, we will take the image path as a command-line argument using
    the `sys` module of Python:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在常规导入之后，我们加载我们想要处理的图像。为了使这个脚本通用，我们将使用Python的`sys`模块将图像路径作为命令行参数：
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We then turn the image into grayscale. At this stage, you may have gathered
    that most processing algorithms in Python need a grayscale feed in order to work.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将图像转换为灰度。在这个阶段，你可能已经注意到，Python中的大多数处理算法都需要灰度输入才能工作。
- en: 'The next step is to create a SIFT object and compute the grayscale image:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建一个SIFT对象并计算灰度图像：
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This is an interesting and important process; the SIFT object uses DoG to detect
    keypoints and computes a feature vector for the surrounding regions of each keypoint.
    As the name of the method clearly gives away, there are two main operations performed:
    detection and computation. The return value of the operation is a tuple containing
    keypoint information (keypoints) and the descriptor.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有趣且重要的过程；SIFT对象使用DoG来检测关键点并为每个关键点周围区域计算特征向量。正如方法名称清楚地表明的那样，这里执行了两个主要操作：检测和计算。操作的返回值是一个包含关键点信息（关键点）和描述符的元组。
- en: Finally, we process this image by drawing the keypoints on it and displaying
    it with the usual `imshow` function.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过在图像上绘制关键点并使用常规的`imshow`函数显示它来处理这个图像。
- en: 'Note that in the `drawKeypoints` function, we pass a flag that has a value
    of 4\. This is actually the `cv2` module property:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在`drawKeypoints`函数中，我们传递一个值为4的标志。这实际上是`cv2`模块属性：
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This code enables the drawing of circles and orientation of each keypoint.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码使得绘制圆圈和每个关键点的方向成为可能。
- en: Anatomy of a keypoint
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关键点的解剖结构
- en: 'Let''s take a quick look at the definition, from the OpenCV documentation,
    of the keypoint class:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速查看从OpenCV文档中获取的关键点类的定义：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Some properties are more self-explanatory than others, but let''s not take
    anything for granted and go through each one:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一些属性比其他属性更易于解释，但让我们不要想当然，而是逐一解释：
- en: The `pt` (point) property indicates the *x* and *y* coordinates of the keypoint
    in the image.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pt`（点）属性表示关键点在图像中的*x*和*y*坐标。'
- en: The `size` property indicates the diameter of the feature.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size`属性表示特征的直径。'
- en: The `angle` property indicates the orientation of the feature as shown in the
    preceding processed image.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`angle`属性表示特征的方向，如前述处理过的图像所示。'
- en: The `response` property indicates the strength of the keypoint. Some features
    are classified by SIFT as stronger than others, and `response` is the property
    you would check to evaluate the strength of a feature.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`response`属性表示关键点的强度。一些特征被SIFT分类为比其他特征更强，而`response`是您用来评估特征强度属性。'
- en: The `octave` property indicates the layer in the pyramid where the feature was
    found. To fully explain this property, we would need to write an entire chapter
    on it, so I will only introduce the basic concept. The SIFT algorithm operates
    in a similar fashion to face detection algorithms in that, it processes the same
    image sequentially but alters the parameters of the computation.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`octave`属性表示在金字塔中找到特征的层。要完全解释这个属性，我们需要写整整一章，所以这里我只介绍基本概念。SIFT算法的操作方式类似于人脸检测算法，即它按顺序处理相同的图像，但改变计算参数。'
- en: For example, the scale of the image and neighboring pixels are parameters that
    change at each iteration (`octave`) of the algorithm. So, the `octave` property
    indicates the layer at which the keypoint was detected.
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，图像的尺度以及相邻像素是算法每次迭代（`octave`）中变化的参数。因此，`octave`属性表示关键点被检测到的层。
- en: Finally, the object ID is the ID of the keypoint.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，对象ID是关键点的ID。
- en: Feature extraction and detection using Fast Hessian and SURF
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用快速Hessian和SURF进行特征提取和检测
- en: Computer vision is a relatively recent branch of computer science and many algorithms
    and techniques are of recent invention. SIFT is in fact only 16 years old, having
    been published by David Lowe in 1999.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉是计算机科学相对较新的一个分支，许多算法和技术都是最近发明的。实际上，SIFT只有16年的历史，由David Lowe于1999年发表。
- en: SURF is a feature detection algorithm published in 2006 by Herbert Bay, which
    is several times faster than SIFT, and it is partially inspired by it.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: SURF是由Herbert Bay于2006年发表的特征检测算法，比SIFT快几倍，并且部分受其启发。
- en: Note
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that both SIFT and SURF are patented algorithms and, for this reason, are
    made available in the `xfeatures2d` module of OpenCV.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，SIFT和SURF都是专利算法，因此它们被包含在OpenCV的`xfeatures2d`模块中。
- en: It is not particularly relevant to this book to understand how SURF works under
    the hood, as much as we can use it in our applications and make the best of it.
    What is important to understand is that SURF is an OpenCV class that operates
    keypoint detection with the Fast Hessian algorithm and extraction with SURF, much
    like the SIFT class in OpenCV operating keypoint detection with DoG and extraction
    with SIFT.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 理解SURF在底层是如何工作的，对我们这本书来说并不特别相关，因为我们可以在我们的应用中使用它，并充分利用它。重要的是要理解的是，SURF是一个OpenCV类，使用快速Hessian算法进行关键点检测，使用SURF进行提取，就像OpenCV中的SIFT类使用DoG进行关键点检测，使用SIFT进行提取一样。
- en: Also, the good news is that as a feature detection algorithm, the API of SURF
    does not differ from SIFT. Therefore, we can simply edit the previous script to
    dynamically choose a feature detection algorithm instead of rewriting the entire
    program.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，好消息是作为一个特征检测算法，SURF的API与SIFT没有区别。因此，我们可以简单地编辑之前的脚本，动态选择一个特征检测算法，而不是重写整个程序。
- en: 'As we only support two algorithms for now, there is no need to find a particularly
    elegant solution to the evaluation of the algorithm to be used and we''ll use
    the simple `if` blocks, as shown in the following code:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们现在只支持两种算法，因此没有必要为评估要使用的算法寻找特别优雅的解决方案，我们将使用简单的`if`块，如下面的代码所示：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here''s the result using SURF with a threshold:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用SURF和阈值的结果：
- en: '![Feature extraction and detection using Fast Hessian and SURF](img/image00221.jpeg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![使用快速Hessian和SURF进行特征提取和检测](img/image00221.jpeg)'
- en: 'This image has been obtained by processing it with a SURF algorithm using a
    Hessian threshold of 8000\. To be precise, I ran the following command:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图像是通过使用8000的Hessian阈值对它进行SURF算法处理获得的。更准确地说，我运行了以下命令：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The higher the threshold, the less features identified, so play around with
    the values until you reach an optimal detection. In the preceding case, you can
    clearly see how individual buildings are detected as features.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值越高，识别的特征越少，所以尝试调整这些值，直到达到最佳检测。在前面的例子中，你可以清楚地看到单个建筑物是如何被检测为特征的。
- en: In a process similar to the one we adopted in [Chapter 4](part0036.xhtml#aid-12AK81
    "Chapter 4. Depth Estimation and Segmentation"), *Depth Estimation and Segmentation*,
    when we were calculating disparity maps, try—as an exercise—to create a trackbar
    to feed the value of the Hessian threshold to the SURF instance, and see the number
    of features increase and decrease in an inversely proportional fashion.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在与我们在[第4章](part0036.xhtml#aid-12AK81 "第4章。深度估计与分割")中采用的过程类似的过程中，当我们计算视差图时，尝试——作为一个练习——创建一个滑块来将Hessian阈值值输入到SURF实例中，并观察特征数量以相反比例增加和减少。
- en: Now, let's examine corner detection with FAST, the BRIEF keypoint descriptor,
    and ORB (which uses the two) and put feature detection to good use.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们用FAST、BRIEF关键点描述符和ORB（它使用了这两个）来检查角点检测，并充分利用特征检测。
- en: ORB feature detection and feature matching
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ORB特征检测与特征匹配
- en: If SIFT is young, and SURF younger, ORB is in its infancy. ORB was first published
    in 2011 as a fast alternative to SIFT and SURF.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果SIFT是年轻的，SURF更年轻，那么ORB还处于婴儿期。ORB首次于2011年作为SIFT和SURF的快速替代方案发表。
- en: 'The algorithm was published in the paper, *ORB: an efficient alternative to
    SIFT or SURF*, and is available in the PDF format at [http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf](http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法发表在论文中，*ORB：SIFT或SURF的有效替代方案*，并以PDF格式在[http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf](http://www.vision.cs.chubu.ac.jp/CV-R/pdf/Rublee_iccv2011.pdf)提供。
- en: ORB mixes techniques used in the FAST keypoint detection and the BRIEF descriptor,
    so it is definitely worth taking a quick look at FAST and BRIEF first. We will
    then talk about Brute-Force matching—one of the algorithms used for feature matching—and
    show an example of feature matching.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ORB结合了FAST关键点检测和BRIEF描述符中使用的技巧，因此确实值得先快速查看FAST和BRIEF。然后我们将讨论暴力匹配——用于特征匹配的算法之一——并展示一个特征匹配的例子。
- en: FAST
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FAST
- en: The **Features from Accelerated Segment Test** (**FAST**) algorithm works in
    a clever way; it draws a circle around including 16 pixels. It then marks each
    pixel brighter or darker than a particular threshold compared to the center of
    the circle. A corner is defined by identifying a number of contiguous pixels marked
    as brighter or darker.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**加速分割测试（FAST**）算法以一种巧妙的方式进行工作；它在包括16个像素的周围画一个圆。然后，它将每个像素标记得比圆心亮或暗，与特定的阈值进行比较。一个角点通过识别被标记为亮或暗的连续像素的数量来定义。'
- en: 'FAST implements a high-speed test, which attempts at quickly skipping the whole
    16-pixel test. To understand how this test works, let''s take a look at this screenshot:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: FAST实现了一个高速测试，试图快速跳过整个16像素测试。为了理解这个测试是如何工作的，让我们看看这张截图：
- en: '![FAST](img/image00222.jpeg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![FAST](img/image00222.jpeg)'
- en: As you can see, three out of four of the test pixels (pixels number **1**, **9**,
    **5**, and **13**) must be within (or beyond) the threshold (and, therefore, marked
    as brighter or darker) and one must be in the opposite side of the threshold.
    If all four are marked as brighter or darker, or two are and two are not, the
    pixel is not a candidate corner.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，四个测试像素中的三个（像素编号**1**、**9**、**5**和**13**）必须在阈值（因此，被标记为亮或暗）内（或超出阈值）和一侧，而另一个必须在阈值另一侧。如果所有四个都被标记为亮或暗，或者两个被标记，两个未被标记，则该像素不是候选角点。
- en: FAST is an incredibly clever algorithm, but not devoid of weaknesses, and to
    compensate these weaknesses, developers analyzing images can implement a machine
    learning approach, feeding a set of images (relevant to your application) to the
    algorithm so that corner detection is optimized.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: FAST是一个非常巧妙的算法，但并非没有弱点，为了弥补这些弱点，分析图像的开发者可以实施机器学习方法，将一组图像（与您的应用相关）输入到算法中，以便优化角点检测。
- en: Despite this, FAST depends on a threshold, so the developer's input is always
    necessary (unlike SIFT).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，FAST仍然依赖于一个阈值，因此开发者的输入总是必要的（与SIFT不同）。
- en: BRIEF
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: BRIEF
- en: '**Binary** **Robust Independent Elementary Features** (**BRIEF**), on the other
    hand, is not a feature detection algorithm, but a descriptor. We have not yet
    explored this concept, so let''s explain what a descriptor is, and then look at
    BRIEF.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**二进制** **鲁棒独立基本特征**（**BRIEF**）另一方面，不是一个特征检测算法，而是一个描述符。我们尚未探讨这个概念，所以让我们解释一下什么是描述符，然后看看BRIEF。'
- en: 'You will notice that when we previously analyzed images with SIFT and SURF,
    the heart of the entire process is the call to the `detectAndCompute` function.
    This function operates two different steps: detection and computation, and they
    return two different results if coupled in a tuple.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，当我们之前使用SIFT和SURF分析图像时，整个过程的精髓是调用`detectAndCompute`函数。这个函数执行两个不同的步骤：检测和计算，如果将它们组合成一个元组，它们会返回两个不同的结果。
- en: The result of detection is a set of keypoints; the result of the computation
    is the descriptor. This means that the OpenCV's SIFT and SURF classes are both
    detectors and descriptors (although, remember that the original algorithms are
    not! OpenCV's SIFT is really DoG plus SIFT and OpenCV's SURF is really Fast Hessian
    plus SURF).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 检测的结果是一组关键点；计算的结果是描述符。这意味着OpenCV的SIFT和SURF类都是检测器和描述符（尽管，记住，原始算法不是！OpenCV的SIFT实际上是DoG加上SIFT，OpenCV的SURF实际上是快速Hessian加上SURF）。
- en: Keypoint descriptors are a representation of the image that serves as the gateway
    to feature matching because you can compare the keypoint descriptors of two images
    and find commonalities.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点描述符是图像的一种表示，它是特征匹配的门户，因为你可以比较两个图像的关键点描述符并找到共同点。
- en: BRIEF is one of the fastest descriptors currently available. The theory behind
    BRIEF is actually quite complicated, but suffice to say that BRIEF adopts a series
    of optimizations that make it a very good choice for feature matching.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: BRIEF是目前可用的最快的描述符之一。BRIEF背后的理论实际上相当复杂，但简单来说，BRIEF采用了一系列优化，使其成为特征匹配的一个非常好的选择。
- en: Brute-Force matching
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 强力匹配
- en: A Brute-Force matcher is a descriptor matcher that compares two descriptors
    and generates a result that is a list of matches. The reason why it's called Brute-Force
    is that there is little optimization involved in the algorithm; all the features
    in the first descriptor are compared to the features in the second descriptor,
    and each comparison is given a distance value and the best result is considered
    a match.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 强力匹配器是一种描述符匹配器，它比较两个描述符并生成一个结果，即匹配列表。之所以称为强力匹配器，是因为算法中涉及到的优化很少；第一个描述符中的所有特征都与第二个描述符中的特征进行比较，每个比较都给出一个距离值，最佳结果被认为是匹配。
- en: This is why it's called Brute-Force. In computing, the term, **brute-force**,
    is often associated with an approach that prioritizes the exhaustion of all possible
    combinations (for example, all the possible combinations of characters to crack
    a password) over some clever and convoluted algorithmical logic. OpenCV provides
    a `BFMatcher` object that does just that.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么它被称为强力匹配。在计算中，术语“强力匹配”通常与一种优先考虑穷尽所有可能组合（例如，破解密码的所有可能字符组合）的方法有关，而不是一些巧妙且复杂的算法逻辑。OpenCV提供了一个`BFMatcher`对象，它正是这样做的。
- en: Feature matching with ORB
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ORB进行特征匹配
- en: Now that we have a general idea of what FAST and BRIEF are, we can understand
    why the team behind ORB (at the time composed by Ethan Rublee, Vincent Rabaud,
    Kurt Konolige, and Gary R. Bradski) chose these two algorithms as a foundation
    for ORB.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对FAST和BRIEF有了大致的了解，我们可以理解为什么ORB背后的团队（当时由Ethan Rublee、Vincent Rabaud、Kurt
    Konolige和Gary R. Bradski组成）选择了这两个算法作为ORB的基础。
- en: 'In their paper, the authors aim at achieving the following results:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的论文中，作者旨在实现以下结果：
- en: The addition of a fast and accurate orientation component to FAST
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将快速且精确的定向组件添加到FAST中
- en: The efficient computation of oriented BRIEF features
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高效计算定向BRIEF特征
- en: Analysis of variance and correlation of oriented BRIEF features
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定向BRIEF特征的分析方差和相关性
- en: A learning method to decorrelate BRIEF features under rotational invariance,
    leading to better performance in nearest-neighbor applications.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种在旋转不变性下解相关BRIEF特征的学习方法，从而在最近邻应用中提高性能。
- en: Aside from very technical jargon, the main points are quite clear; ORB aims
    at optimizing and speeding up operations, including the very important step of
    utilizing BRIEF in a rotation-aware fashion so that matching is improved even
    in situations where a training image has a very different rotation to the query
    image.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 除了非常专业的术语之外，主要观点相当清晰；ORB旨在优化和加速操作，包括利用BRIEF的旋转感知方式，这样即使在训练图像与查询图像具有非常不同的旋转的情况下，匹配也可以得到改善。
- en: At this stage, though, I bet you have had enough of the theory and want to sink
    your teeth in some feature matching, so let's go look at some code.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在这个阶段，我敢打赌您已经对理论感到厌倦，并想要深入一些特征匹配，所以让我们看看一些代码。
- en: 'As an avid listener of music, the first example that comes to my mind is to
    get the logo of a band and match it to one of the band''s albums:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一位热衷的音乐听众，我首先想到的例子是获取乐队的标志并将其与该乐队的一张专辑进行匹配：
- en: '[PRE10]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Let's now examine this code step by step.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们一步一步地检查这段代码。
- en: After the usual imports, we load two images (the query image and the training
    image).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在常规导入之后，我们加载了两张图像（查询图像和训练图像）。
- en: 'Note that you have probably seen the loading of images with a second parameter
    with the value of 0 being passed. This is because `cv2.imread` takes a second
    parameter that can be one of the following flags:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，您可能已经看到使用第二个参数（值为0）加载图像。这是因为 `cv2.imread` 接受第二个参数，可以是以下标志之一：
- en: '[PRE11]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you can see, `cv2.IMREAD_GRAYSCALE` is equal to `0`, so you can pass the
    flag itself or its value; they are the same thing.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`cv2.IMREAD_GRAYSCALE` 等于 `0`，因此您可以传递标志本身或其值；它们是同一件事。
- en: 'This is the image we''ve loaded:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们加载的图像：
- en: '![Feature matching with ORB](img/image00223.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![ORB特征匹配](img/image00223.jpeg)'
- en: 'This is another image that we''ve loaded:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们加载的另一个图像：
- en: '![Feature matching with ORB](img/image00224.jpeg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![ORB特征匹配](img/image00224.jpeg)'
- en: 'Now, we proceed to creating the ORB feature detector and descriptor:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们继续创建ORB特征检测器和描述符：
- en: '[PRE12]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In a similar fashion to what we did with SIFT and SURF, we detect and compute
    the keypoints and descriptors for both images.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前对SIFT和SURF所做的方式类似，我们对两张图像都检测并计算了关键点和描述符。
- en: The theory at this point is pretty simple; iterate through the descriptors and
    determine whether they are a match or not, and then calculate the quality of this
    match (distance) and sort the matches so that we can display the top *n* matches
    with a degree of confidence that they are, in fact, matching features on both
    images.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，理论相当简单；遍历描述符并确定它们是否匹配，然后计算这个匹配的质量（距离）并排序匹配，这样我们就可以以一定的置信度显示前 *n* 个匹配，这些匹配实际上是在两张图像上的匹配特征。
- en: '`BFMatcher`, as described in Brute-Force matching, does this for us:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`BFMatcher`，如 brute-force matching 中所述，为我们做了这件事：'
- en: '[PRE13]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'At this stage, we already have all the information we need, but as computer
    vision enthusiasts, we place quite a bit of importance on visually representing
    data, so let''s draw these matches in a `matplotlib` chart:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们已经有所有需要的信息，但作为计算机视觉爱好者，我们非常重视数据的可视化表示，所以让我们在 `matplotlib` 图表中绘制这些匹配：
- en: '[PRE14]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The result is as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Feature matching with ORB](img/image00225.jpeg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![ORB特征匹配](img/image00225.jpeg)'
- en: Using K-Nearest Neighbors matching
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用K-最近邻匹配
- en: There are a number of algorithms that can be used to detect matches so that
    we can draw them. One of them is **K-Nearest Neighbors** (**KNN**). Using different
    algorithms for different tasks can be really beneficial, because each algorithm
    has strengths and weaknesses. Some may be more accurate than others, some may
    be faster or less computationally expensive, so it's up to you to decide which
    one to use, depending on the task at hand.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多算法可以用来检测匹配，以便我们可以绘制它们。其中之一是**K-最近邻**（**KNN**）。对于不同的任务使用不同的算法可能非常有益，因为每种算法都有其优势和劣势。有些可能比其他更准确，有些可能更快或计算成本更低，所以您需要根据手头的任务来决定使用哪个。
- en: For example, if you have hardware constraints, you may choose an algorithm that
    is less costly. If you're developing a real-time application, you may choose the
    fastest algorithm, regardless of how heavy it is on the processor or memory usage.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您有硬件限制，您可能选择成本较低的算法。如果您正在开发实时应用程序，您可能选择最快的算法，无论它对处理器或内存使用有多重。
- en: Among all the machine learning algorithms, KNN is probably the simplest, and
    while the theory behind it is interesting, it is well out of the scope of this
    book. Instead, we will simply show you how to use KNN in your application, which
    is not very different from the preceding example.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有机器学习算法中，KNN 可能是最简单的，尽管其背后的理论很有趣，但它超出了本书的范围。相反，我们将简单地展示如何在你的应用程序中使用 KNN，这与前一个例子没有太大区别。
- en: 'Crucially, the two points where the script differs to switch to KNN are in
    the way we calculate matches with the Brute-Force matcher, and the way we draw
    these matches. The preceding example, which has been edited to use KNN, looks
    like this:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 关键的是，将脚本切换到 KNN 的两个地方在于我们使用 Brute-Force 匹配器计算匹配的方式，以及我们绘制这些匹配的方式。经过编辑以使用 KNN
    的前一个例子看起来像这样：
- en: '[PRE15]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The final result is somewhat similar to the previous one, so what is the difference
    between `match` and `knnMatch`? The difference is that `match` returns best matches,
    while KNN returns *k* matches, giving the developer the option to further manipulate
    the matches obtained with `knnMatch`.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果与之前的一个相似，那么 `match` 和 `knnMatch` 之间的区别是什么？区别在于 `match` 返回最佳匹配，而 KNN 返回 *k*
    个匹配，这给了开发者进一步操作使用 `knnMatch` 获得的匹配项的选项。
- en: For example, you could iterate through the matches and apply a ratio test so
    that you can filter out matches that do not satisfy a user-defined condition.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以遍历匹配项并应用一个比率测试，这样你就可以过滤掉不满足用户定义条件的匹配项。
- en: FLANN-based matching
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于FLANN的匹配
- en: Finally, we are going to take a look at **Fast Library for Approximate Nearest
    Neighbors** (**FLANN**). The official Internet home of FLANN is at [http://www.cs.ubc.ca/research/flann/](http://www.cs.ubc.ca/research/flann/).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将看看**快速近似最近邻库**（**FLANN**）。FLANN 的官方互联网主页是[http://www.cs.ubc.ca/research/flann/](http://www.cs.ubc.ca/research/flann/)。
- en: Like ORB, FLANN has a more permissive license than SIFT or SURF, so you can
    freely use it in your project. Quoting the website of FLANN,
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 与 ORB 类似，FLANN 拥有比 SIFT 或 SURF 更宽松的许可证，因此你可以自由地在你的项目中使用它。引用 FLANN 的网站，
- en: '*"FLANN is a library for performing fast approximate nearest neighbor searches
    in high dimensional spaces. It contains a collection of algorithms we found to
    work best for nearest neighbor search and a system for automatically choosing
    the best algorithm and optimum parameters depending on the dataset.*'
  id: totrans-146
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"FLANN 是一个用于在高维空间中执行快速近似最近邻搜索的库。它包含了一组我们发现对最近邻搜索效果最好的算法，以及一个根据数据集自动选择最佳算法和最佳参数的系统。"*'
- en: ''
  id: totrans-147
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*FLANN is written in C++ and contains bindings for the following languages:
    C, MATLAB and Python."*'
  id: totrans-148
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*FLANN是用C++编写的，并为以下语言提供了绑定：C、MATLAB 和 Python。"*'
- en: In other words, FLANN possesses an internal mechanism that attempts at employing
    the best algorithm to process a dataset depending on the data itself. FLANN has
    been proven to be 10 times times faster than other nearest neighbors search software.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，FLANN 拥有内部机制，试图根据数据本身来采用最佳算法处理数据集。FLANN 已被证明比其他最近邻搜索软件快 10 倍。
- en: FLANN is even available on GitHub at [https://github.com/mariusmuja/flann](https://github.com/mariusmuja/flann).
    In my experience, I've found FLANN-based matching to be very accurate and fast
    as well as friendly to use.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: FLANN 甚至可以在 GitHub 上找到，地址是[https://github.com/mariusmuja/flann](https://github.com/mariusmuja/flann)。根据我的经验，我发现基于
    FLANN 的匹配非常准确、快速，并且易于使用。
- en: 'Let''s look at an example of FLANN-based feature matching:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个基于 FLANN 的特征匹配的例子：
- en: '[PRE16]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Some parts of the preceding script will be familiar to you at this stage (import
    of modules, image loading, and creation of a SIFT object).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，前一个脚本的一些部分可能对你来说很熟悉（模块导入、图像加载和创建 SIFT 对象）。
- en: Note
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The interesting part is the declaration of the FLANN matcher, which follows
    the documentation at [http://www.cs.ubc.ca/~mariusm/uploads/FLANN/flann_manual-1.6.pdf](http://www.cs.ubc.ca/~mariusm/uploads/FLANN/flann_manual-1.6.pdf).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 最有趣的部分是 FLANN 匹配器的声明，它遵循了[http://www.cs.ubc.ca/~mariusm/uploads/FLANN/flann_manual-1.6.pdf](http://www.cs.ubc.ca/~mariusm/uploads/FLANN/flann_manual-1.6.pdf)上的文档。
- en: 'We find that the FLANN matcher takes two parameters: an `indexParams` object
    and a `searchParams` object. These parameters, passed in a dictionary form in
    Python (and a struct in C++), determine the behavior of the index and search objects
    used internally by FLANN to compute the matches.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现 FLANN 匹配器接受两个参数：一个 `indexParams` 对象和一个 `searchParams` 对象。这些参数以字典形式传递给 Python（在
    C++ 中为 struct），并决定了 FLANN 内部使用的索引和搜索对象的行为。
- en: In this case, we could have chosen between `LinearIndex`, `KTreeIndex`, `KMeansIndex`,
    `CompositeIndex`, and `AutotuneIndex`, and we chose `KTreeIndex`. Why? This is
    because it's a simple enough index to configure (only requires the user to specify
    the number of kernel density trees to be processed; a good value is between 1
    and 16) and clever enough (the kd-trees are processed in parallel). The `searchParams`
    dictionary only contains one field (checks) that specifies the number of times
    an index tree should be traversed. The higher the value, the longer it takes to
    compute the matching, but it will also be more accurate.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以选择`LinearIndex`、`KTreeIndex`、`KMeansIndex`、`CompositeIndex`和`AutotuneIndex`，我们选择了`KTreeIndex`。为什么？这是因为它足够简单以便配置（只需要用户指定要处理的核密度树的数量；一个良好的值在1到16之间）并且足够聪明（kd树是并行处理的）。`searchParams`字典只包含一个字段（检查），它指定了索引树应该遍历的次数。值越高，匹配计算所需的时间越长，但也会更准确。
- en: In reality, a lot depends on the input that you feed the program with. I've
    found that 5 kd-trees and 50 checks always yield a respectably accurate result,
    while only taking a short time to complete.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实中，程序的结果很大程度上取决于你输入的数据。我发现使用5个kd树和50次检查通常能得到相当准确的结果，同时完成时间也很短。
- en: After the creation of the FLANN matcher and having created the matches array,
    matches are then filtered according to the test described by Lowe in his paper,
    *Distinctive Image Features from Scale-Invariant Keypoints*, available at [https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建FLANN匹配器和创建匹配数组之后，匹配将根据Lowe在其论文《Distinctive Image Features from Scale-Invariant
    Keypoints》中描述的测试进行过滤，该论文可在[https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)找到。
- en: In its chapter, *Application to object recognition*, Lowe explains that not
    all matches are "good" ones, and that filtering according to an arbitrary threshold
    would not yield good results all the time. Instead, Dr. Lowe explains,
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在其章节“应用于物体识别”中，Lowe解释说，并非所有匹配都是“好的”，并且根据任意阈值过滤并不总是能得到好的结果。相反，Lowe博士解释说，
- en: '*"The probability that a match is correct can be determined by taking the ratio
    of distance from the closest neighbor to the distance of the second closest."*'
  id: totrans-161
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"匹配正确的概率可以通过取最近邻距离与第二近邻距离的比值来确定。"* '
- en: In the preceding example, discarding any value with a distance greater than
    0.7 will result in just a few good matches being filtered out, while getting rid
    of around 90 percent of false matches.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，丢弃任何大于0.7距离的值将导致只有少数几个好的匹配被过滤掉，同时去除大约90%的误匹配。
- en: 'Let''s unveil the result of a practical example of FLANN. This is the query
    image that I''ve fed the script:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们揭示FLANN的一个实际例子的结果。这是我提供给脚本的查询图像：
- en: '![FLANN-based matching](img/image00226.jpeg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![基于FLANN的匹配](img/image00226.jpeg)'
- en: 'This is the training image:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这是训练图像：
- en: '![FLANN-based matching](img/image00227.jpeg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![基于FLANN的匹配](img/image00227.jpeg)'
- en: Here, you may notice that the image contains the query image at position (5,
    3) of this grid.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可能注意到图像中包含查询图像位于这个网格的(5, 3)位置。
- en: 'This is the FLANN processed result:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这是FLANN处理的结果：
- en: '![FLANN-based matching](img/image00228.jpeg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![基于FLANN的匹配](img/image00228.jpeg)'
- en: A perfect match!!
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 完美匹配！！
- en: FLANN matching with homography
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于单应性的FLANN匹配
- en: 'First of all, what is homography? Let''s read a definition from the Internet:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，什么是单应性？让我们从互联网上读一个定义：
- en: '*"A relation between two figures, such that to any point of the one corresponds
    one and but one point in the other, and vise versa. Thus, a tangent line rolling
    on a circle cuts two fixed tangents of the circle in two sets of points that are
    homographic."*'
  id: totrans-173
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"两个图形之间的关系，使得一个图形的任意一点对应另一个图形中的一个且仅有一个点，反之亦然。因此，在圆上滚动的切线切割圆的两个固定切线，形成两套同构点。"* '
- en: 'If you—like me—are none the wiser from the preceding definition, you will probably
    find this explanation a bit clearer: homography is a condition in which two figures
    find each other when one is a perspective distortion of the other.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你——像我一样——对前面的定义一无所知，你可能会发现这个解释更清晰：单应性是一种条件，其中两个图形在其中一个是对另一个的透视畸变时找到对方。
- en: 'Unlike all the previous examples, let''s first take a look at what we want
    to achieve so that we can fully understand what homography is. Then, we''ll go
    through the code. Here''s the final result:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有前面的例子不同，让我们首先看看我们想要实现什么，这样我们就可以完全理解单应性是什么。然后，我们将通过代码来解释。以下是最终结果：
- en: '![FLANN matching with homography](img/image00229.jpeg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![使用单应性的 FLANN 匹配](img/image00229.jpeg)'
- en: 'As you can see from the screenshot, we took a subject on the left, correctly
    identified in the image on the right-hand side, drew matching lines between keypoints,
    and even drew a white border showing the perspective deformation of the seed subject
    in the right-hand side of the image:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如从截图所示，我们在左侧取了一个主题，在右侧的图像中正确识别，在关键点之间绘制了匹配线，甚至绘制了一个白色边界，显示了右侧图像中种子主题的透视变形：
- en: '[PRE17]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: When compared to the previous FLANN-based matching example, the only difference
    (and this is where all the action happens) is in the `if` block.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的基于 FLANN 的匹配示例相比，唯一的区别（这也是所有动作发生的地方）在于 `if` 块中。
- en: 'Here''s what happens in this code step by step: firstly, we make sure that
    we have at least a certain number of good matches (the minimum required to compute
    a homography is four), which we will arbitrarily set at 10 (in real life, you
    would probably use a higher value than this):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是这个代码步骤的逐步过程：首先，我们确保至少有足够数量的良好匹配（计算单应性所需的最小数量是四个），我们将任意设置为 10（在现实生活中，你可能使用比这更高的值）：
- en: '[PRE18]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, we find the keypoints in the original image and the training image:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们在原始图像和训练图像中找到关键点：
- en: '[PRE19]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, we find the homography:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们找到单应性：
- en: '[PRE20]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Note that we create `matchesMask`, which will be used in the final drawing of
    the matches so that only points lying within the homography will have matching
    lines drawn.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们创建了 `matchesMask`，它将在最终绘制匹配时使用，这样只有位于单应性内的点才会绘制匹配线。
- en: 'At this stage, we simply have to calculate the perspective distortion of the
    original object into the second picture so that we can draw the border:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们只需计算原始物体到第二张图片的透视畸变，以便我们可以绘制边界：
- en: '[PRE21]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: And we then proceed to draw as per all our previous examples.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们继续按照所有之前的示例进行绘制。
- en: A sample application – tattoo forensics
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个示例应用 – 纹身法医
- en: Let's conclude this chapter with a real-life (or kind of) example. Imagine that
    you're working for the Gotham forensics department and you need to identify a
    tattoo. You have the original picture of the tattoo (imagine this coming from
    a CCTV footage) belonging to a criminal, but you don't know the identity of the
    person. However, you possess a database of tattoos, indexed with the name of the
    person to whom the tattoo belongs.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个真实（或类似）的例子来结束这一章。想象一下，你正在为哥谭市法医部门工作，你需要识别一个纹身。你有一张纹身的原始图片（想象一下这是来自监控录像的），属于一个罪犯，但你不知道这个人的身份。然而，你拥有一个纹身数据库，用纹身属于的人的名字进行索引。
- en: 'So, let''s divide the task in two parts: save image descriptors to files first,
    and then, scan these for matches against the picture we are using as a query image.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们将任务分为两部分：首先将图像描述符保存到文件中，然后，扫描这些文件以匹配我们用作查询图像的图片。
- en: Saving image descriptors to file
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将图像描述符保存到文件
- en: The first thing we will do is save image descriptors to an external file. This
    is so that we don't have to recreate the descriptors every time we want to scan
    two images for matches and homography.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要做的事情是将图像描述符保存到外部文件。这样我们就不必每次想要扫描两张图像以查找匹配和单应性时都重新创建描述符。
- en: In our application, we will scan a folder for images and create the corresponding
    descriptor files so that we have them readily available for future searches.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的应用中，我们将扫描一个文件夹中的图像，并创建相应的描述符文件，以便我们可以在未来的搜索中随时使用。
- en: 'To create descriptors and save them to a file, we will use a process we have
    used a number of times in this chapter, namely load an image, create a feature
    detector, detect, and compute:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建描述符并将它们保存到文件中，我们将使用在本章中多次使用的过程，即加载一个图像，创建一个特征检测器，检测，并计算：
- en: '[PRE22]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In this script, we pass the folder name where all our images are contained,
    and then create all the descriptor files in the same folder.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个脚本中，我们传递包含所有图像的文件夹名称，然后在同一文件夹中创建所有描述符文件。
- en: 'NumPy has a very handy `save()` utility, which dumps array data into a file
    in an optimized way. To generate the descriptors in the folder containing your
    script, run this command:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 有一个非常方便的 `save()` 工具，它以优化的方式将数组数据写入文件。要在包含你的脚本的文件夹中生成描述符，请运行此命令：
- en: '[PRE23]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note that `cPickle/pickle` are more popular libraries for Python object serialization.
    However, in this particular context, we are trying to limit ourselves to the usage
    of OpenCV and Python with NumPy and SciPy.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`cPickle/pickle` 是 Python 对象序列化的更受欢迎的库。然而，在这个特定的上下文中，我们试图将自己限制在仅使用 OpenCV
    和 Python 与 NumPy 和 SciPy 的使用上。
- en: Scanning for matches
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 扫描匹配
- en: Now that we have descriptors saved to files, all we need to do is to repeat
    the homography process on all the descriptors and find a potential match to our
    query image.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将描述符保存到文件中，我们只需要对所有描述符重复单应性过程，并找到与查询图像的潜在匹配。
- en: 'This is the process we will put in place:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将要实施的过程：
- en: Loading a query image and creating a descriptor for it (`tattoo_seed.jpg`)
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载一个查询图像并为它创建一个描述符（`tattoo_seed.jpg`）
- en: Scanning the folder with descriptors
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扫描包含描述符的文件夹
- en: For each descriptor, computing a FLANN-based match
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个描述符，计算基于FLANN的匹配
- en: If the number of matches is beyond an arbitrary threshold, including the file
    of potential culprits (remember we're investigating a crime)
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果匹配的数量超过一个任意的阈值，包括潜在的罪犯文件（记住我们正在调查犯罪）
- en: Of all the culprits, electing the one with the highest number of matches as
    the potential suspect
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有罪犯中，选择匹配数量最多的作为潜在嫌疑人
- en: 'Let''s inspect the code to achieve this:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查代码以实现这一点：
- en: '[PRE24]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: I saved this script as `scan_for_matches.py`. The only element of novelty in
    this script is the use of `numpy.load(filename)`, which loads an `npy` file into
    an `np` array.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我将这个脚本保存为`scan_for_matches.py`。这个脚本中唯一的新颖之处在于使用了`numpy.load(filename)`，它将一个`npy`文件加载到`np`数组中。
- en: 'Running the script produces the following output:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 运行脚本会产生以下输出：
- en: '[PRE25]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'If we were to represent this graphically, this is what we would see:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这个图形化表示，我们会看到如下：
- en: '![Scanning for matches](img/image00230.jpeg)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![扫描匹配](img/image00230.jpeg)'
- en: Summary
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about detecting features in images and extracting
    them into descriptors. We explored a number of algorithms available in OpenCV
    to accomplish this task, and then applied them to real-life scenarios to understand
    a real-world application of the concepts we explored.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了在图像中检测特征并将它们提取为描述符。我们探索了OpenCV中可用于完成此任务的多种算法，然后将它们应用于实际场景，以了解我们探索的概念在现实世界中的应用。
- en: We are now familiar with the concept of detecting features in an image (or a
    video frame), which is a good foundation for the next chapter.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在熟悉了在图像（或视频帧）中检测特征的概念，这是下一章的良好基础。
