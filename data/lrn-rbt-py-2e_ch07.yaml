- en: Interfacing Vision Sensors with ROS
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ROS与视觉传感器接口
- en: In the previous chapter, we looked at actuators and how to interface the robot's
    sensors using the Tiva-C LaunchPad board. In this chapter, we will mainly look
    at vision sensors and the interface that they use with our robot.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们探讨了执行器和如何使用Tiva-C LaunchPad板将机器人的传感器接口。在本章中，我们将主要探讨视觉传感器以及它们与我们的机器人使用的接口。
- en: The robot we are designing will have a 3D vision sensor, and we will be able
    to interface it with vision libraries such as **Open Source Computer Vision**
    (**OpenCV**), **Open Natural Interaction (OpenNI)**, and **Point Cloud Library**
    (**PCL**). The main application of the 3D vision sensor in our robot is autonomous
    navigation.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在设计的机器人将配备三维视觉传感器，我们将能够将其与如**开源计算机视觉**（OpenCV）、**开放自然交互（OpenNI**）和**点云库**（PCL）等视觉库接口。三维视觉传感器在我们机器人中的主要应用是自主导航。
- en: We will also look at how to interface the vision sensors with ROS and process
    the images that it senses using vision libraries such as OpenCV. In the last section
    of this chapter, we will look at the mapping and localization algorithm that we
    will use in our robot, called **SLAM** (**simultaneous localization and mapping**),
    and its implementation using a 3D vision sensor, ROS, and image-processing libraries.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将探讨如何将视觉传感器与ROS接口，并使用如OpenCV等视觉库处理其感知到的图像。在本章的最后部分，我们将探讨我们将用于机器人的映射和定位算法，称为**SLAM**（**同时定位与建图**），以及使用三维视觉传感器、ROS和图像处理库的实现。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: List of robotic vision sensors and image libraries
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人视觉传感器和图像库列表
- en: Introduction to OpenCV, OpenNI, and PCL
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV、OpenNI和PCL简介
- en: The ROS-OpenCV interface
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROS-OpenCV接口
- en: Point cloud processing using the PCL-ROS interface
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PCL-ROS接口进行点云处理
- en: Conversion of point cloud data to laser scan data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将点云数据转换为激光扫描数据
- en: Introduction to SLAM
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SLAM简介
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need an Ubuntu 16.04 system with ROS Kinetic installed, as well as
    a web camera and a depth camera in order to try out the example in this chapter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尝试本章中的示例，您需要一个安装了ROS Kinetic的Ubuntu 16.04系统，以及一个网络摄像头和一个深度摄像头。
- en: In the first section, we will look at the 2D and 3D vision sensors that are
    available in the market that can be used in different robots.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一部分，我们将探讨市场上可用的二维和三维视觉传感器，这些传感器可以用于不同的机器人。
- en: List of robotic vision sensors and image libraries
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器人视觉传感器和图像库列表
- en: A 2D vision sensor or an ordinary camera delivers 2D image frames of the surroundings,
    whereas a 3D vision sensor delivers 2D image frames and an additional parameter
    called the depth of each image point. We can find the *x*, *y*, and *z* distance
    of each point from the 3D sensor with respect to the sensor's axis.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 二维视觉传感器或普通摄像头提供周围环境的二维图像帧，而三维视觉传感器提供二维图像帧以及一个额外的参数，即每个图像点的深度。我们可以找到每个点相对于传感器轴的*x*、*y*和*z*距离。
- en: There are quite a few vision sensors available on the market. Some of the 2D
    and 3D vision sensors that can be used in our robot are mentioned in this chapter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 市场上有很多视觉传感器。本章中提到了一些可用于我们机器人的二维和三维视觉传感器。
- en: Pixy2/CMUcam5
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pixy2/CMUcam5
- en: 'The following picture shows the latest 2D vision sensor, called Pixy2/CMUcam5
    ([https://pixycam.com/pixy-cmucam5/](https://pixycam.com/pixy-cmucam5/)), which
    is able to detect color objects with high speed and accuracy, and can be interfaced
    with an Arduino board. Pixy can be used for fast object detection, and the user
    can teach it which object it needs to track. The Pixy module has a CMOS sensor
    and NXP LPC4330 ([http://www.nxp.com/](http://www.nxp.com/)) based on Arm Cortex
    M4/M0 cores for picture processing. The following image shows the Pixy/CMUcam5:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片展示了最新的二维视觉传感器，称为Pixy2/CMUcam5 ([https://pixycam.com/pixy-cmucam5/](https://pixycam.com/pixy-cmucam5/))，它能够以高速和精度检测颜色物体，并且可以与Arduino板接口。Pixy可用于快速目标检测，用户可以教会它需要跟踪的物体。Pixy模块具有基于Arm
    Cortex M4/M0核心的CMOS传感器和NXP LPC4330 ([http://www.nxp.com/](http://www.nxp.com/))，用于图像处理。以下图片展示了Pixy/CMUcam5：
- en: '![](img/451ea8e0-1fe5-48cf-9cec-ca024aa0fc3d.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/451ea8e0-1fe5-48cf-9cec-ca024aa0fc3d.jpg)'
- en: Pixy/CMUcam5 ([http://a.co/fZtPqck](http://a.co/1t91hn6))
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Pixy/CMUcam5 ([http://a.co/fZtPqck](http://a.co/1t91hn6))
- en: The most commonly available 2D vision sensors are webcams. They contain a CMOS
    sensor and USB interface, but they do not have any inbuilt vision-processing capabilities
    like Pixy has.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的2D视觉传感器是网络摄像头。它们包含一个CMOS传感器和USB接口，但它们没有像Pixy那样的内置视觉处理能力。
- en: Logitech C920 webcam
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Logitech C920网络摄像头
- en: 'The following picture shows a popular webcam from Logitech that can capture
    pictures of up to 5-megapixel resolution and HD videos:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片展示了一款来自Logitech的网络摄像头，可以捕捉高达500万像素的图片和高清视频：
- en: '![](img/caf46080-ba33-4b2b-a455-c740153411cd.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/caf46080-ba33-4b2b-a455-c740153411cd.png)'
- en: Logitech HD C920 webcam (http://a.co/02DUUYd)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Logitech HD C920网络摄像头 (http://a.co/02DUUYd)
- en: Kinect 360
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kinect 360
- en: We will now take a look at some of the 3D vision sensors available on the market.
    Some of the more popular sensors are Kinect, the Intel RealSense D400 series,
    and Orbbec Astra.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将查看市场上的一些3D视觉传感器。其中一些更受欢迎的传感器包括Kinect、英特尔RealSense D400系列和Orbbec Astra。
- en: '![](img/584c1ed3-0591-44d6-a5de-6e86baa35746.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/584c1ed3-0591-44d6-a5de-6e86baa35746.png)'
- en: Kinect sensor
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Kinect传感器
- en: Kinect is a 3D vision sensor originally developed for the Microsoft Xbox 360
    game console. It mainly contains an RGB camera, an infrared projector, an IR depth
    camera, a microphone array, and a motor to alter its tilt. The RGB camera and
    depth camera capture images at a resolution of 640 x 480 at 30 Hz. The RGB camera
    captures 2D color images, whereas the depth camera captures monochrome depth images.
    Kinect has a depth-sensing range of between 0.8 m and 4 m.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Kinect是一种最初为微软Xbox 360游戏机开发的3D视觉传感器。它主要包含一个RGB摄像头、一个红外投影仪、一个红外深度摄像头、一个麦克风阵列和一个用于改变其倾斜角度的电机。RGB摄像头和深度摄像头以640
    x 480的分辨率在30 Hz的频率下捕捉图像。RGB摄像头捕捉2D彩色图像，而深度摄像头捕捉单色深度图像。Kinect的深度感应范围在0.8米到4米之间。
- en: Some of the applications of Kinect are 3D motion capture, skeleton tracking,
    face recognition, and voice recognition.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Kinect的一些应用包括3D动作捕捉、骨骼追踪、面部识别和语音识别。
- en: Kinect can be interfaced with a PC using the USB 2.0 interface and programmed
    using Kinect SDK, OpenNI, and OpenCV. Kinect SDK is only available for Windows
    platforms, and SDK is developed and supplied by Microsoft. The other two libraries
    are open source and available for all platforms. The Kinect we are using here
    is the first version of Kinect; the latest versions of Kinect only support Kinect
    SDK when it is running on Windows (see [https://www.microsoft.com/en-us/download/details.aspx?id=40278](https://www.microsoft.com/en-us/download/details.aspx?id=40278)
    for more details).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Kinect可以通过USB 2.0接口与PC连接，并使用Kinect SDK、OpenNI和OpenCV进行编程。Kinect SDK仅适用于Windows平台，由微软开发和提供。其他两个库是开源的，适用于所有平台。我们这里使用的Kinect是第一代产品；Kinect的最新版本仅在Windows上运行时支持Kinect
    SDK（更多详情请见[https://www.microsoft.com/en-us/download/details.aspx?id=40278](https://www.microsoft.com/en-us/download/details.aspx?id=40278)）。
- en: The production of Kinect series sensors is discontinued, but you can still find
    the sensor on Amazon and eBay.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Kinect系列传感器的生产已经停止，但您仍然可以在亚马逊和eBay上找到该传感器。
- en: Intel RealSense D400 series
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Intel RealSense D400系列
- en: '![](img/d8bd3629-00ce-4fa3-9c73-77e997e8bc7a.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d8bd3629-00ce-4fa3-9c73-77e997e8bc7a.jpg)'
- en: Intel RealSense D400 series (https://realsense.intel.com/)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Intel RealSense D400系列 (https://realsense.intel.com/)
- en: The Intel RealSense D400 depth sensors are stereo cameras that come with an
    IR projector to enhance the depth data (see [https://software.intel.com/en-us/realsense/d400](https://software.intel.com/en-us/realsense/d400)
    for more details), as shown in Figure 4\. The more popular sensor models in the
    D400 series are D415 and D435\. In Figure 4, the sensor on the left is D415 and
    the sensor on the right is D435\. Each consists of a stereo camera pair, an RGB
    camera, and an IR projector. The stereo camera pair computes the depth of the
    environment with the help of the IR projector.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 英特尔RealSense D400深度传感器是带有红外投影仪的立体摄像头，用于增强深度数据（更多详情请见[https://software.intel.com/en-us/realsense/d400](https://software.intel.com/en-us/realsense/d400)），如图4所示。D400系列中更受欢迎的传感器型号是D415和D435。在图4中，左侧的传感器是D415，右侧的传感器是D435。每个都由一个立体摄像头对、一个RGB摄像头和一个红外投影仪组成。立体摄像头对在红外投影仪的帮助下计算环境的深度。
- en: The major features of this depth camera are that it can work in an indoor and
    outdoor environment. It can deliver the depth image stream with 1280 x 720 resolution
    at 90 fps, and the RGB camera can deliver a resolution of up to 1920 x 1080\.
    It has a USB-C interface, which enables fast data transfer between the sensor
    and the computer. It has a small form factor and is lightweight, which is ideal
    for a robotics vision application.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这款深度相机的特点是可以室内外环境工作。它可以在90 fps的帧率下提供1280 x 720分辨率的深度图像流，RGB相机可以提供高达1920 x 1080的分辨率。它具有USB-C接口，可以实现传感器和计算机之间快速的数据传输。它体积小，重量轻，非常适合机器人视觉应用。
- en: 'The applications of Kinect and Intel RealSense are the same, except for speech
    recognition. They will work in Windows, Linux, and Mac. We can develop applications
    by using ROS, OpenNI, and OpenCV. The following diagram shows the block diagram
    of the D400 series camera:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Kinect和Intel RealSense的应用相同，除了语音识别。它们将在Windows、Linux和Mac上工作。我们可以通过使用ROS、OpenNI和OpenCV来开发应用程序。以下图显示了D400系列相机的框图：
- en: '![](img/78da5af1-86a5-4c4b-a3b8-2a420ae33cb6.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/78da5af1-86a5-4c4b-a3b8-2a420ae33cb6.png）'
- en: Block diagram of the Intel RealSense D400 series
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Intel RealSense D400系列框图
- en: 'You can find the datasheet of the Intel RealSense series at the following link:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下链接找到英特尔RealSense系列的数据表：
- en: '[https://software.intel.com/sites/default/files/Intel_RealSense_Depth_Cam_D400_Series_Datasheet.pdf](https://software.intel.com/sites/default/files/Intel_RealSense_Depth_Cam_D400_Series_Datasheet.pdf)
    A research paper about Intel RealSense''s depth sensor can be found at the following
    link:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[英特尔RealSense深度摄像头D400系列数据表](https://software.intel.com/sites/default/files/Intel_RealSense_Depth_Cam_D400_Series_Datasheet.pdf)
    您可以在以下链接找到关于英特尔RealSense深度传感器的论文：'
- en: '[https://arxiv.org/abs/1705.05548](https://arxiv.org/abs/1705.05548) You can
    find the Intel RealSense SDK at the following link:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[英特尔RealSense SDK](https://arxiv.org/abs/1705.05548) 您可以在以下链接找到：'
- en: '[https://github.com/IntelRealSense/librealsense](https://github.com/IntelRealSense/librealsense)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[英特尔RealSense开源库](https://github.com/IntelRealSense/librealsense)'
- en: Orbbec Astra depth sensor
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Orbbec Astra深度传感器
- en: 'The new Orbbec Astra sensor is one of the alternatives to Kinect available
    on the market. It has similar specs compared to Kinect and uses similar technology
    to obtain depth information. Similar to Kinect, it has an IR projector, RGB camera,
    and IR sensor. It also comes with a microphone, which helps for voice recognition
    applications. The following image shows all parts of the Orbbec Astra depth sensor:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 新的Orbbec Astra传感器是市场上可用的Kinect替代品之一。它与Kinect具有相似的规格，并使用类似的技术获取深度信息。与Kinect类似，它具有红外投影仪、RGB相机和红外传感器。它还配备了麦克风，有助于语音识别应用。以下图像显示了Orbbec
    Astra深度传感器的所有部分：
- en: '![](img/d2d5d043-de46-472a-8b5c-94e6ecda1f28.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d2d5d043-de46-472a-8b5c-94e6ecda1f28.jpg)'
- en: Orbbec Astra depth sensor (https://orbbec3d.com/product-astra/)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Orbbec Astra深度传感器（https://orbbec3d.com/product-astra/）
- en: 'The Astra sensor comes in two models: Astra and Astra S. The main difference
    between these two models is the depth range. The Astra has a depth range of 0.6-8
    m, whereas the Astra S has a range of 0.4-2 m. The Astra S is best suited for
    3D scanning, whereas the Astra can be used in robotics applications. The size
    and weight of Astra is much lower than that of Kinect. These two models can both
    deliver depth data and an RGB image of 640 x 480 resolution at 30 fps. You can
    use a higher resolution, such as 1280 x 960, but it may reduce the frame rate.
    They also have the ability to track skeletons, like Kinect.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Astra传感器有两种型号：Astra和Astra S。这两种型号之间的主要区别是深度范围。Astra的深度范围为0.6-8米，而Astra S的范围为0.4-2米。Astra
    S非常适合3D扫描，而Astra可用于机器人应用。Astra的大小和重量远低于Kinect。这两种型号都可以在30 fps的帧率下提供640 x 480分辨率的深度数据和RGB图像。您可以使用更高分辨率，如1280
    x 960，但这可能会降低帧率。它们还具有跟踪骨骼的能力，就像Kinect一样。
- en: The sensor is compliant with the OpenNI framework, so an application built using
    OpenNI can also work using this sensor. We are going to use this sensor in our
    robot.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 该传感器符合OpenNI框架，因此使用OpenNI构建的应用程序也可以使用此传感器。我们打算在我们的机器人中使用这个传感器。
- en: The SDK is compatible with Windows, Linux, and Mac OS X. For more information,
    you can go to the sensor's development website at [https://orbbec3d.com/develop/](https://orbbec3d.com/develop/).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: SDK兼容Windows、Linux和Mac OS X。更多信息，您可以访问传感器的开发网站[https://orbbec3d.com/develop/](https://orbbec3d.com/develop/)。
- en: One of the sensors you can also refer to is the ZED Camera (https://www.stereolabs.com/zed/).
    It is a stereo vision camera system which can able to deliver high resolution
    with good frame rate.  The price is around 450 USD which is higher than above
    sensors. This can be used for high-end robotics applications required good accuracy
    from sensors.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以参考的传感器之一是ZED相机（https://www.stereolabs.com/zed/）。这是一个立体视觉相机系统，能够提供高分辨率和良好的帧率。价格大约450美元，高于上述传感器。这可以用于需要传感器有良好精度的高端机器人应用。
- en: We can see the ROS interfacing for this sensor in the upcoming section.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中看到这个传感器的ROS接口。
- en: Introduction to OpenCV, OpenNI, and PCL
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCV、OpenNI和PCL简介
- en: Let's look at the software frameworks and libraries that we will be using in
    our robots. First, let's look at OpenCV. This is one of the libraries that we
    are going to use in this robot for object detection and other image-processing
    capabilities.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们将在机器人中使用的软件框架和库。首先，让我们看看OpenCV。这是我们将在机器人中用于目标检测和其他图像处理功能的库之一。
- en: What is OpenCV?
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCV是什么？
- en: '**OpenCV** is an open source, BSD-licensed computer vision library that includes
    the implementations of hundreds of computer-vision algorithms. The library, mainly
    intended for real-time computer vision, was developed by Intel Russia''s research,
    and is now actively supported by Itseez ([https://github.com/Itseez](https://github.com/Itseez)).
    In 2016, Intel acquired Itseez.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**OpenCV**是一个开源的BSD许可的计算机视觉库，包括数百个计算机视觉算法的实现。这个库主要针对实时计算机视觉，由英特尔俄罗斯研究开发，现在由Itseez（[https://github.com/Itseez](https://github.com/Itseez)）积极支持。2016年，英特尔收购了Itseez。'
- en: OpenCV is written mainly in C and C++, and its primary interface is in C++.
    It also has good interfaces in Python, Java, and MATLAB/Octave, and also has wrappers
    in other languages (such as C# and Ruby).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV主要用C和C++编写，其主接口是C++。它也有很好的Python、Java和MATLAB/Octave接口，并且还有其他语言的包装器（如C#和Ruby）。
- en: In the latest version of OpenCV, there is support for CUDA and OpenCL to enable
    GPU acceleration ([http://www.nvidia.com/object/cuda_home_new.html](http://www.nvidia.com/object/cuda_home_new.html)).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV的最新版本中，支持CUDA和OpenCL以实现GPU加速（[http://www.nvidia.com/object/cuda_home_new.html](http://www.nvidia.com/object/cuda_home_new.html)）。
- en: OpenCV will run on most OS platforms (such as Windows, Linux, Mac OS X, Android,
    FreeBSD, OpenBSD, iOS, and BlackBerry).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV可以在大多数操作系统平台上运行（如Windows、Linux、Mac OS X、Android、FreeBSD、OpenBSD、iOS和BlackBerry）。
- en: In Ubuntu, OpenCV, the Python wrapper, and the ROS wrapper are already installed
    when we install the `ros-kinetic-desktop-full` or `ros-melodic-desktop-full` package.
    The following commands install the OpenCV-ROS package individually.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在Ubuntu上，当我们安装`ros-kinetic-desktop-full`或`ros-melodic-desktop-full`包时，OpenCV、Python包装器和ROS包装器已经安装好了。以下命令将单独安装OpenCV-ROS包。
- en: 'In Kinetic:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kinetic中：
- en: '[PRE0]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In Melodic:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在Melodic中：
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If you want to verify that the OpenCV-Python module is installed on your system,
    take a Linux Terminal, and enter the *python* command. You should then see the
    Python interpreter. Try to execute the following commands in the Python terminal
    to verify the OpenCV installation:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想验证OpenCV-Python模块是否已安装到您的系统上，请打开Linux终端，并输入*python*命令。然后您应该会看到Python解释器。尝试在Python终端中执行以下命令以验证OpenCV的安装：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If this command is successful, this version of OpenCV will be installed on your
    system. The version might be either 3.3.x or 3.2.x.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个命令成功执行，OpenCV的这个版本将会安装到您的系统上。版本可能是3.3.x或3.2.x。
- en: 'If you want to try OpenCV in Windows, you can try the following link:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想在Windows上尝试OpenCV，您可以尝试以下链接：
- en: '[https://docs.opencv.org/3.3.1/d5/de5/tutorial_py_setup_in_windows.html](https://docs.opencv.org/3.3.1/d5/de5/tutorial_py_setup_in_windows.html)
    The following link will guide you through the installation process of OpenCV on
    Mac OS X:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.opencv.org/3.3.1/d5/de5/tutorial_py_setup_in_windows.html](https://docs.opencv.org/3.3.1/d5/de5/tutorial_py_setup_in_windows.html)
    以下链接将指导您完成在Mac OS X上安装OpenCV的过程：'
- en: '[https://www.learnopencv.com/install-opencv3-on-macos/](https://www.learnopencv.com/install-opencv3-on-macos/)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.learnopencv.com/install-opencv3-on-macos/](https://www.learnopencv.com/install-opencv3-on-macos/)'
- en: 'The main applications of OpenCV are in the following fields:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV的主要应用领域如下：
- en: Object detection
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标检测
- en: Gesture recognition
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手势识别
- en: Human-computer interaction
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人机交互
- en: Mobile robotics
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动机器人
- en: Motion tracking
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运动跟踪
- en: Facial-recognition systems
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部识别系统
- en: Installation of OpenCV from the source code in Ubuntu
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Ubuntu上从源代码安装OpenCV
- en: The OpenCV installation can be customized. If you want to customize your OpenCV
    installation, you can try to install it from the source code. You can find out
    how to do this installation at [https://docs.opencv.org/trunk/d7/d9f/tutorial_linux_install.html](https://docs.opencv.org/trunk/d7/d9f/tutorial_linux_install.html).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 的安装可以自定义。如果你想自定义 OpenCV 的安装，你可以尝试从源代码安装它。你可以在 [https://docs.opencv.org/trunk/d7/d9f/tutorial_linux_install.html](https://docs.opencv.org/trunk/d7/d9f/tutorial_linux_install.html)
    找到如何进行此安装的说明。
- en: To work with the examples in this chapter, it's best that you work with OpenCV
    installed, along with ROS.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要与本章中的示例一起工作，最好是安装了 OpenCV 并与 ROS 一起使用。
- en: Reading and displaying an image using the Python-OpenCV interface
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python-OpenCV 接口读取和显示图像
- en: The first example will load an image in grayscale and display it on the screen.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个示例将加载一个灰度图像并在屏幕上显示。
- en: 'In the following section of code, we will import the `numpy` module for handling
    the image array. The `cv2` module is the OpenCV wrapper for Python, which we can
    use to access OpenCV Python APIs. NumPy is an extension to the Python programming
    language, adding support for large multidimensional arrays and matrices, along
    with a large library of high-level mathematical functions to operate on these
    arrays (see [https://pypi.python.org/pypi/numpy](https://pypi.python.org/pypi/numpy)
    for more information):'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码部分，我们将导入 `numpy` 模块来处理图像数组。`cv2` 模块是 OpenCV 的 Python 封装，我们可以使用它来访问 OpenCV
    的 Python API。NumPy 是 Python 编程语言的扩展，增加了对大型多维数组和矩阵的支持，以及一个用于操作这些数组的高级数学函数库（更多信息请见
    [https://pypi.python.org/pypi/numpy](https://pypi.python.org/pypi/numpy)）：
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following function will read the `robot.jpg` image and load this image
    in grayscale. The first argument of the `cv2.imread()` function is the name of
    the image and the next argument is a flag that specifies the color type of the
    loaded image. If the flag is greater than 0, the image returns a three-channel
    RGB color image; if the flag is 0, the loaded image will be a grayscale image;
    and if the flag is less than 0, it will return the same image as was loaded:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数将读取 `robot.jpg` 图像并将其以灰度形式加载。`cv2.imread()` 函数的第一个参数是图像的名称，下一个参数是一个标志，用于指定加载图像的颜色类型。如果标志大于
    0，则图像返回一个三通道 RGB 颜色图像；如果标志为 0，则加载的图像将是灰度图像；如果标志小于 0，则它将返回与加载的相同图像：
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following section of code will show the read image using the `imshow()`
    function. The `cv2.waitKey(0)` function is a keyboard-binding function. Its argument
    is time in milliseconds. If it''s 0, it will wait indefinitely for a key stroke:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码部分将使用 `imshow()` 函数显示读取的图像。`cv2.waitKey(0)` 函数是一个键盘绑定函数。它的参数是毫秒数。如果它是 0，它将无限期地等待按键：
- en: '[PRE5]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `cv2.destroyAllWindows()` function simply destroys all the windows we created:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv2.destroyAllWindows()` 函数简单地销毁我们创建的所有窗口：'
- en: '[PRE6]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Save the preceding code as `image_read.py` and copy a JPG file and name it
    `robot.jpg`. Execute the code using the following command:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 将前面的代码保存为 `image_read.py`，并复制一个 JPG 文件，命名为 `robot.jpg`。使用以下命令执行代码：
- en: '[PRE7]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output will load an image in grayscale because we used `0` as the value
    in the `imread()` function:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将加载一个灰度图像，因为我们使用了 `imread()` 函数中的 `0` 值：
- en: '![](img/6f9b4a8a-56d6-4dd0-a6ec-b1b088ce5844.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6f9b4a8a-56d6-4dd0-a6ec-b1b088ce5844.png)'
- en: Output of read image code
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 读取图像代码的输出
- en: The following example will try to use an open webcam. The program will quit
    when the user presses any button.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例将尝试使用一个打开的摄像头。当用户按下任何按钮时，程序将退出。
- en: Capturing from the web camera
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从网络摄像头捕获
- en: The following code will capture an image using the webcam with the device name
    `/dev/video0` or `/dev/video1`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将使用设备名称 `/dev/video0` 或 `/dev/video1` 的摄像头捕获图像。
- en: 'We need to import the *numpy* and *cv2* modules for capturing an image from
    a camera:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要导入 *numpy* 和 *cv2* 模块来从摄像头捕获图像：
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following function will create a `VideoCapture` object. The `VideoCapture`
    class is used to capture videos from video files or cameras. The initialization
    argument of the `VideoCapture` class is the index of a camera or the name of a
    video file. The device index is just a number that is used to specify the camera.
    The first camera index is 0, and has the device name `/dev/video0`-that''s why
    we will put `0` in the following code:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数将创建一个 `VideoCapture` 对象。`VideoCapture` 类用于从视频文件或摄像头捕获视频。`VideoCapture` 类的初始化参数是摄像头的索引或视频文件的名称。设备索引只是一个用于指定摄像头的数字。第一个摄像头索引是
    0，设备名称为 `/dev/video0`，这就是为什么我们在以下代码中会使用 `0`：
- en: '[PRE9]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following section of code is looped to read image frames from the `VideoCapture`
    object, and shows each frame. It will quit when any key is pressed:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码段是循环读取 `VideoCapture` 对象中的图像帧并显示每个帧。按下任何键时将退出：
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following is a screenshot of the program output:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个程序输出的截图：
- en: '![](img/8f0f6487-3d71-4b6f-afe4-c1ff2a195530.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f0f6487-3d71-4b6f-afe4-c1ff2a195530.png)'
- en: Output of the video capture
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 视频捕获输出
- en: You can explore more OpenCV-Python tutorials at
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下位置探索更多 OpenCV-Python 教程：
- en: '[http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_tutorials.html](http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_tutorials.html).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_tutorials.html](http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_tutorials.html)。'
- en: In the next section, we will look at the OpenNI library and its application.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨 OpenNI 库及其应用。
- en: What is OpenNI?
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenNI 是什么？
- en: OpenNI is a multilanguage, cross-platform framework that defines APIs in order
    to write applications using **natural interaction** (**NI**) (see [https://structure.io/openni](https://structure.io/openni)
    for more information). Natural interaction refers to the way in which people naturally
    communicate through gestures, expressions, and movements, and discover the world
    by looking around and manipulating physical objects and materials.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: OpenNI 是一个多语言、跨平台框架，它定义了 API 以便使用 **自然交互**（**NI**）编写应用程序（更多信息请参阅 [https://structure.io/openni](https://structure.io/openni)）。自然交互指的是人们通过手势、表情和动作自然地交流，通过四处张望和操作物理对象和材料来发现世界的方式。
- en: 'OpenNI APIs are composed of a set of interfaces that are used to write NI applications.
    The following figure shows a three-layered view of the OpenNI library:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: OpenNI API 由一组接口组成，用于编写 NI 应用程序。以下图显示了 OpenNI 库的三层视图：
- en: '![](img/6e270787-c408-45fc-ab89-7cc198e14a74.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6e270787-c408-45fc-ab89-7cc198e14a74.png)'
- en: OpenNI framework software architecture
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: OpenNI 框架软件架构
- en: The top layer represents the application layer that implements the natural interaction-based
    application. The middle layer is the OpenNI layer, and it will provide communication
    interfaces that interact with sensors and middleware components that analyze the
    data from the sensor. Middleware can be used for full-body analysis, hand-point
    analysis, gesture detection, and so on. One example of a middle layer component
    is NITE ([http://www.openni.ru/files/nite/index.html](http://www.openni.ru/files/nite/index.html)),
    which can detect gestures and skeletons.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 顶层代表实现基于自然交互的应用程序的应用层。中间层是 OpenNI 层，它将提供与传感器和中间件组件交互的通信接口，这些组件分析来自传感器的数据。中间件可用于全身分析、手势点分析、手势检测等。中间层组件的一个例子是
    NITE ([http://www.openni.ru/files/nite/index.html](http://www.openni.ru/files/nite/index.html))，它可以检测手势和骨骼。
- en: The bottom layer contains the hardware devices that capture the visual and audio
    elements of the scene. It can include 3D sensors, RGB cameras, IR cameras, and
    microphones.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 底层包含捕获场景视觉和音频元素的硬件设备。它可以包括 3D 传感器、RGB 摄像头、红外摄像头和麦克风。
- en: The latest version of OpenNI is OpenNI 2, which support sensors such as Asus
    Xtion Pro, and Primesense Carmine. The first version of OpenNI mainly supports
    the Kinect 360 sensor.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: OpenNI 的最新版本是 OpenNI 2，它支持 Asus Xtion Pro 和 Primesense Carmine 等传感器。OpenNI 的第一个版本主要支持
    Kinect 360 传感器。
- en: OpenNI is cross platform, and has been successfully compiled and deployed on
    Linux, Mac OS X, and Windows.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: OpenNI 是跨平台的，并且已经在 Linux、Mac OS X 和 Windows 上成功编译和部署。
- en: In the next section, we will see how we to install OpenNI in Ubuntu.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看到如何在 Ubuntu 中安装 OpenNI。
- en: Installing OpenNI in Ubuntu
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Ubuntu 中安装 OpenNI
- en: We can install the OpenNI library along with ROS packages. ROS is already interfaced
    with OpenNI, but the ROS desktop full installation may not install OpenNI packages;
    if so, we need to install it from the package manager.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以安装 OpenNI 库以及 ROS 软件包。ROS 已经与 OpenNI 接口，但 ROS 桌面完整安装可能不会安装 OpenNI 软件包；如果是这样，我们需要从软件包管理器中安装它。
- en: 'The following command will install the ROS-OpenNI library (which is mainly
    supported by the Kinect Xbox 360 sensor) in Kinetic and Melodic:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将在 Kinetic 和 Melodic 中安装 ROS-OpenNI 库（主要支持 Kinect Xbox 360 传感器）：
- en: '[PRE11]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following command will install the ROS-OpenNI 2 library (which is mainly
    supported by Asus Xtion Pro and Primesense Carmine):'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将安装 ROS-OpenNI 2 库（主要支持 Asus Xtion Pro 和 Primesense Carmine）：
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The source code and latest build of OpenNI for Windows, Linux, and MacOS X is
    available at [http://structure.io/openni](http://structure.io/openni).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: OpenNI的源代码和最新构建版本可在[http://structure.io/openni](http://structure.io/openni)获取。
- en: In the next section, we will look at how to install PCL.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何安装PCL。
- en: What is PCL?
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PCL是什么？
- en: A **point cloud** is a set of data points in space that represent a 3D object
    or an environment. Generally, a point cloud is generated from depth sensors, such
    as Kinect and LIDAR. PCL (Point Cloud Library) is a large scale, open project
    for 2D/3D images and point-cloud processing. The PCL framework contains numerous
    algorithms that perform filtering, feature estimation, surface reconstruction,
    registration, model fitting, and segmentation. Using these methods, we can process
    the point cloud, extract key descriptors to recognize objects in the world based
    on their geometric appearance, create surfaces from the point clouds, and visualize
    them.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**点云**是一组空间中的数据点，代表一个3D对象或环境。通常，点云是由深度传感器生成的，例如Kinect和LIDAR。PCL（点云库）是一个大规模、开源的项目，用于2D/3D图像和点云处理。PCL框架包含许多算法，执行过滤、特征估计、表面重建、配准、模型拟合和分割。使用这些方法，我们可以处理点云，提取关键描述符以根据其几何外观识别世界中的对象，从点云中创建表面，并可视化它们。'
- en: PCL is released under the BSD license. It's open source, free for commercial
    use, and free for research use. PCL is cross platform and has been successfully
    compiled and deployed on Linux, macOS X, Windows, and Android/iOS.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: PCL是在BSD许可下发布的。它是开源的，可用于商业用途，也可用于研究。PCL是跨平台的，并且已经在Linux、macOS X、Windows、Android/iOS上成功编译和部署。
- en: You can download PCL at [http://pointclouds.org/downloads/](http://pointclouds.org/downloads/).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[http://pointclouds.org/downloads/](http://pointclouds.org/downloads/)下载PCL。
- en: PCL is already integrated into ROS. The PCL library and its ROS interface are
    included in a ROS full desktop installation. PCL is the 3D-processing backbone
    of ROS. Refer to http://wiki.ros.org/pcl for details on the ROS-PCL package.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: PCL已经集成到ROS中。PCL库及其ROS接口包含在ROS完整桌面安装中。PCL是ROS的3D处理骨干。有关ROS-PCL包的详细信息，请参阅http://wiki.ros.org/pcl。
- en: Programming Kinect with Python using ROS, OpenCV, and OpenNI
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ROS、OpenCV和OpenNI用Python编程Kinect
- en: Let's look at how we can interface and work with the Kinect sensor in ROS. ROS
    is bundled with the OpenNI driver, which can fetch the RGB and depth image of
    Kinect. The OpenNI and OpenNI 2 package in ROS can be used for interfacing with
    Microsoft Kinect, Primesense Carmine, Asus Xtion Pro, and Pro Live.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何与ROS中的Kinect传感器接口和工作。ROS捆绑了OpenNI驱动程序，可以获取Kinect的RGB和深度图像。ROS中的OpenNI和OpenNI
    2包可用于与Microsoft Kinect、Primesense Carmine、Asus Xtion Pro和Pro Live接口。
- en: When we install ROS's `openni_launch` package, it will also install its dependent
    packages, such as `openni_camera`. The `openni_camera` package is the Kinect driver
    that publishes raw data and sensor information, whereas the `openni_launch` package
    contains ROS launch files. These launch files launch multiple nodes at a time
    and publish data such as the raw depth, RGB, and IR images, and the point cloud.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们安装ROS的`openni_launch`包时，它也会安装其依赖包，例如`openni_camera`。`openni_camera`包是Kinect驱动程序，发布原始数据和传感器信息，而`openni_launch`包包含ROS启动文件。这些启动文件一次启动多个节点，并发布原始深度、RGB和IR图像以及点云。
- en: How to launch the OpenNI driver
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何启动OpenNI驱动程序
- en: You can connect the Kinect sensor to your computer using a USB interface and
    make sure it is detected on your PC using the `dmesg` command in the terminal.
    After setting up Kinect, we can start ROS's OpenNI driver to get data from the
    device.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用USB接口将Kinect传感器连接到您的计算机，并确保在PC上使用终端中的`dmesg`命令检测到它。设置好Kinect后，我们可以启动ROS的OpenNI驱动程序以从设备获取数据。
- en: 'The following command will open the OpenNI device and load all nodelets (see
    [http://wiki.ros.org/nodelet](http://wiki.ros.org/nodelet) for more information)
    to convert raw depth/RGB/IR streams to depth images, disparity images, and point
    clouds. The ROS `nodelet` package is designed to provide a way to run multiple
    algorithms in the same process with zero copy transport between algorithms:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将打开OpenNI设备并加载所有节点（有关更多信息，请参阅[http://wiki.ros.org/nodelet](http://wiki.ros.org/nodelet)）以将原始深度/RGB/IR流转换为深度图像、视差图像和点云。ROS
    `nodelet`包旨在提供一种方式，在同一个进程中运行多个算法，并在算法之间实现零拷贝传输：
- en: '[PRE13]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'After starting the driver, you can list out the various topics published by
    the driver using the following command:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 启动驱动程序后，您可以使用以下命令列出驱动程序发布的各种主题：
- en: '[PRE14]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You can view the RGB image using a ROS tool called `image_view`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用名为 `image_view` 的 ROS 工具查看 RGB 图像：
- en: '[PRE15]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In the next section, we will learn how to interface these images with OpenCV
    for image processing.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习如何将这些图像与 OpenCV 进行接口连接以进行图像处理。
- en: The ROS interface with OpenCV
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ROS 与 OpenCV 的接口
- en: OpenCV is also integrated into ROS, mainly for image processing. The `vision_opencv`
    ROS stack includes the complete OpenCV library and the interface with ROS.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 也集成到 ROS 中，主要用于图像处理。`vision_opencv` ROS 栈包括完整的 OpenCV 库以及与 ROS 的接口。
- en: 'The `vision_opencv` meta package consists of individual packages:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`vision_opencv` 元包由单个包组成：'
- en: '`cv_bridge`: This contains the `CvBridge` class. This class converts ROS image
    messages to the OpenCV image data type and vice versa.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv_bridge`：这包含 `CvBridge` 类。此类可以将 ROS 图像消息转换为 OpenCV 图像数据类型，反之亦然。'
- en: '`image_geometry`: This contains a collection of methods to handle image and
    pixel geometry.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_geometry`：这包含了一组处理图像和像素几何的方法。'
- en: 'The following diagram shows how OpenCV is interfaced with ROS:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了 OpenCV 与 ROS 的接口：
- en: '![](img/46faa908-19fe-479d-a6e2-30d47d4c37bd.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/46faa908-19fe-479d-a6e2-30d47d4c37bd.png)'
- en: OpenCV-ROS interfacing
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV-ROS 接口
- en: The image data types of OpenCV are `IplImage` and `Mat`. If we want to work
    with OpenCV in ROS, we have to convert `IplImage` or `Mat` to ROS image messages.
    The ROS package `vision_opencv` has the `CvBridge` class; this class can convert
    `IplImage` to a ROS image and vice versa. Once we get the ROS image topics from
    any kind of vision sensor, we can use ROS CvBridge in order to convert it from
    ROS topic to Mat or IplImage format.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 的图像数据类型为 `IplImage` 和 `Mat`。如果我们想在 ROS 中使用 OpenCV，我们必须将 `IplImage` 或
    `Mat` 转换为 ROS 图像消息。ROS 包 `vision_opencv` 包含 `CvBridge` 类；此类可以将 `IplImage` 转换为
    ROS 图像，反之亦然。一旦我们从任何类型的视觉传感器获取 ROS 图像主题，我们就可以使用 ROS CvBridge 将其从 ROS 主题转换为 Mat
    或 IplImage 格式。
- en: The following section shows you how to create a ROS package; this package contains
    a node to subscribe to RGB and depth images, process RGB images to detect edges
    and display all images after converting them to an image type equivalent to OpenCV.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分将向您展示如何创建 ROS 包；此包包含一个节点，用于订阅 RGB 和深度图像，处理 RGB 图像以检测边缘，并在将它们转换为与 OpenCV
    相当的图像类型后显示所有图像。
- en: Creating a ROS package with OpenCV support
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 OpenCV 支持创建 ROS 包
- en: 'We can create a package called `sample_opencv_pkg` with the following dependencies:
    `sensor_msgs`, `cv_bridge`, `rospy`, and `std_msgs`. The `sensor_msgs` dependency
    defines ROS messages for commonly used sensors, including cameras and scanning-laser
    rangefinders. The `cv_bridge` dependency is the OpenCV interface of ROS.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下依赖项创建一个名为 `sample_opencv_pkg` 的包：`sensor_msgs`、`cv_bridge`、`rospy` 和
    `std_msgs`。`sensor_msgs` 依赖项定义了用于常用传感器的 ROS 消息，包括摄像头和扫描激光测距仪。`cv_bridge` 依赖项是
    ROS 的 OpenCV 接口。
- en: 'The following command will create the ROS package with the aforementioned dependencies:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将创建具有上述依赖项的 ROS 包：
- en: '[PRE16]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: After creating the package, create a `scripts` folder inside the package; we
    will use it as a location in which to save the code that will be mentioned in
    the next section.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 创建包后，在包内创建一个 `scripts` 文件夹；我们将将其用作保存下一节中提到的代码的位置。
- en: Displaying Kinect images using Python, ROS, and cv_bridge
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python、ROS 和 cv_bridge 显示 Kinect 图像
- en: 'The first section of the Python code is given in the following code fragment.
    It mainly involves importing `rospy`, `sys`, `cv2`, `sensor_msgs`, `cv_bridge,`
    and the `numpy` module. The `sensor_msgs` dependency imports the ROS data type
    of both image and camera information type. The `cv_bridge` module imports the
    `CvBridge` class for converting the ROS image data type to the OpenCV data type
    and vice versa:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Python 代码的第一部分在以下代码片段中给出。它主要涉及导入 `rospy`、`sys`、`cv2`、`sensor_msgs`、`cv_bridge`
    和 `numpy` 模块。`sensor_msgs` 依赖项导入了图像和相机信息类型的 ROS 数据类型。`cv_bridge` 模块导入了 `CvBridge`
    类，用于将 ROS 图像数据类型转换为 OpenCV 数据类型，反之亦然：
- en: '[PRE17]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following section of code is a class definition in Python that we will
    use to demonstrate `CvBridge` functions. The class is called `cvBridgeDemo`:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码段是 Python 中的一个类定义，我们将使用它来演示 `CvBridge` 函数。该类名为 `cvBridgeDemo`：
- en: '[PRE18]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here is the callback to visualize the actual RGB image, processed RGB image,
    and depth image:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是用于可视化实际 RGB 图像、处理后的 RGB 图像和深度图像的回调函数：
- en: '[PRE19]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following code gives a callback function of the color image from Kinect.
    When a color image is received on the `/camera/rgb/image_raw` topic, it will call
    this function. This function will process the color frame for edge detection and
    show the edge detected and the raw color image:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码给出了从Kinect获取彩色图像的回调函数。当在 `/camera/rgb/image_raw` 主题上接收到彩色图像时，它将调用此函数。此函数将处理彩色帧以进行边缘检测，并显示检测到的边缘和原始彩色图像：
- en: '[PRE20]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The following code gives a callback function of the depth image from Kinect.
    When a depth image is received on the `/camera/depth/raw_image` topic, it will
    call this function. This function will show the raw depth image:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码给出了从Kinect获取深度图像的回调函数。当在 `/camera/depth/raw_image` 主题上接收到深度图像时，它将调用此函数。此函数将显示原始深度图像：
- en: '[PRE21]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following function is called `process_image(),` and will convert the color
    image to grayscale, then blur the image, and find the edges using the canny edge
    filter:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数被命名为 `process_image()`，它将彩色图像转换为灰度图像，然后使用Canny边缘滤波器对图像进行模糊处理，并找到边缘：
- en: '[PRE22]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The following function is called `process_depth_image()`. It simply returns
    the depth frame:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数被命名为 `process_depth_image()`。它简单地返回深度帧：
- en: '[PRE23]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following function will close the image window when the node shuts down:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数会在节点关闭时关闭图像窗口：
- en: '[PRE24]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following code is the `main()` function. It will initialize the `cvBridgeDemo()`
    class and call the `rospy.spin()` function:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码是 `main()` 函数。它将初始化 `cvBridgeDemo()` 类并调用 `rospy.spin()` 函数：
- en: '[PRE25]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Save the preceding code as `cv_bridge_demo.py` and change the permission of
    the node using the following command. The nodes are only visible to the `rosrun`
    command if we give it executable permission:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 将前面的代码保存为 `cv_bridge_demo.py`，并使用以下命令更改节点的权限。只有当我们给予可执行权限时，节点才对 `rosrun` 命令可见：
- en: '[PRE26]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The following are the commands to start the driver and node. Start the Kinect
    driver using the following command:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是要启动驱动器和节点的命令。使用以下命令启动Kinect驱动器：
- en: '[PRE27]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Run the node using the following command:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令运行节点：
- en: '[PRE28]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The following is a screenshot of the output:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个输出截图：
- en: '![](img/feee3af4-7c2b-44cd-a94a-f9e951f1dfd3.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/feee3af4-7c2b-44cd-a94a-f9e951f1dfd3.png)'
- en: RGB, depth, and edge images
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: RGB、深度和边缘图像
- en: Interfacing Orbbec Astra with ROS
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Orbbec Astra与ROS接口
- en: One of the alternatives to Kinect is Orbbec Astra. There are ROS drivers available
    for Astra, and we can see how to set up that driver and get the image, depth,
    and point cloud from this sensor.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Kinect的替代方案之一是Orbbec Astra。Astra有可用的ROS驱动器，我们可以看到如何设置该驱动器并从该传感器获取图像、深度和点云。
- en: Installing the Astra–ROS driver
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Astra–ROS驱动器
- en: 'The complete instructions to set up the Astra-ROS driver in Ubuntu are mentioned
    at [https://github.com/orbbec/ros_astra_camera](https://github.com/orbbec/ros_astra_camera)
    and [http://wiki.ros.org/Sensors/OrbbecAstra](http://wiki.ros.org/Sensors/OrbbecAstra).
    After installing the driver, you can launch it using the following command:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在Ubuntu中设置Astra-ROS驱动器的完整说明可以在[https://github.com/orbbec/ros_astra_camera](https://github.com/orbbec/ros_astra_camera)和[http://wiki.ros.org/Sensors/OrbbecAstra](http://wiki.ros.org/Sensors/OrbbecAstra)找到。安装驱动器后，可以使用以下命令启动它：
- en: '[PRE29]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You can also install the Astra driver from the ROS package repository. Here
    is the command to install those packages:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以从ROS软件包仓库安装Astra驱动器。以下命令用于安装这些软件包：
- en: '[PRE30]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: After installing these packages, you have to set the permission of the device
    in order to work with the device, as described at [http://wiki.ros.org/astra_camera](http://wiki.ros.org/astra_camera).
    You can check the ROS topics that are generated from this driver using the `rostopic`
    list command in the terminal. In addition, we can use the same Python code for
    image processing that we mentioned in the previous section.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 安装这些软件包后，您必须设置设备的权限才能与设备一起工作，具体说明请参阅[http://wiki.ros.org/astra_camera](http://wiki.ros.org/astra_camera)。您可以使用终端中的
    `rostopic list` 命令检查由此驱动器生成的ROS主题。此外，我们可以使用与上一节中提到的相同Python代码进行图像处理。
- en: Working with point clouds using Kinect, ROS, OpenNI, and PCL
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kinect、ROS、OpenNI和PCL处理点云
- en: 'A 3D point cloud is a way of representing a 3D environment and 3D objects as
    collection points along the x, y, and z axes. We can get a point cloud from various
    sources: Either we can create our point cloud by writing a program or we can generate
    it from depth sensors or laser scanners.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 3D点云是将3D环境和3D对象作为沿x、y和z轴的点集合来表示的一种方式。我们可以从各种来源获取点云：要么通过编写程序创建我们的点云，要么从深度传感器或激光扫描仪生成它。
- en: PCL supports the OpenNI 3D interfaces natively; thus, it can acquire and process
    data from devices (such as Prime Sensor's 3D cameras, Microsoft Kinect, or Asus
    Xtion Pro).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: PCL 原生支持 OpenNI 3D 接口；因此，它可以从设备（如 Prime Sensor 的 3D 摄像头、Microsoft Kinect 或 Asus
    Xtion Pro）获取和处理数据。
- en: PCL will be included in the ROS full desktop installation. Let's see how we
    can generate and visualize a point cloud in RViz, a data visualization tool in
    ROS.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: PCL 将包含在 ROS 完整桌面安装中。让我们看看我们如何在 RViz 中生成和可视化点云，RViz 是 ROS 中的数据可视化工具。
- en: Opening the device and generating a point cloud
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 打开设备并生成点云
- en: 'Open a new terminal and launch the ROS-OpenNI driver, along with the point
    cloud generator nodes, using the following command:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 打开一个新的终端并使用以下命令启动 ROS-OpenNI 驱动程序，以及点云生成节点：
- en: '[PRE31]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This command will activate the Kinect driver and process the raw data into convenient
    outputs, such as a point cloud.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将激活 Kinect 驱动程序并将原始数据处理成方便的输出，例如点云。
- en: 'If you are using Orbbec Astra, you can use the following command:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用 Orbbec Astra，可以使用以下命令：
- en: '[PRE32]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We will use the RViz 3D visualization tool to view our point clouds.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 RViz 3D 可视化工具来查看我们的点云。
- en: 'The following command will start the RViz tool:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将启动 RViz 工具：
- en: '[PRE33]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Set the RViz options for Fixed Frame (at the top of the Displays panel under
    Global Options) to camera_link.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 将 RViz 的固定帧选项（在全局选项下的显示面板顶部）设置为 camera_link。
- en: From the left-hand side panel of the RViz panel, click on the Add button and
    choose the PointCloud2 display option. Set its topic to /camera/depth/points (this
    is the topic for Kinect; it will be different for other sensors)
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 从 RViz 面板的左侧面板中，点击添加按钮并选择 PointCloud2 显示选项。将其主题设置为 /camera/depth/points（这是 Kinect
    的主题；对于其他传感器将不同）
- en: Change the Color Transformer of PointCloud2 to AxisColor.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 将 PointCloud2 的颜色转换器更改为 AxisColor。
- en: 'The following screenshot shows a screenshot of the RViz point cloud data. You
    can see the nearest objects are marked in red and the farthest objects are marked
    in violet and blue. The objects in front of the Kinect are represented as a cylinder
    and cube:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了 RViz 点云数据的截图。你可以看到最近的对象用红色标记，最远的对象用紫色和蓝色标记。Kinect 前面的对象表示为圆柱体和立方体：
- en: '![](img/1639b5ac-df7e-4fee-932b-0eaf19437307.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1639b5ac-df7e-4fee-932b-0eaf19437307.png)'
- en: Visualizing point cloud data in Rviz
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Rviz 中可视化点云数据
- en: Conversion of point cloud data to laser scan data
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将点云数据转换为激光扫描数据
- en: We are using Astra in this robot to replicate the function of an expensive laser
    range scanner. The depth image is processed and converted to the data equivalent
    of a laser scanner using ROS's `depthimage_to_laserscan` package (see [http://wiki.ros.org/depthimage_to_laserscan](http://wiki.ros.org/depthimage_to_laserscan)
    for more information).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个机器人中，我们使用 Astra 来复制昂贵激光测距扫描仪的功能。深度图像通过 ROS 的 `depthimage_to_laserscan` 软件包（更多信息请参阅
    [http://wiki.ros.org/depthimage_to_laserscan](http://wiki.ros.org/depthimage_to_laserscan)）进行处理和转换为激光扫描器的数据等效。
- en: You can either install this package from the source code or use the Ubuntu package
    manager. Here is the command to install this package from the Ubuntu package manager
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从源代码安装此软件包，或者使用 Ubuntu 软件包管理器。以下是使用 Ubuntu 软件包管理器安装此软件包的命令
- en: '[PRE34]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The main function of this package is to slice a section of the depth image
    and convert it to an equivalent laser scan data type. The ROS `sensor_msgs/LaserScan`
    message type is used for publishing the laser scan data. This `depthimage_to_laserscan`
    package will perform this conversion and fake the laser scanner data. The laser
    scanner output can be viewed using RViz. In order to run the conversion, we have
    to start the convertor nodelets that will perform this operation. We have to specify
    this in our launch file in order to start the conversion. The following is the
    required code in the launch file to start the `depthimage_to_laserscan` conversion:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 此软件包的主要功能是切割深度图像的一部分并将其转换为等效的激光扫描数据类型。使用 ROS 的 `sensor_msgs/LaserScan` 消息类型发布激光扫描数据。此
    `depthimage_to_laserscan` 软件包将执行此转换并伪造激光扫描器数据。激光扫描器输出可以使用 RViz 查看。为了运行转换，我们必须启动执行此操作的转换器节点。我们必须在启动文件中指定此操作。以下是在启动文件中启动
    `depthimage_to_laserscan` 转换所需的代码：
- en: '[PRE35]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The topic of the depth image can be changed in each sensor; you have to change
    the topic name according to your depth image topic.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 深度图像的主题可以在每个传感器中更改；你必须根据你的深度图像主题更改主题名称。
- en: As well as starting the nodelet, we need to set certain parameters of the nodelet
    for better conversion. Refer to [http://wiki.ros.org/depthimage_to_laserscan](http://wiki.ros.org/depthimage_to_laserscan)
    for a detailed explanation of each parameter.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 除了启动节点外，我们还需要设置节点的一些参数以实现更好的转换。请参阅[http://wiki.ros.org/depthimage_to_laserscan](http://wiki.ros.org/depthimage_to_laserscan)以获取每个参数的详细说明。
- en: 'The laser scan of the preceding view is given in the following screenshot.
    To view the laser scan, add the LaserScan option. This is similar to how we add
    the PointCloud2 option and change the Topic value of LaserSan to /scan:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 前视的激光扫描在以下屏幕截图中给出。要查看激光扫描，请添加LaserScan选项。这与我们添加PointCloud2选项并更改LaserSan的主题值为/scan的方式相似：
- en: '![](img/c4b6ceac-d6d3-43eb-a6a8-91d112b6cf71.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c4b6ceac-d6d3-43eb-a6a8-91d112b6cf71.png)'
- en: Visualizing laser scan data in Rviz
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在Rviz中可视化激光扫描数据
- en: Working with SLAM using ROS and Kinect
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ROS和Kinect进行SLAM工作
- en: The main aim of deploying vision sensors in our robot is to detect objects and
    navigate the robot through an environment. SLAM is a algorithm that is used in
    mobile robots to build up a map of an unknown environment or update a map within
    a known environment by tracking the current location of the robot.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的机器人中部署视觉传感器的目的是检测物体并通过环境导航机器人。SLAM是一种在移动机器人中使用的算法，通过跟踪机器人的当前位置来构建未知环境的地图或更新已知环境中的地图。
- en: Maps are used to plan the robot's trajectory and to navigate through this path.
    Using maps, the robot will get an idea about the environment. The two main challenges
    in mobile robot navigation are mapping and localization.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 地图用于规划机器人的轨迹并导航通过此路径。使用地图，机器人将获得对环境的了解。移动机器人导航中的两个主要挑战是制图和定位。
- en: Mapping involves generating a profile of obstacles around the robot. Through
    mapping, the robot will understand what the world looks like. Localization is
    the process of estimating the position of the robot relative to the map we build.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 制图涉及生成机器人周围障碍物的轮廓。通过制图，机器人将了解世界是什么样的。定位是估计机器人相对于我们构建的地图的位置的过程。
- en: SLAM fetches data from different sensors and uses it to build maps. The 2D/3D
    vision sensor can be used to input data into SLAM. 2D vision sensors, such as
    web cameras, and 3D sensors, such as Kinect, are mainly used as inputs for the
    SLAM algorithm.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: SLAM从不同的传感器获取数据，并使用这些数据构建地图。2D/3D视觉传感器可以用于将数据输入到SLAM中。2D视觉传感器，如网络摄像头，和3D传感器，如Kinect，主要用于SLAM算法的输入。
- en: A SLAM library called OpenSlam ([http://openslam.org/gmapping.html](http://openslam.org/gmapping.html))
    is integrated with ROS as a package called gmapping. The `gmapping` package provides
    a node to perform laser-based SLAM processing, called `slam_gmapping`. This can
    create a 2D map from the laser and position data collected by the mobile robot.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 一个名为OpenSlam的SLAM库（[http://openslam.org/gmapping.html](http://openslam.org/gmapping.html)）与ROS集成作为一个名为gmapping的包。`gmapping`包提供了一个执行基于激光的SLAM处理的节点，称为`slam_gmapping`。这可以从移动机器人收集的激光和位置数据中创建一个2D地图。
- en: The `gmapping` package is available at [http://wiki.ros.org/gmapping](http://wiki.ros.org/gmapping).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '`gmapping`包可在[http://wiki.ros.org/gmapping](http://wiki.ros.org/gmapping)找到。'
- en: To use the `slam_gmapping` node, we have to input the odometry data of the robot
    and the laser scan output from the laser range finder, which is mounted horizontally
    on the robot.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`slam_gmapping`节点，我们必须输入机器人的里程计数据和激光测距仪从机器人上水平安装的激光扫描输出。
- en: The `slam_gmapping` node subscribes to the `sensor_msgs/LaserScan` messages
    and `nav_msgs/Odometry` messages to build the map (`nav_msgs/OccupancyGrid`).
    The generated map can be retrieved via a ROS topic or service.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '`slam_gmapping`节点订阅`sensor_msgs/LaserScan`消息和`nav_msgs/Odometry`消息以构建地图（`nav_msgs/OccupancyGrid`）。生成的地图可以通过ROS主题或服务检索。'
- en: 'We have used the following launch file to use SLAM in our Chefbot. This launch
    file launches the `slam_gmapping` node and contains the necessary parameters to
    start mapping the robot''s environment:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了以下启动文件在我们的Chefbot中使用SLAM。此启动文件启动了`slam_gmapping`节点，并包含启动制图机器人环境的必要参数：
- en: '[PRE36]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Summary
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we looked at the various vision sensors that can be used in
    Chefbot. We used Kinect and Astra in our robot and learned about OpenCV, OpenNI,
    PCL, and their application. We also discussed the role of vision sensors in robot
    navigation, the popular SLAM technique, and its application using ROS. In the
    next chapter, we will see the complete interfacing of the robot and learn how
    to perform autonomous navigation with our Chefbot.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了可用于Chefbot的各种视觉传感器。我们在机器人上使用了Kinect和Astra，并学习了OpenCV、OpenNI、PCL及其应用。我们还讨论了视觉传感器在机器人导航中的作用、流行的SLAM技术及其在ROS中的应用。在下一章中，我们将看到机器人的完整接口，并学习如何使用Chefbot进行自主导航。
- en: Questions
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are 3D sensors and how are they different from ordinary cameras?
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是3D传感器，它们与普通相机有何不同？
- en: What are the main features of ROS?
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ROS的主要特性有哪些？
- en: What are the applications of OpenCV, OpenNI, and PCL?
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenCV、OpenNI和PCL的应用有哪些？
- en: What is SLAM?
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是SLAM？
- en: What is RGB-D SLAM and how does it work?
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是RGB-D SLAM以及它是如何工作的？
- en: Further reading
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'You can read more about the robotic vision package in ROS at the following
    links:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下链接中了解更多关于ROS中的机器人视觉包的信息：
- en: '[http://wiki.ros.org/vision_opencv](http://wiki.ros.org/vision_opencv)'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://wiki.ros.org/vision_opencv](http://wiki.ros.org/vision_opencv)'
- en: '[http://wiki.ros.org/pcl](http://wiki.ros.org/pcl)'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://wiki.ros.org/pcl](http://wiki.ros.org/pcl)'
