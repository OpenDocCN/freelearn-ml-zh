- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Understanding the Most Common Machine Learning Attacks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解最常见的机器学习攻击
- en: When getting started with securing your projects, there are many things you
    can use to learn security techniques quickly. The best is the **MITRE ATT&CK framework**.
    As a globally recognized knowledge base, it contains valuable information about
    a range of attack techniques that an adversary can use to attack a system and
    their mitigations. In this chapter, we are going to explore the **MITRE ATLAS**
    framework. It is adapted from the MITRE ATT&CK framework for **machine** **learning**
    (**ML**).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当开始为你的项目进行安全加固时，你可以使用许多工具来快速学习安全技巧。其中最好的是**MITRE ATT&CK框架**。作为一个全球公认的知识库，它包含了关于各种攻击技术及其缓解措施的有价值信息，这些攻击技术是攻击者用来攻击系统的方式。在本章中，我们将探讨**MITRE
    ATLAS**框架。它是从MITRE ATT&CK框架中针对**机器学习**（**ML**）进行改编的。
- en: The goal of this chapter is to familiarize ourselves with the different stages
    of an attack and possible attacks on our system. This is essential because, with
    that knowledge, we can understand how an adversary thinks and how to protect our
    system. As there are multiple stages of an attack, you will understand why applying
    the Zero Trust strategy (covered in the previous chapter) is the most effective
    way to protect the system. We must never forget that this is an ongoing process
    as new vulnerabilities and exploits are released daily.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是让我们熟悉攻击的不同阶段以及对我们系统可能的攻击。这是至关重要的，因为有了这些知识，我们可以理解攻击者的思维方式以及如何保护我们的系统。由于攻击有多个阶段，你会明白为什么应用零信任策略（在上一章中介绍）是保护系统的最有效方法。我们必须永远记住，这是一个持续的过程，因为每天都有新的漏洞和利用被发布。
- en: We must always keep up to date with all new information, and the MITRE ATLAS
    framework will help us do exactly that. Finally, after exploring the MITRE ATLAS
    Matrix, we will cover the Azure services related to Azure Machine Learning and
    those most commonly affected by attacks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须始终跟上所有新的信息，MITRE ATLAS框架将帮助我们做到这一点。最后，在探索MITRE ATLAS矩阵之后，我们将涵盖与Azure机器学习相关的Azure服务以及那些最常受到攻击的服务。
- en: 'In this chapter, we’re going to cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introducing the MITRE ATLAS Matrix
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍MITRE ATLAS矩阵
- en: Understanding ML and AI attacks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解机器学习和人工智能攻击
- en: Exploring Azure services involved in ML attacks
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索涉及机器学习攻击的Azure服务
- en: By the end of this chapter, you will have a better understanding of ML attacks
    and their possible mitigations for ML.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将更好地理解机器学习攻击及其对机器学习的可能缓解措施。
- en: Introducing the MITRE ATLAS Matrix
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍MITRE ATLAS矩阵
- en: The MITRE ATT&CK framework is a globally recognized knowledge base and framework.
    Security professionals use it to understand and organize adversary behaviors in
    cyber threat environments. **ATT&CK**® (or ATTACK) stands for **Adversarial Tactics,
    Techniques, and Common Knowledge**. It is essentially a catalog of **tactics,
    techniques, and procedures** (**TTPs**) that adversaries use during different
    stages of a cyberattack. It covers many threat vectors, including initial access,
    execution, persistence, privilege escalation, defense evasion, credential access,
    discovery, lateral movement, collection, exfiltration, and impact.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: MITRE ATT&CK框架是一个全球公认的知识库和框架。安全专业人士使用它来理解和组织网络威胁环境中的攻击者行为。**ATT&CK**®（或ATTACK）代表**对抗性策略、技术和常见知识**。它本质上是一个目录，列出了攻击者在网络攻击的不同阶段使用的**策略、技术和程序**（**TTPs**）。它涵盖了包括初始访问、执行、持久性、权限提升、防御规避、凭证访问、发现、横向移动、收集、数据泄露和影响在内的许多威胁向量。
- en: The MITRE ATT&CK framework organizes these techniques into a matrix that classifies
    them based on the various stages of an attack and the platforms on which they
    are applicable (for example, Windows, macOS, or Linux). Each technique in the
    matrix is described in detail in the MITRE knowledge base, including information
    on how adversaries typically employ it and the potential defensive measures we
    can take to detect and prevent it.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: MITRE ATT&CK框架将这些技术组织成一个矩阵，根据攻击的各个阶段和它们适用的平台（例如，Windows、macOS或Linux）对它们进行分类。矩阵中的每种技术都在MITRE知识库中进行了详细描述，包括攻击者通常如何使用它以及我们可以采取的潜在防御措施来检测和预防它。
- en: Note
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If this is the first time you are hearing about the MITRE ATT&CK® framework,
    you can explore the MITRE ATT&CK® knowledge base at [https://attack.mitre.org/](https://attack.mitre.org/).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你第一次听说MITRE ATT&CK®框架，你可以探索MITRE ATT&CK®知识库，网址为[https://attack.mitre.org/](https://attack.mitre.org/)。
- en: (© 2023 The MITRE Corporation. This work is reproduced and distributed with
    the permission of The MITRE Corporation.)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: （© 2023 MITRE公司。本作品经MITRE公司许可复制和分发。）
- en: The framework has become a widely adopted industry standard. It is used by security
    teams, security solutions vendors, and organizations to enhance their threat intelligence,
    develop more effective security controls, and improve incident response capabilities.
    It enables organizations to align their defenses with real-world adversary behaviors,
    helping them proactively detect, respond to, and mitigate cyber threats.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架已成为广泛采用的行业标准。它被安全团队、安全解决方案供应商和组织使用，以增强他们的威胁情报、开发更有效的安全控制措施，并提高事件响应能力。它使组织能够将他们的防御与实际攻击者的行为对齐，帮助他们主动检测、响应和缓解网络威胁。
- en: 'Although very comprehensive, the MITRE ATT&CK framework might not cover all
    possible known attack methods, but it provides a great starting point. We are
    going to follow the MITRE ATLAS™ framework. **ATLAS** stands for **Adversarial
    Threat Landscape for Artificial-Intelligence Systems**, and it is a knowledge
    base of adversary tactics based on the MITRE ATT&CK framework and contains techniques
    that apply to ML and **artificial intelligence** (**AI**) systems. The ATLAS Matrix
    shows the progression of an attack in stages and the techniques associated with
    each stage. The stages can be seen in the following figure:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管非常全面，但MITRE ATT&CK框架可能并不涵盖所有已知的攻击方法，但它提供了一个很好的起点。我们将遵循MITRE ATLAS™框架。**ATLAS**代表**人工智能系统对抗威胁景观**，它是一个基于MITRE
    ATT&CK框架的对手战术知识库，包含适用于机器学习（ML）和**人工智能**（**AI**）系统的技术。ATLAS矩阵显示了攻击在各个阶段的进展以及与每个阶段相关的技术。阶段可以在以下图中看到：
- en: '![Figure 2.1 – The MITRE ATLAS stages](img/B21076_02_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图2.1 – MITRE ATLAS阶段](img/B21076_02_01.jpg)'
- en: Figure 2.1 – The MITRE ATLAS stages
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 – MITRE ATLAS阶段
- en: While the stages appear in sequence and they usually start from reconnaissance
    and end with impact techniques, not all stages and techniques will be used in
    an attack. It depends on the adversary’s goal and the system architecture.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然阶段看起来是按顺序出现的，并且通常从侦察开始，以影响技术结束，但并非所有阶段和技术都会在攻击中使用。这取决于攻击者的目标和系统架构。
- en: Let us understand each stage in the sections ahead.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在接下来的章节中理解每个阶段。
- en: Reconnaissance
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 侦察
- en: '**Reconnaissance** refers to the initial phase of an attack where an adversary
    gathers information about the target ML system. The goal of reconnaissance is
    to gather intelligence that can be used to identify potential vulnerabilities,
    plan the attack, and increase the chances of success. Information can be anything
    from the ML technologies used or research information that can help the adversary
    obtain relevant ML artifacts and tailor attacks to the victim in the next stages
    of the attack.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**侦察**指的是攻击的初始阶段，攻击者收集有关目标ML系统的信息。侦察的目标是收集可用于识别潜在漏洞、计划攻击并提高成功机会的情报。信息可以是ML技术、研究信息，这些信息可以帮助攻击者获取相关的ML工件，并在攻击的下一阶段针对受害者定制攻击。'
- en: Resource development
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源开发
- en: After the initial reconnaissance, the adversary is trying to discover resources
    they can use to support their endgame. This stage is called **resource development**
    and it is usually where the adversary purchases or steals resources to target
    ML artifacts, infrastructure, accounts, or capabilities that can be used later
    in the attack.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始侦察之后，攻击者试图发现他们可以利用的资源来支持他们的最终目标。这个阶段被称为**资源开发**，通常是在攻击者购买或窃取资源以针对ML工件、基础设施、账户或攻击后期可以使用的能力时。
- en: Initial access
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始访问
- en: In the **initial access** stage, the adversary attempts to access the ML system.
    That can be anything from networks to devices and platforms. If the adversary
    succeeds in this step, they can get an initial foothold in the system.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在**初始访问**阶段，攻击者试图访问ML系统。这可能包括网络、设备和平台等。如果攻击者在这一步成功，他们就可以在系统中获得一个初步的立足点。
- en: ML model access
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML模型访问
- en: After the adversary gains some form of access to the system, they will try to
    get further by gaining access to the ML model. The techniques used in the **ML
    model access** stage vary as the adversary can try to take advantage of many levels
    of access. They can target the database or technology that houses the data, or
    the endpoints used to train the ML model. The endpoint used for predictions or
    any other product or service that utilizes ML as part of its process is also vulnerable
    to attack.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在攻击者获得对系统的某种形式的访问后，他们将通过获取对机器学习模型的访问来进一步行动。在**机器学习模型访问**阶段使用的技术因攻击者可以利用多个访问级别而有所不同。他们可以针对存储数据的数据库或技术，或者用于训练机器学习模型的端点。用于预测或任何其他作为其流程一部分利用机器学习的产品或服务也容易受到攻击。
- en: Execution
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行
- en: In the **execution** stage, the adversary manages to run or embed malicious
    code or commands on a targeted system to achieve their objective. This tactic
    focuses on the actions taken by an adversary to execute their payloads or explore
    the network to steal more data or gain access to more systems. Remote access tools
    can be run here to run scripts and discover unpatched known vulnerabilities.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在**执行**阶段，攻击者设法在目标系统上运行或嵌入恶意代码或命令，以实现他们的目标。这种策略侧重于攻击者执行其有效载荷或探索网络以窃取更多数据或访问更多系统的行动。可以在此处运行远程访问工具来运行脚本并发现未修补的已知漏洞。
- en: Persistence
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 持久化
- en: In the **persistence** stage, the adversary tries to maintain whatever access
    they have gained in the previous steps. Techniques include but are not limited
    to elevating credentials, cutting off access to other users, and leaving behind
    modified data or models and backdoors so they can regain their access more easily
    if they are discovered.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在**持久化**阶段，攻击者试图维持他们在前一步骤中获得的任何访问权限。技术包括但不限于提升凭证、切断其他用户的访问权限，以及留下修改后的数据或模型和后门，以便他们在被发现时能够更容易地恢复访问。
- en: Defense evasion
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 防御规避
- en: Of course, no adversary wants to be discovered before accomplishing their goals.
    **Defense evasion** techniques are used by the adversary to avoid detection. Evading
    detection is something that an adversary can accomplish by turning off security
    features or software such as malware detectors.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，没有攻击者希望在完成目标之前被发现。攻击者使用**防御规避**技术来避免检测。规避检测是攻击者可以通过关闭安全功能或软件，如恶意软件检测器来实现的。
- en: Discovery
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现
- en: The **discovery** stage is like reconnaissance but from the inside. The adversary
    is trying to work out your ML environment. They are trying to gain knowledge about
    the system and internal network to broaden their goals or get as much information
    as possible before launching an attack. In this stage, the adversary will learn
    what they can or cannot control and what else they need to do based on their objective.
    Here, native operating system tools are often used to collect the information
    needed.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**发现**阶段就像侦察，但来自内部。攻击者试图了解你的机器学习环境。他们试图获取有关系统和内部网络的知识，以便在发起攻击之前扩大目标或获取尽可能多的信息。在这个阶段，攻击者将根据他们的目标了解他们可以或不能控制什么，以及他们还需要做什么。在这里，通常使用本地操作系统工具来收集所需的信息。'
- en: Collection
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 收集
- en: In the **collection** stage, all investigation and information-gathering processes
    are finished. The adversary is trying to actively collect data or ML artifacts.
    Suppose their goal is simply to disrupt the service. In that case, the techniques
    in this stage will help them collect everything they need to extract from the
    system before making the service unusable. Extraction is part of the exfiltration
    stage.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在**收集**阶段，所有调查和信息收集过程都已结束。攻击者试图积极收集数据或机器学习工件。假设他们的目标是简单地破坏服务，那么这个阶段的技术将帮助他们收集从系统中提取所需的一切，在使服务不可用之前。提取是外泄阶段的一部分。
- en: ML attack staging
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习攻击阶段
- en: For ML, data extraction or service disruption might not be the only goal of
    the adversary. In AI projects, attacks targeting the ML model can be deployed.
    **ML attack staging** techniques include training proxy models, poisoning the
    target model, and crafting adversarial data to feed the target model. Some of
    them can even be performed offline, so it would be difficult to mitigate in some
    cases.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习来说，数据提取或服务中断可能不是攻击者的唯一目标。在人工智能项目中，可以部署针对机器学习模型的攻击。**机器学习攻击阶段**技术包括训练代理模型、毒化目标模型以及制作对抗数据以供目标模型使用。其中一些甚至可以在离线状态下执行，因此在某些情况下可能难以缓解。
- en: Exfiltration
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 外泄
- en: The **exfiltration** stage would be where data or artifacts will be extracted.
    The adversary is trying to steal (exfiltrate) the ML artifacts or use the information
    for future operations. In this case, the most targeted sources are software repositories,
    container registries, model repositories, and object stores. This is a challenging
    process, as data needs to leave the network, creating traffic that can be detected.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**提取**阶段将是数据或证据将被提取的地方。攻击者试图窃取（提取）机器学习证据或使用这些信息进行未来的操作。在这种情况下，最被针对的来源是软件仓库、容器注册表、模型仓库和对象存储。这是一个具有挑战性的过程，因为数据需要离开网络，从而产生可以被检测到的流量。'
- en: Impact
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 影响
- en: The **impact** stage consists of techniques that disrupt or compromise the integrity
    of the system and possibly manipulate business processes. The adversary can target
    data and corrupt or destroy it. Even worse, data might be slightly changed; not
    enough to trigger suspicion in the system, but just enough to disrupt the services
    in a way that helps the adversary with their endgame or provides cover for a confidentiality
    breach.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**影响**阶段包括破坏或损害系统完整性的技术，以及可能操纵业务流程的技术。攻击者可以针对数据并对其进行篡改或破坏。更糟糕的是，数据可能略有变化；不足以在系统中引起怀疑，但足以以有助于攻击者的最终目标或为机密性泄露提供掩护的方式破坏服务。'
- en: As you can see, these stages form a logical path an adversary might take to
    attack your system. In reality, that might not be the case as the flow heavily
    depends on their goal. Let us see the techniques used in each stage and examples
    of how they might affect our systems.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这些阶段形成了一个攻击者可能采取的逻辑路径来攻击您的系统。在现实中，情况可能并非如此，因为流程很大程度上取决于他们的目标。让我们看看每个阶段使用的技术以及它们可能对我们系统造成的影响的例子。
- en: Understanding ML and AI attacks
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解机器学习和人工智能攻击
- en: All the stages mentioned in the previous section use multiple techniques to
    achieve each goal. The adversary can use these techniques alone, sequentially,
    or combined. Some attacks can be repeated and used in various stages for different
    purposes. It all depends on the adversary’s goal, which is why by applying Zero
    Trust principles and always verifying all levels of the system, we have a better
    chance of protecting our services or at least detecting an incident before it
    has time to do any extensive damage to the system.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节中提到的所有阶段都使用多种技术来实现每个目标。攻击者可以使用这些技术单独使用、顺序使用或组合使用。一些攻击可以重复使用，并在不同的阶段用于不同的目的。这完全取决于攻击者的目标，这就是为什么通过应用零信任原则并始终验证系统的所有级别，我们更有可能保护我们的服务，或者至少在攻击者有时间对系统造成任何重大损害之前检测到事件。
- en: Here, we will describe the most common AI and ML attacks per stage. We will
    also talk about attacks from the MITRE ATT&CK framework that, although not ML-specific,
    can be used to access systems that contain ML capabilities, among other things.
    Although we will outline the possible mitigations for each attack, we will go
    through the implementations in more detail in the following chapters.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将描述每个阶段最常见的AI和机器学习攻击。我们还将讨论来自MITRE ATT&CK框架的攻击，尽管它们不是针对机器学习的，但可以用来访问包含机器学习功能等的系统。虽然我们将概述每种攻击的可能缓解措施，但我们将在以下章节中更详细地介绍实现方法。
- en: Let us explore the attack techniques per stage.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索每个阶段的攻击技术。
- en: Reconnaissance techniques
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 侦察技术
- en: 'There are five reconnaissance techniques that aim to gather information about
    the system, as seen in the following figure:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有五种侦察技术旨在收集有关系统的信息，如下图所示：
- en: '![Figure 2.2 – Reconnaissance techniques](img/B21076_02_02.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2 – 侦察技术](img/B21076_02_02.jpg)'
- en: Figure 2.2 – Reconnaissance techniques
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – 侦察技术
- en: Let us understand each of these techniques in the following sections.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在以下章节中了解每种技术。
- en: Search for the victim’s publicly available information
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 搜索受害者的公开信息
- en: Suppose the organization uses open source model architectures that they have
    trained on additional proprietary data in production or that are in the research
    stage. In that case, they might publish system details with announcements or press
    releases. Although not technical, these might contain details about their model’s
    development and can help craft more realistic proxy models. To mitigate this,
    limit sharing information about the company’s systems, software stack, or frameworks
    used in developing systems when announcing deals or partnerships.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 假设该组织在生产中使用基于额外专有数据的开源模型架构，或者这些架构处于研究阶段。在这种情况下，他们可能会在公告或新闻稿中发布系统细节。尽管这些内容不是技术性的，但它们可能包含有关其模型发展的详细信息，并有助于构建更现实的代理模型。为了减轻这种情况，在宣布交易或合作时，限制分享有关公司系统、软件栈或用于开发系统的框架的信息。
- en: Search victim-owned websites and application repositories
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 搜索受害者拥有的网站和应用存储库
- en: Company websites may have a lot of information publicly available, including
    names of departments/divisions, physical locations, and data about key employees
    such as names, roles, and contact information. These sites may also have information
    that shows business operation details and relationships. The same goes for papers
    or technical blogs published by company employees. Employees are also vulnerable
    to social engineering attacks where the adversary poses as another employee to
    get company information. Ensure that you instruct employees not to share information
    about the projects they are working on—even with other employees if they are not
    working on the project—and anonymize the information they share on personal blogs
    or social media.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 公司网站可能公开了很多信息，包括部门/分部的名称、物理位置以及关于关键员工（如姓名、角色和联系方式）的数据。这些网站还可能包含显示业务运营细节和关系的资料。对于公司员工发布的论文或技术博客也是如此。员工也可能容易受到社会工程学攻击，攻击者冒充其他员工以获取公司信息。确保你指示员工不要分享他们正在工作的项目信息——即使他们不是项目成员——并在个人博客或社交媒体上匿名分享他们分享的信息。
- en: Finally, ML-enabled applications might be available in mobile stores such as
    Google Play, the iOS App Store, the macOS App Store, and the Microsoft Store.
    The adversary might attempt to scan and analyze the app for ML-related components
    or endpoints. Try to obfuscate the application code where possible and ensure
    you secure endpoints if information gets intercepted.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，机器学习应用可能可在移动商店中找到，如Google Play、iOS应用商店、macOS应用商店和Microsoft Store。攻击者可能会尝试扫描和分析应用程序以查找与机器学习相关的组件或端点。尽可能混淆应用程序代码，并在信息被截获时确保保护端点。
- en: Search for publicly available adversarial vulnerability analysis
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 搜索公开可用的对抗性漏洞分析
- en: As soon as the technology is identified, the adversary will research common
    system, model, or algorithm vulnerabilities to see whether they can use existing
    research to stage their attack. Identified vulnerabilities have implementations
    publicly available, making it easier for the adversary to gain initial access
    to the system and plan effectively.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了技术，攻击者将研究常见的系统、模型或算法漏洞，以查看他们是否可以使用现有研究来实施攻击。已识别的漏洞有公开可用的实现，这使得攻击者更容易获得系统的初始访问权限并有效规划攻击。
- en: Active scanning
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动扫描
- en: Active scanning is not a simple reconnaissance or information gathering. The
    adversary is actively probing the system to identify entry points or gather more
    actionable information. They can also be trying to determine whether the collected
    information is valid.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 活动扫描不仅仅是简单的侦察或信息收集。攻击者正在积极探测系统以识别入口点或收集更多可操作的信息。他们也可能试图确定收集到的信息是否有效。
- en: Resource development techniques
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源开发技术
- en: 'There are six techniques in this stage that usually exploit information gathered
    from the reconnaissance stage:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，通常有六种技术利用侦察阶段收集到的信息：
- en: '![Figure 2.3 – Resource development techniques](img/B21076_02_03.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图2.3 – 资源开发技术](img/B21076_02_03.jpg)'
- en: Figure 2.3 – Resource development techniques
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 – 资源开发技术
- en: Acquire public ML artifacts
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取公开的机器学习工件
- en: As soon as the adversary has identified some of the details of the system, this
    can help them launch attacks such as creating a proxy ML model or directly crafting
    adversarial data, which are attack techniques that we will talk about later in
    this chapter. Artifacts include the software stack used to train the model, algorithms,
    model deployments, and training and testing datasets. The artifacts can also be
    in development or testing environments. Suppose they contain some logic, algorithms,
    or techniques that the production model uses. In that case, they can also compromise
    the production environment. Ensure you protect development environments as well
    as production environments. Access to those artifacts might require access keys
    or authenticated requests and you might think that this is enough, but it is not.
    You need to ensure that you differentiate access methods for different environments
    and rotate access keys so that the adversary cannot use the initial access stage
    techniques to acquire access to multiple environments.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦攻击者确定了系统的某些细节，这可以帮助他们发起创建代理机器学习模型或直接制作对抗性数据的攻击，这些是我们将在本章后面讨论的攻击技术。这些工件包括用于训练模型的软件栈、算法、模型部署以及训练和测试数据集。这些工件也可以在开发或测试环境中。假设它们包含生产模型使用的某些逻辑、算法或技术，那么它们也可能危害生产环境。确保您同时保护开发环境和生产环境。访问这些工件可能需要访问密钥或经过身份验证的请求，您可能会认为这已经足够，但事实并非如此。您需要确保您为不同的环境区分访问方法，并定期更换访问密钥，这样攻击者就不能使用初始访问阶段的技术来获取对多个环境的访问权限。
- en: Obtain capabilities
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取能力
- en: Here, the adversary may search for and get software tools to support their operations.
    Software tools can be either malicious or repurposed for malicious intent. Any
    software can be used here, and this tool or software doesn’t need to be ML-enabled.
    For example, the adversary can use a virtual camera to add realistic effects to
    a feed to intercept an actual camera feed going into a system and gain access
    using deep fake technology.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，攻击者可能会搜索并获取支持其操作的软件工具。软件工具可以是恶意的，也可以被重新用于恶意目的。这里可以使用任何软件，并且这个工具或软件不需要是机器学习启用的。例如，攻击者可以使用虚拟摄像头为视频流添加逼真的效果，以拦截进入系统的实际摄像头流，并使用深度伪造技术获取访问权限。
- en: Deep fake technology
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造技术
- en: Deepfake technology is a way to manipulate or generate videos, images, and audio
    of people using deep learning techniques. The technology uses existing audio,
    video, or images of a person to generate new content in the likeness of that person.
    The technology is so powerful that the generated content is indistinguishable
    from a real recorded video or audio and, as a result, can be used for various
    malicious purposes such as fake news, unauthorized access to systems that use
    biometrics, and financial fraud.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造技术是一种利用深度学习技术操纵或生成人物视频、图像和音频的方法。该技术使用人物的现有音频、视频或图像来生成与该人物相似的新内容。这项技术非常强大，生成的内容与真实录制的视频或音频难以区分，因此可以用于各种恶意目的，如虚假新闻、未经授权访问使用生物识别技术的系统以及金融欺诈。
- en: Develop adversarial ML attack capabilities
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开发对抗性机器学习攻击能力
- en: As soon as the adversary has access to the system, or at least information about
    it, they may choose to develop their own attacks or implement ideas described
    in public research. Public research papers with existing libraries as a starting
    point are usually well documented and explain which vulnerabilities they exploit.
    You can use this information to protect your system, so it’s imperative not to
    share information publicly so that the adversary has a limited ability to tailor
    the attack on your system.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦攻击者获得了对系统的访问权限，或者至少获得了有关系统的信息，他们可能会选择开发自己的攻击或实施公开研究中的想法。以现有库作为起点的公开研究论文通常有很好的文档记录，并解释了它们利用哪些漏洞。您可以使用这些信息来保护您的系统，因此不公开分享信息至关重要，这样攻击者就难以针对您的系统定制攻击。
- en: Acquire infrastructure
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取基础设施
- en: The adversary might buy or lease infrastructure they will use throughout their
    operation. This infrastructure can include physical or cloud servers’ domains,
    devices, or services. Depending on the implementation, the adversary will make
    it difficult for you to discover their traffic in your network and they will try
    to blend in. They will probably use infrastructure that can be very quickly provisioned
    and then shut down. That means that even if you discover a suspicious endpoint
    and block it, that doesn’t mean you are safe, as the adversary might provision
    new infrastructure and try again. This is why it’s essential to always follow
    the best industry practices about security to prepare for any attack.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对手可能会购买或租赁在整个操作过程中将使用的基础设施。这些基础设施可以包括物理服务器或云服务器的域名、设备或服务。根据实施情况，对手将使您难以在您的网络中发现他们的流量，并且他们将试图融入其中。他们可能会使用可以非常快速提供和关闭的基础设施。这意味着即使您发现了一个可疑的端点并将其阻止，这并不意味着您就安全了，因为对手可能会提供新的基础设施并再次尝试。这就是为什么始终遵循关于安全的最佳行业实践来准备应对任何攻击至关重要。
- en: Publish poisoned datasets and poison training data
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发布受毒化的数据集和毒化训练数据
- en: When it comes to ML, everything is based on data. Poisoning the training data
    will change the results of the algorithm and the trained model. They can introduce
    vulnerabilities that cannot be easily detectable. The adversary may poison training
    data and publish it in a public location. It can be new data or a different version
    of an open source dataset. Always verify the source of any open source ML artifacts
    you use to train or update your model to protect against poisoned datasets. Staying
    away from public data is not the only thing you can do since data can be introduced
    into your system using the ML supply chain compromise attack, which we will highlight
    later in this chapter. Always validate that the data has not changed in the data
    sources; do not encrypt data or set the data sources as read-only or immutable
    if possible.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（ML）方面，一切都是基于数据的。毒化训练数据将改变算法的结果和训练模型。他们可以引入难以检测到的漏洞。对手可能会毒化训练数据并在公共位置发布。这可能是一份数据或开源数据集的不同版本。始终验证您用于训练或更新模型的任何开源机器学习（ML）工具的来源，以防止受毒化的数据集。远离公共数据不是您可以做的唯一事情，因为数据可以通过机器学习供应链攻击被引入您的系统，我们将在本章后面详细说明。始终验证数据源中的数据是否未发生变化；如果可能，不要加密数据或将数据源设置为只读或不可变。
- en: Establish accounts
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 建立账户
- en: The adversary may create accounts with many services that they can use to target
    your system and gain access to the resources they need. They might also impersonate
    someone from your organization, such as an employee, and use this to gain access
    to your systems. Always verify whom you are talking to about a project and train
    your employees accordingly. For example, if you get a message on LinkedIn from
    a coworker asking you to share access or reset their password for them, always
    verify their identity. Even if they use a company email, if this is not the proper
    process for resetting credentials or requesting access, direct them to follow
    the appropriate process because their account might be compromised. You could
    unknowingly share access information about the ML endpoint or training data with
    a third party.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对手可能会创建许多账户，他们可以使用这些账户针对您的系统并获取他们需要的资源。他们还可能冒充您组织中的某个人，比如员工，并利用这一点来获取对您系统的访问权限。始终验证您在讨论项目时与谁交谈，并相应地培训您的员工。例如，如果您在LinkedIn上收到一条来自同事的消息，要求您与他们分享访问权限或帮他们重置密码，请始终验证他们的身份。即使他们使用公司电子邮件，如果这不是重置凭据或请求访问的正确流程，请直接指导他们遵循适当的流程，因为他们的账户可能已被入侵。您可能无意中将有关机器学习端点或训练数据的访问信息与第三方共享。
- en: Initial access techniques
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始访问技术
- en: 'The adversary can use the following techniques to gain access to the system:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对手可以使用以下技术来获取系统访问权限：
- en: '![Figure 2.4 – Initial access techniques](img/B21076_02_04.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图2.4 – 初始访问技术](img/B21076_02_04.jpg)'
- en: Figure 2.4 – Initial access techniques
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 – 初始访问技术
- en: Let us understand each of these techniques in the following sections.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在以下各节中了解每种技术。
- en: ML supply chain compromise
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习供应链攻击
- en: With the ML supply chain compromise technique, the adversary is trying to gain
    access by compromising the unique parts of the ML supply chain. It usually includes
    hardware used to train the model, such as GPU hardware, data, parts of the software
    stack, or the model itself. When it comes to hardware, always verify that you
    have the latest updates and patches. When using open source libraries, always
    check the implementation of those algorithms. Any updates to the library should
    be checked for vulnerabilities or malicious code. Data can be poisoned, especially
    public data, and private datasets can be compromised during the labeling phase.
    If you are using a third-party service to label your data, make sure there are
    processes in place to protect against data poisoning. Also, keep versions of your
    datasets to compare any changes and identify issues if possible. If you’re using
    Azure Machine Learning, some capabilities can help you with that. Finally, if
    you are using open source models and fine-tuning them using your own private dataset,
    always verify the source of the model or the libraries, especially when updates
    are released. Every time you incorporate new models or execute unknown code, there
    is the possibility it is infected with traditional malware.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用机器学习供应链破坏技术，攻击者试图通过破坏机器学习供应链的独特部分来获取访问权限。这通常包括用于训练模型的硬件，如GPU硬件、数据、软件堆栈的部分或模型本身。当涉及到硬件时，始终要验证您拥有最新的更新和补丁。当使用开源库时，始终检查那些算法的实现。任何对库的更新都应该检查是否存在漏洞或恶意代码。数据可能会被毒化，尤其是公共数据，在标记阶段，私有数据集也可能受到破坏。如果您正在使用第三方服务来标记您的数据，请确保有防止数据毒化的流程。此外，保留数据集的版本以比较任何更改并尽可能识别问题。如果您正在使用Azure机器学习，一些功能可以帮助您做到这一点。最后，如果您正在使用开源模型并使用您自己的私有数据集对其进行微调，请始终验证模型或库的来源，尤其是在更新发布时。每次您整合新的模型或执行未知代码时，都存在其可能感染传统恶意软件的可能性。
- en: Valid accounts
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 有效账户
- en: In this case, the adversary may obtain valid credentials from existing accounts
    or API access keys. Especially when using Azure Machine Learning, leaked or stolen
    credentials may provide access to artifacts and allow the adversary to compromise
    them. We should be worried about two levels of access. The first is the user credentials
    and user accounts with access to the trained model or pipelines, and the second
    is the API keys for the inference model or pipeline.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，攻击者可能从现有账户或API访问密钥中获取有效凭证。特别是在使用Azure机器学习时，泄露或被盗的凭证可能提供对工件访问权限，并允许攻击者对其进行破坏。我们应该担心两个级别的访问权限。第一个是访问训练模型或管道的用户凭证和用户账户，第二个是推理模型或管道的API密钥。
- en: Evade ML model
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 避免机器学习模型
- en: Not all attacks are targeted at your ML project. An adversary can launch a craft
    adversarial data attack to prevent an ML model from correctly identifying data
    contents. This technique disrupts any task that relies on ML. Such tasks or processes
    can be, for example, ML-based malware detection software, network scanning software,
    or antivirus software that protects the system from traditional cyberattacks.
    Mitigations for this technique include model hardening to make ML models robust
    to specific inputs, behaviors, or atypical queries or using an ensemble of models
    for inference to increase robustness since an attack can be effective against
    one model type but not another.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有攻击都是针对您的机器学习项目的。攻击者可以发起精心设计的对抗性数据攻击，以防止机器学习模型正确识别数据内容。这种技术会干扰任何依赖于机器学习的任务。这些任务或流程可以是，例如，基于机器学习的恶意软件检测软件、网络扫描软件或保护系统免受传统网络攻击的杀毒软件。对此技术的缓解措施包括对模型进行加固，使其对特定输入、行为或异常查询具有鲁棒性，或者使用模型集成进行推理以增加鲁棒性，因为攻击可能对一种模型类型有效，而对另一种模型类型无效。
- en: Exploit public-facing applications
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 利用面向公众的应用程序
- en: While Azure provides many security features and complies with several industry-standard
    protocols for its services, the responsibility for protecting anything from ML
    to databases, public-facing applications, and internet-accessible endpoints (such
    as web servers) falls on the customer. So, when protecting your ML assets, you
    must think of all the related services using your model. In this book, we will
    talk a lot about security practices that have nothing to do with ML just because
    they apply to related services that use the ML environment, such as networks and
    applications.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Azure为其服务提供了许多安全功能，并符合多个行业标准协议，但从机器学习到数据库、面向公众的应用程序和互联网可访问的端点（如Web服务器）的保护责任落在客户身上。因此，在保护您的机器学习资产时，您必须考虑使用您模型的所有相关服务。在这本书中，我们将讨论许多与机器学习无关的安全实践，仅仅是因为它们适用于使用机器学习环境的相关服务，例如网络和应用。
- en: ML model access techniques
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习模型访问技术
- en: 'There are four techniques that can be leveraged to access your ML model:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 有四种技术可以用来访问您的机器学习模型：
- en: '![Figure 2.5 – ML model access techniques](img/B21076_02_05.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图2.5 – 机器学习模型访问技术](img/B21076_02_05.jpg)'
- en: Figure 2.5 – ML model access techniques
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 – 机器学习模型访问技术
- en: Let us review each of the ML model access techniques.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下每种机器学习模型访问技术。
- en: ML model inference API access
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习模型推理API访问
- en: The ML model inference API access technique refers to legitimate access to the
    inference API. The goal of creating models is to make predictions. More often
    than not, those predictions are leveraged from web applications. The way to accomplish
    this is to publish the model as a web API for use from the service. This API can
    provide an adversary with information about the model type or the data.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型推理API访问技术指的是对推理API的合法访问。创建模型的目标是进行预测。通常情况下，这些预测是从网络应用程序中利用的。实现这一目标的方法是将模型发布为Web
    API，以便从服务中使用。这个API可以为攻击者提供有关模型类型或数据的详细信息。
- en: Usually, models are retrained to learn based on input. That means if you are
    using the production environment to retrain and improve your model based on actual
    usage, ensure there is an approval process to check the data coming from public
    endpoints. Otherwise, an adversary can introduce false data to the system just
    by using the inference API.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，模型会重新训练以基于输入学习。这意味着如果您正在使用生产环境根据实际使用情况重新训练和改进您的模型，请确保有一个审批流程来检查来自公共端点的数据。否则，攻击者只需使用推理API就可以向系统中引入虚假数据。
- en: ML-enabled product or service
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习产品或服务
- en: Even if your API is not public, the service using it still contains some information
    about the model and its data. An application that has access to an inference endpoint
    still has to send some data to it, which may reveal details of the ML model in
    logs or metadata. Hijacking the application opens up the ML service, making it
    vulnerable to multiple attacks.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您的API不是公开的，使用它的服务仍然包含有关模型及其数据的一些信息。一个可以访问推理端点的应用程序仍然需要向其发送一些数据，这可能会在日志或元数据中泄露机器学习模型的详细信息。劫持应用程序会打开机器学习服务，使其容易受到多种攻击。
- en: Physical environment access
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 物理环境访问
- en: Attacks are not only digital. Suppose the model or the application interacting
    with the model uses real-world data somehow. In that case, the adversary can influence
    the model by accessing the environment where the data has been collected. For
    example, if you have an application that streams data from sensors or cameras
    by accessing the camera feed and poisoning it, the adversary can influence the
    model. Ensure that when you are using sensors, they are properly secured in their
    communication with any form of system and that there’s not a single point of failure
    in the hardware.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击不仅仅是数字上的。假设模型或与模型交互的应用程序以某种方式使用现实世界的数据。在这种情况下，攻击者可以通过访问数据收集的环境来影响模型。例如，如果您有一个通过访问相机流并对其进行投毒来从传感器或摄像头中流式传输数据的应用程序，攻击者可以影响模型。确保当您使用传感器时，它们在与任何形式的系统通信时都得到适当的保护，并且硬件中没有单点故障。
- en: Full ML model access
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 完整机器学习模型访问
- en: Sometimes, although it’s more secure to have the model in a centralized system
    and query it every time you need a prediction in real life, that’s not always
    sustainable or performant. You might be tempted to upload or repackage a mobile
    version of your model and add it to your edge device, such as your sensors or
    mobile device. While this might increase performance and provide faster predictions,
    this increases the attack surface area. If possible, consider uploading your model
    to the cloud with a single access point to reduce the attack surface area.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，尽管将模型放在集中式系统中并在需要实时预测时查询它更为安全，但这并不总是可持续或高效的。你可能会有上传或重新打包模型移动版本并将其添加到边缘设备（如传感器或移动设备）的诱惑。虽然这可能会提高性能并提供更快的预测，但这会增加攻击面。如果可能的话，考虑将模型上传到云中，并使用单一访问点以减少攻击面。
- en: Execution techniques
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行技术
- en: 'There are two execution techniques available, both of which rely on specific
    actions or scripts executed by a user or a tool:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种执行技术可用，这两种技术都依赖于用户或工具执行的特定操作或脚本：
- en: '![Figure 2.6 – Execution techniques](img/B21076_02_06.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图2.6 – 执行技术](img/B21076_02_06.jpg)'
- en: Figure 2.6 – Execution techniques
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6 – 执行技术
- en: Let us explore each of these techniques in the following sections.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在接下来的部分中探讨这些技术的每一个。
- en: User execution
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用户执行
- en: The adversary will usually rely on specific actions made by a legitimate user
    to gain execution. A system user may unknowingly execute unsafe code introduced
    by the ML supply chain compromise technique or social engineering. To mitigate
    this, train your users not to open suspicious or malicious links or documents
    from unknown sources. Part of the training should also be for checking the ML
    artifacts used throughout the ML process, as those can also be poisoned. Always
    check the checksum of the file or source and verify that it is secure and unchanged.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者通常会依赖合法用户采取的特定操作来获取执行权限。系统用户可能无意中执行了由机器学习供应链妥协技术或社会工程学引入的不安全代码。为了减轻这种风险，应培训用户不要打开来自未知来源的可疑或恶意链接或文档。培训的一部分也应包括检查整个机器学习过程中使用的机器学习工件，因为这些也可能被毒化。始终检查文件的校验和或来源，并验证其安全性以及是否未发生变化。
- en: Command and scripting interpreter
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 命令和脚本解释器
- en: Adversaries may use command and script interpreters to execute commands in the
    target system. Those interfaces provide many ways of interacting with the system,
    and it’s a standard feature of different technologies. Depending on the operating
    system, there are tools included. For example, in Windows, the Windows Command
    Shell and PowerShell can be exploited. There are also interpreters for programming
    languages such as Python. Commands and scripts can be embedded in payloads delivered
    to the target system as documents or downloaded from poisoned sources. Remote
    services can also be used.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者可能使用命令和脚本解释器在目标系统中执行命令。这些接口提供了许多与系统交互的方式，并且是不同技术的标准功能。根据操作系统，包含了一些工具。例如，在Windows中，Windows命令外壳和PowerShell可以被利用。还有Python等编程语言的解释器。命令和脚本可以嵌入到作为文档或从受毒化的来源下载的目标系统负载中。也可以使用远程服务。
- en: Persistence techniques
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 持久化技术
- en: 'Two persistent techniques are available, one of which we’ve already discussed
    in the *Resource development* section. The poison training data technique can
    be used to embed vulnerabilities or insert a backdoor trigger. Depending on the
    goal, this can be either a resource development or a persistence technique:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种持久化技术可用，其中一种我们在*资源开发*部分已经讨论过。毒化训练数据技术可以用来嵌入漏洞或插入后门触发器。根据目标，这可以是资源开发或持久化技术：
- en: '![Figure 2.7 – Persistence techniques](img/B21076_02_07.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图2.7 – 持久化技术](img/B21076_02_07.jpg)'
- en: Figure 2.7 – Persistence techniques
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7 – 持久化技术
- en: Backdoor ML model
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 后门机器学习模型
- en: The adversary can introduce a backdoor into the ML model based on other techniques,
    such as the poison training data technique. A model that includes a back door
    usually works as expected but will produce a different output when triggered by
    an input associated with a specific request from the adversary. This technique
    gives the adversary a persistent artifact on the system. The back door can be
    either a model response tailored to the input from the adversary or the invocation
    of an injected payload that bypasses the model and returns a different set of
    results.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者可以通过其他技术，如毒化训练数据技术，将后门引入基于机器学习（ML）的模型。包含后门的模型通常按预期工作，但在被与攻击者特定请求相关的输入触发时会产生不同的输出。这种技术为攻击者提供了系统上的持久性工件。后门可以是针对攻击者输入定制的模型响应，或者调用注入的有效载荷，绕过模型并返回不同的结果集。
- en: Defense evasion techniques
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 防御规避技术
- en: 'There’s only one defense evasion technique we’ve already discussed: the evade
    ML technique. It can also be used as an initial access technique, and after initial
    access has been granted, the adversary is not detected by any other software that
    might be using ML by disrupting its process.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过的唯一一种防御规避技术是规避机器学习技术。它也可以用作初始访问技术，一旦获得初始访问权限，攻击者就不会被任何可能使用机器学习的其他软件检测到，因为它会中断其进程。
- en: '![Figure 2.8 – Defense evasion techniques](img/B21076_02_08.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图2.8 – 防御规避技术](img/B21076_02_08.jpg)'
- en: Figure 2.8 – Defense evasion techniques
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 – 防御规避技术
- en: Discovery techniques
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现技术
- en: 'There are three discovery techniques that all target getting more information
    about the model, its ontology, its family, or the artifacts:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种发现技术，它们都旨在获取更多关于模型、其本体、其家族或其工件的信息：
- en: '![Figure 2.9 – Discovery techniques](img/B21076_02_09.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9 – 发现技术](img/B21076_02_09.jpg)'
- en: Figure 2.9 – Discovery techniques
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9 – 发现技术
- en: Let us explain these techniques in the following sections.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在接下来的章节中解释这些技术。
- en: Discover ML model ontology
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发现机器学习模型本体
- en: To discover the ontology of the ML model output, the adversary can analyze the
    types of objects the model can take as input. The ontology of the model can also
    be found in either documentation or configuration files. To mitigate against this,
    you can try obfuscating the model’s output and restricting the number of requests
    the user can make to a model. Usually, the adversary would have to create a large
    number of requests for the model to produce multiple outputs and get useful information
    from a range of results.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要发现机器学习模型输出的本体，攻击者可以分析模型可以接受的输入对象类型。模型的本体也可以在文档或配置文件中找到。为了减轻这种影响，您可以尝试混淆模型的输出并限制用户对模型发出的请求数量。通常，攻击者必须创建大量请求，以便模型产生多个输出，并从一系列结果中获取有用的信息。
- en: Discover the ML model family
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发现机器学习模型家族
- en: The adversary may use examples from the responses and outputs to discover the
    general family of the model. Ensure that the family of the model is not public
    information and cannot be easily guessed by the inputs and outputs of the model.
    Passive ML output obfuscation can be used here to mitigate this and restrict the
    number of requests a user or application can make to the model in a specific amount
    of time. Anything you can do to limit knowledge about the model can make it more
    difficult for the adversary to tailor an attack to your individual technology
    or model family.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者可能使用响应和输出的示例来发现模型的通用家族。确保模型的家族不是公开信息，并且不能通过模型的输入和输出轻易猜测。被动机器学习输出混淆可以用来减轻这种情况，并限制用户或应用程序在特定时间内对模型发出的请求数量。您能做的任何限制模型知识的事情都会使攻击者更难针对您的特定技术或模型家族定制攻击。
- en: Discover ML artifacts
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发现机器学习工件
- en: At any point, the adversary will try to discover the private or public artifacts
    you are using in your model. This process usually starts in the resource development
    stage, but in this stage, we focus more on private ML artifacts. To mitigate this,
    collect and secure any artifacts, such as the software stack, testing and training
    data, data management systems, container registries, and software repositories.
    Encrypt sensitive information and systems where possible. Azure provides the management
    of encryption not only in data but also in whole services, such as Azure storage
    accounts.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何时刻，攻击者都会试图发现你在模型中使用的是私有或公共工件。这个过程通常从资源开发阶段开始，但在这个阶段，我们更关注私有ML工件。为了减轻这种情况，收集并保护任何工件，例如软件栈、测试和训练数据、数据管理系统、容器注册表和软件存储库。尽可能对敏感信息和系统进行加密。Azure不仅提供数据加密管理，还提供整个服务（如Azure存储账户）的加密管理。
- en: Collection techniques
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 收集技术
- en: 'In the collection stage, we have three techniques that focus on data collection:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在收集阶段，我们有三种专注于数据收集的技术：
- en: '![Figure 2.10 – Collection techniques](img/B21076_02_10.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图2.10 – 收集技术](img/B21076_02_10.jpg)'
- en: Figure 2.10 – Collection techniques
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10 – 收集技术
- en: ML artifact collection
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习工件收集
- en: The adversary might collect any useful data or company information for exfiltration
    as soon as the artifacts are identified. Suppose the adversary’s goal is not to
    disrupt the service but to gather information, such as proprietary data, by using
    your models and datasets. In that case, the adversary will be interested in getting
    as many ML artifacts as possible. Encryption of sensitive information at rest
    and in transit will help mitigate this to some extent because even if the adversary
    collects data, they won’t be able to read or use it.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦识别出工件，攻击者可能会立即收集任何有用的数据或公司信息以进行泄露。假设攻击者的目标不是破坏服务，而是通过使用你的模型和数据集来收集信息，例如专有数据。在这种情况下，攻击者将尽可能多地获取ML工件。在静态和传输中的敏感信息加密可以在一定程度上减轻这种情况，因为即使攻击者收集了数据，他们也无法读取或使用它。
- en: Data from information repositories
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 来自信息存储库的数据
- en: Data for ML is not always stored in databases or used as datasets. Machine learning
    projects usually require collaboration and planning. Information can also be stored
    in several information repositories and can be mined to get valuable information.
    Information repositories include document-sharing services or project management
    systems such as SharePoint, Confluence, and Jira. To mitigate this technique,
    ensure that the users are trained and informed not to share model endpoints or
    information on the project management software. Documentation about the service
    should also be secured and shared only with people required to possess that information
    using secure channels.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习数据并不总是存储在数据库中或用作数据集。机器学习项目通常需要协作和规划。信息也可以存储在多个信息存储库中，并可以挖掘以获取有价值的信息。信息存储库包括文档共享服务或项目管理系统，如SharePoint、Confluence和Jira。为了减轻这种技术，确保用户接受过培训并被告知不要在项目管理软件上共享模型端点或项目信息。关于服务的文档也应得到保护，并且仅通过安全渠道与需要拥有该信息的人员共享。
- en: Data from the local system
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 来自本地系统的数据
- en: Any data stored in any local systems must be secured as well. After gaining
    access to the network, an adversary may search filesystems’ configuration files
    and local datasets to extract data, especially sensitive data such as SSH keys,
    encryption keys, and connection information.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 任何存储在任何本地系统中的数据都必须得到保护。在获得网络访问权限后，攻击者可能会搜索文件系统配置文件和本地数据集以提取数据，特别是像SSH密钥、加密密钥和连接信息这样的敏感数据。
- en: ML attack staging techniques
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习攻击阶段技术
- en: 'After data collection, it makes sense that the adversary will move on to exfiltration
    to get that data out of the system. But for ML, there’s a different stage. We
    also have to consider the ML attack staging. Depending on the adversary’s purpose,
    they might want to leverage their knowledge to disrupt the service by using several
    techniques that target the ML model before they try to extract ML data. Here,
    we can identify four techniques, one of which is the backdoor ML model technique
    that can also be used as a persistent technique. We’ve already discussed it in
    the *Backdoor ML model* section, so here, we will talk about the rest:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据收集之后，对手会继续进行泄露，以便将数据从系统中提取出来。但对于机器学习来说，有一个不同的阶段。我们还需要考虑机器学习攻击阶段。根据对手的目的，他们可能会利用他们的知识，通过使用针对机器学习模型的技术来破坏服务，在他们尝试提取机器学习数据之前。在这里，我们可以识别出四种技术，其中之一是后门机器学习模型技术，它也可以用作持久技术。我们已经在*后门机器学习模型*部分讨论过它，所以在这里，我们将讨论其余部分：
- en: '![Figure 2.11 – ML attack staging techniques](img/B21076_02_11.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图2.11 – 机器学习攻击阶段技术](img/B21076_02_11.jpg)'
- en: Figure 2.11 – ML attack staging techniques
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.11 – 机器学习攻击阶段技术
- en: Create a proxy ML model
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个代理机器学习模型
- en: The adversary might create an ML model as a proxy for the target model. Proxy
    models can be used in a variety of ways. The adversary might train models from
    similar datasets, use available pre-trained models, or train a proxy model from
    ML artifacts they have gathered in previous stages. The proxy model then can serve
    to replicate the victim’s inference API or to replicate access to target another
    model within the organization.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 对手可能会创建一个机器学习模型作为目标模型的代理。代理模型可以以多种方式使用。对手可能会从类似的数据集中训练模型，使用可用的预训练模型，或者从他们在前期阶段收集到的机器学习工件中训练一个代理模型。然后，代理模型可以用来复制受害者的推理API或复制访问组织内部另一个模型。
- en: Verify attack
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 验证攻击
- en: Before the launch of the attack, the adversary might need to verify that the
    strategy they have developed works. That means getting an offline or a replicated
    model and trying out the techniques they have planned. This gives them the confidence
    that the attack is effective. Then, they are free to deploy it in the physical
    environment or keep it and use it at a later time. When the adversary has gathered
    enough information and has the capability to verify the attack in a replicated
    system they have built that mirrors the victim organization system, it presents
    a new problem. The actual attack won’t trigger any significant traffic in the
    victim’s systems, making the use of this technique potentially undetectable.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在攻击发起之前，对手可能需要验证他们开发的策略是否有效。这意味着获取一个离线或复制的模型，并尝试他们计划中的技术。这给了他们信心，认为攻击是有效的。然后，他们可以自由地将它部署在物理环境中，或者保留它并在以后使用。当对手收集了足够的信息，并且有能力在一个复制的系统中验证攻击，该系统反映了受害者组织系统时，就出现了一个新的问题。实际的攻击不会在受害者的系统中触发任何显著的流量，这使得使用这种技术可能无法检测到。
- en: Craft adversarial data
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 精心制作对抗数据
- en: The craft adversarial data technique that was already mentioned in the *Evade
    ML model* section needs information and artifacts collected in multiple stages.
    Typically, the result is data poisoning. Depending on the adversary’s goal, the
    inputs have been modified, which causes effects such as missed predictions, misclassifications,
    or the maximizing of the system’s energy consumption. This attack depends greatly
    on the adversary’s knowledge of the system. You can use many different algorithms
    to develop the adversarial data attack, such as white-box optimization, black-box
    optimization, black-box transfer, or manual modification.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在*规避机器学习模型*部分已经提到的精心制作的对抗数据技术需要收集多个阶段的信息和工件。通常结果是数据中毒。根据对手的目标，输入已经被修改，这导致了诸如预测失误、误分类或最大化系统能耗等影响。这种攻击在很大程度上依赖于对手对系统的了解。你可以使用许多不同的算法来开发对抗数据攻击，例如白盒优化、黑盒优化、黑盒迁移或手动修改。
- en: Exfiltration techniques
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 泄露技术
- en: 'The data is usually extracted in the exfiltration stage, which involves two
    techniques that apply to ML:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 数据通常在泄露阶段提取，这涉及到适用于机器学习的两种技术：
- en: '![Figure 2.12 – Exfiltration techniques](img/B21076_02_12.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图2.12 – 泄露技术](img/B21076_02_12.jpg)'
- en: Figure 2.12 – Exfiltration techniques
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.12 – 泄露技术
- en: Exfiltration via ML inference API
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过机器学习推理API进行泄露
- en: The ML inference API, if vulnerable, can lead to a leak of private information
    about the training, the model itself, or private intellectual property. If the
    model inference API needs to be public, ensure that you secure it as much as possible
    and limit the number of queries a user can do in production so that they cannot
    figure out different ways of getting that information.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果机器学习推理API存在漏洞，可能会导致训练、模型本身或私有知识产权的私人信息的泄露。如果模型推理API需要公开，请确保尽可能安全地保护它，并限制用户在生产环境中可以执行的查询数量，以防止他们找出获取该信息的不同方法。
- en: Exfiltration via cyber-means
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过网络手段的数据外泄
- en: Of course, the ML project is not the only thing that is vulnerable here. Depending
    on the overall security of the environment and the systems, an adversary might
    choose traditional exfiltration techniques to steal data from your network. Exfiltration
    can be accomplished by just transferring data over the network, transferring data
    over a physical medium such as a removable or cloud drive, or via the internet
    to a web service, a code repository, or directly to cloud storage.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，机器学习项目并不是这里唯一容易受到攻击的东西。根据环境和系统的整体安全性，攻击者可能会选择传统的数据外泄技术从您的网络中窃取数据。数据外泄可以通过仅在网络中传输数据、通过物理介质（如可移动或云驱动器）传输数据，或者通过互联网传输到网络服务、代码仓库或直接传输到云存储来实现。
- en: Impact techniques
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 影响技术
- en: 'There are seven impact techniques available where the adversary manipulates
    or interrupts the service for your ML systems or data. We have already covered
    the evade ML model technique. Let us look at the rest of the techniques of this
    stage:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 有七种影响技术可供攻击者操纵或中断您的机器学习系统或数据的服务。我们已经讨论了逃避机器学习模型技术。让我们看看这个阶段的其余技术：
- en: '![Figure 2.13 – Impact techniques](img/B21076_02_13.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图2.13 – 影响技术](img/B21076_02_13.jpg)'
- en: Figure 2.13 – Impact techniques
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.13 – 影响技术
- en: Denial of ML service
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 拒绝机器学习服务
- en: Denial-of-service attacks target ML systems with multiple requests to disrupt
    the service. Since endpoints have finite resources, by using a denial-of-service
    attack, an adversary can create bottlenecks which can be expensive and disrupt
    the service so that it cannot serve other requests, rendering the service useless.
    There are a couple of things you can do to mitigate them that involve deploying
    third-party Azure services, but the first step would probably be to restrict the
    number of ML model requests.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 拒绝服务攻击针对机器学习系统进行多次请求以破坏服务。由于端点资源有限，通过拒绝服务攻击，攻击者可以创建瓶颈，这可能是昂贵的，并破坏服务，使其无法处理其他请求，从而使服务变得无用。您可以通过部署第三方Azure服务来采取一些措施来减轻这些攻击，但第一步可能是限制机器学习模型请求的数量。
- en: Spam ML systems with chaff data
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用干扰数据对垃圾邮件机器学习系统进行攻击
- en: This technique requires the adversary to know that the system probably uses
    the data for predictions to retrain the service. Spamming the system with many
    requests and data that does not make sense will increase the number of predictions
    or false predictions. It will cause analysts or data scientists working on improving
    the system to waste much time reviewing and correcting those incorrect inferences.
    There are capabilities of Azure Machine Learning that we will talk about to mitigate
    this. However, the obvious choice here is to restrict the number of ML model queries
    or block traffic from suspicious endpoints that make multiple unrelated requests.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术要求攻击者知道系统可能使用数据来进行预测以重新训练服务。向系统发送大量无意义的请求和数据会增加预测或错误预测的数量。这将导致分析师或数据科学家在改进系统时浪费大量时间审查和纠正那些错误的推断。我们将讨论Azure机器学习的一些功能来减轻这种情况。然而，这里明显的选择是限制机器学习模型查询的数量或阻止来自多次发送无关请求的可疑端点的流量。
- en: Erode ML model integrity
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 侵蚀机器学习模型完整性
- en: This technique combines spamming the system with data and using adversarial
    data to degrade the model’s performance. This doesn’t have to be a one-time event.
    The attack can be ongoing for quite some time, so the ML system is eroded and
    predictions are inaccurate. This attack might be more difficult to detect since
    it does not have the goal of disrupting the service; it wants to subtly make changes
    to the model that are not detectable over a long period of time.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术结合了使用数据和对抗性数据来降低模型性能的攻击。这不必是一次性事件。攻击可以持续相当长的时间，因此机器学习系统会被侵蚀，预测不准确。这种攻击可能更难检测，因为它没有破坏服务的目标；它想要在长时间内微妙地改变模型，使其不可检测。
- en: Harvest cost
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 收割成本
- en: Systems have finite resources, and usually, when someone is launching multiple
    requests bombarding the system with so much data, it interrupts the service. With
    cloud computing, infrastructure doesn’t have to be a finite resource. Cloud systems
    can scale to accommodate increased traffic, but at the same time, auto-scaling
    affects the costs of those resources. Restricting the number of queries per application
    or detecting those kinds of attacks can mitigate this technique, which targets
    the operational costs of the victim’s organization.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 系统资源有限，通常，当有人发起多个请求，向系统发送大量数据时，会中断服务。使用云计算，基础设施不必是有限的资源。云系统可以扩展以适应增加的流量，但与此同时，自动扩展也会影响这些资源的成本。限制每个应用程序的查询次数或检测这类攻击可以减轻这种技术，它针对的是受害者组织的运营成本。
- en: ML intellectual property theft
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习知识产权盗窃
- en: Sometimes the target is the model itself. Let’s say you provide ML as a service.
    Someone who has managed to extract that model now has unlimited use of your service
    without paying. That can have a significant impact, as the intellectual property
    is unsafe and can cause economic harm to your organization. Mitigations for this
    technique include controlling access to your models and data at rest, securing
    your models and data in transit, and encrypting services and data where possible.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 有时目标是模型本身。假设您提供机器学习作为服务。现在，有人已经成功提取了该模型，他们可以免费无限使用您的服务。这可能会产生重大影响，因为知识产权不安全，可能会对您的组织造成经济损失。对此技术的缓解措施包括控制对您的模型和静态数据的访问、确保您的模型和传输中的数据安全，以及在可能的情况下加密服务和数据。
- en: System misuse for external effect
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 系统滥用以产生外部影响
- en: If the adversary cannot extract the model, they might still attack the system
    and use it for their own purpose. Hijacking the system and using their own data
    to get results or predictions could be an example. By gaining access to a system
    that monitors and protects financial data, the adversary might be able to pass
    invoices that otherwise would be flagged as invalid. As a result, this prohibits
    the system from preventing fraud.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果攻击者无法提取模型，他们仍然可以攻击系统并用于自己的目的。劫持系统并使用自己的数据来获取结果或预测可能是例子之一。通过访问监控和保护财务数据的系统，攻击者可能能够通过那些否则会被标记为无效的发票。结果，这阻止了系统防止欺诈。
- en: Case studies and examples
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 案例研究和示例
- en: For more case studies, you can check the *Further reading* section of this chapter
    or access the complete knowledge base at [https://atlas.mitre.org/](https://atlas.mitre.org/).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如需更多案例研究，您可以查看本章的*进一步阅读*部分，或访问完整的知识库[https://atlas.mitre.org/](https://atlas.mitre.org/)。
- en: After seeing the types of generic techniques used in attacks, let us explore
    the actual services that can be affected in the case of an attack.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了攻击中使用的通用技术类型之后，让我们探索在攻击情况下可能受到影响的具体服务。
- en: Exploring Azure services involved in ML attacks
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索涉及机器学习攻击的Azure服务
- en: As you can see, attacks are multi-level and primarily based on the adversary’s
    goal. Since we do not know what that is, we can deploy multiple mitigation techniques
    to lessen the impact. As Azure Machine Learning is based on the Azure platform,
    we can deploy numerous tools to detect an incident, and by using automation, the
    platform will deploy mitigation steps before we are even aware that something
    has happened. Although we focused on ML attacks, attacks on related systems, virtual
    machines, and databases are still a concern. Let us look at associated services
    that can be used together with **Azure** **Machine Learning**.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，攻击是多层次的，并且主要基于攻击者的目标。由于我们不知道那是什么，我们可以部署多种缓解技术来减轻影响。由于Azure机器学习基于Azure平台，我们可以部署众多工具来检测事件，并通过自动化，平台将在我们甚至不知道发生任何事情之前就部署缓解步骤。尽管我们专注于机器学习攻击，但针对相关系统、虚拟机和数据库的攻击仍然是一个问题。让我们看看可以与**Azure**
    **机器学习**一起使用的相关服务。
- en: Access
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问
- en: '**Microsoft Entra ID** usually handles access in Azure. Microsoft Entra ID
    is Microsoft’s cloud-based identity and access management service. It provides
    a range of features and capabilities to manage user identities and secure access
    to various resources in the Azure cloud and other Microsoft services. Besides
    identity and access management, it also provides **Federation**, **single sign-on**
    (**SSO)**, a developer platform, and various features for security and governance.
    Different services might also offer different ways of authentication, such as
    via service credentials, access keys, and shared access signatures. We will focus
    on learning how to secure and mitigate all those services in the following chapters.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '**Microsoft Entra ID**通常负责Azure中的访问。Microsoft Entra ID是Microsoft的基于云的身份和访问管理服务。它提供了一系列功能和能力来管理用户身份并保护Azure云和其他Microsoft服务中的各种资源的安全访问。除了身份和访问管理之外，它还提供**联合**、**单点登录**（SSO）、开发者平台以及安全和治理的各种功能。不同的服务也可能提供不同的认证方式，例如通过服务凭证、访问密钥和共享访问签名。我们将在接下来的章节中专注于学习如何保护并减轻所有这些服务的风险。'
- en: Data
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据
- en: ML is based on data. Azure Machine Learning supports multiple data sources,
    specifically **Azure Blob** and **File Storage**, **Azure Data Lake**, **Azure
    SQL Database**, **Azure PostgreSQL** database, and **Azure MySQL** database, each
    with individual security and monitoring features. We will be working with their
    security and monitoring features, including encryption at rest and encryption
    in transit, in the upcoming chapters.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习基于数据。Azure机器学习支持多种数据源，具体包括**Azure Blob**和**文件存储**、**Azure Data Lake**、**Azure
    SQL数据库**、**Azure PostgreSQL**数据库和**Azure MySQL**数据库，每个都具备独立的安全和监控功能。我们将在接下来的章节中探讨它们的安全和监控功能，包括静态加密和传输加密。
- en: Network
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络
- en: Although not directly related to Azure Machine Learning, many attacks happen
    by infiltrating the on-premises or cloud network. In the following chapters, we
    will discuss securing the service using network services. These include virtual
    networks, network security groups, **Azure Firewall**, and hybrid solutions such
    as **VPN gateways** and **ExpressRoute**. The **Service Endpoints** and **Private
    Endpoints** features can also be used for better security and isolation.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管与Azure机器学习没有直接关联，但许多攻击是通过渗透本地或云网络发生的。在接下来的章节中，我们将讨论使用网络服务来保护服务。这些包括虚拟网络、网络安全组、**Azure防火墙**以及混合解决方案，如**VPN网关**和**ExpressRoute**。**服务端点**和**私有端点**功能也可以用于提高安全性和隔离性。
- en: An Azure **virtual network** (**VNet**) is a fundamental component of Microsoft
    Azure’s networking architecture. It is a logically isolated network environment
    that allows you to securely connect and control Azure resources, including **virtual
    machines** (**VMs**), **Azure App Service**, and databases.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Azure **虚拟网络**（VNet）是Microsoft Azure网络架构的基本组件。它是一个逻辑上隔离的网络环境，允许您安全地连接和控制Azure资源，包括**虚拟机**（VMs）、**Azure
    App Service**和数据库。
- en: Azure VNets usually work together with **network security groups** (**NSGs**),
    which provide granular network security and act as a basic firewall, allowing
    you to define inbound and outbound traffic rules to filter and control network
    traffic. NSGs do not maintain state but are the first step to securing the network
    traffic.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Azure VNets通常与**网络安全组**（NSGs）一起工作，这些组提供细粒度的网络安全，并充当基本防火墙，允许您定义入站和出站流量规则以过滤和控制网络流量。NSGs不维护状态，但它是确保网络流量安全的第一步。
- en: Azure Firewall is a cloud-based network security service offered by Microsoft
    Azure. It provides centralized, high-level network security and protection for
    VNets. Azure Firewall acts as a fully stateful network traffic filtering and routing
    solution, allowing you to control and monitor both inbound and outbound traffic
    to and from your Azure resources.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Azure防火墙是Microsoft Azure提供的一种基于云的网络安全服务。它为VNets提供集中式、高级别的网络安全和保护。Azure防火墙充当一个完全状态化的网络流量过滤和路由解决方案，允许您控制并监控Azure资源的入站和出站流量。
- en: An Azure VPN gateway is a networking component that enables secure connectivity
    between on-premises networks and VNets. It provides a way to establish a **virtual
    private network** (**VPN**) tunnel over the public internet, ensuring secure communication
    and extending your on-premises network into the Azure cloud.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Azure VPN网关是一个网络组件，它允许本地网络和VNets之间建立安全连接。它提供了一种在公共互联网上建立**虚拟专用网络**（VPN）隧道的方法，确保安全通信并将您的本地网络扩展到Azure云中。
- en: If the VPN gateway is not enough, you can use Azure ExpressRoute. This is a
    Microsoft Azure service that enables private and dedicated network connectivity
    between your on-premises network and Azure. It provides a reliable, high-throughput,
    low-latency connection, bypassing the public internet.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 VPN 网关不足以满足需求，您可以使用 Azure ExpressRoute。这是一项 Microsoft Azure 服务，它允许您的本地网络与
    Azure 之间建立私有和专用的网络连接。它提供可靠、高吞吐量、低延迟的连接，绕过公共互联网。
- en: '**Service Endpoints** and **Private Endpoints** are two features in Azure that
    provide secure and private connectivity to Azure services. Service Endpoints allows
    you to extend your VNet to the Azure service’s backend, providing secure access
    to that service over the Azure backbone network. Private Endpoints allows you
    to access Azure services privately from your VNet using a private IP address.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '**服务端点**和**私有端点**是 Azure 中的两个功能，它们提供了安全且私有的连接到 Azure 服务。服务端点允许您将您的 VNet 扩展到
    Azure 服务的后端，通过 Azure 骨干网络安全访问该服务。私有端点允许您使用私有 IP 地址从您的 VNet 私密访问 Azure 服务。'
- en: Applications
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用程序
- en: Applications can be hosted in multiple services inside and outside of Azure.
    Most ML services are intended to be used by an application, which is another component
    we need to consider when we are working on implementing security. In this book,
    we will learn how to secure services that host applications such as Azure App
    Service, VMs, or **container** services, but we will also analyze some best practices
    for developing software applications. Of course, since the implementation of application
    security heavily depends on the programming language and libraries used, we will
    explain the high-level implementation of mitigation techniques such as SQL injection
    or cross-site scripting.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序可以托管在 Azure 内部和外部多个服务中。大多数机器学习服务旨在由应用程序使用，这是我们实施安全时需要考虑的另一个组件。在这本书中，我们将学习如何保护托管应用程序的服务，例如
    Azure App Service、VM 或**容器**服务，但我们还将分析一些开发软件应用程序的最佳实践。当然，由于应用程序安全实施高度依赖于所使用的编程语言和库，我们将解释缓解技术（如
    SQL 注入或跨站脚本）的高级实现。
- en: Compute
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算
- en: ML relies heavily on computational resources. You can create multiple compute
    targets for training or hosting inference models in the workspace. Targets can
    be local compute, **Azure Machine Learning compute**, **Azure Databricks**, **HDInsight**,
    **Synapse Spark pools**, **Azure Kubernetes Service** (**AKS**), and Azure VMs.
    These compute targets provide the necessary resources and infrastructure to run
    ML workloads at scale. They must be secured and monitored properly, as they are
    a critical part of ML.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习高度依赖于计算资源。您可以在工作区中创建多个计算目标用于训练或托管推理模型。目标可以是本地计算、**Azure 机器学习计算**、**Azure
    Databricks**、**HDInsight**、**Synapse Spark 池**、**Azure Kubernetes 服务**（**AKS**）和
    Azure VM。这些计算目标提供了运行大规模机器学习工作负载所需资源和基础设施。它们必须得到适当的保护和监控，因为它们是机器学习的关键部分。
- en: Local compute allows you to use your local machine or on-premises infrastructure
    as the compute target. This is useful for development and experimentation when
    you don’t require large-scale resources.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 本地计算允许您使用您的本地机器或本地基础设施作为计算目标。当您不需要大规模资源时，这对于开发和实验非常有用。
- en: Azure Machine Learning compute is a managed compute cluster provided by Azure
    Machine Learning. It dynamically provisions and scales compute resources based
    on your workload requirements. It supports both CPU and GPU instances and is optimized
    for running training jobs at scale.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习计算是由 Azure 机器学习提供的一个托管计算集群。它根据您的工作负载需求动态配置和扩展计算资源。它支持 CPU 和 GPU 实例，并针对大规模运行训练作业进行了优化。
- en: Azure Databricks is an Apache Spark-based analytics platform that integrates
    with Azure Machine Learning. You can use Azure Databricks clusters as a compute
    target for training and deploying ML models, taking advantage of the distributed
    computing capabilities of Spark. If you still want to use Spark but are not using
    Databricks, you can use Azure Synapse Spark pools.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Databricks 是一个基于 Apache Spark 的分析平台，它与 Azure 机器学习集成。您可以使用 Azure Databricks
    集群作为训练和部署机器学习模型的计算目标，利用 Spark 的分布式计算能力。如果您仍然想使用 Spark 但不使用 Databricks，您可以使用 Azure
    Synapse Spark 池。
- en: Azure HDInsight can also be set up as a compute target in Azure Machine Learning.
    Using its distributed processing capabilities allows you to execute ML tasks on
    HDInsight clusters.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Azure HDInsight 也可以在 Azure 机器学习中设置为一个计算目标。利用其分布式处理能力，您可以在 HDInsight 集群上执行机器学习任务。
- en: AKS is a managed Kubernetes service in Azure. You can deploy your ML workloads
    as containerized applications on AKS and use them as a compute target for training
    and serving models. AKS provides scalability and flexibility for running distributed
    training and inference workloads.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: AKS 是 Azure 中的托管 Kubernetes 服务。您可以在 AKS 上部署您的机器学习工作负载作为容器化应用程序，并使用它们作为训练和部署模型的计算目标。AKS
    为运行分布式训练和推理工作负载提供了可伸缩性和灵活性。
- en: Azure VM instances can also be a compute target. You can provision VMs with
    the required specifications and use them for training and deploying ML models.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Azure VM 实例也可以作为计算目标。您可以使用所需的规格配置 VM，并使用它们进行训练和部署机器学习模型。
- en: Azure Machine Learning
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Azure Machine Learning
- en: All previously mentioned services relate to or can be used with the **Azure
    Machine Learning workspace**. The workspace is the main point of management for
    Azure Machine Learning; however, the workspace itself can be used for security
    or isolation, for example, if multiple workspaces might be needed for different
    scenarios. The workspace provides multiple features for monitoring and organizing
    assets such as model and dataset versioning and data drift. We will also explore
    security features in algorithms, data, and models, such as fairness, data anonymization,
    and more.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 所有之前提到的服务都与**Azure Machine Learning 工作区**相关或可以与其一起使用。工作区是 Azure Machine Learning
    的主要管理点；然而，工作区本身可以用于安全或隔离，例如，如果需要为不同场景创建多个工作区。工作区提供了多个功能，用于监控和组织资产，如模型和数据集版本控制以及数据漂移。我们还将探讨算法、数据和模型中的安全功能，例如公平性、数据匿名化等。
- en: Now, we’ve learned about the services related to Azure Machine Learning that
    we need to protect. They might not be the only ones—it depends on your system
    architecture—but they are a great start to your security journey.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经了解了需要保护的与 Azure Machine Learning 相关的服务。它们可能不是唯一的——这取决于您的系统架构——但它们是您安全之旅的一个很好的开始。
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: There are many attacks to be prepared for and vulnerabilities are discovered
    daily, so we must follow a framework that helps us keep up to date with current
    vulnerabilities and their mitigations where possible. The MITRE ATLAS framework
    is a great resource to get started as it is adapted to ML. We need to be aware
    of the 12 stages and multiple techniques per stage to protect our ML assets. However,
    as ML assets work with numerous other systems, the implementations we will see
    in the following chapters will include securing Azure Machine Learning and all
    its related services.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要准备许多攻击，并且每天都会发现漏洞，因此我们必须遵循一个框架，帮助我们跟上当前漏洞及其缓解措施。MITRE ATLAS 框架是一个很好的起点，因为它适用于机器学习。我们需要了解
    12 个阶段以及每个阶段的多项技术，以保护我们的机器学习资产。然而，由于机器学习资产与众多其他系统一起工作，接下来章节中我们将看到的实现将包括确保 Azure
    Machine Learning 及其所有相关服务的安全性。
- en: But before diving into those implementations, in the next chapter, we will learn
    about the security industry compliance standards we must adhere to and how to
    implement compliance controls together with responsible AI development practices.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 但在深入这些实现之前，在下一章中，我们将学习必须遵守的安全行业合规标准以及如何与负责任的 AI 开发实践一起实施合规控制。
- en: Further reading
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'DeepPayload: Black-box Backdoor Attack on Deep Learning Models through Neural
    Payload Injection: [https://arxiv.org/abs/2101.06896](https://arxiv.org/abs/2101.06896)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeepPayload：通过神经负载注入对深度学习模型的黑盒后门攻击：[https://arxiv.org/abs/2101.06896](https://arxiv.org/abs/2101.06896)
- en: 'Imitation Attacks and Defenses for Black-box Machine Translation Systems: [https://arxiv.org/abs/2004.15015](https://arxiv.org/abs/2004.15015)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黑盒机器翻译系统的模仿攻击和防御：[https://arxiv.org/abs/2004.15015](https://arxiv.org/abs/2004.15015)
- en: 'Explaining and Harnessing Adversarial Examples: https://arxiv.org/abs/1412.6572'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释和利用对抗性示例：[https://arxiv.org/abs/1412.6572](https://arxiv.org/abs/1412.6572)
