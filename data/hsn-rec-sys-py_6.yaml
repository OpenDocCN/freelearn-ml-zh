- en: Building Collaborative Filters
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建协同过滤器
- en: In the previous chapter, we mathematically defined the collaborative filtering
    problem and gained an understanding of various data mining techniques that we
    assumed would be useful in solving this problem.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章节中，我们通过数学方式定义了协同过滤问题，并了解了我们认为在解决这个问题时有用的各种数据挖掘技术。
- en: The time has finally come for us to put our skills to the test. In the first
    section, we will construct a well-defined framework that will allow us to build
    and test our collaborative filtering models effortlessly. This framework will
    consist of the data, the evaluation metric, and a corresponding function to compute
    that metric for a given model.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 终于到了我们将技能付诸实践的时候了。在第一节中，我们将构建一个明确定义的框架，允许我们轻松构建和测试我们的协同过滤模型。这个框架将包括数据、评估指标和相应的函数，用于计算给定模型的指标。
- en: Technical requirements
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will be required to have Python installed on a system. Finally, to use the
    Git repository of this book, the user needs to install Git.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要在系统中安装Python。最后，为了使用本书的Git仓库，用户还需要安装Git。
- en: 'The code files of this chapter can be found on GitHub:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在GitHub上找到：
- en: '[https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python](https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python](https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python)。'
- en: 'Check out the following video to see the code in action:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，看看代码如何运行：
- en: '[http://bit.ly/2mFmgRo](http://bit.ly/2mFmgRo)[.](http://bit.ly/2mFmgRo)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2mFmgRo](http://bit.ly/2mFmgRo)[.](http://bit.ly/2mFmgRo)'
- en: The framework
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 框架
- en: Just like the knowledge-based and content-based recommenders, we will build
    our collaborative filtering models in the context of movies. Since collaborative
    filtering demands data on user behavior, we will be using a different dataset
    known as MovieLens.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 就像基于知识和基于内容的推荐系统一样，我们将在电影的背景下构建我们的协同过滤模型。由于协同过滤要求有用户行为数据，我们将使用一个不同的数据集，称为MovieLens。
- en: The MovieLens dataset
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MovieLens数据集
- en: 'The MovieLens dataset is made publicly available by GroupLens Research, a computer
    science lab at the University of Minnesota. It is one of the most popular benchmark
    datasets used to test the potency of various collaborative filtering models and
    is usually available in most recommender libraries and packages:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: MovieLens数据集由GroupLens Research提供，GroupLens是明尼苏达大学的一个计算机科学实验室。它是最流行的基准数据集之一，用于测试各种协同过滤模型的效果，通常可以在大多数推荐库和包中找到：
- en: '![](img/dc0f89d7-6e9c-4790-a6c0-06725f2dbe8a.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dc0f89d7-6e9c-4790-a6c0-06725f2dbe8a.png)'
- en: MovieLens gives us user ratings on a variety of movies and is available in various
    sizes. The full version consists of more than 26,000,000 ratings applied to 45,000
    movies by 270,000 users. However, for the sake of fast computation, we will be
    using the much smaller 100,000 dataset, which contains 100,000 ratings applied
    by 1,000 users to 1,700 movies.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: MovieLens提供了关于各种电影的用户评分，且有多个版本可用。完整版本包含超过26,000,000条评分，涉及45,000部电影，由270,000用户评分。然而，为了快速计算，我们将使用一个更小的100,000数据集，该数据集包含100,000条评分，由1,000个用户对1,700部电影进行评分。
- en: Downloading the dataset
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载数据集
- en: Without any further ado, let's go ahead and download the 100,000 dataset. The
    dataset available on the official GroupLens site does not provide us with user
    demographic information anymore. Therefore, we will use a legacy dataset made
    available on Kaggle by Prajit Datta.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 不再废话，让我们直接下载100,000数据集。官方GroupLens网站上提供的数据集已经不再包含用户人口统计信息。因此，我们将使用一个由Prajit
    Datta在Kaggle上发布的旧版数据集。
- en: Download the MovieLens 100,000 dataset at [https://www.kaggle.com/prajitdatta/movielens-100k-dataset/data](https://www.kaggle.com/prajitdatta/movielens-100k-dataset/data).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 下载MovieLens 100,000数据集，请访问[https://www.kaggle.com/prajitdatta/movielens-100k-dataset/data](https://www.kaggle.com/prajitdatta/movielens-100k-dataset/data)。
- en: Unzip the folder and rename it `movielens`*. *Next, move this folder into the `data`folder
    within `RecoSys`*. *The MovieLens dataset should contain around 23 files. However,
    the only files we are interested in are `u.data`, `u.user`, and `u.item`*. *Let's
    explore these files in the next section.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 解压文件夹并将其重命名为`movielens`。*接下来，将该文件夹移动到`RecoSys`中的`data`文件夹内。*MovieLens数据集应该包含大约23个文件。然而，我们只关心`u.data`、`u.user`和`u.item`这几个文件。*让我们在下一节中探讨这些文件。
- en: Exploring the data
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据
- en: As mentioned in the previous section, we are only interested in three files
    in the `movielens`folder: `u.data`, `u.user`, and `u.item`.Although these files
    are not in CSV format, the code required to load them into a Pandas DataFrame
    is almost identical.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前一节所提到的，我们只对`movielens`文件夹中的三个文件感兴趣：`u.data`、`u.user`和`u.item`。尽管这些文件不是CSV格式，但加载它们到Pandas数据框中的代码几乎是相同的。
- en: Let's start with `u.user`*:*
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`u.user`开始*：*
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here is its output**:**
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的输出**：**
- en: '![](img/87603c24-aeb9-49c5-8d2e-9a08936e0a34.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/87603c24-aeb9-49c5-8d2e-9a08936e0a34.png)'
- en: We see that the `u.user`file contains demographic information about our users,
    such as their age, sex, occupation, and zip_code.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到`u.user`文件包含了关于用户的 demographic（人口统计）信息，如年龄、性别、职业和邮政编码。
- en: 'Next, let''s take a look at the `u.item`file, which gives us information about
    the movies that have been rated by our users:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看`u.item`文件，它提供了关于用户已评分电影的信息：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here is its output**:**
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的输出**：**
- en: '![](img/1d17c470-2f66-4030-b088-a6e80885e42a.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d17c470-2f66-4030-b088-a6e80885e42a.png)'
- en: 'We see that this file gives us information regarding the movie''s title, release
    date, IMDb URL, and its genre(s). Since we are focused on building only collaborative
    filters in this chapter, we do not require any of this information, apart from
    the movie title and its corresponding ID:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到这个文件提供了关于电影的标题、上映日期、IMDb网址以及它的类型等信息。由于我们本章专注于构建协同过滤，因此除了电影标题和对应的ID外，我们不需要其他任何信息：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Lastly, let''s import the `u.data`file into our notebook. This is arguably
    the most important file as it contains all the ratings that every user has given
    to a movie. It is from this file that we will construct our ratings matrix:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们将`u.data`文件导入到我们的笔记本中。这个文件可以说是最重要的，因为它包含了每个用户对电影的评分。正是从这个文件中，我们将构建我们的评分矩阵：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here is its output**:**
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的输出**：**
- en: '![](img/4d99de2f-2ad1-4930-8837-e0adc93bd4e6.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4d99de2f-2ad1-4930-8837-e0adc93bd4e6.png)'
- en: 'We see that every row in our new `ratings`DataFrame denotes a rating given
    by a user to a particular movie at a particular time. However, for the purposes
    of the exercises in this chapter, we are not really worried about the time at
    which the ratings were given. Therefore, we will just go ahead and drop it:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，在新的`ratings`数据框中，每一行代表一个用户在某一时间给特定电影的评分。然而，对于本章的练习，我们并不关心评分给出的具体时间。因此，我们将直接去掉这一列：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Training and test data
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和测试数据
- en: The `ratings`DataFrame contains user ratings for movies that range from 1 to
    5\. Therefore, we can model this problem as an instance of supervised learning
    where we need to predict the rating, given a user and a movie. Although the ratings
    can take on only five discrete values, we will model this as a regression problem.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`ratings`数据框包含了电影的用户评分，评分范围从1到5。因此，我们可以将这个问题建模为一个监督学习问题，其中我们需要预测一个用户对一部电影的评分。尽管评分只有五个离散值，我们仍将其建模为回归问题。'
- en: Consider a case where the true rating given by a user to a movie is 5\. A classification
    model will not distinguish between the predicted ratings of 1 and 4\. It will
    treat both as misclassified. However, a regression model will penalize the former
    more than the latter, which is the behavior we want.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一个用户给某电影的真实评分是5。一个分类模型无法区分预测的评分是1还是4，它会将两者都视为错误分类。然而，一个回归模型会对前者给予更多的惩罚，这正是我们希望的行为。
- en: As we saw in [Chapter 5](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml), *Getting
    Started with Data Mining Techniques*, one of the first steps towards building
    a supervised learning model is to construct the test and training sets. The model
    will learn using the training dataset and its potency will be judged using the
    testing dataset.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第5章](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml)中所看到的，*数据挖掘技术入门*，构建监督学习模型的第一步是构造训练集和测试集。模型将使用训练集进行学习，并使用测试集评估其效能。
- en: 'Let''s now split our ratings dataset in such a way that 75% of a user''s ratings
    is in the training dataset and 25% is in the testing dataset. We will do this
    using a slightly hacky way: we will assume that the `user_id`field is the target
    variable (or `y`) and that our `ratings`DataFrame consists of the predictor variables
    (or `X`)*. *We will then pass these two variables into scikit-learn''s `train_test_split`function
    and `stratify`it along *y. *This ensures that the proportion of each class is
    the same in both the training and testing datasets:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将评分数据集拆分成训练集和测试集，其中75%的评分用于训练数据集，25%用于测试数据集。我们将使用一种稍微有点“hacky”的方式来完成：我们假设`user_id`字段是目标变量（或`y`），而我们的`ratings`数据框则由预测变量（或`X`）组成**.**然后我们将这两个变量传递给scikit-learn的`train_test_split`函数，并沿着`y`进行`stratify`处理。这样可以确保训练集和测试集中的每个类别的比例相同：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Evaluation
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估
- en: We know from [Chapter 5](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml), *Getting
    Started with Data Mining Techniques* that the RMSE, or root mean squared error,
    is the most commonly used performance metric for regressors. We will be using
    the RMSE to assess our modeling performance too. `scikit-learn` already gives
    us an implementation of the mean squared error. So, all that we have to do is
    define a function that returns the square root of the value returned by `mean_squared_error`*:*
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从[第5章](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml)，*数据挖掘技术入门*中得知，RMSE（均方根误差）是回归模型中最常用的性能评估指标。我们也将使用RMSE来评估我们的模型表现。`scikit-learn`已经提供了均方误差的实现。因此，我们所要做的就是定义一个函数，返回`mean_squared_error`函数返回值的平方根**:**
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Next, let's define our baseline collaborative filter model. All our **collaborative
    filter** (or **CF**) models will take in a `user_id`and `movie_id`as input and
    output a floating point number between 1 and 5\. We define our baseline model
    in such a way that it returns `3` regardless of `user_id`or `movie_id`*:*
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们定义我们的基准协同过滤模型。我们所有的**协同过滤**（或**CF**）模型都将以`user_id`和`movie_id`作为输入，并输出一个介于1和5之间的浮动值。我们将基准模型定义为无论`user_id`或`movie_id`如何，都返回`3`**:**
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To test the potency of our model, we compute the RMSE obtained by that particular
    model for all user-movie pairs in the test dataset:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试模型的效果，我们计算该特定模型在测试数据集中的所有用户-电影对所得到的RMSE：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We''re all set. Let''s now compute the RMSE obtained by our baseline model:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一切准备就绪。现在让我们计算一下基准模型得到的RMSE：
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We obtain a score of `1.247`. For the models that we build in the subsequent
    sections, we will try to obtain an RMSE that is less than that obtained for the
    baseline.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了一个`1.247`的分数。对于接下来构建的模型，我们将尽力使得RMSE低于基准模型的RMSE。
- en: User-based collaborative filtering
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于用户的协同过滤
- en: 'In [Chapter 1](c4bff0e9-57b3-44ec-90cb-9e5950696b27.xhtml), *Getting Started
    with Recommender Systems*, we learned what user-based collaborative filters do:
    they find users similar to a particular user and then recommend products that
    those users have liked to the first user.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](c4bff0e9-57b3-44ec-90cb-9e5950696b27.xhtml)，*推荐系统入门*中，我们了解了基于用户的协同过滤器的工作原理：它们找到与特定用户相似的用户，然后向第一个用户推荐那些用户喜欢的产品。
- en: In this section, we will implement this idea in code. We will build filters
    of increasing complexity and gauge their performance using the framework we constructed
    in the previous section.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将用代码实现这一思路。我们将构建逐渐复杂的过滤器，并使用前一节中构建的框架来评估它们的表现。
- en: 'To aid us in this process, let''s first build a ratings matrix (described in
    [Chapters 1](c4bff0e9-57b3-44ec-90cb-9e5950696b27.xhtml), *Getting Started with
    Recommender Systems* and [Chapter 5](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml), *Getting
    Started with Data Mining Techniques*) where each row represents a user and each
    column represents a movie. Therefore, the value in the i^(th) row and j^(th) column
    will denote the rating given by user `i` to movie `j`. As usual, pandas gives
    us a very useful function, called `pivot_table`,to construct this matrix from
    our `ratings`DataFrame:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们完成这一过程，让我们首先构建一个评分矩阵（在[第1章](c4bff0e9-57b3-44ec-90cb-9e5950696b27.xhtml)，*推荐系统入门*和[第5章](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml)，*数据挖掘技术入门*中有所描述），其中每一行代表一个用户，每一列代表一部电影。因此，第i^(行)和j^(列)的值表示用户`i`对电影`j`的评分。像往常一样，pandas提供了一个非常有用的函数，叫做`pivot_table`，可以从我们的`ratings`数据框中构建该矩阵：
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here is its output**:**
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的输出**:**
- en: '![](img/42d726f8-5bda-4f13-944d-7516f2744963.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/42d726f8-5bda-4f13-944d-7516f2744963.png)'
- en: We now have a new `r_matrix` DataFrame, where each row is a user and each column
    is a movie. Also, notice that most values in the DataFrame are unspecified. This
    gives us a picture of how sparse our matrix is.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个新的`r_matrix` DataFrame，其中每一行代表一个用户，每一列代表一部电影。另外，请注意，DataFrame中的大多数值是未指定的。这给我们提供了矩阵稀疏程度的一个图景。
- en: Mean
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平均值
- en: Let's first build one of the simplest collaborative filters possible. This simply
    takes in `user_id`and `movie_id`and outputs the mean rating for the movie by all
    the users who have rated it. No distinction is made between the users. In other
    words, the rating of each user is assigned equal weight.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先构建最简单的协同过滤器之一。它只是输入`user_id`和`movie_id`，并输出所有评分该电影的用户的平均评分。用户之间没有区分。换句话说，每个用户的评分都赋予相同的权重。
- en: 'It is possible that some movies are available only in the test set and not
    the training set (and consequentially, not in our ratings matrix). In such cases,
    we will just default to a rating of `3.0`, like the baseline model:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 可能有些电影只在测试集而不在训练集中（因此不在我们的评分矩阵中）。在这种情况下，我们将像基线模型一样默认评分为`3.0`：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We see that the score obtained for this model is lower and therefore better
    than the baseline.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到这个模型的得分较低，因此比基线模型更好。
- en: Weighted mean
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加权平均
- en: In the previous model, we assigned equal weights to all the users. However,
    it makes intuitive sense to give more preference to those users whose ratings
    are similar to the user in question than the other users whose ratings are not.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的模型中，我们给所有用户赋予了相等的权重。然而，从直觉上讲，给那些评分与当前用户相似的用户更多的权重，而不是那些评分不相似的用户，是有道理的。
- en: 'Therefore, let''s alter our previous model by introducing a weight coefficient.
    This coefficient will be one of the similarity metrics that we computed in the
    previous chapter. Mathematically, it is represented as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们通过引入一个权重系数来修改我们之前的模型。这个系数将是我们在上一章中计算的相似度度量之一。从数学上讲，它表示如下：
- en: '![](img/be3fa7ee-447f-4d84-b674-97d3f20b2b9a.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/be3fa7ee-447f-4d84-b674-97d3f20b2b9a.png)'
- en: In this formula, *r*[*u,m* ]represents the rating given by user *u* to movie
    *m.*
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，*r*[*u,m*]表示用户*u*对电影*m*的评分。
- en: For the sake of this exercise, we will use the cosine score as our similarity
    function (or sim). Recall how we constructed a movie cosine similarity matrix
    while building our content-based engine. We will be building a very similar cosine
    similarity matrix for our users in this section.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本次练习，我们将使用余弦分数作为我们的相似度函数（或sim）。回想一下，我们在构建基于内容的引擎时是如何构建电影余弦相似度矩阵的。在本节中，我们将为我们的用户构建一个非常相似的余弦相似度矩阵。
- en: 'However, scikit-learn''s`cosine_similarity`function does not work with `NaN`
    values. Therefore, we will convert all missing values to zero in order to compute
    our cosine similarity matrix:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，scikit-learn的`cosine_similarity`函数无法处理`NaN`值。因此，我们将把所有缺失值转换为零，以便计算我们的余弦相似度矩阵：
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here is its output**:**
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的输出**:**
- en: '![](img/5f2374b3-5ba3-43f4-88e2-9234f4c15f23.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f2374b3-5ba3-43f4-88e2-9234f4c15f23.png)'
- en: With the user cosine similarity matrix in hand, we are now in a position to
    efficiently calculate the weighted mean scores for this model. However, implementing
    this model in code is a little more nuanced than its simpler mean counterpart.
    This is because we need to only consider those cosine similarity scores that have
    a corresponding, non-null rating. In other words, we need to avoid all users that
    have not rated movie *m:*
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有了用户余弦相似度矩阵，我们现在可以有效地计算该模型的加权平均评分。然而，在代码中实现这个模型比其简单的均值模型要复杂一些。这是因为我们只需要考虑那些具有相应非空评分的余弦相似度分数。换句话说，我们需要避免所有没有对电影*m*进行评分的用户：
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Since we are dealing with positive ratings, the cosine similarity score will
    always be positive. Therefore, we do not need to explicitly add in a modulus function
    while computing the normalizing factor (the denominator of the equation that ensures
    the final rating is scaled back to between 1 and 5).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们处理的是正向评分，余弦相似度分数将始终为正。因此，我们在计算归一化因子时（即确保最终评分被缩放回1到5之间的方程的分母）不需要显式地添加模值函数。
- en: However, if you're working with a similarity metric that can be negative in
    this scenario (for instance, the Pearson correlation score), it is important that
    we factor in the modulus.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你正在使用一个可能在此场景中为负的相似度度量（例如，皮尔逊相关系数），那么我们必须考虑模值。
- en: Running this code takes significantly more time than the previous model. However,
    we achieve a (very small) improvement in our RMSE score.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这段代码的时间明显比之前的模型要长。然而，我们在RMSE评分上取得了（非常小的）改进。
- en: User demographics
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用户人口统计
- en: Finally, let's take a look at filters that leverage user demographic information.
    The basic intuition behind these filter is that users of the same demographic
    tend to have similar tastes. Therefore, their effectiveness depends on the assumption
    that women, or teenagers, or people from the same area will share the same taste
    in movies.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看利用用户人口统计信息的过滤器。这些过滤器的基本直觉是，相同人口统计的用户往往有相似的口味。因此，它们的有效性依赖于这样一个假设：女性、青少年或来自同一地区的人会有相同的电影口味。
- en: Unlike the previous models, these filters do not take into account the ratings
    given by all users to a particular movie. Instead, they only look at those users
    that fit a certain demographic.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的模型不同，这些过滤器并不考虑所有用户对特定电影的评分。而是只看那些符合特定人口统计的用户。
- en: Let's now build a gender demographic filter. All this filter does is identify
    the gender of a user, compute the (weighted) mean rating of a movie by that particular
    gender, and return that as the predicted value.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们构建一个性别人口统计过滤器。这个过滤器的作用是识别用户的性别，计算该性别对电影的（加权）平均评分，并返回该值作为预测结果。
- en: 'Our `ratings`DataFrame does not contain the users'' demographics. We will import
    that information from the `users`DataFrame by merging them into one (using pandas,
    as usual). Readers familiar with SQL can see that this is extremely similar to
    the JOIN functionality:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`ratings`DataFrame不包含用户的人口统计信息。我们将通过将`users`DataFrame导入并合并它们来获取这些信息（像往常一样使用pandas）。熟悉SQL的读者会看到，这与JOIN功能非常相似：
- en: '[PRE14]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Here is its output**:**
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的输出**：**
- en: '![](img/6bf67257-c48f-44a6-b898-82685bd2ec96.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6bf67257-c48f-44a6-b898-82685bd2ec96.png)'
- en: 'Next, we need to compute the `mean`rating of each movie by gender. Pandas makes
    this possible with the `groupby`method:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要按性别计算每部电影的`mean`评分。Pandas通过`groupby`方法使这变得可能：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We are now in a position to define a function that identifies the gender of
    the user, extracts the average rating given to the movie in question by that particular
    gender, and return that value as output:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以定义一个函数，识别用户的性别，提取该性别对特定电影的平均评分，并返回该值作为输出：
- en: '[PRE16]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We see that this model actually performs worse than the standard mean ratings
    collaborative filter. This indicates that a user's gender isn't the strongest
    indicator of their taste in movies.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，这个模型实际上比标准的均值评分协同过滤器表现更差。这表明，用户的性别并不是其电影口味的最强指示因素。
- en: 'Let''s try building one more demographic filter, but this time using both gender
    and occupation:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再试构建一个人口统计过滤器，这次使用性别和职业：
- en: '[PRE17]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We see that the `pivot_table` method gives us the required DataFrame. However,
    this could have been done using `groupby`too. `pivot_table`is simply a more compact,
    easier-to-use interface for the `groupby`method:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到`pivot_table`方法为我们提供了所需的DataFrame。然而，这本可以通过`groupby`来完成。`pivot_table`只是`groupby`方法的一种更紧凑、更易于使用的接口：
- en: '[PRE18]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We see that this model performs the worst out of all the filters we've built
    so far, beating only the baseline. This strongly suggests that tinkering with
    user demographic data may not be the best way to go forward with the data that
    we are currently using. However, you are encouraged to try different permutations
    and combinations of user demographics to see what performs best. You are also
    encouraged to try other techniques of improving the model, such as using a weighted
    mean for the `aggfunc` of the`pivot_table`and experimenting with different (perhaps
    more informed) default ratings.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到这个模型的表现是所有我们构建的过滤器中最差的，仅仅比基准模型好一点。这强烈暗示，修改用户人口统计数据可能不是我们当前使用的数据的最佳处理方式。然而，鼓励你尝试不同的用户人口统计数据的排列组合，看看哪些表现最好。你也可以尝试其他改进模型的技术，例如使用加权平均数来作为`pivot_table`的`aggfunc`，并尝试不同（或许更有依据的）默认评分。
- en: Item-based collaborative filtering
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于物品的协同过滤
- en: Item-based collaborative filtering is essentially user-based collaborative filtering
    where the users now play the role that items played, and vice versa.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 基于物品的协同过滤本质上是基于用户的协同过滤，其中用户扮演了物品所扮演的角色，反之亦然。
- en: In item-based collaborative filtering, we compute the pairwise similarity of
    every item in the inventory. Then, given `user_id`and `movie_id`*, *we compute
    the weighted mean of the ratings given by the user to all the items they have
    rated. The basic idea behind this model is that a particular user is likely to
    rate two items that are similar to each other similarly.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于物品的协同过滤中，我们计算库存中每个物品的两两相似度。然后，给定`user_id`和`movie_id`*，*我们计算用户对其评级的所有物品的加权平均值。该模型背后的基本思想是，特定用户可能会类似地评价两个相似的物品。
- en: Building an item-based collaborative filter is left as an exercise to the reader.
    The steps involved are exactly the same except now, as mentioned earlier, the
    movies and users have swapped places.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 构建基于物品的协同过滤器留给读者作为练习。所涉及的步骤与前述完全相同，只是现在电影和用户位置交换了。
- en: Model-based approaches
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于模型的方法
- en: The collaborative filters we have built thus far are known as memory-basedfilters.
    This is because they only make use of similarity metrics to come up with their
    results. They learn any parameters from the data or assign classes/clusters to
    the data. In other words, they do not make use of machine learning algorithms.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们构建的协同过滤器被称为内存型过滤器。这是因为它们只利用相似性度量来得出结果。它们从数据中不学习任何参数，也不为数据分配类别/簇。换句话说，它们不使用机器学习算法。
- en: In this section, we will take a look at some filters that do. We spent an entire
    chapter looking at various supervised and unsupervised learning techniques. The
    time has finally come to see them in action and test their potency.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看一些这样的过滤器。我们花了一整章的时间来研究各种监督和无监督学习技术。现在终于是时候看到它们的实际应用并测试它们的效力了。
- en: Clustering
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: In our weighted mean-based filter, we took every user into consideration when
    trying to predict the final rating. In contrast, our demographic-based filters
    only took users that fit a certain demographic into consideration. We saw that
    the demographic filters performed poorly compared to the weighted mean filter.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的加权平均滤波器中，当试图预测最终评分时，我们考虑了每位用户。相比之下，我们的基于人口统计的过滤器只考虑符合特定人口统计的用户。我们发现，与加权平均滤波器相比，人口统计过滤器表现不佳。
- en: But does this necessarily imply that we need to take all users into consideration
    to achieve better results?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 但这是否必然意味着我们需要考虑所有用户才能取得更好的结果呢？
- en: One of the major drawbacks of the demographic filters was that they were based
    on the assumption that people from a certain demographic think and rate alike.
    However, we can safely say that this is an overreached assumption. Not all men
    like action movies. Nor do all children like animated movies. Similarly, it is
    extremely far-fetched to assume that people from a particular area or occupation
    will have the same taste.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 人口统计过滤器的一个主要缺点是，它们基于这样一种假设：来自某一特定人口统计的人们有相似的思想和评分。然而，我们可以肯定地说，这是一个过于牵强的假设。并非所有男性都喜欢动作片，也不是所有儿童都喜欢动画片。同样，假设来自特定地区或职业的人们会有相同的口味是非常牵强的。
- en: We need to come up with a way of grouping users with a much more powerful metric
    than demographics. From [Chapter 5](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml), *Getting
    Started with Data Mining Techniques*, we already know of one extremely powerful
    tool: `clustering`*.*
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要想出一种比人口统计更强大的方式来分组用户。从[第五章](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml)，《开始使用数据挖掘技术》，我们已经知道一种非常强大的工具：`clustering`*。*
- en: It is possible to use a clustering algorithm, such as k-means, to group users
    into a cluster and then take only the users from the same cluster into consideration
    when predicting ratings.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用聚类算法，如k-means，将用户分组成一个簇，然后在预测评分时只考虑同一簇中的用户。
- en: 'In this section, we will use k-means'' sister algorithm, kNN*, *to build our
    clustering-based collaborative filter. In a nutshell, given an user, *u*, and
    a movie, *m*, these are the steps involved:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用k-means的姐妹算法，kNN*，*来构建基于聚类的协同过滤器。简而言之，给定一个用户*u*和一个电影*m*，涉及以下步骤：
- en: Find the k-nearest neighbors of *u *who have rated movie *m*
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到评价过电影*m*的*u*的k个最近邻居
- en: Output the average rating of the *k* users for the movie *m*
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出*m*的*k*个用户的平均评分
- en: That's it. This extremely simply algorithm happens to be one of the most popularly
    used.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。这种极其简单的算法恰好是最广泛使用的之一。
- en: 'Just like kNN, we will not be implementing the kNN-based collaborative filter
    from scratch. Instead, we will use an extremely popular and robust library called `surprise`:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 和kNN一样，我们不会从头开始实现基于kNN的协同过滤器。相反，我们将使用一个非常流行且强大的库——`surprise`：
- en: '![](img/6f23c30a-a1c2-4fa8-9209-dfb7090f95de.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f23c30a-a1c2-4fa8-9209-dfb7090f95de.png)'
- en: Surprise is a scikit (or scientific kit) for building recommender systems in
    Python. You can think of it as scikit-learn's recommender systems counterpart.
    According to its documentation, `surprise`stands for Simple Python Recommendation
    System Engine. Within a very short span of time, `surprise`has gone on to become
    one of the most popularly used recommender libraries. This is because it is extremely
    robust and easy to use. It gives us ready-to-use implementations of most of the
    popular collaborative filtering algorithms and also allows us to integrate an
    algorithm of our own into the framework.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Surprise是一个用于构建推荐系统的Python科学工具包（scikit）。你可以把它看作是scikit-learn在推荐系统方面的对等物。根据其文档，`surprise`代表简单的Python推荐系统引擎。短短时间内，`surprise`已经成为最流行的推荐库之一。这是因为它非常健壮且易于使用。它为我们提供了大多数流行的协同过滤算法的现成实现，并且还允许我们将自己的算法集成到框架中。
- en: 'To download `surprise`, like any other Python library, open up your Terminal
    and type the following command:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要下载`surprise`，像其他Python库一样，打开终端并输入以下命令：
- en: '[PRE19]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Let''s now build and evaluate our kNN-based collaborative filter. Although *surprise *has
    the MovieLens datasets available within the library, we will still use the external
    data we have in order to get a feel for using the library with alien datasets:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们构建并评估基于kNN的协同过滤器。尽管*surprise*库中已有MovieLens数据集，我们仍然会使用我们手头的外部数据，以便体验如何使用该库处理外部数据集：
- en: '[PRE20]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here is its output**:**
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的输出**:**
- en: '![](img/f3296d5e-c2bf-4166-abd0-8ceef92b158f.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3296d5e-c2bf-4166-abd0-8ceef92b158f.png)'
- en: The output indicates that the filter is making use of a technique known as fivefold `cross-validation`*. *In
    a nutshell, this means that `surprise`divides the data into five equal parts.
    It then uses four parts as the training data and tests it on the fifth part. This
    is done five times, in such a way that every part plays the role of the test data
    once.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果表明，过滤器采用了一种称为五重`交叉验证`*的技术*。简而言之，这意味着`surprise`将数据分为五个相等的部分。然后，它使用其中四部分作为训练数据，并在第五部分上进行测试。这个过程会进行五次，每次都确保每一部分都会充当一次测试数据。
- en: We see that the RMSE obtained by this model is 0.9784\. This is, by far, the
    best result we have achieved.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到该模型得到的RMSE为0.9784，这是目前为止我们取得的最好结果。
- en: Let's now take a tour of some other model-based approaches to collaborative
    filtering and implement a few of them using the *surprise *library.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看其他一些基于模型的协同过滤方法，并使用*surprise*库实现其中一些方法。
- en: Supervised learning and dimensionality reduction
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习与降维
- en: Consider our ratings matrix once again. It is of the *m* × *n* shape, where
    every row represents one of the *m* users and every column represents one of the *n *items.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 再次考虑我们的评分矩阵。它的形状是*m* × *n*，每一行代表*m*个用户之一，每一列代表*n*个物品之一。
- en: Let's now remove one of the *n *columns (say n[j]). We now have an *m *× (*n*-1)
    matrix. If we treat the *m* × (*n*-1) matrix as the predictor variables and n[j]
    as the target variable, we can use supervised learning algorithms to train on
    the values available in n[j] to predict values that are not. This can be repeated
    n times for every column to eventually complete our matrix.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们删除其中一列（比如n[j]）。我们现在得到的是一个*m* × (*n*-1)的矩阵。如果我们将*m* × (*n*-1)的矩阵视为预测变量，并将n[j]视为目标变量，就可以使用监督学习算法训练n[j]中已有的值，以预测其中缺失的值。对于每一列，我们可以重复这个过程n次，最终完成我们的矩阵。
- en: One big problem is that most supervised learning algorithms do not work with
    missing data. In standard problems, it is common practice to impute the missing
    values with the mean or median of the column it belongs to.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一个大问题是，大多数监督学习算法不能处理缺失数据。在标准问题中，通常会用所属列的均值或中位数来填充缺失值。
- en: However, our matrix suffers from heavy data sparsity. More than 99% of the data
    in the matrix is unavailable. Therefore, it is simply not possible to impute values
    (such as mean or median) without introducing a large bias.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的矩阵存在严重的数据稀疏问题。矩阵中超过99%的数据不可用。因此，简单地用均值或中位数填充缺失值是行不通的，因为这会引入大量偏差。
- en: One solution that may come to mind is to compress the predictor matrix in such
    a way that all the values are available. Unfortunately, dimensionality reduction
    techniques, such as SVD and PCA, also do not work in an environment with missing
    values.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 可能想到的一种解决方案是以某种方式压缩预测矩阵，以便所有的值都可以获得。不幸的是，像 SVD 和 PCA 这样的降维技术，在缺失值的环境中同样无法奏效。
- en: While working toward a solution for the Netflix Problem, Simon Funk came up
    with a solution that could be used to reduce the *m* × (*n*-1) matrix into a lower-dimensional
    *m* × *d* matrix where *d* << *n*. He used standard dimensionality-reduction techniques
    (in his case, the SVD) but with slight tweaks. Explaining the technique is outside
    the scope of this book, but is presented in the Appendix for advanced readers.
    For the sake of this chapter, we will treat this technique as a black box that
    converts an *m* × *n* sparse matrix into an *m* × *d* dense matrix where *d* <<
    *n*, and call it `SVD-like`*.*
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在为 Netflix 问题寻找解决方案的过程中，Simon Funk 提出了一个可以将 *m* × (*n*-1) 矩阵降维成一个低维的 *m* × *d*
    矩阵，其中 *d* << *n*。他使用了标准的降维技术（在他这里是 SVD），但是做了一些小的调整。解释这种技术超出了本书的范围，但它已在附录中为进阶读者介绍。为了本章的目的，我们将把这项技术视作一个黑盒，它将
    *m* × *n* 稀疏矩阵转换为 *m* × *d* 稠密矩阵，其中 *d* << *n*，并称之为 `SVD-like`*。
- en: Let's now turn our attention to perhaps the most famous recommendation algorithm
    of all time: singular-value decomposition*.*
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们把注意力转向或许是有史以来最著名的推荐算法：奇异值分解*。*
- en: Singular-value decomposition
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奇异值分解
- en: In [Chapter 5](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml), *Getting Started
    with Data Mining Techniques*, we mentioned that the math behind singular-value
    decomposition is well outside the scope of this book. However, let's try to gain
    an understanding of how it works from a layman's perspective.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 5 章](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml)，*数据挖掘技术入门* 中，我们提到过奇异值分解背后的数学超出了本书的范围。然而，让我们尝试从外行的角度理解它是如何工作的。
- en: Recall from [Chapter 5](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml), *Getting
    Started with Data Mining Techniques,* that **PCA** ( **Principal Component Analysis**)
    transforms an *m* × *n* matrix into *n*, *m*-dimensional vectors (called principal
    components) in such a way that each component is orthogonal to the next component.
    It also constructs these components in such a way that the first component holds
    the most variance (or information), followed by the second component, and so on.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下[第 5 章](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml)，*数据挖掘技术入门*，**PCA**（**主成分分析**）将一个
    *m* × *n* 矩阵转化为 *n* 个 *m* 维的向量（称为主成分），使得每个分量与下一个分量正交。它还构造这些分量的方式是，使得第一个分量包含最多的方差（或信息），接下来是第二个分量，以此类推。
- en: Let's denote our ratings matrix as *A**. *The transpose of this matrix would
    be *A**^T*, which would be of the *n* × *m* shape and each row would represent
    a movie (instead of a user).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将评分矩阵表示为 *A**。* 该矩阵的转置为 *A**^T*，它的形状为 *n* × *m*，每一行将表示一部电影（而不是一个用户）。
- en: We can now use PCA to construct two new matrices, *U *and *V*, from *A*and *A**^T*,
    respectively.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 PCA 从 *A* 和 *A**^T* 分别构建出两个新的矩阵，*U* 和 *V*。
- en: 'Singular-value decomposition allows us to compute *U *and *V *in one go from *A*:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 奇异值分解使我们能够一次性从 *A* 计算出 *U* 和 *V*：
- en: '![](img/37b83a39-36b7-47eb-b790-3981bedf634b.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/37b83a39-36b7-47eb-b790-3981bedf634b.png)'
- en: 'In essence, singular-value decomposition is a matrix-factorization technique.
    It takes in an input, *A*, and outputs *U *and *V *such that:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，奇异值分解是一种矩阵分解技术。它接收一个输入 *A*，并输出 *U* 和 *V*，使得：
- en: '![](img/2ddd6e73-d027-463c-bb87-1a9f7f0c262f.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2ddd6e73-d027-463c-bb87-1a9f7f0c262f.png)'
- en: 'Where ![](img/d4a5f097-a8e4-4459-9b20-2b07a31b5713.png) is a diagonal matrix.
    It is used for scaling purposes and, for the sake of this illustration, can be
    assumed to be merged with either *U *or *V. *Therefore, we now have:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![](img/d4a5f097-a8e4-4459-9b20-2b07a31b5713.png) 是一个对角矩阵。它用于缩放目的，在本示例中可以假设它与
    *U* 或 *V* 合并。因此，我们现在有：
- en: '![](img/fd8ec9cb-9e3f-47a1-9490-35d2da0d9290.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fd8ec9cb-9e3f-47a1-9490-35d2da0d9290.png)'
- en: The *U *matrix, which is essentially composed of user principal components,
    is typically called the user-embedding matrix. Its counterpart, *V*, is called
    the movie-embedding matrix.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '*U* 矩阵，本质上由用户的主成分组成，通常称为用户嵌入矩阵。它的对应矩阵 *V* 被称为电影嵌入矩阵。'
- en: The classic version of SVD, like most other machine learning algorithms, does
    not work with sparse matrices. However, Simon Funk figured out a workaround for
    this problem, and his solution led to one of the most famous solutions in the
    world of recommender systems.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: SVD 的经典版本和大多数其他机器学习算法一样，不适用于稀疏矩阵。然而，Simon Funk 找到了一个解决该问题的方法，他的解决方案成为了推荐系统领域最著名的解决方案之一。
- en: Funk's system took in the sparse ratings matrix, *A*, and constructed two dense
    user- and item-embedding matrices, *U *and *V *respectively. These dense matrices
    directly gave us the predictions for all the missing values in the original matrix, *A.*
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Funk 的系统将稀疏的评分矩阵 *A* 输入，并分别构建了两个稠密的用户和物品嵌入矩阵 *U* 和 *V*。这些稠密矩阵直接为我们提供了原始矩阵 *A*
    中所有缺失值的预测。
- en: 'Let''s now implement the SVD filter using the `surprise` package:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用 `surprise` 包来实现 SVD 滤波器：
- en: '[PRE21]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Here is its output**:**
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的输出**：**
- en: '![](img/833e3cf4-cefb-4416-8332-e958d03d2e84.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/833e3cf4-cefb-4416-8332-e958d03d2e84.png)'
- en: The SVD filter outperforms all other filters, with an RMSE score of 0.9367.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: SVD 滤波器的表现优于所有其他滤波器，RMSE 得分为 0.9367。
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This brings us to the end of our discussion on collaborative filters. In this
    chapter, we built various kinds of user-based collaborative filters and, by extension,
    learned to build item-based collaborative filters as well.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这也标志着我们对协同过滤讨论的结束。在这一章中，我们构建了各种基于用户的协同过滤器，并由此学会了构建基于物品的协同过滤器。
- en: We then shifted our focus to model-based approaches that rely on machine learning
    algorithms to churn out predictions. We were introduced to the *surprise *library
    and used it to implement a clustering model based on kNN. We then took a look
    at an approach to using supervised learning algorithms to predict the missing
    values in the ratings matrix. Finally, we gained a layman's understanding of the
    singular-value decomposition algorithm and implemented it using `surprise`*.*
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将注意力转向了基于模型的方法，这些方法依赖于机器学习算法来生成预测。我们介绍了 *surprise* 库，并使用它实现了基于 kNN 的聚类模型。接着我们看了一种使用监督学习算法预测评分矩阵中缺失值的方法。最后，我们以外行的视角理解了奇异值分解算法，并使用
    `surprise` 库实现了该算法*。*
- en: All the recommenders we've built so far reside only inside our Jupyter Notebooks.
    In the next chapter, we will learn how to deploy our models to the web, where
    they can be used by anyone on the internet.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们构建的所有推荐系统仅存在于我们的 Jupyter Notebook 中。在下一章，我们将学习如何将我们的模型部署到网络上，让任何人都能在互联网上使用它们。
