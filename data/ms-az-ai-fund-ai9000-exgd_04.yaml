- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Describe Core Machine Learning Concepts
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 描述核心机器学习概念
- en: In the previous chapters, you were introduced to some basic **machine learning**
    (**ML**) concepts, including various models and scenarios where a particular type
    of model might be useful. In this chapter, we’re going to explore concepts surrounding
    the actual data used in ML.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，您已经接触了一些基本的**机器学习**（**ML**）概念，包括各种模型以及特定类型的模型可能有用的场景。在本章中，我们将探讨围绕机器学习中实际使用的数据的概念。
- en: 'The objectives and skills we’ll cover in this chapter include the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下目标和技能：
- en: Identify features and labels in a dataset for machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在机器学习数据集中识别特征和标签
- en: Describe how training and validation datasets are used in machine learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述训练和验证数据集在机器学习中的应用
- en: By the end of this chapter, you should be able to clearly articulate the terminology
    surrounding ML.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您应该能够清楚地阐述围绕机器学习的术语。
- en: Identify features and labels in a dataset for machine learning
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在机器学习数据集中识别特征和标签
- en: As you learned in [*Chapter 3*](B22207_03.xhtml#_idTextAnchor042), *Identify
    Common Machine Learning Techniques*, **features** and **labels** are two fundamental
    concepts that define the data you work with when training ML models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在[*第3章*](B22207_03.xhtml#_idTextAnchor042)中学习到的，“*识别常见的机器学习技术*”，**特征**和**标签**是定义您在训练机器学习模型时使用的数据的两个基本概念。
- en: Features are individual measurable properties or characteristics of whatever
    is being observed. In ML models, features are used as input variables. These are
    the data points that you use to make predictions. For example, if you’re trying
    to predict the price of a house, the features might include the number of bedrooms,
    the size of the house in square feet, the neighborhood it’s in, how close it is
    to a fire station, or what the local property tax rates are. Features are represented
    by independent variables in your dataset that you believe will help you make accurate
    predictions about your target variable.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 特征是所观察到的任何事物的单个可测量属性或特征。在机器学习模型中，特征用作输入变量。这些是您用于做出预测的数据点。例如，如果您试图预测房屋的价格，特征可能包括卧室数量、房屋的平方英尺大小、所在社区、距离消防站的远近，或当地的财产税率。特征由您数据集中的独立变量表示，您认为这些变量将帮助您对目标变量做出准确的预测。
- en: Labels, on the other hand, are the output you’re trying to predict or classify.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**标签**是您试图预测或分类的输出。
- en: In **supervised learning** (**SL**), each training example includes a label.
    Continuing with the house pricing example, the label would be the actual selling
    price of the house.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在**监督学习**（**SL**）中，每个训练示例都包含一个标签。以房屋定价为例，标签将是房屋的实际售价。
- en: In classification tasks, labels are the categories assigned to data points.
    For instance, in an ML model trained to identify whether an email is spam or not,
    the labels might be “`spam`” and “`not spam`.”
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类任务中，标签是分配给数据点的类别。例如，在一个训练用于识别电子邮件是否为垃圾邮件的机器学习模型中，标签可能是“`垃圾邮件`”和“`非垃圾邮件`”。
- en: In this section, we’ll dive a little deeper into working with features and labels
    in your datasets.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将更深入地探讨在您的数据集中处理特征和标签。
- en: Identifying features in a dataset
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在数据集中识别特征
- en: Identifying features in an ML dataset involves understanding variables that
    can be used to predict the outcome (target variable). There are many things you
    can do to narrow down what’s important for your ML model.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习数据集中识别特征涉及理解可用于预测结果（目标变量）的变量。您可以通过许多方法来缩小对您的机器学习模型重要性的范围。
- en: Let’s go through them in this section.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在本节中逐一介绍。
- en: Understanding the problem domain
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解问题域
- en: Begin by understanding the domain or context of the problem. This involves researching
    the subject area to understand what factors might influence the outcome. For example,
    if you are working on a project to predict house prices, potential features could
    include the size of the house, the number of bedrooms, the number of bathrooms,
    the year it was built, the location, distance to fire stations, number of public
    libraries in the area, and statistics on the local school system.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，理解问题的领域或上下文。这涉及到研究该领域，以了解可能影响结果的因素。例如，如果您正在从事预测房价的项目，潜在的特征可能包括房屋的大小、卧室数量、浴室数量、建造年份、位置、距离消防站的距离、该地区的公共图书馆数量，以及当地教育系统的统计数据。
- en: When working through this step, it would likely be helpful to speak with domain
    experts to understand important variables. You could also look for existing literature,
    research, or studies to identify common predictors or variables used in similar
    problems.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行这一步骤时，与领域专家交谈以了解重要变量可能是有帮助的。你也可以寻找现有的文献、研究或研究，以确定在类似问题中使用的常见预测器或变量。
- en: Collecting data
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 收集数据
- en: Gather your data from relevant sources. This could include databases, reports,
    files, external APIs connected to industry data sources, or direct measurements.
    The data you collect will consist of various attributes or variables. You should
    work to ensure that the data collected is relevant to the problem domain and includes
    variables identified in your research of the subject matter.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从相关来源收集数据。这可能包括数据库、报告、文件、连接到行业数据源的API，或直接测量。你收集的数据将包括各种属性或变量。你应该努力确保收集到的数据与问题领域相关，并包括你在对主题研究中所确定的变量。
- en: For example, if you’re working on a model that’s going to predict housing prices,
    you’d likely look at data sources such as recent sale prices of houses in a particular
    zip code. Since you’d identified other features such as school system ratings
    and the distances to fire stations and libraries, you’d need to get that data
    as well—which would likely be from different data sources. You’d need to plot
    the distance from each house to the nearest library and fire station and add the
    dataset that you’ll be training a model with.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你正在构建一个预测房价的模型，你可能会查看特定邮编区最近房屋销售价格的数据源。由于你已经确定了其他特征，如学校系统评级以及到消防站和图书馆的距离，你需要获取这些数据——这很可能是来自不同的数据源。你需要绘制每栋房子到最近图书馆和消防站的距离，并添加你将用于训练模型的数据库集。
- en: Exploring the data
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索数据
- en: Perform **exploratory data analysis** (**EDA**) to get a feel for the data.
    This can include summarizing the statistics of the data, visualizing distributions
    and relationships between variables, and identifying any patterns or anomalies.
    Tools such as histograms, scatter plots, and correlation matrices can be useful
    here. You should also use statistical summaries (such as mean, median, mode, and
    standard deviation) to understand the distribution of each variable and identify
    areas where you have outliers.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 进行**探索性数据分析**（EDA）以了解数据。这可以包括总结数据的统计信息、可视化变量之间的分布和关系，以及识别任何模式或异常。工具如直方图、散点图和相关性矩阵在这里可能很有用。你还应该使用统计摘要（如均值、中位数、众数和标准差）来了解每个变量的分布，并确定存在异常值的地方。
- en: 'Here’s an example of a scatter plot:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个散点图的示例：
- en: '![Figure 4.1 – Scatter plot showing the relationship between housing price
    and square footage](img/B22207_04_01.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图4.1 – 显示房价与平方英尺之间关系的散点图](img/B22207_04_01.jpg)'
- en: Figure 4.1 – Scatter plot showing the relationship between housing price and
    square footage
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 – 显示房价与平方英尺之间关系的散点图
- en: Selecting relevant variables
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择相关变量
- en: Not all variables in your dataset may be relevant or necessary for predicting
    the outcome. Select variables that are likely to influence the target variable
    based on your domain knowledge and initial data exploration. Variables that show
    a correlation with the target variable are often good candidates for features.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你的数据集中并非所有变量都与预测结果相关或必要。根据你的领域知识和初步数据探索，选择可能影响目标变量的变量。与目标变量相关联的变量通常是特征的良好候选者。
- en: When identifying variables, it’s important to consider the practical significance
    of variables in addition to their statistical significance. For example, going
    back to the housing example, you may have learned that a house’s proximity to
    a library may not have a very big impact. During the EDA, you also may discover
    other variables that may seem important, such as proximity to a shopping center
    or the number of closets and storage areas.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在识别变量时，除了考虑变量的统计意义外，还重要的是要考虑变量的实际意义。例如，回到住房的例子，你可能已经了解到一栋房子靠近图书馆可能影响不大。在探索性数据分析（EDA）过程中，你也可能发现其他看似重要的变量，例如靠近购物中心或储藏室的数量。
- en: After reviewing your preliminary data, you may discover that you have missing
    attributes or values or that some data may be irrelevant to the problem context.
    Consider discarding that data since it may reduce the effectiveness of your model.
    Continue iterating until you settle in on relevant features.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在审查你的初步数据后，你可能会发现你有缺失的属性或值，或者某些数据可能与问题上下文无关。考虑丢弃这些数据，因为它们可能会降低你模型的有效性。继续迭代，直到你确定相关的特征。
- en: Feature engineering
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征工程
- en: This involves creating new features from existing ones through various techniques
    such as binning, aggregation, and combination of attributes. For example, from
    a dataset containing dates, you might extract features such as the day of the
    week, the month, or the year. Or, you may decide to collapse or combine multiple
    date ranges into fewer features.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及到通过各种技术（如分箱、聚合和属性组合）从现有特征中创建新特征。例如，从一个包含日期的数据集中，你可能可以提取出星期几、月份或年份等特征。或者，你可能会决定将多个日期范围合并成更少的特征。
- en: In the house pricing example, you may decide to aggregate data by month or week
    instead of having individual house prices by day. This may reduce some noise and
    help focus on trends more easily.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在房价示例中，你可能会决定按月或周汇总数据，而不是按日拥有单个房子的价格。这可能会减少一些噪声，并有助于更容易地关注趋势。
- en: 'Advanced techniques, such as polynomial features, can help capture non-linear
    relationships. In a house, a non-linear example might be the relationship between
    the number of bathrooms and closets. One method of creating a polynomial feature
    would be by multiplying two unrelated features together. In this example, you
    could multiply the number of bathrooms and closets: a house that has 3 bathrooms
    and 7 closets could have a new feature with a value of 21.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 高级技术，如多项式特征，可以帮助捕捉非线性关系。在一个房子中，一个非线性例子可能是浴室数量和壁橱数量之间的关系。创建多项式特征的一种方法是将两个无关特征相乘。在这个例子中，你可以将浴室数量和壁橱数量相乘：一个有3个浴室和7个壁橱的房子可以有一个值为21的新特征。
- en: Feature engineering can also involve transforming variables, such as scaling
    or normalizing, to make them more suitable for ML models. For example, you may
    decide to round housing prices to the nearest $25,000 or group houses by the number
    of bedrooms, such as 0-2, 3-4, 5-6, and 7+. Each of these techniques can be used
    to help streamline the data and help produce a clearer set of predictions.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程还可能涉及转换变量，如缩放或归一化，以使它们更适合机器学习模型。例如，你可能会决定将房价四舍五入到最接近的$25,000，或者根据卧室数量将房子分组，例如0-2、3-4、5-6和7+。这些技术中的每一个都可以用来帮助简化数据并帮助产生更清晰的预测集。
- en: Handling missing values
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理缺失值
- en: Decide how to handle missing data in your potential features. You might fill
    in missing values with the mean or median (imputation), discard them, or use a
    model to predict and fill them. Be sure to consider the reasons for missing data
    to determine if it’s random or not.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 决定如何处理潜在特征中的缺失数据。你可能用平均值或中位数（插补）来填充缺失值，丢弃它们，或者使用模型来预测并填充它们。务必考虑缺失数据的原因，以确定它是随机还是非随机的。
- en: Removing irrelevant or redundant features
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 移除无关或冗余特征
- en: Eliminate features that are irrelevant to the outcome or that duplicate information
    contained in other features. Redundant or irrelevant features can introduce noise
    and lead to overfitting. As you develop the model, you may discover that you need
    to remove features to help refine the model to produce better results.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 消除与结果无关或包含在其他特征中信息的特征。冗余或不相关的特征可能会引入噪声并导致过拟合。随着你开发模型，你可能会发现你需要删除特征来帮助细化模型以产生更好的结果。
- en: Consulting with experts
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 咨询专家
- en: If possible, consult with domain experts to validate your selection of features
    and data sources. They might provide insights into which variables are most influential
    or suggest additional variables that you hadn’t considered, as well as indicate
    any known biases for your data source selections.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，咨询领域专家以验证你的特征和数据源选择。他们可能会提供关于哪些变量最有影响力的见解，或者建议你考虑一些你尚未考虑的变量，以及指出你数据源选择中任何已知的偏差。
- en: Using feature selection techniques
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用特征选择技术
- en: 'There are automated feature selection techniques such as **forward selection**,
    **backward elimination**, and **recursive feature elimination** that can help
    identify the most important features based on statistical tests or model performance:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 存在着一些自动特征选择技术，如**前向选择**、**后向消除**和**递归特征消除**，可以根据统计测试或模型性能帮助识别最重要的特征：
- en: '**Forward selection**: Forward selection is a feature selection technique used
    to build a model by iteratively adding one feature at a time, starting with the
    most significant or promising feature. The process continues until a stopping
    criterion is met, such as reaching a predetermined number of features or until
    the addition of new features no longer improves the model’s performance significantly.
    For example, with our house pricing example, this might mean starting with overall
    square footage as the most promising feature that has an impact on the price of
    a house, and then in the next iteration, add the number of bedrooms.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正向选择**：正向选择是一种特征选择技术，通过逐个添加特征来构建模型，从最显著或最有潜力的特征开始。这个过程会持续进行，直到满足停止标准，比如达到预定的特征数量，或者直到新特征的添加不再显著提高模型性能。例如，在我们的房屋定价示例中，这可能意味着从对房屋价格有影响的、最有潜力的总面积特征开始，然后在下一次迭代中添加卧室数量。'
- en: '**Backward elimination**: This is simply the opposite process of forward selection.
    Instead of adding features until the model doesn’t change, you start with all
    of the features to train a model and take out features until the stopping criterion
    is met—such as the number of features remaining or until the removal of features
    no longer improves the model.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反向消除**：这仅仅是正向选择的相反过程。不是添加特征直到模型不再变化，而是从所有特征开始训练一个模型，然后移除特征直到满足停止标准——比如剩余特征的数量，或者直到移除特征不再显著提高模型性能。'
- en: '**Recursive feature elimination**: Similar to backward elimination, recursive
    feature elimination is a process that starts with a full set of features and then
    removes them. Whereas backward elimination simply removes the least significant
    features, recursive feature elimination removes features based on their importance
    and interaction with other features.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**递归特征消除**：与反向消除类似，递归特征消除是一个从完整特征集开始然后移除特征的过程。而反向消除只是简单地移除最不显著的特征，递归特征消除则是根据特征的重要性和与其他特征的交互来移除特征。'
- en: You’ll want to temper any automated feature selection tools with domain knowledge,
    expert insight, and data understanding to ensure you’re choosing the most appropriate
    set of features.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要用领域知识、专家见解和数据理解来调整任何自动化的特征选择工具，以确保你选择的是最合适的特征集。
- en: Remember—model development is an iterative process. As you build and develop
    your models, you might discover that some features are more important than others
    or that some can be removed without decreasing model performance (in regard to
    accuracy).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 记住——模型开发是一个迭代的过程。随着你构建和发展你的模型，你可能会发现某些特征比其他特征更重要，或者某些特征可以被移除而不降低模型性能（就准确性而言）。
- en: Identifying labels in a dataset
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在数据集中识别标签
- en: Identifying labels in an ML dataset involves understanding the outcome or target
    variable that your model aims to predict. Here’s how you can identify labels in
    a dataset.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习数据集中识别标签涉及理解模型旨在预测的结果或目标变量。以下是你在数据集中识别标签的方法。
- en: Defining the objective
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义目标
- en: Start by clearly defining the objective of your ML project. Are you trying to
    predict a continuous value (regression), classify data into categories (classification),
    or identify groups of similar instances (clustering)? Your objective will guide
    what your label should be.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，明确定义你的机器学习项目的目标。你是试图预测一个连续值（回归）、将数据分类到类别中（分类），还是识别相似实例的组（聚类）？你的目标将指导你的标签应该是什么。
- en: Understanding the data
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 理解数据
- en: Examine your dataset and understand each variable. In SL, the label is the variable
    that is being predicted, which could be the outcome of an event, the classification
    category, or the future value of a series.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 检查你的数据集并理解每个变量。在监督学习（SL）中，标签是正在预测的变量，这可能是事件的结果、分类类别或序列的未来值。
- en: Identifying the target variable
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别目标变量
- en: In most datasets used for SL, there is usually a specific column that serves
    as the target variable (label). This could be a column indicating “Yes” or “No”
    for a binary classification problem, a numerical value for a regression problem,
    or category labels for a multiclass classification problem.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数用于监督学习的数据集中，通常有一个特定的列作为目标变量（标签）。这可能是一个表示二分类问题中“是”或“否”的列，回归问题中的数值，或多类分类问题中的类别标签。
- en: Consulting domain experts
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 咨询领域专家
- en: If it’s not clear which variable should be used as the label, consult with domain
    experts or stakeholders of your ML project. They can provide insights into what
    predictions would be most valuable based on the dataset, business outcomes, and
    research objectives.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不清楚应该使用哪个变量作为标签，请咨询您的机器学习项目的领域专家或利益相关者。他们可以根据数据集、业务成果和研究目标提供有关哪些预测最有价值的见解。
- en: Exploring the data
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索数据
- en: Use EDA to better understand potential labels. For instance, if you’re working
    with a dataset where the objective is to predict whether an email is spam or not,
    the label could be a column indicating “spam” or “not spam.” Look for a column
    or other output with categorical or binary data that fits the problem you are
    trying to solve.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用EDA（探索性数据分析）更好地理解潜在的标签。例如，如果您正在处理一个旨在预测电子邮件是否为垃圾邮件的数据集，标签可能是一个表示“垃圾邮件”或“非垃圾邮件”的列。寻找一个或其他的输出，其中包含符合您试图解决的问题的类别或二元数据。
- en: Checking data documentation
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检查数据文档
- en: If your dataset comes with documentation or a **data dictionary**, review this
    material to understand the role of each variable. Often, the documentation will
    explicitly state which column is the target variable (label) for prediction. If
    the documentation doesn’t identify the label, it may provide insights about existing
    fields or column names to help you determine a label.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据集附带文档或**数据字典**，请查阅这些材料以了解每个变量的作用。通常，文档会明确指出哪个列是预测的目标变量（标签）。如果文档没有识别标签，它可能提供有关现有字段或列名的见解，以帮助您确定标签。
- en: Look for pre-labeled data; in some cases, especially in SL tasks, datasets are
    already labeled. This means that for each record, there is an accompanying label
    that has been previously determined. This is common in datasets used for training
    models, where the goal is to learn the relationship between input features and
    labels.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找预标记数据；在某些情况下，特别是在SL任务中，数据集已经标记。这意味着对于每条记录，都有一个之前已确定的伴随标签。这在用于训练模型的数据库中很常见，其目标是学习输入特征和标签之间的关系。
- en: Considering the problem type
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 考虑问题类型
- en: The nature of your label depends on the type of problem you are trying to use
    ML to solve.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 您的标签性质取决于您试图使用机器学习解决的问题类型。
- en: For classification, labels are categorical and represent different classes (for
    example, “spam” or “not spam” for binary classification dealing with whether an
    email is junk mail or not; “cat,” “dog,” and “bird” for multiclass classification
    identifying animals from pictures).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类，标签是分类的，代表不同的类别（例如，对于二元分类处理电子邮件是否为垃圾邮件的情况，“垃圾邮件”或“非垃圾邮件”；对于多类分类识别图片中的动物，“猫”、“狗”和“鸟”）。
- en: For regression, labels are continuous values (such as house prices or temperatures).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归，标签是连续值（例如房价或温度）。
- en: For clustering (an **unsupervised learning** (**UL**) task), labels are not
    provided, and the goal is to discover them through the grouping of similar data
    points.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于聚类（一种**无监督学习**（**UL**）任务），不提供标签，目标是通过对相似数据点的分组来发现它们。
- en: Cleaning the data
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 清洗数据
- en: Ensure your label data is clean and consistent. This might involve correcting
    mislabeling, handling missing values, and ensuring labels are in a format that
    can be used for modeling (for example, converting strings to numerical categories).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您的标签数据干净且一致。这可能涉及纠正错误标记、处理缺失值，并确保标签以可用于建模的格式（例如，将字符串转换为数值类别）。
- en: As you develop your model, you may need to revisit and re-evaluate your choice
    of labels (just as you may need to revisit your choice of features). The effectiveness
    of your model in predicting these labels will help you understand if you have
    identified the correct labels or if adjustments are needed.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发您的模型时，您可能需要重新审视并重新评估您选择的标签（就像您可能需要重新审视您选择的功能一样）。您的模型在预测这些标签方面的有效性将帮助您了解是否已识别正确的标签或是否需要调整。
- en: Describe how training and validation datasets are used in machine learning
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 描述在机器学习中如何使用训练集和验证集
- en: In ML, **training** and **validation** sets are subsets of your overall dataset
    used during the model development phase. Their roles are distinct but complementary,
    aimed at creating a model that is able to make accurate predictions about new,
    unseen data.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，**训练**集和**验证**集是模型开发阶段中使用的整体数据集的子集。它们的作用是不同的但互补的，旨在创建一个能够对新、未见数据做出准确预测的模型。
- en: You may recall seeing the concepts of training and validation sets in [*Chapter
    3*](B22207_03.xhtml#_idTextAnchor042)*, Identify Common Machine Learning Techniques*
    when we discussed dividing the dataset into sections—a subset that would be used
    to train the model, and a “held back” or “reserved” part of the data that we could
    use to test the predictions. These are the training and validation sets, respectively.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能记得在我们讨论将数据集划分为部分——一部分用于训练模型，另一部分“保留”或“预留”用于测试预测时，在[*第3章*](B22207_03.xhtml#_idTextAnchor042)*中看到的训练集和验证集的概念。这些分别是训练集和验证集。
- en: Training set
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练集
- en: This is the data on which the ML model is trained. The model learns to make
    predictions or decisions based on this data. The training set is used to fit the
    parameters of the model, such as the weights in a **neural network** (**NN**)
    or the coefficients in linear regression.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于训练ML模型的实际数据。模型通过这些数据学习如何进行预测或决策。训练集用于拟合模型的参数，例如**神经网络**（**NN**）中的权重或线性回归中的系数。
- en: The training set in ML is the actual dataset used to train the model. Training
    involves adjusting the model’s parameters to minimize errors, typically through
    a process known as learning. The size and quality of the training set can significantly
    influence the performance of the ML model. A larger training set provides more
    examples from which the model can learn, potentially leading to better generalization
    when the model is used to make predictions on new data. However, the data must
    also be representative of the real-world scenario the model will be applied to,
    encompassing a broad range of examples and variations.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在ML中，训练集是用于训练模型的实际数据集。训练涉及调整模型的参数以最小化错误，通常通过称为学习的过程来完成。训练集的大小和质量可以显著影响ML模型的表现。较大的训练集提供了更多模型可以从中学习的示例，当模型用于对新数据进行预测时，可能有助于提高泛化能力。然而，数据也必须代表模型将要应用的现实世界场景，包括广泛的示例和变化。
- en: During the training phase, the model iteratively adjusts its parameters to reduce
    the difference between the predicted output and the actual output, as defined
    by a specific mathematical loss function. This process can vary depending on the
    type of model and learning algorithm. For instance, in SL, each example in the
    training set includes both the input features and the corresponding target label.
    The model uses these pairs to learn underlying patterns in the data. In UL, where
    there are no labels, the model tries to learn the underlying structure of the
    data based on the input features alone.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练阶段，模型会迭代地调整其参数，以减少预测输出与实际输出之间的差异，这种差异由特定的数学损失函数定义。这个过程可能因模型类型和学习算法的不同而有所差异。例如，在SL中，训练集中的每个示例都包含输入特征和相应的目标标签。模型使用这些成对的数据来学习数据中的潜在模式。在UL中，由于没有标签，模型试图仅基于输入特征来学习数据的潜在结构。
- en: The effectiveness of the training process (in both SL and UL) is largely dependent
    on the quality of the training data, the volume of data in the training set, the
    relevance of the features selected, and the suitability of the model for the problem
    at hand. If possible, training on actual data (as opposed to synthetic data) is
    preferred, as it helps the model learn about natural outliers and variances. Sometimes,
    however, due to privacy or other responsible **artificial intelligence** (**AI**)
    development principles, actual data may not be available.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程（无论是SL还是UL）的有效性在很大程度上取决于训练数据的质量、训练集中数据量的大小、所选特征的相关性以及模型对所涉及问题的适用性。如果可能的话，使用实际数据（而非合成数据）进行训练是首选的，因为这有助于模型了解自然异常值和变异性。然而，有时由于隐私或其他负责任的**人工智能**（**AI**）开发原则，实际数据可能不可用。
- en: Generating your own training data
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 生成自己的训练数据
- en: You may also want to consider asking a **generative AI** (**GenAI**) model to
    create training data for you. This may be useful in helping you understand relationships
    between features or protecting privacy if a potential dataset contains personal
    information. However, training data generated by an AI model can also amplify
    any bias in the data that was used to train the generative model, leading to skewed
    or unrealistic training data. In either case, when using GenAI, you’ll need to
    take precautions to ensure that the data is representative of what you’re trying
    to achieve.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还想考虑请求一个**生成式AI**（**GenAI**）模型为你创建训练数据。这可能有助于你理解特征之间的关系，或者在潜在的数据集中包含个人信息时保护隐私。然而，由AI模型生成的训练数据也可能放大用于训练生成模型的原始数据中的任何偏差，导致训练数据出现偏差或不切实际。在任何情况下，当使用GenAI时，你需要采取预防措施，以确保数据能够代表你试图实现的目标。
- en: Typically, the training set constitutes a larger portion of the entire dataset,
    often ranging from 60% to 80%. The aim is to provide the model with a diverse
    and comprehensive set of examples that mirror the real-world scenarios in which
    it will be applied.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，训练集占整个数据集的较大比例，通常在60%到80%之间。目标是向模型提供一组多样化的、全面的示例，这些示例反映了模型将被应用的现实世界场景。
- en: If you’re asking yourself, “How do I know if the model is trained well enough?”
    or “How will I know when I’m done training?” that’s where validation sets come
    in.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在问自己，“我如何知道模型是否训练得足够好？”或者“我何时知道训练完成？”那么这就是验证集发挥作用的地方。
- en: Validation set
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证集
- en: This subset of the dataset is used to provide an unbiased evaluation of a model
    fit on the training dataset while tuning the model’s **hyperparameters** (settings
    or configurations that are not learned from the data) that the model is unable
    to adjust automatically. The validation set acts as a proxy for the test set since
    it is not used for training the model and hence can help in estimating how well
    the model has generalized to unseen data. Typically, the validation set might
    be about 20% to 30% of the entire dataset.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集的子集用于在调整模型无法自动调整的**超参数**（设置或配置，这些不是从数据中学习的）时，提供一个对训练数据集上模型拟合的无偏评估。验证集作为测试集的代理，因为它不用于训练模型，因此可以帮助估计模型对未见数据的泛化程度。通常，验证集可能占整个数据集的20%到30%。
- en: It is crucial to avoid **overfitting** (sometimes referred to as **overtraining**),
    a situation where the model performs well on the training data but poorly on new,
    unseen data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 避免过度拟合（有时也称为过度训练）至关重要，过度拟合是指模型在训练数据上表现良好，但在新的、未见过的数据上表现不佳。
- en: What’s a hyperparameter?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是超参数？
- en: An ML model hyperparameter is a configuration setting that is external to the
    model and influences its learning process. Unlike model parameters, which are
    learned from the training data, hyperparameters are predefined by the user and
    affect aspects such as model complexity, regularization, and optimization. Examples
    include the learning rate in gradient descent, the depth of a decision tree, or
    the number of hidden layers in an NN. Hyperparameter tuning is crucial for optimizing
    model performance. Don’t worry, though—from the perspective of the *AI-900* exam,
    the important concept is that hyperparameters are external to the model.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型超参数是模型外部的配置设置，它影响其学习过程。与从训练数据中学习的模型参数不同，超参数是由用户预先定义的，并影响模型复杂度、正则化和优化等方面。例如，梯度下降中的学习率、决策树的深度或神经网络中的隐藏层数量。超参数调整对于优化模型性能至关重要。不过，不用担心——从*AI-900*考试的角度来看，重要的概念是超参数是模型外部的。
- en: Using a validation set helps detect issues such as **overfitting**. Overfitting
    happens when a model learns noise or random fluctuations in the training data
    instead of actual underlying patterns. By evaluating the model on the validation
    set, you can identify when overfitting is occurring and take steps to mitigate
    it, such as simplifying the model, applying regularization techniques, or obtaining
    more training data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用验证集有助于检测过度拟合等问题。过度拟合发生在模型学习训练数据中的噪声或随机波动，而不是实际的潜在模式。通过在验证集上评估模型，你可以确定何时发生过度拟合，并采取措施减轻它，例如简化模型、应用正则化技术或获取更多训练数据。
- en: Additionally, the validation set allows for the comparison of different models
    and configurations in a controlled manner. After the model has been trained on
    the training set, its performance on the validation set provides an unbiased evaluation.
    Only after the model has been optimized and selected based on its performance
    on the validation set should it be tested on the test set to assess its generalization
    capabilities to new, unseen data. This approach ensures that the final evaluation
    of the model is based on data that has not been used during the training or validation
    phases, providing a more accurate measure of its predictive performance and generalization
    ability.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，验证集允许以受控的方式比较不同的模型和配置。在模型在训练集上训练后，它在验证集上的表现提供了一个无偏的评价。只有在模型根据其在验证集上的表现进行优化和选择后，才应该在测试集上对其进行测试，以评估其对新、未见数据的泛化能力。这种方法确保了模型的最终评估是基于在训练或验证阶段未使用的数据，从而提供了对其预测性能和泛化能力的更准确衡量。
- en: The process usually involves training the model on the training set and then
    evaluating its performance on the validation set. Based on this evaluation, adjustments
    can be made to the model’s configuration. Once the model performs satisfactorily
    on the validation set, it can then be tested on a separate test set to further
    evaluate its performance in a completely unseen data scenario. This practice helps
    ensure that the model is not just memorizing the training data but actually learning
    patterns that are generalizable.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程通常涉及在训练集上训练模型，然后评估其在验证集上的性能。根据这一评估，可以对模型的配置进行调整。一旦模型在验证集上表现满意，它就可以在单独的测试集上测试，以进一步评估其在完全未见数据场景中的性能。这种做法有助于确保模型不仅仅是记住训练数据，而是在学习可泛化的模式。
- en: Summary
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter expanded on concepts relating to data in regard to ML. You learned
    about techniques for identifying features and labels in datasets as well as techniques
    for ensuring data is suitable for learning. You learned about the concepts and
    purposes of both the training set and validation set as well.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 本章扩展了与机器学习中的数据相关的概念。你学习了在数据集中识别特征和标签的技术，以及确保数据适合学习的技术。你还学习了训练集和验证集的概念和目的。
- en: In the next chapter, we’ll dive a little deeper into Azure Machine Learning
    concepts and capabilities.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更深入地探讨Azure机器学习的概念和能力。
- en: Exam Readiness Drill – Chapter Review Questions
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 考试准备练习 – 本章复习题
- en: Apart from a solid understanding of key concepts, being able to think quickly
    under time pressure is a skill that will help you ace your certification exam.
    That is why working on these skills early on in your learning journey is key.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对关键概念有扎实的理解外，能够在时间压力下快速思考是一项帮助你通过认证考试的关键技能。这就是为什么在学习的早期阶段就培养这些技能至关重要。
- en: Chapter review questions are designed to improve your test-taking skills progressively
    with each chapter you learn and review your understanding of key concepts in the
    chapter at the same time. You’ll find these at the end of each chapter.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 本章复习题旨在通过学习每一章并复习章节中的关键概念来逐步提高你的应试技巧。你将在每一章的末尾找到这些复习题。
- en: Before you proceed
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在你继续之前
- en: If you don't have a Packt Library subscription or you haven't purchased this
    book from the Packt store, you will need to unlock the online resources to access
    the exam readiness drills. Unlocking is free and needs to be done only once. To
    learn how to do that, head over to the chapter titled [*Chapter 12*](B22207_12.xhtml#_idTextAnchor228)*,
    Accessing the* *Online Resources*.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有Packt图书馆订阅或没有从Packt商店购买这本书，你需要解锁在线资源以访问考试准备练习。解锁是免费的，并且只需要进行一次。要了解如何操作，请参阅名为[*第12章*](B22207_12.xhtml#_idTextAnchor228)*的章节，*访问在线资源*。
- en: 'To open the Chapter Review Questions for this chapter, perform the following
    steps:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要打开本章的复习题，请执行以下步骤：
- en: Click the link – [https://packt.link/AI-900_CH04](https://packt.link/AI-900_CH04).
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击链接 – [https://packt.link/AI-900_CH04](https://packt.link/AI-900_CH04)。
- en: 'Alternatively, you can scan the following QR code (*Figure 4**.2*):'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者，你可以扫描以下二维码（*图4.2*）：
- en: '![Figure 4.2 – QR code that opens Chapter Review Questions for logged-in users](img/B22207_04_02.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图4.2 – 为已登录用户打开本章复习题的二维码](img/B22207_04_02.jpg)'
- en: Figure 4.2 – QR code that opens Chapter Review Questions for logged-in users
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2 – 为已登录用户打开本章复习题的二维码
- en: 'Once you log in, you’ll see a page similar to the one shown in *Figure 4**.3*:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录后，你会看到一个类似于 *图 4.3* 所示的页面：
- en: '![Figure 4.3 – Chapter Review Questions for Chapter 4](img/B22207_04_03.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3 – 第四章复习题](img/B22207_04_03.jpg)'
- en: Figure 4.3 – Chapter Review Questions for Chapter 4
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – 第四章复习题
- en: Once ready, start the following practice drills, re-attempting the quiz multiple
    times.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备就绪后，开始以下练习，多次重新尝试测验。
- en: Exam Readiness Drill
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 考试准备练习
- en: For the first three attempts, don’t worry about the time limit.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前三次尝试，不必担心时间限制。
- en: ATTEMPT 1
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尝试 1
- en: The first time, aim for at least **40%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix your learning gaps.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次尝试，目标至少达到 **40%**。查看你答错的答案，并再次阅读章节中的相关部分，以修复你的学习差距。
- en: ATTEMPT 2
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尝试 2
- en: The second time, aim for at least **60%**. Look at the answers you got wrong
    and read the relevant sections in the chapter again to fix any remaining learning
    gaps.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次尝试，目标至少达到 **60%**。查看你答错的答案，并再次阅读章节中的相关部分，以修复任何剩余的学习差距。
- en: ATTEMPT 3
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尝试 3
- en: The third time, aim for at least **75%**. Once you score 75% or more, you start
    working on your timing.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 第三次尝试，目标至少达到 **75%**。一旦得分达到 75% 或以上，你就可以开始练习时间管理。
- en: Tip
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: You may take more than **three** attempts to reach 75%. That’s okay. Just review
    the relevant sections in the chapter till you get there.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要超过 **三次** 尝试才能达到 75%。这没关系。只需复习章节中的相关部分，直到达到目标。
- en: Working On Timing
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习时间管理
- en: 'Your aim is to keep the score the same while trying to answer these questions
    as quickly as possible. Here’s an example of how your next attempts should look
    like:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 你的目标是保持分数不变，同时尽可能快地回答这些问题。以下是你下一次尝试的一个示例：
- en: '| **Attempt** | **Score** | **Time Taken** |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| **尝试** | **分数** | **用时** |'
- en: '| --- | --- | --- |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Attempt 5 | 77% | 21 mins 30 seconds |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 尝试 5 | 77% | 21 分 30 秒 |'
- en: '| Attempt 6 | 78% | 18 mins 34 seconds |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 尝试 6 | 78% | 18 分 34 秒 |'
- en: '| Attempt 7 | 76% | 14 mins 44 seconds |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 尝试 7 | 76% | 14 分 44 秒 |'
- en: Table 4.1 – Sample timing practice drills on the online platform
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.1 – 在线平台上的样本时间练习
- en: Note
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: The time limits shown in the above table are just examples. Set your own time
    limits with each attempt based on the time limit of the quiz on the website.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 上表中显示的时间限制只是示例。根据网站上的测验时间限制，为每次尝试设定自己的时间限制。
- en: With each new attempt, your score should stay above **75%** while your “time
    taken” to complete should “decrease”. Repeat as many attempts as you want till
    you feel confident dealing with the time pressure.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 每次新的尝试，你的分数应保持在 **75%** 以上，而完成所需的时间“应减少”。重复尝试，直到你觉得自己能够应对时间压力。
