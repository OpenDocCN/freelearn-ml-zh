- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Security, Governance, and Compliance Strategies
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全、治理和合规策略
- en: In the first eight chapters of this book, we focused on getting our **machine
    learning** (**ML**) experiments and deployments working in the cloud. In addition
    to this, we were able to analyze, clean, and transform several sample datasets
    using a variety of services. For some of the hands-on examples, we made use of
    synthetically generated datasets that are relatively safe to work with from a
    security standpoint (since these datasets do not contain **personally identifiable
    information** (**PII**)). We were able to accomplish a lot of things in the previous
    chapters, but it is important to note that getting the **data engineering** and
    **ML engineering** workloads running in our AWS account is just the first step!
    Once we need to work on production-level ML requirements, we have to worry about
    other challenges concerning the **security**, **governance**, and **compliance**
    of the ML systems and processes. To solve these challenges, we have to use a variety
    of solutions and techniques that help us prevent, detect, mitigate, and report
    these issues.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的前八章中，我们专注于使我们的**机器学习**（**ML**）实验和部署在云中运行。除此之外，我们还能够使用各种服务分析、清理和转换几个样本数据集。对于一些动手实践示例，我们使用了从安全角度相对安全（因为这些数据集不包含**个人身份信息**（**PII**））的合成数据集。在前几章中，我们能够完成很多事情，但重要的是要注意，在我们的AWS账户中运行**数据工程**和**机器学习工程**工作负载只是第一步！一旦我们需要处理生产级别的机器学习需求，我们就必须担心其他与机器学习系统和流程的**安全**、**治理**和**合规**相关的问题。为了解决这些挑战，我们必须使用各种解决方案和技术，帮助我们预防、检测、减轻和报告这些问题。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Managing the security and compliance of ML environments
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理机器学习环境的安全和合规性
- en: Preserving data privacy and model privacy
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保护数据隐私和模型隐私
- en: Establishing ML governance
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立机器学习治理
- en: In contrast to the other chapters in this book, this chapter will not include
    complete step-by-step solutions as we will talk about a broad range of security
    topics. These topics will cover the different strategies and techniques regarding
    how to secure the different services and solutions we discussed in the previous
    chapters. For each of these topics, we will dive a bit deeper into the relevant
    subtopics. We will also discuss several security best practices that can easily
    be implemented on top of existing ML environments running on AWS. With these objectives
    in mind, let’s begin!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 与本书中的其他章节不同，本章将不会包括完整的分步解决方案，因为我们将会讨论广泛的网络安全主题。这些主题将涵盖如何保护我们在前几章中讨论的不同服务和解决方案的不同策略和技术。对于这些主题中的每一个，我们将更深入地探讨相关的子主题。我们还将讨论一些可以在现有的AWS上运行的机器学习环境中轻松实施的网络安全最佳实践。带着这些目标，让我们开始吧！
- en: Managing the security and compliance of ML environments
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理机器学习环境的安全和合规性
- en: 'Data science teams generally spend a big portion of their time processing the
    data, training the ML model, and deploying the model to an inference endpoint.
    Due to the amount of work and research required to succeed in their primary objectives,
    these teams often deprioritize any “additional work” concerning security and compliance.
    After a few months of running production-level ML workloads in the cloud, these
    teams may end up experiencing a variety of security-related issues due to the
    following reasons:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学团队通常花费大量时间处理数据、训练机器学习模型并将模型部署到推理端点。由于成功实现其主要目标所需的工作和研究量很大，这些团队往往将任何关于安全性和合规性的“额外工作”放在次要位置。在云中运行了几个月的生产级别机器学习工作负载后，这些团队可能会因为以下原因而遇到各种与安全相关的问题：
- en: '*A lack of understanding and awareness of the importance of security, governance,
    and compliance*'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*对安全、治理和合规重要性缺乏理解和认识*'
- en: '*Poor awareness of the relevant compliance regulations and policies*'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*对相关合规法规和政策缺乏了解和认识*'
- en: '*The absence of solid security processes and standards*'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*缺乏稳固的安全流程和标准*'
- en: '*Poor internal tracking and reporting mechanisms*'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*内部跟踪和报告机制不佳*'
- en: 'To have a better idea of how to properly manage and handle these issues, we
    will dive deeper into the following topics in this section:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解如何正确管理和处理这些问题，我们将在本节中深入探讨以下主题：
- en: Authentication and authorization
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 身份验证和授权
- en: Network security
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络安全
- en: Encryption at rest and in transit
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静态和传输中的加密
- en: Managing compliance reports
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理合规报告
- en: Vulnerability management
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 漏洞管理
- en: We will start with the best practices on how to work with the **AWS Identity
    and Access Management** (**IAM**) service when securing the different ML engineering
    and data engineering services we used in the previous chapters.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从如何在与前几章中使用的不同机器学习和数据工程服务进行安全工作时与**AWS身份和访问管理**（**IAM**）服务一起工作的最佳实践开始。
- en: Authentication and authorization
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 认证和授权
- en: In [*Chapter 4*](B18638_04.xhtml#_idTextAnchor079), *Serverless Data Management
    on AWS*, we created an IAM user and attached a few existing policies to it. In
    addition to this, we created and attached a custom inline policy that gives the
    IAM user the necessary permissions to manage **Redshift Serverless** and **Lake
    Formation** resources. If you have worked on the hands-on solutions of said chapter,
    you have probably wondered, *Why go through all the trouble of setting this up?*
    For one thing, at the time of writing, Redshift Serverless does not support queries
    being executed using the root account. At the same time, using an IAM user with
    a limited set of permissions is more secure than using the root account directly.
    This limits the harm an attacker can do in case the user account gets compromised.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第4章*](B18638_04.xhtml#_idTextAnchor079)“AWS上的无服务器数据管理”中，我们创建了一个IAM用户并将其附加到一些现有的策略上。除此之外，我们还创建并附加了一个自定义内联策略，该策略为IAM用户提供了管理**Redshift
    Serverless**和**Lake Formation**资源的必要权限。如果你已经完成了该章节的动手解决方案，你可能已经想知道，“为什么要费这么大的劲来设置这个？”。一方面，在撰写本文时，Redshift
    Serverless不支持使用根账户执行查询。同时，使用具有有限权限集的IAM用户比直接使用根账户更安全。这限制了攻击者在用户账户被入侵时可能造成的损害。
- en: Note
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In our example, if the IAM (non-root) user account gets compromised, an attacker
    can only do damage to our Redshift Serverless and Lake Formation resources (unless
    they can perform a **privilege escalation attack**). We will talk about this topic
    in detail in a bit!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，如果IAM（非根）用户账户被入侵，攻击者只能对我们的Redshift Serverless和Lake Formation资源造成损害（除非他们能够执行**权限提升攻击**）。我们将在稍后详细讨论这个话题！
- en: If the access keys and/or credentials of the root account get stolen, an attacker
    will have full access to all the resources of all AWS services. On the other hand,
    if the access keys and/or credentials of an IAM user with a limited set of permissions
    get stolen, the attacker will only have access to the resources accessible to
    the IAM user.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果根账户的访问密钥和/或凭证被盗，攻击者将能够访问所有AWS服务的所有资源。另一方面，如果具有有限权限集的IAM用户的访问密钥和/或凭证被盗，攻击者将只能访问IAM用户可访问的资源。
- en: 'Let’s say that we have accidentally pushed the following code to a public repository
    in GitHub or GitLab:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们不小心将以下代码推送到GitHub或GitLab的公共仓库中：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Assuming that the credentials used here are linked to a root account user, an
    attacker can use these credentials to do “extensive damage,” such as deleting
    all existing resources in the account or creating new resources that will be used
    to attack other accounts.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这里使用的凭证与一个根账户用户相关联，攻击者可以使用这些凭证造成“广泛的破坏”，例如删除账户中所有现有的资源或创建将被用于攻击其他账户的新资源。
- en: Note
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '*How?* One possible move is for the hacker to configure the AWS CLI using the
    credentials obtained from the source code and history pushed to the public repository,
    and then run AWS CLI commands that terminate all the running resources in the
    AWS account.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*如何操作？* 一个可能的行动是黑客使用从源代码和历史记录中获取的凭证配置AWS CLI，然后运行AWS CLI命令，终止AWS账户中所有正在运行的资源。'
- en: 'To prevent such a scenario from happening, we can use the following block of
    code instead:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止出现这种情况，我们可以使用以下代码块代替：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, we are expecting `boto3` to automatically locate and use the credentials
    from the environment where the script is running. For example, if the script is
    running inside an AWS Cloud9 environment, the credentials may be stored inside
    the `~/.aws` directory.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们期望`boto3`能够自动定位并使用脚本运行环境中的凭证。例如，如果脚本在AWS Cloud9环境中运行，凭证可能存储在`~/.aws`目录中。
- en: 'In addition to this, here are some of the best practices and recommended steps
    to secure our IAM setup:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，以下是一些关于如何确保我们的IAM设置的最佳实践和推荐步骤：
- en: Stop using and delete the access keys for the AWS root account (if possible).
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止使用并删除AWS根账户的访问密钥（如果可能的话）。
- en: Enable **multi-factor authentication** (**MFA**) on the root account and all
    the IAM users.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在根账户和所有IAM用户上启用**多因素认证**（**MFA**）。
- en: Rotate the access keys and passwords regularly.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期轮换访问密钥和密码。
- en: Use (and assume) IAM roles to delegate permissions instead of using long-term
    passwords or access key credentials whenever possible.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在可能的情况下，使用（并假定）IAM 角色来委派权限，而不是使用长期密码或访问密钥凭证。
- en: If possible, expire and rotate passwords and keys periodically (for example,
    every 90 days).
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果可能的话，定期过期和轮换密码和密钥（例如，每 90 天一次）。
- en: Achieve a “least privilege” configuration using the **IAM policy simulator**
    and **IAM Access Analyzer.**
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 **IAM 策略模拟器** 和 **IAM 访问分析器** 实现一个“最小权限”配置。
- en: In addition to following the best practices, we should regularly check for any
    IAM permission misconfigurations. We must spend time digging deeper and verifying
    what’s exploitable. For one thing, an attacker with access to an IAM user with
    a limited set of permissions may perform a `iam:AddUserToGroup` permission, the
    attacker can use the AWS CLI (or any alternative method) to add the IAM user to
    an existing IAM Group with a less restrictive set of privileges and permissions.
    If the `AdministratorAccess` managed policy is attached to one of the existing
    IAM Groups, the attacker can add the compromised IAM user to the Group with the
    attached `AdministratorAccess` managed policy to gain full administrator access
    to the entire AWS account. Note that this is just one of the possible scenarios
    and there are several other known privilege escalation methods. In some cases,
    attackers may use a chain or combination of these techniques before gaining full
    administrator access. To prevent these types of attacks, we should avoid granting
    `iam:*` permissions whenever possible.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 除了遵循最佳实践外，我们还应定期检查任何 IAM 权限配置错误。我们必须花时间深入挖掘并验证哪些是可利用的。例如，一个拥有有限权限集的 IAM 用户的攻击者可能会执行
    `iam:AddUserToGroup` 权限，攻击者可以使用 AWS CLI（或任何替代方法）将 IAM 用户添加到一个具有更宽松权限集的现有 IAM 组中。如果
    `AdministratorAccess` 管理策略附加到其中一个现有的 IAM 组，攻击者可以将受损害的 IAM 用户添加到带有附加 `AdministratorAccess`
    管理策略的组中，从而获得对整个 AWS 账户的完全管理员访问权限。请注意，这只是可能情景之一，还有其他几种已知的权限提升方法。在某些情况下，攻击者在获得完全管理员访问权限之前可能会使用这些技术的链或组合。为了防止这类攻击，我们应该尽可能避免授予
    `iam:*` 权限。
- en: At this point, you may be wondering, *How do we test the security of our AWS
    account*? There are several tools, including open source exploitation frameworks
    and security-testing toolkits such as **Pacu**, **ScoutSuite**, and **WeirdAAL**
    (**AWS Attack Library**) that can be used to assess and test the security of cloud
    environments. We won’t discuss how to use these tools in this book, so feel free
    to check these out separately.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可能想知道，*我们如何测试我们 AWS 账户的安全性*？有几个工具，包括开源利用框架和安全测试工具包，如 **Pacu**、**ScoutSuite**
    和 **WeirdAAL**（**AWS 攻击库**），可以用来评估和测试云环境的安全性。我们不会在本书中讨论如何使用这些工具，所以你可以单独查看这些工具。
- en: Note
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: What happens when an attacker gains full administrator access to the AWS account?
    Well, all sorts of horrible things can happen! For one thing, the attacker can
    now freely spin up AWS resources such as EC2 instances, which can be used to attack
    other accounts and systems. Attackers can also use compromised accounts to mine
    cryptocurrencies (for example, Bitcoin). Attackers should also be able to steal
    and access the data stored in the databases hosted in the compromised AWS account.
    It is also possible for all the AWS resources to be deleted.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当攻击者获得对 AWS 账户的完全管理员访问权限时会发生什么？嗯，可能会有各种可怕的事情发生！例如，攻击者现在可以自由地启动 AWS 资源，如 EC2
    实例，这些实例可以用来攻击其他账户和系统。攻击者还可以使用受损害的账户来挖掘加密货币（例如，比特币）。攻击者还应该能够窃取和访问存储在受损害 AWS 账户中数据库中的数据。所有
    AWS 资源都可能被删除。
- en: 'Before ending this section, let’s discuss how SageMaker execution roles work
    so that we will have a better idea of how we can improve the security of our ML
    environment setup. When we use the `get_execution_role` function, we are given
    the IAM role that was created for SageMaker Studio or the Notebook instance where
    the code is running:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束本节之前，让我们讨论一下 SageMaker 执行角色的运作方式，以便我们更好地了解如何提高我们 ML 环境设置的安全性。当我们使用 `get_execution_role`
    函数时，我们会得到为 SageMaker Studio 或运行代码的 Notebook 实例创建的 IAM 角色：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Depending on how this IAM role is set up, it may have the `AmazonSageMakerFullAccess`
    IAM policy attached to it, which grants access to several AWS services. If configured
    with a less restrictive set of permissions, an attacker who can gain access to
    SageMaker Studio or a Notebook instance may be able to use a privilege escalation
    attack to gain additional permissions. Let’s say that you are planning to conduct
    an ML workshop for 10 participants. To set things up, you started by creating
    an IAM user for each of the participants to access a dedicated Notebook instance
    (or the corresponding set of SageMaker Studio domains and users), similar to what
    is shown in the following diagram:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个IAM角色的设置方式，它可能附带了`AmazonSageMakerFullAccess` IAM策略，这允许访问多个AWS服务。如果配置了更宽松的权限集，能够访问SageMaker
    Studio或Notebook实例的攻击者可能能够通过提升权限攻击来获得额外的权限。假设你计划为10名参与者举办一个ML工作坊。为了设置环境，你首先为每个参与者创建了一个IAM用户，以便他们可以访问专用的Notebook实例（或相应的SageMaker
    Studio域和用户集），类似于以下图中所示：
- en: '![Figure 9.1 – Sample IAM configuration of an ML workshop environment ](img/B18638_09_001.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图9.1 – ML工作坊环境中的IAM配置示例](img/B18638_09_001.jpg)'
- en: Figure 9.1 – Sample IAM configuration of an ML workshop environment
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 – ML工作坊环境中的IAM配置示例
- en: 'Here, the IAM users only have the permissions to list down and access the Notebook
    instances available. However, the Notebook instances have IAM roles attached,
    which may have additional permissions that attackers may take advantage of. That
    said, once an attacker (as a workshop participant) uses one of the IAM users to
    access one of the Notebook instances available during the workshop, the attacker
    can simply open a `curl` command inside the Terminal of the Notebook instance:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，IAM用户只有列出和访问可用的Notebook实例的权限。然而，Notebook实例附带了IAM角色，这些角色可能具有攻击者可以利用的额外权限。换句话说，一旦攻击者（作为工作坊参与者）使用IAM用户之一访问工作坊期间可用的Notebook实例之一，攻击者就可以简单地在该Notebook实例的终端内打开一个`curl`命令：
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Alternatively, if you have set up and used **SageMaker Studio** instead for
    the workshop, the attacker can run the following command and obtain the security
    credentials:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你为工作坊设置了并使用了**SageMaker Studio**，攻击者可以运行以下命令并获取安全凭证：
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Once the credentials have been exfiltrated, the attacker now has a variety of
    options regarding how to use these credentials to perform specific attacks. *Scary,
    right?* What if the IAM role attached to the Notebook instances has the `AdministratorAccess`
    managed policy attached to it? This would mean that the attacker would be able
    to gain full administrator access using a privilege escalation attack!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦凭证被窃取，攻击者现在有多种选择来使用这些凭证执行特定的攻击。*这很可怕，对吧？*如果附加到Notebook实例的IAM角色附带了`AdministratorAccess`管理策略，这意味着攻击者将能够通过提升权限攻击获得完整的管理员访问权限！
- en: To mitigate and manage the risks associated with scenarios similar to this,
    it is recommended to practice the **principle of least privilege** when configuring
    the IAM role attached to the AWS resources. This means that we need to dive deeper
    into the policies attached to the IAM role and check which permissions can be
    removed or reduced. This would limit the potential damage, even after a privilege
    escalation attack has been performed. In addition to this, if you were to conduct
    an ML workshop, you may want to utilize **SageMaker Studio Lab** instead of creating
    Notebook instances in your AWS account for your participants to use. With this
    approach, the workshop participants can run ML training experiments and deployments
    without having to use an AWS account. At the same time, using SageMaker Studio
    Lab is free and perfect for workshops!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻和管理与类似场景相关的风险，建议在配置附加到AWS资源的IAM角色时实践**最小权限原则**。这意味着我们需要深入了解附加到IAM角色的策略，并检查哪些权限可以被移除或降低。这将限制即使执行了提升权限攻击后的潜在损害。此外，如果你要举办一个ML工作坊，你可能希望使用**SageMaker
    Studio Lab**而不是在你的AWS账户中为参与者创建Notebook实例。采用这种方法，工作坊参与者可以运行ML训练实验和部署，而无需使用AWS账户。同时，使用SageMaker
    Studio Lab是免费的，非常适合工作坊！
- en: Note
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For more information on this topic, check out [https://studiolab.sagemaker.aws/](https://studiolab.sagemaker.aws/).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于这个主题的信息，请查看[https://studiolab.sagemaker.aws/](https://studiolab.sagemaker.aws/)。
- en: Network security
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络安全
- en: 'When training and deploying ML models, it is possible for ML engineers to accidentally
    use a library or a custom container image that includes malicious code prepared
    by an attacker. For example, an attacker may generate a `model.h5` file that contains
    a reverse shell payload:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练和部署ML模型时，ML工程师可能会意外使用一个包含攻击者准备的恶意代码的库或自定义容器镜像。例如，攻击者可能会生成一个包含反向shell有效载荷的`model.h5`文件：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here, the attacker takes advantage of the **Keras Lambda layer** to run custom
    functions. Loading the generated file is similar to how other models are loaded
    using TensorFlow:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，攻击者利用**Keras Lambda层**来运行自定义函数。加载生成的文件类似于使用TensorFlow加载其他模型的方式：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: There are different variations of this, including injecting a payload to pickle
    files and YAML files, which affects other libraries and frameworks such as *scikit-learn*
    and *PyTorch*.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这有多种变体，包括向pickle文件和YAML文件注入有效载荷，这会影响其他库和框架，如*scikit-learn*和*PyTorch*。
- en: Note
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For more examples of how to inject malicious payloads inside ML model files,
    check out [https://gist.github.com/joshualat/a3fdfa4d49d1d6725b1970133d06866b](https://gist.github.com/joshualat/a3fdfa4d49d1d6725b1970133d06866b).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多如何在ML模型文件中注入恶意有效载荷的示例，请查看[https://gist.github.com/joshualat/a3fdfa4d49d1d6725b1970133d06866b](https://gist.github.com/joshualat/a3fdfa4d49d1d6725b1970133d06866b)。
- en: 'Once the reverse shell payload executes inside the training and inference containers
    within the ML instances, the attacker may be able to access the data and transfer
    it to an external server. To prevent these types of attacks, we can enable `Estimator`
    object, similar to what’s shown in the following block of code:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦反向shell有效载荷在ML实例的训练和推理容器内执行，攻击者可能能够访问数据并将其传输到外部服务器。为了防止这类攻击，我们可以启用类似于以下代码块中所示的`Estimator`对象：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Once we run the training job using the `fit()` method in a later step, the training
    containers inside the ML instances will no longer have network access while the
    training jobs are running.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们在后续步骤中使用`fit()`方法运行训练作业，ML实例内部的训练容器在训练作业运行期间将不再具有网络访问权限。
- en: Note
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Of course, our first layer of defense is to avoid using models and code from
    untrusted and potentially dangerous sources. However, despite our best intentions,
    we may still end up accidentally downloading compromised resources. This is the
    reason why we need to utilize network isolation solutions as the next layer of
    defense.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们的第一层防御是避免使用来自不受信任和可能危险的来源的模型和代码。然而，尽管我们最好的意图，我们仍然可能意外地下载了受损害的资源。这就是为什么我们需要利用网络隔离解决方案作为下一层防御的原因。
- en: 'We can have a similar secure setup by preparing and using a **VPC** without
    the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过准备和使用一个**VPC**（虚拟私有云）来获得类似的网络安全设置，而不需要以下内容：
- en: An **internet gateway**, which enables resources in the public subnets to have
    internet access
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**互联网网关**，它使公共子网中的资源能够访问互联网'
- en: A **NAT gateway**, which allows resources in the private subnets to establish
    “one-way” outbound connections
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NAT网关**，它允许私有子网中的资源建立“单向”出站连接'
- en: Other similar gateways that may allow resources from inside and outside the
    VPC to communicate with each other
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他可能允许VPC内部和外部资源相互通信的类似网关
- en: With this setup, resources deployed inside the VPC will not have internet connectivity.
    That said, if we run a training script containing malicious code inside an EC2
    instance deployed inside the VPC, the malicious code will not be able to access
    the internet and connect to servers and resources outside of the VPC. *What if
    we want to upload and download files from an S3 bucket?* To get this working,
    we will need to configure **VPC endpoints** to enable network connectivity to
    AWS services such as S3\. If we want to connect to resources inside another VPC,
    we can use **AWS PrivateLink** and access these resources using their private
    IP addresses. With this approach, resources are not accessed over the internet
    and no internet gateways need to be present when using AWS PrivateLink (an interface
    VPC endpoint).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种设置，部署在VPC内部的资源将不会拥有互联网连接。话虽如此，如果我们在一个部署在VPC内部的EC2实例中运行包含恶意代码的训练脚本，恶意代码将无法访问互联网并连接到VPC外部的服务器和资源。*如果我们想从S3存储桶上传和下载文件怎么办？*为了使这一功能正常工作，我们需要配置**VPC端点**以启用对AWS服务（如S3）的网络连接。如果我们想连接到另一个VPC内部的资源，我们可以使用**AWS
    PrivateLink**并使用它们的私有IP地址来访问这些资源。使用这种方法，资源不是通过互联网访问的，并且在使用AWS PrivateLink时不需要存在互联网网关（一个接口VPC端点）。
- en: 'The following can be set up so that AWS resources can be accessed directly
    and more securely via PrivateLink:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下设置可以确保通过PrivateLink直接且更安全地访问AWS资源：
- en: Accessing **Amazon Athena** via PrivateLink
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过PrivateLink访问**Amazon Athena**
- en: Accessing **AWS Lambda** via PrivateLink
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过PrivateLink访问**AWS Lambda**
- en: Connecting to **Amazon Redshift** via PrivateLink
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过PrivateLink连接到**Amazon Redshift**
- en: Invoking **SageMaker Inference Endpoints** via PrivateLink
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过PrivateLink调用**SageMaker推理端点**
- en: Connecting to **SageMaker Studio** via PrivateLink
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过PrivateLink连接到**SageMaker Studio**
- en: Accessing **API Gateway** APIs via PrivateLink
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过PrivateLink访问**API Gateway** API
- en: Note that this is not an exhaustive list of what can be secured using PrivateLink,
    as there’s a long list of services that integrate with PrivateLink.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这并不是使用PrivateLink可以保护的所有内容的详尽列表，因为还有许多与PrivateLink集成的服务。
- en: Note
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For more information on the supported list of services, check out [https://docs.aws.amazon.com/vpc/latest/privatelink/aws-services-privatelink-support.xhtml](https://docs.aws.amazon.com/vpc/latest/privatelink/aws-services-privatelink-support.xhtml).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 想要了解更多关于支持的服务列表，请查看[https://docs.aws.amazon.com/vpc/latest/privatelink/aws-services-privatelink-support.xhtml](https://docs.aws.amazon.com/vpc/latest/privatelink/aws-services-privatelink-support.xhtml)。
- en: Encryption at rest and in transit
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 静态和传输中的加密
- en: SageMaker supports a variety of options for the data source when training ML
    models. In most cases, ML engineers default to using an **Amazon S3** bucket as
    the default source of data. In other cases, **Amazon Elastic File System** (**Amazon
    EFS**) would be used instead, especially for workloads that require higher throughput.
    For even higher performance throughput requirements, we can use **Amazon FSx for
    Lustre** (which may be linked to an S3 bucket for the source). These storage options
    integrate with **AWS Key Management Service** (**AWS KMS**), which helps ensure
    that data is automatically encrypted (that is, unreadable without a secret key)
    before being written to the filesystem. Once data needs to be loaded and read,
    it is decrypted automatically.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker在训练机器学习模型时支持多种数据源选项。在大多数情况下，机器学习工程师默认使用**Amazon S3**存储桶作为数据的默认来源。在其他情况下，可能会使用**Amazon
    Elastic File System**（**Amazon EFS**）代替，尤其是在需要更高吞吐量的工作负载中。对于更高的性能吞吐量需求，我们可以使用**Amazon
    FSx for Lustre**（可能链接到S3存储桶作为源）。这些存储选项与**AWS密钥管理服务**（**AWS KMS**）集成，有助于确保数据在写入文件系统之前自动加密（即，没有密钥无法读取）。
- en: Note
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For more information about cryptography concepts such as **asymmetric and symmetric
    encryption**, **decryption**, and **envelope encryption**, feel free to check
    out [https://docs.aws.amazon.com/crypto/latest/userguide/cryptography-concepts.xhtml](https://docs.aws.amazon.com/crypto/latest/userguide/cryptography-concepts.xhtml).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 想要了解更多关于加密概念，如**非对称和对称加密**、**解密**和**封装加密**，请查看[https://docs.aws.amazon.com/crypto/latest/userguide/cryptography-concepts.xhtml](https://docs.aws.amazon.com/crypto/latest/userguide/cryptography-concepts.xhtml)。
- en: 'Note that we have two options when using KMS. The first one involves using
    the default **AWS-managed key** and the second one involves creating and using
    a **customer-managed key**. *When should we use a customer-managed key?* If we
    want more control, such as enabling key rotation along with the option to revoke,
    disable, or delete key access, then we should opt to use a customer-managed key.
    If you are wondering if the storage volumes attached to the training and hosting
    instances can be encrypted with a KMS customer-managed key, then the answer to
    that would be a *YES* as well. To use a customer-managed key, we simply specify
    an optional KMS key ID, similar to what we have in the following block of code:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在使用KMS时，我们有两种选择。第一种是使用默认的**AWS管理的密钥**，第二种是创建并使用**客户管理的密钥**。*我们应该何时使用客户管理的密钥？*
    如果我们想要更多的控制，例如启用密钥轮换以及撤销、禁用或删除密钥访问的选项，那么我们应该选择使用客户管理的密钥。如果你想知道训练和托管实例附加的存储卷是否可以使用KMS客户管理的密钥进行加密，那么答案是*YES*。要使用客户管理的密钥，我们只需指定一个可选的KMS密钥ID，类似于以下代码块中的内容：
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, we can see that we can also specify an optional KMS key that will be used
    to encrypt the output files in Amazon S3\. In addition to encrypting the data
    at rest, we will need to ensure secure data transmission when performing distributed
    training. When multiple instances are used when performing training jobs, we can
    enable **inter-container traffic encryption** to secure the data that’s transmitted
    between the instances. If there are specific regulatory requirements we need to
    comply with, we will need to ensure that the data that’s transmitted is encrypted
    as well.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们还可以指定一个可选的 KMS 密钥，该密钥将用于加密 Amazon S3 中的输出文件。除了加密静态数据外，我们还需要确保在执行分布式训练时数据传输的安全性。当在执行训练作业时使用多个实例，我们可以启用
    **容器间流量加密** 来保护实例之间传输的数据。如果我们需要遵守特定的监管要求，我们需要确保传输的数据也已被加密。
- en: 'Enabling inter-container traffic encryption is straightforward when using the
    **SageMaker Python SDK**:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用 **SageMaker Python SDK** 启用容器间流量加密时，操作简单：
- en: '[PRE9]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*Wasn’t that easy?* Before enabling inter-container traffic encryption, make
    sure that you’re aware of its potential impact on the overall training time and
    cost of the training job. When using distributed deep learning algorithms, the
    overall training time and cost may increase after adding this additional level
    of security. For `NetworkConfig` object, similar to what we have in the following
    block of code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*这不是很简单吗？* 在启用容器间流量加密之前，请确保您了解其对整体训练时间和训练作业成本可能产生的影响。当使用分布式深度学习算法时，添加此额外的安全级别后，整体训练时间和成本可能会增加。对于
    `NetworkConfig` 对象，类似于以下代码块中的内容：'
- en: '[PRE10]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Note that this approach should work across the different “types” of processing
    jobs, as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，此方法应适用于不同“类型”的处理作业，如下所示：
- en: '`SageMakerClarifyProcessor` for model explainability needs and automated bias
    metrics computation'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于模型可解释性和自动偏差指标计算的 `SageMakerClarifyProcessor`
- en: '`PySparkProcessor` for processing jobs using **PySpark**'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于使用 **PySpark** 处理作业的 `PySparkProcessor`
- en: '`SKLearnProcessor` for processing jobs using **scikit-learn**'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于使用 **scikit-learn** 处理作业的 `SKLearnProcessor`
- en: SageMaker also supports the usage of custom container images when processing
    data and when training and deploying models. These container images, which are
    stored inside `docker push` command), ECR automatically encrypts these images.
    Once these container images are pulled (for example, using the `docker pull` command),
    ECR automatically decrypts these images.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 还支持在处理数据以及训练和部署模型时使用自定义容器镜像。这些容器镜像存储在 `docker push` 命令中，ECR 会自动加密这些镜像。一旦这些容器镜像被拉取（例如，使用
    `docker pull` 命令），ECR 会自动解密这些镜像。
- en: 'In addition to these, we can encrypt the following in SageMaker with KMS:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些，我们还可以使用 KMS 在 SageMaker 中加密以下内容：
- en: SageMaker Studio storage volumes
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker Studio 存储卷
- en: The output files of the SageMaker Processing job
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker 处理作业的输出文件
- en: Output data of the SageMaker Ground Truth labeling job
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker Ground Truth 标注作业的输出数据
- en: SageMaker Feature Store online and offline stores
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker Feature Store 的在线和离线存储
- en: Note
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: It’s probably our first time mentioning **SageMaker Ground Truth** and **SageMaker
    Feature Store** in this book! If you’re wondering what these are, SageMaker Ground
    Truth is a data labeling service that helps ML practitioners prepare high-quality
    labeled datasets using a variety of options, while SageMaker Feature Store is
    a fully-managed feature store where features for ML models can be stored, shared,
    and managed. We won’t dive deep into the details on how these work in this book,
    so feel free to check out [https://docs.aws.amazon.com/sagemaker/latest/dg/data-label.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/data-label.xhtml)
    and https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.xhtml for more
    details on these topics.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是我们第一次在这本书中提到 **SageMaker Ground Truth** 和 **SageMaker Feature Store**！如果您想知道这些是什么，SageMaker
    Ground Truth 是一种数据标注服务，它帮助机器学习从业者使用各种选项准备高质量的标注数据集，而 SageMaker Feature Store 是一个完全托管的特征存储，其中可以存储、共享和管理
    ML 模型的特征。我们在这本书中不会深入探讨这些服务的具体工作方式，因此请随时查阅 [https://docs.aws.amazon.com/sagemaker/latest/dg/data-label.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/data-label.xhtml)
    和 https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.xhtml 以获取更多关于这些主题的详细信息。
- en: '*What if we are performing data processing, model training, and model deployments
    outside of SageMaker?* The good news is that many services in the AWS platform
    are integrated with KMS. This means that it’s usually just a minor configuration
    change to enable server-side encryption. Here are some examples of what is immediately
    available with KMS:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果我们在外部执行数据处理、模型训练和模型部署呢？* 好消息是，AWS平台中的许多服务都与KMS集成。这意味着通常只需进行一些小的配置更改即可启用服务器端加密。以下是一些KMS立即可用的示例：'
- en: EBS volume encryption
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: EBS卷加密
- en: Redshift cluster encryption
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redshift集群加密
- en: Encryption of Amazon S3 objects
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加密Amazon S3对象
- en: Encryption of data written by Glue DataBrew jobs
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Glue DataBrew作业写入的数据加密
- en: Encryption of log data stored in CloudWatch Logs
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加密存储在CloudWatch日志中的日志数据
- en: We can also use the **AWS Encryption SDK** to encrypt the data before sending
    the data to an AWS service (for example, Amazon S3). Using the same client-side
    encryption library, we can decrypt the data after retrieving it from the storage
    location.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用**AWS Encryption SDK**在将数据发送到AWS服务（例如Amazon S3）之前加密数据。使用相同的客户端加密库，我们可以在从存储位置检索数据后解密数据。
- en: Note
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: There are several options to choose from when dealing with encryption and decryption
    requirements on AWS. In addition to **AWS KMS** and the **AWS Encryption SDK**,
    there’s also the **DynamoDB Encryption Client** and **AWS CloudHSM**. We won’t
    dive deep into each of these, so feel to check out https://docs.aws.amazon.com/crypto/latest/userguide/awscryp-choose-toplevel.xhtml
    for more information.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理AWS上的加密和解密需求时，有几个选项可供选择。除了**AWS KMS**和**AWS Encryption SDK**之外，还有**DynamoDB
    Encryption Client**和**AWS CloudHSM**。我们不会深入探讨每一个，所以请查阅https://docs.aws.amazon.com/crypto/latest/userguide/awscryp-choose-toplevel.xhtml以获取更多信息。
- en: 'In addition to what has been discussed already, we must know a few additional
    techniques on how to protect and encrypt the data in transit when using EC2 instances
    for ML requirements. In [*Chapter 2*](B18638_02.xhtml#_idTextAnchor041), *Deep
    Learning AMIs*, we launched the **Jupyter Notebook** application from the command
    line inside an EC2 instance. You probably noticed that we accessed the application
    using HTTP instead of HTTPS. One of the improvements we can do is to use SSL (using
    a web certificate) to encrypt the traffic between the server and the browser.
    Another solution would be to access the Jupyter Notebook application using **SSH
    tunneling**. *SSH what?* SSH tunneling is a mechanism that involves using an encrypted
    SSH connection between two computers to forward connections via a secure channel:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 除了已经讨论的内容之外，我们还必须了解一些额外的技术，如何在使用EC2实例进行ML需求时保护并加密传输中的数据。在[*第2章*](B18638_02.xhtml#_idTextAnchor041)
    *深度学习AMIs*中，我们从EC2实例内部的命令行启动了**Jupyter Notebook**应用程序。你可能已经注意到我们使用HTTP而不是HTTPS来访问应用程序。我们可以做的改进之一是使用SSL（使用Web证书）加密服务器和浏览器之间的流量。另一个解决方案是使用**SSH隧道**访问Jupyter
    Notebook应用程序。*SSH是什么？* SSH隧道是一种机制，涉及在两台计算机之间使用加密的SSH连接来通过安全通道转发连接：
- en: '![Figure 9.2 – SSH tunneling ](img/B18638_09_002.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图9.2 – SSH隧道](img/B18638_09_002.jpg)'
- en: Figure 9.2 – SSH tunneling
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 – SSH隧道
- en: Here, we can see that we can access the Jupyter Notebook app from the local
    machine, even if the application is running inside the EC2 instance. Here, we
    make use of SSH tunneling to forward the connection over the secure channel with
    SSH.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到即使应用程序运行在EC2实例内部，我们也可以从本地机器访问Jupyter Notebook应用程序。在这里，我们使用SSH隧道将连接通过SSH的安全通道进行转发。
- en: 'To set this up, we simply need to run a command similar to what we have in
    the following command block (assuming that our local machine is a Unix operating
    system):'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置此环境，我们只需运行一个类似于以下命令块中的命令（假设我们的本地机器是Unix操作系统）：
- en: '[PRE11]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After the command runs, we should be able to access the Jupyter Notebook application
    locally by visiting the following link in a browser: [http://localhost:14344](http://localhost:14344).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 命令运行后，我们应该能够通过在浏览器中访问以下链接来在本地访问Jupyter Notebook应用程序：[http://localhost:14344](http://localhost:14344)。
- en: Now that we’ve discussed several techniques to encrypt the data, let’s proceed
    with discussing some of the services we can use to help us manage the compliance
    of our environments.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经讨论了几种加密数据的技术，那么让我们继续讨论一些可以帮助我们管理环境合规性的服务。
- en: Managing compliance reports
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理合规性报告
- en: In addition to securing ML environments and systems, it is critical for data
    science teams to manage the overall compliance of the processes and configuration
    of the resources used in the AWS account. Managing compliance involves identifying
    the relevant regulations and guidelines an organization needs to comply with (for
    example, **HIPAA**, **PCI-DSS**, and **GDPR**) and performing the recommended
    set of steps to achieve (and maintain) the required compliance.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 除了保护机器学习和系统外，对于数据科学团队来说，管理AWS账户中使用的资源和流程的整体合规性至关重要。管理合规性涉及确定组织需要遵守的相关法规和指南（例如，**HIPAA**、**PCI-DSS**和**GDPR**），并执行推荐的一系列步骤以实现（并维持）所需的合规性。
- en: 'Security and compliance are shared between AWS and the customers. Customers
    generally need to focus on the following aspects:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性和合规性由AWS和客户共享。客户通常需要关注以下方面：
- en: The guest operating system
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户操作系统
- en: Any applications running on top of the AWS services
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在AWS服务之上运行的所有应用程序
- en: The configuration of the different AWS resources used
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用不同AWS资源的配置
- en: Note
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For more details on the **Shared Responsibility Model**, check out [https://aws.amazon.com/compliance/shared-responsibility-model/](https://aws.amazon.com/compliance/shared-responsibility-model/).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于**共享责任模型**的详细信息，请查看[https://aws.amazon.com/compliance/shared-responsibility-model/](https://aws.amazon.com/compliance/shared-responsibility-model/)。
- en: 'There are a variety of services, tools, and capabilities available in AWS when
    dealing with compliance enforcement and reporting:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理合规性执行和报告时，AWS提供了各种服务、工具和能力：
- en: '**AWS Artifact**: This is a central source of security and compliance documents,
    reports, and resources. Here, we can download the relevant security and compliance
    documents we will need.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS Artifact**：这是安全性和合规性文档、报告和资源的集中来源。在这里，我们可以下载我们将需要的有关安全性和合规性文档。'
- en: '**AWS Config**: This can be used to continuously monitor the configuration
    of the AWS resources and enable automated remediation to ensure the compliance
    of ML environments and systems.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS Config**：这可以用来持续监控AWS资源的配置，并启用自动修复以确保机器学习和系统符合性。'
- en: '**AWS Audit Manager**: This helps simplify the risk and compliance assessment
    of AWS resources.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS Audit Manager**：这有助于简化AWS资源的风险和合规性评估。'
- en: '**AWS Compliance Center**: This is a central source of cloud-related regulatory
    resources.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS合规中心**：这是云相关法规资源的集中来源。'
- en: We won’t dive deep into the details of how these services are used, so feel
    free to check out the *Further reading* section at the end of this chapter for
    more details. In the next section, we will quickly discuss some of the relevant
    services that can help us with vulnerability management.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入探讨这些服务如何使用的细节，因此请随意查看本章末尾的**进一步阅读**部分以获取更多详细信息。在下一节中，我们将快速讨论一些可以帮助我们进行漏洞管理的相关服务。
- en: Vulnerability management
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 漏洞管理
- en: Implementing the security best practices will not guarantee that an environment
    or a system is safe from attacks. In addition to following the security best practices
    and compliance requirements, teams should use a variety of vulnerability assessment
    and management tools to check for potentially exploitable vulnerabilities in the
    system.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 实施安全最佳实践并不能保证环境或系统免受攻击。除了遵循安全最佳实践和合规性要求外，团队应使用各种漏洞评估和管理工具来检查系统中可能被利用的漏洞。
- en: One of the practical solutions to use when detecting and managing vulnerabilities
    in AWS is **Amazon Inspector**. Amazon Inspector enables **automated vulnerability
    management** through its automatic detection of vulnerabilities in EC2 instances
    and container images pushed to Amazon ECR. *How does this work?* Every time a
    “change” is detected (for example, a container image push to ECR), Amazon Inspector
    scans the resources automatically so that no manual vulnerability scan needs to
    be initiated by the user. This means that if we are preparing and building a custom
    container image for a **SageMaker Processing** job, training job, or an ML inference
    endpoint, Amazon Inspector will automatically scan the container image for us
    every time we push a new version to the Amazon ECR repository. If vulnerabilities
    are detected and reported by Amazon Inspector, the next step is for us to perform
    the needed remediation steps on the affected resources.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS中检测和管理漏洞的一个实用解决方案是**Amazon Inspector**。Amazon Inspector通过自动检测推送到Amazon ECR的EC2实例和容器镜像中的漏洞来实现**自动漏洞管理**。*这是如何工作的？*每当检测到“更改”（例如，将容器镜像推送到ECR）时，Amazon
    Inspector会自动扫描资源，这样用户就不需要手动启动漏洞扫描。这意味着如果我们正在为**SageMaker Processing**作业、训练作业或ML推理端点准备和构建自定义容器镜像，每次我们将新版本推送到Amazon
    ECR存储库时，Amazon Inspector都会自动为我们扫描容器镜像。如果Amazon Inspector检测到并报告了漏洞，下一步就是我们对受影响的资源执行所需的修复步骤。
- en: Note
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For a step-by-step tutorial on how to use and set up Amazon Inspector, check
    out [https://medium.com/@arvs.lat/automated-vulnerability-management-on-aws-with-amazon-inspector-53c572bf8515](https://medium.com/@arvs.lat/automated-vulnerability-management-on-aws-with-amazon-inspector-53c572bf8515).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 想要了解如何使用和设置Amazon Inspector的逐步教程，请查看[https://medium.com/@arvs.lat/automated-vulnerability-management-on-aws-with-amazon-inspector-53c572bf8515](https://medium.com/@arvs.lat/automated-vulnerability-management-on-aws-with-amazon-inspector-53c572bf8515)。
- en: 'In addition to Amazon Inspector, we can use the following services and capabilities
    to manage security risks and vulnerabilities in our ML environments on AWS:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Amazon Inspector，我们还可以使用以下服务和功能来管理在AWS上我们的ML环境中的安全风险和漏洞：
- en: '**Amazon CodeGuru Reviewer**: This can be used to analyze code and detect security
    issues automatically using **security detectors.**'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon CodeGuru Reviewer**：这可以用于分析代码并使用**安全检测器**自动检测安全问题。'
- en: '**Amazon GuardDuty**: This can be used to automatically detect malicious activities
    such as privilege escalation attacks in an AWS account..'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon GuardDuty**：这可以用于自动检测AWS账户中的恶意活动，如权限提升攻击。'
- en: '**AWS Security Hub**: This can be used to automate security checks and conduct
    cloud security posture management.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS Security Hub**：这可以用于自动化安全检查和执行云安全态势管理。'
- en: 'Before we end this section, let’s quickly discuss how we can protect ML inference
    endpoints using firewalls. In [*Chapter 3*](B18638_03.xhtml#_idTextAnchor060),
    *Deep Learning Containers*, we deployed our ML model inside a Lambda function
    using the custom container image support of the service. Then, we set up and configured
    an API Gateway HTTP API trigger that triggered the Lambda function when there
    were new endpoint requests. If we want to secure this setup and make this serverless
    API available for public use, we can configure an **AWS Web Application Firewall**
    (**WAF**) to protect this, as shown in the following diagram:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束本节之前，让我们快速讨论如何使用防火墙保护ML推理端点。在[*第3章*](B18638_03.xhtml#_idTextAnchor060)
    *深度学习容器*中，我们使用服务的自定义容器镜像支持在Lambda函数内部部署了我们的ML模型。然后，我们设置并配置了一个API Gateway HTTP
    API触发器，当有新的端点请求时触发Lambda函数。如果我们想保护这个设置并使这个无服务器API可供公众使用，我们可以配置一个**AWS Web应用程序防火墙**（**WAF**）来保护它，如图中所示：
- en: '![Figure 9.3 – Using AWS WAF to protect API endpoints ](img/B18638_09_003.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![图9.3 – 使用AWS WAF保护API端点](img/B18638_09_003.jpg)'
- en: Figure 9.3 – Using AWS WAF to protect API endpoints
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 – 使用AWS WAF保护API端点
- en: AWS WAF protects deployed web applications from exploits that take advantage
    of existing vulnerabilities through the use of “rules,” which address issues including
    emerging **Common Vulnerabilities and Exposures** (**CVEs**), **Open Web Application
    Security Project** (**OWASP**) top 10 vulnerabilities, and more.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: AWS WAF通过使用“规则”来保护已部署的Web应用程序免受利用现有漏洞的攻击，这些规则解决了包括新兴的**通用漏洞和暴露**（**CVEs**）、**开放Web应用程序安全项目**（**OWASP**）前10大漏洞等问题。
- en: Note
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Note that this solution will also work if we have an API Gateway interfacing
    with a SageMaker Inference endpoint – whether we use the **API Gateway mapping
    templates** or a **Lambda function** to invoke the SageMaker inference endpoint.
    We can also use AWS WAF to secure our **Amazon CloudFront** and **Application
    Load Balancer** (**ALB**) resources to protect EC2 instances running ML inference
    endpoints behind the ALB.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果我们的API网关与SageMaker推理端点接口，这个解决方案也将适用——无论我们使用**API网关映射模板**还是**Lambda函数**来调用SageMaker推理端点。我们还可以使用AWS
    WAF来保护我们的**Amazon CloudFront**和**应用程序负载均衡器（ALB**）资源，以保护在ALB后面运行的ML推理端点的EC2实例。
- en: At this point, we should have a good idea of the different solutions and strategies
    when managing the security and compliance of ML environments. In the next section,
    we will dive deeper into the different techniques for preserving data privacy
    and model privacy.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们应该对管理机器学习环境的安全性和合规性的不同解决方案和策略有了很好的了解。在下一节中，我们将深入探讨保护数据隐私和模型隐私的不同技术。
- en: Preserving data privacy and model privacy
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护数据隐私和模型隐私
- en: 'When dealing with ML and ML engineering requirements, we need to make sure
    that we protect the training data, along with the parameters of the generated
    model, from attackers. When given the chance, these malicious actors will perform
    a variety of attacks to extract the parameters of the trained model or even recover
    the data used to train the model. This means that PII may be revealed and stolen.
    If the model parameters are compromised, the attacker may be able to perform inference
    on their end by recreating the model that your company took months or years to
    develop. *Scary, right?* Let’s share a few examples of attacks that can be performed
    by attackers:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理机器学习和机器学习工程需求时，我们需要确保我们保护训练数据，以及生成的模型参数，免受攻击者侵害。如果有机会，这些恶意行为者将执行各种攻击，以提取训练模型的参数，甚至恢复用于训练模型的原始数据。这意味着个人身份信息（PII）可能会被泄露和窃取。如果模型参数被破坏，攻击者可能能够通过重新创建公司花费数月或数年开发的模型来进行推理。*这很可怕，对吧？*
    让我们分享一些攻击者可以执行的攻击示例：
- en: '**Model inversion attack**: The attacker attempts to recover the dataset used
    to train the model.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型反演攻击**：攻击者试图恢复用于训练模型的训练数据集。'
- en: '**Model extraction attack**: The attacker tries to steal the trained model
    using the prediction output values.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型提取攻击**：攻击者试图通过预测输出值窃取训练好的模型。'
- en: '**Membership inference attack**: The attacker attempts to infer if a record
    is part of the training dataset used to train a model.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成员推断攻击**：攻击者试图推断一个记录是否是用于训练模型的训练数据集的一部分。'
- en: '**Attribute inference attack**: The attacker tries to guess the missing attributes
    of a training record (using partial information available).'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性推断攻击**：攻击者试图猜测训练记录中缺失的属性（使用可用的部分信息）。'
- en: Now that we have a better idea of some of the possible attacks, let’s discuss
    the solutions and defense mechanisms we can use to preserve the privacy of the
    data and the models.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对一些可能的攻击有了更好的了解，让我们讨论我们可以使用的解决方案和防御机制，以保护数据和模型的隐私。
- en: Federated Learning
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 联邦学习
- en: 'Let’s start by talking about **federated learning**, but before we do that,
    let’s compare it with the typical way we perform ML training and deployment, which
    is *centralized*:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先从**联邦学习**谈起，但在我们这么做之前，让我们将其与典型的机器学习训练和部署方式进行比较，后者是**集中式**的：
- en: '![Figure 9.4 – Centralized ML ](img/B18638_09_004.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图9.4 – 集中式机器学习](img/B18638_09_004.jpg)'
- en: Figure 9.4 – Centralized ML
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4 – 集中式机器学习
- en: 'Here, the data is collected from the mobile devices of the users into a centralized
    location where the ML model training step is performed on a single machine (or
    a cluster of machines using distributed training). There are issues concerning
    the ownership, privacy, and locality of the data with this approach since the
    data sent to the centralized location may contain sensitive information about
    the users. To manage these types of issues, we can utilize Federated Learning,
    where the training step is performed within the edge devices directly, as shown
    in the following diagram:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，数据是从用户的移动设备收集到集中位置的，在单个机器（或使用分布式训练的机器集群）上执行机器学习模型训练步骤。由于发送到集中位置的数据可能包含关于用户的敏感信息，因此这种方法存在关于数据所有权、隐私和局部性的问题。为了管理这些问题，我们可以利用联邦学习，其中训练步骤直接在边缘设备上执行，如下面的图所示：
- en: '![Figure 9.5 – Federated ML ](img/B18638_09_005.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图9.5 – 联邦机器学习](img/B18638_09_005.jpg)'
- en: Figure 9.5 – Federated ML
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.5 – 联邦机器学习
- en: 'Here, only the models are sent back to a server and “merged” with each other
    to produce a new global model. This helps solve **privacy preservation** issues
    since the data stays in the edge devices. In the *Deployment strategies and best
    practices* section of [*Chapter 7*](B18638_07.xhtml#_idTextAnchor151), *SageMaker
    Deployment Solutions*, we mentioned that we can use **SageMaker Edge Manager**
    along with other services when deploying and managing ML models on edge devices.
    Here, we’re under the assumption that the models have already been trained and
    we’re just using these services during the deployment step. *How are the models
    trained?* Here are some of the possible solutions:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，只有模型被发送回服务器并“合并”以生成新的全局模型。这有助于解决**隐私保护**问题，因为数据保持在边缘设备上。在[*第7章*](B18638_07.xhtml#_idTextAnchor151)的“部署策略和最佳实践”部分中，我们提到，在部署和管理边缘设备上的机器学习模型时，我们可以使用**SageMaker
    Edge Manager**以及其他服务。在这里，我们假设模型已经训练好，我们只是在部署步骤中使用这些服务。*模型是如何训练的？*以下是一些可能的解决方案：
- en: Use solutions such as **TensorFlow Federated** ([https://www.tensorflow.org/federated](https://www.tensorflow.org/federated))
    and **PyTorch Mobile** ([https://pytorch.org/mobile/home/](https://pytorch.org/mobile/home/)),
    which can be used for Federated ML requirements.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**TensorFlow Federated**([https://www.tensorflow.org/federated](https://www.tensorflow.org/federated))和**PyTorch
    Mobile**([https://pytorch.org/mobile/home/](https://pytorch.org/mobile/home/))等解决方案，这些解决方案可用于联邦机器学习需求。
- en: Use solutions such as the **Flower** ([https://flower.dev/](https://flower.dev/))
    framework, along with services such as **AWS IoT Greengrass**, **Amazon ECS**,
    and **AWS Step Functions** to manage training cluster unpredictability and coordinator-to-device
    challenges when performing federated learning with edge devices.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Flower**([https://flower.dev/](https://flower.dev/))框架，以及**AWS IoT Greengrass**、**Amazon
    ECS**和**AWS Step Functions**等服务来管理在边缘设备上进行联邦学习时的训练集群不可预测性和协调器到设备挑战。
- en: Use solutions such as `OpenMined/SwiftSyft` (on iOS devices) and `OpenMined/KotlinSyft`
    (on Android devices) to train and deploy **PySyft** models written with **TensorFlow**
    or **PyTorch**.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**OpenMined/SwiftSyft**（在iOS设备上）和**OpenMined/KotlinSyft**（在Android设备上）等解决方案来训练和部署用**TensorFlow**或**PyTorch**编写的**PySyft**模型。
- en: Note
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: What’s **PySyft**? It’s a library from **OpenMined** that utilizes Federated
    Learning, differential privacy, and encrypted computation for secure and private
    deep learning requirements. If you’re wondering what **Differential Privacy**
    and **Encrypted Computation** are, we’ll discuss these now!
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '**PySyft**是什么？它是**OpenMined**的一个库，利用联邦学习、差分隐私和加密计算来满足安全和隐私的深度学习需求。如果你想知道**差分隐私**和**加密计算**是什么，我们现在就来讨论这些内容！'
- en: Differential Privacy
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 差分隐私
- en: 'Now, let’s talk about **Differential Privacy**. Differential Privacy involves
    using techniques that protect the information that’s shared about individual records
    in the dataset, which will give attackers a harder time reverse engineering the
    original data. These techniques include the addition of a carefully designed amount
    of random noise to the training data or model parameters when producing statistics.
    Here are some examples and solutions:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来谈谈**差分隐私**。差分隐私涉及使用技术来保护数据集中关于个体记录共享的信息，这将使攻击者更难逆向工程原始数据。这些技术包括在生成统计数据时，向训练数据或模型参数中添加精心设计的随机噪声。以下是一些示例和解决方案：
- en: Using a variant called **Metric Differential Privacy** while training **natural
    language processing** (**NLP**) models and analyzing data in SageMaker. Here,
    the “meaning” of the words in the training dataset is preserved while protecting
    the privacy of individual records. For more information, check out [https://www.amazon.science/blog/preserving-privacy-in-analyses-of-textual-data](https://www.amazon.science/blog/preserving-privacy-in-analyses-of-textual-data).
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练**自然语言处理**（**NLP**）模型和分析SageMaker中的数据时使用一种名为**度量差分隐私**的变体。在这里，训练数据集中单词的“意义”得到保留，同时保护个体记录的隐私。有关更多信息，请参阅[https://www.amazon.science/blog/preserving-privacy-in-analyses-of-textual-data](https://www.amazon.science/blog/preserving-privacy-in-analyses-of-textual-data)。
- en: Using the open source **TensorFlow Privacy** library when training privacy preserving
    ML models with minimal code changes to existing TensorFlow code. For more information,
    check out [https://blog.tensorflow.org/2019/03/introducing-tensorflow-privacy-learning.xhtml](https://blog.tensorflow.org/2019/03/introducing-tensorflow-privacy-learning.xhtml).
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用开源的**TensorFlow Privacy**库训练具有最小代码更改的隐私保护机器学习模型时。更多信息，请查看[https://blog.tensorflow.org/2019/03/introducing-tensorflow-privacy-learning.xhtml](https://blog.tensorflow.org/2019/03/introducing-tensorflow-privacy-learning.xhtml)。
- en: Using the open source **Opacus** library to train PyTorch models while enabling
    Differential Privacy. For more information, check out [https://opacus.ai/](https://opacus.ai/).
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用开源的**Opacus**库在训练PyTorch模型的同时启用差分隐私。更多信息，请查看[https://opacus.ai/](https://opacus.ai/)。
- en: Note
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you are wondering how these solutions can be used in AWS, we simply need
    to install the required packages and libraries (for example, `opacus`) inside
    the resources where we will perform the ML experiments. For example, if we launched
    an EC2 instance using a `pip install opacus`). If we are using `requirements.txt`
    file when using **script mode** or provide a custom container image that will
    be used by SageMaker.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想知道这些解决方案如何在AWS中使用，我们只需在将要执行机器学习实验的资源内部安装所需的软件包和库（例如，`pip install opacus`）。例如，如果我们使用`pip
    install opacus`启动了一个EC2实例。如果我们使用**脚本模式**时使用`requirements.txt`文件，或者提供将被SageMaker使用的自定义容器镜像。
- en: Privacy-preserving machine learning
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隐私保护机器学习
- en: There’s also a class of techniques under **privacy-preserving machine learning**
    (**PPML**) where ML inference can be performed even if the input payload passed
    to the model is encrypted. This means that we can protect and encrypt sensitive
    data before it’s passed as the payload to an ML inference endpoint. After the
    PPML model is used for inference on the encrypted payload, the results are returned
    to the sender encrypted. The final step would be for the sender to decrypt the
    results. *Pretty cool, right?* An example of this would be a **privacy-preserving
    XGBoost model** that makes use of privacy-preserving encryption schemes and tools
    such as **order-preserving encryption** (**OPE**), **pseudo-random functions**
    (**PRFs**), and **additively homomorphic encryption** (**AHE**) to make predictions
    on encrypted queries. We can use a custom container image when deploying the privacy-preserving
    XGBoost model using the **SageMaker hosting services** so that we have a bit more
    flexibility when it comes to the packages and code used during inference. Note
    that PPML adds some computational overhead, and the resulting models are generally
    slower in terms of performance compared to the unencrypted versions.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在**隐私保护机器学习**（**PPML**）这一类技术中，即使输入模型的数据负载被加密，也可以执行ML推理。这意味着我们可以在将敏感数据作为负载传递给ML推理端点之前对其进行保护和加密。在PPML模型对加密负载进行推理后，结果会被加密返回给发送者。最后一步是发送者解密结果。*这很酷，对吧？*一个例子是**隐私保护XGBoost模型**，它利用隐私保护加密方案和工具，如**顺序保持加密**（**OPE**）、**伪随机函数**（**PRFs**）和**加法同态加密**（**AHE**）来对加密查询进行预测。当使用**SageMaker托管服务**部署隐私保护XGBoost模型时，我们可以使用自定义容器镜像，这样在推理过程中使用的软件包和代码就更有灵活性。请注意，PPML会增加一些计算开销，并且与未加密版本相比，生成的模型在性能上通常较慢。
- en: Note
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We won’t dive deep into the details of how PPML works in this book. For more
    information, check out [https://www.amazon.science/publications/privacy-preserving-xgboost-inference](https://www.amazon.science/publications/privacy-preserving-xgboost-inference).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入探讨本书中PPML的工作细节。更多信息，请查看[https://www.amazon.science/publications/privacy-preserving-xgboost-inference](https://www.amazon.science/publications/privacy-preserving-xgboost-inference)。
- en: Other solutions and options
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他解决方案和选项
- en: 'Finally, when it comes to managing data privacy, data science teams should
    make the most out of the existing security features and capabilities of the services
    and tools they are using. In addition to what was mentioned in the other sections
    of this chapter, here are other services and capabilities available for us when
    protecting our data in AWS:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当涉及到管理数据隐私时，数据科学团队应充分利用他们所使用的服务和工具现有的安全特性和功能。除了本章其他部分提到的内容外，以下是我们保护AWS中的数据时可以使用的其他服务和功能：
- en: '**Amazon Macie**: Used to assess the data privacy and security of the data
    stored in S3 through automated discovery of sensitive data such as PII.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon Macie**：用于通过自动发现敏感数据（如PII）来评估存储在S3中的数据的隐私和安全。'
- en: '**Redshift support for row-level security and column-level access control**:
    Used to enable fine-grained access to the rows and columns in the tables in Redshift.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Redshift 支持行级安全性和列级访问控制**：用于启用对 Redshift 表中行和列的细粒度访问。'
- en: '`*******@email.com` instead of `johndoe@email.com`).'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`*******@email.com` 而不是 `johndoe@email.com`）。'
- en: '**Redshift support for cross-account data sharing**: Used to share the data
    stored in a Redshift warehouse across AWS accounts (so that the data no longer
    needs to be copied and transferred to another account when access needs to be
    shared).'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Redshift 支持跨账户数据共享**：用于在 AWS 账户之间共享存储在 Redshift 仓库中的数据（这样在需要共享访问时，数据就不再需要复制和传输到另一个账户）。'
- en: '**Amazon OpenSearch Service field masking support**: This uses pattern-based
    field masking to hide sensitive data such as PII when performing a search query
    in the Amazon OpenSearch service.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon OpenSearch 服务字段掩码支持**：在执行 Amazon OpenSearch 服务的搜索查询时，使用基于模式的字段掩码来隐藏敏感数据，如
    PII。'
- en: '**S3 Object Lambda**: Custom code is used to process and modify the output
    of S3 GET requests (which includes the ability to mask and redact data).'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**S3 对象 Lambda**：使用自定义代码来处理和修改 S3 GET 请求的输出（包括掩码和编辑数据的能力）。'
- en: '**AWS Lake Formation support for row-level and cell-level security**: This
    enables fine-grained access to query results and AWS Glue ETL jobs.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS Lake Formation 支持行级和单元格级安全**：这使查询结果和 AWS Glue ETL 作业的细粒度访问成为可能。'
- en: '**Principal Component Analysis (SageMaker built-in algorithm)**: A PCA-based
    transformation that’s used to preserve data privacy while preserving the “nature”
    of the data.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主成分分析（SageMaker 内置算法）**：一种基于 PCA 的转换，用于在保护数据隐私的同时保留数据的“本质”。'
- en: At this point, we should have a better understanding of the different approaches
    to managing data and model privacy. In the next section, we will talk about ML
    governance, and we will discuss the different solutions available in AWS.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们应该对管理数据和模型隐私的不同方法有了更好的理解。在下一节中，我们将讨论机器学习治理，并讨论 AWS 中可用的不同解决方案。
- en: Establishing ML governance
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立机器学习治理
- en: 'When working on ML initiatives and requirements, ML governance must be taken
    into account as early as possible. Companies and teams with poor governance experience
    both short-term and long-term issues due to the following reasons:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理机器学习项目和需求时，必须尽早考虑机器学习治理。由于以下原因，治理经验较差的公司和团队会面临短期和长期问题：
- en: '*The absence of clear and accurate inventory tracking of ML models*'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*缺乏对机器学习模型清晰和准确的清单跟踪*'
- en: '*Limitations concerning model explainability and interpretability*'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*关于模型可解释性和可解释性的局限性*'
- en: '*The existence of bias in the training data*'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*训练数据中存在偏差*'
- en: '*Inconsistencies in the training and inference data distributions*'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*训练和推理数据分布的不一致性*'
- en: '*The absence of automated experiment lineage tracking processes*'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*缺乏自动化的实验谱系跟踪流程*'
- en: '*How do we deal with these issues and challenges?* We can solve and manage
    these issues by establishing ML governance (the right way) and making sure that
    the following areas are taken into account:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们如何处理这些问题和挑战？* 我们可以通过建立机器学习治理（正确的方式）并确保以下领域被考虑来解决和管理这些问题：'
- en: Lineage tracking and reproducibility
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谱系跟踪和可重复性
- en: Model inventory
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型清单
- en: Model validation
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型验证
- en: ML explainability
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习可解释性
- en: Bias detection
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偏差检测
- en: Model monitoring
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型监控
- en: Data analysis and data quality reporting
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分析和数据质量报告
- en: Data integrity management
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据完整性管理
- en: We will discuss each of these in detail in this section. Feel free to get a
    cup of coffee or tea before proceeding!
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本节中详细讨论这些内容。在继续之前，请随意喝杯咖啡或茶！
- en: Lineage Tracking and reproducibility
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谱系跟踪和可重复性
- en: In [*Chapter 6*](B18638_06.xhtml#_idTextAnchor132), *SageMaker Training and
    Debugging Solutions*, we discussed how an ML model is produced after using a training
    dataset, an algorithm, a specific configuration of hyperparameter values, and
    other relevant training configuration parameter values as inputs to a training
    job.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第 6 章*](B18638_06.xhtml#_idTextAnchor132) *SageMaker 训练和调试解决方案* 中，我们讨论了在使用训练数据集、算法、特定超参数值的配置以及其他相关训练配置参数值作为训练作业的输入后，如何生成机器学习模型。
- en: Data scientists and ML practitioners must be able to verify that a model can
    be built and reproduced using the same set of configuration settings, along with
    other “inputs” such as the training dataset and the algorithm. If we were dealing
    with a single experiment, manually keeping track of these is relatively easy.
    Maybe storing this information in a spreadsheet or a markdown file would do the
    trick! As our requirements evolve, this information may get lost along the way,
    especially if done manually. That said, keeping track of this “history” or **lineage**
    would get much harder and trickier once we need to run multiple training experiments
    using a variety of combinations of hyperparameter configuration values (for example,
    when using the **Automatic Model Tuning** capability of SageMaker). The good news
    is that SageMaker automatically helps us keep track of this with **SageMaker ML
    Lineage Tracking** and **SageMaker Experiments**. If we want to see the experiment
    lineage along with the other details, **SageMaker Studio** makes it easy for us
    to easily get this information with just a few clicks.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家和机器学习从业者必须能够验证模型是否可以使用相同的配置设置构建和重现，包括其他“输入”如训练数据集和算法。如果我们只处理一个实验，手动跟踪这些信息相对容易。也许将此信息存储在电子表格或Markdown文件中就能解决问题！随着我们需求的演变，这些信息可能会在过程中丢失，尤其是在手动操作的情况下。话虽如此，一旦我们需要使用各种超参数配置值的组合（例如，使用SageMaker的**自动模型调优**功能）运行多个训练实验，跟踪这个“历史”或**血缘**就会变得更加困难和复杂。好消息是，SageMaker自动帮助我们通过**SageMaker
    ML血缘跟踪**和**SageMaker实验**来跟踪这些信息。如果我们想查看实验血缘以及其他详细信息，**SageMaker Studio**只需几点击就能轻松获取这些信息。
- en: Note
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '[PRE12]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In addition to the automated experiment and lineage tracking performed by SageMaker,
    it is important to note that we can also manually create associations programmatically.
    We can also use **boto3** and the **SageMaker Search** API to get details and
    information about the training used to train the ML models. In most cases, we
    would be fine using the SageMaker Console, along with the search functionality
    available.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 除了SageMaker执行的自动实验和血缘跟踪外，重要的是要注意我们还可以通过编程方式手动创建关联。我们还可以使用**boto3**和**SageMaker
    Search** API来获取有关训练ML模型的详细信息。在大多数情况下，我们可以使用SageMaker控制台，以及可用的搜索功能。
- en: If you are using a deep learning framework to run training scripts on top of
    AWS compute services such as EC2, ECS, or Lambda, you may use libraries such as
    **ML Metadata** (for TensorFlow) to keep track of the lineage, along with the
    artifacts of the different components in the ML pipeline.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用深度学习框架在AWS计算服务（如EC2、ECS或Lambda）上运行训练脚本，你可以使用如**ML Metadata**（用于TensorFlow）的库来跟踪血缘，以及机器学习管道中不同组件的工件。
- en: Note
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For more information about **ML Metadata**, check out [https://www.tensorflow.org/tfx/tutorials/mlmd/mlmd_tutorial](https://www.tensorflow.org/tfx/tutorials/mlmd/mlmd_tutorial).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于**ML Metadata**的信息，请查看[https://www.tensorflow.org/tfx/tutorials/mlmd/mlmd_tutorial](https://www.tensorflow.org/tfx/tutorials/mlmd/mlmd_tutorial)。
- en: Model inventory
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型库存
- en: Managing model inventory is crucial to establishing ML governance. Being able
    to maintain an organized model inventory allows key members of the data science
    team to know the current status and performance of models immediately.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 管理模型库存对于建立机器学习治理至关重要。能够维护一个有序的模型库存，使得数据科学团队的关键成员能够立即了解模型的当前状态和性能。
- en: 'There are different ways to manage model inventory in ML environments on AWS.
    One possible approach we can do is to build a custom solution using a variety
    of services! For example, we may design and build a *serverless* model registry
    from scratch using **Amazon DynamoDB**, **Amazon S3**, **Amazon ECR**, **Amazon
    API Gateway**, and **AWS Lambda**, as shown in the following diagram:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS的机器学习环境中管理模型库存有不同方式。我们可以采取的一种可能的方法是使用各种服务构建一个定制解决方案！例如，我们可以从头开始设计和构建一个**无服务器**的模型注册表，使用**Amazon
    DynamoDB**、**Amazon S3**、**Amazon ECR**、**Amazon API Gateway**和**AWS Lambda**，如下面的图所示：
- en: '![Figure 9.6 – Custom-built model registry ](img/B18638_09_006.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图9.6 – 定制构建的模型注册表](img/B18638_09_006.jpg)'
- en: Figure 9.6 – Custom-built model registry
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6 – 定制构建的模型注册表
- en: 'In this custom solution, we prepare the following Lambda functions:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个定制解决方案中，我们准备以下Lambda函数：
- en: '**UPLOAD MODEL PACKAGE**: For uploading a model package (which includes the
    ML model artifacts, scripts for training and inference, container image for the
    environment where the scripts will run, and the model metadata)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上传模型包**：用于上传模型包（包括ML模型工件、训练和推理脚本、脚本将运行的环境的容器镜像以及模型元数据）'
- en: '`PENDING`, `APPROVED`, or `REJECTED` state), along with the identifiers and
    paths where the different components of the model package are stored'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PENDING`、`APPROVED`或`REJECTED`状态，以及模型包不同组件存储的标识符和路径'
- en: '`PENDING`, `APPROVED`, or `REJECTED`'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PENDING`、`APPROVED`或`REJECTED`'
- en: We can easily add more Lambda functions in case we need to extend the functionality
    of this custom-built model registry. This option would give us the greatest amount
    of flexibility at the expense of a few days setting the entire system up.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要扩展此自定义模型注册表的函数，我们可以轻松地添加更多Lambda函数。这个选项将给我们带来最大的灵活性，但需要花费几天时间来设置整个系统。
- en: Another option would be to use an existing one such as **MLFlow Model Registry**
    and deploy it inside an EC2 instance or in an ECS container. Finally, we can use
    **SageMaker Model Registry**, which already has the model inventory management
    features we need, such as model approval and model life cycle tracking.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是使用现有的一个，例如**MLFlow模型注册表**，并在EC2实例或ECS容器中部署它。最后，我们可以使用**SageMaker模型注册表**，它已经具有我们需要的模型库存管理功能，例如模型批准和模型生命周期跟踪。
- en: Note
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Feel free to check out [*Chapter 8*](B18638_08.xhtml#_idTextAnchor172), *Model
    Monitoring and Management Solutions*, for more information and details on how
    to use SageMaker Model Registry.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解更多信息和如何使用SageMaker模型注册表的详细信息，请随时查看[*第8章*](B18638_08.xhtml#_idTextAnchor172)，*模型监控和管理解决方案*。
- en: Model validation
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型验证
- en: After an ML model has been trained, it needs to be evaluated to check if its
    performance allows certain business targets to be achieved. Data science teams
    also need to validate the choice of the model as simple models may be prone to
    **underfitting** while complex models tend to be prone to **overfitting**. At
    the same time, the metrics used for model validation need to be reviewed as the
    ability of some metrics to represent model performance depends on the context
    of the problem being solved. For example, the **balanced F-score** may be a more
    meaningful option compared to **accuracy** for fraud detection use cases (since
    the model accuracy score can still be high due to class imbalance).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在ML模型训练完成后，需要对其进行评估，以检查其性能是否允许实现某些业务目标。数据科学团队还需要验证模型的选择，因为简单模型可能容易**欠拟合**，而复杂模型则容易**过拟合**。同时，需要审查用于模型验证的指标，因为某些指标表示模型性能的能力取决于所解决问题的上下文。例如，对于欺诈检测用例，**平衡F分数**可能是一个更有意义的选项，比**准确率**更有意义（因为由于类别不平衡，模型准确率分数仍然可能很高）。
- en: Note
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For more information on the balanced F-score, feel free to check out [https://en.wikipedia.org/wiki/F-score](https://en.wikipedia.org/wiki/F-score).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解更多关于平衡F分数的信息，请随时查看[https://en.wikipedia.org/wiki/F-score](https://en.wikipedia.org/wiki/F-score)。
- en: 'The first way to evaluate a model is through **offline testing**, where historical
    data is used to evaluate the trained model. This may be done through **validation
    using a “holdout set”**, which is data not used for model training. Another option
    would be to use **k-fold cross-validation**, which is a popular technique to detect
    overfitting. Offline testing can be performed when using SageMaker in a variety
    of ways:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型的第一种方式是通过**离线测试**，使用历史数据来评估训练好的模型。这可以通过使用“保留集”进行**验证**来完成，这些数据未用于模型训练。另一种选择是使用**k折交叉验证**，这是一种流行的检测过拟合的技术。当使用SageMaker时，可以通过多种方式执行离线测试：
- en: 'The model files (stored inside a `model.tar.gz` file) generated after a SageMaker
    training job can be loaded and evaluated without the existence of a SageMaker
    Inference Endpoint using the appropriate library or framework. For example, a
    **Linear Learner** model trained using SageMaker can be loaded using **MXNet**
    (for example, within a custom application running in a container), as shown in
    the following block of code:'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在SageMaker训练作业完成后生成的模型文件（存储在`model.tar.gz`文件中）可以通过适当的库或框架加载和评估，而无需SageMaker推理端点的存在。例如，使用SageMaker训练的**线性学习器**模型可以使用**MXNet**（例如，在容器中运行的定制应用程序内）加载，如下面的代码块所示：
- en: '[PRE13]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Once the model has been evaluated, it can be deployed to an inference endpoint.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型经过评估，就可以部署到推理端点。
- en: An alternative would be to deploy the model into an “alpha” ML inference endpoint
    and evaluate it using historical data. Once the evaluation step has been completed,
    the model can be deployed into the “production” ML inference endpoint and the
    “alpha” endpoint can be deleted.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一种选择是将模型部署到“alpha”机器学习推理端点，并使用历史数据对其进行评估。一旦评估步骤完成，可以将模型部署到“生产”机器学习推理端点，并删除“alpha”端点。
- en: The other approach involves **online testing**, where live data is used to evaluate
    the model. Online testing can be performed using SageMaker through its A/B testing
    support, where two or more models can be deployed under one inference endpoint.
    With this approach, a small percentage of the traffic can be routed to the variant
    of the model that’s being validated for a certain period. Once the validation
    step is complete, 100% of the traffic can be routed to one of the variants completely.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法涉及**在线测试**，使用实时数据来评估模型。可以使用SageMaker通过其A/B测试支持进行在线测试，其中可以在一个推理端点下部署两个或多个模型。采用这种方法，可以将一小部分流量路由到正在验证的模型变体，持续一定时期。一旦验证步骤完成，可以将100%的流量路由到其中一个变体。
- en: Note
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Check out the following Notebook for an example of how to set up A/B testing
    of multiple models using SageMaker: [https://bit.ly/3uSRZSE](https://bit.ly/3uSRZSE).'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下笔记本，了解如何使用SageMaker设置多个模型的A/B测试示例：[https://bit.ly/3uSRZSE](https://bit.ly/3uSRZSE)。
- en: Now that we’ve discussed model evaluation, let’s dive a bit deeper into ML explainability.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经讨论了模型评估，让我们进一步探讨机器学习可解释性。
- en: ML explainability
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习可解释性
- en: In some cases, business owners and stakeholders reject the usage of certain
    types of models due to issues concerning ML explainability. Sometimes, due to
    the complexity of an ML model, it is difficult to conceptually explain how it
    works or how it produces the prediction or inference result. Stakeholders have
    a higher chance of approving the usage of certain models once they have more visibility
    and understanding of how ML models have produced the output. This involves understanding
    how much each feature contributes to the model’s predicted output value.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，由于机器学习可解释性的问题，企业主和利益相关者拒绝使用某些类型的模型。有时，由于机器学习模型的复杂性，很难从概念上解释它是如何工作的，或者它是如何产生预测或推理结果的。一旦利益相关者对机器学习模型如何产生输出有更多的可见性和理解，他们更有可能批准使用某些模型。这涉及到理解每个特征对模型预测输出值的贡献程度。
- en: Note
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Note that **model interpretability** and **model explainability** are often
    interchanged by ML practitioners. However, these two terms are different and should
    be used with care. Interpretability focuses on how an ML model works – that is,
    how it works internally. On the other hand, explainability focuses on the behavior
    of an ML model, which includes how the input feature values contribute to the
    predicted output value. For more information on this topic, feel free to check
    out [https://docs.aws.amazon.com/whitepapers/latest/model-explainability-aws-ai-ml/interpretability-versus-explainability.xhtml](https://docs.aws.amazon.com/whitepapers/latest/model-explainability-aws-ai-ml/interpretability-versus-explainability.xhtml).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，机器学习从业者经常将**模型可解释性**和**模型可解释性**互换使用。然而，这两个术语是不同的，应该谨慎使用。可解释性关注的是机器学习模型的工作方式——即它是如何内部工作的。另一方面，可解释性关注的是机器学习模型的行为，包括输入特征值如何影响预测输出值。有关此主题的更多信息，请随时查看[https://docs.aws.amazon.com/whitepapers/latest/model-explainability-aws-ai-ml/interpretability-versus-explainability.xhtml](https://docs.aws.amazon.com/whitepapers/latest/model-explainability-aws-ai-ml/interpretability-versus-explainability.xhtml)。
- en: ML explainability can be approached with **global explainability** and **local
    explainability**. We can say that global explainability has been achieved if we’re
    able to identify how much each feature contributes to the model’s prediction across
    all predictions. On the other hand, local explainability can be achieved if we’re
    able to identify how much each feature contributes to the model’s prediction for
    a single record (or data point).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习可解释性可以通过**全局可解释性**和**局部可解释性**来处理。如果我们能够识别出每个特征对模型预测的贡献程度，那么我们就实现了全局可解释性。另一方面，如果我们能够识别出每个特征对单个记录（或数据点）的预测的贡献程度，那么我们就可以实现局部可解释性。
- en: Note
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For more information about ML explainability, check out [https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-explainability.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-explainability.xhtml).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多关于机器学习可解释性的信息，请查看[https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-explainability.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-model-explainability.xhtml)。
- en: 'Here are some of the possible solutions when generating ML explainability reports:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成机器学习可解释性报告时，以下是一些可能的解决方案：
- en: Use open source libraries (for example, the `shap` library) and implement a
    custom solution deployed in an **AWS Lambda** function or an **Amazon ECS** container.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用开源库（例如，`shap`库）并在**AWS Lambda**函数或**Amazon ECS**容器中部署自定义解决方案。
- en: 'Use **SageMaker Clarify** to run a job and generate explainability reports:'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**SageMaker Clarify**运行一个作业并生成可解释性报告：
- en: '[PRE25]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Use open source libraries (for example, the `shap` library) and use **SageMaker
    Processing** to run the custom code, along with a custom container image.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用开源库（例如，`shap`库）并使用**SageMaker Processing**运行自定义代码，同时使用自定义容器镜像。
- en: Now that we’ve talked about ML Explainability, let’s jump into how to perform
    ML bias detection using a variety of solutions on AWS.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经讨论了机器学习可解释性，让我们来看看如何在AWS上使用各种解决方案来执行机器学习偏差检测。
- en: Bias detection
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏差检测
- en: Detecting ML bias is critical to the success of any ML project. If ML bias is
    not detected and mitigated, automated systems utilizing ML models may end up with
    unfair predictions. For example, an ML-based recruitment application may make
    unfair candidate selections against certain groups (for example, against female
    candidates). Another example would be an automated loan application that rejects
    loan applications from under-represented groups (for example, those living in
    specific countries).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 检测机器学习偏差对于任何机器学习项目的成功至关重要。如果机器学习偏差没有被检测和缓解，利用机器学习模型的自动化系统可能会得出不公平的预测。例如，基于机器学习的招聘应用程序可能会对某些群体（例如，女性候选人）做出不公平的候选人选择。另一个例子是自动贷款申请可能会拒绝来自代表性不足的群体的贷款申请（例如，居住在特定国家的群体）。
- en: 'ML bias can be measured using a variety of metrics. Here are some of the metrics
    that can be used to measure ML bias:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习偏差可以使用各种指标来衡量。以下是一些可以用来衡量机器学习偏差的指标：
- en: '**Class imbalance**: This measures and detects any imbalance in the number
    of members between different groups.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类别不平衡**：这衡量和检测不同组之间成员数量的任何不平衡。'
- en: '**Label imbalance**: This measures and detects any imbalance in the positive
    outcomes between different groups.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签不平衡**：这衡量和检测不同组之间正结果之间的任何不平衡。'
- en: '**Kullback-Leibler (KL) divergence**: This compares and measures how different
    the outcome distributions of different groups are.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kullback-Leibler (KL) 散度**：这比较和衡量不同组的结果分布之间的差异。'
- en: '**Jensen-Shannon (JS) divergence**: Similar to KL divergence, JS divergence
    compares and measures how different the outcome distributions of different groups
    are.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jensen-Shannon (JS) 散度**：与KL散度类似，JS散度比较和衡量不同组的结果分布之间的差异。'
- en: Note
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you’re interested in learning more about the different metrics to measure
    ML bias, check out [https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.xhtml).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于衡量机器学习偏差的不同指标，请查看[https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-data-bias.xhtml)。
- en: 'Here are some of the possible solutions when using AWS services and capabilities
    to detect ML bias:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用AWS服务和功能来检测机器学习偏差时，以下是一些可能的解决方案：
- en: Use open source libraries (for example, `ResponsiblyAI/responsibly`) and implement
    a custom solution deployed in an **AWS Lambda** function or an **Amazon ECS**
    container.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用开源库（例如，`ResponsiblyAI/responsibly`）并在**AWS Lambda**函数或**Amazon ECS**容器中部署自定义解决方案。
- en: 'Use **SageMaker Clarify** to run a job and generate pre-training and post-training
    bias reports:'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**SageMaker Clarify**运行一个作业并生成预训练和后训练偏差报告：
- en: '[PRE27]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Use open source libraries (for example, `ResponsiblyAI/responsibly` library)
    and use **SageMaker Processing** to run the custom code, along with a custom container
    image.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用开源库（例如，`ResponsiblyAI/responsibly`库）并使用**SageMaker Processing**运行自定义代码，同时使用自定义容器镜像。
- en: Use **SageMaker Model Monitor** with **SageMaker Clarify** to monitor bias drift
    in models deployed in an inference endpoint.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**SageMaker Model Monitor**与**SageMaker Clarify**一起监控推理端点中部署的模型中的偏差漂移。
- en: After detecting ML bias, the next step is to resolve and mitigate the issue(s)
    through a variety of means (depending on the context and type of ML bias). We
    won’t discuss the different bias mitigation strategies in this book, so feel free
    to check out https://sagemaker-examples.readthedocs.io/en/latest/end_to_end/fraud_detection/3-mitigate-bias-train-model2-registry-e2e.xhtml#Develop-an-Unbiased-Model
    for a quick end-to-end example.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测到机器学习偏差后，下一步是通过各种手段（根据上下文和机器学习偏差的类型）解决和缓解问题。本书不会讨论不同的偏差缓解策略，因此请随意查看 https://sagemaker-examples.readthedocs.io/en/latest/end_to_end/fraud_detection/3-mitigate-bias-train-model2-registry-e2e.xhtml#Develop-an-Unbiased-Model
    以获取一个快速端到端示例。
- en: Model monitoring
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型监控
- en: In [*Chapter 8*](B18638_08.xhtml#_idTextAnchor172), *Model Monitoring and Management
    Solutions*, we enabled data capture in an ML inference endpoint and then set up
    scheduled monitoring, which detects violations and data quality issues from the
    data captured. This setup will help us detect any inconsistencies as early as
    possible so that corrective measures can be applied right away. *What will happen
    if these issues and inconsistencies are not corrected?* If corrective measures
    are not applied right away, the deployed model may experience performance decay
    or degradation until the “fixes” have been applied. Of course, before any corrections
    can be applied, we need to detect these inconsistencies first. That said, our
    next question would be, *How do we detect these inconsistencies and issues?*
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第8章*](B18638_08.xhtml#_idTextAnchor172)，*模型监控与管理解决方案*中，我们实现了在机器学习推理端点上的数据捕获，并随后设置了计划监控，该监控能够从捕获的数据中检测违规和数据质量问题。这种设置将帮助我们尽早发现任何不一致性，以便立即采取纠正措施。*如果这些问题和不一致性得不到纠正，会发生什么？*
    如果不立即采取纠正措施，部署的模型可能会经历性能衰减或退化，直到“修复”被应用。当然，在应用任何纠正措施之前，我们首先需要检测这些不一致性。也就是说，我们的下一个问题将是，*我们如何检测这些不一致性和问题？*
- en: '![Figure 9.7 – Detecting drift ](img/B18638_09_007.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![图9.7 – 检测漂移](img/B18638_09_007.jpg)'
- en: Figure 9.7 – Detecting drift
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.7 – 检测漂移
- en: In the preceding diagram, we can see that we can detect “drift” by performing
    the required analysis (for example, data quality checks) on the baseline dataset
    and on the captured ML inference data (which passed through the ML inference endpoint).
    Once the required analysis is complete, the results of both the baseline dataset
    and the captured ML inference data are compared to see if the differences in the
    results exceed a certain threshold.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，我们可以看到，通过在基线数据集和捕获的机器学习推理数据（通过机器学习推理端点）上执行所需的分析（例如，数据质量检查），我们可以检测到“漂移”。一旦完成所需的分析，基线数据集和捕获的机器学习推理数据的分析结果将被比较，以查看结果差异是否超过某个阈值。
- en: 'Note that we can detect the following issues using **SageMaker Model Monitor**:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们可以使用 **SageMaker 模型监控器** 检测以下问题：
- en: '**Data quality drift**: This is detected by comparing the following:'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据质量漂移**：这是通过比较以下内容来检测的：'
- en: '**[“PROPERTIES” – A]**: The statistical nature and the properties (for example,
    data type) of the baseline dataset used to train the model deployed'
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[“属性” – A]**：用于训练部署模型的基线数据集的统计性质和属性（例如，数据类型）'
- en: '**[“PROPERTIES” – B]**: The properties of the capture ML inference data'
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[“属性” – B]**：捕获的机器学习推理数据的属性'
- en: '**Model performance drift**: This is detected by comparing the following:'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型性能漂移**：这是通过比较以下内容来检测的：'
- en: '**[“PROPERTIES” – A]**: The performance of the model on the baseline dataset'
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[“属性” – A]**：模型在基线数据集上的性能'
- en: '**[“PROPERTIES” – B]**: The performance of the model on the captured ML inference
    data (merged with uploaded ground truth labels)'
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[“属性” – B]**：模型在捕获的机器学习推理数据上的性能（与上传的地面实况标签合并）'
- en: '**Model bias drift**: This is detected by comparing the following:'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型偏差漂移**：这是通过比较以下内容来检测的：'
- en: '**[“PROPERTIES” – A]**: The bias metrics of the model on the baseline dataset'
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[“属性” – A]**：模型在基线数据集上的偏差度量'
- en: '**[“PROPERTIES” – B]**: The bias metrics on the captured ML inference data'
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[“属性” – B]**：捕获的机器学习推理数据上的偏差度量'
- en: '**Feature attribution drift**: This is detected by comparing the following:'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征归因漂移**：这是通过比较以下内容来检测的：'
- en: '**[“PROPERTIES” – A]**: The feature distribution values of the baseline dataset'
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[“属性” – A]**：基线数据集的特征分布值'
- en: '**[“PROPERTIES” – B]**: The feature distribution values of the captured ML
    inference data'
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[“属性” – B]**：捕获的机器学习推理数据的特征分布值'
- en: Note
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To make it easier to grasp these concepts, let’s discuss a simple example of
    how `age` and `salary`. Then, we used this training dataset for the baseline of
    SageMaker Model Monitor. After analyzing the dataset, SageMaker Model Monitor
    returned a set of suggested constraints that required that the age and salary
    values be always positive. The ML model was then deployed to a SageMaker inference
    endpoint that was configured to collect the request and response data containing
    the input and output values (that is, the age input and the predicted salary values).
    Then, we configured a SageMaker Model Monitor “schedule” that triggers a processing
    job. This analyzes the collected request and response data and checks for violations
    against the configured constraints. If the collected data contained negative values
    for the age input values, SageMaker Model Monitor should be able to detect this
    and flag this violation after the scheduled processing job has finished running.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易理解这些概念，让我们讨论一个简单的例子，看看如何处理`年龄`和`薪水`。然后，我们使用这个训练数据集作为SageMaker模型监控器的基线。在分析数据集后，SageMaker模型监控器返回了一组建议的约束，要求年龄和薪水的值始终为正。随后，我们将ML模型部署到配置为收集包含输入和输出值（即年龄输入和预测的薪水值）的请求和响应数据的SageMaker推理端点。然后，我们配置了一个SageMaker模型监控器“计划”，该计划触发一个处理作业。这个作业分析收集到的请求和响应数据，并检查是否违反了配置的约束。如果收集到的数据中包含年龄输入值的负值，SageMaker模型监控器应该能够检测到这一点，并在计划的处理作业完成后标记此违规行为。
- en: 'Once the detected inconsistencies and issues have been analyzed, the data science
    team may perform one or more of the following fixes or corrections, depending
    on the issue:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦分析完检测到的不一致性和问题，数据科学团队可能会根据问题执行以下一个或多个修复或更正操作：
- en: Fix issues in the systems that send “bad data” to the ML inference endpoint.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修复向机器学习推理端点发送“不良数据”的系统中的问题。
- en: Replace the deployed model with a new one.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用新的模型替换已部署的模型。
- en: Correct existing issues in the model training and deployment pipeline.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修复模型训练和部署管道中的现有问题。
- en: Now, let’s look at traceability, observability, and auditing.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看可追溯性、可观察性和审计。
- en: Traceability, observability, and auditing
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可追溯性、可观察性和审计
- en: We must be able to audit and check everything happening in every step of an
    ML experiment or deployment, regardless of the steps being performed manually
    or automatically. This allows us to easily identify and fix issues to return the
    system to the desired configuration state. If an ML system is in an “unstable”
    state, an ML engineer must be able to use the right set of tools to troubleshoot
    and fix the issues quickly.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须能够审计和检查机器学习实验或部署的每一步中发生的一切，无论这些步骤是手动执行还是自动执行。这使我们能够轻松地识别和修复问题，使系统回到期望的配置状态。如果一个ML系统处于“不稳定”状态，ML工程师必须能够使用正确的工具集快速进行故障排除和修复问题。
- en: Let’s say that your team has started using an automated ML pipeline that accepts
    a dataset as input and generates a binary classification ML model as output (after
    going through all the steps in the pipeline). For a few weeks, the ML pipeline
    is working just fine... until the team decided to introduce additional data processing
    steps somewhere in the middle of the pipeline. The team noticed that the majority
    of the binary classification models generated by the pipeline *ALWAYS* returned
    a `0`, no matter what the input values were! Before the changes in the pipeline
    were implemented, all the models generated had been returning *0s* and *1s* (which
    is what is expected). As the ML engineer, you decided to dive a bit deeper into
    what happened... only to find out that the ML pipeline steps did not produce logs,
    which made troubleshooting harder. At the same time, you discovered that there
    was no tracking mechanism in place that can help the team “connect the dots” and
    analyze why the generated models were always producing a `0` for the classification
    result. After realizing that it will take a few weeks to troubleshoot and fix
    the existing set of issues, your team decided to stop using the automated ML pipeline
    (which took a few months to build and polish) and throw it away. *Ouch!* If the
    tracking and auditing mechanisms were in place, the automated ML pipeline could
    have been restored to a stable state much faster.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的团队已经开始使用一个自动化的机器学习管道，该管道接受数据集作为输入，并在经过管道中的所有步骤后生成一个二进制分类机器学习模型作为输出。在几周的时间里，机器学习管道运行得很好...直到团队决定在管道的中间某个位置引入额外的数据处理步骤。团队注意到，由管道生成的多数二进制分类模型*总是*返回`0`，无论输入值是什么！在管道更改实施之前，所有生成的模型都返回了*0s*和*1s*（这是预期的）。作为机器学习工程师，你决定深入调查发生了什么...结果发现机器学习管道步骤没有生成日志，这使得故障排除变得更加困难。同时，你发现没有跟踪机制可以帮团队“连接点”并分析为什么生成的模型总是为分类结果生成`0`。在意识到需要几周时间来排查和修复现有问题后，你的团队决定停止使用自动化的机器学习管道（该管道花费了几个月的时间构建和打磨），并将其丢弃。*哎呀!*
    如果有跟踪和审计机制，自动化的机器学习管道可以更快地恢复到稳定状态。
- en: Note
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Don’t let this happen to you and your team! It’s critical to use the right set
    of tools when building ML pipelines. For more information on ML pipelines, feel
    free to check out [*Chapter 10*](B18638_10.xhtml#_idTextAnchor215), *Machine Learning
    Pipelines with Kubeflow on Amazon EKS*, and [*Chapter 11*](B18638_11.xhtml#_idTextAnchor231),
    *Machine Learning Pipelines with SageMaker Pipelines*.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 不要让这种情况发生在你和你的团队身上！在构建机器学习管道时使用正确的工具集至关重要。有关机器学习管道的更多信息，请随时查看[*第10章*](B18638_10.xhtml#_idTextAnchor215)，*在Amazon
    EKS上使用Kubeflow的机器学习管道*，以及[*第11章*](B18638_11.xhtml#_idTextAnchor231)，*使用SageMaker
    Pipelines的机器学习管道*。
- en: 'As an ML engineer, you need to be aware of the “tools” available for these
    types of requirements. We can use the following services and capabilities when
    performing audit work on ML environments and systems in AWS:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 作为机器学习工程师，你需要了解这些类型需求可用的“工具”。在AWS中对机器学习环境和系统执行审计工作时，我们可以使用以下服务和功能：
- en: '**AWS CloudTrail**: This can be used to capture and log any configuration changes
    in the AWS account.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS CloudTrail**：这可以用于捕获和记录AWS账户中的任何配置更改。'
- en: '**AWS CloudTrail Lake**: This is a managed data lake for CloudTrail data analysis.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS CloudTrail Lake**：这是一个用于CloudTrail数据分析的托管数据湖。'
- en: '**Amazon CloudWatch Logs**: This contains the activity logs from a variety
    of services such as SageMaker, EC2, and Redshift.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon CloudWatch 日志**：这包含来自各种服务（如SageMaker、EC2和Redshift）的活动日志。'
- en: '**Amazon Athena CloudWatch connector**: This enables CloudWatch log data to
    be queried in Amazon Athena using SQL statements.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon Athena CloudWatch 连接器**：这使您可以使用SQL语句在Amazon Athena中查询CloudWatch日志数据。'
- en: '**SageMaker Model Registry**: This can be used to track model deployment approvals.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SageMaker Model Registry**：这可以用于跟踪模型部署的批准。'
- en: '**SageMaker Experiments** and **SageMaker Lineage**: These can be used to audit
    and track model lineage after performing experiments in SageMaker.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SageMaker Experiments** 和 **SageMaker Lineage**：这些可以用于在SageMaker中完成实验后审计和跟踪模型血缘。'
- en: '**AWS Audit Manager**: This can be used to simplify and speed up the auditing
    process of an AWS account.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS Audit Manager**：这可以用于简化并加快AWS账户的审计过程。'
- en: '**AWS X-Ray**: This can be used to trace requests across the entire application
    and troubleshoot performance bottlenecks in distributed applications.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS X-Ray**：这可以用于追踪整个应用程序中的请求，并排查分布式应用程序中的性能瓶颈。'
- en: We won’t dive deep into the details of how these services are used, so feel
    free to check out the *Further reading* section at the end of this chapter for
    more details.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入探讨这些服务如何使用，因此请随意查看本章末尾的*进一步阅读*部分以获取更多详细信息。
- en: Data quality analysis and reporting
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据质量分析和报告
- en: Being able to detect data quality issues as early as possible would help us
    manage any risks associated with these issues. At the same time, we would be able
    to perform any required short-term and long-term corrections on the implementation,
    setup, or architecture of the ML system. In this section, we will discuss some
    of the possible solutions we can use to analyze the quality of the data used for
    training and inference.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 能够尽早检测数据质量问题将帮助我们管理与之相关的任何风险。同时，我们能够在ML系统的实现、设置或架构上进行任何必要的短期和长期修正。在本节中，我们将讨论我们可以使用的某些可能的解决方案，以分析用于训练和推理的数据质量。
- en: The first solution involves using custom code and open source packages to prepare
    and generate data quality reports. In [*Chapter 1*](B18638_01.xhtml#_idTextAnchor017),
    *Introduction to ML Engineering on AWS*, we used a Python library called `pandas_profiling`
    to automatically analyze our data and generate a profile report. Note that there
    are similar libraries and packages available that we can use as well. Of course,
    with this approach, we will have to manage the infrastructure aspect ourselves.
    If we want to upgrade this setup, we can choose to deploy our custom data profiling
    scripts in a serverless function using **AWS Lambda** or in a containerized application
    using **Amazon ECS**.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个解决方案涉及使用自定义代码和开源包来准备和生成数据质量报告。在[*第一章*](B18638_01.xhtml#_idTextAnchor017)
    *AWS机器学习工程简介*中，我们使用了一个名为`pandas_profiling`的Python库来自动分析我们的数据并生成分析报告。请注意，还有类似的库和包可供我们使用。当然，采用这种方法，我们将不得不自行管理基础设施方面。如果我们想升级这个设置，我们可以选择在**AWS
    Lambda**或使用**Amazon ECS**容器化应用程序中部署我们的自定义数据分析脚本。
- en: Another practical alternative would be to avoid building custom solutions ourselves
    and simply use an existing service that allows us to focus on our objectives and
    responsibilities. In [*Chapter 5*](B18638_05.xhtml#_idTextAnchor105), *Pragmatic
    Data Processing and Analysis*, we used **AWS Glue DataBrew** to load, profile,
    and process our data. After running a profile job, we had access to additional
    analysis and information, including missing cell values, data distribution statistics,
    and duplicate rows.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个实用的选择是避免自己构建定制解决方案，而简单地使用现有的服务，这样我们可以专注于我们的目标和责任。在[*第五章*](B18638_05.xhtml#_idTextAnchor105)
    *实用数据处理和分析*中，我们使用了**AWS Glue DataBrew**来加载数据、分析数据和处理数据。在运行分析作业后，我们能够访问额外的分析和信息，包括缺失单元格值、数据分布统计和重复行。
- en: Note
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Data quality issues may also arise during inference. Once we have deployed an
    ML model into an inference endpoint, the model can make predictions on request
    payloads with missing values and data quality issues. In [*Chapter 8*](B18638_08.xhtml#_idTextAnchor172),
    *Model Monitoring and Management Solutions*, we enabled data capture and automated
    the process of detecting violations concerning the quality of data that passes
    through our SageMaker real-time inference endpoint. We scheduled a model monitoring
    processing job that would process the data and then generate an automated report
    containing different relevant violation statistics (approximately every hour).
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量问题也可能在推理过程中出现。一旦我们将机器学习模型部署到推理端点，该模型可以对包含缺失值和数据质量问题的请求数据进行预测。在[*第八章*](B18638_08.xhtml#_idTextAnchor172)
    *模型监控和管理解决方案*中，我们启用了数据捕获并自动化了检测通过我们的SageMaker实时推理端点传输的数据质量违规的过程。我们安排了一个模型监控处理作业，该作业将处理数据并生成包含不同相关违规统计信息的自动报告（大约每小时一次）。
- en: Data integrity management
  id: totrans-338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据完整性管理
- en: Maintaining and managing data integrity is not an easy task. Detecting and fixing
    data quality issues such as missing values and duplicate rows is just the first
    part of the challenge. Managing data integrity issues is the next challenge as
    we need to go one step further by ensuring that data stored in the databases is
    complete, accurate, and consistent.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 维护和管理数据完整性并非易事。检测和修复数据质量问题，如缺失值和重复行，只是挑战的第一步。管理数据完整性问题是下一个挑战，因为我们需要进一步确保数据库中存储的数据是完整、准确和一致的。
- en: 'In [*Chapter 4*](B18638_04.xhtml#_idTextAnchor079), *Serverless Data Management
    on AWS*, we loaded a synthetic dataset into a data warehouse (using Redshift Serverless)
    and into a data lake (using Amazon Athena, Amazon S3, and AWS Glue). When we performed
    a few sample queries on the dataset, we just assumed that there were no data quality
    and data integrity issues to worry about. Just to refresh our memory a bit, our
    dataset contains around 21 columns that include a few “derived” columns. A good
    example of a “derived” column is the `has_booking_changes` column. The `has_booking_changes`
    column value is expected to be `True` if the `booking_changes` column value is
    greater than `0`. Otherwise, the value of `has_booking_changes` should be `False`.
    To identify the records where the `booking_changes` column value does not match
    the `has_booking_changes` column value, we performed the following query in our
    serverless data warehouse (Redshift Serverless):'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第4章*](B18638_04.xhtml#_idTextAnchor079) *AWS上的无服务器数据管理*中，我们将一个合成数据集加载到数据仓库（使用Redshift
    Serverless）和加载到数据湖（使用Amazon Athena、Amazon S3和AWS Glue）。当我们对这个数据集执行一些样本查询时，我们只是假设没有需要担心数据质量和数据完整性问题。为了刷新我们的记忆，我们的数据集包含大约21列，其中包括一些“派生”列。一个“派生”列的好例子是`has_booking_changes`列。如果`booking_changes`列的值大于`0`，则`has_booking_changes`列的值预期为`True`。否则，`has_booking_changes`的值应该是`False`。为了识别`booking_changes`列值与`has_booking_changes`列值不匹配的记录，我们在我们的无服务器数据仓库（Redshift
    Serverless）中执行了以下查询：
- en: '[PRE29]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Here are a few ways to fix this:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些修复方法：
- en: If only a few records are affected (relative to the total number of records),
    then we may (soft) delete the affected records and exclude these records from
    future steps in the data processing workflow. Note that this should be done with
    care as excluding records may significantly affect data analysis results and ML
    model performance (if the dataset is used to train an ML model).
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果只有少数记录受到影响（相对于记录总数），那么我们可能（软删除）受影响的记录，并将这些记录排除在数据处理工作流程的未来步骤之外。请注意，这应该谨慎进行，因为排除记录可能会显著影响数据分析结果和机器学习模型性能（如果数据集用于训练机器学习模型）。
- en: We can perform an `UPDATE` statement that corrects the `booking_changes` column
    value.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以执行一个`UPDATE`语句来纠正`booking_changes`列的值。
- en: Note that another possible long-term solution would be to perform the needed
    data integrity checks and corrections before the data is loaded into the data
    warehouse or data lake. This would mean that the data in the data warehouse or
    data lake is expected to already be “clean” upon initial data load and we can
    safely perform the queries and other operations in these centralized data stores.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，另一个可能的长期解决方案是在将数据加载到数据仓库或数据湖之前执行所需的数据完整性检查和修正。这意味着数据仓库或数据湖中的数据预期在初始数据加载时已经是“干净的”，我们可以安全地在这些集中式数据存储中执行查询和其他操作。
- en: Note
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In addition to these, the applications and systems interacting with the data
    must be reviewed. Note that even if we clean the data, there’s a chance that the
    connected applications would introduce a new set of data integrity issues since
    the root cause has not been fixed.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些，还需要审查与数据交互的应用和系统。请注意，即使我们清理了数据，由于根本原因尚未解决，连接的应用程序可能会引入一组新的数据完整性问题。
- en: '*That’s pretty much it!* At this point, we should have a wider range of options
    for solving a variety of issues and challenges when establishing ML governance.
    Feel free to read this chapter again to help you get a deeper appreciation of
    the different concepts and techniques.'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '*就是这样！* 到目前为止，我们在建立机器学习治理时应该有更广泛的选项来解决各种问题和挑战。请随意再次阅读本章，以帮助您更深入地理解不同的概念和技术。'
- en: Summary
  id: totrans-349
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed a variety of strategies and solutions to manage
    the overall security, compliance, and governance of ML environments and systems.
    We started by going through several best practices to improve the security and
    compliance of ML environments. After that, we discussed relevant techniques on
    how to preserve data privacy and model privacy. Toward the end of this chapter,
    we covered different solutions using a variety of AWS services to establish ML
    governance.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了各种策略和解决方案来管理机器学习环境和系统的整体安全性、合规性和治理。我们首先通过几个最佳实践来提高机器学习环境的安全性。之后，我们讨论了有关如何保护数据隐私和模型隐私的相关技术。在本章的末尾，我们介绍了使用各种AWS服务建立机器学习治理的不同解决方案。
- en: In the next chapter, we will provide a quick introduction to **MLOps pipelines**
    and then dive deep into automating ML workflows in AWS using **Kubeflow Pipelines**.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将快速介绍**MLOps管道**，然后深入探讨在AWS中使用**Kubeflow管道**自动化ML工作流程。
- en: Further reading
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information on the topics that were covered in this chapter, feel
    free to check out the following resources:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解更多关于本章所涉及主题的信息，请随意查阅以下资源：
- en: '*AWS IAM Best Practices* ([https://aws.amazon.com/iam/resources/best-practices/](https://aws.amazon.com/iam/resources/best-practices/))'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AWS IAM最佳实践* ([https://aws.amazon.com/iam/resources/best-practices/](https://aws.amazon.com/iam/resources/best-practices/))'
- en: '*Security Best Practices for your VPC* ([https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.xhtml](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.xhtml))'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*您的VPC安全最佳实践* ([https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.xhtml](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.xhtml))'
- en: '*AWS PrivateLink concepts* ([https://docs.aws.amazon.com/vpc/latest/privatelink/concepts.xhtml](https://docs.aws.amazon.com/vpc/latest/privatelink/concepts.xhtml))'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AWS PrivateLink概念* ([https://docs.aws.amazon.com/vpc/latest/privatelink/concepts.xhtml](https://docs.aws.amazon.com/vpc/latest/privatelink/concepts.xhtml))'
- en: '*AWS Audit Manager concepts* ([https://docs.aws.amazon.com/audit-manager/latest/userguide/concepts.xhtml](https://docs.aws.amazon.com/audit-manager/latest/userguide/concepts.xhtml))'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AWS审计管理器概念* ([https://docs.aws.amazon.com/audit-manager/latest/userguide/concepts.xhtml](https://docs.aws.amazon.com/audit-manager/latest/userguide/concepts.xhtml))'
- en: '*AWS Compliance Center* ([https://aws.amazon.com/financial-services/security-compliance/compliance-center/](https://aws.amazon.com/financial-services/security-compliance/compliance-center/))'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AWS合规中心* ([https://aws.amazon.com/financial-services/security-compliance/compliance-center/](https://aws.amazon.com/financial-services/security-compliance/compliance-center/))'
- en: '*Downloading reports in AWS Artifact* ([https://docs.aws.amazon.com/artifact/latest/ug/downloading-documents.xhtml](https://docs.aws.amazon.com/artifact/latest/ug/downloading-documents.xhtml))'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在AWS Artifact中下载报告* ([https://docs.aws.amazon.com/artifact/latest/ug/downloading-documents.xhtml](https://docs.aws.amazon.com/artifact/latest/ug/downloading-documents.xhtml))'
- en: Part 5:Designing and Building End-to-end MLOps Pipelines
  id: totrans-360
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5部分：设计和构建端到端MLOps管道
- en: In this section, readers will learn how to design and build MLOps pipelines
    using a variety of services and solutions.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，读者将学习如何使用各种服务和解决方案设计和构建MLOps管道。
- en: 'This section comprises the following chapters:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包括以下章节：
- en: '[*Chapter 10*](B18638_10.xhtml#_idTextAnchor215), *Machine Learning Pipelines
    with Kubeflow on Amazon EKS*'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B18638_10.xhtml#_idTextAnchor215), *在Amazon EKS上使用Kubeflow的机器学习管道*'
- en: '[*Chapter 11*](B18638_11.xhtml#_idTextAnchor231), *Machine Learning Pipelines
    with SageMaker Pipelines*'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第11章*](B18638_11.xhtml#_idTextAnchor231), *使用SageMaker管道的机器学习管道*'
