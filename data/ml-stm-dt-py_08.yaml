- en: '*Chapter 6*: Online Classification'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第6章*：在线分类'
- en: In the previous two chapters, you were introduced to some basic notions of classification.
    You first saw a use case in which online classification models in River were used
    to build a model that can identify an iris species based on a number of characteristics
    of a plant. This iris dataset is one of the best-known datasets in the world and
    is a very common starting point for classification.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两章中，你被介绍了一些基本的分类概念。你首先看到了一个用例，其中River中的在线分类模型被用来构建一个可以根据植物的一些特征识别鸢尾花种类的模型。这个鸢尾花数据集是世界上最好的数据集之一，也是分类的非常常见的起点。
- en: After that, you looked at anomaly detection. We discussed how classification
    models can be used for anomaly detection for those cases where we can label anomalies
    as one class and non-anomalies as another class. Specific anomaly detection models
    are often better at the task, as they strive to understand only the non-anomalies.
    Classification models will strive to understand each of the classes.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，你看到了异常检测。我们讨论了在我们可以将异常标记为一类，将非异常标记为另一类的情况下，分类模型可以用于异常检测。特定的异常检测模型通常在任务上表现更好，因为它们努力理解只有非异常。分类模型将努力理解每个类别。
- en: In this chapter, you'll go much deeper into classification. The chapter will
    start by posing definitions of what classification is and what it can be used
    for. You will then see a number of classification models, of which you'll learn
    the differences between their online and offline counterparts. You will also implement
    multiple examples in Python using the River package. This will, in the end, result
    in a model benchmarking study for the use case that will be introduced later on.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将更深入地学习分类。本章将从定义什么是分类以及它可以用于什么目的开始。然后，你将看到一些分类模型，你将学习它们在线和离线版本之间的区别。你还将使用River包在Python中实现多个示例。最终，这将导致对稍后将要介绍的使用案例进行模型基准测试研究。
- en: 'This chapter will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Defining classification
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义分类
- en: Identifying use cases of classification
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别分类的使用案例
- en: Classification algorithms in River
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: River中的分类算法
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You can find all the code for this book on GitHub at the following link: [https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python](https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python).
    If you are not yet familiar with Git and GitHub, the easiest way to download the
    notebooks and code samples is the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下链接的GitHub上找到本书的所有代码：[https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python](https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python)。如果你还不熟悉Git和GitHub，下载笔记本和代码样本的最简单方法是以下：
- en: Go to the link of the repository.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往仓库链接。
- en: Click the green **Code** button.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击绿色的**代码**按钮。
- en: Select **Download ZIP**.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**下载ZIP**。
- en: When you download the ZIP file, unzip it in your local environment, and you
    will be able to access the code through your preferred Python editor.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当你下载ZIP文件时，在你的本地环境中解压缩它，你将能够通过你偏好的Python编辑器访问代码。
- en: Python environment
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python环境
- en: To follow along with this book, you can download the code in the repository
    and execute it using your preferred Python editor.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟随本书的内容，你可以从仓库下载代码，并使用你偏好的Python编辑器执行它。
- en: If you are not yet familiar with Python environments, I would advise you to
    check out Anaconda ([https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)),
    which comes with Jupyter Notebook and JupyterLab, which are both great for executing
    notebooks. It also comes with Spyder and VSCode for editing scripts and programs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还不熟悉Python环境，我建议你查看Anaconda（[https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)），它包含Jupyter
    Notebook和JupyterLab，这两个都是执行笔记本的绝佳选择。它还包含Spyder和VSCode，用于编辑脚本和程序。
- en: If you have difficulty installing Python or the associated programs on your
    machine, you can check out Google Colab ([https://colab.research.google.com/](https://colab.research.google.com/))
    or Kaggle Notebooks ([https://www.kaggle.com/code](https://www.kaggle.com/code)),
    which both allow you to run Python code in online notebooks for free, without
    any setup to do.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你安装Python或相关程序有困难，你可以查看Google Colab（[https://colab.research.google.com/](https://colab.research.google.com/)）或Kaggle笔记本（[https://www.kaggle.com/code](https://www.kaggle.com/code)），这两个都允许你在在线笔记本中免费运行Python代码，无需任何设置。
- en: Defining classification
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义分类
- en: In this chapter, you will discover classification. Classification is a supervised
    machine learning task in which a model is constructed that assigns observations
    to a category.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解分类。分类是一种监督机器学习任务，其中构建了一个模型，该模型将观察结果分配到某个类别。
- en: The simplest types of classification models that everybody tends to know are
    decision trees. Let's consider a super simple example of how a decision tree could
    be used for classification.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 每个人都倾向于知道的简单类型的分类模型是决策树。让我们考虑一个决策树如何用于分类的超级简单例子。
- en: Imagine that we have a dataset in which we have observations about five humans
    and five animals. The goal is to use this data to build a decision tree that can
    be used on any new, unseen animal or human.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们有一个包含关于五个人类和五个动物观察结果的数据集。目标是使用这些数据构建一个决策树，该树可以用于任何新的、未见过的动物或人类。
- en: 'The data can be imported as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以按以下方式导入：
- en: Code Block 6-1
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-1
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The data is shown in the following figure:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数据如下所示：
- en: '![Figure 6.1 – The data'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.1 – 数据'
- en: '](img/B18335_06_1.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18335_06_1.jpg)'
- en: Figure 6.1 – The data
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 – 数据
- en: 'Now, to construct the decision tree, you would generally use machine learning,
    as that is far more efficient than constructing the tree by hand. Yet, for this
    example, let''s do a simple decision tree that works as the following graph indicates:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了构建决策树，你通常会使用机器学习，因为手动构建树要低效得多。然而，在这个例子中，让我们构建一个简单的决策树，它的工作方式如下所示：
- en: '![Figure 6.2 – The example decision tree'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.2 – 示例决策树'
- en: '](img/B18335_06_2.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18335_06_2.jpg)'
- en: Figure 6.2 – The example decision tree
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – 示例决策树
- en: Of course, this is a model, so it is only a partial representation of the truth.
    It works quite well for the current dataset of 10 observations, but with more
    data points, you would encounter all types of anomalies, so you'd need more variables.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这是一个模型，所以它只是对真相的部分表示。它对于当前10个观察结果的数据集工作得相当好，但如果有更多的数据点，你会遇到各种异常，因此你需要更多的变量。
- en: 'You could code this model for a `human` versus `not human` classification in
    Python as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用Python编写以下代码来为“人类”与“非人类”分类模型编码：
- en: Code Block 6-2
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-2
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The result is the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 6.3 – The predicted outcomes'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.3 – 预测结果'
- en: '](img/B18335_06_3.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18335_06_3.jpg)'
- en: Figure 6.3 – The predicted outcomes
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 – 预测结果
- en: The general idea behind this is that a classification model is any machine learning
    model that uses the data to generate decision rules to assign observations to
    specific classes. In the next section, we'll be going into some use cases of classification
    to get a better idea of what it can be used for in practice.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的背后的一般思想是，任何使用数据生成决策规则以将观察结果分配到特定类别的机器学习模型都是分类模型。在下一节中，我们将探讨一些分类用例，以更好地了解它在实际应用中的用途。
- en: Identifying use cases of classification
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别分类用例
- en: The use cases of classification are huge; it is a very commonly used method
    in many projects. Still, let's see some examples to get a better idea of the different
    types of use cases that can benefit from classification methods.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 分类用例非常广泛；它是许多项目中非常常用的方法。尽管如此，让我们看看一些例子，以更好地了解可以从中受益的不同类型的用例。
- en: Use case 1 – email spam classification
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用例1 – 电子邮件垃圾邮件分类
- en: The first use case that is generally built on classification is **spam detection**
    in email. Spam emails have been around for a long time. The business model of
    sending fake emails to generally steal people's money is a big problem, and receiving
    many spam emails can negatively impact your emailing experience.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 基于分类的第一个用例通常是电子邮件中的**垃圾邮件检测**。垃圾邮件已经存在很长时间了。向人们发送虚假电子邮件以窃取金钱的商业模式是一个大问题，而且收到许多垃圾邮件会负面影响你的电子邮件体验。
- en: Email service providers have come a long way in detecting spam emails automatically
    and sending them to your spam/junk box. Nowadays, this is all done automatically
    and relies heavily on machine learning.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件服务提供商在自动检测垃圾邮件并将其发送到你的垃圾邮件/垃圾箱方面已经走了很长的路。如今，这一切都是自动完成的，并且高度依赖于机器学习。
- en: If you compare this to our super-small classification example, you could imagine
    that the decision tree (or any other model) can take several information types
    about every received email and use that to decide whether or not the email should
    be classified as spam. This has to be done in real time, as nobody wants to wait
    for a spam detection service to finally send their email through.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将此与我们超级小的分类示例进行比较，你可以想象决策树（或任何其他模型）可以接收关于每封接收到的电子邮件的几种信息类型，并使用这些信息来决定该电子邮件是否应该被分类为垃圾邮件。这必须实时完成，因为没有人愿意等待垃圾邮件检测服务最终发送他们的电子邮件。
- en: 'You can read more about this use case in the following resources:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下资源中了解更多关于此用例的信息：
- en: '[https://www.sciencedirect.com/science/article/pii/S2405844018353404](https://www.sciencedirect.com/science/article/pii/S2405844018353404)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.sciencedirect.com/science/article/pii/S2405844018353404](https://www.sciencedirect.com/science/article/pii/S2405844018353404)'
- en: '[https://www.enjoyalgorithms.com/blog/email-spam-and-non-spam-filtering-using-machine-learning](https://www.enjoyalgorithms.com/blog/email-spam-and-non-spam-filtering-using-machine-learning)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.enjoyalgorithms.com/blog/email-spam-and-non-spam-filtering-using-machine-learning](https://www.enjoyalgorithms.com/blog/email-spam-and-non-spam-filtering-using-machine-learning)'
- en: Use case 2 – face detection in phone camera
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用例 2 – 手机摄像头中的面部检测
- en: The second example of classification is face detection when you want to unlock
    your phone. Your phone has to make a split-second decision whether the face it's
    seeing is the face of its owner or not.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 分类决策的第二个例子是在你想要解锁手机时进行面部检测。你的手机必须在一瞬间做出决定，看它看到的脸是不是所有者的脸。
- en: 'This decision is a classification decision, as it comes down to a yes/no decision:
    it *is* the owner, or it is *not* the owner. This decision will generally be made
    by machine learning, as the rules would be very complex and hard to write down
    as `if`/`else` statements. Machine learning algorithms are, nowadays, relatively
    good at such use cases.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这个决策是一个分类决策，因为它最终归结为一个是/否的决策：它是所有者，或者它不是所有者。这个决策通常由机器学习来完成，因为规则会非常复杂，难以用`if`/`else`语句写下来。如今，机器学习算法在处理此类用例方面相对较好。
- en: 'For other more detailed examples of this use case, you can check out the following
    links:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此用例的其他更详细示例，你可以查看以下链接：
- en: '[https://www.xfinity.com/hub/mobile/facial-recognition-on-phone](https://www.xfinity.com/hub/mobile/facial-recognition-on-phone)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.xfinity.com/hub/mobile/facial-recognition-on-phone](https://www.xfinity.com/hub/mobile/facial-recognition-on-phone)'
- en: '[https://www.nytimes.com/wirecutter/blog/how-facial-recognition-works/](https://www.nytimes.com/wirecutter/blog/how-facial-recognition-works/)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.nytimes.com/wirecutter/blog/how-facial-recognition-works/](https://www.nytimes.com/wirecutter/blog/how-facial-recognition-works/)'
- en: Use case 3 – online marketing ad selection
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用例 3 – 在线营销广告选择
- en: A final example to add to the previous two is online marketing ad selection.
    Many websites nowadays display personalized ads. This means that you will see
    an advertisement that matches you as a customer.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最后要添加到前两个用例中的例子是在线营销广告选择。如今，许多网站都会显示个性化的广告。这意味着你将看到与你作为客户相匹配的广告。
- en: Personalized ad systems do not invent ads though; they have to make a decision
    and choose between multiple available ads to know which one fits you best. In
    this way, it is a classification, as it has to decide between multiple choices.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 个性化广告系统并不是发明广告；它们必须做出决定，在多个可用的广告中选择一个最适合你的。因此，这是一个分类问题，因为它必须在多个选择之间做出决定。
- en: As you can understand, page loads have to be fast and, therefore, ad selection
    has to be done in a split second as well. Real-time responses are key for the
    model to provide any value at all.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所理解的，页面加载必须快速，因此广告选择也必须在瞬间完成。实时响应对于模型提供任何价值至关重要。
- en: 'The following links talk in more depth about this use case:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以下链接更深入地讨论了此用例：
- en: '[https://www.owox.com/blog/articles/machine-learning-in-marketing/](https://www.owox.com/blog/articles/machine-learning-in-marketing/)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.owox.com/blog/articles/machine-learning-in-marketing/](https://www.owox.com/blog/articles/machine-learning-in-marketing/)'
- en: '[https://www.ibm.com/watson-advertising/thought-leadership/benefits-of-machine-learning-in-advertising](https://www.ibm.com/watson-advertising/thought-leadership/benefits-of-machine-learning-in-advertising)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.ibm.com/watson-advertising/thought-leadership/benefits-of-machine-learning-in-advertising](https://www.ibm.com/watson-advertising/thought-leadership/benefits-of-machine-learning-in-advertising)'
- en: In the next section, you'll see a more practical side to doing classification,
    as you will discover several classification algorithms in the River Python library.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将看到进行分类的更实际的一面，因为你将发现 River Python 库中的几个分类算法。
- en: Overview of classification algorithms in River
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: River中分类算法概述
- en: There is a large number of online classification models available in the River
    online machine learning package.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: River在线机器学习包中有大量的在线分类模型。
- en: 'A selection of relevant ones is as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些相关的选择：
- en: '`LogisticRegression`'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LogisticRegression`'
- en: '`Perceptron`'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Perceptron`'
- en: '`AdaptiveRandomForestClassifier`'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AdaptiveRandomForestClassifier`'
- en: '`ALMAClassifier`'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ALMAClassifier`'
- en: '`PAClassifier`'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PAClassifier`'
- en: Classification algorithm 1 – LogisticRegression
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法1 – 逻辑回归
- en: Logistic regression is one of the most basic statistical classification models.
    It models a dependent variable (target variable) that has two classes (1 or 0)
    and can use multiple independent variables to make the prediction.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是最基本的统计分类模型之一。它模型化了一个具有两个类别（1或0）的因变量（目标变量），并且可以使用多个自变量进行预测。
- en: The model combines each of the independent variables as log-odds; you can see
    this as the coefficients in linear regression, except that they are log-odds for
    each variable. The split in the model is based on the logistic function.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 模型将每个自变量组合为对数几率；你可以将其视为线性回归中的系数，只是它们是每个变量的对数几率。模型中的分割基于逻辑函数。
- en: 'You can see a simplified schematic of the idea as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照以下简化示意图来理解这个想法：
- en: '![Figure 6.4 – The logistic curve'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.4 – 逻辑曲线]'
- en: '](img/B18335_06_4.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B18335_06_4.jpg]'
- en: Figure 6.4 – The logistic curve
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 – 逻辑曲线
- en: Logistic regression in River
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: River中的逻辑回归
- en: 'For online logistic regression, you can use the `LogisticRegression` class
    in River''s `linear_model` section. Let''s now see an example of that:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在线逻辑回归，你可以在River的`linear_model`部分使用`LogisticRegression`类。现在让我们看看一个例子：
- en: 'First, you can start by making a classification dataset using sklearn''s inbuilt
    `make_blobs` function, which makes classification datasets. You can use the following
    code for this:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，你可以通过使用sklearn内置的`make_blobs`函数来创建一个分类数据集，该函数用于创建分类数据集。你可以使用以下代码来完成这个任务：
- en: Code Block 6-3
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-3
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To see what this dataset looks like, it is important to make a plot. You can
    use the following `matplotlib` code for this:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了了解这个数据集的样子，制作一个图表是很重要的。你可以使用以下`matplotlib`代码来完成这个任务：
- en: Code Block 6-4
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-4
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You should obtain the following plot, or something resembling it:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下图表，或者类似的东西：
- en: '![Figure 6.5 – The data'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.5 – 数据]'
- en: '](img/B18335_06_5.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B18335_06_5.jpg]'
- en: Figure 6.5 – The data
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 数据
- en: 'To make sure that your model evaluation will be fair, it is important to make
    a train-test split in the data. You can do this with sklearn''s `train_test_split`,
    as shown here:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了确保你的模型评估是公平的，在数据中制作一个训练-测试分割是很重要的。你可以使用sklearn的`train_test_split`来完成这个任务，如下所示：
- en: Code Block 6-5
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-5
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let''s now move on to the application of the logistic regression model. The
    following code shows how to fit the model one data point at a time. Note that
    you should be using a JSON conversion of the input data for `x`, as this is required
    by River:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们继续讨论逻辑回归模型的应用。以下代码展示了如何逐个数据点拟合模型。请注意，你应该使用输入数据`x`的JSON转换，因为这是River所要求的：
- en: Code Block 6-6
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-6
- en: '[PRE18]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The printed data will look something like this:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 打印的数据将看起来像这样：
- en: '![Figure 6.6 – The output of Code Block 6-6'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.6 – 代码块6-6的输出]'
- en: '](img/B18335_06_6.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B18335_06_6.jpg]'
- en: Figure 6.6 – The output of Code Block 6-6
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 – 代码块6-6的输出
- en: 'You can do predictions one by one as well, or you can use `predict_many` to
    make all the predictions on the test set at once. There will not be any difference
    in the result. In the following code, `predict_many` is used:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你也可以逐个进行预测，或者使用`predict_many`在测试集上一次性进行所有预测。结果不会有任何区别。在以下代码中，使用了`predict_many`：
- en: Code Block 6-7
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-7
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To get a quality metric on this prediction, let''s use the accuracy score by
    `scikit-learn`. As you can see in the following code block, the model has obtained
    100% accuracy on the blob data example. It must be stated that this blob data
    example is a simple prediction task as the data is perfectly separable by a straight
    line, as can be seen in the plot shown earlier:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了得到这个预测的质量指标，让我们使用`scikit-learn`的准确度评分。正如你可以在以下代码块中看到的那样，模型在blob数据示例上获得了100%的准确率。必须指出的是，这个blob数据示例是一个简单的预测任务，因为数据可以被一条直线完美地分开，正如之前显示的图表中所示：
- en: Code Block 6-8
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-8
- en: '[PRE20]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This should result in the following output:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会产生以下输出：
- en: '![Figure 6.7 – The output of Code Block 6-8'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.7 – 代码块6-8的输出]'
- en: '](img/B18335_06_7.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B18335_06_7.jpg]'
- en: Figure 6.7 – The output of Code Block 6-8
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 – 代码块6-8的输出
- en: Classification algorithm 2 – Perceptron
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法 2 – 感知器
- en: 'The perceptron is another algorithm for supervised learning on classification
    problems. It takes inputs, multiplies them by weights, and puts the sum of those
    through an activation function. The output is the resulting classification. The
    following graph shows an example:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器是另一个用于分类问题的监督学习算法。它接受输入，将它们乘以权重，并将这些乘积通过激活函数。输出是得到的分类。以下图表显示了一个示例：
- en: '![Figure 6.8 – Schematic overview of a perceptron'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 6.8 – 感知器的示意图]'
- en: '](img/B18335_06_8.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18335_06_8.jpg]'
- en: Figure 6.8 – Schematic overview of a perceptron
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.8 – 感知器的示意图
- en: Perceptron in River
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: River 中的感知器
- en: Like logistic regression, the perceptron is a commonly used offline model that
    has been reworked into an online model for River. In River, the perceptron has
    been implemented as a special case of logistic regression.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 与逻辑回归一样，感知器是一个常用的离线模型，River 已经将其改造成在线模型。在 River 中，感知器被实现为逻辑回归的一个特例。
- en: 'You can use the perceptron just like logistic regression. You can use the same
    code example as in the previous case, as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用感知器就像逻辑回归一样。你可以使用与之前案例相同的代码示例，如下所示：
- en: Code Block 6-9
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块 6-9
- en: '[PRE21]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The result is `1.0`, which is, unsurprisingly, the same as the logistic regression
    result.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是 `1.0`，不出所料，这与逻辑回归的结果相同。
- en: Classification algorithm 3 – AdaptiveRandomForestClassifier
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法 3 – AdaptiveRandomForestClassifier
- en: In the introduction, you already saw the general idea behind a decision tree.
    Random Forests are an ensemble model that improves decision trees.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍中，你已经看到了决策树背后的基本思想。随机森林是一个改进决策树的集成模型。
- en: The idea behind Random Forests is that they reduce the error of single decision
    trees by making a large number of slightly different decision trees. The most
    common prediction among a large number of decision trees is retained as the final
    prediction.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林背后的思想是，通过构建大量略微不同的决策树来减少单个决策树的误差。在大量决策树中最常见的预测被保留为最终预测。
- en: The decision trees are made slightly differently by fitting each of them on
    a slightly different dataset, which is created by resampling the observations.
    There is also a subset of variables used for creating the decision tree splits.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树通过在每个略微不同的数据集上拟合它们而略有不同，这些数据集是通过重采样观测值创建的。还有一个用于创建决策树分割的变量子集。
- en: Random Forest in River
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: River 中的随机森林
- en: 'For online learning, the data needs to be fitted one by one into the Random
    Forest, which is not an easy task. River''s implementation is based on the two
    key elements of Random Forests, which are the resampling and the variable subsets.
    They have also added drift detection for each single decision tree:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在线学习，数据需要逐个拟合到随机森林中，这并不是一件容易的事情。River 的实现基于随机森林的两个关键元素，即重采样和变量子集。他们还为每个单个决策树添加了漂移检测：
- en: 'Let''s use an alternative data creation function, which creates data that is
    harder to separate than the blobs. This function from `sklearn` is called `make_classification`:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用一个替代的数据创建函数，它创建的数据比 blob 更难分离。这个来自 `sklearn` 的函数叫做 `make_classification`：
- en: Code Block 6-10
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块 6-10
- en: '[PRE40]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The data is shown in the following figure:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 数据如下所示：
- en: '![Figure 6.9 – The new data'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 6.9 – 新数据]'
- en: '](img/B18335_06_9.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18335_06_9.jpg]'
- en: Figure 6.9 – The new data
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.9 – 新数据
- en: 'There is a total of 20 variables generated by default, of which a number are
    automatically made more relevant and some are mostly irrelevant. Let''s do a train-test
    split just like before:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，生成了总共 20 个变量，其中一些被自动赋予更高的相关性，而一些则大部分无关。让我们像之前一样进行训练-测试分割：
- en: Code Block 6-11
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块 6-11
- en: '[PRE41]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Using this train-test split, we can move on to building the model:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这个训练-测试分割，我们可以继续构建模型：
- en: Code Block 6-12
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块 6-12
- en: '[PRE42]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now that the model is fit, we can make predictions on the test set. There is
    no `predict_many` function here, so it is necessary to do a loop with `predict_one`
    repeatedly:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在模型已经拟合，我们可以在测试集上进行预测。这里没有 `predict_many` 函数，所以需要通过重复使用 `predict_one` 来进行循环：
- en: Code Block 6-13
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块 6-13
- en: '[PRE43]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'As a final step, let''s compute the accuracy of this model:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为最后一步，让我们计算这个模型的准确率：
- en: Code Block 6-14
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块 6-14
- en: '[PRE44]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The result is `0.86`. Of course, the dataset was more difficult to predict,
    so that is not to be mistaken for a bad score. As an additional metric, we can
    look at the classification report for more information:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果是 `0.86`。当然，数据集更难预测，所以这不是一个坏分数。作为额外的指标，我们可以查看分类报告以获取更多信息：
- en: Code Block 6-15
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-15
- en: '[PRE45]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The result is shown in the following figure:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在下图中：
- en: '![Figure 6.10 – The output of Code Block 6-15'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.10 – 代码块6-15的输出'
- en: '](img/B18335_06_10.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18335_06_10.jpg)'
- en: Figure 6.10 – The output of Code Block 6-15
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10 – 代码块6-15的输出
- en: In this classification report, you see that the precision and recall and the
    scores for positives and negatives are all relatively equal. This shows that there
    is no imbalance in the classifier, which is important when relying on the accuracy
    score.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个分类报告中，你可以看到精确度、召回率和正负样本的分数都相对均衡。这表明分类器没有不平衡，这在依赖于准确度分数时非常重要。
- en: Classification algorithm 4 – ALMAClassifier
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法4 – ALMAClassifier
- en: Now that you have seen some commonly used machine learning models for classification
    in a way adapted to accommodate online learning, it is time to see some more specific
    models as well. The first of these is the ALMA classifier.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了一些适应在线学习的常用机器学习分类模型，是时候看看一些更具体的模型了。这些模型中的第一个是ALMA分类器。
- en: The **approximate large margin algorithm** (**ALMA**) classifier is an incremental
    implementation of **support vector machines** (**SVMs**), a commonly used machine
    learning model for classification.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**近似大间隔算法**（**ALMA**）分类器是**支持向量机**（**SVMs**）的增量实现，这是一种常用的机器学习分类模型。'
- en: 'You saw the adaptation of SVMs in the previous chapter: a one-class SVM is
    often used for anomaly detection. For classification, you''d use a regular (two-class)
    SVM.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 你在前一章中看到了SVMs的适应：单类SVM通常用于异常检测。对于分类，你会使用常规（双类）SVM。
- en: ALMAClassifier in River
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: River中的ALMAClassifier
- en: 'Let''s see how ALMAClassifier compares to the adaptive Random Forest, by executing
    it on the same data:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看ALMAClassifier与自适应随机森林如何比较，通过在相同的数据上执行它：
- en: 'We start by applying the same code that we already defined before:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先应用之前已经定义的相同代码：
- en: Code Block 6-16
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-16
- en: '[PRE46]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The result is `0.77`, not as good as the Random Forest. Let''s also check the
    classification report to see whether anything changed there:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果是`0.77`，不如随机森林。让我们也检查一下分类报告，看看那里是否有什么变化：
- en: Code Block 6-17
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-17
- en: '[PRE47]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The result is shown in the following figure:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果显示在下图中：
- en: '![Figure 6.11 – The output of Code Block 6-17'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.11 – 代码块6-17的输出'
- en: '](img/B18335_06_11.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18335_06_11.jpg)'
- en: Figure 6.11 – The output of Code Block 6-17
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11 – 代码块6-17的输出
- en: There is a little more variation here, but nothing that seems too shocking.
    In general, the Random Forest was just better overall for this data.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些轻微的变化，但没有什么看起来太令人震惊。总的来说，随机森林在这个数据上整体表现更好。
- en: Classification algorithm 5 – PAClassifier
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类算法5 – PAClassifier
- en: 'The **passive-aggressive** (**PA**) classifier is an online machine learning
    model that is not related to any existing offline model. It is based on the idea
    of updating the model at each step and thereby solving the following problem:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**被动-攻击**（**PA**）分类器是一个在线机器学习模型，它与任何现有的离线模型都不相关。它基于在每一步更新模型的想法，从而解决以下问题：'
- en: '*The update of the classifier is performed by solving a constrained optimization
    problem: we would like the new classifier to remain as close as possible to the
    current one while achieving at least a unit margin on the most recent example.*'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '*分类器的更新是通过解决一个约束优化问题来完成的：我们希望新的分类器尽可能接近当前的分类器，同时在最近的例子上至少实现一个单位的间隔。*'
- en: 'This quote has been taken from the following paper on PA algorithms, which
    is also an interesting reference for further reading: [https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf](https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf).'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这段话摘自以下关于PA算法的论文，这也是一个有趣的进一步阅读的参考文献：[https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf](https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf)。
- en: The name *passive-aggressive* comes from the idea that an algorithm that learns
    too quickly from each new data point is considered too aggressive. PA is less
    aggressive.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: “被动-攻击”这个名字来源于这样的想法，即从每个新的数据点学习得太快的算法被认为是过于激进。PA不那么激进。
- en: PAClassifier in River
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: River中的PAClassifier
- en: 'Let''s see how the PA classifier performs on the same task as the two previous
    models:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看PA分类器在执行与之前两个模型相同任务时的表现：
- en: Code Block 6-18
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块6-18
- en: '[PRE48]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: The obtained score is `0.85`. The following section summarizes all the scores
    that we have obtained.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 获得的分数是`0.85`。接下来的部分总结了我们所获得的所有分数。
- en: Evaluating benchmark results
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估基准结果
- en: 'This leaves us with the following accuracy scores for the past three models:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们留下了过去三个模型的以下准确率分数：
- en: '![Table 6.1 – The table with the results'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '![表6.1 – 包含结果的表格'
- en: '](img/B18335_06_Table_01.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18335_06_Table_01.jpg)'
- en: Table 6.1 – The table with the results
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.1 – 包含结果的表格
- en: The best result was obtained by AdaptiveRandomForest and PAClassifier came in
    second place. ALMAClassifier was less performant with a score of `0.77`.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳结果由自适应随机森林获得，PAClassifier排名第二。ALMAClassifier的表现较差，得分为`0.77`。
- en: Summary
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you have first seen a general overview of classification and
    its use cases. You have understood how it is different from anomaly detection,
    but how it can sometimes still be applied to anomaly detection use cases.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你首先看到了分类及其用例的概述。你了解了它与异常检测的不同之处，但有时它仍然可以应用于异常检测用例。
- en: You have learned about five models for online classification of which some are
    mainly adaptations of offline models, and others are specifically designed for
    working in an online manner. Both types exist, and it is important to have the
    tools to benchmark model performance before making a choice for a final model.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经了解了五种在线分类模型，其中一些主要是离线模型的改编，而其他一些则是专门设计用于在线工作的。这两种类型都存在，在为最终模型做出选择之前，拥有评估模型性能的工具是很重要的。
- en: The model benchmark that you executed in Python was done in such a way as to
    find the best model in terms of the accuracy of the model on a test set. You have
    seen clear differences between the benchmarked models, and this is a great showcase
    for the importance of model benchmarking.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 你在Python中执行的模型基准测试是为了找到在测试集上模型准确率最高的模型。你已经看到了基准测试模型之间的明显差异，这是模型基准测试重要性的一个很好的展示。
- en: In the following chapter, you will do the same type of model benchmarking exercise,
    but this time, you will be focusing on a regression use case, which has a goal
    that is fundamentally different from classification. This comes with some changes
    with respect to measuring errors and benchmarking, but from a high-level perspective,
    also has a lot in common with the classification benchmarking use case that you
    worked with in this chapter.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，你将进行相同类型的模型基准测试练习，但这次你将专注于回归用例，其目标与分类的目标在本质上不同。这涉及到对误差测量和基准测试的一些变化，但从高层次来看，也与你在本章中使用的分类基准测试用例有很多共同之处。
- en: Further reading
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*LogisticRegression*: [https://riverml.xyz/latest/api/linear-model/LogisticRegression/](https://riverml.xyz/latest/api/linear-model/LogisticRegression/)'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*逻辑回归*: [https://riverml.xyz/latest/api/linear-model/LogisticRegression/](https://riverml.xyz/latest/api/linear-model/LogisticRegression/)'
- en: '*Perceptron*: [https://riverml.xyz/latest/api/linear-model/Perceptron/](https://riverml.xyz/latest/api/linear-model/Perceptron/)'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*感知器*: [https://riverml.xyz/latest/api/linear-model/Perceptron/](https://riverml.xyz/latest/api/linear-model/Perceptron/)'
- en: '*AdaptiveRandomForestClassifier*: [https://riverml.xyz/latest/api/ensemble/AdaptiveRandomForestClassifier/](https://riverml.xyz/latest/api/ensemble/AdaptiveRandomForestClassifier/)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自适应随机森林分类器*: [https://riverml.xyz/latest/api/ensemble/AdaptiveRandomForestClassifier/](https://riverml.xyz/latest/api/ensemble/AdaptiveRandomForestClassifier/)'
- en: '*ALMA*: [https://riverml.xyz/latest/api/linear-model/ALMAClassifier/](https://riverml.xyz/latest/api/linear-model/ALMAClassifier/)'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ALMA*: [https://riverml.xyz/latest/api/linear-model/ALMAClassifier/](https://riverml.xyz/latest/api/linear-model/ALMAClassifier/)'
- en: '*ALMA*: [https://www.jmlr.org/papers/volume2/gentile01a/gentile01a.pdf](https://www.jmlr.org/papers/volume2/gentile01a/gentile01a.pdf'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ALMA*: [https://www.jmlr.org/papers/volume2/gentile01a/gentile01a.pdf](https://www.jmlr.org/papers/volume2/gentile01a/gentile01a.pdf)'
- en: )
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '*PAClassifier*: [https://riverml.xyz/latest/api/linear-model/PAClassifier/](https://riverml.xyz/latest/api/linear-model/PAClassifier/'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PAClassifier*: [https://riverml.xyz/latest/api/linear-model/PAClassifier/](https://riverml.xyz/latest/api/linear-model/PAClassifier/'
- en: )
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '*PAClassifier*: [https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf](https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PAClassifier*: [https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf](https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf'
- en: )
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '*make_classification*: [https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.htm](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.htm'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*make_classification*: [https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.htm](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.htm'
- en: )
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '*make_blobs*: [https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*make_blobs*: [https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)'
