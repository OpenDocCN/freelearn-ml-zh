- en: Chapter 5. Step 2 – Applying Machine Learning Techniques
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。步骤2 – 应用机器学习技术
- en: This chapter focuses on applying the machine learning algorithm, and it is the
    core of developing the solution. There are different types of techniques that
    learn from the data. Depending on our target, we can use the data to identify
    similarities between objects or to estimate an attribute on new objects.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点在于应用机器学习算法，这是开发解决方案的核心。有不同类型的从数据中学习的技巧。根据我们的目标，我们可以使用数据来识别对象之间的相似性或对新对象估计属性。
- en: In order to show the machine learning techniques, we start from the flag data
    that we processed in the previous chapter. However, reading this chapter doesn't
    require you to know about the previous, although it is recommended to understand
    where the data came from.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示机器学习技术，我们从上一章中处理过的旗帜数据开始。然而，阅读本章不需要你了解前面的内容，尽管了解数据来源是推荐的。
- en: 'In this chapter you will learn to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习到：
- en: Identify homogeneous groups of items
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别项目的一致性组
- en: Explore and visualize the item groups
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索和可视化项目组
- en: Estimate a new country language
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 估计一个新国家的语言
- en: Set the configuration of a machine learning technique
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置机器学习技术的配置
- en: Identifying a homogeneous group of items
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别项目的一致性组
- en: Our data describes each country flag. Is there any way to identify groups of
    countries with similar flag attributes? We can use some clustering techniques
    that are machine learning algorithms that define homogeneous clusters using the
    data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据描述了每个国家旗帜。有没有办法识别具有类似旗帜属性的国家组？我们可以使用一些聚类技术，这些是机器学习算法，它们使用数据定义同质集群。
- en: 'Starting from the flag attributes, in the previous chapter, we built a feature
    table and we stored it into the `dtFeatures.txt` file. In order to load the file
    into R, the first step is to define the directory containing the file using `setwd`.
    Then, we can load the file into the `dfFeatures` data frame using `read.table`,
    and we can convert it into the `dtFeatures` data table, as shown:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从上一章的旗帜属性开始，我们构建了一个特征表并将其存储到`dtFeatures.txt`文件中。为了将文件加载到R中，第一步是使用`setwd`定义包含文件的目录。然后，我们可以使用`read.table`将文件加载到`dfFeatures`数据框中，并将其转换为`dtFeatures`数据表，如下所示：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s take a look at the data using `str`, similar to the previous chapters:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看数据，使用`str`，类似于前面的章节：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The language column is a factor and there are 10 languages, called `levels`
    of the factor. All the other columns contain features describing the flags and
    they are factors with two levels: `yes` and `no`. The features are as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 语言列是一个因素，有10种语言，称为该因素的`级别`。所有其他列都包含描述旗帜的特征，它们是具有两个级别的因素：`是`和`否`。特征如下：
- en: The `colors` feature (for example, `red`) has a `yes` level if the flag contains
    the color
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果旗帜包含颜色，则`colors`特征（例如，`red`）具有`是`级别
- en: The `patterns` feature (for example, `circle`) has a `yes` level if the flag
    contains the pattern
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果旗帜包含图案，则`patterns`特征（例如，`circle`）具有`是`级别
- en: The `nBars`/`nStrp`/`nCol` features followed by a number (for example, `nBars3`)
    have a `yes` level if the flag has 3 bars
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后跟数字的`nBars`/`nStrp`/`nCol`特征（例如，`nBars3`）如果旗帜有3条横线，则具有`是`级别
- en: The `topleft`/`botright`/`mainhue` features followed by a color (for example,
    `topleftblue`) have a `yes` level if the top-left part is blue
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后跟颜色的`topleft`/`botright`/`mainhue`特征（例如，`topleftblue`）如果左上部分是蓝色，则具有`是`级别
- en: Identifying the groups using k-means
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用k-means识别组
- en: Our target is to identify groups of similar flags. For this purpose, we can
    start using a basic clustering algorithm, that is, **k-means**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是识别类似旗帜的组。为此，我们可以开始使用基本的聚类算法，即**k-means**。
- en: The k-means target is to identify *k* (for example, eight) homogeneous clusters
    of flags. Imagine dividing all the flags in eight clusters. One of them includes
    10 flags out of which seven contain the color red. Let's suppose that we have
    a `red` attribute that is `1` if the flag contains red and `0` otherwise. We can
    say that the `average flag` of this cluster contains `red` with a probability
    of 70 percent, so its `red` attribute is 0.7\. Doing the same with every other
    attribute, we can define `average flag`, whose attributes are the average within
    the group. Each cluster has an average flag that we can determine using the same
    approach.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: k-means的目标是识别*k*（例如，八个）同质标志聚类。想象一下将所有标志分成八个聚类。其中一个包含10个标志，其中7个包含红色。假设我们有一个`red`属性，如果标志包含红色则为`1`，否则为`0`。我们可以说这个聚类的`average
    flag`包含红色的概率为70%，因此其`red`属性为0.7。对每个其他属性做同样的处理，我们可以定义`average flag`，其属性是组内的平均值。每个聚类都有一个平均标志，我们可以使用相同的方法来确定。
- en: The k-means algorithm is based on an average object that is called the cluster
    center. At the beginning, the algorithm divides the flags into 8 random groups
    and determines their 8 centers. Then, k-means reassigns each flag to the group
    whose center is the most similar. In this way, the clusters are more homogeneous
    and the algorithm can recompute their centers. After a few iterations, we have
    8 groups containing homogeneous flags.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法基于一个称为聚类中心的平均对象。一开始，算法将标志分为8个随机组并确定它们的8个中心。然后，k-means将每个标志重新分配到中心最相似的组。这样，聚类更加同质化，算法可以重新计算它们的中心。经过几次迭代后，我们就有8个包含同质标志的组。
- en: 'The k-means algorithm is a very popular technique and R provides us with the
    `kmeans` function. In order to use it, we can take a look at its help:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法是一个非常流行的技术，R为我们提供了`kmeans`函数。为了使用它，我们可以查看其帮助信息：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We need two inputs:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要两个输入：
- en: '`x`: A numeric data matrix'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：数值数据矩阵'
- en: '`centers`: The number of clusters (or the cluster centers to start with)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`centers`：聚类数量（或开始时的聚类中心）'
- en: 'Starting from `dtFeatures`, we need to build a numeric feature matrix `dtFeaturesKm`.
    First, we can put the feature names into `arrayFeatures` and generate the `dtFeaturesKm`
    data table containing all the features. Perform the following steps:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从`dtFeatures`开始，我们需要构建一个数值特征矩阵`dtFeaturesKm`。首先，我们可以将特征名称放入`arrayFeatures`中，并生成包含所有特征的`dtFeaturesKm`数据表。执行以下步骤：
- en: 'Define `arrayFeatures` that is a vector containing the feature name. The `dtFeatures`
    method contains the attribute in the first column and the features in the others,
    so we extract all the column names apart from the first:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义包含特征名称的`arrayFeatures`向量。`dtFeatures`方法包含第一列的属性和其余列的特征，因此我们提取除第一列之外的所有列名：
- en: '[PRE3]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Define `dtFeaturesKm` containing the features:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义包含特征的`dtFeaturesKm`：
- en: '[PRE4]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Convert a generic column (for example, `red`) into the numeric format. We can
    use `as.numeric` to convert the column format from factor into numeric:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将通用列（例如，`red`）转换为数值格式。我们可以使用`as.numeric`将列格式从因子转换为数值：
- en: '[PRE5]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The new vector contains `1` if the value is `no` and `2` if the value is `yes`.
    In order to use the same standards as our k-means descriptions, we prefer to have
    `0` if the attribute is `no` and `1` if the attribute is `yes`. In this way, when
    we are computing the average attribute within a group, it will be a number between
    0 and 1 that can be seen as a portion of flags whose attribute is `yes`. Then,
    in order to have 0 and 1, we can use `as.numeric(red) – 1`:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新向量包含`1`如果值是`no`，如果是`yes`则包含`2`。为了与我们的k-means描述使用相同的标准，我们更愿意将`no`属性设置为`0`，将`yes`属性设置为`1`。这样，当我们计算组内的平均属性时，它将是一个介于0和1之间的数字，可以看作是属性为`yes`的标志部分的百分比。然后，为了得到0和1，我们可以使用`as.numeric(red)
    – 1`：
- en: '[PRE6]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Alternatively, we could have done the same using the ifelse function.
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者，我们也可以使用ifelse函数完成同样的操作。
- en: 'We need to convert each column format into 0-1\. The `arrayFeatures` data table
    contains names of all the features and we can process each of them using a `for`
    loop. If we want to transform a column whose name is contained in `nameCol`, we
    need to use the `eval`-`get` notation. With `eval(nameCol) :=` we redefine the
    column, and with `get(nameCol)` we use the current value of the column, as shown:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要将每个列格式转换为0-1。`arrayFeatures`数据表包含所有特征的名称，我们可以使用`for`循环处理每个特征。如果我们想转换包含在`nameCol`中的列名，我们需要使用`eval`-`get`表示法。使用`eval(nameCol)
    :=`我们重新定义列，使用`get(nameCol)`我们使用列的当前值，如下所示：
- en: '[PRE7]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now convert all the features in the 0-1 format. Let''s visualize it:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在将所有特征转换为0-1格式。让我们可视化它：
- en: '[PRE8]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `kmeans` function requires the data to be in the matrix form. In order
    to convert `dtFeaturesKm` into a matrix, we can use `as.matrix`:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kmeans`函数需要数据以矩阵形式。为了将`dtFeaturesKm`转换为矩阵，我们可以使用`as.matrix`：'
- en: '[PRE9]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `matrixFeatures` data table contains data to build the k-means algorithm
    and the other `kmeans` inputs are the parameters. The k-means algorithm doesn''t
    automatically detect the number of clusters, so we need to specify it through
    the `centers` input. Given the set of objects, we can identify any number of clusters
    out of them. Which is the number that reflects the data most? There are some techniques
    that allow us to define it, but they''re out of the scope of this chapter. We
    can just define a reasonable number of centers, for example, 8:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`matrixFeatures`数据表包含构建k-means算法的数据，其他`kmeans`输入是参数。k-means算法不会自动检测集群数量，因此我们需要通过`centers`输入来指定它。给定对象集，我们可以从中识别出任意数量的集群。哪个数字最能反映数据？有一些技术允许我们定义它，但它们超出了本章的范围。我们可以定义一个合理的中心数量，例如，8：'
- en: '[PRE10]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `modelKm` function is a list containing different model components. The
    help of `kmeans` provides us with a detailed description of the output and we
    can use `names` to get the element names. Let''s see the components:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`modelKm`函数是一个包含不同模型组件的列表。`kmeans`的帮助提供了关于输出的详细描述，我们可以使用`names`来获取元素名称。让我们看看组件：'
- en: '[PRE11]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can visualize the cluster centers that are contained in `centers`, as shown:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以可视化包含在`centers`中的集群中心，如下所示：
- en: '[PRE12]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Each row defines a center and each column shows an attribute. All the attributes
    are between 0 and 1, and they represent the percentage of flags in the cluster
    with an attribute equal to `1`. For instance, if `red` is `0.5`, it means that
    half of the flags contain the color red.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 每行定义一个中心，每列显示一个属性。所有属性都在0到1之间，它们代表具有属性等于`1`的集群中旗帜的百分比。例如，如果`red`是`0.5`，这意味着一半的旗帜包含红色。
- en: The element that we will use is `cluster` and it contains a label specifying
    the cluster of each flag. For instance, if the first element of a cluster is `3`,
    this means that the first flag in `matrixFeatures` (and also in `dtFeatures`)
    belongs to the third cluster.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的是`cluster`元素，它包含一个标签，指定每个旗帜的集群。例如，如果一个集群的第一个元素是`3`，这意味着`matrixFeatures`（以及`dtFeatures`）中的第一个旗帜属于第三个集群。
- en: Exploring the clusters
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索集群
- en: 'We can take a look at each cluster in order to explore its flags. In order
    to do that, we can add the cluster to the initial table by defining the `clusterKm`
    column, as shown:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看每个集群，以探索其旗帜。为了做到这一点，我们可以在定义`clusterKm`列时将集群添加到初始表中，如下所示：
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In order to explore a cluster, we can determine how many of its countries speak
    each language. Starting from `dtFeatures`, we can summarize the data about each
    cluster using data table aggregation. First, let''s define the column that contains
    the cluster:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索一个集群，我们可以确定其国家中有多少个国家使用每种语言。从`dtFeatures`开始，我们可以使用数据表聚合来总结每个集群的数据。首先，让我们定义包含集群的列：
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We want to determine how many rows we have in each cluster. The data table
    command that allows us to determine the number of rows is `.N`, shown as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想确定每个集群中有多少行。允许我们确定行数的表格命令是`.N`，如下所示：
- en: '[PRE15]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'If we want to have a different column name for the cluster size, we can specify
    it within the list, as shown:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想为集群大小指定不同的列名，我们可以在列表中指定它，如下所示：
- en: '[PRE16]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In order to determine how many countries we have for each language, we can
    use `table`:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定每种语言有多少个国家，我们可以使用`table`：
- en: '[PRE17]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In order to use `table` within an aggregation, the output should be a list.
    For this purpose, we can convert the table using `as.list`, as shown:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在聚合中使用`table`，输出应该是列表。为此，我们可以使用`as.list`将表转换为列表，如下所示：
- en: '[PRE18]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, we can apply this operation to each group using `by`, as shown:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`by`对每个组应用此操作，如下所示：
- en: '[PRE19]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'What if we want to visualize the percentage of countries speaking each language?
    We can divide each value of the table by the number of countries in the cluster,
    as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想可视化说每种语言的国家百分比？我们可以将表中的每个值除以集群中的国家数量，如下所示：
- en: '[PRE20]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We want to generate `dtClusters` containing the number of countries in each
    group and the percentage of each language. In order to do this, we can generate
    two lists using the commands that we''ve just seen. In order to combine the two
    lists, we can just use `c(list1, list2)`, as shown:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望生成包含每个组国家数量和每种语言百分比的`dtClusters`。为了做到这一点，我们可以使用我们刚刚看到的命令生成两个列表。为了合并这两个列表，我们只需使用`c(list1,
    list2)`，如下所示：
- en: '[PRE21]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Each row of `dtClusters` represents a cluster. The `nCountries` column displays
    the number of countries in the cluster and all the other columns show the percentage
    of each language. In order to visualize this data, we can build a histogram with
    a bar for each cluster. Each bar is divided into segments representing the number
    of countries speaking each language. The `barplot` function allows us to build
    the desired chart, if we give a matrix as the input. Each matrix column corresponds
    to a bar and each row defines the chunks in which the bar is divided.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`dtClusters`的每一行代表一个聚类。`nCountries`列显示聚类中的国家数量，所有其他列显示每种语言的百分比。为了可视化这些数据，我们可以为每个聚类构建一个条形图。每个条形被分割成代表说每种语言的国家数量的段。`barplot`函数允许我们构建所需的图表，如果我们提供矩阵作为输入。每个矩阵列对应一个条形，每行定义条形分割的块。'
- en: 'We need to define a matrix containing the language percentages. This can be
    done by carrying out the following steps:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要定义一个包含语言百分比的矩阵。这可以通过执行以下步骤来完成：
- en: 'Define `arrayLanguages` containing the `dtClusters` language column names:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义包含`dtClusters`语言列名称的`arrayLanguages`：
- en: '[PRE22]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Build `dtBarplot` containing the language columns:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建`dtBarplot`包含语言列：
- en: '[PRE23]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Convert `dtBarplot` into a matrix using `as.matrix`. In order to build the
    chart, we need to transpose the matrix (invert the rows and columns) using the
    R function `t`:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`as.matrix`将`dtBarplot`转换为矩阵。为了构建图表，我们需要使用R函数`t`转置矩阵（反转行和列）：
- en: '[PRE24]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Define a vector with the cluster sizes, that is, the number of countries. We
    will display the numbers under the columns:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个包含聚类大小的向量，即国家数量。我们将在列下显示这些数字：
- en: '[PRE25]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Define the legend names as the country names:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图例名称定义为国家名称：
- en: '[PRE26]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Reduce the legend names'' length in order to avoid having a legend overlapping
    the chart. Using `substring`, we limit the names to 12 characters, as shown:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 减少图例名称的长度，以避免图例与图表重叠。使用`substring`，我们将名称限制为12个字符，如下所示：
- en: '[PRE27]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Define the colors using `rainbow`. We need to define a color for each element
    of `namesLegend`, so the number of colors is `length(namesLegend)`, as shown:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`rainbow`定义颜色。我们需要为`namesLegend`的每个元素定义一个颜色，因此颜色的数量是`length(namesLegend)`，如下所示：
- en: '[PRE28]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Define the chart title using `paste`:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`paste`定义图表标题：
- en: '[PRE29]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now we have all the `barplot` inputs, so we can build the chart. In order to
    be sure that the legend dosen''t overlap the bars, we include the `xlim` argument
    that specifies the plot boundaries, as shown:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了所有`barplot`输入，因此我们可以构建图表。为了确保图例不与条形重叠，我们包括`xlim`参数，该参数指定绘图边界，如下所示：
- en: '[PRE30]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The chart obtained is as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图表如下：
- en: '![Exploring the clusters](img/7740OS_05_01.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![探索聚类](img/7740OS_05_01.jpg)'
- en: The k-means algorithm performs a series of steps starting from the initial clusters
    that are defined by splitting the data randomly. The final output depends on the
    initial random split that is different every time we run the algorithm. So, if
    we run k-means more than once, we might obtain different results. However, this
    chart helps us identify some patterns within the language group. For instance,
    in the eighth cluster, almost all the countries speak English, so we can deduce
    that there are some English-speaking countries with a similar flag. In the fifth
    cluster, more than half of the countries speak French, so we can deduce the same.
    Some less relevant results are that Arabic has a high share in the first cluster
    and Spanish is quite relevant in the seventh cluster.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: K-means算法从通过随机分割数据定义的初始聚类开始执行一系列步骤。最终输出取决于每次运行算法时不同的初始随机分割。因此，如果我们多次运行k-means，可能会得到不同的结果。然而，这个图表帮助我们识别语言组内的某些模式。例如，在第八个聚类中，几乎所有国家都说英语，因此我们可以推断出有一些使用类似国旗的英语国家。在第五个聚类中，超过一半的国家说法语，因此我们可以得出同样的结论。一些不太相关的结果是，阿拉伯语在第一个聚类中占有很高的比例，西班牙语在第七个聚类中相当相关。
- en: 'We are using other clustering algorithms and we will visualize the results
    in a similar way. In order to have clean and compact code, we can define the `plotCluster`
    function. The inputs are the `dtFeatures` feature data table and the `nameCluster`
    cluster column name. The code is almost the same as the preceding one, shown as
    follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用其他聚类算法，并将以类似的方式可视化结果。为了使代码干净且紧凑，我们可以定义`plotCluster`函数。输入是`dtFeatures`特征数据表和聚类列名`nameCluster`。代码几乎与前面的相同，如下所示：
- en: '[PRE31]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This function should build the same histogram as the previous one. Let''s check
    it using the following code:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数应构建与上一个相同的直方图。让我们使用以下代码来检查它：
- en: '[PRE32]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Another way to visualize the clusters is to build a world map using a different
    color for each cluster. In addition, we can visualize a world map for the languages.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可视化聚类的方法是使用不同颜色为每个聚类构建世界地图。此外，我们还可以可视化语言的世界地图。
- en: 'In order to build the map, we need to install and load the `rworldmap` package,
    as shown:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建地图，我们需要安装和加载`rworldmap`包，如下所示：
- en: '[PRE33]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This package builds a world map starting from the country names, that is, in
    our case the `dfFeatures` row names. We can add the `country` column to `dtFeatures`,
    as shown:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 此包从国家名称开始构建世界地图，即在我们的案例中是`dfFeatures`行的名称。我们可以将`country`列添加到`dtFeatures`中，如下所示：
- en: '[PRE34]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Our data is quite old so Germany is still divided in two parts. In order to
    visualize it on the map, we can convert `Germany-FRG` into `Germany`. Similarly,
    we can convert `USSR` into `Russia`, as shown:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据相当旧，所以德国仍然分为两部分。为了在地图上可视化它，我们可以将`Germany-FRG`转换为`Germany`。同样，我们可以将`USSR`转换为`Russia`，如下所示：
- en: '[PRE35]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, we can define a function to build a world map showing the clusters. The
    inputs are the `dtFeatures` data table and the `colPlot` column name of the feature
    to visualize (for example, `clusterKm`). The other argument is `colourPalette`
    and it determines the color to be used in the map. See `help(mapCountryData)`
    for more information, as shown:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以定义一个函数来构建显示聚类的世界地图。输入是`dtFeatures`数据表和要可视化的特征`colPlot`列名（例如，`clusterKm`）。另一个参数是`colourPalette`，它决定了地图中使用的颜色。有关更多信息，请参阅`help(mapCountryData)`，如下所示：
- en: '[PRE36]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We define the `colPlot` column containing the cluster to visualize. In the
    case of a string, we use just the first 12 characters, as shown:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了包含要可视化的聚类的`colPlot`列。在字符串的情况下，我们只使用前12个字符，如下所示：
- en: '[PRE37]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We build `mapFeatures` containing the data that we need to build the chart.
    See `help(joinCountryData2Map)` for more information. The `joinCode = ''NAME''`
    input specifies that the countries are defined by their names and not by an abbreviation.
    The `nameJoinColumn` specifies which column we have the country names in, shown
    as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了包含我们构建图表所需数据的`mapFeatures`。有关更多信息，请参阅`help(joinCountryData2Map)`。`joinCode
    = 'NAME'`输入指定国家由其名称定义，而不是缩写。`nameJoinColumn`指定我们拥有国家名称的列，如下所示：
- en: '[PRE38]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We can build the chart using `mapCountryData`. We specify that we are using
    the colors of the rainbow and that the country with the missing data will be gray,
    as shown in the following code:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`mapCountryData`构建图表。我们指定使用彩虹的颜色，并且缺失数据的该国将以灰色显示，如下面的代码所示：
- en: '[PRE39]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now, we can use `plotMap` to visualize the k-means clusters on the world map,
    as shown:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`plotMap`在地图上可视化k-means聚类，如下所示：
- en: '[PRE40]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![Exploring the clusters](img/7740OS_05_02.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![探索聚类](img/7740OS_05_02.jpg)'
- en: We can see that many Asian countries belong to the fifth cluster. In addition,
    we can observe that Italy, France, and Ireland belong to the same cluster, since
    their flag is similar. Apart from that, it's hard to identify any other pattern.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到许多亚洲国家属于第五个聚类。此外，我们可以观察到意大利、法国和爱尔兰属于同一个聚类，因为它们的旗帜相似。除此之外，很难识别出其他任何模式。
- en: Identifying a cluster's hierarchy
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别聚类的层次结构
- en: Other techniques to identify homogeneous groups are the hierarchic clustering
    algorithms. These techniques build the clusters, merging the objects iteratively.
    At the beginning, we have a cluster for each country. We define a measure of how
    *similar* two clusters are and, at each step, we identify the two clusters whose
    flag is the most *similar* and merge them into a unique cluster. In the end, we
    have a cluster including all the countries.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 识别同质群体的其他技术是层次聚类算法。这些技术通过迭代合并对象来构建聚类。一开始，我们为每个国家都有一个聚类。我们定义了两个聚类如何相似的一个度量，并在每一步中，我们识别出旗帜最相似的两组聚类并将它们合并成一个唯一的聚类。最后，我们有一个包含所有国家的聚类。
- en: 'The R function that performs hierarchic clustering is `hclust`. Let''s take
    a look at its `help` function:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 执行层次聚类的 R 函数是 `hclust`。让我们看看它的 `help` 函数：
- en: '[PRE41]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The first input is `d` and the documentation explains that it''s a dissimilarity
    structure, that is, a matrix containing all the distances between the objects.
    As suggested by the documentation, we can use the `dist` function to build the
    input, as shown:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个输入是 `d`，文档解释说它是一个差异结构，即包含所有对象之间距离的矩阵。如文档建议，我们可以使用 `dist` 函数来构建输入，如下所示：
- en: '[PRE42]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The input of `dist` is a numeric matrix describing the flags. We already built
    `matrixDistances` for the k-means algorithm, so we can reuse it. The other relevant
    input is `method` and it specifies how `dist` measures the distance between two
    flags. Which method should we use? All the features are binary as they have two
    possible outcomes, that is, `0` and `1`. Then, the distance can be the number
    of attributes with a different value. The `method` object that determines the
    distance in this way is `manhattan`, as shown:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '`dist` 的输入是一个描述旗帜的数值矩阵。我们已为 k-means 算法构建了 `matrixDistances`，因此我们可以重用它。另一个相关输入是
    `method`，它指定了 `dist` 如何测量两个旗帜之间的距离。我们应该使用哪种方法？所有特征都是二进制的，因为它们有两种可能的输出，即 `0` 和
    `1`。因此，距离可以是具有不同值的属性的数量。以这种方式确定距离的 `method` 对象是 `manhattan`，如下所示：'
- en: '[PRE43]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The `matrixDistances` function contains the dissimilarity between any two flags.
    The other input is `method` and it specifies the agglomeration method. In our
    case, we set the method as `complete`. There are other options for `method` and
    they define the linkage, that is, the way of computing the distance between clusters,
    as shown:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`matrixDistances` 函数包含任何两个旗帜之间的差异。另一个输入是 `method`，它指定了聚合方法。在我们的情况下，我们将方法设置为
    `complete`。`method` 有其他选项，它们定义了连接，即计算簇之间距离的方式，如下所示：'
- en: '[PRE44]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The `modelHc` method contains the clustering model and we can visualize the
    cluster using `plot`. You can consult the help of `hclust` to understand the `plot`
    parameters, as shown:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`modelHc` 方法包含聚类模型，我们可以使用 `plot` 来可视化簇。你可以查阅 `hclust` 的帮助来了解 `plot` 参数，如下所示：'
- en: '[PRE45]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '![Identifying a cluster''s hierarchy](img/7740OS_05_03.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![识别簇的层次结构](img/7740OS_05_03.jpg)'
- en: 'This chart shows the algorithm procedure. At the bottom, we have all the countries,
    and each flag belongs to a different cluster. Each line represents a cluster and
    the lines converge when the algorithm merges the clusters. On the left-hand side
    of the chart, you can see a scale representing the distance between the flags,
    and at each level the algorithm merges the clusters that are at a specific distance
    from each other. At the top, all the flags belong to the same cluster. This chart
    is called **dendrogram**. Consider the following code:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 此图表显示了算法过程。在底部，我们有所有国家，每个旗帜属于不同的簇。每条线代表一个簇，当算法合并簇时，线会汇聚。在图表的左侧，你可以看到一个表示旗帜之间距离的刻度，在每一级，算法合并彼此距离特定的簇。在顶部，所有旗帜都属于同一个簇。这个图表被称为**树状图**。考虑以下代码：
- en: '[PRE46]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The clusters that we want to identify are the ones above the red line. The
    function that identifies the cluster starting from `modelHc` is `cutree`, and
    we can specify the horizontal line height in the `h` argument, as shown:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要识别的簇是红色线以上的簇。从 `modelHc` 开始识别簇的函数是 `cutree`，我们可以在 `h` 参数中指定水平线的高度，如下所示：
- en: '[PRE47]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Now, we can add the cluster to `dtFeatures`, as shown:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将簇添加到 `dtFeatures` 中，如下所示：
- en: '[PRE48]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'As mentioned earlier, we can see which languages are spoken in each cluster.
    We can reuse `plotCluster` and `plotMap`:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们可以看到每个簇中使用的语言。我们可以重用 `plotCluster` 和 `plotMap`：
- en: '[PRE49]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '![Identifying a cluster''s hierarchy](img/7740OS_05_04.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![识别簇的层次结构](img/7740OS_05_04.jpg)'
- en: In the eighth cluster, English is the predominant language. Apart from that,
    Arabic is relevant in the first cluster only, French and German are relevant in
    the second and third if taken together, and Spanish is relevant in the third.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在第八个簇中，英语是主要语言。除此之外，阿拉伯语只在第一个簇中相关，法语和德语如果一起考虑，在第二个和第三个簇中相关，西班牙语在第三个簇中相关。
- en: 'We can also visualize the world map with the clusters, as shown:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以用簇可视化世界地图，如下所示：
- en: '[PRE50]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The chart obtained is as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图表如下：
- en: '![Identifying a cluster''s hierarchy](img/7740OS_05_05.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![识别簇的层次结构](img/7740OS_05_05.jpg)'
- en: Similar to k-means, the only continent with a predominant cluster is Asia.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 与 k-means 类似，唯一有一个主要簇的大陆是亚洲。
- en: This section described two popular clustering techniques that identify homogeneous
    flag clusters. They both allow us to understand the similarities between different
    flags, and we can use this information as support to solve some problems.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了两种识别同质旗帜集群的流行聚类技术。它们都允许我们理解不同旗帜之间的相似性，我们可以利用这些信息作为支持来解决一些问题。
- en: Applying the k-nearest neighbor algorithm
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用k最近邻算法
- en: This section shows you how to estimate a new country language starting from
    its flag, using a simple supervised learning technique that is the **k-nearest
    neighbor** (**KNN**). In this case, we estimate the language, which is a `categoric`
    attribute so we use a classification technique. If the attribute was numeric,
    we would have used a regression technique. The reason I chose KNN is that it's
    simple to explain, and there are some options to modify its parameters in order
    to improve the result's accuracy.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 本节展示了如何使用一种简单的监督学习技术——**k最近邻**（**KNN**），从其旗帜开始估计一个新国家的语言。在这种情况下，我们估计的是语言，这是一个`categoric`属性，所以我们使用分类技术。如果属性是数值的，我们会使用回归技术。我选择KNN的原因是它易于解释，并且有一些选项可以修改其参数以提高结果的准确性。
- en: Let's see how the KNN works. We know the flag and the language of 150 countries
    and we want to determine the language of a new country starting from its flag.
    First, we identify the 10 countries whose flag is the most similar to the new
    one. Out of them, we have six Spanish-speaking countries, two English-speaking
    countries, one French-speaking country, and one Arabic-speaking country.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看KNN是如何工作的。我们知道150个国家的旗帜和语言，我们想要根据其旗帜确定一个新国家的语言。首先，我们确定与新的旗帜最相似的10个国家。其中，有六个西班牙语国家，两个英语国家，一个法语国家和一个阿拉伯语国家。
- en: Out of these 10 countries, the most common language is Spanish, so we can expect
    that the new flag belongs to a Spanish-speaking country.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在这10个国家中，最常见的语言是西班牙语，因此我们可以预期新的旗帜属于一个讲西班牙语的国家。
- en: The KNN is based upon this approach. In order to estimate a new country language,
    we identify the *K* countries whose flag is the most similar. Then, we estimate
    that the new country speaks the most common language among them.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: KNN基于这种方法。为了估计一个新国家的语言，我们确定旗帜最相似的*K*个国家。然后，我们估计新国家说的是他们中最常见的语言。
- en: We have a table describing 194 flags through 37 binary attributes whose value
    can be `Yes` or `No`. For instance, the `mainhuegreen` attribute is `yes`, if
    the predominant flag color is green and `no` otherwise. All the attributes describe
    the flag's colors and patterns.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个表格，通过37个二进制属性描述了194个旗帜，这些属性可以是`Yes`或`No`。例如，`mainhuegreen`属性是`yes`，如果旗帜的主要颜色是绿色，否则是`no`。所有属性都描述了旗帜的颜色和图案。
- en: 'Similar to the previous section, before modifying `dtFeatures`, we define `arrayFeatures`
    containing the feature names. As we added some columns to `dtFeatures`, we extract
    the feature names from `dfFeatures`. Then, we add the `country` column with the
    country names coming from `dfFeatures`, as shown:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一节类似，在修改`dtFeatures`之前，我们定义了包含特征名称的`arrayFeatures`。由于我们向`dtFeatures`添加了一些列，所以我们从`dfFeatures`中提取特征名称。然后，我们添加了包含来自`dfFeatures`的国家名称的`country`列，如下所示：
- en: '[PRE51]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Starting from `dtFeatures`, we can apply KNN. Given a new flag, how do we determine
    which are the 10 most similar flags? Given any two flags, we can measure how *similar*
    they are. The easiest way is to count how many features have the same value across
    the two flags. The more attributes they have in common, the more similar they
    are.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 从`dtFeatures`开始，我们可以应用KNN。给定一个新的旗帜，我们如何确定最相似的10个旗帜？对于任何两个旗帜，我们可以测量它们之间的相似度。最简单的方法是计算两个旗帜中有多少特征值相同。它们共有的属性越多，它们就越相似。
- en: 'In the previous chapter, we already explored and transformed the features,
    so we don''t need to process them. However, we haven''t explored the language
    column yet. For each language, we can determine how many countries speak the language
    using `table`, as shown:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们已经探索并转换了特征，因此我们不需要处理它们。然而，我们还没有探索语言列。对于每种语言，我们可以使用`table`来确定说这种语言的国家数量，如下所示：
- en: '[PRE52]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The number of countries varies a lot from one language to another. The most
    popular language is `English`, with 43 countries, and there are some languages
    with just four countries. In order to have an overview of all the languages, we
    can visualize the table by building a chart. In the previous section, we defined
    `plotMap`, which shows the groups on the world map. We can use it to show the
    countries speaking each language, as shown:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 不同语言的国家数量差异很大。最受欢迎的语言是`英语`，有43个国家，还有一些语言只有四个国家。为了对所有语言有一个概览，我们可以通过构建图表来可视化表格。在前一节中，我们定义了`plotMap`，它显示了世界地图上的群体。我们可以用它来显示说每种语言的国家，如下所示：
- en: '[PRE53]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The chart obtained is as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图表如下：
- en: '![Applying the k-nearest neighbor algorithm](img/7740OS_05_06.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![应用k最近邻算法](img/7740OS_05_06.jpg)'
- en: 'It''s nice to see a map showing countries that speak each language, but it''s
    still a bit hard to understand how big the groups are. A better option is to generate
    a pie chart whose slices are proportional to the number of countries in each group.
    The R function is `pie`, as shown:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 看到一张显示说每种语言的国家地图是件好事，但它仍然有点难以理解群体的大小。更好的选择是生成一个饼图，其切片与每个群体中的国家数量成比例。R函数是`pie`，如下所示：
- en: '[PRE54]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The `pie` function requires an input, that is, a vector containing the number
    of countries speaking each language. If the input vector fields have a name, it''ll
    be displayed in the chart. We can build the required vector using `table`, as
    shown:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`pie`函数需要一个输入，即包含每种语言说国家数量的向量。如果输入向量的字段有名称，它将在图表中显示。我们可以使用`table`构建所需的向量，如下所示：'
- en: '[PRE55]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Fortunately, `pie` doesn''t require any other argument:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，`pie`不需要任何其他参数：
- en: '[PRE56]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The chart obtained is as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图表如下：
- en: '![Applying the k-nearest neighbor algorithm](img/7740OS_05_07.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![应用k最近邻算法](img/7740OS_05_07.jpg)'
- en: There are some languages that are spoken in just a few countries. For instance,
    there are just 4 Slavic countries. Given a new country, we want to determine its
    language starting from its flag. Let's pretend that we don't know which language
    is spoken in one of the 4 Slavic countries. If we take into account its 10 nearest
    neighbors, there cannot be more than 3 other Slavic countries. What if there are
    4 English-speaking countries out of its 10 neighbors? Despite all the remaining
    Slavic countries that are in its neighborhood, there are more English countries
    just because the English group is bigger. Therefore, the algorithm will estimate
    that the country is English. Similarly, we have the same issue with any other
    small group. Like almost all the machine learning algorithm, the KNN won't be
    able to classify the countries that belong to any other smaller group.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 有些语言只在少数几个国家说。例如，只有4个斯拉夫国家。给定一个新国家，我们想要从其国旗开始确定其语言。让我们假设我们不知道这4个斯拉夫国家中有一个国家说的是哪种语言。如果我们考虑其10个最近的邻居，其中不可能有超过3个其他斯拉夫国家。如果在其10个邻居中有4个说英语的国家呢？尽管在其附近还有其他斯拉夫国家，但由于英语群体更大，所以算法会估计这个国家说的是英语。同样，我们也会遇到任何其他小群体的问题。像几乎所有的机器学习算法一样，KNN无法对属于任何其他更小群体的国家进行分类。
- en: While dealing with any classification problem, if some groups are small, we
    don't have enough related information. In this context, even a good technique
    won't be able to classify the new objects that belong to a small group. In addition,
    given a new country that belongs to a medium-sized group, it likely has a lot
    of neighbors that belong to the big groups. Therefore, a new country speaking
    one of these languages might be assigned to the big groups.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理任何分类问题时，如果某些群体很小，我们就没有足够的相关信息。在这种情况下，即使是一个很好的技术也无法对属于小群体的新对象进行分类。此外，给定一个属于中等大小群体的新国家，它很可能有很多属于大群体的邻居。因此，说这些语言之一的新国家可能会被分配到大型群体中。
- en: 'By knowing the model limitations, we can define a feasible machine learning
    problem. In order to avoid having small groups, we can merge some groups. The
    clustering techniques allowed us to identify which language groups are more well-defined,
    and accordingly, we can split the languages in these groups: `English`, `Spanish`,
    `French and German`, `Slavic and other Indo-European`, `Arabic`, and `Other`.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 通过了解模型限制，我们可以定义一个可行的机器学习问题。为了避免存在小群体，我们可以合并一些群体。聚类技术使我们能够识别哪些语言群体定义得更好，相应地，我们可以将这些群体中的语言分开：`英语`、`西班牙语`、`法语和德语`、`斯拉夫语和其他印欧语系`、`阿拉伯语`和`其他`。
- en: 'We can define the language groups to build `listGroups` whose elements contain
    the language spoken by the groups. For instance, we can define the `indoEu` group
    containing `Slavic` and `Other Indo-European` language, as shown:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以定义语言组来构建`listGroups`，其元素包含组说的语言。例如，我们可以定义包含`Slavic`和`Other Indo-European`语言的`indoEu`组，如下所示：
- en: '[PRE57]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Now, we can redefine the `language` column containing the language groups. For
    each element of `listGroups`, we convert all the languages into the element name.
    For instance, we convert `Slavic` and `Other Indo-European` into `indoEu`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以重新定义包含语言组的`language`列。对于`listGroups`的每个元素，我们将所有语言转换为元素名称。例如，我们将`Slavic`和`Other
    Indo-European`转换为`indoEu`。
- en: 'We can perform this operation within a `for` loop. All the group names are
    contained in the list names, so we can iterate over the elements of `names(listGroups)`,
    as shown:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在`for`循环内执行此操作。所有的组名都包含在`names(listGroups)`列表中，因此我们可以遍历`names(listGroups)`的元素，如下所示：
- en: '[PRE58]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Here, `nameGroup` defines a group name and `listGroups[[nameGroup]]` contains
    its languages. We can extract the rows of `dtFeatures` speaking any of the group
    languages, using `language %in% listGroups[[nameGroup]]`. Then, we can reassign
    the language column to the `nameGroup` group name using the `:=` data table notation,
    as shown:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`nameGroup`定义了一个组名，`listGroups[[nameGroup]]`包含其语言。我们可以使用`language %in% listGroups[[nameGroup]]`提取说任何组语言的`dtFeatures`的行。然后，我们可以使用`:=`数据表符号将语言列重新分配给`nameGroup`组名，如下所示：
- en: '[PRE59]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'We redefined the `language` column grouping the languages. Let''s take a look
    at it:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重新定义了`language`列，按语言进行分组。让我们看看它：
- en: '[PRE60]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Here, `language` is a factor and there are just six possible levels that are
    our language groups. However, you can see that R has printed `16 Levels: Arabic
    Chinese English French ... Other` in the console. The reason is that the `language`
    column format is `factor` and it keeps track of the 10 initial values. In order
    to display just the six language groups, we can redefine the `language` column
    using `factor`, as shown:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里，`language`是一个因子，并且只有六个可能的级别，即我们的语言组。然而，你可以看到R在控制台打印了`16 Levels: Arabic
    Chinese English French ... Other`。原因是`language`列的格式是`factor`，它跟踪前10个初始值。为了只显示六个语言组，我们可以使用`factor`重新定义`language`列，如下所示：'
- en: '[PRE61]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Now we have just six levels. Just like we did earlier, we can visualize the
    group sizes data using `plotMap`, as shown:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只有六个级别。就像我们之前做的那样，我们可以使用`plotMap`可视化组大小数据，如下所示：
- en: '[PRE62]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The map obtained is as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的地图如下：
- en: '![Applying the k-nearest neighbor algorithm](img/7740OS_05_08.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![应用k最近邻算法](img/7740OS_05_08.jpg)'
- en: We can see that the countries of each category are geographically close to each
    other.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，每个类别的国家在地理上彼此相邻。
- en: 'In order to visualize the new group sizes, we can use `pie`, as shown:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化新的组大小，我们可以使用`pie`，如下所示：
- en: '[PRE63]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The chart obtained is as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的图表如下：
- en: '![Applying the k-nearest neighbor algorithm](img/7740OS_05_09.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![应用k最近邻算法](img/7740OS_05_09.jpg)'
- en: All the six groups contain enough countries. The **english** and **other** groups
    are a bit bigger than the others, but the sizes are comparable.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的六个组都有足够的国家。**英语**和**其他**组比其他组稍大，但大小是可比的。
- en: 'Now we can build the KNN model. R provides us with the `kknn` package containing
    the KNN algorithm. Let''s install and load the package, as shown:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以构建KNN模型。R为我们提供了包含KNN算法的`kknn`包。让我们按照以下步骤安装和加载包：
- en: '[PRE64]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The function that builds the KNN is called `kknn`, such as the package. Let''s
    see its help function:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 构建KNN的函数称为`kknn`，例如在包中。让我们看看它的帮助函数：
- en: '[PRE65]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: The first input is formula and it defines the features and the output. Then,
    we have to define a training set, containing the data to be used to build the
    model, and a test set, containing the data upon which we are applying the model.
    We use all the information about the training set and pretend not to know the
    language of the test set countries. There are other optional inputs defining some
    model parameters.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个输入是公式，它定义了特征和输出。然后，我们必须定义一个训练集，包含用于构建模型的数据，以及一个测试集，包含应用模型的数据。我们使用训练集的所有信息，假装不知道测试集国家的语言。还有其他一些可选输入定义了一些模型参数。
- en: 'All the feature names are contained in `arrayFeatures`. In order to define
    how the output depends on the features, we need to build a string in the `output
    ~ feature1 + feature2 + …`. format. Perform the following steps:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的特征名称都包含在`arrayFeatures`中。为了定义输出如何依赖于特征，我们需要构建一个格式为`output ~ feature1 + feature2
    + …`的字符串。执行以下步骤：
- en: 'Define the first part of the string: `output ~` :'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义字符串的第一部分：`output ~`：
- en: '[PRE66]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'For each feature, add `+ feature` using `paste`:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个特征，使用`paste`添加`+ feature`：
- en: '[PRE67]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Convert the string into the `formula` format:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将字符串转换为`formula`格式：
- en: '[PRE68]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: We built `formulaKnn` containing the relationship to put into `kknn`.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了包含要放入`kknn`中的关系的`formulaKnn`。
- en: 'Now, we need to define the training set and the test set starting from `dtFeatures`.
    A fair split is putting 80 percent of the data in the training set, and for this
    purpose we can add each country to the training set with a probability of 80 percent
    and to the test set otherwise. We can define the `indexTrain` vector whose length
    is equal to the number of lines in `dtFeatures`. The R function is `sample`, as
    shown:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要从`dtFeatures`开始定义训练集和测试集。一个公平的分割是将80%的数据放入训练集。为此，我们可以以80%的概率将每个国家添加到训练集中，否则添加到测试集中。我们可以定义长度等于`dtFeatures`中行数的`indexTrain`向量。R函数是`sample`，如下所示：
- en: '[PRE69]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The arguments are:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 参数包括：
- en: '`x`: The values to be put into the vector that are `TRUE` and `FALSE` in this
    case.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：要放入向量的值，在这种情况下为`TRUE`和`FALSE`。'
- en: '`size`: The length of the vector that is the number of rows in `dtFeatures`
    in our case.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size`：向量长度，即在我们的情况下`dtFeatures`中的行数。'
- en: '`replace`: In order to sample the values more than once, it''s `TRUE`.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`replace`：为了多次采样值，设置为`TRUE`。'
- en: '`prob`: The probability of choosing the elements of `x`. In our case, we pick
    `TRUE` with a probability of 80 percent and `FALSE` with a probability of 20 percent.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prob`：选择`x`中元素的概率。在我们的情况下，我们以80%的概率选择`TRUE`，以20%的概率选择`FALSE`。'
- en: 'Using our arguments, we can build `indexTrain`, shown as follows:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的论点，我们可以构建`indexTrain`，如下所示：
- en: '[PRE70]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Now, we need to add the rows, for which `indexTrain` is `TRUE`, to the training
    set and the remaining rows to the testing set. We extract all the rows, for which
    `indexTrain` is `TRUE`, using a simple data table operation, as shown:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要将`indexTrain`为`TRUE`的行添加到训练集中，将剩余的行添加到测试集中。我们使用简单的数据表操作提取所有`indexTrain`为`TRUE`的行，如下所示：
- en: '[PRE71]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'In order to extract the test rows, we have to switch `TRUE` and `FALSE` using
    the `NOT` operator that in R is `!`, as shown:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提取测试行，我们必须使用R中的`NOT`运算符切换`TRUE`和`FALSE`，如下所示：
- en: '[PRE72]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Now we have all the basic arguments for using `kknn`. The other parameters
    that we set are:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了使用`kknn`的所有基本参数。我们设置的其它参数是：
- en: '`k`: The number of neighbors is `10`.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`k`：邻居的数量是`10`。'
- en: '`kernel`: KNN has the option of assigning a different relevance to the features,
    but we''re not using this feature at the moment. Setting the `kernel` parameter
    as `rectangular`, we use the basic KNN.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel`：KNN有选项为特征分配不同的相关性，但我们目前不使用此功能。将`kernel`参数设置为`rectangular`，我们使用基本的KNN。'
- en: '`distance`: We want to compute the distance between two flags as the number
    of attributes that they don''t have in common (similar to the previous chapter).
    In order to do this, we set the distance parameter equal to `1`. For more information,
    you can learn about **Minkowski distance**.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distance`：我们想要计算两个标志之间的距离，即它们没有的共同属性的数量（类似于上一章）。为了做到这一点，我们将距离参数设置为`1`。有关更多信息，您可以了解**闵可夫斯基距离**。'
- en: 'Let''s build the KNN model:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建KNN模型：
- en: '[PRE73]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The model has learned from `dtTrain` and estimated the language of the countries
    in `dtTest`. As we can see in the `kknn` help, `modelKnn` is a list containing
    a description of the model. The component showing the predicted language is `fitted.valued`,
    as shown:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 模型已从`dtTrain`中学习并估计了`dtTest`中国家的语言。正如我们在`kknn`的帮助中看到的那样，`modelKnn`是一个包含模型描述的列表。显示预测语言的组件是`fitted.valued`，如下所示：
- en: '[PRE74]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'We can add the predicted language to `dtTest` in order to compare it with the
    real language:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将预测的语言添加到`dtTest`中，以便与实际语言进行比较：
- en: '[PRE75]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'For the countries in `dtTest`, we know the real and the predicted languages.
    We can count how many times they are the same using `sum(language == languagePred)`.
    We can measure the model accuracy by dividing the number of correct predictions
    by the total, that is, `.N` (the number of rows), as shown:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`dtTest`中的国家，我们知道实际和预测的语言。我们可以使用`sum(language == languagePred)`来计算它们相同的次数。我们可以通过将正确预测的数量除以总数来衡量模型精度，即`.N`（行数），如下所示：
- en: '[PRE76]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Here, `percCorrect` varies a lot depending on the training/test dataset split.
    As we have different language groups, `percCorrect` is not particularly high.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`percCorrect`根据训练/测试数据集分割有很大的变化。由于我们有不同的语言组，`percCorrect`并不特别高。
- en: Optimizing the k-nearest neighbor algorithm
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化k最近邻算法
- en: We built our KNN model using 37 features that have a different relevance to
    the language. Given a new flag, its neighbors are the flags sharing a lot of attributes,
    regardless of their relevance. If a flag has different common attributes that
    are irrelevant to the language, we erroneously include it in the neighborhood.
    On the other hand, if a flag shares a few highly-relevant attributes, it won't
    be included.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用37个具有不同相关性的语言特征构建了我们的KNN模型。给定一个新的标志，其邻居是具有许多属性共享的标志，无论它们的相关性如何。如果一个标志具有与语言无关的不同共同属性，我们将错误地将其包括在邻域中。另一方面，如果一个标志共享一些高度相关的属性，它将不会被包括。
- en: KNN performs worse in the presence of irrelevant attributes. This fact is called
    the curse of dimensionality and it's quite common in machine learning algorithms.
    A solution to the curse of dimensionality is to rank the features on the basis
    of their relevance and to select the most relevant. Another option that we won't
    see in this chapter is using dimensionality reduction techniques.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: KNN 在存在无关属性的情况下表现较差。这个事实被称为维度诅咒，这在机器学习算法中相当常见。解决维度诅咒的一种方法是根据特征的相关性对特征进行排序，并选择最相关的。另一种在本章中不会看到的选择是使用降维技术。
- en: 'In the previous chapter, in the *Ranking the features using a filter or a dimensionality
    reduction* section, we measured the feature''s relevance using the information
    gain ratio. Now, we can compute the `dtGains` table, similar to the previous chapter,
    starting from `dtTrain`. We cannot use the whole `dtFeatures` because we''re pretending
    not to know the language of the test set countries. If you want to see how `information.gain`
    works, you can take a look at [Chapter 4](ch04.html "Chapter 4. Step 1 – Data
    Exploration and Feature Engineering"), *Step 1 – Data Exploration and Feature
    Engineering*. Consider the following example:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章的 *使用过滤器或降维对特征进行排序* 部分，我们使用信息增益比来衡量特征的相关性。现在，我们可以从 `dtTrain` 开始计算 `dtGains`
    表，类似于上一章，从 `dtTrain` 开始。我们不能使用整个 `dtFeatures`，因为我们假装不知道测试集国家的语言。如果你想看看 `information.gain`
    是如何工作的，你可以看看[第4章](ch04.html "第4章。步骤1 – 数据探索和特征工程")，*步骤1 – 数据探索和特征工程*。考虑以下示例：
- en: '[PRE77]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The `feature` column contains the feature names and the `attr_importance` column
    displays the feature gain, which expresses its relevance. In order to select the
    most relevant features, we can first rebuild `arrayFeatures` with the sorted features.
    Then, we''ll be able to select the top, as shown:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '`feature` 列包含特征名称，`attr_importance` 列显示特征增益，它表示其相关性。为了选择最相关的特征，我们可以首先使用排序后的特征重建
    `arrayFeatures`。然后，我们将能够选择顶部，如下所示：'
- en: '[PRE78]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Starting from `arrayFeatures` and given a `nFeatures` number, we want to build
    the formula using the top `nFeatures` features. In order to be able to do this
    for any `nFeatures`, we can define a function to build the formula, as shown:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 从 `arrayFeatures` 开始，给定一个 `nFeatures` 数量，我们想要使用前 `nFeatures` 个特征构建公式。为了能够为任何
    `nFeatures` 执行此操作，我们可以定义一个构建公式的函数，如下所示：
- en: '[PRE79]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The steps are as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤如下：
- en: 'Extract the top `nFeatures` features and put them into `arrayFeaturesTop`:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取前 `nFeatures` 个特征并将它们放入 `arrayFeaturesTop`：
- en: '[PRE80]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Build the first part of the formula string:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建公式字符串的第一部分：
- en: '[PRE81]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Add the features to the formula:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将特征添加到公式中：
- en: '[PRE82]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Convert `formulaKnn` into a `formula` format:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `formulaKnn` 转换为 `formula` 格式：
- en: '[PRE83]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Return the output:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回输出：
- en: '[PRE84]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Using our function, we can build `formulaKnnTop` using the top 10 features,
    as shown:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的函数，我们可以使用前10个特征构建 `formulaKnnTop`，如下所示：
- en: 'Now, we can build the model using the same inputs as before, with the exception
    of `formula input` that now contains `formulaKnnTop`, as shown:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用与之前相同的输入构建模型，除了 `formula input` 现在包含 `formulaKnnTop`，如下所示：
- en: '[PRE86]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'As mentioned earlier, we can add the predicted language to `dtTest` in a new
    column called `languagePred10`:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们可以在名为 `languagePred10` 的新列中向 `dtTest` 添加预测的语言：
- en: '[PRE87]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'We can compute the percentage of languages that we identified correctly:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以计算我们正确识别的语言的百分比：
- en: '[PRE88]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Have we achieved any improvement by selecting the top features? In order to
    determine which model is the most accurate, we can compare `percCorrect10` with
    `percCorrect` and determine which is the highest. We randomly defined the split
    between `dtTrain` and `dtTest`, so the result changes every time we run the algorithm.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 通过选择顶部特征，我们是否取得了任何改进？为了确定哪个模型最准确，我们可以比较 `percCorrect10` 和 `percCorrect`，并确定哪个是最高的。我们随机定义了
    `dtTrain` 和 `dtTest` 之间的分割，所以每次运行算法时结果都会变化。
- en: There is another option to avoid the curse of dimensionality. The flags are
    described by 37 features with different relevancies and we selected the 10 most
    relevant. In this way, the similarity depends on the number of features that are
    in common out of the top 10\. What if we have two flags with just two out of the
    top 10 features and 20 out of the remaining features in common? Are they less
    similar than two flags with three out of the top 10 features in common? Instead
    of ignoring the other 27 features, we can use them giving them a lower relevance.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 避免维度灾难的另一个选项。旗帜由37个不同相关性的特征描述，我们选择了其中最相关的10个。这样，相似性取决于在排名前10的特征中共同的特征数量。如果我们有两个旗帜，只有两个排名前10的特征和20个剩余特征是共同的，它们是否比两个共同拥有三个排名前10的特征的旗帜相似度低？我们不是忽略其他27个特征，而是可以给它们一个较低的相关性，并使用它们。
- en: 'There is a KNN variation, called **weighted KNN**, which identifies the relevance
    of each feature and builds the KNN accordingly. There are different KNN versions
    and the `kknn` function allows us to use some of them, specifying the `kernel`
    argument. In our case, we can set `kernel = ''optimal''`, as shown:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种KNN的变体，称为**加权KNN**，它识别每个特征的相关性并根据此构建KNN。有不同版本的KNN，`kknn`函数允许我们使用其中的一些，指定`kernel`参数。在我们的情况下，我们可以设置`kernel
    = 'optimal'`，如下所示：
- en: '[PRE89]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'As mentioned earlier, we can measure the accuracy:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们可以测量准确性：
- en: '[PRE90]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: Depending on the training/test split, `percCorrectWeighted` can be higher or
    lower than `percCorrect`.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 根据训练/测试分割，`percCorrectWeighted`可以高于或低于`percCorrect`。
- en: We saw different options to build a supervised machine learning model. In order
    to identify which performs best, we need to evaluate each option and optimize
    the parameters.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了构建监督机器学习模型的不同选项。为了确定哪个表现最好，我们需要评估每个选项并优化参数。
- en: Summary
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned how to identify homogeneous clusters and visualize
    the clustering process and results. You defined a feasible supervised machine
    learning problem and solved it using KNN. You evaluated the model, accuracy and
    modified its parameters. You also ranked the features and selected the most relevant.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何识别同质聚类并可视化聚类过程和结果。你定义了一个可行的监督机器学习问题，并使用KNN解决了它。你评估了模型、准确性和修改了其参数。你还对特征进行了排序并选择了最相关的。
- en: In the next chapter, you will see a better approach to evaluating the accuracy
    of a supervised learning model. You will see a structured approach to optimizing
    the model parameters and selecting the most relevant features.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将看到一种更好的方法来评估监督学习模型的准确性。你将看到一种结构化的方法来优化模型参数和选择最相关的特征。
