- en: Optimizing Models in Spark and SageMaker
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark和SageMaker中优化模型
- en: The models that are trained on AWS can be further optimized by modifying the
    training directives or hyperparameters. In this chapter, we will discuss various
    techniques that our readers can use to improve the performance of their algorithms.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS上训练的模型可以通过修改训练指令或超参数进行进一步优化。在本章中，我们将讨论读者可以使用来提高其算法性能的各种技术。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The importance of model optimization
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型优化的重要性
- en: Automatic hyperparameter tuning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动超参数调整
- en: Hyperparameter tuning in Apache Spark and SageMaker
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Spark和SageMaker中的超参数调整
- en: The importance of model optimization
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型优化的重要性
- en: Very few algorithms produce optimized models on a first attempt. This is because
    the algorithm might need some parameter tuning from the data scientist to improve
    their accuracy or performance. For example, the learning rate we mentioned in
    [Chapter 7](c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml), *Implementing Deep Learning
    Algorithms*, for deep neural networks needs to be manually tuned. A low learning
    rate may lead the algorithm to take longer (and hence be more expensive if we're
    running on a cloud), whereas a high learning rate might miss the optimal set of
    weights. Likewise, a tree with more levels may take more time to train, but could
    create a model with better predictive capabilities (though it could also cause
    the tree to overfit). These parameters that direct the learning of the algorithms
    are called **hyperparameters**, and contrary to the model parameters (for example, the
    weights of a network), these are not learned throughout the training process.
    Some hyperparameters are not just used to optimize or tune the model, but also
    to define or constrain the problem. For example, the number of clusters is also
    considered a hyperparameter, though it's not really about optimization here, but
    rather is used to define the problem being solved.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 很少有算法在第一次尝试就能产生优化的模型。这是因为算法可能需要数据科学家进行一些参数调整以提高其准确性或性能。例如，我们在[第7章](c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml)中提到的学习率，*实现深度学习算法*，对于深度神经网络需要手动调整。低学习率可能导致算法运行时间更长（如果我们是在云上运行，那么成本更高），而高学习率可能会错过最优的权重集。同样，具有更多层的树可能需要更多时间来训练，但可能创建一个具有更好预测能力的模型（尽管它也可能导致树过度拟合）。这些指导算法学习的参数被称为**超参数**，与模型参数（例如，网络的权重）不同，这些参数在整个训练过程中并没有被学习。一些超参数不仅用于优化或调整模型，还用于定义或约束问题。例如，簇的数量也被视为超参数，尽管这并不是真的关于优化，而是用于定义要解决的问题。
- en: 'It is not trivial to adjust these hyperparameters for best performance, and
    in many cases it requires understanding the data at hand, as well as how the underlying
    algorithm works. So why not learn these hyperparameters? Many data scientists
    use algorithms that tweak the values of these hyperparameters to see whether they
    produce more accurate results. The problem with this approach is that we could
    be finding the hyperparameters that are optimal on the testing dataset, and we
    might think our model has a better accuracy when we''re just overfitting the testing
    dataset. For this reason, we typically split the dataset into three partitions:
    the training dataset, which is used for training the model, the validation dataset,
    which is used to perform parameter tuning, and the testing dataset, which is just
    used to assess the final accuracy of the model once the parameter tuning is complete.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 调整这些超参数以获得最佳性能并非易事，在许多情况下，它需要理解手头的数据以及底层算法的工作方式。那么，为什么不学习这些超参数呢？许多数据科学家使用调整这些超参数值的算法来查看它们是否会产生更准确的结果。这种方法的缺点是，我们可能会找到在测试数据集上最优的超参数，而我们可能会认为我们的模型具有更好的准确性，当我们只是过度拟合测试数据集时。因此，我们通常将数据集分为三个部分：训练数据集，用于训练模型；验证数据集，用于参数调整；测试数据集，仅在参数调整完成后用于评估模型的最终准确性。
- en: Automatic hyperparameter tuning
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动超参数调整
- en: The simplest way to perform hyperparameter tuning is called grid search. We
    define different values we would like to try for each hyperparameter. For example,
    if we are training trees, we may want to try depths of 5, 10, and 15\. At the
    same time, we'd like to see whether the best impurity measure is information gain
    or gini. This creates a total of six combinations that have to be tested for accuracy.
    As you might be anticipating, the number of combinations will grow exponentially
    with the number of hyperparameters to consider. For this reason, other techniques
    are used to avoid testing all possible combinations. A simple approach is to randomize
    the combinations be tried. Some combinations will be missed, but some variations
    will be tested without an inductive bias.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 调整超参数的最简单方法被称为网格搜索。我们为每个超参数定义我们想要尝试的不同值。例如，如果我们正在训练树，我们可能想要尝试深度为5、10和15。同时，我们还想看看最佳杂质度量是否是信息增益或基尼系数。这总共创建了六种组合，需要测试以确定准确性。正如你可能预料到的，组合的数量将随着要考虑的超参数数量的指数增长。因此，其他技术被用来避免测试所有可能的组合。一种简单的方法是随机化要尝试的组合。一些组合可能会被遗漏，但一些变化将在没有归纳偏差的情况下被测试。
- en: AWS SageMaker provides a service for hyperparameter tuning that is smart in
    choosing the hyperparameters to test. In both grid search and randomization, each
    training run doesn't use information about the accuracy obtained in previous runs.
    SageMaker uses a technique called **Bayesian optimization** that is able to select
    the next set of hyperparameter combinations to test based on the accuracy values
    of previously tested combinations. The main idea behind this algorithm is to construct
    a probability distribution over the hyperparameter space. Each time we obtain
    the accuracy of a given combination, the probability distribution is adjusted
    to reflect the new information. A successful optimization will exploit information
    of known combinations that yielded good accuracy, as well as sufficient exploration
    of new combinations that could lead to potential improvements. You will appreciate
    that this is an extremely hard problem to solve, as each training run is slow
    and probably expensive. We usually can't afford to test too many combinations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: AWS SageMaker提供了一个智能选择要测试的超参数的调优服务。在网格搜索和随机化中，每次训练运行都不会使用先前运行中获得的准确性信息。SageMaker使用一种称为**贝叶斯优化**的技术，能够根据先前测试组合的准确性值选择下一组要测试的超参数组合。该算法背后的主要思想是在超参数空间上构建一个概率分布。每次我们获得给定组合的准确性时，概率分布都会调整以反映新的信息。成功的优化将利用已知组合的信息，这些组合产生了良好的准确性，以及对新组合的充分探索，这些新组合可能导致潜在改进。你会欣赏这是一个极其困难的问题，因为每次训练运行都很慢，可能也很昂贵。我们通常负担不起测试太多的组合。
- en: Hyperparameter tuning in Apache Spark
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark中的超参数调整
- en: Recall our regression problem from [Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml),
    *Predicting House Value with Regression Algorithms*, in which we constructed a
    linear regression to estimate the value of houses. At that point, we used a few
    arbitrary values for our hyperparameters.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下我们来自第3章的回归问题，[预测房价的回归算法](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml)，其中我们构建了一个线性回归来估计房屋的价值。在那个阶段，我们为超参数使用了一些任意值。
- en: 'In the following code block, we will show how Apache Spark can test 18 different
    hyperparameter combinations for `elasticNetParam`, `regParam`, and `solver`:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码块中，我们将展示Apache Spark如何测试`elasticNetParam`、`regParam`和`solver`的18种不同的超参数组合：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We will start by constructing our classifier as usual, without providing any
    hyperparameters. We store the regressor in the `linear` variable. Next, we define
    the different values to test for each hyperparameter by defining a parameter grid.
    The functional reference to the methods that set the values is passed to a `ParamGridBuilder`
    which is responsible for keeping the combinations to test out.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将像往常一样开始构建我们的分类器，不提供任何超参数。我们将回归器存储在`linear`变量中。接下来，我们通过定义一个参数网格来定义要测试的每个超参数的不同值。设置值的方法的函数引用被传递给`ParamGridBuilder`，它负责保持要测试的组合。
- en: 'As usual, we can define our pipeline with any preprocessing stages (in this
    case, we use a vector assembler). `CrossValidator` takes the pipeline, parameter
    grid, and evaluator. Recall that the evaluator was used to obtain a specific score
    using a test dataset:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 与往常一样，我们可以使用任何预处理阶段（在这种情况下，我们使用向量组装器）来定义我们的管道。`CrossValidator`接受管道、参数网格和评估器。回想一下，评估器被用来使用测试数据集获得一个特定的分数：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this case, we will be using the R2 metric as we did in [Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml),
    *Predicting House Value with Regression Algorithms*. `CrossValidator`, upon the
    call to `fit()`, will run all combinations and find the hyperparameter that achieves
    the highest R2 value.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将使用与[第3章](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml)，*使用回归算法预测房价*中相同的R2指标。`CrossValidator`在调用`fit()`时将运行所有组合，并找到实现最高R2值的超参数。
- en: 'Once it completes, we can inspect the underlying best model by accessing it
    through the `optimized_model.bestModel` reference. Through it, we can show the
    actual set of hyperparameters used in the best model found:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成，我们可以通过访问`optimized_model.bestModel`引用来检查底层最佳模型。通过它，我们可以展示在最佳模型中实际使用的超参数集：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output of the above statement is as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 上述语句的输出如下：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'However, more interesting than the actual parameters used is to see the accuracy
    changes across the different combinations tested. The `optimized_model.avgMetrics`
    values will show the accuracy values for all 18 combinations of hyperparameters:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，比实际使用的参数更有趣的是看到不同组合测试中的准确度变化。`optimized_model.avgMetrics`值将显示所有18个超参数组合的准确度值：
- en: '`[0.60228046689935, 0.6022857524897973, ... 0.6034106428627964, 0.6034118340373834]`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`[0.60228046689935, 0.6022857524897973, ... 0.6034106428627964, 0.6034118340373834]`'
- en: 'We can use the `optimized_model`, returned by `CrossValidator`, to obtain predictions
    using the best model, as it is also a transformer:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`CrossValidator`返回的`optimized_model`来使用最佳模型进行预测，因为它也是一个转换器：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this case, we obtain an R2 of 0.72, which is slightly better than what we
    got with our arbitrary set of hyperparameters in [Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml), *Predicting
    House Value with Regression Algorithms*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们得到了一个R2值为0.72，这比我们在[第3章](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml)中，*使用回归算法预测房价*所得到的任意超参数集要好一些。
- en: Hyperparameter tuning in SageMaker
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SageMaker中的超参数调整
- en: As we mentioned in the previous section,  *Automatic hyperparameter tuning*, 
    SageMaker has a library for smart parameter tuning using Bayesian Optimization.
    In this section, we will show how we can further tune the model we created in
    [Chapter 4](af506fc8-f482-453e-8162-93a676b2e737.xhtml), *Predicting User Behavior
    with Tree-based Methods*. Recall from that chapter that we posed a binary classification
    problem for trying to predict whether a user would click on an advertisement.
    We had used an `xgboost` model, but at that point we hadn't performed any parameter
    tuning.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中提到的，*自动超参数调整*，SageMaker有一个使用贝叶斯优化的智能参数调整库。在本节中，我们将展示如何进一步调整我们在[第4章](af506fc8-f482-453e-8162-93a676b2e737.xhtml)，*使用基于树的预测用户行为*中创建的模型。回想一下，在那个章节中，我们提出了一个二元分类问题，试图预测用户是否会点击广告。我们使用了`xgboost`模型，但在那个阶段我们还没有进行任何参数调整。
- en: We will start by creating the SageMaker session and choosing the `xgboost:`
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先创建SageMaker会话并选择`xgboost:`
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, we define the estimator just as we did in [Chapter 4](https://cdp.packtpub.com/mastering_machine_learning_on_aws/wp-admin/post.php?post=39&action=edit#post_27), *Predicting
    User Behavior with Tree-Based Methods*:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义估计器，就像我们在[第4章](https://cdp.packtpub.com/mastering_machine_learning_on_aws/wp-admin/post.php?post=39&action=edit#post_27)，*使用基于树的预测用户行为*中所做的那样：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As we always do with SageMaker service calls, we define the location and format
    of the input data for training and validation:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们总是对SageMaker服务调用所做的那样，我们定义了训练和验证输入数据的位置和格式：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'With the base estimator defined and the input data determined, we can now construct
    a training job that will take this estimator, and run a series of training jobs
    varying the hyperparameters:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了基础估计器和确定了输入数据后，我们现在可以构建一个训练作业，该作业将使用这个估计器，并运行一系列的训练作业，以改变超参数：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'SageMaker: Creating hyperparameter tuning job with name: `xgboost-190407-1532`'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker：创建名为`xgboost-190407-1532`的超参数调整作业
- en: 'The first step is to create an instance of `HyperparameterTuner` in which we
    set the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是创建一个`HyperparameterTuner`实例，在其中我们设置以下内容：
- en: The base estimator upon which the hyperparameters will be varied.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础估计器，超参数将在其上变化。
- en: The objective metric, which will be used to find the best possible combination
    of hyperparameters. Since we're dealing with a binary classification problem,
    using the area under the curve metric on the validation data is a good choice.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标指标，它将被用来找到最佳的超参数组合。由于我们处理的是一个二元分类问题，在验证数据上使用曲线下面积指标是一个不错的选择。
- en: The different ranges we'd like to test for each hyperparameter. These ranges
    can be specified for parameters that vary continuously using `ContinuousParameter`,
    or discretely using `IntegerParameter` or `CategoricalParameter`.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望为每个超参数测试的不同范围。这些范围可以使用`ContinuousParameter`为连续变化的参数指定，或者使用`IntegerParameter`或`CategoricalParameter`为离散参数指定。
- en: The number of jobs to run, as well as the maximum amount of jobs to run in parallel.
    There is a trade off here between accuracy and speed. The more parallel jobs you
    run, the less data about prior job metrics will be used to inform the next set
    of hyperparameters to try. This leads to a sub-optimal range search. However,
    it will complete the tuning faster. In this example, we just run 10 jobs. We typically
    want to run more than that to obtain significant improvements. Here we just present
    a low value so that the reader can get fast results.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要运行的作业数量，以及并行运行的最大作业数量。这里在准确性和速度之间有一个权衡。您运行的并行作业越多，用于告知下一组尝试的超参数的数据就越少。这会导致范围搜索次优。然而，它将更快地完成调整。在这个例子中，我们只运行了10个作业。我们通常希望运行更多的作业以获得显著的改进。在这里，我们只展示一个低值，以便读者可以快速获得结果。
- en: The fitting can be monitored through the AWS console ([https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/hyper-tuning-jobs](https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/hyper-tuning-jobs))
    or through methods in the python SDK, we can see the status of the jobs.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过AWS控制台（[https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/hyper-tuning-jobs](https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/hyper-tuning-jobs)）或通过Python
    SDK中的方法来监控拟合过程，我们可以看到作业的状态。
- en: 'Once it''s complete, the AWS Console should look like the following screenshot;
    in it, you can see the different jobs that ran and the different performance metrics
    that were obtained:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成，AWS控制台应该看起来像下面的截图；在其中，您可以查看已运行的不同的作业和获得的不同性能指标：
- en: '![](img/9a2b965a-7b43-4a80-9ab7-852c603113da.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9a2b965a-7b43-4a80-9ab7-852c603113da.png)'
- en: 'Let us inspect which training job yields the best performance using the SDK.
    The first thing is to find the name of the best job:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用SDK检查哪个训练作业产生了最佳性能。首先，要找到最佳作业的名称：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '''xgboost-190407-1342-001-5c7e2a26'''
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '''xgboost-190407-1342-001-5c7e2a26'''
- en: 'Using the methods in the session object, we can show the values of the hyperparameters
    for the optimal training job:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 使用会话对象中的方法，我们可以显示最优训练作业的超参数值：
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output of the previous describe command is as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个describe命令的输出如下：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Using the `describe_hyper_parameter_tuning_job()` method, we can also get the
    final value of the optimal AUC metric:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`describe_hyper_parameter_tuning_job()`方法，我们还可以获取最优AUC指标的最终值：
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following output is the result of the preceding command:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出是前一个命令的结果：
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: You should explore the full API and Python SDK for a complete set of features
    and options regarding the automatic tuning. Please check out:[ https://github.com/aws/sagemaker-python-sdk ](https://github.com/aws/sagemaker-python-sdk)
    We hope this introduction can help to get started on how to fine-tune the models.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该探索完整的API和Python SDK，以获取有关自动调整的完整功能集和选项。请查看：[https://github.com/aws/sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk)
    我们希望这个介绍能帮助您开始了解如何微调模型。
- en: Summary
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered the importance of model tuning through hyperparameter
    optimization. We provided examples of doing grid search in Apache Spark, as well
    as how to use SageMaker's advanced parameter tuning.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了通过超参数优化进行模型调整的重要性。我们提供了在Apache Spark中进行网格搜索的示例，以及如何使用SageMaker的高级参数调整。
- en: In the next chapter we will focus on optimizing the hardware and cluster set
    up upon which we train and apply models. Both model optimization and hardware
    optimization are important for successful and cost-effective AI processes.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将专注于优化硬件和集群设置，这是我们训练和应用模型的基础。模型优化和硬件优化对于成功且成本效益高的AI流程都至关重要。
- en: Exercises
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Regarding ways to find the best hyperparameters, compare the advantages and
    disadvantages of grid search, random search, and Bayesian optimization as they
    apply to hyperparameter tuning.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于寻找最佳超参数的方法，比较网格搜索、随机搜索和贝叶斯优化在超参数调整中的应用的优缺点。
- en: Why do we typically need three splits of data when we do hyperparameter tuning?
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们在进行超参数调整时通常需要三个数据分割？
- en: 'Which metric do you think would be best for our `xgboost` example: `validation:auc`
    or `training:auc`?'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您认为哪个指标最适合我们的`xgboost`示例：`validation:auc`还是`training:auc`？
