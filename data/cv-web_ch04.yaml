- en: Chapter 4. Smile and Wave, Your Face Has Been Tracked!
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章。微笑和挥手，您的脸部已被跟踪！
- en: The most commonly seen object in our lives is a human face. We interact with
    people everywhere even when we do not meet them in person; we write a lot of messages
    via social networks, such as Twitter and Facebook, or e-mails and text messages
    using our phones. Face detection and tracking has many applications. In some cases,
    you might want to create a human computer interface, which will take the head
    position as an input or, more likely, you might want to help your users with tagging
    their friends. Actually, there are a lot of face detection libraries, which are
    written on JavaScript; these outnumber the libraries that focus on image processing
    itself. This is a good opportunity to choose the library that you really need.
    In addition to face detection, many libraries support face particle recognition
    and recognition of other objects.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的生活中最常见的对象之一是人脸。我们与人们的互动无处不在，即使我们没有亲自见面；我们通过社交媒体，如 Twitter 和 Facebook，或通过手机发送大量消息，如电子邮件和短信。人脸检测和跟踪有许多应用。在某些情况下，你可能想创建一个人机界面，它将头部位置作为输入，或者更有可能的是，你可能想帮助你用户标注他们的朋友。实际上，有很多用
    JavaScript 编写的人脸检测库；这些库的数量超过了专注于图像处理的库。这是一个选择你真正需要的库的好机会。除了人脸检测外，许多库还支持人脸粒子识别和其他对象的识别。
- en: In this chapter, we will focus on the JSFeat ([http://inspirit.github.io/jsfeat/](http://inspirit.github.io/jsfeat/)),
    tracking.js ([http://inspirit.github.io/jsfeat/](http://inspirit.github.io/jsfeat/)),
    and headtrackr ([https://github.com/auduno/headtrackr](https://github.com/auduno/headtrackr))
    libraries. The last library supports head tracking instead of just recognition.
    Most of the libraries focus on Haar-like features detection.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点关注 JSFeat ([http://inspirit.github.io/jsfeat/](http://inspirit.github.io/jsfeat/))、tracking.js
    ([http://inspirit.github.io/jsfeat/](http://inspirit.github.io/jsfeat/)) 和 headtrackr
    ([https://github.com/auduno/headtrackr](https://github.com/auduno/headtrackr))
    库。最后一个库支持头部跟踪而不是仅仅识别。大多数库都专注于 Haar-like 特征检测。
- en: 'With the help of several examples, we will cover the following topics in this
    chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 通过几个示例，我们将在本章中涵盖以下主题：
- en: Face detection with JSFeat
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 JSFeat 进行人脸检测
- en: Tagging people with tracking.js
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 tracking.js 标注人物
- en: Head tracking with Camshift
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Camshift 进行头部跟踪
- en: Face detection with JSFeat
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 JSFeat 进行人脸检测
- en: We saw detection of various objects in the previous chapter. The human face
    is much more complicated than just a regular color object, for example. More complex
    detectors share in common such things like the usage of brightness information
    and the patterns that this information forms. First of all, we need to see how
    face recognition is done. Without that, the tracking process will be quite difficult
    to understand. Actually, in most cases, the face recognition part is just the
    first step of face tracking algorithms.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们看到了各种对象的检测。人脸比普通的颜色对象要复杂得多，例如。更复杂的检测器在诸如使用亮度信息和这些信息形成的模式等方面有共同之处。首先，我们需要了解人脸识别是如何进行的。没有这个，跟踪过程将很难理解。实际上，在大多数情况下，人脸识别部分只是人脸跟踪算法的第一步。
- en: We start with the JSFeat project. This awesome library provides a functionality
    to detect a face in two ways. Both have many applications in the real world. We
    will see how both of them work from the inside and discuss the API provided by
    JSFeat.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 JSFeat 项目开始。这个出色的库提供了两种检测人脸的功能。这两种方法在现实世界中都有很多应用。我们将从内部了解这两种方法的工作原理，并讨论
    JSFeat 提供的 API。
- en: Face detection using Haar-like features
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Haar-like 特征进行人脸检测
- en: This is probably the most popular face detector nowadays. Most of the libraries
    use exactly this algorithm as a common face detector. It is easy to implement
    and use. In addition to this, it can be used in any application as it gives good
    precision in face detection. The method itself forms a Viola-Jones object detection
    framework, which was proposed by Paul Viola and Michael Jones in 2001.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是现在最流行的面部检测器。大多数库都使用这个算法作为通用的面部检测器。它易于实现和使用。除此之外，它可以在任何应用程序中使用，因为它在人脸检测方面提供了良好的精度。该方法本身形成了一个
    Viola-Jones 对象检测框架，该框架由保罗·维奥拉和迈克尔·琼斯于 2001 年提出。
- en: 'Remember the convolution kernels from [Chapter 2](cv-web_ch02.html#aid-I3QM1
    "Chapter 2. Turn Your Browser into Photoshop"), *Turn Your Browser into Photoshop*?
    Take a look at this picture:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 记得第二章中的卷积核吗？[“将您的浏览器变成 Photoshop”](cv-web_ch02.html#aid-I3QM1 "第二章。将您的浏览器变成
    Photoshop")？看看这张图片：
- en: '![Face detection using Haar-like features](img/image00118.jpeg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Haar-like 特征进行人脸检测](img/image00118.jpeg)'
- en: The rectangles are called Haar-like features or Haar features. They are just
    convolution kernels, where we subtract pixels under the white rectangle and add
    pixels where under the black part. To compute them fast, we use integral images.
    If you do not remember the concept, then you had better refresh your memory by
    referring to the section on integral image under the section *What is filtering
    and how to use it* in [Chapter 2](cv-web_ch02.html#aid-I3QM1 "Chapter 2. Turn
    Your Browser into Photoshop"), *Turn Your Browser into Photoshop*. Briefly, the
    integral image provides substantial support in fast calculation of the sum of
    pixels in a rectangular area of an image.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这些矩形被称为Haar-like特征或Haar特征。它们只是卷积核，其中我们从白色矩形下的像素中减去，并在黑色部分下添加像素。为了快速计算它们，我们使用积分图像。如果你不记得这个概念，那么你最好通过参考[第2章](cv-web_ch02.html#aid-I3QM1
    "第2章。将您的浏览器变成Photoshop")中的*什么是滤波以及如何使用它*部分下的积分图像部分来刷新您的记忆，*将您的浏览器变成Photoshop*。简而言之，积分图像在快速计算图像矩形区域像素总和方面提供了大量支持。
- en: We can use the features shown in the right-hand side of the picture too. They
    are rotated by 45 degrees. For that case, we use the tilted integral. They can
    capture more object details. The functionality for tilted features is available
    in most of the libraries. But there is a problem which prevents its usage in real-world
    applications—the Haar features are usually applied on low resolution parts of
    an image, for example, 20 x 20 or 24 x 24; when we rotate a feature (or integral
    image), we may face rounding errors. Because of this, those features are rarely
    used in practice.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用图片右侧显示的特征。它们被旋转了45度。在这种情况下，我们使用倾斜积分。它们可以捕捉到更多的物体细节。倾斜特征的功能在大多数库中都是可用的。但是，有一个问题阻止了它在实际应用中的使用——Haar特征通常应用于图像的低分辨率部分，例如，20
    x 20或24 x 24；当我们旋转一个特征（或积分图像）时，我们可能会遇到舍入误差。正因为如此，这些特征在实践中很少被使用。
- en: 'How can these features help us? Using them, we can describe an object by selecting
    the unique features of it. For example, you see an ordinary female face under
    low resolution in the following images:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特征如何帮助我们呢？使用它们，我们可以通过选择物体的独特特征来描述一个物体。例如，你可以在以下图像中看到低分辨率的普通女性面部：
- en: '![Face detection using Haar-like features](img/image00119.jpeg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![使用Haar-like特征进行面部检测](img/image00119.jpeg)'
- en: Usually, the part with the eyes is darker than the lower part. Furthermore,
    the nose is brighter than the eyes and the brows. We already found two unique
    face features!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，眼睛部分比下部分要暗。此外，鼻子比眼睛和眉毛要亮。我们已经找到了两个独特的面部特征！
- en: For the input image, we use a sliding window to apply those kernels and check
    whether an object in the window is a face or not. We need to do this for all possible
    sizes and locations of kernels, which is practically impossible. Even for a 24
    x 24 window, we need to check more than 160,000 features. Of course, there is
    a solution for this. We need to train a classifier and save only those features
    that are relevant to the detected object, in our case, it is a face. Unfortunately,
    JavaScript libraries do not provide such a functionality. Actually, they do not
    need to do so, since the libraries we use already contain most of necessary classifiers
    for face detection. Besides, the training time can take from several hours to
    months. However, if you need to detect something else or improve the detection
    accuracy, then you will probably want to see other libraries, for example, OpenCV
    ([http://opencv.org](http://opencv.org)). They provide the functionality to train
    your own classifier.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输入图像，我们使用滑动窗口来应用这些核并检查窗口中的物体是否为面部。我们需要对所有可能的核的大小和位置进行检查，这在实际上是不可能的。即使对于24
    x 24的窗口，我们也需要检查超过160,000个特征。当然，有一个解决方案。我们需要训练一个分类器，并只保存与检测到的物体相关的特征，在我们的例子中，它是一个面部。不幸的是，JavaScript库不提供这样的功能。实际上，它们不需要这样做，因为我们使用的库已经包含了大多数必要的面部检测分类器。此外，训练时间可以从几小时到几个月不等。然而，如果你需要检测其他东西或提高检测精度，那么你可能想看看其他库，例如，OpenCV
    ([http://opencv.org](http://opencv.org))。它们提供了训练你自己的分类器的功能。
- en: In short, during the training process, the algorithm checks all possible sizes
    and positions for features and selects the best of them that describe the object.
    After the first step we get several thousands of features. Still, this is too
    much. The next step provides a solution for this problem. We group these features
    into different stages of the classifier. When the algorithm checks the slide window,
    the algorithm evaluates it on each group one-by-one. If the first group fails
    the checking, then we discard that window and move on to another. This whole process
    structure is called a **Cascade of classifiers**. Eventually, the training process
    significantly reduces the number of features that need checking.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，在训练过程中，算法检查所有可能的大小和位置的特征，并选择其中描述对象的最佳特征。在第一步之后，我们得到数千个特征。然而，这仍然太多。下一步提供了这个问题的解决方案。我们将这些特征分组到分类器的不同阶段。当算法检查滑动窗口时，算法会逐个评估每个组。如果第一个组检查失败，那么我们丢弃该窗口并继续到另一个。整个过程结构被称为
    **分类器级联**。最终，训练过程显著减少了需要检查的特征数量。
- en: To make the algorithm scale invariant, it is applied using various window sizes.
    Unfortunately, the algorithm is not rotation invariant. You can try to apply this
    by rotating the source image but in that case, you may face incorrect results.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使算法具有尺度不变性，它使用各种窗口大小应用。不幸的是，该算法不具有旋转不变性。你可以尝试通过旋转源图像来应用它，但在这种情况下，你可能会得到不正确的结果。
- en: 'Now, you have an idea of how the whole algorithm works. Let''s see how we can
    apply it in the JSFeat library by performing the following steps:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你对整个算法的工作原理有了一定的了解。让我们看看我们如何通过以下步骤在 JSFeat 库中应用它：
- en: 'First, we need to define an object which we want to detect. In our case it
    is a face. To set an object, we need to add a JavaScript file:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要定义我们想要检测的对象。在我们的例子中是面部。为了设置对象，我们需要添加一个 JavaScript 文件：
- en: '[PRE0]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, set the classifier in the code. It contains cascades, the original window
    size, and the tilted integral flag, if it is required:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在代码中设置分类器。它包含级联、原始窗口大小和倾斜积分标志，如果需要的话：
- en: '[PRE1]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we get the image data from the context:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们从上下文中获取图像数据：
- en: '[PRE2]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We then define an image and convert it to grayscale:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义一个图像并将其转换为灰度：
- en: '[PRE3]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Sometimes, it is a good choice to increase the image contrast and remove some
    noise, which can be done as follows:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有时，增加图像对比度并移除一些噪声是一个好选择，这可以按以下方式完成：
- en: '[PRE4]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We then predefine arrays for integrals:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先为积分预定义数组：
- en: '[PRE5]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Take a close look at what we do here. We compute the tilted integral only if
    it is set to `true` in the classifier. There is a part that is not required, but
    in some cases, it helps to speed up the computation and remove noisy elements.
    We will check the edges'' density using the Canny edge detector and its integral:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仔细看看我们在这里做了什么。我们只在分类器设置为 `true` 时计算倾斜积分。有一部分是不需要的，但在某些情况下，它有助于加快计算速度并移除噪声元素。我们将使用
    Canny 边缘检测器和其积分来检查边缘密度：
- en: '[PRE6]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If the number of edges in a window is less than the edges'' density. Then the
    program will skip that window without checking the Haar features. You can set
    the density threshold in JSFeat as follows:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果窗口中的边缘数量少于边缘密度。那么程序将跳过该窗口，而不会检查 Haar 特征。你可以在 JSFeat 中设置密度阈值如下：
- en: '[PRE7]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we set the other parameters and call the function:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们设置其他参数并调用函数：
- en: '[PRE8]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If you look into the frontalface.js file, you will see that the original window
    size is 20 x 20 pixels, but we set the `minScale` variable in the preceding code
    block assuming that there will be no face that is smaller than 40x40 pixels. The
    `scaleFactor` variable is the factor for the scale. The process stops when the
    window increases to the image size.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看 frontalface.js 文件，你会看到原始窗口大小是 20 x 20 像素，但我们根据前面的代码块设置了 `minScale` 变量，假设没有小于
    40x40 像素的面。`scaleFactor` 变量是缩放因子的值。当窗口增加到图像大小时，过程停止。
- en: 'The algorithm returns multiple rectangles for each face. Why? Because when
    the algorithm moves the window, the movement can be too small to make a big difference
    to the image. The JSFeat library provides a method to group those rectangles,
    where the last parameter indicates how many neighbors the result should have in
    order to be grouped with another one:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法为每个面部返回多个矩形。为什么？因为当算法移动窗口时，移动可能太小，不足以对图像产生重大影响。JSFeat 库提供了一个方法来分组这些矩形，其中最后一个参数表示结果应该有多少个邻居才能与另一个分组：
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Moreover, the algorithm returns confidence for each detection, and if we want
    to print only the best detections, then we can sort the result array and print
    only the most confident ones:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该算法为每个检测返回置信度，如果我们只想打印最佳检测，那么我们可以对结果数组进行排序，并只打印最自信的检测：
- en: '[PRE10]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After applying this to an image, we get the following result:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 将此应用于图像后，我们得到以下结果：
- en: '![Face detection using Haar-like features](img/image00120.jpeg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![使用Haar-like特征的人脸检测](img/image00120.jpeg)'
- en: On the first image, we painted all rectangles without grouping; see how many
    detections we got for the faces? The different sizes represent different window
    scales. On the second image, we painted the faces after grouping. Already good
    enough, isn't it? And for the last one, we chose the four most confident detections.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一幅图像中，我们没有分组就画了所有矩形；看看我们检测到了多少张脸？不同的尺寸代表不同的窗口尺度。在第二幅图像中，我们在分组后画了脸。已经足够好了，不是吗？而对于最后一幅，我们选择了四个最自信的检测。
- en: As we can see, the algorithm has many interesting parts and it really helps
    to detect faces on photos. There are various implementations of that algorithm.
    In addition, this method has many extensions. We will discuss one of them in the
    next section.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，该算法有许多有趣的组成部分，它确实有助于在照片中检测人脸。该算法有各种实现。此外，这种方法有许多扩展。我们将在下一节讨论其中之一。
- en: Brightness binary features
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亮度二值特征
- en: From the section name, you may conclude that this method works with a change
    in image brightness, probably with its pixels, and that it compares those intensity
    values to receive some sort of a binary check. You are totally right! In some
    ways, it is like getting FAST corners, but the whole idea is a bit more complex.
    Let's discuss it.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从章节名称中，你可以推断出这种方法是通过图像亮度的变化来工作的，可能涉及到像素，并且它将这些强度值进行比较以获得某种二进制检查。你完全正确！在某种程度上，它就像获取FAST角点，但整个想法要复杂得多。让我们来讨论一下。
- en: The main difference between brightness binary features and Haar features is
    that it uses distinct pixels instead of convolutions. Moreover, it uses different
    image pyramids not different sliding window sizes to compute the required features.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 亮度二值特征与Haar特征之间的主要区别在于它使用独立的像素而不是卷积。此外，它使用不同的图像金字塔而不是不同的滑动窗口大小来计算所需特征。
- en: 'You can get an idea from the following image:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从以下图像中获取一些想法：
- en: '![Brightness binary features](img/image00121.jpeg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![亮度二值特征](img/image00121.jpeg)'
- en: We kept the resolution of all three images the same for a better view. But you
    need to keep in mind that the images are 24x24, 12x12, and 6x6 pixels. Besides,
    white and black points represent pixels.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们保留了所有三幅图像的分辨率以获得更好的视觉效果。但你需要记住，这些图像是24x24、12x12和6x6像素。此外，白点和黑点代表像素。
- en: 'Here, the idea is very similar to what you saw while learning the Haar features.
    For example, eyes are much darker than other face particles and because of that,
    we indicate them as dark or black points. The correct instance of an object must
    follow the rules: all white points i and black points j in a window should satisfy
    the expression `I(i) > I(j)`, where `I(position)` is a pixel value of a window
    at this position.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，想法与你在学习Haar特征时看到的是非常相似的。例如，眼睛比其他面部颗粒要暗得多，因此我们将其标记为暗点或黑点。一个对象的正确实例必须遵循以下规则：窗口中的所有白点i和黑点j应满足表达式
    `I(i) > I(j)`，其中 `I(position)` 是窗口在此位置的像素值。
- en: The number of points may vary, it is chosen during the classifier training process.
    The format for the classifier is different from the format of the Haar features.
    The training process is much more complex, since it needs to get various point
    combinations. In case you want to train your own classifier, you may want to follow
    the CCV library ([http://libccv.org/doc/doc-bbf/](http://libccv.org/doc/doc-bbf/)).
    This is a C library that provides implementations of various Computer Vision algorithms.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 点的数量可能会有所不同，它是在分类器训练过程中选择的。分类器的格式与Haar特征的格式不同。训练过程要复杂得多，因为它需要获取各种点组合。如果你想要训练自己的分类器，你可能想要遵循CCV库（[http://libccv.org/doc/doc-bbf/](http://libccv.org/doc/doc-bbf/））。这是一个提供各种计算机视觉算法实现的C库。
- en: 'It is harder to find a BBF algorithm implementation, since it is more complicated
    and the training process is much more difficult. Also, the JSFeat library provides
    the algorithm for the same. First, you need to include the classifier file:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到一个BBF算法的实现比较困难，因为它更复杂，训练过程也更困难。此外，JSFeat库也提供了相同的算法。首先，你需要包含分类器文件：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Then, you need to preallocate some data before the computation starts:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在计算开始之前，你需要预分配一些数据：
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As usual, we work with grayscale images; we get one using the standard JSFeat
    functions:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，我们处理灰度图像；我们使用标准的JSFeat函数来获取一个：
- en: '[PRE13]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'One of the important steps is generating an image pyramid. The input parameters
    are: input image, minimum dimensions of the image in the pyramid, and an interval.
    It sets the number of original scale levels in the pyramid; the larger this number,
    the more pyramid levels you get:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个重要步骤是生成图像金字塔。输入参数包括：输入图像、金字塔中图像的最小尺寸和间隔。它设置了金字塔中原始尺度级别数量；这个数字越大，你得到的金字塔级别就越多：
- en: '[PRE14]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then call the function which takes the image pyramid and the cascade as input
    parameters. After all this, we group the resulting rectangles together:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然后调用一个函数，该函数以图像金字塔和级联作为输入参数。完成所有这些后，我们将生成的矩形分组在一起：
- en: '[PRE15]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here is the result we get with our image:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们使用图像得到的结果：
- en: '![Brightness binary features](img/image00122.jpeg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![亮度二值特征](img/image00122.jpeg)'
- en: For the first part, we took the result without rectangle grouping and for the
    second, with it. As for the Haar features, you may select only the most confident
    results.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一部分，我们没有进行矩形分组就取了结果，对于第二部分，我们进行了分组。至于Haar特征，你可能只想选择最自信的结果。
- en: In the preceding image, we see that the result performed poorly compared to
    the Haar features. It is hard to say why it gives such result. In many cases,
    it highly depends on the implementation or classifier training or maybe just on
    the input image.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图像中，我们看到与Haar特征相比，结果表现不佳。很难说为什么会得到这样的结果。在许多情况下，它高度依赖于实现或分类器训练，或者可能只是输入图像。
- en: We saw two different algorithms, you can select one by your choice. It is probably
    better to stay with the Haar features, since you will find a lot of realizations
    of that algorithm. In contrast, if you want to extend the Computer Vision practical
    boundaries, you may want to tune the BBF implementation or just write your own.
    It is all in your hands!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了两种不同的算法，你可以根据自己的选择选择一个。可能最好坚持使用Haar特征，因为你将找到很多该算法的实现。相比之下，如果你想扩展计算机视觉的实践边界，你可能想要调整BBF实现，或者只是编写你自己的。这完全取决于你！
- en: Tagging people with tracking.js
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用tracking.js标记人员
- en: To see more about Haar-like features and its implementation, we will discuss
    tracking.js library. It provides nearly the same functionality as the JSFeat library.
    What is interesting is that it supplies classifiers for other different objects,
    for example, face particles. Eventually, we will see how to make it possible to
    tag friends.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Haar-like特征及其实现的信息，我们将讨论tracking.js库。它提供了几乎与JSFeat库相同的功能。有趣的是，它为其他不同的对象提供了分类器，例如，面部粒子。最终，我们将看到如何使其能够标记朋友。
- en: Haar features with tracking.js
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Haar特征与tracking.js
- en: 'Tracking.js provides the functionality to detect not only a face, but various
    face particles too. It is very easy to do that. You need to perform the following
    steps:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Tracking.js不仅能够检测面部，还能检测各种面部粒子。这非常容易做到。你需要执行以下步骤：
- en: 'First, you need to add object files for what you want to detect:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，你需要添加你想要检测的对象文件：
- en: '[PRE16]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Next, initialize the `ObjectTracker` function. We did not discuss this in the
    previous chapter, since it is mostly focused on face detection, not just a regular
    object. Anyway, we initialize it with the names of the objects we want to track:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，初始化`ObjectTracker`函数。我们之前没有讨论这个，因为它主要关注的是面部检测，而不仅仅是普通对象。无论如何，我们用我们想要跟踪的对象的名称来初始化它：
- en: '[PRE17]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'There are also custom functions that you can call. One of them is the `setStepSize`
    function, which sets the step size for a sliding window or how it is called in
    the tracking.js library block:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还有你可以调用的自定义函数。其中之一是`setStepSize`函数，它设置滑动窗口的步长或跟踪.js库块中称之为的：
- en: '[PRE18]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We then define the postprocessing function. What we need is to plot our result
    on a canvas:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接着定义后处理函数。我们需要在画布上绘制我们的结果：
- en: '[PRE19]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We also need the `plot` function itself:'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还需要`plot`函数本身：
- en: '[PRE20]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'As we mentioned, there is no functionality to plot different objects with distinct
    colors. For now, you can operate with different objects by creating several different
    trackers at once. Eventually, the last thing you need to do is to call the `track`
    function on a canvas:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们提到的，没有功能可以以不同的颜色绘制不同的对象。目前，你可以通过同时创建几个不同的跟踪器来操作不同的对象。最终，你需要做的最后一件事是在画布上调用`track`函数：
- en: '[PRE21]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'There are various functions that you can use:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种你可以使用的函数：
- en: '`setEdgesDensity`: This is the same as in the JSFeat library, you just set
    a threshold for a sliding window edge''s density. It may significantly improve
    the result; the higher the value, the more edges a window needs to contain to
    be a candidate for an object we want to find.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setEdgesDensity`：这与JSFeat库中的相同，你只需为滑动窗口边缘的密度设置一个阈值。这可能会显著提高结果；值越高，窗口需要包含的边缘越多，才能成为我们想要找到的对象的候选者。'
- en: '`setInitialScale`: This is the initial scale for a sliding window.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setInitialScale`：这是滑动窗口的初始比例。'
- en: '`setScaleFactor`: This is the scale factor for the sliding window.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setScaleFactor`：这是滑动窗口的比例因子。'
- en: Using these functions, you can tune the algorithm a bit to get a better result.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些函数，您可以调整算法以获得更好的结果。
- en: 'We tested the algorithm by applying three detectors one-by-one. For the face,
    eye, and mouth we used red, blue, and green colors, respectively. Here is the
    result:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过逐一应用三个检测器来测试算法。对于面部、眼睛和嘴巴，我们分别使用了红色、蓝色和绿色。以下是结果：
- en: '![Haar features with tracking.js](img/image00123.jpeg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![跟踪.js中的Haar特征](img/image00123.jpeg)'
- en: As you can see, the result for faces is much better than those for face particles.
    This can be due to the bad lighting conditions or poorly trained classifier.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，面部检测结果比面部粒子的结果要好得多。这可能是因为照明条件不佳或分类器训练不当。
- en: Tagging people in photos
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在照片中标记人物
- en: 'Tagging people in photos is a common procedure that you use a lot in social
    networks. If you want to create similar functionality on your website, the JavaScript
    world can offer something for you. Actually, you can do that with any library
    which provides face detection methods, you just need to write some additional
    methods. To simplify the code, we will follow an example from the tracking.js
    library. It is easy to understand and implement:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在照片中标记人物是一个常见的程序，您在社交网络中经常使用它。如果您想在您的网站上创建类似的功能，JavaScript世界可以为您提供一些东西。实际上，您可以使用任何提供面部检测方法的库来完成这项工作，您只需编写一些额外的函数。为了简化代码，我们将遵循tracking.js库的一个示例。它易于理解和实现：
- en: 'First, we need to place our image to the HTML code:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要将我们的图像放置到HTML代码中：
- en: '[PRE22]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here is an array that holds all the names that need to be tagged:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一个包含所有需要标记的名称的数组：
- en: '[PRE23]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, we start from initializing our `ObjectTracker` function with a `face`
    object:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们从初始化`ObjectTracker`函数为一个`face`对象开始：
- en: '[PRE24]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The whole magic goes on in a post processing function:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有的魔法都在后处理函数中发生：
- en: '[PRE25]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Let's review it a bit. First, we sort all rectangles by x coordinates, it will
    be much easier to plot the result when we know the order of detections.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们稍微回顾一下。首先，我们根据x坐标对所有矩形进行排序，当我们知道检测的顺序时，绘制结果会容易得多。
- en: 'Next, we filter our object array and skip all detections in which width is
    less then must be "50" pixels. That will help us to omit background or noisy detections.
    Moreover, we present a new `tag` function, which will tag all detections on a
    photo. See the following code:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们过滤我们的对象数组，跳过所有宽度小于必须为“50”像素的检测。这将帮助我们排除背景或噪声检测。此外，我们提供了一个新的`tag`函数，它将在照片上标记所有检测。请看以下代码：
- en: '[PRE26]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The function creates an `<input>` tag for a name, then takes the first element
    of an array and appends the input element to the `<div>` rectangle.
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 函数为名称创建一个`<input>`标签，然后取数组的第一个元素并将输入元素追加到`<div>`矩形中。
- en: 'The last thing we need to do is to call our tracker on an image:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们最后需要做的是在图像上调用我们的跟踪器：
- en: '[PRE27]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Here is the result:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Tagging people in photos](img/image00124.jpeg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![在照片中标记人物](img/image00124.jpeg)'
- en: As you can see, we have successfully removed the background detection and tagged
    all four people in the correct order.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们已经成功移除了背景检测，并按正确顺序标记了所有四个人。
- en: Head tracking with Camshift
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Camshift进行头部跟踪
- en: Head tracking is another huge topic in the field of Computer Vision. It is very
    useful when you want to create a human computer interface. For example, it is
    usually used in web browser games to move objects or control a 3D interface. There
    are differences between object detection and tracking. First of all, tracking
    works only on videos, since you track an object (not reestimate) a new instance
    in each frame. Consequently, we need to assume that the object we track is the
    same as it was on the previous frame.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 头部跟踪是计算机视觉领域的一个巨大主题。当您想要创建人机界面时，它非常有用。例如，它通常用于网页游戏中的移动对象或控制3D界面。对象检测和跟踪之间有一些区别。首先，跟踪仅在视频中工作，因为您在每个帧中跟踪一个对象（不是重新估计）一个新实例。因此，我们需要假设我们跟踪的对象与上一帧中的相同。
- en: Tracking can be done for multiple objects but here we will focus on a single
    object, in our case, it is a head or more precisely—face. There is a wonderful
    library that can help us to track it. It is called headtrackr ([https://github.com/auduno/headtrackr](https://github.com/auduno/headtrackr)).
    In addition to face tracking, it provides a functionality to create an interface
    that helps to control your browser applications using head motion. We will not
    focus on the motion estimation part here, since the chapter is focused on face
    detection and tracking. But do not worry, we will get to that in the next chapter.
    First, we will see how the tracking algorithm works and then we will focus on
    its practical examples.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 可以对多个对象进行跟踪，但在这里我们将专注于单个对象，在我们的例子中，它是一个头部或更准确地说——面部。有一个很棒的库可以帮助我们跟踪它。它被称为headtrackr
    ([https://github.com/auduno/headtrackr](https://github.com/auduno/headtrackr))。除了面部跟踪外，它还提供了一个功能，可以帮助使用头部运动来控制你的浏览器应用程序。在这里，我们不会关注运动估计部分，因为本章的重点是面部检测和跟踪。但不用担心，我们将在下一章中涉及这一点。首先，我们将看到跟踪算法是如何工作的，然后我们将关注其实际示例。
- en: The idea behind head tracking
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 头部跟踪背后的理念
- en: There are many object tracking algorithms but most of them are not suitable
    for JavaScript and web browsers due to computational complexity. For Haar features,
    it is very difficult to apply them in a rotation-invariant manner because when
    you do that for several skewed images, the algorithm becomes non-real time. The
    headtrackr library tends to solve that problem. It introduces a framework that
    can help you to track a face. Its main focus is creating a human interface, but
    it provides enough flexibility to use it for other tasks as well.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有许多对象跟踪算法，但大多数由于计算复杂度，并不适合JavaScript和网页浏览器。对于Haar特征，以旋转不变的方式应用它们非常困难，因为当你对几个倾斜的图像这样做时，算法就变得不是实时了。headtrackr库倾向于解决这个问题。它引入了一个框架，可以帮助你跟踪面部。它的主要重点是创建一个用户界面，但它提供了足够的灵活性，也可以用于其他任务。
- en: How does the tracking work? Suppose you have found an object on an initial frame,
    for example, using Haar features or another method. We can work with a video file
    or just a webcam. In that case, the difference between neighboring frames will
    not be that huge. These are our core assumptions, let's move on.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪是如何工作的？假设你在初始帧中找到了一个对象，例如，使用Haar特征或另一种方法。我们可以处理一个视频文件或只是一个网络摄像头。在这种情况下，相邻帧之间的差异不会太大。这些都是我们的核心假设，让我们继续前进。
- en: 'We will talk here about objects, not just a face. Let''s assume that our object
    is a group of points and we want to find that group on the next frame. Look at
    the following image:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将讨论对象，而不仅仅是面部。让我们假设我们的对象是一组点，我们想要在下一帧中找到这组点。看看下面的图像：
- en: '![The idea behind head tracking](img/image00125.jpeg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![头部跟踪背后的理念](img/image00125.jpeg)'
- en: The circle (window) **C1** is the location of an object on a previous frame.
    The circle **C2** binds the group of points that we want to find. f we get a sum
    of them in the **C2** circle by adding the *x* and *y* coordinates and dividing
    their sums by the number of points in that circle, we will get point **c_n**,
    which is called **centroid**. After you find the centroid, we move the start circle
    center **c_s** to the new center **c_n**. The algorithm continues the iterating
    process by finding a new centroid until it converges in the end center **c_e**.
    You have found the position of our object on a new frame! This algorithm of finding
    centers of point densities is called **Meanshift**.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 圆形（窗口）**C1**是对象在上一帧中的位置。圆形**C2**绑定我们要找的点组。如果我们通过将它们的*x*和*y*坐标相加，并将它们的和除以该圆中点的数量，在**C2**圆中得到一个总和，我们将得到点**c_n**，这被称为**质心**。在你找到质心后，我们将起始圆心**c_s**移动到新的中心**c_n**。该算法通过找到新的质心继续迭代过程，直到最终收敛到中心**c_e**。你已经在新的帧中找到了我们对象的位置！这种寻找点密度中心的算法被称为**Meanshift**。
- en: 'How can we get the density for the Meanshift algorithm when we use a face?
    The common approach is to generate a skin map, as shown in the following image:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用面部时，如何为Meanshift算法获取密度？常见的方法是生成一个皮肤图，如下面的图像所示：
- en: '![The idea behind head tracking](img/image00126.jpeg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![头部跟踪背后的理念](img/image00126.jpeg)'
- en: In the right-hand side image, each pixel represents the probability of this
    pixel being a skin point. Let's call it a density picture. We get a centroid location
    using these intensity points in a window.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在右侧的图像中，每个像素代表这个像素是皮肤点的概率。让我们称它为密度图。我们使用这些强度点在一个窗口中获取质心位置。
- en: Can you see a problem with the Meanshift approach? We are not changing the size
    of a window. What if an object gets closer or further from the camera? We need
    to adapt the size of an object somehow. This issue was solved by the **CAMshift**
    (**Continuously Adaptive Meanshift**) algorithm. The first stage of the algorithm
    is the Meanshift approach. When we find the window with the highest density, the
    Camshift algorithm updates the window size based on the sum of the intensity values
    in that window. The higher the intensity and the more nonzero points in a window,
    the larger the output size will be. After all, the window converges to the required
    object. Moreover, the algorithm provides computation of a possible head rotation
    using the density picture.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你能看出Meanshift方法的问题吗？我们没有改变窗口的大小。如果一个物体离相机更近或更远呢？我们需要以某种方式调整物体的大小。这个问题是通过**CAMshift**（**连续自适应Meanshift**）算法解决的。算法的第一个阶段是Meanshift方法。当我们找到具有最高密度的窗口时，Camshift算法会根据该窗口中强度值的总和更新窗口大小。强度越高，窗口中的非零点越多，输出的大小就越大。毕竟，窗口会收敛到所需的目标。此外，该算法还提供了使用密度图计算可能头部旋转的功能。
- en: 'See the following image:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 看看下面的图片：
- en: '![The idea behind head tracking](img/image00127.jpeg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![头部跟踪背后的理念](img/image00127.jpeg)'
- en: The first one shows the original rectangle (the smaller one) and the final detection
    by Camshift. The right-hand side image shows the result after the rectangle angle
    calculation.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个显示了原始矩形（较小的那个）和Camshift的最终检测。右侧的图像显示了矩形角度计算后的结果。
- en: 'The headtrackr library can initialize the Meanshift algorithm in two ways:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: headtrackr库可以通过两种方式初始化Meanshift算法：
- en: The user manually selects an object on a video and the tracking is done using
    the user input
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户手动在视频中选取一个物体，并使用用户输入进行跟踪。
- en: The algorithm can use Haar features to detect the face to be tracked
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该算法可以使用Haar特征来检测要跟踪的面部。
- en: We will see an example with the second approach, when a face is detected automatically
    for the first frame using Haar features, and for the other frames, the library
    uses the Camshift approach.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到一个示例，使用第二种方法，当使用Haar特征自动检测第一帧中的面部时，对于其他帧，库使用Camshift方法。
- en: The head tracking application
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 头部跟踪应用程序
- en: 'It is relatively easy to use the headtrackr library. It provides a flexible
    way to create a head tracking application. We will discuss the APIs and opportunities
    it provides:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用headtrackr库相对容易。它提供了一种灵活的方式来创建头部跟踪应用程序。我们将讨论它提供的API和机会：
- en: 'The first thing we need to do is to add a headtrackr script. The Haar detector
    is already included there:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是添加一个headtrackr脚本。Haar检测器已经包含在其中：
- en: '[PRE28]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next, we need to define HTML inputs so that we can easily display the content:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要定义HTML输入，这样我们就可以轻松显示内容：
- en: '[PRE29]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The first one will hold the data required for the library. The video file will
    hold the video. The other two tags are optional, the third one provides a canvas
    to draw the tracking result rectangle on it. The last is used to display the density
    image.
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一个将包含库所需的数据。视频文件将包含视频。其他两个标签是可选的，第三个提供了一个画布，可以在其上绘制跟踪结果的矩形。最后一个用于显示密度图像。
- en: 'If you want, you can add a tag for the headtrackr output text, which will display
    various messages during the working process, so you can understand the stage at
    which the tracker is:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想，你可以为headtrackr输出文本添加一个标签，在工作过程中会显示各种消息，这样你就可以了解跟踪器所处的阶段：
- en: '[PRE30]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'After that, we need to get all the necessary data on the JavaScript side:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们需要在JavaScript端获取所有必要的数据：
- en: '[PRE31]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The canvas should be above the video, so we set its style to be so.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 画布应该在视频上方，所以我们将其样式设置为如此。
- en: 'Next, you need to initialize tracker parameters:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你需要初始化跟踪器参数：
- en: '[PRE32]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: There are a lot of parameters, we will focus on those which are useful in this
    example. By default, the headtrackr library works with a web camera. If you do
    not have one or your browser does not support it, you can provide a video file
    using the `altVideo` parameter. To calculate the head angle, we use the `calcAngles`
    variable, which is `false` by default. The `ui` parameter sets debugging messages
    for a tag with the `headtrackerMessage` id. For a density image, we need to set
    the `debug` parameter.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有很多参数，我们将关注在这个例子中有用的那些。默认情况下，headtrackr库与网络摄像头一起工作。如果你没有或者你的浏览器不支持，你可以使用`altVideo`参数提供一个视频文件。为了计算头部角度，我们使用`calcAngles`变量，默认值为`false`。`ui`参数为具有`headtrackerMessage`
    id的标签设置调试消息。对于密度图像，我们需要设置`debug`参数。
- en: 'Next, we init the tracker with a video and canvas inputs. Then, we start the
    tracker:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用视频和画布输入初始化跟踪器。然后，我们开始跟踪：
- en: '[PRE33]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'To stop the tracking process, you can use the `stop` function. In that case,
    the library will reinitiate the whole process:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要停止跟踪过程，你可以使用`stop`函数。在这种情况下，库将重新启动整个过程：
- en: '[PRE34]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To display the result using overlay, we need to add a listener to the `facetrackingEvent`.
    Besides, you can see how we get the rotated version of a rectangle:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要使用叠加显示结果，我们需要向`facetrackingEvent`添加一个监听器。此外，你还可以看到我们如何获取矩形的旋转版本：
- en: '[PRE35]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The result includes a video with the overlay over it and the debug information
    on the right:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 结果包括一个带有叠加的视频和右侧的调试信息：
- en: '![The head tracking application](img/image00128.jpeg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![头部跟踪应用](img/image00128.jpeg)'
- en: As you can see, there is nothing difficult in applying the head tracking with
    that library. To use the library in a proper manner, you just need to know some
    parts of the algorithm.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，使用该库应用头部跟踪并没有什么困难。要正确使用库，你只需要了解算法的一些部分。
- en: Summary
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: A face is a really complex object. To detect and track it, you need to use a
    new level of algorithms. Fortunately, the JavaScript libraries provide such an
    opportunity through Haar, Brightness Binary features, Meanshift, and Camshift
    algorithms. All of them have their own area of usage. You can apply these wonderful
    methods in different programs, for example, people tagging. We discussed them
    and provided examples which you can start using right away. In addition to face
    detection, there is a potential to detect other objects such as face particles.
    Of course, the detection quality may vary significantly and you should be careful
    when you use other classifiers.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一张脸是一个非常复杂的目标。为了检测和跟踪它，你需要使用新的算法级别。幸运的是，JavaScript库通过Haar、亮度二值化特征、Meanshift和Camshift算法提供了这样的机会。它们各自都有其应用领域。你可以在不同的程序中应用这些奇妙的方法，例如，人物标记。我们已经讨论了它们，并提供了你可以立即开始使用的示例。除了人脸检测，还有潜力检测其他对象，如人脸粒子。当然，检测质量可能会有很大差异，当你使用其他分类器时应该小心。
- en: In this chapter, we already touched on the tracking applications a bit and discussed
    how the tracking can help to create a human interface. In the next chapter, we
    will learn how to control your browser with motion and how the object tracking
    can be used in those applications.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经简要介绍了跟踪应用，并讨论了跟踪如何帮助创建人机界面。在下一章中，我们将学习如何通过动作控制浏览器，以及如何在这些应用中使用对象跟踪。
