- en: '*Chapter 2*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*ç¬¬äºŒç« *'
- en: Exploratory Data Analysis and Visualization
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¢ç´¢æ€§æ•°æ®åˆ†æä¸å¯è§†åŒ–
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å­¦ä¹ ç›®æ ‡
- en: 'By the end of the chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°æœ¬ç« ç»“æŸæ—¶ï¼Œä½ å°†èƒ½å¤Ÿï¼š
- en: Explain the importance of data exploration and communicate the summary statistics
    of a dataset
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è§£é‡Šæ•°æ®æ¢ç´¢çš„é‡è¦æ€§å¹¶ä¼ è¾¾æ•°æ®é›†çš„æ€»ç»“æ€§ç»Ÿè®¡ä¿¡æ¯
- en: Visualize patterns in missing values in data and be able to replace null values
    appropriately
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–æ•°æ®ä¸­ç¼ºå¤±å€¼çš„æ¨¡å¼ï¼Œå¹¶èƒ½å¤Ÿé€‚å½“æ›¿æ¢ç©ºå€¼
- en: Identify continuous features and categorical features
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯†åˆ«è¿ç»­ç‰¹å¾å’Œç±»åˆ«ç‰¹å¾
- en: Visualize distributions of values across individual variables
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–å•ä¸ªå˜é‡å€¼çš„åˆ†å¸ƒ
- en: Describe and analyze relationships between different types of variables using
    correlation and visualizations
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç›¸å…³æ€§å’Œå¯è§†åŒ–åˆ†ææè¿°ä¸åŒç±»å‹å˜é‡ä¹‹é—´çš„å…³ç³»
- en: This chapter takes us through how to perform exploration and analysis on a new
    dataset.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« å°†å¸¦é¢†æˆ‘ä»¬è¿›è¡Œå¯¹æ–°æ•°æ®é›†çš„æ¢ç´¢ä¸åˆ†æã€‚
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»‹ç»
- en: Say we have a problem statement that involves predicting whether a particular
    earthquake caused a tsunami or not. How do we decide what model to use? What do
    we know about the data we have? Nothing! But if we don't know and understand our
    data, chances are we'll end up building a model that's not very interpretable
    or reliable.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªé—®é¢˜é™ˆè¿°ï¼Œæ¶‰åŠé¢„æµ‹æŸæ¬¡åœ°éœ‡æ˜¯å¦å¼•å‘äº†æµ·å•¸ã€‚æˆ‘ä»¬å¦‚ä½•å†³å®šä½¿ç”¨ä»€ä¹ˆæ¨¡å‹ï¼Ÿæˆ‘ä»¬çŸ¥é“æˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®æ˜¯ä»€ä¹ˆå—ï¼Ÿä»€ä¹ˆéƒ½ä¸çŸ¥é“ï¼ä½†å¦‚æœæˆ‘ä»¬ä¸äº†è§£æ•°æ®ï¼Œæœ€ç»ˆå¯èƒ½ä¼šæ„å»ºä¸€ä¸ªæ—¢éš¾ä»¥è§£é‡Šåˆä¸å¯é çš„æ¨¡å‹ã€‚
- en: When it comes to data science, it's important to have a thorough understanding
    of the data we're dealing with, in order to generate features that are highly
    informative and, consequently, to build accurate and powerful models.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•°æ®ç§‘å­¦ä¸­ï¼Œæ·±å…¥ç†è§£æˆ‘ä»¬å¤„ç†çš„æ•°æ®éå¸¸é‡è¦ï¼Œè¿™æ ·å¯ä»¥ç”Ÿæˆé«˜åº¦ä¿¡æ¯é‡çš„ç‰¹å¾ï¼Œä»è€Œæ„å»ºå‡†ç¡®ä¸”å¼ºå¤§çš„æ¨¡å‹ã€‚
- en: In order to gain this understanding, we perform an exploratory analysis on the
    data to see what the data can tell us about the relationships between the features
    and the target variable. Getting to know our data will even help us interpret
    the model we build and identify ways we can improve its accuracy.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è·å¾—è¿™ç§ç†è§£ï¼Œæˆ‘ä»¬å¯¹æ•°æ®è¿›è¡Œæ¢ç´¢æ€§åˆ†æï¼Œçœ‹çœ‹æ•°æ®èƒ½å‘Šè¯‰æˆ‘ä»¬ç‰¹å¾ä¸ç›®æ ‡å˜é‡ä¹‹é—´çš„å…³ç³»ã€‚äº†è§£æ•°æ®ç”šè‡³æœ‰åŠ©äºæˆ‘ä»¬è§£é‡Šæ„å»ºçš„æ¨¡å‹ï¼Œå¹¶æ‰¾å‡ºæ”¹å–„å…¶å‡†ç¡®æ€§çš„æ–¹æ³•ã€‚
- en: The approach we take to achieve this is to allow the data to reveal its structure
    or model, which helps gain some new, often unsuspected, insight into the data.
    Let's learn more about this approach.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å®ç°è¿™ä¸€ç›®æ ‡çš„æ–¹æ³•æ˜¯è®©æ•°æ®æ­ç¤ºå…¶ç»“æ„æˆ–æ¨¡å‹ï¼Œè¿™æœ‰åŠ©äºæˆ‘ä»¬è·å¾—ä¸€äº›æ–°çš„ã€å¸¸å¸¸æ˜¯æ„æƒ³ä¸åˆ°çš„æ•°æ®æ´å¯Ÿã€‚è®©æˆ‘ä»¬æ·±å…¥äº†è§£è¿™ç§æ–¹æ³•ã€‚
- en: Exploratory Data Analysis (EDA)
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰
- en: '**Exploratory data analysis** (**EDA**) is defined as an approach to analyzing
    datasets to summarize their main characteristics, often with visual methods.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¢ç´¢æ€§æ•°æ®åˆ†æ**ï¼ˆ**EDA**ï¼‰è¢«å®šä¹‰ä¸ºä¸€ç§åˆ†ææ•°æ®é›†çš„æ–¹æ³•ï¼Œæ—¨åœ¨æ€»ç»“å…¶ä¸»è¦ç‰¹å¾ï¼Œé€šå¸¸é‡‡ç”¨å¯è§†åŒ–æ–¹æ³•ã€‚'
- en: 'The purpose of EDA is to:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: EDAçš„ç›®çš„ï¼š
- en: Discover patterns within a dataset
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘ç°æ•°æ®é›†ä¸­çš„æ¨¡å¼
- en: Spot anomalies
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘ç°å¼‚å¸¸
- en: Form hypotheses about the behavior of data
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹æ•°æ®çš„è¡Œä¸ºå½¢æˆå‡è®¾
- en: Validate assumptions
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éªŒè¯å‡è®¾
- en: Everything from basic summary statistics to complex visualizations help us gain
    an intuitive understanding of the data itself, which is highly important when
    it comes to forming new hypotheses about the data and uncovering what parameters
    affect the target variable. Often, discovering how the target variable varies
    across a single feature gives us an indication of how important a feature might
    be, and a variation across a combination of several features helps us come up
    with ideas for new informative features to engineer.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä»åŸºç¡€çš„æ€»ç»“æ€§ç»Ÿè®¡æ•°æ®åˆ°å¤æ‚çš„å¯è§†åŒ–å›¾å½¢ï¼Œéƒ½å¸®åŠ©æˆ‘ä»¬å¯¹æ•°æ®æœ¬èº«å½¢æˆç›´è§‚çš„ç†è§£ï¼Œè¿™åœ¨å½¢æˆæ–°çš„å‡è®¾å’Œæ­ç¤ºå“ªäº›å‚æ•°å½±å“ç›®æ ‡å˜é‡æ—¶éå¸¸é‡è¦ã€‚é€šå¸¸ï¼Œé€šè¿‡å‘ç°ç›®æ ‡å˜é‡å¦‚ä½•éšå•ä¸€ç‰¹å¾çš„å˜åŒ–è€Œå˜åŒ–ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬åˆ¤æ–­æŸä¸ªç‰¹å¾çš„é‡è¦æ€§ï¼Œè€Œå¤šä¸ªç‰¹å¾ç»„åˆçš„å˜åŒ–åˆ™å¸®åŠ©æˆ‘ä»¬æ„æ€æ–°çš„æœ‰ç”¨ç‰¹å¾ã€‚
- en: Most exploration and visualization is intended to understand the relationship
    between the features and the target variable. This is because we want to find
    out what relationships exist (or don't exist) between the data we have and the
    values we want to predict.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°æ¢ç´¢å’Œå¯è§†åŒ–çš„ç›®çš„æ˜¯ç†è§£ç‰¹å¾ä¸ç›®æ ‡å˜é‡ä¹‹é—´çš„å…³ç³»ã€‚å› ä¸ºæˆ‘ä»¬æƒ³è¦æ‰¾å‡ºæˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®å’Œæˆ‘ä»¬æƒ³è¦é¢„æµ‹çš„å€¼ä¹‹é—´å­˜åœ¨å“ªäº›ï¼ˆæˆ–ä¸å­˜åœ¨çš„ï¼‰å…³ç³»ã€‚
- en: A very basic domain knowledge is usually necessary to be able to understand
    both the problem statement itself as well as what the data is telling us. In this
    chapter, we'll look at the ways we can get to know more about the data we have
    by analyzing the features we have.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›éå¸¸åŸºæœ¬çš„é¢†åŸŸçŸ¥è¯†é€šå¸¸æ˜¯å¿…è¦çš„ï¼Œä»¥ä¾¿èƒ½å¤Ÿç†è§£é—®é¢˜é™ˆè¿°æœ¬èº«ä»¥åŠæ•°æ®æ‰€ä¼ è¾¾çš„ä¿¡æ¯ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢ç´¢é€šè¿‡åˆ†ææˆ‘ä»¬æ‹¥æœ‰çš„ç‰¹å¾ï¼Œäº†è§£æ›´å¤šå…³äºæ•°æ®çš„æ–¹å¼ã€‚
- en: 'EDA can tell us about:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: EDA å¯ä»¥å‘Šè¯‰æˆ‘ä»¬ï¼š
- en: Features that are unclean, have missing values, or have outliers
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸å¹²å‡€ã€ç¼ºå¤±å€¼æˆ–å­˜åœ¨å¼‚å¸¸å€¼çš„ç‰¹å¾
- en: Features that are informative and are a good indicator of the target
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…·æœ‰ä¿¡æ¯ä»·å€¼å¹¶ä¸”æ˜¯ç›®æ ‡çš„è‰¯å¥½æŒ‡ç¤ºå™¨çš„ç‰¹å¾
- en: The kind of relationships features have with the target
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹å¾ä¸ç›®æ ‡ä¹‹é—´çš„å…³ç³»ç±»å‹
- en: Further features that the data might need that we don't already have
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®å¯èƒ½éœ€è¦çš„å…¶ä»–ç‰¹å¾ï¼Œè€Œè¿™äº›ç‰¹å¾æˆ‘ä»¬ç°åœ¨è¿˜æ²¡æœ‰
- en: Edge cases you might need to account for separately
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½éœ€è¦å•ç‹¬å¤„ç†çš„è¾¹ç¼˜æƒ…å†µ
- en: Filters you might need to apply on the dataset
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½éœ€è¦åœ¨æ•°æ®é›†ä¸Šåº”ç”¨çš„è¿‡æ»¤å™¨
- en: The presence of incorrect or fake data points
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é”™è¯¯æˆ–è™šå‡çš„æ•°æ®ç‚¹çš„å­˜åœ¨
- en: Now that we've looked at why EDA is important and what it can tell us, let's
    talk about what exactly EDA involves. EDA can involve anything from looking at
    basic summary statistics to visualizing complex trends over multiple variables.
    However, even simple statistics and plots can be powerful tools, as they may reveal
    important facts about the data that could change our modeling perspective. When
    we see plots representing data, we are able to easily detect trends and patterns,
    compared to just raw data and numbers. These visualizations further allow us to
    ask questions such as "How?" and "Why?", and form hypotheses about the dataset
    that can be validated by further visualizations. This is a continuous process
    that leads to a deeper understanding of the data. This chapter will introduce
    you to some of the basic tools that can be used to explore any dataset while keeping
    in mind the ultimate problem statement.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»äº†è§£äº†ä¸ºä»€ä¹ˆ EDA å¾ˆé‡è¦ä»¥åŠå®ƒèƒ½å‘Šè¯‰æˆ‘ä»¬ä»€ä¹ˆï¼Œæ¥ä¸‹æ¥è®©æˆ‘ä»¬è®¨è®ºä¸€ä¸‹ EDA å…·ä½“åŒ…æ‹¬ä»€ä¹ˆå†…å®¹ã€‚EDA å¯ä»¥åŒ…æ‹¬ä»æŸ¥çœ‹åŸºæœ¬çš„æ‘˜è¦ç»Ÿè®¡åˆ°å¯è§†åŒ–å¤šä¸ªå˜é‡ä¹‹é—´å¤æ‚è¶‹åŠ¿çš„ä»»ä½•æ“ä½œã€‚ç„¶è€Œï¼Œå³ä½¿æ˜¯ç®€å•çš„ç»Ÿè®¡æ•°æ®å’Œå›¾è¡¨ä¹Ÿå¯ä»¥æ˜¯å¼ºå¤§çš„å·¥å…·ï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½æ­ç¤ºå‡ºæ•°æ®ä¸­çš„é‡è¦äº‹å®ï¼Œè¿™äº›äº‹å®å¯èƒ½ä¼šæ”¹å˜æˆ‘ä»¬å»ºæ¨¡çš„è§†è§’ã€‚å½“æˆ‘ä»¬çœ‹åˆ°è¡¨ç¤ºæ•°æ®çš„å›¾è¡¨æ—¶ï¼Œæˆ‘ä»¬èƒ½å¤Ÿè½»æ¾åœ°æ£€æµ‹åˆ°è¶‹åŠ¿å’Œæ¨¡å¼ï¼Œç›¸æ¯”äºä»…ä»…å¤„ç†åŸå§‹æ•°æ®å’Œæ•°å­—ã€‚è¿™äº›å¯è§†åŒ–è¿›ä¸€æ­¥è®©æˆ‘ä»¬èƒ½å¤Ÿæå‡ºç±»ä¼¼â€œå¦‚ä½•ï¼Ÿâ€å’Œâ€œä¸ºä»€ä¹ˆï¼Ÿâ€çš„é—®é¢˜ï¼Œå¹¶å¯¹æ•°æ®é›†å½¢æˆå‡è®¾ï¼Œè¿™äº›å‡è®¾å¯ä»¥é€šè¿‡è¿›ä¸€æ­¥çš„å¯è§†åŒ–æ¥éªŒè¯ã€‚è¿™æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œèƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬æ›´æ·±å…¥åœ°ç†è§£æ•°æ®ã€‚æœ¬ç« å°†å‘ä½ ä»‹ç»ä¸€äº›å¯ä»¥ç”¨æ¥æ¢ç´¢ä»»ä½•æ•°æ®é›†çš„åŸºæœ¬å·¥å…·ï¼ŒåŒæ—¶ç‰¢è®°æœ€ç»ˆçš„é—®é¢˜é™ˆè¿°ã€‚
- en: We'll start by walking through some basic summary statistics and how to interpret
    them, followed by a section on finding, analyzing, and dealing with missing values.
    Then we'll look at univariate relationships, that is, distributions and the behavior
    of individual variables. This will be followed by the final section on exploring
    relationships between variables. In this chapter, you will be introduced to types
    of plots that can be used to gain a basic overview of the dataset and its features,
    as well as how to gain insights by creating visualizations that combine several
    features, and we'll then work through some examples on how they can be used.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä»ä¸€äº›åŸºæœ¬çš„æ‘˜è¦ç»Ÿè®¡é‡å¼€å§‹ï¼Œä»‹ç»å¦‚ä½•è§£è¯»å®ƒä»¬ï¼Œæ¥ç€æ˜¯å…³äºæŸ¥æ‰¾ã€åˆ†æå’Œå¤„ç†ç¼ºå¤±å€¼çš„éƒ¨åˆ†ã€‚ç„¶åæˆ‘ä»¬å°†ç ”ç©¶å•å˜é‡å…³ç³»ï¼Œå³å•ä¸ªå˜é‡çš„åˆ†å¸ƒå’Œè¡Œä¸ºã€‚æœ€åï¼Œæˆ‘ä»¬ä¼šæ¢è®¨å˜é‡ä¹‹é—´å…³ç³»çš„æ¢ç´¢éƒ¨åˆ†ã€‚æœ¬ç« å°†å‘ä½ ä»‹ç»å¯ä»¥ç”¨æ¥è·å¾—æ•°æ®é›†åŠå…¶ç‰¹å¾åŸºæœ¬æ¦‚è§ˆçš„å›¾è¡¨ç±»å‹ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡åˆ›å»ºç»“åˆå¤šä¸ªç‰¹å¾çš„å¯è§†åŒ–æ¥è·å¾—è§è§£ï¼Œæˆ‘ä»¬è¿˜å°†é€šè¿‡ä¸€äº›ç¤ºä¾‹å±•ç¤ºå®ƒä»¬å¦‚ä½•ä½¿ç”¨ã€‚
- en: 'The dataset that we will use for our exploratory analysis and visualizations
    has been taken from the *Significant Earthquake Database* from NOAA, available
    as a public dataset on Google BigQuery (`table ID: ''bigquery-public-data.noaa_significant_earthquakes.earthquakes''`).
    We will be using a subset of the columns available, the metadata for which is
    available at [https://console.cloud.google.com/bigquery?project=packt-data&folder&organizationId&p=bigquery-public-data&d=noaa_significant_earthquakes&t=earthquakes&page=table](https://console.cloud.google.com/bigquery?project=packt-data&folder&organizationId&p=bigquery-public-data&d=noaa_significant_earthquakes&t=earthquakes&page=table),
    and loading it into a pandas DataFrame to perform the exploration. We''ll primarily
    be using Matplotlib for most of our visualizations, along with Seaborn and Missingno
    for some. It is to be noted, however, that Seaborn merely provides a wrapper over
    Matplotlib''s functionalities, so anything that is plotted using Seaborn can also
    be plotted using Matplotlib. We''ll try to keep things interesting by mixing up
    visualizations from both libraries.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ç”¨äºæ¢ç´¢æ€§åˆ†æå’Œå¯è§†åŒ–çš„æ•°æ®é›†æ¥è‡ªNOAAçš„*é‡å¤§åœ°éœ‡æ•°æ®åº“*ï¼Œè¯¥æ•°æ®é›†ä½œä¸ºå…¬å…±æ•°æ®é›†å¯åœ¨Google BigQueryä¸Šè·å–ï¼ˆ`è¡¨IDï¼š'bigquery-public-data.noaa_significant_earthquakes.earthquakes'`ï¼‰ã€‚æˆ‘ä»¬å°†ä½¿ç”¨å…¶ä¸­éƒ¨åˆ†åˆ—ï¼Œç›¸å…³å…ƒæ•°æ®å¯ä»¥åœ¨[https://console.cloud.google.com/bigquery?project=packt-data&folder&organizationId&p=bigquery-public-data&d=noaa_significant_earthquakes&t=earthquakes&page=table](https://console.cloud.google.com/bigquery?project=packt-data&folder&organizationId&p=bigquery-public-data&d=noaa_significant_earthquakes&t=earthquakes&page=table)æŸ¥çœ‹ï¼Œå¹¶å°†å…¶åŠ è½½åˆ°pandas
    DataFrameä¸­ä»¥è¿›è¡Œæ¢ç´¢ã€‚æˆ‘ä»¬ä¸»è¦ä½¿ç”¨Matplotlibæ¥è¿›è¡Œå¤§å¤šæ•°å¯è§†åŒ–ï¼ŒåŒæ—¶ä¹Ÿä¼šä½¿ç”¨Seabornå’ŒMissingnoè¿›è¡Œéƒ¨åˆ†å¯è§†åŒ–ã€‚ç„¶è€Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒSeabornåªæ˜¯å¯¹MatplotlibåŠŸèƒ½çš„å°è£…ï¼Œå› æ­¤ä»»ä½•ä½¿ç”¨Seabornç»˜åˆ¶çš„å›¾è¡¨éƒ½å¯ä»¥ä½¿ç”¨Matplotlibç»˜åˆ¶ã€‚æˆ‘ä»¬ä¼šé€šè¿‡æ··åˆä½¿ç”¨ä¸¤ä¸ªåº“çš„å¯è§†åŒ–æ–¹å¼ï¼Œæ¥ä¿æŒäº‹æƒ…çš„è¶£å‘³æ€§ã€‚
- en: 'The exploration and analysis will be conducted keeping in mind a sample problem
    statement: *Given the data we have, we want to predict whether an earthquake caused
    a tsunami or not*. This will be a classification problem (more on this in *Chapter
    4*, *Classification*) where the target variable is the `flag_tsunami` column.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢ç´¢å’Œåˆ†æå°†ä»¥ä¸€ä¸ªç¤ºä¾‹é—®é¢˜ä¸ºåŸºç¡€è¿›è¡Œï¼š*ç»™å®šæˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®ï¼Œæˆ‘ä»¬å¸Œæœ›é¢„æµ‹åœ°éœ‡æ˜¯å¦å¼•å‘äº†æµ·å•¸*ã€‚è¿™å°†æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ï¼ˆæ›´å¤šå†…å®¹è¯·è§*ç¬¬4ç« *ï¼Œ*åˆ†ç±»*ï¼‰ï¼Œå…¶ä¸­ç›®æ ‡å˜é‡æ˜¯`flag_tsunami`åˆ—ã€‚
- en: 'Exercise 10: Importing Libraries for Data Exploration'
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  10ï¼šå¯¼å…¥æ•°æ®æ¢ç´¢æ‰€éœ€çš„åº“
- en: 'Before we begin, let''s first import the required libraries, which we will
    be using for most of our data manipulations and visualizations:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬å¼€å§‹ä¹‹å‰ï¼Œé¦–å…ˆå¯¼å…¥æˆ‘ä»¬å°†ç”¨äºå¤§å¤šæ•°æ•°æ®æ“ä½œå’Œå¯è§†åŒ–çš„å¿…è¦åº“ï¼š
- en: 'In a Jupyter notebook, import the following libraries:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨Jupyter Notebookä¸­ï¼Œå¯¼å…¥ä»¥ä¸‹åº“ï¼š
- en: '[PRE0]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `%matplotlib inline` command allows Jupyter to display the plots inline
    within the notebook itself.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`%matplotlib inline`å‘½ä»¤å…è®¸Jupyteråœ¨Notebookä¸­ç›´æ¥æ˜¾ç¤ºå›¾è¡¨ã€‚'
- en: 'We can also read in the metadata containing the data types for each column,
    which are stored in the form of a JSON file. Do this using the following command.
    This command opens the file in readable format and uses the `json` library to
    read the file into a dictionary:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å¯ä»¥è¯»å–åŒ…å«æ¯åˆ—æ•°æ®ç±»å‹çš„å…ƒæ•°æ®ï¼Œè¿™äº›æ•°æ®ç±»å‹ä»¥JSONæ–‡ä»¶çš„å½¢å¼å­˜å‚¨ã€‚å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®Œæˆæ­¤æ“ä½œã€‚è¯¥å‘½ä»¤å°†ä»¥å¯è¯»æ ¼å¼æ‰“å¼€æ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨`json`åº“å°†æ–‡ä»¶è¯»å…¥å­—å…¸ï¼š
- en: '[PRE1]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now, let's get started.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ã€‚
- en: Summary Statistics and Central Values
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ±‡æ€»ç»Ÿè®¡ä¸ä¸­å¿ƒå€¼
- en: In order to find out what our data really looks like, we use a technique known
    as **data profiling**. This is defined as the process of examining the data available
    from an existing information source (for example, a database or a file) and collecting
    statistics or informative summaries about that data. The goal is to make sure
    that you understand your data well and are able to identify any challenges that
    the data may pose early on in the project, which is done by summarizing the dataset
    and assessing its structure, content, and quality.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†äº†è§£æˆ‘ä»¬çš„æ•°æ®åˆ°åº•æ˜¯ä»€ä¹ˆæ ·å­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç§å«åš**æ•°æ®åˆ†æ**çš„æŠ€æœ¯ã€‚æ•°æ®åˆ†æè¢«å®šä¹‰ä¸ºæ£€æŸ¥ç°æœ‰ä¿¡æ¯æºï¼ˆä¾‹å¦‚æ•°æ®åº“æˆ–æ–‡ä»¶ï¼‰ä¸­çš„æ•°æ®ï¼Œå¹¶æ”¶é›†å…³äºè¯¥æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯æˆ–ä¿¡æ¯æ‘˜è¦çš„è¿‡ç¨‹ã€‚ç›®æ ‡æ˜¯ç¡®ä¿ä½ å……åˆ†ç†è§£ä½ çš„æ•°æ®ï¼Œå¹¶èƒ½å¤Ÿå°½æ—©è¯†åˆ«æ•°æ®å¯èƒ½å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œè¿™é€šè¿‡æ€»ç»“æ•°æ®é›†å¹¶è¯„ä¼°å…¶ç»“æ„ã€å†…å®¹å’Œè´¨é‡æ¥å®ç°ã€‚
- en: 'Data profiling includes collecting descriptive statistics and data types. Here
    are a few commands that are commonly used to get a summary of a dataset:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®åˆ†æåŒ…æ‹¬æ”¶é›†æè¿°æ€§ç»Ÿè®¡å’Œæ•°æ®ç±»å‹ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸ç”¨çš„å‘½ä»¤ï¼Œå¯ä»¥ç”¨æ¥è·å–æ•°æ®é›†çš„æ€»ç»“ä¿¡æ¯ï¼š
- en: '`data.info()`: This command tells us how many non-null values there are there
    in each column, along with the data type of the values (non-numeric types are
    represented as `object` types).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data.info()`ï¼šæ­¤å‘½ä»¤å‘Šè¯‰æˆ‘ä»¬æ¯åˆ—ä¸­æœ‰å¤šå°‘éç©ºå€¼ï¼Œå¹¶æ˜¾ç¤ºæ¯åˆ—å€¼çš„æ•°æ®ç±»å‹ï¼ˆéæ•°å€¼ç±»å‹ä»¥ `object` ç±»å‹è¡¨ç¤ºï¼‰ã€‚'
- en: '`data.describe()`: This gives us basic summary statistics for all the numerical
    columns in the DataFrame, such as the count of non-null values, minimum and maximum,
    the mean and standard deviation, and the quarter-wise percentiles for all numerical
    features. If there are any string-type features, it does not include a summary
    of those.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data.describe()`ï¼šè¯¥å‘½ä»¤ä¸º DataFrame ä¸­æ‰€æœ‰æ•°å€¼åˆ—æä¾›åŸºæœ¬çš„æ€»ç»“ç»Ÿè®¡æ•°æ®ï¼Œä¾‹å¦‚éç©ºå€¼çš„è®¡æ•°ã€æœ€å°å€¼å’Œæœ€å¤§å€¼ã€å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä»¥åŠæ‰€æœ‰æ•°å€¼ç‰¹å¾çš„å››åˆ†ä½æ•°ç™¾åˆ†ä½æ•°ã€‚å¦‚æœæœ‰ä»»ä½•å­—ç¬¦ä¸²ç±»å‹çš„ç‰¹å¾ï¼Œåˆ™ä¸åŒ…æ‹¬è¿™äº›ç‰¹å¾çš„æ€»ç»“ã€‚'
- en: '`data.head()` and `data.tail()`: These commands display the first five and
    last five rows of the DataFrame respectively. While the previous commands give
    us a general idea of the dataset, it is a good idea to get a closer look at the
    actual data itself, which can be done using these commands.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data.head()` å’Œ `data.tail()`ï¼šè¿™ä¸¤ä¸ªå‘½ä»¤åˆ†åˆ«æ˜¾ç¤º DataFrame çš„å‰äº”è¡Œå’Œåäº”è¡Œæ•°æ®ã€‚è™½ç„¶å‰é¢çš„å‘½ä»¤å¯ä»¥ç»™æˆ‘ä»¬ä¸€ä¸ªæ•°æ®é›†çš„æ€»ä½“æ¦‚è§ˆï¼Œä½†æ›´æ·±å…¥åœ°äº†è§£å®é™…æ•°æ®æœ¬èº«æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œå¯ä»¥ä½¿ç”¨è¿™äº›å‘½ä»¤æ¥å®Œæˆã€‚'
- en: Standard Deviation
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ ‡å‡†å·®
- en: The standard deviation represents how widespread the distribution of the values
    of *x* are.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡å‡†å·®è¡¨ç¤º *x* çš„å€¼åˆ†å¸ƒçš„å¹¿æ³›ç¨‹åº¦ã€‚
- en: 'For a set of numerical values, xi, the standard deviation is given by:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸€ç»„æ•°å€¼ xiï¼Œæ ‡å‡†å·®ç”±ä»¥ä¸‹å…¬å¼ç»™å‡ºï¼š
- en: '![Figure 2.1: Standard deviation equation](img/C12622_02_01.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.1ï¼šæ ‡å‡†å·®å…¬å¼](img/C12622_02_01.jpg)'
- en: 'Figure 2.1: Standard deviation equation'
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.1ï¼šæ ‡å‡†å·®å…¬å¼
- en: Here, ğˆ is the standard deviation, *N* is the number of data points, and ğ is
    the mean.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œğˆ æ˜¯æ ‡å‡†å·®ï¼Œ*N* æ˜¯æ•°æ®ç‚¹çš„æ•°é‡ï¼Œğ æ˜¯å‡å€¼ã€‚
- en: 'Say we have a set of 10 values, *x = [0,1,1,2,3,4,2,2,0,1]*. The mean, ğ, will
    be the sum of these values, divided by 10\. That is, ğ = 1.6:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€ç»„ 10 ä¸ªå€¼ï¼Œ*x = [0,1,1,2,3,4,2,2,0,1]*ã€‚å‡å€¼ ğ å°†æ˜¯è¿™äº›å€¼çš„æ€»å’Œé™¤ä»¥ 10ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œğ = 1.6ï¼š
- en: '![Figure 2.2: Mean square values for x](img/C12622_02_02.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.2ï¼šx çš„å‡æ–¹å€¼](img/C12622_02_02.jpg)'
- en: 'Figure 2.2: Mean square values for x'
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.2ï¼šx çš„å‡æ–¹å€¼
- en: Then, standard deviation = sqrt(14.4/10) = 1.2.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæ ‡å‡†å·® = sqrt(14.4/10) = 1.2ã€‚
- en: Percentiles
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç™¾åˆ†ä½æ•°
- en: For a set of values, the *n**th* percentile is equal to the value that is greater
    than *n%* of values in the set. For example, the 50*th* percentile is the value
    in the dataset that has as many values greater than it as it does that are less
    than it. Additionally, the fiftieth percentile of a dataset is also known as its
    median, and the twenty-fifth and seventy-fifth percentiles are also known as the
    lower and upper quartiles.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸€ç»„å€¼ï¼Œ*n**th* ç™¾åˆ†ä½æ•°æ˜¯å¤§äºè¯¥å€¼çš„æ•°å€¼æ‰€å æ¯”ä¾‹ä¸º *n%* çš„æ•°æ®ç‚¹ã€‚ä¾‹å¦‚ï¼Œç¬¬ 50*th* ç™¾åˆ†ä½æ•°æ˜¯æ•°æ®é›†ä¸­å¤§äºè¯¥å€¼å’Œå°äºè¯¥å€¼çš„å…ƒç´ æ•°é‡ç›¸åŒçš„å€¼ã€‚æ­¤å¤–ï¼Œæ•°æ®é›†çš„ç¬¬
    50 ç™¾åˆ†ä½æ•°ä¹Ÿç§°ä¸ºå…¶ä¸­ä½æ•°ï¼Œç¬¬ 25 ç™¾åˆ†ä½æ•°å’Œç¬¬ 75 ç™¾åˆ†ä½æ•°ä¹Ÿç§°ä¸ºä¸‹å››åˆ†ä½æ•°å’Œä¸Šå››åˆ†ä½æ•°ã€‚
- en: 'Say we have the same set of 10 values as earlier, *x = [0,1,1,2,3,4,2,2,0,1]*.
    Let''s first sort this list of values. Upon sorting, we have *x = [0,0,1,1,1,2,2,2,3,4]*.
    To find the twenty-fifth percentile, let''s first calculate the index at which
    the value occurs: *i = (p/100) * n)*, where *p = 25* and *n = 10*. Then, *i =
    2.5*.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸ä¹‹å‰ç›¸åŒçš„ 10 ä¸ªå€¼ï¼Œ*x = [0,1,1,2,3,4,2,2,0,1]*ã€‚æˆ‘ä»¬å…ˆå¯¹è¿™ä¸ªå€¼åˆ—è¡¨è¿›è¡Œæ’åºã€‚æ’åºåï¼Œå¾—åˆ° *x = [0,0,1,1,1,2,2,2,3,4]*ã€‚ä¸ºäº†æ‰¾åˆ°ç¬¬
    25 ç™¾åˆ†ä½æ•°ï¼Œæˆ‘ä»¬é¦–å…ˆè®¡ç®—è¯¥å€¼æ‰€åœ¨çš„ç´¢å¼•ï¼š*i = (p/100) * n)*ï¼Œå…¶ä¸­ *p = 25*ï¼Œ*n = 10*ã€‚ç„¶åï¼Œ*i = 2.5*ã€‚
- en: Since *i* is not an integer, we round it up to 3 and take the third element
    in the list as the twenty-fifth percentile. The twenty-fifth percentile in the
    given list would then be *1*, which is the third element in our sorted list.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº *i* ä¸æ˜¯æ•´æ•°ï¼Œæˆ‘ä»¬å°†å…¶å››èˆäº”å…¥ä¸º 3ï¼Œå¹¶å–æ’åºåˆ—è¡¨ä¸­çš„ç¬¬ä¸‰ä¸ªå…ƒç´ ä½œä¸ºç¬¬ 25 ç™¾åˆ†ä½æ•°ã€‚ç»™å®šåˆ—è¡¨ä¸­çš„ç¬¬ 25 ç™¾åˆ†ä½æ•°æ˜¯ *1*ï¼Œå³æˆ‘ä»¬æ’åºåçš„åˆ—è¡¨ä¸­çš„ç¬¬ä¸‰ä¸ªå…ƒç´ ã€‚
- en: 'Exercise 11: Summary Statistics of Our Dataset'
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  11ï¼šæˆ‘ä»¬æ•°æ®é›†çš„æ€»ç»“ç»Ÿè®¡
- en: 'In this exercise, we will use the summary statistics functions we read about
    previously to get a basic idea of our dataset:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¹‹å‰äº†è§£è¿‡çš„æ€»ç»“ç»Ÿè®¡å‡½æ•°ï¼Œè·å–æˆ‘ä»¬æ•°æ®é›†çš„åŸºæœ¬æƒ…å†µï¼š
- en: 'Read the earthquakes data into a `data` pandas DataFrame and use the `dtyp`
    dictionary we read using the `json` library in the previous exercise to specify
    the data types of each column in the CSV:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†åœ°éœ‡æ•°æ®è¯»å…¥ä¸€ä¸ª `data` pandas DataFrameï¼Œå¹¶ä½¿ç”¨åœ¨ä¸Šä¸€ç»ƒä¹ ä¸­é€šè¿‡ `json` åº“è¯»å–çš„ `dtyp` å­—å…¸æ¥æŒ‡å®š CSV ä¸­æ¯ä¸€åˆ—çš„æ•°æ®ç±»å‹ï¼š
- en: '[PRE2]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Use the `data.info()` function to get an overview of the dataset:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `data.info()` å‡½æ•°æ¥è·å–æ•°æ®é›†çš„æ¦‚è§ˆï¼š
- en: '[PRE3]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output will be as follows:'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.3: Overview of the dataset](img/C12622_02_03.jpg)'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.3ï¼šæ•°æ®é›†æ¦‚è§ˆ](img/C12622_02_03.jpg)'
- en: 'Figure 2.3: Overview of the dataset'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.3ï¼šæ•°æ®é›†æ¦‚è§ˆ
- en: 'Print the first five and last five rows of the dataset. The first five rows
    are printed as follows:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰“å°æ•°æ®é›†çš„å‰äº”è¡Œå’Œæœ€åäº”è¡Œã€‚å‰äº”è¡Œæ‰“å°å¦‚ä¸‹ï¼š
- en: '[PRE4]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output will be as shown here:'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.4: The first five rows](img/C12622_02_04.jpg)'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.4ï¼šå‰äº”è¡Œ](img/C12622_02_04.jpg)'
- en: 'Figure 2.4: The first five rows'
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.4ï¼šå‰äº”è¡Œ
- en: 'The last five rows are printed as follows:'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æœ€åäº”è¡Œæ‰“å°å¦‚ä¸‹ï¼š
- en: '[PRE5]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output will be as shown here:'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.5: The last five rows](img/C12622_02_05.jpg)'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.5ï¼šæœ€åäº”è¡Œ](img/C12622_02_05.jpg)'
- en: 'Figure 2.5: The last five rows'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.5ï¼šæœ€åäº”è¡Œ
- en: We can see in these outputs that there are 28 columns, but not all of them are
    displayed. Only the first 10 and last 10 columns are displayed, with the ellipses
    representing the fact that there are columns in between that are not displayed.
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨è¿™äº›è¾“å‡ºä¸­çœ‹åˆ°ï¼Œå…±æœ‰28åˆ—ï¼Œä½†å¹¶ä¸æ˜¯æ‰€æœ‰åˆ—éƒ½æ˜¾ç¤ºå‡ºæ¥ã€‚åªæ˜¾ç¤ºäº†å‰10åˆ—å’Œæœ€å10åˆ—ï¼Œçœç•¥å·è¡¨ç¤ºä¸­é—´è¿˜æœ‰å…¶ä»–æœªæ˜¾ç¤ºçš„åˆ—ã€‚
- en: 'Use `data.describe()` to find the summary statistics of the dataset. Run `data.describe().T`:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `data.describe()` æŸ¥æ‰¾æ•°æ®é›†çš„æ‘˜è¦ç»Ÿè®¡ä¿¡æ¯ã€‚è¿è¡Œ `data.describe().T`ï¼š
- en: '[PRE6]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, `.T` indicates that we're taking a transpose of the DataFrame to which
    it is applied, that is, turning the columns into rows and vice versa. Applying
    it to the `describe()` function allows us to see the output more easily with each
    row in the transposed DataFrame now corresponding to the statistics for a single
    feature.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œ`.T` è¡¨ç¤ºæˆ‘ä»¬æ­£åœ¨å¯¹åº”ç”¨çš„ DataFrame è¿›è¡Œè½¬ç½®æ“ä½œï¼Œå³å°†åˆ—è½¬æ¢ä¸ºè¡Œï¼Œåä¹‹äº¦ç„¶ã€‚å°†å…¶åº”ç”¨äº `describe()` å‡½æ•°ï¼Œå¯ä»¥ä½¿æˆ‘ä»¬æ›´å®¹æ˜“åœ°æŸ¥çœ‹è¾“å‡ºï¼Œå› ä¸ºè½¬ç½®åçš„
    DataFrame ä¸­æ¯ä¸€è¡Œç°åœ¨éƒ½å¯¹åº”äºå•ä¸ªç‰¹å¾çš„ç»Ÿè®¡æ•°æ®ã€‚
- en: 'We should get an output like this:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åº”è¯¥å¾—åˆ°å¦‚ä¸‹è¾“å‡ºï¼š
- en: '![Figure 2.6: Summary statistics](img/C12622_02_06.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.6ï¼šæ‘˜è¦ç»Ÿè®¡](img/C12622_02_06.jpg)'
- en: 'Figure 2.6: Summary statistics'
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.6ï¼šæ‘˜è¦ç»Ÿè®¡
- en: Notice here that the `describe()` function only shows the statistics for columns
    with numerical values. This is because we cannot calculate the statistics for
    the columns having non-numerical values.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œè¿™é‡Œçš„ `describe()` å‡½æ•°ä»…æ˜¾ç¤ºå…·æœ‰æ•°å€¼çš„åˆ—çš„ç»Ÿè®¡ä¿¡æ¯ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬æ— æ³•ä¸ºå…·æœ‰éæ•°å€¼çš„åˆ—è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ã€‚
- en: Missing Values
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¼ºå¤±å€¼
- en: When there is no value (that is, a null value) recorded for a particular feature
    in a data point, we say the data is missing. Having missing values in a real dataset
    is inevitable; no dataset is ever perfect. However, it is important to understand
    why the data is missing, and if there is a factor that has affected the loss of
    data. Appreciating and recognizing this allows us to handle the remaining data
    in an appropriate manner. For example, if the data is missing randomly, then it's
    highly likely that the remaining data is still representative of the population.
    However, if the missing data is not random in nature and we assume that it is,
    it could bias our analysis and subsequent modeling.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æŸä¸ªæ•°æ®ç‚¹çš„ç‰¹å¾æ²¡æœ‰è®°å½•å€¼ï¼ˆå³ç¼ºå¤±å€¼ï¼‰æ—¶ï¼Œæˆ‘ä»¬ç§°æ•°æ®ç¼ºå¤±ã€‚åœ¨çœŸå®çš„æ•°æ®é›†ä¸­å‡ºç°ç¼ºå¤±å€¼æ˜¯ä¸å¯é¿å…çš„ï¼›æ²¡æœ‰æ•°æ®é›†æ˜¯å®Œç¾çš„ã€‚ç„¶è€Œï¼Œç†è§£ä¸ºä»€ä¹ˆæ•°æ®ä¼šç¼ºå¤±ï¼Œä»¥åŠæ˜¯å¦æœ‰æŸç§å› ç´ å½±å“äº†æ•°æ®ä¸¢å¤±æ˜¯å¾ˆé‡è¦çš„ã€‚ç†è§£å’Œè®¤è¯†åˆ°è¿™ä¸€ç‚¹å¯ä»¥å¸®åŠ©æˆ‘ä»¬ä»¥åˆé€‚çš„æ–¹å¼å¤„ç†å‰©ä½™æ•°æ®ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ•°æ®ç¼ºå¤±æ˜¯éšæœºçš„ï¼Œé‚£ä¹ˆå‰©ä½™æ•°æ®å¾ˆå¯èƒ½ä»èƒ½ä»£è¡¨æ€»ä½“ã€‚ç„¶è€Œï¼Œå¦‚æœç¼ºå¤±çš„æ•°æ®ä¸æ˜¯éšæœºçš„ï¼Œæˆ‘ä»¬å´å‡è®¾å®ƒæ˜¯éšæœºçš„ï¼Œå¯èƒ½ä¼šåå‘æˆ‘ä»¬çš„åˆ†æå’Œåç»­å»ºæ¨¡ã€‚
- en: 'Let''s look at the common reasons (or mechanisms) for missing data:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ç¼ºå¤±æ•°æ®çš„å¸¸è§åŸå› ï¼ˆæˆ–æœºåˆ¶ï¼‰ï¼š
- en: '**Missing Completely at Random** (**MCAR**): Values in a dataset are said to
    be MCAR if there is no correlation whatsoever between the value missing and any
    other recorded variable or external parameter. This means that the remaining data
    is still representative of the population, though this is rarely the case and
    taking missing data to be completely random is usually an unrealistic assumption.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®Œå…¨éšæœºç¼ºå¤±**ï¼ˆ**MCAR**ï¼‰ï¼šå¦‚æœæ•°æ®é›†ä¸­çš„ç¼ºå¤±å€¼ä¸ä»»ä½•å…¶ä»–è®°å½•çš„å˜é‡æˆ–å¤–éƒ¨å‚æ•°ä¹‹é—´æ²¡æœ‰ä»»ä½•ç›¸å…³æ€§ï¼Œåˆ™è¯¥å€¼è¢«è®¤ä¸ºæ˜¯MCARã€‚è¿™æ„å‘³ç€å‰©ä½™çš„æ•°æ®ä»ç„¶èƒ½å¤Ÿä»£è¡¨æ€»ä½“ï¼Œå°½ç®¡è¿™ç§æƒ…å†µå¾ˆå°‘å‘ç”Ÿï¼Œå¹¶ä¸”å°†ç¼ºå¤±æ•°æ®è§†ä¸ºå®Œå…¨éšæœºé€šå¸¸æ˜¯ä¸€ä¸ªä¸ç°å®çš„å‡è®¾ã€‚'
- en: For example, in a study that involves determining the reason for obesity among
    K12 children, MCAR is when the parents forgot to take their kids to the clinic
    for the study.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåœ¨ä¸€é¡¹ç ”ç©¶ä¸­ï¼Œç ”ç©¶K12å„¿ç«¥è‚¥èƒ–çš„åŸå› ï¼ŒMCARæ˜¯çˆ¶æ¯å¿˜è®°å¸¦å­©å­å»è¯Šæ‰€å‚åŠ ç ”ç©¶çš„æƒ…å†µã€‚
- en: '**Missing at Random** (**MAR**): If the case where the data is missing is related
    to the data that was recorded rather than the data that was not, then the data
    is said to be MAR. Since it''s unfeasible to statistically verify whether data
    is MAR, we''d have to depend on whether it''s a reasonable possibility or not.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**éšæœºç¼ºå¤±** (**MAR**)ï¼šå¦‚æœæ•°æ®ç¼ºå¤±çš„æƒ…å†µä¸å·²è®°å½•çš„æ•°æ®ç›¸å…³ï¼Œè€Œä¸æ˜¯ä¸æœªè®°å½•çš„æ•°æ®ç›¸å…³ï¼Œé‚£ä¹ˆæ•°æ®è¢«è®¤ä¸ºæ˜¯ MARã€‚ç”±äºæ— æ³•é€šè¿‡ç»Ÿè®¡æ–¹æ³•éªŒè¯æ•°æ®æ˜¯å¦ä¸º
    MARï¼Œæˆ‘ä»¬åªèƒ½ä¾èµ–äºå…¶æ˜¯å¦ä¸ºåˆç†çš„å¯èƒ½æ€§ã€‚'
- en: Using the K12 study, missing data in this case is due to parents moving to a
    different city, hence the children had to leave the study; *missingness* has nothing
    to do with the study itself.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨ K12 ç ”ç©¶ä¸­ï¼Œç¼ºå¤±æ•°æ®æ˜¯ç”±äºçˆ¶æ¯æ¬åˆ°å…¶ä»–åŸå¸‚ï¼Œå¯¼è‡´å­©å­ä¸å¾—ä¸é€€å‡ºç ”ç©¶ï¼›*ç¼ºå¤±æ€§*ä¸ç ”ç©¶æœ¬èº«æ— å…³ã€‚
- en: '**Missing Not at Random** (**MNAR**): Data that is neither MAR nor MCAR is
    said to be MNAR. This is the case of a non-ignorable non-response, that is, the
    value of the variable that''s missing is related to the reason it is missing.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç¼ºå¤±ééšæœº** (**MNAR**)ï¼šæ—¢ä¸æ˜¯ MAR ä¹Ÿä¸æ˜¯ MCAR çš„æ•°æ®è¢«ç§°ä¸º MNARã€‚è¿™æ˜¯ä¸€ä¸ªä¸å¯å¿½ç•¥çš„éå“åº”æƒ…å†µï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œç¼ºå¤±çš„å˜é‡å€¼ä¸å…¶ç¼ºå¤±çš„åŸå› ç›¸å…³ã€‚'
- en: Continuing with the example of the case study, data would be MNAR if the parents
    were offended by the nature of the study and did not want their children to be
    bullied, so they withdrew their kids from the study.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç»§ç»­ä»¥æ¡ˆä¾‹ç ”ç©¶ä¸ºä¾‹ï¼Œå¦‚æœçˆ¶æ¯å¯¹ç ”ç©¶çš„æ€§è´¨æ„Ÿåˆ°åæ„Ÿï¼Œä¸å¸Œæœ›å­©å­å—åˆ°æ¬ºè´Ÿï¼Œå› æ­¤ä»–ä»¬å°†å­©å­ä»ç ”ç©¶ä¸­æ’¤å‡ºï¼Œé‚£ä¹ˆæ•°æ®å°†æ˜¯ MNARã€‚
- en: Finding Missing Values
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¯»æ‰¾ç¼ºå¤±å€¼
- en: So, now that we know why it's important to familiarize ourselves with the reasons
    behind why our data is missing, let's talk about how we can find these missing
    values in a dataset. For a pandas DataFrame, this is most commonly done using
    the `.isnull()` method on a DataFrame to create a mask of the null values (that
    is, a DataFrame of Boolean values) indicating where the null values existâ€”a `True`
    value at any position indicates a null value, while a `False` value indicates
    the existence of a valid value at that position.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¢ç„¶æˆ‘ä»¬å·²ç»äº†è§£äº†ç†Ÿæ‚‰æ•°æ®ç¼ºå¤±åŸå› çš„é‡è¦æ€§ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ¥è®¨è®ºå¦‚ä½•åœ¨æ•°æ®é›†ä¸­æ‰¾åˆ°è¿™äº›ç¼ºå¤±å€¼ã€‚å¯¹äº pandas DataFrameï¼Œé€šå¸¸ä½¿ç”¨ `.isnull()`
    æ–¹æ³•åˆ›å»ºç©ºå€¼æ©ç ï¼ˆå³ä¸€ä¸ªå¸ƒå°”å€¼çš„ DataFrameï¼‰ï¼Œç”¨ä»¥æŒ‡ç¤ºç©ºå€¼çš„ä½ç½®â€”â€”åœ¨ä»»æ„ä½ç½®çš„ `True` å€¼è¡¨ç¤ºç©ºå€¼ï¼Œè€Œ `False` å€¼è¡¨ç¤ºè¯¥ä½ç½®å­˜åœ¨æœ‰æ•ˆå€¼ã€‚
- en: Note
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ³¨æ„
- en: The `.isnull()` method can be used interchangeably with the `.isna()` method
    for pandas DataFrames. Both these methods do exactly the same thingâ€”the reason
    there are two methods to do the same thing is because pandas DataFrames were originally
    based on R DataFrames, and hence have reproduced much of the syntax and ideas
    in the latter.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`.isnull()` æ–¹æ³•å¯ä»¥ä¸ `.isna()` æ–¹æ³•äº’æ¢ä½¿ç”¨ã€‚å¯¹äº pandas DataFrameï¼Œè¿™ä¸¤ä¸ªæ–¹æ³•çš„åŠŸèƒ½å®Œå…¨ç›¸åŒâ€”â€”ä¹‹æ‰€ä»¥æœ‰ä¸¤ä¸ªæ–¹æ³•å®ç°ç›¸åŒçš„åŠŸèƒ½ï¼Œæ˜¯å› ä¸º
    pandas DataFrame æœ€åˆæ˜¯åŸºäº R DataFrame çš„ï¼Œå› æ­¤å¤ç”¨äº†å¾ˆå¤š R ä¸­çš„è¯­æ³•å’Œæ€æƒ³ã€‚'
- en: 'It may not be immediately obvious whether the missing data is random or not:
    discovering the nature of missing values across features in a dataset is possible
    through two common visualization techniques:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®ç¼ºå¤±æ˜¯å¦éšæœºå¯èƒ½ä¸ä¼šç«‹åˆ»æ˜¾ç°ï¼šé€šè¿‡ä¸¤ç§å¸¸è§çš„å¯è§†åŒ–æŠ€æœ¯ï¼Œå¯ä»¥å‘ç°æ•°æ®é›†ä¸­å„ç‰¹å¾ä¹‹é—´ç¼ºå¤±å€¼çš„æ€§è´¨ï¼š
- en: '**Nullity matrix**: This is a data-dense display that lets us quickly visualize
    the patterns in data completion. It gives us a quick glance at how the null values
    within a feature (and across features) are distributed, how many there are, and
    how often they appear with other features.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç©ºå€¼çŸ©é˜µ**ï¼šè¿™æ˜¯ä¸€ç§æ•°æ®å¯†é›†çš„å±•ç¤ºæ–¹å¼ï¼Œèƒ½å¸®åŠ©æˆ‘ä»¬å¿«é€Ÿå¯è§†åŒ–æ•°æ®è¡¥å…¨ä¸­çš„æ¨¡å¼ã€‚å®ƒè®©æˆ‘ä»¬ä¸€çœ¼çœ‹åˆ°æ¯ä¸ªç‰¹å¾ï¼ˆä»¥åŠè·¨ç‰¹å¾ï¼‰çš„ç©ºå€¼åˆ†å¸ƒã€æ•°é‡ä»¥åŠå®ƒä»¬ä¸å…¶ä»–ç‰¹å¾å‡ºç°çš„é¢‘ç‡ã€‚'
- en: '**Nullity-correlation heatmap**: This heatmap visually describes the nullity
    relationship (or a data completeness relationship) between each pair of features,
    that is, it measures how strongly the presence or absence of one variable affects
    the presence of another.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç©ºå€¼ç›¸å…³çƒ­å›¾**ï¼šè¯¥çƒ­å›¾å½¢è±¡åœ°æè¿°äº†æ¯å¯¹ç‰¹å¾ä¹‹é—´çš„ç©ºå€¼å…³ç³»ï¼ˆæˆ–æ•°æ®å®Œæ•´æ€§å…³ç³»ï¼‰ï¼Œå³å®ƒè¡¡é‡äº†ä¸€ä¸ªå˜é‡çš„å­˜åœ¨æˆ–ç¼ºå¤±å¯¹å¦ä¸€ä¸ªå˜é‡å­˜åœ¨çš„å½±å“å¼ºåº¦ã€‚'
- en: 'Akin to regular correlation, nullity correlation values range from -1 to 1:
    the former indicating that one variable appears when the other definitely does
    not, and the latter indicating the simultaneous presence of both variables. A
    value of 0 implies that one variable having a null value has no effect on the
    other being null.'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä¸å¸¸è§„ç›¸å…³æ€§ç±»ä¼¼ï¼Œç©ºå€¼ç›¸å…³æ€§å€¼çš„èŒƒå›´ä» -1 åˆ° 1ï¼šå‰è€…è¡¨ç¤ºä¸€ä¸ªå˜é‡å‡ºç°æ—¶å¦ä¸€ä¸ªå˜é‡è‚¯å®šä¸å‡ºç°ï¼Œåè€…åˆ™è¡¨ç¤ºä¸¤ä¸ªå˜é‡åŒæ—¶å­˜åœ¨ã€‚å€¼ä¸º 0 è¡¨ç¤ºä¸€ä¸ªå˜é‡çš„ç©ºå€¼å¯¹å¦ä¸€ä¸ªå˜é‡ä¸ºç©ºæ²¡æœ‰å½±å“ã€‚
- en: 'Exercise 12: Visualizing Missing Values'
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  12ï¼šå¯è§†åŒ–ç¼ºå¤±å€¼
- en: 'Let''s analyze the nature of the missing values by first looking at the count
    and percentage of missing values for each feature, then plotting a nullity matrix
    and correlation heatmap using the `missingno` library in Python:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ¥åˆ†æç¼ºå¤±å€¼çš„æ€§è´¨ï¼Œé¦–å…ˆæŸ¥çœ‹æ¯ä¸ªç‰¹å¾çš„ç¼ºå¤±å€¼æ•°é‡å’Œç™¾åˆ†æ¯”ï¼Œç„¶åä½¿ç”¨ Python ä¸­çš„ `missingno` åº“ç»˜åˆ¶ç©ºå€¼çŸ©é˜µå’Œç›¸å…³æ€§çƒ­å›¾ï¼š
- en: Calculate the count and percentage of missing values in each column and arrange
    these in decreasing order. We will use the `.isnull()` function on the DataFrame
    to get a mask. The count of null values in each column can then be found using
    the `.sum()` function over the mask DataFrame. Similarly, the fraction of null
    values can be found using `.mean()` over the mask DataFrame and multiplied by
    100 to convert it into a percentage.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¯åˆ—ç¼ºå¤±å€¼çš„æ•°é‡å’Œç™¾åˆ†æ¯”ï¼Œå¹¶æŒ‰é™åºæ’åˆ—ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `.isnull()` å‡½æ•°åœ¨ DataFrame ä¸Šè·å–æ©ç ã€‚æ¯åˆ—çš„ç©ºå€¼æ•°é‡å¯ä»¥é€šè¿‡å¯¹æ©ç  DataFrame
    ä½¿ç”¨ `.sum()` å‡½æ•°æ¥è·å¾—ã€‚åŒæ ·ï¼Œç©ºå€¼çš„æ¯”ä¾‹å¯ä»¥é€šè¿‡å¯¹æ©ç  DataFrame ä½¿ç”¨ `.mean()` å‡½æ•°å¾—åˆ°ï¼Œå¹¶ä¹˜ä»¥ 100 è½¬æ¢ä¸ºç™¾åˆ†æ¯”ã€‚
- en: 'Then, we combine the total and percentage of null values into a single DataFrame
    using the `pd.concat()` function, and subsequently sort the rows by percentage
    of missing values and print the DataFrame:'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ `pd.concat()` å‡½æ•°å°†ç©ºå€¼çš„æ€»æ•°å’Œç™¾åˆ†æ¯”åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„ DataFrameï¼Œå¹¶æŒ‰ç©ºå€¼çš„ç™¾åˆ†æ¯”å¯¹è¡Œè¿›è¡Œæ’åºï¼Œæœ€åæ‰“å°å‡º DataFrameï¼š
- en: '[PRE7]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output will be as follows:'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š
- en: '![Figure 2.7: Count and percentage of missing values in each column](img/C12622_02_07.jpg)'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.7ï¼šæ¯åˆ—ç¼ºå¤±å€¼çš„æ•°é‡å’Œç™¾åˆ†æ¯”](img/C12622_02_07.jpg)'
- en: 'Figure 2.7: Count and percentage of missing values in each column'
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.7ï¼šæ¯åˆ—ç¼ºå¤±å€¼çš„æ•°é‡å’Œç™¾åˆ†æ¯”
- en: Here, we can see that the `state`, `total_damage_millions_dollars`, and `damage_millions_dollars`
    columns have over 90% missing values, which means that data for less than 10%
    of data points in the dataset are available for these columns. On the other hand,
    `year`, `flag_tsunami`, `country`, and `region_code` have no missing values.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° `state`ã€`total_damage_millions_dollars` å’Œ `damage_millions_dollars`
    åˆ—çš„ç¼ºå¤±å€¼è¶…è¿‡ 90%ï¼Œè¿™æ„å‘³ç€æ•°æ®é›†ä¸­è¿™äº›åˆ—ä¸­ä¸åˆ° 10% çš„æ•°æ®ç‚¹æ˜¯å¯ç”¨çš„ã€‚å¦ä¸€æ–¹é¢ï¼Œ`year`ã€`flag_tsunami`ã€`country` å’Œ
    `region_code` åˆ—æ²¡æœ‰ç¼ºå¤±å€¼ã€‚
- en: 'Plot the nullity matrix. First, we find the list of columns that have any null
    values in them using the `.any()` function on the mask DataFrame from the previous
    step. Then, we use the `missingno` library to plot the nullity matrix for a random
    sample of 500 data points from our dataset, for only those columns that have missing
    values:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶ç©ºå€¼çŸ©é˜µã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ `.any()` å‡½æ•°åœ¨ä¸Šä¸€æ­¥çš„æ©ç  DataFrame ä¸ŠæŸ¥æ‰¾åŒ…å«ä»»ä½•ç©ºå€¼çš„åˆ—åˆ—è¡¨ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ `missingno`
    åº“ç»˜åˆ¶ç©ºå€¼çŸ©é˜µï¼Œé’ˆå¯¹æ•°æ®é›†ä¸­éšæœºæŠ½å–çš„ 500 ä¸ªæ•°æ®ç‚¹ï¼Œä»…ç»˜åˆ¶é‚£äº›åŒ…å«ç¼ºå¤±å€¼çš„åˆ—ï¼š
- en: '[PRE8]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output will be as follows:'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š
- en: '![Figure 2.8: The nullity matrix](img/C12622_02_08.jpg)'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.8ï¼šç©ºå€¼çŸ©é˜µ](img/C12622_02_08.jpg)'
- en: 'Figure 2.8: The nullity matrix'
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.8ï¼šç©ºå€¼çŸ©é˜µ
- en: Here, black lines represent non-nullity while the white lines indicate the presence
    of a null value in that column. At a glance, `location_name` appears to be completely
    populated (we know from the previous step that there is, in fact, only one missing
    value in this column), while `latitude` and `longitude` seem mostly complete,
    but spottier.
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œé»‘è‰²çº¿æ¡ä»£è¡¨éç©ºå€¼ï¼Œè€Œç™½è‰²çº¿æ¡åˆ™è¡¨ç¤ºè¯¥åˆ—ä¸­å­˜åœ¨ç©ºå€¼ã€‚é€šè¿‡ä¸€çœ¼çœ‹å»ï¼Œ`location_name` ä¼¼ä¹å®Œå…¨å¡«å……ï¼ˆæˆ‘ä»¬ä»ä¹‹å‰çš„æ­¥éª¤çŸ¥é“ï¼Œè¿™ä¸€åˆ—å®é™…ä¸Šåªæœ‰ä¸€ä¸ªç¼ºå¤±å€¼ï¼‰ï¼Œè€Œ
    `latitude` å’Œ `longitude` åˆ—å¤§å¤šå®Œæ•´ï¼Œä½†æœ‰ä¸€äº›ç©ºç™½ã€‚
- en: The spark line at the right summarizes the general shape of the data completeness
    and points out the rows with the maximum and minimum nullity in the dataset.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å³ä¾§çš„ç«èŠ±çº¿æ€»ç»“äº†æ•°æ®å®Œæ•´æ€§çš„æ€»ä½“å½¢çŠ¶ï¼Œå¹¶æŒ‡å‡ºæ•°æ®é›†ä¸­ç©ºå€¼æœ€å¤šå’Œæœ€å°‘çš„è¡Œã€‚
- en: 'Plot the nullity correlation heatmap. We will plot the nullity correlation
    heatmap using the `missingno` library for our dataset, for only those columns
    that have missing values:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶ç©ºå€¼ç›¸å…³æ€§çƒ­å›¾ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `missingno` åº“ç»˜åˆ¶æ•°æ®é›†çš„ç©ºå€¼ç›¸å…³æ€§çƒ­å›¾ï¼Œä»…é’ˆå¯¹é‚£äº›åŒ…å«ç©ºå€¼çš„åˆ—ï¼š
- en: '[PRE9]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output will be as follows:'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š
- en: '![Figure 2.9: The nullity correlation heatmap](img/C12622_02_09.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.9ï¼šç©ºå€¼ç›¸å…³æ€§çƒ­å›¾](img/C12622_02_09.jpg)'
- en: 'Figure 2.9: The nullity correlation heatmap'
  id: totrans-129
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.9ï¼šç©ºå€¼ç›¸å…³æ€§çƒ­å›¾
- en: Here, we can also see some boxes labeled `injuries` and `total_injuries`, which
    tells us that there are a few records that have one or the other, but not both.
    These types of cases will require special attentionâ€”if the correlation between
    the values of the variables themselves is high, it means that having both is not
    a value and one of the two can be dropped.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°ä¸€äº›æ ‡è®°ä¸º`injuries`å’Œ`total_injuries`çš„æ¡†ï¼Œè¿™å‘Šè¯‰æˆ‘ä»¬æœ‰ä¸€äº›è®°å½•åˆ†åˆ«åŒ…å«è¿™ä¸¤ä¸ªå€¼ä¸­çš„ä¸€ä¸ªï¼Œä½†ä¸åŒæ—¶åŒ…å«è¿™ä¸¤ä¸ªå€¼ã€‚è¿™ç±»æƒ…å†µéœ€è¦ç‰¹åˆ«å…³æ³¨â€”â€”å¦‚æœè¿™äº›å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§è¾ƒé«˜ï¼Œé‚£ä¹ˆæ‹¥æœ‰ä¸¤ä¸ªå€¼å¹¶æ²¡æœ‰æ„ä¹‰ï¼Œä¸¤ä¸ªå€¼ä¸­çš„ä¸€ä¸ªå¯ä»¥è¢«åˆ é™¤ã€‚
- en: Imputation Strategies for Missing Values
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¼ºå¤±å€¼çš„æ’è¡¥ç­–ç•¥
- en: 'There are multiple ways of dealing with missing values in a column. The simplest
    way is to simply delete rows having missing values; however, this can result in
    the loss of valuable information from other columns. Another option is to impute
    the data, that is, replace the missing values with a valid value inferred from
    the known part of the data. The common ways in which this can be done are listed
    here:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†åˆ—ä¸­ç¼ºå¤±å€¼çš„æ–¹æ³•æœ‰å¤šç§ã€‚æœ€ç®€å•çš„æ–¹æ³•æ˜¯ç›´æ¥åˆ é™¤ç¼ºå¤±å€¼æ‰€åœ¨çš„è¡Œï¼›ç„¶è€Œï¼Œè¿™æ ·åšå¯èƒ½ä¼šå¯¼è‡´ä¸¢å¤±å…¶ä»–åˆ—ä¸­çš„æœ‰ä»·å€¼ä¿¡æ¯ã€‚å¦ä¸€ä¸ªé€‰é¡¹æ˜¯æ’è¡¥æ•°æ®ï¼Œå³ç”¨ä»å·²çŸ¥éƒ¨åˆ†æ•°æ®æ¨æ–­å‡ºçš„æœ‰æ•ˆå€¼æ›¿ä»£ç¼ºå¤±å€¼ã€‚å¸¸è§çš„æ’è¡¥æ–¹æ³•åˆ—ä¸¾å¦‚ä¸‹ï¼š
- en: Create a new value that is distinct from the other values to replace the missing
    values in the column so as to differentiate those rows altogether. Then, use a
    non-linear machine learning algorithm (such as ensemble models or support vectors)
    that can separate the values out.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªæ–°çš„å€¼ï¼Œè¯¥å€¼ä¸åŒäºå…¶ä»–å€¼ï¼Œç”¨æ¥æ›¿ä»£åˆ—ä¸­çš„ç¼ºå¤±å€¼ï¼Œä»¥ä¾¿å®Œå…¨åŒºåˆ†è¿™äº›è¡Œã€‚ç„¶åï¼Œä½¿ç”¨éçº¿æ€§æœºå™¨å­¦ä¹ ç®—æ³•ï¼ˆå¦‚é›†æˆæ¨¡å‹æˆ–æ”¯æŒå‘é‡æœºï¼‰æ¥åŒºåˆ†è¿™äº›å€¼ã€‚
- en: Use an appropriate central value from the column (mean, median, or mode) to
    replace the missing values.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åˆ—ä¸­çš„é€‚å½“ä¸­å¿ƒå€¼ï¼ˆå‡å€¼ã€ä¸­ä½æ•°æˆ–ä¼—æ•°ï¼‰æ¥æ›¿æ¢ç¼ºå¤±å€¼ã€‚
- en: Use a model (such as a K-nearest neighbors or a Gaussian mixture model) to learn
    the best value with which to replace the missing values.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¨¡å‹ï¼ˆä¾‹å¦‚Kè¿‘é‚»æˆ–é«˜æ–¯æ··åˆæ¨¡å‹ï¼‰æ¥å­¦ä¹ æ›¿æ¢ç¼ºå¤±å€¼çš„æœ€ä½³å€¼ã€‚
- en: 'Python has a few functions that are useful for replacing null values in a column
    with a static value. One way to do this is using the inherent pandas `.fillna(0)`
    function: there is no ambiguity in imputation hereâ€”the static value with which
    to substitute the null data point in the column is the argument being passed to
    the function (the value in the brackets).'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Pythonæœ‰ä¸€äº›å‡½æ•°å¯¹äºç”¨é™æ€å€¼æ›¿æ¢åˆ—ä¸­çš„ç©ºå€¼éå¸¸æœ‰ç”¨ã€‚å®ç°è¿™ä¸€åŠŸèƒ½çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨å†…å»ºçš„pandas `.fillna(0)`å‡½æ•°ï¼šåœ¨æ’è¡¥ä¸­æ²¡æœ‰æ­§ä¹‰â€”â€”ç”¨æ¥æ›¿ä»£åˆ—ä¸­ç©ºæ•°æ®ç‚¹çš„é™æ€å€¼å³ä¸ºä¼ é€’ç»™å‡½æ•°çš„å‚æ•°ï¼ˆæ‹¬å·ä¸­çš„å€¼ï¼‰ã€‚
- en: 'However, if the number of null values in a column is significant and it''s
    not immediately obvious what the appropriate central value is that can be used
    to replace each null value, then we can either delete the rows having null values
    or delete the column altogether from the modeling perspective, as it may not add
    any significant value. This can be done by using the `.dropna()` function on the
    DataFrame. The parameters that can be passed to the function are:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå¦‚æœåˆ—ä¸­ç©ºå€¼çš„æ•°é‡è¾ƒå¤šï¼Œå¹¶ä¸”æ— æ³•ç«‹å³æ˜ç¡®å¯ä»¥ç”¨æ¥æ›¿æ¢æ¯ä¸ªç©ºå€¼çš„é€‚å½“ä¸­å¿ƒå€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é€‰æ‹©åˆ é™¤åŒ…å«ç©ºå€¼çš„è¡Œï¼Œæˆ–ä»å»ºæ¨¡çš„è§’åº¦å®Œå…¨åˆ é™¤è¯¥åˆ—ï¼Œå› ä¸ºå®ƒå¯èƒ½ä¸ä¼šå¸¦æ¥ä»»ä½•æ˜¾è‘—çš„ä»·å€¼ã€‚è¿™å¯ä»¥é€šè¿‡åœ¨DataFrameä¸Šä½¿ç”¨`.dropna()`å‡½æ•°æ¥å®Œæˆã€‚å¯ä»¥ä¼ é€’ç»™è¯¥å‡½æ•°çš„å‚æ•°åŒ…æ‹¬ï¼š
- en: '`axis`: This defines whether to drop rows or columns, which is determined by
    assigning the parameter a value of 0 or 1 respectively.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`axis`ï¼šæ­¤å‚æ•°å®šä¹‰äº†æ˜¯åˆ é™¤è¡Œè¿˜æ˜¯åˆ é™¤åˆ—ï¼Œé€šè¿‡å°†å‚æ•°åˆ†åˆ«èµ‹å€¼ä¸º0æˆ–1æ¥ç¡®å®šã€‚'
- en: '`how`: A value of `all` or `any` can be assigned to this parameter to indicate
    whether the row/column should contain all null values to drop the column, or whether
    to drop the column if there is at least one null value.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`how`ï¼šå¯ä»¥å°†`all`æˆ–`any`çš„å€¼èµ‹ç»™æ­¤å‚æ•°ï¼Œä»¥æŒ‡ç¤ºè¡Œ/åˆ—æ˜¯å¦åº”åŒ…å«æ‰€æœ‰ç©ºå€¼ä»¥åˆ é™¤è¯¥åˆ—ï¼Œæˆ–è€…æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ªç©ºå€¼æ—¶åˆ é™¤è¯¥åˆ—ã€‚'
- en: '`thresh`: This defines the minimum number of null values the row/column should
    have in order to be dropped.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`thresh`ï¼šæ­¤å‚æ•°å®šä¹‰äº†è¡Œ/åˆ—å¿…é¡»å…·æœ‰çš„æœ€å°ç©ºå€¼æ•°é‡ï¼Œæ‰ä¼šè¢«åˆ é™¤ã€‚'
- en: Additionally, if an appropriate replacement for a null value for a categorical
    feature cannot be determined, a possible alternative to deleting the column is
    to create a new category in the feature that can represent the null values.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œå¦‚æœæ— æ³•ä¸ºåˆ†ç±»ç‰¹å¾çš„ç©ºå€¼ç¡®å®šåˆé€‚çš„æ›¿ä»£å€¼ï¼Œå¯ä»¥è€ƒè™‘åœ¨ç‰¹å¾ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„ç±»åˆ«æ¥è¡¨ç¤ºç©ºå€¼ï¼Œè€Œä¸æ˜¯åˆ é™¤è¯¥åˆ—ã€‚
- en: Note
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ³¨æ„
- en: If it is immediately obvious how a null value for a column can be replaced from
    an intuitive understanding or domain knowledge, then we can replace the value
    on the spot. In many cases, however, such inferences become more obvious at later
    stages in the exploration process. In these cases, we can substitute null values
    as and when we find an appropriate way to do so.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä»ç›´è§‚ç†è§£æˆ–é¢†åŸŸçŸ¥è¯†ä¸Šç«‹å³èƒ½å¤Ÿçœ‹å‡ºå¦‚ä½•æ›¿æ¢åˆ—çš„ç©ºå€¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å½“åœºæ›¿æ¢è¿™äº›å€¼ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œè¿™äº›æ¨æ–­ä¼šåœ¨æ¢ç´¢è¿‡ç¨‹çš„åæœŸå˜å¾—æ›´åŠ æ˜æ˜¾ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®æ‰¾åˆ°çš„åˆé€‚æ–¹æ³•ï¼Œéšæ—¶æ›¿æ¢ç©ºå€¼ã€‚
- en: 'Exercise 13: Imputation Using pandas'
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  13ï¼šä½¿ç”¨ pandas å¡«å……
- en: Let's look at missing values and replace them with zeros in time-based (continuous)
    features having at least one null value (month, day, hour, minute, and second).
    We do this because for cases where we do not have recorded values, it would be
    safe to assume that the events take place at the beginning of the time duration.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æŸ¥çœ‹ç¼ºå¤±å€¼ï¼Œå¹¶å°†å®ƒä»¬æ›¿æ¢ä¸ºé›¶ï¼Œé’ˆå¯¹é‚£äº›å…·æœ‰è‡³å°‘ä¸€ä¸ªç©ºå€¼çš„åŸºäºæ—¶é—´çš„ï¼ˆè¿ç»­ï¼‰ç‰¹å¾ï¼ˆå¦‚æœˆä»½ã€æ—¥æœŸã€å°æ—¶ã€åˆ†é’Ÿå’Œç§’ï¼‰ã€‚æˆ‘ä»¬è¿™æ ·åšæ˜¯å› ä¸ºå¯¹äºæ²¡æœ‰è®°å½•å€¼çš„æƒ…å†µï¼Œå¯ä»¥å®‰å…¨åœ°å‡è®¾äº‹ä»¶å‘ç”Ÿåœ¨æ—¶é—´æ®µçš„å¼€å§‹ã€‚
- en: 'Create a list containing the names of the columns whose values we want to impute:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«æˆ‘ä»¬æƒ³è¦å¡«å……å€¼çš„åˆ—åï¼š
- en: '[PRE10]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Impute the null values using `.fillna()`. We will replace the missing values
    in these columns with `0` using the inherent pandas `.fillna()` function and pass
    `0` as an argument to the function:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `.fillna()` å¡«å……ç©ºå€¼ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ pandas çš„å†…å»º `.fillna()` å‡½æ•°ï¼Œå°†è¿™äº›åˆ—ä¸­çš„ç¼ºå¤±å€¼æ›¿æ¢ä¸º `0`ï¼Œå¹¶å°† `0`
    ä½œä¸ºå‚æ•°ä¼ é€’ç»™å‡½æ•°ï¼š
- en: '[PRE11]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Use the `.info()` function to view null value counts for the imputed columns:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `.info()` å‡½æ•°æŸ¥çœ‹å¡«å……åˆ—çš„ç©ºå€¼è®¡æ•°ï¼š
- en: '[PRE12]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output will be as follows:'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.10: Null value counts](img/C12622_02_10.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.10ï¼šç©ºå€¼è®¡æ•°](img/C12622_02_10.jpg)'
- en: 'Figure 2.10: Null value counts'
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.10ï¼šç©ºå€¼è®¡æ•°
- en: As we can see now, all values for our features in the DataFrame are now non-null.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä»Šï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ•°æ®æ¡†ä¸­æ‰€æœ‰ç‰¹å¾çš„å€¼éƒ½å·²ç»æ˜¯éç©ºå€¼ã€‚
- en: 'Exercise 14: Imputation Using scikit-learn'
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  14ï¼šä½¿ç”¨ scikit-learn å¡«å……
- en: 'Let''s replace the null values in the description-related categorical features
    using scikit-learn''s `SimpleImputer` class. In *Exercise 12: Visualizing Missing
    Values*, we saw that almost all of these features comprised more than 50% of null
    values in the data. Replacing these null values with a central value might bias
    any model we try to build using the features, deeming them irrelevant. Let''s
    instead replace the null values with a separate category, having value `NA`:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä½¿ç”¨ scikit-learn çš„ `SimpleImputer` ç±»ï¼Œæ›¿æ¢ä¸æè¿°ç›¸å…³çš„åˆ†ç±»ç‰¹å¾ä¸­çš„ç©ºå€¼ã€‚åœ¨*ç»ƒä¹  12ï¼šå¯è§†åŒ–ç¼ºå¤±å€¼*ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°å‡ ä¹æ‰€æœ‰è¿™äº›ç‰¹å¾ä¸­è¶…è¿‡
    50% çš„å€¼éƒ½æ˜¯ç©ºå€¼ã€‚å°†è¿™äº›ç©ºå€¼æ›¿æ¢ä¸ºä¸­å¿ƒå€¼å¯èƒ½ä¼šå¯¹æˆ‘ä»¬è¯•å›¾æ„å»ºçš„æ¨¡å‹äº§ç”Ÿåå·®ï¼Œä½¿å®ƒä»¬å˜å¾—ä¸ç›¸å…³ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†ç©ºå€¼æ›¿æ¢ä¸ºä¸€ä¸ªå•ç‹¬çš„ç±»åˆ«ï¼Œå€¼ä¸º `NA`ï¼š
- en: 'Create a list containing the names of the columns whose values we want to impute:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«æˆ‘ä»¬æƒ³è¦å¡«å……å€¼çš„åˆ—åï¼š
- en: '[PRE13]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create an object of the `SimpleImputer` class. Here, we first create an `imp`
    object of the `SimpleImputer` class and initialize it with parameters that represent
    how we want to impute the data. The parameters we will pass to initialize the
    object are:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ª `SimpleImputer` ç±»çš„å¯¹è±¡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ª `imp` å¯¹è±¡ï¼Œå¹¶ä½¿ç”¨è¡¨ç¤ºå¦‚ä½•å¡«å……æ•°æ®çš„å‚æ•°åˆå§‹åŒ–å®ƒã€‚æˆ‘ä»¬å°†ä¼ é€’ç»™å¯¹è±¡åˆå§‹åŒ–çš„å‚æ•°åŒ…æ‹¬ï¼š
- en: '`missing_values`: This is the placeholder for the missing values, that is,
    all occurrences of the values in the `missing_values` parameter will be imputed.'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`missing_values`ï¼šè¿™æ˜¯ç¼ºå¤±å€¼çš„å ä½ç¬¦ï¼Œå³æ‰€æœ‰å‡ºç°åœ¨ `missing_values` å‚æ•°ä¸­çš„å€¼å°†è¢«å¡«å……ã€‚'
- en: '`strategy`: This is the imputation strategy, which can be one of `mean`, `median`,
    `most_frequent` (that is, the mode), or `constant`. While the first three can
    only be used with numeric data and will replace missing values using the specified
    central value along each column, the last one will replace missing values with
    a constant as per the `fill_value` parameter.'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`strategy`ï¼šè¿™æ˜¯å¡«å……ç­–ç•¥ï¼Œå¯ä»¥æ˜¯ `mean`ã€`median`ã€`most_frequent`ï¼ˆå³ä¼—æ•°ï¼‰æˆ– `constant`ã€‚å‰ä¸‰è€…åªèƒ½ç”¨äºæ•°å€¼æ•°æ®ï¼Œå¹¶ä¼šé€šè¿‡æŒ‡å®šçš„ä¸­å¿ƒå€¼æ›¿æ¢æ¯åˆ—ä¸­çš„ç¼ºå¤±å€¼ï¼Œè€Œæœ€åä¸€ä¸ªåˆ™ä¼šæ ¹æ®
    `fill_value` å‚æ•°ï¼Œç”¨å¸¸æ•°æ›¿æ¢ç¼ºå¤±å€¼ã€‚'
- en: '`fill_value`: This specifies the value with which to replace all occurrences
    of `missing_values`. If left to the default, the imputed value will be `0` when
    imputing numerical data and the `missing_value` string for strings or object data
    types:'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`fill_value`ï¼šæŒ‡å®šç”¨æ¥æ›¿æ¢æ‰€æœ‰ `missing_values` çš„å€¼ã€‚å¦‚æœä¿æŒé»˜è®¤è®¾ç½®ï¼Œå½“å¡«å……æ•°å€¼æ•°æ®æ—¶ï¼Œå¡«å……å€¼å°†ä¸º `0`ï¼Œè€Œå­—ç¬¦ä¸²æˆ–å¯¹è±¡æ•°æ®ç±»å‹å°†ä½¿ç”¨
    `missing_value` å­—ç¬¦ä¸²ã€‚'
- en: '[PRE14]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Perform the imputation. We will use `imp.fit_transform()` to actually perform
    the imputation. It takes the DataFrame with null values as input and returns the
    imputed DataFrame:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰§è¡Œå¡«å……ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `imp.fit_transform()` å®é™…æ‰§è¡Œå¡«å……ã€‚å®ƒå°†å¸¦æœ‰ç©ºå€¼çš„ DataFrame ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›å¡«å……åçš„ DataFrameï¼š
- en: '[PRE15]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Use the `.info()` function to view null value counts for the imputed columns:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `.info()` å‡½æ•°æŸ¥çœ‹å¡«å……åˆ—çš„ç©ºå€¼è®¡æ•°ï¼š
- en: '[PRE16]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output will be as follows:'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.11: The null value counts](img/C12622_02_11.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.11ï¼šç©ºå€¼è®¡æ•°](img/C12622_02_11.jpg)'
- en: 'Figure 2.11: The null value counts'
  id: totrans-171
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.11ï¼šç©ºå€¼è®¡æ•°
- en: 'Exercise 15: Imputation Using Inferred Values'
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  15ï¼šä½¿ç”¨æ¨æ–­å€¼è¿›è¡Œå¡«å……
- en: 'Let''s replace the null values in the continuous `damage_millions_dollars`
    feature with information from the categorical `damage_description` feature. Although
    we may not know the exact dollar amount that was incurred, the categorical feature
    gives us information on the range of the amount that was incurred due to damage
    from the earthquake:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç”¨æ¥è‡ªç±»åˆ« `damage_description` ç‰¹å¾çš„ä¿¡æ¯æ›¿æ¢è¿ç»­çš„ `damage_millions_dollars` ç‰¹å¾ä¸­çš„ç©ºå€¼ã€‚å°½ç®¡æˆ‘ä»¬å¯èƒ½ä¸çŸ¥é“ç¡®åˆ‡çš„æŸå¤±é‡‘é¢ï¼Œä½†ç±»åˆ«ç‰¹å¾ä¸ºæˆ‘ä»¬æä¾›äº†å› åœ°éœ‡é€ æˆçš„æŸå¤±é‡‘é¢çš„èŒƒå›´ä¿¡æ¯ï¼š
- en: 'Find how many rows have null `damage_millions_dollars` values, and how many
    of those have non-null `damage_description` values:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰¾å‡ºæœ‰å¤šå°‘è¡Œçš„ `damage_millions_dollars` å€¼ä¸ºç©ºï¼Œä»¥åŠå…¶ä¸­æœ‰å¤šå°‘è¡Œçš„ `damage_description` å€¼ä¸ä¸ºç©ºï¼š
- en: '[PRE17]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output will be as follows:'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](img/C12622_02_12.jpg)'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C12622_02_12.jpg)'
- en: 'Figure 2.12: Count of rows with null values'
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.12ï¼šåŒ…å«ç©ºå€¼çš„è¡Œæ•°
- en: As we can see, 3,849 of 5,594 null values can be easily substituted with the
    help of another variable.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä»¬æ‰€è§ï¼Œ5,594 ä¸ªç©ºå€¼ä¸­æœ‰ 3,849 ä¸ªå¯ä»¥é€šè¿‡å¦ä¸€ä¸ªå˜é‡è½»æ¾æ›¿æ¢ã€‚
- en: 'Find the mean `damage_millions_dollars` value for each category. Since each
    of the categories in `damage_description` represent a range of values, we find
    the mean `damage_millions_dollars` value for each category from the non-null values
    already available. These provide a reasonable estimate for the most likely value
    for that category:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰¾å‡ºæ¯ä¸ªç±»åˆ«çš„å¹³å‡ `damage_millions_dollars` å€¼ã€‚ç”±äº `damage_description` ä¸­çš„æ¯ä¸ªç±»åˆ«ä»£è¡¨ä¸€ç³»åˆ—å€¼ï¼Œæˆ‘ä»¬ä»å·²å­˜åœ¨çš„éç©ºå€¼ä¸­æ‰¾åˆ°æ¯ä¸ªç±»åˆ«çš„å¹³å‡
    `damage_millions_dollars` å€¼ã€‚è¿™äº›ä¸ºè¯¥ç±»åˆ«æä¾›äº†åˆç†çš„æœ€å¯èƒ½å€¼ä¼°ç®—ï¼š
- en: '[PRE18]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output will be as follows:'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.13: The mean damage_millions_dollars value for each category](img/C12622_02_13.jpg)'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.13ï¼šæ¯ä¸ªç±»åˆ«çš„å¹³å‡ damage_millions_dollars å€¼](img/C12622_02_13.jpg)'
- en: 'Figure 2.13: The mean damage_millions_dollars value for each category'
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.13ï¼šæ¯ä¸ªç±»åˆ«çš„å¹³å‡ damage_millions_dollars å€¼
- en: Store the mean values as a dictionary. In this step, we will convert the DataFrame
    containing the mean values to a dictionary (a Python `dict` object) so that accessing
    them is convenient.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å¹³å‡å€¼å­˜å‚¨ä¸ºå­—å…¸ã€‚åœ¨æ­¤æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å°†åŒ…å«å¹³å‡å€¼çš„ DataFrame è½¬æ¢ä¸ºå­—å…¸ï¼ˆPython `dict` å¯¹è±¡ï¼‰ï¼Œè¿™æ ·è®¿é—®å®ƒä»¬å°±æ›´åŠ æ–¹ä¾¿ã€‚
- en: 'Additionally, since the value for the newly created `NA` category (the imputed
    value in the previous exercise) was `NaN` and the value for the `0` category was
    absent (no rows had `damage_description` equal to `0` in the dataset), we explicitly
    added these values in the dictionary as well:'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œç”±äºæ–°åˆ›å»ºçš„ `NA` ç±»åˆ«ï¼ˆåœ¨å‰ä¸€ä¸ªç»ƒä¹ ä¸­çš„å¡«å……å€¼ï¼‰çš„å€¼ä¸º `NaN`ï¼Œå¹¶ä¸” `0` ç±»åˆ«çš„å€¼ç¼ºå¤±ï¼ˆæ•°æ®é›†ä¸­æ²¡æœ‰ `damage_description`
    ç­‰äº `0` çš„è¡Œï¼‰ï¼Œæˆ‘ä»¬ä¹Ÿæ˜ç¡®åœ°å°†è¿™äº›å€¼æ·»åŠ åˆ°å­—å…¸ä¸­ï¼š
- en: '[PRE19]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output will be as follows:'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.14: The dictionary of mean values](img/C12622_02_14.jpg)'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.14ï¼šå¹³å‡å€¼å­—å…¸](img/C12622_02_14.jpg)'
- en: 'Figure 2.14: The dictionary of mean values'
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.14ï¼šå¹³å‡å€¼å­—å…¸
- en: 'Create a series of replacement values. For each value in the `damage_description`
    column, we map the categorical value onto the mean value using the `map` function.
    The `.map()` function is used to map the keys in the column to the corresponding
    values for each element from the `replacement_values` dictionary:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ç³»åˆ—æ›¿ä»£å€¼ã€‚å¯¹äº `damage_description` åˆ—ä¸­çš„æ¯ä¸ªå€¼ï¼Œæˆ‘ä»¬ä½¿ç”¨ `map` å‡½æ•°å°†ç±»åˆ«å€¼æ˜ å°„åˆ°å¹³å‡å€¼ã€‚`.map()` å‡½æ•°ç”¨äºå°†åˆ—ä¸­çš„é”®æ˜ å°„åˆ°
    `replacement_values` å­—å…¸ä¸­æ¯ä¸ªå…ƒç´ çš„å¯¹åº”å€¼ï¼š
- en: '[PRE20]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Replace null values in the column. We do this by using `np.where` as a ternary
    operator: the first argument is the mask, the second is the series from which
    to take the value if the mask is positive, and the third is the series from which
    to take the value if the mask is negative.'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ›¿æ¢åˆ—ä¸­çš„ç©ºå€¼ã€‚æˆ‘ä»¬é€šè¿‡ä½¿ç”¨ `np.where` ä½œä¸ºä¸‰å…ƒè¿ç®—ç¬¦æ¥å®ç°ï¼šç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ©ç ï¼Œç¬¬äºŒä¸ªæ˜¯å¦‚æœæ©ç ä¸ºæ­£æ—¶ä»ä¸­è·å–å€¼çš„ç³»åˆ—ï¼Œç¬¬ä¸‰ä¸ªæ˜¯å¦‚æœæ©ç ä¸ºè´Ÿæ—¶ä»ä¸­è·å–å€¼çš„ç³»åˆ—ã€‚
- en: 'This ensures that the array returned by `np.where` only replaces the null values
    in `damage_millions_dollars` with values from the `imputed_values` series:'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™ç¡®ä¿äº† `np.where` è¿”å›çš„æ•°ç»„ä»…å°† `damage_millions_dollars` ä¸­çš„ç©ºå€¼æ›¿æ¢ä¸º `imputed_values` åºåˆ—ä¸­çš„å€¼ï¼š
- en: '[PRE21]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Use the `.info()` function to view null value counts for the imputed columns:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `.info()` å‡½æ•°æŸ¥çœ‹å¡«å……åˆ—çš„ç©ºå€¼è®¡æ•°ï¼š
- en: '[PRE22]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output will be as follows:'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š
- en: '![Figure 2.15: The null value counts](img/C12622_02_15.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.15ï¼šç©ºå€¼è®¡æ•°](img/C12622_02_15.jpg)'
- en: 'Figure 2.15: The null value counts'
  id: totrans-200
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.15ï¼šç©ºå€¼è®¡æ•°
- en: We can see that, after replacement, there are no null values in the `damage_millions_dollars`
    column.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ›¿æ¢å `damage_millions_dollars` åˆ—ä¸­æ²¡æœ‰ç©ºå€¼ã€‚
- en: 'Activity 2: Summary Statistics and Missing Values'
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ´»åŠ¨ 2ï¼šæ±‡æ€»ç»Ÿè®¡ä¸ç¼ºå¤±å€¼
- en: 'In this activity, we''ll revise some of the summary statistics and missing
    value exploration we have looked at thus far in this chapter. We will be using
    a new dataset, taken from Kaggle''s *House Prices: Advanced Regression Techniques*
    competition (available at [https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)
    or on GitHub at [https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python](https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python)).
    While the Earthquakes dataset used in the exercises is aimed at solving a classification
    problem (when the target variable has only discrete values), the dataset we will
    use in the activities will be aimed at solving a regression problem (when the
    target variable takes on a range of continuous values). We''ll use pandas functions
    to generate summary statistics and visualize missing values using a nullity matrix
    and nullity correlation heatmap.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 'åœ¨æœ¬æ´»åŠ¨ä¸­ï¼Œæˆ‘ä»¬å°†å›é¡¾æœ¬ç« ä¸­åˆ°ç›®å‰ä¸ºæ­¢çœ‹åˆ°çš„ä¸€äº›æ±‡æ€»ç»Ÿè®¡å’Œç¼ºå¤±å€¼åˆ†æã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œæ¥è‡ª Kaggle çš„ *House Prices:
    Advanced Regression Techniques* æ¯”èµ›ï¼ˆå¯ä»¥åœ¨ [https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)
    æˆ– GitHub ä¸Šçš„ [https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python](https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python)
    è·å–ï¼‰ã€‚è™½ç„¶åœ¨ç»ƒä¹ ä¸­ä½¿ç”¨çš„åœ°éœ‡æ•°æ®é›†æ˜¯é’ˆå¯¹è§£å†³åˆ†ç±»é—®é¢˜çš„ï¼ˆå½“ç›®æ ‡å˜é‡åªæœ‰ç¦»æ•£å€¼æ—¶ï¼‰ï¼Œæˆ‘ä»¬å°†åœ¨æ´»åŠ¨ä¸­ä½¿ç”¨çš„æ•°æ®é›†å°†ç”¨äºè§£å†³å›å½’é—®é¢˜ï¼ˆå½“ç›®æ ‡å˜é‡åŒ…å«è¿ç»­å€¼çš„èŒƒå›´æ—¶ï¼‰ã€‚æˆ‘ä»¬å°†ä½¿ç”¨
    pandas å‡½æ•°ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡ï¼Œå¹¶é€šè¿‡ç©ºå€¼çŸ©é˜µå’Œç©ºå€¼ç›¸å…³çƒ­å›¾å¯è§†åŒ–ç¼ºå¤±å€¼ã€‚'
- en: 'The steps to be performed are as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰§è¡Œçš„æ­¥éª¤å¦‚ä¸‹ï¼š
- en: Read the data.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯»å–æ•°æ®ã€‚
- en: Use pandas' `.info()` and `.describe()` methods to view the summary statistics
    of the dataset.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ pandas çš„ `.info()` å’Œ `.describe()` æ–¹æ³•æŸ¥çœ‹æ•°æ®é›†çš„æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯ã€‚
- en: Find the total count and total percentage of missing values in each column of
    the DataFrame and display them for columns having at least one null value, in
    descending order of missing percentages.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŸ¥æ‰¾æ¯åˆ—çš„ç¼ºå¤±å€¼æ€»æ•°å’Œç¼ºå¤±å€¼ç™¾åˆ†æ¯”ï¼Œå¹¶æŒ‰ç¼ºå¤±ç™¾åˆ†æ¯”çš„é™åºæ˜¾ç¤ºè‡³å°‘æœ‰ä¸€ä¸ªç©ºå€¼çš„åˆ—ã€‚
- en: Plot the nullity matrix and nullity correlation heatmap.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶ç©ºå€¼çŸ©é˜µå’Œç©ºå€¼ç›¸å…³çƒ­å›¾ã€‚
- en: Delete the columns having more than 80% of values missing.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ é™¤ç¼ºå¤±å€¼è¶…è¿‡ 80% çš„åˆ—ã€‚
- en: Replace null values in the `FireplaceQu` column with `NA` values.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°† `FireplaceQu` åˆ—ä¸­çš„ç©ºå€¼æ›¿æ¢ä¸º `NA` å€¼ã€‚
- en: Note
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ³¨æ„
- en: The solution for this activity can be found on page 307.
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æœ¬æ´»åŠ¨çš„è§£å†³æ–¹æ¡ˆå¯ä»¥åœ¨ç¬¬ 307 é¡µæ‰¾åˆ°ã€‚
- en: Distribution of Values
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å€¼çš„åˆ†å¸ƒ
- en: In this section, we'll look at how individual variables behaveâ€”what kind of
    values they take, what the distribution across those values is, and how those
    distributions can be represented visually.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹å„ä¸ªå˜é‡çš„è¡Œä¸ºâ€”â€”å®ƒä»¬å–ä»€ä¹ˆå€¼ï¼Œè¿™äº›å€¼çš„åˆ†å¸ƒå¦‚ä½•ï¼Œä»¥åŠå¦‚ä½•ä»¥å¯è§†åŒ–æ–¹å¼è¡¨ç¤ºè¿™äº›åˆ†å¸ƒã€‚
- en: Target Variable
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç›®æ ‡å˜é‡
- en: The target variable can either have values that are continuous (in the case
    of a regression problem) or discrete (as in the case of a classification problem).
    The problem statement we're looking at in this chapter involves predicting whether
    or not an earthquake caused a tsunami, that is, the `flag_tsunami` variable, which
    takes on two discrete values onlyâ€”making it a classification problem.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®æ ‡å˜é‡å¯ä»¥æ˜¯è¿ç»­å€¼ï¼ˆå›å½’é—®é¢˜çš„æƒ…å†µï¼‰æˆ–ç¦»æ•£å€¼ï¼ˆåˆ†ç±»é—®é¢˜çš„æƒ…å†µï¼‰ã€‚æœ¬ç« è®¨è®ºçš„é—®é¢˜æ˜¯é¢„æµ‹åœ°éœ‡æ˜¯å¦å¼•å‘æµ·å•¸ï¼Œä¹Ÿå°±æ˜¯ `flag_tsunami` å˜é‡ï¼Œå®ƒåªæœ‰ä¸¤ä¸ªç¦»æ•£å€¼â€”â€”å› æ­¤æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ã€‚
- en: One way of visualizing how many earthquakes resulted in tsunamis and how many
    didn't is a bar chart, where each bar represents a single discrete value of the
    variable, and the height of the bars is equal to the count of the data points
    having the corresponding discrete value. This gives us a good comparison of the
    absolute counts of each category.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–æœ‰å¤šå°‘åœ°éœ‡å¼•å‘äº†æµ·å•¸ï¼Œä»¥åŠæœ‰å¤šå°‘æ²¡æœ‰å¼•å‘æµ·å•¸çš„ä¸€ç§æ–¹æ³•æ˜¯æŸ±çŠ¶å›¾ï¼Œå…¶ä¸­æ¯ä¸ªæŸ±å­ä»£è¡¨ä¸€ä¸ªç¦»æ•£å€¼ï¼ŒæŸ±å­çš„é«˜åº¦ç­‰äºå…·æœ‰ç›¸åº”ç¦»æ•£å€¼çš„æ•°æ®ç‚¹çš„è®¡æ•°ã€‚è¿™ä¸ºæˆ‘ä»¬æä¾›äº†æ¯ä¸ªç±»åˆ«çš„ç»å¯¹è®¡æ•°çš„è‰¯å¥½æ¯”è¾ƒã€‚
- en: 'Exercise 16: Plotting a Bar Chart'
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 16ï¼šç»˜åˆ¶æŸ±çŠ¶å›¾
- en: 'Let''s look at how many of the earthquakes in our dataset resulted in a tsunami.
    We will do this by using the `value_counts()` method over the column and directly
    using the `.plot(kind=''bar'')` function on the returned pandas series. Follow
    these steps:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹æ•°æ®é›†ä¸­æœ‰å¤šå°‘åœ°éœ‡å¼•å‘äº†æµ·å•¸ã€‚æˆ‘ä»¬å°†é€šè¿‡å¯¹åˆ—ä½¿ç”¨`value_counts()`æ–¹æ³•ï¼Œå¹¶ç›´æ¥å¯¹è¿”å›çš„pandasç³»åˆ—ä½¿ç”¨`.plot(kind='bar')`å‡½æ•°æ¥å®Œæˆã€‚æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š
- en: 'Use `plt.figure()` to initiate the plotting:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `plt.figure()` åˆå§‹åŒ–ç»˜å›¾ï¼š
- en: '[PRE23]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, type in our primary plotting command:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œè¾“å…¥æˆ‘ä»¬çš„ä¸»è¦ç»˜å›¾å‘½ä»¤ï¼š
- en: '[PRE24]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Set the display parameters and display the plot:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¾ç½®æ˜¾ç¤ºå‚æ•°å¹¶æ˜¾ç¤ºå›¾è¡¨ï¼š
- en: '[PRE25]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output will be as follows:'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.16: Bar chart showing how many earthquakes resulted in a tsunami](img/C12622_02_16.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾2.16ï¼šæŸ±çŠ¶å›¾æ˜¾ç¤ºæœ‰å¤šå°‘åœ°éœ‡å¼•å‘äº†æµ·å•¸](img/C12622_02_16.jpg)'
- en: 'Figure 2.16: Bar chart showing how many earthquakes resulted in a tsunami'
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾2.16ï¼šæŸ±çŠ¶å›¾æ˜¾ç¤ºæœ‰å¤šå°‘åœ°éœ‡å¼•å‘äº†æµ·å•¸
- en: From this bar plot, we can see that most of the earthquakes did not result in
    tsunamis, and that less than one-third of the earthquakes did. This shows us that
    the dataset is slightly imbalanced.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™ä¸ªæŸ±çŠ¶å›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¤§å¤šæ•°åœ°éœ‡æ²¡æœ‰å¼•å‘æµ·å•¸ï¼Œè€Œä¸”ä¸åˆ°ä¸‰åˆ†ä¹‹ä¸€çš„åœ°éœ‡å¼•å‘äº†æµ·å•¸ã€‚è¿™æ˜¾ç¤ºå‡ºæ•°æ®é›†ç•¥å¾®å¤±è¡¡ã€‚
- en: 'Let''s look more closely at what these Matplotlib commands do:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ›´ä»”ç»†åœ°çœ‹ä¸€ä¸‹è¿™äº›Matplotlibå‘½ä»¤çš„ä½œç”¨ï¼š
- en: '`plt.figure(figsize=(8,6))`: This command defines how big our plot should be,
    by providing width and height values. This is always the first command before
    any plotting command is written.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plt.figure(figsize=(8,6))`ï¼šæ­¤å‘½ä»¤å®šä¹‰äº†æˆ‘ä»¬çš„å›¾è¡¨å¤§å°ï¼Œé€šè¿‡æä¾›å®½åº¦å’Œé«˜åº¦çš„å€¼ã€‚è¿™æ˜¯æ‰€æœ‰ç»˜å›¾å‘½ä»¤ä¹‹å‰çš„ç¬¬ä¸€æ¡å‘½ä»¤ã€‚'
- en: '`plt.xlabel()` and `plt.ylabel()`: These commands take a string as input, and
    allow us to specify what the labels for the *X* and *Y* axes on the plot should
    be.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plt.xlabel()` å’Œ `plt.ylabel()`ï¼šè¿™äº›å‘½ä»¤æ¥å—å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥ï¼Œå…è®¸æˆ‘ä»¬æŒ‡å®šå›¾è¡¨ä¸­*X*è½´å’Œ*Y*è½´çš„æ ‡ç­¾ã€‚'
- en: '`plt.show()`: This is the final command written when plotting that displays
    the plot inline within the Jupyter notebook.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plt.show()`ï¼šè¿™æ˜¯ç»˜å›¾æ—¶å†™å…¥çš„æœ€åä¸€æ¡å‘½ä»¤ï¼Œå®ƒå°†å›¾è¡¨ä»¥å†…è”æ–¹å¼æ˜¾ç¤ºåœ¨Jupyter Notebookä¸­ã€‚'
- en: Categorical Data
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç±»åˆ«æ•°æ®
- en: 'Categorical variables are ones that take discrete values representing different
    categories or levels of observation that can either be string objects, or integer
    values. For example, our target variable, `flag_tsunami`, is a categorical variable
    having two categories: `Tsu` and `No`.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«å˜é‡æ˜¯é‚£äº›å…·æœ‰ç¦»æ•£å€¼ï¼Œè¡¨ç¤ºä¸åŒç±»åˆ«æˆ–è§‚å¯Ÿæ°´å¹³çš„å˜é‡ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²å¯¹è±¡æˆ–æ•´æ•°å€¼ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬çš„ç›®æ ‡å˜é‡`flag_tsunami`æ˜¯ä¸€ä¸ªç±»åˆ«å˜é‡ï¼Œå…·æœ‰ä¸¤ä¸ªç±»åˆ«ï¼š`Tsu`å’Œ`No`ã€‚
- en: 'Categorical variables can be of two types:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«å˜é‡å¯ä»¥åˆ†ä¸ºä¸¤ç§ç±»å‹ï¼š
- en: '`location_name`. The values that this variable takes cannot be said to be ordered,
    that is, one location is not *greater* than the other. Similarly, more examples
    of such a variable would be color, types of footwear, ethnicity type, and so on.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`location_name`ã€‚è¿™ä¸ªå˜é‡çš„å€¼ä¸èƒ½è¯´æ˜¯æœ‰åºçš„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€ä¸ªåœ°ç‚¹å¹¶ä¸*å¤§äº*å¦ä¸€ä¸ªåœ°ç‚¹ã€‚ç±»ä¼¼çš„å˜é‡ç¤ºä¾‹è¿˜åŒ…æ‹¬é¢œè‰²ã€é‹ç±»ç±»å‹ã€ç§æ—ç±»å‹ç­‰ã€‚'
- en: '`damage_description`, since each value represents an increasing value of damage
    incurred. Another example could be day of the week, which would have values from
    Monday to Sunday, which have some order associated with them and we know that
    Thursday comes after Wednesday but before Friday.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`damage_description`ï¼Œå› ä¸ºæ¯ä¸ªå€¼è¡¨ç¤ºé€æ¸å¢åŠ çš„æŸå®³å€¼ã€‚å¦ä¸€ä¸ªä¾‹å­å¯ä»¥æ˜¯æ˜ŸæœŸå‡ ï¼Œå…¶å€¼ä»æ˜ŸæœŸä¸€åˆ°æ˜ŸæœŸå¤©ï¼Œå…·æœ‰ä¸€å®šçš„é¡ºåºå…³ç³»ï¼Œæˆ‘ä»¬çŸ¥é“æ˜ŸæœŸå››åœ¨æ˜ŸæœŸä¸‰ä¹‹åï¼Œä½†åœ¨æ˜ŸæœŸäº”ä¹‹å‰ã€‚'
- en: Although ordinal variables can be represented by object data types, they are
    often represented as numerical data types as well, often making it difficult to
    differentiate between them and continuous variables.
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å°½ç®¡æœ‰åºå˜é‡å¯ä»¥é€šè¿‡å¯¹è±¡æ•°æ®ç±»å‹è¡¨ç¤ºï¼Œä½†å®ƒä»¬é€šå¸¸ä¹Ÿè¡¨ç¤ºä¸ºæ•°å€¼æ•°æ®ç±»å‹ï¼Œè¿™é€šå¸¸ä½¿å¾—å®ƒä»¬ä¸è¿ç»­å˜é‡ä¹‹é—´çš„åŒºåˆ†å˜å¾—å›°éš¾ã€‚
- en: One of the major challenges faced when dealing with categorical variables in
    a dataset is high cardinality, that is, a large number of categories or distinct
    values with each value appearing a relatively small number of times. For example,
    `location_name` has a large number of unique values, with each value occurring
    a small fraction of times in the dataset.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†æ•°æ®é›†ä¸­çš„ç±»åˆ«å˜é‡æ—¶é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ä¹‹ä¸€æ˜¯é«˜åŸºæ•°ï¼Œå³å¤§é‡çš„ç±»åˆ«æˆ–ä¸åŒçš„å€¼ï¼Œå…¶ä¸­æ¯ä¸ªå€¼åœ¨æ•°æ®é›†ä¸­çš„å‡ºç°æ¬¡æ•°ç›¸å¯¹è¾ƒå°‘ã€‚ä¾‹å¦‚ï¼Œ`location_name`å…·æœ‰å¤§é‡çš„å”¯ä¸€å€¼ï¼Œæ¯ä¸ªå€¼åœ¨æ•°æ®é›†ä¸­çš„å‡ºç°é¢‘ç‡è¾ƒä½ã€‚
- en: Additionally, non-numerical categorical variables will always require some form
    of preprocessing to be converted into a numerical format so that they can be ingested
    for training by a machine learning model. It can be a challenge to encode categorical
    variables numerically without losing out on contextual information that despite
    being easy for humans to interpret (due to domain knowledge or otherwise just
    plain common sense), would be hard for a computer to automatically understand.
    For example, a geographical feature such as country or location name by itself
    would give no indication of the geographical proximity of different values, but
    that might just be an important featureâ€”what if earthquakes that occur at locations
    in South-East Asia trigger more tsunamis than those that occur in Europe? There
    would be no way of capturing that information by merely numerically encoding the
    feature.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œéæ•°å€¼å‹çš„ç±»åˆ«å˜é‡æ€»æ˜¯éœ€è¦æŸç§å½¢å¼çš„é¢„å¤„ç†ï¼Œå°†å…¶è½¬æ¢ä¸ºæ•°å€¼æ ¼å¼ï¼Œä»¥ä¾¿æœºå™¨å­¦ä¹ æ¨¡å‹èƒ½å¤Ÿè¯»å–å¹¶è¿›è¡Œè®­ç»ƒã€‚åœ¨æ²¡æœ‰ä¸¢å¤±ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•å°†ç±»åˆ«å˜é‡ç¼–ç ä¸ºæ•°å€¼å‹æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚å°½ç®¡è¿™äº›ä¿¡æ¯å¯¹äºäººç±»æ¥è¯´ï¼ˆç”±äºé¢†åŸŸçŸ¥è¯†æˆ–å¸¸è¯†ï¼‰éå¸¸å®¹æ˜“ç†è§£ï¼Œä½†è®¡ç®—æœºå´å¾ˆéš¾è‡ªåŠ¨ç†è§£ã€‚ä¾‹å¦‚ï¼Œåƒå›½å®¶æˆ–åœ°ç‚¹åç§°è¿™æ ·çš„åœ°ç†ç‰¹å¾æœ¬èº«å¹¶ä¸èƒ½è¡¨æ˜ä¸åŒå€¼ä¹‹é—´çš„åœ°ç†æ¥è¿‘æ€§ï¼Œä½†è¿™å¯èƒ½æ˜¯ä¸€ä¸ªé‡è¦ç‰¹å¾â€”â€”å¦‚æœå‘ç”Ÿåœ¨ä¸œå—äºšåœ°åŒºçš„åœ°éœ‡æ¯”æ¬§æ´²åœ°åŒºçš„åœ°éœ‡è§¦å‘æ›´å¤šæµ·å•¸å‘¢ï¼Ÿä»…ä»…é€šè¿‡æ•°å€¼ç¼–ç ç‰¹å¾ï¼Œæ— æ³•æ•è·è¿™äº›ä¿¡æ¯ã€‚
- en: 'Exercise 17: Datatypes for Categorical Variables'
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  17ï¼šç±»åˆ«å˜é‡çš„æ•°æ®ç±»å‹
- en: 'Let''s find which variables in our Earthquake dataset are categorical and which
    are continuous. As we now know, categorical variables can also have numerical
    values, so having a numeric data type doesn''t guarantee that a variable is continuous:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ‰¾å‡ºåœ°éœ‡æ•°æ®é›†ä¸­å“ªäº›å˜é‡æ˜¯ç±»åˆ«å‹çš„ï¼Œå“ªäº›æ˜¯è¿ç»­å‹çš„ã€‚æ­£å¦‚æˆ‘ä»¬ç°åœ¨æ‰€çŸ¥é“çš„ï¼Œç±»åˆ«å˜é‡ä¹Ÿå¯ä»¥å…·æœ‰æ•°å€¼å€¼ï¼Œå› æ­¤ï¼Œæ‹¥æœ‰æ•°å€¼æ•°æ®ç±»å‹å¹¶ä¸æ„å‘³ç€å˜é‡å°±æ˜¯è¿ç»­å‹çš„ï¼š
- en: 'Find all the columns that are numerical and object types. We use the `.select_dtypes()`
    method on the DataFrame to create a subset DataFrame having numeric (`np.number`)
    and categorical (`np.object`) columns, and then print the column names for each.
    For numeric columns, use this:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰¾å‡ºæ‰€æœ‰æ•°å€¼å‹å’Œå¯¹è±¡å‹çš„åˆ—ã€‚æˆ‘ä»¬åœ¨ DataFrame ä¸Šä½¿ç”¨ `.select_dtypes()` æ–¹æ³•ï¼Œåˆ›å»ºä¸€ä¸ªåŒ…å«æ•°å€¼å‹ï¼ˆ`np.number`ï¼‰å’Œç±»åˆ«å‹ï¼ˆ`np.object`ï¼‰åˆ—çš„å­é›†
    DataFrameï¼Œç„¶åæ‰“å°æ¯ä¸ªåˆ—çš„åˆ—åã€‚å¯¹äºæ•°å€¼åˆ—ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š
- en: '[PRE26]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output will be as follows:'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.17: All columns that are numerical ](img/C12622_02_17.jpg)'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.17ï¼šæ‰€æœ‰æ•°å€¼å‹çš„åˆ—](img/C12622_02_17.jpg)'
- en: 'Figure 2.17: All columns that are numerical'
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.17ï¼šæ‰€æœ‰æ•°å€¼å‹çš„åˆ—
- en: 'For categorical columns, use this:'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹äºç±»åˆ«åˆ—ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š
- en: '[PRE27]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output will be as follows:'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.18: All columns that are object types](img/C12622_02_18.jpg)'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.18ï¼šæ‰€æœ‰å¯¹è±¡ç±»å‹çš„åˆ—](img/C12622_02_18.jpg)'
- en: 'Figure 2.18: All columns that are object types'
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.18ï¼šæ‰€æœ‰å¯¹è±¡ç±»å‹çš„åˆ—
- en: Here, it is evident that the columns of object type are categorical variables.
    To differentiate between the categorical and continuous variables from the numeric
    columns, let's see how many unique values there are for each of these features.
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¾ç„¶å¯ä»¥çœ‹å‡ºï¼Œå¯¹è±¡ç±»å‹çš„åˆ—æ˜¯ç±»åˆ«å˜é‡ã€‚ä¸ºäº†åŒºåˆ†æ•°å€¼åˆ—ä¸­çš„ç±»åˆ«å˜é‡å’Œè¿ç»­å˜é‡ï¼Œè®©æˆ‘ä»¬æŸ¥çœ‹è¿™äº›ç‰¹å¾çš„å”¯ä¸€å€¼æ•°é‡ã€‚
- en: 'Find the number of unique values for numeric features. We use the `select_dtypes`
    method on the DataFrame to find the number of unique values in each column and
    sort the resulting series in ascending order. For numeric columns, use this:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰¾å‡ºæ•°å€¼ç‰¹å¾çš„å”¯ä¸€å€¼æ•°é‡ã€‚æˆ‘ä»¬åœ¨ DataFrame ä¸Šä½¿ç”¨ `select_dtypes` æ–¹æ³•ï¼Œæ‰¾åˆ°æ¯ä¸€åˆ—çš„å”¯ä¸€å€¼æ•°é‡ï¼Œå¹¶å°†ç»“æœåºåˆ—æŒ‰å‡åºæ’åºã€‚å¯¹äºæ•°å€¼åˆ—ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š
- en: '[PRE28]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output will be as follows:'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.19: Number of unique values for numeric features](img/C12622_02_19.jpg)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.19ï¼šæ•°å€¼ç‰¹å¾çš„å”¯ä¸€å€¼æ•°é‡](img/C12622_02_19.jpg)'
- en: 'Figure 2.19: Number of unique values for numeric features'
  id: totrans-259
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.19ï¼šæ•°å€¼ç‰¹å¾çš„å”¯ä¸€å€¼æ•°é‡
- en: 'For categorical columns, use this:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç±»åˆ«åˆ—ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š
- en: '[PRE29]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output will be as follows:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.20: Number of unique values for categorical columns](img/C12622_02_20.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.20ï¼šç±»åˆ«åˆ—çš„å”¯ä¸€å€¼æ•°é‡](img/C12622_02_20.jpg)'
- en: 'Figure 2.20: Number of unique values for categorical columns'
  id: totrans-264
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.20ï¼šåˆ†ç±»åˆ—çš„å”¯ä¸€å€¼æ•°é‡
- en: For the numeric variables, we can see that the top nine have significantly fewer
    unique values than the remaining rows, and it's likely that these are categorical
    variables. However, we must keep in mind that it is possible that some of them
    might just be continuous variables with a low range of rounded-up values. Also,
    `month` and `day` would not be considered categorical variables here.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ•°å€¼å‹å˜é‡ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å‰ä¹ä¸ªå˜é‡çš„å”¯ä¸€å€¼æ˜¾è‘—å°‘äºå…¶ä½™è¡Œï¼Œè¿™äº›å˜é‡å¾ˆå¯èƒ½æ˜¯åˆ†ç±»å˜é‡ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¿…é¡»è®°ä½ï¼Œå…¶ä¸­ä¸€äº›å¯èƒ½åªæ˜¯å…·æœ‰è¾ƒå°èŒƒå›´çš„å››èˆäº”å…¥å€¼çš„è¿ç»­å˜é‡ã€‚å¦å¤–ï¼Œ`month`
    å’Œ `day` åœ¨è¿™é‡Œä¸ä¼šè¢«è§†ä¸ºåˆ†ç±»å˜é‡ã€‚
- en: 'Exercise 18: Calculating Category Value Counts'
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  18ï¼šè®¡ç®—ç±»åˆ«å€¼è®¡æ•°
- en: 'For columns with categorical values, it would be useful to see what the unique
    values (categories) of the feature are, along with what the frequencies of these
    categories are, that is, how much does each distinct value occur in the dataset.
    Let''s find the number of occurrences of each `0` to `4` label and `NaN` values
    for the `injuries_description` categorical variable:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå…·æœ‰åˆ†ç±»å€¼çš„åˆ—ï¼ŒæŸ¥çœ‹è¯¥ç‰¹å¾çš„å”¯ä¸€å€¼ï¼ˆç±»åˆ«ï¼‰ä»¥åŠè¿™äº›ç±»åˆ«çš„é¢‘ç‡å°†éå¸¸æœ‰ç”¨ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸ªä¸åŒçš„å€¼åœ¨æ•°æ®é›†ä¸­å‡ºç°çš„æ¬¡æ•°ã€‚æˆ‘ä»¬æ¥æ‰¾å‡º `injuries_description`
    åˆ†ç±»å˜é‡ä¸­æ¯ä¸ª `0` åˆ° `4` æ ‡ç­¾å’Œ `NaN` å€¼çš„å‡ºç°æ¬¡æ•°ï¼š
- en: 'Use the `value_counts()` function on the `injuries_description` column to find
    the frequency of each category. Using `value_counts` gives us the frequencies
    of each value in decreasing order in the form of a pandas series:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹ `injuries_description` åˆ—ä½¿ç”¨ `value_counts()` å‡½æ•°æ¥æ‰¾å‡ºæ¯ä¸ªç±»åˆ«çš„é¢‘ç‡ã€‚ä½¿ç”¨ `value_counts`
    ä¼šä»¥é™åºå½¢å¼è¿”å›æ¯ä¸ªå€¼çš„é¢‘ç‡ï¼Œå¹¶ä»¥ pandas ç³»åˆ—çš„å½¢å¼æ˜¾ç¤ºï¼š
- en: '[PRE30]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output should be as follows:'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºåº”å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.21: Frequency of each category](img/C12622_02_21.jpg)'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.21ï¼šæ¯ä¸ªç±»åˆ«çš„é¢‘ç‡](img/C12622_02_21.jpg)'
- en: 'Figure 2.21: Frequency of each category'
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.21ï¼šæ¯ä¸ªç±»åˆ«çš„é¢‘ç‡
- en: 'Sort the values in increasing order of the ordinal variable. If we want the
    frequencies in the order of the values themselves, we can reset the index to give
    us a DataFrame and sort values by the index (that is, the ordinal variable):'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒ‰ç…§é¡ºåºå˜é‡çš„å‡åºæ’åºè¿™äº›å€¼ã€‚å¦‚æœæˆ‘ä»¬å¸Œæœ›æŒ‰å€¼æœ¬èº«çš„é¡ºåºæ˜¾ç¤ºé¢‘ç‡ï¼Œæˆ‘ä»¬å¯ä»¥é‡ç½®ç´¢å¼•ï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ª DataFrameï¼Œå¹¶æŒ‰ç´¢å¼•ï¼ˆå³é¡ºåºå˜é‡ï¼‰æ’åºå€¼ï¼š
- en: '[PRE31]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![Figure 2.22: Sorted values](img/C12622_02_22.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.22ï¼šæ’åºåçš„å€¼](img/C12622_02_22.jpg)'
- en: 'Figure 2.22: Sorted values'
  id: totrans-276
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.22ï¼šæ’åºåçš„å€¼
- en: 'Exercise 19: Plotting a Pie Chart'
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  19ï¼šç»˜åˆ¶é¥¼å›¾
- en: 'Since our target variable in our sample data is categorical, the example in
    *Exercise 16: Plotting a Bar Chart* showed us one way of visualizing how the categorical
    values are distributed (using a bar chart). Another plot that can make it easy
    to see how each category functions as a fraction of the overall dataset is a pie
    chart. Let''s plot a pie chart to visualize the distribution of the discrete values
    of the `damage_description` variable:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä»¬ç¤ºä¾‹æ•°æ®ä¸­çš„ç›®æ ‡å˜é‡æ˜¯åˆ†ç±»çš„ï¼Œ*ç»ƒä¹  16ï¼šç»˜åˆ¶æ¡å½¢å›¾* ä¸­çš„ç¤ºä¾‹å±•ç¤ºäº†å¯è§†åŒ–åˆ†ç±»å€¼åˆ†å¸ƒçš„ä¸€ç§æ–¹å¼ï¼ˆä½¿ç”¨æ¡å½¢å›¾ï¼‰ã€‚å¦ä¸€ç§å¯ä»¥å¸®åŠ©æˆ‘ä»¬è½»æ¾æŸ¥çœ‹æ¯ä¸ªç±»åˆ«åœ¨æ•´ä¸ªæ•°æ®é›†ä¸­æ‰€å æ¯”ä¾‹çš„å›¾è¡¨æ˜¯é¥¼å›¾ã€‚è®©æˆ‘ä»¬ç»˜åˆ¶ä¸€ä¸ªé¥¼å›¾æ¥å¯è§†åŒ–
    `damage_description` å˜é‡çš„ç¦»æ•£å€¼åˆ†å¸ƒï¼š
- en: 'Format the data into the form that needs to be plotted. Here, we run `value_counts()`
    over the column and sort the series by index:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†æ•°æ®æ ¼å¼åŒ–æˆéœ€è¦ç»˜åˆ¶çš„å½¢å¼ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯¹è¯¥åˆ—ä½¿ç”¨ `value_counts()` å¹¶æŒ‰ç´¢å¼•æ’åºç³»åˆ—ï¼š
- en: '[PRE32]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Plot the pie chart. The `plt.pie()` category plots the pie chart using the
    count data. We will use the same three steps for plotting as described in *Exercise
    16: Plotting a Bar Chart*:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶é¥¼å›¾ã€‚`plt.pie()` åˆ†ç±»å‡½æ•°ä½¿ç”¨è®¡æ•°æ•°æ®ç»˜åˆ¶é¥¼å›¾ã€‚æˆ‘ä»¬å°†æŒ‰ç…§ *ç»ƒä¹  16ï¼šç»˜åˆ¶æ¡å½¢å›¾* ä¸­æè¿°çš„ç›¸åŒä¸‰æ­¥è¿›è¡Œç»˜å›¾ï¼š
- en: '[PRE33]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output will be:'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå°†æ˜¯ï¼š
- en: '![Figure 2.23: Pie chart showing counts for damage_description categories](img/C12622_02_23.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.23ï¼šæ˜¾ç¤º `damage_description` ç±»åˆ«è®¡æ•°çš„é¥¼å›¾](img/C12622_02_23.jpg)'
- en: 'Figure 2.23: Pie chart showing counts for damage_description categories'
  id: totrans-285
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.23ï¼šæ˜¾ç¤º `damage_description` ç±»åˆ«è®¡æ•°çš„é¥¼å›¾
- en: Continuous Data
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¿ç»­æ•°æ®
- en: 'Continuous variables can take any number of values and are usually integer
    (for example, number of deaths) or float data types (for example, the height of
    a mountain). It''s useful to get an idea of the basic statistics of the values
    in the feature: the minimum, maximum, and percentile values we see from the output
    of the `describe()` function gives us a fair estimate of this.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ç»­å˜é‡å¯ä»¥å–ä»»æ„æ•°é‡çš„å€¼ï¼Œé€šå¸¸æ˜¯æ•´æ•°ï¼ˆä¾‹å¦‚ï¼Œæ­»äº¡äººæ•°ï¼‰æˆ–æµ®åŠ¨æ•°æ®ç±»å‹ï¼ˆä¾‹å¦‚ï¼Œå±±è„‰çš„é«˜åº¦ï¼‰ã€‚äº†è§£ç‰¹å¾ä¸­å€¼çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯æ˜¯éå¸¸æœ‰ç”¨çš„ï¼š`describe()`
    å‡½æ•°çš„è¾“å‡ºæ˜¾ç¤ºçš„æœ€å°å€¼ã€æœ€å¤§å€¼å’Œç™¾åˆ†ä½æ•°ç»™æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªåˆç†çš„ä¼°ç®—ã€‚
- en: However, for continuous variables, it is also very useful to see how the values
    are distributed in the range they operate in. Since we cannot simply find the
    counts of individual values, instead we order the values in ascending order, group
    them into evenly-sized intervals, and find the counts for each interval. This
    gives us the underlying frequency distribution, and plotting this gives us a histogram,
    which allows us to examine the shape, central values, and amount of variability
    in the data.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå¯¹äºè¿ç»­å˜é‡æ¥è¯´ï¼Œäº†è§£å…¶åœ¨æ“ä½œèŒƒå›´å†…çš„åˆ†å¸ƒæƒ…å†µä¹Ÿéå¸¸æœ‰ç”¨ã€‚ç”±äºæˆ‘ä»¬ä¸èƒ½ç®€å•åœ°è®¡ç®—å„ä¸ªå€¼çš„è®¡æ•°ï¼Œæˆ‘ä»¬ä¼šå°†å€¼æŒ‰å‡åºæ’åˆ—ï¼Œå°†å…¶åˆ†ç»„ä¸ºç­‰é—´éš”çš„åŒºé—´ï¼Œç„¶åè®¡ç®—æ¯ä¸ªåŒºé—´çš„è®¡æ•°ã€‚è¿™ä¸ºæˆ‘ä»¬æä¾›äº†åº•å±‚çš„é¢‘ç‡åˆ†å¸ƒï¼Œç»˜åˆ¶è¯¥åˆ†å¸ƒä¾¿èƒ½å¾—åˆ°ç›´æ–¹å›¾ï¼Œä»è€Œè®©æˆ‘ä»¬æŸ¥çœ‹æ•°æ®çš„å½¢æ€ã€ä¸­å¿ƒå€¼ä»¥åŠå˜å¼‚æ€§ã€‚
- en: Histograms give us an easy view of the data that we're looking at. They tell
    us about the behavior of the values at a glance in terms of the underlying distribution
    (for example, a normal or exponential distribution), the presence of outliers,
    skewness, and more.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: ç›´æ–¹å›¾ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€æ´çš„è§†è§’ï¼Œå¸®åŠ©æˆ‘ä»¬äº†è§£æ­£åœ¨æŸ¥çœ‹çš„æ•°æ®ã€‚å®ƒä»¬è®©æˆ‘ä»¬ä¸€ç›®äº†ç„¶åœ°çœ‹åˆ°æ•°æ®çš„è¡Œä¸ºï¼Œæ­ç¤ºäº†åº•å±‚åˆ†å¸ƒï¼ˆä¾‹å¦‚æ­£æ€åˆ†å¸ƒæˆ–æŒ‡æ•°åˆ†å¸ƒï¼‰ã€å¼‚å¸¸å€¼ã€ååº¦ç­‰ä¿¡æ¯ã€‚
- en: Note
  id: totrans-290
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ³¨æ„
- en: It is easy to get confused between a bar chart and a histogram. The major difference
    is that a histogram is used to plot continuous data that has been binned to visualize
    the frequency distribution, while bar charts can be used for a variety of other
    use cases, including to represent categorical variables as we have done. Additionally,
    it is not just the height of the bar that indicates the frequency of that bin,
    but also the width of the bin itself, which is not the case in a bar chart.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå®¹æ˜“å°†æ¡å½¢å›¾ä¸ç›´æ–¹å›¾æ··æ·†ã€‚ä¸»è¦çš„åŒºåˆ«åœ¨äºï¼Œç›´æ–¹å›¾ç”¨äºç»˜åˆ¶å·²è¢«åˆ†ç»„çš„è¿ç»­æ•°æ®ä»¥å¯è§†åŒ–é¢‘ç‡åˆ†å¸ƒï¼Œè€Œæ¡å½¢å›¾å¯ä»¥ç”¨äºå¤šç§å…¶ä»–ç”¨é€”ï¼ŒåŒ…æ‹¬è¡¨ç¤ºæˆ‘ä»¬ä¹‹å‰å¤„ç†çš„ç±»åˆ«å˜é‡ã€‚æ­¤å¤–ï¼Œæ¡å½¢å›¾ä¸­çš„æ¡å½¢é«˜åº¦è¡¨ç¤ºè¯¥ç®±å­çš„é¢‘ç‡ï¼Œä½†ç›´æ–¹å›¾ä¸­çš„å®½åº¦ä¹Ÿä¼šå½±å“é¢‘ç‡çš„è¡¨ç¤ºï¼Œè¿™åœ¨æ¡å½¢å›¾ä¸­å¹¶ä¸é€‚ç”¨ã€‚
- en: One of the most common frequency distributions is a Gaussian (or normal) distribution.
    This is a symmetric distribution that has a bell-shaped curve, which indicates
    that the values near the middle of the range have the highest occurrences in the
    dataset with a symmetrically decreasing frequency of occurrences as we move away
    from the middle.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å¸¸è§çš„é¢‘ç‡åˆ†å¸ƒä¹‹ä¸€æ˜¯é«˜æ–¯ï¼ˆæˆ–æ­£æ€ï¼‰åˆ†å¸ƒã€‚è¿™æ˜¯ä¸€ç§å¯¹ç§°åˆ†å¸ƒï¼Œå…·æœ‰é’Ÿå½¢æ›²çº¿ï¼Œè¡¨ç¤ºæ¥è¿‘ä¸­é—´å€¼çš„èŒƒå›´åœ¨æ•°æ®é›†ä¸­å‡ºç°é¢‘ç‡æœ€é«˜ï¼Œéšç€è¿œç¦»ä¸­é—´éƒ¨åˆ†ï¼Œé¢‘ç‡å¯¹ç§°æ€§åœ°å‡å°‘ã€‚
- en: It is a probability distribution and the area under the curve equals one.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œæ›²çº¿ä¸‹çš„é¢ç§¯ç­‰äºä¸€ã€‚
- en: '![Figure 2.24: Normal distribution](img/C12622_02_24.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾2.24ï¼šæ­£æ€åˆ†å¸ƒ](img/C12622_02_24.jpg)'
- en: 'Figure 2.24: Normal distribution'
  id: totrans-295
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾2.24ï¼šæ­£æ€åˆ†å¸ƒ
- en: '**Skewness**'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '**ååº¦**'
- en: A distribution is said to be skewed if it is not symmetric in nature, and skewness
    measures the asymmetry of a variable about its mean. The value can be positive
    or negative (or undefined). In the former case, the tail is on the right-hand
    side of the distribution, while the latter indicates that the tail is on the left-hand
    side.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸€ä¸ªåˆ†å¸ƒä¸æ˜¯å¯¹ç§°çš„ï¼Œæˆ‘ä»¬ç§°å…¶ä¸ºåæ–œçš„ï¼Œååº¦è¡¡é‡çš„æ˜¯å˜é‡ç›¸å¯¹äºå…¶å‡å€¼çš„éå¯¹ç§°æ€§ã€‚ååº¦çš„å€¼å¯ä»¥æ˜¯æ­£å€¼ã€è´Ÿå€¼ï¼ˆæˆ–æœªå®šä¹‰ï¼‰ã€‚åœ¨å‰ä¸€ç§æƒ…å†µä¸‹ï¼Œå°¾å·´ä½äºåˆ†å¸ƒçš„å³ä¾§ï¼Œè€Œåä¸€ç§æƒ…å†µåˆ™è¡¨ç¤ºå°¾å·´ä½äºå·¦ä¾§ã€‚
- en: However, it must be noted that a thick and short tail would have the same effect
    on the value of skewness as a long, thin tail.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå¿…é¡»æ³¨æ„çš„æ˜¯ï¼Œåšè€ŒçŸ­çš„å°¾éƒ¨å¯¹ååº¦çš„å½±å“ä¸é•¿è€Œç»†çš„å°¾éƒ¨ç›¸åŒã€‚
- en: '**Kurtosis**'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '**å³°åº¦**'
- en: Kurtosis is a measure of the *tailedness* of the distribution of a variable
    and is used to measure the presence of outliers in one tail versus the other.
    A high value of kurtosis indicates a fatter tail and the presence of outliers.
    In a similar way to the concept of skewness, kurtosis also describes the shape
    of the distribution.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: å³°åº¦æ˜¯è¡¡é‡å˜é‡åˆ†å¸ƒçš„*å°¾éƒ¨å½¢æ€*çš„ä¸€ä¸ªæŒ‡æ ‡ï¼Œç”¨æ¥è¡¡é‡ä¸€ä¾§å°¾éƒ¨æ˜¯å¦å­˜åœ¨å¼‚å¸¸å€¼ã€‚è¾ƒé«˜çš„å³°åº¦å€¼è¡¨ç¤ºå°¾éƒ¨è¾ƒåšï¼Œä¸”å­˜åœ¨å¼‚å¸¸å€¼ã€‚ä¸ååº¦çš„æ¦‚å¿µç±»ä¼¼ï¼Œå³°åº¦ä¹Ÿæè¿°äº†åˆ†å¸ƒçš„å½¢æ€ã€‚
- en: 'Exercise 20: Plotting a Histogram'
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹ 20ï¼šç»˜åˆ¶ç›´æ–¹å›¾
- en: 'Let''s plot the histogram for the `eq_primary` feature using the Seaborn library:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä½¿ç”¨Seabornåº“ç»˜åˆ¶`eq_primary`ç‰¹å¾çš„ç›´æ–¹å›¾ï¼š
- en: 'Use `plt.figure()` to initiate the plotting:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`plt.figure()`æ¥å¯åŠ¨ç»˜å›¾ï¼š
- en: '[PRE34]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '`sns.distplot()` is the primary command that we will use to plot the histogram.
    The first parameter is the one-dimensional data over which to plot the histogram,
    the bins parameter defines the number and size of the bins. Use this as follows:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`sns.distplot()`æ˜¯æˆ‘ä»¬ç”¨æ¥ç»˜åˆ¶ç›´æ–¹å›¾çš„ä¸»è¦å‘½ä»¤ã€‚ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ç”¨æ¥ç»˜åˆ¶ç›´æ–¹å›¾çš„å•ç»´æ•°æ®ï¼Œbinså‚æ•°å®šä¹‰äº†ç®±å­çš„æ•°é‡å’Œå¤§å°ã€‚ä½¿ç”¨æ–¹å¼å¦‚ä¸‹ï¼š'
- en: '[PRE35]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Display the plot using `plt.show()`:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `plt.show()` æ˜¾ç¤ºå›¾è¡¨ï¼š
- en: '[PRE36]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output will be as follows:'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š
- en: '![Figure 2.25: Histogram for the eq_primary feature](img/C12622_02_25.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.25ï¼šeq_primary ç‰¹å¾çš„ç›´æ–¹å›¾](img/C12622_02_25.jpg)'
- en: 'Figure 2.25: Histogram for the eq_primary feature'
  id: totrans-311
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.25ï¼šeq_primary ç‰¹å¾çš„ç›´æ–¹å›¾
- en: The plot gives us a normed (or normalized) histogram, which means that the area
    under the bars of the histogram equals unity. Additionally, the line over the
    histogram is the **kernel density estimate**, which gives us an idea of what the
    probability distribution for the variable would look like.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥å›¾ç»™å‡ºäº†ä¸€ä¸ªæ ‡å‡†åŒ–ï¼ˆæˆ–å½’ä¸€åŒ–ï¼‰ç›´æ–¹å›¾ï¼Œè¿™æ„å‘³ç€ç›´æ–¹å›¾ä¸‹æ–¹çš„åŒºåŸŸæ€»å’Œä¸º1ã€‚æ­¤å¤–ï¼Œç›´æ–¹å›¾ä¸Šçš„æ›²çº¿æ˜¯**æ ¸å¯†åº¦ä¼°è®¡**ï¼Œå®ƒç»™æˆ‘ä»¬æä¾›äº†å˜é‡çš„æ¦‚ç‡åˆ†å¸ƒçš„å½¢æ€ã€‚
- en: From the plot, we can see that the values of `eq_primary` lie mostly between
    5 and 8, which means that most earthquakes had a magnitude with a moderate to
    high value, with barely any earthquakes having a low or very high magnitude.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å›¾ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œ`eq_primary` çš„å€¼å¤§å¤šä½äº 5 åˆ° 8 ä¹‹é—´ï¼Œè¿™æ„å‘³ç€å¤§å¤šæ•°åœ°éœ‡çš„éœ‡çº§æ˜¯ä¸­ç­‰åˆ°é«˜å€¼ï¼Œå‡ ä¹æ²¡æœ‰åœ°éœ‡éœ‡çº§éå¸¸ä½æˆ–éå¸¸é«˜ã€‚
- en: 'Exercise 21: Skew and Kurtosis'
  id: totrans-314
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  21ï¼šååº¦ä¸å³°åº¦
- en: 'Let''s calculate the skew and kurtosis values for all the features in the dataset
    using the core pandas functions available to us:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä½¿ç”¨ pandas æ ¸å¿ƒå‡½æ•°è®¡ç®—æ•°æ®é›†ä¸­æ‰€æœ‰ç‰¹å¾çš„ååº¦å’Œå³°åº¦å€¼ï¼š
- en: 'Use the `.skew()` DataFrame method to calculate the skew for all features and
    then sort the values in ascending order:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `.skew()` æ•°æ®æ¡†æ–¹æ³•è®¡ç®—æ‰€æœ‰ç‰¹å¾çš„ååº¦ï¼Œç„¶åæŒ‰å‡åºæ’åºå€¼ï¼š
- en: '[PRE37]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output will be:'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå°†æ˜¯ï¼š
- en: '![](img/C12622_02_26.jpg)'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C12622_02_26.jpg)'
- en: 'Figure 2.26: Skew values for all the features in the dataset'
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.26ï¼šæ•°æ®é›†ä¸­æ‰€æœ‰ç‰¹å¾çš„ååº¦å€¼
- en: 'Use the `.kurt()` DataFrame method to calculate the kurtosis for all features:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `.kurt()` æ•°æ®æ¡†æ–¹æ³•è®¡ç®—æ‰€æœ‰ç‰¹å¾çš„å³°åº¦ï¼š
- en: '[PRE38]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output will be:'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå°†æ˜¯ï¼š
- en: '![Figure 2.27: Kurtosis values for all the features in the dataset](img/C12622_02_27.jpg)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.27ï¼šæ•°æ®é›†ä¸­æ‰€æœ‰ç‰¹å¾çš„å³°åº¦å€¼](img/C12622_02_27.jpg)'
- en: 'Figure 2.27: Kurtosis values for all the features in the dataset'
  id: totrans-325
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.27ï¼šæ•°æ®é›†ä¸­æ‰€æœ‰ç‰¹å¾çš„å³°åº¦å€¼
- en: Here, we can see that the kurtosis values for some variables deviate significantly
    from 0\. This means that these columns have a long tail. But the values that are
    at the tail end of these variables (which indicate the number of people dead,
    injured, and the monetary value of damage), in our case, may be outliers that
    we may need to pay special attention to. Larger values might, in fact, indicate
    an additional force that added to the devastation caused by an earthquake, that
    is, a tsunami.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æŸäº›å˜é‡çš„å³°åº¦å€¼æ˜¾è‘—åç¦»0ã€‚è¿™æ„å‘³ç€è¿™äº›åˆ—å…·æœ‰é•¿å°¾ã€‚ä½†æ˜¯ï¼Œè¿™äº›å˜é‡å°¾éƒ¨çš„å€¼ï¼ˆå³è¡¨ç¤ºæ­»äº¡ã€å—ä¼¤äººæ•°ä»¥åŠæŸå¤±é‡‘é¢çš„æ•°å€¼ï¼‰åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œå¯èƒ½æ˜¯ç¦»ç¾¤å€¼ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦ç‰¹åˆ«å…³æ³¨å®ƒä»¬ã€‚è¾ƒå¤§çš„å€¼å¯èƒ½å®é™…ä¸Šè¡¨ç¤ºé¢å¤–çš„å› ç´ ï¼Œå¢åŠ äº†ç”±åœ°éœ‡å¼•èµ·çš„ç ´åï¼Œå³æµ·å•¸ã€‚
- en: 'Activity 3: Visually Representing the Distribution of Values'
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ´»åŠ¨ 3ï¼šå¯è§†åŒ–è¡¨ç¤ºå€¼çš„åˆ†å¸ƒ
- en: 'In this activity, we will revise what we learned in the previous section about
    different types of data. We will use the same dataset we used in *Activity 2:
    Summary Statistics and Missing Values*, that is, *House Prices: Advanced Regression
    Techniques* (available at [https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)
    or on GitHub at [https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python](https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python)).
    We''ll use different types of plots to visually represent the distribution of
    values for this dataset.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªæ´»åŠ¨ä¸­ï¼Œæˆ‘ä»¬å°†å¤ä¹ ä¸Šä¸€èŠ‚å…³äºä¸åŒç±»å‹æ•°æ®çš„å†…å®¹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸*æ´»åŠ¨ 2ï¼šæ‘˜è¦ç»Ÿè®¡å’Œç¼ºå¤±å€¼*ä¸­ç›¸åŒçš„æ•°æ®é›†ï¼Œå³ *æˆ¿ä»·ï¼šé«˜çº§å›å½’æŠ€æœ¯*ï¼ˆå¯ä»¥åœ¨[https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)
    æˆ–åœ¨ GitHub ä¸Šæ‰¾åˆ° [https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python](https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python)ï¼‰ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸åŒç±»å‹çš„å›¾è¡¨æ¥å¯è§†åŒ–è¡¨ç¤ºè¯¥æ•°æ®é›†çš„å€¼åˆ†å¸ƒã€‚
- en: 'The steps to be performed are as follows:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰§è¡Œçš„æ­¥éª¤å¦‚ä¸‹ï¼š
- en: Plot a histogram using Matplotlib for the target variable, `SalePrice`.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Matplotlib ç»˜åˆ¶ç›®æ ‡å˜é‡ `SalePrice` çš„ç›´æ–¹å›¾ã€‚
- en: Find the number of unique values within each column having an object type.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰¾å‡ºæ¯ä¸ªå¯¹è±¡ç±»å‹åˆ—ä¸­å”¯ä¸€å€¼çš„æ•°é‡ã€‚
- en: Create a DataFrame representing the number of occurrences for each categorical
    value in the `HouseStyle` column.
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªæ•°æ®æ¡†ï¼Œè¡¨ç¤º `HouseStyle` åˆ—ä¸­æ¯ä¸ªç±»åˆ«å€¼çš„å‡ºç°æ¬¡æ•°ã€‚
- en: Plot a pie chart representing these counts.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶ä¸€ä¸ªé¥¼å›¾ï¼Œè¡¨ç¤ºè¿™äº›è®¡æ•°ã€‚
- en: Find the number of unique values within each column having a number type.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŸ¥æ‰¾æ¯ä¸ªå…·æœ‰æ•°å­—ç±»å‹çš„åˆ—ä¸­å”¯ä¸€å€¼çš„æ•°é‡ã€‚
- en: Plot a histogram using Seaborn for the `LotArea` variable.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Seabornç»˜åˆ¶`LotArea`å˜é‡çš„ç›´æ–¹å›¾ã€‚
- en: Calculate the skew and kurtosis values for the values in each column.
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¯åˆ—å€¼çš„ååº¦å’Œå³°åº¦å€¼ã€‚
- en: Note
  id: totrans-337
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ³¨æ„
- en: The solution for this activity can be found on page 312.
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ­¤æ´»åŠ¨çš„è§£å†³æ–¹æ¡ˆå¯ä»¥åœ¨ç¬¬312é¡µæ‰¾åˆ°ã€‚
- en: Relationships within the Data
  id: totrans-339
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®ä¸­çš„å…³ç³»
- en: 'There are two reasons why it is important to find relationships between variables
    in the data:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°æ•°æ®ä¸­å˜é‡ä¹‹é—´å…³ç³»çš„é‡è¦æ€§æœ‰ä¸¤ä¸ªåŸå› ï¼š
- en: Finding which features are potentially important can be deemed essential, since
    finding ones that have a strong relationship with the target variable will aid
    in the feature selection process.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¾å‡ºå“ªäº›ç‰¹å¾å¯èƒ½æ˜¯é‡è¦çš„å¯ä»¥è¢«è®¤ä¸ºæ˜¯è‡³å…³é‡è¦çš„ï¼Œå› ä¸ºæ‰¾åˆ°ä¸ç›®æ ‡å˜é‡æœ‰å¼ºçƒˆå…³ç³»çš„ç‰¹å¾å°†æœ‰åŠ©äºç‰¹å¾é€‰æ‹©è¿‡ç¨‹ã€‚
- en: Finding relationships between different features themselves can be useful, since
    variables in the dataset are usually never completely independent of every other
    variable and this can affect our modeling in a number of ways.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°ä¸åŒç‰¹å¾ä¹‹é—´çš„å…³ç³»æ˜¯æœ‰ç”¨çš„ï¼Œå› ä¸ºæ•°æ®é›†ä¸­çš„å˜é‡é€šå¸¸ä¸å¯èƒ½å®Œå…¨ç‹¬ç«‹äºå…¶ä»–æ‰€æœ‰å˜é‡ï¼Œè€Œè¿™å¯èƒ½ä¼šä»¥å¤šç§æ–¹å¼å½±å“æˆ‘ä»¬çš„å»ºæ¨¡ã€‚
- en: Now, there are a number of ways we can visualize these relationships, and this
    really depends on the types of variable we are trying to find the relationship
    between, and how many we are considering as part of the equation or comparison.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰è®¸å¤šæ–¹æ³•å¯ä»¥å¯è§†åŒ–è¿™äº›å…³ç³»ï¼Œå…·ä½“æ–¹æ³•å–å†³äºæˆ‘ä»¬è¯•å›¾æ‰¾åˆ°å…³ç³»çš„å˜é‡ç±»å‹ï¼Œä»¥åŠæˆ‘ä»¬è€ƒè™‘ä½œä¸ºæ–¹ç¨‹æˆ–æ¯”è¾ƒçš„ä¸€éƒ¨åˆ†çš„å˜é‡æ•°é‡ã€‚
- en: Relationship between Two Continuous Variables
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸¤ä¸ªè¿ç»­å˜é‡ä¹‹é—´çš„å…³ç³»
- en: To find a relationship between two continuous variables is basically to see
    how one varies as the value of the other is increased. The most common way to
    visualize this would be using a scatter plot, in which we take each variable along
    a single axis (the *X* and *Y* axes in a two-dimensional plane when we have two
    variables) and plot each data point using a marker in the *X-Y* plane. This visualization
    gives us a good idea of whether any kind of relationship exists between the two
    variables at all.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°ä¸¤ä¸ªè¿ç»­å˜é‡ä¹‹é—´çš„å…³ç³»ï¼ŒåŸºæœ¬ä¸Šæ˜¯çœ‹ä¸€ä¸ªå˜é‡çš„å€¼å¢åŠ æ—¶å¦ä¸€ä¸ªå˜é‡å¦‚ä½•å˜åŒ–ã€‚æœ€å¸¸è§çš„å¯è§†åŒ–æ–¹æ³•æ˜¯ä½¿ç”¨æ•£ç‚¹å›¾ï¼Œå…¶ä¸­æˆ‘ä»¬å°†æ¯ä¸ªå˜é‡æ²¿ä¸€ä¸ªè½´ï¼ˆå½“æˆ‘ä»¬æœ‰ä¸¤ä¸ªå˜é‡æ—¶ï¼Œåœ¨äºŒç»´å¹³é¢ä¸­çš„*X*å’Œ*Y*è½´ï¼‰ç»˜åˆ¶ï¼Œå¹¶ä½¿ç”¨æ ‡è®°åœ¨*X-Y*å¹³é¢ä¸­ç»˜åˆ¶æ¯ä¸ªæ•°æ®ç‚¹ã€‚è¿™ç§å¯è§†åŒ–èƒ½å¤Ÿå¾ˆå¥½åœ°å±•ç¤ºè¿™ä¸¤ä¸ªå˜é‡ä¹‹é—´æ˜¯å¦å­˜åœ¨æŸç§å…³ç³»ã€‚
- en: If we want to quantize the relationship between the two variables, however,
    the most common method is to find the correlation between them. If the target
    variable is continuous and it has a high degree of correlation with another variable,
    this is an indication that the feature would be an important part of the model.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬æƒ³é‡åŒ–ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„å…³ç³»ï¼Œæœ€å¸¸ç”¨çš„æ–¹æ³•æ˜¯æ‰¾åˆ°å®ƒä»¬ä¹‹é—´çš„ç›¸å…³æ€§ã€‚å¦‚æœç›®æ ‡å˜é‡æ˜¯è¿ç»­çš„ï¼Œå¹¶ä¸”ä¸å¦ä¸€ä¸ªå˜é‡é«˜åº¦ç›¸å…³ï¼Œè¿™è¡¨æ˜è¯¥ç‰¹å¾åœ¨æ¨¡å‹ä¸­æ˜¯ä¸€ä¸ªé‡è¦éƒ¨åˆ†ã€‚
- en: '**Pearson''s Coefficient of Correlation**'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '**çš®å°”é€Šç›¸å…³ç³»æ•°**'
- en: '**Pearson''s Coefficient of Correlation** is a correlation coefficient that
    is commonly used to show the linear relationship between a pair of variables.
    The formula returns a value between -1 and +1, where:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '**çš®å°”é€Šç›¸å…³ç³»æ•°**æ˜¯ä¸€ç§å¸¸ç”¨çš„ç›¸å…³ç³»æ•°ï¼Œç”¨æ¥æ˜¾ç¤ºä¸€å¯¹å˜é‡ä¹‹é—´çš„çº¿æ€§å…³ç³»ã€‚å…¬å¼è¿”å›ä¸€ä¸ªä»‹äº-1å’Œ+1ä¹‹é—´çš„å€¼ï¼Œå…¶ä¸­ï¼š'
- en: +1 indicates a strong positive relationship
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: +1 è¡¨ç¤ºå¼ºæ­£ç›¸å…³
- en: -1 indicates a strong negative relationship
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -1 è¡¨ç¤ºå¼ºè´Ÿç›¸å…³
- en: 0 indicates no relationship at all
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 è¡¨ç¤ºæ²¡æœ‰å…³ç³»
- en: It's also useful to find correlations between pairs of features themselves.
    Although the presence of highly correlated features wouldn't worsen the model,
    they wouldn't necessarily make any model better, either. For the sake of simplicity,
    it is always better to keep only one from a set of highly correlated features.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·ï¼Œæ‰¾åˆ°ç‰¹å¾å¯¹ä¹‹é—´çš„ç›¸å…³æ€§ä¹Ÿå¾ˆæœ‰ç”¨ã€‚å°½ç®¡é«˜åº¦ç›¸å…³çš„ç‰¹å¾çš„å­˜åœ¨ä¸ä¼šä½¿æ¨¡å‹å˜å·®ï¼Œä½†å®ƒä»¬ä¹Ÿä¸ä¸€å®šä¼šä½¿ä»»ä½•æ¨¡å‹å˜å¾—æ›´å¥½ã€‚ä¸ºäº†ç®€åŒ–èµ·è§ï¼Œæœ€å¥½ä»ä¸€ç»„é«˜åº¦ç›¸å…³çš„ç‰¹å¾ä¸­åªä¿ç•™ä¸€ä¸ªã€‚
- en: Note
  id: totrans-353
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ³¨æ„
- en: When fitting a linear model, having features that are highly correlated to each
    other can result in an unpredictable and widely varying model. This is because
    the coefficients of each feature in a linear model can be interpreted as the unit
    change in the target variable, keeping all other features constant. When a set
    of features are not independent (that is, are correlated), however, we cannot
    determine the effect of the independent changes to the target variable due to
    each feature, resulting in widely varying coefficients.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‹Ÿåˆçº¿æ€§æ¨¡å‹æ—¶ï¼Œç‰¹å¾ä¹‹é—´é«˜åº¦ç›¸å…³å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹ä¸å¯é¢„æµ‹ä¸”å˜åŒ–å¹…åº¦è¾ƒå¤§ã€‚è¿™æ˜¯å› ä¸ºçº¿æ€§æ¨¡å‹ä¸­æ¯ä¸ªç‰¹å¾çš„ç³»æ•°å¯ä»¥è§£é‡Šä¸ºåœ¨ä¿æŒå…¶ä»–ç‰¹å¾ä¸å˜çš„æƒ…å†µä¸‹ï¼Œç›®æ ‡å˜é‡çš„å•ä½å˜åŒ–ã€‚ç„¶è€Œï¼Œå½“ä¸€ç»„ç‰¹å¾ä¸ç‹¬ç«‹ï¼ˆå³å­˜åœ¨ç›¸å…³æ€§ï¼‰æ—¶ï¼Œæˆ‘ä»¬æ— æ³•ç¡®å®šæ¯ä¸ªç‰¹å¾å¯¹ç›®æ ‡å˜é‡çš„ç‹¬ç«‹å˜åŒ–æ‰€é€ æˆçš„å½±å“ï¼Œå¯¼è‡´ç³»æ•°å˜åŒ–å¹…åº¦è¾ƒå¤§ã€‚
- en: To find the pairwise correlation for every numeric feature in a DataFrame with
    every other feature, we can use the `.corr()` function on the DataFrame.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ‰¾åˆ°DataFrameä¸­æ¯ä¸ªæ•°å€¼ç‰¹å¾ä¸å…¶ä»–ç‰¹å¾çš„æˆå¯¹ç›¸å…³æ€§ï¼Œå¯ä»¥åœ¨DataFrameä¸Šä½¿ç”¨`.corr()`å‡½æ•°ã€‚
- en: 'Exercise 22: Plotting a Scatter Plot'
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  22ï¼šç»˜åˆ¶æ•£ç‚¹å›¾
- en: 'Let''s plot a scatter plot between the primary earthquake magnitude on the
    *X* axis and the corresponding number of injuries on the *Y* axis:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç»˜åˆ¶ä¸»éœ‡éœ‡ä¸­éœ‡çº§ï¼ˆ*X*è½´ï¼‰ä¸å¯¹åº”çš„å—ä¼¤äººæ•°ï¼ˆ*Y*è½´ï¼‰ä¹‹é—´çš„æ•£ç‚¹å›¾ï¼š
- en: 'Filter out null values. Since we know that there are null values in both columns,
    let''s first filter the data to include only the non-null rows:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿‡æ»¤æ‰ç©ºå€¼ã€‚ç”±äºæˆ‘ä»¬çŸ¥é“ä¸¤åˆ—ä¸­éƒ½æœ‰ç©ºå€¼ï¼Œé¦–å…ˆè®©æˆ‘ä»¬è¿‡æ»¤æ•°æ®ï¼Œåªä¿ç•™éç©ºè¡Œï¼š
- en: '[PRE39]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Create and display the scatter plot. We will use Matplotlib''s `plt.scatter(x=...,
    y=...)` as the primary command for plotting the data. The `x` and `y` parameters
    state which feature is to be considered along which axis. They take a single-dimensional
    data structure such as a list, a tuple, or a pandas series. We can also send the
    `scatter` function more parameters that define, say, the icon to use to plot an
    individual data point. For example, to use a red cross as the icon, we would need
    to send the following parameters: `marker=''x'', c=''r''`:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºå¹¶æ˜¾ç¤ºæ•£ç‚¹å›¾ã€‚æˆ‘ä»¬å°†ä½¿ç”¨Matplotlibçš„`plt.scatter(x=..., y=...)`ä½œä¸ºç»˜åˆ¶æ•°æ®çš„ä¸»è¦å‘½ä»¤ã€‚`x`å’Œ`y`å‚æ•°æŒ‡å®šå“ªä¸ªç‰¹å¾åº”æ²¿å“ªä¸ªè½´ç»˜åˆ¶ã€‚å®ƒä»¬æ¥å—å•ä¸€ç»´åº¦çš„æ•°æ®ç»“æ„ï¼Œå¦‚åˆ—è¡¨ã€å…ƒç»„æˆ–pandasç³»åˆ—ã€‚æˆ‘ä»¬è¿˜å¯ä»¥å‘`scatter`å‡½æ•°ä¼ é€’æ›´å¤šå‚æ•°ï¼Œä¾‹å¦‚æŒ‡å®šç»˜åˆ¶å•ä¸ªæ•°æ®ç‚¹æ—¶ä½¿ç”¨çš„å›¾æ ‡ã€‚ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨çº¢è‰²çš„äº¤å‰ç¬¦å·ä½œä¸ºå›¾æ ‡ï¼Œæˆ‘ä»¬éœ€è¦ä¼ é€’ä»¥ä¸‹å‚æ•°ï¼š`marker='x',
    c='r'`ï¼š
- en: '[PRE40]'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output will be as follows:'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](img/C12622_02_28.jpg)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12622_02_28.jpg)'
- en: 'Figure 2.28: Scatter plot'
  id: totrans-364
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.28ï¼šæ•£ç‚¹å›¾
- en: From the plot, we can infer that although there doesn't seem to be a trend between
    the number of people who were injured and the earthquake magnitude, there are
    an increasing number of earthquakes with large injury counts as the magnitude
    increases. However, for the majority of earthquakes, there does not seem to be
    a relationship.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å›¾è¡¨ä¸­æˆ‘ä»¬å¯ä»¥æ¨æ–­å‡ºï¼Œè™½ç„¶å—ä¼¤äººæ•°å’Œéœ‡ä¸­éœ‡çº§ä¹‹é—´ä¼¼ä¹æ²¡æœ‰æ˜æ˜¾çš„è¶‹åŠ¿ï¼Œä½†éšç€éœ‡çº§çš„å¢åŠ ï¼Œå—ä¼¤äººæ•°è¾ƒå¤šçš„åœ°éœ‡æ•°é‡ä¹Ÿåœ¨å¢åŠ ã€‚ç„¶è€Œï¼Œå¯¹äºå¤§å¤šæ•°åœ°éœ‡è€Œè¨€ï¼Œä¼¼ä¹æ²¡æœ‰æ˜æ˜¾çš„å…³ç³»ã€‚
- en: 'Exercise 23: Correlation Heatmap'
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  23ï¼šç›¸å…³æ€§çƒ­åŠ›å›¾
- en: Let's plot a correlation heatmap between all the numeric variables in our dataset
    using Seaborn's `sns.heatmap()` function on the inter-feature correlation values
    in the dataset.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä½¿ç”¨Seabornçš„`sns.heatmap()`å‡½æ•°ç»˜åˆ¶æ•°æ®é›†ä¸­æ‰€æœ‰æ•°å€¼å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§çƒ­åŠ›å›¾ï¼Œè¯¥å‡½æ•°åŸºäºæ•°æ®é›†ä¸­çš„ç‰¹å¾é—´ç›¸å…³æ€§å€¼ã€‚
- en: 'The optional parameters passed to the `sns.heatmap()` function are `square`
    and `cmap`, which indicate that the plot should be such that each pixel is square
    and specify which color scheme to use, respectively:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼ é€’ç»™`sns.heatmap()`å‡½æ•°çš„å¯é€‰å‚æ•°æ˜¯`square`å’Œ`cmap`ï¼Œå®ƒä»¬åˆ†åˆ«è¡¨ç¤ºç»˜åˆ¶çš„å›¾è¡¨ä¸­æ¯ä¸ªåƒç´ åº”ä¸ºæ­£æ–¹å½¢ï¼Œå¹¶æŒ‡å®šè¦ä½¿ç”¨çš„é¢œè‰²æ–¹æ¡ˆï¼š
- en: 'Plot a basic heatmap with all the features:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶ä¸€ä¸ªåŒ…å«æ‰€æœ‰ç‰¹å¾çš„åŸºæœ¬çƒ­åŠ›å›¾ï¼š
- en: '[PRE41]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The output will be:'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå°†æ˜¯ï¼š
- en: '![](img/C12622_02_29.jpg)'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C12622_02_29.jpg)'
- en: 'Figure 2.29: Correlation heatmap'
  id: totrans-373
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.29ï¼šç›¸å…³æ€§çƒ­åŠ›å›¾
- en: We can see from the color bar on the right of the plot that the minimum value,
    around `-0.2`, is the lightest shade, which is a misrepresentation of the correlation
    values, which vary from -1 to 1.
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ä»å›¾è¡¨å³ä¾§çš„é¢œè‰²æ¡ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæœ€å°å€¼å¤§çº¦ä¸º`-0.2`ï¼Œå¯¹åº”çš„é¢œè‰²æ˜¯æœ€æµ…çš„ï¼Œè¿™åœ¨æŸç§ç¨‹åº¦ä¸Šè¯¯å¯¼äº†ç›¸å…³æ€§å€¼çš„è¡¨ç¤ºï¼Œå®é™…ç›¸å…³æ€§å€¼èŒƒå›´åº”è¯¥æ˜¯ä»-1åˆ°1ã€‚
- en: 'Plot a subset of features in a more customized heatmap. We will specify the
    upper and lower limits using the `vmin` and `vmax` parameters, and plot the heatmap
    again with annotations specifying the pairwise correlation values on a subset
    of features. We will also change the color scheme to one that can be better interpretedâ€”while
    the neutral white will represent no correlation, increasingly darker shades of
    blue and red will represent higher positive and negative correlation values respectively:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ä¸€ä¸ªæ›´è‡ªå®šä¹‰çš„çƒ­å›¾ä¸­ç»˜åˆ¶ç‰¹å¾çš„å­é›†ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `vmin` å’Œ `vmax` å‚æ•°æŒ‡å®šä¸Šä¸‹é™ï¼Œå¹¶ä½¿ç”¨å¸¦æœ‰æ³¨é‡Šçš„çƒ­å›¾é‡æ–°ç»˜åˆ¶ï¼Œæ³¨é‡Šæ˜¾ç¤ºç‰¹å¾å¯¹ä¹‹é—´çš„ç›¸å…³ç³»æ•°å€¼ã€‚æˆ‘ä»¬è¿˜å°†æ›´æ”¹é¢œè‰²æ–¹æ¡ˆï¼Œä½¿å…¶æ›´æ˜“äºè§£è¯»â€”â€”ä¸­æ€§è‰²ç™½è‰²è¡¨ç¤ºæ— ç›¸å…³æ€§ï¼Œè€Œè¶Šæ¥è¶Šæ·±çš„è“è‰²å’Œçº¢è‰²åˆ†åˆ«è¡¨ç¤ºæ›´é«˜çš„æ­£ç›¸å…³æ€§å’Œè´Ÿç›¸å…³æ€§ï¼š
- en: '[PRE42]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The output will be as follows:'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š
- en: '![](img/C12622_02_30.jpg)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12622_02_30.jpg)'
- en: 'Figure 2.30: Customized correlation heatmap'
  id: totrans-379
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.30ï¼šè‡ªå®šä¹‰çš„ç›¸å…³æ€§çƒ­å›¾
- en: Now, while we can calculate the value of correlation, this only gives us an
    indication of a linear relationship. To better judge whether there's a possible
    dependency, we could plot a scatter plot between pairs of features, which is mostly
    useful when the relationship between the two variables is not known and visualizing
    how the data points are scattered or distributed could give us an idea of whether
    (and how) the two may be related.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè™½ç„¶æˆ‘ä»¬å¯ä»¥è®¡ç®—ç›¸å…³ç³»æ•°çš„å€¼ï¼Œä½†è¿™ä»…ä»…æä¾›äº†çº¿æ€§å…³ç³»çš„æŒ‡ç¤ºã€‚ä¸ºäº†æ›´å¥½åœ°åˆ¤æ–­æ˜¯å¦å­˜åœ¨å¯èƒ½çš„ä¾èµ–å…³ç³»ï¼Œæˆ‘ä»¬å¯ä»¥ç»˜åˆ¶ç‰¹å¾å¯¹ä¹‹é—´çš„æ•£ç‚¹å›¾ï¼Œè¿™åœ¨å˜é‡ä¹‹é—´çš„å…³ç³»ä¸æ˜ç¡®æ—¶ç‰¹åˆ«æœ‰ç”¨ï¼Œå› ä¸ºé€šè¿‡å¯è§†åŒ–æ•°æ®ç‚¹çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥å¤§è‡´åˆ¤æ–­è¿™ä¸¤ä¸ªå˜é‡æ˜¯å¦ï¼ˆä»¥åŠå¦‚ä½•ï¼‰ç›¸å…³ã€‚
- en: 'Exercise 24: Pairplot'
  id: totrans-381
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  24ï¼šPairplot
- en: 'A pairplot is useful for visualizing multiple relationships between pairs of
    features at once, and can be plotted using Seaborn''s `.pairplot()` function.
    In this exercise, we will look at a pairplot between the features having the highest
    pair-wise correlation in the dataset:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: pairplot å¯¹äºåŒæ—¶å¯è§†åŒ–å¤šä¸ªç‰¹å¾å¯¹ä¹‹é—´çš„å…³ç³»éå¸¸æœ‰ç”¨ï¼Œå¯ä»¥ä½¿ç”¨ Seaborn çš„ `.pairplot()` å‡½æ•°ç»˜åˆ¶ã€‚åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹æ•°æ®é›†ä¸­å…·æœ‰æœ€é«˜æˆå¯¹ç›¸å…³æ€§çš„ç‰¹å¾ä¹‹é—´çš„
    pairplotï¼š
- en: 'Define a list having the subset of features on which to create the pairplot:'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®šä¹‰ä¸€ä¸ªåŒ…å«è¦åˆ›å»º pairplot çš„ç‰¹å¾å­é›†çš„åˆ—è¡¨ï¼š
- en: '[PRE43]'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Create the pairplot using Seaborn. The arguments sent to the plotting function
    are: `kind=''scatter''`, which indicates that we want each individual plot between
    the pair of variables in the grid to be represented as a scatter plot, and `diag_kind=''kde''`,
    which indicates that we want the plots along the diagonal (where both the features
    in the pair are the same) to be a kernel density estimate.'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Seaborn åˆ›å»º pairplotã€‚ä¼ é€’ç»™ç»˜å›¾å‡½æ•°çš„å‚æ•°æ˜¯ï¼š`kind='scatter'`ï¼Œè¡¨ç¤ºæˆ‘ä»¬å¸Œæœ›ç½‘æ ¼ä¸­æ¯ä¸€å¯¹å˜é‡ä¹‹é—´çš„å•ç‹¬å›¾å½¢ä»¥æ•£ç‚¹å›¾çš„å½¢å¼å±•ç¤ºï¼›`diag_kind='kde'`ï¼Œè¡¨ç¤ºæˆ‘ä»¬å¸Œæœ›å¯¹è§’çº¿ä¸Šçš„å›¾å½¢ï¼ˆå³ä¸¤å˜é‡ç›¸åŒçš„ä½ç½®ï¼‰ä¸ºæ ¸å¯†åº¦ä¼°è®¡å›¾ã€‚
- en: 'It should also be noted here that the plots symmetrically across the diagonal
    from each other will essentially be the same, just with the axes reversed:'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œè¿˜åº”è¯¥æ³¨æ„ï¼Œå¯¹è§’çº¿å¯¹ç§°çš„å›¾å½¢æœ¬è´¨ä¸Šæ˜¯ç›¸åŒçš„ï¼Œåªä¸è¿‡åæ ‡è½´è¢«åè½¬äº†ï¼š
- en: '[PRE44]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The output will be as follows:'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š
- en: '![](img/C12622_02_31.jpg)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12622_02_31.jpg)'
- en: 'Figure 2.31: Pairplot between the features having the highest pair-wise correlation'
  id: totrans-390
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.31ï¼šå…·æœ‰æœ€é«˜æˆå¯¹ç›¸å…³æ€§çš„ç‰¹å¾ä¹‹é—´çš„ pairplot
- en: Relationship between a Continuous and a Categorical Variable
  id: totrans-391
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¿ç»­å‹å˜é‡ä¸ç±»åˆ«å‹å˜é‡ä¹‹é—´çš„å…³ç³»
- en: A common way to see the relationship between two variables when one is categorical
    and the other is continuous can be using a bar plot or a box plot.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä¸€ä¸ªå˜é‡æ˜¯ç±»åˆ«å‹å˜é‡ï¼Œå¦ä¸€ä¸ªæ˜¯è¿ç»­å‹å˜é‡æ—¶ï¼ŒæŸ¥çœ‹å®ƒä»¬ä¹‹é—´å…³ç³»çš„ä¸€ç§å¸¸è§æ–¹æ³•æ˜¯ä½¿ç”¨æ¡å½¢å›¾æˆ–ç®±çº¿å›¾ã€‚
- en: A bar plot helps compare the value of a variable for a discrete set of parameters
    and is one of the most common types of plots. Each bar represents a categorical
    value and the height of the bar usually represents an aggregated value of the
    continuous variable over that category (such as average, sum, or count of the
    values of the continuous variable in that category).
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¡å½¢å›¾æœ‰åŠ©äºæ¯”è¾ƒä¸€ä¸ªå˜é‡åœ¨ä¸€ç»„ç¦»æ•£å‚æ•°ä¸­çš„å€¼ï¼Œæ˜¯æœ€å¸¸è§çš„å›¾å½¢ç±»å‹ä¹‹ä¸€ã€‚æ¯æ ¹æ¡å½¢ä»£è¡¨ä¸€ä¸ªç±»åˆ«å€¼ï¼Œæ¡å½¢çš„é«˜åº¦é€šå¸¸è¡¨ç¤ºè¯¥ç±»åˆ«ä¸‹è¿ç»­å˜é‡çš„èšåˆå€¼ï¼ˆå¦‚å¹³å‡å€¼ã€æ€»å’Œæˆ–è¯¥ç±»åˆ«ä¸­è¿ç»­å˜é‡çš„å€¼çš„è®¡æ•°ï¼‰ã€‚
- en: A box plot is a rectangle drawn to represent the distribution of the continuous
    variable for each discrete value of the categorical variable. It not only allows
    us to visualize outliers efficiently but also allows us to compare the distribution
    of the continuous variable across categories of the categorical variable. The
    lower and upper edges of the rectangle represent the first and third quartiles
    respectively, the line down through the middle represents the median value, and
    the points (or fliers) above and below the rectangle represent outlier values.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç®±å‹å›¾æ˜¯ä¸€ä¸ªçŸ©å½¢ï¼Œç”¨æ¥è¡¨ç¤ºæ¯ä¸ªç¦»æ•£ç±»åˆ«å˜é‡çš„è¿ç»­å˜é‡çš„åˆ†å¸ƒã€‚å®ƒä¸ä»…èƒ½å¤Ÿæœ‰æ•ˆåœ°å±•ç¤ºå¼‚å¸¸å€¼ï¼Œè¿˜å¯ä»¥è®©æˆ‘ä»¬æ¯”è¾ƒä¸åŒç±»åˆ«å˜é‡ä¸‹è¿ç»­å˜é‡çš„åˆ†å¸ƒã€‚çŸ©å½¢çš„ä¸‹è¾¹ç¼˜å’Œä¸Šè¾¹ç¼˜åˆ†åˆ«ä»£è¡¨ç¬¬ä¸€å’Œç¬¬ä¸‰å››åˆ†ä½æ•°ï¼ŒçŸ©å½¢ä¸­é—´çš„çº¿ä»£è¡¨ä¸­ä½æ•°ï¼Œè€ŒçŸ©å½¢ä¸Šä¸‹çš„ç‚¹ï¼ˆæˆ–ç¦»ç¾¤ç‚¹ï¼‰ä»£è¡¨å¼‚å¸¸å€¼ã€‚
- en: 'Exercise 25: Bar Chart'
  id: totrans-395
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  25ï¼šæŸ±çŠ¶å›¾
- en: 'Let''s visualize the total number of tsunamis created by earthquakes of each
    intensity level using a bar chart:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä½¿ç”¨æŸ±çŠ¶å›¾æ¥å¯è§†åŒ–æ¯ä¸ªå¼ºåº¦çº§åˆ«çš„åœ°éœ‡æ‰€é€ æˆçš„æµ·å•¸æ€»æ•°ï¼š
- en: 'Preprocess the `flag_tsunami` variable. Before we can use the `flag_tsunami`
    variable, we need to preprocess it to convert the `No` values to zeros and the
    `Tsu` values to ones. This will give us the binary target variable. To do this,
    we set the values in the column using the `.loc` operator, with `:` indicating
    that values need to be set for all rows, and the second parameter specifying the
    name of the column for which values are to be set:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é¢„å¤„ç†`flag_tsunami`å˜é‡ã€‚åœ¨ä½¿ç”¨`flag_tsunami`å˜é‡ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦é¢„å¤„ç†å®ƒï¼Œå°†`No`å€¼è½¬æ¢ä¸ºé›¶ï¼Œå°†`Tsu`å€¼è½¬æ¢ä¸ºä¸€ã€‚è¿™å°†ä¸ºæˆ‘ä»¬æä¾›äºŒå…ƒç›®æ ‡å˜é‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨`.loc`æ“ä½œç¬¦è®¾ç½®åˆ—ä¸­çš„å€¼ï¼Œ`:`è¡¨ç¤ºéœ€è¦ä¸ºæ‰€æœ‰è¡Œè®¾ç½®å€¼ï¼Œç¬¬äºŒä¸ªå‚æ•°æŒ‡å®šè¦è®¾ç½®å€¼çš„åˆ—åç§°ï¼š
- en: '[PRE45]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Remove all rows having null `intensity` values from the data we want to plot:'
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ é™¤æ‰€æœ‰`intensity`å€¼ä¸ºnullçš„è¡Œï¼Œå»æ‰æˆ‘ä»¬è¦ç»˜åˆ¶çš„æ•°æ®ï¼š
- en: '[PRE46]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Find the total number of tsunamis for each `intensity` level and display the
    DataFrame. To get the data in a format using which a bar plot can be visualized,
    we will need to group the rows by each intensity level, and then sum over the
    `flag_tsunami` values to get the total number of tsunamis for each intensity level:'
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŸ¥æ‰¾æ¯ä¸ª`intensity`çº§åˆ«çš„æµ·å•¸æ€»æ•°å¹¶æ˜¾ç¤ºæ•°æ®æ¡†ã€‚ä¸ºäº†å°†æ•°æ®è½¬æ¢ä¸ºå¯è§†åŒ–æŸ±çŠ¶å›¾çš„æ ¼å¼ï¼Œæˆ‘ä»¬éœ€è¦æŒ‰æ¯ä¸ªå¼ºåº¦çº§åˆ«å¯¹è¡Œè¿›è¡Œåˆ†ç»„ï¼Œç„¶åå¯¹`flag_tsunami`å€¼è¿›è¡Œæ±‚å’Œï¼Œä»¥è·å¾—æ¯ä¸ªå¼ºåº¦çº§åˆ«çš„æµ·å•¸æ€»æ•°ï¼š
- en: '[PRE47]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output will be as follows:'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.32: Total number of tsunamis for each intensity level](img/C12622_02_32.jpg)'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.32ï¼šæ¯ä¸ªå¼ºåº¦çº§åˆ«çš„æµ·å•¸æ€»æ•°](img/C12622_02_32.jpg)'
- en: 'Figure 2.32: Total number of tsunamis for each intensity level'
  id: totrans-405
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.32ï¼šæ¯ä¸ªå¼ºåº¦çº§åˆ«çš„æµ·å•¸æ€»æ•°
- en: 'Plot the bar chart, using Matplotlib''s `plt.bar(x=..., height=...)` method,
    which takes two arguments, one specifying the `x` values at which bars need to
    be drawn, and the second specifying the height of each bar. Both of these are
    one-dimensional data structures that must have the same length:'
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Matplotlibçš„`plt.bar(x=..., height=...)`æ–¹æ³•ç»˜åˆ¶æŸ±çŠ¶å›¾ï¼Œè¯¥æ–¹æ³•éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªæŒ‡å®šç»˜åˆ¶æŸ±å½¢çš„ä½ç½®ï¼ˆ`x`å€¼ï¼‰ï¼Œå¦ä¸€ä¸ªæŒ‡å®šæ¯ä¸ªæŸ±å½¢çš„é«˜åº¦ã€‚è¿™ä¸¤è€…éƒ½æ˜¯ä¸€ç»´æ•°æ®ç»“æ„ï¼Œå¿…é¡»å…·æœ‰ç›¸åŒçš„é•¿åº¦ï¼š
- en: '[PRE48]'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The output will be as follows:'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.33: Bar chart](img/C12622_02_33.jpg)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.33ï¼šæŸ±çŠ¶å›¾](img/C12622_02_33.jpg)'
- en: 'Figure 2.33: Bar chart'
  id: totrans-410
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.33ï¼šæŸ±çŠ¶å›¾
- en: From this plot, we can see that as the earthquake intensity increases, the number
    of tsunamis caused also increases, but beyond an intensity of 9, the number of
    tsunamis seems to suddenly drop.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™ä¸ªå›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œéšç€åœ°éœ‡å¼ºåº¦çš„å¢åŠ ï¼Œé€ æˆçš„æµ·å•¸æ•°é‡ä¹Ÿå¢åŠ ï¼Œä½†åœ¨å¼ºåº¦è¶…è¿‡9ä¹‹åï¼Œæµ·å•¸çš„æ•°é‡ä¼¼ä¹çªç„¶ä¸‹é™ã€‚
- en: Think about why this could be happening. Perhaps it's just that there are fewer
    earthquakes with an intensity that high, and hence fewer tsunamis. Or it could
    be an entirely independent factor; maybe high-intensity earthquakes have historically
    occurred on land and couldn't trigger a tsunami. Explore the data to find out.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³æƒ³ä¸ºä»€ä¹ˆä¼šå‘ç”Ÿè¿™ç§æƒ…å†µã€‚æˆ–è®¸åªæ˜¯å› ä¸ºé«˜å¼ºåº¦çš„åœ°éœ‡è¾ƒå°‘ï¼Œå› æ­¤æµ·å•¸ä¹Ÿè¾ƒå°‘ã€‚æˆ–è€…å¯èƒ½æ˜¯å®Œå…¨ç‹¬ç«‹çš„å› ç´ ï¼›ä¹Ÿè®¸é«˜å¼ºåº¦çš„åœ°éœ‡å†å²ä¸Šå‘ç”Ÿåœ¨é™†åœ°ä¸Šï¼Œæ— æ³•å¼•å‘æµ·å•¸ã€‚æ¢ç´¢æ•°æ®ä»¥æ‰¾å‡ºåŸå› ã€‚
- en: 'Exercise 26: Box Plot'
  id: totrans-413
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  26ï¼šç®±å‹å›¾
- en: 'In this exercise, we''ll plot a box plot that represents the variation in `eq_primary`
    over the countries with at least 100 earthquakes:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†ç»˜åˆ¶ä¸€ä¸ªç®±å‹å›¾ï¼Œè¡¨ç¤ºå…·æœ‰è‡³å°‘100æ¬¡åœ°éœ‡çš„å›½å®¶ä¸­`eq_primary`çš„å˜åŒ–ï¼š
- en: 'Find countries with over 100 earthquakes. We will find the value counts for
    all the countries in the dataset. Then, we''ll create a series comprising only
    those countries having a count greater than 100:'
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŸ¥æ‰¾å‘ç”Ÿè¶…è¿‡100æ¬¡åœ°éœ‡çš„å›½å®¶ã€‚æˆ‘ä»¬å°†æŸ¥æ‰¾æ•°æ®é›†ä¸­æ‰€æœ‰å›½å®¶çš„è®¡æ•°å€¼ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªä»…åŒ…å«è®¡æ•°å¤§äº100çš„å›½å®¶çš„ç³»åˆ—ï¼š
- en: '[PRE49]'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output will be as follows:'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.34: Countries with over 100 earthquakes](img/C12622_02_34.jpg)'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.34ï¼šåœ°éœ‡è¶…è¿‡ 100 æ¬¡çš„å›½å®¶](img/C12622_02_34.jpg)'
- en: 'Figure 2.34: Countries with over 100 earthquakes'
  id: totrans-419
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.34ï¼šåœ°éœ‡è¶…è¿‡ 100 æ¬¡çš„å›½å®¶
- en: 'Subset the DataFrame to filter in only those rows having countries in the preceding
    set. To filter the rows, we use the `.isin()` method on the pandas series to select
    those rows containing a value in the array-like object passed as a parameter:'
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹ DataFrame è¿›è¡Œå­é›†åŒ–ï¼Œç­›é€‰å‡ºå‰é¢é›†åˆä¸­åŒ…å«çš„å›½å®¶çš„è¡Œã€‚ä¸ºäº†ç­›é€‰è¿™äº›è¡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ `.isin()` æ–¹æ³•åœ¨ pandas ç³»åˆ—ä¸Šé€‰æ‹©åŒ…å«ä¼ é€’ä¸ºå‚æ•°çš„ç±»ä¼¼æ•°ç»„å¯¹è±¡ä¸­çš„å€¼çš„è¡Œï¼š
- en: '[PRE50]'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Create and display the box plot. The primary command for plotting the data
    is `sns.boxplot(x=..., y=..., data=..., order=)`. The `x` and `y` parameters are
    the names of the columns in the DataFrame to be plotted on each axisâ€”the former
    is assumed to be the categorical variable and the latter the continuous. The `data`
    parameter takes the DataFrame from which to take the data and `order` takes a
    list of category names that indicates the order in which to display the categories
    on the *X* axis:'
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºå¹¶æ˜¾ç¤ºç®±å½¢å›¾ã€‚ç»˜åˆ¶æ•°æ®çš„ä¸»è¦å‘½ä»¤æ˜¯ `sns.boxplot(x=..., y=..., data=..., order=)`ã€‚`x` å’Œ `y`
    å‚æ•°æ˜¯ DataFrame ä¸­è¦ç»˜åˆ¶åœ¨æ¯ä¸ªåæ ‡è½´ä¸Šçš„åˆ—åâ€”â€”å‰è€…å‡å®šæ˜¯ç±»åˆ«å˜é‡ï¼Œåè€…æ˜¯è¿ç»­å˜é‡ã€‚`data` å‚æ•°æŒ‡å®šè¦ä»ä¸­è·å–æ•°æ®çš„ DataFrameï¼Œ`order`
    å‚æ•°æ¥å—ä¸€ä¸ªç±»åˆ«åç§°åˆ—è¡¨ï¼ŒæŒ‡ç¤ºåœ¨ *X* è½´ä¸Šæ˜¾ç¤ºç±»åˆ«çš„é¡ºåºï¼š
- en: '[PRE51]'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output will be as follows:'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.35: Box plot](img/C12622_02_35.jpg)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.35ï¼šç®±å½¢å›¾](img/C12622_02_35.jpg)'
- en: 'Figure 2.35: Box plot'
  id: totrans-426
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.35ï¼šç®±å½¢å›¾
- en: Relationship between Two Categorical Variables
  id: totrans-427
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸¤ä¸ªç±»åˆ«å˜é‡ä¹‹é—´çš„å…³ç³»
- en: When we are looking at only a pair of categorical variables to find a relationship
    between them, the most intuitive way to do this is to divide the data on the basis
    of the first category, and then subdivide it further on the basis of the second
    categorical variable and look at the resultant counts to find the distribution
    of data points. While this might seem confusing, a popular way to visualize this
    is using stacked bar charts. As in a regular bar chart, each bar would represent
    a categorical value. But each bar would again be subdivided into color-coded categories
    that would provide an indication of what fraction of the data points in the primary
    category fall into each subcategory (that is, the second category). The variable
    with a larger number of categories is usually considered the primary category.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬åªå…³æ³¨ä¸€å¯¹ç±»åˆ«å˜é‡ä»¥æŸ¥æ‰¾å®ƒä»¬ä¹‹é—´çš„å…³ç³»æ—¶ï¼Œæœ€ç›´è§‚çš„æ–¹å¼æ˜¯åŸºäºç¬¬ä¸€ä¸ªç±»åˆ«å°†æ•°æ®è¿›è¡Œåˆ’åˆ†ï¼Œç„¶åå†æ ¹æ®ç¬¬äºŒä¸ªç±»åˆ«å˜é‡è¿›ä¸€æ­¥ç»†åˆ†ï¼ŒæŸ¥çœ‹ç»“æœçš„è®¡æ•°ä»¥æ‰¾åˆ°æ•°æ®ç‚¹çš„åˆ†å¸ƒã€‚è™½ç„¶è¿™å¯èƒ½çœ‹èµ·æ¥æœ‰äº›æ··ä¹±ï¼Œä½†ä¸€ç§å¸¸è§çš„å¯è§†åŒ–æ–¹å¼æ˜¯ä½¿ç”¨å †å æ¡å½¢å›¾ã€‚ä¸å¸¸è§„çš„æ¡å½¢å›¾ä¸€æ ·ï¼Œæ¯ä¸ªæ¡å½¢å›¾è¡¨ç¤ºä¸€ä¸ªç±»åˆ«å€¼ã€‚ä½†æ¯ä¸ªæ¡å½¢å›¾å°†å†æ¬¡è¢«ç»†åˆ†ä¸ºé¢œè‰²ç¼–ç çš„å­ç±»åˆ«ï¼Œè¿™å¯ä»¥æŒ‡ç¤ºåœ¨ä¸»ç±»åˆ«ä¸­æœ‰å¤šå°‘æ•°æ®ç‚¹è½å…¥æ¯ä¸ªå­ç±»åˆ«ï¼ˆå³ç¬¬äºŒä¸ªç±»åˆ«ï¼‰ã€‚ç±»åˆ«æ•°è¾ƒå¤šçš„å˜é‡é€šå¸¸è¢«è®¤ä¸ºæ˜¯ä¸»ç±»åˆ«ã€‚
- en: 'Exercise 27: Stacked Bar Chart'
  id: totrans-429
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç»ƒä¹  27ï¼šå †å æ¡å½¢å›¾
- en: 'In this exercise, we''ll plot a stacked bar chart that represents the number
    of tsunamis that occurred for for each intensity level:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†ç»˜åˆ¶ä¸€ä¸ªå †å æ¡å½¢å›¾ï¼Œè¡¨ç¤ºæ¯ä¸ªå¼ºåº¦çº§åˆ«å‘ç”Ÿçš„æµ·å•¸æ•°é‡ï¼š
- en: 'Find the number of data points that fall into each grouped value of `intensity`
    and `flag_tsunami`:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŸ¥æ‰¾è½å…¥æ¯ä¸ª `intensity` å’Œ `flag_tsunami` åˆ†ç»„å€¼ä¸­çš„æ•°æ®ç‚¹æ•°é‡ï¼š
- en: '[PRE52]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The output will be as follows:'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](img/C12622_02_36.jpg)'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C12622_02_36.jpg)'
- en: 'Figure 2.36: Data points falling into each grouped value of intensity and flag_tsunami'
  id: totrans-435
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.36ï¼šæ¯ä¸ªåˆ†ç»„çš„å¼ºåº¦å’Œ flag_tsunami ä¸­è½å…¥çš„æ•°æ®ç‚¹
- en: 'Use the `.unstack()` method on the resultant DataFrame to get the level 1 index
    (`flag_tsunami`) as a column:'
  id: totrans-436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹ç»“æœ DataFrame ä½¿ç”¨ `.unstack()` æ–¹æ³•ï¼Œå°†ä¸€çº§ç´¢å¼•ï¼ˆ`flag_tsunami`ï¼‰ä½œä¸ºåˆ—ï¼š
- en: '[PRE53]'
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output will be as follows:'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.37: The level 1 index](img/C12622_02_37.jpg)'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![å›¾ 2.37ï¼šä¸€çº§ç´¢å¼•](img/C12622_02_37.jpg)'
- en: 'Figure 2.37: The level 1 index'
  id: totrans-440
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.37ï¼šä¸€çº§ç´¢å¼•
- en: 'Create the stacked bar chart. We first use the `sns.set()` function to indicate
    that we want to use Seaborn as our visualization library. Then, we can easily
    use the native `.plot()` function in pandas to plot a stacked bar chart by passing
    the `kind=''bar''` and `stacked=True` arguments:'
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºå †å æ¡å½¢å›¾ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨ `sns.set()` å‡½æ•°æ¥æŒ‡ç¤ºæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨ Seaborn ä½œä¸ºå¯è§†åŒ–åº“ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°ä½¿ç”¨ pandas ä¸­çš„åŸç”Ÿ
    `.plot()` å‡½æ•°ï¼Œé€šè¿‡ä¼ é€’ `kind='bar'` å’Œ `stacked=True` å‚æ•°æ¥ç»˜åˆ¶å †å æ¡å½¢å›¾ï¼š
- en: '[PRE54]'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output will be as follows:'
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![Figure 2.38: A stacked bar chart](img/C12622_02_38.jpg)'
  id: totrans-444
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ 2.38ï¼šå †å æ¡å½¢å›¾](img/C12622_02_38.jpg)'
- en: 'Figure 2.38: A stacked bar chart'
  id: totrans-445
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2.38ï¼šå †å æ¡å½¢å›¾
- en: 'The plot now lets us visualize and interpret the fraction of earthquakes that
    caused tsunamis at each intensity level. In *Exercise 25: Bar Chart*, we saw the
    number of tsunamis drop for earthquakes having intensity greater than 9\. From
    this plot, we can now confirm that this was primarily because the number of earthquakes
    themselves dropped beyond level 10; the fraction of tsunamis even increased for
    level 11.'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç°åœ¨ï¼Œè¯¥å›¾è¡¨è®©æˆ‘ä»¬èƒ½å¤Ÿå¯è§†åŒ–å’Œè§£é‡Šæ¯ä¸ªå¼ºåº¦çº§åˆ«å¯¼è‡´æµ·å•¸çš„åœ°éœ‡æ¯”ä¾‹ã€‚åœ¨*ç»ƒä¹  25: æ¡å½¢å›¾*ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°å¤§äº9çº§çš„åœ°éœ‡æ‰€å¯¼è‡´çš„æµ·å•¸æ•°é‡æœ‰æ‰€ä¸‹é™ã€‚ä»è¿™ä¸ªå›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®è®¤ï¼Œä¸»è¦æ˜¯å› ä¸ºè¶…è¿‡10çº§çš„åœ°éœ‡æ•°é‡å‡å°‘äº†ï¼›è€Œ11çº§çš„åœ°éœ‡æ‰€å¯¼è‡´çš„æµ·å•¸æ¯”ä¾‹ç”šè‡³æœ‰æ‰€å¢åŠ ã€‚'
- en: 'Activity 4: Relationships Within the Data'
  id: totrans-447
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'æ´»åŠ¨ 4: æ•°æ®å†…çš„å…³ç³»'
- en: 'In this activity, we will revise what we learned in the previous section about
    relationships between data. We will use the same dataset we used in *Activity
    2: Summary Statistics and Missing Values*, that is, *House Prices: Advanced Regression
    Techniques* (available at [https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)
    or on GitHub at [https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python](https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python)).
    We''ll use different plots to highlight relationships between values in this dataset.'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 'åœ¨æœ¬æ¬¡æ´»åŠ¨ä¸­ï¼Œæˆ‘ä»¬å°†å›é¡¾ä¸Šä¸€èŠ‚ä¸­å…³äºæ•°æ®å…³ç³»çš„å­¦ä¹ å†…å®¹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸*æ´»åŠ¨ 2: æ±‡æ€»ç»Ÿè®¡å’Œç¼ºå¤±å€¼*ç›¸åŒçš„æ•°æ®é›†ï¼Œå³*æˆ¿ä»·ï¼šé«˜çº§å›å½’æŠ€æœ¯*ï¼ˆå¯åœ¨[https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)æˆ–GitHubä¸Šçš„[https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python](https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python)æ‰¾åˆ°ï¼‰ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸åŒçš„å›¾è¡¨æ¥çªå‡ºæ˜¾ç¤ºæ•°æ®é›†ä¸­çš„å€¼ä¹‹é—´çš„å…³ç³»ã€‚'
- en: 'The steps to be performed are as follows:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ‰§è¡Œçš„æ­¥éª¤å¦‚ä¸‹ï¼š
- en: Plot the correlation heatmap for the dataset.
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶æ•°æ®é›†çš„ç›¸å…³æ€§çƒ­å›¾ã€‚
- en: 'Plot a more compact heatmap having annotations for correlation values using
    the following subset of features:'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»˜åˆ¶ä¸€ä¸ªæ›´ç´§å‡‘çš„çƒ­å›¾ï¼Œä½¿ç”¨ä»¥ä¸‹ç‰¹å¾å­é›†å¹¶å¸¦æœ‰ç›¸å…³æ€§å€¼çš„æ³¨é‡Šï¼š
- en: '[PRE55]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Display the pairplot for the same subset of features, with the KDE plot on the
    diagonals and scatter plot elsewhere.
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ˜¾ç¤ºç›¸åŒç‰¹å¾å­é›†çš„é…å¯¹å›¾ï¼ŒKDEå›¾ä½äºå¯¹è§’çº¿ä½ç½®ï¼Œæ•£ç‚¹å›¾ä½äºå…¶ä»–åœ°æ–¹ã€‚
- en: Create a boxplot to show the variation in `SalePrice` for each category of `GarageCars`.
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªç®±å‹å›¾ï¼Œæ˜¾ç¤º`SalePrice`åœ¨æ¯ä¸ª`GarageCars`ç±»åˆ«ä¸­çš„å˜åŒ–ã€‚
- en: Plot a line graph using Seaborn to show the variation in `SalePrice` for older
    and more recently built flats.
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Seabornç»˜åˆ¶æŠ˜çº¿å›¾ï¼Œæ˜¾ç¤ºæ—§å…¬å¯“å’Œæ–°å»ºå…¬å¯“çš„`SalePrice`å˜åŒ–ã€‚
- en: Note
  id: totrans-456
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ³¨æ„
- en: The solution for this activity can be found on page 319.
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æœ¬æ¬¡æ´»åŠ¨çš„è§£å†³æ–¹æ¡ˆå¯ä»¥åœ¨ç¬¬319é¡µæ‰¾åˆ°ã€‚
- en: Summary
  id: totrans-458
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: In this chapter, we started by talking about why data exploration is an important
    part of the modeling process and how it can help in not only preprocessing the
    dataset for the modeling process, but also help us engineer informative features
    and improve model accuracy. This chapter focused on not only gaining a basic overview
    of the dataset and its features, but also gaining insights by creating visualizations
    that combine several features.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè®¨è®ºäº†ä¸ºä»€ä¹ˆæ•°æ®æ¢ç´¢æ˜¯å»ºæ¨¡è¿‡ç¨‹ä¸­çš„é‡è¦éƒ¨åˆ†ï¼Œå®ƒä¸ä»…æœ‰åŠ©äºå¯¹æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ï¼Œè¿˜èƒ½å¸®åŠ©æˆ‘ä»¬è®¾è®¡å…·æœ‰ä¿¡æ¯é‡çš„ç‰¹å¾å¹¶æé«˜æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚æœ¬ç« ä¸ä»…ä¾§é‡äºå¯¹æ•°æ®é›†åŠå…¶ç‰¹å¾çš„åŸºæœ¬æ¦‚è§ˆï¼Œè¿˜é€šè¿‡åˆ›å»ºç»“åˆå¤šä¸ªç‰¹å¾çš„å¯è§†åŒ–æ¥è·å¾—æ´è§ã€‚
- en: We looked at how to find the summary statistics of a dataset using core functionality
    from pandas. We looked at how to find missing values and talked about why they're
    important, while learning how to use the Missingno library to analyze them and
    the pandas and scikit-learn libraries to impute the missing values.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç ”ç©¶äº†å¦‚ä½•ä½¿ç”¨pandasçš„æ ¸å¿ƒåŠŸèƒ½æ‰¾åˆ°æ•°æ®é›†çš„æ±‡æ€»ç»Ÿè®¡æ•°æ®ã€‚æˆ‘ä»¬è¿˜ç ”ç©¶äº†å¦‚ä½•å‘ç°ç¼ºå¤±å€¼ï¼Œå¹¶è®¨è®ºäº†å®ƒä»¬çš„é‡è¦æ€§ï¼ŒåŒæ—¶å­¦ä¹ å¦‚ä½•ä½¿ç”¨Missingnoåº“åˆ†æè¿™äº›ç¼ºå¤±å€¼ï¼Œä»¥åŠä½¿ç”¨pandaså’Œscikit-learnåº“å¡«è¡¥ç¼ºå¤±å€¼ã€‚
- en: Then, we looked at how to study the univariate distributions of variables in
    the dataset and visualize them for both categorical and continuous variables using
    bar charts, pie charts, and histograms. Lastly, we learned how to explore relationships
    between variables, and about how they can be represented using scatter plots,
    heatmaps, box plots, and stacked bar charts, to name a few.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¦‚ä½•ç ”ç©¶æ•°æ®é›†ä¸­å˜é‡çš„å•å˜é‡åˆ†å¸ƒï¼Œå¹¶é€šè¿‡æ¡å½¢å›¾ã€é¥¼å›¾å’Œç›´æ–¹å›¾ç­‰å¯è§†åŒ–æ–¹å¼å±•ç¤ºè¿™äº›åˆ†å¸ƒã€‚æœ€åï¼Œæˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•æ¢ç´¢å˜é‡ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶äº†è§£åˆ°å®ƒä»¬å¯ä»¥é€šè¿‡æ•£ç‚¹å›¾ã€çƒ­å›¾ã€ç®±å‹å›¾ã€å †ç§¯æ¡å½¢å›¾ç­‰å½¢å¼è¿›è¡Œè¡¨ç¤ºã€‚
- en: 'In the following chapters, we will start exploring supervised machine learning
    algorithms. Now that we have an idea of how to explore a dataset that we have,
    we can proceed to the modeling phase. The next chapter will introduce regression:
    a class of algorithms that are primarily used to build models for continuous target
    variables.'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å¼€å§‹æ¢ç´¢ç›‘ç£å¼æœºå™¨å­¦ä¹ ç®—æ³•ã€‚ç°åœ¨æˆ‘ä»¬å·²ç»äº†è§£äº†å¦‚ä½•æ¢ç´¢æˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯ä»¥è¿›å…¥å»ºæ¨¡é˜¶æ®µã€‚ä¸‹ä¸€ç« å°†ä»‹ç»å›å½’ï¼šä¸€ç§ä¸»è¦ç”¨äºæ„å»ºè¿ç»­ç›®æ ‡å˜é‡æ¨¡å‹çš„ç®—æ³•ç±»åˆ«ã€‚
