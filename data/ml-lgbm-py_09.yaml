- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: LightGBM MLOps with AWS SageMaker
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AWS SageMaker进行LightGBM MLOps
- en: In [*Chapter 8*](B16690_08.xhtml#_idTextAnchor134), *Machine Learning Pipelines
    and MLOps with LightGBM*, we built an end-to-end ML pipeline using scikit-learn.
    We also looked at encapsulating the pipeline within a REST API and deployed our
    API to the cloud.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第8章*](B16690_08.xhtml#_idTextAnchor134)“使用LightGBM的机器学习管道和MLOps”中，我们使用scikit-learn构建了一个端到端的ML管道。我们还探讨了将管道封装在REST
    API中，并将我们的API部署到云端。
- en: This chapter will look at developing and deploying a pipeline using **Amazon
    SageMaker**. SageMaker is a complete set of production services for developing,
    hosting, monitoring, and maintaining ML solutions provided by **Amazon Web** **Services**
    (**AWS**).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨使用**Amazon SageMaker**开发和部署管道。SageMaker是Amazon Web Services（**AWS**）提供的一套完整的用于开发、托管、监控和维护ML解决方案的生产服务。
- en: We’ll expand our capabilities with ML pipelines by looking at advanced topics
    such as detecting bias in a trained model and automating deployment to fully scalable,
    serverless web endpoints.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过查看高级主题，如检测训练模型中的偏差和自动化部署到完全可扩展的无服务器Web端点，来扩展我们的ML管道功能。
- en: 'The following main topics will be covered in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: An introduction to AWS and SageMaker
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS和SageMaker简介
- en: Model explainability and bias
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型可解释性和偏差
- en: Building an end-to-end pipeline with SageMaker
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SageMaker构建端到端管道
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter dives deep into building ML models and pipelines using Amazon SageMaker.
    You need access to an Amazon account, and you must also configure a payment method.
    Note that running the example code for this chapter will incur costs on AWS. The
    complete notebooks and scripts for this chapter are available at [https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-9](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-9).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章深入探讨了使用Amazon SageMaker构建ML模型和管道。您需要访问一个Amazon账户，并且您还必须配置一种支付方式。请注意，运行本章的示例代码将在AWS上产生费用。本章的完整笔记本和脚本可在[https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-9](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-9)找到。
- en: An introduction to AWS and SageMaker
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS和SageMaker简介
- en: This section provides a high-level overview of AWS and delves into SageMaker,
    AWS’ ML offering.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了AWS的高级概述，并深入探讨了SageMaker，AWS的ML服务。
- en: AWS
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS
- en: AWS is one of the leading players in the global cloud computing marketplace.
    AWS offers many cloud-based products and services, including databases, **machine
    learning** (**ML**), analytics, networking, storage, developer tools, and enterprise
    applications. The idea behind AWS is to offer businesses an affordable and scalable
    solution to their computing needs, regardless of their size or industry.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: AWS是全球云计算市场的主要参与者之一。AWS提供许多基于云的产品和服务，包括数据库、**机器学习**（**ML**）、分析、网络、存储、开发工具和企业应用程序。AWS背后的理念是为企业提供一种经济实惠且可扩展的解决方案，以满足其计算需求，无论其规模或行业如何。
- en: A key advantage of AWS is elasticity, meaning servers and services can be stopped
    and started quickly and at will, scaling from zero machines to thousands. The
    elasticity of the services goes hand in hand with its primary pricing model of
    pay-as-you-go, meaning customers only pay for the services and resources they
    use without any upfront costs or long-term contracts. This elasticity and pricing
    allow businesses to scale computing needs as needed, on an ad hoc and granular
    level, and then only pay for what they use. This approach has transformed how
    businesses scale IT resources and applications, enabling them to react quickly
    to changing business needs without incurring the heavy costs traditionally associated
    with hardware and software procurement and maintenance.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: AWS的一个关键优势是弹性，这意味着服务器和服务可以快速随意地停止和启动，从零台机器扩展到数千台。服务的弹性与其主要定价模式“按使用付费”相辅相成，这意味着客户只需为使用的服务和资源付费，无需任何预付成本或长期合同。这种弹性和定价允许企业根据需要按需和细粒度地扩展计算需求，然后只为他们使用的付费。这种方法已经改变了企业扩展IT资源和应用程序的方式，使他们能够快速响应不断变化的企业需求，而无需承担与硬件和软件采购和维护相关的传统高昂成本。
- en: Another advantage is the global reach of AWS. AWS services are available in
    many regions across the globe. Regions are geographically separated, and each
    region is further divided into availability zones. The region-zone setup allows
    users to create globally distributed and redundant infrastructure to maximize
    resilience and architect for disaster recovery. The regional data centers also
    allow users to create servers and services close to end users, minimizing latency.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个优势是 AWS 的全球覆盖范围。AWS 服务在全球许多地区都可用。区域在地理上是分开的，每个区域进一步划分为可用区。区域-区域设置允许用户创建全球分布和冗余的基础设施，以最大化弹性和为灾难恢复进行设计。区域数据中心还允许用户在靠近最终用户的地方创建服务器和服务，以最小化延迟。
- en: Core services
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 核心服务
- en: The core AWS services provide computing, networking, and storage capability.
    AWS’s compute services include **Amazon Elastic Compute Cloud** (**EC2**), which
    offers configurable virtual machines to customers, and **AWS Lambda**, a serverless
    compute platform that allows you to run code without the need to provision and
    manage servers. In ML, both EC2 instances and Lambda functions are often used
    to train and validate or serve models via API endpoints. The elastic nature of
    EC2 servers allows ML engineers to scale up training servers to many thousands,
    which can significantly speed up training or parameter-tuning tasks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 核心AWS服务提供计算、网络和存储能力。AWS 的计算服务包括 **Amazon Elastic Compute Cloud**（**EC2**），为用户提供可配置的虚拟机，以及
    **AWS Lambda**，一个无服务器计算平台，允许您在不需要配置和管理服务器的情况下运行代码。在机器学习中，EC2 实例和 Lambda 函数通常用于通过
    API 端点训练、验证或提供服务模型。EC2 服务器的弹性特性允许机器学习工程师将训练服务器扩展到数万个，这可以显著加快训练或参数调整任务。
- en: AWS’s storage and database services, such as **Amazon Simple Storage Service**
    (**S3**) and **Amazon RDS** (**Relational Database Service**), offer reliable,
    scalable, and secure data storage solutions. These services manage storage infrastructure
    and offer high-level features such as backups, patch management, and vertical
    and horizontal scaling. S3 is a widely used service for data engineering and ML.
    S3 offers low-cost, highly redundant secure storage that scales beyond exabytes.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 的存储和数据库服务，如 **Amazon Simple Storage Service**（**S3**）和 **Amazon RDS**（**关系数据库服务**），提供可靠、可扩展和安全的存储解决方案。这些服务管理存储基础设施，并提供高级功能，如备份、补丁管理和垂直和水平扩展。S3
    是广泛用于数据工程和机器学习的服务。S3 提供低成本、高度冗余的安全存储，可扩展到超过艾字节。
- en: AWS also offers data warehousing solutions with **Amazon Redshift**. Large enterprises
    frequently use Redshift as a warehouse or the basis of a data lake, meaning it’s
    often a data source for ML solutions.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 还提供数据仓库解决方案，即 **Amazon Redshift**。大型企业经常使用 Redshift 作为仓库或数据湖的基础，这意味着它通常是机器学习解决方案的数据源。
- en: AWS also offers networking services to help businesses meet complex networking
    and isolation needs. **AWS Direct Connect** allows customers to set up a dedicated
    network connection from a customer’s site to the AWS cloud. Routing and name servers
    can be managed with Amazon Route 53, a flexible and scalable **Domain Name System**
    (**DNS**) service.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 还提供网络服务，以帮助企业在复杂的网络和隔离需求方面取得成功。**AWS Direct Connect** 允许客户从客户的站点设置一个专用网络连接到
    AWS 云。路由和域名服务器可以使用 Amazon Route 53，一个灵活且可扩展的 **域名系统**（**DNS**）服务进行管理。
- en: However, chief among the network services is **Amazon Virtual Private Cloud**
    (**VPC**). VPCs offer customers the ability to configure completely isolated virtual
    networks. Customers can granularly configure subnetworks, routing tables, address
    ranges, gateways, and security groups. VPCs allow users to isolate their environment
    and cloud resources and control inbound and outbound traffic for increased security
    and privacy.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在众多网络服务中，首要的是 **Amazon Virtual Private Cloud**（**VPC**）。VPC 为客户提供配置完全隔离的虚拟网络的能力。客户可以精细配置子网、路由表、地址范围、网关和安全组。VPC
    允许用户隔离他们的环境和云资源，并控制进出流量，以增加安全性和隐私性。
- en: Security
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安全性
- en: A critical piece of any infrastructure equation is security. In terms of security,
    AWS provides a highly secure, scalable, and flexible cloud computing environment.
    AWS’s security services, including **AWS Identity and Access Management** (**IAM**)
    and **Amazon Security Hub**, help customers protect their data and applications
    by implementing robust security measures.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 任何基础设施方程中的关键部分是安全性。在安全性方面，AWS 提供一个高度安全、可扩展和灵活的云计算环境。AWS 的安全服务，包括 **AWS Identity
    and Access Management**（**IAM**）和 **Amazon Security Hub**，通过实施强大的安全措施帮助客户保护他们的数据和应用程序。
- en: AWS also complies with multiple international and industry-specific compliance
    standards, such as GDPR, HIPAA, and ISO 27001\. Further, in terms of data governance,
    AWS makes it easy to comply with data residency and privacy requirements. Due
    to the regional structure of AWS, data can remain resident in specific countries,
    while engineers have access to the full suite of AWS services.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 还符合多个国际和行业特定的合规标准，例如 GDPR、HIPAA 和 ISO 27001。此外，在数据治理方面，AWS 使遵守数据驻留和隐私要求变得容易。由于
    AWS 的区域结构，数据可以保留在特定国家，同时工程师可以访问 AWS 的完整服务套件。
- en: Machine learning
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习
- en: AWS also offers services focused on ML and **artificial intelligence** (**AI**).
    Among these are many fully managed services for specific ML tasks. **AWS Comprehend**
    offers many **natural language processing** (**NLP**) services, such as document
    processing, named entity recognition, and sentiment analysis. **Amazon Lookout**
    is a service for anomaly detection in equipment, metrics, or images. Further,
    **Amazon Rekognition** offers services for machine vision use cases such as image
    classification and facial recognition.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 还提供专注于 ML 和 **人工智能**（**AI**）的服务。其中许多是针对特定 ML 任务的完全托管服务。**AWS Comprehend**
    提供了许多 **自然语言处理**（**NLP**）服务，例如文档处理、命名实体识别和情感分析。**Amazon Lookout** 是用于设备、指标或图像异常检测的服务。此外，**Amazon
    Rekognition** 提供了用于机器视觉用例的服务，例如图像分类和面部识别。
- en: Of particular interest to us is **Amazon SageMaker**, a complete ML platform
    that allows us to create, train, and deploy ML models in the Amazon cloud. The
    following section discusses SageMaker in detail.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说特别感兴趣的是 **Amazon SageMaker**，这是一个完整的 ML 平台，使我们能够在亚马逊云中创建、训练和部署 ML 模型。下一节将详细讨论
    SageMaker。
- en: SageMaker
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SageMaker
- en: '**Amazon SageMaker** is an end-to-end ML platform that allows data scientists
    to work with data and develop, train, deploy, and monitor ML models. SageMaker
    is fully managed, so there is no need to provision or manage servers.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon SageMaker** 是一个端到端的 ML 平台，允许数据科学家与数据一起工作，并开发、训练、部署和监控 ML 模型。SageMaker
    完全托管，因此无需配置或管理服务器。'
- en: The primary appeal of Amazon SageMaker lies in its comprehensive nature as a
    platform. It encompasses all aspects of the ML process, including data labeling,
    model building, training, tuning, deployment, management, and monitoring. By taking
    care of these aspects, SageMaker allows developers and data scientists to focus
    on the core ML tasks instead of managing the infrastructure.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 SageMaker 的主要吸引力在于其作为一个平台的全面性。它涵盖了机器学习（ML）过程的各个方面，包括数据标注、模型构建、训练、调优、部署、管理和监控。通过处理这些方面，SageMaker
    允许开发者和数据科学家专注于核心的 ML 任务，而不是管理基础设施。
- en: As we have discussed, the ML life cycle starts with data gathering, which often
    requires manual data labeling. For this, SageMaker provides a service called **SageMaker
    Ground Truth**. This service makes it easy to annotate ML datasets efficiently.
    It can significantly reduce the time and costs typically associated with data
    labeling by using automated labeling workflows, and it also offers a workforce
    for manual data labeling tasks. Further, SageMaker also provides the **Data Wrangler**
    service, which helps with data preparation and **exploratory data analysis** (**EDA**).
    Data Wrangler provides functionality to query data from S3, Redshift, and other
    platforms and then cleanse, visualize, and understand the data from a single visual
    interface.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，ML 生命周期始于数据收集，这通常需要手动数据标注。为此，SageMaker 提供了一个名为 **SageMaker Ground
    Truth** 的服务。该服务使高效标注 ML 数据集变得容易。通过使用自动标注工作流程，它可以显著减少与数据标注通常相关的耗时和成本，并且还提供了一支用于手动数据标注任务的工作队伍。此外，SageMaker
    还提供了 **Data Wrangler** 服务，该服务有助于数据准备和 **探索性数据分析**（**EDA**）。Data Wrangler 提供了从
    S3、Redshift 和其他平台查询数据的功能，然后从单一可视化界面中净化、可视化和理解数据。
- en: 'SageMaker provides a fully managed service for the model training phase that
    can handle large-scale, distributed model training via **Training Jobs**. The
    service is designed to be flexible and adaptable, allowing users to optimize their
    ML models as needed. Users only need to specify the location of their data, typically
    S3 and the ML algorithm, and SageMaker takes care of the rest of the training
    process. The model training service fully leverages the elastic nature of the
    underlying AWS infrastructure: many servers can be created quickly to perform
    training jobs and discarded after training is complete to save costs.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker为模型训练阶段提供了一个完全管理的服务，可以通过**Training Jobs**处理大规模、分布式模型训练。该服务旨在灵活和适应性强，使用户能够根据需要优化他们的机器学习模型。用户只需指定其数据的位置，通常是S3和机器学习算法，SageMaker就会负责其余的训练过程。模型训练服务充分利用了底层AWS基础设施的弹性：可以快速创建多个服务器来执行训练任务，训练完成后丢弃以节省成本。
- en: This paradigm also extends to hyperparameter tuning. To simplify hyperparameter
    optimization, SageMaker provides an automatic model-tuning feature. Many tuning
    algorithms are provided, such as Optuna or FLAML, and tuning can be run across
    multiple servers.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这种范式也扩展到了超参数调整。为了简化超参数优化，SageMaker提供了一个自动模型调优功能。提供了许多调优算法，例如Optuna或FLAML，并且可以在多个服务器上运行调优。
- en: SageMaker also has support for a more fully AutoML experience via **SageMaker
    Autopilot**. Autopilot is a service that enables automatic model creation. A user
    only needs to provide the raw data and set the target; then, Autopilot automatically
    explores different solutions to find the best model. Autopilot provides complete
    visibility into the process so that data scientists can understand how the model
    is created and make any necessary adjustments.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker还通过**SageMaker Autopilot**支持更全面的AutoML体验。Autopilot是一种服务，它能够实现自动模型创建。用户只需提供原始数据并设置目标；然后，Autopilot会自动探索不同的解决方案以找到最佳模型。Autopilot提供了对整个过程的完全可见性，以便数据科学家可以了解模型是如何创建的，并做出任何必要的调整。
- en: Once a model has been trained and optimized, it must be deployed. SageMaker
    simplifies this process by providing a one-click deployment process. Users can
    quickly deploy their models to production with auto-scaling capabilities without
    worrying about the underlying infrastructure. This deployment autoscaling capability
    allows users to set metrics-based policies that increase or decrease backing servers.
    For instance, the deployment can be scaled up if the number of invocations within
    a period exceeds a specific threshold. SageMaker ensures the high availability
    of models and allows for A/B testing of models to compare different variants and
    decide on the best one. SageMaker also supports multi-model endpoints, allowing
    users to deploy multiple models on a single endpoint.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型经过训练和优化，就必须部署。SageMaker通过提供一键部署过程简化了这一过程。用户可以快速将模型部署到生产环境中，并具有自动扩展功能，无需担心底层基础设施。这种部署自动扩展功能允许用户设置基于指标的策略，以增加或减少后端服务器。例如，如果一段时间内的调用次数超过特定阈值，则可以扩展部署。SageMaker确保模型的高可用性，并允许进行A/B测试以比较不同版本并决定最佳版本。SageMaker还支持多模型端点，允许用户在单个端点上部署多个模型。
- en: Amazon SageMaker also provides capabilities to monitor the model’s performance
    and conduct analysis once deployed. **SageMaker Model Monitor** monitors the quality
    of deployed models continuously (for real-time endpoints) or in batches (for asynchronous
    jobs). Alerts can be defined to notify the user if metric thresholds are exceeded.
    Model Monitor can monitor data drift and model drift based on metrics such as
    accuracy.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker还提供了监控模型性能和分析部署后模型的功能。**SageMaker Model Monitor**持续监控已部署模型的品质（对于实时端点）或批量监控（对于异步作业）。可以定义警报，当指标阈值超过时通知用户。Model
    Monitor可以根据如准确度等指标监控数据漂移和模型漂移。
- en: Finally, SageMaker is both a platform within AWS and a software SDK. The SDK
    is available in both Python and R. The SageMaker SDK provides a range of built-in
    algorithms and frameworks, including support for the most popular algorithms in
    the ML community, such as XGBoost, TensorFlow, PyTorch, and MXNet. It also supports
    a marketplace where users can choose from a vast collection of algorithm and model
    packages shared by AWS and other SageMaker users.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，SageMaker 既是 AWS 中的一个平台，也是一个软件 SDK。SDK 提供了 Python 和 R 两种语言版本。SageMaker SDK
    提供了一系列内置算法和框架，包括对机器学习社区中最受欢迎的算法的支持，如 XGBoost、TensorFlow、PyTorch 和 MXNet。它还支持一个市场，用户可以从
    AWS 和其他 SageMaker 用户共享的大量算法和模型包中选择。
- en: A noteworthy part of SageMaker that simplifies one of the most important aspects
    of model development (bias and fairness) is **SageMaker Clarify**.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 中的一个值得关注的部分，简化了模型开发中最重要的一环（偏差和公平性），就是 **SageMaker Clarify**。
- en: SageMaker Clarify
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SageMaker Clarify
- en: Amazon SageMaker Clarify is a tool that provides greater transparency into ML
    models. SageMaker Clarify aims to assist in understanding how ML models make predictions,
    thereby enabling model explainability and fairness.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker Clarify 是一个提供更多机器学习模型透明度的工具。SageMaker Clarify 的目标是帮助理解机器学习模型如何进行预测，从而实现模型可解释性和公平性。
- en: One of the primary features of SageMaker Clarify is its capacity to provide
    model interpretability. It helps developers understand the relationships between
    the input data and the model’s predictions. The service generates feature attributions
    that show how each feature in the dataset influences predictions, which can be
    critical in many domains, especially those where it’s vital to understand the
    reasoning behind a model’s prediction. In addition to providing insight into individual
    predictions, SageMaker Clarify offers global explanatory capabilities. It measures
    the importance of input features on a model’s predictions in aggregate across
    the whole dataset. Feature impact analysis allows developers and data scientists
    to understand the overall behavior of a model, helping them interpret how different
    features drive model predictions on a global level.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Clarify 的一个主要特性是其提供模型可解释性的能力。它帮助开发者理解输入数据与模型预测之间的关系。该服务生成特征归因，显示数据集中每个特征如何影响预测，这在许多领域都至关重要，尤其是在需要理解模型预测背后的推理时。除了提供对单个预测的洞察外，SageMaker
    Clarify 还提供全局解释能力。它衡量输入特征对模型预测的整体重要性，在整个数据集上汇总。特征影响分析允许开发者和数据科学家理解模型的总体行为，帮助他们从全局层面解释不同特征如何驱动模型预测。
- en: Further, Clarify can help identify potential bias in trained models. The service
    includes pre-training and post-training bias metrics that help us understand if
    a model favors certain groups unfairly. It’s best practice to check all new models
    for bias, but it is also imperative in regulated industries such as finance or
    healthcare, where biased predictions can have severe consequences.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Clarify 可以帮助识别训练模型中的潜在偏差。该服务包括预训练和后训练偏差指标，帮助我们了解模型是否不公平地偏向某些群体。检查所有新模型是否存在偏差是最佳实践，但在金融或医疗保健等受监管行业中，偏差预测可能具有严重后果，因此这一点至关重要。
- en: Clarify provides model interpretability by using an advanced technique known
    as **SHapley Additive** **exPlanations** (**SHAP**).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Clarify 通过使用一种称为 **SHapley Additive **exPlanations**（SHAP）的先进技术来提供模型可解释性。
- en: SHAP
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SHAP
- en: SHAP is a game theoretic approach to interpreting the output of any ML model
    [1]. SHAP aims to provide an understanding of the impact of individual features
    on a model’s overall prediction.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 是一种基于博弈论的解释任何机器学习模型输出的方法 [1]。SHAP 的目标是提供对单个特征对模型整体预测影响的了解。
- en: 'Essentially, SHAP values assess the effect of a particular feature value by
    contrasting it with a baseline value for that feature, highlighting its contribution
    to the prediction. A SHAP value is a fair contribution allocation from each feature
    to the prediction for each instance. SHAP values are rooted in cooperative game
    theory, representing a solution to the following question:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，SHAP 值通过将该特定特征值与该特征的基线值进行对比来评估其影响，突出其对预测的贡献。SHAP 值是每个实例中每个特征对预测的公平贡献分配。SHAP
    值植根于合作博弈论，代表了对以下问题的解决方案：
- en: “*Given the difference a feature makes in predicting an outcome, what portion
    of that difference is attributable to* *each feature?*”
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: “*考虑到一个特征在预测结果中的差异，这部分差异中有多少可以归因于* *每个特征？*”
- en: These values are calculated using the concept of Shapley values from game theory.
    A Shapley value determines the significance of a feature by contrasting a model’s
    predictions with the presence and absence of that feature. Yet, as the sequence
    in which a model encounters features can affect its prediction, Shapley values
    consider all possible orderings. Then, it assigns an importance value to a feature
    so that it equals the average marginal contribution of that feature across all
    possible coalitions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值是使用博弈论中的 Shapley 值概念计算的。Shapley 值通过对比模型预测与该特征存在和不存在的情况来确定特征的重要性。然而，由于模型遇到特征序列可能会影响其预测，Shapley
    值考虑了所有可能的顺序。然后，它为特征分配一个重要性值，使得该特征在所有可能的联盟中的平均边际贡献等于这个值。
- en: There are several advantages to using SHAP for model interpretation. First,
    it offers consistency in interpretation. If the contribution of a feature changes,
    the attributed importance of that feature changes proportionally.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SHAP 进行模型解释有几个优点。首先，它提供了解释的一致性。如果一个特征的影响发生变化，该特征的归因重要性也会成比例地变化。
- en: Secondly, SHAP guarantees local accuracy, which means the sum of the SHAP values
    for all features would equal the difference between the prediction and the average
    prediction for the dataset.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，SHAP 保证局部准确性，这意味着所有特征的 SHAP 值之和将等于预测与数据集平均预测之间的差异。
- en: 'A great way to visualize SHAP values is by using SHAP summary plots. These
    plots provide a bird’s-eye view of feature importance and what is driving it.
    They plot all the SHAP values for a feature on a graph for easy visualization.
    Each point on the graph represents a SHAP value for a feature and an instance.
    The position on the Y-axis is determined by the feature and on the X-axis by the
    SHAP value:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SHAP 摘要图可视化 SHAP 值是一个很好的方法。这些图提供了一个俯瞰特征重要性和驱动因素的全景。它们在图上绘制了每个特征的所有 SHAP 值，以便于可视化。图上的每个点代表一个特征和一个实例的
    SHAP 值。Y 轴上的位置由特征决定，X 轴上的位置由 SHAP 值决定：
- en: '![Figure 9.1 – Local explanation example for the Census Income dataset. Bars
    indicate SHAP values or the relative importance of each feature in predicting
    this specific instance](img/B16690_09_01.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.1 – 人口普查收入数据集的本地解释示例。条形表示 SHAP 值或每个特征在预测此特定实例时的相对重要性](img/B16690_09_01.jpg)'
- en: Figure 9.1 – Local explanation example for the Census Income dataset. Bars indicate
    SHAP values or the relative importance of each feature in predicting this specific
    instance
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 – 人口普查收入数据集的本地解释示例。条形表示 SHAP 值或每个特征在预测此特定实例时的相对重要性
- en: In the context of SageMaker Clarify, the service generates a set of SHAP values
    for each instance in your dataset when you run a clarification job. SageMaker
    Clarify can also provide global feature importance measures by aggregating SHAP
    values across the entire dataset.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SageMaker Clarify 的上下文中，当你运行一个澄清作业时，该服务会为你的数据集中的每个实例生成一组 SHAP 值。SageMaker
    Clarify 还可以通过在整个数据集上聚合 SHAP 值来提供全局特征重要性度量。
- en: SHAP values can help you understand complex model behavior, highlight potential
    issues, and improve your model over time. For example, by examining SHAP values,
    you might discover that a specific feature has a more significant effect on your
    model’s predictions than expected, prompting you to explore why this might happen.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 值可以帮助你理解复杂的模型行为，突出潜在问题，并随着时间的推移改进你的模型。例如，通过检查 SHAP 值，你可能会发现某个特定特征对你的模型预测的影响比预期的更大，这会促使你探索为什么会发生这种情况。
- en: In this section, we looked at AWS and, more specifically, what the AWS ML family
    of services, SageMaker, offers. The functionality available in SageMaker, such
    as model explainability, bias detection, and monitoring, are components we have
    yet to implement in our ML pipelines. In the next section, we’ll look at building
    a complete end-to-end LightGBM-based ML pipeline, including these crucial steps,
    using SageMaker.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了 AWS 以及更具体地，AWS 机器学习服务家族中的 SageMaker 提供了什么。SageMaker 中可用的功能，如模型可解释性、偏差检测和监控，是我们尚未在我们的机器学习管道中实现的部分。在下一节中，我们将探讨使用
    SageMaker 构建一个完整的端到端 LightGBM 机器学习管道，包括这些关键步骤。
- en: Building a LightGBM ML pipeline with Amazon SageMaker
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker 构建 LightGBM 机器学习管道
- en: The dataset we’ll use for our case study of building a SageMaker pipeline is
    the Census Income dataset from *Chapter 4*, *Comparing LightGBM, XGBoost, and
    Deep Learning*. This dataset is also available as a SageMaker sample dataset,
    so it’s easy to work with on SageMaker if you are getting started.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用于构建 SageMaker 管道案例研究的案例数据集来自 *第 4 章*，*比较 LightGBM、XGBoost 和深度学习* 的人口普查收入数据集。此数据集也作为
    SageMaker 示例数据集提供，因此如果您是初学者，在 SageMaker 上使用它很容易。
- en: 'The pipeline we’ll build consists of the following steps:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要构建的管道将包括以下步骤：
- en: Data preprocessing.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据预处理。
- en: Model training and tuning.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练和调优。
- en: Model evaluation.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型评估。
- en: Bias and explainability checks using Clarify.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Clarify 进行偏差和可解释性检查。
- en: Model registration within SageMaker.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 SageMaker 中的模型注册。
- en: Model deployment using an AWS Lambda.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 AWS Lambda 进行模型部署。
- en: 'Here’s a graph showing the complete pipeline:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个显示完整管道的图表：
- en: '![Figure 9.2 – SageMaker ML pipeline for Census Income classification](img/B16690_09_02.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.2 – 用于人口普查收入分类的 SageMaker ML 管道](img/B16690_09_02.jpg)'
- en: Figure 9.2 – SageMaker ML pipeline for Census Income classification
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 – 用于人口普查收入分类的 SageMaker ML 管道
- en: Our approach is to create the entire pipeline using a Jupyter Notebook running
    in SageMaker Studio. The sections that follow explain and go through the code
    for each pipeline step, starting with setting up the SageMaker session.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法是使用在 SageMaker Studio 中运行的 Jupyter Notebook 创建整个管道。接下来的部分将解释并展示每个管道步骤的代码，从设置
    SageMaker 会话开始。
- en: Setting up a SageMaker session
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 SageMaker 会话
- en: 'The following steps assume you have already created an AWS account and set
    up a SageMaker domain to get started. If not, the following documentation can
    be referenced to do so:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤假设您已经创建了一个 AWS 账户并设置了一个 SageMaker 域以开始。如果没有，可以参考以下文档来完成这些操作：
- en: 'Prerequisites: [https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.xhtml)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先决条件：[https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.xhtml)
- en: 'Onboarding to a SageMaker domain: [https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.xhtml)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加入 SageMaker 域：[https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.xhtml)
- en: 'We must initialize the SageMaker session and create S3, SageMaker, and SageMaker
    Runtime clients via `boto3` to get started:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须通过 `boto3` 初始化 SageMaker 会话并创建 S3、SageMaker 和 SageMaker Runtime 客户端以开始：
- en: '[PRE0]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We will use Amazon S3 to store our training data, source code, and all data
    and artifacts created by the pipeline, such as the serialized model. Our data
    and artifacts are split into a read bucket and a separate write bucket. This is
    a standard best practice as it separates the concerns for data storage.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Amazon S3 来存储我们的训练数据、源代码以及由管道创建的所有数据和工件，例如序列化的模型。我们的数据和工件被分为一个读取桶和一个单独的写入桶。这是一个标准的最佳实践，因为它将数据存储的关注点分开。
- en: 'SageMaker sessions have the concept of a default S3 bucket for the session.
    If no default bucket name is supplied, one is generated, and the bucket is created
    for you. Here, we’re grabbing a reference to the bucket. This is our output or
    write bucket. The read bucket is a bucket we’ve created previously that stores
    our training data:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 会话有一个默认的 S3 桶的概念。如果没有提供默认桶名称，则会生成一个，并为您创建一个桶。在这里，我们获取对桶的引用。这是我们输出或写入桶。读取桶是我们之前创建的一个桶，用于存储我们的训练数据：
- en: '[PRE1]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The source code, configuration, and output of each of the steps in the pipeline
    are captured in folders within our S3 write bucket. It’s useful to create variables
    for each S3 URI to avoid errors when repeatedly referring to data, like so:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 管道中每个步骤的源代码、配置和输出都被捕获在我们 S3 写入桶中的文件夹内。为每个 S3 URI 创建变量很有用，这样可以避免在重复引用数据时出错，如下所示：
- en: '[PRE2]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'SageMaker needs us to specify the compute instance types we want to use when
    running the jobs for training, processing, Clarify, and prediction. In our example,
    we’re using `m5.large` instances. Most EC2 instance types can be used with SageMaker.
    However, a few special instance types that support GPUs and deep learning frameworks
    are also available:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 需要我们指定在运行训练、处理、Clarify 和预测作业时想要使用的计算实例类型。在我们的示例中，我们使用 `m5.large` 实例。大多数
    EC2 实例类型都可以与 SageMaker 一起使用。然而，还有一些支持 GPU 和深度学习框架的特殊实例类型也是可用的：
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: SageMaker uses standard EC2 instances for training but runs specific Docker
    images on the instances to provide ML functionality. Amazon SageMaker provides
    many prebuilt Docker images for various ML frameworks and stacks.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 使用标准的 EC2 实例进行训练，但在实例上运行特定的 Docker 镜像以提供 ML 功能。Amazon SageMaker 为各种
    ML 框架和堆栈提供了许多预构建的 Docker 镜像。
- en: 'The SageMaker SDK also provides a function to search for images that are compatible
    with the instance type we need within the AWS region we are using. We can search
    for an image using `retrieve`:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker SDK 还提供了一个函数，用于在使用的 AWS 区域内搜索与我们所需的实例类型兼容的镜像。我们可以使用 `retrieve` 搜索镜像：
- en: '[PRE4]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We specify `None` for the framework parameter as we manage the LightGBM installation
    ourselves.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将框架参数指定为 `None`，因为我们自己管理 LightGBM 的安装。
- en: 'To parameterize our pipeline, we must define SageMaker workflow parameters
    from the `sagemaker.workflow.parameters` package. Wrappers are available for various
    parameter types:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了参数化我们的管道，我们必须从 `sagemaker.workflow.parameters` 包中定义 SageMaker 工作流参数。各种参数类型都有包装器可用：
- en: '[PRE5]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With our pipeline parameters, S3 data paths, and other configuration variables
    set, we can move on to creating our pipeline’s preprocessing step.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置了管道参数、S3 数据路径和其他配置变量后，我们可以继续创建管道的预处理步骤。
- en: Preprocessing step
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理步骤
- en: 'Setting up our preprocessing step has two parts: creating a Python script that
    performs the preprocessing and creating a processor that is added to the pipeline.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 设置我们的预处理步骤有两个部分：创建一个执行预处理的 Python 脚本，并创建一个添加到管道中的处理器。
- en: 'The script we’ll be using is a regular Python script with a main function.
    We’ll use scikit-learn to do our preprocessing. The preprocessing script hasn’t
    been entirely reproduced here but is available in our source code repository.
    Notably, when the pipeline executes the step, the data is retrieved from S3 and
    added to a local staging directory on the preprocessing instance. From here, we
    can read the data using standard pandas tooling:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要使用的脚本是一个带有主函数的常规 Python 脚本。我们将使用 scikit-learn 进行预处理。预处理脚本在此处并未完全重现，但在我们的源代码仓库中可用。值得注意的是，当管道执行步骤时，数据将从
    S3 检索并添加到预处理实例的本地暂存目录中。从这里，我们可以使用标准的 pandas 工具读取数据：
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Similarly, after processing is complete, we can write the results to a local
    directory, from which SageMaker retrieves it and uploads it to S3:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在处理完成后，我们可以将结果写入本地目录，SageMaker 会从该目录检索数据并将其上传到 S3：
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'With a preprocessing script defined, we need to upload it to S3 for the pipeline
    to be able to use it:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理脚本定义后，我们需要将其上传到 S3，以便管道能够使用它：
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can define the preprocessing step as follows. First, we must create an `SKLearnProcessor`
    instance:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以如下定义预处理步骤。首先，我们必须创建一个 `SKLearnProcessor` 实例：
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`SKLearnProcessor` handles the processing task for jobs that require scikit-learn.
    We specify the scikit-learn framework version and the instance type and count
    we defined earlier.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`SKLearnProcessor` 处理需要 scikit-learn 的作业的处理任务。我们指定了 scikit-learn 框架版本以及我们之前定义的实例类型和数量。'
- en: 'The processor is then added to `ProcessingStep` for use in the pipeline:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将处理器添加到 `ProcessingStep` 以在管道中使用：
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`inputs` and `outputs` are defined using the `ProcessingInput` and `ProcessingOutput`
    wrappers, as shown here:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`inputs` 和 `outputs` 使用 `ProcessingInput` 和 `ProcessingOutput` 包装器定义，如下所示：'
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '`ProcessingStep` takes our scikit-learn processor and the inputs and outputs
    for the data. The `ProcessingInput` instances define the S3 source and local directory
    destination to facilitate copying the data (these are the same local directories
    our preprocessing script uses). Similarly, the `ProcessingOutput` instances take
    the local directory source and S3 destinations. We also set job arguments, which
    are passed to the preprocessing script as CLI arguments.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`ProcessingStep` 接收我们的 scikit-learn 处理器以及数据的输入和输出。`ProcessingInput` 实例定义了 S3
    源和本地目录目标，以方便复制数据（这些是我们在预处理脚本中使用的相同本地目录）。同样，`ProcessingOutput` 实例接收本地目录源和 S3 目标。我们还设置了作业参数，这些参数作为
    CLI 参数传递给预处理脚本。'
- en: Having set up the preprocessing step, we can move on to training.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理步骤设置完成后，我们可以继续进行训练。
- en: Model training and tuning
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练和调整
- en: 'We define a training script in the same way as a preprocessing script: a Python
    script with a main function that uses our standard Python tools, such as scikit-learn,
    to train a LightGBM model. However, we also need to install the LightGBM library
    itself.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以与预处理脚本相同的方式定义训练脚本：一个带有主函数的 Python 脚本，使用我们的标准 Python 工具（如 scikit-learn）训练一个
    LightGBM 模型。然而，我们还需要安装 LightGBM 库本身。
- en: An alternative to installing the library is building it into a Docker image
    and using it as our training image in SageMaker. This is the canonical way of
    managing environments in SageMaker. However, it entails significant work and includes
    the long-term need to maintain the image over time. Alternatively, if we only
    need to install a handful of dependencies, we can do that directly from our training
    script, as shown here.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 安装库的另一种方法是将其构建到 Docker 镜像中，并将其用作 SageMaker 中的训练镜像。这是在 SageMaker 中管理环境的标准方式。然而，它需要大量的工作，并且需要在长期内维护镜像。或者，如果我们只需要安装少量依赖项，我们可以直接从我们的训练脚本中安装，如下所示。
- en: 'We must define a helper function to install packages and then use it to install
    LightGBM:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须定义一个辅助函数来安装包，然后使用它来安装 LightGBM：
- en: '[PRE12]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This also has the advantage that we install the latest version (or a specific
    version) every time we run training.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这也有一个优点，即每次我们运行训练时都会安装最新版本（或指定版本）。
- en: 'With the package installed, the rest of the training script trains a standard
    `LGBMClassifier` on the data prepared by the preprocessing step. We can set up
    or train data and parameters from the arguments to the script:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装了包之后，训练脚本的其余部分将在预处理步骤准备的数据上训练标准的 `LGBMClassifier`。我们可以从脚本的参数中设置或训练数据和参数：
- en: '[PRE13]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, we must do standard scikit-learn cross-validation scoring, fit the model
    to the data, and output the training and validation scores:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须进行标准的 scikit-learn 交叉验证评分，将模型拟合到数据，并输出训练和验证分数：
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As shown here, the script accepts CLI arguments to set hyperparameters. This
    is used by the hyperparameter tuning step to set parameters during the optimization
    phase. We can use Python’s `ArgumentParser` for this purpose:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如此所示，脚本接受 CLI 参数来设置超参数。这在优化阶段设置参数时被超参数调整步骤使用。我们可以使用 Python 的 `ArgumentParser`
    来实现这个目的：
- en: '[PRE15]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We can also see that we log training and validation F1 scores, allowing SageMaker
    and CloudWatch to pull the data from logs for reporting and evaluation purposes.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到，我们记录了训练和验证的 F1 分数，这使得 SageMaker 和 CloudWatch 能够从日志中提取数据用于报告和评估目的。
- en: 'Finally, we need to write out the results of the training in a JSON document.
    The results can then be used in subsequent pipeline processes and are shown as
    output from the job in the SageMaker interface. The JSON document is stored on
    disk, along with the serialized model file:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要将训练结果写入一个 JSON 文档中。这些结果随后可以在后续的管道处理中使用，并在 SageMaker 界面中作为作业的输出显示。该 JSON
    文档存储在磁盘上，与序列化的模型文件一起：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As with the preprocessing step, the results are written to a local directory,
    where SageMaker picks them up and copies them to S3.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 与预处理步骤一样，结果被写入到本地目录中，SageMaker 会从中提取并将它们复制到 S3。
- en: With the script defined, we can create the tuning step in the pipeline, which
    trains the model and tunes hyperparameters.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本定义后，我们可以在管道中创建调整步骤，该步骤训练模型并调整超参数。
- en: 'We must define a SageMaker `Estimator` that, similar to `SKLearnProcessor`,
    encapsulates the configuration for training, including a reference to the script
    (on S3):'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须定义一个类似 `SKLearnProcessor` 的 SageMaker `Estimator`，它封装了训练的配置，包括对脚本（在 S3 上）的引用：
- en: '[PRE17]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can then define our SageMaker `HyperparameterTuner`, which performs the
    actual hyperparameter tuning. Similar to Optuna or FLAML, we must specify valid
    ranges for the hyperparameters using SageMaker wrappers:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以定义我们的 SageMaker `HyperparameterTuner`，它执行实际的超参数调整。类似于 Optuna 或 FLAML，我们必须使用
    SageMaker 包装器指定超参数的有效范围：
- en: '[PRE18]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '`HyperparameterTuner` can be set up as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`HyperparameterTuner` 可以设置如下：'
- en: '[PRE19]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'SageMaker supports many strategies for hyperparameter tuning, including Hyperband
    tuning. More information can be found in the documentation for hyperparameter
    tuning: [https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.xhtml).
    Here, we used random search, with a maximum job size of 20\. It’s here that AWS’
    elastic infrastructure can be used to significant benefit. If we increase the
    training instance count, SageMaker automatically distributes the training job
    across all machines. Provisioning additional machines has some overhead and increases
    cost, but it can also majorly reduce tuning time if we run thousands of trials.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 支持许多超参数调优策略，包括 Hyperband 调优。更多信息可以在超参数调优的文档中找到：[https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.xhtml)。在这里，我们使用了随机搜索，最大作业大小为20。在这里，AWS
    的弹性基础设施可以发挥显著作用。如果我们增加训练实例数量，SageMaker 会自动将训练作业分配到所有机器上。配置额外的机器有一些开销并增加成本，但如果运行数千次试验，它也可以显著减少调优时间。
- en: The tuner’s metric definitions define regular expressions that are used to pull
    the results metrics from the logs, as we showed in the training script earlier.
    The parameter optimization framework optimizes relative to the metrics defined
    here, minimizing or maximizing the metric.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 调优器的指标定义定义了正则表达式，用于从日志中提取结果指标，正如我们在之前的训练脚本中所示。参数优化框架相对于这里定义的指标进行优化，最小化或最大化指标。
- en: 'With the hyperparameter tuner defined, we can create a `TuningStep` for inclusion
    into the pipeline:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了超参数调优器后，我们可以创建一个 `TuningStep` 以包含到管道中：
- en: '[PRE20]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The pipeline steps we’ve defined thus far prepare data and produce a trained
    model that’s serialized to S3\. The pipeline’s next step is to create a SageMaker
    `Model` that wraps the model and is used for the evaluation, bias, and inference
    steps. This can be done as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今为止定义的管道步骤准备数据并生成一个序列化到 S3 的训练模型。管道的下一步是创建一个 SageMaker `Model`，它封装了模型并用于评估、偏差和推理步骤。可以按照以下方式完成：
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `Model` instance encapsulates all the necessary configurations to deploy
    and run the model. We can see that `model_data` is taken from the top-performing
    model resulting from the tuning step.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`Model` 实例封装了部署和运行模型所需的所有必要配置。我们可以看到 `model_data` 是从调优步骤中产生的表现最好的模型中获取的。'
- en: 'The pipeline steps we’ve defined so far will produce processed data and train
    a tuned model. The layout for the processed data in S3 is shown in *Figure 9**.3*:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今为止定义的管道步骤将生成处理后的数据和训练一个调优模型。处理数据在 S3 中的布局如图 *9.3* 所示：
- en: '![Figure 9.3 – S3 directory layout for the results of the processing jobs](img/B16690_09_03.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图9.3 – 处理作业结果的S3目录布局](img/B16690_09_03.jpg)'
- en: Figure 9.3 – S3 directory layout for the results of the processing jobs
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 – 处理作业结果的S3目录布局
- en: We could proceed to the deployment step if we needed to. However, we will follow
    best practice and add quality gates to our pipeline that check the model’s performance
    and bias and produce insights into its function.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要进行部署步骤，我们可以继续进行。然而，我们将遵循最佳实践，并在管道中添加质量门，以检查模型的表现和偏差，并对其功能产生见解。
- en: Evaluation, bias, and explainability
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估、偏差和可解释性
- en: 'So far, we’ve seen the general pattern of adding steps to a SageMaker pipeline:
    set up the configuration using SageMaker’s configuration classes and then create
    the relevant pipeline step.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了向 SageMaker 管道添加步骤的一般模式：使用 SageMaker 的配置类设置配置，然后创建相关的管道步骤。
- en: Bias configuration
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 偏差配置
- en: 'To add bias checks to our pipeline, we must create the following configuration:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 要将偏差检查添加到我们的管道中，我们必须创建以下配置：
- en: '[PRE22]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '`BiasConfig` describes which facets (features) we want to check for bias. We’ve
    selected `Sex` and `Age`, which are always essential facets to check when working
    with demographic data.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`BiasConfig` 描述了我们要检查哪些方面（特征）。我们选择了 `Sex` 和 `Age`，这两个方面在处理人口统计数据时始终是必须检查的。'
- en: '`ModeLBiasCheckConfig` wraps the data configuration, model configuration, and
    bias confirmation for the bias check step. It also sets the method to use for
    the bias check. Here, we use the **difference in positive proportions in predicted**
    **labels** (**DPPL**).'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`ModeLBiasCheckConfig` 包装了数据配置、模型配置和偏差确认步骤。它还设置了用于偏差检查的方法。在这里，我们使用**预测标签中正比例的差异**（DPPL）。'
- en: The DPPL is a metric that’s used to gauge if a model predicts outcomes differently
    for varying facets of data. The DPPL is calculated as the difference between the
    proportion of positive predictions for facet “a” and facet “d.” It helps assess
    whether there’s bias in the model predictions after training by comparing them
    with the initial bias present in the dataset. For instance, if a model predicting
    eligibility for a home loan predicts positive outcomes for 70% of male applicants
    (facet “a”) and 60% for female applicants (facet “d”), the 10% difference could
    indicate bias against facet “d.”
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: DPPL 是一个衡量模型是否对数据的不同方面预测结果不同的指标。DPPL 是通过计算“a”方面和“d”方面的正面预测比例之间的差异来计算的。它通过将训练后的模型预测与数据集中最初存在的偏差进行比较，帮助评估模型预测是否存在偏差。例如，如果一个预测家庭贷款资格的模型对
    70% 的男性申请人（方面“a”）预测了积极的结果，而对 60% 的女性申请人（方面“d”）预测了积极的结果，那么 10% 的差异可能表明对方面“d”存在偏见。
- en: 'The DPPL formula is represented as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: DPPL 公式表示如下：
- en: DPPL = q a ′ − q d ′
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: DPPL = q a ′ − q d ′
- en: Here, q a ′ is the predicted proportion of facet “a” receiving a positive outcome,
    and q d ′  is the analogous proportion for facet “d.” For binary and multicategory
    facet labels, normalized DPPL values fall between [-1, 1], while continuous labels
    vary over the interval (-∞, +∞). A positive DPPL value suggests a higher proportion
    of positive predictions for facet “a” versus “d,” indicating a positive bias.
    Conversely, a negative DPPL indicates a higher proportion of positive predictions
    for facet “d,” signifying a negative bias. A DPPL near zero points to a relatively
    equal proportion of positive predictions for both facets, with a value of zero
    implying perfect demographic parity.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，q a ′ 是预测的方面“a”获得积极结果的概率，q d ′ 是类似的比例，对于二进制和多类别方面标签，标准化后的 DPPL 值介于 [-1,
    1] 之间，而连续标签在 (-∞, +∞) 区间内变化。正 DPPL 值表明方面“a”相对于“d”的正面预测比例更高，表明存在正偏差。相反，负 DPPL 指示方面“d”的正面预测比例更高，表明存在负偏差。接近零的
    DPPL 指示两个方面的正面预测比例相对相等，零值表示人口统计学上的完美平等。
- en: 'You can add the bias check to the pipeline using `ClarifyCheckStep`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 `ClarifyCheckStep` 将偏差检查添加到管道中：
- en: '[PRE23]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Explainability configuration
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可解释性配置
- en: 'The configuration for explainability is very similar. Instead of creating `BiasConfig`,
    we must create `SHAPConfig`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性的配置非常相似。我们不是创建 `BiasConfig`，而是必须创建 `SHAPConfig`：
- en: '[PRE24]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Alongside `SHAPConfig`, we must create `ModelExplainabilityCheckConfig` to
    calculate the SHAP values and create an explainability report:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `SHAPConfig` 一起，我们必须创建 `ModelExplainabilityCheckConfig` 来计算 SHAP 值并创建可解释性报告：
- en: '[PRE25]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Everything is then combined using `ClarifyCheckStep`:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用 `ClarifyCheckStep` 将所有内容组合在一起：
- en: '[PRE26]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Evaluation
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估
- en: 'Finally, we also need to evaluate our model against test data. The evaluation
    script is very similar to the training script, except it pulls the tuned model
    from S3 for scoring. The script consists of a main function with two steps. First,
    we must bootstrap the trained model and perform the scoring (in our case, calculating
    the F1 score):'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还需要使用测试数据评估我们的模型。评估脚本与训练脚本非常相似，只是它从 S3 中提取调整后的模型进行评分。该脚本由一个主函数和两个步骤组成。首先，我们必须引导训练模型并进行评分（在我们的情况下，计算
    F1 分数）：
- en: '[PRE27]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Then, we must output the results to a JSON file:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须将结果输出到 JSON 文件中：
- en: '[PRE28]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The evaluation JSON is used for reporting and subsequent steps that rely on
    the evaluation metrics.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 评估 JSON 用于报告以及依赖于评估指标的后续步骤。
- en: Deploying and monitoring the LightGBM model
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署和监控 LightGBM 模型
- en: 'We are now ready to add our pipeline’s final steps for supporting deployment.
    The deployment part of the pipeline consists of three steps:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以添加我们管道的最终步骤以支持部署。管道的部署部分由三个步骤组成：
- en: Registering the model in SageMaker.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 SageMaker 中注册模型。
- en: A conditional check to validate that the model evaluation surpasses a minimum
    threshold.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 条件检查以验证模型评估是否超过最小阈值。
- en: Deploying a model endpoint using an AWS Lambda function.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 AWS Lambda 函数部署模型端点。
- en: Model registration
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型注册
- en: To deploy our model, we first need to register our model in SageMaker’s **Model
    Registry**.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署我们的模型，我们首先需要在 SageMaker 的 **模型注册表** 中注册我们的模型。
- en: SageMaker’s Model Registry is a central repository where you can manage and
    deploy your models.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 的模型注册表是一个中央存储库，您可以在其中管理和部署您的模型。
- en: 'The Model Registry provides the following core functionality:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 模型注册表提供了以下核心功能：
- en: '**Model versioning**: Every time a model is trained and registered, it’s assigned
    a version in the Model Registry. This helps you keep track of different iterations
    of your models, which is useful when you need to compare model performance, roll
    back to previous versions, or maintain reproducibility in your ML projects.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型版本控制**：每次训练并注册模型时，模型注册表中都会为其分配一个版本。这有助于您跟踪模型的各个迭代版本，这在需要比较模型性能、回滚到先前版本或在机器学习项目中保持可重复性时非常有用。'
- en: '**Approval workflow**: The Model Registry supports an approval workflow, where
    models can be marked as “Pending Manual Approval,” “Approved,” or “Rejected.”
    This allows teams to effectively manage the life cycle of their models and ensure
    that only approved models are deployed.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**审批工作流程**：模型注册表支持审批工作流程，模型可以被标记为“待手动审批”、“已批准”或“已拒绝”。这允许团队有效地管理其模型的生命周期，并确保只有经过批准的模型被部署。'
- en: '**Model catalog**: The Model Registry acts as a catalog where all your models
    are centrally stored and accessible. Each model in the registry has metadata associated
    with it, such as the training data used, hyperparameters, and performance metrics.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型目录**：模型注册表充当一个目录，其中集中存储和访问所有模型。注册表中的每个模型都与元数据相关联，例如使用的训练数据、超参数和性能指标。'
- en: While registering our model, we attach the metrics that were calculated from
    our evaluation step. These metrics are also used for model drift detection.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在注册我们的模型时，我们附加了从评估步骤计算出的指标。这些指标也用于模型漂移检测。
- en: 'Two types of drift are possible: **data drift** and **model drift**.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 可能存在两种类型的漂移：**数据漂移**和**模型漂移**。
- en: Data drift refers to a change in the statistical distribution of the incoming
    data compared to our model’s training data. For example, if the training data
    had a male/female split of 60% to 40%, but the data used for prediction is skewed
    to 80% male and 20% female, it’s possible that drift occurred.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 数据漂移指的是与我们的模型训练数据相比，输入数据的统计分布发生变化。例如，如果训练数据中男性和女性的比例为60%到40%，但用于预测的数据偏向于80%男性与20%女性，那么可能发生了漂移。
- en: Model drift is a phenomenon where the statistical properties of the target variable,
    which the model tries to predict, change over time in unforeseen ways, causing
    model performance to degrade.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 模型漂移是一种现象，即模型试图预测的目标变量的统计属性随着时间的推移以不可预见的方式发生变化，导致模型性能下降。
- en: Both data and model drift can occur due to environmental changes, societal behaviors,
    product usage, or other factors not accounted for during model training.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 数据和模型漂移可能由于环境变化、社会行为、产品使用或其他在模型训练期间未考虑到的因素而发生。
- en: SageMaker supports continuous monitoring of drift. SageMaker calculates the
    statistical distribution of both incoming data and the predictions we are making.
    Both are compared against the distributions present in the training data. Should
    drift be detected, SageMaker can produce alerts to AWS CloudWatch.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker支持漂移的持续监控。SageMaker计算输入数据和我们所做预测的统计分布。两者都与训练数据中的分布进行比较。如果检测到漂移，SageMaker可以向AWS
    CloudWatch生成警报。
- en: 'We can configure our metrics as follows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按如下方式配置我们的指标：
- en: '[PRE29]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, for the drift metrics, we must set up `DriftCheckBaselines`:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于漂移指标，我们必须设置`DriftCheckBaselines`：
- en: '[PRE30]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, we must create a model registration step with the following code:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须创建一个包含以下代码的模型注册步骤：
- en: '[PRE31]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Model validation
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型验证
- en: 'The conditional check uses the evaluation data from the evaluation step to
    determine whether the model is suitable for deployment:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 条件检查使用评估步骤中的评估数据来确定模型是否适合部署：
- en: '[PRE32]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Here, we created `ConditionStep` and compared the F1 score against a threshold
    of `0.9`. Deployment can proceed if the model has an F1 score higher than the
    threshold.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了`ConditionStep`并比较了F1分数与`0.9`的阈值。如果模型的F1分数高于阈值，则可以继续部署。
- en: Deployment with AWS Lambda
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用AWS Lambda进行部署
- en: 'The deployment script is a standard AWS Lambda script in Python that defines
    a `lambda_handler` function that obtains a client connection to SageMaker and
    proceeds to create the model endpoint:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 部署脚本是一个标准的AWS Lambda Python脚本，它定义了一个`lambda_handler`函数，该函数获取SageMaker的客户端连接并继续创建模型端点：
- en: '[PRE33]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Notably, the Lambda function does not serve requests for the model. It only
    creates the model endpoint within SageMaker.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，Lambda函数不处理模型的请求。它仅在SageMaker中创建模型端点。
- en: In SageMaker, an **endpoint** is a web service to get predictions from your
    models. Once a model is trained and the training job is complete, you need to
    deploy the model to make real-time or batch predictions. Deployment in SageMaker
    parlance means setting up an endpoint – a hosted, production-ready model.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SageMaker 中，**端点** 是一个获取模型预测的 Web 服务。一旦模型训练完成，训练作业完成后，你需要部署模型以进行实时或批量预测。在
    SageMaker 术语中，部署意味着设置端点 – 一个托管、生产就绪的模型。
- en: An endpoint in SageMaker is a scalable and secure RESTful API that you can use
    to send real-time inference requests to your models. Your applications can access
    an endpoint to make predictions directly via the REST API or AWS SDKs. It can
    scale instances up and down as needed, providing flexibility and cost-effectiveness.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 中的端点是一个可扩展且安全的 RESTful API，你可以用它向模型发送实时推理请求。你的应用程序可以通过 REST API 或
    AWS SDK 直接访问端点进行预测。它可以按需扩展和缩减实例，提供灵活性和成本效益。
- en: SageMaker also supports multi-model endpoints, which can deploy multiple models
    on a single endpoint. This feature can significantly save on costs if many models
    are used infrequently or are not resource-intensive.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 还支持多模型端点，可以在单个端点上部署多个模型。如果许多模型使用频率不高或不是资源密集型，这个功能可以显著节省成本。
- en: 'With the Lambda script defined, it can be incorporated into the pipeline using
    `LambdaStep`:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了 Lambda 脚本后，可以使用 `LambdaStep` 将其纳入管道：
- en: '[PRE34]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Note
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: A model endpoint incurs cost as soon as it’s deployed for the duration of its
    deployment. Once you run your pipeline, an endpoint is created as a result. If
    you are only experimenting with or testing your pipeline, you should delete the
    endpoint once you’re done.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 模型端点一旦部署就会产生费用，直到其部署期间。一旦你运行了管道，就会创建一个端点。如果你只是实验或测试你的管道，你应该在完成后删除端点。
- en: Creating and running the pipeline
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建和运行管道
- en: 'All of our pipeline steps are now in place, which means we can create the pipeline
    itself. The `Pipeline` construct takes the name and parameters we’ve already defined:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的所有管道步骤现在都已就绪，这意味着我们可以创建管道本身。`Pipeline` 构造函数接受我们已定义的名称和参数：
- en: '[PRE35]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We must also pass all the steps we’ve defined as a list parameter and finally
    upsert the pipeline:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须将我们定义的所有步骤作为列表参数传递，并最终更新管道：
- en: '[PRE36]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Executing the pipeline is done by calling the `start` method:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 执行管道是通过调用 `start` 方法完成的：
- en: '[PRE37]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Note the conditions we defined here. When running the pipeline for the first
    time, we must skip the model bias and explainability checks while registering
    new bias and explainability baselines.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们在这里定义的条件。在第一次运行管道时，我们必须在注册新的偏差和可解释性基线的同时跳过模型偏差和可解释性检查。
- en: Both checks require an existing baseline to run (otherwise, there is no data
    to check against). Once baselines have been established, we can disable skipping
    the checks in subsequent runs.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个检查都需要一个现有的基线来运行（否则，没有数据可以检查）。一旦建立了基线，我们就可以在后续运行中禁用跳过检查。
- en: More information on the model life cycle and creating baselines can be found
    at [https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.xhtml).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于模型生命周期和创建基线的信息可以在 [https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.xhtml](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-quality-clarify-baseline-lifecycle.xhtml)
    找到。
- en: Results
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: 'When the pipeline is executed, you can view the execution graph to see the
    status of each step:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 当管道执行时，你可以查看执行图以查看每个步骤的状态：
- en: '![Figure 9.4 – Successful execution of the LightGBM Census Income pipeline](img/B16690_09_04.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.4 – LightGBM 人口普查收入管道成功执行](img/B16690_09_04.jpg)'
- en: Figure 9.4 – Successful execution of the LightGBM Census Income pipeline
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.4 – LightGBM 人口普查收入管道成功执行
- en: 'We can also see the model itself registered in the Model Registry once the
    pipeline completes:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦管道完成，我们还可以在模型注册表中看到已注册的模型本身：
- en: '![Figure 9.5 – SageMaker Model Registry showing the approved Census Income
    model and the related endpoint](img/B16690_09_05.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.5 – SageMaker 模型注册表显示已批准的人口普查收入模型和相关端点](img/B16690_09_05.jpg)'
- en: Figure 9.5 – SageMaker Model Registry showing the approved Census Income model
    and the related endpoint
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5 – SageMaker 模型注册表显示已批准的人口普查收入模型和相关端点
- en: 'The bias and explainability reports can be viewed when a model is selected.
    *Figure 9**.6* shows the bias report for the model that was created by the pipeline.
    We can see a slight imbalance in the DPPL for sex, but less than the class imbalance
    in the training data. The report indicates there isn’t strong evidence for bias:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 当选择模型时，可以查看偏差和可解释性报告。*图 9.6* 显示了由管道创建的模型的偏差报告。我们可以看到在 DPPL 中存在轻微的不平衡，但小于训练数据中的类别不平衡。报告表明没有强有力的证据表明存在偏差：
- en: '![Figure 9.6 – Bias report for the Census Income model. We can see a slight
    imbalance in the DPPL but less than the class imbalance in the training data](img/B16690_09_06.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.6 – 展示DPPL中轻微不平衡但小于训练数据类别不平衡的Census Income模型偏差报告](img/B16690_09_06.jpg)'
- en: Figure 9.6 – Bias report for the Census Income model. We can see a slight imbalance
    in the DPPL but less than the class imbalance in the training data
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.6 – 展示DPPL中轻微不平衡但小于训练数据类别不平衡的Census Income模型偏差报告
- en: 'The explainability report, as shown in *Figure 9**.7*, shows the importance
    of each feature in terms of SHAP values. Here, we can see that the **Capital Gain**
    and **Country** features are dominant regarding importance to predictions:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 9.7* 所示的可解释性报告显示了每个特征在 SHAP 值方面的重要性。在这里，我们可以看到 **资本收益** 和 **国家** 特征在预测的重要性方面占主导地位：
- en: '![Figure 9.7 – Explainability report for the Census Income model showing the
    dominant importance of the Capital Gain and Country features](img/B16690_09_07.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.7 – 展示资本收益和Country特征主导重要性的Census Income模型的可解释性报告](img/B16690_09_07.jpg)'
- en: Figure 9.7 – Explainability report for the Census Income model showing the dominant
    importance of the Capital Gain and Country features
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.7 – 展示资本收益和Country特征主导重要性的Census Income模型的可解释性报告
- en: The bias and explainability reports can also be downloaded in PDF format, which
    can easily be shared with business or non-technical stakeholders.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差和可解释性报告也可以下载为 PDF 格式，可以轻松地与商业或非技术利益相关者共享。
- en: Making predictions using the endpoint
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用端点进行预测
- en: 'Of course, our deployed model is not very useful if we can’t make any predictions
    using it. We can make predictions with the deployed model via REST calls or the
    Python SDK. Here is an example of using the Python SDK:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果我们不能使用部署的模型进行任何预测，那么我们的部署模型就没什么用了。我们可以通过 REST 调用或 Python SDK 使用部署的模型进行预测。以下是一个使用
    Python SDK 的示例：
- en: '[PRE38]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We obtain a SageMaker `Predictor` using the endpoint name and the session. Then,
    we can call `predict`, passing a NumPy array (obtained from a test DataFrame in
    this case).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用端点名称和会话获取 SageMaker `Predictor`，然后我们可以调用 `predict` 方法，传递一个 NumPy 数组（在本例中是从测试
    DataFrame 获取的）。
- en: With that, we have created a complete, end-to-end, production-ready pipeline
    using SageMaker. Our pipeline includes data preprocessing, automatic model tuning,
    bias validation, drift detection, and a fully scalable deployment.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 由此，我们使用 SageMaker 创建了一个完整、端到端、生产就绪的管道。我们的管道包括数据预处理、自动模型调优、偏差验证、漂移检测以及完全可扩展的部署。
- en: Summary
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter introduced AWS and Amazon SageMaker as a platform for building
    and deploying ML solutions. An overview of the SageMaker service was given, including
    the Clarify service, which provides advanced features such as model bias checks
    and explainability.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了 AWS 和 Amazon SageMaker 作为构建和部署机器学习解决方案的平台。给出了 SageMaker 服务的概述，包括 Clarify
    服务，该服务提供高级功能，如模型偏差检查和可解释性。
- en: We then proceeded to build a complete ML pipeline with the SageMaker service.
    The pipeline includes all steps of the ML life cycle, including data preparation,
    model training, tuning, model evaluation, bias checks, explainability reports,
    validation against test data, and deployment to cloud-native, scalable infrastructure.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后使用 SageMaker 服务构建了一个完整的机器学习（ML）管道。该管道包括机器学习生命周期的所有步骤，包括数据准备、模型训练、调优、模型评估、偏差检查、可解释性报告、针对测试数据的验证以及部署到云原生、可扩展的基础设施。
- en: Specific examples were given to build each step within the pipeline, emphasizing
    full automation, looking to enable straightforward retraining and constant monitoring
    of data and model processes.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了具体的示例来构建管道中的每个步骤，强调全面自动化，旨在实现简单的重新训练和持续监控数据及模型过程。
- en: 'The next chapter looks at another MLOps platform called **PostgresML**. PostgresML
    offers ML capabilities on top of a staple of the server landscape: the Postgres
    database.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将探讨另一个名为 **PostgresML** 的 MLOps 平台。PostgresML 在服务器景观的基石——Postgres 数据库之上提供机器学习功能。
- en: References
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '| *[**1]* | *S. M. Lundberg and S.-I. Lee, A Unified Approach to Interpreting
    Model Predictions, in Advances in Neural Information Processing Systems 30, I.
    Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan and R.
    Garnett, Eds., Curran Associates, Inc., 2017,* *p. 4765–4774.* |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| *[**1]* | *S. M. Lundberg 和 S.-I. Lee, 在《神经网络信息处理系统30卷进展》中，关于解释模型预测的统一方法,
    I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan 和 R.
    Garnett 编著，Curran Associates, Inc., 2017,* *第4765–4774页.* |'
- en: '| *[**2]* | *R. P. Moro and P. Cortez, Bank* *Marketing, 2012.* |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| *[**2]* | *R. P. Moro 和 P. Cortez, 银行* *营销, 2012.* |'
