- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Introduction to Recent Advancements in Machine Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习最新进展简介
- en: Supervised learning was the focus of the majority of successful applications
    of machine learning across different industries and application domains until
    2020\. However, other techniques, such as generative modeling, later caught the
    attention of developers and users of machine learning. So, an understanding of
    such techniques will help you to broaden your understanding of machine learning
    capabilities beyond supervised learning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习一直是机器学习在不同行业和应用领域成功应用的重点，直到2020年。然而，其他技术，如生成模型，后来引起了机器学习开发者和用户的关注。因此，了解这些技术将有助于你拓宽对机器学习能力的理解，超越监督学习。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Generative modeling
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成模型
- en: Reinforcement learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习
- en: Self-supervised learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自监督学习
- en: By the end of this chapter, you will have learned about the meaning, widely
    used techniques, and benefits of generative modeling, **reinforcement learning**
    (**RL**), and **self-supervised learning** (**SSL**). You will also practice some
    of these techniques using Python and PyTorch.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将了解生成模型、**强化学习**（**RL**）和**自监督学习**（**SSL**）的含义、广泛使用的技术和好处。你还将使用Python和PyTorch练习其中的一些技术。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following requirements are applicable to this chapter as they will help
    you better understand the concepts, be able to use them in your projects, and
    practice with the provided code:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以下要求适用于本章，因为它们将帮助你更好地理解概念，能够在项目中使用它们，并使用提供的代码进行实践：
- en: 'Python library requirements:'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python库要求：
- en: '`torch` >= 2.0.0'
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch` >= 2.0.0'
- en: '`torchvision` >= 0.15.1'
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torchvision` >= 0.15.1'
- en: '`matplotlib` >= 3.7.1'
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib` >= 3.7.1'
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter14](https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter14).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在GitHub上找到本章的代码文件，地址为[https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter14](https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter14)。
- en: Generative modeling
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型
- en: Generative modeling, or more generally Generative AI, provides you with the
    opportunity to generate data that is close to an expected or reference set of
    data points or distributions, commonly referred to as realistic data. One of the
    most successful applications of generative modeling has been in language modeling.
    The success story of **Generative Pre-trained Transformer** (**GPT**)-4 and ChatGPT
    ([https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)), a chatbot
    built on top of GPT-4 and GPT-3.5, and similar tools such as Perplexity ([https://www.perplexity.ai/](https://www.perplexity.ai/)),
    resulted in the rise in interest among engineers, scientists, people in different
    businesses such as finance and healthcare, and many other job roles in generative
    modeling. When using Chat-GPT or GPT-4, you can ask a question or provide the
    description of an ask, called a prompt, and then these tools generate a series
    of statements or data to provide you with the answer, information, or text you
    asked for.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型，或更普遍的生成AI，为你提供了生成接近预期或参考数据点集或分布的数据的机会，通常称为真实数据。生成模型最成功的应用之一是语言建模。**生成预训练Transformer**（**GPT**）-4和ChatGPT（[https://openai.com/blog/ChatGPT](https://openai.com/blog/ChatGPT)），这是一个建立在GPT-4和GPT-3.5之上的聊天机器人，以及类似的工具如Perplexity（[https://www.perplexity.ai/](https://www.perplexity.ai/)），引起了工程师、科学家、金融和医疗保健等不同行业的人士以及许多其他生成模型相关岗位的人士的兴趣。当使用Chat-GPT或GPT-4时，你可以提出一个问题或提供询问的描述，称为提示，然后这些工具会生成一系列陈述或数据来为你提供你请求的答案、信息或文本。
- en: In addition to the successful application of generative modeling in text generation,
    many other applications of generative modeling can help you in your work or studies.
    For example, GPT-4 and its previous versions or other similar models, such as
    LLaMA (Touvron et al., 2023), can be used for code generation and completion ([https://github.com/features/copilot/](https://github.com/features/copilot/)
    and [https://github.com/sahil280114/codealpaca](https://github.com/sahil280114/codealpaca)).
    You can write the code you are interested in generating and it generates the corresponding
    code for you. Although the generated code might not work as expected all the time,
    it is usually close to what is expected, at least after a couple of trials.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在文本生成中成功应用生成模型之外，许多其他生成模型的应用可以帮助你在工作或学习中。例如，GPT-4及其之前的版本或其他类似模型，如LLaMA（Touvron等，2023年），可用于代码生成和补全（[https://github.com/features/copilot/](https://github.com/features/copilot/)
    和 [https://github.com/sahil280114/codealpaca](https://github.com/sahil280114/codealpaca)）。你可以编写你感兴趣生成的代码，它会为你生成相应的代码。尽管生成的代码可能并不总是按预期工作，但通常在经过几次尝试后，它至少接近预期。
- en: There have also been many other successful applications of generative modeling,
    such as in image generation ([https://openai.com/product/dall-e-2](https://openai.com/product/dall-e-2)),
    drug discovery (Cheng et al., 2021), fashion design (Davis et al., 2023), manufacturing
    (Zhao et al., 2023), and so on.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型还有许多其他成功的应用，例如在图像生成（[https://openai.com/product/dall-e-2](https://openai.com/product/dall-e-2)）、药物发现（Cheng等，2021年）、时尚设计（Davis等，2023年）、制造业（Zhao等，2023年）等领域。
- en: Beginning in 2023, many traditional commercial tools and services started integrating
    Generative AI capabilities. For example, you can now edit photos using Generative
    AI in Adobe Photoshop simply by explaining what you need in plain English ([https://www.adobe.com/ca/products/photoshop/generative-fill.html](https://www.adobe.com/ca/products/photoshop/generative-fill.html)).
    WolframAlpha also combined its power of symbolic computation with Generative AI,
    which you can use to ask for specific symbolic processes in plain English ([https://www.wolframalpha.com/input?i=Generative+Adversarial+Networks](https://www.wolframalpha.com/input?i=Generative+Adversarial+Networks)).
    Khan Academy ([https://www.khanacademy.org/](https://www.khanacademy.org/)) designed
    a strategy to help teachers and students benefit from Generative AI, specifically
    ChatGPT, instead of it being harmful to the education of students.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 从2023年开始，许多传统商业工具和服务开始整合生成AI功能。例如，你现在可以使用生成AI在Adobe Photoshop中编辑照片，只需用简单的英语说明你需要什么（[https://www.adobe.com/ca/products/photoshop/generative-fill.html](https://www.adobe.com/ca/products/photoshop/generative-fill.html)）。WolframAlpha也将它的符号计算能力与生成AI结合，你可以用简单的英语请求特定的符号过程（[https://www.wolframalpha.com/input?i=Generative+Adversarial+Networks](https://www.wolframalpha.com/input?i=Generative+Adversarial+Networks)）。可汗学院（[https://www.khanacademy.org/](https://www.khanacademy.org/））制定了一种策略，帮助教师和学生从生成AI中受益，特别是ChatGPT，而不是对学生的教育造成伤害。
- en: These success stories have been achieved by relying on different deep learning
    techniques designed for generative modeling, which we will briefly review next.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这些成功故事是通过依赖为生成模型设计的不同深度学习技术实现的，我们将在下面简要回顾。
- en: Generative deep learning techniques
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成深度学习技术
- en: There are multiple generative modeling approaches with available the APIs available
    in PyTorch or other deep learning frameworks, such as TensorFlow. Here, we will
    review some of them to help you start learning more about how they work and how
    you can use them in Python.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyTorch或其他深度学习框架（如TensorFlow）中，有多种生成模型方法可供使用。在这里，我们将回顾其中的一些，以帮助你开始了解它们是如何工作的，以及你如何在Python中使用它们。
- en: Transformer-based text generation
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于Transformer的文本生成
- en: You already learned that transformers, introduced in 2017 (Vaswani et al., 2017),
    are used to generate the most successful recent language models in [*Chapter 13*](B16369_13.xhtml#_idTextAnchor342),
    *Advanced Deep Learning Techniques*. However, these models are not useful only
    for tasks such as translation, which is traditional in natural language processing,
    but can be used in generative modeling to help us generate meaningful text, for
    example, in response to a question we ask. This is the approach behind GPT models,
    Chat-GPT, and many other generative language models. The process of providing
    a short text, as an ask or a question, is also called prompting, in which we need
    to provide a good prompt to get a good answer. We will talk about optimal prompting
    in the *Prompt engineering for text-based generative* *models* section.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经了解到，2017年引入的转换器（Vaswani et al., 2017）被用于生成最近最成功的语言模型，这在[*第13章*](B16369_13.xhtml#_idTextAnchor342)“高级深度学习技术”中有详细描述。然而，这些模型并不仅限于像翻译这样的传统自然语言处理任务，它们还可以用于生成建模，帮助我们生成有意义的文本，例如，回答我们提出的问题。这正是GPT模型、Chat-GPT以及许多其他生成语言模型背后的方法。提供简短文本作为提问或问题的过程也被称为提示（prompting），在这个过程中，我们需要提供一个好的提示以获得好的答案。我们将在“基于文本的生成模型的提示工程”部分讨论最优提示。
- en: Variational autoencoders (VAEs)
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 变分自编码器（VAEs）
- en: Autoencoders are techniques with which you can reduce the number of features
    to an information-rich set of embeddings, which you can consider a more complicated
    version of **principal component analysis** (**PCA**) to better understand it.
    It does that by first attempting to encode the original space to the new embedding
    (called encoding), then decode the embeddings, and regenerate the original features
    for each data point (called decoding). In a VAE (Kingma and Welling, 2013), instead
    of one set of features (embeddings), it generates a distribution for each new
    feature. For example, instead of reducing the original 1,000 features to 100 features,
    each having one float value, you get 100 new variables, each being a normal (or
    Gaussian) distribution. The beauty of this process is that then you can select
    different values from these distributions for each variable and generate a new
    set of 100 embeddings. In the process of decoding them, these embeddings get decoded
    and a new set of features with the original size (1,000) gets generated. This
    process can be used for different types of data such as images (Vahdat et al.,
    2020) and graphs (Simonovsky et al., 2018; Wengong et al., 2018). You can find
    a collection of VAEs implemented in PyTorch at [https://github.com/AntixK/PyTorch-VAE](https://github.com/AntixK/PyTorch-VAE).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一种技术，你可以将特征数量减少到一个信息丰富的嵌入集，你可以将其视为**主成分分析**（PCA）的更复杂版本，以更好地理解它。它是通过首先尝试将原始空间编码到新的嵌入（称为编码），然后解码嵌入，并为每个数据点（称为解码）重新生成原始特征来实现的。在VAE（Kingma
    and Welling, 2013）中，它不是生成一组特征（嵌入），而是为每个新特征生成一个分布。例如，不是将原始的1,000个特征减少到100个特征，每个特征有一个浮点值，而是得到100个新的变量，每个变量都是一个正态分布（或高斯分布）。这个过程的美妙之处在于，然后你可以从这些分布中选择不同的值来为每个变量生成一组新的100个嵌入。在解码它们的过程中，这些嵌入被解码，并生成一组具有原始大小（1,000）的新特征。这个过程可以用于不同类型的数据，如图像（Vahdat
    et al., 2020）和图（Simonovsky et al., 2018; Wengong et al., 2018）。你可以在[https://github.com/AntixK/PyTorch-VAE](https://github.com/AntixK/PyTorch-VAE)找到实现PyTorch的VAE的集合。
- en: Generative Adversarial Networks (GANs)
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成对抗网络（GANs）
- en: In this technique introduced in 2014 (Goodfellow et al., 2020), a discriminator
    that works like a supervised classification model and a generator work alongside
    each other. The generator, which could be a neural network architecture for generating
    the desired data types, such as images, generates images aiming to fool the discriminator
    into recognizing the generated data as real data. The discriminator learns to
    remain good at distinguishing generated data from real data. The generated data
    in some cases is called fake data, as in technologies and models such as deepfakes
    ([https://www.businessinsider.com/guides/tech/what-is-deepfake](https://www.businessinsider.com/guides/tech/what-is-deepfake)).
    However, the generated data can be used as opportunities for new data points to
    be used in different applications, such as drug discovery (Prykhodko et al., 2019).
    You can use `torchgan` to implement GANs ([https://torchgan.readthedocs.io/en/latest/](https://torchgan.readthedocs.io/en/latest/)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在2014年引入的这项技术（Goodfellow et al., 2020）中，一个类似于监督分类模型的判别器和生成器协同工作。生成器，可能是一个用于生成所需数据类型（如图像）的神经网络架构，旨在生成图像以欺骗判别器，使其将生成的数据识别为真实数据。判别器学习如何保持区分生成数据和真实数据的能力。在某些情况下，生成的数据被称为假数据，例如在深度伪造（[https://www.businessinsider.com/guides/tech/what-is-deepfake](https://www.businessinsider.com/guides/tech/what-is-deepfake)）等技术模型中。然而，生成的数据可以作为新数据点在不同应用中使用的机会，例如药物发现（Prykhodko
    et al., 2019）。你可以使用`torchgan`来实现GANs（[https://torchgan.readthedocs.io/en/latest/](https://torchgan.readthedocs.io/en/latest/)）。
- en: As there has been an emerging generation of prompt-based technologies built
    on top of generative models, we will provide a better understanding of how to
    optimally design prompts next.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由于基于生成模型之上涌现出一批基于提示的技术，我们将提供如何最优设计提示的更好理解。
- en: Prompt engineering for text-based generative models
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于文本生成模型的提示工程
- en: Prompt engineering is not only a recent topic in machine learning but has also
    become a highly paid job title. In prompt engineering, we aim to provide optimal
    prompts to generate the best possible result (for example, text, code, and images)
    and identify issues with the generative models as opportunities for improving
    them. A basic understanding of large language and generative models, your language
    proficiency, and domain knowledge for domain-specific data generation can help
    you in better prompting. There are free resources that you can use to learn about
    prompt engineering, such as a course by Andrew Ng and OpenAI ([https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/))
    and some introductory content about prompt engineering released by Microsoft ([https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/prompt-engineering](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/prompt-engineering)).
    However, we will not leave you to learn this topic from scratch by yourself. We
    will provide you with some guidance for optimal prompting here that will help
    you improve your prompting skills.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程不仅是在机器学习中的一个新兴话题，而且已经成为一个高薪的职位名称。在提示工程中，我们的目标是提供最优的提示以生成最佳可能的结果（例如，文本、代码和图像），并将生成模型的问题识别为改进它们的机会。对大型语言和生成模型的基本理解、你的语言熟练度和特定领域的数据生成领域的专业知识可以帮助你更好地进行提示。有一些免费资源可以帮助你学习提示工程，例如Andrew
    Ng和OpenAI提供的一门课程（[https://www.deeplearning.ai/short-courses/ChatGPT-prompt-engineering-for-developers/](https://www.deeplearning.ai/short-courses/ChatGPT-prompt-engineering-for-developers/)）以及微软发布的一些关于提示工程的入门内容（[https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/prompt-engineering](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/prompt-engineering)）。然而，我们不会让你自己从头开始学习这个话题。在这里，我们将提供一些关于最优提示的指导，这将帮助你提高你的提示技能。
- en: Targeted prompting
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目标提示
- en: 'In our daily conversations, either at work, university, or home, there are
    ways we try to make sure the person across from us better understands what we
    mean, and as a result, we get a better response. For example, if you tell your
    friend, “Give me that” instead of “Give me that bottle of water on the desk,”
    there is a chance that your friend won’t give you the bottle of water or get confused
    about what exactly you are referring to. In prompting, you can get better responses
    and data generated, such as images, if you clearly explain what you want for a
    very specific task. Here are a few techniques to use for better prompting:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的日常对话中，无论是在工作、大学还是家里，我们都有方法确保对方更好地理解我们的意思，从而得到更好的回应。例如，如果你对朋友说“给我那个”，而不是“给我桌子上那瓶水”，你的朋友可能不会给你那瓶水，或者对你具体指的是什么感到困惑。在提示中，如果你清楚地解释了针对一个非常具体的任务你想要什么，你可以得到更好的回应和生成数据，比如图像。以下是一些用于更好提示的技术：
- en: '**Be specific about the ask**: You can provide specific information such as
    the format of the data you would like to be generated, such as bullet points or
    code, and the task you are referring to, such as writing an email versus a business
    plan.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**明确要求**：你可以提供具体信息，例如你希望生成的数据的格式，如项目符号或代码，以及你所指的任务，如撰写电子邮件与编写商业计划。'
- en: '**Specify who the data is getting generated for**: You can even specify an
    expertise or job title for whom the data is getting generated, such as generating
    a piece of text for a machine learning engineer, business manager, or software
    developer.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指定数据生成对象**：你甚至可以指定为谁生成数据的专业技能或职位，例如为机器学习工程师、业务经理或软件开发人员生成一段文本。'
- en: '**Specify time**: You can specify whether you want information about the date
    when technology got released, the first time something was announced, the chronological
    order of events, the change in something such as the net worth of a famous rich
    person such as Elon Musk over time, and so on.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指定时间**：你可以指定你想要的信息，比如技术发布日期、某事首次宣布的时间、事件的年代顺序，以及像埃隆·马斯克这样的名人随时间变化的净资产变化等等。'
- en: '**Simplify the concepts**: You can provide a simplified version of what you
    ask to make sure the model doesn’t get confused by the complexity of your prompt.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简化概念**：你可以提供一个简化的版本，确保模型不会被你提示的复杂性所困惑。'
- en: Although these techniques will help you in better prompting, there is still
    a chance of getting false answers with high confidence if you ask for a text response
    or unrelated data generation. This is what is usually referred to as a hallucination.
    One of the ways to decrease the chance of irrelevant or wrong responses or data
    generation is to provide tests for the model to use. When we write functions and
    classes in Python, we can design unit tests to make sure their output meets the
    expectation, as discussed in [*Chapter 8*](B16369_08.xhtml#_idTextAnchor243),
    *Controlling Risks Using* *Test-Driven Development*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些技巧可以帮助你更好地进行提示，但如果要求文本响应或生成无关数据，仍然有可能得到高度自信的虚假答案。这通常被称为幻觉。减少无关或不正确响应或数据生成机会的一种方法是为模型提供测试。当我们用Python编写函数和类时，我们可以设计单元测试来确保它们的输出符合预期，正如在第[*8章*](B16369_08.xhtml#_idTextAnchor243)中讨论的，*使用测试驱动开发控制风险*。
- en: Generative modeling using PyTorch
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PyTorch进行生成建模
- en: You can develop generative models based on different techniques discussed earlier
    in this chapter using PyTorch. We want to practice with VAEs here. With VAEs,
    the aim is to identify a probability distribution for a lower-dimensional representation
    of data. For example, the model learns about the mean and variance (or log variance)
    for the representations of the input parameters, assuming normal or Gaussian distribution
    for the latent space (that is, the space of the latent variables or representations).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用本章前面讨论的不同技术，基于PyTorch开发生成模型。我们在这里想练习使用VAEs。VAE的目标是为数据的低维表示找到一个概率分布。例如，模型学习关于输入参数表示的均值和方差（或对数方差），假设潜在空间（即潜在变量或表示的空间）为正态或高斯分布。
- en: 'We first import the required libraries and modules and load the `Flowers102`
    dataset from PyTorch:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入所需的库和模块，并从PyTorch加载`Flowers102`数据集：
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we define a class for the VAE as follows in which two linear layers are
    defined to encode the input pixels of images. Then, the mean and variance of the
    probability distribution of latent space are also defined by two linear layers
    for decoding the latent variables back to the original number of inputs to generate
    images similar to the input data. The learned mean and variance of the distribution
    in latent space will be then used to generate new latent variables and potentially
    generate new data:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义了一个用于VAE的类，如下所示，其中定义了两个线性层来编码图像的输入像素。然后，通过两个线性层定义了潜在空间概率分布的均值和方差，以便将潜在变量解码回原始输入数量以生成与输入数据相似的图像。在潜在空间中学习的分布的均值和方差将被用来生成新的潜在变量，并可能生成新的数据：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We now initialize the defined `VAE` class and determine the `Adam` optimizer
    as the optimization algorithm with `0.002` as the learning rate:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们初始化定义的`VAE`类，并将`Adam`优化器作为优化算法，学习率为`0.002`：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We then define a loss function using `binary_cross_entropy` as follows to compare
    the regenerated pixels with the input pixels:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义了一个使用`binary_cross_entropy`的损失函数，如下所示，以比较重新生成的像素与输入像素：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we are ready to train the model using the `Flowers102` dataset we loaded
    before:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备使用之前加载的`Flowers102`数据集来训练模型：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We can then use this trained model to generate images that almost look like
    flowers (see *Figure 14**.1*). Upon hyperparameter optimization, such as changing
    the model's architecture, you can achieve better results. You can review hyperparameter
    optimization in deep learning in [*Chapter 12*](B16369_12.xhtml#_idTextAnchor320),
    *Going Beyond ML Debugging with* *Deep Learning*.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用这个训练好的模型来生成几乎像花朵一样的图像（见*图14**.1*）。通过超参数优化，例如改变模型的架构，你可以获得更好的结果。你可以在[*第12章*](B16369_12.xhtml#_idTextAnchor320)中回顾深度学习中的超参数优化，*超越机器学习调试的深度学习*。
- en: '![Figure 14.1 – Example images generated by the simple VAE we developed earlier](img/B16369_14_01.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图14.1 – 我们之前开发的简单VAE生成的示例图像](img/B16369_14_01.jpg)'
- en: Figure 14.1 – Example images generated by the simple VAE we developed earlier
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.1 – 我们之前开发的简单VAE生成的示例图像
- en: This was a simple example of generative modeling using PyTorch. In spite of
    the success of generative modeling, part of the recent success of tools developed
    using generative models, such as Chat-GPT, is due to the smart use of reinforcement
    learning, which we will discuss next.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个使用PyTorch进行生成建模的简单示例。尽管生成建模取得了成功，但最近使用生成模型开发的工具（如Chat-GPT）的部分成功归功于强化学习的智能使用，我们将在下一节中讨论。
- en: Reinforcement learning
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习
- en: '**Reinforcement learning** (**RL**) is not a new idea or technique. The initial
    idea dates back to the 1950s, when it was introduced by Richard Bellman with the
    concept of the Bellman equation (Sutton and Barto, 2018). However, its recent
    combination with human feedback, which we will explain in the next section, provided
    a new opportunity for its utility in developing machine learning technologies.
    The general idea of RL is to learn by experience, or interaction with a specified
    environment, instead of using a collected set of data points for training, as
    in supervised learning. An agent is considered in RL, which learns how to improve
    actions to get a greater reward (Kaelbling et al., 1996). The agent learns to
    improve its approach to taking action, or policy in more technical terminology,
    iteratively after receiving the reward of the action taken in the previous step.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**强化学习**（**RL**）不是一个新想法或技术。其最初的想法可以追溯到20世纪50年代，当时由理查德·贝尔曼提出，并引入了贝尔曼方程（Sutton和Barto，2018）。然而，它最近与人类反馈的结合，我们将在下一节中解释，为它在开发机器学习技术中的效用提供了新的机会。强化学习的一般思想是通过经验学习，或与指定环境的交互，而不是像监督学习那样使用收集到的数据点集进行训练。在强化学习中，考虑了一个代理，它学习如何改进动作以获得更大的奖励（Kaelbling等人，1996）。代理在接收到前一步采取的动作的奖励后，会迭代地改进其采取行动的方法，或更技术性地说是策略。'
- en: In the history of RL, two important developments and utilities resulted in an
    increase in its popularity including the development of Q-learning (Watkins, 1989)
    and combining RL and deep learning (Mnih et al., 2013) using Q-learning. In spite
    of the success stories behind RL and the intuition that it mimics learning by
    experience as humans do, it has been shown that deep reinforcement learning is
    not data efficient and requires large amounts of data or iterative experience,
    which makes it fundamentally different from human learning (Botvinick et al.,
    2019).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在 RL 的历史上，两个重要的发展和用途导致了其流行度的增加，包括 Q-learning（Watkins，1989）的发展以及使用 Q-learning
    将 RL 和深度学习（Mnih 等人，2013）相结合。尽管 RL 背后的成功故事和它模仿人类经验学习的直觉，但已经证明深度强化学习不是数据高效的，需要大量的数据或迭代经验，这使得它与人类学习在本质上不同（Botvinick
    等人，2019）。
- en: More recently, **reinforcement learning with human feedback** (**RLHF**) was
    used as a successful application of reinforcement learning to improve the results
    of generative models, which we will discuss next.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，**带有人类反馈的强化学习**（**RLHF**）被用作强化学习成功应用于改进生成模型结果的应用，我们将在下文中讨论。
- en: Reinforcement learning with human feedback (RLHF)
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带有人类反馈的强化学习（RLHF）
- en: 'With reinforcement learning with human feedback, the reward is calculated based
    on the feedback of humans, either experts or non-experts, depending on the problem.
    However, the reward is not like a predefined mathematical formula considering
    the complexity of the problems such as language modeling. The feedback provided
    by humans results in improving the model step by step. For example, the training
    process of a RLHF language model can be summarized as follows ([https://huggingface.co/blog/rlhf](https://huggingface.co/blog/rlhf)):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用带有人类反馈的强化学习，奖励是根据人类反馈计算的，无论是专家还是非专家，这取决于问题。然而，奖励并不是一个预定义的数学公式，考虑到问题的复杂性，如语言模型。人类提供的反馈会导致模型逐步改进。例如，RLHF
    语言模型的训练过程可以总结如下 ([https://huggingface.co/blog/rlhf](https://huggingface.co/blog/rlhf))：
- en: Training a language model, which is referred to as pretraining.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练语言模型，这被称为预训练。
- en: Data collection and training the reward model.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据收集和训练奖励模型。
- en: Fine-tuning the language model with reinforcement learning using the reward
    model.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用奖励模型通过强化学习微调语言模型。
- en: However, learning how to use PyTorch to design RLHF-based models could be helpful
    to better understand this concept.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，学习如何使用 PyTorch 设计基于 RLHF 的模型可能有助于更好地理解这一概念。
- en: RLHF with PyTorch
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于 PyTorch 的 RLHF
- en: One of the major challenges in benefitting from RLHF is designing an infrastructure
    for human feedback collection and curation, then providing them to calculate the
    reward, and then improving the main pre-trained model. Here, we don’t want to
    get into that aspect of RLHF but rather go through a simple code example to understand
    how such feedback can be incorporated into a machine learning model. There are
    good resources, such as [https://github.com/lucidrains/PaLM-rlhf-pytorch](https://github.com/lucidrains/PaLM-rlhf-pytorch),
    that can help you to improve your understanding of RLHF and how to implement it
    using Python and PyTorch.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从 RLHF 中受益的一个主要挑战是设计用于人类反馈收集和整理的基础设施，然后提供它们来计算奖励，然后改进主要预训练模型。在这里，我们不想深入探讨 RLHF
    的这一方面，而是通过一个简单的代码示例来了解如何将此类反馈纳入机器学习模型。有一些很好的资源，如 [https://github.com/lucidrains/PaLM-rlhf-pytorch](https://github.com/lucidrains/PaLM-rlhf-pytorch)，可以帮助你更好地理解
    RLHF 以及如何使用 Python 和 PyTorch 来实现它。
- en: 'Here, we will use GPT-2 ([https://huggingface.co/transformers/v1.2.0/_modules/pytorch_transformers/modeling_gpt2.html](https://huggingface.co/transformers/v1.2.0/_modules/pytorch_transformers/modeling_gpt2.html))
    as the pre-trained model. First, we import the necessary libraries and modules
    and initialize the model, tokenizer, and optimizer, which is chosen to be `Adam`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用 GPT-2 ([https://huggingface.co/transformers/v1.2.0/_modules/pytorch_transformers/modeling_gpt2.html](https://huggingface.co/transformers/v1.2.0/_modules/pytorch_transformers/modeling_gpt2.html))
    作为预训练模型。首先，我们导入必要的库和模块，并初始化模型、分词器和优化器，这里选择的是 `Adam`：
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, assuming we collected the human feedback and formatted it properly, we
    can use it to create a DataLoader from PyTorch:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们已经收集了人类反馈并正确格式化，我们可以使用它来创建一个来自 PyTorch 的 DataLoader：
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The next step is to design a reward model, for which we use a two-layer fully
    connected neural network:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是设计一个奖励模型，我们使用一个两层全连接神经网络：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We then initialize the reward model using the previously defined class:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用先前定义的类初始化奖励模型：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We are now ready to improve our pre-trained model using the collected human
    feedback and the reward model. If you pay attention to the following code, the
    main difference between this simple loop over epochs and batches for model training
    compared to neural networks without a reward model is the reward calculation and
    then using it for loss calculation:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用收集到的人类反馈和奖励模型来改进我们的预训练模型。如果你注意以下代码，与没有奖励模型的神经网络相比，这个简单的循环遍历epochs和batches进行模型训练的主要区别在于奖励计算，然后将其用于损失计算：
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This was a very simple example of designing RLHF-based model improvement, used
    to help you better understand the concept. Resources such as [https://github.com/lucidrains/PaLM-rlhf-pytorch](https://github.com/lucidrains/PaLM-rlhf-pytorch)
    will help you to implement more complex ways of incorporating such human feedback
    for improving your models.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个设计基于RLHF的模型改进的非常简单的例子，用于帮助你更好地理解这个概念。例如，[https://github.com/lucidrains/PaLM-rlhf-pytorch](https://github.com/lucidrains/PaLM-rlhf-pytorch)这样的资源将帮助你实现更复杂的方法，将此类人类反馈纳入模型改进。
- en: Next, let’s go through another interesting topic in machine learning, called
    self-supervised learning.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们探讨机器学习中的另一个有趣话题，称为自监督学习。
- en: Self-supervised learning (SSL)
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自监督学习（SSL）
- en: '**Self-supervised learning** (**SSL**) is not a new concept. It''s similar
    to RL, but it gained attention after its combination with deep learning due to
    its effectiveness in learning data representations. Examples of such models are
    Word2vec for language modeling (Mikolov et al., 2013) and Meta’s RoBERTa models
    trained using SSL, which achieved state-of-the-art performance on several language
    modeling tasks. The idea of SSL is to define an objective for the machine learning
    model that doesn’t rely on pre-labeling or the quantification of data points –
    for example, predicting the positions of objects or people in videos for each
    time step using previous time steps, masking parts of images or sequence data,
    and aiming to refill those masked sections. One of the widely used applications
    of such models is in RL to learn representations of images and text, and then
    use those representations in other contexts, for example, in supervised modeling
    of smaller datasets with data labels (Kolesnikov et al., 2019, Wang et al., 2020).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**自监督学习**（**SSL**）不是一个新概念。它与强化学习类似，但由于其在学习数据表示方面的有效性，在深度学习结合之后引起了人们的关注。此类模型的例子包括用于语言建模的Word2vec（Mikolov等人，2013年）和Meta的RoBERTa模型，这些模型使用SSL训练，在多个语言建模任务上取得了最先进的性能。SSL的想法是为机器学习模型定义一个目标，该目标不依赖于预先标记或数据点的量化——例如，使用前一时间步预测视频中的对象或人的位置，遮盖图像或序列数据的一部分，并试图填充这些被遮盖的部分。此类模型的一个广泛应用的例子是在强化学习中学习图像和文本的表示，然后在其他上下文中使用这些表示，例如，在带有数据标签的小数据集上进行监督建模（Kolesnikov等人，2019年，王等人，2020年）。'
- en: 'There are multiple techniques under the umbrella of SSL, three of which are
    as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: SSL的范畴下有多个技术，以下列举三个：
- en: '**Contrastive learning**: The idea of contrastive learning is to learn representations
    that result in similar data points being closer to each other compared to dissimilar
    data points (Jaiswal et al., 2020).'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对比学习**：对比学习的想法是学习表示，使得相似的数据点比不相似的数据点更接近（Jaiswal等人，2020年）。'
- en: '**Autoregressive models**: In autoregressive modeling, the model aims to predict
    the next data points, either based on time or a specific sequence order, given
    the previous ones. This is a very popular technique in language modeling, where
    models such as GPT predict the next word in a sentence (Radford et al., 2019).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自回归模型**：在自回归建模中，模型旨在根据之前的数据点预测下一个数据点，无论是基于时间还是特定的序列顺序。这在语言建模中是一个非常流行的技术，例如GPT模型预测句子中的下一个单词（Radford等人，2019年）。'
- en: '**Self-supervision via inpainting**: In this approach, we mask parts of the
    data and train the models to fill in the missing parts. For example, a portion
    of an image might be masked, and the model is trained to predict the masked portion.
    Masked autoencoder is an example of such a technique in which the masked portions
    of images are refilled in the decoding process of the autoencoder (Zhang et al.,
    2022).'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过修复缺失部分进行自监督**：在这种方法中，我们遮盖数据的一部分，并训练模型来填补缺失的部分。例如，图像的一部分可能被遮盖，模型被训练来预测被遮盖的部分。遮盖自动编码器是这种技术的一个例子，其中自动编码器的解码过程中填充了图像被遮盖的部分（张等人，2022年）。'
- en: Next, we will practice with a simple example of self-supervised modeling using
    Python and PyTorch.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过一个简单的Python和PyTorch自监督建模示例进行练习。
- en: Self-supervised learning with PyTorch
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PyTorch的自监督学习
- en: From a programming perspective, the main difference between deep learning for
    SSL compared to supervised learning is in defining the objectives and data for
    training and testing. Here, we want to practice with `Flowers102` dataset we used
    to practice with RLHF.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 从编程的角度来看，与监督学习相比，SSL深度学习的主要区别在于定义训练和测试的目标和数据。在这里，我们想使用我们用来练习RLHF的`Flowers102`数据集进行练习。
- en: 'We first define the neural network class using two encoding and decoding `torch.nn.Conv2d()`
    layers as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用两个编码和解码`torch.nn.Conv2d()`层定义神经网络类，如下所示：
- en: '[PRE10]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We then initialize the model, specify `torch.nn.MSELoss()` as the criterion
    for comparison of predicted and true images, and `torch.optim.Adam()` as the optimizer
    with a learning rate of `0.001`:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们初始化模型，指定`torch.nn.MSELoss()`作为预测图像和真实图像比较的标准，以及`torch.optim.Adam()`作为优化器，学习率为`0.001`：
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following function helps us to implement masking on random 8x8 portions
    of each image, which then the autoencoder learns to fill:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数帮助我们实现对每个图像随机8x8部分的掩码，然后自动编码器学习填充这些部分：
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, we train the model for 200 epochs as follows. As you can see in *Figure
    14**.2*, the images first get masked, and then in the decoding step, the autoencoder
    attempts to rebuild the full image, including the masked portions:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们按照以下方式训练模型200个epoch。正如你在*图14.2*中可以看到的，图像首先被掩码，然后在解码步骤中，自动编码器试图重建完整的图像，包括掩码部分：
- en: '[PRE13]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As you can see in the examples of the resulting refilled images shown in *Figure
    14**.2*, the model could find the patterns correctly. However, with proper hyperparameter
    optimization and designing models with better neural network architectures, you
    can achieve higher performance and better models.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*图14.2*中看到的填充图像的示例中所示，模型能够正确地找到模式。然而，通过适当的超参数优化和设计具有更好神经网络架构的模型，你可以实现更高的性能和更好的模型。
- en: '![Figure 14.2 – Example images (first row), their masked versions (second row),
    and regenerated versions (third row) using the convolutional autoencoder model](img/B16369_14_02.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图14.2 – 使用卷积自动编码器模型的示例图像（第一行）、其掩码版本（第二行）和再生版本（第三行）](img/B16369_14_02.jpg)'
- en: Figure 14.2 – Example images (first row), their masked versions (second row),
    and regenerated versions (third row) using the convolutional autoencoder model
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.2 – 使用卷积自动编码器模型的示例图像（第一行）、其掩码版本（第二行）和再生版本（第三行）
- en: You can read more about SSL and the other techniques provided in this chapter
    using the provided resources and references to better understand these concepts.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过提供的资源和参考资料了解更多关于SSL和本章中提供的技术，以更好地理解这些概念。
- en: Summary
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you gained a high-level understanding of recent advancements
    in machine learning modeling beyond supervised learning, including generative
    modeling, reinforcement learning, and self-supervised learning. You also learned
    about optimal prompting and prompt engineering to benefit from tools and applications
    built on top of generative models that accept text prompts as input from users.
    You were provided with the relevant code repositories and functionalities available
    in Python and PyTorch that will help you to start learning more about these advanced
    techniques. This knowledge helps you not only better understand how they work
    if you come across them but also start building models of your own using these
    advanced techniques.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你获得了对机器学习建模中监督学习之外的最新进展的高级理解，包括生成建模、强化学习和自监督学习。你还了解了最佳提示和提示工程，以便从基于生成模型并接受用户文本提示的工具和应用中受益。你提供了相关的代码仓库和Python和PyTorch中可用的功能，这将帮助你开始学习这些高级技术。这些知识不仅帮助你更好地理解它们是如何工作的，如果你遇到它们，而且开始使用这些高级技术构建自己的模型。
- en: In the next chapter, you will learn about the benefits of identifying causal
    relationships in machine learning modeling and practice with Python libraries
    that help you in implementing causal modeling.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将了解在机器学习建模和实践中识别因果关系的好处，以及使用Python库实现因果建模的示例。
- en: Questions
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are examples of generative deep learning techniques?
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成深度学习技术的例子有哪些？
- en: What are examples of generative text models that use transformers?
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用transformers的生成文本模型的例子有哪些？
- en: What are generators and discriminators in GANs?
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GAN中的生成器和判别器是什么？
- en: What are some of the techniques you can use for better prompting?
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用哪些技术来提高提示的效果？
- en: Could you explain how RL could be helpful in importing the results of generative
    models?
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能解释一下强化学习如何有助于导入生成模型的结果吗？
- en: Briefly explain contrastive learning.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 简要解释对比学习。
- en: References
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Cheng, Yu, et al. “*Molecular design in drug discovery: a comprehensive review
    of deep generative models*.” *Briefings in bioinformatics* 22.6 (2021): bbab344.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cheng, Yu, 等人. “*药物发现中的分子设计：深度生成模型的全面综述*。” *生物信息学简报* 22.6 (2021): bbab344.'
- en: 'Davis, Richard Lee, et al. “*Fashioning the Future: Unlocking the Creative
    Potential of Deep Generative Models for Design Space Exploration*.” *Extended
    Abstracts of the 2023 CHI Conference on Human Factors in Computing* *Systems*
    (2023).'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Davis, Richard Lee, 等人. “*塑造未来：解锁深度生成模型在设计空间探索中的创造潜能*。” *2023年CHI会议关于人机交互系统人类因素扩展摘要*
    (2023).
- en: 'Zhao, Yaoyao Fiona, et al., eds. “*Design for Advanced Manufacturing*.” *Journal
    of Mechanical Design* 145.1 (2023): 010301.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhao, Yaoyao Fiona, 等人，编。 “*高级制造设计*。” *机械设计杂志* 145.1 (2023): 010301.'
- en: 'Touvron, Hugo, et al. “*Llama: Open and efficient foundation language models*.”
    arXiv preprint arXiv:2302.13971 (2023).'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Touvron, Hugo, 等人. “*Llama：开放且高效的基金会语言模型*。” arXiv预印本 arXiv:2302.13971 (2023).
- en: Vaswani, Ashish, et al. “*Attention is all you need*.” *Advances in neural information
    processing systems* 30 (2017).
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani, Ashish, 等人. “*注意力即所需*。” *神经信息处理系统进展* 30 (2017).
- en: Kingma, Diederik P., and Max Welling. “*Auto-encoding variational bayes*.” arXiv
    preprint arXiv:1312.6114 (2013).
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma, Diederik P., 和 Max Welling. “*自动编码变分贝叶斯*。” arXiv预印本 arXiv:1312.6114
    (2013).
- en: 'Vahdat, Arash, and Jan Kautz. “*NVAE: A deep hierarchical variational autoencoder*.”
    *Advances in neural information processing systems* 33 (2020): 19667-19679.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vahdat, Arash, 和 Jan Kautz. “*NVAE：一种深度分层变分自动编码器*。” *神经信息处理系统进展* 33 (2020):
    19667-19679.'
- en: 'Simonovsky, Martin, and Nikos Komodakis. “*Graphvae: Towards generation of
    small graphs using variational autoencoders*.” *Artificial Neural Networks and
    Machine Learning–ICANN 2018: 27th International Conference on Artificial Neural
    Networks*, Rhodes, Greece, October 4-7, 2018, Proceedings, Part I 27\. Springer
    International Publishing (2018).'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simonovsky, Martin, 和 Nikos Komodakis. “*Graphvae：使用变分自动编码器生成小图*。” *人工神经网络与机器学习–ICANN
    2018：第27届国际人工神经网络会议，希腊罗得岛，2018年10月4-7日，会议论文集，第1部分* 27\. Springer国际出版社 (2018).
- en: Jin, Wengong, Regina Barzilay, and Tommi Jaakkola. “*Junction tree variational
    autoencoder for molecular graph generation*.” *International conference on machine
    learning*. PMLR (2018).
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin, Wengong, Regina Barzilay, 和 Tommi Jaakkola. “*用于分子图生成的连接树变分自动编码器*。” *机器学习国际会议*
    PMLR (2018).
- en: 'Goodfellow, Ian, et al. “*Generative adversarial networks*.” *Communications
    of the ACM* 63.11 (2020): 139-144.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Goodfellow, Ian, 等人. “*生成对抗网络*。” *ACM通讯* 63.11 (2020): 139-144.'
- en: Karras, Tero, Samuli Laine, and Timo Aila. “*A style-based generator architecture
    for generative adversarial networks*.” *Proceedings of the IEEE/CVF conference
    on computer vision and pattern* *recognition* (2019).
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karras, Tero, Samuli Laine, 和 Timo Aila. “*基于风格的生成对抗网络生成器架构*。” *IEEE/CVF计算机视觉与模式识别会议论文集*
    (2019).
- en: 'Prykhodko, Oleksii, et al. “*A de novo molecular generation method using latent
    vector based generative adversarial network*.” *Journal of Cheminformatics* 11.1
    (2019): 1-13.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Prykhodko, Oleksii, 等人. “*基于潜在向量生成对抗网络的从头分子生成方法*。” *化学信息学杂志* 11.1 (2019): 1-13.'
- en: 'Sutton, Richard S., and Andrew G. Barto. *Reinforcement learning: An introduction*.
    MIT Press (2018).'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sutton, Richard S., 和 Andrew G. Barto. *强化学习：入门*。 MIT出版社 (2018).
- en: 'Kaelbling, Leslie Pack, Michael L. Littman, and Andrew W. Moore. “*Reinforcement
    learning: A survey*.” *Journal of artificial intelligence research* 4 (1996):
    237-285.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kaelbling, Leslie Pack, Michael L. Littman, 和 Andrew W. Moore. “*强化学习：综述*。”
    *人工智能研究杂志* 4 (1996): 237-285.'
- en: Watkins, Christopher John Cornish Hellaby. *Learning from delayed* *rewards*.
    (1989).
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Watkins, Christopher John Cornish Hellaby. *从延迟奖励中学习*。 (1989).
- en: Mnih, Volodymyr, et al. “*Playing atari with deep reinforcement learning*.”
    arXiv preprint arXiv:1312.5602 (2013).
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mnih, Volodymyr, 等人. “*使用深度强化学习玩Atari*。” arXiv预印本 arXiv:1312.5602 (2013).
- en: 'Botvinick, Matthew, et al. “*Reinforcement learning, fast and slow*.” *Trends
    in cognitive sciences* 23.5 (2019): 408-422.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Botvinick, Matthew, 等人. “*强化学习，快与慢*。” *认知科学趋势* 23.5 (2019): 408-422.'
- en: Kolesnikov, Alexander, Xiaohua Zhai, and Lucas Beyer. “*Revisiting self-supervised
    visual representation learning*.” *Proceedings of the IEEE/CVF conference on computer
    vision and pattern* *recognition* (2019).
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kolesnikov, Alexander, Xiaohua Zhai 和 Lucas Beyer。“*重新审视自监督视觉表示学习*。” *IEEE/CVF
    计算机视觉与模式识别会议论文集* (2019).
- en: 'Wang, Jiangliu, Jianbo Jiao, and Yun-Hui Liu. “*Self-supervised video representation
    learning by pace prediction*.” *Computer Vision–ECCV 2020: 16th European Conference*,
    Glasgow, UK, August 23–28, 2020, Proceedings, Part XVII 16\. Springer International
    Publishing (2020).'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang, Jiangliu, Jianbo Jiao 和 Yun-Hui Liu。“*通过速度预测进行自监督视频表示学习*。” *计算机视觉–ECCV
    2020: 第16届欧洲计算机视觉会议*，英国格拉斯哥，2020年8月23日至28日，第17卷16。Springer 国际出版社 (2020)。'
- en: 'Jaiswal, Ashish, et al. “*A survey on contrastive self-supervised learning*.”
    *Technologies* 9.1 (2020): 2.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jaiswal, Ashish, 等人。“*关于对比自监督学习的综述*。” *Technologies* 9.1 (2020): 2.'
- en: 'Radford, Alec, et al. “*Language models are unsupervised multitask learners*.”
    OpenAI blog 1.8 (2019): 9.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Radford, Alec, 等人。“*语言模型是无监督的多任务学习者*。” OpenAI 博客 1.8 (2019): 9.'
- en: Zhang, Chaoning, et al. “*A survey on masked autoencoder for self-supervised
    learning in vision and beyond*.” arXiv preprint arXiv:2208.00173 (2022).
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang, Chaoning, 等人。“*关于视觉和更多领域的掩码自动编码器在自监督学习中的应用综述*。” arXiv 预印本 arXiv:2208.00173
    (2022).
- en: Part 5:Advanced Topics in Model Debugging
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5部分：模型调试的高级主题
- en: In the concluding part of this book, we will address some of the most pivotal
    topics in machine learning. We will begin by explaining differences between correlation
    and causality, shedding light on their distinct implications in model development.
    Transitioning to the topic of security and privacy, we will discuss the pressing
    concerns, challenges, and techniques that ensure our models are both robust and
    respectful of user data. We will wrap up the book with an explanation of human-in-the
    -loop machine learning, emphasizing the synergy between human expertise and automated
    systems, and how this collaboration paves the way for more effective solutions.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的结论部分，我们将探讨机器学习中最关键的一些主题。我们将首先解释相关性和因果性的区别，阐明它们在模型开发中的不同影响。过渡到安全和隐私的主题，我们将讨论确保我们的模型既强大又尊重用户数据的紧迫问题、挑战和技术。我们将以对人类在循环机器学习的解释来结束本书，强调人类专业知识与自动化系统之间的协同作用，以及这种合作如何为更有效的解决方案铺平道路。
- en: 'This part has the following chapters:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 15*](B16369_15.xhtml#_idTextAnchor406), *Correlation versus Causality*'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第15章*](B16369_15.xhtml#_idTextAnchor406), *相关性 versus 因果性*'
- en: '[*Chapter 16*](B16369_16.xhtml#_idTextAnchor429), *Security and Privacy in
    Machine Learning*'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第16章*](B16369_16.xhtml#_idTextAnchor429)，*机器学习中的安全和隐私*'
- en: '[*Chapter 17*](B16369_17.xhtml#_idTextAnchor447), *Human-in-the-Loop Machine
    Learning*'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第17章*](B16369_17.xhtml#_idTextAnchor447)，*人类在循环机器学习*'
