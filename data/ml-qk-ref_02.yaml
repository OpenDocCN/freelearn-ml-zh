- en: Evaluating Kernel Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估核学习
- en: 'In machine learning, pattern finding is an area that is being explored to the
    hilt. There are many methods and algorithms that can drive this kind of work and
    analysis. However, in this chapter, we will try to focus on how kernels are making
    a significant difference to the whole machine learning outlook. The application
    of kernel learning doesn''t have any boundaries: starting from a simple regression
    problem to a computer vision classification, it has made its presence felt everywhere.
    **Support vector machine** (**SVM**) is one of those algorithms that happens to
    make use of kernel learning.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，模式识别是一个被彻底探索的领域。有许多方法和算法可以推动这种工作和分析。然而，在本章中，我们将尝试专注于核如何对整个机器学习前景产生重大影响。核学习的应用没有界限：从简单的回归问题到计算机视觉分类，它无处不在。**支持向量机**（**SVM**）是那些利用核学习的方法之一。
- en: 'In this chapter, we will be focusing on the following concepts:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将关注以下概念：
- en: Concepts of vectors, linear separability, and hyperplanes
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量、线性可分性和超平面概念
- en: SVM
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVM
- en: Kernel tricks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核技巧
- en: Gaussian process
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高斯过程
- en: Parameter optimization
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数优化
- en: Introduction to vectors
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量简介
- en: Before moving on to the core topic, we would like to build a foundation for
    getting there. Hence, this segment of the chapter is very important. It might
    look familiar to you and many of you will be cognizant about this. However, going
    through this channel will set the flow.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续探讨核心主题之前，我们希望为达到那个目标打下基础。因此，本章的这一部分非常重要。它可能对你来说很熟悉，你们中的许多人都会对此有所了解。然而，通过这条途径将设定流程。
- en: 'A vector is an object that has both a direction and magnitude. It is represented
    by an arrow and with a coordinate (*x*, *y*) in space, as shown in the following
    plot:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 向量是一个既有方向又有大小的对象。它由一个箭头和一个空间中的坐标 (*x*, *y*) 表示，如下面的图所示：
- en: '![](img/69d91204-36be-4e74-87ee-6f080307281d.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/69d91204-36be-4e74-87ee-6f080307281d.png)'
- en: 'As shown in the preceding diagram, the vector OA has the coordinates *(4,3)*:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，向量 OA 的坐标为 *(4,3)*：
- en: '*Vector OA= (4,3)*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量 OA= (4,3)*'
- en: However, it is not sufficient to define a vector just by coordinates—we also
    need a direction. That means the direction from the *x* axis.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅用坐标定义向量是不够的——我们还需要一个方向。这意味着从 *x* 轴的方向。
- en: Magnitude of the vector
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量的模
- en: 'The magnitude of the vector is also called the **norm**. It is represented
    by *||OA||*:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 向量的模也称为**范数**。它由 *||OA||* 表示：
- en: '![](img/b44d86d0-04f1-4c5d-abdb-4d64361bb275.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b44d86d0-04f1-4c5d-abdb-4d64361bb275.png)'
- en: 'To find out magnitude of this vector, we can follow the Pythagorean theorem:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要找出这个向量的模长，我们可以遵循勾股定理：
- en: '*OA^(2 )= OB² + AB²*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*OA² = OB² + AB²*'
- en: '*= 4^(2 )+ 3² *'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 4² + 3²*'
- en: '*= 16 + 9*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 16 + 9*'
- en: '*= 25*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 25*'
- en: 'Hence:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 因此：
- en: '*OA = √25 = 5*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*OA = √25 = 5*'
- en: '*||OA||= 5*'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*||OA||= 5*'
- en: 'So, if there is a vector *x = (x[1,]x[2],....,x[n])*:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果有一个向量 *x = (x[1], x[2], ..., x[n])*：
- en: '*||x||= x[1]^(2 )+ x[2]²+........+x[n]²*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*||x||= x[1]² + x[2]² + ... + x[n]²*'
- en: 'And direction of this vector as:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以及这个向量的方向如下：
- en: '![](img/416b0c98-2520-42ea-9f6f-72e6aff74934.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/416b0c98-2520-42ea-9f6f-72e6aff74934.png)'
- en: Dot product
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 点积
- en: The dot product of two vectors returns a number that happens to be scalar. It
    is a representation of how two vectors are associated with each other.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 两个向量的点积返回一个恰好是标量的数。它表示两个向量如何相互关联。
- en: 'Geometrically, the dot product of two vectors *x* and *y* would be as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 几何上，两个向量 *x* 和 *y* 的点积如下：
- en: '*x . y= ||x|| ||y|| cosθ*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*x . y= ||x|| ||y|| cosθ*'
- en: '*θ* is the angle between the vector *x* and *y*.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*θ* 是向量 *x* 和 *y* 之间的角度。'
- en: 'However, algebraically, we get the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，从代数上，我们得到以下结果：
- en: '![](img/92a6025d-116f-4815-a073-b003c343e241.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/92a6025d-116f-4815-a073-b003c343e241.png)'
- en: 'Geometrically, we get the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 几何上，我们得到以下结果：
- en: '*θ=β-α*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*θ=β-α*'
- en: '*cosθ=cos(β-α)*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*cosθ=cos(β-α)*'
- en: '*cosθ = cosβ cosα + sinβ sinα*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*cosθ = cosβ cosα + sinβ sinα*'
- en: '*cosθ = (x[1]/||x||) (y[1]/||y||) + (x2/||x||) (y2/||y||)*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*cosθ = (x[1]/||x||) (y[1]/||y||) + (x[2]/||x||) (y[2]/||y||)*'
- en: '*||x||||y|| cosθ= x[1] y[1 ]+ x[2]y[2]*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*||x|| ||y|| cosθ= x[1]y[1] + x[2]y[2]*'
- en: '*x . y = x[1] y[1 ]+ x[2]y[2]*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*x . y = x[1]y[1] + x[2]y[2]*'
- en: Linear separability
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性可分性
- en: Linear separability implies that if there are two classes then there will be
    a point, line, plane, or hyperplane that splits the input features in such a way
    that all points of one class are in one-half space and the second class is in
    the other half-space.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 线性可分性意味着如果有两个类别，那么将有一个点、线、平面或超平面将输入特征分割成这样的方式，即一个类别的所有点都在一个半空间中，而第二个类别在另一个半空间中。
- en: 'For example, here is a case of selling a house based on area and price. We
    have got a number of data points for that along with the class, which is house
    **Sold**/**Not Sold**:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里有一个基于面积和价格出售房屋的案例。我们为此得到了一些数据点以及类别，即房屋**已售出**/**未售出**：
- en: '![](img/c608dc6d-58f1-4548-b5d7-f3ba22fe1709.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c608dc6d-58f1-4548-b5d7-f3ba22fe1709.png)'
- en: In the preceding figure, all the **N**, are the class (event) of **Not Sold**,
    which has been derived based on the **Price** and **Area** of the house and all
    the instances of **S** represent the class of the house getting sold. The number
    of **N** and **S** represent the data points on which the class has been determined.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，所有的 **N** 都代表**未售出**（事件）类别，这是基于房屋的**价格**和**面积**推导出来的，而所有的 **S** 代表**已售出**的房屋类别。**N**
    和 **S** 的数量代表确定类别的数据点数量。
- en: In the first diagram, **N** and **S** are quite close and happen to be more
    random, hence, it's difficult to have linear separability achieved as no matter
    how you try to separate two classes, at least one of them would be in the misclassified
    region. It implies that there won't be a correct possible line to separate the
    two. But the second diagram depicts datasets that can easily be separated based
    on given conditions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一幅图中，**N** 和 **S** 非常接近，并且更随机，因此很难实现线性可分，无论你如何尝试分离两个类别，至少有一个会在错误分类的区域。这意味着不可能有一条正确的线来分离这两个类别。但第二幅图描述的是根据给定条件可以轻松分离的数据集。
- en: 'Separation methodology changes based on the number of dimensions. If there
    is just one dimensional situation, we can have a point separating classes. Adding
    more dimensions will require a different arrangement to split the class. Once
    we have got a 2D situation, a line (as seen previously) will be required to separate
    it. Similarly, more than 2D will need a plane (a set of points) in order to separate
    the classes, as shown:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 分离方法根据维度数而变化。如果只有一个维度的情况，我们可以有一个点来分离类别。增加更多维度将需要不同的排列来分割类别。一旦我们有了2D情况，就需要一条线（如之前所见）来分离它。同样，超过2D将需要平面（一组点）来分离类别，如下所示：
- en: '![](img/ffd8af10-e582-402b-8887-197f5abb2b79.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ffd8af10-e582-402b-8887-197f5abb2b79.png)'
- en: 'Separation method:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 分离方法：
- en: '| **Number of dimensions** | **Separation method** |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| **维度数** | **分离方法** |'
- en: '| 1 | Point |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 点 |'
- en: '| 2 | Line |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 直线 |'
- en: '| 3 | Plane |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 平面 |'
- en: What if we have more than 3D? What do we do? What's the solution? Any guesses?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有超过3D的情况呢？我们该怎么办？有什么解决方案？有什么猜测？
- en: Hyperplanes
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超平面
- en: Many of you will have guessed it right. We use hyperplanes when it comes to
    more than 3D. We will define it using a bit of mathematics.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你们中的许多人可能已经猜对了。当我们涉及到超过3D的情况时，我们会使用超平面。我们将用一点数学来定义它。
- en: A linear equation looks like this: *y = ax + b* has got two variables, *x* and
    *y*, and a *y*-intercept, which is *b*. If we rename *y* as *x[2]* and *x* as
    *x[1]*, the equation comes out as *x[2]=ax[1] + b *which implies *ax[1] - x[2]
    + b=0*. If we define 2D vectors as *x= (x[1],x[2])* and *w=(a,-1)* and if we make
    use of the dot product, then the equation becomes *w.x + b = 0.*
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一个线性方程看起来是这样的：*y = ax + b* 有两个变量，*x* 和 *y*，以及一个 *y*-截距，即 *b*。如果我们把 *y* 重命名为
    *x[2]*，把 *x* 重命名为 *x[1]*，那么方程就变成了 *x[2]=ax[1] + b*，这等价于 *ax[1] - x[2] + b=0*。如果我们定义二维向量为
    *x= (x[1],x[2])* 和 *w=(a,-1)*，并且使用点积，那么方程就变成了 *w.x + b = 0*。
- en: Remember, *x.y = x[1]y[1] + x[2]y[2].*
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，*x.y = x[1]y[1] + x[2]y[2]*。
- en: So, a hyperplane is a set of points that satisfies the preceding equation. But
    how do we classify with the help of hyperplane?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，超平面是一组满足前述方程的点集。但是，我们如何借助超平面进行分类呢？
- en: 'We define a hypothesis function *h*:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义一个假设函数 *h*：
- en: '*h(x[i]) = +1 if w.x[i] + b ≥ 0*'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*h(x[i]) = +1 if w.x[i] + b ≥ 0*'
- en: '*-1 if w.x[i] + b < 0*'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*-1 if w.x[i] + b < 0*'
- en: 'This could be equivalent to the following:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能等同于以下内容：
- en: '*h(x[i])= sign(w.x[i] + b) *'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*h(x[i])= sign(w.x[i] + b)*'
- en: 'It could also be equivalent to the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 它也可以等同于以下内容：
- en: '*sign(w.x[i]) if (x[0]=1 and w[0]=b)*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*sign(w.x[i]) if (x[0]=1 and w[0]=b)*'
- en: What it means is that it will use the position of *x* with respect to the hyperplane
    to predict a value for *y*. A data point on one side of the hyperplane gets a
    classification and a data point on other side of hyperplane gets another class.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着它将使用 *x* 相对于超平面的位置来预测 *y* 的值。位于超平面一侧的数据点得到一个分类，而位于超平面另一侧的数据点得到另一个分类。
- en: Because it uses the equation of a hyperplane that happens to be the linear combination
    of the values, it is called a **linear classifier**. The shape of hyperplane is
    by *w* as it has elements as b and a responsible for the shape.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它使用超平面的方程，而这个方程恰好是值的线性组合，所以它被称为 **线性分类器**。超平面的形状由 *w* 决定，因为它有 b 和 a 元素，这些元素负责形状。
- en: SVM
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SVM
- en: 'Now we are ready to understand SVMs. SVM is an algorithm that enables us to
    make use of it for both classification and regression. Given a set of examples,
    it builds a model to assign a group of observations into one category and others
    into a second category. It is a non-probabilistic linear classifier. Training
    data being linearly separable is the key here. All the observations or training
    data are a representation of vectors that are mapped into a space and SVM tries
    to classify them by using a margin that has to be as wide as possible:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好理解支持向量机（SVM）。SVM 是一种算法，使我们能够将其用于分类和回归。给定一组示例，它构建一个模型将一组观测值分配到一个类别，并将其他观测值分配到第二个类别。它是一个非概率线性分类器。训练数据线性可分是关键。所有观测值或训练数据都是映射到空间的向量的表示，SVM
    通过使用尽可能宽的边界来尝试对它们进行分类：
- en: '![](img/4d4cb88e-65ce-4483-81ea-5b640aa0c860.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4d4cb88e-65ce-4483-81ea-5b640aa0c860.png)'
- en: Let's say there are two classes **A** and **B** as in the preceding screenshot.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有两个类别 **A** 和 **B**，如前述截图所示。
- en: 'And from the preceding section, we have learned the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 并且从上一节中，我们学到了以下内容：
- en: '*g(x) = w. x + b*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*g(x) = w. x + b*'
- en: 'Where:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '*w*: Weight vector that decides the orientation of the hyperplane'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*：权重向量，决定超平面的方向'
- en: '*b*: Bias term that decides the position of the hyperplane in n-dimensional
    space by biasing it'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*b*：偏差项，通过偏差决定超平面在 n 维空间中的位置'
- en: 'The preceding equation is also called a **linear discriminant function**. If
    there is a vector *x[1]* that lies on the positive side of the hyperplane, the
    equation becomes the following:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方程也被称为 **线性判别函数**。如果有一个向量 *x[1]* 位于超平面的正侧，方程变为以下形式：
- en: '*g(x[1])= w.x[1] +b >0 *'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*g(x[1])= w.x[1] +b >0*'
- en: 'The equation will become the following:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 方程将变为以下形式：
- en: '*g(x[1])<0*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*g(x[1])<0*'
- en: If *x[1]* lies on the positive side of the hyperplane.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *x[1]* 位于超平面的正侧。
- en: What if *g(x[1])=0*? Can you guess where *x[1]* would be? Well, yes, it would
    be on the hyperplane, since our goal is to find out the class of the vector.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *g(x[1])=0* 会怎样？你能猜到 *x[1]* 会在哪里吗？嗯，是的，它会在超平面上，因为我们的目标是找出向量的类别。
- en: So, if *g(x[1])>0 => x[1]* belongs to **Class A**, *g(x[1])<0 => x[1]* belongs
    to **Class B**.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果 *g(x[1])>0 => x[1]* 属于 **类别 A**，*g(x[1])<0 => x[1]* 属于 **类别 B**。
- en: 'Here, it''s evident that we can find out the classification by using the previous
    equation. But can you see the issue in it? Let''s say the boundary line is like
    the following plot:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，很明显我们可以使用前面的方程进行分类。但你看到了问题吗？假设边界线如下所示：
- en: '![](img/9adf98c4-d994-4397-89f9-a022df614a5d.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9adf98c4-d994-4397-89f9-a022df614a5d.png)'
- en: 'Even in the preceding scenario, we are able to classify those feature vectors
    here. But is it desirable? What can be seen here is that the boundary line or
    the classifier is close to the **Class B**. It implies that it brings in a large
    bias in the favor of **Class A** but penalizes **Class B**. As a result of that,
    due to any disturbances in the vectors close to the boundary, they might cross
    over and become part of **Class A**, which might not be correct. Hence, our goal
    is to find an optimal classifier that has got the widest margin, like what is
    shown in the following plot:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在上述情况下，我们也能对这些特征向量进行分类。但这是否可取？在这里可以看到，边界线或分类器接近 **类别 B**。这意味着它给 **类别 A** 带来了很大的偏差，但惩罚了
    **类别 B**。因此，由于靠近边界的向量中的任何干扰，它们可能会跨越并成为 **类别 A** 的一部分，这可能是错误的。因此，我们的目标是找到一个具有最宽边界的最优分类器，就像以下图中所示：
- en: '![](img/4d4cb88e-65ce-4483-81ea-5b640aa0c860.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4d4cb88e-65ce-4483-81ea-5b640aa0c860.png)'
- en: 'Through SVM, we are attempting to create a boundary or hyperplane such that
    the distance from each of the feature vectors to the boundary is maximized so
    that any slight noise or disturbance won''t cause the change in classification.
    So, in this scenario, if we try to bring in certain *y[i]* which happens to be
    the class belonging to *xi,* we get the following:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 通过支持向量机（SVM），我们试图创建一个边界或超平面，使得每个特征向量到边界的距离最大化，这样任何微小的噪声或干扰都不会导致分类的改变。因此，在这种情况下，如果我们尝试引入某些属于
    *xi* 类别的 *y[i]*，我们会得到以下结果：
- en: '*y[i]= ± 1*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*y[i]= ± 1*'
- en: '*y[i] (w.x[i] + b)* will always be greater than 0. *y[i](w.x[i] + b) >0* because
    when *x[i ]∈ class A*, *w.x[i] +b>0* then *y[i]>0,* so the whole term will be
    positive. Also, if *x[i ]∈ class B*, *w.x[i] + b<0* then *y[i]<0*, and it will
    make the term positive.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*y[i] (w.x[i] + b)* 将始终大于 0。*y[i](w.x[i] + b) >0* 因为当 *x[i ]∈ 类别 A* 时，*w.x[i]
    +b>0* 则 *y[i]>0*，因此整个项将是正的。同样，如果 *x[i ]∈ 类别 B*，*w.x[i] + b<0* 则 *y[i]<0*，这将使项为正。'
- en: 'So, now if we have to redesign it, we say the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在如果我们必须重新设计它，我们可以说以下内容：
- en: '*w.x[i] + b> γ* where *γ* is the measure of the distance of hyperplane from
    *xi*.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*w.x[i] + b > γ* 其中 *γ* 是超平面到 *xi* 的距离的度量。'
- en: 'And if there is a hyperplane *w.x + b = 0*, then the distance of point *x*
    from the preceding hyperplane is as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存在超平面 *w.x + b = 0*，则点 *x* 到先前超平面的距离如下：
- en: '* w.x + b/ ||w||*'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '* w.x + b/ ||w||*'
- en: 'Hence, as mentioned previously:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如前所述：
- en: '*w.x + b/ ||w|| ≥ γ*'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*w.x + b/ ||w|| ≥ γ*'
- en: '*w.x + b ≥ γ.||w||*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*w.x + b ≥ γ.||w||*'
- en: 'On performing proper scaling, we can say the following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行适当的缩放后，我们可以得出以下结论：
- en: '*w.x + b ≥ 1 (since γ.||w|| = 1)*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*w.x + b ≥ 1（因为 γ.||w|| = 1)*'
- en: 'It implies that if there is a classification to be arrived at based on the
    previous result, it follows this:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着如果基于前面的结果需要进行分类，那么它遵循以下规则：
- en: '*w.x + b ≥ 1 if x ∈ class A and*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*w.x + b ≥ 1 如果 x ∈ 类别 A*'
- en: '*w.x + b ≤ -1 if x ∈ class B*'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*w.x + b ≤ -1 如果 x ∈ 类别 B*'
- en: 'And now, again, if we bring in a class belonging to *y[i]* here, the equation
    becomes the following:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，再次，如果我们引入一个属于 *y[i]* 的类别，方程变为以下形式：
- en: '*yi (w.xi + b) ≥ 1*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*yi (w.xi + b) ≥ 1*'
- en: But, if *y[i] (w.x[i] + b) =** 1*, *x[i]* is a support vector. Next, we will
    learn what a support vector is.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果 *y[i] (w.x[i] + b) =** 1*，*x[i]* 是一个支持向量。接下来，我们将学习什么是支持向量。
- en: Support vector
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量
- en: 'We draw two boundary lines passing through feature vectors of one class closest
    to the feature vectors of another class. The center line of these boundary lines
    is the hyperplane we have been talking about. For example, for **Class B**, a
    boundary line is passing through **p** and **q** along the way and another boundary
    line through **r** and **s** because **p** and **q** are the closest to the feature
    vectors of **Class B** and so are **r** and **s**. These are called **support
    vectors**. We will understand now why these are called **support vectors**:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们绘制两条通过一个类别的特征向量与另一个类别的特征向量最近的边界线。这些边界线的中心线就是我们一直在谈论的超平面。例如，对于 **类别 B**，一条边界线通过
    **p** 和 **q**，另一条边界线通过 **r** 和 **s**，因为 **p** 和 **q** 是最接近 **类别 B** 的特征向量，同样 **r**
    和 **s** 也是。这些被称为 **支持向量**。我们现在将了解为什么它们被称为 **支持向量**：
- en: '![](img/480ad417-ed82-49ab-ae3f-fa33bcc91538.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/480ad417-ed82-49ab-ae3f-fa33bcc91538.png)'
- en: Let's say that if we try to remove one of the feature vectors that is not so
    close to the boundary line, we will not have an impact on the position or orientation
    of the hyperplane because the hyperplane's position is decided by boundary lines
    crossing through vectors **p**, **q**, **r**, and **s**. And, since these are
    the points holding (supporting) the hyperplane together, they have been named
    support vectors.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们尝试移除一个与边界线不太接近的特征向量，这将不会对超平面的位置或方向产生影响，因为超平面的位置是由穿过向量 **p**、**q**、**r**
    和 **s** 的边界线决定的。由于这些点是支撑超平面的点，因此它们被称为支持向量。
- en: So, this equation *y[i] (w.x[i] + b) =** 1* holds true when *x[i]* is **p**, **q**, **r**,
    or **s**.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个方程 *y[i] (w.x[i] + b) =** 1* 在 *x[i]* 是 **p**、**q**、**r** 或 **s** 时成立。
- en: We will go back to the equation *w.x + b/ ||w|| ≥ γ*; here, we are trying to
    maximize *γ*, and in order to do so either we need to maximize b or minimize *||w||*.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将回到方程 **w.x + b/ ||w|| ≥ γ**；在这里，我们试图最大化 **γ**，为了做到这一点，我们需要最大化 b 或最小化 **||w||**。
- en: Or we can say we have to minimize *w.w*. If we convert that into a function, *Φ(w)
    = w.w* has to be minimized. *Φ(w) =1/2( w.w)* (here 1/2 has been added for mathematical
    convenience).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 或者我们可以说我们必须最小化 *w.w*。如果我们将其转换为函数，*Φ(w) = w.w* 必须被最小化。*Φ(w) =1/2( w.w)*（这里添加了
    1/2 以方便数学运算）。
- en: 'So, the objective function of SVM becomes *Φ(w) =1/2( w.w)*, which has to be
    minimized subject to constraints, as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，SVM 的目标函数变为 *Φ(w) =1/2( w.w)*，它必须在以下约束条件下被最小化：
- en: '*y[i] (w.x[i] + b) = 1*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*y[i] (w.x[i] + b) = 1*'
- en: Since it is a constrained optimization problem, it can be converted into an
    unconstrained optimization problem using the Lagrangian multiplier.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个约束优化问题，可以使用拉格朗日乘数将其转换为无约束优化问题。
- en: Hence, *L(w,b)= 1/2(w.w) - ∑ αi [yi(w.xi+b) - 1]* where αi is the Lagrangian
    multiplier, *L(w,b)= 1/2(w.w) - ∑ α[i] y[i] (w.x[i]) -∑ α[i] y[i] b + ∑ α[i]*.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，*L(w,b)= 1/2(w.w) - ∑ αi [yi(w.xi+b) - 1]*，其中 αi 是拉格朗日乘子，*L(w,b)= 1/2(w.w)
    - ∑ α[i] y[i] (w.x[i]) - ∑ α[i] y[i] b + ∑ α[i]*。
- en: 'Let''s find out *w* and *b* by using maxima and minima calculus:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用最大值和最小值微积分来找出 *w* 和 *b*：
- en: '*δL/δb = 0 *'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '*δL/δb = 0*'
- en: 'It results in* ∑ α[i] y[i]=0, **δL/**δw = 0* would result in *∑ αi yi xi =
    w*.Now, putting these results back into the Lagrangian function yields the following:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致* ∑ α[i] y[i]=0，δL/δw = 0*，这将导致 *∑ αi yi xi = w*。现在，将这些结果放回拉格朗日函数中，得到以下结果：
- en: '*L= ∑ α[i] - 1/2 ∑ α[i] α[j] y[i] y[j] (x[j].x[i])*'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*L= ∑ α[i] - 1/2 ∑ α[i] α[j] y[i] y[j] (x[j].x[i])* '
- en: 'It means that if the value of *α[i]* is very high then the corresponding *x*.There
    will be a lot of influence on the position of the hyperplane. Hence, for classification
    and for unknown feature vector *z*, the required equation would be the following:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着如果 *α[i]* 的值非常高，那么相应的 *x* 将对超平面的位置产生很大影响。因此，对于分类和未知特征向量 *z*，所需的方程将是以下：
- en: '*D(z) = Sign( ∑ αi xi yi z + b)*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*D(z) = Sign(∑ αi xi yi z + b)*'
- en: 'If *D(z) >0*, then *z* would belong to class A and if *D(z)<0*, *z ∈ class
    B*. Let''s try to perform a case study in Python:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *D(z) >0*，则 *z* 属于类别A；如果 *D(z)<0*，*z* 属于类别B。让我们尝试在Python中做一个案例研究：
- en: '![](img/44b032dc-d35e-4103-8986-55a7e8d79b98.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/44b032dc-d35e-4103-8986-55a7e8d79b98.png)'
- en: Kernel trick
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 核技巧
- en: 'We have already seen that SVM works smoothly when it comes to having linear
    separable data. Just have a look at the following figure; it depicts that vectors
    are not linearly separable, but the noticeable part is that it is not being separable
    in 2D space:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，当数据是线性可分的时候，支持向量机（SVM）工作得非常顺利。只需看看以下图示；它描绘了向量不是线性可分的，但值得注意的是，它不是在二维空间中可分的：
- en: '![](img/c938db90-3030-49a0-bcbb-76090683fa47.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c938db90-3030-49a0-bcbb-76090683fa47.png)'
- en: With a few adjustments, we can still make use of SVM here.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一些调整，我们仍然可以使用支持向量机（SVM）。
- en: Transformation of a two-dimensional vector into a 3D vector or any other higher
    dimensional vector can set things right for us. The next step would be to train
    the SVM using a higher dimensional vector. But the question arises of how high
    in dimension we should go to transform the vector. What this means is if the transformation
    has to be a two-dimensional vector, or 3D or 4D or more. It actually depends on
    the which brings separability into the dataset.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 将二维向量转换成三维向量或其他更高维度的向量可以为我们解决问题。下一步将是使用更高维度的向量来训练支持向量机（SVM）。但是，问题出现了，我们应该将向量转换到多高的维度。这意味着如果转换必须是一个二维向量，或者3D、4D或更高维，这实际上取决于它将可分性引入数据集。
- en: Kernel
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 核函数
- en: A non-separable dataset like the one used previously is always a tough thing
    to deal with, however, there are ways to deal with it. One way is to set the vectors
    into higher dimensions through transformation. But, can we really do it when we
    have millions of data or vector in reckoning? It will take lots of computation
    and, also, time. That's where kernel to saves our day.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 像之前使用的那样，一个不可分的数据集总是很难处理，然而，有方法可以处理它。一种方法是通过转换将向量设置到更高的维度。但是，当我们有数百万的数据或向量时，我们真的能这样做吗？这将需要大量的计算和时间。这就是核函数帮我们解决问题的时刻。
- en: 'We have seen the following equation. In this, only the dot product of the training
    examples are responsible for making the model learn. Let''s try to do a small
    exercise here:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了以下方程。在这个方程中，只有训练样本的点积负责使模型学习。让我们在这里尝试一个小练习：
- en: '![](img/81286c92-7e64-42d9-931f-29a4232387d9.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/81286c92-7e64-42d9-931f-29a4232387d9.png)'
- en: 'Let''s take two vectors here:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，让我们考虑两个向量：
- en: '[PRE0]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, build a transformation function that will help in transforming these 2D
    vectors into 3D.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，构建一个转换函数，它将帮助将这些二维向量转换成三维向量。
- en: 'The function to be used in order to transform is the following:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 用于转换的函数如下：
- en: '*t(x1,x2)= (x1²,x1 x2 √2,x2²)*'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*t(x1,x2)= (x1²,x1 x2 √2,x2²)*'
- en: '[PRE1]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now let''s use this function:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用这个函数：
- en: '[PRE2]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'But can''t we do this without transforming the values. Kernel can help us in
    doing it:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我们能否在不转换值的情况下做到这一点呢？核函数可以帮助我们做到这一点：
- en: '[PRE3]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'It''s the time to use this `kernel` now:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候使用这个 `kernel` 了：
- en: '[PRE4]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Isn't it quite thrilling to see such an amazing result that is the same as before,
    without using transformation? So, kernel is a function that leads to the dot-product-like
    result in another space.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 看到这样一个惊人的结果，它和之前一样，而且没有使用转换，难道不令人兴奋吗？所以，核函数是在另一个空间中导致点积类似结果的函数。
- en: Back to Kernel trick
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回到核技巧
- en: 'So, now we have got a fair understanding of kernel and its importance. And,
    as discussed in the last section, the `kernel` function is:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在我们已经对核及其重要性有了相当的了解。并且，如上一节所述，核函数是：
- en: '*K(x[i],x[j])= x[i ]. x[j]*'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '*K(x[i],x[j])= x[i ]. x[j]*'
- en: 'So, now the margin problem becomes the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在边际问题变成了以下：
- en: '![](img/81b41737-cd77-4e76-8316-b22acd9dc135.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/81b41737-cd77-4e76-8316-b22acd9dc135.png)'
- en: 'This is subject to *0 ≤ α[i] **≤ C*, for any *i = 1, ..., m*:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这适用于*0 ≤ α[i] ≤ C*，对于任何*i = 1, ..., m*：
- en: '![](img/46d3bf1e-49a9-4c32-8561-e063baab823b.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/46d3bf1e-49a9-4c32-8561-e063baab823b.png)'
- en: Applying the kernel trick simply means replacing the dot product of two examples
    with a `kernel` function.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 应用核技巧简单来说就是用核函数替换两个示例之间的点积。
- en: 'Now even the hypothesis function will change as well:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设函数也会发生变化：
- en: '![](img/d1477ee3-964a-4d74-b35a-460418052ad5.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d1477ee3-964a-4d74-b35a-460418052ad5.png)'
- en: This function will be able to decide on and classify the categories. Also, since
    *S* denotes the set of support vectors, it implies that we need to compute the
    `kernel` function only on support vectors.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将能够决定并分类类别。此外，由于*S*表示支持向量的集合，这意味着我们只需要在支持向量上计算核函数。
- en: Kernel types
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 核类型
- en: We're going to explain the types of in this section.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本节中解释这些类型。
- en: Linear kernel
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性核
- en: 'Let''s say there are two vectors, *x*[*1* ]and *x[2]*, so the linear kernel
    can be defined by the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有两个向量，*x*[*1* ]和*x[2]*，那么线性核可以通过以下方式定义：
- en: '*K(x[1,] x[2])= x[1 . ]x[2]*'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '*K(x[1,] x[2])= x[1 . ]x[2]*'
- en: Polynomial kernel
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多项式核
- en: 'If there are two vectors, *x**[1]*and *x**[2]*, the linear kernel can be defined
    by the following:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有两个向量，*x**[1]*和*x**[2]*，线性核可以通过以下方式定义：
- en: '*K(x[1,] x[2])= (x[1 . ]x[2 ]+ c)^d*'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*K(x[1,] x[2])= (x[1 . ]x[2 ]+ c)^d*'
- en: 'Where:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '*c*: Constant'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*c*：常数'
- en: '*d*: Degree of polynomial:'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*d*：多项式的次数：'
- en: '[PRE5]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If we use the same `x1` and `x2` as used previously, we get the following:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用之前使用的相同的*x1*和*x2*，我们得到以下结果：
- en: '[PRE6]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If we increase the degree of polynomial, we will try to get influenced by other
    vectors as the decision boundary becomes too complex and it will result in overfitting:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们增加多项式的次数，我们试图受到其他向量的影响，因为决策边界变得过于复杂，这会导致过拟合：
- en: '![](img/14b37f8d-a6d2-4f1e-8d95-e64b604952e2.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/14b37f8d-a6d2-4f1e-8d95-e64b604952e2.png)'
- en: '![](img/4b52d85d-9734-4bf2-9432-c3ccccadc31c.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4b52d85d-9734-4bf2-9432-c3ccccadc31c.png)'
- en: Polynomial kernel using degree as 6.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 使用6次方的多项式核。
- en: Gaussian kernel
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高斯核
- en: 'The polynomial kernel has given us a good boundary line. But can we work with
    polynomial kernels all the time? Not in the following scenario:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式核给出了良好的边界线。但我们是否可以始终使用多项式核？在以下场景中不行：
- en: '![](img/d5af809b-ac44-4604-9bfa-888ecf1ea487.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d5af809b-ac44-4604-9bfa-888ecf1ea487.png)'
- en: 'The solution is a radial basis function or Gaussian kernel. It''s nothing but
    the similarity function of the vectors to translate them into a high dimensional
    space or infinite dimensional space. Its value depends on the distance from the
    Gaussian kernel function, as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案是径向基函数或高斯核。这不过是向量的相似函数，将它们转换到高维空间或无限维空间。其值取决于高斯核函数的距离，如下所示：
- en: '*K(x,x^'') = exp(-γ ||x-x''||²)*'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '*K(x,x^'') = exp(-γ ||x-x''||²)*'
- en: 'Without loss of generality, let ![](img/610290f7-d9ab-43ca-8211-b8623507ae1f.png):'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 为了不失一般性，让![](img/610290f7-d9ab-43ca-8211-b8623507ae1f.png)：
- en: '![](img/5a59facc-78d6-4edb-bbb9-2d3bd597f660.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5a59facc-78d6-4edb-bbb9-2d3bd597f660.png)'
- en: '![](img/e89bba32-a989-40f4-8517-c3dce9f75b45.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e89bba32-a989-40f4-8517-c3dce9f75b45.png)'
- en: With the help of this RBF as a similarity function, all the feature vectors
    get calculated.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个RBF相似函数的帮助下，所有特征向量都被计算出来。
- en: SVM example and parameter optimization through grid search
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过网格搜索进行SVM示例和参数优化
- en: Here, we are taking a breast cancer dataset wherein we have classified according
    to whether the cancer is benign/malignant.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们正在使用乳腺癌数据集，其中根据癌症是否为良性/恶性进行分类。
- en: 'The following is for importing all the required libraries:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为了导入所有必需的库：
- en: '[PRE7]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, let''s load the breast cancer dataset:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们加载乳腺癌数据集：
- en: '[PRE8]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following allows us to check the details of the dataset:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 以下允许我们检查数据集的详细信息：
- en: '[PRE9]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This if for splitting the dataset into train and test:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这是为了将数据集分为训练集和测试集：
- en: '[PRE10]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This is for setting the model with the linear kernel and finding out the accuracy:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这是为了设置具有线性核的模型并找出准确度：
- en: '[PRE11]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We get the accuracy output as shown:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到如下的准确度输出：
- en: '[PRE12]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Setting the model with the Gaussian/RBF kernel and accuracy is done like this:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 使用高斯/径向基函数核并设置准确度的方式如下：
- en: '[PRE13]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output can be seen as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE14]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'It''s quite apparent that the model is overfitted. So, we will go for normalization:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，模型已经过拟合。因此，我们将进行归一化：
- en: '[PRE15]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This code is for setting up the model again:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码用于重新设置模型：
- en: '[PRE16]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The following shows the output:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的输出如下：
- en: '[PRE17]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, the overfitting issue cannot be seen any more. Let''s move on to having
    an optimal result:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，过拟合问题已经不再明显。让我们继续追求最佳结果：
- en: '[PRE18]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'With the help of grid search, we get the optimal combination for `gamma`, `kernel`,
    and `C` as shown:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在网格搜索的帮助下，我们得到了`gamma`、`kernel`和`C`的最佳组合，如下所示：
- en: '![](img/a0614335-6cba-4c29-9033-97af3f63bb68.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a0614335-6cba-4c29-9033-97af3f63bb68.png)'
- en: With the help of this, we can see and find out which combination of parameters
    is giving us the better result.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个方法，我们可以看到并找出哪种参数组合给我们带来了更好的结果。
- en: Here, the best combination turns out to be a linear kernel with a `C` value
    of `1`.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，最佳组合是具有`C`值为`1`的线性核。
- en: Summary
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we were introduced to vectors, magnitude of vector, and the
    dot product. We learned about SVMs that can be used for both classification and
    regression. We studied support vectors and kernels and the different types of
    kernels. Lastly, we studied the SVM example and parameter optimization through
    grid search.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了向量、向量的模和点积。我们学习了可以用于分类和回归的支持向量机（SVMs）。我们研究了支持向量和核，以及不同类型的核。最后，我们通过网格搜索研究了SVM示例和参数优化。
- en: In the next chapter, we will learn about performance in ensemble learning.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习集成学习中的性能。
