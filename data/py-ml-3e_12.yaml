- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Implementing a Multilayer Artificial Neural Network from Scratch
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从零开始实现多层人工神经网络
- en: As you may know, deep learning is getting a lot of attention from the press
    and is without any doubt the hottest topic in the machine learning field. Deep
    learning can be understood as a subfield of machine learning that is concerned
    with training artificial neural networks (NNs) with many layers efficiently. In
    this chapter, you will learn the basic concepts of artificial NNs so that you
    are well equipped for the following chapters, which will introduce advanced Python-based
    deep learning libraries and **deep neural network** (**DNN**) architectures that
    are particularly well suited for image and text analyses.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，深度学习正在受到媒体的广泛关注，毫无疑问，它是机器学习领域最热门的话题。深度学习可以理解为机器学习的一个子领域，专注于高效训练具有多层的人工神经网络（NN）。在本章中，你将学习人工神经网络的基本概念，为接下来的章节做好准备，后续章节将介绍基于Python的深度学习库以及特别适用于图像和文本分析的**深度神经网络**（**DNN**）架构。
- en: 'The topics that we will cover in this chapter are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将覆盖的主题如下：
- en: Gaining a conceptual understanding of multilayer NNs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获得多层神经网络的概念性理解
- en: Implementing the fundamental backpropagation algorithm for NN training from
    scratch
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从头开始实现神经网络训练的基本反向传播算法
- en: Training a basic multilayer NN for image classification
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练用于图像分类的基础多层神经网络
- en: Modeling complex functions with artificial neural networks
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用人工神经网络建模复杂函数
- en: At the beginning of this book, we started our journey through machine learning
    algorithms with artificial neurons in *Chapter 2*, *Training Simple Machine Learning
    Algorithms for Classification*. Artificial neurons represent the building blocks
    of the multilayer artificial NNs that we will discuss in this chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的开头，我们从*第2章* *训练简单的机器学习算法进行分类*开始了我们对机器学习算法的探索。人工神经元代表了我们将在本章讨论的多层人工神经网络的构建模块。
- en: The basic concept behind artificial NNs was built upon hypotheses and models
    of how the human brain works to solve complex problem tasks. Although artificial
    NNs have gained a lot of popularity in recent years, early studies of NNs go back
    to the 1940s when Warren McCulloch and Walter Pitts first described how neurons
    could work. (*A logical calculus of the ideas immanent in nervous activity*, *W.
    S. McCulloch* and *W. Pitts*. *The Bulletin of Mathematical Biophysics*, 5(4):115–133,
    1943.)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络的基本概念建立在对人类大脑如何解决复杂问题任务的假设和模型之上。尽管人工神经网络近年来获得了很高的关注，但神经网络的早期研究可以追溯到1940年代，当时沃伦·麦卡洛克（Warren
    McCulloch）和沃尔特·皮茨（Walter Pitts）首次描述了神经元的工作原理。 (*神经活动中固有思想的逻辑演算*，*W. S. McCulloch*
    和 *W. Pitts*， *数学生物物理学公报*，5(4):115–133，1943年)
- en: 'However, in the decades that followed the first implementation of the **McCulloch-Pitts
    neuron** model—Rosenblatt''s perceptron in the 1950s — many researchers and machine
    learning practitioners slowly began to lose interest in NNs since no one had a
    good solution for training an NN with multiple layers. Eventually, interest in
    NNs was rekindled in 1986 when D.E. Rumelhart, G.E. Hinton, and R.J. Williams
    were involved in the (re)discovery and popularization of the backpropagation algorithm
    to train NNs more efficiently, which we will discuss in more detail later in this
    chapter (*Learning representations by back-propagating errors*, *D. E. Rumelhart*,
    *G. E. Hinton*, *R. J. Williams*, *Nature*, 323 (6088): 533–536, *1986*). Readers
    who are interested in the history of **artificial intelligence** (**AI**), machine
    learning, and NNs are also encouraged to read the Wikipedia article on the so-called
    *AI winters*, which are the periods of time where a large portion of the research
    community lost interest in the study of NNs ([https://en.wikipedia.org/wiki/AI_winter](https://en.wikipedia.org/wiki/AI_winter)).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，在**麦卡洛克-皮茨神经元**模型首次实现后的几十年里——20世纪50年代的罗森布拉特感知机——许多研究人员和机器学习从业者逐渐失去了对神经网络的兴趣，因为没有人找到一个有效的解决方案来训练具有多层的神经网络。最终，随着D.E.
    Rumelhart、G.E. Hinton和R.J. Williams在1986年重新发现并推广了反向传播算法，神经网络的兴趣再次被点燃，这使得神经网络的训练更加高效。我们将在本章稍后详细讨论这一点
    (*通过反向传播错误学习表示*，*D. E. Rumelhart*，*G. E. Hinton*，*R. J. Williams*，*Nature*，323
    (6088): 533–536，*1986*）。对于那些对**人工智能**（**AI**）、机器学习和神经网络的历史感兴趣的读者，我们也鼓励阅读维基百科上关于所谓的*AI寒冬*的文章，AI寒冬指的是研究界在一段时间内对神经网络的研究兴趣大幅下降的时期
    ([https://en.wikipedia.org/wiki/AI_winter](https://en.wikipedia.org/wiki/AI_winter))。'
- en: However, NNs are more popular today than ever thanks to the many major breakthroughs
    that have been made in the previous decade, which resulted in what we now call
    deep learning algorithms and architectures—NNs that are composed of many layers.
    NNs are a hot topic not only in academic research but also in big technology companies,
    such as Facebook, Microsoft, Amazon, Uber, and Google, that invest heavily in
    artificial NNs and deep learning research.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，神经网络（NNs）今天比以往任何时候都更受欢迎，这得益于过去十年中的许多重大突破，最终催生了我们现在称之为深度学习算法和架构——由多层组成的神经网络。神经网络不仅在学术研究中是一个热门话题，而且在大科技公司中也同样火热，如Facebook、Microsoft、Amazon、Uber和Google，它们在人工神经网络和深度学习研究方面投入巨大。
- en: As of today, complex NNs powered by deep learning algorithms are considered
    the state-of-the-art solutions for complex problem solving such as image and voice
    recognition. Popular examples of the products in our everyday life that are powered
    by deep learning are Google's image search and Google Translate—an application
    for smartphones that can automatically recognize text in images for real-time
    translation into more than 20 languages.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 截至今天，由深度学习算法驱动的复杂神经网络被认为是解决复杂问题（如图像和语音识别）的最先进解决方案。我们日常生活中许多基于深度学习的产品，如Google的图像搜索和Google翻译，都是这些技术的典型应用——一款智能手机应用，可以自动识别图像中的文字并实时翻译成20多种语言。
- en: 'Many exciting applications of DNNs have been developed at major tech companies
    and the pharmaceutical industry as listed in the following, non-comprehensive
    list of examples:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 许多令人兴奋的深度神经网络（DNNs）应用已在主要科技公司和制药行业中开发，以下是一些示例（并非详尽无遗）：
- en: 'Facebook''s DeepFace for tagging images (*DeepFace: Closing the Gap to Human-Level
    Performance in Face Verification*, *Y. Taigman*, *M. Yang*, *M. Ranzato*, and
    *L. Wolf*, *IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*,
    pages 1701–1708, *2014*)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Facebook的DeepFace用于图像标记（*DeepFace: Closing the Gap to Human-Level Performance
    in Face Verification*，*Y. Taigman*，*M. Yang*，*M. Ranzato*，和*L. Wolf*，*IEEE计算机视觉与模式识别会议(CVPR)*，第1701–1708页，*2014*）'
- en: 'Baidu''s DeepSpeech, which is able to handle voice queries in Mandarin (*DeepSpeech:
    Scaling up end-to-end speech recognition*, *A. Hannun*, *C. Case*, *J. Casper*,
    *B. Catanzaro*, *G. Diamos*, *E. Elsen*, *R. Prenger*, *S. Satheesh*, *S. Sengupta*,
    *A. Coates*, and *Andrew Y. Ng*, arXiv preprint arXiv:1412.5567, *2014*)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '百度的DeepSpeech，能够处理普通话语音查询（*DeepSpeech: Scaling up end-to-end speech recognition*，*A.
    Hannun*，*C. Case*，*J. Casper*，*B. Catanzaro*，*G. Diamos*，*E. Elsen*，*R. Prenger*，*S.
    Satheesh*，*S. Sengupta*，*A. Coates*，和*Andrew Y. Ng*，arXiv预印本arXiv:1412.5567，*2014*）'
- en: 'Google''s new language translation service (*Google''s Neural Machine Translation
    System: Bridging the Gap between Human and Machine Translation*, arXiv preprint
    arXiv:1412.5567, *2016*)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Google的新语言翻译服务（*Google''s Neural Machine Translation System: Bridging the Gap
    between Human and Machine Translation*，arXiv预印本arXiv:1412.5567，*2016*）'
- en: Novel techniques for drug discovery and toxicity prediction (*Toxicity prediction
    using Deep Learning*, *T. Unterthiner*, *A. Mayr*, *G. Klambauer*, and *S. Hochreiter*,
    arXiv preprint arXiv:1503.01445, *2015*)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 药物发现和毒性预测的新技术（*Toxicity prediction using Deep Learning*，*T. Unterthiner*，*A.
    Mayr*，*G. Klambauer*，和*S. Hochreiter*，arXiv预印本arXiv:1503.01445，*2015*）
- en: A mobile application that can detect skin cancer with an accuracy similar to
    professionally trained dermatologists (*Dermatologist-level classification of
    skin cancer with deep neural networks*, *A. Esteva*, *B.Kuprel*, *R. A. Novoa*,
    *J. Ko*, *S. M. Swetter*, *H. M. Blau*, and *S.Thrun*, in *Nature* 542, no. 7639,
    *2017*, pages 115-118)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一款可以以类似专业训练皮肤科医生的准确性检测皮肤癌的移动应用（*Dermatologist-level classification of skin cancer
    with deep neural networks*，*A. Esteva*，*B.Kuprel*，*R. A. Novoa*，*J. Ko*，*S. M.
    Swetter*，*H. M. Blau*，和*S.Thrun*，发表于*自然*杂志，542卷，第7639期，*2017*，第115-118页）
- en: Protein 3D structure prediction from gene sequences (*De novo structure prediction
    with deep-learning based scoring*, *R. Evans, J. Jumper, J. Kirkpatrick, L. Sifre,
    T.F.G. Green, C. Qin, A. Zidek, A. Nelson, A. Bridgland, H. Penedones, S. Petersen,
    K. Simonyan, S. Crossan, D.T. Jones, D. Silver, K. Kavukcuoglu, D. Hassabis, and
    A.W. Senior*, in *Thirteenth Critical Assessment of Techniques for Protein Structure
    Prediction*, 1-4 December, *2018*)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从基因序列预测蛋白质三维结构（*De novo structure prediction with deep-learning based scoring*，*R.
    Evans*，*J. Jumper*，*J. Kirkpatrick*，*L. Sifre*，*T.F.G. Green*，*C. Qin*，*A. Zidek*，*A.
    Nelson*，*A. Bridgland*，*H. Penedones*，*S. Petersen*，*K. Simonyan*，*S. Crossan*，*D.T.
    Jones*，*D. Silver*，*K. Kavukcuoglu*，*D. Hassabis*，和*A.W. Senior*，发表于*第十三届蛋白质结构预测技术的关键评估*，2018年12月1-4日）
- en: Learning how to drive in dense traffic from purely observational data such as
    camera video streams (*Model-predictive policy learning with uncertainty regularization
    for driving in dense traffic, M. Henaff, A. Canziani, Y. LeCun, 2019*, in *Conference
    Proceedings of the International Conference on Learning Representations*, *ICLR*,
    2019)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从纯粹的观察数据（如摄像头视频流）中学习如何在密集交通中驾驶（*基于模型的预测策略学习与不确定性正则化在密集交通中驾驶的应用，M. Henaff, A.
    Canziani, Y. LeCun, 2019*，发表于*国际学习表征会议论文集*，*ICLR*，2019）
- en: Single-layer neural network recap
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单层神经网络回顾
- en: 'This chapter is all about multilayer NNs, how they work, and how to train them
    to solve complex problems. However, before we dig deeper into a particular multilayer
    NN architecture, let''s briefly reiterate some of the concepts of single-layer
    NNs that we introduced in *Chapter 2*, *Training Simple Machine Learning Algorithms
    for Classification*, namely, the **ADAptive LInear NEuron** (**Adaline**) algorithm,
    which is shown in the following figure:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讲述的是多层神经网络，它们是如何工作的，以及如何训练它们来解决复杂问题。然而，在我们深入探讨某一特定的多层神经网络架构之前，让我们简要回顾一下我们在*第2章*，*训练简单的机器学习算法进行分类*中介绍的一些单层神经网络的概念，即**自适应线性神经元**（**Adaline**）算法，如下图所示：
- en: '![](img/B13208_12_01.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_01.png)'
- en: 'In *Chapter 2*, *Training Simple Machine Learning Algorithms for Classification*,
    we implemented the Adaline algorithm to perform binary classification, and we
    used the gradient descent optimization algorithm to learn the weight coefficients
    of the model. In every epoch (pass over the training dataset), we updated the
    weight vector *w* using the following update rule:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第2章*，*训练简单的机器学习算法进行分类*中，我们实现了 Adaline 算法来进行二分类，并使用梯度下降优化算法来学习模型的权重系数。在每一个训练周期（遍历训练数据集）中，我们使用以下更新规则更新权重向量
    *w*：
- en: '![](img/B13208_12_001.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_001.png)'
- en: In other words, we computed the gradient based on the whole training dataset
    and updated the weights of the model by taking a step into the opposite direction
    of the gradient ![](img/B13208_12_002.png). In order to find the optimal weights
    of the model, we optimized an objective function that we defined as the **sum
    of squared errors** (**SSE**) cost function ![](img/B13208_12_003.png). Furthermore,
    we multiplied the gradient by a factor, the **learning rate** ![](img/B13208_12_004.png),
    which we had to choose carefully to balance the speed of learning against the
    risk of overshooting the global minimum of the cost function.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们基于整个训练数据集计算梯度，并通过向梯度的反方向迈进一步来更新模型的权重！[](img/B13208_12_002.png)。为了找到模型的最优权重，我们优化了我们定义的目标函数，即**平方误差之和**（**SSE**）成本函数！[](img/B13208_12_003.png)。此外，我们还将梯度乘以一个因子——**学习率**！[](img/B13208_12_004.png)，该因子需要我们小心选择，以平衡学习的速度与避免超过成本函数的全局最小值之间的风险。
- en: 'In gradient descent optimization, we updated all weights simultaneously after
    each epoch, and we defined the partial derivative for each weight ![](img/B13208_12_005.png)
    in the weight vector *w* as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在梯度下降优化中，我们在每个训练周期（epoch）后同时更新所有权重，并且我们为权重向量 *w* 中的每个权重定义了偏导数，如下所示：![](img/B13208_12_005.png)
- en: '![](img/B13208_12_006.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_006.png)'
- en: Here, ![](img/B13208_12_007.png) is the target class label of a particular sample
    ![](img/B13208_12_008.png), and ![](img/B13208_12_009.png) is the activation of
    the neuron, which is a linear function in the special case of Adaline.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/B13208_12_007.png)是特定样本的目标类标签 ![](img/B13208_12_008.png)，而![](img/B13208_12_009.png)是神经元的激活值，在
    Adaline 的特例中，这是一个线性函数。
- en: 'Furthermore, we defined the activation function ![](img/B13208_12_010.png)
    as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还定义了激活函数，如下所示：![](img/B13208_12_010.png)
- en: '![](img/B13208_12_011.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_011.png)'
- en: 'Here, the net input, *z*, is a linear combination of the weights that are connecting
    the input layer to the output layer:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，净输入 *z* 是连接输入层与输出层的权重的线性组合：
- en: '![](img/B13208_12_012.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_012.png)'
- en: 'While we used the activation ![](img/B13208_12_013.png) to compute the gradient
    update, we implemented a threshold function to squash the continuous valued output
    into binary class labels for prediction:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们使用激活值 ![](img/B13208_12_013.png) 来计算梯度更新，但我们实现了一个阈值函数，将连续值的输出压缩成二分类标签以进行预测：
- en: '![](img/B13208_12_014.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_014.png)'
- en: '**Single-layer naming convention**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**单层命名约定**'
- en: Note that although Adaline consists of two layers, one input layer and one output
    layer, it is called a single-layer network because of its single link between
    the input and output layers.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，尽管Adaline由两层组成，一个输入层和一个输出层，但它被称为单层网络，因为输入层与输出层之间只有一个连接。
- en: Also, we learned about a certain *trick* to accelerate the model learning, the
    so-called **stochastic gradient descent** (**SGD**) optimization. SGD approximates
    the cost from a single training sample (online learning) or a small subset of
    training examples (mini-batch learning). We will make use of this concept later
    in this chapter when we implement and train a multilayer perceptron (MLP). Apart
    from faster learning—due to the more frequent weight updates compared to gradient
    descent—its noisy nature is also regarded as beneficial when training multilayer
    NNs with nonlinear activation functions, which do not have a convex cost function.
    Here, the added noise can help to escape local cost minima, but we will discuss
    this topic in more detail later in this chapter.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还了解了一种加速模型学习的*技巧*，即所谓的**随机梯度下降**（**SGD**）优化方法。SGD通过一个单独的训练样本（在线学习）或一小部分训练样本（小批量学习）来逼近成本。稍后我们在本章中实现并训练多层感知机（MLP）时将会利用这个概念。除了比梯度下降更频繁地更新权重从而加速学习外，SGD的噪声特性在训练具有非线性激活函数且没有凸成本函数的多层神经网络（NN）时也被认为是有益的。这里，增加的噪声有助于逃离局部成本最小值，但我们将在本章后面详细讨论这个话题。
- en: Introducing the multilayer neural network architecture
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入多层神经网络架构
- en: In this section, you will learn how to connect multiple single neurons to a
    multilayer feedforward NN; this special type of *fully connected* network is also
    called **MLP**.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何将多个单个神经元连接成一个多层前馈神经网络；这种特殊类型的*全连接*网络也被称为**MLP**。
- en: 'The following figure illustrates the concept of an MLP consisting of three
    layers:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个由三层组成的MLP的概念：
- en: '![](img/B13208_12_02.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_02.png)'
- en: The MLP depicted in the preceding figure has one input layer, one hidden layer,
    and one output layer. The units in the hidden layer are fully connected to the
    input layer, and the output layer is fully connected to the hidden layer. If such
    a network has more than one hidden layer, we also call it a **deep artificial
    NN**.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 前面图示的MLP有一个输入层、一个隐藏层和一个输出层。隐藏层的单元与输入层全连接，输出层与隐藏层全连接。如果这样一个网络有多个隐藏层，我们也称之为**深度人工神经网络**。
- en: '**Adding additional hidden layers**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**添加额外的隐藏层**'
- en: We can add any number of hidden layers to the MLP to create deeper network architectures.
    Practically, we can think of the number of layers and units in an NN as additional
    hyperparameters that we want to optimize for a given problem task using cross-validation
    technique, which we discussed in *Chapter 6*, *Learning Best Practices for Model
    Evaluation and Hyperparameter Tuning*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以向MLP中添加任意数量的隐藏层，以创建更深的网络架构。在实际操作中，我们可以将神经网络中的层数和单元数视为额外的超参数，利用交叉验证技术优化这些超参数，以解决特定的任务，这一技术我们在*第六章*中讨论过，*模型评估与超参数调优的最佳实践*。
- en: However, the error gradients, which we will calculate later via backpropagation,
    will become increasingly small as more layers are added to a network. This vanishing
    gradient problem makes the model learning more challenging. Therefore, special
    algorithms have been developed to help train such DNN structures; this is known
    as **deep learning**.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着网络中层数的增加，我们稍后通过反向传播计算的误差梯度将变得越来越小。这种梯度消失问题使得模型学习更加困难。因此，已经开发了特殊的算法来帮助训练这种深度神经网络（DNN）结构；这就是**深度学习**。
- en: 'As shown in the preceding figure, we denote the *i*th activation unit in the
    *l*th layer as ![](img/B13208_12_015.png). To make the math and code implementations
    a bit more intuitive, we will not use numerical indices to refer to layers, but
    we will use the *in* superscript for the input layer, the *h* superscript for
    the hidden layer, and the *out* superscript for the output layer. For instance,
    ![](img/B13208_12_016.png) refers to the *i*th value in the input layer, ![](img/B13208_12_017.png)
    refers to the *i*th unit in the hidden layer, and ![](img/B13208_12_018.png) refers
    to the *i*th unit in the output layer. Here, the activation units ![](img/B13208_12_019.png)
    and ![](img/B13208_12_020.png) are the bias units, which we set equal to 1\. The
    activation of the units in the input layer is just its input plus the bias unit:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，我们将层 *l* 中第 *i* 个激活单元表示为 ![](img/B13208_12_015.png)。为了让数学公式和代码实现更加直观，我们不再使用数字索引来表示层，而是使用
    *in* 上标表示输入层，*h* 上标表示隐藏层，*out* 上标表示输出层。例如，![](img/B13208_12_016.png) 表示输入层中的第
    *i* 个值，![](img/B13208_12_017.png) 表示隐藏层中的第 *i* 个单元，![](img/B13208_12_018.png)
    表示输出层中的第 *i* 个单元。这里，激活单元 ![](img/B13208_12_019.png) 和 ![](img/B13208_12_020.png)
    是偏置单元，我们将其设为 1。输入层单元的激活值就是它的输入加上偏置单元：
- en: '![](img/B13208_12_021.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_021.png)'
- en: '**Notational convention for the bias units**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**偏置单元的符号约定**'
- en: Later in this chapter, we will implement an MLP using separate vectors for the
    bias units, which makes code implementation more efficient and easier to read.
    This concept is also used by TensorFlow, a deep learning library that we will
    cover in *Chapter 13*, *Parallelizing Neural Network Training with TensorFlow*.
    However, the mathematical equations that will follow would appear more complex
    or convoluted if we had to work with additional variables for the bias. Note that
    the computation via appending 1s to the input vector (as shown previously) and
    using a weight variable as bias is exactly the same as operating with separate
    bias vectors; it is merely a different convention.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本章后面，我们将使用单独的向量来实现 MLP 中的偏置单元，这使得代码实现更高效、更易读。这个概念也被深度学习库 TensorFlow 使用，我们将在*第13章*《使用
    TensorFlow 并行化神经网络训练》中详细讲解。然而，如果我们必须使用额外的偏置变量，接下来的数学方程会显得更加复杂或晦涩。请注意，通过将 1 附加到输入向量（如前所示）并使用权重变量作为偏置，实际上与使用单独的偏置向量的操作完全相同，只是采用了不同的约定。
- en: Each unit in layer *l* is connected to all units in layer *l* + 1 via a weight
    coefficient. For example, the connection between the *k*th unit in layer *l* to
    the *j*th unit in layer *l* + 1 will be written as ![](img/B13208_12_022.png).
    Referring back to the previous figure, we denote the weight matrix that connects
    the input to the hidden layer as ![](img/B13208_12_023.png), and we write the
    matrix that connects the hidden layer to the output layer as ![](img/B13208_12_024.png).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 层 *l* 中的每个单元都通过权重系数与层 *l* + 1 中的所有单元相连接。例如，层 *l* 中第 *k* 个单元与层 *l* + 1 中第 *j*
    个单元之间的连接将写作 ![](img/B13208_12_022.png)。回顾前面的图，我们将连接输入层和隐藏层的权重矩阵表示为 ![](img/B13208_12_023.png)，而将连接隐藏层和输出层的矩阵表示为
    ![](img/B13208_12_024.png)。
- en: While one unit in the output layer would suffice for a binary classification
    task, we saw a more general form of NN in the preceding figure, which allows us
    to perform multiclass classification via a generalization of the **one-versus-all**
    (**OvA**) technique. To better understand how this works, remember the **one-hot**
    representation of categorical variables that we introduced in *Chapter 4*, *Building
    Good Training Datasets – Data Preprocessing*.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然输出层中的一个单元足以处理二分类任务，但我们在前面的图中看到了一种更通用的神经网络形式，它通过**一对多**（**OvA**）技术的泛化来实现多分类任务。为了更好地理解这种方法，回想一下我们在*第4章*《构建良好的训练数据集—数据预处理》中介绍的**一热编码**表示法。
- en: 'For example, we can encode the three class labels in the familiar Iris dataset
    (*0=Setosa, 1=Versicolor, 2=Virginica*) as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以将熟悉的鸢尾花数据集中的三个类别标签（*0=Setosa, 1=Versicolor, 2=Virginica*）编码如下：
- en: '![](img/B13208_12_025.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_025.png)'
- en: This one-hot vector representation allows us to tackle classification tasks
    with an arbitrary number of unique class labels present in the training dataset.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这种一热编码向量表示法使我们能够处理训练数据集中具有任意数量独特类别标签的分类任务。
- en: 'If you are new to NN representations, the indexing notation (subscripts and
    superscripts) may look a little bit confusing at first. What may seem overly complicated
    at first will make much more sense in later sections when we vectorize the NN
    representation. As introduced earlier, we summarize the weights that connect the
    input and hidden layers by a matrix ![](img/B13208_12_026.png), where *d* is the
    number of hidden units and *m* is the number of input units including the bias
    unit. Since it is important to internalize this notation to follow the concepts
    later in this chapter, let''s summarize what we have just learned in a descriptive
    illustration of a simplified 3-4-3 MLP:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对神经网络（NN）表示法不熟悉，索引符号（下标和上标）一开始可能会有些混乱。最初看似过于复杂的东西，在后续章节中当我们对神经网络表示法进行向量化时，会更容易理解。正如前面所介绍的，我们通过矩阵
    ![](img/B13208_12_026.png) 来总结连接输入层和隐藏层的权重，其中*d*是隐藏单元的数量，*m*是包括偏置单元在内的输入单元数量。由于掌握这一表示法对于理解本章后续概念非常重要，让我们通过一个简化的3-4-3
    MLP示意图来总结我们刚刚学到的内容：
- en: '![](img/B13208_12_03.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_03.png)'
- en: Activating a neural network via forward propagation
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过前向传播激活神经网络
- en: 'In this section, we will describe the process of **forward propagation** to
    calculate the output of an MLP model. To understand how it fits into the context
    of learning an MLP model, let''s summarize the MLP learning procedure in three
    simple steps:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述**前向传播**的过程，以计算MLP模型的输出。为了理解它如何融入学习MLP模型的背景中，我们将MLP学习过程总结为三个简单步骤：
- en: Starting at the input layer, we forward propagate the patterns of the training
    data through the network to generate an output.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输入层开始，我们将训练数据的模式通过网络进行前向传播，以生成输出。
- en: Based on the network's output, we calculate the error that we want to minimize
    using a cost function that we will describe later.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于网络的输出，我们计算希望最小化的误差，并使用稍后将描述的成本函数。
- en: We backpropagate the error, find its derivative with respect to each weight
    in the network, and update the model.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们反向传播误差，找到它对网络中每个权重的导数，并更新模型。
- en: Finally, after we repeat these three steps for multiple epochs and learn the
    weights of the MLP, we use forward propagation to calculate the network output
    and apply a threshold function to obtain the predicted class labels in the one-hot
    representation, which we described in the previous section.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在我们为多个时期重复这三步并学习MLP的权重后，我们使用前向传播来计算网络输出，并应用阈值函数以获得前一节中描述的独热表示的预测类别标签。
- en: 'Now, let''s walk through the individual steps of forward propagation to generate
    an output from the patterns in the training data. Since each unit in the hidden
    layer is connected to all units in the input layers, we first calculate the activation
    unit of the hidden layer ![](img/B13208_12_027.png) as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们逐步通过前向传播来生成训练数据模式的输出。由于隐藏层中的每个单元都与输入层中的所有单元相连，我们首先计算隐藏层的激活单元 ![](img/B13208_12_027.png)，计算方式如下：
- en: '![](img/B13208_12_028.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_028.png)'
- en: 'Here, ![](img/B13208_12_029.png) is the net input and ![](img/B13208_12_030.png)
    is the activation function, which has to be differentiable to learn the weights
    that connect the neurons using a gradient-based approach. To be able to solve
    complex problems such as image classification, we need nonlinear activation functions
    in our MLP model, for example, the sigmoid (logistic) activation function that
    we remember from the section about logistic regression in *Chapter 3*, *A Tour
    of Machine Learning Classifiers Using scikit-learn*:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B13208_12_029.png)是净输入，![](img/B13208_12_030.png)是激活函数，必须可微分，以便使用基于梯度的方法学习连接神经元的权重。为了能够解决图像分类等复杂问题，我们在MLP模型中需要非线性激活函数，例如我们在*第3章*《使用scikit-learn的机器学习分类器巡礼》中记得的sigmoid（逻辑）激活函数：
- en: '![](img/B13208_12_031.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_031.png)'
- en: 'As you may recall, the sigmoid function is an *S*-shaped curve that maps the
    net input *z* onto a logistic distribution in the range 0 to 1, which cuts the
    *y*-axis at *z* = 0, as shown in the following graph:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所记得，sigmoid函数是一个*S*形曲线，它将净输入*z*映射到一个在0到1范围内的逻辑分布，在*z* = 0时切割*y*轴，如下图所示：
- en: '![](img/B13208_12_04.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_04.png)'
- en: MLP is a typical example of a feedforward artificial NN. The term **feedforward**
    refers to the fact that each layer serves as the input to the next layer without
    loops, in contrast to recurrent NNs—an architecture that we will discuss later
    in this chapter and discuss in more detail in *Chapter 16*, *Modeling Sequential
    Data Using Recurrent Neural Networks*. The term *multilayer perceptron* may sound
    a little bit confusing since the artificial neurons in this network architecture
    are typically sigmoid units, not perceptrons. We can think of the neurons in the
    MLP as logistic regression units that return values in the continuous range between
    0 and 1.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: MLP 是一种典型的前馈人工神经网络（NN）。术语 **前馈** 指的是每一层作为下一层的输入，没有循环，这与递归神经网络（RNN）不同——我们将在本章稍后讨论并在*第16章*《使用递归神经网络建模序列数据》中详细讨论。术语
    *多层感知器* 可能有点令人困惑，因为在这个网络架构中，人工神经元通常是 sigmoid 单元，而不是感知器。我们可以把 MLP 中的神经元看作是逻辑回归单元，返回的值在
    0 到 1 之间的连续范围内。
- en: 'For purposes of code efficiency and readability, we will now write the activation
    in a more compact form using the concepts of basic linear algebra, which will
    allow us to vectorize our code implementation via NumPy rather than writing multiple
    nested and computationally expensive Python `for` loops:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高代码效率和可读性，我们将使用基础线性代数的概念以更紧凑的形式编写激活函数，这将使我们能够通过 NumPy 向量化实现代码，而不是编写多个嵌套且计算量大的
    Python `for` 循环：
- en: '![](img/B13208_12_032.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_032.png)'
- en: Here, ![](img/B13208_12_033.png) is our ![](img/B13208_12_034.png) dimensional
    feature vector of a sample ![](img/B13208_12_035.png) plus a bias unit.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B13208_12_033.png) 是我们样本的 ![](img/B13208_12_034.png) 维特征向量加上一个偏置单元
    ![](img/B13208_12_035.png)。
- en: '![](img/B13208_12_036.png) is an ![](img/B13208_12_037.png) dimensional weight
    matrix where *d* is the number of units in the hidden layer. After matrix-vector
    multiplication, we obtain the ![](img/B13208_12_038.png) dimensional net input
    vector ![](img/B13208_12_039.png) to calculate the activation ![](img/B13208_12_040.png)
    (where ![](img/B13208_12_041.png)).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B13208_12_036.png) 是一个 ![](img/B13208_12_037.png) 维的权重矩阵，其中 *d* 是隐藏层中的单元数量。经过矩阵-向量乘法，我们得到
    ![](img/B13208_12_038.png) 维的净输入向量 ![](img/B13208_12_039.png)，以计算激活值 ![](img/B13208_12_040.png)（其中
    ![](img/B13208_12_041.png)）。'
- en: 'Furthermore, we can generalize this computation to all *n* examples in the
    training dataset:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以将此计算推广到训练数据集中的所有 *n* 个样本：
- en: '![](img/B13208_12_042.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_042.png)'
- en: 'Here, ![](img/B13208_12_043.png) is now an ![](img/B13208_12_044.png) matrix,
    and the matrix-matrix multiplication will result in an ![](img/B13208_12_045.png)
    dimensional net input matrix ![](img/B13208_12_046.png). Finally, we apply the
    activation function ![](img/B13208_12_047.png) to each value in the net input
    matrix to get the ![](img/B13208_12_048.png) activation matrix the next layer
    (here, the output layer):'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/B13208_12_043.png) 现在是一个 ![](img/B13208_12_044.png) 矩阵，矩阵-矩阵乘法将得到一个
    ![](img/B13208_12_045.png) 维的净输入矩阵 ![](img/B13208_12_046.png)。最后，我们对净输入矩阵中的每个值应用激活函数
    ![](img/B13208_12_047.png)，以获得下一层的激活矩阵（这里是输出层）：
- en: '![](img/B13208_12_049.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_049.png)'
- en: 'Similarly, we can write the activation of the output layer in vectorized form
    for multiple examples:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以为多个样本写出输出层的激活值的向量化形式：
- en: '![](img/B13208_12_050.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_050.png)'
- en: Here, we multiply the ![](img/B13208_12_051.png) matrix ![](img/B13208_12_052.png)
    (*t* is the number of output units) by the ![](img/B13208_12_053.png) dimensional
    matrix ![](img/B13208_12_054.png) to obtain the ![](img/B13208_12_055.png) dimensional
    matrix ![](img/B13208_12_056.png) (the columns in this matrix represent the outputs
    for each sample).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将 ![](img/B13208_12_051.png) 矩阵 ![](img/B13208_12_052.png)（*t* 是输出单元的数量）与
    ![](img/B13208_12_053.png) 维的矩阵 ![](img/B13208_12_054.png) 相乘，以获得 ![](img/B13208_12_055.png)
    维的矩阵 ![](img/B13208_12_056.png)（该矩阵的列表示每个样本的输出）。
- en: 'Lastly, we apply the sigmoid activation function to obtain the continuous valued
    output of our network:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们应用 sigmoid 激活函数以获得网络的连续值输出：
- en: '![](img/B13208_12_057.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_057.png)'
- en: Classifying handwritten digits
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手写数字分类
- en: In the previous section, we covered a lot of the theory around NNs, which can
    be a little bit overwhelming if you are new to this topic. Before we continue
    with the discussion of the algorithm for learning the weights of the MLP model,
    backpropagation, let's take a short break from the theory and see an NN in action.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讲解了许多关于神经网络（NN）的理论，对于初学者来说，这可能会有些令人不知所措。在我们继续讨论用于学习MLP模型权重的算法——反向传播之前，先暂时休息一下理论部分，看看神经网络的实际应用。
- en: '**Additional resources on backpropagation**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**关于反向传播的额外资源**'
- en: 'The NN theory can be quite complex; thus, it is recommended that you refer
    to two additional resources, which cover some of the concepts that we discuss
    in this chapter in more detail:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络理论可能相当复杂，因此建议参考两份额外资源，它们更加详细地讨论了我们在本章中讨论的一些概念：
- en: '*Chapter 6*, *Deep Feedforward Networks*, *Deep Learning*, *I. Goodfellow*,
    *Y. Bengio*, and *A. Courville*, MIT Press, *2016* (Manuscripts freely accessible
    at [http://www.deeplearningbook.org](http://www.deeplearningbook.org)).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第6章*，*深度前馈网络*，*深度学习*，*I. Goodfellow*，*Y. Bengio*，*A. Courville*，MIT出版社，*2016*（手稿可在[http://www.deeplearningbook.org](http://www.deeplearningbook.org)免费下载）。'
- en: '*Pattern Recognition and Machine Learning*, *C. M. Bishop* and others, Volume
    1\. *Springer New York*, *2006*.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模式识别与机器学习*，*C. M. Bishop* 等著，第1卷。*Springer New York*，*2006*。'
- en: 'Lecture slides from the deep learning course at the University of Wisconsin–Madison:'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自威斯康星大学麦迪逊分校的深度学习课程讲义：
- en: '[https://sebastianraschka.com/pdf/lecture-notes/stat479ss19/L08_logistic_slides.pdf](https://sebastianraschka.com/pdf/lecture-notes/stat479ss19/L08_logistic_slides.pdf)'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://sebastianraschka.com/pdf/lecture-notes/stat479ss19/L08_logistic_slides.pdf](https://sebastianraschka.com/pdf/lecture-notes/stat479ss19/L08_logistic_slides.pdf)'
- en: '[https://sebastianraschka.com/pdf/lecture-notes/stat479ss19/L09_mlp_slides.pdf](https://sebastianraschka.com/pdf/lecture-notes/stat479ss19/L09_mlp_slides.pdf%20)'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://sebastianraschka.com/pdf/lecture-notes/stat479ss19/L09_mlp_slides.pdf](https://sebastianraschka.com/pdf/lecture-notes/stat479ss19/L09_mlp_slides.pdf%20)'
- en: 'In this section, we will implement and train our first multilayer NN to classify
    handwritten digits from the popular **Mixed National Institute of Standards and
    Technology** (**MNIST**) dataset that has been constructed by Yann LeCun and others
    and serves as a popular benchmark dataset for machine learning algorithms (*Gradient-Based
    Learning Applied to Document Recognition*, *Y. LeCun*, *L. Bottou*, *Y. Bengio*,
    and *P. Haffner*, *Proceedings of the IEEE*, 86(11): 2278-2324, *November 1998*).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将实现并训练我们的第一个多层神经网络，用于从流行的**混合国家标准与技术研究所**（**MNIST**）数据集中分类手写数字。该数据集由Yann
    LeCun等人构建，是机器学习算法的一个流行基准数据集（*基于梯度的学习应用于文档识别*，*Y. LeCun*，*L. Bottou*，*Y. Bengio*，*P.
    Haffner*，*IEEE会议论文集*，86(11)：2278-2324，*1998年11月*）。
- en: Obtaining and preparing the MNIST dataset
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取和准备MNIST数据集
- en: 'The MNIST dataset is publicly available at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)
    and consists of the following four parts:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST数据集可以在[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)上公开获取，并包括以下四个部分：
- en: '**Training dataset images**: `train-images-idx3-ubyte.gz` (9.9 MB, 47 MB unzipped,
    and 60,000 examples)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据集图像**：`train-images-idx3-ubyte.gz`（9.9 MB，解压后为47 MB，共60,000个样本）'
- en: '**Training dataset labels**: `train-labels-idx1-ubyte.gz` (29 KB, 60 KB unzipped,
    and 60,000 labels)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据集标签**：`train-labels-idx1-ubyte.gz`（29 KB，解压后为60 KB，共60,000个标签）'
- en: '**Test dataset images**: `t10k-images-idx3-ubyte.gz` (1.6 MB, 7.8 MB unzipped,
    and 10,000 examples)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试数据集图像**：`t10k-images-idx3-ubyte.gz`（1.6 MB，解压后为7.8 MB，共10,000个样本）'
- en: '**Test dataset labels**: `t10k-labels-idx1-ubyte.gz` (5 KB, 10 KB unzipped,
    and 10,000 labels)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试数据集标签**：`t10k-labels-idx1-ubyte.gz`（5 KB，解压后为10 KB，共10,000个标签）'
- en: The MNIST dataset was constructed from two datasets of the US **National Institute
    of Standards and Technology** (**NIST**). The training dataset consists of handwritten
    digits from 250 different people, 50 percent high school students and 50 percent
    employees from the Census Bureau. Note that the test dataset contains handwritten
    digits from different people following the same split.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST数据集是由美国**国家标准与技术研究所**（**NIST**）的两个数据集构建的。训练数据集包含来自250个不同人的手写数字，其中50%来自高中生，50%来自人口普查局的工作人员。请注意，测试数据集包含来自不同人的手写数字，并且遵循相同的划分方式。
- en: 'After you download the files, it is recommended that you unzip them using the
    Unix/Linux `gzip` tool from the terminal for efficiency, using the following command
    in your local MNIST download directory:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 下载文件后，建议使用Unix/Linux中的`gzip`工具从终端解压这些文件，以提高效率。你可以在本地的MNIST下载目录中使用以下命令：
- en: '[PRE0]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Alternatively, you can use your favorite unzipping tool if you are working with
    a machine running Microsoft Windows.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你使用的是运行Microsoft Windows的机器，你也可以使用你喜欢的解压工具。
- en: 'The images are stored in byte format, and we will read them into NumPy arrays
    that we will use to train and test our MLP implementation. In order to do that,
    we will define the following helper function:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图像以字节格式存储，我们将它们读取到NumPy数组中，这些数组将用于训练和测试我们的MLP实现。为此，我们将定义以下辅助函数：
- en: '[PRE1]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `load_mnist` function returns two arrays, the first being an ![](img/B13208_12_058.png)
    dimensional NumPy array (`images`), where *n* is the number of examples and *m*
    is the number of features (here, pixels). The training dataset consists of 60,000
    training digits and the test dataset contains 10,000 examples, respectively.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`load_mnist`函数返回两个数组，第一个是一个![](img/B13208_12_058.png)维的NumPy数组（`images`），其中*n*是示例的数量，*m*是特征的数量（这里是像素）。训练数据集包含60,000个训练数字，测试数据集包含10,000个示例。'
- en: The images in the MNIST dataset consist of ![](img/B13208_12_059.png) pixels,
    and each pixel is represented by a grayscale intensity value. Here, we unroll
    the ![](img/B13208_12_060.png) pixels into one-dimensional row vectors, which
    represent the rows in our `images` array (784 per row or image). The second array
    (`labels`) returned by the `load_mnist` function contains the corresponding target
    variable, the class labels (integers 0-9) of the handwritten digits.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST数据集中的图像由![](img/B13208_12_059.png)像素组成，每个像素由灰度强度值表示。在这里，我们将![](img/B13208_12_060.png)像素展开为一维行向量，这些向量代表我们`images`数组中的行（每行或每幅图像有784个像素）。`load_mnist`函数返回的第二个数组（`labels`）包含相应的目标变量，即手写数字的类标签（整数0-9）。
- en: 'The way we read in the image might seem a little bit strange at first:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们读取图像的方式刚开始可能看起来有点奇怪：
- en: '[PRE2]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To understand how those two lines of code work, let''s take a look at the dataset
    description from the MNIST website:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这两行代码是如何工作的，让我们先看看来自MNIST网站的数据集描述：
- en: '[PRE3]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Using the two preceding lines of code, we first read in the magic number, which
    is a description of the file protocol, as well as the number of items (`n`) from
    the file buffer, before we load the following bytes into a NumPy array using the
    `fromfile` method. The `fmt` parameter value, `''>II''`, that we passed as an
    argument to `struct.unpack` can be composed into the two following parts:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面两行代码，我们首先从文件缓冲区读取魔数，它是文件协议的描述，以及项目数量（`n`），然后我们使用`fromfile`方法将接下来的字节加载到NumPy数组中。我们传递给`struct.unpack`的`fmt`参数值`'>II'`可以分解成以下两个部分：
- en: '`>`: This is big-endian—it defines the order in which a sequence of bytes is
    stored; if you are unfamiliar with the terms big-endian and little-endian, you
    can find an excellent article about *Endianness* on Wikipedia: [https://en.wikipedia.org/wiki/Endianness](https://en.wikipedia.org/wiki/Endianness)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`>`: 这是大端字节序——它定义了字节序列的存储顺序；如果你不熟悉大端字节序和小端字节序的术语，你可以在维基百科上找到一篇关于*字节序*的优秀文章：[https://en.wikipedia.org/wiki/Endianness](https://en.wikipedia.org/wiki/Endianness)'
- en: '`I`: This is an unsigned integer'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`I`: 这是一个无符号整数'
- en: 'Finally, we also normalized the pixels values in MNIST to the range –1 to 1
    (originally 0 to 255) via the following code line:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还通过以下代码行将MNIST中的像素值规范化到范围–1到1（原始范围是0到255）：
- en: '[PRE4]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The reason behind this is that gradient-based optimization is much more stable
    under these conditions as discussed in *Chapter 2*, *Training Simple Machine Learning
    Algorithms for Classification*. Note that we scaled the images on a pixel-by-pixel
    basis, which is different from the feature scaling approach that we took in previous
    chapters.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的原因是，基于梯度的优化在这些条件下更加稳定，正如*第2章*《为分类训练简单机器学习算法》中所讨论的那样。请注意，我们是按像素逐个对图像进行缩放的，这与我们在前几章中采取的特征缩放方法不同。
- en: Previously, we derived scaling parameters from the training dataset and used
    these to scale each column in the training dataset and test dataset. However,
    when working with image pixels, centering them at zero and rescaling them to a
    [–1, 1] range is also common and usually works well in practice.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们从训练数据集中推导出缩放参数，并用这些参数对训练数据集和测试数据集中的每一列进行缩放。然而，在处理图像像素时，将像素值居中为零并重新缩放到[–1,
    1]范围也是常见的做法，并且在实践中通常效果很好。
- en: '**Batch normalization**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**批量归一化**'
- en: 'A commonly used trick for improving convergence in gradient-based optimization
    through input scaling is *batch normalization*, which is an advanced topic that
    we will cover in *Chapter 17*, *Generative Adversarial Networks for Synthesizing
    New Data*. Also, you can read more about batch normalization in the excellent
    research article *Batch Normalization: Accelerating Deep Network Training by Reducing
    Internal Covariate Shift* by *Sergey Ioffe* and *Christian Szegedy* (2015, [https://arxiv.org/abs/1502.03167](https://arxiv.org/abs/1502.03167)).'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '一个常用的技巧是通过输入缩放来改善基于梯度的优化收敛性，称为 *批量归一化*，这是一个高级主题，我们将在 *第17章*，*生成对抗网络用于合成新数据*
    中详细讨论。此外，您还可以阅读由 *Sergey Ioffe* 和 *Christian Szegedy*（2015年，[https://arxiv.org/abs/1502.03167](https://arxiv.org/abs/1502.03167)）撰写的优秀研究文章
    *Batch Normalization: Accelerating Deep Network Training by Reducing Internal
    Covariate Shift* 来了解更多批量归一化的内容。'
- en: '[PRE5]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To get an idea of how those images in MNIST look, let''s visualize examples
    of the digits 0-9 after reshaping the 784-pixel vectors from our feature matrix
    into the original ![](img/B13208_12_061.png) image that we can plot via Matplotlib''s
    `imshow` function:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解 MNIST 中这些图像的样子，让我们在将特征矩阵中的 784 像素向量重塑为原始的 ![](img/B13208_12_061.png) 图像后，通过
    Matplotlib 的 `imshow` 函数来可视化数字 0-9 的示例：
- en: '[PRE7]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We should now see a plot of the ![](img/B13208_12_062.png) subfigures showing
    a representative image of each unique digit:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在应该看到一个图形，展示了每个独特数字的代表性图像的 ![](img/B13208_12_062.png) 子图：
- en: '![](img/B13208_12_05.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_05.png)'
- en: 'In addition, let''s also plot multiple examples of the same digit to see how
    different the handwriting for each really is:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还可以绘制多个相同数字的示例，以查看每个手写数字之间的差异：
- en: '[PRE8]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'After executing the code, we should now see the first 25 variants of the digit
    7:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 执行代码后，我们应该能看到数字 7 的前 25 种变体：
- en: '![](img/B13208_12_06.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_06.png)'
- en: 'After we''ve gone through all the previous steps, it is a good idea to save
    the scaled images in a format that we can load more quickly into a new Python
    session to avoid the overhead of reading in and processing the data again. When
    we are working with NumPy arrays, an efficient and convenient method to save multidimensional
    arrays to disk is NumPy''s `savez` function. (The official documentation can be
    found here: [https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html).)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成之前的所有步骤后，最好将缩放后的图像保存为一种格式，以便在新的 Python 会话中更快速地加载，避免再次读取和处理数据的开销。当我们处理 NumPy
    数组时，保存多维数组到磁盘的一种高效且方便的方法是使用 NumPy 的 `savez` 函数。（官方文档可以在这里找到：[https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html)。）
- en: '[PRE9]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After we create the `.npz` files, we can load the preprocessed MNIST image
    arrays using NumPy''s `load` function as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 `.npz` 文件后，我们可以使用 NumPy 的 `load` 函数按如下方式加载预处理过的 MNIST 图像数组：
- en: '[PRE11]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The `mnist` variable now refers to an object that can access the four data
    arrays that we provided as keyword arguments to the `savez_compressed` function.
    These input arrays are now listed under the `files` attribute list of the `mnist`
    object:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`mnist` 变量现在指向一个对象，该对象可以访问我们作为关键字参数提供给 `savez_compressed` 函数的四个数据数组。这些输入数组现在列在
    `mnist` 对象的 `files` 属性列表下：'
- en: '[PRE12]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'For instance, to load the training data into our current Python session, we
    will access the `X_train` array as follows (similar to a Python dictionary):'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要将训练数据加载到当前的 Python 会话中，我们将按如下方式访问 `X_train` 数组（类似于 Python 字典）：
- en: '[PRE13]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Using a list comprehension, we can retrieve all four data arrays as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 使用列表推导式，我们可以按如下方式检索所有四个数据数组：
- en: '[PRE14]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note that while the preceding `np.savez_compressed` and `np.load` examples are
    not essential for executing the code in this chapter, they serve as a demonstration
    of how to save and load NumPy arrays conveniently and efficiently.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，虽然前面的 `np.savez_compressed` 和 `np.load` 示例对于执行本章代码并非必需，但它们作为如何方便高效地保存和加载
    NumPy 数组的演示是很有帮助的。
- en: '**Loading MNIST using scikit-learn**'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 scikit-learn 加载 MNIST**'
- en: 'Using scikit-learn''s new `fetch_openml` function, it is now also possible
    to load the MNIST dataset more conveniently. For example, you can use the following
    code to create a 50,000-example training dataset and and a 10,000-example test
    dataset by fetching the dataset from [https://www.openml.org/d/554](https://www.openml.org/d/554):'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 新的 `fetch_openml` 函数，现在也可以更方便地加载 MNIST 数据集。例如，您可以使用以下代码通过从 [https://www.openml.org/d/554](https://www.openml.org/d/554)
    获取数据集来创建一个包含 50,000 个示例的训练数据集和一个包含 10,000 个示例的测试数据集：
- en: '[PRE15]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Please note that the distribution of MNIST records into training and test datasets
    will be different from the manual approach outlined in this section. Thus, you
    will observe slightly different results in the following sections if you load
    the dataset using the `fetch_openml` and `train_test_split` functions.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，MNIST记录分配到训练集和测试集的方式将不同于本节中概述的手动方法。因此，如果你使用`fetch_openml`和`train_test_split`函数加载数据集，你将在接下来的章节中观察到略有不同的结果。
- en: Implementing a multilayer perceptron
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现一个多层感知器
- en: In this subsection, we will now implement an MLP from scratch to classify the
    images in the MNIST dataset. To keep things simple, we will implement an MLP with
    only one hidden layer. Since the approach may seem a little bit complicated at
    first, you are encouraged to download the sample code for this chapter from the
    Packt Publishing website or from GitHub ([https://github.com/rasbt/python-machine-learning-book-3rd-edition](https://github.com/rasbt/python-machine-learning-book-3rd-edition))
    so that you can view this MLP implementation annotated with comments and syntax
    highlighting for better readability.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们将从头开始实现一个多层感知器（MLP），以对MNIST数据集中的图像进行分类。为了简化，我们将只实现一个包含一个隐藏层的MLP。由于该方法一开始可能会显得有些复杂，建议你从Packt出版社网站或GitHub（[https://github.com/rasbt/python-machine-learning-book-3rd-edition](https://github.com/rasbt/python-machine-learning-book-3rd-edition)）下载本章的示例代码，以便查看带有注释和语法高亮的MLP实现，增强可读性。
- en: 'If you are not running the code from the accompanying Jupyter Notebook file
    or don''t have access to the Internet, copy the `NeuralNetMLP` code from this
    chapter into a Python script file in your current working directory (for example,
    `neuralnet.py``)`, which you can then import into your current Python session
    via the following command:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不是在配套的Jupyter Notebook文件中运行代码，或者没有互联网连接，可以将本章中的`NeuralNetMLP`代码复制到当前工作目录下的Python脚本文件中（例如，`neuralnet.py`），然后通过以下命令将其导入当前的Python会话：
- en: '[PRE16]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The code will contain parts that we have not talked about yet, such as the backpropagation
    algorithm, but most of the code should look familiar to you based on the Adaline
    implementation in *Chapter 2*, *Training Simple Machine Learning Algorithms for
    Classification*, and the discussion of forward propagation in earlier sections.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 代码中将包含一些我们尚未讨论的部分，例如反向传播算法，但基于*第二章*《训练简单的机器学习分类算法》中的Adaline实现和前向传播的讨论，大部分代码对你来说应该是熟悉的。
- en: Do not worry if not all of the code makes immediate sense to you; we will follow
    up on certain parts later in this chapter. However, going over the code at this
    stage can make it easier to follow the theory later.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果所有代码对你来说一时难以理解，不要担心；我们将在本章后面讲解某些部分。然而，在此阶段回顾代码可以帮助你更容易地理解后续的理论内容。
- en: 'The following is the implementation of an MLP:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是多层感知器的实现：
- en: '[PRE17]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After executing this code, we next initialize a new 784-100-10 MLP—an NN with
    784 input units (`n_features`), 100 hidden units (`n_hidden`), and 10 output units
    (`n_output`):'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此代码后，我们接下来将初始化一个新的784-100-10多层感知器（MLP）——一个具有784个输入单元（`n_features`）、100个隐藏单元（`n_hidden`）和10个输出单元（`n_output`）的神经网络：
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If you read through the `NeuralNetMLP` code, you''ve probably already guessed
    what these parameters are for. Here, you find a short summary of them:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你浏览过`NeuralNetMLP`代码，可能已经猜到这些参数的用途。这里是它们的简短总结：
- en: '`l2`: This is the ![](img/B13208_12_063.png) parameter for L2 regularization
    to decrease the degree of overfitting.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`l2`：这是用于L2正则化的![](img/B13208_12_063.png)参数，用于减少过拟合的程度。'
- en: '`epochs`: This is the number of passes over the training dataset.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epochs`：这是对训练数据集的迭代次数。'
- en: '`eta`: This is the learning rate ![](img/B13208_12_064.png).'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta`：这是学习率![](img/B13208_12_064.png)。'
- en: '`shuffle`: This is for shuffling the training set prior to every epoch to prevent
    the algorithm getting stuck in circles.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shuffle`：这是用于在每个训练轮次前对训练集进行洗牌，以防止算法陷入循环中。'
- en: '`seed`: This is a random seed for shuffling and weight initialization.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seed`：这是用于洗牌和权重初始化的随机种子。'
- en: '`minibatch_size`: This is the number of training examples in each mini-batch
    when splitting the training data in each epoch for SGD. The gradient is computed
    for each mini-batch separately instead of the entire training data for faster
    learning.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minibatch_size`：这是每个小批量中的训练样本数量，用于在每个epoch中将训练数据划分为小批量进行随机梯度下降（SGD）。梯度将在每个小批量上单独计算，而不是在整个训练数据上计算，以加速学习。'
- en: Next, we train the MLP using 55,000 examples from the already shuffled MNIST
    training dataset and use the remaining 5,000 examples for validation during training.
    Note that training the NN may take up to five minutes on standard desktop computer
    hardware.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用已经打乱的MNIST训练数据集中的55,000个示例来训练MLP，并使用剩余的5,000个示例在训练过程中进行验证。请注意，在标准桌面计算机硬件上，训练神经网络可能需要最多五分钟的时间。
- en: 'As you may have noticed from the preceding code, we implemented the `fit` method
    so that it takes four input arguments: training images, training labels, validation
    images, and validation labels. In NN training, it is really useful to compare
    training and validation accuracy, which helps us judge whether the network model
    performs well, given the architecture and hyperparameters. For example, if we
    observe a low training and validation accuracy, there is likely an issue with
    the training dataset, or the hyperparameters settings are not ideal. A relatively
    large gap between the training and the validation accuracy indicated that the
    model is likely overfitting the training dataset so that we want to reduce the
    number of parameters in the model or increase the regularization strength. If
    both the training and validation accuracies are high, the model is likely to generalize
    well to new data, for example, the test dataset, which we use for the final model
    evaluation.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从前面的代码中可能已经注意到的，我们实现了`fit`方法，使其接受四个输入参数：训练图像、训练标签、验证图像和验证标签。在神经网络训练中，比较训练准确度和验证准确度非常有用，它帮助我们判断给定架构和超参数下，网络模型的表现如何。例如，如果我们观察到训练和验证准确度都很低，可能是训练数据集存在问题，或者超参数设置不理想。如果训练准确度和验证准确度之间存在较大差距，说明模型可能过拟合训练数据集，此时我们需要减少模型中的参数数量，或者增加正则化强度。如果训练和验证准确度都很高，模型可能会很好地泛化到新数据上，例如用于最终模型评估的测试数据集。
- en: In general, training (deep) NNs is relatively expensive compared with the other
    models we've discussed so far. Thus, we want to stop it early in certain circumstances
    and start over with different hyperparameter settings. On the other hand, if we
    find that it increasingly tends to overfit the training data (noticeable by an
    increasing gap between training and validation dataset performance), we may want
    to stop the training early as well.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，训练（深度）神经网络比我们到目前为止讨论的其他模型更为昂贵。因此，我们希望在某些情况下提前停止训练，并以不同的超参数设置重新开始。另一方面，如果我们发现模型越来越倾向于过拟合训练数据（通过训练和验证数据集性能之间差距的增加可以观察到），我们也可能希望提前停止训练。
- en: 'Now, to start the training, we execute the following code:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了开始训练，我们执行以下代码：
- en: '[PRE19]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In our `NeuralNetMLP` implementation, we also defined an `eval_` attribute
    that collects the cost, training, and validation accuracy for each epoch so that
    we can visualize the results using Matplotlib:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`NeuralNetMLP`实现中，我们还定义了一个`eval_`属性，它收集每个epoch的成本、训练准确度和验证准确度，以便我们使用Matplotlib可视化结果：
- en: '[PRE20]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The preceding code plots the cost over the 200 epochs, as shown in the following
    graph:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码绘制了200个epoch中的成本变化，如下图所示：
- en: '![](img/B13208_12_07.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_07.png)'
- en: As we can see, the cost decreased substantially during the first 100 epochs
    and seems to slowly converge in the last 100 epochs. However, the small slope
    between epoch `175` and epoch `200` indicates that the cost would further decrease
    with a training over additional epochs.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，成本在前100个epoch期间大幅下降，并且在最后100个epoch中似乎慢慢收敛。然而，`175`到`200`个epoch之间的斜率较小，表明继续训练更多epoch后，成本可能会进一步下降。
- en: 'Next, let''s take a look at the training and validation accuracy:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来看一下训练和验证的准确度：
- en: '[PRE21]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The preceding code examples plot those accuracy values over the 200 training
    epochs, as shown in the following figure:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码示例绘制了这200个训练epoch中的准确度值，如下图所示：
- en: '![](img/B13208_12_08.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_08.png)'
- en: The plot reveals that the gap between training and validation accuracy increases
    as we train for more epochs. At approximately the 50th epoch, the training and
    validation accuracy values are equal, and then, the network starts overfitting
    the training data.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图表显示，随着训练epoch的增加，训练和验证准确度之间的差距逐渐增大。在大约第50个epoch时，训练和验证准确度相等，然后网络开始过拟合训练数据。
- en: Note that this example was chosen deliberately to illustrate the effect of overfitting
    and demonstrate why it is useful to compare the validation and training accuracy
    values during training. One way to decrease the effect of overfitting is to increase
    the regularization strength—for example, by setting `l2=0.1`. Another useful technique
    to tackle overfitting in NNs is *dropout*, which will be covered in *Chapter 15*,
    *Classifying Images with Deep Convolutional Neural Networks*.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，选择这个例子是故意为了说明过拟合的影响，并展示为什么在训练过程中比较验证集和训练集的准确率值是有用的。减少过拟合的一个方法是增加正则化强度——例如，设置`l2=0.1`。另一个应对神经网络中过拟合的有效技术是*dropout*，这一点将在*第15章*《使用深度卷积神经网络进行图像分类》中详细讨论。
- en: 'Finally, let''s evaluate the generalization performance of the model by calculating
    the prediction accuracy on the test dataset:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们通过计算测试数据集上的预测准确率来评估模型的泛化性能：
- en: '[PRE22]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Despite the slight overfitting on the training data, our relatively simple one-hidden-layer
    NN achieved a relatively good performance on the test dataset, similar to the
    validation dataset accuracy (97.98 percent).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在训练数据上存在轻微的过拟合，我们的相对简单的一层隐藏层神经网络在测试数据集上取得了相对不错的表现，准确率与验证数据集相似（97.98%）。
- en: To further fine-tune the model, we could change the number of hidden units,
    values of the regularization parameters, and the learning rate, or use various
    other tricks that have been developed over the years but are beyond the scope
    of this book. In *Chapter 15*, *Classifying Images with Deep Convolutional Neural
    Networks*, you will learn about a different NN architecture that is known for
    its good performance on image datasets. Also, the chapter will introduce additional
    performance-enhancing tricks such as adaptive learning rates, more sophisticated
    SGD-based optimization algorithms, batch normalization, and dropout.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步微调模型，我们可以改变隐藏单元的数量、正则化参数的值和学习率，或者使用多年来开发的各种技巧，这些技巧超出了本书的范围。在*第15章*《使用深度卷积神经网络进行图像分类》中，你将学习一种不同的神经网络架构，这种架构在图像数据集上表现良好。此外，本章还将介绍一些提升性能的技巧，如自适应学习率、更加复杂的基于SGD的优化算法、批归一化和dropout。
- en: 'Other common tricks that are beyond the scope of the following chapters include:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些常见的技巧，超出了接下来的章节的范围，包括：
- en: Adding skip-connections, which are the main contribution of residual NNs (*Deep
    residual learning for image recognition*. K. He, X. Zhang, S. Ren, J. Sun (2016).
    In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*,
    pp. 770-778)
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加跳跃连接，这是残差神经网络（*深度残差学习用于图像识别*，K. He, X. Zhang, S. Ren, J. Sun，2016年，见《IEEE计算机视觉与模式识别会议论文集》，第770-778页）最主要的贡献。
- en: Using learning rate schedulers that change the learning rate during training
    (*Cyclical learning rates for training neural networks*. L.N. Smith (2017). In
    *2017 IEEE Winter Conference on Applications of Computer Vision (WACV)*, pp. 464-472)
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用学习率调度器，在训练过程中动态改变学习率（*神经网络训练中的循环学习率*，L.N. Smith，2017年，见《2017年IEEE冬季计算机视觉应用会议（WACV）》论文集，第464-472页）。
- en: Attaching loss functions to earlier layers in the networks as it's being done
    in the popular Inception v3 architecture (*Rethinking the Inception architecture
    for computer vision*. C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna
    (2016). In *Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition*, pp. 2818-2826)
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将损失函数附加到网络的早期层，这与流行的Inception v3架构中的做法相似（*重新思考Inception架构用于计算机视觉*，C. Szegedy,
    V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna，2016年，见《IEEE计算机视觉与模式识别会议论文集》，第2818-2826页）。
- en: 'Lastly, let''s take a look at some of the images that our MLP struggles with:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看一些我们的多层感知机（MLP）难以处理的图像：
- en: '[PRE23]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We should now see a ![](img/B13208_12_065.png) subplot matrix where the first
    number in the subtitles indicates the plot index, the second number represents
    the true class label (`t`), and the third number stands for the predicted class
    label (`p`):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在应该看到一个子图矩阵，其中字幕中的第一个数字表示情节索引，第二个数字表示真实类别标签（`t`），第三个数字表示预测类别标签（`p`）：
- en: '![](img/B13208_12_09.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_09.png)'
- en: As we can see in the preceding figure, some of those images are even challenging
    for us humans to classify correctly. For example, the 6 in subplot `8` really
    looks like a carelessly drawn 0, and the 8 in subplot `23` could be a 9 due to
    the narrow lower part combined with the bold line.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的图中看到的那样，其中一些图像甚至对于我们人类来说也很难正确分类。例如，子图`8`中的6看起来像是一个随意画的0，而子图`23`中的8可能会因为下部狭窄并且有粗线条而被误判为9。
- en: Training an artificial neural network
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练人工神经网络
- en: Now that we have seen an NN in action and have gained a basic understanding
    of how it works by looking over the code, let's dig a little bit deeper into some
    of the concepts, such as the logistic cost function and the backpropagation algorithm
    that we implemented to learn the weights.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到一个神经网络（NN）的实际应用，并通过查看代码对其工作原理有了基本了解，让我们进一步探讨一些概念，比如逻辑成本函数和我们实现的反向传播算法，用于学习权重。
- en: Computing the logistic cost function
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算逻辑成本函数
- en: 'The logistic cost function that we implemented as the `_compute_cost` method
    is actually pretty simple to follow since it is the same cost function that we
    described in the logistic regression section in *Chapter 3*, *A Tour of Machine
    Learning Classifiers Using scikit-learn*:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现的作为`_compute_cost`方法的逻辑成本函数实际上很简单，因为它与我们在*第3章*“使用scikit-learn的机器学习分类器之旅”中描述的逻辑回归部分的成本函数相同：
- en: '![](img/B13208_12_066.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_066.png)'
- en: 'Here, ![](img/B13208_12_067.png) is the sigmoid activation of the *i*th sample
    in the dataset, which we compute in the forward propagation step:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B13208_12_067.png)是数据集中第*i*个样本的Sigmoid激活值，这是我们在前向传播步骤中计算的：
- en: '![](img/B13208_12_068.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_068.png)'
- en: Again, note that in this context, the superscript [*i*] is an index for training
    examples, not layers.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，在这个上下文中，上标[*i*]是训练示例的索引，而不是层的索引。
- en: 'Now, let''s add a regularization term, which allows us to reduce the degree
    of overfitting. As you recall from earlier chapters, the L2 regularization term
    is defined as follows (remember that we don''t regularize the bias units):'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加一个正则化项，这样可以帮助我们减少过拟合的程度。如你从前面的章节中回忆的那样，L2正则化项定义如下（请记住，我们不对偏置单元进行正则化）：
- en: '![](img/B13208_12_069.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_069.png)'
- en: 'By adding the L2 regularization term to our logistic cost function, we obtain
    the following equation:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将L2正则化项添加到我们的逻辑成本函数中，我们得到以下方程：
- en: '![](img/B13208_12_070.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_070.png)'
- en: 'Previously, we implemented an MLP for multiclass classification that returns
    an output vector of *t* elements that we need to compare to the ![](img/B13208_12_071.png)
    dimensional target vector in the one-hot encoding representation. If we predict
    the class label of an input image with class label 2, using this MLP, the activation
    of the third layer and the target may look like this:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们实现了一个用于多类分类的多层感知机（MLP），它返回一个包含*t*个元素的输出向量，我们需要将其与在独热编码表示中的![](img/B13208_12_071.png)维目标向量进行比较。如果我们使用这个MLP预测一个标签为2的输入图像的类别标签，那么第三层的激活值和目标可能如下所示：
- en: '![](img/B13208_12_072.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_072.png)'
- en: Thus, we need to generalize the logistic cost function to all *t* activation
    units in our network.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要将逻辑成本函数推广到我们网络中的所有*t*个激活单元。
- en: 'The cost function (without the regularization term) becomes the following:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 没有正则化项的成本函数变为如下：
- en: '![](img/B13208_12_073.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_073.png)'
- en: Here, again, the superscript [*i*] is the index of a particular sample in our
    training dataset.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，再次强调，上标[*i*]是我们训练数据集中某个特定样本的索引。
- en: 'The following generalized regularization term may look a little bit complicated
    at first, but here we are just calculating the sum of all weights of an *l* layer
    (without the bias term) that we added to the first column:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的广义正则化项一开始可能看起来有些复杂，但这里我们只是计算第*l*层所有权重的和（不包括偏置项），并将其添加到第一列：
- en: '![](img/B13208_12_074.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_074.png)'
- en: 'Here, ![](img/B13208_12_075.png) refers to the number of units in a given layer
    *l*, and the following expression represents the penalty term:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B13208_12_075.png)表示给定层*l*中的单元数量，以下表达式表示惩罚项：
- en: '![](img/B13208_12_076.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_076.png)'
- en: 'Remember that our goal is to minimize the cost function *J*(*W*); thus, we
    need to calculate the partial derivative of the parameters *W* with respect to
    each weight for every layer in the network:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们的目标是最小化成本函数*J*(*W*)；因此，我们需要计算每一层网络中参数*W*相对于每个权重的偏导数：
- en: '![](img/B13208_12_077.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_077.png)'
- en: In the next section, we will talk about the backpropagation algorithm, which
    allows us to calculate those partial derivatives to minimize the cost function.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将讨论反向传播算法，该算法允许我们计算这些偏导数以最小化成本函数。
- en: 'Note that *W* consists of multiple matrices. In an MLP with one hidden layer,
    we have the weight matrix, ![](img/B13208_12_078.png), which connects the input
    to the hidden layer, and ![](img/B13208_12_079.png), which connects the hidden
    layer to the output layer. A visualization of the three-dimensional tensor *W*
    is provided in the following figure:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，*W*由多个矩阵组成。在具有一个隐藏层的MLP中，我们有连接输入到隐藏层的权重矩阵![](img/B13208_12_078.png)，以及连接隐藏层到输出层的权重矩阵![](img/B13208_12_079.png)。三维张量*W*的可视化如下图所示：
- en: '![](img/B13208_12_10.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_10.png)'
- en: In this simplified figure, it may seem that both ![](img/B13208_12_080.png)
    and ![](img/B13208_12_081.png) have the same number of rows and columns, which
    is typically not the case unless we initialize an MLP with the same number of
    hidden units, output units, and input features.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简化的图中，似乎![](img/B13208_12_080.png)和![](img/B13208_12_081.png)的行数和列数相同，但通常情况下并非如此，除非我们初始化一个具有相同隐藏单元数、输出单元数和输入特征的MLP。
- en: If this sounds confusing, stay tuned for the next section, where we will discuss
    the dimensionality of ![](img/B13208_12_082.png) and ![](img/B13208_12_083.png)
    in more detail in the context of the backpropagation algorithm. Also, you are
    encouraged to read through the code of the `NeuralNetMLP` again, which is annotated
    with helpful comments about the dimensionality of the different matrices and vector
    transformations. You can obtain the annotated code either from Packt or the book's
    GitHub repository at [https://github.com/rasbt/python-machine-learning-book-3rd-edition](https://github.com/rasbt/python-machine-learning-book-3rd-edition).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这听起来令人困惑，请继续关注下一部分，我们将在反向传播算法的背景下更详细地讨论![](img/B13208_12_082.png)和![](img/B13208_12_083.png)的维度问题。此外，建议您再次阅读带有关于不同矩阵和向量转换维度的有用注释的`NeuralNetMLP`代码。您可以从Packt或该书的GitHub仓库获取带有注释的代码，网址为[https://github.com/rasbt/python-machine-learning-book-3rd-edition](https://github.com/rasbt/python-machine-learning-book-3rd-edition)。
- en: Developing your understanding of backpropagation
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发展您对反向传播的理解
- en: 'Although backpropagation was rediscovered and popularized more than 30 years
    ago (*Learning representations by back-propagating errors*, *D. E. Rumelhart*,
    *G. E. Hinton*, and *R. J. Williams*, *Nature*, 323: 6088, pages 533–536, *1986*),
    it still remains one of the most widely used algorithms to train artificial NNs
    very efficiently. If you are interested in additional references regarding the
    history of backpropagation, Juergen Schmidhuber wrote a nice survey article, *Who
    Invented Backpropagation?*, which you can find online at [http://people.idsia.ch/~juergen/who-invented-backpropagation.html](http://people.idsia.ch/~juergen/who-invented-backpropagation.html).'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管反向传播在30多年前重新发现和广为流传（*通过反向传播误差学习表示*，*D.E. Rumelhart*，*G.E. Hinton*和*R.J. Williams*，*Nature*，323：6088，页533-536，*1986年*），但它仍然是训练人工神经网络非常高效的最广泛使用的算法之一。如果您对反向传播的历史有兴趣，可以阅读Juergen
    Schmidhuber撰写的一篇很好的调查文章，*Who Invented Backpropagation?*，您可以在[http://people.idsia.ch/~juergen/who-invented-backpropagation.html](http://people.idsia.ch/~juergen/who-invented-backpropagation.html)找到该文章。
- en: This section will provide both a short, clear summary and the bigger picture
    of how this fascinating algorithm works before we dive into more mathematical
    details. In essence, we can think of backpropagation as a very computationally
    efficient approach to compute the partial derivatives of a complex cost function
    in multilayer NNs. Here, our goal is to use those derivatives to learn the weight
    coefficients for parameterizing such a multilayer artificial NN. The challenge
    in the parameterization of NNs. is that we are typically dealing with a very large
    number of weight coefficients in a high-dimensional feature space. In contrast
    to cost functions of single-layer NNs such as Adaline or logistic regression,
    which we have seen in previous chapters, the error surface of an NN cost function
    is not convex or smooth with respect to the parameters. There are many bumps in
    this high-dimensional cost surface (local minima) that we have to overcome in
    order to find the global minimum of the cost function.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将提供一个简短而清晰的总结，并展示这个迷人算法的全貌，然后再深入探讨更多的数学细节。本质上，我们可以将反向传播看作是一种计算多层神经网络（NN）中复杂成本函数的偏导数的高效方法。我们的目标是利用这些导数来学习权重系数，从而为多层人工神经网络（NN）进行参数化。神经网络参数化的挑战在于，我们通常需要处理在高维特征空间中非常大量的权重系数。与我们在前几章中看到的单层神经网络（如
    Adaline 或逻辑回归）的成本函数不同，神经网络成本函数的误差面对于参数而言既不凸也不光滑。在这个高维成本面上有许多波动（局部最小值），我们必须克服这些波动，才能找到成本函数的全局最小值。
- en: 'You may recall the concept of the chain rule from your introductory calculus
    classes. The chain rule is an approach to compute the derivative of a complex,
    nested function, such as *f*( *g*(*x*)), as follows:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得在初级微积分课程中学过链式法则的概念。链式法则是一种计算复杂嵌套函数（如 *f*(*g*(*x*））的导数的方法，具体如下：
- en: '![](img/B13208_12_084.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_084.png)'
- en: 'Similarly, we can use the chain rule for an arbitrarily long function composition.
    For example, let''s assume that we have five different functions, *f*(*x*), *g*(*x*),
    *h*(*x*), *u*(*x*), and *v*(*x*), and let *F* be the function composition: *F*(*x*)
    = *f*(*g*(*h*(*u*(*v*(*x*))))). Applying the chain rule, we can compute the derivative
    of this function as follows:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们也可以对任意长的函数组合使用链式法则。例如，假设我们有五个不同的函数，*f*(*x*), *g*(*x*), *h*(*x*), *u*(*x*),
    和 *v*(*x*)，并且令 *F* 为这些函数的组合：*F*(*x*) = *f*(*g*(*h*(*u*(*v*(*x*))))）。应用链式法则，我们可以如下计算该函数的导数：
- en: '![](img/B13208_12_085.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_085.png)'
- en: In the context of computer algebra, a set of techniques has been developed to
    solve such problems very efficiently, which is also known as **automatic differentiation**.
    If you are interested in learning more about automatic differentiation in machine
    learning applications, read A. G. Baydin and B. A. Pearlmutter's article *Automatic
    Differentiation of Algorithms for Machine Learning*, arXiv preprint arXiv:1404.7456,
    *2014*, which is freely available on arXiv at [http://arxiv.org/pdf/1404.7456.pdf](http://arxiv.org/pdf/1404.7456.pdf).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机代数的背景下，已经开发出一套技术来非常高效地解决此类问题，这也被称为**自动微分**。如果你有兴趣了解更多关于机器学习中自动微分的应用，可以阅读A.
    G. Baydin 和 B. A. Pearlmutter的文章《自动微分算法在机器学习中的应用》（*Automatic Differentiation of
    Algorithms for Machine Learning*），该文章已在 arXiv 上免费提供，预印本为 arXiv:1404.7456，发布时间为
    *2014*，链接为 [http://arxiv.org/pdf/1404.7456.pdf](http://arxiv.org/pdf/1404.7456.pdf)。
- en: Automatic differentiation comes with two modes, the forward and reverse modes;
    backpropagation is simply a special case of reverse-mode automatic differentiation.
    The key point is that applying the chain rule in the forward mode could be quite
    expensive since we would have to multiply large matrices for each layer (Jacobians)
    that we would eventually multiply by a vector to obtain the output.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 自动微分有两种模式：前向模式和反向模式；反向传播实际上是反向模式自动微分的一个特例。关键点在于，在前向模式下应用链式法则可能非常昂贵，因为我们需要对每一层（雅可比矩阵）进行大矩阵相乘，最后再与一个向量相乘以获得输出。
- en: 'The trick of reverse mode is that we start from right to left: we multiply
    a matrix by a vector, which yields another vector that is multiplied by the next
    matrix and so on. Matrix-vector multiplication is computationally much cheaper
    than matrix-matrix multiplication, which is why backpropagation is one of the
    most popular algorithms used in NN training.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 反向模式的技巧在于我们从右到左开始：我们将一个矩阵与一个向量相乘，得到另一个向量，再与下一个矩阵相乘，以此类推。矩阵与向量相乘在计算上比矩阵与矩阵相乘便宜得多，这也是为什么反向传播是神经网络训练中最流行的算法之一。
- en: '**A basic calculus refresher**'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '**基础微积分回顾**'
- en: To fully understand backpropagation, we need to borrow certain concepts from
    differential calculus, which is outside the scope of this book. However, you can
    refer to a review chapter of the most fundamental concepts, which you might find
    useful in this context. It discusses function derivatives, partial derivatives,
    gradients, and the Jacobian. This text is freely accessible at [https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf](https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf).
    If you are unfamiliar with calculus or need a brief refresher, consider reading
    this text as an additional supporting resource before reading the next section.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完全理解反向传播，我们需要借用一些微积分的概念，这些内容超出了本书的范围。然而，你可以参考本书的附录部分，它涵盖了最基本的微积分概念，可能在本节中会对你有所帮助。该部分讨论了函数的导数、偏导数、梯度和雅可比矩阵。这篇文章可以在
    [https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf](https://sebastianraschka.com/pdf/books/dlb/appendix_d_calculus.pdf)
    上免费获取。如果你不熟悉微积分或需要简要的复习，建议在阅读下一节之前先阅读这篇文章，作为补充资源。
- en: Training neural networks via backpropagation
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过反向传播训练神经网络
- en: In this section, we will go through the math of backpropagation to understand
    how you can learn the weights in an NN very efficiently. Depending on how comfortable
    you are with mathematical representations, the following equations may seem relatively
    complicated at first.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将详细讲解反向传播的数学原理，以帮助你理解如何高效地学习神经网络中的权重。根据你对数学表示的熟悉程度，以下公式可能一开始看起来相对复杂。
- en: 'In a previous section, we saw how to calculate the cost as the difference between
    the activation of the last layer and the target class label. Now, we will see
    how the backpropagation algorithm works to update the weights in our MLP model
    from a mathematical perspective, which we implemented after the `# Backpropagation`
    code comment inside the `fit` method. As we recall from the beginning of this
    chapter, we first need to apply forward propagation in order to obtain the activation
    of the output layer, which we formulated as follows:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，我们看到如何计算代价函数，它是最后一层激活值与目标类标签之间的差异。现在，我们将从数学角度来看反向传播算法是如何工作的，来更新我们 MLP
    模型中的权重，我们在 `fit` 方法中的 `# Backpropagation` 代码注释后实现了这一过程。正如我们从本章开头回忆的那样，我们首先需要应用前向传播，以便获得输出层的激活值，我们将其表示如下：
- en: '![](img/B13208_12_086.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_086.png)'
- en: 'Concisely, we just forward-propagate the input features through the connection
    in the network, as shown in the following illustration:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我们通过网络中的连接将输入特征前向传播，具体如以下示意图所示：
- en: '![](img/B13208_12_11.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_11.png)'
- en: 'In backpropagation, we propagate the error from right to left. We start by
    calculating the error vector of the output layer:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在反向传播中，我们从右向左传播误差。我们首先计算输出层的误差向量：
- en: '![](img/B13208_12_087.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_087.png)'
- en: Here, *y* is the vector of the true class labels (the corresponding variable
    in the `NeuralNetMLP` code is `delta_out`).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*y* 是真实类标签的向量（在 `NeuralNetMLP` 代码中对应的变量是 `delta_out`）。
- en: 'Next, we calculate the error term of the hidden layer:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们计算隐藏层的误差项：
- en: '![](img/B13208_12_088.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_088.png)'
- en: 'Here, ![](img/B13208_12_089.png) is simply the derivative of the sigmoid activation
    function, which we computed as `sigmoid_derivative_h = a_h * (1\. - a_h)` in the
    `fit` method of the `NeuralNetMLP`:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/B13208_12_089.png) 只是 sigmoid 激活函数的导数，我们在 `NeuralNetMLP` 的 `fit`
    方法中计算为 `sigmoid_derivative_h = a_h * (1. - a_h)`：
- en: '![](img/B13208_12_090.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_090.png)'
- en: Note that the ![](img/B13208_12_091.png) symbol means element-wise multiplication
    in this context.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，![](img/B13208_12_091.png) 符号在此处表示按元素相乘。
- en: '**Activation function derivative**'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '**激活函数的导数**'
- en: 'Although it is not important to follow the next equations, you may be curious
    how the derivative of the activation function was obtained; it is summarized step
    by step here:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然接下来的公式并不是必须完全跟随的，但你可能会好奇激活函数的导数是如何得到的；它在这里进行了逐步总结：
- en: '![](img/B13208_12_092.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_092.png)'
- en: 'Next, we compute the ![](img/B13208_12_093.png) layer error matrix (`delta_h`)
    as follows:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们计算 ![](img/B13208_12_093.png) 层的误差矩阵（`delta_h`），计算公式如下：
- en: '![](img/B13208_12_094.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_094.png)'
- en: To better understand how we computed this ![](img/B13208_12_095.png) term, let's
    walk through it in more detail. In the preceding equation, we used the transpose
    ![](img/B13208_12_096.png) of the ![](img/B13208_12_097.png)-dimensional matrix
    ![](img/B13208_12_098.png). Here, *t* is the number of output class labels and
    *h* is the number of hidden units. The matrix multiplication between the ![](img/B13208_12_099.png)-dimensional
    ![](img/B13208_12_100.png) matrix and the ![](img/B13208_12_101.png)-dimensional
    matrix ![](img/B13208_12_102.png) results in an ![](img/B13208_12_103.png)-dimensional
    matrix that we multiplied element-wise by the sigmoid derivative of the same dimension
    to obtain the ![](img/B13208_12_104.png)-dimensional matrix ![](img/B13208_12_105.png).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解我们是如何计算这个![](img/B13208_12_095.png)项的，让我们更详细地讲解一下。在之前的方程中，我们使用了![](img/B13208_12_096.png)的转置，即![](img/B13208_12_097.png)维度的矩阵![](img/B13208_12_098.png)。这里，*t*是输出类标签的数量，*h*是隐藏单元的数量。![](img/B13208_12_099.png)维度的![](img/B13208_12_100.png)矩阵与![](img/B13208_12_101.png)维度的矩阵![](img/B13208_12_102.png)相乘，得到一个![](img/B13208_12_103.png)维度的矩阵，然后我们将该矩阵与同维度的sigmoid导数逐元素相乘，得到了![](img/B13208_12_104.png)维度的矩阵![](img/B13208_12_105.png)。
- en: 'Eventually, after obtaining the ![](img/B13208_12_106.png) terms, we can now
    write the derivation of the cost function as follows:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，在获得![](img/B13208_12_106.png)项后，我们现在可以将成本函数的推导写成如下：
- en: '![](img/B13208_12_107.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_107.png)'
- en: 'Next, we need to accumulate the partial derivative of every node in each layer
    and the error of the node in the next layer. However, remember that we need to
    compute ![](img/B13208_12_108.png) for every sample in the training dataset. Thus,
    it is easier to implement it as a vectorized version like in our `NeuralNetMLP`
    code implementation:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要累积每一层每个节点的偏导数和下一层节点的误差。不过，请记住，我们需要为训练数据集中的每个样本计算![](img/B13208_12_108.png)。因此，将其实现为矢量化版本，就像在我们的`NeuralNetMLP`代码实现中一样，会更容易一些：
- en: '![](img/B13208_12_109.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_109.png)'
- en: 'And after we have accumulated the partial derivatives, we can add the following
    regularization term:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在累积偏导数后，我们可以添加以下正则化项：
- en: '![](img/B13208_12_110.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_110.png)'
- en: (Please note that the bias units are usually not regularized.)
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: （请注意，偏置单元通常不进行正则化。）
- en: The two previous mathematical equations correspond to the code variables `delta_w_h`,
    `delta_b_h`, `delta_w_out`, and `delta_b_out` in `NeuralNetMLP`.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 前面两个数学方程对应于`NeuralNetMLP`中的代码变量`delta_w_h`、`delta_b_h`、`delta_w_out`和`delta_b_out`。
- en: 'Lastly, after we have computed the gradients, we can update the weights by
    taking an opposite step toward the gradient for each layer *l*:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在计算完梯度后，我们可以通过朝着每一层*l*的梯度方向迈出一个相反的步伐来更新权重：
- en: '![](img/B13208_12_111.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_111.png)'
- en: 'This is implemented as follows:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 它的实现如下：
- en: '[PRE24]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'To bring everything together, let''s summarize backpropagation in the following
    figure:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将所有内容结合起来，让我们在下图中总结反向传播：
- en: '![](img/B13208_12_12.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_12.png)'
- en: About the convergence in neural networks
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于神经网络的收敛性
- en: You might be wondering why we did not use regular gradient descent but instead
    used mini-batch learning to train our NN for the handwritten digit classification.
    You may recall our discussion on SGD that we used to implement online learning.
    In online learning, we compute the gradient based on a single training example
    (*k* = 1) at a time to perform the weight update. Although this is a stochastic
    approach, it often leads to very accurate solutions with a much faster convergence
    than regular gradient descent. Mini-batch learning is a special form of SGD where
    we compute the gradient based on a subset *k* of the *n* training examples with
    1 < *k* < *n*. Mini-batch learning has the advantage over online learning that
    we can make use of our vectorized implementations to improve computational efficiency.
    However, we can update the weights much faster than in regular gradient descent.
    Intuitively, you can think of mini-batch learning as predicting the voter turnout
    of a presidential election from a poll by asking only a representative subset
    of the population rather than asking the entire population (which would be equal
    to running the actual election).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，为什么我们没有使用常规的梯度下降法，而是使用小批量学习来训练我们用于手写数字分类的神经网络。你可能还记得我们在讨论 SGD 时提到过在线学习。在在线学习中，我们每次基于一个训练样本（*k*
    = 1）来计算梯度并执行权重更新。尽管这是一种随机方法，但它通常能比常规的梯度下降法更快收敛，并且能够得到非常准确的解决方案。小批量学习是 SGD 的一种特殊形式，其中我们基于
    *n* 个训练样本中的一个子集 *k*（1 < *k* < *n*）来计算梯度。与在线学习相比，小批量学习的优势在于我们可以利用向量化实现来提高计算效率。然而，我们的权重更新速度要比常规的梯度下降法快得多。直观地讲，你可以将小批量学习看作是通过对一部分具有代表性的选民群体进行调查，而不是对整个选民群体进行投票调查，来预测总统选举的选民投票率（这相当于进行实际的选举）。
- en: 'Multilayer NNs are much harder to train than simpler algorithms such as Adaline,
    logistic regression, or support vector machines. In multilayer NNs, we typically
    have hundreds, thousands, or even billions of weights that we need to optimize.
    Unfortunately, the output function has a rough surface and the optimization algorithm
    can easily become trapped in local minima, as shown in the following figure:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 多层神经网络（NN）比简单的算法如 Adaline、逻辑回归或支持向量机更难训练。在多层神经网络中，我们通常需要优化数百、数千甚至数十亿个权重。不幸的是，输出函数具有粗糙的表面，优化算法很容易陷入局部最小值，正如下图所示：
- en: '![](img/B13208_12_13.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B13208_12_13.png)'
- en: Note that this representation is extremely simplified since our NN has many
    dimensions; it makes it impossible to visualize the actual cost surface for the
    human eye. Here, we only show the cost surface for a single weight on the *x*-axis.
    However, the main message is that we do not want our algorithm to get trapped
    in local minima. By increasing the learning rate, we can more readily escape such
    local minima. On the other hand, we also increase the chance of overshooting the
    global optimum if the learning rate is too large. Since we initialize the weights
    randomly, we start with a solution to the optimization problem that is typically
    hopelessly wrong.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个表示方式是极其简化的，因为我们的神经网络具有许多维度，这使得人眼无法可视化实际的代价表面。在这里，我们仅展示了一个权重在 *x* 轴上的代价表面。然而，主要的信息是我们不希望我们的算法陷入局部最小值。通过增加学习率，我们可以更容易地跳出这些局部最小值。另一方面，如果学习率过大，我们也会增加越过全局最优解的机会。由于我们是随机初始化权重的，所以我们从一个通常完全错误的优化问题解开始。
- en: A few last words about the neural network implementation
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于神经网络实现的最后几点
- en: You may be wondering why we went through all of this theory just to implement
    a simple multilayer artificial network that can classify handwritten digits instead
    of using an open source Python machine learning library. In fact, we will introduce
    more complex NN models in the next chapters, which we will train using the open
    source TensorFlow library ([https://www.tensorflow.org](https://www.tensorflow.org)).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，为什么我们要通过这些理论来实现一个简单的多层人工神经网络，它可以对手写数字进行分类，而不使用开源的 Python 机器学习库。实际上，在接下来的章节中，我们将介绍更复杂的神经网络模型，并使用开源的
    TensorFlow 库进行训练（[https://www.tensorflow.org](https://www.tensorflow.org)）。
- en: Although the from-scratch implementation in this chapter seems a bit tedious
    at first, it was a good exercise for understanding the basics behind backpropagation
    and NN training, and a basic understanding of algorithms is crucial for applying
    machine learning techniques appropriately and successfully.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本章中从零实现的过程一开始看起来有些繁琐，但它是理解反向传播和神经网络训练基本原理的一个好练习，而对算法的基本理解对于恰当地和成功地应用机器学习技术至关重要。
- en: Now that you have learned how feedforward NNs work, we are ready to explore
    more sophisticated DNNs by using TensorFlow, which allows us to construct NNs
    more efficiently, as we will see in *Chapter 13*, *Parallelizing Neural Network
    Training with TensorFlow*.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了前馈神经网络的工作原理，我们准备使用TensorFlow探索更复杂的DNN，它能让我们更高效地构建神经网络，正如我们将在*第13章*《使用TensorFlow并行训练神经网络》中看到的那样。
- en: Over the past two years, since its release in November 2015, TensorFlow has
    gained a lot of popularity among machine learning researchers, who use it to construct
    DNNs because of its ability to optimize mathematical expressions for computations
    on multidimensional arrays utilizing **graphics processing units** (**GPUs**).
    While TensorFlow can be considered a low-level deep learning library, simplifying
    APIs such as Keras have been developed that make the construction of common deep
    learning models even more convenient, which we will see in *Chapter 13*, *Parallelizing
    Neural Network Training with TensorFlow*.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的两年里，自2015年11月发布以来，TensorFlow在机器学习研究人员中获得了广泛的关注，他们使用它来构建DNN，因为它能够优化多维数组上使用**图形处理单元**（**GPU**）进行计算的数学表达式。虽然TensorFlow可以被认为是一个低级深度学习库，但已经开发出了像Keras这样的简化API，使得构建常见的深度学习模型更加便捷，正如我们在*第13章*《使用TensorFlow并行训练神经网络》中将看到的那样。
- en: Summary
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you have learned the basic concepts behind multilayer artificial
    NNs, which are currently the hottest topic in machine learning research. In *Chapter
    2*, *Training Simple Machine Learning Algorithms for Classification*, we started
    our journey with simple single-layer NN structures and now we have connected multiple
    neurons to a powerful NN architecture to solve complex problems such as handwritten
    digit recognition. We demystified the popular backpropagation algorithm, which
    is one of the building blocks of many NN models that are used in deep learning.
    After learning about the backpropagation algorithm in this chapter, we are well
    equipped for exploring more complex DNN architectures. In the remaining chapters,
    we will cover TensorFlow, an open source library geared toward deep learning,
    which allows us to implement and train multilayer NNs more efficiently.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了多层人工神经网络的基本概念，这是目前机器学习研究中最热门的话题。在*第2章*《训练简单的机器学习算法进行分类》中，我们从简单的单层神经网络结构开始，而现在我们已经将多个神经元连接成一个强大的神经网络架构，用来解决如手写数字识别等复杂问题。我们解开了流行的反向传播算法的神秘面纱，反向传播是许多深度学习神经网络模型的构建基石。通过学习本章的反向传播算法，我们已经为探索更复杂的DNN架构做好了准备。在接下来的章节中，我们将介绍TensorFlow，一个面向深度学习的开源库，它能让我们更高效地实现和训练多层神经网络。
