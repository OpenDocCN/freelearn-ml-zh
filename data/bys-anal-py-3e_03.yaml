- en: Chapter 4
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章
- en: Modeling with Lines
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线性模型
- en: 'In more than three centuries of science everything has changed except perhaps
    one thing: the love for the simple. – Jorge Wagensberg'
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在三百多年的科学历史中，唯一没有改变的或许只有一点：对简单的热爱。– 乔治·瓦根斯贝格
- en: Music—from classical compositions to *Sheena is a Punk Rocker* by The Ramones,
    passing through unrecognized hits from garage bands and Piazzolla’s Libertango—is
    made of recurring patterns. The same scales, combinations of chords, riffs, motifs,
    and so on appear over and over again, giving rise to a wonderful sonic landscape
    capable of eliciting and modulating the entire range of emotions that humans can
    experience. Similarly, the universe of statistics is built upon recurring patterns,
    small motifs that appear now and again. In this chapter, we are going to look
    at one of the most popular and useful of them, the **linear** **model** (or motif,
    if you want). This is a very useful model on its own and also the building block
    of many other models. If you’ve ever taken a statistics course, you may have heard
    of simple and multiple linear regression, logistic regression, ANOVA, ANCOVA,
    and so on. All these methods are variations of the same underlying motif, the
    linear regression model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 音乐——从古典作品到The Ramones的*Sheena is a Punk Rocker*，再到车库乐队的未被认可的热门歌曲以及皮亚佐拉的《自由探戈》——由重复出现的模式构成。相同的音阶、和弦组合、吉他即兴、旋律等反复出现，创造出一个美妙的音景，能够激发并调节人类可能体验到的所有情感。同样，统计学的世界也是建立在不断出现的模式上的，这些小的动机时不时地出现。在本章中，我们将关注其中一个最流行和有用的模式，即**线性**
    **模型**（或者如果你愿意，可以叫做动机）。这是一个非常有用的模型，独立使用时效果显著，同时也是许多其他模型的基础。如果你曾经学过统计学课程，你可能听说过简单和多元线性回归、逻辑回归、方差分析（ANOVA）、协方差分析（ANCOVA）等方法。所有这些方法都是同一个基本模式——线性回归模型——的不同变体。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涉及以下主题：
- en: Simple linear regression
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单线性回归
- en: NegativeBinomial regression
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负二项回归
- en: Robust regression
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稳健回归
- en: Logistic regression
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Variable variance
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量的方差
- en: Hierarchical linear regression
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层次线性回归
- en: Multiple linear regression
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多元线性回归
- en: 4.1 Simple linear regression
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 简单线性回归
- en: Many problems we find in science, engineering, and business are of the following
    form. We have a variable *X* and we want to model or predict a variable *Y* .
    Importantly, these variables are paired like {(*x*[1]*,y*[1])*,*(*x*[2]*,y*[2])*,*![⋅⋅⋅](img/file96.jpg)*,*(*x*[*n*]*,y*[*n*])}.
    In the most simple scenario, known as simple linear regression, both *X* and *Y*
    are uni-dimensional continuous random variables. By continuous, we mean a variable
    represented using real numbers. Using NumPy, you will represent these variables
    as one-dimensional arrays of floats. Usually, people call *Y* the dependent, predicted,
    or outcome variable, and *X* the independent, predictor, or input variable.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在科学、工程和商业中遇到的许多问题都具有以下形式：我们有一个变量*X*，我们想要建模或预测一个变量*Y*。重要的是，这些变量是成对的，如{(*x*[1]*,y*[1])*,*(*x*[2]*,y*[2])*,*![⋅⋅⋅](img/file96.jpg)*,*(*x*[*n*]*,y*[*n*])}。在最简单的情况下，即简单线性回归中，*X*和*Y*都是一维连续随机变量。所谓连续，意味着该变量用实数表示。使用NumPy，你将把这些变量表示为一维浮点数组。通常，人们称*Y*为因变量、预测变量或结果变量，*X*为自变量、预测因子或输入变量。
- en: 'Some typical situations where linear regression models can be used are the
    following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一些典型的线性回归模型应用场景如下：
- en: 'Model the relationship between soil salinity and crop productivity. Then, answer
    questions such as: is the relationship linear? How strong is this relationship?'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模拟土壤盐分与作物生产力之间的关系。然后，回答一些问题，比如：这种关系是线性的吗？这种关系有多强？
- en: Find a relationship between average chocolate consumption by country and the
    number of Nobel laureates in that country, and then understand why this relationship
    could be spurious.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找出各国平均巧克力消费量与该国诺贝尔奖得主数量之间的关系，并理解为何这种关系可能是虚假的。
- en: Predict the gas bill (used for heating and cooking) of your house by using the
    solar radiation from the local weather report. How accurate is this prediction?
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用本地天气报告中的太阳辐射，预测你家的燃气账单（用于取暖和烹饪）。这个预测有多准确？
- en: 'In *Chapter [2](CH02.xhtml#x1-440002)*, we saw the Normal model, which we define
    as:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第[2章](CH02.xhtml#x1-440002)*中，我们看到了正态模型，我们定义它为：
- en: '![ μ ∼ some prior σ ∼ some other prior Y ∼ 𝒩 (μ,σ) ](img/file97.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![ μ ∼ 某个先验 σ ∼ 另一个先验 Y ∼ 𝒩 (μ,σ) ](img/file97.jpg)'
- en: 'The main idea of linear regression is to extend this model by adding a predictor
    variable *X* to the estimation of the mean *μ*:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归的主要思想是通过添加一个预测变量*X*来扩展此模型，以估计均值*μ*：
- en: '![ 𝛼 ∼ a prior 𝛽 ∼ another prior σ ∼ some other prior μ = 𝛼 + 𝛽X Y ∼ 𝒩 (μ,σ)
    ](img/file98.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![ 𝛼 ∼ 一个先验 𝛽 ∼ 另一个先验 σ ∼ 其他先验 μ = 𝛼 + 𝛽X Y ∼ 𝒩 (μ,σ) ](img/file98.jpg)'
- en: This model says that there is a linear relation between the variable *X* and
    the variable *Y* . But that relationship is not deterministic, because of the
    noise term *σ*. Additionally, the model says that the mean of *Y* is a linear
    function of *X*, with **intercept** *α* and **slope** *β*. The intercept tells
    us the value of *Y* when *X* = 0 and the slope tells us the change in *Y* per
    unit change in *X*. Because we don’t know the values of *α*, *β*, or *σ* we set
    priors distribution over them.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型表示变量 *X* 与变量 *Y* 之间存在线性关系。但由于噪声项 *σ* 的存在，这种关系并不是确定性的。此外，该模型表示 *Y* 的均值是 *X*
    的线性函数，具有**截距** *α* 和**斜率** *β*。截距告诉我们当 *X* = 0 时 *Y* 的值，斜率则告诉我们 *X* 每变化一个单位，*Y*
    会发生多少变化。由于我们不知道 *α*、*β* 或 *σ* 的具体值，因此我们为它们设定了先验分布。
- en: When setting priors for linear models we typically assume that they are independent.
    This assumption greatly simplifies setting priors because we then need to set
    three priors instead of one joint prior. At least in principle, *α* and *β* can
    take any value on the real line, thus it is common to use Normal priors for them.
    And because *σ* is a positive number, it is common to use a HalfNormal or Exponential
    prior for it.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在为线性模型设定先验时，我们通常假设它们是独立的。这个假设极大简化了先验设置，因为这样我们只需要设置三个先验，而不是一个联合先验。至少原则上，*α* 和
    *β* 可以取实数线上的任何值，因此通常使用正态分布作为它们的先验。而因为 *σ* 是一个正数，通常为其使用半正态分布或指数分布作为先验。
- en: The values the intercept can take can vary a lot from one problem to another
    and for different domain knowledge. For many problems I have worked on, *α* is
    usually centered around 0 and with a standard deviation no larger than 1, but
    this is just my experience (almost anecdotal) with a small subset of problems
    and not something easy to transfer to other problems. Usually, it may be easier
    to have an informed guess for the slope (*β*). For instance, we may know the sign
    of the slope a priori; for example, we expect the variable weight to increase,
    on average, with the variable height. For *σ*, we can set it to a large value
    on the scale of the variable *Y* , for example, two times the value for its standard
    deviation. We should be careful of using the observed data to guesstimate priors;
    usually, it is fine if the data is used to avoid using very restrictive priors.
    If we don’t have too much knowledge of the parameter, it makes sense to ensure
    our prior is vague. If we instead want more informative priors, then we should
    not get that information from the observed data; instead, we should get it from
    our domain knowledge.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 截距的值可以根据不同的问题和领域知识有很大的变化。对于我曾处理过的许多问题，*α* 通常围绕 0 中心，且标准差不超过 1，但这只是我在一小部分问题上的经验（几乎是轶事性质的），并不是可以轻易迁移到其他问题的经验。通常，预测斜率（*β*）的先验值可能更为容易。例如，我们可能知道斜率的符号：例如，我们期望变量体重与身高变量平均呈正相关。对于
    *σ*，我们可以将其设置为与变量 *Y* 的值同量级的大值，例如是其标准差的两倍。我们应该小心不要使用观察数据来推测先验；通常，数据用来避免使用过于严格的先验是可以接受的。如果我们对参数知之甚少，那么确保我们的先验具有模糊性是合乎逻辑的。如果我们希望使用更具信息量的先验，那么不应从观察数据中获取这些信息，而应从我们的领域知识中获得。
- en: Extending the Normal Model
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展常规模型
- en: A linear regression model is an extension of the Normal model where the mean
    is computed as a linear function of a predictor variable.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型是常规模型的扩展，其中均值是作为预测变量的线性函数计算的。
- en: 4.2 Linear bikes
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 线性单车模型
- en: We now have a general idea of what Bayesian linear models look like. Let’s try
    to cement that idea with an example. We are going to start very simply; we have
    a record of temperatures and the number of bikes rented in a city. We want to
    model the relationship between the temperature and the number of bikes rented.
    *Figure [4.1](#x1-78002r1)* shows a scatter plot of these two variables from the
    bike-sharing dataset from the UCI Machine Learning Repository ( [https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在对贝叶斯线性模型有了一个大致的了解。让我们通过一个例子来巩固这个概念。我们将从一个非常简单的例子开始：我们有一座城市的温度记录和租赁自行车的数量。我们想要建立温度和租赁自行车数量之间的关系模型。*图
    [4.1](#x1-78002r1)* 显示了来自UCI机器学习库的共享单车数据集这两个变量的散点图（[https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)）。
- en: '![PIC](img/file99.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file99.png)'
- en: '**Figure 4.1**: Bike-sharing dataset. Scatter plot of temperature in Celcius
    vs. number of rented bikes'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.1**：自行车共享数据集。摄氏温度与租用自行车数量的散点图'
- en: 'The original dataset contains 17,379 records, and each record has 17 variables.
    We will only use 359 records and two variables, `temperature` (Celcius) `rented`
    (number of rented bikes). We are going to use`temperature` as our independent
    variable (our X) and the number of bikes rented as our dependent variable (our
    Y). We are going to use the following model:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集包含 17,379 条记录，每条记录有 17 个变量。我们将只使用 359 条记录和两个变量，`temperature`（摄氏温度）和 `rented`（租用的自行车数量）。我们将使用
    `temperature` 作为自变量（我们的 X），租用的自行车数量作为因变量（我们的 Y）。我们将使用以下模型：
- en: '**Code 4.1**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.1**'
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Take a moment to read the code line by line and be sure to understand what is
    going on. Also check *Figure [4.2](#x1-78012r2)* for a visual representation of
    this model.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 花点时间逐行阅读代码，确保理解代码的含义。同时查看 *图 [4.2](#x1-78012r2)*，以获得该模型的可视化表示。
- en: '![PIC](img/file100.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file100.png)'
- en: '**Figure 4.2**: Bayesian linear model for the bike-sharing dataset'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.2**：自行车共享数据集的贝叶斯线性模型'
- en: As we have previously said, this is like a Normal model, but now the mean is
    modeled as a linear function of the temperature. The intercept is *α* and the
    slope is *β*. The noise term is ![](img/e.png) and the mean is *μ*. The only new
    thing here is the `Deterministic` variable *μ*. This variable is not a random
    variable, it is a deterministic variable, and it is computed from the intercept,
    the slope, and the temperature. We need to specify this variable because we want
    to save it in InferenceData for later use. We could have just written *μ* `=`
    *α* `+` *β* `* bikes.temperature` or even `_ = pm.Normal(’y_pred’, mu=`*α* `+`
    *β* `* bikes.temperature, ...` and the model will be the same, but we would not
    have been able to save *μ* in InferenceData. Notice that *μ* is a vector with
    the same length as `bikes.temperature`, which is the same as the number of records
    in the dataset.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所说，这类似于一个正态模型，但现在均值被建模为温度的线性函数。截距是 *α*，斜率是 *β*。噪声项是 ![](img/e.png)，均值是
    *μ*。这里唯一的新东西是 `Deterministic` 变量 *μ*。这个变量不是随机变量，而是一个确定性变量，它由截距、斜率和温度计算得出。我们需要指定这个变量，因为我们希望将其保存在
    InferenceData 中以备后续使用。我们本可以写 *μ* `=` *α* `+` *β* `* bikes.temperature`，甚至可以写成
    `_ = pm.Normal('y_pred', mu=`*α* `+` *β* `* bikes.temperature, ...`，模型会保持不变，但我们将无法将
    *μ* 保存在 InferenceData 中。注意，*μ* 是一个与 `bikes.temperature` 长度相同的向量，它与数据集中的记录数相同。
- en: 4.2.1 Interpreting the posterior mean
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.1 解释后验均值
- en: 'To explore the results of our inference, we are going to generate a posterior
    plot but omit the deterministic variable *μ*. We commit it because otherwise,
    we would get a lot of plots, one for each value of `temperature`. We can do this
    by passing the names of the variables we want to include in the plot as a list
    to the `var_names` argument or we can negate the variable that we want to exclude
    as in the following block of code:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索推断结果，我们将生成一个后验图，但会省略确定性变量 *μ*。我们这样做是因为如果不省略该变量，我们将得到很多图表，每个 `temperature`
    值对应一个图表。我们可以通过将我们想要包含在图表中的变量名作为列表传递给 `var_names` 参数，或者像以下代码块中那样否定我们想要排除的变量：
- en: '**Code 4.2**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.2**'
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![PIC](img/file101.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file101.png)'
- en: '**Figure 4.3**: Posterior plot for the bike linear model'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.3**：自行车线性模型的后验图'
- en: From *Figure [4.3](#x1-79005r3)*, we can see the marginal posterior distribution
    for *α*, *β*, and *σ*. If we only read the means of each distribution, say *μ*
    = 69 + 7*.*9*X*, with this information we can say that the expected value of rented
    bikes when the temperature is 0 is 69, and for each degree of temperature the
    number of rented bikes increases by 7.9\. So for a temperature of 28 degrees,
    we expect to rent 69 + 7*.*9 ∗ 28 ≈ 278 bikes. This is our expectation, but the
    posterior also informs us about the uncertainty around this estimate. For instance,
    the 94% HDI for *β* is (6.1, 9.7), so for each degree of temperature the number
    of rented bikes could increase from 6 to about 10\. Also even if we omit the posterior
    uncertainty and we only pay attention to the means, we still have uncertainty
    about the number of rented bikes because we have a value of *σ* of 170\. So if
    we say that for a temperature of 28 degrees, we expect to rent 278 bikes, we should
    not be surprised if the actual number turns out to be somewhere between 100 and
    500 bikes.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图 [4.3](#x1-79005r3)*中，我们可以看到*α*、*β*和*σ*的边际后验分布。如果我们只读取每个分布的均值，比如*μ* = 69
    + 7*.*9*X*，通过这些信息我们可以得出，温度为0时租赁自行车的预期数量为69辆，每升高1度温度，租赁的自行车数量增加7.9辆。因此，当温度为28度时，我们预期租赁278辆自行车，即69
    + 7*.*9 ∗ 28 ≈ 278辆。这是我们的预期值，但后验分布也告诉我们这个估计值的周围不确定性。例如，*β*的94% HDI为（6.1, 9.7），所以每升高1度温度，租赁的自行车数量可能增加6辆至约10辆。此外，即使我们忽略后验不确定性，只关注均值，我们仍然对租赁自行车数量有不确定性，因为我们有一个*σ*值为170。因此，如果我们说温度为28度时我们预期租赁278辆自行车，我们也不应该感到惊讶，实际数量可能在100到500辆之间。
- en: Now let’s create a few plots that will help us visualize the combined uncertainty
    of these parameters. Let’s start with two plots for the mean (see *Figure [4.4](#x1-79007r4)*).
    Both are plots of the mean number of rented bikes as a function of the temperature.
    The difference is how we represent the uncertainty. We show two popular ways of
    doing it. In the left subpanel, we take 50 samples from the posterior and plot
    them as individual lines. In the right subpanel, we instead take all the available
    posterior samples for *μ* and use them to compute the 94% HDI.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一些图表，帮助我们可视化这些参数的综合不确定性。我们从两个图开始，展示均值（见*图 [4.4](#x1-79007r4)*）。这两个图都是温度作为自变量时租赁自行车数量的均值图。不同之处在于我们如何表示不确定性。我们展示了两种常见的表示方法。在左侧子面板中，我们从后验分布中抽取50个样本，并将它们作为单独的线条绘制。在右侧子面板中，我们则采用所有可用的后验样本来计算94%的HDI。
- en: '![PIC](img/file102.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file102.png)'
- en: '**Figure 4.4**: Posterior plot for the bike linear model'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.4**：自行车线性模型的后验图'
- en: The plots in *Figure [4.4](#x1-79007r4)* convey essentially the same information,
    but one represents uncertainty as a set of lines and the other as a shaded area.
    Notice that if you repeat the code to generate the plot, you will get different
    lines, because we are sampling from the posterior. The shaded area, however, will
    be the same, because we are using all the available posterior samples. If we go
    further and refit the model, we will not only get different lines but the shaded
    area could also change, and probably the difference between runs is going to be
    very small; if not, you probably need to increase the number of draws, or there
    is something funny about your model and sampling (see *Chapter [10](CH10.xhtml#x1-18900010)*
    for guidance).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 [4.4](#x1-79007r4)*中的图表传达的基本相同的信息，只是其中一个通过一组线条表示不确定性，另一个则通过阴影区域表示。请注意，如果你重复代码生成图表，你会得到不同的线条，因为我们正在从后验分布中采样。然而，阴影区域将保持不变，因为我们使用了所有可用的后验样本。如果我们进一步拟合模型，我们不仅会得到不同的线条，阴影区域也可能发生变化，并且不同运行之间的差异可能非常小；如果差异很大，可能需要增加抽样次数，或者模型和采样存在问题（有关指导，请参见*第
    [10](CH10.xhtml#x1-18900010)章*）。'
- en: Anyway, why are we showing two slightly different plots if they convey the same
    information? Well, to highlight that there are different ways to represent uncertainty.
    Which one is better? As usual, that is context-dependent. The shaded area is a
    good option; it is very common, and it is simple to compute and interpret. Unless
    there are specific reasons to show individual posterior samples, the shaded area
    may be your preferred choice. But we may want to show individual posterior samples.
    For instance, most of the lines might span a certain region, but we get a few
    with very high slopes. A shaded area could hide that information. When showing
    individual samples from the posterior it may be a good idea to animate them if
    you are showing them in a presentation or a video (see [Kale et al.](Bibliography.xhtml#Xkale_2018) [[2019](Bibliography.xhtml#Xkale_2018)]
    for more on this).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 不管怎样，为什么我们要展示两个略有不同的图，它们传达的是相同的信息呢？嗯，这是为了突出不同的方式来表示不确定性。哪种更好？像往常一样，这取决于具体的上下文。阴影区域是一个不错的选择；它非常常见，且计算和解释都很简单。除非有特定的原因需要展示单个后验样本，否则阴影区域可能是你首选的方式。但我们也许希望展示单个后验样本。例如，大多数线条可能覆盖某个区域，但我们得到一些斜率非常大的线条。阴影区域可能会掩盖这些信息。如果你在展示单个后验样本时，可能可以考虑将其做成动画，特别是当你在演示或视频中展示时（详见[Kale
    等人](Bibliography.xhtml#Xkale_2018) [[2019](Bibliography.xhtml#Xkale_2018)]了解更多）。
- en: 'Another reason to show you the two plots in *Figure [4.4](#x1-79007r4)* is
    that you can learn different ways of extracting information from the posterior.
    Please pay attention to the next block of code. For clarity, we have omitted the
    code for plotting and we only show the core computations:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 向你展示*图 [4.4](#x1-79007r4)*中的两个图的另一个原因是，你可以学习从后验中提取信息的不同方式。请注意接下来的代码块。为了清晰起见，我们省略了绘图代码，只展示核心计算：
- en: '**Code 4.3**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.3**'
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can see that in the first line, we used `az.extract`. This function takes
    the `chain` and `draw` dimensions and stacks them in a single `sample` dimension,
    which can be useful for later processing. Additionally, we use the `num_samples`
    argument to ask for a subsample from the posterior. By default, `az.extract` will
    operate on the posterior group. If you want to extract information from another
    group, you can use the `group` argument. On the second line, we define a DataArray
    called `x_plot`, with equally spaced values ranging from the minimum to the maximum
    observed temperatures. The reason to create a DataArray is to be able to use Xarray’s
    automatic alignment capabilities in the next two lines. If we use a NumPy array,
    we will need to add extra dimensions, which is usually confusing. The best way
    to fully understand what I mean is to define `x_plot = np.linspace(bikes.temperature.min(),
    bikes.temperature.max())` and try to redo the plot. In the third line of code,
    we compute the mean of the posterior for *μ* for each value of `x_plot`, and in
    the fourth line, we compute individual values for *μ*. In these two lines we could
    have used `posterior[’`*μ*`’]`, but instead, we explicitly rewrite the linear
    model. We do this with the hope that it will help you to gain more intuition about
    linear models.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到在第一行中，我们使用了`az.extract`。这个函数将`chain`和`draw`维度堆叠到一个单一的`sample`维度中，这在后续处理时可能会很有用。此外，我们使用`num_samples`参数从后验中请求一个子样本。默认情况下，`az.extract`会作用于后验组。如果你想从另一个组提取信息，可以使用`group`参数。在第二行中，我们定义了一个叫做`x_plot`的DataArray，包含从最小到最大观测温度的等间距值。创建DataArray的原因是能够在接下来的两行中使用Xarray的自动对齐功能。如果我们使用NumPy数组，则需要添加额外的维度，这通常会令人困惑。为了更好地理解我的意思，最好的方式是定义`x_plot
    = np.linspace(bikes.temperature.min(), bikes.temperature.max())`并尝试重新绘制图形。在代码的第三行，我们计算了后验中*μ*的均值，针对每个`x_plot`的值；在第四行，我们计算了*μ*的个别值。在这两行中，我们本可以使用`posterior[’`*μ*`’]`，但我们显式地重写了线性模型。我们这样做的目的是希望能帮助你更好地理解线性模型。
- en: 4.2.2 Interpreting the posterior predictions
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.2 解释后验预测
- en: What if we are not just interested in the expected (mean) value, but we want
    to think in terms of predictions, that is, in terms of rented bikes? Well, for
    that, we can do posterior predictive sampling. After executing the next line of
    code, `idata_lb` will be populated with a new group, `posterior_predictive`, with
    a variable, `y_pred`, representing the posterior predictive distribution for the
    number of rented bikes.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不仅仅对期望值（均值）感兴趣，而是想从预测的角度来思考，也就是说，从租用自行车的角度来看怎么办？嗯，为此，我们可以进行后验预测采样。在执行下一行代码后，`idata_lb`将被填充一个新的组，`posterior_predictive`，其中包含一个变量`y_pred`，表示租用自行车数量的后验预测分布。
- en: '**Code 4.4**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.4**'
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The black line in *Figure [4.5](#x1-80006r5)* is the mean of the number of rented
    bikes. This is the same as in *Figure [4.4](#x1-79007r4)*. The new elements are
    the dark gray band representing the central 50% (quantiles 0.25 and 0.75) for
    the rented bikes and the light gray band, representing the central 94% (quantiles
    0.03 and 0.97). You may notice that our model is predicting a negative number
    of bikes, which does not make sense. But upon reflection, this should be expected
    as we use a Normal distribution for the likelihood in `model_lb`. A very dirty
    *fix* could be to clip the predictions at values lower than 0, but that’s ugly.
    In the next section, we will see that we can easily improve this model to avoid
    nonsensical predictions.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 [4.5](#x1-80006r5)* 中的黑线代表租赁自行车的均值。这与 *图 [4.4](#x1-79007r4)* 中的情况相同。新增元素包括代表租赁自行车中心
    50% 的深灰色带（分位数 0.25 和 0.75），以及代表中心 94% 的浅灰色带（分位数 0.03 和 0.97）。您可能注意到我们的模型预测了一个负数自行车数量，这是没有意义的。但仔细思考后，我们会发现这是预期的，因为在
    `model_lb` 中我们使用了正态分布来描述似然。一个非常简陋的 *修正* 可以是将预测值剪切为低于 0 的值，但那样很丑陋。在接下来的部分，我们将看到我们可以轻松改进这个模型，以避免不合理的预测。'
- en: '![PIC](img/file103.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file103.png)'
- en: '**Figure 4.5**: Posterior predictive plot for the bike linear model'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.5**：自行车线性模型的后验预测图'
- en: 4.3 Generalizing the linear model
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 泛化线性模型
- en: 'The linear model we have been using is a special case of a more general model,
    the **Generalized Linear Model** (**GLM**). The GLM is a generalization of the
    linear model that allows us to use different distributions for the likelihood.
    At a high level, we can write a Bayesian GLM like:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在使用的线性模型是更一般模型的特例，即**广义线性模型**（**GLM**）。GLM 是线性模型的泛化，允许我们使用不同的分布来描述似然。在高层次上，我们可以将贝叶斯
    GLM 写成：
- en: '![𝛼 ∼ a prior 𝛽 ∼ another prior θ ∼ some prior μ = 𝛼 + 𝛽X Y ∼ ϕ (f (μ ),θ)
    ](img/file104.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![𝛼 ∼ 先验 𝛽 ∼ 另一个先验 θ ∼ 某些先验 μ = 𝛼 + 𝛽X Y ∼ ϕ (f (μ ),θ) ](img/file104.jpg)'
- en: '![](img/phi.png) is an arbitrary distribution; some common cases are Normal,
    Student’s t, Gamma, and NegativeBinomial. *θ* represents any *auxiliary* parameter
    the distribution may have, like *σ* for the Normal. We also have *f*, usually
    called the inverse link function. When ![](img/phi.png) is Normal, then *f* is
    the identity function. For distributions like Gamma and NegativeBinomial, *f*
    is usually the exponential function. Why do we need *f*? Because the linear model
    will generally be on the real line, but the *μ* parameter (or its equivalent)
    may be defined on a different domain. For instance, *μ* for the NegativeBinomial
    is defined for positive values, so we need to transform *μ*. The exponential function
    is a good candidate for this transformation. We are going to explore a few GLMs
    in this book. A good exercise for you, while reading the book, is to create a
    table, and every time you see a new GLM, you add one line indicating what *phi*,
    *theta*, and *f* are and maybe some notes about when this GLM is used. OK, let’s
    start with our first concrete example of a GLM.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/phi.png) 是任意分布；一些常见情况包括正态分布、学生 t 分布、伽马分布和负二项分布。*θ* 表示分布可能具有的任何 *辅助*
    参数，例如正态分布中的 *σ*。我们还有 *f*，通常称为反向链接函数。当 ![](img/phi.png) 是正态分布时，*f* 是恒等函数。对于伽马分布和负二项分布等分布，*f*
    通常是指数函数。为什么我们需要 *f*？因为线性模型通常位于实数线上，但 *μ* 参数（或其等价物）可能在不同的定义域上。例如，负二项分布的 *μ* 定义为正值，因此我们需要对
    *μ* 进行变换。指数函数是这种变换的一个好选择。我们将在本书中探讨几种 GLM。在阅读本书时，一个很好的练习是创建一个表格，每次看到新的 GLM 时，添加一行说明
    *phi*、*theta* 和 *f* 是什么，以及关于何时使用该 GLM 的一些注释。好的，让我们从我们第一个具体的 GLM 示例开始。'
- en: 4.4 Counting bikes
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 计数自行车
- en: 'How can we change `model_lb` to better accommodate the bike data? There are
    two things to note: the number of rented bikes is discrete and it is bounded at
    0\. This is usually known as count data, which is data that is the result of counting
    something. Count data is sometimes modeled using a continuous distribution like
    a Normal, especially when the number of counts is large. But it is often a good
    idea to use a discrete distribution. Two common choices are the Poisson and NegativeBinomial
    distributions. The main difference is that for Poisson, the mean and the variance
    are the same, but if this is not true or even approximately true, then NegativeBinomial
    may be a better choice as it allows the mean and variance to be different. When
    in doubt, you can fit both Poisson and NegativeBinomial and see which one provides
    a better model. We are going to do that in *Chapter [5](CH05.xhtml#x1-950005)*.
    But for now, we are going to use NegativeBinomial.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如何改进 `model_lb` 以更好地适应自行车数据？需要注意两点：租赁自行车数量是离散的，并且其下界为 0。这通常被称为计数数据，指的是通过计数某物得出的数据。计数数据有时使用连续分布（如正态分布）来建模，特别是当计数数量较大时。但通常使用离散分布更为合适。两种常见的选择是泊松分布和
    NegativeBinomial 分布。主要的区别是，对于泊松分布，均值和方差是相同的，但如果这不成立或甚至大致不成立，那么 NegativeBinomial
    可能是一个更好的选择，因为它允许均值和方差不同。如果不确定，可以同时拟合泊松分布和 NegativeBinomial 分布，看看哪个模型更好。我们将在 *第
    [5](CH05.xhtml#x1-950005) 章* 中进行这一操作。但目前，我们将使用 NegativeBinomial 模型。
- en: '**Code 4.5**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.5**'
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The PyMC model is very similar to the previous one but with two main differences.
    First, we use `pm.NegativeBinomial` instead of `pm.Normal` for the likelihood.
    The NegativeBinomial distribution has two parameters, the mean *μ* and a dispersion
    parameter *α*. The variance of NegativeBinomial is *μ* + ![μ2 𝛼-](img/file105.jpg),
    so the larger the value of *α* the larger the variance. The second difference
    is that *μ* is `pm.math.exp(`*α* `+` *β* `* bikes.temperature)` instead of just
    *α* `+` *β* `* bikes.temperature` and, as we already explained, this is needed
    to transform the real line into the positive interval.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: PyMC 模型与之前的模型非常相似，但有两个主要区别。首先，我们使用 `pm.NegativeBinomial` 代替 `pm.Normal` 作为似然函数。NegativeBinomial
    分布有两个参数：均值 *μ* 和离散参数 *α*。NegativeBinomial 的方差为 *μ* + ![μ2 𝛼-](img/file105.jpg)，因此
    *α* 的值越大，方差越大。第二个区别是，*μ* 现在是 `pm.math.exp(`*α* `+` *β* `* bikes.temperature)`，而不是简单的
    *α* `+` *β* `* bikes.temperature`，正如我们之前解释的那样，这需要将实数线转换为正的区间。
- en: The posterior predictive distribution for `model_neg` is shown in *Figure [4.6](#x1-82014r6)*.
    The posterior predictive distribution is also very similar to the one we obtained
    with the linear model (*Figure [4.5](#x1-80006r5)*). The main difference is that
    now we are not predicting a negative number of rented bikes! We can also see that
    the variance of the predictions increases with the mean. This is expected because
    the variance of NegativeBinomial is *μ* + ![μ2 𝛼](img/file106.jpg).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`model_neg` 的后验预测分布显示在 *图 [4.6](#x1-82014r6)* 中。后验预测分布与我们在使用线性模型时获得的分布非常相似（*图
    [4.5](#x1-80006r5)*）。主要的区别是，现在我们不再预测负数的租赁自行车数量！我们还可以看到，预测的方差随着均值的增加而增大。这是预期之中的，因为
    NegativeBinomial 的方差为 *μ* + ![μ2 𝛼](img/file106.jpg)。'
- en: '![PIC](img/file107.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file107.png)'
- en: '**Figure 4.6**: Posterior predictive plot for the bike NegativeBinomial linear
    model'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.6**：自行车 NegativeBinomial 线性模型的后验预测图'
- en: '*Figure [4.7](#x1-82017r7)* shows the posterior predictive check for `model_lb`
    on the left and `model_neg` on the right. We can see that when using a Normal,
    the largest mismatch is that the model predicts a negative number of rented bikes,
    but even on the positive side we see that the fit is not that good. On the other
    hand, the NegativeBinomial model seems to be a better fit, although it’s not perfect.
    Look at the right tail: it’s heavier for the predictions than observations. But
    also notice that the probability of this very high demand is low. So, overall
    we can restate that the NegativeBinomial model is better than the Normal one.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 [4.7](#x1-82017r7)* 显示了 `model_lb` 的后验预测检验（左侧）和 `model_neg` 的后验预测检验（右侧）。我们可以看到，当使用正态分布时，最大的偏差是模型预测出租赁自行车数量为负数，但即使在正值范围内，我们也能看到拟合效果不太好。另一方面，NegativeBinomial
    模型似乎更适合，尽管它并不完美。看右尾：预测值的尾部比观测值重。但也注意到，这种非常高的需求的概率较低。因此，总的来说，我们可以重新表述为，NegativeBinomial
    模型比正态分布模型更好。'
- en: '![PIC](img/file108.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file108.png)'
- en: '**Figure 4.7**: Posterior predictive check for the bike linear model'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.7**：自行车线性模型的后验预测检验'
- en: 4.5 Robust regression
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 稳健回归
- en: I once ran a complex simulation of a molecular system. At each step of the simulation,
    I needed it to fit a linear regression as an intermediate step. I had theoretical
    and empirical reasons to think that my Y was conditionally Normal given my Xs,
    so I decided simple linear regression should do the trick. But from time to time
    the simulation generated a few values of Y that were way above or below the bulk
    of the data. This completely ruined my simulation and I had to restart it.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾经运行过一个复杂的分子系统模拟。在每一步模拟中，我都需要进行线性回归拟合作为中间步骤。我有理论和经验上的理由认为，在给定X值的情况下，我的Y值是条件正态分布的，所以我决定使用简单的线性回归来解决。但有时，模拟会生成一些远高于或低于数据主群的Y值。这完全破坏了我的模拟，我不得不重新启动它。
- en: Usually, these values that are very different from the bulk of the data are
    called outliers. The reason for the failure of my simulations was that the outliers
    were *pulling* the regression line away from the bulk of the data and when I passed
    this estimate to the next step in the simulation, the thing just halted. I solved
    this with the help of our good friend the Student’s t-distribution, which, as
    we saw in *Chapter [2](CH02.xhtml#x1-440002)*, has heavier tails than the Normal
    distribution. This means that the outliers have less influence on the regression
    line. This is an example of a robust regression.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这些与数据主群非常不同的值被称为异常值。我的模拟失败的原因是这些异常值*拉扯*回归线远离数据主群，而当我将这个估计传递到模拟的下一步时，事情就停止了。我通过我们亲爱的朋友——学生t分布解决了这个问题，正如我们在*第[2章](CH02.xhtml#x1-440002)*中看到的，学生t分布比正态分布有更重的尾部。这意味着异常值对回归线的影响较小。这就是稳健回归的一个例子。
- en: 'To exemplify the robustness that a Student’s T distribution brings to linear
    regression, we are going to use a very simple and nice dataset: the third data
    group from Anscombe’s quartet. If you do not know what Anscombe’s quartet is,
    check it out on Wikipedia ( [https://en.wikipedia.org/wiki/Anscombe%27s_quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了举例说明学生t分布为线性回归带来的稳健性，我们将使用一个非常简单且有趣的数据集：Anscombe四重奏中的第三组数据。如果你不知道Anscombe四重奏是什么，可以在维基百科查看（
    [https://en.wikipedia.org/wiki/Anscombe%27s_quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)
    ）。
- en: 'In the following model, `model_t`, we are using a shifted exponential to avoid
    values close to 0\. The non-shifted Exponential puts too much weight on values
    close to 0\. In my experience, this is fine for data with none to moderate outliers,
    but for data with extreme outliers (or data with a few bulk points), like in Anscombe’s
    third dataset, it is better to avoid such low values. Take this, as well as other
    prior recommendations, with a pinch of salt. The defaults are good starting points,
    but there’s no need to stick to them. Other common priors are Gamma(2, 0.1) and
    Gamma(mu=20, sigma=15), which are somewhat similar to Exponential(1/30) but with
    less values closer to 0:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的模型`model_t`中，我们使用了一个移位的指数分布来避免接近0的值。未移位的指数分布对接近0的值赋予过多权重。根据我的经验，这对没有异常值或异常值适中的数据来说是可以的，但对于有极端异常值（或包含少量集群点）的数据，如Anscombe的第三组数据，最好避免这种低值。请对这一点，以及其他先前的建议持谨慎态度。默认值是一个不错的起点，但没有必要死守它们。其他常见的先验包括Gamma(2,
    0.1)和Gamma(mu=20, sigma=15)，它们与Exponential(1/30)相似，但更少有接近0的值：
- en: '**Code 4.6**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.6**'
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In *Figure [4.8](#x1-83015r8)*, we can see the robust fit, according to `model_t`,
    and the non-robust fit, according to SciPy’s `linregress` (this function is doing
    least-squares regression).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 [4.8](#x1-83015r8)*中，我们可以看到根据`model_t`的稳健拟合和根据SciPy的`linregress`（此函数执行最小二乘回归）的非稳健拟合。
- en: '![PIC](img/file109.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file109.png)'
- en: '**Figure 4.8**: Robust regression according to `model_t`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.8**：根据`model_t`的稳健回归'
- en: While the non-robust fit tries to *compromise* and include all points, the robust
    Bayesian model, `model_t`, automatically *discards* one point and fits a line
    that passes closer through all the remaining points. I know this is a very peculiar
    dataset, but the message remains the same as for other datasets; a Student’s t-distribution,
    due to its heavier tails, gives less importance to points that are far away from
    the bulk of the data.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然非稳健拟合试图*妥协*并包含所有点，但稳健贝叶斯模型`model_t`自动*丢弃*一个点，并拟合一条通过所有剩余点更接近的直线。我知道这是一个非常特殊的数据集，但其信息与其他数据集的结论相同；由于学生t分布的尾部更重，它对远离数据主群的点赋予较小的权重。
- en: From *Figure [4.9](#x1-83017r9)*, we can see that for the bulk of the data,
    we get a very good match. Also, notice that our model predicts values away from
    the bulk to both sides and not just above the bulk (as in the observed data).
    For our current purposes, this model is performing just fine and it does not need
    further changes. Nevertheless, notice that for some problems, we may want to avoid
    this. In such a case, we should probably go back and change the model to restrict
    the possible values of `y_pred` to positive values using a truncated Student’s
    t-distribution. This is left as an exercise for the reader.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图 [4.9](#x1-83017r9)*中，我们可以看到对于大部分数据，我们得到了一个非常好的匹配。同时，注意到我们的模型预测了远离大多数数据的值，向两侧扩展，而不仅仅是像观察到的数据那样在大部分数据上方。就我们目前的目的而言，这个模型表现得相当不错，不需要进一步修改。然而，注意到对于某些问题，我们可能希望避免这种情况。在这种情况下，我们可能需要回过头来修改模型，使用截断的学生t分布将`y_pred`的可能值限制为正值。这部分留给读者作为练习。
- en: '![PIC](img/file110.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file110.png)'
- en: '**Figure 4.9**: Posterior predictive check for `model_t`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.9**：`model_t`的后验预测检验'
- en: 4.6 Logistic regression
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6 逻辑回归
- en: 'The logistic regression model is a generalization of the linear regression
    model, which we can use when the response variable is binary. This model uses
    the logistic function as an inverse link function. Let’s get familiar with this
    function before we move on to the model:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型是线性回归模型的推广，我们可以在响应变量为二元时使用该模型。该模型使用逻辑函数作为逆链接函数。在我们继续讨论模型之前，让我们先熟悉一下这个函数：
- en: '![logistic(z) = ---1--- 1+ e−z ](img/file111.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![logistic(z) = ---1--- 1+ e−z](img/file111.jpg)'
- en: For our purpose, the key property of the logistic function is that irrespective
    of the values of its argument *z*, the result will always be a number in the [0-1]
    interval. Thus, we can see this function as a convenient way to compress the values
    computed from a linear model into values that we can feed into a Bernoulli distribution.
    This logistic function is also known as the sigmoid function because of its characteristic
    S-shaped aspect, as we can see from *Figure [4.10](#x1-84003r10)*.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们而言，逻辑函数的关键特性是，无论其自变量*z*的值如何，结果总是一个位于[0-1]区间的数字。因此，我们可以将这个函数看作是将通过线性模型计算得出的值压缩成可以输入伯努利分布的值的一种便捷方式。由于其特有的S形状，这个逻辑函数也被称为sigmoid函数，正如我们从*图
    [4.10](#x1-84003r10)*中看到的那样。
- en: '![PIC](img/file112.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file112.png)'
- en: '**Figure 4.10**: Logistic function'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.10**：逻辑函数'
- en: 4.6.1 The logistic model
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6.1 逻辑模型
- en: We have almost all the elements to turn a simple linear regression into a simple
    logistic regression. Let’s begin with the case of only two classes, for example,
    ham/spam, safe/unsafe, cloudy/sunny, healthy/ill, or hotdog/not hotdog. First,
    we codify these classes by saying that the predicted variable *y* can only take
    two values, 0 or 1, that is *y* ∈{0*,*1}.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎具备了将一个简单的线性回归转换为一个简单的逻辑回归所需的所有元素。我们从只有两个类别的情况开始，例如，垃圾邮件/非垃圾邮件、安全/不安全、多云/晴天、健康/生病，或热狗/非热狗。首先，我们通过声明预测变量*y*只能取两个值，即0或1来对这些类别进行编码，即*y*
    ∈{0,*1}。
- en: 'Stated this way, the problem sounds very similar to the coin-flipping one we
    used in previous chapters. We may remember we used the Bernoulli distribution
    as the likelihood. The difference with the coin-flipping problem is that now *θ*
    is not going to be generated from a beta distribution; instead, *θ* is going to
    be defined by a linear model with the logistic as the inverse link function. Omitting
    the priors, we have:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个角度描述，问题听起来非常像我们在前几章使用的掷硬币问题。我们可能记得我们使用了伯努利分布作为似然函数。与掷硬币问题的不同之处在于，现在*θ*不会从beta分布生成，而是通过一个线性模型来定义，使用逻辑函数作为逆链接函数。省略先验分布后，我们有：
- en: '![θ = logistic(𝛼 + 𝛽x) y ∼ Bernoulli(θ) ](img/file113.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![θ = logistic(𝛼 + 𝛽x) y ∼ Bernoulli(θ)](img/file113.jpg)'
- en: 'We are going to apply logistic regression to the classic iris dataset which
    has measurements from flowers from three closely related species: setosa, virginica,
    and versicolor. These measurements are the petal length, petal width, sepal length,
    and sepal width. In case you are wondering, sepals are modified leaves whose function
    is generally related to protecting the flowers in a bud.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对经典的鸢尾花数据集应用逻辑回归，该数据集包含来自三种密切相关物种的花卉测量数据：setosa、virginica和versicolor。这些测量数据包括花瓣长度、花瓣宽度、萼片长度和萼片宽度。如果你想知道，萼片是经过改良的叶子，通常与保护花朵在花蕾中的功能有关。
- en: We are going to begin with a simple case. Let’s assume we only have two classes,
    setosa, and versicolor, and just one independent variable or feature, `sepal_length`.
    We want to predict the probability of a flower being setosa given its sepal length.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个简单的案例开始。假设我们只有两个类别，setosa和versicolor，并且只有一个独立变量或特征，`sepal_length`。我们希望根据花萼长度预测一朵花是setosa的概率。
- en: 'As is usually done, we are going to encode the `setosa` and `versicolor` categories
    with the numbers `0` and `1`. Using pandas, we can do the following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如同常见的做法，我们将使用数字`0`和`1`对`setosa`和`versicolor`类别进行编码。使用pandas，我们可以执行以下操作：
- en: '**Code 4.7**'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.7**'
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As with other linear models, centering the data can help with the sampling.
    Now that we have the data in the right format, we can finally build the model
    with PyMC:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他线性模型一样，中心化数据有助于采样。现在我们已经将数据转换为正确的格式，接下来我们可以使用PyMC构建模型：
- en: '**Code 4.8**'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.8**'
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`model_lrs` has two deterministic variables: *θ* and `bd`. *θ* is the result
    of applying the logistic function to variable *μ*. `bd` is the boundary decision,
    which is the value we use to separate classes. We will discuss this later in detail.
    Another point worth mentioning is that instead of writing the logistic function
    ourselves, we are using the one provided by PyMC, `pm.math.sigmoid`.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`model_lrs`有两个确定性变量：*θ*和`bd`。*θ*是将逻辑函数应用于变量*μ*的结果。`bd`是边界决策值，我们使用这个值来区分类别。我们稍后会详细讨论这一点。另一个值得注意的地方是，我们并没有自己编写逻辑函数，而是使用了PyMC提供的`pm.math.sigmoid`函数。'
- en: '*Figure [4.11](#x1-85023r11)* shows the result of `model_lrs`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 [4.11](#x1-85023r11)* 显示了`model_lrs`的结果：'
- en: '![PIC](img/file114.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file114.png)'
- en: '**Figure 4.11**: Logistic regression, result of `model_lrs`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.11**：逻辑回归，`model_lrs`的结果'
- en: '*Figure [4.11](#x1-85023r11)* shows the sepal length versus the probability
    of being versicolor *θ* (and if you want, also the probability of being setosa,
    1 − *θ*). We have added some jitter (noise) to the binary response so the point
    does not overlap. An S-shaped (black) line is the mean value of *θ*. This line
    can be interpreted as the probability of a flower being versicolor, given that
    we know the value of the sepal length. The semitransparent S-shaped band is the
    94% HDI. What about the vertical line? That’s the topic of the next section.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 [4.11](#x1-85023r11)* 显示了花萼长度与为versicolor的概率*θ*（如果需要，也可以是为setosa的概率，1 −
    *θ*）的关系。我们对二元响应添加了一些抖动（噪音），以避免数据点重叠。黑色的S形线表示*θ*的平均值。这条线可以解释为在已知花萼长度的情况下，一朵花为versicolor的概率。半透明的S形带表示94%的HDI。垂直线又代表什么呢？这将是下一节的主题。'
- en: 4.6.2 Classification with logistic regression
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6.2 使用逻辑回归进行分类
- en: My mother prepares a delicious dish called sopa seca, which is basically a spaghetti-based
    recipe and translates literally to ”dry soup.” While it may sound like a misnomer
    or even an oxymoron, the name of the dish makes total sense when you learn how
    it is cooked (you may check out the recipe in the GitHub repo for this book at
    [https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)). Something
    similar happens with logistic regression, a model that, despite its name, is generally
    framed as a method for solving classification problems. Let’s see the source of
    this duality.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我的母亲做了一道美味的菜叫做sopa seca，基本上是一道以意大利面为主的菜肴，字面意思是“干汤”。虽然听起来可能像是个误称，甚至是个矛盾修饰法，但当你了解它的做法时，这道菜的名字就完全合理了（你可以在本书的GitHub仓库中查看这个食谱：[https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)）。类似的事情也发生在逻辑回归中，尽管它的名字如此，但通常被当作一种解决分类问题的方法。让我们看看这种二元性的来源。
- en: Regression problems are about predicting a continuous value for an output variable
    given the values of one or more input variables. We have seen many examples of
    regression that include logistic regression. However, logistic regression is usually
    discussed in terms of classification. Classification involves assigning discrete
    values (representing a class, like versicolor) to an output variable given some
    input variables, for instance, stating that a flower is versicolor or setosa given
    its sepal length.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 回归问题是关于根据一个或多个输入变量的值来预测输出变量的连续值。我们已经见过许多回归的例子，包括逻辑回归。然而，逻辑回归通常是以分类的形式讨论的。分类涉及根据一些输入变量为输出变量分配离散值（代表一个类别，比如versicolor），例如，根据花萼长度判断一朵花是versicolor还是setosa。
- en: 'So, is logistic regression a regression or a classification method? The answer
    is that it is a regression method; we are regressing the probability of belonging
    to some class, but it can be used for classification too. The only thing we need
    is a decision rule: for example, we assign the class `versicolor` if *θ* ≥ 0*.*5
    and assign `setosa` otherwise. The vertical line in *Figure [4.11](#x1-85023r11)*
    is the boundary decision, and it is defined as the value of the independent variable
    that makes the probability of being versicolor equal to 0.5\. We can calculate
    this value analytically, and it is equal to −![𝛼- 𝛽](img/file115.jpg). This calculation
    is based on the definition of the model:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，逻辑回归是回归方法还是分类方法呢？答案是，它是一种回归方法；我们回归的是属于某个类别的概率，但它也可以用于分类。我们需要的只是一个决策规则：例如，如果*θ*
    ≥ 0*.*5，则将样本归为`versicolor`类，否则归为`setosa`类。*图 [4.11](#x1-85023r11)*中的垂直线是边界决策，它被定义为使得versicolor的概率等于0.5时独立变量的值。我们可以通过分析计算出这个值，它等于−![𝛼-
    𝛽](img/file115.jpg)。这个计算基于模型的定义：
- en: '![θ = logistic(𝛼 + 𝛽x) ](img/file116.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![θ = logistic(𝛼 + 𝛽x) ](img/file116.jpg)'
- en: And from the definition of the logistic function, we have that *θ* = 0*.*5 when
    *α* + *β**x* = 0.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 根据逻辑函数的定义，当*α* + *β**x* = 0时，*θ* = 0*.*5。
- en: '![0.5 = logistic(𝛼 + 𝛽x ) ⇐ ⇒ 0 = 𝛼 + 𝛽x ](img/file117.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![0.5 = logistic(𝛼 + 𝛽x ) ⇐ ⇒ 0 = 𝛼 + 𝛽x ](img/file117.jpg)'
- en: Reordering, we find that the value of *x* that makes *θ* = 0*.*5 is −![𝛼𝛽-](img/file118.jpg).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 通过重新排列，我们发现使得*θ* = 0*.*5的*x*值是−![𝛼𝛽-](img/file118.jpg)。
- en: Because we have uncertainty in the value of *α* and *β*, we also have uncertainty
    about the value of the boundary decision. This uncertainty is represented as the
    vertical (gray) band in *Figure [4.11](#x1-85023r11)*, which goes from ≈ 5*.*3
    to ≈ 5*.*6\. If we were doing automatic classification of flowers based on their
    sepal length (or any similar problem that could be framed within this model),
    we could assign setosa to flowers with a sepal length below 5.3 and versicolor
    to flowers with sepal length above 5.6\. For flowers with a sepal lengths between
    5.3 and 5.6, we would be uncertain about their class, so we could either assign
    them randomly or use some other information to make a decision, including asking
    a human to check the flower.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们对*α*和*β*的值存在不确定性，所以我们对于边界决策的值也存在不确定性。这种不确定性在*图 [4.11](#x1-85023r11)*中以垂直（灰色）带的形式表示，范围从≈5*.*3到≈5*.*6。如果我们根据花萼长度进行花卉的自动分类（或任何可以在此模型框架下描述的类似问题），我们可以将花萼长度小于5.3的花归为setosa类，将花萼长度大于5.6的花归为versicolor类。对于花萼长度在5.3到5.6之间的花，我们将对其类别感到不确定，因此可以随机分配它们的类别，或者使用其他信息做出决策，包括让人类检查这些花卉。
- en: 'To summarize this section:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 总结本节内容：
- en: The value of *θ* is, generally speaking, *P*(*Y* = 1|*X*). In this sense, logistic
    regression is a true regression; the key detail is that we are regressing the
    probability that a data point belongs to class 1, given a linear combination of
    features.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*θ*的值通常来说是*P*(*Y* = 1|*X*)。从这个角度来看，逻辑回归是真正的回归方法；关键细节是，我们正在回归一个数据点属于类别1的概率，前提是给定特征的线性组合。'
- en: We are modeling the mean of a dichotomous variable, which is a number in the
    [0-1] interval. Thus, if we want to use logistic regression for classification,
    we need to introduce a rule to turn this probability into a two-class assignment.
    For example, if *P*(*Y* = 1) *>* 0*.*5, we assign that observation to class 1,
    otherwise we assign it to class 0.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们正在建模一个二元变量的均值，它是[0-1]区间中的一个数字。因此，如果我们想将逻辑回归用于分类，我们需要引入一个规则，将这个概率转换为二分类赋值。例如，如果*P*(*Y*
    = 1) *>* 0*.*5，我们将该观测值分配给类别1，否则分配给类别0。
- en: There is nothing special about the value of 0.5, other than that it is the number
    in the middle of 0 and 1\. This boundary can be justified when we are OK with
    misclassifying a data point in either direction. But this is not always the case,
    because the cost associated with the misclassification does not need to be symmetrical.
    For example, if we are trying to predict whether a patient has a disease or not,
    we may want to use a boundary that minimizes the number of false negatives (patients
    that have the disease but we predict they don’t) or false positives (patients
    that don’t have the disease but we predict they do). We will discuss this in more
    detail in the next section.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值0.5并没有什么特别之处，除了它是0和1之间的中间值。当我们可以接受将数据点错误分类到任一方向时，这个边界是可以解释的。但这并不总是如此，因为错误分类的成本不一定是对称的。例如，如果我们尝试预测一个病人是否患有某种疾病，我们可能希望使用一个边界来最小化假阴性（患病但我们预测他们没有）或假阳性（未患病但我们预测他们患病）的数量。我们将在下一节中更详细地讨论这个问题。
- en: 4.6.3 Interpreting the coefficients of logistic regression
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6.3 解释逻辑回归的系数
- en: We must be careful when interpreting the coefficients of logistic regression.
    Interpretation is not as straightforward as with simple linear models. Using the
    logistic inverse link function introduces a non-linearity that we have to take
    into account. If *β* is positive, increasing *x* will increase *p*(*y* = 1) by
    some amount, but the amount is not a linear function of *x*. Instead, the dependency
    is non-linear on the value of *x*, meaning that the effect of *x* on *p*(*y* =
    1) depends on the value of *x*. We can visualize this fact in *Figure [4.11](#x1-85023r11)*.
    Instead of a line with a constant slope, we have an S-shaped line with a slope
    that changes as a function of *x*.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释逻辑回归的系数时，我们必须小心。与简单线性模型不同，解释并不是那么直接。使用逻辑逆链接函数引入了一个非线性因素，我们必须考虑到这一点。如果*β*为正，则增加*x*会使*p*(*y*
    = 1)增加一定量，但这个量不是*x*的线性函数。相反，依赖关系是*x*值的非线性函数，这意味着*x*对*p*(*y* = 1)的影响取决于*x*的值。我们可以在*图
    [4.11](#x1-85023r11)*中直观地展示这一点。我们不再得到一条常数斜率的直线，而是得到一条S形的曲线，斜率随*x*的变化而变化。
- en: 'A little bit of algebra can give us some further insight into how much *p*(*y*
    = 1) changes with *x*. The basic logistic model is:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 一些代数可以帮助我们进一步理解*p*(*y* = 1)随着*x*的变化有多少变化。基本的逻辑斯蒂模型是：
- en: '![θ = logistic(𝛼 + 𝛽x) ](img/file119.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![θ = logistic(𝛼 + 𝛽x) ](img/file119.jpg)'
- en: 'The inverse of the logistic is the logit function, which is:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的逆函数是logit函数，公式为：
- en: '![ --z-- logit(z) = log 1 − z ](img/file120.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![ --z-- logit(z) = log 1 − z ](img/file120.jpg)'
- en: 'Combining these two expressions, we get:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 结合这两个表达式，我们得到：
- en: '![ θ logit(θ) = log1-−-θ = 𝛼 + 𝛽x ](img/file121.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![ θ logit(θ) = log1-−-θ = 𝛼 + 𝛽x ](img/file121.jpg)'
- en: 'Remember that *θ* in our model is *p*(*y* = 1), so we can rewrite the previous
    expression as:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在我们的模型中，*θ*是*p*(*y* = 1)，所以我们可以将之前的表达式改写为：
- en: '![ ( ) log --p(y-=-1)-- = 𝛼 + 𝛽x 1 − p(y = 1) ](img/file122.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![ ( ) log --p(y-=-1)-- = 𝛼 + 𝛽x 1 − p(y = 1) ](img/file122.jpg)'
- en: The ![-p(y=1)-- 1−p(y=1)](img/file123.jpg) quantity is known as the **odds**
    of *y* = 1\. If we call *y* = 1 a *success*, then the odds of success is the ratio
    of the probability of success over the probability of failure. For example, while
    the probability of getting a 2 by rolling a fair die is ![1 6](img/file124.jpg),
    the odds of getting a 2 are ![1∕6- 5∕6](img/file125.jpg) = ![1 5](img/file126.jpg)
    = 0*.*2\. In other words, there is one favorable event for every five unfavorable
    events. Odds are often used by gamblers because they provide a more intuitive
    tool to think about bets than raw probabilities. *Figure [4.12](#x1-87002r12)*
    shows how probabilities are related to odds and log-odds.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![-p(y=1)-- 1−p(y=1)](img/file123.jpg) 这一量被称为*p* = 1的**赔率**。如果我们把*p* = 1看作是*成功*，那么成功的赔率就是成功的概率与失败的概率之比。例如，掷一个公平的骰子得到2的概率是![1
    6](img/file124.jpg)，而得到2的赔率是![1∕6- 5∕6](img/file125.jpg) = ![1 5](img/file126.jpg)
    = 0*.*2\. 换句话说，每五次不成功的事件中就有一次成功事件。赔率通常被赌博者使用，因为它们比原始概率提供了更直观的投注思考工具。*图 [4.12](#x1-87002r12)*展示了概率、赔率和log-odds之间的关系。'
- en: '![PIC](img/file127.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file127.png)'
- en: '**Figure 4.12**: Relationship between probability, odds, and log-odds'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.12**：概率、赔率和log-odds的关系'
- en: Interpreting Logistic Regression
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 解释逻辑回归
- en: In logistic regression, the *β* coefficient (the *slope*) encodes the increase
    in log-odds units by a unit increase of the *x* variable.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在逻辑回归中，*β*系数（*斜率*）表示*x*变量增加一个单位时，log-odds单位的增加。
- en: The transformation from probability to odds is a monotonic transformation, meaning
    the odds increase as the probability increases, and the other way around. While
    probabilities are restricted to the [0*,*1] interval, odds live in the [0*,*∞)
    interval. The logarithm is another monotonic transformation and log-odds are in
    the (−∞*,*∞) interval.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 从概率到赔率的转换是单调变化，意味着随着概率的增加，赔率也会增加，反之亦然。虽然概率限制在[0*,*1]区间内，但赔率位于[0*,*∞)区间内。对数是另一种单调变化，而对数赔率则位于(−∞*,*∞)区间内。
- en: 4.7 Variable variance
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.7 变量方差
- en: We have been using the linear motif to model the mean of a distribution and,
    in the previous section, we used it to model interactions. In statistics, it is
    said that a linear regression model presents heteroskedasticity when the variance
    of the errors is not constant in all the observations made. For those cases, we
    may want to consider the variance (or standard deviation) as a (linear) function
    of the dependent variable.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直使用线性模式来建模分布的均值，并且在上一节中，我们用它来建模交互效应。在统计学中，当误差的方差在所有观察值中不恒定时，我们称线性回归模型呈现异方差性。在这种情况下，我们可能需要考虑将方差（或标准差）作为因变量的（线性）函数。
- en: 'The World Health Organization and other health institutions around the world
    collect data for newborns and toddlers and design growth chart standards. These
    charts are an essential component of the pediatric toolkit and also a measure
    of the general well-being of populations to formulate health-related policies,
    plan interventions, and monitor their effectiveness. An example of such data is
    the lengths (heights) of newborn/toddler girls as a function of their age (in
    months):'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 世界卫生组织及其他全球卫生机构收集新生儿和幼儿的数据，并设计生长曲线标准。这些图表是儿科工具包的重要组成部分，也是衡量人群整体健康状况的标准，能够帮助制定健康相关政策、规划干预措施并监测其效果。这样的数据示例包括新生儿/幼儿女孩的身高（体长）与年龄（月龄）之间的关系：
- en: '**Code 4.9**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.9**'
- en: '[PRE8]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To model this data, we are going to introduce three elements we have not seen
    before:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对这些数据进行建模，我们将引入三个我们之前未见过的元素：
- en: '*σ* is now a linear function of the predictor variable. Thus, we add two new
    parameters, *γ* and *δ*. These are direct analogs of *α* and *β* in the linear
    model for the mean.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*σ*现在是预测变量的线性函数。因此，我们新增了两个参数，*γ*和*δ*。这两个参数是均值线性模型中*α*和*β*的直接类比。'
- en: The linear model for the mean is a function of ![](img/file128.png). This is
    just a simple trick to fit a linear model to a curve.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均值的线性模型是一个函数！[](img/file128.png)。这只是一个简单的技巧，用于将线性模型拟合到曲线上。
- en: We define a `MutableData` variable, `x_shared`. Why we want to do this will
    become clear soon.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义了一个`MutableData`变量，`x_shared`。为什么要这么做，很快就会明了。
- en: 'Our full model is:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的完整模型是：
- en: '**Code 4.10**'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.10**'
- en: '[PRE9]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: On the left panel of *Figure [4.13](#x1-88022r13)*, we can see the mean of *μ*
    represented by a black curve, and the two semi-transparent gray bands represent
    one and two standard deviations. On the right panel, we have the estimated variance
    as a function of the length. As you can see, the variance increases with the length,
    which is what we expected.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 [4.13](#x1-88022r13)*的左面板中，我们可以看到由黑色曲线表示的*μ*的均值，两个半透明的灰色带表示一个和两个标准差。在右面板中，我们看到了随着身长变化的估计方差。正如你所见，方差随着身长的增加而增大，这是我们预期的结果。
- en: '![PIC](img/file129.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file129.png)'
- en: '**Figure 4.13**: Posterior fit for `model_vv` on the left panel. On the right
    is the mean estimated variance as a function of the length'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.13**：左面板为`model_vv`的后验拟合。右面板是随着身长变化的均值估计方差。'
- en: 'Now that we have fitted the model, we might want to use the model to find out
    how the length of a particular girl compares to the distribution. One way to answer
    this question is to ask the model for the distribution of the variable `length`
    for babies of, say, 0.5 months. We can answer this question by sampling from the
    posterior predictive distribution conditional on a length of 0.5\. Using PyMC,
    we can get the answer by sampling `pm.sample_posterior_predictive`; the only problem
    is that by default, this function will return values of *ỹ* for the already observed
    values of *x*, i.e., the values used to fit the model. The easiest way to get
    predictions for unobserved values is to define a `MutableData` variable (`x_shared`
    in the example) and then update the value of this variable right before sampling
    the posterior predictive distribution, as shown in the following code block:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拟合了模型，可能想使用模型来了解某个特定女孩的身高与分布的比较。回答这个问题的一种方法是询问模型关于0.5个月大婴儿的`length`变量的分布。我们可以通过从后验预测分布中进行采样，条件是身高为0.5来回答这个问题。使用
    PyMC，我们可以通过采样`pm.sample_posterior_predictive`得到答案；唯一的问题是，默认情况下，这个函数会返回*ỹ*值，这些值是已经观察到的*x*值，即用于拟合模型的值。获取未观察值的预测值的最简单方法是定义一个`MutableData`变量（在这个例子中是`x_shared`），然后在采样后验预测分布之前更新这个变量的值，如下代码块所示：
- en: '**Code 4.11**'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.11**'
- en: '[PRE10]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now we can plot the expected distribution of lengths for 2-week-old girls and
    calculate other quantities, like the percentile for a girl of that length (see
    *Figure [4.14](#x1-88029r14)*).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以绘制出2周大女孩的预期身长分布，并计算其他量，如该身长女孩的百分位（见*图 [4.14](#x1-88029r14)*）。
- en: '![PIC](img/file130.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file130.png)'
- en: '**Figure 4.14**: Expected distribution of length at 0.5 months. The shaded
    area represents 32% of the accumulated mass'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.14**：0.5个月时的身高预期分布。阴影区域表示32%的累计质量'
- en: 4.8 Hierarchical linear regression
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.8 层次线性回归
- en: In *Chapter [3](CH03.xhtml#x1-670003)*, we learned the rudiments of hierarchical
    models, a very powerful concept that allows us to model complex data structures.
    Hierarchical models allow us to deal with inferences at the group level and estimations
    above the group level. As we have already seen, this is done by including hyperpriors.
    We also showed that groups can share information by using a common hyperprior
    and this provides shrinkage, which can help us to regularize the estimates.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第[3章](CH03.xhtml#x1-670003)*中，我们学习了层次模型的基本概念，这是一个非常强大的概念，它允许我们建模复杂的数据结构。层次模型使我们能够处理组层次的推断以及组层次以上的估计。如我们所见，这可以通过包含超先验来实现。我们还展示了组之间可以通过使用共同的超先验来共享信息，这提供了收缩效应，有助于正则化估计。
- en: We can apply these very same concepts to linear regression to obtain hierarchical
    linear regression models. In this section, we are going to walk through two examples
    to elucidate the application of these concepts in practical scenarios. The first
    one uses a synthetic dataset, and the second one uses the `pigs` dataset.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些相同的概念应用到线性回归中，得到层次线性回归模型。在本节中，我们将通过两个例子来阐明这些概念在实际场景中的应用，第一个使用的是合成数据集，第二个使用的是`pigs`数据集。
- en: For the first example, I have created eight related groups, including one group
    with just one data point. We can see what the data looks like from *Figure [4.15](#x1-89002r15)*.
    If you want to learn more how this data was generated please check the GitHub
    repository [https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个例子，我创建了八个相关的组，其中有一个组只有一个数据点。我们可以从*图 [4.15](#x1-89002r15)* 中看到数据的表现。如果你想了解更多关于这些数据是如何生成的，请访问
    GitHub 仓库 [https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)。
- en: '![PIC](img/file131.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file131.png)'
- en: '**Figure 4.15**: Synthetic data for the hierarchical linear regression example'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.15**：层次线性回归示例的合成数据'
- en: 'First, we are going to fit a non-hierarchical model:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将拟合一个非层次模型：
- en: '**Code 4.12**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.12**'
- en: '[PRE11]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*Figure [4.16](#x1-89014r16)* shows the posterior estimated values for the
    parameters *α* and *β*.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 [4.16](#x1-89014r16)* 显示了参数*α*和*β*的后验估计值。'
- en: '![PIC](img/file132.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file132.png)'
- en: '**Figure 4.16**: Posterior distribution for *α* and *β* for `unpooled_model`'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.16**：`unpooled_model`的*α*和*β*的后验分布'
- en: As you can see from *Figure [4.16](#x1-89014r16)* the estimates for group `H`
    are very different from the ones for the other groups. This is expected as for
    group `H`, we only have one data point, that is we do not have enough information
    to fit a line. We need at least two points; otherwise, the model will be over-parametrized,
    meaning we have more parameters than the ones we can determine from the data alone.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 正如*图[4.16](#x1-89014r16)*所示，组`H`的估计值与其他组的估计值非常不同。这是预期中的情况，因为对于组`H`，我们只有一个数据点，也就是说我们没有足够的信息来拟合一条直线。我们至少需要两个数据点；否则，模型会过度参数化，这意味着我们有比数据所能确定的更多的参数。
- en: To overcome this situation we can provide some more information; we can do this
    by using priors or by adding more structure to the model. Let’s add more structure
    by building a hierarchical model.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这种情况，我们可以提供更多的信息；我们可以通过使用先验或向模型中添加更多结构来实现这一点。让我们通过构建一个分层模型来添加更多结构。
- en: 'This is the PyMC model for the hierarchical model:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这是分层模型的PyMC模型：
- en: '**Code 4.13**'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.13**'
- en: '[PRE12]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: If you run `hierarchical_centered`, you will see a message from PyMC saying
    something like `There were 149 divergences after tuning. Increase target_accept
    or reparameterize.` This message means that samples generated from PyMC may not
    be trustworthy. So far, we have assumed that PyMC always returns samples that
    we can use without issues, but that’s not always the case. In *Chapter [10](CH10.xhtml#x1-18900010)*,
    we further discuss why this is, along with diagnostic methods to help you identify
    those situations and recommendations to fix the potential issues. In that section,
    we also explain what divergences are. For now, we will only say that when working
    with hierarchical linear models, we will usually get a lot of divergences.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行`hierarchical_centered`，你会看到PyMC显示一条信息，类似于`调整后有149次发散。增加target_accept或重新参数化。`
    这条信息意味着PyMC生成的样本可能不可信。到目前为止，我们假设PyMC总是返回我们可以无问题使用的样本，但事实并非总是如此。在*第[10章](CH10.xhtml#x1-18900010)*中，我们将进一步讨论为什么会这样，并提供一些诊断方法，帮助你识别这些情况以及解决潜在问题的建议。在这一节中，我们也会解释什么是发散现象。现在，我们只想说，当使用分层线性模型时，我们通常会遇到很多发散现象。
- en: 'The easy way to solve them is to increase `target_accept`, as PyMC kindly suggests.
    This is an argument of `pm.sample()` that defaults to 0.8 and can take a maximum
    value of 1\. If you see divergences, setting this argument to values like 0.85,
    0.9, or even higher can help. But if you reach values like 0.99 and still have
    divergences, you are probably out of luck with this simple trick and you need
    to do something else. And that’s reparametrization. What is this? Reparametrization
    is writing a model in a different way, but that is mathematically equivalent to
    your original model: you are not changing the model, just writing it in another
    way. Many models, if not all, can be written in alternative ways. Sometimes, reparametrization
    can have a positive effect on the efficiency of the sampler or on the model’s
    interpretability. For instance, you can remove divergences by doing a reparametrization.
    Let’s see how to do that in the next section.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的简单方法是增加`target_accept`，正如PyMC亲切地建议的那样。它是`pm.sample()`的一个参数，默认值为0.8，最大值为1。如果你看到有发散现象，可以将这个参数设置为0.85、0.9，甚至更高值，这有助于解决问题。但如果你已经设置到0.99，仍然有发散现象，那么这种简单的方法可能就不奏效了，你需要采取其他措施。这就是重新参数化。那么，什么是重新参数化呢？重新参数化就是以一种不同的方式编写模型，但这在数学上与原始模型是等价的：你并没有改变模型，只是以另一种方式表达它。许多模型，如果不是所有模型，都可以用其他方式来编写。有时，重新参数化可以提高采样器的效率或模型的可解释性。例如，通过重新参数化，你可以消除发散现象。接下来我们将在下一节中讲解如何做到这一点。
- en: 4.8.1 Centered vs. noncentered hierarchical models
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.8.1 分层模型：集中式与非集中式
- en: 'There are two common parametrizations for hierarchical linear models, centered
    and non-centered. The `hierarchical_centered` model uses the centered one. The
    hallmark of this parametrization is that we are directly estimating parameters
    for individual groups; for instance, we are explicitly estimating the slope of
    each group. On the contrary, for the non-centered parametrization, we estimate
    the common slope for all groups and then a deflection for each group. It is important
    to notice that we are still modeling the slope of each group, but relative to
    the common slope, the information we are getting is the same, just represented
    differently. Since a model is worth a thousand words, let’s check `hierarchical_non_centered`:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 层次线性模型有两种常见的参数化方法，分别是中心化和非中心化。`hierarchical_centered`模型使用的是中心化方法。该参数化方法的特点是，我们直接为各个小组估计参数；例如，我们明确地估计每个小组的斜率。相反，对于非中心化参数化方法，我们为所有小组估计一个共同的斜率，然后为每个小组估计一个偏移量。需要注意的是，我们仍然是在为每个小组建模斜率，但相对于共同的斜率，所获得的信息是相同的，只是表达方式不同。因为模型胜过千言万语，我们来看看`hierarchical_non_centered`：
- en: '**Code 4.14**'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.14**'
- en: '[PRE13]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The difference is that for the model `hierarchical_centered`, we defined *β*
    ∼ ![](img/N.PNG)(*β*[*μ*]*,*β**[*σ*]), and for `hierarchical_non_centered` we
    did *β* = *β*[*μ*] + *β*[offset] * *β*[*σ*]. The non-centered parametrization
    is more efficient: when I run the model I only get 2 divergences instead of 148
    as before. To remove these remaining divergences, we may still need to increase
    `target_accept`. For this particular case, changing it from 0.8 to 0.85 worked
    like magic. To fully understand why this reparametrization works, you need to
    understand the geometry of the posterior distribution, but that’s beyond the scope
    of this section. Don’t worry, we will discuss this in *Chapter [10](CH10.xhtml#x1-18900010)*.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 区别在于，对于模型`hierarchical_centered`，我们定义了*β* ∼ ![](img/N.PNG)(*β*[*μ*]*,*β**[*σ*])，而对于`hierarchical_non_centered`，我们则定义了*β*
    = *β*[*μ*] + *β*[offset] * *β*[*σ*]。非中心化参数化更高效：当我运行模型时，只有2个发散点，而不是之前的148个。为了去除这些剩余的发散点，我们可能仍然需要增加`target_accept`。对于这个特定的案例，将其从0.8改为0.85效果非常好。要完全理解为什么这种重新参数化有效，你需要理解后验分布的几何结构，但这超出了本节的范围。别担心，我们会在*第[10章](CH10.xhtml#x1-18900010)*讨论这个问题。
- en: Now that our samples are divergence-free, we can go back to analyze the posterior.
    *Figure [4.17](#x1-90023r17)* shows the estimated values for *α* and *β* for `hierarchical_model`.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的样本没有发散点了，我们可以回去分析后验分布。*图[4.17](#x1-90023r17)*展示了`hierarchical_model`中*α*和*β*的估计值。
- en: '![PIC](img/file133.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file133.png)'
- en: '**Figure 4.17**: Posterior distribution for *α* and *β* for `hierarchical_non_centered`'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.17**：`hierarchical_non_centered`模型中*α*和*β*的后验分布'
- en: The estimates for group `H` are still the ones with higher uncertainty. But
    the results look less crazy than those in *Figure [4.16](#x1-89014r16)*; the reason
    is that groups are sharing information. Hence, even when we don’t have enough
    information to fit a line to a single point, group `H` *is being informed* by
    the other groups. Actually, all groups are informing all groups. This is the power
    of hierarchical models.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 小组`H`的估计值仍然具有较高的不确定性。但结果看起来比*图[4.16](#x1-89014r16)*中的要更合理；原因在于小组之间共享了信息。因此，即使我们没有足够的信息将一条线拟合到一个单一的点上，小组`H`也*受到了其他小组的影响*。实际上，所有小组都在相互影响。这就是层次模型的强大之处。
- en: '*Figure [4.18](#x1-90024r18)* shows the fitted lines for each of the eight
    groups. We can see that we managed to fit a line to a single point. At first,
    this may sound weird or even fishy, but this is just a consequence of the structure
    of the hierarchical model. Each line is informed by the lines of the other groups,
    thus we are not truly adjusting a line to a single point. Instead, we are adjusting
    a line that’s been informed by the points in the other groups to a single point.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '*图[4.18](#x1-90024r18)*展示了八个小组的拟合线。我们可以看到，尽管我们设法将一条直线拟合到一个单一的点上，乍一看这可能显得奇怪甚至可疑，但这只是层次模型结构的结果。每一条线都受到其他小组的影响，因此我们并非真正地将一条线拟合到一个单一的点，而是将一条已被其他小组数据所影响的线拟合到该点。'
- en: '![PIC](img/file134.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file134.png)'
- en: '**Figure 4.18**: Fitted lines for `hierarchical_non_centered`'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.18**：`hierarchical_non_centered`的拟合线'
- en: 4.9 Multiple linear regression
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.9 多元线性回归
- en: 'So far, we have been working with one dependent variable and one independent
    variable. Nevertheless, it is not unusual to have several independent variables
    that we want to include in our model. Some examples could be:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在处理一个因变量和一个自变量。然而，拥有多个自变量并将它们纳入模型是很常见的。一些例子可能是：
- en: Perceived quality of wine (dependent) and acidity, density, alcohol level, residual
    sugar, and sulfates content (independent variables)
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 葡萄酒的感知质量（因变量）和酸度、密度、酒精含量、残糖量、硫酸盐含量（自变量）
- en: A student’s average grades (dependent) and family income, distance from home
    to school, and mother’s education level (categorical variable)
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学生的平均成绩（因变量）和家庭收入、从家到学校的距离、母亲的教育水平（类别变量）
- en: We can easily extend the simple linear regression model to deal with more than
    one independent variable. We call this model multiple linear regression or, less
    often, multivariable linear regression (not to be confused with multivariate linear
    regression, the case where we have multiple dependent variables).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以很容易地将简单线性回归模型扩展到处理多个自变量。我们称这种模型为多元线性回归，或者较少使用的名称是多变量线性回归（不要与多元回归线性回归混淆，后者是指我们有多个因变量的情况）。
- en: 'In a multiple linear regression model, we model the mean of the dependent variable
    as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在多元线性回归模型中，我们将因变量的均值建模如下：
- en: '![μ = 𝛼 + 𝛽1X1 + 𝛽2X2 + ⋅⋅⋅+ 𝛽kXk ](img/file135.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![μ = 𝛼 + 𝛽1X1 + 𝛽2X2 + ⋅⋅⋅+ 𝛽kXk ](img/file135.jpg)'
- en: 'Using linear algebra notation, we can write a shorter version:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线性代数符号，我们可以写出更简短的版本：
- en: '![μ = 𝛼+ X𝛽 ](img/file136.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![μ = 𝛼+ X𝛽 ](img/file136.jpg)'
- en: '**X** is a matrix of size *n* × *k* with the values of the independent variables,
    *β* is a vector of size *k* with the coefficients of the independent variables,
    and *n* is the number of observations.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**X**是一个*n* × *k*大小的矩阵，包含自变量的值，*β*是一个*k*大小的向量，包含自变量的系数，*n*是观测值的数量。'
- en: 'If you are a little rusty with your linear algebra, you may want to check the
    Wikipedia article about the dot product between two vectors and its generalization
    to matrix multiplication: [https://en.wikipedia.org/wiki/Dot_product](https://en.wikipedia.org/wiki/Dot_product).
    Basically, what you need to know is that we are just using a shorter and more
    convenient way to write our model:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对线性代数有些生疏，可能需要查看维基百科关于两个向量的点积及其矩阵乘法推广的文章：[https://en.wikipedia.org/wiki/Dot_product](https://en.wikipedia.org/wiki/Dot_product)。基本上，你需要知道的是，我们只是在使用一种更简洁、方便的方式来书写我们的模型：
- en: '![ ∑n X 𝛽 = 𝛽iXi = 𝛽1X1 + 𝛽2X2 + ⋅⋅⋅+ 𝛽kXk i ](img/file137.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑n X 𝛽 = 𝛽iXi = 𝛽1X1 + 𝛽2X2 + ⋅⋅⋅+ 𝛽kXk i ](img/file137.jpg)'
- en: Using the simple linear regression model, we find a straight line that (hopefully)
    explains our data. Under the multiple linear regression model, we find, instead,
    a hyperplane of dimension *k*. Thus, the multiple linear regression model is essentially
    the same as the simple linear regression model, the only difference being that
    now *β* is a vector and **X** is a matrix.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 使用简单线性回归模型，我们找到了一条直线，能够（希望）解释我们的数据。而在多元线性回归模型下，我们得到的是一个维度为*k*的超平面。因此，多元线性回归模型本质上与简单线性回归模型相同，唯一的区别在于，现在*β*是一个向量，**X**是一个矩阵。
- en: To see an example of a
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下下面的例子
- en: 'multiple linear regression model, let’s go back to the bikes dataset. We will
    use the temperature and the humidity of the day to predict the number of rented
    bikes:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多元线性回归模型，让我们回到自行车数据集。我们将使用当天的温度和湿度来预测租赁的自行车数量：
- en: '**Code 4.15**'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码 4.15**'
- en: '[PRE14]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Please take a moment to compare `model_mlb`, which has two independent variables,
    `temperature` and `hour`, with `model_neg`, which only has one independent variable,
    `temperature`. The only difference is that now we have two *β* coefficients, one
    for each independent variable. The rest of the model is the same. Notice that
    we could have written *β* `= pm.Normal("`*β*`1", mu=0, sigma=10, shape=2)` and
    then used *β*`1[0]` and *β*`1[1]` in the definition of *μ*. I usually do that.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 请花一点时间对比`model_mlb`（有两个自变量：`temperature`和`hour`）和`model_neg`（只有一个自变量：`temperature`）。唯一的区别是现在我们有了两个*β*系数，每个自变量对应一个系数。模型的其余部分相同。注意，我们本来可以写作*β*`=
    pm.Normal("`*β*`1", mu=0, sigma=10, shape=2)`，然后在定义*μ*时使用*β*`1[0]`和*β*`1[1]`。我通常会这么做。
- en: As you can see, writing a multiple regression model is not that different from
    writing a simple regression model. Interpreting the results can be more challenging,
    though. For instance, the coefficient of `temperature` is now *β*[0] and the coefficient
    of `hour` is *β*[1]. We can still interpret the coefficients as the change in
    the dependent variable for a unit change in the independent variable. But now
    we have to be careful to specify which independent variable we are talking about.
    For instance, we can say that for a unit increase in the temperature, the number
    of rented bikes increases by *β*[0] units, while holding the value of `hour` constant.
    Or we can say that for a unit increase in the hour, the number of rented bikes
    increases by *β*[1] units, while holding the value of `temperature` constant.
    Also, the value of a coefficient for a given variable is dependent on what other
    variables we are including in the model. For instance, the coefficient of `temperature`
    will vary depending on whether we incorporate the variable `hour` into the model
    or not.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，编写多元回归模型与编写简单回归模型并没有太大不同。不过，解释结果可能更加具有挑战性。例如，`temperature`的系数现在是*β*[0]，而`hour`的系数是*β*[1]。我们仍然可以将系数解释为因变量在自变量变化一个单位时的变化量。但现在我们必须小心地指定我们正在讨论的是哪个自变量。例如，我们可以说，温度增加一个单位时，租赁自行车的数量增加*β*[0]个单位，同时保持`hour`的值不变。或者我们可以说，小时数增加一个单位时，租赁自行车的数量增加*β*[1]个单位，同时保持`temperature`的值不变。此外，某一变量的系数值取决于我们在模型中包含了哪些其他变量。例如，`temperature`的系数将根据是否将`hour`变量纳入模型而有所变化。
- en: '*Figure [4.19](#x1-91017r19)* shows the *β* coefficients for models `model_neg`
    (only `temperature`) and for model `model_mld` (`temperature` and `hour`).'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 [4.19](#x1-91017r19)* 显示了模型`model_neg`（仅有`temperature`）和模型`model_mld`（`temperature`和`hour`）的*β*系数。'
- en: '![PIC](img/file138.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file138.png)'
- en: '**Figure 4.19**: Scaled *β* coefficients for `model_neg` and `model_mlb`'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4.19**：`model_neg`和`model_mlb`的缩放*β*系数'
- en: We can see that the coefficient of `temperature` is different in both models.
    This is because the effect of `temperature` on the number of rented bikes depends
    on the hour of the day. Even more, the values of the *β* coefficients have been
    scaled by the standard deviation of their corresponding independent variable,
    so we can make them comparable. We can see that once we include `hour` in the
    model, the effect of `temperature` on the number of rented bikes gets smaller.
    This is because the effect of `hour` is already explaining some of the variations
    in the number of rented bikes that were previously explained by `temperature`.
    In extreme cases, the addition of a new variable can make the coefficient go to
    0 or even change the sign. We will discuss more of this in the next chapter.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，`temperature`的系数在两个模型中是不同的。这是因为`temperature`对租赁自行车数量的影响取决于一天中的小时数。更进一步，*β*系数的值已经通过其对应的独立变量的标准差进行了缩放，因此我们可以使它们具有可比性。我们可以看到，一旦在模型中加入了`hour`，`temperature`对租赁自行车数量的影响变得更小。这是因为`hour`的影响已经解释了之前由`temperature`解释的部分租赁自行车数量的变化。在极端情况下，新增一个变量可能会使系数变为0，甚至改变符号。我们将在下一章中进一步讨论这个问题。
- en: 4.10 Summary
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.10 总结
- en: In this chapter, we have learned about linear regression, which aims to model
    the relationship between a dependent variable and an independent variable. We
    have seen how to use PyMC to fit a linear regression model and how to interpret
    the results and make plots that we can share with different audiences.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了线性回归，旨在建立因变量与自变量之间的关系模型。我们了解了如何使用PyMC拟合线性回归模型，并如何解释结果和制作可以与不同受众分享的图表。
- en: Our first example was a model with a Gaussian response. But then we saw that
    this is just one assumption and we can easily change it to deal with non-Gaussian
    responses, such as count data, using a NegativeBinomial regression model or a
    logistic regression model for binary data. We saw that when doing so we also need
    to set an inverse link function to map the linear predictor to the response variable.
    Using a Student’s t-distribution as the likelihood can be useful for dealing with
    outliers. We spent most of the chapter modeling the mean as a linear function
    of the independent variable, but we learned that we can also model other parameters,
    like the variance. This is useful when we have heteroscedastic data. We learned
    how to apply the concept of partial pooling to create hierarchical linear regression
    models. Finally, we briefly discussed multiple linear regression models.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个例子是一个具有高斯响应的模型。但随后我们看到这只是一个假设，我们可以轻松地将其更改为处理非高斯响应，例如使用负二项回归模型处理计数数据，或使用逻辑回归模型处理二元数据。我们还看到，当这样做时，我们还需要设置一个逆链接函数，将线性预测器映射到响应变量。使用Student’s
    t分布作为似然函数对于处理异常值很有用。我们花费了大部分章节将均值建模为自变量的线性函数，但我们了解到我们也可以建模其他参数，如方差。当我们有异方差数据时，这非常有用。我们学会了如何应用部分汇聚的概念来创建层次线性回归模型。最后，我们简要讨论了多元线性回归模型。
- en: PyMC makes it very easy to implement all these different flavors of Bayesian
    linear regression by changing one or a few lines of code. In the next chapter,
    we will learn more about linear regression and we will learn about Bambi, a tool
    built on top of PyMC that makes it even easier to build and analyze linear regression
    models.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: PyMC通过修改一两行代码，使得实现各种贝叶斯线性回归变得非常简单。在下一章中，我们将学习更多关于线性回归的内容，并且我们将学习Bambi，这是一个构建在PyMC之上的工具，它使得构建和分析线性回归模型变得更加容易。
- en: 4.11 Exercises
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.11 练习
- en: Using the howell dataset (available at [https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)),
    create a linear model of the weight (x) against the height (y). Exclude subjects
    that are younger than 18\. Explain the results.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用howell数据集（可在[https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)获取），创建一个体重（x）与身高（y）之间的线性模型。排除18岁以下的受试者。解释结果。
- en: 'For four subjects, we get the weights (45.73, 65.8, 54.2, 32.59), but not their
    heights. Using the model from the previous exercise, predict the height for each
    subject, together with their 50% and 94% HDIs. Tip: Use `pm.MutableData`.'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于四个受试者，我们得到了体重（45.73, 65.8, 54.2, 32.59），但没有身高。使用前面的模型，预测每个受试者的身高，并给出他们的50%和94%
    HDI。提示：使用`pm.MutableData`。
- en: Repeat exercise 1, this time including those below 18 years old. Explain the
    results.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复练习1，这次包括18岁以下的受试者。解释结果。
- en: It is known for many species that weight does not scale with height, but with
    the logarithm of the weight. Use this information to fit the howell data (including
    subjects from all ages).
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 已知许多物种的体重与身高不成比例，而是与体重的对数成比例。使用这一信息来拟合howell数据（包括所有年龄段的受试者）。
- en: See the accompanying code `model_t2` (and the data associated with it). Experiment
    with priors for *ν*, like the non-shifted Exponential and Gamma priors (they are
    commented on in the code). Plot the prior distribution to ensure that you understand
    them. An easy way to do this is to call the `pm.sample_prior_predictive()` function
    instead of `pm.sample()`. You can also use PreliZ.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看附带的代码`model_t2`（以及与之相关的数据）。尝试不同的*ν*先验，例如未移位的指数分布和伽玛分布先验（它们在代码中有注释）。绘制先验分布，以确保你理解它们。一种简单的方法是调用`pm.sample_prior_predictive()`函数，而不是`pm.sample()`。你也可以使用PreliZ。
- en: Rerun `model_lrs` using the `petal_length` variable and then the `petal_width`
    variable. What are the main differences in the results? How wide or narrow is
    the 94% HDI in each case?
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`petal_length`变量重新运行`model_lrs`，然后使用`petal_width`变量。结果有哪些主要区别？在每种情况下，94% HDI的宽度是多大？
- en: Repeat the previous exercise, this time using a Student’s t-distribution as
    a weakly informative prior. Try different values of *ν*.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复前面的练习，这次使用Student’s t分布作为一个弱信息先验。尝试不同的*ν*值。
- en: Choose a dataset that you find interesting and use it with the simple linear
    regression model. Be sure to explore the results using ArviZ functions. If you
    do not have an interesting dataset, try searching online, for example, at [http://data.worldbank.org](http://data.worldbank.org)
    or [http://www.stat.ufl.edu/~winner/datasets.html](http://www.stat.ufl.edu/~winner/datasets.html).
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个你感兴趣的数据集，并使用简单线性回归模型进行分析。一定要利用 ArviZ 函数探索结果。如果你没有找到感兴趣的数据集，可以尝试在线搜索，例如，在
    [http://data.worldbank.org](http://data.worldbank.org) 或 [http://www.stat.ufl.edu/~winner/datasets.html](http://www.stat.ufl.edu/~winner/datasets.html)
    查找。
- en: Join our community Discord space
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我们的社区 Discord 空间
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at: [https://packt.link/bayesian](https://packt.link/bayesian)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区，与志同道合的人们一起学习，并与超过5000名成员共同成长，链接地址：[https://packt.link/bayesian](https://packt.link/bayesian)
- en: '![PIC](img/file1.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file1.png)'
