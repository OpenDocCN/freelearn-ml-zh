- en: ChapterÂ 4
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬4ç« 
- en: Modeling with Lines
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨çº¿æ€§æ¨¡å‹
- en: 'In more than three centuries of science everything has changed except perhaps
    one thing: the love for the simple. â€“ Jorge Wagensberg'
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨ä¸‰ç™¾å¤šå¹´çš„ç§‘å­¦å†å²ä¸­ï¼Œå”¯ä¸€æ²¡æœ‰æ”¹å˜çš„æˆ–è®¸åªæœ‰ä¸€ç‚¹ï¼šå¯¹ç®€å•çš„çƒ­çˆ±ã€‚â€“ ä¹”æ²»Â·ç“¦æ ¹æ–¯è´æ ¼
- en: Musicâ€”from classical compositions to *Sheena is a Punk Rocker* by The Ramones,
    passing through unrecognized hits from garage bands and Piazzollaâ€™s Libertangoâ€”is
    made of recurring patterns. The same scales, combinations of chords, riffs, motifs,
    and so on appear over and over again, giving rise to a wonderful sonic landscape
    capable of eliciting and modulating the entire range of emotions that humans can
    experience. Similarly, the universe of statistics is built upon recurring patterns,
    small motifs that appear now and again. In this chapter, we are going to look
    at one of the most popular and useful of them, the **linear** **model** (or motif,
    if you want). This is a very useful model on its own and also the building block
    of many other models. If youâ€™ve ever taken a statistics course, you may have heard
    of simple and multiple linear regression, logistic regression, ANOVA, ANCOVA,
    and so on. All these methods are variations of the same underlying motif, the
    linear regression model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: éŸ³ä¹â€”â€”ä»å¤å…¸ä½œå“åˆ°The Ramonesçš„*Sheena is a Punk Rocker*ï¼Œå†åˆ°è½¦åº“ä¹é˜Ÿçš„æœªè¢«è®¤å¯çš„çƒ­é—¨æ­Œæ›²ä»¥åŠçš®äºšä½æ‹‰çš„ã€Šè‡ªç”±æ¢æˆˆã€‹â€”â€”ç”±é‡å¤å‡ºç°çš„æ¨¡å¼æ„æˆã€‚ç›¸åŒçš„éŸ³é˜¶ã€å’Œå¼¦ç»„åˆã€å‰ä»–å³å…´ã€æ—‹å¾‹ç­‰åå¤å‡ºç°ï¼Œåˆ›é€ å‡ºä¸€ä¸ªç¾å¦™çš„éŸ³æ™¯ï¼Œèƒ½å¤Ÿæ¿€å‘å¹¶è°ƒèŠ‚äººç±»å¯èƒ½ä½“éªŒåˆ°çš„æ‰€æœ‰æƒ…æ„Ÿã€‚åŒæ ·ï¼Œç»Ÿè®¡å­¦çš„ä¸–ç•Œä¹Ÿæ˜¯å»ºç«‹åœ¨ä¸æ–­å‡ºç°çš„æ¨¡å¼ä¸Šçš„ï¼Œè¿™äº›å°çš„åŠ¨æœºæ—¶ä¸æ—¶åœ°å‡ºç°ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†å…³æ³¨å…¶ä¸­ä¸€ä¸ªæœ€æµè¡Œå’Œæœ‰ç”¨çš„æ¨¡å¼ï¼Œå³**çº¿æ€§**
    **æ¨¡å‹**ï¼ˆæˆ–è€…å¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥å«åšåŠ¨æœºï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„æ¨¡å‹ï¼Œç‹¬ç«‹ä½¿ç”¨æ—¶æ•ˆæœæ˜¾è‘—ï¼ŒåŒæ—¶ä¹Ÿæ˜¯è®¸å¤šå…¶ä»–æ¨¡å‹çš„åŸºç¡€ã€‚å¦‚æœä½ æ›¾ç»å­¦è¿‡ç»Ÿè®¡å­¦è¯¾ç¨‹ï¼Œä½ å¯èƒ½å¬è¯´è¿‡ç®€å•å’Œå¤šå…ƒçº¿æ€§å›å½’ã€é€»è¾‘å›å½’ã€æ–¹å·®åˆ†æï¼ˆANOVAï¼‰ã€åæ–¹å·®åˆ†æï¼ˆANCOVAï¼‰ç­‰æ–¹æ³•ã€‚æ‰€æœ‰è¿™äº›æ–¹æ³•éƒ½æ˜¯åŒä¸€ä¸ªåŸºæœ¬æ¨¡å¼â€”â€”çº¿æ€§å›å½’æ¨¡å‹â€”â€”çš„ä¸åŒå˜ä½“ã€‚
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« å°†æ¶‰åŠä»¥ä¸‹ä¸»é¢˜ï¼š
- en: Simple linear regression
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç®€å•çº¿æ€§å›å½’
- en: NegativeBinomial regression
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è´ŸäºŒé¡¹å›å½’
- en: Robust regression
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¨³å¥å›å½’
- en: Logistic regression
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€»è¾‘å›å½’
- en: Variable variance
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å˜é‡çš„æ–¹å·®
- en: Hierarchical linear regression
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å±‚æ¬¡çº¿æ€§å›å½’
- en: Multiple linear regression
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šå…ƒçº¿æ€§å›å½’
- en: 4.1 Simple linear regression
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 ç®€å•çº¿æ€§å›å½’
- en: Many problems we find in science, engineering, and business are of the following
    form. We have a variable *X* and we want to model or predict a variable *Y* .
    Importantly, these variables are paired like {(*x*[1]*,y*[1])*,*(*x*[2]*,y*[2])*,*![â‹…â‹…â‹…](img/file96.jpg)*,*(*x*[*n*]*,y*[*n*])}.
    In the most simple scenario, known as simple linear regression, both *X* and *Y*
    are uni-dimensional continuous random variables. By continuous, we mean a variable
    represented using real numbers. Using NumPy, you will represent these variables
    as one-dimensional arrays of floats. Usually, people call *Y* the dependent, predicted,
    or outcome variable, and *X* the independent, predictor, or input variable.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨ç§‘å­¦ã€å·¥ç¨‹å’Œå•†ä¸šä¸­é‡åˆ°çš„è®¸å¤šé—®é¢˜éƒ½å…·æœ‰ä»¥ä¸‹å½¢å¼ï¼šæˆ‘ä»¬æœ‰ä¸€ä¸ªå˜é‡*X*ï¼Œæˆ‘ä»¬æƒ³è¦å»ºæ¨¡æˆ–é¢„æµ‹ä¸€ä¸ªå˜é‡*Y*ã€‚é‡è¦çš„æ˜¯ï¼Œè¿™äº›å˜é‡æ˜¯æˆå¯¹çš„ï¼Œå¦‚{(*x*[1]*,y*[1])*,*(*x*[2]*,y*[2])*,*![â‹…â‹…â‹…](img/file96.jpg)*,*(*x*[*n*]*,y*[*n*])}ã€‚åœ¨æœ€ç®€å•çš„æƒ…å†µä¸‹ï¼Œå³ç®€å•çº¿æ€§å›å½’ä¸­ï¼Œ*X*å’Œ*Y*éƒ½æ˜¯ä¸€ç»´è¿ç»­éšæœºå˜é‡ã€‚æ‰€è°“è¿ç»­ï¼Œæ„å‘³ç€è¯¥å˜é‡ç”¨å®æ•°è¡¨ç¤ºã€‚ä½¿ç”¨NumPyï¼Œä½ å°†æŠŠè¿™äº›å˜é‡è¡¨ç¤ºä¸ºä¸€ç»´æµ®ç‚¹æ•°ç»„ã€‚é€šå¸¸ï¼Œäººä»¬ç§°*Y*ä¸ºå› å˜é‡ã€é¢„æµ‹å˜é‡æˆ–ç»“æœå˜é‡ï¼Œ*X*ä¸ºè‡ªå˜é‡ã€é¢„æµ‹å› å­æˆ–è¾“å…¥å˜é‡ã€‚
- en: 'Some typical situations where linear regression models can be used are the
    following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›å…¸å‹çš„çº¿æ€§å›å½’æ¨¡å‹åº”ç”¨åœºæ™¯å¦‚ä¸‹ï¼š
- en: 'Model the relationship between soil salinity and crop productivity. Then, answer
    questions such as: is the relationship linear? How strong is this relationship?'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡æ‹ŸåœŸå£¤ç›åˆ†ä¸ä½œç‰©ç”Ÿäº§åŠ›ä¹‹é—´çš„å…³ç³»ã€‚ç„¶åï¼Œå›ç­”ä¸€äº›é—®é¢˜ï¼Œæ¯”å¦‚ï¼šè¿™ç§å…³ç³»æ˜¯çº¿æ€§çš„å—ï¼Ÿè¿™ç§å…³ç³»æœ‰å¤šå¼ºï¼Ÿ
- en: Find a relationship between average chocolate consumption by country and the
    number of Nobel laureates in that country, and then understand why this relationship
    could be spurious.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰¾å‡ºå„å›½å¹³å‡å·§å…‹åŠ›æ¶ˆè´¹é‡ä¸è¯¥å›½è¯ºè´å°”å¥–å¾—ä¸»æ•°é‡ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶ç†è§£ä¸ºä½•è¿™ç§å…³ç³»å¯èƒ½æ˜¯è™šå‡çš„ã€‚
- en: Predict the gas bill (used for heating and cooking) of your house by using the
    solar radiation from the local weather report. How accurate is this prediction?
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡ä½¿ç”¨æœ¬åœ°å¤©æ°”æŠ¥å‘Šä¸­çš„å¤ªé˜³è¾å°„ï¼Œé¢„æµ‹ä½ å®¶çš„ç‡ƒæ°”è´¦å•ï¼ˆç”¨äºå–æš–å’Œçƒ¹é¥ªï¼‰ã€‚è¿™ä¸ªé¢„æµ‹æœ‰å¤šå‡†ç¡®ï¼Ÿ
- en: 'In *Chapter [2](CH02.xhtml#x1-440002)*, we saw the Normal model, which we define
    as:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*ç¬¬[2ç« ](CH02.xhtml#x1-440002)*ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†æ­£æ€æ¨¡å‹ï¼Œæˆ‘ä»¬å®šä¹‰å®ƒä¸ºï¼š
- en: '![ Î¼ âˆ¼ some prior Ïƒ âˆ¼ some other prior Y âˆ¼ ğ’© (Î¼,Ïƒ) ](img/file97.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![ Î¼ âˆ¼ æŸä¸ªå…ˆéªŒ Ïƒ âˆ¼ å¦ä¸€ä¸ªå…ˆéªŒ Y âˆ¼ ğ’© (Î¼,Ïƒ) ](img/file97.jpg)'
- en: 'The main idea of linear regression is to extend this model by adding a predictor
    variable *X* to the estimation of the mean *Î¼*:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§å›å½’çš„ä¸»è¦æ€æƒ³æ˜¯é€šè¿‡æ·»åŠ ä¸€ä¸ªé¢„æµ‹å˜é‡*X*æ¥æ‰©å±•æ­¤æ¨¡å‹ï¼Œä»¥ä¼°è®¡å‡å€¼*Î¼*ï¼š
- en: '![ ğ›¼ âˆ¼ a prior ğ›½ âˆ¼ another prior Ïƒ âˆ¼ some other prior Î¼ = ğ›¼ + ğ›½X Y âˆ¼ ğ’© (Î¼,Ïƒ)
    ](img/file98.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![ ğ›¼ âˆ¼ ä¸€ä¸ªå…ˆéªŒ ğ›½ âˆ¼ å¦ä¸€ä¸ªå…ˆéªŒ Ïƒ âˆ¼ å…¶ä»–å…ˆéªŒ Î¼ = ğ›¼ + ğ›½X Y âˆ¼ ğ’© (Î¼,Ïƒ) ](img/file98.jpg)'
- en: This model says that there is a linear relation between the variable *X* and
    the variable *Y* . But that relationship is not deterministic, because of the
    noise term *Ïƒ*. Additionally, the model says that the mean of *Y* is a linear
    function of *X*, with **intercept** *Î±* and **slope** *Î²*. The intercept tells
    us the value of *Y* when *X* = 0 and the slope tells us the change in *Y* per
    unit change in *X*. Because we donâ€™t know the values of *Î±*, *Î²*, or *Ïƒ* we set
    priors distribution over them.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹è¡¨ç¤ºå˜é‡ *X* ä¸å˜é‡ *Y* ä¹‹é—´å­˜åœ¨çº¿æ€§å…³ç³»ã€‚ä½†ç”±äºå™ªå£°é¡¹ *Ïƒ* çš„å­˜åœ¨ï¼Œè¿™ç§å…³ç³»å¹¶ä¸æ˜¯ç¡®å®šæ€§çš„ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¡¨ç¤º *Y* çš„å‡å€¼æ˜¯ *X*
    çš„çº¿æ€§å‡½æ•°ï¼Œå…·æœ‰**æˆªè·** *Î±* å’Œ**æ–œç‡** *Î²*ã€‚æˆªè·å‘Šè¯‰æˆ‘ä»¬å½“ *X* = 0 æ—¶ *Y* çš„å€¼ï¼Œæ–œç‡åˆ™å‘Šè¯‰æˆ‘ä»¬ *X* æ¯å˜åŒ–ä¸€ä¸ªå•ä½ï¼Œ*Y*
    ä¼šå‘ç”Ÿå¤šå°‘å˜åŒ–ã€‚ç”±äºæˆ‘ä»¬ä¸çŸ¥é“ *Î±*ã€*Î²* æˆ– *Ïƒ* çš„å…·ä½“å€¼ï¼Œå› æ­¤æˆ‘ä»¬ä¸ºå®ƒä»¬è®¾å®šäº†å…ˆéªŒåˆ†å¸ƒã€‚
- en: When setting priors for linear models we typically assume that they are independent.
    This assumption greatly simplifies setting priors because we then need to set
    three priors instead of one joint prior. At least in principle, *Î±* and *Î²* can
    take any value on the real line, thus it is common to use Normal priors for them.
    And because *Ïƒ* is a positive number, it is common to use a HalfNormal or Exponential
    prior for it.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸ºçº¿æ€§æ¨¡å‹è®¾å®šå…ˆéªŒæ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å‡è®¾å®ƒä»¬æ˜¯ç‹¬ç«‹çš„ã€‚è¿™ä¸ªå‡è®¾æå¤§ç®€åŒ–äº†å…ˆéªŒè®¾ç½®ï¼Œå› ä¸ºè¿™æ ·æˆ‘ä»¬åªéœ€è¦è®¾ç½®ä¸‰ä¸ªå…ˆéªŒï¼Œè€Œä¸æ˜¯ä¸€ä¸ªè”åˆå…ˆéªŒã€‚è‡³å°‘åŸåˆ™ä¸Šï¼Œ*Î±* å’Œ
    *Î²* å¯ä»¥å–å®æ•°çº¿ä¸Šçš„ä»»ä½•å€¼ï¼Œå› æ­¤é€šå¸¸ä½¿ç”¨æ­£æ€åˆ†å¸ƒä½œä¸ºå®ƒä»¬çš„å…ˆéªŒã€‚è€Œå› ä¸º *Ïƒ* æ˜¯ä¸€ä¸ªæ­£æ•°ï¼Œé€šå¸¸ä¸ºå…¶ä½¿ç”¨åŠæ­£æ€åˆ†å¸ƒæˆ–æŒ‡æ•°åˆ†å¸ƒä½œä¸ºå…ˆéªŒã€‚
- en: The values the intercept can take can vary a lot from one problem to another
    and for different domain knowledge. For many problems I have worked on, *Î±* is
    usually centered around 0 and with a standard deviation no larger than 1, but
    this is just my experience (almost anecdotal) with a small subset of problems
    and not something easy to transfer to other problems. Usually, it may be easier
    to have an informed guess for the slope (*Î²*). For instance, we may know the sign
    of the slope a priori; for example, we expect the variable weight to increase,
    on average, with the variable height. For *Ïƒ*, we can set it to a large value
    on the scale of the variable *Y* , for example, two times the value for its standard
    deviation. We should be careful of using the observed data to guesstimate priors;
    usually, it is fine if the data is used to avoid using very restrictive priors.
    If we donâ€™t have too much knowledge of the parameter, it makes sense to ensure
    our prior is vague. If we instead want more informative priors, then we should
    not get that information from the observed data; instead, we should get it from
    our domain knowledge.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æˆªè·çš„å€¼å¯ä»¥æ ¹æ®ä¸åŒçš„é—®é¢˜å’Œé¢†åŸŸçŸ¥è¯†æœ‰å¾ˆå¤§çš„å˜åŒ–ã€‚å¯¹äºæˆ‘æ›¾å¤„ç†è¿‡çš„è®¸å¤šé—®é¢˜ï¼Œ*Î±* é€šå¸¸å›´ç»• 0 ä¸­å¿ƒï¼Œä¸”æ ‡å‡†å·®ä¸è¶…è¿‡ 1ï¼Œä½†è¿™åªæ˜¯æˆ‘åœ¨ä¸€å°éƒ¨åˆ†é—®é¢˜ä¸Šçš„ç»éªŒï¼ˆå‡ ä¹æ˜¯è½¶äº‹æ€§è´¨çš„ï¼‰ï¼Œå¹¶ä¸æ˜¯å¯ä»¥è½»æ˜“è¿ç§»åˆ°å…¶ä»–é—®é¢˜çš„ç»éªŒã€‚é€šå¸¸ï¼Œé¢„æµ‹æ–œç‡ï¼ˆ*Î²*ï¼‰çš„å…ˆéªŒå€¼å¯èƒ½æ›´ä¸ºå®¹æ˜“ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½çŸ¥é“æ–œç‡çš„ç¬¦å·ï¼šä¾‹å¦‚ï¼Œæˆ‘ä»¬æœŸæœ›å˜é‡ä½“é‡ä¸èº«é«˜å˜é‡å¹³å‡å‘ˆæ­£ç›¸å…³ã€‚å¯¹äº
    *Ïƒ*ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶è®¾ç½®ä¸ºä¸å˜é‡ *Y* çš„å€¼åŒé‡çº§çš„å¤§å€¼ï¼Œä¾‹å¦‚æ˜¯å…¶æ ‡å‡†å·®çš„ä¸¤å€ã€‚æˆ‘ä»¬åº”è¯¥å°å¿ƒä¸è¦ä½¿ç”¨è§‚å¯Ÿæ•°æ®æ¥æ¨æµ‹å…ˆéªŒï¼›é€šå¸¸ï¼Œæ•°æ®ç”¨æ¥é¿å…ä½¿ç”¨è¿‡äºä¸¥æ ¼çš„å…ˆéªŒæ˜¯å¯ä»¥æ¥å—çš„ã€‚å¦‚æœæˆ‘ä»¬å¯¹å‚æ•°çŸ¥ä¹‹ç”šå°‘ï¼Œé‚£ä¹ˆç¡®ä¿æˆ‘ä»¬çš„å…ˆéªŒå…·æœ‰æ¨¡ç³Šæ€§æ˜¯åˆä¹é€»è¾‘çš„ã€‚å¦‚æœæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨æ›´å…·ä¿¡æ¯é‡çš„å…ˆéªŒï¼Œé‚£ä¹ˆä¸åº”ä»è§‚å¯Ÿæ•°æ®ä¸­è·å–è¿™äº›ä¿¡æ¯ï¼Œè€Œåº”ä»æˆ‘ä»¬çš„é¢†åŸŸçŸ¥è¯†ä¸­è·å¾—ã€‚
- en: Extending the Normal Model
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰©å±•å¸¸è§„æ¨¡å‹
- en: A linear regression model is an extension of the Normal model where the mean
    is computed as a linear function of a predictor variable.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§å›å½’æ¨¡å‹æ˜¯å¸¸è§„æ¨¡å‹çš„æ‰©å±•ï¼Œå…¶ä¸­å‡å€¼æ˜¯ä½œä¸ºé¢„æµ‹å˜é‡çš„çº¿æ€§å‡½æ•°è®¡ç®—çš„ã€‚
- en: 4.2 Linear bikes
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 çº¿æ€§å•è½¦æ¨¡å‹
- en: We now have a general idea of what Bayesian linear models look like. Letâ€™s try
    to cement that idea with an example. We are going to start very simply; we have
    a record of temperatures and the number of bikes rented in a city. We want to
    model the relationship between the temperature and the number of bikes rented.
    *Figure [4.1](#x1-78002r1)* shows a scatter plot of these two variables from the
    bike-sharing dataset from the UCI Machine Learning Repository ( [https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯¹è´å¶æ–¯çº¿æ€§æ¨¡å‹æœ‰äº†ä¸€ä¸ªå¤§è‡´çš„äº†è§£ã€‚è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªä¾‹å­æ¥å·©å›ºè¿™ä¸ªæ¦‚å¿µã€‚æˆ‘ä»¬å°†ä»ä¸€ä¸ªéå¸¸ç®€å•çš„ä¾‹å­å¼€å§‹ï¼šæˆ‘ä»¬æœ‰ä¸€åº§åŸå¸‚çš„æ¸©åº¦è®°å½•å’Œç§Ÿèµè‡ªè¡Œè½¦çš„æ•°é‡ã€‚æˆ‘ä»¬æƒ³è¦å»ºç«‹æ¸©åº¦å’Œç§Ÿèµè‡ªè¡Œè½¦æ•°é‡ä¹‹é—´çš„å…³ç³»æ¨¡å‹ã€‚*å›¾
    [4.1](#x1-78002r1)* æ˜¾ç¤ºäº†æ¥è‡ªUCIæœºå™¨å­¦ä¹ åº“çš„å…±äº«å•è½¦æ•°æ®é›†è¿™ä¸¤ä¸ªå˜é‡çš„æ•£ç‚¹å›¾ï¼ˆ[https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)ï¼‰ã€‚
- en: '![PIC](img/file99.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file99.png)'
- en: '**FigureÂ 4.1**: Bike-sharing dataset. Scatter plot of temperature in Celcius
    vs. number of rented bikes'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.1**ï¼šè‡ªè¡Œè½¦å…±äº«æ•°æ®é›†ã€‚æ‘„æ°æ¸©åº¦ä¸ç§Ÿç”¨è‡ªè¡Œè½¦æ•°é‡çš„æ•£ç‚¹å›¾'
- en: 'The original dataset contains 17,379 records, and each record has 17 variables.
    We will only use 359 records and two variables, `temperature` (Celcius) `rented`
    (number of rented bikes). We are going to use`temperature` as our independent
    variable (our X) and the number of bikes rented as our dependent variable (our
    Y). We are going to use the following model:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹æ•°æ®é›†åŒ…å« 17,379 æ¡è®°å½•ï¼Œæ¯æ¡è®°å½•æœ‰ 17 ä¸ªå˜é‡ã€‚æˆ‘ä»¬å°†åªä½¿ç”¨ 359 æ¡è®°å½•å’Œä¸¤ä¸ªå˜é‡ï¼Œ`temperature`ï¼ˆæ‘„æ°æ¸©åº¦ï¼‰å’Œ `rented`ï¼ˆç§Ÿç”¨çš„è‡ªè¡Œè½¦æ•°é‡ï¼‰ã€‚æˆ‘ä»¬å°†ä½¿ç”¨
    `temperature` ä½œä¸ºè‡ªå˜é‡ï¼ˆæˆ‘ä»¬çš„ Xï¼‰ï¼Œç§Ÿç”¨çš„è‡ªè¡Œè½¦æ•°é‡ä½œä¸ºå› å˜é‡ï¼ˆæˆ‘ä»¬çš„ Yï¼‰ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹æ¨¡å‹ï¼š
- en: '**CodeÂ 4.1**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.1**'
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Take a moment to read the code line by line and be sure to understand what is
    going on. Also check *Figure [4.2](#x1-78012r2)* for a visual representation of
    this model.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: èŠ±ç‚¹æ—¶é—´é€è¡Œé˜…è¯»ä»£ç ï¼Œç¡®ä¿ç†è§£ä»£ç çš„å«ä¹‰ã€‚åŒæ—¶æŸ¥çœ‹ *å›¾ [4.2](#x1-78012r2)*ï¼Œä»¥è·å¾—è¯¥æ¨¡å‹çš„å¯è§†åŒ–è¡¨ç¤ºã€‚
- en: '![PIC](img/file100.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file100.png)'
- en: '**FigureÂ 4.2**: Bayesian linear model for the bike-sharing dataset'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.2**ï¼šè‡ªè¡Œè½¦å…±äº«æ•°æ®é›†çš„è´å¶æ–¯çº¿æ€§æ¨¡å‹'
- en: As we have previously said, this is like a Normal model, but now the mean is
    modeled as a linear function of the temperature. The intercept is *Î±* and the
    slope is *Î²*. The noise term is ![](img/e.png) and the mean is *Î¼*. The only new
    thing here is the `Deterministic` variable *Î¼*. This variable is not a random
    variable, it is a deterministic variable, and it is computed from the intercept,
    the slope, and the temperature. We need to specify this variable because we want
    to save it in InferenceData for later use. We could have just written *Î¼* `=`
    *Î±* `+` *Î²* `* bikes.temperature` or even `_ = pm.Normal(â€™y_predâ€™, mu=`*Î±* `+`
    *Î²* `* bikes.temperature, ...` and the model will be the same, but we would not
    have been able to save *Î¼* in InferenceData. Notice that *Î¼* is a vector with
    the same length as `bikes.temperature`, which is the same as the number of records
    in the dataset.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬ä¹‹å‰æ‰€è¯´ï¼Œè¿™ç±»ä¼¼äºä¸€ä¸ªæ­£æ€æ¨¡å‹ï¼Œä½†ç°åœ¨å‡å€¼è¢«å»ºæ¨¡ä¸ºæ¸©åº¦çš„çº¿æ€§å‡½æ•°ã€‚æˆªè·æ˜¯ *Î±*ï¼Œæ–œç‡æ˜¯ *Î²*ã€‚å™ªå£°é¡¹æ˜¯ ![](img/e.png)ï¼Œå‡å€¼æ˜¯
    *Î¼*ã€‚è¿™é‡Œå”¯ä¸€çš„æ–°ä¸œè¥¿æ˜¯ `Deterministic` å˜é‡ *Î¼*ã€‚è¿™ä¸ªå˜é‡ä¸æ˜¯éšæœºå˜é‡ï¼Œè€Œæ˜¯ä¸€ä¸ªç¡®å®šæ€§å˜é‡ï¼Œå®ƒç”±æˆªè·ã€æ–œç‡å’Œæ¸©åº¦è®¡ç®—å¾—å‡ºã€‚æˆ‘ä»¬éœ€è¦æŒ‡å®šè¿™ä¸ªå˜é‡ï¼Œå› ä¸ºæˆ‘ä»¬å¸Œæœ›å°†å…¶ä¿å­˜åœ¨
    InferenceData ä¸­ä»¥å¤‡åç»­ä½¿ç”¨ã€‚æˆ‘ä»¬æœ¬å¯ä»¥å†™ *Î¼* `=` *Î±* `+` *Î²* `* bikes.temperature`ï¼Œç”šè‡³å¯ä»¥å†™æˆ
    `_ = pm.Normal('y_pred', mu=`*Î±* `+` *Î²* `* bikes.temperature, ...`ï¼Œæ¨¡å‹ä¼šä¿æŒä¸å˜ï¼Œä½†æˆ‘ä»¬å°†æ— æ³•å°†
    *Î¼* ä¿å­˜åœ¨ InferenceData ä¸­ã€‚æ³¨æ„ï¼Œ*Î¼* æ˜¯ä¸€ä¸ªä¸ `bikes.temperature` é•¿åº¦ç›¸åŒçš„å‘é‡ï¼Œå®ƒä¸æ•°æ®é›†ä¸­çš„è®°å½•æ•°ç›¸åŒã€‚
- en: 4.2.1 Interpreting the posterior mean
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.1 è§£é‡ŠåéªŒå‡å€¼
- en: 'To explore the results of our inference, we are going to generate a posterior
    plot but omit the deterministic variable *Î¼*. We commit it because otherwise,
    we would get a lot of plots, one for each value of `temperature`. We can do this
    by passing the names of the variables we want to include in the plot as a list
    to the `var_names` argument or we can negate the variable that we want to exclude
    as in the following block of code:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¢ç´¢æ¨æ–­ç»“æœï¼Œæˆ‘ä»¬å°†ç”Ÿæˆä¸€ä¸ªåéªŒå›¾ï¼Œä½†ä¼šçœç•¥ç¡®å®šæ€§å˜é‡ *Î¼*ã€‚æˆ‘ä»¬è¿™æ ·åšæ˜¯å› ä¸ºå¦‚æœä¸çœç•¥è¯¥å˜é‡ï¼Œæˆ‘ä»¬å°†å¾—åˆ°å¾ˆå¤šå›¾è¡¨ï¼Œæ¯ä¸ª `temperature`
    å€¼å¯¹åº”ä¸€ä¸ªå›¾è¡¨ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†æˆ‘ä»¬æƒ³è¦åŒ…å«åœ¨å›¾è¡¨ä¸­çš„å˜é‡åä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™ `var_names` å‚æ•°ï¼Œæˆ–è€…åƒä»¥ä¸‹ä»£ç å—ä¸­é‚£æ ·å¦å®šæˆ‘ä»¬æƒ³è¦æ’é™¤çš„å˜é‡ï¼š
- en: '**CodeÂ 4.2**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.2**'
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![PIC](img/file101.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file101.png)'
- en: '**FigureÂ 4.3**: Posterior plot for the bike linear model'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.3**ï¼šè‡ªè¡Œè½¦çº¿æ€§æ¨¡å‹çš„åéªŒå›¾'
- en: From *Figure [4.3](#x1-79005r3)*, we can see the marginal posterior distribution
    for *Î±*, *Î²*, and *Ïƒ*. If we only read the means of each distribution, say *Î¼*
    = 69 + 7*.*9*X*, with this information we can say that the expected value of rented
    bikes when the temperature is 0 is 69, and for each degree of temperature the
    number of rented bikes increases by 7.9\. So for a temperature of 28 degrees,
    we expect to rent 69 + 7*.*9 âˆ— 28 â‰ˆ 278 bikes. This is our expectation, but the
    posterior also informs us about the uncertainty around this estimate. For instance,
    the 94% HDI for *Î²* is (6.1, 9.7), so for each degree of temperature the number
    of rented bikes could increase from 6 to about 10\. Also even if we omit the posterior
    uncertainty and we only pay attention to the means, we still have uncertainty
    about the number of rented bikes because we have a value of *Ïƒ* of 170\. So if
    we say that for a temperature of 28 degrees, we expect to rent 278 bikes, we should
    not be surprised if the actual number turns out to be somewhere between 100 and
    500 bikes.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä»*å›¾ [4.3](#x1-79005r3)*ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°*Î±*ã€*Î²*å’Œ*Ïƒ*çš„è¾¹é™…åéªŒåˆ†å¸ƒã€‚å¦‚æœæˆ‘ä»¬åªè¯»å–æ¯ä¸ªåˆ†å¸ƒçš„å‡å€¼ï¼Œæ¯”å¦‚*Î¼* = 69
    + 7*.*9*X*ï¼Œé€šè¿‡è¿™äº›ä¿¡æ¯æˆ‘ä»¬å¯ä»¥å¾—å‡ºï¼Œæ¸©åº¦ä¸º0æ—¶ç§Ÿèµè‡ªè¡Œè½¦çš„é¢„æœŸæ•°é‡ä¸º69è¾†ï¼Œæ¯å‡é«˜1åº¦æ¸©åº¦ï¼Œç§Ÿèµçš„è‡ªè¡Œè½¦æ•°é‡å¢åŠ 7.9è¾†ã€‚å› æ­¤ï¼Œå½“æ¸©åº¦ä¸º28åº¦æ—¶ï¼Œæˆ‘ä»¬é¢„æœŸç§Ÿèµ278è¾†è‡ªè¡Œè½¦ï¼Œå³69
    + 7*.*9 âˆ— 28 â‰ˆ 278è¾†ã€‚è¿™æ˜¯æˆ‘ä»¬çš„é¢„æœŸå€¼ï¼Œä½†åéªŒåˆ†å¸ƒä¹Ÿå‘Šè¯‰æˆ‘ä»¬è¿™ä¸ªä¼°è®¡å€¼çš„å‘¨å›´ä¸ç¡®å®šæ€§ã€‚ä¾‹å¦‚ï¼Œ*Î²*çš„94% HDIä¸ºï¼ˆ6.1, 9.7ï¼‰ï¼Œæ‰€ä»¥æ¯å‡é«˜1åº¦æ¸©åº¦ï¼Œç§Ÿèµçš„è‡ªè¡Œè½¦æ•°é‡å¯èƒ½å¢åŠ 6è¾†è‡³çº¦10è¾†ã€‚æ­¤å¤–ï¼Œå³ä½¿æˆ‘ä»¬å¿½ç•¥åéªŒä¸ç¡®å®šæ€§ï¼Œåªå…³æ³¨å‡å€¼ï¼Œæˆ‘ä»¬ä»ç„¶å¯¹ç§Ÿèµè‡ªè¡Œè½¦æ•°é‡æœ‰ä¸ç¡®å®šæ€§ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰ä¸€ä¸ª*Ïƒ*å€¼ä¸º170ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬è¯´æ¸©åº¦ä¸º28åº¦æ—¶æˆ‘ä»¬é¢„æœŸç§Ÿèµ278è¾†è‡ªè¡Œè½¦ï¼Œæˆ‘ä»¬ä¹Ÿä¸åº”è¯¥æ„Ÿåˆ°æƒŠè®¶ï¼Œå®é™…æ•°é‡å¯èƒ½åœ¨100åˆ°500è¾†ä¹‹é—´ã€‚
- en: Now letâ€™s create a few plots that will help us visualize the combined uncertainty
    of these parameters. Letâ€™s start with two plots for the mean (see *Figure [4.4](#x1-79007r4)*).
    Both are plots of the mean number of rented bikes as a function of the temperature.
    The difference is how we represent the uncertainty. We show two popular ways of
    doing it. In the left subpanel, we take 50 samples from the posterior and plot
    them as individual lines. In the right subpanel, we instead take all the available
    posterior samples for *Î¼* and use them to compute the 94% HDI.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€äº›å›¾è¡¨ï¼Œå¸®åŠ©æˆ‘ä»¬å¯è§†åŒ–è¿™äº›å‚æ•°çš„ç»¼åˆä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬ä»ä¸¤ä¸ªå›¾å¼€å§‹ï¼Œå±•ç¤ºå‡å€¼ï¼ˆè§*å›¾ [4.4](#x1-79007r4)*ï¼‰ã€‚è¿™ä¸¤ä¸ªå›¾éƒ½æ˜¯æ¸©åº¦ä½œä¸ºè‡ªå˜é‡æ—¶ç§Ÿèµè‡ªè¡Œè½¦æ•°é‡çš„å‡å€¼å›¾ã€‚ä¸åŒä¹‹å¤„åœ¨äºæˆ‘ä»¬å¦‚ä½•è¡¨ç¤ºä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬å±•ç¤ºäº†ä¸¤ç§å¸¸è§çš„è¡¨ç¤ºæ–¹æ³•ã€‚åœ¨å·¦ä¾§å­é¢æ¿ä¸­ï¼Œæˆ‘ä»¬ä»åéªŒåˆ†å¸ƒä¸­æŠ½å–50ä¸ªæ ·æœ¬ï¼Œå¹¶å°†å®ƒä»¬ä½œä¸ºå•ç‹¬çš„çº¿æ¡ç»˜åˆ¶ã€‚åœ¨å³ä¾§å­é¢æ¿ä¸­ï¼Œæˆ‘ä»¬åˆ™é‡‡ç”¨æ‰€æœ‰å¯ç”¨çš„åéªŒæ ·æœ¬æ¥è®¡ç®—94%çš„HDIã€‚
- en: '![PIC](img/file102.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file102.png)'
- en: '**FigureÂ 4.4**: Posterior plot for the bike linear model'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.4**ï¼šè‡ªè¡Œè½¦çº¿æ€§æ¨¡å‹çš„åéªŒå›¾'
- en: The plots in *Figure [4.4](#x1-79007r4)* convey essentially the same information,
    but one represents uncertainty as a set of lines and the other as a shaded area.
    Notice that if you repeat the code to generate the plot, you will get different
    lines, because we are sampling from the posterior. The shaded area, however, will
    be the same, because we are using all the available posterior samples. If we go
    further and refit the model, we will not only get different lines but the shaded
    area could also change, and probably the difference between runs is going to be
    very small; if not, you probably need to increase the number of draws, or there
    is something funny about your model and sampling (see *Chapter [10](CH10.xhtml#x1-18900010)*
    for guidance).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [4.4](#x1-79007r4)*ä¸­çš„å›¾è¡¨ä¼ è¾¾çš„åŸºæœ¬ç›¸åŒçš„ä¿¡æ¯ï¼Œåªæ˜¯å…¶ä¸­ä¸€ä¸ªé€šè¿‡ä¸€ç»„çº¿æ¡è¡¨ç¤ºä¸ç¡®å®šæ€§ï¼Œå¦ä¸€ä¸ªåˆ™é€šè¿‡é˜´å½±åŒºåŸŸè¡¨ç¤ºã€‚è¯·æ³¨æ„ï¼Œå¦‚æœä½ é‡å¤ä»£ç ç”Ÿæˆå›¾è¡¨ï¼Œä½ ä¼šå¾—åˆ°ä¸åŒçš„çº¿æ¡ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨ä»åéªŒåˆ†å¸ƒä¸­é‡‡æ ·ã€‚ç„¶è€Œï¼Œé˜´å½±åŒºåŸŸå°†ä¿æŒä¸å˜ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨äº†æ‰€æœ‰å¯ç”¨çš„åéªŒæ ·æœ¬ã€‚å¦‚æœæˆ‘ä»¬è¿›ä¸€æ­¥æ‹Ÿåˆæ¨¡å‹ï¼Œæˆ‘ä»¬ä¸ä»…ä¼šå¾—åˆ°ä¸åŒçš„çº¿æ¡ï¼Œé˜´å½±åŒºåŸŸä¹Ÿå¯èƒ½å‘ç”Ÿå˜åŒ–ï¼Œå¹¶ä¸”ä¸åŒè¿è¡Œä¹‹é—´çš„å·®å¼‚å¯èƒ½éå¸¸å°ï¼›å¦‚æœå·®å¼‚å¾ˆå¤§ï¼Œå¯èƒ½éœ€è¦å¢åŠ æŠ½æ ·æ¬¡æ•°ï¼Œæˆ–è€…æ¨¡å‹å’Œé‡‡æ ·å­˜åœ¨é—®é¢˜ï¼ˆæœ‰å…³æŒ‡å¯¼ï¼Œè¯·å‚è§*ç¬¬
    [10](CH10.xhtml#x1-18900010)ç« *ï¼‰ã€‚'
- en: Anyway, why are we showing two slightly different plots if they convey the same
    information? Well, to highlight that there are different ways to represent uncertainty.
    Which one is better? As usual, that is context-dependent. The shaded area is a
    good option; it is very common, and it is simple to compute and interpret. Unless
    there are specific reasons to show individual posterior samples, the shaded area
    may be your preferred choice. But we may want to show individual posterior samples.
    For instance, most of the lines might span a certain region, but we get a few
    with very high slopes. A shaded area could hide that information. When showing
    individual samples from the posterior it may be a good idea to animate them if
    you are showing them in a presentation or a video (see [Kale etÂ al.](Bibliography.xhtml#Xkale_2018)Â [[2019](Bibliography.xhtml#Xkale_2018)]
    for more on this).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ç®¡æ€æ ·ï¼Œä¸ºä»€ä¹ˆæˆ‘ä»¬è¦å±•ç¤ºä¸¤ä¸ªç•¥æœ‰ä¸åŒçš„å›¾ï¼Œå®ƒä»¬ä¼ è¾¾çš„æ˜¯ç›¸åŒçš„ä¿¡æ¯å‘¢ï¼Ÿå—¯ï¼Œè¿™æ˜¯ä¸ºäº†çªå‡ºä¸åŒçš„æ–¹å¼æ¥è¡¨ç¤ºä¸ç¡®å®šæ€§ã€‚å“ªç§æ›´å¥½ï¼Ÿåƒå¾€å¸¸ä¸€æ ·ï¼Œè¿™å–å†³äºå…·ä½“çš„ä¸Šä¸‹æ–‡ã€‚é˜´å½±åŒºåŸŸæ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ï¼›å®ƒéå¸¸å¸¸è§ï¼Œä¸”è®¡ç®—å’Œè§£é‡Šéƒ½å¾ˆç®€å•ã€‚é™¤éæœ‰ç‰¹å®šçš„åŸå› éœ€è¦å±•ç¤ºå•ä¸ªåéªŒæ ·æœ¬ï¼Œå¦åˆ™é˜´å½±åŒºåŸŸå¯èƒ½æ˜¯ä½ é¦–é€‰çš„æ–¹å¼ã€‚ä½†æˆ‘ä»¬ä¹Ÿè®¸å¸Œæœ›å±•ç¤ºå•ä¸ªåéªŒæ ·æœ¬ã€‚ä¾‹å¦‚ï¼Œå¤§å¤šæ•°çº¿æ¡å¯èƒ½è¦†ç›–æŸä¸ªåŒºåŸŸï¼Œä½†æˆ‘ä»¬å¾—åˆ°ä¸€äº›æ–œç‡éå¸¸å¤§çš„çº¿æ¡ã€‚é˜´å½±åŒºåŸŸå¯èƒ½ä¼šæ©ç›–è¿™äº›ä¿¡æ¯ã€‚å¦‚æœä½ åœ¨å±•ç¤ºå•ä¸ªåéªŒæ ·æœ¬æ—¶ï¼Œå¯èƒ½å¯ä»¥è€ƒè™‘å°†å…¶åšæˆåŠ¨ç”»ï¼Œç‰¹åˆ«æ˜¯å½“ä½ åœ¨æ¼”ç¤ºæˆ–è§†é¢‘ä¸­å±•ç¤ºæ—¶ï¼ˆè¯¦è§[Kale
    ç­‰äºº](Bibliography.xhtml#Xkale_2018) [[2019](Bibliography.xhtml#Xkale_2018)]äº†è§£æ›´å¤šï¼‰ã€‚
- en: 'Another reason to show you the two plots in *Figure [4.4](#x1-79007r4)* is
    that you can learn different ways of extracting information from the posterior.
    Please pay attention to the next block of code. For clarity, we have omitted the
    code for plotting and we only show the core computations:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å‘ä½ å±•ç¤º*å›¾ [4.4](#x1-79007r4)*ä¸­çš„ä¸¤ä¸ªå›¾çš„å¦ä¸€ä¸ªåŸå› æ˜¯ï¼Œä½ å¯ä»¥å­¦ä¹ ä»åéªŒä¸­æå–ä¿¡æ¯çš„ä¸åŒæ–¹å¼ã€‚è¯·æ³¨æ„æ¥ä¸‹æ¥çš„ä»£ç å—ã€‚ä¸ºäº†æ¸…æ™°èµ·è§ï¼Œæˆ‘ä»¬çœç•¥äº†ç»˜å›¾ä»£ç ï¼Œåªå±•ç¤ºæ ¸å¿ƒè®¡ç®—ï¼š
- en: '**CodeÂ 4.3**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.3**'
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can see that in the first line, we used `az.extract`. This function takes
    the `chain` and `draw` dimensions and stacks them in a single `sample` dimension,
    which can be useful for later processing. Additionally, we use the `num_samples`
    argument to ask for a subsample from the posterior. By default, `az.extract` will
    operate on the posterior group. If you want to extract information from another
    group, you can use the `group` argument. On the second line, we define a DataArray
    called `x_plot`, with equally spaced values ranging from the minimum to the maximum
    observed temperatures. The reason to create a DataArray is to be able to use Xarrayâ€™s
    automatic alignment capabilities in the next two lines. If we use a NumPy array,
    we will need to add extra dimensions, which is usually confusing. The best way
    to fully understand what I mean is to define `x_plot = np.linspace(bikes.temperature.min(),
    bikes.temperature.max())` and try to redo the plot. In the third line of code,
    we compute the mean of the posterior for *Î¼* for each value of `x_plot`, and in
    the fourth line, we compute individual values for *Î¼*. In these two lines we could
    have used `posterior[â€™`*Î¼*`â€™]`, but instead, we explicitly rewrite the linear
    model. We do this with the hope that it will help you to gain more intuition about
    linear models.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥çœ‹åˆ°åœ¨ç¬¬ä¸€è¡Œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†`az.extract`ã€‚è¿™ä¸ªå‡½æ•°å°†`chain`å’Œ`draw`ç»´åº¦å †å åˆ°ä¸€ä¸ªå•ä¸€çš„`sample`ç»´åº¦ä¸­ï¼Œè¿™åœ¨åç»­å¤„ç†æ—¶å¯èƒ½ä¼šå¾ˆæœ‰ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨`num_samples`å‚æ•°ä»åéªŒä¸­è¯·æ±‚ä¸€ä¸ªå­æ ·æœ¬ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ`az.extract`ä¼šä½œç”¨äºåéªŒç»„ã€‚å¦‚æœä½ æƒ³ä»å¦ä¸€ä¸ªç»„æå–ä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨`group`å‚æ•°ã€‚åœ¨ç¬¬äºŒè¡Œä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå«åš`x_plot`çš„DataArrayï¼ŒåŒ…å«ä»æœ€å°åˆ°æœ€å¤§è§‚æµ‹æ¸©åº¦çš„ç­‰é—´è·å€¼ã€‚åˆ›å»ºDataArrayçš„åŸå› æ˜¯èƒ½å¤Ÿåœ¨æ¥ä¸‹æ¥çš„ä¸¤è¡Œä¸­ä½¿ç”¨Xarrayçš„è‡ªåŠ¨å¯¹é½åŠŸèƒ½ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨NumPyæ•°ç»„ï¼Œåˆ™éœ€è¦æ·»åŠ é¢å¤–çš„ç»´åº¦ï¼Œè¿™é€šå¸¸ä¼šä»¤äººå›°æƒ‘ã€‚ä¸ºäº†æ›´å¥½åœ°ç†è§£æˆ‘çš„æ„æ€ï¼Œæœ€å¥½çš„æ–¹å¼æ˜¯å®šä¹‰`x_plot
    = np.linspace(bikes.temperature.min(), bikes.temperature.max())`å¹¶å°è¯•é‡æ–°ç»˜åˆ¶å›¾å½¢ã€‚åœ¨ä»£ç çš„ç¬¬ä¸‰è¡Œï¼Œæˆ‘ä»¬è®¡ç®—äº†åéªŒä¸­*Î¼*çš„å‡å€¼ï¼Œé’ˆå¯¹æ¯ä¸ª`x_plot`çš„å€¼ï¼›åœ¨ç¬¬å››è¡Œï¼Œæˆ‘ä»¬è®¡ç®—äº†*Î¼*çš„ä¸ªåˆ«å€¼ã€‚åœ¨è¿™ä¸¤è¡Œä¸­ï¼Œæˆ‘ä»¬æœ¬å¯ä»¥ä½¿ç”¨`posterior[â€™`*Î¼*`â€™]`ï¼Œä½†æˆ‘ä»¬æ˜¾å¼åœ°é‡å†™äº†çº¿æ€§æ¨¡å‹ã€‚æˆ‘ä»¬è¿™æ ·åšçš„ç›®çš„æ˜¯å¸Œæœ›èƒ½å¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£çº¿æ€§æ¨¡å‹ã€‚
- en: 4.2.2 Interpreting the posterior predictions
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.2 è§£é‡ŠåéªŒé¢„æµ‹
- en: What if we are not just interested in the expected (mean) value, but we want
    to think in terms of predictions, that is, in terms of rented bikes? Well, for
    that, we can do posterior predictive sampling. After executing the next line of
    code, `idata_lb` will be populated with a new group, `posterior_predictive`, with
    a variable, `y_pred`, representing the posterior predictive distribution for the
    number of rented bikes.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ä¸ä»…ä»…å¯¹æœŸæœ›å€¼ï¼ˆå‡å€¼ï¼‰æ„Ÿå…´è¶£ï¼Œè€Œæ˜¯æƒ³ä»é¢„æµ‹çš„è§’åº¦æ¥æ€è€ƒï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä»ç§Ÿç”¨è‡ªè¡Œè½¦çš„è§’åº¦æ¥çœ‹æ€ä¹ˆåŠï¼Ÿå—¯ï¼Œä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡ŒåéªŒé¢„æµ‹é‡‡æ ·ã€‚åœ¨æ‰§è¡Œä¸‹ä¸€è¡Œä»£ç åï¼Œ`idata_lb`å°†è¢«å¡«å……ä¸€ä¸ªæ–°çš„ç»„ï¼Œ`posterior_predictive`ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªå˜é‡`y_pred`ï¼Œè¡¨ç¤ºç§Ÿç”¨è‡ªè¡Œè½¦æ•°é‡çš„åéªŒé¢„æµ‹åˆ†å¸ƒã€‚
- en: '**CodeÂ 4.4**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç Â 4.4**'
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The black line in *Figure [4.5](#x1-80006r5)* is the mean of the number of rented
    bikes. This is the same as in *Figure [4.4](#x1-79007r4)*. The new elements are
    the dark gray band representing the central 50% (quantiles 0.25 and 0.75) for
    the rented bikes and the light gray band, representing the central 94% (quantiles
    0.03 and 0.97). You may notice that our model is predicting a negative number
    of bikes, which does not make sense. But upon reflection, this should be expected
    as we use a Normal distribution for the likelihood in `model_lb`. A very dirty
    *fix* could be to clip the predictions at values lower than 0, but thatâ€™s ugly.
    In the next section, we will see that we can easily improve this model to avoid
    nonsensical predictions.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [4.5](#x1-80006r5)* ä¸­çš„é»‘çº¿ä»£è¡¨ç§Ÿèµè‡ªè¡Œè½¦çš„å‡å€¼ã€‚è¿™ä¸ *å›¾ [4.4](#x1-79007r4)* ä¸­çš„æƒ…å†µç›¸åŒã€‚æ–°å¢å…ƒç´ åŒ…æ‹¬ä»£è¡¨ç§Ÿèµè‡ªè¡Œè½¦ä¸­å¿ƒ
    50% çš„æ·±ç°è‰²å¸¦ï¼ˆåˆ†ä½æ•° 0.25 å’Œ 0.75ï¼‰ï¼Œä»¥åŠä»£è¡¨ä¸­å¿ƒ 94% çš„æµ…ç°è‰²å¸¦ï¼ˆåˆ†ä½æ•° 0.03 å’Œ 0.97ï¼‰ã€‚æ‚¨å¯èƒ½æ³¨æ„åˆ°æˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹äº†ä¸€ä¸ªè´Ÿæ•°è‡ªè¡Œè½¦æ•°é‡ï¼Œè¿™æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚ä½†ä»”ç»†æ€è€ƒåï¼Œæˆ‘ä»¬ä¼šå‘ç°è¿™æ˜¯é¢„æœŸçš„ï¼Œå› ä¸ºåœ¨
    `model_lb` ä¸­æˆ‘ä»¬ä½¿ç”¨äº†æ­£æ€åˆ†å¸ƒæ¥æè¿°ä¼¼ç„¶ã€‚ä¸€ä¸ªéå¸¸ç®€é™‹çš„ *ä¿®æ­£* å¯ä»¥æ˜¯å°†é¢„æµ‹å€¼å‰ªåˆ‡ä¸ºä½äº 0 çš„å€¼ï¼Œä½†é‚£æ ·å¾ˆä¸‘é™‹ã€‚åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°æˆ‘ä»¬å¯ä»¥è½»æ¾æ”¹è¿›è¿™ä¸ªæ¨¡å‹ï¼Œä»¥é¿å…ä¸åˆç†çš„é¢„æµ‹ã€‚'
- en: '![PIC](img/file103.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file103.png)'
- en: '**FigureÂ 4.5**: Posterior predictive plot for the bike linear model'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾Â 4.5**ï¼šè‡ªè¡Œè½¦çº¿æ€§æ¨¡å‹çš„åéªŒé¢„æµ‹å›¾'
- en: 4.3 Generalizing the linear model
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 æ³›åŒ–çº¿æ€§æ¨¡å‹
- en: 'The linear model we have been using is a special case of a more general model,
    the **Generalized Linear Model** (**GLM**). The GLM is a generalization of the
    linear model that allows us to use different distributions for the likelihood.
    At a high level, we can write a Bayesian GLM like:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸€ç›´åœ¨ä½¿ç”¨çš„çº¿æ€§æ¨¡å‹æ˜¯æ›´ä¸€èˆ¬æ¨¡å‹çš„ç‰¹ä¾‹ï¼Œå³**å¹¿ä¹‰çº¿æ€§æ¨¡å‹**ï¼ˆ**GLM**ï¼‰ã€‚GLM æ˜¯çº¿æ€§æ¨¡å‹çš„æ³›åŒ–ï¼Œå…è®¸æˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„åˆ†å¸ƒæ¥æè¿°ä¼¼ç„¶ã€‚åœ¨é«˜å±‚æ¬¡ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å°†è´å¶æ–¯
    GLM å†™æˆï¼š
- en: '![ğ›¼ âˆ¼ a prior ğ›½ âˆ¼ another prior Î¸ âˆ¼ some prior Î¼ = ğ›¼ + ğ›½X Y âˆ¼ Ï• (f (Î¼ ),Î¸)
    ](img/file104.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![ğ›¼ âˆ¼ å…ˆéªŒ ğ›½ âˆ¼ å¦ä¸€ä¸ªå…ˆéªŒ Î¸ âˆ¼ æŸäº›å…ˆéªŒ Î¼ = ğ›¼ + ğ›½X Y âˆ¼ Ï• (f (Î¼ ),Î¸) ](img/file104.jpg)'
- en: '![](img/phi.png) is an arbitrary distribution; some common cases are Normal,
    Studentâ€™s t, Gamma, and NegativeBinomial. *Î¸* represents any *auxiliary* parameter
    the distribution may have, like *Ïƒ* for the Normal. We also have *f*, usually
    called the inverse link function. When ![](img/phi.png) is Normal, then *f* is
    the identity function. For distributions like Gamma and NegativeBinomial, *f*
    is usually the exponential function. Why do we need *f*? Because the linear model
    will generally be on the real line, but the *Î¼* parameter (or its equivalent)
    may be defined on a different domain. For instance, *Î¼* for the NegativeBinomial
    is defined for positive values, so we need to transform *Î¼*. The exponential function
    is a good candidate for this transformation. We are going to explore a few GLMs
    in this book. A good exercise for you, while reading the book, is to create a
    table, and every time you see a new GLM, you add one line indicating what *phi*,
    *theta*, and *f* are and maybe some notes about when this GLM is used. OK, letâ€™s
    start with our first concrete example of a GLM.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/phi.png) æ˜¯ä»»æ„åˆ†å¸ƒï¼›ä¸€äº›å¸¸è§æƒ…å†µåŒ…æ‹¬æ­£æ€åˆ†å¸ƒã€å­¦ç”Ÿ t åˆ†å¸ƒã€ä¼½é©¬åˆ†å¸ƒå’Œè´ŸäºŒé¡¹åˆ†å¸ƒã€‚*Î¸* è¡¨ç¤ºåˆ†å¸ƒå¯èƒ½å…·æœ‰çš„ä»»ä½• *è¾…åŠ©*
    å‚æ•°ï¼Œä¾‹å¦‚æ­£æ€åˆ†å¸ƒä¸­çš„ *Ïƒ*ã€‚æˆ‘ä»¬è¿˜æœ‰ *f*ï¼Œé€šå¸¸ç§°ä¸ºåå‘é“¾æ¥å‡½æ•°ã€‚å½“ ![](img/phi.png) æ˜¯æ­£æ€åˆ†å¸ƒæ—¶ï¼Œ*f* æ˜¯æ’ç­‰å‡½æ•°ã€‚å¯¹äºä¼½é©¬åˆ†å¸ƒå’Œè´ŸäºŒé¡¹åˆ†å¸ƒç­‰åˆ†å¸ƒï¼Œ*f*
    é€šå¸¸æ˜¯æŒ‡æ•°å‡½æ•°ã€‚ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ *f*ï¼Ÿå› ä¸ºçº¿æ€§æ¨¡å‹é€šå¸¸ä½äºå®æ•°çº¿ä¸Šï¼Œä½† *Î¼* å‚æ•°ï¼ˆæˆ–å…¶ç­‰ä»·ç‰©ï¼‰å¯èƒ½åœ¨ä¸åŒçš„å®šä¹‰åŸŸä¸Šã€‚ä¾‹å¦‚ï¼Œè´ŸäºŒé¡¹åˆ†å¸ƒçš„ *Î¼* å®šä¹‰ä¸ºæ­£å€¼ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å¯¹
    *Î¼* è¿›è¡Œå˜æ¢ã€‚æŒ‡æ•°å‡½æ•°æ˜¯è¿™ç§å˜æ¢çš„ä¸€ä¸ªå¥½é€‰æ‹©ã€‚æˆ‘ä»¬å°†åœ¨æœ¬ä¹¦ä¸­æ¢è®¨å‡ ç§ GLMã€‚åœ¨é˜…è¯»æœ¬ä¹¦æ—¶ï¼Œä¸€ä¸ªå¾ˆå¥½çš„ç»ƒä¹ æ˜¯åˆ›å»ºä¸€ä¸ªè¡¨æ ¼ï¼Œæ¯æ¬¡çœ‹åˆ°æ–°çš„ GLM æ—¶ï¼Œæ·»åŠ ä¸€è¡Œè¯´æ˜
    *phi*ã€*theta* å’Œ *f* æ˜¯ä»€ä¹ˆï¼Œä»¥åŠå…³äºä½•æ—¶ä½¿ç”¨è¯¥ GLM çš„ä¸€äº›æ³¨é‡Šã€‚å¥½çš„ï¼Œè®©æˆ‘ä»¬ä»æˆ‘ä»¬ç¬¬ä¸€ä¸ªå…·ä½“çš„ GLM ç¤ºä¾‹å¼€å§‹ã€‚'
- en: 4.4 Counting bikes
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 è®¡æ•°è‡ªè¡Œè½¦
- en: 'How can we change `model_lb` to better accommodate the bike data? There are
    two things to note: the number of rented bikes is discrete and it is bounded at
    0\. This is usually known as count data, which is data that is the result of counting
    something. Count data is sometimes modeled using a continuous distribution like
    a Normal, especially when the number of counts is large. But it is often a good
    idea to use a discrete distribution. Two common choices are the Poisson and NegativeBinomial
    distributions. The main difference is that for Poisson, the mean and the variance
    are the same, but if this is not true or even approximately true, then NegativeBinomial
    may be a better choice as it allows the mean and variance to be different. When
    in doubt, you can fit both Poisson and NegativeBinomial and see which one provides
    a better model. We are going to do that in *Chapter [5](CH05.xhtml#x1-950005)*.
    But for now, we are going to use NegativeBinomial.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½•æ”¹è¿› `model_lb` ä»¥æ›´å¥½åœ°é€‚åº”è‡ªè¡Œè½¦æ•°æ®ï¼Ÿéœ€è¦æ³¨æ„ä¸¤ç‚¹ï¼šç§Ÿèµè‡ªè¡Œè½¦æ•°é‡æ˜¯ç¦»æ•£çš„ï¼Œå¹¶ä¸”å…¶ä¸‹ç•Œä¸º 0ã€‚è¿™é€šå¸¸è¢«ç§°ä¸ºè®¡æ•°æ•°æ®ï¼ŒæŒ‡çš„æ˜¯é€šè¿‡è®¡æ•°æŸç‰©å¾—å‡ºçš„æ•°æ®ã€‚è®¡æ•°æ•°æ®æœ‰æ—¶ä½¿ç”¨è¿ç»­åˆ†å¸ƒï¼ˆå¦‚æ­£æ€åˆ†å¸ƒï¼‰æ¥å»ºæ¨¡ï¼Œç‰¹åˆ«æ˜¯å½“è®¡æ•°æ•°é‡è¾ƒå¤§æ—¶ã€‚ä½†é€šå¸¸ä½¿ç”¨ç¦»æ•£åˆ†å¸ƒæ›´ä¸ºåˆé€‚ã€‚ä¸¤ç§å¸¸è§çš„é€‰æ‹©æ˜¯æ³Šæ¾åˆ†å¸ƒå’Œ
    NegativeBinomial åˆ†å¸ƒã€‚ä¸»è¦çš„åŒºåˆ«æ˜¯ï¼Œå¯¹äºæ³Šæ¾åˆ†å¸ƒï¼Œå‡å€¼å’Œæ–¹å·®æ˜¯ç›¸åŒçš„ï¼Œä½†å¦‚æœè¿™ä¸æˆç«‹æˆ–ç”šè‡³å¤§è‡´ä¸æˆç«‹ï¼Œé‚£ä¹ˆ NegativeBinomial
    å¯èƒ½æ˜¯ä¸€ä¸ªæ›´å¥½çš„é€‰æ‹©ï¼Œå› ä¸ºå®ƒå…è®¸å‡å€¼å’Œæ–¹å·®ä¸åŒã€‚å¦‚æœä¸ç¡®å®šï¼Œå¯ä»¥åŒæ—¶æ‹Ÿåˆæ³Šæ¾åˆ†å¸ƒå’Œ NegativeBinomial åˆ†å¸ƒï¼Œçœ‹çœ‹å“ªä¸ªæ¨¡å‹æ›´å¥½ã€‚æˆ‘ä»¬å°†åœ¨ *ç¬¬
    [5](CH05.xhtml#x1-950005) ç« * ä¸­è¿›è¡Œè¿™ä¸€æ“ä½œã€‚ä½†ç›®å‰ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ NegativeBinomial æ¨¡å‹ã€‚
- en: '**CodeÂ 4.5**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.5**'
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The PyMC model is very similar to the previous one but with two main differences.
    First, we use `pm.NegativeBinomial` instead of `pm.Normal` for the likelihood.
    The NegativeBinomial distribution has two parameters, the mean *Î¼* and a dispersion
    parameter *Î±*. The variance of NegativeBinomial is *Î¼* + ![Î¼2 ğ›¼-](img/file105.jpg),
    so the larger the value of *Î±* the larger the variance. The second difference
    is that *Î¼* is `pm.math.exp(`*Î±* `+` *Î²* `* bikes.temperature)` instead of just
    *Î±* `+` *Î²* `* bikes.temperature` and, as we already explained, this is needed
    to transform the real line into the positive interval.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: PyMC æ¨¡å‹ä¸ä¹‹å‰çš„æ¨¡å‹éå¸¸ç›¸ä¼¼ï¼Œä½†æœ‰ä¸¤ä¸ªä¸»è¦åŒºåˆ«ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ `pm.NegativeBinomial` ä»£æ›¿ `pm.Normal` ä½œä¸ºä¼¼ç„¶å‡½æ•°ã€‚NegativeBinomial
    åˆ†å¸ƒæœ‰ä¸¤ä¸ªå‚æ•°ï¼šå‡å€¼ *Î¼* å’Œç¦»æ•£å‚æ•° *Î±*ã€‚NegativeBinomial çš„æ–¹å·®ä¸º *Î¼* + ![Î¼2 ğ›¼-](img/file105.jpg)ï¼Œå› æ­¤
    *Î±* çš„å€¼è¶Šå¤§ï¼Œæ–¹å·®è¶Šå¤§ã€‚ç¬¬äºŒä¸ªåŒºåˆ«æ˜¯ï¼Œ*Î¼* ç°åœ¨æ˜¯ `pm.math.exp(`*Î±* `+` *Î²* `* bikes.temperature)`ï¼Œè€Œä¸æ˜¯ç®€å•çš„
    *Î±* `+` *Î²* `* bikes.temperature`ï¼Œæ­£å¦‚æˆ‘ä»¬ä¹‹å‰è§£é‡Šçš„é‚£æ ·ï¼Œè¿™éœ€è¦å°†å®æ•°çº¿è½¬æ¢ä¸ºæ­£çš„åŒºé—´ã€‚
- en: The posterior predictive distribution for `model_neg` is shown in *Figure [4.6](#x1-82014r6)*.
    The posterior predictive distribution is also very similar to the one we obtained
    with the linear model (*Figure [4.5](#x1-80006r5)*). The main difference is that
    now we are not predicting a negative number of rented bikes! We can also see that
    the variance of the predictions increases with the mean. This is expected because
    the variance of NegativeBinomial is *Î¼* + ![Î¼2 ğ›¼](img/file106.jpg).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`model_neg` çš„åéªŒé¢„æµ‹åˆ†å¸ƒæ˜¾ç¤ºåœ¨ *å›¾ [4.6](#x1-82014r6)* ä¸­ã€‚åéªŒé¢„æµ‹åˆ†å¸ƒä¸æˆ‘ä»¬åœ¨ä½¿ç”¨çº¿æ€§æ¨¡å‹æ—¶è·å¾—çš„åˆ†å¸ƒéå¸¸ç›¸ä¼¼ï¼ˆ*å›¾
    [4.5](#x1-80006r5)*ï¼‰ã€‚ä¸»è¦çš„åŒºåˆ«æ˜¯ï¼Œç°åœ¨æˆ‘ä»¬ä¸å†é¢„æµ‹è´Ÿæ•°çš„ç§Ÿèµè‡ªè¡Œè½¦æ•°é‡ï¼æˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°ï¼Œé¢„æµ‹çš„æ–¹å·®éšç€å‡å€¼çš„å¢åŠ è€Œå¢å¤§ã€‚è¿™æ˜¯é¢„æœŸä¹‹ä¸­çš„ï¼Œå› ä¸º
    NegativeBinomial çš„æ–¹å·®ä¸º *Î¼* + ![Î¼2 ğ›¼](img/file106.jpg)ã€‚'
- en: '![PIC](img/file107.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file107.png)'
- en: '**FigureÂ 4.6**: Posterior predictive plot for the bike NegativeBinomial linear
    model'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.6**ï¼šè‡ªè¡Œè½¦ NegativeBinomial çº¿æ€§æ¨¡å‹çš„åéªŒé¢„æµ‹å›¾'
- en: '*Figure [4.7](#x1-82017r7)* shows the posterior predictive check for `model_lb`
    on the left and `model_neg` on the right. We can see that when using a Normal,
    the largest mismatch is that the model predicts a negative number of rented bikes,
    but even on the positive side we see that the fit is not that good. On the other
    hand, the NegativeBinomial model seems to be a better fit, although itâ€™s not perfect.
    Look at the right tail: itâ€™s heavier for the predictions than observations. But
    also notice that the probability of this very high demand is low. So, overall
    we can restate that the NegativeBinomial model is better than the Normal one.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [4.7](#x1-82017r7)* æ˜¾ç¤ºäº† `model_lb` çš„åéªŒé¢„æµ‹æ£€éªŒï¼ˆå·¦ä¾§ï¼‰å’Œ `model_neg` çš„åéªŒé¢„æµ‹æ£€éªŒï¼ˆå³ä¾§ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå½“ä½¿ç”¨æ­£æ€åˆ†å¸ƒæ—¶ï¼Œæœ€å¤§çš„åå·®æ˜¯æ¨¡å‹é¢„æµ‹å‡ºç§Ÿèµè‡ªè¡Œè½¦æ•°é‡ä¸ºè´Ÿæ•°ï¼Œä½†å³ä½¿åœ¨æ­£å€¼èŒƒå›´å†…ï¼Œæˆ‘ä»¬ä¹Ÿèƒ½çœ‹åˆ°æ‹Ÿåˆæ•ˆæœä¸å¤ªå¥½ã€‚å¦ä¸€æ–¹é¢ï¼ŒNegativeBinomial
    æ¨¡å‹ä¼¼ä¹æ›´é€‚åˆï¼Œå°½ç®¡å®ƒå¹¶ä¸å®Œç¾ã€‚çœ‹å³å°¾ï¼šé¢„æµ‹å€¼çš„å°¾éƒ¨æ¯”è§‚æµ‹å€¼é‡ã€‚ä½†ä¹Ÿæ³¨æ„åˆ°ï¼Œè¿™ç§éå¸¸é«˜çš„éœ€æ±‚çš„æ¦‚ç‡è¾ƒä½ã€‚å› æ­¤ï¼Œæ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥é‡æ–°è¡¨è¿°ä¸ºï¼ŒNegativeBinomial
    æ¨¡å‹æ¯”æ­£æ€åˆ†å¸ƒæ¨¡å‹æ›´å¥½ã€‚'
- en: '![PIC](img/file108.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file108.png)'
- en: '**FigureÂ 4.7**: Posterior predictive check for the bike linear model'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.7**ï¼šè‡ªè¡Œè½¦çº¿æ€§æ¨¡å‹çš„åéªŒé¢„æµ‹æ£€éªŒ'
- en: 4.5 Robust regression
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 ç¨³å¥å›å½’
- en: I once ran a complex simulation of a molecular system. At each step of the simulation,
    I needed it to fit a linear regression as an intermediate step. I had theoretical
    and empirical reasons to think that my Y was conditionally Normal given my Xs,
    so I decided simple linear regression should do the trick. But from time to time
    the simulation generated a few values of Y that were way above or below the bulk
    of the data. This completely ruined my simulation and I had to restart it.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ›¾ç»è¿è¡Œè¿‡ä¸€ä¸ªå¤æ‚çš„åˆ†å­ç³»ç»Ÿæ¨¡æ‹Ÿã€‚åœ¨æ¯ä¸€æ­¥æ¨¡æ‹Ÿä¸­ï¼Œæˆ‘éƒ½éœ€è¦è¿›è¡Œçº¿æ€§å›å½’æ‹Ÿåˆä½œä¸ºä¸­é—´æ­¥éª¤ã€‚æˆ‘æœ‰ç†è®ºå’Œç»éªŒä¸Šçš„ç†ç”±è®¤ä¸ºï¼Œåœ¨ç»™å®šXå€¼çš„æƒ…å†µä¸‹ï¼Œæˆ‘çš„Yå€¼æ˜¯æ¡ä»¶æ­£æ€åˆ†å¸ƒçš„ï¼Œæ‰€ä»¥æˆ‘å†³å®šä½¿ç”¨ç®€å•çš„çº¿æ€§å›å½’æ¥è§£å†³ã€‚ä½†æœ‰æ—¶ï¼Œæ¨¡æ‹Ÿä¼šç”Ÿæˆä¸€äº›è¿œé«˜äºæˆ–ä½äºæ•°æ®ä¸»ç¾¤çš„Yå€¼ã€‚è¿™å®Œå…¨ç ´åäº†æˆ‘çš„æ¨¡æ‹Ÿï¼Œæˆ‘ä¸å¾—ä¸é‡æ–°å¯åŠ¨å®ƒã€‚
- en: Usually, these values that are very different from the bulk of the data are
    called outliers. The reason for the failure of my simulations was that the outliers
    were *pulling* the regression line away from the bulk of the data and when I passed
    this estimate to the next step in the simulation, the thing just halted. I solved
    this with the help of our good friend the Studentâ€™s t-distribution, which, as
    we saw in *Chapter [2](CH02.xhtml#x1-440002)*, has heavier tails than the Normal
    distribution. This means that the outliers have less influence on the regression
    line. This is an example of a robust regression.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œè¿™äº›ä¸æ•°æ®ä¸»ç¾¤éå¸¸ä¸åŒçš„å€¼è¢«ç§°ä¸ºå¼‚å¸¸å€¼ã€‚æˆ‘çš„æ¨¡æ‹Ÿå¤±è´¥çš„åŸå› æ˜¯è¿™äº›å¼‚å¸¸å€¼*æ‹‰æ‰¯*å›å½’çº¿è¿œç¦»æ•°æ®ä¸»ç¾¤ï¼Œè€Œå½“æˆ‘å°†è¿™ä¸ªä¼°è®¡ä¼ é€’åˆ°æ¨¡æ‹Ÿçš„ä¸‹ä¸€æ­¥æ—¶ï¼Œäº‹æƒ…å°±åœæ­¢äº†ã€‚æˆ‘é€šè¿‡æˆ‘ä»¬äº²çˆ±çš„æœ‹å‹â€”â€”å­¦ç”Ÿtåˆ†å¸ƒè§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨*ç¬¬[2ç« ](CH02.xhtml#x1-440002)*ä¸­çœ‹åˆ°çš„ï¼Œå­¦ç”Ÿtåˆ†å¸ƒæ¯”æ­£æ€åˆ†å¸ƒæœ‰æ›´é‡çš„å°¾éƒ¨ã€‚è¿™æ„å‘³ç€å¼‚å¸¸å€¼å¯¹å›å½’çº¿çš„å½±å“è¾ƒå°ã€‚è¿™å°±æ˜¯ç¨³å¥å›å½’çš„ä¸€ä¸ªä¾‹å­ã€‚
- en: 'To exemplify the robustness that a Studentâ€™s T distribution brings to linear
    regression, we are going to use a very simple and nice dataset: the third data
    group from Anscombeâ€™s quartet. If you do not know what Anscombeâ€™s quartet is,
    check it out on Wikipedia ( [https://en.wikipedia.org/wiki/Anscombe%27s_quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä¸¾ä¾‹è¯´æ˜å­¦ç”Ÿtåˆ†å¸ƒä¸ºçº¿æ€§å›å½’å¸¦æ¥çš„ç¨³å¥æ€§ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªéå¸¸ç®€å•ä¸”æœ‰è¶£çš„æ•°æ®é›†ï¼šAnscombeå››é‡å¥ä¸­çš„ç¬¬ä¸‰ç»„æ•°æ®ã€‚å¦‚æœä½ ä¸çŸ¥é“Anscombeå››é‡å¥æ˜¯ä»€ä¹ˆï¼Œå¯ä»¥åœ¨ç»´åŸºç™¾ç§‘æŸ¥çœ‹ï¼ˆ
    [https://en.wikipedia.org/wiki/Anscombe%27s_quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)
    ï¼‰ã€‚
- en: 'In the following model, `model_t`, we are using a shifted exponential to avoid
    values close to 0\. The non-shifted Exponential puts too much weight on values
    close to 0\. In my experience, this is fine for data with none to moderate outliers,
    but for data with extreme outliers (or data with a few bulk points), like in Anscombeâ€™s
    third dataset, it is better to avoid such low values. Take this, as well as other
    prior recommendations, with a pinch of salt. The defaults are good starting points,
    but thereâ€™s no need to stick to them. Other common priors are Gamma(2, 0.1) and
    Gamma(mu=20, sigma=15), which are somewhat similar to Exponential(1/30) but with
    less values closer to 0:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¥ä¸‹æ¥çš„æ¨¡å‹`model_t`ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªç§»ä½çš„æŒ‡æ•°åˆ†å¸ƒæ¥é¿å…æ¥è¿‘0çš„å€¼ã€‚æœªç§»ä½çš„æŒ‡æ•°åˆ†å¸ƒå¯¹æ¥è¿‘0çš„å€¼èµ‹äºˆè¿‡å¤šæƒé‡ã€‚æ ¹æ®æˆ‘çš„ç»éªŒï¼Œè¿™å¯¹æ²¡æœ‰å¼‚å¸¸å€¼æˆ–å¼‚å¸¸å€¼é€‚ä¸­çš„æ•°æ®æ¥è¯´æ˜¯å¯ä»¥çš„ï¼Œä½†å¯¹äºæœ‰æç«¯å¼‚å¸¸å€¼ï¼ˆæˆ–åŒ…å«å°‘é‡é›†ç¾¤ç‚¹ï¼‰çš„æ•°æ®ï¼Œå¦‚Anscombeçš„ç¬¬ä¸‰ç»„æ•°æ®ï¼Œæœ€å¥½é¿å…è¿™ç§ä½å€¼ã€‚è¯·å¯¹è¿™ä¸€ç‚¹ï¼Œä»¥åŠå…¶ä»–å…ˆå‰çš„å»ºè®®æŒè°¨æ…æ€åº¦ã€‚é»˜è®¤å€¼æ˜¯ä¸€ä¸ªä¸é”™çš„èµ·ç‚¹ï¼Œä½†æ²¡æœ‰å¿…è¦æ­»å®ˆå®ƒä»¬ã€‚å…¶ä»–å¸¸è§çš„å…ˆéªŒåŒ…æ‹¬Gamma(2,
    0.1)å’ŒGamma(mu=20, sigma=15)ï¼Œå®ƒä»¬ä¸Exponential(1/30)ç›¸ä¼¼ï¼Œä½†æ›´å°‘æœ‰æ¥è¿‘0çš„å€¼ï¼š
- en: '**CodeÂ 4.6**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.6**'
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In *Figure [4.8](#x1-83015r8)*, we can see the robust fit, according to `model_t`,
    and the non-robust fit, according to SciPyâ€™s `linregress` (this function is doing
    least-squares regression).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*å›¾ [4.8](#x1-83015r8)*ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ ¹æ®`model_t`çš„ç¨³å¥æ‹Ÿåˆå’Œæ ¹æ®SciPyçš„`linregress`ï¼ˆæ­¤å‡½æ•°æ‰§è¡Œæœ€å°äºŒä¹˜å›å½’ï¼‰çš„éç¨³å¥æ‹Ÿåˆã€‚
- en: '![PIC](img/file109.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file109.png)'
- en: '**FigureÂ 4.8**: Robust regression according to `model_t`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.8**ï¼šæ ¹æ®`model_t`çš„ç¨³å¥å›å½’'
- en: While the non-robust fit tries to *compromise* and include all points, the robust
    Bayesian model, `model_t`, automatically *discards* one point and fits a line
    that passes closer through all the remaining points. I know this is a very peculiar
    dataset, but the message remains the same as for other datasets; a Studentâ€™s t-distribution,
    due to its heavier tails, gives less importance to points that are far away from
    the bulk of the data.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶éç¨³å¥æ‹Ÿåˆè¯•å›¾*å¦¥å*å¹¶åŒ…å«æ‰€æœ‰ç‚¹ï¼Œä½†ç¨³å¥è´å¶æ–¯æ¨¡å‹`model_t`è‡ªåŠ¨*ä¸¢å¼ƒ*ä¸€ä¸ªç‚¹ï¼Œå¹¶æ‹Ÿåˆä¸€æ¡é€šè¿‡æ‰€æœ‰å‰©ä½™ç‚¹æ›´æ¥è¿‘çš„ç›´çº¿ã€‚æˆ‘çŸ¥é“è¿™æ˜¯ä¸€ä¸ªéå¸¸ç‰¹æ®Šçš„æ•°æ®é›†ï¼Œä½†å…¶ä¿¡æ¯ä¸å…¶ä»–æ•°æ®é›†çš„ç»“è®ºç›¸åŒï¼›ç”±äºå­¦ç”Ÿtåˆ†å¸ƒçš„å°¾éƒ¨æ›´é‡ï¼Œå®ƒå¯¹è¿œç¦»æ•°æ®ä¸»ç¾¤çš„ç‚¹èµ‹äºˆè¾ƒå°çš„æƒé‡ã€‚
- en: From *Figure [4.9](#x1-83017r9)*, we can see that for the bulk of the data,
    we get a very good match. Also, notice that our model predicts values away from
    the bulk to both sides and not just above the bulk (as in the observed data).
    For our current purposes, this model is performing just fine and it does not need
    further changes. Nevertheless, notice that for some problems, we may want to avoid
    this. In such a case, we should probably go back and change the model to restrict
    the possible values of `y_pred` to positive values using a truncated Studentâ€™s
    t-distribution. This is left as an exercise for the reader.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ä»*å›¾ [4.9](#x1-83017r9)*ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¯¹äºå¤§éƒ¨åˆ†æ•°æ®ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªéå¸¸å¥½çš„åŒ¹é…ã€‚åŒæ—¶ï¼Œæ³¨æ„åˆ°æˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹äº†è¿œç¦»å¤§å¤šæ•°æ•°æ®çš„å€¼ï¼Œå‘ä¸¤ä¾§æ‰©å±•ï¼Œè€Œä¸ä»…ä»…æ˜¯åƒè§‚å¯Ÿåˆ°çš„æ•°æ®é‚£æ ·åœ¨å¤§éƒ¨åˆ†æ•°æ®ä¸Šæ–¹ã€‚å°±æˆ‘ä»¬ç›®å‰çš„ç›®çš„è€Œè¨€ï¼Œè¿™ä¸ªæ¨¡å‹è¡¨ç°å¾—ç›¸å½“ä¸é”™ï¼Œä¸éœ€è¦è¿›ä¸€æ­¥ä¿®æ”¹ã€‚ç„¶è€Œï¼Œæ³¨æ„åˆ°å¯¹äºæŸäº›é—®é¢˜ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›é¿å…è¿™ç§æƒ…å†µã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦å›è¿‡å¤´æ¥ä¿®æ”¹æ¨¡å‹ï¼Œä½¿ç”¨æˆªæ–­çš„å­¦ç”Ÿtåˆ†å¸ƒå°†`y_pred`çš„å¯èƒ½å€¼é™åˆ¶ä¸ºæ­£å€¼ã€‚è¿™éƒ¨åˆ†ç•™ç»™è¯»è€…ä½œä¸ºç»ƒä¹ ã€‚
- en: '![PIC](img/file110.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file110.png)'
- en: '**FigureÂ 4.9**: Posterior predictive check for `model_t`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾Â 4.9**ï¼š`model_t`çš„åéªŒé¢„æµ‹æ£€éªŒ'
- en: 4.6 Logistic regression
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6 é€»è¾‘å›å½’
- en: 'The logistic regression model is a generalization of the linear regression
    model, which we can use when the response variable is binary. This model uses
    the logistic function as an inverse link function. Letâ€™s get familiar with this
    function before we move on to the model:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: é€»è¾‘å›å½’æ¨¡å‹æ˜¯çº¿æ€§å›å½’æ¨¡å‹çš„æ¨å¹¿ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å“åº”å˜é‡ä¸ºäºŒå…ƒæ—¶ä½¿ç”¨è¯¥æ¨¡å‹ã€‚è¯¥æ¨¡å‹ä½¿ç”¨é€»è¾‘å‡½æ•°ä½œä¸ºé€†é“¾æ¥å‡½æ•°ã€‚åœ¨æˆ‘ä»¬ç»§ç»­è®¨è®ºæ¨¡å‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆç†Ÿæ‚‰ä¸€ä¸‹è¿™ä¸ªå‡½æ•°ï¼š
- en: '![logistic(z) = ---1--- 1+ eâˆ’z ](img/file111.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![logistic(z) = ---1--- 1+ eâˆ’z](img/file111.jpg)'
- en: For our purpose, the key property of the logistic function is that irrespective
    of the values of its argument *z*, the result will always be a number in the [0-1]
    interval. Thus, we can see this function as a convenient way to compress the values
    computed from a linear model into values that we can feed into a Bernoulli distribution.
    This logistic function is also known as the sigmoid function because of its characteristic
    S-shaped aspect, as we can see from *Figure [4.10](#x1-84003r10)*.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æˆ‘ä»¬è€Œè¨€ï¼Œé€»è¾‘å‡½æ•°çš„å…³é”®ç‰¹æ€§æ˜¯ï¼Œæ— è®ºå…¶è‡ªå˜é‡*z*çš„å€¼å¦‚ä½•ï¼Œç»“æœæ€»æ˜¯ä¸€ä¸ªä½äº[0-1]åŒºé—´çš„æ•°å­—ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªå‡½æ•°çœ‹ä½œæ˜¯å°†é€šè¿‡çº¿æ€§æ¨¡å‹è®¡ç®—å¾—å‡ºçš„å€¼å‹ç¼©æˆå¯ä»¥è¾“å…¥ä¼¯åŠªåˆ©åˆ†å¸ƒçš„å€¼çš„ä¸€ç§ä¾¿æ·æ–¹å¼ã€‚ç”±äºå…¶ç‰¹æœ‰çš„Så½¢çŠ¶ï¼Œè¿™ä¸ªé€»è¾‘å‡½æ•°ä¹Ÿè¢«ç§°ä¸ºsigmoidå‡½æ•°ï¼Œæ­£å¦‚æˆ‘ä»¬ä»*å›¾
    [4.10](#x1-84003r10)*ä¸­çœ‹åˆ°çš„é‚£æ ·ã€‚
- en: '![PIC](img/file112.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file112.png)'
- en: '**FigureÂ 4.10**: Logistic function'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾Â 4.10**ï¼šé€»è¾‘å‡½æ•°'
- en: 4.6.1 The logistic model
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6.1 é€»è¾‘æ¨¡å‹
- en: We have almost all the elements to turn a simple linear regression into a simple
    logistic regression. Letâ€™s begin with the case of only two classes, for example,
    ham/spam, safe/unsafe, cloudy/sunny, healthy/ill, or hotdog/not hotdog. First,
    we codify these classes by saying that the predicted variable *y* can only take
    two values, 0 or 1, that is *y* âˆˆ{0*,*1}.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‡ ä¹å…·å¤‡äº†å°†ä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’è½¬æ¢ä¸ºä¸€ä¸ªç®€å•çš„é€»è¾‘å›å½’æ‰€éœ€çš„æ‰€æœ‰å…ƒç´ ã€‚æˆ‘ä»¬ä»åªæœ‰ä¸¤ä¸ªç±»åˆ«çš„æƒ…å†µå¼€å§‹ï¼Œä¾‹å¦‚ï¼Œåƒåœ¾é‚®ä»¶/éåƒåœ¾é‚®ä»¶ã€å®‰å…¨/ä¸å®‰å…¨ã€å¤šäº‘/æ™´å¤©ã€å¥åº·/ç”Ÿç—…ï¼Œæˆ–çƒ­ç‹—/éçƒ­ç‹—ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡å£°æ˜é¢„æµ‹å˜é‡*y*åªèƒ½å–ä¸¤ä¸ªå€¼ï¼Œå³0æˆ–1æ¥å¯¹è¿™äº›ç±»åˆ«è¿›è¡Œç¼–ç ï¼Œå³*y*
    âˆˆ{0,*1}ã€‚
- en: 'Stated this way, the problem sounds very similar to the coin-flipping one we
    used in previous chapters. We may remember we used the Bernoulli distribution
    as the likelihood. The difference with the coin-flipping problem is that now *Î¸*
    is not going to be generated from a beta distribution; instead, *Î¸* is going to
    be defined by a linear model with the logistic as the inverse link function. Omitting
    the priors, we have:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™ä¸ªè§’åº¦æè¿°ï¼Œé—®é¢˜å¬èµ·æ¥éå¸¸åƒæˆ‘ä»¬åœ¨å‰å‡ ç« ä½¿ç”¨çš„æ·ç¡¬å¸é—®é¢˜ã€‚æˆ‘ä»¬å¯èƒ½è®°å¾—æˆ‘ä»¬ä½¿ç”¨äº†ä¼¯åŠªåˆ©åˆ†å¸ƒä½œä¸ºä¼¼ç„¶å‡½æ•°ã€‚ä¸æ·ç¡¬å¸é—®é¢˜çš„ä¸åŒä¹‹å¤„åœ¨äºï¼Œç°åœ¨*Î¸*ä¸ä¼šä»betaåˆ†å¸ƒç”Ÿæˆï¼Œè€Œæ˜¯é€šè¿‡ä¸€ä¸ªçº¿æ€§æ¨¡å‹æ¥å®šä¹‰ï¼Œä½¿ç”¨é€»è¾‘å‡½æ•°ä½œä¸ºé€†é“¾æ¥å‡½æ•°ã€‚çœç•¥å…ˆéªŒåˆ†å¸ƒåï¼Œæˆ‘ä»¬æœ‰ï¼š
- en: '![Î¸ = logistic(ğ›¼ + ğ›½x) y âˆ¼ Bernoulli(Î¸) ](img/file113.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![Î¸ = logistic(ğ›¼ + ğ›½x) y âˆ¼ Bernoulli(Î¸)](img/file113.jpg)'
- en: 'We are going to apply logistic regression to the classic iris dataset which
    has measurements from flowers from three closely related species: setosa, virginica,
    and versicolor. These measurements are the petal length, petal width, sepal length,
    and sepal width. In case you are wondering, sepals are modified leaves whose function
    is generally related to protecting the flowers in a bud.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å¯¹ç»å…¸çš„é¸¢å°¾èŠ±æ•°æ®é›†åº”ç”¨é€»è¾‘å›å½’ï¼Œè¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªä¸‰ç§å¯†åˆ‡ç›¸å…³ç‰©ç§çš„èŠ±å‰æµ‹é‡æ•°æ®ï¼šsetosaã€virginicaå’Œversicolorã€‚è¿™äº›æµ‹é‡æ•°æ®åŒ…æ‹¬èŠ±ç“£é•¿åº¦ã€èŠ±ç“£å®½åº¦ã€è¼ç‰‡é•¿åº¦å’Œè¼ç‰‡å®½åº¦ã€‚å¦‚æœä½ æƒ³çŸ¥é“ï¼Œè¼ç‰‡æ˜¯ç»è¿‡æ”¹è‰¯çš„å¶å­ï¼Œé€šå¸¸ä¸ä¿æŠ¤èŠ±æœµåœ¨èŠ±è•¾ä¸­çš„åŠŸèƒ½æœ‰å…³ã€‚
- en: We are going to begin with a simple case. Letâ€™s assume we only have two classes,
    setosa, and versicolor, and just one independent variable or feature, `sepal_length`.
    We want to predict the probability of a flower being setosa given its sepal length.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä»ä¸€ä¸ªç®€å•çš„æ¡ˆä¾‹å¼€å§‹ã€‚å‡è®¾æˆ‘ä»¬åªæœ‰ä¸¤ä¸ªç±»åˆ«ï¼Œsetosaå’Œversicolorï¼Œå¹¶ä¸”åªæœ‰ä¸€ä¸ªç‹¬ç«‹å˜é‡æˆ–ç‰¹å¾ï¼Œ`sepal_length`ã€‚æˆ‘ä»¬å¸Œæœ›æ ¹æ®èŠ±è¼é•¿åº¦é¢„æµ‹ä¸€æœµèŠ±æ˜¯setosaçš„æ¦‚ç‡ã€‚
- en: 'As is usually done, we are going to encode the `setosa` and `versicolor` categories
    with the numbers `0` and `1`. Using pandas, we can do the following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚åŒå¸¸è§çš„åšæ³•ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ•°å­—`0`å’Œ`1`å¯¹`setosa`å’Œ`versicolor`ç±»åˆ«è¿›è¡Œç¼–ç ã€‚ä½¿ç”¨pandasï¼Œæˆ‘ä»¬å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
- en: '**CodeÂ 4.7**'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.7**'
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As with other linear models, centering the data can help with the sampling.
    Now that we have the data in the right format, we can finally build the model
    with PyMC:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å…¶ä»–çº¿æ€§æ¨¡å‹ä¸€æ ·ï¼Œä¸­å¿ƒåŒ–æ•°æ®æœ‰åŠ©äºé‡‡æ ·ã€‚ç°åœ¨æˆ‘ä»¬å·²ç»å°†æ•°æ®è½¬æ¢ä¸ºæ­£ç¡®çš„æ ¼å¼ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å¯ä»¥ä½¿ç”¨PyMCæ„å»ºæ¨¡å‹ï¼š
- en: '**CodeÂ 4.8**'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.8**'
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`model_lrs` has two deterministic variables: *Î¸* and `bd`. *Î¸* is the result
    of applying the logistic function to variable *Î¼*. `bd` is the boundary decision,
    which is the value we use to separate classes. We will discuss this later in detail.
    Another point worth mentioning is that instead of writing the logistic function
    ourselves, we are using the one provided by PyMC, `pm.math.sigmoid`.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`model_lrs`æœ‰ä¸¤ä¸ªç¡®å®šæ€§å˜é‡ï¼š*Î¸*å’Œ`bd`ã€‚*Î¸*æ˜¯å°†é€»è¾‘å‡½æ•°åº”ç”¨äºå˜é‡*Î¼*çš„ç»“æœã€‚`bd`æ˜¯è¾¹ç•Œå†³ç­–å€¼ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªå€¼æ¥åŒºåˆ†ç±»åˆ«ã€‚æˆ‘ä»¬ç¨åä¼šè¯¦ç»†è®¨è®ºè¿™ä¸€ç‚¹ã€‚å¦ä¸€ä¸ªå€¼å¾—æ³¨æ„çš„åœ°æ–¹æ˜¯ï¼Œæˆ‘ä»¬å¹¶æ²¡æœ‰è‡ªå·±ç¼–å†™é€»è¾‘å‡½æ•°ï¼Œè€Œæ˜¯ä½¿ç”¨äº†PyMCæä¾›çš„`pm.math.sigmoid`å‡½æ•°ã€‚'
- en: '*Figure [4.11](#x1-85023r11)* shows the result of `model_lrs`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [4.11](#x1-85023r11)* æ˜¾ç¤ºäº†`model_lrs`çš„ç»“æœï¼š'
- en: '![PIC](img/file114.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file114.png)'
- en: '**FigureÂ 4.11**: Logistic regression, result of `model_lrs`'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.11**ï¼šé€»è¾‘å›å½’ï¼Œ`model_lrs`çš„ç»“æœ'
- en: '*Figure [4.11](#x1-85023r11)* shows the sepal length versus the probability
    of being versicolor *Î¸* (and if you want, also the probability of being setosa,
    1 âˆ’ *Î¸*). We have added some jitter (noise) to the binary response so the point
    does not overlap. An S-shaped (black) line is the mean value of *Î¸*. This line
    can be interpreted as the probability of a flower being versicolor, given that
    we know the value of the sepal length. The semitransparent S-shaped band is the
    94% HDI. What about the vertical line? Thatâ€™s the topic of the next section.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [4.11](#x1-85023r11)* æ˜¾ç¤ºäº†èŠ±è¼é•¿åº¦ä¸ä¸ºversicolorçš„æ¦‚ç‡*Î¸*ï¼ˆå¦‚æœéœ€è¦ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸ºsetosaçš„æ¦‚ç‡ï¼Œ1 âˆ’
    *Î¸*ï¼‰çš„å…³ç³»ã€‚æˆ‘ä»¬å¯¹äºŒå…ƒå“åº”æ·»åŠ äº†ä¸€äº›æŠ–åŠ¨ï¼ˆå™ªéŸ³ï¼‰ï¼Œä»¥é¿å…æ•°æ®ç‚¹é‡å ã€‚é»‘è‰²çš„Så½¢çº¿è¡¨ç¤º*Î¸*çš„å¹³å‡å€¼ã€‚è¿™æ¡çº¿å¯ä»¥è§£é‡Šä¸ºåœ¨å·²çŸ¥èŠ±è¼é•¿åº¦çš„æƒ…å†µä¸‹ï¼Œä¸€æœµèŠ±ä¸ºversicolorçš„æ¦‚ç‡ã€‚åŠé€æ˜çš„Så½¢å¸¦è¡¨ç¤º94%çš„HDIã€‚å‚ç›´çº¿åˆä»£è¡¨ä»€ä¹ˆå‘¢ï¼Ÿè¿™å°†æ˜¯ä¸‹ä¸€èŠ‚çš„ä¸»é¢˜ã€‚'
- en: 4.6.2 Classification with logistic regression
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6.2 ä½¿ç”¨é€»è¾‘å›å½’è¿›è¡Œåˆ†ç±»
- en: My mother prepares a delicious dish called sopa seca, which is basically a spaghetti-based
    recipe and translates literally to â€dry soup.â€ While it may sound like a misnomer
    or even an oxymoron, the name of the dish makes total sense when you learn how
    it is cooked (you may check out the recipe in the GitHub repo for this book at
    [https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)). Something
    similar happens with logistic regression, a model that, despite its name, is generally
    framed as a method for solving classification problems. Letâ€™s see the source of
    this duality.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„æ¯äº²åšäº†ä¸€é“ç¾å‘³çš„èœå«åšsopa secaï¼ŒåŸºæœ¬ä¸Šæ˜¯ä¸€é“ä»¥æ„å¤§åˆ©é¢ä¸ºä¸»çš„èœè‚´ï¼Œå­—é¢æ„æ€æ˜¯â€œå¹²æ±¤â€ã€‚è™½ç„¶å¬èµ·æ¥å¯èƒ½åƒæ˜¯ä¸ªè¯¯ç§°ï¼Œç”šè‡³æ˜¯ä¸ªçŸ›ç›¾ä¿®é¥°æ³•ï¼Œä½†å½“ä½ äº†è§£å®ƒçš„åšæ³•æ—¶ï¼Œè¿™é“èœçš„åå­—å°±å®Œå…¨åˆç†äº†ï¼ˆä½ å¯ä»¥åœ¨æœ¬ä¹¦çš„GitHubä»“åº“ä¸­æŸ¥çœ‹è¿™ä¸ªé£Ÿè°±ï¼š[https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)ï¼‰ã€‚ç±»ä¼¼çš„äº‹æƒ…ä¹Ÿå‘ç”Ÿåœ¨é€»è¾‘å›å½’ä¸­ï¼Œå°½ç®¡å®ƒçš„åå­—å¦‚æ­¤ï¼Œä½†é€šå¸¸è¢«å½“ä½œä¸€ç§è§£å†³åˆ†ç±»é—®é¢˜çš„æ–¹æ³•ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™ç§äºŒå…ƒæ€§çš„æ¥æºã€‚
- en: Regression problems are about predicting a continuous value for an output variable
    given the values of one or more input variables. We have seen many examples of
    regression that include logistic regression. However, logistic regression is usually
    discussed in terms of classification. Classification involves assigning discrete
    values (representing a class, like versicolor) to an output variable given some
    input variables, for instance, stating that a flower is versicolor or setosa given
    its sepal length.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å›å½’é—®é¢˜æ˜¯å…³äºæ ¹æ®ä¸€ä¸ªæˆ–å¤šä¸ªè¾“å…¥å˜é‡çš„å€¼æ¥é¢„æµ‹è¾“å‡ºå˜é‡çš„è¿ç»­å€¼ã€‚æˆ‘ä»¬å·²ç»è§è¿‡è®¸å¤šå›å½’çš„ä¾‹å­ï¼ŒåŒ…æ‹¬é€»è¾‘å›å½’ã€‚ç„¶è€Œï¼Œé€»è¾‘å›å½’é€šå¸¸æ˜¯ä»¥åˆ†ç±»çš„å½¢å¼è®¨è®ºçš„ã€‚åˆ†ç±»æ¶‰åŠæ ¹æ®ä¸€äº›è¾“å…¥å˜é‡ä¸ºè¾“å‡ºå˜é‡åˆ†é…ç¦»æ•£å€¼ï¼ˆä»£è¡¨ä¸€ä¸ªç±»åˆ«ï¼Œæ¯”å¦‚versicolorï¼‰ï¼Œä¾‹å¦‚ï¼Œæ ¹æ®èŠ±è¼é•¿åº¦åˆ¤æ–­ä¸€æœµèŠ±æ˜¯versicolorè¿˜æ˜¯setosaã€‚
- en: 'So, is logistic regression a regression or a classification method? The answer
    is that it is a regression method; we are regressing the probability of belonging
    to some class, but it can be used for classification too. The only thing we need
    is a decision rule: for example, we assign the class `versicolor` if *Î¸* â‰¥ 0*.*5
    and assign `setosa` otherwise. The vertical line in *Figure [4.11](#x1-85023r11)*
    is the boundary decision, and it is defined as the value of the independent variable
    that makes the probability of being versicolor equal to 0.5\. We can calculate
    this value analytically, and it is equal to âˆ’![ğ›¼- ğ›½](img/file115.jpg). This calculation
    is based on the definition of the model:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œé€»è¾‘å›å½’æ˜¯å›å½’æ–¹æ³•è¿˜æ˜¯åˆ†ç±»æ–¹æ³•å‘¢ï¼Ÿç­”æ¡ˆæ˜¯ï¼Œå®ƒæ˜¯ä¸€ç§å›å½’æ–¹æ³•ï¼›æˆ‘ä»¬å›å½’çš„æ˜¯å±äºæŸä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼Œä½†å®ƒä¹Ÿå¯ä»¥ç”¨äºåˆ†ç±»ã€‚æˆ‘ä»¬éœ€è¦çš„åªæ˜¯ä¸€ä¸ªå†³ç­–è§„åˆ™ï¼šä¾‹å¦‚ï¼Œå¦‚æœ*Î¸*
    â‰¥ 0*.*5ï¼Œåˆ™å°†æ ·æœ¬å½’ä¸º`versicolor`ç±»ï¼Œå¦åˆ™å½’ä¸º`setosa`ç±»ã€‚*å›¾ [4.11](#x1-85023r11)*ä¸­çš„å‚ç›´çº¿æ˜¯è¾¹ç•Œå†³ç­–ï¼Œå®ƒè¢«å®šä¹‰ä¸ºä½¿å¾—versicolorçš„æ¦‚ç‡ç­‰äº0.5æ—¶ç‹¬ç«‹å˜é‡çš„å€¼ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ†æè®¡ç®—å‡ºè¿™ä¸ªå€¼ï¼Œå®ƒç­‰äºâˆ’![ğ›¼-
    ğ›½](img/file115.jpg)ã€‚è¿™ä¸ªè®¡ç®—åŸºäºæ¨¡å‹çš„å®šä¹‰ï¼š
- en: '![Î¸ = logistic(ğ›¼ + ğ›½x) ](img/file116.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![Î¸ = logistic(ğ›¼ + ğ›½x) ](img/file116.jpg)'
- en: And from the definition of the logistic function, we have that *Î¸* = 0*.*5 when
    *Î±* + *Î²**x* = 0.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®é€»è¾‘å‡½æ•°çš„å®šä¹‰ï¼Œå½“*Î±* + *Î²**x* = 0æ—¶ï¼Œ*Î¸* = 0*.*5ã€‚
- en: '![0.5 = logistic(ğ›¼ + ğ›½x ) â‡ â‡’ 0 = ğ›¼ + ğ›½x ](img/file117.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![0.5 = logistic(ğ›¼ + ğ›½x ) â‡ â‡’ 0 = ğ›¼ + ğ›½x ](img/file117.jpg)'
- en: Reordering, we find that the value of *x* that makes *Î¸* = 0*.*5 is âˆ’![ğ›¼ğ›½-](img/file118.jpg).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡é‡æ–°æ’åˆ—ï¼Œæˆ‘ä»¬å‘ç°ä½¿å¾—*Î¸* = 0*.*5çš„*x*å€¼æ˜¯âˆ’![ğ›¼ğ›½-](img/file118.jpg)ã€‚
- en: Because we have uncertainty in the value of *Î±* and *Î²*, we also have uncertainty
    about the value of the boundary decision. This uncertainty is represented as the
    vertical (gray) band in *Figure [4.11](#x1-85023r11)*, which goes from â‰ˆ 5*.*3
    to â‰ˆ 5*.*6\. If we were doing automatic classification of flowers based on their
    sepal length (or any similar problem that could be framed within this model),
    we could assign setosa to flowers with a sepal length below 5.3 and versicolor
    to flowers with sepal length above 5.6\. For flowers with a sepal lengths between
    5.3 and 5.6, we would be uncertain about their class, so we could either assign
    them randomly or use some other information to make a decision, including asking
    a human to check the flower.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ä»¬å¯¹*Î±*å’Œ*Î²*çš„å€¼å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯¹äºè¾¹ç•Œå†³ç­–çš„å€¼ä¹Ÿå­˜åœ¨ä¸ç¡®å®šæ€§ã€‚è¿™ç§ä¸ç¡®å®šæ€§åœ¨*å›¾ [4.11](#x1-85023r11)*ä¸­ä»¥å‚ç›´ï¼ˆç°è‰²ï¼‰å¸¦çš„å½¢å¼è¡¨ç¤ºï¼ŒèŒƒå›´ä»â‰ˆ5*.*3åˆ°â‰ˆ5*.*6ã€‚å¦‚æœæˆ‘ä»¬æ ¹æ®èŠ±è¼é•¿åº¦è¿›è¡ŒèŠ±å‰çš„è‡ªåŠ¨åˆ†ç±»ï¼ˆæˆ–ä»»ä½•å¯ä»¥åœ¨æ­¤æ¨¡å‹æ¡†æ¶ä¸‹æè¿°çš„ç±»ä¼¼é—®é¢˜ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥å°†èŠ±è¼é•¿åº¦å°äº5.3çš„èŠ±å½’ä¸ºsetosaç±»ï¼Œå°†èŠ±è¼é•¿åº¦å¤§äº5.6çš„èŠ±å½’ä¸ºversicolorç±»ã€‚å¯¹äºèŠ±è¼é•¿åº¦åœ¨5.3åˆ°5.6ä¹‹é—´çš„èŠ±ï¼Œæˆ‘ä»¬å°†å¯¹å…¶ç±»åˆ«æ„Ÿåˆ°ä¸ç¡®å®šï¼Œå› æ­¤å¯ä»¥éšæœºåˆ†é…å®ƒä»¬çš„ç±»åˆ«ï¼Œæˆ–è€…ä½¿ç”¨å…¶ä»–ä¿¡æ¯åšå‡ºå†³ç­–ï¼ŒåŒ…æ‹¬è®©äººç±»æ£€æŸ¥è¿™äº›èŠ±å‰ã€‚
- en: 'To summarize this section:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“æœ¬èŠ‚å†…å®¹ï¼š
- en: The value of *Î¸* is, generally speaking, *P*(*Y* = 1|*X*). In this sense, logistic
    regression is a true regression; the key detail is that we are regressing the
    probability that a data point belongs to class 1, given a linear combination of
    features.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Î¸*çš„å€¼é€šå¸¸æ¥è¯´æ˜¯*P*(*Y* = 1|*X*)ã€‚ä»è¿™ä¸ªè§’åº¦æ¥çœ‹ï¼Œé€»è¾‘å›å½’æ˜¯çœŸæ­£çš„å›å½’æ–¹æ³•ï¼›å…³é”®ç»†èŠ‚æ˜¯ï¼Œæˆ‘ä»¬æ­£åœ¨å›å½’ä¸€ä¸ªæ•°æ®ç‚¹å±äºç±»åˆ«1çš„æ¦‚ç‡ï¼Œå‰ææ˜¯ç»™å®šç‰¹å¾çš„çº¿æ€§ç»„åˆã€‚'
- en: We are modeling the mean of a dichotomous variable, which is a number in the
    [0-1] interval. Thus, if we want to use logistic regression for classification,
    we need to introduce a rule to turn this probability into a two-class assignment.
    For example, if *P*(*Y* = 1) *>* 0*.*5, we assign that observation to class 1,
    otherwise we assign it to class 0.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨å»ºæ¨¡ä¸€ä¸ªäºŒå…ƒå˜é‡çš„å‡å€¼ï¼Œå®ƒæ˜¯[0-1]åŒºé—´ä¸­çš„ä¸€ä¸ªæ•°å­—ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æƒ³å°†é€»è¾‘å›å½’ç”¨äºåˆ†ç±»ï¼Œæˆ‘ä»¬éœ€è¦å¼•å…¥ä¸€ä¸ªè§„åˆ™ï¼Œå°†è¿™ä¸ªæ¦‚ç‡è½¬æ¢ä¸ºäºŒåˆ†ç±»èµ‹å€¼ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ*P*(*Y*
    = 1) *>* 0*.*5ï¼Œæˆ‘ä»¬å°†è¯¥è§‚æµ‹å€¼åˆ†é…ç»™ç±»åˆ«1ï¼Œå¦åˆ™åˆ†é…ç»™ç±»åˆ«0ã€‚
- en: There is nothing special about the value of 0.5, other than that it is the number
    in the middle of 0 and 1\. This boundary can be justified when we are OK with
    misclassifying a data point in either direction. But this is not always the case,
    because the cost associated with the misclassification does not need to be symmetrical.
    For example, if we are trying to predict whether a patient has a disease or not,
    we may want to use a boundary that minimizes the number of false negatives (patients
    that have the disease but we predict they donâ€™t) or false positives (patients
    that donâ€™t have the disease but we predict they do). We will discuss this in more
    detail in the next section.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å€¼0.5å¹¶æ²¡æœ‰ä»€ä¹ˆç‰¹åˆ«ä¹‹å¤„ï¼Œé™¤äº†å®ƒæ˜¯0å’Œ1ä¹‹é—´çš„ä¸­é—´å€¼ã€‚å½“æˆ‘ä»¬å¯ä»¥æ¥å—å°†æ•°æ®ç‚¹é”™è¯¯åˆ†ç±»åˆ°ä»»ä¸€æ–¹å‘æ—¶ï¼Œè¿™ä¸ªè¾¹ç•Œæ˜¯å¯ä»¥è§£é‡Šçš„ã€‚ä½†è¿™å¹¶ä¸æ€»æ˜¯å¦‚æ­¤ï¼Œå› ä¸ºé”™è¯¯åˆ†ç±»çš„æˆæœ¬ä¸ä¸€å®šæ˜¯å¯¹ç§°çš„ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å°è¯•é¢„æµ‹ä¸€ä¸ªç—…äººæ˜¯å¦æ‚£æœ‰æŸç§ç–¾ç—…ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›ä½¿ç”¨ä¸€ä¸ªè¾¹ç•Œæ¥æœ€å°åŒ–å‡é˜´æ€§ï¼ˆæ‚£ç—…ä½†æˆ‘ä»¬é¢„æµ‹ä»–ä»¬æ²¡æœ‰ï¼‰æˆ–å‡é˜³æ€§ï¼ˆæœªæ‚£ç—…ä½†æˆ‘ä»¬é¢„æµ‹ä»–ä»¬æ‚£ç—…ï¼‰çš„æ•°é‡ã€‚æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­æ›´è¯¦ç»†åœ°è®¨è®ºè¿™ä¸ªé—®é¢˜ã€‚
- en: 4.6.3 Interpreting the coefficients of logistic regression
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6.3 è§£é‡Šé€»è¾‘å›å½’çš„ç³»æ•°
- en: We must be careful when interpreting the coefficients of logistic regression.
    Interpretation is not as straightforward as with simple linear models. Using the
    logistic inverse link function introduces a non-linearity that we have to take
    into account. If *Î²* is positive, increasing *x* will increase *p*(*y* = 1) by
    some amount, but the amount is not a linear function of *x*. Instead, the dependency
    is non-linear on the value of *x*, meaning that the effect of *x* on *p*(*y* =
    1) depends on the value of *x*. We can visualize this fact in *Figure [4.11](#x1-85023r11)*.
    Instead of a line with a constant slope, we have an S-shaped line with a slope
    that changes as a function of *x*.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è§£é‡Šé€»è¾‘å›å½’çš„ç³»æ•°æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å°å¿ƒã€‚ä¸ç®€å•çº¿æ€§æ¨¡å‹ä¸åŒï¼Œè§£é‡Šå¹¶ä¸æ˜¯é‚£ä¹ˆç›´æ¥ã€‚ä½¿ç”¨é€»è¾‘é€†é“¾æ¥å‡½æ•°å¼•å…¥äº†ä¸€ä¸ªéçº¿æ€§å› ç´ ï¼Œæˆ‘ä»¬å¿…é¡»è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ã€‚å¦‚æœ*Î²*ä¸ºæ­£ï¼Œåˆ™å¢åŠ *x*ä¼šä½¿*p*(*y*
    = 1)å¢åŠ ä¸€å®šé‡ï¼Œä½†è¿™ä¸ªé‡ä¸æ˜¯*x*çš„çº¿æ€§å‡½æ•°ã€‚ç›¸åï¼Œä¾èµ–å…³ç³»æ˜¯*x*å€¼çš„éçº¿æ€§å‡½æ•°ï¼Œè¿™æ„å‘³ç€*x*å¯¹*p*(*y* = 1)çš„å½±å“å–å†³äº*x*çš„å€¼ã€‚æˆ‘ä»¬å¯ä»¥åœ¨*å›¾
    [4.11](#x1-85023r11)*ä¸­ç›´è§‚åœ°å±•ç¤ºè¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬ä¸å†å¾—åˆ°ä¸€æ¡å¸¸æ•°æ–œç‡çš„ç›´çº¿ï¼Œè€Œæ˜¯å¾—åˆ°ä¸€æ¡Så½¢çš„æ›²çº¿ï¼Œæ–œç‡éš*x*çš„å˜åŒ–è€Œå˜åŒ–ã€‚
- en: 'A little bit of algebra can give us some further insight into how much *p*(*y*
    = 1) changes with *x*. The basic logistic model is:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›ä»£æ•°å¯ä»¥å¸®åŠ©æˆ‘ä»¬è¿›ä¸€æ­¥ç†è§£*p*(*y* = 1)éšç€*x*çš„å˜åŒ–æœ‰å¤šå°‘å˜åŒ–ã€‚åŸºæœ¬çš„é€»è¾‘æ–¯è’‚æ¨¡å‹æ˜¯ï¼š
- en: '![Î¸ = logistic(ğ›¼ + ğ›½x) ](img/file119.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![Î¸ = logistic(ğ›¼ + ğ›½x) ](img/file119.jpg)'
- en: 'The inverse of the logistic is the logit function, which is:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: é€»è¾‘å›å½’çš„é€†å‡½æ•°æ˜¯logitå‡½æ•°ï¼Œå…¬å¼ä¸ºï¼š
- en: '![ --z-- logit(z) = log 1 âˆ’ z ](img/file120.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![ --z-- logit(z) = log 1 âˆ’ z ](img/file120.jpg)'
- en: 'Combining these two expressions, we get:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“åˆè¿™ä¸¤ä¸ªè¡¨è¾¾å¼ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š
- en: '![ Î¸ logit(Î¸) = log1-âˆ’-Î¸ = ğ›¼ + ğ›½x ](img/file121.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![ Î¸ logit(Î¸) = log1-âˆ’-Î¸ = ğ›¼ + ğ›½x ](img/file121.jpg)'
- en: 'Remember that *Î¸* in our model is *p*(*y* = 1), so we can rewrite the previous
    expression as:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½ï¼Œåœ¨æˆ‘ä»¬çš„æ¨¡å‹ä¸­ï¼Œ*Î¸*æ˜¯*p*(*y* = 1)ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥å°†ä¹‹å‰çš„è¡¨è¾¾å¼æ”¹å†™ä¸ºï¼š
- en: '![ ( ) log --p(y-=-1)-- = ğ›¼ + ğ›½x 1 âˆ’ p(y = 1) ](img/file122.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![ ( ) log --p(y-=-1)-- = ğ›¼ + ğ›½x 1 âˆ’ p(y = 1) ](img/file122.jpg)'
- en: The ![-p(y=1)-- 1âˆ’p(y=1)](img/file123.jpg) quantity is known as the **odds**
    of *y* = 1\. If we call *y* = 1 a *success*, then the odds of success is the ratio
    of the probability of success over the probability of failure. For example, while
    the probability of getting a 2 by rolling a fair die is ![1 6](img/file124.jpg),
    the odds of getting a 2 are ![1âˆ•6- 5âˆ•6](img/file125.jpg) = ![1 5](img/file126.jpg)
    = 0*.*2\. In other words, there is one favorable event for every five unfavorable
    events. Odds are often used by gamblers because they provide a more intuitive
    tool to think about bets than raw probabilities. *Figure [4.12](#x1-87002r12)*
    shows how probabilities are related to odds and log-odds.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![-p(y=1)-- 1âˆ’p(y=1)](img/file123.jpg) è¿™ä¸€é‡è¢«ç§°ä¸º*p* = 1çš„**èµ”ç‡**ã€‚å¦‚æœæˆ‘ä»¬æŠŠ*p* = 1çœ‹ä½œæ˜¯*æˆåŠŸ*ï¼Œé‚£ä¹ˆæˆåŠŸçš„èµ”ç‡å°±æ˜¯æˆåŠŸçš„æ¦‚ç‡ä¸å¤±è´¥çš„æ¦‚ç‡ä¹‹æ¯”ã€‚ä¾‹å¦‚ï¼Œæ·ä¸€ä¸ªå…¬å¹³çš„éª°å­å¾—åˆ°2çš„æ¦‚ç‡æ˜¯![1
    6](img/file124.jpg)ï¼Œè€Œå¾—åˆ°2çš„èµ”ç‡æ˜¯![1âˆ•6- 5âˆ•6](img/file125.jpg) = ![1 5](img/file126.jpg)
    = 0*.*2\. æ¢å¥è¯è¯´ï¼Œæ¯äº”æ¬¡ä¸æˆåŠŸçš„äº‹ä»¶ä¸­å°±æœ‰ä¸€æ¬¡æˆåŠŸäº‹ä»¶ã€‚èµ”ç‡é€šå¸¸è¢«èµŒåšè€…ä½¿ç”¨ï¼Œå› ä¸ºå®ƒä»¬æ¯”åŸå§‹æ¦‚ç‡æä¾›äº†æ›´ç›´è§‚çš„æŠ•æ³¨æ€è€ƒå·¥å…·ã€‚*å›¾ [4.12](#x1-87002r12)*å±•ç¤ºäº†æ¦‚ç‡ã€èµ”ç‡å’Œlog-oddsä¹‹é—´çš„å…³ç³»ã€‚'
- en: '![PIC](img/file127.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file127.png)'
- en: '**FigureÂ 4.12**: Relationship between probability, odds, and log-odds'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.12**ï¼šæ¦‚ç‡ã€èµ”ç‡å’Œlog-oddsçš„å…³ç³»'
- en: Interpreting Logistic Regression
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: è§£é‡Šé€»è¾‘å›å½’
- en: In logistic regression, the *Î²* coefficient (the *slope*) encodes the increase
    in log-odds units by a unit increase of the *x* variable.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é€»è¾‘å›å½’ä¸­ï¼Œ*Î²*ç³»æ•°ï¼ˆ*æ–œç‡*ï¼‰è¡¨ç¤º*x*å˜é‡å¢åŠ ä¸€ä¸ªå•ä½æ—¶ï¼Œlog-oddså•ä½çš„å¢åŠ ã€‚
- en: The transformation from probability to odds is a monotonic transformation, meaning
    the odds increase as the probability increases, and the other way around. While
    probabilities are restricted to the [0*,*1] interval, odds live in the [0*,*âˆ)
    interval. The logarithm is another monotonic transformation and log-odds are in
    the (âˆ’âˆ*,*âˆ) interval.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ¦‚ç‡åˆ°èµ”ç‡çš„è½¬æ¢æ˜¯å•è°ƒå˜åŒ–ï¼Œæ„å‘³ç€éšç€æ¦‚ç‡çš„å¢åŠ ï¼Œèµ”ç‡ä¹Ÿä¼šå¢åŠ ï¼Œåä¹‹äº¦ç„¶ã€‚è™½ç„¶æ¦‚ç‡é™åˆ¶åœ¨[0*,*1]åŒºé—´å†…ï¼Œä½†èµ”ç‡ä½äº[0*,*âˆ)åŒºé—´å†…ã€‚å¯¹æ•°æ˜¯å¦ä¸€ç§å•è°ƒå˜åŒ–ï¼Œè€Œå¯¹æ•°èµ”ç‡åˆ™ä½äº(âˆ’âˆ*,*âˆ)åŒºé—´å†…ã€‚
- en: 4.7 Variable variance
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.7 å˜é‡æ–¹å·®
- en: We have been using the linear motif to model the mean of a distribution and,
    in the previous section, we used it to model interactions. In statistics, it is
    said that a linear regression model presents heteroskedasticity when the variance
    of the errors is not constant in all the observations made. For those cases, we
    may want to consider the variance (or standard deviation) as a (linear) function
    of the dependent variable.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸€ç›´ä½¿ç”¨çº¿æ€§æ¨¡å¼æ¥å»ºæ¨¡åˆ†å¸ƒçš„å‡å€¼ï¼Œå¹¶ä¸”åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬ç”¨å®ƒæ¥å»ºæ¨¡äº¤äº’æ•ˆåº”ã€‚åœ¨ç»Ÿè®¡å­¦ä¸­ï¼Œå½“è¯¯å·®çš„æ–¹å·®åœ¨æ‰€æœ‰è§‚å¯Ÿå€¼ä¸­ä¸æ’å®šæ—¶ï¼Œæˆ‘ä»¬ç§°çº¿æ€§å›å½’æ¨¡å‹å‘ˆç°å¼‚æ–¹å·®æ€§ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦è€ƒè™‘å°†æ–¹å·®ï¼ˆæˆ–æ ‡å‡†å·®ï¼‰ä½œä¸ºå› å˜é‡çš„ï¼ˆçº¿æ€§ï¼‰å‡½æ•°ã€‚
- en: 'The World Health Organization and other health institutions around the world
    collect data for newborns and toddlers and design growth chart standards. These
    charts are an essential component of the pediatric toolkit and also a measure
    of the general well-being of populations to formulate health-related policies,
    plan interventions, and monitor their effectiveness. An example of such data is
    the lengths (heights) of newborn/toddler girls as a function of their age (in
    months):'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸–ç•Œå«ç”Ÿç»„ç»‡åŠå…¶ä»–å…¨çƒå«ç”Ÿæœºæ„æ”¶é›†æ–°ç”Ÿå„¿å’Œå¹¼å„¿çš„æ•°æ®ï¼Œå¹¶è®¾è®¡ç”Ÿé•¿æ›²çº¿æ ‡å‡†ã€‚è¿™äº›å›¾è¡¨æ˜¯å„¿ç§‘å·¥å…·åŒ…çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä¹Ÿæ˜¯è¡¡é‡äººç¾¤æ•´ä½“å¥åº·çŠ¶å†µçš„æ ‡å‡†ï¼Œèƒ½å¤Ÿå¸®åŠ©åˆ¶å®šå¥åº·ç›¸å…³æ”¿ç­–ã€è§„åˆ’å¹²é¢„æªæ–½å¹¶ç›‘æµ‹å…¶æ•ˆæœã€‚è¿™æ ·çš„æ•°æ®ç¤ºä¾‹åŒ…æ‹¬æ–°ç”Ÿå„¿/å¹¼å„¿å¥³å­©çš„èº«é«˜ï¼ˆä½“é•¿ï¼‰ä¸å¹´é¾„ï¼ˆæœˆé¾„ï¼‰ä¹‹é—´çš„å…³ç³»ï¼š
- en: '**CodeÂ 4.9**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.9**'
- en: '[PRE8]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To model this data, we are going to introduce three elements we have not seen
    before:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¯¹è¿™äº›æ•°æ®è¿›è¡Œå»ºæ¨¡ï¼Œæˆ‘ä»¬å°†å¼•å…¥ä¸‰ä¸ªæˆ‘ä»¬ä¹‹å‰æœªè§è¿‡çš„å…ƒç´ ï¼š
- en: '*Ïƒ* is now a linear function of the predictor variable. Thus, we add two new
    parameters, *Î³* and *Î´*. These are direct analogs of *Î±* and *Î²* in the linear
    model for the mean.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Ïƒ*ç°åœ¨æ˜¯é¢„æµ‹å˜é‡çš„çº¿æ€§å‡½æ•°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ–°å¢äº†ä¸¤ä¸ªå‚æ•°ï¼Œ*Î³*å’Œ*Î´*ã€‚è¿™ä¸¤ä¸ªå‚æ•°æ˜¯å‡å€¼çº¿æ€§æ¨¡å‹ä¸­*Î±*å’Œ*Î²*çš„ç›´æ¥ç±»æ¯”ã€‚'
- en: The linear model for the mean is a function of ![](img/file128.png). This is
    just a simple trick to fit a linear model to a curve.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡å€¼çš„çº¿æ€§æ¨¡å‹æ˜¯ä¸€ä¸ªå‡½æ•°ï¼[](img/file128.png)ã€‚è¿™åªæ˜¯ä¸€ä¸ªç®€å•çš„æŠ€å·§ï¼Œç”¨äºå°†çº¿æ€§æ¨¡å‹æ‹Ÿåˆåˆ°æ›²çº¿ä¸Šã€‚
- en: We define a `MutableData` variable, `x_shared`. Why we want to do this will
    become clear soon.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ª`MutableData`å˜é‡ï¼Œ`x_shared`ã€‚ä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåšï¼Œå¾ˆå¿«å°±ä¼šæ˜äº†ã€‚
- en: 'Our full model is:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„å®Œæ•´æ¨¡å‹æ˜¯ï¼š
- en: '**CodeÂ 4.10**'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.10**'
- en: '[PRE9]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: On the left panel of *Figure [4.13](#x1-88022r13)*, we can see the mean of *Î¼*
    represented by a black curve, and the two semi-transparent gray bands represent
    one and two standard deviations. On the right panel, we have the estimated variance
    as a function of the length. As you can see, the variance increases with the length,
    which is what we expected.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*å›¾ [4.13](#x1-88022r13)*çš„å·¦é¢æ¿ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç”±é»‘è‰²æ›²çº¿è¡¨ç¤ºçš„*Î¼*çš„å‡å€¼ï¼Œä¸¤ä¸ªåŠé€æ˜çš„ç°è‰²å¸¦è¡¨ç¤ºä¸€ä¸ªå’Œä¸¤ä¸ªæ ‡å‡†å·®ã€‚åœ¨å³é¢æ¿ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†éšç€èº«é•¿å˜åŒ–çš„ä¼°è®¡æ–¹å·®ã€‚æ­£å¦‚ä½ æ‰€è§ï¼Œæ–¹å·®éšç€èº«é•¿çš„å¢åŠ è€Œå¢å¤§ï¼Œè¿™æ˜¯æˆ‘ä»¬é¢„æœŸçš„ç»“æœã€‚
- en: '![PIC](img/file129.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file129.png)'
- en: '**FigureÂ 4.13**: Posterior fit for `model_vv` on the left panel. On the right
    is the mean estimated variance as a function of the length'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.13**ï¼šå·¦é¢æ¿ä¸º`model_vv`çš„åéªŒæ‹Ÿåˆã€‚å³é¢æ¿æ˜¯éšç€èº«é•¿å˜åŒ–çš„å‡å€¼ä¼°è®¡æ–¹å·®ã€‚'
- en: 'Now that we have fitted the model, we might want to use the model to find out
    how the length of a particular girl compares to the distribution. One way to answer
    this question is to ask the model for the distribution of the variable `length`
    for babies of, say, 0.5 months. We can answer this question by sampling from the
    posterior predictive distribution conditional on a length of 0.5\. Using PyMC,
    we can get the answer by sampling `pm.sample_posterior_predictive`; the only problem
    is that by default, this function will return values of *á»¹* for the already observed
    values of *x*, i.e., the values used to fit the model. The easiest way to get
    predictions for unobserved values is to define a `MutableData` variable (`x_shared`
    in the example) and then update the value of this variable right before sampling
    the posterior predictive distribution, as shown in the following code block:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»æ‹Ÿåˆäº†æ¨¡å‹ï¼Œå¯èƒ½æƒ³ä½¿ç”¨æ¨¡å‹æ¥äº†è§£æŸä¸ªç‰¹å®šå¥³å­©çš„èº«é«˜ä¸åˆ†å¸ƒçš„æ¯”è¾ƒã€‚å›ç­”è¿™ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯è¯¢é—®æ¨¡å‹å…³äº0.5ä¸ªæœˆå¤§å©´å„¿çš„`length`å˜é‡çš„åˆ†å¸ƒã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»åéªŒé¢„æµ‹åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·ï¼Œæ¡ä»¶æ˜¯èº«é«˜ä¸º0.5æ¥å›ç­”è¿™ä¸ªé—®é¢˜ã€‚ä½¿ç”¨
    PyMCï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é‡‡æ ·`pm.sample_posterior_predictive`å¾—åˆ°ç­”æ¡ˆï¼›å”¯ä¸€çš„é—®é¢˜æ˜¯ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™ä¸ªå‡½æ•°ä¼šè¿”å›*á»¹*å€¼ï¼Œè¿™äº›å€¼æ˜¯å·²ç»è§‚å¯Ÿåˆ°çš„*x*å€¼ï¼Œå³ç”¨äºæ‹Ÿåˆæ¨¡å‹çš„å€¼ã€‚è·å–æœªè§‚å¯Ÿå€¼çš„é¢„æµ‹å€¼çš„æœ€ç®€å•æ–¹æ³•æ˜¯å®šä¹‰ä¸€ä¸ª`MutableData`å˜é‡ï¼ˆåœ¨è¿™ä¸ªä¾‹å­ä¸­æ˜¯`x_shared`ï¼‰ï¼Œç„¶ååœ¨é‡‡æ ·åéªŒé¢„æµ‹åˆ†å¸ƒä¹‹å‰æ›´æ–°è¿™ä¸ªå˜é‡çš„å€¼ï¼Œå¦‚ä¸‹ä»£ç å—æ‰€ç¤ºï¼š
- en: '**CodeÂ 4.11**'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.11**'
- en: '[PRE10]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now we can plot the expected distribution of lengths for 2-week-old girls and
    calculate other quantities, like the percentile for a girl of that length (see
    *Figure [4.14](#x1-88029r14)*).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ç»˜åˆ¶å‡º2å‘¨å¤§å¥³å­©çš„é¢„æœŸèº«é•¿åˆ†å¸ƒï¼Œå¹¶è®¡ç®—å…¶ä»–é‡ï¼Œå¦‚è¯¥èº«é•¿å¥³å­©çš„ç™¾åˆ†ä½ï¼ˆè§*å›¾ [4.14](#x1-88029r14)*ï¼‰ã€‚
- en: '![PIC](img/file130.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file130.png)'
- en: '**FigureÂ 4.14**: Expected distribution of length at 0.5 months. The shaded
    area represents 32% of the accumulated mass'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.14**ï¼š0.5ä¸ªæœˆæ—¶çš„èº«é«˜é¢„æœŸåˆ†å¸ƒã€‚é˜´å½±åŒºåŸŸè¡¨ç¤º32%çš„ç´¯è®¡è´¨é‡'
- en: 4.8 Hierarchical linear regression
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.8 å±‚æ¬¡çº¿æ€§å›å½’
- en: In *Chapter [3](CH03.xhtml#x1-670003)*, we learned the rudiments of hierarchical
    models, a very powerful concept that allows us to model complex data structures.
    Hierarchical models allow us to deal with inferences at the group level and estimations
    above the group level. As we have already seen, this is done by including hyperpriors.
    We also showed that groups can share information by using a common hyperprior
    and this provides shrinkage, which can help us to regularize the estimates.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*ç¬¬[3ç« ](CH03.xhtml#x1-670003)*ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†å±‚æ¬¡æ¨¡å‹çš„åŸºæœ¬æ¦‚å¿µï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„æ¦‚å¿µï¼Œå®ƒå…è®¸æˆ‘ä»¬å»ºæ¨¡å¤æ‚çš„æ•°æ®ç»“æ„ã€‚å±‚æ¬¡æ¨¡å‹ä½¿æˆ‘ä»¬èƒ½å¤Ÿå¤„ç†ç»„å±‚æ¬¡çš„æ¨æ–­ä»¥åŠç»„å±‚æ¬¡ä»¥ä¸Šçš„ä¼°è®¡ã€‚å¦‚æˆ‘ä»¬æ‰€è§ï¼Œè¿™å¯ä»¥é€šè¿‡åŒ…å«è¶…å…ˆéªŒæ¥å®ç°ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†ç»„ä¹‹é—´å¯ä»¥é€šè¿‡ä½¿ç”¨å…±åŒçš„è¶…å…ˆéªŒæ¥å…±äº«ä¿¡æ¯ï¼Œè¿™æä¾›äº†æ”¶ç¼©æ•ˆåº”ï¼Œæœ‰åŠ©äºæ­£åˆ™åŒ–ä¼°è®¡ã€‚
- en: We can apply these very same concepts to linear regression to obtain hierarchical
    linear regression models. In this section, we are going to walk through two examples
    to elucidate the application of these concepts in practical scenarios. The first
    one uses a synthetic dataset, and the second one uses the `pigs` dataset.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†è¿™äº›ç›¸åŒçš„æ¦‚å¿µåº”ç”¨åˆ°çº¿æ€§å›å½’ä¸­ï¼Œå¾—åˆ°å±‚æ¬¡çº¿æ€§å›å½’æ¨¡å‹ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä¸¤ä¸ªä¾‹å­æ¥é˜æ˜è¿™äº›æ¦‚å¿µåœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œç¬¬ä¸€ä¸ªä½¿ç”¨çš„æ˜¯åˆæˆæ•°æ®é›†ï¼Œç¬¬äºŒä¸ªä½¿ç”¨çš„æ˜¯`pigs`æ•°æ®é›†ã€‚
- en: For the first example, I have created eight related groups, including one group
    with just one data point. We can see what the data looks like from *Figure [4.15](#x1-89002r15)*.
    If you want to learn more how this data was generated please check the GitHub
    repository [https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç¬¬ä¸€ä¸ªä¾‹å­ï¼Œæˆ‘åˆ›å»ºäº†å…«ä¸ªç›¸å…³çš„ç»„ï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªç»„åªæœ‰ä¸€ä¸ªæ•°æ®ç‚¹ã€‚æˆ‘ä»¬å¯ä»¥ä»*å›¾ [4.15](#x1-89002r15)* ä¸­çœ‹åˆ°æ•°æ®çš„è¡¨ç°ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºè¿™äº›æ•°æ®æ˜¯å¦‚ä½•ç”Ÿæˆçš„ï¼Œè¯·è®¿é—®
    GitHub ä»“åº“ [https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)ã€‚
- en: '![PIC](img/file131.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file131.png)'
- en: '**FigureÂ 4.15**: Synthetic data for the hierarchical linear regression example'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.15**ï¼šå±‚æ¬¡çº¿æ€§å›å½’ç¤ºä¾‹çš„åˆæˆæ•°æ®'
- en: 'First, we are going to fit a non-hierarchical model:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬å°†æ‹Ÿåˆä¸€ä¸ªéå±‚æ¬¡æ¨¡å‹ï¼š
- en: '**CodeÂ 4.12**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.12**'
- en: '[PRE11]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*Figure [4.16](#x1-89014r16)* shows the posterior estimated values for the
    parameters *Î±* and *Î²*.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [4.16](#x1-89014r16)* æ˜¾ç¤ºäº†å‚æ•°*Î±*å’Œ*Î²*çš„åéªŒä¼°è®¡å€¼ã€‚'
- en: '![PIC](img/file132.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file132.png)'
- en: '**FigureÂ 4.16**: Posterior distribution for *Î±* and *Î²* for `unpooled_model`'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.16**ï¼š`unpooled_model`çš„*Î±*å’Œ*Î²*çš„åéªŒåˆ†å¸ƒ'
- en: As you can see from *Figure [4.16](#x1-89014r16)* the estimates for group `H`
    are very different from the ones for the other groups. This is expected as for
    group `H`, we only have one data point, that is we do not have enough information
    to fit a line. We need at least two points; otherwise, the model will be over-parametrized,
    meaning we have more parameters than the ones we can determine from the data alone.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚*å›¾[4.16](#x1-89014r16)*æ‰€ç¤ºï¼Œç»„`H`çš„ä¼°è®¡å€¼ä¸å…¶ä»–ç»„çš„ä¼°è®¡å€¼éå¸¸ä¸åŒã€‚è¿™æ˜¯é¢„æœŸä¸­çš„æƒ…å†µï¼Œå› ä¸ºå¯¹äºç»„`H`ï¼Œæˆ‘ä»¬åªæœ‰ä¸€ä¸ªæ•°æ®ç‚¹ï¼Œä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥æ‹Ÿåˆä¸€æ¡ç›´çº¿ã€‚æˆ‘ä»¬è‡³å°‘éœ€è¦ä¸¤ä¸ªæ•°æ®ç‚¹ï¼›å¦åˆ™ï¼Œæ¨¡å‹ä¼šè¿‡åº¦å‚æ•°åŒ–ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬æœ‰æ¯”æ•°æ®æ‰€èƒ½ç¡®å®šçš„æ›´å¤šçš„å‚æ•°ã€‚
- en: To overcome this situation we can provide some more information; we can do this
    by using priors or by adding more structure to the model. Letâ€™s add more structure
    by building a hierarchical model.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å…‹æœè¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬å¯ä»¥æä¾›æ›´å¤šçš„ä¿¡æ¯ï¼›æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨å…ˆéªŒæˆ–å‘æ¨¡å‹ä¸­æ·»åŠ æ›´å¤šç»“æ„æ¥å®ç°è¿™ä¸€ç‚¹ã€‚è®©æˆ‘ä»¬é€šè¿‡æ„å»ºä¸€ä¸ªåˆ†å±‚æ¨¡å‹æ¥æ·»åŠ æ›´å¤šç»“æ„ã€‚
- en: 'This is the PyMC model for the hierarchical model:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯åˆ†å±‚æ¨¡å‹çš„PyMCæ¨¡å‹ï¼š
- en: '**CodeÂ 4.13**'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.13**'
- en: '[PRE12]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: If you run `hierarchical_centered`, you will see a message from PyMC saying
    something like `There were 149 divergences after tuning. Increase target_accept
    or reparameterize.` This message means that samples generated from PyMC may not
    be trustworthy. So far, we have assumed that PyMC always returns samples that
    we can use without issues, but thatâ€™s not always the case. In *Chapter [10](CH10.xhtml#x1-18900010)*,
    we further discuss why this is, along with diagnostic methods to help you identify
    those situations and recommendations to fix the potential issues. In that section,
    we also explain what divergences are. For now, we will only say that when working
    with hierarchical linear models, we will usually get a lot of divergences.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¿è¡Œ`hierarchical_centered`ï¼Œä½ ä¼šçœ‹åˆ°PyMCæ˜¾ç¤ºä¸€æ¡ä¿¡æ¯ï¼Œç±»ä¼¼äº`è°ƒæ•´åæœ‰149æ¬¡å‘æ•£ã€‚å¢åŠ target_acceptæˆ–é‡æ–°å‚æ•°åŒ–ã€‚`
    è¿™æ¡ä¿¡æ¯æ„å‘³ç€PyMCç”Ÿæˆçš„æ ·æœ¬å¯èƒ½ä¸å¯ä¿¡ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å‡è®¾PyMCæ€»æ˜¯è¿”å›æˆ‘ä»¬å¯ä»¥æ— é—®é¢˜ä½¿ç”¨çš„æ ·æœ¬ï¼Œä½†äº‹å®å¹¶éæ€»æ˜¯å¦‚æ­¤ã€‚åœ¨*ç¬¬[10ç« ](CH10.xhtml#x1-18900010)*ä¸­ï¼Œæˆ‘ä»¬å°†è¿›ä¸€æ­¥è®¨è®ºä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Œå¹¶æä¾›ä¸€äº›è¯Šæ–­æ–¹æ³•ï¼Œå¸®åŠ©ä½ è¯†åˆ«è¿™äº›æƒ…å†µä»¥åŠè§£å†³æ½œåœ¨é—®é¢˜çš„å»ºè®®ã€‚åœ¨è¿™ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿä¼šè§£é‡Šä»€ä¹ˆæ˜¯å‘æ•£ç°è±¡ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬åªæƒ³è¯´ï¼Œå½“ä½¿ç”¨åˆ†å±‚çº¿æ€§æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šé‡åˆ°å¾ˆå¤šå‘æ•£ç°è±¡ã€‚
- en: 'The easy way to solve them is to increase `target_accept`, as PyMC kindly suggests.
    This is an argument of `pm.sample()` that defaults to 0.8 and can take a maximum
    value of 1\. If you see divergences, setting this argument to values like 0.85,
    0.9, or even higher can help. But if you reach values like 0.99 and still have
    divergences, you are probably out of luck with this simple trick and you need
    to do something else. And thatâ€™s reparametrization. What is this? Reparametrization
    is writing a model in a different way, but that is mathematically equivalent to
    your original model: you are not changing the model, just writing it in another
    way. Many models, if not all, can be written in alternative ways. Sometimes, reparametrization
    can have a positive effect on the efficiency of the sampler or on the modelâ€™s
    interpretability. For instance, you can remove divergences by doing a reparametrization.
    Letâ€™s see how to do that in the next section.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: è§£å†³è¿™ä¸ªé—®é¢˜çš„ç®€å•æ–¹æ³•æ˜¯å¢åŠ `target_accept`ï¼Œæ­£å¦‚PyMCäº²åˆ‡åœ°å»ºè®®çš„é‚£æ ·ã€‚å®ƒæ˜¯`pm.sample()`çš„ä¸€ä¸ªå‚æ•°ï¼Œé»˜è®¤å€¼ä¸º0.8ï¼Œæœ€å¤§å€¼ä¸º1ã€‚å¦‚æœä½ çœ‹åˆ°æœ‰å‘æ•£ç°è±¡ï¼Œå¯ä»¥å°†è¿™ä¸ªå‚æ•°è®¾ç½®ä¸º0.85ã€0.9ï¼Œç”šè‡³æ›´é«˜å€¼ï¼Œè¿™æœ‰åŠ©äºè§£å†³é—®é¢˜ã€‚ä½†å¦‚æœä½ å·²ç»è®¾ç½®åˆ°0.99ï¼Œä»ç„¶æœ‰å‘æ•£ç°è±¡ï¼Œé‚£ä¹ˆè¿™ç§ç®€å•çš„æ–¹æ³•å¯èƒ½å°±ä¸å¥æ•ˆäº†ï¼Œä½ éœ€è¦é‡‡å–å…¶ä»–æªæ–½ã€‚è¿™å°±æ˜¯é‡æ–°å‚æ•°åŒ–ã€‚é‚£ä¹ˆï¼Œä»€ä¹ˆæ˜¯é‡æ–°å‚æ•°åŒ–å‘¢ï¼Ÿé‡æ–°å‚æ•°åŒ–å°±æ˜¯ä»¥ä¸€ç§ä¸åŒçš„æ–¹å¼ç¼–å†™æ¨¡å‹ï¼Œä½†è¿™åœ¨æ•°å­¦ä¸Šä¸åŸå§‹æ¨¡å‹æ˜¯ç­‰ä»·çš„ï¼šä½ å¹¶æ²¡æœ‰æ”¹å˜æ¨¡å‹ï¼Œåªæ˜¯ä»¥å¦ä¸€ç§æ–¹å¼è¡¨è¾¾å®ƒã€‚è®¸å¤šæ¨¡å‹ï¼Œå¦‚æœä¸æ˜¯æ‰€æœ‰æ¨¡å‹ï¼Œéƒ½å¯ä»¥ç”¨å…¶ä»–æ–¹å¼æ¥ç¼–å†™ã€‚æœ‰æ—¶ï¼Œé‡æ–°å‚æ•°åŒ–å¯ä»¥æé«˜é‡‡æ ·å™¨çš„æ•ˆç‡æˆ–æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡é‡æ–°å‚æ•°åŒ–ï¼Œä½ å¯ä»¥æ¶ˆé™¤å‘æ•£ç°è±¡ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­è®²è§£å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚
- en: 4.8.1 Centered vs. noncentered hierarchical models
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.8.1 åˆ†å±‚æ¨¡å‹ï¼šé›†ä¸­å¼ä¸éé›†ä¸­å¼
- en: 'There are two common parametrizations for hierarchical linear models, centered
    and non-centered. The `hierarchical_centered` model uses the centered one. The
    hallmark of this parametrization is that we are directly estimating parameters
    for individual groups; for instance, we are explicitly estimating the slope of
    each group. On the contrary, for the non-centered parametrization, we estimate
    the common slope for all groups and then a deflection for each group. It is important
    to notice that we are still modeling the slope of each group, but relative to
    the common slope, the information we are getting is the same, just represented
    differently. Since a model is worth a thousand words, letâ€™s check `hierarchical_non_centered`:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: å±‚æ¬¡çº¿æ€§æ¨¡å‹æœ‰ä¸¤ç§å¸¸è§çš„å‚æ•°åŒ–æ–¹æ³•ï¼Œåˆ†åˆ«æ˜¯ä¸­å¿ƒåŒ–å’Œéä¸­å¿ƒåŒ–ã€‚`hierarchical_centered`æ¨¡å‹ä½¿ç”¨çš„æ˜¯ä¸­å¿ƒåŒ–æ–¹æ³•ã€‚è¯¥å‚æ•°åŒ–æ–¹æ³•çš„ç‰¹ç‚¹æ˜¯ï¼Œæˆ‘ä»¬ç›´æ¥ä¸ºå„ä¸ªå°ç»„ä¼°è®¡å‚æ•°ï¼›ä¾‹å¦‚ï¼Œæˆ‘ä»¬æ˜ç¡®åœ°ä¼°è®¡æ¯ä¸ªå°ç»„çš„æ–œç‡ã€‚ç›¸åï¼Œå¯¹äºéä¸­å¿ƒåŒ–å‚æ•°åŒ–æ–¹æ³•ï¼Œæˆ‘ä»¬ä¸ºæ‰€æœ‰å°ç»„ä¼°è®¡ä¸€ä¸ªå…±åŒçš„æ–œç‡ï¼Œç„¶åä¸ºæ¯ä¸ªå°ç»„ä¼°è®¡ä¸€ä¸ªåç§»é‡ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬ä»ç„¶æ˜¯åœ¨ä¸ºæ¯ä¸ªå°ç»„å»ºæ¨¡æ–œç‡ï¼Œä½†ç›¸å¯¹äºå…±åŒçš„æ–œç‡ï¼Œæ‰€è·å¾—çš„ä¿¡æ¯æ˜¯ç›¸åŒçš„ï¼Œåªæ˜¯è¡¨è¾¾æ–¹å¼ä¸åŒã€‚å› ä¸ºæ¨¡å‹èƒœè¿‡åƒè¨€ä¸‡è¯­ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹`hierarchical_non_centered`ï¼š
- en: '**CodeÂ 4.14**'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.14**'
- en: '[PRE13]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The difference is that for the model `hierarchical_centered`, we defined *Î²*
    âˆ¼ ![](img/N.PNG)(*Î²*[*Î¼*]*,*Î²**[*Ïƒ*]), and for `hierarchical_non_centered` we
    did *Î²* = *Î²*[*Î¼*] + *Î²*[offset] * *Î²*[*Ïƒ*]. The non-centered parametrization
    is more efficient: when I run the model I only get 2 divergences instead of 148
    as before. To remove these remaining divergences, we may still need to increase
    `target_accept`. For this particular case, changing it from 0.8 to 0.85 worked
    like magic. To fully understand why this reparametrization works, you need to
    understand the geometry of the posterior distribution, but thatâ€™s beyond the scope
    of this section. Donâ€™t worry, we will discuss this in *Chapter [10](CH10.xhtml#x1-18900010)*.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: åŒºåˆ«åœ¨äºï¼Œå¯¹äºæ¨¡å‹`hierarchical_centered`ï¼Œæˆ‘ä»¬å®šä¹‰äº†*Î²* âˆ¼ ![](img/N.PNG)(*Î²*[*Î¼*]*,*Î²**[*Ïƒ*])ï¼Œè€Œå¯¹äº`hierarchical_non_centered`ï¼Œæˆ‘ä»¬åˆ™å®šä¹‰äº†*Î²*
    = *Î²*[*Î¼*] + *Î²*[offset] * *Î²*[*Ïƒ*]ã€‚éä¸­å¿ƒåŒ–å‚æ•°åŒ–æ›´é«˜æ•ˆï¼šå½“æˆ‘è¿è¡Œæ¨¡å‹æ—¶ï¼Œåªæœ‰2ä¸ªå‘æ•£ç‚¹ï¼Œè€Œä¸æ˜¯ä¹‹å‰çš„148ä¸ªã€‚ä¸ºäº†å»é™¤è¿™äº›å‰©ä½™çš„å‘æ•£ç‚¹ï¼Œæˆ‘ä»¬å¯èƒ½ä»ç„¶éœ€è¦å¢åŠ `target_accept`ã€‚å¯¹äºè¿™ä¸ªç‰¹å®šçš„æ¡ˆä¾‹ï¼Œå°†å…¶ä»0.8æ”¹ä¸º0.85æ•ˆæœéå¸¸å¥½ã€‚è¦å®Œå…¨ç†è§£ä¸ºä»€ä¹ˆè¿™ç§é‡æ–°å‚æ•°åŒ–æœ‰æ•ˆï¼Œä½ éœ€è¦ç†è§£åéªŒåˆ†å¸ƒçš„å‡ ä½•ç»“æ„ï¼Œä½†è¿™è¶…å‡ºäº†æœ¬èŠ‚çš„èŒƒå›´ã€‚åˆ«æ‹…å¿ƒï¼Œæˆ‘ä»¬ä¼šåœ¨*ç¬¬[10ç« ](CH10.xhtml#x1-18900010)*è®¨è®ºè¿™ä¸ªé—®é¢˜ã€‚
- en: Now that our samples are divergence-free, we can go back to analyze the posterior.
    *Figure [4.17](#x1-90023r17)* shows the estimated values for *Î±* and *Î²* for `hierarchical_model`.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çš„æ ·æœ¬æ²¡æœ‰å‘æ•£ç‚¹äº†ï¼Œæˆ‘ä»¬å¯ä»¥å›å»åˆ†æåéªŒåˆ†å¸ƒã€‚*å›¾[4.17](#x1-90023r17)*å±•ç¤ºäº†`hierarchical_model`ä¸­*Î±*å’Œ*Î²*çš„ä¼°è®¡å€¼ã€‚
- en: '![PIC](img/file133.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file133.png)'
- en: '**FigureÂ 4.17**: Posterior distribution for *Î±* and *Î²* for `hierarchical_non_centered`'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.17**ï¼š`hierarchical_non_centered`æ¨¡å‹ä¸­*Î±*å’Œ*Î²*çš„åéªŒåˆ†å¸ƒ'
- en: The estimates for group `H` are still the ones with higher uncertainty. But
    the results look less crazy than those in *Figure [4.16](#x1-89014r16)*; the reason
    is that groups are sharing information. Hence, even when we donâ€™t have enough
    information to fit a line to a single point, group `H` *is being informed* by
    the other groups. Actually, all groups are informing all groups. This is the power
    of hierarchical models.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: å°ç»„`H`çš„ä¼°è®¡å€¼ä»ç„¶å…·æœ‰è¾ƒé«˜çš„ä¸ç¡®å®šæ€§ã€‚ä½†ç»“æœçœ‹èµ·æ¥æ¯”*å›¾[4.16](#x1-89014r16)*ä¸­çš„è¦æ›´åˆç†ï¼›åŸå› åœ¨äºå°ç»„ä¹‹é—´å…±äº«äº†ä¿¡æ¯ã€‚å› æ­¤ï¼Œå³ä½¿æˆ‘ä»¬æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯å°†ä¸€æ¡çº¿æ‹Ÿåˆåˆ°ä¸€ä¸ªå•ä¸€çš„ç‚¹ä¸Šï¼Œå°ç»„`H`ä¹Ÿ*å—åˆ°äº†å…¶ä»–å°ç»„çš„å½±å“*ã€‚å®é™…ä¸Šï¼Œæ‰€æœ‰å°ç»„éƒ½åœ¨ç›¸äº’å½±å“ã€‚è¿™å°±æ˜¯å±‚æ¬¡æ¨¡å‹çš„å¼ºå¤§ä¹‹å¤„ã€‚
- en: '*Figure [4.18](#x1-90024r18)* shows the fitted lines for each of the eight
    groups. We can see that we managed to fit a line to a single point. At first,
    this may sound weird or even fishy, but this is just a consequence of the structure
    of the hierarchical model. Each line is informed by the lines of the other groups,
    thus we are not truly adjusting a line to a single point. Instead, we are adjusting
    a line thatâ€™s been informed by the points in the other groups to a single point.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾[4.18](#x1-90024r18)*å±•ç¤ºäº†å…«ä¸ªå°ç»„çš„æ‹Ÿåˆçº¿ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå°½ç®¡æˆ‘ä»¬è®¾æ³•å°†ä¸€æ¡ç›´çº¿æ‹Ÿåˆåˆ°ä¸€ä¸ªå•ä¸€çš„ç‚¹ä¸Šï¼Œä¹ä¸€çœ‹è¿™å¯èƒ½æ˜¾å¾—å¥‡æ€ªç”šè‡³å¯ç–‘ï¼Œä½†è¿™åªæ˜¯å±‚æ¬¡æ¨¡å‹ç»“æ„çš„ç»“æœã€‚æ¯ä¸€æ¡çº¿éƒ½å—åˆ°å…¶ä»–å°ç»„çš„å½±å“ï¼Œå› æ­¤æˆ‘ä»¬å¹¶éçœŸæ­£åœ°å°†ä¸€æ¡çº¿æ‹Ÿåˆåˆ°ä¸€ä¸ªå•ä¸€çš„ç‚¹ï¼Œè€Œæ˜¯å°†ä¸€æ¡å·²è¢«å…¶ä»–å°ç»„æ•°æ®æ‰€å½±å“çš„çº¿æ‹Ÿåˆåˆ°è¯¥ç‚¹ã€‚'
- en: '![PIC](img/file134.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file134.png)'
- en: '**FigureÂ 4.18**: Fitted lines for `hierarchical_non_centered`'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.18**ï¼š`hierarchical_non_centered`çš„æ‹Ÿåˆçº¿'
- en: 4.9 Multiple linear regression
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.9 å¤šå…ƒçº¿æ€§å›å½’
- en: 'So far, we have been working with one dependent variable and one independent
    variable. Nevertheless, it is not unusual to have several independent variables
    that we want to include in our model. Some examples could be:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨å¤„ç†ä¸€ä¸ªå› å˜é‡å’Œä¸€ä¸ªè‡ªå˜é‡ã€‚ç„¶è€Œï¼Œæ‹¥æœ‰å¤šä¸ªè‡ªå˜é‡å¹¶å°†å®ƒä»¬çº³å…¥æ¨¡å‹æ˜¯å¾ˆå¸¸è§çš„ã€‚ä¸€äº›ä¾‹å­å¯èƒ½æ˜¯ï¼š
- en: Perceived quality of wine (dependent) and acidity, density, alcohol level, residual
    sugar, and sulfates content (independent variables)
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è‘¡è„é…’çš„æ„ŸçŸ¥è´¨é‡ï¼ˆå› å˜é‡ï¼‰å’Œé…¸åº¦ã€å¯†åº¦ã€é…’ç²¾å«é‡ã€æ®‹ç³–é‡ã€ç¡«é…¸ç›å«é‡ï¼ˆè‡ªå˜é‡ï¼‰
- en: A studentâ€™s average grades (dependent) and family income, distance from home
    to school, and motherâ€™s education level (categorical variable)
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å­¦ç”Ÿçš„å¹³å‡æˆç»©ï¼ˆå› å˜é‡ï¼‰å’Œå®¶åº­æ”¶å…¥ã€ä»å®¶åˆ°å­¦æ ¡çš„è·ç¦»ã€æ¯äº²çš„æ•™è‚²æ°´å¹³ï¼ˆç±»åˆ«å˜é‡ï¼‰
- en: We can easily extend the simple linear regression model to deal with more than
    one independent variable. We call this model multiple linear regression or, less
    often, multivariable linear regression (not to be confused with multivariate linear
    regression, the case where we have multiple dependent variables).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°å°†ç®€å•çº¿æ€§å›å½’æ¨¡å‹æ‰©å±•åˆ°å¤„ç†å¤šä¸ªè‡ªå˜é‡ã€‚æˆ‘ä»¬ç§°è¿™ç§æ¨¡å‹ä¸ºå¤šå…ƒçº¿æ€§å›å½’ï¼Œæˆ–è€…è¾ƒå°‘ä½¿ç”¨çš„åç§°æ˜¯å¤šå˜é‡çº¿æ€§å›å½’ï¼ˆä¸è¦ä¸å¤šå…ƒå›å½’çº¿æ€§å›å½’æ··æ·†ï¼Œåè€…æ˜¯æŒ‡æˆ‘ä»¬æœ‰å¤šä¸ªå› å˜é‡çš„æƒ…å†µï¼‰ã€‚
- en: 'In a multiple linear regression model, we model the mean of the dependent variable
    as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬å°†å› å˜é‡çš„å‡å€¼å»ºæ¨¡å¦‚ä¸‹ï¼š
- en: '![Î¼ = ğ›¼ + ğ›½1X1 + ğ›½2X2 + â‹…â‹…â‹…+ ğ›½kXk ](img/file135.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![Î¼ = ğ›¼ + ğ›½1X1 + ğ›½2X2 + â‹…â‹…â‹…+ ğ›½kXk ](img/file135.jpg)'
- en: 'Using linear algebra notation, we can write a shorter version:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨çº¿æ€§ä»£æ•°ç¬¦å·ï¼Œæˆ‘ä»¬å¯ä»¥å†™å‡ºæ›´ç®€çŸ­çš„ç‰ˆæœ¬ï¼š
- en: '![Î¼ = ğ›¼+ Xğ›½ ](img/file136.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![Î¼ = ğ›¼+ Xğ›½ ](img/file136.jpg)'
- en: '**X** is a matrix of size *n* Ã— *k* with the values of the independent variables,
    *Î²* is a vector of size *k* with the coefficients of the independent variables,
    and *n* is the number of observations.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**X**æ˜¯ä¸€ä¸ª*n* Ã— *k*å¤§å°çš„çŸ©é˜µï¼ŒåŒ…å«è‡ªå˜é‡çš„å€¼ï¼Œ*Î²*æ˜¯ä¸€ä¸ª*k*å¤§å°çš„å‘é‡ï¼ŒåŒ…å«è‡ªå˜é‡çš„ç³»æ•°ï¼Œ*n*æ˜¯è§‚æµ‹å€¼çš„æ•°é‡ã€‚'
- en: 'If you are a little rusty with your linear algebra, you may want to check the
    Wikipedia article about the dot product between two vectors and its generalization
    to matrix multiplication: [https://en.wikipedia.org/wiki/Dot_product](https://en.wikipedia.org/wiki/Dot_product).
    Basically, what you need to know is that we are just using a shorter and more
    convenient way to write our model:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¯¹çº¿æ€§ä»£æ•°æœ‰äº›ç”Ÿç–ï¼Œå¯èƒ½éœ€è¦æŸ¥çœ‹ç»´åŸºç™¾ç§‘å…³äºä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯åŠå…¶çŸ©é˜µä¹˜æ³•æ¨å¹¿çš„æ–‡ç« ï¼š[https://en.wikipedia.org/wiki/Dot_product](https://en.wikipedia.org/wiki/Dot_product)ã€‚åŸºæœ¬ä¸Šï¼Œä½ éœ€è¦çŸ¥é“çš„æ˜¯ï¼Œæˆ‘ä»¬åªæ˜¯åœ¨ä½¿ç”¨ä¸€ç§æ›´ç®€æ´ã€æ–¹ä¾¿çš„æ–¹å¼æ¥ä¹¦å†™æˆ‘ä»¬çš„æ¨¡å‹ï¼š
- en: '![ âˆ‘n X ğ›½ = ğ›½iXi = ğ›½1X1 + ğ›½2X2 + â‹…â‹…â‹…+ ğ›½kXk i ](img/file137.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘n X ğ›½ = ğ›½iXi = ğ›½1X1 + ğ›½2X2 + â‹…â‹…â‹…+ ğ›½kXk i ](img/file137.jpg)'
- en: Using the simple linear regression model, we find a straight line that (hopefully)
    explains our data. Under the multiple linear regression model, we find, instead,
    a hyperplane of dimension *k*. Thus, the multiple linear regression model is essentially
    the same as the simple linear regression model, the only difference being that
    now *Î²* is a vector and **X** is a matrix.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç®€å•çº¿æ€§å›å½’æ¨¡å‹ï¼Œæˆ‘ä»¬æ‰¾åˆ°äº†ä¸€æ¡ç›´çº¿ï¼Œèƒ½å¤Ÿï¼ˆå¸Œæœ›ï¼‰è§£é‡Šæˆ‘ä»¬çš„æ•°æ®ã€‚è€Œåœ¨å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ä¸‹ï¼Œæˆ‘ä»¬å¾—åˆ°çš„æ˜¯ä¸€ä¸ªç»´åº¦ä¸º*k*çš„è¶…å¹³é¢ã€‚å› æ­¤ï¼Œå¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹æœ¬è´¨ä¸Šä¸ç®€å•çº¿æ€§å›å½’æ¨¡å‹ç›¸åŒï¼Œå”¯ä¸€çš„åŒºåˆ«åœ¨äºï¼Œç°åœ¨*Î²*æ˜¯ä¸€ä¸ªå‘é‡ï¼Œ**X**æ˜¯ä¸€ä¸ªçŸ©é˜µã€‚
- en: To see an example of a
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹ä¸€ä¸‹ä¸‹é¢çš„ä¾‹å­
- en: 'multiple linear regression model, letâ€™s go back to the bikes dataset. We will
    use the temperature and the humidity of the day to predict the number of rented
    bikes:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ï¼Œè®©æˆ‘ä»¬å›åˆ°è‡ªè¡Œè½¦æ•°æ®é›†ã€‚æˆ‘ä»¬å°†ä½¿ç”¨å½“å¤©çš„æ¸©åº¦å’Œæ¹¿åº¦æ¥é¢„æµ‹ç§Ÿèµçš„è‡ªè¡Œè½¦æ•°é‡ï¼š
- en: '**CodeÂ 4.15**'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  4.15**'
- en: '[PRE14]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Please take a moment to compare `model_mlb`, which has two independent variables,
    `temperature` and `hour`, with `model_neg`, which only has one independent variable,
    `temperature`. The only difference is that now we have two *Î²* coefficients, one
    for each independent variable. The rest of the model is the same. Notice that
    we could have written *Î²* `= pm.Normal("`*Î²*`1", mu=0, sigma=10, shape=2)` and
    then used *Î²*`1[0]` and *Î²*`1[1]` in the definition of *Î¼*. I usually do that.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·èŠ±ä¸€ç‚¹æ—¶é—´å¯¹æ¯”`model_mlb`ï¼ˆæœ‰ä¸¤ä¸ªè‡ªå˜é‡ï¼š`temperature`å’Œ`hour`ï¼‰å’Œ`model_neg`ï¼ˆåªæœ‰ä¸€ä¸ªè‡ªå˜é‡ï¼š`temperature`ï¼‰ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸¤ä¸ª*Î²*ç³»æ•°ï¼Œæ¯ä¸ªè‡ªå˜é‡å¯¹åº”ä¸€ä¸ªç³»æ•°ã€‚æ¨¡å‹çš„å…¶ä½™éƒ¨åˆ†ç›¸åŒã€‚æ³¨æ„ï¼Œæˆ‘ä»¬æœ¬æ¥å¯ä»¥å†™ä½œ*Î²*`=
    pm.Normal("`*Î²*`1", mu=0, sigma=10, shape=2)`ï¼Œç„¶ååœ¨å®šä¹‰*Î¼*æ—¶ä½¿ç”¨*Î²*`1[0]`å’Œ*Î²*`1[1]`ã€‚æˆ‘é€šå¸¸ä¼šè¿™ä¹ˆåšã€‚
- en: As you can see, writing a multiple regression model is not that different from
    writing a simple regression model. Interpreting the results can be more challenging,
    though. For instance, the coefficient of `temperature` is now *Î²*[0] and the coefficient
    of `hour` is *Î²*[1]. We can still interpret the coefficients as the change in
    the dependent variable for a unit change in the independent variable. But now
    we have to be careful to specify which independent variable we are talking about.
    For instance, we can say that for a unit increase in the temperature, the number
    of rented bikes increases by *Î²*[0] units, while holding the value of `hour` constant.
    Or we can say that for a unit increase in the hour, the number of rented bikes
    increases by *Î²*[1] units, while holding the value of `temperature` constant.
    Also, the value of a coefficient for a given variable is dependent on what other
    variables we are including in the model. For instance, the coefficient of `temperature`
    will vary depending on whether we incorporate the variable `hour` into the model
    or not.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½ æ‰€è§ï¼Œç¼–å†™å¤šå…ƒå›å½’æ¨¡å‹ä¸ç¼–å†™ç®€å•å›å½’æ¨¡å‹å¹¶æ²¡æœ‰å¤ªå¤§ä¸åŒã€‚ä¸è¿‡ï¼Œè§£é‡Šç»“æœå¯èƒ½æ›´åŠ å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¾‹å¦‚ï¼Œ`temperature`çš„ç³»æ•°ç°åœ¨æ˜¯*Î²*[0]ï¼Œè€Œ`hour`çš„ç³»æ•°æ˜¯*Î²*[1]ã€‚æˆ‘ä»¬ä»ç„¶å¯ä»¥å°†ç³»æ•°è§£é‡Šä¸ºå› å˜é‡åœ¨è‡ªå˜é‡å˜åŒ–ä¸€ä¸ªå•ä½æ—¶çš„å˜åŒ–é‡ã€‚ä½†ç°åœ¨æˆ‘ä»¬å¿…é¡»å°å¿ƒåœ°æŒ‡å®šæˆ‘ä»¬æ­£åœ¨è®¨è®ºçš„æ˜¯å“ªä¸ªè‡ªå˜é‡ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è¯´ï¼Œæ¸©åº¦å¢åŠ ä¸€ä¸ªå•ä½æ—¶ï¼Œç§Ÿèµè‡ªè¡Œè½¦çš„æ•°é‡å¢åŠ *Î²*[0]ä¸ªå•ä½ï¼ŒåŒæ—¶ä¿æŒ`hour`çš„å€¼ä¸å˜ã€‚æˆ–è€…æˆ‘ä»¬å¯ä»¥è¯´ï¼Œå°æ—¶æ•°å¢åŠ ä¸€ä¸ªå•ä½æ—¶ï¼Œç§Ÿèµè‡ªè¡Œè½¦çš„æ•°é‡å¢åŠ *Î²*[1]ä¸ªå•ä½ï¼ŒåŒæ—¶ä¿æŒ`temperature`çš„å€¼ä¸å˜ã€‚æ­¤å¤–ï¼ŒæŸä¸€å˜é‡çš„ç³»æ•°å€¼å–å†³äºæˆ‘ä»¬åœ¨æ¨¡å‹ä¸­åŒ…å«äº†å“ªäº›å…¶ä»–å˜é‡ã€‚ä¾‹å¦‚ï¼Œ`temperature`çš„ç³»æ•°å°†æ ¹æ®æ˜¯å¦å°†`hour`å˜é‡çº³å…¥æ¨¡å‹è€Œæœ‰æ‰€å˜åŒ–ã€‚
- en: '*Figure [4.19](#x1-91017r19)* shows the *Î²* coefficients for models `model_neg`
    (only `temperature`) and for model `model_mld` (`temperature` and `hour`).'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [4.19](#x1-91017r19)* æ˜¾ç¤ºäº†æ¨¡å‹`model_neg`ï¼ˆä»…æœ‰`temperature`ï¼‰å’Œæ¨¡å‹`model_mld`ï¼ˆ`temperature`å’Œ`hour`ï¼‰çš„*Î²*ç³»æ•°ã€‚'
- en: '![PIC](img/file138.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file138.png)'
- en: '**FigureÂ 4.19**: Scaled *Î²* coefficients for `model_neg` and `model_mlb`'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 4.19**ï¼š`model_neg`å’Œ`model_mlb`çš„ç¼©æ”¾*Î²*ç³»æ•°'
- en: We can see that the coefficient of `temperature` is different in both models.
    This is because the effect of `temperature` on the number of rented bikes depends
    on the hour of the day. Even more, the values of the *Î²* coefficients have been
    scaled by the standard deviation of their corresponding independent variable,
    so we can make them comparable. We can see that once we include `hour` in the
    model, the effect of `temperature` on the number of rented bikes gets smaller.
    This is because the effect of `hour` is already explaining some of the variations
    in the number of rented bikes that were previously explained by `temperature`.
    In extreme cases, the addition of a new variable can make the coefficient go to
    0 or even change the sign. We will discuss more of this in the next chapter.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œ`temperature`çš„ç³»æ•°åœ¨ä¸¤ä¸ªæ¨¡å‹ä¸­æ˜¯ä¸åŒçš„ã€‚è¿™æ˜¯å› ä¸º`temperature`å¯¹ç§Ÿèµè‡ªè¡Œè½¦æ•°é‡çš„å½±å“å–å†³äºä¸€å¤©ä¸­çš„å°æ—¶æ•°ã€‚æ›´è¿›ä¸€æ­¥ï¼Œ*Î²*ç³»æ•°çš„å€¼å·²ç»é€šè¿‡å…¶å¯¹åº”çš„ç‹¬ç«‹å˜é‡çš„æ ‡å‡†å·®è¿›è¡Œäº†ç¼©æ”¾ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿å®ƒä»¬å…·æœ‰å¯æ¯”æ€§ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œä¸€æ—¦åœ¨æ¨¡å‹ä¸­åŠ å…¥äº†`hour`ï¼Œ`temperature`å¯¹ç§Ÿèµè‡ªè¡Œè½¦æ•°é‡çš„å½±å“å˜å¾—æ›´å°ã€‚è¿™æ˜¯å› ä¸º`hour`çš„å½±å“å·²ç»è§£é‡Šäº†ä¹‹å‰ç”±`temperature`è§£é‡Šçš„éƒ¨åˆ†ç§Ÿèµè‡ªè¡Œè½¦æ•°é‡çš„å˜åŒ–ã€‚åœ¨æç«¯æƒ…å†µä¸‹ï¼Œæ–°å¢ä¸€ä¸ªå˜é‡å¯èƒ½ä¼šä½¿ç³»æ•°å˜ä¸º0ï¼Œç”šè‡³æ”¹å˜ç¬¦å·ã€‚æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ç« ä¸­è¿›ä¸€æ­¥è®¨è®ºè¿™ä¸ªé—®é¢˜ã€‚
- en: 4.10 Summary
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.10 æ€»ç»“
- en: In this chapter, we have learned about linear regression, which aims to model
    the relationship between a dependent variable and an independent variable. We
    have seen how to use PyMC to fit a linear regression model and how to interpret
    the results and make plots that we can share with different audiences.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†çº¿æ€§å›å½’ï¼Œæ—¨åœ¨å»ºç«‹å› å˜é‡ä¸è‡ªå˜é‡ä¹‹é—´çš„å…³ç³»æ¨¡å‹ã€‚æˆ‘ä»¬äº†è§£äº†å¦‚ä½•ä½¿ç”¨PyMCæ‹Ÿåˆçº¿æ€§å›å½’æ¨¡å‹ï¼Œå¹¶å¦‚ä½•è§£é‡Šç»“æœå’Œåˆ¶ä½œå¯ä»¥ä¸ä¸åŒå—ä¼—åˆ†äº«çš„å›¾è¡¨ã€‚
- en: Our first example was a model with a Gaussian response. But then we saw that
    this is just one assumption and we can easily change it to deal with non-Gaussian
    responses, such as count data, using a NegativeBinomial regression model or a
    logistic regression model for binary data. We saw that when doing so we also need
    to set an inverse link function to map the linear predictor to the response variable.
    Using a Studentâ€™s t-distribution as the likelihood can be useful for dealing with
    outliers. We spent most of the chapter modeling the mean as a linear function
    of the independent variable, but we learned that we can also model other parameters,
    like the variance. This is useful when we have heteroscedastic data. We learned
    how to apply the concept of partial pooling to create hierarchical linear regression
    models. Finally, we briefly discussed multiple linear regression models.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªä¾‹å­æ˜¯ä¸€ä¸ªå…·æœ‰é«˜æ–¯å“åº”çš„æ¨¡å‹ã€‚ä½†éšåæˆ‘ä»¬çœ‹åˆ°è¿™åªæ˜¯ä¸€ä¸ªå‡è®¾ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°å°†å…¶æ›´æ”¹ä¸ºå¤„ç†éé«˜æ–¯å“åº”ï¼Œä¾‹å¦‚ä½¿ç”¨è´ŸäºŒé¡¹å›å½’æ¨¡å‹å¤„ç†è®¡æ•°æ•°æ®ï¼Œæˆ–ä½¿ç”¨é€»è¾‘å›å½’æ¨¡å‹å¤„ç†äºŒå…ƒæ•°æ®ã€‚æˆ‘ä»¬è¿˜çœ‹åˆ°ï¼Œå½“è¿™æ ·åšæ—¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦è®¾ç½®ä¸€ä¸ªé€†é“¾æ¥å‡½æ•°ï¼Œå°†çº¿æ€§é¢„æµ‹å™¨æ˜ å°„åˆ°å“åº”å˜é‡ã€‚ä½¿ç”¨Studentâ€™s
    tåˆ†å¸ƒä½œä¸ºä¼¼ç„¶å‡½æ•°å¯¹äºå¤„ç†å¼‚å¸¸å€¼å¾ˆæœ‰ç”¨ã€‚æˆ‘ä»¬èŠ±è´¹äº†å¤§éƒ¨åˆ†ç« èŠ‚å°†å‡å€¼å»ºæ¨¡ä¸ºè‡ªå˜é‡çš„çº¿æ€§å‡½æ•°ï¼Œä½†æˆ‘ä»¬äº†è§£åˆ°æˆ‘ä»¬ä¹Ÿå¯ä»¥å»ºæ¨¡å…¶ä»–å‚æ•°ï¼Œå¦‚æ–¹å·®ã€‚å½“æˆ‘ä»¬æœ‰å¼‚æ–¹å·®æ•°æ®æ—¶ï¼Œè¿™éå¸¸æœ‰ç”¨ã€‚æˆ‘ä»¬å­¦ä¼šäº†å¦‚ä½•åº”ç”¨éƒ¨åˆ†æ±‡èšçš„æ¦‚å¿µæ¥åˆ›å»ºå±‚æ¬¡çº¿æ€§å›å½’æ¨¡å‹ã€‚æœ€åï¼Œæˆ‘ä»¬ç®€è¦è®¨è®ºäº†å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ã€‚
- en: PyMC makes it very easy to implement all these different flavors of Bayesian
    linear regression by changing one or a few lines of code. In the next chapter,
    we will learn more about linear regression and we will learn about Bambi, a tool
    built on top of PyMC that makes it even easier to build and analyze linear regression
    models.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: PyMCé€šè¿‡ä¿®æ”¹ä¸€ä¸¤è¡Œä»£ç ï¼Œä½¿å¾—å®ç°å„ç§è´å¶æ–¯çº¿æ€§å›å½’å˜å¾—éå¸¸ç®€å•ã€‚åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ æ›´å¤šå…³äºçº¿æ€§å›å½’çš„å†…å®¹ï¼Œå¹¶ä¸”æˆ‘ä»¬å°†å­¦ä¹ Bambiï¼Œè¿™æ˜¯ä¸€ä¸ªæ„å»ºåœ¨PyMCä¹‹ä¸Šçš„å·¥å…·ï¼Œå®ƒä½¿å¾—æ„å»ºå’Œåˆ†æçº¿æ€§å›å½’æ¨¡å‹å˜å¾—æ›´åŠ å®¹æ˜“ã€‚
- en: 4.11 Exercises
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.11 ç»ƒä¹ 
- en: Using the howell dataset (available at [https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)),
    create a linear model of the weight (x) against the height (y). Exclude subjects
    that are younger than 18\. Explain the results.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨howellæ•°æ®é›†ï¼ˆå¯åœ¨[https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)è·å–ï¼‰ï¼Œåˆ›å»ºä¸€ä¸ªä½“é‡ï¼ˆxï¼‰ä¸èº«é«˜ï¼ˆyï¼‰ä¹‹é—´çš„çº¿æ€§æ¨¡å‹ã€‚æ’é™¤18å²ä»¥ä¸‹çš„å—è¯•è€…ã€‚è§£é‡Šç»“æœã€‚
- en: 'For four subjects, we get the weights (45.73, 65.8, 54.2, 32.59), but not their
    heights. Using the model from the previous exercise, predict the height for each
    subject, together with their 50% and 94% HDIs. Tip: Use `pm.MutableData`.'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹äºå››ä¸ªå—è¯•è€…ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä½“é‡ï¼ˆ45.73, 65.8, 54.2, 32.59ï¼‰ï¼Œä½†æ²¡æœ‰èº«é«˜ã€‚ä½¿ç”¨å‰é¢çš„æ¨¡å‹ï¼Œé¢„æµ‹æ¯ä¸ªå—è¯•è€…çš„èº«é«˜ï¼Œå¹¶ç»™å‡ºä»–ä»¬çš„50%å’Œ94%
    HDIã€‚æç¤ºï¼šä½¿ç”¨`pm.MutableData`ã€‚
- en: Repeat exercise 1, this time including those below 18 years old. Explain the
    results.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡å¤ç»ƒä¹ 1ï¼Œè¿™æ¬¡åŒ…æ‹¬18å²ä»¥ä¸‹çš„å—è¯•è€…ã€‚è§£é‡Šç»“æœã€‚
- en: It is known for many species that weight does not scale with height, but with
    the logarithm of the weight. Use this information to fit the howell data (including
    subjects from all ages).
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å·²çŸ¥è®¸å¤šç‰©ç§çš„ä½“é‡ä¸èº«é«˜ä¸æˆæ¯”ä¾‹ï¼Œè€Œæ˜¯ä¸ä½“é‡çš„å¯¹æ•°æˆæ¯”ä¾‹ã€‚ä½¿ç”¨è¿™ä¸€ä¿¡æ¯æ¥æ‹Ÿåˆhowellæ•°æ®ï¼ˆåŒ…æ‹¬æ‰€æœ‰å¹´é¾„æ®µçš„å—è¯•è€…ï¼‰ã€‚
- en: See the accompanying code `model_t2` (and the data associated with it). Experiment
    with priors for *Î½*, like the non-shifted Exponential and Gamma priors (they are
    commented on in the code). Plot the prior distribution to ensure that you understand
    them. An easy way to do this is to call the `pm.sample_prior_predictive()` function
    instead of `pm.sample()`. You can also use PreliZ.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹é™„å¸¦çš„ä»£ç `model_t2`ï¼ˆä»¥åŠä¸ä¹‹ç›¸å…³çš„æ•°æ®ï¼‰ã€‚å°è¯•ä¸åŒçš„*Î½*å…ˆéªŒï¼Œä¾‹å¦‚æœªç§»ä½çš„æŒ‡æ•°åˆ†å¸ƒå’Œä¼½ç›åˆ†å¸ƒå…ˆéªŒï¼ˆå®ƒä»¬åœ¨ä»£ç ä¸­æœ‰æ³¨é‡Šï¼‰ã€‚ç»˜åˆ¶å…ˆéªŒåˆ†å¸ƒï¼Œä»¥ç¡®ä¿ä½ ç†è§£å®ƒä»¬ã€‚ä¸€ç§ç®€å•çš„æ–¹æ³•æ˜¯è°ƒç”¨`pm.sample_prior_predictive()`å‡½æ•°ï¼Œè€Œä¸æ˜¯`pm.sample()`ã€‚ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨PreliZã€‚
- en: Rerun `model_lrs` using the `petal_length` variable and then the `petal_width`
    variable. What are the main differences in the results? How wide or narrow is
    the 94% HDI in each case?
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`petal_length`å˜é‡é‡æ–°è¿è¡Œ`model_lrs`ï¼Œç„¶åä½¿ç”¨`petal_width`å˜é‡ã€‚ç»“æœæœ‰å“ªäº›ä¸»è¦åŒºåˆ«ï¼Ÿåœ¨æ¯ç§æƒ…å†µä¸‹ï¼Œ94% HDIçš„å®½åº¦æ˜¯å¤šå¤§ï¼Ÿ
- en: Repeat the previous exercise, this time using a Studentâ€™s t-distribution as
    a weakly informative prior. Try different values of *Î½*.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡å¤å‰é¢çš„ç»ƒä¹ ï¼Œè¿™æ¬¡ä½¿ç”¨Studentâ€™s tåˆ†å¸ƒä½œä¸ºä¸€ä¸ªå¼±ä¿¡æ¯å…ˆéªŒã€‚å°è¯•ä¸åŒçš„*Î½*å€¼ã€‚
- en: Choose a dataset that you find interesting and use it with the simple linear
    regression model. Be sure to explore the results using ArviZ functions. If you
    do not have an interesting dataset, try searching online, for example, at [http://data.worldbank.org](http://data.worldbank.org)
    or [http://www.stat.ufl.edu/~winner/datasets.html](http://www.stat.ufl.edu/~winner/datasets.html).
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€‰æ‹©ä¸€ä¸ªä½ æ„Ÿå…´è¶£çš„æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨ç®€å•çº¿æ€§å›å½’æ¨¡å‹è¿›è¡Œåˆ†æã€‚ä¸€å®šè¦åˆ©ç”¨ ArviZ å‡½æ•°æ¢ç´¢ç»“æœã€‚å¦‚æœä½ æ²¡æœ‰æ‰¾åˆ°æ„Ÿå…´è¶£çš„æ•°æ®é›†ï¼Œå¯ä»¥å°è¯•åœ¨çº¿æœç´¢ï¼Œä¾‹å¦‚ï¼Œåœ¨
    [http://data.worldbank.org](http://data.worldbank.org) æˆ– [http://www.stat.ufl.edu/~winner/datasets.html](http://www.stat.ufl.edu/~winner/datasets.html)
    æŸ¥æ‰¾ã€‚
- en: Join our community Discord space
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ å…¥æˆ‘ä»¬çš„ç¤¾åŒº Discord ç©ºé—´
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at: [https://packt.link/bayesian](https://packt.link/bayesian)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ å…¥æˆ‘ä»¬çš„ Discord ç¤¾åŒºï¼Œä¸å¿—åŒé“åˆçš„äººä»¬ä¸€èµ·å­¦ä¹ ï¼Œå¹¶ä¸è¶…è¿‡5000åæˆå‘˜å…±åŒæˆé•¿ï¼Œé“¾æ¥åœ°å€ï¼š[https://packt.link/bayesian](https://packt.link/bayesian)
- en: '![PIC](img/file1.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file1.png)'
