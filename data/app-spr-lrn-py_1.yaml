- en: '*Chapter 1*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第一章*'
- en: Python Machine Learning Toolkit
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 机器学习工具包
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，你将能够：
- en: Explain supervised machine learning and describe common examples of machine
    learning problems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释监督学习，并描述常见的机器学习问题示例
- en: Install and load Python libraries into your development environment for use
    in analysis and machine learning problems
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装并加载 Python 库到开发环境中，用于分析和机器学习问题
- en: Access and interpret the documentation of a subset of Python libraries, including
    the powerful pandas library
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问并解读 Python 库子集的文档，包括强大的 pandas 库
- en: Create an IPython Jupyter notebook and use executable code cells and markdown
    cells to create a dynamic report
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个 IPython Jupyter 笔记本，并使用可执行代码单元和 markdown 单元来创建动态报告
- en: Load an external data source using pandas and use a variety of methods to search,
    filter, and compute descriptive statistics of the data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 pandas 加载外部数据源，并利用各种方法对数据进行搜索、过滤和计算描述性统计
- en: Clean a data source of mediocre quality and gauge the potential impact of various
    issues within the data source
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清洗质量较差的数据源，并评估数据源中各种问题可能产生的影响
- en: This chapter introduces supervised learning, Jupyter notebooks, and some of
    the most common pandas data methods.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了监督学习、Jupyter 笔记本以及一些常见的 pandas 数据方法。
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: The study and application of machine learning and artificial intelligence has
    recently been the source of much interest and research in the technology and business
    communities. Advanced data analytics and machine learning techniques have shown
    great promise in advancing many sectors, such as personalized healthcare and self-driving
    cars, as well as in solving some of the world's greatest challenges, such as combating
    climate change. This book has been designed to assist you in taking advantage
    of the unique confluence of events in the field of data science and machine learning
    today. Across the globe, private enterprises and governments are realizing the
    value and efficiency of data-driven products and services. At the same time, reduced
    hardware costs and open source software solutions are significantly reducing the
    barriers to entry of learning and applying machine learning techniques.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习和人工智能的研究与应用，近年来成为了科技和商业界广泛关注和研究的热点。先进的数据分析和机器学习技术在推动许多领域（如个性化医疗和自动驾驶汽车）发展方面展现出了巨大的潜力，同时也在解决全球一些重大挑战（如应对气候变化）方面发挥着重要作用。本书旨在帮助你抓住当前数据科学和机器学习领域的独特机遇。在全球范围内，私营企业和政府意识到数据驱动的产品和服务的价值和效率。同时，硬件成本的降低和开源软件解决方案的普及大大降低了学习和应用机器学习技术的门槛。
- en: Throughout this book, you will develop the skills required to identify, prepare,
    and build predictive models using supervised machine learning techniques in the
    Python programming language. The six chapters each cover one aspect of supervised
    learning. This chapter introduces a subset of the Python machine learning toolkit,
    as well as some of the things that need to be considered when loading and using
    data sources. This data exploration process is further explored in *Chapter 2*,
    *Exploratory Data Analysis and Visualization*, as we introduce exploratory data
    analysis and visualization. *Chapter 3*, *Regression Analysis*, and *Chapter 4*,
    *Classification*, look at two subsets of machine learning problems – regression
    and classification analysis – and demonstrate these techniques through examples.
    Finally, *Chapter 5*, *Ensemble Modeling*, covers ensemble networks, which use
    multiple predictions from different models to boost overall performance, while
    *Chapter 6*, *Model Evaluation*, covers the extremely important concepts of validation
    and evaluation metrics. These metrics provide a means of estimating the true performance
    of a model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将帮助你发展所需的技能，使你能够使用 Python 编程语言中的监督学习技术来识别、准备和构建预测模型。六个章节分别涵盖了监督学习的各个方面。本章介绍了
    Python 机器学习工具包的一个子集，以及在加载和使用数据源时需要考虑的一些事项。这个数据探索过程将在*第二章*《探索性数据分析与可视化》中进一步探讨，介绍探索性数据分析和可视化。*第三章*《回归分析》和*第四章*《分类》将探讨机器学习问题的两个子集——回归分析和分类分析，并通过实例展示这些技术。最后，*第五章*《集成建模》介绍了集成网络，该技术通过多个不同模型的预测来提高整体性能，而*第六章*《模型评估》则涵盖了验证和评估指标这两个极为重要的概念。这些指标提供了一种估计模型真实表现的方法。
- en: Supervised Machine Learning
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有监督机器学习
- en: A machine learning algorithm is commonly thought of as simply the mathematical
    process (or algorithm) itself, such as a neural network, deep neural network,
    or random forest algorithm. However, this is only a component of the overall system;
    firstly, we must define the problem that can be adequately solved using such techniques.
    Then, we must specify and procure a clean dataset that is composed of information
    that can be mapped from the first number space to a secondary one. Once the dataset
    has been designed and procured, the machine learning model can be specified and
    designed; for example, a single-layer neural network with 100 hidden nodes that
    uses a *tanh* activation function.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法通常被认为仅仅是数学过程（或算法）本身，例如神经网络、深度神经网络或随机森林算法。然而，这只是整体系统的一个组成部分；首先，我们必须定义可以通过这些技术充分解决的问题。接着，我们必须指定并获取一个干净的数据集，该数据集由可以从第一个数值空间映射到第二个数值空间的信息组成。一旦数据集被设计并获得，机器学习模型就可以被指定和设计；例如，使用*tanh*激活函数的100个隐藏节点的单层神经网络。
- en: With the dataset and model well defined, the means of determining the exact
    values for the model can be specified. This is a repetitive optimization process
    that evaluates the output of the model against some existing data and is commonly
    referred to as **training**. Once training has been completed and you have your
    defined model, then it is good practice to evaluate it against some reference
    data to provide a benchmark of overall performance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集和模型被明确定义后，可以指定确定模型精确值的方法。这是一个重复的优化过程，它通过评估模型的输出与现有数据的匹配度，通常被称为**训练**。一旦训练完成，且你拥有已定义的模型，接下来最好通过一些参考数据对其进行评估，以提供整体性能的基准。
- en: 'Considering this general description of a complete machine learning algorithm,
    the problem definition and data collection stages are often the most critical.
    What is the problem you are trying to solve? What outcome would you like to achieve?
    How are you going to achieve it? How you answer these questions will drive and
    define many of the subsequent decisions or model design choices. It is also in
    answering these questions that we will select which category of machine learning
    algorithms we will choose: supervised or unsupervised methods.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到完整机器学习算法的这个一般描述，问题定义和数据收集阶段通常是最关键的。你要解决的问题是什么？你希望达到什么样的结果？你打算如何实现这一目标？你如何回答这些问题将决定并定义后续的许多决策或模型设计选择。在回答这些问题时，我们将选择哪种机器学习算法类别：有监督还是无监督方法。
- en: 'So, what exactly are supervised and unsupervised machine learning problems
    or methods? **Supervised learning** techniques center on mapping some set of information
    to another by providing the training process with the input information and the
    desired outputs, then checking its ability to provide the correct result. As an
    example, let''s say you are the publisher of a magazine that reviews and ranks
    hairstyles from various time periods. Your readers frequently send you far more
    images of their favorite hairstyles for review than you can manually process.
    To save some time, you would like to automate the sorting of the hairstyles images
    you receive based on time periods, starting with hairstyles from the 1960s and
    1980s:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么是有监督和无监督机器学习问题或方法呢？**有监督学习**技术的核心是通过为训练过程提供输入信息和期望输出，映射某些信息集到另一个信息集，并检查其提供正确结果的能力。例如，假设你是一本杂志的出版商，负责评审并排名来自不同时间段的发型。你的读者常常会给你发送大量的发型图片，比你手动处理的要多。为了节省时间，你希望自动对收到的发型图片按时间段进行分类，从1960年代和1980年代的发型开始：
- en: '![Figure 1.1: Hairstyles images from different time periods'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.1：来自不同时间段的发型图片'
- en: '](img/C12622_01_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12622_01_01.jpg)'
- en: 'Figure 1.1: Hairstyles images from different time periods'
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.1：来自不同时间段的发型图片
- en: To create your hairstyles-sorting algorithm, you start by collecting a large
    sample of hairstyles images and manually labeling each one with its corresponding
    time period. Such a dataset (known as a **labeled dataset**) is the input data
    (hairstyles images) and the desired output information (time period) is known
    and recorded. This type of problem is a classic supervised learning problem; we
    are trying to develop an algorithm that takes a set of inputs and learns to return
    the answers that we have told it are correct.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建你的发型分类算法，你需要先收集大量发型图片，并手动为每一张图片标注对应的时间段。这样的数据集（称为**标注数据集**）是输入数据（发型图片），并且所需的输出信息（时间段）是已知且记录下来的。这种问题是经典的监督学习问题；我们试图开发一个算法，输入一组数据，然后让它学会返回我们已经告诉它正确的答案。
- en: When to Use Supervised Learning
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 何时使用监督学习
- en: 'Generally, if you are trying to automate or replicate an existing process,
    the problem is a supervised learning problem. Supervised learning techniques are
    both very useful and powerful, and you may have come across them or even helped
    create labeled datasets for them without realizing. As an example, a few years
    ago, Facebook introduced the ability to tag your friends in any image uploaded
    to the platform. To tag a friend, you would draw a square over your friend''s
    face and then add the name of your friend to notify them of the image. Fast-forward
    to today and Facebook will automatically identify your friends in the image and
    tag them for you. This is yet another example of supervised learning. If you ever
    used the early tagging system and manually identified your friends in an image,
    you were in fact helping to create Facebook''s labeled dataset. A user who uploaded
    an image of a person''s face (the input data) and tagged the photo with the subject''s
    name would then create the label for the dataset. As users continued to use this
    tagging service, a sufficiently large labeled dataset was created for the supervised
    learning problem. Now friend-tagging is completed automatically by Facebook, replacing
    the manual process with a supervised learning algorithm, as opposed to manual
    user input:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，如果你试图自动化或复制一个现有的过程，那么这个问题就是一个监督学习问题。监督学习技术既非常有用又非常强大，或许你已经接触过它们，甚至在不知情的情况下帮助创建了它们的标注数据集。举个例子，几年前，Facebook
    引入了在平台上传任何图片时标记朋友的功能。要标记一个朋友，你只需在朋友的面部上画一个框，然后添加朋友的名字以通知他们图片的存在。快进到今天，Facebook
    会自动识别图片中的朋友并为你标记他们。这又是一个监督学习的例子。如果你曾经使用过早期的标记系统，并手动在图片中标记你的朋友，实际上你是在帮助创建 Facebook
    的标注数据集。用户上传一个人的面部图片（输入数据），并用该人物的名字标记照片，这样就为数据集创建了标签。随着用户持续使用这个标记服务，一个足够大的标注数据集就被创建出来，解决了监督学习问题。现在，Facebook
    自动完成朋友标记，使用监督学习算法替代了手动输入的过程：
- en: '![Figure 1.2: Tagging a friend on Facebook](img/C12622_01_02.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2：在 Facebook 上标记朋友](img/C12622_01_02.jpg)'
- en: 'Figure 1.2: Tagging a friend on Facebook'
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.2：在 Facebook 上标记朋友
- en: One particularly timely and straightforward example of supervised learning is
    the training of self-driving cars. In this example, the algorithm uses the target
    route as determined by the GPS system, as well as on-board instrumentation, such
    as speed measures, the brake position, and/or a camera or **Light Detection and
    Ranging** (**LIDAR**), for road obstacle detection as the labeled outputs of the
    system. During training, the algorithm samples the control inputs as provided
    by the human driver, such as speed, steering angle, and brake position, mapping
    them against the outputs of the system; thus providing the labeled dataset. This
    data can then be used to train the driving/navigation systems within the self-driving
    car or in simulation exercises.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一个特别及时且直接的监督学习例子是自动驾驶汽车的训练。在这个例子中，算法使用由 GPS 系统确定的目标路线，以及车载仪器，如速度测量、刹车位置和/或 **光学雷达**（**LIDAR**）进行道路障碍物检测，作为系统的标注输出。在训练过程中，算法采集人类驾驶员提供的控制输入，如速度、转向角度和刹车位置，并将其与系统的输出进行映射，从而提供标注数据集。这些数据可以用来训练自动驾驶汽车的驾驶/导航系统，或用于模拟练习。
- en: 'Image-based supervised problems, while popular, are not the only examples of
    supervised learning problems. Supervised learning is also commonly used in the
    automatic analysis of text to determine whether the opinion or tone of a message
    is positive, negative, or neutral. Such analysis is known as **sentiment analysis**
    and frequently involves creating and using a labeled dataset of a series of words
    or statements that are manually identified as either positive, neutral, or negative.
    Consider these sentences: *I like that movie* and *I hate that movie*. The first
    sentence is clearly positive, while the second is negative. We can then decompose
    the words in the sentences into either positive, negative, or neutral (both positive,
    both negative); see the following table:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图像的监督问题虽然很流行，但并不是监督学习问题的唯一例子。监督学习也常用于自动分析文本，以判断消息的意见或语气是积极的、消极的还是中立的。这种分析被称为**情感分析**，通常涉及创建并使用一个标记数据集，其中一系列的单词或语句被手动标识为积极、消极或中立。例如，考虑以下句子：*我喜欢这部电影*
    和 *我讨厌这部电影*。第一个句子显然是积极的，而第二个是消极的。我们可以将句子中的单词分解为积极、消极或中立（都积极、都消极）；见下表：
- en: '![Figure 1.3: Decomposition of the words](img/C12622_01_03.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.3：单词的分解](img/C12622_01_03.jpg)'
- en: 'Figure 1.3: Decomposition of the words'
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.3：单词的分解
- en: Using sentiment analysis, a supervised learning algorithm could be created,
    say, using the movie database site IMDb to analyze comments posted about movies
    to determine whether the movie is being positively or negatively reviewed by the
    audience. Supervised learning methods could have other applications, such as analyzing
    customer complaints, automating troubleshooting calls/chat sessions, or even medical
    applications such as analyzing images of moles to detect abnormalities ([https://www.nature.com/articles/nature21056](https://www.nature.com/articles/nature21056)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用情感分析，可能会创建一个监督学习算法，比如使用电影数据库网站IMDb分析发布的关于电影的评论，以确定观众是对电影进行积极评价还是消极评价。监督学习方法还可以应用于其他领域，如分析客户投诉、自动化故障排除电话/聊天会话，甚至在医学领域，如分析痣的图像来检测异常（[https://www.nature.com/articles/nature21056](https://www.nature.com/articles/nature21056)）。
- en: This should give you a good understanding of the concept of supervised learning,
    as well as some examples of problems that can be solved using these techniques.
    While supervised learning involves training an algorithm to map the input information
    to corresponding known outputs, **unsupervised learning** methods, by contrast,
    do not utilize known outputs, either because they are not available or even known.
    Rather than relying on a set of manually annotated labels, unsupervised learning
    methods model the supplied data through specific constraints or rules designed
    into the training process.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该能帮助你更好地理解监督学习的概念，以及一些可以使用这些技术解决的问题示例。监督学习涉及训练一个算法，将输入信息映射到相应的已知输出；而**无监督学习**方法则不同，它们不使用已知的输出，可能是因为这些输出不可用或甚至未知。无监督学习方法并不依赖于一组手动标注的标签，而是通过在训练过程中设计的特定约束或规则来对提供的数据进行建模。
- en: Clustering analysis is a common form of unsupervised learning where a dataset
    is to be divided into a specified number of different groups based on the clustering
    process being used. In the case of k-nearest neighbors clustering, each sample
    from the dataset is labeled or classified in accordance with the majority vote
    of the k-closest points to the sample. As there are no manually identified labels,
    the performance of unsupervised algorithms can vary greatly with the data being
    used, as well as the selected parameters of the model. For example, should we
    use the 5 closest or 10 closest points in the majority vote of the k-closest points?
    The lack of known and target outputs during training leads to unsupervised methods
    being commonly used in exploratory analysis or in scenarios where the ground truth
    targets are somewhat ambiguous and are better defined by the constraints of the
    learning method.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类分析是一种常见的无监督学习形式，其中数据集会根据所使用的聚类过程被划分为指定数量的不同组。以k近邻聚类为例，数据集中的每个样本会根据与该样本最接近的k个点的多数投票结果进行标记或分类。由于没有手动识别的标签，无监督算法的性能会根据使用的数据以及模型选择的参数大不相同。例如，我们是否应该在k个最接近的点中使用5个最接近的点，还是10个最接近的点进行多数投票？由于训练过程中缺乏已知和目标输出，无监督方法通常用于探索性分析或在那些真实目标比较模糊且通过学习方法的约束来更好定义的场景中。
- en: We will not cover unsupervised learning in great detail in this book, but it
    is useful to summarize the main difference between the two methods. Supervised
    learning methods require ground truth labels or the *answers* for the input data,
    while unsupervised methods do not use such labels, and the final result is determined
    by the constraints applied during the training process.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中我们不会深入讨论无监督学习，但总结两种方法之间的主要区别是有帮助的。监督学习方法需要真实标签或输入数据的*答案*，而无监督学习方法不使用这些标签，最终结果由训练过程中应用的约束决定。
- en: Why Python?
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么选择Python？
- en: 'So, why have we chosen the Python programming language for our investigation
    into supervised machine learning? There are a number of alternative languages
    available, including C++, R, and Julia. Even the Rust community is developing
    machine learning libraries for their up-and-coming language. There are a number
    of reasons why Python is the first-choice language for machine learning:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么我们选择Python编程语言来进行监督学习的研究呢？虽然有多种替代语言可供选择，包括C++、R和Julia，甚至Rust社区也在为其新兴语言开发机器学习库，但Python仍是机器学习的首选语言，原因有很多：
- en: There is great demand for developers with Python expertise in both industry
    and academic research.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在工业界和学术研究中，对具备Python技能的开发人员有着极大的需求。
- en: Python is currently one of the most popular programming languages, even reaching
    the number one spot in *IEEE Spectrum* magazine's survey of the top 10 programming
    languages ([https://spectrum.ieee.org/at-work/innovation/the-2018-top-programming-languages](https://spectrum.ieee.org/at-work/innovation/the-2018-top-programming-languages)).
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python目前是最受欢迎的编程语言之一，甚至在*IEEE Spectrum*杂志对十大编程语言的调查中位居第一（[https://spectrum.ieee.org/at-work/innovation/the-2018-top-programming-languages](https://spectrum.ieee.org/at-work/innovation/the-2018-top-programming-languages)）。
- en: Python is an open source project, with the entire source code for the Python
    programming language being freely available under the GNU GPL Version 2 license.
    This licensing mechanism has allowed Python to be used, modified, and even extended
    in a number of other projects, including the Linux operating system, supporting
    NASA ([https://www.python.org/about/success/usa/](https://www.python.org/about/success/usa/)),
    and a plethora of other libraries and projects that have provided additional functionality,
    choice, and flexibility to the Python programming language. In our opinion, this
    flexibility is one of the key components that has made Python so popular.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python是一个开源项目，Python编程语言的全部源代码在GNU GPL Version 2许可证下免费提供。这种许可机制使得Python能够在许多其他项目中使用、修改甚至扩展，包括Linux操作系统、支持NASA的项目（[https://www.python.org/about/success/usa/](https://www.python.org/about/success/usa/)），以及众多提供额外功能、选择和灵活性的库和项目。在我们看来，这种灵活性是Python如此受欢迎的关键因素之一。
- en: Python provides a common set of features that can be used to run a web server,
    a microservice on an embedded device, or to leverage the power of graphical processing
    units to perform precise calculations on large datasets.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python提供了一套通用的功能，可用于运行Web服务器、嵌入式设备上的微服务，或利用图形处理单元的强大功能对大型数据集进行精确计算。
- en: Using Python and a handful of specific libraries (or packages, as they are known
    in Python), an entire machine learning product can be developed—starting with
    exploratory data analysis, model definition, and refinement, through to API construction
    and deployment. All of these steps can be completed within Python to build an
    end-to-end solution. This is the significant advantage Python has over some of
    its competitors, particularly within the data science and machine learning space.
    While R and Julia have the advantage of being specifically designed for numerical
    and statistical computing, models developed in these languages typically require
    translation into some other language before they can be deployed in a production
    setting.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python和一些特定的库（或在Python中称为“包”），可以开发出整个机器学习产品——从探索性数据分析、模型定义与优化，到API构建和部署。这些步骤都可以在Python中完成，构建一个端到端的解决方案。这是Python相对于一些竞争者，特别是在数据科学和机器学习领域的一个显著优势。尽管R和Julia在数值计算和统计计算方面具有优势，但用这些语言开发的模型通常需要在部署到生产环境之前，转译成其他语言。
- en: We hope that, through this book, you will gain an understanding of the flexibility
    and power of the Python programming language and will start on the path of developing
    end-to-end supervised learning solutions in Python. So, let's get started.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望通过本书，你能了解 Python 编程语言的灵活性和强大功能，并开始开发 Python 中端到端监督学习解决方案的道路。那么，让我们开始吧。
- en: Jupyter Notebooks
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Jupyter 笔记本
- en: One aspect of the data science development environment that distinguishes itself
    from other Python projects is the use of IPython Jupyter notebooks ([https://jupyter.org](https://jupyter.org)).
    Jupyter notebooks provide a means of creating and sharing interactive documents
    with live, executable code snippets, and plots, as well as the rendering of mathematical
    equations through the Latex ([https://www.latex-project.org](https://www.latex-project.org))
    typesetting system. This section of the chapter will introduce you to Jupyter
    notebooks and some of their key features to ensure your development environment
    is correctly set up.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学开发环境的一个独特之处是使用 IPython Jupyter 笔记本 ([https://jupyter.org](https://jupyter.org))，这与其他
    Python 项目有所不同。Jupyter 笔记本提供了一种创建和共享交互式文档的方式，文档中可以包含实时执行的代码片段、图表以及通过 Latex ([https://www.latex-project.org](https://www.latex-project.org))
    排版系统渲染的数学公式。本章节将介绍 Jupyter 笔记本及其一些关键特性，确保你的开发环境正确设置。
- en: 'Throughout this book, we will make frequent reference to the documentation
    for each of the introduced tools/packages. The ability to effectively read and
    understand the documentation for each tool is extremely important. Many of the
    packages we will use contain so many features and implementation details that
    it is very difficult to memorize them all. The following documentation may come
    in handy for the upcoming section on Jupyter notebooks:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将经常参考每个介绍的工具/包的文档。有效阅读和理解每个工具的文档非常重要。我们将使用的许多包包含了如此多的功能和实现细节，以至于很难记住它们的所有内容。以下文档可能对接下来的
    Jupyter 笔记本部分有所帮助：
- en: The Anaconda documentation can be found at [https://docs.anaconda.com](https://docs.anaconda.com).
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda 文档可以在 [https://docs.anaconda.com](https://docs.anaconda.com) 找到。
- en: The Anaconda user guide can be found at [https://docs.anaconda.com/anaconda/user-guide](https://docs.anaconda.com/anaconda/user-guide).
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda 用户指南可以在 [https://docs.anaconda.com/anaconda/user-guide](https://docs.anaconda.com/anaconda/user-guide)
    找到。
- en: The Jupyter Notebook documentation can be found at [https://jupyter-notebook.readthedocs.io/en/stable/](https://jupyter-notebook.readthedocs.io/en/stable/).
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jupyter 笔记本文档可以在 [https://jupyter-notebook.readthedocs.io/en/stable/](https://jupyter-notebook.readthedocs.io/en/stable/)
    找到。
- en: 'Exercise 1: Launching a Jupyter Notebook'
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 1：启动 Jupyter 笔记本
- en: 'In this exercise, we will launch our Jupyter notebook. Ensure you have correctly
    installed Anaconda with Python 3.7, as per the *Preface*:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将启动 Jupyter 笔记本。请确保你已按 *前言* 中的说明正确安装了 Python 3.7 版本的 Anaconda：
- en: There are two ways of launching a Jupyter notebook through Anaconda. The first
    method is to open Jupyter using the `Anaconda` folder of the Windows Start menu.
    Click on the `http://localhost:8888`, and will start in a default folder path.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 Anaconda 启动 Jupyter 笔记本有两种方式。第一种方法是通过 Windows 开始菜单中的 `Anaconda` 文件夹打开 Jupyter。点击
    `http://localhost:8888`，它将在默认的文件夹路径下启动。
- en: 'The second method is to launch Jupyter via the Anaconda prompt. To launch the
    Anaconda prompt, simply click on the **Anaconda Prompt** menu item, also in the
    Windows Start menu, and you should see a pop-up window similar to the following
    screenshot:![Figure 1.4: Anaconda prompt](img/C12622_01_04.jpg)'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二种方法是通过 Anaconda 提示符启动 Jupyter。要启动 Anaconda 提示符，只需点击 Windows 开始菜单中的 **Anaconda
    Prompt** 菜单项，你应该会看到一个类似以下屏幕截图的弹出窗口：![图 1.4：Anaconda 提示符](img/C12622_01_04.jpg)
- en: 'Figure 1.4: Anaconda prompt'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.4：Anaconda 提示符
- en: 'Once in the Anaconda prompt, change to the desired directory using the `cd`
    (change directory) command. For example, to change into the `Desktop` directory
    for the `Packt` user, do the following:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入 Anaconda 提示符后，使用 `cd`（更改目录）命令切换到所需的目录。例如，要切换到 `Packt` 用户的 `Desktop` 目录，可以执行以下操作：
- en: '[PRE0]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once in the desired directory, launch a Jupyter notebook using the following
    command:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入所需的目录后，使用以下命令启动 Jupyter 笔记本：
- en: '[PRE1]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The notebook will launch with the working directory from the one you specified
    earlier. This then allows you to navigate and save your notebooks in the directory
    of your choice as opposed to the default, which can vary between systems, but
    is typically your home or `My Computer` directory. Irrespective of the method
    of launching Jupyter, a window similar to the following will open in your default
    browser. If there are existing files in the directory, you should also see them
    here:'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 笔记本将会在你之前指定的工作目录中启动。这样，你可以在你选择的目录中浏览并保存你的笔记本，而不是默认的目录，默认目录因系统而异，但通常是你的主目录或`我的电脑`目录。无论是通过何种方式启动
    Jupyter，都会在你的默认浏览器中打开一个类似下面的窗口。如果目录中有现有文件，你也应该在这里看到它们：
- en: '![Figure 1.5: Jupyter notebook launch window](img/C12622_01_05.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.5：Jupyter 笔记本启动窗口](img/C12622_01_05.jpg)'
- en: 'Figure 1.5: Jupyter notebook launch window'
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.5：Jupyter 笔记本启动窗口
- en: 'Exercise 2: Hello World'
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 2：Hello World
- en: 'The *Hello World* exercise is a rite of passage, so you certainly cannot be
    denied that experience! So, let''s print `Hello World` in a Jupyter notebook in
    this exercise:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*Hello World* 练习是一个必经之路，所以你当然不能错过这个体验！现在，让我们在这个练习中在 Jupyter 笔记本中打印出`Hello World`：'
- en: 'Start by creating a new Jupyter notebook by clicking on the **New** button
    and selecting **Python 3**. Jupyter allows you to run different versions of Python
    and other languages, such as R and Julia, all in the same interface. We can also
    create new folders or text files here too. But for now, we will start with a Python
    3 notebook:![Figure 1.6: Creating a new notebook](img/C12622_01_06.jpg)'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先通过点击**新建**按钮并选择**Python 3**来创建一个新的 Jupyter 笔记本。Jupyter 允许你在同一个界面中运行不同版本的 Python
    以及其他语言，如 R 和 Julia。我们也可以在这里创建新的文件夹或文本文件。但现在，我们将从一个 Python 3 笔记本开始：![图 1.6：创建一个新笔记本](img/C12622_01_06.jpg)
- en: 'Figure 1.6: Creating a new notebook'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.6：创建一个新笔记本
- en: 'This will launch a new Jupyter notebook in a new browser window. We will first
    spend some time looking over the various tools that are available in the notebook:'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将会在一个新的浏览器窗口中启动一个新的 Jupyter 笔记本。我们将首先花一些时间查看笔记本中可用的各种工具：
- en: '![Figure 1.7: The new notebook](img/C12622_01_07.jpg)'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.7：新笔记本](img/C12622_01_07.jpg)'
- en: 'Figure 1.7: The new notebook'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.7：新笔记本
- en: 'There are three main sections in each Jupyter notebook, as shown in the following
    screenshot: the title bar (**1**), the toolbar (**2**), and the body of the document
    (**3**). Let''s look at each of these components in order:'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个 Jupyter 笔记本有三个主要部分，如下截图所示：标题栏（**1**）、工具栏（**2**）和文档正文（**3**）。我们按顺序来看一下这些组件：
- en: '![Figure 1.8: Components of the notebook](img/C12622_01_08.jpg)'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.8：笔记本的组件](img/C12622_01_08.jpg)'
- en: 'Figure 1.8: Components of the notebook'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.8：笔记本的组件
- en: 'The title bar simply displays the name of the current Jupyter notebook and
    allows the notebook to be renamed. Click on the `Hello World` and click **Rename**:![Figure
    1.9: Renaming the notebook](img/C12622_01_09.jpg)'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标题栏仅显示当前 Jupyter 笔记本的名称，并允许对笔记本进行重命名。点击`Hello World`，然后点击**重命名**：![图 1.9：重命名笔记本](img/C12622_01_09.jpg)
- en: 'Figure 1.9: Renaming the notebook'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.9：重命名笔记本
- en: For the most part, the toolbar contains all the normal functionality that you
    would expect. You can open, save, and make copies of—or create new—Jupyter notebooks
    in the **File** menu. You can search replace, copy, and cut content in the **Edit**
    menu and adjust the view of the document in the **View** menu. As we discuss the
    body of the document, we will also describe some of the other functionalities
    in more detail, such as the ones included in the **Insert**, **Cell**, and **Kernel**
    menus. One aspect of the toolbar that requires further examination is the far
    right-hand side, the outline of the circle on the right of Python 3.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大多数情况下，工具栏包含所有你预期的常见功能。你可以在**文件**菜单中打开、保存和复制笔记本，或者创建新的 Jupyter 笔记本。在**编辑**菜单中，你可以查找替换、复制和剪切内容，在**视图**菜单中，你可以调整文档的显示方式。在我们讨论文档正文的同时，我们还会更详细地描述一些其他功能，例如**插入**、**单元格**和**内核**菜单中的功能。工具栏有一个部分需要进一步检查，即位于
    Python 3 右侧的圆形轮廓区域。
- en: 'Hover your mouse over the circle and you will see the **Kernel Idle** popup.
    This circle is an indicator to signify whether the Python kernel is currently
    processing; when processing, this circle indicator will be filled in. If you ever
    suspect that something is running or is not running, you can easily refer to this
    icon for more information. When the Python kernel is not running, you will see
    this:'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将鼠标悬停在圆圈上，你将看到**内核空闲**的弹出窗口。这个圆圈是一个指示器，用来表示 Python 内核当前是否正在处理；当正在处理时，这个圆圈指示器将被填充。如果你怀疑某些操作正在运行或没有运行，你可以轻松查看这个图标获取更多信息。当
    Python 内核没有运行时，你将看到这个：
- en: '![Figure 1.10: Kernel idle](img/C12622_01_10.jpg)'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.10：内核空闲](img/C12622_01_10.jpg)'
- en: 'Figure 1.10: Kernel idle'
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.10：内核空闲
- en: 'When the Python kernel is running, you will see this:'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当 Python 内核正在运行时，你会看到这个：
- en: '![Figure 1.11: Kernel busy](img/C12622_01_11.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.11：内核忙碌](img/C12622_01_11.jpg)'
- en: 'Figure 1.11: Kernel busy'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.11：内核忙碌
- en: This brings us to the body of the document, where the actual content of the
    notebook will be entered. Jupyter notebooks differ from standard Python scripts
    or modules, in that they are divided into separate executable cells. While Python
    scripts or modules will run the entirety of the script when executed, Jupyter
    notebooks can run all of the cells sequentially, or can also run them separately
    and in a different order if manually executed.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将带我们进入文档的主体部分，实际的 notebook 内容将在这里输入。Jupyter notebooks 与标准的 Python 脚本或模块不同，它们被分成多个可执行的单元格。虽然
    Python 脚本或模块在执行时会运行整个脚本，但 Jupyter notebooks 可以按顺序运行所有单元格，或者如果手动执行，还可以单独运行它们并以不同的顺序执行。
- en: 'Double-click on the first cell and enter the following:'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 双击第一个单元格并输入以下内容：
- en: '[PRE2]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Click on **Run** (or use the *Ctrl* + *Enter* keyboard shortcut):'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**运行**（或使用*Ctrl* + *Enter* 快捷键）：
- en: '![Figure 1.12: Running a cell](img/C12622_01_12.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.12：运行单元格](img/C12622_01_12.jpg)'
- en: 'Figure 1.12: Running a cell'
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.12：运行单元格
- en: Congratulations! You just completed *Hello World* in a Jupyter notebook.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你刚刚在 Jupyter notebook 中完成了*Hello World*。
- en: 'Exercise 3: Order of Execution in a Jupyter Notebook'
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3：Jupyter Notebook 中的执行顺序
- en: 'In the previous exercise, notice how the `print` statement is executed under
    the cell. Now let''s take it a little further. As mentioned earlier, Jupyter notebooks
    are composed of a number of separately executable cells; it is best to think of
    them as just blocks of code you have entered into the Python interpreter, and
    the code is not executed until you press the *Ctrl* + *Enter* keys. While the
    code is run at a different time, all of the variables and objects remain in the
    session within the Python kernel. Let''s investigate this a little further:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个练习中，注意到`print`语句是在单元格下方执行的。现在让我们再深入一点。如前所述，Jupyter notebooks 由多个可单独执行的单元格组成；最好将它们视为你输入到
    Python 解释器中的代码块，代码在你按下*Ctrl* + *Enter* 键之前不会执行。尽管代码在不同的时间运行，但所有的变量和对象都保持在 Python
    内核的会话中。让我们进一步探讨这一点：
- en: 'Launch a new Jupyter notebook and then, in three separate cells, enter the
    code shown in the following screenshot:![Figure 1.13: Entering code into multiple
    cells](img/C12622_01_13.jpg)'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动一个新的 Jupyter notebook，然后在三个单独的单元格中输入以下截图中显示的代码：![图 1.13：在多个单元格中输入代码](img/C12622_01_13.jpg)
- en: 'Figure 1.13: Entering code into multiple cells'
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.13：在多个单元格中输入代码
- en: Click `hello_world` variable is declared (and thus executed) in the second cell
    and remains in memory, and thus is printed in the third cell. As we mentioned
    before, you can also run the cells out of order.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`hello_world`变量在第二个单元格中被声明（并执行），并保持在内存中，因此会在第三个单元格中打印出来。如前所述，你还可以不按顺序运行这些单元格。
- en: 'Click on the second cell, containing the declaration of `hello_world`, change
    the value to add a few more exclamation points, and run the cell again:![Figure
    1.14: Changing the content of the second cell](img/C12622_01_14.jpg)'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击第二个单元格，里面包含了`hello_world`的声明，修改值，添加几个感叹号，然后重新运行该单元格：![图 1.14：更改第二个单元格的内容](img/C12622_01_14.jpg)
- en: 'Figure 1.14: Changing the content of the second cell'
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.14：更改第二个单元格的内容
- en: 'Notice that the second cell is now the most recently executed cell (`print`
    statement after it has not been updated. To update the `print` statement, you
    would then need to execute the cell below it. *Warning: be careful about your
    order of execution*. If you are not careful, you can easily override values or
    declare variables in cells below their first use, as in notebooks, you no longer
    need to run the entire script at once. As such, it is good practice to regularly
    click **Kernel** | **Restart & Run All**. This will clear all variables from memory
    and run all cells from top to bottom in order. There is also the option to run
    all cells below or above a particular cell in the **Cell** menu:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意第二个单元格现在是最新执行的单元格（`print` 语句后它没有更新）。要更新 `print` 语句，你需要执行其下方的单元格。*警告：小心执行顺序*。如果不小心，你很容易覆盖值或在变量首次使用之前在下方单元格中声明变量，因为在
    notebooks 中，你不需要一次性运行整个脚本。因此，建议定期点击 **Kernel** | **Restart & Run All**。这将清除内存中的所有变量，并按顺序从上到下运行所有单元格。你还可以在
    **Cell** 菜单中选择运行特定单元格下方或上方的所有单元格：
- en: '![Figure 1.15: Restarting the kernel](img/C12622_01_15.jpg)'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.15：重启内核](img/C12622_01_15.jpg)'
- en: 'Figure 1.15: Restarting the kernel'
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.15：重启内核
- en: Note
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Write and structure your notebook cells as if you were to run them all in order,
    top to bottom. Use manual cell execution only for debugging/early investigation.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 写作和组织你的 notebook 单元格时，应该像是要按顺序从上到下依次运行它们一样。仅在调试/早期调查时使用手动单元格执行。
- en: 'You can also move cells around using either the up/down arrows on the left
    of `hello_world` variable to above its declaration:![Figure 1.16: Moving cells](img/C12622_01_16.jpg)'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你还可以使用 `hello_world` 变量左侧的上下箭头将单元格移动到其声明之前：![图 1.16：移动单元格](img/C12622_01_16.jpg)
- en: 'Figure 1.16: Moving cells'
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.16：移动单元格
- en: 'Click on **Restart & Run All** cells:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Restart & Run All** 单元格：
- en: '![Figure 1.17: Variable not defined error](img/C12622_01_17.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.17：变量未定义错误](img/C12622_01_17.jpg)'
- en: 'Figure 1.17: Variable not defined error'
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.17：变量未定义错误
- en: Notice the error reporting that the variable is not defined. This is because
    it is being used before its declaration. Also, notice that the cell after the
    error has not been executed as shown by the empty **In [ ]**.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 注意错误报告中显示变量未定义。这是因为它在声明之前被使用了。还要注意，错误后的单元格没有被执行，**In [ ]** 显示为空。
- en: 'Exercise 4: Advantages of Jupyter Notebooks'
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 4：Jupyter Notebooks 的优势
- en: 'There are a number of additional features of Jupyter notebooks that make them
    very useful. In this exercise, we will examine some of these features:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter notebooks 还有许多其他有用的功能。在本练习中，我们将探讨其中的一些功能：
- en: 'Jupyter notebooks can execute commands directly within the Anaconda prompt
    by including an exclamation point prefix (`!`). Enter the code shown in the following
    screenshot and run the cell:![Figure 1.18: Running Anaconda commands](img/C12622_01_18.jpg)'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Jupyter notebooks 可以通过在 Anaconda 提示符中包含感叹号前缀 (`!`) 来直接执行命令。输入以下截图所示的代码并运行该单元格：![图
    1.18：运行 Anaconda 命令](img/C12622_01_18.jpg)
- en: 'Figure 1.18: Running Anaconda commands'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.18：运行 Anaconda 命令
- en: One of the best features of Jupyter notebooks is the ability to create live
    reports that contain executable code. Not only does this save time in preventing
    separate creation of reports and code, but it can also assist in communicating
    the exact nature of the analysis being completed. Through the use of Markdown
    and HTML, we can embed headings, sections, images, or even JavaScript for dynamic
    content.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Jupyter notebooks 最棒的功能之一是能够创建包含可执行代码的实时报告。这不仅节省了防止分开创建报告和代码的时间，还能帮助传达正在完成的分析的准确性质。通过使用
    Markdown 和 HTML，我们可以嵌入标题、章节、图片，甚至是用于动态内容的 JavaScript。
- en: 'To use Markdown in our notebook, we first need to change the cell type. First,
    click on the cell you want to change to Markdown, then click on the **Code** drop-down
    menu and select **Markdown**:'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要在我们的 notebook 中使用 Markdown，首先需要更改单元格类型。首先，点击你想要更改为 Markdown 的单元格，然后点击 **Code**
    下拉菜单，选择 **Markdown**：
- en: '![Figure 1.19: Running Anaconda commands](img/C12622_01_19.jpg)'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.19：运行 Anaconda 命令](img/C12622_01_19.jpg)'
- en: 'Figure 1.19: Running Anaconda commands'
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.19：运行 Anaconda 命令
- en: Notice that **In [ ]** has disappeared and the color of the box lining the cell
    is no longer blue.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，**In [ ]** 已经消失，单元格边框的颜色不再是蓝色。
- en: 'You can now enter valid Markdown syntax and HTML by double-clicking in the
    cell and then clicking **Run** to render the markdown. Enter the syntax shown
    in the following screenshot and run the cell to see the output:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在您可以通过双击单元格并点击**运行**来输入有效的Markdown语法和HTML，以渲染Markdown。输入以下截图中显示的语法并运行单元格以查看输出：
- en: '![Figure 1.20: Markdown syntax](img/C12622_01_20.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图1.20：Markdown语法](img/C12622_01_20.jpg)'
- en: 'Figure 1.20: Markdown syntax'
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.20：Markdown语法
- en: 'The output will be as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '![Figure 1.21: Markdown output](img/C12622_01_21.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图1.21：Markdown输出](img/C12622_01_21.jpg)'
- en: 'Figure 1.21: Markdown output'
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.21：Markdown输出
- en: Note
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: For a quick reference on Markdown, refer to the `Markdown Syntax.ipynb` Jupyter
    notebook in the code files for this chapter.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 若要快速参考Markdown，请查看本章的代码文件中的`Markdown Syntax.ipynb` Jupyter笔记本。
- en: Python Packages and Modules
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python包和模块
- en: 'While the standard features that are included in Python are certainly feature-rich,
    the true power of Python lies in the additional libraries (also known as packages
    in Python), which, thanks to open source licensing, can be easily downloaded and
    installed through a few simple commands. In an Anaconda installation, it is even
    easier as many of the most common packages come pre-built within Anaconda. You
    can get a complete list of the pre-installed packages in the Anaconda environment
    by running the following command in a notebook cell:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Python包含的标准功能确实非常丰富，但Python真正的力量在于额外的库（在Python中也称为包），由于开源许可证，可以通过几个简单的命令轻松下载和安装。在Anaconda安装中，这更加简单，因为许多最常见的包都预先在Anaconda中构建。您可以通过在笔记本单元格中运行以下命令来获取Anaconda环境中预安装包的完整列表：
- en: '[PRE3]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In this book, we will be using the following additional Python packages:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将使用以下附加Python包：
- en: '**NumPy** (pronounced *Num Pie* and available at [https://www.numpy.org/](https://www.numpy.org/)):
    NumPy (short for numerical Python) is one of the core components of scientific
    computing in Python. NumPy provides the foundational data types from which a number
    of other data structures derive, including linear algebra, vectors and matrices,
    and key random number functionality.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NumPy**（发音为*Num Pie*，可访问[https://www.numpy.org/](https://www.numpy.org/)）：NumPy（即数值Python）是Python科学计算的核心组件之一。NumPy提供了基础数据类型，包括线性代数、向量和矩阵，以及关键的随机数功能。'
- en: '**SciPy** (pronounced *Sigh Pie* and available at [https://www.scipy.org](https://www.scipy.org)):
    SciPy, along with NumPy, is a core scientific computing package. SciPy provides
    a number of statistical tools, signal processing tools, and other functionality,
    such as Fourier transforms.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SciPy**（发音为*Sigh Pie*，可访问[https://www.scipy.org](https://www.scipy.org)）：SciPy与NumPy一起，是核心科学计算包。SciPy提供了许多统计工具、信号处理工具以及傅立叶变换等其他功能。'
- en: '**pandas** (available at [https://pandas.pydata.org/](https://pandas.pydata.org/)):
    pandas is a high-performance library for loading, cleaning, analyzing, and manipulating
    data structures.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pandas**（可访问[https://pandas.pydata.org/](https://pandas.pydata.org/)）：pandas是一个高性能库，用于加载、清理、分析和操作数据结构。'
- en: '**Matplotlib** (available at [https://matplotlib.org/](https://matplotlib.org/)):
    Matplotlib is the foundational Python library for creating graphs and plots of
    datasets and is also the base package from which other Python plotting libraries
    derive. The Matplotlib API has been designed in alignment with the Matlab plotting
    library to facilitate an easy transition to Python.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib**（可访问[https://matplotlib.org/](https://matplotlib.org/)）：Matplotlib是创建数据集的图形和图表的基础Python库，也是其他Python绘图库的基础包。Matplotlib
    API与Matlab绘图库设计保持一致，以便轻松过渡到Python。'
- en: '**Seaborn** (available at [https://seaborn.pydata.org/](https://seaborn.pydata.org/)):
    Seaborn is a plotting library built on top of Matplotlib, providing attractive
    color and line styles as well as a number of common plotting templates.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Seaborn**（可访问[https://seaborn.pydata.org/](https://seaborn.pydata.org/)）：Seaborn是建立在Matplotlib之上的绘图库，提供吸引人的颜色和线条样式，以及许多常见的绘图模板。'
- en: '**Scikit-learn** (available at [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)):
    Scikit-learn is a Python machine learning library that provides a number of data
    mining, modeling, and analysis techniques in a simple API. Scikit-learn includes
    a number of machine learning algorithms out of the box, including classification,
    regression, and clustering techniques.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scikit-learn**（可在 [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)
    获取）：Scikit-learn 是一个 Python 机器学习库，提供了一系列简单 API 的数据挖掘、建模和分析技术。Scikit-learn 包含了许多开箱即用的机器学习算法，包括分类、回归和聚类技术。'
- en: 'These packages form the foundation of a versatile machine learning development
    environment with each package contributing a key set of functionalities. As discussed,
    by using Anaconda, you will already have all of the required packages installed
    and ready for use. If you require a package that is not included in the Anaconda
    installation, it can be installed by simply entering and executing the following
    in a Jupyter notebook cell:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包构成了一个多功能的机器学习开发环境，每个包都提供了一套关键功能。如前所述，通过使用 Anaconda，您将已经安装并准备好所有必需的包。如果您需要一个在
    Anaconda 安装中未包含的包，可以通过在 Jupyter 笔记本单元中输入并执行以下命令来安装：
- en: '[PRE4]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As an example, if we wanted to install Seaborn, we''d run this:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，如果我们想要安装 Seaborn，只需运行以下命令：
- en: '[PRE5]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To use one of these packages in a notebook, all we need to do is import it:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要在笔记本中使用这些包，我们只需要导入它：
- en: '[PRE6]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: pandas
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: pandas
- en: As mentioned before, pandas is a library for loading, cleaning, and analyzing
    a variety of different data structures. It is the flexibility of pandas, in addition
    to the sheer number of built-in features, that makes it such a powerful, popular,
    and useful Python package. It is also a great package to start with as, obviously,
    we cannot analyze any data if we do not first load it into the system. As pandas
    provides so much functionality, one very important skill in using the package
    is the ability to read and understand the documentation. Even after years of experience
    programming in Python and using pandas, we still refer to the documentation very
    frequently. The functionality within the API is so extensive that it is impossible
    to memorize all of the features and specifics of the implementation.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，pandas 是一个用于加载、清洗和分析各种数据结构的库。正是由于 pandas 的灵活性，以及内置功能的丰富性，使其成为一个强大、流行且实用的
    Python 包。它也是一个非常适合入门的包，因为显然，如果我们不先将数据加载到系统中，就无法对其进行分析。由于 pandas 提供了如此多的功能，使用该包的一个非常重要的技能就是能够阅读和理解文档。即使是多年使用
    Python 编程和 pandas 的经验，我们仍然经常参考文档。API 中的功能如此广泛，以至于无法记住所有特性和实现细节。
- en: Note
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The pandas documentation can be found at [https://pandas.pydata.org/pandas-docs/stable/index.html](https://pandas.pydata.org/pandas-docs/stable/index.html).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 文档可以在 [https://pandas.pydata.org/pandas-docs/stable/index.html](https://pandas.pydata.org/pandas-docs/stable/index.html)
    找到。
- en: Loading Data in pandas
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 pandas 中加载数据
- en: 'pandas has the ability to read and write a number of different file formats
    and data structures, including CSV, JSON, and HDF5 files, as well as SQL and Python
    Pickle formats. The pandas input/output documentation can be found at [https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html).
    We will continue to look into the pandas functionality through loading data via
    a CSV file. The dataset we will be using for this chapter is the *Titanic: Machine
    Learning from Disaster* dataset, available from [https://www.kaggle.com/c/Titanic/data](https://www.kaggle.com/c/Titanic/data)
    or [https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python](https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python),
    which contains a roll of the guests on board the Titanic as well as their age,
    survival status, and number of siblings/parents. Before we get started with loading
    the data into Python, it is critical that we spend some time looking over the
    information provided for the dataset so that we can have a thorough understanding
    of what it contains. Download the dataset and place it in the directory you''re
    working in.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 'pandas具有读取和写入多种文件格式和数据结构的能力，包括CSV、JSON和HDF5文件，以及SQL和Python Pickle格式。pandas的输入/输出文档可以在[https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)找到。我们将继续通过加载CSV文件来探讨pandas的功能。本章使用的数据集是*TITANIC:
    机器学习灾难*数据集，可以从[https://www.kaggle.com/c/Titanic/data](https://www.kaggle.com/c/Titanic/data)或[https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python](https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-Python)下载，该数据集包含了泰坦尼克号上乘客的名单以及他们的年龄、生存状态和兄弟姐妹/父母人数。在我们开始加载数据到Python之前，至关重要的是我们花些时间查看数据集提供的信息，以便全面了解其内容。请下载数据集并将其放置在你正在使用的目录中。'
- en: 'Looking at the description for the data, we can see that we have the following
    fields available:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 查看数据的描述，我们可以看到我们有以下字段可用：
- en: '![Figure 1.22: Fields in the Titanic dataset](img/C12622_01_22.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.22: 泰坦尼克数据集中的字段](img/C12622_01_22.jpg)'
- en: 'Figure 1.22: Fields in the Titanic dataset'
  id: totrans-146
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 1.22: 泰坦尼克数据集中的字段'
- en: 'We are also provided with some additional contextual information:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一些额外的上下文信息：
- en: '`pclass`: This is a proxy for socio-economic status, where first class is upper,
    second class is middle, and third class is lower status.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pclass`：这是社会经济地位的代理变量，其中头等舱为上层，中等舱为中层，三等舱为下层。'
- en: '`age`: This is a fractional value if less than 1; for example, *0.25* is 3
    months. If the age is estimated, it is in the form of *xx.5*.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`age`：如果年龄小于1，这是一个分数值；例如，*0.25*表示3个月。如果年龄是估算的，通常以*xx.5*的形式表示。'
- en: '`sibsp`: A sibling is defined as a brother, sister, stepbrother, or stepsister,
    and a spouse is a husband or wife.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sibsp`：兄弟姐妹定义为兄弟、姐妹、继兄或继姐，配偶定义为丈夫或妻子。'
- en: '`parch`: A parent is a mother or father, a child is a daughter, son, stepdaughter,
    or stepson. Children that traveled only with a nanny did not travel with a parent.
    Thus, *0* was assigned for this field.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`parch`：父母是指母亲或父亲，孩子是指女儿、儿子、继女或继子。只有与保姆一起旅行的儿童才不与父母一起旅行。因此，这一字段为*0*。'
- en: '`embarked`: The point of embarkation is the location where the passenger boarded
    the ship.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embarked`：登船地点是乘客登船的地点。'
- en: Note that the information provided with the dataset does not give any context
    as to how the data was collected. The `survival`, `pclass`, and `embarked` fields
    are known as categorical variables as they are assigned to one of a fixed number
    of labels or categories to indicate some other information. For example, in `embarked`,
    the `C` label indicates that the passenger boarded the ship at Cherbourg, and
    the value of `1` in `survival` indicates they survived the sinking.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，数据集提供的信息没有说明数据是如何收集的。`survival`、`pclass`和`embarked`字段被称为类别变量，因为它们被分配到固定数量的标签或类别中，用于表示其他信息。例如，在`embarked`字段中，`C`标签表示乘客在谢尔堡登船，而`survival`字段中的值`1`表示他们在沉船事故中幸存。
- en: 'Exercise 5: Loading and Summarizing the Titanic Dataset'
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '练习 5: 加载和总结泰坦尼克数据集'
- en: 'In this exercise, we will read our Titanic dataset into Python and perform
    a few basic summary operations on it:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将把泰坦尼克数据集读入Python，并对其执行一些基本的总结操作：
- en: 'Import the pandas package using shorthand notation, as shown in the following
    screenshot:![Figure 1.23: Importing the pandas package](img/C12622_01_23.jpg)'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '使用简写符号导入pandas包，如下图所示：![图 1.23: 导入pandas包](img/C12622_01_23.jpg)'
- en: 'Figure 1.23: Importing the pandas package'
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.23：导入 pandas 包
- en: 'Open the `titanic.csv` file by clicking on it in the Jupyter notebook home
    page:![Figure 1.24: Opening the CSV file](img/C12622_01_24.jpg)'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Jupyter notebook 首页中点击 `titanic.csv` 文件以打开它：![图 1.24：打开 CSV 文件](img/C12622_01_24.jpg)
- en: 'Figure 1.24: Opening the CSV file'
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.24：打开 CSV 文件
- en: 'The file is a CSV file, which can be thought of as a table, where each line
    is a row in the table and each comma separates columns in the table. Thankfully,
    we don''t need to work with these tables in raw text form and can load them using
    pandas:'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该文件是 CSV 文件，可以视为一个表格，其中每一行是表格中的一行，每个逗号分隔表格中的列。幸运的是，我们不需要以原始文本形式处理这些表格，可以使用 pandas
    将其加载：
- en: '![Figure 1.25: Contents of the CSV file](img/C12622_01_25.jpg)'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.25：CSV 文件的内容](img/C12622_01_25.jpg)'
- en: 'Figure 1.25: Contents of the CSV file'
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.25：CSV 文件的内容
- en: Note
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Take a moment to look up the pandas documentation for the `read_csv` function
    at [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).
    Note the number of different options available for loading CSV data into a pandas
    DataFrame.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 花点时间查看 pandas 文档中的 `read_csv` 函数，地址：[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)。请注意，加载
    CSV 数据到 pandas DataFrame 中有多种不同的选项。
- en: 'In an executable Jupyter notebook cell, execute the following code to load
    the data from the file:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在可执行的 Jupyter notebook 单元格中，执行以下代码来从文件加载数据：
- en: '[PRE7]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The pandas DataFrame class provides a comprehensive set of attributes and methods
    that can be executed on its own contents, ranging from sorting, filtering, and
    grouping methods to descriptive statistics, as well as plotting and conversion.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pandas DataFrame 类提供了一整套属性和方法，可以在其自身内容上执行，范围涵盖排序、过滤、分组方法到描述性统计分析、绘图和转换等功能。
- en: Note
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Open and read the documentation for pandas DataFrame objects at [https://pandas.pydata.org/pandas-docs/stable/reference/frame.html](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html).
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 打开并阅读关于 pandas DataFrame 对象的文档，地址：[https://pandas.pydata.org/pandas-docs/stable/reference/frame.html](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)。
- en: 'Read the first five rows of data using the `head()` method of the DataFrame:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 DataFrame 的 `head()` 方法读取前五行数据：
- en: '[PRE8]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Figure 1.26: Reading the first five rows](img/C12622_01_26.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.26：读取前五行](img/C12622_01_26.jpg)'
- en: 'Figure 1.26: Reading the first five rows'
  id: totrans-173
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.26：读取前五行
- en: In this sample, we have a visual representation of the information in the DataFrame.
    We can see that the data is organized in a tabular, almost spreadsheet-like structure.
    The different types of data are organized by columns, while each sample is organized
    by rows. Each row is assigned to an index value and is shown as the numbers **0**
    to **4** in bold on the left-hand side of the DataFrame. Each column is assigned
    to a label or name, as shown in bold at the top of the DataFrame.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们可以看到 DataFrame 中信息的可视化表示。我们可以看到数据是按表格形式组织的，几乎像一个电子表格。不同类型的数据按列组织，每个样本按行组织。每一行都有一个索引值，并且在
    DataFrame 的左侧以粗体数字 **0** 到 **4** 显示。每一列都有一个标签或名称，如同在 DataFrame 顶部以粗体显示的那样。
- en: The idea of a DataFrame as a kind of spreadsheet is a reasonable analogy; as
    we will see in this chapter, we can sort, filter, and perform computations on
    the data just as you would in a spreadsheet program. While not covered in this
    chapter, it is interesting to note that DataFrames also contain pivot table functionality,
    just like a spreadsheet ([https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html)).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 将 DataFrame 看作一种电子表格是一个合理的类比；正如我们将在本章中看到的那样，我们可以像在电子表格程序中一样对数据进行排序、过滤和计算。虽然本章没有涉及，但有趣的是，DataFrame
    还包含数据透视表功能，就像电子表格一样（[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html)）。
- en: 'Exercise 6: Indexing and Selecting Data'
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 6：索引和选择数据
- en: 'Now that we have loaded some data, let''s use the selection and indexing methods
    of the DataFrame to access some data of interest:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经加载了一些数据，让我们使用 DataFrame 的选择和索引方法来访问一些感兴趣的数据：
- en: 'Select individual columns in a similar way to a regular dictionary, by using
    the labels of the columns, as shown here:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以类似普通字典的方式选择单独的列，方法是使用列的标签，如下所示：
- en: '[PRE9]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Figure 1.27: Selecting the Age column](img/C12622_01_27.jpg)'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.27：选择 Age 列](img/C12622_01_27.jpg)'
- en: 'Figure 1.27: Selecting the Age column'
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.27：选择Age列
- en: 'If there are no spaces in the column name, we can also use the dot operator.
    If there are spaces in the column names, we will need to use the bracket notation:'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果列名中没有空格，我们也可以使用点操作符。如果列名中有空格，则需要使用括号表示法：
- en: '[PRE10]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Figure 1.28: Using the dot operator to select the Age column](img/C12622_01_28.jpg)'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.28：使用点操作符选择Age列](img/C12622_01_28.jpg)'
- en: 'Figure 1.28: Using the dot operator to select the Age column'
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.28：使用点操作符选择Age列
- en: 'Select multiple columns at once using bracket notation, as shown here:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用括号表示法一次选择多个列，如下所示：
- en: '[PRE11]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Figure 1.29: Selecting multiple columns](img/C12622_01_29.jpg)'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.29：选择多个列](img/C12622_01_29.jpg)'
- en: 'Figure 1.29: Selecting multiple columns'
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.29：选择多个列
- en: 'Select the first row using `iloc`:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`iloc`选择第一行：
- en: '[PRE12]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Figure 1.30: Selecting the first row](img/C12622_01_30.jpg)'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.30：选择第一行](img/C12622_01_30.jpg)'
- en: 'Figure 1.30: Selecting the first row'
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.30：选择第一行
- en: 'Select the first three rows using `iloc`:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`iloc`选择前三行：
- en: '[PRE13]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Figure 1.31: Selecting the first three rows](img/C12622_01_31.jpg)'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.31：选择前三行](img/C12622_01_31.jpg)'
- en: 'Figure 1.31: Selecting the first three rows'
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.31：选择前三行
- en: 'We can also get a list of all of the available columns. Do this as shown here:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以获取所有可用列的列表。按以下方式操作：
- en: '[PRE14]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![Figure 1.32: Getting all the columns](img/C12622_01_32.jpg)'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.32：获取所有列](img/C12622_01_32.jpg)'
- en: 'Figure 1.32: Getting all the columns'
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.32：获取所有列
- en: 'Use this list of columns and the standard Python slicing syntax to get columns
    2, 3, and 4, and their corresponding values:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这个列列表和标准的Python切片语法来获取第2、3和4列及其对应的值：
- en: '[PRE15]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![Figure 1.33: Getting the second, third, and fourth columns](img/C12622_01_33.jpg)'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.33：获取第二、第三和第四列](img/C12622_01_33.jpg)'
- en: 'Figure 1.33: Getting the second, third, and fourth columns'
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.33：获取第二、第三和第四列
- en: 'Use the `len` operator to get the number of rows in the DataFrame:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`len`操作符获取DataFrame中的行数：
- en: '[PRE16]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Figure 1.34: Getting the number of rows](img/C12622_01_34.jpg)'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.34：获取行数](img/C12622_01_34.jpg)'
- en: 'Figure 1.34: Getting the number of rows'
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.34：获取行数
- en: 'What if we wanted the value for the `Fare` column at row `2`? There are a few
    different ways to do so. First, we''ll try the row-centric methods. Do this as
    follows:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们想要获取`Fare`列在第`2`行的值，该怎么做呢？有几种不同的方法。首先，我们将尝试行中心方法。按以下方式操作：
- en: '[PRE17]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![Figure 1.35: Getting a particular value using the normal row-centric method](img/C12622_01_35.jpg)'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.35：使用正常的行中心方法获取特定值](img/C12622_01_35.jpg)'
- en: 'Figure 1.35: Getting a particular value using the normal row-centric method'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.35：使用正常的行中心方法获取特定值
- en: 'Try using the dot operator for the column. Do this as follows:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试使用点操作符来选择列。按以下方式操作：
- en: '[PRE18]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![Figure 1.36: Getting a particular value using the row-centric dot operator](img/C12622_01_36.jpg)'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.36：使用行中心点操作符获取特定值](img/C12622_01_36.jpg)'
- en: 'Figure 1.36: Getting a particular value using the row-centric dot operator'
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.36：使用行中心点操作符获取特定值
- en: 'Try using the column-centric method. Do this as follows:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试使用列中心方法。按以下方式操作：
- en: '[PRE19]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![Figure 1.37: Getting a particular value using the normal column-centric method](img/C12622_01_37.jpg)'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.37：使用正常的列中心方法获取特定值](img/C12622_01_37.jpg)'
- en: 'Figure 1.37: Getting a particular value using the normal column-centric method'
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.37：使用正常的列中心方法获取特定值
- en: 'Try the column-centric method with the dot operator. Do this as follows:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试使用列中心方法与点操作符。按以下方式操作：
- en: '[PRE20]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![Figure 1.38: Getting a particular value using the column-centric dot operator](img/C12622_01_38.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.38：使用列中心点操作符获取特定值](img/C12622_01_38.jpg)'
- en: 'Figure 1.38: Getting a particular value using the column-centric dot operator'
  id: totrans-225
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.38：使用列中心点操作符获取特定值
- en: 'Exercise 7: Advanced Indexing and Selection'
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 7：高级索引和选择
- en: 'With the basics of indexing and selection under our belt, we can turn our attention
    to more advanced indexing and selection. In this exercise, we will look at a few
    important methods for performing advanced indexing and selecting data:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在掌握了索引和选择的基础知识后，我们可以将注意力转向更高级的索引和选择。在这个练习中，我们将介绍一些执行高级索引和选择数据的重要方法：
- en: 'Create a list of the passengers'' names and ages for those passengers under
    the age of 21, as shown here:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为年龄小于21岁的乘客创建一个包含姓名和年龄的列表，如下所示：
- en: '[PRE21]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![Figure 1.39: List of the passengers’ names and ages for those passengers
    under the age of 21](img/C12622_01_39.jpg)'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图1.39：列出所有21岁以下乘客的姓名和年龄](img/C12622_01_39.jpg)'
- en: 'Figure 1.39: List of the passengers'' names and ages for those passengers under
    the age of 21'
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.39：列出所有21岁以下乘客的姓名和年龄
- en: 'Count how many child passengers there were, as shown here:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算儿童乘客的数量，如下所示：
- en: '[PRE22]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![Figure 1.40: Count of child passengers](img/C12622_01_40.jpg)'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图1.40：儿童乘客计数](img/C12622_01_40.jpg)'
- en: 'Figure 1.40: Count of child passengers'
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.40：儿童乘客计数
- en: 'Count how many passengers were between the ages of 21 and 30\. Do not use Python''s
    `and` logical operator for this step, but rather the ampersand symbol (`&`). Do
    this as follows:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算年龄在21到30岁之间的乘客数量。不要使用Python的`and`逻辑运算符，而是使用与符号（`&`）。操作如下：
- en: '[PRE23]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![Figure 1.41: Count of passengers between the ages of 21 and 30](img/C12622_01_41.jpg)'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图1.41：计算年龄在21到30岁之间的乘客](img/C12622_01_41.jpg)'
- en: 'Figure 1.41: Count of passengers between the ages of 21 and 30'
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.41：计算年龄在21到30岁之间的乘客
- en: 'Count the passengers that were either first- or third-class ticket holders.
    Again, we will not use the Python logical `or` operator but rather the pipe symbol
    (`|`). Do this as follows:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算那些持有一等舱或三等舱票的乘客。再次提醒，我们不会使用Python的`or`逻辑运算符，而是使用管道符号（`|`）。操作如下：
- en: '[PRE24]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![Figure 1.42: Count of passengers that were either first- or third-class ticket
    holders](img/C12622_01_42.jpg)'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图1.42：计算那些持有一等舱或三等舱票的乘客](img/C12622_01_42.jpg)'
- en: 'Figure 1.42: Count of passengers that were either first- or third-class ticket
    holders'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.42：计算那些持有一等舱或三等舱票的乘客
- en: 'Count the passengers who were not holders of either first- or third-class tickets.
    Do not simply select the second class ticket holders, but rather use the `~` symbol
    for the `not` logical operator. Do this as follows:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算那些既没有持有一等舱也没有持有三等舱票的乘客人数。不要简单地选择二等舱票的持有者，而是使用`~`符号作为`not`逻辑运算符。操作如下：
- en: '[PRE25]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![Figure 1.43: Count of passengers who were not holders of either first- or
    third-class tickets](img/C12622_01_43.jpg)'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图1.43：计算那些既没有持有一等舱也没有持有三等舱票的乘客](img/C12622_01_43.jpg)'
- en: 'Figure 1.43: Count of passengers who were not holders of either first- or third-class
    tickets'
  id: totrans-247
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.43：计算那些既没有持有一等舱也没有持有三等舱票的乘客
- en: 'We no longer need the `Unnamed: 0` column, so delete it using the `del` operator:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '我们不再需要`Unnamed: 0`列，因此可以使用`del`运算符将其删除：'
- en: '[PRE26]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![Figure 1.44: The del operator](img/C12622_01_44.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![图1.44：del运算符](img/C12622_01_44.jpg)'
- en: 'Figure 1.44: The del operator'
  id: totrans-251
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.44：del运算符
- en: pandas Methods
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: pandas方法
- en: Now that we are confident with some pandas basics, as well as some more advanced
    indexing and selecting tools, let's look at some other DataFrame methods. For
    a complete list of all methods available in a DataFrame, we can refer to the class
    documentation.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了一些pandas基础知识以及一些更高级的索引和选择工具，让我们来看一下其他DataFrame方法。有关所有可用方法的完整列表，我们可以参考类文档。
- en: Note
  id: totrans-254
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注
- en: The pandas documentation is available at [https://pandas.pydata.org/pandas-docs/stable/reference/frame.html](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: pandas文档可以在[https://pandas.pydata.org/pandas-docs/stable/reference/frame.html](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)找到。
- en: You should now know how many methods are available within a DataFrame. There
    are far too many to cover in detail in this chapter, so we will select a few that
    will give you a great start in supervised machine learning.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该知道DataFrame中有哪些方法可用。本章内容太多，无法详细介绍所有方法，因此我们将选择一些方法，帮助你在监督学习中起步。
- en: 'We have already seen the use of one method, `head()`, which provides the first
    five lines of the DataFrame. We can select more or less lines if we wish, by providing
    the number of lines as an argument, as shown here:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看过使用`head()`方法，它可以提供DataFrame的前五行。如果我们希望选择更多或更少的行，可以通过提供行数作为参数来实现，如下所示：
- en: '[PRE27]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Another useful method is `describe`, which is a super-quick way of getting
    the descriptive statistics of the data within a DataFrame. We can see next that
    the sample size (count), mean, minimum, maximum, standard deviation, and 25th,
    50th, and 75th percentiles are returned for all columns of numerical data in the
    DataFrame (note that text columns have been omitted):'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有用的方法是`describe`，它是快速获取DataFrame中数据描述性统计信息的方式。我们接下来可以看到，对于DataFrame中的所有数值数据列（注意文本列已被省略），返回了样本量（count）、均值、最小值、最大值、标准差以及25%、50%和75%的分位数：
- en: '[PRE28]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![Figure 1.45: The describe method](img/C12622_01_45.jpg)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.45：describe方法](img/C12622_01_45.jpg)'
- en: 'Figure 1.45: The describe method'
  id: totrans-262
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.45：describe方法
- en: Note that only columns of numerical data have been included within the summary.
    This simple command provides us with a lot of useful information; looking at the
    values for `count` (which counts the number of valid samples), we can see that
    there are 1,046 valid samples in the `Age` category, but 1,308 in `Fare`, and
    only 891 in `Survived`. We can see that the youngest person was 0.17 years, the
    average age is 29.898, and the eldest 80\. The minimum fare was £0, with £33.30
    the average and £512.33 the most expensive. If we look at the `Survived` column,
    we have 891 valid samples, with a mean of 0.38, which means about 38% survived.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，只有数值型数据列包含在汇总中。这个简单的命令为我们提供了很多有用的信息；查看`count`的值（它统计有效样本的数量），我们可以看到`Age`类别中有1,046个有效样本，`Fare`中有1,308个，`Survived`中只有891个。我们可以看到最年轻的人是0.17岁，平均年龄是29.898岁，最年长的是80岁。最低票价是£0，平均票价为£33.30，最贵票价为£512.33。如果我们查看`Survived`列，我们有891个有效样本，均值为0.38，这意味着大约38%的人存活。
- en: 'We can also get these values separately for each of the columns by calling
    the respective methods of the DataFrame, as shown here:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过调用DataFrame的各自方法，单独获取每一列的这些值，如下所示：
- en: '[PRE29]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![Figure 1.46: The count method](img/C12622_01_46.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.46：count方法](img/C12622_01_46.jpg)'
- en: 'Figure 1.46: The count method'
  id: totrans-267
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.46：count方法
- en: 'But we have some columns that contain text data, such as `Embarked`, `Ticket`,
    `Name`, and `Sex`. So, what about these? How can we get some descriptive information
    for these columns? We can still use `describe`; we just need to pass it some more
    information. By default, `describe` will only include numerical columns and will
    compute the 25th, 50th, and 75th percentiles. But we can configure this to include
    text-based columns by passing the `include = ''all''` argument, as shown here:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们有些列包含文本数据，如`Embarked`、`Ticket`、`Name`和`Sex`。那这些呢？我们怎么获取这些列的描述性信息呢？我们仍然可以使用`describe`，只需要为其提供更多信息。默认情况下，`describe`只会包含数值列，并计算第25、第50和第75百分位数。但我们可以通过传递`include
    = 'all'`参数来配置它，包含文本列，如下所示：
- en: '[PRE30]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '![Figure 1.47: The describe method with text-based columns](img/C12622_01_47.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.47：带有文本列的describe方法](img/C12622_01_47.jpg)'
- en: 'Figure 1.47: The describe method with text-based columns'
  id: totrans-271
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.47：带有文本列的describe方法
- en: That's better—now we have much more information. Looking at the `Cabin` column,
    we can see that there are 295 entries, with 186 unique values. The most common
    values are `C32`, `C25`, and `C27`, and they occur 6 times (from the `freq` value).
    Similarly, if we look at the `Embarked` column, we see that there are 1,307 entries,
    3 unique values, and that the most commonly occurring value is `S` with 914 entries.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 现在好多了——我们有更多的信息了。查看`Cabin`列，我们可以看到有295条记录，其中186个唯一值。最常见的值是`C32`、`C25`和`C27`，它们出现了6次（根据`freq`值）。类似地，如果我们查看`Embarked`列，我们可以看到有1,307条记录，3个唯一值，最常出现的值是`S`，出现了914次。
- en: Notice the occurrence of `NaN` values in our `describe` output table. `NaN`,
    or **Not a Number**, values are very important within DataFrames, as they represent
    missing or not available data. The ability of the pandas library to read from
    data sources that contain missing or incomplete information is both a blessing
    and a curse. Many other libraries would simply fail to import or read the data
    file in the event of missing information, while the fact that it can be read also
    means that the missing data must be handled appropriately.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意我们在`describe`输出表格中出现的`NaN`值。`NaN`，即**非数字**，在DataFrame中非常重要，因为它们表示缺失或不可用的数据。pandas库能够读取包含缺失或不完整信息的数据源既是一个优势也是一个弊端。许多其他库会在缺失信息的情况下直接无法导入或读取数据文件，而它能够读取数据也意味着必须适当地处理这些缺失的数据。
- en: 'When looking at the output of the `describe` method, you should notice that
    the Jupyter notebook renders it in the same way as the original DataFrame that
    we read in using `read_csv`. There is a very good reason for this, as the results
    returned by the `describe` method are themselves a pandas DataFrame and thus possess
    the same methods and characteristics as the data read in from the CSV file. This
    can be easily verified using Python''s built-in `type` function:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 查看`describe`方法的输出时，你应该注意到Jupyter Notebook将其呈现的方式与我们通过`read_csv`读取的原始DataFrame相同。这样做是有充分理由的，因为`describe`方法返回的结果本身就是一个pandas
    DataFrame，因此它具有与从CSV文件中读取的数据相同的方法和特性。你可以通过Python内建的`type`函数轻松验证这一点：
- en: '![Figure 1.48: Checking the type](img/C12622_01_48.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.48：检查类型](img/C12622_01_48.jpg)'
- en: 'Figure 1.48: Checking the type'
  id: totrans-276
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.48：检查类型
- en: Now that we have a summary of the dataset, let's dive in with a little more
    detail to get a better understanding of the available data.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了数据集的概览，接下来让我们深入一些，详细了解可用数据。
- en: Note
  id: totrans-278
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: A comprehensive understanding of the available data is critical in any supervised
    learning problem. The source and type of the data, the means by which it is collected,
    and any errors potentially resulting from the collection process all have an effect
    on the performance of the final model.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 对可用数据的全面理解在任何监督学习问题中都是至关重要的。数据的来源和类型、收集数据的方式以及收集过程中可能出现的任何错误都会影响最终模型的表现。
- en: Hopefully, by now, you are comfortable with using pandas to provide a high-level
    overview of the data. We will now spend some time looking into the data in greater
    detail.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 希望到目前为止，您已经能够熟练使用 pandas 提供数据的高层次概览。接下来我们将花些时间更深入地分析这些数据。
- en: 'Exercise 8: Splitting, Applying, and Combining Data Sources'
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 8：拆分、应用和合并数据源
- en: 'We have already seen how we can index or select rows or columns from a DataFrame
    and use advanced indexing techniques to filter the available data based on specific
    criteria. Another handy method that allows for such selection is the `groupby`
    method, which provides a quick method for selecting groups of data at a time and
    provides additional functionality through the `DataFrameGroupBy` object:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到如何从 DataFrame 中索引或选择行或列，并使用高级索引技术根据特定标准过滤可用数据。另一个有用的方法是 `groupby` 方法，它提供了一种快速选择一组数据的方法，并通过
    `DataFrameGroupBy` 对象提供了额外的功能：
- en: 'Use the `groupby` method to group the data by the `Embarked` column. How many
    different values for `Embarked` are there? Let''s see:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `groupby` 方法按 `Embarked` 列对数据进行分组。`Embarked` 列有多少个不同的值？让我们来看一下：
- en: '[PRE31]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![Figure 1.49: Grouping the data by the Embarked column](img/C12622_01_49.jpg)'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.49：按 Embarked 列对数据进行分组](img/C12622_01_49.jpg)'
- en: 'Figure 1.49: Grouping the data by the Embarked column'
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.49：按 Embarked 列对数据进行分组
- en: 'What does the `groupby` method actually do? Let''s check. Display the output
    of `embarked_grouped.groups`:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`groupby` 方法到底做了什么？我们来看看。显示 `embarked_grouped.groups` 的输出：'
- en: '[PRE32]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![Figure 1.50: Output of embarked_grouped.groups](img/C12622_01_50.jpg)'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.50：embarked_grouped.groups 的输出](img/C12622_01_50.jpg)'
- en: 'Figure 1.50: Output of embarked_grouped.groups'
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.50：embarked_grouped.groups 的输出
- en: We can see here that the three groups are `C`, `Q`, and `S`, and that `embarked_grouped.groups`
    is actually a dictionary where the keys are the groups. The values are the rows
    or indexes of the entries that belong to that group.
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里我们可以看到，三个组是 `C`、`Q` 和 `S`，而 `embarked_grouped.groups` 实际上是一个字典，字典的键是这些组，值是属于该组的行或索引。
- en: 'Use the `iloc` method to inspect row `1` and confirm that it belongs to embarked
    group `C`:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `iloc` 方法检查第 `1` 行，并确认它属于 Embarked 组 `C`：
- en: '[PRE33]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![Figure 1.51: Inspecting row 1](img/C12622_01_51.jpg)'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.51：检查第 1 行](img/C12622_01_51.jpg)'
- en: 'Figure 1.51: Inspecting row 1'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.51：检查第 1 行
- en: 'As the groups are a dictionary, we can iterate through them and execute computations
    on the individual groups. Compute the mean age for each group, as shown here:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于这些组是字典，我们可以遍历它们，并对各个组执行计算。计算每个组的平均年龄，如下所示：
- en: '[PRE34]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![Figure 1.52: Computing the mean age for each group using iteration](img/C12622_01_52.jpg)'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.52：使用迭代计算每个组的平均年龄](img/C12622_01_52.jpg)'
- en: 'Figure 1.52: Computing the mean age for each group using iteration'
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.52：使用迭代计算每个组的平均年龄
- en: 'Another option is to use the `aggregate` method, or `agg` for short, and provide
    it the function to apply across the columns. Use the `agg` method to determine
    the mean of each group:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另一种选择是使用 `aggregate` 方法，简称 `agg`，并提供要应用到列上的函数。使用 `agg` 方法来计算每个组的均值：
- en: '[PRE35]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![Figure 1.53: Using the agg method](img/C12622_01_53.jpg)'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.53：使用 agg 方法](img/C12622_01_53.jpg)'
- en: 'Figure 1.53: Using the agg method'
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.53：使用 agg 方法
- en: So, how exactly does `agg` work and what type of functions can we pass it? Before
    we can answer these questions, we need to first consider the data type of each
    column in the DataFrame, as each column is passed through this function to produce
    the result we see here. Each DataFrame is comprised of a collection of columns
    of pandas series data, which in many ways operates just like a list. As such,
    any function that can take a list or a similar iterable and compute a single value
    as a result can be used with `agg`.
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 那么，`agg`到底是如何工作的，我们可以传递什么类型的函数给它呢？在回答这些问题之前，我们需要首先考虑DataFrame中每列的数据类型，因为每列都会传递给此函数，以生成我们在此看到的结果。每个DataFrame由一组pandas系列数据列组成，这在许多方面类似于列表。因此，任何可以接受列表或类似可迭代对象并计算出一个单一值的函数，都可以与`agg`一起使用。
- en: 'As an example, define a simple function that returns the first value in the
    column, then pass that function through to `agg`:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 例如，定义一个简单的函数，返回列中的第一个值，然后将该函数传递给`agg`：
- en: '[PRE36]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![Figure 1.54: Using the agg method with a function](img/C12622_01_54.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.54：使用agg方法与函数](img/C12622_01_54.jpg)'
- en: 'Figure 1.54: Using the agg method with a function'
  id: totrans-308
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.54：使用agg方法与函数
- en: Lambda Functions
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Lambda函数
- en: One common and useful way of implementing `agg` is through the use of Lambda
    functions.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Lambda函数实现`agg`是一种常见且实用的方法。
- en: '`def` keyword. Lambda functions are essentially provided for convenience and
    aren''t intended to be used for extensive periods. The standard syntax for a Lambda
    function is as follows (always starting with the `lambda` keyword):'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '`def`关键字。Lambda函数本质上是为了方便而提供的，并不打算长期使用。Lambda函数的标准语法如下（始终以`lambda`关键字开头）：'
- en: '[PRE37]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Exercise 9: Lambda Functions'
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 9：Lambda函数
- en: 'In this exercise, we will create a Lambda function that returns the first value
    in a column and use it with `agg`:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将创建一个Lambda函数，该函数返回列中的第一个值，并与`agg`一起使用：
- en: 'Write the `first_val` function as a Lambda function, passed to `agg`:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`first_val`函数写为一个Lambda函数，并传递给`agg`：
- en: '[PRE38]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '![Figure 1.55: Using the agg method with a Lambda function](img/C12622_01_55.jpg)'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.55：使用agg方法与Lambda函数](img/C12622_01_55.jpg)'
- en: 'Figure 1.55: Using the agg method with a Lambda function'
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.55：使用agg方法与Lambda函数
- en: Obviously, we get the same result, but notice how much more convenient the Lambda
    function was to use, especially given the fact that it is only intended to be
    used briefly.
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 显然，我们得到了相同的结果，但请注意，Lambda函数的使用更加便捷，尤其是考虑到它本意仅用于短时间的操作。
- en: 'We can also pass multiple functions to `agg` via a list to apply the functions
    across the dataset. Pass the Lambda function as well as the NumPy mean and standard
    deviation functions, like this:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以通过列表将多个函数传递给`agg`，以便对整个数据集应用这些函数。传递Lambda函数以及NumPy的均值和标准差函数，如下所示：
- en: '[PRE39]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '![Figure 1.56: Using the agg method with multiple Lambda functions](img/C12622_01_56.jpg)'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.56：使用agg方法与多个Lambda函数](img/C12622_01_56.jpg)'
- en: 'Figure 1.56: Using the agg method with multiple Lambda functions'
  id: totrans-323
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.56：使用agg方法与多个Lambda函数
- en: 'What if we wanted to apply different functions to different columns in the
    DataFrame? Apply `numpy.sum` to the `Fare` column and the Lambda function to the
    `Age` column by passing `agg` a dictionary where the keys are the columns to apply
    the function to and the values are the functions themselves:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们想对DataFrame中的不同列应用不同的函数怎么办？可以通过向`agg`传递一个字典，字典的键是需要应用函数的列，而值是相应的函数，从而将`numpy.sum`应用到`Fare`列，将Lambda函数应用到`Age`列：
- en: '[PRE40]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![Figure 1.57: Using the agg method with a dictionary of different columns](img/C12622_01_57.jpg)'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.57：使用agg方法与包含不同列的字典](img/C12622_01_57.jpg)'
- en: 'Figure 1.57: Using the agg method with a dictionary of different columns'
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.57：使用agg方法与包含不同列的字典
- en: 'Finally, you can also execute the `groupby` method using more than one column.
    Provide the method with a list of the columns (`Sex` and `Embarked`) to `groupby`,
    like this:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，您还可以使用多个列来执行`groupby`方法。向方法提供一个包含列（`Sex`和`Embarked`）的列表进行`groupby`，如下所示：
- en: '[PRE41]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![Figure 1.58: Using the groupby method with more than one column](img/C12622_01_58.jpg)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.58：使用groupby方法与多个列](img/C12622_01_58.jpg)'
- en: 'Figure 1.58: Using the groupby method with more than one column'
  id: totrans-331
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.58：使用groupby方法与多个列
- en: Similar to when the groupings were computed by just the `Embarked` column, we
    can see here that a dictionary is returned where the keys are the combination
    of the `Sex` and `Embarked` columns returned as a tuple. The first key-value pair
    in the dictionary is a tuple, `('Male', 'S')`, and the values correspond to the
    indices of rows with that specific combination. There will be a key-value pair
    for each combination of unique values in the `Sex` and `Embarked` columns.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我们仅通过 `Embarked` 列进行分组时的情况，我们可以看到这里返回的是一个字典，其中键是`Sex`和`Embarked`列的组合，作为元组返回。字典中的第一个键值对是一个元组
    `('Male', 'S')`，值对应的是具有该特定组合的行的索引。对于`Sex`和`Embarked`列中每个唯一值的组合，都将有一个键值对。
- en: Data Quality Considerations
  id: totrans-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据质量考虑因素
- en: The quality of data used in any machine learning problem, supervised or unsupervised,
    is critical to the performance of the final model, and should be at the forefront
    when planning any machine learning project. As a simple rule of thumb, if you
    have clean data, in sufficient quantity, with a good correlation between the input
    data type and the desired output, then the specifics regarding the type and details
    of the selected supervised learning model become significantly less important
    to achieve a good result.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何机器学习问题中，无论是监督学习还是无监督学习，数据的质量对最终模型的表现至关重要，应该在规划任何机器学习项目时放在首位。简单的经验法则是，如果你拥有干净的数据，数据量足够，而且输入数据类型与期望输出之间有良好的相关性，那么关于所选监督学习模型的类型和细节就变得不那么重要，仍然可以获得良好的结果。
- en: In reality, however, this can rarely be the case. There are usually some issues
    regarding the quantity of available data, the quality or **signal-to-noise ratio**
    in the data, the correlation between the input and output, or some combination
    of all three factors. As such, we will use this last section of this chapter to
    consider some of the data quality problems that may occur and some mechanisms
    for addressing them. Previously, we mentioned that in any machine learning problem,
    having a thorough understanding of the dataset is critical if we to are construct
    a high-performing model. This is particularly the case when looking into data
    quality and attempting to address some of the issues present within the data.
    Without a comprehensive understanding of the dataset, additional noise or other
    unintended issues may be introduced during the data cleaning process leading to
    a further degradation of performance.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，实际上这种情况很少发生。通常会涉及到一些关于数据量、数据质量或**信噪比**、输入和输出之间的相关性，或者这些因素的某种组合。因此，我们将利用本章的最后部分来讨论可能出现的一些数据质量问题以及一些解决这些问题的机制。之前我们提到过，在任何机器学习问题中，彻底理解数据集是至关重要的，尤其是在构建高性能模型时。当涉及到数据质量并试图解决数据中的一些问题时，这一点尤其重要。如果没有对数据集的全面了解，在数据清理过程中可能会引入额外的噪声或其他意外问题，从而导致性能进一步下降。
- en: Note
  id: totrans-336
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: A detailed description of the Titanic dataset and the type of data included
    is contained in the *Loading Data in pandas* section. If you need a quick refresher,
    go back and review these details now.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 Titanic 数据集的详细描述以及其中包含的数据类型，详见 *在 pandas 中加载数据* 部分。如果你需要快速回顾这些细节，请现在回去查看。
- en: Managing Missing Data
  id: totrans-338
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理缺失数据
- en: 'As we discussed earlier, the ability of pandas to read data with missing values
    is both a blessing and a curse and arguably is the most common issue that needs
    to be managed before we can continue with developing our supervised learning model.
    The simplest, but not necessarily the most effective, method is to just remove
    or ignore those entries that are missing data. We can easily do this in pandas
    using the `dropna` method of the DataFrame:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，pandas 处理缺失数据的能力既是一个福音也是一个诅咒，这无疑是我们在继续开发监督学习模型之前需要管理的最常见问题。最简单的做法（但不一定是最有效的）是直接删除或忽略缺失数据的条目。我们可以通过
    pandas 中 `dropna` 方法轻松实现这一点：
- en: '[PRE42]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'There is one very significant consequence of simply dropping rows with missing
    data and that is we may be throwing away a lot of important information. This
    is highlighted very clearly in the Titanic dataset as a lot of rows contain missing
    data. If we were to simply ignore these rows, we would start with a sample size
    of 1,309 and end with a sample of 183 entries. Developing a reasonable supervised
    learning model with a little over 10% of the data would be very difficult indeed:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地丢弃缺失数据的行有一个非常重大的后果，那就是我们可能会丢失很多重要的信息。这在泰坦尼克数据集中非常明显，因为很多行都包含缺失数据。如果我们简单地忽略这些行，我们将从1,309个样本开始，最终只剩下183个样本。在仅使用不到10%的数据的情况下，开发一个合理的监督学习模型将变得非常困难：
- en: '![Figure 1.59: Total number of rows and total number of rows with NaN values](img/C12622_01_59.jpg)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.59：行总数和含有NaN值的行总数](img/C12622_01_59.jpg)'
- en: 'Figure 1.59: Total number of rows and total number of rows with NaN values'
  id: totrans-343
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.59：行总数和含有NaN值的行总数
- en: 'So, with the exception of the early, explorative phase, it is rarely acceptable
    to simply discard all rows with invalid information. We can be a little more sophisticated
    about this though. Which rows are actually missing information? Is the missing
    information problem unique to certain columns or is it consistent throughout all
    columns of the dataset? We can use `aggregate` to help us here as well:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，除了早期的探索性阶段，简单地丢弃所有包含无效信息的行通常是不被接受的。不过，我们可以对此稍微做得更复杂一些。到底是哪些行缺失了信息？缺失信息的问题是某些特定列独有的，还是贯穿整个数据集的所有列？我们也可以使用`aggregate`来帮助我们：
- en: '[PRE43]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![Figure 1.60: Using agg with a Lambda function to identify rows with NaN values](img/C12622_01_60.jpg)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.60：使用agg与Lambda函数识别含有NaN值的行](img/C12622_01_60.jpg)'
- en: 'Figure 1.60: Using agg with a Lambda function to identify rows with NaN values'
  id: totrans-347
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.60：使用agg与Lambda函数识别含有NaN值的行
- en: Now, this is useful! We can see that the vast majority of missing information
    is in the `Cabin` column, some in `Age`, and a little more in `Survived`. This
    is one of the first times in the data cleaning process that we may need to make
    an educated judgement call.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这很有用！我们可以看到，大多数缺失的信息都在`Cabin`列中，一些在`Age`列中，还有一点在`Survived`列中。这是数据清洗过程中第一次我们可能需要做出有根据的判断。
- en: What do we want to do with the `Cabin` column? There is so much missing information
    here that it, in fact, may not be possible to use it in any reasonable way. We
    could attempt to recover the information by looking at the names, ages, and number
    of parents/siblings and see whether we can match some families together to provide
    information, but there would be a lot of uncertainty in this process. We could
    also simplify the column by using the level of the cabin on the ship rather than
    the exact cabin number, which may then correlate better with name, age, and social
    status. This is unfortunate as there could be a good correlation between `Cabin`
    and `Survived`, as perhaps those passengers in the lower decks of the ship may
    have had a harder time evacuating. We could examine only the rows with valid `Cabin`
    values to see whether there is any predictive power in the `Cabin` entry; but,
    for now, we will simply disregard `Cabin` as a reasonable input (or feature).
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我们该如何处理`Cabin`列呢？这里缺失的信息太多，实际上可能无法以任何合理的方式使用它。我们可以尝试通过查看姓名、年龄和父母/兄弟姐妹的数量来恢复信息，看看能否将一些家庭联系起来提供信息，但这个过程会充满不确定性。我们也可以通过使用船舱的等级而不是具体的船舱号来简化该列，这可能与姓名、年龄和社会地位更好地相关。这是令人遗憾的，因为`Cabin`与`Survived`之间可能有很好的相关性，或许船舱较低层的乘客可能更难撤离。我们也可以仅查看包含有效`Cabin`值的行，看看`Cabin`条目是否具有任何预测能力；但现在，我们会暂时忽略`Cabin`作为一个合理的输入（或特征）。
- en: 'We can see that the `Embarked` and `Fare` columns only have three missing samples
    between them. If we decided that we needed the `Embarked` and `Fare` columns for
    our model, it would be a reasonable argument to simply drop these rows. We can
    do this using our indexing techniques, where `~` represents the `not` operation,
    or flipping the result (that is, where `df.Embarked` is not `NaN` and `df.Fare`
    is not `NaN`):'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，`Embarked`和`Fare`列之间只有三个缺失的样本。如果我们决定需要`Embarked`和`Fare`列来进行建模，那么仅仅丢弃这些行是一个合理的做法。我们可以使用索引技巧来完成这项操作，其中`~`表示`not`操作，或者翻转结果（即，`df.Embarked`不是`NaN`并且`df.Fare`不是`NaN`）：
- en: '[PRE44]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The missing age values are a little more interesting, as there are too many
    rows with missing age values to just discard them. But we also have a few more
    options here, as we can have a little more confidence in some plausible values
    to fill in. The simplest option would be to simply fill in the missing age values
    with the mean age for the dataset:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失的年龄值稍微有些复杂，因为有太多行缺少年龄值，不能仅仅把它们丢弃。但我们在这里有更多的选择，因为我们可以对一些合理的值有更多的信心来填充。最简单的选项是直接用数据集的平均年龄填补缺失的年龄值：
- en: '[PRE45]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'This is OK, but there are probably better ways of filling in the data rather
    than just giving all 263 people the same value. Remember, we are trying to clean
    up the data with the goal of maximizing the predictive power of the input features
    and the survival rate. Giving everyone the same value, while simple, doesn''t
    seem too reasonable. What if we were to look at the average ages of the members
    of each of the classes (`Pclass`)? This may give a better estimate, as the average
    age reduces from class 1 through 3:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做没问题，但可能有更好的方法来填充数据，而不是直接给所有263个人相同的值。记住，我们的目标是清理数据，以最大化输入特征的预测能力和生存率。虽然这种做法简单，但似乎不太合理。如果我们考虑每个类别（`Pclass`）成员的平均年龄呢？这可能会给出一个更好的估算，因为从类别1到类别3，平均年龄逐渐减少：
- en: '![Figure 1.61: Average ages of the members of each of the classes](img/C12622_01_61.jpg)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.61: 各个类别成员的平均年龄](img/C12622_01_61.jpg)'
- en: 'Figure 1.61: Average ages of the members of each of the classes'
  id: totrans-356
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 1.61: 各个类别成员的平均年龄'
- en: 'What if we consider sex as well as ticket class (social status)? Do the average
    ages differ here too? Let''s find out:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们考虑性别以及票种类（社会地位）呢？平均年龄在这里也有差异吗？让我们来看看：
- en: '[PRE46]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '![Figure 1.62: Average ages of the members of each sex and class](img/C12622_01_62.jpg)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.62: 各性别和类别成员的平均年龄](img/C12622_01_62.jpg)'
- en: 'Figure 1.62: Average ages of the members of each sex and class'
  id: totrans-360
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 1.62: 各性别和类别成员的平均年龄'
- en: 'We can see here that males in all ticket classes are typically older. This
    combination of sex and ticket class provides much more resolution than simply
    filling in all missing fields with the mean age. To do this, we will use the `transform`
    method, which applies a function to the contents of a series or DataFrame and
    returns another series or DataFrame with the transformed values. This is particularly
    powerful when combined with the `groupby` method:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，所有票种类的男性通常年龄较大。性别和票种类的组合提供了比简单地用平均年龄填补所有缺失值更高的分辨率。为了实现这一点，我们将使用`transform`方法，它将一个函数应用于序列或数据框的内容，并返回一个包含转换后值的序列或数据框。将它与`groupby`方法结合使用时尤其强大：
- en: '[PRE47]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'There is a lot in these two lines of code, so let''s break them down into components.
    Let''s look at the first line:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 这两行代码中有很多内容，所以让我们将其分解为几个部分。我们先看第一行：
- en: '[PRE48]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We are already familiar with `df_valid.groupby([''Pclass'', ''Sex''])[''Age'']`,
    which groups the data by ticket class and sex and returns only the `Age` column.
    The `lambda x: x.fillna(x.mean())` Lambda function takes the input pandas series,
    and fills the `NaN` values with the mean value of the series.'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '我们已经熟悉`df_valid.groupby([''Pclass'', ''Sex''])[''Age'']`，它根据票种类和性别对数据进行分组，并仅返回`Age`列。`lambda
    x: x.fillna(x.mean())` Lambda函数接受输入的pandas序列，并用该序列的均值填充`NaN`值。'
- en: 'The second line assigns the filled values within `mean_ages` to the `Age` column.
    Note the use of the `loc[:, ''Age'']` indexing method, which indicates that all
    rows within the `Age` column are to be assigned the values contained within `mean_ages`:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 第二行将`mean_ages`中的填充值赋给`Age`列。请注意使用了`loc[:, 'Age']`索引方法，这表示`Age`列中的所有行都将被赋予`mean_ages`中包含的值：
- en: '[PRE49]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We have described a few different ways of filling in the missing values within
    the `Age` column, but by no means has this been an exhaustive discussion. There
    are many more methods that we could use to fill the missing data: we could apply
    random values within one standard deviation of the mean for the grouped data,
    we could also look at grouping the data by sex and the number of parents/children
    (`Parch`) or by the number of siblings, or by ticket class, sex, and the number
    of parents/children. What is most important about the decisions made during this
    process is the end result of the prediction accuracy. We may need to try different
    options, rerun our models and consider the effect on the accuracy of final predictions.
    This is an important aspect of the process of feature engineering, that is, selecting
    the features or components that provide the model with the most predictive power;
    you will find that, during this process, you will try a few different features,
    run the model, look at the end result and repeat, until you are happy with the
    performance.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经描述了几种填补`Age`列缺失值的方法，但这并不是一个详尽的讨论。我们还有很多其他方法可以用来填补缺失数据：我们可以为分组数据应用均值一个标准差范围内的随机值，也可以根据性别、父母/子女数量（`Parch`）或兄弟姐妹数量，或者根据舱位、性别和父母/子女数量对数据进行分组。这个过程中最重要的决策是最终预测准确度的结果。在这个过程中，我们可能需要尝试不同的选项，重新运行模型并考虑其对最终预测准确度的影响。这是特征工程过程中一个重要的方面，即选择能为模型提供最大预测能力的特征或组件；在这个过程中，你会尝试不同的特征，运行模型，查看最终结果并重复，直到你对模型的表现感到满意。
- en: The ultimate goal of this supervised learning problem is to predict the survival
    of passengers on the Titanic given the information we have available. So, that
    means that the `Survived` column provides our labels for training. What are we
    going to do if we are missing 418 of the labels? If this was a project where we
    had control over the collection of the data and access to its origins, we would
    obviously correct this by recollecting or asking for the labels to be clarified.
    With the Titanic dataset, we do not have this ability so we must make another
    educated judgement call. We could try some unsupervised learning techniques to
    see whether there are some patterns in the survival information that we could
    use. However, we may not have a choice of simply ignoring these rows. The task
    is to predict whether a person survived or perished, not whether they may have
    survived. By estimating the ground truth labels, we may introduce significant
    noise into the dataset, reducing our ability to accurately predict survival.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 这个监督学习问题的最终目标是根据我们可用的信息预测泰坦尼克号乘客的生还情况。因此，这意味着`Survived`列提供了我们训练的标签。如果我们缺失了418个标签，我们该怎么办？如果这是一个我们可以控制数据收集并访问其来源的项目，我们显然可以通过重新收集数据或要求澄清标签来纠正这一点。在泰坦尼克号数据集中，我们无法做到这一点，因此必须做出另一个有根据的判断。我们可以尝试一些无监督学习技术，看看是否能发现一些可以用于生还信息的模式。然而，我们可能别无选择，只能忽略这些行。我们的任务是预测一个人是否生还，而不是他们是否可能生还。通过估算真实标签，我们可能会给数据集引入显著的噪音，降低我们准确预测生还情况的能力。
- en: Class Imbalance
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 类别不平衡
- en: 'Missing data is not the only problem that may be present within a dataset.
    Class imbalance – that is, having more of one class or classes compared to another
    – can be a significant problem, particularly in the case of classification problems
    (we''ll see more on classification in *Chapter 4*, *Classification*), where we
    are trying to predict which class (or classes) a sample is from. Looking at our
    `Survived` column, we can see that there are far more people who perished (`Survived`
    equals `0`) than survived (`Survived` equals `1`) in the dataset:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据并不是数据集可能存在的唯一问题。类别不平衡——即某一类别或多个类别的样本数远多于其他类别——可能是一个显著的问题，特别是在分类问题中（我们将在*第4章*，*分类*中深入讨论分类问题），在这些问题中，我们试图预测一个样本属于哪个类别（或哪些类别）。查看我们的`Survived`列，我们可以看到数据集中死亡人数（`Survived`为`0`）远多于生还人数（`Survived`为`1`）：
- en: '![Figure 1.63: Number of people who perished versus survived](img/C12622_01_63.jpg)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.63: 死亡与生还人数对比](img/C12622_01_63.jpg)'
- en: 'Figure 1.63: Number of people who perished versus survived'
  id: totrans-373
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 1.63: 死亡与生还人数对比'
- en: If we don't take this class imbalance into account, the predictive power of
    our model could be significantly reduced as, during training, the model would
    simply need to guess that the person did not survive to be correct 61% (*549 /
    (549 + 342)*) of the time. If, in reality, the actual survival rate was, say,
    50%, then when being applied to unseen data, our model would predict not survived
    too often.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不考虑类别不平衡，模型的预测能力可能会大大降低，因为在训练过程中，模型只需要猜测“该人未能幸存”就可以正确预测61%（*549 / (549 +
    342)*)的时间。如果现实中的实际生存率是50%，那么当模型应用于未见数据时，可能会过度预测未幸存的情况。
- en: There are a few options available for managing class imbalance, one of which,
    similar to the missing data scenario, is to randomly remove samples from the over-represented
    class until balance has been achieved. Again, this option is not ideal, or perhaps
    even appropriate, as it involves ignoring available data. A more constructive
    example may be to oversample the under-represented class by randomly copying samples
    from the under-represented class in the dataset to boost the number of samples.
    While removing data can lead to accuracy issues due to discarding useful information,
    oversampling the under-represented class can lead to being unable to predict the
    label of unseen data, also known as overfitting (which we will cover in *Chapter
    5*, *Ensemble Modeling*).
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以用来管理类别不平衡，其中一种方法与缺失数据情境类似，就是随机从过多样本的类别中删除样本，直到达到平衡。再说一次，这个选项并不理想，甚至可能不合适，因为它涉及到忽略可用数据。一个更具建设性的例子是通过从数据集中随机复制样本，来对不足样本的类别进行过采样，从而增加样本数量。虽然删除数据可能会导致由于丢失有用信息而出现准确性问题，但对不足样本类别进行过采样可能会导致无法预测未见数据的标签，这也叫做过拟合（我们将在*第5章*，*集成建模*中讨论）。
- en: 'Adding some random noise to the input features for oversampled data may prevent
    some degree of overfitting, but this is highly dependent on the dataset itself.
    As with missing data, it is important to check the effect of any class imbalance
    corrections on the overall model performance. It is relatively straightforward
    to copy more data into a DataFrame using the `append` method, which works in a
    very similar fashion to lists. If we wanted to copy the first row to the end of
    the DataFrame, we would do this:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 向过采样数据的输入特征添加一些随机噪声可能有助于防止一定程度的过拟合，但这高度依赖于数据集本身。与缺失数据一样，检查任何类别不平衡修正对整体模型性能的影响非常重要。使用`append`方法将更多数据复制到DataFrame中相对简单，它的工作方式与列表非常相似。如果我们想把第一行复制到DataFrame的末尾，我们可以这样做：
- en: '[PRE50]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Low Sample Size
  id: totrans-378
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 样本量不足
- en: The field of machine learning can be considered a branch of the larger field
    of statistics. As such, the principles of confidence and sample size can also
    be applied to understand the issues with a small dataset. Recall that if we were
    to take measurements from a data source with high variance, then the degree of
    uncertainty in the measurements would also be high and more samples would be required
    to achieve a specified confidence in the value of the mean. The sample principles
    can be applied to machine learning datasets. Those datasets with a variance in
    the features with the most predictive power generally require more samples for
    reasonable performance as more confidence is also required.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习领域可以看作是更大统计学领域的一个分支。因此，置信度和样本量的原理同样可以应用于理解小数据集的问题。回想一下，如果我们从一个具有高方差的数据源中采样，那么测量值的不确定性程度也会很高，并且为了对均值值达到指定的置信度，需要更多的样本。这些样本原理也可以应用到机器学习数据集中。那些具有最具预测力的特征方差的数据集通常需要更多的样本来获得合理的性能，因为也需要更多的置信度。
- en: There are a few techniques that can be used to compensate for a reduced sample
    size, such as transfer learning. However, these lie outside the scope of this
    book. Ultimately, though, there is only so much that can be done with a small
    dataset, and significant performance increases may only occur once the sample
    size is increased.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种技术可以用来弥补样本量不足的问题，例如迁移学习。然而，这些技术超出了本书的范围。不过，最终来说，使用小数据集能做的事情有限，显著的性能提升可能只有在样本量增加后才会出现。
- en: 'Activity 1: pandas Functions'
  id: totrans-381
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动1：pandas函数
- en: In this activity, we will test ourselves on the various pandas functions we
    have learned about in this chapter. We will use the same Titanic dataset for this.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将测试自己在本章中学习到的各种pandas函数。我们将使用相同的Titanic数据集进行测试。
- en: 'The steps to be performed are as follows:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行的步骤如下：
- en: Open a new Jupyter notebook.
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter笔记本。
- en: Use pandas to load the Titanic dataset and describe the summary data for all
    columns.
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas加载泰坦尼克号数据集，并描述所有列的摘要数据。
- en: 'We don''t need the `Unnamed: 0` column. In *Exercise 7: Advanced Indexing and
    Selection*, we demonstrated how to remove the column using the `del` command.
    How else could we remove this column? Remove this column without using `del`.'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '我们不需要`Unnamed: 0`列。在*练习7：高级索引和选择*中，我们展示了如何使用`del`命令删除该列。我们还可以通过其他方式删除此列？不使用`del`命令删除此列。'
- en: Compute the mean, standard deviation, minimum, and maximum values for the columns
    of the DataFrame without using `describe`.
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算数据框列的均值、标准差、最小值和最大值，而不使用`describe`方法。
- en: What about the 33, 66, and 99% quartiles? How would we get these values using
    their individual methods? Use the `quantile` method to do this ([https://pandas.pydata.org/pandas-docs/stable/reference/frame.html](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)).
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 那么33%、66%和99%的四分位数呢？我们如何使用各自的方法得到这些值？使用`quantile`方法来完成此操作（[https://pandas.pydata.org/pandas-docs/stable/reference/frame.html](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)）。
- en: How many passengers were from each class? Find the answer using the `groupby`
    method.
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个类别的乘客有多少？使用`groupby`方法找到答案。
- en: How many passengers were from each class? Find the answer by using selecting/indexing
    methods to count the members of each class.
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个类别的乘客有多少？通过选择/索引方法统计每个类别的成员数量，找到答案。
- en: Confirm that the answers to *Step 6* and *Step 7* match.
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确认*步骤6*和*步骤7*的答案是否匹配。
- en: Determine who the eldest passenger in third class was.
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定第三类中最年长的乘客是谁。
- en: For a number of machine learning problems, it is very common to scale the numerical
    values between 0 and 1\. Use the `agg` method with Lambda functions to scale the
    `Fare` and `Age` columns between 0 and 1.
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于许多机器学习问题，常常需要将数值缩放到0和1之间。使用带有Lambda函数的`agg`方法将`Fare`和`Age`列缩放到0和1之间。
- en: 'There is one individual in the dataset without a listed `Fare` value, which
    can be found out as follows:'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集中有一名个体没有列出`Fare`值，可以通过以下方法找出。
- en: '[PRE51]'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output will be as follows:'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 1.64: Individual without a listed Fare value](img/C12622_01_64.jpg)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![图1.64：没有列出`Fare`值的个体](img/C12622_01_64.jpg)'
- en: 'Figure 1.64: Individual without a listed Fare value'
  id: totrans-398
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.64：没有列出`Fare`值的个体
- en: Replace the `NaN` value of this row in the main DataFrame with the mean `Fare`
    value for those corresponding with the same class and `Embarked` location using
    the `groupby` method.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`groupby`方法，将主数据框中这一行的`NaN`值替换为与相同类别和`Embarked`位置对应的`Fare`平均值。
- en: Note
  id: totrans-400
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can found on page 300.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以在第300页找到。
- en: Summary
  id: totrans-402
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we introduced the concept of supervised machine learning, along
    with a number of use cases, including the automation of manual tasks such as identifying
    hairstyles from the 1960s and 1980s. In this introduction, we encountered the
    concept of labeled datasets and the process of mapping one information set (the
    input data or features) to the corresponding labels.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了监督学习机器学习的概念，并列举了一些应用案例，包括自动化手动任务，如识别1960年代和1980年代的发型。在此介绍中，我们接触到了标签数据集的概念，以及将一个信息集（输入数据或特征）映射到相应标签的过程。
- en: We took a practical approach to the process of loading and cleaning data using
    Jupyter notebooks and the extremely powerful pandas library. Note that this chapter
    has only covered a small fraction of the functionality within pandas, and that
    an entire book could be dedicated to the library itself. It is recommended that
    you become familiar with reading the pandas documentation and continue to develop
    your pandas skills through practice.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了实际操作的方法，通过Jupyter笔记本和强大的pandas库加载和清洗数据。需要注意的是，本章仅涵盖了pandas功能的一小部分，实际上整个书籍都可以专门讨论该库。建议你熟悉pandas文档，并通过实践不断提升你的pandas技能。
- en: The final section of this chapter covered a number of data quality issues that
    need to be considered to develop a high-performing supervised learning model,
    including missing data, class imbalance, and low sample sizes. We discussed a
    number of options for managing such issues and emphasized the importance of checking
    these mitigations against the performance of the model.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的最后部分讨论了数据质量问题，这些问题在开发高效的监督学习模型时需要考虑，包括缺失数据、类别不平衡和样本量过小。我们讨论了多种处理这些问题的方法，并强调了根据模型表现检查这些缓解措施的重要性。
- en: In the next chapter, we will extend upon the data cleaning process that we covered
    and will investigate the data exploration and visualization process. Data exploration
    is a critical aspect of any machine learning solution, as without a comprehensive
    knowledge of the dataset, it would be almost impossible to model the information
    provided.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将扩展我们所涵盖的数据清理过程，并将探讨数据探索和可视化过程。数据探索是任何机器学习解决方案中的关键环节，因为没有对数据集的全面了解，几乎不可能对提供的信息进行建模。
