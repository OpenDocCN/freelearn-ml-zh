- en: '*Chapter 8*: Evaluating and Optimizing Models'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第8章*: 评估和优化模型'
- en: It is now time to learn how to evaluate and optimize machine learning models.
    During the process of modeling, or even after model completion, you might want
    to understand how your model is performing. Each type of model has its own set
    of metrics that can be used to evaluate performance, and that is what we are going
    to study in this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候学习如何评估和优化机器学习模型了。在建模过程中，甚至在模型完成后，你可能想要了解你的模型表现如何。每种类型的模型都有其自己的指标集，可以用来评估性能，这正是我们将在本章中研究的。
- en: Apart from model evaluation, as a data scientist, you might also need to improve
    your model's performance by tuning the hyperparameters of your algorithm. We will
    take a look at some nuances of this modeling task.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 除了模型评估之外，作为数据科学家，你可能还需要通过调整算法的超参数来提高你的模型性能。我们将探讨这个建模任务的某些细微差别。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introducing model evaluation
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍模型评估
- en: Evaluating classification models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估分类模型
- en: Evaluating regression models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估回归模型
- en: Model optimization
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型优化
- en: Alright, let's do it!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们开始吧！
- en: Introducing model evaluation
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍模型评估
- en: There are several different scenarios in which we might want to evaluate model
    performance, some of them are as follows.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种不同的场景，我们可能想要评估模型性能，以下是一些例子。
- en: You are creating a model and testing different approaches and/or algorithms.
    Therefore, you need to compare these models to select the best one.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你正在创建一个模型并测试不同的方法和/或算法。因此，你需要比较这些模型以选择最佳模型。
- en: You have just completed your model and you need to document your work, which
    includes specifying the model's performance metrics that you have reached out
    to during the modeling phase.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你刚刚完成了你的模型，你需要记录你的工作，这包括在建模阶段指定你达到的模型性能指标。
- en: Your model is running in a production environment and you need to track its
    performance. If you encounter model drift, then you might want to retrain the
    model.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的模型正在生产环境中运行，你需要跟踪其性能。如果你遇到模型漂移，那么你可能想要重新训练模型。
- en: Important note
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: The term **model drift** is used to refer to the problem of model deterioration.
    When you are building a machine learning model, you must use data to train the
    algorithm. This set of data is known as training data, and it reflects the business
    rules at a particular point in time. If these business rules change over time,
    your model will probably fail to adapt to that change. This is because it was
    trained on top of another dataset, which was reflecting another business scenario.
    To solve this problem, you must retrain the model so that it can consider the
    rules of the new business scenario. Reinforcement learning systems might not suffer
    from this issue since they can adapt to the new data by themselves.
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 术语**模型漂移**用来指代模型退化的问题。当你构建机器学习模型时，你必须使用数据来训练算法。这组数据被称为训练数据，它反映了特定时间点的业务规则。如果这些业务规则随时间变化，你的模型可能无法适应这种变化。这是因为它是基于另一个数据集训练的，该数据集反映了另一个业务场景。为了解决这个问题，你必须重新训练模型，以便它可以考虑新业务场景的规则。强化学习系统可能不会遇到这个问题，因为它们可以自行适应新数据。
- en: 'We perform model evaluations by designing a testing approach. We have learned
    about holdout validation and cross-validation before. However, both testing approaches
    share the same requirement: they need a metric in order to evaluate performance.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过设计测试方法来进行模型评估。我们之前已经了解过保留验证和交叉验证。然而，这两种测试方法都有相同的要求：它们需要一个指标来评估性能。
- en: This metric is specific to the problem domain, for example, there are specific
    metrics for regression models, classification models, clustering, natural language
    processing, and more. Therefore, during the design of your testing approach, you
    have to consider what type of model you are building in order to define the evaluation
    metrics.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指标是特定于问题域的，例如，对于回归模型、分类模型、聚类、自然语言处理等都有特定的指标。因此，在设计你的测试方法时，你必须考虑你正在构建哪种类型的模型，以便定义评估指标。
- en: In the following sections, we will take a look at the most important metrics
    and concepts that you should know to evaluate your models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，我们将探讨你评估模型时应该了解的最重要指标和概念。
- en: Evaluating classification models
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估分类模型
- en: Classification models are one of the most traditional classes of problems that
    you might face, either during the exam or during your journey as a data scientist.
    A very important artifact that you might want to generate during the classification
    model evaluation is known as a **confusion matrix**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型是你可能会遇到的最传统的模型类别之一，无论是在考试中还是在作为数据科学家的旅程中。在分类模型评估期间你可能想要生成的一个重要工具被称为**混淆矩阵**。
- en: 'A confusion matrix compares your model predictions against the real values
    of each class under evaluation. *Figure 8.1* shows what a confusion matrix looks
    like in a binary classification problem:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵比较你的模型预测与每个评估类别的真实值。*图8.1*展示了在二元分类问题中混淆矩阵的样子：
- en: '![Figure 8.1 – A confusion matrix'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.1 – 一个混淆矩阵'
- en: '](img/B16735_08_01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_08_01.jpg)'
- en: Figure 8.1 – A confusion matrix
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 一个混淆矩阵
- en: 'We find the following components in a confusion matrix:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在混淆矩阵中找到了以下组成部分：
- en: '**TP**: This is the number of **True Positive** cases. Here, we have to count
    the number of cases that have been predicted as true and are, indeed, true. For
    example, in a fraud detection system, this would be the number of fraudulent transactions
    that were correctly predicted as fraud.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TP**：这是**正确阳性**案例的数量。在这里，我们需要计算被预测为真且确实为真的案例数量。例如，在一个欺诈检测系统中，这将是被正确预测为欺诈的欺诈交易数量。'
- en: '**TN**: This is the number of **True Negative** cases. Here, we have to count
    the number of cases that have been predicted as false and are, indeed, false.
    For example, in a fraud detection system, this would be the number of non-fraudulent
    transactions that were correctly predicted as not fraud.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TN**：这是**正确阴性**案例的数量。在这里，我们需要计算被预测为假且确实为假的案例数量。例如，在一个欺诈检测系统中，这将是被正确预测为非欺诈的非欺诈交易数量。'
- en: '**FN**: This is the number of **False Negative** cases. Here, we have to count
    the number of cases that have been predicted as false but are, instead, true.
    For example, in a fraud detection system, this would be the number of fraudulent
    transactions that were wrongly predicted as not fraud.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FN**：这是**错误阴性**案例的数量。在这里，我们需要计算被预测为假但实际上是真的案例数量。例如，在一个欺诈检测系统中，这将是被错误预测为非欺诈的欺诈交易数量。'
- en: '**FP**: This is the number of **False Positive** cases. Here, we have to count
    the number of cases that have been predicted as true but are, instead, false.
    For example, in a fraud detection system, this would be the number of non-fraudulent
    transactions that were wrongly predicted as fraud.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FP**：这是**错误阳性**案例的数量。在这里，我们需要计算被预测为真但实际上是假的案例数量。例如，在一个欺诈检测系统中，这将是被错误预测为欺诈的非欺诈交易数量。'
- en: In a perfect scenario, your confusion matrix will have only true positive and
    true negative cases, which means that your model has an accuracy of 100%. In practical
    terms, if that type of scenario occurs, you should be skeptical instead of happy
    since it is expected that your model will contain errors. If your model does not
    contain errors, you are likely to be suffering from overfitting issues, so be
    careful.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个完美的场景中，你的混淆矩阵将只有正确阳性和正确阴性案例，这意味着你的模型准确率为100%。在实践中，如果发生这种情况，你应该持怀疑态度而不是高兴，因为预期你的模型将包含错误。如果你的模型不包含错误，你很可能是过度拟合问题，所以请小心。
- en: Once false negatives and false positives are expected, the most that you can
    do is to prioritize one of them. For example, you can reduce the number of false
    negatives by increasing the number of false positives and vice versa. This is
    known as the precision versus recall trade-off. Let's take a look at these metrics
    next.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦预期到错误阴性和错误阳性，你能做的最多就是优先考虑其中之一。例如，你可以通过增加错误阳性来减少错误阴性的数量，反之亦然。这被称为精确度与召回率的权衡。让我们接下来看看这些指标。
- en: Extracting metrics from a confusion matrix
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从混淆矩阵中提取指标
- en: 'The simplest metric that we can extract from a confusion matrix is known as
    **accuracy**. Accuracy is given by the number of true positives plus true negatives
    over the total number of cases. In *Figure 8.2*, we have filled out all the components
    of the confusion matrix for the sake of this demonstration:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从混淆矩阵中提取的最简单指标被称为**准确率**。准确率是通过将正确阳性和正确阴性的数量除以总案例数量来计算的。在*图8.2*中，我们为了演示的目的填写了混淆矩阵的所有组成部分：
- en: '![Figure 8.2 – A confusion matrix filled with some examples'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.2 – 一个填充了一些示例的混淆矩阵'
- en: '](img/B16735_08_02.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_08_02.jpg)'
- en: Figure 8.2 – A confusion matrix filled with some examples
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 填充了一些示例的混淆矩阵
- en: According to *Figure 8.2*, the accuracy would be (100 + 90) / 210, which is
    equal to 0.90\. There is a common issue that occurs when utilizing an accuracy
    metric, which is related to the balance of each class. Problems with highly imbalanced
    classes, such as 99% of positive cases and 1% of negative cases, will impact the
    accuracy score and make it useless.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图8.2，准确率将是(100 + 90) / 210，等于0.90。当使用准确率指标时，会出现一个常见问题，这与每个类别的平衡有关。高度不平衡的类别问题，例如99%的正例和1%的负例，将影响准确率分数并使其变得无用。
- en: For example, if your training data has 99% of positive cases (the majority class),
    your model is likely to correctly classify most of the positive cases but go badly
    in the classification of negative cases (the minority class). The accuracy will
    be very high (due to the correctness of the classification of the positive cases),
    regardless of the bad results in the minority class classification.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你的训练数据有99%的正例（多数类），你的模型很可能会正确分类大多数正例，但在负例（少数类）的分类上表现不佳。准确率将非常高（由于正例分类的正确性），无论少数类分类的结果如何。
- en: The point is that on highly imbalanced problems, we usually have more interest
    in correctly classifying the minority class, not the majority class. That's the
    case on most fraud detection systems, for example, where the minority class corresponds
    to fraudulent cases. For imbalanced problems, you should look for other types
    of metrics, which we will cover next.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于在高度不平衡的问题上，我们通常对正确分类少数类而不是多数类更感兴趣。例如，在大多数欺诈检测系统中就是这种情况，少数类对应于欺诈案例。对于不平衡问题，你应该寻找其他类型的指标，我们将在下一节中介绍。
- en: Another important metric that we can extract from a confusion matrix is known
    as **recall**, which is the number of true positives over the number of true positives
    plus false negatives. In other words, recall is given by the number of true positive
    and overall positive cases. Recall is also known as **sensitivity**.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从混淆矩阵中我们可以提取的一个重要指标被称为**召回率**，它是真实正例数与真实正例数加上假负例数的比值。换句话说，召回率由真实正例数和总体正例数给出。召回率也被称为**灵敏度**。
- en: According to *Figure 8.2*, recall is given by 100 / 112, which is equal to 0.89\.
    **Precision**, on the other hand, is given by the number of true positives over
    the number of true positives plus false positives. In other words, precision is
    given by the number of true positive and overall predicted positive cases. Precision
    is also known as **positive predictive power**.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图8.2，召回率由100 / 112给出，等于0.89。另一方面，**精确度**是由真实正例数与真实正例数加上假正例数的比值给出的。换句话说，精确度是由真实正例数和总体预测正例数给出的。精确度也被称为**阳性预测值**。
- en: According to *Figure 8.2*, precision is given by 100 / 108, which is equal to
    0.93\. In general, we can increase precision by the cost of decrease recall and
    vice versa. There is another model evaluation artifact in which we can play around
    with this precision versus recall trade-off. It is known as a **precision-recall
    curve**.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图8.2，精确度由100 / 108给出，等于0.93。一般来说，我们可以通过降低召回率来提高精确度，反之亦然。还有一个模型评估的伪指标，我们可以在这个精确度与召回率的权衡中玩转。它被称为**精确度-召回率曲线**。
- en: 'Precision-recall curves summarize the precision versus recall trade-off by
    using different probability thresholds. For example, the default threshold is
    0.5, where any prediction above 0.5 will be considered as true; otherwise, it
    is false. You can change the default threshold according to your need so that
    you can prioritize recall or precision. *Figure 8.3* shows an example of a precision-recall
    curve:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度-召回率曲线通过使用不同的概率阈值来总结精确度与召回率的权衡。例如，默认阈值是0.5，其中任何高于0.5的预测将被视为真；否则，它是假的。你可以根据你的需求更改默认阈值，以便你可以优先考虑召回率或精确度。*图8.3*显示了精确度-召回率曲线的一个示例：
- en: '![Figure 8.3 – A precision-recall curve'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.3 – 精确度-召回率曲线'
- en: '](img/B16735_08_03.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_08_03.jpg)'
- en: Figure 8.3 – A precision-recall curve
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 – 精确度-召回率曲线
- en: As you can see in *Figure 8.3*, increasing the precision will reduce the amount
    of recall and vice versa. *Figure 8.3* shows the precision/recall for each threshold
    for a gradient boosting model (as shown by the orange line) compared to a no-skill
    model (as shown by the blue dashed line). A perfect model will approximate the
    curve to the point (1,1), forming a squared corner in the top right-hand side
    of the chart.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*图8.3*中看到的，提高精确率会减少召回量，反之亦然。*图8.3*显示了梯度提升模型（由橙色线表示）的每个阈值与无技能模型（由蓝色虚线表示）的精确率/召回率进行比较。一个完美的模型将曲线近似到点（1,1），在图表的右上角形成一个平方角。
- en: Another visual analysis we can do on top of confusion matrixes is known as a
    **Receiver Operating Characteristic** (**ROC**) curve. ROC curves summarize the
    trade-off between the **true positive rate** and the **false positive rate** according
    to different thresholds, as in the precision-recall curve.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在混淆矩阵之上进行的另一种视觉分析被称为**受试者工作特征**（**ROC**）曲线。ROC曲线根据不同的阈值总结了**真正例率**和**假正例率**之间的权衡，就像在精确率-召回率曲线中一样。
- en: You already know about the true positive rate, or sensitivity, which is the
    same as what we have just learned in the precision-recall curve. The other dimension
    of an ROC curve is the **false positive rate**, which is the number of false positives
    over the number of false positives plus true negatives.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经了解了真正例率，或称为灵敏度，这与我们在精确率-召回率曲线中刚刚学习的内容相同。ROC曲线的另一个维度是**假正例率**，它是假正例数除以假正例数加上真正例数。
- en: 'In literature, you might find the false positive rate referred to as inverted
    **specificity**, represented by *1 – specificity*. Specificity is given as the
    number of true negatives over the number of true negatives plus false positives.
    Furthermore, false-positive rates or inverted specificity are the same. *Figure
    8.4* shows what an ROC curve looks like:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在文献中，你可能会发现假正例率被称为倒置的**特异性**，表示为*1 – 特异性*。特异性给出的是真正例数除以真正例数加上假正例数。此外，假正例率或倒置的特异性是相同的。*图8.4*显示了ROC曲线的形状：
- en: '![Figure 8.4 – An ROC curve'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.4 – ROC曲线'
- en: '](img/B16735_08_04.png)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_08_04.png)'
- en: Figure 8.4 – An ROC curve
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4 – ROC曲线
- en: A perfect model will approximate the curve to the point (0,1), forming a squared
    corner in the top left-hand side of the chart. The orange line represents the
    trade-off between the true positive rate and the false positive rate of a gradient
    boosting classifier. The dashed blue line represents a no-skill model, which cannot
    predict the classes properly.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一个完美的模型将曲线近似到点（0,1），在图表的左上角形成一个平方角。橙色线代表梯度提升分类器的真正例率和假正例率之间的权衡。虚线蓝色线代表一个无技能模型，它无法正确预测类别。
- en: To summarize, you can use ROC curves for fairly balanced datasets and precision-recall
    curves for moderate to imbalanced datasets.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，对于相当平衡的数据集，你可以使用ROC曲线，而对于适度到不平衡的数据集，则可以使用精确率-召回率曲线。
- en: Summarizing precision and recall
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结精确率和召回率
- en: 'Sometimes, we might want to use a metric that summarizes precision and recall,
    instead of prioritizing one over the other. Two very popular metrics can be used
    to summarize precision and recall: **F1 score** and **Area Under Curve** (**AUC**).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们可能想要使用一个总结精确率和召回率的度量，而不是优先考虑其中一个。两个非常流行的度量可以用来总结精确率和召回率：**F1分数**和**曲线下面积**（**AUC**）。
- en: The F1 score, also known as **F-measure**, computes the harmonic mean of precision
    and recall. AUC summarizes the approximation of the area under the precision-recall
    curve.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数，也称为**F度量**，计算精确率和召回率的调和平均值。AUC总结了精确率-召回率曲线下的近似面积。
- en: That brings us to the end of this section on classification metrics. Let's now
    take a look at the evaluation metrics for regression models.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这就带我们来到了分类度量标准部分的结尾。现在让我们来看看回归模型的评估度量标准。
- en: Evaluating regression models
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估回归模型
- en: Regression models are quite different from classification models since the outcome
    of the model is a continuous number. Therefore, the metrics around regression
    models aim to monitor the difference between real and predicted values.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型与分类模型相当不同，因为模型的输出是一个连续的数字。因此，围绕回归模型的度量旨在监控实际值和预测值之间的差异。
- en: The simplest way to check the difference between a predicted value (*yhat*)
    and its actual value (*y*) is by performing a simple subtraction operation, where
    the error will be equal to the absolute value of *yhat – y*. This metric is known
    as the **Mean Absolute Error** (**MAE**).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 检查预测值（*yhat*）与其实际值（*y*）之间差异的最简单方法是通过执行简单的减法操作，其中误差将等于*yhat – y*的绝对值。这个指标被称为**平均绝对误差**（**MAE**）。
- en: 'Since we usually have to evaluate the error of each prediction, *i*, we have
    to take the mean value of the errors. The following formula shows how this error
    can be formally defined:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们通常必须评估每个预测的误差，*i*，我们必须取误差的平均值。以下公式显示了如何正式定义这个误差：
- en: '![](img/Formula_09_001.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![公式图片](img/Formula_09_001.jpg)'
- en: Sometimes, you might want to penalize bigger errors over smaller errors. To
    achieve this, you can use another metric, which is known as the **Mean Squared
    Error** (**MSE**). MSE will square each error and return the mean value.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你可能想要对较大的误差进行惩罚，而不是较小的误差。为了实现这一点，你可以使用另一个指标，被称为**平均平方误差**（**MSE**）。MSE将每个误差平方并返回平均值。
- en: 'By squaring errors, MSE will penalize the bigger ones. The following formula
    shows how MSE can be formally defined:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通过平方误差，MSE将对较大的误差进行惩罚。以下公式显示了MSE是如何正式定义的：
- en: '![](img/B16735_08_05.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B16735_08_05.jpg)'
- en: 'There is a potential interpretation problem with MSE. Since it has to compute
    the squared error, it might be difficult to interpret the final results from a
    business perspective. The **Root Mean Squared Error** (**RMSE**) works around
    this interpretation issue, by taking the square root of MSE. Here is the RMSE
    equation:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: MSE存在一个潜在的解释问题。由于它必须计算平方误差，从业务角度来看，解释最终结果可能很困难。**均方根误差**（**RMSE**）通过取MSE的平方根来解决这个问题。以下是RMSE的方程式：
- en: '![](img/Formula_09_002.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![公式图片](img/Formula_09_002.jpg)'
- en: RMSE is probably the most used metric for regression models since it can either
    penalize bigger errors, yet still be easily interpreted.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: RMSE可能是回归模型中最常用的指标，因为它既可以惩罚较大的误差，同时仍然容易解释。
- en: Exploring other regression metrics
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索其他回归指标
- en: There are many more metrics that are suitable for regression problems aside
    from the ones that we have just learned. We will not be able to cover most of
    them here, but there are a few more metrics that might be important for you to
    know.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们刚刚学到的那些之外，还有很多适合回归问题的指标。我们在这里可能无法涵盖它们中的大多数，但还有一些额外的指标可能对你来说很重要。
- en: 'One of these metrics is known as the **Mean Absolute Percentage Error** (**MAPE**).
    As the name suggests, MAPE will compute the absolute percentage error of each
    prediction and then take the average value. The following formula shows how this
    metric is computed:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个指标被称为**平均绝对百分比误差**（**MAPE**）。正如其名称所暗示的，MAPE将计算每个预测的绝对百分比误差，然后取平均值。以下公式显示了该指标是如何计算的：
- en: '![](img/B16735_08_06.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B16735_08_06.jpg)'
- en: MAPE is broadly used on forecasting models since it is very simple to interpret,
    and it provides a very good sense of how far (or close) the predictions are from
    the actual values (in terms of a percentage).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: MAPE在预测模型中得到广泛应用，因为它很容易解释，并且提供了关于预测值（从百分比的角度）与实际值之间距离（或接近程度）的良好感觉。
- en: We have now completed this section on regression metrics. Next, we will talk
    about model optimizations.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经完成了关于回归指标的这一部分。接下来，我们将讨论模型优化。
- en: Model optimization
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型优化
- en: As you know, understanding evaluation metrics is very important in order to
    measure your model's performance and document your work. In the same way, when
    we want to optimize our current models, evaluating metrics also plays a very important
    role in defining the baseline performance that we want to challenge.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所知，为了衡量你的模型性能和记录你的工作，理解评估指标非常重要。同样，当我们想要优化我们当前的模型时，评估指标在定义我们想要挑战的基线性能中也起着非常重要的作用。
- en: The process of model optimization consists of finding the best configuration
    (also known as hyperparameters) of the machine learning algorithm for a particular
    data distribution. We don't want to find hyperparameters that overfit the training
    data in the same way that we don't want to find hyperparameters that underfit
    the training data.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 模型优化的过程包括为特定数据分布找到机器学习算法的最佳配置（也称为超参数）。我们不希望找到过度拟合训练数据的超参数，就像我们不希望找到欠拟合训练数据的超参数一样。
- en: You learned about overfitting and underfitting in [*Chapter 1*](B16735_01_Final_VK_ePub.xhtml#_idTextAnchor014),
    *Machine Learning Fundamentals*. In the same chapter, you also learned how to
    avoid these two types of modeling issues.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 你在[*第一章*](B16735_01_Final_VK_ePub.xhtml#_idTextAnchor014)《机器学习基础》中学习了过拟合和欠拟合。在同一章中，你也学习了如何避免这两种建模问题。
- en: In this section, we will learn about some techniques that you can use to find
    the best configuration for a particular algorithm and dataset. You can combine
    these techniques of model optimization with other methods, such as cross-validation,
    to find the best set of hyperparameters for your model and avoid fitting issues.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解一些你可以用来找到特定算法和数据集最佳配置的技术。你可以将这些模型优化技术与其他方法（如交叉验证）结合使用，以找到你模型的最佳超参数集，避免拟合问题。
- en: Important note
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Always remember that you don't want to optimize your algorithm to the underlying
    training data but to the data distribution behind the training data. This is so
    that your model will work in the training data as well as in the production data
    (that is, the data that has never been exposed to your model during the training
    process). A machine learning model that works only in the training data is useless.
    That's why combining model-tuning techniques (such as the ones we will learn about
    next) with sampling techniques (such as cross-validation) makes all the difference
    when it comes to creating a good model.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 总是记住，你不想优化你的算法以适应底层的训练数据，而是要适应训练数据背后的数据分布。这样，你的模型将在训练数据以及生产数据（即在训练过程中从未暴露给模型的那些数据）上工作。只在训练数据上工作的机器学习模型是无用的。这就是为什么将模型调整技术（如我们接下来将要学习的）与采样技术（如交叉验证）结合起来，在创建一个好的模型时至关重要。
- en: Grid search
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网格搜索
- en: '**Grid search** is probably the most popular method for model optimization.
    It consists of testing different combinations of the algorithm and selecting the
    best one. Here, we have two important points that we need to pay attention to:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**网格搜索**可能是模型优化中最受欢迎的方法。它包括测试算法的不同组合并选择最佳组合。在这里，有两个重要点我们需要注意：'
- en: How to define the best one?
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何定义最佳模型？
- en: How many combinations should we test?
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该测试多少种组合？
- en: The best model is defined based on an evaluation metric. In other words, you
    have to first define which metric you are going to use to evaluate the model's
    performance. Secondly, you have to define how you are going to evaluate the model.
    Usually, we use cross-validation to evaluate the model on multiple datasets that
    have never been used for training.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳模型是根据评估指标定义的。换句话说，你必须首先定义你将使用哪个指标来评估模型性能。其次，你必须定义你将如何评估模型。通常，我们使用交叉验证在多个从未用于训练的数据集上评估模型。
- en: 'In terms of the number of combinations, this is the most challenging part when
    playing with grid search. Each hyperparameter of an algorithm may have multiple
    or, sometimes, infinite possibilities of values. If you consider that an algorithm
    will usually have multiple hyperparameters, this becomes a function with quadratic
    cost, where the number of unique combinations to test (also known as a model for
    testing) is given as *the number of values of hyperparameter a * the number of
    values of hyperparameter b * the number of values of hyperparameter i*. *Figure
    8.5* shows how you could potentially set a grid search configuration for a decision
    tree model:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在组合数量方面，这是在玩网格搜索时最具挑战性的部分。一个算法的每个超参数可能有多个或有时是无限的可能值。如果你考虑到一个算法通常会有多个超参数，这将成为一个二次成本函数，其中要测试的唯一组合数（也称为测试模型）由*超参数a的值*乘以*超参数b的值*乘以*超参数i的值*给出。*图8.5*展示了你可以如何设置决策树模型的网格搜索配置：
- en: '![Figure 8.5 – Grid search configuration'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.5 – 网格搜索配置'
- en: '](img/B16735_08_Table_1.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16735_08_Table_1.jpg)'
- en: Figure 8.5 – Grid search configuration
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5 – 网格搜索配置
- en: 'In *Figure 8.5*, there are three hyperparameters: **Criterion**, **Max depth**,
    and **Min samples leaf**. Each of these hyperparameters has a list of values for
    testing: 2, 3, and 3 values, respectively. That means, by the end of the grid
    search process, we will have tested 18 models (2 * 3 * 3), where only the best
    one will be selected.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图8.5*中，有三个超参数：**标准**、**最大深度**和**最小叶子节点样本数**。每个超参数都有一个用于测试的值列表：分别为2、3和3个值。这意味着，在网格搜索过程结束时，我们将测试18个模型（2
    * 3 * 3），其中只有最佳模型将被选中。
- en: 'As you might have noticed, all the different combinations of those three hyperparameters
    will be tested, for example, consider the following:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已经注意到，这三个超参数的所有不同组合都将被测试，例如，考虑以下内容：
- en: Criterion = Gini, Max depth = 2, Min samples leaf = 10
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准差 = Gini，最大深度 = 2，最小叶子样本数 = 10
- en: Criterion = Gini, Max depth = 5, Min samples leaf = 10
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准差 = Gini，最大深度 = 5，最小叶子样本数 = 10
- en: Criterion = Gini, Max depth = 10, Min samples leaf = 10
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准差 = Gini，最大深度 = 10，最小叶子样本数 = 10
- en: 'Other questions that you might be wondering could include the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还想知道的其他问题可能包括以下内容：
- en: Considering that a particular algorithm might have several hyperparameters,
    which ones should I tune?
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑到某个特定的算法可能有几个超参数，我应该调整哪些？
- en: Considering that a particular hyperparameter might accept infinite values, which
    values should I test?
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑到某个特定的超参数可能接受无限值，我应该测试哪些值？
- en: These are good questions and grid search will not give you a straight answer
    for them. Instead, this is closer to an empirical process, where you have to test
    as much as you need to achieve your target performance.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是很好的问题，网格搜索不会直接给出答案。相反，这更接近于一个经验过程，您必须测试足够多的内容以达到您的目标性能。
- en: Important note
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Of course, grid search cannot guarantee that you will come up with your target
    performance. That depends on the algorithm and the training data.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，网格搜索不能保证您能达到目标性能。这取决于算法和训练数据。
- en: A common practice, though, is to define the values for testing by using a **linear
    space** or **log space**, where you can manually set the limits of the hyperparameter
    you want to test and the number of values for testing. Then, the intermediate
    values will be drawn by a linear or log function.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一个常见的做法是使用**线性空间**或**对数空间**来定义测试值，您可以在其中手动设置要测试的超参数的界限和测试值的数量。然后，中间值将通过线性或对数函数绘制。
- en: As you might imagine, grid search can take a long time to run. A number of alternative
    methods have been proposed to work around this time issue. **Random search** is
    one of them, where the list of values for testing is randomly selected from the
    search space.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所想象，网格搜索可能需要很长时间才能运行。已经提出了许多替代方法来解决这个问题。**随机搜索**就是其中之一，其中测试值的列表是从搜索空间中随机选择的。
- en: Another method that has gained rapid adoption across the industry is known as
    **Bayesian optimization**. Algorithm optimizations, such as **gradient descent**,
    try to find what is called the **global minima**, by calculating derivatives of
    the cost function. Global minima are the points where you find the algorithm configuration
    with the least associated cost.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个行业中迅速得到广泛采用的另一种方法是称为**贝叶斯优化**。算法优化，如**梯度下降**，试图通过计算成本函数的导数来找到所谓的**全局最小值**。全局最小值是您找到具有最低相关成本算法配置的点。
- en: Bayesian optimization is useful when calculating derivatives is not an option.
    So, we can use the **Bayes theorem**, a probabilistic approach, to find the global
    minima using the smallest number of steps.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算导数不是一种选择时，贝叶斯优化是有用的。因此，我们可以使用**贝叶斯定理**，一种概率方法，通过使用最少的步骤来找到全局最小值。
- en: In practical terms, Bayesian optimization will start testing the entire search
    space to find the most promising set of optimal hyperparameters. Then, it will
    perform more tests specifically in the place where the global minima are likely
    to be.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，贝叶斯优化将从整个搜索空间开始测试，以找到最有希望的优化超参数集。然后，它将在全局最小值可能存在的特定位置进行更多测试。
- en: Summary
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about the main metrics for model evaluation. We
    first started with the metrics for classification problems and then we moved on
    to the metrics for regression problems.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学习了模型评估的主要指标。我们首先从分类问题的指标开始，然后转向回归问题的指标。
- en: In terms of classification metrics, you have been introduced to the well-known
    confusion matrix, which is probably the most important artifact to perform a model
    evaluation on classification models.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类指标方面，您已经了解了著名的混淆矩阵，这可能是对分类模型进行模型评估最重要的工具。
- en: Aside from knowing what true positive, true negative, false positive, and false
    negative are, we have learned how to combine these components to extract other
    metrics, such as accuracy, precision, recall, the F1 score, and AUC.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 除了了解什么是真正例、真反例、假正例和假反例外，我们还学习了如何将这些组件组合起来以提取其他指标，例如准确率、精确率、召回率、F1分数和AUC。
- en: We went even deeper and learned about ROC curves, as well as precision-recall
    curves. We learned that we can use ROC curves to evaluate fairly balanced datasets
    and precision-recall curves for moderate to imbalanced datasets.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步深入学习了ROC曲线以及精确度-召回率曲线。我们了解到，我们可以使用ROC曲线来评估相对平衡的数据集，而使用精确度-召回率曲线来评估适度到不平衡的数据集。
- en: By the way, when you are dealing with imbalanced datasets, remember that using
    accuracy might not be a good idea.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，当你处理不平衡数据集时，请记住使用准确率可能不是一个好主意。
- en: In terms of regression metrics, we learned that the most popular ones, and the
    most likely to be present in the *AWS Machine Learning Specialty* exam, are MAE,
    MSE, RMSE, and MAPE. Make sure you know the basics of each of them before taking
    the exam.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归指标方面，我们了解到最流行且最可能在*AWS机器学习专业考试*中出现的指标是MAE、MSE、RMSE和MAPE。在参加考试之前，确保你了解它们的基本知识。
- en: Finally, you learned about methods for hyperparameter optimization, where grid
    search and Bayesian optimization are the primary ones. In the next chapter, we
    will take a look at SageMaker and learn how it can be used for modeling. But first,
    let's take a moment to practice these questions on model evaluation and model
    optimization.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你学习了超参数优化的方法，其中网格搜索和贝叶斯优化是主要方法。在下一章中，我们将探讨SageMaker，并学习如何将其用于建模。但首先，让我们花点时间练习这些关于模型评估和模型优化的问题。
- en: Questions
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: You are working as a data scientist for a pharmaceutical company. You are collaborating
    with other teammates to create a machine learning model to classify certain types
    of diseases on image exams. The company wants to prioritize the assertiveness
    rate of positive cases, even if they have to wrongly return false negatives. Which
    type of metric would you use to optimize the underlying model?
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你正在一家制药公司担任数据科学家，与其他团队成员合作创建一个机器学习模型，用于在图像检查中分类某些类型的疾病。公司希望优先考虑正例的确定性率，即使他们必须错误地返回假阴性。你会使用哪种类型的指标来优化底层模型？
- en: a. Recall
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 召回率
- en: b. Precision
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 精确度
- en: c. R-squared
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. R-squared
- en: d. RMSE
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. RMSE
- en: Answer
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案
- en: In this scenario, the company prefers to have a higher probability to be right
    on positive outcomes at the cost of wrongly classifying some positive cases as
    negative. Technically, they prefer to increase precision at the cost of reducing
    recall.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个场景中，公司更倾向于以将一些正例错误分类为负例为代价，提高正确预测正例的概率。技术上，他们更倾向于提高精确度，而牺牲召回率。
- en: You are working as a data scientist for a pharmaceutical company. You are collaborating
    with other teammates to create a machine learning model to classify certain types
    of diseases on image exams. The company wants to prioritize the capture of positive
    cases, even if they have to wrongly return false positives. Which type of metric
    would you use to optimize the underlying model?
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你正在一家制药公司担任数据科学家，与其他团队成员合作创建一个机器学习模型，用于在图像检查中分类某些类型的疾病。公司希望优先考虑捕获正例，即使他们必须错误地返回假阳性。你会使用哪种类型的指标来优化底层模型？
- en: a. Recall
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 召回率
- en: b. Precision
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 精确度
- en: c. R-squared
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. R-squared
- en: d. RMSE
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. RMSE
- en: Answer
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案
- en: In this scenario, the company prefers to find most of the positive cases at
    the cost of wrongly classifying some negative cases as positive. Technically,
    they prefer to increase recall at the cost of reducing precision.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个场景中，公司更倾向于找到大多数正例，而以将一些负例错误分类为正例为代价。技术上，他们更倾向于提高召回率，而牺牲精确度。
- en: You are working in a fraud identification system, where one of the components
    is a classification model. You want to check the model's performance. Which of
    the following metrics could be used and why?
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你正在一个欺诈识别系统中工作，其中一个组件是分类模型。你想检查模型的表现。以下哪些指标可以使用，为什么？
- en: a. Accuracy. Since fraudulent system datasets are naturally unbalanced, this
    metric is good to take into consideration the assertiveness of both positive and
    negative classes.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 准确度。由于欺诈系统数据集自然是不平衡的，这个指标有助于考虑正负类的确定性。
- en: b. Precision. Since fraudulent system datasets are naturally unbalanced, this
    metric is good to take into consideration the assertiveness of both positive and
    negative classes.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 精确度。由于欺诈系统数据集自然是不平衡的，这个指标有助于考虑正负类的确定性。
- en: c. Recall. Since fraudulent system datasets are naturally unbalanced, this metric
    is good to take into consideration the assertiveness of both positive and negative
    classes.
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. 召回率。由于欺诈系统数据集自然不平衡，这个指标有助于考虑正负类的积极性。
- en: d. The F1 score. Since fraudulent system datasets are naturally unbalanced,
    this metric is good to take into consideration the assertiveness of both positive
    and negative classes.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. F1分数。由于欺诈系统数据集自然不平衡，这个指标有助于考虑正负类的积极性。
- en: Answer
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案
- en: Option "d" is the only one that matches the explanation of the proposed metric
    and provides a valid measure to the problem. Accuracy cannot be used in this problem
    due to the unbalanced issue. Precision and recall could be potentially used together
    to provide a quality view of the problem, but there is no such option in the list
    of answers.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 选项“d”是唯一一个与所提出指标的解释相匹配并提供对问题有效度量的选项。由于不平衡问题，准确性不能用于这个问题。精确度和召回率可以潜在地一起使用，以提供对问题的质量视图，但在答案列表中没有这样的选项。
- en: You are building a machine learning model to predict house prices. You have
    approached the problem as a regression model. Which of the following metrics are
    not applicable for regression models? (Select all correct answers.)
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你正在构建一个机器学习模型来预测房价。你将这个问题作为一个回归模型来处理。以下哪个指标不适用于回归模型？（选择所有正确答案。）
- en: a. Recall
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 召回率
- en: b. Precision
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 精确度
- en: c. MAPE
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. MAPE
- en: d. RMSE
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. RMSE
- en: Answer
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案
- en: Recall and precision are applicable for classification problems; that's why
    they are the correct answers. On the other hand, MAPE and RMSE are applicable
    for regression models.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 召回率和精确度适用于分类问题；这就是它们是正确答案的原因。另一方面，MAPE和RMSE适用于回归模型。
- en: Which of the following metrics help us to penalize bigger errors on regression
    models?
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个指标有助于我们在回归模型上惩罚较大误差？
- en: a. Recall
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 召回率
- en: b. Precision
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 精确度
- en: c. MAPE
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. MAPE
- en: d. RMSE
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. RMSE
- en: Answer
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案
- en: RMSE computes the squared error of each prediction. Then, it takes the squared
    root of the MSE. By computing the squared error, RMSE will penalize bigger errors
    over smaller errors.
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RMSE计算每个预测的平方误差。然后，它取MSE的平方根。通过计算平方误差，RMSE会对较大误差进行惩罚，而较小误差则不会。
- en: You are working as a data scientist for a financial services company and you
    have created a regression model to predict credit utilization. If you decide to
    include more features in the model, what will happen to R-squared and Adjusted
    R-squared?
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你正在为一家金融服务公司担任数据科学家，并创建了一个回归模型来预测信用利用率。如果你决定在模型中包含更多特征，R-squared和调整后的R-squared会发生什么变化？
- en: a. Adjusted R-squared will increase, whereas R-squared can either increase or
    decrease.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 调整后的R-squared会增加，而R-squared可能增加或减少。
- en: b. R-squared will decrease, whereas Adjusted R-squared can either increase or
    decrease.
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. R-squared会减少，而调整后的R-squared可能增加或减少。
- en: c. R-squared will increase, whereas Adjusted R-squared can either increase or
    decrease.
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. R-squared会增加，而调整后的R-squared可能增加或减少。
- en: d. Adjusted R-squared will decrease, whereas R-squared can either increase or
    decrease.
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. 调整后的R-squared会减少，而R-squared可能增加或减少。
- en: Answer
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案
- en: R-squared will increase since the extra information will help the model to capture
    more variance in the data. However, Adjusted R-squared can either increase or
    decrease, depending on the gain of adding the extra variable.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于额外信息将帮助模型捕捉到数据中的更多变异性，因此R-squared会增加。然而，调整后的R-squared可能增加或减少，这取决于添加额外变量的收益。
- en: Which of the following metrics will compute the percentage of errors instead
    of absolute errors?
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个指标将计算错误百分比而不是绝对误差？
- en: a. Recall
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 召回率
- en: b. Precision
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 精确度
- en: c. MAPE
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. MAPE
- en: d. RMSE
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. RMSE
- en: Answer
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案
- en: MAPE is applicable for regression models and it will compute the error as a
    percentage number.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MAPE适用于回归模型，并且将以百分比数字计算误差。
- en: You are the lead data scientist of the company. Your team wants to optimize
    a model that is no longer performing well in production. The team has decided
    to use grid search to retrain the hyperparameters; however, the process is taking
    a long time and does not complete. Which approach could you take to speed up the
    process of tuning and still maximize your chances of finding a better model?
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你是公司的首席数据科学家。你的团队想要优化一个在生产中不再表现良好的模型。团队已经决定使用网格搜索来重新训练超参数；然而，这个过程花费了很长时间并且没有完成。你可以采取什么方法来加快调整过程，同时最大限度地提高找到更好模型的机会？
- en: a) Reduce the search space to speed up the training process.
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 减少搜索空间以加快训练过程。
- en: b) Use Bayesian optimization instead of grid search.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 使用贝叶斯优化而不是网格搜索。
- en: c) Increase the search space to speed up the training process.
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 增加搜索空间以加快训练过程。
- en: d) None of the above.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 以上皆非。
- en: Answer
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案
- en: Reducing the search space of grid search will help to speed up the process of
    tuning, but you will test fewer models. This will reduce your chances of finding
    the best model for the problem. Increasing the search space will increase the
    time for tuning. Option "b" is the most resealable one since Bayesian optimization
    can focus on the most important search space, potentially reducing the time for
    processing and increasing your chances of finding the best model.
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 减少网格搜索的搜索空间将有助于加快调整过程，但你将测试 fewer models。这将减少你找到最佳模型的机会。增加搜索空间将增加调整所需的时间。选项
    "b" 是最可重用的，因为贝叶斯优化可以专注于最重要的搜索空间，从而可能减少处理时间并增加你找到最佳模型的机会。
- en: You are using grid search to tune a machine learning model. During the tuning
    process, you obtain good performance metrics. However, when you execute the model
    in production, the model performance is not acceptable. You have to troubleshoot
    the problem. Which of the following options are valid reasons for this issue?
    (Select all correct answers.)
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你正在使用网格搜索调整机器学习模型。在调整过程中，你获得了良好的性能指标。然而，当你将模型在生产环境中执行时，模型性能不可接受。你必须解决问题。以下哪些选项是此问题的有效原因？（选择所有正确答案。）
- en: a) You are tuning and evaluating the model in the training data, which is causing
    overfitting.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 你正在训练数据中调整和评估模型，这导致了过度拟合。
- en: b) The production data does not have the same distribution as the training data.
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 生产数据与训练数据不具有相同的分布。
- en: c) You are not using cross-validation in the training process.
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 你在训练过程中没有使用交叉验证。
- en: d) You are not tuning the right hyperparameters.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) 你没有调整正确的超参数。
- en: Answer
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案
- en: You can't tune and test the model in the same dataset at the risk of overfitting
    it. That's why option "a" is correct. If the production data does not follow the
    same distribution of the training data, the model will not work, so option "b"
    is also correct. Option "c" is not valid because cross-validation is not mandatory
    for model evaluation. Option "d" would be correct if you find bad results in the
    training data, not in the production data.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你不能在同一个数据集上调整和测试模型，以免过度拟合。这就是为什么选项 "a" 是正确的。如果生产数据不遵循训练数据的相同分布，则模型将无法工作，因此选项
    "b" 也是正确的。选项 "c" 是无效的，因为交叉验证不是模型评估的强制性要求。如果发现在训练数据中发现不良结果，而不是在生产数据中，则选项 "d" 将是正确的。
- en: You are working for a global financial company. Your team has created a binary
    classification model to identify fraudulent transactions. The model has been put
    into production and is automatically flagging fraudulent transactions and sending
    them for further screening. The operation team is complaining that this model
    is blocking too many transactions and they would prefer to flag a smaller number
    of transactions. According to the preceding scenario, what is the expectation
    of the operation team?
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你在一家全球金融公司工作。你的团队创建了一个二元分类模型来识别欺诈交易。该模型已投入生产，并自动标记欺诈交易并将它们发送进行进一步筛选。操作团队抱怨这个模型阻止了太多的交易，他们更希望标记更少的交易。根据前面的场景，操作团队有什么期望？
- en: a) They want to calibrate the model threshold at 0.5.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 他们希望将模型阈值校准在 0.5。
- en: b) They want to prioritize precision over recall.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 他们希望优先考虑精确度而不是召回率。
- en: b) They want to prioritize recall over precision.
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 他们希望优先考虑召回率而不是精确度。
- en: b) They want to use F-measure.
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 他们希望使用 F-measure。
- en: Answer
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案
- en: We always have to match model usage with business goals and capacity. In this
    scenario, the model is flagging a lot of potentially fraudulent transactions,
    but there isn't a big enough human workforce to evaluate all of those blocked
    transactions. Furthermore, what makes more sense is "calibrating" the model to
    the real business scenario, where it will flag fewer (but more likely) fraudulent
    cases for further screening.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们总是需要将模型的使用与业务目标和能力相匹配。在这种情况下，模型正在标记大量潜在的欺诈交易，但并没有足够的人力资源来评估所有这些被阻止的交易。此外，更有意义的是将模型“校准”到实际业务场景中，在那里它将标记更少（但更有可能）的欺诈案例以进行进一步筛选。
