- en: Chapter 6. Learning Object Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 学习对象分类
- en: In the previous chapter, we introduced you to the basic concepts of object segmentation
    and detection. This means isolating the objects that appear in an image for future
    processing and analysis.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们向您介绍了对象分割和检测的基本概念。这意味着将图像中出现的对象隔离出来，以便进行未来的处理和分析。
- en: This chapter covers how to classify each of these isolated objects. In order
    to allow us to classify each object, we need to train our system to be capable
    of learning the required parameters to decide which specific label should be assigned
    to the detected object (depending on the different categories taken into account
    during the training phase).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍如何对每个这些孤立的对象进行分类。为了使我们能够对每个对象进行分类，我们需要训练我们的系统，使其能够学习所需的参数，以决定应该将哪个特定的标签分配给检测到的对象（取决于训练阶段考虑的不同类别）。
- en: This chapter is going to introduce you to the basic concepts of machine learning
    to classify images with different labels.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将向您介绍机器学习的基本概念，以对具有不同标签的图像进行分类。
- en: We will create a basic application based on the segmentation algorithm, as discussed
    in [Chapter 5](ch05.html "Chapter 5. Automated Optical Inspection, Object Segmentation,
    and Detection"), *Automated Optical Inspection, Object Segmentation, and Detection*.
    This segmentation algorithm extracts parts of an image, which contains objects.
    For each object, we will extract the different features and analyze them using
    a machine learning algorithm. Using a machine learning algorithm, we are able
    to show, using our user interface, the labels of each object detected in the input
    image to the end user.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将基于第5章中讨论的分割算法创建一个基本应用，[第5章](ch05.html "第5章. 自动光学检测、对象分割和检测")，《自动光学检测、对象分割和检测》。这个分割算法提取图像中的部分，其中包含对象。对于每个对象，我们将提取不同的特征并使用机器学习算法进行分析。通过使用机器学习算法，我们能够在用户界面中向最终用户展示输入图像中检测到的每个对象的标签。
- en: 'In this chapter, we will cover the different topics and algorithms, which are
    as follows:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍不同的主题和算法，具体如下：
- en: An introduction to machine learning concepts
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习概念的介绍
- en: Common machine learning algorithms and processes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的机器学习算法和过程
- en: Feature extraction
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征提取
- en: Support vector machines
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Training and prediction
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和预测
- en: Introducing machine learning concepts
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍机器学习概念
- en: Machine learning is an old concept that was defined in 1959 by Arthur Samuel
    as a *field of study that gives computers the ability to learn without being explicitly
    programmed*. Tom. M. Mitchel provided a more formal definition. In this definition,
    Tom links the concept of samples or experiences, labels, and performance measurements.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个古老的概念，由亚瑟·塞缪尔在1959年定义为“一个研究领域，它赋予计算机在没有明确编程的情况下学习的能力”。汤姆·M·米切尔提供了一个更正式的定义。在这个定义中，汤姆将样本或经验、标签和性能测量的概念联系起来。
- en: Note
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The machine learning definition by Arthur Samuel is referenced from *Some Studies
    in Machine Learning Using the Game of Checkers* in the *IBM Journal of Research
    and Development* (Volume: 3, Issue: 3), p. 210 and a phrase in *The New Yorker*
    and *Office Management* the same year.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 亚瑟·塞缪尔对机器学习的定义引用自《IBM研究与发展杂志》中的《使用国际象棋游戏进行机器学习研究》一文（卷：3，期：3），第210页，以及同年《纽约客》和《办公室管理》中的一句话。
- en: The more formal definition by Tom. M. Mitchel is referenced from *Machine Learning
    Book*, McGray Hill 1997 ([http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html](http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 汤姆·M·米切尔给出的更正式的定义引用自《机器学习书》，McGraw Hill 1997 ([http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html](http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html))。
- en: Machine learning involves pattern recognition and the learning theory in artificial
    intelligence and is related to computational statistics.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习涉及人工智能中的模式识别和学习理论，与计算统计学相关。
- en: Machine learning is used in hundreds of applications such as **OCR** (**Optical
    Character Recognition**), spam filtering, search engines, and thousands of Computer
    Vision applications that we will develop in the current chapter, where a machine
    learning algorithm tries to classify the objects that appear in the input image.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习被应用于数百个应用中，例如**OCR**（**光学字符识别**）、垃圾邮件过滤、搜索引擎，以及我们在本章中将要开发的数千个计算机视觉应用，其中机器学习算法试图对输入图像中出现的对象进行分类。
- en: 'Depending on how machine ML algorithms learn from the data or samples, we can
    divide them into three categories, which are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 根据机器学习算法如何从数据或样本中学习，我们可以将它们分为以下三类：
- en: '**Supervised learning**: The computer learns from a set of labeled data. The
    goal is to learn the parameters of the model and rules that allow computers to
    map the relation between data and output label results.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**：计算机从一组标记数据中学习。目标是学习模型的参数和规则，这些规则允许计算机映射数据与输出标签结果之间的关系。'
- en: '**Unsupervised learning**: No labels are given, and the computer tries to discover
    the input structure of the input data.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**：没有给出标签，计算机试图发现输入数据的结构。'
- en: '**Reinforcement learning**: The computer interacts with a dynamic environment
    that performs its goal and learns from its mistakes.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习**：计算机与动态环境交互，执行其目标并从其错误中学习。'
- en: 'Depending on the desired results that we obtain from our machine learning algorithm,
    we can categorize them into the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们从机器学习算法中获得的结果，我们可以将它们分类如下：
- en: '**Classification**: In classification, the space of the inputs can be divided
    into *N* classes, and the prediction results of a given sample are one of these
    training classes. This is one of the most used categories. A typical example is
    an e-mail spam filtering where there are only two classes: spam and non spam or
    OCR, where only *N* characters are available, and each character is one class.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：在分类中，输入空间可以划分为*N*个类别，给定样本的预测结果是这些训练类别之一。这是最常用的类别之一。一个典型的例子是电子邮件垃圾邮件过滤，其中只有两个类别：垃圾邮件和非垃圾邮件或OCR，其中只有*N*个字符可用，每个字符是一个类别。'
- en: '**Regression**: The output is a continuous value instead of a discrete value
    such as a classification result. One example of regression can be the prediction
    of the house price by providing the house size, number of years, and location.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**：输出是一个连续值，而不是像分类结果这样的离散值。回归的一个例子可以是根据房屋大小、年份和位置预测房价。'
- en: '**Clustering**: The inputs are divided into *N* groups using unsupervised training.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**：使用无监督训练将输入划分为*N*组。'
- en: '**Density estimation**: This finds the (probability) distribution of inputs.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**密度估计**：这找到输入的（概率）分布。'
- en: In our example, we will use a supervised learning classification algorithm,
    where a training dataset (with labels) is used to train the model, and the result
    of our model is a prediction of one label.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们将使用一个监督学习分类算法，其中使用带有标签的训练数据集来训练模型，我们模型的结果是对一个标签的预测。
- en: Machine learning is a modern approach to artificial intelligence and statistics
    and involves both the techniques.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是人工智能和统计学的一种现代方法，它涉及这两种技术。
- en: In machine learning, there are several approaches and methods, and some of them
    used are **SVM** (**support vector machines**), **ANNs** (**artificial neural
    networks**), clustering such as **K-Nearest Neighbors**, **decision trees,** or
    deep learning, which is a big **neural network** approach used in some cases that
    are convolutional, and so on.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，有几种方法和途径，其中一些使用的是**SVM**（**支持向量机**）、**ANNs**（**人工神经网络**）、聚类如**K-Nearest
    Neighbors**、**决策树**或深度学习，这是一种在某些情况下使用的大的**神经网络**方法，例如卷积等。
- en: All these methods and approaches are supported, implemented, and well-documented
    in OpenCV. We are going to explain one of them, SVM, in the next section.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方法和途径都在OpenCV中得到支持、实现和良好记录。我们将在下一节中解释其中之一，即SVM。
- en: 'OpenCV implements eight of these machine learning algorithms. They all inherit
    from the `StatModel` class:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV实现了这些机器学习算法中的八个。它们都继承自`StatModel`类：
- en: Artificial neural networks
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工神经网络
- en: Boost
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boost
- en: Random trees
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机树
- en: Expectation maximization
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 期望最大化
- en: K-Nearest Neighbours
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K-Nearest Neighbours
- en: Logistic regression
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: The Normal Bayes Classifier
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正态贝叶斯分类器
- en: Support vector machines
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Note
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: To get more details of each algorithm, read the OpenCV document page of machine
    learning at [http://docs.opencv.org/trunk/dc/dd6/ml_intro.html](http://docs.opencv.org/trunk/dc/dd6/ml_intro.html).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解每个算法的更多细节，请阅读OpenCV机器学习文档页面[http://docs.opencv.org/trunk/dc/dd6/ml_intro.html](http://docs.opencv.org/trunk/dc/dd6/ml_intro.html)。
- en: 'In the following image, you can see the machine learning class hierarchy:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图像中，你可以看到机器学习类层次结构：
- en: '![Introducing machine learning concepts](img/B04283_06_01.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![介绍机器学习概念](img/B04283_06_01.jpg)'
- en: The `StatModel` class provides all the `read` and `write` functions that are
    very important to save our machine learning parameters and training data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`StatModel`类提供了所有重要的`read`和`write`函数，这些函数对于保存我们的机器学习参数和训练数据非常重要。'
- en: In machine learning, the most time-consuming part is the `training` method.
    Training can take from seconds to weeks or months for large datasets and complex
    machine learning structures; for example, in deep learning and a big neural network
    structure with more than 100,000 images. In deep learning algorithms, it is common
    to use parallel hardware processing; for example, GPUs or graphic cards with the
    CUDA technology used to decrease the computing time during training.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，最耗时的部分是`训练`方法。对于大型数据集和复杂的机器学习结构，训练可能需要从几秒到几周或几个月；例如，在深度学习和包含超过10万张图片的大神经网络结构中。在深度学习算法中，通常使用并行硬件处理；例如，使用CUDA技术的GPU或显卡来减少训练过程中的计算时间。
- en: This means that we cannot train our algorithm each time we run our application,
    and it's recommended that we save our model after it is trained because all training/prediction
    parameters of machine learning are saved. Next, when we want to run it in the
    future, we only need to load/read from our saved model without training anymore
    if we need to update our model with more data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们每次运行应用程序时都不能重新训练我们的算法，并且建议我们在模型训练后保存我们的模型，因为所有机器学习的训练/预测参数都被保存。接下来，当我们想要在未来运行它时，如果我们需要用更多数据更新我们的模型，我们只需要从我们的保存模型中加载/读取，而无需再次进行训练。
- en: The `StatModel` is an interface that is implemented by each of its implementations.
    The two key functions are `train` and `predict`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`StatModel`是一个接口，由其实现的每个实现实现。两个关键函数是`train`和`predict`。'
- en: 'The `train` method is responsible for learning the parameters of the model
    from a training dataset. The `train` function has the following four calls that
    can be called in four different ways:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`train`方法负责从训练数据集中学习模型的参数。`train`函数有以下四个调用方式，可以以四种不同的方式调用：'
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'It has the following parameters:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 它有以下参数：
- en: '`trainData`: This is the training data that can be loaded or created from the
    `TrainData` class. This class is new in OpenCV 3 and helps developers to create
    training data because different algorithms require different types of structure
    of arrays for training and prediction, such as the ANN algorithm.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainData`：这是可以从`TrainData`类加载或创建的训练数据。这个类是OpenCV 3中的新功能，帮助开发者创建训练数据，因为不同的算法需要不同的数组结构来训练和预测，例如ANN算法。'
- en: '`samples`: This is the array of training array samples such as training data
    in the format required by the machine learning algorithm.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`samples`：这是训练数组样本的数组，例如机器学习算法所需的格式要求的训练数据。'
- en: '`layout`: There are two types of layouts: `ROW_SAMPLE` (training samples are
    the matrix rows) and `COL_SAMPLE` (training samples are the matrix columns).'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layout`：有两种类型的布局：`ROW_SAMPLE`（训练样本是矩阵行）和`COL_SAMPLE`（训练样本是矩阵列）。'
- en: '`responses`: This is the vector of responses that is associated with the sample
    data.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`responses`：这是与样本数据相关联的响应向量。'
- en: '`p`: This is the `StatModel` parameter.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`p`：这是`StatModel`参数。'
- en: '`flags`: These are optional flags defined by each method.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flags`：这些是由每个方法定义的可选标志。'
- en: 'The `predict` method is simpler and has only one call:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict`方法更简单，只有一个调用：'
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'It has the following parameters:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 它有以下参数：
- en: '`samples`: These are the input samples to be predicted. There can be only one
    or multiple data to be predicted.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`samples`：这些是要预测的输入样本。可以只有一个或多个要预测的数据。'
- en: '`results`: This is the result of each input row samples (computed by the algorithm
    from the previously trained model).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`results`：这是每个输入行样本的结果（由算法从前一个训练模型计算得出）。'
- en: '`flags`: These are optional flags that are model-dependent. Some models, such
    as Boost and SVM recognize the `StatModel::RAW_OUTPUT` flag, which makes the method
    return the raw results (the sum) and not the class label.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flags`：这些是模型相关的可选标志。一些模型，如Boost和SVM，识别`StatModel::RAW_OUTPUT`标志，这使得方法返回原始结果（总和）而不是类标签。'
- en: 'The `StatModel` class provides other very useful methods, which are as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`StatModel`类提供了其他非常实用的方法，具体如下：'
- en: '`isTrained()`: This returns `true` if the model is trained'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`isTrained()`：如果模型已训练，则返回`true`。'
- en: '`isClassifier()`: This returns `true` if the model is a classifier or `false`
    in the case of regression'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`isClassifier()`：如果模型是分类器，则返回`true`；如果是回归，则返回`false`。'
- en: '`getVarCount()`: This returns the number of variables in training samples'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getVarCount()`：返回训练样本中的变量数。'
- en: '`save(const string& filename)`: This saves the model in the filename'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save(const string& filename)`: 这将模型保存到文件名指定的位置'
- en: '`Ptr<_Tp> load(const string& filename)`: This loads the model from the filename,
    for example: `Ptr<SVM> svm = StatModel::load<SVM>("my_svm_model.xml");`'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Ptr<_Tp> load(const string& filename)`: 这将从文件名中加载模型，例如：`Ptr<SVM> svm = StatModel::load<SVM>("my_svm_model.xml");`'
- en: '`calcError(const Ptr<TrainData>& data, bool test, OutputArray resp)`: This
    calculates the error from a test data, where the data is the training data. If
    the test is `true`, the method calculates the error from the test subset of all
    the training data, otherwise it''s computed over the training subset of the data.
    Finally `resp` is the optional output results.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`calcError(const Ptr<TrainData>& data, bool test, OutputArray resp)`: 这从测试数据中计算误差，其中数据是训练数据。如果测试为`true`，该方法计算所有训练数据测试子集的误差，否则它计算数据训练子集的误差。最后`resp`是可选的输出结果。'
- en: Now, we will learn how to construct a basic application that uses machine learning
    in Computer Vision apps.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将学习如何构建一个基本的应用程序，该程序在计算机视觉应用中使用机器学习。
- en: Computer Vision and the machine learning workflow
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉和机器学习工作流程
- en: 'The Computer Vision applications with machine learning have a common basic
    structure. This structure is divided into different steps that are repeated in
    almost all Computer Vision applications, and some others are omitted. In the following
    diagram, we show you the different steps involved:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 带有机器学习的计算机视觉应用具有一个共同的基本结构。这个结构被划分为不同的步骤，这些步骤几乎在所有计算机视觉应用中都会重复，而有些步骤则被省略。在下面的图中，我们展示了涉及的不同步骤：
- en: '![Computer Vision and the machine learning workflow](img/B04283_06_02.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![计算机视觉和机器学习工作流程](img/B04283_06_02.jpg)'
- en: Almost any Computer Vision application starts with a preprocessing stage that
    is applied to the input image. Preprocessing involves light removal conditions
    and noise, thresholding, blur, and so on.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎任何计算机视觉应用都以一个预处理阶段开始，该阶段应用于输入图像。预处理包括光照条件去除、噪声、阈值、模糊等。
- en: After we apply all the preprocessing steps required to the input image, the
    second step is segmentation. In the segmentation step, we need to extract the
    regions of interest of an image and isolate each one as a unique object of interest.
    For example, in a face detection system, we need to separate the faces from the
    rest of the parts in the scene.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们对输入图像应用所有必要的预处理步骤之后，第二步是分割。在分割步骤中，我们需要提取图像中的感兴趣区域，并将每个区域隔离为独特的感兴趣对象。例如，在人脸检测系统中，我们需要将人脸与场景中的其他部分分开。
- en: After getting the objects inside the image, we continue with the next step.
    We need to extract all the features of each one detected object; a feature is
    a vector of characteristics of objects. A characteristic describes our objects
    and can be the area of the object, contour, texture pattern, and so on.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在获取图像中的对象之后，我们继续下一步。我们需要提取每个检测到的对象的全部特征；特征是对象特性的向量。特性描述我们的对象，可以是对象的面积、轮廓、纹理图案等。
- en: 'Now, we have the descriptor of our object; a descriptor is a feature that describes
    an object, and we use these descriptors to train our model or predict one of them.
    To do this, we need to create a big dataset of features, where hundreds, thousands,
    and millions of images are preprocessed, and extracted features use all these
    features in a train model function that we choose:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了我们对象的描述符；描述符是描述对象的特征，我们使用这些描述符来训练我们的模型或预测其中的一个。为此，我们需要创建一个包含数百、数千和数百万图像的特征大数据集，这些图像经过预处理，并提取的特征用于我们选择的训练模型函数中：
- en: '![Computer Vision and the machine learning workflow](img/B04283_06_03.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![计算机视觉和机器学习工作流程](img/B04283_06_03.jpg)'
- en: 'When we train a dataset, the model learns all the parameters required to predict
    when a new vector of features with an unknown label is given:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们训练一个数据集时，模型学习所有必要的参数，以便在给定一个具有未知标签的新特征向量时进行预测：
- en: '![Computer Vision and the machine learning workflow](img/B04283_06_04.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![计算机视觉和机器学习工作流程](img/B04283_06_04.jpg)'
- en: After we get the prediction, sometimes, a post-processing of output data is
    required; for example, merging multiple classifications to decrease the prediction
    error or merging multiple labels. A sample case is **OCR** (**Optical Character
    Recognition**), where the classification result is per character, and by combining
    the results of character recognitions, we construct a word. This means that we
    can create a post-processing method to correct errors in detected words.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们得到预测结果后，有时需要对输出数据进行后处理；例如，合并多个分类以减少预测误差或合并多个标签。一个示例是**OCR**（**光学字符识别**），其中分类结果是每个字符，通过结合字符识别的结果，我们构建一个单词。这意味着我们可以创建一个后处理方法来纠正检测到的单词中的错误。
- en: With this small introduction to machine learning for Computer Vision, we will
    learn how to implement our own application that uses machine learning to classify
    objects in a slide tape. We will use support vector machines as our classification
    methods, and see how to use them. The other machine learning algorithms have very
    similar uses. The OpenCV documentation has a detailed information about all machine
    learning algorithms.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对计算机视觉中机器学习的简要介绍，我们将学习如何实现我们自己的应用，该应用使用机器学习对幻灯片带中的对象进行分类。我们将使用支持向量机作为我们的分类方法，并了解如何使用它们。其他机器学习算法有非常相似的应用。OpenCV文档提供了所有机器学习算法的详细信息。
- en: Automatic object inspection classification example
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动对象检测分类示例
- en: Continuing with the example of the previous chapter, the automatic object inspection
    segmentation, where a carrier tape contains three different types of objects (nuts,
    screws, and rings), and with Computer Vision, we will be able to recognize each
    one of them to send notifications to a robot or similar to put each one in different
    boxes.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 继续上一章的例子，自动对象检测分割，其中载体带包含三种不同类型的对象（螺母、螺丝和环），利用计算机视觉，我们将能够识别每一个，并发送通知给机器人或类似设备将它们放入不同的盒子中。
- en: '![Automatic object inspection classification example](img/B04283_06_05.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![自动对象检测分类示例](img/B04283_06_05.jpg)'
- en: In [Chapter 5](ch05.html "Chapter 5. Automated Optical Inspection, Object Segmentation,
    and Detection"), *Automated Optical Inspection, Object Segmentation, and Detection,*
    we preprocessed the input images and extracted the regions of interest of images
    and isolated each object using different techniques. Now, we will apply all these
    concepts, as explained in previous sections, in this example to extract features
    and classify each object and allow to possible robot to put each one in different
    boxes. In our application, we are only going to show the labels of each image
    in an image, but we can send the positions in the image and the labels to other
    devices as a robot.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第5章](ch05.html "第5章. 自动光学检测、对象分割和检测")*自动光学检测、对象分割和检测*中，我们预处理了输入图像，并使用不同的技术提取了图像的兴趣区域和隔离每个对象。现在，我们将应用前几节中解释的所有这些概念，在这个例子中提取特征并对每个对象进行分类，以便可能的机器人将它们放入不同的盒子中。在我们的应用中，我们只将展示图像中的每个图像的标签，但我们可以将图像中的位置和标签发送到其他设备，如机器人。
- en: 'Then, our goal is from an input image with few objects to show the objects''
    names over each one, as per the following image. However, to learn all the steps
    of the complete process, we will train our system to show each image that is trained,
    create a plot to show each object the features that we are going to use with different
    colors, the preprocessed input image, and finally, the output classification result
    with the following result:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们的目标是根据以下图像，从包含少量对象的输入图像中显示每个对象的名称，但是为了学习整个过程的全部步骤，我们将训练我们的系统显示每个训练图像，创建一个图表显示每个对象我们将使用不同颜色的特征，预处理后的输入图像，最后，以下结果的输出分类结果：
- en: '![Automatic object inspection classification example](img/B04283_06_06.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![自动对象检测分类示例](img/B04283_06_06.jpg)'
- en: 'We will perform the following steps for our example application:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为我们的示例应用执行以下步骤：
- en: 'For training each image:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个图像的训练：
- en: Preprocess an image
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理图像
- en: Segment an image
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分割图像
- en: 'For each object in an image:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于图像中的每个对象：
- en: Extract the features
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取特征
- en: Add the object to the training feature vector with its label
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将对象及其标签添加到训练特征向量中
- en: Create an SVM model.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建SVM模型。
- en: Train our SVM model with the training feature vector.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练特征向量训练我们的SVM模型。
- en: Preprocess an input image to be classified.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理待分类的输入图像。
- en: Segment an input image.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分割输入图像。
- en: 'For each object detected:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于检测到的每个对象：
- en: Extract the features
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取特征
- en: Predict with an SVM model
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 SVM 模型进行预测
- en: Paint the result in an output image
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在输出图像上绘制结果
- en: For the preprocessing and segmentation stage, we will use the code discussed
    in [Chapter 5](ch05.html "Chapter 5. Automated Optical Inspection, Object Segmentation,
    and Detection"), *Automated Optical Inspection, Object Segmentation, and Detection*,
    and we will explain how to extract the features and create the vectors required
    to train and predict our model.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于预处理和分割阶段，我们将使用第 5 章中讨论的代码，*自动光学检测、对象分割和检测*，我们将解释如何提取特征并创建训练和预测我们模型所需的向量。
- en: Feature extraction
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征提取
- en: Now, let's extract the features of each object. To understand the feature concept
    of a feature vector, we will extract very simple features, but it is enough to
    get good results. In other solutions, we can get more complex features, such as
    texture descriptors, contour descriptors, and so on.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们提取每个对象的特征。为了理解特征向量的特征概念，我们将提取非常简单的特征，但这足以获得良好的结果。在其他解决方案中，我们可以获得更复杂的特征，例如纹理描述符、轮廓描述符等。
- en: 'In our example, we only have these three types of objects, *nuts*, *rings*,
    and *screws*, in different possible positions. All these possible objects and
    positions are shown in the following figure:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们只有这三种类型的对象，*螺母*、*环*和*螺丝*，在不同的可能位置。所有这些可能的对象和位置都在以下图中展示：
- en: '![Feature extraction](img/B04283_06_07.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![特征提取](img/B04283_06_07.jpg)'
- en: 'We will explore the good characteristics that will help the computer to identify
    each object. The characteristics are as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探索有助于计算机识别每个对象的良好特征。特征如下：
- en: The area of an object
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物体的面积
- en: The aspect ratio, which is the width divided by the height of the bounding rectangle
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 长宽比，即边界矩形的宽度除以高度
- en: The number of holes
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 孔洞的数量
- en: The number of contour sides
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮廓边的数量
- en: These characteristics can describe our objects very well, and if we use all
    of them, the classification error can be very small. However, in our implemented
    example, we will use only the first two characteristics, the area and aspect ratio,
    for learning purposes because we can plot these characteristics in 2D graphics,
    and we can show that these values describe our objects correctly. We can differentiate
    one kind of object from the others visually in the graphic plot.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特征可以很好地描述我们的对象，如果我们使用所有这些特征，分类错误可以非常小。然而，在我们的实现示例中，我们将只使用前两个特征，即面积和宽高比，用于学习目的，因为我们可以在二维图形中绘制这些特征，并且我们可以展示这些值正确地描述了我们的对象。我们可以在图形图中直观地区分一种对象与其他对象。
- en: 'To extract these features, we will use the black/white input ROI image as the
    input, where only one object appears in a white color with a black background.
    This input is the result of segmentation, as discussed in [Chapter 5](ch05.html
    "Chapter 5. Automated Optical Inspection, Object Segmentation, and Detection"),
    *Automated Optical Inspection, Object Segmentation, and Detection*. We will use
    the `findCountours` algorithm for segmentation objects and create the `ExtractFeatures`
    function for this purpose:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提取这些特征，我们将使用黑色/白色输入 ROI 图像作为输入，其中只有一个对象以白色出现，背景为黑色。这个输入是分割的结果，如第 5 章中所述，*自动光学检测、对象分割和检测*。我们将使用
    `findCountours` 算法进行对象分割，并为此创建 `ExtractFeatures` 函数：
- en: '[PRE2]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let's understand the code in detail.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细理解一下代码。
- en: We will create a function that has one image as the input and returns two vectors
    of left and top position for each object detected in the image as parameters;
    this will be used to draw its label over each object. The output of the function
    is a vector of vectors of floats; in other words, a matrix where each row contains
    the features of each object that is detected.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个函数，该函数以一个图像作为输入，并返回每个在图像中检测到的对象的左和顶位置的两个向量作为参数；这将用于在每个对象上绘制其标签。该函数的输出是一个浮点向量向量的向量；换句话说，是一个矩阵，其中每一行包含检测到的每个对象的特征。
- en: 'Let''s create a function that draws a label over each other:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个函数，在每一个对象上绘制标签：
- en: 'Firstly, we need to create the output vector variable and contours variable
    that are to be used in our `FindContours` algorithm segmentation, and we need
    to create a copy of our input image because the `findContours` OpenCV functions
    modify the input image:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要创建输出向量变量和轮廓变量，这些变量将在我们的 `FindContours` 算法分割中使用，并且我们需要创建输入图像的一个副本，因为 `findContours`
    OpenCV 函数会修改输入图像：
- en: '[PRE3]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, we can use the `findContours` function to retrieve each object in an image.
    If we don''t detect any contour, we return an empty output matrix:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 `findContours` 函数检索图像中的每个对象。如果我们没有检测到任何轮廓，我们返回一个空输出矩阵：
- en: '[PRE4]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'For each object `contour` we are going to draw in a black image each object
    using `1` as the color value. This is our mask image to compute all features:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们将要在黑色图像中绘制的每个 `contour` 对象，我们使用 `1` 作为颜色值。这是我们用于计算所有特征的掩码图像：
- en: '[PRE5]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'It''s important to use the value `1` to draw inside the shape because we can
    calculate the area by summing all values inside the contour:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用值 `1` 在形状内部绘制非常重要，因为我们可以通过计算轮廓内的所有值来计算面积：
- en: '[PRE6]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This area is our first feature. Now, we will use this area value as a filter
    to remove the small objects that we need to avoid. All objects with an area less
    than a minimum area are discarded. After we pass the filter, we create the second
    feature, that is, the aspect ratio of an object. This means that the maximum width
    or height is divided by the minimum width or height. This feature can differentiate
    the screw from other objects easily:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个面积是我们的第一个特征。现在，我们将使用这个面积值作为过滤器，以移除我们需要避免的小对象。所有面积小于最小面积的物体都被丢弃。在通过过滤器之后，我们创建第二个特征，即物体的长宽比。这意味着最大宽度或高度除以最小宽度或高度。这个特征可以很容易地将螺丝与其他物体区分开来：
- en: '[PRE7]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, we have the features, and we only need to add these features to the output
    vector. To do this, we create a row vector of floats and add these values, and
    later on, add this row to the output vector:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经有了这些特征，我们只需要将这些特征添加到输出向量中。为此，我们创建一个浮点行向量并添加这些值，稍后，将这个行向量添加到输出向量中：
- en: '[PRE8]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If the left and top `params` are passed, then add the top-left values to the
    `params` output:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果传递了左上角 `params`，则将左上角的值添加到 `params` 输出中：
- en: '[PRE9]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, we will show the detected objects in a window for the user feedback,
    and when we finish processing all the objects in the image, we will return the
    output feature vector:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将向用户展示检测到的对象，以便获取用户反馈，当我们处理完图像中的所有对象后，我们将返回输出特征向量：
- en: '[PRE10]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now, we can extract the features of each input image, and we need to continue
    with the next step, which is to train our model.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以提取每个输入图像的特征，并需要继续下一步，即训练我们的模型。
- en: Training an SVM model
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练SVM模型
- en: We will use a supervised learning model, and then, we will require images of
    each object and their corresponding labels. There are no minimum number of images
    in the dataset. If we provide more images for the training process, we will get
    a better classification model (in most of the cases), but simple classifiers can
    be enough to train simple models. To do this, we create three folders (`screw`,
    `nut`, and `ring`), where all the images of each type are placed together.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个监督学习模型，然后，我们需要每个对象的图像及其相应的标签。数据集中没有图像的最小数量限制。如果我们为训练过程提供更多图像，我们将得到一个更好的分类模型（在大多数情况下），但简单的分类器足以训练简单的模型。为此，我们创建了三个文件夹（`screw`、`nut`
    和 `ring`），其中每个类型的所有图像都放在一起。
- en: For each image in the folder, we need to extract the features and add them to
    the train feature matrix, and at same time, we need to create a new vector with
    the labels for each row, corresponding to each training matrix.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文件夹中的每个图像，我们需要提取特征并将它们添加到训练特征矩阵中，同时，我们还需要创建一个新向量，其中包含每行的标签，对应于每个训练矩阵。
- en: To evaluate our system, we split each folder into a number of images for testing
    and training purposes. We leave around 20 images for testing and the others for
    training. Then, we need to create two vectors of labels and two matrices for train
    and test.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估我们的系统，我们将每个文件夹分成用于测试和训练目的的多个图像。我们保留大约20个图像用于测试，其余的用于训练。然后，我们需要创建两个标签向量和两个用于训练和测试的矩阵。
- en: 'Then, let''s understand the code. First, we need to create our model. We need
    to declare the model in order to be able access it as a global variable. OpenCV
    uses the `Ptr` template class for pointers:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们理解一下代码。首先，我们需要创建我们的模型。我们需要声明模型以便能够将其作为全局变量访问。OpenCV使用 `Ptr` 模板类来处理指针：
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After we declare the pointer to the new SVM model, we need to create it and
    train it. We create the `trainAndTest` function for this purpose:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们声明新的SVM模型指针之后，我们需要创建它并对其进行训练。为此，我们创建了一个 `trainAndTest` 函数：
- en: '[PRE12]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Let's understand the code in detail.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细理解一下代码。
- en: 'First, we need to create the required variables to store the training and test
    data:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要创建存储训练和测试数据的所需变量：
- en: '[PRE13]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'As mentioned earlier, we need to read all the images from each folder, extract
    the features, and save them in our training and test data. To do this, we will
    use the `readFolderAndExtractFeatures` function:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们需要从每个文件夹中读取所有图像，提取特征，并将它们保存到我们的训练和测试数据中。为此，我们将使用`readFolderAndExtractFeatures`函数：
- en: '[PRE14]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `readFolderAndExtractFeatures` function uses the `VideoCapture` OpenCV
    function to read all the images of a folder like a video or camera. For each image
    read, we extract the features and then add them to the corresponding output vector:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`readFolderAndExtractFeatures`函数使用OpenCV的`VideoCapture`函数读取文件夹中的所有图像，就像视频或摄像头一样。对于每个读取的图像，我们提取特征，然后将它们添加到相应的输出向量中：'
- en: '[PRE15]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'After filling all the vectors with features and labels, we need to convert
    them to the OpenCV `mat` format in order to send them to the `training` function:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在将所有向量填充好特征和标签后，我们需要将它们转换为OpenCV `mat`格式，以便将它们发送到`training`函数：
- en: '[PRE16]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We are now ready to create and train our machine learning model, as mentioned
    earlier, and we are going to use a support vector machine. First, we need to set
    up the basic model parameters:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前提到的，我们现在准备创建和训练我们的机器学习模型，我们将使用支持向量机。首先，我们需要设置基本模型参数：
- en: '[PRE17]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We need to define the SVM type and kernel to be used and the criteria to stop
    the learning process; in our case, we will use a maximum number of iterations,
    stopping at 100 iterations. For more information on each parameter and what it
    does, check out the OpenCV documentation. After we create the parameters of the
    setup, we need to create the model by calling the `train` method and using the
    `trainingDataMat` and response matrices:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要定义要使用的SVM类型和核，以及停止学习过程的准则；在我们的情况下，我们将使用最大迭代次数，停止在100次迭代。有关每个参数及其功能的更多信息，请参阅OpenCV文档。在创建设置参数后，我们需要通过调用`train`方法并使用`trainingDataMat`和响应矩阵来创建模型：
- en: '[PRE18]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We use the test vector (by setting the `num_for_test` variable greater than
    `0`) to obtain an approximation error of our model. To get the error estimation,
    we need to predict all the test vector features to obtain the SVM prediction results
    and then compare these results to the original labels:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用测试向量（通过将`num_for_test`变量设置为大于`0`）来获得我们模型的近似误差。为了获得误差估计，我们需要预测所有测试向量特征以获得SVM预测结果，然后比较这些结果与原始标签：
- en: '[PRE19]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We use the `predict` function using the `testDataMat` features and a new `mat`
    to predict results. The `predict` function allows you to do multiple predictions
    at the same time, giving a matrix instead of only one row.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`predict`函数，利用`testDataMat`特征和一个新的`mat`来预测结果。`predict`函数允许你同时进行多个预测，返回一个矩阵而不是只有一行。
- en: After the prediction is done, we only need to get the difference of `testPredict`
    using our `testResponses` (the original labels). If there are differences, we
    only need to count the number of differences and divide them by the total number
    of tests to get the error.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 预测完成后，我们只需要使用我们的`testResponses`（原始标签）获取`testPredict`的差异。如果有差异，我们只需要计算差异的数量，并将它们除以测试总数以获得错误。
- en: Note
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: We can use the new `TrainData` class to generate the feature vectors and samples
    and split out train data in test and train vectors.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用新的`TrainData`类生成特征向量和样本，并将训练数据分割成测试和训练向量。
- en: 'Finally, we need to show the training data in a 2D plot, where the *y* axis
    is the aspect ratio feature and the *x* axis is the area of objects. Each point
    has a different color and shape (cross, square, and circle) that shows a different
    kind of object, and we can clearly see the groups of objects in the following
    figure:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要在2D图中显示训练数据，其中*y*轴是宽高比特征，*x*轴是物体的面积。每个点都有不同的颜色和形状（交叉、正方形和圆形），表示不同类型的物体，我们可以在以下图中清楚地看到物体的组：
- en: '![Training an SVM model](img/B04283_06_08.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![训练SVM模型](img/B04283_06_08.jpg)'
- en: Now, we are very close to finishing our application sample. We have a trained
    SVM model that we can use as a classification model to detect the type of a new
    incoming and unknown feature vector. Then, the next step is to predict an input
    image with unknown objects.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们非常接近完成我们的应用程序样本。我们有一个训练好的SVM模型，我们可以将其用作分类模型来检测新到达的未知特征向量类型。然后，下一步是预测包含未知物体的输入图像。
- en: Input image prediction
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输入图像预测
- en: 'Now, we are ready to explain the main function, which loads the input image
    and predicts the objects that appear inside. We are going to use something like
    this, as shown in the following figure, as the input image where multiple and
    different objects appear:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备解释主要功能，该功能加载输入图像并预测出现在内部的物体。我们将使用如下所示的内容作为输入图像，其中出现多个不同的物体，如图所示：
- en: '![Input image prediction](img/B04283_06_09.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![输入图像预测](img/B04283_06_09.jpg)'
- en: 'For all training images, we need to load and preprocess the input image:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有训练图像，我们需要加载和预处理输入图像：
- en: First, we load and convert the images to gray color values.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将图像加载并转换为灰度颜色值。
- en: 'We then apply the preprocessing tasks, as discussed in [Chapter 5](ch05.html
    "Chapter 5. Automated Optical Inspection, Object Segmentation, and Detection"),
    *Automated Optical Inspection, Object Segmentation, and Detection,* using the
    `preprocessImage` function:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们应用前面讨论的预处理任务，使用`preprocessImage`函数，如[第5章](ch05.html "第5章. 自动光学检测、目标分割和检测")，*自动光学检测、目标分割和检测*：
- en: '[PRE20]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, we extract the features of vectors of all the objects that appear in the
    image and the top-left positions of each one using the `ExtractFeatures` that
    we mentioned earlier:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们使用前面提到的`ExtractFeatures`提取图像中所有出现的物体的特征以及每个物体的左上角位置：
- en: '[PRE21]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'For each object that we detect, we store it as a feature row, and then, we
    convert each row as a `Mat` of one row and two features:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们检测到的每个物体，我们将其存储为特征行，然后，我们将每一行转换为具有一行和两个特征的`Mat`：
- en: '[PRE22]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then, we predict the single object using the `predict` function of our `StatModel`
    SVM:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用我们的`StatModel` SVM的`predict`函数预测单个物体：
- en: '[PRE23]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The float result of the prediction is the label of the object that is detected.
    Then, to complete the application, we only need to draw the label over each image
    in an output image.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预测的浮点结果是检测到的物体的标签。然后，为了完成应用程序，我们只需要在输出图像的每个图像上绘制标签。
- en: 'We will use a `stringstream` to store the text and a `Scalar` to store the
    color of each different label:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`stringstream`来存储文本，使用`Scalar`来存储每个不同标签的颜色：
- en: '[PRE24]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Draw the label text over each object using its detected position in the `ExtractFeatures`
    function:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ExtractFeatures`函数中检测到的位置在每个物体上绘制标签文本：
- en: '[PRE25]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Finally, we will draw our results in the output window:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将结果绘制在输出窗口中：
- en: '[PRE26]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The final result of our application shows a window that is tiled with four
    screens, where the top-left image is the input training image, the top-right image
    is the plot training image, the bottom-left image is the input image to analyze
    preprocessed, and the bottom-right image is the final result of the prediction:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用程序的最终结果显示一个由四个屏幕拼贴的窗口，其中左上角的图像是输入训练图像，右上角的图像是绘图训练图像，左下角的图像是分析预处理后的输入图像，右下角的图像是预测的最终结果：
- en: '![Input image prediction](img/B04283_06_10.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![输入图像预测](img/B04283_06_10.jpg)'
- en: Summary
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned the basics of the machine learning model and how
    to apply a small sample application to understand all the basic tips required
    to create our own ML application.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了机器学习模型的基础知识以及如何应用一个小型样例应用来理解创建我们自己的ML应用所需的所有基本技巧。
- en: Machine learning is complex and involves different techniques for each use case
    (supervised learning, unsupervised, clustering, and so on), and we learned how
    to create the most typical ML application and the supervised learning with an
    SVM.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是复杂的，涉及针对每个用例的不同技术（监督学习、无监督学习、聚类等），我们学习了如何创建最典型的ML应用以及使用SVM的监督学习。
- en: 'The most important concepts in supervised machine learning are: first, we need
    to have an appropriate number of samples or datasets; and second, we need to correctly
    choose the features that describe our objects correctly. For more information
    on image features, refer to [Chapter 8](ch08.html "Chapter 8. Video Surveillance,
    Background Modeling, and Morphological Operations"), *Video Surveillance, Background
    Modeling, and Morphological Operations*. Third, choose the best model that gives
    us the best predictions.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习中的最重要的概念是：首先，我们需要有适当数量的样本或数据集；其次，我们需要正确选择描述我们对象的特征。有关图像特征的更多信息，请参阅[第8章](ch08.html
    "第8章. 视频监控、背景建模和形态学操作")，*视频监控、背景建模和形态学操作*。第三，选择给我们最佳预测的最佳模型。
- en: If we don't reach the correct predictions we have to check each one of these
    concepts to look for where the issue is.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有达到正确的预测，我们必须检查这些概念中的每一个，以寻找问题所在。
- en: In the next chapter, we will introduce background subtraction methods, which
    are very useful for video surveillance applications where the backgrounds don't
    give us any interesting information and must be discarded to allow the segmentation
    of the interested objects in which to analyze.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍背景减法方法，这对于视频监控应用非常有用，在这些应用中，背景不提供任何有趣的信息，必须被丢弃，以便对感兴趣的对象进行分割和分析。
