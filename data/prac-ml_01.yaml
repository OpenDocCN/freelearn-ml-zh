- en: Chapter 1. Introduction to Machine learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 机器学习简介
- en: The goal of this chapter is to take you through the Machine learning landscape
    and lay out the basic concepts upfront for the chapters that follow. More importantly,
    the focus is to help you explore various learning strategies and take a deep dive
    into the different subfields of Machine learning. The techniques and algorithms
    under each subfield, and the overall architecture that forms the core for any
    Machine learning project implementation, are covered in depth.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是带您了解机器学习领域，并为后续章节提前概述基本概念。更重要的是，重点是帮助您探索各种学习策略，并深入不同机器学习子领域。每个子领域下的技术和算法，以及构成任何机器学习项目实施核心的整体架构，都将进行深入探讨。
- en: There are many publications on Machine learning, and a lot of work has been
    done in past in this field. Further to the concepts of Machine learning, the focus
    will be primarily on specific practical implementation aspects through real-world
    examples. It is important that you already have a relatively high degree of knowledge
    in basic programming techniques and algorithmic paradigms; although for every
    programming section, the required primers are in place.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 关于机器学习有许多出版物，过去在这个领域已经做了很多工作。除了机器学习概念之外，重点将主要放在通过实际案例的具体实践方面。重要的是你已经对基本编程技术和算法范式有相当高的了解；尽管对于每个编程部分，都有相应的入门指南。
- en: 'The following topics listed are covered in depth in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将深入探讨以下主题：
- en: Introduction to Machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习简介
- en: A basic definition and the usage context
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本定义和用法环境
- en: The differences and similarities between Machine learning and data mining, **Artificial
    Intelligence** (**AI**), statistics, and data science
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习与数据挖掘、**人工智能**（**AI**）、统计学和数据科学之间的差异和相似性
- en: The relationship with big data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与大数据的关系
- en: 'The terminology and mechanics: model, accuracy, data, features, complexity,
    and evaluation measures'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 术语和机制：模型、准确性、数据、特征、复杂性和评估指标
- en: 'Machine learning subfields: supervised learning, unsupervised learning, semi-supervised
    learning, reinforcement learning, and deep learning. Specific Machine learning
    techniques and algorithms are also covered under each of the machine learning
    subfields'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习子领域：监督学习、无监督学习、半监督学习、强化学习和深度学习。每个机器学习子领域也涵盖了特定的机器学习技术和算法
- en: 'Machine learning problem categories: Classification, Regression, Forecasting,
    and Optimization'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习问题类别：分类、回归、预测和优化
- en: Machine learning architecture, process lifecycle, and practical problems
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习架构、生命周期和实际问题
- en: Machine learning technologies, tools, and frameworks
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习技术、工具和框架
- en: Machine learning
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: Machine learning has been around for many years now and all social media users,
    at some point in time, have been consumers of Machine learning technology. One
    of the common examples is face recognition software, which is the capability to
    identify whether a digital photograph includes a given person. Today, Facebook
    users can see automatic suggestions to tag their friends in the digital photographs
    that are uploaded. Some cameras and software such as iPhoto also have this capability.
    There are many examples and use cases that will be discussed in more detail later
    in this chapter.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习已经存在很多年了，所有社交媒体用户在某个时间点都曾是机器学习技术的消费者。一个常见的例子是面部识别软件，它具有识别数字照片中是否包含特定人物的能力。如今，Facebook用户可以在上传的数字照片中看到自动建议标记他们的朋友。一些相机和软件，如iPhoto，也具备这种功能。本章后面将更详细地讨论许多例子和用例。
- en: 'The following concept map represents the key aspects and semantics of Machine
    learning that will be covered throughout this chapter:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下概念图代表了本章将涵盖的机器学习的关键方面和语义：
- en: '![Machine learning](img/B03980_01_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习](img/B03980_01_01.jpg)'
- en: Definition
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义
- en: 'Let''s start with defining what Machine learning is. There are many technical
    and functional definitions for Machine learning, and some of them are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义机器学习是什么开始。机器学习有许多技术和功能定义，以下是一些例子：
- en: '|   | *"A computer program is said to learn from experience E with respect
    to some class of tasks T and performance measure P, if its performance at tasks
    in T, as measured by P, improves with experience E."* |   |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '|   | *"如果一个计算机程序在任务T中从经验E中学习，相对于某些任务类T和性能度量P，如果其性能随着经验E的提高而提高，则称该程序从经验E中学习。"
    |   |'
- en: '|   | --*Tom M. Mitchell* |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '|   | --*Tom M. Mitchell* |'
- en: '|   | *"Machine learning is the training of a model from data that generalizes
    a decision against a performance measure."* |   |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '|   | *"机器学习是从数据中训练模型，该模型对性能度量进行泛化决策。" |   |'
- en: '|   | --*Jason Brownlee* |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '|   | --*Jason Brownlee* |'
- en: '|   | *"A branch of artificial intelligence in which a computer generates rules
    underlying or based on raw data that has been fed into it."* |   |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '|   | *"人工智能的一个分支，其中计算机生成基于输入的原始数据的基本规则。" |   |'
- en: '|   | --*Dictionary.com* |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '|   | --*Dictionary.com* |'
- en: '|   | *"Machine learning is a scientific discipline that is concerned with
    the design and development of algorithms that allow computers to evolve behaviors
    based on empirical data, such as from sensor data or databases."* |   |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '|   | *"机器学习是一门科学，它涉及设计和发展算法，使计算机能够根据经验数据，如传感器数据或数据库中的数据，进化行为。" |   |'
- en: '|   | --*Wikipedia* |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '|   | --*Wikipedia* |'
- en: The preceding definitions are fascinating and relevant. They either have an
    algorithmic, statistical, or mathematical perspective.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 上述定义既迷人又相关。它们要么具有算法、统计或数学的角度。
- en: Beyond these definitions, a single term or definition for Machine learning is
    the key to facilitating the definition of a problem-solving platform. Basically,
    it is *a mechanism for pattern search* and building intelligence into a machine
    to be able to learn, implying that it will be able to do better in the future
    from its own experience.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些定义之外，一个单一的术语或定义对于机器学习的定义至关重要，它有助于促进问题解决平台的定义。基本上，它是一种*模式搜索机制*，将智能构建到机器中，使其能够学习，这意味着它将能够从自己的经验中做得更好。
- en: Drilling down a little more into what a pattern typically is, pattern search
    or pattern recognition is essentially the study of how machines perceive the environment,
    learn to discriminate behavior of interest from the rest, and be able to take
    reasonable decisions about categorizing the behavior. This is more often performed
    by humans. The goal is to foster accuracy, speed, and avoid the possibility of
    inappropriate use of the system.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 深入探讨一个模式通常是什么，模式搜索或模式识别本质上研究的是机器如何感知环境，学会区分感兴趣的行为与其他行为，并能够对分类行为做出合理的决策。这通常由人类来完成。目标是提高准确性、速度，并避免系统被不当使用的可能性。
- en: Machine learning algorithms that are constructed this way handle building intelligence.
    Essentially, machines make sense of data in much the same way that humans do.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式构建的机器学习算法处理构建智能。本质上，机器以与人类相似的方式理解数据。
- en: The primary goal of a Machine learning implementation is to develop a general
    purpose algorithm that solves a practical and focused problem. Some of the aspects
    that are important and need to be considered in this process include data, time,
    and space requirements. Most importantly, with the ability to be applied to a
    broad class of learning problems, the goal of a learning algorithm is to produce
    a result that is a rule and is as accurate as possible.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习实现的根本目标是开发一个通用的算法，该算法能够解决实际且具体的问题。在这个过程中需要考虑的重要方面包括数据、时间和空间需求。最重要的是，具有应用于广泛学习问题的能力，学习算法的目标是产生一个尽可能准确的结果，即一条规则。
- en: Another important aspect is the big data context; that is, Machine learning
    methods are known to be effective even in cases where insights need to be uncovered
    from datasets that are large, diverse, and rapidly changing. More on the large
    scale data aspect of Machine learning will be covered in [Chapter 2](ch02.html
    "Chapter 2. Machine learning and Large-scale datasets"), *Machine Learning and
    Large-scale Datasets*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的方面是大数据环境；也就是说，机器学习方法已知在需要从大型、多样化和快速变化的数据集中发现洞察力的情况下也有效。关于机器学习的大规模数据方面的更多内容将在[第2章](ch02.html
    "第2章。机器学习与大规模数据集") *机器学习与大规模数据集* 中介绍。
- en: Core Concepts and Terminology
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核心概念和术语
- en: At the heart of Machine learning is knowing and using the data appropriately.
    This includes collecting the *right* data, cleansing the data, and processing
    the data using learning algorithms iteratively to build models using certain key
    features of data, and based on the hypotheses from these models, making predictions.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的核心是了解并适当地使用数据。这包括收集*正确*的数据、清洗数据，并使用学习算法迭代地处理数据，利用数据的关键特征构建模型，并根据这些模型的假设进行预测。
- en: In this section, we will cover the standard nomenclature or terminology used
    in machine learning, starting from how to describe data, learning, modeling, algorithms,
    and specific machine learning tasks.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍机器学习中使用的标准术语或命名法，从如何描述数据、学习、建模、算法以及特定的机器学习任务开始。
- en: What is learning?
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是学习？
- en: 'Now, let us look at the definition of "learning" in the context of Machine
    learning. In simple terms, historical data or observations are used to predict
    or derive actionable tasks. Very clearly, one mandate for an intelligent system
    is its ability to learn. The following are some considerations to define a learning
    problem:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看在机器学习背景下“学习”的定义。简单来说，历史数据或观察结果被用来预测或推导出可执行的任务。非常明显，一个智能系统的基本要求就是其学习能力。以下是一些定义学习问题的考虑因素：
- en: Provide a definition of what the learner should learn and the need for learning.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供一个定义，说明学习者应该学习什么以及学习的必要性。
- en: Define the data requirements and the sources of the data.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义数据需求和数据来源。
- en: Define if the learner should operate on the dataset in entirety or a subset
    will do.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义学习者是否应该在整个数据集上操作，或者一个子集就足够了。
- en: Before we plunge into understanding the internals of each learning type in the
    following sections, you need to understand the simple process that is followed
    to solve a learning problem, which involves building and validating models that
    solve a problem with maximum accuracy.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入理解以下各节中每种学习类型的内部机制之前，你需要了解解决学习问题所遵循的简单过程，这涉及到构建和验证模型，以最大精度解决问题。
- en: Tip
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: A model is nothing but an output from applying an algorithm to a dataset, and
    it is usually a representation of the data. We cover more on models in the later
    sections.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 模型不过是将算法应用于数据集的输出，它通常是数据的表示。我们将在后面的章节中更详细地介绍模型。
- en: In general, for performing Machine learning, there are primarily two types of
    datasets required. The first dataset is usually manually prepared, where the input
    data and the expected output data are available and prepared. It is important
    that every piece of input data has an expected output data point available as
    this will be used in a supervised manner to build the rule. The second dataset
    is where we have the input data, and we are interested in predicting the expected
    output.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，为了执行机器学习，主要需要两种类型的数据集。第一种数据集通常是手动准备的，其中输入数据和预期的输出数据都可用并已准备。重要的是，每一条输入数据都应该有一个可预期的输出数据点，因为这将以监督方式用于构建规则。第二种数据集是我们有输入数据，我们感兴趣的是预测预期的输出。
- en: 'As a first step, the given data is segregated into three datasets: training,
    validation, and testing. There is no one hard rule on what percentage of data
    should be training, validation, and testing datasets. It can be 70-10-20, 60-30-10,
    50-25-25, or any other values.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，给定的数据被划分为三个数据集：训练集、验证集和测试集。没有一条固定的规则规定数据集的百分比应该是多少，可以是70-10-20、60-30-10、50-25-25或其他任何值。
- en: The training dataset refers to the data examples that are used to learn or build
    a classifier, for example. The validation dataset refers to the data examples
    that are verified against the built classifier and can help tune the accuracy
    of the output. The testing dataset refers to the data examples that help assess
    the performance of the classifier.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集指的是用于学习或构建分类器的数据示例，例如。验证数据集指的是用于验证构建的分类器的数据示例，可以帮助调整输出的准确性。测试数据集指的是帮助评估分类器性能的数据示例。
- en: 'There are typically three phases for performing Machine learning:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 执行机器学习通常有三个阶段：
- en: '**Phase 1—Training Phase**: This is the phase where training data is used to
    train the model by pairing the given input with the expected output. The output
    of this phase is the learning model itself.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第一阶段——训练阶段**：这是使用训练数据通过将给定的输入与预期的输出配对来训练模型的过程。这一阶段的输出是学习模型本身。'
- en: '**Phase 2—Validation and Test Phase**: This phase is to measure how good the
    learning model that has been trained is and estimate the model properties, such
    as error measures, recall, precision, and others. This phase uses a validation
    dataset, and the output is a sophisticated learning model.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第二阶段——验证和测试阶段**：这个阶段是为了衡量已经训练好的学习模型的好坏，并估计模型属性，如误差度量、召回率、精确度等。这个阶段使用验证数据集，输出是一个复杂的学习模型。'
- en: '**Phase 3—Application Phase**: In this phase, the model is subject to the real-world
    data for which the results need to be derived.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第三阶段——应用阶段**：在这个阶段，模型需要接受实际世界的数据，并从中得出结果。'
- en: 'The following figure depicts how learning can be applied to predict the behavior:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了如何将学习应用于预测行为：
- en: '![What is learning?](img/B03980_01_02.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![什么是学习？](img/B03980_01_02.jpg)'
- en: Data
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: Data forms the main source of learning in Machine learning. The data that is
    being referenced here can be in any format, can be received at any frequency,
    and can be of any size. When it comes to handling large datasets in the Machine
    learning context, there are some new techniques that have evolved and are being
    experimented with. There are also more big data aspects, including parallel processing,
    distributed storage, and execution. More on the large-scale aspects of data will
    be covered in the next chapter, including some unique differentiators.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是机器学习中的主要学习来源。这里所引用的数据可以是任何格式，可以以任何频率接收，可以是任何大小。在处理机器学习环境中的大型数据集时，有一些新技术已经发展起来，并正在被实验。还有更多的大数据方面，包括并行处理、分布式存储和执行。下一章将更详细地介绍数据的这些大规模方面，包括一些独特的区分因素。
- en: When we think of data, dimensions come to mind. To start with, we have rows
    and columns when it comes to structured and unstructured data. This book will
    cover handling both structured and unstructured data in the machine learning context.
    In this section, we will cover the terminology related to data within the Machine
    learning context.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想到数据时，维度就会浮现在脑海中。首先，对于结构化和非结构化数据，我们有行和列。这本书将涵盖在机器学习环境中处理结构化和非结构化数据。在本节中，我们将介绍与机器学习环境中的数据相关的术语。
- en: '| Term | Purpose or meaning in the context of Machine learning |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 术语 | 在机器学习环境中的目的或意义 |'
- en: '| --- | --- |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Feature, attribute, field, or variable | This is a single column of data
    being referenced by the learning algorithms. Some features can be input to the
    learning algorithm, and some can be the outputs. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 特征、属性、字段或变量 | 这是学习算法所引用的单个数据列。一些特征可以作为输入提供给学习算法，而一些可以是输出。|'
- en: '| Instance | This is a single row of data in the dataset. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 实例 | 这是数据集中的一个单独的数据行。|'
- en: '| Feature vector or tuple | This is a list of features. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 特征向量或元组 | 这是一个特征列表。|'
- en: '| Dimension | This is a subset of attributes used to describe a property of
    data. For example, a date dimension consists of three attributes: day, month,
    and year. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 维度 | 这是用于描述数据属性的一组属性子集。例如，日期维度由三个属性组成：日、月和年。|'
- en: '| Dataset | A collection of rows or instances is called a dataset. In the context
    of Machine learning, there are different types of datasets that are meant to be
    used for different purposes. An algorithm is run on different datasets at different
    stages to measure the accuracy of the model. There are three types of dataset:
    training, testing, and evaluation datasets. Any given comprehensive dataset is
    split into three categories of datasets and is usually in the following proportions:
    60% training, 30% testing, and 10% evaluation. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 行或实例的集合被称为数据集。在机器学习环境中，存在不同类型的数据集，用于不同的目的。算法在不同的数据集上运行，以衡量模型的准确性。有三种类型的数据集：训练数据集、测试数据集和评估数据集。任何给定的大型数据集通常会被分成三个数据集类别，其比例通常是：60%训练，30%测试，10%评估。|'
- en: '| a. Training Dataset | The training dataset is the dataset that is the base
    dataset against which the model is built or trained. |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| a. 训练数据集 | 训练数据集是模型构建或训练的基础数据集。|'
- en: '| b. Testing Dataset | The testing dataset is the dataset that is used to validate
    the model built. This dataset is also referred to as a validating dataset. |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| b. 测试数据集 | 测试数据集是用于验证所构建模型的那个数据集。这个数据集也被称为验证数据集。|'
- en: '| c. Evaluation Dataset | The evaluation dataset is the dataset that is used
    for final verification of the model (and can be treated more as user acceptance
    testing). |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| c. 评估数据集 | 评估数据集是用于模型最终验证的数据集（可以更类似于用户验收测试）。|'
- en: '| Data Types | Attributes or features can have different data types. Some of
    the data types are listed here:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '| 数据类型 | 属性或特征可以有不同的数据类型。以下列出了一些数据类型：'
- en: 'Categorical (for example: young, old).'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类（例如：年轻，年老）。
- en: 'Ordinal (for example: 0, 1).'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序数（例如：0，1）。
- en: 'Numeric (for example: 1.3, 2.1, 3.2, and so on).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值（例如：1.3，2.1，3.2等）。
- en: '|'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Coverage | The percentage of a dataset for which a prediction is made or
    the model is covered. This determines the confidence of the prediction model.
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 覆盖率 | 预测或模型覆盖的数据集百分比。这决定了预测模型的置信度。|'
- en: Labeled and unlabeled data
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标记和未标记数据
- en: Data in the Machine learning context can either be labeled or unlabeled. Before
    we go deeper into the Machine learning basics, you need to understand this categorization,
    and what data is used when, as this terminology will be used throughout this book.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习背景下，数据可以是标记的或未标记的。在我们深入探讨机器学习基础知识之前，你需要了解这种分类，以及何时使用哪些数据，因为这种术语将在整本书中使用。
- en: Unlabeled data is usually the raw form of the data. It consists of samples of
    natural or human-created artifacts. This category of data is easily available
    in abundance. For example, video streams, audio, photos, and tweets among others.
    This form of data usually has no explanation of the meaning attached.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 未标记数据通常是数据的原始形式。它由自然或人为创造的样本组成。这类数据在数量上很容易获得。例如，视频流、音频、照片和推文等。这种形式的数据通常没有附加的解释说明。
- en: The unlabeled data becomes labeled data the moment a meaning is attached. Here,
    we are talking about attaching a "tag" or "label" that is required, and is mandatory,
    to interpret and define the relevance. For example, labels for a photo can be
    the details of what it contains, such as animal, tree, college, and so on, or,
    in the context of an audio file, a political meeting, a farewell party, and so
    on. More often, the labels are mapped or defined by humans and are significantly
    more expensive to obtain than the unlabeled raw data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个意义被附加到未标记数据上时，它就变成了标记数据。在这里，我们谈论的是附加一个“标签”或“标记”，这是必需的，并且是解释和定义相关性的强制性要求。例如，照片的标签可以是它包含的细节，如动物、树木、大学等，或者在音频文件的情况下，可以是政治会议、告别派对等。更常见的是，标签由人类映射或定义，并且比未标记的原始数据获得成本高得多。
- en: The learning models can be applied to both labeled and unlabeled data. We can
    derive more accurate models using a combination of labeled and unlabeled datasets.
    The following diagram represents labeled and unlabeled data. Both triangles and
    bigger circles represent labeled data and small circles represent unlabeled data.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 学习模型可以应用于标记数据和未标记数据。我们可以通过结合标记和未标记数据集来推导出更精确的模型。以下图表表示了标记和未标记数据。三角形和更大的圆圈代表标记数据，而小圆圈代表未标记数据。
- en: '![Labeled and unlabeled data](img/B03980_01_03.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![标记和未标记数据](img/B03980_01_03.jpg)'
- en: The application of labeled and unlabeled data is discussed in more detail in
    the following sections. You will see that supervised learning adopts labeled data
    and unsupervised learning adopts unlabeled data. Semi-supervised learning and
    deep learning techniques apply a combination of labeled and unlabeled data in
    a variety of ways to build accurate models.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 标记和未标记数据的应用将在以下章节中更详细地讨论。你会看到，监督学习采用标记数据，无监督学习采用未标记数据。半监督学习和深度学习技术以各种方式结合标记和未标记数据来构建准确的模型。
- en: Tasks
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 任务
- en: A task is a problem that the Machine learning algorithm is built to solve. It
    is important that we measure the performance on a task. The term "performance"
    in this context is nothing but the extent or confidence with which the problem
    is solved. Different algorithms when run on different datasets produce a different
    model. It is important that the models thus generated are not compared, and instead,
    the consistency of the results with different datasets and different models is
    measured.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 任务是机器学习算法旨在解决的问题。我们衡量任务上的性能是很重要的。在这个上下文中，“性能”一词无非是解决问题的程度或信心。不同的算法在不同的数据集上运行会产生不同的模型。重要的是，生成的模型不应进行比较，而应衡量不同数据集和不同模型之间结果的一致性。
- en: Algorithms
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 算法
- en: After getting a clear understanding of the Machine learning problem at hand,
    the focus is on what data and algorithms are relevant or applicable. There are
    several algorithms available. These algorithms are either grouped by the learning
    subfields (such as supervised, unsupervised, reinforcement, semi-supervised, or
    deep) or the problem categories (such as Classification, Regression, Clustering
    or Optimization). These algorithms are applied iteratively on different datasets,
    and output models that evolve with new data are captured.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在对当前机器学习问题有一个清晰的理解之后，重点转向哪些数据和算法是相关或适用的。有几种算法可供选择。这些算法要么按学习子领域（如监督学习、无监督学习、强化学习、半监督学习或深度学习）分组，要么按问题类别（如分类、回归、聚类或优化）分组。这些算法在多个数据集上迭代应用，并捕获随着新数据而演化的模型。
- en: Models
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型
- en: 'Models are central to any Machine learning implementation. A model describes
    data that is observed in a system. Models are the output of algorithms applied
    to a dataset. In many cases, these models are applied to new datasets that help
    the models learn new behavior and also predict them. There is a vast range of
    machine learning algorithms that can be applied to a given problem. At a very
    high level, models are categorized as the following:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是任何机器学习实现的核心。模型描述了系统中观察到的数据。模型是应用于数据集的算法的输出。在许多情况下，这些模型应用于新的数据集，这有助于模型学习新的行为并预测它们。针对给定问题，有广泛的机器学习算法可供应用。在非常高的层面上，模型被分类如下：
- en: Logical models
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑模型
- en: Geometric models
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 几何模型
- en: Probabilistic models
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率模型
- en: Logical models
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 逻辑模型
- en: 'Logical models are more algorithmic in nature and help us derive a set of rules
    by running the algorithms iteratively. A Decision tree is one such example:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑模型在本质上更具有算法性，通过迭代运行算法帮助我们推导出一组规则。决策树就是一个这样的例子：
- en: '![Logical models](img/B03980_01_04.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑模型](img/B03980_01_04.jpg)'
- en: Geometric models
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 几何模型
- en: 'Geometric models use geometric concepts such as lines, planes, and distances.
    These models usually operate, or can operate, on high volumes of data. Usually,
    linear transformations help compare different Machine learning methods:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 几何模型使用诸如线、平面和距离等几何概念。这些模型通常在大量数据上操作，或者可以操作。通常，线性变换有助于比较不同的机器学习方法：
- en: '![Geometric models](img/B03980_01_05.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![几何模型](img/B03980_01_05.jpg)'
- en: Probabilistic models
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 概率模型
- en: 'Probabilistic models are statistical models that employ statistical techniques.
    These models are based on a strategy that defines the relationship between two
    variables. This relationship can be derived for sure as this involves using a
    random background process. In most cases, a subset of the overall data can be
    considered for processing:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 概率模型是采用统计技术的统计模型。这些模型基于一种定义两个变量之间关系的策略。由于涉及使用随机背景过程，这种关系可以确定地推导出来。在大多数情况下，可以认为整体数据的一个子集用于处理：
- en: '| Viagra | Lottery | P(Y= Spam (Viagra, lottery)) | P(Y= ham (Viagra, lottery))
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| Viagra | Lottery | P(Y= Spam (Viagra, lottery)) | P(Y= ham (Viagra, lottery))
    |'
- en: '| --- | --- | --- | --- |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 0 | 0.31 | 0.69 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 0.31 | 0.69 |'
- en: '| 0 | 1 | 0.65 | 0.35 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1 | 0.65 | 0.35 |'
- en: '| 1 | 0 | 0.80 | 0.20 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0 | 0.80 | 0.20 |'
- en: '| 1 | 1 | 0.40 | 0.60 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 0.40 | 0.60 |'
- en: Data and inconsistencies in Machine learning
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习中的数据和不一致性
- en: 'This section details all the possible data inconsistencies that may be encountered
    while implementing Machine learning projects, such as:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 本节详细介绍了在实施机器学习项目过程中可能遇到的所有可能的数据不一致性，例如：
- en: Under-fitting
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欠拟合
- en: Over-fitting
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过拟合
- en: Data instability
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据不稳定
- en: Unpredictable future
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可预测的未来
- en: Fortunately, there are some established processes in place today to address
    these inconsistencies. The following sections cover these inconsistencies.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，目前有一些既定的流程来解决这些不一致性。以下各节将介绍这些不一致性。
- en: Under-fitting
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 欠拟合
- en: A model is said to be under-fitting when it doesn't take into consideration
    enough information to accurately model the actual data. For example, if only two
    points on an exponential curve are mapped, this possibly becomes a linear representation,
    but there could be a case where a pattern does not exist. In cases like these,
    we will see increasing errors and subsequently an inaccurate model. Also, in cases
    where the classifier is too rigid or is not complex enough, under-fitting is caused
    not just due to a lack of data, but can also be a result of incorrect modeling.
    For example, if the two classes form concentric circles and we try to fit a linear
    model, assuming they were linearly separable, this could potentially result in
    under-fitting.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个模型没有考虑足够的信息来准确建模实际数据时，我们称其为欠拟合。例如，如果只在指数曲线上映射两个点，这可能会成为一个线性表示，但可能存在没有模式的情况。在这些情况下，我们会看到不断增加的错误，随后是一个不准确的模型。此外，在分类器过于僵化或不够复杂的情况下，欠拟合不仅可能是由于数据不足，也可能是由于建模不正确。例如，如果两个类别形成同心圆，而我们试图拟合一个线性模型，假设它们是线性可分的，这可能会导致欠拟合。
- en: The accuracy of the model is determined by a measure called "power" in the statistical
    world. If the dataset size is too small, we can never target an optimal solution.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的准确性由统计世界中称为“功率”的度量来确定。如果数据集大小太小，我们永远无法达到最优解。
- en: Over-fitting
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 过拟合
- en: This case is just the opposite of the under-fitting case explained before. While
    too small a sample is not appropriate to define an optimal solution, a large dataset
    also runs the risk of having the model over-fit the data. Over-fitting usually
    occurs when the statistical model describes noise instead of describing the relationships.
    Elaborating on the preceding example in this context, let's say we have 500,000
    data points. If the model ends up catering to accommodate all 500,000 data points,
    this becomes over-fitting. This will in effect mean that the model is memorizing
    the data. This model works well as long as the dataset does not have points outside
    the curve. A model that is over-fit demonstrates poor performance as minor fluctuations
    in data tend to be exaggerated. The primary reason for over-fitting also could
    be that the criterion used to train the model is different from the criterion
    used to judge the efficacy of the model. In simple terms, if the model memorizes
    the training data rather than learning, this situation is seen to occur more often.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况与之前解释的欠拟合情况正好相反。虽然样本太小不适合定义最优解，但大数据集也存在模型过拟合数据的危险。过拟合通常发生在统计模型描述噪声而不是描述关系时。在这个背景下详细说明前面的例子，假设我们有500,000个数据点。如果模型最终要适应所有500,000个数据点，这就变成了过拟合。这实际上意味着模型正在记忆数据。只要数据集没有曲线外的点，这个模型就能很好地工作。一个过拟合的模型表现不佳，因为数据的小幅波动往往会被夸大。过拟合的主要原因也可能是用于训练模型的准则与用于评估模型有效性的准则不同。简单来说，如果模型记住训练数据而不是学习，这种情况就会更频繁地发生。
- en: 'Now, in the process of mitigating the problem of under-fitting the data, by
    giving it more data, this can in itself be a risk and end up in over-fitting.
    Considering that more data can mean more complexity and noise, we could potentially
    end up with a solution model that fits the current data at hand and nothing else,
    which makes it unusable. In the following graph, with the increasing model complexity
    and errors, the conditions for over-fit and under-fit are pointed out:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在缓解数据欠拟合问题的过程中，通过提供更多数据，这本身可能就是一个风险，并最终导致过拟合。考虑到更多数据可能意味着更多的复杂性和噪声，我们可能会得到一个解决方案模型，它只适合当前的数据，而不适合其他任何数据，这使得它无法使用。在下面的图中，随着模型复杂性和错误的增加，过拟合和欠拟合的条件被指出来：
- en: '![Over-fitting](img/B03980_01_06.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![过拟合](img/B03980_01_06.jpg)'
- en: Data instability
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据不稳定
- en: Machine learning algorithms are usually robust to noise within the data. A problem
    will occur if the outliers are due to manual error or misinterpretation of the
    relevant data. This will result in a skewing of the data, which will ultimately
    end up in an incorrect model.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法通常对数据中的噪声具有鲁棒性。如果异常值是由于人为错误或对相关数据的误解造成的，那么就会发生问题。这将导致数据偏斜，最终导致模型错误。
- en: Therefore, there is a strong need to have a process to correct or handle human
    errors that can result in building an incorrect model.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有一个过程来纠正或处理可能导致构建错误模型的人为错误是非常必要的。
- en: Unpredictable data formats
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不可预测的数据格式
- en: Machine learning is meant to work with new data constantly coming into the system
    and learning from that data. Complexity will creep in when the new data entering
    the system comes in formats that are not supported by the machine learning system.
    It is now difficult to say if our models work well for the new data given the
    instability in the formats that we receive the data, unless there is a mechanism
    built to handle this.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习旨在与系统不断进入的新数据一起工作，并从这些数据中学习。当进入系统的新的数据格式不被机器学习系统支持时，复杂性就会逐渐增加。鉴于我们接收到的数据格式不稳定，现在很难说我们的模型对新数据是否工作良好，除非有机制来处理这种情况。
- en: Practical Machine learning examples
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实际机器学习示例
- en: In this section, let's explore some real-world machine learning applications.
    We covered various examples within the introductory section of this chapter and
    we will now cover some domain-specific examples with a brief description of each
    problem.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，让我们探索一些实际的机器学习应用。我们在本章的介绍部分涵盖了各种示例，现在我们将涵盖一些特定领域的示例，并对每个问题进行简要描述。
- en: For online and offline applications, some of the following examples can easily
    be guessed. In the chapters to follow, a subset of these examples will be picked
    to demonstrate the practical implementation aspects using suitable Machine learning
    algorithms.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在线和离线应用，以下的一些示例可以轻松猜出。在接下来的章节中，将选择这些示例的子集，以使用合适的机器学习算法展示实际实施方面的示例。
- en: '| Problem / problem Domain | Description |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 问题 / 问题域 | 描述 |'
- en: '| --- | --- |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Spam detection | The problem statement here is to identify which e-mails
    are "spam". A Machine learning algorithm can categorize an e-mail to be marked
    as spam based on some rules that it builds using some key features of e-mail data.
    Once an e-mail is marked as spam, that e-mail is then moved to the spam folder
    and the rest are left in the inbox. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 邮件垃圾检测 | 这里的问题陈述是要识别哪些电子邮件是“垃圾邮件”。一个机器学习算法可以根据它使用电子邮件数据的一些关键特征构建的规则，将电子邮件分类为垃圾邮件。一旦电子邮件被标记为垃圾邮件，该邮件就会被移动到垃圾邮件文件夹，其余的则留在收件箱中。|'
- en: '| Credit card fraud detection | This is one of the recent problems that credit
    card firms need a solution for. Based on the usage patterns of the credit card
    by the consumer and the purchase behavior of the customer, the need is to identify
    any transaction that is not potentially made by the customer and mark them as
    fraudulent for necessary action to be taken. |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 信用卡欺诈检测 | 这是信用卡公司需要解决的一个近期问题。基于消费者使用的信用卡模式和客户的购买行为，需要识别任何可能不是由客户进行的交易，并将它们标记为欺诈，以便采取必要的行动。|'
- en: '| Digit recognition | This is a very simple use case that requires the ability
    to group posts based on the zip code. This includes the need to interpret a handwritten
    numeric accurately and bucket the posts based on the zip code for faster processing.
    |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 数字识别 | 这是一个非常简单的用例，需要根据邮编对帖子进行分组的能力。这包括准确解释手写数字并根据邮编对帖子进行分类以加快处理的需求。|'
- en: '| Speech recognition | Automated call centers need this capability where a
    user''s request on the phone is interpreted and mapped to one of the tasks for
    execution. The moment the user request can be mapped to a task, its execution
    can be automated. A model of this problem will allow a program to understand and
    make an attempt to fulfill that request. The iPhone with Siri has this capability.
    |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 语音识别 | 自动呼叫中心需要这种能力，即用户的电话请求被解释并映射到执行任务之一。一旦用户请求可以映射到任务，其执行就可以自动化。这个问题的一个模型将允许程序理解并尝试满足那个请求。配备Siri的iPhone就有这种能力。|'
- en: '| Face detection | This is one of the key features that today''s social media
    websites provide. This feature provides an ability to tag a person across many
    digital photographs. This gives aptitude to a group or categorizes the photographs
    by a person. Some cameras and software such as iPhoto have this capability. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 人脸检测 | 这是今天社交媒体网站提供的关键功能之一。这个功能提供了一种在许多数字照片中标记人的能力。这为按人分组或对照片进行分类提供了能力。一些相机和软件，如iPhoto，就有这种能力。|'
- en: '| Product recommendation or customer segmentation | This capability is found
    in almost all of the top online shopping websites today. Given a purchase history
    for a customer and a large inventory of products, the idea is to identify those
    products that the customer will most likely be interested in buying, thus motivating
    more product purchases. There are many online shopping and social websites that
    support this feature (for example: Amazon, Facebook, Google+, and many others).There
    are other cases like the ability to predict whether a trial version customer opts
    for the paid version of the product. |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 产品推荐或客户细分 | 这种能力几乎存在于今天所有的顶级在线购物网站上。给定一个客户的购买历史和大量产品库存，目标是识别那些客户最有可能购买的产品，从而激励更多的产品购买。许多在线购物和社交网站支持此功能（例如：亚马逊、Facebook、Google+等）。还有其他情况，比如预测试用版客户是否会选择产品的付费版本。'
- en: '| Stock trading | This means predicting stock performance based on the current
    past stock movement. This task is critical to financial analysts and helps provide
    decision support when buying and selling stocks. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 股票交易 | 这意味着根据当前和过去的股票走势来预测股票表现。这项任务对金融分析师至关重要，并在买卖股票时提供决策支持。|'
- en: '| Sentiment analysis | Many times, we find that the customers make decisions
    based on opinions shared by others. For example, we buy a product because it has
    received positive feedback from the majority of its users. Not only in commercial
    businesses as detailed earlier, but sentiment analysis is also being used by political
    strategists to gauge public opinion on policy announcements or campaign messages.
    |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 情感分析 | 许多时候，我们发现客户是基于他人的意见做出决定的。例如，我们购买一个产品是因为它的大部分用户给出了积极的反馈。不仅如前所述的商业业务中，情感分析也被政治策略家用来衡量政策声明或竞选信息的公众舆论。|'
- en: Types of learning problems
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习问题的类型
- en: 'This section focuses on elaborating different learning problem categories.
    Machine learning algorithms are also classified under these learning problems.
    The following figure depicts various types of learning problems:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 本节重点阐述不同的学习问题类别。机器学习算法也被归类在这些学习问题中。以下图展示了各种类型的学习问题：
- en: '![Types of learning problems](img/B03980_01_07.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![学习问题的类型](img/B03980_01_07.jpg)'
- en: Classification
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类
- en: Classification is a way to identify a grouping technique for a given dataset
    in such a way that depending on a value of the target or output attribute, the
    entire dataset can be qualified to belong to a class. This technique helps in
    identifying the data behavior patterns. This is, in short, a discrimination mechanism.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是一种识别给定数据集分组技术的方法，这样根据目标或输出属性的一个值，整个数据集可以被归类为属于一个类别。这项技术有助于识别数据行为模式。简而言之，这是一种区分机制。
- en: For example, a sales manager needs help in identifying a prospective customer
    and wants to determine whether it is worth spending the effort and time the customer
    demands. The key input for the manager is the customer's data, and this case is
    commonly referred to as **Total Lifetime Value** (**TLV**).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，销售经理需要帮助识别潜在客户，并想确定是否值得花费客户要求的努力和时间。经理的关键输入是客户数据，这种情况通常被称为**总终身价值**（**TLV**）。
- en: We take the data and start plotting blindly on a graph (as shown in the following
    graph) with the *x* axis representing the total items purchased and the *y* axis
    representing the total money spent (in multiples of hundreds of dollars). Now
    we define the criteria to determine, for example, whether a customer is good or
    bad. In the following graph, all the customers who spend more than 800 dollars
    in a single purchase are categorized as good customers (note that this is a hypothetical
    example or analysis).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获取数据，开始在图表上盲目地绘制（如下面的图表所示），其中 *x* 轴代表购买的总商品数量，*y* 轴代表花费的总金额（以美元的百倍为单位）。现在我们定义标准以确定，例如，一个客户是好是坏。在下面的图表中，所有单次购买超过800美元的客户都被归类为好客户（请注意，这是一个假设的例子或分析）。
- en: '![Classification](img/B03980_01_08.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![分类](img/B03980_01_08.jpg)'
- en: Now when new customer data comes in, the sales manager can plot the new customers
    on this graph and based on which side they fall, predict whether the customer
    is likely to be good or bad.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在当新的客户数据进来时，销售经理可以将新客户绘制在这个图表上，并根据他们所在的哪一侧，预测客户是否可能成为好客户或坏客户。
- en: Tip
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Note that classification need not always be binary (yes or no, male or female,
    good or bad, and so on) and any number of classifications can be defined (poor,
    below average, average, above average, good) based on the problem definition.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，分类不一定是二元的（是或否，男或女，好或坏，等等），可以根据问题定义定义任意数量的分类（差，低于平均水平，平均水平，高于平均水平，好）。
- en: Clustering
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚类
- en: In many cases, the data analyst is just given some data and is expected to unearth
    interesting patterns that may help derive intelligence. The main difference between
    this task and that of a classification is that in the classification problem,
    the business user specifies what he/she is looking for (a good customer or a bad
    customer, a success or a failure, and so on).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，数据分析师只是被提供了一些数据，并期望他们能够挖掘出可能有助于得出情报的有趣模式。这个任务与分类任务的主要区别在于，在分类问题中，业务用户指定了他/她正在寻找的内容（一个好的客户或一个坏的客户，一个成功或一个失败，等等）。
- en: Let's now expand on the same example considered in the classification section.
    Here the patterns to classify the customers are identified without any target
    in mind or any prior classification, and unlike running a classification, the
    results may always not be the same (for example, depending on how the initial
    centroids are picked). An example modeling method for clustering is k-means clustering.
    More details on k-means clustering is covered in the next section and in detail
    in the following chapters.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来扩展在分类部分提到的相同例子。在这里，识别用于分类客户的模式时并没有考虑任何目标或先前的分类，而且与运行分类不同，结果可能并不总是相同的（例如，取决于初始质心的选择方式）。聚类的一个示例建模方法是k-means聚类。关于k-means聚类的更多细节将在下一节和后续章节中详细说明。
- en: In short, clustering is a classification analysis that does not start with a
    specific target in mind (good/bad, will buy/will not buy).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，聚类是一种分类分析，它并不以一个特定的目标为出发点（好/坏，会买/不会买）。
- en: Forecasting, prediction or regression
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测、预测或回归
- en: Similar to classification, forecasting or prediction is also about identifying
    the way things would happen in the future. This information is derived from past
    experience or knowledge. In some cases, there is not enough data, and there is
    a need to define the future through regression. Forecasting and prediction results
    are always presented along with the degree of uncertainty or probability. This
    classification of the problem type is also called **rule extraction**.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 与分类类似，预测或预测也是关于识别事物未来可能发生的方式。这种信息是从过去的经验或知识中得出的。在某些情况下，数据不足，需要通过回归来定义未来。预测和预测结果总是与不确定性的程度或概率一起呈现。这种问题类型的分类也称为**规则提取**。
- en: Let's take an example here, an agricultural scientist working on a new crop
    that she developed. As a trial, this seed was planted at various altitudes and
    the yield was computed. The requirement here is to predict the yield of the crop
    given the altitude details (and some more related data points). The relationship
    between yield gained and the altitude is determined by plotting a graph between
    the parameters. An equation is noted that fits most of the data points, and in
    cases where data does not fit the curve, we can get rid of the data. This technique
    is called regression.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举一个例子，一个农业科学家正在研究她开发的新作物。作为试验，这种种子在各个海拔高度种植，并计算了产量。这里的要求是根据海拔细节（以及一些相关的数据点）预测作物的产量。通过在参数之间绘制图表，确定了产量与海拔之间的关系。记录了一个适合大多数数据点的方程，在数据不拟合曲线的情况下，我们可以去除这些数据。这种技术被称为回归。
- en: '![Forecasting, prediction or regression](img/B03980_01_09.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![预测、预测或回归](img/B03980_01_09.jpg)'
- en: Simulation
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模拟
- en: In addition to all the techniques we defined until now, there might be situations
    where the data in context itself has many uncertainty. For example, an outsourcing
    manager is given a task and can estimate with experience that the task can be
    done by an identified team with certain skills in 2-4 hours.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们之前定义的所有技术之外，可能存在数据本身具有许多不确定性的情况。例如，一个外包经理被分配了一个任务，并且可以根据经验估计，这个任务可以由一个具有特定技能的团队在2-4小时内完成。
- en: Let's say the cost of input material may vary between $100-120 and the number
    of employees who come to work on any given day may be between 6 and 9\. An analyst
    then estimates how much time the project might take. Solving such problems requires
    the simulation of a vast amount of alternatives.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 假设输入材料的成本可能在100-120美元之间，而任何给定一天来上班的员工数量可能在6到9人之间。然后分析师估计项目可能需要多长时间。解决这类问题需要模拟大量的替代方案。
- en: Typically in forecasting, classification, and unsupervised learning, we are
    given data and we really do not know how the data is interconnected. There is
    no equation to describe one variable as a function of others.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通常在预测、分类和无监督学习中，我们被给予数据，但我们实际上并不知道数据是如何相互关联的。没有方程可以描述一个变量作为其他变量的函数。
- en: 'Essentially, data scientists combine one or more of the preceding techniques
    to solve challenging problems, which are:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，数据科学家结合使用前面提到的一种或多种技术来解决具有挑战性的问题，这些问题包括：
- en: Web search and information extraction
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络搜索和信息提取
- en: Drug design
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 药物设计
- en: Predicting capital market behavior
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测资本市场行为
- en: Understanding customer behavior
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解客户行为
- en: Designing robots
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计机器人
- en: Optimization
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化
- en: Optimization, in simple terms, is a mechanism to make something better or define
    a context for a solution that makes it the best.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，优化是一种使某事物变得更好或为解决方案定义一个使其成为最佳的上下文的机制。
- en: Considering a production scenario, let's assume there are two machines that
    produce the desired product but one machine requires more energy for high speed
    in production and lower raw materials while the other requires higher raw materials
    and less energy to produce the same output in the same time. It is important to
    understand the patterns in the output based on the variation in inputs; a combination
    that gives the highest profits would probably be the one the production manager
    would want to know. You, as an analyst, need to identify the best possible way
    to distribute the production between the machines that gives him the highest profit.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个生产场景，假设有两个机器可以生产所需的产品，但一个机器在生产高速时需要更多的能量和较少的原材料，而另一个机器则需要更多的原材料和较少的能量来在相同的时间内生产相同的输出。理解基于输入变化的输出模式非常重要；可能带来最高利润的组合可能是生产经理想要了解的。作为分析师，你需要确定在机器之间分配生产以获得最高利润的最佳方式。
- en: The following image shows the point of highest profit when a graph was plotted
    for various distribution options between the two machines. Identifying this point
    is the goal of this technique.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了在两个机器之间绘制各种分布选项的图表时，最高利润点。识别这个点是这种技术的目标。
- en: '![Optimization](img/B03980_01_10.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B03980_01_10.jpg)'
- en: Unlike the case of simulations where there is uncertainty associated with the
    input data, in optimization we not only have access to data, but also have the
    information on the dependencies and relationships between data attributes.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 与存在与输入数据相关的不确定性的模拟案例不同，在优化中，我们不仅能够访问数据，而且还有关于数据属性之间依赖关系和关系的信息。
- en: One of the key concepts in Machine learning is a process called **induction**.
    The following learning subfields use the induction process to build models. Inductive
    learning is a reasoning process that uses the results of one experiment to run
    the next set of experiments and iteratively evolve a model from specific information.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的一个关键概念是称为**归纳**的过程。以下学习子领域使用归纳过程来构建模型。归纳学习是一个推理过程，它使用一个实验的结果来运行下一组实验，并通过迭代从具体信息中演变出一个模型。
- en: The following figure depicts various subfields of Machine learning. These subfields
    are one of the ways the machine learning algorithms are classified.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 下图描述了机器学习的各个子领域。这些子领域是机器学习算法分类的方式之一。
- en: '![Optimization](img/B03980_01_11.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B03980_01_11.jpg)'
- en: Supervised learning
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督学习
- en: Supervised learning is all about operating to a known expectation and in this
    case, what needs to be analyzed from the data being defined. The input datasets
    in this context are also referred to as "labeled" datasets. Algorithms classified
    under this category focus on establishing a relationship between the input and
    output attributes, and use this relationship speculatively to generate an output
    for new input data points. In the preceding section, the example defined for the
    classification problem is also an example of supervised learning. Labeled data
    helps build reliable models but is usually expensive and limited.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习完全是关于操作到一个已知的期望，在这种情况下，需要从定义中的数据中分析什么。在这个背景下，输入数据集也被称为“标记”数据集。归类在这个类别的算法专注于建立输入和输出属性之间的关系，并使用这种关系推测性地为新的输入数据点生成输出。在前一小节中，为分类问题定义的例子也是监督学习的一个例子。标记数据有助于构建可靠的模型，但通常成本高昂且有限。
- en: When the input and output attributes of the data are known, the key in supervised
    learning is the mapping between the inputs to outputs. There are quite a few examples
    of these mappings, but the complicated function that links up the input and output
    attributes is not known. A supervised learning algorithm takes care of this linking,
    and given a large dataset of input/output pairs, these functions help predict
    the output for any new input value.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据的输入和输出属性已知时，监督学习的关键是输入到输出的映射。这些映射有很多例子，但连接输入和输出属性的复杂函数是未知的。监督学习算法负责这种连接，并且给定大量输入/输出对的大数据集，这些函数有助于预测任何新输入值的输出。
- en: Unsupervised learning
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无监督学习
- en: In some of the learning problems, we do not have any specific target in mind
    to solve. In the earlier section, we discussed clustering, which is a classification
    analyses where we do not start with a specific target in mind (good/bad, will
    buy/will not buy) and is hence referred to as unsupervised analyses or learning.
    The goal in this case is to decipher the structure in the data against the build
    mapping between input and output attributes of data and, in fact, the output attributes
    are not defined. These learning algorithms operate on an "unlabeled" dataset for
    this reason.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些学习问题中，我们并没有特定的目标来解决。在前面的小节中，我们讨论了聚类，这是一种分类分析，我们并没有带着特定的目标（好/坏，会买/不会买）开始，因此被称为无监督分析或学习。在这种情况下，目标是解码数据中的结构，与数据输入和输出属性之间的构建映射相对，实际上输出属性并未定义。这些学习算法因此在一个“未标记”的数据集上操作。
- en: Semi-supervised learning
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 半监督学习
- en: Semi-supervised learning is about using both labeled and unlabeled data to learn
    models better. It is important that there are appropriate assumptions for the
    unlabeled data and any inappropriate assumptions can invalidate the model. Semi-supervised
    learning gets its motivation from the human way of learning.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习是关于使用标记数据和未标记数据来更好地学习模型。对于未标记数据，存在适当的假设是很重要的，任何不适当的假设都可能使模型无效。半监督学习从人类的学习方式中获得其动机。
- en: Reinforcement learning
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 强化学习
- en: Reinforcement learning is learning that focuses on maximizing the rewards from
    the result. For example, while teaching toddlers new habits, rewarding them every
    time they follow instructions works very well. In fact, they figure out what behavior
    helps them earn rewards. This is reinforcement learning, and it is also called
    credit assessment learning.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是关注最大化结果奖励的学习。例如，在教导幼儿新习惯时，每次他们遵循指示就给予奖励非常有效。事实上，他们发现哪些行为有助于他们获得奖励。这是强化学习，也称为信用评估学习。
- en: The most important thing is that in reinforcement learning the model is additionally
    responsible for making decisions for which a periodic reward is received. The
    results in this case, unlike supervised learning, are not immediate and may require
    a sequence of steps to be executed before the final result is seen. Ideally, the
    algorithm will generate a sequence of decisions that helps achieve the highest
    reward or utility.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习中，模型除了负责做出决策外，还要对收到周期性奖励的决策负责。在这种情况下，结果与监督学习不同，不是立即的，可能需要执行一系列步骤才能看到最终结果。理想情况下，算法将生成一系列决策，有助于实现最高的奖励或效用。
- en: The goal in this learning technique is to measure the trade-offs effectively
    by exploring and exploiting the data. For example, when a person has to travel
    from a point A to point B, there will be many ways that include travelling by
    air, water, road or by walking, and there is significant value in considering
    this data by measuring the trade-offs for each of these options. Another important
    aspect is the significance of a delay in the rewards. How would this affect learning?
    For example, in games like chess, any delay in reward identification may change
    the result.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种学习技术中的目标是通过对数据进行探索和利用来有效地衡量权衡。例如，当一个人必须从点A到点B旅行时，会有许多方式，包括乘坐飞机、水路、公路或步行，通过衡量这些选项中的每一个的权衡来考虑这些数据具有很大的价值。另一个重要方面是奖励延迟的重要性。这会如何影响学习？例如，在象棋等游戏中，任何奖励识别的延迟都可能改变结果。
- en: Deep learning
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度学习
- en: 'Deep learning is an area of Machine learning that focuses on unifying Machine
    learning with artificial intelligence. In terms of the relationship with artificial
    neural networks, this field is more of an advancement to artificial neural networks
    that work on large amounts of common data to derive practical insights. It deals
    with building more complex neural networks to solve problems classified under
    semi-supervised learning and operates on datasets that have little labeled data.
    Some Deep learning techniques are listed as follows:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个领域，它侧重于将机器学习与人工智能统一。从与人工神经网络的关系来看，这个领域更多的是对在大量常见数据上工作的人工神经网络的进步，以得出实用的见解。它涉及构建更复杂的神经网络来解决半监督学习下的问题，并在具有少量标记数据的数据集上运行。以下列出了一些深度学习技术：
- en: Convolutional Networks
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积网络
- en: '**Restricted Boltzmann** **Machine** (**RBM**)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**受限玻尔兹曼** **机** (**RBM**)'
- en: '**Deep Belief** **Networks** (**DBN**)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度信念** **网络** (**DBN**)'
- en: Stacked Autoencoders
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆叠自编码器
- en: Performance measures
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能度量
- en: Performance measures are used to evaluate learning algorithms and form an important
    aspect of machine learning. In some cases, these measures are also used as heuristics
    to build learning models.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 性能度量用于评估学习算法，并形成机器学习的一个重要方面。在某些情况下，这些度量也用作启发式方法来构建学习模型。
- en: 'Now let''s explore the concept of the **Probably Approximately Correct** (**PAC**)
    theory. While we describe the accuracy of hypothesis, we usually talk about two
    types of uncertainties as per the PAC theory:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们探讨**可能近似正确**（**PAC**）理论的概念。当我们描述假设的准确性时，我们通常根据PAC理论谈论两种类型的不确定性：
- en: '**Approximate**: This measures the extent to which an error is accepted for
    a hypothesis'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**近似**: 这个度量表示对假设错误的接受程度'
- en: '**Probability**: This measure is the percentage certainty of the hypothesis
    being correct'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概率**: 这个度量是假设正确的百分比确定性'
- en: 'The following graph shows how the number of samples grow with error, probability,
    and hypothesis:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了样本数量随错误、概率和假设增长的情况：
- en: '![Performance measures](img/B03980_01_12.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![性能度量](img/B03980_01_12.jpg)'
- en: Is the solution good?
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案好吗？
- en: The error measures for a classification and prediction problem are different.
    In this section, we will cover some of these error measures followed by how they
    can be addressed.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 分类和预测问题的错误度量是不同的。在本节中，我们将介绍一些这些错误度量，然后介绍如何解决它们。
- en: In a classification problem, you can have two different types of errors, which
    can be elegantly represented using the "confusion matrix". Let's say in our target
    marketing problem, we work on 10,000 customer records to predict which customers
    are likely to respond to our marketing effort.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类问题中，你可以有两种不同类型的错误，这些错误可以用“混淆矩阵”优雅地表示。假设在我们的目标营销问题中，我们处理了10,000个客户记录，以预测哪些客户可能对我们的营销活动做出响应。
- en: 'After analyzing the campaign, you can construct the following table, where
    the columns are your predictions and the rows are the real observations:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析活动后，你可以构建以下表格，其中列是你的预测，行是实际观察：
- en: '| Action | Predicted (that there will be a buy) | Predicted (that there will
    be no buy) |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 行动 | 预测（将有购买） | 预测（将没有购买） |'
- en: '| --- | --- | --- |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Actually bought | TP: 500 | FN: 400 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 实际购买 | TP: 500 | FN: 400 |'
- en: '| Actually did not buy | FP: 100 | TN: 9000 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '实际未购买 | FP: 100 | TN: 9000 |'
- en: In the principal diagonal, we have buyers and non-buyers for whom the prediction
    matched with reality. These are correct predictions. They are called true positive
    and true negative respectively. In the upper right-hand side, we have those who
    we predicted are non-buyers, but in reality are buyers. This is an error known
    as a false negative error. In the lower left-hand side, we have those we predicted
    as buyers, but are non-buyers. This is another error known as false positive.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在主对角线上，我们有买家和非买家，他们的预测与实际情况相符。这些都是正确的预测。它们分别被称为真阳性（true positive）和真阴性（true negative）。在上右角，我们有那些我们预测为非买家，但实际上是买家的人。这是一个被称为假阴性错误（false
    negative error）的错误。在下左角，我们有那些我们预测为买家，但实际上是非买家的人。这是另一个被称为假阳性（false positive）的错误。
- en: Are both errors equally expensive for the customers? Actually no! If we predict
    that someone is a buyer and they turn out to be a non-buyer, the company at most
    would have lost money spent on a mail or a call. However, if we predicted that
    someone would not buy and they were in fact buyers, the company would not have
    called them based on this prediction and lost a customer. So, in this case, a
    false negative is much more expensive than a false positive error.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 对于客户来说，两种错误同样昂贵吗？实际上并非如此！如果我们预测某人是买家，而他们实际上不是买家，公司最多只会损失在邮件或电话上的开支。然而，如果我们预测某人不会购买，而他们实际上确实是买家，公司就不会基于这个预测给他们打电话，从而失去了一位客户。因此，在这种情况下，假阴性错误比假阳性错误要昂贵得多。
- en: 'The Machine learning community uses three different error measures for classification
    problems:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习社区在分类问题中使用三种不同的错误度量：
- en: '**Measure 1: Accuracy** is the percent of predictions that were correct.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**度量1：准确率**是指正确预测的百分比。'
- en: 'Example: The "accuracy" was (9,000+500) out of 10,000 = 95%'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例：准确率为（9,000+500）/ 10,000 = 95%
- en: '**Measure 2: Recall** is the percent of positives cases that you were able
    to catch. If false positives are low, recall will be high.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**度量2：召回率**是指你能够捕捉到的阳性病例的百分比。如果假阳性率低，召回率就会高。'
- en: 'Example: The "recall" was 500 out of 600 = 83.33%'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例：召回率为500/600 = 83.33%
- en: '**Measure 3: Precision** is the percent of positive predictions that were correct.
    If false negatives are low, precision is high.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**度量3：精确度**是指正确预测的阳性预测的百分比。如果假阴性率低，精确度就会高。'
- en: 'Example: The "precision" was 500 out of 900 = 55.55%'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 示例：精确率为500/900 = 55.55%
- en: In forecasting, you are predicting a continuous variable. So, the error measures
    are fairly different here. As usual, the error metrics are obtained by comparing
    the predictions of the models with the real values of the target variables and
    calculating the average error. Here are a few metrics.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测中，你是在预测一个连续变量。因此，这里的错误度量相当不同。通常，错误度量是通过比较模型的预测值与目标变量的真实值，并计算平均误差来获得的。这里有一些度量。
- en: Mean squared error (MSE)
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 均方误差 (MSE)
- en: 'To compute the MSE, we first take the square of the difference between the
    actual and predicted values of every record. We then take the average value of
    these squared errors. If the predicted value of the *i^(th)* record is *Pi* and
    the actual value is *Ai*, then the MSE is:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算MSE，我们首先取每个记录实际值与预测值之间差值的平方。然后我们取这些平方误差的平均值。如果第*i*个记录的预测值是*Pi*，实际值是*Ai*，那么MSE是：
- en: '![Mean squared error (MSE)](img/B03980_01_18.jpg)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![均方误差 (MSE)](img/B03980_01_18.jpg)'
- en: It is also common to use the square root of this quantity called **root mean
    square error** (**RMSE**).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个数量（称为**均方根误差**）的平方根也是很常见的。
- en: Mean absolute error (MAE)
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 均方误差 (MAE)
- en: To compute the MAE, we take the absolute difference between the predicted and
    actual values of every record. We then take the average of those absolute differences.
    The choice of performance metric depends on the application. The MSE is a good
    performance metric for many applications as it has more statistical grounding
    with variance. On the other hand, the MAE is more intuitive and less sensitive
    to outliers. Looking at the MAE and RMSE gives us additional information about
    the distribution of the errors. In regression, if the RMSE is close to the MAE,
    the model makes many relatively small errors. If the RMSE is close to the MAE2,
    the model makes a few but large errors.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算MAE，我们取每个记录预测值与实际值之间的绝对差值。然后我们取这些绝对差值的平均值。性能指标的选择取决于应用。MSE是许多应用的优秀性能指标，因为它与方差有更多的统计基础。另一方面，MAE更直观，对异常值不太敏感。观察MAE和RMSE可以给我们关于误差分布的额外信息。在回归中，如果RMSE接近MAE，则模型会犯许多相对较小的错误。如果RMSE接近MAE^2，则模型会犯一些但较大的错误。
- en: '![Mean absolute error (MAE)](img/B03980_01_19.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![平均绝对误差（MAE）](img/B03980_01_19.jpg)'
- en: Normalized MSE and MAE (NMSE and NMAE)
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 归一化均方误差和平均绝对误差（NMSE和NMAE）
- en: Both the MSE and MAE do not indicate how big the error is as they are numeric
    values depending on the scale of the target variable. Comparing with a benchmarking
    index provides a better insight. The common practice is to take the mean of the
    primary attribute we are predicting and assume that our naïve prediction model
    is just the mean. Then we compute the MSE based on the naïve model and the original
    model. The ratio provides an insight into how good or bad our model is compared
    to the naïve model.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: MSE和MAE都不表示误差有多大，因为它们是依赖于目标变量尺度的数值。与基准指数比较可以提供更好的洞察。常见的做法是取我们预测的主要属性的均值，并假设我们的朴素预测模型就是均值。然后我们根据朴素模型和原始模型计算MSE。这个比率可以提供关于我们的模型与朴素模型相比是好是坏的洞察。
- en: '![Normalized MSE and MAE (NMSE and NMAE)](img/B03980_01_20.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![归一化均方误差和平均绝对误差（NMSE和NMAE）](img/B03980_01_20.jpg)'
- en: A similar definition can also be used for the MAE.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 类似的定义也可以用于MAE。
- en: 'Solving the errors: bias and variance'
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决误差：偏差和方差
- en: This trap of building highly customized higher order models is called over-fitting
    and is a critical concept. The resulting error is known as the **variance** of
    the model. Essentially, if we had taken a different training set, we would have
    obtained a very different model. Variance is a measure of the dependency of model
    on the training set. By the way, the model you see on the right most side (linear
    fit) is called under-fitting and the error caused due to under-fitting is called
    bias. In an under-fitting or high bias situation, the model does not explain the
    relationship between the data. Essentially, we're trying to fit an overly simplistic
    hypothesis, for example, linear where we should be looking for a higher order
    polynomial.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这种构建高度定制化高阶模型的陷阱被称为过拟合，这是一个关键概念。由此产生的错误被称为模型的**方差**。本质上，如果我们采用了不同的训练集，我们将得到一个非常不同的模型。方差是衡量模型对训练集依赖性的一个指标。顺便说一句，你看到的最右侧（线性拟合）的模型被称为欠拟合，由于欠拟合而产生的错误被称为偏差。在欠拟合或高偏差的情况下，模型无法解释数据之间的关系。本质上，我们试图拟合一个过于简单的假设，例如，线性拟合，而我们应该寻找更高阶的多项式。
- en: To avoid the trap of over-fitting and under-fitting, data scientists build the
    model on a training set and then find the error on a test set. They refine the
    model until the error in the test set comes down. As the model starts getting
    customized to the training data, the error on the test set starts going up. They
    stop refining the model after that point.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免过拟合和欠拟合的陷阱，数据科学家在训练集上构建模型，然后在测试集上找到误差。他们不断优化模型，直到测试集上的误差降低。随着模型开始定制于训练数据，测试集上的误差开始上升。他们在那个点停止优化模型。
- en: 'Let''s analyze bias and variance a bit more in this chapter and learn a few
    practical ways of dealing with them. The error in any model can be represented
    as a combination of bias, variance, and random error. With *Err(x)=Bias2+Variance+Irreducible
    Error* in less complex models, the bias term is high, and in models with higher
    complexity, the variance term is high, as shown in the following figure:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在本章中更深入地分析偏差和方差，并学习一些处理它们的实用方法。任何模型的误差都可以表示为偏差、方差和随机误差的组合。在较简单的模型中，偏差项较高，而在更复杂的模型中，方差项较高，如下面的图所示：
- en: '![Solving the errors: bias and variance](img/B03980_01_13.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![解决误差：偏差和方差](img/B03980_01_13.jpg)'
- en: To reduce bias or variance, let's first ask this question. If a model has a
    high bias, how does its error vary as a function of the amount of data?
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少偏差或方差，让我们先问这个问题。如果一个模型有高偏差，它的误差如何随着数据量的增加而变化？
- en: At a very low data size, any model can fit the data well (any model fits a single
    point, any linear model can fit two points, a quadratic can fit three points,
    and so on). So, the error of a high bias model on a training set starts minuscule
    and goes up with increasing data points. However, on the test set, the error remains
    high initially as the model is highly customized to the training set. As the model
    gets more and more refined, the error reduces and becomes equal to that of the
    training set.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在非常小的数据量下，任何模型都可以很好地拟合数据（任何模型都可以拟合一个点，任何线性模型都可以拟合两个点，二次函数可以拟合三个点，依此类推）。因此，高偏差模型在训练集上的误差开始时非常小，随着数据点的增加而增加。然而，在测试集上，误差最初保持较高，因为模型高度定制于训练集。随着模型越来越精细，误差减少并等于训练集的误差。
- en: 'The following graph depicts the situation clearly:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表清楚地描述了这种情况：
- en: '![Solving the errors: bias and variance](img/B03980_01_14.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![解决错误：偏差和方差](img/B03980_01_14.jpg)'
- en: 'The remedy for this situation could be one of the following:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这种情况的方法可能包括以下之一：
- en: Most likely, you are working with very few features, so you must find more features
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很可能你正在处理非常少的特征，因此你必须找到更多特征
- en: Increase the complexity of the model by increasing polynomials and depth
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过增加多项式和深度来增加模型的复杂性
- en: Increasing the data size will not be of much help if the model has a high bias
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果模型有很高的偏差，增加数据量将不会有很大帮助
- en: '![Solving the errors: bias and variance](img/B03980_01_15.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![解决错误：偏差和方差](img/B03980_01_15.jpg)'
- en: 'When you face such situations, you can try the following remedies (the reverse
    of the previous ones):'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 当你面临这种情况时，你可以尝试以下补救措施（与之前的相反）：
- en: Most likely, you are working with too many features, so, you must reduce the
    features
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很可能你正在处理太多的特征，因此你必须减少特征数量
- en: Decrease the complexity of the model
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少模型的复杂性
- en: Increasing the data size will be some help
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加数据量将有所帮助
- en: Some complementing fields of Machine learning
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一些补充的机器学习领域
- en: Machine learning has a close relationship to many related fields including artificial
    intelligence, data mining, statistics, data science, and others listed shortly.
    In fact, Machine learning is in that way a multi-disciplinary field, and in some
    ways is linked to all of these fields.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习与许多相关领域密切相关，包括人工智能、数据挖掘、统计学、数据科学等。实际上，机器学习是一种多学科领域，并且在某些方面与所有这些领域都有联系。
- en: In this section, we will define some of these fields, draw parallels to how
    they correlate to Machine learning, and understand the similarities and dissimilarities,
    if any. Overall, we will start with the core Machine learning definition as a
    field of science that includes developing self-learning algorithms. Most of the
    fields we are going to discuss now either use machine learning techniques or a
    superset or subset of machine learning techniques.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将定义一些这些领域，将它们与机器学习的相关性进行类比，并了解它们之间的相似之处和不同之处。总体而言，我们将从机器学习的核心定义开始，将其作为一个包括开发自学习算法的科学领域。我们现在将要讨论的大多数领域要么使用机器学习技术，要么使用机器学习技术的超集或子集。
- en: Data mining
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据挖掘
- en: Data mining is a process of analyzing data and deriving insights from a (large)
    dataset by applying business rules to it. The focus here is on the data and the
    domain of the data. Machine learning techniques are adopted in the process of
    identifying which rules are relevant and which aren't.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 数据挖掘是一个通过应用业务规则到（大量）数据集中，分析数据并从中提取洞察的过程。这里的重点是数据和数据的领域。在识别哪些规则相关、哪些不相关的过程中采用了机器学习技术。
- en: '| Machine learning versus Data mining |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习与数据挖掘 |'
- en: '| --- |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| **Similarities with Machine learning** | **Dissimilarities with Machine learning**
    | **Relationship with Machine learning** |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| **与机器学习的相似之处** | **与机器学习的不同之处** | **与机器学习的关系** |'
- en: '| Both Machine learning and data mining look at data with the goal of extracting
    value from it.Most of the tools used for Machine learning and data mining are
    common. For example, R and Weka among others. | While Machine learning focuses
    on using known knowledge or experience, data mining focuses on discovering unknown
    knowledge, like the existence of a specific structure in data that will be of
    help in analyzing the data.Intelligence derived is meant to be consumed by machines
    in Machine learning compared to data mining where the target consumers are humans.
    | The fields of Machine learning and data mining are intertwined, and there is
    a significant overlap in the underlying principles and methodologies. |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习和数据挖掘都旨在从数据中提取价值。用于机器学习和数据挖掘的大多数工具都是通用的。例如，R 和 Weka 等。 | 虽然机器学习侧重于使用已知的知识或经验，而数据挖掘侧重于发现未知的知识，如数据中存在的特定结构，这有助于分析数据。在机器学习中，从数据中提取的智能旨在由机器消费，而在数据挖掘中，目标消费者是人类。
    | 机器学习和数据挖掘领域相互交织，在基本原理和方法上存在显著的重叠。 |'
- en: Artificial intelligence (AI)
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能 (AI)
- en: 'Artificial intelligence focuses on building systems that can mimic human behavior.
    It has been around for a while now and the modern AI has been continuously evolving,
    now includes specialized data requirements. Among many other capabilities, AI
    should demonstrate the following:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能专注于构建能够模仿人类行为的系统。它已经存在了一段时间，现代人工智能一直在持续发展，现在包括专门的数据需求。在许多其他能力中，人工智能应该展示以下特点：
- en: Knowledge storage and representation to hold all the data that is subject to
    interrogation and investigation
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知识存储和表示，以保存所有受调查和调查的数据
- en: '**Natural Language Processing** (**NLP**) capabilities to be able to process
    text'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言处理**（**NLP**）能力，以便能够处理文本'
- en: Reasoning capabilities to be able to answer questions and facilitate conclusions
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推理能力，以便能够回答问题和促进结论
- en: The ability to plan, schedule, and automate
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够规划、调度和自动化
- en: Machine learning to be able to build self-learning algorithms
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习，以便能够构建自学习算法
- en: Robotics and more
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人和更多
- en: Machine learning is a subfield of artificial intelligence.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是人工智能的一个子领域。
- en: '| Machine learning versus Artificial Intelligence |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习与人工智能比较 |'
- en: '| --- |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| **Similarities with Machine learning** | **Dissimilarities with Machine learning**
    | **Relationship with Machine learning** |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| **与机器学习的相似之处** | **与机器学习的不同之处** | **与机器学习的关系** |'
- en: '| Both machine learning and artificial intelligence employ learning algorithms
    and focus on automation when reasoning or decision-making. | Though Machine learning
    is considered to be in the AI''s range of interests, Machine learning''s primary
    focus is to improve on a machine''s performance of a task, and the experience
    built need not always be human behavior. In the case of artificial intelligence,
    human inspired algorithms are employed. | Machine learning is often considered
    as a subfield of artificial intelligence. |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习和人工智能都采用学习算法，在推理或决策时侧重于自动化。 | 虽然机器学习被认为是人工智能兴趣范围内的一个领域，但机器学习的主要重点是提高机器在执行任务时的性能，并且构建的经验不一定是人类行为。在人工智能的情况下，采用受人类启发的算法。
    | 机器学习通常被认为是人工智能的一个子领域。 |'
- en: Statistical learning
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统计学习
- en: In statistical learning, the predictive functions are arrived at and primarily
    derived from samples of data. It is of great importance how the data is collected,
    cleansed, and managed in this process. Statistics is pretty close to mathematics,
    as it is about quantifying data and operating on numbers.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学习中，预测函数是通过数据样本得出的，并且主要来源于样本数据。在这个过程中，数据的收集、清洗和管理非常重要。统计学与数学非常接近，因为它涉及数据的量化和对数字的操作。
- en: '| Machine learning versus Statistical learning |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习与统计学习比较 |'
- en: '| --- |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| **Similarities with Machine learning** | **Dissimilarities with Machine learning**
    | **Relationship with Machine learning** |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| **与机器学习的相似之处** | **与机器学习的不同之处** | **与机器学习的关系** |'
- en: '| Just like Machine learning, statistical learning is also about building the
    ability to infer from the data that in some cases represents experience. | Statistical
    learning focuses on coming up with valid conclusions while Machine learning is
    about predictions. Statistical learning works on and allows assumptions as against
    Machine learning. Machine learning and statistics are practiced by different groups.
    Machine learning is a relatively new field when compared to statistics. | The
    Machine learning technology implements statistical techniques. |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 就像机器学习一样，统计学习也是关于从数据中推断出某些情况下代表经验的能力。 | 统计学习侧重于得出有效的结论，而机器学习则是关于预测。统计学习在数据和允许假设方面与机器学习不同。机器学习和统计学由不同的群体实践。与统计学相比，机器学习是一个相对较新的领域。
    | 机器学习技术实现了统计技术。 |'
- en: Data science
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学
- en: Data science is all about turning data into products. It is analytics and machine
    learning put into action to draw inferences and insights out of data. Data science
    is perceived to be a first step from traditional data analysis and knowledge systems,
    such as **Data Warehouses** (**DW**) and **Business Intelligence** (**BI**), which
    considers all aspects of big data.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学是将数据转化为产品的过程。它是将分析学和机器学习付诸实践，从数据中得出推论和见解。数据科学被认为是从传统的数据分析知识系统，如**数据仓库**（**DW**）和**商业智能**（**BI**），到大数据的各个方面的一个第一步，这些系统考虑了大数据的所有方面。
- en: The data science lifecycle includes steps from data availability/loading to
    deriving and communicating data insights up to operationalizing the process, and
    Machine learning often forms a subset of this process.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学生命周期包括从数据可用性/加载到推导和传达数据洞察，直至将过程投入运营的步骤，而机器学习通常是这个过程中的一个子集。
- en: '| Machine learning versus Data science |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习与数据科学 |'
- en: '| --- |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| **Similarities with Machine learning** | **Dissimilarities with Machine learning**
    | **Relationship with Machine learning** |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| **与机器学习的相似之处** | **与机器学习的不同之处** | **与机器学习的关系** |'
- en: '| Machine learning and data science have prediction as a common binding outcome
    given the problem''s context. | One of the important differences between Machine
    learning and data science is the need for domain expertise. Data science focuses
    on solving domain-specific problems, while Machine learning focuses on building
    models that can generically fit a problem context. | Data science is a superset
    of Machine learning, data mining, and related subjects. It extensively covers
    the complete process starting from data loading until production. |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| 机器学习和数据科学在问题背景下有一个共同的绑定结果：预测。 | 机器学习和数据科学之间的重要区别是需要领域专业知识。数据科学专注于解决特定领域的问题，而机器学习专注于构建可以通用地适应问题背景的模型。
    | 数据科学是机器学习、数据挖掘和相关学科的集合。它广泛涵盖了从数据加载到生产的完整过程。 |'
- en: Machine learning process lifecycle and solution architecture
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习过程生命周期和解决方案架构
- en: 'In this section, we will discuss the machine learning implementation process
    and solution architecture:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论机器学习实现过程和解决方案架构：
- en: The first step toward defining the solution architecture is defining the problem
    statement, which includes defining the goal, process, and assumptions.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义解决方案架构的第一步是定义问题陈述，这包括定义目标、过程和假设。
- en: Determine what problem type is this problem classified under? Whether it is
    a classification, regression, or optimization problem?
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定这个问题属于哪种问题类型？是分类、回归还是优化问题？
- en: Choose a metric that will be used to measure the accuracy of the model.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个将用于衡量模型准确性的指标。
- en: 'In order to ensure the model works well with the unseen data:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了确保模型能够很好地处理未见过的数据：
- en: Build the model using training data.
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练数据构建模型。
- en: Tweak the model using test data.
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用测试数据调整模型。
- en: Declare an accuracy based on the final version.
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据最终版本声明准确性。
- en: 'The following figure explains the flow and architecture of the underlying system:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图解释了底层系统的流程和架构：
- en: '![Machine learning process lifecycle and solution architecture](img/B03980_01_16.jpg)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习过程生命周期和解决方案架构](img/B03980_01_16.jpg)'
- en: Machine learning algorithms
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习算法
- en: Now, let's look at the important machine learning algorithms and some brief
    details about each of them. In-depth implementation aspects for each of the algorithms
    will be covered in later chapters. These algorithms are either classified under
    the problem type or the learning type. There is a simple classification of the
    algorithms given but it is intuitive and not necessarily exhaustive.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看重要的机器学习算法以及关于每个算法的一些简要细节。每个算法的深入实现方面将在后面的章节中介绍。这些算法要么根据问题类型，要么根据学习类型进行分类。给出了算法的简单分类，但它是直观的，并不一定是详尽的。
- en: 'There are many ways of classifying or grouping machine learning algorithms,
    and in this book we will use the learning model based grouping. In each chapter,
    starting from [Chapter 5](ch05.html "Chapter 5. Decision Tree based learning"),
    *Decision Tree based learning*, we will cover one or more learning models and
    associated algorithms. The following concept model depicts a listing of learning
    models:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以对机器学习算法进行分类或分组，在这本书中，我们将使用基于学习模型的分组方法。从第[第5章](ch05.html "第5章. 基于决策树的学习")开始，我们将涵盖一个或多个学习模型及其相关算法。以下的概念模型描述了学习模型的列表：
- en: '![Machine learning algorithms](img/B03980_01_17.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习算法](img/B03980_01_17.jpg)'
- en: Decision tree based algorithms
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于决策树的算法
- en: 'Decision tree based algorithms define models that are iteratively or recursively
    constructed based on the data provided. The goal of Decision tree based algorithms
    is to predict the value of a target variable given a set of input variables. Decision
    trees help solve classification and regression problems using tree based methods.
    Decisions fork in tree structures until a prediction decision is made for a given
    record. Some of the algorithms are as follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 基于决策树的算法定义了基于提供的数据迭代或递归构建的模型。基于决策树的算法的目标是在给定一组输入变量的情况下预测目标变量的值。决策树通过基于树的方法帮助解决分类和回归问题。在树结构中，决策分支直到对给定记录做出预测决策。以下是一些算法：
- en: Random forest
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: '**Classification and** **Regression Tree** (**CART**)'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类和** **回归树**（**CART**）'
- en: C4.5 and C5.0
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C4.5 和 C5.0
- en: Chi-square
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卡方检验
- en: '**Gradient** **boosting machines** (**GBM**)'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度** **提升机**（**GBM**）'
- en: '**Chi-Squared Automatic** **Interaction** **Detection** (**CHAID**)'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卡方自动** **交互** **检测**（**CHAID**）'
- en: Decision stump
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: '**Multivariate adaptive** **regression splines** (**MARS**)'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多元自适应** **回归样条**（**MARS**）'
- en: Bayesian method based algorithms
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于贝叶斯方法的算法
- en: 'Bayesian methods are those that explicitly apply the Bayesian inference theorem
    and again solve classification and regression problems. Bayesian methods facilitate
    subjective probability in modeling. The following are some of the Bayesian based
    algorithms:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯方法是那些明确应用贝叶斯推理定理并再次解决分类和回归问题的方法。贝叶斯方法促进了建模中的主观概率。以下是一些基于贝叶斯的算法：
- en: Naïve Bayes
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单贝叶斯
- en: '**Averaged one-dependence** **estimators** (**AODE**)'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均** **一依赖** **估计器**（**AODE**）'
- en: '**Bayesian belief** **network** (**BBN**)'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯信念** **网络**（**BBN**）'
- en: Kernel method based algorithms
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于核方法的算法
- en: 'When we hear about kernel methods, the first thing that comes to mind is **Support
    Vector Machines** (**SVM**). These methods are usually a group of methods in themselves.
    kernel methods are concerned with pattern analysis and as explained in the preceding
    sections, that crux of pattern analysis includes various mapping techniques. Here,
    the mapping datasets include vector spaces. Some examples of kernel method based
    learning algorithms are listed as follows:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们听到核方法时，首先想到的是**支持向量机**（**SVM**）。这些方法通常是一组方法本身。核方法关注模式分析，正如前几节所解释的，模式分析的核心包括各种映射技术。在这里，映射数据集包括向量空间。以下是一些基于核方法的学习算法的例子：
- en: SVM
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）
- en: '**Linear discriminant analysis** (**LDA**)'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性判别分析**（**LDA**）'
- en: Clustering methods
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚类方法
- en: 'Clustering, like regression, describes a class of problems and a class of methods.
    Clustering methods are typically organized by the modeling approaches such as
    centroid-based and hierarchical. These methods organize data into groups by assessing
    the similarity in the structure of input data:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类，就像回归一样，描述了一类问题和一类方法。聚类方法通常按建模方法组织，如基于质心的和层次化的。这些方法通过评估输入数据结构中的相似性来组织数据成组：
- en: K-means
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K-均值
- en: '**Expectation** **maximization** (**EM**) and **Gaussian** **mixture models**
    (**GMM**)'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**期望** **最大化**（**EM**）和**高斯** **混合模型**（**GMM**）'
- en: Artificial neural networks (ANN)
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工神经网络（ANN）
- en: Similar to kernel methods, artificial neural networks are again a class of pattern
    matching techniques, but these models are inspired by the structure of biological
    neural networks. These methods are again used to solve classifications and regression
    problems. They relate to Deep learning modeling and have many subfields of algorithms
    that help solve specific problems in context.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 与核方法类似，人工神经网络再次成为一类模式匹配技术，但这些模型是受生物神经网络结构的启发。这些方法再次用于解决分类和回归问题。它们与深度学习建模相关，并且有许多子算法领域，有助于解决特定上下文中的问题。
- en: 'Some of the methods in this category include:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类别中的一些方法包括：
- en: '**Learning** **vector** **quantization** (**LVQ**)'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习** **向量** **量化**（**LVQ**）'
- en: '**Self-organizing** **maps** (**SOM**)'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自组织** **映射**（**SOM**）'
- en: Hopfield network
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跳频网络
- en: Perceptron
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 感知机
- en: Backpropagation
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反向传播
- en: Dimensionality reduction
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维度约简
- en: 'Like clustering methods, dimensionality reduction methods work iteratively
    and on the data structure in an unsupervised manner. Given the dataset and the
    dimensions, more dimensions would mean more work in the Machine learning implementation.
    The idea is to iteratively reduce the dimensions and bring more relevant dimensions
    forward. This technique is usually used to simplify high-dimensional data and
    then apply a supervised learning technique. Some example dimensionality reduction
    methods are listed as follows:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 与聚类方法一样，降维方法以迭代和无监督的方式在数据结构上工作。给定数据集和维度，更多的维度意味着在机器学习实现中需要做更多的工作。想法是迭代地减少维度，并将更多相关的维度向前推进。这种技术通常用于简化高维数据，然后应用监督学习技术。以下是一些降维方法的示例：
- en: '**Multidimensional** **scaling** (**MDS**)'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多维** **尺度** （**MDS**）'
- en: '**Principal component** **analysis** (**PCA**)'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主成分** **分析** （**PCA**）'
- en: '**Projection** **pursuit** (**PP**)'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**投影** **追踪** （**PP**）'
- en: '**Partial least** **squares** (**PLS**) regression'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏最小** **二乘** （**PLS**） 回归'
- en: Sammon mapping
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sammon映射
- en: Ensemble methods
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成方法
- en: 'As the name suggests, ensemble methods encompass multiple models that are built
    independently and the results of these models are combined and responsible for
    overall predictions. It is critical to identify what independent models are to
    be combined or included, how the results need to be combined, and in what way
    to achieve the required result. The subset of models that are combined is sometimes
    referred to as weaker models as the results of these models need not completely
    fulfill the expected outcome in isolation. This is a very powerful and widely
    adopted class of techniques. The following are some of the Ensemble method algorithms:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，集成方法包括多个独立构建的模型，这些模型的输出被组合并负责整体预测。确定要组合或包含哪些独立模型，如何组合结果以及如何实现所需结果的方式是至关重要的。组合的模型子集有时被称为较弱模型，因为这些模型的结果在独立情况下不需要完全满足预期结果。这是一类非常强大且广泛采用的技术。以下是一些集成方法算法的示例：
- en: Random forest
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: Bagging
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bagging
- en: AdaBoost
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AdaBoost
- en: Bootstrapped Aggregation (Boosting)
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自举聚合（Boosting）
- en: Stacked generalization (blending)
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆叠泛化（blending）
- en: '**Gradient** **boosting machines** (**GBM**)'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度** **提升机** （**GBM**）'
- en: Instance based learning algorithms
  id: totrans-339
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于实例的学习算法
- en: 'Instances are nothing but subsets of datasets, and instance based learning
    models work on an identified instance or groups of instances that are critical
    to the problem. The results across instances are compared, which can include an
    instance of new data as well. This comparison uses a particular similarity measure
    to find the best match and predict. Instance based methods are also called case-based
    or memory-based learning. Here the focus is on the representation of the instances
    and similarity measures for comparison between instances. Some of the instance
    based learning algorithms are listed as follows:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 实例不过是数据集的子集，基于实例的学习模型在识别的实例或对问题至关重要的实例组上工作。实例之间的结果会被比较，这可以包括新数据的一个实例。这种比较使用特定的相似度度量来找到最佳匹配并进行预测。基于实例的方法也被称为基于案例或基于记忆的学习。在这里，重点是实例的表示和实例之间比较的相似度度量。以下是一些基于实例的学习算法的示例：
- en: '**k-Nearest** **Neighbour** (**k-NN**)'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**k-最近** **邻** （**k-NN**）'
- en: Self-Organizing
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自组织
- en: '**Learning** **vector** **quantization** (**LVQ**)'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习** **向量** **量化** （**LVQ**）'
- en: '**Self-organizing** **maps** (**SOM**)'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自组织** **映射** （**SOM**）'
- en: Regression analysis based algorithms
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于回归分析的算法
- en: 'Regression is a process of refining the model iteratively based on the error
    generated by the model. Regression also is used to define a machine learning problem
    type. Some example algorithms in regression are:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是一个基于模型产生的误差进行迭代优化的过程。回归也被用来定义机器学习问题类型。回归中的一些示例算法包括：
- en: Ordinary least squares linear regression
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 普通最小二乘线性回归
- en: Logistic regression
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: '**Multivariate adaptive regression splines** (**MARS**)'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多元自适应回归样条** （**MARS**）'
- en: Stepwise regression
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步进回归
- en: Association rule based learning algorithms
  id: totrans-351
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于关联规则的机器学习算法
- en: 'Given the variables, association rule based learning algorithms extract and
    define rules that can be applied on a dataset and demonstrate experienced-based
    learning, and thus prediction. These rules when associated in a multi-dimensional
    data context can be useful in a commercial context as well. Some of the examples
    of Association rule based algorithms are given as follows:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到变量，基于关联规则的机器学习算法提取并定义可以在数据集上应用并展示基于经验学习的规则，从而进行预测。这些规则在多维数据环境中关联时，在商业环境中也可能很有用。以下是一些基于关联规则的算法示例：
- en: The Apriori algorithm
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apriori算法
- en: The Eclat algorithm
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eclat算法
- en: Machine learning tools and frameworks
  id: totrans-355
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习工具和框架
- en: Machine learning adoption is rapidly increasing among technology and business
    organizations. Every organization is actively strategizing on how to capitalize
    on their data and use it to augment their client's experiences and build new businesses.
    When it comes to tools or frameworks for Machine learning, there are many open
    source and commercial options on the market. The new age tools are all built to
    support big data, distributed storage, and parallel processing. In the next chapter,
    we will cover some aspects of handling large scale data in the context of Machine
    learning.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习在技术和商业组织中迅速普及。每个组织都在积极制定战略，以利用他们的数据，并利用它来增强客户的体验和建立新的业务。当涉及到机器学习的工具或框架时，市场上有很多开源和商业选项。新一代的工具都是构建来支持大数据、分布式存储和并行处理的。在下一章中，我们将介绍机器学习环境中处理大规模数据的一些方面。
- en: At a very high level, there are three generations of Machine learning tools.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在非常高的层面上，机器学习工具有三代。
- en: The first generation of Machine learning tools is focused on providing a richness
    of the Machine learning algorithms and supporting deep analytics. These tools
    haven't been built to focus on handling large scale data or for supporting distributed
    storage and parallel processing. Some of them still handle volumes as a result
    of their support for vertical scalability. Some of the tools that come under this
    category are SAS, SPSS, Weka, R, and more. Having said that, most of these tools
    are now being upgraded to support big data requirements too.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 第一代机器学习工具主要关注提供丰富的机器学习算法和深度分析支持。这些工具并非专为处理大规模数据或支持分布式存储和并行处理而构建。其中一些工具由于支持垂直扩展，仍然可以处理大量数据。属于这一类别的工具包括SAS、SPSS、Weka、R等。尽管如此，现在大多数这些工具都在升级以支持大数据需求。
- en: The second generation tools are focused on supporting big data requirements,
    most of them work on the Hadoop platform, and they provide capabilities to run
    machine learning algorithms in a MapReduce paradigm. Some of the tools that are
    categorized here are Mahout, RapidMiner, Pentaho, and MADlib. Some of these tools
    do not support all the machine learning algorithms.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 第二代工具专注于支持大数据需求，其中大多数在Hadoop平台上运行，并提供在MapReduce范式下运行机器学习算法的能力。属于这一类别的工具包括Mahout、RapidMiner、Pentaho和MADlib。其中一些工具不支持所有机器学习算法。
- en: The third generations tools are the smart kids on the road, breaking the traditional
    norms of operating in batch mode, supporting real-time analytics, providing support
    for advanced data types of big data, and at the same time supporting deeper analytics.
    Some of the tools that are categorized under this are Spark, HaLoop, and Pregel.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 第三代工具是道路上的聪明孩子，打破了批量操作的传统规范，支持实时分析，提供对大数据高级数据类型的支持，同时支持更深入的统计分析。属于这一类别的工具包括Spark、HaLoop和Pregel。
- en: In [Chapter 4](ch04.html "Chapter 4. Machine Learning Tools, Libraries, and
    Frameworks"), *Machine Learning Tools, Libraries, and Frameworks*, we will cover
    some of the key machine learning tools and demonstrate how they can be used based
    on the problem's context. Implementation details for tools such as R, Julia, Python,
    Mahout, and Spark will be covered in depth. Required technology primers and installation
    or setup-related guidance will be provided.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](ch04.html "第4章。机器学习工具、库和框架")《机器学习工具、库和框架》中，我们将介绍一些关键的机器学习工具，并展示如何根据问题的上下文使用它们。对于R、Julia、Python、Mahout和Spark等工具的实现细节将进行深入探讨。还将提供所需的技术入门和安装或设置相关的指导。
- en: Summary
  id: totrans-362
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, which forms the basis for the rest of the chapters of this
    book, we covered the basics of Machine learning and the landscape of Machine learning
    semantics. We started by defining Machine learning in simple terms and introduced
    Machine learning jargon or the commonly used terms.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，它构成了本书其余章节的基础，我们介绍了机器学习的基础知识和机器学习语义的格局。我们首先用简单的术语定义了机器学习，并介绍了机器学习的术语或常用术语。
- en: There are many competing and complementing fields of Machine learning. We have
    thoroughly explained the similarities, dissimilarities, and the relationship of
    Machine learning with fields such as artificial intelligence, data mining, data
    science, and statistics. Overall, all these fields are very similar and have overlapping
    goals. In most cases, the practitioners of these fields were different. Even in
    terms of the tools being used, there were many common points.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习领域中有许多相互竞争和补充的分支。我们已经详细解释了机器学习与人工智能、数据挖掘、数据科学和统计学等领域的相似性、差异以及它们之间的关系。总体而言，所有这些领域都非常相似，并且具有重叠的目标。在大多数情况下，这些领域的从业者各不相同。即使在使用的工具方面，也存在许多共同点。
- en: We have also looked at some of the latest and best-of-breed tools that can be
    employed in Machine learning. Some of these tools will be demonstrated in the
    chapters using practical examples.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还研究了机器学习中可以使用的最新和最优秀的工具。其中一些工具将在使用实际例子的章节中进行演示。
- en: In the next chapter, we will cover a unique aspect of Machine learning that
    has pretty much changed the way Machine learning implementations have been looked
    at. We will explore how the big data, or large dataset, aspect of Machine learning
    has impacted the choice of tools and implementation approaches.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨机器学习的一个独特方面，这个方面在很大程度上改变了人们看待机器学习实现的方式。我们将探讨大数据或大型数据集的方面如何影响了工具选择和实现方法的选择。
