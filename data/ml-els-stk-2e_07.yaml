- en: '*Chapter 5*: Interpreting Results'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第五章*：解释结果'
- en: As we have seen throughout the previous chapters, Elastic ML creates extremely
    useful analysis as regards both anomaly detection and forecasting. But, up until
    this point, we've only looked at the results created by Elastic ML in a relatively
    superficial way. In this chapter, we will go deeper into learning about the results
    that are created, how they are stored, and how you can leverage those results
    in different ways to bring additional insight.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在前几章中看到的，Elastic ML 在异常检测和预测方面都创建出极其有用的分析。但是，直到现在，我们只以相对肤浅的方式查看 Elastic ML
    创建的结果。在本章中，我们将更深入地了解创建的结果，它们是如何存储的，以及您如何以不同的方式利用这些结果来获得额外的洞察。
- en: 'Specifically, this chapter will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，本章将涵盖以下主题：
- en: Viewing the Elastic ML results index
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看 Elastic ML 结果索引
- en: Anomaly scores
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常分数
- en: Results index schema details
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果索引模式细节
- en: Multi-bucket anomalies
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多桶异常
- en: Forecast results
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测结果
- en: Results API
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果 API
- en: Custom dashboards and Canvas workpads
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义仪表板和 Canvas 工作台
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The information in this chapter is based on the Elastic Stack as it exists in
    v7.10\.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的信息基于 v7.10 版本的 Elastic Stack。
- en: Viewing the Elastic ML results index
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看 Elastic ML 结果索引
- en: 'As we go through much of the discussion of how users should interpret the results
    from Elastic ML''s anomaly detection jobs, it will be helpful to relate what is
    conveyed with how that information is stored within Elastic ML''s internal results
    index. To get a quick initial peek into that index, you can either query the index
    pattern directly using the `_search` API in Elasticsearch, or perhaps more intuitively,
    add the index pattern to Kibana and view the index with native Kibana tools. In
    order to do this, we must first use the following procedure to expose Elastic
    ML''s internal results index to Kibana:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们讨论用户应该如何解释 Elastic ML 异常检测作业的结果，将有助于将所传达的信息与 Elastic ML 内部结果索引中存储的信息联系起来。为了快速初步查看该索引，您可以直接使用
    Elasticsearch 中的 `_search` API 直接查询索引模式，或者更直观地，将索引模式添加到 Kibana 中，并使用原生 Kibana
    工具查看索引。为了做到这一点，我们首先必须使用以下程序将 Elastic ML 的内部结果索引暴露给 Kibana：
- en: In Kibana, click on the side menu and then select **Stack Management** from
    the list:![Figure 5.1 – Selecting Stack Management
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Kibana 中，点击侧菜单，然后从列表中选择**堆栈管理**：![图 5.1 – 选择堆栈管理
- en: '](img/B17040_05_1.jpg)'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_1.jpg]'
- en: Figure 5.1 – Selecting Stack Management
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.1 – 选择堆栈管理
- en: Select **Index Patterns**:![Figure 5.2 – Selecting Index Patterns
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**索引模式**：![图 5.2 – 选择索引模式
- en: '](img/B17040_05_2.jpg)'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_2.jpg]'
- en: Figure 5.2 – Selecting Index Patterns
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.2 – 选择索引模式
- en: Select **Create index pattern**:![Figure 5.3 – Selecting the Create index pattern
    button
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**创建索引模式**：![图 5.3 – 选择创建索引模式按钮
- en: '](img/B17040_05_3.jpg)'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_3.jpg]'
- en: Figure 5.3 – Selecting the Create index pattern button
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.3 – 选择创建索引模式按钮
- en: Enter `.ml-anomalies-*` for the **Index pattern name** and then toggle the **Include
    system and hidden indices switch to on**. Then, click the **Next step** button:![Figure
    5.4 – Naming the index pattern
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将**索引模式名称**输入为 `.ml-anomalies-*`，然后切换**包括系统和隐藏索引**开关到开启状态。然后，点击**下一步**按钮：![图
    5.4 – 命名索引模式
- en: '](img/B17040_05_4.jpg)'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_4.jpg]'
- en: Figure 5.4 – Naming the index pattern
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.4 – 命名索引模式
- en: Choose `timestamp` for **Time field** and then click the **Create index pattern**
    button:![Figure 5.5 – Defining the time field
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**时间字段**为 `timestamp`，然后点击**创建索引模式**按钮：![图 5.5 – 定义时间字段
- en: '](img/B17040_05_5.jpg)'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_5.jpg]'
- en: Figure 5.5 – Defining the time field
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.5 – 定义时间字段
- en: 'Confirm that the index pattern is defined:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确认索引模式已定义：
- en: '![Figure 5.6 – Confirming that the index pattern is defined'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.6 – 确认索引模式已定义'
- en: '](img/B17040_05_6.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_6.jpg]'
- en: Figure 5.6 – Confirming that the index pattern is defined
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 – 确认索引模式已定义
- en: 'Now that the index pattern for `.ml-anomalies-*` is defined, we can use Kibana''s
    Discover to explore the contents of the results index (select **Discover** from
    the main Kibana menu):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`.ml-anomalies-*` 的索引模式已定义，我们可以使用 Kibana 的 Discover 来探索结果索引的内容（从主 Kibana
    菜单中选择**Discover**）：
- en: '![Figure 5.7 – Viewing the results index in Kibana Discover'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.7 – 在 Kibana Discover 中查看结果索引'
- en: '](img/B17040_05_7.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_7.jpg]'
- en: Figure 5.7 – Viewing the results index in Kibana Discover
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 – 在 Kibana Discover 中查看结果索引
- en: 'Now that we''re able to view the results index in Kibana Discover, we can use
    Discover''s search and filter capabilities to explore the results in any way that
    we want. For example, you could retrieve all record-level anomalies for a certain
    anomaly detection job name where the record''s anomaly score is more than a certain
    value:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们能够在 Kibana Discover 中查看结果索引，我们可以使用 Discover 的搜索和过滤功能以任何我们想要的方式探索结果。例如，您可以检索具有特定异常检测作业名称的所有记录级异常，其中记录的异常分数超过某个值：
- en: '![Figure 5.8 – Using Kibana Discover to search and filter anomalies'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.8 – 使用 Kibana Discover 搜索和过滤异常'
- en: '](img/B17040_05_8.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_8.jpg)'
- en: Figure 5.8 – Using Kibana Discover to search and filter anomalies
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 – 使用 Kibana Discover 搜索和过滤异常
- en: 'The syntax of this query in KQL is as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在 KQL 中，此查询的语法如下：
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, we can see two specific occurrences that matched our query. There is a
    plethora of information in the results index, and we will systematically learn
    to decipher the bulk of that information throughout this chapter.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到两个与我们查询匹配的具体事件。结果索引中包含大量信息，我们将系统地学习在本章中解析这些信息的大部分。
- en: Note
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: While it is safe to look at and query the results within the `.ml-anomalies-*`
    index pattern, we should remember that the indices matched by this index pattern
    are system indices and it is unwise to attempt to manually modify or delete the
    contents of these indices.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然查看和查询`.ml-anomalies-*`索引模式内的结果和查询是安全的，但我们应记住，与此索引模式匹配的索引是系统索引，尝试手动修改或删除这些索引的内容是不明智的。
- en: The first concept to understand is that there are different kinds of results
    (hence the `result_type` field) as well as different kinds of scores that reflect
    the analysis from different angles or levels. As such, let's start with a better
    understanding of the different kinds of scoring and how those scores are calculated
    and stored within the results index.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要理解的概念是，存在不同类型的结果（因此有`result_type`字段）以及不同类型的分数，它们从不同的角度或层面反映了分析。因此，让我们从更好地理解不同类型的评分以及这些分数是如何在结果索引中计算和存储的入手。
- en: Anomaly scores
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异常分数
- en: 'Interpreting the results of Elastic ML''s anomaly detection jobs first requires
    the ability to recognize the fact that there are several levels of scoring unusualness,
    expressed within the results. They are as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 首先解读 Elastic ML 异常检测作业的结果需要具备识别以下事实的能力：结果中有几个不同级别的异常评分，如下所示：
- en: '`result_type:bucket`): This level summarizes the results of the entirety of
    the anomaly detection job per time bucket. Essentially, it is a representation
    of how unusual that time bucket is, given the configuration of your job.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`result_type:bucket`): 此级别总结了每个时间桶内整个异常检测作业的结果。本质上，它表示了给定作业配置的时间桶有多不寻常。'
- en: '`result_type:influencer`): This is used to better understand the most unusual
    entities (influencers) within a timespan.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`result_type:influencer`): 这用于更好地理解在特定时间段内最不寻常的实体（影响者）。'
- en: '`result_type:record`): This is the most detailed information regarding every
    anomalous occurrence or anomalous entity within a time bucket. Again, depending
    on the job configuration (multiple detectors, splits, and so on), there can be
    many record-level documents per time bucket.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`result_type:record`): 这是关于每个时间桶内每个异常发生或异常实体的最详细信息。同样，根据作业配置（多个检测器、拆分等），每个时间桶可能有多个记录级文档。'
- en: 'Additionally, to fully appreciate how scoring is done, we also need to fully
    understand the following concepts:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了完全理解评分是如何进行的，我们还需要完全理解以下概念：
- en: '**Normalization**: The concept of projecting anomalousness onto a fixed scale
    between 0 and 100.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**归一化**：将异常性投射到0到100之间的固定尺度上的概念。'
- en: '**Influencers**: Entities that induce the creation of anomalies via their influential
    contribution to the dataset at the time that the anomaly occurs.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**影响者**：在异常发生时，通过对其数据集的有影响力贡献而引发异常创建的实体。'
- en: Let's investigate each of these five concepts in more depth in this section.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在本节中更深入地研究这五个概念。
- en: Bucket-level scoring
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 桶级别评分
- en: 'An anomaly score at the bucket level is akin to answering the question, "How
    unusual was this interval of time, relative to all other intervals of time for
    this job?", where that interval is defined by the anomaly detection job''s `bucket_span`.
    If your job has multiple detectors or splits in the analysis resulting in results
    for possibly many entities simultaneously, then each bucket-level result is an
    aggregated representation of all of those things. The bucket-level anomaly score
    is viewable in a few ways, the first being the **Overall** swim lane at the top
    in the Anomaly Explorer UI:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 桶级别的异常得分类似于回答这样的问题：“相对于这个作业的所有其他时间间隔，这个时间间隔有多不寻常？”，其中这个时间间隔由异常检测作业的`bucket_span`定义。如果你的作业有多个检测器或分析中的分割，导致可能同时为许多实体生成结果，那么每个桶级别的结果都是所有这些事物的聚合表示。桶级别的异常得分可以通过几种方式查看，第一种是在异常探索器UI顶部的**总体**泳道：
- en: '![Figure 5.9 – The swim lanes of the Anomaly Explorer'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.9 – 异常探索器的泳道'
- en: '](img/B17040_05_9.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_9.jpg)'
- en: Figure 5.9 – The swim lanes of the Anomaly Explorer
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 – 异常探索器的泳道
- en: 'Here, we see that the `Max anomaly score` of `88`. It is important to note
    here that the time range being shown in this view encompasses data from January
    6th through February 5th; therefore, there are about 30 "tiles" horizontally in
    the swim lanes, with each one representing one day. The anomaly detection job
    was configured to have a bucket span of 15 minutes, so each tile shows the maximum
    score from the entire day. If we were to zoom the display to only one day using
    Kibana''s time picker (the date/time range control near the top-right corner of
    the screen), we would see more detail, specifically, that the bucket-level anomalies
    in the **Overall** swim lane occurred between 02:00 A.M. and 02:30 A.M.:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到“最大异常得分”为`88`。在此需要注意的是，在此视图中显示的时间范围涵盖了从1月6日到2月5日的数据；因此，泳道中大约有30个“瓷砖”，每个代表一天。异常检测作业被配置为15分钟的桶跨度，因此每个瓷砖显示的是整个一天的最大得分。如果我们使用Kibana的时间选择器（屏幕右上角的时间/日期范围控制）仅放大显示一天，我们会看到更多细节，具体来说，**总体**泳道中的桶级别异常发生在凌晨02:00至02:30之间：
- en: '![Figure 5.10 – The swim lanes of the Anomaly Explorer, after zooming in'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.10 – 放大后的异常探索器泳道'
- en: '](img/B17040_05_10.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_10.jpg)'
- en: Figure 5.10 – The swim lanes of the Anomaly Explorer, after zooming in
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 – 放大后的异常探索器泳道
- en: It is also important to note here how the **Overall** swim lane relates (or
    doesn't relate) to the grid of swim lanes below it. This grid of swim lanes shows
    influencer-level scoring (discussed in the next section) and is therefore not
    directly related to the bucket-level scoring. This is a common misconception,
    as many people think that the **Overall** swim lane is some type of combination
    (for example, a maximum score) of the columns from the grid below it. You can
    certainly see in *Figure 5.10* that this is obviously not true, as the group of
    influencer-level scores in the second row of the grid (around 07:00 A.M.) have
    no corresponding score at the **Overall** (bucket) level. Why is this? The short
    answer is that the **Overall** swim lane is a comparison of time buckets against
    one another. Therefore, the most unusual time buckets get the highest scores,
    and time buckets that are a lot less unusual (due to the number and severity of
    individual anomalies within that time bucket) get smaller scores, or even no score
    at all. The process of determining this relative scoring is called **normalization**.
    It is an important part of the scoring at all levels and deserves some independent
    explanation.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 同样重要的是要注意**总体**泳道如何（或不如何）与下面的泳道网格相关联。这个泳道网格显示了影响者级别的评分（将在下一节中讨论），因此它并不直接与桶级别的评分相关。这是一个常见的误解，因为许多人认为**总体**泳道是其下方网格列（例如，最大得分）的一种组合。你当然可以在*图
    5.10*中看到这显然是不正确的，因为网格第二行（大约07:00 AM）的影响者级别评分在**总体**（桶）级别没有相应的得分。为什么是这样？简短的答案是**总体**泳道是时间桶相互之间的比较。因此，最不寻常的时间桶得到最高的得分，而那些非常不寻常的时间桶（由于该时间桶内单个异常的数量和严重性）得到较小的得分，甚至没有得分。确定这种相对评分的过程称为**正则化**。这是所有级别评分的重要部分，值得独立解释。
- en: Normalization
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则化
- en: As first introduced in [*Chapter 1*](B17040_01_Epub_AM.xhtml#_idTextAnchor016),
    *Machine Learning for IT*, we saw that raw probability values for specific anomalies
    are normalized on a scale from 0 to 100\. This process is what allows there to
    be a relative ranking of anomalousness, while also bounding the values to a fixed
    interval of values that become useful in assessing severity for the purposes of
    triage and/or alerting.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如在[*第一章*](B17040_01_Epub_AM.xhtml#_idTextAnchor016)中首次介绍，即《IT领域的机器学习》，我们了解到特定异常的原始概率值在0到100的范围内进行了标准化。这个过程使得异常的相对排名成为可能，同时也将值限制在一个固定区间内，这对于评估严重性以进行分类和/或警报是有用的。
- en: 'The key aspect in the last sentence is this notion of relative ranking. In
    other words, the normalized values take into account things that have been seen
    by the anomaly detection job *so far* and rank them accordingly. This also means
    that previously assigned normalized scores may change over time as new anomalies
    are discovered. As such, you will notice that scores within the results index
    have both an "initial" value and the current value, for example:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一句中的关键方面是这个相对排名的概念。换句话说，标准化值考虑了异常检测工作到目前为止所看到的东西，并据此进行排名。这也意味着，随着新异常的发现，先前分配的标准化分数可能会随时间而改变。因此，您会注意到结果索引中的分数既有“初始”值，也有当前值，例如：
- en: '`initial_anomaly_score`: The bucket-level anomaly score that was recorded at
    the time the anomaly was created'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initial_anomaly_score`: 在异常创建时记录的桶级别异常分数'
- en: '`anomaly_score`: The current bucket-level normalized anomaly score'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`anomaly_score`: 当前桶级别的标准化异常分数'
- en: These two values may be the same but may indeed diverge over time. The initial
    score is a fixed value, but the current score may be adjusted as additional, perhaps
    as more egregious anomalies are encountered over time. The normalization process
    happens every few hours during real-time operation, or spontaneously if the analytics
    detect drastic changes in the normalization table. It is also done if the anomaly
    detection job is *closed* (put into the closed state). Normalization may rescore
    anomalies as far back in time as whatever the `renormalization_window_days` setting
    is configured to (30 days or 100 bucket spans is the default value, and the value
    is only changeable if the job is created with the API or the Advanced job wizard
    by directly modifying the job's configuration JSON).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个值可能相同，但确实可能会随着时间的推移而分歧。初始分数是一个固定值，但当前分数可能会随着时间调整，例如，可能会遇到更多的严重异常。标准化过程在实时操作中每几个小时发生一次，或者在分析检测到标准化表中的剧烈变化时自发发生。如果异常检测工作被*关闭*（置于关闭状态），也会进行标准化。标准化可能会重新评分时间上可以追溯到`renormalization_window_days`设置配置的任何时间（默认值为30天或100个桶跨度，并且只有在通过API或高级作业向导直接修改作业的配置JSON创建作业时，该值才可更改）。
- en: Influencer-level scoring
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 影响者级别评分
- en: 'An anomaly score at the influencer level is akin to answering the question,
    "What are the most unusual entities during this time?", where we are now ranking
    these entities against one another. The influencer-level scores are viewable in
    a few ways, the first being the main grid of swim lanes in the middle of the Anomaly
    Explorer UI, and the second being the **Top influencers** list along the left-hand
    side:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在影响者级别的异常分数类似于回答问题，“在这段时间里，哪些实体最不寻常？”，其中我们现在正在将这些实体相互比较。影响者级别的分数可以通过几种方式查看，第一种是在异常探索器UI中间的主网格泳道，第二种是在左侧的**顶级影响者**列表：
- en: '![Figure 5.11 – Influencers in the Anomaly Explorer'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.11 – 异常探索器中的影响者'
- en: '](img/B17040_05_11.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17040_05_11.jpg]'
- en: Figure 5.11 – Influencers in the Anomaly Explorer
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.11 – 异常探索器中的影响者
- en: 'Here, we see that in the main grid of swim lanes, the country codes of the
    `geo.src` field are listed in decreasing total influencer score. Notice that despite
    the grid being set to show 10 rows per page, only six anomalous country codes
    are listed (there are no more that have significant influencer scores during this
    time period). Also, the top influencers are listed on the left-hand side, showing
    for each entity both the maximum influencer score (99 for `geo.src:IN`) as well
    as the sum of all influencer scores for this time range (223 for `geo.src:IN`).
    In this case, since there is only one influencer defined for this job, so this
    information may seem redundant. However, many jobs have more than one influencer
    defined, so the view becomes more sensible in that case. For example, if we look
    at a population analysis job on the `kibana_sample_data_logs` index in which we
    choose `distinct_count("url.keyword") over clientip` as the detector and choose
    both `clientip` and `response.keyword` as influencers, the Anomaly Explorer view
    could look like this:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到在泳道的主网格中，`geo.src`字段的国籍代码按总影响因素分数递减排列。请注意，尽管网格设置为每页显示 10 行，但只列出了六个异常的国籍代码（在此时间段内没有更多具有显著影响因素分数的代码）。此外，主要影响因素列在左侧，显示每个实体的最大影响因素分数（`geo.src:IN`
    为 99）以及此时间范围内所有影响因素分数的总和（`geo.src:IN` 为 223）。在这种情况下，由于此作业只定义了一个影响因素，所以这些信息可能看起来是多余的。然而，许多作业定义了多个影响因素，所以在这种情况下，视图变得更加合理。例如，如果我们查看在
    `kibana_sample_data_logs` 索引上进行的群体分析作业，我们选择 `distinct_count("url.keyword") over
    clientip` 作为检测器，并选择 `clientip` 和 `response.keyword` 作为影响因素，异常检测探索器视图可能看起来像这样：
- en: '![Figure 5.12 – Multiple influencers in the Anomaly Explorer'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.12 – 异常检测探索器中的多个影响因素'
- en: '](img/B17040_05_12.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_12.jpg)'
- en: Figure 5.12 – Multiple influencers in the Anomaly Explorer
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 – 异常检测探索器中的多个影响因素
- en: Notice that the grid's `clientip`, but the **Top influencers** list on the left
    show both influencer lists.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到网格的 `clientip`，但左边的**主要影响因素**列表显示了两个影响因素列表。
- en: 'The Anomaly Explorer is interactive, so if we select the critical anomaly tile
    in the **Overall** swim lane for the day of February 19th, the influencer grid
    and lists change as the filter for that period is implicitly applied:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测探索器是交互式的，所以如果我们选择 2 月 19 日**总体**泳道中的关键异常瓷砖，影响因素网格和列表会随着该时期的过滤器隐式应用而改变：
- en: '![Figure 5.13 – Anomaly Explorer filtered for a specific day'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.13 – 对特定一天进行过滤的异常检测探索器'
- en: '](img/B17040_05_13.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_13.jpg)'
- en: Figure 5.13 – Anomaly Explorer filtered for a specific day
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13 – 对特定一天进行过滤的异常检测探索器
- en: We now see only the relevant entities for the selected day. Now that we've gotten
    a little bit of a sense of what influencers are, you may ask what fields are good
    candidates for influencers if this is how they can be represented? Let's take
    a quick detour to discuss influencers in more depth.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在只看到所选日期的相关实体。既然我们已经对影响因素有了一定的了解，你可能会问，如果它们可以以这种方式表示，哪些字段是好的影响因素候选者？让我们快速偏离一下，更深入地讨论一下影响因素。
- en: Influencers
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 影响因素
- en: Within the anomaly detection job configuration, there is the ability to define
    fields as an influencer. The concept of an influencer is a field that describes
    an entity for which you'd like to know whether it is to blame for the existence
    of the anomaly, or at least whether it had a significant contribution. Note that
    any field chosen as a candidate to be an influencer doesn't need to be part of
    the detection logic, although it is natural to pick fields that are used as splits
    or populations to also be influencers.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在异常检测作业配置中，可以定义字段作为影响因素。影响因素的概念是描述一个实体的字段，你想要知道它是否是异常存在的原因，或者至少是否做出了重大贡献。请注意，任何被选为候选影响因素的字段不需要是检测逻辑的一部分，尽管选择用作拆分或群体的字段作为影响因素是很自然的。
- en: 'If we revisit the example shown in *Figure 5.13*, we see that both the `clientip`
    and the `response.keyword` fields were declared as influencers for the job (where
    `clientip` was part of the detector configuration, but `response.keyword` was
    not). The client IP address of `30.156.16.164` is identified as a top influencer.
    This seems a bit of a redundant declaration, because the anomaly was for that
    client IP – but this is an expected situation when influencers are chosen for
    the fields that define the population or are the split fields. The other top influencer
    (`response.keyword`) has a value of `404`. This particular piece of information
    is extremely relevant in that it gives the user an immediate clue of whatever
    the `30.156.16.164` IP address was doing during the anomaly. If we investigate
    the anomalous IP address at the time of the anomaly, we will see that 100% of
    the requests made resulted in a response code of `404`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们重新审视*图5.13*中展示的例子，我们会看到`clientip`和`response.keyword`字段都被声明为作业的影响因子（其中`clientip`是检测器配置的一部分，但`response.keyword`不是）。客户端IP地址`30.156.16.164`被识别为顶级影响因子。这种声明似乎有点冗余，因为异常正是针对该客户端IP地址的——但这是在为定义人口或分割字段选择影响因子时预期的情况。另一个顶级影响因子(`response.keyword`)的值为`404`。这个特定的信息非常相关，因为它为用户提供了一个关于`30.156.16.164`
    IP地址在异常期间所做事情的即时线索。如果我们调查异常发生时的异常IP地址，我们会看到100%的请求都导致了`404`响应代码：
- en: '![Figure 5.14 – The influencer field value of 404 dominates the results at
    the time of the anomaly'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.14 – 异常发生时，影响字段值404主导了结果'
- en: '](img/B17040_05_14.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_14.jpg)'
- en: Figure 5.14 – The influencer field value of 404 dominates the results at the
    time of the anomaly
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14 – 异常发生时，影响字段值404主导了结果
- en: As such, the value of `404` has a high influencer score (`50`, as shown in *Figure
    5.13*). You may think that because 100% of the requests were `404`, the influencer
    score should also be 100, but it is not that simple. The influencer scores are
    normalized against other influencer scores and the influencer score is also expressing
    how unusual the value of `404` has been over time. In this specific example dataset,
    there are hundreds more occurrences of `404` over time, but most of those have
    not been associated with anomalies. As such, the influencer score for this particular
    anomaly is tempered by that fact. There may be a compelling argument for Elastic
    ML to separate these two concepts – one score that expresses the unusualness of
    the entity over time, and another score for how much a field value influences
    a particular anomaly – but for the time being, those notions are blended into
    the influencer score.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`404`的值具有高影响因子得分（如图5.13所示为`50`）。你可能认为，由于100%的请求都是`404`，影响因子得分也应该为100，但事实并非如此简单。影响因子得分是相对于其他影响因子得分进行归一化的，影响因子得分也表达了`404`值随时间变化的不寻常程度。在这个特定的示例数据集中，随着时间的推移，有数百次`404`的发生，但其中大多数并没有与异常相关联。因此，这个特定异常的影响因子得分受到了这一事实的调和。对于Elastic
    ML来说，可能有一个有说服力的论点来区分这两个概念——一个分数表示实体随时间的不寻常程度，另一个分数表示字段值对特定异常的影响程度——但到目前为止，这些概念被融合到了影响因子得分中。
- en: It is also key to understand that the process of finding potential influencers
    happens after Elastic ML finds the anomaly. In other words, it does not affect
    any of the probability calculations that are made as part of the detection. Once
    the anomaly has been determined, ML will systematically go through all instances
    of each candidate influencer field and remove that instance's contribution to
    the data in that time bucket. If, once removed, the remaining data is no longer
    anomalous, then via counterfactual reasoning, that instance's contribution must
    have been influential and is scored accordingly (with an `influencer_score` in
    the results).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要理解的是，寻找潜在影响因子的过程发生在Elastic ML找到异常之后。换句话说，它不会影响作为检测一部分所做的任何概率计算。一旦确定异常，机器学习将系统地遍历每个候选影响因子字段的每个实例，并移除该实例在时间桶中的数据贡献。如果移除后剩余的数据不再异常，那么通过反事实推理，该实例的贡献必须是具有影响力的，并且会相应地进行评分（结果中的`influencer_score`）。
- en: Influencers can become a very powerful thing to leverage when viewing the results
    of not just a single ML job, but potentially several related jobs. In [*Chapter
    7*](B17040_07_Epub_AM.xhtml#_idTextAnchor131), *AIOps and Root Cause Analysis*,
    we'll see how to effectively use influencers to assist with root cause analysis.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 影响者可以成为在查看单个机器学习作业的结果时非常强大的工具，甚至可能是几个相关作业。在[*第 7 章*](B17040_07_Epub_AM.xhtml#_idTextAnchor131)，“AIOps
    和根本原因分析”中，我们将看到如何有效地使用影响者来协助根本原因分析。
- en: Record-level scoring
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 记录级评分
- en: 'An anomaly score at the record level is the lowest level of abstraction in
    the results and contains the most amount of detail. In the Anomaly Explorer UI,
    the record-level results are shown in the table at the bottom:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 记录级别的异常得分是结果中的最低抽象级别，包含最多的细节。在异常探索器 UI 中，记录级结果显示在底部的表格中：
- en: '![Figure 5.15 – Anomaly table showing record-level results'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.15 – 显示记录级结果的异常表'
- en: '](img/B17040_05_15.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_05_15.jpg)'
- en: Figure 5.15 – Anomaly table showing record-level results
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.15 – 显示记录级结果的异常表
- en: Notice that if the **Interval** selector is set to **Auto**, then any anomalies
    that are adjacent serially in time will be collapsed such that only the highest
    score anomaly is shown. Setting the **Interval** field to **Show all** will reveal
    each individual anomaly, if desired.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果**间隔**选择器设置为**自动**，则任何在时间上连续相邻的异常将被合并，只显示得分最高的异常。将**间隔**字段设置为**显示所有**将揭示每个单独的异常，如果需要的话。
- en: A common misconception is that the record-level anomaly score is directly related
    to the deviation articulated in the `41x higher`). The score is purely driven
    by the probability calculation, using the same normalization process that was
    described earlier. The **description** field, and even the **typical** value,
    are simplified bits of contextual information to make the anomaly easier to understand.
    In fact, as you'll see later, the **description** field isn't stored in the results
    index – it is only calculated on the fly in Kibana.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的误解是记录级异常得分与在 `41x higher)` 中阐述的偏差直接相关。得分完全由概率计算驱动，使用之前描述的相同归一化过程。**描述**字段，甚至**典型**值，都是简化后的上下文信息，以便更容易理解异常。实际上，正如你稍后将会看到的，**描述**字段并没有存储在结果索引中——它只是在
    Kibana 中即时计算的。
- en: When looking at these different level anomaly records in the `.ml-anomalies-*`
    index, we can see that many fields are there for our use. Some may be obvious,
    and some may not be. In the next section, we'll systematically go through the
    schema of the results index and will describe the meaning of the important fields.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当查看 `.ml-anomalies-*` 索引中的不同级别异常记录时，我们可以看到那里有许多字段可供我们使用。其中一些可能是明显的，而另一些可能不明显。在下一节中，我们将系统地介绍结果索引的模式，并将描述重要字段的含义。
- en: Results index schema details
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果索引模式细节
- en: 'As we have already hinted, inside the results index, there are a variety of
    different documents, each with their own usefulness with respect to understanding
    the results of the anomaly detection jobs. The ones we will discuss in this section
    are the ones that directly relate to the three levels of abstraction that we discussed
    previously in this chapter. They are aptly named as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经暗示的，在结果索引内部，有各种不同的文档，每个文档都有其自身的用途，有助于理解异常检测作业的结果。在本节中，我们将讨论的文档是与我们在本章先前讨论的三个抽象级别直接相关的。它们被恰当地命名为以下内容：
- en: '`result_type:bucket`: To give bucket-level results'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`result_type:bucket`：以提供桶级结果'
- en: '`result_type:record`: To give record-level results'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`result_type:record`：以提供记录级结果'
- en: '`result_type:influencer`: To give influencer-level results'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`result_type:influencer`：以提供影响者级结果'
- en: 'The distribution of these document types will depend on the ML job configuration
    and the characteristics of the dataset being analyzed. These document types are
    written with the following heuristic:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这些文档类型的分布将取决于机器学习作业的配置以及正在分析的数据集的特征。这些文档类型是根据以下启发式方法编写的：
- en: '`result_type:bucket`: One document is written for every bucket span''s worth
    of time. In other words, if the bucket span is 15 minutes, then there will be
    one document of this type being written every 15 minutes. Its timestamp will be
    equal to the leading edge of the bucket. For example, for the time bucket that
    encompasses the range between 11:30 and 11:45, the result document of this type
    will have a timestamp of 11:30.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`result_type:bucket`：对于每个桶跨度的时间，都会写入一个文档。换句话说，如果桶跨度是 15 分钟，那么每 15 分钟就会有一个这种类型的文档被写入。其时间戳将等于桶的前沿。例如，对于包含
    11:30 到 11:45 范围的时间桶，此类型的结果文档将有一个 11:30 的时间戳。'
- en: '`result_type:record`: One document is written for every occurrence of an anomaly
    within a time bucket. Therefore, with big datasets encompassing many entities
    (IP addresses, hostnames, and so on), a particular bucket of time could have hundreds
    or even thousands of anomaly records in a bucket during a major anomalous event
    or widespread outage. This document will also have a timestamp equal to the leading
    edge of the bucket.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`result_type:record`：对于时间桶内的每个异常情况，都会写入一个文档。因此，对于包含许多实体（IP 地址、主机名等）的大数据集，在重大异常事件或大规模故障期间，一个特定的时间桶可能会有数百甚至数千个异常记录。此文档也将有一个时间戳，等于桶的前沿。'
- en: '`result_type:influencer`: One document is written for every influencer that
    is found for each anomaly record. Because there can potentially be more than one
    influencer type found for each anomaly record, this type of document can be even
    more voluminous than record results. This document will also have a timestamp
    that is equal to the leading edge of the bucket.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`result_type:influencer`：对于每个异常记录中找到的每个影响者，都会写入一个文档。因为每个异常记录可能找到多个影响者类型，所以这种类型的文档可能比记录结果更庞大。此文档也将有一个时间戳，等于桶的前沿。'
- en: Understanding the fields within these document types is especially important
    when we get to [*Chapter 6*](B17040_06_Epub_AM.xhtml#_idTextAnchor117), *Alerting
    on ML Analysis*, because there will inevitably be a balance between alert detail
    (usually, more is preferable to less) and the number of individual alerts per
    unit of time (usually, less is preferable to more). We will revisit this when
    we start writing actual alerts.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进入 [*第 6 章*](B17040_06_Epub_AM.xhtml#_idTextAnchor117)，*基于机器学习的警报* 时，理解这些文档类型中的字段尤其重要，因为不可避免地会在警报细节（通常，越多越好）和单位时间内的单个警报数量（通常，越少越好）之间取得平衡。我们将在开始编写实际警报时重新审视这一点。
- en: Bucket results
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 桶结果
- en: At the highest level of abstraction are the results at the bucket level. Remember
    that this is the aggregated results for the entire job as a function of time and
    essentially answers the question, "How unusual was this bucket of time?"
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在最高抽象级别上，是桶级别的结果。请记住，这是整个作业随时间聚合的结果，本质上回答了“这个时间桶有多不寻常？”的问题。
- en: 'Let''s look at an example document in the `.ml-anomalies-*` index by using
    Kibana Discover and issuing the following KQL query:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用 Kibana Discover 和执行以下 KQL 查询来查看 `.ml-anomalies-*` 索引中的一个示例文档：
- en: '[PRE1]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This will yield the following output:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 5.16 – Bucket-level result document as seen in Kibana Discover'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.16 – Kibana Discover 中看到的桶级别结果文档'
- en: '](img/B17040_05_16.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_16.jpg)'
- en: Figure 5.16 – Bucket-level result document as seen in Kibana Discover
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.16 – Kibana Discover 中看到的桶级别结果文档
- en: 'Clicking on the **>** icon next to the timestamp for the document in *Figure
    5.16* will expand it so that you can see all of the details:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 点击图 5.16 中文档时间戳旁边的 **>** 图标，可以将其展开，以便您可以看到所有详细信息：
- en: '![Figure 5.17 – Bucket-level document detail in Kibana Discover'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.17 – Kibana Discover 中的桶级别文档细节'
- en: '](img/B17040_05_17.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_17.jpg)'
- en: Figure 5.17 – Bucket-level document detail in Kibana Discover
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.17 – Kibana Discover 中的桶级别文档细节
- en: 'You can see that just one bucket-level document was returned from our query
    in *Figure 5.16*, a single anomalous time bucket (at timestamp `1613824200000`,
    or in my time zone, February 20, 2021, 07:30:00 A.M. GMT-05:00) that has an `anomaly_score`
    greater than 98\. In other words, there were no other time buckets with anomalies
    that big in this time range. Let''s look at the key fields:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从图 5.16 中看到，我们的查询只返回了一个桶级别的文档，一个单独的异常时间桶（时间戳为 `1613824200000`，或者在我的时区中，2021
    年 2 月 20 日上午 07:30:00 GMT-05:00），其 `anomaly_score` 大于 98。换句话说，在这个时间范围内没有其他时间桶有如此大的异常。让我们看看关键字段：
- en: '`timestamp`: The timestamp of the leading edge of the time bucket. In Kibana,
    this field will be displayed by default in your local time zone (although it is
    stored in the index in epoch format with the time zone of UTC).'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestamp`: 时间桶的前沿时间戳。在 Kibana 中，此字段将默认以您的本地时区显示（尽管它在索引中以 UTC 时区的纪元格式存储）。'
- en: '`anomaly_score`: The current normalized score of the bucket, based upon the
    range of probabilities seen over the entirety of the job. The value of this score
    may fluctuate over time as new data is processed by the job and new anomalies
    are found.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`anomaly_score`: 基于整个作业中看到的概率范围，桶的当前标准化分数。随着作业处理新数据和新异常的发现，此分数的值可能会随时间波动。'
- en: '`initial_anomaly_score`: The normalized score of the bucket, that is, when
    that bucket was first analyzed by the analytics. This score, unlike `anomaly_score`,
    will not change as more data is analyzed.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initial_anomaly_score`: 桶的标准化分数，即当该桶首次由分析分析时。与 `anomaly_score` 不同，随着更多数据的分析，此分数不会改变。'
- en: '`event_count`: The number of raw Elasticsearch documents seen by the ML algorithms
    during the bucket''s span.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`event_count`: 在桶跨度内由 ML 算法看到的原始 Elasticsearch 文档的数量。'
- en: '`is_interim`: A flag that signifies whether the bucket is finalized or whether
    is still waiting for all of the data within the bucket span to be received. This
    field is relevant for ongoing jobs that are operating in real time. For certain
    types of analysis, there could be interim results, even though not all of the
    data for the bucket has been seen.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_interim`: 一个标志，表示桶是否已最终确定，或者是否仍在等待桶跨度内的所有数据接收。对于在实时中运行的工作，此字段是相关的。对于某些类型的分析，即使桶中并非所有数据都已看到，也可能有临时结果。'
- en: '`job_id`: The name of the anomaly detection job that created this result.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`job_id`: 创建此结果的异常检测作业的名称。'
- en: '`processing_time_ms`: An internal performance measurement of how much processing
    time (in milliseconds) the analytics took to process this bucket''s worth of data.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`processing_time_ms`: 分析处理此桶数据所需处理时间（以毫秒为单位）的内部性能度量。'
- en: '`bucket_influencers`: An array of influencers (and details on them) that have
    been identified for this current bucket. Even if no influencers have been chosen
    as part of the job configuration, or there are no influencers as part of the analysis,
    there will always be a default influencer of the `influencer_field_name:bucket_time`
    type, which is mostly an internal record-keeping device to allow for the ordering
    of bucket-level anomalies in cases where explicit influencers cannot be determined.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bucket_influencers`: 为当前桶识别出的影响因子（及其详细信息）的数组。即使在工作配置中没有选择影响因子，或者分析中没有影响因子，也始终会存在一个默认的
    `influencer_field_name:bucket_time` 类型的影响因子，这主要是一个内部记录工具，以便在无法确定显式影响因子的情况下对桶级别的异常进行排序。'
- en: If a job does have named and identified influencers, then the `bucket_influencers`
    array may look like what is shown in *Figure 5.17*.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果作业具有命名和识别的影响因子，那么 `bucket_influencers` 数组可能看起来像 *图 5.17* 所示。
- en: Notice that in addition to the default entry of the `influencer_field_name:bucket_time`
    type, in this case, there is an entry for a field name of an analytics-identified
    influencer for the `geo.src` field. This is a cue that `geo.src` was a relevant
    influencer type that was discovered at the time of this anomaly. Since multiple
    influencer candidates can be chosen in the job configuration, it should be noted
    that in this case, `geo.src` is the only influencer field and no other fields
    were found to be influential. It should also be noted that, at this level of detail,
    the particular instance of `geo.src` (that is, which one) is not disclosed; that
    information will be disclosed when querying at the lower levels of abstraction,
    which we will discuss next.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，除了默认的 `influencer_field_name:bucket_time` 类型条目外，在这种情况下，还有一个针对 `geo.src` 字段的由分析识别出的影响因子的字段名条目。这是一个提示，表明
    `geo.src` 是在此次异常发生时发现的有关影响因子类型。由于在作业配置中可以选择多个影响因子候选人，应注意的是，在这种情况下，`geo.src` 是唯一的影响因子字段，没有发现其他具有影响力的字段。还应注意的是，在这个细节级别，`geo.src`
    的特定实例（即哪一个）没有公开；当在较低层次抽象查询时，将公开该信息，我们将在下一节讨论。
- en: Record results
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 记录结果
- en: At a lower level of abstraction, there are results at the record level. Giving
    the most amount of detail, record results show specific instances of anomalies
    and essentially answer the question, "What entity was unusual and by how much?"
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在较低层次的抽象级别，存在记录级别的结果。提供最大量的细节，记录结果显示了异常的具体实例，并基本上回答了问题：“哪个实体不寻常以及程度如何？”
- en: 'Let''s look at an example document in the `.ml-anomalies-*` index by using
    Kibana Discover and issuing the following KQL query:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用 Kibana Discover 和执行以下 KQL 查询来查看 `.ml-anomalies-*` 索引中的一个示例文档：
- en: '[PRE2]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will result in something similar to this:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致类似以下内容：
- en: '![Figure 5.18 – Record-level result document as seen in Kibana Discover'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.18 – 在 Kibana Discover 中看到的记录级别结果文档'
- en: '](img/B17040_05_18.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_18.jpg)'
- en: Figure 5.18 – Record-level result document as seen in Kibana Discover
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.18 – 在 Kibana Discover 中看到的记录级别结果文档
- en: 'Clicking on the **>** icon next to the timestamp for the document will expand
    it so that you are able to see all of the details:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 点击文档时间戳旁边的 **>** 图标将展开它，以便您可以看到所有详细信息：
- en: '![Figure 5.19 – Record-level document detail in Kibana Discover'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.19 – 在 Kibana Discover 中的记录级别文档详情'
- en: '](img/B17040_05_19.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_19.jpg)'
- en: Figure 5.19 – Record-level document detail in Kibana Discover
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.19 – 在 Kibana Discover 中的记录级别文档详情
- en: 'You can see that a few bucket-level documents were returned from our query
    in *Figure 5.18*. Let''s look at the key fields:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 *图 5.18* 中看到，我们的查询返回了一些桶级别文档。让我们看看关键字段：
- en: '`timestamp`: The timestamp of the leading edge of the time bucket, inside which
    this anomaly occurred. This is similar as explained earlier.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestamp`：时间桶的前沿时间戳，其中发生了此异常。这与前面解释的类似。'
- en: '`job_id`: The name of the anomaly detection job that created this result.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`job_id`：创建此结果的事务检测作业的名称。'
- en: '`record_score`: The current normalized score of the anomaly record, based upon
    the range of the probabilities seen over the entirety of the job. The value of
    this score may fluctuate over time as new data is processed by the job and new
    anomalies are found.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`record_score`：基于整个作业中看到的概率范围，异常记录的当前归一化分数。随着作业处理新数据并发现新的异常，此分数的值可能会随时间波动。'
- en: '`initial_record_score`: The normalized score of the anomaly record, that is,
    when that bucket was first analyzed by the analytics. This score, unlike `record_score`,
    will not change as more data is analyzed.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initial_record_score`：异常记录的归一化分数，即当该桶首次由分析处理时的分数。与 `record_score` 不同，随着更多数据的分析，此分数不会改变。'
- en: '`detector_index`: An internal counter to keep track of the detector configuration
    that this anomaly belongs to. Obviously, with a single-detector job, this value
    will be zero, but it may be non-zero in jobs with multiple detectors.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detector_index`：一个内部计数器，用于跟踪此异常所属的检测器配置。显然，对于单检测器作业，此值将为零，但在具有多个检测器的作业中，此值可能不为零。'
- en: '`function`: A reference to keep track of which detector function was used for
    the creation of this anomaly.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`function`：一个引用，用于跟踪用于创建此异常的检测器函数。'
- en: '`is_interim`: A flag that signifies whether or not the bucket is finalized
    or whether the bucket is still waiting for all of the data within the bucket span
    to be received. This field is relevant for ongoing jobs that are operating in
    real time. For certain types of analysis, there could be interim results, even
    though not all of the data for the bucket has been seen.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_interim`：一个标志，表示桶是否已最终确定，或者桶是否仍在等待接收桶跨度内的所有数据。对于在实时中运行的作业，此字段是相关的。对于某些类型的分析，即使桶中尚未看到所有数据，也可能有临时结果。'
- en: '`actual`: The actual observed value of the analyzed data in this bucket. For
    example, if the function is `count`, then this represents the number of documents
    that are encountered (and counted) in this time bucket.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`actual`：在此桶中分析的数据的实际观察值。例如，如果函数是 `count`，则这表示在此时间桶中遇到（并计数）的文档数量。'
- en: '`typical`: A representation of the expected or predicted value based upon the
    ML model for this dataset.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`typical`：基于此数据集的机器学习模型的预期或预测值的表示。'
- en: '`multi_bucket_impact`: A measurement (on a scale from -5 to +5) that determines
    how much this particular anomaly was influenced by the secondary multi-bucket
    analysis (explained later in the chapter), from no influence (-5) to all influence
    (+5).'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`multi_bucket_impact`：一个测量值（从 -5 到 +5 的范围），用于确定此特定异常受后续多桶分析（本章后面解释）影响的程度，从无影响（-5）到全部影响（+5）。'
- en: '`influencers`: An array of which influencers (and the values of those influencers)
    are relevant to this anomaly record.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`influencers`：一个数组，其中包含哪些影响者（以及这些影响者的值）与这个异常记录相关。'
- en: 'If a job has splits defined (either with `by_field_name` and/or `partition_field_name`)
    and identified influencers, then the record results documents will have more information,
    such as what is seen in *Figure 5.19*:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果作业定义了拆分（无论是使用`by_field_name`和/或`partition_field_name`）并确定了影响者，那么记录结果文档将包含更多信息，例如*图5.19*中所示：
- en: '`partition_field_name`: A cue that a partition field was defined and that an
    anomaly was found for one of the partition field values.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`partition_field_name`：一个提示，表明已定义分区字段，并且对于分区字段值之一发现了异常。'
- en: '`partition_field_value`: The value of the partition field that this anomaly
    occurred for. In other words, the entity name this anomaly was found for.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`partition_field_value`：发生异常的分区字段的值。换句话说，这是发现异常的实体名称。'
- en: In addition to the fields mentioned here (which would have been `by_field_name`
    and `by_field_value` if the job had been configured to use a `by` field), we also
    see an explicit instance of the `geo.src` field. This is just a shortcut – every
    partition, `by`, or `over_field_value` in the results will also have a direct
    field name.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这里提到的字段（如果作业配置为使用`by`字段，则将是`by_field_name`和`by_field_value`），我们还看到了`geo.src`字段的显式实例。这只是一个快捷方式——结果中的每个分区、`by`或`over_field_value`都将有一个直接的字段名。
- en: 'If your job is doing population analysis (via the use of `over_field_name`),
    then the record results document will be organized slightly differently as the
    reporting is done with orientation as to the unusual members of the population.
    For example, if we look at a population analysis job on the `kibana_sample_data_logs`
    index in which we choose `distinct_count("url.keyword") over clientip` as the
    detector, then an example record-level results document will also contain a causes
    array:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的作业正在进行人口分析（通过使用`over_field_name`），那么记录结果文档将组织得略有不同，因为报告是以人口中不寻常成员的取向进行的。例如，如果我们查看在`kibana_sample_data_logs`索引上的人口分析作业，并选择`distinct_count("url.keyword")
    over clientip`作为检测器，那么一个示例记录级结果文档也将包含一个原因数组：
- en: '![Figure 5.20 – Record-level document showing the causes array for a population
    job'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.20 – 显示人口作业原因数组的记录级文档'
- en: '](img/B17040_05_20.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_20.jpg)'
- en: Figure 5.20 – Record-level document showing the causes array for a population
    job
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.20 – 显示人口作业原因数组的记录级文档
- en: The `causes` array is built to compactly express all of the anomalous things
    that that IP did in that bucket. Again, many things seem redundant, but it is
    primarily because there may be different ways of aggregating the information for
    results presentation in dashboards or alerts.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`causes`数组旨在紧凑地表达该IP在该桶中做的所有异常事情。再次强调，许多事情看起来似乎是多余的，但这主要是因为在仪表板或警报中展示结果时，可能存在不同的信息聚合方式。'
- en: 'Also, in the case of this population analysis, we see that the `influencers`
    array contains both the `clientip` field and the `response.keyword` field:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在本人口分析案例中，我们发现`influencers`数组中既包含`clientip`字段，也包含`response.keyword`字段：
- en: '![Figure 5.21 – Record-level document showing the influencers array for a population
    job'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.21 – 显示人口作业影响者数组的记录级文档'
- en: '](img/B17040_05_21.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_21.jpg)'
- en: Figure 5.21 – Record-level document showing the influencers array for a population
    job
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.21 – 显示人口作业影响者数组的记录级文档
- en: Let's conclude our survey of the results index schema by looking at the influencers-level
    results.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过查看影响者级别的结果来结束我们对结果索引模式的调查。
- en: Influencer results
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 影响者结果
- en: 'Yet another lens by which to view the results is via influencers. Viewing the
    results this way allows us to answer the question, "What were the most unusual
    entities in my ML job and when were they unusual?" To understand the structure
    and content of influencer-level results, let''s look at an example document in
    the `.ml-anomalies-*` index by using Kibana Discover and issuing the following
    KQL query:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 通过影响者这一视角来查看结果，我们可以回答问题：“在我的机器学习作业中，哪些实体最不寻常，以及它们何时变得不寻常？”为了理解影响者级别结果的结构和内容，让我们通过使用Kibana
    Discover和执行以下KQL查询来查看`.ml-anomalies-*`索引中的一个示例文档：
- en: '[PRE3]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Figure 5.22 – Influencer-level result document as seen in Kibana Discover'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.22 – 在Kibana Discover中看到的影响者级别结果文档'
- en: '](img/B17040_05_22.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_05_22.jpg)'
- en: Figure 5.22 – Influencer-level result document as seen in Kibana Discover
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.22 – 在Kibana Discover中看到的影响者级别结果文档
- en: Notice that in this case, we didn't query on the score (`influencer_score`),
    but rather on an expected entity name and value. The last document listed (with
    an `influencer_score` of `50.174`, matches what we saw back in *Figure 5.13*.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这种情况下，我们没有查询分数（`influencer_score`），而是查询一个预期的实体名称和值。列出的最后一份文档（`influencer_score`为`50.174`）与我们在*图5.13*中看到的一致。
- en: 'Let''s look at the key fields:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看关键字段：
- en: '`timestamp`: The timestamp of the leading edge of the time bucket, inside which
    this influencer''s anomalous activity occurred. This is similar to what was explained
    earlier.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestamp`: 包含此推广者异常活动的时间桶的前沿时间戳。这与之前解释的类似。'
- en: '`job_id`: The name of the anomaly detection job that created this result.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`job_id`: 创建此结果的异常检测作业的名称。'
- en: '`influencer_field_name`: The name of the field that was declared as an influencer
    in the job configuration.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`influencer_field_name`: 在作业配置中声明的推广者字段的名称。'
- en: '`influencer_field_value`: The value of the influencer field for which this
    result is relevant.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`influencer_field_value`: 该结果相关的推广者字段值。'
- en: '`influencer_score`: The current normalized score of how unusual and contributory
    the influencer was to anomalies at this point.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`influencer_score`: 推广者在此点对异常的贡献程度和异常性的当前标准化分数。'
- en: '`initial_influencer_score`: The normalized score of the influencer when that
    bucket was first analyzed by the analytics. This score, unlike `influencer_score`,
    will not change as more data is analyzed.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initial_influencer_score`: 分析首次分析该桶时推广者的标准化分数。与`influencer_score`不同，此分数在分析更多数据时不会改变。'
- en: '`is_interim`: A flag that signifies whether or not the bucket is finalized
    or whether the bucket is still waiting for all of the data within the bucket span
    to be received. This field is relevant for ongoing jobs that are operating in
    real time. For certain types of analysis, there could be interim results, even
    though not all of the data for the bucket has been seen.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_interim`: 一个标志，表示桶是否已最终确定，或者桶是否仍在等待桶跨度内的所有数据接收。对于实时运行的作业，此字段相关。对于某些类型的分析，即使桶中尚未看到所有数据，也可能有临时结果。'
- en: Now that we have exhaustively explained the relevant fields that are available
    to the user, we can file that information away for when we build custom dashboards,
    visualizations, and sophisticated alerting in subsequent sections and chapters.
    But, before we exit this chapter, we still have a few important concepts to explore.
    Next up is a discussion on a special kind of anomaly – the multi-bucket anomaly.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经详尽地解释了用户可用的相关字段，我们可以在后续章节中构建自定义仪表板、可视化以及复杂的警报时将这些信息存档。但是，在我们离开这一章之前，我们还有一些重要的概念需要探讨。接下来是关于一种特殊类型的异常——多桶异常的讨论。
- en: Multi-bucket anomalies
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多桶异常
- en: Almost everything that we've studied so far with anomalies being generated by
    Elastic ML's anomaly detection jobs has been with respect to looking at a specific
    anomaly being raised at a specific time, but quantized at the interval of `bucket_span`.
    However, we can certainly have situations in which a particular observation within
    a bucket span may not be that unusual, but an extended window of time, taken collectively
    together, might be more significantly unusual than any single observation. Let's
    see an example.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们研究的大多数关于由Elastic ML的异常检测作业生成的异常，都是关于在特定时间查看特定异常，但以`bucket_span`的间隔进行量化。然而，我们当然可以有一些情况，其中桶跨度内的特定观察可能并不那么异常，但一个扩展的时间窗口，如果整体来看，可能比任何单个观察更显著地异常。让我们看一个例子。
- en: Multi-bucket anomaly example
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多桶异常示例
- en: 'First shown in the example in [*Chapter 3*](B17040_03_Epub_AM.xhtml#_idTextAnchor049),
    *Anomaly Detection*, in *Figure 3.17*, we repeat the figure here to show how multi-bucket
    anomalies exhibit themselves in the Elastic ML UI:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第三章*（[B17040_03_Epub_AM.xhtml#_idTextAnchor049]）的示例中首次展示的*异常检测*，在*图3.17*中，我们在此重复该图，以展示多桶异常如何在Elastic
    ML UI中展现：
- en: '![Figure 5.23 – Multi-bucket anomalies first shown in Chapter 3'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.23 – 多桶异常首次在第三章展示'
- en: '](img/B17040_05_23.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_23.jpg]'
- en: Figure 5.23 – Multi-bucket anomalies first shown in Chapter 3
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.23 – 多桶异常首次在第三章展示
- en: As we discussed in [*Chapter 3*](B17040_03_Epub_AM.xhtml#_idTextAnchor049),
    *Anomaly Detection*, multi-bucket anomalies are designated with a different symbol
    in the UI (a cross instead of a dot). They denote cases in which the actual singular
    value may not necessarily be anomalous, but that there is a trend that is occurring
    in a sliding window of 12 consecutive buckets. Here, you can see that there is
    a noticeable slump spanning several adjacent buckets.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如在[*第三章*](B17040_03_Epub_AM.xhtml#_idTextAnchor049)中讨论的，*异常检测*，多桶异常在UI中以不同的符号表示（一个十字而不是一个点）。它们表示实际的单个值可能不一定异常，但在12个连续桶的滑动窗口中存在一个趋势。在这里，您可以注意到几个相邻桶中存在一个明显的下滑。
- en: Note, however, that some of the multi-bucket anomaly markers are placed on the
    data at times after the data has "recovered." This can be somewhat confusing to
    users until you realize that because the determination of multi-bucket anomalies
    is a secondary analysis (in addition to the bucket-by-bucket analysis) and because
    this analysis is a sliding window looking in arrears, the leading edge of that
    window, when the anomaly is recorded, might be after the situation has recovered.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，请注意，一些多桶异常标记有时会在数据“恢复”之后放置在数据上。这可能会让用户感到有些困惑，直到你意识到，由于多桶异常的确定是一种二级分析（除了桶级分析之外）并且由于这种分析是一个向后看的滑动窗口，当异常被记录时，窗口的前沿可能会在情况恢复之后。
- en: Multi-bucket scoring
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多桶评分
- en: As mentioned, multi-bucket analysis is a secondary analysis. Therefore, two
    probabilities are calculated for each bucket span – the probability of the observation
    seen in the current bucket, and the probability of a multi-bucket feature – a
    kind of weighted average of the current bucket and the previous 11\. If those
    two probabilities are roughly the same order of magnitude, then `multi_bucket_impact`
    will be low (on the negative side of the -5 to +5 scale). If, on the other hand,
    the multi-bucket feature probability is wildly lower (thus more unusual), then
    `multi_bucket_impact` will be high.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前提到的，多桶分析是一种二级分析。因此，对于每个桶跨度，计算两个概率——当前桶中观察到的观测值的概率，以及多桶特征的概率——这是当前桶和前11个桶的加权平均值。如果这两个概率大致处于相同的数量级，那么`multi_bucket_impact`将较低（在-5到+5的负值范围内）。另一方面，如果多桶特征的概率明显较低（因此更不寻常），那么`multi_bucket_impact`将较高。
- en: 'In the example shown in *Figure 5.23,* the UI will show the user the multi-bucket
    impact as being `high`, but will not give you the actual scoring:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 5.23*中显示的示例中，UI将向用户显示多桶影响为`高`，但不会给出实际的评分：
- en: '![Figure 5.24 – Multi-bucket anomalies, with impact scoring shown'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.24 – 多桶异常，显示影响评分'
- en: '](img/B17040_05_24.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_24.jpg](img/B17040_05_24.jpg)'
- en: Figure 5.24 – Multi-bucket anomalies, with impact scoring shown
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.24 – 多桶异常，显示影响评分
- en: 'However, if you look at the raw record-level result, you will see that `multi_bucket_impact`
    has indeed been given a value of +5:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果您查看原始记录级结果，您将看到`multi_bucket_impact`确实被赋予了+5的值：
- en: '![Figure 5.25 – Multi-bucket anomaly record, with the raw score shown'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.25 – 多桶异常记录，显示原始分数'
- en: '](img/B17040_05_25.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_25.jpg](img/B17040_05_25.jpg)'
- en: Figure 5.25 – Multi-bucket anomaly record, with the raw score shown
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.25 – 多桶异常记录，显示原始分数
- en: Multi-bucket anomalies give you a different perspective on the behavior of your
    data. You will want to keep in mind how they are signified and scored via the
    `multi_bucket_impact` field in order for you to include or exclude them, as required,
    from your reporting or alerting logic.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 多桶异常为您提供了对数据行为的不同视角。您需要记住它们是如何通过`multi_bucket_impact`字段来表示和评分的，以便您可以根据需要将它们包含或排除在报告或警报逻辑中。
- en: Let's now look forward (yes, pun intended) to how results from forecasts are
    represented in the results index.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在来看看（是的，这里有意使用了双关语）预测结果在结果索引中的表示方式。
- en: Forecast results
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测结果
- en: 'As explained in depth in [*Chapter 4*](B17040_04_Epub_AM.xhtml#_idTextAnchor081),
    *Forecasting*, we can get Elastic ML to extrapolate into the future the trends
    of the data that has been analyzed. Recall what we showed in *Figure 4.21*:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如在[*第四章*](B17040_04_Epub_AM.xhtml#_idTextAnchor081)中详细解释的，*预测*，我们可以让Elastic
    ML将分析过的数据趋势外推到未来。回想一下我们在[*图 4.21*](B17040_04_Epub_AM.xhtml#_idTextAnchor081)中展示了什么：
- en: '![Figure 5.26 – Forecast results first shown in Chapter 4'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.26 – 预测结果首次在第四章展示'
- en: '](img/B17040_05_26.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_26.jpg](img/B17040_05_26.jpg)'
- en: Figure 5.26 – Forecast results first shown in Chapter 4
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.26 – 预测结果首次在第四章展示
- en: 'Remember that the prediction value is the value with the highest likelihood
    (probability), and that the shaded area is the range of the 95th percentile of
    confidence. These three key values are stored in the `.ml-anomalies-*` results
    indices with the following names:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，预测值是最有可能的值（概率），阴影区域是置信度 95% 的范围。这三个关键值存储在 `.ml-anomalies-*` 结果索引中，名称如下：
- en: '`forecast_prediction`'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`forecast_prediction`'
- en: '`forecast_upper`'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`forecast_upper`'
- en: '`forecast_lower`'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`forecast_lower`'
- en: Querying for forecast results
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询预测结果
- en: When querying for the forecast results in the `.ml-anomalies-*` results indices,
    it is important to remember that forecast results are transient – they have a
    default lifespan of 14 days following creation, especially if they are created
    from the UI in Kibana. If a different expiration duration is desired, then the
    forecast will have to be invoked via the `_forecast` API endpoint and explicitly
    setting the `expires_in` duration.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 当在 `.ml-anomalies-*` 结果索引中查询预测结果时，重要的是要记住预测结果是短暂的——它们在创建后的默认生命周期为 14 天，尤其是在从
    Kibana UI 创建时。如果需要不同的过期持续时间，则必须通过 `_forecast` API 端点调用预测并显式设置 `expires_in` 持续时间。
- en: 'Another thing to remember is that multiple forecasts may have been invoked
    at different moments in time on the same dataset. As shown back in *Figure 4.4*
    and repeated here, multiple forecast invocations produce multiple forecast results:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 另一件需要注意的事情是，可能在同一数据集的不同时间点调用了多个预测。正如之前在 *图 4.4* 中所示并在此重复，多次调用预测会产生多个预测结果：
- en: '![Figure 5.27 – A symbolic representation of invoking multiple forecasts at
    different times'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.27 – 在不同时间调用多个预测的符号表示'
- en: '](img/B17040_05_27.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17040_05_27.jpg]'
- en: Figure 5.27 – A symbolic representation of invoking multiple forecasts at different
    times
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.27 – 在不同时间调用多个预测的符号表示
- en: 'As such, we need a way to discern between the results. In the Kibana UI, they
    are discernable simply by looking at the **Created** date:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要一种方法来区分结果。在 Kibana UI 中，只需查看 **创建** 日期即可简单区分：
- en: '![Figure 5.28 – Viewing multiple previously run forecasts'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.28 – 查看多次运行的预测结果'
- en: '](img/B17040_05_28.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17040_05_28.jpg]'
- en: Figure 5.28 – Viewing multiple previously run forecasts
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.28 – 查看多次运行的预测结果
- en: 'However, when looking at the results index, it should be noted that each invoked
    forecast has a unique `forecast_id`:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当查看结果索引时，应注意每个调用的预测都有一个唯一的 `forecast_id`：
- en: '![Figure 5.29 – Viewing forecast results in Kibana Discover'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.29 – 在 Kibana Discover 中查看预测结果'
- en: '](img/B17040_05_29.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17040_05_29.jpg]'
- en: Figure 5.29 – Viewing forecast results in Kibana Discover
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.29 – 在 Kibana Discover 中查看预测结果
- en: This `forecast_id` is only obvious when invoking the forecast using the `_forecast`
    API because `forecast_id` is returned as part of the payload of the API call.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用 `_forecast` API 调用预测时，这个 `forecast_id` 才是明显的，因为 `forecast_id` 是 API 调用负载的一部分返回的。
- en: Therefore, if multiple forecasts were created spanning a common time frame,
    there would be more than one result with different IDs.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果创建了跨越相同时间框架的多个预测，将会有多个具有不同 ID 的结果。
- en: 'When querying the forecast results, you can think of two possible orientations:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 当查询预测结果时，你可以考虑两种可能的查询方向：
- en: '**Value-focused**: The query supplies a date and time, and the result is a
    particular value for that time is returned. The question, "What is my utilization
    5 days from now?" would be a good example.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**值聚焦**：查询提供一个日期和时间，结果返回该时间的特定值。例如，“5 天后我的利用率是多少？”就是一个很好的例子。'
- en: '**Time-focused**: The query supplies a value, and the result is a time at which
    that value is realized. The question, "When does my utilization reach 80%?" would
    be a good example.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间聚焦**：查询提供一个值，结果是一个实现该值的时间。例如，“我的利用率何时达到 80%？”就是一个很好的例子。'
- en: 'Obviously, either type of query is possible. To satisfy the time-focused inquiry,
    for example, we need to re-orient the query a little to ask it to return the date
    (or dates) on which the predicted values meet certain criteria. The user can query
    for the forecast results using other traditional query methods (KQL, Elasticsearch
    DSL), but to mix it up a little, we''ll submit the query using Elastic SQL in
    the Kibana Dev Tools Console:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，任何一种查询都是可能的。例如，为了满足以时间为重点的查询，我们需要稍微调整查询，要求它返回预测值满足某些标准的时间（或日期）。用户可以使用其他传统查询方法（KQL、Elasticsearch
    DSL）查询预测结果，但为了稍微变化一下，我们将在 Kibana Dev Tools 控制台中使用 Elastic SQL 提交查询：
- en: '[PRE4]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here, we are asking whether there are any times during which the predicted
    value exceeds our limit of the value of 16,890\. The response is as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们询问是否存在任何预测值超过我们设定的16,890值限制的时间。响应如下：
- en: '[PRE5]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In other words, we may breach the threshold on March 17 at 9:45 A.M. GMT (although
    remember from [*Chapter 4*](B17040_04_Epub_AM.xhtml#_idTextAnchor081), *Forecasting*,
    that the sample data used is from the past and therefore forecast predictions
    are also in the past). Now that we have a good understanding of how to query for
    forecast results, we could include them in dashboards and visualizations, which
    we will cover later in this chapter – or even in alerts, as we'll see in [*Chapter
    6*](B17040_06_Epub_AM.xhtml#_idTextAnchor117), *Alerting on ML Analysis*.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们可能在3月17日上午9:45 GMT时突破阈值（尽管请记住，从[*第4章*](B17040_04_Epub_AM.xhtml#_idTextAnchor081)，*预测*中，所使用的样本数据来自过去，因此预测预测也属于过去）。现在我们已经很好地理解了如何查询预测结果，我们可以将它们包含在仪表板和可视化中，我们将在本章后面部分介绍——甚至可以在警报中，正如我们在[*第6章*](B17040_06_Epub_AM.xhtml#_idTextAnchor117)，*基于机器学习的警报*中看到的。
- en: But, before we look at including results in custom dashboards and visualizations,
    let's cover one last brief topic – the Elastic ML results API.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，在我们查看如何在自定义仪表板和可视化中包含结果之前，让我们再简要介绍一个主题——Elastic ML结果API。
- en: Results API
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果API
- en: If programmatic access to the results is your thing, in addition to querying
    the results indices directly, you could opt to instead query Elastic ML's results
    API. Some parts of the API are redundant to what we've already explored, and some
    parts are unique. We will now check them out in the upcoming sections.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 如果程序化访问结果是你的事情，除了直接查询结果索引外，你还可以选择查询Elastic ML的结果API。API的一些部分与我们之前探索的内容重复，而一些部分是独特的。我们现在将在接下来的部分中检查它们。
- en: Results API endpoints
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果API端点
- en: 'There are five different results API endpoints available:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 有五个不同的结果API端点可用：
- en: Get buckets
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取桶
- en: Get influencers
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取影响因素
- en: Get records
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取记录
- en: Get overall buckets
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取整体桶
- en: Get categories
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取类别
- en: The first three API endpoints give results that are redundant in light of what
    we've already covered in this chapter by way of querying the results index directly
    (through Kibana or using the Elasticsearch `_search` API), and that method actually
    allows more flexibility, so we really won't bother discussing them here. However,
    the last two API endpoints are novel, and each deserves an explanation.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 前三个API端点提供的结果与我们通过直接查询结果索引（通过Kibana或使用Elasticsearch `_search` API）在本章中已经涵盖的内容重复，这种方法实际上提供了更多的灵活性，所以我们在这里不会详细讨论它们。然而，最后两个API端点是新颖的，每个都值得解释。
- en: Getting the overall buckets API
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取整体桶API
- en: 'The overall buckets API call is a means by which to return summarized results
    across multiple anomaly detection jobs in a programmatic way. We''re not going
    to explore every argument of the request body, nor will we describe every field
    in the response body, as you can reference the documentation. But we will discuss
    here the important function of this API call, which is to request the results
    from an arbitrary number of jobs, and to receive a single result score (called
    `overall_score`) that encapsulates the `top_n` average of the maximum bucket `anomaly_score`
    for each job requested. As shown in the documentation, an example call is one
    that asks for the top two jobs (in the set of jobs that begin with the name `job-`)
    whose bucket anomaly score, when averaged together, is higher than `50.0`, starting
    from a specific timestamp:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 整体桶API调用是一种以编程方式返回多个异常检测作业的汇总结果的方法。我们不会探索请求体的每个参数，也不会描述响应体中的每个字段，因为你可以参考文档。但我们将讨论这个API调用的重要功能，即请求任意数量的作业的结果，并接收一个单一的结果评分（称为`overall_score`），它封装了每个请求作业的最大桶`anomaly_score`的`top_n`平均值。如文档所示，一个示例调用是请求桶异常评分平均高于`50.0`的前两个作业（在以`job-`开头的作业集中），从特定的时间戳开始：
- en: '[PRE6]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This will result in the following sample return:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下样本返回：
- en: '[PRE7]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Notice that `overall_score` is the average of the two highest scores in this
    case (the result of `overall_score` of `55.0` is the average of the `job-3` score
    of `80.0` and the `job-1` score of `30.0`), even though three anomaly detection
    jobs match the query pattern of `job-*`. While this is certainly interesting,
    perhaps for building a composite alert, you should realize the limitations in
    this reporting, especially if you can only access the bucket-level anomaly score
    and not anything from the record or influencer level. In [*Chapter 6*](B17040_06_Epub_AM.xhtml#_idTextAnchor117),
    *Alerting on ML Analysis*, we will explore some options regarding composite alerting.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这种情况下，`overall_score`是两个最高分数的平均值（`overall_score`的`55.0`是`job-3`分数`80.0`和`job-1`分数`30.0`的平均值），尽管有三个异常检测作业匹配`job-*`的查询模式。虽然这确实很有趣，也许是为了构建复合警报，你应该意识到这种报告的限制，特别是如果你只能访问桶级别的异常分数，而不能访问记录或影响因素级别的任何信息。在[*第6章*](B17040_06_Epub_AM.xhtml#_idTextAnchor117)，“基于机器学习分析的警报”，我们将探讨一些关于复合警报的选项。
- en: Getting the categories API
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取类别API
- en: 'The `categories` API call is only relevant for jobs that leverage categorization,
    as described in detail in [*Chapter 3*](B17040_03_Epub_AM.xhtml#_idTextAnchor049),
    *Anomaly Detection*. The `categories` API returns some interesting internal definitions
    of the categories found during the textual analysis of the documents. If we run
    the API on the categorization job that we created back in [*Chapter 3*](B17040_03_Epub_AM.xhtml#_idTextAnchor049),
    *Anomaly Detection* (abbreviated to only return one record for brevity), the output
    is as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '`categories` API调用仅适用于使用分类的作业，如[*第3章*](B17040_03_Epub_AM.xhtml#_idTextAnchor049)“异常检测”中详细描述。`categories`
    API返回在文档文本分析过程中发现的类别的一些有趣的内部定义。如果我们对在[*第3章*](B17040_03_Epub_AM.xhtml#_idTextAnchor049)“异常检测”中创建的分类作业运行API（为了简洁起见，仅返回一条记录），输出如下：'
- en: '[PRE8]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will see the following response:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下响应：
- en: '[PRE9]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Several elements are part of the reply:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 回复中包含以下几个元素：
- en: '`category_id`: This is the number of the category of message (incremented from
    1). It corresponds to the value of the `mlcategory` field in the results index.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`category_id`: 这是消息类别的编号（从1开始递增）。它对应于结果索引中`mlcategory`字段的值。'
- en: '`terms`: This is a list of the static, non-mutable words extracted from the
    message.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`terms`: 这是一个从消息中提取的静态、不可变的单词列表。'
- en: '`examples`: An array of complete, unaltered sample log lines that fall into
    this category. These are used to show the users what some of the real log lines
    look like.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`examples`: 一个包含完整、未修改的样本日志行的数组，这些行属于此类。这些用于向用户展示一些真实日志行的样子。'
- en: '`grok_pattern`: A regexp-style pattern match that could be leveraged for Logstash
    or an ingest pipeline that you could use to match this message category.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`grok_pattern`: 一个正则表达式样式的模式匹配，可以用于Logstash或一个可以用来匹配此消息类别的摄取管道。'
- en: '`num_matches`: A count of the number of times this message category was seen
    in the logs throughout the anomaly detection job running on this dataset.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_matches`: 在此数据集上运行的异常检测作业中，此消息类别在日志中出现的次数。'
- en: Perhaps the most interesting use of this API is not for anomaly detection, but
    rather around merely understanding the unique number of category types and the
    distribution of those types in your unstructured logs – to answer questions such
    as, "What kinds of messages are in my logs and how many of each type?" Some of
    this capability may be leveraged in the future to create a "data preparation"
    pipeline to assist users in ingesting unstructured logs into Elasticsearch more
    easily.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 也许这个API最有趣的使用不是用于异常检测，而是仅仅为了理解你的非结构化日志中类别类型的唯一数量及其分布——以回答诸如“我的日志中有什么类型的消息，每种类型有多少？”等问题。这些功能中的一些可能在将来被利用来创建一个“数据准备”管道，以帮助用户更容易地将非结构化日志摄取到Elasticsearch中。
- en: Let's now explore how results gleaned from Elastic ML's anomaly detection and
    forecasting jobs can be leveraged in custom dashboards, visualizations, and Canvas
    workpads.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来探讨如何利用从Elastic ML的异常检测和预测作业中获得的结果，在自定义仪表板、可视化以及Canvas工作垫中发挥作用。
- en: Custom dashboards and Canvas workpads
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义仪表板和Canvas工作垫
- en: It's clear that now that we know the ins and outs of the results index, which
    stores all the goodness that comes out of Elastic ML's anomaly detection and forecast
    analytics, our imagination is the limit concerning how we can then express those
    results in a way that is meaningful for our own goals. This section will briefly
    explore some of the concepts and ideas that you can use to bring Elastic ML's
    results to a big screen near you!
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，现在我们知道了结果索引的来龙去脉，该索引存储了Elastic ML的异常检测和预测分析的精华，我们关于如何以对我们自己的目标有意义的方 式表达这些结果的想象力是无限的。本节将简要探讨一些概念和想法，您可以使用它们将Elastic
    ML的结果带到您附近的大屏幕上！
- en: Dashboard "embeddables"
  id: totrans-277
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仪表板“可嵌入内容”
- en: 'One recent addition to the capabilities of Elastic ML is the ability to embed
    the Anomaly Explorer timeline ("swim lanes") into existing custom dashboards.
    To accomplish this, simply click the "three dots" menu at the top right of the
    Anomaly timeline and select the **Add to dashboard** option:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic ML功能的一个最近增加是能够将异常探索器时间线（“泳道”）嵌入到现有的自定义仪表板中。要完成此操作，只需点击异常时间线右上角的“三个点”菜单，并选择**添加到仪表板**选项：
- en: '![Figure 5.30 – Adding the Anomaly timeline to another dashboard'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.30 – 将异常时间线添加到另一个仪表板'
- en: '](img/B17040_05_30.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_05_30.jpg)'
- en: Figure 5.30 – Adding the Anomaly timeline to another dashboard
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.30 – 将异常时间线添加到另一个仪表板
- en: 'At this point, select which part of the swim lane views you want to include
    and select which dashboard(s) you wish to add them to:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，选择您想要包含的泳道视图的哪个部分，并选择您希望将它们添加到哪个仪表板（们）：
- en: '![Figure 5.31 – Adding the Anomaly timeline to a specific dashboard'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.31 – 将异常时间线添加到特定仪表板'
- en: '](img/B17040_05_31.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_05_31.jpg)'
- en: Figure 5.31 – Adding the Anomaly timeline to a specific dashboard
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.31 – 将异常时间线添加到特定仪表板
- en: 'Clicking on the **Add and edit dashboard** button will then transport the user
    to the target dashboard and allow them to move and resize the embedded panels.
    For example, we can have the anomalies side by side with the other visualizations:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**添加和编辑仪表板**按钮，然后会将用户带到目标仪表板，并允许他们移动和调整嵌入的面板大小。例如，我们可以将异常与其他可视化并排显示：
- en: '![Figure 5.32 – New dashboard now containing Anomaly swim lane visualizations'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.32 – 新仪表板现在包含异常泳道可视化'
- en: '](img/B17040_05_32.jpg)'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_05_32.jpg)'
- en: Figure 5.32 – New dashboard now containing Anomaly swim lane visualizations
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.32 – 新仪表板现在包含异常泳道可视化
- en: Anomalies as annotations in TSVB
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在TSVB中的异常作为注释
- en: 'The `kibana_sample_data_logs` with the following panel options:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '`kibana_sample_data_logs`具有以下面板选项：'
- en: '![Figure 5.33 – Creating a new TSVB visualization – Panel options'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.33 – 创建新的TSVB可视化 – 面板选项'
- en: '](img/B17040_05_33.jpg)'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_05_33.jpg)'
- en: Figure 5.33 – Creating a new TSVB visualization – Panel options
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.33 – 创建新的TSVB可视化 – 面板选项
- en: 'Then, there is the following configuration for the `geo.src`):'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，这是`geo.src`的以下配置）：
- en: '![Figure 5.34 – Creating a new TSVB visualization – Data options'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.34 – 创建新的TSVB可视化 – 数据选项'
- en: '](img/B17040_05_34.jpg)'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_05_34.jpg)'
- en: Figure 5.34 – Creating a new TSVB visualization – Data options
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.34 – 创建新的TSVB可视化 – 数据选项
- en: 'Then, we have the following configuration for the `web_traffic_per_country`
    to select anomalies with record scores over `90`:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们有以下配置的`web_traffic_per_country`以选择记录分数超过`90`的异常：
- en: '![Figure 5.35 – Creating a new TSVB visualization – Annotation options'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.35 – 创建新的TSVB可视化 – 注释选项'
- en: '](img/B17040_05_35.jpg)'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_05_35.jpg)'
- en: Figure 5.35 – Creating a new TSVB visualization – Annotation options
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.35 – 创建新的TSVB可视化 – 注释选项
- en: 'Note the `record_score` and `partition_field_value`) and `Anomaly:{{record_score}}
    for {{partition_field_value}}`). Once this is done, we have the final result:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`record_score`和`partition_field_value`)以及`Anomaly:{{record_score}} for {{partition_field_value}}`)。一旦完成，我们就得到了最终结果：
- en: '![Figure 5.36 – Creating a new TSVB visualization complete with anomaly annotations'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.36 – 创建新的TSVB可视化，包含异常注释'
- en: '](img/B17040_05_36.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17040_05_36.jpg)'
- en: Figure 5.36 – Creating a new TSVB visualization complete with anomaly annotations
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.36 – 创建新的TSVB可视化，包含异常注释
- en: We now have a nice visualization panel with anomalies superimposed on the original
    raw data.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个很好的可视化面板，异常数据叠加在原始原始数据上。
- en: Customizing Canvas workpads
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义画布工作垫
- en: Kibana Canvas is the ultimate tool for creating pixel-perfect infographics that
    are data-driven from Elasticsearch. You can create highly custom-tailored reports
    with a set of customizable elements. The experience in Canvas is very different
    from standard Kibana dashboards. Canvas presents you with a workspace where you
    can build sets of slides (similar in concept to Microsoft PowerPoint) called the
    **workpad**.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana Canvas 是创建由 Elasticsearch 驱动的像素完美信息图的终极工具。您可以使用一组可定制的元素创建高度定制化的报告。Canvas
    中的体验与标准的 Kibana 仪表板非常不同。Canvas 为您提供了一个工作区，您可以在其中构建一系列幻灯片（在概念上类似于 Microsoft PowerPoint），称为**工作垫**。
- en: To leverage anomaly detection and/or forecast results in a Canvas workpad, there
    isn't anything special that needs to be done – everything that has been learned
    so far in this chapter is applicable. This is because it is very easy to use the
    `essql` command in Canvas to query the `.ml-anomalies-*` index pattern and extract
    the information we care about.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Canvas 工作垫中利用异常检测和/或预测结果，不需要做任何特别的事情——本章迄今为止学到的所有内容都适用。这是因为使用 `essql` 命令在
    Canvas 中查询 `.ml-anomalies-*` 索引模式并提取我们关心的信息非常容易。
- en: 'When we install the Kibana sample data, we also get a few sample Canvas workpads
    to enjoy:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们安装 Kibana 样本数据时，我们也会得到一些样本 Canvas 工作垫来享受：
- en: '![Figure 5.37 – Sample Canvas workpads'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.37 – 样本 Canvas 工作垫'
- en: '](img/B17040_05_37.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_37](img/B17040_05_37.jpg)'
- en: Figure 5.37 – Sample Canvas workpads
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.37 – 样本 Canvas 工作垫
- en: 'Clicking on the **[Logs] Web Traffic** sample workpad opens it for us to edit:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**[日志]网络流量**样本工作垫，我们可以打开它进行编辑：
- en: '![Figure 5.38 – Sample web traffic workpad'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.38 – 样本网络流量工作垫'
- en: '](img/B17040_05_38.jpg)'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_38](img/B17040_05_38.jpg)'
- en: Figure 5.38 – Sample web traffic workpad
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.38 – 样本网络流量工作垫
- en: 'Selecting one of the elements on the page (perhaps the `324`) and then selecting
    **Expression** **editor** at the bottom-right corner of Canvas will reveal the
    details of the element:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 选择页面上的一个元素（可能是 `324`），然后在 Canvas 的右下角选择**表达式编辑器**，将显示该元素的详细信息：
- en: '![Figure 5.39 – Editing a Canvas element in the Expression editor'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.39 – 在表达式编辑器中编辑 Canvas 元素'
- en: '](img/B17040_05_39.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_39](img/B17040_05_39.jpg)'
- en: Figure 5.39 – Editing a Canvas element in the Expression editor
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.39 – 在表达式编辑器中编辑 Canvas 元素
- en: 'Notice that the real "magic" of obtaining live data is embedded in the `essql`
    command – the rest of the expression is merely formatting. As a simple example,
    we can adjust the SQL with the following syntax:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，获取实时数据的真正“魔法”嵌入在 `essql` 命令中——表达式其余部分仅仅是格式化。作为一个简单的例子，我们可以使用以下语法调整 SQL：
- en: '[PRE10]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: One thing to note is that because the `.ml-anomalies-*` index pattern's name
    begins with a non-alphabet character, the name needs to be enclosed in double-quotes,
    and those double-quotes need to be escaped with the backslash character.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于 `.ml-anomalies-*` 索引模式的名字以非字母字符开头，因此名字需要用双引号括起来，并且这些双引号需要用反斜杠字符转义。
- en: 'This will return the total number of critical anomalies (those that have a
    `record_score` larger than `75`) for a particular anomaly detection job on that
    dataset:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回特定数据集上特定异常检测作业中关键异常（`record_score` 大于 `75` 的异常）的总数：
- en: '![Figure 5.40 – Displaying the count of critical anomalies'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.40 – 显示关键异常的数量'
- en: '](img/B17040_05_40.jpg)'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_05_40](img/B17040_05_40.jpg)'
- en: Figure 5.40 – Displaying the count of critical anomalies
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.40 – 显示关键异常的数量
- en: In short, it is quite easy to use Canvas to create very beautiful and meaningful
    data visualizations and leverage information from either anomaly detection results
    or forecast results.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，使用 Canvas 创建非常美丽和有意义的数据可视化以及利用异常检测结果或预测结果中的信息非常容易。
- en: Summary
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Elastic ML's anomaly detection and forecasting analytics creates wonderful and
    meaningful results that are explorable via the rich UI that is provided in Kibana,
    or programmatically via direct querying of the results indices and the API. Understanding
    the results of your anomaly detection and forecasting jobs and being able to appropriately
    leverage that information for further custom visualizations or alerts makes those
    custom assets even more powerful.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic ML 的异常检测和预测分析通过 Kibana 中提供的丰富 UI 或通过直接查询结果索引和 API 的编程方式创建出奇妙而有意义的结果。理解您的异常检测和预测作业的结果，并能够适当地利用这些信息进行进一步的定制可视化或警报，使这些定制资产更加强大。
- en: In the next chapter, we'll leverage the results to create sophisticated and
    useful proactive alerts to further increase the operational value of Elastic ML.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将利用这些结果来创建复杂且实用的主动警报，以进一步提高Elastic ML的操作价值。
