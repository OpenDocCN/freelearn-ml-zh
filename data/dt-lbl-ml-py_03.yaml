- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Labeling Data for Regression
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为回归数据标签化
- en: 'In this chapter, we will explore the process of labeling data for regression-based
    machine learning tasks, such as predicting housing prices, in situations where
    there is insufficient labeled data available for training. Regression tasks are
    tasks that involve predicting numerical values using a labeled training dataset,
    making them integral to fields such as finance and economics. However, real-world
    scenarios often present a challenge: labeled data is a precious commodity, often
    in short supply.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨在训练数据中可用标签数据不足的情况下，为基于回归的机器学习任务（如预测房价）进行数据标签的过程。回归任务涉及使用标记的训练数据集预测数值，这使得它们对金融和经济等领域至关重要。然而，现实场景往往面临挑战：标记数据是一种珍贵的商品，通常供应不足。
- en: If there is a short supply of labeled data to train a machine learning model,
    you can still use summary statistics, semi-supervised learning, and clustering
    to predict the target labels for your unlabeled data. We have demonstrated this
    using house price data as an example and generated the predicted labels for house
    prices programmatically using Python. We will look at different approaches to
    labeling data for regression using Snorkel libraries, semi-supervised learning,
    data augmentation, and K-means clustering methods. In real-world projects, it
    is challenging to get the labeled data required for training machine learning
    regression models. For example, adequate data may not be available to train the
    model to predict house prices. In those cases, we prepare the training data by
    using various Python libraries.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果缺乏标记数据来训练机器学习模型，您仍然可以使用汇总统计、半监督学习和聚类来预测未标记数据的目标标签。我们已通过使用房价数据作为示例并使用Python编程生成房价预测的预测标签来演示这一点。我们将探讨使用Snorkel库、半监督学习、数据增强和K-means聚类方法进行回归数据标签化的不同方法。在现实世界的项目中，获取训练机器学习回归模型所需的标记数据是一项挑战。例如，可能没有足够的数据来训练模型以预测房价。在这些情况下，我们通过使用各种Python库来准备训练数据。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: Using rules based on summary statistics to generate house price labels for regression
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于汇总统计的规则生成房价标签进行回归
- en: Using semi-supervised learning to label regression data for house price prediction
    with regression
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用半监督学习为房价预测进行回归标签化
- en: Generating house price data labels with data augmentation to generate synthetic
    data for regression
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据增强生成房价数据标签以生成回归的合成数据
- en: Using K-means clustering to label the house price data for regression
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用K-means聚类为回归房价数据标签化
- en: By the end of this chapter, you will be able to generate labels for regression
    data using Python libraries programmatically. Furthermore, you’ll have the expertise
    required to overcome regression challenges adeptly, ensuring your data-driven
    endeavors steer toward success.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将能够使用Python库编程方式生成回归数据的标签。此外，您将具备克服回归挑战的专业技能，确保您的数据驱动项目能够成功。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will use the California house price dataset ([https://www.kaggle.com/datasets/camnugent/california-housing-prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices))
    for this chapter. You can download the `housing.csv` file from GitHub at the following
    path: [https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/datasets](https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/datasets).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用加利福尼亚房价数据集([https://www.kaggle.com/datasets/camnugent/california-housing-prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices))作为本章的内容。您可以从以下GitHub路径下载`housing.csv`文件：[https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/datasets](https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/tree/main/datasets)。
- en: 'We also need to install Python 3.7+ and set up any of the following Python
    editors:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要安装Python 3.7+并设置以下任一Python编辑器：
- en: The VS Code IDE
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VS Code IDE
- en: Anaconda
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda
- en: Jupyter Notebook
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jupyter Notebook
- en: Replit
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Replit
- en: We recommend following the complete code on GitHub to follow along with the
    chapter.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议您遵循GitHub上的完整代码来跟随本章内容。
- en: Using summary statistics to generate housing price labels
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用汇总统计生成房价标签
- en: In this section, we are going to generate house price labels using summary statistics
    of a small set of available labeled housing price data. This is useful in real-world
    projects when there is insufficient labeled data for regression tasks. In such
    scenarios, we will generate labeled data by creating some rules based on summary
    statistics.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用一小组可用的标记房价数据的摘要统计信息来生成房价标签。这在现实世界的项目中非常有用，当回归任务缺乏足够的标记数据时。在这种情况下，我们将通过基于摘要统计信息创建一些规则来生成标记数据。
- en: We decode the significance of the data’s underlying trends. By computing the
    mean of each feature within the labeled training dataset, we embark on a journey
    to quantify the essence of the data. This approach ingeniously leverages distance
    metrics to unveil the closest match for a label, bestowing unlabeled data points
    with the wisdom of their labeled counterparts.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解码数据的潜在趋势的重要性。通过计算标记训练数据集中每个特征的平均值，我们开始量化数据的本质。这种方法巧妙地利用距离度量来揭示标签的最近匹配，赋予未标记数据点其标记对应点的智慧。
- en: 'Let’s load the data from the `housing.csv` file using pandas:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 pandas 从 `housing.csv` 文件加载数据：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here’s the output:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '![Figure 3.1 – Snippet of the DataFrame](img/B18944_03_1.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1 – DataFrame的片段](img/B18944_03_1.jpg)'
- en: Figure 3.1 – Snippet of the DataFrame
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – DataFrame的片段
- en: 'After loading the labeled data using `pd.read_csv`, we then compute the summary
    statistics for each feature by target label using the `groupby()` and `describe()`
    methods. This gives us the mean, standard deviation, minimum, maximum, and quartile
    values for each feature by target label:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `pd.read_csv` 加载标记数据后，我们通过 `groupby()` 和 `describe()` 方法计算每个特征按目标标签的摘要统计信息。这为我们提供了每个特征按目标标签的平均值、标准差、最小值、最大值和四分位数：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here’s the output:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '![Figure 3.2 – Summary statistics of the house price dataset](img/B18944_03_2.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图3.2 – 房价数据集的摘要统计信息](img/B18944_03_2.jpg)'
- en: Figure 3.2 – Summary statistics of the house price dataset
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 – 房价数据集的摘要统计信息
- en: Finding the closest labeled observation to match the label
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 寻找与标签匹配的最近标记观察值
- en: 'We then loop through each row in the unlabeled data and compute the distances
    to each target label’s summary statistics using Euclidean distance. We select
    the target label with the minimum distance as the predicted target label and assign
    it to the current row:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们然后遍历未标记数据中的每一行，并使用欧几里得距离计算每个目标标签摘要统计信息的距离。我们选择距离最小的目标标签作为预测的目标标签，并将其分配给当前行：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The Euclidean distance is the distance between two points on a plane. Here,
    the distance between two points `(x1, y1)` and `(x2, y2)` is `d = √[(x2 – x1)2
    + (y2 – y1)2]`. This is used to find similar points, that is, the closest point
    to an unlabeled data point in the labeled data points, so that we can assign the
    corresponding label from the labeled dataset to the unlabeled data point. unlabeled
    dataset) is calculated by combining the distance between all the features in the
    row. We assign the target label of a row with the minimum distance from the predicted
    target label to the current row in the unlabeled dataset. This helps us to assign
    labels to the unlabeled dataset based on the closest match to the label in the
    training dataset using distance metrics.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 欧几里得距离是平面上两点之间的距离。在这里，两点 `(x1, y1)` 和 `(x2, y2)` 之间的距离是 `d = √[(x2 – x1)² +
    (y2 – y1)²]`。这用于找到相似点，即标记数据点中与未标记数据点最近的点，以便我们可以将标记数据集中的相应标签分配给未标记数据点。未标记数据集的标签是通过结合行中所有特征的距离来计算的。我们分配具有最小距离的行的目标标签，将其与未标记数据集中的当前行预测的目标标签进行比较。这有助于我们根据训练数据集中标签的最近匹配使用距离度量来分配未标记数据集的标签。
- en: 'Here, the outermost `for` loop reads one row at a time from unlabeled data
    and then performs the following steps on that row in the inner `for` loop:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，最外层的 `for` 循环逐行读取未标记数据，然后在内部 `for` 循环中对该行执行以下步骤：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The outermost `for` loop reads one row at a time from unlabeled data and then
    performs the following steps on that row in the inner `for` loop:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最外层的 `for` 循环逐行读取未标记数据，然后在内部 `for` 循环中对该行执行以下步骤：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `for target` loop iterates over each target label in the `summary_stats`
    DataFrame. The `index` attribute of a DataFrame returns the row labels, which
    in this case are the target labels:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`for target` 循环遍历 `summary_stats` DataFrame 中的每个目标标签。DataFrame 的 `index` 属性返回行标签，在这种情况下是目标标签：'
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following line initializes the `dist` variable to `0`, which we will use
    to accumulate the distance between the current unlabeled data point and the current
    target label’s summary statistics:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以下行将`dist`变量初始化为`0`，我们将使用它来累积当前未标记数据点与当前目标标签的汇总统计之间的距离：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `for col` loop iterates over each column in the `df_unlabeled` DataFrame.
    We want to compute the distance between the current unlabeled data point and each
    target label’s summary statistics for each feature.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`for col`循环遍历`df_unlabeled` DataFrame中的每一列。我们想要计算当前未标记数据点与每个目标标签的汇总统计中每个特征的距离。'
- en: 'The following line checks if the current column is not the target column. We
    don’t want to compute the distance between the current unlabeled data point and
    the summary statistics of the target column, as this would not make sense:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下行检查当前列是否不是目标列。我们不希望计算当前未标记数据点与目标列的汇总统计之间的距离，因为这没有意义：
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following line computes the squared distance between the current unlabeled
    data point’s feature value and the corresponding feature’s mean value in the current
    target label’s summary statistics. We square the distance to make it positive
    and exaggerate the differences:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下行计算当前未标记数据点的特征值与当前目标标签汇总统计中相应特征的均值之间的平方距离。我们将距离平方以使其为正并夸大差异：
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following line saves the computed distance in the `dists` dictionary for
    the current target label:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 以下行将计算的距离保存到`dists`字典中，针对当前目标标签：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: By the end of this inner loop, the `dists` dictionary will contain the squared
    distances between the current unlabeled data point and each target label’s summary
    statistics. We will then select the target label with the minimum distance as
    the predicted target label for the current data point.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 到此内循环结束时，`dists`字典将包含当前未标记数据点与每个目标标签的汇总统计之间的平方距离。然后我们将选择距离最小的目标标签作为当前数据点的预测目标标签。
- en: The same process continues for each row of the unlabeled data to compute distances
    from each of the target label’s features mean values in the summary statistics
    to the corresponding column in the unlabeled data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于未标记数据的每一行，都会继续进行相同的处理，以计算从每个目标标签的特征均值到未标记数据中相应列的距离。
- en: Finally, we save the labeled data to a new CSV file using the `to_csv()` method,
    `df_unlabeled.to_csv('housing_result.csv')`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用`to_csv()`方法将标记数据保存到新的CSV文件中，`df_unlabeled.to_csv('housing_result.csv')`。
- en: '![Figure 3.3 – Labeled data with predicted median house value](img/B18944_03_3.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3 – 带有预测中位数房价的标记数据](img/B18944_03_3.jpg)'
- en: Figure 3.3 – Labeled data with predicted median house value
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 – 带有预测中位数房价的标记数据
- en: Now, we can see that `median_house_value` is assigned to the row in the unlabeled
    dataset. Note that this approach assumes that the summary statistics of the labeled
    data can be used to predict the target labels of the unlabeled data accurately.
    Therefore, it is essential to validate the accuracy of the predictions before
    using them in practice.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看到`median_house_value`被分配到未标记数据集中的行。请注意，这种方法假设标记数据的汇总统计可以准确地预测未标记数据的目标标签。因此，在使用它们之前验证预测的准确性是至关重要的。
- en: Using semi-supervised learning to label regression data
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用半监督学习标记回归数据
- en: In this section, we are going to use semi-supervised learning to label the regression
    data. Semi-supervised learning is a type of machine learning that combines both
    labeled and unlabeled data to improve the accuracy of a predictive model. In semi-supervised
    learning, a small amount of labeled data is used with a much larger amount of
    unlabeled data to train the model. The idea is that the unlabeled data can provide
    additional information about the underlying patterns in the data that can help
    the model to learn more effectively. By using both labeled and unlabeled data,
    semi-supervised learning can improve the accuracy of machine learning models,
    especially when labeled data is scarce or expensive to obtain.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用半监督学习来标记回归数据。半监督学习是一种机器学习方法，它结合了标记数据和未标记数据以提高预测模型的准确性。在半监督学习中，使用少量标记数据与大量未标记数据来训练模型。其理念是未标记数据可以提供有关数据中潜在模式的信息，这有助于模型更有效地学习。通过使用标记数据和未标记数据，半监督学习可以提高机器学习模型的准确性，尤其是在标记数据稀缺或难以获取时。
- en: Now, let’s look in detail at the pseudo-labeling method and how it is used for
    data labeling.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们详细看看伪标记方法及其在数据标记中的应用。
- en: Pseudo-labeling
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伪标记
- en: Pseudo-labeling is a technique used in semi-supervised learning where a model
    trained on labeled data is used to predict the labels of the unlabeled data. These
    predicted labels are called pseudo-labels. The model then combines the labeled
    and pseudo-labeled data to retrain and improve the accuracy of the model. Pseudo-labeling
    is a way to leverage the unlabeled data to improve the performance of the model,
    especially when labeled data is limited.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 伪标记是一种在半监督学习中使用的技巧，其中使用在标记数据上训练的模型来预测未标记数据的标签。这些预测的标签被称为伪标签。然后，模型将标记和伪标记数据结合起来重新训练并提高模型的准确性。伪标记是一种利用未标记数据来提高模型性能的方法，尤其是在标记数据有限时。
- en: 'The pseudo-labeling process involves the following steps:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 伪标记过程包括以下步骤：
- en: '**Train a model on labeled data**: Train a supervised learning model on the
    labeled data using a training algorithm. The model is fitted to the training set
    using the provided labels.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在标记数据上训练模型**：使用训练算法在标记数据上训练一个监督学习模型。模型通过提供的标签与训练集相匹配。'
- en: '**Predict labels for unlabeled data**: Use the trained model to predict the
    labels for the unlabeled data. These predicted labels are called pseudo-labels.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测未标记数据的标签**：使用训练好的模型来预测未标记数据的标签。这些预测的标签被称为伪标签。'
- en: '**Combine labeled and pseudo-labeled data**: Combine the labeled data with
    the pseudo-labeled data to form a new, larger training set. The pseudo-labeled
    data is treated as if it were labeled data.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**合并标记和伪标记数据**：将标记数据与伪标记数据合并，形成一个新的大训练集。伪标记数据被视为标记数据。'
- en: '**Retrain the model**: Retrain the model using the combined dataset. The model
    is updated using both the labeled and pseudo-labeled data to improve the model’s
    accuracy.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**重新训练模型**：使用合并后的数据集重新训练模型。模型通过标记和伪标记数据更新，以提高模型的准确性。'
- en: '**Repeat steps 2-4**: Iterate the process by reusing the updated model to predict
    labels for new, previously unlabeled data, and combining the newly labeled data
    with the existing labeled data for the next round of model retraining, and the
    process is repeated until convergence.'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**重复步骤 2-4**：通过重复使用更新后的模型来预测新标记数据（之前未标记的数据）的标签，并将新标记的数据与现有标记数据合并，用于下一轮模型重新训练，这个过程一直重复，直到收敛。'
- en: Pseudo-labeling can be an effective way to leverage the large amount of unlabeled
    data that is typically available in many applications. By using this unlabeled
    data to improve the accuracy of the model, pseudo-labeling can help to improve
    the performance of supervised machine learning models, especially when enough
    labeled training data is not easily available.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 伪标记可以是一种有效的方法，利用许多应用中通常可用的大量未标记数据。通过使用这些未标记数据来提高模型的准确性，伪标记可以帮助提高监督机器学习模型的表现，尤其是在足够的标记训练数据不易获得时。
- en: 'Let’s use the house price dataset to predict the labels for regression:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用房价数据集来预测回归的标签：
- en: '[PRE10]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let’s load the house price dataset and then split the labeled data into the
    `labeled_data` DataFrame and unlabeled data into the `unlabeled_data` DataFrame,
    as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们加载房价数据集，然后将标记数据拆分为 `labeled_data` DataFrame，未标记数据拆分为 `unlabeled_data` DataFrame，如下所示：
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This code snippet is used to divide the labeled data into two parts: a training
    set and a testing set. The training set contains the features (input data) and
    the corresponding labels (output data) that we will use to train our machine learning
    model. The testing set is a small portion of the data that we will use to evaluate
    the model’s performance. The `train_test_split` function from the `sklearn.model_selection`
    library helps us achieve this division while specifying the size of the testing
    set (in this case, 20% of the data). Let’s train the model using the training
    dataset for regression, as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码片段用于将标记数据分为两部分：一个训练集和一个测试集。训练集包含我们将用于训练机器学习模型的特征（输入数据）和相应的标签（输出数据）。测试集是数据的一小部分，我们将用它来评估模型的性能。`train_test_split`
    函数来自 `sklearn.model_selection` 库，它帮助我们实现这种划分，同时指定测试集的大小（在这种情况下，数据的 20%）。以下是如何使用训练数据集进行回归来训练模型：
- en: '[PRE12]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In this code snippet, we’re building and training a linear regression model
    using the labeled data. First, we import the `LinearRegression` class from the
    `sklearn.linear_model` library. Then, we create an instance of the linear regression
    model named `regressor`. Finally, we train the model using the training data (`train_data`)
    as the input features and the corresponding labels (`train_labels`) as the desired
    outputs. The model learns from this data to make predictions later. Now, let’s
    predict the labels using the regressor for the unlabeled dataset, as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，我们使用标记数据构建和训练一个线性回归模型。首先，我们从`sklearn.linear_model`库中导入`LinearRegression`类。然后，我们创建一个名为`regressor`的线性回归模型实例。最后，我们使用训练数据`train_data`作为输入特征和相应的标签`train_labels`作为期望的输出来训练模型。模型从这些数据中学习以进行后续的预测。现在，让我们使用回归器对未标记数据集进行标签预测，如下所示：
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In this code snippet, we’re employing the trained linear regression model to
    predict labels for unlabeled data points. We initialize an empty list, `predicted_labels`,
    to store the predictions. By applying the `predict` method of the trained `regressor`
    model, we generate predictions based on the features (input data) in the `unlabeled_data`.
    The `price` column is excluded since it’s the target variable we want to predict.
    The `predicted_labels` list now holds the predicted outcomes of the regression
    model for the unlabeled data. Now we will combine this predicted labeled data
    with the labeled data and train the model, as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，我们使用训练好的线性回归模型来预测未标记数据点的标签。我们初始化一个空列表`predicted_labels`来存储预测结果。通过应用训练好的`regressor`模型的`predict`方法，我们根据`unlabeled_data`中的特征（输入数据）生成预测。由于`price`列是我们想要预测的目标变量，因此将其排除。现在`predicted_labels`列表包含了回归模型对未标记数据的预测结果。现在我们将这些预测的标签数据与标记数据结合起来，并按照以下方式训练模型：
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this code snippet, we’re creating a new dataset, `new_data`, by combining
    the labeled and the newly predicted data. First, we use `pd.concat` to concatenate
    the `labeled_data` and `unlabeled_data` dataframes, creating a continuous dataset.
    The `ignore_index=True` argument ensures that the index is reset for the new dataset.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，我们通过合并标记数据和新预测的数据创建一个新的数据集`new_data`。首先，我们使用`pd.concat`将`labeled_data`和`unlabeled_data`数据框连接起来，创建一个连续的数据集。`ignore_index=True`参数确保新数据集的索引被重置。
- en: 'Next, we’re populating the `''price''` column in the `new_data` DataFrame.
    We achieve this by concatenating the `train_labels` (from the labeled data) with
    the predicted labels stored in the `predicted_labels` list. This step ensures
    that our new dataset has complete labels for all data points, combining both known
    and predicted values:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在`new_data` DataFrame中填充`'price'`列。我们通过将`train_labels`（来自标记数据）与存储在`predicted_labels`列表中的预测标签连接起来来实现这一点。这一步确保我们的新数据集对所有数据点都有完整的标签，结合了已知和预测的值：
- en: '[PRE15]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In this code snippet, we’re training a new linear regression model on the combined
    dataset that includes both the labeled and predicted data. First, we split the
    combined data into new training and testing sets using the `train_test_split`
    function, similar to what we did before. The new training data is stored in `new_train_data`,
    and the corresponding labels are stored in `new_train_labels`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，我们在一个包含标记和预测数据的组合数据集上训练一个新的线性回归模型。首先，我们使用`train_test_split`函数将组合数据分割成新的训练和测试集，类似于我们之前所做的那样。新的训练数据存储在`new_train_data`中，相应的标签存储在`new_train_labels`中。
- en: 'Next, we create a new instance of the linear regression model called `new_regressor`.
    Finally, we train the new model using `new_train_data` as input features and `new_train_labels`
    as the desired outputs. This step ensures that our new model is fine-tuned to
    predict the combined data, leveraging both labeled and predicted information:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个新的线性回归模型实例，称为`new_regressor`。最后，我们使用`new_train_data`作为输入特征和`new_train_labels`作为期望的输出来训练新模型。这一步确保我们的新模型经过微调以预测组合数据，利用了标记和预测信息：
- en: '[PRE16]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here’s the output:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '![Figure 3.4 – Performance of the model after adding pseudo-labeled data](img/B18944_03_4.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图3.4 – 添加伪标签数据后的模型性能](img/B18944_03_4.jpg)'
- en: Figure 3.4 – Performance of the model after adding pseudo-labeled data
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 – 添加伪标签数据后的模型性能
- en: In this code snippet, we’re evaluating the performance of the new linear regression
    model on the test data that it hasn’t seen during training. The R-squared(coefficient
    of determination) score is calculated using the `score` method of the `new_regressor`
    model. The R^2 score is a measure of how well the model’s predictions match the
    actual data values. Higher R^2 scores indicate better predictive accuracy.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，我们正在评估新的线性回归模型在训练过程中未见过的测试数据上的性能。R-squared（确定系数）分数是通过`new_regressor`模型的`score`方法计算的。R^2分数是衡量模型预测与实际数据值匹配程度的一个指标。更高的R^2分数表示更好的预测准确性。
- en: As we can see, the R^2 score is higher (`0.6905783112767134`) with the combined
    dataset than with the original labeled trained dataset (`0.624186740765541`).
    Finally, we use this model to predict the labels. Now, let’s see another method,
    data augmentation, to generate synthetic data with labels for regression.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，结合数据集的R^2分数（`0.6905783112767134`）比原始标记训练数据集的R^2分数（`0.624186740765541`）要高。最后，我们使用这个模型来预测标签。现在，让我们看看另一种方法，即数据增强，用于为回归生成带有标签的合成数据。
- en: Using data augmentation to label regression data
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数据增强来标记回归数据
- en: 'Data augmentation can be used to generate additional labeled data for regression
    tasks where labeled data is limited. Here is a way to use data augmentation to
    label regression data:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强可以用于为回归任务生成额外的标记数据，其中标记数据有限。以下是使用数据增强来标记回归数据的方法：
- en: '**Collect labeled data**: Collect the limited labeled data available for the
    regression task.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**收集标记数据**：收集可用于回归任务的有限标记数据。'
- en: '**Define data augmentation techniques**: Define a set of data augmentation
    techniques that can be used to generate new data points from the available labeled
    data. For regression tasks, common data augmentation techniques include adding
    noise, scaling, and rotating the data.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定义数据增强技术**：定义一组可以用于从可用标记数据生成新数据点的数据增强技术。对于回归任务，常见的数据增强技术包括添加噪声、缩放和旋转数据。'
- en: '**Generate augmented data**: Use data augmentation techniques to generate new
    data points from the available labeled data. The new data points will have labels
    based on the labels of the original data points.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生成增强数据**：使用数据增强技术从可用标记数据生成新的数据点。新的数据点将基于原始数据点的标签。'
- en: '**Train the model**: Train a regression model using the augmented data and
    the original labeled data. This step involves fitting a model to the combined
    dataset using a supervised learning algorithm.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练模型**：使用增强数据和原始标记数据训练一个回归模型。这一步涉及到使用监督学习算法将模型拟合到组合数据集。'
- en: '**Evaluate the model**: Evaluate the performance of the trained model on a
    validation set. This step involves testing the accuracy of the model’s predictions
    on new, unseen data.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估模型**：在验证集上评估训练模型的性能。这一步涉及到测试模型预测在新的、未见过的数据上的准确性。'
- en: '**Fine-tune the model**: Fine-tune the model based on the performance on the
    validation set. This step involves adjusting the model’s hyperparameters to improve
    its performance on the validation set.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**微调模型**：根据验证集上的性能来微调模型。这一步涉及到调整模型的超参数，以提高其在验证集上的性能。'
- en: '**Test the model**: Finally, test the model’s performance on a test set to
    evaluate its generalization performance.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**测试模型**：最后，在测试集上测试模型的性能，以评估其泛化性能。'
- en: By using data augmentation to generate additional labeled data, it is possible
    to train a more accurate regression model even when limited labeled data is available.
    However, it is important to be careful when using data augmentation techniques
    to ensure that the generated data is meaningful and representative of the original
    data distribution.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用数据增强来生成额外的标记数据，即使在有限的标记数据可用的情况下，也有可能训练出一个更准确的回归模型。然而，在使用数据增强技术时，必须小心谨慎，以确保生成数据是有意义且代表原始数据分布的。
- en: 'In the context of numerical data, we should focus on the following data augmentation
    techniques that are relevant and meaningful for the given dataset. For example,
    we can consider the following:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在数值数据的背景下，我们应该关注以下与给定数据集相关且有意义的数据增强技术。例如，我们可以考虑以下：
- en: '**Adding noise**: Adding random noise to numerical features and labels can
    simulate variations and uncertainties in the data'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**添加噪声**：向数值特征和标签添加随机噪声可以模拟数据中的变化和不确定性。'
- en: '**Scaling**: Scaling numerical features can simulate changes in units or magnitudes'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缩放**：缩放数值特征可以模拟单位或量级的改变'
- en: '**Jittering**: Introducing small perturbations to numerical values can account
    for measurement errors or fluctuations'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**抖动**：向数值引入小的扰动可以解释测量误差或波动'
- en: '**Outlier injection**: Introducing outliers can help the model become more
    robust to extreme values'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值注入**：引入异常值可以帮助模型对极端值更加鲁棒'
- en: '**Shuffling**: Randomly shuffling the order of data points can prevent the
    model from learning any sequence-related bias'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**洗牌**：随机打乱数据点的顺序可以防止模型学习任何与序列相关的偏差'
- en: Remember that the choice of data augmentation techniques should be based on
    the characteristics of your dataset and the problem you’re trying to solve. The
    techniques should add meaningful variations that align with the nature of your
    data.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，数据增强技术的选择应基于您的数据集和您试图解决的问题的特征。这些技术应添加与数据本质相符的有意义的变异。
- en: 'Let’s see how we generate augmented data for the house price dataset to predict
    labels. Let’s import the necessary libraries, load the house price dataset, and
    define the `noise`, `scale`, and `rotate` data augmentation functions, as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何为房价数据集生成增强数据以预测标签。让我们导入必要的库，加载房价数据集，并定义 `noise`、`scale` 和 `rotate`
    数据增强函数，如下所示：
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Then we load the labeled data stored in a CSV file named `labeled_data.csv`
    with columns for the features and a column named `price` for the target variable:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们加载存储在名为 `labeled_data.csv` 的 CSV 文件中的标记数据，该文件具有特征列和一个名为 `price` 的列作为目标变量：
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The following code defines two data augmentation techniques that add noise.
    It generates new data points by applying these augmentation techniques to the
    labeled data:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码定义了两种添加噪声的数据增强技术。它通过将这些增强技术应用于标记数据来生成新的数据点：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The range of data augmentation parameters for noise range is defined, and for
    each available data point, it generates multiple augmented data points with different
    parameter values:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了噪声范围的增强参数范围，并且对于每个可用的数据点，它使用不同的参数值生成多个增强数据点：
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: By iterating through each value in `noise_range` and adding noise to each data
    point’s `price` feature, the code generates multiple data points with different
    levels of noise. This process results in more labeled data points for the machine
    learning model to learn from and improves the model’s accuracy.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遍历 `noise_range` 中的每个值并向每个数据点的 `price` 特征添加噪声，代码生成了具有不同噪声级别的多个数据点。这个过程产生了更多标记数据点供机器学习模型学习，并提高了模型的准确性。
- en: '`noise_range` is a list of standard deviation values for generating different
    levels of noise. It could be any list of values to add different levels of noise
    to the data points:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`noise_range` 是用于生成不同级别噪声的标准差值的列表。它可以是对数据点添加不同级别噪声的任何值列表：'
- en: '`for noise in noise_range` creates a loop that iterates through each value
    in the `noise_range` list.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`for noise in noise_range` 创建一个循环，遍历 `noise_range` 列表中的每个值。'
- en: '`new_row = row.copy()` creates a copy of the original data point (i.e., row).'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`new_row = row.copy()` 创建原始数据点（即行）的副本。'
- en: '`new_row["price"] = add_noise(row["price"], noise)` adds noise to the copied
    data point’s `price` feature using the `add_noise()` function. The `add_noise()`
    function adds random noise to each data point based on the standard deviation
    provided in the `noise` variable.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`new_row["price"] = add_noise(row["price"], noise)` 使用 `add_noise()` 函数向复制的数据点的
    `price` 特征添加噪声。`add_noise()` 函数根据 `noise` 变量中提供的不确定性向每个数据点添加随机噪声。'
- en: '`augmented_data.append(new_row)` appends the newly generated data point to
    the `augmented_data` list. The `augmented_data` list contains all the newly generated
    data points for all levels of noise in the `noise_range` list.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`augmented_data.append(new_row)` 将新生成的数据点添加到 `augmented_data` 列表中。`augmented_data`
    列表包含 `noise_range` 列表中所有级别的噪声的所有新生成数据点。'
- en: 'Similarly, let’s define another data augmentation scale function:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，让我们定义另一个数据增强比例函数：
- en: '[PRE21]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The range of parameters for `scale_range` is defined, and for each available
    data point, it generates multiple augmented data points with different parameter
    values:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了 `scale_range` 的参数范围，并且对于每个可用的数据点，它使用不同的参数值生成多个增强数据点：
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In this code snippet, we’re utilizing data augmentation to generate augmented
    data by applying scaling to the `price` feature. For each scale factor within
    the specified `scale_range`, we duplicate the current data row by creating a copy
    of it using `row.copy()`. Then, we apply scaling to the `price` feature using
    `scale_factor`, effectively modifying the price values while preserving the data’s
    relationships.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，我们正在利用数据增强技术，通过对`price`特征应用缩放来生成增强数据。对于指定的`scale_range`内的每个缩放因子，我们通过使用`row.copy()`创建当前数据行的副本来重复当前数据行。然后，我们使用`scale_factor`对`price`特征进行缩放，从而有效地修改价格值，同时保留数据之间的关系。
- en: 'Finally, the augmented row is added to the list of augmented data stored in
    the `augmented_data` list. This approach empowers us to explore how varying scales
    affect the `price` feature and enrich our dataset with diverse instances for improved
    model training and testing:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，增强行被添加到存储在`augmented_data`列表中的增强数据列表中。这种方法使我们能够探索不同缩放对`price`特征的影响，并通过具有不同实例的数据集丰富我们的数据集，以改善模型训练和测试：
- en: '[PRE23]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here’s the augmented data:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是增强数据：
- en: '![Figure 3.5 – Original data and augmented data](img/B18944_03_5.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图3.5 – 原始数据和增强数据](img/B18944_03_5.jpg)'
- en: Figure 3.5 – Original data and augmented data
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – 原始数据和增强数据
- en: 'The code then combines the original labeled data with the augmented data, splits
    it into training and testing sets, trains a linear regression model on the combined
    data, and evaluates the model’s performance on the test set using mean squared
    error as the evaluation metric:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后代码将原始标记数据与增强数据结合，将其分为训练集和测试集，在组合数据上训练线性回归模型，并使用均方误差作为评估指标在测试集上评估模型的性能：
- en: '[PRE24]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: By iterating through each value in `noise_range` and adding noise to each available
    data point, it generates multiple augmented data points with different levels
    of noise. This process results in more labeled data points for the machine learning
    model to learn from and improves the model’s accuracy. Similarly, scale factor
    and rotation degree are used to generate labeled data using data augmentation
    to predict house prices using regression.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遍历`noise_range`中的每个值并向每个可用数据点添加噪声，它生成了具有不同噪声级别的多个增强数据点。这个过程产生了更多标记数据点供机器学习模型学习，并提高了模型的准确性。同样，缩放因子和旋转度数也用于通过数据增强生成标记数据，以使用回归预测房价。
- en: In this section, we have seen how to generate the augmented data using noise
    and scale techniques for regression. Now, let’s see how we can use the K-means
    clustering unsupervised learning method to label the house price data.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了如何使用噪声和缩放技术生成用于回归的增强数据。现在，让我们看看我们如何使用K-means无监督学习方法来标记房价数据。
- en: Using k-means clustering to label regression data
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用k-means聚类标记回归数据
- en: In this section, we are going to use the unsupervised K-means clustering method
    to label the regression data. We use K-means to cluster data points into groups
    or clusters based on their similarity.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用无监督的K-means聚类方法来标记回归数据。我们使用K-means根据数据点的相似性将数据点聚类成组或簇。
- en: Once the clustering is done, we can compute the average label value for each
    cluster by taking the mean of the labeled data points that belong to that cluster.
    This is because the labeled data points in a cluster are likely to have similar
    label values since they are similar in terms of their feature values.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦聚类完成，我们可以通过取属于该簇的标记数据点的平均值来计算每个簇的平均标签值。这是因为簇中的标记数据点可能具有相似的标签值，因为它们在特征值方面相似。
- en: '![Figure 3.6 – Basic k-means clustering with no. of clusters =3](img/B18944_03_6.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图3.6 – 基本k-means聚类，聚类数量=3](img/B18944_03_6.jpg)'
- en: Figure 3.6 – Basic k-means clustering with no. of clusters =3
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 – 基本k-means聚类，聚类数量=3
- en: For example, let’s say we have a dataset of house prices with which we want
    to predict the price of a house based on features such as size, location, number
    of rooms, and so on. We have some labeled data points that consist of the features
    and their corresponding prices, but we also have some unlabeled data points with
    the same features.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有一个包含房价的房价数据集，我们想要根据大小、位置、房间数量等特征预测房屋的价格。我们有一些带有特征及其对应价格的标记数据点，但我们也有一些具有相同特征的未标记数据点。
- en: We can use K-means clustering to cluster the labeled and unlabeled data points
    into groups based on their features. Then, we can compute the average price for
    each cluster by taking the mean of the labeled data points in that cluster.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用K-means聚类根据特征将标记和未标记的数据点聚类成组。然后，我们可以通过取该聚类中标记数据点的平均值来计算每个聚类的平均价格。
- en: Finally, we can use these average prices to predict the prices of the unlabeled
    data points based on their cluster assignment.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用这些平均价格根据它们的聚类分配预测未标记数据点的价格。
- en: 'We can use these predicted labels to create a new dataset by combining the
    labeled and unlabeled data. We then train a new model on the combined data and
    evaluate its performance on the test data:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这些预测标签通过结合标记和未标记数据创建一个新的数据集。然后，我们在组合数据上训练一个新的模型，并在测试数据上评估其性能：
- en: '[PRE25]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Here, we import the necessary libraries and define the labeled and unlabeled
    data arrays:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们导入必要的库并定义标记的和未标记的数据数组：
- en: '[PRE26]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We specify the number of clusters (`n_clusters`) and use k-means clustering
    to fit the model to the labeled features:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们指定聚类数量（`n_clusters`）并使用k-means聚类将模型拟合到标记特征：
- en: '[PRE27]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We predict cluster labels for the unlabeled data using the trained k-means
    model:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用训练好的k-means模型预测未标记数据的聚类标签：
- en: '[PRE28]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We calculate the average prices for each cluster by iterating through cluster
    indices and calculating the mean of the labeled prices for each cluster.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过遍历聚类索引并计算每个聚类的标记价格的平均值来计算每个聚类的平均价格。
- en: The line `cluster_mask = (kmeans_model.labels_ == cluster_idx)` creates a boolean
    mask that identifies the data points in a specific cluster.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 行`cluster_mask = (kmeans_model.labels_ == cluster_idx)`创建了一个布尔掩码，用于识别特定聚类中的数据点。
- en: 'Here’s a breakdown of what each part of the line does:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是这一行每个部分的作用：
- en: '`kmeans_model.labels_`: This is an attribute of the K-means model that contains
    the cluster labels assigned to each data point during the clustering process.
    Each value in `kmeans_model.labels_` corresponds to the cluster label assigned
    to the corresponding data point in the order they appear in the input data.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kmeans_model.labels_`：这是K-means模型的一个属性，包含在聚类过程中分配给每个数据点的聚类标签。`kmeans_model.labels_`中的每个值对应于在输入数据中出现顺序中分配给对应数据点的聚类标签。'
- en: '`cluster_idx`: This is the index of the cluster you’re interested in, ranging
    from 0 to the number of clusters minus one. It’s used to specify which cluster
    you want to create the mask for.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster_idx`：这是你感兴趣的聚类的索引，范围从0到聚类数量减一。它用于指定你想为哪个聚类创建掩码。'
- en: '`kmeans_model.labels_ == cluster_idx`: This part creates a boolean array where
    each element is `True` if the corresponding data point’s cluster label is equal
    to `cluster_idx`, and `False` otherwise. Essentially, it’s checking which data
    points belong to the specific cluster of interest.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kmeans_model.labels_ == cluster_idx`：这部分创建了一个布尔数组，其中每个元素如果对应的点的聚类标签等于`cluster_idx`则为`True`，否则为`False`。本质上，它是在检查哪些数据点属于感兴趣的特定聚类。'
- en: '`cluster_mask`: This is the resulting boolean mask that identifies the data
    points belonging to the cluster with the index `cluster_idx`.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster_mask`：这是识别属于索引`cluster_idx`的聚类的数据点的布尔掩码。'
- en: 'In summary, the line `cluster_mask = (kmeans_model.labels_ == cluster_idx)`
    creates a mask that helps you filter and select the data points in a specific
    cluster based on their assigned cluster labels. This mask can then be used to
    perform various operations on the data points belonging to that cluster. Predicted
    prices are assigned to the unlabeled data based on the calculated cluster average
    prices:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，行`cluster_mask = (kmeans_model.labels_ == cluster_idx)`创建了一个掩码，有助于根据分配的聚类标签过滤和选择特定聚类的数据点。这个掩码可以用来对属于该聚类的数据点执行各种操作。根据计算出的聚类平均价格，将预测价格分配给未标记数据：
- en: '[PRE29]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Finally, we display the predicted prices for the unlabeled data using the K-means
    clustering technique, providing insights into the potential housing prices for
    the unlabeled samples.:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用K-means聚类技术显示未标记数据的预测价格，从而为未标记样本提供潜在房价的见解：
- en: '[PRE30]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Here’s the output for the predicted labels:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预测标签的输出：
- en: '![Figure 3.7 – Predicted price for unlabeled data based on the mean value of
    the labeled data cluster](img/B18944_03_7.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图3.7 – 基于标记数据聚类平均值的未标记数据预测价格](img/B18944_03_7.jpg)'
- en: Figure 3.7 – Predicted price for unlabeled data based on the mean value of the
    labeled data cluster
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 – 基于标记数据聚类平均值的未标记数据预测价格
- en: 'As shown in the output, we can predict the house price for unlabeled data using
    K-means clustering when there is a scarce training dataset. Then, we can combine
    the predicted labeled dataset and the original training dataset to fit the model
    using regression:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如输出所示，当训练数据集稀缺时，我们可以使用K-means聚类来预测未标记数据的房价。然后，我们可以将预测的标记数据集和原始训练数据集结合起来，使用回归来拟合模型：
- en: '[PRE31]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Overall, we have seen how clustering can be used in unsupervised learning to
    generate labels for unlabeled data. By computing the average label value for each
    cluster, we can effectively assign labels to the unlabeled data points based on
    their similarity to the labeled data.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，我们已经看到了如何将聚类应用于无监督学习，为未标记数据生成标签。通过计算每个聚类的平均标签值，我们可以根据它们与标记数据的相似性，有效地为未标记数据点分配标签。
- en: Summary
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have explored a range of techniques to tackle the challenge
    of data labeling in regression tasks. We began by delving into the power of summary
    statistics, harnessing the mean of each feature in the labeled dataset to predict
    labels for unlabeled data. This technique not only simplifies the labeling process
    but also introduces a foundation for accurate predictions.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探索了一系列技术来解决回归任务中数据标记的挑战。我们首先深入研究了汇总统计的力量，利用标记数据集中每个特征的均值来预测未标记数据的标签。这项技术不仅简化了标记过程，还为准确预测奠定了基础。
- en: Further enriching our labeling arsenal, we ventured into semi-supervised learning,
    leveraging a small set of labeled data to generate pseudo-labels. The amalgamation
    of genuine and pseudo-labels in model training not only extends our labeled data
    but also equips our models to make more informed predictions for unlabeled data.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步丰富我们的标记工具库，我们探索了半监督学习，利用一小部分标记数据生成伪标签。在模型训练中将真实标签和伪标签的融合不仅扩展了我们的标记数据，还使我们的模型能够为未标记数据做出更明智的预测。
- en: Data augmentation has emerged as a vital tool in enhancing regression data.
    Techniques such as scaling and noise injection have breathed new life into our
    dataset, providing varied instances that empower models to discern patterns better
    and boost prediction accuracy.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强已成为增强回归数据的重要工具。诸如缩放和噪声注入等技术为我们的数据集注入了新的活力，提供了多样化的实例，使模型能够更好地识别模式并提高预测精度。
- en: The utilization of k-means clustering rounded off our exploration, as we ventured
    into grouping data into clusters and assigning labels based on cluster mean values.
    This approach not only saves time but also bolsters the prediction precision of
    our models.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 利用k-means聚类完成了我们的探索，因为我们尝试将数据分组到簇中，并根据簇的均值值分配标签。这种方法不仅节省了时间，还提高了我们模型预测的精确度。
- en: The key takeaways from this chapter are that summary statistics simplify data
    labeling by leveraging means and distances. Semi-supervised learning merges genuine
    and pseudo-labels for comprehensive training. Data augmentation techniques such
    as scaling and noise addition enrich and diversify datasets. K-means clustering
    optimizes labeling by grouping data into clusters and assigning cluster-wide mean
    labels.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的关键要点是，汇总统计通过利用均值和距离简化了数据标记。半监督学习通过合并真实标签和伪标签进行综合训练。数据增强技术如缩放和噪声添加丰富了数据集并增加了多样性。K-means聚类通过将数据分组到簇中并分配簇的均值标签来优化标记。
- en: These acquired skills bestow resilience and versatility to our regression models,
    instilling them with the ability to handle real-world, unlabeled data effectively.
    In the next chapter, we’ll delve into the exploratory data analysis of image data
    in machine learning.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这些获得的技术赋予我们的回归模型弹性和多功能性，使它们能够有效地处理现实世界中的未标记数据。在下一章中，我们将深入探讨机器学习中图像数据的探索性数据分析。
- en: 'Part 2: Labeling Image Data'
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2部分：标记图像数据
- en: In this part of the book, you will learn how to analyze image data, extract
    features from images, and label images using Python libraries such as Snorkel.
    The content also covers various methods of image data augmentation, along with
    the utilization of **support vector machine** (**SVM**), **convolutional** **neural
    network** (**CNN**), and pre-trained models such as YOLO for image classification
    and labeling.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的这一部分，您将学习如何分析图像数据，从图像中提取特征，并使用Python库如Snorkel来标记图像。内容还涵盖了图像数据增强的各种方法，以及利用**支持向量机**（**SVM**）、**卷积****神经网络**（**CNN**）和预训练模型如YOLO进行图像分类和标记的应用。
- en: 'This part comprises the following chapters:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 4*](B18944_04.xhtml#_idTextAnchor081), *Exploring Image Data*'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第4章*](B18944_04.xhtml#_idTextAnchor081), *探索图像数据*'
- en: '[*Chapter 5*](B18944_05.xhtml#_idTextAnchor104), *Labeling Image Data Using
    Rules*'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B18944_05.xhtml#_idTextAnchor104), *使用规则标注图像数据*'
- en: '[*Chapter 6*](B18944_06.xhtml#_idTextAnchor124), *Labeling Image Data Using
    Data Augmentation*'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B18944_06.xhtml#_idTextAnchor124), *使用数据增强标注图像数据*'
