- en: Chapter 10. Computer Vision
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章 计算机视觉
- en: Image analysis and computer vision have always been important in industrial
    and scientific applications. With the popularization of cell phones with powerful
    cameras and Internet connections, images now are increasingly generated by consumers.
    Therefore, there are opportunities to make use of computer vision to provide a
    better user experience in new contexts.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分析和计算机视觉一直在工业和科学应用中占有重要地位。随着拥有强大相机和互联网连接的手机的普及，图像现在越来越多地由消费者生成。因此，利用计算机视觉为新情境中的用户体验提供更好的服务，成为了一个机会。
- en: In this chapter, we will look at how to apply techniques you have learned in
    the rest of this book to this specific type of data. In particular, we will learn
    how to use the mahotas computer vision package to extract features from images.
    These features can be used as input to the same classification methods we studied
    in other chapters. We will apply these techniques to publicly available datasets
    of photographs. We will also see how the same features can be used on another
    problem, that is, the problem of finding similar looking images.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何将你在本书其余部分学到的技术应用到这种特定类型的数据上。具体来说，我们将学习如何使用mahotas计算机视觉包从图像中提取特征。这些特征可以作为我们在其他章节中学习的分类方法的输入。我们将这些技术应用于公开可用的照片数据集。我们还将看到这些相同的特征如何用于另一个问题，即寻找相似图像的问题。
- en: Finally, at the end of this chapter, we will learn about using local features.
    These are relatively new methods (the first of these methods to achieve state-of-the-art
    performance, the **scale-invariant feature transform** (**SIFT**), was introduced
    in 1999) and achieve very good results in many tasks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在本章的结尾，我们将学习如何使用局部特征。这些方法相对较新（其中第一种取得最新成果的方法，即**尺度不变特征变换**（**SIFT**），是在1999年提出的），并在许多任务中取得了非常好的效果。
- en: Introducing image processing
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍图像处理
- en: From the point of view of the computer, an image is a large rectangular array
    of pixel values. Our goal is to process this image and to arrive at a decision
    for our application.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 从计算机的角度来看，图像是一个由像素值组成的大型矩形数组。我们的目标是处理这个图像，并为我们的应用程序做出决策。
- en: The first step will be to load the image from disk, where it is typically stored
    in an image-specific format such as PNG or JPEG, the former being a lossless compression
    format, and the latter a lossy compression one that is optimized for visual assessment
    of photographs. Then, we may wish to perform preprocessing on the images (for
    example, normalizing them for illumination variations).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是从磁盘加载图像，图像通常以PNG或JPEG等图像特定格式存储，前者是一种无损压缩格式，后者是一种有损压缩格式，优化了对照片的视觉评估。然后，我们可能希望对图像进行预处理（例如，对其进行归一化，以适应光照变化）。
- en: We will have a classification problem as a driver for this chapter. We want
    to be able to learn a support vector machine (or other) classifier that can be
    trained from images. Therefore, we will use an intermediate representation, extracting
    numeric features from the images before applying machine learning.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将以分类问题为驱动。我们希望能够学习一个支持向量机（或其他）分类器，能够从图像中进行训练。因此，我们将使用一个中间表示，在应用机器学习之前，从图像中提取数值特征。
- en: Loading and displaying images
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载和显示图像
- en: In order to manipulate images, we will use a package called mahotas. You can
    obtain mahotas from [https://pypi.python.org/pypi/mahotas](https://pypi.python.org/pypi/mahotas)
    and read its manual at [http://mahotas.readthedocs.org](http://mahotas.readthedocs.org).
    Mahotas is an open source package (MIT license, so it can be used in any project)
    that was developed by one of the authors of this book. Fortunately, it is based
    on NumPy. The NumPy knowledge you have acquired so far can be used for image processing.
    There are other image packages, such as scikit-image (skimage), the ndimage (n-dimensional
    image) module in SciPy, and the Python bindings for OpenCV. All of these work
    natively with NumPy arrays, so you can even mix and match functionality from different
    packages to build a combined pipeline.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了操作图像，我们将使用一个名为mahotas的软件包。你可以从[https://pypi.python.org/pypi/mahotas](https://pypi.python.org/pypi/mahotas)获取mahotas，并在[http://mahotas.readthedocs.org](http://mahotas.readthedocs.org)阅读其手册。Mahotas是一个开源软件包（MIT许可，因此可以在任何项目中使用），由本书的作者之一开发。幸运的是，它是基于NumPy的。你迄今为止学到的NumPy知识可以用于图像处理。还有其他图像处理软件包，例如scikit-image（skimage）、SciPy中的ndimage（n维图像）模块和OpenCV的Python绑定。所有这些都可以原生支持NumPy数组，因此你甚至可以将来自不同软件包的功能混合使用，构建一个综合的处理管道。
- en: 'We start by importing mahotas, with the `mh` abbreviation, which we will use
    throughout this chapter, as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入mahotas库，并使用`mh`作为缩写，这将在本章中一直使用，如下所示：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, we can load an image file using `imread` as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`imread`来加载图像文件，如下所示：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `scene00.jpg` file (this file is contained in the dataset available on this
    book's companion code repository) is a color image of height `h` and width `w`;
    the image will be an array of shape `(h, w, 3)`. The first dimension is the height,
    the second is the width, and the third is red/green/blue. Other systems put the
    width in the first dimension, but this is the convention that is used by all NumPy-based
    packages. The type of the array will typically be `np.uint8` (an unsigned 8-bit
    integer). These are the images that your camera takes or that your monitor can
    fully display.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '`scene00.jpg`文件（该文件包含在本书附带的代码仓库数据集中）是一个高度为`h`、宽度为`w`的彩色图像；该图像将是一个形状为`(h, w,
    3)`的数组。第一个维度是高度，第二个是宽度，第三个是红/绿/蓝。其他系统将宽度放在第一个维度，但这是所有基于NumPy的包使用的惯例。数组的类型通常是`np.uint8`（无符号8位整数）。这些是您的相机拍摄的图像，或者是您的显示器能够完全显示的图像。'
- en: Some specialized equipment, used in scientific and technical applications, can
    take images with higher bit resolution (that is, with more sensitivity to small
    variations in brightness). Twelve or sixteen bits are common in this type of equipment.
    Mahotas can deal with all these types, including floating point images. In many
    computations, even if the original data is composed of unsigned integers, it is
    advantageous to convert to floating point numbers in order to simplify handling
    of rounding and overflow issues.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一些专业设备，常用于科学和技术应用中，可以拍摄具有更高位深度的图像（即对亮度变化更加敏感）。这种设备中，12位或16位是常见的位深。Mahotas可以处理所有这些类型的图像，包括浮点图像。在许多计算中，即使原始数据是无符号整数，转换为浮点数仍然有助于简化处理舍入和溢出问题。
- en: Note
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Mahotas can use a variety of different input/output backends. Unfortunately,
    none of them can load all image formats that exist (there are hundreds, with several
    variations of each). However, loading PNG and JPEG images is supported by all
    of them. We will focus on these common formats and refer you to the mahotas documentation
    on how to read uncommon formats.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Mahotas支持多种不同的输入/输出后端。遗憾的是，它们没有一个能够加载所有存在的图像格式（存在数百种格式，并且每种格式都有多个变体）。然而，PNG和JPEG格式的图像是所有后端都支持的。我们将重点介绍这些常见格式，并参考mahotas文档，了解如何读取不常见的格式。
- en: 'We can display the image on screen using matplotlib, the plotting library we
    have already used several times, as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用matplotlib来显示图像，这个我们已经多次使用过的绘图库，如下所示：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As shown in the following, this code shows the image using the convention that
    the first dimension is the height and the second the width. It correctly handles
    color images as well. When using Python for numerical computation, we benefit
    from the whole ecosystem working well together: mahotas works with NumPy arrays,
    which can be displayed with matplotlib; later we will compute features from images
    to use with scikit-learn.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示，这段代码展示了图像，遵循的惯例是第一个维度为高度，第二个维度为宽度。它也正确处理彩色图像。当使用Python进行数值计算时，我们可以受益于整个生态系统的良好协同工作：mahotas与NumPy数组兼容，这些数组可以通过matplotlib显示；稍后我们将从图像中计算特征，以便与scikit-learn一起使用。
- en: '![Loading and displaying images](img/2772OS_10_01.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![加载和显示图像](img/2772OS_10_01.jpg)'
- en: Thresholding
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阈值处理
- en: '**Thresholding** is a very simple operation: we transform all pixel values
    above a certain threshold to `1` and all those below it to `0` (or by using Booleans,
    transform it to `True` and `False`). The important question in thresholding is
    to select a good value to use as the threshold limit. Mahotas implements a few
    methods for choosing a threshold value from the image. One is called **Otsu**,
    after its inventor. The first necessary step is to convert the image to grayscale,
    with `rgb2gray` in the `mahotas.colors` submodule.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**阈值处理**是一种非常简单的操作：我们将所有高于某个阈值的像素值转换为`1`，将低于该阈值的像素值转换为`0`（或者使用布尔值，将其转换为`True`和`False`）。阈值处理中的一个重要问题是选择一个合适的阈值作为分界线。Mahotas实现了一些从图像中选择阈值的方法。其中一种方法叫做**Otsu**，以其发明者命名。第一个必要的步骤是使用`mahotas.colors`子模块中的`rgb2gray`将图像转换为灰度图像。'
- en: Instead of `rgb2gray`, we could also have just the mean value of the red, green,
    and blue channels, by callings `image.mean(2)`. The result, however, would not
    be the same, as `rgb2gray` uses different weights for the different colors to
    give a subjectively more pleasing result. Our eyes are not equally sensitive to
    the three basic colors.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用红色、绿色和蓝色通道的平均值来代替 `rgb2gray`，方法是调用 `image.mean(2)`。然而，结果会有所不同，因为 `rgb2gray`
    为不同的颜色使用了不同的权重，以得到更为主观上更令人愉悦的结果。我们的眼睛对三种基本颜色的敏感度并不相同。
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'By default, matplotlib will display this single-channel image as a false color
    image, using red for high values and blue for low values. For natural images,
    a grayscale is more appropriate. You can select it with:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，matplotlib 会将这张单通道图像显示为伪彩色图像，使用红色表示高值，蓝色表示低值。对于自然图像，灰度图像更加合适。你可以通过以下方式选择灰度显示：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now the image is shown in gray scale. Note that only the way in which the pixel
    values are interpreted and shown has changed and the image data is untouched.
    We can continue our processing by computing the threshold value:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在图像已显示为灰度图像。请注意，仅仅是像素值的解释和显示方式发生了变化，图像数据本身没有被改变。我们可以继续处理，通过计算阈值：
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'When applied to the previous screenshot, this method finds the threshold to
    be 138, which separates the ground from the sky above, as shown in the following
    image:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用到之前的截图时，这种方法找到了阈值为 138，它将地面与上方的天空分开，如下图所示：
- en: '![Thresholding](img/2772OS_10_03.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![阈值化](img/2772OS_10_03.jpg)'
- en: Gaussian blurring
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高斯模糊
- en: 'Blurring your image may seem odd, but it often serves to reduce noise, which
    helps with further processing. With mahotas, it is just a function call:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对图像进行模糊处理可能看起来很奇怪，但它通常能减少噪声，这有助于进一步的处理。使用 mahotas，它只需要一个函数调用：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Notice that we did not convert the grayscale image to unsigned integers: we
    just made use of the floating point result as it is. The second argument to the
    `gaussian_filter` function is the size of the filter (the standard deviation of
    the filter). Larger values result in more blurring, as shown in the following
    screenshot:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们并没有将灰度图像转换为无符号整数：我们只是直接使用了浮动点结果。`gaussian_filter` 函数的第二个参数是滤波器的大小（即滤波器的标准差）。较大的值会导致更多的模糊，如下图所示：
- en: '![Gaussian blurring](img/2772OS_10_04.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![高斯模糊](img/2772OS_10_04.jpg)'
- en: 'We can use the screenshot on the left and threshold with Otsu (using the same
    previous code). Now, the boundaries are smoother, without the jagged edges, as
    shown in the following screenshot:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用左侧的截图并结合 Otsu 阈值方法（使用之前相同的代码）。现在，边界更加平滑，没有了锯齿状边缘，如下图所示：
- en: '![Gaussian blurring](img/2772OS_10_05.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![高斯模糊](img/2772OS_10_05.jpg)'
- en: Putting the center in focus
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让中心对焦
- en: 'The final example shows how to mix NumPy operators with a tiny bit of filtering
    to get an interesting result. We start with the Lena image and split it into the
    color channels:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的示例展示了如何将 NumPy 运算符与一些简单的滤波操作结合，得到有趣的效果。我们从 Lena 图像开始，将其分割成颜色通道：
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This is an image of a young woman that has been often for image processing
    demos. It is shown in the following screenshot:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一张年轻女性的图像，经常用于图像处理演示。它在下图中展示：
- en: '![Putting the center in focus](img/2772OS_10_06.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![让中心对焦](img/2772OS_10_06.jpg)'
- en: 'To split the red, green, and blue channels, we use the following code:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分割红色、绿色和蓝色通道，我们使用以下代码：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, we filter the three channels separately and build a composite image out
    of it with `mh.as_rgb`. This function takes three two-dimensional arrays, performs
    contrast stretching to make each be an 8-bit integer array, and then stacks them,
    returning a color RGB image:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们分别对三个通道进行滤波，并通过 `mh.as_rgb` 将它们组合成一张图像。此函数接受三个二维数组，进行对比度拉伸使每个数组成为 8 位整数数组，然后将它们堆叠，返回一张彩色
    RGB 图像：
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, we blend the two images from the center away to the edges. First, we need
    to build a weights array `W`, which will contain at each pixel a normalized value,
    which is its distance to the center:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将两张图像从中心到边缘进行混合。首先，我们需要构建一个权重数组 `W`，它在每个像素处包含一个归一化值，即该像素到中心的距离：
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We used the `np.mgrid` object, which returns arrays of size `(h, w)`, with
    values corresponding to the *y* and *x* coordinates, respectively. The next steps
    are as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 `np.mgrid` 对象，它返回大小为 `(h, w)` 的数组，值对应于 *y* 和 *x* 坐标。接下来的步骤如下：
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We now use a Gaussian function to give the center region a high value:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用一个高斯函数，给中心区域赋予一个高值：
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Notice how all of these manipulations are performed using NumPy arrays and
    not some mahotas-specific methodology. Finally, we can combine the two images
    to have the center be in sharp focus and the edges softer:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，所有这些操作都是使用NumPy数组而不是mahotas特定的方法来完成的。最后，我们可以将两张图片结合起来，使得中心部分聚焦清晰，而边缘部分则更柔和：
- en: '[PRE13]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Putting the center in focus](img/2772OS_10_17.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![聚焦中心](img/2772OS_10_17.jpg)'
- en: Basic image classification
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基本图像分类
- en: 'We will start with a small dataset that was collected especially for this book.
    It has three classes: buildings, natural scenes (landscapes), and pictures of
    texts. There are 30 images in each category, and they were all taken using a cell
    phone camera with minimal composition. The images are similar to those that would
    be uploaded to a modern website by users with no photography training. This dataset
    is available from this book''s website or the GitHub code repository. Later in
    this chapter, we will look at a harder dataset with more images and more categories.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个专门为本书收集的小型数据集开始。该数据集包含三个类别：建筑物、自然场景（风景）和文本图片。每个类别有30张图片，所有图片均使用手机摄像头拍摄，构图简单。图像与那些没有摄影训练的用户上传到现代网站上的图片类似。这个数据集可以通过本书的网站或GitHub代码库获得。在本章后面，我们将介绍一个更难的数据集，包含更多的图片和类别。
- en: When classifying images, we start with a large rectangular array of numbers
    (pixel values). Nowadays, millions of pixels are common. We could try to feed
    all these numbers as features into the learning algorithm. This is not a very
    good idea. This is because the relationship of each pixel (or even each small
    group of pixels) to the final result is very indirect. Also, having millions of
    pixels, but only as a small number of example images, results in a very hard statistical
    learning problem. This is an extreme form of the P greater than N type of problem
    we discussed in [Chapter 7](ch07.html "Chapter 7. Regression"), *Regression*.
    Instead, a good approach is to compute features from the image and use those features
    for classification.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行图像分类时，我们从一个包含大量数字（像素值）的矩阵开始。现在，百万级像素已是常见情况。我们可以尝试将所有这些数字作为特征输入学习算法，但这并不是一个很好的主意。原因是，每个像素（甚至每小组像素）与最终结果之间的关系非常间接。此外，如果像素数有百万，但样本图像的数量很少，这将导致一个非常困难的统计学习问题。这是我们在[第七章](ch07.html
    "第七章 回归")《回归》中讨论的P大于N类型问题的极端形式。相反，一个好的方法是从图像中计算特征，并利用这些特征进行分类。
- en: Having said that, I will point out that, in fact, there are a few methods that
    do work directly from the pixel values. They have feature computation submodules
    inside them. They may even attempt to learn good features automatically. These
    methods are the topic of current research. They typically work best with very
    large datasets (millions of images).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我还是要指出，实际上，有一些方法是可以直接从像素值中工作并计算特征的。这些方法有自己的特征计算子模块，甚至可能尝试自动学习合适的特征。这些方法是当前研究的主题，通常在非常大的数据集（数百万张图片）上效果最佳。
- en: 'We previously used an example of the scene class. The following are examples
    of the text and building classes:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前使用了一个场景类别的例子。以下是文本类和建筑类的示例：
- en: '![Basic image classification](img/2772OS_10_10.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![基本图像分类](img/2772OS_10_10.jpg)'
- en: Computing features from images
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从图像中计算特征
- en: With mahotas, it is very easy to compute features from images. There is a submodule
    named `mahotas.features`, where feature computation functions are available.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用mahotas时，从图像中计算特征非常简单。它有一个名为`mahotas.features`的子模块，提供了特征计算函数。
- en: 'A commonly used set of texture features is the Haralick. As with many methods
    in image processing, the name is due to its inventor. These features are texture-based:
    they distinguish between images that are smooth from those that are patterned,
    and between different patterns. With mahotas, it is very easy to compute them
    as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常用的纹理特征集是Haralick特征。和许多图像处理方法一样，这个名字来源于其发明者。这些特征是基于纹理的：它们能区分平滑的图像和有图案的图像，并且能区分不同的图案。使用mahotas时，计算这些特征非常简单，方法如下：
- en: '[PRE14]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `mh.features.haralick` function returns a 4x13 array. The first dimension
    refers to four possible directions in which to compute the features (vertical,
    horizontal, diagonal, and the anti-diagonal). If we are not interested in the
    direction specifically, we can use the average over all the directions (shown
    in the earlier code as `haralick_features_mean`). Otherwise, we can use all the
    features separately (using `haralick_features_all`). This decision should be informed
    by the properties of the dataset. In our case, we reason that the horizontal and
    vertical directions should be kept separately. Therefore, we will use `haralick_features_all`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`mh.features.haralick`函数返回一个4x13的数组。第一维表示计算特征的四个可能方向（垂直、水平、对角线和反对角线）。如果我们对方向没有特别兴趣，我们可以使用所有方向的平均值（如前面的代码中的`haralick_features_mean`）。否则，我们可以分别使用所有特征（使用`haralick_features_all`）。这个决策应根据数据集的属性来决定。在我们的案例中，我们推测水平和垂直方向应该分别保留。因此，我们将使用`haralick_features_all`。'
- en: There are a few other feature sets implemented in mahotas. Linear binary patterns
    are another texture-based feature set, which is very robust against illumination
    changes. There are other types of features, including local features, which we
    will discuss later in this chapter.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: mahotas中还实现了一些其他的特征集。线性二进制模式是另一种基于纹理的特征集，它对光照变化非常稳健。还有其他类型的特征，包括局部特征，我们将在本章后面讨论。
- en: 'With these features, we use a standard classification method such as logistic
    regression as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些特征时，我们采用标准的分类方法，如逻辑回归，具体如下：
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The three classes have very different textures. Buildings have sharp edges and
    big blocks where the color is similar (the pixel values are rarely exactly the
    same, but the variation is slight). Text is made of many sharp dark-light transitions,
    with small black areas in a sea of white. Natural scenes have smoother variations
    with fractal-like transitions. Therefore, a classifier based on texture is expected
    to do well.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个类别有非常不同的纹理。建筑物有锐利的边缘和大块区域，颜色相似（像素值很少完全相同，但变化很小）。文本由许多锐利的暗-亮过渡组成，黑色小区域在白色背景中。自然场景有更平滑的变化，带有类似分形的过渡。因此，基于纹理的分类器预计会表现良好。
- en: 'As a classifier, we are going to use a logistic regression classifier with
    preprocessing of the features as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 作为分类器，我们将使用逻辑回归分类器，并对特征进行如下预处理：
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Since our dataset is small, we can use leave-one-out regression as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的数据集较小，我们可以使用如下的留一法回归：
- en: '[PRE17]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Eighty-one percent is not bad for the three classes (random guessing would correspond
    to 33 percent). We can do better, however, by writing our own features.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于三个类别，81%的准确率不错（随机猜测的准确率大约为33%）。然而，通过编写我们自己的特征，我们可以做得更好。
- en: Writing your own features
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写你自己的特征
- en: A feature is nothing magical. It is simply a number that we computed from an
    image. There are several feature sets already defined in the literature. These
    often have the added advantage that they have been designed and studied to be
    invariant to many unimportant factors. For example, linear binary patterns are
    completely invariant to multiplying all pixel values by a number or adding a constant
    to all these values. This makes this feature set robust against illumination changes
    of images.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 特征没有什么神奇之处。它只是我们从图像中计算出的一个数字。文献中已经定义了几种特征集。这些特征集通常有一个额外的优势，即它们被设计和研究为对许多不重要的因素具有不变性。例如，线性二进制模式对将所有像素值乘以一个数字或将一个常数加到所有像素值上完全不变。这使得这个特征集对图像的光照变化具有稳健性。
- en: However, it is also possible that your particular use case would benefit from
    a few specially designed features.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，也有可能你的特定使用案例将从一些特别设计的功能中受益。
- en: A simple type of feature that is not shipped with mahotas is a color histogram.
    Fortunately, this feature is easy to implement. A color histogram partitions the
    color space into a set of bins, and then counts how many pixels fall into each
    of the bins.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: mahotas中没有提供的一种简单功能是颜色直方图。幸运的是，这个功能很容易实现。颜色直方图将颜色空间划分为一组区间，然后计算每个区间内有多少个像素。
- en: 'The images are in RGB format, that is, each pixel has three values: R for red,
    G for green, and B for blue. Since each of these components is an 8-bit value,
    the total is 17 million different colors. We are going to reduce this number to
    only 64 colors by grouping colors into bins. We will write a function to encapsulate
    this algorithm as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图像采用 RGB 格式，即每个像素有三个值：R 表示红色，G 表示绿色，B 表示蓝色。由于这些组件每个都是 8 位值，总共有 1700 万种不同的颜色。我们将通过将颜色分组到箱子中，将这个数字减少到仅
    64 种颜色。我们将编写一个函数来封装这个算法，如下所示：
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To bin the colors, we first divide the image by 64, rounding down the pixel
    values as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对颜色进行分箱，我们首先将图像除以 64，按如下方式向下取整像素值：
- en: '[PRE19]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This makes the pixel values range from 0 to 3, which gives a total of 64 different
    colors.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得像素值的范围从 0 到 3，总共产生了 64 种不同的颜色。
- en: 'Separate the red, green, and blue channels as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下方式分离红色、绿色和蓝色通道：
- en: '[PRE20]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Convert to log scale, as seen in the following code snippet. This is not strictly
    necessary, but makes for better features. We use `np.log1p`, which computes *log(h+1)*.
    This ensures that zero values are kept as zero values (mathematically, the logarithm
    of zero is not defined, and NumPy prints a warning if you attempt to compute it).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 转换为对数尺度，如下代码片段所示。这并非严格必要，但能够产生更好的特征。我们使用 `np.log1p`，它计算 *log(h+1)*。这确保了零值保持为零值（从数学角度看，零的对数是未定义的，如果你尝试计算，NumPy
    会给出警告）。
- en: '[PRE21]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We can adapt the previous processing code to use the function we wrote very
    easily:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以很容易地将之前的处理代码调整为使用我们编写的函数：
- en: '[PRE22]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Using the same cross-validation code we used earlier, we obtain 90 percent
    accuracy. The best results, however, come from combining all the features, which
    we can implement as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们之前使用的相同交叉验证代码，我们获得了 90% 的准确率。然而，最佳结果来自于将所有特征结合在一起，我们可以按如下方式实现：
- en: '[PRE23]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'By using all of these features, we get 95.6 percent accuracy, as shown in the
    following code snippet:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用所有这些特征，我们获得了 95.6% 的准确率，如以下代码片段所示：
- en: '[PRE24]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This is a perfect illustration of the principle that good algorithms are the
    easy part. You can always use an implementation of state-of-the-art classification
    from scikit-learn. The real secret and added value often comes in feature design
    and engineering. This is where knowledge of your dataset is valuable.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个完美的例子，说明了好算法是容易的部分。你总是可以使用 scikit-learn 中的最先进的分类实现。真正的秘密和附加价值通常体现在特征设计和工程上。这就是你对数据集的知识变得非常有价值的地方。
- en: Using features to find similar images
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用特征来查找相似图像
- en: The basic concept of representing an image by a relatively small number of features
    can be used for more than just classification. For example, we can also use it
    to find similar images to a given query image (as we did before with text documents).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 通过用相对较少的特征表示图像的基本概念，不仅可以用于分类。例如，我们还可以用它来查找与给定查询图像相似的图像（就像我们之前在文本文档中做的那样）。
- en: 'We will compute the same features as before, with one important difference:
    we will ignore the bordering area of the picture. The reason is that due to the
    amateur nature of the compositions, the edges of the picture often contain irrelevant
    elements. When the features are computed over the whole image, these elements
    are taken into account. By simply ignoring them, we get slightly better features.
    In the supervised example, it is not as important, as the learning algorithm will
    then learn which features are more informative and weigh them accordingly. When
    working in an unsupervised fashion, we need to be more careful to ensure that
    our features are capturing important elements of the data. This is implemented
    in the loop as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将计算与之前相同的特征，唯一不同的是：我们将忽略图像的边缘区域。原因是由于构图的业余性质，图像的边缘常常包含无关的元素。当特征在整个图像上计算时，这些元素会被考虑在内。通过简单地忽略它们，我们可以得到稍微更好的特征。在监督学习示例中，这并不那么重要，因为学习算法会学习哪些特征更具信息量并相应地加权。当以无监督的方式工作时，我们需要更加小心，确保我们的特征能够捕捉到数据中重要的元素。这在循环中实现如下：
- en: '[PRE25]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We now normalize the features and compute the distance matrix as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在标准化特征并计算距离矩阵，如下所示：
- en: '[PRE26]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We will plot just a subset of the data (every 10th element) so that the query
    will be on top and the returned "nearest neighbor" at the bottom, as shown in
    the following:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将仅绘制数据的一个子集（每第十个元素），这样查询图像会显示在顶部，返回的“最近邻”图像显示在底部，如下所示：
- en: '[PRE27]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The result is shown in the following screenshot:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如以下截图所示：
- en: '![Using features to find similar images](img/2772OS_10_02.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![使用特征查找相似图像](img/2772OS_10_02.jpg)'
- en: It is clear that the system is not perfect, but can find images that are at
    least visually similar to the queries. In all but one case, the image found comes
    from the same class as the query.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，系统并不完美，但至少可以找到与查询在视觉上相似的图像。在除了一个案例外，找到的图像都来自与查询相同的类别。
- en: Classifying a harder dataset
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类更困难的数据集
- en: The previous dataset was an easy dataset for classification using texture features.
    In fact, many of the problems that are interesting from a business point of view
    are relatively easy. However, sometimes we may be faced with a tougher problem
    and need better and more modern techniques to get good results.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个数据集是一个使用纹理特征进行分类的简单数据集。事实上，从商业角度来看，许多有趣的问题相对简单。然而，有时我们可能会面临一个更困难的问题，需要更好、更现代的技术来获得良好的结果。
- en: 'We will now test a public dataset, which has the same structure: several photographs
    split into a small number of classes. The classes are animals, cars, transportation,
    and natural scenes.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将测试一个公共数据集，它具有相同的结构：若干张照片分为少数几个类别。这些类别是动物、汽车、交通工具和自然场景。
- en: 'When compared to the three class problem we discussed previously, these classes
    are harder to tell apart. Natural scenes, buildings, and texts have very different
    textures. In this dataset, however, texture and color are not as clear marker,
    of the image class. The following is one example from the animal class:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前讨论的三类问题相比，这些类别更难区分。自然场景、建筑物和文本的纹理差异很大。然而，在这个数据集中，纹理和颜色不再是图像类别的明显标记。以下是来自动物类的一个例子：
- en: '![Classifying a harder dataset](img/2772OS_10_07.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![Classifying a harder dataset](img/2772OS_10_07.jpg)'
- en: 'And here is another example from the car class:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这是来自汽车类别的另一个例子：
- en: '![Classifying a harder dataset](img/2772OS_10_21.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![Classifying a harder dataset](img/2772OS_10_21.jpg)'
- en: 'Both objects are against natural backgrounds, and with large smooth areas inside
    the objects. This is a harder problem than the simple dataset, so we will need
    to use more advanced methods. The first improvement will be to use a slightly
    more powerful classifier. The logistic regression that scikit-learn provides is
    a penalized form of logistic regression, which contains an adjustable parameter,
    `C`. By default, `C = 1.0`, but this may not be optimal. We can use grid search
    to find a good value for this parameter as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个对象背景都是自然背景，并且对象内部有较大的平滑区域。这是比简单数据集更具挑战性的问题，因此我们需要使用更先进的方法。第一个改进是使用一个稍微更强大的分类器。scikit-learn
    提供的逻辑回归是一个带惩罚项的逻辑回归，包含一个可调参数`C`。默认情况下，`C = 1.0`，但这可能不是最佳选择。我们可以使用网格搜索来找到这个参数的最佳值，具体方法如下：
- en: '[PRE28]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The data is not organized in a random order inside the dataset: similar images
    are close together. Thus, we use a cross-validation schedule that considers the
    data shuffled so that each fold has a more representative training set, as shown
    in the following:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的数据并不是按随机顺序组织的：相似的图像彼此靠近。因此，我们使用交叉验证策略，考虑数据已被洗牌，这样每个折叠（fold）都有一个更具代表性的训练集，如下所示：
- en: '[PRE29]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This is not so bad for four classes, but we will now see if we can do better
    by using a different set of features. In fact, we will see that we need to combine
    these features with other methods to get the best possible results.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对于四个类别来说，这还算不错，但我们现在将看看是否能通过使用不同的特征集来做得更好。事实上，我们将看到，结合这些特征与其他方法，才能获得最好的结果。
- en: Local feature representations
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 局部特征表示
- en: A relatively recent development in the computer vision world has been the development
    of local-feature based methods. Local features are computed on a small region
    of the image, unlike the previous features we considered, which had been computed
    on the whole image. Mahotas supports computing a type of these features, **Speeded
    Up Robust Features** (**SURF**). There are several others, the most well-known
    being the original proposal of SIFT. These features are designed to be robust
    against rotational or illumination changes (that is, they only change their value
    slightly when illumination changes).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉领域的一个相对较新的发展是基于局部特征的方法。局部特征是在图像的小区域内计算的，与我们之前考虑的在整个图像上计算的特征不同。Mahotas支持计算一种这种特征，**加速稳健特征**（**SURF**）。还有其他几种，最著名的是SIFT的原始提案。这些特征旨在对旋转或光照变化具有鲁棒性（即，它们在光照变化时仅略微改变其值）。
- en: 'When using these features, we have to decide where to compute them. There are
    three possibilities that are commonly used:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些特征时，我们必须决定在哪里计算它们。常用的三种计算位置如下：
- en: Randomly
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机地
- en: In a grid
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在网格中
- en: Detecting interesting areas of the image (a technique known as keypoint detection
    or interest point detection)
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测图像中的有趣区域（这是一种被称为关键点检测或兴趣点检测的技术）
- en: All of these are valid and will, under the right circumstances, give good results.
    Mahotas supports all three. Using interest point detection works best if you have
    a reason to expect that your interest point will correspond to areas of importance
    in the image.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方法都是有效的，在合适的情况下，会得到很好的结果。Mahotas 支持这三种方法。如果你有理由认为你的兴趣点将对应于图像中重要区域，那么使用兴趣点检测效果最好。
- en: 'We will be using the interest point method. Computing the features with mahotas
    is easy: import the right submodule and call the `surf.surf` function as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用兴趣点方法。使用 mahotas 计算特征非常简单：导入正确的子模块并调用 `surf.surf` 函数，如下所示：
- en: '[PRE30]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `descriptors_only=True` flag means that we are only interested in the descriptors
    themselves, and not in their pixel location, size, or orientation. Alternatively,
    we could have used the dense sampling method, using the `surf.dense` function
    as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`descriptors_only=True` 标志意味着我们只关心描述符本身，而不是它们的像素位置、大小或方向。或者，我们也可以使用密集采样方法，使用
    `surf.dense` 函数如下所示：'
- en: '[PRE31]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This returns the value of the descriptors computed on points that are at a distance
    of 16 pixels from each other. Since the position of the points is fixed, the metainformation
    on the interest points is not very interesting and is not returned by default.
    In either case, the result (descriptors) is an n-times-64 array, where *n* is
    the number of points sampled. The number of points depends on the size of your
    images, their content, and the parameters you pass to the functions. In this example,
    we are using the default settings, and we obtain a few hundred descriptors per
    image.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回计算在相距 16 像素的点上的描述符值。由于点的位置是固定的，兴趣点的元信息并不十分有趣，默认情况下不会返回。在任何情况下，结果（描述符）是一个
    n×64 的数组，其中 *n* 是采样点的数量。点的数量取决于图像的大小、内容以及你传递给函数的参数。在这个例子中，我们使用的是默认设置，每张图像得到几百个描述符。
- en: We cannot directly feed these descriptors to a support vector machine, logistic
    regressor, or similar classification system. In order to use the descriptors from
    the images, there are several solutions. We could just average them, but the results
    of doing so are not very good as they throw away all location specific information.
    In that case, we would have just another global feature set based on edge measurements.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能直接将这些描述符输入到支持向量机、逻辑回归器或类似的分类系统中。为了使用来自图像的描述符，有几种解决方案。我们可以直接对它们求平均，但这样做的结果并不好，因为这样丢弃了所有关于位置的特定信息。在那种情况下，我们只会得到一个基于边缘度量的全局特征集。
- en: 'The solution we will use here is the **bag of words** model, which is a very
    recent idea. It was published in this form first in 2004\. This is one of those
    obvious-in-hindsight ideas: it is very simple to implement and achieves very good
    results.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里使用的解决方案是**词袋模型**，这是一种非常新的思想。它首次于 2004 年以这种形式发布。这是一个事后看非常显而易见的想法：它非常简单实现，并且能够取得非常好的结果。
- en: It may seem strange to speak of *words* when dealing with images. It may be
    easier to understand if you think that you have not written words, which are easy
    to distinguish from each other, but orally spoken audio. Now, each time a word
    is spoken, it will sound slightly different, and different speakers will have
    their own pronunciation. Thus, a word's waveform will not be identical every time
    it is spoken. However, by using clustering on these waveforms, we can hope to
    recover most of the structure so that all the instances of a given word are in
    the same cluster. Even if the process is not perfect (and it will not be), we
    can still talk of grouping the waveforms into words.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理图像时，说到*单词*可能会显得有些奇怪。如果你理解为你没有写出那些彼此容易区分的单词，而是口头发出的音频，可能更容易理解。现在，每次说出一个单词时，它的发音会略有不同，而且不同的发言者会有自己的发音方式。因此，一个单词的波形每次说出来时都不会完全相同。然而，通过对这些波形进行聚类，我们可以期望恢复大部分结构，使得给定单词的所有实例都在同一个聚类中。即使过程不完美（而且确实不会完美），我们仍然可以谈论将波形分组成单词。
- en: 'We perform the same operation with image data: we cluster together similar
    looking regions from all images and call these **visual words**.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对图像数据执行相同的操作：我们将所有图像中看起来相似的区域聚类在一起，并将这些区域称为**视觉词汇**。
- en: Note
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The number of words used does not usually have a big impact on the final performance
    of the algorithm. Naturally, if the number is extremely small (10 or 20, when
    you have a few thousand images), then the overall system will not perform well.
    Similarly, if you have too many words (many more than the number of images, for
    example), the system will also not perform well. However, in between these two
    extremes, there is often a very large plateau, where you can choose the number
    of words without a big impact on the result. As a rule of thumb, using a value
    such as 256, 512, or 1,024 if you have very many images should give you a good
    result.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的词数通常对算法的最终性能影响不大。自然，如果词数非常少（例如10或20，当你拥有几千张图像时），那么整体系统的表现会很差。同样，如果你有太多的词（例如，比图像的数量多得多），系统的表现也会不佳。然而，在这两者之间，通常会有一个较大的平稳区间，在这个区间内，你可以选择词数而不会对结果产生太大影响。作为经验法则，如果你有很多图像，使用256、512或1024这样的值应该能给你一个不错的结果。
- en: 'We are going to start by computing the features as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下方式开始计算特征：
- en: '[PRE32]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This results in over 2 million local descriptors. Now, we use k-means clustering
    to obtain the centroids. We could use all the descriptors, but we are going to
    use a smaller sample for extra speed, as shown in the following:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了超过200万个局部描述符。现在，我们使用k-means聚类来获取质心。我们可以使用所有描述符，但为了提高速度，我们将使用较小的样本，如下所示：
- en: '[PRE33]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'After this is done (which will take a while), the `km` object contains information
    about the centroids. We now go back to the descriptors and build feature vectors
    as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此操作后（这需要一些时间），`km`对象包含有关质心的信息。我们现在回到描述符，并按以下方式构建特征向量：
- en: '[PRE34]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The end result of this loop is that `sfeatures[fi, fj]` is the number of times
    that the image `fi` contains the element `fj`. The same could have been computed
    faster with the `np.histogram` function, but getting the arguments just right
    is a little tricky. We convert the result to floating point as we do not want
    integer arithmetic (with its rounding semantics).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这个循环的最终结果是，`sfeatures[fi, fj]`表示图像`fi`中包含元素`fj`的次数。虽然使用`np.histogram`函数可以更快地计算这个值，但正确设置参数会有些棘手。我们将结果转换为浮点数，因为我们不想使用整数运算（及其舍入语义）。
- en: 'The result is that each image is now represented by a single array of features,
    of the same size (the number of clusters, in our case 256). Therefore, we can
    use our standard classification methods as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，每个图像现在都由一个大小相同的特征数组表示（在我们的例子中是256个聚类）。因此，我们可以按以下方式使用我们的标准分类方法：
- en: '[PRE35]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This is worse than before! Have we gained nothing?
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 结果比之前更差！我们什么也没得到吗？
- en: 'In fact, we have, as we can combine all features together to obtain 76.1 percent
    accuracy, as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们有，因为我们可以将所有特征结合起来，达到76.1%的准确率，具体如下：
- en: '[PRE36]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This is the best result we have, better than any single feature set. This is
    due to the fact that the local SURF features are different enough to add new information
    to the global image features we had before and improve the combined result.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们获得的最佳结果，优于任何单一的特征集。之所以如此，是因为局部的SURF特征与我们之前的全局图像特征有足够的区别，能够提供新的信息，从而提升了综合结果。
- en: Summary
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'We learned the classical feature-based approach to handling images in a machine
    learning context: by converting from a million pixels to a few numeric features,
    we are able to directly use a logistic regression classifier. All of the technologies
    that we learned in the other chapters suddenly become directly applicable to image
    problems. We saw one example in the use of image features to find similar images
    in a dataset.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了在机器学习环境中处理图像的经典特征方法：通过将数百万个像素转换为少量数值特征，我们能够直接使用逻辑回归分类器。我们在其他章节中学到的所有技术突然变得可以直接应用于图像问题。我们在使用图像特征查找数据集中相似图像时，看到了一个例子。
- en: We also learned how to use local features, in a bag of words model, for classification.
    This is a very modern approach to computer vision and achieves good results while
    being robust to many irrelevant aspects of the image, such as illumination, and
    even uneven illumination in the same image. We also used clustering as a useful
    intermediate step in classification rather than as an end in itself.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还学习了如何在词袋模型中使用局部特征进行分类。这是一种非常现代的计算机视觉方法，在提高分类精度的同时，对图像中的许多无关因素（如光照，甚至同一图像中的不均匀光照）具有很强的鲁棒性。我们还使用了聚类作为分类中的一个有用中间步骤，而不是仅仅作为最终目标。
- en: We focused on mahotas, which is one of the major computer vision libraries in
    Python. There are others that are equally well maintained. Skimage (scikit-image)
    is similar in spirit, but has a different set of features. OpenCV is a very good
    C++ library with a Python interface. All of these can work with NumPy arrays and
    you can mix and match functions from different libraries to build complex computer
    vision pipelines.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们专注于mahotas，它是Python中主要的计算机视觉库之一。还有其他同样维护良好的库。Skimage（scikit-image）在精神上类似，但有不同的功能集。OpenCV是一个非常优秀的C++库，具有Python接口。这些库都可以与NumPy数组配合使用，你可以混合搭配不同库中的函数，构建复杂的计算机视觉管道。
- en: 'In the next chapter, you will learn a different form of machine learning: dimensionality
    reduction. As we saw in several earlier chapters, including when using images
    in this chapter, it is very easy to computationally generate many features. However,
    often we want to have a reduced number of features for speed and visualization,
    or to improve our results. In the next chapter, we will see how to achieve this.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习一种不同形式的机器学习：降维。如我们在前几章中所见，包括在本章中使用图像时，计算上生成许多特征是非常容易的。然而，通常我们希望通过减少特征数量来提高速度和可视化，或者改善我们的结果。在下一章中，我们将看到如何实现这一目标。
