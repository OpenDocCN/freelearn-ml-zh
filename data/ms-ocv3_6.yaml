- en: Face Recognition Using Eigenfaces or Fisherfaces
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用特征脸或费舍尔脸进行面部识别
- en: 'In this chapter, we cover the following:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下内容：
- en: Face detection
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部检测
- en: Face preprocessing
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部预处理
- en: Training a machine-learning algorithm from collected faces
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从收集到的面部训练机器学习算法
- en: Face recognition
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部识别
- en: Finishing touches
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成细节
- en: Introduction to face recognition and face detection
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部识别和面部检测简介
- en: 'Face recognition is the process of putting a label to a known face. Just like
    humans learn to recognize their family, friends, and celebrities just by seeing
    their face, there are many techniques for a computer to learn to recognize a known
    face. These generally involve four main steps:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 面部识别是将标签贴在已知面部上的过程。就像人类通过看到他们的面孔来识别家人、朋友和名人一样，计算机学习识别已知面部有许多技术。这些通常涉及四个主要步骤：
- en: '**Face detection**: This is the process of locating a face region in an image
    (a large rectangle near the center of the following screenshot). This step does
    not care who the person is, just that it is a human face.'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**面部检测**：这是在图像中定位面部区域的过程（如下截图中心附近的大矩形）。这一步不关心这个人是谁，只关心它是一个人脸。'
- en: '**Face preprocessing**: This is the process of adjusting the face image to
    look more clear and similar to other faces (a small grayscale face in the top-center
    of the following screenshot).'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**面部预处理**：这是调整面部图像以使其看起来更清晰并与其他面部相似的过程（如下截图顶部中央的小灰度面部图像）。'
- en: '**Collecting and learning faces**: This is the process of saving many preprocessed
    faces (for each person that should be recognized), and then learning how to recognize
    them.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**收集和学习面部**：这是保存许多预处理后的面部（对于应该被识别的每个人），然后学习如何识别它们的过程。'
- en: '**Face recognition**: This is the process that checks which of the collected
    people are most similar to the face in the camera (a small rectangle on the top-right
    of the following screenshot).'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**面部识别**：这是检查收集到的人中谁与相机中的面部最相似的过程（如下截图右上角的小矩形）。'
- en: Note that the phrase **face recognition** is often used by the general public
    for finding positions of faces (that is, face detection, as described in step
    1), but this book will use the formal definition of face recognition referring
    to step 4 and face detection referring to *step 1*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，短语**面部识别**通常被公众用于查找面部位置（即面部检测，如步骤1中所述），但本书将使用正式的定义，面部识别指步骤4，面部检测指*步骤1*。
- en: 'The following screenshot shows the final `WebcamFaceRec` project, including
    a small rectangle at the top-right corner highlighting the recognized person.
    Also notice the confidence bar that is next to the preprocessed face (a small
    face at the top-center of the rectangle marking the face), which in this case
    shows roughly 70 percent confidence that it has recognized the correct person:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了最终的`WebcamFaceRec`项目，包括右上角的小矩形突出显示识别的人。同时注意旁边的置信度条，它位于预处理后的面部旁边（矩形标记面部顶部中央的小面部），在这种情况下，显示大约70%的置信度，表明它已正确识别了正确的人：
- en: '![](img/image_07_001.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_001.jpg)'
- en: The current face detection techniques are quite reliable in real-world conditions,
    whereas current face recognition techniques are much less reliable when used in
    real-world conditions. For example, it is easy to find research papers showing
    face recognition accuracy rates above 95 percent, but when testing those same
    algorithms yourself, you may often find that accuracy is lower than 50 percent.
    This comes from the fact that current face recognition techniques are very sensitive
    to exact conditions in the images, such as the type of lighting, direction of
    lighting and shadows, exact orientation of the face, expression of the face, and
    the current mood of the person. If they are all kept constant when training (collecting
    images) as well as when testing (from the camera image), then face recognition
    should work well, but if the person was standing to the left-hand side of the
    lights in a room when training, and then stood to the right-hand side while testing
    with the camera, it may give quite bad results. So the dataset used for training
    is very important.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的人脸检测技术在现实世界条件下相当可靠，而当前的人脸识别技术在现实世界条件下使用时可靠性要低得多。例如，很容易找到显示人脸识别准确率超过95%的研究论文，但当你自己测试这些相同的算法时，你可能会经常发现准确率低于50%。这源于当前的人脸识别技术对图像中的精确条件非常敏感，例如光照类型、光照方向和阴影、人脸的精确方向、面部表情以及人的当前情绪。如果它们在训练（收集图像）以及测试（从摄像头图像）时都保持恒定，那么人脸识别应该会工作得很好，但如果人在训练时站在房间灯光的左侧，而在测试时站在摄像头的右侧，可能会得到相当糟糕的结果。因此，用于训练的数据集非常重要。
- en: Face preprocessing (*step 2*) aims to reduce these problems, such as by making
    sure the face always appears to have similar brightness and contrast, and perhaps
    making sure the features of the face will always be in the same position (such
    as aligning the eyes and/or nose to certain positions). A good face preprocessing
    stage will help improve the reliability of the whole face recognition system,
    so this chapter will place some emphasis on face preprocessing methods.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸预处理（*第二步*）旨在减少这些问题，例如确保人脸始终看起来具有相似的亮度和对比度，并可能确保人脸的特征始终位于相同的位置（例如将眼睛和/或鼻子对齐到某些位置）。一个良好的人脸预处理阶段将有助于提高整个人脸识别系统的可靠性，因此本章将重点介绍人脸预处理方法。
- en: Despite the big claims about face recognition for security in the media, it
    is unlikely that the current face recognition methods alone are reliable enough
    for any true security system, but they can be used for purposes that don't need
    high reliability, such as playing personalized music for different people entering
    a room or a robot that says your name when it sees you. There are also various
    practical extensions to face recognition, such as gender recognition, age recognition,
    and emotion recognition.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管媒体上关于人脸识别在安全方面的夸大其词，但单独依靠当前的人脸识别方法不太可能足够可靠，以用于任何真正的安全系统，但它们可以用于不需要高可靠性的目的，例如为进入房间或看到你时说出你名字的机器人播放个性化的音乐。还有各种人脸识别的实际扩展，如性别识别、年龄识别和情绪识别。
- en: Step 1 - face detection
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一步 - 人脸检测
- en: Until the year 2000, there were many different techniques used for finding faces,
    but all of them were either very slow, very unreliable, or both. A major change
    came in 2001 when Viola and Jones invented the Haar-based cascade classifier for
    object detection, and in 2002 when it was improved by Lienhart and Maydt. The
    result is an object detector that is both fast (it can detect faces in real time
    on a typical desktop with a VGA webcam) and reliable (it detects approximately
    95 percent of frontal faces correctly). This object detector revolutionized the
    field of face recognition (as well as that of robotics and computer vision in
    general), as it finally allowed real-time face detection and face recognition,
    especially as Lienhart himself wrote the object detector that comes free with
    OpenCV! It works not only for frontal faces but also side-view faces (referred
    to as profile faces), eyes, mouths, noses, company logos, and many other objects.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 直到2000年，用于寻找面部的方法有很多种，但它们要么非常慢，要么非常不可靠，或者两者兼而有之。2001年，Viola和Jones发明了基于Haar的级联分类器用于物体检测，2002年，Lienhart和Maydt对其进行了改进。结果是，这个物体检测器既快（它可以在典型的桌面电脑上使用VGA摄像头实时检测面部）又可靠（它正确检测大约95%的前置面部）。这个物体检测器彻底改变了面部识别领域（以及机器人学和计算机视觉领域），因为它最终实现了实时面部检测和面部识别，尤其是Lienhart本人还编写了与OpenCV一起免费提供的物体检测器！它不仅适用于正面面部，还适用于侧面视角的面部（称为侧面面部）、眼睛、嘴巴、鼻子、公司标志以及许多其他物体。
- en: This object detector was extended in OpenCV v2.0 to also use LBP features for
    detection based on work by Ahonen, Hadid, and Pietikäinen in 2006, as LBP-based
    detectors are potentially several times faster than Haar-based detectors, and
    don't have the licensing issues that many Haar detectors have.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV v2.0中，这个物体检测器被扩展，以使用Ahonen、Hadid和Pietikäinen在2006年的工作成果中的LBP特征进行检测，因为基于LBP的检测器可能比基于Haar的检测器快几倍，而且没有许多Haar检测器所面临的许可问题。
- en: The basic idea of the Haar-based face detector is that if you look at most frontal
    faces, the region with the eyes should be darker than the forehead and cheeks,
    and the region with the mouth should be darker than cheeks, and so on. It typically
    performs about 20 stages of comparisons like this to decide if it is a face or
    not, but it must do this at each possible position in the image and for each possible
    size of the face, so in fact it often does thousands of checks per image. The
    basic idea of the LBP-based face detector is similar to the Haar-based one, but
    it uses histograms of pixel intensity comparisons, such as edges, corners, and
    flat regions.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Haar的面部检测器的基本思想是，如果你观察大多数正面面部，眼睛所在区域应该比额头和脸颊暗，嘴巴所在区域应该比脸颊暗，等等。它通常进行大约20次这样的比较来决定是否为面部，但它必须在图像的每个可能位置和每个可能的面部大小上进行这种操作，因此实际上它通常每张图像都要进行数千次检查。基于LBP的面部检测器的基本思想与基于Haar的类似，但它使用像素强度比较的直方图，例如边缘、角点和平坦区域。
- en: Rather than have a person decide which comparisons would best define a face,
    both Haar- and LBP-based face detectors can be automatically trained to find faces
    from a large set of images, with the information stored as XML files to be used
    later. These cascade classifier detectors are typically trained using at least
    1,000 unique face images and 10,000 non-face images (for example, photos of trees,
    cars, and text), and the training process can take a long time even on a multi-core
    desktop (typically a few hours for LBP but 1week for Haar!). Luckily, OpenCV comes
    with some pretrained Haar and LBP detectors for you to use! In fact you can detect
    frontal faces, profile (side-view) faces, eyes, or noses just by loading different
    cascade classifier XML files to the object detector, and choose between the Haar
    or LBP detector, based on which XML file you choose.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是让一个人决定哪些比较最能定义面部，基于Haar和LBP的面部检测器都可以自动训练，从大量图像中找到面部，信息存储为XML文件以供以后使用。这些级联分类器检测器通常使用至少1,000张独特的面部图像和10,000张非面部图像（例如树木、汽车和文本的照片）进行训练，即使在多核桌面电脑上训练过程也可能需要很长时间（通常LBP需要几个小时，而Haar需要一周！）幸运的是，OpenCV附带了一些预训练的Haar和LBP检测器供你使用！实际上，你只需将不同的级联分类器XML文件加载到物体检测器中，就可以检测正面面部、侧面（侧面视角）面部、眼睛或鼻子，并根据你选择的XML文件选择Haar或LBP检测器。
- en: Implementing face detection using OpenCV
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用OpenCV实现面部检测
- en: 'As mentioned previously, OpenCV v2.4 comes with various, pretrained XML detectors
    that you can use for different purposes. The following table lists some of the
    most popular XML files:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，OpenCV v2.4 包含各种预训练的 XML 检测器，可用于不同的目的。以下表格列出了其中一些最受欢迎的 XML 文件：
- en: '| **Type of cascade classifier** | **XML filename** |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| **级联分类器类型** | **XML 文件名** |'
- en: '| Face detector (default) | `haarcascade_frontalface_default.xml` |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 人脸检测器（默认） | `haarcascade_frontalface_default.xml` |'
- en: '| Face detector (fast Haar) | `haarcascade_frontalface_alt2.xml` |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 人脸检测器（快速 Haar） | `haarcascade_frontalface_alt2.xml` |'
- en: '| Face detector (fast LBP) | `lbpcascade_frontalface.xml` |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 人脸检测器（快速 LBP） | `lbpcascade_frontalface.xml` |'
- en: '| Profile (side-looking) face detector | `haarcascade_profileface.xml` |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 轮廓（侧面）人脸检测器 | `haarcascade_profileface.xml` |'
- en: '| Eye detector (separate for left and right) | `haarcascade_lefteye_2splits.xml`
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 眼睛检测器（左眼和右眼分开） | `haarcascade_lefteye_2splits.xml` |'
- en: '| Mouth detector | `haarcascade_mcs_mouth.xml` |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 嘴巴检测器 | `haarcascade_mcs_mouth.xml` |'
- en: '| Nose detector | `haarcascade_mcs_nose.xml` |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 鼻子检测器 | `haarcascade_mcs_nose.xml` |'
- en: '| Whole person detector | `haarcascade_fullbody.xml` |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 全身检测器 | `haarcascade_fullbody.xml` |'
- en: Haar-based detectors are stored in the `datahaarcascades` folder and LBP-based
    detectors are stored in the `datalbpcascades` folder of the OpenCV root folder,
    such as `C:opencvdatalbpcascades`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 Haar 的检测器存储在 OpenCV 根目录的 `datahaarcascades` 文件夹中，而基于 LBP 的检测器存储在 `datalbpcascades`
    文件夹中，例如 `C:opencvdatalbpcascades`。
- en: For our face recognition project, we want to detect frontal faces, so let's
    use the LBP face detector because it is the fastest and doesn't have patent licensing
    issues. Note that this pretrained LBP face detector that comes with OpenCV v2.x
    is not tuned as well as the pretrained Haar face detectors, so if you want more
    reliable face detection then you may want to train your own LBP face detector
    or use a Haar face detector.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的面部识别项目，我们希望检测正面人脸，因此让我们使用 LBP 人脸检测器，因为它是最快的，并且没有专利许可问题。请注意，OpenCV v2.x
    中包含的此预训练 LBP 人脸检测器没有像预训练的 Haar 人脸检测器那样经过良好的调整，因此如果您想要更可靠的人脸检测，则可能需要训练自己的 LBP 人脸检测器或使用
    Haar 人脸检测器。
- en: Loading a Haar or LBP detector for object or face detection
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载 Haar 或 LBP 检测器以进行物体或人脸检测
- en: 'To perform object or face detection, first you must load the pretrained XML
    file using OpenCV''s `CascadeClassifier` class as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行物体或人脸检测，首先您必须使用 OpenCV 的 `CascadeClassifier` 类加载预训练的 XML 文件，如下所示：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This can load Haar or LBP detectors just by giving a different filename. A
    very common mistake when using this is to provide the wrong folder or filename,
    but depending on your build environment, the `load()` method will either return
    `false` or generate a C++ exception (and exit your program with an assert error).
    So it is best to surround the `load()` method with a `try... catch` block and
    display a nice error message to the user if something went wrong. Many beginners
    skip checking for errors, but it is crucial to show a help message to the user
    when something did not load correctly, otherwise you may spend a very long time
    debugging other parts of your code before eventually realizing something did not
    load. A simple error message can be displayed as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通过提供不同的文件名，可以加载 Haar 或 LBP 检测器。在使用此功能时，一个常见的错误是提供错误的文件夹或文件名，但根据您的构建环境，`load()`
    方法将返回 `false` 或生成一个 C++ 异常（并使用断言错误退出您的程序）。因此，最好将 `load()` 方法用 `try... catch` 块包围，并在出现问题时向用户显示一个友好的错误消息。许多初学者会跳过错误检查，但显示帮助消息对于用户来说至关重要，否则您可能会花费很长时间调试代码的其他部分，最终意识到某些内容没有正确加载。以下是一个简单的错误消息示例：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Accessing the webcam
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问摄像头
- en: To grab frames from a computer's webcam or even from a video file, you can simply
    call the `VideoCapture::open()` function with the camera number or video filename,
    then grab the frames using the C++ stream operator, as mentioned in the section,*Accessing
    the webcam* in [Chapter 1](03913e76-ec18-4a31-875e-dfceca32d26f.xhtml), *Cartoonifier
    and Skin Changer for Raspberry Pi*.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要从计算机的摄像头或视频文件中捕获帧，您可以简单地调用 `VideoCapture::open()` 函数，传入摄像头编号或视频文件名，然后使用 C++
    流操作符捕获帧，如第 1 章“访问摄像头”部分所述，[第 1 章](03913e76-ec18-4a31-875e-dfceca32d26f.xhtml)，“Raspberry
    Pi 的卡通化器和皮肤变换器”。
- en: Detecting an object using the Haar or LBP Classifier
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Haar 或 LBP 分类器检测物体
- en: 'Now that we have loaded the classifier (just once during initialization), we
    can use it to detect faces in each new camera frame. But first, we should do some
    initial processing of the camera image just for face detection, by performing
    the following steps:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经加载了分类器（初始化期间只加载一次），我们就可以用它来检测每个新摄像头帧中的人脸。但首先，我们应该对摄像头图像进行一些初始处理，以便进行人脸检测，具体步骤如下：
- en: '**Grayscale color conversion**: Face detection only works on grayscale images.
    So we should convert the color camera frame to grayscale.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**灰度颜色转换**：人脸检测仅适用于灰度图像。因此，我们应该将彩色摄像头帧转换为灰度。'
- en: '**Shrinking the camera image**: The speed of face detection depends on the
    size of the input image (it is very slow for large images but fast for small images),
    and yet detection is still fairly reliable even at low resolutions. So we should
    shrink the camera image to a more reasonable size (or use a large value for `minFeatureSize`
    in the detector, as explained shortly).'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**缩小摄像头图像**：人脸检测的速度取决于输入图像的大小（对于大图像来说非常慢，但对于小图像来说很快），即使在低分辨率下，检测仍然相当可靠。因此，我们应该将摄像头图像缩小到更合理的大小（或者，如稍后所述，在检测器中将`minFeatureSize`变量的值设置得很大）。'
- en: '**Histogram equalization**: Face detection is not as reliable in low-light
    conditions. So we should perform histogram equalization to improve the contrast
    and brightness.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**直方图均衡化**：在低光照条件下，人脸检测的可靠性不高。因此，我们应该进行直方图均衡化以改善对比度和亮度。'
- en: Grayscale color conversion
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 灰度颜色转换
- en: 'We can easily convert an RGB color image to grayscale using the `cvtColor()`
    function. But we should do this only if we know we have a color image (that is,
    it is not a grayscale camera), and we must specify the format of our input image
    (usually 3-channel BGR on desktop or 4-channel BGRA on mobile). So we should allow
    three different input color formats, as shown in the following code:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`cvtColor()`函数轻松地将RGB彩色图像转换为灰度。但我们应该只在知道我们有一个彩色图像的情况下这样做（也就是说，它不是一个灰度摄像头），并且我们必须指定输入图像的格式（通常在桌面上是3通道BGR，在移动设备上是4通道BGRA）。因此，我们应该允许三种不同的输入颜色格式，如下面的代码所示：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Shrinking the camera image
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缩小摄像头图像
- en: 'We can use the `resize()` function to shrink an image to a certain size or
    scale factor. Face detection usually works quite well for any image size greater
    than 240x240 pixels (unless you need to detect faces that are far away from the
    camera), because it will look for any faces larger than the `minFeatureSize` (typically
    20x20 pixels). So let''s shrink the camera image to be 320 pixels wide; it doesn''t
    matter if the input is a VGA webcam or a five mega pixel HD camera. It is also
    important to remember and enlarge the detection results, because if you detect
    faces in a shrunk image then the results will also be shrunk. Note that instead
    of shrinking the input image, you could use a large value for the `minFeatureSize` variable
    in the detector instead. We must also ensure the image does not become fatter
    or thinner. For example, a widescreen 800x400 image when shrunk to 300x200 would
    make a person look thin. So we must keep the aspect ratio (the ratio of width
    to height) of the output the same as the input. Let''s calculate how much to shrink
    the image width by, then apply the same scale factor to the height as well, as
    follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`resize()`函数将图像缩小到特定大小或缩放因子。人脸检测通常对任何大于240x240像素的图像大小效果都很好（除非你需要检测远离摄像头的面孔），因为人脸检测会寻找大于`minFeatureSize`（通常是20x20像素）的人脸。所以让我们将摄像头图像缩小到320像素宽；无论是VGA摄像头还是五百万像素的HD摄像头，这都无关紧要。同时，记住并放大检测结果也很重要，因为如果你在缩小的图像中检测到人脸，那么结果也会被缩小。请注意，你不必缩小输入图像，也可以在检测器中将`minFeatureSize`变量的值设置得很大。我们还必须确保图像不会变得过宽或过窄。例如，当800x400的宽屏图像缩小到300x200时，会使人物看起来很瘦。因此，我们必须保持输出图像的宽高比（宽度和高度的比率）与输入相同。让我们计算图像宽度需要缩小多少，然后应用相同的缩放因子到高度，如下所示：
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Histogram equalization
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 直方图均衡化
- en: 'We can easily perform histogram equalization to improve the contrast and brightness
    of an image, using the `equalizeHist()` function. Sometimes this will make the
    image look strange, but in general it should improve the brightness and contrast
    and help face detection. The `equalizeHist()` function is used as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`equalizeHist()`函数轻松地进行直方图均衡化，以改善图像的对比度和亮度。有时这会使图像看起来很奇怪，但通常应该提高亮度和对比度，并有助于人脸检测。`equalizeHist()`函数的使用方法如下：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Detecting the face
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测人脸
- en: 'Now that we have converted the image to grayscale, shrunk the image, and equalized
    the histogram, we are ready to detect the faces using the `CascadeClassifier::detectMultiScale()`
    function! There are many parameters that we pass to this function:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将图像转换为灰度，缩小了图像，并均衡了直方图，我们就可以使用`CascadeClassifier::detectMultiScale()`函数来检测面部了！我们向此函数传递了许多参数：
- en: '`minFeatureSize`: This parameter determines the minimum face size that we care
    about, typically 20x20 or 30x30 pixels but this depends on your use case and image
    size. If you are performing face detection on a webcam or smartphone where the
    face will always be very close to the camera, you could enlarge this to 80 x 80
    to have much faster detections, or if you want to detect far away faces, such
    as on a beach with friends, then leave this as 20x20.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minFeatureSize`：此参数确定我们关心的最小面部大小，通常是20x20或30x30像素，但这取决于你的使用情况和图像大小。如果你在摄像头或智能手机上执行面部检测，其中面部始终非常靠近摄像头，你可以将其放大到80
    x 80以获得更快的检测，或者如果你想检测远处的面部，例如在海滩上和朋友在一起，那么保持为20x20。'
- en: '`searchScaleFactor`: This parameter determines how many different sizes of
    faces to look for; typically it would be `1.1`, for good detection, or `1.2` for
    faster detection that does not find the face as often.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`searchScaleFactor`：此参数确定要查找多少种不同大小的面部；通常它会是`1.1`，以获得良好的检测效果，或者`1.2`以获得更快的检测速度，但可能不会经常找到面部。'
- en: '`minNeighbors`: This parameter determines how sure the detector should be that
    it has detected a face, typically a value of `3` but you can set it higher if
    you want more reliable faces, even if many faces are not detected.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minNeighbors`：此参数确定检测器应该有多确信它已经检测到面部，通常值为`3`，但如果你想获得更可靠的面部，即使许多面部没有被检测到，你也可以将其设置得更高。'
- en: '`flags`: This parameter allows you to specify whether to look for all faces
    (default) or only look for the largest face (`CASCADE_FIND_BIGGEST_OBJECT`). If
    you only look for the largest face, it should run faster. There are several other
    parameters you can add to make the detection about 1% or 2% faster, such as `CASCADE_DO_ROUGH_SEARCH`
    or `CASCADE_SCALE_IMAGE`.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flags`：此参数允许你指定是否寻找所有面部（默认）或只寻找最大的面部（`CASCADE_FIND_BIGGEST_OBJECT`）。如果你只寻找最大的面部，它应该运行得更快。你可以添加几个其他参数来使检测速度提高大约1%或2%，例如`CASCADE_DO_ROUGH_SEARCH`或`CASCADE_SCALE_IMAGE`。'
- en: 'The output of the `detectMultiScale()` function will be a `std::vector` of
    the `cv::Rect` type object. For example, if it detects two faces then it will
    store an array of two rectangles in the output. The `detectMultiScale()` function
    is used as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`detectMultiScale()`函数的输出将是一个`cv::Rect`类型对象的`std::vector`。例如，如果它检测到两个面部，那么它将在输出中存储两个矩形的数组。`detectMultiScale()`函数的使用方法如下：'
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We can see if any faces were detected by looking at the number of elements stored
    in our vector of rectangles; that is, by using the `objects.size()` function.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过查看我们矩形向量中存储的元素数量来查看是否检测到了任何面部；即，通过使用`objects.size()`函数。
- en: 'As mentioned earlier, if we gave a shrunken image to the face detector, the
    results will also be shrunk, so we need to enlarge them if we want to know the
    face regions for the original image. We also need to make sure faces on the border
    of the image stay completely within the image, as OpenCV will now raise an exception
    if this happens, as shown by the following code:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，如果我们给面部检测器一个缩小的图像，结果也会缩小，所以如果我们想了解原始图像的面部区域，我们需要将其放大。我们还需要确保图像边缘的面部完全位于图像内，因为如果发生这种情况，OpenCV现在会抛出异常，如下面的代码所示：
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Note that the preceding code will look for all faces in the image, but if you
    only care about one face, then you could change the flag variable as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，前面的代码将寻找图像中的所有面部，但如果你只关心一个面部，那么你可以按以下方式更改标志变量：
- en: '[PRE7]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The `WebcamFaceRec` project includes a wrapper around OpenCV''s Haar or LBP
    detector, to make it easier to find a face or eye within an image. For example:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`WebcamFaceRec`项目包括OpenCV的Haar或LBP检测器的包装，以便更容易在图像中找到面部或眼睛。例如：'
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now that we have a face rectangle, we can use it in many ways, such as to extract
    or crop the face image from the original image. The following code allows us to
    access the face:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有一个面部矩形，我们可以用它以多种方式使用，例如从原始图像中提取或裁剪面部图像。以下代码允许我们访问面部：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following image shows the typical rectangular region given by the face
    detector:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了面部检测器给出的典型矩形区域：
- en: '![](img/image_07_002.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_07_002.jpg)'
- en: Step 2 - face preprocessing
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2步 - 面部预处理
- en: As mentioned earlier, face recognition is extremely vulnerable to changes in
    lighting conditions, face orientation, face expression, and so on, so it is very
    important to reduce these differences as much as possible. Otherwise the face
    recognition algorithm will often think there is more similarity between faces
    of two different people in the same conditions than between two faces of the same
    person.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，人脸识别对光照条件、人脸朝向、面部表情等变化极为敏感，因此尽可能减少这些差异非常重要。否则，人脸识别算法通常会认为在相同条件下，两个人的面部之间的相似性比同一个人的两个面部之间的相似性更大。
- en: The easiest form of face preprocessing is just to apply histogram equalization
    using the `equalizeHist()` function, like we just did for face detection. This
    may be sufficient for some projects where the lighting and positional conditions
    won't change by much. But for reliability in real-world conditions, we need many
    sophisticated techniques, including facial feature detection (for example, detecting
    eyes, nose, mouth, and eyebrows). For simplicity, this chapter will just use eye
    detection and ignore other facial features such as the mouth and nose, which are
    less useful. The following image shows an enlarged view of a typical preprocessed
    face, using the techniques that will be covered in this section.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的人脸预处理形式就是使用 `equalizeHist()` 函数应用直方图均衡化，就像我们刚才对人脸检测所做的那样。这可能对于一些项目来说已经足够，在这些项目中，光照和位置条件不会发生很大变化。但是，为了在现实世界条件下的可靠性，我们需要许多复杂的技术，包括面部特征检测（例如，检测眼睛、鼻子、嘴巴和眉毛）。为了简单起见，本章将仅使用眼睛检测并忽略其他面部特征，如嘴巴和鼻子，这些特征不太有用。以下图像显示了使用本节将要介绍的技术对典型预处理人脸的放大视图。
- en: Eye detection
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 眼睛检测
- en: Eye detection can be very useful for face preprocessing, because for frontal
    faces you can always assume a person's eyes should be horizontal and on opposite
    locations of the face and should have a fairly standard position and size within
    a face, despite changes in facial expressions, lighting conditions, camera properties,
    distance to camera, and so on. It is also useful to discard false positives when
    the face detector says it has detected a face and it is actually something else.
    It is rare that the face detector and two eye detectors will all be fooled at
    the same time, so if you only process images with a detected face and two detected
    eyes then it will not have many false positives (but will also give fewer faces
    for processing, as the eye detector will not work as often as the face detector).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 眼睛检测对于人脸预处理非常有用，因为对于正面人脸，你可以始终假设一个人的眼睛应该是水平的，并且位于脸的相对位置，并且在一个脸内应该有相当标准的位置和大小，尽管面部表情、光照条件、相机属性、与相机的距离等发生变化。当人脸检测器声称它检测到人脸但实际上是其他东西时，丢弃假阳性也是很有用的。同时被人脸检测器和两个眼睛检测器欺骗的情况很少见，所以如果你只处理检测到人脸和两个眼睛的图像，那么假阳性将不会很多（但也会处理更少的人脸，因为眼睛检测器不会像人脸检测器那样经常工作）。
- en: Some of the pretrained eye detectors that come with OpenCV v2.4 can detect an
    eye whether it is open or closed, whereas some of them can only detect open eyes.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV v2.4附带的一些预训练的眼睛检测器可以检测睁眼或闭眼，而其中一些只能检测睁眼。
- en: 'Eye detectors that detect open or closed eyes are as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 检测睁眼或闭眼的眼睛检测器如下：
- en: '`haarcascade_mcs_lefteye.xml` (and `haarcascade_mcs_righteye.xml`)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`haarcascade_mcs_lefteye.xml`（以及 `haarcascade_mcs_righteye.xml`)'
- en: '`haarcascade_lefteye_2splits.xml` (and `haarcascade_righteye_2splits.xml`)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`haarcascade_lefteye_2splits.xml`（以及 `haarcascade_righteye_2splits.xml`）'
- en: 'Eye detectors that detect open eyes only are as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 仅检测睁眼的眼睛检测器如下：
- en: '`haarcascade_eye.xml`'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`haarcascade_eye.xml`'
- en: '`haarcascade_eye_tree_eyeglasses.xml`'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`haarcascade_eye_tree_eyeglasses.xml`'
- en: As the open or closed eye detectors specify which eye they are trained on, you
    need to use a different detector for the left and the right eye, whereas the detectors
    for just open eyes can use the same detector for left or right eyes.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 由于睁眼或闭眼检测器指定了它们训练的是哪只眼睛，因此你需要为左右眼使用不同的检测器，而仅检测睁眼的检测器可以使用左右眼相同的检测器。
- en: The detector `haarcascade_eye_tree_eyeglasses.xml` can detect the eyes if the
    person is wearing glasses, but is not reliable if they don't wear glasses.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 检测器 `haarcascade_eye_tree_eyeglasses.xml` 可以检测佩戴眼镜的人的眼睛，但如果他们不戴眼镜则不可靠。
- en: If the XML filename says *left eye*, it means the actual left eye of the person,
    so in the camera image it would normally appear on the right-hand side of the
    face, not on the left-hand side!
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果XML文件名是*左眼*，那么它指的是人的实际左眼，所以在相机图像中它通常出现在脸的右侧，而不是左侧！
- en: The list of four eye detectors mentioned is ranked in approximate order from
    most reliable to least reliable, so if you know you don't need to find people
    with glasses then the first detector is probably the best choice.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 提到的四个眼检测器的列表按从最可靠到最不可靠的顺序排列，所以如果你知道你不需要找到戴眼镜的人，那么第一个检测器可能是最佳选择。
- en: Eye search regions
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 眼搜索区域
- en: For eye detection, it is important to crop the input image to just show the
    approximate eye region, just like doing face detection and then cropping to just
    a small rectangle where the left eye should be (if you are using the left eye
    detector) and the same for the right rectangle for the right eye detector. If
    you just do eye detection on a whole face or whole photo then it will be much
    slower and less reliable. Different eye detectors are better suited to different
    regions of the face; for example, the `haarcascade_eye.xml` detector works best
    if it only searches in a very tight region around the actual eye, whereas the
    `haarcascade_mcs_lefteye.xml` and `haarcascade_lefteye_2splits.xml` detectors
    work best when there is a large region around the eye.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于眼检测，重要的是将输入图像裁剪，仅显示大约的眼部区域，就像进行人脸检测然后裁剪到仅包含左眼的小矩形中（如果你使用的是左眼检测器）以及对于右眼检测器的相同操作。如果你在整个脸部或整个照片上仅进行眼检测，那么它将慢得多且可靠性较低。不同的眼检测器更适合脸部的不同区域；例如，`haarcascade_eye.xml`检测器在仅搜索实际眼睛周围非常紧密的区域时效果最佳，而`haarcascade_mcs_lefteye.xml`和`haarcascade_lefteye_2splits.xml`检测器在眼睛周围有较大区域时效果最佳。
- en: 'The following table lists some good search regions of the face for different
    eye detectors (when using the LBP face detector), using relative coordinates within
    the detected face rectangle:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 下表列出了不同眼检测器（在使用LBP人脸检测器时）的一些良好的搜索区域，使用检测到的脸矩形内的相对坐标：
- en: '| **Cascade classifier** | **EYE_SX** | **EYE_SY** | **EYE_SW** | **EYE_SH**
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| **级联分类器** | **EYE_SX** | **EYE_SY** | **EYE_SW** | **EYE_SH** |'
- en: '| `haarcascade_eye.xml` | 0.16 | 0.26 | 0.30 | 0.28 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| `haarcascade_eye.xml` | 0.16 | 0.26 | 0.30 | 0.28 |'
- en: '| `haarcascade_mcs_lefteye.xml` | 0.10 | 0.19 | 0.40 | 0.36 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `haarcascade_mcs_lefteye.xml` | 0.10 | 0.19 | 0.40 | 0.36 |'
- en: '| `haarcascade_lefteye_2splits.xml` | 0.12 | 0.17 | 0.37 | 0.36 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| `haarcascade_lefteye_2splits.xml` | 0.12 | 0.17 | 0.37 | 0.36 |'
- en: Here is the source code to extract the left-eye and right-eye regions from a
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是提取左眼和右眼区域的源代码
- en: 'detected face:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 检测到的脸：
- en: '[PRE10]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following image shows the ideal search regions for the different eye detectors,
    where the `haarcascade_eye.xml` and `haarcascade_eye_tree_eyeglasses.xml` files
    are best with the small search region, while the `haarcascade_mcs_*eye.xml` and
    `haarcascade_*eye_2splits.xml` files are best with larger search regions. Note
    that the detected face rectangle is also shown, to give an idea of how large the
    eye search regions are compared to the detected face rectangle:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了不同眼检测器的理想搜索区域，其中`haarcascade_eye.xml`和`haarcascade_eye_tree_eyeglasses.xml`文件最适合小搜索区域，而`haarcascade_mcs_*eye.xml`和`haarcascade_*eye_2splits.xml`文件最适合大搜索区域。请注意，检测到的脸矩形也显示出来，以给出眼搜索区域与检测到的脸矩形相比的大小概念：
- en: '![](img/image_07_003.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/image_07_003.jpg)'
- en: 'When using the eye search regions given in the preceding table, here are the
    approximate detection properties of the different eye detectors:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用前面表格中给出的眼搜索区域时，以下是不同眼检测器的近似检测特性：
- en: '| **Cascade classifier** | **Reliability*** | **Speed**** | **Eyes found**
    | **Glasses** |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| **级联分类器** | **可靠性** | **速度** | **检测到的眼睛** | **眼镜** |'
- en: '| `haarcascade_mcs_lefteye.xml` | 80% | 18 msec | Open or closed | no |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| `haarcascade_mcs_lefteye.xml` | 80% | 18毫秒 | 开或闭 | 无 |'
- en: '| `haarcascade_lefteye_2splits.xml` | 60% | 7 msec | Open or closed | no |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| `haarcascade_lefteye_2splits.xml` | 60% | 7毫秒 | 开或闭 | 无 |'
- en: '| `haarcascade_eye.xml` | 40% | 5 msec | Open only | no |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| `haarcascade_eye.xml` | 40% | 5毫秒 | 仅开 | 无 |'
- en: '| `haarcascade_eye_tree_eyeglasses.xml` | 15% | 10 msec | Open only | yes |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| `haarcascade_eye_tree_eyeglasses.xml` | 15% | 10毫秒 | 仅开 | 是 |'
- en: '*** Reliability** values show how often both eyes will be detected after LBP
    frontal face detection when no eyeglasses are worn and both eyes are open. If
    eyes are closed then the reliability may drop, or if eyeglasses are worn then
    both reliability and speed will drop.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**可靠性**值显示了在无眼镜和双眼睁开的情况下，经过LBP正面面部检测后，双眼被检测到的频率。如果眼睛是闭着的，可靠性可能会下降，或者如果戴着眼镜，可靠性和速度都会下降。'
- en: '**** Speed** values are in milliseconds for images scaled to the size of 320x240
    pixels on an Intel Core i7 2.2 GHz (averaged across 1,000 photos). Speed is typically
    much faster when eyes are found than when eyes are not found, as it must scan
    the entire image, but the `haarcascade_mcs_lefteye.xml` is still much slower than
    the other eye detectors.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**速度**值是以毫秒为单位，针对在Intel Core i7 2.2 GHz（在1000张照片上平均）上缩放到320x240像素大小的图像。当找到眼睛时，速度通常比找不到眼睛时快得多，因为它必须扫描整个图像，但`haarcascade_mcs_lefteye.xml`仍然比其他眼睛检测器慢得多。'
- en: For example, if you shrink a photo to 320x240 pixels, perform a histogram equalization
    on it, use the LBP frontal face detector to get a face, then extract the
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你将照片缩小到320x240像素，对其执行直方图均衡化，使用LBP正面面部检测器获取面部，然后提取
- en: '*left-eye-region* and *right-eye-region* from the face using the `haarcascade_mcs_lefteye.xml`
    values, then perform a histogram equalization on each eye region. Then if you
    the `haarcascade_mcs_lefteye.xml` detector on the left eye (which is actually
    on the top-right side of your image) and use the `haarcascade_mcs_righteye.xml`
    detector on the right eye (the top-left part of your image), each eye detector
    should work in roughly 90 percent of photos with LBP-detected frontal faces. So
    if you want both eyes detected then it should work in roughly 80 percent'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`haarcascade_mcs_lefteye.xml`值从面部检测到**左眼区域**和**右眼区域**，然后对每个眼睛区域执行直方图均衡化。然后，如果你在左眼上使用`haarcascade_mcs_lefteye.xml`检测器（实际上位于图像的右上角）并在右眼上使用`haarcascade_mcs_righteye.xml`检测器（图像的左上部分），每个眼睛检测器应该在大约90%的LBP检测到的正面面部照片中正常工作。所以如果你想检测两只眼睛，那么它应该在大约80%
- en: of photos with LBP-detected frontal faces.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LBP检测到的正面面部照片。
- en: Note that while it is recommended to shrink the camera image before detecting
    faces, you should detect eyes at the full camera resolution because eyes will
    obviously be much smaller than faces, so you need as much resolution as you can
    get.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，虽然建议在检测面部之前缩小相机图像，但你应使用完整的相机分辨率来检测眼睛，因为眼睛显然比面部小得多，因此你需要尽可能多的分辨率。
- en: Based on the table, it seems that when choosing an eye detector to use, you
    should decide whether you want to detect closed eyes or only open eyes. And remember
    that you can even use a one eye detector, and if it does not detect an eye then
    you can try with another one.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 根据表格，似乎在选择要使用的眼睛检测器时，你应该决定是想检测闭眼还是只检测睁眼。并且记住，你甚至可以使用一个单眼检测器，如果它没有检测到眼睛，那么你可以尝试另一个。
- en: For many tasks, it is useful to detect eyes whether they are opened or closed,
    so if speed is not crucial, it is best to search with the `mcs_*eye` detector
    first, and if it fails then search with the `eye_2splits` detector.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多任务，检测睁眼或闭眼的眼晴都是有用的，所以如果速度不是关键因素，最好首先使用`mcs_*eye`检测器进行搜索，如果失败，则使用`eye_2splits`检测器进行搜索。
- en: But for face recognition, a person will appear quite different if their eyes
    are closed, so it is best to search with the plain `haarcascade_eye` detector
    first, and if it fails then search with the `haarcascade_eye_tree_eyeglasses`
    detector.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 但对于面部识别，如果一个人的眼睛是闭着的，那么他们的外观会有很大不同，因此最好首先使用普通的`haarcascade_eye`检测器进行搜索，如果失败，则使用`haarcascade_eye_tree_eyeglasses`检测器进行搜索。
- en: 'We can use the same `detectLargestObject()` function we used for face detection
    to search for eyes, but instead of asking to shrink the images before eye detection,
    we specify the full eye region width to get a better eye detection. It is easy
    to search for the left eye using one detector, and if it fails then try another
    detector (same for right eye). The eye detection is done as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用与面部检测相同的`detectLargestObject()`函数来搜索眼睛，但在进行眼睛检测之前，我们指定完整的眼睛区域宽度以获得更好的眼睛检测。使用一个检测器很容易找到左眼，如果失败，则尝试另一个检测器（右眼也是如此）。眼睛检测的步骤如下：
- en: '[PRE11]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'With the face and both eyes detected, we''ll perform face preprocessing by
    combining:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测到面部和两只眼睛后，我们将通过以下方式执行面部预处理：
- en: '**Geometrical transformation and cropping**: This process would include scaling,
    rotating, and translating the images so that the eyes are aligned, followed by
    the removal of the forehead, chin, ears, and background from the face image.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**几何变换和裁剪**：这个过程将包括缩放、旋转和移动图像，以便眼睛对齐，然后从脸部图像中移除额头、下巴、耳朵和背景。'
- en: '**Separate histogram equalization for left and right sides**: This process
    standardizes the brightness and contrast on both the left- and right-hand sides
    of the face independently.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**左右两侧分别进行直方图均衡化**：这个过程独立地对脸部的左右两侧的亮度和对比度进行标准化。'
- en: '**Smoothing**: This process reduces the image noise using a bilateral filter.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平滑**：这个过程使用双边滤波器减少图像噪声。'
- en: '**Elliptical mask**: The elliptical mask removes some remaining hair and background
    from the face image.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**椭圆形遮罩**：椭圆形遮罩从脸部图像中移除一些剩余的头发和背景。'
- en: 'The following image shows the face preprocessing steps 1 to 4 applied to a
    detected face. Notice how the final image has good brightness and contrast on
    both sides of the face, whereas the original does not:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像显示了将步骤1到4应用于检测到的脸部预处理步骤。注意最终图像在脸部的两侧都有良好的亮度和对比度，而原始图像则没有：
- en: Geometrical transformation
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 几何变换
- en: It is important that the faces are all aligned together, otherwise the face-recognition
    algorithm might be comparing part of a nose with part of an eye, and so on. The
    output of face detection just seen will give aligned faces to some extent, but
    it is not very accurate (that is, the face rectangle will not always be starting
    from the same point on the forehead).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 确保所有脸部都对齐在一起非常重要，否则人脸识别算法可能会将鼻子的部分与眼睛的部分进行比较，等等。刚刚看到的脸部检测输出将在一定程度上提供对齐的脸部，但并不非常准确（也就是说，脸部矩形不会始终从额头上的同一点开始）。
- en: 'To have better alignment, we will use eye detection to align the face so the
    positions of the two detected eyes line up perfectly in the desired positions.
    We will do the geometrical transformation using the `warpAffine()` function, which
    is a single operation that will do four things:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得更好的对齐，我们将使用眼睛检测来对齐脸部，使得两个检测到的眼睛的位置在期望的位置上完美对齐。我们将使用`warpAffine()`函数进行几何变换，这是一个单一的操作，将完成以下四件事情：
- en: Rotate the face so that the two eyes are horizontal
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旋转脸部，使得两个眼睛水平
- en: Scale the face so that the distance between the two eyes is always the same
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将脸部缩放，使得两眼之间的距离始终相同
- en: Translate the face so that the eyes are always centered horizontally and at
    a desired height
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将脸部进行平移，使得眼睛始终水平居中并处于期望的高度
- en: Crop the outer parts of the face, since we want to crop away the image background,
    hair, forehead, ears, and chin
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 裁剪脸部的外部部分，因为我们想要裁剪掉图像背景、头发、额头、耳朵和下巴
- en: 'Affine Warping takes an affine matrix that transforms the two detected eye
    locations to the two desired eye locations, and then crops to a desired size and
    position. To generate this affine matrix, we will get the center between the eyes,
    calculate the angle at which the two detected eyes appear, and look at their distance
    apart as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 仿射变换接受一个仿射矩阵，将两个检测到的眼睛位置变换为两个期望的眼睛位置，然后裁剪到期望的大小和位置。为了生成这个仿射矩阵，我们将获取眼睛之间的中心，计算两个检测到的眼睛出现的角度，并观察它们之间的距离，如下所示：
- en: '[PRE12]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now we can transform the face (rotate, scale, and translate) to get the two
    detected eyes to be in the desired eye positions in an ideal face as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以变换脸部（旋转、缩放和移动），以使两个检测到的眼睛在理想的脸部中位于期望的眼睛位置，如下所示：
- en: '[PRE13]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Separate histogram equalization for left and right sides
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 左右两侧分别进行直方图均衡化
- en: In real-world conditions, it is common to have strong lighting on one half of
    the face and weak lighting on the other. This has an enormous effect on the face-recognition
    algorithm, as the left- and right-hand sides of the same face will seem like very
    different people. So we will perform histogram equalization separately on the
    left and right halves of the face, to have standardized brightness and contrast
    on each side of the face.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界的条件下，脸部的一半通常会有强烈的照明，而另一半则照明较弱。这对人脸识别算法有巨大的影响，因为同一张脸的左右两侧看起来像是非常不同的人。因此，我们将分别对脸部的左右两侧进行直方图均衡化，以使脸部的每一侧都具有标准化的亮度和对比度。
- en: If we simply applied histogram equalization on the left half and then again
    on the right half, we would see a very distinct edge in the middle because the
    average brightness is likely to be different on the left and the right side, so
    to remove this edge, we will apply the two histogram equalizations gradually from
    the left-or right-hand side towards the center and mix it with a whole-face histogram
    equalization, so that the far left-hand side will use the left histogram equalization,
    the far right-hand side will use the right histogram equalization, and the center
    will use a smooth mix of the left or right value and the whole-face equalized
    value.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只是对左半部分应用直方图均衡化，然后再对右半部分应用直方图均衡化，我们会在中间看到一个非常明显的边缘，因为左右两侧的平均亮度很可能是不同的，因此为了消除这个边缘，我们将从左或右侧面逐渐向中心应用两个直方图均衡化，并将其与整个脸部的直方图均衡化混合，这样远左侧面将使用左直方图均衡化，远右侧面将使用右直方图均衡化，而中心将使用左或右值和整个脸部均衡化值的平滑混合。
- en: 'The following image shows how the left-equalized, whole-equalized, and right-equalized
    images are blended together:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像显示了左均衡化、整体均衡化和右均衡化图像是如何混合在一起的：
- en: '![](img/a7829_7_6.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a7829_7_6.png)'
- en: 'To perform this, we need copies of the whole face equalized as well as the
    left half equalized and the right half equalized, which is done as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行此操作，我们需要整个脸部均衡化的副本，以及左半部分均衡化和右半部分均衡化的副本，具体操作如下：
- en: '[PRE14]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now we combine the three images together. As the images are small, we can easily
    access pixels directly using the `image.at<uchar>(y,x)` function even if it is
    slow; so let''s merge the three images by directly accessing pixels in the three
    input images and output images, as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将这三张图像合并在一起。由于图像较小，我们可以通过使用`image.at<uchar>(y,x)`函数直接访问像素，即使它比较慢；因此，让我们通过直接访问三个输入图像和输出图像中的像素来合并这三张图像，如下所示：
- en: '[PRE15]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This separated histogram equalization should significantly help reduce the effect
    of different lighting on the left- and right-hand sides of the face, but we must
    understand that it won't completely remove the effect of one-sided lighting, since
    the face is a complex 3D shape with many shadows.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分离的直方图均衡化应该可以显著减少不同光照对脸部左右两侧的影响，但我们必须理解，它并不能完全消除单侧光照的影响，因为脸部是一个复杂的3D形状，有许多阴影。
- en: Smoothing
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平滑
- en: 'To reduce the effect of pixel noise, we will use a bilateral filter on the
    face, as a bilateral filter is very good at smoothing, most of an image while
    keeping edges sharp. Histogram equalization can significantly increase the pixel
    noise, so we will make the filter strength `20` to cover heavy pixel noise, but
    use a neighborhood of just two pixels as we want to heavily smooth the tiny pixel
    noise but not the large image regions, as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少像素噪声的影响，我们将在脸部使用双边滤波器，因为双边滤波器非常擅长在保持边缘清晰的同时平滑图像的大部分区域。直方图均衡化可以显著增加像素噪声，因此我们将滤波器强度设置为`20`以覆盖严重的像素噪声，但使用仅两个像素的邻域，因为我们想要大量平滑微小的像素噪声，而不是大图像区域，如下所示：
- en: '[PRE16]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Elliptical mask
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 椭圆形蒙版
- en: 'Although we have already removed most of the image background and forehead
    and hair when we did the geometrical transformation, we can apply an elliptical
    mask to remove some of the corner region such as the neck, which might be in shadow
    from the face, particularly if the face is not looking perfectly straight towards
    the camera. To create the mask, we will draw a black-filled ellipse onto a white
    image. One ellipse to perform this has a horizontal radius of 0.5 (that is, it
    covers the face width perfectly), a vertical radius of 0.8 (as faces are usually
    taller than they are wide), and centered at the coordinates 0.5, 0.4, as shown
    in the following image, where the elliptical mask has removed some unwanted corners
    from the face:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在进行几何变换时已经移除了大部分图像背景、额头和头发，但我们仍然可以应用一个椭圆形蒙版来移除一些角落区域，如颈部，这些区域可能因脸部而处于阴影中，尤其是如果脸部没有完美直视相机的话。为了创建这个蒙版，我们将在一个白色图像上绘制一个黑色填充的椭圆形。为了执行此操作，一个椭圆形的水平半径为0.5（即完美覆盖脸部宽度），垂直半径为0.8（因为脸部通常比宽），中心坐标为0.5,
    0.4，如下面的图像所示，其中椭圆形蒙版已经从脸部移除了一些不需要的角落：
- en: '![](img/a7829_7_7.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a7829_7_7.png)'
- en: 'We can apply the mask when calling the `cv::setTo()` function, which would
    normally set a whole image to a certain pixel value, but as we will give a mask
    image, it will only set some parts to the given pixel value. We will fill the
    image in gray so that it should have less contrast to the rest of the face:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在调用`cv::setTo()`函数时应用掩码，该函数通常将整个图像设置为某个像素值，但因为我们提供了一个掩码图像，所以它只会将某些部分设置为给定的像素值。我们将用灰色填充图像，以便它与面部其余部分对比度更低：
- en: '[PRE17]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following enlarged image shows a sample result from all the face preprocessing
    stages. Notice it is much more consistent for face recognition at a different
    brightness, face rotations, angle from camera, backgrounds, positions of lights,
    and so on. This preprocessed face will be used as input to the face-recognition
    stages, both when collecting faces for training, and when trying to recognize
    input faces:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 以下放大图像显示了所有面部预处理阶段的示例结果。请注意，它在不同亮度、面部旋转、摄像头角度、背景、灯光位置等方面对面部识别的一致性要好得多。这个预处理面部将被用作收集面部进行训练和尝试识别输入面部时的面部识别阶段的输入：
- en: '![](img/a7829_7_8.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a7829_7_8.png)'
- en: Step 3 - Collecting faces and learning from them
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3步 - 收集人脸并从中学习
- en: Collecting faces can be just as simple as putting each newly preprocessed face
    into an array of preprocessed faces from the camera, as well as putting a label
    into an array (to specify which person the face was taken from). For example,
    you could use 10 preprocessed faces of the first person and 10 preprocessed faces
    of a second person, so the input to the face-recognition algorithm will be an
    array of 20 preprocessed faces and an array of 20 integers (where the first 10
    numbers are 0 and the next 10 numbers are 1).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 收集人脸可以像将每个新预处理的面部放入来自摄像头的预处理面部数组中一样简单，以及将标签放入数组中（以指定面部是从哪个人那里拍摄的）。例如，您可以使用第一个人预处理的前10张面部和第二个人预处理的前10张面部，因此面部识别算法的输入将是一个包含20张预处理面部的数组和一个包含20个整数的数组（其中前10个数字是0，接下来的10个数字是1）。
- en: The face-recognition algorithm will then learn how to distinguish between the
    faces of the different people. This is referred to as the training phase and the
    collected faces are referred to as the training set. After the face-recognition
    algorithm has finished training, you could then save the generated knowledge to
    a file or memory and later use it to recognize which person is seen in front of
    the camera. This is referred to as the testing phase. If you used it directly
    from a camera input then the preprocessed face would be referred to as the test
    image, and if you tested with many images (such as from a folder of image files),
    it would be referred to as the testing set.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 面部识别算法将学习如何区分不同人的面部。这被称为训练阶段，收集的面部被称为训练集。面部识别算法完成训练后，您可以将其生成的知识保存到文件或内存中，然后用于识别摄像头前的人。这被称为测试阶段。如果您直接从摄像头输入使用，则预处理后的面部被称为测试图像；如果您使用多张图像（例如从图像文件文件夹中）进行测试，则称为测试集。
- en: It is important that you provide a good training set that covers the types of
    variations you expect to occur in your testing set. For example, if you will only
    test with faces that are looking perfectly straight ahead (such as ID photos),
    then you only need to provide training images with faces that are looking perfectly
    straight ahead. But if the person might be looking to the left or up, then you
    should make sure the training set will also include faces of that person doing
    this, otherwise the face-recognition algorithm will have trouble recognizing them,
    as their face will appear quite different. This also applies to other factors
    such as facial expression (for example, if the person is always smiling in the
    training set but not smiling in the testing set) or lighting direction (for example,
    a strong light is to the left-hand side in the training set but to the right-hand
    side in the testing set), then the face recognition algorithm will have difficulty
    recognizing them. The face preprocessing steps that we just saw will help reduce
    these issues, but it certainly won't remove these factors, particularly the direction
    in which the face is looking, as it has a large effect on the position of all
    elements in the face.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 提供一个涵盖你预期在测试集中出现的各种变化的良好训练集非常重要。例如，如果你只使用正面直视的脸部进行测试（例如身份证照片），那么你只需要提供正面直视的脸部训练图像。但如果这个人可能向左或向上看，那么你应该确保训练集也包括这个人这样做时的脸部图像，否则面部识别算法将难以识别他们，因为他们的脸部看起来会相当不同。这也适用于其他因素，如面部表情（例如，如果训练集中的人总是微笑，但在测试集中不微笑）或光照方向（例如，训练集中强烈的灯光在左侧，但在测试集中在右侧），那么面部识别算法将难以识别他们。我们刚才看到的面部预处理步骤将有助于减少这些问题，但绝对不能消除这些因素，尤其是脸部朝向的方向，因为它对脸部所有元素的位置都有很大影响。
- en: One way to obtain a good training set that will cover many different real-world
    conditions is for each person to rotate their head from looking left, to up, to
    right, to down, then looking directly straight. Then the person tilts their head
    sideways and then up and down, while also changing their facial expression, such
    as alternating between smiling, looking angry, and having a neutral face. If each
    person follows a routine such as this while collecting faces, then there is a
    much better chance of recognizing everyone in the real-world conditions.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 获得一个能够涵盖许多不同真实世界条件的良好训练集的一种方法，是让每个人从向左看，转到向上看，再转到向右看，然后向下看，最后直接向前看。然后，这个人将头部向侧面倾斜，并上下移动，同时改变面部表情，例如在微笑、愤怒和保持中性表情之间交替。如果每个人在收集面部图像时都遵循这样的常规，那么在真实世界条件下识别每个人的可能性会大得多。
- en: For even better results, it should be performed again with one or two more locations
    or directions, such as by turning the camera around by 180 degrees and walking
    in the opposite direction of the camera and then repeating the whole routine,
    so that the training set would include many different lighting conditions.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得更好的结果，应该再次在更多的一个或两个位置或方向上执行，例如通过将相机旋转180度，然后向与相机相反的方向行走，并重复整个程序，这样训练集就会包括许多不同的光照条件。
- en: So in general, having 100 training faces for each person is likely to give better
    results than having just 10 training faces for each person, but if all 100 faces
    look almost identical then it will still perform badly because it is more important
    that the training set has enough variety to cover the testing set, rather than
    to just have a large number of faces. So to make sure the faces in the training
    set are not all too similar, we should add a noticeable delay between each collected
    face. For example, if the camera is running at 30 frames per second, then it might
    collect 100 faces in just several seconds when the person has not had time to
    move around, so it is better to collect just one face per second, while the person
    moves their face around. Another simple method to improve the variation in the
    training set is to only collect a face if it is noticeably different from the
    previously collected face.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一般来说，为每个人提供100个训练面部可能比每人只有10个训练面部给出更好的结果，但如果所有100个面部几乎完全相同，那么它仍然表现不佳，因为更重要的是训练集有足够的多样性来覆盖测试集，而不是仅仅拥有大量的面部。所以为了确保训练集中的面部不是都太相似，我们应在每个收集到的面部之间添加一个明显的延迟。例如，如果相机以每秒30帧的速度运行，那么当这个人没有时间移动时，它可能在几秒钟内收集100个面部，所以最好每秒只收集一个面部，同时这个人移动他们的面部。另一种提高训练集多样性的简单方法是在收集面部时，只有当它与之前收集到的面部明显不同时才收集。
- en: Collecting preprocessed faces for training
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集预处理面部进行训练
- en: 'To make sure there is at least a 1 second gap between collecting new faces,
    we need to measure how much time has passed. This is done as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保收集新面部之间至少有1秒的间隔，我们需要测量已经过去的时间。这是按照以下步骤进行的：
- en: '[PRE18]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To compare the similarity of two images, pixel by pixel, you can find the relative
    L2 error, which just involves subtracting one image from the other, summing the
    squared value of it, and then getting the square root of it. So if the person
    had not moved at all, subtracting the current face with the previous face should
    give a very low number at each pixel, but if they had just moved slightly in any
    direction, subtracting the pixels would give a large number and so the L2 error
    will be high. As the result is summed over all pixels, the value will depend on
    the image resolution. So to get the mean error, we should divide this value by
    the total number of pixels in the image. Let''s put this in a handy function,
    `getSimilarity()`, as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 要比较两张图像的相似度，逐像素比较，你可以找到相对L2误差，这仅仅涉及从一张图像中减去另一张图像，求和其平方值，然后取其平方根。所以如果这个人完全没有移动，当前面部与之前面部的减法应该在每个像素上给出一个非常小的数字，但如果他们只在任何方向上稍微移动了一点，减去像素会给出一个大的数字，因此L2误差会很高。由于结果是所有像素的总和，所以这个值将取决于图像分辨率。因此，为了得到平均误差，我们应该将这个值除以图像中的总像素数。让我们把这个放入一个方便的函数`getSimilarity()`中，如下所示：
- en: '[PRE19]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This similarity will often be less than 0.2 if the image did not move much,
    and
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果图像没有太大移动，这个相似度通常会小于0.2，
- en: higher than 0.4 if the image did move, so let's use 0.3 as our threshold for
    collecting
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果图像移动了，这个相似度会高于0.4，所以让我们将0.3作为我们收集的阈值
- en: a new face.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一个新的面部。
- en: 'There are many tricks we can play to obtain more training data, such as using
    mirrored faces, adding random noise, shifting the face by a few pixels, scaling
    the face by a percentage, or rotating the face by a few degrees (even though we
    specifically tried to remove these effects when preprocessing the face!). Let''s
    add mirrored faces to the training set, so that we have both a larger training
    set as well as a reduction in the problems of asymmetrical faces or if a user
    is always oriented slightly to the left or right during training but not testing.
    This is done as follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以采取许多技巧来获取更多的训练数据，例如使用镜像面部、添加随机噪声、将面部移动几个像素、按百分比缩放面部，或者旋转面部几个度（尽管我们在预处理面部时特意尝试去除这些效果！）。让我们将镜像面部添加到训练集中，这样我们就有了一个更大的训练集，同时减少了不对称面部的问题，或者如果用户在训练时总是稍微向左或向右倾斜，但在测试时没有这样做。这是按照以下步骤进行的：
- en: '[PRE20]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This will collect the `std::vector` arrays `preprocessedFaces` and `faceLabels`
    for a preprocessed face as well as the label or ID number of that person (assuming
    it is in the integer `m_selectedPerson` variable).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这将收集预处理面部`std::vector`数组`preprocessedFaces`和`faceLabels`以及该人的标签或ID号（假设它在整数`m_selectedPerson`变量中）。
- en: 'To make it more obvious to the user that we have added their current face to
    the collection, you could provide a visual notification by either displaying a
    large white rectangle over the whole image or just displaying their face for just
    a fraction of a second so they realize a photo was taken. With OpenCV''s C++ interface,
    you can use the `+` overloaded `cv::Mat` operator to add a value to every pixel
    in the image and have it clipped to 255 (using `saturate_cast`, so it doesn''t
    overflow from white back to black!) Assuming `displayedFrame` will be a copy of
    the color camera frame that should be shown, insert this after the preceding code
    for face collection:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让用户更明显地意识到我们已经将他们的当前面部添加到集合中，您可以通过在整张图像上显示一个大的白色矩形或仅显示他们的面部几秒钟来实现视觉通知，使他们意识到已经拍摄了一张照片。使用OpenCV的C++接口，您可以使用`+`重载的`cv::Mat`运算符向图像中的每个像素添加值，并将其裁剪到255（使用`saturate_cast`，这样就不会从白色溢出到黑色！）假设`displayedFrame`将是应该显示的颜色摄像头帧的副本，在收集人脸的前面代码后插入此代码：
- en: '[PRE21]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Training the face recognition system from collected faces
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从收集的人脸训练人脸识别系统
- en: After you have collected enough faces for each person to recognize, you must
    train the system to learn the data using a machine-learning algorithm suited for
    face recognition. There are many different face-recognition algorithms in the
    literature, the simplest of which are Eigenfaces and Artificial Neural Networks.
    Eigenfaces tends to work better than ANNs, and despite its simplicity, it tends
    to work almost as well as many more complex face-recognition algorithms, so it
    has become very popular as the basic face-recognition algorithm for beginners
    as well as for new algorithms to be compared to.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在为每个人收集足够的人脸以供识别后，您必须使用适合人脸识别的机器学习算法来训练系统学习数据。文献中有很多不同的人脸识别算法，其中最简单的是Eigenfaces和人工神经网络。Eigenfaces通常比人工神经网络表现更好，尽管它很简单，但它的表现几乎与许多更复杂的人脸识别算法相当，因此它已成为初学者以及与新技术比较的基本人脸识别算法。
- en: 'Any reader who wishes to work further on face recognition is recommended to
    read the theory behind:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 建议任何希望进一步研究人脸识别的读者阅读以下理论：
- en: Eigenfaces (also referred to as **Principal Component Analysis** (**PCA**)
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eigenfaces（也称为**主成分分析**（**PCA**））
- en: Fisherfaces (also referred to as **Linear Discriminant Analysis** (**LDA**)
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fisherfaces（也称为**线性判别分析**（**LDA**））
- en: Other classic face recognition algorithms (many are available at [h t t p ://w
    w w . f a c e - r e c . o r g /a l g o r i t h m s /](http://www.face-rec.org/algorithms/))
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他经典的人脸识别算法（许多可以在[http://www.face-rec.org/algorithms/](http://www.face-rec.org/algorithms/)找到）
- en: Newer face recognition algorithms in recent Computer Vision research papers
    (such as CVPR and ICCV at [http://www.cvpapers.com/](http://www.cvpapers.com/)),
    as there are hundreds of face recognition papers published each year
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 近期计算机视觉研究论文中更新的面部识别算法（如CVPR和ICCV在[http://www.cvpapers.com/](http://www.cvpapers.com/)），每年有数百篇面部识别论文发表
- en: 'However, you don''t need to understand the theory of these algorithms in order
    to use them as shown in this book. Thanks to the OpenCV team and Philipp Wagner''s
    `libfacerec` contribution, OpenCV v2.4.1 provided `cv::Algo``rithm` as a simple
    and generic method to perform face recognition using one of several different
    algorithms (even selectable at runtime) without necessarily understanding how
    they are implemented. You can find the available algorithms in your version of
    OpenCV by using the `Algorithm::getList()` function, such as with this code:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您不需要理解这些算法的理论，就可以像本书中展示的那样使用它们。感谢OpenCV团队和Philipp Wagner的`libfacerec`贡献，OpenCV
    v2.4.1提供了`cv::Algorithm`作为使用几种不同算法（甚至可以在运行时选择）进行人脸识别的简单通用方法，而不必理解它们是如何实现的。您可以通过使用`Algorithm::getList()`函数找到您版本OpenCV中可用的算法，例如以下代码：
- en: '[PRE22]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here are the three face-recognition algorithms available in OpenCV v2.4.1:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是OpenCV v2.4.1中可用的三种人脸识别算法：
- en: '`FaceRecognizer.Eigenfaces`: Eigenfaces, also referred to as PCA, first used
    by Turk and Pentland in 1991.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FaceRecognizer.Eigenfaces`：Eigenfaces，也称为PCA，由Turk和Pentland于1991年首次使用。'
- en: '`FaceRecognizer.Fisherfaces`: Fisherfaces, also referred to as LDA, invented
    by Belhumeur, Hespanha, and Kriegman in 1997.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FaceRecognizer.Fisherfaces`：Fisherfaces，也称为LDA，由Belhumeur、Hespanha和Kriegman于1997年发明。'
- en: '`FaceRecognizer.LBPH`: Local Binary Pattern Histograms, invented by Ahonen,
    Hadid, and Pietikäinen in 2004.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FaceRecognizer.LBPH`：局部二值模式直方图，由Ahonen、Hadid和Pietikäinen于2004年发明。'
- en: More information on these face-recognition algorithm implementations can be
    found with documentation, samples, and Python equivalents for each of them on
    Philipp Wagner's websites ([http://bytefish.de/blog](http://bytefish.de/blog)
    and [http://bytefish.de/dev/libfacerec/](http://bytefish.de/dev/libfacerec/)).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些人脸识别算法实现的更多信息可以在Philipp Wagner的网站上找到，包括文档、示例和每个算法的Python等效代码（[http://bytefish.de/blog](http://bytefish.de/blog)
    和 [http://bytefish.de/dev/libfacerec/](http://bytefish.de/dev/libfacerec/))。
- en: 'These face recognition-algorithms are available through the `FaceRecognizer`
    class in OpenCV''s `contrib` module. Due to dynamic linking, it is possible that
    your program is linked to the `contrib` module but it is not actually loaded at
    runtime (if it was deemed as not required). So it is recommended to call the `cv::initModule_contrib()`
    function before trying to access the `FaceRecognizer` algorithms. This function
    is only available from OpenCV v2.4.1, so it also ensures that the face-recognition
    algorithms are at least available to you at compile time:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这些人脸识别算法可以通过OpenCV的`contrib`模块中的`FaceRecognizer`类获得。由于动态链接，您的程序可能链接到了`contrib`模块，但在运行时实际上并没有加载（如果它被认为不是必需的）。因此，建议在尝试访问`FaceRecognizer`算法之前调用`cv::initModule_contrib()`函数。此函数仅从OpenCV
    v2.4.1版本开始提供，因此它还确保人脸识别算法至少在编译时对您可用：
- en: '[PRE23]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To use one of the face-recognition algorithms, we must create a `FaceRecognizer`
    object using the `cv::Algorithm::create<FaceRecognizer>()` function. We pass the
    name of the face-recognition algorithm we want to use, as a string to this create
    function. This will give us access to that algorithm, if it is available in the
    OpenCV version. So it may be used as a runtime error check to ensure the user
    has OpenCV v2.4.1 or newer. For example:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用人脸识别算法之一，我们必须使用`cv::Algorithm::create<FaceRecognizer>()`函数创建一个`FaceRecognizer`对象。我们将要使用的人脸识别算法的名称作为字符串传递给这个创建函数。这将使我们能够访问该算法，如果它在OpenCV版本中可用。因此，它可以作为一个运行时错误检查，以确保用户有OpenCV
    v2.4.1或更新的版本。例如：
- en: '[PRE24]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Once we have loaded the `FaceRecognizer` algorithm, we simply call the `FaceRecognizer::train()`
    function with our collected face data as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们加载了`FaceRecognizer`算法，我们只需使用以下方式调用`FaceRecognizer::train()`函数，并传入我们收集到的面部数据：
- en: '[PRE25]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This one line of code will run the whole face recognition training algorithm
    that you selected (for example, Eigenfaces, Fisherfaces, or potentially other
    algorithms). If you have just a few people with less than 20 faces, then this
    training should return very quickly, but if you have many people with many faces,
    it is possible that `train()` function will take several seconds or even minutes
    to process all the data.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这一行代码将运行您所选的整个人脸识别训练算法（例如，Eigenfaces、Fisherfaces或可能的其他算法）。如果您只有少数人，且每人少于20张脸，那么这次训练应该会非常快地完成，但如果您有很多人，且每人有很多张脸，那么`train()`函数可能需要几秒钟甚至几分钟来处理所有数据。
- en: Viewing the learned knowledge
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看学习到的知识
- en: While it is not necessary, it is quite useful to view the internal data structures
    that the face-recognition algorithm generated when learning your training data,
    particularly if you understand the theory behind the algorithm you selected and
    want to verify if it worked or find out why it is not working as you hoped. The
    internal data structures can be different for different algorithms, but luckily
    they are the same for eigenfaces and fisherfaces, so let's just look at those
    two. They are both based on 1D eigenvector matrices that appear somewhat like
    faces when viewed as 2D images, therefore it is common to refer as eigenvectors
    as eigenfaces when using the **Eigenface** algorithm or as fisherfaces when using
    the **Fisherface** algorithm.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这不是必需的，但查看人脸识别算法在学习您的训练数据时生成的内部数据结构非常有用，尤其是如果您理解您选择的算法背后的理论，并希望验证它是否按预期工作或找出为什么它没有按预期工作。不同的算法可能有不同的内部数据结构，但幸运的是，对于主成分面（eigenfaces）和Fisher面（fisherfaces），它们是相同的，所以我们只需查看这两个。它们都基于1D特征向量矩阵，当作为2D图像查看时，看起来有点像人脸，因此在使用**Eigenface**算法时通常将特征向量称为eigenfaces，在使用**Fisherface**算法时称为fisherfaces。
- en: In simple terms, the basic principle of Eigenfaces is that it will calculate
    a set of special images (eigenfaces) and blending ratios (eigenvalues), which
    when combined in different ways can generate each of the images in the training
    set but can also be used to differentiate the many face images in the training
    set from each other. For example, if some of the faces in the training set had
    a moustache and some did not, then there would be at least one eigenface that
    shows a moustache, and so the training faces with a moustache would have a high
    blending ratio for that eigenface to show that it has a moustache, and the faces
    without a moustache would have a low blending ratio for that eigenvector. If the
    training set had five people with 20 faces for each person, then there would be
    100 eigenfaces and eigenvalues to differentiate the 100 total faces in the training
    set, and in fact these would be sorted so the first few eigenfaces and eigenvalues
    would be the most critical differentiators, and the last few eigenfaces and eigenvalues
    would just be random pixel noises that don't actually help to differentiate the
    data. So it is common practice to discard some of the last eigenfaces and just
    keep the first 50 or so eigenfaces.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，Eigenfaces的基本原理是，它将计算一组特殊的图像（特征脸）和混合比（特征值），这些图像以不同的方式组合可以生成训练集中每个图像，同时也可以用来区分训练集中许多不同的脸图像。例如，如果训练集中的一些人脸有胡须，而另一些没有，那么至少会有一个特征脸显示出胡须，因此有胡须的训练人脸将会有一个高混合比的特征脸来显示它有胡须，而没有胡须的人脸将会有一个低混合比的特征向量。如果训练集中有五个人，每人有20张脸，那么将会有100个特征脸和特征值来区分训练集中的100张脸，实际上这些特征脸和特征值会被排序，前几个特征脸和特征值将是最重要的区分因素，而最后几个特征脸和特征值将只是随机像素噪声，实际上并不能帮助区分数据。因此，通常的做法是丢弃一些最后的特征脸，只保留前50个左右的特征脸。
- en: In comparison, the basic principle of Fisherfaces is that instead of calculating
    a special eigenvector and eigenvalue for each image in the training set, it only
    calculates one special eigenvector and eigenvalue for each person. So in the preceding
    example that has fivepeople with 20 faces for each person, the Eigenfaces algorithm
    would use 100 eigenfaces and eigenvalues whereas the Fisherfaces algorithm would
    use just five fisherfaces and eigenvalues.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 与之相比，Fisherfaces的基本原理是，它不是为训练集中每个图像计算一个特殊的特征向量和特征值，而是为每个人只计算一个特殊的特征向量和特征值。因此，在前面提到的例子中，有五个人，每人有20张脸，Eigenfaces算法将使用100个特征脸和特征值，而Fisherfaces算法只需使用五个fisherfaces和特征值。
- en: 'To access the internal data structures of the Eigenfaces and Fisherfaces algorithms,
    we must use the `cv::Algorithm::get()` function to obtain them at runtime, as
    there is no access to them at compile time. The data structures are used internally
    as part of mathematical calculations rather than for image processing, so they
    are usually stored as floating-point numbers typically ranging between 0.0 and
    1.0, rather than 8-bit `uchar` pixels ranging from 0 to 255, similar to pixels
    in regular images. Also, they are often either a 1D row or column matrix or they
    make up one of the many 1D rows or columns of a larger matrix. So before you can
    display many of these internal data structures, you must reshape them to be the
    correct rectangular shape, and convert them to 8-bit `uchar` pixels between 0
    and 255\. As the matrix data might range from 0.0 to 1.0 or -1.0 to 1.0 or anything
    else, you can use the `cv::normalize()` function with the `cv::NORM_MINMAX` option
    to make sure it outputs data ranging between 0 and 255 no matter what the input
    range may be. Let''s create a function to perform this reshaping to a rectangle
    and conversion to 8-bit pixels for us as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问Eigenfaces和Fisherfaces算法的内部数据结构，我们必须使用`cv::Algorithm::get()`函数在运行时获取它们，因为在编译时无法访问它们。这些数据结构作为数学计算的一部分内部使用，而不是用于图像处理，因此它们通常以介于0.0和1.0之间的浮点数存储，而不是介于0到255之间的8位`uchar`像素，类似于常规图像中的像素。此外，它们通常是1D行或列矩阵，或者构成更大矩阵的许多1D行或列之一。因此，在您能够显示这些内部数据结构之前，您必须将它们重塑为正确的矩形形状，并将它们转换为介于0到255之间的8位`uchar`像素。由于矩阵数据可能介于0.0到1.0或-1.0到1.0或任何其他值，您可以使用带有`cv::NORM_MINMAX`选项的`cv::normalize()`函数来确保无论输入范围如何，它都输出介于0到255之间的数据。以下是一个创建函数以执行此重塑到矩形形状并将它们转换为8位像素的示例：
- en: '[PRE26]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To make it easier to debug OpenCV code and even more so, when internally debugging
    the `cv::Algorithm` data structure, we can use the `ImageUtils.cpp` and `ImageUtils.h`
    files to display information about a `cv::Mat` structure easily as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易调试OpenCV代码，尤其是在内部调试`cv::Algorithm`数据结构时，我们可以使用`ImageUtils.cpp`和`ImageUtils.h`文件来轻松显示有关`cv::Mat`结构的信息，如下所示：
- en: '[PRE27]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You will see something similar to the following printed to your console:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在控制台看到类似以下内容打印出来：
- en: '[PRE28]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This tells you that it is 640 elements wide and 480 high (that is, a 640 x 480
    image or a 480 x 640 matrix, depending on how you view it), with three channels
    per pixel that are 8-bits each (that is, a regular BGR image), and it shows the
    min and max value in the image for each of the color channels.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明它宽度为640个元素，高度为480个元素（即640 x 480的图像或480 x 640的矩阵，具体取决于你如何查看它），每个像素有三个通道，每个通道是8位的（即常规BGR图像），并且它显示了图像中每个颜色通道的最小值和最大值。
- en: It is also possible to print the actual contents of an image or matrix by using
    the `printMat()` function instead of the `printMatInfo()` function. This is quite
    handy for viewing matrices and multichannel-float matrices as these can be quite
    tricky to view for beginners.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以通过使用`printMat()`函数而不是`printMatInfo()`函数来打印图像或矩阵的实际内容。这对于查看矩阵和多通道浮点矩阵非常有用，因为这些对于初学者来说可能相当难以查看。
- en: The `ImageUtils` code is mostly for OpenCV's C interface, but is gradually including
    more of the C++ interface over time. The most recent version can be found at [http://shervinemami.info/openCV.html](http://shervinemami.info/openCV.html).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`ImageUtils`代码主要是为OpenCV的C接口编写的，但随着时间的推移，它逐渐包括了更多的C++接口。最新版本可以在[http://shervinemami.info/openCV.html](http://shervinemami.info/openCV.html)找到。'
- en: Average face
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平均脸
- en: 'Both the Eigenfaces and Fisherfaces algorithms first calculate the average
    face that is the mathematical average of all the training images, so they can
    subtract the average image from each facial image to have better face recognition
    results. So let''s view the average face from our training set. The average face
    is named `mean` in the Eigenfaces and Fisherfaces implementations, shown as follows:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是Eigenfaces算法还是Fisherfaces算法，它们首先计算平均脸，即所有训练图像的数学平均值，因此它们可以从每个面部图像中减去平均图像，以获得更好的面部识别结果。因此，让我们查看我们的训练集中的平均脸。在Eigenfaces和Fisherfaces实现中，平均脸被命名为`mean`，如下所示：
- en: '[PRE29]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You should now see an average face image on your screen similar to the following
    (enlarged) image that is a combination of a man, a woman, and a baby. You should
    also see similar text to this shown on your console:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该在屏幕上看到类似以下（放大）的平均脸图像，它是一个男人、一个女人和一个婴儿的组合。你也应该在控制台上看到类似此处的文本：
- en: '[PRE30]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The image would appear as shown in the following screenshot:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图像将如图下所示截图所示：
- en: '![](img/a7829_7_9.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a7829_7_9.png)'
- en: Notice that `averageFace (row)` was a single row matrix of 64-bit floats, whereas
    `averageFace` is a rectangular image with 8-bit pixels covering the full range
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到`averageFace (row)`是一个64位浮点数的单行矩阵，而`averageFace`是一个覆盖整个范围的8位像素的矩形图像
- en: from 0 to 255.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 从0到255。
- en: Eigenvalues, Eigenfaces, and Fisherfaces
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征值、Eigenfaces和Fisherfaces
- en: 'Let''s view the actual component values in the eigenvalues (as text):'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看特征值中的实际分量值（以文本形式）：
- en: '[PRE31]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'For Eigenfaces, there is one eigenvalue for each face, so if we have three
    people with four faces each, we get a column vector with 12 eigenvalues sorted
    from best to worst as follows:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Eigenfaces，每个面部都有一个特征值，所以如果我们有三个人各有四个面部，我们得到一个包含12个特征值的列向量，从最好到最差排序如下：
- en: '[PRE32]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'For Fisherfaces, there is just one eigenvalue for each extra person, so if
    there are three people with four faces each, we just get a row vector with two
    eigenvalues as follows:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Fisherfaces，每个额外的人只有一个特征值，所以如果有三个人各有四个面部，我们只得到一个包含两个特征值的行向量，如下所示：
- en: '[PRE33]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'To view the eigenvectors (as Eigenface or Fisherface images), we must extract
    them as columns from the big eigenvectors matrix. As data in OpenCV and C/C++
    is normally stored in matrices using row-major order, it means that to extract
    a column, we should use the `Mat::clone()` function to ensure the data will be
    continuous, otherwise we can''t reshape the data to a rectangle. Once we have
    a continuous column `Mat`, we can display the eigenvectors using the `getImageFrom1DFloatMat()`
    function just like we did for the average face:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看特征向量（作为特征脸或费舍尔脸图像），我们必须从大特征向量矩阵中提取它们作为列。由于OpenCV和C/C++中的数据通常使用行主序存储在矩阵中，这意味着要提取一列，我们应该使用`Mat::clone()`函数来确保数据将是连续的，否则我们无法将数据重塑为矩形。一旦我们有一个连续的列`Mat`，我们就可以使用`getImageFrom1DFloatMat()`函数来显示特征向量，就像我们为平均脸所做的那样：
- en: '[PRE34]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The following figure displays eigenvectors as images. You can see that for
    three people with four faces, there are 12 Eigenfaces (left-hand side of the figure)
    or two Fisherfaces (right-hand side):'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了特征向量作为图像。你可以看到，对于有四个脸的三个人的情况，存在12个特征脸（图的左侧）或两个费舍尔脸（图的右侧）：
- en: '![](img/a7829_7_10.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a7829_7_10.png)'
- en: Notice that both Eigenfaces and Fisherfaces seem to have the resemblance of
    some facial features but they don't really look like faces. This is simply because
    the average face was subtracted from them, so they just show the differences for
    each Eigenface from the average face. The numbering shows which Eigenface it is,
    because they are always ordered from the most significant Eigenface to the least
    significant Eigenface, and if you have 50 or more Eigenfaces then the later Eigenfaces
    will often just show random image noise and therefore should be discarded.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，特征脸和费舍尔脸似乎都有一些面部特征的相似之处，但它们实际上并不像脸。这仅仅是因为从它们中减去了平均脸，所以它们只是显示了每个特征脸与平均脸的差异。编号显示了它是哪个特征脸，因为它们总是从最重要的特征脸到最不重要的特征脸有序排列，如果你有50个或更多的特征脸，那么后面的特征脸通常会只显示随机的图像噪声，因此应该被丢弃。
- en: Step 4 - face recognition
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4步 - 面部识别
- en: Now that we have trained the Eigenfaces or Fisherfaces machine-learning algorithm
    with our set of training images and face labels, we are finally ready to figure
    out who a person is, just from a facial image! This last step is referred to as
    face recognition or face identification.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经使用我们的训练图像和面部标签集训练了特征脸或费舍尔脸机器学习算法，我们终于准备好确定一个人的身份，仅从面部图像中！这一最后步骤被称为面部识别或面部识别。
- en: Face identification - recognizing people from their face
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部识别 - 从面部识别人
- en: Thanks to OpenCV's `FaceRecognizer` class, we can identify the person in a photo
    simply by calling the `FaceRecognizer::predict()` function on a facial image
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢OpenCV的`FaceRecognizer`类，我们可以通过在面部图像上调用`FaceRecognizer::predict()`函数来简单地识别照片中的人
- en: 'as follows:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示：
- en: '[PRE35]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This `identity` value will be the label number that we originally used when
    collecting faces for training. For example, 0 for the first person, 1 for the
    second person, and so on.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`identity`值将是我们最初在收集训练用面部时使用的标签号。例如，第一个人为0，第二个人为1，依此类推。
- en: The problem with this identification is that it will always predict one of the
    given people, even if the input photo is of an unknown person or of a car. It
    would still tell you which person is the most likely person in that photo, so
    it can be difficult to trust the result! The solution is to obtain a confidence
    metric so we can judge how reliable the result is, and if it seems that the confidence
    is too low then we assume it is an unknown person.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这个识别的问题在于，它总是会预测给定的人之一，即使输入的照片是未知的人或汽车的照片。它仍然会告诉你照片中最可能的人是谁，因此很难相信结果！解决方案是获得一个置信度指标，这样我们就可以判断结果有多可靠，如果看起来置信度太低，那么我们假设它是一个未知的人。
- en: Face verification - validating that it is the claimed person
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部验证 - 验证是否为声称的人
- en: To confirm if the result of the prediction is reliable or whether it should
    be taken as an unknown person, we perform **face verification** (also referred
    to as **face authentication**), to obtain a confidence metric showing whether
    the single face image is similar to the claimed person (as opposed to face identification,
    which we just performed, comparing the single face image with many people).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确认预测结果是否可靠，或者是否应该将其视为未知的人，我们执行**面部验证**（也称为**面部认证**），以获得一个置信度指标，显示单个面部图像是否与声称的人相似（与我们所做的面部识别相反，我们比较的是单个面部图像与许多人）。
- en: OpenCV's `FaceRecognizer` class can return a confidence metric when you call
    the `predict()` function but unfortunately the confidence metric is simply based
    on the distance in eigen-subspace, so it is not very reliable. The method we will
    use is to reconstruct the facial image using the *eigenvectors* and *eigenvalues*,
    and compare this reconstructed image with the input image. If the person had many
    of their faces included in the training set, then the reconstruction should work
    quite well from the learned eigenvectors and eigenvalues, but if the person did
    not have any faces in the training set (or did not have any that have similar
    lighting and facial expressions as the test image), then the reconstructed face
    will look very different from the input face, signaling that it is probably an
    unknown face.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 当你调用`predict()`函数时，OpenCV的`FaceRecognizer`类可以返回一个置信度指标，但遗憾的是，置信度指标仅仅是基于特征子空间中的距离，因此它并不非常可靠。我们将使用的方法是使用*特征向量*和*特征值*来重建面部图像，并将这个重建图像与输入图像进行比较。如果这个人在训练集中包含了很多面部，那么从学习到的特征向量和特征值中重建应该会相当好，但如果这个人在训练集中没有任何面部（或者没有与测试图像具有相似照明和面部表情的面部），那么重建的面部将与输入面部非常不同，这表明它可能是一个未知的面部。
- en: Remember we said earlier that the Eigenfaces and Fisherfaces algorithms are
    based on the notion that an image can be roughly represented as a set of eigenvectors
    (special face images) and eigenvalues (blending ratios). So if we combine all
    the eigenvectors with the eigenvalues from one of the faces in the training set
    then we should obtain a fairly close replica of that original training image.
    The same applies with other images that are similar to the training set--if we
    combine the trained eigenvectors with the eigenvalues from a similar test image,
    we should be able to reconstruct an image that is somewhat a replica to the test
    image.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们之前说过，Eigenfaces和Fisherfaces算法是基于这样的观点：一个图像可以被大致表示为一组特征向量（特殊的面部图像）和特征值（混合比率）。因此，如果我们结合训练集中某个面部特征向量和特征值，我们应该能够获得一个相当接近原始训练图像的复制品。同样的原理也适用于与训练集相似的其他图像——如果我们结合训练的特征向量和与训练集相似的测试图像的特征值，我们应该能够重建一个与测试图像相似度较高的图像。
- en: 'Once again, OpenCV''s `FaceRecognizer` class makes it quite easy to generate
    a reconstructed face from any input image, by using the `subspaceProject()` function
    to project onto the eigenspace and the `subspaceReconstruct()` function to go
    back from eigenspace to image space. The trick is that we need to convert it from
    a floating-point row matrix to a rectangular 8-bit image (like we did when displaying
    the average face and eigenfaces), but we don''t want to normalize the data, as
    it is already in the ideal scale to compare with the original image. If we normalized
    the data, it would have a different brightness and contrast from the input image,
    and it would become difficult to compare the image similarity just by using the
    L2 relative error. This is done as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，OpenCV的`FaceRecognizer`类通过使用`subspaceProject()`函数将图像投影到特征空间，以及使用`subspaceReconstruct()`函数从特征空间返回到图像空间，使得从任何输入图像生成重建人脸变得非常容易。技巧在于我们需要将其从浮点行矩阵转换为矩形8位图像（就像我们在显示平均人脸和特征人脸时做的那样），但我们不想归一化数据，因为它已经在理想的尺度上，可以与原始图像进行比较。如果我们归一化数据，它将与输入图像具有不同的亮度和对比度，这将使得仅通过使用L2相对误差来比较图像相似度变得困难。以下是实现方法：
- en: '[PRE36]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The following image shows two typical reconstructed faces. The face on the
    left-hand side was reconstructed well because it was from a known person, whereas
    the face on the right-hand side was reconstructed badly because it was from an
    unknown person or a known person but with unknown lighting conditions/facial expression/face
    direction:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了两个典型的重建人脸。左侧的人脸重建得很好，因为它来自一个已知的人，而右侧的人脸重建得不好，因为它来自一个未知的人或者是一个已知的人但具有未知的照明条件/面部表情/面部方向：
- en: '![](img/a7829_7_11.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a7829_7_11.png)'
- en: 'We can now calculate how similar this reconstructed face is to the input face
    by using the same `getSimilarity()` function we created previously for comparing
    two images, where a value less than 0.3 implies that the two images are very similar.
    For Eigenfaces, there is one eigenvector for each face, so reconstruction tends
    to work well and therefore we can typically use a threshold of 0.5, but Fisherfaces
    has just one eigenvector for each person, so reconstruction will not work as well
    and therefore it needs a higher threshold, say 0.7\. This is done as follows:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以通过使用之前为比较两张图像而创建的相同的`getSimilarity()`函数来计算这个重建的面部与输入面部的相似度。其中，小于0.3的值意味着两张图像非常相似。对于Eigenfaces，每个面部都有一个特征向量，因此重建通常效果很好，因此我们可以通常使用0.5的阈值，但Fisherfaces对每个人只有一个特征向量，因此重建效果不会很好，因此需要更高的阈值，比如0.7。以下是实现方法：
- en: '[PRE37]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Now you can just print the identity to the console, or use it for wherever your
    imagination takes you! Remember that this face-recognition method and this face-verification
    method are only reliable in the certain conditions that you train them for. So
    to obtain good recognition accuracy, you will need to ensure that the training
    set of each person covers the full range of lighting conditions, facial expressions,
    and angles that you expect to test with. The face preprocessing stage helped reduce
    some differences with lighting conditions and in-plane rotation (if the person
    tilts their head towards their left or right shoulder), but for other differences,
    such as out-of-plane rotation (if the person turns their head towards the left-hand
    side or right-hand side), it will only work if it is covered well in your training
    set.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你只需将身份信息打印到控制台，或者将其用于你的想象所及之处！记住，这种面部识别方法和这种面部验证方法只有在训练它们时特定的条件下才是可靠的。因此，为了获得良好的识别精度，你需要确保每个人的训练集涵盖了预期的测试中的全部光照条件、面部表情和角度。面部预处理阶段有助于减少与光照条件和平面旋转（如果人将头部倾斜向左或右肩）的一些差异，但对于其他差异，如平面外旋转（如果人将头部转向左侧或右侧），只有在你的训练集中得到很好的覆盖时才会有效。
- en: Finishing touches - saving and loading files
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 完成细节 - 保存和加载文件
- en: You could potentially add a command-line based method that processes input files
    and saves them to the disk, or even perform face detection, face preprocessing
    and/or face recognition as a web service, and so on. For these types of projects,
    it is quite easy to add the desired functionality by using the `save` and `load`
    functions of the `FaceRecognizer` class. You may also want to save the trained
    data and then load it on the program's start up.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以潜在地添加一个基于命令行的方法来处理输入文件并将它们保存到磁盘上，或者甚至将面部检测、面部预处理和/或面部识别作为网络服务执行，等等。对于这些类型的项目，通过使用`FaceRecognizer`类的`save`和`load`函数添加所需的功能相当容易。你可能还想在程序启动时保存训练数据然后加载它。
- en: 'Saving the trained model to an XML or YML file is very easy:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 将训练模型保存到XML或YML文件非常简单：
- en: '[PRE38]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: You may also want to save the array of preprocessed faces and labels, if you
    want to add more data to the training set later.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还想保存预处理过的面部和标签数组，以便以后向训练集添加更多数据。
- en: 'For example, here is some sample code for loading the trained model from a
    file. Note that you must specify the face-recognition algorithm (for example, `FaceRecognizer.Eigenfaces`
    or `FaceRecognizer.Fisherfaces`) that was originally used to create the trained
    model:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是从文件中加载训练模型的示例代码。请注意，你必须指定最初用于创建训练模型的面部识别算法（例如，`FaceRecognizer.Eigenfaces`或`FaceRecognizer.Fisherfaces`）：
- en: '[PRE39]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Finishing touches - making a nice and interactive GUI
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 完成细节 - 制作一个漂亮且交互式的GUI
- en: While the code given so far in this chapter is sufficient for a whole face recognition
    system, there still needs to be a way to put the data into the system and a way
    to use it. Many face recognition systems for research will choose the ideal input
    to be text files listing where the static image files are stored on the computer,
    as well as other important data such as the true name or identity of the person
    and perhaps true pixel coordinates of regions of the face (such as ground truth
    of where the face and eye centers actually are). This would either be collected
    manually or by another face recognition system.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本章中给出的代码足以构建一个完整的面部识别系统，但仍需要一种方法将数据放入系统中，以及一种使用它的方法。许多用于研究的人脸识别系统会选择将文本文件作为理想的输入，列出静态图像文件在计算机上的存储位置，以及其他重要数据，例如人员的真实姓名或身份，以及面部区域的真实像素坐标（例如面部和眼睛中心的确切位置）。这些数据可以手动收集，或者由另一个面部识别系统收集。
- en: The ideal output would then be a text file comparing the recognition results
    with the ground truth, so that statistics may be obtained for comparing the face
    recognition system with other face recognition systems.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 理想输出将是一个文本文件，比较识别结果与地面实况，以便可以获得统计数据，用于比较面部识别系统与其他面部识别系统。
- en: However, as the face recognition system in this chapter is designed for learning
    as well as practical fun purposes, rather than competing with the latest research
    methods, it is useful to have an easy-to-use GUI that allows face collection,
    training, and testing, interactively from the webcam in real time. So this section
    will provide an interactive GUI providing these features. The reader is expected
    to either use this provided GUI that comes with this book, or to modify the GUI
    for their own purposes, or to ignore this GUI and design their own GUI to perform
    the face recognition techniques discussed so far.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于本章中的人脸识别系统旨在学习以及实际娱乐目的，而不是与最新的研究方法竞争，因此拥有一个易于使用的GUI，允许从实时摄像头交互式地进行面部收集、训练和测试，是非常有用的。因此，本节将提供一个提供这些功能的交互式GUI。预期读者要么使用本书附带提供的GUI，要么根据自身目的修改GUI，或者忽略此GUI并设计自己的GUI以执行迄今为止讨论的人脸识别技术。
- en: 'As we need the GUI to perform multiple tasks, let''s create a set of modes
    or states that the GUI will have, with buttons or mouse clicks for the user to
    change modes:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们需要GUI执行多个任务，让我们创建一组GUI将具有的模式或状态，以及用户可以通过按钮或鼠标点击来更改模式：
- en: '**Startup**: This state loads and initializes the data and webcam.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**启动**：此状态加载并初始化数据和摄像头。'
- en: '**Detection**: This state detects faces and shows them with preprocessing,
    until the user clicks on the Add Person button.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检测**：此状态检测面部，并在预处理后显示，直到用户点击添加人员按钮。'
- en: '**Collection**: This state collects faces for the current person, until the
    user clicks anywhere in the window. This also shows the most recent face of each
    person. The user clicks either one of the existing people or the Add Person button,
    to collect faces for different people.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集**：此状态收集当前人员的面部，直到用户在窗口中点击任何位置。这也会显示每个人的最新面部。用户点击现有人员之一或添加人员按钮，以收集不同人员的面部。'
- en: '**Training**: In this state, the system is trained with the help of all the
    collected faces of all the collected people.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练**：在此状态下，系统使用收集到的所有人员的所有面部进行训练。'
- en: '**Recognition**: This consists of highlighting the recognized person and showing
    a confidence meter. The user clicks either one of the people or the Add Person
    button, to return to mode 2 (*Collection*).'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**识别**：这包括突出显示识别出的人员并显示置信度计。用户点击人员之一或添加人员按钮，以返回模式2（*收集*）。'
- en: To quit, the user can hit the *Esc* key in the window at any time. Let's also
    add a Delete All mode that restarts a new face recognition system, and a Debug
    button that toggles the display of extra debug info. We can create an enumerated
    `mode` variable to show the current mode.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 要退出，用户可以在窗口中的任何时间按*Esc*键。我们还可以添加一个删除所有模式，该模式将重新启动一个新的面部识别系统，以及一个切换额外调试信息显示的调试按钮。我们可以创建一个枚举的`mode`变量来显示当前模式。
- en: Drawing the GUI elements
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制GUI元素
- en: 'To display the current mode on the screen, let''s create a function to draw
    text easily. OpenCV comes with a `cv::putText()` function with several fonts and
    anti-aliasing, but it can be tricky to place the text in the correct location
    that you want. Luckily, there is also a `cv::getTextSize()` function to calculate
    the bounding box around the text, so we can create a wrapper function to make
    it easier to place text. We want to be able to place text along any edge of the
    window and make sure it is completely visible and also to allow placing multiple
    lines or words of text next to each other without overwriting each other. So here
    is a wrapper function to allow you to specify either left-justified or right-justified,
    as well as to specify top-justified or bottom-justified, and return the bounding
    box, so we can easily draw multiple lines of text on any corner or edge of the
    window:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 要在屏幕上显示当前模式，让我们创建一个函数来轻松绘制文本。OpenCV 提供了一个具有多种字体和抗锯齿的 `cv::putText()` 函数，但将其放置在正确位置可能有些棘手。幸运的是，还有一个
    `cv::getTextSize()` 函数可以计算文本周围的边界框，因此我们可以创建一个包装函数来简化文本的放置。我们希望能够在窗口的任何边缘放置文本，并确保它完全可见，同时允许放置多行或多词文本，而不会相互覆盖。所以这里有一个包装函数，允许您指定左对齐或右对齐，以及指定顶部对齐或底部对齐，并返回边界框，这样我们就可以轻松地在窗口的任何角落或边缘绘制多行文本：
- en: '[PRE40]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now to display the current mode on the GUI, as the background of the window
    will be the camera feed, it is quite possible that if we simply draw text over
    the camera feed; it might be the same color as the camera background! So let''s
    just draw a black shadow of text that is just 1 pixel apart from the foreground
    text we want to draw. Let''s also draw a line of helpful text below it, so the
    user knows the steps to follow. Here is an example of how to draw some text using
    the `drawString()` function:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在要在 GUI 上显示当前模式，由于窗口的背景是摄像头视频流，如果我们直接在摄像头视频流上绘制文本，它可能与摄像头背景颜色相同！所以让我们只绘制一个与前景文本相隔
    1 像素的黑色阴影文本。我们还可以在下面绘制一行有用的文本，以便用户知道要遵循的步骤。以下是如何使用 `drawString()` 函数绘制文本的示例：
- en: '[PRE41]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The following partial screenshot shows the mode and info at the bottom of the
    GUI window, overlaid on top of the camera image:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分截图显示了 GUI 窗口底部的模式和信息，叠加在相机图像之上：
- en: '![](img/a7829_07_12.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a7829_07_12.png)'
- en: 'We mentioned that we want a few GUI buttons, so let''s create a function to
    draw a GUI button easily as follows:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到过，我们想要一些 GUI 按钮，所以让我们创建一个函数来轻松绘制 GUI 按钮，如下所示：
- en: '[PRE42]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Now we create several clickable GUI buttons using the `drawButton()` function,
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用 `drawButton()` 函数创建几个可点击的 GUI 按钮，
- en: which will always be shown at the top-left of the GUI, as shown in the following
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 它将始终显示在 GUI 的左上角，如下所示
- en: 'partial screenshot:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 部分截图：
- en: '![](img/image_07_006.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_006.jpg)'
- en: As we mentioned, the GUI program has some modes that it switches between (as
    a finite state machine), beginning with the Startup mode. We will store the current
    mode as the `m_mode` variable.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们提到的，GUI 程序有一些模式，它会在这些模式之间切换（作为一个有限状态机），从启动模式开始。我们将当前模式存储为 `m_mode` 变量。
- en: Startup mode
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动模式
- en: 'In the Startup mode, we just need to load the XML detector files to detect
    the face and eyes and initialize the webcam, which we''ve already covered. Let''s
    also create a main GUI window with a mouse callback function that OpenCV will
    call whenever the user moves or clicks their mouse in our window. It may also
    be desirable to set the camera resolution to something reasonable; for example,
    640x480, if the camera supports it. This is done as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动模式下，我们只需要加载 XML 检测器文件以检测面部和眼睛，并初始化摄像头，这部分我们已经讨论过了。让我们也创建一个带有鼠标回调函数的主 GUI
    窗口，当用户在我们的窗口中移动或点击鼠标时，OpenCV 将会调用这个函数。也许还需要将摄像头分辨率设置为合理的值；例如，如果摄像头支持的话，640x480。以下是实现方式：
- en: '[PRE43]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Detection mode
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测模式
- en: In the Detection mode, we want to continuously detect faces and eyes, draw rectangles
    or circles around them to show the detection result, and show the current preprocessed
    face. In fact, we will want these to be displayed no matter which mode we are
    in. The only thing special about the Detection mode is that it will change to
    the next mode (*Collection*) when the user clicks the Add Person button.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测模式下，我们希望持续检测面部和眼睛，围绕它们绘制矩形或圆形以显示检测结果，并显示当前的预处理面部。实际上，我们希望无论处于哪种模式，这些内容都能显示出来。检测模式唯一特殊的地方是，当用户点击添加人员按钮时，它将切换到下一个模式（*收集*）。
- en: 'If you remember from the detection step previously in this chapter, the output
    of our detection stage will be:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还记得本章之前提到的检测步骤，我们的检测阶段的输出将是：
- en: '`Mat preprocessedFace`: The preprocessed face (if face and eyes'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Mat preprocessedFace`: 预处理的脸部图像（如果检测到脸部和眼睛）'
- en: were detected).
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: were detected).
- en: '`Rect faceRect`: The detected face region coordinates.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Rect faceRect`: 检测到的脸部区域坐标。'
- en: '`Point leftEye`, `rightEye`: The detected left and right eye center coordinates.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Point leftEye`, `rightEye`: 检测到的左右眼中心坐标。'
- en: 'So we should check if a preprocessed face was returned and draw a rectangle
    and circles around the face and eyes if they were detected as follows:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们应该检查是否返回了预处理的脸部图像，并在检测到脸部和眼睛的情况下绘制围绕脸部和眼睛的矩形和圆圈，如下所示：
- en: '[PRE44]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We will overlay the current preprocessed face at the top-center of the window
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在窗口顶部中央叠加当前预处理的脸部图像
- en: 'as follows:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 'as follows:'
- en: '[PRE45]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The following screenshot shows the displayed GUI when in the Detection mode.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了在检测模式下的显示GUI。
- en: The preprocessed face is shown at the top-center, and the detected face and
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理的脸部图像显示在顶部中央，检测到的脸部和
- en: 'eyes are marked:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 'eyes are marked:'
- en: '![](img/image_07_007.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](img/image_07_007.jpg)'
- en: Collection mode
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集合模式
- en: We enter the Collection mode when the user clicks on the Add Person button to
    signal that they want to begin collecting faces for a new person. As mentioned
    previously, we have limited the face collection to one face per second and then
    only if it has changed noticeably from the previously collected face. And remember,
    we decided to collect not only the preprocessed face but also the mirror image
    of the preprocessed face.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户点击添加人员按钮以表示他们想要开始收集新人物的脸部图像时，我们进入集合模式。如前所述，我们将脸部收集限制为每秒一个脸部，并且只有当它与之前收集的脸部有显著变化时才进行收集。并且记住，我们决定收集不仅包括预处理的脸部，还包括预处理的镜像图像。
- en: In the Collection mode, we want to show the most recent face of each known person
    and let the user click on one of those people to add more faces to them or click
    the Add Person button to add a new person to the collection. The user must click
    somewhere in the middle of the window to continue to the next (*Training mode*)
    mode.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在集合模式中，我们希望显示每个已知人物的最新脸部图像，并允许用户点击其中之一以添加更多脸部图像，或者点击添加人员按钮以将新人物添加到集合中。用户必须点击窗口中间的某个位置以继续到下一个（*训练模式*）模式。
- en: 'So first we need to keep a reference to the latest face that was collected
    for each person. We''ll do this by updating the `m_latestFaces` array of integers,
    which just stores the array index of each person, from the big `preprocessedFaces`
    array (that is, the collection of all faces of all the people). As we also store
    the mirrored face in that array, we want to reference the second last face, not
    the last face. This code should be appended to the code that adds a new face (and
    mirrored face) to the `preprocessedFaces` array as follows:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，首先我们需要为每个人收集的最新脸部图像保留一个引用。我们将通过更新整数数组`m_latestFaces`来完成此操作，该数组仅存储每个人员在大型`preprocessedFaces`数组（即所有人的所有脸部图像的集合）中的数组索引。由于我们也在该数组中存储了镜像脸部，我们想要引用倒数第二个脸部，而不是最后一个脸部。以下代码应附加到将新脸部（和镜像脸部）添加到`preprocessedFaces`数组的代码中，如下所示：
- en: '[PRE46]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We just have to remember to always grow or shrink the `m_latestFaces` array
    whenever a new person is added or deleted (for example, due to the user clicking
    on the Add Person button). Now let''s display the most recent face for each of
    the collected people, on the right-hand side of the window (both in the Collection
    mode and Recognition mode later) as follows:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要记住，每当添加或删除新人物时（例如，由于用户点击添加人员按钮），我们都要记得增长或缩小`m_latestFaces`数组。现在让我们按照以下方式显示收集到的每个人的最新脸部图像，在窗口的右侧（在后续的集合模式和识别模式中）：
- en: '[PRE47]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We also want to highlight the current person being collected, using a thick
    red border around their face. This is done as follows:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还希望使用粗红色的边框突出显示当前正在收集的人物，如下所示：
- en: '[PRE48]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: The following partial screenshot shows the typical display when faces for several
    people have been collected. The user can click any of the people at the top-right
    to collect more faces for that person.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分截图显示了收集到几个人的脸部图像时的典型显示。用户可以点击右上角的人来收集该人的更多脸部图像。
- en: '![](img/a7829_07_15.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a7829_07_15.png)'
- en: Training mode
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练模式
- en: When the user finally clicks in the middle of the window, the face-recognition
    algorithm will begin training on all the collected faces. But it is important
    to make sure there have been enough faces or people collected, otherwise the program
    may crash. In general, this just requires making sure there is at least one face
    in the training set (which implies there is at least one person). But the Fisherfaces
    algorithm looks for comparisons between people, so if there are less than two
    people in the training set, it will also crash. So we must check whether the selected
    face-recognition algorithm is Fisherfaces. If it is, then we require at least
    two people with faces, otherwise we require at least one person with a face. If
    there isn't enough data, then the program goes back to the Collection mode so
    the user can add more faces before training.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户最终点击窗口中间时，面部识别算法将开始对所有收集到的面部进行训练。但重要的是要确保收集到了足够多的面部或人物，否则程序可能会崩溃。一般来说，这只需要确保训练集中至少有一个面部（这意味着至少有一个人）。但Fisherfaces算法寻找人物之间的比较，所以如果训练集中少于两个人，它也会崩溃。因此，我们必须检查所选的面部识别算法是否为Fisherfaces。如果是的话，那么我们要求至少有两个人有面部，否则我们要求至少有一个人有面部。如果数据不足，程序将回到收集模式，以便用户在训练前添加更多面部。
- en: 'To check if there are at least two people with collected faces, we can make
    sure that when a user clicks on the Add Person button, a new person is only added
    if there isn''t any empty person (that is, a person that was added but does not
    have any collected faces yet). If there are just two people and we are using the
    Fisherfaces algorithm, then we must make sure an `m_latestFaces` reference was
    set for the last person during the Collection mode. `m_latestFaces[i]` is initialized
    to -1 when there still haven''t been any faces added to that person, and then
    it becomes `0` or higher once faces for that person have been added. This is done
    as follows:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查是否至少有两个人收集到了面部，我们可以确保当用户点击添加人员按钮时，只有在没有空人员（即添加了但没有收集到任何面部的人）的情况下才会添加新人员。如果只有两个人，并且我们使用Fisherfaces算法，那么我们必须确保在收集模式下为最后一个人设置了`m_latestFaces`引用。`m_latestFaces[i]`在还没有为该人添加任何面部时初始化为-1，一旦为该人添加了面部，它就变为`0`或更高。这是按照以下方式完成的：
- en: '[PRE49]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The training may take a fraction of a second or it may take several seconds
    or even minutes, depending on how much data is collected. Once the training of
    collected faces is complete, the face recognition system will automatically enter
    the *Recognition mode*.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 训练可能只需要几分之一秒，也可能需要几秒甚至几分钟，这取决于收集了多少数据。一旦收集到的面部训练完成，面部识别系统将自动进入*识别模式*。
- en: Recognition mode
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别模式
- en: In the Recognition mode, a confidence meter is shown next to the preprocessed
    face, so the user knows how reliable the recognition is. If the confidence level
    is higher than the unknown threshold, it will draw a green rectangle around the
    recognized person to show the result easily. The user can add more faces for further
    training if they click on the Add Person button or one of the existing people,
    which causes the program to return to the Collection mode.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在识别模式下，预处理后的面部旁边会显示一个置信度计，这样用户就知道识别的可靠性。如果置信度高于未知阈值，它将在识别出的人周围画一个绿色的矩形，以便轻松显示结果。如果用户点击添加人员按钮或现有人员之一，程序将返回收集模式，以便用户可以添加更多面部进行进一步训练。
- en: 'Now we have obtained the recognized identity and the similarity with the reconstructed
    face as mentioned earlier. To display the confidence meter, we know that the L2
    similarity value is generally between 0 to 0.5 for high confidence and between
    0.5 to 1.0 for low confidence, so we can just subtract it from 1.0 to get the
    confidence level between 0.0 to 1.0\. Then we just draw a filled rectangle using
    the confidence level as the ratio shown as follows:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经获得了识别出的身份和与重建面部的相似度，如前所述。为了显示置信度计，我们知道L2相似度值通常在0到0.5之间表示高置信度，在0.5到1.0之间表示低置信度，因此我们可以从1.0中减去它，以获得0.0到1.0之间的置信度水平。然后我们只需使用置信度水平作为以下所示的比例绘制一个填充矩形：
- en: '[PRE50]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: To highlight the recognized person, we draw a green rectangle around their face
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 为了突出显示识别出的人，我们在他们的面部周围画一个绿色的矩形。
- en: 'as follows:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示：
- en: '[PRE51]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The following partial screenshot shows a typical display when running in Recognition
    mode, showing the confidence meter next to the preprocessed face
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分截图显示了在识别模式下运行时的典型显示，显示了预处理后的面部旁边的置信度计。
- en: at the top-center, and highlighting the recognized person in the top-right corner.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部中央，并突出显示右上角被识别的人。
- en: Checking and handling mouse clicks
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查和处理鼠标点击
- en: 'Now that we have all our GUI elements drawn, we just need to process mouse
    events. When we initialized the display window, we told OpenCV that we want a
    mouse event callback to our `onMouse` function. We don''t care about mouse movement,
    only the mouse clicks, so first we skip the mouse events that aren''t for the
    left-mouse-button click as follows:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经绘制了所有GUI元素，我们只需要处理鼠标事件。当我们初始化显示窗口时，我们告诉OpenCV我们想要将鼠标事件回调到我们的`onMouse`函数。我们只关心鼠标点击，而不关心鼠标移动，所以我们首先跳过不是针对左鼠标按钮点击的鼠标事件，如下所示：
- en: '[PRE52]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: As we obtained the drawn rectangle bounds of the buttons when drawing them,
    we just check if the mouse click location is in any of our button regions by calling
    OpenCV's `inside()` function. Now we can check for each button we have created.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在绘制按钮时获得了绘制的矩形边界，我们只需通过调用OpenCV的`inside()`函数来检查鼠标点击位置是否在我们的任何按钮区域内。现在我们可以检查我们创建的每个按钮。
- en: When the user clicks on the Add Person button, we just add 1 to the `m_numPersons`
    variable, allocate more space in the `m_latestFaces` variable, select the new
    person for collection, and begin the Collection mode (no matter which mode we
    were previously in).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户点击添加人员按钮时，我们只需将`m_numPersons`变量加1，在`m_latestFaces`变量中分配更多空间，选择新的人员进行收集，并开始收集模式（无论我们之前处于哪种模式）。
- en: But there is one complication; to ensure that we have at least one face for
    each
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 但有一个复杂的问题；为了确保我们至少为每个
- en: 'person when training, we will only allocate space for a new person if there
    isn''t already a person with zero faces. This will ensure that we can always check
    the value of `m_latestFaces[m_numPersons-1]` to see if a face has been collected
    for every person. This is done as follows:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练时，如果还没有零人脸的人员，我们才会为新人分配空间。这将确保我们始终可以检查`m_latestFaces[m_numPersons-1]`的值，以查看是否为每个人收集到了人脸。这是如下进行的：
- en: '[PRE53]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'This method can be used to test for other button clicks, such as toggling the
    debug flag as follows:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法可用于测试其他按钮点击，例如如下切换调试标志：
- en: '[PRE54]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'To handle the Delete All button, we need to empty various data structures that
    are local to our main loop (that is, not accessible from the mouse event callback
    function), so we change to the Delete All mode and then we can delete everything
    from inside the main loop. We also must deal with the user clicking the main window
    (that is, not a button). If they clicked on one of the people on the right-hand
    side, then we want to select that person and change to the Collection mode. Or
    if they clicked in the main window while in the Collection mode, then we want
    to change to the Training mode. This is done as follows:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理删除所有按钮，我们需要清空我们主循环中局部的一些数据结构（即，不可从鼠标事件回调函数中访问），因此我们切换到删除所有模式，然后我们就可以在主循环内部删除所有内容。我们还必须处理用户点击主窗口（即，不是按钮）。如果他们点击了右侧的某个人，那么我们想要选择那个人并切换到收集模式。或者如果他们在收集模式时点击主窗口，那么我们想要切换到训练模式。这是如下进行的：
- en: '[PRE55]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Summary
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter has shown you all the steps required to create a real-time face
    recognition app, with enough preprocessing to allow some differences between the
    training set conditions and the testing set conditions, just using basic algorithms.
    We used face detection to find the location of a face within the camera image,
    followed by several forms of face preprocessing to reduce the effects of different
    lighting conditions, camera and face orientations, and facial expressions. We
    then trained an Eigenfaces or Fisherfaces machine-learning system with the preprocessed
    faces we collected, and finally we performed face recognition to see who the person
    is with face verification providing a confidence metric in case it is an unknown
    person.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向您展示了创建实时人脸识别应用所需的所有步骤，包括足够的预处理以允许训练集条件与测试集条件之间的一些差异，仅使用基本算法。我们使用人脸检测来找到相机图像中人脸的位置，然后通过几种形式的人脸预处理来减少不同光照条件、相机和人脸方向以及面部表情的影响。然后，我们使用收集到的预处理人脸训练了一个Eigenfaces或Fisherfaces机器学习系统，并最终进行了人脸识别以确定该人是谁，如果是一个未知的人，则通过人脸验证提供一个置信度指标。
- en: Rather than providing a command-line tool that processes image files in an offline
    manner, we combined all the preceding steps into a self-contained real-time GUI
    program to allow immediate use of the face recognition system. You should be able
    to modify the behavior of the system for your own purposes, such as to allow an
    automatic login of your computer, or if you are interested in improving the recognition
    reliability then you can read conference papers about recent advances in face
    recognition to potentially improve each step of the program until it is reliable
    enough for your specific needs. For example, you could improve the face preprocessing
    stages, or use a more advanced machine-learning algorithm, or an even better face
    verification algorithm, based on methods at [h t t p ://w w w . f a c e - r e
    c . o r g /a l g o r i t h m s /](http://www.face-rec.org/algorithms/) and [h
    t t p ://w w w . c v p a p e r s . c o m](http://www.cvpapers.com).
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不是提供一个处理图像文件的离线命令行工具，而是将所有前面的步骤组合成一个自包含的实时GUI程序，以便立即使用面部识别系统。您应该能够根据您的需求修改系统的行为，例如允许计算机自动登录，或者如果您对提高识别可靠性感兴趣，您可以阅读关于面部识别最新进展的会议论文，以潜在地改进程序的每个步骤，直到它足够可靠以满足您的特定需求。例如，您可以改进面部预处理阶段，或使用更先进的机器学习算法，或基于[http://www.face-rec.org/algorithms/](http://www.face-rec.org/algorithms/)和[http://www.cvpapers.com](http://www.cvpapers.com)上的方法使用更好的面部验证算法。
- en: References
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Rapid Object Detection using a Boosted Cascade of Simple Features*, *P. Viola'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用简单特征级联快速对象检测*，*P. Viola*'
- en: and M.J. Jones*, *Proceedings of the IEEE Transactions on CVPR 2001*, *Vol.
    1*,
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 和 M.J. Jones*，*《IEEE Transactions on Computer Vision and Pattern Recognition》2001年第1卷*,
- en: '*pp. 511-518*'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*pp. 511-518*'
- en: '*An Extended Set of Haar-like Features for Rapid Object Detection*, *R. Lienhart
    and J. Maydt*, *Proceedings of the IEEE Transactions on ICIP 2002*, *Vol. 1*,
    *pp. 900-903*'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用于快速对象检测的扩展Haar-like特征集*，*R. Lienhart 和 J. Maydt*，*《IEEE Transactions on Image
    Processing》2002年第1卷*，*pp. 900-903*'
- en: '*Face Description with Local Binary Patterns: Application to Face Recognition*,
    *T. Ahonen, A. Hadid and M. Pietikäinen*, *Proceedings of the IEEE Transactions
    on PAMI 2006*, *Vol. 28*, *Issue 12*, *pp. 2037-2041*'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于局部二值模式的面部描述：应用于面部识别*，*T. Ahonen, A. Hadid 和 M. Pietikäinen*，*《IEEE Transactions
    on Pattern Analysis and Machine Intelligence》2006年第28卷第12期*，*pp. 2037-2041*'
- en: '*Learning OpenCV: Computer Vision with the OpenCV Library*, *G. Bradski and
    A. Kaehler*, *pp. 186-190*, *O''Reilly Media*.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《学习OpenCV：使用OpenCV库进行计算机视觉》*，*G. Bradski 和 A. Kaehler*，*pp. 186-190*，*O''Reilly
    Media*.'
- en: '*Eigenfaces for recognition*, *M. Turk and A. Pentland*, *Journal of Cognitive
    Neuroscience 3*, *pp. 71-86*'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征脸用于识别*，*M. Turk 和 A. Pentland*，*《Journal of Cognitive Neuroscience》第3卷*，*pp.
    71-86*'
- en: '*Eigenfaces vs. Fisherfaces: Recognition using class specific linear projection*,
    *P.N. Belhumeur, J. Hespanha and D. Kriegman*, *Proceedings of the IEEE Transactions
    on PAMI 1997*, *Vol. 19*, *Issue 7*, *pp. 711-720*'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征脸与Fisher脸：基于类特定线性投影的识别*，*P.N. Belhumeur, J. Hespanha 和 D. Kriegman*，*《IEEE
    Transactions on Pattern Analysis and Machine Intelligence》1997年第19卷第7期*，*pp. 711-720*'
- en: '*Face Recognition with Local Binary Patterns*, *T. Ahonen, A. Hadid and M.
    Pietikäinen*, *Computer Vision - ECCV 2004*, *pp. 469-48*'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于局部二值模式的面部识别*，*T. Ahonen, A. Hadid 和 M. Pietikäinen*，*《Computer Vision -
    ECCV 2004》*，*pp. 469-48*'
