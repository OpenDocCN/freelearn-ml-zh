- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Bias Mitigation and Causal Inference Methods
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差缓解和因果推断方法
- en: In *Chapter 6*, *Anchors and Counterfactual Explanations*, we examined fairness
    and its connection to decision-making but limited to post hoc model interpretation
    methods. In *Chapter 10*, *Feature Selection and Engineering for Interpretability*,
    we broached the topic of cost-sensitivity, which often relates to balance or fairness.
    In this chapter, we will engage with methods that will balance data and tune models
    for fairness.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在第6章“锚点和反事实解释”中，我们探讨了公平及其与决策的关系，但仅限于事后模型解释方法。在第10章“用于可解释性的特征选择和工程”中，我们提出了成本敏感性的问题，这通常与平衡或公平相关。在本章中，我们将探讨平衡数据和调整模型以实现公平的方法。
- en: With a credit card default dataset, we will learn how to leverage target visualizers
    such as class balance to detect undesired bias, then how to reduce it via preprocessing
    methods such as reweighting and disparate impact remover for in-processing and
    equalized odds for post-processing. Extending from the topics of *Chapter 6*,
    *Anchors and Counterfactual Explanations*, and *Chapter 10*, *Feature Selection
    and Engineering for Interpretability*, we will also study how policy decisions
    can have unexpected, counterintuitive, or detrimental effects. A decision, in
    the context of hypothesis testing, is called a **treatment**. For many decision-making
    scenarios, it is critical to estimate their effect and make sure this estimate
    is reliable.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用信用卡违约数据集，我们将学习如何利用目标可视化工具，如类平衡，来检测不希望的偏差，然后通过预处理方法，如重新加权和不平等影响移除（用于处理过程中）和等概率（用于后处理）来减少它。从第6章的“锚点和反事实解释”和第10章的“用于可解释性的特征选择和工程”等主题扩展，我们还将研究政策决策可能产生意外、反直觉或有害的影响。在假设检验的背景下，一个决策被称为**治疗**。对于许多决策场景，估计其效果并确保这个估计是可靠的至关重要。
- en: Therefore, we will hypothesize treatments for reducing credit card default for
    the most vulnerable populations and leverage causal modeling to determine its
    **Average Treatment Effects** (**ATE**) and **Conditional Average Treatment Effects**
    (**CATE**). Finally, we will test causal assumptions and the robustness of estimates
    using a variety of methods.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将假设针对最脆弱的信用卡违约人群的治疗方法，并利用因果模型来确定其**平均治疗效果**（**ATE**）和**条件平均治疗效果**（**CATE**）。最后，我们将使用各种方法测试因果假设和估计的稳健性。
- en: 'These are the main topics we are going to cover:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们将要涵盖的主要主题：
- en: Detecting bias
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测偏差
- en: Mitigating bias
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓解偏差
- en: Creating a causal model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建因果模型
- en: Understanding heterogeneous treatment effects
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解异质治疗效果
- en: Testing estimate robustness
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试估计的稳健性
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter’s example uses the `mldatasets`, `pandas`, `numpy`, `sklearn`,
    `lightgbm`, `xgboost`, `matplotlib`, `seaborn`, `xai`, `aif360`, `econml`, and
    `dowhy` libraries. Instructions on how to install all these libraries are in the
    preface.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的示例使用了`mldatasets`、`pandas`、`numpy`、`sklearn`、`lightgbm`、`xgboost`、`matplotlib`、`seaborn`、`xai`、`aif360`、`econml`和`dowhy`库。有关如何安装所有这些库的说明见前言。
- en: 'The code for this chapter is located here:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码位于此处：
- en: '[https://packt.link/xe6ie](https://packt.link/xe6ie)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/xe6ie](https://packt.link/xe6ie)'
- en: The mission
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务
- en: Over 2.8 billion credit cards are circulating worldwide, and we collectively
    spend over $25 trillion (US) on them every year ([https://www.ft.com/content/ad826e32-2ee8-11e9-ba00-0251022932c8](https://www.ft.com/content/ad826e32-2ee8-11e9-ba00-0251022932c8)).
    This is an astronomical amount, no doubt, but the credit card industry’s size
    is best measured not by what is spent, but by what is owed. Card issuers such
    as banks make the bulk of their money from interest. So, the over $60 trillion
    owed by consumers (2022), of which credit card debt is a sizable portion, provides
    a steady income to lenders in the form of interest. It could be argued this is
    good for business, but it also poses ample risk because if a borrower defaults
    before the principal plus operation costs have been repaid, the lender could lose
    money, especially once they’ve exhausted legal avenues to collect the debt.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 全球流通的信用卡超过28亿张，我们每年在它们上的总消费超过25万亿美元（美元）（[https://www.ft.com/content/ad826e32-2ee8-11e9-ba00-0251022932c8](https://www.ft.com/content/ad826e32-2ee8-11e9-ba00-0251022932c8)）。这无疑是一个天文数字，但衡量信用卡行业的规模，不应仅看消费额，而应看债务总额。银行等发卡机构主要通过收取利息来赚取大部分收入。因此，消费者（2022年）欠下的超过60万亿美元的债务，其中信用卡债务占很大一部分，为贷方提供了稳定的利息收入。这可能有利于商业，但也带来了充足的风险，因为如果借款人在本金加运营成本偿还之前违约，贷方可能会亏损，尤其是当他们已经用尽法律途径追讨债务时。
- en: When there’s a credit bubble, this problem is compounded because an unhealthy
    level of debt can compromise lenders’ finances and take their stakeholders down
    with them when the bubble bursts. Such was the case with the 2008 housing bubble,
    also known as the subprime mortgage crisis. These bubbles often begin with speculation
    on growth and seeking unqualified demand to fuel that growth. In the case of the
    mortgage crisis, the banks offered mortgages to people with no proven capacity
    to repay. They also, sadly, targeted minorities who had their entire net worth
    wiped out once the bubble burst. Financial crises and depressions, and every calamity
    in between, tend to affect those that are most vulnerable at much higher rates.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当出现信用泡沫时，这个问题会加剧，因为不健康的债务水平可能会损害贷方的财务状况，并在泡沫破裂时将他们的股东拖下水。2008年的住房泡沫，也称为次贷危机，就是这种情况。这些泡沫通常始于对增长的投机和对无资格需求的寻求，以推动这种增长。在次贷危机的情况下，银行向那些没有证明还款能力的个人提供了抵押贷款。遗憾的是，他们也针对了少数族裔，一旦泡沫破裂，他们的全部净资产就会被清零。金融危机、萧条以及介于两者之间的每一次灾难，往往以更高的比率影响最脆弱的人群。
- en: Credit cards have also been involved in catastrophic bubbles, notably in South
    Korea in 2003 ([https://www.bis.org/repofficepubl/arpresearch_fs_200806.10.pdf](https://www.bis.org/repofficepubl/arpresearch_fs_200806.10.pdf))
    and Taiwan in 2006\. This chapter will examine data from 2005, leading to the
    Taiwanese credit card crisis. By 2006, delinquent credit card debt reached $268
    billion owed by over 700,000 people. Just over 3% of the Taiwanese population
    could not pay even the credit card’s minimum balance and colloquially were known
    as **credit card slaves**. Significant societal ramifications ensued, such as
    a sharp increase in homelessness, drug trafficking/abuse, and even suicide. In
    the aftermath of the 1997 Asian financial crisis, suicide steadily increased around
    the region. A 23% jump between 2005 and 2006 pushed Taiwan’s suicide rate to the
    world’s second highest.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 信用卡也涉及到了灾难性的泡沫，特别是在2003年的韩国([https://www.bis.org/repofficepubl/arpresearch_fs_200806.10.pdf](https://www.bis.org/repofficepubl/arpresearch_fs_200806.10.pdf))和2006年的台湾。本章将考察2005年的数据，导致台湾信用卡危机。到2006年，逾期信用卡债务达到2680亿美元，由超过70万人欠下。超过3%的台湾人口甚至无法支付信用卡的最低还款额，俗称为**信用卡奴隶**。随之而来的是重大的社会影响，如无家可归者数量的急剧增加、毒品走私/滥用，甚至自杀。在1997年亚洲金融危机之后，该地区的自杀率稳步上升。2005年至2006年间的23%的增幅将台湾的自杀率推到了世界第二高。
- en: If we trace back the crisis to its root causes, it was about new card-issuing
    banks having exhausted a saturated real-estate market, slashing requirements to
    obtain credit cards, which at the time were poorly regulated by authorities.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将危机追溯到其根本原因，那是因为新发卡银行已经耗尽了一个饱和的房地产市场，削减了获取信用卡的要求，而当时这些信用卡的监管由当局执行得并不好。
- en: It hit younger people the most because they typically have less income and experience
    in managing money. In 2005, the Taiwanese Financial Supervisory Commission issued
    new regulations to raise credit card applicants’ requirements, preventing new
    credit card slaves. However, more policies would be needed to attend to the debt
    and the debtors already in the system.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这对年轻人影响最大，因为他们通常收入较低，管理资金的经验也较少。2005年，台湾金融监督管理委员会发布了新规定，提高了信用卡申请人的要求，防止出现新的信用卡奴隶。然而，还需要更多的政策来处理系统中已经存在的债务和债务人。
- en: Authorities started discussing the creation of **asset management corporations**
    (**AMCs**) to take bad debts from the balance sheet of banks. They also wanted
    to pass a *debtors’ repayment regulation* that would provide a framework to negotiate
    a reasonable repayment plan. Neither of these policies were codified into law
    untill 2006.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当局开始讨论创建**资产管理公司**（**AMCs**）以从银行的资产负债表中剥离不良债务。他们还希望通过一项*债务人还款规定*，为谈判合理的还款计划提供一个框架。这两项政策直到2006年才被纳入法律。
- en: Hypothetically, let’s say it’s August 2005, and you have come from the future
    armed with novel machine learning and causal inference methods! A Taiwanese bank
    wants to create a classification model to predict customers that will default
    on their loans. They have provided you with a dataset of 30,000 of their credit
    card customers. Regulators are still drafting the laws, so there’s an opportunity
    to propose policies that benefit both the bank and the debtors. When the laws
    have passed, using the classification model, they can then anticipate which debts
    they should sell to the AMCs and, with the causal model, estimate which policies
    would benefit other customers and the bank, but they want to do this fairly and
    robustly—this is your mission!
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一下，现在是2005年8月，你从未来带着新颖的机器学习和因果推理方法来到这里！一家台湾银行希望创建一个分类模型来预测将违约的客户。他们为你提供了一份包含30,000名信用卡客户的数据库。监管机构仍在起草法律，因此有机会提出既有利于银行又有利于债务人的政策。当法律通过后，他们可以使用分类模型预测哪些债务应该卖给资产管理公司（AMCs），并通过因果模型估计哪些政策将有利于其他客户和银行，但他们希望公平且稳健地完成这项任务——这是你的使命！
- en: The approach
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法
- en: 'The bank has stressed to you how important it is that there’s fairness embedded
    in your methods because the regulators and the public at large want assurance
    that banks will not cause any more harm. Their reputation depends on it too, because
    in recent months, the media has been relentless in blaming them for dishonest
    and predatory lending practices, causing distrust in consumers. For this reason,
    they want to use state-of-the-art robustness testing to demonstrate that the prescribed
    policies will alleviate the problem. Your proposed approach includes the following
    points:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 银行已经强调，将公平性嵌入到你的方法中是多么重要，因为监管机构和公众普遍希望确保银行不会造成更多的伤害。他们的声誉也依赖于这一点，因为在最近几个月里，媒体一直在无情地指责他们进行不诚实和掠夺性贷款行为，导致消费者失去信任。因此，他们希望使用最先进的稳健性测试来证明规定的政策将减轻问题。你提出的方法包括以下要点：
- en: Younger lenders have been reported to be more prone to defaulting on repayment,
    so you expect to find age bias, but you will also *look for bias* with other protected
    groups such as gender.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 据报道，年轻放贷人更容易违约还款，因此你预计会发现年龄偏差，但你也会寻找其他受保护群体，如性别，的偏差。
- en: Once you have detected bias, you can *mitigate bias* with preprocessing, in-processing,
    and post-processing algorithms using the **AI Fairness 360** (**AIF360**) library.
    In this process, you will train different models with each algorithm, assess their
    fairness, and choose the fairest model.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦检测到偏差，你可以使用**AI Fairness 360**（**AIF360**）库中的预处理、处理和后处理算法来*减轻偏差*。在这个过程中，你将使用每个算法训练不同的模型，评估它们的公平性，并选择最公平的模型。
- en: To be able to understand the impact of policies, the bank has conducted an experiment
    on a small portion of customers. With the experimental results, you can fit a
    *causal model* through the `dowhy` library, which will identify the *causal effect*.
    These effects are broken down further by the causal model to reveal the heterogeneous
    treatment effects.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了能够理解政策的影响，银行对一小部分客户进行了一项实验。通过实验结果，你可以通过`dowhy`库拟合一个*因果模型*，这将识别出*因果效应*。这些效应进一步由因果模型分解，以揭示异质的治疗效应。
- en: Then, you can *assess the heterogeneous treatment effects* to understand them
    and decide which treatment is the most effective.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，你可以*评估异质处理效果*来理解它们并决定哪种处理最有效。
- en: Lastly, to *ensure that your conclusions are robust*, you will refute the results
    with several methods to see if the effects hold.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，为了*确保你的结论是稳健的*，你需要用几种方法来反驳结果，看看效果是否仍然存在。
- en: Let’s dig in!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨！
- en: The preparations
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'You will find the code for this example here: [https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python/blob/master/Chapter11/CreditCardDefaults.ipynb](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python/blob/master/Chapter11/CreditCardDefaults.ipynb).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下链接找到本例的代码：[https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python/blob/master/Chapter11/CreditCardDefaults.ipynb](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python/blob/master/Chapter11/CreditCardDefaults.ipynb).
- en: Loading the libraries
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载库
- en: 'To run this example, you need to install the following libraries:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此示例，您需要安装以下库：
- en: '`mldatasets` to load the dataset'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mldatasets`用于加载数据集'
- en: '`pandas` and `numpy` to manipulate it'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas`和`numpy`用于操作数据'
- en: '`sklearn` (scikit-learn), `xgboost`, `aif360`, and `lightgbm` to split the
    data and fit the models'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn`（scikit-learn）、`xgboost`、`aif360`和`lightgbm`用于分割数据和拟合模型'
- en: '`matplotlib`, `seaborn`, and `xai` to visualize the interpretations'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib`、`seaborn`和`xai`用于可视化解释'
- en: '`econml` and `dowhy` for causal inference'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`econml`和`dowhy`用于因果推断'
- en: 'You should load all of them first, as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该首先加载所有这些库，如下所示：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Understanding and preparing the data
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解和准备数据
- en: 'We load the data like this into a DataFrame called `ccdefault_all_df`:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据如下加载到名为`ccdefault_all_df`的DataFrame中：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'There should be 30,000 records and 31 columns. We can verify this is the case
    with `info()`, like this:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 应该有30,000条记录和31列。我们可以使用`info()`来验证这一点，如下所示：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding code outputs the following:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码输出以下内容：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The output checks out. All features are numerical, with no missing values because
    we used `prepare=True`, which ensures that all null values are imputed. Categorical
    features are all `int8` because they have already been encoded.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 输出检查无误。所有特征都是数值型，没有缺失值，因为我们使用了`prepare=True`，这确保了所有空值都被填补。分类特征都是`int8`，因为它们已经被编码。
- en: The data dictionary
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据字典
- en: There are 30 features, but we won’t use them together because 18 of them are
    for the bias mitigation exercise, and the remaining 12 that start with an underscore
    (_) are for the causal inference exercise. Soon, we will split the data into the
    corresponding datasets for each exercise. It’s important to note that lowercase
    features have to do with each client’s transactional history, whereas client account
    or target features are uppercase.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有30个特征，但我们不会一起使用它们，因为其中18个用于偏差缓解练习，剩下的12个以下划线（_）开头的用于因果推断练习。很快，我们将把数据分割成每个练习对应的相应数据集。重要的是要注意，小写特征与每个客户的交易历史有关，而客户账户或目标特征是大写的。
- en: 'We will use the following features in the *bias mitigation exercise*:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在以下*偏差缓解练习*中使用以下特征：
- en: '`CC_LIMIT_CAT`: ordinal; the credit card limit (`_CC_LIMIT`) separated into
    eight approximately equally distributed quartiles'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CC_LIMIT_CAT`: 序数；信用卡额度（`_CC_LIMIT`）分为八个大致均匀分布的四分位数'
- en: '`EDUCATION`: ordinal; the customer’s educational attainment level (`0`: Other,
    `1`: High School, `2`: Undergraduate, `3`: Graduate)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EDUCATION`: 序数；客户的受教育程度（`0`: 其他，`1`: 高中，`2`: 本科，`3`: 研究生）'
- en: '`MARITAL_STATUS`: nominal; the customer’s marital status (`0`: Other, `1`:
    Single, `2`: Married)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MARITAL_STATUS`: 名义变量；客户的婚姻状况（`0`: 其他，`1`: 单身，`2`: 已婚）'
- en: '`GENDER`: nominal; the gender of the customer (`1`: Male, `2`: Female)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GENDER`: 名义变量；客户的性别（`1`: 男，`2`: 女）'
- en: '`AGE GROUP`: binary; denoting if the customer belongs to a privileged age group
    (`1`: privileged (26-47 years old), `0`: underprivileged (every other age))'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AGE GROUP`: 二元变量；表示客户是否属于特权年龄组（`1`: 特权组（26-47岁），`0`: 非特权组（其他所有年龄））'
- en: '`pay_status_1` `pay_status_6`: ordinal; the repayment status for the previous
    six periods from April, `pay_status_6`, to August 2005, `pay_status_1` (`-1`:
    payment on time, `1`: payment is 1 month delayed, `2`: payment is 2 months delayed
    `8`: 8 months delayed, `9`: 9 months and above)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pay_status_1` `pay_status_6`: 序数；从2005年4月的`pay_status_6`到8月的还款状态（`-1`: 按时还款，`1`:
    延迟1个月还款，`2`: 延迟2个月还款，`8`: 延迟8个月，`9`: 延迟9个月及以上）'
- en: '`paid_pct_1` `paid_pct_6`: continuous; the percentage of the bill due each
    month from April, `paid_pct_6`, to August 2005, `paid_pct_1`, that was paid'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`paid_pct_1` `paid_pct_6`: 连续型；从4月到2005年8月，每月应付款项的百分比，`paid_pct_6`为8月，`paid_pct_1`为4月。'
- en: '`bill1_over_limit`: continuous; the last bill’s ratio in August 2005 over the
    corresponding credit limit'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bill1_over_limit`: 连续型；2005年8月最后一张账单与相应信用额度的比率'
- en: '`IS_DEFAULT`: binary; target variable; whether the customer defaulted'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IS_DEFAULT`: 二元型；目标变量；客户是否违约'
- en: 'These are the features we will use only in the *causal inference exercise*:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们将在*因果推断练习*中使用的特征：
- en: '`_AGE`: continuous; the age in years of the customer.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_AGE`: 连续型；客户的年龄，单位为年。'
- en: '`_spend`: continuous; how much was spent by each customer in **New Taiwan Dollar**
    (**NT$**).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_spend`: 连续型；每位客户在**新台币**（**NT$**）中的消费金额。'
- en: '`_tpm`: continuous; median transactions per month made by the customer with
    the credit card over the previous 6 months.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_tpm`: 连续型；客户在前6个月内使用信用卡的月均交易量。'
- en: '`_ppm`: continuous; median purchases per month made by the customer with the
    credit card over the previous 6 months.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_ppm`: 连续型；客户在前6个月内使用信用卡的月均购买量。'
- en: '`_RETAIL`: binary; if the customer is a retail customer, instead of a customer
    obtained through their employer.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_RETAIL`: 二元型；如果客户是零售客户，而不是通过雇主获得的客户。'
- en: '`_URBAN`: binary; if the customer is an urban customer.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_URBAN`: 二元型；如果客户是城市客户。'
- en: '`_RURAL`: binary; if the customer is a rural customer.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_RURAL`: 二元型；如果客户是农村客户。'
- en: '`_PREMIUM`: binary; if the customer is “premium.” Premium customers get cashback
    offers and other spending incentives.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_PREMIUM`: 二元型；如果客户是“高级”客户。高级客户会获得现金返还和其他消费激励。'
- en: '`_TREATMENT`: nominal; the intervention or policy prescribed to each customer
    (`-1`: Not part of the experiment, `0`: Control group, `1`: Lower Credit Limit,
    `2`: Payment Plan, `3`: Payment Plan and Credit Limit).'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_TREATMENT`: 名义型；针对每位客户指定的干预或政策（`-1`：非实验部分，`0`：对照组，`1`：降低信用额度，`2`：支付计划，`3`：支付计划和信用额度）。'
- en: '`_LTV`: continuous; the outcome of the intervention, which is the lifetime
    value estimated in *NT$* given the credit payment behavior over the previous 6
    months.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_LTV`: 连续型；干预的结果，即在过去的6个月信用支付行为的基础上，估计的*新台币*（NT$）终身价值。'
- en: '`_CC_LIMIT`: continuous; the original credit card limit in *NT$* that the customer
    had before the treatment. Bankers expect the outcome of the treatment to be greatly
    impacted by this feature.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_CC_LIMIT`: 连续型；客户在治疗前的原始信用卡额度，单位为*新台币*（NT$）。银行家们预期治疗结果将受到这一特征的极大影响。'
- en: '`_risk_score`: continuous; the risk score that the bank computed 6 months prior
    for each customer based on credit card bills’ ratio over their credit card limit.
    It’s like `bill1_over_limit` except it’s a weighted average of 6 months of payment
    history, and it was produced 5 months before choosing the treatment.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_risk_score`: 连续型；银行在6个月前根据信用卡账单与信用额度比率计算出的每位客户的风险评分。它与`bill1_over_limit`类似，但它是对6个月支付历史记录的加权平均值，且在选择治疗措施前5个月产生。'
- en: 'We will explain the causal inference features a bit more and their purpose
    in the following sections. Meanwhile, let’s break down the `_TREATMENT` feature
    by its values with `value_counts()` to understand how we will split this dataset,
    as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的几节中更详细地解释因果推断特征及其目的。同时，让我们通过`value_counts()`按其值分解`_TREATMENT`特征，以了解我们将如何分割这个数据集，如下所示：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding code outputs the following:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码输出了以下内容：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Most of the observations are treatment `-1`, so they are not part of the causal
    inference. The remainder was split evenly between the three treatments (`1-3`)
    and the control group (`0`). Naturally, we will use these four groups for the
    causal inference exercise. However, since the control group wasn’t prescribed
    treatment, we can use it in our bias mitigation exercise along with the `-1` treatments.
    We have to be careful to exclude customers whose behaviors were manipulated in
    the bias mitigation exercise. The whole point is to predict which customers are
    most likely to default under “business as usual” circumstances while attempting
    to reduce bias.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数观测值是治疗`-1`，因此它们不是因果推断的一部分。其余部分在三种治疗（`1-3`）和对照组（`0`）之间平均分配。自然地，我们将使用这四个组进行因果推断练习。然而，由于对照组没有指定治疗措施，我们可以将其与`-1`治疗措施一起用于我们的偏差缓解练习。我们必须小心排除在偏差缓解练习中行为被操纵的客户。整个目的是在尝试减少偏差的同时，预测在“照常营业”的情况下，哪些客户最有可能违约。
- en: Data preparation
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'Our single data preparation step, for now, is to split the datasets, which
    can be easily done by subsetting the `pandas` DataFrames using the `_TREATMENT`
    column. We will create one DataFrame for each exercise with this subsetting: bias
    mitigation (`ccdefault_bias_df`) and causal inference (`ccdefault_causal_df`).
    These can be seen in the following code snippet:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们的单一数据准备步骤是将数据集拆分，这可以通过使用`_TREATMENT`列对`pandas` DataFrame进行子集化轻松完成。我们将为每个练习创建一个DataFrame，使用这种子集化：偏差缓解（`ccdefault_bias_df`）和因果推断（`ccdefault_causal_df`）。这些可以在以下代码片段中看到：
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We will do a few other data preparation steps in the in-depth sections but,
    for now, we are good to go to get started!
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在深入部分进行一些其他数据准备步骤，但现在我们可以开始着手了！
- en: Detecting bias
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测偏差
- en: There are many sources of bias in machine learning. As outlined in *Chapter
    1*, *Interpretation, Interpretability, and Explainability; and Why Does It All
    Matter?*, there are ample sources of bias. Those rooted in the *truths* that the
    data represents, such as systemic and structural ones, lead to prejudice bias
    in the data. There are also biases rooted in the data, such as sample, exclusion,
    association, and measurement biases. Lastly, there are biases in the insights
    we derive from data or models we have to be careful with, such as conservatism
    bias, salience bias, and fundamental attribution error.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中存在许多偏差来源。如*第一章*中所述，“解释、可解释性和可解释性；以及这一切为什么都重要？”，存在大量的偏差来源。那些根植于数据所代表*真相*的，如系统性和结构性偏差，导致数据中的偏见偏差。还有根植于数据的偏差，如样本、排除、关联和测量偏差。最后，还有我们从数据或模型中得出的见解中的偏差，我们必须小心处理，如保守主义偏差、显著性偏差和基本归因错误。
- en: For this example, to properly disentangle so many bias levels, we ought to connect
    our data to census data for Taiwan in 2005 and historical lending data split by
    demographics. Then, using these external datasets, control for credit card contract
    conditions, as well as gender, income, and other demographic data to ascertain
    if young people, in particular, were targeted for high-interest credit cards they
    shouldn’t have qualified for. We would also need to trace the dataset to the authors
    and consult with them and the domain experts to examine the dataset for bias-related
    data quality issues. Ideally, these steps would be necessary to validate the hypothesis,
    but that would be a monumental task requiring several chapters’ worth of explanation.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，为了正确地解开这么多偏差水平，我们应该将我们的数据与2005年台湾的普查数据和按人口统计划分的历史贷款数据联系起来。然后，使用这些外部数据集，控制信用卡合同条件，以及性别、收入和其他人口统计数据，以确定年轻人是否特别被针对，获得他们不应有资格的高利率信用卡。我们还需要追踪数据集到作者那里，并与他们以及领域专家协商，检查数据集中与偏差相关的数据质量问题。理想情况下，这些步骤对于验证假设是必要的，但这将是一个需要几章解释的巨大任务。
- en: Therefore, in the spirit of expediency, we take the premise of this chapter
    at face value. That is, due to predatory lending practices, certain age groups
    are more vulnerable to credit card default, not through any fault of their own.
    We will also take at face value the quality of the dataset. With these caveats
    in place, it means that if we find disparities between age groups in the data
    or any model derived from this data, it can be attributed solely to predatory
    lending practices.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本着简便的原则，我们直接接受本章的前提。也就是说，由于掠夺性贷款行为，某些年龄群体更容易受到信用卡违约的影响，这不是他们自己的任何过错。我们还将直接接受数据集的质量。有了这些保留，这意味着如果我们发现数据或由此数据派生的任何模型中年龄群体之间存在差异，这可以归因于掠夺性贷款行为。
- en: 'There are also two types of fairness, outlined here:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还概述了两种公平性类型：
- en: '**Procedural fairness**: This is about fair or equal treatment. It’s hard to
    define this term legally because it depends so much on the context.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**程序公平性**：这是关于公平或平等对待。在法律上很难定义这个术语，因为它在很大程度上取决于上下文。'
- en: '**Outcome fairness**: This is solely about measuring fair outcomes.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结果公平性**：这完全是关于衡量公平的结果。'
- en: These two concepts aren’t mutually exclusive since the procedure may be fair
    but the outcome unfair, or vice versa. In this example, the unfair *procedure*
    was the offering of high-interest credit cards to unqualified customers. Nevertheless,
    we are going to focus on outcome fairness in this chapter.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个概念并不是相互排斥的，因为程序可能是公平的，但结果可能不公平，反之亦然。在这个例子中，不公平的程序是向不合格的客户提供高利率信用卡。尽管如此，我们将在本章中关注结果公平性。
- en: 'When we discuss bias in machine learning, it will impact *protected* groups,
    and within these groups, there will be *privileged* and *underprivileged* groups.
    The latter is a group that is adversely impacted by bias. There are also many
    ways in which bias is manifested, and thus addressed, as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们讨论机器学习中的偏差时，它将影响*受保护*的群体，并且在这些群体中，将存在*特权*和*弱势*群体。后者是一个受到偏差负面影响的群体。偏差的表现方式也有很多，以下是如何应对偏差的：
- en: '**Representation**: There can be a lack of representation or an overrepresentation
    of the underprivileged group. The model will learn either too little or too much
    about this group, compared to others.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代表性**：可能存在代表性不足或弱势群体过度代表的情况。与其它群体相比，模型将学习关于这个群体的信息要么太少要么太多。'
- en: '**Distribution**: Differences in the distribution of features between groups
    can lead the model to make biased associations that can impact model outcomes
    either directly or indirectly.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布**：特征在群体之间的分布差异可能导致模型做出有偏的关联，这些关联可能直接或间接地影响模型的结果。'
- en: '**Probability**: For classification problems, class balance discrepancies between
    groups such as those discussed in *Chapter 6*, *Anchors and Counterfactual Explanations*,
    can lead to the model learning that one group has a higher probability of being
    part of one class or another. These can be easily observed through confusion matrices
    or by comparing their classification metrics, such as false positive or false
    negative rates.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概率**：对于分类问题，如*第6章*中讨论的，群体之间的类别平衡差异可能导致模型学习到某个群体有更高的概率属于某一类或另一类。这些可以通过混淆矩阵或比较它们的分类指标（如假阳性或假阴性率）来轻松观察到。'
- en: '**Hybrid**: A combination of any of the preceding manifestations.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合**：上述任何表现形式的组合。'
- en: 'Strategies for any bias manifestation are discussed in the *Mitigating bias*
    section, but the kind we address in the chapter pertains to disparities with probability
    for our main protected attribute (`_AGE`). We will observe this through these
    means:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在*缓解偏差*部分讨论了任何偏差表现策略，但我们在本章中讨论的偏差类型与我们的主要受保护属性（`_AGE`）的概率差异有关。我们将通过以下方式观察这一点：
- en: '**Visualizing dataset bias**: Observing disparities in the data for the protected
    feature through visualizations.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可视化数据集偏差**：通过可视化观察受保护特征的差异。'
- en: '**Quantifying dataset bias**: Measuring bias using fairness metrics.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**量化数据集偏差**：使用公平性指标来衡量偏差。'
- en: '**Quantifying model bias**: We will train a classification model and use other
    fairness metrics designed for models.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**量化模型偏差**：我们将训练一个分类模型并使用为模型设计的其他公平性指标。'
- en: Model bias can be visualized, as we have done already in *Chapter 6*, *Anchors
    and Counterfactual Explanations*, or as we will do in *Chapter 12*, *Monotonic
    Constraints and Model Tuning for Interpretability*. We will quickly explore some
    other visualizations later in this chapter, in a subsection called *Tying it all
    together!* Without further ado, let’s move on to the practical portion of this
    section.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 模型偏差可以像我们在*第6章*，*锚点和反事实解释*中已经做的那样可视化，或者像我们在*第12章*，*单调约束和模型调优以提高可解释性*中将要做的那样可视化。我们将在本章稍后的一个子节*将所有内容结合起来*中快速探索一些其他可视化。现在，让我们不耽搁，继续本节的实际部分。
- en: Visualizing dataset bias
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化数据集偏差
- en: 'The data itself tells the story of how probable it is that one group belongs
    to a positive class versus another. If it’s a categorical feature, these probabilities
    can be obtained by dividing the `value_counts()` function for the positive class
    over all classes. For instance, for gender, we could do this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 数据本身讲述了某个群体属于正类与另一类相比的可能性有多大。如果是一个分类特征，可以通过将正类的`value_counts()`函数除以所有类别的总和来获得这些概率。例如，对于性别，我们可以这样做：
- en: '[PRE7]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding snippet produces the following output, which shows that males
    have, on average, a higher probability of defaulting on their credit card:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段产生了以下输出，显示了男性平均有更高的概率违约他们的信用卡：
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The code for doing this for a continuous feature is a bit more complicated.
    It is recommended that you use `pandas`' `qcut` to divide the feature into quartiles
    first and then use the same approach used for categorical features. Fortunately,
    the `plot_prob_progression` function does this for you and plots the progression
    of probabilities for each quartile. The first attribute is a `pandas` series,
    an array or list with the protected feature (`_AGE`), and the second is the same
    but for the target feature (`IS_DEFAULT`). We then choose the number of intervals
    (`x_intervals`) that we are setting as quartiles (`use_quantiles=True`).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于连续特征的这种操作代码要复杂一些。建议您首先使用`pandas`的`qcut`将特征划分为四分位数，然后使用与分类特征相同的方法。幸运的是，`plot_prob_progression`函数为您完成了这项工作，并绘制了每个四分位数的概率进展。第一个属性是`pandas`系列，一个包含受保护特征（`_AGE`）的数组或列表，第二个是相同的，但用于目标特征（`IS_DEFAULT`）。然后我们选择要设置为四分位数的区间数（`x_intervals`）（`use_quantiles=True`）。
- en: 'The rest of the attributes are aesthetic, such as the label, title, and adding
    a `mean_line`. The code can be seen in the following snippet:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的属性是美学上的，例如标签、标题和添加`mean_line`。代码可以在下面的片段中看到：
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding code produced the following output, which depicts how the youngest
    (`21-25`) and oldest (`47-79`) are most likely to default. All other groups represent
    just over one standard deviation from the mean:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出，展示了最年轻（`21-25`）和最年长（`47-79`）的人群最有可能违约。其他所有群体仅代表超过一个标准差：
- en: '![Chart, line chart  Description automatically generated](img/B18406_11_01.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图表，折线图  自动生成的描述](img/B18406_11_01.png)'
- en: 'Figure 11.1: Probability of CC default by _AGE'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1：按年龄划分的CC违约概率
- en: 'We can call the youngest and oldest quartiles the underprivileged group and
    all others the privileged group. In order to detect and mitigate unfairness, it
    is best to code them as a binary feature—and we have done just that with `AGE_GROUP`.
    We can leverage `plot_prob_progression` again, but this time with `AGE_GROUP`
    instead of `AGE`, and we will `replace` the numbers with labels we can interpret
    more easily. The code can be seen in the following snippet:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将最年轻和最年长的四分位数称为弱势群体，而其他所有人称为特权群体。为了检测和减轻不公平性，最好将它们编码为二元特征——我们正是这样使用`AGE_GROUP`做到的。我们可以再次利用`plot_prob_progression`，但这次用`AGE_GROUP`代替`AGE`，并将数字替换为我们更容易理解的标签。代码可以在下面的片段中看到：
- en: '[PRE10]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding snippet produced the following output, in which the disparities
    between both groups are pretty evident:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 上述片段生成了以下输出，其中两组之间的差异相当明显：
- en: '![Chart, line chart  Description automatically generated](img/B18406_11_02.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图表，折线图  自动生成的描述](img/B18406_11_02.png)'
- en: 'Figure 11.2: Probability of CC default by AGE_GROUP'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2：按年龄组划分的CC违约概率
- en: 'Next, let’s bring `GENDER` back into the picture. We can employ `plot_prob_contour_map`,
    which is like `plot_prob_progression` but in two dimensions, color-coding the
    probabilities instead of drawing a line. So, the first two attributes are the
    features we want on the *x*-axis (`GENDER`) and *y*-axis (`AGE_GROUP`), and the
    third is the target (`IS_DEFAULT`). Since both our features are binary, it is
    best to use `plot_type=''grid''` as opposed to `contour`. The code can be seen
    in the following snippet:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们将`GENDER`重新引入画面。我们可以使用`plot_prob_contour_map`，它类似于`plot_prob_progression`，但在二维空间中，用颜色编码概率而不是绘制线条。因此，前两个属性是我们希望在*x*轴（`GENDER`）和*y*轴（`AGE_GROUP`）上的特征，第三个是目标（`IS_DEFAULT`）。由于我们的特征都是二元的，最好使用`plot_type='grid'`而不是`contour`。代码可以在下面的片段中看到：
- en: '[PRE11]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Chart, treemap chart  Description automatically generated](img/B18406_11_03.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图表，树状图  自动生成的描述](img/B18406_11_03.png)'
- en: 'Figure 11.3: Probability grid of CC default by GENDER and AGE_GROUP'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3：按性别和年龄组划分的CC默认概率网格
- en: The gender difference is an interesting observation, and we could present a
    number of hypotheses as to why females default less. Are they just simply better
    at managing debt? Does it have to do with their marital status or education? We
    won’t dig deeper into these questions. Given that we only know of age-based discrimination,
    we will only use `AGE_GROUP` in privilege groups but keep `GENDER` a protected
    attribute, which will be factored in some fairness metrics we will monitor. Speaking
    of metrics, we will quantify dataset bias next.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 性别差异是一个有趣的观察结果，我们可以提出许多假设来解释为什么女性违约较少。她们是否只是简单地更擅长管理债务？这是否与她们的婚姻状况或教育有关？我们不会深入探讨这些问题。鉴于我们只知道基于年龄的歧视，我们将在特权组中仅使用`AGE_GROUP`，但将`GENDER`保持为受保护属性，这将在我们监控的一些公平性指标中考虑。说到指标，我们将量化数据集偏差。
- en: Quantifying dataset bias
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 量化数据集偏差
- en: 'There are three categories of fairness metrics, outlined here:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 公平性指标分为三类，如下概述：
- en: '**Individual fairness**: How close individual observations are to their peers
    in the data. Distance metrics such as *Euclidean* and *Manhattan distance* can
    serve this purpose.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个体公平性**：个体观察值在数据中与同龄人的接近程度。例如，*欧几里得距离*和*曼哈顿距离*等距离度量可以用于此目的。'
- en: '**Group fairness**: How labels or outcomes between groups are, on average,
    distant from each other. This can be measured either in the data or for a model.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组公平性**：组与组之间标签或结果的平均距离。这可以在数据或模型中进行衡量。'
- en: '**Both**: A few metrics measure entropy or variance by factoring inequality
    both in-group and between groups, such as the *Theil index* and the *coefficient
    of variation*.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**两者都**：一些指标通过在组内和组间同时考虑不平等来衡量熵或方差，例如*Theil指数*和*变异系数*。'
- en: We will focus exclusively on group fairness metrics in this chapter.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于组公平性指标。
- en: 'Before we compute fairness metrics, there are a few pending data preparation
    steps. Let’s make sure the dataset we will use for the bias mitigation exercise
    (`ccdefault_bias_df`) only has the pertinent columns, which are those that don’t
    begin with an underscore (`"_"`). On the other hand, the causal inference exercise
    will include only the underscored columns plus `AGE_GROUP` and `IS_DEFAULT`. The
    code can be seen in the following snippet:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们计算公平性指标之前，有一些待处理的数据准备步骤。让我们确保我们将用于偏差缓解练习的数据集（`ccdefault_bias_df`）只包含相关的列，这些列不以下划线（`"_"`）开头。另一方面，因果推断练习将包括以下划线开头的列以及`AGE_GROUP`和`IS_DEFAULT`。代码可以在下面的代码片段中看到：
- en: '[PRE12]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Also, it’s more important to quantify dataset bias on the training data because
    that is the data the model will learn from, so let’s go ahead and split the data
    into train and test `X` and `y` pairs. We do this after we have, of course, initialized
    the random seed to aim for some reproducibility. The code can be seen in the following
    snippet:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，量化训练数据集中的数据集偏差更为重要，因为这是模型将从中学习的数据，所以让我们继续将数据分成训练集和测试集`X`和`y`对。我们在初始化随机种子以实现某些可重复性之后进行此操作。代码可以在下面的代码片段中看到：
- en: '[PRE13]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Even though we will use the `pandas` data we just split for training and performance
    evaluation, the library we will use for this exercise, called AIF360, abstracts
    datasets into base classes. These classes include the data converted to a `numpy`
    array and store attributes related to fairness.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们将使用我们刚刚分割的`pandas`数据用于训练和性能评估，但我们将在这次练习中使用的库，称为AIF360，将数据集抽象为基类。这些类包括转换为`numpy`数组的数据，并存储与公平性相关的属性。
- en: 'For regression, AIF360 has `RegressionDataset`, but for this binary classification
    example, we will use `BinaryLabelDataset`. You can initialize it with the `pandas`
    DataFrame with both features and labels (`X_train.join(y_train)`). Then, you specify
    the name of the label (`label_names`) and protected attributes (`protected_attribute_names`),
    and it is recommended that you enter a value for `favorable_label` and `unfavorable_label`,
    which tells AIF360 which label values are preferred so that it factors them into
    how it assesses fairness. As confusing as it may seem, positive and, in contrast,
    negative in binary classification only pertain to what we are trying to predict—the
    positive class—and not whether it is a favorable outcome. The code can be seen
    in the following snippet:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归，AIF360有`RegressionDataset`，但对于这个二元分类示例，我们将使用`BinaryLabelDataset`。你可以使用包含特征和标签的`pandas`
    DataFrame来初始化它（`X_train.join(y_train)`）。然后，你指定标签的名称（`label_names`）和受保护的属性（`protected_attribute_names`），并且建议你为`favorable_label`和`unfavorable_label`输入一个值，这样AIF360就可以将其纳入评估公平性的考量。尽管这可能听起来很复杂，但在二元分类中，正数和负数仅与我们要预测的内容相关——正类——而不是它是否是一个有利的结果。代码可以在下面的片段中看到：
- en: '[PRE14]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, we create arrays for `underprivileged groups` and `privileged_groups`.
    Those in `AGE_GROUP=1` have a lower probability of default, so they are privileged,
    and vice versa. Then, with these and the abstracted dataset for training (`train_ds`),
    we can initialize a metrics class via `BinaryLabelDatasetMetric`. This class has
    functions for computing several group fairness metrics, judging the data alone.
    We will output three of them and then explain what they mean. The code can be
    seen in the following snippet:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们为`underprivileged groups`和`privileged_groups`创建数组。在`AGE_GROUP=1`中的成员有较低的违约概率，因此他们是特权组，反之亦然。然后，使用这些数组以及用于训练的抽象数据集(`train_ds`)，我们可以通过`BinaryLabelDatasetMetric`初始化一个度量类。这个类有计算几个群体公平度度量的函数，仅凭数据本身进行判断。我们将输出其中的三个，并解释它们的含义。代码可以在下面的片段中看到：
- en: '[PRE15]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The preceding snippet generates the following output:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段生成了以下输出：
- en: '[PRE16]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, let’s explain what each metric means, as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们解释每个度量分别代表什么，如下：
- en: '**Statistical Parity Difference** (**SPD**): Also known as the **mean difference**,
    this is the difference between the mean probability of favorable outcomes between
    underprivileged and privileged groups. A negative number represents unfairness
    to the underprivileged group and a positive number is better, yet a number closer
    to zero represents a fair outcome with no significant difference between the privileged
    and underprivileged groups. It’s computed with the following formula, where *f*
    is the value for the favorable class, *D* is the group of the customer, and *Y*
    is whether the customer will default or not:'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统计差异差异**（**SPD**）：也称为**平均差异**，这是弱势群体和特权群体之间有利结果平均概率的差异。负数表示对弱势群体的不公平，正数表示更好，但接近零的数字表示公平的结果，特权群体和弱势群体之间没有显著差异。它使用以下公式计算，其中*f*是有利类的值，*D*是客户组，*Y*是客户是否会违约：'
- en: '![](img/B18406_11_001.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_11_001.png)'
- en: '**Disparate Impact** (**DI**): DI is exactly like SPD except it’s the ratio,
    not the difference. And, as ratios go, the closer to one the better for the underprivileged
    group. In other words, one represents a fair outcome between groups with no difference,
    below one means unfavorable outcomes to the underprivileged group compared to
    the privileged group, and over one means favorable outcomes to the underprivileged
    group compared to the privileged group. The formula is shown here:'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**差异影响**（**DI**）：DI与SPD完全相同，只是它是比率而不是差异。在比率方面，越接近一，对弱势群体来说越好。换句话说，一代表群体之间公平的结果，没有差异，低于一表示与特权群体相比，弱势群体不利的结果，而高于一表示与特权群体相比，弱势群体有利的结果。公式如下：'
- en: '![](img/B18406_11_002.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_11_002.png)'
- en: '**Smoothed Empirical Differential Fairness** (**SEDF**): This fairness metric
    is one of the many newer ones from a paper called *“An Intersectional Definition
    of Fairness.”* Unlike the previous two metrics, it’s not restricted to the predetermined
    privileged and underprivileged groups, but it’s extended to include all the categories
    in the protected attributes—in this case, the four in *Figure 11.3*. The authors
    of the paper argue that fairness is particularly tricky when you have a crosstab
    of protected attributes. This occurs because of **Simpson’s paradox**, which is
    that one group can be advantaged or disadvantaged in aggregate but not when subdivided
    into crosstabs. We won’t get into the math, but their method accounts for this
    possibility while measuring a sensible level of fairness in intersectional scenarios.
    To interpret it, zero represents absolute fairness, and the farther from zero
    it is, the less fair it is.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平滑经验差异公平性**（**SEDF**）：这个公平性指标是从一篇名为*“交叉性公平性的定义。”*的论文中提出的许多新指标之一。与前面两个指标不同，它不仅限于预定的特权群体和弱势群体，而是扩展到包括受保护属性中的所有类别——在本例中是*图11.3*中的四个。论文的作者们认为，当有受保护属性的交叉表时，公平性尤其棘手。这是因为**辛普森悖论**，即一个群体在总体上可能是有利的或是不利的，但在细分到交叉表时则不是。我们不会深入数学，但他们的方法在测量交叉性场景中的合理公平性水平时考虑到这种可能性。为了解释它，零代表绝对公平，越远离零，公平性越低。'
- en: Next, we will quantify group fairness metrics for a model.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将量化模型的群体公平性指标。
- en: Quantifying model bias
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 量化模型偏差
- en: Before we compute metrics, we will need to train a model. To that end, we will
    initialize a LightGBM classifier (`LGBMClassifier`) with optimal hyperparameters
    (`lgb_params`). These have already been hyperparameter-tuned for us (more details
    on how to do this in *Chapter 12*, *Monotonic Constraints and Model Tuning for
    Interpretability*).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们计算指标之前，我们需要训练一个模型。为此，我们将使用最佳超参数(`lgb_params`)初始化一个LightGBM分类器(`LGBMClassifier`)。这些参数已经为我们进行了超参数调整（更多关于如何做这件事的细节在*第12章*，*单调约束和模型调优以提高可解释性*）。
- en: 'Please note that these parameters include `scale_pos_weight`, which is for
    class weighting. Since this is an unbalanced classification task, this is an essential
    parameter to leverage so that the classifier is cost-sensitive-trained, penalizing
    one form of misclassification over another. Once the classifier is initialized,
    it is `fit` and evaluated with `evaluate_class_mdl`, which returns a dictionary
    with predictive performance metrics that we can store in a model dictionary (`cls_mdls`).
    The code can be seen in the following snippet:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这些参数包括`scale_pos_weight`，这是用于类别加权的。由于这是一个不平衡的分类任务，这是一个重要的参数，以便使分类器进行成本敏感训练，对一种误分类形式进行惩罚，而不是另一种。一旦分类器初始化，它将通过`evaluate_class_mdl`进行`fit`和评估，该函数返回一个包含预测性能指标的字典，我们可以将其存储在模型字典(`cls_mdls`)中。代码可以在下面的代码片段中看到：
- en: '[PRE17]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](img/B18406_11_04.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_11_04.png)'
- en: 'Figure 11.4: Evaluation of the LightGBM base model'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4：LightGBM基础模型的评估
- en: 'Next, let’s compute the fairness metrics for the model. To do this, we need
    to make a “deep” copy (`deepcopy=True`) of the AIF360 dataset, but we change the
    `labels` and `scores` to be those predicted by our model. The `compute_aif_metrics`
    function employs the `ClassificationMetric` class of AIF360 to do for the model
    what `BinaryLabelDatasetMetric` did for the dataset. However, it doesn’t engage
    with the model directly. It computes fairness using the original dataset (`test_ds`)
    and the modified one with the model’s predictions (`test_pred_ds`). The `compute_aif_metrics`
    function creates a dictionary with several precalculated metrics (`metrics_test_dict`)
    and the metric class (`metrics_test_cls`), which can be used to obtain metrics
    one by one. The code can be seen in the following snippet:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们计算模型的公平性指标。为此，我们需要对AIF360数据集进行“深度”复制（`deepcopy=True`），但我们将`labels`和`scores`更改为我们的模型预测的值。`compute_aif_metrics`函数使用AIF360的`ClassificationMetric`类为模型执行`BinaryLabelDatasetMetric`为数据集所执行的操作。然而，它并不直接与模型交互。它使用原始数据集（`test_ds`）和修改后的数据集（`test_pred_ds`）包含模型的预测来计算公平性。`compute_aif_metrics`函数创建一个包含几个预先计算的指标（`metrics_test_dict`）和指标类（`metrics_test_cls`）的字典，可以用来逐个获取指标。代码可以在下面的代码片段中看到：
- en: '[PRE18]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The preceding snippet generates the following output:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段生成了以下输出：
- en: '[PRE19]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, putting the metrics we already explained aside, let’s explain what the
    other ones mean, as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，把我们已经解释过的指标放在一边，让我们解释其他指标的含义，如下所示：
- en: '**Average Odds Difference** (**AOD**): The difference between **False-Positive
    Rates** (**FPR**) averaged with the difference between **False-Negative Rates**
    (**FNR**) for both privileged and underprivileged groups. Negative means there’s
    a disadvantage for the underprivileged group, and the closer to zero, the better.
    The formula is shown here:'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均机会差异**（**AOD**）：这是对特权组和弱势群体**假阳性率**（**FPR**）的平均值与**假阴性率**（**FNR**）之间的差异。负值表示弱势群体存在不利，越接近零越好。公式如下：'
- en: '![](img/B18406_11_003.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_11_003.png)'
- en: '**Equal Opportunity Difference** (**EOD**): It’s only the **True Positive Rate**
    (**TPR**) differences of AOD, so it’s only useful to measure the *opportunity*
    for TPRs. As with AOD, negative confirms a disadvantage for the underprivileged
    group, and the closer the value is to zero means there is no significant difference
    between groups. The formula is shown here:'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平等机会差异**（**EOD**）：它只是AOD的**真正阳性率**（**TPR**）差异，因此它只用于测量TPR的*机会*。与AOD一样，负值确认了弱势群体存在不利，值越接近零意味着组间没有显著差异。公式如下：'
- en: '![](img/B18406_11_004.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_11_004.png)'
- en: '**Differential Fairness Bias Amplification** (**DFBA**): This metric was defined
    in the same paper as SEDF, and similarly has zero as the baseline of fairness
    and is also intersectional. However, it only measures the difference in unfairness
    in proportion between the model and the data in a phenomenon called bias amplification.
    In other words, the value represents how much more the model increases unfairness
    compared to the original data.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**差异公平性偏差放大**（**DFBA**）：这个指标与SEDF在同一篇论文中定义，同样以零作为公平性的基准，并且也是交叉的。然而，它只测量了在称为偏差放大的现象中，模型和数据在不公平性比例上的差异。换句话说，这个值表示模型相对于原始数据增加了多少不公平性。'
- en: If you compare the model’s `SPD` and `DI` metrics to that of the data, they
    are indeed worse. No surprise there, because it’s to be expected since model-learned
    representations tend to amplify bias. You can confirm this with the `DFBA` metrics.
    As for `AOD` and `EOD`, they tend to be in the same neighborhood as the `SPD`
    metrics, but ideally, the `EOD` metric is substantially closer to zero than the
    `AOD` metric because we care more about TPRs in this example.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将模型的`SPD`和`DI`指标与数据相比，它们确实更差。这并不奇怪，因为这是预期的，因为模型学习到的表示往往会放大偏差。你可以用`DFBA`指标来证实这一点。至于`AOD`和`EOD`，它们通常与`SPD`指标在同一区域，但理想情况下，`EOD`指标应该比`AOD`指标更接近零，因为我们在这个例子中更关心TPR。
- en: Next, we will go over methods to mitigate bias in the model.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍减轻模型偏差的方法。
- en: Mitigating bias
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 减轻偏差
- en: 'We can mitigate bias at three different levels with methods that operate at
    these individual levels:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在以下三个不同层面上操作的方法来在三个不同层面上减轻偏差：
- en: '**Preprocessing**: These are interventions to detect and remove bias from the
    training **data** before training the model. Methods that leverage pre-processing
    have the advantage that they tackle bias at the source. On the other hand, any
    undetected bias could still be amplified by the model.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预处理**：这些是在训练模型之前检测和消除训练**数据**中偏差的干预措施。利用预处理的方法的优点是它们在源头解决偏差。另一方面，任何未检测到的偏差仍可能被模型放大。'
- en: '**In-processing**: These methods mitigate bias during the **model training**
    and are, therefore, highly dependent on the model and tend to not be model-agnostic
    like the pre-processing and post-processing methods. They also require hyperparameter
    tuning to calibrate fairness metrics.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内处理**：这些方法在模型训练期间减轻偏差，因此高度依赖于模型，并且通常不像预处理和后处理方法那样不依赖于模型。它们还需要调整超参数来校准公平性指标。'
- en: '**Post-processing**: These methods mitigate bias during **model inference**.
    In *Chapter 6*, *Anchors and Counterfactual Explanations*, we touched on the subject
    of using the What-If tool to choose the right thresholds (see *Figure 6.13* in
    that chapter), and we manually adjusted them to achieve parity with false positives.
    Just as we did then, post-processing methods aim to detect and correct fairness
    directly in the outcomes, but what adjustments to make will depend on which metrics
    matter most to your problem. Post-processing methods have the advantage that they
    can tackle outcome unfairness where it can have the greatest impact, but since
    it’s disconnected from the rest of the model development, it can distort things.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**后处理**：这些方法在**模型推理**期间缓解偏差。在*第6章*，*锚点和反事实解释*中，我们提到了使用What-If工具来选择正确的阈值（参见该章节中的*图6.13*），并且我们手动调整它们以达到与假阳性相同的效果。就像那时一样，后处理方法旨在直接在结果中检测和纠正公平性，但需要进行的调整将取决于哪些指标对你的问题最重要。后处理方法的优势在于它们可以解决结果不公平性，这在可以产生最大影响的地方，但由于它与模型开发的其余部分脱节，可能会扭曲事物。'
- en: 'Please note that bias mitigation methods can hurt predictive performance, so
    there’s often a trade-off. There can be opposing goals, especially in cases where
    the data is reflective of a biased truth. We can choose to aim for a better truth
    instead: a righteous one—*the one we want, not the one we have*.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，偏差缓解方法可能会损害预测性能，因此通常存在权衡。可能会有相反的目标，尤其是在数据反映了有偏见的真相的情况下。我们可以选择追求更好的真相：一个正义的真相——*我们想要的，而不是我们拥有的那个*。
- en: This section will explain several methods for each level but will only implement
    and evaluate two for each. Also, we won’t do it in this chapter, but you can combine
    different kinds of methods to maximize mitigation—for instance, you could use
    a preprocessing method to de-bias the data, then train a model with it, and lastly,
    use a post-processing method to remove bias added by the model.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将解释每个级别的几种方法，但只为每种方法实现和评估两个。此外，我们不会在本章中这样做，但你可以将不同类型的方法结合起来以最大化缓解——例如，你可以使用预处理方法来去偏数据，然后用它来训练模型，最后使用后处理方法来移除模型添加的偏差。
- en: Preprocessing bias mitigation methods
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理偏差缓解方法
- en: 'These are some of the most important preprocessing or data-specific bias mitigation
    methods:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些最重要的预处理或数据特定偏差缓解方法：
- en: '**Unawareness**: Also known as **suppression**. The most straightforward way
    to remove bias is to exclude biased features from the dataset, but it’s a naïve
    approach because you assume that bias is strictly contained in those features.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无意识**：也称为**压制**。移除偏差最直接的方法是排除数据集中的有偏特征，但这是一种天真方法，因为你假设偏差严格包含在这些特征中。'
- en: '**Feature engineering**: Sometimes, continuous features capture bias because
    there are so many sparse areas where the model can fill voids with assumptions
    or learn from outliers. It can do the same with interactions. Feature engineering
    can place guardrails. We will discuss this topic in *Chapter 12*, *Monotonic Constraints
    and Model Tuning for Interpretability*.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程**：有时，连续特征会捕捉到偏差，因为存在许多稀疏区域，模型可以用假设来填补空白或从异常值中学习。它也可以与交互做同样的事情。特征工程可以设置护栏。我们将在*第12章*，*单调约束和模型调优以实现可解释性*中讨论这个话题。'
- en: '**Balancing**: Also known as **resampling**. On their own, representation problems
    are relatively easy to fix by balancing the dataset. The XAI library ([https://github.com/EthicalML/xai](https://github.com/EthicalML/xai))
    has a `balance` function that does this by random downsampling and upsampling
    of group representations. Downsampling, or under-sampling, is what we typically
    call sampling, which is just taking a certain percentage of the observations,
    whereas upsampling, or over-sampling, creates a certain percentage of random duplicates.
    Some strategies synthetically upsample rather than duplicate, such as the **Synthetic
    Minority Oversampling TEchnique** (**SMOTE**). However, we must caution that it’s
    always preferable to downsample than upsample if you have enough data. It’s best
    not to use only the balancing strategy if there are other possible bias problems.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平衡**：也称为**重采样**。单独来看，通过平衡数据集可以相对容易地修复表示问题。XAI库（[https://github.com/EthicalML/xai](https://github.com/EthicalML/xai)）有一个`balance`函数，通过随机下采样和上采样组表示来实现这一点。下采样，或欠采样，就是我们通常所说的采样，即只取一定比例的观察结果，而上采样，或过采样，则是创建一定比例的随机重复。一些策略会合成上采样而不是重复，例如**合成少数过采样技术**（**SMOTE**）。然而，我们必须警告，如果你有足够的数据，总是优先下采样而不是上采样。如果有其他可能的偏见问题，最好不要只使用平衡策略。'
- en: '**Relabeling**: Also known as **massaging**, this is having an algorithm change
    the labels for observations that appear to be most biased, resulting in *massaged
    data* by ranking them. Usually, this is performed with a Naïve-Bayes classifier,
    and to maintain class distribution, it not only promotes some observations but
    demotes an equal amount.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重新标记**：也称为**调整**，这是一种算法改变最可能存在偏见的观察结果的标签，通过排名来产生*调整后的数据*。通常，这使用朴素贝叶斯分类器执行，为了保持类别分布，它不仅提升了一些观察结果，还降低了一样多的数量。'
- en: '**Reweighing**: This method similarly ranks observations as relabeling does,
    but instead of flipping their labels it derives a weight for each one, which we
    can then implement in the learning process. Much like class weights are applied
    to each class, sample weights are applied to each observation or sample. Many
    regressors and classifiers, `LGBMClassifier` included, support sample weights.
    Even though, technically, reweighting doesn’t touch the data and solution applied
    to the model, it is a preprocessing method because we detected bias in the data.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重新加权**：这种方法与重新标记类似，但不是翻转它们的标签，而是为每个观察结果推导出一个权重，我们可以在学习过程中实现它。就像类别权重应用于每个类别一样，样本权重应用于每个观察结果或样本。许多回归器和分类器，包括`LGBMClassifier`，都支持样本权重。尽管技术上重新加权不接触数据和模型应用到的解决方案，但它是一种预处理方法，因为我们检测到数据中的偏见。'
- en: '**Disparate impact remover**: The authors of this method were very careful
    to abide by legal definitions of bias and preserve the integrity of the data without
    changing the labels or the protected attributes. It implements a repair process
    that attempts to remove bias in the remaining features. It’s an excellent process
    to use whenever we suspect that’s where most of the bias is located—that is, the
    features are highly correlated with the protected attributes, but it doesn’t address
    bias elsewhere. In any case, it’s a good baseline to use to understand how much
    of the bias is non-protected features.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**差异影响消除器**：这种方法的设计者非常小心，遵守法律对偏见的定义，并在不改变标签或受保护属性的情况下保持数据的完整性。它实施了一个修复过程，试图从剩余的特征中消除偏见。当我们怀疑偏见主要存在于那里时，这是一个非常好的过程——也就是说，特征与受保护属性高度相关，但它不解决其他地方的偏见。在任何情况下，它都是一个很好的基线，用于了解有多少偏见是非受保护特征。'
- en: '**Learning fair representations**: This leverages an adversarial learning framework.
    There’s a generator (autoencoder) that creates representations of the data excluding
    the protected attribute, and a critic whose goal is that the learned representations
    within privileged and underprivileged groups are as close as possible.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习公平表示**：这种方法利用了对抗性学习框架。有一个生成器（自动编码器）创建排除受保护属性的数据表示，还有一个评论家，其目标是使特权组和弱势群体中学习的表示尽可能接近。'
- en: '**Optimized preprocessing for discrimination prevention**: This method produces
    transformations through mathematical optimization of the data in such a way that
    overall probability distributions are maintained. At the same time, the correlation
    between protected attributes and the target is nullified. The result of this process
    is data that is distorted slightly to de-bias it.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用于歧视预防的优化预处理**：这种方法通过数学优化数据，以保持整体概率分布。同时，保护属性与目标之间的相关性被消除。这个过程的结果是数据略微扭曲，以消除偏差。'
- en: Given that there are so many pre-processing methods, we will only employ two
    of them in this chapter. Still, if you are interested in using the ones we won’t
    cover, they are available in the AIF360 library, and you can read about them in
    their documentation ([https://aif360.res.ibm.com/](https://aif360.res.ibm.com/)).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 由于存在许多预处理方法，我们将在本章中仅使用其中两种。尽管如此，如果你对使用我们未涉及的方法感兴趣，它们在AIF360库中可用，你可以在其文档中了解它们（[https://aif360.res.ibm.com/](https://aif360.res.ibm.com/))。
- en: The Reweighing method
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重新加权方法
- en: 'The `Reweighing` method is fairly simple to implement. You initialize it by
    specifying the groups, then `fit` and `transform` the data as you would with any
    scikit-learn encoder or scaler. For those that aren’t familiar with `fit`, the
    algorithm learns how to transform the provided data, and `transform` uses what
    was learned to transform it. The code can be seen in the following snippet:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`重新加权`方法相对简单易行。你通过指定组来初始化它，然后像使用任何scikit-learn编码器或缩放器一样`fit`和`transform`数据。对于那些不熟悉`fit`的人来说，算法学习如何转换提供的数据，而`transform`使用学到的知识来转换它。以下代码片段中可以看到代码：'
- en: '[PRE20]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The transformation derived from this process doesn’t change the data but creates
    weights for each observation. The AIF360 library is equipped to factor these weights
    into the calculations of fairness, so we can use `BinaryLabelDatasetMetric`, as
    we have before, to compute different metrics. The code can be seen in the following
    snippet:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个过程得到的转换不会改变数据，但为每个观测值创建权重。AIF360库能够将这些权重因素纳入公平性的计算中，因此我们可以使用之前使用的`BinaryLabelDatasetMetric`来计算不同的指标。以下代码片段中可以看到代码：
- en: '[PRE21]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The preceding code outputs the following:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码输出以下内容：
- en: '[PRE22]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The weights have a perfect effect on SPD and DI, making them absolutely fair
    from those metrics’ standpoints. However, note that SEDF is better than before,
    but not zero. This is because privileged and underprivileged groups only pertain
    to the `AGE_GROUP` protected attribute, but not `GENDER`. SEDF is a measure of
    intersectional fairness that reweighting does not address.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 权重对SPD和DI有完美的影响，使它们在这些指标方面绝对公平。然而，请注意，SEDF比以前更好，但不是零。这是因为特权群体和弱势群体仅与`AGE_GROUP`保护属性相关，但不与`GENDER`相关。SEDF是交叉公平性的度量，重新加权没有涉及。
- en: 'You would think that adding weights to observations would adversely impact
    predictive performance. However, this method was designed to maintain balance.
    In an unweighted dataset, all observations have a weight of one, and therefore
    the average of all the weights is one. While reweighting changes the weights for
    observations, the mean is still approximately one. You can check this is the case
    by taking the absolute difference in the mean of `instance_weights` between the
    original dataset and the reweighted one. It should be infinitesimal. The code
    can be seen in the following snippet:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为给观测值添加权重会对预测性能产生不利影响。然而，这种方法被设计用来保持平衡。在未加权的数据集中，所有观测值都有一个权重为1，因此所有权重的平均值是1。在重新加权时，会改变观测值的权重，但平均值仍然大约是1。你可以通过比较原始数据集和重新加权的数据集中`instance_weights`的平均值的绝对差异来检查这一点。它应该是微不足道的。以下代码片段中可以看到代码：
- en: '[PRE23]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'So, how can you apply `instance_weights`?, you ask. Many model classes have
    a lesser-known attribute in the `fit` method, called `sample_weight`. You simply
    plug it in there, and while training, it will learn from observations in accordance
    with the respective weights. This method is shown in the following code snippet:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你可能会问，如何应用`instance_weights`？许多模型类在`fit`方法中有一个不太为人所知的属性，称为`sample_weight`。你只需将其插入其中，在训练过程中，它将根据相应的权重从观测值中学习。以下代码片段展示了这种方法：
- en: '[PRE24]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We can evaluate this model as we have with the base model, with `evaluate_class_mdl`.
    However, when we calculate the fairness metrics with `compute_aif_metrics`, we
    will save them in the model dictionary. Instead of looking at each method’s outcomes
    one by one, we will compare them at the end of the section. Have a look at the
    following code snippet:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用与基础模型相同的方法评估此模型，使用`evaluate_class_mdl`。然而，当我们使用`compute_aif_metrics`计算公平性指标时，我们将它们保存在模型字典中。我们不会逐个查看每种方法的输出，而是在本节结束时进行比较。以下是一个代码片段：
- en: '[PRE25]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![Chart, waterfall chart  Description automatically generated](img/B18406_11_05.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图表，瀑布图 描述自动生成](img/B18406_11_05.png)'
- en: 'Figure 11.5: Evaluation of the LightGBM reweighted model'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5：LightGBM重新加权模型的评估
- en: If you compare *Figure 11.5* to *Figure 11.4*, you can conclude that there’s
    not much difference in predictive performance between the reweighted and the base
    model. This outcome was expected, but it’s still good to verify it. Some bias-mitigation
    methods can adversely impact predictive performance, but reweighing did not. Neither
    should **Disparate Impact** (**DI**) remover, for that matter, which we will discuss
    next!
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将*图11.5*与*图11.4*进行比较，你可以得出结论，重新加权模型和基础模型之间的预测性能没有太大差异。这个结果是可以预料的，但仍然值得验证。一些偏差缓解方法可能会对预测性能产生不利影响，但重新加权并没有。同样，DI消除器（**差异影响**，**DI**）也不应该如此，我们将在下一节中讨论！
- en: The disparate impact remover method
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 差异影响消除方法
- en: 'This method focuses on bias not located in the protected attribute (`AGE_GROUP`),
    so we will have to delete this feature during the process. To that end, we will
    need its index—in other words, what position it has within the list of columns.
    We can save this position (`protected_index`) as a variable, like this:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法专注于不在受保护属性（`AGE_GROUP`）中的偏差，因此我们将在过程中删除此特征。为此，我们需要它的索引——换句话说，它在列列表中的位置。我们可以将此位置（`protected_index`）保存为变量，如下所示：
- en: '[PRE26]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'DI remover is parametric. It requires a repair level between zero and one,
    so we need to find the optimal one. To that end, we can iterate through an array
    with different values for repair level (`levels`), initialize `DisparateImpactRemover`
    with each `level`, and `fit_transform` the data, which will de-bias the data.
    However, we then train the model without the protected attribute and use `BinaryLabelDatasetMetric`
    to assess the `disparate_impact`. Remember that DI is a ratio, so it’s a metric
    that can be between over and under one, and an optimal DI is closest to one. Therefore,
    as we iterate across different repair levels, we will continuously save the model
    whose DI is closest to one. We will also append the DIs into an array for later
    use. Have a look at the following code snippet:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: DI消除器是参数化的。它需要一个介于零和一之间的修复水平，因此我们需要找到最佳值。为此，我们可以遍历一个具有不同修复水平值的数组（`levels`），使用每个`level`初始化`DisparateImpactRemover`，并对数据进行`fit_transform`，这将消除数据中的偏差。然而，我们随后在不包含受保护属性的情况下训练模型，并使用`BinaryLabelDatasetMetric`评估`disparate_impact`。记住，DI是一个比率，因此它是一个可以在超过和低于一之间的指标，最佳DI是最接近一的。因此，当我们遍历不同的修复水平时，我们将持续保存DI最接近一的模型。我们还将DI追加到数组中，以供以后使用。以下是一个代码片段：
- en: '[PRE27]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To observe the DI at different repair levels, we can use the following code,
    and if you want to zoom in on the area where the best DI is located, just uncomment
    the `xlim` line:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了观察不同修复水平下的DI，我们可以使用以下代码，如果你想要放大最佳DI所在区域，只需取消注释`xlim`行：
- en: '[PRE28]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The preceding code generates the following output. As you can tell by this,
    there’s an optimal repair level somewhere between 0 and 0.1 because that’s where
    it gets closest to one:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出。正如你所看到的，最佳修复水平位于0和0.1之间，因为那里的值最接近1：
- en: '![Chart, line chart  Description automatically generated](img/B18406_11_06.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图表，折线图 描述自动生成](img/B18406_11_06.png)'
- en: 'Figure 11.6: DI at different DI remover repair levels'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6：不同DI消除修复水平下的DI
- en: 'Now, let’s evaluate the best DI-repaired model with `evaluate_class_mdl` and
    compute the fairness metrics (`compute_aif_metrics`). We won’t even plot the confusion
    matrix this time, but we will save all results into the `cls_mdls` dictionary
    for later inspection. The code can be seen in the following snippet:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用`evaluate_class_mdl`评估最佳的DI修复模型，并计算公平性指标（`compute_aif_metrics`）。这次我们甚至不会绘制混淆矩阵，但我们会将所有结果保存到`cls_mdls`字典中，以供后续检查。代码如下所示：
- en: '[PRE29]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The next link in the chain after data is the model, so even if we de-bias the
    data, the model introduces bias on its own, thus it makes sense to train models
    that are equipped to deal with it, which is what we will learn how to do next!
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 数据链中的下一个链接是模型，因此即使我们去除了数据中的偏差，模型本身也会引入偏差，因此训练能够处理这种偏差的模型是有意义的，这正是我们接下来将要学习如何做的！
- en: In-processing bias mitigation methods
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理中偏差减轻方法
- en: 'These are some of the most important in-processing or model-specific bias mitigation
    methods:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些最重要的处理中或模型特定的偏差减轻方法：
- en: '**Cost-sensitive training**: We are already incorporating this method into
    every LightGBM model trained in this chapter through the `scale_pos_weight` parameter.
    It’s typically used in imbalanced classification problems and is simply seen as
    a means to improve accuracy for minor classes. However, given that imbalances
    with classes tend to favor some groups over others, this method can also be used
    to mitigate bias, but there are no guarantees that it will. It can be incorporated
    as class weights or by creating a custom loss function. The implementation will
    vary according to the model class and what costs are associated with the bias.
    If they grow linearly with misclassifications, the class weighting will suffice,
    but otherwise, a custom loss function is recommended.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本敏感训练**：我们已经在本章训练的每个LightGBM模型中通过`scale_pos_weight`参数整合了这种方法。它通常用于不平衡分类问题，并被简单地视为提高少数类准确率的一种手段。然而，鉴于类别不平衡往往倾向于使某些群体优于其他群体，这种方法也可以用来减轻偏差，但并不能保证一定会这样做。它可以作为类权重或通过创建自定义损失函数来整合。实现方式将根据模型类别和与偏差相关的成本而有所不同。如果它们与误分类线性增长，则类权重就足够了，否则建议使用自定义损失函数。'
- en: '**Constraints**: Many model classes support monotonic and interaction constraints,
    and **TensorFlow Lattice** (**TFL**) offers more advanced custom shape constraints.
    These ensure that relationships between features and targets are restricted to
    a certain pattern, placing guardrails at the model level. There are many reasons
    you would want to employ them, but chief among them is to mitigate bias. We will
    discuss this topic in *Chapter 12*, *Monotonic Constraints and Model Tuning for
    Interpretability*.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**约束**：许多模型类别支持单调性和交互约束，**TensorFlow Lattice**（**TFL**）提供了更高级的自定义形状约束。这些确保了特征和目标之间的关系被限制在某种模式中，在模型级别上设置了护栏。你会有很多理由想要使用它们，但其中最重要的是减轻偏差。我们将在第12章*单调约束和模型调优以实现可解释性*中讨论这个话题。'
- en: '**Prejudice remover regularizer**: This method defines prejudice as the statistical
    dependence between the sensitive and target variables. However, the aim of this
    method is to minimize indirect prejudice, which excludes the prejudice that can
    be avoided by simply removing the sensitive variable. Therefore, the method starts
    by quantifying it with a **Prejudice Index** (**PI**), which is the mutual information
    between the target and sensitive variable. Incidentally, we covered mutual information
    in *Chapter 10*, *Feature Selection and Engineering for Interpretability*. Then,
    along with L2, the PI is incorporated into a custom regularization term. In theory,
    any model classifier can regularize using the PI-based regularizer, but the only
    implementation, so far, uses logistic regression.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏见消除正则化器**：这种方法将偏见定义为敏感变量和目标变量之间的统计依赖性。然而，这种方法的目标是最大限度地减少间接偏见，排除可以通过简单地删除敏感变量来避免的偏见。因此，该方法首先通过**偏见指数**（**PI**）对其进行量化，这是目标和敏感变量之间的互信息。顺便提一下，我们在第10章*可解释性特征选择和工程*中介绍了互信息。然后，与L2一起，PI被整合到一个自定义正则化项中。从理论上讲，任何模型分类器都可以使用基于PI的正则化器进行正则化，但到目前为止，唯一实现的例子是逻辑回归。'
- en: '**Gerry fair classifier**: This is inspired by the concept of **fairness gerrymandering**,
    which has the appearance of fairness in one group but lacks fairness when subdivided
    into subgroups. The algorithm leverages a **fictitious play** game-theory-inspired
    approach in which you have a zero-sum game between a *learner* and an *auditor*.
    The learner minimizes the prediction error and aggregate fairness-based penalty
    term. The auditor takes it one step further by penalizing the learner based on
    the worst outcomes observed in the most unfairly treated subgroup.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Gerry fair分类器**：这是受**公平性划分**概念的启发，它在某一群体中看似公平，但在细分到子群体时却缺乏公平性。该算法利用一种基于博弈论的**虚构博弈**方法，其中你有一个学习者和审计员之间的零和游戏。学习者最小化预测误差和基于公平性的总惩罚项。审计员通过基于在最不公平对待的子群体中观察到的最坏结果来进一步惩罚学习者。'
- en: The game’s objective is to achieve a **Nash equilibrium**, which is achieved
    when two non-cooperative players with possibly contradictory aims reach a solution
    that partially satisfies both. In this case, the learner gets a minimal prediction
    error and aggregate unfairness, and the auditor gets minimal subgroup unfairness.
    The implementation of this method is model-agnostic.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏的目标是达到**纳什均衡**，这是在两个可能具有矛盾目标的非合作玩家达成部分满足双方的解决方案时实现的。在这种情况下，学习者获得最小的预测误差和总体不公平性，审计员获得最小的子群体不公平性。该方法的实现是模型无关的。
- en: '**Adversarial debiasing**: Similar to the gerry fair classifier, adversarial
    debiasing leverages two opposing actors, but this time it’s with two neural networks:
    a predictor and an adversary. We maximize the predictor’s ability to predict the
    target while minimizing the adversary’s ability to predict the protected feature,
    thus increasing the equality of odds between privileged and underprivileged groups.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对抗性去偏**：与gerry fair分类器类似，对抗性去偏利用两个对立的演员，但这次是两个神经网络：预测器和对手。我们最大化预测器预测目标的能力，同时最小化对手预测受保护特征的能力，从而增加特权群体和弱势群体之间机会的平等性。'
- en: '**Exponentiated gradient reduction**: This method automates cost-sensitive
    optimization by reducing it to a sequence of such problems and using fairness
    constraints concerning protected attributes such as demographic parity or equalized
    odds. It is model-agnostic but limited only to scikit-learn-compatible binary
    classifiers.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指数梯度下降法**：这种方法通过将其简化为一系列此类问题来自动化成本敏感优化，并使用关于受保护属性（如人口统计学平等或均衡机会）的公平性约束。它是模型无关的，但仅限于与scikit-learn兼容的二分类器。'
- en: Given that there are so many in-processing methods, we will only employ two
    of them in this chapter. Still, if you are interested in using ones we won’t cover,
    they are available in the AIF360 library and documentation.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 由于存在如此多的预处理方法，我们将在本章中仅使用其中两种。尽管如此，如果你对我们将不涉及的方法感兴趣，它们可以在AIF360库和文档中找到。
- en: The exponentiated gradient reduction method
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指数梯度下降法
- en: 'The `ExponentiatedGradientReduction` method is an implementation of cost-sensitive
    training with constraints . We initialize it with a base estimator, the maximum
    number of iterations to perform (`max_iter`) and specify the disparity `constraints`
    to use. Then, we `fit` it. This method can be seen in the following code snippet:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`ExponentiatedGradientReduction`方法是对具有约束的成本敏感训练的实现。我们用基估计器初始化它，指定要执行的迭代次数的最大值（`max_iter`），并指定要使用的差异`constraints`。然后，我们`fit`它。这种方法可以在下面的代码片段中看到：'
- en: '[PRE30]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can use the `predict` function to get the training and test predictions
    and then employ `evaluate_class_metrics_mdl` and `compute_aif_metrics` to obtain
    predictive performance and fairness metrics, respectively. We place both into
    the `cls_mdls` dictionary, as illustrated in the following code snippet:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`predict`函数来获取训练和测试预测，然后使用`evaluate_class_metrics_mdl`和`compute_aif_metrics`分别获取预测性能和公平性指标。我们将它们都放入`cls_mdls`字典中，如下面的代码片段所示：
- en: '[PRE31]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Next, we will learn about a partially model-agnostic in-processing method that
    takes into account intersectionality.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解一种部分模型无关的预处理方法，它考虑了交叉性。
- en: The gerry fair classifier method
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: gerry fair分类器方法
- en: 'The gerry fair classifier is partially model-agnostic. It only supports linear
    models, **Support Vector Machines** (**SVMs**), kernel regression, and decision
    trees. We initialize `GerryFairClassifier` by defining a regularization strength
    (`C`), a fairness approximation for early stopping (`gamma`), whether to be verbose
    (`printflag`), the maximum number of iterations (`max_iters`), the model (`predictor`),
    and the fairness notion to employ (`fairness_def`). We will use the fairness notion
    of false negatives (`"FN"`) to compute the fairness violations’ weighted disparity.
    Once it’s been initialized, all we need to do is `fit` it and enable `early_termination`
    to stop if it hasn’t improved in five iterations. The code is shown in the following
    snippet:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Gerry fair分类器部分是模型无关的。它只支持线性模型、**支持向量机**（**SVMs**）、核回归和决策树。我们通过定义正则化强度（`C`）、用于早期停止的公平近似（`gamma`）、是否详细输出（`printflag`）、最大迭代次数（`max_iters`）、模型（`predictor`）以及要采用的公平概念（`fairness_def`）来初始化`GerryFairClassifier`。我们将使用错误的负例（`"FN"`）的公平概念来计算公平违规的加权差异。一旦初始化完成，我们只需要调用`fit`方法并启用`early_termination`，如果它在五次迭代中没有改进，则停止。以下代码片段展示了代码：
- en: '[PRE32]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We can use the `predict` function to get the training and test predictions
    and then employ `evaluate_class_metrics_mdl` and `compute_aif_metrics` to obtain
    predictive performance and fairness metrics, respectively. We place both into
    the `cl_smdls` dictionary, as illustrated in the following code snippet:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`predict`函数来获取训练和测试预测，然后使用`evaluate_class_metrics_mdl`和`compute_aif_metrics`来分别获得预测性能和公平性指标。我们将它们都放入`cl_smdls`字典中，如下面的代码片段所示：
- en: '[PRE33]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The next and last link in the chain after the model is inference, so even if
    you de-bias the data and the model there might be some bias left, thus it makes
    sense to deal with it in this stage too, which is what we will learn how to do
    next!
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型推理之后的链中的下一个和最后一个链接，因此即使你去除了数据和模型的偏差，也可能还剩下一些偏差，因此在这个阶段处理它也是有意义的，这正是我们接下来将要学习如何做的！
- en: Post-processing bias mitigation methods
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 后处理偏差缓解方法
- en: 'These are some of the most important post-processing or inference-specific
    bias mitigation methods:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些最重要的后处理或推理特定偏差缓解方法：
- en: '**Prediction abstention**: This has many potential benefits such as fairness,
    safety, and controlling costs, but which one applies will depend on your problem.
    Typically, a model will return all predictions, even low-confidence ones—that
    is, predictions that are close to the classification threshold or when the model
    returns confidence intervals that fall outside of a predetermined threshold. When
    fairness is involved, if we change predictions to **I don’t know** (**IDK**) in
    low-confidence regions, the model will likely become fairer as a side-effect when
    we assess fairness metrics only against predictions that were made. It is also
    possible to make prediction abstention an in-processing method. A paper called
    *Predict Responsibly: Increasing Fairness by Learning to Defer* discusses two
    approaches to do this, by training a model to either **punt** (learn to predict
    IDK) or **defer** (predict IDK when the odds of being correct are lower than an
    expert opinion). Another paper called *The Utility of Abstaining in Binary Classification*
    employs a reinforcement learning framework called **Knows What It Knows** (**KWIK**),
    which has self-awareness of its mistakes but allows for abstentions.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测弃权**：这有许多潜在的好处，如公平性、安全性和控制成本，但具体应用取决于你的问题。通常，模型会返回所有预测，即使是低置信度的预测——也就是说，接近分类阈值的预测，或者当模型返回的置信区间超出预定阈值时。当涉及公平性时，如果我们将在低置信度区域将预测改为**我不知道**（**IDK**），那么在评估公平性指标时，仅针对所做的预测，模型可能会因为副作用而变得更加公平。还可能将预测弃权作为一个内部处理方法。一篇名为《负责任地预测：通过学习推迟来提高公平性》的论文讨论了两种方法，通过训练模型来**回避**（学习预测IDK）或**推迟**（当正确率低于专家意见时预测IDK）。另一篇名为《在二元分类中弃权的效用》的论文采用了一个名为**Knows
    What It Knows**（**KWIK**）的强化学习框架，它对自己的错误有自我意识，但允许弃权。'
- en: '**Equalized odds postprocessing**: Also known as disparate mistreatment, this
    ensures that privileged and underprivileged groups have equal treatment for misclassifications,
    whether false-positive or false-negative. It finds optimal probability thresholds
    with which changing the labels equalizes the odds between groups.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均衡机会后处理**：也称为不同对待，这确保了特权群体和弱势群体在错误分类方面得到平等对待，无论是假阳性还是假阴性。它找到最佳概率阈值，通过改变标签来平衡组之间的机会。'
- en: '**Calibrated equalized odds postprocessing**: Instead of changing the labels,
    this method modifies the probability estimates so that they are on average equal.
    It calls this calibration. However, this constraint cannot be satisfied for false
    positives and false negatives concurrently, so you are forced to prefer one over
    the other. Therefore, it is advantageous in cases where recall is far more important
    than precision or vice versa, and there are benefits to calibrating the estimated
    probabilities.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**校准的均等机会后处理**：这种方法不是改变标签，而是修改概率估计，使它们平均相等。它称之为校准。然而，这个约束不能同时满足假阳性和假阴性，因此你被迫在两者之间做出选择。因此，在召回率远比精确度更重要或反之亦然的情况下，校准估计的概率是有利的。'
- en: '**Reject option classification**: This method leverages the intuition that
    predictions around the decision boundary tend to be the least fair. It then finds
    an optimal band around the decision boundary for which flipping the labels for
    underprivileged and privileged groups yields the most equitable outcomes.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拒绝选项分类法**：这种方法利用了直觉，即决策边界周围的预测往往是最不公平的。然后，它找到决策边界周围的一个最优带，在这个带中，翻转弱势和优势群体的标签可以产生最公平的结果。'
- en: We will only employ two of these post-processing methods in this chapter. Reject
    option classification is available in the AIF360 library and documentation.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们只会使用这两种后处理方法。拒绝选项分类法在AIF360库和文档中可用。
- en: The equalized odds post-processing method
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 均等机会后处理方法
- en: 'The equalized odds post-processing method (`EqOddsPostprocessing`) is initialized
    with the groups we want to equalize odds for and the random `seed`. Then, we `fit`
    it. Note that fitting takes two datasets: the original one (`test_ds`) and then
    the dataset with predictions for our base model (`test_pred_ds`). What `fit` does
    is compute the optimal probability thresholds. Then, `predict` creates a new dataset
    where these thresholds have changed the `labels`. The code can be seen in the
    following snippet:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 均等机会后处理方法（`EqOddsPostprocessing`）初始化时，需要指定我们想要均等机会的群体和随机`种子`。然后，我们`fit`它。请注意，拟合需要两个数据集：原始数据集（`test_ds`）以及为我们基础模型提供预测的数据集（`test_pred_ds`）。`fit`所做的就是计算最优概率阈值。然后，`predict`创建一个新的数据集，其中这些阈值已经改变了`labels`。代码可以在下面的片段中看到：
- en: '[PRE34]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We can employ `evaluate_class_metrics_mdl` and `compute_aif_metrics` to obtain
    predictive performance and fairness metrics for **Equal-Proportion Probability**
    (**EPP**), respectively. We place both into the `cls_mdls` dictionary. The code
    can be seen in the following snippet:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`evaluate_class_metrics_mdl`和`compute_aif_metrics`来分别获得**等比例概率**（**EPP**）的预测性能和公平性指标。我们将它们都放入`cls_mdls`字典中。代码可以在下面的片段中看到：
- en: '[PRE35]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Next, we will learn about another post-processing method. The main difference
    is that it calibrates the probability scores rather than only changing the predicted
    labels.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解另一种后处理方法。主要区别在于它校准概率分数，而不仅仅是改变预测标签。
- en: The calibrated equalized odds postprocessing method
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 校准的均等机会后处理方法
- en: 'Calibrated equalized odds (`CalibratedEqOddsPostprocessing`) is implemented
    exactly like equalized odds, except it has one more crucial attribute (`cost_constraint`).
    This attribute defines which constraint to satisfy since it cannot make the scores
    fair for FPRs and FNRs simultaneously. We choose FPR and then `fit`, `predict`,
    and `evaluate`, as we did for equalized odds. The code can be seen in the following
    snippet:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 校准的均等机会（`CalibratedEqOddsPostprocessing`）的实现方式与均等机会完全相同，但它有一个更关键的属性（`cost_constraint`）。这个属性定义了要满足哪个约束，因为它不能同时使分数对FPRs和FNRs都是公平的。我们选择FPR，然后`fit`、`predict`和`evaluate`，就像我们对均等机会所做的那样。代码可以在下面的片段中看到：
- en: '[PRE36]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Now that we have tried six bias mitigation methods, two at every level, we can
    compare them against each other and the base model!
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经尝试了六种偏差缓解方法，每个级别两种，我们可以将它们相互比较，并与基础模型进行比较！
- en: Tying it all together!
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将所有这些结合起来！
- en: 'To compare the metrics for all the methods, we can take the dictionary (`cls_mdls`)
    and place it in the DataFrame (`cls_metrics_df`). We are only interested in a
    few performance metrics and most of the fairness metrics recorded. Then, we output
    the DataFrame sorted by test accuracy and with all the fairness metrics color-coded.
    The code can be seen in the following snippet:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较所有方法的指标，我们可以将字典（`cls_mdls`）放入DataFrame（`cls_metrics_df`）中。我们只对一些性能指标和记录的大多数公平性指标感兴趣。然后，我们输出按测试准确率排序的DataFrame，并使用所有公平性指标进行颜色编码。代码可以在下面的片段中看到：
- en: '[PRE37]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The preceding snippet outputs the following DataFrame:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段输出了以下 DataFrame：
- en: '![](img/B18406_11_07.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_11_07.png)'
- en: 'Figure 11.7: Comparison of all bias mitigation methods with different fairness
    metrics'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7：所有偏差缓解方法与不同公平性指标的对比
- en: '*Figure 11.7* shows that most methods yielded models that are fairer than the
    base model for SPD, DI, AOD, and EOD. Calibrated equalized odds post-processing
    (`lgb_3_cpp`) was the exception, but it had one of the best DFBAs but it yielded
    a suboptimal DI because of the lopsided nature of the calibration. Note that this
    method is particularly good at achieving parity for FPR or FNR while calibrating
    scores, but none of these fairness metrics are useful for picking up on this.
    Instead, you could create a metric that’s the ratio between FPRs, as we did in
    *Chapter 6*, *Anchors and Counterfactual Explanations*. Incidentally, this would
    be the perfect use case for **Calibrated Equalized Odds** (**CPP**).'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 11.7* 显示，大多数方法在 SPD、DI、AOD 和 EOD 方面产生的模型比基础模型更公平。校准等概率后处理 (`lgb_3_cpp`)
    是一个例外，但它具有最佳的 DFBAs 之一，但由于校准的不平衡性质，它产生了次优的 DI。请注意，这种方法在校准分数时特别擅长实现 FPR 或 FNR 的平衡，但所有这些公平性指标对于捕捉这一点都没有用。相反，你可以创建一个指标，它是
    FPRs 的比率，就像我们在 *第 6 章*，*锚点和反事实解释* 中所做的那样。偶然的是，这将是一个完美的 **校准等概率** （**CPP**） 的用例。'
- en: 'The method that obtained the best SPD, DI, AOD, and DFBA, and the second-best
    EOD was equalized odds post-processing (`lgb_3_epp`), so let’s visualize fairness
    for it using XAI’s plots. To this end, we first create a DataFrame with the test
    examples (`test_df`) and then use `replace` to make an `AGE_GROUP` categorical
    and obtain the list of categorical columns (`cat_cols_l`). Then, we can compare
    different metrics (`metrics_plot`) using the true labels (`y_test`), predicted
    probability scores for the EPP model, the DataFrame (`test_df`), the protected
    attribute (`cross_cols`), and categorical columns. We can do the same for the
    **Receiver Operating Characteristic** (**ROC**) plot (`roc_plot`) and the **Precision-Recall**
    (**PR**) plot (`pr_plot`). The code can be seen in the following snippet:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 获得最佳 SPD、DI、AOD 和 DFBA 以及次优 EOD 的方法是等概率后处理 (`lgb_3_epp`)，因此让我们使用 XAI 的图表来可视化其公平性。为此，我们首先创建一个包含测试示例的
    DataFrame (`test_df`)，然后使用 `replace` 将 `AGE_GROUP` 转换为分类变量，并获取分类列的列表 (`cat_cols_l`)。然后，我们可以使用真实标签
    (`y_test`)、EPP 模型的预测概率分数、DataFrame (`test_df`)、受保护属性 (`cross_cols`) 和分类列来比较不同的指标
    (`metrics_plot`)。我们也可以为 **受试者工作特征** （**ROC**） 图表 (`roc_plot`) 和 **精确率-召回率** （**PR**）
    图表 (`pr_plot`) 做同样的事情。代码可以在下面的代码片段中看到：
- en: '[PRE38]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '![](img/B18406_11_08.png)Figure 11.8: Plots demonstrating fairness for the
    fairest model'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B18406_11_08.png) 图 11.8：展示最公平模型的公平性图表'
- en: We’ve concluded the bias mitigation exercise and will move on to the causal
    inference exercise, where we will discuss how to ensure fair and robust policies.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了偏差缓解练习，并将继续进行因果推断练习，我们将讨论如何确保公平和稳健的政策。
- en: Creating a causal model
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建因果模型
- en: Decision-making will often involve understanding cause and effect. If the effect
    is desirable, you can decide to replicate its cause, or otherwise avoid it. You
    can change something on purpose to observe how it changes outcomes, or trace an
    accidental effect back to its cause, or simulate which change will produce the
    most beneficial impact. Causal inference can help us do all this by creating causal
    graphs and models. These tie all variables together and estimate effects to make
    more principled decisions. However, to properly assess the impact of a cause,
    whether by design or accident, you’ll need to separate its effect from confounding
    variables.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 决策通常需要理解因果关系。如果效果是可取的，你可以决定复制其原因，或者避免它。你可以故意改变某些东西来观察它如何改变结果，或者将意外效应追溯到其原因，或者模拟哪种改变会产生最大的积极影响。因果推断可以通过创建因果图和模型来帮助我们完成所有这些，这些图将所有变量联系起来并估计效应，以便做出更原则性的决策。然而，为了正确评估原因的影响，无论是设计还是意外，你需要将其效应与混杂变量分开。
- en: The reason causal inference is relevant to this chapter is that the bank’s policy
    decisions have the power to impact cardholder livelihoods significantly and, given
    the rise in suicides, even life and death. Therefore, there’s a moral imperative
    to assess policy decisions with the utmost care.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 因果推断与本章相关的原因是银行的决策具有显著影响持卡人生计的力量，鉴于自杀率的上升，甚至关系到生死。因此，有必要极其谨慎地评估政策决策。
- en: 'The Taiwanese bank conducted a lending policy experiment for 6 months. The
    bank saw the writing on the wall and knew that the customers with the highest
    risk of default would somehow be written off their balance sheets in a way that
    diminished those customers’ financial obligations. Therefore, the experiment’s
    focus only involved what the bank considered salvageable, which were low-to-mid
    risk-of-default customers, and now that the experiment has ended, they want to
    understand how the following policies have impacted customer behavior:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 台湾银行进行了一项为期6个月的贷款政策实验。银行看到了形势的严峻，知道那些最高风险的违约客户将 somehow 从资产负债表中注销，从而减轻了这些客户的财务义务。因此，实验的重点仅涉及银行认为可以挽救的部分，即低至中等风险的违约客户，现在实验已经结束，他们想了解以下政策如何影响了客户行为：
- en: '**Lower credit limit**: Some customers had their credit limit reduced by 25%.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降低信用额度**：一些客户的信用额度降低了25%。'
- en: '**Payment plan**: They were given 6 months to pay back their current credit
    card debt. In other words, the debt was split up into six parts, and every month
    they would have to pay one part.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**付款计划**：他们被给予6个月的时间来偿还当前的信用卡债务。换句话说，债务被分成六部分，每个月他们必须偿还一部分。'
- en: '**Both measures**: A reduction in credit limit and the payment plan.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**两项措施**：降低信用额度和付款计划。'
- en: Also, prevailing credit card interest rates in Taiwan were around 16-20% in
    2005, but the bank caught wind that these would be capped at 4% by the Taiwanese
    Financial Supervisory Commission. Therefore, they ensured all customers in the
    experiment were automatically provided with interest rates at that level. Some
    bank executives thought this would only aggravate the indebtedness and create
    more “credit card slaves” in the process. These concerns prompted the proposal
    to conduct the experiment with a lower credit card limit as a countermeasure.
    On the other hand, the payment plan was devised to understand whether debt relief
    gave customers breathing room to use the card without fear.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，2005年台湾普遍的信用卡利率约为16-20%，但银行得知这些利率将被台湾金融监督管理委员会限制在4%。因此，他们确保所有参与实验的客户都能自动获得该水平的利率。一些银行高管认为这只会加剧债务负担，并在这个过程中创造更多的“信用卡奴隶”。这些担忧促使提出以较低的信用卡额度作为对策进行实验的建议。另一方面，制定付款计划是为了了解债务减免是否给了客户使用信用卡而不必担心的空间。
- en: On the business side, the rationale was that a healthy level of spending needed
    to be encouraged because with lower interest rates, the bulk of the profits would
    come from payment processing, cashback partnerships, and other sources tied to
    spending and, in turn, increased customer longevity. Yet, this would also be beneficial
    to customers because if they were more profitable as spenders than as debtors,
    it meant the incentives were in place to keep them from becoming the latter. All
    this justified the use of estimated lifetime value (`_LTV`) as a proxy metric
    for how the experiment’s outcome benefited both the bank and its customers. For
    years, the bank has been using a reasonably accurate calculation to estimate how
    much value a credit card holder will provide to the bank given their spending
    and payment history, and parameters such as limits and interest rates.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在业务方面，理由是必须鼓励健康水平的消费，因为随着利率的降低，大部分利润将来自支付处理、现金返还合作伙伴关系和其他与消费相关的来源，从而增加客户的使用寿命。这对客户也有好处，因为如果他们在作为消费者比作为债务人更有利可图，这意味着激励措施已经到位，以防止他们成为后者。所有这些都证明了使用估计的终身价值（`_LTV`）作为代理指标来衡量实验结果如何使银行和客户受益的合理性。多年来，银行一直在使用一种相当准确的计算方法来估计信用卡持卡人根据他们的消费和支付历史以及诸如额度、利率等参数将为银行提供多少价值。
- en: 'In the parlance of experimental design, the chosen policy is called a **treatment**,
    and along with the three treated groups, there’s a control group that wasn’t prescribed
    a treatment—that is, no change in policy at all, not even the lower interest rates.
    Before we move forward, let’s first initialize a list with the treatment names
    (`treatment_names`) and one that includes even the control group (`all_treatment_names`),
    as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验设计的术语中，选择的政策被称为**治疗**，除了三个接受治疗的组别外，还有一个未接受治疗的对照组——即政策没有任何变化，甚至没有降低利率。在我们继续前进之前，让我们首先初始化一个包含治疗名称的列表（`treatment_names`）和一个包含甚至对照组的列表（`all_treatment_names`），如下所示：
- en: '[PRE39]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Now, let’s examine the results of the experiment to help us design an optimal
    causal model.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查实验的结果，以帮助我们设计一个最优的因果模型。
- en: Understanding the results of the experiment
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解实验结果
- en: 'A fairly intuitive way of assessing the effectiveness of a treatment is by
    comparing their outcomes. We want to know the answers to the following two simple
    questions:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 评估治疗有效性的一个相当直观的方法是通过比较它们的成果。我们想知道以下两个简单问题的答案：
- en: Did the treatment decrease the default rate compared to the control group?
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比对照组，治疗是否降低了违约率？
- en: Were the spending behaviors conducive to an increase in lifetime value estimates?
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支出行为是否有利于提高终身价值估计？
- en: 'We can visualize both in a single plot. To this end, we obtain a `pandas` series
    with the percentage for each group that defaulted (`pct_s`), then another one
    with the sum of lifetime values for each group (`ltv_s`) in thousands of NTD (`K$`).
    We put both series into a `pandas` DataFrame and `plot` it, as illustrated in
    the following code snippet:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在一个图表中可视化这两个因素。为此，我们获得一个包含每个组违约百分比的`pandas`系列（`pct_s`），然后另一个包含每个组终身价值总和的系列（`ltv_s`），单位为千新台币（NTD）（`K$`）。我们将这两个系列放入`pandas`
    DataFrame中，并绘制它，如下面的代码片段所示：
- en: '[PRE40]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![Chart, line chart  Description automatically generated](img/B18406_11_09.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图表，折线图 描述自动生成](img/B18406_11_09.png)'
- en: 'Figure 11.9: Outcomes for treatment experiment with different credit policies'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.9：不同信用政策的治疗实验结果
- en: 'Before bank executives rejoice that they have found the winning policy, we
    must examine how they distributed it among the credit cardholders in the experiment.
    We learned that they chose the treatment according to the risk factor, which is
    measured by the `_risk_score` variable. However, lifetime value is largely affected
    by the credit limit available (`_CC_LIMIT`), so we must take that into account.
    One way to understand the distribution is by plotting both variables against each
    other in a scatter plot color-coded by `_TREATMENT`. The code for this can be
    seen in the following snippet:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在银行高管们为找到了获胜政策而欢欣鼓舞之前，我们必须检查他们是如何在实验中的信用卡持卡人之间分配它的。我们了解到，他们根据风险因素（由`_risk_score`变量衡量）选择治疗。然而，终身价值在很大程度上受到可用信用额（`_CC_LIMIT`）的影响，因此我们必须考虑这一点。理解分布的一种方法是通过将两个变量以散点图的形式相互对比，并按`_TREATMENT`进行颜色编码。以下代码片段展示了如何实现这一点：
- en: '[PRE41]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The preceding code generated the plot in *Figure 11.10*. It shows that the
    three treatments correspond to different risk levels, while the control group
    (`None`) is spread out more vertically. The choice to assign treatments based
    on risk level also meant that they unevenly distributed the treatments based on
    `_CC_LIMIT`. We ought to ask ourselves if this experiment’s biased conditions
    make it even viable to interpret the outcomes. Have a look at the following output:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成了*图11.10*中的图表。它显示三种治疗对应不同的风险水平，而对照组（`None`）在垂直方向上分布得更广。基于风险水平分配治疗的选择也意味着他们基于`_CC_LIMIT`不均匀地分配了治疗。我们应该问自己，这个实验的偏见条件是否使得结果解释甚至变得可行。请看以下输出：
- en: '![Chart, scatter chart  Description automatically generated](img/B18406_11_10.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![图表，散点图 描述自动生成](img/B18406_11_10.png)'
- en: 'Figure 11.10: Risk factors versus original credit limit'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.10：风险因素与原始信用额的比较
- en: 'The scatterplot in *Figure 11.10* demonstrates the stratification of the treatments
    across risk factors. However, scatter plots can be challenging to interpret to
    understand distributions. For that, it’s best to use a **K****ernel Density Estimate**
    (**KDE**) plot. So, let’s see how `_CC_LIMIT` and lifetime value (`_LTV`) is distributed
    across all treatments with Seaborn’s `displot`. Have a look at the following code
    snippet:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '*图11.10*中的散点图展示了治疗在风险因素上的分层。然而，散点图在理解分布时可能具有挑战性。为此，最好使用**核密度估计（KDE**）图。因此，让我们看看`_CC_LIMIT`和终身价值（`_LTV`）在所有治疗中的分布情况，使用Seaborn的`displot`。请看以下代码片段：'
- en: '[PRE42]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![Chart  Description automatically generated](img/B18406_11_11.png)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![图表 描述自动生成](img/B18406_11_11.png)'
- en: 'Figure 11.11: KDE distributions for _CC_LIMIT and _LTV by _TREATMENT'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.11：根据_TREATMENT的_CC_LIMIT和_LTV的KDE分布
- en: Ideally, when you design an experiment such as this, you should aim for equal
    distribution among all groups based on any pertinent factors that could alter
    the outcomes. However, this might not always be feasible, either because of logistical
    or strategic constraints. In this case, the outcome (`_LTV`) varies according
    to customer credit card limits (`_CC_LIMIT`), the **heterogeneity feature**—in
    other words, the varying feature that directly impacts the treatment effect, also
    known as the **heterogeneous treatment effect modifier**. We can create a causal
    model that includes both the `_TREATMENT` feature and the effect modifier (`_CC_LIMIT`).
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，当你设计此类实验时，你应该根据可能改变结果的相关因素，在所有组别中追求平等分布。然而，这并不总是可行的，可能因为物流或战略限制。在这种情况下，结果（`_LTV`）根据客户信用卡额度（`_CC_LIMIT`）、**异质性特征**——换句话说，直接影响处理效果的变量，也称为**异质性处理效应调节因子**而变化。我们可以创建一个包含`_TREATMENT`特征和效应调节因子（`_CC_LIMIT`）的因果模型。
- en: Understanding causal models
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解因果模型
- en: 'The causal model we will build can be separated into four components, as follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要构建的因果模型可以分为以下四个部分：
- en: '**Outcome** (*Y*): The outcome variable(s) of the causal model.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结果** (*Y*): 因果模型的结果变量。'
- en: '**Treatments** (*T*): The treatment variable(s) that influences the outcome.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理** (*T*): 影响结果的处理变量。'
- en: '**Effect modifiers** (*X*): The variable(s) that influences the effect’s heterogeneity
    conditioning it. It sits in between the treatment and the outcome.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效应调节因子** (*X*): 影响效应异质性的变量，它位于处理和结果之间。'
- en: '**Controls** (*W*): Also known as **common causes** or **confounders**. They
    are the features that influence both the outcome and the treatment.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制变量** (*W*): 也称为**共同原因**或**混杂因素**。它们是影响结果和处理的特征。'
- en: 'We will start by identifying each one of these components in the data as separate
    `pandas` DataFrames, as follows:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先将这些组件在数据中识别为单独的`pandas`数据框，如下所示：
- en: '[PRE43]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We will use the **Doubly Robust Learning** (**DRL**) method to estimate the
    treatment effects. It’s called “doubly” because it leverages two models, as follows:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**双重稳健学习**（**DRL**）方法来估计处理效应。它被称为“双重”，因为它利用了两个模型，如下所示：
- en: 'It predicts the outcome with a *regression model*, as illustrated here:'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用**回归模型**预测结果，如图所示：
- en: '![](img/B18406_11_005.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_11_005.png)'
- en: 'It predicts the treatment with a *propensity model*, as illustrated here:'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用**倾向模型**预测处理，如图所示：
- en: '![](img/B18406_11_006.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_11_006.png)'
- en: 'It’s also *robust* because of the final stage, which combines both models while
    maintaining many desirable statistical properties such as confidence intervals
    and asymptotic normality. More formally, the estimation leverages regression model
    *g* and propensity model *p* conditional on treatment *t*, like this:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最终阶段结合了两种模型，同时保持了多个理想的统计特性，如置信区间和渐近正态性，因此它也是**稳健的**。更正式地说，估计利用了条件在处理**t**上的回归模型**g**和倾向模型**p**，如下所示：
- en: '![](img/B18406_11_007.png)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B18406_11_007.png)'
- en: 'It also does this:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 它还做了以下操作：
- en: '![](img/B18406_11_008.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_11_008.png)'
- en: 'The goal is to derive the **Conditional Average Treatment Effect** (**CATE**)
    denoted as ![](img/B18406_11_009.png) associated with each treatment **t** given
    heterogeneous effect **X**. First, the DRL method de-biases the regression model
    by applying the inverse propensity, like this:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是推导出与每个处理**t**相关的异质效应**X**的**条件平均处理效应**（**CATE**），表示为![](img/B18406_11_009.png)。首先，DRL方法通过应用逆倾向来去偏回归模型，如下所示：
- en: '![](img/B18406_11_010.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_11_010.png)'
- en: How exactly to estimate coefficients ![](img/B18406_11_011.png) from model ![](img/B18406_11_012.png)
    will depend on the DRL variant employed. We will use a linear variant (`LinearDRLearner`)
    so that it returns coefficients and intercepts, which can be easily interpreted.
    It derives ![](img/B18406_11_013.png) by running **ordinary linear regression**
    (**OLS**) for the outcome differences between a treatment *t* and the control
    ![](img/B18406_11_014.png) on *x*[t] . This intuitively makes sense because the
    estimated effect of a treatment minus the estimated effect of the absence of a
    treatment (t = 0) is the *net* effect of said treatment.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 如何精确地估计模型![](img/B18406_11_011.png)中的系数![](img/B18406_11_012.png)将取决于所采用的DRL变体。我们将使用线性变体（`LinearDRLearner`），以便它返回系数和截距，这些可以很容易地解释。它通过在处理组`t`和控制组![](img/B18406_11_014.png)在*x*[t]上的结果差异中运行**普通线性回归**（**OLS**）来推导![](img/B18406_11_013.png)。这种直观的做法是有意义的，因为处理的估计效应减去没有处理的估计效应（t
    = 0）是这种处理的*净*效应。
- en: Now, with all the theory out of the way, let’s dig in!
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，所有理论都已经讲完，让我们深入挖掘吧！
- en: Initializing the linear doubly robust learner
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始化线性双重稳健学习器
- en: 'We can initialize a `LinearDRLearner` from the `econml` library, which we call
    `drlearner`, by specifying any scikit-learn-compatible regressor (`model_regression`)
    and classifier (`model_propensity`). We will use XGBoost for both, but note that
    the classifier has an `objective=multi:softmax` attribute. Remember that we have
    multiple treatments, so it’s a multiclass classification problem. The code can
    be seen in the following snippet:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过指定任何与scikit-learn兼容的回归器（`model_regression`）和分类器（`model_propensity`）来从`econml`库初始化一个`LinearDRLearner`，我们称之为`drlearner`。我们将使用XGBoost来处理这两个，但请注意，分类器有一个`objective=multi:softmax`属性。记住，我们有多个处理，所以这是一个多类分类问题。代码可以在下面的片段中看到：
- en: '[PRE44]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: If you want to understand what both the regression and propensity model are
    doing, you can easily fit `xgb.XGBRegressor().fit(W.join(X),Y)` and `xgb.XGBClassifier(objective="multi:softmax").fit(W.join(X),
    T)` models. We won’t do this now but if you are curious, you could evaluate their
    performance and even run feature importance methods to understand what influences
    their predictions individually. The causal model brings them together with the
    DRL framework, leading to different conclusions.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解回归模型和倾向性模型都在做什么，你可以轻松地拟合`xgb.XGBRegressor().fit(W.join(X),Y)`和`xgb.XGBClassifier(objective="multi:softmax").fit(W.join(X),
    T)`模型。我们现在不会这样做，但如果你好奇，你可以评估它们的性能，甚至运行特征重要性方法来了解它们各自预测的影响。因果模型将它们与DRL框架结合在一起，导致不同的结论。
- en: Fitting the causal model
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拟合因果模型
- en: 'We can use `fit` in the `drlearner` to fit the causal model leveraging the
    `dowhy` wrapper of `econml`. The first attributes are the `Y`, `T`, `X`, and `Y`
    components: `pandas` DataFrames. Optionally, you can provide variable names for
    each of these components: the column names of each of the `pandas` DataFrames.
    Lastly, we would like to estimate the treatment effects. Optionally, we can provide
    the effect modifiers (`X`) to do this with, and we will use half of this data
    to do so, as illustrated in the following code snippet:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`drlearner`中的`fit`来拟合因果模型，利用`econml`的`dowhy`包装器。首先的属性是`Y`、`T`、`X`和`Y`组件：`pandas`数据框。可选地，你可以为这些组件提供变量名称：每个`pandas`数据框的列名。最后，我们希望估计处理效应。可选地，我们可以提供用于此的效果修饰符（`X`），我们将使用其中的一半数据来这样做，如下面的代码片段所示：
- en: '[PRE45]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'With the causal model initialized, we can visualize it. The `pydot` library
    with `pygraphviz` can do this for us. Please note that this library is difficult
    to configure in some environments, so it might not load and show you the much
    less attractive default graphic instead with `view_model`. Don’t worry if this
    happens. Have a look at the following code snippet:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在因果模型初始化后，我们可以可视化它。`pydot`库与`pygraphviz`可以为我们完成这项工作。请注意，这个库在某些环境中配置困难，所以它可能无法加载并显示`view_model`的默认图形。如果发生这种情况，请不要担心。看看下面的代码片段：
- en: '[PRE46]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The code in the preceding snippet outputs the model diagram shown here. With
    it, you can appreciate how all the variables connect:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个代码片段中的代码输出了此处显示的模型图。有了它，你可以欣赏到所有变量是如何相互连接的：
- en: '![Diagram  Description automatically generated](img/B18406_11_12.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B18406_11_12.png)'
- en: 'Figure 11.12: Causal model diagram'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.12：因果模型图
- en: The causal model has already been fitted, so let’s examine and interpret the
    results, shall we?
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 因果模型已经拟合，那么让我们检查和解释结果，好吗？
- en: Understanding heterogeneous treatment effects
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解异质处理效应
- en: Firstly, it’s important to note how the `dowhy` wrapper of `econml` has cut
    down on a few steps with the `dowhy.fit` method. Usually, when you build a `CausalModel`
    such as this one directly with `dowhy`, it has a method called `identify_effect`
    that derives the probability expression for the effect to be estimated (the *identified
    estimand*). In this case, this is called the **Average Treatment Effect** (**ATE**).
    Then, another method called `estimate_effect` takes this expression and the models
    it’s supposed to tie together (regression and propensity). With them, it computes
    both the ATE, ![](img/B18406_11_015.png), and CATE, ![](img/B18406_11_016.png),
    for every outcome *i* and treatment *t*. However, since we used the wrapper to
    `fit` the causal model, it automatically takes care of both the identification
    and estimation steps.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，需要注意的是，`econml` 的 `dowhy` 包装器通过 `dowhy.fit` 方法简化了一些步骤。通常，当你直接使用 `dowhy` 构建
    `CausalModel`（如本例所示）时，它有一个名为 `identify_effect` 的方法，该方法推导出要估计的效果的概率表达式（即 *识别估计量*）。在这种情况下，这被称为
    **平均处理效应**（**ATE**）。然后，另一个名为 `estimate_effect` 的方法接受这个表达式以及它应该与之关联的模型（回归和倾向）。有了它们，它为每个结果
    *i* 和处理 *t* 计算ATE，![](img/B18406_11_015.png)，和CATE，![](img/B18406_11_016.png)。然而，由于我们使用了包装器来
    `fit` 因果模型，它自动处理了识别和估计步骤。
- en: 'You can access the identified ATE with the `identified_estimand_` property
    and the estimate results with the `estimate_` property for the causal model. The
    code can be seen in the following snippet:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过因果模型的 `identified_estimand_` 属性访问识别的ATE，并通过 `estimate_` 属性访问估计结果。以下代码片段显示了代码：
- en: '[PRE47]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Next, we can iterate across all treatments in the causal model and return a
    summary for each treatment, like this:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以遍历因果模型中的所有处理，并为每个处理返回一个总结，如下所示：
- en: '[PRE49]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The preceding code outputs three linear regression summaries. The first one
    looks like this:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码输出了三个线性回归总结。第一个看起来像这样：
- en: '![Graphical user interface, table  Description automatically generated](img/B18406_11_13.png)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，表格  自动生成的描述](img/B18406_11_13.png)'
- en: 'Figure 11.13: Summary of one of the treatments'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.13：某处理总结
- en: 'To get a better sense of the coefficients and intercepts, we can plot them
    with their respective confidence intervals. To do this, we first create an index
    of treatments (`idxs`). There are three treatments, so this is just an array of
    numbers between 0 and 2\. Then, place all the coefficients (`coef_`) and intercepts
    (`intercept_`) into an array using list comprehension. However, it’s a bit more
    complicated for the 90% confidence intervals for both coefficients and intercepts
    because `coef__interval` and `intercept__interval` return the lower and upper
    bounds of these intervals. We need the length of the margin of error in both directions,
    not the bounds. We deduct the coefficient and intercepts from these bounds to
    obtain their respective margin of error, as illustrated in the following code
    snippet:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解系数和截距，我们可以用它们各自的置信区间来绘制它们。为此，我们首先创建一个处理索引（`idxs`）。有三个处理，所以这是一个介于0和2之间的数字数组。然后，使用列表推导将所有系数（`coef_`）和截距（`intercept_`）放入一个数组中。然而，对于系数和截距的90%置信区间来说，这要复杂一些，因为
    `coef__interval` 和 `intercept__interval` 返回这些区间的下限和上限。我们需要两个方向的误差范围的长度，而不是界限。我们从这些界限中减去系数和截距，以获得它们各自的误差范围，如下面的代码片段所示：
- en: '[PRE50]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Next, we plot the coefficients for each treatment and respective errors using
    `errorbar`. We can do the same with the intercepts as another subplot, as illustrated
    in the following code snippet:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用 `errorbar` 函数绘制每个处理及其相应误差的系数。我们还可以将截距作为另一个子图进行相同的操作，如下面的代码片段所示：
- en: '[PRE51]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The preceding snippet outputs the following:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段输出以下内容：
- en: '![A picture containing chart  Description automatically generated](img/B18406_11_14.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![包含图表的图片  自动生成的描述](img/B18406_11_14.png)'
- en: 'Figure 11.14: Coefficients and intercepts for all treatments'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.14：所有处理的系数和截距
- en: With *Figure 11.14*, you can appreciate how relatively large the margin of error
    is for all intercepts and coefficients. Nonetheless, it’s pretty clear that from
    the coefficients alone, treatments keep getting marginally better when read from
    left to right. But before we conclude that **Payment Plan & Lower Credit Limit**
    is the best policy, we must consider the intercept, which is lower for this treatment
    than the first one. Essentially, this means that a customer with a minimal credit
    card limit is likely to improve lifetime value more with the first policy because
    the coefficients are multiplied by the limit, whereas the intercept is the starting
    point. Given that there’s no one best policy for all customers, let’s examine
    how to choose policies for each, using the causal model.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 通过*图11.14*，你可以欣赏到所有截距和系数的相对误差范围有多大。尽管如此，很明显，仅从系数来看，从左到右读取时，治疗的效果会逐渐变好。但在我们得出**支付计划
    & 降低信用额度**是最佳政策的结论之前，我们必须考虑截距，这个截距对于这种治疗比第一个要低。本质上，这意味着具有最低信用卡额度的客户更有可能通过第一种政策提高终身价值，因为系数是乘以限制的，而截距是起点。鉴于没有一种最佳政策适用于所有客户，让我们来看看如何使用因果模型为每个客户选择政策。
- en: Choosing policies
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择政策
- en: We can decide on a credit policy on a customer basis using the `const_marginal_effect`
    method, which takes the *X* effect modifier (`_CC_LIMIT`) and computes the counterfactual
    CATE, ![](img/B18406_11_018.png). In other words, it returns the estimated `_LTV`
    for all treatments for all observations in *X*.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`const_marginal_effect`方法根据客户基础制定信用政策，该方法考虑了*X*效果修正器（`_CC_LIMIT`）并计算反事实CATE，![图片](img/B18406_11_018.png)。换句话说，它返回了所有观察到的*X*中所有治疗的估计`_LTV`。
- en: 'However, they don’t all cost the same. Setting up a payment plan requires administrative
    and legal costs of about *NT$*1,000 per contract, and according to the bank’s
    actuarial department, lowering the credit limit by 25 has an opportunity cost
    estimated at *NT$*72 per average payment per month (`_ppm`) over the lifetime
    of the customer. To factor these costs, we can set up a simple `lambda` function
    that takes the payment plan costs for all treatments and adds them to the variable
    credit limit costs, which, naturally, is multiplied by `_ppm`. Given an array
    with credit card limits of *n* length, the cost function returns an array of (*n*,
    3) dimensions with a cost for each treatment. Then, we obtain the counterfactual
    CATE and deduct the costs (`treatment_effect_minus_costs`). Then, we expand the
    array to include a column of zeros representing the **None** treatment and use
    `argmax` to return each customer’s recommended treatment index (`recommended_T`),
    as illustrated in the following code snippet:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它们并不都花费相同。制定支付计划需要每份合同约*NT$*1,000的行政和法律费用，根据银行的精算部门，降低信用额度25的机遇成本估计为每月平均支付*NT$*72（`_ppm`），在整个客户生命周期内。为了考虑这些成本，我们可以设置一个简单的`lambda`函数，该函数接受所有治疗的支付计划成本并将它们添加到变量信用额度成本中，这自然地乘以`_ppm`。给定一个长度为*n*的信用卡额度数组，成本函数返回一个(*n*,
    3)维度的数组，其中包含每个治疗的成本。然后，我们获得反事实CATE并扣除成本（`treatment_effect_minus_costs`）。然后，我们将数组扩展以包括一列表示**无**治疗的零，并使用`argmax`返回每个客户的推荐治疗索引（`recommended_T`），如下面的代码片段所示：
- en: '[PRE52]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We can use `scatterplot` `_CC_LIMIT` and `_ppm`, color-coded by the recommended
    treatment to observe the customer’s optimal credit policy, as follows:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`scatterplot` `_CC_LIMIT`和`_ppm`，按推荐治疗进行颜色编码，以观察客户的最佳信用政策，如下所示：
- en: '[PRE53]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The preceding snippet outputs the following scatterplot:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段输出以下散点图：
- en: '![Chart, scatter chart  Description automatically generated](img/B18406_11_15.png)Figure
    11.15: Optimal credit policy by customer depending on original credit limit and
    card usage'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '![图表，散点图  自动生成的描述](img/B18406_11_15.png)图11.15：根据原始信用额度和卡片使用情况，客户最优信用政策'
- en: It’s evident in *Figure 11.15* that “None” (no treatment) is never recommended
    for any customer. This fact holds even when costs aren’t deducted—you can remove
    `cost_fn` from `treatment_effect_minus_costs` and rerun the code that outputs
    the plot to verify that treatment is always prescribed regardless of the costs.
    You can deduce that all treatments are beneficial to customers, some more than
    others. And, of course, some treatments benefit the bank more than others, depending
    on the customer. There’s a thin line to tread here.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 11.15* 中很明显，“None”（无治疗）永远不会被推荐给任何客户。即使不扣除成本，这一事实也成立——你可以从 `treatment_effect_minus_costs`
    中移除 `cost_fn` 并重新运行输出图表的代码来验证，无论成本如何，治疗总是被推荐的。你可以推断出所有治疗对客户都有益，其中一些比其他更多。当然，根据客户的不同，一些治疗比其他治疗对银行更有利。这里有一条很细的界限。
- en: 'One of the biggest concerns is fairness to customers, especially those that
    the bank wronged the most: the underprivileged age group. Just because one policy
    is more costly to the bank than another, it should not preclude the opportunity
    to access other policies. One way to assess this would be with a percentage-stacked
    bar plot for all recommended policies. That way, we can observe how the recommended
    policy is split between privileged and underprivileged groups. Have a look at
    the following code snippet:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 最大的担忧之一是客户的公平性，特别是那些银行伤害最严重的客户：弱势年龄群体。仅仅因为一项政策对银行的成本比另一项更高，并不意味着应该排除访问其他政策的机会。评估这一点的一种方法可以使用所有推荐政策的百分比堆叠条形图。这样，我们可以观察推荐政策在特权群体和弱势群体之间的分配情况。看看下面的代码片段：
- en: '[PRE54]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The code in the preceding snippet outputs the following:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个代码片段中的代码输出如下：
- en: '![](img/B18406_11_16.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18406_11_16.png)'
- en: 'Figure 11.16: Fairness of optimal policy distributions'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.16：最优策略分布的公平性
- en: '*Figure 11.16* shows how privileged groups are at a higher proportion assigned
    one of the policies with the **Payment Plan**. This disparity is primarily due
    to the bank’s costs being a factor, so if the bank were to absorb some of these
    costs, it could make it fairer. But what would be a fair solution? Choosing credit
    policies is an example of procedural fairness, and there are many possible definitions.
    Does equal treatment literally mean equal treatment or proportional treatment?
    Does it encompass notions of freedom of choice too? What if a customer prefers
    one policy over another? Should they be allowed to switch? Whatever the definition
    is, it can be resolved with help from the causal model. We can assign all customers
    the same policy, or the distribution of recommended policies can be calibrated
    so that proportions are equal, or every customer can choose between the first
    and second most optimal policy. There are so many ways to go about it!'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 11.16* 展示了特权群体被分配到具有**支付计划**的政策的比例更高。这种差异主要是由于银行的成本是一个因素，所以如果银行能够承担一些这些成本，那么它可能会更加公平。但什么是公平的解决方案呢？选择信贷政策是程序公平性的一个例子，并且有许多可能的定义。平等对待是否字面意义上的平等对待或比例对待？它是否包括选择自由的概念？如果客户更喜欢一项政策而不是另一项，他们应该被允许切换吗？无论定义如何，都可以通过因果模型的帮助来解决。我们可以将相同的政策分配给所有客户，或者调整推荐政策的分布，使得比例相等，或者每个客户都可以在第一和第二最优政策之间进行选择。有如此多的方法可以这样做！'
- en: Testing estimate robustness
  id: totrans-360
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试估计的鲁棒性
- en: 'The `dowhy` library comes with four methods to test the robustness of the estimated
    causal effect, outlined as follows:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '`dowhy` 库提供了四种方法来测试估计因果效应的鲁棒性，具体如下：'
- en: '**Random common cause**: Adding a randomly generated confounder. If the estimate
    is robust, the ATE should not change too much.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机共同原因**：添加一个随机生成的混杂因素。如果估计是鲁棒的，ATE（平均处理效应）不应该变化太多。'
- en: '**Placebo treatment refuter**: Replacing treatments with random variables (placebos).
    If the estimate is robust, the ATE should be close to zero.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安慰剂治疗反驳者**：用随机变量（安慰剂）替换治疗。如果估计是鲁棒的，ATE 应该接近零。'
- en: '**Data subset refuter**: Removing a random subset of the data. If the estimator
    generalizes well, the ATE should not change too much.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据子集反驳者**：移除数据的一个随机子集。如果估计器泛化良好，ATE 不应该变化太多。'
- en: '**Add unobserved common cause**: Adding an unobserved confounder that is associated
    with both the treatment and outcome. The estimator assumes some level of unconfoundedness
    but adding more should bias the estimates. Depending on the strength of the confounder’s
    effect, it should have an equal impact on the ATE.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**添加未观察到的共同原因**：添加一个与处理和结果都相关的未观察到的混杂因素。估计量假设存在一定程度的未混杂性，但添加更多应该会偏误估计。根据混杂因素效应的强度，它应该对ATE有相同的影响。'
- en: We will test robustness with the first two next.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用前两个来测试稳健性。
- en: Adding a random common cause
  id: totrans-367
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加随机共同原因
- en: 'This method is the easiest to implement by calling `refute_estimate` with `method_name="random_common_cause"`.
    This will return a summary that you can print. Have a look at the following code
    snippet:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法通过调用`refute_estimate`并指定`method_name="random_common_cause"`来实现，这是最简单的实现方式。这将返回一个可以打印的摘要。请看以下代码片段：
- en: '[PRE55]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The code in the preceding snippet outputs the following:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 前述代码片段输出如下：
- en: '[PRE56]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The preceding output tells us that a new common cause, or *W* variable, doesn’t
    have a sizable impact on the ATE.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的输出告诉我们，一个新的共同原因，或称 *W* 变量，对平均处理效应（ATE）没有显著影响。
- en: Replacing the treatment variable with a random variable
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用随机变量替换处理变量
- en: 'With this method, we will replace the treatment variable with noise. If the
    treatment correlates robustly with the outcome, this should bring the average
    effect to zero. To implement it, we also call the `refute_estimate` function but
    with `placebo_treatment_refuter` for the method. We must also specify the `placebo_type`
    and the number of simulations (`num_simulations`). The placebo type we will use
    is `permute`, and the more simulations the better, but this will also take longer.
    The code can be seen in the following snippet:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此方法，我们将用噪声替换处理变量。如果处理与结果有稳健的相关性，这应该将平均效应降至零。为了实现它，我们同样调用`refute_estimate`函数，但使用`placebo_treatment_refuter`作为方法。我们还必须指定`placebo_type`和模拟次数（`num_simulations`）。我们将使用的安慰剂类型是`permute`，模拟次数越多越好，但这也会花费更长的时间。代码可以在以下片段中看到：
- en: '[PRE57]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The preceding code outputs the following:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码输出如下：
- en: '[PRE58]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: As you can tell by the preceding output, the new effect is close to zero. However,
    given that the p-value is above 0.05, we cannot reject the null hypothesis that
    ascertains that the ATE is greater than zero. This tells us that the estimated
    causal effect is not very robust. We can likely improve it by adding relevant
    confounders or by using a different causal model, but also, the experimental design
    had flaws that we cannot fix, such as the biased way the bank prescribed the treatments
    according to the risk factor.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述输出所示，新的效应接近于零。然而，鉴于p值高于0.05，我们不能拒绝ATE大于零的零假设。这告诉我们，估计的因果效应并不非常稳健。我们可能通过添加相关的混杂因素或使用不同的因果模型来改进它，但同样，实验设计存在我们无法修复的缺陷，例如银行根据风险因素偏袒地指定治疗方式。
- en: Mission accomplished
  id: totrans-379
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务完成
- en: 'The mission of this chapter was twofold, as outlined here:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的任务有两个，如下所述：
- en: Create a fair predictive model to predict which customers are most likely to
    default.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个公平的预测模型来预测哪些客户最有可能违约。
- en: Create a robust causal model to estimate which policies are most beneficial
    to customers and the bank.
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个稳健的因果模型来估计哪些政策对客户和银行最有益。
- en: Regarding the first goal, we have produced four models with bias mitigation
    methods that are objectively fairer than the base model, according to four fairness
    metrics (SPD, DI, AOD, EOD)—when comparing privileged and underprivileged age
    groups. However, only two of these models are intersectionally fairer using both
    age group and gender, according to DFBA (see *Figure 11.7*). We can still improve
    fairness significantly by combining methods, yet any one of the four models improves
    the base model.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 关于第一个目标，我们已经根据四个公平性指标（SPD、DI、AOD、EOD）——在比较特权群体和弱势群体年龄组时——产生了四个具有偏差缓解方法的模型，这些模型在客观上比基础模型更公平。然而，根据DFBA（参见*图11.7*），只有其中两个模型在同时使用年龄组和性别时具有交叉公平性。通过结合方法，我们仍然可以显著提高公平性，但任何一种模型都能改进基础模型。
- en: 'As for the second goal, the causal inference framework determined that any
    of the policies tested is better than no policy for both parties. Hooray! However,
    it yielded estimates that didn’t establish a single winning one. Still, as expected,
    the recommended policy varies according to the customer’s credit limit—on the
    other hand, if we aim to maximize bank profitability, we must factor in the average
    use of credit cards. The question of profitability presents two goals that we
    must reconcile: prescribing the recommended policies that benefit either the customer
    or the bank the most.'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个目标，因果推断框架确定，所测试的任何政策对于双方来说都比没有政策要好。太好了！然而，它得出的估计并没有确立一个单一的获胜者。尽管如此，正如预期的那样，推荐的政策会根据客户的信用额度而变化——另一方面，如果我们旨在最大化银行利润，我们必须考虑信用卡的平均使用情况。盈利性的问题提出了我们必须协调的两个目标：制定对客户或银行最有利的推荐政策。
- en: For this reason, how to be procedurally fair is a complicated question with
    many possible answers, and any of the solutions would involve the bank absorbing
    some of the costs associated with implementing the policies. As for robustness,
    despite the flawed experiment, we can conclude that our estimates have a mediocre
    level of robustness, passing one robustness test but not the other. That being
    said, it all depends on what we consider robust enough to validate our findings.
    Ideally, we would ask the bank to start a new unbiased experiment but waiting
    another 6 months might not be feasible.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如何程序上公平是一个复杂的问题，有许多可能的答案，任何解决方案都可能导致银行吸收与实施政策相关的部分成本。至于鲁棒性，尽管实验存在缺陷，但我们可以说我们的估计具有中等水平的鲁棒性，通过了一个鲁棒性测试但没有通过另一个。话虽如此，这完全取决于我们认为足够鲁棒以验证我们的发现。理想情况下，我们会要求银行开始一个新的无偏实验，但等待另外6个月可能不可行。
- en: In data science, we often find ourselves working with flawed experiments and
    biased data and have to make the most of it. Causal inference provides a way to
    do so by disentangling cause and effect, complete with estimates and their respective
    confidence intervals. We can then offer findings with all the disclaimers so that
    decision-makers can make informed decisions. Biased decisions lead to biased outcomes,
    so the moral imperative of tackling bias can start by shaping decision-making.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，我们经常发现自己在与有缺陷的实验和有偏差的数据打交道，并必须充分利用它们。因果推断通过分离原因和效果，包括估计及其相应的置信区间，提供了一种这样做的方法。然后我们可以提供带有所有免责声明的发现，以便决策者可以做出明智的决策。有偏差的决策会导致有偏差的结果，因此解决偏差的道德必要性可以从塑造决策开始。
- en: Summary
  id: totrans-387
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: After reading this chapter, you should understand how bias can be detected visually
    and with metrics, both in data and models, then mitigated through preprocessing,
    in-processing, and post-processing methods. We also learned about causal inference
    by estimating heterogeneous treatment effects, making fair policy decisions with
    them, and testing their robustness. In the next chapter, we also discuss bias
    but learn how to tune models to meet several objectives, including fairness.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本章之后，你应该了解如何通过视觉和指标在数据和模型中检测偏差，然后通过预处理、处理和后处理方法来减轻偏差。我们还通过估计异质处理效应、用它们做出公平的政策决策以及测试它们的鲁棒性来了解因果推断。在下一章中，我们也将讨论偏差，但学习如何调整模型以满足多个目标，包括公平性。
- en: Dataset sources
  id: totrans-389
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集来源
- en: 'Yeh, I. C., & Lien, C. H. (2009). *The comparisons of data mining techniques
    for the predictive accuracy of probability of default of credit card clients*.
    Expert Systems with Applications, 36(2), 2473-2480: [https://dl.acm.org/doi/abs/10.1016/j.eswa.2007.12.020](https://dl.acm.org/doi/abs/10.1016/j.eswa.2007.12.020)'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 'Yeh, I. C., & Lien, C. H. (2009). *比较数据挖掘技术在预测信用卡客户违约概率方面的准确性*. 《专家系统与应用》，36(2)，2473-2480:
    [https://dl.acm.org/doi/abs/10.1016/j.eswa.2007.12.020](https://dl.acm.org/doi/abs/10.1016/j.eswa.2007.12.020)'
- en: Further reading
  id: totrans-391
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Chang, C., Chang, H.H., and Tien, J., 2017, *A Study on the Coping Strategy
    of Financial Supervisory Organization under Information Asymmetry: Case Study
    of Taiwan’s Credit Card Market*. Universal Journal of Management, 5, 429-436:
    [http://doi.org/10.13189/ujm.2017.050903](http://doi.org/10.13189/ujm.2017.050903)'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chang, C., Chang, H.H., and Tien, J., 2017, *关于信息不对称下金融监管机构应对策略的研究：台湾信用卡市场案例研究*.
    《通用管理杂志》，5，429-436: [http://doi.org/10.13189/ujm.2017.050903](http://doi.org/10.13189/ujm.2017.050903)'
- en: 'Foulds, J., and Pan, S., 2020, *An Intersectional Definition of Fairness*.
    2020 IEEE 36th International Conference on Data Engineering (ICDE), 1918-1921:
    [https://arxiv.org/abs/1807.08362](https://arxiv.org/abs/1807.08362)'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Foulds, J., and Pan, S., 2020, *An Intersectional Definition of Fairness*.
    2020 IEEE 36th International Conference on Data Engineering (ICDE), 1918-1921:
    [https://arxiv.org/abs/1807.08362](https://arxiv.org/abs/1807.08362)'
- en: 'Kamiran, F., and Calders, T., 2011, *Data preprocessing techniques for classification
    without discrimination*. Knowledge and Information Systems, 33, 1-33: [https://link.springer.com/article/10.1007/s10115-011-0463-8](https://link.springer.com/article/10.1007/s10115-011-0463-8)'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kamiran, F., and Calders, T., 2011, *Data preprocessing techniques for classification
    without discrimination*. Knowledge and Information Systems, 33, 1-33: [https://link.springer.com/article/10.1007/s10115-011-0463-8](https://link.springer.com/article/10.1007/s10115-011-0463-8)'
- en: 'Feldman, M., Friedler, S., Moeller, J., Scheidegger, C., and Venkatasubramanian,
    S., 2015, *Certifying and Removing DI*. Proceedings of the 21st ACM SIGKDD International
    Conference on Knowledge Discovery and Data Mining: [https://arxiv.org/abs/1412.3756](https://arxiv.org/abs/1412.3756)'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Feldman, M., Friedler, S., Moeller, J., Scheidegger, C., and Venkatasubramanian,
    S., 2015, *Certifying and Removing DI*. Proceedings of the 21st ACM SIGKDD International
    Conference on Knowledge Discovery and Data Mining: [https://arxiv.org/abs/1412.3756](https://arxiv.org/abs/1412.3756)'
- en: 'Kamishima, T., Akaho, S., Asoh, H., and Sakuma, J., 2012, *Fairness-Aware Classifier
    with Prejudice Remover Regularizer*. ECML/PKDD: [https://dl.acm.org/doi/10.5555/3120007.3120011](https://dl.acm.org/doi/10.5555/3120007.3120011)'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kamishima, T., Akaho, S., Asoh, H., and Sakuma, J., 2012, *Fairness-Aware Classifier
    with Prejudice Remover Regularizer*. ECML/PKDD: [https://dl.acm.org/doi/10.5555/3120007.3120011](https://dl.acm.org/doi/10.5555/3120007.3120011)'
- en: A. Agarwal, A. Beygelzimer, M. Dudik, J. Langford, and H. Wallach, *A Reductions
    Approach to Fair Classification*, International Conference on Machine Learning,
    2018\. [https://arxiv.org/pdf/1803.02453.pdf](https://arxiv.org/pdf/1803.02453.pdf)
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A. Agarwal, A. Beygelzimer, M. Dudik, J. Langford, and H. Wallach, *A Reductions
    Approach to Fair Classification*, International Conference on Machine Learning,
    2018\. [https://arxiv.org/pdf/1803.02453.pdf](https://arxiv.org/pdf/1803.02453.pdf)
- en: 'Kearns, M., Neel, S., Roth, A., and Wu, Z., 2018, *Preventing Fairness Gerrymandering:
    Auditing and Learning for Subgroup Fairness*. ICML: [https://arxiv.org/pdf/1711.05144.pdf](https://arxiv.org/pdf/1711.05144.pdf)'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kearns, M., Neel, S., Roth, A., and Wu, Z., 2018, *Preventing Fairness Gerrymandering:
    Auditing and Learning for Subgroup Fairness*. ICML: [https://arxiv.org/pdf/1711.05144.pdf](https://arxiv.org/pdf/1711.05144.pdf)'
- en: 'Pleiss, G., Raghavan, M., Wu, F., Kleinberg, J., and Weinberger, K.Q., 2017,
    *On Fairness and Calibration*. NIPS: [https://arxiv.org/abs/1709.02012](https://arxiv.org/abs/1709.02012)'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pleiss, G., Raghavan, M., Wu, F., Kleinberg, J., and Weinberger, K.Q., 2017,
    *On Fairness and Calibration*. NIPS: [https://arxiv.org/abs/1709.02012](https://arxiv.org/abs/1709.02012)'
- en: 'Foster, D. and Syrgkanis, V., 2019, *Orthogonal Statistical Learning*. ICML:
    [http://arxiv.org/abs/1901.09036](http://arxiv.org/abs/1901.09036)'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Foster, D. and Syrgkanis, V., 2019, *Orthogonal Statistical Learning*. ICML:
    [http://arxiv.org/abs/1901.09036](http://arxiv.org/abs/1901.09036)'
- en: Learn more on Discord
  id: totrans-401
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Discord 上了解更多
- en: 'To join the Discord community for this book – where you can share feedback,
    ask the author questions, and learn about new releases – follow the QR code below:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 要加入这本书的 Discord 社区——在那里您可以分享反馈、向作者提问，并了解新版本——请扫描下面的二维码：
- en: '[https://packt.link/inml](Chapter_11.xhtml)'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/inml](Chapter_11.xhtml)'
- en: '![](img/QR_Code107161072033138125.png)'
  id: totrans-404
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code107161072033138125.png)'
