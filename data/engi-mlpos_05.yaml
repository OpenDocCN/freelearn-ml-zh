- en: 'Chapter 4: Machine Learning Pipelines'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：机器学习管道
- en: In this chapter, we will explore and implement **machine learning** (**ML**)
    pipelines by going through hands-on examples using the MLOps approach. We will
    learn more by solving the business problem that we've been working on in [*Chapter
    3*](B16572_03_Final_JM_ePub.xhtml#_idTextAnchor053), *Code Meets Data*. This theoretical
    and practical approach to learning will ensure that you will have comprehensive
    knowledge of architecting and implementing ML pipelines for your problems or your
    company's problems. A ML pipeline has modular scripts or code that perform all
    the traditional steps in ML, such as data preprocessing, feature engineering,
    and feature scaling before training or retraining any model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过使用 MLOps 方法通过实际示例探索和实现 **机器学习**（**ML**）管道。我们将通过解决我们在 [*第 3 章*](B16572_03_Final_JM_ePub.xhtml#_idTextAnchor053)
    中一直在工作的业务问题，即 *代码遇见数据*，来学习更多。这种理论与实践相结合的学习方法将确保您将全面了解为您的或您公司的问题构建和实现 ML 管道的知识。ML
    管道具有模块化脚本或代码，执行所有传统的 ML 步骤，例如在训练或重新训练任何模型之前进行数据预处理、特征工程和特征缩放。
- en: 'We begin this chapter by ingesting the preprocessed data we worked on in the
    last chapter by performing feature engineering and scaling it to get it in shape
    for the ML training. We will discover the principles of ML pipelines and implement
    them on the business problem. Going ahead, we''ll look into ML model training,
    hyperparameter tuning, and the testing of the trained models. Finally, we''ll
    learn about packaging the models and their needed artifacts. We''ll register the
    models for further evaluation and will deploy the ML models. We are going to cover
    the following main topics in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从本章开始，通过执行特征工程和缩放，将我们在上一章中处理过的预处理数据摄取进来，以便为 ML 训练做好准备。我们将发现 ML 管道的原理，并在业务问题中实现它们。接下来，我们将探讨
    ML 模型训练、超参数调整和训练模型的测试。最后，我们将学习如何打包模型及其所需工件。我们将注册模型以进行进一步评估，并将部署 ML 模型。在本章中，我们将涵盖以下主要主题：
- en: Going through the basics of ML pipelines
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 掌握 ML 管道的基础知识
- en: Data ingestion and feature engineering
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据摄取和特征工程
- en: ML training and hyperparameter optimization
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ML 训练和超参数优化
- en: Model testing and defining metrics
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型测试和定义指标
- en: Model packaging
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型打包
- en: Registering models and production artifacts
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注册模型和生产工件
- en: Going through the basics of ML pipelines
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 掌握 ML 管道的基础知识
- en: Before we jump into the implementation of the ML pipeline, let's get the basics
    right. We will reflect on ML pipelines and set up the needed resources for ML
    pipeline implementation and then we will get started with data ingestion. Let's
    demystify ML pipelines by reflecting on the ML pipeline we discussed in *Figure
    14* of [*Chapter 1*](B16572_01_Final_JM_ePub.xhtml#_idTextAnchor015), *Fundamentals
    of MLOps Workflow*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始实现 ML 管道之前，让我们先掌握基础知识。我们将反思 ML 管道，并为 ML 管道实现设置所需资源，然后我们将开始数据摄取。让我们通过反思
    *第 1 章* 中 *MLOps 工作流程基础* 的 *图 14* 中讨论的 ML 管道来揭开 ML 管道的神秘面纱。
- en: '![ Figure 4.1 – Machine learning pipeline'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.1 – 机器学习管道'
- en: '](img/B16572_04_001.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_04_001.jpg)'
- en: Figure 4.1 – Machine learning pipeline
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – 机器学习管道
- en: 'As shown in *Figure 4.1*, a comprehensive ML pipeline consists of the following
    steps:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 4.1* 所示，一个全面的 ML 管道包括以下步骤：
- en: Data ingestion
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据摄取
- en: Model training
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练
- en: Model testing
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型测试
- en: Model packaging
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型打包
- en: Model registering
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型注册
- en: 'We will implement all these steps of the pipeline using the Azure ML service
    (cloud-based) and MLflow (open source) simultaneously for the sake of a diverse
    perspective. Azure ML and MLflow are a power couple for MLOps: they exhibit the
    features shown in *Table 4.1*. They are also unique in their capabilities, as
    we can see from the following table.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得不同的视角，我们将同时使用基于云的 Azure ML 服务和开源的 MLflow 来实现管道的所有这些步骤。Azure ML 和 MLflow
    是 MLOps 的强大组合：它们展示了 *表 4.1* 中显示的功能。从以下表格中我们可以看到，它们在功能上也是独特的。
- en: '![Table 4.2 – MLflow versus Azure ML service'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![表 4.2 – MLflow 与 Azure ML 服务比较'
- en: '](img/01.jpg)![Table 4.2 – MLflow versus Azure ML service'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/01.jpg)![表 4.2 – MLflow 与 Azure ML 服务比较'
- en: '](img/02.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/02.jpg)'
- en: Table 4.2 – MLflow versus Azure ML service
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.2 – MLflow 与 Azure ML 服务比较
- en: To implement the ML pipeline, we need a storage resource for our dataset and
    a computational resource for our ML models. As discussed before in [*Chapter 2*](B16572_02_Final_JM_ePub.xhtml#_idTextAnchor028),
    *Characterizing Your Machine Learning Problem*, we will perform the computation
    required to implement the ML pipeline and the business problem, as shown in *Figure
    4.2*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现机器学习管道，我们需要为我们的数据集提供存储资源，并为我们的机器学习模型提供计算资源。如前所述，在[*第2章*](B16572_02_Final_JM_ePub.xhtml#_idTextAnchor028)“描述您的机器学习问题”中，我们将执行实现机器学习管道和业务问题的计算，如图*图4.2*所示。
- en: We process the data on our local computer or PC to get started and preprocess
    the data for our ML training. For ML training and pipeline implementation, we
    use compute resources provisioned on the cloud (Microsoft Azure). Even though
    ML training for the pipeline can be done on your local computer, we will use compute
    resources on the cloud to learn how to provision and use the needed compute resources
    for the ML pipeline.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本地计算机或PC上处理数据以开始，并预处理数据以进行机器学习训练。对于机器学习训练和管道实现，我们使用云上配置的计算资源（Microsoft Azure）。尽管管道的机器学习训练可以在您的本地计算机上进行，但我们将使用云上的计算资源来学习如何配置和使用所需的计算资源以实现机器学习管道。
- en: '![ Figure 4.3 – Computation location for data and ML tasks'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.3 – 数据和机器学习任务的计算位置'
- en: '](img/B16572_04_002.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16572_04_002.jpg]'
- en: Figure 4.3 – Computation location for data and ML tasks
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – 数据和机器学习任务的计算位置
- en: 'Without further ado, let''s configure the needed compute resources for the
    ML pipeline using the following steps:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 不再拖延，让我们按照以下步骤配置所需的机器学习管道计算资源：
- en: Go to your ML workspace.![Figure 4.4 – Azure Machine Learning workspace
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往您的机器学习工作空间。![图4.4 – Azure机器学习工作空间
- en: '](img/B16572_04_003.jpg)'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ']'
- en: Figure 4.4 – Azure Machine Learning workspace
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.4 – Azure机器学习工作空间
- en: Go to the **Compute** option and click the **Create** button to explore compute
    options available on the cloud.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往**计算**选项，点击**创建**按钮以探索云上可用的计算选项。
- en: Select the suitable compute option for the ML model training to be optimal and
    efficient.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择适合机器学习模型训练的最佳和高效的计算选项。
- en: Select a suitable compute option based on your training needs and cost limitations
    and give it a name. For example, in *Figure 4.4*, a compute or virtual machine
    is selected for the experiment `unique_code-ml-compute1`). The selected compute
    option in *Figure 4.4* is one of the cheapest compute options and this is sufficient
    for implementing the ML pipeline for the business problem. For faster implementation
    and training ML models, it is recommended to use the `STANDARD_DS11_V2` (2 cores,
    14 GB RAM) virtual machine size. With this option, training a model will take
    around 12 minutes.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据您的训练需求和成本限制选择合适的计算选项，并为其命名。例如，在*图4.4*中，为实验`unique_code-ml-compute1`选择了计算或虚拟机。*图4.4*中选择的计算选项是成本最低的计算选项之一，这足以实现业务问题的机器学习管道。为了更快地实现和训练机器学习模型，建议使用`STANDARD_DS11_V2`（2核，14
    GB RAM）虚拟机大小。使用此选项，训练一个模型将大约需要12分钟。
- en: Provision the compute resource created previously. After naming and creating
    the needed compute resource, your compute resource is provisioned, ready, and
    running for ML training on the cloud, as shown in *Figure 4.5*.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置之前创建的计算资源。在命名并创建所需的计算资源后，您的计算资源已配置、就绪并运行在云上，如图*图4.5*所示。
- en: '![Figure 4.6 – Provisioned compute in an AzureML workspace'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.6 – AzureML工作空间中的配置计算'
- en: '](img/B16572_04_005.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16572_04_005.jpg]'
- en: Figure 4.6 – Provisioned compute in an AzureML workspace
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6 – AzureML工作空间中的配置计算
- en: After it is provisioned, select the **JupyterLab** option. JupyterLab is an
    open source web-based user interface. It comes with features such as text editor,
    code editor, terminal, and custom components integrated in an extensible manner.
    We will use this as a programming interface connected to the provisioned compute
    to train the ML models.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置完成后，选择**JupyterLab**选项。JupyterLab是一个开源的基于Web的用户界面。它集成了文本编辑器、代码编辑器、终端和可扩展方式集成的自定义组件等功能。我们将使用它作为连接到配置的计算资源以训练机器学习模型的编程接口。
- en: 'Now we''ll begin with the hands-on implementation of the ML pipeline. Follow
    these steps to implement the ML pipeline:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将开始实际实现机器学习管道。按照以下步骤实现机器学习管道：
- en: To start the implementation, clone the repository you have imported into the
    Azure DevOps project. To clone the repository, click on the **Clone** button in
    the upper-right corner from the **Repos** menu and then click on the **Generate
    Git Credentials** button. A hash password will be created.![Figure 4.7 – Cloning
    an Azure DevOps Git repository (Generate Git Credentials)
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要开始实施，克隆您已导入到 Azure DevOps 项目的仓库。要克隆仓库，请从 **仓库** 菜单的右上角点击 **克隆** 按钮，然后点击 **生成
    Git 凭据** 按钮。将创建一个哈希密码。![图 4.7 – 克隆 Azure DevOps Git 仓库（生成 Git 凭据）
- en: '](img/B16572_04_006.jpg)'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16572_04_006.jpg)'
- en: Figure 4.7 – Cloning an Azure DevOps Git repository (Generate Git Credentials)
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.7 – 克隆 Azure DevOps Git 仓库（生成 Git 凭据）
- en: 'Copy the HTTPS link from the **Command Line** section to get the Azure DevOps
    repository link, like this:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 **命令行** 部分复制 HTTPS 链接以获取 Azure DevOps 仓库链接，如下所示：
- en: '[PRE0]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Copy the password generated from *step 1* and add it to the link from *step
    2* by adding the password just after the first username separated by `:` before
    the `@` character. Then it is possible to use the following `git clone` command
    without getting permission errors:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制从 *步骤 1* 生成的密码，并将其添加到 *步骤 2* 中的链接，方法是在 `@` 字符之前用 `:` 分隔的第一个用户名之后添加密码。然后就可以使用以下
    `git clone` 命令而不会出现权限错误：
- en: '[PRE1]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once you are running JupyterLab, we will access the terminal to clone the repository
    to the azure compute. To access the terminal, you must select the **Terminal**
    option from the **Launcher** tab. Another way to access the terminal directly
    is by using the Terminal link from the Application URI column in the list of compute
    instances in the Azure ML workspace. Go to the **Terminal** option of JupyterLab
    and implement the following (as shown in *Figure 4.7*):'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦启动了 JupyterLab，我们将访问终端以将仓库克隆到 Azure 计算中。要访问终端，您必须从 **启动器** 选项卡中选择 **终端** 选项。另一种直接访问终端的方法是使用
    Azure ML 工作区中计算实例列表中的应用程序 URI 列表中的 **终端** 链接。转到 JupyterLab 的 **终端** 选项并执行以下操作（如图
    4.7 所示）：
- en: '[PRE2]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here is the output:'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '![Figure 4.8 – Clone the Azure DevOps Git repository on Azure compute'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.8 – 在 Azure 计算上克隆 Azure DevOps Git 仓库'
- en: '](img/B16572_04_007.jpg)'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16572_04_007.jpg)'
- en: Figure 4.8 – Clone the Azure DevOps Git repository on Azure compute
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.8 – 在 Azure 计算上克隆 Azure DevOps Git 仓库
- en: Go to the `04_MLpipelines` folder and follow the implementation steps on `ML-pipeline.ipynb`
    from the cloned repository. All of the following steps are implemented in `ML-pipeline.ipynb`.
    It is recommended to follow the file instructions to have a better understanding
    of the implementation and execute the code yourself in a new file as per your
    setup.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入 `04_MLpipelines` 文件夹，并按照克隆仓库中的 `ML-pipeline.ipynb` 文件中的实施步骤进行操作。所有以下步骤都在
    `ML-pipeline.ipynb` 中实现。建议遵循文件说明以更好地理解实施，并按照您的设置在新的文件中自行执行代码。
- en: So far, we have provisioned the compute resource and cloned the GitHub repository
    in the compute.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经配置了计算资源并在计算中克隆了 GitHub 仓库。
- en: 'Next, we start implementing the `ML-pipeline.ipynb` file by importing the needed
    libraries, such as `pandas`, `numpy`, `azureml`, `pickle`, `mlflow`, and others,
    as shown in the following code block:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们通过导入所需的库开始实施 `ML-pipeline.ipynb` 文件，例如 `pandas`、`numpy`、`azureml`、`pickle`、`mlflow`
    等，如下面的代码块所示：
- en: '[PRE3]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we use setup MLflow (for tracking experiments). Use the `get_mlflow_tracking_url()`
    function to get a tracking ID for where MLflow experiments and artifacts should
    be logged (in this case, we get the tracking ID for the provisioned training compute).
    Then use the `set_tracking_uri()` function to connect to a tracking URI (the uniform
    resource identifier of a specific resource) for the provisioned training compute.
    The tracking URI can be either for a remote server, a database connection string,
    or a local path to log data in a local directory. In our case, we point the tracking
    URI to the local path by default (on the provisioned training compute):'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用 setup MLflow（用于跟踪实验）。使用 `get_mlflow_tracking_url()` 函数获取 MLflow 实验和工件应记录的位置的跟踪
    ID（在这种情况下，我们获取已配置的训练计算的跟踪 ID）。然后使用 `set_tracking_uri()` 函数连接到已配置训练计算的跟踪 URI（特定资源的统一资源标识符）。跟踪
    URI 可以是远程服务器、数据库连接字符串或本地目录中记录数据的本地路径。在我们的情况下，我们默认将跟踪 URI 指向本地路径（在已配置的训练计算上）：
- en: '[PRE4]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: By setting the tracking URI for your MLflow experiments, you have set the location
    for MLflow to save its artifacts and logs in the `mlruns` folder (on your provisioned
    compute). After executing these commands, check for the current path. You will
    find the `mlruns` folder.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过设置MLflow实验的跟踪URI，您已为MLflow设置保存其工件和日志的`mlruns`文件夹（在您配置的计算上）的位置。在执行这些命令后，检查当前路径。您将找到`mlruns`文件夹。
- en: Data ingestion and feature engineering
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据摄入和特征工程
- en: Data is essential to train ML models; without data, there is no ML. Data ingestion
    is a trigger step for the ML pipeline. It deals with the volume, velocity, veracity,
    and variety of data by extracting data from various data sources and ingesting
    the needed data for model training.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 数据对于训练机器学习模型至关重要；没有数据，就没有机器学习。数据摄入是机器学习管道的触发步骤。它通过从各种数据源提取数据并摄入模型训练所需的数据来处理数据的量、速度、真实性和多样性。
- en: 'The ML pipeline is initiated by ingesting the right data for training the ML
    models. We will start by accessing the preprocessed data we registered in the
    previous chapter. Follow these steps to access and import the preprocessed data
    and get it ready for ML training:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道通过摄入用于训练机器学习模型的正确数据来启动。我们将从上一章中注册的预处理数据开始。按照以下步骤访问和导入预处理数据，使其为机器学习训练做好准备：
- en: 'Using the `Workspace()` function from the Azure ML SDK, access the data from
    the datastore in the ML workspace as follows:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Azure ML SDK中的`Workspace()`函数，如下访问机器学习工作区中的数据存储：
- en: '[PRE5]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Import the preprocessed dataset that was prepared in the previous chapter.
    The preprocessed dataset is imported using the `.get_by_name()` function from
    the `Dataset` function from the Azureml SDK and the function is used to retrieve
    the needed dataset:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入上一章中准备好的预处理数据集。使用Azureml SDK中的`Dataset`函数的`.get_by_name()`函数导入预处理数据集，并使用该函数检索所需的数据集：
- en: '[PRE6]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Upon successfully retrieving or mounting the dataset, you can confirm by printing
    `dataset.name` and `dataset.version`, which should print `processed_weather_data_portofTurku
    1` or as per the name you have given the dataset previously.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在成功检索或挂载数据集后，可以通过打印`dataset.name`和`dataset.version`来确认，应打印`processed_weather_data_portofTurku
    1`或您之前给数据集命名的名称。
- en: 'After retrieving the preprocessed data, it is vital to split it into training
    and validation sets in order to train the ML model and test or evaluate it in
    the training phase and later stages. Hence, we split it into the training and
    validation sets, by splitting it in the 80% (training set) and 20% (test set)
    split-ratio as follows:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在检索到预处理数据后，将其分为训练集和验证集至关重要，以便在训练阶段和后续阶段训练机器学习模型并进行测试或评估。因此，我们将其分为80%（训练集）和20%（测试集）的分割比，如下所示：
- en: '[PRE7]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After successfully splitting the data, these two datasets are stored and registered
    to the datastore (connected to the Azure ML workspace) as follows:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在成功分割数据后，这两个数据集被存储并注册到数据存储（连接到Azure ML工作区）中，如下所示：
- en: '[PRE8]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: By using the `register()` function, we are able to register the training and
    test datasets, which can be imported later from the datastore.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`register()`函数，我们能够注册训练集和测试集，这些数据集可以在以后从数据存储中导入。
- en: Next, we will import the training data and ingest it into the ML pipeline and
    use the test dataset later to test the model's performance on unseen data in production
    or for model analysis.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将导入训练数据并将其摄入到机器学习管道中，并使用测试数据集来测试模型在生产中对未见数据的性能或用于模型分析。
- en: Data ingestion (training dataset)
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据摄入（训练数据集）
- en: 'To ingest training data into the ML pipeline, we start by importing it using
    the `get_by_name()` function and converting it to a pandas dataframe using the
    `to_pandas_dataframe()` function:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要将训练数据摄入到机器学习管道中，我们首先使用`get_by_name()`函数导入它，然后使用`to_pandas_dataframe()`函数将其转换为pandas数据框：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The training dataset is now retrieved and will be used to further train the
    ML models. The goal is to train classification models to predict whether it will
    rain or not. Hence, select the `Temperature`, `Humidity`, `Wind_speed`, `Wind_bearing`,
    `Visibility`, `Pressure`, and `Current_weather_conditions` features to train the
    binary classification models to predict weather conditions in the future (4 hours
    ahead).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已检索到训练数据集，并将用于进一步训练机器学习模型。目标是训练分类模型以预测是否会下雨。因此，选择`Temperature`（温度）、`Humidity`（湿度）、`Wind_speed`（风速）、`Wind_bearing`（风向）、`Visibility`（能见度）、`Pressure`（气压）和`Current_weather_conditions`（当前天气状况）特征来训练二元分类模型，以预测未来的天气状况（4小时后）。
- en: 'Follow these steps to select features and scale them:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤选择特征并进行缩放：
- en: 'Before training the ML models, selecting the right features and scaling the
    data is vital. Therefore, we select features as follows. The values in the variable
    `X` represent the independent variables and the variable `Y` is the dependent
    variable (forecasted weather):'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练机器学习模型之前，选择正确的特征和缩放数据是至关重要的。因此，我们按照以下方式选择特征。变量`X`中的值代表自变量，而变量`Y`是因变量（预测的天气）：
- en: '[PRE10]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Split the training data into the training and testing sets (for training validation
    after training) using the `train_test_split()` function from `sklearn`. Fixing
    the random seed (`random_state`) is needed to reproduce a training session by
    keeping the samples from the previous experiment with the same configuration.
    Hence, we will use `random_state=1`:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`sklearn`中的`train_test_split()`函数将训练数据分割成训练集和测试集（用于训练后的验证）。为了通过保持与先前实验相同配置的样本来重现训练会话，需要固定随机种子（`random_state`）。因此，我们将使用`random_state=1`：
- en: '[PRE11]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: With an 80% (training data) and 20% (test data) split, the training and test
    datasets are now ready for feature scaling and ML model training.
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在80%（训练数据）和20%（测试数据）的分割下，训练集和测试集现在已准备好进行特征缩放和机器学习模型训练。
- en: 'For the ML model training to be optimal and efficient, the data needs to be
    on the same scale. Therefore, we scale the data using `StandardScalar()` from
    `sklearn` to calibrate all the numeric values in the data on the same scale:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使机器学习模型训练达到最佳和高效，数据需要在同一尺度上。因此，我们使用`sklearn`中的`StandardScaler()`对数据进行缩放，以校准数据中的所有数值到同一尺度：
- en: '[PRE12]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: With this step, the numeric values of the training data are scaled using `StandardScalar`
    and all the values are transformed in the range of `-1` to `1`, based on `X_train
    values`. Now we are ready to train ML models (the fun part)!
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这一步中，使用`StandardScaler`对训练数据的数值进行缩放，并将所有值转换到基于`X_train`值的`-1`到`1`的范围内。现在我们已准备好训练机器学习模型（有趣的部分）！
- en: Machine learning training and hyperparameter optimization
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习训练和超参数优化
- en: We are all set to do the fun part, training ML models! This step enables model
    training; it has modular scripts or code that perform all the traditional steps
    in ML training, such as fitting and transforming data to train the model and hyperparameter
    tuning to converge the best model. The output of this step is a trained ML model.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好进行有趣的部分，即训练机器学习模型！这一步使模型训练成为可能；它包含模块化脚本或代码，执行所有传统的机器学习训练步骤，例如拟合和转换数据以训练模型，以及超参数调整以收敛到最佳模型。这一步骤的输出是一个训练好的机器学习模型。
- en: To solve the business problem, we will train two well-known models using the
    **Support Vector Machine** classifier and the **Random Forest** classifier. These
    are chosen based on their popularity and consistency of results; you are free
    to choose models of your choice – there are no limitations in this step. First,
    we will train the Support Vector Machine classifier and then the Random Forest
    classifier.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决业务问题，我们将使用**支持向量机**分类器和**随机森林**分类器训练两个著名的模型。这些模型的选择基于它们的流行度和结果的一致性；你可以自由选择你喜欢的模型——在这个步骤中没有限制。首先，我们将训练支持向量机分类器，然后是随机森林分类器。
- en: Support Vector Machine
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持向量机
- en: '**Support Vector Machine (SVM)** is a popular supervised learning algorithm
    (used for classification and regression). The data points are classified using
    hyperplanes in an N-dimensional space. It is known for producing significant accuracy
    with less computation power. It is recommended to know SVM, in theory, to better
    understand the model training in practice. To learn more about SVM, head here:
    [https://www.kdnuggets.com/2017/02/yhat-support-vector-machine.html](https://www.kdnuggets.com/2017/02/yhat-support-vector-machine.html).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机（SVM**）是一种流行的监督学习算法（用于分类和回归）。数据点在N维空间中使用超平面进行分类。它以较少的计算能力产生显著的准确性而闻名。建议在理论上了解SVM，以便更好地理解实践中的模型训练。了解更多关于SVM的信息，请访问：[https://www.kdnuggets.com/2017/02/yhat-support-vector-machine.html](https://www.kdnuggets.com/2017/02/yhat-support-vector-machine.html)。'
- en: 'Let''s get started with training the SVM classifier:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始训练SVM分类器：
- en: 'We begin by initiating the training or experiment using the `Experiment()`
    function from the Azure SDK. The purpose of this function is to start a training
    run or experiment in order to monitor and log the model training performance in
    the Azure ML workspace:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先使用Azure SDK中的`Experiment()`函数启动训练或实验。此函数的目的是在Azure ML工作区中启动一个训练运行或实验，以便监控和记录模型训练性能：
- en: '[PRE13]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Similarly, the MLflow experiment is also initiated to observe a different perspective:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，MLflow实验也被启动，以观察不同的视角：
- en: '[PRE14]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now we have initiated an experiment in both the Azure ML workspace and MLflow.
    The following training step will be monitored and logged.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们在Azure ML工作区和MLflow中启动了实验。以下训练步骤将被监控和记录。
- en: 'Next, we do hyperparameter tuning to find the best parameters to converge the
    best model. This can be done manually, but more efficient and automatic solutions
    such as Grid Search or Random Search exist. For training, the SVM classifier uses
    Grid Search as follows. We proceed by using the `SVC()` and `Grid SearchCV()`
    functions from `sklearn` and logging the run on Azure ML and MLflow:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们进行超参数调整，以找到收敛最佳模型的最佳参数。这可以手动完成，但更高效和自动的解决方案，如Grid Search或Random Search存在。对于训练，SVM分类器使用以下Grid
    Search。我们通过使用`SVC()`和`GridSearchCV()`函数从`sklearn`中，并在Azure ML和MLflow上记录运行来继续操作：
- en: '[PRE15]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, using the best parameters, a new model is trained using `C=1` and
    `kernel=''rbf ''` as follows:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用最佳参数，以下是用`C=1`和`kernel='rbf '`训练新模型的步骤：
- en: '[PRE16]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: With this, we have trained the SVM model! We will now train the Random Forest
    classifier model.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过这种方式，我们已经训练了SVM模型！现在我们将训练随机森林分类器模型。
- en: Random Forest classifier
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机森林分类器
- en: Random Forest is another popular supervised learning model (used for classification
    and regression). Random Forest is an ensemble learning method that operates with
    a multitude of decision trees. Before performing the model training, it is recommended
    to know the theoretical working of the Random Forest model. To know more about
    the Random Forest model, visit [https://www.kdnuggets.com/2020/01/random-forest-powerful-ensemble-learning-algorithm.html](https://www.kdnuggets.com/2020/01/random-forest-powerful-ensemble-learning-algorithm.html).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是另一种流行的监督学习模型（用于分类和回归）。随机森林是一种集成学习方法，它使用多个决策树。在执行模型训练之前，建议了解随机森林模型的理论工作原理。要了解更多关于随机森林模型的信息，请访问[https://www.kdnuggets.com/2020/01/random-forest-powerful-ensemble-learning-algorithm.html](https://www.kdnuggets.com/2020/01/random-forest-powerful-ensemble-learning-algorithm.html)。
- en: 'To start training the Random Forest classifier, initialize the experiment in
    the Azure ML workspace and the MLflow experiment as follows:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要开始训练随机森林分类器，按照以下方式在Azure ML工作区和MLflow实验中初始化实验：
- en: '[PRE17]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After the experiment is successfully initiated, training can be initiated by
    importing the `RandomForestClassifier()` function from `sklearn.ensemble` and
    calling the function with the needed parameters, shown as follows. These parameters
    are randomly chosen (no `Grid Search` is done). `Grid Search` or `RandomizedSearch`
    can be used to determine the best parameters and optimize the algorithm:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实验成功启动后，可以通过从`sklearn.ensemble`导入`RandomForestClassifier()`函数并使用所需参数来启动训练，如下所示。这些参数是随机选择的（没有进行`Grid
    Search`）。可以使用`Grid Search`或`RandomizedSearch`来确定最佳参数并优化算法：
- en: '[PRE18]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The model training is done using the `fit(X_train, y_train)` function by passing
    the training data to it. The training dataset and parameters are logged to Azure
    ML and MLflow experiments as follows:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练是通过传递训练数据到`fit(X_train, y_train)`函数来完成的。训练数据集和参数如下记录到Azure ML和MLflow实验中：
- en: '[PRE19]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After training, the output is shown as follows:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练后，输出如下所示：
- en: '[PRE20]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This is the expected result when finishing training the Random Forest model.
    With this, you have successfully finished training the Random Forest model and,
    in total, two ML models: the SVM classifier and the Random Forest classifier.'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是完成随机森林模型训练后的预期结果。通过这种方式，你已经成功完成了随机森林模型的训练，总共训练了两个机器学习模型：SVM分类器和随机森林分类器。
- en: After training, it is vital to test the performance of the model in terms of
    accuracy and other metrics to know whether the model is fit enough for the production
    or testing environment.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练后，从准确度和其他指标方面测试模型性能至关重要，以了解模型是否足够适合生产或测试环境。
- en: Next, we will test the performance of the trained models on the test data that
    we split before training the models.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将测试在训练模型之前分割的测试数据的训练模型的性能。
- en: Model testing and defining metrics
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型测试和定义指标
- en: In this step, we evaluate the trained model performance on a separate set of
    data points, named test data (which was split and versioned earlier, in the data
    ingestion step). The inference of the trained model is evaluated according to
    the selected metrics as per the use case. The output of this step is a report
    on the trained model performance.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们将评估训练好的模型在单独的数据点集上的性能，这些数据点被称为测试数据（在数据摄入步骤中提前分割和版本化）。根据用例选择的指标评估训练模型的推断。这一步的输出是关于训练模型性能的报告。
- en: 'To gain a comprehensive analysis of the model performance, we will measure
    the accuracy, precision, recall, and f-score. This is what they mean in practice
    in the context of the business problem:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面分析模型性能，我们将测量准确率、精确率、召回率和 F 分数。这在业务问题背景下的实际含义如下：
- en: '**Accuracy**: Number of correct predictions by the total number of predictions
    of data test samples.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确率**：正确预测的数据测试样本总数与预测总数之比。'
- en: '**Precision**: Precision measures the proportion of positives that were correctly
    predicted as positive. *Precision = True Positives / (True Positives + False Positives)*'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确率**：精确率衡量的是正确预测为正例的正例的比例。*精确率 = 真正例 / (真正例 + 假正例)*'
- en: '**Recall**: Recall measures the proportion of actual positives that were identified
    correctly. *Recall = True Positives / (True Positives + False Negatives)*'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率**：召回率衡量的是正确识别的实际正例的比例。*召回率 = 真正例 / (真正例 + 假负例)*'
- en: '**F-score**: Both precision and recall are taken into account in the calculation
    of the f-score. It is the harmonic mean (average) of precision and recall. *F1
    Score = 2*(Recall * Precision) / (Recall + Precision)*.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F 分数**：在计算 F 分数时，既考虑了精确率也考虑了召回率。它是精确率和召回率的调和平均（平均值）。*F1 Score = 2*(Recall
    * Precision) / (Recall + Precision)*。'
- en: We will measure these metrics for the trained model on the validation dataset.
    Let's see the results for the SVM classifier and the Random Forest classifier.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在验证数据集上测量这些指标。让我们看看 SVM 分类器和随机森林分类器的结果。
- en: Testing the SVM classifier
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试 SVM 分类器
- en: Using `sklearn.metrics`, we calculate the `accuracy`, `f1_score`, `precision`,
    and `recall` for the model performance on test data samples and log them to the
    Azure ML workspace and MLflow experiments using the `run.log()` function as follows.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `sklearn.metrics`，我们计算模型在测试数据样本上的性能指标 `accuracy`、`f1_score`、`precision` 和
    `recall`，并使用 `run.log()` 函数将它们记录到 Azure ML 工作区和 MLflow 实验，如下所示。
- en: 'From `sklearn.metrics`, import `accuracy_score`, `f1_score`, `precision_score`,
    and `recall_score`:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 从 `sklearn.metrics` 中导入 `accuracy_score`、`f1_score`、`precision_score` 和 `recall_score`：
- en: '[PRE21]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The results of the test data metrics are logged in the Azure ML workspace as
    per the experiment. You can read these logs later after registering the model
    (we will register the model in *Registering models and production artifacts*).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 根据实验，测试数据指标的输出已记录在 Azure ML 工作区。您可以在注册模型（我们将在 *注册模型和生产工件* 中注册模型）后稍后读取这些日志。
- en: Testing the Random Forest classifier
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试随机森林分类器
- en: 'Similar to what we did for the SVM classifier model, using `sklearn.metrics`
    we calculate the `accuracy`, `f1_score`, `precision`, and `recall`:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们为 SVM 分类器模型所做的工作类似，使用 `sklearn.metrics` 我们计算 `accuracy`、`f1_score`、`precision`
    和 `recall`：
- en: '[PRE22]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The output of the model performance metrics on test data samples are logged
    to the Azure ML workspace and MLflow experiments using the `run.log()` function.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `run.log()` 函数，将模型在测试数据样本上的性能指标输出记录到 Azure ML 工作区和 MLflow 实验。
- en: Model packaging
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型打包
- en: After the trained model has been tested in the previous step, the model can
    be serialized into a file to be exported to the test or the production environment.
    Serialized files come with compatibility challenges, such as model interoperability,
    if not done right. Model interoperability is a challenge, especially when models
    are trained using different frameworks. For example, if model 1 is trained using
    `sklearn` and model 2 is trained using TensorFlow, then model 1 cannot be imported
    or exported using TensorFlow for further model fine-tuning or model inference.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一步测试了训练好的模型之后，可以将模型序列化为文件以导出到测试或生产环境。序列化文件可能会遇到兼容性挑战，例如模型互操作性，如果操作不当。模型互操作性是一个挑战，尤其是在使用不同框架训练模型时。例如，如果模型
    1 使用 `sklearn` 训练，而模型 2 使用 TensorFlow 训练，那么模型 1 就不能使用 TensorFlow 导入或导出以进行进一步的模型微调或模型推理。
- en: To avoid this problem, ONNX offers an open standard for model interoperability.
    ONNX stands for Open Neural Network Exchange. It provides a serialization standard
    for importing and exporting models. We will use the ONNX format to serialize the
    models to avoid compatibility and interoperability issues.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这个问题，ONNX 提供了一个模型互操作性的开放标准。ONNX 代表 Open Neural Network Exchange。它为导入和导出模型提供了一个序列化标准。我们将使用
    ONNX 格式序列化模型，以避免兼容性和互操作性问题的出现。
- en: 'Using ONNX, the trained model is serialized using the `skl2onnx` library. The
    model is serialized as the file `svc.onnx` for further exporting and importing
    of the model into test and production environments:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ONNX，通过 `skl2onnx` 库将训练好的模型序列化。模型以 `svc.onnx` 文件的形式序列化，以便进一步将模型导出和导入到测试和生产环境：
- en: '[PRE23]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output of this code is a serialized `svc.onnx` file. Similarly, using ONNX,
    we will convert the Random Forest model into a serialized file named `rf.onnx`
    for further exporting and importing of the model into test and production environments:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码的输出是一个序列化的 `svc.onnx` 文件。同样，使用 ONNX，我们将随机森林模型转换为名为 `rf.onnx` 的序列化文件，以便进一步将模型导出和导入到测试和生产环境：
- en: '[PRE24]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The output of this code is a serialized `rf.onnx` file. Next, we will register
    these serialized models to the model registry.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码的输出是一个序列化的 `rf.onnx` 文件。接下来，我们将这些序列化模型注册到模型注册表中。
- en: Registering models and production artifacts
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注册模型和生产工件
- en: In this step, the model that has been serialized or containerized in the previous
    step is registered and stored in the model registry. A registered model is compiled
    as a logical container for one or more files that function as a model. For instance,
    a model made up of multiple files can be registered as a single model in the model
    registry. By downloading the registered model, all the files can be received.
    The registered model can be deployed and used for inference on demand.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，之前步骤中已序列化或容器化的模型被注册并存储在模型注册表中。一个注册的模型被编译为一个逻辑容器，用于一个或多个作为模型功能使用的文件。例如，由多个文件组成的模型可以注册为模型注册表中的单个模型。通过下载注册的模型，可以接收所有文件。注册的模型可以按需部署和使用进行推理。
- en: 'Let''s register our serialized models in the previous section by using the
    `model .register()` function from the Azure ML SDK. By using this function, the
    serialized ONNX file is registered to the workspace for further use and deploying
    to the test and production environment. Let''s register the serialized SVM classifier
    model (`svc.onnx`):'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 Azure ML SDK 中的 `model.register()` 函数，将上一节中序列化的模型注册。通过使用此函数，序列化的 ONNX
    文件被注册到工作区，以便进一步使用和部署到测试和生产环境。现在，让我们注册序列化的 SVM 分类器模型（`svc.onnx`）：
- en: '[PRE25]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The model is registered by naming and tagging the model as per the need. We
    can confirm the successful registering of the model by checking the registered
    model name and version. The output will reflect the model name you used when registering
    (for example, `support-vector-classifier`) and will show the model version as
    `1`. Likewise, let''s register the serialized Random Forest classifier model (`rf.onnx`):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 模型通过命名和标记模型以符合需求进行注册。我们可以通过检查注册的模型名称和版本来确认模型注册成功。输出将反映您在注册时使用的模型名称（例如，`support-vector-classifier`）并显示模型版本为
    `1`。同样，让我们注册序列化的随机森林分类器模型（`rf.onnx`）：
- en: '[PRE26]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'After successful registering of the model, the output of the `print` function
    will reflect the model name you used while registering (`random-forest-classifier`)
    and will show the model version as `1`. Lastly, we will register production artifacts
    for inference. Now you can see both models in the **Models** section of the Azure
    ML workspace as shown in *Figure 4.8*:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 模型注册成功后，`print` 函数的输出将反映您在注册时使用的模型名称（例如，`random-forest-classifier`）并显示模型版本为
    `1`。最后，我们将注册用于推理的生产工件。现在，您可以在 Azure ML 工作区的 **模型** 部分中看到这两个模型，如图 4.8 所示：
- en: '![Figure 4.9 – Registered SVM model (with test metrics)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.9 – 已注册的 SVM 模型（含测试指标）'
- en: '](img/B16572_04_008.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16572_04_008.jpg)'
- en: Figure 4.9 – Registered SVM model (with test metrics)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – 已注册的 SVM 模型（含测试指标）
- en: This way, you can visualize and analyze your training and testing logs for each
    model trained in the Azure ML workspace. It offers a bird's-eye view of training
    and testing the model while enabling traceability for registered models.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，您可以可视化并分析在 Azure ML 工作区中训练和测试的每个模型的训练和测试日志。它提供了对模型训练和测试的鸟瞰图，同时为注册的模型提供了可追溯性。
- en: Registering production artifacts
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注册生产工件
- en: For model inference in real time, a scalar is needed in order to scale the incoming
    data on the scale at which the data was scaled for ML training. We will use the
    same scaler function used for `scaling X_train` using `sc.fit_transform(X_train)`
    and serialize this variable into a `pickle` file. Lastly, we register this `pickle`
    file to the workspace for further retrieval and usage as needed (especially for
    model inference in the test and production environment). Using `pickle`, write
    the scaler variable `sc` into a `pickle` file using the `pickle.dump()` function
    as follows.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在实时模型推理中缩放输入数据，需要一个标量来将数据缩放到与ML训练时数据缩放相同的尺度。我们将使用用于`scaling X_train`的相同缩放函数，并将这个变量序列化到一个`pickle`文件中。最后，我们将这个`pickle`文件注册到工作区，以便后续检索和使用（特别是对于测试和生产环境中的模型推理）。使用`pickle`，可以通过以下方式使用`pickle.dump()`函数将缩放变量`sc`写入一个`pickle`文件。
- en: 'Import `pickle` with `open(''./outputs/scaler.pkl'', ''wb'') as scaler_pkl`:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`import pickle as open('./outputs/scaler.pkl', 'wb') as scaler_pkl`导入`pickle`：
- en: '[PRE27]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output of the code will save a serialized `pickle` file for the scaler
    with the filename `scaler.pkl`. Next, we will register this file to the model
    registry to later download and deploy together with our models for inference.
    The scaler is registered using the `model .register()` function as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的输出将保存一个名为`scaler.pkl`的序列化`pickle`文件，用于缩放器。接下来，我们将此文件注册到模型注册表中，以便以后与我们的模型一起下载和部署以进行推理。缩放器是通过以下`model.register()`函数注册的：
- en: '[PRE28]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Upon saving and registering the scaler object, a registered object can be found
    on the Azure ML workspace. Likewise, registered models can be tracked, as shown
    in *Figure 4.8*:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在保存和注册缩放对象后，可以在Azure ML工作区中找到已注册的对象。同样，已注册的模型也可以跟踪，如图*图4.8*所示：
- en: '![Figure 4.10 – Registered models'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.10 – 已注册的模型'
- en: '](img/B16572_04_009.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16572_04_009.jpg](img/B16572_04_009.jpg)'
- en: Figure 4.10 – Registered models
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.10 – 已注册的模型
- en: Congratulations! Both the SVM classifier and Random Forest classifier, along
    with the serialized scaler, are registered in the model registry. These models
    can be downloaded and deployed later. This brings us to the successful implementation
    of the ML pipeline!
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！SVM分类器和随机森林分类器，以及序列化的缩放器，都已注册到模型注册表中。这些模型可以在以后下载和部署。这标志着ML管道的成功实施！
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we went through the theory of ML pipelines and practiced them
    by building ML pipelines for a business problem. We set up tools, resources, and
    the development environment for training these ML models. We started with the
    data ingestion step, followed by the model training step, testing step, and packaging
    step, and finally, we completed the registering step. Congrats! So far, you have
    implemented a critical building block of the MLOps workflow.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了ML管道的理论，并通过构建用于商业问题的ML管道来实践。我们为训练这些ML模型设置了工具、资源和开发环境。我们从数据摄取步骤开始，接着是模型训练步骤、测试步骤、打包步骤，最后完成了注册步骤。恭喜！到目前为止，你已经实现了MLOps工作流程的关键构建块。
- en: In the next chapter, we will look into evaluating and packaging production models.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨评估和打包生产模型。
