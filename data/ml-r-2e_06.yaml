- en: Chapter 6. Forecasting Numeric Data – Regression Methods
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 数值数据预测——回归方法
- en: Mathematical relationships help us to understand many aspects of everyday life.
    For example, body weight is a function of one's calorie intake, income is often
    related to education and job experience, and poll numbers help us estimate a presidential
    candidate's odds of being re-elected.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数学关系帮助我们理解日常生活中的许多方面。例如，体重是摄入卡路里的函数，收入通常与教育和工作经验有关，民意调查数据帮助我们估计总统候选人连任的几率。
- en: When such relationships are expressed with exact numbers, we gain additional
    clarity. For example, an additional 250 kilocalories consumed daily may result
    in nearly a kilogram of weight gain per month; each year of job experience may
    be worth an additional $1,000 in yearly salary; and a president is more likely
    to be re-elected when the economy is strong. Obviously, these equations do not
    perfectly fit every situation, but we expect that they are reasonably correct,
    on average.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当这些关系用精确的数字表示时，我们获得了更多的清晰度。例如，每天额外摄入250千卡的热量可能导致每月增加近1公斤体重；每增加一年的工作经验，年薪可能增加$1,000；而在经济强劲时，总统连任的可能性更大。显然，这些方程式并不完美适用于每种情况，但我们可以预期它们在平均情况下是相对正确的。
- en: 'This chapter extends our machine learning toolkit by going beyond the classification
    methods covered previously and introducing techniques for estimating relationships
    among numeric data. While examining several real-world numeric prediction tasks,
    you will learn:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章通过超越前面所述的分类方法，引入了估计数值数据之间关系的技术，从而扩展了我们的机器学习工具包。在研究几个现实世界的数值预测任务时，您将学习到：
- en: The basic statistical principles used in regression, a technique that models
    the size and the strength of numeric relationships
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归中使用的基本统计原理，一种模拟数值关系的大小和强度的技术
- en: How to prepare data for regression analysis, and estimate and interpret a regression
    model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何准备回归分析的数据，并估算和解读回归模型
- en: A pair of hybrid techniques known as regression trees and model trees, which
    adapt decision tree classifiers for numeric prediction tasks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一对混合技术，称为回归树和模型树，它们将决策树分类器适应于数值预测任务
- en: Based on a large body of work in the field of statistics, the methods used in
    this chapter are a bit heavier on math than those covered previously, but don't
    worry! Even if your algebra skills are a bit rusty, R takes care of the heavy
    lifting.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 基于统计学领域的大量研究，本章所用的方法在数学方面略重于之前所讲的内容，但别担心！即使你的代数技能有些生疏，R语言会帮你完成繁重的计算。
- en: Understanding regression
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解回归
- en: Regression is concerned with specifying the relationship between a single numeric
    **dependent variable** (the value to be predicted) and one or more numeric **independent
    variables** (the predictors). As the name implies, the dependent variable depends
    upon the value of the independent variable or variables. The simplest forms of
    regression assume that the relationship between the independent and dependent
    variables follows a straight line.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析关注的是指定单一数值**因变量**（即要预测的值）与一个或多个数值**自变量**（即预测变量）之间的关系。顾名思义，因变量取决于自变量的值。回归的最简单形式假设自变量与因变量之间的关系呈直线。
- en: Note
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The origin of the term "regression" to describe the process of fitting lines
    to data is rooted in a study of genetics by Sir Francis Galton in the late 19th
    century. He discovered that fathers who were extremely short or extremely tall
    tended to have sons whose heights were closer to the average height. He called
    this phenomenon "regression to the mean".
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: “回归”一词用于描述将线条拟合到数据的过程，源自19世纪末弗朗西斯·高尔顿爵士在遗传学研究中的发现。他发现，极端矮小或极端高大的父亲，往往有身高更接近平均值的儿子。他将这一现象称为“回归到均值”。
- en: You might recall from basic algebra that lines can be defined in a **slope-intercept
    form** similar to *y = a + bx*. In this form, the letter *y* indicates the dependent
    variable and *x* indicates the independent variable. The **slope** term *b* specifies
    how much the line rises for each increase in *x*. Positive values define lines
    that slope upward while negative values define lines that slope downward. The
    term *a* is known as the **intercept** because it specifies the point where the
    line crosses, or intercepts, the vertical *y* axis. It indicates the value of
    *y* when *x = 0*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得从基础代数中，直线可以用**斜率-截距形式**来定义，类似于 *y = a + bx*。在这种形式中，字母*y*表示因变量，*x*表示自变量。**斜率**项*b*指定了直线在*x*每增加一个单位时上升的量。正值定义了向上倾斜的直线，而负值则定义了向下倾斜的直线。项*a*被称为**截距**，因为它指定了直线交叉或截取垂直*y*轴的点。它表示当*x
    = 0*时*y*的值。
- en: '![Understanding regression](img/B03905_06_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![理解回归](img/B03905_06_01.jpg)'
- en: Regression equations model data using a similar slope-intercept format. The
    machine's job is to identify values of *a* and *b* so that the specified line
    is best able to relate the supplied *x* values to the values of *y*. There may
    not always be a single function that perfectly relates the values, so the machine
    must also have some way to quantify the margin of error. We'll discuss this in
    depth shortly.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 回归方程使用类似于斜率-截距形式的数据模型。机器的任务是确定* a *和* b *的值，使得指定的直线能最好地将提供的*x*值与*y*值关联起来。可能并不总是存在一个完美关联这些值的单一函数，因此机器还必须有某种方式来量化误差范围。我们稍后会深入讨论这一点。
- en: 'Regression analysis is commonly used for modeling complex relationships among
    data elements, estimating the impact of a treatment on an outcome, and extrapolating
    into the future. Although it can be applied to nearly any task, some specific
    use cases include:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析通常用于建模数据元素之间的复杂关系，估计处理对结果的影响，并进行未来的外推。尽管它可以应用于几乎任何任务，但一些特定的应用案例包括：
- en: Examining how populations and individuals vary by their measured characteristics,
    for use in scientific research across fields as diverse as economics, sociology,
    psychology, physics, and ecology
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检验群体和个体在其测量特征上的变异性，广泛应用于经济学、社会学、心理学、物理学和生态学等多个学科的科学研究。
- en: Quantifying the causal relationship between an event and the response, such
    as those in clinical drug trials, engineering safety tests, or marketing research
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定量分析事件与响应之间的因果关系，例如临床药物试验、工程安全测试或市场调研中的因果关系。
- en: Identifying patterns that can be used to forecast future behavior given known
    criteria, such as predicting insurance claims, natural disaster damage, election
    results, and crime rates
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别可以用来根据已知标准预测未来行为的模式，如预测保险理赔、自然灾害损失、选举结果和犯罪率等。
- en: Regression methods are also used for **statistical hypothesis testing**, which
    determines whether a premise is likely to be true or false in light of the observed
    data. The regression model's estimates of the strength and consistency of a relationship
    provide information that can be used to assess whether the observations are due
    to chance alone.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 回归方法也用于**统计假设检验**，该方法通过观察到的数据来判断一个前提是否可能为真或为假。回归模型对关系的强度和一致性的估计提供了可以用来评估观察结果是否仅仅由偶然因素造成的信息。
- en: Note
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Hypothesis testing is extremely nuanced and falls outside the scope of machine
    learning. If you are interested in this topic, an introductory statistics textbook
    is a good place to get started.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 假设检验是极其复杂的，超出了机器学习的范畴。如果你对这个话题感兴趣，入门级统计学教材是一个很好的起点。
- en: Regression analysis is not synonymous with a single algorithm. Rather, it is
    an umbrella for a large number of methods that can be adapted to nearly any machine
    learning task. If you were limited to choosing only a single method, regression
    would be a good choice. One could devote an entire career to nothing else and
    perhaps still have much to learn.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析并不等同于单一算法。相反，它是一个涵盖大量方法的总称，这些方法可以适应几乎任何机器学习任务。如果你只能选择一种方法，回归方法是一个不错的选择。有人可以将一生献给这一领域，或许仍然有许多要学习的内容。
- en: In this chapter, we'll focus only on the most basic **linear regression** models—those
    that use straight lines. When there is only a single independent variable it is
    known as **simple linear regression**. In the case of two or more independent
    variables, this is known as **multiple linear regression**, or simply "multiple
    regression". Both of these techniques assume that the dependent variable is measured
    on a continuous scale.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将仅关注最基本的**线性回归**模型——那些使用直线的模型。当只有一个自变量时，称为**简单线性回归**。当有两个或更多自变量时，称为**多元线性回归**，或简称为“多元回归”。这两种技术都假设因变量是连续量度的。
- en: Regression can also be used for other types of dependent variables and even
    for some classification tasks. For instance, **logistic regression** is used to
    model a binary categorical outcome, while **Poisson regression**—named after the
    French mathematician Siméon Poisson—models integer count data. The method known
    as **multinomial logistic regression** models a categorical outcome; thus, it
    can be used for classification. The same basic principles apply across all the
    regression methods, so after understanding the linear case, it is fairly simple
    to learn the others.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 回归还可以用于其他类型的因变量，甚至一些分类任务。例如，**逻辑回归**用于建模二元分类结果，而**泊松回归**——以法国数学家西门·泊松命名——用于建模整数计数数据。被称为**多项式逻辑回归**的方法则用于建模分类结果，因此它可以用于分类。所有回归方法遵循相同的基本原理，因此在理解了线性回归后，学习其他方法相对简单。
- en: Tip
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Many of the specialized regression methods fall into a class of **Generalized
    Linear Models** (**GLM**). Using a GLM, linear models can be generalized to other
    patterns via the use of a **link function**, which specifies more complex forms
    for the relationship between *x* and *y*. This allows regression to be applied
    to almost any type of data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 许多专业的回归方法属于**广义线性模型**（**GLM**）类。使用GLM时，线性模型可以通过使用**链接函数**来推广到其他模式，这些函数为*x*和*y*之间的关系指定了更复杂的形式。这样，回归就可以应用于几乎任何类型的数据。
- en: We'll begin with the basic case of simple linear regression. Despite the name,
    this method is not too simple to address complex problems. In the next section,
    we'll see how the use of a simple linear regression model might have averted a
    tragic engineering disaster.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从简单线性回归的基本情况开始。尽管名字中有“简单”二字，这种方法并不简单，仍能解决复杂问题。在下一节中，我们将看到如何通过使用简单线性回归模型来避免一次悲剧性的工程灾难。
- en: Simple linear regression
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单线性回归
- en: On January 28, 1986, seven crew members of the United States space shuttle *Challenger*
    were killed when a rocket booster failed, causing a catastrophic disintegration.
    In the aftermath, experts focused on the launch temperature as a potential culprit.
    The rubber O-rings responsible for sealing the rocket joints had never been tested
    below 40ºF (4ºC) and the weather on the launch day was unusually cold and below
    freezing.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 1986年1月28日，美国航天飞机*挑战者号*的七名机组成员在火箭助推器发生故障后丧生，导致灾难性的解体。在事后，专家们将发射温度视为潜在的罪魁祸首。负责密封火箭接头的橡胶O型环从未在40ºF（4ºC）以下的温度下进行过测试，而发射当天的天气异常寒冷，气温低于冰点。
- en: With the benefit of hindsight, the accident has been a case study for the importance
    of data analysis and visualization. Although it is unclear what information was
    available to the rocket engineers and decision makers leading up to the launch,
    it is undeniable that better data, utilized carefully, might very well have averted
    this disaster.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 从后见之明来看，这起事故成为了数据分析和可视化重要性的案例研究。尽管目前不清楚火箭工程师和决策者在发射前掌握了哪些信息，但不可否认的是，如果有更好的数据并加以谨慎使用，很可能能够避免这场灾难。
- en: Note
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'This section''s analysis is based on data presented in Dalal SR, Fowlkes EB,
    Hoadley B. *Risk analysis of the space shuttle: pre-Challenger prediction of failure*.
    Journal of the American Statistical Association. 1989; 84:945-957\. For one perspective
    on how data may have changed the result, see Tufte ER. *Visual Explanations: Images
    and Quantities, Evidence and Narrative*. Graphics Press; 1997\. For a counterpoint,
    see Robison W, Boisioly R, Hoeker D, Young, S. *Representation and misrepresentation:
    Tufte and the Morton Thiokol engineers on the Challenger*. Science and Engineering
    Ethics. 2002; 8:59-81.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 本节分析基于Dalal SR, Fowlkes EB, Hoadley B. *航天飞机的风险分析：挑战者号发射前的故障预测*。美国统计学会学报，1989年；84：945-957。有关数据如何改变结果的一个视角，参见Tufte
    ER. *视觉解释：图像与数量、证据与叙述*。Graphics Press，1997年。一个反观点请参见Robison W, Boisioly R, Hoeker
    D, Young, S. *代表与误代表：Tufte与Morton Thiokol工程师对挑战者号的看法*。科学与工程伦理，2002年；8：59-81。
- en: The rocket engineers almost certainly knew that cold temperatures could make
    the components more brittle and less able to seal properly, which would result
    in a higher chance of a dangerous fuel leak. However, given the political pressure
    to continue with the launch, they needed data to support this hypothesis. A regression
    model that demonstrated a link between temperature and O-ring failure, and could
    forecast the chance of failure given the expected temperature at launch, might
    have been very helpful.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 火箭工程师几乎肯定知道，低温可能使部件变脆，无法正确密封，从而导致更高的危险燃料泄漏的可能性。然而，考虑到继续发射的政治压力，他们需要数据来支持这一假设。一个能够展示温度与O型环故障之间关联的回归模型，并能够根据预期的发射温度预测故障的可能性，可能会非常有帮助。
- en: To build the regression model, scientists might have used the data on launch
    temperature and component distresses from 23 previous successful shuttle launches.
    A component distress indicates one of the two types of problems. The first problem,
    called erosion, occurs when excessive heat burns up the O-ring. The second problem,
    called blowby, occurs when hot gases leak through or "blow by" a poorly sealed
    O-ring. Since the shuttle has a total of six primary O-rings, up to six distresses
    can occur per flight. Though the rocket can survive one or more distress events,
    or fail with as few as one, each additional distress increases the probability
    of a catastrophic failure.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建回归模型，科学家们可能使用了来自23次成功航天飞机发射的数据，包括发射温度和部件故障数据。部件故障表示两种问题之一。第一个问题叫做侵蚀，当过热烧坏O型环时就会发生这种情况。第二个问题叫做泄漏，当热气体通过或“冲过”密封不良的O型环时，就会发生泄漏。由于航天飞机总共有六个主要O型环，因此每次飞行最多可能发生六个故障事件。尽管火箭可以在发生一个或多个故障事件的情况下生还，或者在发生一个故障事件的情况下就失败，但每增加一个故障事件，灾难性失败的概率就会增加。
- en: 'The following scatterplot shows a plot of primary O-ring distresses detected
    for the previous 23 launches, as compared to the temperature at launch:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下散点图展示了前23次发射中检测到的主要O型环故障与发射温度的关系：
- en: '![Simple linear regression](img/B03905_06_02.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![简单线性回归](img/B03905_06_02.jpg)'
- en: Examining the plot, there is an apparent trend. Launches occurring at higher
    temperatures tend to have fewer O-ring distress events.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 观察图表，可以发现一个明显的趋势。发生在较高温度下的发射，O型环故障事件较少。
- en: Additionally, the coldest launch (53º F) had two distress events, a level which
    had only been reached in one other launch. With this information at hand, the
    fact that the Challenger was scheduled to launch at a temperature over 20 degrees
    colder seems concerning. But exactly how concerned should we be? To answer this
    question, we can turn to simple linear regression.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，最冷的发射温度（53º F）发生了两次故障事件，这是在另外一次发射中才达到的水平。掌握了这些信息后，可以看出挑战者号计划在比这低20多度的温度下发射，这似乎令人担忧。那么我们到底应该多担心呢？为了回答这个问题，我们可以借助简单线性回归。
- en: 'A simple linear regression model defines the relationship between a dependent
    variable and a single independent predictor variable using a line defined by an
    equation in the following form:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 简单线性回归模型通过使用一个由方程定义的直线，定义了一个因变量与单一自变量之间的关系，方程形式如下：
- en: '![Simple linear regression](img/B03905_06_03.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![简单线性回归](img/B03905_06_03.jpg)'
- en: Don't be alarmed by the Greek characters, this equation can still be understood
    using the slope-intercept form described previously. The intercept, *α* (alpha),
    describes where the line crosses the *y* axis, while the slope, *β* (beta), describes
    the change in *y* given an increase of *x*. For the shuttle launch data, the slope
    would tell us the expected reduction in the number of O-ring failures for each
    degree the launch temperature increases.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 不要被希腊字符吓到，这个方程仍然可以通过之前描述的斜截式形式来理解。截距，*α*（阿尔法），描述了直线与*y*轴的交点，而斜率，*β*（贝塔），描述了当*x*增加时，*y*的变化。对于航天飞机发射数据，斜率告诉我们每升高1度发射温度，O型环故障的预期减少量。
- en: Tip
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Greek characters are often used in the field of statistics to indicate variables
    that are parameters of a statistical function. Therefore, performing a regression
    analysis involves finding **parameter estimates** for *α* and *β*. The parameter
    estimates for alpha and beta are often denoted using *a* and *b*, although you
    may find that some of this terminology and notation is used interchangeably.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 希腊字符常常在统计学领域中用来表示统计函数的参数变量。因此，进行回归分析时，需要找到**参数估计值**，即*α*和*β*的估计值。阿尔法和贝塔的参数估计值通常用*a*和*b*表示，尽管你可能会发现这些术语和符号有时可以互换使用。
- en: 'Suppose we know that the estimated regression parameters in the equation for
    the shuttle launch data are: *a = 3.70* and *b = -0.048*.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们知道航天飞机发射数据的回归方程中估计的回归参数为：*a = 3.70*和*b = -0.048*。
- en: 'Hence, the full linear equation is *y = 3.70 – 0.048x*. Ignoring for a moment
    how these numbers were obtained, we can plot the line on the scatterplot like
    this:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，完整的线性方程是*y = 3.70 – 0.048x*。暂时忽略这些数字是如何得出的，我们可以像这样将直线绘制在散点图上：
- en: '![Simple linear regression](img/B03905_06_04.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![简单线性回归](img/B03905_06_04.jpg)'
- en: As the line shows, at 60 degrees Fahrenheit, we predict just under one O-ring
    distress. At 70 degrees Fahrenheit, we expect around 0.3 failures. If we extrapolate
    our model, all the way to 31 degrees—the forecasted temperature for the Challenger
    launch—we would expect about *3.70 - 0.048 * 31 = 2.21* O-ring distress events.
    Assuming that each O-ring failure is equally likely to cause a catastrophic fuel
    leak means that the Challenger launch at 31 degrees was nearly three times more
    risky than the typical launch at 60 degrees, and over eight times more risky than
    a launch at 70 degrees.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，在华氏60度时，我们预测O型环故障略低于1个；在华氏70度时，我们预计约有0.3个故障。如果我们将模型外推到31度——挑战者号发射时的预测温度——我们预计将有大约*3.70
    - 0.048 * 31 = 2.21*个O型环故障事件。假设每个O型环故障都有相同的概率导致灾难性的燃料泄漏，那么在31度时，挑战者号发射的风险几乎是60度典型发射的三倍，是70度发射的八倍以上。
- en: Notice that the line doesn't pass through each data point exactly. Instead,
    it cuts through the data somewhat evenly, with some predictions lower or higher
    than the line. In the next section, we will learn about why this particular line
    was chosen.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，直线并不是精确通过每一个数据点的。相反，它大致穿过数据，部分预测值高于直线，部分低于直线。在下一部分中，我们将学习为什么选择了这条特定的直线。
- en: Ordinary least squares estimation
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 普通最小二乘估计
- en: 'In order to determine the optimal estimates of *α* and *β*, an estimation method
    known as **Ordinary Least Squares** (**OLS**) was used. In OLS regression, the
    slope and intercept are chosen so that they minimize the sum of the squared errors,
    that is, the vertical distance between the predicted *y* value and the actual
    *y* value. These errors are known as **residuals**, and are illustrated for several
    points in the following diagram:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定*α*和*β*的最优估计值，使用了一种叫做**普通最小二乘法**（**OLS**）的估计方法。在OLS回归中，选择的斜率和截距是为了最小化平方误差的和，即预测的*y*值与实际的*y*值之间的垂直距离。这些误差被称为**残差**，并在以下图示中为若干点进行了说明：
- en: '![Ordinary least squares estimation](img/B03905_06_05.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![普通最小二乘估计](img/B03905_06_05.jpg)'
- en: 'In mathematical terms, the goal of OLS regression can be expressed as the task
    of minimizing the following equation:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 用数学术语表达，OLS回归的目标可以表示为最小化以下方程：
- en: '![Ordinary least squares estimation](img/B03905_06_06.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![普通最小二乘估计](img/B03905_06_06.jpg)'
- en: In plain language, this equation defines *e* (the error) as the difference between
    the actual *y* value and the predicted *y* value. The error values are squared
    and summed across all the points in the data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 用通俗的话来说，这个方程将*e*（误差）定义为实际的*y*值与预测的*y*值之间的差异。误差值被平方并在所有数据点上求和。
- en: Tip
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: The caret character (`^`) above the *y* term is a commonly used feature of statistical
    notation. It indicates that the term is an estimate for the true *y* value. This
    is referred to as the *y*-hat, and is pronounced exactly like the hat you'd wear
    on your head.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 位于* y *项上方的插入符号（`^`）是统计符号中常用的功能。它表示该项是对真实* y *值的估计。这被称为* y *帽，发音就像你头上戴的帽子。
- en: 'The solution for *a* depends on the value of *b*. It can be obtained using
    the following formula:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '* a *的解依赖于* b *的值。可以使用以下公式来获得：'
- en: '![Ordinary least squares estimation](img/B03905_06_07.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![普通最小二乘估计](img/B03905_06_07.jpg)'
- en: Tip
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: To understand these equations, you'll need to know another bit of statistical
    notation. The horizontal bar appearing over the *x* and *y* terms indicates the
    mean value of *x* or *y*. This is referred to as the *x*-bar or *y*-bar, and is
    pronounced just like the establishment you'd go to for an alcoholic drink.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这些方程式，您需要了解另一个统计符号。出现在* x *和* y *项上方的横杠表示* x *或* y *的平均值。这被称为* x *横杠或* y
    *横杠，发音就像你去喝酒的地方。
- en: 'Though the proof is beyond the scope of this book, it can be shown using calculus
    that the value of *b* that results in the minimum squared error is:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管证明超出了本书的范围，但可以使用微积分来证明，导致最小平方误差的* b *值为：
- en: '![Ordinary least squares estimation](img/B03905_06_08.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![普通最小二乘估计](img/B03905_06_08.jpg)'
- en: 'If we break this equation apart into its component pieces, we can simplify
    it a bit. The denominator for *b* should look familiar; it is very similar to
    the variance of *x*, which is denoted as *Var(x)*. As we learned in [Chapter 2](ch02.html
    "Chapter 2. Managing and Understanding Data"), *Managing and Understanding Data*,
    the variance involves finding the average squared deviation from the mean of *x*.
    This can be expressed as:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这个方程拆解成其组成部分，我们可以稍微简化它。* b *的分母应该看起来很熟悉；它非常类似于* x *的方差，表示为* Var(x)*。正如我们在[第2章](ch02.html
    "第2章 管理与理解数据")《管理与理解数据》中学到的，方差涉及找到* x *均值的平均平方偏差。可以表示为：
- en: '![Ordinary least squares estimation](img/B03905_06_09.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![普通最小二乘估计](img/B03905_06_09.jpg)'
- en: 'The numerator involves taking the sum of each data point''s deviation from
    the mean *x* value multiplied by that point''s deviation away from the mean *y*
    value. This is similar to the **covariance** function for *x* and *y*, denoted
    as *Cov(x, y)*. The covariance formula is:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 分子涉及将每个数据点从均值* x *值的偏差与该点从均值* y *值的偏差相乘。这类似于* x *和* y *的**协方差**函数，表示为* Cov(x,
    y)*。协方差公式为：
- en: '![Ordinary least squares estimation](img/B03905_06_10.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![普通最小二乘估计](img/B03905_06_10.jpg)'
- en: 'If we divide the covariance function by the variance function, the *n* terms
    get cancelled and we can rewrite the formula for *b* as:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将协方差函数除以方差函数，* n *项将被取消，我们可以将* b *的公式重写为：
- en: '![Ordinary least squares estimation](img/B03905_06_11.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![普通最小二乘估计](img/B03905_06_11.jpg)'
- en: Given this restatement, it is easy to calculate the value of *b* using built-in
    R functions. Let's apply it to the rocket launch data to estimate the regression
    line.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 给定这个重述，通过使用内置的R函数，计算* b *的值变得很容易。让我们将其应用于火箭发射数据，来估算回归线。
- en: Tip
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: If you would like to follow along with these examples, download the `challenger.csv`
    file from the Packt Publishing website and load to a data frame using the `launch
    <- read.csv("challenger.csv")` command.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想跟随这些示例，请从Packt Publishing网站下载`challenger.csv`文件，并使用`launch <- read.csv("challenger.csv")`命令加载到数据框中。
- en: 'Assume that our shuttle launch data is stored in a data frame named `launch`,
    the independent variable *x* is temperature, and the dependent variable *y* is
    `distress_ct`. We can then use R''s `cov()` and `var()` functions to estimate
    *b*:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的航天飞机发射数据存储在一个名为`launch`的数据框中，独立变量* x *是温度，依赖变量* y *是`distress_ct`。然后我们可以使用R的`cov()`和`var()`函数来估算*
    b *：
- en: '[PRE0]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'From here we can estimate *a* using the `mean()` function:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里我们可以使用`mean()`函数估算* a *：
- en: '[PRE1]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Estimating the regression equation by hand is not ideal, so R provides functions
    for performing this calculation automatically. We will use such methods shortly.
    First, we will expand our understanding of regression by learning a method for
    measuring the strength of a linear relationship, and then we will see how linear
    regression can be applied to data having more than one independent variable.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 手动估计回归方程并不理想，因此 R 提供了自动执行此计算的函数。我们将很快使用这些方法。首先，我们将通过学习一种测量线性关系强度的方法来扩展我们对回归的理解，然后我们将看到如何将线性回归应用于包含多个自变量的数据。
- en: Correlations
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关性
- en: The **correlation** between two variables is a number that indicates how closely
    their relationship follows a straight line. Without additional qualification,
    correlation typically refers to **Pearson's correlation coefficient**, which was
    developed by the 20th century mathematician Karl Pearson. The correlation ranges
    between -1 and +1\. The extreme values indicate a perfectly linear relationship,
    while a correlation close to zero indicates the absence of a linear relationship.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关性**是两个变量之间的一个数字，表示它们的关系与一条直线的贴合程度。通常，相关性指的是 **Pearson 相关系数**，它由 20 世纪的数学家
    Karl Pearson 开发。相关性范围在 -1 到 +1 之间。极端值表示完美的线性关系，而接近零的相关性则表示缺乏线性关系。'
- en: 'The following formula defines Pearson''s correlation:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以下公式定义了 Pearson 相关性：
- en: '![Correlations](img/B03905_06_12.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![相关性](img/B03905_06_12.jpg)'
- en: Tip
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: More Greek notation has been introduced here. The first symbol (which looks
    like a lowercase p) is *rho*, and it is used to denote the Pearson correlation
    statistic. The characters that look like q turned sideways are the Greek letter
    *sigma*, and they indicate the standard deviation of *x* or *y*.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里引入了更多的希腊符号。第一个符号（看起来像小写字母 p）是 *rho*，用于表示 Pearson 相关性统计量。那些看起来像横过的 q 字母是希腊字母
    *sigma*，它们表示 *x* 或 *y* 的标准差。
- en: 'Using this formula, we can calculate the correlation between the launch temperature
    and the number of O-ring distress events. Recall that the covariance function
    is `cov()` and the standard deviation function is `sd()`. We''ll store the result
    in `r`, a letter that is commonly used to indicate the estimated correlation:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个公式，我们可以计算发射温度与 O 环密封件故障事件数量之间的相关性。回顾一下，协方差函数是`cov()`，标准差函数是`sd()`。我们将把结果存储在`r`中，这是一个常用于表示估计相关性的字母：
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Alternatively, we can use R''s correlation function, `cor()`:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用 R 的相关性函数`cor()`：
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The correlation between the temperature and the number of distressed O-rings
    is -0.51\. The negative correlation implies that increases in temperature are
    related to decreases in the number of distressed O-rings. To the NASA engineers
    studying the O-ring data, this would have been a very clear indicator that a low
    temperature launch could be problematic. The correlation also tells us about the
    relative strength of the relationship between temperature and O-ring distress.
    Because -0.51 is halfway to the maximum negative correlation of -1, this implies
    that there is a moderately strong negative linear association.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 温度与受损 O 环数量之间的相关性为 -0.51。负相关意味着温度的升高与 O 环受损数量的减少相关联。对于研究 O 环数据的 NASA 工程师来说，这将是一个非常明显的指标，表明低温发射可能会存在问题。相关性还告诉我们温度与
    O 环受损之间关系的相对强度。由于 -0.51 距离最大负相关 -1 还差一半，这意味着它们之间有着适度强的负线性关联。
- en: There are various rules of thumb used to interpret correlation strength. One
    method assigns a status of "weak" to values between 0.1 and 0.3, "moderate" to
    the range of 0.3 to 0.5, and "strong" to values above 0.5 (these also apply to
    similar ranges of negative correlations). However, these thresholds may be too
    lax for some purposes. Often, the correlation must be interpreted in context.
    For data involving human beings, a correlation of 0.5 may be considered extremely
    high, while for data generated by mechanical processes, a correlation of 0.5 may
    be weak.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种经验法则用于解释相关性的强度。一种方法是将 0.1 到 0.3 之间的值标为“弱”，0.3 到 0.5 之间的值标为“中等”，大于 0.5 的值标为“强”（这些也适用于负相关的类似范围）。然而，这些阈值对于某些目的来说可能太宽松了。通常，相关性必须结合上下文进行解释。对于涉及人类的数据，0.5
    的相关性可能被认为是极高的，而对于由机械过程生成的数据，0.5 的相关性可能较弱。
- en: Tip
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: You have probably heard the expression "correlation does not imply causation."
    This is rooted in the fact that a correlation only describes the association between
    a pair of variables, yet there could be other unmeasured explanations. For example,
    there may be a strong association between mortality and time per day spent matching
    movies, but before doctors should start recommending that we all watch more movies,
    we need to rule out another explanation—younger people watch more movies and are
    less likely to die.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听过“相关性不代表因果关系”这一说法。其根源在于，相关性仅描述了两个变量之间的关联，但可能存在其他未测量的解释。例如，死亡率与每天观看电影的时间之间可能有很强的关联，但在医生开始建议我们都多看电影之前，我们需要排除另一种解释——年轻人看更多的电影，并且死亡的可能性较小。
- en: Measuring the correlation between two variables gives us a way to quickly gauge
    the relationships among the independent and dependent variables. This will be
    increasingly important as we start defining the regression models with a larger
    number of predictors.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 衡量两个变量之间的相关性为我们提供了一种快速评估独立变量和依赖变量之间关系的方法。随着我们开始使用更多预测变量定义回归模型，这一点将变得愈加重要。
- en: Multiple linear regression
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多元线性回归
- en: 'Most real-world analyses have more than one independent variable. Therefore,
    it is likely that you will be using **multiple linear regression** for most numeric
    prediction tasks. The strengths and weaknesses of multiple linear regression are
    shown in the following table:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数实际分析都有多个独立变量。因此，你很可能会使用**多元线性回归**来进行大多数数值预测任务。多元线性回归的优缺点见下表：
- en: '| Strengths | Weaknesses |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 优点 | 缺点 |'
- en: '| --- | --- |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '|'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: By far the most common approach for modeling numeric data
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 到目前为止，建模数值数据最常见的方法
- en: Can be adapted to model almost any modeling task
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以适应几乎任何建模任务
- en: Provides estimates of both the strength and size of the relationships among
    features and the outcome
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供特征与结果之间关系的强度和大小的估计
- en: '|'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Makes strong assumptions about the data
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据做出了强假设
- en: The model's form must be specified by the user in advance
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的形式必须由用户提前指定
- en: Does not handle missing data
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不处理缺失数据
- en: Only works with numeric features, so categorical data requires extra processing
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅适用于数值特征，因此分类数据需要额外的处理
- en: Requires some knowledge of statistics to understand the model
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要一定的统计学知识才能理解该模型
- en: '|'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: We can understand multiple regression as an extension of simple linear regression.
    The goal in both cases is similar—find values of beta coefficients that minimize
    the prediction error of a linear equation. The key difference is that there are
    additional terms for additional independent variables.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '我们可以将多元回归理解为简单线性回归的扩展。两者的目标相似——寻找能够最小化线性方程预测误差的β系数值。关键的不同点在于，针对额外的独立变量，有了更多的项。 '
- en: 'Multiple regression equations generally follow the form of the following equation.
    The dependent variable *y* is specified as the sum of an intercept term *α* plus
    the product of the estimated *β* value and the *x* values for each of the *i*
    features. An error term (denoted by the Greek letter *epsilon*) has been added
    here as a reminder that the predictions are not perfect. This represents the **residual**
    term noted previously:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 多元回归方程通常遵循以下方程的形式。依赖变量 *y* 被指定为截距项 *α* 与估计的 *β* 值与每个 *i* 特征的 *x* 值之积的和。这里加入了一个误差项（用希腊字母
    *epsilon* 表示），以提醒我们预测并不完美。这代表了前面提到的**残差**项：
- en: '![Multiple linear regression](img/B03905_06_13.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![多元线性回归](img/B03905_06_13.jpg)'
- en: Let's consider for a moment the interpretation of the estimated regression parameters.
    You will note that in the preceding equation, a coefficient is provided for each
    feature. This allows each feature to have a separate estimated effect on the value
    of *y*. In other words, *y* changes by the amount *β[i]* for each unit increase
    in *x[i]*. The intercept *α* is then the expected value of *y* when the independent
    variables are all zero.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时考虑一下估计的回归参数的解释。你会注意到，在前面的方程中，为每个特征提供了一个系数。这使得每个特征对 *y* 值的影响可以单独估计。换句话说，*y*
    会因每个 *x[i]* 单位增加而改变 *β[i]* 的数量。截距 *α* 则是当所有独立变量为零时 *y* 的期望值。
- en: 'Since the intercept term *α* is really no different than any other regression
    parameter, it is also sometimes denoted as *β[0]* (pronounced beta-naught), as
    shown in the following equation:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 由于截距项*α*与其他任何回归参数并无不同，它有时也被表示为*β[0]*（读作beta零），如以下公式所示：
- en: '![Multiple linear regression](img/B03905_06_14.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![多元线性回归](img/B03905_06_14.jpg)'
- en: 'Just like before, the intercept is unrelated to any of the independent *x*
    variables. However, for reasons that will become clear shortly, it helps to imagine
    *β[0]* as if it were being multiplied by a term *x[0]*, which is a constant with
    the value 1:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 就像之前一样，截距与任何自变量*x*并无直接关系。然而，出于很快会变得清晰的原因，帮助理解的方式是将*β[0]*想象成与一个常数项*x[0]*相乘，其中*x[0]*的值为1：
- en: '![Multiple linear regression](img/B03905_06_15.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![多元线性回归](img/B03905_06_15.jpg)'
- en: 'In order to estimate the values of the regression parameters, each observed
    value of the dependent variable *y* must be related to the observed values of
    the independent *x* variables using the regression equation in the previous form.
    The following figure illustrates this structure:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了估计回归参数的值，每个观测值的因变量*y*必须通过前述形式的回归方程与观测值的自变量*x*相关联。以下图展示了这种结构：
- en: '![Multiple linear regression](img/B03905_06_16.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![多元线性回归](img/B03905_06_16.jpg)'
- en: 'The many rows and columns of data illustrated in the preceding figure can be
    described in a condensed formulation using bold font **matrix notation** to indicate
    that each of the terms represents multiple values:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 前面图示中展示的大量行列数据，可以用粗体字体的**矩阵符号**来简洁地表示，表明每个术语代表多个值：
- en: '![Multiple linear regression](img/B03905_06_17.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![多元线性回归](img/B03905_06_17.jpg)'
- en: The dependent variable is now a vector, **Y**, with a row for every example.
    The independent variables have been combined into a matrix, **X**, with a column
    for each feature plus an additional column of '1' values for the intercept term.
    Each column has a row for every example. The regression coefficients **β** and
    residual errors **ε** are also now vectors.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，因变量是一个向量**Y**，每一行对应一个示例。自变量已经合并成一个矩阵**X**，其中每列对应一个特征，另外还有一列全为'1'的值，代表截距项。每列有一个对应示例的行。回归系数**β**和残差**ε**现在也都是向量。
- en: 'The goal is now to solve for **β**, the vector of regression coefficients that
    minimizes the sum of the squared errors between the predicted and actual **Y**
    values. Finding the optimal solution requires the use of matrix algebra; therefore,
    the derivation deserves more careful attention than can be provided in this text.
    However, if you''re willing to trust the work of others, the best estimate of
    the vector **β** can be computed as:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是解出**β**，即回归系数向量，它最小化预测值与实际**Y**值之间的平方误差和。寻找最优解需要使用矩阵代数；因此，推导过程需要比本书所能提供的更为详细的关注。不过，如果你愿意相信他人的研究，**β**向量的最佳估计可以通过以下方式计算：
- en: '![Multiple linear regression](img/B03905_06_18.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![多元线性回归](img/B03905_06_18.jpg)'
- en: This solution uses a pair of matrix operations—the **T** indicates the **transpose**
    of matrix **X**, while the negative exponent indicates the **matrix inverse**.
    Using R's built-in matrix operations, we can thus implement a simple multiple
    regression learner. Let's apply this formula to the Challenger launch data.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解决方案使用了一对矩阵运算——**T**表示矩阵**X**的**转置**，而负指数表示**矩阵的逆**。使用R的内置矩阵运算，我们可以实现一个简单的多元回归学习器。接下来，我们将这个公式应用于挑战者发射数据。
- en: Tip
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: If you are unfamiliar with the preceding matrix operations, the Wikipedia pages
    for transpose and matrix inverse provide a thorough introduction and are quite
    understandable, even without a strong mathematics background.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对前面的矩阵运算不熟悉，维基百科上关于转置和矩阵逆的页面提供了详细的介绍，即使没有强大的数学背景，也能很好地理解。
- en: 'Using the following code, we can create a basic regression function named `reg()`,
    which takes a parameter `y` and a parameter `x` and returns a vector of estimated
    beta coefficients:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码，我们可以创建一个名为`reg()`的基本回归函数，它接受一个参数`y`和一个参数`x`，并返回一个估计的beta系数向量：
- en: '[PRE4]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `reg()` function created here uses several R commands that we have not
    used previously. First, since we will be using the function with sets of columns
    from a data frame, the `as.matrix()` function is used to convert the data frame
    into matrix form. Next, the `cbind()` function is used to bind an additional column
    onto the `x` matrix; the command `Intercept = 1` instructs R to name the new column
    `Intercept` and to fill the column with repeating 1 values. Then, a number of
    matrix operations are performed on the `x` and `y` objects:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这里创建的 `reg()` 函数使用了我们之前没有用过的几个 R 命令。首先，由于我们将使用该函数处理数据框中的列集，`as.matrix()` 函数用于将数据框转换为矩阵形式。接下来，`cbind()`
    函数用于将一个额外的列绑定到 `x` 矩阵上；命令 `Intercept = 1` 指示 R 将新列命名为 `Intercept` 并用重复的 1 填充该列。然后，对
    `x` 和 `y` 对象执行一系列矩阵操作：
- en: '`solve()` takes the inverse of a matrix'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`solve()` 求解矩阵的逆'
- en: '`t()` is used to transpose a matrix'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t()` 用于转置矩阵'
- en: '`%*%` multiplies two matrices'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`%*%` 用于两个矩阵的乘法'
- en: By combining these as shown, our function will return a vector `b`, which contains
    the estimated parameters for the linear model relating `x` to `y`. The final two
    lines in the function give the `b` vector a name and print the result on screen.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将这些组合在一起，我们的函数将返回一个向量 `b`，其中包含线性模型中与 `x` 相关的估计参数。函数中的最后两行给 `b` 向量命名，并将结果打印到屏幕上。
- en: 'Let''s apply our function to the shuttle launch data. As shown in the following
    code, the dataset includes three features and the distress count (`distress_ct`),
    which is the outcome of interest:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将该函数应用于航天飞机发射数据。如以下代码所示，该数据集包括三个特征和故障计数（`distress_ct`），这是我们关心的结果：
- en: '[PRE5]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can confirm that our function is working correctly by comparing its result
    to the simple linear regression model of O-ring failures versus temperature, which
    we found earlier to have parameters *a = 3.70* and *b = -0.048*. Since temperature
    is in the third column of the launch data, we can run the `reg()` function as
    follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将结果与温度与 O 型环故障之间的简单线性回归模型进行比较来确认我们的函数是否正确。我们之前发现该模型的参数为 *a = 3.70* 和 *b
    = -0.048*。由于温度在发射数据的第三列中，我们可以按如下方式运行 `reg()` 函数：
- en: '[PRE6]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'These values exactly match our prior result, so let''s use the function to
    build a multiple regression model. We''ll apply it just as before, but this time
    specifying three columns of data instead of just one:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值与我们之前的结果完全一致，因此我们可以使用该函数来构建一个多元回归模型。我们将像之前一样应用它，不过这次我们指定三列数据，而不仅仅是其中的一列：
- en: '[PRE7]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This model predicts the number of O-ring distress events versus temperature,
    field check pressure, and the launch ID number. As with the simple linear regression
    model, the coefficient for the temperature variable is negative, which suggests
    that as temperature increases, the number of expected O-ring events decreases.
    The field check pressure refers to the amount of pressure applied to the O-ring
    to test it prior to launch. Although the check pressure had originally been 50
    psi, it was raised to 100 and 200 psi for some launches, which led some to believe
    that it may be responsible for O-ring erosion. The coefficient is positive, but
    small. The flight number is included to account for the shuttle's age. As it gets
    older, its parts may be more brittle or prone to fail. The small positive association
    between flight number and distress count may reflect this fact.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型预测了温度、现场检查压力和发射 ID 号与 O 型环故障事件的关系。与简单线性回归模型类似，温度变量的系数为负，表明随着温度升高，预期的 O 型环故障事件数减少。现场检查压力是指发射前对
    O 型环施加的压力。虽然检查压力最初是 50 psi，但在某些发射中，它被提高到 100 psi 和 200 psi，这使得一些人认为它可能是 O 型环腐蚀的原因。该系数为正，但较小。飞行编号被包含在内，以考虑航天飞机的使用年限。随着使用年限的增加，其部件可能变得更脆弱或更容易发生故障。飞行编号与故障次数之间的微弱正相关可能反映了这一事实。
- en: So far we've only scratched the surface of linear regression modeling. Although
    our work was useful to help us understand exactly how regression models are built,
    R's functions also include some additional functionality necessary for the more
    complex modeling tasks and diagnostic output that are needed to aid model interpretation
    and assess fit. Let's apply our knowledge of regression to a more challenging
    learning task.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只触及了线性回归建模的表面。虽然我们的工作有助于我们准确理解回归模型是如何构建的，但 R 的函数还包括一些额外的功能，必要时可用于更复杂的建模任务和诊断输出，这些对于帮助模型解释和评估拟合度是必需的。让我们将回归知识应用于一个更具挑战性的学习任务。
- en: Example – predicting medical expenses using linear regression
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 – 使用线性回归预测医疗费用
- en: In order for a health insurance company to make money, it needs to collect more
    in yearly premiums than it spends on medical care to its beneficiaries. As a result,
    insurers invest a great deal of time and money in developing models that accurately
    forecast medical expenses for the insured population.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使健康保险公司盈利，它需要收取的年度保费高于用于支付受益人医疗费用的支出。因此，保险公司在开发能够准确预测被保险人群体医疗费用的模型上投入了大量的时间和金钱。
- en: Medical expenses are difficult to estimate because the most costly conditions
    are rare and seemingly random. Still, some conditions are more prevalent for certain
    segments of the population. For instance, lung cancer is more likely among smokers
    than non-smokers, and heart disease may be more likely among the obese.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗费用很难估算，因为最昂贵的疾病较为罕见且看似随机。然而，某些疾病在特定人群中更为常见。例如，吸烟者比非吸烟者更容易患上肺癌，而肥胖者可能更容易患上心脏病。
- en: The goal of this analysis is to use patient data to estimate the average medical
    care expenses for such population segments. These estimates can be used to create
    actuarial tables that set the price of yearly premiums higher or lower, depending
    on the expected treatment costs.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 本次分析的目标是使用患者数据来估算特定人群的平均医疗费用。这些估算结果可以用于创建精算表，根据预期的治疗费用来调整年度保费价格。
- en: Step 1 – collecting data
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1步 – 收集数据
- en: For this analysis, we will use a simulated dataset containing hypothetical medical
    expenses for patients in the United States. This data was created for this book
    using demographic statistics from the US Census Bureau, and thus, approximately
    reflect real-world conditions.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 本次分析将使用一个模拟数据集，其中包含美国患者的假设医疗费用数据。这些数据是使用美国人口普查局的统计数据为本书创建的，因此大致反映了现实世界的情况。
- en: Tip
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: If you would like to follow along interactively, download the `insurance.csv`
    file from the Packt Publishing website and save it to your R working folder.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望互动地跟随本书的内容，可以从Packt Publishing网站下载`insurance.csv`文件，并将其保存在R的工作文件夹中。
- en: 'The `insurance.csv` file includes 1,338 examples of beneficiaries currently
    enrolled in the insurance plan, with features indicating characteristics of the
    patient as well as the total medical expenses charged to the plan for the calendar
    year. The features are:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`insurance.csv`文件包括1,338个目前已参加保险计划的受益人示例，文件中包含患者的特征以及该年度总医疗费用。特征包括：'
- en: '`age`: An integer indicating the age of the primary beneficiary (excluding
    those above 64 years, since they are generally covered by the government).'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`age`：一个整数，表示主要受益人的年龄（不包括64岁以上的人群，因为他们通常由政府提供保险）。'
- en: '`sex`: The policy holder''s gender, either male or female.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sex`：保险持有人的性别，可以是男性或女性。'
- en: '`bmi`: The body mass index (BMI), which provides a sense of how over- or under-weight
    a person is relative to their height. BMI is equal to weight (in kilograms) divided
    by height (in meters) squared. An ideal BMI is within the range of 18.5 to 24.9.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bmi`：身体质量指数（BMI），它表示一个人的体重与身高的关系。BMI等于体重（以千克为单位）除以身高（以米为单位）的平方。理想的BMI范围是18.5到24.9。'
- en: '`children`: An integer indicating the number of children/dependents covered
    by the insurance plan.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`children`：一个整数，表示保险计划所涵盖的子女/受抚养人数量。'
- en: '`smoker`: A yes or no categorical variable that indicates whether the insured
    regularly smokes tobacco.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`smoker`：一个是或否的分类变量，表示被保险人是否定期吸烟。'
- en: '`region`: The beneficiary''s place of residence in the US, divided into four
    geographic regions: northeast, southeast, southwest, or northwest.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`region`：受益人在美国的居住地，分为四个地理区域：东北、东南、西南或西北。'
- en: It is important to give some thought to how these variables may be related to
    billed medical expenses. For instance, we might expect that older people and smokers
    are at higher risk of large medical expenses. Unlike many other machine learning
    methods, in regression analysis, the relationships among the features are typically
    specified by the user rather than being detected automatically. We'll explore
    some of these potential relationships in the next section.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这些变量如何与计费医疗费用相关是非常重要的。例如，我们可能预期，老年人和吸烟者面临较大医疗费用的风险。与许多其他机器学习方法不同，在回归分析中，特征之间的关系通常由用户指定，而不是自动检测。我们将在下一节探讨这些潜在的关系。
- en: Step 2 – exploring and preparing the data
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步 – 探索和准备数据
- en: 'As we have done before, we will use the `read.csv()` function to load the data
    for analysis. We can safely use `stringsAsFactors = TRUE` because it is appropriate
    to convert the three nominal variables to factors:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所做的，我们将使用`read.csv()`函数加载数据进行分析。我们可以安全地使用`stringsAsFactors = TRUE`，因为将这三个名义变量转换为因子是合适的：
- en: '[PRE8]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `str()` function confirms that the data is formatted as we had expected:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`str()`函数确认数据格式符合我们的预期：'
- en: '[PRE9]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Our model''s dependent variable is `expenses`, which measures the medical costs
    each person charged to the insurance plan for the year. Prior to building a regression
    model, it is often helpful to check for normality. Although linear regression
    does not strictly require a normally distributed dependent variable, the model
    often fits better when this is true. Let''s take a look at the summary statistics:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模型的因变量是`expenses`，它表示每个人在一年内为保险计划支付的医疗费用。在构建回归模型之前，检查数据是否符合正态分布通常是有帮助的。尽管线性回归并不严格要求因变量正态分布，但当这一假设成立时，模型往往拟合得更好。让我们看一下汇总统计信息：
- en: '[PRE10]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Because the mean value is greater than the median, this implies that the distribution
    of insurance expenses is right-skewed. We can confirm this visually using a histogram:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 因为均值大于中位数，这意味着保险费用的分布是右偏的。我们可以通过直方图来直观确认这一点：
- en: '[PRE11]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is shown as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下所示：
- en: '![Step 2 – exploring and preparing the data](img/B03905_06_19.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![步骤 2 – 探索和准备数据](img/B03905_06_19.jpg)'
- en: As expected, the figure shows a right-skewed distribution. It also shows that
    the majority of people in our data have yearly medical expenses between zero and
    $15,000, in spite of the fact that the tail of the distribution extends far past
    these peaks. Although this distribution is not ideal for a linear regression,
    knowing this weakness ahead of time may help us design a better-fitting model
    later on.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，图表显示了右偏的分布。它还表明，尽管分布的尾部远超这些峰值，但我们数据中的大多数人年医疗费用在零到$15,000之间。虽然这个分布并不适合线性回归，但提前了解这一弱点有助于我们设计出更适合的模型。
- en: 'Before we address that issue, another problem is at hand. Regression models
    require that every feature is numeric, yet we have three factor-type features
    in our data frame. For instance, the sex variable is divided into male and female
    levels, while smoker is divided into yes and no. From the `summary()` output,
    we know that the `region` variable has four levels, but we need to take a closer
    look to see how they are distributed:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们解决这个问题之前，还有另一个问题需要处理。回归模型要求每个特征都是数值型的，但我们在数据框中有三个因子型特征。例如，性别变量分为男性和女性两个级别，而吸烟者分为是和否。从`summary()`输出中，我们知道`region`变量有四个级别，但我们需要进一步查看它们的分布：
- en: '[PRE12]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, we see that the data has been divided nearly evenly among four geographic
    regions. We will see how R's linear regression function handles these factor variables
    shortly.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到数据几乎均匀地划分到四个地理区域中。稍后我们将看到R的线性回归函数如何处理这些因子变量。
- en: Exploring relationships among features – the correlation matrix
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索特征之间的关系——相关矩阵
- en: Before fitting a regression model to data, it can be useful to determine how
    the independent variables are related to the dependent variable and each other.
    A **correlation matrix** provides a quick overview of these relationships. Given
    a set of variables, it provides a correlation for each pairwise relationship.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在拟合回归模型之前，确定自变量与因变量及相互之间的关系是很有帮助的。**相关矩阵**提供了这些关系的快速概览。给定一组变量，它为每一对关系提供相关性。
- en: 'To create a correlation matrix for the four numeric variables in the insurance
    data frame, use the `cor()` command:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 要为保险数据框中的四个数值变量创建相关矩阵，可以使用`cor()`命令：
- en: '[PRE13]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: At the intersection of each row and column pair, the correlation is listed for
    the variables indicated by that row and column. The diagonal is always `1.0000000`
    since there is always a perfect correlation between a variable and itself. The
    values above and below the diagonal are identical since correlations are symmetrical.
    In other words, `cor(x, y)` is equal to `cor(y, x)`.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一行和列的交点处，会列出由该行和列所表示的变量的相关性。对角线上的值始终是`1.0000000`，因为一个变量与它自身的相关性总是完美的。对角线上的值上下是对称的，因此相关性是对称的。换句话说，`cor(x,
    y)`等于`cor(y, x)`。
- en: None of the correlations in the matrix are considered strong, but there are
    some notable associations. For instance, `age` and `bmi` appear to have a weak
    positive correlation, meaning that as someone ages, their body mass tends to increase.
    There is also a moderate positive correlation between `age` and `expenses`, `bmi`
    and `expenses`, and `children` and `expenses`. These associations imply that as
    age, body mass, and number of children increase, the expected cost of insurance
    goes up. We'll try to tease out these relationships more clearly when we build
    our final regression model.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵中的相关性都不算强，但有一些显著的关联。例如，`age`和`bmi`之间似乎存在弱正相关，意味着随着年龄的增长，体重通常会增加。`age`与`expenses`、`bmi`与`expenses`、以及`children`与`expenses`之间也有中等程度的正相关。这些关联意味着随着年龄、体重和孩子数量的增加，预期的保险费用也会上升。我们将在构建最终回归模型时更清晰地揭示这些关系。
- en: Visualizing relationships among features – the scatterplot matrix
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化特征间的关系 – 散点图矩阵
- en: It can also be helpful to visualize the relationships among numeric features
    by using a scatterplot. Although we could create a scatterplot for each possible
    relationship, doing so for a large number of features might become tedious.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 使用散点图来可视化数值特征之间的关系也很有帮助。尽管我们可以为每一种可能的关系创建散点图，但对于大量特征来说，这样做可能会变得很繁琐。
- en: An alternative is to create a **scatterplot matrix** (sometimes abbreviated
    as **SPLOM**), which is simply a collection of scatterplots arranged in a grid.
    It is used to detect patterns among three or more variables. The scatterplot matrix
    is not a true multidimensional visualization because only two features are examined
    at a time. Still, it provides a general sense of how the data may be interrelated.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是创建一个**散点图矩阵**（有时简写为**SPLOM**），它仅仅是一个按网格排列的散点图集合。它用于检测三个或更多变量之间的模式。散点图矩阵并不是真正的多维可视化，因为每次仅检查两个特征。但它提供了一个大致的感知，显示数据可能的相互关系。
- en: 'We can use R''s graphical capabilities to create a scatterplot matrix for the
    four numeric features: `age`, `bmi`, `children`, and `expenses`. The `pairs()`
    function is provided in a default R installation and provides basic functionality
    for producing scatterplot matrices. To invoke the function, simply provide it
    the data frame to present. Here, we''ll limit the `insurance` data frame to the
    four numeric variables of interest:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用R的图形功能为四个数值特征（`age`、`bmi`、`children`和`expenses`）创建一个散点图矩阵。`pairs()`函数在默认的R安装中提供，能够生成基本的散点图矩阵功能。要调用该函数，只需提供要展示的数据框。这里，我们将`insurance`数据框限制为四个感兴趣的数值变量：
- en: '[PRE14]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This produces the following diagram:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成如下图表：
- en: '![Visualizing relationships among features – the scatterplot matrix](img/B03905_06_20.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![可视化特征间的关系 – 散点图矩阵](img/B03905_06_20.jpg)'
- en: In the scatterplot matrix, the intersection of each row and column holds the
    scatterplot of the variables indicated by the row and column pair. The diagrams
    above and below the diagonal are transpositions since the *x* axis and *y* axis
    have been swapped.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在散点图矩阵中，每一行和每一列的交点处展示的是由行和列所表示的变量的散点图。对角线以上和以下的图表是转置的，因为*x*轴和*y*轴已被交换。
- en: Do you notice any patterns in these plots? Although some look like random clouds
    of points, a few seem to display some trends. The relationship between `age` and
    `expenses` displays several relatively straight lines, while the `bmi` versus
    `expenses` plot has two distinct groups of points. It is difficult to detect trends
    in any of the other plots.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 你在这些图表中注意到任何模式吗？尽管有些看起来像是随机的点云，但有些似乎展示了一些趋势。`age`与`expenses`之间的关系显示了几条相对直的线，而`bmi`与`expenses`的图表则有两组明显不同的点。在其他图表中很难发现趋势。
- en: 'If we add more information to the plot, it can be even more useful. An enhanced
    scatterplot matrix can be created with the `pairs.panels()` function in the `psych`
    package. If you do not have this package installed, type `install.packages("psych")`
    to install it on your system and load it using the `library(psych)` command. Then,
    we can create a scatterplot matrix as we had done previously:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在图表中添加更多信息，它将变得更加有用。可以使用`psych`包中的`pairs.panels()`函数创建一个增强版的散点图矩阵。如果你没有安装该包，请输入`install.packages("psych")`进行安装，并通过`library(psych)`命令加载它。然后，我们可以像之前那样创建一个散点图矩阵：
- en: '[PRE15]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This produces a slightly more informative scatterplot matrix, as shown here:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成一个稍微更具信息量的散点图矩阵，如下所示：
- en: '![Visualizing relationships among features – the scatterplot matrix](img/B03905_06_21.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![可视化特征之间的关系 – 散点图矩阵](img/B03905_06_21.jpg)'
- en: Above the diagonal, the scatterplots have been replaced with a correlation matrix.
    On the diagonal, a histogram depicting the distribution of values for each feature
    is shown. Finally, the scatterplots below the diagonal are now presented with
    additional visual information.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 对角线以上的散点图已被相关矩阵替代。对角线上的直方图显示了每个特征值的分布情况。最后，对角线下方的散点图现在呈现了更多的视觉信息。
- en: The oval-shaped object on each scatterplot is a **correlation ellipse**. It
    provides a visualization of correlation strength. The dot at the center of the
    ellipse indicates the point at the mean values for the *x* and *y* axis variables.
    The correlation between the two variables is indicated by the shape of the ellipse;
    the more it is stretched, the stronger the correlation. An almost perfectly round
    oval, as with `bmi` and `children`, indicates a very weak correlation (in this
    case, it is 0.01).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 每个散点图上椭圆形的物体是一个**相关椭圆**。它提供了相关性强度的可视化。椭圆中心的点表示 *x* 和 *y* 轴变量的均值位置。变量之间的相关性通过椭圆的形状来表示；它越被拉伸，相关性越强。几乎完全圆形的椭圆，如
    `bmi` 和 `children` 之间的关系，表明相关性非常弱（在这种情况下为 0.01）。
- en: The curve drawn on the scatterplot is called a **loess curve**. It indicates
    the general relationship between the *x* and *y* axis variables. It is best understood
    by example. The curve for `age` and `children` is an upside-down U, peaking around
    middle age. This means that the oldest and youngest people in the sample have
    fewer children on the insurance plan than those around middle age. Because this
    trend is non-linear, this finding could not have been inferred from the correlations
    alone. On the other hand, the loess curve for `age` and `bmi` is a line sloping
    gradually up, implying that body mass increases with age, but we had already inferred
    this from the correlation matrix.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图上绘制的曲线称为**局部加权回归曲线（loess curve）**。它表示 *x* 和 *y* 轴变量之间的一般关系。通过示例最容易理解。`age`
    和 `children` 的曲线呈倒 U 形，峰值出现在中年左右。这意味着样本中最年长和最年轻的人群在保险计划中有的孩子比中年人少。由于这一趋势是非线性的，仅凭相关性是无法得出这一结论的。另一方面，`age`
    和 `bmi` 的 loess 曲线是逐渐向上的直线，表明随着年龄的增长，体重指数也在增加，但我们已经通过相关矩阵推断出这一点。
- en: Step 3 – training a model on the data
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3 – 在数据上训练模型
- en: 'To fit a linear regression model to data with R, the `lm()` function can be
    used. This is included in the `stats` package, which should be included and loaded
    by default with your R installation. The `lm()` syntax is as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 R 中拟合线性回归模型，可以使用 `lm()` 函数。该函数包含在 `stats` 包中，默认情况下应该随着 R 安装一起加载。`lm()` 的语法如下：
- en: '![Step 3 – training a model on the data](img/B03905_06_22.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![步骤 3 – 在数据上训练模型](img/B03905_06_22.jpg)'
- en: 'The following command fits a linear regression model relating the six independent
    variables to the total medical expenses. The R formula syntax uses the tilde character
    `~` to describe the model; the dependent variable `expenses` goes to the left
    of the tilde while the independent variables go to the right, separated by `+`
    signs. There is no need to specify the regression model''s intercept term as it
    is assumed by default:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令拟合一个线性回归模型，将六个自变量与总医疗费用相关联。R 的公式语法使用波浪号字符 `~` 来描述模型；因变量 `expenses` 位于波浪号的左侧，而自变量位于右侧，并由
    `+` 符号分隔。由于回归模型的截距项默认假定存在，因此无需明确指定：
- en: '[PRE16]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Because the `.` character can be used to specify all the features (excluding
    those already specified in the formula), the following command is equivalent to
    the preceding command:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `.` 字符可以用来指定所有特征（排除公式中已指定的特征），因此以下命令等同于之前的命令：
- en: '[PRE17]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After building the model, simply type the name of the model object to see the
    estimated beta coefficients:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 构建模型后，只需输入模型对象的名称即可查看估计的贝塔系数：
- en: '[PRE18]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Understanding the regression coefficients is fairly straightforward. The intercept
    is the predicted value of `expenses` when the independent variables are equal
    to zero. As is the case here, quite often the intercept is of little value alone
    because it is impossible to have values of zero for all features. For example,
    since no person exists with age zero and BMI zero, the intercept has no real-world
    interpretation. For this reason, in practice, the intercept is often ignored.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 理解回归系数是相当简单的。截距是当所有自变量为零时，`expenses`的预测值。正如这里的情况，截距通常单独没有太大意义，因为所有特征不可能都有零值。例如，由于不存在年龄为零且BMI为零的人，因此截距没有实际意义。出于这个原因，在实践中，截距通常会被忽略。
- en: The beta coefficients indicate the estimated increase in expenses for an increase
    of one in each of the features, assuming all other values are held constant. For
    instance, for each additional year of age, we would expect $256.80 higher medical
    expenses on average, assuming everything else is equal. Similarly, each additional
    child results in an average of $475.70 in additional medical expenses each year,
    and each unit increase in BMI is associated with an average increase of $339.30
    in yearly medical expenses, all else equal.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 贝塔系数表示每增加一个特征值，假设其他所有值保持不变，医疗费用的预估增加。例如，每增加一年年龄，平均预计医疗费用增加$256.80，假设其他条件不变。类似地，每增加一个孩子，平均每年医疗费用增加$475.70，而每增加一个单位的BMI，平均每年医疗费用增加$339.30，其他条件不变。
- en: You might notice that although we only specified six features in our model formula,
    there are eight coefficients reported in addition to the intercept. This happened
    because the `lm()` function automatically applied a technique known as **dummy
    coding** to each of the factor-type variables we included in the model.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，尽管我们在模型公式中只指定了六个特征，但报告的系数除了截距之外还有八个。这是因为`lm()`函数自动对我们在模型中包含的每个因子类型变量应用了一种称为**虚拟编码**的技术。
- en: 'Dummy coding allows a nominal feature to be treated as numeric by creating
    a binary variable, often called a **dummy** **variable**, for each category of
    the feature. The dummy variable is set to `1` if the observation falls into the
    specified category or `0` otherwise. For instance, the `sex` feature has two categories:
    `male` and `female`. This will be split into two binary variables, which R names
    `sexmale` and `sexfemale`. For observations where `sex = male`, then `sexmale
    = 1` and `sexfemale = 0`; conversely, if `sex = female`, then `sexmale = 0` and
    `sexfemale = 1`. The same coding applies to variables with three or more categories.
    For example, R split the four-category feature `region` into four dummy variables:
    `regionnorthwest`, `regionsoutheast`, `regionsouthwest`, and `regionnortheast`.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟编码通过为特征的每个类别创建一个二元变量，通常称为**虚拟** **变量**，将一个名义特征处理为数值型特征。如果观察值属于指定的类别，则虚拟变量为`1`，否则为`0`。例如，`sex`特征有两个类别：`male`和`female`。这将被拆分为两个二元变量，R分别命名为`sexmale`和`sexfemale`。对于`sex
    = male`的观察值，`sexmale = 1`且`sexfemale = 0`；反之，如果`sex = female`，则`sexmale = 0`且`sexfemale
    = 1`。对于具有三个或更多类别的变量也适用相同的编码方式。例如，R将四类别特征`region`拆分为四个虚拟变量：`regionnorthwest`、`regionsoutheast`、`regionsouthwest`和`regionnortheast`。
- en: When adding a dummy variable to a regression model, one category is always left
    out to serve as the reference category. The estimates are then interpreted relative
    to the reference. In our model, R automatically held out the `sexfemale`, `smokerno`,
    and `regionnortheast` variables, making female non-smokers in the northeast region
    the reference group. Thus, males have $131.40 less medical expenses each year
    relative to females and smokers cost an average of $23,847.50 more than non-smokers
    per year. The coefficient for each of the three regions in the model is negative,
    which implies that the reference group, the northeast region, tends to have the
    highest average expenses.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在向回归模型中添加虚拟变量时，始终会有一个类别被排除作为参考类别。然后，系数会相对于该参考类别进行解释。在我们的模型中，R自动排除了`sexfemale`、`smokerno`和`regionnortheast`变量，将女性非吸烟者所在的东北地区作为参考组。因此，相对于女性，每年男性的医疗费用少$131.40，而吸烟者每年比非吸烟者多花费$23,847.50。模型中每个三大地区的系数都是负数，这意味着参考组——东北地区的平均费用最高。
- en: Tip
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: By default, R uses the first level of the factor variable as the reference.
    If you would prefer to use another level, the `relevel()` function can be used
    to specify the reference group manually. Use the `?relevel` command in R for more
    information.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，R使用因子变量的第一个级别作为参考。如果你希望使用其他级别，可以使用`relevel()`函数手动指定参考组。欲了解更多信息，请在R中使用`?relevel`命令。
- en: 'The results of the linear regression model make logical sense: old age, smoking,
    and obesity tend to be linked to additional health issues, while additional family
    member dependents may result in an increase in physician visits and preventive
    care such as vaccinations and yearly physical exams. However, we currently have
    no sense of how well the model is fitting the data. We''ll answer this question
    in the next section.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型的结果是合乎逻辑的：老年、吸烟和肥胖倾向于与额外的健康问题相关，而额外的家庭成员抚养负担可能导致医生就诊次数和预防性护理（如疫苗接种和年度体检）的增加。然而，我们目前并不清楚模型拟合数据的效果如何。我们将在下一节回答这个问题。
- en: Step 4 – evaluating model performance
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 4 – 评估模型性能
- en: 'The parameter estimates we obtained by typing `ins_model` tell us about how
    the independent variables are related to the dependent variable, but they tell
    us nothing about how well the model fits our data. To evaluate the model performance,
    we can use the `summary()` command on the stored model:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过输入`ins_model`获得的参数估计值告诉我们自变量与因变量之间的关系，但它们并没有告诉我们模型与数据的拟合度。为了评估模型性能，我们可以对存储的模型使用`summary()`命令：
- en: '[PRE19]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This produces the following output. Note that the output has been labeled for
    illustrative purposes:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下输出。请注意，输出已经标注了说明性标签：
- en: '![Step 4 – evaluating model performance](img/B03905_06_23.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![步骤 4 – 评估模型性能](img/B03905_06_23.jpg)'
- en: 'The `summary()` output may seem confusing at first, but the basics are easy
    to pick up. As indicated by the numbered labels in the preceding output, the output
    provides three key ways to evaluate the performance, or fit, of our model:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`summary()`输出一开始可能让人感到困惑，但基本概念很容易掌握。如前输出中的编号标签所示，输出提供了评估模型性能或拟合度的三种关键方法：'
- en: The **residuals** section provides summary statistics for the errors in our
    predictions, some of which are apparently quite substantial. Since a residual
    is equal to the true value minus the predicted value, the maximum error of 29981.7
    suggests that the model under-predicted expenses by nearly $30,000 for at least
    one observation. On the other hand, 50 percent of errors fall within the 1Q and
    3Q values (the first and third quartile), so the majority of predictions were
    between $2,850.90 over the true value and $1,383.90 under the true value.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**残差**部分提供了我们预测中错误的汇总统计信息，其中一些显然相当大。由于残差等于真实值减去预测值，因此最大误差为29981.7，表明模型在至少一个观测值中低估了近$30,000的支出。另一方面，50%的误差落在1Q和3Q值（第一四分位数和第三四分位数）之间，因此大多数预测结果介于真实值之上$2,850.90和真实值之下$1,383.90之间。'
- en: For each estimated regression coefficient, the **p-value**, denoted `Pr(>|t|)`,
    provides an estimate of the probability that the true coefficient is zero given
    the value of the estimate. Small p-values suggest that the true coefficient is
    very unlikely to be zero, which means that the feature is extremely unlikely to
    have no relationship with the dependent variable. Note that some of the p-values
    have stars (`***`), which correspond to the footnotes to indicate the **significance
    level** met by the estimate. This level is a threshold, chosen prior to building
    the model, which will be used to indicate "real" findings, as opposed to those
    due to chance alone; p-values less than the significance level are considered
    **statistically significant**. If the model had few such terms, it may be cause
    for concern, since this would indicate that the features used are not very predictive
    of the outcome. Here, our model has several highly significant variables, and
    they seem to be related to the outcome in logical ways.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个估计的回归系数，**p值**，用`Pr(>|t|)`表示，提供了一个估算值，表示在给定估计值的情况下，真实系数为零的概率。小的p值表明真实系数非常不可能为零，这意味着该特征极不可能与因变量没有关系。请注意，某些p值有星号（`***`），这些星号对应脚注，表示估计值所达到的**显著性水平**。这个水平是一个阈值，在建立模型之前选择，用来指示“真实”的发现，而不是仅仅由于偶然因素；小于显著性水平的p值被视为**统计显著**。如果模型中有很少这样的项，可能需要引起关注，因为这表明所使用的特征对结果的预测能力较弱。这里，我们的模型有多个高度显著的变量，而且它们似乎与结果在逻辑上相关。
- en: The **multiple R-squared value** (also called the coefficient of determination)
    provides a measure of how well our model as a whole explains the values of the
    dependent variable. It is similar to the correlation coefficient, in that the
    closer the value is to 1.0, the better the model perfectly explains the data.
    Since the R-squared value is 0.7494, we know that the model explains nearly 75
    percent of the variation in the dependent variable. Because models with more features
    always explain more variation, the **adjusted R-squared value** corrects R-squared
    by penalizing models with a large number of independent variables. It is useful
    for comparing the performance of models with different numbers of explanatory
    variables.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多重 R 方值**（也叫决定系数）提供了衡量我们模型整体解释因变量值的能力。它类似于相关系数，数值越接近 1.0，模型对数据的解释越完美。由于 R
    方值为 0.7494，我们知道模型解释了因变量近 75% 的变化。由于具有更多特征的模型总是能解释更多变化，**调整 R 方值**通过对具有大量独立变量的模型进行惩罚来修正
    R 方值。它对于比较具有不同数量解释变量的模型表现非常有用。'
- en: Given the preceding three performance indicators, our model is performing fairly
    well. It is not uncommon for regression models of real-world data to have fairly
    low R-squared values; a value of 0.75 is actually quite good. The size of some
    of the errors is a bit concerning, but not surprising given the nature of medical
    expense data. However, as shown in the next section, we may be able to improve
    the model's performance by specifying the model in a slightly different way.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前述的三个性能指标，我们的模型表现得相当不错。回归模型在实际数据中往往会有较低的 R 方值，0.75 的值实际上已经相当不错。一些误差的大小有些令人担忧，但考虑到医疗费用数据的特性，这并不令人惊讶。然而，正如下一节所示，我们可能通过稍微不同的方式指定模型来提高模型的性能。
- en: Step 5 – improving model performance
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 5 步 – 提高模型性能
- en: As mentioned previously, a key difference between the regression modeling and
    other machine learning approaches is that regression typically leaves feature
    selection and model specification to the user. Consequently, if we have subject
    matter knowledge about how a feature is related to the outcome, we can use this
    information to inform the model specification and potentially improve the model's
    performance.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，回归建模与其他机器学习方法的一个关键区别在于，回归通常将特征选择和模型指定留给用户。因此，如果我们了解某个特征与结果之间的关系，我们可以利用这些信息来指导模型的指定，从而可能提高模型的性能。
- en: Model specification – adding non-linear relationships
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型指定 – 添加非线性关系
- en: In linear regression, the relationship between an independent variable and the
    dependent variable is assumed to be linear, yet this may not necessarily be true.
    For example, the effect of age on medical expenditure may not be constant throughout
    all the age values; the treatment may become disproportionately expensive for
    oldest populations.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归中，自变量与因变量之间的关系假定为线性，但这不一定为真。例如，年龄对医疗支出的影响可能在所有年龄值中并非恒定；对于最年长的群体，治疗可能变得不成比例地昂贵。
- en: 'If you recall, a typical regression equation follows a form similar to this:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你记得的话，典型的回归方程通常类似于此：
- en: '![Model specification – adding non-linear relationships](img/B03905_06_24.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![模型指定 – 添加非线性关系](img/B03905_06_24.jpg)'
- en: 'To account for a non-linear relationship, we can add a higher order term to
    the regression model, treating the model as a polynomial. In effect, we will be
    modeling a relationship like this:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 为了考虑非线性关系，我们可以向回归模型中添加更高阶的项，将模型视为多项式。实际上，我们将模拟这样的关系：
- en: '![Model specification – adding non-linear relationships](img/B03905_06_25.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![模型指定 – 添加非线性关系](img/B03905_06_25.jpg)'
- en: The difference between these two models is that an additional beta will be estimated,
    which is intended to capture the effect of the *x*-squared term. This allows the
    impact of age to be measured as a function of age squared.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个模型之间的区别在于将估计一个额外的贝塔系数，旨在捕捉 *x* 的平方项的影响。这使得年龄的影响可以作为年龄平方的函数来衡量。
- en: 'To add the non-linear age to the model, we simply need to create a new variable:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 要将非线性年龄加入模型，我们只需创建一个新的变量：
- en: '[PRE20]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Then, when we produce our improved model, we'll add both `age` and `age2` to
    the `lm()` formula using the `expenses ~ age + age2` form. This will allow the
    model to separate the linear and non-linear impact of age on medical expenses.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，当我们生成我们改进的模型时，我们将使用`expenses ~ age + age2`形式将`age`和`age2`都添加到`lm()`公式中。这将使模型能够分离年龄对医疗支出的线性和非线性影响。
- en: Transformation – converting a numeric variable to a binary indicator
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 转换 - 将数值变量转换为二元指示器
- en: Suppose we have a hunch that the effect of a feature is not cumulative, rather
    it has an effect only after a specific threshold has been reached. For instance,
    BMI may have zero impact on medical expenditures for individuals in the normal
    weight range, but it may be strongly related to higher costs for the obese (that
    is, BMI of 30 or above).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一种直觉，即某个特征的影响不是累积的，而是只有在达到特定阈值后才会产生影响。例如，BMI对于正常体重范围内的个体可能没有医疗支出的影响，但对于肥胖者（即BMI达到或超过30）可能与更高的费用密切相关。
- en: We can model this relationship by creating a binary obesity indicator variable
    that is 1 if the BMI is at least 30, and 0 if less. The estimated beta for this
    binary feature would then indicate the average net impact on medical expenses
    for individuals with BMI of 30 or above, relative to those with BMI less than
    30.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过创建一个二元肥胖指示变量来建模这种关系，如果BMI至少为30，则为1，否则为0。然后，这个二元特征的估计β值将指示BMI达到或超过30的个体对医疗支出的平均净影响，相对于BMI低于30的个体。
- en: 'To create the feature, we can use the `ifelse()` function, which for each element
    in a vector tests a specified condition and returns a value depending on whether
    the condition is true or false. For BMI greater than or equal to 30, we will return
    `1`, otherwise `0`:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建该特征，我们可以使用`ifelse()`函数，该函数对向量中的每个元素测试指定的条件，并根据条件是真还是假返回一个值。对于BMI大于或等于30，我们将返回`1`，否则返回`0`：
- en: '[PRE21]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We can then include the `bmi30` variable in our improved model, either replacing
    the original `bmi` variable or in addition, depending on whether or not we think
    the effect of obesity occurs in addition to a separate linear BMI effect. Without
    good reason to do otherwise, we'll include both in our final model.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来可以在我们改进的模型中包含`bmi30`变量，可以替换原来的`bmi`变量或者同时加入，这取决于我们是否认为肥胖的影响会在单独的线性BMI效应之外发生。如果没有充分的理由做出改变，我们将在最终模型中都包含它们。
- en: Tip
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: If you have trouble deciding whether or not to include a variable, a common
    practice is to include it and examine the p-value. If the variable is not statistically
    significant, you have evidence to support excluding it in the future.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在决定是否包含一个变量时遇到困难，一个常见的做法是将其包含在内并检查P值。如果变量在统计上不显著，您有理由在将来排除它。
- en: Model specification – adding interaction effects
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型规范化 - 添加交互效应
- en: So far, we have only considered each feature's individual contribution to the
    outcome. What if certain features have a combined impact on the dependent variable?
    For instance, smoking and obesity may have harmful effects separately, but it
    is reasonable to assume that their combined effect may be worse than the sum of
    each one alone.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只考虑了每个特征对结果的个体贡献。如果某些特征共同影响因变量呢？例如，吸烟和肥胖可能分别具有有害效应，但合并效应可能比单独每个因素的总和更糟糕是合理的假设。
- en: When two features have a combined effect, this is known as an **interaction**.
    If we suspect that two variables interact, we can test this hypothesis by adding
    their interaction to the model. Interaction effects are specified using the R
    formula syntax. To have the obesity indicator (`bmi30`) and the smoking indicator
    (`smoker`) interact, we would write a formula in the form `expenses ~ bmi30*smoker`.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个特征具有联合效应时，这被称为**交互作用**。如果我们怀疑两个变量之间存在交互作用，我们可以通过将它们的交互项添加到模型中来测试这一假设。交互效应使用R公式语法指定。为了让肥胖指示器(`bmi30`)和吸烟指示器(`smoker`)交互，我们会编写如下形式的公式：`expenses
    ~ bmi30*smoker`。
- en: The `*` operator is shorthand that instructs R to model `expenses ~ bmi30 +
    smokeryes + bmi30:smokeryes`. The `:` (colon) operator in the expanded form indicates
    that `bmi30:smokeryes` is the interaction between the two variables. Note that
    the expanded form also automatically included the `bmi30` and `smoker` variables
    as well as the interaction.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '`*`运算符是一个快捷方式，指示R模型为`expenses ~ bmi30 + smokeryes + bmi30:smokeryes`。在扩展形式中，冒号`:`运算符表示`bmi30:smokeryes`是两个变量之间的交互作用。请注意，扩展形式还自动包括了`bmi30`和`smoker`变量以及交互作用。'
- en: Tip
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Interactions should never be included in a model without also adding each of
    the interacting variables. If you always create interactions using the `*` operator,
    this will not be a problem since R will add the required components automatically.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 交互项在模型中绝不能单独包含，而不添加每个交互变量。如果你总是使用`*`运算符来创建交互作用，那么这个问题就不会出现，因为R会自动添加所需的组件。
- en: Putting it all together – an improved regression model
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 综合起来——一个改进的回归模型
- en: 'Based on a bit of subject matter knowledge of how medical costs may be related
    to patient characteristics, we developed what we think is a more accurately specified
    regression formula. To summarize the improvements, we:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 基于对医学费用可能与患者特征相关的一些主题知识，我们开发了我们认为更准确的回归公式。总结改进的内容，我们：
- en: Added a non-linear term for age
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为年龄添加了一个非线性项
- en: Created an indicator for obesity
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了一个用于肥胖的指标
- en: Specified an interaction between obesity and smoking
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定了肥胖与吸烟之间的交互作用
- en: 'We''ll train the model using the `lm()` function as before, but this time we''ll
    add the newly constructed variables and the interaction term:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将像之前一样使用`lm()`函数来训练模型，但这次我们将添加新构建的变量和交互项：
- en: '[PRE22]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Next, we summarize the results:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们总结结果：
- en: '[PRE23]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output is shown as follows:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '![Putting it all together – an improved regression model](img/B03905_06_26.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![综合起来——一个改进的回归模型](img/B03905_06_26.jpg)'
- en: The model fit statistics help to determine whether our changes improved the
    performance of the regression model. Relative to our first model, the R-squared
    value has improved from 0.75 to about 0.87\. Similarly, the adjusted R-squared
    value, which takes into account the fact that the model grew in complexity, also
    improved from 0.75 to 0.87\. Our model is now explaining 87 percent of the variation
    in medical treatment costs. Additionally, our theories about the model's functional
    form seem to be validated. The higher-order `age2` term is statistically significant,
    as is the obesity indicator, `bmi30`. The interaction between obesity and smoking
    suggests a massive effect; in addition to the increased costs of over $13,404
    for smoking alone, obese smokers spend another $19,810 per year. This may suggest
    that smoking exacerbates diseases associated with obesity.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 模型拟合统计量有助于确定我们的修改是否提高了回归模型的性能。与我们的第一个模型相比，R平方值从0.75提高到了大约0.87。同样，考虑到模型复杂度增加的调整后R平方值也从0.75提高到了0.87。我们的模型现在解释了87%的医疗费用变异。此外，我们关于模型功能形式的理论似乎得到了验证。高阶`age2`项是统计显著的，肥胖指标`bmi30`也是如此。肥胖与吸烟的交互作用表明有巨大的影响；除了吸烟本身导致的超过$13,404的费用外，肥胖吸烟者每年还要额外花费$19,810。这可能表明吸烟加剧了与肥胖相关的疾病。
- en: Note
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Strictly speaking, regression modeling makes some strong assumptions about
    the data. These assumptions are not as important for numeric forecasting, as the
    model''s worth is not based upon whether it truly captures the underlying process—we
    simply care about the accuracy of its predictions. However, if you would like
    to make firm inferences from the regression model coefficients, it is necessary
    to run diagnostic tests to ensure that the regression assumptions have not been
    violated. For an excellent introduction to this topic, see Allison PD*. Multiple
    regression: A primer*. Pine Forge Press; 1998.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 严格来说，回归建模对数据做出了一些强假设。这些假设对于数值预测来说并不那么重要，因为模型的价值并不依赖于它是否真正捕捉到了潜在的过程——我们关心的是其预测的准确性。然而，如果你希望从回归模型系数中得出明确的推论，就有必要进行诊断测试，确保回归假设没有被违反。关于这一主题的优秀介绍，参见Allison
    PD*《多元回归：基础》*，Pine Forge Press，1998年。
- en: Understanding regression trees and model trees
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解回归树和模型树
- en: If you recall from [Chapter 5](ch05.html "Chapter 5. Divide and Conquer – Classification
    Using Decision Trees and Rules"), *Divide and Conquer – Classification Using Decision
    Trees and Rules*, a decision tree builds a model much like a flowchart in which
    decision nodes, leaf nodes, and branches define a series of decisions that are
    used to classify examples. Such trees can also be used for numeric prediction
    by making only small adjustments to the tree-growing algorithm. In this section,
    we will consider only the ways in which trees for numeric prediction differ from
    trees used for classification.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你记得[第5章](ch05.html "第5章：分而治之 – 使用决策树和规则进行分类")，*分而治之 – 使用决策树和规则进行分类*，决策树构建的模型就像一个流程图，其中决策节点、叶节点和分支定义了一系列决策，用于分类示例。这样的树也可以通过对树生长算法进行小的调整，用于数值预测。在本节中，我们只会讨论用于数值预测的树与用于分类的树的不同之处。
- en: Trees for numeric prediction fall into two categories. The first, known as **regression
    trees**, were introduced in the 1980s as part of the seminal **Classification
    and Regression Tree** (**CART**) algorithm. Despite the name, regression trees
    do not use linear regression methods as described earlier in this chapter, rather
    they make predictions based on the average value of examples that reach a leaf.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 用于数值预测的树分为两类。第一类称为**回归树**，它们在1980年代作为开创性的**分类与回归树**（**CART**）算法的一部分被引入。尽管名称中有回归二字，回归树并没有使用本章前面描述的线性回归方法，而是基于达到叶节点的示例的平均值来进行预测。
- en: Note
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The CART algorithm is described in detail in Breiman L, Friedman JH, Stone
    CJ, Olshen RA. *Classification and Regression Trees*. Belmont, CA: Chapman and
    Hall; 1984.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 'CART 算法在 Breiman L, Friedman JH, Stone CJ, Olshen RA 的《*分类与回归树*》一书中有详细描述。Belmont,
    CA: Chapman and Hall; 1984年。'
- en: The second type of trees for numeric prediction are known as **model trees**.
    Introduced several years later than regression trees, they are lesser-known, but
    perhaps more powerful. Model trees are grown in much the same way as regression
    trees, but at each leaf, a multiple linear regression model is built from the
    examples reaching that node. Depending on the number of leaf nodes, a model tree
    may build tens or even hundreds of such models. This may make model trees more
    difficult to understand than the equivalent regression tree, with the benefit
    that they may result in a more accurate model.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 第二类用于数值预测的树被称为**模型树**。它们比回归树晚几年引入，虽然不太为人所知，但可能更强大。模型树的生长方式与回归树非常相似，但在每个叶节点上，会基于到达该节点的示例构建一个多元线性回归模型。根据叶节点的数量，模型树可能会构建几十个甚至几百个这样的模型。这可能使得模型树比等效的回归树更难理解，但好处是，它们可能会产生更精确的模型。
- en: Note
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The earliest model tree algorithm, **M5**, is described in Quinlan JR. *Learning
    with continuous classes*. Proceedings of the 5th Australian Joint Conference on
    Artificial Intelligence. 1992:343-348.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 最早的模型树算法，**M5**，在 Quinlan JR 的《*使用连续类别进行学习*》中有描述。1992年，澳大利亚第五届联合人工智能会议论文集：343-348。
- en: Adding regression to trees
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向树中添加回归
- en: 'Trees that can perform numeric prediction offer a compelling yet often overlooked
    alternative to regression modeling. The strengths and weaknesses of regression
    trees and model trees relative to the more common regression methods are listed
    in the following table:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 可以执行数值预测的树提供了一种引人注目但常被忽视的回归建模替代方案。回归树和模型树相对于更常见的回归方法的优缺点在下表中列出：
- en: '| Strengths | Weaknesses |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 优点 | 缺点 |'
- en: '| --- | --- |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '|'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Combines the strengths of decision trees with the ability to model numeric data
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合了决策树的优点和建模数值数据的能力
- en: Does not require the user to specify the model in advance
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无需用户提前指定模型
- en: Uses automatic feature selection, which allows the approach to be used with
    a very large number of features
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自动特征选择，允许该方法应用于非常大量的特征
- en: May fit some types of data much better than linear regression
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能比线性回归更适合某些类型的数据
- en: Does not require knowledge of statistics to interpret the model
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不需要统计学知识来解释模型
- en: '|'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Not as well-known as linear regression
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不像线性回归那样知名
- en: Requires a large amount of training data
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要大量的训练数据
- en: Difficult to determine the overall net effect of individual features on the
    outcome
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 难以确定单个特征对结果的整体净影响
- en: Large trees can become more difficult to interpret than a regression model
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型树可能比回归模型更难以解释
- en: '|'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Though traditional regression methods are typically the first choice for numeric
    prediction tasks, in some cases, numeric decision trees offer distinct advantages.
    For instance, decision trees may be better suited for tasks with many features
    or many complex, non-linear relationships among features and outcome. These situations
    present challenges for regression. Regression modeling also makes assumptions
    about how numeric data is distributed that are often violated in real-world data.
    This is not the case for trees.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然传统的回归方法通常是数值预测任务的首选，但在某些情况下，数值决策树提供了明显的优势。例如，决策树可能更适合具有许多特征或特征与结果之间存在许多复杂的非线性关系的任务。这些情况对回归造成了挑战。回归建模还对数值数据的分布方式做出了假设，而这些假设在现实世界的数据中经常被违反。而这种情况在树中并非如此。
- en: Trees for numeric prediction are built in much the same way as they are for
    classification. Beginning at the root node, the data is partitioned using a divide-and-conquer
    strategy according to the feature that will result in the greatest increase in
    homogeneity in the outcome after a split is performed. In classification trees,
    you will recall that homogeneity is measured by entropy, which is undefined for
    numeric data. Instead, for numeric decision trees, homogeneity is measured by
    statistics such as variance, standard deviation, or absolute deviation from the
    mean.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 用于数值预测的树的构建方式与分类中的方式基本相同。从根节点开始，根据能够在拆分后最大增加结果均匀性的特征使用分治策略对数据进行分区。在分类树中，您会记得均匀性是通过熵来衡量的，但对于数值数据，熵是未定义的。相反，对于数值决策树，均匀性是通过方差、标准偏差或与均值的绝对偏差等统计量来衡量的。
- en: 'One common splitting criterion is called the **Standard Deviation Reduction**
    (**SDR**). It is defined by the following formula:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的拆分标准称为**标准偏差减少**（**SDR**）。它由以下公式定义：
- en: '![Adding regression to trees](img/B03905_06_27.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![向树添加回归](img/B03905_06_27.jpg)'
- en: In this formula, the *sd(T)* function refers to the standard deviation of the
    values in set *T*, while *T[1]*, *T[2]*, ..., *T[n]* are the sets of values resulting
    from a split on a feature. The *|T|* term refers to the number of observations
    in set *T*. Essentially, the formula measures the reduction in standard deviation
    by comparing the standard deviation pre-split to the weighted standard deviation
    post-split.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，*sd(T)*函数指的是集合*T*中值的标准偏差，而*T[1]*、*T[2]*、...、*T[n]*是由特征拆分产生的值集合。*|T|*项指的是集合*T*中的观测数量。本质上，该公式通过比较拆分前的标准偏差与加权后的标准偏差来衡量标准偏差的减少。
- en: 'For example, consider the following case in which a tree is deciding whether
    or not to perform a split on binary feature A or B:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下情况，树正在决定是否在二进制特征A或B上执行拆分：
- en: '![Adding regression to trees](img/B03905_06_28.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![向树添加回归](img/B03905_06_28.jpg)'
- en: 'Using the groups that would result from the proposed splits, we can compute
    the SDR for A and B as follows. The `length()` function used here returns the
    number of elements in a vector. Note that the overall group T is named `tee` to
    avoid overwriting R''s built-in `T()` and `t()` functions:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 使用提议的拆分结果得到的组，我们可以计算如下的A和B的SDR。这里使用的`length()`函数返回向量中的元素数量。请注意，整体组T被命名为`tee`，以避免覆盖R的内置`T()`和`t()`函数：
- en: '[PRE24]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let''s compare the SDR of A against the SDR of B:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较A的SDR和B的SDR：
- en: '[PRE25]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The SDR for the split on feature A was about 1.2 versus 1.4 for the split on
    feature B. Since the standard deviation was reduced more for the split on B, the
    decision tree would use B first. It results in slightly more homogeneous sets
    than with A.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 特征A的拆分的SDR约为1.2，而特征B的拆分的SDR约为1.4。由于B的标准偏差减少更多，决策树将首先使用B。这导致比A更均匀的集合。
- en: Suppose that the tree stopped growing here using this one and only split. A
    regression tree's work is done. It can make predictions for new examples depending
    on whether the example's value on feature B places the example into group *T[1]*
    or *T[2]*. If the example ends up in *T[1]*, the model would predict *mean(bt1)
    = 2*, otherwise it would predict *mean(bt2) = 6.25*.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 假设树在此处停止生长，并仅使用此一次拆分。回归树的工作完成了。它可以根据特征B上的示例值将示例预测为属于组*T[1]*或*T[2]*。如果示例位于*T[1]*中，则模型将预测*mean(bt1)
    = 2*，否则将预测*mean(bt2) = 6.25*。
- en: In contrast, a model tree would go one step further. Using the seven training
    examples falling in group *T[1]* and the eight in *T[2]*, the model tree could
    build a linear regression model of the outcome versus feature A. Note that Feature
    B is of no help in building the regression model because all examples at the leaf
    have the same value of B—they were placed into *T[1]* or *T[2]* according to their
    value of B. The model tree can then make predictions for new examples using either
    of the two linear models.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 与此不同，模型树会更进一步。利用落在组* T[1]*中的七个训练示例和落在* T[2]*中的八个训练示例，模型树可以建立一个线性回归模型，将结果与特征A进行比较。请注意，特征B在建立回归模型时没有帮助，因为所有叶节点中的示例B值相同——它们是根据B值被分配到*
    T[1]*或* T[2]*中的。然后，模型树可以使用这两个线性模型中的任何一个为新示例做出预测。
- en: To further illustrate the differences between these two approaches, let's work
    through a real-world example.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步说明这两种方法之间的差异，让我们通过一个现实世界的例子来说明。
- en: Example – estimating the quality of wines with regression trees and model trees
  id: totrans-299
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 – 使用回归树和模型树估计葡萄酒的质量
- en: Winemaking is a challenging and competitive business that offers the potential
    for great profit. However, there are numerous factors that contribute to the profitability
    of a winery. As an agricultural product, variables as diverse as the weather and
    the growing environment impact the quality of a varietal. The bottling and manufacturing
    can also affect the flavor for better or worse. Even the way the product is marketed,
    from the bottle design to the price point, can affect the customer's perception
    of taste.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 酿酒业是一个具有挑战性且竞争激烈的行业，具有巨大的盈利潜力。然而，葡萄酒厂的盈利能力受到多种因素的影响。作为一种农产品，天气和生长环境等变量会影响葡萄酒的质量。瓶装和生产过程也会对味道产生影响，可能是更好也可能是更差。即便是产品的营销方式，从瓶子设计到定价，也会影响消费者对味道的认知。
- en: As a consequence, the winemaking industry has heavily invested in data collection
    and machine learning methods that may assist with the decision science of winemaking.
    For example, machine learning has been used to discover key differences in the
    chemical composition of wines from different regions, or to identify the chemical
    factors that lead a wine to taste sweeter.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，酿酒行业在数据收集和机器学习方法上的投资非常巨大，这些方法有助于酿酒决策科学。例如，机器学习已经被用于发现不同地区葡萄酒化学成分的关键差异，或者识别导致葡萄酒味道更甜的化学因素。
- en: More recently, machine learning has been employed to assist with rating the
    quality of wine—a notoriously difficult task. A review written by a renowned wine
    critic often determines whether the product ends up on the top or bottom shelf,
    in spite of the fact that even the expert judges are inconsistent when rating
    a wine in a blinded test.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，机器学习已被用来协助葡萄酒质量的评分——这是一项著名的困难任务。著名酒评家的评论往往决定了产品最终是上架还是下架，尽管即使是专家在盲测中评分时也常常表现出不一致性。
- en: In this case study, we will use regression trees and model trees to create a
    system capable of mimicking expert ratings of wine. Because trees result in a
    model that is readily understood, this can allow the winemakers to identify the
    key factors that contribute to better-rated wines. Perhaps more importantly, the
    system does not suffer from the human elements of tasting, such as the rater's
    mood or palate fatigue. Computer-aided wine testing may therefore result in a
    better product as well as more objective, consistent, and fair ratings.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例研究中，我们将使用回归树和模型树创建一个系统，能够模仿专家对葡萄酒的评分。由于树结构生成的模型易于理解，这可以帮助酿酒师识别出对高评分葡萄酒至关重要的因素。或许更重要的是，该系统不受品酒时人类因素的影响，比如评分者的情绪或味觉疲劳。因此，计算机辅助的葡萄酒测试可能会带来更好的产品，并且评分更加客观、一致和公平。
- en: Step 1 – collecting data
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤1 – 收集数据
- en: To develop the wine rating model, we will use data donated to the UCI Machine
    Learning Data Repository ([http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml))
    by P. Cortez, A. Cerdeira, F. Almeida, T. Matos, and J. Reis. The data include
    examples of red and white Vinho Verde wines from Portugal—one of the world's leading
    wine-producing countries. Because the factors that contribute to a highly rated
    wine may differ between the red and white varieties, for this analysis we will
    examine only the more popular white wines.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开发葡萄酒评级模型，我们将使用P. Cortez, A. Cerdeira, F. Almeida, T. Matos和J. Reis捐赠给UCI机器学习数据库的数据（[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)）。这些数据包括来自葡萄牙的红葡萄酒和白葡萄酒样本—葡萄牙是世界领先的葡萄酒生产国之一。由于影响葡萄酒高评分的因素可能在红葡萄酒和白葡萄酒之间有所不同，因此在本次分析中，我们只会考察更受欢迎的白葡萄酒。
- en: Tip
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: To follow along with this example, download the `whitewines.csv` file from the
    Packt Publishing website and save it to your R working directory. The `redwines.csv`
    file is also available in case you would like to explore this data on your own.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随本示例，请从Packt Publishing网站下载`whitewines.csv`文件，并将其保存到您的R工作目录中。如果您希望自行探索数据，`redwines.csv`文件也可以下载。
- en: The white wine data includes information on 11 chemical properties of 4,898
    wine samples. For each wine, a laboratory analysis measured characteristics such
    as acidity, sugar content, chlorides, sulfur, alcohol, pH, and density. The samples
    were then rated in a blind tasting by panels of no less than three judges on a
    quality scale ranging from zero (very bad) to 10 (excellent). In the case of judges
    disagreeing on the rating, the median value was used.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 白葡萄酒数据包括4,898个葡萄酒样本的11个化学属性信息。每个样本通过实验室分析测量了酸度、糖分、氯化物、硫磺、酒精、pH值和密度等特性。然后，这些样本通过不低于三名评委的盲品进行质量评分，评分范围从0（非常差）到10（优秀）。如果评委们对评分有异议，则使用中位数值。
- en: 'The study by Cortez evaluated the ability of three machine learning approaches
    to model the wine data: multiple regression, artificial neural networks, and support
    vector machines. We covered multiple regression earlier in this chapter, and we
    will learn about neural networks and support vector machines in [Chapter 7](ch07.html
    "Chapter 7. Black Box Methods – Neural Networks and Support Vector Machines"),
    *Black Box Methods – Neural Networks and Support Vector Machines*. The study found
    that the support vector machine offered significantly better results than the
    linear regression model. However, unlike regression, the support vector machine
    model is difficult to interpret. Using regression trees and model trees, we may
    be able to improve the regression results while still having a model that is easy
    to understand.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: Cortez的研究评估了三种机器学习方法在建模葡萄酒数据方面的能力：多元回归、人工神经网络和支持向量机。我们在本章早些时候已经介绍了多元回归，而我们将在[第7章](ch07.html
    "第7章. 黑箱方法 – 神经网络与支持向量机")中学习神经网络和支持向量机，*黑箱方法 – 神经网络与支持向量机*。研究发现，支持向量机比线性回归模型提供了显著更好的结果。然而，与回归模型不同，支持向量机模型较难解释。通过使用回归树和模型树，我们可能能够在改进回归结果的同时，仍然保持一个易于理解的模型。
- en: Note
  id: totrans-310
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: To read more about the wine study described here, please refer to Cortez P,
    Cerdeira A, Almeida F, Matos T, Reis J. *Modeling wine preferences by data mining
    from physicochemical properties*. Decision Support Systems*.* 2009; 47:547-553.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于这里描述的葡萄酒研究的信息，请参阅Cortez P, Cerdeira A, Almeida F, Matos T, Reis J. *通过物理化学性质的数据挖掘建模葡萄酒偏好*。决策支持系统*。2009;
    47:547-553。
- en: Step 2 – exploring and preparing the data
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步 – 探索和准备数据
- en: 'As usual, we will use the `read.csv()` function to load the data into R. Since
    all of the features are numeric, we can safely ignore the `stringsAsFactors` parameter:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 如常，我们将使用`read.csv()`函数将数据加载到R中。由于所有特征都是数值型的，因此我们可以安全地忽略`stringsAsFactors`参数：
- en: '[PRE26]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The wine data includes 11 features and the quality outcome, as follows:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 葡萄酒数据包括11个特征和质量结果，如下所示：
- en: '[PRE27]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Compared with other types of machine learning models, one of the advantages
    of trees is that they can handle many types of data without preprocessing. This
    means we do not need to normalize or standardize the features.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他类型的机器学习模型相比，树模型的一个优势是能够处理多种类型的数据而无需预处理。这意味着我们不需要对特征进行归一化或标准化。
- en: 'However, a bit of effort to examine the distribution of the outcome variable
    is needed to inform our evaluation of the model''s performance. For instance,
    suppose that there was a very little variation in quality from wine-to-wine, or
    that wines fell into a bimodal distribution: either very good or very bad. To
    check for such extremes, we can examine the distribution of quality using a histogram:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要稍微努力检查结果变量的分布，以便更好地评估模型的表现。例如，假设酒的质量变化很小，或者酒的质量呈双峰分布：要么非常好，要么非常差。为了检查这些极端情况，我们可以使用直方图检查质量分布：
- en: '[PRE28]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This produces the following figure:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下图形：
- en: '![Step 2 – exploring and preparing the data](img/B03905_06_29.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![第二步 – 探索和准备数据](img/B03905_06_29.jpg)'
- en: The wine quality values appear to follow a fairly normal, bell-shaped distribution,
    centered around a value of six. This makes sense intuitively because most wines
    are of average quality; few are particularly bad or good. Although the results
    are not shown here, it is also useful to examine the `summary(wine)` output for
    outliers or other potential data problems. Even though trees are fairly robust
    with messy data, it is always prudent to check for severe problems. For now, we'll
    assume that the data is reliable.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 酒的质量值似乎遵循一个相当正常的钟形分布，集中在六的值附近。这是直观合理的，因为大多数酒的质量是中等的；很少有酒特别差或者特别好。尽管这里没有展示结果，但检查
    `summary(wine)` 输出中的异常值或其他潜在的数据问题也是很有用的。尽管树模型对杂乱数据相当稳健，但检查严重问题总是明智的。现在，我们假设数据是可靠的。
- en: 'Our last step then is to divide into training and testing datasets. Since the
    `wine` data set was already sorted into random order, we can partition into two
    sets of contiguous rows as follows:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最后一步是将数据划分为训练集和测试集。由于 `wine` 数据集已经是随机排序的，我们可以按照以下方式将其分成两组连续的行：
- en: '[PRE29]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In order to mirror the conditions used by Cortez, we used sets of 75 percent
    and 25 percent for training and testing, respectively. We'll evaluate the performance
    of our tree-based models on the testing data to see if we can obtain results comparable
    to the prior research study.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与 Cortez 使用的条件相符，我们分别使用了 75% 和 25% 的数据集进行训练和测试。我们将评估基于树的模型在测试数据上的表现，以查看我们是否能获得与先前研究相当的结果。
- en: Step 3 – training a model on the data
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三步 – 在数据上训练模型
- en: We will begin by training a regression tree model. Although almost any implementation
    of decision trees can be used to perform regression tree modeling, the `rpart`
    (recursive partitioning) package offers the most faithful implementation of regression
    trees as they were described by the CART team. As the classic R implementation
    of CART, the `rpart` package is also well-documented and supported with functions
    for visualizing and evaluating the `rpart` models.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先训练一棵回归树模型。尽管几乎任何决策树的实现都可以用于回归树建模，但 `rpart`（递归分区）包提供了最忠实的回归树实现，正如 CART 团队所描述的那样。作为
    CART 的经典 R 实现，`rpart` 包也有很好的文档支持，并提供了可视化和评估 `rpart` 模型的函数。
- en: Install the `rpart` package using the `install.packages("rpart")` command. It
    can then be loaded into your R session using the `library(rpart)` command. The
    following syntax will train a tree using the default settings, which typically
    work fairly well. If you need more finely-tuned settings, refer to the documentation
    for the control parameters using the `?rpart.control` command.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `install.packages("rpart")` 命令安装 `rpart` 包。然后可以使用 `library(rpart)` 命令将其加载到
    R 会话中。以下语法将使用默认设置训练一棵树，这些设置通常工作得相当好。如果需要更精细的设置，请使用 `?rpart.control` 命令查看控制参数的文档。
- en: '![Step 3 – training a model on the data](img/B03905_06_30.jpg)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![第三步 – 在数据上训练模型](img/B03905_06_30.jpg)'
- en: 'Using the R formula interface, we can specify `quality` as the outcome variable
    and use the dot notation to allow all the other columns in the `wine_train` data
    frame to be used as predictors. The resulting regression tree model object is
    named `m.rpart` to distinguish it from the model tree that we will train later:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 R 公式接口，我们可以指定 `quality` 作为结果变量，并使用点符号使得 `wine_train` 数据框中的所有其他列作为预测变量。生成的回归树模型对象命名为
    `m.rpart`，以便与我们稍后训练的模型树区分开来：
- en: '[PRE30]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'For basic information about the tree, simply type the name of the model object:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取树的基本信息，只需输入模型对象的名称：
- en: '[PRE31]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: For each node in the tree, the number of examples reaching the decision point
    is listed. For instance, all 3,750 examples begin at the root node, of which 2,372
    have `alcohol < 10.85` and 1,378 have `alcohol >= 10.85`. Because alcohol was
    used first in the tree, it is the single most important predictor of wine quality.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 对于树中的每个节点，都会列出到达该决策点的示例数量。例如，所有3,750个示例从根节点开始，其中2,372个示例满足`alcohol < 10.85`，1,378个示例满足`alcohol
    >= 10.85`。由于酒精在树中首先被使用，它是预测葡萄酒质量的最重要因素。
- en: Nodes indicated by `*` are terminal or leaf nodes, which means that they result
    in a prediction (listed here as `yval`). For example, node 5 has a `yval` of 5.971091\.
    When the tree is used for predictions, any wine samples with `alcohol < 10.85`
    and `volatile.acidity < 0.2275` would therefore be predicted to have a quality
    value of 5.97.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 由`*`指示的节点是终端节点或叶节点，这意味着它们会产生预测结果（在此列为`yval`）。例如，节点5的`yval`为5.971091。当使用该树进行预测时，任何酒精含量`alcohol
    < 10.85`且挥发性酸度`volatile.acidity < 0.2275`的葡萄酒样本，预测的质量值为5.97。
- en: A more detailed summary of the tree's fit, including the mean squared error
    for each of the nodes and an overall measure of feature importance, can be obtained
    using the `summary(m.rpart)` command.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`summary(m.rpart)`命令获取树的拟合结果的更详细摘要，包括每个节点的均方误差和特征重要性的总体度量。
- en: Visualizing decision trees
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化决策树
- en: Although the tree can be understood using only the preceding output, it is often
    more readily understood using visualization. The `rpart.plot` package by Stephen
    Milborrow provides an easy-to-use function that produces publication-quality decision
    trees.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可以仅通过前面的输出理解树的结构，但通常使用可视化会更容易理解。Stephen Milborrow的`rpart.plot`包提供了一个易于使用的函数，可以生成高质量的决策树图。
- en: Note
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more information on `rpart.plot`, including additional examples of the types
    of decision tree diagrams that the function can produce, refer to the author's
    website at [http://www.milbo.org/rpart-plot/](http://www.milbo.org/rpart-plot/).
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`rpart.plot`的更多信息，包括该函数可以生成的不同类型决策树图的其他示例，请访问作者的网站：[http://www.milbo.org/rpart-plot/](http://www.milbo.org/rpart-plot/)。
- en: 'After installing the package using the `install.packages("rpart.plot")` command,
    the `rpart.plot()` function produces a tree diagram from any `rpart` model object.
    The following commands plot the regression tree we built earlier:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`install.packages("rpart.plot")`命令安装该包后，`rpart.plot()`函数可以从任何`rpart`模型对象生成树形图。以下命令绘制了我们之前构建的回归树：
- en: '[PRE32]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The resulting tree diagram is as follows:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的树形图如下所示：
- en: '![Visualizing decision trees](img/B03905_06_31.jpg)'
  id: totrans-344
  prefs: []
  type: TYPE_IMG
  zh: '![可视化决策树](img/B03905_06_31.jpg)'
- en: 'In addition to the `digits` parameter that controls the number of numeric digits
    to include in the diagram, many other aspects of the visualization can be adjusted.
    The following command shows just a few of the useful options: The `fallen.leaves`
    parameter forces the leaf nodes to be aligned at the bottom of the plot, while
    the `type` and `extra` parameters affect the way the decisions and nodes are labeled:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 除了控制图中数字位数的`digits`参数外，许多可视化的其他方面也可以进行调整。以下命令展示了几种有用的选项：`fallen.leaves`参数强制叶节点对齐到图的底部，而`type`和`extra`参数则影响决策和节点的标签方式：
- en: '[PRE33]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The result of these changes is a very different looking tree diagram:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 这些更改的结果是一个外观截然不同的树形图：
- en: '![Visualizing decision trees](img/B03905_06_32.jpg)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
  zh: '![可视化决策树](img/B03905_06_32.jpg)'
- en: Visualizations like these may assist with the dissemination of regression tree
    results, as they are readily understood even without a mathematics background.
    In both cases, the numbers shown in the leaf nodes are the predicted values for
    the examples reaching that node. Showing the diagram to the wine producers may
    thus help to identify the key factors that predict the higher rated wines.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样的可视化图可能有助于回归树结果的传播，因为即使没有数学背景的人也能轻松理解。在这两种情况下，叶节点中显示的数字是到达该节点的示例的预测值。因此，将图表展示给葡萄酒生产者，可能有助于确定预测高评分葡萄酒的关键因素。
- en: Step 4 – evaluating model performance
  id: totrans-350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4步 – 评估模型性能
- en: 'To use the regression tree model to make predictions on the test data, we use
    the `predict()` function. By default, this returns the estimated numeric value
    for the outcome variable, which we''ll save in a vector named `p.rpart`:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用回归树模型对测试数据进行预测，我们使用`predict()`函数。默认情况下，它返回结果变量的估计数值，我们将其保存在名为`p.rpart`的向量中：
- en: '[PRE34]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'A quick look at the summary statistics of our predictions suggests a potential
    problem; the predictions fall on a much narrower range than the true values:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 快速查看我们预测的摘要统计数据表明了一个潜在的问题；预测值的范围明显比真实值要窄：
- en: '[PRE35]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This finding suggests that the model is not correctly identifying the extreme
    cases, in particular the best and worst wines. On the other hand, between the
    first and third quartile, we may be doing well.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 这一发现表明模型未能正确识别极端情况，尤其是最好的和最差的葡萄酒。另一方面，在第一四分位数和第三四分位数之间，我们可能做得很好。
- en: 'The correlation between the predicted and actual quality values provides a
    simple way to gauge the model''s performance. Recall that the `cor()` function
    can be used to measure the relationship between two equal-length vectors. We''ll
    use this to compare how well the predicted values correspond to the true values:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 预测值与实际质量值之间的相关性提供了一种简单的方法来衡量模型的表现。请记住，`cor()`函数可用于衡量两个等长向量之间的关系。我们将使用它来比较预测值与真实值的对应情况：
- en: '[PRE36]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: A correlation of 0.54 is certainly acceptable. However, the correlation only
    measures how strongly the predictions are related to the true value; it is not
    a measure of how far off the predictions were from the true values.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 0.54的相关性是完全可以接受的。然而，相关性仅仅衡量预测值与真实值之间的关联程度；它并不能衡量预测值与真实值之间的差距。
- en: Measuring performance with the mean absolute error
  id: totrans-359
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用平均绝对误差衡量性能
- en: 'Another way to think about the model''s performance is to consider how far,
    on average, its prediction was from the true value. This measurement is called
    the **mean absolute error** (**MAE**). The equation for MAE is as follows, where
    *n* indicates the number of predictions and *e[i]* indicates the error for prediction
    *i*:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种衡量模型表现的方法是考虑其预测与真实值之间的平均偏差。这一度量被称为**平均绝对误差**（**MAE**）。MAE的计算公式如下，其中*n*表示预测次数，*e[i]*表示第i个预测的误差：
- en: '![Measuring performance with the mean absolute error](img/B03905_06_33.jpg)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![使用平均绝对误差衡量性能](img/B03905_06_33.jpg)'
- en: 'As the name implies, this equation takes the mean of the absolute value of
    the errors. Since the error is just the difference between the predicted and actual
    values, we can create a simple `MAE()` function as follows:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 正如名字所示，这个方程计算误差的绝对值的平均值。由于误差仅仅是预测值和实际值之间的差异，我们可以创建一个简单的`MAE()`函数，如下所示：
- en: '[PRE37]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The MAE for our predictions is then:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的预测的MAE为：
- en: '[PRE38]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This implies that, on average, the difference between our model's predictions
    and the true quality score was about 0.59\. On a quality scale from zero to 10,
    this seems to suggest that our model is doing fairly well.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，平均而言，我们模型的预测值与真实质量评分之间的差异大约为0.59。在从零到10的质量评分尺度上，这似乎表明我们的模型表现相当不错。
- en: On the other hand, recall that most wines were neither very good nor very bad;
    the typical quality score was around five to six. Therefore, a classifier that
    did nothing but predict the mean value may still do fairly well according to this
    metric.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，请记住，大多数葡萄酒既不特别好也不特别差；典型的质量评分大约在五到六之间。因此，仅仅预测平均值的分类器根据这个标准仍然可能表现得相当好。
- en: 'The mean quality rating in the training data is as follows:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据中的平均质量评分如下：
- en: '[PRE39]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'If we predicted the value 5.87 for every wine sample, we would have a mean
    absolute error of only about 0.67:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对每个葡萄酒样本都预测值为5.87，我们的平均绝对误差将仅约为0.67：
- en: '[PRE40]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Our regression tree (*MAE = 0.59*) comes closer on average to the true quality
    score than the imputed mean (*MAE = 0.67*), but not by much. In comparison, Cortez
    reported an MAE of 0.58 for the neural network model and an MAE of 0.45 for the
    support vector machine. This suggests that there is room for improvement.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的回归树（*MAE = 0.59*）的平均预测结果比填充平均值（*MAE = 0.67*）更接近真实质量评分，但差距不大。相比之下，Cortez报告了神经网络模型的MAE为0.58，支持向量机的MAE为0.45。这表明仍有改进的空间。
- en: Step 5 – improving model performance
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 5 – 改进模型性能
- en: To improve the performance of our learner, let's try to build a model tree.
    Recall that a model tree improves on regression trees by replacing the leaf nodes
    with regression models. This often results in more accurate results than regression
    trees, which use only a single value for prediction at the leaf nodes.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高学习器的性能，我们可以尝试构建一个模型树。回想一下，模型树通过将叶节点替换为回归模型，从而改进了回归树。这通常会比回归树产生更准确的结果，因为回归树在叶节点使用的只是一个单一的预测值。
- en: The current state-of-the-art in model trees is the **M5' algorithm** (**M5-prime**)
    by Y. Wang and I.H. Witten, which is a variant of the original M5 model tree algorithm
    proposed by J.R. Quinlan in 1992.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 当前模型树的最新技术是**M5'算法**（**M5-prime**），由Y. Wang和I.H. Witten提出，它是J.R. Quinlan于1992年提出的原始M5模型树算法的变种。
- en: Note
  id: totrans-376
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more information on the M5' algorithm, see Wang Y, Witten IH. *Induction
    of model trees for predicting continuous classes*. Proceedings of the Poster Papers
    of the European Conference on Machine Learning. 1997.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多有关M5'算法的信息，请参阅Wang Y, Witten IH. *用于预测连续类别的模型树诱导*。欧洲机器学习会议海报论文集，1997年。
- en: The M5 algorithm is available in R via the `RWeka` package and the `M5P()` function.
    The syntax of this function is shown in the following table. Be sure to install
    the `RWeka` package if you haven't already. Because of its dependence on Java,
    the installation instructions are included in [Chapter 1](ch01.html "Chapter 1. Introducing
    Machine Learning"), *Introducing Machine Learning*.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: M5算法可以通过R中的`RWeka`包和`M5P()`函数来实现。该函数的语法如下表所示。如果你还没有安装`RWeka`包，请确保先安装。由于它依赖于Java，安装说明已包含在[第1章](ch01.html
    "第1章. 引入机器学习")中，*引入机器学习*。
- en: '![Step 5 – improving model performance](img/B03905_06_34.jpg)'
  id: totrans-379
  prefs: []
  type: TYPE_IMG
  zh: '![步骤5 – 改进模型性能](img/B03905_06_34.jpg)'
- en: 'We''ll fit the model tree using essentially the same syntax as we used for
    the regression tree:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与回归树相同的语法来拟合模型树：
- en: '[PRE41]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The tree itself can be examined by typing its name. In this case, the tree
    is very large and only the first few lines of output are shown:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过输入树的名称来检查树本身。在这种情况下，树非常大，只有前几行输出会显示出来：
- en: '[PRE42]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: You will note that the splits are very similar to the regression tree that we
    built earlier. Alcohol is the most important variable, followed by volatile acidity
    and free sulfur dioxide. A key difference, however, is that the nodes terminate
    not in a numeric prediction, but a linear model (shown here as `LM1` and `LM2`).
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，这些分裂与我们之前构建的回归树非常相似。酒精是最重要的变量，其次是挥发性酸度和游离二氧化硫。然而，一个关键的区别是，节点的终止不是数值预测，而是一个线性模型（在此显示为`LM1`和`LM2`）。
- en: 'The linear models themselves are shown later in the output. For instance, the
    model for `LM1` is shown in the forthcoming output. The values can be interpreted
    exactly the same as the multiple regression models we built earlier in this chapter.
    Each number is the net effect of the associated feature on the predicted wine
    quality. The coefficient of `0.266` for fixed acidity implies that for an increase
    of 1 unit of acidity, the wine quality is expected to increase by `0.266`:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型本身会在输出中显示。例如，`LM1`的模型将在接下来的输出中显示。这些值的解释方式与我们在本章前面构建的多重回归模型完全相同。每个数字表示相关特征对预测酒质的净效应。固定酸度的系数为`0.266`，意味着酸度增加1单位时，预计酒质将增加`0.266`：
- en: '[PRE43]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: It is important to note that the effects estimated by `LM1` apply only to wine
    samples reaching this node; a total of 36 linear models were built in this model
    tree, each with different estimates of the impact of fixed acidity and the other
    10 features.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，由`LM1`估算的效果仅适用于达到该节点的酒样；在这个模型树中总共构建了36个线性模型，每个模型都对固定酸度和其他10个特征的影响进行了不同的估算。
- en: 'For statistics on how well the model fits the training data, the `summary()`
    function can be applied to the M5P model. However, note that since these statistics
    are based on the training data, they should be used only as a rough diagnostic:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 若要查看模型拟合训练数据的统计信息，可以对M5P模型应用`summary()`函数。然而，请注意，由于这些统计信息是基于训练数据的，因此它们仅应作为粗略的诊断依据：
- en: '[PRE44]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Instead, we''ll look at how well the model performs on the unseen test data.
    The `predict()` function gets us a vector of predicted values:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们将查看模型在未见过的测试数据上的表现。`predict()`函数为我们提供了一组预测值：
- en: '[PRE45]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The model tree appears to be predicting a wider range of values than the regression
    tree:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 模型树似乎预测了比回归树更广泛的值范围：
- en: '[PRE46]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The correlation also seems to be substantially higher:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性似乎也显著更高：
- en: '[PRE47]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Furthermore, the model has slightly reduced the mean absolute error:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该模型略微减少了平均绝对误差：
- en: '[PRE48]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Although we did not improve a great deal beyond the regression tree, we surpassed
    the performance of the neural network model published by Cortez, and we are getting
    closer to the published mean absolute error value of 0.45 for the support vector
    machine model, all by using a much simpler learning method.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在回归树的基础上并没有取得太大进展，但我们超越了Cortez发布的神经网络模型的表现，并且我们逐渐接近支持向量机模型发布的平均绝对误差值0.45，所有这些都是通过使用一种更简单的学习方法实现的。
- en: Tip
  id: totrans-399
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Not surprisingly, we have confirmed that predicting the quality of wines is
    a difficult problem; wine tasting, after all, is inherently subjective. If you
    would like additional practice, you may try revisiting this problem after reading
    [Chapter 11](ch11.html "Chapter 11. Improving Model Performance"), *Improving
    Model Performance*, which covers additional techniques that may lead to better
    results.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不意外，我们确认预测葡萄酒质量是一个困难的问题；毕竟，葡萄酒品鉴本质上是主观的。如果你想要额外练习，可以在阅读[第11章](ch11.html "第11章：提高模型性能")，*提高模型性能*后再次尝试解决这个问题，里面涵盖了一些可能带来更好结果的技术。
- en: Summary
  id: totrans-401
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we studied two methods for modeling numeric data. The first
    method, linear regression, involves fitting straight lines to data. The second
    method uses decision trees for numeric prediction. The latter comes in two forms:
    regression trees, which use the average value of examples at leaf nodes to make
    numeric predictions; and model trees, which build a regression model at each leaf
    node in a hybrid approach that is, in some ways, the best of both worlds.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们研究了两种建模数值数据的方法。第一种方法是线性回归，它涉及将直线拟合到数据上。第二种方法使用决策树进行数值预测。后者有两种形式：回归树，它通过叶节点处示例的平均值来进行数值预测；以及模型树，它在每个叶节点构建一个回归模型，这是一种混合方法，在某些方面是两者的最佳结合。
- en: We used linear regression modeling to calculate the expected medical costs for
    various segments of the population. Because the relationship between the features
    and the target variable are well-described by the estimated regression model,
    we were able to identify certain demographics, such as smokers and the obese,
    who may need to be charged higher insurance rates to cover the higher-than-average
    medical expenses.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用线性回归模型来计算不同人口群体的预期医疗费用。由于特征与目标变量之间的关系通过估算的回归模型得到了很好的描述，我们能够识别出某些人群，如吸烟者和肥胖者，可能需要被收取更高的保险费率，以覆盖高于平均水平的医疗费用。
- en: Regression trees and model trees were used to model the subjective quality of
    wines from measureable characteristics. In doing so, we learned how regression
    trees offer a simple way to explain the relationship between features and a numeric
    outcome, but the more complex model trees may be more accurate. Along the way,
    we learned several methods for evaluating the performance of numeric models.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 回归树和模型树被用来根据可衡量的特征对葡萄酒的主观质量进行建模。在此过程中，我们了解到回归树提供了一种简单的方法来解释特征与数值结果之间的关系，但更复杂的模型树可能更为准确。在这个过程中，我们学习了几种评估数值模型表现的方法。
- en: In stark contrast to this chapter, which covered machine learning methods that
    result in a clear understanding of the relationships between the input and the
    output, the next chapter covers methods that result in nearly-incomprehensible
    models. The upside is that they are extremely powerful techniques—among the most
    powerful stock classifiers—that can be applied to both classification and numeric
    prediction problems.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 与本章涉及的机器学习方法（这些方法能够清晰地理解输入与输出之间的关系）形成鲜明对比的是，下章将介绍一些导致近乎难以理解的模型的方法。其优点是，这些方法是极为强大的技术——是最强大的股票分类器之一——可以应用于分类和数值预测问题。
