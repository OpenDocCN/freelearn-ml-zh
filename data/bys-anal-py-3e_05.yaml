- en: ChapterÂ 6
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬6ç« 
- en: Modeling with Bambi
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Bambiå»ºæ¨¡
- en: A good tool improves the way you work. A great tool improves the way you think.
    â€“ Jeff Duntemann
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸€ä»¶å¥½å·¥å…·èƒ½æ”¹å–„ä½ çš„å·¥ä½œæ–¹å¼ï¼Œä¸€ä»¶ä¼Ÿå¤§çš„å·¥å…·èƒ½æ”¹å–„ä½ çš„æ€ç»´æ–¹å¼ã€‚â€”â€”Jeff Duntemann
- en: In *Chapter [4](CH04.xhtml#x1-760004)*, we described the basic ingredients of
    linear regression models and how to generalize them to better fit our needs. In
    this chapter, we are going to keep learning about linear models, but this time,
    we are going to work with Bambi [[Capretto etÂ al.](Bibliography.xhtml#XCapretto_2022),Â [2022](Bibliography.xhtml#XCapretto_2022)],
    a high-level Bayesian model-building interface written on top of PyMC. Bambi is
    designed to make it extremely easy to fit linear models, including hierarchical
    ones. We will see that Bambiâ€™s domain is more comprehensive than just linear models.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*ç¬¬[4ç« ](CH04.xhtml#x1-760004)*ä¸­ï¼Œæˆ‘ä»¬æè¿°äº†çº¿æ€§å›å½’æ¨¡å‹çš„åŸºæœ¬æˆåˆ†ä»¥åŠå¦‚ä½•å°†å…¶æ¨å¹¿ä»¥æ›´å¥½åœ°é€‚åº”æˆ‘ä»¬çš„éœ€æ±‚ã€‚åœ¨è¿™ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†ç»§ç»­å­¦ä¹ çº¿æ€§æ¨¡å‹ï¼Œä½†è¿™æ¬¡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Bambi
    [[Capretto et al.](Bibliography.xhtml#XCapretto_2022), [2022](Bibliography.xhtml#XCapretto_2022)]ï¼Œä¸€ä¸ªåŸºäºPyMCæ„å»ºçš„é«˜å±‚è´å¶æ–¯æ¨¡å‹æ„å»ºæ¥å£ã€‚Bambiæ—¨åœ¨ä½¿æ‹Ÿåˆçº¿æ€§æ¨¡å‹ï¼ŒåŒ…æ‹¬åˆ†å±‚æ¨¡å‹ï¼Œå˜å¾—æå…¶ç®€å•ã€‚æˆ‘ä»¬å°†çœ‹åˆ°Bambiçš„é¢†åŸŸä¸ä»…é™äºçº¿æ€§æ¨¡å‹ã€‚
- en: 'We are going to learn about:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å­¦ä¹ ä»¥ä¸‹å†…å®¹ï¼š
- en: Using Bambi to build and fit models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Bambiæ„å»ºå¹¶æ‹Ÿåˆæ¨¡å‹
- en: Analyzing results with Bambi
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Bambiåˆ†æç»“æœ
- en: Polynomial regression and splines
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼å›å½’ä¸æ ·æ¡å‡½æ•°
- en: Distributional models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†å¸ƒæ¨¡å‹
- en: Categorical predictors
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†ç±»é¢„æµ‹å˜é‡
- en: Interactions
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº¤äº’ä½œç”¨
- en: Variable selection with Kulprit
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Kulpritè¿›è¡Œå˜é‡é€‰æ‹©
- en: 6.1 One syntax to rule them all
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 ä¸€ç§è¯­æ³•è§£å†³æ‰€æœ‰é—®é¢˜
- en: PyMC has a very simple and expressive syntax that allows us to build arbitrary
    models. Thatâ€™s usually a blessing, but it can be a burden too. Bambi instead focuses
    on regression models, and this restriction leads to a more focused syntax and
    features, as we will see.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: PyMCæœ‰ä¸€ä¸ªéå¸¸ç®€å•è€Œå¯Œæœ‰è¡¨ç°åŠ›çš„è¯­æ³•ï¼Œå®ƒå…è®¸æˆ‘ä»¬æ„å»ºä»»æ„æ¨¡å‹ã€‚è¿™é€šå¸¸æ˜¯ä¸€ä¸ªç¦éŸ³ï¼Œä½†æœ‰æ—¶ä¹Ÿå¯èƒ½æˆä¸ºè´Ÿæ‹…ã€‚Bambiåˆ™ä¸“æ³¨äºå›å½’æ¨¡å‹ï¼Œè¿™ç§é™åˆ¶ä½¿å¾—è¯­æ³•å’ŒåŠŸèƒ½æ›´åŠ ä¸“æ³¨ï¼Œæ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„é‚£æ ·ã€‚
- en: Bambi uses a Wilkinson-formula syntax similar to the one used by many R packages
    like nlme, lme4, and brms. Letâ€™s assume `data` is a pandas DataFrame like the
    one shown in *Table [6.1](#x1-121002r1)*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Bambiä½¿ç”¨äº†ç±»ä¼¼è®¸å¤šRåŒ…ï¼ˆå¦‚nlmeã€lme4å’Œbrmsï¼‰æ‰€ç”¨çš„Wilkinsonå…¬å¼è¯­æ³•ã€‚å‡è®¾`data`æ˜¯ä¸€ä¸ªåƒ*è¡¨æ ¼[6.1](#x1-121002r1)*ä¸­å±•ç¤ºçš„é‚£æ ·çš„pandas
    DataFrameã€‚
- en: '|  | *y* | *x* | *z* | *g* |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '|  | *y* | *x* | *z* | *g* |'
- en: '| 0 | -0.633494 | -0.196436 | -0.355148 | Group A |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 0 | -0.633494 | -0.196436 | -0.355148 | Aç»„ |'
- en: '| 1 | 2.32684 | 0.0163941 | -1.22847 | Group B |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2.32684 | 0.0163941 | -1.22847 | Bç»„ |'
- en: '| 2 | 0.999604 | 0.107602 | -0.391528 | Group C |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.999604 | 0.107602 | -0.391528 | Cç»„ |'
- en: '| 3 | -0.119111 | 0.804268 | 0.967253 | Group A |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 3 | -0.119111 | 0.804268 | 0.967253 | Aç»„ |'
- en: '| 4 | 2.07504 | 0.991417 | 0.590832 | Group B |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 2.07504 | 0.991417 | 0.590832 | Bç»„ |'
- en: '| 5 | -0.412135 | 0.691132 | -2.13044 | Group C |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 5 | -0.412135 | 0.691132 | -2.13044 | Cç»„ |'
- en: '**TableÂ 6.1**: A dummy pandas DataFrame'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¡¨æ ¼ 6.1**ï¼šä¸€ä¸ªç¤ºä¾‹pandas DataFrame'
- en: 'Using this data, we want to build a linear model that predicts `y` from `x`.
    Using PyMC, we would do something like the model in the following code block:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è¿™äº›æ•°æ®ï¼Œæˆ‘ä»¬æƒ³è¦æ„å»ºä¸€ä¸ªä»`x`é¢„æµ‹`y`çš„çº¿æ€§æ¨¡å‹ã€‚ä½¿ç”¨PyMCï¼Œæˆ‘ä»¬ä¼šåšç±»ä¼¼ä»¥ä¸‹ä»£ç å—ä¸­çš„æ¨¡å‹ï¼š
- en: '**CodeÂ 6.1**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.1**'
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The formula syntax used by Bambi allows us to define an equivalent model in
    a much more compact way:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Bambiä½¿ç”¨çš„å…¬å¼è¯­æ³•è®©æˆ‘ä»¬å¯ä»¥æ›´ç´§å‡‘åœ°å®šä¹‰ä¸€ä¸ªç­‰æ•ˆçš„æ¨¡å‹ï¼š
- en: '**CodeÂ 6.2**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.2**'
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'On the left side of the tilde (âˆ¼), we have the dependent variable, and on the
    right side, the independent variable(s). With this syntax, we are just specifying
    the mean (*Î¼* in the PyMCâ€™s model `lm`). By default, Bambi assumes the likelihood
    is Gaussian; you can change this with the `family` argument. The formula syntax
    does not specify priors distribution, just how the dependent and independent variables
    are related. Bambi will automatically define (very) weakly informative priors
    for us. We can get more information by printing a Bambi model. If you print `a_model`,
    you should get something like this:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ³¢æµªç¬¦å·ï¼ˆâˆ¼ï¼‰çš„å·¦ä¾§æ˜¯å› å˜é‡ï¼Œå³ä¾§æ˜¯è‡ªå˜é‡ï¼ˆä»¬ï¼‰ã€‚é€šè¿‡è¿™ç§è¯­æ³•ï¼Œæˆ‘ä»¬åªæ˜¯æŒ‡å®šäº†å‡å€¼ï¼ˆåœ¨PyMCæ¨¡å‹`lm`ä¸­çš„*Î¼*ï¼‰ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒBambiå‡è®¾ä¼¼ç„¶å‡½æ•°æ˜¯é«˜æ–¯åˆ†å¸ƒï¼›ä½ å¯ä»¥é€šè¿‡`family`å‚æ•°æ¥æ›´æ”¹è¿™ä¸€ç‚¹ã€‚å…¬å¼è¯­æ³•å¹¶æ²¡æœ‰æŒ‡å®šå…ˆéªŒåˆ†å¸ƒï¼Œåªæ˜¯æè¿°äº†å› å˜é‡å’Œè‡ªå˜é‡ä¹‹é—´çš„å…³ç³»ã€‚Bambiä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬å®šä¹‰ï¼ˆéå¸¸ï¼‰å¼±çš„ä¿¡æ¯å…ˆéªŒã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æ‰“å°Bambiæ¨¡å‹æ¥è·å–æ›´å¤šä¿¡æ¯ã€‚å¦‚æœä½ æ‰“å°`a_model`ï¼Œä½ åº”è¯¥ä¼šçœ‹åˆ°ç±»ä¼¼å¦‚ä¸‹çš„å†…å®¹ï¼š
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The first line shows the formula we used to define the model, and the second
    line is the likelihood. The third line is the link function. Then we have the
    number of observations used to fit the model, and the next is telling us we are
    linearly modeling the parameter `mu` of the Gaussian. The latter part of the output
    shows the model structure: the common-level effects, in this case, the intercept
    (`Intercept`) and the slope (`x`), and the auxiliary parameters, i.e., all the
    parameters not linearly modeled, in this case, the standard deviation of the Gaussian.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€è¡Œæ˜¾ç¤ºäº†æˆ‘ä»¬ç”¨æ¥å®šä¹‰æ¨¡å‹çš„å…¬å¼ï¼Œç¬¬äºŒè¡Œæ˜¯ä¼¼ç„¶å‡½æ•°ã€‚ç¬¬ä¸‰è¡Œæ˜¯é“¾æ¥å‡½æ•°ã€‚ç„¶åæˆ‘ä»¬æœ‰ç”¨äºæ‹Ÿåˆæ¨¡å‹çš„è§‚æµ‹æ•°é‡ï¼Œæ¥ä¸‹æ¥å‘Šè¯‰æˆ‘ä»¬æˆ‘ä»¬æ­£åœ¨çº¿æ€§å»ºæ¨¡é«˜æ–¯çš„å‚æ•°`mu`ã€‚è¾“å‡ºçš„ååŠéƒ¨åˆ†æ˜¾ç¤ºäº†æ¨¡å‹ç»“æ„ï¼šå…±åŒæ°´å¹³æ•ˆåº”ï¼Œåœ¨æœ¬ä¾‹ä¸­æ˜¯æˆªè·(`Intercept`)å’Œæ–œç‡(`x`)ï¼Œä»¥åŠè¾…åŠ©å‚æ•°ï¼Œå³æ‰€æœ‰éçº¿æ€§å»ºæ¨¡çš„å‚æ•°ï¼Œæœ¬ä¾‹ä¸­æ˜¯é«˜æ–¯æ ‡å‡†å·®ã€‚
- en: 'You can override the default priors by passing a dictionary to the `priors`
    argument to `bmb.Model`. For instance, if we want to define a custom prior for
    the coefficient of the variable `x` and also for the auxiliary parameter `sigma`,
    we can do this:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡å°†å­—å…¸ä¼ é€’ç»™`bmb.Model`çš„`priors`å‚æ•°æ¥è¦†ç›–é»˜è®¤å…ˆéªŒåˆ†å¸ƒã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³ä¸ºå˜é‡`x`çš„ç³»æ•°å’Œè¾…åŠ©å‚æ•°`sigma`å®šä¹‰è‡ªå®šä¹‰å…ˆéªŒåˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·åšï¼š
- en: '**CodeÂ 6.3**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç Â 6.3**'
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As a result, we will get the following model specifications:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœï¼Œæˆ‘ä»¬å°†å¾—åˆ°ä»¥ä¸‹æ¨¡å‹è§„èŒƒï¼š
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If you want to omit the intercept from your model, you can do it like this:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³ä»æ¨¡å‹ä¸­çœç•¥æˆªè·ï¼Œå¯ä»¥è¿™æ ·åšï¼š
- en: 'CodeÂ 6.4:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç Â 6.4ï¼š
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Or even like this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ç”šè‡³è¿™æ ·åšï¼š
- en: 'CodeÂ 6.5:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç Â 6.5ï¼š
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Print the model `no_intercept_model`, and you will see that the intercept is
    not there anymore.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰“å°æ¨¡å‹`no_intercept_model`ï¼Œæ‚¨ä¼šçœ‹åˆ°æˆªè·ä¸å†å­˜åœ¨ã€‚
- en: 'What if we want to include more variables? We can do it like this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æƒ³è¦åŒ…å«æ›´å¤šå˜é‡æ€ä¹ˆåŠï¼Ÿæˆ‘ä»¬å¯ä»¥è¿™æ ·åšï¼š
- en: '**CodeÂ 6.6**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç Â 6.6**'
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can also include group-level effects (hierarchies); for example, if we want
    to use the variable `g` to partially pool the estimates of `x`, we can do it like
    this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å¯ä»¥åŒ…å«ç»„çº§æ•ˆåº”ï¼ˆå±‚æ¬¡ç»“æ„ï¼‰ï¼›ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦ä½¿ç”¨å˜é‡`g`æ¥éƒ¨åˆ†æ±‡æ€»`x`çš„ä¼°è®¡å€¼ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·åšï¼š
- en: '**CodeÂ 6.7**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç Â 6.7**'
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can see a visual representation of this model in *Figure [6.1](#x1-121081r1)*.
    Notice the variables `1|g_offset` and `x|g_offset`. By default, Bambi fits a noncentered
    hierarchical model; you can change this with the argument `noncentered`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨*å›¾ [6.1](#x1-121081r1)*ä¸­çœ‹åˆ°è¿™ä¸ªæ¨¡å‹çš„è§†è§‰è¡¨ç¤ºã€‚æ³¨æ„å˜é‡`1|g_offset`å’Œ`x|g_offset`ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒBambiæ‹Ÿåˆä¸€ä¸ªéå±…ä¸­çš„åˆ†å±‚æ¨¡å‹ï¼›æ‚¨å¯ä»¥é€šè¿‡å‚æ•°`noncentered`æ¥æ›´æ”¹è¿™ä¸€ç‚¹ã€‚
- en: '![PIC](img/file169.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file169.png)'
- en: '**FigureÂ 6.1**: A visual representation of `model_h`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾Â 6.1**ï¼š`model_h`çš„è§†è§‰è¡¨ç¤º'
- en: The formula syntax is very simple, but it is also very powerful. We have just
    scratched the surface of what we can do with it. Instead of describing the syntax
    all at once, we are going to show it by example. If you want to go deeper, you
    can check Formulae documentation [https://bambinos.github.io/formulae/](https://bambinos.github.io/formulae/).
    formulae is the Python package in charge of parsing Wilkinsonâ€™s formulas for Bambi.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å…¬å¼è¯­æ³•éå¸¸ç®€å•ï¼Œä½†ä¹Ÿéå¸¸å¼ºå¤§ã€‚æˆ‘ä»¬åªæ˜¯åˆæ­¥å±•ç¤ºäº†å¯ä»¥ä½¿ç”¨å®ƒåšä»€ä¹ˆã€‚å¦‚æœæ‚¨æƒ³æ·±å…¥äº†è§£ï¼Œå¯ä»¥æŸ¥çœ‹å…¬å¼æ–‡æ¡£ [https://bambinos.github.io/formulae/](https://bambinos.github.io/formulae/)ã€‚
    formulaeæ˜¯è´Ÿè´£è§£æå¨å°”é‡‘æ£®å…¬å¼ç”¨äºBambiçš„PythonåŒ…ã€‚
- en: 6.2 The bikes model, Bambiâ€™s version
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 è‡ªè¡Œè½¦æ¨¡å‹ï¼ŒBambiç‰ˆæœ¬
- en: 'The first model we are going to use to illustrate how to use Bambi is the bikes
    model from *Chapter [4](CH04.xhtml#x1-760004)*. We can load the data with:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é¦–å…ˆä½¿ç”¨è‡ªè¡Œè½¦æ¨¡å‹æ¥è¯´æ˜å¦‚ä½•ä½¿ç”¨Bambiï¼Œè¯¥æ¨¡å‹æ¥è‡ª*ç¬¬ [4](CH04.xhtml#x1-760004)*ç« ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼åŠ è½½æ•°æ®ï¼š
- en: '**CodeÂ 6.8**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç Â 6.8**'
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now we can build and fit the model:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥æ„å»ºå’Œæ‹Ÿåˆæ¨¡å‹ï¼š
- en: '**CodeÂ 6.9**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç Â 6.9**'
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '*Figure [6.2](#x1-122009r2)* shows a visual representation of the model. If
    you want to visually inspect the priors, you can use `model.plot_priors()`:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [6.2](#x1-122009r2)*å±•ç¤ºäº†æ¨¡å‹çš„è§†è§‰è¡¨ç¤ºã€‚å¦‚æœæ‚¨æƒ³è¦ç›´è§‚åœ°æ£€æŸ¥å…ˆéªŒåˆ†å¸ƒï¼Œå¯ä»¥ä½¿ç”¨`model.plot_priors()`ï¼š'
- en: '![PIC](img/file170.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file170.png)'
- en: '**FigureÂ 6.2**: A visual representation of the bikes model, computed with the
    command `model.graph()`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾Â 6.2**ï¼šç”¨å‘½ä»¤`model.graph()`è®¡ç®—çš„è‡ªè¡Œè½¦æ¨¡å‹çš„è§†è§‰è¡¨ç¤º'
- en: 'Letâ€™s now plot the posterior mean and the posterior predictive distribution
    (predictions). Omitting some details needed to make the plots look nice, the code
    to do this is:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬ç»˜åˆ¶åéªŒå‡å€¼å’ŒåéªŒé¢„æµ‹åˆ†å¸ƒï¼ˆé¢„æµ‹ï¼‰ã€‚ä¸ºäº†ä½¿å›¾è¡¨çœ‹èµ·æ¥æ¼‚äº®ï¼Œçœç•¥äº†ä¸€äº›ç»†èŠ‚ï¼Œåšè¿™äº›æ“ä½œçš„ä»£ç æ˜¯ï¼š
- en: '**CodeÂ 6.10**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç Â 6.10**'
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '`plot_predictions` is a function from Bambiâ€™s submodule `interpret`. This function
    helps to analyze regression models by plotting conditional adjusted predictions,
    visualizing how a parameter of the (conditional) response distribution varies
    as a function of (some) interpolated explanatory variables. We can see the result
    of this code in *Figure [6.3](#x1-122018r3)*. The left panel shows the posterior
    mean and the 94% HDI, while the right panel shows the posterior predictive distribution
    (the predicted distribution of the rented bikes). Notice that the uncertainty
    for the predictions is much larger than the uncertainty for the mean (`pps=False`).
    This is because the posterior predictive distribution accounts for the uncertainty
    in the model parameters and the uncertainty in the data, whereas the posterior
    distribution of the mean only accounts for the uncertainty in the intercept and
    slope parameters.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`plot_predictions` æ˜¯ Bambi å­æ¨¡å— `interpret` ä¸­çš„ä¸€ä¸ªå‡½æ•°ã€‚è¿™ä¸ªå‡½æ•°é€šè¿‡ç»˜åˆ¶æ¡ä»¶è°ƒæ•´é¢„æµ‹ï¼Œå¸®åŠ©åˆ†æå›å½’æ¨¡å‹ï¼Œå±•ç¤ºï¼ˆæ¡ä»¶ï¼‰å“åº”åˆ†å¸ƒä¸­çš„æŸä¸ªå‚æ•°å¦‚ä½•éšï¼ˆæŸäº›ï¼‰æ’å€¼çš„è§£é‡Šå˜é‡å˜åŒ–ã€‚æˆ‘ä»¬å¯ä»¥åœ¨*å›¾
    [6.3](#x1-122018r3)*ä¸­çœ‹åˆ°è¿™æ®µä»£ç çš„ç»“æœã€‚å·¦ä¾§é¢æ¿æ˜¾ç¤ºåéªŒå‡å€¼å’Œ 94% HDIï¼Œè€Œå³ä¾§é¢æ¿æ˜¾ç¤ºåéªŒé¢„æµ‹åˆ†å¸ƒï¼ˆç§Ÿç”¨è‡ªè¡Œè½¦çš„é¢„æµ‹åˆ†å¸ƒï¼‰ã€‚è¯·æ³¨æ„ï¼Œé¢„æµ‹çš„ä¸ç¡®å®šæ€§è¿œå¤§äºå‡å€¼çš„ä¸ç¡®å®šæ€§ï¼ˆ`pps=False`ï¼‰ã€‚è¿™æ˜¯å› ä¸ºåéªŒé¢„æµ‹åˆ†å¸ƒè€ƒè™‘äº†æ¨¡å‹å‚æ•°çš„ä¸ç¡®å®šæ€§ä»¥åŠæ•°æ®çš„ä¸ç¡®å®šæ€§ï¼Œè€Œå‡å€¼çš„åéªŒåˆ†å¸ƒä»…è€ƒè™‘äº†æˆªè·å’Œæ–œç‡å‚æ•°çš„ä¸ç¡®å®šæ€§ã€‚'
- en: '![PIC](img/file171.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file171.png)'
- en: '**FigureÂ 6.3**: Posterior mean and posterior predictive distribution for the
    bikes model'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.3**ï¼šè‡ªè¡Œè½¦æ¨¡å‹çš„åéªŒå‡å€¼å’ŒåéªŒé¢„æµ‹åˆ†å¸ƒ'
- en: 'The utility of `plot_cap` becomes more evident when we have more than one explanatory
    variable. For example, letâ€™s fit a model that uses both temperature and humidity
    to predict the number of rented bikes:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬æœ‰å¤šä¸ªè§£é‡Šå˜é‡æ—¶ï¼Œ`plot_cap` çš„å®ç”¨æ€§å˜å¾—æ›´åŠ æ˜æ˜¾ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æ‹Ÿåˆä¸€ä¸ªæ¨¡å‹ï¼Œä½¿ç”¨æ¸©åº¦å’Œæ¹¿åº¦æ¥é¢„æµ‹ç§Ÿèµçš„è‡ªè¡Œè½¦æ•°é‡ï¼š
- en: '**CodeÂ 6.11**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.11**'
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In *Figure [6.4](#x1-122029r4)*, we can see five panels, each one showing the
    change of the number of rented bikes with the temperature at different values
    of `humidity`. As you can see, the number of rented bikes increases with temperature,
    but the slope is larger when humidity is low.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*å›¾ [6.4](#x1-122029r4)*ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°äº”ä¸ªé¢æ¿ï¼Œæ¯ä¸ªé¢æ¿å±•ç¤ºäº†åœ¨ä¸åŒæ¹¿åº¦å€¼ä¸‹ï¼Œç§Ÿèµè‡ªè¡Œè½¦æ•°é‡éšæ¸©åº¦å˜åŒ–çš„æƒ…å†µã€‚æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œç§Ÿèµçš„è‡ªè¡Œè½¦æ•°é‡éšæ¸©åº¦ä¸Šå‡è€Œå¢åŠ ï¼Œä½†åœ¨æ¹¿åº¦è¾ƒä½æ—¶ï¼Œæ–œç‡æ›´å¤§ã€‚
- en: '![PIC](img/file172.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file172.png)'
- en: '**FigureÂ 6.4**: Posterior mean for the bikes model with temperature and humidity'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.4**ï¼šå¸¦æœ‰æ¸©åº¦å’Œæ¹¿åº¦çš„è‡ªè¡Œè½¦æ¨¡å‹çš„åéªŒå‡å€¼'
- en: 6.3 Polynomial regression
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 å¤šé¡¹å¼å›å½’
- en: 'One way to fit curves using a linear regression model is by building a polynomial,
    like this:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹æ‹Ÿåˆæ›²çº¿çš„ä¸€ç§æ–¹æ³•æ˜¯æ„å»ºä¸€ä¸ªå¤šé¡¹å¼ï¼Œåƒè¿™æ ·ï¼š
- en: '![Î¼ = ğ›½0 + ğ›½1x + ğ›½2x2 + ğ›½3x3 + ğ›½4x4...ğ›½mxm ](img/file173.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![Î¼ = ğ›½0 + ğ›½1x + ğ›½2x2 + ğ›½3x3 + ğ›½4x4...ğ›½mxm ](img/file173.jpg)'
- en: We call *m* the degree of the polynomial.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç§°*m*ä¸ºå¤šé¡¹å¼çš„æ¬¡æ•°ã€‚
- en: There are two important things to notice. First, polynomial regression is still
    linear regression; the linearity refers to the coefficients (the *Î²*s), not the
    variables (the *x*s). The second thing to note is that we are creating new variables
    out of thin air. The only observed variable is `x`, the rest are just powers of
    `x`. Creating new variables from observed ones is a perfectly valid â€trickâ€ when
    doing regression; sometimes the transformation can be motivated or justified by
    theory (like taking the square root of the length of babies), but sometimes it
    is just a way to fit a curve. The intuition with polynomials is that for a given
    value of `x`, the higher the degree of the polynomial, the more flexible the curve
    can be. A polynomial of degree 1 is a line, a polynomial of degree 2 is a curve
    that can go up or down, a polynomial of degree 3 is a curve that can go up and
    then down (or the other way around), and so on. Notice I said â€canâ€ because if
    we have a polynomial of degree 3, like *Î²*[0] + *Î²*[1]*x* + *Î²*[2]*x*Â² + *Î²*[3]*x*Â³,
    but the coefficients *Î²*[2] and *Î²*[3] are 0 (or practically 0), then the curve
    will be a line.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸¤ç‚¹éœ€è¦æ³¨æ„ã€‚é¦–å…ˆï¼Œå¤šé¡¹å¼å›å½’ä»ç„¶æ˜¯çº¿æ€§å›å½’ï¼›çº¿æ€§æ˜¯æŒ‡ç³»æ•°ï¼ˆ*Î²*ï¼‰ï¼Œè€Œä¸æ˜¯å˜é‡ï¼ˆ*x*ï¼‰ã€‚ç¬¬äºŒç‚¹éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬æ­£åœ¨å‡­ç©ºåˆ›å»ºæ–°å˜é‡ã€‚å”¯ä¸€è¢«è§‚æµ‹åˆ°çš„å˜é‡æ˜¯`x`ï¼Œå…¶ä½™çš„åªæ˜¯`x`çš„å¹‚ã€‚é€šè¿‡è§‚å¯Ÿåˆ°çš„å˜é‡åˆ›é€ æ–°å˜é‡æ˜¯å›å½’ä¸­å®Œå…¨æœ‰æ•ˆçš„â€œæŠ€å·§â€ï¼›æœ‰æ—¶è¿™ç§å˜æ¢å¯ä»¥é€šè¿‡ç†è®ºæ¥è§£é‡Šæˆ–è¯´æ˜ï¼ˆæ¯”å¦‚å–å©´å„¿èº«é•¿çš„å¹³æ–¹æ ¹ï¼‰ï¼Œä½†æœ‰æ—¶å®ƒä»…ä»…æ˜¯ä¸ºäº†æ‹Ÿåˆæ›²çº¿ã€‚å¤šé¡¹å¼çš„ç›´è§‚ç†è§£æ˜¯ï¼Œå¯¹äºç»™å®šçš„`x`å€¼ï¼Œé˜¶æ•°è¶Šé«˜çš„å¤šé¡¹å¼ï¼Œæ›²çº¿çš„çµæ´»æ€§è¶Šå¼ºã€‚1é˜¶å¤šé¡¹å¼æ˜¯ç›´çº¿ï¼Œ2é˜¶å¤šé¡¹å¼æ˜¯å¯ä»¥å‘ä¸Šæˆ–å‘ä¸‹çš„æ›²çº¿ï¼Œ3é˜¶å¤šé¡¹å¼æ˜¯å¯ä»¥å…ˆä¸Šå‡å†ä¸‹é™çš„æ›²çº¿ï¼ˆæˆ–åä¹‹ï¼‰ï¼Œä»¥æ­¤ç±»æ¨ã€‚æ³¨æ„æˆ‘è¯´çš„æ˜¯â€œå¯ä»¥â€ï¼Œå› ä¸ºå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ª3é˜¶å¤šé¡¹å¼ï¼Œæ¯”å¦‚
    *Î²*[0] + *Î²*[1]*x* + *Î²*[2]*x*Â² + *Î²*[3]*x*Â³ï¼Œä½†ç³»æ•°*Î²*[2]å’Œ*Î²*[3]æ˜¯0ï¼ˆæˆ–å‡ ä¹ä¸º0ï¼‰ï¼Œé‚£ä¹ˆæ›²çº¿å°±ä¼šæ˜¯ä¸€æ¡ç›´çº¿ã€‚
- en: 'There are two ways to define a polynomial regression with Bambi. We can write
    the *raw* polynomials:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Bambiå®šä¹‰å¤šé¡¹å¼å›å½’æœ‰ä¸¤ç§æ–¹å¼ã€‚æˆ‘ä»¬å¯ä»¥å†™å‡º*åŸå§‹*å¤šé¡¹å¼ï¼š
- en: '**CodeÂ 6.12**'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.12**'
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, we use the identity function `I()` to make it clear that we want to elevate
    *x* to some power. We need this because the `**` operator has a special meaning
    for Bambi. If we use this syntax, we are telling Bambi to model the mean of *y*
    as *Î±* + *Î²*[0]*x* + *Î²*[0]*x*Â² + *Î²*[0]*x*Â³ + *Î²*[0]*x*â´.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨æ’ç­‰å‡½æ•°`I()`æ¥æ˜ç¡®è¡¨ç¤ºæˆ‘ä»¬å¸Œæœ›å°†*x*æå‡åˆ°æŸä¸ªå¹‚æ¬¡ã€‚æˆ‘ä»¬éœ€è¦è¿™æ ·åšï¼Œå› ä¸º`**`æ“ä½œç¬¦åœ¨Bambiä¸­æœ‰ç‰¹æ®Šçš„å«ä¹‰ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨è¿™ç§è¯­æ³•ï¼Œå®é™…ä¸Šæ˜¯åœ¨å‘Šè¯‰Bambiå°†*y*çš„å‡å€¼å»ºæ¨¡ä¸º
    *Î±* + *Î²*[0]*x* + *Î²*[0]*x*Â² + *Î²*[0]*x*Â³ + *Î²*[0]*x*â´ã€‚
- en: 'Alternatively, we can write:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥å†™ï¼š
- en: '**CodeÂ 6.13**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.13**'
- en: '[PRE14]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This will also generate a polynomial of degree 4, but the polynomial terms will
    be orthogonal to each other, meaning the correlation between the terms is reduced.
    Without going into the mathematical details, this has at least two important consequences
    with respect to the *standard* polynomial. First, the estimation can be numerically
    more stable, and second, the interpretation of the coefficients is different.
    In `standard` polynomial regression, the coefficients can be difficult to interpret,
    as changing the value of one coefficient affects the entire polynomial. In contrast,
    orthogonal polynomials allow you to interpret the effect of each term more clearly,
    as they are independent of each other. While the interpretation of the coefficients
    is different, other results remain the same. For instance, you should get the
    same predictions with both approaches.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¹Ÿä¼šç”Ÿæˆä¸€ä¸ª4é˜¶çš„å¤šé¡¹å¼ï¼Œä½†å¤šé¡¹å¼é¡¹ä¹‹é—´æ˜¯æ­£äº¤çš„ï¼Œè¿™æ„å‘³ç€é¡¹ä¹‹é—´çš„ç›¸å…³æ€§è¢«é™ä½äº†ã€‚ä¸æ·±å…¥æ•°å­¦ç»†èŠ‚ï¼Œè¿™è‡³å°‘æœ‰ä¸¤ä¸ªé‡è¦çš„ç»“æœä¸*æ ‡å‡†*å¤šé¡¹å¼ç›¸æ¯”ã€‚é¦–å…ˆï¼Œä¼°è®¡å¯èƒ½åœ¨æ•°å€¼ä¸Šæ›´ç¨³å®šï¼›å…¶æ¬¡ï¼Œç³»æ•°çš„è§£é‡Šæ–¹å¼ä¸åŒã€‚åœ¨`æ ‡å‡†`å¤šé¡¹å¼å›å½’ä¸­ï¼Œç³»æ•°å¯èƒ½å¾ˆéš¾è§£é‡Šï¼Œå› ä¸ºæ”¹å˜ä¸€ä¸ªç³»æ•°çš„å€¼ä¼šå½±å“æ•´ä¸ªå¤šé¡¹å¼ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ­£äº¤å¤šé¡¹å¼å¯ä»¥è®©ä½ æ›´æ¸…æ™°åœ°è§£é‡Šæ¯ä¸ªé¡¹çš„å½±å“ï¼Œå› ä¸ºå®ƒä»¬å½¼æ­¤ç‹¬ç«‹ã€‚å°½ç®¡ç³»æ•°çš„è§£é‡Šä¸åŒï¼Œä½†å…¶ä»–ç»“æœä¿æŒä¸å˜ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨è¿™ä¸¤ç§æ–¹æ³•ä½ åº”è¯¥å¾—åˆ°ç›¸åŒçš„é¢„æµ‹ç»“æœã€‚
- en: 'Letâ€™s build an orthogonal polynomial of degree 4 to model the bike data. For
    this example, we are going to use the `hour` variable:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ª4é˜¶çš„æ­£äº¤å¤šé¡¹å¼æ¥æ‹Ÿåˆè‡ªè¡Œè½¦æ•°æ®ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨`hour`å˜é‡ï¼š
- en: '**CodeÂ 6.14**'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.14**'
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '*Figure [6.5](#x1-123014r5)* shows the posterior mean and the posterior predictive
    distribution. On the first row, you will see a polynomial of degree 1, which is
    equivalent to a linear model. On the second row, you will see a polynomial of
    degree 4.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [6.5](#x1-123014r5)* æ˜¾ç¤ºäº†åéªŒå‡å€¼å’ŒåéªŒé¢„æµ‹åˆ†å¸ƒã€‚åœ¨ç¬¬ä¸€è¡Œï¼Œä½ å°†çœ‹åˆ°ä¸€ä¸ª1é˜¶çš„å¤šé¡¹å¼ï¼Œå®ƒç›¸å½“äºä¸€ä¸ªçº¿æ€§æ¨¡å‹ã€‚åœ¨ç¬¬äºŒè¡Œï¼Œä½ å°†çœ‹åˆ°ä¸€ä¸ª4é˜¶çš„å¤šé¡¹å¼ã€‚'
- en: '![PIC](img/file174.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file174.png)'
- en: '**FigureÂ 6.5**: Posterior mean and posterior predictive distribution for the
    bikes model with temperature and humidity'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾6.5**ï¼šæ¸©åº¦å’Œæ¹¿åº¦ä¸‹çš„è‡ªè¡Œè½¦æ¨¡å‹çš„åéªŒå‡å€¼å’ŒåéªŒé¢„æµ‹åˆ†å¸ƒ'
- en: One problem with polynomials is that they act *globally*. When we apply a polynomial
    of degree *m*, we are saying that the relationship between the independent and
    dependent variables is of degree *m* for the entire dataset. This can be problematic
    when different regions of our data need different levels of flexibility. This
    could lead, for example, to curves that are too flexible. As the degree increases,
    the fit becomes more sensitive to the removal of points, or equivalently to the
    addition of future data. In other words, as the degree increases, the model becomes
    more prone to overfitting. Bayesian polynomial regression usually suffers less
    of this â€excessâ€ of flexibility because we usually donâ€™t use flat priors, and
    we do not compute a single set of coefficients, but the entire posterior distribution.
    Still, we can do better.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼çš„ä¸€ä¸ªé—®é¢˜æ˜¯å®ƒä»¬ä½œç”¨*å…¨å±€*ã€‚å½“æˆ‘ä»¬åº”ç”¨ä¸€ä¸ªé˜¶æ•°ä¸º*m*çš„å¤šé¡¹å¼æ—¶ï¼Œæˆ‘ä»¬å®é™…ä¸Šæ˜¯åœ¨è¯´è‡ªå˜é‡ä¸å› å˜é‡ä¹‹é—´çš„å…³ç³»åœ¨æ•´ä¸ªæ•°æ®é›†ä¸­éƒ½æ˜¯é˜¶æ•°*m*ã€‚å½“æ•°æ®çš„ä¸åŒåŒºåŸŸéœ€è¦ä¸åŒçµæ´»æ€§æ—¶ï¼Œè¿™å¯èƒ½ä¼šé€ æˆé—®é¢˜ã€‚ä¾‹å¦‚ï¼Œè¿™å¯èƒ½å¯¼è‡´æ›²çº¿è¿‡äºçµæ´»ã€‚éšç€é˜¶æ•°çš„å¢åŠ ï¼Œæ‹Ÿåˆå˜å¾—æ›´åŠ æ•æ„Ÿäºæ•°æ®ç‚¹çš„ç§»é™¤ï¼Œæˆ–è€…ç­‰åŒäºå¯¹æœªæ¥æ•°æ®çš„åŠ å…¥ã€‚æ¢å¥è¯è¯´ï¼Œéšç€é˜¶æ•°çš„å¢åŠ ï¼Œæ¨¡å‹æ›´å®¹æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆã€‚è´å¶æ–¯å¤šé¡¹å¼å›å½’é€šå¸¸è¾ƒå°‘é­é‡è¿™ç§â€œè¿‡åº¦â€çµæ´»æ€§ï¼Œå› ä¸ºæˆ‘ä»¬é€šå¸¸ä¸ä½¿ç”¨å¹³å¦çš„å…ˆéªŒï¼Œå¹¶ä¸”æˆ‘ä»¬ä¸ä¼šè®¡ç®—å•ä¸€çš„ç³»æ•°é›†ï¼Œè€Œæ˜¯è®¡ç®—æ•´ä¸ªåéªŒåˆ†å¸ƒã€‚ä¸è¿‡ï¼Œæˆ‘ä»¬è¿˜æ˜¯å¯ä»¥åšå¾—æ›´å¥½ã€‚
- en: 6.4 Splines
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.4 æ ·æ¡æ›²çº¿
- en: 'A general way to write very flexible models is to apply functions *B*[*m*]
    to *X*[*m*] and then multiply them by coefficients *Î²*[*m*]:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€èˆ¬æ¥è¯´ï¼Œå†™å‡ºéå¸¸çµæ´»çš„æ¨¡å‹çš„æ–¹æ³•æ˜¯å°†å‡½æ•°*B*[*m*]åº”ç”¨äº*X*[*m*]ï¼Œç„¶åå°†å®ƒä»¬ä¸ç³»æ•°*Î²*[*m*]ç›¸ä¹˜ï¼š
- en: '![Î¼ = ğ›½0 + ğ›½1B1 (X1) + ğ›½2B2(X2 )+ â‹…â‹…â‹…+ ğ›½mBm (Xm ) ](img/file175.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![Î¼ = ğ›½0 + ğ›½1B1 (X1) + ğ›½2B2(X2 )+ â‹…â‹…â‹…+ ğ›½mBm (Xm ) ](img/file175.jpg)'
- en: We are free to pick *B*[*m*] as we wish; for instance, we can pick polynomials.
    But we can also pick other functions. A popular choice is to use B-splines; we
    are not going to discuss their definition, but we can think of them as a way to
    create smooth curves in such a way that we get flexibility, as with polynomials,
    but less prone to overfitting. We achieve this by using piecewise polynomials,
    that is, polynomials that are restricted to affect only a portion of the data.
    *Figure [6.6](#x1-124002r6)* shows three examples of piecewise polynomials of
    increasing degrees. The dotted vertical lines show the â€knots,â€ which are the
    points used to restrict the regions, the dashed gray line represents the function
    we want to approximate, and the black lines are the piecewise polynomials.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è‡ªç”±é€‰æ‹©*B*[*m*]ï¼Œä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©å¤šé¡¹å¼ã€‚ä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥é€‰æ‹©å…¶ä»–å‡½æ•°ã€‚ä¸€ç§å¸¸è§çš„é€‰æ‹©æ˜¯ä½¿ç”¨Bæ ·æ¡ï¼›æˆ‘ä»¬ä¸æ‰“ç®—è®¨è®ºå®ƒä»¬çš„å®šä¹‰ï¼Œä½†å¯ä»¥å°†å®ƒä»¬è§†ä¸ºä¸€ç§åˆ›å»ºå¹³æ»‘æ›²çº¿çš„æ–¹å¼ï¼Œä½¿å¾—æˆ‘ä»¬åœ¨è·å¾—åƒå¤šé¡¹å¼ä¸€æ ·çš„çµæ´»æ€§æ—¶ï¼Œè¿‡æ‹Ÿåˆçš„å¯èƒ½æ€§è¾ƒå°ã€‚æˆ‘ä»¬é€šè¿‡ä½¿ç”¨åˆ†æ®µå¤šé¡¹å¼æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œå³å°†å¤šé¡¹å¼é™åˆ¶åœ¨ä»…å½±å“æ•°æ®çš„ä¸€éƒ¨åˆ†çš„åŒºåŸŸå†…ã€‚*å›¾
    [6.6](#x1-124002r6)* æ˜¾ç¤ºäº†é€æ­¥å¢åŠ é˜¶æ•°çš„åˆ†æ®µå¤šé¡¹å¼çš„ä¸‰ä¸ªç¤ºä¾‹ã€‚è™šçº¿å‚ç›´çº¿è¡¨ç¤ºâ€œèŠ‚ç‚¹â€ï¼Œå®ƒä»¬æ˜¯ç”¨äºé™åˆ¶åŒºåŸŸçš„ç‚¹ï¼Œè™šç°çº¿è¡¨ç¤ºæˆ‘ä»¬è¦é€¼è¿‘çš„å‡½æ•°ï¼Œé»‘çº¿è¡¨ç¤ºåˆ†æ®µå¤šé¡¹å¼ã€‚
- en: '![PIC](img/file176.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file176.png)'
- en: '**FigureÂ 6.6**: Piecewise polynomials of increasing degrees'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾6.6**ï¼šé€æ­¥å¢åŠ é˜¶æ•°çš„åˆ†æ®µå¤šé¡¹å¼'
- en: '*Figure [6.7](#x1-124004r7)* shows examples of splines of degree 1 and 3; the
    dots at the bottom represent the knots, and the dashed lines are the B-splines.
    At the top, we have all the B-splines with equal weight; we use grayscale to highlight
    that we have many B-splines. On the bottom panel, each B-spline is weighted differently
    (we multiply them by *Î²*[*m*] coefficients); if we sum the weighted B-splines,
    we get the black line as a result. This black line is what we usually call â€the
    spline.â€ We can use Bayesian statistics to find the proper weights for the B-splines.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [6.7](#x1-124004r7)* æ˜¾ç¤ºäº†1é˜¶å’Œ3é˜¶æ ·æ¡çš„ç¤ºä¾‹ï¼›åº•éƒ¨çš„ç‚¹è¡¨ç¤ºâ€œèŠ‚ç‚¹â€ï¼Œè™šçº¿è¡¨ç¤ºBæ ·æ¡ã€‚åœ¨é¡¶éƒ¨ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æ‰€æœ‰å…·æœ‰ç›¸ç­‰æƒé‡çš„Bæ ·æ¡ï¼›æˆ‘ä»¬ä½¿ç”¨ç°åº¦æ¥çªå‡ºæ˜¾ç¤ºæˆ‘ä»¬æœ‰å¤šä¸ªBæ ·æ¡ã€‚åœ¨åº•éƒ¨é¢æ¿ä¸­ï¼Œæ¯ä¸ªBæ ·æ¡çš„æƒé‡ä¸åŒï¼ˆæˆ‘ä»¬é€šè¿‡*Î²*[*m*]ç³»æ•°å¯¹å®ƒä»¬è¿›è¡ŒåŠ æƒï¼‰ï¼›å¦‚æœæˆ‘ä»¬å¯¹åŠ æƒåçš„Bæ ·æ¡è¿›è¡Œæ±‚å’Œï¼Œæœ€ç»ˆå¾—åˆ°çš„é»‘çº¿å°±æ˜¯ç»“æœã€‚è¿™æ¡é»‘çº¿é€šå¸¸è¢«ç§°ä¸ºâ€œæ ·æ¡æ›²çº¿â€ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è´å¶æ–¯ç»Ÿè®¡æ¥æ‰¾åˆ°Bæ ·æ¡çš„é€‚å½“æƒé‡ã€‚'
- en: '![PIC](img/file177.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file177.png)'
- en: '**FigureÂ 6.7**: B-splines of degree 1 (piecewise linear) or 3 (cubic spline)
    and the resulting splines.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾6.7**ï¼š1é˜¶ï¼ˆåˆ†æ®µçº¿æ€§ï¼‰æˆ–3é˜¶ï¼ˆç«‹æ–¹æ ·æ¡ï¼‰çš„Bæ ·æ¡åŠå…¶ç»“æœæ ·æ¡æ›²çº¿ã€‚'
- en: 'We can use B-splines with Bambi by using the `bs` function. For example, letâ€™s
    fit a spline of degree 3 to the bikes data:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨`bs`å‡½æ•°ï¼Œåœ¨Bambiä¸­ä½¿ç”¨Bæ ·æ¡ã€‚ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬å¯¹è‡ªè¡Œè½¦æ•°æ®æ‹Ÿåˆä¸€ä¸ª3é˜¶çš„æ ·æ¡æ›²çº¿ï¼š
- en: '**CodeÂ 6.15**'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç 6.15**'
- en: '[PRE16]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '*Figure [6.8](#x1-124013r8)* shows that the number of rental bikes is at the
    lowest number late at night. There is then an increase, probably as people wake
    up and go to work or school, or do other activities. We have a first peak at around
    hour 8, then a slight decline, followed by the second peak at around hour 18,
    probably because people commute back home, after which there is a steady decline.
    Notice that the curve is not very smooth; this is not because of the spline but
    because of the data. We have measurements at discrete times (every hour).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [6.8](#x1-124013r8)* æ˜¾ç¤ºäº†ç§Ÿèµè‡ªè¡Œè½¦æ•°é‡åœ¨æ·±å¤œæ—¶æœ€ä½ã€‚ç„¶åæœ‰ä¸€ä¸ªå¢åŠ ï¼Œå¯èƒ½æ˜¯å› ä¸ºäººä»¬é†’æ¥å»ä¸Šç­ã€ä¸Šå­¦æˆ–åšå…¶ä»–æ´»åŠ¨ã€‚æˆ‘ä»¬åœ¨å¤§çº¦ç¬¬8å°æ—¶å·¦å³æœ‰ä¸€ä¸ªç¬¬ä¸€ä¸ªé«˜å³°ï¼Œç„¶åç•¥å¾®ä¸‹é™ï¼Œæ¥ç€åœ¨å¤§çº¦ç¬¬18å°æ—¶å‡ºç°ç¬¬äºŒä¸ªé«˜å³°ï¼Œå¯èƒ½æ˜¯å› ä¸ºäººä»¬ä¸‹ç­å›å®¶ï¼Œä¹‹åå‡ºç°ç¨³å®šçš„ä¸‹é™ã€‚æ³¨æ„ï¼Œæ›²çº¿å¹¶ä¸æ˜¯éå¸¸å¹³æ»‘ï¼›è¿™å¹¶ä¸æ˜¯å› ä¸ºæ ·æ¡æ¨¡å‹çš„åŸå› ï¼Œè€Œæ˜¯å› ä¸ºæ•°æ®çš„åŸå› ã€‚æˆ‘ä»¬çš„æµ‹é‡æ˜¯åœ¨ç¦»æ•£çš„æ—¶é—´ç‚¹ï¼ˆæ¯å°æ—¶ï¼‰è¿›è¡Œçš„ã€‚'
- en: '![PIC](img/file178.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file178.png)'
- en: '**FigureÂ 6.8**: Posterior mean for the spline model'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.8**ï¼šæ ·æ¡æ¨¡å‹çš„åéªŒå‡å€¼'
- en: When working with splines, one important decision we must make is determining
    the number and placement of knots. This can be a somewhat daunting task since
    the optimal number of knots and their spacing are not immediately apparent. A
    useful suggestion for determining the knot locations is to consider placing them
    based on quantiles rather than uniformly â€“ something like `knots = np.quantile(bikes.hour,
    np.linspace(0, 1, num_knots))`. By doing so, we would position more knots in areas
    where we have a greater amount of data, while placing fewer knots in areas with
    less data. This results in a more adaptable approximation that effectively captures
    the variability in regions with a higher density of data points. Additionally,
    we may want to fit splines with varying numbers of knots and positions and then
    evaluate the results, using tools such as LOO, as we saw in *Chapter [5](CH05.xhtml#x1-950005)*.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤„ç†æ ·æ¡æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»åšå‡ºä¸€ä¸ªé‡è¦çš„å†³ç­–ï¼Œé‚£å°±æ˜¯ç¡®å®šç»“ç‚¹çš„æ•°é‡å’Œä½ç½®ã€‚è¿™å¯èƒ½æ˜¯ä¸€ä¸ªç›¸å½“ä»¤äººå¤´ç–¼çš„ä»»åŠ¡ï¼Œå› ä¸ºæœ€ä½³çš„ç»“ç‚¹æ•°é‡åŠå…¶é—´è·å¹¶ä¸ç«‹åˆ»æ˜¾ç°å‡ºæ¥ã€‚ä¸€ä¸ªæœ‰ç”¨çš„å»ºè®®æ˜¯è€ƒè™‘åŸºäºåˆ†ä½æ•°è€Œéå‡åŒ€åˆ†å¸ƒæ¥ç¡®å®šç»“ç‚¹çš„ä½ç½®â€”â€”åƒè¿™æ ·
    `knots = np.quantile(bikes.hour, np.linspace(0, 1, num_knots))`ã€‚é€šè¿‡è¿™æ ·åšï¼Œæˆ‘ä»¬ä¼šåœ¨æ•°æ®é‡è¾ƒå¤§çš„åŒºåŸŸæ”¾ç½®æ›´å¤šçš„ç»“ç‚¹ï¼Œè€Œåœ¨æ•°æ®é‡è¾ƒå°‘çš„åŒºåŸŸæ”¾ç½®è¾ƒå°‘çš„ç»“ç‚¹ã€‚è¿™æ ·å¯ä»¥å¾—åˆ°ä¸€ä¸ªæ›´å…·é€‚åº”æ€§çš„è¿‘ä¼¼ï¼Œä»è€Œæœ‰æ•ˆåœ°æ•æ‰æ•°æ®ç‚¹å¯†åº¦è¾ƒé«˜åŒºåŸŸçš„å˜åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›å°è¯•ä½¿ç”¨ä¸åŒæ•°é‡å’Œä½ç½®çš„ç»“ç‚¹æ¥æ‹Ÿåˆæ ·æ¡ï¼Œç„¶åè¯„ä¼°ç»“æœï¼Œä½¿ç”¨è¯¸å¦‚LOOç­‰å·¥å…·ï¼Œå°±åƒæˆ‘ä»¬åœ¨*ç¬¬[5ç« ](CH05.xhtml#x1-950005)*ä¸­çœ‹åˆ°çš„é‚£æ ·ã€‚
- en: 6.5 Distributional models
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.5 åˆ†å¸ƒæ¨¡å‹
- en: We saw earlier that we can use linear models for parameters other than the mean
    (or location parameter). For example, we can use a linear model for the mean and
    a linear model for the standard deviation of a Gaussian distribution. These models
    are usually called distributional models. The syntax for distributional models
    is very similar; we just need to add a line for the auxiliary parameters we want
    to model. For instance, *Ïƒ* for a Gaussian, or *Î±* for a NegativeBinomial.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°ï¼Œå¯ä»¥ä½¿ç”¨çº¿æ€§æ¨¡å‹æ¥è¡¨ç¤ºå‡å€¼ï¼ˆæˆ–ä½ç½®å‚æ•°ï¼‰ä»¥å¤–çš„å…¶ä»–å‚æ•°ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºé«˜æ–¯åˆ†å¸ƒçš„å‡å€¼å’Œæ ‡å‡†å·®åˆ†åˆ«ä½¿ç”¨çº¿æ€§æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹é€šå¸¸è¢«ç§°ä¸ºåˆ†å¸ƒæ¨¡å‹ã€‚åˆ†å¸ƒæ¨¡å‹çš„è¯­æ³•éå¸¸ç›¸ä¼¼ï¼›æˆ‘ä»¬åªéœ€è¦ä¸ºæˆ‘ä»¬æƒ³è¦å»ºæ¨¡çš„è¾…åŠ©å‚æ•°æ·»åŠ ä¸€è¡Œã€‚ä¾‹å¦‚ï¼Œé«˜æ–¯åˆ†å¸ƒçš„*Ïƒ*ï¼Œæˆ–è´ŸäºŒé¡¹åˆ†å¸ƒçš„*Î±*ã€‚
- en: 'Letâ€™s now reproduce an example from *Chapter [4](CH04.xhtml#x1-760004)*, the
    babies example:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬é‡ç°*ç¬¬[4ç« ](CH04.xhtml#x1-760004)*ä¸­çš„ä¸€ä¸ªä¾‹å­â€”â€”å©´å„¿ç¤ºä¾‹ï¼š
- en: '**CodeÂ 6.16**'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.16**'
- en: '[PRE17]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '*Figure [6.9](#x1-125011r9)* shows the posterior distribution values of sigma
    for `model_dis` (varying sigma) and for a model with constant sigma. We can see
    that when sigma is allowed to vary, we obtain values below and above the estimate
    for a constant sigma, meaning that we are both under- and over-estimating this
    parameter when we donâ€™t allow it to change.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [6.9](#x1-125011r9)* æ˜¾ç¤ºäº† `model_dis`ï¼ˆå˜åŒ–çš„ sigmaï¼‰å’Œå¸¸æ•° sigma æ¨¡å‹çš„åéªŒåˆ†å¸ƒå€¼ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå½“
    sigma å…è®¸å˜åŒ–æ—¶ï¼Œå¾—åˆ°çš„å€¼æ—¢ä½äºä¹Ÿé«˜äºå¸¸æ•° sigma çš„ä¼°è®¡å€¼ï¼Œè¿™æ„å‘³ç€å½“æˆ‘ä»¬ä¸å…è®¸ sigma æ”¹å˜æ—¶ï¼Œæˆ‘ä»¬ä¼šä½ä¼°æˆ–é«˜ä¼°è¿™ä¸ªå‚æ•°ã€‚'
- en: '![PIC](img/file179.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file179.png)'
- en: '**FigureÂ 6.9**: Constant and varying sigma for the babies data'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.9**ï¼šå©´å„¿æ•°æ®çš„å¸¸æ•°ä¸å˜åŒ–çš„ sigma'
- en: '*Figure [6.10](#x1-125012r10)* shows the posterior fit for `model_dis`. Notice
    that the model can capture the increase in variability as the babies grow. This
    figure is very similar to *Figure [4.13](CH04.xhtml#x1-88022r13)*.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [6.10](#x1-125012r10)* æ˜¾ç¤ºäº† `model_dis` çš„åéªŒæ‹Ÿåˆã€‚æ³¨æ„ï¼Œæ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°å©´å„¿æˆé•¿è¿‡ç¨‹ä¸­å˜åŒ–çš„å˜å¼‚æ€§ã€‚è¿™ä¸ªå›¾ä¸*å›¾
    [4.13](CH04.xhtml#x1-88022r13)*éå¸¸ç›¸ä¼¼ã€‚'
- en: '![PIC](img/file180.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file180.png)'
- en: '**FigureÂ 6.10**: Posterior fit for `model_dis`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.10**ï¼š`model_dis`çš„åéªŒæ‹Ÿåˆ'
- en: 'When working with PyMC, we saw that sampling from the posterior predictive
    distribution, at not observed values, requires us to define the â€Xsâ€ as `Mutable
    data` and then update the variable before computing the posterior predictive distribution.
    With Bambi, this is not necessary. We can use the `predict` method to predict
    new values by passing the new values to the `data` argument. For example, letâ€™s
    predict the length of a baby at 0.5 months (15 days):'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½¿ç”¨PyMCæ—¶ï¼Œæˆ‘ä»¬çœ‹åˆ°ä»åéªŒé¢„æµ‹åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·æ—¶ï¼Œéœ€è¦å®šä¹‰â€œXsâ€ä½œä¸º`å¯å˜æ•°æ®`ï¼Œç„¶ååœ¨è®¡ç®—åéªŒé¢„æµ‹åˆ†å¸ƒä¹‹å‰æ›´æ–°è¯¥å˜é‡ã€‚è€Œåœ¨Bambiä¸­ï¼Œè¿™ä¸éœ€è¦ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`predict`æ–¹æ³•ï¼Œé€šè¿‡å°†æ–°å€¼ä¼ é€’ç»™`data`å‚æ•°æ¥é¢„æµ‹æ–°å€¼ã€‚ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬é¢„æµ‹ä¸€åªå°ä¼é¹…åœ¨0.5ä¸ªæœˆï¼ˆ15å¤©ï¼‰æ—¶çš„ä½“é•¿ï¼š
- en: '**CodeÂ 6.17**'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.17**'
- en: '[PRE18]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 6.6 Categorical predictors
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.6 ç±»åˆ«é¢„æµ‹å˜é‡
- en: 'A categorical variable represents distinct groups or categories that can take
    on a limited set of values from those categories. These values are typically labels
    or names that donâ€™t possess numerical significance on their own. Some examples
    are:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«å˜é‡è¡¨ç¤ºä¸åŒçš„ç»„æˆ–ç±»åˆ«ï¼Œè¿™äº›ç±»åˆ«åªèƒ½ä»æœ‰é™çš„é›†åˆä¸­å–å€¼ã€‚é€šå¸¸ï¼Œè¿™äº›å€¼æ˜¯æ ‡ç­¾æˆ–åç§°ï¼Œæœ¬èº«ä¸å…·å¤‡æ•°å€¼æ„ä¹‰ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ä¾‹å­ï¼š
- en: 'Political affiliation: conservative, liberal, or progressive.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ”¿æ²»ç«‹åœºï¼šä¿å®ˆæ´¾ã€è‡ªç”±æ´¾æˆ–è¿›æ­¥æ´¾ã€‚
- en: 'Sex: female or male.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ€§åˆ«ï¼šå¥³æ€§æˆ–ç”·æ€§ã€‚
- en: 'Customer satisfaction level: very unsatisfied, unsatisfied, neutral, satisfied,
    or very satisfied.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®¢æˆ·æ»¡æ„åº¦ï¼šéå¸¸ä¸æ»¡æ„ã€ä¸æ»¡æ„ã€ä¸­ç«‹ã€æ»¡æ„æˆ–éå¸¸æ»¡æ„ã€‚
- en: Linear regression models can easily accommodate categorical variables; we just
    need to encode the categories as numbers. There are a few options to do so. Bambi
    can easily handle the details for us. The devil is in the interpretation of the
    results, as we will explore in the next two sections.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§å›å½’æ¨¡å‹å¯ä»¥è½»æ¾åœ°å¤„ç†ç±»åˆ«å˜é‡ï¼›æˆ‘ä»¬åªéœ€è¦å°†ç±»åˆ«ç¼–ç ä¸ºæ•°å­—ã€‚å¯ä»¥é€šè¿‡å‡ ç§æ–¹å¼åšåˆ°è¿™ä¸€ç‚¹ï¼ŒBambiå¯ä»¥è½»æ¾åœ°ä¸ºæˆ‘ä»¬å¤„ç†è¿™äº›ç»†èŠ‚ã€‚çœŸæ­£çš„éš¾ç‚¹åœ¨äºç»“æœçš„è§£é‡Šï¼Œæˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„ä¸¤èŠ‚ä¸­æ·±å…¥æ¢è®¨ã€‚
- en: 6.6.1 Categorical penguins
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6.1 ç±»åˆ«ä¼é¹…
- en: For the current example, we are going to use the palmerpenguins dataset, [Horst
    etÂ al.](Bibliography.xhtml#Xpenguins)Â [[2020](Bibliography.xhtml#Xpenguins)],
    which contains 344 observations of 8 variables. For the moment, we are interested
    in modeling the mass of the penguins as a function of the length of their bills.
    It is expected that the mass of the penguins increases as the bill length increases.
    The novelty of this example is that we are going to consider the categorical variable,
    `species`. In this dataset, we have 3 categories or levels for the species variable,
    namely, Adelie, Chinstrap, and Gentoo. *Figure [6.11](#x1-127002r11)* shows a
    scatter plot for the variables we want to model.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå½“å‰çš„ä¾‹å­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨palmerpenguinsæ•°æ®é›†ï¼Œ[Horstç­‰äºº](Bibliography.xhtml#Xpenguins)[[2020](Bibliography.xhtml#Xpenguins)]ï¼Œè¯¥æ•°æ®é›†åŒ…å«344ä¸ªè§‚æµ‹å€¼å’Œ8ä¸ªå˜é‡ã€‚ç›®å‰ï¼Œæˆ‘ä»¬å…³å¿ƒçš„æ˜¯å°†ä¼é¹…çš„ä½“é‡å»ºæ¨¡ä¸ºå–™é•¿çš„å‡½æ•°ã€‚é¢„è®¡éšç€å–™é•¿çš„å¢åŠ ï¼Œä¼é¹…çš„ä½“é‡ä¹Ÿä¼šå¢åŠ ã€‚æœ¬ä¾‹çš„æ–°é¢–ä¹‹å¤„åœ¨äºï¼Œæˆ‘ä»¬å°†è€ƒè™‘ç±»åˆ«å˜é‡`species`ã€‚åœ¨è¿™ä¸ªæ•°æ®é›†ä¸­ï¼Œç‰©ç§å˜é‡æœ‰3ä¸ªç±»åˆ«æˆ–çº§åˆ«ï¼Œåˆ†åˆ«æ˜¯Adelieã€Chinstrapå’ŒGentooã€‚*å›¾
    [6.11](#x1-127002r11)* æ˜¾ç¤ºäº†æˆ‘ä»¬è¦å»ºæ¨¡çš„å˜é‡çš„æ•£ç‚¹å›¾ã€‚
- en: '![PIC](img/file181.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file181.png)'
- en: '**FigureÂ 6.11**: Bill length vs mass for 3 species of penguins'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.11**ï¼š3ç§ä¼é¹…çš„å–™é•¿ä¸ä½“é‡çš„å…³ç³»'
- en: 'Letâ€™s load the data and fit the model:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ è½½æ•°æ®å¹¶æ‹Ÿåˆæ¨¡å‹ï¼š
- en: '**CodeÂ 6.18**'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.18**'
- en: '[PRE19]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Notice that there is no special syntax to define Bambiâ€™s model for categorical
    variables. Bambi can detect and handle them automatically.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå®šä¹‰Bambiæ¨¡å‹ä¸­çš„ç±»åˆ«å˜é‡æ—¶æ²¡æœ‰ç‰¹æ®Šçš„è¯­æ³•ã€‚Bambiå¯ä»¥è‡ªåŠ¨æ£€æµ‹å¹¶å¤„ç†å®ƒä»¬ã€‚
- en: '*Figure [6.12](#x1-127011r12)* show a forest plot for `model_p`. Notice something
    unexpected? There are no posterior values for Adelie. This is no mistake. By default,
    Bambi encodes categorical variables with N levels (3 species) as N-1 dummy variables
    (2 species). Thus the coefficients species-Chinstrap and species-Gentoo are modeled
    as deflections from the baseline model:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [6.12](#x1-127011r12)* æ˜¾ç¤ºäº†`model_p`çš„æ£®æ—å›¾ã€‚æ³¨æ„åˆ°ä»€ä¹ˆæ„å¤–æƒ…å†µäº†å—ï¼ŸAdelieæ²¡æœ‰åéªŒå€¼ã€‚è¿™ä¸æ˜¯é”™è¯¯ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒBambiå°†å…·æœ‰Nä¸ªçº§åˆ«ï¼ˆ3ä¸ªç‰©ç§ï¼‰çš„ç±»åˆ«å˜é‡ç¼–ç ä¸ºN-1ä¸ªè™šæ‹Ÿå˜é‡ï¼ˆ2ä¸ªç‰©ç§ï¼‰ã€‚å› æ­¤ï¼Œç‰©ç§-Chinstrapå’Œç‰©ç§-Gentooçš„ç³»æ•°è¢«å»ºæ¨¡ä¸ºä¸åŸºçº¿æ¨¡å‹çš„åå·®ï¼š'
- en: '![mass = ğ›½0 + ğ›½1bill length ](img/file182.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![è´¨é‡ = ğ›½0 + ğ›½1å–™é•¿](img/file182.jpg)'
- en: To make this more clear, letâ€™s check a couple of plots. We can read *Figure
    [6.12](#x1-127011r12)* as saying that the body mass of Chinstrap is, on average,
    -0.89 relative to Adelieâ€™s body mass. The same goes for Gentoo, but this time,
    we have to add 0.66 to the mean of the baseline model.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´æ¸…æ¥šåœ°è¯´æ˜è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æ¥æŸ¥çœ‹å‡ ä¸ªå›¾è¡¨ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡*å›¾ [6.12](#x1-127011r12)* ç†è§£ä¸ºï¼ŒChinstrapçš„ä½“é‡å¹³å‡æ¯”Adelieè½»0.89ã€‚Gentooä¹Ÿæ˜¯å¦‚æ­¤ï¼Œä¸è¿‡è¿™æ¬¡æˆ‘ä»¬éœ€è¦åœ¨åŸºçº¿æ¨¡å‹çš„å‡å€¼ä¸ŠåŠ ä¸Š0.66ã€‚
- en: '![PIC](img/file183.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file183.png)'
- en: '**FigureÂ 6.12**: Forest plot from `model_p`'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾Â 6.12**: æ¥è‡ª `model_p` çš„æ£®æ—å›¾'
- en: You can check that these two statements are true by looking at *Figure [6.13](#x1-127012r13)*.
    See how the three lines are essentially parallel to each other with Adelie in
    the middle, Chinstrap below (-0.89), and Gentoo above (0.58).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥é€šè¿‡æŸ¥çœ‹*å›¾ [6.13](#x1-127012r13)* æ¥éªŒè¯è¿™ä¸¤ä¸ªé™ˆè¿°çš„çœŸå®æ€§ã€‚æ³¨æ„ä¸­é—´æ˜¯é˜¿å¾·åˆ©ï¼ˆAdelieï¼‰ï¼Œä¸‹æ–¹æ˜¯æ‹Ÿä¼é¹…ï¼ˆChinstrapï¼Œ-0.89ï¼‰ï¼Œä¸Šæ–¹æ˜¯æ ¹è¶¾ä¼é¹…ï¼ˆGentooï¼Œ0.58ï¼‰ï¼Œå®ƒä»¬çš„ä¸‰æ¡çº¿åŸºæœ¬å¹³è¡Œã€‚
- en: '![PIC](img/file184.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file184.png)'
- en: '**FigureÂ 6.13**: Mean in-sample predictions from `model_p`'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾Â 6.13**: æ¥è‡ª `model_p` çš„å¹³å‡æ ·æœ¬é¢„æµ‹'
- en: 6.6.2 Relation to hierarchical models
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6.2 å…³äºåˆ†å±‚æ¨¡å‹çš„å…³ç³»
- en: In *Chapter [3](CH03.xhtml#x1-670003)*, we discussed and contrasted pooled and
    hierarchical (or partially pooled) models. There we showed that it is often the
    case that we take advantage of the structure or hierarchies in data. Following
    the logic of that chapter, you could argue that Adelie, Gentoo, and Chinstrap,
    while being different species, are all penguins. So modeling their body masses
    hierarchically may be a good idea. And you would be right to think so. So what
    is the difference between such a model and the one we used in this section?
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨*ç¬¬ [3](CH03.xhtml#x1-670003)* ç« ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¹¶å¯¹æ¯”äº†æ±‡é›†æ¨¡å‹å’Œåˆ†å±‚ï¼ˆæˆ–éƒ¨åˆ†æ±‡é›†ï¼‰æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨é‚£é‡Œå±•ç¤ºäº†é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åˆ©ç”¨æ•°æ®çš„ç»“æ„æˆ–å±‚æ¬¡ã€‚éµå¾ªè¯¥ç« èŠ‚çš„é€»è¾‘ï¼Œä½ å¯ä»¥è®¤ä¸ºé˜¿å¾·åˆ©ã€æ ¹è¶¾ä¼é¹…å’Œæ‹Ÿä¼é¹…è™½ç„¶æ˜¯ä¸åŒçš„ç‰©ç§ï¼Œä½†éƒ½æ˜¯ä¼é¹…ã€‚å› æ­¤ï¼Œåˆ†å±‚å»ºæ¨¡å®ƒä»¬çš„ä½“é‡å¯èƒ½æ˜¯ä¸ªå¥½ä¸»æ„ã€‚ä½ è¿™æ ·æƒ³æ˜¯æ­£ç¡®çš„ã€‚é‚£ä¹ˆè¿™ç§æ¨¡å‹ä¸æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¸­ä½¿ç”¨çš„æ¨¡å‹æœ‰ä»€ä¹ˆåŒºåˆ«å‘¢ï¼Ÿ
- en: 'The distinguishing factor lies in the subtleties of the slope and intercept
    components. In the case of the latter, the slope remains the same across all three
    penguin species, while the intercepts can vary: `Intercept + 0` for Adelie, `Intercept
    + species[Chinstrap]` for Chinstrap, and `Intercept + species[Gentoo]` for Gentoo.
    Thus, this model highlights the distinct intercepts while keeping the slope uniform.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: åŒºåˆ†å› ç´ åœ¨äºæ–œç‡å’Œæˆªè·çš„å¾®å¦™ç»„æˆéƒ¨åˆ†ã€‚åœ¨åè€…çš„æƒ…å†µä¸‹ï¼Œæ–œç‡åœ¨ä¸‰ç§ä¼é¹…ç‰©ç§ä¸­ä¿æŒä¸å˜ï¼Œè€Œæˆªè·å¯ä»¥å˜åŒ–ï¼šé˜¿å¾·åˆ©çš„`Intercept + 0`ï¼Œæ‹Ÿä¼é¹…çš„`Intercept
    + species[Chinstrap]`ï¼Œæ ¹è¶¾ä¼é¹…çš„`Intercept + species[Gentoo]`ã€‚å› æ­¤ï¼Œè¯¥æ¨¡å‹çªå‡ºäº†ä¸åŒçš„æˆªè·ï¼ŒåŒæ—¶ä¿æŒäº†ç»Ÿä¸€çš„æ–œç‡ã€‚
- en: If instead we had built the hierarchical model `body_mass ~(bill_length|species)`,
    we would have been asking for a partially pooled slope and intercept. And if instead
    we had modeled `body_mass ~(0 + bill_length | species)`, we would have been asking
    for a partially pooled slope and a common intercept.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å»ºç«‹äº†å±‚æ¬¡æ¨¡å‹ `body_mass ~(bill_length|species)`ï¼Œæˆ‘ä»¬å°†è¯·æ±‚éƒ¨åˆ†æ±‡é›†çš„æ–œç‡å’Œæˆªè·ã€‚å¦‚æœæˆ‘ä»¬å»ºç«‹äº†æ¨¡å‹ `body_mass
    ~(0 + bill_length | species)`ï¼Œæˆ‘ä»¬å°†è¯·æ±‚éƒ¨åˆ†æ±‡é›†çš„æ–œç‡å’Œå…¬å…±æˆªè·ã€‚
- en: Besides these particular models, when thinking about using a predictor as a
    grouping variable or as a categorical predictor, it is usually useful to ask if
    the variable includes all possible categories (like all days of the week, all
    species, and so on) or only a subgroup (some schools, or a few musical genres).
    If we have all possible categories, then we may prefer to model it as a categorical
    predictor, otherwise, as a grouping variable.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†è¿™äº›ç‰¹å®šçš„æ¨¡å‹å¤–ï¼Œåœ¨è€ƒè™‘å°†é¢„æµ‹å˜é‡ä½œä¸ºåˆ†ç»„å˜é‡æˆ–åˆ†ç±»é¢„æµ‹å˜é‡ä½¿ç”¨æ—¶ï¼Œé€šå¸¸æœ‰å¿…è¦é—®é—®è¯¥å˜é‡æ˜¯å¦åŒ…æ‹¬æ‰€æœ‰å¯èƒ½çš„ç±»åˆ«ï¼ˆä¾‹å¦‚æ‰€æœ‰æ˜ŸæœŸçš„æ‰€æœ‰å¤©ï¼Œæ‰€æœ‰ç‰©ç§ç­‰ï¼‰ï¼Œè¿˜æ˜¯ä»…åŒ…æ‹¬å­ç»„ï¼ˆæŸäº›å­¦æ ¡æˆ–å°‘æ•°éŸ³ä¹æµæ´¾ï¼‰ã€‚å¦‚æœæˆ‘ä»¬æœ‰æ‰€æœ‰å¯èƒ½çš„ç±»åˆ«ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯èƒ½æ›´å–œæ¬¢å°†å…¶å»ºæ¨¡ä¸ºåˆ†ç±»é¢„æµ‹å˜é‡ï¼Œå¦åˆ™å»ºæ¨¡ä¸ºåˆ†ç»„å˜é‡ã€‚
- en: As we already discussed, we often create more than one model before deciding
    which one we like the most. The *best* model is the one that aligns with the goals
    of your analysis, provides meaningful insights, and accurately represents the
    underlying patterns in your data. Itâ€™s often a good idea to explore multiple models,
    compare their performance using appropriate criteria (such as those discussed
    in *Chapter [5](CH05.xhtml#x1-950005)*), and consider the practical implications
    of each model for your research or decision-making process.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬ä¹‹å‰è®¨è®ºè¿‡çš„ï¼Œé€šå¸¸åœ¨å†³å®šå“ªä¸€ä¸ªæ¨¡å‹æœ€ä½³ä¹‹å‰ï¼Œæˆ‘ä»¬ä¼šåˆ›å»ºå¤šä¸ªæ¨¡å‹ã€‚*æœ€ä½³*æ¨¡å‹æ˜¯ä¸ä½ åˆ†æç›®æ ‡ä¸€è‡´ã€æä¾›æœ‰æ„ä¹‰çš„è§è§£ï¼Œå¹¶å‡†ç¡®ä»£è¡¨æ•°æ®æ½œåœ¨æ¨¡å¼çš„æ¨¡å‹ã€‚æ¢ç´¢å¤šä¸ªæ¨¡å‹ï¼Œä½¿ç”¨é€‚å½“çš„æ ‡å‡†ï¼ˆä¾‹å¦‚*ç¬¬
    [5](CH05.xhtml#x1-950005)* ç« ä¸­è®¨è®ºçš„æ ‡å‡†ï¼‰æ¯”è¾ƒå®ƒä»¬çš„æ€§èƒ½ï¼Œå¹¶è€ƒè™‘æ¯ä¸ªæ¨¡å‹å¯¹ç ”ç©¶æˆ–å†³ç­–è¿‡ç¨‹çš„å®é™…å½±å“é€šå¸¸æ˜¯ä¸ªå¥½ä¸»æ„ã€‚
- en: 6.7 Interactions
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.7 äº¤äº’ä½œç”¨
- en: 'An interaction effect, or statistical interaction, happens when the effect
    of an independent variable on the response changes depending on the value of another
    independent variable. An interaction can occur between two or more variables.
    Some examples are:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 'äº¤äº’æ•ˆåº”æˆ–ç»Ÿè®¡äº¤äº’æ•ˆåº”å‘ç”Ÿåœ¨ç‹¬ç«‹å˜é‡å¯¹å“åº”çš„å½±å“å› å¦ä¸€ä¸ªç‹¬ç«‹å˜é‡çš„å€¼è€Œå˜åŒ–æ—¶ã€‚äº¤äº’ä½œç”¨å¯ä»¥å‘ç”Ÿåœ¨ä¸¤ä¸ªæˆ–å¤šä¸ªå˜é‡ä¹‹é—´ã€‚ä¸€äº›ä¾‹å­åŒ…æ‹¬:'
- en: '**Education level and income impact**: Higher education may have a stronger
    positive effect on income for one gender compared to the other, resulting in an
    interaction between education and gender.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ•™è‚²æ°´å¹³å’Œæ”¶å…¥çš„å½±å“**ï¼šè¾ƒé«˜çš„æ•™è‚²æ°´å¹³å¯èƒ½å¯¹æŸä¸€æ€§åˆ«çš„æ”¶å…¥äº§ç”Ÿæ›´å¼ºçš„æ­£å‘å½±å“ï¼Œä»è€Œå½¢æˆæ•™è‚²å’Œæ€§åˆ«ä¹‹é—´çš„äº¤äº’ä½œç”¨ã€‚'
- en: '**Medication efficacy and age**: A drug that works better for older individuals
    than younger ones.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¯ç‰©ç–—æ•ˆä¸å¹´é¾„**ï¼šä¸€ç§å¯¹å¹´é•¿è€…æ•ˆæœæ›´å¥½çš„è¯ç‰©ï¼Œè€Œå¯¹å¹´è½»äººæ•ˆæœè¾ƒå·®ã€‚'
- en: '**Exercise and diet effects on weight loss**: It could be that the dietâ€™s effect
    on weight loss is small for people who do little or no exercise and large for
    people who do moderate exercise.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¿åŠ¨å’Œé¥®é£Ÿå¯¹å‡é‡çš„å½±å“**ï¼šå¯¹äºåšå¾ˆå°‘æˆ–ä¸åšè¿åŠ¨çš„äººæ¥è¯´ï¼Œé¥®é£Ÿå¯¹å‡é‡çš„å½±å“å¯èƒ½è¾ƒå°ï¼›è€Œå¯¹äºåšä¸­ç­‰å¼ºåº¦è¿åŠ¨çš„äººæ¥è¯´ï¼Œé¥®é£Ÿå¯¹å‡é‡çš„å½±å“å¯èƒ½è¾ƒå¤§ã€‚'
- en: '**Temperature and humidity for crop growth**: Some crops could thrive in hot
    and humid conditions, while others might perform better in cooler and less humid
    environments.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä½œç‰©ç”Ÿé•¿çš„æ¸©åº¦å’Œæ¹¿åº¦**ï¼šä¸€äº›ä½œç‰©å¯èƒ½åœ¨é«˜æ¸©é«˜æ¹¿çš„ç¯å¢ƒä¸­èŒå£®æˆé•¿ï¼Œè€Œå…¶ä»–ä½œç‰©åˆ™å¯èƒ½åœ¨è¾ƒå‡‰çˆ½ã€æ¹¿åº¦è¾ƒä½çš„ç¯å¢ƒä¸­è¡¨ç°æ›´å¥½ã€‚'
- en: 'We have an interaction when the combined effect of two or more variables acting
    together is not equal to the sum of their individual effects. So we cannot model
    an interaction if we have a model like the following:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä¸¤ä¸ªæˆ–æ›´å¤šå˜é‡çš„è”åˆæ•ˆåº”ä¸ç­‰äºå®ƒä»¬å•ç‹¬æ•ˆåº”çš„æ€»å’Œæ—¶ï¼Œæˆ‘ä»¬å°±æœ‰äº†äº¤äº’ä½œç”¨ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æœ‰å¦‚ä¸‹æ¨¡å‹ï¼Œæˆ‘ä»¬å°±æ— æ³•å»ºæ¨¡äº¤äº’ä½œç”¨ï¼š
- en: '![Î¼ = ğ›¼ + ğ›½0X0 + ğ›½1X1 ](img/file185.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![Î¼ = ğ›¼ + ğ›½0X0 + ğ›½1X1 ](img/file185.jpg)'
- en: 'The most common way to model an interaction effect is by multiplying two (or
    more) variables. Take, for example, a model like the following:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: å»ºæ¨¡äº¤äº’ä½œç”¨æ•ˆåº”çš„æœ€å¸¸è§æ–¹æ³•æ˜¯å°†ä¸¤ä¸ªï¼ˆæˆ–æ›´å¤šï¼‰å˜é‡ç›¸ä¹˜ã€‚ä¾‹å¦‚ï¼Œè€ƒè™‘ä»¥ä¸‹è¿™æ ·çš„æ¨¡å‹ï¼š
- en: '![ main terms â—œ----â—â—Ÿ----â— Î¼ = ğ›¼ + ğ›½0X0 + ğ›½1X1 + ğ›½â—Ÿ2X0â—Xâ—œ1â— interaction term
    ](img/file186.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![ ä¸»è¦æœ¯è¯­ â—œ----â—â—Ÿ----â— Î¼ = ğ›¼ + ğ›½0X0 + ğ›½1X1 + ğ›½â—Ÿ2X0â—Xâ—œ1â— äº¤äº’ä½œç”¨é¡¹ ](img/file186.jpg)'
- en: It is common when modeling interaction effects to also include the main effect/terms.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å»ºæ¨¡äº¤äº’ä½œç”¨æ•ˆåº”æ—¶ï¼Œé€šå¸¸è¿˜ä¼šåŒ…æ‹¬ä¸»æ•ˆåº”/é¡¹ã€‚
- en: New predictors
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: æ–°çš„é¢„æµ‹å› å­
- en: Multiplying two variables can be seen as a trick, similar to the one we use
    for polynomial regression (or any transformation of a given variable). Instead
    of multiplying a predictor with itself, we multiply two different predictors and
    obtain a new one.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ä¸¤ä¸ªå˜é‡ç›¸ä¹˜å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§æŠ€å·§ï¼Œç±»ä¼¼äºæˆ‘ä»¬åœ¨å¤šé¡¹å¼å›å½’ï¼ˆæˆ–å¯¹ç»™å®šå˜é‡çš„ä»»ä½•å˜æ¢ï¼‰ä¸­ä½¿ç”¨çš„æ–¹æ³•ã€‚æˆ‘ä»¬ä¸æ˜¯å°†ä¸€ä¸ªé¢„æµ‹å› å­ä¸è‡ªèº«ç›¸ä¹˜ï¼Œè€Œæ˜¯å°†ä¸¤ä¸ªä¸åŒçš„é¢„æµ‹å› å­ç›¸ä¹˜ï¼Œå¾—åˆ°ä¸€ä¸ªæ–°çš„é¢„æµ‹å› å­ã€‚
- en: 'Defining an interaction between two variables is easy for a PyMC model; we
    just need to multiply the two predictors together and also add a coefficient.
    For a Bambi model, it is even easier; we use the `:` operator. To make the difference
    crystal clear, letâ€™s look at an example of a model with and without interactions:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ PyMC æ¨¡å‹ä¸­å®šä¹‰ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„äº¤äº’ä½œç”¨éå¸¸ç®€å•ï¼›æˆ‘ä»¬åªéœ€è¦å°†è¿™ä¸¤ä¸ªé¢„æµ‹å› å­ç›¸ä¹˜ï¼Œå¹¶æ·»åŠ ä¸€ä¸ªç³»æ•°ã€‚å¯¹äº Bambi æ¨¡å‹æ¥è¯´ï¼Œæ›´åŠ ç®€å•ï¼›æˆ‘ä»¬ä½¿ç”¨
    `:` è¿ç®—ç¬¦ã€‚ä¸ºäº†è®©åŒºåˆ«æ›´åŠ æ¸…æ™°ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä¸€ä¸ªæœ‰äº¤äº’ä½œç”¨å’Œæ²¡æœ‰äº¤äº’ä½œç”¨çš„æ¨¡å‹ç¤ºä¾‹ï¼š
- en: '**CodeÂ 6.19**'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.19**'
- en: '[PRE20]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We now use Bambiâ€™s `plot_prediction` to compare how different values of `bill_length`
    affect `body_mass` as a function of `bill_depth` generate. *Figure [6.14](#x1-129015r14)*
    shows the result. We have the mean regression fit for `bill_depth` evaluated at
    5 fixed values of `bill_length`. On the left, we have the result for `model_noint`
    (no interactions), and on the right, for `model_int` (with interactions). We can
    see that when we donâ€™t have interactions, the fitted lines for `bill_depth` are
    parallel at different levels of `bill_length`. Instead, when we have interactions,
    the lines are no longer parallel, precisely because the effect of changing `bill_depth`
    on how much `body_mass` changes is no longer constant but modulated by the values
    of `bill_length`.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨ä½¿ç”¨ Bambi çš„ `plot_prediction` æ¥æ¯”è¾ƒä¸åŒ `bill_length` å€¼å¦‚ä½•ä½œä¸º `bill_depth` çš„å‡½æ•°å½±å“
    `body_mass`ã€‚*å›¾ [6.14](#x1-129015r14)* æ˜¾ç¤ºäº†ç»“æœã€‚æˆ‘ä»¬ä¸º `bill_depth` åœ¨ 5 ä¸ªå›ºå®šçš„ `bill_length`
    å€¼ä¸‹è®¡ç®—äº†å¹³å‡å›å½’æ‹Ÿåˆã€‚å·¦ä¾§æ˜¯ `model_noint`ï¼ˆæ— äº¤äº’ä½œç”¨ï¼‰ç»“æœï¼Œå³ä¾§æ˜¯ `model_int`ï¼ˆæœ‰äº¤äº’ä½œç”¨ï¼‰ç»“æœã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå½“æ²¡æœ‰äº¤äº’ä½œç”¨æ—¶ï¼Œ`bill_depth`
    çš„æ‹Ÿåˆæ›²çº¿åœ¨ä¸åŒçš„ `bill_length` æ°´å¹³ä¸Šæ˜¯å¹³è¡Œçš„ã€‚ç›¸åï¼Œå½“å­˜åœ¨äº¤äº’ä½œç”¨æ—¶ï¼Œè¿™äº›æ›²çº¿ä¸å†å¹³è¡Œï¼Œæ­£å› ä¸º `bill_depth` çš„å˜åŒ–å¯¹ `body_mass`
    å˜åŒ–çš„å½±å“ä¸å†æ˜¯å¸¸æ•°ï¼Œè€Œæ˜¯å—åˆ° `bill_length` å€¼çš„è°ƒèŠ‚ã€‚
- en: '![PIC](img/file187.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file187.png)'
- en: '**FigureÂ 6.14**: Mean in-sample predictions from `model_noint` (left) and `model_int`
    (right)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.14**ï¼š`model_noint`ï¼ˆå·¦ï¼‰å’Œ `model_int`ï¼ˆå³ï¼‰çš„æ ·æœ¬å†…å¹³å‡é¢„æµ‹'
- en: If you generate a figure like *Figure [6.14](#x1-129015r14)*, but instead of
    fixing `bill_length`, you decide to fix `bill_depth`, you will observe a similar
    behavior.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ç”Ÿæˆäº†åƒ*å›¾ [6.14](#x1-129015r14)* è¿™æ ·çš„å›¾ï¼Œä½†ä¸æ˜¯å›ºå®š `bill_length`ï¼Œè€Œæ˜¯å†³å®šå›ºå®š `bill_depth`ï¼Œä½ å°†è§‚å¯Ÿåˆ°ç±»ä¼¼çš„è¡Œä¸ºã€‚
- en: In the GitHub repository for this book ( [https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)),
    you are going to find the file `interactions.ipynb`. This script generates a figure
    in 3D, which I hope will help you build intuition about what we are doing when
    adding interactions. If you run it, you will see that when there are no interactions,
    we are fitting a 2D plane, a flat surface like a sheet of paper. But when adding
    interactions, you are fitting a curved surface. Compare the result of `interactions.ipynb`
    with *Figure [6.14](#x1-129015r14)*.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ä¹¦çš„GitHubä»“åº“ä¸­ï¼ˆ[https://github.com/aloctavodia/BAP3](https://github.com/aloctavodia/BAP3)ï¼‰ï¼Œä½ å°†æ‰¾åˆ°æ–‡ä»¶
    `interactions.ipynb`ã€‚è¿™ä¸ªè„šæœ¬ç”Ÿæˆä¸€ä¸ª3Då›¾å½¢ï¼Œæˆ‘å¸Œæœ›å®ƒèƒ½å¸®åŠ©ä½ å»ºç«‹å…³äºæ·»åŠ äº¤äº’é¡¹æ—¶æˆ‘ä»¬æ‰€åšå·¥ä½œçš„ç›´è§‰ã€‚å¦‚æœä½ è¿è¡Œå®ƒï¼Œä½ ä¼šçœ‹åˆ°ï¼Œå½“æ²¡æœ‰äº¤äº’é¡¹æ—¶ï¼Œæˆ‘ä»¬æ‹Ÿåˆçš„æ˜¯ä¸€ä¸ª2Då¹³é¢ï¼Œä¸€å¼ åƒçº¸ä¸€æ ·çš„å¹³å¦è¡¨é¢ã€‚ä½†æ˜¯ï¼Œå½“æ·»åŠ äº¤äº’é¡¹æ—¶ï¼Œä½ ä¼šæ‹Ÿåˆä¸€ä¸ªå¼¯æ›²çš„è¡¨é¢ã€‚å°†
    `interactions.ipynb` çš„ç»“æœä¸ *å›¾ [6.14](#x1-129015r14)* è¿›è¡Œæ¯”è¾ƒã€‚
- en: We have just seen visually that interpreting linear models with interactions
    is not as easy as interpreting linear models without them. Letâ€™s see this mathematically.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆšåˆšé€šè¿‡å¯è§†åŒ–çœ‹åˆ°ï¼Œè§£é‡ŠåŒ…å«äº¤äº’é¡¹çš„çº¿æ€§æ¨¡å‹å¹¶ä¸åƒè§£é‡Šæ²¡æœ‰äº¤äº’é¡¹çš„çº¿æ€§æ¨¡å‹é‚£æ ·ç®€å•ã€‚è®©æˆ‘ä»¬ä»æ•°å­¦ä¸Šæ¥çœ‹ä¸€ä¸‹ã€‚
- en: 'Letâ€™s assume we have a model with 2 variables, *X*[0] and *X*[1], and an interaction
    between them:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å«2ä¸ªå˜é‡ *X*[0] å’Œ *X*[1] ä»¥åŠå®ƒä»¬ä¹‹é—´çš„äº¤äº’ä½œç”¨çš„æ¨¡å‹ï¼š
- en: '![Î¼ = ğ›¼ + ğ›½0X0 + ğ›½1X1 + ğ›½2X0X1 ](img/file188.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![Î¼ = ğ›¼ + ğ›½0X0 + ğ›½1X1 + ğ›½2X0X1 ](img/file188.jpg)'
- en: 'We can rewrite this model as:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªæ¨¡å‹é‡å†™ä¸ºï¼š
- en: '![Î¼ = ğ›¼+ (â—Ÿğ›½0-+â—ğ›½â—œ2X1-)â—X0 + ğ›½1X1 slope of X0 ](img/file189.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![Î¼ = ğ›¼+ (â—Ÿğ›½0-+â—ğ›½â—œ2X1-)â—X0 + ğ›½1X1 X0çš„æ–œç‡](img/file189.jpg)'
- en: 'Or even like this:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è€…ç”šè‡³åƒè¿™æ ·ï¼š
- en: '![Î¼ = ğ›¼+ ğ›½0X0 + (â—Ÿğ›½1 +â—ğ›½â—œ2X0-)â—X1 slope of X1 ](img/file190.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![Î¼ = ğ›¼+ ğ›½0X0 + (â—Ÿğ›½1 +â—ğ›½â—œ2X0-)â—X1 X1çš„æ–œç‡](img/file190.jpg)'
- en: 'From this expression, we can see that:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™ä¸ªè¡¨è¾¾å¼ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼š
- en: The interaction term can be understood as a linear model inside a linear model.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº¤äº’é¡¹å¯ä»¥ç†è§£ä¸ºçº¿æ€§æ¨¡å‹ä¸­çš„çº¿æ€§æ¨¡å‹ã€‚
- en: The interaction is symmetric; we can think of it as the slope of *X*[0] as a
    function of *X*[1] and at the same time as the slope of *X*[1] as a function of
    *X*[0]. This can also be seen from the interactive figure.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº¤äº’ä½œç”¨æ˜¯å¯¹ç§°çš„ï¼›æˆ‘ä»¬å¯ä»¥å°†å…¶ç†è§£ä¸º *X*[0] ä½œä¸º *X*[1] çš„å‡½æ•°çš„æ–œç‡ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ *X*[1] ä½œä¸º *X*[0] çš„å‡½æ•°çš„æ–œç‡ã€‚è¿™ä¹Ÿå¯ä»¥ä»äº¤äº’å¼å›¾å½¢ä¸­çœ‹åˆ°ã€‚
- en: We know from before that the *Î²*[0] coefficient can be interpreted as the amount
    of change of *Î¼* per unit change of *X*[0] (that is why we call it the slope).
    If we add an interaction term, then this is only true at *X*[1] = 0\. Try using
    the interactive figure to see this by yourself. Mathematically, this is true because
    when *X*[1] = 0, then *Î²*[2]*X*[1] = 0, and thus the slope of *X*[0] reduces to
    *Î²*[0]*X*[0]. By symmetry, the same reasoning can be applied to *Î²*[1].
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹‹å‰çŸ¥é“ï¼Œ*Î²*[0] ç³»æ•°å¯ä»¥è§£é‡Šä¸º *Î¼* å¯¹ *X*[0] å•ä½å˜åŒ–çš„å“åº”é‡ï¼ˆè¿™å°±æ˜¯æˆ‘ä»¬ç§°ä¹‹ä¸ºæ–œç‡çš„åŸå› ï¼‰ã€‚å¦‚æœæˆ‘ä»¬æ·»åŠ ä¸€ä¸ªäº¤äº’é¡¹ï¼Œé‚£ä¹ˆåªæœ‰å½“
    *X*[1] = 0 æ—¶ï¼Œè¿™ä¸ªå…³ç³»æ‰æˆç«‹ã€‚è¯•ç€ä½¿ç”¨äº¤äº’å¼å›¾å½¢è‡ªå·±çœ‹çœ‹ã€‚æ•°å­¦ä¸Šï¼Œè¿™æ˜¯çœŸçš„ï¼Œå› ä¸ºå½“ *X*[1] = 0 æ—¶ï¼Œ*Î²*[2]*X*[1] = 0ï¼Œå› æ­¤
    *X*[0] çš„æ–œç‡ç®€åŒ–ä¸º *Î²*[0]*X*[0]ã€‚é€šè¿‡å¯¹ç§°æ€§ï¼ŒåŒæ ·çš„æ¨ç†å¯ä»¥åº”ç”¨äº *Î²*[1]ã€‚
- en: 6.8 Interpreting models with Bambi
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.8 ä½¿ç”¨Bambiè§£é‡Šæ¨¡å‹
- en: We have been using `bmb.interpret_plot_predictions` a lot in this chapter. But
    thatâ€™s not the only tool that Bambi offers us to help us understand models. One
    of them is `bmb.interpret_plot_comparisons`. This tool helps us answer the question,
    â€What is the expected predictive difference when we compare two values of a given
    variable while keeping all the rest at constant values?â€.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å·²ç»å¤šæ¬¡ä½¿ç”¨äº† `bmb.interpret_plot_predictions`ã€‚ä½†è¿™å¹¶ä¸æ˜¯ Bambi æä¾›çš„å”¯ä¸€å¸®åŠ©æˆ‘ä»¬ç†è§£æ¨¡å‹çš„å·¥å…·ã€‚å¦ä¸€ä¸ªå·¥å…·æ˜¯
    `bmb.interpret_plot_comparisons`ã€‚è¿™ä¸ªå·¥å…·å¸®åŠ©æˆ‘ä»¬å›ç­”è¿™æ ·çš„é—®é¢˜ï¼šâ€œå½“æˆ‘ä»¬æ¯”è¾ƒæŸä¸ªå˜é‡çš„ä¸¤ä¸ªå€¼æ—¶ï¼Œä¿æŒå…¶ä»–æ‰€æœ‰å€¼ä¸å˜ï¼Œé¢„æµ‹å·®å¼‚æ˜¯ä»€ä¹ˆï¼Ÿâ€
- en: 'Letâ€™s use `model_int` from the previous section, so we donâ€™t need to fit a
    new model. We use the following code block to generate *Figure [6.15](#x1-130007r15)*:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ä¸Šä¸€èŠ‚çš„ `model_int`ï¼Œå› æ­¤æ— éœ€é‡æ–°æ‹Ÿåˆæ¨¡å‹ã€‚æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç å—ç”Ÿæˆ *å›¾ [6.15](#x1-130007r15)*ï¼š
- en: '**CodeÂ 6.20**'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.20**'
- en: '[PRE21]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '*Figure [6.15](#x1-130007r15)* shows that when comparing a hypothetical penguin
    with `bill_depth` of 1.8 against one with `bill_depth` of 1.4, the expected difference
    is:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [6.15](#x1-130007r15)* æ˜¾ç¤ºäº†å½“å°†å‡è®¾çš„ä¼é¹…çš„ `bill_depth` ä» 1.8 æ¯”è¾ƒåˆ° 1.4 æ—¶ï¼ŒæœŸæœ›çš„å·®å¼‚æ˜¯ï¼š'
- en: Approx 0.8 kg for a bill length of 3.5 cm
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§çº¦ 0.8 åƒå…‹ï¼Œå½“å–™é•¿ä¸º 3.5 å˜ç±³æ—¶
- en: -0.6 kg for a bill length of 4.5 cm
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -0.6 åƒå…‹ï¼Œå½“å–™é•¿ä¸º 4.5 å˜ç±³æ—¶
- en: Approx -2 kg for a bill length of 5.5 cm
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§çº¦ -2 åƒå…‹ï¼Œå½“å–™é•¿ä¸º 5.5 å˜ç±³æ—¶
- en: '![PIC](img/file191.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file191.png)'
- en: '**FigureÂ 6.15**: Contrast of `bill_depth` from 1.8 to 1.4 cm for 3 fixed values
    of `bill_length`'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.15**ï¼šåœ¨ 3 ä¸ªå›ºå®šçš„ `bill_length` å€¼ä¸‹ï¼Œå°† `bill_depth` ä» 1.8 å˜ç±³å¯¹æ¯”åˆ° 1.4 å˜ç±³'
- en: If you want the information in tabular form, use the function `bmb.interpret.comparisons`
    and you will get a DataFrame instead of a plot.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¸Œæœ›ä»¥è¡¨æ ¼å½¢å¼æŸ¥çœ‹ä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨å‡½æ•°`bmb.interpret.comparisons`ï¼Œè¿™æ ·ä½ å°†å¾—åˆ°ä¸€ä¸ªDataFrameè€Œä¸æ˜¯å›¾è¡¨ã€‚
- en: 'Another useful function is `bmb.interpret_plot_slopes`, which can be used to
    compute the â€instant rate of changeâ€ or slope at a given value. We use the following
    code block to generate *Figure [6.16](#x1-130014r16)*:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªæœ‰ç”¨çš„å‡½æ•°æ˜¯`bmb.interpret_plot_slopes`ï¼Œå®ƒå¯ç”¨äºè®¡ç®—ç»™å®šå€¼ä¸‹çš„â€œç¬æ—¶å˜åŒ–ç‡â€æˆ–æ–œç‡ã€‚æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç å—ç”Ÿæˆ*å›¾ [6.16](#x1-130014r16)*ï¼š
- en: '**CodeÂ 6.21**'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.21**'
- en: '[PRE22]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '*Figure [6.16](#x1-130014r16)* shows that the slopes at a `bill_depth` of 1.8
    are:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾ [6.16](#x1-130014r16)* æ˜¾ç¤ºäº†`bill_depth`ä¸º1.8æ—¶çš„æ–œç‡ï¼š'
- en: â‰ˆ 2 kg/cm for a bill length of 3.5 cm
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â‰ˆ 2 kg/cmï¼Œé€‚ç”¨äºé¸Ÿå˜´é•¿åº¦ä¸º3.5 cmæ—¶
- en: -1.4 kg/cm for a bill length of 4.5 cm
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -1.4 kg/cmï¼Œé€‚ç”¨äºé¸Ÿå˜´é•¿åº¦ä¸º4.5 cmæ—¶
- en: â‰ˆ -5 kg/cm for a bill length of 5.5 cm
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â‰ˆ -5 kg/cmï¼Œé€‚ç”¨äºé¸Ÿå˜´é•¿åº¦ä¸º5.5 cmæ—¶
- en: '![PIC](img/file192.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file192.png)'
- en: '**FigureÂ 6.16**: Slopes of `bill_depth` at 1.8 cm for 3 fixed values of `bill_length`'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.16**ï¼šå¯¹äº`bill_length`çš„ä¸‰ä¸ªå›ºå®šå€¼ï¼Œ`bill_depth`åœ¨1.8 cmæ—¶çš„æ–œç‡'
- en: If you want the information in tabular form, use the function `bmb.interpret.slopes`
    and you will get a DataFrame instead of a plot.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¸Œæœ›ä»¥è¡¨æ ¼å½¢å¼æŸ¥çœ‹ä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨å‡½æ•°`bmb.interpret.slopes`ï¼Œè¿™æ ·ä½ å°†å¾—åˆ°ä¸€ä¸ªDataFrameè€Œä¸æ˜¯å›¾è¡¨ã€‚
- en: In this section, we have just scratched the surface of what we can do with the
    tools in the `bmb.interpret` module. This module is a very useful feature of Bambi,
    especially for models with interactions and/or models with link functions other
    than the identity function. I highly recommend you read the Bambi documentation
    for more examples and details not covered here.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»…ä»…è§¦åŠäº†`bmb.interpret`æ¨¡å—å·¥å…·çš„è¡¨é¢ã€‚è¿™ä¸ªæ¨¡å—æ˜¯Bambiçš„ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„åŠŸèƒ½ï¼Œå°¤å…¶é€‚ç”¨äºå«æœ‰äº¤äº’ä½œç”¨å’Œ/æˆ–å…·æœ‰é™¤æ’ç­‰å‡½æ•°ä¹‹å¤–é“¾æ¥å‡½æ•°çš„æ¨¡å‹ã€‚æˆ‘å¼ºçƒˆå»ºè®®ä½ é˜…è¯»Bambiæ–‡æ¡£ï¼Œè·å–æ›´å¤šæœªåœ¨æ­¤ä»‹ç»çš„ç¤ºä¾‹å’Œç»†èŠ‚ã€‚
- en: 6.9 Variable selection
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.9 å˜é‡é€‰æ‹©
- en: Variable selection refers to the process of identifying the most relevant variables
    in a model from a larger set of potential predictors. We perform variable selection
    under the assumption that only a subset of variables have a considerable impact
    on the outcome of interest, while others contribute little or no additional value.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: å˜é‡é€‰æ‹©æ˜¯æŒ‡ä»ä¸€ç»„æ½œåœ¨é¢„æµ‹å˜é‡ä¸­è¯†åˆ«å‡ºå¯¹æ¨¡å‹ç»“æœæœ€ç›¸å…³çš„å˜é‡çš„è¿‡ç¨‹ã€‚æˆ‘ä»¬è¿›è¡Œå˜é‡é€‰æ‹©æ—¶å‡è®¾ï¼Œåªæœ‰ä¸€éƒ¨åˆ†å˜é‡å¯¹æ„Ÿå…´è¶£çš„ç»“æœæœ‰æ˜¾è‘—å½±å“ï¼Œè€Œå…¶ä»–å˜é‡å‡ ä¹æ²¡æœ‰æˆ–æ²¡æœ‰é¢å¤–çš„ä»·å€¼ã€‚
- en: Arguably the â€most Bayesian thing to doâ€ when building a model is to include
    all the variables that we may think of in a single model and then use the posterior
    from that model to make predictions or gain an understanding of the relationships
    of the variables. This is the â€most Bayesianâ€ approach because we are using as
    much data as possible and incorporating in the posterior the uncertainty about
    the importance of the variables. However, being *more Bayesian than Bayes* is
    not always the best idea. We already saw in *Chapter [5](CH05.xhtml#x1-950005)*
    that Bayes factors can be problematic, even when they are a direct consequence
    of Bayesâ€™ theorem.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»ºæ¨¡å‹æ—¶ï¼Œæœ€â€œè´å¶æ–¯â€çš„åšæ³•å¯èƒ½æ˜¯å°†æˆ‘ä»¬å¯èƒ½æƒ³åˆ°çš„æ‰€æœ‰å˜é‡éƒ½åŒ…å«åœ¨ä¸€ä¸ªæ¨¡å‹ä¸­ï¼Œç„¶ååˆ©ç”¨è¯¥æ¨¡å‹çš„åéªŒåˆ†å¸ƒè¿›è¡Œé¢„æµ‹æˆ–äº†è§£å˜é‡ä¹‹é—´çš„å…³ç³»ã€‚è¿™æ˜¯æœ€â€œè´å¶æ–¯â€çš„æ–¹æ³•ï¼Œå› ä¸ºæˆ‘ä»¬å°½å¯èƒ½åœ°ä½¿ç”¨æ•°æ®ï¼Œå¹¶åœ¨åéªŒä¸­çº³å…¥å˜é‡é‡è¦æ€§çš„æœªçŸ¥æ€§ã€‚ç„¶è€Œï¼Œæ¯”è´å¶æ–¯æ›´â€œè´å¶æ–¯â€å¹¶ä¸æ€»æ˜¯æœ€ä½³é€‰æ‹©ã€‚æˆ‘ä»¬åœ¨*ç¬¬[5ç« ](CH05.xhtml#x1-950005)*ä¸­å·²ç»çœ‹åˆ°ï¼Œå³ä½¿è´å¶æ–¯å› å­æ˜¯è´å¶æ–¯å®šç†çš„ç›´æ¥ç»“æœï¼Œå®ƒä»¬ä¹Ÿå¯èƒ½å­˜åœ¨é—®é¢˜ã€‚
- en: 'Performing variable selection is a good idea when:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä»¥ä¸‹æƒ…å†µå‡ºç°æ—¶ï¼Œæ‰§è¡Œå˜é‡é€‰æ‹©æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼š
- en: We need to reduce the measurement cost. For instance, in medicine, we may have
    the money and resources to run a pilot study and measure 30 variables for 200
    patients. But we cannot do the same for thousands. Or we may be able to place
    a lot of sensors in an open field to better model crop gains, but we cannot extend
    that to the size of a country. Reducing costs is not always about money or time;
    when working with humans or other animals, reducing pain and discomfort is important
    too. For example, we may want to predict the risk of a patient having a heart
    attack. We can do this by measuring a lot of variables, but we can also do it
    by measuring just a few variables that are less invasive.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦é™ä½æµ‹é‡æˆæœ¬ã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»å­¦ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½æœ‰èµ„é‡‘å’Œèµ„æºè¿›è¡Œä¸€é¡¹è¯•ç‚¹ç ”ç©¶ï¼Œæµ‹é‡200åæ‚£è€…çš„30ä¸ªå˜é‡ã€‚ä½†æ˜¯æˆ‘ä»¬æ— æ³•å¯¹æ•°åƒäººåšåŒæ ·çš„äº‹æƒ…ã€‚æˆ–è€…ï¼Œæˆ‘ä»¬å¯èƒ½èƒ½åœ¨å¼€é˜”åœ°å¸¦æ”¾ç½®å¤§é‡ä¼ æ„Ÿå™¨æ¥æ›´å¥½åœ°å»ºæ¨¡ä½œç‰©æ”¶ç›Šï¼Œä½†æˆ‘ä»¬æ— æ³•å°†å…¶æ‰©å±•åˆ°ä¸€ä¸ªå›½å®¶çš„è§„æ¨¡ã€‚é™ä½æˆæœ¬å¹¶ä¸æ€»æ˜¯æ„å‘³ç€é‡‘é’±æˆ–æ—¶é—´ï¼›åœ¨ä¸äººç±»æˆ–å…¶ä»–åŠ¨ç‰©å·¥ä½œæ—¶ï¼Œå‡å°‘ç–¼ç—›å’Œä¸é€‚ä¹Ÿå¾ˆé‡è¦ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³é¢„æµ‹æ‚£è€…å‘ç”Ÿå¿ƒè„ç—…å‘ä½œçš„é£é™©ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æµ‹é‡å¾ˆå¤šå˜é‡æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡æµ‹é‡å°‘é‡æ›´ä¸å…·ä¾µå…¥æ€§çš„å˜é‡æ¥å®ç°ã€‚
- en: We want to reduce the computational cost. This is not a problem for small and
    simple models, but when we have a lot of variables, a lot of data, or both, the
    computational cost can be prohibitive.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›å‡å°‘è®¡ç®—æˆæœ¬ã€‚è¿™å¯¹äºå°å‹å’Œç®€å•æ¨¡å‹æ¥è¯´ä¸æ˜¯é—®é¢˜ï¼Œä½†å½“æˆ‘ä»¬æœ‰å¤§é‡å˜é‡ã€å¤§é‡æ•°æ®æˆ–ä¸¤è€…å…¼æœ‰æ—¶ï¼Œè®¡ç®—æˆæœ¬å¯èƒ½ä¼šå˜å¾—æ— æ³•æ‰¿å—ã€‚
- en: 'We seek a better understanding of significant correlation structures. That
    is, we are interested in understanding which variables provide better predictions.
    It is important to state that we are not talking about causality. While statistical
    models, in particular, GLMS, can be used to infer causality, doing so requires
    extra steps and assumptions. In this book, we do not discuss how to perform causal
    inference. For a very gentle introduction to causal inference, please see this
    video: [https://www.youtube.com/watch?v=gV6wzTk3o1U](https://www.youtube.com/watch?v=gV6wzTk3o1U).
    If you are more serious, you can check out the online book Causal Inference: The
    Mixtape by Scott Cunningham [[Cunningham](Bibliography.xhtml#Xcunningham2021causal),Â [2021](Bibliography.xhtml#Xcunningham2021causal)]
    [https://mixtape.scunning.com/](https://mixtape.scunning.com/).'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯»æ±‚æ›´å¥½åœ°ç†è§£é‡è¦çš„å…³è”ç»“æ„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬æœ‰å…´è¶£ç†è§£å“ªäº›å˜é‡æä¾›æ›´å¥½çš„é¢„æµ‹ã€‚éœ€è¦æ˜ç¡®çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸æ˜¯åœ¨è®¨è®ºå› æœå…³ç³»ã€‚è™½ç„¶ç»Ÿè®¡æ¨¡å‹ï¼Œå°¤å…¶æ˜¯å¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼ˆGLMSï¼‰ï¼Œå¯ä»¥ç”¨æ¥æ¨æ–­å› æœå…³ç³»ï¼Œä½†è¿™éœ€è¦é¢å¤–çš„æ­¥éª¤å’Œå‡è®¾ã€‚åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬ä¸è®¨è®ºå¦‚ä½•è¿›è¡Œå› æœæ¨æ–­ã€‚å¦‚æœä½ æƒ³è¦ä¸€ä¸ªéå¸¸åŸºç¡€çš„å› æœæ¨æ–­ä»‹ç»ï¼Œè¯·å‚è§è¿™ä¸ªè§†é¢‘ï¼š[https://www.youtube.com/watch?v=gV6wzTk3o1U](https://www.youtube.com/watch?v=gV6wzTk3o1U)ã€‚å¦‚æœä½ æ›´åŠ ä¸¥è‚ƒï¼Œæ‚¨å¯ä»¥æŸ¥é˜…Scott
    Cunninghamçš„åœ¨çº¿ä¹¦ç±ã€Šå› æœæ¨æ–­ï¼šæ··éŸ³å¸¦ã€‹[[Cunningham](Bibliography.xhtml#Xcunningham2021causal)ï¼Œ[2021](Bibliography.xhtml#Xcunningham2021causal)]
    [https://mixtape.scunning.com/](https://mixtape.scunning.com/)ã€‚
- en: When we desire a model that is more resilient to changes in the data-generating
    distribution, we can see variable selection as a method to make the model more
    robust against unrepresentative data.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬å¸Œæœ›è·å¾—ä¸€ä¸ªå¯¹æ•°æ®ç”Ÿæˆåˆ†å¸ƒå˜åŒ–æ›´å…·éŸ§æ€§çš„æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†å˜é‡é€‰æ‹©è§†ä¸ºä¸€ç§ä½¿æ¨¡å‹å¯¹ä¸å…·ä»£è¡¨æ€§æ•°æ®æ›´åŠ ç¨³å¥çš„æ–¹æ³•ã€‚
- en: 6.9.1 Projection predictive inference
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.9.1 æŠ•å½±é¢„æµ‹æ¨æ–­
- en: There are many methods to perform variable selection. In this section, we will
    focus on one of them called projection predictive inference [[Piironen etÂ al.](Bibliography.xhtml#XPiironen2020),Â [2020](Bibliography.xhtml#XPiironen2020),Â [McLatchie
    etÂ al.](Bibliography.xhtml#Xmclatchie2023),Â [2023](Bibliography.xhtml#Xmclatchie2023)].
    The main reason we are focusing on this single method is that it has shown very
    good performance across a broad range of fields.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰è®¸å¤šæ–¹æ³•å¯ä»¥æ‰§è¡Œå˜é‡é€‰æ‹©ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç»å…¶ä¸­ä¸€ç§å«åšæŠ•å½±é¢„æµ‹æ¨æ–­çš„æ–¹æ³•[[Piironenç­‰äºº](Bibliography.xhtml#XPiironen2020)ï¼Œ[2020](Bibliography.xhtml#XPiironen2020)ï¼Œ[McLatchieç­‰äºº](Bibliography.xhtml#Xmclatchie2023)ï¼Œ[2023](Bibliography.xhtml#Xmclatchie2023)]ã€‚æˆ‘ä»¬ä¸“æ³¨äºè¿™ç§æ–¹æ³•çš„ä¸»è¦åŸå› æ˜¯ï¼Œå®ƒåœ¨å¹¿æ³›çš„é¢†åŸŸä¸­è¡¨ç°å‡ºäº†éå¸¸å¥½çš„æ€§èƒ½ã€‚
- en: 'The main steps of projective prediction inference are:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ•å½±é¢„æµ‹æ¨æ–­çš„ä¸»è¦æ­¥éª¤å¦‚ä¸‹ï¼š
- en: Generate a reference model, i.e., a model with all the variables you think can
    be relevant and/or you were able to measure.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆä¸€ä¸ªå‚è€ƒæ¨¡å‹ï¼Œå³åŒ…å«æ‰€æœ‰ä½ è®¤ä¸ºå¯èƒ½ç›¸å…³å’Œ/æˆ–ä½ èƒ½å¤Ÿæµ‹é‡çš„å˜é‡çš„æ¨¡å‹ã€‚
- en: Generate a set of submodels, i.e., models that only include some subset of the
    variables in the reference model.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆä¸€ç»„å­æ¨¡å‹ï¼Œå³ä»…åŒ…å«å‚è€ƒæ¨¡å‹ä¸­æŸäº›å­é›†å˜é‡çš„æ¨¡å‹ã€‚
- en: Project the reference modelâ€™s posterior distribution into the submodels.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å‚è€ƒæ¨¡å‹çš„åéªŒåˆ†å¸ƒæŠ•å½±åˆ°å­æ¨¡å‹ä¸­ã€‚
- en: Pick the smallest model that makes predictions close enough to the reference
    model.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€‰æ‹©ä¸€ä¸ªé¢„æµ‹ç»“æœä¸å‚è€ƒæ¨¡å‹è¶³å¤Ÿæ¥è¿‘çš„æœ€å°æ¨¡å‹ã€‚
- en: When doing projection predictive inference, we only need to perform Bayesian
    inference once, just for the reference model. For the submodels, the posteriors
    are projected. Without going into the technical details, the projection consists
    of finding the parameters for the submodels in such a way that the predictions
    of the submodels are as close as possible to the predictions of the reference
    model. The projection can be done in a computationally efficient way so the cost
    of estimating a posterior is orders of magnitude cheaper than with MCMC methods.
    This is relevant because the total number of possible submodels explodes as we
    increase the number of variables in the reference model. Consider that we need
    to evaluate all possible combinations, without repeating variables. For instance,
    say we have four variables (*A*, *B*, *C*, and *D*) and we need to evaluate 7
    models, namely, *A*, *B*, *C*, *AB*, *BC*, *AC*, and the reference model *ABC*.
    Seven does not sound like a lot, but by the time we reach 8 variables, we will
    need to evaluate 92 different models. See, we double the number of variables,
    and the number of models increases more than 10 times!
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿›è¡ŒæŠ•å½±é¢„æµ‹æ¨æ–­æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦æ‰§è¡Œä¸€æ¬¡è´å¶æ–¯æ¨æ–­ï¼Œä»…é’ˆå¯¹å‚è€ƒæ¨¡å‹ã€‚å¯¹äºå­æ¨¡å‹ï¼ŒåéªŒåˆ†å¸ƒæ˜¯é€šè¿‡æŠ•å½±å¾—åˆ°çš„ã€‚ä¸æ·±å…¥è®¨è®ºæŠ€æœ¯ç»†èŠ‚ï¼ŒæŠ•å½±è¿‡ç¨‹æ˜¯é€šè¿‡æŸç§æ–¹å¼æ‰¾åˆ°å­æ¨¡å‹çš„å‚æ•°ï¼Œä½¿å¾—å­æ¨¡å‹çš„é¢„æµ‹å°½å¯èƒ½æ¥è¿‘å‚è€ƒæ¨¡å‹çš„é¢„æµ‹ã€‚è¿™ä¸ªæŠ•å½±è¿‡ç¨‹å¯ä»¥ä»¥è®¡ç®—æ•ˆç‡é«˜çš„æ–¹å¼è¿›è¡Œï¼Œå› æ­¤ä¼°è®¡åéªŒåˆ†å¸ƒçš„æˆæœ¬æ¯”ä½¿ç”¨MCMCæ–¹æ³•ä½å‡ ä¸ªæ•°é‡çº§ã€‚è¿™ä¸€ç‚¹å¾ˆé‡è¦ï¼Œå› ä¸ºå½“æˆ‘ä»¬å¢åŠ å‚è€ƒæ¨¡å‹ä¸­çš„å˜é‡æ•°æ—¶ï¼Œå¯èƒ½çš„å­æ¨¡å‹æ€»æ•°ä¼šå‘ˆæŒ‡æ•°å¢é•¿ã€‚è€ƒè™‘ä¸€ä¸‹æˆ‘ä»¬éœ€è¦è¯„ä¼°æ‰€æœ‰å¯èƒ½çš„ç»„åˆï¼Œä¸é‡å¤å˜é‡ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æœ‰å››ä¸ªå˜é‡ï¼ˆ*A*ï¼Œ*B*ï¼Œ*C*
    å’Œ *D*ï¼‰ï¼Œéœ€è¦è¯„ä¼°7ä¸ªæ¨¡å‹ï¼Œåˆ†åˆ«æ˜¯ *A*ï¼Œ*B*ï¼Œ*C*ï¼Œ*AB*ï¼Œ*BC*ï¼Œ*AC* å’Œå‚è€ƒæ¨¡å‹ *ABC*ã€‚ä¸ƒä¸ªæ¨¡å‹å¬èµ·æ¥ä¸å¤šï¼Œä½†å½“æˆ‘ä»¬å¢åŠ åˆ°8ä¸ªå˜é‡æ—¶ï¼Œæˆ‘ä»¬å°†éœ€è¦è¯„ä¼°92ä¸ªä¸åŒçš„æ¨¡å‹ã€‚çœ‹åˆ°æ²¡æœ‰ï¼Œæˆ‘ä»¬å°†å˜é‡æ•°ç¿»å€ï¼Œæ¨¡å‹çš„æ•°é‡å´å¢åŠ äº†10å€ä»¥ä¸Šï¼
- en: Of course, there are ways to reduce the total number of submodels to explore.
    For instance, we could use some cheap method to filter out the most promising
    variables and only do projection predictive inference on those. Another alternative
    is known as forward search; that is, we first fit as many models as the variables
    we have. We then select one model/variable, the one generating the closest predictions
    to the reference model. We then generate all the submodels with 2 variables that
    included the variable selected in the previous step and so on. If we do this forward
    procedure for a reference model with 8 variables instead of 92 different models,
    we will need to evaluate just 36.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œå‡å°‘éœ€è¦æ¢ç´¢çš„å­æ¨¡å‹æ€»æ•°æ˜¯æœ‰åŠæ³•çš„ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æŸäº›å»‰ä»·æ–¹æ³•ç­›é€‰å‡ºæœ€æœ‰å‰æ™¯çš„å˜é‡ï¼Œç„¶ååªå¯¹è¿™äº›å˜é‡è¿›è¡ŒæŠ•å½±é¢„æµ‹æ¨æ–­ã€‚å¦ä¸€ä¸ªæ›¿ä»£æ–¹æ¡ˆè¢«ç§°ä¸ºå‰å‘æœç´¢ï¼›ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆæ‹Ÿåˆä¸æˆ‘ä»¬æ‰€æ‹¥æœ‰çš„å˜é‡æ•°é‡ç›¸ç­‰çš„æ¨¡å‹ã€‚ç„¶åé€‰æ‹©ä¸€ä¸ªæ¨¡å‹/å˜é‡ï¼Œå³ç”Ÿæˆä¸å‚è€ƒæ¨¡å‹çš„é¢„æµ‹æœ€æ¥è¿‘çš„é‚£ä¸ªæ¨¡å‹ã€‚æ¥ç€ï¼Œæˆ‘ä»¬ç”Ÿæˆæ‰€æœ‰åŒ…å«ä¸Šä¸€é˜¶æ®µé€‰æ‹©å˜é‡çš„ä¸¤ä¸ªå˜é‡å­æ¨¡å‹ï¼Œä¾æ­¤ç±»æ¨ã€‚å¦‚æœæˆ‘ä»¬å¯¹ä¸€ä¸ªåŒ…å«8ä¸ªå˜é‡çš„å‚è€ƒæ¨¡å‹è¿›è¡Œè¿™ç§å‰å‘ç¨‹åºï¼Œè€Œä¸æ˜¯92ä¸ªä¸åŒçš„æ¨¡å‹ï¼Œæˆ‘ä»¬åªéœ€è¦è¯„ä¼°36ä¸ªæ¨¡å‹ã€‚
- en: Another aspect that is relevant to consider when doing projection predictive
    inference is that we only provided priors for the reference model. The submodels
    donâ€™t have explicit priors; they just inherit, somehow, the priors of the reference
    model through the projection procedure.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªåœ¨è¿›è¡ŒæŠ•å½±é¢„æµ‹æ¨æ–­æ—¶éœ€è¦è€ƒè™‘çš„å› ç´ æ˜¯ï¼Œæˆ‘ä»¬åªä¸ºå‚è€ƒæ¨¡å‹æä¾›äº†å…ˆéªŒåˆ†å¸ƒã€‚å­æ¨¡å‹æ²¡æœ‰æ˜ç¡®çš„å…ˆéªŒåˆ†å¸ƒï¼›å®ƒä»¬åªæ˜¯é€šè¿‡æŠ•å½±è¿‡ç¨‹ç»§æ‰¿äº†å‚è€ƒæ¨¡å‹çš„å…ˆéªŒåˆ†å¸ƒã€‚
- en: One reason projective prediction works in practice is thanks to the use of a
    reference model. By fitting the submodels to the in-sample predictions made by
    the reference model, instead of the observed data, we are filtering out the noise
    in the data. This helps separate the more relevant variables from the less relevant
    ones. Another factor is the use of cross-validation in selecting the submodels,
    as discussed in *Chapter [5](CH05.xhtml#x1-950005)*.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ•å½±é¢„æµ‹åœ¨å®è·µä¸­æœ‰æ•ˆçš„åŸå› ä¹‹ä¸€ï¼Œæ­£æ˜¯å¾—ç›Šäºå‚è€ƒæ¨¡å‹çš„ä½¿ç”¨ã€‚é€šè¿‡å°†å­æ¨¡å‹æ‹Ÿåˆåˆ°å‚è€ƒæ¨¡å‹åœ¨æ ·æœ¬ä¸­çš„é¢„æµ‹ï¼Œè€Œä¸æ˜¯æ‹Ÿåˆè§‚å¯Ÿåˆ°çš„æ•°æ®ï¼Œæˆ‘ä»¬èƒ½å¤Ÿè¿‡æ»¤æ‰æ•°æ®ä¸­çš„å™ªå£°ã€‚è¿™æœ‰åŠ©äºå°†æ›´ç›¸å…³çš„å˜é‡ä¸ä¸å¤ªç›¸å…³çš„å˜é‡åŒºåˆ†å¼€ã€‚å¦ä¸€ä¸ªå› ç´ æ˜¯ï¼Œåœ¨é€‰æ‹©å­æ¨¡å‹æ—¶ä½¿ç”¨äº†äº¤å‰éªŒè¯ï¼Œå¦‚åœ¨*ç¬¬[5](CH05.xhtml#x1-950005)ç« *ä¸­æ‰€è®¨è®ºçš„é‚£æ ·ã€‚
- en: 6.9.2 Projection predictive with Kulprit
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.9.2 ä½¿ç”¨Kulpritè¿›è¡ŒæŠ•å½±é¢„æµ‹
- en: Kulprit is a Python package for projection predictive inference. It works with
    Bambi, as we can pass a reference model built with it and Kulprit will do all
    the hard work for us. To illustrate how to use Kulprit, we are going to use the
    body fat dataset [[Penrose etÂ al.](Bibliography.xhtml#Xpenrose1985),Â [1985](Bibliography.xhtml#Xpenrose1985)].
    This dataset has measurements from 251 individuals, including their age, weight,
    height, the circumference of the abdomen, etc. Our purpose is to predict the percentage
    of body fat (as estimated by the `siri` variable). Since obtaining accurate measurements
    of body fat is expensive and potentially annoying for patients, we want to reduce
    the measurements while keeping a good predictive accuracy for `siri`. The original
    dataset included 13 variables; to keep this example really simple, I have preselected
    6.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Kulprit æ˜¯ä¸€ä¸ªç”¨äºæŠ•å½±é¢„æµ‹æ¨æ–­çš„ Python åŒ…ã€‚å®ƒä¸ Bambi é…åˆä½¿ç”¨ï¼Œæˆ‘ä»¬å¯ä»¥ä¼ é€’ä¸€ä¸ªç”¨ Bambi æ„å»ºçš„å‚è€ƒæ¨¡å‹ï¼ŒKulprit
    ä¼šä¸ºæˆ‘ä»¬å®Œæˆæ‰€æœ‰å¤æ‚çš„å·¥ä½œã€‚ä¸ºäº†è¯´æ˜å¦‚ä½•ä½¿ç”¨ Kulpritï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä½“è„‚æ•°æ®é›† [[Penrose et al.](Bibliography.xhtml#Xpenrose1985),
    [1985](Bibliography.xhtml#Xpenrose1985)]ã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å«äº†251ä¸ªä¸ªä½“çš„æµ‹é‡æ•°æ®ï¼ŒåŒ…æ‹¬ä»–ä»¬çš„å¹´é¾„ã€ä½“é‡ã€èº«é«˜ã€è…¹å›´ç­‰ã€‚æˆ‘ä»¬çš„ç›®çš„æ˜¯é¢„æµ‹ä½“è„‚ç™¾åˆ†æ¯”ï¼ˆé€šè¿‡
    `siri` å˜é‡ä¼°ç®—ï¼‰ã€‚ç”±äºè·å¾—å‡†ç¡®çš„ä½“è„‚æµ‹é‡æ—¢æ˜‚è´µåˆå¯èƒ½å¯¹æ‚£è€…é€ æˆå›°æ‰°ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨å‡å°‘æµ‹é‡æ•°é‡çš„åŒæ—¶ä¿æŒ `siri` çš„è‰¯å¥½é¢„æµ‹å‡†ç¡®æ€§ã€‚åŸå§‹æ•°æ®é›†åŒ…å«13ä¸ªå˜é‡ï¼›ä¸ºäº†ç®€åŒ–ç¤ºä¾‹ï¼Œæˆ‘å·²ç»é¢„å…ˆé€‰æ‹©äº†6ä¸ªå˜é‡ã€‚
- en: 'The first thing we need to do is to define and fit a Bambi model, as usual.
    We have to be sure that we include the argument `idata_kwargs=â€™log_likelihoodâ€™:True`.
    Internally, Kulprit computes the ELPD, and as we discussed in *Chapter [5](CH05.xhtml#x1-950005)*,
    we need the log likelihood in the InferenceData object to be able to estimate
    the ELPD:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆéœ€è¦åƒå¾€å¸¸ä¸€æ ·å®šä¹‰å¹¶æ‹Ÿåˆä¸€ä¸ª Bambi æ¨¡å‹ã€‚æˆ‘ä»¬å¿…é¡»ç¡®ä¿åŒ…å«å‚æ•° `idata_kwargs=â€™log_likelihoodâ€™:True`ã€‚Kulprit
    å†…éƒ¨ä¼šè®¡ç®— ELPDï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨ *ç¬¬ [5](CH05.xhtml#x1-950005) ç« * ä¸­è®¨è®ºçš„é‚£æ ·ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ InferenceData å¯¹è±¡ä¸­åŒ…å«å¯¹æ•°ä¼¼ç„¶å€¼ï¼Œä»¥ä¾¿èƒ½å¤Ÿä¼°ç®—
    ELPDï¼š
- en: '**CodeÂ 6.22**'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.22**'
- en: '[PRE23]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'After this, we are ready to use Kulprit. First, we need to call the `ProjectionPredictive`
    class and pass the Bambi model and the idata resulting from the fit of that model.
    Then we ask Kulprit to perform a search; by default, it will do a forward search:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæˆè¿™äº›åï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹ä½¿ç”¨ Kulprit äº†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦è°ƒç”¨ `ProjectionPredictive` ç±»ï¼Œå¹¶ä¼ å…¥ Bambi æ¨¡å‹å’Œä»è¯¥æ¨¡å‹æ‹Ÿåˆå¾—åˆ°çš„
    idataã€‚ç„¶åæˆ‘ä»¬è®© Kulprit æ‰§è¡Œæœç´¢ï¼›é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒä¼šè¿›è¡Œå‰å‘æœç´¢ï¼š
- en: 'CodeÂ 6.23:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç  6.23ï¼š
- en: '[PRE24]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: After the search has finished, we can ask Kulprit to compare the submodels in
    terms of the ELPD. The submodels will show ordered from lowest ELPD to highest,
    as in *Figure [6.17](#x1-133012r17)*. On the x-axis, we have the submodel size,
    i.e., number of variables; we start at zero because we include the intercept-only
    model. The dashed gray line corresponds to the ELPD for the reference model.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: æœç´¢å®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥è®© Kulprit æ ¹æ® ELPD æ¯”è¾ƒå„ä¸ªå­æ¨¡å‹ã€‚å­æ¨¡å‹ä¼šæŒ‰ ELPD ä»ä½åˆ°é«˜æ’åºï¼Œå¦‚ *å›¾ [6.17](#x1-133012r17)*
    æ‰€ç¤ºã€‚åœ¨ x è½´ä¸Šï¼Œæˆ‘ä»¬æœ‰å­æ¨¡å‹çš„å¤§å°ï¼Œå³å˜é‡çš„æ•°é‡ï¼›æˆ‘ä»¬ä»é›¶å¼€å§‹ï¼Œå› ä¸ºæˆ‘ä»¬åŒ…å«äº†ä»…æœ‰æˆªè·çš„æ¨¡å‹ã€‚è™šçº¿ç°è‰²çº¿è¡¨ç¤ºå‚è€ƒæ¨¡å‹çš„ ELPDã€‚
- en: '![PIC](img/file193.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file193.png)'
- en: '**FigureÂ 6.17**: Comparison of the submodels obtained with Kulprit. Generated
    with `ppi.plot_compare`'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.17**ï¼šä½¿ç”¨ Kulprit å¾—åˆ°çš„å­æ¨¡å‹æ¯”è¾ƒã€‚ç”± `ppi.plot_compare` ç”Ÿæˆã€‚'
- en: 'We can see then that a submodel of size 3 is practically equivalent to the
    reference model. But what variables are exactly included in this and the other
    submodels? If we print the `ppi` object, after performing a search, we will get
    an ordered list of the formulas for the submodels matching the order in the plot
    obtained with the command `ppi.plot_compare`:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¤§å°ä¸º 3 çš„å­æ¨¡å‹å‡ ä¹ä¸å‚è€ƒæ¨¡å‹ç­‰æ•ˆã€‚ä½†å…·ä½“åŒ…å«äº†å“ªäº›å˜é‡å‘¢ï¼Ÿå¦‚æœæˆ‘ä»¬åœ¨æ‰§è¡Œæœç´¢åæ‰“å° `ppi` å¯¹è±¡ï¼Œæˆ‘ä»¬å°†å¾—åˆ°ä¸€ä¸ªå­æ¨¡å‹å…¬å¼çš„æœ‰åºåˆ—è¡¨ï¼Œåˆ—è¡¨é¡ºåºä¸é€šè¿‡å‘½ä»¤
    `ppi.plot_compare` å¾—åˆ°çš„å›¾ä¸­çš„é¡ºåºç›¸åŒ¹é…ï¼š
- en: '**CodeÂ 6.24**'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.24**'
- en: '[PRE25]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Then we can see that the model of size 3 is the one including the variables
    `abdomen`, `wrist`, and `height`. This result tells us that if we want to choose
    a model with fewer variables than the reference model but with similar predictive
    accuracy, then this is a good choice. Depending on the context, other submodels
    may also be a good idea. For instance, we may argue that the difference between
    the submodel of sizes 2 and 3 is rather small. Thus, we may be willing to sacrifice
    some accuracy in favor of an even smaller model. For this example, measuring the
    height of patients may not be that problematic, but for other scenarios, adding
    a third variable could be expensive, annoying, dangerous, etc.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¤§å°ä¸º 3 çš„æ¨¡å‹æ˜¯åŒ…å«å˜é‡ `abdomen`ï¼ˆè…¹éƒ¨ï¼‰ã€`wrist`ï¼ˆæ‰‹è…•ï¼‰å’Œ `height`ï¼ˆèº«é«˜ï¼‰çš„æ¨¡å‹ã€‚è¿™ä¸ªç»“æœå‘Šè¯‰æˆ‘ä»¬ï¼Œå¦‚æœæˆ‘ä»¬æƒ³é€‰æ‹©ä¸€ä¸ªæ¯”å‚è€ƒæ¨¡å‹æ›´å°‘å˜é‡çš„æ¨¡å‹ï¼Œä½†é¢„æµ‹ç²¾åº¦ç›¸ä¼¼ï¼Œé‚£ä¹ˆè¿™æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚æ ¹æ®ä¸åŒçš„æƒ…å¢ƒï¼Œå…¶ä»–å­æ¨¡å‹ä¹Ÿå¯èƒ½æ˜¯ä¸€ä¸ªå¥½é€‰æ‹©ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè®¤ä¸ºå¤§å°ä¸º
    2 å’Œ 3 çš„å­æ¨¡å‹ä¹‹é—´çš„å·®å¼‚éå¸¸å°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯èƒ½æ„¿æ„ç‰ºç‰²ä¸€äº›ç²¾åº¦æ¥é€‰æ‹©ä¸€ä¸ªæ›´å°çš„æ¨¡å‹ã€‚å¯¹äºè¿™ä¸ªä¾‹å­æ¥è¯´ï¼Œæµ‹é‡æ‚£è€…èº«é«˜å¯èƒ½ä¸ä¼šå¸¦æ¥å¤ªå¤§é—®é¢˜ï¼Œä½†åœ¨å…¶ä»–åœºæ™¯ä¸‹ï¼Œæ·»åŠ ç¬¬ä¸‰ä¸ªå˜é‡å¯èƒ½ä¼šå¾ˆæ˜‚è´µã€éº»çƒ¦ã€å±é™©ç­‰ç­‰ã€‚
- en: Another way to interpret *Figure [6.17](#x1-133012r17)* is by noticing how close
    the ELPDs are for models with size 3 or larger. It may be the case that if we
    repeat the analysis with a slightly different dataset, or even the same dataset
    but with more posterior samples, we could get a slightly different order. Thus,
    if we have many models of size 3 with potentially the same practical predictive
    accuracy, we could justify the selection of the third variable by external factors
    such as how easy or cheap it is to measure, or which one will be less painful
    for patients, etc. In summary, as with other statistical tools, results should
    not be taken blindly but in context; you should have the final word and the tools
    should help you inform your decisions.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ç§è§£é‡Š *å›¾ [6.17](#x1-133012r17)* çš„æ–¹å¼æ˜¯æ³¨æ„åˆ°å¤§å°ä¸º 3 æˆ–æ›´å¤§çš„æ¨¡å‹çš„ ELPD å€¼æ˜¯éå¸¸æ¥è¿‘çš„ã€‚å¯èƒ½çš„æƒ…å†µæ˜¯ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨ç¨å¾®ä¸åŒçš„æ•°æ®é›†ï¼Œç”šè‡³æ˜¯ç›¸åŒçš„æ•°æ®é›†ï¼Œä½†å¢åŠ æ›´å¤šçš„åéªŒæ ·æœ¬ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šå¾—åˆ°ä¸€ä¸ªç•¥æœ‰ä¸åŒçš„é¡ºåºã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æœ‰è®¸å¤šå¤§å°ä¸º
    3 çš„æ¨¡å‹ï¼Œå®ƒä»¬å¯èƒ½å…·æœ‰ç›¸åŒçš„å®é™…é¢„æµ‹ç²¾åº¦ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¤–éƒ¨å› ç´ æ¥ä¸ºé€‰æ‹©ç¬¬ä¸‰ä¸ªå˜é‡æä¾›ç†ç”±ï¼Œæ¯”å¦‚å®ƒçš„æµ‹é‡æ˜¯å¦å®¹æ˜“æˆ–ä¾¿å®œï¼Œæˆ–è€…å“ªä¸ªå¯¹æ‚£è€…æ¥è¯´æ›´ä¸ç—›è‹¦ç­‰ç­‰ã€‚æ€»ä¹‹ï¼Œå’Œå…¶ä»–ç»Ÿè®¡å·¥å…·ä¸€æ ·ï¼Œç»“æœä¸åº”ç›²ç›®æ¥å—ï¼Œè€Œæ˜¯è¦ç»“åˆä¸Šä¸‹æ–‡æ¥è§£è¯»ï¼›ä½ åº”è¯¥æœ‰æœ€ç»ˆçš„å†³å®šæƒï¼Œå·¥å…·åº”å¸®åŠ©ä½ åšå‡ºå†³ç­–ã€‚
- en: 'OK, letâ€™s say that we are indeed interested in the submodel of size 3 computed
    by Kulprit; we can get it with:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œå‡è®¾æˆ‘ä»¬ç¡®å®å¯¹ Kulprit è®¡ç®—çš„å¤§å°ä¸º 3 çš„å­æ¨¡å‹æ„Ÿå…´è¶£ï¼›æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–å®ƒï¼š
- en: '**CodeÂ 6.25**'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»£ç  6.25**'
- en: '[PRE27]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: From the `submodel` object, we can then retrieve some useful information like
    Bambiâ€™s model `submodel.model` or the InferenceData object `submodel.idata`.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ä» `submodel` å¯¹è±¡ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æ£€ç´¢ä¸€äº›æœ‰ç”¨çš„ä¿¡æ¯ï¼Œæ¯”å¦‚ Bambi çš„æ¨¡å‹ `submodel.model` æˆ– InferenceData
    å¯¹è±¡ `submodel.idata`ã€‚
- en: One word of caution about interpreting these two objectsâ€”`submodel.model` is
    a Bambi model generated from a formula. Thus, its priors will be those automatically
    computed by Bambi. But, the posterior that Kulprit computes, which is stored in
    `submodel.idata.posterior`, does not come directly from this model. Instead, it
    is computed using projection predictive inference (not MCMC) with priors that
    are implicitly inherited during the projection step (not explicit priors). *Figure
    [6.18](#x1-133019r18)* shows such a projected posterior.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè§£é‡Šè¿™ä¸¤ä¸ªå¯¹è±¡ï¼Œæœ‰ä¸€ç‚¹éœ€è¦æ³¨æ„â€”â€”`submodel.model` æ˜¯ä¸€ä¸ªç”±å…¬å¼ç”Ÿæˆçš„ Bambi æ¨¡å‹ã€‚å› æ­¤ï¼Œå®ƒçš„å…ˆéªŒå°†æ˜¯ Bambi è‡ªåŠ¨è®¡ç®—çš„é‚£äº›ã€‚ä½†
    Kulprit è®¡ç®—çš„åéªŒï¼Œå­˜å‚¨åœ¨ `submodel.idata.posterior` ä¸­ï¼Œå¹¶éç›´æ¥æ¥è‡ªè¯¥æ¨¡å‹ã€‚ç›¸åï¼Œå®ƒæ˜¯ä½¿ç”¨æŠ•å½±é¢„æµ‹æ¨ç†ï¼ˆè€Œé MCMCï¼‰è®¡ç®—çš„ï¼Œå…ˆéªŒæ˜¯åœ¨æŠ•å½±æ­¥éª¤ä¸­éšå¼ç»§æ‰¿çš„ï¼ˆè€Œéæ˜¾å¼å…ˆéªŒï¼‰ã€‚*å›¾
    [6.18](#x1-133019r18)* å±•ç¤ºäº†è¿™ç§æŠ•å½±åçš„åéªŒã€‚
- en: '![PIC](img/file194.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file194.png)'
- en: '**FigureÂ 6.18**: Projected posterior for submodel of size 3'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.18**ï¼šå¤§å°ä¸º 3 çš„å­æ¨¡å‹çš„æŠ•å½±åéªŒ'
- en: 'Can we trust projected posteriors? Under very general conditions this should
    be a valid posterior so we can trust it. It should be enough to give you an approximate
    idea of the values of the parameters and, of course, it is enough for variable
    selection. The lack of explicit priors could make the interpretation of the model
    more difficult, but if you only care about predictions, that should not be an
    issue. Of course, you can always use Bambi (or PyMC) to explicitly compute the
    full posterior as usual and specify the priors yourself if needed. *Figure [6.19](#x1-133020r19)*
    shows a forest plot for the posterior of the submodel as computed with Bambi (True)
    and approximated with Kulprit (Projected). Notice that there are two possible
    sources of differences here: the intrinsic differences between MCMC and projection
    predictive methods and the different priors for both models.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä¿¡ä»»é¢„æµ‹çš„åéªŒåˆ†å¸ƒå—ï¼Ÿåœ¨éå¸¸ä¸€èˆ¬çš„æ¡ä»¶ä¸‹ï¼Œè¿™åº”è¯¥æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„åéªŒåˆ†å¸ƒï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä¿¡ä»»å®ƒã€‚å®ƒåº”è¯¥è¶³å¤Ÿæä¾›å‚æ•°å€¼çš„å¤§è‡´æ¦‚å¿µï¼Œå½“ç„¶ï¼Œè¿™å¯¹äºå˜é‡é€‰æ‹©ä¹Ÿæ˜¯è¶³å¤Ÿçš„ã€‚ç¼ºä¹æ˜¾å¼çš„å…ˆéªŒå¯èƒ½ä¼šä½¿æ¨¡å‹çš„è§£é‡Šæ›´åŠ å›°éš¾ï¼Œä½†å¦‚æœä½ åªå…³å¿ƒé¢„æµ‹ï¼Œè¿™åº”è¯¥ä¸æ˜¯é—®é¢˜ã€‚å½“ç„¶ï¼Œä½ å§‹ç»ˆå¯ä»¥ä½¿ç”¨Bambiï¼ˆæˆ–PyMCï¼‰åƒå¾€å¸¸ä¸€æ ·æ˜¾å¼åœ°è®¡ç®—å®Œæ•´çš„åéªŒï¼Œå¹¶åœ¨éœ€è¦æ—¶è‡ªå·±æŒ‡å®šå…ˆéªŒã€‚*å›¾
    [6.19](#x1-133020r19)* æ˜¾ç¤ºäº†é€šè¿‡Bambiï¼ˆçœŸå®ï¼‰è®¡ç®—çš„å­æ¨¡å‹åéªŒçš„æ£®æ—å›¾å’Œé€šè¿‡Kulpritï¼ˆé¢„æµ‹ï¼‰è¿‘ä¼¼çš„å­æ¨¡å‹åéªŒã€‚è¯·æ³¨æ„ï¼Œè¿™é‡Œæœ‰ä¸¤ä¸ªå¯èƒ½çš„å·®å¼‚æ¥æºï¼šMCMCæ–¹æ³•ä¸æŠ•å½±é¢„æµ‹æ–¹æ³•ä¹‹é—´çš„å†…åœ¨å·®å¼‚ï¼Œä»¥åŠä¸¤ä¸ªæ¨¡å‹çš„ä¸åŒå…ˆéªŒã€‚
- en: '![PIC](img/file195.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file195.png)'
- en: '**FigureÂ 6.19**: Comparison of the posterior of the submodel (`siri ~abdomen
    + wrist + height`) as computed by Kulprit and the reference model as computed
    by Bambi; variables not shared by both models have been omitted'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾ 6.19**ï¼šé€šè¿‡Kulpritè®¡ç®—çš„å­æ¨¡å‹ï¼ˆ`siri ~abdomen + wrist + height`ï¼‰åéªŒä¸é€šè¿‡Bambiè®¡ç®—çš„å‚è€ƒæ¨¡å‹åéªŒçš„æ¯”è¾ƒï¼›æœªåœ¨ä¸¤ä¸ªæ¨¡å‹ä¸­å…±äº«çš„å˜é‡å·²è¢«çœç•¥'
- en: Kulprit is a very new library that will keep evolving, and users can expect
    numerous enhancements and refinements shortly. If Kulprit interests you, you can
    help with its development by reporting issues, suggesting ideas, improving the
    documentation, or working on its codebase at [https://github.com/bambinos/kulprit](https://github.com/bambinos/kulprit).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Kulpritæ˜¯ä¸€ä¸ªéå¸¸æ–°çš„åº“ï¼Œå°†ä¸æ–­å‘å±•ï¼Œç”¨æˆ·å¯ä»¥æœŸå¾…ä¸ä¹…åä¼šæœ‰å¤§é‡çš„å¢å¼ºå’Œæ”¹è¿›ã€‚å¦‚æœKulpritå¼•èµ·äº†ä½ çš„å…´è¶£ï¼Œä½ å¯ä»¥é€šè¿‡æŠ¥å‘Šé—®é¢˜ã€æå‡ºå»ºè®®ã€æ”¹è¿›æ–‡æ¡£æˆ–å‚ä¸å…¶ä»£ç åº“çš„å¼€å‘æ¥å¸®åŠ©å…¶å‘å±•ï¼Œç½‘å€æ˜¯[https://github.com/bambinos/kulprit](https://github.com/bambinos/kulprit)ã€‚
- en: 6.10 Summary
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.10 å°ç»“
- en: In this chapter, we have seen how to use Bambi to fit Bayesian models as an
    alternative to the pure PyMC model. We start with the simplest case, a model with
    a single predictor, and then move to more complex models, including polynomials,
    splines, distributional models, models with categorical predictors, and interactions.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ°å¦‚ä½•ä½¿ç”¨Bambiæ‹Ÿåˆè´å¶æ–¯æ¨¡å‹ï¼Œä½œä¸ºçº¯PyMCæ¨¡å‹çš„æ›¿ä»£æ–¹æ¡ˆã€‚æˆ‘ä»¬ä»æœ€ç®€å•çš„æƒ…å†µå¼€å§‹ï¼Œä¸€ä¸ªåŒ…å«å•ä¸€é¢„æµ‹å˜é‡çš„æ¨¡å‹ï¼Œç„¶åè¿‡æ¸¡åˆ°æ›´å¤æ‚çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬å¤šé¡¹å¼ã€æ ·æ¡ã€åˆ†å¸ƒæ¨¡å‹ã€åŒ…å«åˆ†ç±»é¢„æµ‹å˜é‡çš„æ¨¡å‹ä»¥åŠäº¤äº’ä½œç”¨æ¨¡å‹ã€‚
- en: The main advantage of Bambi is that it is very easy to use; it is very similar
    to Râ€™s `formula` syntax. And internally, Bambi defines weakly informative priors
    and handles details that can be cumbersome for complex models. The main disadvantage
    is that it is not as flexible as PyMC. The range of models that Bambi can handle
    is a small subset of those from PyMC. Still, this subset contains many of the
    most commonly used statistical models in both industry and academia. The strength
    of Bambi is not just easy model building, but easier model interpretation. Across
    the chapter, we have seen how to use Bambiâ€™s `interpret` module to gain a better
    understanding of the models we fit. Finally, we have seen how to use Kulprit to
    perform projection predictive inference and perform variable selection. Projection
    predictive inference offers a promising approach to variable selection, and Kulprit
    is a promising Pythonic way of doing it.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Bambiçš„ä¸»è¦ä¼˜åŠ¿åœ¨äºå®ƒéå¸¸æ˜“äºä½¿ç”¨ï¼›å®ƒä¸Rçš„`formula`è¯­æ³•éå¸¸ç›¸ä¼¼ã€‚å†…éƒ¨ï¼ŒBambiå®šä¹‰äº†å¼±ä¿¡æ¯é‡çš„å…ˆéªŒï¼Œå¹¶å¤„ç†äº†å¤æ‚æ¨¡å‹ä¸­å¯èƒ½ç¹ççš„ç»†èŠ‚ã€‚ä¸»è¦çš„ç¼ºç‚¹æ˜¯å®ƒä¸åƒPyMCé‚£æ ·çµæ´»ã€‚Bambièƒ½å¤Ÿå¤„ç†çš„æ¨¡å‹èŒƒå›´æ˜¯PyMCæ¨¡å‹èŒƒå›´çš„ä¸€ä¸ªå°å­é›†ã€‚ä¸è¿‡ï¼Œè¿™ä¸ªå­é›†åŒ…å«äº†å·¥ä¸šç•Œå’Œå­¦æœ¯ç•Œä¸­æœ€å¸¸ç”¨çš„è®¸å¤šç»Ÿè®¡æ¨¡å‹ã€‚Bambiçš„ä¼˜åŠ¿ä¸ä»…ä»…åœ¨äºè½»æ¾æ„å»ºæ¨¡å‹ï¼Œè¿˜åœ¨äºæ›´å®¹æ˜“çš„æ¨¡å‹è§£é‡Šã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ°å¦‚ä½•ä½¿ç”¨Bambiçš„`interpret`æ¨¡å—æ›´å¥½åœ°ç†è§£æˆ‘ä»¬æ‹Ÿåˆçš„æ¨¡å‹ã€‚æœ€åï¼Œæˆ‘ä»¬è¿˜çœ‹åˆ°äº†å¦‚ä½•ä½¿ç”¨Kulpritè¿›è¡ŒæŠ•å½±é¢„æµ‹æ¨æ–­å¹¶è¿›è¡Œå˜é‡é€‰æ‹©ã€‚æŠ•å½±é¢„æµ‹æ¨æ–­ä¸ºå˜é‡é€‰æ‹©æä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ï¼Œè€ŒKulpritåˆ™æ˜¯ä¸€ç§æœ‰å‰æ™¯çš„PythonåŒ–æ–¹å¼ã€‚
- en: 6.11 Exercises
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.11 ç»ƒä¹ 
- en: Read the Bambi documentation ( [https://bambinos.github.io/bambi/](https://bambinos.github.io/bambi/))
    and learn how to specify custom priors.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é˜…è¯»Bambiæ–‡æ¡£ï¼ˆ[https://bambinos.github.io/bambi/](https://bambinos.github.io/bambi/)ï¼‰å¹¶å­¦ä¹ å¦‚ä½•æŒ‡å®šè‡ªå®šä¹‰å…ˆéªŒã€‚
- en: Apply what you learned in the previous point and specify a HalfNormal prior
    for the slope of `model_t`.
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åº”ç”¨å‰ä¸€ç‚¹å­¦åˆ°çš„å†…å®¹ï¼Œä¸º `model_t` çš„æ–œç‡æŒ‡å®šä¸€ä¸ª HalfNormal å…ˆéªŒåˆ†å¸ƒã€‚
- en: Define a model like `model_poly4`, but using `raw` polynomials, compare the
    coefficients and the mean fit of both models.
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®šä¹‰ä¸€ä¸ªç±»ä¼¼ `model_poly4` çš„æ¨¡å‹ï¼Œä½†ä½¿ç”¨ `raw` å¤šé¡¹å¼ï¼Œæ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹çš„ç³»æ•°å’Œå‡å€¼æ‹Ÿåˆæ•ˆæœã€‚
- en: Explain in your own words what a distributional model is.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”¨ä½ è‡ªå·±çš„è¯è§£é‡Šä»€ä¹ˆæ˜¯åˆ†å¸ƒæ¨¡å‹ã€‚
- en: Expand `model_spline` to a distributional model. Use another spline to model
    the *Î±* parameter of the NegativeBinomial family.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°† `model_spline` æ‰©å±•ä¸ºä¸€ä¸ªåˆ†å¸ƒæ¨¡å‹ã€‚ä½¿ç”¨å¦ä¸€ä¸ªæ ·æ¡æ¥å»ºæ¨¡ NegativeBinomial å®¶æ—çš„ *Î±* å‚æ•°ã€‚
- en: Create a model named `model_p2` for the `body_mass` with the predictors `bill_length`,
    `bill_depth`, `flipper_length`, and `species`.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªåä¸º `model_p2` çš„æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹ `body_mass`ï¼Œå…¶é¢„æµ‹å˜é‡ä¸º `bill_length`ã€`bill_depth`ã€`flipper_length`
    å’Œ `species`ã€‚
- en: Use LOO to compare the model in the previous point and `model_p.`
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ LOO æ–¹æ³•æ¯”è¾ƒå‰ä¸€ç‚¹ä¸­çš„æ¨¡å‹å’Œ `model_p`ã€‚
- en: Use the functions in the `interpret` module to interpret `model_p2`. Use both
    plots and tables.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `interpret` æ¨¡å—ä¸­çš„å‡½æ•°æ¥è§£é‡Š `model_p2`ï¼Œå¹¶åŒæ—¶ä½¿ç”¨å›¾è¡¨å’Œè¡¨æ ¼ã€‚
- en: Join our community Discord space
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ å…¥æˆ‘ä»¬çš„ç¤¾åŒº Discord ç©ºé—´
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at: [https://packt.link/bayesian](https://packt.link/bayesian)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ å…¥æˆ‘ä»¬çš„ Discord ç¤¾åŒºï¼Œä¸å¿—åŒé“åˆçš„äººä¸€èµ·å­¦ä¹ ï¼Œå¹¶ä¸è¶…è¿‡5000åæˆå‘˜å…±åŒæˆé•¿ï¼Œè®¿é—®é“¾æ¥ï¼š[https://packt.link/bayesian](https://packt.link/bayesian)
- en: '![PIC](img/file1.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1.png)'
