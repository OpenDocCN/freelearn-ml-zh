- en: Section 3 – Modeling Continuous Targets with Supervised Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3节 - 使用监督学习建模连续目标
- en: The final ten chapters of this book introduce a wide range of machine learning
    algorithms, for predicting both continuous or categorical targets, or when there
    is no target. We explore models for continuous targets in this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书最后十章介绍了广泛的各种机器学习算法，用于预测连续或分类目标，或者在没有目标的情况下。我们在本章探索连续目标的模型。
- en: A persistent theme in these chapters is that finding the best possible model
    is partly about balancing variance and bias. When our models fit the training
    data too well, they may not be as generalizable as we need them to be. In cases
    like that, they may have low bias but high variance. For each algorithm we examine
    in these chapters, we discuss strategies for achieving this balance. These strategies
    range from regularization for linear regression and support vector regression
    models, to the value of k for k-nearest neighbors, to the maximum depth of decision
    trees.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这些章节的一个持续主题是，找到最佳模型部分是关于平衡方差和偏差。当我们的模型对训练数据拟合得太好时，它们可能没有我们需要的那么具有可推广性。在这种情况下，它们可能具有低偏差但高方差。在这些章节中，我们检查的每个算法，我们都讨论了实现这种平衡的策略。这些策略从线性回归和支持向量回归模型的正则化，到k近邻中的k值，再到决策树的最大深度。
- en: We also get a chance to practice the preprocessing, feature selection, and model
    evaluation strategies we worked with in [*Chapter 6*](B17978_06_ePub.xhtml#_idTextAnchor078)*,
    Preparing for Model Evaluation*. Each of the algorithms we discuss in this section
    requires different preprocessing for optimal results. For example, feature scaling
    is important for support vector regression, but not usually for a decision tree
    regression. We might use a polynomial transformation with a linear regression
    model, but that would also be unnecessary with a decision tree. We consider those
    choices in each chapter of this part.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也有机会练习在[*第6章*](B17978_06_ePub.xhtml#_idTextAnchor078)*，准备模型评估*中使用的预处理、特征选择和模型评估策略。本节中我们讨论的每个算法都需要不同的预处理以获得最佳结果。例如，特征缩放对于支持向量回归很重要，但对于决策树回归通常不是。我们可能会使用多项式变换与线性回归模型，但在决策树中这也会是不必要的。我们在这部分的每一章中考虑这些选择。
- en: 'This section comprises the following chapters:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包括以下章节：
- en: '[*Chapter 7*](B17978_07_ePub.xhtml#_idTextAnchor091), *Linear Regression Models*'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B17978_07_ePub.xhtml#_idTextAnchor091), *线性回归模型*'
- en: '[*Chapter 8*](B17978_08_ePub.xhtml#_idTextAnchor106), *Support Vector Regression*'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B17978_08_ePub.xhtml#_idTextAnchor106), *支持向量回归*'
- en: '[*Chapter 9*](B17978_09_ePub.xhtml#_idTextAnchor113), *K-Nearest Neighbor,
    Decision Tree, Random Forest, and Gradient Boosted Regression*'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B17978_09_ePub.xhtml#_idTextAnchor113), *K近邻、决策树、随机森林和梯度提升回归*'
