- en: Chapter 7. Model Evaluation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章 模型评估
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Estimating model performance with k-fold cross-validation
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用k折交叉验证估计模型性能
- en: Performing cross-validation with the e1071 package
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用e1071包进行交叉验证
- en: Performing cross-validation with the caret package
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`caret`包进行交叉验证
- en: Ranking the variable importance with the caret package
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`caret`包对变量重要性进行排名
- en: Ranking the variable importance with the rminer package
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`rminer`包对变量重要性进行排名
- en: Finding highly correlated features with the caret package
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`caret`包寻找高度相关的特征
- en: Selecting features using the caret package
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`caret`包选择特征
- en: Measuring the performance of a regression model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量回归模型的性能
- en: Measuring the prediction performance with the confusion matrix
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用混淆矩阵测量预测性能
- en: Measuring the prediction performance using ROCR
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ROCR测量预测性能
- en: Comparing an ROC curve using the caret package
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`caret`包比较ROC曲线
- en: Measuring performance differences between models with the caret package
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`caret`包测量模型之间的性能差异
- en: Introduction
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Model evaluation is performed to ensure that a fitted model can accurately predict
    responses for future or unknown subjects. Without model evaluation, we might train
    models that over-fit in the training data. To prevent overfitting, we can employ
    packages, such as `caret`, `rminer`, and `rocr` to evaluate the performance of
    the fitted model. Furthermore, model evaluation can help select the optimum model,
    which is more robust and can accurately predict responses for future subjects.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 模型评估是为了确保拟合的模型能够准确预测未来或未知主体的响应。如果没有模型评估，我们可能会训练出在训练数据上过度拟合的模型。为了防止过度拟合，我们可以使用如`caret`、`rminer`和`rocr`等包来评估拟合模型的性能。此外，模型评估有助于选择最佳模型，该模型更稳健，并能准确预测未来主体的响应。
- en: In the following chapter, we will discuss how one can implement a simple R script
    or use one of the packages (for example, `caret` or `rminer`) to evaluate the
    performance of a fitted model.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何实现一个简单的R脚本或使用一个包（例如`caret`或`rminer`）来评估拟合模型的性能。
- en: Estimating model performance with k-fold cross-validation
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用k折交叉验证估计模型性能
- en: The k-fold cross-validation technique is a common technique used to estimate
    the performance of a classifier as it overcomes the problem of over-fitting. For
    k-fold cross-validation, the method does not use the entire dataset to build the
    model, instead it splits the data into a training dataset and a testing dataset.
    Therefore, the model built with a training dataset can then be used to assess
    the performance of the model on the testing dataset. By performing n repeats of
    the k-fold validation, we can then use the average of *n* accuracies to truly
    assess the performance of the built model. In this recipe, we will illustrate
    how to perform a k-fold cross-validation.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: k折交叉验证技术是一种常用的技术，用于估计分类器的性能，因为它克服了过度拟合的问题。对于k折交叉验证，该方法不使用整个数据集来构建模型，而是将数据分割成训练数据集和测试数据集。因此，使用训练数据集构建的模型可以用来评估模型在测试数据集上的性能。通过执行n次k折验证，我们可以使用n个准确率的平均值来真正评估构建的模型性能。在本菜谱中，我们将说明如何执行k折交叉验证。
- en: Getting ready
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will continue to use the telecom `churn` dataset as the input
    data source to train the support vector machine. For those who have not prepared
    the dataset, please refer to [Chapter 5](part0060_split_000.html#page "Chapter 5. Classification
    (I) – Tree, Lazy, and Probabilistic"), *Classification (I) – Tree, Lazy, and Probabilistic*,
    for detailed information.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将继续使用telecom `churn`数据集作为输入数据源来训练支持向量机。对于那些尚未准备数据集的人，请参阅[第5章](part0060_split_000.html#page
    "第5章. 分类（I）-树、懒惰和概率性")，*分类（I）-树、懒惰和概率性*，以获取详细信息。
- en: How to do it...
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following steps to cross-validate the telecom `churn` dataset:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以交叉验证telecom `churn`数据集：
- en: 'Split the index into `10` fold using the cut function:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cut`函数将索引分割成10折：
- en: '[PRE0]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, use `for` loop to perform a 10 fold cross-validation, repeated `10` times:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用`for`循环执行10折交叉验证，重复10次：
- en: '[PRE1]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can then print the accuracies:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以打印出准确率：
- en: '[PRE2]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Lastly, you can generate average accuracies with the `mean` function:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，你可以使用`mean`函数生成平均准确率：
- en: '[PRE3]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How it works...
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we implement a simple script performing 10-fold cross-validations.
    We first generate an index with 10 fold with the `cut` function. Then, we implement
    a `for` loop to perform a 10-fold cross-validation 10 times. Within the loop,
    we first apply `svm` on `9` folds of data as the training set. We then use the
    fitted model to predict the label of the rest of the data (the testing dataset).
    Next, we use the sum of the correctly predicted labels to generate the accuracy.
    As a result of this, the loop stores 10 generated accuracies. Finally, we use
    the `mean` function to retrieve the average of the accuracies.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们实现了一个简单的脚本，执行10折交叉验证。我们首先使用`cut`函数生成10个折的索引。然后，我们实现一个`for`循环，执行10次10折交叉验证。在循环中，我们首先将`svm`应用于`9`个数据折作为训练集。然后，我们使用拟合的模型预测剩余数据（测试数据集）的标签。接下来，我们使用正确预测的标签总和来生成准确率。因此，循环存储了10个生成的准确率。最后，我们使用`mean`函数检索准确率的平均值。
- en: There's more...
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'If you wish to perform the k-fold validation with the use of other models,
    simply replace the line to generate the variable fit to whatever classifier you
    prefer. For example, if you would like to assess the Naïve Bayes model with a
    10-fold cross-validation, you just need to replace the calling function from `svm`
    to `naiveBayes`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望使用其他模型执行k折交叉验证，只需替换生成变量fit的行，以您偏好的分类器为准。例如，如果您想使用10折交叉验证来评估朴素贝叶斯模型，只需将调用函数从`svm`替换为`naiveBayes`：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Performing cross-validation with the e1071 package
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用e1071包进行交叉验证
- en: Besides implementing a `loop` function to perform the k-fold cross-validation,
    you can use the `tuning` function (for example, `tune.nnet`, `tune.randomForest`,
    `tune.rpart`, `tune.svm`, and `tune.knn`.) within the `e1071` package to obtain
    the minimum error value. In this recipe, we will illustrate how to use `tune.svm`
    to perform the 10-fold cross-validation and obtain the optimum classification
    model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 除了实现一个`loop`函数来执行k折交叉验证外，您还可以在`e1071`包中使用`tuning`函数（例如，`tune.nnet`、`tune.randomForest`、`tune.rpart`、`tune.svm`和`tune.knn`）来获取最小误差值。在本例中，我们将说明如何使用`tune.svm`执行10折交叉验证并获得最佳分类模型。
- en: Getting ready
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we continue to use the telecom `churn` dataset as the input
    data source to perform 10-fold cross-validation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们继续使用电信`churn`数据集作为输入数据源执行10折交叉验证。
- en: How to do it...
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following steps to retrieve the minimum estimation error using
    cross-validation:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以使用交叉验证检索最小估计误差：
- en: 'Apply `tune.svm` on the training dataset, `trainset`, with the 10-fold cross-validation
    as the tuning control. (If you find an error message, such as `could not find
    function predict.func`, please clear the workspace, restart the R session and
    reload the `e1071` library again):'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据集`trainset`上应用`tune.svm`，使用10折交叉验证作为调整控制。（如果您发现错误消息，例如`could not find function
    predict.func`，请清除工作区，重新启动R会话并重新加载`e1071`库）：
- en: '[PRE5]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, you can obtain the summary information of the model, tuned:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，您可以获取模型的摘要信息，调整：
- en: '[PRE6]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, you can access the performance details of the tuned model:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您可以访问调整后模型的性能细节：
- en: '[PRE7]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Lastly, you can use the optimum model to generate a classification table:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，您可以使用最佳模型生成分类表：
- en: '[PRE8]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: How it works...
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The `e1071` package provides miscellaneous functions to build and assess models,
    therefore, you do not need to reinvent the wheel to evaluate a fitted model. In
    this recipe, we use the `tune.svm` function to tune the svm model with the given
    formula, dataset, gamma, cost, and control functions. Within the `tune.control`
    options, we configure the option as `cross=10`, which performs a 10-fold cross
    validation during the tuning process. The tuning process will eventually return
    the minimum estimation error, performance detail, and the best model during the
    tuning process. Therefore, we can obtain the performance measures of the tuning
    and further use the optimum model to generate a classification table.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`e1071`包提供了构建和评估模型的各种函数，因此，您无需重新发明轮子来评估拟合模型。在本例中，我们使用`tune.svm`函数使用给定的公式、数据集、gamma、成本和控制函数调整svm模型。在`tune.control`选项中，我们将选项配置为`cross=10`，在调整过程中执行10折交叉验证。调整过程最终将返回最小估计误差、性能细节以及调整过程中的最佳模型。因此，我们可以获得调整的性能指标，并进一步使用最佳模型生成分类表。'
- en: See also
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考信息
- en: 'In the `e1071` package, the `tune` function uses a grid search to tune parameters.
    For those interested in other tuning functions, use the help function to view
    the `tune` document:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`e1071`包中，`tune`函数使用网格搜索来调整参数。对于那些对其他调整函数感兴趣的人，请使用帮助函数查看`tune`文档：
- en: '[PRE9]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Performing cross-validation with the caret package
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用caret包进行交叉验证
- en: The `Caret` (classification and regression training) package contains many functions
    in regard to the training process for regression and classification problems.
    Similar to the `e1071` package, it also contains a function to perform the k-fold
    cross validation. In this recipe, we will demonstrate how to the perform k-fold
    cross validation using the `caret` package.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`Caret`（分类和回归训练）包包含许多关于回归和分类问题训练过程的函数。类似于`e1071`包，它也包含一个执行k折交叉验证的函数。在本菜谱中，我们将演示如何使用`caret`包执行k折交叉验证。'
- en: Getting ready
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will continue to use the telecom `churn` dataset as the input
    data source to perform the k-fold cross validation.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在本菜谱中，我们将继续使用电信`churn`数据集作为输入数据源来执行k折交叉验证。
- en: How to do it...
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following steps to perform the k-fold cross-validation with the
    `caret` package:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以使用`caret`包执行k折交叉验证：
- en: 'First, set up the control parameter to train with the 10-fold cross validation
    in `3` repetitions:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，设置控制参数以进行10折交叉验证，重复3次：
- en: '[PRE10]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, you can train the classification model on telecom churn data with `rpart`:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你可以使用`rpart`在电信客户流失数据上训练分类模型：
- en: '[PRE11]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, you can examine the output of the generated model:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，你可以检查生成的模型的输出：
- en: '[PRE12]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: How it works...
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, we demonstrate how convenient it is to conduct the k-fold cross-validation
    using the `caret` package. In the first step, we set up the training control and
    select the option to perform the 10-fold cross-validation in three repetitions.
    The process of repeating the k-fold validation is called repeated k-fold validation,
    which is used to test the stability of the model. If the model is stable, one
    should get a similar test result. Then, we apply `rpart` on the training dataset
    with the option to scale the data and to train the model with the options configured
    in the previous step.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本菜谱中，我们展示了使用`caret`包进行k折交叉验证是多么方便。在第一步中，我们设置了训练控制并选择了在三次重复中执行10折交叉验证的选项。重复k折验证的过程称为重复k折验证，用于测试模型的稳定性。如果模型稳定，应该得到相似的训练结果。然后，我们使用`rpart`在训练数据集上应用，并选择缩放数据以及使用之前步骤中配置的选项来训练模型。
- en: After the training process is complete, the model outputs three resampling results.
    Of these results, the model with `cp=0.05555556` has the largest accuracy value
    (`0.904`), and is therefore selected as the optimal model for classification.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程完成后，模型输出三个重采样结果。在这些结果中，`cp=0.05555556`的模型具有最大的准确值（`0.904`），因此被选为分类的最佳模型。
- en: See also
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: 'You can configure the `resampling` function in `trainControl`, in which you
    can specify `boot`, `boot632`, `cv`, `repeatedcv`, `LOOCV`, `LGOCV`, `none`, `oob`,
    `adaptive`_`cv`, `adaptive_boot`, or `adaptive_LGOCV`. To view more detailed information
    of how to choose the resampling method, view the `trainControl` document:'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在`trainControl`中配置`resampling`函数，其中你可以指定`boot`、`boot632`、`cv`、`repeatedcv`、`LOOCV`、`LGOCV`、`none`、`oob`、`adaptive_cv`、`adaptive_boot`或`adaptive_LGOCV`。要查看如何选择重采样方法的更详细信息，请查看`trainControl`文档：
- en: '[PRE13]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Ranking the variable importance with the caret package
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用caret包对变量重要性进行排名
- en: After building a supervised learning model, we can estimate the importance of
    features. This estimation employs a sensitivity analysis to measure the effect
    on the output of a given model when the inputs are varied. In this recipe, we
    will show you how to rank the variable importance with the `caret` package.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建监督学习模型后，我们可以估计特征的重要性。这种估计采用敏感性分析来衡量当输入变化时对给定模型输出的影响。在本菜谱中，我们将向您展示如何使用`caret`包对变量重要性进行排名。
- en: Getting ready
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You need to have completed the previous recipe by storing the fitted `rpart`
    object in the `model` variable.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要完成之前的菜谱，并将拟合的`rpart`对象存储在`model`变量中。
- en: How to do it...
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following steps to rank the variable importance with the `caret`
    package:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以使用`caret`包对变量重要性进行排名：
- en: 'First, you can estimate the variable importance with the `varImp` function:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，你可以使用`varImp`函数估计变量重要性：
- en: '[PRE14]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, you can generate the variable importance plot with the `plot` function:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您可以使用`plot`函数生成可变重要性图：
- en: '[PRE15]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![How to do it...](img/00123.jpeg)'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/00123.jpeg)'
- en: 'Figure 1: The visualization of variable importance using the caret package'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1：使用caret包的可变重要性可视化
- en: How it works...
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, we first use the `varImp` function to retrieve the variable
    importance and obtain the summary. The overall results show the sensitivity measure
    of each attribute. Next, we plot the variable importance in terms of rank, which
    shows that the `number_customer_service_calls` attribute is the most important
    variable in the sensitivity measure.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们首先使用`varImp`函数检索可变重要性并获取摘要。整体结果显示了每个属性的敏感性度量。接下来，我们按排名绘制可变重要性，这表明`number_customer_service_calls`属性在敏感性度量中是最重要的变量。
- en: There's more...
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多内容...
- en: 'In some classification packages, such as `rpart`, the object generated from
    the training model contains the variable importance. We can examine the variable
    importance by accessing the output object:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些分类包中，例如`rpart`，从训练模型生成的对象包含变量重要性。我们可以通过访问输出对象来检查变量重要性：
- en: '[PRE16]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Ranking the variable importance with the rminer package
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用rminer包对可变重要性进行排名
- en: Besides using the `caret` package to generate variable importance, you can use
    the `rminer` package to generate the variable importance of a classification model.
    In the following recipe, we will illustrate how to use `rminer` to obtain the
    variable importance of a fitted model.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用`caret`包生成可变重要性外，您还可以使用`rminer`包生成分类模型的可变重要性。在下面的食谱中，我们将说明如何使用`rminer`获取拟合模型的可变重要性。
- en: Getting ready
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will continue to use the telecom `churn` dataset as the input
    data source to rank the variable importance.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将继续使用电信`churn`数据集作为输入数据源来对可变重要性进行排序。
- en: How to do it...
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following steps to rank the variable importance with `rminer`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以使用`rminer`对可变重要性进行排名：
- en: 'Install and load the package, `rminer`:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装并加载包，`rminer`：
- en: '[PRE17]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Fit the svm model with the training set:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练集拟合svm模型：
- en: '[PRE18]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Use the `Importance` function to obtain the variable importance:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Importance`函数获取可变重要性：
- en: '[PRE19]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Plot the variable importance ranked by the variance:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按方差绘制可变重要性图
- en: '[PRE20]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![How to do it...](img/00124.jpeg)'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/00124.jpeg)'
- en: 'Figure 2: The visualization of variable importance using the `rminer` package'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2：使用`rminer`包的可变重要性可视化
- en: How it works...
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Similar to the `caret` package, the `rminer` package can also generate the variable
    importance of a classification model. In this recipe, we first train the svm model
    on the training dataset, `trainset`, with the `fit` function. Then, we use the
    `Importance` function to rank the variable importance with a sensitivity measure.
    Finally, we use `mgraph` to plot the rank of the variable importance. Similar
    to the result obtained from using the `caret` package, `number_customer_service_calls`
    is the most important variable in the measure of sensitivity.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 与`caret`包类似，`rminer`包也可以生成分类模型的可变重要性。在本食谱中，我们首先使用`fit`函数在训练数据集`trainset`上训练svm模型。然后，我们使用`Importance`函数使用敏感性度量对可变重要性进行排名。最后，我们使用`mgraph`绘制可变重要性的排名。与使用`caret`包获得的结果相似，`number_customer_service_calls`是在敏感性度量中最重要的变量。
- en: See also
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'The `rminer` package provides many classification models for one to choose
    from. If you are interested in using models other than svm, you can view these
    options with the following command:'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rminer`包提供许多分类模型供用户选择。如果您对使用svm以外的模型感兴趣，可以使用以下命令查看这些选项：'
- en: '[PRE21]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Finding highly correlated features with the caret package
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用caret包寻找高度相关的特征
- en: When performing regression or classification, some models perform better if
    highly correlated attributes are removed. The `caret` package provides the `findCorrelation`
    function, which can be used to find attributes that are highly correlated to each
    other. In this recipe, we will demonstrate how to find highly correlated features
    using the `caret` package.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行回归或分类时，如果移除高度相关的属性，某些模型的表现会更好。`caret`包提供了`findCorrelation`函数，可以用来查找彼此高度相关的属性。在本食谱中，我们将演示如何使用`caret`包查找高度相关的特征。
- en: Getting ready
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will continue to use the telecom `churn` dataset as the input
    data source to find highly correlated features.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将继续使用电信`churn`数据集作为输入数据源来寻找高度相关的特征。
- en: How to do it...
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following steps to find highly correlated attributes:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以找到高度相关的属性：
- en: 'Remove the features that are not coded in numeric characters:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除未用数值字符编码的特征：
- en: '[PRE22]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then, you can obtain the correlation of each attribute:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你可以获得每个属性的关联性：
- en: '[PRE23]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, we use `findCorrelation` to search for highly correlated attributes with
    a cut off equal to 0.75:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用`findCorrelation`搜索截止值为0.75的高度相关属性：
- en: '[PRE24]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We then obtain the name of highly correlated attributes:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们获得高度相关属性的名称：
- en: '[PRE25]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: How it works...
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we search for highly correlated attributes using the `caret`
    package. In order to retrieve the correlation of each attribute, one should first
    remove nonnumeric attributes. Then, we perform correlation to obtain a correlation
    matrix. Next, we use `findCorrelation` to find highly correlated attributes with
    the cut off set to 0.75\. We finally obtain the names of highly correlated (with
    a correlation coefficient over 0.75) attributes, which are `total_intl_minutes`,
    `total_day_charge`, `total_eve_minutes`, and `total_night_minutes`. You can consider
    removing some highly correlated attributes and keep one or two attributes for
    better accuracy.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在本菜谱中，我们使用`caret`包搜索高度相关的属性。为了检索每个属性的关联性，首先应移除非数值属性。然后，我们执行关联性分析以获得关联矩阵。接下来，我们使用`findCorrelation`找到高度相关的属性，截止值为0.75。我们最终获得高度相关（相关系数超过0.75）的属性名称，分别是`total_intl_minutes`、`total_day_charge`、`total_eve_minutes`和`total_night_minutes`。你可以考虑移除一些高度相关的属性，保留一个或两个属性以获得更好的准确性。
- en: See also
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关内容
- en: In addition to the `caret` package, you can use the `leaps`, `genetic`, and
    `anneal` functions in the `subselect` package to achieve the same goal
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了`caret`包外，你还可以使用`subselect`包中的`leaps`、`genetic`和`anneal`函数达到相同的目的
- en: Selecting features using the caret package
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用caret包进行特征选择
- en: The feature selection method searches the subset of features with minimized
    predictive errors. We can apply feature selection to identify which attributes
    are required to build an accurate model. The `caret` package provides a recursive
    feature elimination function, `rfe`, which can help automatically select the required
    features. In the following recipe, we will demonstrate how to use the `caret`
    package to perform feature selection.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择方法搜索具有最小预测误差的特征子集。我们可以应用特征选择来识别构建准确模型所需的属性。`caret`包提供了一个递归特征消除函数`rfe`，可以帮助自动选择所需的特征。在下面的菜谱中，我们将演示如何使用`caret`包进行特征选择。
- en: Getting ready
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will continue to use the telecom `churn` dataset as the input
    data source for feature selection.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本菜谱中，我们将继续使用电信`churn`数据集作为特征选择的输入数据源。
- en: How to do it...
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following steps to select features:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以选择特征：
- en: 'Transform the feature named as `international_plan` of the training dataset,
    `trainset`, to `intl_yes` and `intl_no`:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练数据集`trainset`中名为`international_plan`的特征转换为`intl_yes`和`intl_no`：
- en: '[PRE26]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Transform the feature named as `voice_mail_plan` of the training dataset, `trainset`,
    to `voice_yes` and `voice_no`:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练数据集`trainset`中名为`voice_mail_plan`的特征转换为`voice_yes`和`voice_no`：
- en: '[PRE27]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Remove the `international_plan` and `voice_mail_plan` attributes and combine
    the training dataset, `trainset` with the data frames, `intl_plan` and `voice_plan`:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除`international_plan`和`voice_mail_plan`属性，并将训练数据集`trainset`与数据框`intl_plan`和`voice_plan`合并：
- en: '[PRE28]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Transform the feature named as `international_plan` of the testing dataset,
    `testset`, to `intl_yes` and `intl_no`:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将测试数据集`testset`中名为`international_plan`的特征转换为`intl_yes`和`intl_no`：
- en: '[PRE29]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Transform the feature named as `voice_mail_plan` of the training dataset, `trainset`,
    to `voice_yes` and `voice_no`:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练数据集`trainset`中名为`voice_mail_plan`的特征转换为`voice_yes`和`voice_no`：
- en: '[PRE30]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Remove the `international_plan` and `voice_mail_plan` attributes and combine
    the testing dataset, `testset` with the data frames, `intl_plan` and `voice_plan`:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除`international_plan`和`voice_mail_plan`属性，并将测试数据集`testset`与数据框`intl_plan`和`voice_plan`合并：
- en: '[PRE31]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We then create a feature selection algorithm using linear discriminant analysis:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用线性判别分析创建一个特征选择算法：
- en: '[PRE32]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, we perform a backward feature selection on the training dataset, `trainset`
    using subsets from 1 to 18:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们在训练数据集`trainset`上使用从1到18的子集进行向后特征选择：
- en: '[PRE33]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Next, we can plot the selection result:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们可以绘制选择结果：
- en: '[PRE34]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![How to do it...](img/00125.jpeg)'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/00125.jpeg)'
- en: 'Figure 3: The feature selection result'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3：特征选择结果
- en: 'We can then examine the best subset of the variables:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以检查变量的最佳子集：
- en: '[PRE35]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, we can examine the fitted model:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以检查拟合的模型：
- en: '[PRE36]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Finally, we can calculate the performance across resamples:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以计算跨样本的性能：
- en: '[PRE37]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: How it works...
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, we perform feature selection using the `caret` package. As there
    are factor-coded attributes within the dataset, we first use a function called
    `model.matrix` to transform the factor-coded attributes into multiple binary attributes.
    Therefore, we transform the `international_plan` attribute to `intl_yes` and `intl_no`.
    Additionally, we transform the `voice_mail_plan` attribute to `voice_yes` and
    `voice_no`.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用`caret`包进行特征选择。由于数据集中存在因子编码的属性，我们首先使用一个名为`model.matrix`的函数将因子编码的属性转换为多个二元属性。因此，我们将`international_plan`属性转换为`intl_yes`和`intl_no`。此外，我们将`voice_mail_plan`属性转换为`voice_yes`和`voice_no`。
- en: Next, we set up control parameters for training using the cross-validation method,
    `cv`, with the linear discriminant function, `ldaFuncs`. Then, we use the recursive
    feature elimination, `rfe`, to perform feature selection with the use of the `control`
    function, `ldaFuncs`. The `rfe` function generates the summary of feature selection,
    which contains resampling a performance over the subset size and top variables.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用交叉验证方法`cv`和线性判别函数`ldaFuncs`设置训练的控制参数。然后，我们使用`control`函数`ldaFuncs`进行特征选择，使用递归特征消除`rfe`。`rfe`函数生成特征选择摘要，其中包含对子集大小和顶级变量的重采样性能。
- en: We can then use the obtained model information to plot the number of variables
    against accuracy. From Figure 3, it is obvious that using 12 features can obtain
    the best accuracy. In addition to this, we can retrieve the best subset of the
    variables in (12 variables in total) the fitted model. Lastly, we can calculate
    the performance across resamples, which yields an accuracy of 0.86 and a kappa
    of 0.27.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用获得模型信息来绘制变量数量与准确率的关系图。从图3中可以看出，使用12个特征可以获得最佳准确率。除此之外，我们还可以检索出拟合模型中最佳变量子集（总共有12个变量）。最后，我们可以计算跨样本的性能，得到准确率为0.86和kappa值为0.27。
- en: See also
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'In order to specify the algorithm used to control feature selection, one can
    change the control function specified in `rfeControl`. Here are some of the options
    you can use:'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了指定用于控制特征选择的算法，可以在`rfeControl`中更改指定的控制函数。以下是一些你可以使用的选项：
- en: '[PRE38]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Measuring the performance of the regression model
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 衡量回归模型的表现
- en: To measure the performance of a regression model, we can calculate the distance
    from predicted output and the actual output as a quantifier of the performance
    of the model. Here, we often use the **root mean square error** (**RMSE**), **relative
    square error** (**RSE**) and R-Square as common measurements. In the following
    recipe, we will illustrate how to compute these measurements from a built regression
    model.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为了衡量回归模型的表现，我们可以计算预测输出与实际输出之间的距离，作为模型性能的量化指标。在这里，我们通常使用**均方根误差**（**RMSE**）、**相对平方误差**（**RSE**）和R-Square作为常见的测量指标。在下面的菜谱中，我们将展示如何从一个构建的回归模型中计算这些测量值。
- en: Getting ready
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will use the `Quartet` dataset, which contains four regression
    datasets, as our input data source.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用包含四个回归数据集的`Quartet`数据集作为我们的输入数据源。
- en: How to do it...
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Perform the following steps to measure the performance of the regression model:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来衡量回归模型的表现：
- en: 'Load the `Quartet` dataset from the `car` package:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`car`包中加载`Quartet`数据集：
- en: '[PRE39]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Plot the attribute, `y3`, against x using the `lm` function:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`lm`函数将属性`y3`与x绘制出来：
- en: '[PRE40]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![How to do it...](img/00126.jpeg)'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何做...](img/00126.jpeg)'
- en: 'Figure 4: The linear regression plot'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4：线性回归图
- en: 'You can retrieve predicted values by using the `predict` function:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用`predict`函数检索预测值：
- en: '[PRE41]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, you can calculate the root mean square error:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你可以计算均方根误差：
- en: '[PRE42]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'You can calculate the relative square error:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以计算相对平方误差：
- en: '[PRE43]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Also, you can use R-Square as a measurement:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，你还可以使用R-Square作为测量指标：
- en: '[PRE44]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Then, you can plot attribute, y3, against x using the `rlm` function from the
    MASS package:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你可以使用MASS包中的`rlm`函数将属性y3与x绘制出来：
- en: '[PRE45]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '![How to do it...](img/00127.jpeg)'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何做...](img/00127.jpeg)'
- en: 'Figure 5: The robust linear regression plot on the Quartet dataset'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5：Quartet数据集上的稳健线性回归图
- en: 'You can then retrieve the predicted value using the `predict` function:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你可以使用`predict`函数检索预测值：
- en: '[PRE46]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Next, you can calculate the root mean square error using the distance of the
    predicted and actual value:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你可以使用预测值和实际值之间的距离来计算根均方误差：
- en: '[PRE47]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Calculate the relative square error between the predicted and actual labels:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算预测标签和实际标签之间的相对平方误差：
- en: '[PRE48]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now, you can calculate the R-Square value:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你可以计算 R-Square 值：
- en: '[PRE49]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: How it works...
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The measurement of the performance of the regression model employs the distance
    between the predicted value and the actual value. We often use these three measurements,
    root mean square error, relative square error, and R-Square, as the quantifier
    of the performance of regression models. In this recipe, we first load the `Quartet`
    data from the `car` package. We then use the `lm` function to fit the linear model,
    and add the regression line on a scatter plot of the x variable against the `y3`
    variable. Next, we compute the predicted value using the predict function, and
    begin to compute the **root mean square error** (**RMSE**), **relative square
    error** (**RSE**), and R-Square for the built model.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型性能的测量使用预测值和实际值之间的距离。我们通常使用这三个度量，即均方根误差、相对平方误差和 R-Square，作为回归模型性能的量化指标。在这个菜谱中，我们首先从
    `car` 包中加载 `Quartet` 数据。然后，我们使用 `lm` 函数拟合线性模型，并在 x 变量对 `y3` 变量的散点图上添加回归线。接下来，我们使用预测函数计算预测值，并开始计算构建模型的
    **均方根误差**（**RMSE**）、**相对平方误差**（**RSE**）和 R-Square。
- en: As this dataset has an outlier at `x=13`, we would like to quantify how the
    outlier affects the performance measurement. To achieve this, we first train a
    regression model using the `rlm` function from the `MASS` package. Similar to
    the previous step, we then generate a performance measurement of the root square
    mean error, relative error and R-Square. From the output measurement, it is obvious
    that the mean square error and the relative square errors of the `lm` model are
    smaller than the model built by `rlm`, and the score of R-Square shows that the
    model built with `lm` has a greater prediction power. However, for the actual
    scenario, we should remove the outlier at `x=13`. This comparison shows that the
    outlier may be biased toward the performance measure and may lead us to choose
    the wrong model.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个数据集在 `x=13` 处有一个异常值，我们希望量化异常值对性能测量的影响。为了实现这一点，我们首先使用 `MASS` 包中的 `rlm` 函数训练一个回归模型。类似于前面的步骤，然后我们生成根平方均方误差、相对误差和
    R-Square 的性能测量。从输出测量来看，显然 `lm` 模型的均方误差和相对平方误差小于由 `rlm` 构建的模型，R-Square 的得分显示使用
    `lm` 构建的模型具有更大的预测能力。然而，对于实际场景，我们应该移除 `x=13` 处的异常值。这个比较表明异常值可能偏向于性能测量，并可能导致我们选择错误的模型。
- en: There's more…
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多内容...
- en: 'If you would like to perform cross-validation on a linear regression model,
    you can use the `tune` function within the `e1071` package:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要对一个线性回归模型进行交叉验证，你可以在 `e1071` 包中使用 `tune` 函数：
- en: '[PRE50]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Other than the `e1071` package, you can use the `train` function from the `caret`
    package to perform cross-validation. In addition to this, you can also use `cv.lm`
    from the `DAAG` package to achieve the same goal.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 `e1071` 包之外，你还可以使用 `caret` 包中的 `train` 函数来进行交叉验证。此外，你还可以使用 `DAAG` 包中的 `cv.lm`
    来达到相同的目的。
- en: Measuring prediction performance with a confusion matrix
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用混淆矩阵衡量预测性能
- en: To measure the performance of a classification model, we can first generate
    a classification table based on our predicted label and actual label. Then, we
    can use a confusion matrix to obtain performance measures such as precision, recall,
    specificity, and accuracy. In this recipe, we will demonstrate how to retrieve
    a confusion matrix using the `caret` package.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 为了衡量分类模型的性能，我们首先可以根据我们的预测标签和实际标签生成一个分类表。然后，我们可以使用混淆矩阵来获得性能度量，如精确度、召回率、特异性和准确率。在这个菜谱中，我们将演示如何使用
    `caret` 包检索混淆矩阵。
- en: Getting ready
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will continue to use the telecom `churn` dataset as our example
    dataset.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将继续使用电信 `churn` 数据集作为我们的示例数据集。
- en: How to do it...
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Perform the following steps to generate a classification measurement:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以生成分类测量：
- en: 'Train an svm model using the training dataset:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练数据集训练 svm 模型：
- en: '[PRE51]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'You can then predict labels using the fitted model, `svm.model`:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你可以使用拟合的模型 `svm.model` 来预测标签：
- en: '[PRE52]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Next, you can generate a classification table:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你可以生成一个分类表：
- en: '[PRE53]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Lastly, you can generate a confusion matrix using the prediction results and
    the actual labels from the testing dataset:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，你可以使用预测结果和测试数据集中的实际标签生成一个混淆矩阵：
- en: '[PRE54]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: How it works...
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, we demonstrate how to obtain a confusion matrix to measure the
    performance of a classification model. First, we use the `train` function from
    the `caret` package to train an svm model. Next, we use the `predict` function
    to extract the predicted labels of the svm model using the testing dataset. Then,
    we perform the `table` function to obtain the classification table based on the
    predicted and actual labels. Finally, we use the `confusionMatrix` function from
    the `caret` package to a generate a confusion matrix to measure the performance
    of the classification model.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们展示了如何获取混淆矩阵来衡量分类模型的性能。首先，我们使用`caret`包中的`train`函数来训练svm模型。接下来，我们使用`predict`函数使用测试数据集提取svm模型的预测标签。然后，我们执行`table`函数以根据预测和实际标签获取分类表。最后，我们使用`caret`包中的`confusionMatrix`函数生成一个混淆矩阵来衡量分类模型的性能。
- en: See also
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关内容
- en: 'If you are interested in the available methods that can be used in the `train`
    function, you can refer to this website: [http://topepo.github.io/caret/modelList.html](http://topepo.github.io/caret/modelList.html)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你感兴趣，可以在`train`函数中使用的方法，可以参考这个网站：[http://topepo.github.io/caret/modelList.html](http://topepo.github.io/caret/modelList.html)
- en: Measuring prediction performance using ROCR
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ROCR测量预测性能
- en: A **receiver operating characteristic** (**ROC**) curve is a plot that illustrates
    the performance of a binary classifier system, and plots the true positive rate
    against the false positive rate for different cut points. We most commonly use
    this plot to calculate the **area under curve** (**AUC**) to measure the performance
    of a classification model. In this recipe, we will demonstrate how to illustrate
    an ROC curve and calculate the AUC to measure the performance of a classification
    model.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**接收者操作特征**（ROC）曲线是说明二元分类器系统性能的图表，它将不同截断点的真正例率和假正例率进行绘图。我们最常用这个图表来计算**曲线下面积**（AUC），以衡量分类模型的性能。在这个菜谱中，我们将展示如何绘制ROC曲线并计算AUC来衡量分类模型的性能。'
- en: Getting ready
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we will continue using the telecom `churn` dataset as our example
    dataset.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将继续使用电信`churn`数据集作为我们的示例数据集。
- en: How to do it...
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following steps to generate two different classification examples
    with different costs:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以生成具有不同成本的两种不同的分类示例：
- en: 'First, you should install and load the `ROCR` package:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，你应该安装并加载`ROCR`包：
- en: '[PRE55]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Train the svm model using the training dataset with a probability equal to
    `TRUE`:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练数据集并设置概率等于`TRUE`来训练svm模型：
- en: '[PRE56]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Make predictions based on the trained model on the testing dataset with the
    probability set as `TRUE`:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试数据集上基于训练模型进行预测，并将概率设置为`TRUE`：
- en: '[PRE57]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Obtain the probability of labels with `yes`:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`yes`标签获取概率：
- en: '[PRE58]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Use the `prediction` function to generate a prediction result:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`prediction`函数生成预测结果：
- en: '[PRE59]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Use the `performance` function to obtain the performance measurement:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`performance`函数获取性能度量：
- en: '[PRE60]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Visualize the ROC curve using the `plot` function:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`plot`函数可视化ROC曲线：
- en: '[PRE61]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '![How to do it...](img/00128.jpeg)'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/00128.jpeg)'
- en: 'Figure 6: The ROC curve for the svm classifier performance'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6：svm分类器性能的ROC曲线
- en: How it works...
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, we demonstrated how to generate an ROC curve to illustrate the
    performance of a binary classifier. First, we should install and load the library,
    `ROCR`. Then, we use svm, from the `e1071` package, to train a classification
    model, and then use the model to predict labels for the testing dataset. Next,
    we use the prediction function (from the package, `ROCR`) to generate prediction
    results. We then adapt the performance function to obtain the performance measurement
    of the true positive rate against the false positive rate. Finally, we use the
    `plot` function to visualize the ROC plot, and add the value of AUC on the title.
    In this example, the AUC value is 0.92, which indicates that the svm classifier
    performs well in classifying telecom user churn datasets.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们展示了如何生成ROC曲线来展示二元分类器的性能。首先，我们应该安装并加载库，`ROCR`。然后，我们使用来自`e1071`包的svm来训练一个分类模型，并使用该模型对测试数据集进行预测。接下来，我们使用预测函数（来自`ROCR`包）生成预测结果。然后，我们将性能函数调整为获得真正例率对假正例率的性能测量。最后，我们使用`plot`函数可视化ROC图，并在标题上添加AUC值。在这个例子中，AUC值是0.92，这表明svm分类器在电信用户流失数据集的分类中表现良好。
- en: See also
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考内容
- en: For those interested in the concept and terminology of ROC, you can refer to
    [http://en.wikipedia.org/wiki/Receiver_operating_characteristic](http://en.wikipedia.org/wiki/Receiver_operating_characteristic)
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于对ROC的概念和术语感兴趣的人，您可以参考[http://en.wikipedia.org/wiki/Receiver_operating_characteristic](http://en.wikipedia.org/wiki/Receiver_operating_characteristic)
- en: Comparing an ROC curve using the caret package
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用caret包比较ROC曲线
- en: In previous chapters, we introduced many classification methods; each method
    has its own advantages and disadvantages. However, when it comes to the problem
    of how to choose the best fitted model, you need to compare all the performance
    measures generated from different prediction models. To make the comparison easy,
    the caret package allows us to generate and compare the performance of models.
    In this recipe, we will use the function provided by the `caret` package to compare
    different algorithm trained models on the same dataset.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们介绍了许多分类方法；每种方法都有其自身的优缺点。然而，当涉及到如何选择最佳拟合模型的问题时，您需要比较来自不同预测模型生成的所有性能指标。为了使比较变得容易，`caret`包允许我们生成并比较模型的性能。在本例中，我们将使用`caret`包提供的函数来比较在同一数据集上训练的不同算法模型。
- en: Getting ready
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Here, we will continue to use telecom dataset as our input data source.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将继续使用telecom数据集作为我们的输入数据源。
- en: How to do it...
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Perform the following steps to generate an ROC curve of each fitted model:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以生成每个拟合模型的ROC曲线：
- en: 'Install and load the library, `pROC`:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装并加载库，`pROC`：
- en: '[PRE62]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Set up the training control with a 10-fold cross-validation in 3 repetitions:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置训练控制，使用3次重复的10折交叉验证：
- en: '[PRE63]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Then, you can train a classifier on the training dataset using `glm`:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您可以使用`glm`在训练数据集上训练一个分类器：
- en: '[PRE64]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Also, you can train a classifier on the training dataset using `svm`:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，您还可以使用`svm`在训练数据集上训练一个分类器：
- en: '[PRE65]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'To see how `rpart` performs on the training data, we use the `rpart` function:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了查看`rpart`在训练数据上的表现，我们使用`rpart`函数：
- en: '[PRE66]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'You can make predictions separately based on different trained models:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以根据不同的训练模型分别进行预测：
- en: '[PRE67]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'You can generate the ROC curve of each model, and plot the curve on the same
    figure:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以为每个模型生成ROC曲线，并在同一图上绘制曲线：
- en: '[PRE68]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '![How to do it...](img/00129.jpeg)'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何做...](img/00129.jpeg)'
- en: 'Figure 7: The ROC curve for the performance of three classifiers'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7：三个分类器性能的ROC曲线
- en: How it works...
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Here, we demonstrate how we can compare fitted models by illustrating their
    ROC curve in one figure. First, we set up the control of the training process
    with a 10-fold cross validation in 3 repetitions with the performance evaluation
    in `twoClassSummary`. After setting up control of the training process, we then
    apply `glm`, `svm`, and `rpart` algorithms on the training dataset to fit the
    classification models. Next, we can make a prediction based on each generated
    model and plot the ROC curve, respectively. Within the generated figure, we find
    that the model trained by svm has the largest area under curve, which is 0.9233
    (plotted in green), the AUC of the `glm` model (red) is 0.82, and the AUC of the
    `rpart` model (blue) is 0.7581\. From *Figure 7*, it is obvious that `svm` performs
    the best among all the fitted models on this training dataset (without requiring
    tuning).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们通过展示如何在一张图上绘制它们的ROC曲线来说明我们如何比较拟合模型。首先，我们通过在`twoClassSummary`中进行性能评估，使用10折交叉验证和3次重复来设置训练过程的控制。在设置好训练过程的控制后，我们接着在训练数据集上应用`glm`、`svm`和`rpart`算法来拟合分类模型。接下来，我们可以基于每个生成的模型进行预测并分别绘制ROC曲线。在生成的图中，我们发现由svm训练的模型具有最大的曲线下面积，为0.9233（用绿色绘制），`glm`模型的AUC为0.82，`rpart`模型的AUC为0.7581。从*图7*中可以看出，`svm`在此训练数据集上（无需调整）的所有拟合模型中表现最佳。
- en: See also
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'We use another ROC visualization package, `pROC`, which can be employed to
    display and analyze ROC curves. If you would like to know more about the package,
    please use the `help` function:'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用另一个ROC可视化包`pROC`，它可以用来显示和分析ROC曲线。如果您想了解更多关于这个包的信息，请使用`help`函数：
- en: '[PRE69]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Measuring performance differences between models with the caret package
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用caret包测量模型之间的性能差异
- en: In the previous recipe, we introduced how to generate ROC curves for each generated
    model, and have the curve plotted on the same figure. Apart from using an ROC
    curve, one can use the resampling method to generate statistics of each fitted
    model in ROC, sensitivity and specificity metrics. Therefore, we can use these
    statistics to compare the performance differences between each model. In the following
    recipe, we will introduce how to measure performance differences between fitted
    models with the `caret` package.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的步骤中，我们介绍了如何为每个生成的模型生成ROC曲线，并将曲线绘制在同一张图上。除了使用ROC曲线外，还可以使用重采样方法来生成每个拟合模型在ROC、敏感性和特异性指标中的统计数据。因此，我们可以使用这些统计数据来比较每个模型之间的性能差异。在接下来的步骤中，我们将介绍如何使用`caret`包来测量拟合模型之间的性能差异。
- en: Getting ready
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: One needs to have completed the previous recipe by storing the `glm` fitted
    model, `svm` fitted model, and the `rpart` fitted model into `glm.model`, `svm.model`,
    and `rpart.model`, respectively.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 需要完成之前的步骤，将`glm`拟合模型、`svm`拟合模型和`rpart`拟合模型分别存储到`glm.model`、`svm.model`和`rpart.model`中。
- en: How to do it...
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Perform the following steps to measure performance differences between each
    fitted model:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来测量每个拟合模型之间的性能差异：
- en: 'Resample the three generated models:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重采样三个生成的模型：
- en: '[PRE70]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Then, you can obtain a summary of the resampling result:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您可以获得重采样结果的摘要：
- en: '[PRE71]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Use `dotplot` to plot the resampling result in the ROC metric:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`dotplot`在ROC指标中绘制重采样结果：
- en: '[PRE72]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '![How to do it...](img/00130.jpeg)'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何做...](img/00130.jpeg)'
- en: 'Figure 8: The dotplot of resampling result in ROC metric'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图8：ROC指标中重采样结果的点图
- en: 'Also, you can use a box-whisker plot to plot the resampling result:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，您还可以使用箱线图来绘制重采样结果：
- en: '[PRE73]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '![How to do it...](img/00131.jpeg)'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何做...](img/00131.jpeg)'
- en: 'Figure 9: The box-whisker plot of resampling result'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9：重采样结果的箱线图
- en: How it works...
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we demonstrate how to measure the performance differences among
    three fitted models using the resampling method. First, we use the `resample`
    function to generate the statistics of each fitted model (`svm.model`, `glm.model`,
    and `rpart.model`). Then, we can use the `summary` function to obtain the statistics
    of these three models in the ROC, sensitivity and specificity metrics. Next, we
    can apply a `dotplot` on the resampling result to see how ROC varied between each
    model. Last, we use a box-whisker plot on the resampling results to show the box-whisker
    plot of different models in the ROC, sensitivity and specificity metrics on a
    single plot.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们展示了如何使用重采样方法来衡量三个拟合模型之间的性能差异。首先，我们使用 `resample` 函数生成每个拟合模型（`svm.model`、`glm.model`
    和 `rpart.model`）的统计数据。然后，我们可以使用 `summary` 函数获取这三个模型在ROC、敏感性和特异性指标中的统计数据。接下来，我们可以在重采样结果上应用
    `dotplot` 来查看ROC在不同模型之间的变化情况。最后，我们使用箱线图在重采样结果上展示不同模型在ROC、敏感性和特异性指标上的箱线图。
- en: See also
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: Besides using `dotplot` and `bwplot` to measure performance differences, one
    can use `densityplot`, `splom`, and `xyplot` to visualize the performance differences
    of each fitted model in the ROC, sensitivity, and specificity metrics.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了使用 `dotplot` 和 `bwplot` 来衡量性能差异外，还可以使用 `densityplot`、`splom` 和 `xyplot` 来可视化每个拟合模型在ROC、敏感性和特异性指标中的性能差异。
