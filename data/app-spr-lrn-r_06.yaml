- en: '*Chapter 6:*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第6章：*'
- en: Feature Selection and Dimensionality Reduction
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征选择和降维
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Implement feature engineering techniques such as discretization, one-hot encoding,
    and transformation
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施特征工程技术，如离散化、独热编码和转换
- en: Execute feature selection methods on a real-world dataset using univariate feature
    selection, correlation matrix, and model-based feature importance ranking
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用单变量特征选择、相关矩阵和基于模型的特征重要性排序在真实世界数据集上执行特征选择方法
- en: Apply feature reduction using principal component analysis (PCA) for dimensionality
    reduction, variable reduction with clustering, and linear discriminant analysis
    (LDA)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用主成分分析（PCA）进行降维，使用聚类进行变量减少，以及线性判别分析（LDA）
- en: Implement PCA and LDA and observe the differences between them
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现PCA和LDA，并观察它们之间的差异
- en: In this chapter, we will explore the feature selection and dimensionality reduction
    methods to build an effective feature set and hence improve the model performance.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨特征选择和降维方法，以构建有效的特征集，从而提高模型性能。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简介
- en: In the last two chapters (on regression and classification), we focused on understanding
    and implementing the various machine learning algorithms in the supervised learning
    category on a given dataset pertaining to a problem.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后两章（关于回归和分类）中，我们专注于理解和实现监督学习类别中给定数据集的相关各种机器学习算法。
- en: In this chapter, we will focus more on effectively using the features of the
    dataset to build the best performing model. Often in many datasets, the feature
    space is quite large (with many features). The model performance takes a hit as
    the patterns are hard to find and often much noise is present in the data. Feature
    selections are specific methods that are used to identify the importance of each
    feature and assign a score to each. We can then select the top 10 or 15 features
    (or even more) based on the score for building our model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将更多地关注有效地使用数据集的特征来构建性能最佳的模型。在许多数据集中，特征空间相当大（具有许多特征）。由于模式难以发现，数据中通常存在很多噪声，模型性能受到影响。特征选择是用于识别每个特征的重要性并为每个特征分配分数的特定方法。然后，我们可以根据分数选择前10个或15个特征（甚至更多）来构建我们的模型。
- en: 'Another possibility is to create new variables using a linear combination of
    all the input variables. This helps in keeping the representation of all variables
    and reducing the dimensionality of feature space. However, such a reduction often
    reduces the explainable variance. In this chapter, we will focus on the three
    major actions we perform on the dataset for improving model performance:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可能性是使用所有输入变量的线性组合创建新的变量。这有助于保持所有变量的表示并降低特征空间的维度。然而，这种降低通常会导致可解释方差减少。在本章中，我们将重点关注我们执行的三项主要操作，以改进模型性能：
- en: '**Feature engineering:** Essentially transforms the features so the machine
    learning algorithms will work'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程：**本质上是将特征进行转换，以便机器学习算法能够工作'
- en: '**Selection:** Selects the features with high importance to bring out the best
    performance of the model'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择：**选择具有高重要性的特征以发挥模型的最佳性能'
- en: '**Reduction:** Reduces the feature dimensionality by representing a higher
    order dataset into a lower dimension'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少：**通过将高阶数据集表示为低维数据来降低特征维度'
- en: All three are closely related yet different in how they function.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个都是紧密相关但又各自不同的功能。
- en: In this chapter, in addition to the Beijing PM2.5 dataset, we will use the Los
    Angeles ozone pollution data, 1976, provided in the `mlbench` library of R. It
    is a data frame with 366 observations on 13 variables, where each observation
    is of one day.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，除了北京PM2.5数据集外，我们还将使用R的`mlbench`库中提供的1976年洛杉矶臭氧污染数据。这是一个包含366个观测值和13个变量的数据框，其中每个观测值代表一天。
- en: '![Figure 6.1: List of variables in Los Angeles ozone pollution data, 1976'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.1：洛杉矶臭氧污染数据中的变量列表，1976年'
- en: '](img/C12624_06_01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![图C12624_06_01.jpg]'
- en: 'Figure 6.1: List of variables in Los Angeles ozone pollution data, 1976'
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.1：洛杉矶臭氧污染数据中的变量列表，1976年
- en: Originally, the dataset was provided for the problem of predicting the daily
    maximum one-hour-average ozone readings (the fourth variable in the table). Both
    Beijing PM2.5 and Los Angeles ozone datasets resonate with the effects of pollutants
    on our environment.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集是为预测每日最大一小时平均臭氧读数（表中的第四个变量）的问题提供的。北京 PM2.5 和洛杉矶臭氧数据集都与污染物对我们环境的影响产生共鸣。
- en: Feature Engineering
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程
- en: The algorithms we use in machine learning will perform based on the quality
    and goodness of the data; they do not have any intelligence of their own. The
    better and innovative you become in designing features, the better the model performance.
    **Feature engineering** in many ways helps in bringing the best out of data. The
    term feature engineering essentially refers to the process of the **derivation**
    and **transformation** of given features, thus better characterizing the meaning
    of the features and representing the underlying problem of the predictive model.
    By this process, we anticipate the improvement in the model's **predictability
    power** and **accuracy**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在机器学习中使用的算法将根据数据的质量和良好性执行；它们本身没有任何智能。你在设计特征方面的越好和创新，模型的性能就越好。**特征工程**在许多方面有助于发挥数据的最优效果。特征工程这个术语本质上是指给定特征的**推导**和**转换**过程，从而更好地表征特征的意义和表示预测模型的潜在问题。通过这个过程，我们预计模型的**可预测性**和**准确性**将得到提高。
- en: Discretization
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 离散化
- en: In *Chapter 3*, *Introduction to Supervised Learning*, we converted the numeric
    values of a 3-hour rolling average of PM2.5 in the Beijing dataset to the binary
    values 1 and 0 for logistic regression, based on the threshold of 35, where 1
    means **normal** and 0 means **above normal**. The process is called **discretization**,
    also commonly referred to as **binning, or** in our case, **binary discretization**.
    More broadly, in applied mathematics, discretization is the process of transferring
    continuous functions, models, variables, and equations into discrete counterparts.
    Now, let's perform the process on a variable.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第 3 章*，*监督学习简介* 中，我们将北京数据集中 3 小时滚动平均 PM2.5 的数值转换为逻辑回归的二元值 1 和 0，基于 35 的阈值，其中
    1 表示**正常**，0 表示**高于正常**。这个过程称为**离散化**，也常被称为**分箱**，在我们的情况下，**二值离散化**。更广泛地说，在应用数学中，离散化是将连续函数、模型、变量和方程转换为离散对应物的过程。现在，让我们对一个变量执行这个过程。
- en: 'Exercise 77: Performing Binary Discretization'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 77：执行二值离散化
- en: In this exercise, we will create a binary variable using the `pm2.5` variable
    of the Beijing PM2.5 dataset. Binary discretization of the `pm2.5` variable will
    create a column that will be 1 if the PM2.5 level is greater than 35, else it
    will be 0\. This process will help us create a discrete categorical variable (to
    be called `pollution_level`) from a continuous numeric variable.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用北京 PM2.5 数据集的 `pm2.5` 变量创建一个二元变量。`pm2.5` 变量的二值离散化将创建一个列，如果 PM2.5
    水平大于 35，则该列将为 1，否则为 0。这个过程将帮助我们从一个连续的数值变量创建一个离散的分类变量（称为 `pollution_level`）。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: 'Start with reading the Beijing PM2.5 dataset using the following command:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下命令开始读取北京 PM2.5 数据集：
- en: '[PRE0]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Load the following libraries:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载以下库：
- en: '[PRE1]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Combine year, month, day, and hour into a `datetime` variable using the with
    function from the lubridate package:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 lubridate 包中的 with 函数将年、月、日和小时合并为一个 `datetime` 变量：
- en: '[PRE2]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, remove any row with an NA in the column:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，删除任何在列中包含 NA 的行：
- en: '[PRE3]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Using the zoo structure, compute the moving average every `3` hours:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 zoo 结构，每 `3` 小时计算一次移动平均：
- en: '[PRE4]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, convert the output of the moving average into a DataFrame:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将移动平均的输出转换为 DataFrame：
- en: '[PRE5]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, put the timestamp in the row names into the main columns:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，将行名中的时间戳放入主列中：
- en: '[PRE6]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Get rid of the row names (optional):'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除行名（可选）：
- en: '[PRE7]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Rename the columns:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重命名列：
- en: '[PRE8]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Create two levels based on the PM2.5 average. `0` implies `1` implies **above
    the normal**:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据 PM2.5 平均值创建两个级别。`0` 表示**正常**，`1` 表示**高于正常**：
- en: '[PRE9]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Randomly select 10 rows using the following command:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令随机选择 10 行：
- en: '[PRE10]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Print the output using the following command:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令打印输出：
- en: '[PRE11]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Observe that the variable `pollution_level` is now a binary categorical variable,
    which we created in Step 11\. The dataset with `pollution_level` as an output
    variable could be used with any classification algorithm.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，变量 `pollution_level` 现在是一个二进制分类变量，我们在第 11 步中创建了它。以 `pollution_level` 作为输出变量的数据集可以与任何分类算法一起使用。
- en: Multi-Category Discretization
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多类别离散化
- en: A more general form of discretization is to divide the range of values of a
    continuous variable into many smaller ranges of values using appropriate cut-points.
    One way of identifying the appropriate cut-point is to analyze the distribution
    of the variable.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 离散化的更一般形式是将连续变量的值范围划分为许多更小的值范围，使用适当的切点。确定适当切点的一种方法是对变量的分布进行分析。
- en: 'Using the following code, plot a histogram of `avg_pm25` with `binwidth` of
    `30 (`meaning the range of values will be divided into ranges of size `30)`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码，以 `binwidth` 为 `30`（意味着值范围将被划分为大小为 `30` 的范围）绘制 `avg_pm25` 的直方图：
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Figure 6.2: Histogram of 3-hour rolling average of PM2.5 values from Beijing
    dataset'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.2：北京数据集中 3 小时滚动平均 PM2.5 值的直方图](img/Figure_6.2_Histogram_of_3-hour_rolling_average_of_PM2.5_values_from_Beijing_dataset)'
- en: '](img/C12624_06_02.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/C12624_06_02.jpg)'
- en: 'Figure 6.2: Histogram of 3-hour rolling average of PM2.5 values from Beijing
    dataset'
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.2：北京数据集中 3 小时滚动平均 PM2.5 值的直方图
- en: The plot in *Figure 6.2* shows the right skewness in the variable, which means
    the majority of values are on the left of the range of values, mostly concentrated
    between 0 and 250\. Such skewness inhibits the model from generalizing, hence
    it has a lower predictive power. Now, let's explore how we can utilize multi-category
    discretization to improve this scenario.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6.2* 中的图显示了变量的右偏态，这意味着大多数值位于值范围的左侧，主要集中在 0 到 250 之间。这种偏态阻碍了模型的泛化，因此其预测能力较低。现在，让我们探讨如何利用多类别离散化来改善这种情况。'
- en: 'Exercise 78: Demonstrating the Use of Quantile Function'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 78：展示分位数函数的使用
- en: In this exercise, we will demonstrate the use of the `avg_pm25`.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将展示 `avg_pm25` 的使用。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: Import the required libraries and packages.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库和包。
- en: 'Find the quantiles on `avg_pm25`:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `avg_pm25` 上找到分位数：
- en: '[PRE13]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, calculate the vertical lines on the quantile points:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，计算分位数点的垂直线：
- en: '[PRE14]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The plot is as follows:'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图如下：
- en: '![](img/C12624_06_03.jpg)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](img/C12624_06_03.jpg)'
- en: Figure 6.3 Histogram of 3-hour rolling average of PM2.5 values from Beijing
    dataset with cut-lines corresponding to 0th, 25th, 50th, 75th, and 100th percentile
    points
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.3：北京数据集中 3 小时滚动平均 PM2.5 值的直方图，对应于 0%、25%、50%、75% 和 100% 分位数点
- en: The following code snippet creates the variable `avg_pm25_quartiles` in the
    dataset, which represents the five percentile points on the values of `avg_pm25`.
    This new variable could be used in modeling after **one-hot encoding,** which
    we will discuss in the next section.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段在数据集中创建了一个名为 `avg_pm25_quartiles` 的变量，它代表了 `avg_pm25` 值的五个百分位数点。这个新变量在
    **one-hot 编码** 后可用于建模，我们将在下一节讨论。
- en: 'Let''s use the following code to add a new variable `avg_pm25_quartiles` in
    the dataset:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用以下代码在数据集中添加一个新变量 `avg_pm25_quartiles`：
- en: '[PRE15]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We have just seen how discretization helps to remove any data skewness before
    modelling.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚看到离散化如何帮助在建模之前消除任何数据偏态。
- en: One-Hot Encoding
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: One-Hot 编码
- en: One-hot encoding is a process of binarizing the categorical variable. This is
    done by transforming a categorical variable with *n* unique values into *n* unique
    columns in the datasets while keeping the number of rows the same. The following
    table shows how the wind direction column is transformed into five binary columns.
    For example, the row number **1** has the value **North**, so we get a **1** in
    the corresponding column named **Direction_N** and **0** in the remaining columns.
    So on for the other rows. Note that out of these sample five rows of data, the
    direction **West** is not present. However, the larger dataset would have got
    the value for us to have the column **Direction_W**.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: One-Hot 编码是一个将分类变量二进制化的过程。这是通过将具有 *n* 个唯一值的分类变量转换成数据集中的 *n* 个唯一列，同时保持行数不变来完成的。以下表格显示了风向列如何转换成五个二进制列。例如，行号
    **1** 的值为 **北风**，因此我们在名为 **Direction_N** 的对应列中得到 **1**，而在其他列中得到 **0**。其他行也是如此。注意，在这五个样本数据行中，方向
    **西风** 不存在。然而，更大的数据集会为我们提供 **Direction_W** 列的值。
- en: '![Figure 6.4 Transforming a categorical variable into Binary 1s and 0s using
    one-hot encoding'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.4 使用独热编码将分类变量转换为二进制 1 和 0]'
- en: '](img/C12624_06_04.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12624_06_04.jpg)'
- en: Figure 6.4 Transforming a categorical variable into Binary 1s and 0s using one-hot
    encoding
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.4 使用独热编码将分类变量转换为二进制 1 和 0
- en: One primary reason for converting categorical variables (such as the one shown
    in the previous table) to binary columns is related to the limitation of many
    machine learning algorithms, which can only deal with numerical values. However,
    in order to convert the categorical variables into a numerical variable, we have
    to represent it with some mapping value, such as `North = 1`, `South = 2`, `West
    = 3`, and so on. The problem with such encoding is that the values `1`, `2`, and
    `3` are integers, where `3>2>1`; however, this is not the case with wind direction.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 将分类变量（如前表中所示）转换为二进制列的一个主要原因是与许多机器学习算法的限制有关，这些算法只能处理数值。然而，为了将分类变量转换为数值变量，我们必须用一些映射值来表示它，例如
    `北 = 1`，`南 = 2`，`西 = 3` 等。这种编码的问题在于值 `1`，`2` 和 `3` 是整数，其中 `3>2>1`；然而，风向的情况并非如此。
- en: The interpretation is entirely wrong. Binary one-hot encoding overcomes this
    challenge by creating one column for each value in the categorical variable, thus
    giving us a more elegant representation. We can now use any algorithm from machine
    learning on such data as long as it satisfies the type of problem.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 解释完全错误。二进制独热编码通过为分类变量中的每个值创建一列来克服这一挑战，从而提供了更优雅的表示。现在，只要满足问题类型，我们可以使用任何机器学习算法来处理此类数据。
- en: 'Exercise 79: Using One-Hot Encoding'
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 79：使用独热编码
- en: In this exercise, we will use the one-hot encoding for creating one column for
    each value in the categorical variable.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用独热编码为分类变量中的每个值创建一列。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: Import the required libraries and packages.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库和包。
- en: 'Create the `OzoneData` variable and store the value of `ozone1.csv` using the
    `read.csv` function:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `read.csv` 函数创建 `OzoneData` 变量并存储 `ozone1.csv` 的值：
- en: '[PRE16]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Import the required `caret` packages into the system:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所需的 `caret` 包导入系统：
- en: '[PRE17]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Create input datasets:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建输入数据集：
- en: '[PRE18]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Create the response DataFrame:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建响应 DataFrame：
- en: '[PRE19]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Plot the data using the `head()` function:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `head()` 函数绘制数据：
- en: '[PRE20]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output is as follows:'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE21]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Observe the `OneHot` variable we have created in the `OzoneData` DataFrame.
    After one-hot encoding, each value (1 to 7) in `Day_of_week` is represented as
    a separate column.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 观察我们在 `OzoneData` DataFrame 中创建的 `OneHot` 变量。经过独热编码后，`Day_of_week` 中的每个值（1 到
    7）都表示为单独的列。
- en: 'Activity 11: Converting the CBWD Feature of the Beijing PM2.5 Dataset into
    One-Hot Encoded Columns'
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 11：将北京 PM2.5 数据集的 CBWD 特征转换为独热编码列
- en: In this activity, we will learn how to convert any categorical variable into
    a one-hot encoded vector. Particularly, we will convert the CBWD feature of the
    Beijing PM2.5 dataset into one-hot encoded columns. Many machine learning algorithms
    work only on numerical features; in such cases, it becomes imperative to use one-hot
    encoding.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将学习如何将任何分类变量转换为独热编码向量。特别是，我们将把北京 PM2.5 数据集的 CBWD 特征转换为独热编码列。许多机器学习算法只处理数值特征；在这种情况下，使用独热编码变得至关重要。
- en: 'Perform the following steps to complete the activity:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成活动：
- en: Read the Beijing PM2.5 dataset.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取北京 PM2.5 数据集。
- en: Create a variable `cbwd_one_hot` for storing the result of the `dummyVars` function
    with `~ cbwd` as its first argument.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量 `cbwd_one_hot` 用于存储 `dummyVars` 函数的结果，其第一个参数为 `~ cbwd`。
- en: Use the output of the `predict()` function on `cbwd_one_hot`.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `predict()` 函数在 `cbwd_one_hot` 上的输出。
- en: Remove the original `cbwd` variable from the `PM25` DataFrame.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `PM25` DataFrame 中移除原始的 `cbwd` 变量。
- en: Using the `cbind()` function, add `cbwd_one_hot` to the `PM25` DataFrame.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cbind()` 函数，将 `cbwd_one_hot` 添加到 `PM25` DataFrame 中。
- en: Print the top six rows of `PM25`.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印 `PM25` 的前六行。
- en: 'The output is as follows:'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE22]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Note
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 459.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以在第 459 页找到。
- en: Log Transformation
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对数转换
- en: 'The most common technique to correct for skewed distribution is to find an
    appropriate mathematical function that has an inverse. One such function is a
    log, represented as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 修正偏斜分布最常见的技术是找到一个合适的具有逆函数的数学函数。其中一个这样的函数是对数，表示如下：
- en: '![](img/C12624_06_15.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12624_06_15.jpg)'
- en: 'In other words, ![](img/C12624_06_16.png) is the ![](img/C12624_06_17.png)
    of ![](img/C12624_06_18.png) to the base ![](img/C12624_06_19.png). The inverse,
    to find the ![](img/C12624_06_19a.png), can be computed as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，![](img/C12624_06_16.png) 是 ![](img/C12624_06_17.png) 对 ![](img/C12624_06_18.png)
    的对数，以 ![](img/C12624_06_19.png) 为底。其逆运算，即找到 ![](img/C12624_06_19a.png)，可以按以下方式计算：
- en: '![](img/C12624_06_20.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12624_06_20.jpg)'
- en: This transformation gives the ability to handle the skewness in the data; at
    the same time, the original value can be easily computed once the model is built.
    The most popular log transformation is the natural ![](img/C12624_06_21.png),
    where ![](img/C12624_06_22.png) is the mathematical constant ![](img/C12624_06_23.png),
    which equals roughly `2.71828`.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转换赋予了处理数据偏斜的能力；同时，一旦建立模型，原始值可以轻松计算。最流行的对数转换是自然对数 ![](img/C12624_06_21.png)，其中
    ![](img/C12624_06_22.png) 是数学常数 ![](img/C12624_06_23.png)，其值大约为 `2.71828`。
- en: One useful property of the log function is that it handles the data skewness
    elegantly. For example, the following code demonstrates the difference between
    `log(10000)` and `log(1000000)` as just `4.60517`. The number ![](img/C12624_06_24.png)
    is 100 times bigger than ![](img/C12624_06_25.png). This reduces the skewness
    that we otherwise let the model handle, which it might not do sufficiently.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 对数函数的一个有用特性是它优雅地处理数据偏斜。例如，以下代码演示了 `log(10000)` 和 `log(1000000)` 的差异仅为 `4.60517`。数字
    ![](img/C12624_06_24.png) 是 ![](img/C12624_06_25.png) 的 100 倍。这减少了我们通常让模型处理的偏斜，而模型可能不足以处理。
- en: '[PRE23]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Let's see the result of applying the natural log on the 3-hour rolling average
    of the PM2.5 values.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看对 PM2.5 值的 3 小时滚动平均应用自然对数的结果。
- en: 'Exercise 80: Performing Log Transformation'
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 80：执行对数转换
- en: In this exercise, we will draw a histogram of the `avg_pm25` variable with log
    transformation and compare it with the skewed distribution of the original values.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将绘制经过对数转换的 `avg_pm25` 变量的直方图，并将其与原始值的偏斜分布进行比较。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: Import the required libraries and packages.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库和包。
- en: 'Create a histogram of `avg_pm25`:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 `avg_pm25` 的直方图：
- en: '[PRE24]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is as follows:'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 6.5 Histogram of the 3-hour rolling average of PM2.5 values from the
    Beijing dataset'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.5 来自北京数据集的 PM2.5 值 3 小时滚动平均的直方图'
- en: '](img/C12624_06_05.jpg)'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C12624_06_05.jpg)'
- en: Figure 6.5 Histogram of the 3-hour rolling average of PM2.5 values from the
    Beijing dataset
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.5 来自北京数据集的 PM2.5 值 3 小时滚动平均的直方图
- en: 'Create a histogram of `log_avg_pm25`:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 `log_avg_pm25` 的直方图：
- en: '[PRE25]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output is as follows:'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 6.6 Histogram of the natural log of the 3-hour rolling average of
    PM2.5 values from the Beijing dataset'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.6 来自北京数据集的 PM2.5 值 3 小时滚动平均的自然对数直方图'
- en: '](img/C12624_06_06.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12624_06_06.jpg)'
- en: Figure 6.6 Histogram of the natural log of the 3-hour rolling average of PM2.5
    values from the Beijing dataset
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.6 来自北京数据集的 PM2.5 值 3 小时滚动平均的自然对数直方图
- en: In this exercise, we drew a plot to show the 3-hour rolling average of the PM2.5
    values from the Beijing dataset and contrasted it with the histogram of the natural
    log of the 3-hour rolling average of the PM2.5 values from the Beijing dataset.
    Taking the log made the histogram look more symmetrical around the mean and the
    skewness.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们绘制了一个图表来展示北京数据集中 PM2.5 值的 3 小时滚动平均值，并将其与北京数据集中 PM2.5 值 3 小时滚动平均的自然对数直方图进行了对比。取对数使得直方图在平均值周围看起来更加对称，并减少了偏斜。
- en: Feature Selection
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征选择
- en: While **feature engineering** ensures that the quality and data issues are rectified,
    **feature selection** helps with determining the right set of features for improving
    the performance of the model. Feature selection techniques identify the features
    that contribute the most in the prediction ability of the model. Features with
    less importance inhibit the model's ability to learn from the independent variable.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当**特征工程**确保质量和数据问题得到纠正时，**特征选择**有助于确定用于提高模型性能的正确特征集。特征选择技术识别对模型预测能力贡献最大的特征。重要性较低的特征会抑制模型从独立变量中学习的能力。
- en: 'Feature selection offers benefits such as:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择提供了以下好处：
- en: Reducing overfitting
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少过拟合
- en: Improving accuracy
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高准确性
- en: Reducing the time to train the model
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少训练模型的时间
- en: Univariate Feature Selection
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单变量特征选择
- en: A statistical test such as the **chi-squared** ![](img/C12624_06_26.png) test
    is a popular method to select features with a strong relationship to the dependent
    or target variable. It mainly works on categorical features in a classification
    problem. So, for this to work on a numerical variable, one needs to make the feature
    into categorical using discretization.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 像卡方检验（**chi-squared**）这样的统计检验是选择与因变量或目标变量有强关系的特征的一种流行方法。它主要在分类问题中的分类特征上工作。因此，为了在数值变量上使用它，需要将特征转换为分类，使用离散化。
- en: 'In the most general form, chi-squared statistics could be computed as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在最一般的形式中，卡方统计量可以计算如下：
- en: '![](img/C12624_06_27.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/C12624_06_26.png)'
- en: 'This tests whether or not there is a significant difference between observed
    frequency and expected frequency. A higher chi-squared value establishes a stronger
    dependence of the target variable and the particular feature. More formally:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这测试了观察频率与预期频率之间是否存在显著差异。较大的卡方值表明目标变量与特定特征的依赖性更强。更正式地说：
- en: '![](img/C12624_06_28.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/C12624_06_28.jpg)'
- en: 'Where:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '![](img/C12624_06_29_33.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/C12624_06_29_33.jpg)'
- en: 'Exercise 81: Exploring Chi-Squared'
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习81：探索卡方检验
- en: In this exercise, we will compute the chi-squared statistic for all the variables
    in the `Ozone` dataset. The top five variables with the highest chi-squared value
    will be our best feature for modelling.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将计算`Ozone`数据集中所有变量的卡方统计量。具有最高卡方值的五个变量将是我们建模的最佳特征。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 完成以下步骤以完成练习：
- en: Import the required libraries and packages.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库和包。
- en: 'Create a variable named `OzoneData` and assign the value from the `read.csv`
    function:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`OzoneData`的变量，并将`read.csv`函数的值分配给它：
- en: '[PRE26]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, set the `path` as illustrated here:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，设置`path`如上图所示：
- en: '[PRE27]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Next, use the Sys.getenv function to obtain the values of the environment variables:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用Sys.getenv函数获取环境变量的值：
- en: '[PRE28]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Install the required packages using the following command:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令安装所需的包：
- en: '[PRE29]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Import the `rJava` package:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`rJava`包：
- en: '[PRE30]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Calculate the chi-squared statistics:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算卡方统计量：
- en: '[PRE31]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Print the results:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印结果：
- en: '[PRE32]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The output is as follows:'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE33]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Select the top five variables:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择前五个变量：
- en: '[PRE34]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Print the final formula that can be used for classification:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印可用于分类的最终公式：
- en: '[PRE35]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The output is as follows:'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE36]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We used the chi.squared() function to compute the chi-squared values for each
    feature in our Ozone dataset. The function outputs the attribute importance based
    on the chi-squared value. The formula in Step 10 that uses the top five features
    from the chi-squared statistic could be used for building a supervised learning
    model.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用chi.squared()函数计算了Ozone数据集中每个特征的卡方值。该函数根据卡方值输出属性的重要性。步骤10中使用的卡方统计量前五个特征可以用于构建监督学习模型。
- en: Highly Correlated Variables
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高度相关的变量
- en: Generally, two highly correlated variables likely contribute to the prediction
    ability of the model, which makes one redundant. For example, if we have a dataset
    with `age`, `height`, and `BMI` as variables, we know that `BMI` is a function
    of `age` and `height` and it will always be highly correlated with the other two.
    If it's not, then something is wrong with the BMI calculation. In such cases,
    one might decide to remove the other two. However, it is always not this straight.
    In certain cases, a pair of variables might be highly correlated, but it is not
    easy to interpret why that is the case. In such cases, one can randomly drop one
    of the two.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，两个高度相关的变量可能对模型的预测能力做出贡献，这使得其中一个变得冗余。例如，如果我们有一个包含`age`（年龄）、`height`（身高）和`BMI`（体质指数）作为变量的数据集，我们知道`BMI`是`age`和`height`的函数，并且它总是与这两个变量高度相关。如果不是这样，那么BMI的计算可能有问题。在这种情况下，可能会决定删除其他两个变量。然而，这并不总是这样。在某些情况下，一对变量可能高度相关，但很难解释为什么会出现这种情况。在这种情况下，可以随机删除两个中的一个。
- en: 'Exercise 82: Plotting a Correlated Matrix'
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习82：绘制相关矩阵
- en: In this exercise, we will compute the correlation between a pair of variables
    and draw a correlation plot using the `corrplot` package.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将计算一对变量的相关性，并使用`corrplot`包绘制相关图。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 完成练习的以下步骤：
- en: 'Import the required libraries using the following command:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令导入所需的库：
- en: '[PRE37]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output is as follows:'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE38]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, load the data and calculate the correlation matrix:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，加载数据并计算相关矩阵：
- en: '[PRE39]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Summarize the correlation matrix:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总结相关矩阵：
- en: '[PRE40]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output is as follows:'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE41]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Find attributes that are highly correlated (ideally >0.75):'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到高度相关的属性（理想情况下 >0.75）：
- en: '[PRE42]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Print the indexes of the highly correlated attributes:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印高度相关属性的索引：
- en: '[PRE43]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The output is as follows:'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE44]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Import the `corrplot` library:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`corrplot`库：
- en: '[PRE45]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Plot the correlation matrix:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制相关矩阵：
- en: '[PRE46]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The output is as follows:'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 6.7: Plotting correlated matrix'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.7：绘制相关矩阵'
- en: '](img/C12624_06_07.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12624_06_07.jpg)'
- en: 'Figure 6.7: Plotting correlated matrix'
  id: totrans-209
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.7：绘制相关矩阵
- en: Observe in *Figure 6.7* that the dark blue circles represent high positive correlation
    and the dark red circles represent high negative correlation. The range of correlation
    values is between `-1` and `1`. Visually inspecting, we can see the variable `Inversion_temperature`
    has high positive correlation with `pressure_height` and high negative correlation
    with `Inversion_base_height`. For example, if `Inversion_temperature` increases,
    `pressure_height` will also increase and vice versa.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图6.7*中观察，深蓝色圆圈表示高度正相关，深红色圆圈表示高度负相关。相关值的范围在`-1`和`1`之间。通过视觉检查，我们可以看到变量`Inversion_temperature`与`pressure_height`有高度正相关，与`Inversion_base_height`有高度负相关。例如，如果`Inversion_temperature`增加，`pressure_height`也会增加，反之亦然。
- en: Note
  id: totrans-211
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'Figure 6.7 can be found on GitHub: https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-R/blob/master/Lesson06/C12624_06_07.png.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7可以在GitHub上找到：https://github.com/TrainingByPackt/Applied-Supervised-Learning-with-R/blob/master/Lesson06/C12624_06_07.png.
- en: Model-Based Feature Importance Ranking
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于模型的特征重要性排序
- en: A model such as random forest, an ensemble modeling technique where we build
    several models and combine their results using a simple voting technique (as described
    in *Chapter 5*, *Classification)*, has a useful technique to utilize all the variables
    in a dataset and at the same time not compromise the model performance. The simple
    idea behind the random forest model is that it randomly selects a subset of data
    and variables to build many decision trees. The final model prediction happens
    through not one decision tree but collectively using many decision trees. Majority
    voting is a commonly used technique for final prediction; in other words, what
    the majority of the decision tree predicts is the final prediction.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，随机森林这样的模型，它是一种集成建模技术，我们构建多个模型，并使用简单的投票技术（如第5章、*分类*中所述）来组合它们的结果，它有一个有用的技术来利用数据集中的所有变量，同时不损害模型性能。随机森林模型背后的简单想法是它随机选择数据集和变量的子集来构建多个决策树。最终的模型预测不是通过一个决策树，而是通过集体使用多个决策树来完成的。多数投票是用于最终预测的常用技术；换句话说，大多数决策树预测的结果是最终预测。
- en: The technique naturally gives a combination of variables that result in highest
    accuracy. (Other model evaluation metrics could also be used.)
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术自然地给出了一种组合变量，这些变量导致最高的准确率。（也可以使用其他模型评估指标。）
- en: Note
  id: totrans-216
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: For certain research work in genomics and computational biology*****, where
    potential predictor variables vary in their scale of measurement (input features
    including both sequence and categorical variables such as folding energy) and
    their number of categories (for example, when amino acid sequence data show different
    numbers of categories), random forest importance measures are not reliable.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些基因组学和计算生物学的研究工作****，其中潜在的预测变量在测量尺度上有所不同（包括序列和分类变量，如折叠能）以及它们的类别数量（例如，当氨基酸序列数据显示不同的类别数量），随机森林的重要性度量不可靠。
- en: '***** Bias in random forest variable importance measures: Illustrations, sources
    and a solution: https://link.springer.com/article/10.1186/1471-2105-8-25.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '***** 随机森林变量重要性度量中的偏差：说明、来源和解决方案：https://link.springer.com/article/10.1186/1471-2105-8-25.'
- en: 'Exercise 83: Exploring RFE Using RF'
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习83：使用RF探索RFE
- en: In this exercise, we will explore **recursive feature elimination** (**RFE**)
    using the random forest algorithm. RFE helps in selecting the best features with
    highest feature importance.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用随机森林算法探索**递归特征消除**（**RFE**）。RFE有助于选择具有最高特征重要性的最佳特征。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: 'Import the `party` package:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`party`包：
- en: '[PRE47]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Fit the random forest:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合随机森林：
- en: '[PRE48]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Calculate the variable importance, based on a mean decrease in MSE. The `varimp()`
    function implements the RFE technique:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据均方误差的减少量计算变量重要性。`varimp()`函数实现了RFE技术：
- en: '[PRE49]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output is as follows:'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE50]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: In Step 2, the `party` package provides the method `cforest()`, which fits a
    random forest model using the parameter `mtry = 2` and `ntree = 50` and finds
    the best model where the `x`, using only the trees that did not have `x` in their
    bootstrap sample. The function `varimp()` returns the variable importance using
    the permutation principle (with values randomly shuffled) of the mean decrease
    in MSE. In other words, variable importance is measured as the mean decrease of
    the MSE over all out-of-bag cross-validated predictions, when a given variable
    is permuted after training but before prediction.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤2中，`party` 包提供了 `cforest()` 方法，使用参数 `mtry = 2` 和 `ntree = 50` 拟合随机森林模型，并找到最佳模型，其中
    `x` 仅使用没有 `x` 的bootstrap样本的树。函数 `varimp()` 使用排列原理（值随机打乱）计算平均MSE减少的变量重要性。换句话说，变量重要性是通过在训练后但在预测之前对给定变量进行排列后，所有袋外交叉验证预测的平均MSE减少来衡量的。
- en: As a result of randomly shuffled (permuted) variables, we expect a *bad* variable
    to be created and inclusion of this shuffled variable to increase the MSE compared
    to when it is not included in the model. Hence, if the mean decrease in the MSE
    is high, the MSE of the model as a result of shuffling of the variable has got
    to be high. So, we can conclude the variable has higher importance.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 由于随机打乱的变量，我们预计会创建一个 *差的* 变量，并且包含这个打乱变量的MSE与不包含在模型中的MSE相比会增加。因此，如果MSE的平均减少量很高，那么由于变量打乱而产生的模型MSE肯定很高。所以，我们可以得出结论，该变量的重要性更高。
- en: 'Exercise 84: Exploring the Variable Importance using the Random Forest Model'
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习84：使用随机森林模型探索变量重要性
- en: In this exercise, we will explore the variable importance using the random forest
    model. We will again use the Beijing dataset to see which among the five variables
    (`month`, `DEWP`, `TEMP`, `PRES`, and `Iws)` predicts the PM2.5 the best.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用随机森林模型探索变量重要性。我们再次使用北京市数据集，以查看五个变量（`month`、`DEWP`、`TEMP`、`PRES`
    和 `Iws`）中哪一个最好地预测PM2.5。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 完成以下步骤以完成练习：
- en: 'Import the randomForest package using the following command:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令导入随机森林包：
- en: '[PRE51]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Now, create a new object using the following command:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令创建一个新的对象：
- en: '[PRE52]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Print the model:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印模型：
- en: '[PRE53]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output is as follows:'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE54]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Find the R-squared value for each tree:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每棵树找到R-squared值：
- en: '[PRE55]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output is as follows:'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE56]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Next, calculate the variable importance plot:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，计算变量重要性图：
- en: '[PRE57]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The output is as follows:'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 6.8: Percentage increase in MSE and increase in node purity value
    obtained by fitting the randomForest model on the Beijing PM2.5 data'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 6.8：通过在北京市PM2.5数据上拟合随机森林模型获得的MSE百分比增加和节点纯度值增加](img/C12624_06_08.jpg)'
- en: '](img/C12624_06_08.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/C12624_06_08.jpg](img/C12624_06_08.jpg)'
- en: 'Figure 6.8: Percentage increase in MSE and increase in node purity value obtained
    by fitting the randomForest model on the Beijing PM2.5 data'
  id: totrans-252
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.8：通过在北京市PM2.5数据上拟合随机森林模型获得的MSE百分比增加和节点纯度值增加
- en: 'The previous exercise demonstrates another way to look at the variable importance.
    Instead of the `party` package, we have used the `randomForest` package. `%IncMSE`
    is computed as described in the following steps:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个练习演示了查看变量重要性的另一种方法。我们使用了 `randomForest` 包，而不是 `party` 包。`%IncMSE` 的计算方法如下所述：
- en: Fit random forest (in our case, it's a regression random forest). Compute OOB-MSE
    and name this `MSE_Base`.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合随机森林（在我们的情况下，是回归随机森林）。计算OOB-MSE并将其命名为 `MSE_Base`。
- en: 'For each variable `j`: permute values of column `j`, then predict and compute
    `OOB_MSE_j`.'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个变量 `j`：对列 `j` 的值进行排列，然后预测并计算 `OOB_MSE_j`.
- en: '`%IncMSE` of the `jth` variable equals `(OOB_MSE_j - MSE_Base)/ MSE_Base *
    100%`.'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`%IncMSE` 的 `jth` 变量等于 `(OOB_MSE_j - MSE_Base)/ MSE_Base * 100%`.'
- en: '*Figure 6.8* shows that inclusion of the variable `Iws` in the model increases
    the MSE by `22%` compared with the variable DEWP, which increases the MSE only
    by `15%`. We know that as a result of the shuffled values of the variable, the
    MSE is bound to increase, so the higher `%` implies a good variable. If we see
    the variable `TEMP`, the shuffling of values has not impacted the MSE that much
    compared with `Iws` and `DEWP`; hence, relatively, it is less important.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.8* 显示，将变量 `Iws` 包含在模型中，与变量 DEWP 相比，MSE增加了 `22%`，而 DEWP 仅使MSE增加了 `15%`。我们知道由于变量值的打乱，MSE肯定会增加，所以更高的
    `%` 意味着是一个好的变量。如果我们看到变量 `TEMP`，与 `Iws` 和 `DEWP` 相比，值的打乱对MSE的影响不大；因此，相对而言，它不太重要。'
- en: Node purity computes the value of loss function, which in this model is MSE.
    It helps in choosing the best split. Decrease in the MSE gives a higher node purity
    value. DEWP has the highest node purity followed by the feature month. In our
    dataset, both `%IncMSE` and `IncNodePurity` show similar results. However, keep
    in mind that `IncNodePurity` is often biased and should always be seen in conjunction
    with `%IncMSE`.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 节点纯度计算损失函数的值，在这个模型中是均方误差 (MSE)。它有助于选择最佳分割。MSE 的降低会给出更高的节点纯度值。DEWP 具有最高的节点纯度，其次是月份特征。在我们的数据集中，`%IncMSE`
    和 `IncNodePurity` 显示了类似的结果。然而，请记住，`IncNodePurity` 往往存在偏差，并且应该始终与 `%IncMSE` 结合起来考虑。
- en: Feature Reduction
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征降维
- en: '**Feature reduction** helps get rid of redundant variables that reduce the
    model efficiency in the following ways:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征降维**有助于去除冗余变量，以下方式降低模型效率：'
- en: Time to develop/train the model increases.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型开发/训练时间增加。
- en: Interpretation of the results becomes tedious.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果的解释变得繁琐。
- en: It inflates the variance of the estimates.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它夸大了估计的方差。
- en: In this section, we will see three feature reduction techniques that help in
    improving the model efficiency.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到三种特征降维技术，这些技术有助于提高模型效率。
- en: Principal Component Analysis (PCA)
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 主成分分析 (PCA)
- en: N. A. Campbell and William R. Atchley in their classic paper, *The Geometry
    of Canonical Variate Analysis,* Systematic Biology, Volume 30, Issue 3, September
    1981, Pages 268–280, geometrically defined *a principal component analysis as
    a rotation of the axes of the original variable coordinate system to new orthogonal
    axes, called principal axes, such that the new axes coincide with directions of
    maximum variation of the original observation*. This forms the crux of what PCA
    does. In other words, it represents the original variable with principal components
    that explain the maximum variation of the original observations or data.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: N. A. Campbell 和 William R. Atchley 在他们经典论文《典型变量分析的几何学》中，系统生物学，第 30 卷，第 3 期，1981
    年 9 月，第 268–280 页，从几何角度定义了**主成分分析**为将原始变量坐标系统的轴旋转到新的正交轴，称为主轴，使得新轴与原始观察的最大变化方向一致。这是
    PCA 的核心所在。换句话说，它用解释原始观察或数据最大变化的主成分来表示原始变量。
- en: The paper elegantly presents the geometrical representation of principal components
    as shown in the following figure, which is a representation of the scatter diagram
    for two variables, showing the mean for each variable ![](img/C12624_06_34.png),
    *95%* concentration ellipse, and principal axes ![](img/C12624_06_35.png) and
    ![](img/C12624_06_36.png). The points ![](img/C12624_06_37.png) and ![](img/C12624_06_38.png)
    give the principal component scores for the observation ![](img/C12624_06_39.png)
    = . The cosine of the angle ![](img/C12624_06_40.png) between ![](img/C12624_06_41.png)
    and ![](img/C12624_06_42.png) gives the first component ![](img/C12624_06_43.png)
    of the eigenvector corresponding to ![](img/C12624_06_44.png).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 论文巧妙地展示了主成分的几何表示，如下所示图，这是两个变量的散点图表示，显示了每个变量的均值 ![img/C12624_06_34.png]，*95%*
    浓集椭圆，以及主轴 ![img/C12624_06_35.png] 和 ![img/C12624_06_36.png]。点 ![img/C12624_06_37.png]
    和 ![img/C12624_06_38.png] 给出了观察 ![img/C12624_06_39.png] = . 的主成分得分。向量 ![img/C12624_06_41.png]
    和 ![img/C12624_06_42.png] 之间角度 ![img/C12624_06_40.png] 的余弦值给出了对应于 ![img/C12624_06_44.png]
    的特征向量的第一个分量 ![img/C12624_06_43.png]。
- en: In linear algebra, an eigenvector of a linear transformation is a non-zero vector
    that changes by only a scalar factor when that linear transformation is applied
    to it.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性代数中，线性变换的特征向量是一个非零向量，当该线性变换应用于它时，它只改变一个标量因子。
- en: '![](img/C12624_06_09.jpg)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![img/C12624_06_09.jpg]'
- en: 'Figure 6.9: Shows the representation of the scatter diagram for two variables,
    showing the mean for each variable (x ̅_1 and x ̅_2), 95% concentration ellipse,
    and principal axes Y_1 and Y_2'
  id: totrans-270
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.9：显示了两个变量的散点图表示，显示了每个变量的均值（x̅_1 和 x̅_2），95% 浓集椭圆，以及主轴 Y_1 和 Y_2
- en: 'Source: The Geometry of Canonical Variate Analysis, Systematic Biology, Volume
    30, Issue 3, September 1981, Pages 268–280'
  id: totrans-271
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 来源：典型变量分析的几何学，系统生物学，第 30 卷，第 3 期，1981 年 9 月，第 268–280 页
- en: 'Exercise 85: Performing PCA'
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 85：执行 PCA
- en: In this exercise, we will perform PCA, which will help reduce the dimensionality
    of the feature space. In other words, fewer principal components that are the
    linear combination of input features will represent the entire dataset.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将执行 PCA，这将有助于降低特征空间的维度。换句话说，更少的由输入特征线性组合的主成分将代表整个数据集。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: 'Import the `OzoneData` package:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`OzoneData`包：
- en: '[PRE58]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The output is as follows:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE59]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Print the column name using the `colnames` function:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`colnames`函数打印列名：
- en: '[PRE60]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The output is as follows:'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE61]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Find the means for all variables:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算所有变量的均值：
- en: '[PRE62]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The output is as follows:'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE63]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Find the variance of all variables:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算所有变量的方差：
- en: '[PRE64]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The output is as follows:'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE65]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Significant differences in variance of the variables will control the principal
    components. `prcomp()` will standardize the variables (mean `0` and variance `1`)
    before finding out the principal component.
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 变量的方差显著差异将控制主成分。`prcomp()`函数在找出主成分之前会对变量进行标准化（均值`0`和方差`1`）。
- en: '[PRE66]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Next, find the summary of the PCA:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，找到PCA的摘要：
- en: '[PRE67]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The output is as follows:'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE68]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Create a biplot using the `ggbiplot` function:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ggbiplot`函数创建双图：
- en: '[PRE69]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The output is as follows:'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 6.10 Scaled biplot of the first two principle components using ggbiplot'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.10 使用ggbiplot缩放双图的前两个主成分'
- en: '](img/C12624_06_10.jpg)'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/C12624_06_10.jpg]'
- en: Figure 6.10 Scaled biplot of the first two principle components using ggbiplot
  id: totrans-302
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.10 使用ggbiplot缩放双图的前两个主成分
- en: The biplot in the figure shows how `Ozone` dataset. As shown in the output of
    `summary(pca.out)`, biplots depict the explained variance by using the various
    features in the dataset. The axes are seen as arrows originating from the center
    point. The figure also shows that the variables `pressure_height` and `inversion_temperature`
    contribute to `Visibility` and `day_of_the_week` contribute to **PC2** with higher
    values.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的双图显示了`Ozone`数据集。如`summary(pca.out)`的输出所示，双图使用数据集中的各种特征来描述解释的方差。轴被看作是从中心点发出的箭头。该图还显示，变量`pressure_height`和`inversion_temperature`对`Visibility`有贡献，而`day_of_the_week`对**PC2**有更高的值。
- en: 'If you find difficulty installing `ggbiplot`, you could also use the `biplot()`
    function from base R, as shown in the following plot. First, let''s build a biplot
    to understand better:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在安装`ggbiplot`时遇到困难，您也可以使用R基础包中的`biplot()`函数，如下面的图所示。首先，让我们构建一个双图以更好地理解：
- en: '[PRE70]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '![Figure 6.11 Scaled biplot of the first principle component'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.11 第一主成分的缩放双图'
- en: '](img/C12624_06_11.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/C12624_06_11.jpg]'
- en: Figure 6.11 Scaled biplot of the first principle component
  id: totrans-308
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.11 第一主成分的缩放双图
- en: Observe that the maximum percentage of variance is explained by PC1 and all
    PCs are mutually uncorrelated. In particular, around `40%` of the variance is
    explained by PC1, and the first principal component (PC1-PC4) explains 70% of
    the variance. In other words, if we use the first four principal components, we
    should get a model almost similar to the one we would get when we use all the
    variables in the dataset. This should not be surprising as the principal component
    is a linear combination of the variables.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，最大百分比方差由PC1解释，所有主成分彼此不相关。特别是，大约`40%`的方差由PC1解释，第一个主成分（PC1-PC4）解释了70%的方差。换句话说，如果我们使用前四个主成分，我们应该得到一个与使用数据集中所有变量得到的模型几乎相同的模型。这并不令人惊讶，因为主成分是变量的线性组合。
- en: Variable Clustering
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变量聚类
- en: '**Variable clustering** is used for measuring collinearity, calculating redundancy,
    and for separating variables into clusters that can be counted as a single variable,
    thus resulting in data reduction. Hierarchical cluster analysis on variables uses
    any one of the following: Hoeffding''s D statistics, squared Pearson or Spearman
    correlations, or uses as a similarity measure the proportion of observations for
    which two variables are both positive. The idea is to find the cluster of correlated
    variables that are correlated with themselves and not with variables in another
    cluster. This reduces a large number of features into a smaller number of features
    or variable clusters.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '**变量聚类**用于测量共线性、计算冗余，并将变量分离成可以计为一个单一变量的聚类，从而实现数据降维。对变量的层次聚类分析可以使用以下任何一个：Hoeffding的D统计量、平方皮尔逊或斯皮尔曼相关系数，或者使用两个变量都为正的观测比例作为相似性度量。其思想是找到与自身相关且不与另一个聚类中的变量相关的相关变量簇。这可以将大量特征减少到更少的特征或变量簇。'
- en: 'Exercise 86: Using Variable Clustering'
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习86：使用变量聚类
- en: In this exercise, we will use feature clustering for identifying a cluster of
    similar features. From each cluster, we can select one or more features for the
    model. We will use the hierarchical cluster algorithm from the Hmisc package in
    R. The similarity measure should be set to "spear," which stands for the Pearson
    correlation, a robust measure for computing the similarity between two observations.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用特征聚类来识别相似特征簇。从每个簇中，我们可以选择一个或多个特征用于模型。我们将使用R中的Hmisc包中的层次聚类算法。相似度度量应设置为"spear"，代表皮尔逊相关系数，它是计算两个观测值之间相似性的稳健度量。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: 'Install the `Hmisc` package using the following command:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令安装`Hmisc`包：
- en: '[PRE71]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Import the `Hmisc` package and set the seed to `1`:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`Hmisc`包并设置随机种子为`1`：
- en: '[PRE72]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Use variable clustering with Spearman correlation as the similarity measure:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用变量聚类，以Spearman相关系数作为相似度度量：
- en: '[PRE73]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The output is as follows:'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE74]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Print the value:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印值：
- en: '[PRE75]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The output is as follows:'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE76]'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Based on the similarity matrix, the following figure shows the plot of variables
    in the same cluster. For example, `Temperature_ElMonte` and `Inversion_temperature`
    are both clustered into one cluster with a Spearman correlation score of 0.85\.
    Similarly, `Humidity` and `Pressure_gradient` have a Spearman correlation of 0.25\.
    A high similarity would entail the decision of dropping one of them. In addition
    to the top of the output of the cluster, one should also consider the model metrics
    before taking the final call of dropping the variable completely:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 根据相似度矩阵，以下图显示了同一簇中的变量。例如，`Temperature_ElMonte`和`Inversion_temperature`都被聚类到一个簇中，Spearman相关系数为0.85。同样，`Humidity`和`Pressure_gradient`的Spearman相关系数为0.25。高相似度将导致决定删除其中一个。除了查看聚类输出顶部之外，在最终决定完全删除变量之前，还应考虑模型指标：
- en: '[PRE77]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '![Figure 6.12: Hierarchical cluster of variables in Ozone dataset'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.12：臭氧数据集中变量的层次聚类'
- en: '](img/C12624_06_12.jpg)'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12624_06_12.jpg)'
- en: 'Figure 6.12: Hierarchical cluster of variables in Ozone dataset'
  id: totrans-331
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6.12：臭氧数据集中变量的层次聚类
- en: Linear Discriminant Analysis for Feature Reduction
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性判别分析用于特征降维
- en: '**Linear discriminant analysis** (**LDA**) helps in maximizing the class separation
    by projecting the data into a new feature space: lower dimensional space with
    good class separability in order to avoid overfitting (*curse of dimensionality*).
    LDA also reduces computational costs, which makes it suitable as a classification
    algorithm. The idea is to maximize the distance between the mean of each class
    (or category) and minimize the variability within the class. (This sounds certainly
    like how the clustering algorithm in unsupervised learning works, but we will
    not touch that here as it is not in the scope of this book.) Note that LDA assumes
    that data follows a Gaussian distribution; if it''s not, the performance of LDA
    will be reduced. In this section, we will use LDA as a feature reduction technique
    rather than as a classifier.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性判别分析**（**LDA**）通过将数据投影到新的特征空间（低维空间，具有良好的类别可分性）来最大化类别分离，以避免过拟合（**维度诅咒**）。LDA还降低了计算成本，使其适合作为分类算法。其思想是最大化每个类别（或类别）的均值之间的距离，并最小化类别内的变异性。（这确实听起来像无监督学习中的聚类算法，但在这里我们不会涉及，因为它超出了本书的范围。）请注意，LDA假设数据遵循高斯分布；如果不是，LDA的性能将降低。在本节中，我们将使用LDA作为特征降维技术，而不是作为分类器。'
- en: 'For the two-class problem, if we have an *m*-dimensional dataset ![](img/C12624_06_45.png)
    with *N* observations, of which ![](img/C12624_06_46.png) belongs to class ![](img/C12624_06_47.png)
    and ![](img/C12624_06_48.png) belongs to class ![](img/C12624_06_49.png). In this
    case, we can project the data onto a line (with *C=2*, project into *C-1* space):'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二分类问题，如果我们有一个*m*-维数据集 ![](img/C12624_06_45.png) ，包含*N*个观测值，其中 ![](img/C12624_06_46.png)
    属于类别 ![](img/C12624_06_47.png) ，而 ![](img/C12624_06_48.png) 属于类别 ![](img/C12624_06_49.png)
    。在这种情况下，我们可以将数据投影到一条线（*C=2*，投影到*C-1*空间）：
- en: '![](img/C12624_06_50.jpg)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12624_06_50.jpg)'
- en: Such a projection is achieved by projecting the mean of *X* onto the mean of
    *Y*. Of all the lines possible, we would like to select the one that maximizes
    the separability of the scalars. In other words, where the projections of observation
    from the same class are projected very close to each other and, at the same time,
    the projected means are as far apart as possible.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的投影是通过将 *X* 的均值投影到 *Y* 的均值上实现的。在所有可能的线中，我们希望选择一条最大化标量可分性的线。换句话说，来自同一类的观察值的投影非常接近，同时，投影的均值尽可能远。
- en: It should be noted that while in LDA we use the class variable more like supervised
    learning, PCA does not need any class variable to reduce the feature size. That
    is why, while LDA preserves as much of the class discriminatory information as
    possible, PCA does not much care about it.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意的是，虽然 LDA 中我们更像是监督学习使用类变量，PCA 不需要任何类变量来减少特征大小。这就是为什么，虽然 LDA 尽可能多地保留了类区分信息，PCA
    并不太关心这一点。
- en: '![Figure 6.13: Comparing PCA and LDA'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 6.13: Comparing PCA and LDA'
- en: '](img/C12624_06_13.jpg)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/C12624_06_13.jpg](img/C12624_06_13.jpg)'
- en: 'Figure 6.13: Comparing PCA and LDA'
  id: totrans-340
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.13：比较 PCA 和 LDA
- en: 'Source: https://sebastianraschka.com/Articles/2014_python_lda.html'
  id: totrans-341
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 来源：https://sebastianraschka.com/Articles/2014_python_lda.html
- en: 'Exercise 87: Exploring LDA'
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 87：探索 LDA
- en: In this exercise, we will perform LDA for feature reduction. We will observe
    the difference in the model performance with all the features and the reduced
    features using LDA.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将执行 LDA 进行特征降维。我们将观察使用所有特征和 LDA 降维后的特征在模型性能上的差异。
- en: 'Perform the following steps:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤：
- en: 'Merge the two DataFrames on timestamp to stack other environmental variables
    along with PM2.5 into one DataFrame:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将两个 DataFrame 在时间戳上合并以堆叠其他环境变量以及 PM2.5 到一个 DataFrame 中：
- en: '[PRE78]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Split the dataset into train and test:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集分为训练集和测试集：
- en: '[PRE79]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Import the `MASS` package:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `MASS` 包：
- en: '[PRE80]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Fit the LDA model on the training dataset:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据集上拟合 LDA 模型：
- en: '[PRE81]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Plot 100 randomly selected projected values:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制 100 个随机选择的投影值：
- en: '[PRE82]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'The output is as follows:'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 6.14: Plot of randomly selected 100 projected values'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![Figure 6.14: Plot of randomly selected 100 projected values'
- en: '](img/C12624_06_14.jpg)'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/C12624_06_14.jpg](img/C12624_06_14.jpg)'
- en: 'Figure 6.14: Plot of randomly selected 100 projected values'
  id: totrans-358
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6.14：随机选择的 100 个投影值的图
- en: 'Perform the model testing:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行模型测试：
- en: '[PRE83]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Import the `caret` library and print the confusion matrix:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `caret` 库并打印混淆矩阵：
- en: '[PRE84]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'The output is as follows:'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE85]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Find the dimension-reduced dataset:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找降维后的数据集：
- en: '[PRE86]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Test the dataset:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试数据集：
- en: '[PRE87]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Use the projected data. Let''s fit a logistic model. You could use any other
    classification model as well:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用投影数据。让我们拟合一个逻辑模型。你也可以使用其他任何分类模型：
- en: '[PRE88]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Perform the model evaluation on testing data:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试数据上执行模型评估：
- en: '[PRE89]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Predict 1 if probability > 0.5:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果概率大于 0.5，则预测 1：
- en: '[PRE90]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'Find the confusion matrix:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找混淆矩阵：
- en: '[PRE91]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'The output is as follows:'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE92]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: Note that the accuracy in `LDA_test` and the projected `new_LDA_test` are strikingly
    similar. This indicates that the projected values in the new lower dimensional
    space perform equally well compared with the original. It might always not be
    the case that the new space will result in the same performance as the original.
    Therefore, a thorough scrutiny is required before reducing the feature space.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`LDA_test` 和投影的 `new_LDA_test` 的准确性惊人地相似。这表明在新低维空间中的投影值与原始值相比表现同样出色。并不总是新空间会带来与原始空间相同的表现。因此，在减少特征空间之前需要进行彻底的审查。
- en: Summary
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we saw various feature selection and reduction techniques.
    The three main topics covered in this chapter were: Feature Engineering, Feature
    Selection, and Feature Reduction. The latter two have the same purpose of shrinking
    the number of features; however, the techniques used are completely different.
    Feature Engineering focuses on transforming variables into a new form that either
    helps in improving the model performance or makes the variable be in compliance
    with model assumption. An example is the linearity assumption in the linear regression
    model, where we typically could square or cube the variables and the skewness
    in data distribution, which could be addressed using log transformation. Feature
    Selection and Feature Reduction help in providing the best feature set or the
    best representation of the feature set, which improves model performance. Most
    importantly, both techniques shrink the feature space, which drastically improves
    the model training time without compromising the performance in terms of accuracy,
    **RMSE,** or any relevant model evaluation metric.'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了各种特征选择和降维技术。本章涵盖的三个主要主题是：特征工程、特征选择和特征降维。后两者具有缩小特征数量的相同目的；然而，所使用的技巧完全不同。特征工程侧重于将变量转换成新的形式，这有助于提高模型性能或使变量符合模型假设。例如，在线性回归模型中的线性假设，我们通常可以对变量进行平方或立方，以及解决数据分布中的偏斜度，这可以通过对数变换来解决。特征选择和特征降维有助于提供最佳的特征集或特征集的最佳表示，从而提高模型性能。最重要的是，这两种技术都缩小了特征空间，这极大地提高了模型训练时间，同时没有在准确性、**RMSE**或任何相关模型评估指标方面妥协性能。
- en: We also saw how some of the models themselves, such as random forest and **LDA,**
    could directly be used as feature selection and reduction techniques. While random
    forest works by selecting the best features through a method of random selection,
    LDA works by finding the best representation of features. Thus, the former is
    used in feature selection and the latter in reduction.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到了一些模型本身，例如随机森林和**LDA**，可以直接用作特征选择和降维技术。随机森林通过随机选择的方法选择最佳特征，而LDA则是通过寻找特征的最佳表示来工作。因此，前者用于特征选择，后者用于降维。
- en: In the next chapter, we will explore more about model improvement, where some
    of the learnings from this chapter will be employed.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨更多关于模型改进的内容，其中将应用本章的一些学习成果。
