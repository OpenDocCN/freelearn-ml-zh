- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Productionizing ML on Databricks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Databricks 上实现 ML 的生产化
- en: “Production is 80% of the work.”
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: “生产是工作的 80%。”
- en: — Matei Zaharia
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: —— 玛泰·扎哈里亚
- en: Once you’ve refined your model and have satisfactory results, you are ready
    to put it into production. We’ve now entered the field of **machine learning operations**
    (**MLOps**)! Unfortunately, this is where many data scientists and ML engineers
    get stuck, and it’s common for companies to struggle here. Implementing models
    in production is much more complex than running models ad hoc because MLOps requires
    distinct tools and skill sets and sometimes, entirely new teams. MLOps is an essential
    part of the data science process because the actual value of a model is often
    only realized post-deployment.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您已经优化了模型并获得了满意的结果，您就可以将其投入生产。我们现在已经进入了 **机器学习操作** (**MLOps**) 的领域！不幸的是，这正是许多数据科学家和
    ML 工程师遇到困难的地方，公司在这里遇到困难也很常见。在生产中实施模型比临时运行模型要复杂得多，因为 MLOps 需要不同的工具和技能集，有时甚至需要全新的团队。MLOps
    是数据科学过程中的一个重要部分，因为模型的实际价值通常只有在部署后才能实现。
- en: 'You can think of MLOps as combining **DevOps**, **DataOps**, and **ModelOps**.
    MLOps is often divided into two parts: inner and outer loops. The inner loop covers
    the data science work and includes tracking various stages of the model development
    and experimentation process. The outer loop encompasses methods to orchestrate
    your data science project throughout its life cycle, from testing to staging and
    ultimately into production.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将 MLOps 视为 **DevOps**、**DataOps** 和 **ModelOps** 的结合。MLOps 通常分为两个部分：内循环和外循环。内循环涵盖数据科学工作，包括跟踪模型开发和实验过程的各个阶段。外循环包括在整个生命周期中协调您的数据科学项目的方法，从测试到预生产和最终投入生产。
- en: Fortunately, the path from model development to production doesn’t have to depend
    entirely on another team and tool stack when using the Databricks **Data Intelligence**
    (**DI**) platform. Productionizing an ML model using Databricks products makes
    the journey more straightforward and cohesive by incorporating functionality such
    as the **Unity Catalog Registry** (**UC Registry**), Databricks workflows, **Databricks
    Asset Bundles** (**DABs**), and model serving capabilities. This chapter will
    cover the tools and practices for taking your models from development to production.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，在使用 Databricks **数据智能** (**DI**) 平台时，从模型开发到生产的路径不必完全依赖于另一个团队和工具栈。使用 Databricks
    产品将 ML 模型投入生产，通过整合诸如 **Unity Catalog 注册表** (**UC 注册表**), Databricks 工作流, **Databricks
    资产包** (**DABs**) 和模型托管功能等功能，使这一过程更加直接和连贯。本章将涵盖将您的模型从开发到生产的工具和实践。
- en: 'Here is what you will learn as part of this chapter:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作为本章的一部分，您将学习以下内容：
- en: Deploying the MLOps inner loop
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署 MLOps 内循环
- en: Deploying the MLOps outer loop
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署 MLOps 外循环
- en: Deploying your model
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署您的模型
- en: Applying our learning
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用我们的学习
- en: Deploying the MLOps inner loop
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署 MLOps 内循环
- en: In Databricks, the MLOps inner loop uses a variety of tools within the DI platform
    that we’ve already touched upon throughout this book, such as MLflow, Feature
    Engineering with Unity Catalog, and Delta. This chapter will highlight how you
    can leverage them together to facilitate MLOps from one place. MLOps is covered
    in even more depth by Databricks’ ebook, *The Big Book of MLOps*, which we highly
    recommend if you wish to learn more about the guiding principles and design decisions
    when architecting your own MLOps solution. We use `mlflow.log_input()` method.
    The upstream sources of the feature tables we create are automatically tracked
    by UC lineage.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Databricks 中，MLOps 内循环使用 DI 平台内的一系列工具，这些工具我们在本书中已经多次提及，例如 MLflow、使用 Unity
    Catalog 的特征工程和 Delta。本章将突出展示您如何利用它们共同促进 MLOps 的实施。Databricks 的电子书 *MLOps 大全* 对
    MLOps 进行了更深入的探讨，我们强烈推荐您阅读，如果您想了解更多关于构建自己的 MLOps 解决方案时的指导原则和设计决策。我们使用 `mlflow.log_input()`
    方法。我们创建的特征表的上游来源会自动通过 UC 线索进行跟踪。
- en: Registering a model
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注册模型
- en: Let’s jump into model registries and their role in productionalization. A model
    registry is a centralized model store that helps manage the entire model life
    cycle, including versioning or aliasing, CI/CD integration, webhooks, and notifications.
    In Databricks, the UC Registry extends the governance features of Unity Catalog
    to the model registries, including centralized access control, auditing, lineage,
    and model discovery across workspaces. The UC Registry is a centralized repository
    for your models and their chronological lineage. This means that the experiment
    and experiment run that created each respective model are linked to the respective
    code and data source. Once you are satisfied with your ML model, the first thing
    to do is register it in Databricks under your central model registry. A registered
    model is a logical grouping of a model’s version history. The UC Registry tracks
    different model versions, including each version’s training data, hyperparameters,
    and evaluation metrics. A model rarely, if ever, has only one version. In addition
    to experimentation of model types and hyperparameter values, there are also cases
    where we want to experiment with different versions of a model. We can refer to
    these different model versions using model aliases. For example, deploying different
    versions simultaneously can be helpful for A/B testing; we’ll cover this in more
    detail in the *Model inference* section. With the UC Registry, you can easily
    create and manage multiple model aliases, making it easier to track changes, compare
    performance, and revert to earlier versions if needed.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解模型注册表及其在生产中的应用。模型注册表是一个集中的模型存储库，有助于管理整个模型生命周期，包括版本控制或别名、CI/CD 集成、webhooks
    和通知。在 Databricks 中，UC 注册表扩展了 Unity Catalog 的治理功能到模型注册表，包括集中访问控制、审计、血缘关系和跨工作区的模型发现。UC
    注册表是您模型及其时间顺序血缘关系的集中存储库。这意味着创建每个相应模型的实验和实验运行都与相应的代码和数据源相关联。一旦您对您的机器学习模型满意，首先要做的是在
    Databricks 的中央模型注册表中注册它。已注册的模型是模型版本历史的逻辑分组。UC 注册表跟踪不同的模型版本，包括每个版本的训练数据、超参数和评估指标。模型很少只有一个版本。除了对模型类型和超参数值的实验外，还有我们想要对模型的不同版本进行实验的情况。我们可以使用模型别名来引用这些不同的模型版本。例如，同时部署不同版本对于
    A/B 测试可能很有帮助；我们将在 *模型推理* 部分更详细地介绍这一点。有了 UC 注册表，您可以轻松创建和管理多个模型别名，这使得跟踪更改、比较性能以及在需要时回滚到早期版本变得更加容易。
- en: Collaborative development
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协作开发
- en: The UC Registry provides a collaborative model development environment, enabling
    teams to share and review models. This collaboration is also tracked, allowing
    multiple teams or leads to stay abreast of the model development process. Team
    or project leads can also require documentation before allowing a model to continue
    through the life cycle. We find it easier to add snippets of documentation throughout
    the project rather than trying to remember everything and take the time to write
    it all down afterward.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: UC 注册表提供了一个协作的模型开发环境，使团队能够共享和审查模型。这种协作也被跟踪，使多个团队或负责人能够跟上模型开发过程。团队或项目负责人还可以在允许模型继续生命周期之前要求提供文档。我们发现，在整个项目过程中添加文档片段比试图记住所有内容并在之后花费时间写下它们要容易得多。
- en: The UC Registry allows you to tag models and model versions. In the Streaming
    Transactions project, we use tags to track the validation status of a model. The
    approval process can be automated or may require human interaction. An approval
    process can ensure that models are high quality and meet business requirements.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: UC 注册表允许您对模型和模型版本进行标记。在流式事务项目中，我们使用标签来跟踪模型的验证状态。审批流程可以是自动化的，也可能需要人工交互。一个审批流程可以确保模型质量高且满足业务需求。
- en: '*Figure 7**.1* shows a screenshot of the UC Model Registry. Note that there
    are built-in locations for tags, aliases, and comments:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7**.1* 展示了 UC 模型注册表的截图。请注意，其中内置了标签、别名和注释的位置：'
- en: '![Figure 7.1 – The UC Model Registry UI shows each model version](img/B16865_07_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.1 – UC 模型注册表 UI 展示每个模型版本](img/B16865_07_01.jpg)'
- en: Figure 7.1 – The UC Model Registry UI shows each model version
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – UC 模型注册表 UI 展示每个模型版本
- en: The UC Registry is tightly integrated with the DI platform. This provides a
    single technical stack – a unified environment for moving a model through experimentation
    to deployment. The seamless integration lets you leverage other Databricks components
    such as Databricks Notebooks, Databricks Jobs, Databricks Lakehouse Monitoring,
    and Databricks Model Serving.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: UC注册与DI平台紧密集成。这提供了一个单一的技术栈 – 一个统一的环境，用于将模型从实验移动到部署。无缝集成让您可以利用其他Databricks组件，例如Databricks
    Notebooks、Databricks Jobs、Databricks Lakehouse Monitoring和Databricks Model Serving。
- en: Next, let’s move on to product features that support the outer loop process.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们继续探讨支持外部循环过程的产品功能。
- en: Deploying the MLOps outer loop
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署MLOps外部循环
- en: The ML life cycle looks different for different use cases. However, the set
    of tools available in the Databricks platform makes it possible to automate as
    you like and supports your MLOps. The outer loop connects the inner loop products
    with the help of Workflows, Databricks Terraform Provider, REST API, DABs, and
    more. We covered automating the tracking process through MLflow Tracking and the
    UC Registry. The UC Registry is tightly integrated with the Model Serving feature
    and has a robust API that can easily be integrated into the automation process
    using webhooks. Each of these features can play a role in automating the ML life
    cycle.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习生命周期对于不同的用例看起来不同。然而，Databricks平台上的工具集使得自动化变得可能，并支持您的MLOps。外部循环通过工作流程、Databricks
    Terraform Provider、REST API、DABs等将内部循环产品连接起来。我们介绍了通过MLflow Tracking和UC注册自动化跟踪过程。UC注册与模型服务功能紧密集成，并具有一个强大的API，可以轻松地通过webhooks集成到自动化过程中。这些功能中的每一个都可以在自动化机器学习生命周期中发挥作用。
- en: Workflows
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作流程
- en: 'Databricks Workflows is a flexible orchestration tool for productionizing and
    automating ML projects. Workflows help the ML life cycle by providing a unified
    way to chain together all aspects of ML, from data preparation to model deployment.
    With Databricks Workflows, you can designate dependencies between tasks to ensure
    tasks are completed in the required order. These dependencies are visualized with
    arrows connecting the tasks, as shown in *Figure 7**.2*:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks Workflows是一个灵活的编排工具，用于生产化和自动化机器学习项目。工作流程通过提供统一的方式来连接机器学习的各个方面，从数据准备到模型部署，帮助机器学习生命周期。使用Databricks
    Workflows，您可以指定任务之间的依赖关系，以确保任务按所需顺序完成。这些依赖关系通过连接任务的箭头进行可视化，如图*7.2*所示：
- en: "![Figure 7.2 – A Databricks workflow with five tasks, with the feature engineering\
    \ task having two\uFEFF dependencies](img/B16865_07_02.jpg)"
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图7.2 – 一个包含五个任务的Databricks工作流程，其中特征工程任务有两个依赖项](img/B16865_07_02.jpg)'
- en: Figure 7.2 – A Databricks workflow with five tasks, with the feature engineering
    task having two dependencies
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 – 一个包含五个任务的Databricks工作流程，其中特征工程任务有两个依赖项
- en: 'Tasks in a workflow are not limited to notebooks. In [*Chapter 3*](B16865_03.xhtml#_idTextAnchor123),
    we prepared a DLT pipeline to prepare data in the Bronze layer, and DLT pipelines
    can be a workflow component. Additional objects, such as JAR files, Python scripts,
    and SQL, can be tasks within a workflow, as shown in *Figure 7**.3*:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程中的任务不仅限于笔记本。在[*第3章*](B16865_03.xhtml#_idTextAnchor123)中，我们准备了一个DLT管道来准备青铜层的数据，DLT管道可以是工作流程组件。其他对象，如JAR文件、Python脚本和SQL，也可以作为工作流程中的任务，如图*7.3*所示：
- en: '![Figure 7.3 – Examples of objects that can be used as tasks within a workflow](img/B16865_07_03.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图7.3 – 可以用作工作流程中任务的对象示例](img/B16865_07_03.jpg)'
- en: Figure 7.3 – Examples of objects that can be used as tasks within a workflow
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 – 可以用作工作流程中任务的对象示例
- en: Workflows are robust and play a key role in automating work within Databricks.
    DABs are another tool for productionization in Databricks.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程稳健，在Databricks中自动化工作发挥着关键作用。DABs是Databricks中生产化的另一种工具。
- en: DABs
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DABs
- en: DABs are a way to bring uniformity and standardization to the deployment approach
    for all data products built on the Databricks platform. They are an **Infrastructure
    as Code** (**IaC**) approach to managing your projects, allowing developers to
    outline a project’s infrastructure and resources using a YAML configuration file.
    DABs are especially useful for managing complex projects that involve a lot of
    collaborators and require automation. Where **continuous integration and continuous
    deployment** (**CI/CD**) is necessary, DABs are a wonderful way to manage ML pipeline
    resources across environments and to help your team follow best practices throughout
    the development and productionalization processes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: DABs是一种为基于Databricks平台构建的所有数据产品的部署方法带来统一性和标准化的方式。它们是一种**基础设施即代码**（**IaC**）的方法，用于管理项目，允许开发者使用YAML配置文件概述项目的基础设施和资源。DABs对于管理涉及众多协作者和需要自动化的复杂项目特别有用。在需要**持续集成和持续部署**（**CI/CD**）的地方，DABs是管理跨环境ML管道资源和管理团队在整个开发和生产过程中的最佳实践的绝佳方式。
- en: Under the hood, DABs are collections of Databricks artifacts (including jobs,
    DLT pipelines, and ML models) and assets (for example, notebooks, SQL queries,
    and dashboards). These bundles are managed through YAML templates that are created
    and maintained alongside source code. You can build DAB YAML files manually or
    use templates to automate. You can also build custom templates for more complex
    processing tasks.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，DABs是Databricks工件（包括作业、DLT管道和ML模型）和资产（例如笔记本、SQL查询和仪表板）的集合。这些捆绑包通过创建和维护在源代码旁边的YAML模板进行管理。您可以手动构建DAB
    YAML文件或使用模板来自动化。您还可以为更复杂的处理任务构建自定义模板。
- en: Using DABs requires the Databricks CLI. We discussed installing the CLI in [*Chapter
    2*](B16865_02.xhtml#_idTextAnchor073) if you want to review it again. Also, DABs
    are fairly new and not incorporated into the projects. However, great resources
    are listed in *Further reading* that cover this new product feature in depth.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用DABs需要Databricks CLI。如果您想再次查看，我们已在[*第二章*](B16865_02.xhtml#_idTextAnchor073)中讨论了CLI的安装。此外，DABs相对较新，尚未纳入项目中。然而，在*进一步阅读*中列出了大量资源，深入介绍了这个新产品特性。
- en: REST API
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: REST API
- en: Everything you can do in the UI can be accomplished via the API as well. The
    UI is great for exploring product features and building workflows for the first
    time. For example, we automated the process after building out our AutoML experiment
    in the UI. Additionally, we saw how secrets are completely contained in the API
    and not available via the UI. As we’ll see in the next section, it is possible
    to deploy your models via the API.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 您在UI中能做的所有事情都可以通过API完成。UI非常适合探索产品功能和构建首次使用的流程。例如，我们在UI中构建了AutoML实验后，自动化了该过程。此外，我们还看到了如何通过API完全包含密钥，而UI则无法访问。正如我们将在下一节中看到的，通过API部署模型是可能的。
- en: Deploying your model
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署您的模型
- en: Deploying a model can be done in many ways, depending on the use case and data
    availability. For example, deployment may look like packaging a model in a container
    and deploying it on an endpoint or model that runs daily in a production workflow
    to provide predictions in tables that can be consumed by applications. Databricks
    has product features to pave the way to production for all inference types.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的部署方式有很多种，这取决于用例和数据可用性。例如，部署可能看起来像是将模型打包到容器中，并在端点或生产工作流程中每天运行的模型上部署，以提供可以被应用程序消费的表格预测。Databricks提供了产品功能，为所有推理类型铺平通往生产的道路。
- en: Model Inference
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型推理
- en: 'We’ve walked through the methods and tools that help you set up your model
    in production, and finally, you have a model ready for inference! But one key
    question you should consider as part of this process is how your model should
    be used. Do you need the results once a day? Is the model powering an application
    that requires real-time results? Your model’s purpose will help you decide the
    type of deployment you need. You’ve seen the words “batch” and “streaming” a few
    times in this chapter already, so let’s quickly define what those mean in the
    context of model inference:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了帮助您在生产中设置模型的方法和工具，最终，您有一个准备进行推理的模型！但在这个过程中，您应该考虑的一个关键问题是您的模型应该如何使用。您是否每天需要结果一次？模型是否为需要实时结果的应用程序提供动力？您模型的目的将帮助您决定所需的部署类型。您在本章中已经几次看到了“批量”和“流式”这两个词，所以让我们快速定义在模型推理的上下文中这些词的含义：
- en: '**Batch inference**: Batch inference (also known as offline inference) refers
    to a job that generates predictions on a group (or “batch”) of data all at once.
    Batch jobs are scheduled to run on a specified cadence, such as once a day. This
    type of inference is best when there are no/low-latency requirements and allows
    you to take advantage of scalable compute resources.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量推理**：批量推理（也称为离线推理）指的是一次性对一组（或“批量”）数据生成预测的工作。批量作业被安排在指定的周期上运行，例如每天一次。当没有/低延迟要求时，这种推理类型最佳，并且允许你利用可扩展的计算资源。'
- en: '**Streaming inference**: Streaming inference (also known as online inference)
    refers to a job that generates predictions on data as it is streamed. This is
    possible in the Databricks platform via Delta Live Tables.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流式推理**：流式推理（也称为在线推理）指的是在数据流式传输时生成预测的工作。在 Databricks 平台上，这可以通过 Delta Live
    Tables 实现。'
- en: '**Real-time inference**: Real-time inference (also known as model serving)
    refers to the process of exposing your models as REST API endpoints. This enables
    universally available, low-latency predictions and is especially useful when deploying
    models that generate predictions required by real-time applications.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时推理**：实时推理（也称为模型服务）指的是将你的模型作为 REST API 端点公开的过程。这可以实现低延迟的、普遍可用的预测，当部署需要实时应用程序的预测模型时特别有用。'
- en: All these options are available via the Databricks UI. Let’s use the Favorita
    Store example again. Perhaps we’ve met with our beverages business team, and they
    would like to see weekly forecasts to help decide how much of each product they
    should purchase. We will opt for batch inference since we only need to produce
    an updated forecast once a week. It just takes a few clicks to set up a model
    for batch processing. Follow the *Applying our learning* section of the Favorita
    Sales dataset for detailed instructions on deploying your model for batch inference.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些选项都可通过 Databricks UI 获取。让我们再次使用 Favorita Store 示例。也许我们已经遇到了我们的饮料业务团队，他们希望看到每周的预测以帮助他们决定应该购买每种产品的数量。我们将选择批量推理，因为我们只需要每周生成一次更新的预测。只需几步点击即可设置用于批量处理的模型。有关部署模型进行批量推理的详细说明，请参考
    Favorita 销售数据集的“应用我们的学习”部分。
- en: Model serving
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型服务
- en: Let’s dive deeper into real-time inference or **model serving**. The process
    of model serving can be complex and costly, involving additional tools and systems
    to achieve real-time needs. Fortunately, deploying a registered model as an endpoint
    only takes a single click from the Databricks platform! Because model serving
    is tightly integrated with MLflow, the path from development to production is
    much faster. Using a model registered in the MLflow Model Registry, Databricks
    automatically prepares a production-ready container and deploys the container
    to serverless compute.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地探讨实时推理或**模型服务**。模型服务的流程可能很复杂且成本高昂，需要额外的工具和系统来满足实时需求。幸运的是，从 Databricks
    平台部署已注册的模型作为端点只需单击一次！因为模型服务与 MLflow 紧密集成，从开发到生产的路径要快得多。使用 MLflow 模型注册表中注册的模型，Databricks
    自动准备一个生产就绪的容器并将容器部署到无服务器计算。
- en: 'It’s also easy to deploy models via API, as shown here. A forecasting problem
    doesn’t make much sense as a model serving use case, so let’s consider instead
    the MIC problem we’ve been working on throughout this book. We will use model
    serving to serve our classification model in real time. The following example
    code snippet creates an endpoint that serves a version of a model named `asl_model`:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 API 部署模型也很容易，如这里所示。预测问题作为模型服务用例没有太多意义，所以让我们考虑一下我们在这本书中一直在工作的 MIC 问题。我们将使用模型服务在实时中提供我们的分类模型。以下示例代码片段创建了一个端点，该端点提供名为
    `asl_model` 的模型版本：
- en: "![Figure 7.4 – Deploying a mo\uFEFFdel through a serving endpoint](img/B16865_07_04.jpg)"
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.4 – 通过服务端点部署模型](img/B16865_07_04.jpg)'
- en: Figure 7.4 – Deploying a model through a serving endpoint
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4 – 通过服务端点部署模型
- en: 'Model serving lets you build workflows around model endpoints, which provides
    plenty of flexibility in terms of model deployment. For example, an organization
    may want to A/B test two or more models. Model serving makes it easy to deploy
    multiple models behind the same endpoint and distribute traffic among them. In
    another pattern, you can deploy the same model behind multiple endpoints. The
    following is an example of the UI and the analysis you can perform when A/B testing
    models:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 模型服务让您能够围绕模型端点构建工作流程，这为模型部署提供了充分的灵活性。例如，一个组织可能想要对两个或更多模型进行A/B测试。模型服务使得在相同端点后面部署多个模型并分配流量变得容易。在另一种模式中，您可以在多个端点后面部署相同的模型。以下是在进行A/B测试模型时可以执行的UI和分析示例：
- en: '![Figure 7.5 – Model serving gives us the flexibility to A/B test models deployed
    behind the same endpoint](img/B16865_07_05.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图7.5 – 模型服务为我们提供了在相同端点部署的模型进行A/B测试的灵活性](img/B16865_07_05.jpg)'
- en: Figure 7.5 – Model serving gives us the flexibility to A/B test models deployed
    behind the same endpoint
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 – 模型服务为我们提供了在相同端点部署的模型进行A/B测试的灵活性
- en: Get ready to follow along in your own Databricks workspace as we review the
    [*Chapter 7*](B16865_07.xhtml#_idTextAnchor325) code project by project.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 准备在您的Databricks工作区中跟随我们逐个项目地回顾 [*第7章*](B16865_07.xhtml#_idTextAnchor325) 的代码项目。
- en: Applying our learning
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用我们的学习
- en: Let’s use what we have learned to productionalize our models.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运用我们所学的知识来将我们的模型投入生产。
- en: Technical requirements
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'Here are the technical requirements needed to complete the hands-on examples
    in this chapter:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是需要完成本章动手示例所需的技术要求：
- en: On-demand features require the use of DBR ML 13.1 or higher.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按需功能需要使用 DBR ML 13.1 或更高版本。
- en: RAG and CV parts require DBR ML 14.2 and higher.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG和CV部分需要DBR ML 14.2和更高版本。
- en: Python UDFs are created and governed in UC; hence, Unity Catalog must be enabled
    for the workspace – no shared clusters.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python UDFs在UC中创建和管理；因此，Unity Catalog必须在工作区中启用 – 没有共享集群。
- en: The Streaming Transactions project uses `scikit-learn==1.4.0rc1`. The notebooks
    that need it install it.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流式事务项目使用 `scikit-learn==1.4.0rc1`。需要它的笔记本会进行安装。
- en: 'The Streaming Transactions project, again, performs better with parallel compute.
    We’ll use the multi-node cluster from [*Chapter 5*](B16865_05.xhtml#_idTextAnchor244).
    See *Figure 7**.6* for the multi-node CPU configuration:'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流式事务项目，再次证明，使用并行计算表现更佳。我们将使用来自 [*第5章*](B16865_05.xhtml#_idTextAnchor244) 的多节点集群。参见
    *图7**.6 中的多节点 CPU 配置：
- en: "![Figure 7.6 – Multi-node CPU c\uFEFFluster configuration (on AWS)](img/B16865_07_06.jpg)"
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图7.6 – 多节点CPU集群配置（在AWS上）](img/B16865_07_06.jpg)'
- en: Figure 7.6 – Multi-node CPU cluster configuration (on AWS)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 – 多节点CPU集群配置（在AWS上）
- en: Project – Favorita Sales forecasting
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 项目 – Favorita 销售预测
- en: 'In this chapter, we discussed using managed MLflow and the UC Model Registry
    to register and prepare models for deployment. We’ll start by walking through
    the UI, so please open the following notebooks and a tab within the Experiments
    UI page:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了使用托管MLflow和UC模型注册表来注册和准备模型以供部署。我们将首先通过UI进行操作，因此请打开以下笔记本和实验UI页面中的标签：
- en: '`CH7-01-Registering` `the Model`'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-01-Registering` `the Model`'
- en: '`CH7-02-Batch Inference`'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-02-Batch Inference`'
- en: 'As a reminder, in [*Chapter 6*](B16865_06.xhtml#_idTextAnchor297), we ran experiments
    to find a baseline model, and you can review those experiments from the Experiments
    UI page in Databricks. To follow along in your workspace, please open the Experiments
    UI page from [*Chapter 6*](B16865_06.xhtml#_idTextAnchor297), as shown in *Figure
    7**.7*:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，在 [*第6章*](B16865_06.xhtml#_idTextAnchor297) 中，我们进行了实验以找到基线模型，您可以从Databricks的实验UI页面中回顾这些实验。为了在您的空间中跟随，请打开来自
    [*第6章*](B16865_06.xhtml#_idTextAnchor297) 的实验UI页面，如图 *图7**.7 所示：
- en: "![Figure 7.7 – The Experiments UI page for \uFEFFexploring the experiment runs](img/B16865_07_07.jpg)"
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图7.7 – 探索实验运行的实验UI页面](img/B16865_07_07.jpg)'
- en: Figure 7.7 – The Experiments UI page for exploring the experiment runs
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 – 探索实验运行的实验UI页面
- en: 'For the sake of the project, we will move forward as though the best baseline
    model is the model we want in production. To productionalize the model, follow
    these steps:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了项目的目的，我们将继续前进，好像最好的基线模型就是我们想要的在生产中的模型。要将模型投入生产，请按照以下步骤操作：
- en: 'On the AutoML experiment page, click on the best run (the run at the top when
    sorting by the evaluation metric in descending order). This will open the run
    details page. As shown in *Figure 7**.8*, there are four tabs – **Overview**,
    **Model metrics**, **System metrics**, and **Artifacts**:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AutoML实验页面上，点击最佳运行（按评估指标降序排列时位于顶部的运行）。这将打开运行详情页面。如图7.8所示，有四个选项卡 – **概述**、**模型指标**、**系统指标**和**工件**：
- en: '![Figure 7.8 – Exploring the model details page](img/B16865_07_08.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图7.8 – 探索模型详情页面](img/B16865_07_08.jpg)'
- en: Figure 7.8 – Exploring the model details page
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 – 探索模型详情页面
- en: 'Click `CH7-01-Registering the Model` notebook. When running the notebook in
    your workspace, you must update the `runs:/` URL in the notebook before executing
    it:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`CH7-01-注册模型`笔记本。在您的工作区中运行笔记本之前，必须更新笔记本中的`runs:/` URL：
- en: "![Figure \uFEFF7.9 – Registering a new model](img/B16865_07_09.jpg)"
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图7.9 – 注册新模型](img/B16865_07_09.jpg)'
- en: Figure 7.9 – Registering a new model
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9 – 注册新模型
- en: While still in your notebook, execute the final cell a second time. This creates
    a second version of the same model.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的笔记本中，执行最后一个单元格第二次。这将创建相同模型的第二个版本。
- en: 'Navigate to the `favorita_forecasting` database in Unity Catalog. Selecting
    the **Models** tab opens a new UI, as shown in *Figure 7**.10*:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到Unity Catalog中的`favorita_forecasting`数据库。选择**模型**选项卡将打开一个新的UI，如图7.10所示：
- en: '![Figure 7.10 – Viewing the model in Unity Catalog](img/B16865_07_10.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图7.10 – 在Unity Catalog中查看模型](img/B16865_07_10.jpg)'
- en: Figure 7.10 – Viewing the model in Unity Catalog
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10 – 在Unity Catalog中查看模型
- en: 'Select the forecasting model. You’ll notice that we have two versions of the
    model. Add an alias to each: **champion** and **challenger** are common to indicate
    the current best model and the newer version being considered to replace the current
    best model:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择预测模型。您会注意到我们有两个模型版本。为每个版本添加一个别名：**champion**和**challenger**是常见的，用来表示当前最佳模型和正在考虑替换当前最佳模型的新版本：
- en: '![Figure 7.11 – Assigning aliases to identify model status](img/B16865_07_11.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图7.11 – 分配别名以识别模型状态](img/B16865_07_11.jpg)'
- en: Figure 7.11 – Assigning aliases to identify model status
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.11 – 分配别名以识别模型状态
- en: Now, it’s time to think about how we want to deploy this model. Since this is
    a sales forecasting use case that’s predicting 10+ days in advance, real-time
    inference doesn’t make the most sense.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候考虑我们想要如何部署这个模型了。由于这是一个预测10+天前的销售预测用例，实时推理并不最合理。
- en: 'Open `CH7-02-Batch Inference` to run inference on the test set. Notice that
    in *Figure 7**.12*, we define `model_uri` using the alias rather than the model
    version number:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`CH7-02-Batch Inference`以在测试集上运行推理。注意在*图7.12*中，我们使用别名而不是模型版本号来定义`model_uri`：
- en: '![Figure 7.12 – Batch forecasting on the test set using the Champion model](img/B16865_07_12.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图7.12 – 使用Champion模型在测试集上进行批量预测](img/B16865_07_12.jpg)'
- en: Figure 7.12 – Batch forecasting on the test set using the Champion model
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.12 – 使用Champion模型在测试集上进行批量预测
- en: This inference code will always run inference on the data provided using the
    Champion model. If we later determine that an updated version is better, we can
    change the model alias and run the correct model without making any code changes
    to the inference code.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此推理代码将始终使用Champion模型对提供的数据进行推理。如果我们后来确定更新版本更好，我们可以更改模型别名并运行正确的模型，而无需对推理代码进行任何代码更改。
- en: The next practical step is to set up a workflow on a schedule. Please refer
    to the streaming project to see this demonstrated. This wraps up the end of this
    project. In [*Chapter 8*](B16865_08.xhtml#_idTextAnchor384), we will use the Favorita
    Sales data to show how easily a SQLbot can be created using the Foundational Model
    API.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个实际步骤是在计划中设置工作流程。请参考流式项目以查看演示。这标志着本项目的结束。在[*第8章*](B16865_08.xhtml#_idTextAnchor384)中，我们将使用Favorita销售数据来展示如何使用Foundational
    Model API轻松创建SQLbot。
- en: Project – Streaming Transactions
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 项目 – 流式事务
- en: 'We have much to do to wrap up the Streaming Transactions project! We will build
    our model, wrap it, validate it, and implement batch inference. To accomplish
    this, we’ll begin ingesting the labels into a different table. This allows us
    to set up the inference table and merge the actual labels after the predictions
    happen. We will create two workflows: *Production Streaming Transactions* and
    *Production Batch Inference and* *Model Retraining*.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有很多事情要做来完成流式事务项目！我们将构建我们的模型，封装它，验证它，并实现批量推理。为了完成这项任务，我们将开始将标签摄入到不同的表中。这允许我们在预测发生后设置推理表并合并实际标签。我们将创建两个工作流程：*生产流式事务*和*生产批量推理与*
    *模型重训练*。
- en: As with any project, we must refine the previously written code as we work toward
    production. The notebooks that look familiar from earlier in this book may have
    some minor updates, but most of the code remains unchanged.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何项目一样，我们必须在生产过程中对之前编写的代码进行细化。这本书早期部分看起来熟悉的笔记本可能有一些小的更新，但大部分代码保持不变。
- en: 'Before we jump in, let’s remember where we are and where we are going by taking
    a quick look at the project pipeline:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入之前，让我们通过快速查看项目流程来记住我们现在在哪里以及我们要去哪里：
- en: '![Figure 7.13 – The project pipeline for the Production Streaming Transactions
    project](img/B16865_07_13.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图7.13 – 生产流式事务项目的项目流程](img/B16865_07_13.jpg)'
- en: Figure 7.13 – The project pipeline for the Production Streaming Transactions
    project
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.13 – 生产流式事务项目的项目流程
- en: 'To follow along in your workspace, please open the following notebooks:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的工作区中跟随，请打开以下笔记本：
- en: '`CH7-01-Generating Records`'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-01-生成记录`'
- en: '`CH7-02-Auto Loader`'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-02-自动加载器`'
- en: '`CH7-03-Feature` `Engineering Streams`'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-03-特征工程流`'
- en: '`CH7-04-Update Maximum Price` `Feature Table`'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-04-更新最大价格` `特征表`'
- en: '`CH7-05-Wrapping and Logging the` `Baseline Model`'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-05-封装和记录` `基线模型`'
- en: '`CH7-06-Wrapping and Logging the` `Production Model`'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-06-封装和记录` `生产模型`'
- en: '`CH7-07-Model Validation`'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-07-模型验证`'
- en: '`CH7-08-Batch Inference`'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-08-批量推理`'
- en: '`CH7-09-Production` `Batch Inference`'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-09-生产` `批量推理`'
- en: '`CH7-10-Auto` `Label Loader`'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-10-自动` `标签加载器`'
- en: '`mlia_utils/transactions_funcs.py`'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlia_utils/transactions_funcs.py`'
- en: '`production_streams.yaml`'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`production_streams.yaml`'
- en: '`model_retraining_n_inference_workflow.yaml`'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_retraining_n_inference_workflow.yaml`'
- en: 'We recommend using a multi-node CPU cluster for this project. The first four
    notebooks (`CH7-01` through `CH7-04`) are nearly identical to their previous versions
    in [*Chapter 6*](B16865_06.xhtml#_idTextAnchor297), but the [*Chapter 7*](B16865_07.xhtml#_idTextAnchor325)
    versions all point to the production rather than the development catalog. Table
    names are parameterized in widgets so that they can be set in workflows. Here
    is a list of the essential notebook-specific changes that have been made to the
    first four notebooks:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议使用多节点CPU集群来完成这个项目。前四个笔记本（`CH7-01`到`CH7-04`）几乎与它们之前的版本在[*第6章*](B16865_06.xhtml#_idTextAnchor297)中相同，但[*第7章*](B16865_07.xhtml#_idTextAnchor325)的版本都指向生产目录而不是开发目录。表名在控件中参数化，以便可以在工作流程中设置。以下是已对前四个笔记本所做的关键笔记本特定更改列表：
- en: '`CH7-01-Generating Records`: Labels and transactions are now being written
    to separate folders. The data generation components have also been moved to the
    `transactions_funcs` file in the `utils` folder.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-01-生成记录`：标签和事务现在被写入不同的文件夹。数据生成组件也已移动到`utils`文件夹中的`transactions_funcs`文件。'
- en: '`CH7-02-Auto Loader`: The label column is no longer being added to the transactions
    table. For production, we ensure that the table being written to has `delta.enableChangeDataFeed
    = true` before the stream starts. If the table property is set after the stream
    starts, the stream is interrupted and will require a restart. Lastly, if the table
    property is never set, Lakehouse Monitoring is negatively impacted and will not
    support continuous monitoring.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-02-自动加载器`：标签列不再被添加到事务表中。对于生产，我们在流开始之前确保写入的表具有`delta.enableChangeDataFeed
    = true`属性。如果在流开始后设置表属性，则流会被中断并需要重启。最后，如果表属性从未设置，Lakehouse监控将受到负面影响，将不支持连续监控。'
- en: '`CH7-03-Feature Engineering Streams`: Similar to the `CH7-02-Pipeline Auto
    Loader` notebook, table properties are set before any data is written.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-03-特征工程流`：与`CH7-02-管道自动加载器`笔记本类似，在写入任何数据之前设置表属性。'
- en: '`CH7-04-Update Maximum Price Feature Table`: The code is cleaned up for a step
    toward production. Specifically, the feature table is updated rather than created
    once it exists.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-04-更新最大价格特征表`：代码已清理，以迈向生产。具体来说，一旦存在，特征表就会更新而不是创建。'
- en: 'You will need transaction data in the production catalog to create the model.
    Note the new setup variable, `$env=prod`. The pipeline workflow notebooks – that
    is, `CH7-01`, `CH7-02`, and `CH7-03` – are ready to be added to a workflow in
    the jobs section of Databricks. Start by clicking the `production_streams.yaml`,
    to guide you. Note that in the YAML file and *Figure 7**.14*, the tasks do not
    depend on one another:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要生产目录中的交易数据来创建模型。注意新的设置变量`$env=prod`。管道工作流程笔记本——即`CH7-01`、`CH7-02`和`CH7-03`——已准备好添加到Databricks作业部分的流程中。首先点击`production_streams.yaml`，以引导您。请注意，在YAML文件和[*图7**.14*]中，任务之间没有依赖关系：
- en: '![Figure 7.14 – The task DAG (left) and some settings (right) for the Production
    Streaming Transactions job](img/B16865_07_14.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图7.14 – 生产流式事务作业的任务DAG（左）和一些设置（右）](img/B16865_07_14.jpg)'
- en: Figure 7.14 – The task DAG (left) and some settings (right) for the Production
    Streaming Transactions job
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.14 – 生产流式事务作业的任务DAG（左）和一些设置（右）
- en: As shown in *Figure 7**.14*, you can use the compute cluster shown in *Figure
    7**.6* for the job and the other notebooks. Also, we chose to add parameters at
    the job level rather than the individual tasks. You can now easily generate the
    data needed to build the model.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如[*图7**.14*]所示，您可以使用[*图7**.6*]中显示的计算集群来完成作业和其他笔记本。我们还选择在作业级别而不是单个任务级别添加参数。现在您可以轻松生成构建模型所需的数据。
- en: We will use `training_set`, which we created in [*Chapter 6*](B16865_06.xhtml#_idTextAnchor297),
    to train an updated version of the model. Recall that logging a model in Unity
    Catalog packages the feature metadata with the model. Hence, at inference time,
    it automatically looks up features from feature tables provided in the specified
    training set. We added this spec to the `CH7-05-Wrapping and Logging the Baseline
    Model` and `CH7-06-Wrapping and Logging the Production Model` notebooks. We will
    not go through these notebooks separately. The difference between them is that
    the baseline model is trained on data in the development catalog. Then, the model
    is re-trained in production using production data from the inference table.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用在[*第6章*](B16865_06.xhtml#_idTextAnchor297)中创建的`training_set`来训练模型的更新版本。回想一下，在Unity
    Catalog中记录模型会将特征元数据与模型打包。因此，在推理时，它会自动从指定训练集中提供的特征表中查找特征。我们将此规范添加到了`CH7-05-包装和记录基线模型`和`CH7-06-包装和记录生产模型`笔记本中。我们不会单独介绍这些笔记本。它们之间的区别在于，基线模型是在开发目录中的数据上训练的。然后，使用推理表中的生产数据在生产环境中重新训练模型。
- en: 'We know that we don’t have an inference table yet. Don’t worry – it’s coming!
    Going back to `training_set`, being able to match up the features is only useful
    if we have feature values. We use the time boundaries of our feature table to
    ensure that the raw transactions being used for training have feature values.
    Also, we require the label column to be present, as shown in *Figure 7**.15*:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道我们还没有推理表。不用担心——它即将到来！回到`training_set`，能够匹配特征只有在我们有特征值时才有用。我们使用特征表的时间边界来确保用于训练的原始交易具有特征值。此外，我们要求存在标签列，如[*图7**.15*]所示：
- en: '![Figure 7.15 – Defining the feature lookups for the inference model](img/B16865_07_15.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图7.15 – 定义推理模型的特征查找](img/B16865_07_15.jpg)'
- en: Figure 7.15 – Defining the feature lookups for the inference model
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.15 – 定义推理模型的特征查找
- en: 'The transactions shown in *Figure 7**.15* come from the inference table, `packaged_transaction_model_predictions`,
    which was created in `CH7-08-Batch Inference`. The baseline model does something
    similar with the `raw_transactions` table. The baseline model also sets the model
    description, as shown in *Figure 7**.16*:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[*图7**.15*]中显示的交易来自推理表`packaged_transaction_model_predictions`，该表是在`CH7-08-批量推理`中创建的。基线模型使用`raw_transactions`表做类似的事情。基线模型还设置了模型描述，如[*图7**.16*]所示：'
- en: '![Figure 7.16 – Setting the model description](img/B16865_07_16.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图7.16 – 设置模型描述](img/B16865_07_16.jpg)'
- en: Figure 7.16 – Setting the model description
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.16 – 设置模型描述
- en: 'We are now ready to focus on the model. Let’s walk through the rest of the
    process:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以专注于模型了。让我们继续介绍剩余的过程：
- en: Set the model registry to Unity Catalog with `mlflow.set_registry_uri("databricks-uc")`.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型注册设置为Unity Catalog，使用`mlflow.set_registry_uri("databricks-uc")`。
- en: Use `pip` to save a `requirements.txt` file.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pip` 保存一个 `requirements.txt` 文件。
- en: Create a PyFunc wrapper for `TransactionModelWrapper`.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 `TransactionModelWrapper` 创建一个 PyFunc 包装器。
- en: 'Most of the code for `TransactionModelWrapper` should look familiar to those
    who have created a model using Sklearn. The initialization function, `__init__(self,
    model, X, y, numeric_columns, cat_columns)`, accepts a model and DataFrames. The
    data preprocessing for training and inference data is standardized within the
    wrapper. `TransactionModelWrapper` consists of four methods: `init`, `predict`,
    `preprocess_data`, and `fit`.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些使用 Sklearn 创建过模型的人来说，`TransactionModelWrapper` 的大部分代码应该看起来很熟悉。初始化函数 `__init__(self,
    model, X, y, numeric_columns, cat_columns)` 接受一个模型和 DataFrame。训练数据和推理数据的数据预处理在包装器内部标准化。`TransactionModelWrapper`
    由四个方法组成：`init`、`predict`、`preprocess_data` 和 `fit`。
- en: 'The initialization method does the following:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化方法执行以下操作：
- en: Splits the data into train and test sets.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为训练集和测试集。
- en: Initializes and fits `OneHotEncoder` for the categorical feature columns provided.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化并拟合 `OneHotEncoder` 以处理提供的分类特征列。
- en: Initializes and fits `StandardScaler` for the numerical feature columns provided.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化并拟合 `StandardScaler` 以处理提供的数值特征列。
- en: Applies the `preprocess_data` method to the training and test data.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `preprocess_data` 方法应用于训练数据和测试数据。
- en: Defines an `evaluation` method to calculate the log loss on the *X* and *y*
    sets provided.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个 `evaluation` 方法来计算提供的 *X* 和 *y* 集合上的对数损失。
- en: Invokes the `evaluation` method on preprocessed test data.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在预处理后的测试数据上调用 `evaluation` 方法。
- en: Defines and invokes the `_model_signature` method to easily provide the signature
    when logging the model.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义并调用 `_model_signature` 方法，以便在记录模型时轻松提供签名。
- en: 'The `predict` method calls the `preprocess_data` (*Figure 7**.17)* method on
    the input DataFrame before performing and returning the prediction. This method
    is used to process the training data and the inference data, ensuring identical
    preprocessing for predictions:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict` 方法在执行并返回预测之前，在输入 DataFrame 上调用 `preprocess_data` (*图 7.17)* 方法。此方法用于处理训练数据和推理数据，确保预测的预处理相同：'
- en: '![Figure 7.17 – The preprocessing method for the model](img/B16865_07_17.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.17 – 模型的预处理方法](img/B16865_07_17.jpg)'
- en: Figure 7.17 – The preprocessing method for the model
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.17 – 模型的预处理方法
- en: As shown in *Figure 7**.17*, the fitted numeric scaler and one-hot encoder are
    passed as input. This protects against skew between the training and inference
    features. Notice how `TransactionTimestamp` is dropped. This is done because after
    the features from the feature tables are present, we no longer need a timestamp.
    The input DataFrame can be a Spark or pandas DataFrame. This is why we need different
    syntax to drop the timestamp column.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 7.17* 所示，拟合的数值缩放器和单热编码器作为输入传递。这可以防止训练和推理特征之间的偏斜。注意 `TransactionTimestamp`
    是如何被删除的。这是因为特征表中的特征存在之后，我们不再需要一个时间戳。输入 DataFrame 可以是 Spark 或 pandas DataFrame。这就是为什么我们需要不同的语法来删除时间戳列。
- en: In the following command cell, you customize `mlflow.autolog` and start the
    MLflow experiment for training, testing, wrapping, and logging the model. You
    will use `mlflow.evaluate` to handle the evaluation process. The logging process
    is easy – you call `log_model` with the model name, wrapped model, `pyfunc` flavor,
    and previously created training set. This process also registers the model in
    Unity Catalog. The last thing in this notebook is a quick test that’s performed
    on the predict function showing how to pass in the Spark context with the input
    data. You are now ready to validate the model.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的命令单元格中，您自定义 `mlflow.autolog` 并开始 MLflow 实验以进行训练、测试、包装和记录模型。您将使用 `mlflow.evaluate`
    来处理评估过程。记录过程很简单 – 您只需调用 `log_model` 并传入模型名称、包装模型、`pyfunc` 风味和先前创建的训练集。此过程还将模型注册到
    Unity 目录中。这个笔记本的最后一件事是对预测函数进行快速测试，展示如何传递 Spark 上下文和输入数据。现在，您已经准备好验证模型。
- en: Next, focus on the `CH7-07-Model Validation` notebook, which checks that the
    input model has the correct metadata so that it’s ready for production. This notebook
    can be used to test any model. Ideally, you will add numerous checks, including
    the ability to predict and possibly test the accuracy of specific slices of data.
    For example, you could check the model performance on each product or geography.
    You can pass those columns with tags when slices need testing.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，关注`CH7-07-Model Validation`笔记本，该笔记本检查输入模型是否具有正确的元数据，以便其可以用于生产。此笔记本可以用于测试任何模型。理想情况下，您将添加许多检查，包括预测特定数据切片的能力以及测试其准确性的可能性。例如，您可以检查每个产品或地理区域的模型性能。当需要测试切片时，您可以通过标签传递这些列。
- en: 'Collect the model details, as shown in *Figure 7**.18*. Notice the use of the
    `util` function, which is imported in a previous cell from `mlia_utils.mlflow_funcs`
    `import get_latest_model_version`:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 收集模型详细信息，如图*图7.18*所示。注意`util`函数的使用，该函数是从上一个单元格中导入的`mlia_utils.mlflow_funcs`
    `import get_latest_model_version`：
- en: '![Figure 7.18 – Using the mlfclient and util functions to access the model
    details](img/B16865_07_18.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图7.18 – 使用mlfclient和util函数访问模型详细信息](img/B16865_07_18.jpg)'
- en: Figure 7.18 – Using the mlfclient and util functions to access the model details
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.18 – 使用mlfclient和util函数访问模型详细信息
- en: 'Each time you train and log the model, a new model version is created. Using
    tags, you can indicate which model version(s) must be tested and validated before
    deployment:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 每次训练并记录模型时，都会创建一个新的模型版本。使用标签，您可以指明哪些模型版本必须在部署前进行测试和验证：
- en: '![Figure 7.19 – Assertions to ensure the model needs to be tested](img/B16865_07_19.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图7.19 – 断言以确保模型需要被测试](img/B16865_07_19.jpg)'
- en: Figure 7.19 – Assertions to ensure the model needs to be tested
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.19 – 断言以确保模型需要被测试
- en: 'As shown in *Figure 7**.20*, you need an informative model description for
    all production models. We recommend that you include information about the use
    case the model is used for. Metadata hygiene is becoming increasingly important
    as companies want to leverage generative AI on internal data. This is because
    LLMs use the metadata fields to find relevant information in the models:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图7.20*所示，所有生产模型都需要一个信息丰富的模型描述。我们建议您包括有关模型用途的信息。随着公司希望利用内部数据上的生成式AI，元数据卫生变得越来越重要。这是因为LLMs使用元数据字段在模型中查找相关信息：
- en: '![Figure 7.20 – Validating that a model description is present](img/B16865_07_20.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图7.20 – 验证模型描述是否存在](img/B16865_07_20.jpg)'
- en: Figure 7.20 – Validating that a model description is present
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.20 – 验证模型描述是否存在
- en: 'Similar to what’s shown in *Figure 7**.20*, the notebook checks for tags. These
    are examples to get you started. This is an ideal section to expand on the current
    code and continue adding validation results and update tags:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 与*图7.20*中所示类似，笔记本会检查标签。这些是帮助您开始的示例。这是一个理想的扩展当前代码并继续添加验证结果和更新标签的部分：
- en: '![Figure 7.21 – Processing the results of the validation tests](img/B16865_07_21.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图7.21 – 处理验证测试的结果](img/B16865_07_21.jpg)'
- en: Figure 7.21 – Processing the results of the validation tests
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.21 – 处理验证测试的结果
- en: 'With a tested model, you can progress to inference; see the `CH7-08-Batch Inference`
    notebook. Review the examples of performing batch inference on a DataFrame (*Figure
    7**.22*) and a JSON data string:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 使用经过测试的模型，您可以进行推理；参见`CH7-08-Batch Inference`笔记本。回顾在DataFrame上执行批量推理的示例（*图7.22*）和JSON数据字符串：
- en: '![Figure 7.22 – Loading and scoring the model by performing batch inference
    on a DataFrame](img/B16865_07_22.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图7.22 – 通过在DataFrame上执行批量推理来加载和评分模型](img/B16865_07_22.jpg)'
- en: Figure 7.22 – Loading and scoring the model by performing batch inference on
    a DataFrame
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.22 – 通过在DataFrame上执行批量推理来加载和评分模型
- en: 'Now, look at the code in `CH7-09-Production Batch Inference`. The substantial
    changes include `scoring_df`, which is the DataFrame we apply our model to for
    predictions. Notice that in *Figure 7**.23*, the `min_time` and `max_time` variables
    provide boundaries for the transactions, ensuring the batch feature values have
    been calculated. Additionally, the inference table provides a boundary that prevents
    duplicate prediction calculations:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，查看`CH7-09-Production Batch Inference`中的代码。主要变化包括`scoring_df`，这是我们应用模型进行预测的DataFrame。注意在*图7.23*中，`min_time`和`max_time`变量为交易提供了边界，确保批量特征值已计算。此外，推理表提供了一个边界，防止重复的预测计算：
- en: '![Figure 7.23 – The scoring_df query’s configuration](img/B16865_07_23.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图7.23 – `scoring_df`查询的配置](img/B16865_07_23.jpg)'
- en: Figure 7.23 – The scoring_df query’s configuration
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.23 – `scoring_df`查询的配置
- en: 'The inference table in `CH7-08` needs to be updated to fit the requirements
    for the inference table monitoring provided by Lakehouse Monitoring. This means
    adding the `model_version` and `actual_label` columns. The `actual_label` column
    is set to `NULL` so that it is clear the value has not been updated yet; see *Figure
    7**.24*:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '`CH7-08`中的推理表需要更新以符合Lakehouse Monitoring提供的推理表监控要求。这意味着添加`model_version`和`actual_label`列。`actual_label`列设置为`NULL`，以便清楚地表明值尚未更新；见图*7.24*：'
- en: '![Figure 7.24 – The addition of the model version and actual label columns](img/B16865_07_24.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图7.24 – 添加模型版本和实际标签列](img/B16865_07_24.jpg)'
- en: Figure 7.24 – The addition of the model version and actual label columns
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.24 – 添加模型版本和实际标签列
- en: 'These two additional columns for the inference table are requirements for Lakehouse
    Monitoring. The `InferenceLog` monitor comes with autogenerated dashboards. However,
    you need to populate the table. Begin by creating a bronze table for the transaction
    labels. The Auto Loader is back again, focusing on labels; see `CH7-10-Auto Label
    Loader` and *Figure 7**.25*. In the notebook, the `transaction_labels` table was
    created; this is similar to the code from [*Chapter 3*](B16865_03.xhtml#_idTextAnchor123).
    In *Figure 7**.25*, you can use the CDF and CDC Delta features to update the new
    inference table with the ground truth label:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个额外的推理表列是Lakehouse Monitoring的要求。`InferenceLog`监控器附带自动生成的仪表板。但是，您需要填充表格。首先创建一个用于交易标签的青铜表。自动加载器再次出现，专注于标签；见`CH7-10-Auto
    Label Loader`和图*7.25*。在笔记本中，创建了`transaction_labels`表；这与[*第3章*](B16865_03.xhtml#_idTextAnchor123)中的代码类似。在图*7.25*中，您可以使用CDF和CDC
    Delta功能将地面真实标签更新到新的推理表中：
- en: '![Figure 7.25 – Merging transaction labels into the inference table](img/B16865_07_25.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图7.25 – 将交易标签合并到推理表中](img/B16865_07_25.jpg)'
- en: Figure 7.25 – Merging transaction labels into the inference table
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.25 – 将交易标签合并到推理表中
- en: 'You now have a bronze table and the ability to merge new labels into the inference
    table. However, the inference table is still empty. So, let’s create a workflow
    job, as shown in *Figure 7**.26*, to generate predictions every 15 minutes:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您有一个青铜表和将新标签合并到推理表中的能力。然而，推理表仍然是空的。因此，让我们创建一个如图*7.26*所示的流程作业，每15分钟生成一次预测：
- en: '![Figure 7.26 – The DAG for the inference (upper) and model retraining (lower)
    job](img/B16865_07_26.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图7.26 – 推理（上方）和模型重新训练（下方）作业的DAG](img/B16865_07_26.jpg)'
- en: Figure 7.26 – The DAG for the inference (upper) and model retraining (lower)
    job
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.26 – 推理（上方）和模型重新训练（下方）作业的DAG
- en: Walk through the two workflow paths, starting with the upper path. The batch
    features are updated, thus providing feature data for inference. The data is ready
    for predictions, and the inference task can begin.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 检查这两个工作流路径，从上方的路径开始。批量特征被更新，从而为推理提供特征数据。数据已准备好进行预测，推理任务可以开始。
- en: 'As its first task, the lower path updates labels. It adds the latest data to
    the `transaction_labels` table and merges all new labels that match previous predictions
    into the inference table. Skip forward beyond the first iteration and the inference
    table contains not only previous predictions but also the labels for those predictions.
    Model training is performed using the updated table containing the features. Retraining
    the model only occurs if there is data in the inference table, as shown in *Figure
    7**.27*. The retraining process is, of course, followed by validation when needed.
    The validation notebook exits when it detects that the latest version of the model
    has already been tested:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 作为其第一个任务，下方的路径更新标签。它将最新数据添加到`transaction_labels`表中，并将所有与先前预测匹配的新标签合并到推理表中。跳过第一次迭代之后，推理表不仅包含先前预测，还包括这些预测的标签。使用包含特征的更新表进行模型训练。只有在推理表中存在数据时，才会重新训练模型，如图*7.27*所示。当然，在需要时，重新训练过程之后会进行验证。当验证笔记本检测到最新版本的模型已经过测试时，它将退出：
- en: '![Figure 7.27 – The retraining notebook exits if there is no data to retrain
    on](img/B16865_07_27.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图7.27 – 如果没有数据重新训练，则重新训练笔记本退出](img/B16865_07_27.jpg)'
- en: Figure 7.27 – The retraining notebook exits if there is no data to retrain on
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.27 – 如果没有数据重新训练，则重新训练笔记本退出
- en: 'Create the workflow job shown in *Figure 7**.29*. You can reference the configuration
    for the job in the `model_retraining_n_inference_workflow.yaml` file. The workflow
    automatically provides the lineage of all upstream and downstream tables. You
    can see these in *Figure 7**.26*. This saves us time on documentation:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 创建如图 *7.29* 所示的工作流程作业。你可以参考`model_retraining_n_inference_workflow.yaml`文件中的作业配置。工作流程自动提供所有上游和下游表的血缘关系。你可以在
    *图 7.26* 中看到这些。这节省了我们在文档上的时间：
- en: '![Figure 7.28 – The workflow table lineage](img/B16865_07_28.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.28 – 工作流程表血缘关系](img/B16865_07_28.jpg)'
- en: Figure 7.28 – The workflow table lineage
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.28 – 工作流程表血缘关系
- en: 'All that is left is to run both workflows simultaneously. After letting both
    run for a bit (don’t forget to schedule the Production Batch Inference and Model
    Retraining workflow), you should have a screen that looks similar to what’s shown
    in *Figure 7**.29*:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的只是同时运行两个工作流程。在运行一段时间后（别忘了安排生产批量推理和工作流程模型重训练），你应该会有一个类似于 *图 7.29* 所示的屏幕：
- en: '![Figure 7.29 –  The historical view of successful job runs](img/B16865_07_29.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.29 – 成功作业运行的历史视图](img/B16865_07_29.jpg)'
- en: Figure 7.29 – The historical view of successful job runs
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.29 – 成功作业运行的历史视图
- en: You now have all of the pieces to productionize this project.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在拥有了将此项目投入生产的所有部件。
- en: Project – multilabel image classification
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 项目 – 多标签图像分类
- en: 'We currently have a working image classification model that we trained and
    evaluated in [*Chapter 6*](B16865_06.xhtml#_idTextAnchor297). Now, let’s add some
    infrastructure around our code to serve our model and make it available to downstream
    applications and, ultimately, our end users. To follow along in your workspace,
    please open the following notebooks:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们目前有一个工作图像分类模型，我们在[*第 6 章*](B16865_06.xhtml#_idTextAnchor297)中对其进行了训练和评估。现在，让我们在我们的代码周围添加一些基础设施来提供服务我们的模型，使其可供下游应用程序和最终用户使用。为了在你的工作区中跟随，请打开以下笔记本：
- en: '`Ch7-01-Create_Final_Wrapper_Production`'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Ch7-01-Create_Final_Wrapper_Production`'
- en: '`Ch7-02-Serve_In_Production`'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Ch7-02-Serve_In_Production`'
- en: 'We’ll start by creating our model class wrapper. This wrapper includes two
    functions, `feature_extractor` and `predict`. The `feature_extractor` function
    is required because otherwise, our fine-tuned model won’t contain the same preprocessing
    step that’s used during fine-tuning and would, therefore, not be consistent during
    serving. Of course, you can simply serve your original model if you do not need
    to make any custom modifications to your model and only need the raw format outputs:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先创建我们的模型类包装器。这个包装器包括两个函数，`feature_extractor` 和 `predict`。`feature_extractor`
    函数是必需的，因为否则我们的微调模型将不包含在微调期间使用的相同预处理步骤，因此在服务期间将不一致。当然，如果你不需要对你的模型进行任何自定义修改，并且只需要原始格式输出，你可以简单地提供服务你的原始模型：
- en: '![Figure 7.30 – Creating the model class wrapper](img/B16865_07_30.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.30 – 创建模型类包装器](img/B16865_07_30.jpg)'
- en: Figure 7.30 – Creating the model class wrapper
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.30 – 创建模型类包装器
- en: The `feature_extractor` function, which transforms an image into the format
    required by the served model, is the same code we used to score the model in [*Chapter
    6*](B16865_06.xhtml#_idTextAnchor297). Let’s dive into the prediction part; it’s
    similar to what we created in [*Chapter 6*](B16865_06.xhtml#_idTextAnchor297)
    to score our model.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像转换为服务模型所需格式的`feature_extractor`函数，与我们用于在[*第 6 章*](B16865_06.xhtml#_idTextAnchor297)中评分模型的相同代码。让我们深入预测部分；它与我们在[*第
    6 章*](B16865_06.xhtml#_idTextAnchor297)中创建的用于评分模型的代码类似。
- en: 'The `predict` function is similar to the one we used to score our model in
    [*Chapter 6*](B16865_06.xhtml#_idTextAnchor297)using `pandas_udf`. Note that we
    are not only returning the predicted label but also a label corresponding to it
    in a dictionary format (this isn’t required, but we wanted to show the output
    format’s flexibility):'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict` 函数与我们在[*第 6 章*](B16865_06.xhtml#_idTextAnchor297)中使用 `pandas_udf`
    评分模型的函数类似。请注意，我们不仅返回预测标签，还返回一个以字典格式对应的标签（这不是必需的，但我们想展示输出格式的灵活性）：'
- en: '![Figure 7.31 – Including the feature_extractor and predict functions in the
    model class wrapper](img/B16865_07_31.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.31 – 在模型类包装器中包含 feature_extractor 和 predict 函数](img/B16865_07_31.jpg)'
- en: Figure 7.31 – Including the feature_extractor and predict functions in the model
    class wrapper
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.31 – 在模型类包装器中包含 feature_extractor 和 predict 函数
- en: 'Now, we are ready to wrap our fine-tuned model from [*Chapter 4*](B16865_04.xhtml#_idTextAnchor180)
    into the wrapper. To do this, we must load the artifact from MLflow and pass it
    to the pre-created `CVModelWrapper` class:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好将[*第 4 章*](B16865_04.xhtml#_idTextAnchor180)中微调的模型封装到包装器中。为此，我们必须从
    MLflow 加载工件并将其传递给预先创建的 `CVModelWrapper` 类：
- en: '![Figure 7.32 – Loading our model from the existing MLflow experiment](img/B16865_07_32.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.32 – 从现有的 MLflow 实验中加载我们的模型](img/B16865_07_32.jpg)'
- en: Figure 7.32 – Loading our model from the existing MLflow experiment
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.32 – 从现有的 MLflow 实验中加载我们的模型
- en: 'Let’s test whether our wrapper is functioning as expected. To do so, we must
    encode a few images (as the model serving accepts strings and cannot accept images
    and convert them yet) and save them into a pandas DataFrame. Then, we must use
    our model wrapper to get a prediction:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试我们的包装器是否按预期工作。为此，我们必须对一些图像进行编码（因为模型提供程序接受字符串，但不能接受图像并立即将它们转换），并将它们保存到一个
    pandas DataFrame 中。然后，我们必须使用我们的模型包装器来获取预测：
- en: '![Figure 7.33 – Using our model wrapper to create predictions on a few images](img/B16865_07_33.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.33 – 使用我们的模型包装器在几幅图像上创建预测](img/B16865_07_33.jpg)'
- en: Figure 7.33 – Using our model wrapper to create predictions on a few images
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.33 – 使用我们的模型包装器在几幅图像上创建预测
- en: 'Next, we will use MLflow to log and serve the model via Databricks Model Serving:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 MLflow 通过 Databricks Model Serving 记录和提供模型：
- en: '![Figure 7.34 – Logging and running models using MLflow](img/B16865_07_34.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.34 – 使用 MLflow 记录和运行模型](img/B16865_07_34.jpg)'
- en: Figure 7.34 – Logging and running models using MLflow
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.34 – 使用 MLflow 记录和运行模型
- en: 'During the production phase, you will usually operate on the aliases and the
    latest model version, so here, we’ll simulate setting the alias, Champion, to
    the best-performing model and getting the latest model version to be deployed:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产阶段，你通常会操作别名和最新模型版本，因此在这里，我们将模拟设置别名“Champion”为表现最佳的模型，并获取要部署的最新模型版本：
- en: '![Figure 7.35 – Loading our champion model](img/B16865_07_35.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.35 – 加载我们的冠军模型](img/B16865_07_35.jpg)'
- en: Figure 7.35 – Loading our champion model
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.35 – 加载我们的冠军模型
- en: 'Next, we must create our model serving endpoint using the Databricks SDK. You
    could also create your endpoint using the UI. If you decide to use the SDK, you
    must create a configuration file for your endpoint. The following example is for
    a CPU container with a small workload size. If you are unfamiliar with this option,
    please check out *Create model serving endpoints* in the *Further* *reading* section:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须使用 Databricks SDK 创建我们的模型提供程序端点。你也可以使用 UI 创建你的端点。如果你决定使用 SDK，你必须为你的端点创建一个配置文件。以下示例是一个具有小型工作负载大小的
    CPU 容器。如果你不熟悉此选项，请参阅 *进一步阅读* 部分的 *创建模型提供程序端点*：
- en: '![Figure 7.36 – Setting config input for the endpoint to serve our model](img/B16865_07_36.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.36 – 为端点设置配置输入以提供我们的模型](img/B16865_07_36.jpg)'
- en: Figure 7.36 – Setting config input for the endpoint to serve our model
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.36 – 为端点设置配置输入以提供我们的模型
- en: 'Once the settings have been provided, you are ready to deploy or update your
    endpoint if it already exists:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提供了设置，你就可以部署或更新你的端点，如果它已经存在：
- en: '![Figure 7.37 – Deploying a new endpoint if it does not exist or updating the
    existing one](img/B16865_07_37.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.37 – 如果不存在则部署新端点或更新现有端点](img/B16865_07_37.jpg)'
- en: Figure 7.37 – Deploying a new endpoint if it does not exist or updating the
    existing one
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.37 – 如果不存在则部署新端点或更新现有端点
- en: 'Keep in mind that if your endpoint does not exist, it will take a while to
    deploy:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，如果你的端点不存在，部署将需要一段时间：
- en: '![Figure 7.38 – UI example while the GPU endpoint is deploying/updating](img/B16865_07_38.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.38 – GPU 端点部署/更新时的 UI 示例](img/B16865_07_38.jpg)'
- en: Figure 7.38 – UI example while the GPU endpoint is deploying/updating
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.38 – GPU 端点部署/更新时的 UI 示例
- en: 'Now, we can score our model. Again, for simplicity and reusability, we are
    covering the serving call into a `score_model` function:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以对模型进行评分。同样，为了简单性和可重用性，我们将提供调用封装到 `score_model` 函数中：
- en: '![Figure 7.39 – Defining a model scoring function](img/B16865_07_39.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.39 – 定义模型评分函数](img/B16865_07_39.jpg)'
- en: Figure 7.39 – Defining a model scoring function
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.39 – 定义模型评分函数
- en: 'Lastly, we must score our model using our model scoring function, as shown
    in *Figure 7**.40*:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们必须使用我们的模型评分函数对模型进行评分，如图 *图 7**.40* 所示：
- en: '![Figure 7.40 – Scoring our model](img/B16865_07_40.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.40 – 评分我们的模型](img/B16865_07_40.jpg)'
- en: Figure 7.40 – Scoring our model
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.40 – 评分我们的模型
- en: 'Here is an example of scoring under the UI page:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是在 UI 页面上评分的一个示例：
- en: '![Figure 7.41 – Scoring our model under the UI page of the Databricks Model
    Serving](img/B16865_07_41.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.41 – 在 Databricks 模型服务的 UI 页面上评估我们的模型](img/B16865_07_41.jpg)'
- en: Figure 7.41 – Scoring our model under the UI page of the Databricks Model Serving
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.41 – 在 Databricks 模型服务的 UI 页面上评估我们的模型
- en: Now that our model is ready for production, we can train and create it, designate
    our champion model, serve it on an endpoint, and score. The next steps might include
    setting up a monitor to track image pixel distributions, the number of images,
    label distributions, and the distribution of the response. We will talk more about
    model monitoring in [*Chapter 8*](B16865_08.xhtml#_idTextAnchor384).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已准备好投入生产，我们可以对其进行训练和创建，指定我们的冠军模型，在端点上提供服务，并进行评分。下一步可能包括设置监控器以跟踪图像像素分布、图像数量、标签分布和响应分布。我们将在
    [*第 8 章*](B16865_08.xhtml#_idTextAnchor384) 中更多地讨论模型监控。
- en: Project – retrieval augmented generation chatbot
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 项目 - 检索增强生成聊天机器人
- en: In the previous chapter, we completed our chatbot and tested it out in a notebook.
    It might be tempting to jump to the final deployment step immediately, but that
    would involve skipping a critical step in the process – evaluation! Evaluating
    projects for correctness before providing them to the end users should always
    be part of the development process. However, it can be especially tricky to build
    automated evaluation solutions for newer technologies and techniques, such as
    when working with LLMs. This is a continually developing area of research, and
    we recommend reading Databricks’ recommendations on *Best Practices for LLM Evaluation*
    for more information (linked in *Further reading*). We’ll walk through the MLflow
    evaluation capability to evaluate the RAG chatbot we’ve built.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们完成了我们的聊天机器人，并在笔记本中进行了测试。可能有人会想立即跳到最终部署步骤，但那样会跳过过程中的一个关键步骤——评估！在将项目提供给最终用户之前，评估项目的正确性应该始终是开发过程的一部分。然而，为新技术和技巧构建自动评估解决方案可能特别棘手，例如在处理大型语言模型（LLMs）时。这是一个持续发展的研究领域，我们建议阅读
    Databricks 关于 *LLM 评估的最佳实践* 的建议以获取更多信息（见 *进一步阅读*）。我们将介绍 MLflow 评估功能，以评估我们构建的 RAG
    聊天机器人。
- en: 'To follow along in your workspace, please open the following notebooks:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的工作区中跟随，请打开以下笔记本：
- en: '`CH7-01-GetData`'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-01-GetData`'
- en: '`CH7-02-Evaluating_ChatBot`'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CH7-02-Evaluating_ChatBot`'
- en: Loading the ground truth labels
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载真实标签
- en: 'We’ll start in the first notebook, `CH7-01-GetData`. To evaluate our model,
    we must have ground truth labels – that is, the correct answers. This generally
    involves human effort to write out some typical questions you expect users to
    ask your chatbot and the answers you expect your chatbot to respond with. To simplify
    this process, we created a file containing 35 sample questions and the corresponding
    human-generated answers for this project, saved to `Questions_Evaluation.csv`.
    Let’s load this file and examine the question and answer pairs:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从第一个笔记本 `CH7-01-GetData` 开始。为了评估我们的模型，我们必须有真实标签——即正确答案。这通常涉及人力编写一些典型的您期望用户向您的聊天机器人提出的问题以及您期望聊天机器人响应的答案。为了简化此过程，我们为该项目创建了一个包含
    35 个样本问题和相应人工生成的答案的文件，并将其保存到 `Questions_Evaluation.csv`。让我们加载此文件并检查问题和答案对：
- en: '![Figure 7.42 – Reading our pre-created evaluation set](img/B16865_07_42.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.42 – 读取我们预先创建的评估集](img/B16865_07_42.jpg)'
- en: Figure 7.42 – Reading our pre-created evaluation set
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.42 – 读取我们预先创建的评估集
- en: 'Take a look at some of the records to get a sense of the questions a user might
    ask and the expected answers. You can also add your own examples to augment the
    evaluation data further:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 查看一些记录，以了解用户可能提出的问题和预期的答案。您还可以添加自己的示例来进一步扩充评估数据：
- en: '![Figure 7.43 – Question-answer pair examples](img/B16865_07_43.jpg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.43 – 问答对示例](img/B16865_07_43.jpg)'
- en: Figure 7.43 – Question-answer pair examples
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.43 – 问答对示例
- en: 'Let’s save these examples to a Delta table named `evaluation_table`. That way,
    if a new `Question_Evaluation.csv` file with different examples is uploaded, you
    can append the new examples to the existing table without risking losing the original
    data:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这些示例保存到名为 `evaluation_table` 的 Delta 表中。这样，如果上传了包含不同示例的新 `Question_Evaluation.csv`
    文件，您可以将新示例追加到现有表中，而不会丢失原始数据：
- en: '![Figure 7.44 – Creating evaluation_table to store the question/answer pairs](img/B16865_07_44.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.44 – 创建 evaluation_table 以存储问题/答案对](img/B16865_07_44.jpg)'
- en: Figure 7.44 – Creating evaluation_table to store the question/answer pairs
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.44 – 创建evaluation_table以存储问题/答案对](img/B16865_07_44.jpg)'
- en: 'Upon saving the table, we are now ready to evaluate our model:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在保存表之后，我们现在可以评估我们的模型：
- en: "![Figure 7.45 – Saving  thequestions_evaluation.csv da\uFEFFta to a Delta table](img/B16865_07_45.jpg)"
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![图7.45 – 将questions_evaluation.csv数据保存到Delta表](img/B16865_07_45.jpg)'
- en: Figure 7.45 – Saving thequestions_evaluation.csv data to a Delta table
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.45 – 将questions_evaluation.csv数据保存到Delta表
- en: Setting up the evaluation workflow
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置评估工作流程
- en: 'We’re now ready to open the second notebook, `CH7-02-Evaluating_ChatBot`, and
    evaluate our chatbot against the ground truth labels we saved to `evaluation_table`.
    Let’s briefly discuss how we will compare our model’s outputs to the human-generated
    answers. While there is plenty of ongoing research in the realm of automated LLM
    evaluation methods, we will focus on one technique in particular: *LLM-as-a-judge*.
    This method brings in a second LLM to evaluate the performance of the first, automating
    the tedious task of comparing the generated answer to the true answer, something
    a human would traditionally have to do. Follow these steps:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好打开第二个笔记本，`CH7-02-Evaluating_ChatBot`，并评估我们的聊天机器人与存储在`evaluation_table`中的地面真实标签。让我们简要讨论我们将如何比较我们模型的输出与人工生成的答案。虽然在这个自动化的LLM评估方法领域有许多正在进行的研究，但我们将专注于一种特定的技术：*LLM作为裁判*。这种方法引入第二个LLM来评估第一个LLM的性能，自动化了将生成的答案与真实答案比较的繁琐任务，这是人类传统上必须做的。按照以下步骤进行：
- en: 'To use an LLM as a judge, we must load the original model we created in [*Chapter
    6*](B16865_06.xhtml#_idTextAnchor297):'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要使用LLM作为裁判，我们必须加载我们在[*第6章*](B16865_06.xhtml#_idTextAnchor297)中创建的原始模型：
- en: '![Figure 7.46 – Loading mlaction_chatbot_model as rag_model](img/B16865_07_46.jpg)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![图7.46 – 将mlaction_chatbot_model作为rag_model加载](img/B16865_07_46.jpg)'
- en: Figure 7.46 – Loading mlaction_chatbot_model as rag_model
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.46 – 将mlaction_chatbot_model作为rag_model加载
- en: 'Now, we must run a quick test to verify that our RAG model works as expected:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们必须运行一个快速测试来验证我们的RAG模型按预期工作：
- en: '![Figure 7.47 – Verifying our loaded model works as expected](img/B16865_07_47.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![图7.47 – 验证我们加载的模型按预期工作](img/B16865_07_47.jpg)'
- en: Figure 7.47 – Verifying our loaded model works as expected
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.47 – 验证我们加载的模型按预期工作
- en: 'Next, we must use our RAG chatbot to generate answers for all of the example
    questions we stored in `evaluation_table`. These responses are what we will compare
    against the ground truth answers. We’ll build a `pandas_udf` function to make
    this part run faster:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须使用我们的RAG聊天机器人来生成所有存储在`evaluation_table`中的示例问题的答案。这些回答是我们将与之比较的地面真实答案。我们将构建一个`pandas_udf`函数来使这部分运行更快：
- en: '![Figure 7.48 – Creating a function to receive a question and return an answer
    using our RAG model](img/B16865_07_48.jpg)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![图7.48 – 创建一个函数，使用我们的RAG模型接收问题并返回答案](img/B16865_07_48.jpg)'
- en: Figure 7.48 – Creating a function to receive a question and return an answer
    using our RAG model
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.48 – 创建一个函数，使用我们的RAG模型接收问题并返回答案](img/B16865_07_48.jpg)'
- en: 'We used Llama-2-70b for our judge, but you could use GPT-4 or any other LLM
    you prefer (though we cannot guarantee satisfactory results!). Our code leverages
    the Databricks Foundational Model API, which we also used in [*Chapter 3*](B16865_03.xhtml#_idTextAnchor123)
    when creating the embeddings of ArXiv article text chunks. As a reminder, the
    Databricks Foundation Model APIs provide direct access to state-of-the-art open
    models from a serving endpoint, allowing you to incorporate high-quality generative
    AI models into your application without the need to maintain your model deployment.
    We call the Llama-2-70b endpoint in *Figure 7**.49*:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Llama-2-70b作为裁判，但您可以使用GPT-4或任何您喜欢的其他LLM（尽管我们无法保证满意的结果！）！我们的代码利用了Databricks基础模型API，我们在[*第3章*](B16865_03.xhtml#_idTextAnchor123)中创建ArXiv文章文本块嵌入时也使用了它。作为提醒，Databricks基础模型API提供了从服务端点到最先进开放模型的直接访问，允许您在不维护模型部署的情况下将高质量的生成AI模型集成到您的应用程序中。我们在*图7.49*中调用Llama-2-70b端点：
- en: '![Figure 7.49 – Testing the Foundation Model endpoint for Llama-2-70b](img/B16865_07_49.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![图7.49 – 测试Llama-2-70b的Foundation Model端点](img/B16865_07_49.jpg)'
- en: Figure 7.49 – Testing the Foundation Model endpoint for Llama-2-70b
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.49 – 测试Llama-2-70b的Foundation Model端点
- en: 'Next, we must build a DataFrame from the `evaluation_table` questions and answers.
    If you have added many more question/answer examples to this dataset, you may
    want to downsample the number of questions and speed up the prediction process.
    Then, we must call our UDF, `predict_answer`:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须从 `evaluation_table` 的问题和答案构建一个 DataFrame。如果你已经向这个数据集添加了更多的问答示例，你可能想要减少问题的数量并加快预测过程。然后，我们必须调用我们的
    UDF，`predict_answer`：
- en: '![Figure 7.50 – Building a DataFrame with questions and ground truth answers,
    and adding RAG chatbot answers](img/B16865_07_50.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.50 – 使用问题和真实答案构建 DataFrame，并添加 RAG 聊天机器人答案](img/B16865_07_50.jpg)'
- en: Figure 7.50 – Building a DataFrame with questions and ground truth answers,
    and adding RAG chatbot answers
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.50 – 使用问题和真实答案构建 DataFrame，并添加 RAG 聊天机器人答案
- en: 'Now that we have our DataFrame with the chatbot’s responses to each question,
    we must save this to a Delta table. We’ll continue to reference the DataFrame
    throughout the rest of this code, but this way, we won’t have to generate the
    chatbot’s responses again if we want to query this data in the future:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了包含聊天机器人对每个问题的回答的 DataFrame，我们必须将其保存到 Delta 表中。我们将在代码的其余部分继续引用 DataFrame，但这样，如果我们将来想要查询这些数据，我们就不必再次生成聊天机器人的回答：
- en: '![Figure 7.51 – Writing our evaluation DataFrame to a new table](img/B16865_07_51.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.51 – 将我们的评估 DataFrame 写入新表](img/B16865_07_51.jpg)'
- en: Figure 7.51 – Writing our evaluation DataFrame to a new table
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.51 – 将我们的评估 DataFrame 写入新表
- en: 'As we mentioned at the beginning of this section, we are using MLflow’s Evaluate
    capability to facilitate our model evaluation. Before we evaluate our RAG chatbot,
    let’s load the methods and verify how MLflow Evaluate works by default. First,
    we must load the “answer correctness” metric, which we will use as-is:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如本节开头所述，我们正在使用 MLflow 的评估功能来简化我们的模型评估。在我们评估 RAG 聊天机器人之前，让我们加载方法并验证 MLflow 评估默认的工作方式。首先，我们必须加载“答案正确性”指标，我们将直接使用它：
- en: '![Figure 7.52 – Viewing the answer correctness metrics](img/B16865_07_52.jpg)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.52 – 查看答案正确性指标](img/B16865_07_52.jpg)'
- en: Figure 7.52 – Viewing the answer correctness metrics
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.52 – 查看答案正确性指标
- en: 'The out-of-the-box metrics are good, but professionalism is also an important
    criterion for our use case, so we’ll create a custom professionalism metric. *Figure
    7**.53* shows how to use the `make_genai_metric()` function to build out our professionalism
    evaluation metric:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 默认指标很好，但专业性也是我们用例的重要标准之一，因此我们将创建一个自定义的专业性指标。*图 7.53* 展示了如何使用 `make_genai_metric()`
    函数构建我们的专业性评估指标：
- en: '![Figure 7.53 – Adding a custom professionalism metric](img/B16865_07_53.jpg)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.53 – 添加自定义专业性指标](img/B16865_07_53.jpg)'
- en: Figure 7.53 – Adding a custom professionalism metric
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.53 – 添加自定义专业性指标
- en: 'As you can see from `grading_prompt`, we’ve designed this metric to give a
    score between one and five, where a score of one identifies text as casual and
    a score of five evaluates text as noticeably formal. This is a powerful tool to
    evaluate your model based on criteria that are important to your business use
    case. You can modify the template according to your needs. We must also add examples
    of the metric, as defined in *Figure 7**.54*:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如 `grading_prompt` 所示，我们设计了此指标，使其在 1 到 5 之间给出分数，其中 1 分将文本识别为非正式，5 分则评估文本为明显正式。这是一个强大的工具，可以根据对您的业务用例重要的标准评估您的模型。您可以根据需要修改模板。我们还必须添加该指标的示例，如
    *图 7.54* 所定义：
- en: '![Figure 7.54 – Adding an example for the custom professionalism metric](img/B16865_07_54.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.54 – 添加自定义专业性指标的示例](img/B16865_07_54.jpg)'
- en: Figure 7.54 – Adding an example for the custom professionalism metric
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.54 – 添加自定义专业性指标的示例
- en: 'With our professionalism metric, let’s run the model evaluation using MLfLow.
    To run an evaluation, we can call `mlflow.evaluate()` against the pandas DataFrame
    containing the questions, ground truth answers, and chatbot-generated answers.
    We’ll include the answer correctness and professionalism metrics as extra metrics.
    The following code will calculate many other metrics in addition to the two we
    specified, such as token count, toxicity, and Automated Readability Index grade
    (the approximate grade level required to comprehend the text):'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们的专业性指标，让我们使用 MLfLow 运行模型评估。要运行评估，我们可以调用 `mlflow.evaluate()` 对包含问题、真实答案和聊天机器人生成的答案的
    pandas DataFrame 进行操作。我们将包括答案正确性和专业性指标作为额外指标。以下代码将计算我们指定的两个指标以外的许多其他指标，例如令牌计数、毒性以及自动可读性指数等级（理解文本所需的近似等级）：
- en: "![Figure 7.55 – Running an MLflow experiment with m\uFEFFlflow.evaluate()](img/B16865_07_55.jpg)"
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.55 – 使用 mlflow.evaluate() 运行 MLflow 实验](img/B16865_07_55.jpg)'
- en: Figure 7.55 – Running an MLflow experiment with mlflow.evaluate()
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.55 – 使用 mlflow.evaluate() 运行 MLflow 实验
- en: Once we’ve run the experiment, the metrics can be accessed in our notebook and
    via the UI so that we can easily see how our chatbot is performing in terms of
    accuracy and professionalism.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们运行了实验，我们可以在笔记本和 UI 中访问这些指标，这样我们就可以轻松地看到我们的聊天机器人在准确性和专业性方面的表现。
- en: Evaluating the chatbot’s responses
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估聊天机器人的响应
- en: 'First, let’s look at the MLfLow UI in Databricks to compare the results between
    the human-generated and chatbot-generated responses. To do so, navigate to the
    `CH7-02-Evaluating Chatbot`). Then, navigate to the `answers` match what we would
    expect to see, but it is also particularly useful when you want to test and compare
    outputs across different models or chunking strategies:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看 Databricks 中的 MLfLow UI，以比较人工生成和聊天机器人生成的响应之间的结果。要做到这一点，导航到 `CH7-02-Evaluating
    Chatbot`)。然后，导航到 `answers` 匹配我们预期的内容，但当你想要测试和比较不同模型或分块策略的输出时，这也特别有用：
- en: '![Figure 7.56 – Using the Evaluation view in Databricks MLflow](img/B16865_07_56.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.56 – 在 Databricks MLflow 中使用评估视图](img/B16865_07_56.jpg)'
- en: Figure 7.56 – Using the Evaluation view in Databricks MLflow
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.56 – 在 Databricks MLflow 中使用评估视图
- en: 'Take a look at a few examples from the evaluation dataset. We’ll see that our
    model, according to a quick human assessment, is performing reasonably well. Of
    course, this form of evaluation isn’t scalable, so let’s dig into the other metrics
    as well. We’ll use the common visualization library, `plotly`, to take a closer
    look at our model results. First, we’ll look at the distribution of token counts
    in our chatbot’s responses:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 查看评估数据集的一些示例。我们会看到，根据快速的人工评估，我们的模型表现相当不错。当然，这种评估形式不可扩展，所以让我们也深入查看其他指标。我们将使用常见的可视化库
    `plotly` 来更仔细地查看我们的模型结果。首先，我们将查看聊天机器人响应中标记计数的分布：
- en: '![Figure 7.57 – Plotting token counts from our chatbot’s responses](img/B16865_07_57.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.57 – 绘制聊天机器人响应的标记计数](img/B16865_07_57.jpg)'
- en: Figure 7.57 – Plotting token counts from our chatbot’s responses
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.57 – 绘制聊天机器人响应的标记计数
- en: 'While interesting, what we care about here are the two metrics we discussed
    earlier: correctness and professionalism. Let’s take a look at the distribution
    of the correctness scores:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然很有趣，但我们关心的是我们之前讨论的两个指标：正确性和专业性。让我们看看正确性分数的分布：
- en: '![Figure 7.58 – Plotting the correctness score distribution](img/B16865_07_58.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.58 – 绘制正确性分数分布](img/B16865_07_58.jpg)'
- en: Figure 7.58 – Plotting the correctness score distribution
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.58 – 绘制正确性分数分布
- en: 'Let’s also view the professionalism score distribution. Our distribution is
    threes and fours, which means the tone is most often “borderline professional.”
    This is how we defined it in our custom metric:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看看专业性分数的分布。我们的分布是三和四，这意味着语气通常是“边缘专业性”。这是我们自定义指标中的定义方式：
- en: '![Figure 7.59 – Plotting the professionalism score distribution](img/B16865_07_59.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.59 – 绘制专业性分数分布](img/B16865_07_59.jpg)'
- en: Figure 7.59 – Plotting the professionalism score distribution
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.59 – 绘制专业性分数分布
- en: 'Overall, our model is looking good! If we’re satisfied with the accuracy and
    professionalism scores, we can mark this model as ready for production by giving
    it a production alias:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，我们的模型看起来不错！如果我们对准确性和专业性分数满意，我们可以通过给它一个生产别名来标记这个模型为生产就绪：
- en: '![Figure 7.60 – Aliasing our model to show it is production-ready](img/B16865_07_60.jpg)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.60 – 为模型创建别名以显示其已准备好投入生产](img/B16865_07_60.jpg)'
- en: Figure 7.60 – Aliasing our model to show it is production-ready
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.60 – 为模型创建别名以显示其已准备好投入生产
- en: With that, we evaluated our chatbot by creating predictions from our question-and-answer
    dataset, created a custom evaluation metrics to evaluate the professionalism of
    each response, and visualized information about our model outputs. In the last
    chapter, we will demonstrate how to build a Gradio app so that you can bring your
    RAG chatbot to your end users!
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们通过从我们的问答数据集中创建预测来评估我们的聊天机器人，创建了一个自定义评估指标来评估每个响应的专业性，并可视化了我们的模型输出信息。在最后一章中，我们将演示如何构建一个
    Gradio 应用程序，这样你就可以将你的 RAG 聊天机器人带给你的最终用户！
- en: Summary
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Implementing models in production can be challenging, but with tools designed
    to support productionizing models and automating the MLOps process, it is much
    easier. In this chapter, we looked at using the UC Model Registry to manage the
    life cycle of an ML model. We highlighted MLflow and how it can be used to create
    reproducible, modularized data science workflows that automatically track parameters
    and performance metrics. We also discussed techniques for calculating features
    at the time of inference. To make the end-to-end MLOps process more manageable,
    we showed how to use workflows and webhooks to automate the ML life cycle. We
    also showed how to serve models and make inferences using MLflow and the Databricks
    platform.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中实现模型可能会具有挑战性，但有了旨在支持模型生产化和自动化MLOps流程的工具，这会容易得多。在本章中，我们探讨了如何使用UC模型注册表来管理机器学习模型的生命周期。我们强调了MLflow及其如何被用来创建可重复、模块化的数据科学工作流程，这些工作流程可以自动跟踪参数和性能指标。我们还讨论了在推理时计算特征的技术。为了使端到端的MLOps流程更易于管理，我们展示了如何使用工作流程和webhooks来自动化机器学习生命周期。我们还展示了如何使用MLflow和Databricks平台来提供模型和进行推理。
- en: In the last chapter, *Monitoring, Evaluating, and More*, we will look at monitoring
    our data and ML models within the Databricks Lakehouse so that you can get the
    most value from your data.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章“监控、评估和更多”中，我们将探讨如何在Databricks Lakehouse中监控我们的数据和机器学习模型，以便你能从你的数据中获得最大价值。
- en: Questions
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Let’s test ourselves on what we’ve learned by going through the following questions:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下问题来测试一下我们所学的内容：
- en: Can more than one model be in production simultaneously? When would you want
    to use two models in production?
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否可以同时生产多个模型？你会在什么情况下想要在生产中使用两个模型？
- en: What component of MLflow could you use to route approvals?
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用MLflow的哪个组件来路由审批？
- en: Can you use an MLflow API to serve your model?
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用MLflow API来提供你的模型吗？
- en: Answers
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 答案
- en: 'After putting some thought into the preceding questions, compare your answers
    to ours:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在思考了前面的问题之后，比较一下你的答案和我们的答案：
- en: Yes, having multiple models in production simultaneously is possible, and this
    is appropriate for use cases such as comparing models in a challenger/champion
    test or running A/B tests.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是的，同时在生产中拥有多个模型是可能的，这适用于比较挑战者/冠军测试中的模型或运行A/B测试等用例。
- en: The UC Model Registry can be used to route approvals.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用UC模型注册表来路由审批。
- en: The Model Serving API within MLFlow can be used for model serving.
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MLFlow内部的模型服务API可以用于模型服务。
- en: Further reading
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: This chapter discussed tools and technologies to help productionize ML. Please
    take a look at these resources to dive deeper into the areas that interest you
    most – and help you get more of your ML projects into production!
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了帮助生产化机器学习的工具和技术。请查看这些资源，深入了解你最感兴趣的领域，并帮助你将更多的机器学习项目投入生产！
- en: '*Best Practices for Using Structured Streaming in Production - The Databricks*
    *Blog*: [https://www.databricks.com/blog/streaming-production-collected-best-practices](https://www.databricks.com/blog/streaming-production-collected-best-practices)'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在生产中使用结构化流量的最佳实践 - Databricks博客*：[https://www.databricks.com/blog/streaming-production-collected-best-practices](https://www.databricks.com/blog/streaming-production-collected-best-practices)'
- en: '*The big book of machine learning use* *cases*: [https://www.databricks.com/resources/ebook/big-book-of-machine-learning-use-cases](https://www.databricks.com/resources/ebook/big-book-of-machine-learning-use-cases)'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习用例大全*：[https://www.databricks.com/resources/ebook/big-book-of-machine-learning-use-cases](https://www.databricks.com/resources/ebook/big-book-of-machine-learning-use-cases)'
- en: '*Databricks Model* *Serving*: [https://www.databricks.com/blog/2023/03/07/announcing-general-availability-databricks-model-serving.html](https://www.databricks.com/blog/2023/03/07/announcing-general-availability-databricks-model-serving.html)'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Databricks模型服务*：[https://www.databricks.com/blog/2023/03/07/announcing-general-availability-databricks-model-serving.html](https://www.databricks.com/blog/2023/03/07/announcing-general-availability-databricks-model-serving.html)'
- en: '*Create and manage serving endpoints using* *Mlflow*: [https://docs.databricks.com/en/machine-learning/model-serving/create-serving-endpoints-mlflow.html](https://docs.databricks.com/en/machine-learning/model-serving/create-serving-endpoints-mlflow.html)'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 *Mlflow* 创建和管理服务端点：[https://docs.databricks.com/en/machine-learning/model-serving/create-serving-endpoints-mlflow.html](https://docs.databricks.com/en/machine-learning/model-serving/create-serving-endpoints-mlflow.html)
- en: '*Model Evaluation in* *MLFLow*: [https://www.databricks.com/blog/2022/04/19/model-evaluation-in-mlflow.html](https://www.databricks.com/blog/2022/04/19/model-evaluation-in-mlflow.html)'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLFlow 中的模型评估*：[https://www.databricks.com/blog/2022/04/19/model-evaluation-in-mlflow.html](https://www.databricks.com/blog/2022/04/19/model-evaluation-in-mlflow.html)'
- en: '*The big book of* *MLOps*: [https://www.databricks.com/resources/ebook/the-big-book-of-mlops](https://www.databricks.com/resources/ebook/the-big-book-of-mlops)'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLOps 的宝典*：[https://www.databricks.com/resources/ebook/the-big-book-of-mlops](https://www.databricks.com/resources/ebook/the-big-book-of-mlops)'
- en: '*Databricks Asset Bundles - Programmatically define, deploy, and run Databricks
    jobs, Delta Live Tables pipelines, and MLOps Stacks using CI/CD best practices
    and* *workflows*: [https://docs.databricks.com/en/dev-tools/bundles/index.html](https://docs.databricks.com/en/dev-tools/bundles/index.html)'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Databricks 资产包 - 使用 CI/CD 最佳实践和工作流程程序化定义、部署和运行 Databricks 作业、Delta Live Tables
    管道和 MLOps Stacks*：[https://docs.databricks.com/en/dev-tools/bundles/index.html](https://docs.databricks.com/en/dev-tools/bundles/index.html)'
- en: '*Model Registry Webhooks*: `MLflow Model Registry Webhooks` `on Databricks`'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型注册 Webhooks*：`MLflow 模型注册 Webhooks` `在 Databricks`'
- en: '*Webhooks*: [https://docs.databricks.com/en/mlflow/model-registry-webhooks.html](https://docs.databricks.com/en/mlflow/model-registry-webhooks.html)'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Webhooks*：[https://docs.databricks.com/en/mlflow/model-registry-webhooks.html](https://docs.databricks.com/en/mlflow/model-registry-webhooks.html)'
- en: '*CI/CD workflows with Git and Databricks Repos - Use GitHub and Databricks
    Repos for source control and CI/CD* *workflows*: [https://docs.databricks.com/en/repos/ci-cd-techniques-with-repos.html](https://docs.databricks.com/en/repos/ci-cd-techniques-with-repos.html)'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 Git 和 Databricks 仓库的 CI/CD 工作流程 - 使用 GitHub 和 Databricks 仓库进行源代码控制和 CI/CD
    工作流程*：[https://docs.databricks.com/en/repos/ci-cd-techniques-with-repos.html](https://docs.databricks.com/en/repos/ci-cd-techniques-with-repos.html)'
- en: '*Continuous integration and delivery using GitHub Actions - Build a CI/CD workflow
    on GitHub that uses GitHub Actions developed for* *Databricks*: [https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-github.html](https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-github.html)'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 GitHub Actions 进行持续集成和交付 - 在 GitHub 上构建使用为 *Databricks* 开发的 GitHub Actions
    的 CI/CD 工作流程*：[https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-github.html](https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-github.html)'
- en: '*CI/CD with Jenkins on Databricks – Develop a CI/CD pipeline for Databricks
    that uses* *Jenkins*: [https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-jenkins.html](https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-jenkins.html)'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在 Databricks 上使用 Jenkins 的 CI/CD – 为 Databricks 开发使用 *Jenkins* 的 CI/CD 管道*：[https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-jenkins.html](https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-jenkins.html)'
- en: '*Orchestrate Databricks jobs with Apache Airflow – Manage and schedule a data
    pipeline that uses Apache* *Airflow*: [https://docs.databricks.com/en/workflows/jobs/how-to/use-airflow-with-jobs.html](https://docs.databricks.com/en/workflows/jobs/how-to/use-airflow-with-jobs.html)'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 Apache Airflow 调度 Databricks 作业 – 管理和调度使用 Apache *Airflow* 的数据管道*：[https://docs.databricks.com/en/workflows/jobs/how-to/use-airflow-with-jobs.html](https://docs.databricks.com/en/workflows/jobs/how-to/use-airflow-with-jobs.html)'
- en: '*Service principals for CI/CD –* *Use service principals instead of users with
    CI/CD* *systems*: [https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-sp.html](https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-sp.html)'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*CI/CD 的服务主体 – 使用服务主体而不是用户进行 CI/CD *系统*：[https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-sp.html](https://docs.databricks.com/en/dev-tools/ci-cd/ci-cd-sp.html)'
- en: '*DFE* *client*: [https://docs.databricks.com/en/machine-learning/feature-store/python-api.html#use-the-clients-for-unit-testing](https://docs.databricks.com/en/machine-learning/feature-store/python-api.html#use-the-clients-for-unit-testing)'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DFE 客户端*：[https://docs.databricks.com/en/machine-learning/feature-store/python-api.html#use-the-clients-for-unit-testing](https://docs.databricks.com/en/machine-learning/feature-store/python-api.html#use-the-clients-for-unit-testing)'
- en: '*Unity*: [https://docs.databricks.com/en/udf/unity-catalog.html](https://docs.databricks.com/en/udf/unity-catalog.html)'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Unity*：[https://docs.databricks.com/en/udf/unity-catalog.html](https://docs.databricks.com/en/udf/unity-catalog.html)'
- en: '*Best Practices for LLM Evaluation of RAG Applications, Part* *1*: [https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG](https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG)'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*RAG 应用程序 LLM 评估的最佳实践，第 *1* 部分*：[https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG](https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG)'
- en: '*Best Practices for LLM Evaluation of RAG Applications, Part* *2*: [https://www.databricks.com/blog/announcing-mlflow-28-llm-judge-metrics-and-best-practices-llm-evaluation-rag-applications-part](https://www.databricks.com/blog/announcing-mlflow-28-llm-judge-metrics-and-best-practices-llm-evaluation-rag-applications-part)'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*RAG应用LLM评估的最佳实践，第二部分*：[https://www.databricks.com/blog/announcing-mlflow-28-llm-judge-metrics-and-best-practices-llm-evaluation-rag-applications-part](https://www.databricks.com/blog/announcing-mlflow-28-llm-judge-metrics-and-best-practices-llm-evaluation-rag-applications-part)'
- en: '*Create model serving* *endpoints*: [https://docs.databricks.com/en/machine-learning/model-serving/create-manage-serving-endpoints.html](https://docs.databricks.com/en/machine-learning/model-serving/create-manage-serving-endpoints.html)'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*创建模型服务端点*：[https://docs.databricks.com/en/machine-learning/model-serving/create-manage-serving-endpoints.html](https://docs.databricks.com/en/machine-learning/model-serving/create-manage-serving-endpoints.html)'
