- en: Chapter 8. Detecting Interest Points
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章. 检测兴趣点
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下食谱：
- en: Detecting corners in an image
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测图像中的角点
- en: Detecting features quickly
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速检测特征
- en: Detecting scale-invariant features
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测尺度不变特征
- en: Detecting FAST features at multiple scales
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多个尺度上检测FAST特征
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: In computer vision, the concept of interest points—also called **keypoints**
    or **feature points**—has been largely used to solve many problems in object recognition,
    image registration, visual tracking, 3D reconstruction, and more. This concept
    relies on the idea that instead of looking at the image as a whole, it could be
    advantageous to select some special points in the image and perform a local analysis
    on them. This approach works well as long as a sufficient number of such points
    are detected in the images of interest and these points are distinguishing and
    stable features that can be accurately localized.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉中，兴趣点的概念——也称为**关键点**或**特征点**——已被广泛用于解决物体识别、图像配准、视觉跟踪、3D重建等问题。这个概念依赖于这样的想法：与其将图像作为一个整体来看待，不如选择图像中的某些特殊点，并对它们进行局部分析。只要在感兴趣的图像中检测到足够数量的此类点，并且这些点是区分性和稳定的特征，可以精确地定位，这种方法就会很有效。
- en: Because they are used for analyzing image content, feature points should ideally
    be detected at the same scene or object location no matter from which viewpoint,
    scale, or orientation the image was taken. View invariance is a very desirable
    property in image analysis and has been the object of numerous studies. As we
    will see, different detectors have different invariance properties. This chapter
    focuses on the keypoint extraction process itself. The next two chapters will
    then show you how interest points can be put to work in different contexts such
    as image matching or image geometry estimation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们用于分析图像内容，特征点理想情况下应该在相同的场景或物体位置被检测到，无论图像是从哪个视角、尺度或方向拍摄的。视域不变性是图像分析中一个非常理想化的属性，并且一直是许多研究的对象。正如我们将看到的，不同的检测器有不同的不变性属性。本章重点介绍关键点提取过程本身。接下来的两章将展示如何在不同的上下文中使用兴趣点，例如图像匹配或图像几何估计。
- en: Detecting corners in an image
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测图像中的角点
- en: When searching for interesting feature points in images, corners come out as
    an interesting solution. They are indeed local features that can be easily localized
    in an image, and in addition, they should abound in scenes of man-made objects
    (where they are produced by walls, doors, windows, tables, and so on). Corners
    are also interesting because they are two-dimensional features that can be accurately
    localized (even at sub-pixel accuracy), as they are at the junction of two edges.
    This is in contrast to points located on a uniform area or on the contour of an
    object and points that would be difficult to repeatedly localize precisely on
    other images of the same object. The Harris feature detector is a classical approach
    to detecting corners in an image. We will explore this operator in this recipe.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当在图像中搜索有趣的特征点时，角点被证明是一个有趣的解决方案。它们确实是易于在图像中定位的局部特征，并且此外，它们在人造物体场景中应该很丰富（它们是由墙壁、门、窗户、桌子等产生的）。角点也很有趣，因为它们是二维特征，可以精确地定位（甚至达到亚像素精度），因为它们位于两条边的交汇处。这与位于均匀区域或物体轮廓上的点以及在其他相同物体的图像上难以精确重复定位的点形成对比。Harris特征检测器是检测图像中角点的经典方法。我们将在本食谱中探讨这个算子。
- en: How to do it...
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The basic OpenCV function that is used to detect Harris corners is called `cv::cornerHarris`
    and is straightforward to use. You call it on an input image, and the result is
    an image of floats that gives you the corner strength at each pixel location.
    A threshold is then applied on this output image in order to obtain a set of detected
    corners. This is accomplished with the following code:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 用于检测Harris角的基本OpenCV函数被称为`cv::cornerHarris`，使用起来非常简单。你可以在输入图像上调用它，结果是一个浮点图像，它给出了每个像素位置的角点强度。然后对这个输出图像应用一个阈值，以获得一组检测到的角点。这可以通过以下代码实现：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here is the original image:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这是原始图像：
- en: '![How to do it...](img/00125.jpeg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00125.jpeg)'
- en: 'The result is a binary map image shown in the following screenshot, which is
    inverted for better viewing (that is, we used `cv::THRESH_BINARY_INV` instead
    of `cv::THRESH_BINARY` to get the detected corners in black):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个二值映射图像，如以下截图所示，为了更好的观看效果已进行反转（即，我们使用了`cv::THRESH_BINARY_INV`而不是`cv::THRESH_BINARY`来获取检测到的角点为黑色）：
- en: '![How to do it...](img/00126.jpeg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00126.jpeg)'
- en: From the preceding function call, we observe that this interest point detector
    requires several parameters (these will be explained in the next section) that
    might make it difficult to tune. In addition, the corner map that is obtained
    contains many clusters of corner pixels that contradict the fact that we would
    like to detect well-localized points. Therefore, we will try to improve the corner-detection
    method by defining our own class to detect Harris corners.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的函数调用中，我们可以观察到这个兴趣点检测器需要几个参数（这些将在下一节中解释），这些参数可能会使其难以调整。此外，获得的角点图包含许多角像素簇，这与我们希望检测良好定位点的愿望相矛盾。因此，我们将尝试通过定义我们自己的类来检测Harris角来改进角检测方法。
- en: 'The class encapsulates the Harris parameters with their default values and
    corresponding getter and setter methods (which are not shown here):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 该类封装了Harris参数及其默认值和相应的getter和setter方法（此处未显示）：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To detect the Harris corners on an image, we proceed with two steps. First,
    the Harris values at each pixel are computed:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要在图像上检测Harris角，我们进行两个步骤。首先，计算每个像素的Harris值：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, the feature points are obtained based on a specified threshold value.
    Since the range of possible values for Harris depends on the particular choices
    of its parameters, the threshold is specified as a quality level that is defined
    as a fraction of the maximal Harris value computed in the image:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，根据指定的阈值值获取特征点。由于Harris的可能值范围取决于其参数的特定选择，因此阈值被指定为质量水平，该水平定义为图像中计算出的最大Harris值的分数：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This method returns a binary corner map of the detected features. The fact
    that the detection of the Harris features has been split into two methods allows
    us to test the detection with a different threshold (until an appropriate number
    of feature points are obtained) without the need to repeat costly computations.
    It is also possible to obtain the Harris features in the form of a `std::vector`
    of `cv::Point`:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法返回检测到的特征的二值角点图。将Harris特征的检测分为两种方法，这使得我们可以使用不同的阈值（直到获得适当数量的特征点）来测试检测，而无需重复昂贵的计算。也可以以`std::vector`的`cv::Point`形式获取Harris特征：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This class also improves the detection of the Harris corners by adding a non-maxima
    suppression step, which will be explained in the next section. The detected points
    can now be drawn on an image using the `cv::circle` function, as demonstrated
    by the following method:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本类通过添加一个非极大值抑制步骤来提高Harris角检测，这一步骤将在下一节中解释。现在可以使用`cv::circle`函数在图像上绘制检测到的点，如下所示的方法演示：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Using this class, the detection of the Harris points is accomplished as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此类，Harris点的检测如下完成：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This results in the following image:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下图像：
- en: '![How to do it...](img/00127.jpeg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00127.jpeg)'
- en: How it works...
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何工作...
- en: 'To define the notion of corners in images, the Harris feature detector looks
    at the average change in directional intensity in a small window around a putative
    interest point. If we consider a displacement vector, `(u,v)`, the average intensity
    change is given by the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定义图像中角点的概念，Harris特征检测器检查围绕潜在兴趣点的小窗口中方向强度的平均变化。如果我们考虑一个位移向量`(u,v)`，平均强度变化由以下公式给出：
- en: '![How it works...](img/00128.jpeg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00128.jpeg)'
- en: The summation is over a defined neighborhood around the considered pixel (the
    size of this neighborhood corresponds to the third parameter in the `cv::cornerHarris`
    function). This average intensity change can then be computed in all possible
    directions, which leads to the definition of a corner as a point for which the
    average change is high in more than one direction. From this definition, the Harris
    test is performed as follows. We first obtain the direction of the maximal average
    intensity change. Next, we check whether the average intensity change in the orthogonal
    direction is high as well. If this is the case, then we have a corner.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 求和是在考虑的像素周围定义的邻域内进行的（这个邻域的大小对应于`cv::cornerHarris`函数的第三个参数）。然后可以计算所有可能方向上的平均强度变化，这导致了一个角点的定义：即在一个方向上平均变化高，而在另一个方向上也高的点。从这个定义出发，Harris测试如下进行。我们首先获得最大平均强度变化的方向。接下来，我们检查正交方向上的平均强度变化是否也高。如果是这样，那么我们就有一个角点。
- en: 'Mathematically, this condition can be tested by using an approximation of the
    preceding formula using the Taylor expansion:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，这个条件可以通过使用前一个公式的泰勒展开来近似测试：
- en: '![How it works...](img/00129.jpeg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00129.jpeg)'
- en: 'This is then rewritten in the matrix form:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将其重写为矩阵形式：
- en: '![How it works...](img/00130.jpeg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00130.jpeg)'
- en: This matrix is a covariance matrix that characterizes the rate of intensity
    change in all directions. This definition involves the image's first derivatives
    that are often computed using the Sobel operator. This is the case with the OpenCV
    implementation, which is the fourth parameter of the function that corresponds
    to the aperture used for the computation of the Sobel filters. It can be shown
    that the two eigenvalues of the covariance matrix give you the maximal average
    intensity change and the average intensity change for the orthogonal direction.
    Then, if these two eigenvalues are low, we are in a relatively homogenous region.
    If one eigenvalue is high and the other is low, we must be on an edge. Finally,
    if both eigenvalues are high, then we are at a corner location. Therefore, the
    condition for a point to be accepted as a corner is that it must have the smallest
    eigenvalue of the covariance matrix at a higher point than a given threshold.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这个矩阵是一个协方差矩阵，它表征了所有方向上强度变化的速度。这个定义涉及到图像的第一导数，这些导数通常使用Sobel算子来计算。这是OpenCV实现的情况，它是函数的第四个参数，对应于用于计算Sobel滤波器的孔径。可以证明，协方差矩阵的两个特征值给出了最大平均强度变化和正交方向上的平均强度变化。然后，如果这两个特征值较低，我们处于一个相对均匀的区域。如果一个特征值较高而另一个较低，我们必须处于一个边缘。最后，如果两个特征值都较高，那么我们处于一个角落位置。因此，一个点要被接受为角落的条件是它必须在高于给定阈值的点上具有协方差矩阵的最小特征值。
- en: 'The original definition of the Harris corner algorithm uses some properties
    of the eigen decomposition theory in order to avoid the cost of explicitly computing
    the eigenvalues. These properties are as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 哈里斯角算法的原始定义使用特征分解理论的一些性质，以避免显式计算特征值的成本。这些性质如下：
- en: The product of the eigenvalues of a matrix is equal to its determinant
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵的特征值之积等于其行列式
- en: The sum of the eigenvalues of a matrix is equal to the sum of the diagonal of
    the matrix (also known as the **trace** of the matrix)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵的特征值之和等于矩阵的对角线之和（也称为矩阵的**迹**）
- en: 'It then follows that we can verify whether the eigenvalues of a matrix are
    high by computing the following score:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以通过计算以下分数来验证矩阵的特征值是否较高：
- en: '![How it works...](img/00131.jpeg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00131.jpeg)'
- en: One can easily verify that this score will indeed be high only if both eigenvalues
    are high too. This is the score that is computed by the `cv::cornerHarris` function
    at each pixel location. The value of `k` is specified as the fifth parameter of
    the function. It could be difficult to determine what would be the best value
    for this parameter. However, in practice, it has been seen that a value in the
    range of `0.05` and `0.5` generally gives good results.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 可以很容易地验证，只有当两个特征值都较高时，这个分数才会确实较高。这是`cv::cornerHarris`函数在每个像素位置计算的分数。`k`的值被指定为函数的第五个参数。确定这个参数的最佳值可能很困难。然而，在实践中，已经看到在`0.05`和`0.5`范围内的值通常给出良好的结果。
- en: 'To improve the result of the detection, the class described in the previous
    section adds an additional non-maxima suppression step. The goal here is to exclude
    Harris corners that are adjacent to others. Therefore, to be accepted, the Harris
    corner must not only have a score higher than the specified threshold, but it
    must also be a local maximum. This condition is tested by using a simple trick
    that consists of dilating the image of the Harris score in our `detect` method:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高检测结果，前一小节中描述的类别增加了一个额外的非极大值抑制步骤。这里的目的是排除相邻的其他哈里斯角。因此，为了被接受，哈里斯角不仅必须有一个高于指定阈值的分数，而且它还必须是一个局部最大值。这个条件是通过使用一个简单的技巧来测试的，该技巧包括在`detect`方法中膨胀哈里斯分数的图像：
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Since the dilation replaces each pixel value with the maximum in the defined
    neighborhood, the only points that will not be modified are the local maxima.
    This is what is verified by the following equality test:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由于膨胀将每个像素值替换为定义的邻域中的最大值，唯一不会修改的点就是局部最大值。这正是以下等式测试所验证的：
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `localMax` matrix will therefore be true (that is, non-zero) only at local
    maxima locations. We then use it in our `getCornerMap` method to suppress all
    non-maximal features (using the `cv::bitwise_and` function).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`localMax`矩阵仅在局部极大值位置为真（即非零）。然后我们使用它在我们自己的`getCornerMap`方法中来抑制所有非极大特征（使用`cv::bitwise_and`函数）。
- en: There's more...
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Additional improvements can be made to the original Harris corner algorithm.
    This section describes another corner detector found in OpenCV, which expands
    the Harris detector to make its corners more uniformly distributed across the
    image. As we will see, this operator has an implementation for the feature detector
    in the OpenCV 2 common interface.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 可以对原始的Harris角算法进行更多改进。本节描述了OpenCV中找到的另一个角检测器，它将Harris检测器扩展到使角在图像中分布得更均匀。正如我们将看到的，此操作符在OpenCV
    2通用接口中为特征检测器提供了一个实现。
- en: Good features to track
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟踪的良好特征
- en: With the advent of floating-point processors, the mathematical simplification
    introduced to avoid eigenvalue decomposition has become negligible, and consequently,
    the detection of Harris corners can be made based on the explicitly computed eigenvalues.
    In principle, this modification should not significantly affect the result of
    the detection, but it avoids the use of the arbitrary `k` parameter. Note that
    two functions exist that allow you to explicitly get the eigenvalues (and eignevectors)
    of the Harris covariance matrix; these are `cv::cornerEigenValsAndVecs` and `cv::cornerMinEigenVal`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 随着浮点处理器的出现，为了避免特征值分解而引入的数学简化变得可以忽略不计，因此，基于显式计算的特征值，可以基于Harris角进行检测。原则上，这种修改不应显著影响检测结果，但它避免了使用任意的`k`参数。请注意，存在两个函数允许您显式获取Harris协方差矩阵的特征值（和特征向量）；这些是`cv::cornerEigenValsAndVecs`和`cv::cornerMinEigenVal`。
- en: 'A second modification addresses the problem of feature point clustering. Indeed,
    in spite of the introduction of the local maxima condition, interest points tend
    to be unevenly distributed across an image, showing concentrations at highly textured
    locations. A solution to this problem is to impose a minimum distance between
    two interest points. This can be achieved using the following algorithm. Starting
    from the point with the strongest Harris score (that is, with the largest minimum
    eigenvalue), only accept interest points if they are located at, at least, a given
    distance from the already accepted points. This solution is implemented in OpenCV
    in the `cv::goodFeaturesToTrack` function, which is thus named because the features
    it detects can be used as a good starting set in visual tracking applications.
    This is called as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种修改解决了特征点聚类的问题。事实上，尽管引入了局部极大值条件，但兴趣点在图像中往往分布不均，在高度纹理的位置出现集中。解决这个问题的一个方法是强制两个兴趣点之间保持最小距离。这可以通过以下算法实现。从具有最强Harris分数的点（即具有最大最小特征值）开始，只有当兴趣点位于已接受点至少给定距离之外时，才接受兴趣点。这个解决方案在OpenCV的`cv::goodFeaturesToTrack`函数中实现，因此得名，因为检测到的特征可以用作视觉跟踪应用中的良好起始集。其调用方式如下：
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In addition to the quality-level threshold value and the minimum tolerated
    distance between interest points, the function also uses a maximum number of points
    that can be returned (this is possible since points are accepted in the order
    of strength). The preceding function call produces the following result:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除了质量级别阈值值和兴趣点之间可容忍的最小距离之外，该函数还使用可以返回的最大点数（这是可能的，因为点按强度顺序接受）。前面的函数调用产生以下结果：
- en: '![Good features to track](img/00132.jpeg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![跟踪的良好特征](img/00132.jpeg)'
- en: This approach increases the complexity of the detection, since it requires the
    interest points to be sorted by their Harris score, but it also clearly improves
    the distribution of the points across the image. Note that this function also
    includes an optional flag that requests Harris corners to be detected using the
    classical corner score definition (using the covariance matrix determinant and
    trace).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法增加了检测的复杂性，因为它需要根据Harris分数对兴趣点进行排序，但它也明显改善了点在图像中的分布。请注意，此函数还包括一个可选标志，请求使用经典角评分定义（使用协方差矩阵的行列式和迹）来检测Harris角。
- en: The feature detector's common interface
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征检测器的通用接口
- en: OpenCV 2 has introduced a common interface for its different interest point
    detectors. This interface allows easy testing of different interest point detectors
    within the same application.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 2为它的不同兴趣点检测器引入了一个通用接口。这个接口允许在同一个应用程序中轻松测试不同的兴趣点检测器。
- en: The interface defines a `cv::Keypoint` class that encapsulates the properties
    of each detected feature point. For the Harris corners, only the position of the
    keypoints and its response strength is relevant. The *Detecting scale-invariant
    features* recipe will discuss the other properties that can be associated with
    a keypoint.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接口定义了一个`cv::Keypoint`类，它封装了每个检测到的特征点的属性。对于哈里斯角，仅关键点的位置及其响应强度是相关的。*检测尺度不变特征*菜谱将讨论可以与关键点关联的其他属性。
- en: 'The `cv::FeatureDetector` abstract class basically imposes the existence of
    a `detect` operation with the following signatures:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv::FeatureDetector`抽象类基本上强制存在一个具有以下签名的`detect`操作：'
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The second method allows interest points to be detected in a vector of images.
    The class also includes other methods that can read and write the detected points
    in a file.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法允许在图像向量中检测兴趣点。该类还包括其他可以读取和写入检测到的点的文件的方法。
- en: 'The `cv::goodFeaturesToTrack` function has a wrapper class called `cv::GoodFeaturesToTrackDetector`,
    which inherits from the `cv::FeatureDetector` class. It can be used in a way that
    is similar to what we did with our Harris corners class, as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv::goodFeaturesToTrack`函数有一个名为`cv::GoodFeaturesToTrackDetector`的包装类，它继承自`cv::FeatureDetector`类。它可以像我们处理Harris角类那样使用，如下所示：'
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The result is the same as the one obtained previously, since the same function
    is ultimately called by the wrapper. Note how we used the OpenCV 2 smart pointer
    class `(cv::Ptr)` that, as explained in [Chapter 1](part0014_split_000.html#page
    "Chapter 1. Playing with Images"), *Playing with Images*, automatically releases
    the pointed object when the reference count drops to zero.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 结果与之前获得的结果相同，因为包装器最终调用的函数是相同的。注意我们使用了OpenCV 2的智能指针类`(cv::Ptr)`，正如在[第1章](part0014_split_000.html#page
    "第1章. 玩转图像")中解释的那样，*玩转图像*，当引用计数降至零时，会自动释放指向的对象。
- en: See also
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The classic article that describes the Harris operator by C. Harris and M.J.
    Stephens*, A combined corner and edge detector, Alvey Vision Conference, pp. 147–152,
    1988*
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述哈里斯算子的经典文章由C. Harris和M.J. Stephens撰写*，A combined corner and edge detector,
    Alvey Vision Conference, pp. 147–152, 1988*
- en: The article by J. Shi and C. Tomasi*, Good features to track, Int. Conference
    on Computer Vision and Pattern Recognition, pp. 593-600, 1994*, introduces these
    features
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: J. Shi和C. Tomasi的论文*Good features to track, Int. Conference on Computer Vision
    and Pattern Recognition, pp. 593-600, 1994*介绍了这些特征
- en: The article by K. Mikolajczyk and C. Schmid, *Scale and Affine invariant interest
    point detectors, International Journal of Computer Vision, vol 60, no 1, pp. 63-86,
    2004*, proposes a multi-scale and affine-invariant Harris operator
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K. Mikolajczyk和C. Schmid的论文*Scale and Affine invariant interest point detectors,
    International Journal of Computer Vision, vol 60, no 1, pp. 63-86, 2004*提出了一种多尺度且仿射不变性的哈里斯算子
- en: Detecting features quickly
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速检测特征
- en: The Harris operator proposed a formal mathematical definition for corners (or
    more generally, interest points) based on the rate of intensity changes in two
    perpendicular directions. Although this constitutes a sound definition, it requires
    the computation of the image derivatives, which is a costly operation, especially
    considering the fact that interest point detection is often just the first step
    in a more complex algorithm.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 哈里斯算子提出了基于两个垂直方向上强度变化率的角（或更一般地说，兴趣点）的正式数学定义。尽管这是一个合理的定义，但它需要计算图像导数，这是一个代价高昂的操作，尤其是考虑到兴趣点检测通常只是更复杂算法的第一步。
- en: In this recipe, we present another feature point operator, called **FAST** (**Features
    from Accelerated Segment Test**). This one has been specifically designed to allow
    quick detection of interest points in an image; the decision to accept or not
    to accept a keypoint is based on only a few pixel comparisons.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们介绍另一个特征点算子，称为**FAST**（**加速段测试特征**）。这个算子是专门设计用来快速检测图像中的兴趣点的；是否接受或拒绝一个关键点的决定仅基于少数像素的比较。
- en: How to do it...
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Using the OpenCV 2 common interface for feature point detection makes the deployment
    of any feature point detectors easy. The detector presented in this recipe is
    the FAST detector. As the name suggests, it has been designed to be quick in order
    to compute the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 使用OpenCV 2通用接口进行特征点检测使得部署任何特征点检测器变得容易。本食谱中介绍的是FAST检测器。正如其名所示，它被设计得很快，以便计算以下内容：
- en: '[PRE12]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Note that OpenCV also proposes a generic function to draw keypoints on an image:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，OpenCV还提供了一个通用的函数来在图像上绘制关键点：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'By specifying the chosen drawing flag, the keypoints are drawn over the input
    image, thus producing the following output result:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通过指定选择的绘制标志，关键点被绘制在输入图像上，从而产生以下输出结果：
- en: '![How to do it...](img/00133.jpeg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/00133.jpeg)'
- en: An interesting option is to specify a negative value for the keypoint color.
    In this case, a different random color will be selected for each drawn circle.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的选项是为关键点颜色指定一个负值。在这种情况下，将为每个绘制的圆圈选择不同的随机颜色。
- en: How it works...
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: As in the case with the Harris point detector, the FAST feature algorithm derives
    from the definition of what constitutes a *corner*. This time, this definition
    is based on the image intensity around a putative feature point. The decision
    to accept a keypoint is taken by examining a circle of pixels centered at a candidate
    point. If an arc of contiguous points of a length greater than 3/4 of the circle
    perimeter in which all pixels significantly differ from the intensity of the center
    point (being all darker or all brighter) is found, then a keypoint is declared.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 与哈里斯点检测器的情况一样，FAST特征算法源自对“角”的定义。这次，这个定义是基于假设特征点周围的图像强度。是否接受关键点的决定是通过检查以候选点为中心的像素圆来做出的。如果在圆周上找到一个连续点弧，其长度大于圆周长度的3/4，并且其中所有像素与中心点的强度显著不同（都是较暗或较亮），则宣布存在一个关键点。
- en: This is a simple test that can be computed quickly. Moreover, in its original
    formulation, the algorithm uses an additional trick to further speed up the process.
    Indeed, if we first test four points separated by 90 degrees on the circle (for
    example, top, bottom, right, and left points), it can be easily shown that in
    order to satisfy the condition expressed previously, at least three of these points
    must all be brighter or darker than the central pixel.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可以快速计算的简单测试。此外，在其原始公式中，该算法使用了一个额外的技巧来进一步加快处理速度。确实，如果我们首先测试圆周上相隔90度的四个点（例如，顶部、底部、右侧和左侧点），可以很容易地证明，为了满足之前表达的条件，至少有三个这些点必须与中心像素一样亮或一样暗。
- en: If this is not the case, the point can be rejected immediately, without inspecting
    additional points on the circumference. This is a very effective test, since in
    practice, most of the image points will be rejected by this simple 4-comparison
    test.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不是这种情况，则可以立即拒绝该点，而无需检查圆周上的其他点。这是一个非常有效的测试，因为在实践中，大多数图像点都会被这个简单的4比较测试所拒绝。
- en: 'In principle, the radius of the circle of examined pixels could have been a
    parameter of the method. However, it has been found that in practice, a radius
    of `3` gives you both good results and high efficiency. There are, then, `16`
    pixels that need to be considered on the circumference of the circle, shown as
    follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在原则上，检查像素圆的半径可以是该方法的一个参数。然而，在实践中发现，半径为`3`既可以得到良好的结果，又具有高效率。因此，圆周上需要考虑的像素有`16`个，如下所示：
- en: '![How it works...](img/00134.jpeg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/00134.jpeg)'
- en: The four points used for the pretest are the **1**, **5**, **9**, and **13**
    pixels, and the required number of contiguous darker or brighter points is **12**.
    However, it has been observed that by reducing the length of the contiguous segment
    to **9**, better repeatability of the detected corners across images is obtained.
    This variant is often designated as the **FAST-9** corner detector, and this is
    the one that is used by OpenCV. Note that there exists a `cv::FASTX` function
    that proposes another variant of the FAST detector.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 预测试中使用的四个点是**1**、**5**、**9**和**13**像素，并且需要连续的较暗或较亮的点的数量是**12**。然而，观察发现，通过将连续段长度减少到**9**，可以获得更好的检测角在图像间的重复性。这个变体通常被称为**FAST-9**角检测器，这正是OpenCV所使用的。请注意，存在一个`cv::FASTX`函数，它提出了FAST检测器的另一种变体。
- en: To be considered as being significantly darker or brighter, the intensity of
    a point must differ from the intensity of the central pixel by at least a given
    amount; this value corresponds to the threshold parameter specified in the function
    call. The larger this threshold is, the fewer corner points will be detected.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 要被认为是明显更暗或更亮，一个点的强度必须至少比中心像素的强度高出一个给定的量；这个值对应于函数调用中指定的阈值参数。这个阈值越大，检测到的角点就越少。
- en: 'As for Harris features, it is often better to perform non-maxima suppression
    on the corners that have been found. Therefore, a corner strength measure needs
    to be defined. Several alternatives measures to this can considered, and the one
    that has been retained is the following. The strength of a corner is given by
    the sum of the absolute difference between the central pixel and the pixels on
    the identified contiguous arc. Note that the algorithm is also available through
    a direct function call:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 至于Harris特征，通常对已找到的角点执行非极大值抑制会更好。因此，需要定义一个角点强度度量。可以考虑几种替代度量，而保留的是以下度量。角点的强度由中心像素与识别出的连续弧上的像素之间的绝对差之和给出。请注意，该算法也可以通过直接函数调用获得：
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: However, because of its flexibility, the use of the `cv::FeatureDetector` interface
    is recommended.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于其灵活性，建议使用`cv::FeatureDetector`接口。
- en: This algorithm results in very fast interest point detection and is therefore
    the feature of choice when speed is a concern. This is the case, for example,
    in real-time visual tracking or object-recognition applications where several
    points must be tracked or matched in a live video stream.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 此算法导致非常快的兴趣点检测，因此在速度是关注点时，这是首选的特征。例如，在实时视觉跟踪或对象识别应用中，必须跟踪或匹配实时视频流中的多个点时，情况就是这样。
- en: There's more...
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: To improve the detection of feature points, additional tools are offered by
    OpenCV. Indeed, a number of class adapters are available in order to better control
    the way the keypoints are extracted.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高特征点的检测，OpenCV提供了额外的工具。确实，有多个类适配器可用，以便更好地控制关键点的提取方式。
- en: Adapted feature detection
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 适应性特征检测
- en: 'If you wish to better control the number of detected points, a special subclass
    of the `cv::FeatureDetector` class, called `cv::DynamicAdaptedFeatureDetector`,
    is available. This allows you to specify the number of interest points that can
    be detected as an interval. In the case of the FAST feature detector, this is
    used as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望更好地控制检测到的点的数量，有一个特殊的`cv::FeatureDetector`类的子类，称为`cv::DynamicAdaptedFeatureDetector`，可供使用。这允许你指定可以检测到的兴趣点数量的区间。在FAST特征检测器的情况下，使用方法如下：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The interest points will then be iteratively detected. After each iteration,
    the number of detected points is checked and the detector threshold is adjusted
    accordingly in order to produce more or less points; this process is repeated
    until the number of detected points fit into the specified interval. A maximum
    number of iterations is specified in order to avoid that the method spends too
    much time on multiple detections. For this method to be implemented in a generic
    way, the used `cv::FeatureDetector` class must implement the `cv::AdjusterAdapter`
    interface. This class includes a `tooFew` method and a `tooMany` method, both
    of which modify the internal threshold of the detector in order to produce more
    or less keypoints. There is also a `good` predicate method that returns `true`
    if the detector threshold can still be adjusted. Using a `cv::DynamicAdaptedFeatureDetector`
    class can be a good strategy to obtain an appropriate number of feature points;
    however, you must understand that there is a performance price that you will have
    to to pay for this benefit. Moreover, there is no guarantee that you will indeed
    obtain the requested number of features within the specified number of iterations.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将迭代检测兴趣点。每次迭代后，都会检查检测到的点的数量，并根据需要调整检测器的阈值以产生更多或更少的点；这个过程会重复，直到检测到的点的数量符合指定的区间。指定一个最大迭代次数，以避免该方法在多次检测上花费太多时间。为了以通用方式实现此方法，所使用的`cv::FeatureDetector`类必须实现`cv::AdjusterAdapter`接口。这个类包括一个`tooFew`方法和一个`tooMany`方法，这两个方法都修改检测器的内部阈值以产生更多或更少的关键点。还有一个`good`谓词方法，如果检测器的阈值还可以调整，则返回`true`。使用`cv::DynamicAdaptedFeatureDetector`类可以是一个获得适当数量特征点的良好策略；然而，你必须理解，为了这个好处，你必须付出性能代价。此外，没有保证你确实能在指定的迭代次数内获得所需数量的特征。
- en: You probably noticed that we passed an argument, which is the address of a dynamically
    allocated object, to specify the feature detector that will be used by the adapter
    class. You might wonder whether you have to release the allocated memory at some
    point in order to avoid memory leaks. The answer is no, and this is because the
    pointer is transferred to a `cv::Ptr<FeatureDetector>` parameter that automatically
    releases the pointed object.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，我们传递了一个参数，即动态分配对象的地址，以指定适配器类将使用的特征检测器。你可能想知道是否需要在某个时候释放分配的内存以避免内存泄漏。答案是无需释放，这是因为指针被转移到`cv::Ptr<FeatureDetector>`参数，该参数会自动释放指向的对象。
- en: Grid adapted feature detection
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网格适应特征检测
- en: 'A second useful class adapter is the `cv::GridAdaptedFeatureDetector` class.
    As the name suggests, it allows you to define a grid over the image. Each cell
    of this grid is then constrained to contain a maximum number of elements. The
    idea here is to spread the set of detected keypoints over the image in a better
    manner. When detecting keypoints in an image, it is indeed common to see a concentration
    of interest points in a specific textured area. This is the case, for example,
    of the two towers of the church image on which a very dense set of FAST points
    have been detected. This class adapter is used as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个有用的类适配器是`cv::GridAdaptedFeatureDetector`类。正如其名所示，它允许你在图像上定义一个网格。然后，这个网格的每个单元格都被限制只能包含最大数量的元素。这里的想法是将检测到的关键点集在图像上以更好的方式分布。在检测图像中的关键点时，确实常见到在特定纹理区域有大量兴趣点的集中。例如，在教堂图像的两个塔上，检测到了一个非常密集的FAST点集。这个类适配器可以这样使用：
- en: '[PRE16]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The class adapter simply proceeds by detecting feature points on each individual
    cell using the provided `cv::FeatureDetector` object. A maximum total number of
    points is also specified. Only the strongest points in each cell are kept in order
    to not exceed the specified maximum.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 类适配器简单地通过使用提供的`cv::FeatureDetector`对象在每个单独的单元格上检测特征点来继续进行。还指定了最大点数。为了不超过指定的最大值，只保留每个单元格中最强的点。
- en: Pyramid adapted feature detection
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 金字塔适应特征检测
- en: 'The `cv::PyramidAdaptedFeatureDetector` adapter proceeds by applying the feature
    detector on an image pyramid. The results are combined in the output vector of
    keypoints. This is called as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv::PyramidAdaptedFeatureDetector`适配器通过在图像金字塔上应用特征检测器来继续进行。结果被组合在关键点的输出向量中。这可以通过以下方式实现：'
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The coordinates of each point are specified in the original image coordinates.
    In addition, the special `size` attribute of the `cv::Keypoint` class is set such
    that points detected at half the original resolution are attributed a size that
    is twice the size of the detected points in the original image. There is a special
    flag in the `cv::drawKeypoints` function that will draw the keypoints with a radius
    that is equal to the keypoint's `size` attribute.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 每个点的坐标都指定在原始图像坐标中。此外，`cv::Keypoint`类的特殊`size`属性被设置为，在原始分辨率的一半处检测到的点被赋予的尺寸是原始图像中检测到的点尺寸的两倍。`cv::drawKeypoints`函数中有一个特殊标志，它将以与关键点`size`属性相等的半径绘制关键点。
- en: '![Pyramid adapted feature detection](img/00135.jpeg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![金字塔适应特征检测](img/00135.jpeg)'
- en: See also
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考阅读
- en: The article by E. Rosten and T. Drummond*, Machine learning for high-speed corner
    detection, In European Conference on Computer Vision, pp. 430-443, 2006*, describes
    the FAST feature algorithm and its variants in detail
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: E. Rosten和T. Drummond*的论文《高速角点检测中的机器学习》，载于欧洲计算机视觉会议，第430-443页，2006*，详细描述了FAST特征算法及其变体。
- en: Detecting scale-invariant features
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测尺度不变特征
- en: The view invariance of feature detection was presented as an important concept
    in the introduction of this chapter. While orientation invariance, which is the
    ability to detect the same points even if an image is rotated, has been relatively
    well handled by the simple feature point detectors that have been presented so
    far, the invariance to scale changes is more difficult to achieve. To address
    this problem, the concept of scale-invariant features has been introduced in computer
    vision. The idea here is to not only have a consistent detection of keypoints
    no matter at which scale an object is pictured, but to also have a scale factor
    associated with each of the detected feature points. Ideally, for the same object
    point featured at two different scales on two different images, the ratio of the
    two computed scale factors should correspond to the ratio of their respective
    scales. In recent years, several scale-invariant features have been proposed,
    and this recipe presents one of them, the **SURF** features. SURF stands for Speeded
    Up Robust Features, and as we will see, they are not only scale-invariant features,
    but they also offer the advantage of being computed very efficiently.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 特征检测的视角不变性在本章的引言中被提出作为一个重要概念。虽然方向不变性，即即使图像旋转也能检测到相同点的能力，已经被迄今为止提出的简单特征点检测器相对较好地处理，但尺度变化的不变性更难实现。为了解决这个问题，计算机视觉中引入了尺度不变特征的概念。这里的想法是，无论物体在何种尺度下被拍摄，都要保持关键点的检测一致性，并且每个检测到的特征点都要关联一个尺度因子。理想情况下，对于在两张不同图像上以不同尺度特征化的同一物体点，两个计算尺度因子的比率应该对应它们各自尺度的比率。近年来，已经提出了几种尺度不变特征，本菜谱介绍了其中之一，即**SURF**特征。SURF代表加速鲁棒特征，正如我们将看到的，它们不仅是尺度不变特征，而且计算效率也非常高。
- en: How to do it...
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The SURF feature detector is implemented in OpenCV in the `cv::SURF` function.
    It is also possible to use this through `cv::FeatureDetector` as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: SURF特征检测器在OpenCV中通过`cv::SURF`函数实现。也可以通过`cv::FeatureDetector`使用它，如下所示：
- en: '[PRE18]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To draw these features, we again use the `cv::drawKeypoints` OpenCV function
    with the `DRAW_RICH_KEYPOINTS` flag such that we can visualize the associated
    scale factor:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要绘制这些特征，我们再次使用带有`DRAW_RICH_KEYPOINTS`标志的`cv::drawKeypoints` OpenCV函数，这样我们就可以可视化相关的尺度因子：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The resulting image with the detected features is then as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 检测到特征的结果图像如下：
- en: '![How to do it...](img/00136.jpeg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00136.jpeg)'
- en: As explained in the previous recipe, the size of the keypoint circles resulting
    from the use of the `DRAW_RICH_KEYPOINTS` flag is proportional to the computed
    scale of each feature. The SURF algorithm also associates an orientation with
    each feature to make them invariant to rotations. This orientation is illustrated
    by a radial line inside each drawn circle.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一个菜谱中所述，使用`DRAW_RICH_KEYPOINTS`标志得到的关键点圆圈的大小与每个特征的计算尺度成正比。SURF算法还与每个特征关联一个方向，以使它们对旋转不变。这个方向通过每个绘制圆圈内的辐射线表示。
- en: 'If we take another picture of the same object but at a different scale, the
    feature-detection result is as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以不同的尺度拍摄同一物体的另一张照片，特征检测的结果如下：
- en: '![How to do it...](img/00137.jpeg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00137.jpeg)'
- en: By carefully observing the detected keypoints on the two images, it can be seen
    that the change in the size of corresponding circles is often proportional to
    the change in scale. As an example, consider the bottom part of the upper-right
    window of the church. In both images, a SURF feature has been detected at that
    location, and the two corresponding circles (of different sizes) contain the same
    visual elements. Of course, this is not the case for all features, but as we will
    discover in the next chapter, the repeatability rate is sufficiently high to allow
    good matching between the two images.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仔细观察两张图像上检测到的关键点，可以看出对应圆圈大小的变化通常与尺度变化成正比。例如，考虑教堂右上角窗户的底部部分。在两张图像中，都检测到了该位置的SURF特征，并且两个对应的不同大小的圆圈包含相同的视觉元素。当然，并非所有特征都如此，但正如我们在下一章将要发现的，重复率足够高，可以保证两张图像之间良好的匹配。
- en: How it works...
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In [Chapter 6](part0047_split_000.html#page "Chapter 6. Filtering the Images"),
    *Filtering the Images*, we learned that the derivatives of an image can be estimated
    using Gaussian filters. These filters make use of a `σ` parameter, which defines
    the aperture (size) of the kernel. As we saw, this `σ` parameter corresponds to
    the variance of the Gaussian function used to construct the filter, and it then
    implicitly defines a scale at which the derivative is evaluated. Indeed, a filter
    that has a larger `σ` value smoothes out the finer details of the image. This
    is why we can say that it operates at a coarser scale.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](part0047_split_000.html#page "第6章。图像滤波")，“图像滤波”中，我们了解到可以使用高斯滤波器估计图像的导数。这些滤波器使用一个`σ`参数，该参数定义了核的孔径（大小）。正如我们所见，这个`σ`参数对应于构建滤波器使用的高斯函数的方差，并且它隐式地定义了导数评估的尺度。确实，具有较大`σ`值的滤波器会平滑掉图像的更细的细节。这就是为什么我们可以说它在一个更粗的尺度上操作。
- en: Now, if we compute, for instance, the Laplacian of a given image point using
    Gaussian filters at different scales, then different values are obtained. Looking
    at the evolution of the filter response for different scale factors, we obtain
    a curve that eventually reaches a maximum value at a `σ` value. If we extract
    this maximum value for two images of the same object taken at two different scales,
    the ratio of these two `σ` maxima will correspond to the ratio of the scales at
    which the images were taken. This important observation is at the core of the
    scale-invariant feature extraction process. That is, scale-invariant features
    should be detected as the local maxima in both the spatial space (in the image)
    and the scale space (as obtained from the derivative filters applied at different
    scales).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们使用高斯滤波器在不同尺度上计算给定图像点的拉普拉斯算子，那么会得到不同的值。观察不同尺度因子下滤波器响应的变化，我们得到一条曲线，最终在`σ`值处达到最大值。如果我们从两个不同尺度拍摄的同物图像中提取这个最大值，这两个`σ`最大值之比将对应于拍摄图像的尺度比。这个重要的观察结果是尺度不变特征提取过程的核心。也就是说，尺度不变特征应该在空间空间（在图像中）和尺度空间（从不同尺度应用导数滤波器获得）中的局部最大值中被检测到。
- en: 'SURF implements this idea by proceeding as follows. First, to detect the features,
    the Hessian matrix is computed at each pixel. This matrix measures the local curvature
    of a function and is defined as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: SURF通过以下步骤实现这一想法。首先，为了检测特征，计算每个像素处的Hessian矩阵。这个矩阵衡量函数的局部曲率，定义为以下：
- en: '![How it works...](img/00138.jpeg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00138.jpeg)'
- en: The determinant of this matrix gives you the strength of this curvature. The
    idea, therefore, is to define corners as image points with high local curvature
    (that is, high variation in more than one direction). Since it is composed of
    second-order derivatives, this matrix can be computed using Laplacian of Gaussian
    kernels of a different scale, such as `σ`. This Hessian then becomes a function
    of three variables, which are `H(x,y,σ)`. Therefore, a scale-invariant feature
    is declared when the determinant of this Hessian reaches a local maximum in both
    spatial and scale space (that is, `3x3x3` non-maxima suppression needs to be performed).
    Note that in order to be considered as a valid point, this determinant must have
    a minimum value as specified by the first parameter in the constructor of the
    `cv::SURF` class.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这个矩阵的行列式给出了这个曲率的强度。因此，定义角点为具有高局部曲率（即，在多个方向上变化很大）的图像点。由于它由二阶导数组成，这个矩阵可以使用不同尺度的高斯拉普拉斯核来计算，例如`σ`。因此，Hessian成为一个关于三个变量的函数，即`H(x,y,σ)`。因此，当这个Hessian的行列式在空间和尺度空间中都达到局部最大值时（即，需要进行`3x3x3`非最大值抑制），就宣布存在一个尺度不变特征。请注意，为了被视为一个有效点，这个行列式必须具有由`cv::SURF`类的构造函数的第一个参数指定的最小值。
- en: 'However, the calculation of all of these derivatives at different scales is
    computationally costly. The objective of the SURF algorithm is to make this process
    as efficient as possible. This is achieved by using approximated Gaussian kernels
    that involve only few integer additions. These have the following structure:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在不同尺度上计算所有这些导数在计算上代价高昂。SURF算法的目标是尽可能使这个过程高效。这是通过使用仅涉及少量整数加法的近似高斯核来实现的。这些核具有以下结构：
- en: '![How it works...](img/00139.jpeg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00139.jpeg)'
- en: The kernel on the left-hand side is used to estimate the mixed second derivatives,
    while the one on the right-hand side estimates the second derivative in the vertical
    direction. A rotated version of this second kernel estimates the second derivative
    in the horizontal direction. The smallest kernels have a size of `9x9` pixels,
    corresponding to `σ≈1.2`. To obtain a scale-space representation, kernels of increasing
    size are successively applied. The exact number of filters that are applied can
    be specified by additional parameters of the SURF class. By default, 12 different
    sizes of kernels are used (going up to size `99x99`). Note that the fact that
    integral images are used guarantees that the sum inside each lobe of each filter
    can be computed by using only three additions independent of the size of the filter.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧的核心用于估计混合的二阶导数，而右侧的核心用于估计垂直方向上的二阶导数。这个二阶核心的旋转版本用于估计水平方向上的二阶导数。最小的核心大小为`9x9`像素，对应于`σ≈1.2`。为了获得尺度空间表示，依次应用不同大小的核心。可以由SURF类的附加参数指定应用的确切滤波器数量。默认情况下，使用12种不同大小的核心（最大到`99x99`）。请注意，使用积分图像保证了每个滤波器每个波峰内部的和可以通过仅使用三个与滤波器大小无关的加法来计算。
- en: Once the local maxima are identified, the precise position of each detected
    interest point is obtained through interpolation in both scale and image space.
    The result is then a set of feature points that are localized at sub-pixel accuracy
    and to which a scale value is associated.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了局部极大值，通过在尺度和图像空间中进行插值，就可以获得每个检测到的兴趣点的精确位置。结果是具有亚像素精度的特征点集，并且与一个尺度值相关联。
- en: There's more...
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多...
- en: The SURF algorithm has been developed as an efficient variant of another well-known
    scale-invariant feature detector called **SIFT** (**Scale-Invariant Feature Transform**).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: SURF算法被开发为一个效率更高的变体，称为另一个著名的尺度不变特征检测器**SIFT**（**尺度不变特征变换**）。
- en: The SIFT feature-detection algorithm
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SIFT特征检测算法
- en: SIFT also detects features as local maxima in the image and scale space but
    uses the Laplacian filter response instead of the Hessian determinant. This Laplacian
    is computed at different scales (that is, increasing values of `σ`) using the
    difference of Gaussian filters, as explained in [Chapter 6](part0047_split_000.html#page
    "Chapter 6. Filtering the Images"), *Filtering the Images*. To improve efficiency,
    each time the value of `σ` is doubled, the size of the image is reduced by two.
    Each pyramid level corresponds to an **octave**, and each scale is a *layer*.
    There are typically three layers per octave.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: SIFT同样在图像和尺度空间中检测特征作为局部极大值，但使用拉普拉斯滤波器响应而不是海森矩阵。这个拉普拉斯在不同的尺度（即`σ`的增大值）上使用高斯滤波器的差值来计算，如[第6章](part0047_split_000.html#page
    "第6章. 过滤图像")中所述，*过滤图像*。为了提高效率，每次`σ`的值加倍时，图像的大小就减少两倍。每个金字塔层对应一个**八度**，每个尺度是一个**层**。通常每个八度有三个层。
- en: 'The following figure illustrates a pyramid of two octaves in which the four
    Gaussian-filtered images of the first octave produce three DoG layers:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了两个八度的金字塔，其中第一个八度的四个高斯滤波图像产生了三个DoG层：
- en: '![The SIFT feature-detection algorithm](img/00140.jpeg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![SIFT特征检测算法](img/00140.jpeg)'
- en: 'OpenCV has a class that detects these features, and it is called in a way that
    is similar to the SURF one:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV有一个类可以检测这些特征，其调用方式与SURF类似：
- en: '[PRE20]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here, we use all the default arguments to construct the detector, but you can
    specify the number of desired SIFT points (the strongest ones are kept), the number
    of layers per octave, and the initial value for `σ`. The result is similar to
    the one obtained with SURF:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用所有默认参数来构建检测器，但你也可以指定所需的SIFT点数（保留最强的点），每个八度的层数，以及`σ`的初始值。结果是类似于使用SURF获得的结果：
- en: '![The SIFT feature-detection algorithm](img/00141.jpeg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![SIFT特征检测算法](img/00141.jpeg)'
- en: However, since the computation of the feature point is based on floating-point
    kernels, SIFT is generally considered to be more accurate in terms of feature
    localization in regards to space and scale. For the same reason, it is also more
    computationally expensive, although this relative efficiency depends on each particular
    implementation.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于特征点的计算基于浮点核心，SIFT在空间和尺度上的特征定位方面通常被认为更准确。同样地，它也更耗费计算资源，尽管这种相对效率取决于每个特定的实现。
- en: As a final remark, you might have noticed that the SURF and SIFT classes have
    been placed in a nonfree package of the OpenCV distribution. This is because these
    algorithms have been patented, and as such, their use in commercial applications
    might be subject to licensing agreements.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点，你可能已经注意到，SURF和SIFT类被放置在OpenCV分布的非自由软件包中。这是因为这些算法已经获得专利，因此，它们在商业应用中的使用可能受到许可协议的约束。
- en: See also
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Computing the Laplacian of an image* recipe in [Chapter 6](part0047_split_000.html#page
    "Chapter 6. Filtering the Images"), *Filtering the Images*, gives you more details
    on the Laplacian-of-Gaussian operator and the use of the difference of Gaussians
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第6章](part0047_split_000.html#page "第6章. 过滤图像")中的*计算图像拉普拉斯算子*配方，*过滤图像*，为你提供了更多关于高斯拉普拉斯算子和高斯差分使用的细节'
- en: The *Describing local intensity patterns* recipe in [Chapter 9](part0063_split_000.html#page
    "Chapter 9. Describing and Matching Interest Points"), *Describing and Matching
    Interest Points*, explains how these scale-invariant features can be described
    for robust image matching
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第9章](part0063_split_000.html#page "第9章. 描述和匹配兴趣点")中的*描述局部强度模式*配方，*描述和匹配兴趣点*，解释了如何描述这些尺度不变特征以实现鲁棒的图像匹配'
- en: 'The article *SURF: Speeded Up Robust Features* by H. Bay, A. Ess, T. Tuytelaars
    and L. Van Gool in *Computer Vision and Image Understanding, vol. 110, No. 3,
    pp. 346-359, 2008*, describes the SURF feature algorithm'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H. Bay, A. Ess, T. Tuytelaars和L. Van Gool在*计算机视觉与图像理解，第110卷，第3期，第346-359页，2008年*上发表的*SURF：加速鲁棒特征*文章描述了SURF特征算法
- en: The pioneering work by D. Lowe*, Distinctive Image Features from Scale Invariant
    Features* in *International Journal of Computer Vision, Vol. 60, No. 2, 2004,
    pp. 91-110*, describes the SIFT algorithm
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: D. Lowe在*国际计算机视觉杂志，第60卷，第2期，2004年，第91-110页*上发表的*从尺度不变特征中提取独特图像特征*的开创性工作描述了SIFT算法
- en: Detecting FAST features at multiple scales
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在多个尺度上检测FAST特征
- en: FAST has been introduced as a quick way to detect keypoints in an image. With
    SURF and SIFT, the emphasis was on designing scale-invariant features. More recently,
    new interest point detectors have been introduced with the objective of achieving
    both fast detection and invariance to scale changes. This recipe presents the
    **Binary Robust Invariant Scalable Keypoints** (**BRISK**) detector. It is based
    on the FAST feature detector that we described in a previous recipe of this chapter.
    Another detector, called **ORB** (**Oriented FAST and Rotated BRIEF**), will also
    be discussed at the end of this recipe. These two feature point detectors constitute
    an excellent solution when fast and reliable image matching is required. They
    are especially efficient when they are used in conjunction with their associated
    binary descriptors, as will be discussed in [Chapter 9](part0063_split_000.html#page
    "Chapter 9. Describing and Matching Interest Points"), *Describing and Matching
    Interest Points*.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: FAST被引入作为一种快速检测图像中关键点的方法。与SURF和SIFT相比，重点是设计尺度不变特征。最近，新引入了兴趣点检测器，旨在实现快速检测和尺度变化的不变性。本配方介绍了**二值鲁棒不变可缩放关键点**（**BRISK**）检测器。它基于我们在本章前面的配方中描述的FAST特征检测器。另一种称为**ORB**（**方向性FAST和旋转BRIEF**）的检测器也将在本配方的末尾讨论。这两个特征点检测器构成了在需要快速且可靠的图像匹配时的优秀解决方案。当它们与相关的二进制描述符一起使用时，效率尤其高，这将在[第9章](part0063_split_000.html#page
    "第9章. 描述和匹配兴趣点")，*描述和匹配兴趣点*中讨论。
- en: How to do it...
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Following what we did in the previous recipes, the detection of keypoints with
    BRISK uses the `cv::FeatureDetector` abstract class. We first create an instance
    of the detector, and then the `detect` method is called on an image:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 按照我们在前面的配方中所做的，使用BRISK检测关键点的过程使用了`cv::FeatureDetector`抽象类。我们首先创建检测器的实例，然后在图像上调用`detect`方法：
- en: '[PRE21]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The image result shows you the keypoints that are detected at multiple scales:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图像结果显示了在多个尺度上检测到的关键点：
- en: '![How to do it...](img/00142.jpeg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/00142.jpeg)'
- en: How it works...
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: BRISK is not only a feature point detector; the method also includes a procedure
    that describes the neighborhood of each detected keypoint. This second aspect
    will be the subject of the next chapter. We describe here how the quick detection
    of keypoints at multiple scales is performed using BRISK.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: BRISK不仅是一个特征点检测器；该方法还包括描述每个检测到的关键点邻域的程序。这一第二个方面将是下一章的主题。在这里，我们描述了如何使用BRISK在多个尺度上快速检测关键点。
- en: In order to detect interest points at different scales, the method first builds
    an image pyramid through two down-sampling processes. The first process starts
    from the original image size and downscales it by half at each layer (or octave).
    Secondly, in-between layers are created by down-sampling the original image by
    a factor of 1.5, and from this reduced image, additional layers are generated
    through successive half-sampling.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在不同尺度上检测兴趣点，该方法首先通过两个下采样过程构建一个图像金字塔。第一个过程从原始图像大小开始，并在每一层（或八分音符）上将它减半。其次，通过将原始图像以
    1.5 的因子下采样，在中间层之间创建层，然后通过连续的半采样从这个减少的图像生成额外的层。
- en: '![How it works...](img/00143.jpeg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/00143.jpeg)'
- en: The FAST feature detector is then applied on all the images of this pyramid.
    Keypoint extraction is based on a criterion that is similar to the one used by
    SIFT. First, an acceptable interest point must be a local maximum when comparing
    its strength with one of its eight spatial neighbors. If this is the case, the
    point is then compared with the scores of the neighboring points in the layers
    above and below; if its score is higher in scale as well, then it is accepted
    as an interest point. A key aspect of BRISK resides in the fact that the different
    layers of the pyramid have different resolutions. The method requires interpolation
    in both scale and space in order to locate each keypoint precisely. This interpolation
    is based on the FAST keypoint scores. In space, the interpolation is performed
    on a 3 x 3 neighborhood. In scale, it is computed by fitting a 1D parabola along
    the scale axis through the current point and its two neighboring local keypoints
    in the layers above and below; this keypoint localization in scale is illustrated
    in the preceding figure. As a result, even if the FAST keypoint detection is performed
    at discrete image scales, the resulting detected scales associated with each keypoint
    are continuous values.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将 FAST 特征检测器应用于这个金字塔的所有图像。关键点提取基于与 SIFT 相似的标准。首先，一个可接受的兴趣点在将其强度与其八个空间邻居之一比较时必须是局部最大值。如果是这样，该点随后将与上层和下层相邻点的分数进行比较；如果其分数在尺度上更高，则它被接受为兴趣点。BRISK
    的一个关键方面在于金字塔的不同层具有不同的分辨率。该方法需要在尺度和空间上进行插值，以精确地定位每个关键点。这种插值基于 FAST 关键点分数。在空间上，插值在
    3 x 3 邻域内进行。在尺度上，它通过沿尺度轴通过当前点及其上层和下层两个相邻局部关键点拟合一个一维抛物线来计算；这种尺度上的关键点定位在先前的图中进行了说明。因此，即使
    FAST 关键点检测是在离散图像尺度上进行的，与每个关键点相关联的检测尺度也是连续值。
- en: 'The `cv::BRISK` class proposes two optional parameters to control the detection
    of the keypoints. The first parameter is a threshold value that accepts FAST keypoints,
    and the second parameter is the number of octaves that will be generated in the
    image pyramid:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv::BRISK` 类提出了两个可选参数来控制关键点的检测。第一个参数是一个阈值值，它接受 FAST 关键点，第二个参数是将在图像金字塔中生成的八分音符的数量：'
- en: '[PRE22]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: There's more...
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: BRISK is not the only multiscale, fast detector that is proposed in OpenCV.
    The ORB feature detector can also perform efficient keypoint detection.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: BRISK 并不是 OpenCV 中唯一被提出的多尺度快速检测器。ORB 特征检测器也能进行高效的关键点检测。
- en: The ORB feature-detection algorithm
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ORB 特征检测算法
- en: ORB stands for **Oriented FAST and Rotated BRIEF**. The first part of this acronym
    refers to the keypoint detection part, while the second part refers to the descriptor
    that is proposed by ORB. Here, we focus here on the detection method; the descriptor
    will be presented in the next chapter.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ORB 代表 **Oriented FAST and Rotated BRIEF**。这个缩写的第一部分指的是关键点检测部分，而第二部分指的是 ORB
    提出的描述符。在这里，我们主要关注检测方法；描述符将在下一章中介绍。
- en: As with BRISK, ORB first creates an image pyramid. This one is made of a number
    of layers in which each layer is a down-sampled version of the previous one by
    a certain scale factor (typically, `8` scales and `1.2` scale factor reduction;
    these are parameters in the `cv::ORB` function). The strongest `N` keypoints are
    then accepted where the keypoint score is defined by the Harris *cornerness* measure
    that was defined in the first recipe of this chapter (authors of this method found
    the Harris score to be a more reliable measure).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 与BRISK类似，ORB首先创建一个图像金字塔。这个金字塔由多个层组成，每一层是前一层通过一定比例因子（通常是`8`个比例和`1.2`的比例因子减小；这些是`cv::ORB`函数中的参数）下采样得到的。然后接受得分最高的`N`个关键点，其中关键点得分由本章第一道菜中定义的Harris
    *角点*度量来定义（该方法作者发现Harris得分是一个更可靠的度量）。
- en: An original aspect of the ORB detector resides in the fact that an orientation
    is associated with each detected interest point. As we will see in the next chapter,
    this information will be useful to align the descriptors of keypoints detected
    in different images. In the *Computing components' shape descriptors* recipe of
    [Chapter 7](part0052_split_000.html#page "Chapter 7. Extracting Lines, Contours,
    and Components"), *Extracting Lines, Contours, and Components*, we introduced
    the concept of image moments and in particular, we showed you how the centroid
    of a component can be computed from its first three moments. ORB proposes that
    we use the orientation of the centroid of a circular neighborhood around the keypoint.
    Since, FAST keypoints, by definition, always have a decentered centroid, the angle
    of the line that joins the central point and the centroid will always be well
    defined.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ORB检测器的原始特点在于每个检测到的兴趣点都与一个方向相关联。正如我们将在下一章中看到的，这些信息将有助于对齐在不同图像中检测到的关键点的描述符。在[第7章](part0052_split_000.html#page
    "第7章. 提取线、轮廓和组件")的《计算组件形状描述符》菜谱中，我们介绍了图像矩的概念，特别是我们展示了如何从组件的前三个矩计算其质心。ORB建议我们使用围绕关键点的圆形邻域的质心的方向。由于，根据定义，FAST关键点总是有一个偏心的质心，连接中心点和质心的线的角度总是定义良好的。
- en: 'The ORB features are detected as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ORB特征检测如下：
- en: '[PRE23]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This call produces the following result:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 此调用产生以下结果：
- en: '![The ORB feature-detection algorithm](img/00144.jpeg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![ORB特征检测算法](img/00144.jpeg)'
- en: As can be seen, since the keypoints are independently detected on each pyramid
    layer, the detector tends to repeatedly detect the same feature point at different
    scales.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如所见，由于关键点在每个金字塔层上独立检测，检测器倾向于在不同尺度上重复检测相同的特征点。
- en: See also
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Describing keypoints with binary features* recipe in [Chapter 9](part0063_split_000.html#page
    "Chapter 9. Describing and Matching Interest Points"), *Describing and Matching
    Interest Points*, explains how simple binary descriptors can be used for efficient
    robust matching of these features
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第9章](part0063_split_000.html#page "第9章. 描述和匹配兴趣点")的《使用二进制特征描述关键点》菜谱解释了如何使用简单的二进制描述符进行这些特征的效率鲁棒匹配'
- en: 'The article *BRISK: Binary Robust Invariant Scalable Keypoint by* S. Leutenegger,
    M. Chli and R. Y. Siegwart in *IEEE International Conference on Computer Vision,
    pp. 2448--2555, 2011*, describes the BRISK feature algorithm'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文章《BRISK：基于二值鲁棒不变可伸缩关键点的算法》由S. Leutenegger、M. Chli和R. Y. Siegwart在2011年的《IEEE国际计算机视觉会议，第2448-2555页》中描述了BRISK特征算法
- en: 'The article *ORB: an efficient alternative to SIFT or SURF* by E. Rublee, V.
    Rabaud, K. Konolige and G. Bradski in *IEEE International Conference on Computer
    Vision, pp.2564-2571, 2011*, describes the ORB feature algorithm'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文章《ORB：SIFT或SURF的有效替代方案》由E. Rublee、V. Rabaud、K. Konolige和G. Bradski在2011年的《IEEE国际计算机视觉会议，第2564-2571页》中描述了ORB特征算法
