- en: '16'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '16'
- en: Designing Generative AI Platforms and Solutions
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计生成式AI平台和解决方案
- en: Deploying generative AI at scale in an enterprise introduces new complexities
    around infrastructure, tooling, and operational processes required to harness
    its potential while managing risks. This chapter explores the essential components
    for building robust generative AI platforms and examines **Retrieval-Augmented
    Generation** (**RAG**), an effective architecture pattern for generative applications.
    Additionally, we highlight near-term generative AI solution opportunities ripe
    for business adoption across industries. With the right platform foundations and
    a pragmatic approach focused on delivering tangible value, enterprises can start
    realizing benefits from generative AI today while paving the way for increasing
    innovation as this technology matures. Readers will gain insight into the practical
    building blocks and strategies that accelerate generative AI adoption.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业中大规模部署生成式AI引入了新的复杂性，围绕基础设施、工具和运营流程，这些流程对于利用其潜力同时管理风险是必需的。本章探讨了构建稳健生成式AI平台的基本组件，并考察了**检索增强生成**（**RAG**），这是一种有效的生成应用架构模式。此外，我们还强调了适合行业商业采用的近期能够成熟的生成式AI解决方案机会。有了正确的平台基础和关注于提供实际价值的实用方法，企业今天就可以开始从生成式AI中获益，并为随着该技术的成熟而不断增加的创新铺平道路。读者将深入了解加速生成式AI采用的实用构建块和策略。
- en: 'Specifically, this chapter is going to cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，本章将涵盖以下主题：
- en: Operational considerations for generative AI platforms and solutions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI平台和解决方案的运营考虑因素
- en: The retrieval-augmented generation pattern
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索增强生成模式
- en: Choosing a **Large Language Model** (**LLM**) adaptation method
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择**大型语言模型**（**LLM**）适配方法
- en: End-to-end generative AI platforms
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端到端生成式AI平台
- en: Considerations for deploying generative AI applications in production
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署生成式AI应用程序的生产考虑因素
- en: Practical generative AI business solutions
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实用的生成式AI商业解决方案
- en: Are we close to artificial general intelligence?
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否接近通用人工智能？
- en: Operational considerations for generative AI platforms and solutions
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI平台和解决方案的运营考虑因素
- en: In an enterprise, deploying generative AI solutions at scale requires robust
    infrastructure, tools, and operations. Organizations should contemplate establishing
    a dedicated generative AI platform to meet these evolving project demands.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业中，大规模部署生成式AI解决方案需要稳健的基础设施、工具和运营。组织应考虑建立一个专门的生成式AI平台来满足这些不断变化的项目需求。
- en: Architecturally and operationally, a generative AI platform builds on top of
    an ML platform with additional new and enhanced technology infrastructure for
    large-scale model training, large model hosting, model evaluation, guardrails,
    and model monitoring. As such, the core operation and automation requirements
    for a generative AI platform are similar to those of a traditional MLOps practice.
    However, the unique aspects of generative AI projects such as model selection,
    model tuning, and integration with external data sources, require several new
    process workflows to be established, and as a result, new technology components
    need to be incorporated into the operation and automation of the AI/ML platform.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在架构和运营方面，生成式AI平台建立在ML平台之上，并增加了新的和增强的技术基础设施，用于大规模模型训练、大型模型托管、模型评估、安全措施和模型监控。因此，生成式AI平台的核心运营和自动化需求与传统MLOps实践相似。然而，生成式AI项目独特的方面，如模型选择、模型调整和与外部数据源的集成，需要建立几个新的流程工作流程，因此，需要将新的技术组件纳入AI/ML平台的运营和自动化中。
- en: In this section, we will delve into several new business and operational workflows
    involved in building and running generative AI initiatives, and their implication
    in new technology requirements and new functional roles.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将深入探讨涉及构建和运行生成式AI项目的新业务和运营工作流程，以及它们在新技术需求和新的职能角色中的影响。
- en: New generative AI workflow and processes
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新的生成式AI工作流程和流程
- en: One of the key steps in building generative AI solutions is to select the right
    foundation models for further evaluation and/or fine-tuning against the requirements.
    Before generative AI, data scientists were mainly concerned with selecting the
    right algorithms to train models from scratch. While there were techniques such
    as transfer learning available, the scope was small, and mainly limited to some
    computer vision tasks and tuning of language models such as BERT. With large foundation
    models, the process of model selection becomes a lot more involved, and the model-tuning
    process has evolved as well. While instruction fine-tuning remains similar to
    traditional supervised learning, **Reinforcement Learning Human Feedback** (**RLHF**)
    is a brand-new process to be considered.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 构建生成AI解决方案的关键步骤之一是选择合适的基座模型进行进一步评估和/或微调以满足需求。在生成AI之前，数据科学家主要关注选择合适的算法从头开始训练模型。虽然存在诸如迁移学习等技术，但其范围较小，主要限于一些计算机视觉任务以及BERT等语言模型的调整。随着大型基座模型的出现，模型选择的过程变得更加复杂，模型调整过程也发生了演变。虽然指令微调与传统监督学习相似，但**强化学习人类反馈**（**RLHF**）是一个全新的过程，需要考虑。
- en: A generative AI project also requires a new process to manage and evaluate different
    prompt templates against different generative AI models for different use cases.
    These templates need to be version-tracked against various versions of different
    generative AI models as part of experimentation and testing. Metadata such as
    descriptions of the templates, their intended use, and limitations need to be
    documented and tracked. Testing results for the different combination of templates
    and models need to be stored and managed. New capabilities such as prompt template
    generation and tuning are also required.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 生成AI项目还需要一个新的流程来管理和评估针对不同用例的不同生成AI模型的不同提示模板。这些模板需要与不同版本的生成AI模型进行版本跟踪，作为实验和测试的一部分。需要记录和跟踪有关模板的描述、预期用途和限制的元数据。还需要存储和管理不同模板和模型组合的测试结果。还需要新的功能，如提示模板生成和调整。
- en: Some generative AI use cases such as document search and retrieval also require
    a new workflow for generating embeddings for different data modalities. This requires
    a new architecture pattern for splitting the source data (e.g., documents) and
    running it through embedding models to generate embeddings. These processes often
    need to be tuned to support different embedding needs. Moreover, the knowledge
    encoded in pre-trained foundation models is frozen in time. To keep the knowledge
    up to date, continuous incremental pre-training is required with new, up-to-date
    datasets. This flow to source, process, and manage the new dataset to hydrate
    the knowledge of the foundation model requires new technology components to manage
    it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一些生成AI用例，如文档搜索和检索，也需要为不同数据模态生成嵌入的新工作流程。这需要一种新的架构模式来分割源数据（例如，文档）并通过嵌入模型生成嵌入。这些过程通常需要调整以支持不同的嵌入需求。此外，预训练基座模型中编码的知识是冻结在时间中的。为了保持知识的更新，需要使用新的、最新的数据集进行持续的增量预训练。这个过程需要新的技术组件来管理它。
- en: Lastly, as generative AI technology can generate factually incorrect and sometimes
    toxic information, a new monitoring capability is needed for detection. For example,
    a set of filters might be needed to detect potential adversarial prompting and
    monitor the output response for incorrect and toxic information.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于生成AI技术可以生成事实错误且有时具有毒性的信息，因此需要新的监控能力来进行检测。例如，可能需要一套过滤器来检测潜在的对抗性提示，并监控输出响应中的错误和有毒信息。
- en: New technology components
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新技术组件
- en: From a technology component perspective, some new tools such as vector databases
    and prompt stores, FM evaluation tools, and RLHF workflow tools are now needed
    to support the additional requirements. From a model deployment perspective, in
    addition to the deployment of large generative models themselves, new models are
    now needed for inspecting the inputs from the users and outputs from the model
    to ensure responsible AI principles are followed and adversarial attacks are detected
    and mitigated.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术组件的角度来看，现在需要一些新的工具来支持额外的需求，例如矢量数据库和提示存储、FM评估工具以及RLHF工作流程工具。从模型部署的角度来看，除了部署大型生成模型本身之外，还需要新的模型来检查用户的输入和模型的输出，以确保遵循负责任的AI原则，并检测和缓解对抗性攻击。
- en: New roles
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新角色
- en: In addition to the traditional roles and personas involved in ML projects and
    ML platforms, some new roles are now also required for building and using generative
    AI models. For example, to support RLHF, a new set of data annotators with domain
    expertise and language and linguistic proficiency is needed to help rate/rank
    responses. These annotators need knowledge to detect bias and harmful content,
    as well as being a good judge of the style and tone of texts. To support the development
    and testing of prompts, a new role called prompt engineer has also been established.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在ML项目和ML平台中涉及的传统角色和人物之外，现在还需要一些新的角色来构建和使用生成式AI模型。例如，为了支持RLHF，需要一套具有领域专业知识、语言和语言能力的数据标注员来帮助评估/排名响应。这些标注员需要具备检测偏见和有害内容的知识，同时还要能够很好地判断文本的风格和语气。为了支持提示的开发和测试，还设立了一个新的角色，即提示工程师。
- en: Exploring generative AI platforms
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索生成式AI平台
- en: A generative AI platform builds on top of an ML platform, with new technology
    components to support new workflows such as prompt management and FM benchmarking.
    It is a new, emerging concept yet to have commonly agreed-upon architecture patterns.
    The following diagram illustrates one example blueprint for building such a platform.
    Keep in mind that many of the proposed components will need to be custom-built
    as there is no managed or even open-source technology available.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI平台建立在ML平台之上，包含支持新工作流程如提示管理和FM基准测试的新技术组件。这是一个新兴的概念，尚未形成普遍认同的架构模式。以下图表展示了一个构建此类平台的示例蓝图。请注意，许多提议的组件将需要定制构建，因为目前没有现成的或开源的技术可用。
- en: '![](img/B20836_16_01.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B20836_16_01.png)'
- en: 'Figure 16.1: Generative AI platform'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.1：生成式AI平台
- en: 'As you can see from the preceding figure, the following new technology components
    will be needed to enhance the existing MLOps platform to support the needs of
    generative AI model development and deployment:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，为了增强现有的MLOps平台以支持生成式AI模型开发和部署的需求，以下新技术组件将需要被采用：
- en: '**Prompt management**: As one of the most important factors in getting desired
    responses from FMs, prompts need to be properly managed, tracked, and versioned.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示管理**：作为从FM获得期望响应的最重要因素之一，提示需要得到适当的处理、跟踪和版本控制。'
- en: '**FM benchmarking/playground workbench**: As the field continues to accelerate,
    we expect more FMs to become available. In addition, organizations will fine-tune
    existing FMs to create new models. To quickly determine if any new or fine-tuned
    FMs should be considered for different use cases, it is important to have an FM
    benchmark tool to quickly evaluate FMs against required criteria and use cases.
    Automation is critical as well as human-in-the-loop review and approval. Experiment
    tracking is also critical as part of the new capability to track and measure the
    performance of various prompts and response pairs.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FM基准测试/工作台**：随着该领域的快速发展，我们预计将有更多的FM变得可用。此外，组织将微调现有的FM以创建新的模型。为了快速确定任何新的或微调的FM是否应该考虑用于不同的用例，拥有一个FM基准工具来快速评估FM是否符合所需的标准和用例至关重要。自动化以及人工审查和批准同样关键。实验跟踪也是新能力的一部分，用于跟踪和衡量各种提示和响应对的性能。'
- en: '**Central foundation model repository**: Unlike a regular model registry, where
    the main purpose is to keep an inventory of all models. There is a need to maintain
    a list of approved FMs for the rest of the organization to use. Both the process
    of introducing new models into the central repository and the process of adopting
    it for various downstream tasks such as fine-tuning and additional pre-training
    need to be properly managed. In addition, many of the foundation models will come
    from third-party providers via an API, so the new model repository will need to
    handle proper listing and access provisioning on behalf of the third-party providers.
    Centralizing FM models, especially those from third-party sources, in a shared
    repository raises additional cybersecurity concerns. These models may potentially
    harbor vulnerabilities that could be exploited. To mitigate these risks, it is
    crucial to implement robust cybersecurity measures, including thorough security
    scans, before adding the models to the repository. This helps ensure the integrity
    and security of the model repository.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中心基础模型库**：与主要用于记录所有模型的常规模型注册库不同，需要维护一个获准使用的基础模型（FM）列表，供组织其他部分使用。将新模型引入中心库以及将其用于各种下游任务（如微调和额外预训练）的过程都需要得到妥善管理。此外，许多基础模型将通过API从第三方提供商处获得，因此新的模型库需要代表第三方提供商处理适当的列表和访问配置。在共享库中集中FM模型，特别是来自第三方来源的模型，会引发额外的网络安全担忧。这些模型可能潜在地包含可能被利用的漏洞。为了减轻这些风险，在将模型添加到库之前实施强大的网络安全措施至关重要，包括彻底的安全扫描。这有助于确保模型库的完整性和安全性。'
- en: '**Supervised fine-tuning and RLHF**: This component provides support for frequent
    instruction fine-tuning and domain adaptation incremental pre-training.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督微调和RLHF**：此组件提供对频繁的指令微调和领域自适应增量预训练的支持。'
- en: '**Enhanced model monitoring and filters**: The platform should provide a common
    set of capabilities to monitor in production both the input and output of models
    for bias, toxic content, and factually incorrect responses. These should be configurable
    capabilities that can meet the needs of different use cases and responsible AI
    requirements.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强模型监控和过滤器**：平台应提供一组通用的能力，用于在生产环境中监控模型的输入和输出，以检测偏差、有害内容和事实性错误响应。这些能力应该是可配置的，以满足不同用例和负责任的AI需求。'
- en: '**FM gateway**: Many organizations will likely adopt FMs from different internal
    and external sources and providers. A governed and secured FM gateway layer for
    accessing different FMs is a new platform component that needs to be implemented.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FM网关**：许多组织可能会从不同的内部和外部来源和提供商采用FM。一个受管理和安全的FM网关层，用于访问不同的FM，是必须实现的新平台组件。'
- en: Now, let’s take a closer look at some of the key components of a generative
    AI platform.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们更详细地看看生成式AI平台的一些关键组件。
- en: The prompt management component
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示管理组件
- en: 'The prompt management component integrates with various generative AI platform
    components, enriching workflows such as model evaluation, generative AI chat applications,
    and generative AI agent interactions. At its core, the prompt management component
    consists of two main layers: the store and the management layer.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 提示管理组件与各种生成式AI平台组件集成，丰富了如模型评估、生成式AI聊天应用和生成式AI代理交互等工作流程。在其核心，提示管理组件由两个主要层组成：存储和管理层。
- en: '![A diagram of a software application  Description automatically generated](img/B20836_16_02.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![软件应用图示 自动生成描述](img/B20836_16_02.png)'
- en: 'Figure 16.2: Prompt management component'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.2：提示管理组件
- en: In the preceding figure, the prompt management component illustrates the role
    of the management layer in overseeing a catalog of reusable, versioned prompt
    templates. This layer not only facilitates template authoring, tagging, and ingestion
    capabilities but also governs template access and consumption features, including
    the logging of usage history. It should also have workflow tools to automate the
    process for prompt approval and publishing. Other core functionalities could include
    a prompt recommendation engine based on context and automated prompt generation
    based on inputs and model targets.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，提示管理组件说明了管理层在监督一个可重用、版本化的提示模板目录中的作用。这一层不仅促进了模板的编写、标记和摄取功能，还管理着模板的访问和消费功能，包括使用历史的记录。它还应具备工作流程工具来自动化提示的审批和发布过程。其他核心功能可能包括基于上下文的提示推荐引擎和基于输入和模型目标的自动提示生成。
- en: For those opting to build this component on AWS, DynamoDB can serve as a viable
    choice for constructing the template store and managing usage history and metadata.
    The management layer and web UI can be implemented as a custom containerized software
    stack running on compute services like EKS. The API management layer can be easily
    implemented using AWS API Gateway.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于选择在 AWS 上构建此组件的用户，DynamoDB 可以作为构建模板存储和管理使用历史和元数据的可行选择。管理层和 Web UI 可以作为在计算服务如
    EKS 上运行的定制容器化软件堆栈来实现。API 管理层可以使用 AWS API Gateway 实现得非常容易。
- en: An API Gateway-enabled API access layer will be used to support both prompt
    store user applications and integration with other downstream and consuming applications
    and systems.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将使用 API Gateway 启用的 API 访问层来支持提示存储用户应用程序以及与其他下游和消费应用程序和系统的集成。
- en: FM benchmark workbench
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FM 基准工作台
- en: The following diagram illustrates a high-level architecture for building an
    FM benchmarking solution using AWS services.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示展示了使用 AWS 服务构建 FM 基准解决方案的高级架构。
- en: '![A diagram of a process  Description automatically generated](img/B20836_16_03.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![一个流程图，描述自动生成](img/B20836_16_03.png)'
- en: 'Figure 16.3: FM benchmark workbench'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.3：FM 基准工作台
- en: Within this architecture, target models sourced from a model registry are loaded
    into SageMaker endpoints. The testing process involves the generation of testing
    prompts by inserting various testing data from databases or S3 into predefined
    prompt templates, all of which are hosted within DynamoDB. These generated prompts
    are subsequently sent to the API endpoint for response generation. The resulting
    responses are evaluated using a predefined set of metrics, and the evaluation
    results are stored in DynamoDB. This stored data is made accessible to a workbench
    front-end application for further reference and utilization by the users.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在此架构中，从模型注册表中获取的目标模型被加载到 SageMaker 端点。测试过程涉及通过将各种测试数据从数据库或 S3 插入预定义的提示模板中生成测试提示，所有这些模板都托管在
    DynamoDB 中。随后，这些生成的提示被发送到 API 端点以生成响应。使用预定义的指标集评估生成的响应，并将评估结果存储在 DynamoDB 中。这些存储的数据可供工作台前端应用程序进一步参考和使用，供用户进一步利用。
- en: 'Amazon SageMaker now also has built-in model evaluation capabilities with its
    Clarify component. SageMaker Clarify’s **Foundation Model Evaluations** (**FMEval**)
    provides a centralized solution to assess model quality, fairness, and reliability
    across LLMs. It has support for both automated model evaluation and workflows
    for human evaluation. Some of the main tasks supported by the automated evaluation
    include:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 SageMaker 现在也通过其 Clarify 组件内置了模型评估功能。SageMaker Clarify 的 **基础模型评估**（**FMEval**）提供了一个集中解决方案，用于评估
    LLMs 的模型质量、公平性和可靠性。它支持自动模型评估和人工评估的工作流程。自动评估支持的主要任务包括：
- en: '**Open-ended text generation**: For this task, Clarify can automate evaluations
    for factual knowledge, semantic robustness, prompt stereotyping, and toxicity.
    Clarify provides default testing datasets including TREX, CrowS-Pairs, RealToxicityPrompt,
    and BOLD.'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**开放式文本生成**：对于这个任务，Clarify 可以自动化对事实知识、语义鲁棒性、提示刻板印象和毒性的评估。Clarify 提供了默认的测试数据集，包括
    TREX、CrowS-Pairs、RealToxicityPrompt 和 BOLD。'
- en: '**Text summarization**: With this task, Clarify can assess accuracy, toxicity,
    and semantic robustness. For this evaluation, Clarify has built-in datasets including
    Government Report dataset, gigaword, and XSum.'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文本摘要**：在这个任务中，Clarify 可以评估准确性、毒性和语义鲁棒性。为此评估，Clarify 内置了包括政府报告数据集、gigaword
    和 XSum 在内的数据集。'
- en: '**Question answering**: For question and answering tasks, Clarify also assesses
    accuracy, toxicity, and semantic robustness, with built-in datasets such as BoolQ,
    TriviaQA, and Natural Questions.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**问答**：对于问答任务，Clarify 还评估准确性、毒性和语义鲁棒性，内置数据集包括 BoolQ、TriviaQA 和 Natural Questions。'
- en: '**Classification**: For this task, Clarify uses Women’s E-Commerce Clothing
    Reviews to assess accuracy and semantic robustness.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分类**：对于这个任务，Clarify 使用女性电子商务服装评论来评估准确性和语义鲁棒性。'
- en: With automated evaluation, you can use built-in datasets or bring your own dataset
    for testing.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自动化评估，您可以使用内置数据集或自带数据集进行测试。
- en: To perform the human evaluation of a natural language processing model, you
    must first define the relevant metrics and metric types. A comparative rating
    can be used to evaluate multiple models side by side on those metrics. Individual
    rating is required for evaluating a single model. Both rating mechanisms are applicable
    to any text-related task.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行自然语言处理模型的人类评估，您必须首先定义相关的指标和指标类型。可以使用比较评分来评估多个模型在这些指标上的并列表现。对于评估单个模型，需要个别评分。这两种评分机制适用于任何与文本相关的任务。
- en: Supervised fine-tuning and RLHF
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督微调和 RLHF
- en: As organizations seek to customize FMs for their specific use cases, they need
    tools for fine-tuning and aligning FMs with human preferences and use cases. The
    core components of FM fine-tuning and RLHF play a pivotal role in facilitating
    end-to-end adaptation workflows.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 随着组织寻求为特定用例定制 FM，他们需要用于微调和将 FM 与人类偏好和用例对齐的工具。FM 微调和 RLHF 的核心组件在促进端到端适应工作流程中发挥着关键作用。
- en: The core functionalities of these components should include automated supervised
    fine-tuning on an organization-specific dataset for target use cases while ensuring
    integration with the underlying training infrastructure. Additionally, it would
    also integrate with the FM evaluation service for both automated and human-assisted
    model evaluation.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件的核心功能应包括在特定组织数据集上针对目标用例的自动化监督微调，同时确保与底层训练基础设施的集成。此外，它还将与 FM 评估服务集成，以进行自动和人工辅助的模型评估。
- en: Another core functionality should be the support for a complete RLHF loop, allowing
    support from the collection and management of human preference data to interactive
    human evaluation/voting of FM outputs, automated reward model training, and finally,
    fine-tuning of models through reinforcement learning.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个核心功能应该是支持完整的 RLHF 循环，允许从收集和管理人类偏好数据到交互式人类评估/投票 FM 输出，再到通过强化学习进行模型微调。
- en: FM monitoring
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FM 监控
- en: 'Since FMs are trained on extensive public datasets, which can potentially contain
    harmful and biased content, these models may demonstrate similar problematic behavior.
    While many proprietary models have integrated safeguards and filters to screen
    out harmful responses or inappropriate prompts, organizations may have distinct
    requirements for filtering, especially when they utilize open-source models that
    may lack similar built-in safeguards. The following diagram illustrates an architectural
    approach for incorporating supplementary filtering components into the inference
    workflow:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 FM 在广泛公开的数据集上训练，这些数据集可能包含有害和偏见的内容，这些模型可能表现出类似的问题行为。虽然许多专有模型已集成保障措施和过滤器以筛选有害响应或不适当的提示，但组织可能有不同的过滤要求，尤其是在他们使用可能缺乏类似内置保障措施的开源模型时。以下图示说明了将补充过滤组件纳入推理工作流程的架构方法：
- en: '![A diagram of a software system  Description automatically generated](img/B20836_16_04.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![软件系统图  描述自动生成](img/B20836_16_04.png)'
- en: 'Figure 16.4: Implementing model monitoring for generative AI models'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.4：实现生成式 AI 模型的模型监控
- en: In this architecture framework, AWS Lambda functions are positioned within the
    inference workflow to inspect both the input fed into the generative models and
    the responses generated by these models. Specialized detectors and classifier
    models, including toxicity classifiers, bias detectors, and adversarial prompt
    detectors, can be deployed and hosted as distinct endpoints. These Lambda functions
    are responsible for triggering these models to execute screening procedures. Moreover,
    alongside employing ML models, the Lambda functions can also incorporate rule-based
    logic to apply supplementary filtering measures.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在此架构框架中，AWS Lambda 函数位于推理工作流中，用于检查输入到生成模型中的数据和这些模型生成的响应。可以部署和托管专门的检测器和分类模型，包括毒性分类器、偏见检测器和对抗性提示检测器，作为独立的端点。这些
    Lambda 函数负责触发这些模型执行筛选程序。此外，除了使用机器学习模型外，Lambda 函数还可以结合基于规则的逻辑来应用额外的过滤措施。
- en: AWS has also implemented FM monitoring support, called guardrails, directly
    in its Bedrock service. It provides capabilities such as blocking undesired topics,
    filtering harmful content, and redacting PII data for the FMs hosted in Bedrock.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 还在其 Bedrock 服务中直接实现了 FM 监控支持，称为“护栏”，它提供了诸如阻止不受欢迎的主题、过滤有害内容和为 Bedrock 中托管的
    FM 红acting PII 数据等功能。
- en: Generative AI platform architecture and implementation are yet to mature at
    the time of writing. Organizations will need to evaluate the specific needs and
    invest in the building of these technology components to support their new generative
    AI workload at scale.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 生成人工智能平台架构和实施在撰写本文时尚未成熟。组织需要评估具体需求并投资于构建这些技术组件，以支持其大规模的生成人工智能工作负载。
- en: The retrieval-augmented generation pattern
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增强检索的生成模式
- en: Foundation models are frozen in time and limited to the knowledge they were
    trained on, lacking access to an organization’s private data or changing public
    domain information. To enhance the accuracy of responses, especially when using
    proprietary or up-to-date data, we require a mechanism to integrate external information
    into the model’s response generation process.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型被冻结在时间中，并且仅限于它们训练的知识，无法访问组织的私有数据或不断变化的公共领域信息。为了提高响应的准确性，尤其是在使用专有或最新数据时，我们需要一种机制将外部信息集成到模型的响应生成过程中。
- en: 'This is where **retrieval-augmented generation** (**RAG**) can step in. RAG
    is a new architecture pattern introduced to support generative AI-based solutions
    such as enterprise knowledge search and document question answering where external
    data sources are required. There are two main stages to RAG:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是**增强检索生成**（**RAG**）可以介入的地方。RAG 是一种新的架构模式，旨在支持需要外部数据源的基于生成人工智能的解决方案，例如企业知识搜索和文档问答。RAG
    有两个主要阶段：
- en: The indexing stage for preparing a knowledge base with data ingestion and indexes.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 索引阶段，用于准备包含数据摄取和索引的知识库。
- en: The query stage for retrieving relevant context from the knowledge base and
    passing it to the LLM to generate a response.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询阶段，用于从知识库检索相关上下文并将其传递给 LLM 以生成响应。
- en: 'Architecturally, RAG architecture consists of the following key components:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在架构上，RAG 架构由以下关键组件组成：
- en: '**Knowledge and document store**: This contains enterprise knowledge and documents
    used to provide context and facts for the LLM to generate responses based on real
    knowledge and facts. The store can be a knowledge graph, a database, a document
    store, or an object store.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知识和文档存储**：这包含用于为 LLM 提供上下文和事实的企业知识和文档，以便基于真实知识和事实生成响应。存储可以是知识图谱、数据库、文档存储或对象存储。'
- en: '**Document chunking component**: Long documents need to be broken up into small
    chunks containing different knowledge and data, and they can be managed and retrieved
    based on specific user queries. This technology component splits the documents
    into small pieces based on predefined logic and rules (by number of words/characters,
    by paragraph).'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档分块组件**：长文档需要分成包含不同知识和数据的较小块，可以根据特定用户查询进行管理和检索。该技术组件根据预定义的逻辑和规则（按单词/字符数、按段落）将文档拆分成小块。'
- en: '**Document embedding component**: This component creates embeddings from the
    document chunks so these chunks can be effectively searched based on semantic
    similarity. This is a key concept for knowledge retrieval.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档嵌入组件**：该组件从文档块创建嵌入，以便可以根据语义相似性有效地搜索这些块。这是知识检索的关键概念。'
- en: '**Vector DB**: This component stores the document chunks and associated embeddings
    and provides the capability for semantic searches using various techniques such
    as cosine similarity.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量数据库**：此组件存储文档块和相关嵌入，并提供了使用各种技术（如余弦相似度）进行语义搜索的能力。'
- en: '**Retriever and re-ranker**: This component retrieves and re-ranks the top
    matches from the vector DB depending on specific requirements or context.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索器和重新排序器**：此组件根据特定要求或上下文从向量数据库中检索并重新排序顶级匹配项。'
- en: '**Query embedding component**: This component creates embeddings of user queries;
    these queries are then used to look up embeddings from the vector DB.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询嵌入组件**：此组件创建用户查询的嵌入；然后使用这些查询来从向量数据库中查找嵌入。'
- en: '**Workflow orchestration**: This component orchestrates the various steps in
    the chunking, embedding, and query/response flow.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作流程编排**：此组件编排了分块、嵌入和查询/响应流程中的各个步骤。'
- en: '**Prompt template store**: This store maintains prompt templates to construct
    appropriate queries against LLMs.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示模板存储库**：此存储库维护提示模板，以构建针对LLM的适当查询。'
- en: '**Task prompt builder**: This component selects the appropriate prompts from
    the prompt template store and creates a task prompt using the original query and
    retrieved document/knowledge as context. The prompt is formatted to optimize the
    responses from the LLMs.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务提示构建器**：此组件从提示模板存储库中选择适当的提示，并使用原始查询和检索到的文档/知识作为上下文创建任务提示。提示格式化以优化LLM的响应。'
- en: '**LLMs**: These LLMs are responsible for constructing responses from templates
    that use the knowledge/document chunks as part of the context to provide more
    factual and fluent responses.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLMs**：这些LLM负责从模板构建响应，这些模板使用知识/文档块作为上下文的一部分，以提供更准确和流畅的响应。'
- en: 'The following diagram illustrates this architecture and flow:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示说明了此架构和流程：
- en: '![A diagram of a vector database  Description automatically generated](img/B20836_16_05.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![向量数据库的图示  自动生成的描述](img/B20836_16_05.png)'
- en: 'Figure 16.5: Retrieval-augmented generation architecture'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.5：检索增强生成架构
- en: During the indexing stage, source documents are broken up by a document-chunking
    component that breaks them up into small chunks. These chunks are further processed
    by an embedding component, whereby a vector representation (embedding) is created
    for each chunk, capturing the semantic meaning of the text in that chunk. The
    embeddings, along with their associated document chunks, are then stored in a
    vector database.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在索引阶段，源文档由文档分块组件分解成小块。这些块随后由嵌入组件进一步处理，为每个块创建一个向量表示（嵌入），捕获该块中文本的语义意义。然后，嵌入及其相关的文档块被存储在向量数据库中。
- en: During the query stage, the user’s query (prompt) is first processed by an embedding
    component to generate a vector representation (embedding) for the query itself.
    A retriever component then uses this query embedding to retrieve matching vectors
    and their associated document chunks from the previously indexed vector database,
    typically by calculating similarity measures like cosine distance between the
    query and stored embeddings. The document chunks corresponding to the most similar
    embeddings are retrieved. These retrieved chunks are then incorporated into the
    original user query as additional context, forming a new, augmented prompt that
    combines the initial query with the relevant retrieved information.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在查询阶段，用户的查询（提示）首先由嵌入组件处理，以生成查询本身的向量表示（嵌入）。然后，检索器组件使用此查询嵌入从先前索引的向量数据库中检索匹配的向量和相关的文档块，通常通过计算查询和存储嵌入之间的相似度度量（如余弦距离）。检索到的与最相似嵌入对应的文档块被检索。然后，这些检索到的块被纳入原始用户查询作为额外的上下文，形成一个新增强的提示，该提示结合了初始查询和相关的检索信息。
- en: Finally, this augmented prompt is sent to an LLM for synthesis, allowing the
    LLM to generate a response informed by both the original query and the contextual
    information retrieved from the database.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个增强提示被发送到一个LLM进行合成，允许LLM根据原始查询和从数据库检索到的上下文信息生成响应。
- en: In the following sections, we will first explore leading open-source frameworks
    for building RAG applications. We will then discuss the evaluation of the RAG
    pipeline, followed by advanced RAG patterns. Finally, we will understand how to
    build RAG architecture using AWS services. Let’s get started!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将首先探讨构建RAG应用程序的领先开源框架。然后，我们将讨论RAG管道的评估，接着是高级RAG模式。最后，我们将了解如何使用AWS服务构建RAG架构。让我们开始吧！
- en: Open-source frameworks for RAG
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG的开源框架
- en: As RAG has emerged as an important architecture for many generative AI use cases,
    multiple technology frameworks have been developed by the open-source community
    to help streamline the implementation of RAG-based solutions and provide new capabilities.
    There are many RAG frameworks such as LangChain, LlamaIndex, REALM, and Haystack.
    Here, let’s briefly review LangChain and LlamaIndex, two of the more popular frameworks
    for RAG.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 随着RAG成为许多生成式AI用例的重要架构，开源社区已经开发了多个技术框架，以帮助简化基于RAG解决方案的实施并提供新的功能。有许多RAG框架，如LangChain、LlamaIndex、REALM和Haystack。在这里，我们将简要回顾LangChain和LlamaIndex，这两个是RAG中更受欢迎的框架。
- en: LangChain
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LangChain
- en: One of the key challenges of building an LLM-based application is the coordination
    of various components, including vector DB, data retrieval, embedding LLM, and
    response generation LLMs.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 构建基于LLM的应用程序的一个关键挑战是协调各种组件，包括向量数据库、数据检索、嵌入LLM和响应生成LLM。
- en: LangChain is an open-source library that provides a capability that provides
    abstraction for these various RAG components and allows you to orchestrate them.
    LangChain supports the concept of a chain whereby a list of dependent tasks and
    components are connected to perform a function. For example, you can create a
    simple chain that takes an input query, reformat it using a predefined prompt
    template, and then invoke an LLM with the reformatted query. You can also have
    a complex chain that takes a document, splits it into small chunks, passes them
    to an embedding LLM, and then stores the embeddings in a vector DB. While these
    orchestrations can be hardcoded programmatically, a LangChain chain provides a
    dynamic way to define the orchestration and provides modular abstractions for
    many components, such as the LLMs and vector DBs, to simplify the implementation.
    LangChain comes with a list of built-in use-case-specific chains for quick implementation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain是一个开源库，它提供了一种对这些各种RAG组件的抽象能力，并允许您编排它们。LangChain支持链的概念，其中一系列依赖的任务和组件连接起来执行一个功能。例如，您可以创建一个简单的链，它接受一个输入查询，使用预定义的提示模板重新格式化它，然后调用一个LLM来处理重新格式化的查询。您还可以有一个复杂的链，它接受一个文档，将其分割成小块，将它们传递给嵌入LLM，然后将嵌入存储在向量数据库中。虽然这些编排可以通过编程方式硬编码，但LangChain链提供了一种动态定义编排并提供许多组件（如LLM和向量数据库）的模块化抽象的方法，从而简化了实现。LangChain附带了一系列内置的特定用例链，以实现快速实施。
- en: 'The following is a simple code example of using LangChain for a question-answering
    task:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个使用LangChain进行问答任务的简单代码示例：
- en: '[PRE0]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This code sample initializes an OpenSearch and Amazon Bedrock client, defines
    a prompt template, creates a built-in RetrievalQA chain instance, and executes
    the chain to generate an answer to the question.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码示例初始化了一个OpenSearch和Amazon Bedrock客户端，定义了一个提示模板，创建了一个内置的检索问答链实例，并执行链以生成问题的答案。
- en: LangChain also supports the concept of a tool. A tool is a function that LangChain
    can invoke to perform an action such as math calculation or searching the web.
    This is a critical feature as this extends an LLM’s capability to perform more
    complex and precise tasks and be more factually correct.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain还支持工具的概念。工具是LangChain可以调用的函数，用于执行诸如数学计算或搜索网络等操作。这是一个关键特性，因为它扩展了LLM执行更复杂和精确任务的能力，并使其更符合事实。
- en: In addition, LangChain also has support for the concept of an agent. An agent
    helps link LLMs with different tools for dynamic execution, enabling LLMs to select
    the right tool to perform different tasks based on the query. For example, you
    might have a query that requires first searching the internet to get some facts
    and then performing a mathematical calculation on the result. In this case, an
    agent would allow an LLM to dynamically figure out which tool to use to complete
    the query. The following diagram illustrates how agents and tools can work together
    to support the workflow.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，LangChain 还支持代理的概念。代理帮助将 LLM 与不同的工具连接起来以实现动态执行，使 LLM 能够根据查询选择合适的工具来执行不同的任务。例如，你可能有一个需要首先搜索互联网获取一些事实，然后对结果进行数学计算的查询。在这种情况下，代理将允许
    LLM 动态确定用于完成查询的工具。以下图示说明了代理和工具如何协同工作以支持工作流程。
- en: '![A diagram of a tool  Description automatically generated](img/B20836_16_06.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![工具的示意图  描述由系统自动生成](img/B20836_16_06.png)'
- en: 'Figure 16.6: Agent and tool workflow'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.6：代理和工具工作流程
- en: Since its initial release in 2022, LangChain has seen rapid uptake across the
    AI community and companies. Numerous integrations have been developed to provide
    a range of capabilities, such as document loaders, vector stores, embedding models,
    LLMs, and tools.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 自 2022 年初版发布以来，LangChain 在 AI 社区和公司中得到了快速采用。已经开发了众多集成，以提供一系列功能，如文档加载器、向量存储、嵌入模型、LLM
    和工具。
- en: LlamaIndex
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LlamaIndex
- en: LlamaIndex is a data framework for building LLM applications. LlamaIndex offers
    a comprehensive toolkit encompassing data connectors for diverse data sources
    and formats (e.g., APIs, PDFs, SQL), data indexes that structure information for
    efficient consumption by LLMs, and a query interface for sending queries and getting
    back responses from the underlying indexes.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaIndex 是构建 LLM 应用程序的数据框架。LlamaIndex 提供了一个全面的工具包，包括用于各种数据源和格式的数据连接器（例如，API、PDF、SQL）、为
    LLM 效率消费而结构化信息的数据索引，以及用于发送查询和从底层索引获取响应的查询接口。
- en: After the data is ingested using LlamaIndex, the data is split up into data
    chunks and an embedding is created for each chunk. A data chunk and its embedding
    is called a node in LlamaIndex. The nodes are stored in the underlying vector
    databases. It also supports the concept of a list index where a list of related
    nodes are linked together; for example, a list of all chunks from a single document.
    This can be used for use cases where you want to summarize the entire document
    instead of returning a piece of relevant information.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LlamaIndex 消费数据后，数据被分割成数据块，并为每个块创建一个嵌入。一个数据块及其嵌入在 LlamaIndex 中被称为节点。节点存储在底层向量数据库中。它还支持列表索引的概念，其中相关节点被链接在一起；例如，来自单个文档的所有数据块的列表。这可以用于需要总结整个文档而不是返回相关信息的用例。
- en: These engines include query engines for robust knowledge retrieval, chat engines
    for interactive conversations, and data agents that empower LLM-driven knowledge
    workers with a range of tools and integrations. Moreover, LlamaIndex seamlessly
    integrates with various applications, such as LangChain, Flask, Docker, ChatGPT,
    and others, ensuring cohesive integration within your broader ecosystem.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这些引擎包括用于稳健知识检索的查询引擎、用于交互式对话的聊天引擎以及赋予 LLM 驱动的知识工作者一系列工具和集成的数据代理。此外，LlamaIndex
    与各种应用程序无缝集成，例如 LangChain、Flask、Docker、ChatGPT 等，确保在更广泛的生态系统中实现一致集成。
- en: LlamaIndex has the concept of data agents, which are knowledge workers that
    perform various tasks including searching and the retrieval of data, and calling
    external service APIs. This concept is similar to the agent concept in LangChain.
    Given an input query, the data agent uses a reasoning loop to determine which
    tool to use and in which sequence to invoke the tools.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaIndex 拥有数据代理的概念，这些知识工作者执行各种任务，包括搜索和数据的检索，以及调用外部服务 API。这个概念与 LangChain 中的代理概念类似。给定一个输入查询，数据代理使用推理循环来确定使用哪个工具以及调用工具的顺序。
- en: There are some overlaps between LlamaIndex and LangChain in the area of external
    data connectors and indexing, query management for data retrieval, and interacting
    with LLMs. The key difference is that LlamaIndex focuses on building rich capabilities
    in those overlapping areas, while LangChain is more general-purpose with support
    for tools, agents, and chains.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在外部数据连接器和索引、数据检索的查询管理以及与LLM交互方面，LlamaIndex和LangChain之间存在一些重叠。关键区别在于，LlamaIndex专注于在重叠领域构建丰富的功能，而LangChain则更通用，支持工具、代理和链。
- en: Evaluating a RAG pipeline
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估RAG管道
- en: Evaluating the performance of a RAG pipeline is a complex task as there are
    multiple processes involved, such as knowledge indexing, knowledge retrieval,
    and response synthesis. In addition, there is the unpredictable nature of text
    generation.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 评估RAG管道的性能是一个复杂任务，因为涉及多个过程，如知识索引、知识检索和响应合成。此外，文本生成的不可预测性也是一个因素。
- en: 'Evaluating a RAG application involves multiple stages:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 评估RAG应用涉及多个阶段：
- en: '**Stage 1 – Faithfulness evaluation of response against the context**: This
    stage tests if the synthesized response faithfully captures the facts and context
    of the retrieved source documents. If it does not, then it is a sign of LLM hallucination.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第一阶段 – 对响应的忠实度评估**：这一阶段测试合成的响应是否忠实于检索到的源文档的事实和上下文。如果不忠实，那么这就是LLM幻觉的迹象。'
- en: '**Stage 2 – Response relevancy evaluation against the query**: This stage checks
    if the response matches the retrieved source documents, and then this stage evaluates
    if the synthesized response answers the query. If it does not match, then it is
    an indication that the semantic search and/or embeddings do not function correctly.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第二阶段 – 对查询的响应相关性评估**：这一阶段检查响应是否与检索到的源文档匹配，然后评估合成的响应是否回答了查询。如果不匹配，那么这表明语义搜索和/或嵌入没有正确工作。'
- en: '**Stage 3 – Question answering on the source document**: This stage uses an
    external tool to generate questions from the source document, and test if the
    LLM can answer questions using data. If the LLM cannot answer the question correctly,
    then the LLM is defective.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第三阶段 – 在源文档上的问答**：这一阶段使用外部工具从源文档生成问题，并测试LLM是否能够使用数据回答问题。如果LLM不能正确回答问题，那么LLM就有缺陷。'
- en: There are several tools that can be used for RAG evaluation. For example, LlamaIndex
    provides a number of modules for evaluating hallucination and relevancy, as well
    as generating questions from source data. There are also other open-source tools,
    such as DeepEval for writing unit tests, and Ragas, which measures the RAG pipeline’s
    performance against different dimensions, including faithfulness and answer relevancy
    for response generation, and context precision and recall for the retrieved context
    against annotated answers.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种工具可以用于RAG评估。例如，LlamaIndex提供了一系列模块来评估幻觉和相关性，以及从源数据生成问题。还有其他开源工具，如DeepEval用于编写单元测试，以及Ragas，它衡量RAG管道在不同维度上的性能，包括响应生成的忠实度和答案的相关性，以及检索到的上下文与标注答案的上下文精确度和召回率。
- en: Advanced RAG patterns
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级RAG模式
- en: While RAG has proven to be highly versatile and effective in solving many generative
    AI use cases, it also comes with its unique set of challenges that we need to
    be aware of and address when implementing a RAG solution.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然RAG已被证明在解决许多生成式AI用例方面非常灵活和有效，但它也带来了一组独特的挑战，我们在实施RAG解决方案时需要意识到并解决这些挑战。
- en: A core challenge in developing effective RAG solutions is ensuring high-quality
    retrieval results. Poor retrieval can stem from various factors. For instance,
    retrieved text blocks may lack correlation with the original query, leading to
    hallucinated or fabricated responses. Additionally, failure to retrieve all relevant
    knowledge blocks prevents the model from synthesizing complete, high-quality answers.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发有效的RAG解决方案中，一个核心挑战是确保高质量的检索结果。低质量的检索可能源于各种因素。例如，检索到的文本块可能与原始查询缺乏相关性，导致幻觉或虚构的响应。此外，未能检索到所有相关的知识块会阻止模型合成完整、高质量的回答。
- en: 'One way to improve retrieval quality is to improve the indexing of the documents.
    There are several methods for improving indexing:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 提高检索质量的一种方法是通过改进文档的索引。有几种改进索引的方法：
- en: '**Pre-indexing data optimization**: Standardizing text, removing irrelevant
    content, eliminating redundancies, and validating factual accuracy before indexing.
    This reduces noise in the indexed data.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预索引数据优化**：在索引前标准化文本，删除无关内容，消除冗余，并验证事实准确性。这减少了索引数据中的噪声。'
- en: '**Index structure optimization**: Tuning chunk size parameters to balance context
    preservation against quality. Strategies like sliding window chunking help retain
    contextual information across chunks.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**索引结构优化**：调整块大小参数以平衡上下文保留与质量。如滑动窗口块分割等策略有助于在块之间保留上下文信息。'
- en: '**Metadata enhancement**: Incorporating supplemental metadata like chapter
    descriptions and dates into chunks provides useful indexing context.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据增强**：将补充元数据如章节描述和日期纳入块中，提供有用的索引上下文。'
- en: '**Embedding fine-tuning**: Fine-tuning embeddings adds critical in-domain context
    for specialized areas with uncommon terms.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入微调**：微调嵌入为具有不常见术语的专业领域添加了关键的领域上下文。'
- en: '**Dynamic embedding**: Generating contextualized embeddings improves upon static
    embedding limitations.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态嵌入**：生成上下文化的嵌入可以克服静态嵌入的限制。'
- en: 'Beyond indexing, implementing smarter retrieval pipelines can further enhance
    RAG performance:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 除了索引之外，实施更智能的检索管道可以进一步提高RAG性能：
- en: '**Recursive retrieval**: This approach introduces a multi-stage querying approach,
    first retrieving smaller semantic blocks followed by larger contextual blocks.
    This balances efficiency with rich contextual grounding.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**递归检索**：这种方法引入了多阶段查询方法，首先检索较小的语义块，然后检索较大的上下文块。这平衡了效率与丰富的上下文基础。'
- en: '**Subqueries**: Various query strategies can be employed in different scenarios,
    including using query engines provided by frameworks like LlamaIndex, employing
    tree queries, utilizing vector queries, or employing the most basic sequential
    querying of chunks.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子查询**：在不同场景中可以采用各种查询策略，包括使用LlamaIndex等框架提供的查询引擎，采用树查询，利用向量查询，或者采用最基本的块顺序查询。'
- en: Retrieving relevant contextual documents is only the first step. Preparing the
    retrieved evidence for input into the LLM presents additional challenges. Inputting
    all documents at once risks exceeding the LLM’s context capacity. Meanwhile, concatenating
    documents creates lengthy, unfocused prompts. Advanced techniques are needed to
    optimize the retrieved evidence for response generation. With optimized evidence
    preparation, the LLM can focus on crucial information within its context window
    for producing high-quality responses grounded in the retrieved data.
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 获取相关上下文文档只是第一步。将检索到的证据准备输入到LLM中又带来了额外的挑战。一次性输入所有文档可能会超过LLM的上下文容量。同时，拼接文档会创建冗长且不集中的提示。需要高级技术来优化检索到的证据以生成响应。通过优化的证据准备，LLM可以专注于上下文窗口内的关键信息，从而产生基于检索数据的优质响应。
- en: '**Re-ranking**: Re-ranking techniques can optimize document order to prioritize
    the most relevant information for synthesizing. There are different rankers available.
    For example, the Diversity Ranker reorders documents to increase diversity within
    the context window. The LostInTheMiddleRanker positions the best document at the
    start and end of the context window alternately. Through re-ranking, the most
    informative evidence is strategically placed for the language model to focus on.
    This prevents the most relevant details from getting lost in the middle of a lengthy
    context. Effective re-ranking is crucial for enabling models to produce high-quality
    responses grounded in the top retrieved evidence.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重新排序**：重新排序技术可以优化文档顺序，优先考虑合成中最相关的信息。有不同类型的排序器可用。例如，Diversity Ranker重新排序文档以增加上下文窗口内的多样性。LostInTheMiddleRanker交替地将最佳文档放置在上下文窗口的开始和结束位置。通过重新排序，最有信息量的证据被策略性地放置，以便语言模型可以专注于。这防止了最相关的细节在冗长的上下文中丢失。有效的重新排序对于使模型能够基于顶级检索证据产生高质量响应至关重要。'
- en: '**Prompt compression**: Post-retrieval processing techniques can remove irrelevant
    context from prompts to reduce noise and improve response quality in RAG systems.
    For example, some models calculate mutual information across prompt elements to
    estimate and filter out unimportant or distracting information. By stripping away
    non-essential text, the language model can focus on the truly salient evidence
    when generating responses. Careful prompt pruning is an impactful strategy to
    reduce hallucinations and keep RAG responses grounded in the most critical supporting
    context.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示压缩**：检索后处理技术可以从提示中移除无关的上下文，以减少噪声并提高 RAG 系统的响应质量。例如，一些模型通过计算提示元素之间的互信息来估计和过滤掉不重要或分散注意力的信息。通过去除非必要文本，语言模型可以在生成响应时专注于真正显著的证据。仔细修剪提示是一种减少幻觉并使
    RAG 响应保持最关键支持上下文的有力策略。'
- en: In summary, optimizing the indexing, implementing recursive retrieval pipelines,
    strategically reformatting evidence, and pruning prompts are all impactful strategies
    to address these challenges. When combined creatively, these advanced patterns
    enable models to retrieve the most relevant knowledge at each stage, hone in on
    the salient context, and synthesize this tailored evidence into high-quality,
    grounded responses.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，优化索引、实施递归检索管道、策略性地重新格式化证据以及修剪提示都是解决这些挑战的有效策略。当这些高级模式创造性地结合在一起时，它们使模型能够在每个阶段检索最相关的知识，聚焦于显著上下文，并将这些定制证据综合成高质量、有根据的回应。
- en: Designing a RAG architecture on AWS
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 AWS 上设计 RAG 架构
- en: If you use AWS, there are multiple ready-to-use AWS and third-party services
    you can use to build a RAG architecture.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用 AWS，你可以使用多个现成的 AWS 和第三方服务来构建 RAG 架构。
- en: '**SageMaker JumpStart**: SageMaker JumpStart provides pre-trained, open-source
    models for a wide range of problem types. You can incrementally train and tune
    these models for specific requirements and host these models using the SageMaker
    hosting service to support RAG architecture. Choose SageMaker JumpStart if you
    like to train and host open-source FMs yourself and have the choice of different
    compute options for model hosting.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SageMaker JumpStart**：SageMaker JumpStart 为广泛的难题类型提供了预训练的开源模型。您可以为特定要求逐步训练和调整这些模型，并使用
    SageMaker 托管服务托管这些模型以支持 RAG 架构。如果您喜欢自己训练和托管开源 FM 并有选择不同计算选项进行模型托管的选择，请选择 SageMaker
    JumpStart。'
- en: '**Amazon Bedrock**: Amazon Bedrock is a fully managed service that makes FMs
    from Amazon and leading AI startups available through an API. At the time of writing,
    Amazon Bedrock provides the Titan FM from Amazon, and FMs from AI21, Stability
    AI, Cohere, Meta, Mistral, and Anthropic. For more details about Bedrock, you
    can visit the AWS public site. You want to explore Bedrock if you want access
    to the top proprietary FMs via an API instead of hosting your own. Also, for workloads
    with a low volume of transactions, Bedrock can be more cost-effective. Amazon
    Bedrock also has built-in support for document indexing and vector storage, known
    as the Bedrock knowledge base for RAG development. It also comes with support
    for agents and tools, called Agents for Amazon Bedrock, for building agent-based
    workflow applications.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon Bedrock**：Amazon Bedrock 是一项完全托管的服务，通过 API 使 Amazon 和领先的 AI 创业公司的
    FM 可用。在撰写本文时，Amazon Bedrock 提供了 Amazon 的 Titan FM 以及 AI21、Stability AI、Cohere、Meta、Mistral
    和 Anthropic 的 FM。有关 Bedrock 的更多详细信息，您可以访问 AWS 公共网站。如果您想通过 API 获取顶级专有 FM 而不是托管自己的，则可以探索
    Bedrock。此外，对于交易量较低的工作负载，Bedrock 可能更具成本效益。Amazon Bedrock 还内置了对文档索引和向量存储的支持，称为 Bedrock
    知识库，用于 RAG 开发。它还附带了对代理和工具的支持，称为 Amazon Bedrock 的代理，用于构建基于代理的工作流应用程序。'
- en: '**Amazon OpenSearch**: Amazon OpenSearch Service provides capabilities for
    interactive log analytics, real-time application monitoring, website search, and
    more. It can also be used as a vector database in the RAG architecture. It allows
    for the building of indexes for knowledge chunks and embeddings, and it provides
    proximity-based vector search. OpenSearch can integrate with LangChain and LlamaIndex.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon OpenSearch**：Amazon OpenSearch 服务提供了交互式日志分析、实时应用程序监控、网站搜索等功能。它还可以用作
    RAG 架构中的向量数据库。它允许构建知识块和嵌入的索引，并提供基于邻近度的向量搜索。OpenSearch 可以与 LangChain 和 LlamaIndex
    集成。'
- en: '**Amazon Kendra**: Amazon Kendra is an intelligent search service that can
    be used as a knowledge store for RAG. Amazon Kendra also provides a RAG retrieval
    API that can work with LangChain seamlessly.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon Kendra**：Amazon Kendra是一种智能搜索服务，可以用作RAG的知识存储。Amazon Kendra还提供了一个可以与LangChain无缝工作的RAG检索API。'
- en: '**Amazon Q**: Amazon Q is a relatively new service from AWS. There are multiple
    independent services under the Amazon Q product suite, including Amazon Q for
    Business, Amazon Q for Builder, Amazon Q for QuickSight, and Amazon Q for Connect.
    Amazon Q for Business is a fully managed RAG-based assistant that can answer questions,
    provide summaries, and generate content based on enterprise data.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon Q**：Amazon Q是AWS的一个相对较新的服务。Amazon Q产品套件下有多个独立服务，包括Amazon Q for Business、Amazon
    Q for Builder、Amazon Q for QuickSight和Amazon Q for Connect。Amazon Q for Business是一个基于RAG的完全托管助手，可以回答问题、提供摘要并根据企业数据生成内容。'
- en: There are other third-party and open-source vector database options available,
    such as Pinecone and FAISS.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 可用其他第三方和开源向量数据库选项，例如Pinecone和FAISS。
- en: 'The following is an example RAG architecture designed using AWS services:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个使用AWS服务设计的RAG架构示例：
- en: '![A diagram of data lake  Description automatically generated](img/B20836_16_07.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![数据湖的图示  描述自动生成](img/B20836_16_07.png)'
- en: 'Figure 16.7: RAG architecture on AWS'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.7：AWS上的RAG架构
- en: A RAG-based architecture can support many use cases, such as question answering
    over documents, querying data from databases and knowledge graphs using natural
    language, interactive chatbots, customer support assistants, medical information
    search and recommendations, and education and training.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 基于RAG的架构可以支持许多用例，例如在文档上进行问答、使用自然语言从数据库和知识图谱中查询数据、交互式聊天机器人、客户支持助手、医疗信息搜索和推荐，以及教育和培训。
- en: As RAG architecture is becoming a common critical component of many LLM application
    architecture stacks, it is crucial to establish an operational capability and
    process that is similar to that of a GenAI/ML platform. However, since this is
    still a new area, there has not been much development of technical capabilities
    and tools around RAG management. Different organizations will need to evaluate
    needs and develop customer software and infrastructure to enable the operation
    of a common RAG platform. Organizations can consider RAG infrastructure as an
    independent platform or part of the overall generative AI platform.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 随着RAG架构成为许多LLM应用架构堆栈的常见关键组件，建立与GenAI/ML平台类似的操作能力和流程至关重要。然而，由于这还是一个新领域，围绕RAG管理的技朮能力和工具的发展尚未充分。不同的组织将需要评估需求并开发客户软件和基础设施，以实现通用RAG平台的运行。组织可以将RAG基础设施视为一个独立平台或整体生成式AI平台的一部分。
- en: Choosing an LLM adaptation method
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择一个LLM适配方法
- en: 'We have covered various LLM adaptation methods, including prompt engineering,
    domain adaptation pre-training, fine-tuning, and RAG. All these methods are intended
    to get better responses from the pre-trained LLMs. With all these options, it
    leaves one wondering: how do we choose which method to use?'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了各种LLM适配方法，包括提示工程、领域自适应预训练、微调和RAG。所有这些方法都是为了从预训练的LLM中获得更好的响应。有了所有这些选项，人们不禁要问：我们如何选择使用哪种方法？
- en: Let’s break down some of the considerations when choosing these different methods.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下在选择这些不同方法时需要考虑的一些因素。
- en: Response quality
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 响应质量
- en: Response quality measures how accurately the LLM response is aligned with the
    intent of the user queries. The evaluation of response quality can be intricate
    for different use cases, as there are different considerations for evaluating
    response quality, such as knowledge domain affinity, task accuracy, up-to-date
    data, source data transparency, and hallucination.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 响应质量衡量LLM响应与用户查询意图的准确性。对于不同的用例，响应质量的评估可能很复杂，因为评估响应质量有不同的考虑因素，例如知识领域亲和度、任务准确性、最新数据、源数据透明度和幻觉。
- en: For knowledge domain affinity, domain adaptation pre-training can be used to
    effectively teach LLM domain-specific knowledge and terminology. RAG is efficient
    in retrieving relevant data, but the LLM used for the response synthetization
    may not capture domain-specific patterns, terminology, and nuance as well as fine-tuned
    or domain adaptation pre-training models. If you need strong domain-specific performance,
    you want to consider domain adaptation pre-training.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 对于知识领域亲和力，可以使用领域自适应预训练来有效地教授LLM特定领域的知识和术语。RAG在检索相关数据方面效率很高，但用于响应合成的LLM可能无法像微调或领域自适应预训练模型那样很好地捕捉特定领域的模式、术语和细微差别。如果您需要强大的特定领域性能，您应该考虑领域自适应预训练。
- en: If you need to maximize accuracy for specific tasks, then fine-tuning is the
    recommended approach. Prompt engineering can also help improve task accuracy through
    single-shot or few-shot prompting techniques, but it is prompt-specific and does
    not generalize across different prompts.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要最大化特定任务的准确性，那么微调是推荐的方法。提示工程也可以通过单次或少量提示技术帮助提高任务准确性，但它特定于提示，并且不能推广到不同的提示。
- en: If information freshness in the response is the primary goal, then RAG is the
    ideal solution since it has access to dynamic external data sources. Prompt engineering
    can also help with data freshness when up-to-date knowledge is provided as part
    of the prompt. Fine-tuning and domain adaptation pre-training have knowledge cutoffs
    based on the latest training dataset used.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果响应中的信息新鲜度是首要目标，那么RAG是理想的解决方案，因为它可以访问动态的外部数据源。当最新的知识作为提示的一部分提供时，提示工程也可以帮助提高数据的新鲜度。微调和领域自适应预训练的知识截止点基于最新使用的训练数据集。
- en: For some applications such as medical diagnosis or financial analysis, knowing
    how the decisions were made and what data sources were used in making the decision
    is crucial. If this is a critical requirement for the use case, then RAG is the
    clear choice here, as RAG can provide references to the knowledge it used for
    constructing the response. Fine-tuning and domain adaptation pre-training behave
    more like a “black box,” often obscuring what data sources are used for decision-making.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些应用，如医学诊断或财务分析，了解决策是如何做出的以及用于做出决策的数据源至关重要。如果这是用例的关键要求，那么RAG在这里是明确的选择，因为RAG可以提供用于构建响应的知识参考。微调和领域自适应预训练更像是一个“黑盒”，通常掩盖了用于决策的数据源。
- en: As mentioned in the previous chapter, LLMs sometimes generate inaccurate responses
    that are not grounded in their training data or user input when they encounter
    unfamiliar queries and hallucinate plausible but false information. Fine-tuning
    can reduce fabrication by focusing the model on domain-specific knowledge. However,
    the risk remains for unfamiliar inputs. RAG systems better address hallucination
    risks by anchoring responses to retrieved documents. The initial retrieval step
    acts as a fact check, finding relevant passages to ground the response in real
    data. Subsequent generation is confined within the context of the retrievals rather
    than being unconstrained. This mechanism minimizes fabricated responses not supported
    by data.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，当LLM遇到不熟悉的查询并产生基于其训练数据或用户输入的虚假信息时，有时会生成不准确且没有根据的响应。微调可以通过将模型集中在特定领域的知识上来减少伪造。然而，对于不熟悉的输入，风险仍然存在。RAG系统通过将响应锚定到检索到的文档中更好地解决了幻觉风险。初始检索步骤充当事实核查，找到相关段落以将响应建立在真实数据上。随后的生成被限制在检索的上下文中，而不是不受约束。这种机制最小化了没有数据支持伪造的响应。
- en: Cost of the adaptation
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自适应成本
- en: When evaluating LLM adaptation approaches, it is important to consider both
    initial implementation costs as well as long-term maintenance costs. With this
    in mind, let’s compare the costs of the different approaches.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当评估LLM自适应方法时，重要的是要考虑初始实施成本以及长期维护成本。考虑到这一点，让我们比较不同方法的开销。
- en: Prompt engineering has the lowest overhead, involving simply writing and testing
    prompts to yield good results from the pre-trained language model. Maintenance
    may require occasional prompt updates as the foundation model is updated over
    time.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程具有最低的开销，只需简单地编写和测试提示，就可以从预训练语言模型中获得良好的结果。维护可能需要偶尔更新提示，因为基础模型会随着时间的推移而更新。
- en: RAG systems have moderately high startup costs due to requiring multiple components
    – embeddings, vector stores, retrievers, and language models. However, these systems
    are relatively static over time.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: RAG系统由于需要多个组件（嵌入、向量存储、检索器和语言模型）而具有中等高的启动成本。然而，这些系统在时间上相对静态。
- en: Full fine-tuning and domain adaptation pre-training can be expensive, needing
    massive computational resources and time to completely update potentially all
    parameters of a large foundation model, as well as the cost of dataset preparation.
    **Parameter Efficient Fine-Tuning** (**PEFT**) can be cheaper than full fine-tuning
    and domain adaptation pre-training. However, it is still considered more expensive
    than RAG due to the requirement for high-quality dataset preparation and training
    resource requirements.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 全微调和领域自适应预训练可能成本高昂，需要大量的计算资源和时间来完全更新大型基础模型的所有潜在参数，以及数据集准备的成本。**参数高效微调（PEFT**）可能比全微调和领域自适应预训练便宜，然而，由于需要高质量的数据集准备和训练资源要求，它仍然被认为比RAG更昂贵。
- en: Implementation complexity
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现复杂度
- en: The implementation complexity varies significantly across different techniques,
    from straightforward to highly advanced configurations.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 实现复杂度在不同技术之间差异很大，从简单到高度复杂配置不等。
- en: Prompt engineering has relatively low complexity, requiring mainly language
    skills and few-shot learning familiarity to craft prompts that elicit good performance
    from the foundation model. There are minimal requirements for programming skills
    and science knowledge.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程具有相对较低的复杂度，主要需要语言技能和少量学习熟悉度来制作能够从基础模型中激发良好性能的提示。对编程技能和科学知识的要求很少。
- en: RAG systems have moderate complexity, needing software engineering to build
    the pipeline components like retrievers and integrators. The complexity rises
    with advanced RAG configurations and infrastructure, such as complex workflows
    involving agents and tools, and infrastructure components for monitoring, observability,
    evaluation, and orchestration.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: RAG系统具有中等复杂度，需要软件工程来构建管道组件，如检索器和集成器。随着高级RAG配置和基础设施的发展，复杂度会增加，例如涉及代理和工具的复杂工作流，以及用于监控、可观察性、评估和编排的基础设施组件。
- en: PEFT and full model fine-tuning have the highest complexity. These require deep
    expertise in deep learning, NLP, and data science to select training data, write
    tuning scripts, choose hyperparameters like learning rates, loss functions, etc.,
    and ultimately update the model’s internal representations.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: PEFT和全模型微调具有最高的复杂度。这需要深厚的深度学习、NLP和数据科学专业知识来选择训练数据，编写微调脚本，选择学习率、损失函数等超参数，并最终更新模型的内部表示。
- en: Bringing it all together
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将所有内容整合在一起
- en: Having delved into the various technical components separately within the generative
    AI technical stack, let’s now consolidate them into a unified perspective.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成式AI技术栈中分别深入研究了各种技术组件之后，现在让我们将它们整合到一个统一的视角中。
- en: '![](img/B20836_16_08.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B20836_16_08.png)'
- en: 'Figure 16.8: Generative AI tech stack'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.8：生成式AI技术栈
- en: In summary, a generative AI platform is an extension of an ML platform by introducing
    additional capabilities such as prompt management, input/output filtering, and
    tools for FM evaluation and RLHF workflows. To accommodate these enhancements,
    the ML platform’s pipeline capability will need to include new generative AI workflows.
    The new RAG infrastructure will form the foundational backbone of RAG-based LLM
    applications and will be closely integrated with the underlying generative AI
    platform.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，生成式AI平台是通过引入额外的功能，如提示管理、输入/输出过滤以及FM评估和RLHF工作流工具，来扩展ML平台。为了适应这些增强功能，ML平台的管道能力需要包括新的生成式AI工作流。新的RAG基础设施将成为基于RAG的LLM应用的基础骨干，并将与底层生成式AI平台紧密集成。
- en: The development of generative AI applications will continue to leverage other
    core application architecture components, including streaming, batch processing,
    message queuing, and workflow tools.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI应用的发展将继续利用其他核心应用架构组件，包括流处理、批量处理、消息队列和工作流工具。
- en: Although many of the core components will likely possess their unique set of
    security and governance capabilities, there will be an overarching need for comprehensive
    end-to-end observability, monitoring, security, and governance for generative
    AI application development and operation at scale.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多核心组件可能拥有其独特的安全和治理能力，但将需要一个全面的端到端可观察性、监控、安全和治理，以支持生成式AI应用的大规模开发和运营。
- en: Considerations for deploying generative AI applications in production
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在生产环境中部署生成式AI应用的考虑因素
- en: Deploying generative AI applications in production environments introduces a
    new set of challenges that go beyond the considerations for traditional software
    and ML deployments. While aspects such as functional correctness, system/application
    security, security scan of artifacts such as model files and code, infrastructure
    scalability, documentation, and operational readiness (e.g., observability, change
    management, incident management, and audit) remain essential, there are additional
    factors to consider when deploying generative AI models.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中部署生成式AI应用引入了一组新的挑战，这些挑战超出了传统软件和机器学习部署的考虑因素。虽然功能性正确性、系统/应用安全性、对模型文件和代码等工件的安全扫描、基础设施可扩展性、文档和运营准备（例如，可观察性、变更管理、事件管理和审计）等方面仍然是基本要素，但在部署生成式AI模型时，还有其他因素需要考虑。
- en: The following are some of the key additional considerations when deciding on
    the production deployment of generative AI applications.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在决定生成式AI应用的生产部署时的一些关键附加考虑因素。
- en: Model readiness
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型准备就绪
- en: When deciding whether a generative AI model is ready for production deployment,
    the focus should be on its accuracy for the target use cases. These models can
    solve a wide range of problems, but attempting to test for all possible scenarios
    and use cases would be an endless endeavor, making it challenging to feel confident
    in the deployment. Instead, concentrate on designing the application layer to
    support only the targeted use cases, simplifying the evaluation process.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 当决定一个生成式AI模型是否准备好投入生产部署时，重点应放在其针对目标用例的准确性上。这些模型可以解决广泛的问题，但尝试测试所有可能的场景和用例将是一项无休止的努力，这使得对部署的信心变得困难。相反，应专注于设计应用层以仅支持目标用例，简化评估过程。
- en: Additionally, when determining if a performance metric is satisfactory, it’s
    essential to establish a threshold using existing benchmarks as a baseline. For
    example, if the error rate for the current process is 20% and deemed acceptable
    for business operations, then a generative AI application that can achieve the
    same or lower error rate should be considered capable of delivering at least the
    same or better value. By adopting this approach, you can confidently proceed with
    production deployment.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在确定性能指标是否满意时，使用现有基准作为基线来建立阈值至关重要。例如，如果当前流程的错误率为20%，并且被认为对业务运营是可接受的，那么能够实现相同或更低错误率的生成式AI应用应被视为能够至少提供相同或更好的价值。采用这种方法，你可以自信地进行生产部署。
- en: Decision-making workflow
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 决策工作流程
- en: When deploying generative AI applications, it’s crucial to consider whether
    the system will make automated decisions or involve human oversight. Due to the
    potential for hallucinations or inaccuracies in these models, the level of testing
    and evaluation rigor needs to be determined based on the decision-making flow.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署生成式AI应用时，考虑系统是否会做出自动化决策或涉及人工监督至关重要。由于这些模型可能存在幻觉或不准确性的潜在可能性，测试和评估的严格程度需要根据决策流程来确定。
- en: If the system is designed to make fully automated decisions, you must assess
    the risk of incorrect decisions being made. Is this risk tolerable for your use
    case? If so, then automated decision-making can proceed after thorough testing
    against the target use cases and scenarios. However, if the potential risk is
    not tolerable, it’s essential to incorporate human oversight into the decision-making
    process.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果系统被设计为做出完全自动化的决策，你必须评估做出错误决策的风险。这种风险在你的用例中是否可以容忍？如果是的话，那么在针对目标用例和场景进行彻底测试后，可以继续进行自动化决策。然而，如果潜在的风险不可容忍，那么在决策过程中纳入人工监督是至关重要的。
- en: In cases where human oversight is required, ensure that the individuals involved
    are well qualified to make informed decisions with the support of the generative
    AI application. The system should be designed to provide recommendations or insights
    to human decision-makers, who can then apply their expertise and judgment to mitigate
    potential errors or biases from the AI model.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在需要人工监督的情况下，确保涉及的个体具备在生成式AI应用支持下做出明智决策的充分资格。系统应设计为向人类决策者提供建议或洞察，然后他们可以运用自己的专业知识和判断力来减轻AI模型可能产生的错误或偏差。
- en: Responsible AI assessment
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负责任的AI评估
- en: When it comes to responsible AI considerations, such as bias and harmful content,
    it’s essential to evaluate them on a case-by-case basis for each specific use
    case. Different use cases may have varying tolerances for certain types of language
    or biases. For example, some use cases could be more tolerant of certain language
    patterns, while others may have stricter requirements.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到负责任的AI考虑因素，如偏见和有害内容时，对每个特定用例进行逐案评估是至关重要的。不同的用例可能对某些类型的语言或偏见有不同的容忍度。例如，某些用例可能对某些语言模式更为宽容，而其他用例可能有更严格的要求。
- en: Similarly, the degree of bias that is considered acceptable can vary depending
    on the use case and scenarios involved. What might be considered an acceptable
    level of bias for one application may be unacceptable for another. It’s crucial
    to assess the potential impact of biases within the context of each use case and
    determine the appropriate thresholds.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，可接受的偏见程度可能因用例和涉及的场景而异。对于某个应用程序可能被认为是可接受的偏见水平，对于另一个应用程序可能是不可以接受的。在评估每个用例中偏见可能产生的影响时，确定适当的阈值至关重要。
- en: Instead of applying a one-size-fits-all approach, it’s recommended to conduct
    a thorough evaluation of bias and harmful content considerations for each specific
    use case. This targeted assessment will ensure that the deployed generative AI
    application aligns with the unique requirements and constraints of that particular
    use case, minimizing potential risks and ensuring responsible and ethical deployment.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是采用一刀切的方法，建议对每个特定用例进行彻底的偏见和有害内容评估。这种有针对性的评估将确保部署的生成式AI应用与该特定用例的独特需求和限制相一致，最大限度地降低潜在风险，并确保负责任和道德的部署。
- en: Guardrails in production environments
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生产环境中的防护措施
- en: Despite thorough testing and evaluation during the development phase, generative
    AI models can still exhibit unexpected or undesirable behaviors when deployed
    in live production environments. To address this challenge, it is essential to
    establish a comprehensive set of guardrails within the production environment.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在开发阶段进行了彻底的测试和评估，但生成式AI模型在部署到实际生产环境时仍可能表现出意外或不希望的行为。为了应对这一挑战，在生产环境中建立一套全面的防护措施是至关重要的。
- en: At the core of these guardrails are robust input validation systems. These systems
    scrutinize the data and prompts fed into the generative AI models, ensuring that
    only appropriate, safe, and intended inputs are used. This protects the models
    from being exposed to potentially harmful or adversarial inputs, which could trigger
    unpredictable or undesirable outputs.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这些防护措施的核心是强大的输入验证系统。这些系统仔细审查输入到生成式AI模型中的数据和提示，确保仅使用适当、安全和预期的输入。这保护了模型免受可能有害或对抗性输入的影响，这些输入可能会触发不可预测或不受欢迎的输出。
- en: Complementing the input validation, organizations must also develop sophisticated
    output filtering and moderation systems. These systems review the generated content
    before it is released or exposed to end-users, detecting and flagging any outputs
    that may be biased, offensive, sensitive (PII), or otherwise undesirable. This
    allows for timely review and intervention, ensuring that potentially problematic
    content is addressed before it reaches the public.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 输入验证的补充，组织还必须开发复杂的输出过滤和监管系统。这些系统在内容发布或向最终用户暴露之前对其进行审查，检测并标记任何可能存在偏见、冒犯性、敏感（PII）或其他不受欢迎的输出。这允许及时审查和干预，确保在内容到达公众之前解决潜在的问题内容。
- en: To enable rapid response and intervention, the monitoring and validation systems
    should be integrated with automated alerting mechanisms. These mechanisms quickly
    notify the appropriate teams of any concerning behaviors or outputs detected by
    the system. This allows organizations to act swiftly, addressing issues before
    they escalate or cause harm.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现快速响应和干预，监控和验证系统应与自动警报机制集成。这些机制会迅速通知适当的团队系统检测到的任何令人担忧的行为或输出。这允许组织迅速行动，在问题升级或造成损害之前解决问题。
- en: Ultimately, the human remains a crucial safeguard. Generative AI workflows must
    maintain the ability for experienced operators to override or intervene when necessary.
    This serves as a backstop, allowing knowledgeable personnel to make informed decisions
    when the models exhibit unpredictable or undesirable behaviors that require immediate
    attention.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，人类仍然是一个关键的安全保障。生成式AI工作流程必须保持经验丰富的操作员在必要时进行覆盖或干预的能力。这作为一个后备措施，允许有知识的人员在模型表现出不可预测或不受欢迎的行为并需要立即关注时做出明智的决定。
- en: If you use Amazon Bedrock, you can consider the built-in Guardrails feature
    which can detect and filter out undesired topics, harmful content, or PII data.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用Amazon Bedrock，你可以考虑内置的Guardrails功能，该功能可以检测和过滤掉不希望的主题、有害内容或PII数据。
- en: External knowledge change management
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 外部知识变更管理
- en: For generative AI applications that rely on external knowledge retrieval, such
    as those based on the RAG architecture, it is crucial to consider the dynamic
    nature of the underlying knowledge sources. External knowledge can change over
    time, and for the same query, there could be multiple relevant answers depending
    on the recency and timeline of the information.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 对于依赖于外部知识检索的生成式AI应用，例如基于RAG架构的应用，考虑底层知识源的动态性质至关重要。外部知识可能会随时间变化，对于同一个查询，根据信息的时效性和时间线，可能会有多个相关答案。
- en: To address this challenge, it is essential to either design prompts that accurately
    capture the desired temporal context or ensure that the knowledge retriever component
    is aware of the knowledge lineage and timeline. This way, the system can retrieve
    and present the most relevant and up-to-date information in response to a given
    query.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这一挑战，设计能够准确捕捉所需时间背景的提示或确保知识检索组件了解知识谱系和时间线是至关重要的。这样，系统可以根据给定的查询检索并呈现最相关和最新的信息。
- en: For example, if a query pertains to a standard operating procedure, the procedure
    itself may evolve over time. Without considering the timeline, the system might
    retrieve outdated information, potentially leading to incorrect or irrelevant
    responses. By incorporating knowledge lineage or explicitly specifying the desired
    time frame in the prompt, the system can retrieve the appropriate version of the
    standard operating procedure that aligns with the intended temporal context.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果查询涉及标准操作程序，该程序本身可能会随时间演变。如果不考虑时间线，系统可能会检索过时的信息，可能导致不正确或不相关的响应。通过纳入知识谱系或在提示中明确指定所需的时间框架，系统可以检索与预期时间背景相符的标准操作程序的正确版本。
- en: Alternatively, the knowledge retriever component can be designed to maintain
    and leverage a timeline or versioning system for external knowledge sources. This
    would allow the system to automatically retrieve the most recent and relevant
    information based on the query’s context, without relying solely on prompt engineering.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，知识检索组件可以被设计成维护和利用外部知识源的时间线或版本控制系统。这将允许系统根据查询的上下文自动检索最新和最相关的信息，而无需完全依赖提示工程。
- en: Implementing these considerations is crucial for ensuring the accuracy, relevance,
    and reliability of generative AI applications that depend on external knowledge
    sources, especially in domains where information evolves rapidly or where temporal
    context is critical.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 确保依赖于外部知识源的生成式AI应用的准确性、相关性和可靠性，实施这些考虑因素至关重要，尤其是在信息快速演变或时间背景至关重要的领域。
- en: The list provided earlier serves as a sample of additional considerations. Organizations
    should contemplate additional decision points tailored to their specific needs,
    industry, and regulatory environment. It is crucial to carefully assess the scope
    and use case of generative AI, implementing checks and controls within the defined
    scope to facilitate efficient deployment decision-making. As generative AI technology
    advances, evolving requirements will emerge, necessitating ongoing considerations.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 之前提供的列表是额外考虑因素的样本。组织应考虑针对其特定需求、行业和监管环境定制的额外决策点。仔细评估生成式人工智能的范围和用例，在定义的范围内实施检查和控制，以促进高效的部署决策制定至关重要。随着生成式人工智能技术的进步，将出现新的要求，需要持续考虑。
- en: Practical generative AI business solutions
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实用的生成式人工智能商业解决方案
- en: In the previous chapter, we talked about the business potential of generative
    AI and potential use cases in various industries. We then followed that with a
    detailed discussion of the lifecycle of a generative project from business use
    case identification to deployment. In this chapter, we have covered operational
    considerations, building enterprise generative AI platforms, and one of the most
    important architecture patterns for building generative AI applications, RAG.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了生成式人工智能在各个行业的商业潜力以及潜在用例。然后，我们接着详细讨论了从业务用例识别到部署的生成项目生命周期。在本章中，我们涵盖了运营考虑因素、构建企业生成式人工智能平台以及构建生成式人工智能应用最重要的架构模式之一，即RAG。
- en: In this section, we will highlight some of the more practical generative AI
    solution opportunities ready for business adoption in the near term. While research
    continues on aspirational applications, prudent enterprises should evaluate proven
    pilot use cases to drive measurable impact from generative AI’s rapid advances.
    With these examples, we will present the recommended approach to identify generative
    AI opportunities by understanding challenges associated with the specific business
    workflow within several industries.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将突出一些即将在短期内可供商业采用的更实用的生成式人工智能解决方案机会。虽然对有抱负的应用的研究仍在继续，但谨慎的企业应评估经过验证的试点用例，以从生成式人工智能的快速进步中获得可衡量的影响。通过这些示例，我们将展示通过理解与特定行业业务流程相关的挑战来识别生成式人工智能机会的推荐方法。
- en: Generative AI-powered semantic search engine
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成式人工智能驱动的语义搜索引擎
- en: Enterprise search solutions enable organizations to provide powerful search
    capabilities for their internal data and content. Companies in sectors like technology,
    healthcare, finance, and manufacturing have widely adopted enterprise search platforms
    to improve information discovery for employees. These tools index structured databases,
    intranets, document repositories, emails, and more within an organization. Users
    can then quickly find relevant content by searching instead of hunting across
    siloed systems. Advanced natural language processing, ML algorithms, and cognitive
    capabilities enable enterprise search solutions to deliver precise, relevant results.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 企业搜索解决方案使组织能够为其内部数据和内容提供强大的搜索能力。在技术、医疗保健、金融和制造等领域的公司已广泛采用企业搜索平台，以改善员工的信息发现。这些工具在组织内部索引结构化数据库、内部网络、文档存储库、电子邮件等。用户可以通过搜索而不是在孤岛系统中搜索来快速找到相关内容。高级自然语言处理、机器学习算法和认知能力使企业搜索解决方案能够提供精确、相关的结果。
- en: With the arrival of generative AI technologies, especially LLMs, enterprise
    search can be enhanced to provide an improved user experience, more accurate information,
    and greater specificity. For example, instead of simply returning a list of search
    results using keywords, LLMs can take natural language queries and directly provide
    the answers or a summarized version of an answer in natural language. LLMs can
    help understand the user intent and context semantically in the user queries for
    more relevant information retrieval.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成式人工智能技术的到来，尤其是大型语言模型（LLMs），企业搜索可以增强以提供改进的用户体验、更准确的信息和更高的特异性。例如，LLMs可以接受自然语言查询并直接以自然语言提供答案或答案的摘要版本，而不仅仅是使用关键词返回搜索结果列表。LLMs可以帮助在用户查询中语义上理解用户意图和上下文，以检索更相关的信息。
- en: LLMs can also take query/response history as part of the context when constructing
    search queries against the underlying knowledge base. LLMs can also help rewrite
    the queries with synonyms, related terms, and rephrases to broaden the search
    scope. With LLMs, results can be matched based on meaning, relationship, and concepts
    rather than just keywords.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs还可以将查询/响应历史作为上下文的一部分，在针对底层知识库构建搜索查询时使用。LLMs还可以帮助用同义词、相关术语和改写来重写查询，以扩大搜索范围。使用LLMs，结果可以根据意义、关系和概念进行匹配，而不仅仅是关键词。
- en: There are multiple technology options and architecture patterns available to
    build an enterprise search platform powered by generative AI. You can choose to
    build your own semantic search engine using a combination of open-source and commercial
    components. Building a semantic search engine largely follows the RAG architecture
    pattern we have discussed previously. The following architecture shows a semantic
    search engine using a combination of AWS-managed services and open-source components.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 建立由生成式AI驱动的企业搜索平台有多种技术选项和架构模式可供选择。您可以选择使用开源和商业组件的组合来构建自己的语义搜索引擎。构建语义搜索引擎主要遵循我们之前讨论过的RAG架构模式。以下架构展示了使用AWS托管服务和开源组件组合的语义搜索引擎。
- en: '![A diagram of a chat interface  Description automatically generated](img/B20836_16_09.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![聊天界面的图示 自动生成描述](img/B20836_16_09.png)'
- en: 'Figure 16.9: Semantic search engine on AWS'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.9：AWS上的语义搜索引擎
- en: With this architecture, Kendra takes care of document ingestion and indexing,
    semantic search, and ranking. Amazon OpenSearch can be used to build additional
    alternative knowledge indexes if needed. The LLMs model from Bedrock or hosted
    in SageMaker provide query understanding and response generation via the Amazon
    Lex chat interface.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在此架构下，Kendra负责文档摄取和索引、语义搜索和排名。如有需要，可以使用Amazon OpenSearch构建额外的替代知识索引。Bedrock中的LLMs模型或托管在SageMaker中的模型可以通过Amazon
    Lex聊天界面提供查询理解和响应生成。
- en: Although generative AI significantly improves the enterprise search experience,
    it is essential to acknowledge its limitations. In contrast to traditional keyword
    or semantic search methods, generative AI occasionally yields results that are
    irrelevant or off-topic, lacking the precision characteristic of conventional
    approaches. Moreover, it presents consistency challenges, generating different
    outputs for the same or similar inputs due to variations in its interpretation
    of instructions over time and the accuracy of the index retrievers.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管生成式AI显著提高了企业搜索体验，但承认其局限性是至关重要的。与传统基于关键词或语义搜索方法相比，生成式AI有时会产生不相关或离题的结果，缺乏传统方法的精确性特征。此外，它还面临着一致性挑战，由于对指令的解释随时间变化以及索引检索器的准确性变化，它可能会为相同或相似输入生成不同的输出。
- en: Additionally, there is the potential for privacy concerns, as generative AI
    might inadvertently disclose sensitive information, raising issues related to
    privacy violations if sensitive datasets such as PII/PHI are not masked in the
    model training/tuning process.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还可能存在隐私问题，因为生成式AI可能会无意中泄露敏感信息，如果在模型训练/调整过程中未对PII/PHI等敏感数据集进行屏蔽，可能会引发隐私违规问题。
- en: Financial data analysis and research workflow
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 财务数据分析与研究工作流程
- en: Financial analysts across banking, asset management, and other domains rely
    heavily on analyzing and synthesizing data to deliver insights. For example, an
    investment bank analyst might gather information from earnings reports, news,
    filings, and research coverage to extract details on financials, business outlooks,
    and corporate actions. The analyst then performs a comparative valuation analysis,
    forecasts growth and returns, and advises an investment strategy. This requires
    manually crunching numbers, modeling scenarios, and creating reports to communicate
    findings. With so much reading, data gathering, and analysis required, the process
    is often tedious and time-consuming.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 银行、资产管理以及其他领域的财务分析师高度依赖分析和综合数据以提供洞见。例如，投资银行分析师可能会从收益报告、新闻、文件和研究成果中收集信息，以提取财务、业务前景和公司行为的细节。分析师随后进行比较估值分析，预测增长和回报，并建议投资策略。这需要手动处理数字、模拟场景和创建报告以传达发现。由于需要大量阅读、数据收集和分析，这个过程通常既繁琐又耗时。
- en: 'Generative AI capabilities like natural language processing, data extraction,
    summarization, and text generation have shown promise in augmenting analysts’
    workflows. Generative AI-powered assistants that automate data aggregation, run
    comparative analytics, and draft reports could amplify analyst productivity multifold.
    The following are several areas in the workflow where generative AI can be applied:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI的能力，如自然语言处理、数据提取、总结和文本生成，在增强分析师工作流程方面展现出巨大潜力。由生成式AI驱动的助手可以自动化数据聚合、运行比较分析和撰写报告，从而大幅提高分析师的生产力。以下是在工作流程中可以应用生成式AI的几个领域：
- en: '**Data extraction**: Generative AI provides new capabilities to automatically
    extract structured data from unstructured documents and output it in usable formats.
    Traditional NLP techniques have enabled entity extraction and relation mapping
    to some extent. However, LLMs now achieve superior performance in accurately identifying
    key entities, relationships, and data points in texts. These models can parse
    details like financial figures, corporate actions, and business events from earnings
    reports, filings, news, and other sources. The extracted data can then be formatted
    for seamless loading into workflows like Excel financial models and PowerPoint
    presentations for further analysis. This alleviates tedious manual data entry
    and copying for analysts. With higher accuracy at directly generating structured
    outputs, generative AI can integrate deep unstructured data understanding into
    downstream systems. This fills a major gap in leveraging textual data like reports
    and articles in quantitative finance workflows.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据提取**：生成式AI提供了从非结构化文档中自动提取结构化数据并输出为可用格式的新能力。传统的NLP技术在一定程度上实现了实体提取和关系映射。然而，LLMs现在在准确识别文本中的关键实体、关系和数据点方面实现了更优越的性能。这些模型可以从收益报告、公告、新闻和其他来源中解析出诸如财务数据、公司行为和商业事件等详细信息。提取的数据可以随后格式化，以便无缝加载到Excel财务模型和PowerPoint演示文稿等工作流程中，以进行进一步分析。这减轻了分析师繁琐的手动数据输入和复制工作。通过直接生成结构化输出的更高准确性，生成式AI可以将对非结构化数据的深度理解集成到下游系统中。这填补了在量化金融工作流程中利用报告和文章等文本数据的主要空白。'
- en: '**Document QA**: Generative AI models enable users to ask freeform questions
    in natural language to extract additional insights from documents. For example,
    an analyst could query, “What were the key revenue drivers last quarter?” and
    the model would comprehend the underlying earnings transcript to summarize the
    major growth factors concisely in a generated response. Such ad hoc queries allow
    flexibly extracting only the most relevant points instead of processing the full
    document. The model would focus on areas related to the question and ignore superfluous
    text. By generating condensed, tailored answers to natural language questions,
    generative AI provides a powerful capability to slice and dice documents on demand.
    Analysts can dynamically explore and analyze long reports by conversing with the
    AI in plain language to uncover relevant facts, relationships, and conclusions.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档问答**：生成式AI模型使用户能够用自然语言提出自由形式的问题，从文档中提取额外的见解。例如，分析师可以查询，“上季度的主要收入驱动因素是什么？”模型将理解背后的收益报告，并简洁地总结出主要增长因素，在生成的响应中。这种即兴查询允许灵活地提取最相关的要点，而不是处理整个文档。模型将专注于与问题相关的内容，忽略多余的文字。通过生成针对自然语言问题的浓缩、定制答案，生成式AI提供了强大的按需切片和切块文档的能力。分析师可以通过与AI用普通语言进行对话，动态地探索和分析长篇报告，以揭示相关事实、关系和结论。'
- en: '**Enterprise search and data query against internal data sources**: Conversational
    interfaces powered by generative AI can enable financial analysts to gather data
    through natural dialog. Instead of needing to navigate disparate systems and remember
    specific query languages, analysts could simply ask questions in plain language.
    For example, “Get me the 3-year sales growth by region from the EMEA market database.”
    The model would interpret the intent, translate the required queries for each
    data source, gather the results, and summarize them in a readable format for the
    analyst. This conversational ability to retrieve cross-system data on demand has
    the potential to unify access and accelerate insights. Analysts could explore
    connections across internal document stores, financial databases, knowledge bases,
    and search engines using everyday language.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**针对内部数据源的企业搜索和数据查询**：由生成式人工智能驱动的对话界面可以使金融分析师通过自然对话收集数据。分析师无需导航不同的系统或记住特定的查询语言，他们只需用普通语言提问即可。例如，“从EMEA市场数据库中获取3年的区域销售增长率。”模型将解释意图，将每个数据源所需的查询进行翻译，收集结果，并以可读的格式总结给分析师。这种按需检索跨系统数据的能力有可能统一访问并加速洞察。分析师可以使用日常语言探索内部文档存储、财务数据库、知识库和搜索引擎之间的联系。'
- en: '**Financial analysis and report generation**: Generative AI enables financial
    analysts to directly request certain analytical tasks using natural language instructions.
    For example, an analyst could ask the model, “Compare the 5-year revenue growth
    and profitability margins for the top 5 companies in the industry.” The model
    would then extract relevant financial figures, compute required ratios, generate
    suitable visualizations, and summarize key takeaways in an output report. Where
    required, it could seamlessly leverage external tools and APIs to augment its
    analysis. Unlike rigid commands, natural instructions allow analysts to specify
    bespoke analysis on demand. By automating data gathering, financial modeling,
    and report generation, while coordinating external services, generative AI can
    dramatically amplify an analyst’s productivity.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**财务分析和报告生成**：生成式人工智能使金融分析师能够直接使用自然语言指令请求某些分析任务。例如，分析师可以要求模型，“比较行业前5大公司的5年营收增长率和盈利能力。”然后模型将提取相关的财务数据，计算所需的比率，生成合适的可视化，并在输出报告中总结关键要点。在需要的情况下，它可以无缝利用外部工具和API来增强其分析。与僵化的命令不同，自然指令允许分析师按需指定定制分析。通过自动化数据收集、财务建模和报告生成，同时协调外部服务，生成式人工智能可以显著提高分析师的生产力。'
- en: 'The following example prompt can help provide a financial analysis across a
    number of financial dimensions:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例提示可以帮助在多个金融维度上提供财务分析：
- en: '[PRE1]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Architecturally, building generative AI-powered financial analysis and research
    solutions is mainly based on the RAG architecture and principles. The following
    diagram illustrates a conceptual application architecture for such an application.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在架构上，构建基于生成式人工智能的金融分析和研究解决方案主要基于RAG架构和原则。以下图表展示了此类应用的 conceptual application
    architecture。
- en: '![A diagram of data lake  Description automatically generated](img/B20836_16_10.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![数据湖的图表  描述自动生成](img/B20836_16_10.png)'
- en: 'Figure 16.10: Generative AI-powered financial analysis application'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.10：基于生成式人工智能的财务分析应用
- en: Finance is a highly precise science and business domain, and as such generative
    AI solutions for financial analysis require stringent accuracy and factual grounding.
    To limit hallucination risks in LLMs, techniques beyond prompt engineering and
    fine-tuning are necessary. Advanced information retrieval and embedding approaches
    can enhance output relevancy and correctness.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 金融是一个高度精确的科学和商业领域，因此，用于财务分析的生成式人工智能解决方案需要严格的准确性和事实依据。为了限制LLMs中的幻觉风险，除了提示工程和微调之外，还需要采用其他技术。高级信息检索和嵌入方法可以增强输出的相关性和正确性。
- en: For example, instead of retrieving information just once and then generating
    the response for a query, the system can implement multi-hop information retrieval
    by predicting the related queries and retrieving other relevant information for
    a more complete context. From an embedding perspective, instead of simply chunking
    up documents and creating embeddings for the chunks, additional structural, semantic,
    and domain meta can be combined to create enriched embeddings. On the retrieval
    end, instead of returning the top matching fragments as is from a vector DB, a
    re-ranker can be implemented to post-process the outputs based on unique requirements.
    Comprehensive evaluation techniques and processes also need to be implemented
    to establish high confidence in the system. Where possible, implement a facts
    validator to validate responses against known facts.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，系统可以通过预测相关查询并检索其他相关信息以获得更完整的上下文，从而实现多跳信息检索，而不是仅仅检索一次信息并生成查询的响应。从嵌入的角度来看，系统不是简单地分割文档并为这些片段创建嵌入，还可以结合额外的结构、语义和领域元信息来创建丰富的嵌入。在检索端，系统不是直接从向量数据库中返回匹配的片段，而是可以实施一个重新排序器，根据独特的要求后处理输出。还需要实施全面的评估技术和流程，以建立对系统的信心。在可能的情况下，实施一个事实验证器来验证响应与已知事实的一致性。
- en: Although advanced LLMs and techniques have showcased remarkable capabilities
    in automating or aiding various facets of financial analysis tasks, it remains
    premature to depend solely on LLMs for intricate financial analysis tasks. The
    precision demanded in financial decision-making necessitates accurate information,
    as any inaccuracies in LLM responses could result in substantial negative consequences.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管先进的LLM和技术在自动化或辅助金融分析任务的各个方面展示了显著的能力，但完全依赖LLM进行复杂的金融分析任务还为时尚早。金融决策所需的精确性需要准确的信息，因为LLM响应中的任何不准确都可能导致严重的负面后果。
- en: The financial services industry as a whole has been actively embracing and implementing
    generative AI technology to achieve diverse business objectives. This widespread
    adoption has the potential to significantly impact various financial functions,
    ranging from financial analysis and combating financial crimes to the development
    of new business models, products, and enhanced customer experiences. However,
    this increasing trend also gives rise to concerns, particularly in areas such
    as risk management and transparency. For instance, in financial analysis, maintaining
    transparency is crucial for regulatory compliance and effective risk management.
    The inherent opacity of LLMs may pose challenges in meeting these regulatory requirements.
    Additionally, the demand for explanations in financial decision-making could be
    a potential hurdle, as comprehending the decision-making process of LLMs may prove
    challenging.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 整个金融服务行业一直在积极采用和实施生成式人工智能技术，以实现多样化的商业目标。这种广泛的应用有可能对各种金融功能产生重大影响，从金融分析和打击金融犯罪到新商业模式、产品和客户体验的提升。然而，这种日益增长的趋势也引发了一些担忧，尤其是在风险管理、透明度等方面。例如，在金融分析中，保持透明度对于合规性和有效的风险管理至关重要。LLM的内在不透明性可能对满足这些监管要求构成挑战。此外，在金融决策中对解释的需求可能是一个潜在的障碍，因为理解LLM的决策过程可能具有挑战性。
- en: Clinical trial recruiting workflow
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 临床试验招募工作流程
- en: 'Clinical trials are lengthy research processes that test new medical treatments
    like drugs, devices, or interventions on human subjects. Clinical trials progress
    through different phases to evaluate a new medical treatment, starting with safety
    in smaller groups before expanding to measure efficacy and comparisons. In addition,
    patient recruiting is an important process in all phases of a clinical trial.
    Let’s look at these phases in more detail:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 临床试验是长期的研究过程，测试新的医疗治疗方法，如药物、设备或干预措施对人类受试者的影响。临床试验通过不同的阶段来评估新的医疗治疗方法，从在小群体中的安全性开始，然后扩展到测量有效性和比较。此外，患者招募是临床试验所有阶段的
    重要过程。让我们更详细地看看这些阶段：
- en: In Phase 1 trials, the treatment is given to fewer than 100 people to assess
    safety and side effects. Since it focuses on a smaller, healthy group, recruiting
    patients at this stage is less complex.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第一阶段试验中，治疗仅给予不到100人，以评估安全性和副作用。由于它关注的是较小的、健康的群体，因此在这个阶段招募患者较为简单。
- en: Phase 2 trials administer the treatment to several hundred participants with
    the target condition. Here, researchers continue collecting safety data while
    gathering preliminary efficacy information. Recruiting becomes more difficult
    as patients need to have the specific condition.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第2阶段试验将治疗给予数百名具有目标条件的参与者。在这里，研究人员继续收集安全性数据，同时收集初步的有效性信息。随着患者需要具有特定条件，招募变得更加困难。
- en: In Phase 3, the trial expands to 300-3000 participants to further understand
    safety, efficacy, dosages, and how it compares to existing treatments. The much
    larger sample size covering diverse demographics makes recruiting extremely challenging
    at this advanced stage.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第3阶段，试验扩展到300-3000名参与者，以进一步了解安全性、有效性、剂量以及与现有治疗的比较。覆盖不同人群的更大样本量使得在这个高级阶段招募变得极具挑战性。
- en: Phase 4 trials monitor the approved treatment in broad real-world populations
    to gather additional long-term safety and efficacy data. Recruiting for Phase
    4 can also be challenging as criteria tend to be more expansive.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第4阶段试验在广泛的现实世界人群中监测批准的治疗，以收集额外的长期安全性和有效性数据。由于标准往往更加宽泛，第4阶段的招募也可能具有挑战性。
- en: During recruitment, clinical research coordinators meticulously screen patient
    medical history across various systems like electronic health records to check
    if criteria like health status, past conditions, medications, demographics, etc.
    match the trial’s eligibility requirements. This manual and repetitive process
    of collating data from multiple sources to identify matches is a major bottleneck.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在招募过程中，临床研究协调员会仔细审查患者的医疗历史，跨越各种系统，如电子健康记录，以检查健康状况、既往状况、药物、人口统计学等是否符合试验的资格要求。从多个来源收集数据以识别匹配的这种手动和重复的过程是主要瓶颈。
- en: Generative AI could automate and accelerate screening by intelligently querying
    patient EHR data against complex inclusion/exclusion logic specified in natural
    language. As EHRs contain comprehensive histories including diagnoses, medications,
    procedures, and test results, the models can parse criteria and rapidly filter
    candidates. For example, a researcher can directly ask the generative AI platform
    to compare a patient’s EHR records with the inclusion/exclusion criteria to determine
    if the patient is a match. Generative AI can also help synthesize and generate
    a summarized report about the overall selected cohort population and individual
    patients to help with human review. This can significantly speed up finding eligible
    patients for different trial phases.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI可以通过智能查询患者EHR数据与自然语言中指定的复杂纳入/排除逻辑来自动化和加速筛选。由于EHR包含包括诊断、药物、程序和测试结果在内的全面历史记录，模型可以解析标准并快速筛选候选人。例如，研究人员可以直接要求生成式AI平台比较患者的EHR记录与纳入/排除标准，以确定患者是否为匹配对象。生成式AI还可以帮助综合和生成关于整体选定队列人群和个别患者的总结报告，以帮助进行人工审查。这可以显著加快在不同试验阶段找到合格患者的过程。
- en: Additionally, combining generative capabilities with predictive analytics can
    optimize trial performance. The combined capabilities can forecast enrollment
    rates, monitor site progress, and trigger recommended interventions when delays
    or issues occur by generating insights from patient and site data.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，将生成能力与预测分析相结合可以优化试验性能。结合的能力可以预测招募率，监控站点进度，并在出现延误或问题时通过从患者和站点数据中生成见解来触发建议的干预措施。
- en: 'The following diagram shows a conceptual flow of applying generative AI and
    traditional predictive analytics to optimize the various tasks within clinical
    trials:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了将生成式AI和传统预测分析应用于优化临床试验中各种任务的构想流程。
- en: '![A diagram of a computer  Description automatically generated](img/B20836_16_11.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![计算机图示 自动生成描述](img/B20836_16_11.png)'
- en: 'Figure 16.11: Clinical trial optimization'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.11：临床试验优化
- en: 'The following is an example command for patient search against medical records
    using a list of inclusion and exclusion criteria:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个使用纳入和排除标准搜索医疗记录的示例命令：
- en: '[PRE2]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Behind the scenes of the command, an agent can facilitate the search of patient
    records against the semantic search engine of EHR records and generate a response
    with a list of matching patients.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在命令的背后，一个代理可以促进对EHR记录语义搜索引擎中患者记录的搜索，并生成一个包含匹配患者列表的响应。
- en: While generative AI has the potential to automate and accelerate patient recruitment
    for clinical trials, it is crucial to keep qualified humans in the loop throughout
    the process. AI systems alone cannot fully validate that trial participants meet
    the complex eligibility criteria, which often involves interpreting medical histories,
    test results, prior conditions, and more. Humans with clinical expertise need
    to review participant profiles surfaced by AI to catch any inaccurate assessments
    of eligibility and prevent improper enrollment.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然生成式人工智能有潜力自动化并加速临床试验的患者招募，但在整个过程中保持合格的人类参与是至关重要的。仅靠人工智能系统无法完全验证试验参与者是否符合复杂的资格标准，这通常涉及解读病史、测试结果、既往状况等。具有临床专业知识的人类需要审查人工智能呈现的参与者资料，以捕捉任何关于资格评估的不准确之处，并防止不当的招募。
- en: In addition, human oversight is required to ensure AI-assisted recruiting adheres
    to ethical guidelines around transparency, fairness, and avoiding undue influence.
    Participants should comprehend why they were targeted and how their data is used.
    Automated processes could lead to opaque and biased recruiting without checks
    against discrimination. Experienced clinical research staff need to steward participant
    interactions to uphold understandability, equitability, and medical appropriateness.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还需要人类监督以确保人工智能辅助的招募遵守关于透明度、公平性和避免不当影响的伦理指南。参与者应理解为什么被选中以及他们的数据如何被使用。如果没有针对歧视的检查，自动化流程可能导致不透明和有偏见的招募。经验丰富的临床研究人员需要管理参与者互动，以维护可理解性、公平性和医学适宜性。
- en: Lastly, human involvement lends necessary nuance and discretion on a case-by-case
    basis. Factors like availability, transportation needs, and personal situations
    must be weighed. AI models alone lack the empathy and adaptability needed. The
    clinical trial process ultimately deals with human lives, so the compassion and
    experience of human recruiters remain indispensable when augmented by AI efficiency
    gains.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在个案基础上，人类的参与提供了必要的细微差别和判断力。需要权衡的因素包括可用性、交通需求和个人情况。仅靠人工智能模型缺乏必要的同理心和适应性。临床试验过程最终涉及人类生命，因此，当人工智能效率提升时，人类招募人员的同情心和经验仍然是不可或缺的。
- en: In conclusion, generative AI’s ability to deeply understand criteria, reason
    across data sources, and generate matches and recommendations offers immense potential
    to transform the protracted patient recruitment process to help advance critical
    medical research. It is also important to acknowledge its limitations, such as
    hallucination, opaqueness, and privacy concerns such as the handling of PII/PHI
    data. Furthermore, the regulatory environment around the adoption of generative
    AI for clinical trials remains unclear, which poses challenges in the adoption
    of generative AI in this domain.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，生成式人工智能深入理解标准、跨数据源推理以及生成匹配和推荐的能力，为将漫长的患者招募过程转变为帮助推进关键医学研究提供了巨大潜力。同时，也必须承认其局限性，如幻觉、不透明性和隐私问题，例如处理PII/PHI数据。此外，关于在临床试验中采用生成式人工智能的监管环境尚不明确，这给生成式人工智能在该领域的采用带来了挑战。
- en: Media entertainment content creation workflow
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 媒体娱乐内容创作工作流程
- en: The content creation process in the media and entertainment industry encompasses
    multiple stages, spanning from idea generation and scriptwriting to casting, production,
    post-production editing, sound design, graphics and animation, distribution, marketing,
    and monetization. However, this process is accompanied by various challenges that
    can impact the success of a project. These challenges include the need to generate
    unique and resonating ideas, crafting compelling and coherent storylines, ensuring
    that visual representations effectively convey intended emotions, the time-consuming
    nature of post-production editing, and the difficulty in selecting or creating
    suitable music and sounds.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 媒体和娱乐行业的内容创作过程包括多个阶段，从创意生成和剧本创作到选角、制作、后期制作编辑、音效设计、图形和动画、发行、营销和货币化。然而，这个过程伴随着各种挑战，可能会影响项目的成功。这些挑战包括需要产生独特且引人共鸣的想法、构建引人入胜且连贯的故事情节、确保视觉表现能够有效地传达预期的情感、后期制作编辑的耗时性，以及选择或创造合适的音乐和声音的困难。
- en: Additionally, specialized skills are often required for animation and visual
    effects, and breaking through the competitive market with effective marketing
    strategies can be a daunting task.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，动画和视觉效果通常需要专门的技能，而通过有效的营销策略在竞争激烈的市场中脱颖而出可能是一项艰巨的任务。
- en: 'Generative AI presents a promising solution to address these challenges in
    practical ways:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI以实际可行的方式解决这些挑战，提供了一个有希望的解决方案：
- en: '**Script generation**: Generative AI can be used to generate movie or TV show
    scripts based on human-provided ideas and inputs.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**剧本生成**：生成式AI可以根据人类提供的思想和输入生成电影或电视剧本。'
- en: '**Storyboarding**: Generative AI can propose visual representations aligned
    with intended themes and emotions from the scripts.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分镜设计**：生成式AI可以提出与剧本中预期的主题和情感相一致的可视化表示。'
- en: '**Production**: Generative AI can be used to generate images and photos needed
    on film sets.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**制作**：生成式AI可以用于生成电影拍摄现场所需的图像和照片。'
- en: '**Post-production editing**: Generative AI can help automate post-production
    editing processes through techniques like text-guided editing. For example, you
    can use generative to create special effects, and for editing scenes and images.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**后期制作编辑**：生成式AI可以通过文本引导编辑等技术自动化后期制作编辑流程。例如，你可以使用生成式AI来创建特效，以及编辑场景和图像。'
- en: '**Media asset search**: Generative AI can help enhance media content search
    through advanced tagging and semantic matching.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**媒体资产搜索**：生成式AI可以通过高级标签和语义匹配帮助增强媒体内容搜索。'
- en: '**Marketing and promotion**: Generative AI can generate compelling marketing
    messages and visuals for promotional campaigns.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**市场营销和推广**：生成式AI可以生成吸引人的营销信息和视觉内容，用于促销活动。'
- en: '**Engagement**: Generative AI can enhance user engagement experience through
    personalization and recommendations.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参与度**：生成式AI可以通过个性化和建议来增强用户体验。'
- en: 'The following diagram shows where generative AI can be applied throughout the
    media lifecycle:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示显示了生成式AI在整个媒体生命周期中的应用：
- en: '![A diagram of a marketing process  Description automatically generated](img/B20836_16_12.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![营销流程图  自动生成的描述](img/B20836_16_12.png)'
- en: 'Figure 16.12: Media content development and distribution flow'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.12：媒体内容开发和分发流程
- en: 'The following is an example of a prompt to generate a movie script:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个生成电影剧本的提示示例：
- en: '[PRE3]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If you run the preceding prompt against ChatGPT, you could get something like
    the following:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将前面的提示输入到ChatGPT中，你可能会得到以下内容：
- en: '[PRE4]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If we want to create visual representations for some of the scenes from the
    script, we can employ a text-to-image model. For instance, we can provide the
    following input to a Stable Diffusion model:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要为剧本中的某些场景创建视觉表示，我们可以使用文本到图像模型。例如，我们可以向Stable Diffusion模型提供以下输入：
- en: '[PRE5]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The resulting image would resemble the image depicted here:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图像将类似于以下图像：
- en: '![](img/B20836_16_13.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![分镜设计图](img/B20836_16_13.png)'
- en: 'Figure 16.13: Storyboarding using text-to-image model'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.13：使用文本到图像模型进行分镜设计
- en: It’s still early days for generative AI-created entertainment, but it is already
    clear that the tremendous opportunities have attracted many companies to build
    generative AI tools for media use cases such as storyline generation tools. A
    generative AI video editing tool from Runway, a company that builds video editing
    tools, has been used for post-production editing such as in *Everything, Everywhere,
    All At Once*. However, this type of tool raises questions about intellectual property.
    If AI creates a new character influenced by a well-known figure, who owns the
    copywrite? There is also concern about the social impact that this technology
    will have on creative professionals such as animators, scriptwriters, and visual
    artists. Some generative AI technologies have taken a more cautious approach to
    creative content generation. For example, the Claude chatbot tool from Anthropic
    will block the generation of full-length movie scripts to avoid potential negative
    consequences.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI创造的娱乐内容还处于早期阶段，但已经很明显，巨大的机遇吸引了众多公司为媒体用例如剧情生成工具等构建生成式AI工具。Runway公司，一家视频编辑工具构建公司，其生成式AI视频编辑工具已被用于如《一切，无处不在，同时发生》等电影的后期制作。然而，这类工具引发了关于知识产权的问题。如果AI创造了一个受知名人物影响的全新角色，版权归谁所有？还有关于这项技术将对动画师、编剧和视觉艺术家等创意专业人士产生的社会影响的担忧。一些生成式AI技术对创意内容生成采取了更为谨慎的方法。例如，Anthropic公司的Claude聊天机器人工具将阻止生成完整的电影剧本，以避免潜在的负面后果。
- en: Car design workflow
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 汽车设计工作流程
- en: 'Car design plays an essential role in shaping a high-quality automobile. It
    encompasses three key domains: exterior design, interior design, and color and
    trim design. The design team responsible for the exterior of the vehicle develops
    the proportions, shape, and surface details of the vehicle. The interior designer
    develops the proportions, shape, placement, and surfaces for the instrument panel,
    seats, door trim panels, headliner, pillar trims, etc.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 汽车设计在塑造高质量汽车方面发挥着至关重要的作用。它包括三个关键领域：外观设计、内饰设计和颜色及装饰设计。负责车辆外观的设计团队开发车辆的比例、形状和表面细节。内饰设计师开发仪表盘、座椅、车门装饰面板、车顶内衬、立柱装饰等的比例、形状、位置和表面。
- en: Here, the emphasis is on ergonomics and the comfort of the passengers. Lastly,
    the trim designer is responsible for the research, design, and development of
    all interior and exterior colors and materials used on a vehicle.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，重点是人体工程学和乘客的舒适性。最后，内饰设计师负责车辆上所有内饰和外观颜色及材料的研究、设计和开发。
- en: The design development process for exterior and interior design starts with
    manual sketches and digital drawings, which form the foundation of concept development.
    These sketches and drawings undergo rigorous review and approval processes within
    various layers of management. Subsequently, the concept is rendered into a digital
    format using a **computer-aided styling** (**CAS**) tool to further refine the
    style, and the design is transformed into vivid images. After that, industrial
    plasticine or clay modeling is developed from the images.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 外部和内饰设计的设计开发过程始于手工草图和数字绘图，这些构成了概念发展的基础。这些草图和绘图在各个管理层中经过严格的审查和批准流程。随后，概念通过**计算机辅助设计**（**CAS**）工具渲染成数字格式，以进一步细化风格，并将设计转化为生动的图像。之后，从图像中开发出工业塑料或粘土模型。
- en: During the design process, it is imperative to maintain alignment with the designer’s
    stylistic vision while adhering to stringent criteria encompassing performance,
    manufacturability, and safety regulations. This requires product engineering to
    work concurrently with the designer to ensure the styling is grounded in various
    engineering constraints.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计过程中，必须保持与设计师的风格愿景一致，同时遵守包括性能、可制造性和安全法规在内的严格标准。这需要产品工程与设计师协同工作，以确保设计符合各种工程限制。
- en: 'One area generative AI can play a role is concept development. Designers can
    use text-guided prompts, using keywords such as “pronounced spoiler,” “futuristic,”
    or “aerodynamics,” to swiftly generate car design concepts. General-purpose text-to-image
    models such as Stable Diffusion, Imagen, Amazon Titan Image Generator and DALLE-2
    models have demonstrated immense potential in text-guided concept design. For
    example, the following prompt example will generate a car exterior concept:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI可以在概念发展中发挥作用。设计师可以使用文本引导的提示，使用诸如“明显的尾翼”、“未来派”或“空气动力学”等关键词，快速生成汽车设计概念。通用文本到图像模型，如Stable
    Diffusion、Imagen、Amazon Titan Image Generator和DALLE-2模型，在文本引导的概念设计中展示了巨大的潜力。例如，以下提示示例将生成一辆汽车外观概念：
- en: '[PRE6]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following is one output variation when running the prompt using the Stable
    Diffusion model from Stability AI:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在使用Stability AI的Stable Diffusion模型运行提示时的一个输出变体：
- en: '![A blue sports car on a road  Description automatically generated](img/B20836_16_14.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![一条路上的一辆蓝色跑车  自动生成的描述](img/B20836_16_14.png)'
- en: 'Figure 16.14: Sports car concept design using generative AI'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.14：使用生成式AI的跑车概念设计
- en: It is important to note, however, that these tools can only provide a source
    of style inspiration and do not address complex engineering and safety considerations
    integral to actual car design for production. These models need to be enhanced
    to support image generation while also optimizing specific engineering constraints.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，这些工具只能提供风格灵感的来源，并不能解决实际汽车设计中不可或缺的复杂工程和安全考虑。这些模型需要增强以支持图像生成，同时优化特定的工程限制。
- en: Progress has been made in this area, with examples like drag-guided diffusion
    models that can render creative car concepts while minimizing drag. Technically,
    these techniques aim to minimize an auxiliary loss function tied to a particular
    constraint, such as drag, during the model training and image generation process.
    As a result, when a car design image is generated, it also aligns with optimized
    constraints, such as minimizing the drag value.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域已经取得了一些进展，例如拖拽引导扩散模型，可以在最小化阻力的情况下渲染创意汽车概念。技术上，这些技术旨在在模型训练和图像生成过程中最小化与特定约束（如阻力）相关的辅助损失函数。因此，当生成汽车设计图像时，它也符合优化的约束，如最小化阻力值。
- en: '![A diagram of a car  Description automatically generated](img/B20836_16_15.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![汽车图解  描述自动生成](img/B20836_16_15.png)'
- en: 'Figure 16.15: Generative AI-powered car design flow'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.15：由生成式AI驱动的汽车设计流程
- en: Such tools have the potential to greatly enhance the productivity of both car
    designers and product engineers, enabling them to avoid investing time in impractical
    car design concepts that cannot be feasibly produced for the market.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具有可能极大地提高汽车设计师和产品工程师的生产力，使他们能够避免在无法实际生产的汽车设计概念上浪费时间。
- en: The adoption of generative AI in the automotive industry has significant implications
    across various aspects of the sector. Generative AI has the potential to revolutionize
    vehicle design, manufacturing processes, and overall operational efficiency. It
    can play a crucial role in the development of autonomous vehicles, enhancing their
    perception, decision-making, and response capabilities. However, the adoption
    of generative AI in the automotive industry also raises challenges and considerations.
    Safety and security concerns, ethical considerations related to decision-making
    algorithms, and regulatory compliance are critical aspects that need careful attention.
    Striking the right balance between innovation and responsible use of AI is crucial
    for the successful and sustainable integration of generative AI in the automotive
    sector.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI在汽车行业的应用对行业的各个方面都有重大影响。生成式AI有潜力彻底改变车辆设计、制造流程和整体运营效率。它可以在自动驾驶汽车的开发中发挥关键作用，增强其感知、决策和响应能力。然而，生成式AI在汽车行业的应用也带来了挑战和考虑因素。安全和安全方面的担忧、与决策算法相关的伦理考量以及法规遵从性是需要仔细关注的重点方面。在创新和负责任地使用AI之间取得平衡对于生成式AI在汽车行业的成功和可持续集成至关重要。
- en: Contact center customer service operation
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 联系中心客户服务运营
- en: Generative AI has the potential to revolutionize the entire customer operations
    function, improving the customer experience and agent productivity through digital
    self-service and enhancing and augmenting agent skills. The technology has already
    gained traction in customer service because of its ability to automate interactions
    with customers using natural language. Contact centers are critical customer service
    operations across sectors like finance, telecom, and healthcare. Key responsibilities
    include workforce staffing, performance monitoring, agent training, and customer
    engagement.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI有潜力彻底改变整个客户运营职能，通过数字自助服务提高客户体验和代理生产力，并通过增强和提升代理技能来改善。这项技术因其能够使用自然语言自动化与客户的互动而已经在客户服务领域取得了进展。联系中心是金融、电信和医疗保健等行业的核心客户服务运营。主要职责包括人员配备、绩效监控、代理培训和客户参与。
- en: However, several challenges plague contact center workflows – high call volumes,
    agent attrition, inconsistent service quality, meeting customer speed and personalization
    expectations, and agent burnout. Multilingual support and extracting insights
    from customer feedback add complexity.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，几个挑战困扰着联系中心的工作流程——高呼叫量、代理流失、服务质量不一致、满足客户速度和个人化期望以及代理疲劳。多语言支持和从客户反馈中提取见解增加了复杂性。
- en: 'Generative AI can address many of these challenges:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI可以解决许多这些挑战：
- en: For agent training, models can synthesize guided learning content from call
    transcripts and history. Generative AI can enhance quality assurance and coaching
    by gathering insights from customer conversations, determining what could be done
    better, and coaching agents.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于代理培训，模型可以从通话记录和历史中合成引导学习内容。生成式AI可以通过从客户对话中获取见解、确定可以做得更好的地方以及指导代理来提高质量保证和辅导。
- en: During customer interactions, AI assistants provide agents with real-time recommendations
    and answers to boost resolution rates. For example, generative AI can instantly
    retrieve data a company has on a specific customer, which can help a human customer
    service representative more successfully answer questions and resolve issues during
    an initial interaction. Generative AI can cut the time a human sales representative
    spends responding to a customer by providing assistance in real time and recommending
    the next steps.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在客户互动过程中，AI助手为代理提供实时建议和答案，以提高解决率。例如，生成式AI可以立即检索公司关于特定客户的数据，这有助于人类客户服务代表在初次互动中更成功地回答问题和解决问题。生成式AI可以通过实时提供帮助和推荐下一步行动来减少人类销售代表响应客户所需的时间。
- en: For self-service, generative AI-fueled chatbots can give immediate and personalized
    responses to complex customer inquiries regardless of the language or location
    of the customer. By improving the quality and effectiveness of interactions via
    automated channels, generative AI could automate responses to a higher percentage
    of customer inquiries, enabling customer care teams to take on inquiries that
    can only be resolved by a human agent.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于自助服务，由生成式AI驱动的聊天机器人可以立即提供个性化的响应，以应对复杂的客户查询，无论客户的语言或位置如何。通过通过自动化渠道提高互动的质量和有效性，生成式AI可以自动化对更高比例的客户查询的响应，使客户关怀团队能够处理只能由人工代理解决的问题。
- en: Post-call analysis by generative models identifies areas for improvement from
    conversation data.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过生成模型进行的通话后分析确定了从对话数据中改进的领域。
- en: Mining dialogs also reveals customer needs and intents to generate cross-sell
    opportunities.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挖掘对话也揭示了客户的需求和意图，以生成交叉销售机会。
- en: Enabling call centers with generative AI capabilities requires the integration
    of LLMs, semantic search engines, and contact center applications. The following
    diagram shows an architecture for enabling Amazon Connect (an AWS call center
    service) with generative AI and chatbot capabilities.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 使呼叫中心具备生成式AI功能需要集成LLMs（大型语言模型）、语义搜索引擎和接触中心应用程序。以下图显示了为Amazon Connect（AWS呼叫中心服务）启用生成式AI和聊天机器人功能的架构。
- en: '![A diagram of a phone  Description automatically generated](img/B20836_16_16.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![电话图  自动生成的描述](img/B20836_16_16.png)'
- en: 'Figure 16.16: Generative AI-powered contact center self-service'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.16：由生成式AI驱动的接触中心自助服务
- en: With careful implementation, generative AI can drive significant operational
    efficiencies, service quality improvements, and customer experience breakthroughs
    across the contact center. With all the possibilities, it is also important to
    recognize the potential limitations of adopting generative AI for contact centers
    such as providing factually incorrect answers due to hallucination and misunderstanding
    of user queries, risk of exposing sensitive and private information, and introducing
    potentially harmful and biased responses.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 通过谨慎的实施，生成式AI可以在接触中心推动显著的操作效率、服务质量改进和客户体验突破。在所有可能性中，认识到采用生成式AI为呼叫中心带来的潜在局限性也很重要，例如由于幻觉和对用户查询的理解错误而提供事实错误答案的风险，暴露敏感和私人信息的风险，以及引入可能有害和有偏见的响应。
- en: Are we close to having artificial general intelligence?
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们是否接近拥有通用人工智能？
- en: '**Artificial General Intelligence** (**AGI**) is a field within theoretical
    AI research working to create AI systems with cognitive functions comparable to
    human capabilities. AGI remains a theoretical concept that’s not well defined,
    and its definition and opinions on its eventual realization vary. Nevertheless,
    loosely speaking, AGI involves AI systems/agents equipped with a broad capacity
    to understand and learn across many diverse domains and address diverse problems
    in various contexts, not just narrow expertise in one field. These systems should
    have the ability to generalize the knowledge they gain, transfer learning from
    one domain, and apply knowledge and skills to novel situations and problems like
    humans do.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '**通用人工智能**（**AGI**）是理论人工智能研究中的一个领域，致力于创建具有与人类能力相当认知功能的AI系统。AGI仍然是一个定义不明确的理论概念，其定义及其最终实现的观点各不相同。然而，从广义上讲，AGI涉及具有广泛理解和学习能力的人工智能系统/代理，能够在许多不同的领域理解和解决问题，而不仅仅是某一领域的狭窄专业知识。这些系统应该能够概括他们获得的知识，从某一领域迁移学习，并将知识和技能应用于人类所做的新颖情境和问题。'
- en: The impressive capabilities displayed by LLMs and diffusion models have generated
    a lot of excitement about the potential to achieve AGI. Their ability to perform
    reasonably well across a wide variety of natural language processing and image
    generation tasks with minimal fine-tuning seems closer to flexible human-like
    intelligence than the previous narrow AI systems. As a result, there is increasingly
    optimistic speculation among some researchers and the media about whether we are
    on the brink of achieving true AGI through just the scaling of the data, model,
    and compute.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs和扩散模型所展现的令人印象深刻的性能已经引发了人们对实现通用人工智能（AGI）潜力的极大兴趣。它们在自然语言处理和图像生成等众多任务中，仅需少量微调就能表现出色，这似乎比之前的窄AI系统更接近灵活的人类智能。因此，一些研究人员和媒体对是否仅通过数据、模型和计算的扩展就能实现真正的AGI越来越持乐观看法。
- en: However, most AI experts caution that we still have a long way to go to realize
    fully general and human-level intelligence. While very broad in scope, FMs remain
    confined to language and visual domains. Moreover, their knowledge and reasoning
    abilities remain brittle and narrow compared to humans. Transferring learning
    across radically different tasks and knowledge domains remains difficult for current
    FMs. Moreover, multimodality is integral to human intelligence, and while significant
    progress has been made in multimodal AI, it is still early to have seamlessly
    integrated understanding and reasoning of different modalities like text, image,
    video, sound, touch, social cues, etc. Thus, while the capabilities of LLMs like
    GPT and Anthropic Claude represent notable progress, we are still far from replicating
    the robustness, flexibility, and multidimensional qualities of human cognition.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数AI专家警告说，我们还有很长的路要走才能实现完全通用和人类水平的人工智能。虽然FM的范围非常广泛，但它们仍然局限于语言和视觉领域。此外，与人类相比，它们的认知能力和推理能力仍然脆弱且狭窄。对于当前FM来说，跨不同任务和知识领域的迁移学习仍然很困难。此外，多模态是人类智能的组成部分，尽管在多模态AI方面取得了显著进展，但将不同模态（如文本、图像、视频、声音、触觉、社交线索等）的无缝理解和推理整合在一起仍然为时尚早。因此，虽然像GPT和Anthropic
    Claude这样的LLMs的能力代表了显著的进步，但我们仍然远未复制人类认知的稳健性、灵活性和多维特性。
- en: 'To help measure the progress of AGI, Google’s DeepMind has published an AGI
    levels guide using performance and generality (narrow tasks vs. a range of general
    tasks) as the two dimensions. On the performance dimension, there are six levels
    in the guide:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助衡量AGI的进展，谷歌的DeepMind发布了一份AGI级别指南，使用性能和通用性（窄任务与一系列通用任务）作为两个维度。在性能维度上，指南中有六个级别：
- en: '**Level 0 – No AI**: At this level, AI is not used for either narrow or general
    intelligent tasks.'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第0级 – 无AI**：在这个级别，AI既不用于窄任务也不用于通用智能任务。'
- en: '**Level 1 – Emergent**: At this level, AI is equal to or better than unskilled
    humans in either some narrow tasks or a range of general tasks. The guide states
    that FMs such as GPT, Bard, Llama 2, Claude, and Gemini have achieved this level
    of maturity.'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第1级 – 出现**：在这个级别，AI在某些窄任务或一系列通用任务中与无技能人类相当或更好。指南指出，GPT、Bard、Llama 2、Claude和Gemini等FM已经达到了这个成熟度级别。'
- en: '**Level 2 – Competent**: At this level, AI is better than at least 50% of skilled
    adults. According to the guide, some narrowly focused AI technology has achieved
    this level on some narrow tasks such as AI assistants like Siri and Alexa, essay
    writing, and coding. However, AGI has not achieved this level of progress.'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第2级 – 能力**：在这个级别，AI优于至少50%的熟练成年人。根据指南，一些专注于狭窄领域的AI技术已经在某些狭窄任务上实现了这一水平，例如Siri和Alexa这样的AI助手、论文写作和编码。然而，AGI尚未达到这一进展水平。'
- en: '**Level 3 – Expert**: At this level, AI is better than at least 90% of skilled
    adults. Technologies such as AI grammar checkers and image generators have achieved
    this level on specific narrow tasks, however, no AGI has arrived at this level.'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第3级 – 专家**：在这个级别，AI优于至少90%的熟练成年人。像AI语法检查器和图像生成器这样的技术已经在特定狭窄任务上达到了这一水平，然而，还没有AGI达到这一水平。'
- en: '**Level 4 – Virtuoso**: At this level, AI is better than 99% of skilled adults.
    Only a few narrow AI technologies such as AlphaGo have achieved this level of
    capability on narrow AI tasks.'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第四级 – 精通者**：在这个级别，AI的技能优于99%的熟练成年人。只有少数像AlphaGo这样的窄AI技术在这一级别的窄AI任务上实现了这种能力。'
- en: '**Level 5 – Superhuman**: This is where AI is better than 100% of humans. Again,
    only narrow AI such as AlphaFold (a protein folding model), AlphaZero (an AI model
    that plays the game of Go), and Stockfish (an open-source chess engine) has achieved
    this level of capability. So what is the path to achieving AGI? No one has claimed
    they know the definitive answer yet, but the pursuit continues through the exploration
    of various active research areas such as multi-modality understanding, memory
    management, cross-domain reasoning and planning, and continuous self-learning.
    Furthermore, leading AI experts have been proposing diverse theoretical approaches
    in these domains, ranging from the integration of symbolic reasoning and connectionist
    architectures to the study of emergent phenomena, and the whole organism approach.
    In the subsequent section, let’s explore the symbolic, connectionist, and neural-symbolic
    approaches.'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第五级 – 超人类**：这是人工智能优于100%的人类的地方。再次强调，只有像AlphaFold（一个蛋白质折叠模型）、AlphaZero（一个玩围棋的人工智能模型）和Stockfish（一个开源的国际象棋引擎）这样的窄人工智能达到了这一能力水平。那么实现通用人工智能的路径是什么？至今没有人声称他们知道确切的答案，但追求仍在通过探索各种活跃的研究领域继续进行，如多模态理解、内存管理、跨领域推理和规划以及持续的自学习。此外，领先的AI专家们在这些领域提出了各种理论方法，从符号推理和连接主义架构的集成到对涌现现象的研究，以及整体有机体方法。在下一节中，我们将探讨符号、连接主义和神经符号方法。'
- en: The symbolic approach
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 符号方法
- en: The symbolic approach relies on explicitly representing knowledge and reasoning
    using symbolic representations, such as logical statements, rules, and structured
    data formats. In this paradigm, the knowledge about a particular domain is manually
    encoded into the system using formal languages and logical formalisms. An example
    of symbolic representation could be “dogs have four legs.” This encoded knowledge
    forms a knowledge base, which acts as a repository of facts, concepts, relationships,
    and rules that define how the world works within that domain. The symbolic AI
    system then uses an inference engine, which is a component that applies logical
    operations and rules of reasoning to the knowledge base. This allows the system
    to derive new conclusions, make inferences, and solve problems by manipulating
    and combining the symbolic representations in a structured and logical manner.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 符号方法依赖于使用符号表示法明确表示知识和推理，例如逻辑语句、规则和结构化数据格式。在这个范例中，特定领域的知识是通过形式语言和逻辑形式主义手动编码到系统中的。符号表示的一个例子可以是“狗有四条腿。”这种编码的知识形成了一个知识库，它作为事实、概念、关系和规则的存储库，这些规则定义了该领域内世界运作的方式。符号人工智能系统随后使用推理引擎，这是一个应用逻辑运算和推理规则的组件。这使得系统能够通过以结构化和逻辑的方式操纵和组合符号表示来推导新的结论、进行推理和解决问题。
- en: For example, in a symbolic AI system designed for medical diagnosis, the knowledge
    base might contain rules that represent the relationships between symptoms, diseases,
    and treatments. The inference engine could then use these rules to analyze a patient’s
    symptoms and logically deduce the most likely diagnosis and appropriate treatment
    plan.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在一个为医学诊断设计的符号人工智能系统中，知识库可能包含表示症状、疾病和治疗之间关系的规则。推理引擎随后可以使用这些规则来分析患者的症状，并逻辑地推断出最可能的诊断和适当的治疗方案。
- en: One of the key advantages of symbolic AI is its ability to provide explainable
    and interpretable reasoning. Since the knowledge and reasoning processes are explicitly
    represented, the system’s decision-making process can be traced and understood
    by humans, which is particularly important in domains such as finance, law, and
    healthcare, where transparency and accountability are crucial.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 符号人工智能的一个关键优势是它能够提供可解释和可理解的推理。由于知识和推理过程是明确表示的，因此人类可以追踪和理解系统的决策过程，这在金融、法律和医疗保健等领域尤为重要，在这些领域，透明度和问责制至关重要。
- en: However, symbolic AI systems also face challenges, such as the knowledge acquisition
    bottleneck, where manually encoding vast amounts of knowledge can be time-consuming
    and labor-intensive.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，符号人工智能系统也面临挑战，例如知识获取瓶颈，手动编码大量知识可能既耗时又费力。
- en: Additionally, these systems often struggle with handling ambiguity, uncertainty,
    and context-dependent knowledge, which are more easily tackled by other AI approaches,
    such as ML and neural networks.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这些系统在处理歧义、不确定性和上下文相关的知识方面往往遇到困难，而这些知识对于其他人工智能方法（如机器学习和神经网络）来说则更容易解决。
- en: '![](img/B20836_16_17.png)Figure 16.17: Symbolic approach'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '![图16.17：符号方法](img/B20836_16_17.png)'
- en: One prominent example of symbolic projects is the Cyc project, which stands
    as one of the longest-running symbolic AI initiatives. This ambitious endeavor
    aims to construct a comprehensive ontology and knowledge base that captures common
    sense rules about how the world operates. The Cyc project employs formal logic
    as its primary mechanism for reasoning and inference.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 符号项目的一个突出例子是Cyc项目，这是持续时间最长的符号人工智能倡议之一。这个雄心勃勃的项目旨在构建一个全面的本体和知识库，捕捉关于世界如何运作的常识规则。Cyc项目采用形式逻辑作为其推理和推理的主要机制。
- en: While groundbreaking in its scope and ambition, the Cyc project also highlights
    key challenges inherent to the symbolic AI approach. These challenges include
    the knowledge acquisition bottleneck, which refers to the arduous task of manually
    encoding vast amounts of knowledge in the system. Additionally, the project grapples
    with issues of brittleness, where slight deviations from the encoded rules or
    representations can lead to unexpected or erroneous behavior.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在范围和雄心方面具有开创性，Cyc项目也突显了符号人工智能方法固有的关键挑战。这些挑战包括知识获取瓶颈，这指的是在系统中手动编码大量知识的艰巨任务。此外，项目还面临着脆弱性问题，即对编码规则或表示的微小偏差可能导致意外或错误的行为。
- en: Scalability concerns also arise, as the complexity of symbolic systems can rapidly
    escalate as the knowledge base expands, potentially leading to computational intractability.
    Furthermore, the robust handling of nuance, uncertainty, and context-dependent
    interpretations remains a formidable challenge within the symbolic paradigm.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性问题也出现了，因为随着知识库的扩大，符号系统的复杂性可能会迅速增加，可能导致计算不可行。此外，在符号范式内，对细微差别、不确定性和情境相关解释的稳健处理仍然是一个巨大的挑战。
- en: Despite these obstacles, the Cyc project’s pioneering efforts have contributed
    significantly to the field of symbolic AI, pushing the boundaries of knowledge
    representation and reasoning capabilities. Its ongoing development continues to
    shed light on both the potential and limitations of the symbolic approach in the
    quest for artificial general intelligence.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些障碍，Cyc项目的开创性努力对符号人工智能领域做出了重大贡献，推动了知识表示和推理能力的边界。其持续的发展继续揭示了在追求通用人工智能过程中符号方法的潜力和局限性。
- en: While symbolic AI laid the crucial groundwork for establishing formal methods
    for knowledge representation and reasoning, many researchers believe that purely
    symbolic systems alone are unlikely to be sufficient for realizing the flexibility,
    robustness, and open-ended generalization required for general intelligence comparable
    to humans.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管符号人工智能为建立知识表示和推理的正式方法奠定了关键基础，但许多研究人员认为，仅符号系统本身可能不足以实现与人类智能相当所需的灵活性、鲁棒性和开放式泛化。
- en: The debate surrounding the extent to which symbolic approaches should be incorporated
    into AGI systems – whether as a core architecture or in a more complementary role
    – remains an active area of research with differing perspectives. Critics argue
    that the inherent limitations of symbolic systems, such as brittleness, scalability
    issues, and the knowledge acquisition bottleneck, pose significant challenges
    in capturing the nuanced, context-dependent, and continuously evolving nature
    of human intelligence. As a result, many advocate for a synergistic approach that
    combines the strengths of symbolic methods with other paradigms, leveraging the
    interpretability and strong generalization capabilities of symbolic reasoning
    while mitigating its weaknesses through complementary techniques, such as connectionist
    models or hybrid architectures.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 关于在通用人工智能系统中应将符号方法纳入何种程度——是作为核心架构还是更补充的角色——的辩论仍然是一个活跃的研究领域，存在不同的观点。批评者认为，符号系统固有的局限性，如脆弱性、可扩展性问题以及知识获取瓶颈，在捕捉人类智能的细微差别、情境相关性和持续演变性质方面构成了重大挑战。因此，许多人主张一种协同方法，结合符号方法和其他范式的优势，利用符号推理的可解释性和强大的泛化能力，同时通过互补技术，如连接主义模型或混合架构，来减轻其弱点。
- en: The connectionist/neural network approach
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接主义/神经网络方法
- en: This approach focuses on constructing systems that emulate the human brain.
    Neural network systems, like the brain, employ extensive parallel processing across
    interconnected nodes or “neurons,” distributing knowledge across connections.
    Unlike explicit symbolic encodings or rules such as “a dog is an animal,” neural
    models rely on sub-symbolic distributed representations for the same concept.
    In sub-symbolic representation, which is used in approaches like neural networks
    and connectionist models, knowledge or concepts are represented not through explicit
    symbols or rules, but through patterns of features and characteristics.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法侧重于构建模拟人脑的系统。神经网络系统，就像大脑一样，通过相互连接的节点或“神经元”进行广泛的并行处理，将知识分布在连接中。与显式的符号编码或规则，如“狗是一种动物”不同，神经网络模型依赖于亚符号分布式表示来表示相同的概念。在亚符号表示中，这种表示在神经网络和连接主义模型等方法中使用，知识和概念不是通过显式的符号或规则来表示，而是通过特征和特性的模式来表示。
- en: Integrated neural network approaches aspire to develop comprehensive end-to-end
    cognitive architectures covering perception, reasoning, and action. The hypothesis
    is that scaling up neural networks in both architecture and training data may
    induce the emergence of general intelligence, resembling the neural connections
    in the brain. However, current neural nets face challenges, as they are often
    narrow, lack systematicity, and encounter difficulties with transfer learning.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 集成神经网络方法旨在开发涵盖感知、推理和行动的综合端到端认知架构。假设在架构和训练数据两方面扩大神经网络规模可能会引发通用智能的出现，类似于大脑中的神经网络连接。然而，当前的神经网络面临挑战，因为它们通常很狭窄，缺乏系统性，并且在迁移学习方面遇到困难。
- en: '![](img/B20836_16_18.png)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B20836_16_18.png)'
- en: 'Figure 16.18: Connectionist or neural network approach'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.18：连接主义或神经网络方法
- en: 'With the remarkable capabilities demonstrated by LLMs, a compelling question
    arises: Can these models, arguably the most advanced neural networks to date,
    pave the way toward AGI? This question has sparked contrasting viewpoints within
    the AI community. Yann LeCun, the chief AI scientist at Meta, contends that the
    current autoregressive approach employed by LLMs is unlikely to lead to AGI, as
    these models are primarily trained to predict the next token rather than engage
    in genuine planning or reasoning processes. According to LeCun, current LLMs lack
    the ability to truly comprehend and reason about knowledge; instead, they retrieve
    and generate information in an approximate manner.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLMs）所展现的非凡能力，一个引人深思的问题是：这些模型，可以说是迄今为止最先进的神经网络，能否为AGI铺平道路？这个问题在人工智能社区中引发了不同的观点。Meta的首席人工智能科学家Yann
    LeCun认为，LLMs目前采用的当前自回归方法不太可能导致AGI，因为这些模型主要是训练来预测下一个标记，而不是参与真正的规划或推理过程。据LeCun所说，当前的LLMs缺乏真正理解和推理知识的能力；相反，它们以近似的方式检索和生成信息。
- en: On the other hand, Ilya Sutskever, chief scientist at OpenAI, seems to lean
    toward the perspective that, with sufficient data and increasingly larger architectures,
    LLMs may indeed develop a profound understanding of semantic meanings, potentially
    leading to AGI. Some alternative viewpoints suggest that LLMs, especially multimodal
    variants capable of integrating diverse information sources, combined with their
    ability to leverage different tools, could achieve a certain level of general
    intelligence.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，OpenAI的首席科学家Ilya Sutskever似乎倾向于这样的观点，即，随着数据的充分和架构的日益扩大，LLMs确实可能发展出对语义意义的深刻理解，这可能导致AGI。一些替代观点认为，LLMs，特别是能够整合多种信息来源的多模态变体，结合它们利用不同工具的能力，可能达到一定程度的通用智能。
- en: As newer and more capable models are developed, and as more innovative systems
    are created around these models, only time will tell whether the current approach
    can ultimately lead to AGI. The ongoing advancements and debates within the field
    underscore the complexity and uncertainty surrounding this quest, while simultaneously
    fueling the relentless pursuit of more powerful AI.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 随着更先进和更有能力的模型被开发出来，以及围绕这些模型创建更多创新系统，只有时间才能告诉我们当前的方法是否最终能导致通用人工智能（AGI）。该领域内持续的进步和辩论凸显了这一追求的复杂性和不确定性，同时也在推动对更强大人工智能的持续追求。
- en: The neural-symbolic approach
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经符号方法
- en: The neural-symbolic approach aims to combine the best of both worlds by integrating
    neural networks with symbolic reasoning systems. The idea is to create AI systems
    that can learn patterns and representations from data using neural networks, while
    also leveraging the explicit knowledge and logical reasoning capabilities of symbolic
    AI.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 神经-符号方法旨在通过整合神经网络与符号推理系统，结合两者的最佳之处。其理念是创建能够使用神经网络从数据中学习模式和表示的AI系统，同时利用符号AI的显式知识和逻辑推理能力。
- en: 'Here’s a simple analogy: Imagine a young child is learning about the world.
    The child’s brain (the neural network component) can learn and recognize patterns,
    like shapes, colors, and objects, through experience and exposure. However, to
    truly understand and reason about the world, the child also needs to learn explicit
    rules, concepts, and knowledge from teachers, books, and other sources (the symbolic
    component).'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个简单的类比：想象一个小孩在学习世界。小孩的大脑（神经网络组件）可以通过经验和接触学习并识别模式，如形状、颜色和物体。然而，要真正理解和推理世界，小孩还需要从老师、书籍和其他来源学习显式规则、概念和知识（符号组件）。
- en: In a neural-symbolic AI system, the neural network component would be responsible
    for learning patterns and representations from data, just like the child’s brain.
    At the same time, the symbolic component would provide a structured knowledge
    base and logical reasoning capabilities, similar to the child learning from books
    and teachers.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个神经-符号AI系统中，神经网络组件将负责从数据中学习模式和表示，就像小孩的大脑一样。同时，符号组件将提供一个结构化的知识库和逻辑推理能力，类似于小孩从书籍和老师那里学习。
- en: By tightly integrating these two components, the AI system can leverage the
    strengths of both approaches. It can learn and adapt like neural networks, while
    also reasoning and making inferences using explicit knowledge and logical rules,
    much like humans do.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 通过紧密集成这两个组件，AI系统可以利用两种方法的优势。它可以像神经网络一样学习和适应，同时也能使用显式知识和逻辑规则进行推理和做出推断，就像人类一样。
- en: 'The neural-symbolic approach is seen by many researchers as a promising path
    toward achieving AGI, as it aims to capture the key aspects of human-like intelligence:
    the ability to learn from experience, reason with structured knowledge, and adapt
    to new situations.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究人员认为，神经-符号方法是实现通用人工智能（AGI）的有希望的途径，因为它旨在捕捉类似人类智能的关键方面：从经验中学习的能力、使用结构化知识进行推理的能力，以及适应新情况的能力。
- en: '![](img/B20836_16_19.png)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B20836_16_19.png)'
- en: 'Figure 16.19: Neural-symbolic architecture'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.19：神经-符号架构
- en: AlphaGeometry, developed by DeepMind, is an innovative AI system that leverages
    the neural-symbolic approach to tackle complex geometric reasoning tasks. This
    system combines the powerful pattern recognition and learning capabilities of
    deep neural networks with the structured reasoning and symbolic manipulation of
    geometric knowledge.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 由DeepMind开发的AlphaGeometry是一个创新的AI系统，它利用神经-符号方法来解决复杂的几何推理任务。该系统结合了深度神经网络的强大模式识别和学习能力，以及几何知识的结构化推理和符号操作。
- en: At the core of AlphaGeometry lies a neural network component that processes
    visual inputs and generates candidate symbolic expressions representing geometric
    concepts and relationships. These symbolic expressions are then passed to a symbolic
    reasoning engine, which employs logical rules and constraints to validate, refine,
    and manipulate the expressions. The symbolic output is then interpreted and used
    to guide the neural network’s predictions, enabling the system to iteratively
    improve its geometric understanding.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: AlphaGeometry的核心是一个神经网络组件，它处理视觉输入并生成代表几何概念和关系的候选符号表达式。然后，这些符号表达式被传递给一个符号推理引擎，该引擎使用逻辑规则和约束来验证、精炼和操作这些表达式。符号输出随后被解释并用于指导神经网络的预测，使系统能够迭代地提高其对几何的理解。
- en: By tightly integrating neural and symbolic components, AlphaGeometry can effectively
    combine the strengths of both paradigms. The neural network excels at learning
    patterns and extracting geometric features from visual data, while the symbolic
    component provides a structured representation of geometric knowledge and enables
    logical reasoning over complex relationships.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 通过紧密集成神经和符号组件，AlphaGeometry可以有效地结合两种范例的优势。神经网络擅长从视觉数据中学习模式和提取几何特征，而符号组件则提供了几何知识的结构化表示，并使复杂的逻辑关系可以进行推理。
- en: This neural-symbolic approach allows AlphaGeometry to achieve impressive performance
    on challenging geometric tasks, outperforming previous methods and demonstrating
    an ability to generalize to novel problems. It showcases the potential of hybrid
    systems in advancing AI capabilities, particularly in domains that require both
    robust pattern recognition and structured reasoning.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 这种神经-符号方法使AlphaGeometry在具有挑战性的几何任务上取得了令人印象深刻的性能，超越了先前的方法，并展示了将知识推广到新问题的能力。它展示了混合系统在提升人工智能能力方面的潜力，特别是在需要稳健的模式识别和结构化推理的领域。
- en: As the pursuit for AGI continues to captivate researchers and pioneers across
    multiple disciplines, the future holds both immense opportunities and formidable
    challenges. While connectionist approaches have demonstrated remarkable pattern
    recognition and learning capabilities, pushing the boundaries of these models
    to achieve the breadth and flexibility of human-level intelligence remains an
    ongoing endeavor. Symbolic approaches, with their explicit knowledge representation
    and reasoning prowess, offer a complementary pathway, yet struggles with the knowledge
    acquisition bottleneck and brittleness issues persist. The neural-symbolic paradigm,
    seamlessly fusing the strengths of these two worlds, emerges as a highly promising
    avenue.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 随着对AGI的追求继续吸引着多个学科的研究人员和先驱，未来既充满巨大机遇，也面临严峻挑战。尽管连接主义方法已经展示了惊人的模式识别和学习能力，但将这些模型的边界推向实现人类水平智能的广度和灵活性仍然是一项持续的努力。符号方法，凭借其显式的知识表示和推理能力，提供了一条补充路径，但知识获取瓶颈和脆弱性问题仍然存在。神经-符号范式，无缝融合这两个世界的优势，成为了一条极具前景的道路。
- en: Irrespective of the path, the realization of AGI hinges on our ability to synergize
    diverse approaches, harness the exponential growth of data and computing power,
    and deepen our understanding of intelligence itself. As researchers continue their
    pursuit in this uncharted territory, unprecedented breakthroughs and paradigm
    shifts await.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 不论路径如何，实现通用人工智能（AGI）的关键在于我们能够协同多种方法，利用数据的指数级增长和计算能力的提升，并深化我们对智能本身的理解。随着研究人员在这个未知的领域继续追求，前所未有的突破和范式转变正在等待着我们。
- en: Summary
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We are now coming to the end of this book spanning the breadth of machine learning
    – from foundational concepts to cutting-edge generative AI. We started the book
    by covering core ML techniques, algorithms, and industry applications to provide
    a strong base. We then progressed to data architectures, ML tools like TensorFlow
    and PyTorch, and engineering best practices to put skills into practice. Architecting
    robust ML infrastructure on AWS and optimization methods prepared you for real-world
    systems.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在正接近这本书的结尾，这本书涵盖了机器学习的广度——从基础概念到前沿的生成式人工智能。我们以介绍核心机器学习技术、算法和行业应用作为本书的开端，以提供一个坚实的基础。然后我们逐步深入到数据架构、机器学习工具如TensorFlow和PyTorch，以及工程最佳实践，以将技能付诸实践。在AWS上构建稳健的机器学习基础设施和优化方法为现实世界系统做好了准备。
- en: Securing and governing AI responsibly is critical, so we delved into risk management.
    To guide organizations on the ML journey, we discussed maturity models and evolutionary
    steps.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 负责任地保障和治理人工智能至关重要，因此我们深入探讨了风险管理。为了指导组织在机器学习之旅中前进，我们讨论了成熟度模型和演变步骤。
- en: Closing the chapter by looking at generative AI and AGI, we explored the immense
    possibilities of the most disruptive new capability currently. Specifically, we
    delved into the intricacies of generative AI platforms, RAG architecture, and
    considerations for generative AI production deployment. Furthermore, we examined
    practical generative AI business applications across various industries, showcasing
    the transformative potential of this technology. Finally, the chapter concluded
    with an introduction to various theoretical approaches for achieving artificial
    general intelligence, providing a glimpse into the future of this rapidly evolving
    field.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 通过审视生成式人工智能和AGI来结束这一章，我们探索了目前最具颠覆性的新能力的巨大可能性。具体来说，我们深入探讨了生成式人工智能平台、RAG架构和生成式人工智能生产部署的考虑因素。此外，我们还考察了跨各个行业的实际生成式人工智能商业应用，展示了这项技术的变革潜力。最后，本章以介绍实现人工通用智能的各种理论方法结束，为这个快速发展的领域提供了未来的一瞥。
- en: I hope you found this book enriching and that it provides a comprehensive foundation
    to propel your AI learning to new heights. The concepts and frameworks covered
    aim to equip you to build practical ML solutions. Keep learning, practicing, and
    developing your skills to maximize the value of AI. The future promises to be
    exponentially more exciting!
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你觉得这本书内容丰富，并且它为你提供了推动你的AI学习达到新高度的综合基础。涵盖的概念和框架旨在帮助你构建实用的机器学习解决方案。继续学习、实践和发展你的技能，以最大化AI的价值。未来承诺将带来指数级的更多激动人心的体验！
- en: Leave a review!
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 留下评论！
- en: Enjoyed this book? Help readers like you by leaving an Amazon review. Scan the
    QR code below to get a free eBook of your choice.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 喜欢这本书吗？通过留下亚马逊评论来帮助像你这样的读者。扫描下面的二维码，获取你选择的免费电子书。
- en: '![](img/Review_Copy.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![评论副本](img/Review_Copy.png)'
- en: '**Limited Offer*'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '**限时优惠*'
