- en: '16'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '16'
- en: Integrating ML Systems in Ecosystems
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在生态系统中集成机器学习系统
- en: ML systems have gained a lot of popularity for two reasons – their ability to
    learn from data (which we’ve explored throughout this book), and their ability
    to be packaged into web services.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统因其两个原因而获得了大量人气——它们从数据中学习的能力（我们已在整本书中探讨了这一点），以及它们被打包成网络服务的能力。
- en: Packaging these ML systems into web services allows us to integrate them into
    workflows in a very flexible way. Instead of compiling or using dynamically linked
    libraries, we can deploy ML components that communicate over HTTP protocols using
    JSON protocols. We have already seen how to use that protocol by using the GPT-3
    model that is hosted by OpenAI. In this chapter, we’ll explore the possibility
    of creating a Docker container with a pre-trained ML model, deploying it, and
    integrating it with other components.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些机器学习系统打包成网络服务，使我们能够以非常灵活的方式将它们集成到工作流程中。我们不必编译或使用动态链接库，而是可以部署通过HTTP协议使用JSON协议进行通信的机器学习组件。我们已经看到了如何使用该协议，通过使用由OpenAI托管的GPT-3模型。在本章中，我们将探讨创建一个包含预训练机器学习模型的Docker容器、部署它以及将其与其他组件集成的可能性。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: ML system of systems – software ecosystems
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习系统——软件生态系统
- en: Creating web services over ML models using Flask
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Flask在机器学习模型上创建网络服务
- en: Deploying ML models using Docker
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Docker部署机器学习模型
- en: Combining web services into ecosystems
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将网络服务组合成生态系统
- en: Ecosystems
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生态系统
- en: In the dynamic realm of software engineering, the tools, methodologies, and
    paradigms are in a constant state of evolution. Among the most influential forces
    driving this transformation is ML. While ML itself is a marvel of computational
    prowess, its true genius emerges when integrated into the broader software engineering
    ecosystems. This chapter delves into the nuances of embedding ML within an ecosystem.
    Ecosystems are groups of software that work together but are not connected at
    compile time. A well-known ecosystem is the PyTorch ecosystem, where a set of
    libraries work together in the context of ML. However, there is much more than
    that to ML ecosystems in software engineering.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件工程的动态领域，工具、方法和范式处于不断演化的状态。推动这一变革的最有影响力的力量之一是机器学习。虽然机器学习本身是计算能力的奇迹，但它的真正天才在于将其集成到更广泛的软件工程生态系统中。本章深入探讨了在生态系统中嵌入机器学习的细微差别。生态系统是一组协同工作的软件，但在编译时并未连接。一个著名的生态系统是PyTorch生态系统，其中一系列库在机器学习环境中协同工作。然而，在软件工程中的机器学习生态系统中还有更多内容。
- en: From automated testing systems that learn from each iteration to recommendation
    engines that adapt to user behaviors, ML is redefining how software is designed,
    developed, and deployed. However, integrating ML into software engineering is
    not a mere plug-and-play operation. It demands a rethinking of traditional workflows,
    a deeper understanding of data-driven decision-making, and a commitment to continuous
    learning and adaptation.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从从每次迭代中学习的自动化测试系统到适应用户行为的推荐引擎，机器学习正在重新定义软件的设计、开发和部署方式。然而，将机器学习集成到软件工程中并非简单的即插即用操作。它要求重新思考传统的工作流程，更深入地理解数据驱动决策，并致力于持续学习和适应。
- en: 'As we delve deeper into the integration of ML within software engineering,
    it becomes imperative to discuss two pivotal components that are reshaping the
    landscape: web services and Docker containers. These technologies, while not exclusive
    to ML applications, play a crucial role in the seamless deployment and scaling
    of ML-driven solutions in the software ecosystem.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们深入探讨机器学习在软件工程中的集成，讨论两个关键组成部分变得至关重要：网络服务和Docker容器。这些技术虽然并非仅限于机器学习应用，但在软件生态系统中无缝部署和扩展机器学习驱动解决方案中发挥着关键作用。
- en: Web services, especially in the era of microservices architecture, provide a
    modular approach to building software applications. By encapsulating specific
    functionalities into distinct services, they allow for greater flexibility and
    scalability. When combined with ML models, web services can deliver dynamic, real-time
    responses based on the insights derived from data. For instance, a web service
    might leverage an ML model to provide personalized content recommendations to
    users or to detect fraudulent activities in real time.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Web服务，特别是在微服务架构时代，为构建软件应用程序提供了一种模块化方法。通过将特定功能封装到不同的服务中，它们提供了更大的灵活性和可扩展性。当与机器学习模型结合使用时，Web服务可以根据从数据中得出的见解提供动态的、实时的响应。例如，一个Web服务可能会利用机器学习模型为用户提供个性化的内容推荐或实时检测欺诈活动。
- en: Docker containers, on the other hand, have revolutionized the way software,
    including ML models, is packaged and deployed. Containers encapsulate an application
    along with all its dependencies into a standardized unit, ensuring consistent
    behavior across different environments. For ML practitioners, this means the painstaking
    process of setting up environments, managing dependencies, and ensuring compatibility
    is vastly simplified. Docker containers ensure that an ML model trained on a developer’s
    machine will run with the same efficiency and accuracy on a production server
    or any other platform.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Docker容器已经彻底改变了软件（包括机器学习模型）的打包和部署方式。容器将应用程序及其所有依赖项封装到一个标准化的单元中，确保在不同环境中的一致行为。对于机器学习从业者来说，这意味着设置环境、管理依赖项和确保兼容性的繁琐过程得到了极大的简化。Docker容器确保在开发者的机器上训练的机器学习模型将在生产服务器或任何其他平台上以相同的效率和精度运行。
- en: Furthermore, when web services and Docker containers are combined, they pave
    the way for ML-driven microservices. Such architectures allow for the rapid deployment
    of scalable, isolated services that can be updated independently without disrupting
    the entire system. This is especially valuable in the realm of ML, where models
    might need frequent updates based on new data or improved algorithms.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当Web服务和Docker容器结合使用时，它们为基于机器学习的微服务铺平了道路。这种架构允许快速部署可扩展的、隔离的服务，这些服务可以独立更新而不会干扰整个系统。这在机器学习领域尤其有价值，因为模型可能需要根据新数据或改进的算法进行频繁更新。
- en: In this chapter, we’ll learn how to use both technologies to package models
    and create an ecosystem based on Docker containers. After reading this chapter,
    we shall have a good understanding of how we can scale up our development by using
    ML as part of a larger system of systems – ecosystems.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何使用这两种技术来打包模型并创建基于Docker容器的生态系统。阅读本章后，我们将对如何通过将机器学习（ML）作为更大系统体系的一部分来扩展我们的开发有一个良好的理解——生态系统。
- en: Creating web services over ML models using Flask
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Flask在机器学习模型上创建Web服务
- en: In this book, we’ve mostly focused on training, evaluating, and deploying ML
    models. However, we did not discuss the need to structure them flexibly. We worked
    with monolithic software. Monolithic software is characterized by its unified,
    single code base structure where all the functionalities, from the user interface
    to data processing, are tightly interwoven and operate as one cohesive unit. This
    design simplifies initial development and deployment since everything is bundled
    together and they are compiled together. Any change, however minor, requires the
    entire application to be rebuilt and redeployed. This makes it problematic when
    the evolution of contemporary software is fast.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们主要关注了机器学习模型的训练、评估和部署。然而，我们没有讨论对它们进行灵活结构化的需求。我们使用的是单体软件。单体软件的特点是统一的、单一的代码库结构，其中所有功能，从用户界面到数据处理，都是紧密交织并作为一个统一的单元运行的。这种设计简化了初始开发和部署，因为所有内容都捆绑在一起并一起编译。任何微小的变化都需要重新构建和重新部署整个应用程序。这使得当当代软件的演变速度很快时变得有问题。
- en: 'On the other hand, web service-based software, which is often associated with
    microservices architecture, breaks down the application into smaller, independent
    services that communicate over the web, typically using protocols such as HTTP
    and REST. Each service is responsible for a specific functionality and operates
    independently. This modular approach offers greater flexibility. Services can
    be scaled, updated, or redeployed individually without affecting the entire system.
    Moreover, failures in one service don’t necessarily bring down the whole application.
    *Figure 16**.1* presents how the difference between these two types of software
    can be seen:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，基于Web服务的软件，通常与微服务架构相关联，将应用程序分解为更小、独立的、通过网络通信的服务，通常使用HTTP和REST等协议。每个服务负责特定的功能并且独立运行。这种模块化方法提供了更大的灵活性。服务可以单独扩展、更新或重新部署，而不会影响整个系统。此外，一个服务的故障并不一定会导致整个应用程序崩溃。*图16.1*展示了这两种类型软件之间的差异：
- en: '![Figure 16.1 – Monolithic software versus web service-based software](img/B19548_16_1.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图16.1 – 单体软件与基于Web服务的软件](img/B19548_16_1.jpg)'
- en: Figure 16.1 – Monolithic software versus web service-based software
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.1 – 单体软件与基于Web服务的软件
- en: On the left-hand side, we have all the components bundled together into one
    product. Users interact with the product through the user interface. Only one
    user can interact with the software, and more users require more installations
    of the software.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧，所有组件都捆绑在一起成为一个产品。用户通过用户界面与产品交互。只有一个用户可以与软件交互，更多的用户需要更多的软件安装。
- en: On the right-hand side, we have a decentralized architecture where each component
    is a separate web service. The coordination of these components is done by a thin
    client. If more users/clients want to use the same services, they can just connect
    them using the HTTP REST protocol (API).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在右侧，我们有一个去中心化的架构，其中每个组件都是一个独立的Web服务。这些组件的协调是通过一个瘦客户端完成的。如果更多的用户/客户端想要使用相同的服务，他们只需使用HTTP
    REST协议（API）将它们连接起来。
- en: Here is my first best practice.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我的第一条最佳实践。
- en: 'Best practice #75'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践#75
- en: Use web services (RESTful API) when deploying ML models for production.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署机器学习模型到生产环境时使用Web服务（RESTful API）。
- en: Although it takes additional effort to create web services, it is worth using
    them. They provide a great separation of concerns and asynchronous access and
    also provide great possibilities for load balancing. We can use different servers
    to run the same web service and therefore balance the load.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然创建Web服务需要额外的努力，但它们是值得使用的。它们提供了很好的关注点分离和异步访问，同时也提供了负载均衡的巨大可能性。我们可以使用不同的服务器来运行相同的Web服务，从而平衡负载。
- en: So, let’s create the first web service using Flask.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们使用Flask创建第一个Web服务。
- en: Creating a web service using Flask
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Flask创建Web服务
- en: 'Flask is a framework that allows us to provide easy access to internal APIs
    via the REST interface over HTTP protocol. First, we need to install it:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Flask是一个框架，它允许我们通过HTTP协议上的REST接口提供对内部API的便捷访问。首先，我们需要安装它：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once we’ve installed the interface, we can write our programs. In this example,
    our first web service calculates the lines of code and complexity of the program
    sent to it. The following code fragment exemplifies this:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们安装了接口，我们就可以编写我们的程序。在这个例子中，我们的第一个Web服务计算发送给它的程序代码行数和复杂度。以下代码片段展示了这一点：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'First, the code requires a few imports and then initializes the application
    in `app = Flask(__name__)`. Then, it creates the routes – that is, the places
    where the program will be able to communicate via the REST API:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，代码需要一些导入，然后在`app = Flask(__name__)`中初始化应用程序。然后，它创建路由——即程序将通过REST API进行通信的地方：
- en: '`@app.route(''/'')`: This is a decorator that defines a route for the root
    URL (`"/"`). When users access the root URL, it renders the `"``index.html"` template.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@app.route(''/'')`：这是一个装饰器，它定义了根URL（`"/"`）的路由。当用户访问根URL时，它渲染`"index.html"`模板。'
- en: '`@app.route(''/success'', methods=[''POST''])`: This decorator defines a route
    for the `"/success"` URL, which expects HTTP POST requests. This route is used
    to handle file uploads, count lines of code, and calculate McCabe complexity.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@app.route(''/success'', methods=[''POST''])`：这个装饰器定义了一个针对`"/success"` URL的路由，它期望HTTP
    POST请求。此路由用于处理文件上传、计算代码行数和计算麦卡贝复杂度。'
- en: '`@app.route(''/metrics'', methods=[''GET''])`: This decorator defines a route
    for the `"/metrics"` URL, which expects HTTP GET requests. It is used to retrieve
    and display the metrics.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@app.route(''/metrics'', methods=[''GET''])`: 这个装饰器定义了`"/metrics"` URL的路由，它期望HTTP
    GET请求。它用于检索和显示度量。'
- en: '`def main()`: This function is associated with the root (`"/"`) route. It returns
    an HTML template called `"index.html"` when users access the root URL.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`def main()`: 这个函数与根（`"/"`）路由相关联。当用户访问根URL时，它返回一个名为 `"index.html"` 的HTML模板。'
- en: '`def success()`: This function is associated with the `"/success"` route, which
    handles file uploads:'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`def success()`: 这个函数与`"/success"`路由相关联，它处理文件上传：'
- en: It checks if the request method is POST
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它检查请求方法是否为POST
- en: It saves the uploaded file to the server
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将上传的文件保存到服务器
- en: It counts the lines of code in the uploaded file
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它计算上传文件的代码行数
- en: It calculates the McCabe complexity using the radon library
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用radon库计算McCabe复杂性
- en: It stores the metrics (lines of code and McCabe complexity) in the metrics dictionary
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将度量（代码行数和McCabe复杂性）存储在度量字典中
- en: It returns the metrics for the uploaded file as a JSON response
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它以JSON响应返回上传文件的度量
- en: '`def get_metrics()`: This function is associated with the `/``metrics` route:'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`def get_metrics()`: 这个函数与`/metrics`路由相关联：'
- en: It checks if the request method is GET.
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它检查请求方法是否为GET。
- en: It returns the entire metrics dictionary as a JSON response. This is used for
    debugging purposes to see the metrics for all files that are uploaded during the
    session.
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它返回整个度量字典作为JSON响应。这用于调试目的，以查看会话期间上传的所有文件的度量。
- en: '`if __name__ == ''__main__'':`: This block ensures that the web application
    is only run when this script is executed directly (not when it’s imported as a
    module).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`if __name__ == ''__main__'':`: 这个块确保只有当此脚本直接执行时（而不是作为模块导入时）才会运行Web应用程序。'
- en: '`app.run(host=''0.0.0.0'', debug=True)`: This starts the Flask application
    in debug mode, allowing you to see detailed error messages during development.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`app.run(host=''0.0.0.0'', debug=True)`: 这以调试模式启动Flask应用程序，允许你在开发期间看到详细的错误消息。'
- en: 'Then, the application is executed – `app.run(debug=True)` starts the Flask
    application with debugging mode enabled. This means that any changes made to the
    code will automatically reload the server, and any errors will be displayed in
    the browser. Once we execute it, the following web page appears (note that the
    code of the page has to be in the `templates` subfolder and should contain the
    following code):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，应用程序被执行 – `app.run(debug=True)` 以启用调试模式启动Flask应用程序。这意味着对代码所做的任何更改都将自动重新加载服务器，并且任何错误都将显示在浏览器中。一旦执行，就会出现以下网页（请注意，网页的代码必须位于`templates`子文件夹中，并且应包含以下代码）：
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The page contains a simple form that allows us to upload the file to the server:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 页面包含一个简单的表单，允许我们上传文件到服务器：
- en: '![Figure 16.2 – The web page where we can send the file to calculate lines
    of code. This is only one way of sending this information to the web service](img/B19548_16_2.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图16.2 – 我们可以发送文件以计算代码行数的网页。这是将此信息发送到网络服务的一种方式](img/B19548_16_2.jpg)'
- en: Figure 16.2 – The web page where we can send the file to calculate lines of
    code. This is only one way of sending this information to the web service
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.2 – 我们可以发送文件以计算代码行数的网页。这是将此信息发送到网络服务的一种方式
- en: 'After uploading the file, we get the results:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 上传文件后，我们得到结果：
- en: '![Figure 16.3 – Results of calculating the lines of code](img/B19548_16_3.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图16.3 – 计算代码行数的结果](img/B19548_16_3.jpg)'
- en: Figure 16.3 – Results of calculating the lines of code
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.3 – 计算代码行数的结果
- en: The majority of the transmission is done by the Flask framework, which makes
    the development a really pleasant experience. However, just counting lines of
    code and complexity is not a great ML model. Therefore, we need to create another
    web service with the code of the ML model itself.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数传输都是由Flask框架完成的，这使得开发过程非常愉快。然而，仅仅计算代码行数和复杂性并不是一个很好的机器学习模型。因此，我们需要创建另一个包含机器学习模型本身的代码的Web服务。
- en: Therefore, my next best practice is about dual interfaces.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我的下一个最佳实践是关于双接口。
- en: 'Best practice #76'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践#76
- en: Use both a website and an API for the web services.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用网站和API为Web服务。
- en: Although we can always design web services so that they only accept JSON/REST
    calls, we should try to provide different interfaces. The web interface (presented
    previously) allows us to test the web service and even send data to it without
    the need to write a separate program.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们总是可以设计Web服务，使其只接受JSON/REST调用，但我们应尝试提供不同的接口。之前展示的Web界面允许我们测试Web服务，甚至向其发送数据，而无需编写单独的程序。
- en: Creating a web service that contains a pre-trained ML model
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建包含预训练ML模型的Web服务
- en: 'The code of the ML model web service follows the same template. It uses the
    Flask framework to provide the REST API of the web service for the software. Here
    is the code fragment that shows this web service:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型Web服务的代码遵循相同的模板。它使用Flask框架来提供Web服务的REST API。以下是显示此Web服务的代码片段：
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The main entry point to this web service takes two parameters: `@app.route(''/predict/<loc>/<mcc>'')`.
    It uses these two parameters as parameters of the method that instantiates the
    models and uses it to make a prediction – `make_prediction(loc, mcc)`. The `make_prediction`
    method reads a model from a `joblib` file and uses it to predict whether the module
    will contain a defect or not. I use `joblib` for this model as it is based on
    a NumPy array. However, if a model is based on a Python object (for example, when
    it is an estimator from a scikit-learn library), then it is better to use pickle
    instead of `joblib`. It returns the JSON string containing the result. *Figure
    16**.4* illustrates how we can use a web browser to invoke this web service –
    not the address bar:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 此Web服务的主要入口点接受两个参数：`@app.route('/predict/<loc>/<mcc>')`。它使用这两个参数作为实例化模型并使用它进行预测的方法的参数
    – `make_prediction(loc, mcc)`。`make_prediction`方法从一个`joblib`文件中读取模型，并使用它来预测模块是否包含缺陷。我使用`joblib`来存储这个模型，因为它基于NumPy数组。然而，如果一个模型基于Python对象（例如，当它是一个来自scikit-learn库的估计器时），那么最好使用pickle而不是`joblib`。它返回包含结果的JSON字符串。*图16**.4*说明了我们可以如何使用网页浏览器调用这个Web服务
    – 而不是地址栏：
- en: '![Figure 16.4 – Using the prediction endpoint to get the predicted number of
    defects in this module](img/B19548_16_4.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图16.4 – 使用预测端点获取此模块中预测的缺陷数量](img/B19548_16_4.jpg)'
- en: Figure 16.4 – Using the prediction endpoint to get the predicted number of defects
    in this module
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.4 – 使用预测端点获取此模块中预测的缺陷数量
- en: The address bar sends the parameters to the model and the response is a JSON
    string that says that this module will, most probably, contain a defect. Well,
    this is not a surprise as we say that the module has 10 lines of code and a complexity
    of 100 (unrealistic, but possible).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 地址栏将参数发送给模型，响应是一个JSON字符串，表示这个模块很可能包含一个缺陷。嗯，这并不令人惊讶，因为我们说这个模块有10行代码，复杂度为100（不切实际，但可能）。
- en: These two web services already give us an example of how powerful the REST API
    can be. Now, let’s learn how to package that with Docker so that we can deploy
    these web services even more easily.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个Web服务已经为我们提供了一个例子，说明了REST API可以多么强大。现在，让我们学习如何使用Docker打包它，这样我们就可以更容易地部署这些Web服务。
- en: Deploying ML models using Docker
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker部署ML模型
- en: To create a Docker container with our newly created web service (or two of them),
    we need to install Docker on our system. Once we’ve installed Docker, we can use
    it to compile the container.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个包含我们新创建的Web服务（或两个）的Docker容器，我们需要在我们的系统上安装Docker。一旦我们安装了Docker，我们就可以用它来编译容器。
- en: The crucial part of packaging the web service into the Docker container is the
    Dockerfile. It is a recipe for how to assemble the container and how to start
    it. If you’re interested, I’ve suggested a good book about Docker containers in
    the *Further reading* section so that you can learn more about how to create more
    advanced components than the ones in this book.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 将Web服务打包到Docker容器中的关键部分是Dockerfile。它是一个如何组装容器以及如何启动它的配方。如果你感兴趣，我在*进一步阅读*部分建议了一本关于Docker容器的优秀书籍，这样你可以了解更多关于如何创建比这本书中更高级的组件。
- en: 'In our example, we need two containers. The first one will be the container
    for the measurement instrument. The code for that container is as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们需要两个容器。第一个将是测量仪器的容器。该容器的代码如下：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This Dockerfile is setting up an Alpine Linux-based environment, installing
    Python and the necessary development packages, copying your application code into
    the image, and then running the Python script as the default command when the
    container starts. It’s a common pattern for creating Docker images for Python
    applications. Let’s take a closer look:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Dockerfile 正在设置基于 Alpine Linux 的环境，安装 Python 和必要的开发包，将您的应用程序代码复制到镜像中，然后在容器启动时作为默认命令运行
    Python 脚本。这是为 Python 应用程序创建 Docker 镜像的常见模式。让我们更仔细地看看：
- en: '`FROM alpine:latest`: This line specifies the base image for the Docker image.
    In this case, it uses the Alpine Linux distribution, which is a lightweight and
    minimalistic distribution that’s often used in Docker containers. `latest` refers
    to the latest version of the Alpine image available on Docker Hub.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`FROM alpine:latest`: 这一行指定了 Docker 镜像的基础镜像。在这种情况下，它使用 Alpine Linux 发行版，这是一个轻量级和极简的发行版，通常用于
    Docker 容器。`latest` 指的是 Docker Hub 上可用的 Alpine 镜像的最新版本。'
- en: '`RUN apk update`: This command updates the package index of the Alpine Linux
    package manager (`apk`) to ensure it has the latest information about available
    packages.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`RUN apk update`: 这个命令更新了 Alpine Linux 包管理器（`apk`）的包索引，以确保它有关于可用包的最新信息。'
- en: '`RUN apk add py-pip`: Here, it installs the `py-pip` package, which is the
    package manager for Python packages. This step is necessary to be able to install
    Python packages using `pip`.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`RUN apk add py-pip`: 这里，它安装了 `py-pip` 包，这是 Python 包的包管理器。这一步是使用 `pip` 安装 Python
    包所必需的。'
- en: '`RUN apk add --no-cache python3-dev`: This installs the `python3-dev` package,
    which provides development files for Python. These development files are often
    needed when compiling or building Python packages that have native code extensions.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`RUN apk add --no-cache python3-dev`: 这安装了 `python3-dev` 包，它提供了 Python 的开发文件。这些开发文件在编译或构建具有本地代码扩展的
    Python 包时通常需要。'
- en: '`RUN pip install --upgrade pip`: This upgrades the `pip` package manager to
    the latest version.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`RUN pip install --upgrade pip`: 这个命令将 `pip` 包管理器升级到最新版本。'
- en: '`WORKDIR /app`: This sets the working directory for the subsequent commands
    to `/app`. This directory is where the application code will be copied, and it
    becomes the default directory for running commands.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WORKDIR /app`: 这为后续命令设置了 `/app` 作为工作目录。这个目录是应用程序代码将被复制的地方，并且它成为运行命令的默认目录。'
- en: '`COPY . /app`: This copies the contents of the current directory (where the
    Dockerfile is located) into the `/app` directory in the Docker image. This typically
    includes the application code, including `requirements.txt`.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`COPY . /app`: 这将当前目录（Dockerfile 所在的位置）的内容复制到 Docker 镜像中的 `/app` 目录。这通常包括应用程序代码，包括
    `requirements.txt`。'
- en: '`RUN pip --no-cache-dir install -r requirements.txt`: This installs Python
    dependencies specified in the `requirements.txt` file. The `--no-cache-dir` flag
    is used to ensure that no cache is used during the installation, which can help
    reduce the size of the Docker image.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`RUN pip --no-cache-dir install -r requirements.txt`: 这安装了在 `requirements.txt`
    文件中指定的 Python 依赖项。`--no-cache-dir` 标志用于确保在安装过程中不使用缓存，这有助于减小 Docker 镜像的大小。'
- en: '`CMD ["python3", "main.py"]`: This specifies the default command to run when
    a container is started from this image. In this case, it runs the `main.py` Python
    script using `python3`. This is the command that will be executed when we run
    a container based on this Docker image.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`CMD ["python3", "main.py"]`: 这指定了从该镜像启动容器时默认要运行的命令。在这种情况下，它使用 `python3` 运行
    `main.py` Python 脚本。这是我们基于此 Docker 镜像运行容器时将要执行的命令。'
- en: 'In *step 8*, we need the `requirements.txt` file. In this case, the file does
    not have to be too complex – it needs to use the same imports as the web service
    script:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第 8 步* 中，我们需要 `requirements.txt` 文件。在这种情况下，文件不需要太复杂——它需要使用与网络服务脚本相同的导入：
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we are ready to compile the Docker container. We can do that with the
    following command from the command line:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好编译 Docker 容器。我们可以通过以下命令从命令行完成：
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once the compilation process is complete, we can start the container:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦编译过程完成，我们可以启动容器：
- en: '[PRE7]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The preceding command tells the Docker environment that we want to start the
    container, `measurementinstrument`, and map the port of the web service (`5000`)
    to the same port in `localmachine`. Now, if we navigate to the address, we can
    upload the file just like we could when the web service was running without the
    Docker containers.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令告诉 Docker 环境我们要启动名为 `measurementinstrument` 的容器，并将网络服务的端口（`5000`）映射到本地机器上的相同端口。现在，如果我们导航到该地址，我们可以上传文件，就像在没有
    Docker 容器运行网络服务时一样。
- en: 'Best practice #77'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '最佳实践 #77'
- en: Dockerize your web services for both version control and portability.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了版本控制和可移植性，将你的网络服务 Docker 化。
- en: Using Docker is one way we can ensure the portability of our web services. Once
    we package our web service into the container, we can be sure that it will behave
    the same on every system that is capable of running Docker. This makes our lives
    much easier even more than using `requirements.txt` files to set up Python environments.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Docker 是确保我们的网络服务可移植性的方法之一。一旦我们将网络服务打包到容器中，我们就可以确信它将在任何能够运行 Docker 的系统上表现相同。这使得我们的生活比使用
    `requirements.txt` 文件来设置 Python 环境更加容易。
- en: 'Once we have the container with the measurement instrument, we can package
    the second web service – with the prediction model – into another web service.
    The following Dockerfile does this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了包含测量仪器的容器，我们可以将第二个网络服务（带有预测模型）打包到另一个网络服务中。下面的 Dockerfile 执行此操作：
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This Dockerfile sets up an Ubuntu-based environment, installs Python 3 and
    `pip`, copies your application code into the image, installs Python dependencies
    from `requirements.txt`, and then runs the Python script as the default command
    when the container starts. Please note that we use Ubuntu here and not Alpine
    Linux. This is no accident. There is no scikit-learn package for Alpine Linux,
    so we need to use Ubuntu (for which that Python package is available):'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Dockerfile 设置了一个基于 Ubuntu 的环境，安装 Python 3 和 `pip`，将你的应用程序代码复制到镜像中，从 `requirements.txt`
    安装 Python 依赖项，然后在容器启动时运行 Python 脚本作为默认命令。请注意，我们在这里使用 Ubuntu 而不是 Alpine Linux。这不是偶然的。Alpine
    Linux 上没有 scikit-learn 软件包，因此我们需要使用 Ubuntu（该 Python 软件包可用）：
- en: '`FROM ubuntu:latest`: This line specifies the base image for the Docker image.
    In this case, it uses the latest version of the Ubuntu Linux distribution as the
    base image. `latest` refers to the latest version of the Ubuntu image available
    on Docker Hub.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FROM ubuntu:latest`: 这一行指定了 Docker 镜像的基础镜像。在这种情况下，它使用 Ubuntu Linux 分发的最新版本作为基础镜像。`latest`
    指的是 Docker Hub 上可用的 Ubuntu 镜像的最新版本。'
- en: '`RUN apt update && apt install python3 python3-pip -y`: This command is used
    to update the package index of the Ubuntu package manager (`apt`) and then install
    Python 3 and Python 3 `pip`. The `-y` flag is used to automatically answer “yes”
    to any prompts during the installation process.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RUN apt update && apt install python3 python3-pip -y`: 这个命令用于更新 Ubuntu 软件包管理器
    (`apt`) 的软件包索引，然后安装 Python 3 和 Python 3 的 `pip`。`-y` 标志用于在安装过程中自动回答“是”以响应任何提示。'
- en: '`WORKDIR /app`: This sets the working directory for the subsequent commands
    to `/app`. This directory is where the application code will be copied, and it
    becomes the default directory for running commands.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WORKDIR /app`: 这个命令设置后续命令的工作目录为 `/app`。这个目录是应用程序代码将被复制的地方，并且它成为运行命令的默认目录。'
- en: '`COPY . /app`: This copies the contents of the current directory (where the
    Dockerfile is located) into the `/app` directory in the Docker image.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`COPY . /app`: 这个命令将当前目录（Dockerfile 所在的位置）的内容复制到 Docker 镜像中的 `/app` 目录。'
- en: '`RUN pip --no-cache-dir install -q -r requirements.txt`: This installs Python
    dependencies specified in the `requirements.txt` file using pip. The flags that
    are used here are as follows:'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RUN pip --no-cache-dir install -q -r requirements.txt`: 这个命令使用 pip 安装 `requirements.txt`
    文件中指定的 Python 依赖项。这里使用的标志如下：'
- en: '`--no-cache-dir`: This ensures that no cache is used during the installation,
    which can help reduce the size of the Docker image'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--no-cache-dir`: 这个标志确保在安装过程中不使用缓存，这有助于减少 Docker 镜像的大小。'
- en: '`-q`: This flag runs `pip` in quiet mode, meaning it will produce less output,
    which can make the Docker build process less verbose'
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-q`: 这个标志以静默模式运行 `pip`，意味着它将产生更少的输出，这可以使 Docker 构建过程不那么冗长。'
- en: '`CMD ["python3", "main.py"]`: This specifies the default command to run when
    a container is started from this image. In this case, it runs the `main.py` Python
    script using `python3`. This is the command that will be executed when we run
    a container based on this Docker image.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CMD ["python3", "main.py"]`：这指定了从该镜像启动容器时运行的默认命令。在这种情况下，它使用`python3`运行`main.py`
    Python脚本。这是我们基于此Docker镜像运行容器时将执行的命令。'
- en: 'In this case, the requirements code is a bit longer, although not extremely
    complex:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，需求代码稍微长一点，尽管不是特别复杂：
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We compile the Docker container with a similar command:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用类似的命令编译Docker容器：
- en: '[PRE10]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We execute it with a similar command:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用类似的命令执行它：
- en: '[PRE11]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now, we should be able to use the same browser commands to connect. Please note
    that we use a different port so that this new web service does not collide with
    the previous one.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们应该能够使用相同的浏览器命令来连接。请注意，我们使用不同的端口，这样新的web服务就不会与之前的冲突。
- en: Combining web services into ecosystems
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将web服务组合成生态系统
- en: 'Now, let’s develop the software that will connect these two web services. For
    this, we’ll create a new file that will send one file to the first web service,
    get the data, and then send it to the second web service to make predictions:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开发将连接这两个web服务的软件。为此，我们将创建一个新的文件，该文件将向第一个web服务发送一个文件，获取数据，然后将数据发送到第二个web服务进行预测：
- en: '[PRE12]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This code demonstrates how to upload a file to a Flask web service to obtain
    metrics and then send those metrics to another Flask web service for making predictions.
    It uses the `requests` library to handle HTTP requests and JSON responses between
    the two services:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码演示了如何将文件上传到Flask web服务以获取度量，然后将这些度量发送到另一个Flask web服务进行预测。它使用`requests`库来处理两个服务之间的HTTP请求和JSON响应：
- en: '`import requests`: This line imports the `requests` library, which is used
    to send HTTP requests to web services.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import requests`：这一行导入了`requests`库，该库用于向web服务发送HTTP请求。'
- en: '`upload_url`: This variable stores the URL of the Flask web service for file
    upload.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upload_url`：这个变量存储了用于文件上传的Flask web服务的URL。'
- en: '`prediction_url`: This variable stores the URL of the Flask web service for
    predictions.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_url`：这个变量存储了用于预测的Flask web服务的URL。'
- en: '`upload_file_and_get_metrics`:'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`upload_file_and_get_metrics`：'
- en: This function takes `file_path` as input, which should be the path to the file
    you want to upload and obtain metrics for
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个函数接受`file_path`作为输入，它应该是你想要上传并获取度量的文件路径
- en: It sends a POST request to `upload_url` to upload the specified file
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它向`upload_url`发送POST请求以上传指定的文件
- en: After uploading the file, it parses the JSON response received from the file
    upload service
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在上传文件后，它解析从文件上传服务收到的JSON响应
- en: It extracts the `"lines_of_code"` and `"mccabe_complexity"` fields from the
    JSON response
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它从JSON响应中提取`"lines_of_code"`和`"mccabe_complexity"`字段
- en: The extracted metrics are printed, and the function returns them
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取的度量被打印出来，并且函数返回它们
- en: '`send_metrics_for_prediction`:'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`send_metrics_for_prediction`：'
- en: This function takes `loc` (lines of code) and `mcc` (McCabe complexity) values
    as input
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个函数接受`loc`（代码行数）和`mcc`（McCabe复杂性）值作为输入
- en: It constructs the URL for making predictions by appending the `loc` and `mcc`
    values to `prediction_url`
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它通过将`loc`和`mcc`值附加到`prediction_url`来构造用于预测的URL
- en: It sends a GET request to the prediction service using the constructed URL
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用构造的URL向预测服务发送GET请求
- en: After receiving the prediction, it parses the JSON response to obtain the `"``Defect"`
    value
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在收到预测后，它解析JSON响应以获取`"Defect"`值
- en: The prediction is printed to the console
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测结果被打印到控制台
- en: '`if __name__ == ''__main__''`: This block specifies the file path (`file_path`)
    that you want to upload and obtain metrics for. It calls the `upload_file_and_get_metrics`
    function to upload the file and obtain the metrics (lines of code and McCabe complexity).
    Then, it calls the `send_metrics_for_prediction` function to send these metrics
    for prediction and prints the prediction.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`if __name__ == ''__main__''`：这个块指定了你想要上传并获取度量的文件路径（`file_path`）。它调用`upload_file_and_get_metrics`函数上传文件并获取度量（代码行数和McCabe复杂性）。然后，它调用`send_metrics_for_prediction`函数将这些度量发送给预测，并打印预测结果。'
- en: This program shows that we can package our model into a web service (with or
    without a container) and then use it, just like *Figure 16**.1* suggested. This
    way of designing the entire system allows us to make the software more scalable
    and robust. Depending on the usage scenario, we can adapt the web services and
    deploy them on several different servers for scalability and load balancing.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序表明我们可以将我们的模型打包成一个Web服务（带或不带容器），然后使用它，正如*图16**.1*所建议的那样。这种设计整个系统的方式使我们能够使软件更具可扩展性和健壮性。根据使用场景，我们可以调整Web服务并在多个不同的服务器上部署，以实现可扩展性和负载均衡。
- en: Summary
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to deploy ML models using web services and Docker.
    Although we only deployed two web services, we can see that it can become an ecosystem
    for ML. By separating predictions and measurements, we can separate the computational-heavy
    workloads (prediction) and the data collection parts of the pipeline. Since the
    model can be deployed on any server, we can reuse the servers and therefore reduce
    the energy consumption of these models.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用Web服务和Docker部署机器学习模型。尽管我们只部署了两个Web服务，但我们可以看出它可以成为一个机器学习生态系统。通过分离预测和测量，我们可以分离计算密集型工作负载（预测）和数据收集部分的管道。由于模型可以部署在任何服务器上，我们可以重用服务器，从而减少这些模型的能源消耗。
- en: With that, we have come to was last technical chapter of this book. In the next
    chapter, we’ll take a look at the newest trends in ML and peer into our crystal
    ball to predict, or at least guess, the future.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们来到了这本书的最后一章技术章节。在下一章，我们将探讨机器学习的新趋势，并展望未来，至少是猜测未来。
- en: References
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Masse, M., REST API design rulebook: designing consistent RESTful web service
    interfaces. 2011: “O’Reilly* *Media, Inc.”.*'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Masse, M., REST API设计规则手册：设计一致的RESTful Web服务接口。2011: “O’Reilly* *Media, Inc.”.*'
- en: '*Raj, P., J.S. Chelladhurai, and V. Singh, Learning Docker. 2015: Packt* *Publishing
    Ltd.*'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Raj, P.，J.S. Chelladhurai和V. Singh，学习Docker。2015: Packt* *Publishing Ltd.*'
- en: '*Staron, M., et al. Robust Machine Learning in Critical Care—Software Engineering
    and Medical Perspectives. In 2021 IEEE/ACM 1st Workshop on AI Engineering-Software
    Engineering for AI (WAIN).* *2021\. IEEE.*'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Staron, M.等，重症监护中的鲁棒机器学习——软件工程和医学视角。在2021年IEEE/ACM首届人工智能工程-人工智能软件工程（WAIN）研讨会。2021.
    IEEE.*'
- en: '*McCabe, T.J., A complexity measure. IEEE Transactions on Software Engineering,
    1976(4):* *p. 308-320.*'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*McCabe, T.J., 复杂度度量。IEEE软件工程 Transactions，1976(4):* *p. 308-320.*'
