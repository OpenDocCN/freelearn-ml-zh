- en: Building Content-Based Recommenders
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建基于内容的推荐系统
- en: In the previous chapter, we built an IMDB Top 250 clone (a type of simple recommender)
    and a knowledge-based recommender that suggested movies based on timeline, genre,
    and duration. However, these systems were extremely primitive. The simple recommender
    did not take into consideration an individual user's preferences. The knowledge-based recommender
    did take account of the user's preference for genres, timelines, and duration,
    but the model and its recommendations still remained very generic.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们建立了一个 IMDB Top 250 克隆（一个简单推荐系统）和一个基于知识的推荐系统，根据时间线、类型和时长建议电影。然而，这些系统都非常原始。简单推荐系统没有考虑个别用户的偏好。基于知识的推荐系统考虑了用户对类型、时间线和时长的偏好，但模型及其推荐仍然非常通用。
- en: Imagine that Alice likes the movies *The Dark Knight, **Iron Man*,and *Man of
    Steel. *It is pretty evident that Alice has a taste for superhero movies. However,
    our models from the previous chapter would not be able to capture this detail.
    The best it could do is suggest *action *movies (by making Alice input *action *as
    the preferred genre), which is a superset of superhero movies.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 Alice 喜欢的电影有 *《黑暗骑士》*、**《钢铁侠》** 和 *《超人：钢铁之躯》*。很显然，Alice 喜欢超级英雄电影。然而，我们在上一章建立的模型无法捕捉到这一细节。它们能做的最好的事情就是建议
    *动作* 电影（通过让 Alice 输入 *动作* 作为首选类型），而动作电影是超级英雄电影的超集。
- en: It is also possible that two movies have the same genre, timeline, and duration
    characteristics, but differ hugely in their audience. Consider *The* *Hangover *and *Forgetting
    Sarah Marshall, *for example. Both these movies were released in the first decade
    of the 21st century, both lasted around two hours, and both were comedies. However,
    the kind of audience that enjoyed these movies was very different.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 也有可能两部电影拥有相同的类型、时间线和时长特征，但在受众上有很大的不同。例如，考虑 *《宿醉》* 和 *《遗忘萨拉·马歇尔》*。这两部电影都是21世纪第一个十年上映的，都持续了大约两个小时，都是喜剧片。然而，喜欢这两部电影的观众类型却截然不同。
- en: An obvious fix to this problem is to ask the user for more metadata as input.
    For instance, if we introduced a *sub-genre *input, the user would be able to
    input values such as *superhero, black comedy,* and *romantic comedy, *and obtain
    more appropriate results, but this solution suffers heavily from the perspective
    of usability.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的一个显而易见的办法是要求用户提供更多的元数据作为输入。例如，如果我们增加 *子类型* 输入，用户就能输入如 *超级英雄、黑色幽默* 和 *浪漫喜剧*
    等值，从而获得更合适的推荐结果，但这种解决方案在可用性方面存在很大问题。
- en: The first problem is that we do not possess data on *sub-genres.* Secondly,
    even if we did, our users are extremely unlikely to possess knowledge of their
    favorite movies' metadata. Finally, even if they did, they would certainly not
    have the patience to input it into a long form. Instead, what they would be more
    willing to do is tell you the movies they like/dislike and expect recommendations
    that match their tastes.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个问题是我们没有 *子类型* 数据。其次，即使有数据，用户极不可能了解他们喜欢的电影的元数据。最后，即使他们知道这些，他们也肯定不会有耐心将这些信息输入到一个长表单中。相反，他们更愿意做的是告诉你他们喜欢/不喜欢的电影，并期待得到与他们口味相符的推荐。
- en: As we discussed in the first chapter, this is exactly what sites like Netflix
    do. When you sign up on Netflix for the first time, it doesn't have any information
    about your tastes for it to build a profile, leverage the power of its community,
    and give you recommendations with (a concept we'll explore in later chapters).
    Instead, what it does is ask you for a few movies you like and show you results
    that are most similar to those movies.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第一章中讨论的那样，这正是 Netflix 等网站所做的。当你第一次注册 Netflix 时，它没有任何关于你口味的信息来建立个人档案，利用社区的力量为你推荐电影（这是我们在后续章节中会探讨的概念）。相反，它会要求你提供一些你喜欢的电影，并显示与你喜欢的电影最相似的结果。
- en: 'In this chapter, we are going to build two types of content-based recommender:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将构建两种类型的基于内容的推荐系统：
- en: '**Plot description-based recommender: **This model compares the descriptions
    and taglines of different movies, and provides recommendations that have the most
    similar plot descriptions.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于情节描述的推荐系统：** 该模型比较不同电影的描述和标语，提供情节描述最相似的推荐结果。'
- en: '**Metadata-based recommender: **This model takes a host of features, such as
    genres, keywords, cast, and crew, into consideration and provides recommendations
    that are the most similar with respect to the aforementioned features.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于元数据的推荐系统：**该模型考虑了大量特征，例如类型、关键词、演员和制作人员，并提供最相似的推荐，基于上述特征。'
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will be required to have Python installed on a system. Finally, to use the
    Git repository of this book, the user needs to install Git.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要在系统上安装Python。最后，要使用本书的Git仓库，用户需要安装Git。
- en: 'The code files of this chapter can be found on GitHub:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在GitHub上找到：
- en: '[https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python](https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python)[.](https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python](https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python)[.](https://github.com/PacktPublishing/Hands-On-Recommendation-Systems-with-Python)'
- en: 'Check out the following video to see the code in action:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，看看代码如何执行：
- en: '[http://bit.ly/2LOcac2](http://bit.ly/2LOcac2)[.](http://bit.ly/2LOcac2)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2LOcac2](http://bit.ly/2LOcac2)[.](http://bit.ly/2LOcac2)'
- en: Exporting the clean DataFrame
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导出清理后的DataFrame
- en: In the previous chapter, we performed a series of data wrangling and cleaning
    processes on our metadata in order to convert it into a form that was more usable.
    To avoid having to perform these steps again, let's save this cleaned DataFrame
    into a CSV file. As always, doing this with pandas happens to be extremely easy.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们对元数据进行了系列数据整理和清理，以将其转换为更易用的形式。为了避免再次执行这些步骤，我们将清理后的DataFrame保存为CSV文件。像往常一样，使用pandas来做这一切非常简单。
- en: 'In the knowledge recommendernotebook from Chapter 4*, *enter the following
    code in the last cell:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在第四章的知识推荐器notebook中，*请输入以下代码*：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Your `data`folder should now contain a new file, `metadata_clean.csv`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 您的`data`文件夹现在应该包含一个新文件，`metadata_clean.csv`。
- en: 'Let''s create a new folder, `Chapter 4`*, *and open a new Jupyter Notebook
    within this folder. Let''s now import our new file into this Notebook:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个新的文件夹，`Chapter 4`*，*并在该文件夹内打开一个新的Jupyter Notebook。现在让我们将新文件导入这个Notebook：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The cell should output a DataFrame that is already clean and in the desired
    form.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该单元应输出一个已经清理并符合所需格式的DataFrame。
- en: Document vectors
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文档向量
- en: Essentially, the models we are building compute the pairwise similarity between
    bodies of text. But how do we numerically quantify the similarity between two
    bodies of text?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，我们正在构建的模型计算文本之间的成对相似度。那么，我们如何用数字量化两篇文本之间的相似度呢？
- en: 'To put it another way, consider three movies: A, B, and C. How can we mathematically
    prove that the plot of A is more similar to the plot of B than to that of C (or
    vice versa)?'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，考虑三部电影：A、B和C。我们如何在数学上证明A的情节比B更像C的情节（或反之）？
- en: The first step toward answering these questions is to represent the bodies of
    text (henceforth referred to as documents)as mathematical quantities. This is
    done by representing these documents as vectors*. *In other words, every document
    is depicted as a series of *n *numbers, where each number represents a dimension
    and *n *is the size of the vocabulary of all the documents put together.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 解答这些问题的第一步是将文本体（以下简称为文档）表示为数学量。这是通过将这些文档表示为向量来实现的*。*换句话说，每个文档都被描绘为一系列*n*个数字，其中每个数字代表一个维度，*n*是所有文档词汇的总大小。
- en: But what are the values of these vectors? The answer to that question depends
    on the *vectorizer *we are using to convert our documents into vectors. The two
    most popular vectorizers are CountVectorizer and TF-IDFVectorizer*.*
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这些向量的值是多少？这个问题的答案取决于我们使用的*向量化工具*，即将文档转换为向量的工具。最受欢迎的两种向量化工具是CountVectorizer和TF-IDFVectorizer*。
- en: CountVectorizer
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CountVectorizer
- en: 'CountVectorizer is the simplest type of vectorizer and is best explained with
    the help of an example. Imagine that we have three documents, A, B, and C, which
    are as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: CountVectorizer是最简单的向量化工具，最好的解释方法是通过一个示例。假设我们有三篇文档，A、B和C，如下所示：
- en: '**A**: The sun is a star.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A**：太阳是一颗恒星。'
- en: '**B**: My love is like a red, red rose'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**B**：我的爱像一朵红红的玫瑰'
- en: '**C**: Mary had a little lamb'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C**：玛丽有只小羊'
- en: We now have to convert these documents into their vector forms using CountVectorizer.
    The first step is to compute the size of the vocabulary. The vocabulary is the
    number of unique words present across all documents. Therefore, the vocabulary
    for this set of three documents is as follows: the, sun, is, a, star, my, love,
    like, red, rose, mary, had, little, lamb. Consequently, the size of the vocabulary
    is 14.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要使用 CountVectorizer 将这些文档转换为向量形式。第一步是计算词汇表的大小。词汇表是指所有文档中出现的唯一词汇数量。因此，这三份文档的词汇表如下：the,
    sun, is, a, star, my, love, like, red, rose, mary, had, little, lamb。结果，词汇表的大小是
    14。
- en: 'It is common practice to not include extremely common words such as a, the,
    is, had, my, and so on (also known as stop words) in the vocabulary. Therefore,
    eliminating the stop words, our vocabulary, *V,* is as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通常的做法是不会将极为常见的单词（如 a, the, is, had, my 等）包含在词汇表中，这些单词也被称为停用词。因此，在去除停用词后，我们的词汇表
    *V* 如下：
- en: '**V**: like, little, lamb, love, mary, red, rose, sun, star'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**V**：like, little, lamb, love, mary, red, rose, sun, star'
- en: The size of our vocabulary is now nine. Therefore, our documents will be represented
    as nine-dimensional vectors, and each dimension here will represent the number
    of times a particular word occurs in a document. In other words, the first dimension
    will represent the number of times likeoccurs, the second will represent the number
    of times little occurs, and so on.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的词汇表大小是九。因此，我们的文档将被表示为九维向量，每个维度代表某个特定单词在文档中出现的次数。换句话说，第一个维度表示 "like" 出现的次数，第二个维度表示
    "little" 出现的次数，以此类推。
- en: 'Therefore, using the CountVectorizer approach, A, B, and C will now be represented
    as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用 CountVectorizer 方法，A、B 和 C 将现在表示如下：
- en: '**A**: (0, 0, 0, 0, 0, 0, 0, 1, 1)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A**：（0, 0, 0, 0, 0, 0, 0, 1, 1）'
- en: '**B**: (1, 0, 0, 1, 0, 2, 1, 0, 0)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**B**：（1, 0, 0, 1, 0, 2, 1, 0, 0）'
- en: '**C**: (0, 1, 1, 0, 1, 0, 0, 0, 0)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C**：（0, 1, 1, 0, 1, 0, 0, 0, 0）'
- en: TF-IDFVectorizer
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TF-IDF Vectorizer
- en: Not all words in a document carry equal weight. We already observed this when
    we eliminated the stop words from our vocabulary altogether. But the words that
    were in the vocabulary were all given equal weighting.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 不是文档中的所有词汇都具有相同的权重。当我们完全去除停用词时，我们已经观察到了这一点。但词汇中存在的词都赋予了相等的权重。
- en: But should this always be the case?
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 但这总是正确的吗？
- en: For example, consider a corpus of documents on dogs. Now, it is obvious that
    all these documents will frequently contain the word dog. Therefore, the appearance
    of the word *dog *isn't as important as another word that only appears in a few
    documents.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个关于狗的文档集合。现在，很明显，这些文档中将频繁出现 "dog" 这个词。因此，"dog" 的出现并不像其他只在少数文档中出现的词那样重要。
- en: '**TF-IDF****Vectorizer** (**Term Frequency-Inverse Document Frequency**)takes
    the aforementioned point into consideration and assigns weights to each word according
    to the following formula. For every word *i *in document *j*, the following applies:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**TF-IDF** **Vectorizer**（**词频-逆文档频率**）考虑到了上述因素，并根据以下公式为每个单词分配权重。对于文档 *j* 中的每个单词
    *i*，适用以下公式：'
- en: '![](img/3d0955be-dfd1-488a-9288-d0a0c83922e3.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d0955be-dfd1-488a-9288-d0a0c83922e3.png)'
- en: 'In this formula, the following is true:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，以下是成立的：
- en: '*w*[*i, j* ]is the weight of word *i *in document *j*'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[*i, j*] 是词汇 *i* 在文档 *j* 中的权重'
- en: '*df[i] *is the number of documents that contain the term *i*'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*df[i]* 是包含词汇 *i* 的文档数量'
- en: '*N *is the total number of documents'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*N* 是文档的总数'
- en: 'We won''t go too much into the formula and the associated calculations. Just
    keep in mind that the weight of a word in a document is greater if it occurs more
    frequently in that document and is present in fewer documents. The weight *w*[*i,j* ]takes
    values between `0` and `1`:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入探讨公式及相关计算。只需记住，文档中一个词的权重越大，如果它在该文档中出现的频率越高，并且出现在较少的文档中。权重 *w*[*i,j*]的取值范围是`0`到`1`：
- en: '![](img/b02a313f-7888-4ddd-8398-411cfa8e712f.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b02a313f-7888-4ddd-8398-411cfa8e712f.png)'
- en: We will be using TF-IDFVectorizer because some words (pictured in the preceding
    word cloud) occur much more frequently in plot descriptions than others. It is
    therefore a good idea to assign weights to each word in a document according to
    the TF-IDF formula.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 TF-IDF Vectorizer，因为某些词（如前面词云中的词汇）在描述图表时的出现频率远高于其他词。因此，根据 TF-IDF 公式为文档中的每个单词分配权重是一个好主意。
- en: Another reason to use TF-IDF is that it speeds up the calculation of the cosine
    similarity score between a pair of documents. We will discuss this point in greater
    detail when we implement this in code.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TF-IDF的另一个原因是它加速了计算文档对之间的余弦相似度得分。当我们在代码中实现时，将会更详细地讨论这一点。
- en: The cosine similarity score
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 余弦相似度得分
- en: We will discuss similarity scores in detail in [Chapter 5](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml),
    *Getting Started with Data Mining Techniques*. Presently, we will make use of
    the *cosine similarity *metric to build our models. The cosine score is extremely
    robust and easy to calculate (especially when used in conjunction with TF-IDFVectorizer).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第五章](cde5090f-2e41-4e6f-ab11-f5179f1ee2a6.xhtml)《数据挖掘技术入门》中详细讨论相似度得分。现在，我们将使用*余弦相似度*度量来构建我们的模型。余弦得分非常稳健且容易计算（尤其是当与TF-IDF向量化器一起使用时）。
- en: 'The cosine similarity score between two documents, *x *and *y, *is as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 两个文档*x*和*y*之间的余弦相似度得分计算公式如下：
- en: '![](img/848e2bba-80ee-4352-94ed-ddbc3997b56a.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/848e2bba-80ee-4352-94ed-ddbc3997b56a.png)'
- en: The cosine score can take any value between -1 and 1\. The higher the cosine
    score, the more similar the documents are to each other. We now have a good theoretical
    base to proceed to build the content-based recommenders using Python.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦得分可以取从-1到1之间的任何值。余弦得分越高，文档之间的相似度就越大。现在，我们有了一个良好的理论基础，可以开始使用Python构建基于内容的推荐系统了。
- en: Plot description-based recommender
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于剧情描述的推荐系统
- en: 'Our plot description-based recommender will take in a movie title as an argument
    and output a list of movies that are most similar based on their plots. These
    are the steps we are going to perform in building this model:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的基于剧情描述的推荐系统将以电影标题作为输入，并输出一份基于电影剧情最相似的电影列表。以下是我们将在构建该模型时执行的步骤：
- en: Obtain the data required to build the model
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取构建模型所需的数据
- en: Create TF-IDF vectors for the plot description (or overview) of every movie
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每部电影的剧情描述（或概述）创建TF-IDF向量
- en: Compute the pairwise cosine similarity score of every movie
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每对电影的余弦相似度得分
- en: Write the recommender function that takes in a movie title as an argument and
    outputs movies most similar to it based on the plot
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写推荐函数，该函数接受电影标题作为输入，并基于剧情输出与其最相似的电影
- en: Preparing the data
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据
- en: In its present form, the DataFrame, although clean, does not contain the features
    that are required to build the plot description-based recommender. Fortunately,
    these requisite features are available in the original metadata file.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，虽然数据框（DataFrame）已经清理完毕，但它并不包含构建基于剧情描述的推荐系统所需的特征。幸运的是，这些必要的特征可以在原始元数据文件中找到。
- en: 'All we have to do is import them and add them to our DataFrame:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的就是导入它们并将其添加到我们的数据框中：
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The DataFrame should now contain two new features: `overview` and `id`.We will
    use `overview`in building this model and `id`for building the next.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据框应该包含两个新特征：`overview`和`id`。我们将在构建这个模型时使用`overview`，而使用`id`来构建下一个模型。
- en: The `overview`feature consists of strings and, ideally, we should clean them
    up by removing all punctuation and converting all the words to lowercase. However,
    as we will see shortly, all this will be done for us automatically by `scikit-learn`*, *the
    library we're going to use heavily in building the models in this chapter.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`overview`特征由字符串组成，理想情况下，我们应该通过去除所有标点符号并将所有单词转换为小写来清理它们。然而，正如我们接下来会看到的，`scikit-learn`库会自动为我们完成这一切工作，这个库将在本章中大规模应用于构建模型。'
- en: Creating the TF-IDF matrix
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建TF-IDF矩阵
- en: 'The next step is to create a DataFrame where each row represents the TF-IDF
    vector of the `overview` feature of the corresponding movie in our main DataFrame.
    To do this, we will use the `scikit-learn`library, which gives us access to a
    TfidfVectorizer object to perform this process effortlessly:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建一个数据框，其中每一行表示我们主数据框中对应电影的`overview`特征的TF-IDF向量。为此，我们将使用`scikit-learn`库，它为我们提供了一个TfidfVectorizer对象，能够轻松地完成这一过程：
- en: '[PRE3]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We see that the vectorizer has created a 75,827-dimensional vector for the overview
    of every movie.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，向量化器为每部电影的概述创建了一个75,827维的向量。
- en: Computing the cosine similarity score
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算余弦相似度得分
- en: The next step is to calculate the pairwise cosine similarity score of every
    movie. In other words, we are going to create a 45,466 × 45,466 matrix, where
    the cell in the *i^(th )*row and *j^(th) *column represents the similarity score
    between movies *i *and *j. *We can easily see that this matrix is symmetric in
    nature and every element in the diagonal is 1, since it is the similarity score
    of the movie with itself.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是计算每部电影的成对余弦相似度分数。换句话说，我们将创建一个 45,466 × 45,466 的矩阵，其中第*i^(th)*行和第*j^(th)*列的单元格表示电影*i*和*j*之间的相似度分数。*我们可以很容易地看到，这个矩阵具有对称性，且对角线上的每个元素都是
    1，因为它表示电影与自身的相似度分数。*
- en: 'Like TF-IDFVectorizer, `scikit-learn`also has functionality for computing the
    aforementioned similarity matrix. Calculating the cosine similarity is, however,
    a computationally expensive process. Fortunately, since our movie plots are represented
    as TF-IDF vectors, their magnitude is always 1\. Hence, we do not need to calculate
    the denominator in the cosine similarity formula as it will always be 1\. Our
    work is now reduced to computing the much simpler and computationally cheaper
    dot product (a functionality that is also provided by `scikit-learn`):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 和 TF-IDFVectorizer 一样，`scikit-learn`也有计算上述相似度矩阵的功能。然而，计算余弦相似度是一个计算上昂贵的过程。幸运的是，由于我们的电影情节是以
    TF-IDF 向量表示的，因此它们的幅度始终为 1。*因此，我们无需计算余弦相似度公式中的分母，因为它始终是 1。我们的工作现在简化为计算一个更简单、更计算廉价的点积（这也是`scikit-learn`提供的功能）：*
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Although we're computing the cheaper dot product, the process will still take
    a few minutes to complete. With the similarity scores of every movie with every
    other movie, we are now in a very good position to write our final recommender
    function.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在计算更便宜的点积，整个过程仍然需要几分钟才能完成。通过计算每部电影与其他电影的相似度分数，我们现在处于一个非常有利的位置，可以编写我们的最终推荐函数。
- en: Building the recommender function
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建推荐函数
- en: 'The final step is to create our recommender function. However, before we do
    that, let''s create a reverse mapping of movie titles and their respective indices.
    In other words, let''s create a pandas series with the index as the movie title
    and the value as the corresponding index in the main DataFrame:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是创建我们的推荐函数。但是，在此之前，让我们先创建一个电影标题及其对应索引的反向映射。换句话说，让我们创建一个 pandas 系列，将电影标题作为索引，电影在主
    DataFrame 中的索引作为值：
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will perform the following steps in building the recommender function:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在构建推荐函数时执行以下步骤：
- en: Declare the title of the movie as an argument.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将电影标题声明为一个参数。
- en: Obtain the index of the movie from the `indices`reverse mapping.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`indices`反向映射中获取电影的索引。
- en: Get the list of cosine similarity scores for that particular movie with all
    movies using `cosine_sim`. Convert this into a list of tuples where the first
    element is the position and the second is the similarity score.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cosine_sim`获取该电影与所有其他电影的余弦相似度分数列表。将其转换为一个元组列表，其中第一个元素是位置，第二个元素是相似度分数。
- en: Sort this list of tuples on the basis of the cosine similarity scores.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据余弦相似度分数对这个元组列表进行排序。
- en: Get the top 10 elements of this list. Ignore the first element as it refers
    to the similarity score with itself (the movie most similar to a particular movie
    is obviously the movie itself).
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取这个列表的前 10 个元素。忽略第一个元素，因为它表示与自身的相似度分数（与某部电影最相似的电影显然就是它自己）。
- en: 'Return the titles corresponding to the indices of the top 10 elements, excluding
    the first:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回与前 10 个元素索引对应的标题，排除第一个：
- en: '[PRE6]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Congratulations! You've built your very first content-based recommender. Now
    it is time to see our recommender in action! Let's ask it for recommendations
    of movies similar to `The Lion King`*:*
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经构建了你的第一个基于内容的推荐系统。现在是时候让我们的推荐系统实际运作了！让我们请求它推荐类似于`《狮子王》`的电影：*
- en: '[PRE7]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](img/b4947e84-7420-41ae-be55-37bfda306563.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b4947e84-7420-41ae-be55-37bfda306563.png)'
- en: We see that our recommender has suggested all of *The Lion King's* sequels in
    its top-10 list. We also notice that most of the movies in the list have to do
    with lions.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到我们的推荐系统在其前 10 名列表中建议了所有*《狮子王》*的续集。我们还注意到，列表中的大多数电影都与狮子有关。
- en: It goes without saying that a person who loves *The Lion King* is very likely
    to have a thing for Disney movies. They may also prefer to watch animated movies.
    Unfortunately, our plot description recommender isn't able to capture all this
    information.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 不言而喻，喜欢*《狮子王》*的人很可能对迪士尼电影情有独钟。他们也许还更倾向于观看动画片。不幸的是，我们的情节描述推荐器无法捕捉到所有这些信息。
- en: Therefore, in the next section, we will build a recommender that uses more advanced
    metadata, such as genres, cast, crew, and keywords (or sub-genres). This recommender
    will be able to do a much better job of identifying an individual's taste for
    a particular director, actor, sub-genre, and so on.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在下一部分中，我们将构建一个使用更高级元数据的推荐系统，如类型、演员、工作人员和关键词（或子类型）。这个推荐系统将能够更好地识别个人对特定导演、演员、子类型等的喜好。
- en: Metadata-based recommender
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于元数据的推荐系统
- en: We will largely follow the same steps as the plot description-based recommender
    to build our metadata-based model. The main difference, of course, is in the type
    of data we use to build the model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将大致按照基于剧情描述的推荐系统的步骤来构建我们的基于元数据的模型。当然，主要的区别在于我们用来构建模型的数据类型。
- en: Preparing the data
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'To build this model, we will be using the following metdata:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建这个模型，我们将使用以下元数据：
- en: The genre of the movie.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影的类型。
- en: The director of the movie. This person is part of the crew.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影的导演。此人是工作人员的一部分。
- en: The movie's three major stars. They are part of the cast.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影的三大主演。他们是演员阵容的一部分。
- en: Sub-genres or keywords.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 子类型或 关键词。
- en: With the exception of genres, our DataFrames (both original and cleaned) do
    not contain the data that we require. Therefore, for this exercise, we will need
    to download two additional files: `credits.csv`*, *which contains information
    on the cast and crew of the movies, and `keywords.csv`*, *which contains information
    on the sub-genres.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 除了类型之外，我们的DataFrame（无论是原始的还是清洗过的）并未包含我们所需要的数据。因此，在这次练习中，我们需要下载两个附加文件：`credits.csv`*，*其中包含电影演员和工作人员的信息，以及 `keywords.csv`*，*其中包含子类型的信息。
- en: You can download the necessary files from the following URL: [https://www.kaggle.com/rounakbanik/the-movies-dataset/data](https://www.kaggle.com/rounakbanik/the-movies-dataset/data).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从以下网址下载所需的文件：[https://www.kaggle.com/rounakbanik/the-movies-dataset/data](https://www.kaggle.com/rounakbanik/the-movies-dataset/data)。
- en: Place both files in your `data`folder. We need to perform a good amount of wrangling
    before the data is converted into a form that is usable. Let's begin!
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 将两个文件放入你的 `data`文件夹中。在将数据转换为可用格式之前，我们需要进行大量的清洗工作。让我们开始吧！
- en: The keywords and credits datasets
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键词和演员阵容数据集
- en: 'Let''s start by loading our new data into the existing Jupyter Notebook:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始加载新数据到现有的Jupyter Notebook中：
- en: '[PRE8]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](img/16fbcd9d-f350-4369-ace4-7cfb2161c48e.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/16fbcd9d-f350-4369-ace4-7cfb2161c48e.png)'
- en: '[PRE9]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](img/095b3e0a-e471-4a7c-b5d6-d5704da38a9e.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/095b3e0a-e471-4a7c-b5d6-d5704da38a9e.png)'
- en: We can see that the cast, crew, and the keywords are in the familiar `list of
    dictionaries`form. Just like `genres`*, *we have to reduce them to a string or
    a list of strings.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到演员阵容、工作人员和关键词都采用了我们熟悉的`字典列表`格式。就像 `genres`*，*我们必须将它们简化为字符串或字符串列表。
- en: Before we do this, however, we will jointhe three DataFrames so that all our
    features are in a single DataFrame. Joining pandas DataFrames is identical to
    joining tables in SQL. The key we're going to use to join the DataFrames is the `id`feature.
    However, in order to use this, we first need to explicitly convert is listed as
    an ID. This is clearly bad data. Therefore, we should fin
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在此之前，我们将联合三个DataFrame，以便将所有特征合并到一个DataFrame中。连接pandas DataFrame与在SQL中连接表格是相同的。我们将用于连接DataFrame的键是 `id` 特征。然而，为了使用这个，我们首先需要明确地将其转换为ID格式。这显然是错误的数据。因此，我们应该查找
- en: 'into an integer. We already know how to do this:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 转换为整数。我们已经知道如何做到这一点：
- en: '[PRE10]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Running the preceding code results in a `ValueError`. On closer inspection,
    we see that *1997-08-20* is listed as an ID. This is clearly bad data. Therefore,
    we should find all the rows with bad IDs and remove them in order for the code
    execution to be successful:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上面的代码会导致`ValueError`。仔细检查后，我们发现*1997-08-20* 被列为ID。这显然是错误的数据。因此，我们应该找到所有ID错误的行并删除它们，以确保代码执行成功：
- en: '[PRE11]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We are now in a good position to convert the IDs of all three DataFrames into
    integers and merge them into a single DataFrame:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好将所有三个DataFrame的ID转换为整数，并将它们合并成一个DataFrame：
- en: '[PRE12]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](img/ce2ccf31-5289-4d31-91e7-d9404323db07.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce2ccf31-5289-4d31-91e7-d9404323db07.png)'
- en: Wrangling keywords, cast, and crew
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理关键词、演员和工作人员
- en: 'Now that we have all the desired features in a single DataFrame, let''s  convert
    them into a form that is more usable. More specifically, these are the transformations
    we will be looking to perform:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将所有需要的特征合并到一个DataFrame中，让我们将它们转换为更易于使用的格式。更具体地说，我们将进行以下几项转换：
- en: Convert `keywords`into a list of strings where each string is a keyword (similar
    to genres). We will include only the top three keywords. Therefore, this list
    can have a maximum of three elements.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`keywords`转换为字符串列表，其中每个字符串是一个关键词（类似于类型）。我们只会包括前三个关键词。因此，这个列表最多可以包含三个元素。
- en: Convert `cast`into a list of strings where each string is a star. Like `keywords`*,*
    we will only include the top three stars in our cast.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`cast`转换为字符串列表，其中每个字符串都是一位明星。像`keywords`一样，我们只会包括我们演员阵容中的前三位明星。
- en: Convert `crew`into `director`*. *In other words, we will extract only the director
    of the movie and ignore all other crew members.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`crew`转换为`director`。换句话说，我们只提取电影的导演，忽略其他所有工作人员。
- en: 'The first step is to convert these stringified objects into native Python objects:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是将这些字符串化的对象转换为原生的Python对象：
- en: '[PRE13]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, let''s extract the director from our `crew` list. To do this, we will
    first examine the structure of the dictionary in the `crew`list:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们从`crew`列表中提取导演。为此，我们首先检查`crew`列表中字典的结构：
- en: '[PRE14]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We see that this dictionary consists of `job`and `name`keys. Since we''re only
    interested in the director, we will loop through all the crew members in a particular
    list and extract the `name`when the `job`is `Director`. Let''s write a function
    that does this:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到这个字典由`job`和`name`键组成。由于我们只对导演感兴趣，我们将循环遍历特定列表中的所有工作人员，并在`job`为`Director`时提取`name`。让我们编写一个函数来实现这一点：
- en: '[PRE15]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now that we have the `get_director`function, we can define the new `director`feature:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经有了`get_director`函数，我们可以定义新的`director`特性：
- en: '[PRE16]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Both `keywords`and `cast`are dictionary lists as well. And, in both cases,
    we need to extract the top three `name` attributes of each list. Therefore, we
    can write a single function to wrangle both these features. Also, just like `keywords`and `cast`*, *we
    will only consider the top three genres for every movie:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`keywords`和`cast`都是字典列表。在这两种情况下，我们需要提取每个列表中的前三个`name`属性。因此，我们可以编写一个单一的函数来处理这两个特性。另外，和`keywords`以及`cast`一样，我们只会考虑每部电影的前三个类型：'
- en: '[PRE17]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We will use this function to wrangle our `cast`and `keywords`features. We will
    also only consider the first three `genres`listed:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这个函数来处理我们的`cast`和`keywords`特性。我们也只会考虑前三个列出的`genres`：
- en: '[PRE18]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s now take a look at a sample of our wrangled data:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看我们处理后的数据样本：
- en: '[PRE19]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](img/2e13c055-03c2-4dfe-a215-c10fe68ce6a6.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2e13c055-03c2-4dfe-a215-c10fe68ce6a6.png)'
- en: In the subsequent steps, we are going to use a vectorizer to build document
    vectors. If two actors had the same first name (say, Ryan Reynolds and Ryan Gosling),
    the vectorizer will treat both Ryans as the same, although they are clearly different
    entities. This will impact the quality of the recommendations we receive. If a
    person likes Ryan Reynolds' movies, it doesn't imply that they like movies by
    all Ryans.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在后续步骤中，我们将使用向量化器来构建文档向量。如果两个演员有相同的名字（比如Ryan Reynolds和Ryan Gosling），向量化器会将这两个Ryan视为相同的人，尽管它们显然是不同的个体。这会影响我们获得的推荐质量。如果一个人喜欢Ryan
    Reynolds的电影，并不意味着他也喜欢所有Ryan的电影。
- en: 'Therefore, the last step is to strip the spaces between keywords, and actor
    and director names, and convert them all into lowercase. Therefore, the two Ryans
    in the preceding example will become *ryangosling* and *ryanreynolds*, and our
    vectorizer will now be able to distinguish between them:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最后一步是去除关键词、演员和导演姓名之间的空格，并将它们全部转换为小写字母。因此，前面例子中的两个Ryan将变成*ryangosling*和*ryanreynolds*，我们的向量化器现在能够区分它们：
- en: '[PRE20]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Creating the metadata soup
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建元数据soup
- en: In the plot description-based recommender, we worked with a single *overview *feature,
    which was a body of text. Therefore, we were able to apply our vectorizer directly.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于剧情描述的推荐系统中，我们只处理了一个*overview*特性，这是一个文本体。因此，我们能够直接应用我们的向量化器。
- en: 'However, this is not the case with our metadata-based recommender. We have
    four features to work with, of which three are lists and one is a string. What
    we need to do is create a `soup`that contains the actors, director, keywords,
    and genres. This way, we can feed this soup into our vectorizer and perform similar
    follow-up steps to before:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在基于元数据的推荐系统中情况并非如此。我们有四个特性需要处理，其中三个是列表，一个是字符串。我们需要做的是创建一个包含演员、导演、关键词和类型的`soup`。这样，我们就可以将这个soup输入到我们的向量化器中，并执行类似之前的后续步骤：
- en: '[PRE21]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'With this function in hand, we create the `soup`feature:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个功能，我们创建了`soup`特性：
- en: '[PRE22]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let''s now take a look at one of the `soup`values. It should be a string containing
    words that represent genres, cast, and keywords:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一下其中一个 `soup` 值。它应该是一个包含表示电影类型、演员和关键词的字符串：
- en: '[PRE23]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: With the `soup`created, we are now in a good position to create our document
    vectors, compute similarity scores, and build the metadata-based recommender function.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 创建好 `soup` 后，我们现在处于一个良好的位置，可以创建文档向量、计算相似度得分，并构建基于元数据的推荐函数。
- en: Generating the recommendations
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成推荐
- en: The next steps are almost identical to the corresponding steps from the previous
    section.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤几乎与前一部分的相应步骤相同。
- en: Instead of using TF-IDFVectorizer, we will be using CountVectorizer. This is
    because using TF-IDFVectorizer will accord less weight to actors and directors
    who have acted and directed in a relatively larger number of movies.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 CountVectorizer，而不是 TF-IDFVectorizer。这是因为使用 TF-IDFVectorizer 会对在较多电影中担任演员和导演的人员赋予较低的权重。
- en: 'This is not desirable, as we do not want to penalize artists for directing
    or appearing in more movies:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这是不理想的，因为我们不希望因为艺术家参与或执导更多电影而给予惩罚：
- en: '[PRE24]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Unfortunately, using CountVectorizer means that we are forced to use the more
    computationally expensive `cosine_similarity`function to compute our scores:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，使用 CountVectorizer 意味着我们必须使用计算开销更大的 `cosine_similarity` 函数来计算相似度得分：
- en: '[PRE25]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Since we dropped a few movies with bad indices, we need to construct our reverse
    mapping again. Let''s do that as the next step:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们剔除了几个索引不良的电影，我们需要重新构建反向映射。让我们在下一步中完成这项工作：
- en: '[PRE26]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: With the new reverse mapping constructed and the similarity scores computed,
    we can reuse the `content_recommender`function defined in the previous section
    by passing in `cosine_sim2`as an argument. Let's now try out our new model by
    asking recommendations for the same movie, `The Lion King`*:*
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建好新的反向映射并计算出相似度得分后，我们可以通过传入 `cosine_sim2` 作为参数，重用上一部分定义的 `content_recommender`
    函数。现在，让我们通过请求同一部电影《狮子王》的推荐来测试我们的新模型：
- en: '[PRE27]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](img/5097b401-71d0-4e11-86f2-cd9e5613cd87.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5097b401-71d0-4e11-86f2-cd9e5613cd87.png)'
- en: The recommendations given in this case are vastly different to the ones that
    our plot description-based recommender gave. We see that it has been able to capture
    more information than just lions. Most of the movies in the list are animated
    and feature anthropomorphic characters.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 该案例给出的推荐与我们基于剧情描述的推荐系统提供的推荐截然不同。我们看到，它能够捕捉到比“狮子”更多的信息。列表中的大多数电影都是动画片，且包含拟人化角色。
- en: 'Personally, I found the *Pokemon: Arceus and the Jewel of Life *recommendation
    especially interesting. Both this movie and *The Lion King* feature cartoon anthropomorphic
    characters who return after a few years to exact revenge on those who had wronged
    them.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 就个人而言，我觉得 *《宝可梦：阿尔宙斯与生命之珠》* 的推荐尤其有趣。这部电影与 *《狮子王》* 都 featuring 动画拟人化角色，这些角色几年后回来报复那些曾经伤害过他们的人。
- en: Suggestions for improvements
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进建议
- en: 'The content-based recommenders we''ve built in this chapter are, of course,
    nowhere near the powerful models used in the industry. There is still plenty of
    scope for improvement. In this section, I will suggest a few ideas for upgrading
    the recommenders that you''ve already built:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 本章构建的基于内容的推荐系统，当然，远远不及行业中使用的强大模型。仍有许多提升空间。在这一部分，我将提出一些关于如何升级您已经构建的推荐系统的建议：
- en: '**Experiment with the number of keywords, genres, and cast**:In the model that
    we built, we considered at most three keywords, genres, and actors for our movies.
    This was, however, an arbitrary decision. It is a good idea to experiment with
    the number of these features in order to be considered for the metadata soup.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**尝试不同数量的关键词、类型和演员**：在我们构建的模型中，我们最多考虑了三个关键词、类型和演员。这是一个随意的决定。实验不同数量的这些特征，看看是否能有效地为元数据“汤”贡献更多信息。'
- en: '**Come up with more well-defined sub-genres**:Our model only considered the
    first three keywords that appeared in the keywords list. There was, however, no
    justification for doing so. In fact, it is entirely possible that certain keywords
    appeared in only one movie (thus rendering them useless). A much more potent technique
    would be to define, as with the genres, a definite number of sub-genres and assign
    only these sub-genres to the movies.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提出更多明确的子类型**：我们的模型只考虑了关键词列表中出现的前三个关键词。然而，这样做并没有充分的理由。事实上，某些关键词可能只出现在一部电影中（从而使它们变得无用）。一个更有效的技术是，像定义电影类型一样，定义一个明确的子类型数量，并只将这些子类型分配给电影。'
- en: '**Give more weight to the director**:Our model gave as much importance to the
    director as to the actors. However, you can argue that the character of a movie
    is determined more by the former. We can give more emphasis to the director by
    mentioning this individual multiple times in our soup instead of just once. Experiment
    with the number of repetitions of the director in the soup.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**给予导演更多的权重**：我们的模型给导演和演员同等的权重。然而，你可以认为，电影的特色更多是由导演决定的。我们可以通过在推荐模型中多次提到导演，而不仅仅是一次，来给导演更多的关注。可以尝试调整导演在推荐中的出现次数。'
- en: '**Consider other members of the crew**:The director isn''t the only person
    that gives the movie its character. You can also consider adding other crew members,
    such as producers and screenwriters, to your soup.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**考虑其他工作人员成员**：导演并不是唯一赋予电影其特色的人物。你也可以考虑加入其他工作人员成员，比如制作人和编剧，来丰富你的推荐模型。'
- en: '**Experiment with other metadata**:We only considered genres, keywords, and
    credits while building our metadata model. However, our dataset contains plenty
    of other features, such as production companies, countries, and languages. You
    may consider these data points, too, as they may be able to capture important
    information (such as if two movies are produced by *Pixar).*'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**尝试其他元数据**：在构建我们的元数据模型时，我们只考虑了类型、关键词和演员名单。然而，我们的数据集中还有很多其他特征，比如制作公司、国家和语言。你也可以考虑这些数据点，因为它们可能能够捕捉到重要的信息（比如两部电影是否由*皮克斯*制作）。'
- en: '**Introduce a popularity filter**:It is entirely possible that two movies have
    the same genres and sub-genres, but differ wildly in quality and popularity. In
    such cases, you may want to introduce a popularity filter that considers the *n *most
    similar movies, computes a weighted rating, and displays the top five results.
    You have already learned how to do this in the previous chapter.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**引入流行度过滤器**：有可能两部电影有相同的类型和子类型，但在质量和受欢迎程度上却相差甚远。在这种情况下，你可能希望引入一个流行度过滤器，考虑*n*最相似的电影，计算加权评分，并展示前五个结果。你已经在上一章学习了如何做到这一点。'
- en: Summary
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We have come a long way in this chapter. We first learned about document vectors
    and gained a brief introduction to the cosine similarity score. Next, we built
    a recommender that identified movies with similar plot descriptions. We then proceeded
    to build a more advanced model that leveraged the power of other metadata, such
    as genres, keywords, and credits. Finally, we discussed a few methods by which
    we could improve our existing system.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们已经走了很长一段路。我们首先学习了文档向量，并简要介绍了余弦相似度评分。接下来，我们构建了一个推荐系统，能够识别具有相似剧情描述的电影。然后，我们构建了一个更高级的模型，利用了其他元数据的力量，比如类型、关键词和演员名单。最后，我们讨论了几种可以改进现有系统的方法。
- en: 'With this, we formally come to an end of our tour of content-based recommendation
    system. In the next chapters, we will cover what is arguably the most popular
    recommendation model in the industry today: collaborative filtering.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们正式结束了基于内容的推荐系统的学习。在接下来的章节中，我们将讨论目前业界最流行的推荐模型之一：协同过滤。
