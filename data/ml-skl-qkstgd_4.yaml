- en: Predicting Categories with Naive Bayes and SVMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯和支持向量机预测类别
- en: 'In this chapter, you will learn about two popular classification machine learning
    algorithms: the Naive Bayes algorithm and the linear support vector machine. The
    Naive Bayes algorithm is a probabilistic model that predicts classes and categories,
    while the linear support vector machine uses a linear decision boundary to predict
    classes and categories.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习两种流行的分类机器学习算法：朴素贝叶斯算法和线性支持向量机。朴素贝叶斯算法是一个概率模型，用于预测类别和分类，而线性支持向量机则使用线性决策边界来预测类别和分类。
- en: 'In this chapter, you will learn about the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习以下内容：
- en: The theoretical concept behind the Naive Bayes algorithm, explained in mathematical
    terms
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释朴素贝叶斯算法背后的理论概念，使用数学术语
- en: Implementing the Naive Bayes algorithm by using scikit-learn
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 实现朴素贝叶斯算法
- en: How the linear support vector machine algorithm works under the hood
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性支持向量机算法的工作原理
- en: Graphically optimizing the hyperparameters of the linear support vector machines
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图形化优化线性支持向量机的超参数
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will be required to have Python 3.6 or greater, Pandas ≥ 0.23.4, Scikit-learn
    ≥ 0.20.0, and Matplotlib ≥ 3.0.0 installed on your system.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要在系统上安装 Python 3.6 或更高版本、Pandas ≥ 0.23.4、Scikit-learn ≥ 0.20.0 和 Matplotlib
    ≥ 3.0.0。
- en: 'The code files of this chapter can be found on GitHub:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在 GitHub 上找到：
- en: '[https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_04.ipynb](https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_04.ipynb)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_04.ipynb](https://github.com/PacktPublishing/Machine-Learning-with-scikit-learn-Quick-Start-Guide/blob/master/Chapter_04.ipynb)'
- en: 'Check out the following video to see the code in action:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，看看代码如何运行：
- en: '[http://bit.ly/2COBMUj](http://bit.ly/2COBMUj)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2COBMUj](http://bit.ly/2COBMUj)'
- en: The Naive Bayes algorithm
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朴素贝叶斯算法
- en: The Naive Bayes algorithm makes use of the Bayes theorem, in order to classify
    classes and categories. The word **naive** was given to the algorithm because
    the algorithm assumes that all attributes are independent of one another. This
    is not actually possible, as every attribute/feature in a dataset is related to
    another attribute, in one way or another.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯算法利用贝叶斯定理来进行分类。算法之所以被称为**朴素**，是因为它假设所有特征之间是相互独立的。但实际上这是不可能的，因为数据集中的每个属性/特征在某种程度上与其他属性相关。
- en: 'Despite being naive, the algorithm does well in actual practice. The formula
    for the Bayes theorem is as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管朴素贝叶斯算法是“朴素”的，但它在实际应用中表现良好。贝叶斯定理的公式如下：
- en: '![](img/1b16aa8f-172a-40bb-8fcd-29c05d95d1b4.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1b16aa8f-172a-40bb-8fcd-29c05d95d1b4.png)'
- en: Bayes theorem formula
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理公式
- en: 'We can split the preceding algorithm into the following components:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将前述算法分解为以下几个组成部分：
- en: '**p(h|D)**:This is the probability of a hypothesis taking place, provided that
    we have a dataset. An example of this would be the probability of a fraudulent
    transaction taking place, provided that we had a dataset that consisted of fraudulent
    and non-fraudulent transactions.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**p(h|D)**：这是在给定数据集的前提下，假设发生的概率。举个例子，这可以是一个欺诈交易发生的概率，前提是我们有一个包含欺诈和非欺诈交易的数据集。'
- en: '**p(D|h)**:This is the probability of having the data, given a hypothesis.
    An example of this would be the probability of having a dataset that contained
    fraudulent transactions.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**p(D|h)**：这是在假设的前提下，数据存在的概率。举个例子，这可以是拥有一个包含欺诈交易的数据集的概率。'
- en: '**p(h)**:This is the probability of a hypothesis taking place, in general.
    An example of this would be a statement that the average probability of fraudulent
    transactions taking place in the mobile industry is 2%.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**p(h)**：这是假设发生的概率。举个例子，这可以是一个声明，表示在移动行业中，欺诈交易发生的平均概率为 2%。'
- en: '**p(D)**:This is the probability of having the data before knowing any hypothesis.
    An example of this would be the probability that a dataset of mobile transactions
    could be found without knowing what we wanted to do with it (for example, predict
    fraudulent mobile transactions).'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**p(D)**：这是在不知道任何假设的情况下，数据存在的概率。举个例子，这可以是一个数据集存在的概率，而我们并不知道具体要做什么（例如，预测欺诈性移动交易）。'
- en: 'In the preceding formula, the *p(D)*can be rewritten in terms of *p(h)* and
    *p(D|h),*as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述公式中，*p(D)*可以用*p(h)*和*p(D|h)*来重新写为如下形式：
- en: '![](img/a6afb98e-348a-465e-9789-3cdf54bf90c7.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a6afb98e-348a-465e-9789-3cdf54bf90c7.png)'
- en: 'Let''s take a look at how we can implement this with the method of predicting
    classes, in the case of the mobile transaction example:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看如何在移动交易示例中使用预测类别的方法来实现这一点：
- en: '| **p(D&#124;h)** | **p(h)** | **p(D&#124;-h)** | **(1 - p(h))** |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| **p(D&#124;h)** | **p(h)** | **p(D&#124;-h)** | **(1 - p(h))** |'
- en: '| 0.8 | 0.08 | 0.02 | 0.92 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 0.8 | 0.08 | 0.02 | 0.92 |'
- en: Substituting the values in the preceding table into the Bayes theorem formula
    produces a result of 0.77\. This means that the classifier predicts that there
    is a 77% probability that a transaction will be predicted as fraudulent, using
    the data that was given previously.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 将上述表格中的值代入贝叶斯定理公式，得到结果为0.77。这意味着，使用之前给定的数据，分类器预测交易为欺诈的概率为77%。
- en: Implementing the Naive Bayes algorithm in scikit-learn
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在scikit-learn中实现朴素贝叶斯算法
- en: Now that you have learned how the Naive Bayes algorithm generates predictions,
    we will implement the same classifier using scikit-learn, in order to predict
    whether a particular transaction is fraudulent.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了朴素贝叶斯算法如何生成预测，我们将使用scikit-learn实现相同的分类器，以预测某一交易是否为欺诈。
- en: The first step is to import the data, create the feature and target arrays,
    and split the data into training and test sets.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步骤是导入数据，创建特征数组和目标数组，并将数据划分为训练集和测试集。
- en: 'We can do this by using the following code:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码来实现：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The next step is to build the Naive Bayes classifier. We can do this by using
    the following code:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是构建朴素贝叶斯分类器。我们可以使用以下代码来实现：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the preceding code, the following applies:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，以下内容适用：
- en: First, we import the `GaussianNB`module from scikit-learn
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们从scikit-learn导入`GaussianNB`模块
- en: Next, we initialize a Naive Bayes classifier and store it in the variable `nb_classifier`
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们初始化一个朴素贝叶斯分类器，并将其存储在变量`nb_classifier`中
- en: Then, we fit the classifier to the training data and evaluate its accuracy on
    the test data
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将分类器拟合到训练数据，并在测试数据上评估其准确性。
- en: 'The Naive Bayes classifier has only one hyperparameter, which is the prior
    probability of the hypothesis, *p(h)***.** However, keep the following in mind:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器只有一个超参数，即假设的先验概率，*p(h)*。**然而，请牢记以下几点：
- en: The prior probability will not be available to us in most problems
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大多数问题中，先验概率是不可用的。
- en: Even if it is, the value is usually fixed as a statistical fact, and therefore,
    hyperparameter optimization is not performed
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使如此，通常会将值固定为一个统计事实，因此不会进行超参数优化。
- en: Support vector machines
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量机
- en: 'In this section, you will learn about **support vector machines (SVMs),** or,
    to be more specific, **linear support vector machines**. In order to understand
    support vector machines, you will need to know what support vectors are. They
    are illustrated for you in the following diagram:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习**支持向量机（SVMs）**，或者更具体地说，**线性支持向量机**。为了理解支持向量机，您需要知道什么是支持向量。它们在下图中得到了说明：
- en: '![](img/0a99c06e-4d59-437e-8c66-e6c83ccbe883.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0a99c06e-4d59-437e-8c66-e6c83ccbe883.png)'
- en: The concept of support vectors
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量的概念
- en: 'In the preceding diagram, the following applies:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述图表中，以下内容适用：
- en: The linear support vector machine is a form of linear classifier. A linear decision
    tree boundary is constructed, and the observations on one side of the boundary
    (the circles) belong to one class, while the observations on the other side of
    the boundary (the squares) belong to another class.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性支持向量机是一种线性分类器。构建一个线性决策边界，边界一侧的观测点（圆形）属于一个类别，而另一侧的观测点（方形）属于另一个类别。
- en: The support vectors are the observations that have a triangle on them.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量是那些上面有三角形标记的观测点。
- en: These are the observations that are either very close to the linear decision
    boundary or have been incorrectly classified.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些是非常接近线性决策边界的观测点，或者被错误分类的观测点。
- en: We can define which observations we want to make support vectors by defining
    how close to the decision boundary they should be.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以通过定义观测点距离决策边界的接近程度，来确定哪些观测点将成为支持向量。
- en: This is controlled by the hyperparameter known as the **inverse regularization
    strength****.**
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这一点由名为**逆正则化强度**的超参数控制。**
- en: 'In order to understand how the linear support vector machines work, consider
    the following diagram:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解线性支持向量机的工作原理，请考虑以下图示：
- en: '![](img/5bbc50eb-d97f-40c3-9b0a-a27f872768ff.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5bbc50eb-d97f-40c3-9b0a-a27f872768ff.png)'
- en: Concept of max-margins
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最大边距的概念
- en: 'In the preceding diagram, the following applies:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图示中，适用以下内容：
- en: The line between the support vectors and the linear decision boundary is known
    as the **margin**
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量和线性决策边界之间的线称为**边距**。
- en: The goal of the support vector machines is to maximize this margin, so that
    a new data point will be correctly classified
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机的目标是最大化这个边界，以便正确地分类一个新的数据点。
- en: A low value of inverse regularization strength ensures that this margin is as
    big as possible
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逆正则化强度的低值确保该边界尽可能大。
- en: Implementing the linear support vector machine algorithm in scikit-learn
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在scikit-learn中实现线性支持向量机算法
- en: 'In this section, you will learn how to implement the linear support vector
    machines in scikit-learn. The first step is to import the data and split it into
    training and testing sets. We can do this by using the following code:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习如何在scikit-learn中实现线性支持向量机。第一步是导入数据并将其拆分为训练集和测试集。我们可以通过以下代码实现：
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The next step is to build the linear support vector machine classifier. We
    can do this by using the following code:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是构建线性支持向量机分类器。我们可以通过以下代码实现：
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the preceding code, the following applies:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，适用以下内容：
- en: First, we import the `LinearSVC`module from scikit-learn
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们从scikit-learn导入`LinearSVC`模块。
- en: Next, we initialize a linear support vector machine object with a random state
    of 50, so that the model produces the same result every time
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们初始化一个线性支持向量机对象，设置随机状态为50，这样模型每次都会生成相同的结果。
- en: Finally, we fit the model to the training data and evaluate its accuracy on
    the test data
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将模型拟合到训练数据，并评估其在测试数据上的准确度。
- en: Now that we have built the model, we can find and optimize the most ideal value
    for the hyperparameters.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建了模型，可以找到并优化超参数的最理想值。
- en: Hyperparameter optimization for the linear SVMs
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性支持向量机的超参数优化
- en: 'In this section, you will learn how to optimize the hyperparameters for the
    linear support vector machines. In particular, there is one hyperparameter of
    interest: the **inverse regularization strength**.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习如何优化线性支持向量机的超参数。特别地，有一个超参数值得关注：**逆正则化强度**。
- en: We will explore how to optimize this hyperparameter, both graphically and algorithmically.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探索如何通过图形化和算法两种方式来优化这个超参数。
- en: Graphical hyperparameter optimization
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图形化超参数优化
- en: 'In order to optimize the inverse regularization strength, we will plot the
    accuracy scores for the training and testing sets, using the following code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化逆正则化强度，我们将绘制训练集和测试集的准确度得分，使用以下代码：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the preceding code, the following applies:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，适用以下内容：
- en: First, we initialize two empty lists, in order to store the accuracy scores
    for both the training and testing datasets
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们初始化两个空列表，用于存储训练集和测试集的准确度得分。
- en: The next step is to create a list of values of the hyperparameter, which, in
    this case, is the inverse regularization strength
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是创建超参数的值列表，在本例中，超参数是逆正则化强度。
- en: We then loop over each value in the hyperparameter list and build a linear support
    vector machine classifier with each inverse regularization strength value
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们遍历超参数列表中的每个值，使用每个逆正则化强度值构建线性支持向量机分类器。
- en: The accuracy scores for the training and testing datasets are then appended
    to the empty lists
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，训练集和测试集的准确度得分将被追加到空列表中。
- en: Using `matplotlib`, we then create a plot between the inverse regularization
    strength (along the *x* axis) and the accuracy scores for both the training and
    test sets (along the *y* axis)
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`matplotlib`，我们将逆正则化强度（沿*X*轴）与训练集和测试集的准确度得分（沿*Y*轴）绘制成图。
- en: 'This will produce a plot as shown in the following diagram:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成如下图所示的图表：
- en: '![](img/f919f6a8-5f0d-4d0d-87f2-6bc652d2ca54.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f919f6a8-5f0d-4d0d-87f2-6bc652d2ca54.png)'
- en: Graphical hyperparameter optimization
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图形化超参数优化
- en: 'In the preceding diagram, the following applies:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图示中，适用以下内容：
- en: We can observe that the accuracy score is highest for the training and testing
    sets for an inverse regularization strength of 10^(-2)
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以观察到，对于逆正则化强度为10^(-2)时，训练集和测试集的准确度得分最高。
- en: It is important to pick a value that has a high value of accuracy for both the
    training and testing sets, and not just either one of the datasets
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重要的是选择一个在训练集和测试集上都具有较高准确度的值，而不仅仅是其中一个数据集
- en: This will help you to prevent both overfitting and underfitting
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这将帮助你避免过拟合和欠拟合
- en: Hyperparameter optimization using GridSearchCV
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 `GridSearchCV` 进行超参数优化
- en: 'In this section, you will learn how to optimize the inverse regularization
    strength using the `GridSearchCV` algorithm. We can do this using the following
    code:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何使用 `GridSearchCV` 算法优化反正则化强度。我们可以使用以下代码来完成这一操作：
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the preceding code, the following applies:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，以下内容适用：
- en: First, we import the `GridSearchCV`module from scikit-learn
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们从 scikit-learn 导入 `GridSearchCV` 模块
- en: The next step is to initialize a linear support vector machine model with a
    random state of 50, in order to ensure that we obtain the same results every time
    we build the model
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是初始化一个线性支持向量机模型，随机状态设为 50，以确保每次构建模型时得到相同的结果
- en: We then initialize a grid of possible hyperparameter values for the inverse
    regularization strength
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接着初始化一个可能的超参数值网格，用于反正则化强度
- en: Finally, we fit the grid of hyperparameter values to the training set, so that
    we can build multiple linear SVM models with the different values of the inverse
    regularization strength
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将超参数值网格拟合到训练集上，从而构建多个线性 SVM 模型，使用不同的反正则化强度值
- en: The `GridSearchCV` algorithm then evaluates the model that produces the fewest
    generalization errors and returns the optimal value of the hyperparameter
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`GridSearchCV` 算法接着评估模型，选择产生最少泛化误差的模型，并返回超参数的最优值'
- en: It's a good practice to compare and contrast the results of the graphical method
    of hyperparameter optimization with that of `GridSearchCV`, in order to validate
    your results.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 将超参数优化的图形方法结果与 `GridSearchCV` 的结果进行比较是一个好习惯，这样可以验证你的结果。
- en: Scaling the data for performance improvement
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缩放数据以提高性能
- en: 'In this section, you will learn about how scaling and standardizing the data
    can lead to an improvement in the overall performance of the linear support vector
    machines. The concept of scaling remains the same as in the case of the previous
    chapters, and it will not be discussed here. In order to scale the data, we use
    the following code:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何通过缩放和标准化数据来提高线性支持向量机的整体性能。缩放的概念与前几章相同，这里不会再讨论。为了缩放数据，我们使用以下代码：
- en: '[PRE6]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the preceding code, the following applies:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，以下内容适用：
- en: First, we import the `StandardScaler` the `Pipeline`modules from scikit-learn,
    in order to build a scaling pipeline
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们从 scikit-learn 导入 `StandardScaler` 和 `Pipeline` 模块，以便构建一个缩放管道
- en: We then set up the order of the pipeline, which specifies that we use the `StandardScaler()`function
    first, in order to scale the data and build the linear support vector machine
    on that scaled data
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接着设置管道的顺序，指定首先使用 `StandardScaler()` 函数来缩放数据，并在该缩放数据上构建线性支持向量机
- en: The `Pipeline()`function is applied to the order of the pipeline which sets
    up the pipeline
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Pipeline()` 函数用于设置管道的顺序，建立管道'
- en: We then fit this pipeline to the training data and extract the scaled accuracy
    scores from the test data
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们将这个管道拟合到训练数据上，并从测试数据中提取缩放后的准确度得分
- en: Summary
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'This chapter introduced you to two fundamental supervised machine learning
    algorithms: the Naive Bayes algorithm and linear support vector machines. More
    specifically, you learned about the following topics:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向你介绍了两种基本的监督式机器学习算法：朴素贝叶斯算法和线性支持向量机。更具体地说，你学习了以下内容：
- en: How the Bayes theorem is used to produce a probability, to indicate whether
    a data point belongs to a particular class or category
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯定理如何用于生成概率，以指示数据点是否属于某个特定类别或类别
- en: Implementing the Naive Bayes classifier in scikit-learn
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 scikit-learn 中实现朴素贝叶斯分类器
- en: How the linear support vector machines work under the hood
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性支持向量机的工作原理
- en: Implementing the linear support vector machines in scikit-learn
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 scikit-learn 中实现线性支持向量机
- en: Optimizing the inverse regularization strength, both graphically and by using
    the `GridSearchCV` algorithm
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图形方法和 `GridSearchCV` 算法优化反正则化强度
- en: How to scale your data for a potential improvement in performance
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何缩放数据以潜在地提高性能
- en: 'In the next chapter, you will learn about the other type of supervised machine
    learning algorithm, which is used to predict numeric values, rather than classes
    and categories: linear regression!'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习另一种有监督的机器学习算法，它用于预测数值，而不是类别和分类：线性回归！
