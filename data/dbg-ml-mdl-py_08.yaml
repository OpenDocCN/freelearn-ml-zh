- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Controlling Risks Using Test-Driven Development
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用测试驱动开发控制风险
- en: There are risks, such as selecting unreliable models, associated with creating
    models and technologies built on top of our models. The question is, could we
    avoid them and better manage the risks associated with machine learning modeling?
    In this chapter, we will talk about programming strategies such as unit testing,
    which could help us not only in developing and selecting better models but also
    in reducing risks associated with modeling.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 与创建基于我们模型的模型和技术相关的风险，例如选择不可靠的模型，是存在的。问题是，我们能否避免这些风险并更好地管理与机器学习建模相关的风险？在本章中，我们将讨论编程策略，如单元测试，这些策略不仅可以帮助我们开发和选择更好的模型，还可以降低建模相关的风险。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Test-driven development
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 驱动式开发
- en: Machine learning differential testing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习差异测试
- en: Tracking machine learning experiments
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪机器学习实验
- en: By the end of this chapter, you will have learned how to reduce the risk of
    unreliable modeling and software development using unit and differential testing
    and how to reliably build upon previous attempts in model training and evaluation
    using machine learning experiment tracking.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将学会如何通过单元测试和差异测试来降低不可靠建模和软件开发的风险，以及如何使用机器学习实验跟踪可靠地构建模型训练和评估的先前尝试。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following requirements should be considered for this chapter as they will
    help you better understand the concepts, use them in your projects, and practice
    with the provided code:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，以下要求应予以考虑，因为它们将帮助您更好地理解概念，在您的项目中使用它们，并使用提供的代码进行实践：
- en: 'Python library requirements:'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python库要求：
- en: '`pytest` >= 7.2.2'
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pytest` >= 7.2.2'
- en: '`ipytest` >= 0.13.0'
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ipytest` >= 0.13.0'
- en: '`mlflow` >= 2.1.1'
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlflow` >= 2.1.1'
- en: '`aif360` >= 0.5.0'
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aif360` >= 0.5.0'
- en: '`shap` >= 0.41.0'
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shap` >= 0.41.0'
- en: '`sklearn` >= 1.2.2'
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn` >= 1.2.2'
- en: '`numpy` >= 1.22.4'
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy` >= 1.22.4'
- en: '`pandas` >= 1.4.4'
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas` >= 1.4.4'
- en: You will also require basic knowledge of model bias and the definition of bias
    measures such as the **disparate impact** **ratio** (**DIR**)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您还需要了解模型偏差和偏差度量定义的基本知识，例如**差异影响** **比率**（**DIR**）
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter08](https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter08).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在GitHub上找到本章的代码文件，网址为[https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter08](https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter08)。
- en: Test-driven development for machine learning modeling
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 驱动式开发用于机器学习建模
- en: One approach to reducing the risks of developing unreliable models and pushing
    them to production is test-driven development. We aim to design unit tests (that
    is, tests designed to test individual components of software) that reduce the
    risks of code revision either within the same or in different life cycles. To
    better understand this concept, we need to understand what unit tests are and
    how we can design and use them in Python.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 减少开发不可靠模型并将其推送到生产的风险的一种方法是通过测试驱动开发。我们的目标是设计单元测试（即设计用于测试软件单个组件的测试），以降低代码修订在同一或不同生命周期中的风险。为了更好地理解这个概念，我们需要了解单元测试是什么，以及我们如何在Python中设计和使用它们。
- en: Unit testing
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单元测试
- en: Unit tests are designed to test the smallest components, or units, in the code
    and software we design. In machine learning modeling, we might have many modules
    taking care of different steps of a machine learning life cycle, such as data
    curation and wrangling or model evaluation. Unit tests help us avoid errors and
    mistakes, and design our code without the need to worry about whether we made
    a mistake that will not be detected early on. Detecting issues in our code early
    has lower costs and helps us to avoid error pile-ups, which makes the debugging
    process easier. Pytest is a Python testing framework that helps us in designing
    different tests, including unit tests, in machine learning programming.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 单元测试旨在测试我们设计和编写的代码和软件中最小的组件或单元。在机器学习建模中，我们可能有多个模块负责机器学习生命周期的不同步骤，例如数据整理和清洗或模型评估。单元测试帮助我们避免错误和失误，并在编写代码时无需担心是否犯了不会被早期发现的错误。早期发现代码中的问题成本较低，并有助于我们避免错误累积，从而使调试过程更加容易。Pytest是一个Python测试框架，它帮助我们设计不同的测试，包括单元测试，在机器学习编程中使用。
- en: Using Pytest
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Pytest
- en: 'Pytest is a simple-to-use Python library that we can use to design unit tests
    by performing the following steps:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Pytest 是一个易于使用的 Python 库，我们可以通过以下步骤来设计单元测试：
- en: Identify the component we want to design the unit test for.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定我们想要为哪个组件设计单元测试。
- en: Define a small operation to be used for testing that component. For example,
    if the module is part of data processing, the test can be designed using a very
    small toy dataset, either real or synthetic.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个小操作来用于测试该组件。例如，如果该模块是数据处理的一部分，测试可以设计使用一个非常小的玩具数据集，无论是真实的还是合成的。
- en: Design a function starting with `"test_"` for the corresponding component.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为相应的组件设计一个以 `"test_"` 开头的函数。
- en: Repeat *Steps 1* to *3* for all the components of the code for which we want
    to design unit tests. It is better to cover as many components as possible.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们想要设计单元测试的所有代码组件，重复 *步骤 1* 到 *3*。最好尽可能覆盖更多组件。
- en: 'The designed tests can then be used to test changes in your code. We will practice
    unit test design here, using Pytest, for a function that calculates the DIR and
    returns “unbiased data” or “biased data” using the input thresholds for DIR for
    bias detection:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 设计的测试可以用来测试代码中的更改。我们将在这里使用 Pytest 实践单元测试设计，针对一个计算 DIR 并使用 DIR 的输入阈值进行偏差检测以返回“无偏数据”或“有偏数据”的函数：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now that we’ve defined an example usage of this function to use for our unit
    test design, we can select the first 100 rows of the dataset and calculate the
    DIR:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了这个函数的示例用法，用于我们的单元测试设计，我们可以选择数据集的前 100 行并计算 DIR：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'According to the calculated DIR, this subset of the data is biased concerning
    the `''Sex''` attribute. To design the unit tests, we need to import the `pytest`
    library. But if you are using Jupyter or Colab notebooks for prototyping, you
    can use `ipytest` to test your code:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 根据计算出的 DIR，这个数据子集在 `'Sex'` 属性方面是有偏的。为了设计单元测试，我们需要导入 `pytest` 库。但如果你使用 Jupyter
    或 Colab 笔记本进行原型设计，你可以使用 `ipytest` 来测试你的代码：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We must add `%%ipytest -qq` if we’re using `pytest` in a Jupyter or Colab notebook
    and want to run the tests using `ipytest`. Then, we can define our unit test function,
    `test_dir_grouping()`, as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在 Jupyter 或 Colab Notebook 中使用 `pytest` 并想使用 `ipytest` 运行测试，我们必须添加 `%%ipytest
    -qq`。然后，我们可以定义我们的单元测试函数，`test_dir_grouping()`，如下所示：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `assert` command checks whether the result of the `dir_grouping()` function
    is “biased data,” as it is supposed to be according to our previous analysis,
    for the first 100 rows of the dataset. If the result is different, then the test
    fails.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`assert` 命令检查 `dir_grouping()` 函数的结果是否为“有偏数据”，正如我们之前的分析所预期的那样，对于数据集的前 100 行。如果结果不同，则测试失败。'
- en: 'When you have all the unit tests ready for the components of your software,
    you can run `pytest` in the `test_dir_grouping`, as shown in the preceding code,
    within a Python script called `test_script.py`, you can only test that script
    as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当你为软件组件准备好所有单元测试时，你可以在 `test_dir_grouping` 中运行 `pytest`，如前面的代码所示，在名为 `test_script.py`
    的 Python 脚本中，你只能测试该脚本，如下所示：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Alternatively, you can run `pytest` in a specific directory. If you have a
    code base that contains many different modules, you can organize your tests according
    to the grouping of your main functions and classes and then test each directory,
    as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以在特定目录中运行 `pytest`。如果你有一个包含许多不同模块的代码库，你可以根据你的主要函数和类的分组来组织你的测试，然后测试每个目录，如下所示：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Instead, if you simply run `pytest`, it will execute all the tests in all the
    files named `test_*.py` or `\*_test.py` in the current directory and its subdirectories:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，如果你简单地运行 `pytest`，它将在当前目录及其子目录中执行所有名为 `test_*.py` 或 `\*_test.py` 的文件中的所有测试：
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can also use a Python interpreter to execute the tests using `pytest`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用 Python 解释器通过 `pytest` 执行测试：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you are using Jupyter or Colab Notebook and used `ipytest`, you can run
    Pytest as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用 Jupyter 或 Colab Notebook 并且使用了 `ipytest`，你可以按照以下方式运行 Pytest：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, imagine we execute the designed `test_dir_grouping()` function in one
    of these ways. When the test is passed, we will see a message like the following,
    which tells us 100% of the tests passed. This is because we are only testing one
    test and the test passed (*Figure 8**.1*):'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们以这种方式执行设计的 `test_dir_grouping()` 函数。当测试通过时，我们将看到如下消息，它告诉我们 100% 的测试通过了。这是因为我们只测试了一个测试，并且测试通过了（*图
    8**.1*）：
- en: '![Figure 8.1 – The output of Pytest when the designed test passed](img/B16369_08_01.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.1 – 当设计的测试通过时 Pytest 的输出](img/B16369_08_01.jpg)'
- en: Figure 8.1 – The output of Pytest when the designed test passed
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 当设计的测试通过时Pytest的输出
- en: 'If we mistakenly change `assessment = "biased data"` to `assessment = "unbiased
    data"` in the `dir_grouping()` function, we get the following result instead,
    which tells us 100% of the tests failed. This is because we only have one test,
    which failed in this case (*Figure 8**.2*):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在`dir_grouping()`函数中错误地将`assessment = "biased data"`改为`assessment = "unbiased
    data"`，我们会得到以下结果，这告诉我们100%的测试失败了。这是因为我们只有一个测试，在这种情况下失败了（*图8**.2*）：
- en: '![Figure 8.2 – Failure message after running Pytest](img/B16369_08_02.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图8.2 – 运行Pytest后的失败信息](img/B16369_08_02.jpg)'
- en: Figure 8.2 – Failure message after running Pytest
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 运行Pytest后的失败信息
- en: The failure message in `pytest` contains some complementary information that
    we can use to debug our code. In this case, it is telling us that in `test_dir_grouping()`,
    it tried to assert the output of `test_dir_grouping()`, which was “unbiased data,”
    with “biased data.”
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest`中的失败信息包含一些补充信息，我们可以使用这些信息来调试我们的代码。在这种情况下，它告诉我们，在`test_dir_grouping()`中，它试图断言`test_dir_grouping()`的输出，即“unbiased
    data”，与“biased data”。'
- en: Pytest fixtures
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Pytest夹具
- en: 'When programming for data analysis and machine learning modeling, we need to
    use data that is in different variables or data objects, comes from a file in
    our local machine or the cloud, is queried from a database, or comes from a URL
    in our tests. Fixtures help us in these processes by removing the need to repeat
    the same code across our tests. Attaching a fixture function to a test will run
    it and return data to the test before each test runs. Here, we have used examples
    provided on the Pytest documentation page for fixtures (source: [https://docs.pytest.org/en/7.1.x/how-to/fixtures.html](https://docs.pytest.org/en/7.1.x/how-to/fixtures.html)).
    First, let’s define two very simple classes called `Fruit` and `FruitSalad`:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们为数据分析和学习建模编程时，我们需要使用来自不同变量或数据对象的数据，这些数据可能来自我们本地机器或云中的文件，是从数据库中查询的，或者来自测试中的URL。夹具通过消除在测试中重复相同代码的需要来帮助我们完成这些过程。将夹具函数附加到测试上将在每个测试运行之前运行它，并将数据返回给测试。在这里，我们使用了Pytest文档页面上提供的夹具示例（来源：[https://docs.pytest.org/en/7.1.x/how-to/fixtures.html](https://docs.pytest.org/en/7.1.x/how-to/fixtures.html)）。首先，让我们定义两个非常简单的类，称为`Fruit`和`FruitSalad`：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'When we use `pytest`, it looks at the parameters in the test function signature
    and looks for fixtures with the same names as those parameters. Pytest then runs
    those fixtures, captures what they return, and passes those objects as arguments
    to the test function. We inform Pytest that a function is a fixture by decorating
    it with `@pytest.fixture`. In the following example, when we run the tests, `test_fruit_salad`
    requests `fruit_bowl`, and Pytest executes `fruit_bowl` and passes the returned
    object into `test_fruit_salad`:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用`pytest`时，它会查看测试函数签名中的参数，并寻找与这些参数具有相同名称的夹具。Pytest然后运行这些夹具，捕获它们返回的内容，并将这些对象作为参数传递给测试函数。我们通过使用`@pytest.fixture`装饰器来通知Pytest一个函数是夹具。在以下示例中，当我们运行测试时，`test_fruit_salad`请求`fruit_bowl`，Pytest执行`fruit_bowl`并将返回的对象传递给`test_fruit_salad`：
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here are some of the features of fixtures that can help us in designing our
    tests:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些夹具的特性，可以帮助我们设计测试：
- en: Fixtures can request other fixtures. This helps us in designing smaller fixtures
    that can be even used as part of other fixtures to make more complex tests.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 夹具可以请求其他夹具。这有助于我们设计更小的夹具，甚至可以将它们作为其他夹具的一部分来构建更复杂的测试。
- en: Fixtures can be reused in different tests. They work like functions to be used
    in different tests with their own returned results.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 夹具可以在不同的测试中重复使用。它们就像函数一样，在不同的测试中使用，并返回它们自己的结果。
- en: A test or fixture can request more than one fixture at a time.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个测试或夹具可以同时请求多个夹具。
- en: Fixtures can be requested more than once per test.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 夹具可以在每个测试中请求多次。
- en: In test-driven development, we aim to write production-ready code that passes
    the designed unit tests. Higher coverage of the modules and components in your
    code by the designed unit test could help you in revising your code that’s related
    to any component of a machine learning life cycle with peace of mind.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试驱动开发中，我们的目标是编写生产就绪的代码，这些代码能够通过设计的单元测试。通过设计的单元测试对代码中的模块和组件进行更高覆盖，可以帮助你在安心的情况下修订与机器学习生命周期任何组件相关的代码。
- en: In this section, you learned about unit testing, but other techniques can help
    us in reliable programming and machine learning model development, such as differential
    testing. We will introduce this next.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你学习了单元测试，但其他技术可以帮助我们在可靠的编程和机器学习模型开发中，例如差异测试。我们将在下一节介绍这一内容。
- en: Machine learning differential testing
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习差异测试
- en: 'Differential testing attempts to check two versions of a piece of software,
    considered as base and test versions, on the same input and then compare the outputs.
    This process helps us identify whether the outputs are the same and identify unexpected
    differences (Gulzar et al., 2019; *Figure 8**.3*):'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 差异测试试图检查同一软件的两个版本，视为基准版本和测试版本，在相同的输入上进行比较，然后比较输出。这个过程帮助我们确定输出是否相同，并识别意外的差异（Gulzar等人，2019年；*图8**.3*）：
- en: '![Figure 8.3 – Simplified flowchart of differential testing as a process to
    test the outputs of two implementations of the same process on the same data](img/B16369_08_03.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图8.3 – 差异测试的简化流程图，作为测试同一数据上同一过程两个实现输出的过程](img/B16369_08_03.jpg)'
- en: Figure 8.3 – Simplified flowchart of differential testing as a process to test
    the outputs of two implementations of the same process on the same data
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 – 差异测试的简化流程图，作为测试同一数据上同一过程两个实现输出的过程
- en: In differential testing, the base version is already verified and considered
    the approved version, while the test version needs to be checked in comparison
    with the base version in producing the correct output. In differential testing,
    we can also aim to assess whether the observed differences between the outputs
    of the base and test versions are expected or can be explained.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在差异测试中，基准版本已经过验证，并被认为是批准版本，而测试版本需要与基准版本进行比较，以产生正确的输出。在差异测试中，我们还可以旨在评估基准版本和测试版本输出之间的观察到的差异是否是预期的或可以解释的。
- en: 'In machine learning modeling, we can also benefit from differential testing
    when comparing two different implementations of the same algorithms on the same
    data. For example, we can use it to compare models built using `scikit-learn`
    and Spark `MLlib` as two different libraries for machine learning modeling. If
    we need to recreate a model using `scikit-learn` and add it to our pipeline while
    the original model is built in Spark `MLlib`, we can use differential testing
    to assess the outputs and make sure either there is no difference or the differences
    are expected (Herbold and Tunkel, 2023). *Table 8.1* provides some examples of
    algorithms with available classes in both `scikit-learn` and Spark `MLlib`. This
    approach has been used more extensively to compare models between different deep
    learning frameworks, such as TensorFlow and PyTorch:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习建模中，我们还可以在比较同一数据上同一算法的两个不同实现时从差异测试中受益。例如，我们可以用它来比较使用`scikit-learn`和Spark
    `MLlib`构建的模型，作为机器学习建模的两个不同库。如果我们需要使用`scikit-learn`重新创建一个模型并将其添加到我们的管道中，而原始模型是在Spark
    `MLlib`中构建的，我们可以使用差异测试来评估输出并确保没有差异或差异是预期的（Herbold和Tunkel，2023年）。*表8.1*提供了`scikit-learn`和Spark
    `MLlib`中可用类的一些算法示例。这种方法已被更广泛地用于比较不同深度学习框架之间的模型，例如TensorFlow和PyTorch：
- en: '| **Method** | **scikit-learn** | **Spark MLlib** |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| **方法** | **scikit-learn** | **Spark MLlib** |'
- en: '| Logistic regression | `LogisticRegression` | `LogisticRegression` |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 逻辑回归 | `LogisticRegression` | `LogisticRegression` |'
- en: '| Naive Bayes | `GaussianNB, MultinomialNB` | `NaiveBayes` |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 朴素贝叶斯 | `GaussianNB, MultinomialNB` | `NaiveBayes` |'
- en: '| Decision tree | `DecisionTree Classifier` | `DecisionTreeClassifier` |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 决策树 | `DecisionTree Classifier` | `DecisionTreeClassifier` |'
- en: '| Random forest | `RandomForest Classifier` | `RandomForestClassifier` |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 随机森林 | `RandomForest Classifier` | `RandomForestClassifier` |'
- en: '| Support vector machine | `LinearSVC` | `LinearSVC` |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 支持向量机 | `LinearSVC` | `LinearSVC` |'
- en: '| Multilayer perceptron | `MLPClassifier` | `MultilayerPerceptron Classifier`
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 多层感知器 | `MLPClassifier` | `MultilayerPerceptron Classifier` |'
- en: '| Gradient boosting | `GradientBoosting Classifier` | `GBTClassifier` |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 梯度提升 | `GradientBoosting Classifier` | `GBTClassifier` |'
- en: Table 8.1 – Some of the overlapping algorithms and their class names in scikit-learn
    and Spark MLlib
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.1 – scikit-learn和Spark MLlib中一些重叠的算法及其类名
- en: Experiment tracking is another technique that we can benefit from besides unit
    and differential testing in our machine learning projects.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 除了单元测试和差异测试之外，实验跟踪是我们可以在机器学习项目中受益的另一种技术。
- en: Tracking machine learning experiments
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪机器学习实验
- en: 'Keeping track of our machine learning experiments will help us reduce the risks
    of invalid conclusions and selecting unreliable models. Experiment tracking in
    machine learning is about saving the information about the experiments – for instance,
    the data that has been used – the testing performance and the metric used for
    performance assessment, and the algorithms and the hyperparameters used for modeling.
    Here are some of the important considerations for using a machine learning experiment
    tracking tool:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪我们的机器学习实验将帮助我们减少得出无效结论和选择不可靠模型的风险。机器学习中的实验跟踪是关于保存实验信息——例如，使用的数据——测试性能和用于性能评估的指标，以及用于建模的算法和超参数。以下是使用机器学习实验跟踪工具的一些重要考虑因素：
- en: Can you integrate the tool with your **continuous integration/continuous development**
    (**CI/CD**) pipeline and machine learning modeling frameworks?
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能否将工具集成到你的 **持续集成/持续部署**（**CI/CD**）管道和机器学习建模框架中？
- en: Can you reproduce your experiments?
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能重现你的实验吗？
- en: Can you easily search through the experiments to find the best models or models
    with bad or unexpected behaviors?
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能否轻松地搜索实验以找到最佳模型或具有不良或意外行为的模型？
- en: Does it cause any security or privacy issues?
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是否会引起任何安全或隐私问题？
- en: Does the tool help you better collaborate in your machine learning projects?
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具是否帮助你更好地在机器学习项目中协作？
- en: Does the tool let you track hardware (for example, memory) consumption?
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具是否允许你跟踪硬件（例如，内存）消耗？
- en: 'Some of the commonly used machine learning experiment tracking tools and their
    URLs are provided in *Table 8.2*:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*表8.2* 中提供了常用的机器学习实验跟踪工具及其URL：'
- en: '| **Tool** | **URL** |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| **工具** | **URL** |'
- en: '| MLflow Tracking | [https://mlflow.org/docs/latest/tracking.html](https://mlflow.org/docs/latest/tracking.html)
    |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| MLflow Tracking | [https://mlflow.org/docs/latest/tracking.html](https://mlflow.org/docs/latest/tracking.html)
    |'
- en: '| DVC | [https://dvc.org/doc/use-cases/experiment-tracking](https://dvc.org/doc/use-cases/experiment-tracking)
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| DVC | [https://dvc.org/doc/use-cases/experiment-tracking](https://dvc.org/doc/use-cases/experiment-tracking)
    |'
- en: '| Weights & Biases | [https://wandb.ai/site/experiment-tracking](https://wandb.ai/site/experiment-tracking)
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| Weights & Biases | [https://wandb.ai/site/experiment-tracking](https://wandb.ai/site/experiment-tracking)
    |'
- en: '| Comet ML | [https://www.comet.com/site/products/ml-experiment-tracking/](https://www.comet.com/site/products/ml-experiment-tracking/)
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| Comet ML | [https://www.comet.com/site/products/ml-experiment-tracking/](https://www.comet.com/site/products/ml-experiment-tracking/)
    |'
- en: '| ClearML | [https://clear.ml/clearml-experiment/](https://clear.ml/clearml-experiment/)
    |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| ClearML | [https://clear.ml/clearml-experiment/](https://clear.ml/clearml-experiment/)
    |'
- en: '| Polyaxon | [https://polyaxon.com/product/#tracking](https://polyaxon.com/product/#tracking)
    |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| Polyaxon | [https://polyaxon.com/product/#tracking](https://polyaxon.com/product/#tracking)
    |'
- en: '| TensorBoard | [https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard)
    |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| TensorBoard | [https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard)
    |'
- en: '| Neptune AI | [https://neptune.ai/product/experiment-tracking](https://neptune.ai/product/experiment-tracking)
    |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| Neptune AI | [https://neptune.ai/product/experiment-tracking](https://neptune.ai/product/experiment-tracking)
    |'
- en: '| SageMaker | [https://aws.amazon.com/sagemaker/experiments/](https://aws.amazon.com/sagemaker/experiments/)
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| SageMaker | [https://aws.amazon.com/sagemaker/experiments/](https://aws.amazon.com/sagemaker/experiments/)
    |'
- en: Table 8.2 – Examples of tools for teaching machine learning experiments
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.2 – 教学机器学习实验的工具示例
- en: 'Here, we want to practice **MLflow Tracking** in Python. First, we need to
    import the required libraries:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们想要在 Python 中练习 **MLflow Tracking**。首先，我们需要导入所需的库：
- en: '[PRE11]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Then, we must define a function for evaluating the results of the models we
    would like to test:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须定义一个函数来评估我们想要测试的模型的结果：
- en: '[PRE12]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next, we must load the breast cancer dataset from `scikit-learn` for modeling:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须从 `scikit-learn` 加载乳腺癌数据集以进行建模：
- en: '[PRE13]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now, we are ready to define an experiment using `mlflow`:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备使用 `mlflow` 定义一个实验：
- en: '[PRE14]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, we must go over three different numbers of decision trees, or three different
    numbers of estimators, to build, train, and test three different random forest
    models on the loaded breast cancer dataset. All the information from these three
    runs will be stored within the specified experiment but as different runs. As
    you can see in the following code, we use different functionalities in `mlflow`:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们必须检查三个不同的决策树数量，或者三个不同的估计器数量，在加载的乳腺癌数据集上构建、训练和测试三个不同的随机森林模型。这三个运行的所有信息都将存储在指定的实验中，但作为不同的运行。正如你可以在下面的代码中看到的那样，我们使用了
    `mlflow` 的不同功能：
- en: '`mlflow.start_run`: To start a run as part of an experiment'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlflow.start_run`：作为实验的一部分启动一个运行'
- en: '`mlflow.log_param`: To log the number of estimators as a hyperparameter of
    the model'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlflow.log_param`：为了记录模型作为超参数的估计器数量'
- en: '`mlflow.log_metric`: To log the calculated metric for the performance of the
    model on the defined test set'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlflow.log_metric`：为了记录在定义的测试集上模型性能的计算指标'
- en: '`mlflow.sklearn.log_model`: To log the model:'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlflow.sklearn.log_model`：为了记录模型：'
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can also retrieve an already stored experiment, as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以检索已存储的实验，如下所示：
- en: '[PRE16]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Then, we can get information on different runs in that experiment:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以获取该实验中不同运行的详细信息：
- en: '[PRE17]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can also identify the best runs according to a metric used for model testing,
    which is ROC-AUC in this example:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据用于模型测试的指标来识别最佳运行，例如本例中的 ROC-AUC：
- en: '[PRE18]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This results in the following output:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE19]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can also delete runs of a run or an experiment altogether if needed, as
    follows. But you need to make sure you wish to delete such information:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，我们还可以删除运行或实验的运行，如下所示。但你需要确保你确实希望删除此类信息：
- en: '[PRE20]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In this section, you learned about experiment tracking in a machine learning
    setting. You will learn more about the techniques you can use for risk control
    in your machine learning projects in the next two chapters.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你学习了在机器学习环境中进行实验跟踪。你将在下一两章中学习更多关于你在机器学习项目中用于风险控制的技术。
- en: Summary
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about test-driven development using unit testing
    to control risks in your machine learning development projects. You learned about
    unit testing in Python using the `pytest` library. We also briefly reviewed the
    concept of differential testing, which helps you in comparing different versions
    of your machine learning modules and software. Later, you learned about model
    experiment tracking as an important tool that not only facilitates your model
    experimentations and selection but also helps you in risk control in your machine
    learning projects. You practiced using `mlflow` in Python as one of the widely
    used machine learning experiment tracking tools. Now, you know how to develop
    reliable models and programming modules through test-driven development and experiment
    tracking.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了使用单元测试进行驱动开发以控制你的机器学习开发项目中的风险。你学习了使用 `pytest` 库在 Python 中的单元测试。我们还简要回顾了差分测试的概念，这有助于你比较你的机器学习模块和软件的不同版本。稍后，你学习了模型实验跟踪作为一项重要工具，它不仅有助于你的模型实验和选择，还有助于你在机器学习项目中进行风险控制。你练习了使用
    `mlflow` 作为广泛使用的机器学习实验跟踪工具之一。现在，你知道如何通过测试驱动开发和实验跟踪来开发可靠的模型和编程模块。
- en: In the next chapter, you will learn about strategies to test models, assess
    their qualities, and monitor their performance in production. You will learn about
    practical methods for model monitoring, integration testing, and model pipeline
    and infrastructure testing.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习关于测试模型、评估其质量以及监控其在生产中的性能的策略。你将了解模型监控、集成测试和模型管道及基础设施测试的实用方法。
- en: Questions
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: How does `pytest` help you in developing code modules in your machine learning
    projects?
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`pytest` 如何帮助你开发机器学习项目中的代码模块？'
- en: How do `pytest` fixtures help you in using `pytest`?
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`pytest` fixtures 如何帮助你使用 `pytest`？'
- en: What is differential testing and when do you need it?
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是差分测试，何时需要它？
- en: What is `mlflow` and how does it help you in your machine learning modeling
    projects?
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是 `mlflow` 以及它如何帮助你在机器学习建模项目中？
- en: References
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Herbold, Steffen, and Steffen Tunkel. *Differential testing for machine learning:
    an analysis for classification algorithms beyond deep learning*. Empirical Software
    Engineering 28.2 (2023): 34.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Herbold, Steffen, 和 Steffen Tunkel. *机器学习中的差分测试：超越深度学习的分类算法分析*. 实证软件工程 28.2
    (2023): 34。'
- en: 'Lichman, M. (2013). *UCI Machine Learning Repository* [[https://archive.ics.uci.edu/ml](https://archive.ics.uci.edu/ml)].
    Irvine, CA: University of California, School of Information and Computer Science.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lichman, M. (2013). *UCI 机器学习仓库* [[https://archive.ics.uci.edu/ml](https://archive.ics.uci.edu/ml)]。Irvine,
    CA：加州大学信息与计算机科学学院。
- en: 'Gulzar, Muhammad Ali, Yongkang Zhu, and Xiaofeng Han. *Perception and practices
    of differential testing*. 2019 IEEE/ACM 41st International Conference on Software
    Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE, 2019.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gulzar, Muhammad Ali, Yongkang Zhu, 和 Xiaofeng Han. *差分测试的感知与实践*. 2019 IEEE/ACM
    第41届国际软件工程会议：软件工程实践（ICSE-SEIP）。IEEE，2019。
