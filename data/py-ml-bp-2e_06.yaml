- en: Predict whether Your Content Will Go Viral
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测你的内容是否会成为病毒式传播
- en: Like many great things, this all begins with a bet. It was 2001, and Jonah Peretti,
    a graduate student at MIT at the time, was procrastinating. Instead of writing
    his thesis, he had decided to take up Nike on their offer to personalize a pair
    of sneakers. Under a recently launched program, anyone could do so from their
    website, NIKEiD. The only problem, at least from Nike's point of view, was that
    emblazoning them with the word *sweatshop*, as Peretti had requested, was a non-starter.
    Peretti, in a series of emails, demurred pointing out that in no way did the word
    fall into any of the categories of objectionable terms that would result in his
    personalization request being rejected.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多伟大的事物一样，这一切都始于一场赌注。那是2001年，乔纳·佩雷蒂当时是麻省理工学院的研究生，他在拖延。与其写论文，他决定接受耐克提供的定制运动鞋服务。在耐克最近推出的一个项目下，任何人都可以通过他们的网站NIKEiD来定制鞋子。唯一的问题，至少从耐克的角度来看，就是佩雷蒂要求在鞋子上印上“*sweatshop*”字样，这显然是不可行的。佩雷蒂通过一系列电子邮件回应，指出这个词绝不属于任何会导致个性化请求被拒绝的敏感词汇类别。
- en: Peretti, believing others might find the back-and-forth with Nike's customer
    service representatives amusing as well, forwarded them to a number of close friends.
    Within days, the emails had found their way into inboxes across the world. Major
    media outlets, such as Time, Salon, The Guardian, and even the Today Show, had
    picked up on it. Peretti was at the center of a viral sensation.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 佩雷蒂认为其他人也许会觉得他与耐克客服代表之间的来回邮件很有趣，于是将这些邮件转发给了几位亲密的朋友。几天之内，这些邮件传到了全世界的收件箱里。包括《时代》杂志、Salon、《卫报》以及《今日秀》等主要媒体纷纷报道。佩雷蒂成为了一场病毒式现象的中心。
- en: But the question that began nagging at Peretti was, could this sort of thing
    be replicated? His friend, Cameron Marlow, had been preparing to write his PhD
    thesis on viral phenomena, and was adamant that such things were far too complex
    for anyone to engineer. And it is here that the bet comes into play. Marlow wagered
    that Peretti could not repeat the success he had enjoyed with that original set
    of emails with Nike.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 但困扰佩雷蒂的问题是，这种事情能否被复制？他的朋友卡梅伦·马洛正在准备写他的博士论文，研究病毒式现象，并坚信这种事情过于复杂，任何人都无法复制。而在这里，赌注开始起作用。马洛打赌，佩雷蒂无法复制他在最初那组与耐克的电子邮件中获得的成功。
- en: Fast forward 15 years, and Jonah Peretti leads the website whose name has become
    synonymous with virality—BuzzFeed. With more than 77 million unique visitors in
    2015, it ranked higher than the New York Times in total reach. I think it's safe
    to say that Peretti won that bet.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 快进到15年后，乔纳·佩雷蒂领导着那个名字已与病毒式传播划上等号的网站——BuzzFeed。2015年，它的独立访客超过7700万，排名超越了《纽约时报》的总覆盖面。我想可以放心地说，佩雷蒂赢得了那场赌注。
- en: But how exactly did Peretti do it? How did he piece together the secret formula
    for creating content that spreads like wildfire? In this chapter, we'll attempt
    to unravel some of these mysteries. We'll examine some of the most shared content
    and attempt to find the common elements that differentiate it from the content
    people were less willing to share.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 那么佩雷蒂到底是如何做到的呢？他是如何拼凑出创造如野火般传播内容的秘密公式的？在本章中，我们将尝试解开其中的一些谜团。我们将研究一些最具分享性的内容，并尝试找出与人们不太愿意分享的内容之间的共同点。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: What does research tell us about virality?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究告诉我们关于病毒式传播的什么？
- en: Sourcing shared counts and content
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取共享数量和内容
- en: Exploring the features of shareability
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索分享性特点
- en: Building a predictive content scoring model
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个预测内容得分模型
- en: What does research tell us about virality?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 研究告诉我们关于病毒式传播的什么？
- en: Understanding sharing behavior is big business. As consumers become increasingly
    blind to traditional advertising year on year, the push is on to go beyond simple
    pitches to tell engaging stories. And increasingly, the success of these endeavors
    is measured in social shares. Why go to so much trouble? Because, as a brand,
    every share I receive represents another consumer I've reached—all without spending
    an additional cent.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 理解分享行为是大生意。随着消费者越来越对传统广告视而不见，推动的力量是超越简单的推销，讲述引人入胜的故事。越来越多地，这些努力的成功是通过社交分享来衡量的。为什么要这么麻烦？因为作为一个品牌，每一次分享都代表着我接触到的另一个消费者——而这一切不需要花费额外的一分钱。
- en: 'Because of this value, several researchers have examined sharing behavior in
    the hope of understanding what motivates it. Among the reasons researchers have
    found are the following:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种价值，一些研究者已经研究了分享行为，希望了解其动机。研究者们发现的动机包括以下几点：
- en: To provide practical value to others (an altruistic motive)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了为他人提供实际价值（利他动机）
- en: To associate ourselves with certain ideas and concepts (an identity motive)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了与某些观念和概念关联（身份动机）
- en: To bond with others around a common emotion (a communal motive)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了与他人围绕共同的情感建立联系（社群动机）
- en: With regard to the last motive, one particularly well-designed study looked
    at the 7,000 pieces of content from the New York Times to examine the effect of
    emotion on sharing. They found that simple emotional sentiment was not enough
    to explain sharing behavior, but when combined with emotional arousal, the explanatory
    power was greater.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 关于最后一个动机，有一项特别精心设计的研究调查了《纽约时报》上的7,000篇内容，研究了情感对分享的影响。他们发现，仅仅简单的情感倾向不足以解释分享行为，但当情感与情绪激发相结合时，解释力更强。
- en: 'For example, while sadness has a strong negative valence, it is considered
    to be a low arousal state. Anger, on the other hand, has a negative valence, which
    is paired with a high arousal state. As such, stories that sadden the reader tend
    to generate far fewer stories than anger-inducing stories. Is it any wonder then
    that much of the *fake news* that plays such a large part in politics these days
    comes in this form? Following image shows the same result:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，尽管悲伤具有强烈的负面情感，它被认为是一种低激发状态。而愤怒则具有负面情感，且与高度激发状态相伴。因此，令读者感到悲伤的故事往往生成的分享远少于激怒读者的故事。那么，难道我们不应该感到惊讶的是，如今在政治中起着重要作用的*假新闻*往往就是这种形式吗？下图展示了相同的结果：
- en: '![](img/9b9b8c3b-d282-4c1f-890b-1b728d14e6cf.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9b9b8c3b-d282-4c1f-890b-1b728d14e6cf.png)'
- en: 'Figure taken from *What Makes Online Content Viral?* by Jonah Berger and Katherine
    L. Milkman, Journal of Marketing Research, available at: http://jonahberger.com/wp-content/uploads/2013/02/ViralityB.pdf'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 该图摘自*《什么使在线内容具有病毒性？》*，作者：乔纳·伯杰（Jonah Berger）与凯瑟琳·L·米尔克曼（Katherine L. Milkman），《市场营销研究杂志》，可通过以下网址获得：http://jonahberger.com/wp-content/uploads/2013/02/ViralityB.pdf
- en: 'This covers the motivational aspects, but if we hold those factors constant,
    how do other attributes affect the virality of a piece of content? Some of these
    factors could include the following: headline wording, headline length, headline
    parts of speech, content length, social network of post, the topic, the timeliness
    of the subject matter, and so on. Without a doubt, a person could spend their
    entire life studying this phenomenon. For now, however, we''ll just spend the
    next 30 or so pages doing so. From there, you can decide whether you''d like to
    take it further.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分内容涵盖了动机方面的内容，但如果我们将这些因素保持不变，其他属性如何影响内容的病毒性呢？其中的一些因素可能包括以下内容：标题措辞、标题长度、标题的词性、内容长度、发布的社交网络、主题、内容的时效性等等。毫无疑问，一个人可以花费一生的时间研究这一现象。然而，现阶段，我们只会花大约30页左右的篇幅来进行探讨。从那里，你可以决定是否希望进一步深入研究。
- en: Sourcing shared counts and content
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享计数和内容的来源
- en: Before we can begin exploring which features make content shareable, we need
    to get our hands on a fair amount of content, as well as data on how often it's
    shared. Unfortunately, securing this type of data has gotten more difficult in
    the last few years. In fact, when the first edition of this book came out in 2016,
    this data was easily obtainable. But today, there appears to be no free sources
    of this type of data, though if you are willing to pay, you can still find it.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始探讨哪些特征使内容具有可分享性之前，我们需要收集大量的内容，并获取有关这些内容被分享的频率的数据。不幸的是，获取这类数据在过去几年变得更加困难。实际上，当本书的第一版在2016年出版时，这些数据是很容易获得的。但如今，似乎没有免费的数据来源，尽管如果你愿意支付费用，仍然可以找到这些数据。
- en: 'Fortunately for us, I have a dataset that was collected from a now defunct
    website, `ruzzit.com`. This site, when it was active, tracked the most shared
    content over time, which is exactly what we require for this project:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我拥有一个从现已关闭的网站`ruzzit.com`收集的数据集。当这个网站还在运营时，它追踪了随着时间推移分享次数最多的内容，这正是我们这个项目所需要的：
- en: '![](img/bca0d0d0-360c-413e-a842-42d21fb7502f.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bca0d0d0-360c-413e-a842-42d21fb7502f.png)'
- en: 'We''ll begin by loading our imports into our notebook, as we always do, and
    then load in the data. This particular data is in the form of a JSON file. We
    can read it in using the pandas `read_json()` method, as demonstrated in the following
    code block:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先将我们的导入文件加载到笔记本中，像往常一样，然后加载数据。这个数据是JSON格式的。我们可以使用pandas的`read_json()`方法读取，如下所示：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding code generates the following output:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码会生成以下输出：
- en: '![](img/89f77732-6fef-499e-b962-3e4066a30c3e.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/89f77732-6fef-499e-b962-3e4066a30c3e.png)'
- en: 'Let''s take a look at the columns of this dataset to better understand what
    we''ll be working with:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这个数据集的列，以更好地理解我们将要处理的内容：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The preceding code generates the following output:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码会生成以下输出：
- en: '![](img/65c84592-3c86-4e83-8d6d-788da676f882.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/65c84592-3c86-4e83-8d6d-788da676f882.png)'
- en: 'Now, let''s walk through what each of these columns represents:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来逐一看看这些列代表的含义：
- en: '`title`: The title of the article'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`title`: 文章的标题'
- en: '`link`: The `ruzzit.com` link'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`link`: `ruzzit.com`的链接'
- en: '`bb`: The number of Facebook likes'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bb`: Facebook的点赞次数'
- en: '`lnkdn`: The number of LinkedIn shares'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lnkdn`: LinkedIn分享次数'
- en: '`pins`: The number of Pinterest pins'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pins`: Pinterest上的钉住次数'
- en: '`date`: The date of the article'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`date`: 文章的日期'
- en: '`redirect`: The link to the original article'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`redirect`: 原始文章的链接'
- en: '`pg_missing`: A field that describes whether that page is available'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pg_missing`: 描述该页面是否可用的字段'
- en: '`img_link`: The link to the image for the article'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`img_link`: 文章中图片的链接'
- en: '`json_data`: Additional data pertaining to the article'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`json_data`: 文章的附加数据'
- en: '`site`: The domain the article is hosted on'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`site`: 文章托管的网站域名'
- en: '`img_count`: The number of images contained in the article'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`img_count`: 文章中包含的图片数量'
- en: '`entities`: Person-, place-, and thing-related features of the article'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`entities`: 与人物、地点和事物相关的文章特征'
- en: '`html`: The body of the article'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`html`: 文章的正文'
- en: '`text`: The text of the body of the article'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text`: 文章正文的文本'
- en: 'Another feature that will be instructive is the word count of each article.
    We don''t have that in our data currently, so let''s go ahead and create a function
    that will provide this for us:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有用的功能是每篇文章的字数。我们目前的数据中没有这个信息，因此让我们创建一个函数来提供字数：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding code generates the following output:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码会生成以下输出：
- en: '![](img/efe55afa-952b-41db-b88c-7a3f2dae6855.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/efe55afa-952b-41db-b88c-7a3f2dae6855.png)'
- en: 'Let''s add more features. We''ll add the most prominent color of the first
    image on the page. The colors for each image are listed by RGB value in the JSON
    data, so we can extract it from there:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来添加更多功能。我们将提取页面中第一张图片的最突出颜色。每张图片的颜色以RGB值的形式列在JSON数据中，因此我们可以从中提取：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The preceding code generates the following output:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码会生成以下输出：
- en: '![](img/e8be8d5f-ad65-4e2d-8fbb-ddf8ec321b25.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e8be8d5f-ad65-4e2d-8fbb-ddf8ec321b25.png)'
- en: We've pulled the most prominent color from the first image as an RGB value,
    but we have also transformed that into a hex value. We'll use that later when
    we examine the image colors.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从第一张图片中提取了最突出颜色的RGB值，同时也将其转换为十六进制值。稍后我们会在分析图片颜色时使用这个值。
- en: With our data now ready, we can begin to perform our analysis. We're going to
    attempt to find what makes content highly shareable.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 数据现在准备好了，我们可以开始进行分析。我们将尝试找出是什么让内容具有高度的分享性。
- en: Exploring the features of shareability
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索分享功能
- en: The stories we have collected here represent roughly the 500 most shared pieces
    of content in 2015 and early 2016\. We're going to try to deconstruct these articles
    to find the common traits that make them so shareable. We'll begin by looking
    at the image data.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里收集的故事大约代表了2015年和2016年初最具分享性的500篇内容。我们将尝试拆解这些文章，找出让它们如此具有分享性的共同特征。我们将从图片数据开始。
- en: Exploring image data
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索图片数据
- en: 'Let''s begin by looking at the number of images included with each story. We''ll
    run a value count and then plot the numbers:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们先来看看每篇故事包含的图片数量。我们将对其进行计数，然后绘制图表：
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This should display an output similar to the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会显示类似以下的输出：
- en: '![](img/d6207023-2df1-40aa-a943-0b94c084e7bd.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d6207023-2df1-40aa-a943-0b94c084e7bd.png)'
- en: 'Now, let''s plot that same information:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们绘制相同的信息：
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This code generates the following output:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码会生成以下输出：
- en: '![](img/420c6673-50df-4242-bbff-e11f21996146.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/420c6673-50df-4242-bbff-e11f21996146.png)'
- en: Already, I'm surprised by the numbers. The vast majority of stories have five
    pictures in them, while those stories that have either one or no pictures at all
    are quite rare.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 目前为止，我对这些数字感到惊讶。绝大多数故事都包含五张图片，而那些只有一张图片或完全没有图片的故事则相当罕见。
- en: 'Hence, we can see that people tend to share content with lots of images. Now,
    let''s take a look at the most common colors in those images:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到人们倾向于分享大量包含图片的内容。接下来，我们来看看这些图片中最常见的颜色：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This code generates the following output:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成了以下输出：
- en: '![](img/eb32ef86-1152-4fdf-8a25-5b11cac04f3d.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb32ef86-1152-4fdf-8a25-5b11cac04f3d.png)'
- en: 'I don''t know about you, but this isn''t extremely helpful given that I don''t
    see hex values as colors. We can, however, use a new feature in pandas called
    conditional formatting to help us out:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我不知道你怎么看，但对我来说，这并不十分有帮助，因为我并不能把十六进制值当作颜色来看。不过，我们可以使用 pandas 中的一个新功能——条件格式化来帮助我们：
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding code generates the following output:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '![](img/ebb9a741-3b26-4c14-9955-65c53d80d847.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ebb9a741-3b26-4c14-9955-65c53d80d847.png)'
- en: Clustering
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: This certainly helps, but the colors are so granular that we have over 450 unique colors
    in total. Let's use a bit of clustering to get this down to a more manageable
    range. Since we have the RBG values for each color, we can create a three-dimensional
    space to cluster them using the k-means algorithm. I won't go into the details
    of the algorithm here, but it is a fairly simple iterative algorithm based upon
    generating clusters by measuring the distance to centers and repeating. The algorithm
    does require us to select the *k*, or the number of clusters we expect. Because
    RGB ranges from 0 to 256, we'll use the square root of 256, which is 16\. That
    should give us a manageable number while retaining the characteristics of our
    palette.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这当然有所帮助，但颜色的粒度如此精细，以至于我们总共有超过 450 种独特的颜色。让我们使用一点聚类技术将其缩减到一个更易管理的范围。由于我们有每种颜色的
    RGB 值，因此我们可以创建一个三维空间，通过 k-means 算法对它们进行聚类。这里我不打算深入讲解该算法，但它是一个相当简单的迭代算法，基于通过测量与中心的距离来生成聚类并进行重复。该算法要求我们选择
    *k*，即我们期望的聚类数量。由于 RGB 的范围是从 0 到 256，我们将使用 256 的平方根，即 16。这样应该能给我们一个可管理的数量，同时保留我们调色板的特点。
- en: 'First, we''ll split our RGB values into individual columns:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将 RGB 值拆分成单独的列：
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, we''ll use this to run our k-means model and retrieve the center values:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用这个功能来运行我们的 k-means 模型，并获取中心值：
- en: '[PRE9]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This generates the following output:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '![](img/99774024-acd8-44f3-afc6-9911ae7f455c.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99774024-acd8-44f3-afc6-9911ae7f455c.png)'
- en: 'Now, we have the sixteen most popular dominant colors from the first image
    in each picture. Let''s check whether they are using our pandas `DataFrame.style()`
    method and the function we created previously to color our cells. We''ll need
    to set our index equal to the hex value of the three columns to use our `color_cells`
    function, so we''ll do that as well:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们从每张图片的第一张图片中提取了十六种最流行的主导颜色。接下来，我们来看看它们是否使用了我们在之前创建的 `DataFrame.style()`
    方法，以及用于为单元格着色的函数。我们需要将索引设置为三列的十六进制值，以便使用我们的 `color_cells` 函数，因此我们也会做这一步：
- en: '[PRE10]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This generates the following output:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '![](img/b49f4800-869d-4ba3-b975-48fc31cfe1b2.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b49f4800-869d-4ba3-b975-48fc31cfe1b2.png)'
- en: So there you have it; those are the most common colors you will see (at least
    for the first image) in the most frequently shared content. This is a bit more
    on the drab side than I had expected as the first several all seem to be shades
    of beige and gray.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，结果就是这些；这些是你在最常被分享的内容中看到的最常见的颜色（至少是第一张图片中的颜色）。这些颜色比我预期的有些单调，因为前几种似乎都是米色和灰色的不同色调。
- en: Now, let's move on and examine the headlines of our stories.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续，检查一下我们故事的头条新闻。
- en: Exploring the headlines
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索头条新闻
- en: 'Let''s start by creating a function we can use to examine the most common tuples.
    We''ll set it up so that we can use it later on the body text as well. We''ll
    do this using the Python **Natural Language Toolkit** (**NLTK**) library. This
    can be pip installed if you don''t have it currently:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建一个可以用来检查最常见元组的函数开始。我们将使它可以在稍后的正文文本中使用。我们将使用 Python **自然语言工具包**（**NLTK**）库来实现。如果你还没有安装这个库，可以通过
    pip 安装：
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: There is a lot in there, so let's unpack it. We created a function that takes
    in a series, an integer, and a Boolean value. The integer determines the *n* we'll
    use for n-gram parsing, while the Boolean determines whether or not we exclude
    stop words. The function returns the number of tuples per row and the frequency
    for each tuple.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这里面有很多内容，我们来逐步解析。我们创建了一个函数，该函数接收一个系列、一个整数和一个布尔值。整数确定我们将用于 n-gram 解析的 *n* 值，而布尔值决定是否排除停用词。该函数返回每行的元组数和每个元组的频率。
- en: 'Let''s run it on our headlines, while retaining the stop words. We''ll begin
    with just single words:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在保留停用词的情况下运行这个，首先从单个词开始：
- en: '[PRE12]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This generates the following output:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成以下输出：
- en: '![](img/2b68bf0e-a421-4183-8ac8-162b1fa0612f.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2b68bf0e-a421-4183-8ac8-162b1fa0612f.png)'
- en: 'Now, we have the word count for each headline. Let''s see what the stats on
    this look like:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们得到了每个标题的字数统计。让我们看看这些统计数据是什么样的：
- en: '[PRE13]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This code generates the following output:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成以下输出：
- en: '![](img/8a848a0e-9844-406f-9848-57aba1428cfc.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8a848a0e-9844-406f-9848-57aba1428cfc.png)'
- en: 'We can see that the median headline length for our viral stories comes in at
    exactly 11 words. Let''s take a look at the most frequently used words:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，我们的病毒式故事的中位数标题长度恰好是 11 个单词。接下来，我们来看看最常用的单词：
- en: '![](img/94de7857-688e-4dcc-af0f-68970d4e398e.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/94de7857-688e-4dcc-af0f-68970d4e398e.png)'
- en: 'That is not exactly useful, but is in keeping with what we might expect. Now,
    let''s take a look at the same information for bi-grams:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不完全有用，但符合我们可能的预期。现在，我们来看一下双字组（bi-grams）的相同信息：
- en: '[PRE14]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This generates the following output:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成以下输出：
- en: '![](img/3b85a514-c0c3-4493-bf6c-804bb0a83c1a.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3b85a514-c0c3-4493-bf6c-804bb0a83c1a.png)'
- en: This is definitely more interesting. We can start to see some of the components
    of the headlines over and over again. The two that stand out are `(donald, trump)`
    and `(dies, at)`. Trump makes sense as he said some headline-grabbing statements
    during the election, but I was surprised by the *dies* headlines. I took a look
    at the headlines, and apparently a number of high-profile people died in the year
    in question, so that also makes sense.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这明显更有趣了。我们开始看到标题中一些重复出现的元素。最突出的是 `(donald, trump)` 和 `(dies, at)`。特朗普在选举期间发表了一些引人注目的声明，所以特朗普的名字出现很有道理，但我对
    *dies* 这个词的标题感到惊讶。我查看了这些标题，显然有很多高调的人物在那一年去世，所以这也能解释得通。
- en: 'Now, let''s run this with the stop words removed:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在移除停用词后运行这个：
- en: '[PRE15]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This generates the following output:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成以下输出：
- en: '![](img/e644b50e-4c13-449f-87e8-70d0bf290465.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e644b50e-4c13-449f-87e8-70d0bf290465.png)'
- en: Again, we can see many things we might expect. It looks like if we changed how
    we parsed numbers (replacing each of them with a single identifier like number),
    we would likely see more of these bubble up. I'll leave that as an exercise to
    the reader, if you'd like to attempt that.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们可以看到很多我们可能预期的结果。看起来如果我们改变解析数字的方式（将每个数字替换为一个单一标识符，比如数字），我们可能会看到更多这些词汇浮现出来。如果你想尝试，留给读者自己去做这个练习吧。
- en: 'Now, let''s take a look at tri-grams:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来看看三字组（tri-grams）：
- en: '[PRE16]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This code generates the following output:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成以下输出：
- en: '![](img/9d842935-566f-41b8-9acd-1dd4dfcc85c2.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9d842935-566f-41b8-9acd-1dd4dfcc85c2.png)'
- en: 'It seems that the more words we include, the more the headlines come to resemble
    the classic BuzzFeed prototype. In fact, let''s see whether that''s the case.
    We haven''t looked at which sites produce the most viral stories; let''s see whether
    BuzzFeed leads the charts:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们包含的单词越多，标题就越接近经典的 BuzzFeed 原型。实际上，咱们来看看是不是这样。我们还没有查看哪些网站产生了最多的病毒式故事；让我们看看
    BuzzFeed 是否占据了榜首：
- en: '[PRE17]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This generates the following output:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成以下输出：
- en: '![](img/ca85393f-97c5-4256-a0cf-771359f589e1.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ca85393f-97c5-4256-a0cf-771359f589e1.png)'
- en: We can clearly see that BuzzFeed dominates the list. In a distant second place,
    we can see The Huffington Post, which incidentally is another site that Jonah
    Peretti worked for. It appears that studying the science of virality can pay big
    dividends.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以清楚地看到，BuzzFeed 主导了这个列表。排在第二位的是《赫芬顿邮报》，顺便提一下，乔纳·佩雷蒂曾在这家网站工作过。看起来，研究病毒传播的科学确实能带来丰厚的回报。
- en: So far, we have examined images and headlines. Now, let's move on to examining
    the full text of the stories.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经检查了图像和标题。接下来，我们将开始检查故事的完整文本。
- en: Exploring the story content
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索故事内容
- en: In the last section, we created a function to examine the common n-grams that
    are found in the headlines of our stories. Now, let's apply that to explore the
    full content of our stories.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们创建了一个函数来检查我们故事标题中常见的 n-grams。现在，让我们将这一方法应用到探索故事的完整内容上。
- en: 'We''ll start by exploring bi-grams with the stop words removed. Since headlines
    are so short compared to the body of the stories, it makes sense to look at them
    with the stop words intact, although within the story, it typically makes sense
    to eliminate them:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先探索去除停用词的二元组。由于标题相较于正文较短，因此查看带有停用词的标题是合理的，而在正文中，通常需要去除停用词：
- en: '[PRE18]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This generates the following output:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '![](img/134d9d43-1e9e-4c0d-9f18-fc64adf7b4be.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/134d9d43-1e9e-4c0d-9f18-fc64adf7b4be.png)'
- en: Interestingly, we can see that the frivolity we saw in the headlines has completely
    disappeared. The text is now filled with content discussing terrorism, politics,
    and race relations.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们可以看到，在标题中的轻松氛围完全消失了。现在，文本充满了讨论恐怖主义、政治和种族关系的内容。
- en: How is it possible that the headlines are light-hearted, while the text is dark
    and controversial? I would suggest that this is because articles such as *13 Puppies
    Who Look Like Elvis* are going to have substantially less text than *The History
    of the Islamic State*.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 既然标题如此轻松愉快，而正文却显得沉重且富有争议，怎么可能是这样呢？我认为这是因为像《*13只看起来像猫王的小狗*》这样的文章，其正文文字会比《*伊斯兰国历史*》少得多。
- en: 'Let''s take a look at one more. We''ll evaluate the tri-grams for the story
    bodies:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一个。我们将评估故事正文的三元组（tri-grams）：
- en: '[PRE19]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This code generates the following output:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成了以下输出：
- en: '![](img/7c15e854-45cf-4047-9aa0-8b7fc40323a0.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7c15e854-45cf-4047-9aa0-8b7fc40323a0.png)'
- en: We appear to have suddenly entered the land of advertising and social pandering.
    With that, let's move on to building a predictive model for content scoring.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们似乎突然进入了广告和社会迎合的领域。接下来，让我们开始构建一个用于内容评分的预测模型。
- en: Building a predictive content scoring model
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建预测内容评分模型
- en: Let's use what we have learned to create a model that can estimate the share
    counts for a given piece of content. We'll use the features we have already created,
    along with a number of additional ones.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运用所学知识，创建一个可以估算给定内容分享数的模型。我们将使用已经创建的特征，并结合一些额外的特征。
- en: Ideally, we would have a much larger sample of content—especially content that
    had more typical share counts—but we'll have to make do with what we have here.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们会有一个更大的内容样本，尤其是那些有更多典型分享数的内容，但我们只能利用手头的这些。
- en: We're going to be using an algorithm called **random forest regression**. In
    previous chapters, we looked at a more typical implementation of random forests
    that is based on classification, but here we're going to attempt to predict the
    share counts. We could consolidate our share classes into ranges, but it is preferable
    to use regression when dealing with continuous variables, which is what we're
    working with here.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一种叫做**随机森林回归**的算法。在之前的章节中，我们讨论了基于分类的随机森林的更典型实现，但在这里，我们将尝试预测分享数。我们可以将分享类别合并为区间，但在处理连续变量时，使用回归更为合适，而我们这里正是处理的连续变量。
- en: 'To begin, we''ll create a bare-bones model. We''ll use the number of images,
    the site, and the word count. We''ll train our model in terms of the number of
    Facebook likes. We''re also going to be splitting our data into two sets: a training
    set and a test set.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将创建一个简化的模型。我们将使用图像数量、网站和字数作为特征，并以 Facebook 点赞数作为训练目标。我们还将把数据分为两个集合：训练集和测试集。
- en: 'First, we''ll import the scikit-learn library, and then we''ll prepare our
    data by removing the rows with nulls, resetting our index, and finally splitting
    the frame into our training and test set:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将导入 scikit-learn 库，然后通过删除空值行、重置索引，最后将数据框分为训练集和测试集来准备数据：
- en: '[PRE20]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We used a random number generator with a probability set for approximately
    two-thirds and one-third to determine which row items (based on their `index`)
    would be placed in each set. Setting the probabilities like this ensures that
    we get approximately twice the number of rows in our training set compared to
    the test set. We can see this in the following code:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了一个随机数生成器，并设置了约三分之二和三分之一的概率，用来决定哪些行项（根据它们的`index`）将被分配到每个集合中。通过这种概率设置，我们确保训练集的行数大约是测试集的两倍。我们可以在以下代码中看到这一点：
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The preceding code generates the following output:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![](img/4a1c3eea-65ba-4512-b7f8-98619dfc242d.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4a1c3eea-65ba-4512-b7f8-98619dfc242d.png)'
- en: 'Now, we''ll continue with preparing our data. Next, we need to set up categorical
    encoding for our sites. Currently, our DataFrame has the name for each site represented
    with a string. We need to use dummy encoding. This creates a column for each site,
    and if the row has that particular site, then that column will be filled with
    a `1`, while all the other columns for sites will be coded with a `0`. Let''s
    do that now:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将继续准备我们的数据。接下来，我们需要为我们的网站设置分类编码。目前，我们的 DataFrame 中每个网站的名称都是以字符串形式表示的。我们需要使用虚拟编码。这会为每个网站创建一列，如果该行包含该网站，那么该列将填充为`1`，而所有其他网站的列将用`0`进行编码。现在我们来做这个：
- en: '[PRE22]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The preceding code generates the following output:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![](img/e33a452e-3b1d-4e81-bcad-405e5ca0f5ab.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e33a452e-3b1d-4e81-bcad-405e5ca0f5ab.png)'
- en: You can see from the preceding output how the dummy encoding appears.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从上述输出中看到虚拟编码是如何显示的。
- en: 'We''ll now continue:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们继续：
- en: '[PRE23]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'With that, we''ve set up our `X_test`, `X_train`, `y_test`, and `y_train` variables.
    Now, we''re going to use our training data to build our model:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些步骤，我们已经设置好了我们的`X_test`、`X_train`、`y_test`和`y_train`变量。现在，我们将使用我们的训练数据来构建模型：
- en: '[PRE24]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'With those two lines of code, we have trained our model. Let''s use it to predict
    the Facebook likes for our test set:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这两行代码，我们已经训练了我们的模型。现在，让我们使用它来预测测试集中的 Facebook 点赞数：
- en: '[PRE25]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This code generates the following output:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成以下输出：
- en: '![](img/652a88fe-3dc0-4869-9bbf-bae54f746b38.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/652a88fe-3dc0-4869-9bbf-bae54f746b38.png)'
- en: 'Here, we can see the predicted values, the actual value, and the difference
    as a percentage  side by side. Let''s take a look at the descriptive stats for
    this:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到预测值、实际值以及它们之间的差异（以百分比形式）并排显示。让我们来看一下这些数据的描述性统计：
- en: '[PRE26]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The preceding code generates the following output:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![](img/85467ba6-ebe3-4d00-bb24-7d9c290c189a.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/85467ba6-ebe3-4d00-bb24-7d9c290c189a.png)'
- en: This looks amazing. Our median error is 0! Well, unfortunately, this is a particularly
    useful bit of information as errors are on both sides—positive and negative—and
    tend to average out, which is what we can see here. Let's look at a more informative
    metric to evaluate our model. We're going to look at root mean square error as
    a percentage of the actual mean.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来很棒。我们的中位数误差是0！不过，不幸的是，这实际上是一个相当有用的信息，因为误差在正负两边都有——并且倾向于平均化，这也是我们在这里看到的。让我们看看一个更有信息量的指标来评估我们的模型。我们将看一下均方根误差占实际均值的百分比。
- en: Evaluating the model
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型
- en: 'To illustrate why this is more useful, let''s run the following scenario on
    two sample series:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这为什么更有用，我们来在两个示例序列上运行以下场景：
- en: '[PRE27]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This generates the following output:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '![](img/3e6c455f-9fd7-426a-ad2c-83d1f49e5d69.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3e6c455f-9fd7-426a-ad2c-83d1f49e5d69.png)'
- en: 'Now, compare that to the mean:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将其与均值进行比较：
- en: '[PRE28]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This generates the following output:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '![](img/8601f8fe-5653-4dea-acef-3aa10929af7a.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8601f8fe-5653-4dea-acef-3aa10929af7a.png)'
- en: 'Clearly, the latter is the more meaningful statistic. Now, let''s run it for
    our model:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，后者是更有意义的统计数据。现在，我们来为我们的模型运行它：
- en: '[PRE29]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This generates the following output:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '![](img/31be237c-21be-42c2-8426-e4c19010c4ea.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/31be237c-21be-42c2-8426-e4c19010c4ea.png)'
- en: 'Suddenly, our awesome model looks a lot less awesome. Let''s take a look at
    some of the predictions our model made versus the actual values that can be seen
    in the data:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 突然间，我们的精彩模型看起来没那么精彩了。让我们来看看模型的部分预测值与实际值的对比：
- en: '[PRE30]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The preceding code generates the following output:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '![](img/651e35ce-564f-46c1-9ab5-84c5368adffc.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/651e35ce-564f-46c1-9ab5-84c5368adffc.png)'
- en: 'Based on what we can see here, the model—at least for this sample—tends to
    modestly underpredict the virality of the typical article, but then heavily underpredicts
    the virality for a small number. Let''s see what those are:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们在这里看到的数据，模型——至少在这个样本中——倾向于轻微低估典型文章的传播性，但对于少数几篇文章则严重低估其传播性。我们来看一下那些数据：
- en: '[PRE31]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The preceding code results in the following output:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码会产生以下输出：
- en: '![](img/dc0d413e-750f-4ab1-80ac-4ed042511fca.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dc0d413e-750f-4ab1-80ac-4ed042511fca.png)'
- en: From the preceding output, we can see that an article on *Malala* and an article
    on *a husband complaining about how much his stay-at-home wife costs him* greatly
    overshot the predicted numbers of our model. Both would seem to have high emotional
    valence.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中，我们可以看到，一篇关于*马拉拉*的文章和一篇关于*丈夫抱怨留守妻子花费过多*的文章，远远超出了我们模型预测的数字。这两篇文章似乎都具有较高的情感效价。
- en: Adding new features to our model
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向我们的模型添加新特征
- en: 'Now, let''s add another feature to our model. Let''s see whether adding the
    counts for words will help our model. We''ll use a `CountVectorizer` to do this.
    Much like what we did with the site names, we''ll be transforming individual words
    and n-grams into features:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们为我们的模型添加另一个特征。我们来看看，加入单词计数是否能帮助我们的模型。我们将使用`CountVectorizer`来完成这一操作。就像我们处理网站名称时一样，我们将把单个词和n-grams转换成特征：
- en: '[PRE32]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In the preceding lines, we have joined our existing features to our new n-gram
    features. Let''s train our model and see whether we have any improvement:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的几行中，我们将现有特征与新的n-gram特征结合起来。让我们训练我们的模型，看看是否有任何改善：
- en: '[PRE33]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This code generates the following output:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成了以下输出：
- en: '![](img/6334cdc0-b783-401e-b824-f4f149adc245.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6334cdc0-b783-401e-b824-f4f149adc245.png)'
- en: 'And if we check our error again, we will see the following:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再次检查我们的错误，我们将看到以下结果：
- en: '[PRE34]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The preceding code generates the following output:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '![](img/4f1d6244-a80d-4cfa-8456-5544081a5801.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4f1d6244-a80d-4cfa-8456-5544081a5801.png)'
- en: 'So it appears that we have a modestly improved model. Let''s add one more feature
    to our model—the word count of the title:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们的模型有了适度的改善。让我们再为模型添加一个特征——标题的单词数：
- en: '[PRE35]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This code generates the following output:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成了以下输出：
- en: '![](img/5f26bec4-8c20-45ec-b2ec-44f44c37328f.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f26bec4-8c20-45ec-b2ec-44f44c37328f.png)'
- en: It appears that each feature has modestly improved our model. There are certainly
    more features we could add to it. For example, we could add the day of the week
    and the hour of the posting, we could determine whether the article is a listicle
    by running a regex on the headline, or we could examine the sentiment of each
    article. But this only just touches on the features that could be important for
    modeling virality. We would certainly need to go much further to continue reducing
    the number of errors in our model.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来每个特征都对我们的模型有了一定的改进。当然，我们还有更多的特征可以添加。例如，我们可以添加星期几和发布时间的小时数，或者通过对标题进行正则表达式匹配来判断文章是否为列表文章，或者我们可以分析每篇文章的情感。但是，这仅仅触及了模型化病毒传播中可能重要的特征。我们当然需要走得更远，继续减少模型中的错误。
- en: I should also note that we have done only the most cursory testing of our model.
    Each measurement should be run multiple times to get a more accurate representation
    of the actual error rate. It is possible that there is no statistically discernible
    difference between our last two models since we only performed one test.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我还应该指出，我们对模型只做了最初步的测试。每个测量结果应该进行多次测试，以便更准确地表示实际的错误率。由于我们只进行了一次测试，可能没有统计学上显著的差异。
- en: Summary
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we examined what the common features of viral content are and
    how we can build a model to predict virality using a random forest regression.
    We also learned how to combine multiple types of features and how to split our
    model into training and test sets.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们考察了病毒式内容的共同特征，以及如何使用随机森林回归模型来预测病毒传播性。我们还学会了如何组合多种类型的特征，以及如何将模型拆分为训练集和测试集。
- en: Hopefully, you will take what you've learned here to build the next viral empire.
    If that doesn't work out, perhaps the next chapter on mastering the stock market
    will.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你能将你在这里学到的知识运用到下一个病毒式传播的帝国。如果那不行，也许下一章关于掌握股市的内容会有帮助。
